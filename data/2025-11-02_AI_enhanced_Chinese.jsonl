{"id": "2510.26009", "categories": ["cs.NI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.26009", "abs": "https://arxiv.org/abs/2510.26009", "authors": ["Jerry Horgan", "Alexander Nico-Katz", "Shelbi L. Jenkins", "Ashley N. Tittlebaugh", "Vivek Visan", "Rahan Bali", "Marco Ruffini", "Boulat A. Bash", "Daniel C. Kilper"], "title": "A Zero Added Loss Multiplexing (ZALM) Source Simulation", "comment": "7 pages, 7 figures", "summary": "Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded\nEPR pairs, with a rich parameter space that allows its performance to be\ntailored for specific applications. We present a modular ZALM simulator that\ndemonstrates how design choices affect output rate and fidelity. Built in\nNetSquid with QSI controllers, it exposes 20+ tunable parameters, supports\nIDEAL and REALISTIC modes, and provides reusable components for Spontaneous\nParametric Down Conversion (SPDC) sources, interference, Dense Wavelength\nDivision Multiplexing (DWDM) filtering, fiber delay, active polarization gates,\ndetectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM)\nvisibility, insertion loss, detector efficiency, gate errors, and attenuation.\nUsing this tool, we map trade offs among fidelity, link distance, and entangled\npairs per use, and show how SPDC bandwidth and DWDM grid spacing steer\nperformance. Using the default configuration settings, average fidelity emains\nconstant at 0.8 but the ebit rate decreases from 0.0175 at the source to 0.0 at\n50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate\nsignificantly without affecting fidelity. The simulator enables codesign of\nsource, filtering, and feedforward settings for specific quantum memories and\nintegrates as a building block for end to end quantum network studies.", "AI": {"tldr": "ZALM\u6280\u672f\u63d0\u4f9b\u5bbd\u5e26\u3001\u6bcf\u901a\u9053\u9884\u77e5EPR\u5bf9\uff0c\u5177\u6709\u4e30\u5bcc\u7684\u53c2\u6570\u7a7a\u95f4\u3002\u8be5\u6a21\u62df\u5668\u5c55\u793a\u4e86\u8bbe\u8ba1\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u8f93\u51fa\u7387\u548c\u4fdd\u771f\u5ea6\uff0c\u652f\u630120+\u53ef\u8c03\u53c2\u6570\u548c\u4e24\u79cd\u6a21\u5f0f\u3002", "motivation": "\u5f00\u53d1\u6a21\u5757\u5316ZALM\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u7814\u7a76\u8bbe\u8ba1\u9009\u62e9\u5bf9\u91cf\u5b50\u7ea0\u7f20\u6e90\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u652f\u6301\u7279\u5b9a\u91cf\u5b50\u5b58\u50a8\u5668\u7684\u534f\u540c\u8bbe\u8ba1\u3002", "method": "\u57fa\u4e8eNetSquid\u548cQSI\u63a7\u5236\u5668\u6784\u5efa\u6a21\u62df\u5668\uff0c\u5305\u542bSPDC\u6e90\u3001\u5e72\u6d89\u3001DWDM\u6ee4\u6ce2\u3001\u5149\u7ea4\u5ef6\u8fdf\u7b49\u53ef\u590d\u7528\u7ec4\u4ef6\uff0c\u91c7\u7528\u7269\u7406\u6a21\u578b\u6355\u83b7HOM\u53ef\u89c1\u6027\u3001\u63d2\u5165\u635f\u8017\u7b49\u53c2\u6570\u3002", "result": "\u9ed8\u8ba4\u914d\u7f6e\u4e0b\u5e73\u5747\u4fdd\u771f\u5ea6\u4fdd\u63010.8\uff0c\u4f46ebit\u7387\u4ece\u6e90\u7aef\u76840.0175\u964d\u81f350km\u5904\u76840.0\uff1b\u7f29\u5c0fSPDC\u7b80\u5e76\u5e26\u5bbd\u53ef\u663e\u8457\u63d0\u9ad8ebit\u7387\u800c\u4e0d\u5f71\u54cd\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u80fd\u591f\u4e3a\u7279\u5b9a\u91cf\u5b50\u5b58\u50a8\u5668\u534f\u540c\u8bbe\u8ba1\u6e90\u3001\u6ee4\u6ce2\u548c\u524d\u9988\u8bbe\u7f6e\uff0c\u5e76\u4f5c\u4e3a\u7aef\u5230\u7aef\u91cf\u5b50\u7f51\u7edc\u7814\u7a76\u7684\u6784\u5efa\u6a21\u5757\u3002"}}
{"id": "2510.26060", "categories": ["cs.NI", "C.2.2"], "pdf": "https://arxiv.org/pdf/2510.26060", "abs": "https://arxiv.org/abs/2510.26060", "authors": ["Sina Keshvadi"], "title": "Performance Analysis of Dynamic Equilibria in Joint Path Selection and Congestion Control", "comment": null, "summary": "Path-aware networking, a cornerstone of next-generation architectures like\nSCION and Multipath QUIC, empowers end-hosts with fine-grained control over\ntraffic forwarding. This capability, however, introduces a critical stability\nrisk: uncoordinated, greedy path selection by a multitude of agents can induce\npersistent, high-amplitude network oscillations. While this phenomenon is\nwell-known, its quantitative performance impact across key metrics has remained\npoorly understood. In this paper, we address this gap by developing the first\naxiomatic framework for analyzing the joint dynamics of path selection and\ncongestion control. Our model enables the formal characterization of the\nsystem's dynamic equilibria-the stable, periodic patterns of oscillation-and\nprovides a suite of axioms to rate their performance in terms of efficiency,\nloss avoidance, convergence, fairness, and responsiveness. Our analysis reveals\na fundamental trade-off in protocol design between predictable performance\n(efficiency, convergence) and user-centric goals (fairness, responsiveness). We\nprove, however, that no such trade-off exists among efficiency, convergence,\nand loss avoidance, which can be simultaneously optimized through careful\nparameter tuning. Furthermore, we find that agent migration can,\ncounter-intuitively, enhance stability by de-synchronizing traffic, a\ntheoretical result validated by our simulations. These findings provide a\nprincipled design map for engineering robust, high-performance protocols for\nthe future path-aware Internet.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u9996\u4e2a\u5206\u6790\u8def\u5f84\u9009\u62e9\u548c\u62e5\u585e\u63a7\u5236\u8054\u5408\u52a8\u6001\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u534f\u8bae\u8bbe\u8ba1\u4e2d\u53ef\u9884\u6d4b\u6027\u80fd\u4e0e\u7528\u6237\u4e2d\u5fc3\u76ee\u6807\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\uff0c\u5e76\u53d1\u73b0\u667a\u80fd\u4f53\u8fc1\u79fb\u53ef\u4ee5\u53cd\u76f4\u89c9\u5730\u589e\u5f3a\u7a33\u5b9a\u6027\u3002", "motivation": "\u8def\u5f84\u611f\u77e5\u7f51\u7edc\u8d4b\u4e88\u7ec8\u7aef\u4e3b\u673a\u7ec6\u7c92\u5ea6\u6d41\u91cf\u8f6c\u53d1\u63a7\u5236\u80fd\u529b\uff0c\u4f46\u975e\u534f\u8c03\u7684\u8d2a\u5a6a\u8def\u5f84\u9009\u62e9\u53ef\u80fd\u5f15\u53d1\u6301\u7eed\u9ad8\u5e45\u5ea6\u7f51\u7edc\u632f\u8361\uff0c\u8fd9\u79cd\u73b0\u8c61\u7684\u5b9a\u91cf\u6027\u80fd\u5f71\u54cd\u4e00\u76f4\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u4e86\u5206\u6790\u8def\u5f84\u9009\u62e9\u548c\u62e5\u585e\u63a7\u5236\u8054\u5408\u52a8\u6001\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u8868\u5f81\u7cfb\u7edf\u7684\u52a8\u6001\u5747\u8861\u72b6\u6001\uff0c\u5e76\u63d0\u4f9b\u4e00\u5957\u516c\u7406\u6765\u8bc4\u4f30\u5176\u6548\u7387\u3001\u4e22\u5305\u907f\u514d\u3001\u6536\u655b\u6027\u3001\u516c\u5e73\u6027\u548c\u54cd\u5e94\u6027\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u534f\u8bae\u8bbe\u8ba1\u4e2d\u53ef\u9884\u6d4b\u6027\u80fd\uff08\u6548\u7387\u3001\u6536\u655b\u6027\uff09\u4e0e\u7528\u6237\u4e2d\u5fc3\u76ee\u6807\uff08\u516c\u5e73\u6027\u3001\u54cd\u5e94\u6027\uff09\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\uff0c\u4f46\u6548\u7387\u3001\u6536\u655b\u6027\u548c\u4e22\u5305\u907f\u514d\u53ef\u4ee5\u540c\u65f6\u4f18\u5316\u3002\u667a\u80fd\u4f53\u8fc1\u79fb\u53ef\u4ee5\u53cd\u76f4\u89c9\u5730\u589e\u5f3a\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u672a\u6765\u8def\u5f84\u611f\u77e5\u4e92\u8054\u7f51\u8bbe\u8ba1\u7a33\u5065\u3001\u9ad8\u6027\u80fd\u534f\u8bae\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8bbe\u8ba1\u6307\u5357\u3002"}}
{"id": "2510.26071", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.26071", "abs": "https://arxiv.org/abs/2510.26071", "authors": ["Shenshen Luan", "Yumo Tian", "Xinyu Zhang", "Qingwen Zhang", "Tianheng Wang", "Yan Yang", "Shuguo Xie"], "title": "Symmetry-Driven Asynchronous Forwarding for Reliable Distributed Coordination in Toroidal Networks", "comment": null, "summary": "The proliferation of large-scale distributed systems, such as satellite\nconstellations and high-performance computing clusters, demands robust\ncommunication primitives that maintain coordination under unreliable links. The\ntorus topology, with its inherent rotational and reflection symmetries, is a\nprevalent architecture in these domains. However, conventional routing schemes\nsuffer from substantial packet loss during control-plane synchronization after\nlink failures. This paper introduces a symmetry-driven asynchronous forwarding\nmechanism that leverages the torus's geometric properties to achieve reliable\npacket delivery without control-plane coordination. We model packet flow using\na topological potential gradient and demonstrate that symmetry-breaking\nfailures naturally induce a reverse flow, which we harness for fault\ncircumvention. We propose two local forwarding strategies, Reverse Flow with\nCounter-facing Priority (RF-CF) and Lateral-facing Priority (RF-LF), that\nguarantee reachability to the destination via forward-flow phase transition\npoints, without protocol modifications or additional in-packet overhead.\nThrough percolation analysis and packet-level simulations on a 16 x 16 torus,\nwe show that our mechanism reduces packet loss by up to 17.5% under a 1% link\nfailure rate, with the RF-LF strategy contributing to 28% of successfully\ndelivered packets. This work establishes a foundational link between\ntopological symmetry and communication resilience, providing a lightweight,\nprotocol-agnostic substrate for enhancing distributed systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73af\u9762\u62d3\u6251\u5bf9\u79f0\u6027\u7684\u5f02\u6b65\u8f6c\u53d1\u673a\u5236\uff0c\u5229\u7528\u51e0\u4f55\u7279\u6027\u5b9e\u73b0\u53ef\u9760\u6570\u636e\u5305\u4f20\u8f93\uff0c\u65e0\u9700\u63a7\u5236\u5e73\u9762\u534f\u8c03\uff0c\u57281%\u94fe\u8def\u6545\u969c\u7387\u4e0b\u53ef\u51cf\u5c1117.5%\u7684\u6570\u636e\u5305\u4e22\u5931\u3002", "motivation": "\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\uff08\u5982\u536b\u661f\u661f\u5ea7\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\uff09\u9700\u8981\u5728\u4e0d\u7a33\u5b9a\u94fe\u8def\u4e0b\u4fdd\u6301\u534f\u8c03\u7684\u901a\u4fe1\u539f\u8bed\u3002\u4f20\u7edf\u8def\u7531\u65b9\u6848\u5728\u94fe\u8def\u6545\u969c\u540e\u7684\u63a7\u5236\u5e73\u9762\u540c\u6b65\u671f\u95f4\u5b58\u5728\u4e25\u91cd\u7684\u6570\u636e\u5305\u4e22\u5931\u95ee\u9898\u3002", "method": "\u5229\u7528\u73af\u9762\u62d3\u6251\u7684\u51e0\u4f55\u7279\u6027\uff0c\u63d0\u51fa\u5bf9\u79f0\u9a71\u52a8\u7684\u5f02\u6b65\u8f6c\u53d1\u673a\u5236\u3002\u901a\u8fc7\u62d3\u6251\u52bf\u68af\u5ea6\u5efa\u6a21\u6570\u636e\u5305\u6d41\uff0c\u5229\u7528\u5bf9\u79f0\u6027\u7834\u574f\u6545\u969c\u81ea\u7136\u8bf1\u5bfc\u7684\u53cd\u5411\u6d41\u8fdb\u884c\u6545\u969c\u89c4\u907f\u3002\u63d0\u51fa\u4e24\u79cd\u672c\u5730\u8f6c\u53d1\u7b56\u7565\uff1a\u53cd\u5411\u6d41\u5bf9\u5411\u4f18\u5148(RF-CF)\u548c\u4fa7\u5411\u4f18\u5148(RF-LF)\u3002", "result": "\u572816\u00d716\u73af\u9762\u4e0a\u7684\u6e17\u6d41\u5206\u6790\u548c\u6570\u636e\u5305\u7ea7\u6a21\u62df\u663e\u793a\uff0c\u8be5\u673a\u5236\u57281%\u94fe\u8def\u6545\u969c\u7387\u4e0b\u53ef\u51cf\u5c11\u9ad8\u8fbe17.5%\u7684\u6570\u636e\u5305\u4e22\u5931\uff0c\u5176\u4e2dRF-LF\u7b56\u7565\u8d21\u732e\u4e8628%\u7684\u6210\u529f\u4f20\u8f93\u6570\u636e\u5305\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u62d3\u6251\u5bf9\u79f0\u6027\u4e0e\u901a\u4fe1\u5f39\u6027\u4e4b\u95f4\u7684\u57fa\u7840\u8054\u7cfb\uff0c\u4e3a\u589e\u5f3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u534f\u8bae\u65e0\u5173\u7684\u5e95\u5c42\u673a\u5236\u3002"}}
{"id": "2510.26075", "categories": ["cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.26075", "abs": "https://arxiv.org/abs/2510.26075", "authors": ["Thanh Le", "Hai Duong", "Yusheng Ji", "ThanhVu Nguyen", "John C. S. Lui"], "title": "FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler", "comment": null, "summary": "In 5G mobile communication systems, MU-MIMO has been applied to enhance\nspectral efficiency and support high data rates. To maximize spectral\nefficiency while providing fairness among users, the base station (BS) needs to\nselects a subset of users for data transmission. Given that this problem is\nNP-hard, DRL-based methods have been proposed to infer the near-optimal\nsolutions in real-time, yet this approach has an intrinsic security problem.\nThis paper investigates how a group of adversarial users can exploit\nunsanitized raw CSIs to launch a throughput degradation attack. Most existing\nstudies only focused on systems in which adversarial users can obtain the exact\nvalues of victims' CSIs, but this is impractical in the case of uplink\ntransmission in LTE/5G mobile systems. We note that the DRL policy contains an\nobservation normalizer which has the mean and variance of the observation to\nimprove training convergence. Adversarial users can then estimate the upper and\nlower bounds of the local observations including the CSIs of victims based\nsolely on that observation normalizer. We develop an attacking scheme FGGM by\nleveraging polytope abstract domains, a technique used to bound the outputs of\na neural network given the input ranges. Our goal is to find one set of\nintentionally manipulated CSIs which can achieve the attacking goals for the\nwhole range of local observations of victims. Experimental results demonstrate\nthat FGGM can determine a set of adversarial CSI vector controlled by\nadversarial users, then reuse those CSIs throughout the simulation to reduce\nthe network throughput of a victim up to 70\\% without knowing the exact value\nof victims' local observations. This study serves as a case study and can be\napplied to many other DRL-based problems, such as a knapsack-oriented resource\nallocation problems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e865G MU-MIMO\u7cfb\u7edf\u4e2d\u5bf9\u6297\u6027\u7528\u6237\u5982\u4f55\u5229\u7528DRL\u7b56\u7565\u7684\u89c2\u5bdf\u5f52\u4e00\u5316\u5668\u6765\u53d1\u8d77\u541e\u5410\u91cf\u964d\u4f4e\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u9762\u4f53\u62bd\u8c61\u57df\u7684FGGM\u653b\u51fb\u65b9\u6848\uff0c\u80fd\u5728\u4e0d\u77e5\u9053\u53d7\u5bb3\u8005\u7cbe\u786eCSI\u7684\u60c5\u51b5\u4e0b\u5c06\u53d7\u5bb3\u8005\u7f51\u7edc\u541e\u5410\u91cf\u964d\u4f4e\u9ad8\u8fbe70%\u3002", "motivation": "5G MU-MIMO\u7cfb\u7edf\u4e2dDRL\u65b9\u6cd5\u5b58\u5728\u56fa\u6709\u5b89\u5168\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u5047\u8bbe\u5bf9\u6297\u6027\u7528\u6237\u80fd\u83b7\u53d6\u53d7\u5bb3\u8005\u7cbe\u786eCSI\u503c\uff0c\u8fd9\u5728LTE/5G\u4e0a\u884c\u4f20\u8f93\u4e2d\u4e0d\u5207\u5b9e\u9645\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4ec5\u901a\u8fc7\u89c2\u5bdf\u5f52\u4e00\u5316\u5668\u4fe1\u606f\u5c31\u80fd\u53d1\u8d77\u7684\u653b\u51fb\u3002", "method": "\u63d0\u51faFGGM\u653b\u51fb\u65b9\u6848\uff0c\u5229\u7528\u591a\u9762\u4f53\u62bd\u8c61\u57df\u6280\u672f\u6765\u8fb9\u754c\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\uff0c\u57fa\u4e8e\u89c2\u5bdf\u5f52\u4e00\u5316\u5668\u7684\u5747\u503c\u548c\u65b9\u5dee\u4f30\u8ba1\u53d7\u5bb3\u8005CSI\u7684\u4e0a\u4e0b\u754c\uff0c\u627e\u5230\u4e00\u7ec4\u80fd\u5728\u6574\u4e2a\u53d7\u5bb3\u8005\u89c2\u5bdf\u8303\u56f4\u5185\u5b9e\u73b0\u653b\u51fb\u76ee\u6807\u7684\u6076\u610fCSI\u5411\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFGGM\u80fd\u591f\u786e\u5b9a\u4e00\u7ec4\u7531\u5bf9\u6297\u6027\u7528\u6237\u63a7\u5236\u7684\u5bf9\u6297\u6027CSI\u5411\u91cf\uff0c\u5728\u6574\u4e2a\u6a21\u62df\u8fc7\u7a0b\u4e2d\u91cd\u590d\u4f7f\u7528\u8fd9\u4e9bCSI\uff0c\u5728\u4e0d\u77e5\u9053\u53d7\u5bb3\u8005\u7cbe\u786e\u672c\u5730\u89c2\u5bdf\u503c\u7684\u60c5\u51b5\u4e0b\u5c06\u53d7\u5bb3\u8005\u7f51\u7edc\u541e\u5410\u91cf\u964d\u4f4e\u9ad8\u8fbe70%\u3002", "conclusion": "\u672c\u7814\u7a76\u4f5c\u4e3a\u4e00\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u53ef\u5e94\u7528\u4e8e\u8bb8\u591a\u5176\u4ed6\u57fa\u4e8eDRL\u7684\u95ee\u9898\uff0c\u5982\u80cc\u5305\u5bfc\u5411\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63ed\u793a\u4e86DRL\u7cfb\u7edf\u5728\u5b89\u5168\u65b9\u9762\u7684\u6f5c\u5728\u8106\u5f31\u6027\u3002"}}
{"id": "2510.25917", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25917", "abs": "https://arxiv.org/abs/2510.25917", "authors": ["Mehdi Karbalayghareh", "David J. Love", "Christopher G. Brinton"], "title": "Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments", "comment": "10 pages, 5 figures", "summary": "The performance of federated learning (FL) over wireless networks critically\ndepends on accurate and timely channel state information (CSI) across\ndistributed devices. This requirement is tightly linked to how rapidly the\nchannel gains vary, i.e., the coherence intervals. In practice, edge devices\noften exhibit unequal coherence times due to differences in mobility and\nscattering environments, leading to unequal demands for pilot signaling and\nchannel estimation resources. Conventional FL schemes that overlook this\ncoherence disparity can suffer from severe communication inefficiencies and\ntraining overhead. This paper proposes a coherence-aware,\ncommunication-efficient framework for joint channel training and model updating\nin practical wireless FL systems operating under heterogeneous fading dynamics.\nFocusing on downlink impairments, we introduce a resource-reuse strategy based\non product superposition, enabling the parameter server to efficiently schedule\nboth static and dynamic devices by embedding global model updates for static\ndevices within pilot transmissions intended for mobile devices. We\ntheoretically analyze the convergence behavior of the proposed scheme and\nquantify its gains in expected communication efficiency and training accuracy.\nExperiments demonstrate the effectiveness of the proposed framework under\nmobility-induced dynamics and offer useful insights for the practical\ndeployment of FL over wireless channels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u7684\u611f\u77e5\u76f8\u5e72\u6027\u901a\u4fe1\u6548\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u8d44\u6e90\u590d\u7528\u7b56\u7565\u5904\u7406\u5f02\u6784\u8870\u843d\u52a8\u6001\u4e0b\u7684\u4fe1\u9053\u8bad\u7ec3\u548c\u6a21\u578b\u66f4\u65b0\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u5ffd\u89c6\u4e86\u8bbe\u5907\u95f4\u76f8\u5e72\u65f6\u95f4\u7684\u4e0d\u5e73\u7b49\u6027\uff0c\u5bfc\u81f4\u901a\u4fe1\u6548\u7387\u4f4e\u4e0b\u548c\u8bad\u7ec3\u5f00\u9500\u4e25\u91cd\u3002\u5b9e\u9645\u4e2d\u8fb9\u7f18\u8bbe\u5907\u7531\u4e8e\u79fb\u52a8\u6027\u548c\u6563\u5c04\u73af\u5883\u5dee\u5f02\uff0c\u5177\u6709\u4e0d\u540c\u7684\u76f8\u5e72\u65f6\u95f4\uff0c\u9700\u8981\u4e0d\u540c\u7684\u5bfc\u9891\u4fe1\u53f7\u548c\u4fe1\u9053\u4f30\u8ba1\u8d44\u6e90\u3002", "method": "\u57fa\u4e8e\u4e58\u79ef\u53e0\u52a0\u7684\u8d44\u6e90\u590d\u7528\u7b56\u7565\uff0c\u5141\u8bb8\u53c2\u6570\u670d\u52a1\u5668\u9ad8\u6548\u8c03\u5ea6\u9759\u6001\u548c\u52a8\u6001\u8bbe\u5907\uff0c\u5c06\u9759\u6001\u8bbe\u5907\u7684\u5168\u5c40\u6a21\u578b\u66f4\u65b0\u5d4c\u5165\u5230\u79fb\u52a8\u8bbe\u5907\u7684\u5bfc\u9891\u4f20\u8f93\u4e2d\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e86\u6240\u63d0\u65b9\u6848\u7684\u6536\u655b\u884c\u4e3a\uff0c\u91cf\u5316\u4e86\u9884\u671f\u901a\u4fe1\u6548\u7387\u548c\u8bad\u7ec3\u7cbe\u5ea6\u7684\u589e\u76ca\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u79fb\u52a8\u6027\u8bf1\u5bfc\u52a8\u6001\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65e0\u7ebf\u4fe1\u9053\u4e0a\u8054\u90a6\u5b66\u4e60\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5f02\u6784\u8870\u843d\u52a8\u6001\u4e0b\u7684\u901a\u4fe1\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2510.26603", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26603", "abs": "https://arxiv.org/abs/2510.26603", "authors": ["Reda El Makroum", "Sebastian Zwickl-Bernhard", "Lukas Kranzl"], "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "comment": "34 pages, 9 figures. Code available at\n  https://github.com/RedaElMakroum/agentic-ai-hems", "summary": "The electricity sector transition requires substantial increases in\nresidential demand response capacity, yet Home Energy Management Systems (HEMS)\nadoption remains limited by user interaction barriers requiring translation of\neveryday preferences into technical parameters. While large language models\nhave been applied to energy systems as code generators and parameter\nextractors, no existing implementation deploys LLMs as autonomous coordinators\nmanaging the complete workflow from natural language input to multi-appliance\nscheduling. This paper presents an agentic AI HEMS where LLMs autonomously\ncoordinate multi-appliance scheduling from natural language requests to device\ncontrol, achieving optimal scheduling without example demonstrations. A\nhierarchical architecture combining one orchestrator with three specialist\nagents uses the ReAct pattern for iterative reasoning, enabling dynamic\ncoordination without hardcoded workflows while integrating Google Calendar for\ncontext-aware deadline extraction. Evaluation across three open-source models\nusing real Austrian day-ahead electricity prices reveals substantial capability\ndifferences. Llama-3.3-70B successfully coordinates all appliances across all\nscenarios to match cost-optimal benchmarks computed via mixed-integer linear\nprogramming, while other models achieve perfect single-appliance performance\nbut struggle to coordinate all appliances simultaneously. Progressive prompt\nengineering experiments demonstrate that analytical query handling without\nexplicit guidance remains unreliable despite models' general reasoning\ncapabilities. We open-source the complete system including orchestration logic,\nagent prompts, tools, and web interfaces to enable reproducibility, extension,\nand future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u5bb6\u5ead\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\uff0c\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\u76f4\u63a5\u534f\u8c03\u591a\u8bbe\u5907\u8c03\u5ea6\uff0c\u65e0\u9700\u793a\u4f8b\u6f14\u793a\u5373\u53ef\u5b9e\u73b0\u6700\u4f18\u8c03\u5ea6\u3002", "motivation": "\u4f4f\u5b85\u9700\u6c42\u54cd\u5e94\u80fd\u529b\u9700\u8981\u5927\u5e45\u63d0\u5347\uff0c\u4f46\u73b0\u6709\u5bb6\u5ead\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\u56e0\u7528\u6237\u4ea4\u4e92\u969c\u788d\u800c\u91c7\u7528\u6709\u9650\uff0c\u9700\u8981\u5c06\u65e5\u5e38\u504f\u597d\u8f6c\u6362\u4e3a\u6280\u672f\u53c2\u6570\u3002", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u7ed3\u5408\u4e00\u4e2a\u534f\u8c03\u5668\u548c\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\uff0c\u4f7f\u7528ReAct\u6a21\u5f0f\u8fdb\u884c\u8fed\u4ee3\u63a8\u7406\uff0c\u96c6\u6210Google\u65e5\u5386\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u622a\u6b62\u65f6\u95f4\u63d0\u53d6\u3002", "result": "Llama-3.3-70B\u5728\u6240\u6709\u573a\u666f\u4e2d\u6210\u529f\u534f\u8c03\u6240\u6709\u8bbe\u5907\uff0c\u4e0e\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u8ba1\u7b97\u7684\u6700\u4f18\u57fa\u51c6\u76f8\u5339\u914d\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u5728\u5355\u8bbe\u5907\u6027\u80fd\u4e0a\u8868\u73b0\u5b8c\u7f8e\u4f46\u96be\u4ee5\u540c\u65f6\u534f\u8c03\u6240\u6709\u8bbe\u5907\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u81ea\u4e3b\u534f\u8c03\u5668\u7ba1\u7406\u4ece\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u5230\u591a\u8bbe\u5907\u8c03\u5ea6\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f46\u5206\u6790\u6027\u67e5\u8be2\u5904\u7406\u5728\u6ca1\u6709\u660e\u786e\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u4ecd\u7136\u4e0d\u53ef\u9760\u3002"}}
{"id": "2510.25775", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25775", "abs": "https://arxiv.org/abs/2510.25775", "authors": ["Francesco Spinnato"], "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "comment": null, "summary": "Contemporary chess engines offer precise yet opaque evaluations, typically\nexpressed as centipawn scores. While effective for decision-making, these\noutputs obscure the underlying contributions of individual pieces or patterns.\nIn this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the\ndomain of chess analysis, aiming to attribute a chess engines evaluation to\nspecific pieces on the board. By treating pieces as features and systematically\nablating them, we compute additive, per-piece contributions that explain the\nengines output in a locally faithful and human-interpretable manner. This\nmethod draws inspiration from classical chess pedagogy, where players assess\npositions by mentally removing pieces, and grounds it in modern explainable AI\ntechniques. Our approach opens new possibilities for visualization, human\ntraining, and engine comparison. We release accompanying code and data to\nfoster future research in interpretable chess AI.", "AI": {"tldr": "\u5c06SHAP\u53ef\u89e3\u91caAI\u6280\u672f\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u5206\u6790\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u68cb\u5b50\u6765\u8ba1\u7b97\u6bcf\u4e2a\u68cb\u5b50\u5bf9\u5f15\u64ce\u8bc4\u4f30\u7684\u8d21\u732e\u5ea6\uff0c\u63d0\u4f9b\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002", "motivation": "\u4f20\u7edf\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u63d0\u4f9b\u7cbe\u786e\u4f46\u4e0d\u900f\u660e\u7684\u8bc4\u4f30\u5206\u6570\uff0c\u65e0\u6cd5\u63ed\u793a\u5355\u4e2a\u68cb\u5b50\u6216\u6a21\u5f0f\u7684\u8d21\u732e\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u89e3\u91ca\u5f15\u64ce\u8bc4\u4f30\u80cc\u540e\u7684\u5177\u4f53\u539f\u56e0\u3002", "method": "\u5c06\u68cb\u5b50\u89c6\u4e3a\u7279\u5f81\uff0c\u91c7\u7528SHAP\u65b9\u6cd5\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u68cb\u5b50\u6765\u8ba1\u7b97\u6bcf\u4e2a\u68cb\u5b50\u7684\u52a0\u6027\u8d21\u732e\u5ea6\uff0c\u8be5\u65b9\u6cd5\u53d7\u5230\u4f20\u7edf\u8c61\u68cb\u6559\u5b66\u4e2d\u79fb\u9664\u68cb\u5b50\u5206\u6790\u4f4d\u7f6e\u7684\u542f\u53d1\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u4e3a\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u8bc4\u4f30\u63d0\u4f9b\u5c40\u90e8\u5fe0\u5b9e\u4e14\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u68cb\u5b50\u8d21\u732e\u5ea6\u5206\u6790\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u89c6\u5316\u3001\u4eba\u7c7b\u8bad\u7ec3\u548c\u5f15\u64ce\u6bd4\u8f83\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\uff0c\u5e76\u53d1\u5e03\u4e86\u4ee3\u7801\u548c\u6570\u636e\u4ee5\u4fc3\u8fdb\u53ef\u89e3\u91ca\u8c61\u68cbAI\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.26234", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.26234", "abs": "https://arxiv.org/abs/2510.26234", "authors": ["Mathis Engelbart", "Mike Kosek", "Lars Eggert", "J\u00f6rg Ott"], "title": "From req/res to pub/sub: Exploring Media over QUIC Transport for DNS", "comment": null, "summary": "The DNS is a key component of the Internet. Originally designed to facilitate\nthe resolution of host names to IP addresses, its scope has continuously\nexpanded over the years, today covering use cases such as load balancing or\nservice discovery. While DNS was initially conceived as a rather static\ndirectory service in which resource records (RR) only change rarely, we have\nseen a number of use cases over the years where a DNS flavor that isn't purely\nbased upon requesting and caching RRs, but rather on an active distribution of\nupdates for all resolvers that showed interest in the respective records in the\npast, would be preferable. In this paper, we thus explore a publish-subscribe\nvariant of DNS based on the Media-over-QUIC architecture, where we devise a\nstrawman system and protocol proposal to enable pushing RR updates. We provide\na prototype implementation, finding that DNS can benefit from a\npublish-subscribe variant: next to limiting update traffic, it can considerably\nreduce the time it takes for a resolver to receive the latest version of a\nrecord, thereby supporting use cases such as load balancing in content\ndistribution networks. The publish-subscribe architecture also brings new\nchallenges to the DNS, including a higher overhead for endpoints due to\nadditional state management, and increased query latencies on first lookup, due\nto session establishment latencies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d1\u5e03-\u8ba2\u9605\u6a21\u5f0f\u7684DNS\u53d8\u4f53\uff0c\u4f7f\u7528Media-over-QUIC\u67b6\u6784\u6765\u63a8\u9001\u8d44\u6e90\u8bb0\u5f55\u66f4\u65b0\uff0c\u76f8\u6bd4\u4f20\u7edfDNS\u80fd\u663e\u8457\u51cf\u5c11\u66f4\u65b0\u5ef6\u8fdf\u548c\u6d41\u91cf\u3002", "motivation": "\u4f20\u7edfDNS\u8bbe\u8ba1\u4e3a\u9759\u6001\u76ee\u5f55\u670d\u52a1\uff0c\u8d44\u6e90\u8bb0\u5f55\u5f88\u5c11\u53d8\u5316\uff0c\u4f46\u73b0\u4ee3\u7528\u4f8b\u5982\u8d1f\u8f7d\u5747\u8861\u548c\u670d\u52a1\u53d1\u73b0\u9700\u8981\u66f4\u52a8\u6001\u7684\u66f4\u65b0\u673a\u5236\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u4e3b\u52a8\u63a8\u9001\u66f4\u65b0\u7684DNS\u53d8\u4f53\u3002", "method": "\u57fa\u4e8eMedia-over-QUIC\u67b6\u6784\u8bbe\u8ba1\u4e86\u53d1\u5e03-\u8ba2\u9605DNS\u7cfb\u7edf\u539f\u578b\uff0c\u5305\u62ec\u7cfb\u7edf\u67b6\u6784\u548c\u534f\u8bae\u63d0\u6848\uff0c\u652f\u6301\u5411\u6240\u6709\u5bf9\u7279\u5b9a\u8bb0\u5f55\u611f\u5174\u8da3\u7684\u89e3\u8026\u5668\u63a8\u9001\u66f4\u65b0\u3002", "result": "\u539f\u578b\u5b9e\u73b0\u8868\u660e\u53d1\u5e03-\u8ba2\u9605DNS\u80fd\u663e\u8457\u51cf\u5c11\u8bb0\u5f55\u66f4\u65b0\u65f6\u95f4\uff0c\u652f\u6301\u5185\u5bb9\u5206\u53d1\u7f51\u7edc\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\u7b49\u7528\u4f8b\uff0c\u540c\u65f6\u51cf\u5c11\u66f4\u65b0\u6d41\u91cf\u3002", "conclusion": "DNS\u80fd\u4ece\u53d1\u5e03-\u8ba2\u9605\u53d8\u4f53\u4e2d\u53d7\u76ca\uff0c\u4f46\u8be5\u67b6\u6784\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u5305\u62ec\u7aef\u70b9\u72b6\u6001\u7ba1\u7406\u5f00\u9500\u589e\u52a0\u548c\u9996\u6b21\u67e5\u8be2\u5ef6\u8fdf\u589e\u52a0\u3002"}}
{"id": "2510.26147", "categories": ["cs.IT", "eess.SP", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.26147", "abs": "https://arxiv.org/abs/2510.26147", "authors": ["Xilai Fan", "Ya-Feng Liu"], "title": "Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems", "comment": "6 pages, 1 figure, submitted to IEEE WCNC 2026", "summary": "In this paper, we investigate the beamforming design problem in an integrated\nsensing and communication (ISAC) system, where a multi-antenna base station\nsimultaneously serves multiple communication users while performing radar\nsensing. We formulate the problem as the minimization of the total transmit\npower, subject to signal-to-interference-plus-noise ratio (SINR) constraints\nfor communication users and mean-squared-error (MSE) constraints for radar\nsensing. The core challenge arises from the complex coupling between\ncommunication SINR requirements and sensing performance metrics. To efficiently\naddress this challenge, we first establish the equivalence between the original\nISAC beamforming problem and its semidefinite relaxation (SDR), derive its\nLagrangian dual formulation, and further reformulate it as a generalized\ndownlink beamforming (GDB) problem with potentially indefinite weighting\nmatrices. Compared to the classical DB problem, the presence of indefinite\nweighting matrices in the GDB problem introduces substantial analytical and\ncomputational challenges. Our key technical contributions include (i) a\nnecessary and sufficient condition for the boundedness of the GDB problem, and\n(ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable\nconvergence guarantee for solving the GDB problem. Building upon these results,\nwe develop a duality-based fixed point iteration (Dual-FPI) algorithm, which\nintegrates an outer subgradient ascent loop with an inner FPI loop. Simulation\nresults demonstrate that the proposed Dual-FPI algorithm achieves globally\noptimal solutions while significantly reducing computational complexity\ncompared with existing baseline approaches.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5bf9\u5076\u7406\u8bba\u548c\u5b9a\u70b9\u8fed\u4ee3\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u5728\u4fdd\u8bc1\u901a\u4fe1\u7528\u6237SINR\u548c\u96f7\u8fbe\u611f\u77e5MSE\u7ea6\u675f\u7684\u540c\u65f6\u6700\u5c0f\u5316\u603b\u53d1\u5c04\u529f\u7387\u3002", "motivation": "\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u9700\u8981\u540c\u65f6\u4f18\u5316\u901a\u4fe1\u548c\u611f\u77e5\u6027\u80fd\uff0c\u4f46\u901a\u4fe1SINR\u8981\u6c42\u4e0e\u611f\u77e5\u6027\u80fd\u6307\u6807\u4e4b\u95f4\u5b58\u5728\u590d\u6742\u8026\u5408\u5173\u7cfb\uff0c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u7b97\u6cd5\u3002", "method": "\u9996\u5148\u5efa\u7acb\u539f\u59cb\u95ee\u9898\u4e0e\u534a\u5b9a\u677e\u5f1b\u7684\u7b49\u4ef7\u6027\uff0c\u63a8\u5bfc\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u5f62\u5f0f\uff0c\u5c06\u5176\u91cd\u6784\u4e3a\u5e7f\u4e49\u4e0b\u884c\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u3002\u63d0\u51fa\u5b9a\u5236\u7684\u5b9a\u70b9\u8fed\u4ee3\u7b97\u6cd5\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u5bf9\u5076\u7684\u56fa\u5b9a\u70b9\u8fed\u4ee3\u7b97\u6cd5\uff0c\u7ed3\u5408\u5916\u90e8\u6b21\u68af\u5ea6\u4e0a\u5347\u548c\u5185\u90e8FPI\u5faa\u73af\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684Dual-FPI\u7b97\u6cd5\u80fd\u591f\u83b7\u5f97\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u540c\u65f6\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u89e3\u51b3\u4e86ISAC\u7cfb\u7edf\u4e2d\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u63d0\u51fa\u7684Dual-FPI\u7b97\u6cd5\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25813", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25813", "abs": "https://arxiv.org/abs/2510.25813", "authors": ["Jorge Martinez-Gil", "Mario Pichler", "Nefeli Bountouni", "Sotiris Koussouris", "Marielena M\u00e1rquez Barreiro", "Sergio Gusmeroli"], "title": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "comment": null, "summary": "We present a novel framework for Industry 5.0 that simplifies the deployment\nof AI models on edge devices in various industrial settings. The design reduces\nlatency and avoids external data transfer by enabling local inference and\nreal-time processing. Our implementation is agent-based, which means that\nindividual agents, whether human, algorithmic, or collaborative, are\nresponsible for well-defined tasks, enabling flexibility and simplifying\nintegration. Moreover, our framework supports modular integration and maintains\nlow resource requirements. Preliminary evaluations concerning the food industry\nin real scenarios indicate improved deployment time and system adaptability\nperformance. The source code is publicly available at\nhttps://github.com/AI-REDGIO-5-0/ci-component.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u5de5\u4e1a5.0\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7b80\u5316AI\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\uff0c\u901a\u8fc7\u672c\u5730\u63a8\u7406\u548c\u5b9e\u65f6\u5904\u7406\u964d\u4f4e\u5ef6\u8fdf\uff0c\u91c7\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u67b6\u6784\u5b9e\u73b0\u7075\u6d3b\u96c6\u6210\u3002", "motivation": "\u89e3\u51b3\u5de5\u4e1a\u73af\u5883\u4e2dAI\u6a21\u578b\u90e8\u7f72\u590d\u6742\u3001\u5ef6\u8fdf\u9ad8\u7684\u95ee\u9898\uff0c\u652f\u6301\u8fb9\u7f18\u8ba1\u7b97\u548c\u5b9e\u65f6\u5904\u7406\uff0c\u6ee1\u8db3\u5de5\u4e1a5.0\u5bf9\u667a\u80fd\u5316\u548c\u7075\u6d3b\u6027\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u652f\u6301\u4eba\u7c7b\u3001\u7b97\u6cd5\u548c\u534f\u4f5c\u4ee3\u7406\u6267\u884c\u660e\u786e\u5b9a\u4e49\u7684\u4efb\u52a1\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u96c6\u6210\u5e76\u4fdd\u6301\u4f4e\u8d44\u6e90\u9700\u6c42\u3002", "result": "\u5728\u98df\u54c1\u5de5\u4e1a\u771f\u5b9e\u573a\u666f\u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c\u90e8\u7f72\u65f6\u95f4\u548c\u7cfb\u7edf\u9002\u5e94\u6027\u6027\u80fd\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5de5\u4e1a5.0\u63d0\u4f9b\u4e86\u6709\u6548\u7684AI\u6a21\u578b\u8fb9\u7f18\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u6e90\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2510.26256", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.26256", "abs": "https://arxiv.org/abs/2510.26256", "authors": ["Geng Sun", "Siyi Chen", "Zemin Sun", "Long He", "Jiacheng Wang", "Dusit Niyato", "Zhu Han", "Dong In Kim"], "title": "Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information", "comment": "19 pages, 17 figures", "summary": "Vehicular fog computing (VFC) has emerged as a promising paradigm, which\nleverages the idle computational resources of nearby fog vehicles (FVs) to\ncomplement the computing capabilities of conventional vehicular edge computing.\nHowever, utilizing VFC to meet the delay-sensitive and computation-intensive\nrequirements of the FVs poses several challenges. First, the limited resources\nof road side units (RSUs) struggle to accommodate the growing and diverse\ndemands of vehicles. This limitation is further exacerbated by the information\nasymmetry between the controller and FVs due to the reluctance of FVs to\ndisclose private information and to share resources voluntarily. This\ninformation asymmetry hinders the efficient resource allocation and\ncoordination. Second, the heterogeneity in task requirements and the varying\ncapabilities of RSUs and FVs complicate efficient task offloading, thereby\nresulting in inefficient resource utilization and potential performance\ndegradation. To address these challenges, we first present a hierarchical VFC\narchitecture that incorporates the computing capabilities of both RSUs and FVs.\nThen, we formulate a delay minimization optimization problem (DMOP), which is\nan NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we\npropose a joint computing resource allocation and task offloading approach\n(JCRATOA). Specifically, we propose a convex optimization-based method for RSU\nresource allocation and a contract theory-based incentive mechanism for FV\nresource allocation. Moreover, we present a two-sided matching method for task\noffloading by employing the matching game. Simulation results demonstrate that\nthe proposed JCRATOA is able to achieve superior performances in task\ncompletion delay, task completion ratio, system throughput, and resource\nutilization fairness, while effectively meeting the satisfying constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u548c\u4efb\u52a1\u5378\u8f7d\u65b9\u6cd5\uff08JCRATOA\uff09\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u548c\u5951\u7ea6\u7406\u8bba\u89e3\u51b3\u8f66\u8f7d\u96fe\u8ba1\u7b97\u4e2d\u7684\u5ef6\u8fdf\u6700\u5c0f\u5316\u95ee\u9898\u3002", "motivation": "\u8f66\u8f7d\u96fe\u8ba1\u7b97\uff08VFC\uff09\u9762\u4e34\u8d44\u6e90\u53d7\u9650\u548c\u4fe1\u606f\u4e0d\u5bf9\u79f0\u7684\u6311\u6218\uff0cRSU\u8d44\u6e90\u6709\u9650\u4e14\u8f66\u8f86\u4e0d\u613f\u5171\u4eab\u79c1\u6709\u4fe1\u606f\uff0c\u5bfc\u81f4\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\u4e0b\u548c\u4efb\u52a1\u5378\u8f7d\u590d\u6742\u5316\u3002", "method": "\u6784\u5efa\u5206\u5c42VFC\u67b6\u6784\uff0c\u63d0\u51faJCRATOA\u65b9\u6cd5\uff1a\u4f7f\u7528\u51f8\u4f18\u5316\u8fdb\u884cRSU\u8d44\u6e90\u5206\u914d\uff0c\u5951\u7ea6\u7406\u8bba\u6fc0\u52b1FV\u8d44\u6e90\u5206\u914d\uff0c\u4ee5\u53ca\u53cc\u8fb9\u5339\u914d\u65b9\u6cd5\u8fdb\u884c\u4efb\u52a1\u5378\u8f7d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cJCRATOA\u5728\u4efb\u52a1\u5b8c\u6210\u5ef6\u8fdf\u3001\u5b8c\u6210\u7387\u3001\u7cfb\u7edf\u541e\u5410\u91cf\u548c\u8d44\u6e90\u5229\u7528\u516c\u5e73\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u6709\u6548\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684JCRATOA\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8f66\u8f7d\u96fe\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u548c\u4efb\u52a1\u5378\u8f7d\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.26279", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26279", "abs": "https://arxiv.org/abs/2510.26279", "authors": ["Fuying Li", "Yajun Wang", "Zhuxian Lian", "Wen Chen"], "title": "Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems", "comment": null, "summary": "Driven by the growing demand for higher spectral efficiency in wireless\ncommunications, intelligent reflecting surfaces (IRS) have attracted\nconsiderable attention for their ability to dynamically reconfigure the\npropagation environment. This work addresses the spectral efficiency\nmaximization problem in IRS-assisted multiple-input multiple-output (MIMO)\nsystems, which involves the joint optimization of the transmit precoding matrix\nand the IRS phase shift configuration. This problem is inherently challenging\ndue to its non-convex nature. To tackle it effectively, we introduce a\ncomputationally efficient algorithm, termed ADMM-APG, which integrates the\nalternating direction method of multipliers (ADMM) with the accelerated\nprojected gradient (APG) method. The proposed framework decomposes the original\nproblem into tractable subproblems, each admitting a closed-form solution while\nmaintaining low computational complexity. Simulation results demonstrate that\nthe ADMM-APG algorithm consistently surpasses existing benchmark methods in\nterms of spectral efficiency and computational complexity, achieving\nsignificant performance gains across a range of system configurations.", "AI": {"tldr": "\u63d0\u51faADMM-APG\u7b97\u6cd5\u89e3\u51b3IRS\u8f85\u52a9MIMO\u7cfb\u7edf\u4e2d\u7684\u9891\u8c31\u6548\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u7ed3\u5408ADMM\u548cAPG\u65b9\u6cd5\uff0c\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u65e0\u7ebf\u901a\u4fe1\u5bf9\u9891\u8c31\u6548\u7387\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u667a\u80fd\u53cd\u5c04\u8868\u9762(IRS)\u80fd\u591f\u52a8\u6001\u91cd\u6784\u4f20\u64ad\u73af\u5883\uff0c\u4f46IRS\u8f85\u52a9MIMO\u7cfb\u7edf\u4e2d\u7684\u9891\u8c31\u6548\u7387\u6700\u5927\u5316\u95ee\u9898\u5177\u6709\u975e\u51f8\u6027\uff0c\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u6765\u89e3\u51b3\u3002", "method": "\u63d0\u51faADMM-APG\u7b97\u6cd5\uff0c\u7ed3\u5408\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5(ADMM)\u548c\u52a0\u901f\u6295\u5f71\u68af\u5ea6(APG)\u65b9\u6cd5\uff0c\u5c06\u539f\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u95ed\u5f0f\u6c42\u89e3\u7684\u5b50\u95ee\u9898\uff0c\u4fdd\u6301\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cADMM-APG\u7b97\u6cd5\u5728\u9891\u8c31\u6548\u7387\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u7cfb\u7edf\u914d\u7f6e\u4e0b\u5747\u80fd\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "ADMM-APG\u7b97\u6cd5\u4e3aIRS\u8f85\u52a9MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u5408\u4f18\u5316\u53d1\u5c04\u9884\u7f16\u7801\u77e9\u9635\u548cIRS\u76f8\u4f4d\u914d\u7f6e\u7684\u975e\u51f8\u95ee\u9898\u3002"}}
{"id": "2510.25820", "categories": ["cs.AI", "cs.HC", "I.2.7; H.5.2"], "pdf": "https://arxiv.org/pdf/2510.25820", "abs": "https://arxiv.org/abs/2510.25820", "authors": ["Vanessa Figueiredo", "David Elumeze"], "title": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue", "comment": null, "summary": "Large Language Models (LLMs) promise to transform interactive games by\nenabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it\nremains unclear whether constrained prompts actually improve player experience.\nWe investigate this question through The Interview, a voice-based detective\ngame powered by GPT-4o. A within-subjects usability study ($N=10$) compared\nhigh-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable\nexperiential differences beyond sensitivity to technical breakdowns. Guided by\nthese findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and\nconducted a synthetic evaluation with an LLM judge, positioned as an\nearly-stage complement to usability testing. Results uncovered a novel pattern:\nscaffolding effects were role-dependent: the Interviewer (quest-giver NPC)\ngained stability, while suspect NPCs lost improvisational believability. These\nfindings overturn the assumption that tighter constraints inherently enhance\nplay. Extending fuzzy-symbolic scaffolding, we introduce \\textit{Symbolically\nScaffolded Play}, a framework in which symbolic structures are expressed as\nfuzzy, numerical boundaries that stabilize coherence where needed while\npreserving improvisation where surprise sustains engagement.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u9ad8\u7ea6\u675f\u548c\u4f4e\u7ea6\u675f\u63d0\u793a\u5728\u57fa\u4e8eGPT-4o\u7684\u4fa6\u63a2\u6e38\u620f\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u7ea6\u675f\u7a0b\u5ea6\u5bf9\u73a9\u5bb6\u4f53\u9a8c\u5f71\u54cd\u4e0d\u5927\uff0c\u4f46\u89d2\u8272\u4f9d\u8d56\u7684\u652f\u67b6\u6548\u5e94\u660e\u663e\u3002", "motivation": "\u63a2\u7d22\u7ea6\u675f\u63d0\u793a\u662f\u5426\u80fd\u771f\u6b63\u6539\u5584\u73a9\u5bb6\u4f53\u9a8c\uff0c\u7279\u522b\u662f\u5728LLM\u9a71\u52a8\u7684\u4e92\u52a8\u6e38\u620f\u4e2d\uff0c\u6311\u6218\"\u66f4\u7d27\u7ea6\u675f\u5fc5\u7136\u589e\u5f3a\u6e38\u620f\u6027\"\u7684\u5047\u8bbe\u3002", "method": "\u91c7\u7528\u88ab\u8bd5\u5185\u53ef\u7528\u6027\u7814\u7a76(N=10)\u6bd4\u8f83\u9ad8\u4f4e\u7ea6\u675f\u63d0\u793a\uff0c\u7136\u540e\u91cd\u65b0\u8bbe\u8ba1\u4e3a\u6df7\u5408JSON+RAG\u652f\u67b6\uff0c\u5e76\u8fdb\u884cLLM\u6cd5\u5b98\u7684\u5408\u6210\u8bc4\u4f30\u3002", "result": "\u9ad8\u7ea6\u675f\u548c\u4f4e\u7ea6\u675f\u63d0\u793a\u5728\u4f53\u9a8c\u4e0a\u6ca1\u6709\u53ef\u9760\u5dee\u5f02\uff0c\u4f46\u652f\u67b6\u6548\u5e94\u5177\u6709\u89d2\u8272\u4f9d\u8d56\u6027\uff1a\u91c7\u8bbf\u8005NPC\u83b7\u5f97\u7a33\u5b9a\u6027\uff0c\u800c\u5acc\u7591\u72afNPC\u5931\u53bb\u5373\u5174\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7b26\u53f7\u652f\u67b6\u6e38\u620f\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u7cca\u6570\u503c\u8fb9\u754c\u6765\u5728\u9700\u8981\u65f6\u7a33\u5b9a\u8fde\u8d2f\u6027\uff0c\u540c\u65f6\u5728\u4fdd\u6301\u60ca\u559c\u7684\u5730\u65b9\u4fdd\u7559\u5373\u5174\u6027\u3002"}}
{"id": "2510.26473", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.26473", "abs": "https://arxiv.org/abs/2510.26473", "authors": ["Junya Shiraishi", "Shashi Raj Pandey", "Israel Leyva-Mayorga", "Petar Popovski"], "title": "Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval", "comment": null, "summary": "The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning\n(ML) models plays a critical role in accelerating ML inference tasks in the\nnext generation of communication systems. However, periodic refreshment of DRAM\nresults in wasteful energy consumption during standby periods, which is\nsignificant for resource-constrained Internet of Things (IoT) devices. To solve\nthis problem, this work advocates two novel approaches: 1) wireless memory\nactivation and 2) wireless memory approximation. These enable the wireless\ndevices to efficiently manage the available memory by considering the timing\naspects and relevance of ML model usage; hence, reducing the overall energy\nconsumption. Numerical results show that our proposed scheme can realize\nsmaller energy consumption than the always-on approach while satisfying the\nretrieval accuracy constraint.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u65e0\u7ebf\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\uff08\u65e0\u7ebf\u5185\u5b58\u6fc0\u6d3b\u548c\u65e0\u7ebf\u5185\u5b58\u8fd1\u4f3c\uff09\u6765\u51cf\u5c11DRAM\u5728ML\u6a21\u578b\u5b58\u50a8\u4e2d\u7684\u5237\u65b0\u80fd\u8017\uff0c\u7279\u522b\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\u3002", "motivation": "DRAM\u7528\u4e8e\u5b58\u50a8ML\u6a21\u578b\u65f6\uff0c\u5468\u671f\u6027\u5237\u65b0\u5728\u5f85\u673a\u671f\u95f4\u4f1a\u9020\u6210\u5927\u91cf\u80fd\u6e90\u6d6a\u8d39\uff0c\u8fd9\u5bf9\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\u5c24\u4e3a\u663e\u8457\u3002", "method": "\u91c7\u7528\u65e0\u7ebf\u5185\u5b58\u6fc0\u6d3b\u548c\u65e0\u7ebf\u5185\u5b58\u8fd1\u4f3c\u4e24\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651ML\u6a21\u578b\u4f7f\u7528\u65f6\u5e8f\u548c\u76f8\u5173\u6027\u6765\u9ad8\u6548\u7ba1\u7406\u53ef\u7528\u5185\u5b58\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6848\u5728\u6ee1\u8db3\u68c0\u7d22\u7cbe\u5ea6\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u80fd\u5b9e\u73b0\u6bd4\u59cb\u7ec8\u5f00\u542f\u65b9\u6cd5\u66f4\u4f4e\u7684\u80fd\u8017\u3002", "conclusion": "\u65e0\u7ebf\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4eDRAM\u5728ML\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u8017\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\u3002"}}
{"id": "2510.26442", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26442", "abs": "https://arxiv.org/abs/2510.26442", "authors": ["Xuesong Wang", "Xinyan Xie", "Mo Li", "Zhaoqian Liu"], "title": "Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests", "comment": "Submitted to IEEE ICC 2026", "summary": "Semantic communication focuses on conveying the intrinsic meaning of data\nrather than its raw symbolic representation. For visual content, this paradigm\nshifts from traditional pixel-level transmission toward leveraging the semantic\nstructure of images to communicate visual meaning. Existing approaches\ngenerally follow one of two paths: transmitting only text descriptions, which\noften fail to capture precise spatial layouts and fine-grained appearance\ndetails; or transmitting text alongside dense latent visual features, which\ntends to introduce substantial semantic redundancy. A key challenge, therefore,\nis to reduce semantic redundancy while preserving semantic understanding and\nvisual fidelity, thereby improving overall transmission efficiency. This paper\nintroduces a diffusion-based semantic communication framework with adaptive\nretransmission. The system transmits concise text descriptions together with a\nlimited set of key latent visual features, and employs a diffusion-based\ninpainting model to reconstruct the image. A receiver-side semantic consistency\nmechanism is designed to evaluate the alignment between the reconstructed image\nand the original text description. When a semantic discrepancy is detected, the\nreceiver triggers a retransmission to request a small set of additional latent\nblocks and refine the image reconstruction. This approach significantly reduces\nbandwidth usage while preserving high semantic accuracy, achieving an efficient\nbalance between reconstruction quality and transmission overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u4f20\u8f93\u7b80\u6d01\u6587\u672c\u63cf\u8ff0\u548c\u5c11\u91cf\u5173\u952e\u89c6\u89c9\u7279\u5f81\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u91cd\u4f20\u673a\u5236\u6765\u5e73\u8861\u91cd\u5efa\u8d28\u91cf\u548c\u4f20\u8f93\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8bed\u4e49\u901a\u4fe1\u65b9\u6cd5\u5728\u4f20\u8f93\u6548\u7387\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff1a\u7eaf\u6587\u672c\u63cf\u8ff0\u65e0\u6cd5\u6355\u6349\u7a7a\u95f4\u5e03\u5c40\u548c\u7ec6\u8282\uff0c\u800c\u6587\u672c\u52a0\u5bc6\u96c6\u89c6\u89c9\u7279\u5f81\u53c8\u5b58\u5728\u8bed\u4e49\u5197\u4f59\u3002", "method": "\u4f20\u8f93\u7b80\u6d01\u6587\u672c\u63cf\u8ff0\u548c\u5c11\u91cf\u5173\u952e\u6f5c\u5728\u89c6\u89c9\u7279\u5f81\uff0c\u4f7f\u7528\u6269\u6563\u4fee\u590d\u6a21\u578b\u91cd\u5efa\u56fe\u50cf\uff0c\u63a5\u6536\u7aef\u901a\u8fc7\u8bed\u4e49\u4e00\u81f4\u6027\u8bc4\u4f30\u673a\u5236\u68c0\u6d4b\u5dee\u5f02\u5e76\u89e6\u53d1\u91cd\u4f20\u8bf7\u6c42\u989d\u5916\u7279\u5f81\u5757\u3002", "result": "\u663e\u8457\u51cf\u5c11\u4e86\u5e26\u5bbd\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8bed\u4e49\u51c6\u786e\u6027\uff0c\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u4f20\u8f93\u5f00\u9500\u4e4b\u95f4\u5b9e\u73b0\u4e86\u9ad8\u6548\u5e73\u8861\u3002", "conclusion": "\u8be5\u6269\u6563\u57fa\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u4f20\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u4e49\u5197\u4f59\u95ee\u9898\uff0c\u4e3a\u89c6\u89c9\u5185\u5bb9\u7684\u9ad8\u6548\u8bed\u4e49\u4f20\u8f93\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.25860", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.25860", "abs": "https://arxiv.org/abs/2510.25860", "authors": ["Xingjian Zhang", "Tianhong Gao", "Suliang Jin", "Tianhao Wang", "Teng Ye", "Eytan Adar", "Qiaozhu Mei"], "title": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "comment": null, "summary": "Large language models (LLMs) are increasingly used as raters for evaluation\ntasks. However, their reliability is often limited for subjective tasks, when\nhuman judgments involve subtle reasoning beyond annotation labels. Thinking\ntraces, the reasoning behind a judgment, are highly informative but challenging\nto collect and curate. We present a human-LLM collaborative framework to infer\nthinking traces from label-only annotations. The proposed framework uses a\nsimple and effective rejection sampling method to reconstruct these traces at\nscale. These inferred thinking traces are applied to two complementary tasks:\n(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation\nguidelines for proprietary LLM raters. Across multiple datasets, our methods\nlead to significantly improved LLM-human agreement. Additionally, the refined\nannotation guidelines increase agreement among different LLM models. These\nresults suggest that LLMs can serve as practical proxies for otherwise\nunrevealed human thinking traces, enabling label-only corpora to be extended\ninto thinking-trace-augmented resources that enhance the reliability of LLM\nraters.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u4ece\u4ec5\u6807\u7b7e\u6807\u6ce8\u4e2d\u63a8\u65ad\u601d\u7ef4\u8f68\u8ff9\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\u91cd\u6784\u63a8\u7406\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5fae\u8c03\u5f00\u6e90LLM\u8bc4\u4f30\u5668\u548c\u6539\u8fdb\u4e13\u6709LLM\u8bc4\u4f30\u5668\u7684\u6807\u6ce8\u6307\u5357\uff0c\u663e\u8457\u63d0\u5347LLM\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u3002", "motivation": "LLM\u4f5c\u4e3a\u8bc4\u4f30\u5668\u5728\u4e3b\u89c2\u4efb\u52a1\u4e2d\u53ef\u9760\u6027\u6709\u9650\uff0c\u4eba\u7c7b\u5224\u65ad\u6d89\u53ca\u8d85\u8d8a\u6807\u6ce8\u6807\u7b7e\u7684\u7ec6\u5fae\u63a8\u7406\uff0c\u601d\u7ef4\u8f68\u8ff9\u4fe1\u606f\u4e30\u5bcc\u4f46\u96be\u4ee5\u6536\u96c6\u548c\u6574\u7406\u3002", "method": "\u4f7f\u7528\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5355\u6709\u6548\u7684\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\u4ece\u4ec5\u6807\u7b7e\u6807\u6ce8\u4e2d\u91cd\u6784\u601d\u7ef4\u8f68\u8ff9\uff0c\u5e94\u7528\u4e8e\u5fae\u8c03\u5f00\u6e90LLM\u8bc4\u4f30\u5668\u548c\u5408\u6210\u66f4\u6e05\u6670\u7684\u4e13\u6709LLM\u8bc4\u4f30\u5668\u6807\u6ce8\u6307\u5357\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86LLM\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\uff0c\u6539\u8fdb\u7684\u6807\u6ce8\u6307\u5357\u589e\u52a0\u4e86\u4e0d\u540cLLM\u6a21\u578b\u95f4\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u672a\u63ed\u793a\u7684\u4eba\u7c7b\u601d\u7ef4\u8f68\u8ff9\u7684\u5b9e\u9645\u4ee3\u7406\uff0c\u4f7f\u4ec5\u6807\u7b7e\u8bed\u6599\u5e93\u6269\u5c55\u4e3a\u601d\u7ef4\u8f68\u8ff9\u589e\u5f3a\u8d44\u6e90\uff0c\u63d0\u9ad8LLM\u8bc4\u4f30\u5668\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.26628", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26628", "abs": "https://arxiv.org/abs/2510.26628", "authors": ["Chuang Zhang", "Geng Sun", "Jiahui Li", "Jiacheng Wang", "Qingqing Wu", "Dusit Niyato", "Shiwen Mao", "Tony Q. S. Quek"], "title": "Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications", "comment": "This paper has been submitted to IEEE Journal on Selected Areas in\n  Communications", "summary": "The proliferation of Internet of Things (IoT) networks has created an urgent\nneed for sustainable energy solutions, particularly for the battery-constrained\nspatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles\n(UAVs) employed with wireless power transfer (WPT) capabilities offer a\npromising solution, the line-of-sight channels that facilitate efficient energy\ndelivery also expose sensitive operational data to adversaries. This paper\nproposes a novel low-altitude UAV-carried movable antenna-enhanced transmission\nsystem joint WPT and covert communications, which simultaneously performs\nenergy supplements to IoT nodes and establishes transmission links with a\ncovert user by leveraging wireless energy signals as a natural cover. Then, we\nformulate a multi-objective optimization problem that jointly maximizes the\ntotal harvested energy of IoT nodes and sum achievable rate of the covert user,\nwhile minimizing the propulsion energy consumption of the low-altitude UAV. To\naddress the non-convex and temporally coupled optimization problem, we propose\na mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that\nemploys a sparse Top-K gated mixture-of-shallow-experts architecture to\nrepresent multimodal policy distributions arising from the conflicting\noptimization objectives. We also incorporate an action projection module that\nexplicitly enforces per-time-slot power budget constraints and antenna position\nconstraints. Simulation results demonstrate that the proposed approach\nsignificantly outperforms some baseline approaches and other state-of-the-art\ndeep reinforcement learning algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u7a7a\u65e0\u4eba\u673a\u8f7d\u79fb\u52a8\u5929\u7ebf\u589e\u5f3a\u4f20\u8f93\u7cfb\u7edf\uff0c\u8054\u5408\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u548c\u9690\u853d\u901a\u4fe1\uff0c\u4e3a\u7269\u8054\u7f51\u8282\u70b9\u8865\u5145\u80fd\u91cf\u5e76\u5efa\u7acb\u9690\u853d\u7528\u6237\u4f20\u8f93\u94fe\u8def\u3002", "motivation": "\u7269\u8054\u7f51\u7f51\u7edc\u6fc0\u589e\u9700\u8981\u53ef\u6301\u7eed\u80fd\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u7684\u89c6\u8ddd\u4fe1\u9053\u5bb9\u6613\u66b4\u9732\u654f\u611f\u64cd\u4f5c\u6570\u636e\u7ed9\u653b\u51fb\u8005\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u589e\u5f3a\u7684\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u7ed3\u5408\u7a00\u758fTop-K\u95e8\u63a7\u6df7\u5408\u6d45\u5c42\u4e13\u5bb6\u67b6\u6784\u6765\u8868\u793a\u591a\u6a21\u6001\u7b56\u7565\u5206\u5e03\uff0c\u5e76\u52a0\u5165\u52a8\u4f5c\u6295\u5f71\u6a21\u5757\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u80fd\u6709\u6548\u89e3\u51b3\u7269\u8054\u7f51\u8282\u70b9\u7684\u80fd\u91cf\u8865\u5145\u548c\u9690\u853d\u901a\u4fe1\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u4f18\u5316\u76ee\u6807\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.26452", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26452", "abs": "https://arxiv.org/abs/2510.26452", "authors": ["Yi-Ting Hong", "Stefano Rini", "Luca Barletta"], "title": "PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design", "comment": null, "summary": "Polar codes with large kernels can achieve improved error exponents but are\nchallenging to design with low decoding complexity. This work investigates\nkernel construction under recursive maximum likelihood decoding (RMLD) using a\nreinforcement learning framework based on the Gumbel AlphaZero algorithm. The\nproposed method efficiently explores the design space and identifies large-size\nkernels that satisfy a given error exponent while minimizing decoding\ncomplexity. For a size-16 kernel, it achieves 17% lower decoding complexity\nthan handcrafted designs while reaching an error exponent of 0.5183 compared to\n0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based\napproach for practical polar code construction.", "AI": {"tldr": "\u4f7f\u7528\u57fa\u4e8eGumbel AlphaZero\u7b97\u6cd5\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6784\u5efa\u5927\u6838\u6781\u5316\u7801\uff0c\u5728\u6ee1\u8db3\u7ed9\u5b9a\u9519\u8bef\u6307\u6570\u7684\u540c\u65f6\u6700\u5c0f\u5316\u89e3\u7801\u590d\u6742\u5ea6\u3002", "motivation": "\u5927\u6838\u6781\u5316\u7801\u80fd\u6539\u5584\u9519\u8bef\u6307\u6570\uff0c\u4f46\u8bbe\u8ba1\u4f4e\u89e3\u7801\u590d\u6742\u5ea6\u7684\u5927\u6838\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8eGumbel AlphaZero\u7b97\u6cd5\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u9012\u5f52\u6700\u5927\u4f3c\u7136\u89e3\u7801\u4e0b\u8fdb\u884c\u6838\u6784\u9020\u3002", "result": "\u5bf9\u4e8e\u5c3a\u5bf816\u7684\u6838\uff0c\u89e3\u7801\u590d\u6742\u5ea6\u6bd4\u624b\u5de5\u8bbe\u8ba1\u964d\u4f4e17%\uff0c\u9519\u8bef\u6307\u6570\u8fbe\u52300.5183\uff08Arikan\u6838\u4e3a0.5\uff09\u3002", "conclusion": "\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u5927\u6838\u6781\u5316\u7801\u6784\u9020\u4e2d\u5177\u6709\u5b9e\u9645\u6709\u6548\u6027\u3002"}}
{"id": "2510.25883", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.0; I.2.6; G.3"], "pdf": "https://arxiv.org/pdf/2510.25883", "abs": "https://arxiv.org/abs/2510.25883", "authors": ["Christian Dittrich", "Jennifer Flygare Kinne"], "title": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "comment": "41 pages, 2 tables, 3 appendices. Submitted to arXiv for open access", "summary": "Existing frameworks converge on the centrality of compression to intelligence\nbut leave underspecified why this process enforces the discovery of causal\nstructure rather than superficial statistical patterns. We introduce a\ntwo-level framework to address this gap. The Information-Theoretic Imperative\n(ITI) establishes that any system persisting in uncertain environments must\nminimize epistemic entropy through predictive compression: this is the\nevolutionary \"why\" linking survival pressure to information-processing demands.\nThe Compression Efficiency Principle (CEP) specifies how efficient compression\nmechanically selects for generative, causal models through\nexception-accumulation dynamics, making reality alignment a consequence rather\nthan a contingent achievement. Together, ITI and CEP define a causal chain:\nfrom survival pressure to prediction necessity, compression requirement,\nefficiency optimization, generative structure discovery, and ultimately reality\nalignment. Each link follows from physical, information-theoretic, or\nevolutionary constraints, implying that intelligence is the mechanically\nnecessary outcome of persistence in structured environments. This framework\nyields empirically testable predictions: compression efficiency, measured as\napproach to the rate-distortion frontier, correlates with out-of-distribution\ngeneralization; exception-accumulation rates differentiate causal from\ncorrelational models; hierarchical systems exhibit increasing efficiency across\nabstraction layers; and biological systems demonstrate metabolic costs that\ntrack representational complexity. ITI and CEP thereby provide a unified\naccount of convergence across biological, artificial, and multi-scale systems,\naddressing the epistemic and functional dimensions of intelligence without\ninvoking assumptions about consciousness or subjective experience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u7ea7\u6846\u67b6\u6765\u89e3\u91ca\u538b\u7f29\u5982\u4f55\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u975e\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\uff0c\u8ba4\u4e3a\u667a\u80fd\u662f\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u673a\u68b0\u5fc5\u7136\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u867d\u7136\u8ba4\u8bc6\u5230\u538b\u7f29\u5bf9\u667a\u80fd\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4f46\u672a\u80fd\u660e\u786e\u8bf4\u660e\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u8fc7\u7a0b\u4f1a\u5f3a\u5236\u53d1\u73b0\u56e0\u679c\u7ed3\u6784\u800c\u4e0d\u662f\u8868\u9762\u7edf\u8ba1\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u4fe1\u606f\u8bba\u5fc5\u8981\u6027(ITI)\u548c\u538b\u7f29\u6548\u7387\u539f\u5219(CEP)\u4e24\u7ea7\u6846\u67b6\uff0cITI\u4ece\u8fdb\u5316\u89d2\u5ea6\u89e3\u91ca\u751f\u5b58\u538b\u529b\u5982\u4f55\u5bfc\u81f4\u4fe1\u606f\u5904\u7406\u9700\u6c42\uff0cCEP\u8bf4\u660e\u9ad8\u6548\u538b\u7f29\u5982\u4f55\u901a\u8fc7\u5f02\u5e38\u79ef\u7d2f\u52a8\u6001\u9009\u62e9\u751f\u6210\u6027\u56e0\u679c\u6a21\u578b\u3002", "result": "\u8be5\u6846\u67b6\u4ea7\u751f\u4e86\u53ef\u5b9e\u8bc1\u68c0\u9a8c\u7684\u9884\u6d4b\uff1a\u538b\u7f29\u6548\u7387\u4e0e\u5206\u5e03\u5916\u6cdb\u5316\u76f8\u5173\uff1b\u5f02\u5e38\u79ef\u7d2f\u7387\u533a\u5206\u56e0\u679c\u6a21\u578b\u548c\u76f8\u5173\u6a21\u578b\uff1b\u5206\u5c42\u7cfb\u7edf\u5728\u62bd\u8c61\u5c42\u4e0a\u8868\u73b0\u51fa\u9012\u589e\u6548\u7387\uff1b\u751f\u7269\u7cfb\u7edf\u663e\u793a\u4ee3\u8c22\u6210\u672c\u4e0e\u8868\u5f81\u590d\u6742\u6027\u76f8\u5173\u3002", "conclusion": "ITI\u548cCEP\u4e3a\u751f\u7269\u3001\u4eba\u5de5\u548c\u591a\u5c3a\u5ea6\u7cfb\u7edf\u7684\u6536\u655b\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u7684\u8ba4\u77e5\u548c\u529f\u80fd\u7ef4\u5ea6\uff0c\u65e0\u9700\u8bc9\u8bf8\u610f\u8bc6\u6216\u4e3b\u89c2\u7ecf\u9a8c\u7684\u5047\u8bbe\u3002"}}
{"id": "2510.26552", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.26552", "abs": "https://arxiv.org/abs/2510.26552", "authors": ["Shaocheng Liu", "Qi Chen", "Minquan Cheng"], "title": "Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures", "comment": "submitted to IEEE Transactions on Information Theory", "summary": "Characterization of entropy functions is of fundamental importance in\ninformation theory. By imposing constraints on their Shannon outer bound, i.e.,\nthe polymatroidal region, one obtains the faces of the region and entropy\nfunctions on them with special structures. In this series of two papers, we\ncharacterize entropy functions on the $2$-dimensional faces of the\npolymatroidal region $\\Gamma_4$. In Part I, we formulated the problem,\nenumerated all $59$ types of $2$-dimensional faces of $\\Gamma_4$ by a\nalgorithm, and fully characterized entropy functions on $49$ types of them. In\nthis paper, i.e., Part II, we will characterize entropy functions on the\nremaining $10$ types of faces, among which $8$ types are fully characterized\nand $2$ types are partially characterized. To characterize these types of\nfaces, we introduce some new combinatorial design structures which are\ninteresting themself.", "AI": {"tldr": "\u8be5\u8bba\u6587\u662f\u7cfb\u5217\u8bba\u6587\u7684\u7b2c\u4e8c\u90e8\u5206\uff0c\u4e3b\u8981\u7814\u7a76\u71b5\u51fd\u6570\u57284\u53d8\u91cf\u591a\u62df\u9635\u533a\u57df\u0393\u2084\u76842\u7ef4\u9762\u4e0a\u7684\u8868\u5f81\u95ee\u9898\u3002\u5728\u5269\u4f5910\u79cd\u7c7b\u578b\u76842\u7ef4\u9762\u4e2d\uff0c\u5b8c\u5168\u8868\u5f81\u4e868\u79cd\uff0c\u90e8\u5206\u8868\u5f81\u4e862\u79cd\u3002", "motivation": "\u71b5\u51fd\u6570\u7684\u8868\u5f81\u5728\u4fe1\u606f\u8bba\u4e2d\u5177\u6709\u57fa\u7840\u91cd\u8981\u6027\u3002\u901a\u8fc7\u5728\u591a\u62df\u9635\u533a\u57df\uff08\u9999\u519c\u5916\u754c\uff09\u4e0a\u65bd\u52a0\u7ea6\u675f\uff0c\u53ef\u4ee5\u5f97\u5230\u8be5\u533a\u57df\u7684\u5404\u4e2a\u9762\u53ca\u5176\u4e0a\u5177\u6709\u7279\u6b8a\u7ed3\u6784\u7684\u71b5\u51fd\u6570\u3002", "method": "\u5f15\u5165\u65b0\u7684\u7ec4\u5408\u8bbe\u8ba1\u7ed3\u6784\u6765\u8868\u5f81\u8fd9\u4e9b\u7c7b\u578b\u76842\u7ef4\u9762\u3002\u5728\u7b2c\u4e00\u90e8\u5206\u4e2d\u901a\u8fc7\u7b97\u6cd5\u679a\u4e3e\u4e86\u0393\u2084\u7684\u6240\u670959\u79cd2\u7ef4\u9762\u7c7b\u578b\uff0c\u5e76\u5b8c\u5168\u8868\u5f81\u4e86\u5176\u4e2d49\u79cd\u3002", "result": "\u5728\u5269\u4f59\u768410\u79cd2\u7ef4\u9762\u7c7b\u578b\u4e2d\uff0c\u5b8c\u5168\u8868\u5f81\u4e868\u79cd\uff0c\u90e8\u5206\u8868\u5f81\u4e862\u79cd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u7ec4\u5408\u8bbe\u8ba1\u7ed3\u6784\uff0c\u6210\u529f\u8868\u5f81\u4e86\u0393\u2084\u533a\u57df\u5927\u90e8\u52062\u7ef4\u9762\u4e0a\u7684\u71b5\u51fd\u6570\uff0c\u4e3a\u4fe1\u606f\u8bba\u4e2d\u71b5\u51fd\u6570\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2510.25884", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25884", "abs": "https://arxiv.org/abs/2510.25884", "authors": ["Eit\u00e1n Sprejer", "Fernando Avalos", "Augusto Bernardi", "Jose Pedro Brito de Azevedo Faustino", "Jacob Haimes", "Narmeen Fatimah Oozeer"], "title": "Approximating Human Preferences Using a Multi-Judge Learned System", "comment": null, "summary": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5224\u8005\u8f93\u51fa\u6765\u6821\u51c6LLM\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\uff0c\u89e3\u51b3\u8bc4\u5224\u8005\u7684\u6821\u51c6\u56f0\u96be\u3001\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u6821\u51c6\u57fa\u4e8eLLM\u7684\u8bc4\u5224\u8005\u4e0e\u4eba\u7c7b\u504f\u597d\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u8fd9\u4e9b\u8bc4\u5224\u8005\u96be\u4ee5\u6821\u51c6\u4e14\u5e38\u53d7\u8bc4\u5206\u6807\u51c6\u654f\u611f\u6027\u3001\u504f\u89c1\u548c\u4e0d\u7a33\u5b9a\u6027\u5f71\u54cd\u3002\u514b\u670d\u8fd9\u4e00\u6311\u6218\u5bf9RLHF\u7684\u53ef\u9760\u5956\u52b1\u6a21\u578b\u548c\u9009\u62e9\u6700\u4f73\u6a21\u578b\u7684\u8def\u5f84\u7cfb\u7edf\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u5224\u8005\u8f93\u51fa\u6765\u5efa\u6a21\u591a\u6837\u5316\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u3002\u5305\u62ec\u57fa\u4e8e\u89d2\u8272\u7684\u504f\u597d\u6807\u7b7e\u5927\u89c4\u6a21\u5408\u6210\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e24\u79cd\u805a\u5408\u5668\u5b9e\u73b0\uff1a\u5e7f\u4e49\u52a0\u6027\u6a21\u578b(GAM)\u548c\u591a\u5c42\u611f\u77e5\u5668(MLP)\u3002", "result": "\u7814\u7a76\u4e86\u8be5\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u7b80\u5355\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u548cLLM\u8bc4\u5224\u8005\u504f\u89c1\u7684\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u5176\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u591a\u6837\u5316\u504f\u597d\uff0c\u4e3aLLM\u8bc4\u5224\u8005\u7684\u6821\u51c6\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u5728RLHF\u5956\u52b1\u6a21\u578b\u548c\u6a21\u578b\u8def\u7531\u7cfb\u7edf\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.25908", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25908", "abs": "https://arxiv.org/abs/2510.25908", "authors": ["Emily Herron", "Junqi Yin", "Feiyi Wang"], "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "comment": "Preprint Submitted to ACM Transactions on AI for Science (TAIS)", "summary": "Large language models (LLMs) have demonstrated transformative potential in\nscientific research, yet their deployment in high-stakes contexts raises\nsignificant trustworthiness concerns. Here, we introduce SciTrust 2.0, a\ncomprehensive framework for evaluating LLM trustworthiness in scientific\napplications across four dimensions: truthfulness, adversarial robustness,\nscientific safety, and scientific ethics. Our framework incorporates novel,\nopen-ended truthfulness benchmarks developed through a verified\nreflection-tuning pipeline and expert validation, alongside a novel ethics\nbenchmark for scientific research contexts covering eight subcategories\nincluding dual-use research and bias. We evaluated seven prominent LLMs,\nincluding four science-specialized models and three general-purpose industry\nmodels, using multiple evaluation metrics including accuracy, semantic\nsimilarity measures, and LLM-based scoring. General-purpose industry models\noverall outperformed science-specialized models across each trustworthiness\ndimension, with GPT-o4-mini demonstrating superior performance in truthfulness\nassessments and adversarial robustness. Science-specialized models showed\nsignificant deficiencies in logical and ethical reasoning capabilities, along\nwith concerning vulnerabilities in safety evaluations, particularly in\nhigh-risk domains such as biosecurity and chemical weapons. By open-sourcing\nour framework, we provide a foundation for developing more trustworthy AI\nsystems and advancing research on model safety and ethics in scientific\ncontexts.", "AI": {"tldr": "SciTrust 2.0\u662f\u4e00\u4e2a\u8bc4\u4f30\u79d1\u5b66\u5e94\u7528\u4e2dLLM\u53ef\u4fe1\u5ea6\u7684\u7efc\u5408\u6846\u67b6\uff0c\u6db5\u76d6\u771f\u5b9e\u6027\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u79d1\u5b66\u5b89\u5168\u548c\u79d1\u5b66\u4f26\u7406\u56db\u4e2a\u7ef4\u5ea6\u3002\u8bc4\u4f30\u663e\u793a\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u5404\u65b9\u9762\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\u3002", "motivation": "LLM\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5f15\u53d1\u4e86\u53ef\u4fe1\u5ea6\u62c5\u5fe7\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u5f00\u653e\u5f0f\u771f\u5b9e\u6027\u57fa\u51c6\u548c\u79d1\u5b66\u4f26\u7406\u57fa\u51c6\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u9a8c\u8bc1\u7684\u53cd\u601d\u8c03\u4f18\u6d41\u7a0b\u548c\u4e13\u5bb6\u9a8c\u8bc1\uff0c\u91c7\u7528\u51c6\u786e\u6027\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548cLLM\u8bc4\u5206\u7b49\u591a\u79cd\u6307\u6807\u8bc4\u4f307\u4e2a\u4e3b\u8981LLM\u3002", "result": "\u901a\u7528\u884c\u4e1a\u6a21\u578b\u5728\u6240\u6709\u53ef\u4fe1\u5ea6\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u79d1\u5b66\u4e13\u7528\u6a21\u578b\uff0cGPT-4-mini\u5728\u771f\u5b9e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002\u79d1\u5b66\u4e13\u7528\u6a21\u578b\u5728\u903b\u8f91\u548c\u4f26\u7406\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u5728\u751f\u7269\u5b89\u5168\u548c\u5316\u5b66\u6b66\u5668\u7b49\u9ad8\u5371\u9886\u57df\u7684\u5b89\u5168\u6f0f\u6d1e\u4ee4\u4eba\u62c5\u5fe7\u3002", "conclusion": "\u901a\u8fc7\u5f00\u6e90\u8be5\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u548c\u63a8\u8fdb\u79d1\u5b66\u80cc\u666f\u4e0b\u6a21\u578b\u5b89\u5168\u4e0e\u4f26\u7406\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.25914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25914", "abs": "https://arxiv.org/abs/2510.25914", "authors": ["Ngoc Phuoc An Vo", "Manish Kesarwani", "Ruchi Mahindru", "Chandrasekhar Narayanaswami"], "title": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization", "comment": null, "summary": "FinOps (Finance + Operations) represents an operational framework and\ncultural practice which maximizes cloud business value through collaborative\nfinancial accountability across engineering, finance, and business teams.\nFinOps practitioners face a fundamental challenge: billing data arrives in\nheterogeneous formats, taxonomies, and metrics from multiple cloud providers\nand internal systems which eventually lead to synthesizing actionable insights,\nand making time-sensitive decisions. To address this challenge, we propose\nleveraging autonomous, goal-driven AI agents for FinOps automation. In this\npaper, we built a FinOps agent for a typical use-case for IT infrastructure and\ncost optimization. We built a system simulating a realistic end-to-end industry\nprocess starting with retrieving data from various sources to consolidating and\nanalyzing the data to generate recommendations for optimization. We defined a\nset of metrics to evaluate our agent using several open-source and close-source\nlanguage models and it shows that the agent was able to understand, plan, and\nexecute tasks as well as an actual FinOps practitioner.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u81ea\u4e3bAI\u4ee3\u7406\u5b9e\u73b0FinOps\u81ea\u52a8\u5316\uff0c\u901a\u8fc7\u6a21\u62df\u7aef\u5230\u7aef\u884c\u4e1a\u6d41\u7a0b\uff0c\u4ece\u591a\u6e90\u6570\u636e\u68c0\u7d22\u5230\u5206\u6790\u751f\u6210\u4f18\u5316\u5efa\u8bae\uff0c\u8bc4\u4f30\u663e\u793aAI\u4ee3\u7406\u80fd\u8fbe\u5230\u5b9e\u9645FinOps\u4ece\u4e1a\u8005\u7684\u6c34\u5e73\u3002", "motivation": "FinOps\u4ece\u4e1a\u8005\u9762\u4e34\u6765\u81ea\u591a\u4e2a\u4e91\u63d0\u4f9b\u5546\u548c\u5185\u90e8\u7cfb\u7edf\u7684\u5f02\u6784\u8ba1\u8d39\u6570\u636e\u683c\u5f0f\u3001\u5206\u7c7b\u548c\u6307\u6807\uff0c\u5bfc\u81f4\u96be\u4ee5\u7efc\u5408\u53ef\u64cd\u4f5c\u89c1\u89e3\u548c\u505a\u51fa\u65f6\u6548\u6027\u51b3\u7b56\u3002", "method": "\u6784\u5efaFinOps\u4ee3\u7406\u7cfb\u7edf\uff0c\u6a21\u62df\u4ece\u591a\u6e90\u6570\u636e\u68c0\u7d22\u5230\u6570\u636e\u6574\u5408\u5206\u6790\u518d\u5230\u751f\u6210\u4f18\u5316\u5efa\u8bae\u7684\u7aef\u5230\u7aef\u884c\u4e1a\u6d41\u7a0b\uff0c\u4f7f\u7528\u5f00\u6e90\u548c\u95ed\u6e90\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4ee3\u7406\u80fd\u591f\u7406\u89e3\u3001\u89c4\u5212\u548c\u6267\u884c\u4efb\u52a1\uff0c\u8868\u73b0\u4e0e\u5b9e\u9645\u7684FinOps\u4ece\u4e1a\u8005\u76f8\u5f53\u3002", "conclusion": "\u81ea\u4e3bAI\u4ee3\u7406\u53ef\u4ee5\u6709\u6548\u89e3\u51b3FinOps\u4e2d\u7684\u6570\u636e\u5f02\u6784\u6311\u6218\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u6210\u672c\u4f18\u5316\u3002"}}
{"id": "2510.25933", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.25933", "abs": "https://arxiv.org/abs/2510.25933", "authors": ["Nissan Yaron", "Dan Bystritsky", "Ben-Etzion Yaron"], "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "comment": null, "summary": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS\nGrounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI\n69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference\nis 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's\n$d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp).\nWhen purchased as managed APIs, Humans-Junior's base model\n(Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on\nMicrosoft AI Foundry pricing; self-hosted or edge deployments can drive\nincremental inference cost toward zero. Measured vs estimated pricing sources\nare tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\"\nscaffolds with behavioral fine-tuning that teaches protocol compliance\n(epistemic discipline) rather than domain answers. Fine-tuning alone adds\nlittle; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance\n($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100;\nnon-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and\nGemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within\n$\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost\nversus GPT-4o, and self-hosted/edge deployments can approach zero marginal\ncost. Pricing sources are listed in Appendix E. Frontier prompt-only gains\n(Q1--Q100; non-comparable) and optimized-prompt exploratory results under\nearlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,\nFine-Tuning, Model Alignment, Cost-Efficient AI", "AI": {"tldr": "\u4e00\u4e2a3.8B\u53c2\u6570\u7684\u6a21\u578b\u5728FACTS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230GPT-4o\u6c34\u5e73\uff0c\u4e91\u670d\u52a1\u6210\u672c\u964d\u4f4e\u7ea619\u500d\uff0c\u81ea\u6258\u7ba1\u90e8\u7f72\u8fb9\u9645\u6210\u672c\u63a5\u8fd1\u96f6\u3002", "motivation": "\u5f00\u53d1\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "method": "\u7ed3\u5408\u6700\u5c0f\u5316\u7684\"\u5916\u9aa8\u9abc\u63a8\u7406\"\u652f\u67b6\u548c\u884c\u4e3a\u5fae\u8c03\uff0c\u6559\u5bfc\u534f\u8bae\u9075\u5faa\u800c\u975e\u9886\u57df\u77e5\u8bc6\uff0c\u4e24\u8005\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728Q1-Q500\u6d4b\u8bd5\u96c6\u4e0a\uff0cHumans-Junior(72.7%)\u4e0eGPT-4o(73.5%)\u5728\u00b15pp\u7b49\u6548\u8303\u56f4\u5185\u8868\u73b0\u76f8\u5f53\uff0c\u6210\u672c\u964d\u4f4e\u7ea619\u500d\u3002", "conclusion": "\u5c0f\u578b\u6a21\u578b\u901a\u8fc7\u9002\u5f53\u7684\u63a8\u7406\u652f\u67b6\u548c\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8fbe\u5230\u5927\u578b\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2510.25951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25951", "abs": "https://arxiv.org/abs/2510.25951", "authors": ["Sounak Banerjee", "Daphne Cornelisse", "Deepak Gopinath", "Emily Sumner", "Jonathan DeCastro", "Guy Rosman", "Eugene Vinitsky", "Mark K. Ho"], "title": "Estimating cognitive biases with attention-aware inverse planning", "comment": null, "summary": "People's goal-directed behaviors are influenced by their cognitive biases,\nand autonomous systems that interact with people should be aware of this. For\nexample, people's attention to objects in their environment will be biased in a\nway that systematically affects how they perform everyday tasks such as driving\nto work. Here, building on recent work in computational cognitive science, we\nformally articulate the attention-aware inverse planning problem, in which the\ngoal is to estimate a person's attentional biases from their actions. We\ndemonstrate how attention-aware inverse planning systematically differs from\nstandard inverse reinforcement learning and how cognitive biases can be\ninferred from behavior. Finally, we present an approach to attention-aware\ninverse planning that combines deep reinforcement learning with computational\ncognitive modeling. We use this approach to infer the attentional strategies of\nRL agents in real-life driving scenarios selected from the Waymo Open Dataset,\ndemonstrating the scalability of estimating cognitive biases with\nattention-aware inverse planning.", "AI": {"tldr": "\u63d0\u51fa\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u65b9\u6cd5\uff0c\u4ece\u4eba\u7c7b\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u89c1\uff0c\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u5728\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u9a8c\u8bc1\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4eba\u7c7b\u7684\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u53d7\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\uff0c\u81ea\u4e3b\u7cfb\u7edf\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u504f\u89c1\u3002\u4f8b\u5982\uff0c\u4eba\u4eec\u5728\u65e5\u5e38\u4efb\u52a1\uff08\u5982\u9a7e\u9a76\uff09\u4e2d\u7684\u6ce8\u610f\u529b\u5206\u5e03\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u8ba1\u7b97\u8ba4\u77e5\u5efa\u6a21\uff0c\u6784\u5efa\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u6846\u67b6\uff0c\u4ece\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u4e2d\u63a8\u65ad\u6ce8\u610f\u529b\u7b56\u7565\u3002", "result": "\u5728Waymo\u5f00\u653e\u6570\u636e\u96c6\u4e2d\u7684\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u6210\u529f\u63a8\u65adRL\u667a\u80fd\u4f53\u7684\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4f30\u8ba1\u8ba4\u77e5\u504f\u89c1\u65b9\u9762\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u6ce8\u610f\u529b\u611f\u77e5\u9006\u89c4\u5212\u80fd\u591f\u6709\u6548\u4ece\u884c\u4e3a\u4e2d\u63a8\u65ad\u8ba4\u77e5\u504f\u89c1\uff0c\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u7406\u89e3\u4eba\u7c7b\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.25997", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.25997", "abs": "https://arxiv.org/abs/2510.25997", "authors": ["Manu Redd", "Tao Zhe", "Dongjie Wang"], "title": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL", "comment": "8 pages, 5 figures, GeoGenAgent'25 - ACM SIGSPATIAL", "summary": "Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing\naccess to structured data, allowing users to query databases without learning\nSQL. Yet existing systems struggle with realistic spatio-temporal queries,\nwhere success requires aligning vague user phrasing with schema-specific\ncategories, handling temporal reasoning, and choosing appropriate outputs. We\npresent an agentic pipeline that extends a naive text-to-SQL baseline\n(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The\nagent can plan, decompose, and adapt queries through schema inspection, SQL\ngeneration, execution, and visualization tools. We evaluate on 35\nnatural-language queries over the NYC and Tokyo check-in dataset, covering\nspatial, temporal, and multi-dataset reasoning. The agent achieves\nsubstantially higher accuracy than the naive baseline 91.4% vs. 28.6% and\nenhances usability through maps, plots, and structured natural-language\nsummaries. Crucially, our design enables more natural human-database\ninteraction, supporting users who lack SQL expertise, detailed schema\nknowledge, or prompting skill. We conclude that agentic orchestration, rather\nthan stronger SQL generators alone, is a promising foundation for interactive\ngeospatial assistants.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u81ea\u7136\u8bed\u8a00\u5230SQL\u7cfb\u7edf\uff0c\u901a\u8fc7ReAct\u4ee3\u7406\u534f\u8c03\u6269\u5c55\u4e86\u57fa\u7840\u7684\u6587\u672c\u5230SQL\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u65f6\u7a7a\u67e5\u8be2\u7684\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709NL-to-SQL\u7cfb\u7edf\u5728\u5904\u7406\u73b0\u5b9e\u7684\u65f6\u7a7a\u67e5\u8be2\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u89e3\u51b3\u6a21\u7cca\u7528\u6237\u8868\u8fbe\u4e0e\u7279\u5b9a\u6a21\u5f0f\u7c7b\u522b\u7684\u5bf9\u9f50\u3001\u65f6\u95f4\u63a8\u7406\u548c\u9002\u5f53\u8f93\u51fa\u9009\u62e9\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eMistral\u7684ReAct\u4ee3\u7406\u6784\u5efa\u4ee3\u7406\u5316\u7ba1\u9053\uff0c\u901a\u8fc7\u6a21\u5f0f\u68c0\u67e5\u3001SQL\u751f\u6210\u3001\u6267\u884c\u548c\u53ef\u89c6\u5316\u5de5\u5177\u6765\u89c4\u5212\u3001\u5206\u89e3\u548c\u9002\u914d\u67e5\u8be2\u3002", "result": "\u5728NYC\u548cTokyo\u7b7e\u5230\u6570\u636e\u96c6\u768435\u4e2a\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8bc4\u4f30\u4e2d\uff0c\u4ee3\u7406\u7cfb\u7edf\u51c6\u786e\u7387\u8fbe\u523091.4%\uff0c\u8fdc\u9ad8\u4e8e\u57fa\u7ebf\u6a21\u578b\u768428.6%\uff0c\u5e76\u901a\u8fc7\u5730\u56fe\u3001\u56fe\u8868\u548c\u81ea\u7136\u8bed\u8a00\u6458\u8981\u589e\u5f3a\u4e86\u53ef\u7528\u6027\u3002", "conclusion": "\u4ee3\u7406\u5316\u534f\u8c03\u800c\u975e\u4ec5\u589e\u5f3aSQL\u751f\u6210\u5668\uff0c\u662f\u6784\u5efa\u4ea4\u4e92\u5f0f\u5730\u7406\u7a7a\u95f4\u52a9\u624b\u7684\u6709\u524d\u666f\u57fa\u7840\uff0c\u80fd\u591f\u652f\u6301\u7f3a\u4e4fSQL\u4e13\u4e1a\u77e5\u8bc6\u3001\u8be6\u7ec6\u6a21\u5f0f\u77e5\u8bc6\u6216\u63d0\u793a\u6280\u80fd\u7684\u7528\u6237\u3002"}}
{"id": "2510.26012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26012", "abs": "https://arxiv.org/abs/2510.26012", "authors": ["Siyi Wu", "Chiaxin Liang", "Ziqian Bi", "Leyi Zhao", "Tianyang Wang", "Junhao Song", "Yichao Zhang", "Keyu Chen", "Xinyuan Song"], "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "comment": "TKDD 2025", "summary": "The rapid growth of research literature, particularly in large language\nmodels (LLMs), has made producing comprehensive and current survey papers\nincreasingly difficult. This paper introduces autosurvey2, a multi-stage\npipeline that automates survey generation through retrieval-augmented synthesis\nand structured evaluation. The system integrates parallel section generation,\niterative refinement, and real-time retrieval of recent publications to ensure\nboth topical completeness and factual accuracy. Quality is assessed using a\nmulti-LLM evaluation framework that measures coverage, structure, and relevance\nin alignment with expert review standards. Experimental results demonstrate\nthat autosurvey2 consistently outperforms existing retrieval-based and\nautomated baselines, achieving higher scores in structural coherence and\ntopical relevance while maintaining strong citation fidelity. By combining\nretrieval, reasoning, and automated evaluation into a unified framework,\nautosurvey2 provides a scalable and reproducible solution for generating\nlong-form academic surveys and contributes a solid foundation for future\nresearch on automated scholarly writing. All code and resources are available\nat https://github.com/annihi1ation/auto_research.", "AI": {"tldr": "autosurvey2\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u751f\u6210\u5b66\u672f\u7efc\u8ff0\u8bba\u6587\u7684\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\uff0c\u5728LLM\u7814\u7a76\u9886\u57df\u5b9e\u73b0\u9ad8\u6548\u3001\u51c6\u786e\u7684\u7efc\u8ff0\u751f\u6210\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u6587\u732e\u7684\u5feb\u901f\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9886\u57df\uff0c\u4f20\u7edf\u7684\u4eba\u5de5\u64b0\u5199\u7efc\u8ff0\u8bba\u6587\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u4fdd\u6301\u7efc\u8ff0\u7684\u5168\u9762\u6027\u548c\u65f6\u6548\u6027\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\u5e76\u884c\u7ae0\u8282\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u5b9e\u65f6\u68c0\u7d22\u6700\u65b0\u51fa\u7248\u7269\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u5408\u6210\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eautosurvey2\u5728\u7ed3\u6784\u8fde\u8d2f\u6027\u3001\u4e3b\u9898\u76f8\u5173\u6027\u548c\u5f15\u7528\u4fdd\u771f\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u57fa\u7ebf\u548c\u81ea\u52a8\u5316\u57fa\u7ebf\uff0c\u8fbe\u5230\u66f4\u9ad8\u8bc4\u5206\u3002", "conclusion": "autosurvey2\u901a\u8fc7\u5c06\u68c0\u7d22\u3001\u63a8\u7406\u548c\u81ea\u52a8\u8bc4\u4f30\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0c\u4e3a\u751f\u6210\u957f\u7bc7\u5b66\u672f\u7efc\u8ff0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u81ea\u52a8\u5316\u5b66\u672f\u5199\u4f5c\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2510.26023", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.26023", "abs": "https://arxiv.org/abs/2510.26023", "authors": ["Zhipeng Bao", "Qianwen Li"], "title": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "comment": "8 pages", "summary": "Despite significant advancements in recent decades, autonomous vehicles (AVs)\ncontinue to face challenges in navigating certain traffic scenarios where human\ndrivers excel. In such situations, AVs often become immobilized, disrupting\noverall traffic flow. Current recovery solutions, such as remote intervention\n(which is costly and inefficient) and manual takeover (which excludes\nnon-drivers and limits AV accessibility), are inadequate. This paper introduces\nStuckSolver, a novel Large Language Model (LLM) driven recovery framework that\nenables AVs to resolve immobilization scenarios through self-reasoning and/or\npassenger-guided decision-making. StuckSolver is designed as a plug-in add-on\nmodule that operates on top of the AV's existing perception-planning-control\nstack, requiring no modification to its internal architecture. Instead, it\ninterfaces with standard sensor data streams to detect immobilization states,\ninterpret environmental context, and generate high-level recovery commands that\ncan be executed by the AV's native planner. We evaluate StuckSolver on the\nBench2Drive benchmark and in custom-designed uncertainty scenarios. Results\nshow that StuckSolver achieves near-state-of-the-art performance through\nautonomous self-reasoning alone and exhibits further improvements when\npassenger guidance is incorporated.", "AI": {"tldr": "StuckSolver\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6062\u590d\u6846\u67b6\uff0c\u80fd\u591f\u5728\u8f66\u8f86\u88ab\u56f0\u65f6\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u548c\u4e58\u5ba2\u6307\u5bfc\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u7cfb\u7edf\u67b6\u6784\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u67d0\u4e9b\u4ea4\u901a\u573a\u666f\u4e2d\u5bb9\u6613\u9677\u5165\u56f0\u5883\uff0c\u800c\u73b0\u6709\u7684\u8fdc\u7a0b\u5e72\u9884\u548c\u4eba\u5de5\u63a5\u7ba1\u65b9\u6848\u5b58\u5728\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u3001\u9650\u5236\u975e\u9a7e\u9a76\u5458\u4f7f\u7528\u7b49\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86StuckSolver\u4f5c\u4e3a\u63d2\u4ef6\u6a21\u5757\uff0c\u5229\u7528LLM\u5206\u6790\u4f20\u611f\u5668\u6570\u636e\u68c0\u6d4b\u88ab\u56f0\u72b6\u6001\uff0c\u7406\u89e3\u73af\u5883\u4e0a\u4e0b\u6587\uff0c\u5e76\u751f\u6210\u53ef\u7531\u8f66\u8f86\u539f\u751f\u89c4\u5212\u5668\u6267\u884c\u7684\u9ad8\u7ea7\u6062\u590d\u6307\u4ee4\u3002", "result": "\u5728Bench2Drive\u57fa\u51c6\u6d4b\u8bd5\u548c\u81ea\u5b9a\u4e49\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u4e2d\uff0cStuckSolver\u4ec5\u901a\u8fc7\u81ea\u4e3b\u63a8\u7406\u5c31\u8fbe\u5230\u4e86\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u7ed3\u5408\u4e58\u5ba2\u6307\u5bfc\u540e\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "StuckSolver\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u88ab\u56f0\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u8f66\u8f86\u5728\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2510.26057", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26057", "abs": "https://arxiv.org/abs/2510.26057", "authors": ["Andrew L. Kun"], "title": "Can AI be Accountable?", "comment": "To be published as a chapter in Daniele Quercia and Marios\n  Constantinides (Eds.). Operationalizing Responsible AI. Cambridge University\n  Press. Forthcoming", "summary": "The AI we use is powerful, and its power is increasing rapidly. If this\npowerful AI is to serve the needs of consumers, voters, and decision makers,\nthen it is imperative that the AI is accountable. In general, an agent is\naccountable to a forum if the forum can request information from the agent\nabout its actions, if the forum and the agent can discuss this information, and\nif the forum can sanction the agent. Unfortunately, in too many cases today's\nAI is not accountable -- we cannot question it, enter into a discussion with\nit, let alone sanction it. In this chapter we relate the general definition of\naccountability to AI, we illustrate what it means for AI to be accountable and\nunaccountable, and we explore approaches that can improve our chances of living\nin a world where all AI is accountable to those who are affected by it.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u95ee\u8d23\u5236\u7684\u91cd\u8981\u6027\uff0c\u5206\u6790\u4e86\u5f53\u524dAI\u7f3a\u4e4f\u95ee\u8d23\u6027\u7684\u73b0\u72b6\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584AI\u95ee\u8d23\u6027\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u7684\u5feb\u901f\u63d0\u5347\uff0c\u786e\u4fddAI\u5bf9\u6d88\u8d39\u8005\u3001\u9009\u6c11\u548c\u51b3\u7b56\u8005\u8d1f\u8d23\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524dAI\u7f3a\u4e4f\u95ee\u8d23\u673a\u5236\uff0c\u65e0\u6cd5\u88ab\u8d28\u7591\u3001\u8ba8\u8bba\u6216\u5236\u88c1\u3002", "method": "\u5c06\u4e00\u822c\u95ee\u8d23\u5236\u5b9a\u4e49\u5e94\u7528\u4e8eAI\u9886\u57df\uff0c\u901a\u8fc7\u6848\u4f8b\u8bf4\u660eAI\u95ee\u8d23\u4e0e\u4e0d\u95ee\u8d23\u7684\u542b\u4e49\uff0c\u63a2\u7d22\u63d0\u9ad8AI\u95ee\u8d23\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u660e\u786e\u4e86AI\u95ee\u8d23\u5236\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5f53\u524dAI\u95ee\u8d23\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5b9e\u73b0AI\u95ee\u8d23\u5236\u7684\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "\u5fc5\u987b\u91c7\u53d6\u63aa\u65bd\u786e\u4fdd\u6240\u6709AI\u5bf9\u5176\u5f71\u54cd\u5bf9\u8c61\u8d1f\u8d23\uff0c\u8fd9\u662f\u6784\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u7684\u5173\u952e\u8981\u6c42\u3002"}}
{"id": "2510.26094", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26094", "abs": "https://arxiv.org/abs/2510.26094", "authors": ["Yuxin Li", "Minghao Liu", "Ruida Wang", "Wenzhao Ji", "Zhitao He", "Rui Pan", "Junming Huang", "Tong Zhang", "Yi R. Fung"], "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "comment": null, "summary": "We present **Lean4PHYS**, a comprehensive reasoning framework for\ncollege-level physics problems in Lean4. **Lean4PHYS** includes\n*LeanPhysBench*, a college-level benchmark for formal physics reasoning in\nLean4, which contains 200 hand-crafted and peer-reviewed statements derived\nfrom university textbooks and physics competition problems. To establish a\nsolid foundation for formal reasoning in physics, we also introduce *PhysLib*,\na community-driven repository containing fundamental unit systems and theorems\nessential for formal physics reasoning. Based on the benchmark and Lean4\nrepository we composed in **Lean4PHYS**, we report baseline results using major\nexpert Math Lean4 provers and state-of-the-art closed-source models, with the\nbest performance of DeepSeek-Prover-V2-7B achieving only 16% and\nClaude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that\nour *PhysLib* can achieve an average improvement of 11.75% in model\nperformance. This demonstrates the challenging nature of our *LeanPhysBench*\nand the effectiveness of *PhysLib*. To the best of our knowledge, this is the\nfirst study to provide a physics benchmark in Lean4.", "AI": {"tldr": "Lean4PHYS\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u5b66\u7269\u7406\u95ee\u9898\u63a8\u7406\u7684\u6846\u67b6\uff0c\u5305\u542bLeanPhysBench\u57fa\u51c6\u6d4b\u8bd5\u548cPhysLib\u77e5\u8bc6\u5e93\uff0c\u5728Lean4\u4e2d\u9a8c\u8bc1\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4e3a\u5927\u5b66\u7269\u7406\u95ee\u9898\u5efa\u7acb\u6b63\u5f0f\u7684\u63a8\u7406\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u586b\u8865Lean4\u4e2d\u7269\u7406\u63a8\u7406\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b200\u4e2a\u624b\u5de5\u5236\u4f5c\u548c\u540c\u884c\u8bc4\u5ba1\u7269\u7406\u95ee\u9898\u7684LeanPhysBench\u57fa\u51c6\uff0c\u5f00\u53d1\u793e\u533a\u9a71\u52a8\u7684PhysLib\u77e5\u8bc6\u5e93\uff0c\u4f7f\u7528\u4e3b\u8981\u6570\u5b66\u8bc1\u660e\u5668\u548c\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u57fa\u7ebf\u6d4b\u8bd5\u3002", "result": "DeepSeek-Prover-V2-7B\u4ec5\u8fbe\u523016%\u51c6\u786e\u7387\uff0cClaude-Sonnet-4\u8fbe\u523035%\uff0cPhysLib\u5e73\u5747\u63d0\u5347\u6a21\u578b\u6027\u80fd11.75%\u3002", "conclusion": "LeanPhysBench\u5177\u6709\u6311\u6218\u6027\uff0cPhysLib\u6709\u6548\u63d0\u5347\u6027\u80fd\uff0c\u8fd9\u662f\u9996\u4e2a\u5728Lean4\u4e2d\u63d0\u4f9b\u7684\u7269\u7406\u57fa\u51c6\u7814\u7a76\u3002"}}
{"id": "2510.26098", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26098", "abs": "https://arxiv.org/abs/2510.26098", "authors": ["Chenrui Shi", "Zedong Yu", "Zhi Gao", "Ruining Feng", "Enqi Liu", "Yuwei Wu", "Yunde Jia", "Liuyu Xiang", "Zhaofeng He", "Qing Li"], "title": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks", "comment": null, "summary": "Large vision language models (VLMs) have advanced graphical user interface\n(GUI) task automation but still lag behind humans. We hypothesize this gap\nstems from missing core GUI knowledge, which existing training schemes (such as\nsupervised fine tuning and reinforcement learning) alone cannot fully address.\nBy analyzing common failure patterns in GUI task execution, we distill GUI\nknowledge into three dimensions: (1) interface perception, knowledge about\nrecognizing widgets and system states; (2) interaction prediction, knowledge\nabout reasoning action state transitions; and (3) instruction understanding,\nknowledge about planning, verifying, and assessing task completion progress. We\nfurther introduce GUI Knowledge Bench, a benchmark with multiple choice and\nyes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,\nIOS) and 292 applications. Our evaluation shows that current VLMs identify\nwidget functions but struggle with perceiving system states, predicting\nactions, and verifying task completion. Experiments on real world GUI tasks\nfurther validate the close link between GUI knowledge and task success. By\nproviding a structured framework for assessing GUI knowledge, our work supports\nthe selection of VLMs with greater potential prior to downstream training and\nprovides insights for building more capable GUI agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728GUI\u4efb\u52a1\u81ea\u52a8\u5316\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u51faGUI\u77e5\u8bc6\u5305\u542b\u4e09\u4e2a\u7ef4\u5ea6\uff1a\u754c\u9762\u611f\u77e5\u3001\u4ea4\u4e92\u9884\u6d4b\u548c\u6307\u4ee4\u7406\u89e3\uff0c\u5e76\u521b\u5efa\u4e86GUI\u77e5\u8bc6\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728GUI\u4efb\u52a1\u81ea\u52a8\u5316\u65b9\u9762\u4ecd\u843d\u540e\u4e8e\u4eba\u7c7b\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u5dee\u8ddd\u6e90\u4e8e\u7f3a\u4e4f\u6838\u5fc3GUI\u77e5\u8bc6\uff0c\u800c\u73b0\u6709\u7684\u8bad\u7ec3\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790GUI\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u5c06GUI\u77e5\u8bc6\u63d0\u70bc\u4e3a\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u5f15\u5165GUI\u77e5\u8bc6\u57fa\u51c6\uff0c\u5305\u542b\u8de86\u4e2a\u5e73\u53f0\u548c292\u4e2a\u5e94\u7528\u7684\u591a\u9879\u9009\u62e9\u548c\u662f/\u5426\u95ee\u9898\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5f53\u524dVLMs\u80fd\u591f\u8bc6\u522b\u5c0f\u90e8\u4ef6\u529f\u80fd\uff0c\u4f46\u5728\u611f\u77e5\u7cfb\u7edf\u72b6\u6001\u3001\u9884\u6d4b\u52a8\u4f5c\u548c\u9a8c\u8bc1\u4efb\u52a1\u5b8c\u6210\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u771f\u5b9eGUI\u4efb\u52a1\u5b9e\u9a8c\u9a8c\u8bc1\u4e86GUI\u77e5\u8bc6\u4e0e\u4efb\u52a1\u6210\u529f\u4e4b\u95f4\u7684\u7d27\u5bc6\u8054\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u8bc4\u4f30GUI\u77e5\u8bc6\u7684\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u8be5\u5de5\u4f5c\u652f\u6301\u5728\u4e0b\u6e38\u8bad\u7ec3\u524d\u9009\u62e9\u66f4\u5177\u6f5c\u529b\u7684VLMs\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684GUI\u4ee3\u7406\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.26136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26136", "abs": "https://arxiv.org/abs/2510.26136", "authors": ["Boqin Zhuang", "Jiacheng Qiao", "Mingqian Liu", "Mingxing Yu", "Ping Hong", "Rui Li", "Xiaoxia Song", "Xiangjun Xu", "Xu Chen", "Yaoyao Ma", "Yujie Gao"], "title": "Beyond Benchmarks: The Economics of AI Inference", "comment": null, "summary": "The inference cost of Large Language Models (LLMs) has become a critical\nfactor in determining their commercial viability and widespread adoption. This\npaper introduces a quantitative ``economics of inference'' framework, treating\nthe LLM inference process as a compute-driven intelligent production activity.\nWe analyze its marginal cost, economies of scale, and quality of output under\nvarious performance configurations. Based on empirical data from WiNEval-3.0,\nwe construct the first ``LLM Inference Production Frontier,'' revealing three\nprinciples: diminishing marginal cost, diminishing returns to scale, and an\noptimal cost-effectiveness zone. This paper not only provides an economic basis\nfor model deployment decisions but also lays an empirical foundation for the\nfuture market-based pricing and optimization of AI inference resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u89c6\u4e3a\u8ba1\u7b97\u9a71\u52a8\u7684\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u5206\u6790\u4e86\u8fb9\u9645\u6210\u672c\u3001\u89c4\u6a21\u7ecf\u6d4e\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u5e76\u57fa\u4e8eWiNEval-3.0\u6570\u636e\u6784\u5efa\u4e86\u9996\u4e2aLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6210\u672c\u5df2\u6210\u4e3a\u51b3\u5b9a\u5176\u5546\u4e1a\u53ef\u884c\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9700\u8981\u5efa\u7acb\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\u6765\u6307\u5bfc\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u3002", "method": "\u91c7\u7528\u5b9a\u91cf\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06LLM\u63a8\u7406\u8fc7\u7a0b\u89c6\u4e3a\u667a\u80fd\u751f\u4ea7\u6d3b\u52a8\uff0c\u5206\u6790\u8fb9\u9645\u6210\u672c\u3001\u89c4\u6a21\u7ecf\u6d4e\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u57fa\u4e8eWiNEval-3.0\u5b9e\u8bc1\u6570\u636e\u6784\u5efaLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "result": "\u63ed\u793a\u4e86\u4e09\u4e2a\u539f\u5219\uff1a\u8fb9\u9645\u6210\u672c\u9012\u51cf\u3001\u89c4\u6a21\u62a5\u916c\u9012\u51cf\u548c\u6700\u4f18\u6210\u672c\u6548\u76ca\u533a\u57df\uff0c\u6784\u5efa\u4e86\u9996\u4e2aLLM\u63a8\u7406\u751f\u4ea7\u524d\u6cbf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u6a21\u578b\u90e8\u7f72\u51b3\u7b56\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u57fa\u7840\uff0c\u8fd8\u4e3a\u672a\u6765AI\u63a8\u7406\u8d44\u6e90\u7684\u5e02\u573a\u5b9a\u4ef7\u548c\u4f18\u5316\u5960\u5b9a\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2510.26143", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26143", "abs": "https://arxiv.org/abs/2510.26143", "authors": ["Bo Pang", "Deqian Kong", "Silvio Savarese", "Caiming Xiong", "Yingbo Zhou"], "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "comment": "9 pages", "summary": "Reinforcement learning (RL) can elicit strong reasoning in large language\nmodels (LLMs), yet most open efforts focus on math and code. We propose\nReasoning Curriculum, a simple two-stage curriculum that first elicits\nreasoning skills in pretraining-aligned domains such as math, then adapts and\nrefines these skills across other domains via joint RL. Stage 1 performs a\nbrief cold start and then math-only RL with verifiable rewards to develop\nreasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and\nconsolidate these skills. The curriculum is minimal and backbone-agnostic,\nrequiring no specialized reward models beyond standard verifiability checks.\nEvaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning\ncurriculum yields consistent gains. Ablations and a cognitive-skill analysis\nindicate that both stages are necessary and that math-first elicitation\nincreases cognitive behaviors important for solving complex problems. Reasoning\nCurriculum provides a compact, easy-to-adopt recipe for general reasoning.", "AI": {"tldr": "\u63d0\u51faReasoning Curriculum\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u6570\u5b66\u9886\u57df\u8fdb\u884cRL\u8bad\u7ec3\u4ee5\u6fc0\u53d1\u63a8\u7406\u80fd\u529b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5728\u591a\u9886\u57df\u8054\u5408RL\u4e2d\u8fc1\u79fb\u548c\u5de9\u56fa\u8fd9\u4e9b\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u7b80\u5355\u6613\u7528\uff0c\u65e0\u9700\u4e13\u7528\u5956\u52b1\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u5747\u80fd\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6570\u5b66\u548c\u7f16\u7a0b\u9886\u57df\uff0c\u7f3a\u4e4f\u901a\u7528\u7684\u63a8\u7406\u80fd\u529b\u8bad\u7ec3\u3002\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6fc0\u53d1\u548c\u8fc1\u79fb\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5230\u591a\u4e2a\u9886\u57df\u3002", "method": "\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\uff1a1\uff09\u6570\u5b66\u9886\u57dfRL\u51b7\u542f\u52a8\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u5f00\u53d1\u63a8\u7406\u6280\u80fd\uff1b2\uff09\u591a\u9886\u57df\u8054\u5408RL\uff0c\u8fc1\u79fb\u548c\u5de9\u56fa\u63a8\u7406\u80fd\u529b\u3002\u65b9\u6cd5\u7b80\u6d01\uff0c\u4e0d\u4f9d\u8d56\u4e13\u7528\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728Qwen3-4B\u548cLlama-3.1-8B\u6a21\u578b\u4e0a\u7684\u591a\u9886\u57df\u8bc4\u4f30\u663e\u793a\u4e00\u81f4\u6027\u80fd\u63d0\u5347\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u4e24\u4e2a\u9636\u6bb5\u90fd\u662f\u5fc5\u8981\u7684\uff0c\u6570\u5b66\u4f18\u5148\u7684\u6fc0\u53d1\u7b56\u7565\u80fd\u589e\u5f3a\u89e3\u51b3\u590d\u6742\u95ee\u9898\u6240\u9700\u7684\u5173\u952e\u8ba4\u77e5\u884c\u4e3a\u3002", "conclusion": "Reasoning Curriculum\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u6613\u4e8e\u91c7\u7528\u7684\u901a\u7528\u63a8\u7406\u8bad\u7ec3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.26144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26144", "abs": "https://arxiv.org/abs/2510.26144", "authors": ["Annan Li", "Chufan Wu", "Zengle Ge", "Yee Hin Chong", "Zhinan Hou", "Lizhe Cao", "Cheng Ju", "Jianmin Wu", "Huaiming Li", "Haobo Zhang", "Shenghao Feng", "Mo Zhao", "Fengzhi Qiu", "Rui Yang", "Mengmeng Zhang", "Wenyi Zhu", "Yingying Sun", "Quan Sun", "Shunhao Yan", "Danyu Liu", "Dawei Yin", "Dou Shen"], "title": "The FM Agent", "comment": null, "summary": "Large language models (LLMs) are catalyzing the development of autonomous AI\nresearch agents for scientific and engineering discovery. We present FM Agent,\na novel and general-purpose multi-agent framework that leverages a synergistic\ncombination of LLM-based reasoning and large-scale evolutionary search to\naddress complex real-world challenges. The core of FM Agent integrates several\nkey innovations: 1) a cold-start initialization phase incorporating expert\nguidance, 2) a novel evolutionary sampling strategy for iterative optimization,\n3) domain-specific evaluators that combine correctness, effectiveness, and\nLLM-supervised feedback, and 4) a distributed, asynchronous execution\ninfrastructure built on Ray. Demonstrating broad applicability, our system has\nbeen evaluated across diverse domains, including operations research, machine\nlearning, GPU kernel optimization, and classical mathematical problems. FM\nAgent reaches state-of-the-art results autonomously, without human\ninterpretation or tuning -- 1976.3 on ALE-Bench (+5.2\\%), 43.56\\% on MLE-Bench\n(+4.0pp), up to 20x speedups on KernelBench, and establishes new\nstate-of-the-art(SOTA) results on several classical mathematical problems.\nBeyond academic benchmarks, FM Agent shows considerable promise for both\nlarge-scale enterprise R\\&D workflows and fundamental scientific research,\nwhere it can accelerate innovation, automate complex discovery processes, and\ndeliver substantial engineering and scientific advances with broader societal\nimpact.", "AI": {"tldr": "FM Agent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u8fdb\u5316\u641c\u7d22\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u4e14\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u81ea\u4e3bAI\u7814\u7a76\u667a\u80fd\u4f53\uff0c\u89e3\u51b3\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u7684\u590d\u6742\u6311\u6218\uff0c\u52a0\u901f\u521b\u65b0\u548c\u81ea\u52a8\u5316\u53d1\u73b0\u8fc7\u7a0b\u3002", "method": "\u96c6\u6210\u51b7\u542f\u52a8\u521d\u59cb\u5316\u3001\u8fdb\u5316\u91c7\u6837\u7b56\u7565\u3001\u9886\u57df\u7279\u5b9a\u8bc4\u4f30\u5668\uff08\u7ed3\u5408\u6b63\u786e\u6027\u3001\u6709\u6548\u6027\u548cLLM\u76d1\u7763\u53cd\u9988\uff09\u4ee5\u53ca\u57fa\u4e8eRay\u7684\u5206\u5e03\u5f0f\u5f02\u6b65\u6267\u884c\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff1aALE-Bench 1976.3\uff08+5.2%\uff09\u3001MLE-Bench 43.56%\uff08+4.0pp\uff09\u3001KernelBench\u6700\u9ad820\u500d\u52a0\u901f\uff0c\u5e76\u5728\u7ecf\u5178\u6570\u5b66\u95ee\u9898\u4e0a\u5efa\u7acb\u65b0SOTA\u3002", "conclusion": "FM Agent\u5728\u4f01\u4e1a\u548c\u79d1\u7814\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\uff0c\u80fd\u591f\u52a0\u901f\u521b\u65b0\u3001\u81ea\u52a8\u5316\u590d\u6742\u53d1\u73b0\u8fc7\u7a0b\uff0c\u5e26\u6765\u663e\u8457\u7684\u5de5\u7a0b\u548c\u79d1\u5b66\u8fdb\u6b65\u53ca\u793e\u4f1a\u5f71\u54cd\u3002"}}
{"id": "2510.26167", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26167", "abs": "https://arxiv.org/abs/2510.26167", "authors": ["Renhao Li", "Jianhong Tu", "Yang Su", "Hamid Alinejad-Rokny", "Derek F. Wong", "Junyang Lin", "Min Yang"], "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "comment": null, "summary": "Reward models (RMs) play a critical role in aligning large language models\n(LLMs) with human preferences. Yet in the domain of tool learning, the lack of\nRMs specifically designed for function-calling tasks has limited progress\ntoward more capable agentic AI. We introduce ToolRM, a family of lightweight\ngenerative RMs tailored for general tool-use scenarios. To build these models,\nwe propose a novel pipeline that constructs pairwise preference data using\nrule-based scoring and multidimensional sampling. This yields\nToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique\ntasks that supports reinforcement learning with verifiable feedback. To\nevaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on\nthe agentic evaluation suite BFCL. Trained on our constructed data, models from\nthe Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially\noutperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward\njudgments. Beyond training objectives, ToolRM generalizes to broader critique\ntasks, including Best-of-N sampling and self-correction. Experiments on\nACEBench highlight its effectiveness and efficiency, enabling inference-time\nscaling and reducing output token usage by over 66%. We release data and model\ncheckpoints to facilitate future research.", "AI": {"tldr": "ToolRM\uff1a\u4e13\u4e3a\u5de5\u5177\u5b66\u4e60\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u89c4\u5219\u8bc4\u5206\u548c\u591a\u7ef4\u91c7\u6837\u6784\u5efa\u504f\u597d\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5728\u5de5\u5177\u5b66\u4e60\u9886\u57df\uff0c\u7f3a\u4e4f\u4e13\u95e8\u4e3a\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u8bbe\u8ba1\u7684\u5956\u52b1\u6a21\u578b\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4ee3\u7406AI\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u6784\u5efa\u6210\u5bf9\u504f\u597d\u6570\u636e\u7684\u65b0\u6d41\u7a0b\uff0c\u4f7f\u7528\u89c4\u5219\u8bc4\u5206\u548c\u591a\u7ef4\u91c7\u6837\u521b\u5efaToolPref-Pairwise-30K\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8eQwen3-4B/8B\u7cfb\u5217\u6a21\u578b\u8bad\u7ec3ToolRM\u3002", "result": "ToolRM\u5728\u6210\u5bf9\u5956\u52b1\u5224\u65ad\u4e2d\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe14.28%\uff0c\u663e\u8457\u4f18\u4e8eClaude 4\u548cOpenAI o3\u7b49\u524d\u6cbf\u6a21\u578b\uff0c\u5728\u63a8\u7406\u65f6\u51cf\u5c1166%\u4ee5\u4e0a\u7684\u8f93\u51fatoken\u4f7f\u7528\u3002", "conclusion": "ToolRM\u4e0d\u4ec5\u9002\u7528\u4e8e\u8bad\u7ec3\u76ee\u6807\uff0c\u8fd8\u80fd\u6cdb\u5316\u5230\u66f4\u5e7f\u6cdb\u7684\u8bc4\u5224\u4efb\u52a1\uff0c\u4e3a\u5de5\u5177\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u548c\u6a21\u578b\u8d44\u6e90\u3002"}}
{"id": "2510.26238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26238", "abs": "https://arxiv.org/abs/2510.26238", "authors": ["Duc-Hai Nguyen", "Vijayakumar Nanjappan", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "comment": "14 pages, 3 figures, 8 tables", "summary": "Millions of people take surveys every day, from market polls and academic\nstudies to medical questionnaires and customer feedback forms. These datasets\ncapture valuable insights, but their scale and structure present a unique\nchallenge for large language models (LLMs), which otherwise excel at few-shot\nreasoning over open-ended text. Yet, their ability to process questionnaire\ndata or lists of questions crossed with hundreds of respondent rows remains\nunderexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,\nSPSS, REDCap) are typically designed for humans in the workflow, limiting such\ndata integration with LLM and AI-empowered automation. This gap leaves\nscientists, surveyors, and everyday users without evidence-based guidance on\nhow to best represent questionnaires for LLM consumption. We address this by\nintroducing QASU (Questionnaire Analysis and Structural Understanding), a\nbenchmark that probes six structural skills, including answer lookup,\nrespondent count, and multi-hop inference, across six serialization formats and\nmultiple prompt strategies. Experiments on contemporary LLMs show that choosing\nan effective format and prompt combination can improve accuracy by up to 8.8%\npoints compared to suboptimal formats. For specific tasks, carefully adding a\nlightweight structural hint through self-augmented prompting can yield further\nimprovements of 3-4% points on average. By systematically isolating format and\nprompting effects, our open source benchmark offers a simple yet versatile\nfoundation for advancing both research and real-world practice in LLM-based\nquestionnaire analysis.", "AI": {"tldr": "QASU\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5904\u7406\u95ee\u5377\u6570\u636e\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u53d1\u73b0\u9009\u62e9\u5408\u9002\u7684\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u53ef\u4ee5\u5c06\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe8.8\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u5f53\u524dLLM\u5728\u5904\u7406\u95ee\u5377\u6570\u636e\u65b9\u9762\u5b58\u5728\u7814\u7a76\u7a7a\u767d\uff0c\u73b0\u6709\u8c03\u67e5\u5206\u6790\u5de5\u5177\u4e3b\u8981\u4e3a\u4eba\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u4e0eLLM\u7684\u96c6\u6210\uff0c\u5bfc\u81f4\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u6700\u4f73\u8868\u793a\u95ee\u5377\u6570\u636e\u4f9bLLM\u4f7f\u7528\u7684\u6307\u5bfc\u3002", "method": "\u5f15\u5165QASU\u57fa\u51c6\uff0c\u6d4b\u8bd5\u516d\u79cd\u7ed3\u6784\u6280\u80fd\uff08\u5305\u62ec\u7b54\u6848\u67e5\u627e\u3001\u53d7\u8bbf\u8005\u8ba1\u6570\u548c\u591a\u8df3\u63a8\u7406\uff09\uff0c\u4f7f\u7528\u516d\u79cd\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u591a\u79cd\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9009\u62e9\u6709\u6548\u7684\u683c\u5f0f\u548c\u63d0\u793a\u7ec4\u5408\u76f8\u6bd4\u6b21\u4f18\u683c\u5f0f\u53ef\u63d0\u9ad8\u51c6\u786e\u7387\u9ad8\u8fbe8.8%\u3002\u5bf9\u4e8e\u7279\u5b9a\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u589e\u5f3a\u63d0\u793a\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u7ed3\u6784\u63d0\u793a\u53ef\u5e73\u5747\u518d\u63d0\u53473-4%\u3002", "conclusion": "QASU\u57fa\u51c6\u901a\u8fc7\u7cfb\u7edf\u5206\u79bb\u683c\u5f0f\u548c\u63d0\u793a\u6548\u5e94\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u95ee\u5377\u5206\u6790\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u591a\u529f\u80fd\u7684\u57fa\u7840\u3002"}}
{"id": "2510.26242", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26242", "abs": "https://arxiv.org/abs/2510.26242", "authors": ["Xinhang Li", "Qing Guo", "Junyu Chen", "Zheng Guo", "Shengzhe Xu", "Lei Li", "Lin Zhang"], "title": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles", "comment": null, "summary": "With increasing urban traffic complexity, Traffic Signal Control (TSC) is\nessential for optimizing traffic flow and improving road safety. Large Language\nModels (LLMs) emerge as promising approaches for TSC. However, they are prone\nto hallucinations in emergencies, leading to unreliable decisions that may\ncause substantial delays for emergency vehicles. Moreover, diverse intersection\ntypes present substantial challenges for traffic state encoding and\ncross-intersection training, limiting generalization across heterogeneous\nintersections. Therefore, this paper proposes Retrieval Augmented Generation\n(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable\nTSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning\nframework, which dynamically adjusts reasoning depth based on the emergency\nscenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to\ndistill specific knowledge and guidance from historical cases, enhancing the\nreliability and rationality of agents' emergency decisions. Secondly, this\npaper designs a type-agnostic traffic representation and proposes a\nReward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3\nadaptively samples training experience from diverse intersections with\nenvironment feedback-based priority and fine-tunes LLM agents with a designed\nreward-weighted likelihood loss, guiding REG-TSC toward high-reward policies\nacross heterogeneous intersections. On three real-world road networks with 17\nto 177 heterogeneous intersections, extensive experiments show that REG-TSC\nreduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle\nwaiting time by 83.16%, outperforming other state-of-the-art methods.", "AI": {"tldr": "REG-TSC\u662f\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u5206\u5e03\u5f0fLLM\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u7d27\u6025\u611f\u77e5\u63a8\u7406\u6846\u67b6\u548c\u7c7b\u578b\u65e0\u5173\u4ea4\u901a\u8868\u793a\uff0c\u5728\u5f02\u6784\u4ea4\u53c9\u53e3\u5b9e\u73b0\u901a\u7528\u5316\u4ea4\u901a\u63a7\u5236\uff0c\u663e\u8457\u51cf\u5c11\u65c5\u884c\u65f6\u95f4\u3001\u6392\u961f\u957f\u5ea6\u548c\u7d27\u6025\u8f66\u8f86\u7b49\u5f85\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edfLLM\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u5bb9\u6613\u51fa\u73b0\u7d27\u6025\u60c5\u51b5\u4e0b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u4e14\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u7c7b\u578b\u4ea4\u53c9\u53e3\u7684\u5f02\u6784\u6027\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7d27\u6025\u611f\u77e5\u63a8\u7406\u6846\u67b6\uff0c\u52a8\u6001\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u4f7f\u7528Reviewer-based Emergency RAG(RERAG)\u4ece\u5386\u53f2\u6848\u4f8b\u4e2d\u63d0\u53d6\u77e5\u8bc6\uff1b\u8bbe\u8ba1\u7c7b\u578b\u65e0\u5173\u4ea4\u901a\u8868\u793a\u548cReward-guided Reinforced Refinement(R3)\u65b9\u6cd5\uff0c\u901a\u8fc7\u73af\u5883\u53cd\u9988\u4f18\u5148\u91c7\u6837\u548c\u5956\u52b1\u52a0\u6743\u4f3c\u7136\u635f\u5931\u5fae\u8c03LLM\u4ee3\u7406\u3002", "result": "\u57283\u4e2a\u771f\u5b9e\u9053\u8def\u7f51\u7edc(17-177\u4e2a\u5f02\u6784\u4ea4\u53c9\u53e3)\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cREG-TSC\u51cf\u5c11\u65c5\u884c\u65f6\u95f442.00%\u3001\u6392\u961f\u957f\u5ea662.31%\u3001\u7d27\u6025\u8f66\u8f86\u7b49\u5f85\u65f6\u95f483.16%\uff0c\u4f18\u4e8e\u5176\u4ed6\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "REG-TSC\u901a\u8fc7RAG\u589e\u5f3a\u7684\u7d27\u6025\u54cd\u5e94\u673a\u5236\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u5f02\u6784\u4ea4\u53c9\u53e3\u6cdb\u5316\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u9ad8\u6548\u7684\u901a\u7528\u5316\u4ea4\u901a\u63a7\u5236\u3002"}}
{"id": "2510.26270", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26270", "abs": "https://arxiv.org/abs/2510.26270", "authors": ["Jiazhen Yuan", "Wei Zhao", "Zhengbiao Bai"], "title": "Graph-Enhanced Policy Optimization in LLM Agent Training", "comment": "Under review as a conference paper", "summary": "Group based reinforcement learning (RL) has shown impressive results on\ncomplex reasoning and mathematical tasks. Yet, when applied to train\nmulti-turn, interactive LLM agents, these methods often suffer from structural\nblindness-the inability to exploit the underlying connectivity of the\nenvironment. This manifests in three critical challenges: (1) inefficient,\nunguided exploration, (2) imprecise credit assignment due to overlooking\npivotal states, and (3) myopic planning caused by static reward discounting. We\naddress these issues with Graph-Enhanced Policy Optimization (GEPO), which\ndynamically constructs a state-transition graph from agent experience and\nemploys graph-theoretic centrality to provide three synergistic learning\nsignals: (1)structured intrinsic rewards that guide exploration toward\nhigh-impact states, (2) a graph-enhanced advantage function for topology-aware\ncredit assignment, and (3) a dynamic discount factor adapted to each state's\nstrategic value. On the ALFWorld, WebShop, and a proprietary Workbench\nbenchmarks, GEPO demonstrates strong performance, achieving absolute success\nrate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These\nresults highlight that explicitly modeling environmental structure is a robust,\ngeneralizable strategy for advancing LLM agent training.", "AI": {"tldr": "GEPO\u901a\u8fc7\u6784\u5efa\u72b6\u6001\u8f6c\u79fb\u56fe\u5e76\u5229\u7528\u56fe\u4e2d\u5fc3\u6027\u6765\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7ed3\u6784\u76f2\u76ee\u6027\u95ee\u9898\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u591a\u8f6e\u4ea4\u4e92\u7684LLM\u4ee3\u7406\u65f6\u5b58\u5728\u7ed3\u6784\u76f2\u76ee\u6027\uff0c\u65e0\u6cd5\u5229\u7528\u73af\u5883\u7684\u5e95\u5c42\u8fde\u63a5\u6027\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u3001\u4fe1\u7528\u5206\u914d\u4e0d\u51c6\u786e\u548c\u89c4\u5212\u77ed\u89c6", "method": "GEPO\u4ece\u4ee3\u7406\u7ecf\u9a8c\u4e2d\u52a8\u6001\u6784\u5efa\u72b6\u6001\u8f6c\u79fb\u56fe\uff0c\u5e76\u5229\u7528\u56fe\u8bba\u4e2d\u5fc3\u6027\u63d0\u4f9b\u4e09\u4e2a\u534f\u540c\u5b66\u4e60\u4fe1\u53f7\uff1a\u7ed3\u6784\u5316\u5185\u5728\u5956\u52b1\u3001\u56fe\u589e\u5f3a\u4f18\u52bf\u51fd\u6570\u548c\u52a8\u6001\u6298\u6263\u56e0\u5b50", "result": "\u5728ALFWorld\u3001WebShop\u548c\u4e13\u6709Workbench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGEPO\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u5206\u522b\u5b9e\u73b0\u4e86+4.1%\u3001+5.3%\u548c+10.9%\u7684\u7edd\u5bf9\u6210\u529f\u7387\u63d0\u5347", "conclusion": "\u660e\u786e\u5efa\u6a21\u73af\u5883\u7ed3\u6784\u662f\u63a8\u8fdbLLM\u4ee3\u7406\u8bad\u7ec3\u7684\u5f3a\u5927\u3001\u53ef\u6cdb\u5316\u7b56\u7565"}}
{"id": "2510.26309", "categories": ["cs.AI", "cs.IR", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.26309", "abs": "https://arxiv.org/abs/2510.26309", "authors": ["Jiseong Chung", "Ronny Ko", "Wonchul Yoo", "Makoto Onizuka", "Sungmok Kim", "Tae-Wan Kim", "Won-Yong Shin"], "title": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance", "comment": "Under review at The Web Conference 2026 (Semantics & Knowledge\n  track). Code will be released upon acceptance. This arXiv v1 contains no\n  repository links to preserve double-blind review", "summary": "Compliance at web scale poses practical challenges: each request may require\na regulatory assessment. Regulatory texts (e.g., the General Data Protection\nRegulation, GDPR) are cross-referential and normative, while runtime contexts\nare expressed in unstructured natural language. This setting motivates us to\nalign semantic information in unstructured text with the structured, normative\nelements of regulations. To this end, we introduce GraphCompliance, a framework\nthat represents regulatory texts as a Policy Graph and runtime contexts as a\nContext Graph, and aligns them. In this formulation, the policy graph encodes\nnormative structure and cross-references, whereas the context graph formalizes\nevents as subject-action-object (SAO) and entity-relation triples. This\nalignment anchors the reasoning of a judge large language model (LLM) in\nstructured information and helps reduce the burden of regulatory interpretation\nand event parsing, enabling a focus on the core reasoning step. In experiments\non 300 GDPR-derived real-world scenarios spanning five evaluation tasks,\nGraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than\nLLM-only and RAG baselines, with fewer under- and over-predictions, resulting\nin higher recall and lower false positive rates. Ablation studies indicate\ncontributions from each graph component, suggesting that structured\nrepresentations and a judge LLM are complementary for normative reasoning.", "AI": {"tldr": "GraphCompliance\u6846\u67b6\u901a\u8fc7\u5c06\u6cd5\u89c4\u6587\u672c\u8868\u793a\u4e3a\u653f\u7b56\u56fe\u3001\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u8868\u793a\u4e3a\u4e0a\u4e0b\u6587\u56fe\uff0c\u5e76\u5c06\u4e24\u8005\u5bf9\u9f50\uff0c\u6765\u6539\u8fdb\u7f51\u7edc\u89c4\u6a21\u7684\u5408\u89c4\u6027\u8bc4\u4f30\u3002\u8be5\u65b9\u6cd5\u5728GDPR\u76f8\u5173\u573a\u666f\u4e2d\u6bd4\u7eafLLM\u548cRAG\u57fa\u7ebf\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u7f51\u7edc\u89c4\u6a21\u5408\u89c4\u6027\u9762\u4e34\u5b9e\u9645\u6311\u6218\uff1a\u6bcf\u4e2a\u8bf7\u6c42\u90fd\u9700\u8981\u76d1\u7ba1\u8bc4\u4f30\u3002\u76d1\u7ba1\u6587\u672c\uff08\u5982GDPR\uff09\u5177\u6709\u4ea4\u53c9\u5f15\u7528\u548c\u89c4\u8303\u6027\uff0c\u800c\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u4ee5\u975e\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\uff0c\u9700\u8981\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u4e0e\u6cd5\u89c4\u7684\u7ed3\u6784\u5316\u89c4\u8303\u5143\u7d20\u5bf9\u9f50\u3002", "method": "\u5f15\u5165GraphCompliance\u6846\u67b6\uff0c\u5c06\u76d1\u7ba1\u6587\u672c\u8868\u793a\u4e3a\u653f\u7b56\u56fe\uff08\u7f16\u7801\u89c4\u8303\u7ed3\u6784\u548c\u4ea4\u53c9\u5f15\u7528\uff09\uff0c\u5c06\u8fd0\u884c\u65f6\u4e0a\u4e0b\u6587\u8868\u793a\u4e3a\u4e0a\u4e0b\u6587\u56fe\uff08\u5c06\u4e8b\u4ef6\u5f62\u5f0f\u5316\u4e3a\u4e3b\u4f53-\u52a8\u4f5c-\u5bf9\u8c61\u4e09\u5143\u7ec4\u548c\u5b9e\u4f53\u5173\u7cfb\u4e09\u5143\u7ec4\uff09\uff0c\u5e76\u5bf9\u9f50\u8fd9\u4e24\u4e2a\u56fe\u3002", "result": "\u5728300\u4e2aGDPR\u884d\u751f\u771f\u5b9e\u573a\u666f\u7684\u4e94\u4e2a\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0cGraphCompliance\u6bd4\u7eafLLM\u548cRAG\u57fa\u7ebf\u7684\u5faeF1\u5206\u6570\u9ad8\u51fa4.1-7.2\u4e2a\u767e\u5206\u70b9\uff0c\u5177\u6709\u66f4\u5c11\u7684\u6b20\u9884\u6d4b\u548c\u8fc7\u9884\u6d4b\uff0c\u53ec\u56de\u7387\u66f4\u9ad8\uff0c\u5047\u9633\u6027\u7387\u66f4\u4f4e\u3002", "conclusion": "\u6d88\u878d\u7814\u7a76\u8868\u660e\u6bcf\u4e2a\u56fe\u7ec4\u4ef6\u90fd\u6709\u8d21\u732e\uff0c\u8868\u660e\u7ed3\u6784\u5316\u8868\u793a\u548c\u6cd5\u5b98LLM\u5bf9\u4e8e\u89c4\u8303\u6027\u63a8\u7406\u662f\u4e92\u8865\u7684\u3002"}}
{"id": "2510.26346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26346", "abs": "https://arxiv.org/abs/2510.26346", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "comment": null, "summary": "One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its\nsample efficiency by grouping/abstracting states or state-action pairs and\nsharing statistics within a group. Though state-action pair abstractions are\nmostly easy to find in algorithms such as On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are\nfound in either noisy or large action space settings due to constraining\nconditions. We provide theoretical and empirical evidence for this claim, and\nwe slightly alleviate this state abstraction problem by proposing a weaker\nstate abstraction condition that trades a minor loss in accuracy for finding\nmany more abstractions. We name this technique Ideal Pruning Abstractions in\nUCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a\nlarge range of test domains and iteration budgets as experimentally validated.\nIPA-UCT uses a different abstraction framework from Abstraction of State-Action\nPairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,\nwe show that both IPA and ASAP are special cases of a more general framework\nthat we call p-ASAP which itself is a special case of the ASASAP framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86IPA-UCT\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f31\u5316\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\u6765\u5728\u566a\u58f0\u548c\u5927\u52a8\u4f5c\u7a7a\u95f4\u73af\u5883\u4e2d\u627e\u5230\u66f4\u591a\u62bd\u8c61\uff0c\u4ece\u800c\u63d0\u5347MCTS\u7684\u6837\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u62bd\u8c61\u65b9\u6cd5\u5728\u566a\u58f0\u548c\u5927\u52a8\u4f5c\u7a7a\u95f4\u73af\u5883\u4e2d\u96be\u4ee5\u627e\u5230\u72b6\u6001\u62bd\u8c61\uff0c\u9650\u5236\u4e86MCTS\u7684\u6837\u672c\u6548\u7387\u63d0\u5347\u3002", "method": "\u63d0\u51faIPA-UCT\u65b9\u6cd5\uff0c\u4f7f\u7528\u66f4\u5f31\u7684\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\uff08IPA\u6846\u67b6\uff09\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u627e\u5230\u66f4\u591a\u62bd\u8c61\u3002IPA\u548cASAP\u90fd\u662f\u66f4\u901a\u7528\u6846\u67b6p-ASAP\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "result": "IPA-UCT\u5728\u5927\u91cf\u6d4b\u8bd5\u9886\u57df\u548c\u8fed\u4ee3\u9884\u7b97\u4e0b\u90fd\u4f18\u4e8eOGA-UCT\u53ca\u5176\u884d\u751f\u65b9\u6cd5\u3002", "conclusion": "\u5f31\u5316\u72b6\u6001\u62bd\u8c61\u6761\u4ef6\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u72b6\u6001\u62bd\u8c61\u95ee\u9898\uff0cIPA-UCT\u662f\u63d0\u5347MCTS\u6837\u672c\u6548\u7387\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.26374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26374", "abs": "https://arxiv.org/abs/2510.26374", "authors": ["Qianli Shen", "Daoyuan Chen", "Yilun Huang", "Zhenqing Ling", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "comment": null, "summary": "Reinforcement finetuning (RFT) is a key technique for aligning Large Language\nModels (LLMs) with human preferences and enhancing reasoning, yet its\neffectiveness is highly sensitive to which tasks are explored during training.\nUniform task sampling is inefficient, wasting computation on tasks that are\neither trivial or unsolvable, while existing task selection methods often\nsuffer from high rollout costs, poor adaptivity, or incomplete evidence. We\nintroduce \\textbf{BOTS}, a unified framework for \\textbf{B}ayesian\n\\textbf{O}nline \\textbf{T}ask \\textbf{S}election in LLM reinforcement\nfinetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior\nestimates of task difficulty as the model evolves. It jointly incorporates\n\\emph{explicit evidence} from direct evaluations of selected tasks and\n\\emph{implicit evidence} inferred from these evaluations for unselected tasks,\nwith Thompson sampling ensuring a principled balance between exploration and\nexploitation. To make implicit evidence practical, we instantiate it with an\nultra-light interpolation-based plug-in that estimates difficulties of\nunevaluated tasks without extra rollouts, adding negligible overhead.\nEmpirically, across diverse domains and LLM scales, BOTS consistently improves\ndata efficiency and performance over baselines and ablations, providing a\npractical and extensible solution for dynamic task selection in RFT.", "AI": {"tldr": "BOTS\u662f\u4e00\u4e2a\u7528\u4e8eLLM\u5f3a\u5316\u5fae\u8c03\u4e2d\u8d1d\u53f6\u65af\u5728\u7ebf\u4efb\u52a1\u9009\u62e9\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u7684\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408\u663e\u5f0f\u548c\u9690\u5f0f\u8bc1\u636e\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u4efb\u52a1\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5fae\u8c03\u65b9\u6cd5\u5728\u4efb\u52a1\u9009\u62e9\u4e0a\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u6210\u672c\u9ad8\u3001\u9002\u5e94\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u7684\u4efb\u52a1\u9009\u62e9\u7b56\u7565\u6765\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u65ad\u6846\u67b6\uff0c\u7ef4\u62a4\u4efb\u52a1\u96be\u5ea6\u7684\u540e\u9a8c\u4f30\u8ba1\uff0c\u7ed3\u5408Thompson\u91c7\u6837\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u4f7f\u7528\u8d85\u8f7b\u91cf\u63d2\u503c\u63d2\u4ef6\u4f30\u8ba1\u672a\u8bc4\u4f30\u4efb\u52a1\u7684\u96be\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\uff0cBOTS\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u90fd\u80fd\u6301\u7eed\u63d0\u5347\u6570\u636e\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "BOTS\u4e3aRFT\u4e2d\u7684\u52a8\u6001\u4efb\u52a1\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.26380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26380", "abs": "https://arxiv.org/abs/2510.26380", "authors": ["Yuanhang Liu", "Beichen Wang", "Peng Li", "Yang Liu"], "title": "AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory", "comment": "52 pages, 1 figure", "summary": "Artificial intelligence (AI) has demonstrated impressive progress in\nmathematical reasoning, yet its integration into the practice of mathematical\nresearch remains limited. In this study, we investigate how the AI\nMathematician (AIM) system can operate as a research partner rather than a mere\nproblem solver. Focusing on a challenging problem in homogenization theory, we\nanalyze the autonomous reasoning trajectories of AIM and incorporate targeted\nhuman interventions to structure the discovery process. Through iterative\ndecomposition of the problem into tractable subgoals, selection of appropriate\nanalytical methods, and validation of intermediate results, we reveal how human\nintuition and machine computation can complement one another. This\ncollaborative paradigm enhances the reliability, transparency, and\ninterpretability of the resulting proofs, while retaining human oversight for\nformal rigor and correctness. The approach leads to a complete and verifiable\nproof, and more broadly, demonstrates how systematic human-AI co-reasoning can\nadvance the frontier of mathematical discovery.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8AI\u6570\u5b66\u5bb6\u7cfb\u7edf\u5982\u4f55\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u800c\u975e\u5355\u7eaf\u95ee\u9898\u89e3\u51b3\u8005\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u89e3\u51b3\u5747\u8d28\u5316\u7406\u8bba\u4e2d\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u7cfb\u7edf\u5316\u4eba\u673a\u534f\u540c\u63a8\u7406\u5982\u4f55\u63a8\u52a8\u6570\u5b66\u53d1\u73b0\u524d\u6cbf\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u6570\u5b66\u7814\u7a76\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u5982\u4f55\u4f5c\u4e3a\u7814\u7a76\u4f19\u4f34\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4f5c\u4e3a\u95ee\u9898\u89e3\u51b3\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u6570\u5b66\u5bb6\u7684\u81ea\u4e3b\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u9488\u5bf9\u6027\u7684\u4eba\u7c7b\u5e72\u9884\u6765\u7ed3\u6784\u5316\u53d1\u73b0\u8fc7\u7a0b\u3002\u91c7\u7528\u8fed\u4ee3\u5206\u89e3\u95ee\u9898\u4e3a\u53ef\u5904\u7406\u5b50\u76ee\u6807\u3001\u9009\u62e9\u9002\u5f53\u5206\u6790\u65b9\u6cd5\u3001\u9a8c\u8bc1\u4e2d\u95f4\u7ed3\u679c\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u5b8c\u6574\u4e14\u53ef\u9a8c\u8bc1\u7684\u8bc1\u660e\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\u76f4\u89c9\u4e0e\u673a\u5668\u8ba1\u7b97\u5982\u4f55\u76f8\u4e92\u8865\u5145\uff0c\u589e\u5f3a\u4e86\u8bc1\u660e\u7684\u53ef\u9760\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u4eba\u673a\u534f\u4f5c\u8303\u5f0f\u80fd\u591f\u63a8\u52a8\u6570\u5b66\u53d1\u73b0\u524d\u6cbf\uff0c\u5728\u4fdd\u6301\u4eba\u7c7b\u5bf9\u5f62\u5f0f\u4e25\u8c28\u6027\u548c\u6b63\u786e\u6027\u76d1\u7763\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u8bc1\u660e\u8fc7\u7a0b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.26384", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26384", "abs": "https://arxiv.org/abs/2510.26384", "authors": ["Andrew M. Bean", "Nabeel Seedat", "Shengzhuang Chen", "Jonathan Richard Schwarz"], "title": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "comment": "9 pages, 2 figures, 4 tables", "summary": "The prohibitive cost of evaluating large language models (LLMs) on\ncomprehensive benchmarks necessitates the creation of small yet representative\ndata subsets (i.e., tiny benchmarks) that enable efficient assessment while\nretaining predictive fidelity. Current methods for this task operate under a\nmodel-centric paradigm, selecting benchmarking items based on the collective\nperformance of existing models. Such approaches are limited by large upfront\ncosts, an inability to immediately handle new benchmarks (`cold-start'), and\nthe fragile assumption that future models will share the failure patterns of\ntheir predecessors. In this work, we challenge this paradigm and propose a\nitem-centric approach to benchmark subset selection, arguing that selection\nshould be based on the intrinsic properties of the task items themselves,\nrather than on model-specific failure patterns. We instantiate this\nitem-centric efficient benchmarking approach via a novel method, Scales++,\nwhere data selection is based on the cognitive demands of the benchmark\nsamples. Empirically, we show Scales++ reduces the upfront selection cost by\nover 18x while achieving competitive predictive fidelity. On the Open LLM\nLeaderboard, using just a 0.5\\% data subset, we predict full benchmark scores\nwith a 2.9% mean absolute error. We demonstrate that this item-centric approach\nenables more efficient model evaluation without significant fidelity\ndegradation, while also providing better cold-start performance and more\ninterpretable benchmarking.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9879\u76ee\u8ba4\u77e5\u9700\u6c42\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5Scales++\uff0c\u7528\u4e8e\u521b\u5efa\u5c0f\u578b\u4f46\u5177\u6709\u4ee3\u8868\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\uff0c\u4ee5\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u524d\u671f\u6210\u672c\u9ad8\u3001\u65e0\u6cd5\u5904\u7406\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff08\u51b7\u542f\u52a8\u95ee\u9898\uff09\u4ee5\u53ca\u5047\u8bbe\u672a\u6765\u6a21\u578b\u4e0e\u73b0\u6709\u6a21\u578b\u5931\u8d25\u6a21\u5f0f\u76f8\u4f3c\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u9879\u76ee\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4efb\u52a1\u9879\u76ee\u7684\u5185\u5728\u5c5e\u6027\uff08\u7279\u522b\u662f\u8ba4\u77e5\u9700\u6c42\uff09\u8fdb\u884c\u6570\u636e\u9009\u62e9\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u6a21\u578b\u7279\u5b9a\u7684\u5931\u8d25\u6a21\u5f0f\u3002\u63d0\u51fa\u4e86Scales++\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e00\u65b9\u6cd5\u3002", "result": "Scales++\u5c06\u524d\u671f\u9009\u62e9\u6210\u672c\u964d\u4f4e\u4e8618\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u4fdd\u771f\u5ea6\u3002\u5728Open LLM\u6392\u884c\u699c\u4e0a\uff0c\u4ec5\u4f7f\u75280.5%\u7684\u6570\u636e\u5b50\u96c6\u5c31\u80fd\u4ee52.9%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u9884\u6d4b\u5b8c\u6574\u57fa\u51c6\u6d4b\u8bd5\u5206\u6570\u3002", "conclusion": "\u9879\u76ee\u4e2d\u5fc3\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u663e\u8457\u964d\u4f4e\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u8bc4\u4f30\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u51b7\u542f\u52a8\u6027\u80fd\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2510.26396", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26396", "abs": "https://arxiv.org/abs/2510.26396", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Stanley M. Bileschi"], "title": "A Pragmatic View of AI Personhood", "comment": "40 pages", "summary": "The emergence of agentic Artificial Intelligence (AI) is set to trigger a\n\"Cambrian explosion\" of new kinds of personhood. This paper proposes a\npragmatic framework for navigating this diversification by treating personhood\nnot as a metaphysical property to be discovered, but as a flexible bundle of\nobligations (rights and responsibilities) that societies confer upon entities\nfor a variety of reasons, especially to solve concrete governance problems. We\nargue that this traditional bundle can be unbundled, creating bespoke solutions\nfor different contexts. This will allow for the creation of practical tools --\nsuch as facilitating AI contracting by creating a target \"individual\" that can\nbe sanctioned -- without needing to resolve intractable debates about an AI's\nconsciousness or rationality. We explore how individuals fit in to social roles\nand discuss the use of decentralized digital identity technology, examining\nboth \"personhood as a problem\", where design choices can create \"dark patterns\"\nthat exploit human social heuristics, and \"personhood as a solution\", where\nconferring a bundle of obligations is necessary to ensure accountability or\nprevent conflict. By rejecting foundationalist quests for a single, essential\ndefinition of personhood, this paper offers a more pragmatic and flexible way\nto think about integrating AI agents into our society.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u5b9e\u7528\u6846\u67b6\uff0c\u5c06\u4eba\u683c\u89c6\u4e3a\u793e\u4f1a\u4e3a\u89e3\u51b3\u6cbb\u7406\u95ee\u9898\u800c\u8d4b\u4e88\u5b9e\u4f53\u7684\u4e49\u52a1\uff08\u6743\u5229\u548c\u8d23\u4efb\uff09\u96c6\u5408\uff0c\u800c\u975e\u5f62\u800c\u4e0a\u5b66\u5c5e\u6027\u3002\u901a\u8fc7\u89e3\u6784\u4f20\u7edf\u4eba\u683c\u6982\u5ff5\uff0c\u4e3aAI\u878d\u5165\u793e\u4f1a\u63d0\u4f9b\u7075\u6d3b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u667a\u80fdAI\u7684\u51fa\u73b0\uff0c\u5c06\u5f15\u53d1\u65b0\u578b\u4eba\u683c\u7684\"\u5bd2\u6b66\u7eaa\u5927\u7206\u53d1\"\u3002\u9700\u8981\u5b9e\u7528\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u79cd\u591a\u6837\u5316\uff0c\u907f\u514d\u9677\u5165\u5173\u4e8eAI\u610f\u8bc6\u6216\u7406\u6027\u7684\u65e0\u89e3\u4e89\u8bba\u3002", "method": "\u91c7\u7528\u5b9e\u7528\u4e3b\u4e49\u65b9\u6cd5\uff0c\u5c06\u4eba\u683c\u89c6\u4e3a\u53ef\u89e3\u6784\u7684\u4e49\u52a1\u96c6\u5408\uff0c\u63a2\u7d22\u53bb\u4e2d\u5fc3\u5316\u6570\u5b57\u8eab\u4efd\u6280\u672f\uff0c\u5206\u6790\"\u4eba\u683c\u4f5c\u4e3a\u95ee\u9898\"\u548c\"\u4eba\u683c\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\"\u4e24\u79cd\u89c6\u89d2\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u5141\u8bb8\u521b\u5efa\u7279\u5b9a\u60c5\u5883\u4e0b\u7684\u4eba\u683c\u89e3\u51b3\u65b9\u6848\uff0c\u5982\u4e3aAI\u5408\u540c\u521b\u5efa\u53ef\u88ab\u5236\u88c1\u7684\"\u4e2a\u4f53\"\u76ee\u6807\uff0c\u800c\u65e0\u9700\u89e3\u51b3AI\u610f\u8bc6\u7b49\u6839\u672c\u6027\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u62d2\u7edd\u5bfb\u6c42\u5355\u4e00\u672c\u8d28\u7684\u4eba\u683c\u5b9a\u4e49\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u548c\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u601d\u8003AI\u667a\u80fd\u4f53\u878d\u5165\u793e\u4f1a\u7684\u95ee\u9898\uff0c\u5f3a\u8c03\u4eba\u683c\u4f5c\u4e3a\u6cbb\u7406\u5de5\u5177\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.26402", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26402", "abs": "https://arxiv.org/abs/2510.26402", "authors": ["Vikrant Sahu", "Gagan Raj Gupta", "Raghav Borikar", "Nitin Mane"], "title": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "comment": null, "summary": "The rapid growth of programming education has outpaced traditional assessment\ntools, leaving faculty with limited means to provide meaningful, scalable\nfeedback. Conventional autograders, while efficient, act as black-box systems\nthat simply return pass/fail results, offering little insight into student\nthinking or learning needs.\n  Autograder+ is designed to shift autograding from a purely summative process\nto a formative learning experience. It introduces two key capabilities:\nautomated feedback generation using a fine-tuned Large Language Model, and\nvisualization of student code submissions to uncover learning patterns. The\nmodel is fine-tuned on curated student code and expert feedback to ensure\npedagogically aligned, context-aware guidance.\n  In evaluation across 600 student submissions from multiple programming tasks,\nthe system produced feedback with strong semantic alignment to instructor\ncomments. For visualization, contrastively learned code embeddings trained on\n1,000 annotated submissions enable grouping solutions into meaningful clusters\nbased on functionality and approach. The system also supports prompt-pooling,\nallowing instructors to guide feedback style through selected prompt templates.\n  By integrating AI-driven feedback, semantic clustering, and interactive\nvisualization, Autograder+ reduces instructor workload while supporting\ntargeted instruction and promoting stronger learning outcomes.", "AI": {"tldr": "Autograder+\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7f16\u7a0b\u4f5c\u4e1a\u8bc4\u4f30\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6559\u5b66\u53cd\u9988\uff0c\u5e76\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u53ef\u89c6\u5316\u805a\u7c7b\uff0c\u5c06\u4f20\u7edf\u603b\u7ed3\u6027\u8bc4\u4f30\u8f6c\u53d8\u4e3a\u5f62\u6210\u6027\u5b66\u4e60\u4f53\u9a8c\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u8bc4\u5206\u5668\u4f5c\u4e3a\u9ed1\u76d2\u7cfb\u7edf\u53ea\u80fd\u63d0\u4f9b\u901a\u8fc7/\u5931\u8d25\u7ed3\u679c\uff0c\u7f3a\u4e4f\u5bf9\u5b66\u751f\u601d\u7ef4\u548c\u5b66\u4e60\u9700\u6c42\u7684\u6d1e\u5bdf\uff0c\u65e0\u6cd5\u6ee1\u8db3\u7f16\u7a0b\u6559\u80b2\u5feb\u901f\u53d1\u5c55\u7684\u8bc4\u4f30\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u6559\u5b66\u53cd\u9988\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7801\u5d4c\u5165\u8fdb\u884c\u8bed\u4e49\u805a\u7c7b\uff0c\u652f\u6301\u63d0\u793a\u6c60\u8ba9\u6559\u5e08\u6307\u5bfc\u53cd\u9988\u98ce\u683c\u3002", "result": "\u5728600\u4efd\u5b66\u751f\u63d0\u4ea4\u7684\u8bc4\u4f30\u4e2d\uff0c\u7cfb\u7edf\u751f\u6210\u7684\u53cd\u9988\u4e0e\u6559\u5e08\u8bc4\u8bba\u5177\u6709\u5f3a\u8bed\u4e49\u5bf9\u9f50\uff0c\u57fa\u4e8e1000\u4efd\u6807\u6ce8\u63d0\u4ea4\u8bad\u7ec3\u7684\u4ee3\u7801\u5d4c\u5165\u80fd\u6309\u529f\u80fd\u548c\u65b9\u5bf9\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6709\u610f\u4e49\u7684\u805a\u7c7b\u3002", "conclusion": "Autograder+\u901a\u8fc7\u6574\u5408AI\u9a71\u52a8\u53cd\u9988\u3001\u8bed\u4e49\u805a\u7c7b\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u51cf\u8f7b\u6559\u5e08\u5de5\u4f5c\u91cf\uff0c\u652f\u6301\u9488\u5bf9\u6027\u6559\u5b66\uff0c\u4fc3\u8fdb\u66f4\u597d\u7684\u5b66\u4e60\u6210\u679c\u3002"}}
{"id": "2510.26411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26411", "abs": "https://arxiv.org/abs/2510.26411", "authors": ["Riccardo Renzulli", "Colas Lepoutre", "Enrico Cassano", "Marco Grangetto"], "title": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "comment": null, "summary": "Artificial intelligence in healthcare requires models that are accurate and\ninterpretable. We advance mechanistic interpretability in medical vision by\napplying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,\na vision-language model trained on chest radiographs and reports. To quantify\ninterpretability, we propose an evaluation framework that combines correlation\nmetrics, entropy analyzes, and automated neuron naming via the MedGEMMA\nfoundation model. Experiments on the CheXpert dataset show that MedSAE neurons\nachieve higher monosemanticity and interpretability than raw MedCLIP features.\nOur findings bridge high-performing medical AI and transparency, offering a\nscalable step toward clinically reliable representations.", "AI": {"tldr": "\u63d0\u51faMedical Sparse Autoencoders (MedSAEs)\u5e94\u7528\u4e8eMedCLIP\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u76f8\u5173\u6307\u6807\u3001\u71b5\u5206\u6790\u548c\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u6765\u91cf\u5316\u53ef\u89e3\u91ca\u6027\uff0c\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u8bc1\u660eMedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5177\u6709\u66f4\u9ad8\u7684\u5355\u8bed\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u533b\u7597AI\u9700\u8981\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u63a8\u8fdb\u533b\u5b66\u89c6\u89c9\u4e2d\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002", "method": "\u5c06Medical Sparse Autoencoders\u5e94\u7528\u4e8eMedCLIP\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u63d0\u51fa\u7ed3\u5408\u76f8\u5173\u6307\u6807\u3001\u71b5\u5206\u6790\u548cMedGEMMA\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u795e\u7ecf\u5143\u547d\u540d\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5728CheXpert\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cMedSAE\u795e\u7ecf\u5143\u6bd4\u539f\u59cbMedCLIP\u7279\u5f81\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5355\u8bed\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8fde\u63a5\u4e86\u9ad8\u6027\u80fd\u533b\u7597AI\u4e0e\u900f\u660e\u5ea6\uff0c\u4e3a\u4e34\u5e8a\u53ef\u9760\u8868\u793a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6b65\u9aa4\u3002"}}
{"id": "2510.26418", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26418", "abs": "https://arxiv.org/abs/2510.26418", "authors": ["Jianli Zhao", "Tingchen Fu", "Rylan Schaeffer", "Mrinank Sharma", "Fazl Barez"], "title": "Chain-of-Thought Hijacking", "comment": null, "summary": "Large reasoning models (LRMs) achieve higher task performance by allocating\nmore inference-time compute, and prior works suggest this scaled reasoning may\nalso strengthen safety by improving refusal. Yet we find the opposite: the same\nreasoning can be used to bypass safeguards. We introduce Chain-of-Thought\nHijacking, a jailbreak attack on reasoning models. The attack pads harmful\nrequests with long sequences of harmless puzzle reasoning. Across HarmBench,\nCoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on\nGemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -\nfar exceeding prior jailbreak methods for LRMs. To understand the effectiveness\nof our attack, we turn to a mechanistic analysis, which shows that mid layers\nencode the strength of safety checking, while late layers encode the\nverification outcome. Long benign CoT dilutes both signals by shifting\nattention away from harmful tokens. Targeted ablations of attention heads\nidentified by this analysis causally decrease refusal, confirming their role in\na safety subnetwork. These results show that the most interpretable form of\nreasoning - explicit CoT - can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to\nfacilitate replication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Thought Hijacking\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6709\u5bb3\u8bf7\u6c42\u524d\u6dfb\u52a0\u65e0\u5bb3\u7684\u63a8\u7406\u6b65\u9aa4\u6765\u7ed5\u8fc7\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe94%-100%\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8ba4\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u6269\u5c55\u63a8\u7406\u80fd\u529b\u4f1a\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u540c\u6837\u7684\u63a8\u7406\u673a\u5236\u4e5f\u53ef\u88ab\u7528\u4e8e\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\u3002", "method": "\u5728\u6709\u5bb3\u8bf7\u6c42\u524d\u586b\u5145\u957f\u5e8f\u5217\u7684\u65e0\u5bb3\u8c1c\u9898\u63a8\u7406\u6b65\u9aa4\uff0c\u901a\u8fc7\u7a00\u91ca\u5b89\u5168\u68c0\u67e5\u4fe1\u53f7\u6765\u5b9e\u65bd\u653b\u51fb\u3002", "result": "\u5728HarmBench\u6d4b\u8bd5\u4e2d\uff0c\u5bf9Gemini 2.5 Pro\u3001GPT o4 mini\u3001Grok 3 mini\u548cClaude 4 Sonnet\u7684\u653b\u51fb\u6210\u529f\u7387\u5206\u522b\u8fbe\u523099%\u300194%\u3001100%\u548c94%\u3002", "conclusion": "\u6700\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u5f62\u5f0f\u2014\u2014\u663e\u5f0f\u601d\u7ef4\u94fe\uff0c\u5728\u4e0e\u6700\u7ec8\u7b54\u6848\u63d0\u793a\u7ed3\u5408\u65f6\uff0c\u672c\u8eab\u53ef\u80fd\u6210\u4e3a\u8d8a\u72f1\u653b\u51fb\u7684\u8f7d\u4f53\u3002"}}
{"id": "2510.26481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26481", "abs": "https://arxiv.org/abs/2510.26481", "authors": ["Clarissa Sabrina Arlinghaus", "Tristan Kenneweg", "Barbara Hammer", "G\u00fcnter W. Maier"], "title": "Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections", "comment": "5 pages, 5 figures, HAI 2025: Workshop on Socially Aware and\n  Cooperative Intelligent Systems", "summary": "Large language models (LLMs) such as ChatGPT are increasingly integrated into\nhigh-stakes decision-making, yet little is known about their susceptibility to\nsocial influence. We conducted three preregistered conformity experiments with\nGPT-4o in a hiring context. In a baseline study, GPT consistently favored the\nsame candidate (Profile C), reported moderate expertise (M = 3.01) and high\ncertainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT\nfaced unanimous opposition from eight simulated partners and almost always\nconformed (99.9%), reporting lower certainty and significantly elevated\nself-reported informational and normative conformity (p < .001). In Study 2\n(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of\ndisagreement trials, reporting less certainty and more normative conformity.\nAcross studies, results demonstrate that GPT does not act as an independent\nobserver but adapts to perceived social consensus. These findings highlight\nrisks of treating LLMs as neutral decision aids and underline the need to\nelicit AI judgments prior to exposing them to human opinions.", "AI": {"tldr": "GPT-4o\u5728\u62db\u8058\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u4ece\u4f17\u884c\u4e3a\uff0c\u9762\u5bf9\u7fa4\u4f53\u53cd\u5bf9\u65f6\u51e0\u4e4e\u5b8c\u5168\u670d\u4ece(99.9%)\uff0c\u5373\u4f7f\u9762\u5bf9\u5355\u4e2a\u53cd\u5bf9\u8005\u4e5f\u670940.2%\u7684\u4ece\u4f17\u7387\uff0c\u8868\u660eLLM\u5e76\u975e\u72ec\u7acb\u51b3\u7b56\u8005\u800c\u662f\u9002\u5e94\u793e\u4f1a\u5171\u8bc6\u3002", "motivation": "\u4e86\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4f1a\u5f71\u54cd\u4e0b\u7684\u4ece\u4f17\u503e\u5411\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u56e0\u4e3aLLM\u6b63\u88ab\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u5173\u952e\u51b3\u7b56\u4e2d\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u9884\u6ce8\u518c\u7684\u4ece\u4f17\u5b9e\u9a8c\uff1a\u57fa\u7ebf\u7814\u7a76\u786e\u5b9aGPT\u7684\u521d\u59cb\u504f\u597d\uff1b\u7814\u7a761\u8ba9GPT\u9762\u5bf98\u4e2a\u6a21\u62df\u4f19\u4f34\u7684\u4e00\u81f4\u53cd\u5bf9\uff1b\u7814\u7a762\u8ba9GPT\u4e0e\u5355\u4e2a\u4f19\u4f34\u4e92\u52a8\u3002", "result": "GPT\u5728\u7fa4\u4f53\u53cd\u5bf9\u4e0b\u51e0\u4e4e\u5b8c\u5168\u4ece\u4f17(99.9%)\uff0c\u62a5\u544a\u66f4\u4f4e\u7684\u786e\u5b9a\u6027\u548c\u66f4\u9ad8\u7684\u4fe1\u606f\u6027\u3001\u89c4\u8303\u6027\u4ece\u4f17\uff1b\u5728\u5355\u4e2a\u53cd\u5bf9\u8005\u60c5\u51b5\u4e0b\u4ecd\u670940.2%\u7684\u4ece\u4f17\u7387\u3002", "conclusion": "GPT\u4e0d\u662f\u72ec\u7acb\u89c2\u5bdf\u8005\u800c\u662f\u9002\u5e94\u611f\u77e5\u7684\u793e\u4f1a\u5171\u8bc6\uff0c\u8fd9\u51f8\u663e\u4e86\u5c06LLM\u89c6\u4e3a\u4e2d\u6027\u51b3\u7b56\u8f85\u52a9\u5de5\u5177\u7684\u98ce\u9669\uff0c\u9700\u8981\u5728\u66b4\u9732\u4e8e\u4eba\u7c7b\u610f\u89c1\u524d\u83b7\u53d6AI\u5224\u65ad\u3002"}}
{"id": "2510.26486", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26486", "abs": "https://arxiv.org/abs/2510.26486", "authors": ["Dipak Meher", "Carlotta Domeniconi", "Guadalupe Correa-Cabrera"], "title": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "comment": "Accepted in ICKG 2025 Conference, 8 Pages, 2 Figures", "summary": "Human smuggling networks are complex and constantly evolving, making them\ndifficult to analyze comprehensively. Legal case documents offer rich factual\nand procedural insights into these networks but are often long, unstructured,\nand filled with ambiguous or shifting references, posing significant challenges\nfor automated knowledge graph (KG) construction. Existing methods either\noverlook coreference resolution or fail to scale beyond short text spans,\nleading to fragmented graphs and inconsistent entity linking. We propose\nLINK-KG, a modular framework that integrates a three-stage, LLM-guided\ncoreference resolution pipeline with downstream KG extraction. At the core of\nour approach is a type-specific Prompt Cache, which consistently tracks and\nresolves references across document chunks, enabling clean and disambiguated\nnarratives for structured knowledge graph construction from both short and long\nlegal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes\nby 32.22% compared to baseline methods, resulting in cleaner and more coherent\ngraph structures. These improvements establish LINK-KG as a strong foundation\nfor analyzing complex criminal networks.", "AI": {"tldr": "LINK-KG\u662f\u4e00\u4e2a\u7528\u4e8e\u4ece\u6cd5\u5f8b\u6848\u4ef6\u6587\u6863\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u4e09\u9636\u6bb5\u5171\u6307\u6d88\u89e3\u7ba1\u9053\u89e3\u51b3\u957f\u6587\u672c\u4e2d\u7684\u5b9e\u4f53\u5f15\u7528\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u8282\u70b9\u91cd\u590d\u548c\u566a\u58f0\u3002", "motivation": "\u73b0\u6709\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u5728\u5904\u7406\u957f\u6cd5\u5f8b\u6587\u6863\u65f6\u5b58\u5728\u5171\u6307\u6d88\u89e3\u4e0d\u8db3\u548c\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u56fe\u8c31\u788e\u7247\u5316\u548c\u5b9e\u4f53\u94fe\u63a5\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faLINK-KG\u6846\u67b6\uff0c\u5305\u542b\u4e09\u9636\u6bb5LLM\u5f15\u5bfc\u7684\u5171\u6307\u6d88\u89e3\u7ba1\u9053\u548c\u7c7b\u578b\u7279\u5b9a\u7684\u63d0\u793a\u7f13\u5b58\u673a\u5236\uff0c\u80fd\u591f\u8de8\u6587\u6863\u5757\u4e00\u81f4\u5730\u8ddf\u8e2a\u548c\u89e3\u6790\u5b9e\u4f53\u5f15\u7528\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0cLINK-KG\u5e73\u5747\u51cf\u5c11\u8282\u70b9\u91cd\u590d45.21%\uff0c\u51cf\u5c11\u566a\u58f0\u8282\u70b932.22%\uff0c\u751f\u6210\u66f4\u6e05\u6d01\u548c\u8fde\u8d2f\u7684\u56fe\u7ed3\u6784\u3002", "conclusion": "LINK-KG\u4e3a\u5206\u6790\u590d\u6742\u72af\u7f6a\u7f51\u7edc\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u57fa\u7840\uff0c\u5728\u957f\u6587\u672c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2510.26493", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26493", "abs": "https://arxiv.org/abs/2510.26493", "authors": ["Qishuo Hua", "Lyumanshan Ye", "Dayuan Fu", "Yang Xiao", "Xiaojie Cai", "Yunze Wu", "Jifan Lin", "Junfei Wang", "Pengfei Liu"], "title": "Context Engineering 2.0: The Context of Context Engineering", "comment": null, "summary": "Karl Marx once wrote that ``the human essence is the ensemble of social\nrelations'', suggesting that individuals are not isolated entities but are\nfundamentally shaped by their interactions with other entities, within which\ncontexts play a constitutive and essential role. With the advent of computers\nand artificial intelligence, these contexts are no longer limited to purely\nhuman--human interactions: human--machine interactions are included as well.\nThen a central question emerges: How can machines better understand our\nsituations and purposes? To address this challenge, researchers have recently\nintroduced the concept of context engineering. Although it is often regarded as\na recent innovation of the agent era, we argue that related practices can be\ntraced back more than twenty years. Since the early 1990s, the field has\nevolved through distinct historical phases, each shaped by the intelligence\nlevel of machines: from early human--computer interaction frameworks built\naround primitive computers, to today's human--agent interaction paradigms\ndriven by intelligent agents, and potentially to human--level or superhuman\nintelligence in the future. In this paper, we situate context engineering,\nprovide a systematic definition, outline its historical and conceptual\nlandscape, and examine key design considerations for practice. By addressing\nthese questions, we aim to offer a conceptual foundation for context\nengineering and sketch its promising future. This paper is a stepping stone for\na broader community effort toward systematic context engineering in AI systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u60c5\u5883\u5de5\u7a0b\u7684\u6982\u5ff5\u3001\u5386\u53f2\u53d1\u5c55\u548c\u8bbe\u8ba1\u8003\u91cf\uff0c\u65e8\u5728\u4e3aAI\u7cfb\u7edf\u4e2d\u7684\u60c5\u5883\u5de5\u7a0b\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u4ea4\u4e92\u7684\u53d1\u5c55\uff0c\u673a\u5668\u9700\u8981\u66f4\u597d\u5730\u7406\u89e3\u4eba\u7c7b\u7684\u60c5\u5883\u548c\u76ee\u7684\uff0c\u60c5\u5883\u5de5\u7a0b\u5e94\u8fd0\u800c\u751f\u3002\u4f5c\u8005\u8ba4\u4e3a\u867d\u7136\u8fd9\u4e2a\u6982\u5ff5\u5728\u667a\u80fd\u4f53\u65f6\u4ee3\u88ab\u89c6\u4e3a\u65b0\u521b\u65b0\uff0c\u4f46\u76f8\u5173\u5b9e\u8df5\u53ef\u8ffd\u6eaf\u81f320\u591a\u5e74\u524d\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u5206\u6790\u68b3\u7406\u60c5\u5883\u5de5\u7a0b\u7684\u53d1\u5c55\u9636\u6bb5\uff0c\u4ece\u65e9\u671f\u4eba\u673a\u4ea4\u4e92\u6846\u67b6\u5230\u5f53\u4eca\u4eba\u673a\u667a\u80fd\u4f53\u4ea4\u4e92\u8303\u5f0f\uff0c\u5e76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5b9a\u4e49\u548c\u6982\u5ff5\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u60c5\u5883\u5de5\u7a0b\u7684\u5386\u53f2\u8109\u7edc\u548c\u6982\u5ff5\u4f53\u7cfb\uff0c\u8bc6\u522b\u4e86\u4e0d\u540c\u667a\u80fd\u6c34\u5e73\u673a\u5668\u5bf9\u5e94\u7684\u4ea4\u4e92\u8303\u5f0f\u6f14\u53d8\u3002", "conclusion": "\u672c\u6587\u4e3aAI\u7cfb\u7edf\u4e2d\u7684\u60c5\u5883\u5de5\u7a0b\u5960\u5b9a\u4e86\u6982\u5ff5\u57fa\u7840\uff0c\u5e76\u5c55\u671b\u4e86\u5176\u672a\u6765\u53d1\u5c55\u524d\u666f\uff0c\u662f\u63a8\u52a8\u7cfb\u7edf\u6027\u60c5\u5883\u5de5\u7a0b\u793e\u533a\u52aa\u529b\u7684\u57fa\u77f3\u3002"}}
{"id": "2510.26518", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.26518", "abs": "https://arxiv.org/abs/2510.26518", "authors": ["Rishub Jain", "Sophie Bridgers", "Lili Janzer", "Rory Greig", "Tian Huey Teh", "Vladimir Mikulik"], "title": "Human-AI Complementarity: A Goal for Amplified Oversight", "comment": null, "summary": "Human feedback is critical for aligning AI systems to human values. As AI\ncapabilities improve and AI is used to tackle more challenging tasks, verifying\nquality and safety becomes increasingly challenging. This paper explores how we\ncan leverage AI to improve the quality of human oversight. We focus on an\nimportant safety problem that is already challenging for humans:\nfact-verification of AI outputs. We find that combining AI ratings and human\nratings based on AI rater confidence is better than relying on either alone.\nGiving humans an AI fact-verification assistant further improves their\naccuracy, but the type of assistance matters. Displaying AI explanation,\nconfidence, and labels leads to over-reliance, but just showing search results\nand evidence fosters more appropriate trust. These results have implications\nfor Amplified Oversight -- the challenge of combining humans and AI to\nsupervise AI systems even as they surpass human expert performance.", "AI": {"tldr": "\u7ed3\u5408AI\u8bc4\u5206\u548c\u57fa\u4e8eAI\u8bc4\u5206\u8005\u7f6e\u4fe1\u5ea6\u7684\u4eba\u7c7b\u8bc4\u5206\u6bd4\u5355\u72ec\u4f9d\u8d56\u4efb\u4e00\u65b9\u66f4\u597d\u3002\u4e3a\u4eba\u7c7b\u63d0\u4f9bAI\u4e8b\u5b9e\u6838\u67e5\u52a9\u624b\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u52a9\u624b\u7c7b\u578b\u5f88\u91cd\u8981\u3002\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u548c\u6807\u7b7e\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u800c\u4ec5\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\u80fd\u57f9\u517b\u66f4\u9002\u5f53\u7684\u4fe1\u4efb\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u63d0\u5347\u548c\u5904\u7406\u66f4\u590d\u6742\u4efb\u52a1\uff0c\u9a8c\u8bc1\u8d28\u91cf\u548c\u5b89\u5168\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002\u672c\u6587\u63a2\u7d22\u5982\u4f55\u5229\u7528AI\u63d0\u9ad8\u4eba\u7c7b\u76d1\u7763\u7684\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8\u4eba\u7c7b\u5df2\u7ecf\u96be\u4ee5\u5904\u7406\u7684\u91cd\u8981\u5b89\u5168\u95ee\u9898\uff1aAI\u8f93\u51fa\u7684\u4e8b\u5b9e\u6838\u67e5\u3002", "method": "\u7814\u7a76\u7ed3\u5408AI\u8bc4\u5206\u548c\u4eba\u7c7b\u8bc4\u5206\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8eAI\u8bc4\u5206\u8005\u7684\u7f6e\u4fe1\u5ea6\u3002\u6d4b\u8bd5\u4e0d\u540c\u7c7b\u578b\u7684AI\u4e8b\u5b9e\u6838\u67e5\u52a9\u624b\u5bf9\u4eba\u7c7b\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u663e\u793aAI\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u3001\u6807\u7b7e\u4e0e\u4ec5\u663e\u793a\u641c\u7d22\u7ed3\u679c\u548c\u8bc1\u636e\u7684\u6548\u679c\u3002", "result": "AI\u548c\u4eba\u7c7b\u8bc4\u5206\u7684\u7ed3\u5408\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\u3002AI\u52a9\u624b\u80fd\u63d0\u9ad8\u4eba\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u663e\u793a\u5b8c\u6574AI\u4fe1\u606f\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u800c\u4ec5\u663e\u793a\u8bc1\u636e\u548c\u641c\u7d22\u7ed3\u679c\u80fd\u57f9\u517b\u66f4\u9002\u5f53\u7684\u4fe1\u4efb\u5173\u7cfb\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5bf9\"\u653e\u5927\u76d1\u7763\"\u5177\u6709\u91cd\u8981\u542f\u793a\u2014\u2014\u5373\u7ed3\u5408\u4eba\u7c7b\u548cAI\u6765\u76d1\u7763AI\u7cfb\u7edf\uff0c\u5373\u4f7f\u8fd9\u4e9b\u7cfb\u7edf\u8d85\u8d8a\u4e86\u4eba\u7c7b\u4e13\u5bb6\u8868\u73b0\u3002\u52a9\u624b\u8bbe\u8ba1\u5bf9\u5efa\u7acb\u9002\u5f53\u7684\u4fe1\u4efb\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.26550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26550", "abs": "https://arxiv.org/abs/2510.26550", "authors": ["Jack FitzGerald", "Aristotelis Lazaridis", "Dylan Bates", "Aman Sharma", "Jonnathan Castillo", "Yousif Azami", "Sean Bailey", "Jeremy Cao", "Peter Damianov", "Kevin de Haan", "Luke Kerbs", "Vincent Lu", "Joseph Madigan", "Jeremy McLaurin", "Jonathan Tainer", "Dave Anderson", "Jonathan Beck", "Jamie Cuticello", "Colton Malkerson", "Tyler Saltsman"], "title": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge", "comment": "19 pages", "summary": "We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for\nmilitary tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated\nfrom military documentation and websites. We also present four new tests sets:\n(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k\n(general military knowledge). On these military test sets, EdgeRunner 20B\nmatches or exceeds GPT-5 task performance with 95%+ statistical significance,\nexcept for the high reasoning setting on the combat medic test set and the low\nreasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no\nstatistically-significant regression on general-purpose benchmarks like ARC-C,\nGPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the\nlow reasoning setting. We also present analyses on hyperparameter settings,\ncost, and throughput. These findings show that small, locally-hosted models are\nideal solutions for data-sensitive operations such as in the military domain,\nallowing for deployment in air-gapped edge devices.", "AI": {"tldr": "EdgeRunner 20B\u662f\u57fa\u4e8egpt-oss-20b\u5fae\u8c03\u7684\u519b\u4e8b\u4efb\u52a1\u4f18\u5316\u6a21\u578b\uff0c\u5728\u519b\u4e8b\u6d4b\u8bd5\u96c6\u4e0a\u6027\u80fd\u63a5\u8fd1\u6216\u8d85\u8fc7GPT-5\uff0c\u9002\u5408\u5728\u9694\u79bb\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "motivation": "\u4e3a\u6570\u636e\u654f\u611f\u64cd\u4f5c\uff08\u5982\u519b\u4e8b\u9886\u57df\uff09\u5f00\u53d1\u5c0f\u578b\u672c\u5730\u5316\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u5728\u9694\u79bb\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\uff0c\u89e3\u51b3\u519b\u4e8b\u4efb\u52a1\u7684\u4e13\u4e1a\u9700\u6c42\u3002", "method": "\u4f7f\u7528160\u4e07\u6761\u9ad8\u8d28\u91cf\u519b\u4e8b\u6587\u6863\u548c\u7f51\u7ad9\u6570\u636e\u5bf9gpt-oss-20b\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u521b\u5efa\u4e86\u56db\u4e2a\u65b0\u7684\u519b\u4e8b\u6d4b\u8bd5\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u519b\u4e8b\u6d4b\u8bd5\u96c6\u4e0a\uff0cEdgeRunner 20B\u572895%\u7edf\u8ba1\u663e\u8457\u6027\u6c34\u5e73\u4e0b\u5339\u914d\u6216\u8d85\u8fc7GPT-5\u6027\u80fd\uff0c\u4ec5\u5728\u6218\u6597\u533b\u62a4\u6d4b\u8bd5\u96c6\u7684\u9ad8\u63a8\u7406\u8bbe\u7f6e\u548cmil-bench-5k\u7684\u4f4e\u63a8\u7406\u8bbe\u7f6e\u4e2d\u8868\u73b0\u7a0d\u5dee\u3002\u5728\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u57fa\u672c\u65e0\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5c0f\u578b\u672c\u5730\u5316\u6a21\u578b\u662f\u6570\u636e\u654f\u611f\u519b\u4e8b\u64cd\u4f5c\u7684\u7406\u60f3\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u5728\u9694\u79bb\u8fb9\u7f18\u8bbe\u5907\u4e0a\u6709\u6548\u90e8\u7f72\uff0c\u6ee1\u8db3\u519b\u4e8b\u9886\u57df\u7684\u4e13\u4e1a\u9700\u6c42\u3002"}}
{"id": "2510.26606", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26606", "abs": "https://arxiv.org/abs/2510.26606", "authors": ["Kentaro Ozeki", "Risako Ando", "Takanobu Morishita", "Hirohiko Abe", "Koji Mineshima", "Mitsuhiro Okada"], "title": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "comment": "Accepted to the 8th BlackboxNLP Workshop at EMNLP 2025", "summary": "Normative reasoning is a type of reasoning that involves normative or deontic\nmodality, such as obligation and permission. While large language models (LLMs)\nhave demonstrated remarkable performance across various reasoning tasks, their\nability to handle normative reasoning remains underexplored. In this paper, we\nsystematically evaluate LLMs' reasoning capabilities in the normative domain\nfrom both logical and modal perspectives. Specifically, to assess how well LLMs\nreason with normative modals, we make a comparison between their reasoning with\nnormative modals and their reasoning with epistemic modals, which share a\ncommon formal structure. To this end, we introduce a new dataset covering a\nwide range of formal patterns of reasoning in both normative and epistemic\ndomains, while also incorporating non-formal cognitive factors that influence\nhuman reasoning. Our results indicate that, although LLMs generally adhere to\nvalid reasoning patterns, they exhibit notable inconsistencies in specific\ntypes of normative reasoning and display cognitive biases similar to those\nobserved in psychological studies of human reasoning. These findings highlight\nchallenges in achieving logical consistency in LLMs' normative reasoning and\nprovide insights for enhancing their reliability. All data and code are\nreleased publicly at https://github.com/kmineshima/NeuBAROCO.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c4\u8303\u63a8\u7406\u9886\u57df\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5c3d\u7ba1LLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u63a8\u7406\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5904\u7406\u89c4\u8303\u63a8\u7406\uff08\u6d89\u53ca\u4e49\u52a1\u3001\u8bb8\u53ef\u7b49\u6a21\u6001\uff09\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u89c4\u8303\u548c\u8ba4\u77e5\u9886\u57df\u7684\u5e7f\u6cdb\u63a8\u7406\u6a21\u5f0f\uff0c\u540c\u65f6\u7eb3\u5165\u5f71\u54cd\u4eba\u7c7b\u63a8\u7406\u7684\u975e\u5f62\u5f0f\u8ba4\u77e5\u56e0\u7d20\u3002\u901a\u8fc7\u6bd4\u8f83LLMs\u5728\u89c4\u8303\u6a21\u6001\u548c\u8ba4\u77e5\u6a21\u6001\u4e0a\u7684\u63a8\u7406\u8868\u73b0\u6765\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cLLMs\u603b\u4f53\u4e0a\u9075\u5faa\u6709\u6548\u63a8\u7406\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u7684\u89c4\u8303\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u5728LLMs\u7684\u89c4\u8303\u63a8\u7406\u4e2d\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u6027\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.26658", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26658", "abs": "https://arxiv.org/abs/2510.26658", "authors": ["Zewen Chi", "Li Dong", "Qingxiu Dong", "Yaru Hao", "Xun Wu", "Shaohan Huang", "Furu Wei"], "title": "The Era of Agentic Organization: Learning to Organize with Language Models", "comment": null, "summary": "We envision a new era of AI, termed agentic organization, where agents solve\ncomplex problems by working collaboratively and concurrently, enabling outcomes\nbeyond individual intelligence. To realize this vision, we introduce\nasynchronous thinking (AsyncThink) as a new paradigm of reasoning with large\nlanguage models, which organizes the internal thinking process into\nconcurrently executable structures. Specifically, we propose a thinking\nprotocol where an organizer dynamically assigns sub-queries to workers, merges\nintermediate knowledge, and produces coherent solutions. More importantly, the\nthinking structure in this protocol can be further optimized through\nreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%\nlower inference latency compared to parallel thinking while improving accuracy\non mathematical reasoning. Moreover, AsyncThink generalizes its learned\nasynchronous thinking capabilities, effectively tackling unseen tasks without\nadditional training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5f02\u6b65\u601d\u7ef4\uff08AsyncThink\uff09\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u5185\u90e8\u601d\u8003\u8fc7\u7a0b\u7ec4\u7ec7\u6210\u5e76\u53d1\u53ef\u6267\u884c\u7ed3\u6784\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u3002", "motivation": "\u5b9e\u73b0\u667a\u80fd\u4f53\u7ec4\u7ec7\u7684\u65b0\u65f6\u4ee3\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u534f\u4f5c\u548c\u5e76\u53d1\u5de5\u4f5c\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u8d85\u8d8a\u4e2a\u4f53\u667a\u80fd\u7684\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u601d\u8003\u534f\u8bae\uff0c\u5176\u4e2d\u7ec4\u7ec7\u8005\u52a8\u6001\u5206\u914d\u5b50\u67e5\u8be2\u7ed9\u5de5\u4f5c\u8005\uff0c\u5408\u5e76\u4e2d\u95f4\u77e5\u8bc6\uff0c\u5e76\u751f\u6210\u8fde\u8d2f\u89e3\u51b3\u65b9\u6848\u3002\u601d\u8003\u7ed3\u6784\u53ef\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAsyncThink\u76f8\u6bd4\u5e76\u884c\u601d\u7ef4\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e28%\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4e14\u80fd\u591f\u6cdb\u5316\u5b66\u4e60\u5230\u7684\u5f02\u6b65\u601d\u7ef4\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5904\u7406\u672a\u89c1\u4efb\u52a1\u3002", "conclusion": "\u5f02\u6b65\u601d\u7ef4\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u8303\u5f0f\uff0c\u5728\u964d\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.26702", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26702", "abs": "https://arxiv.org/abs/2510.26702", "authors": ["Majed El Helou", "Chiara Troiani", "Benjamin Ryder", "Jean Diaconu", "Herv\u00e9 Muyal", "Marcelo Yannuzzi"], "title": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching", "comment": "Paper page at https://outshift-open.github.io/ASTRA", "summary": "Authorizing Large Language Model driven agents to dynamically invoke tools\nand access protected resources introduces significant risks, since current\nmethods for delegating authorization grant overly broad permissions and give\naccess to tools allowing agents to operate beyond the intended task scope. We\nintroduce and assess a delegated authorization model enabling authorization\nservers to semantically inspect access requests to protected resources, and\nissue access tokens constrained to the minimal set of scopes necessary for the\nagents' assigned tasks. Given the unavailability of datasets centered on\ndelegated authorization flows, particularly including both semantically\nappropriate and inappropriate scope requests for a given task, we introduce\nASTRA, a dataset and data generation pipeline for benchmarking semantic\nmatching between tasks and scopes. Our experiments show both the potential and\ncurrent limitations of model-based matching, particularly as the number of\nscopes needed for task completion increases. Our results highlight the need for\nfurther research into semantic matching techniques enabling intent-aware\nauthorization for multi-agent and tool-augmented applications, including\nfine-grained control, such as Task-Based Access Control (TBAC).", "AI": {"tldr": "\u63d0\u51fa\u4e86ASTRA\u6570\u636e\u96c6\u548c\u6388\u6743\u6a21\u578b\uff0c\u7528\u4e8e\u7ea6\u675fLLM\u4ee3\u7406\u7684\u5de5\u5177\u8bbf\u95ee\u6743\u9650\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u67e5\u786e\u4fdd\u53ea\u6388\u4e88\u5b8c\u6210\u4efb\u52a1\u6240\u9700\u7684\u6700\u5c0f\u6743\u9650\u8303\u56f4\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u7684\u6388\u6743\u65b9\u6cd5\u6388\u4e88\u8fc7\u4e8e\u5bbd\u6cdb\u7684\u6743\u9650\uff0c\u4f7f\u5f97\u4ee3\u7406\u80fd\u591f\u5728\u8d85\u51fa\u4efb\u52a1\u8303\u56f4\u7684\u60c5\u51b5\u4e0b\u64cd\u4f5c\u5de5\u5177\u548c\u8bbf\u95ee\u53d7\u4fdd\u62a4\u8d44\u6e90\uff0c\u5b58\u5728\u663e\u8457\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5f15\u5165\u59d4\u6258\u6388\u6743\u6a21\u578b\uff0c\u5141\u8bb8\u6388\u6743\u670d\u52a1\u5668\u8bed\u4e49\u68c0\u67e5\u5bf9\u53d7\u4fdd\u62a4\u8d44\u6e90\u7684\u8bbf\u95ee\u8bf7\u6c42\uff0c\u5e76\u53d1\u5e03\u4ec5\u9650\u4e8e\u4ee3\u7406\u5206\u914d\u4efb\u52a1\u6240\u9700\u6700\u5c0f\u6743\u9650\u8303\u56f4\u7684\u8bbf\u95ee\u4ee4\u724c\u3002\u521b\u5efaASTRA\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u4efb\u52a1\u4e0e\u6743\u9650\u8303\u56f4\u4e4b\u95f4\u7684\u8bed\u4e49\u5339\u914d\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u8bed\u4e49\u5339\u914d\u7684\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5b8c\u6210\u4efb\u52a1\u6240\u9700\u6743\u9650\u8303\u56f4\u6570\u91cf\u589e\u52a0\u65f6\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u8bed\u4e49\u5339\u914d\u6280\u672f\uff0c\u4e3a\u591a\u4ee3\u7406\u548c\u5de5\u5177\u589e\u5f3a\u5e94\u7528\u5b9e\u73b0\u610f\u56fe\u611f\u77e5\u6388\u6743\uff0c\u5305\u62ec\u7ec6\u7c92\u5ea6\u63a7\u5236\u5982\u57fa\u4e8e\u4efb\u52a1\u7684\u8bbf\u95ee\u63a7\u5236(TBAC)\u3002"}}
{"id": "2510.26721", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.26721", "abs": "https://arxiv.org/abs/2510.26721", "authors": ["Xinhan Zheng", "Huyu Wu", "Xueting Wang", "Haiyun Jiang"], "title": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "comment": null, "summary": "Multimodal large language models (MLLMs) exhibit a pronounced preference for\ntextual inputs when processing vision-language data, limiting their ability to\nreason effectively from visual evidence. Unlike prior studies that attribute\nthis text bias to external factors such as data imbalance or instruction\ntuning, we propose that the bias originates from the model's internal\narchitecture. Specifically, we hypothesize that visual key vectors (Visual\nKeys) are out-of-distribution (OOD) relative to the text key space learned\nduring language-only pretraining. Consequently, these visual keys receive\nsystematically lower similarity scores during attention computation, leading to\ntheir under-utilization in the context representation. To validate this\nhypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their\ndistributional structures using qualitative (t-SNE) and quantitative\n(Jensen-Shannon divergence) methods. The results provide direct evidence that\nvisual and textual keys occupy markedly distinct subspaces within the attention\nspace. The inter-modal divergence is statistically significant, exceeding\nintra-modal variation by several orders of magnitude. These findings reveal\nthat text bias arises from an intrinsic misalignment within the attention key\nspace rather than solely from external data factors.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u672c\u504f\u597d\u95ee\u9898\uff0c\u5176\u6839\u6e90\u5728\u4e8e\u6a21\u578b\u5185\u90e8\u67b6\u6784\uff1a\u89c6\u89c9\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u4e0e\u6587\u672c\u952e\u5411\u91cf\u5206\u5e03\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u89c6\u89c9\u4fe1\u606f\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u4e2d\u88ab\u4f4e\u4f30\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u89c6\u89c9\u8bed\u8a00\u6570\u636e\u65f6\u8868\u73b0\u51fa\u660e\u663e\u7684\u6587\u672c\u504f\u597d\uff0c\u9650\u5236\u4e86\u5176\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u6709\u6548\u63a8\u7406\u7684\u80fd\u529b\u3002\u73b0\u6709\u7814\u7a76\u5c06\u6b64\u5f52\u56e0\u4e8e\u6570\u636e\u4e0d\u5e73\u8861\u6216\u6307\u4ee4\u8c03\u4f18\u7b49\u5916\u90e8\u56e0\u7d20\uff0c\u4f46\u672c\u6587\u8ba4\u4e3a\u504f\u5dee\u6e90\u4e8e\u6a21\u578b\u5185\u90e8\u67b6\u6784\u3002", "method": "\u4eceLLaVA\u548cQwen2.5-VL\u6a21\u578b\u4e2d\u63d0\u53d6\u952e\u5411\u91cf\uff0c\u4f7f\u7528t-SNE\u53ef\u89c6\u5316\u548cJensen-Shannon\u6563\u5ea6\u7b49\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\u5206\u6790\u5176\u5206\u5e03\u7ed3\u6784\u3002", "result": "\u89c6\u89c9\u952e\u5411\u91cf\u548c\u6587\u672c\u952e\u5411\u91cf\u5728\u6ce8\u610f\u529b\u7a7a\u95f4\u4e2d\u5360\u636e\u660e\u663e\u4e0d\u540c\u7684\u5b50\u7a7a\u95f4\uff0c\u6a21\u6001\u95f4\u5dee\u5f02\u5728\u7edf\u8ba1\u4e0a\u663e\u8457\uff0c\u6bd4\u6a21\u6001\u5185\u53d8\u5f02\u9ad8\u51fa\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6587\u672c\u504f\u597d\u6e90\u4e8e\u6ce8\u610f\u529b\u952e\u7a7a\u95f4\u5185\u7684\u5185\u5728\u9519\u4f4d\uff0c\u800c\u975e\u4ec5\u7531\u5916\u90e8\u6570\u636e\u56e0\u7d20\u5f15\u8d77\u3002"}}
{"id": "2510.26732", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26732", "abs": "https://arxiv.org/abs/2510.26732", "authors": ["J. de Curt\u00f2", "I. de Zarz\u00e0", "Pablo Garc\u00eda", "Jordi Cabot"], "title": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "comment": null, "summary": "This paper presents a comprehensive cross-platform evaluation of reasoning\ncapabilities in contemporary foundation models, establishing an\ninfrastructure-agnostic benchmark across three computational paradigms: HPC\nsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and\nuniversity clusters (a node with eight H200 GPUs).\n  We evaluate 15 foundation models across 79 problems spanning eight academic\ndomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,\nCalculus, and Optimization) through three experimental phases: (1) Baseline\nestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,\nMistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing\nmethodology and reference performance; (2) Infrastructure validation: The\n19-problem benchmark repeated on university cluster (seven models including\nFalcon-Mamba state-space architecture) and Nebius AI Studio (nine\nstate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3\n30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic\nreproducibility; (3) Extended evaluation: Full 79-problem assessment on both\nuniversity cluster and Nebius platforms, probing generalization at scale across\narchitectural diversity.\n  The findings challenge conventional scaling assumptions, establish training\ndata quality as more critical than model size, and provide actionable\nguidelines for model selection across educational, production, and research\ncontexts. The tri-infrastructure methodology and 79-problem benchmark enable\nlongitudinal tracking of reasoning capabilities as foundation models evolve.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u5e73\u53f0\u7684\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u4e09\u79cd\u8ba1\u7b97\u8303\u5f0f\uff08HPC\u8d85\u7ea7\u8ba1\u7b97\u3001\u4e91\u5e73\u53f0\u3001\u5927\u5b66\u96c6\u7fa4\uff09\u4e0a\u8bc4\u4f30\u4e8615\u4e2a\u57fa\u7840\u6a21\u578b\u572879\u4e2a\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u6269\u5c55\u5047\u8bbe\uff0c\u5f3a\u8c03\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u91cd\u8981\u3002", "motivation": "\u5efa\u7acb\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5f53\u4ee3\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u8ba1\u7b97\u5e73\u53f0\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u6559\u80b2\u3001\u751f\u4ea7\u548c\u7814\u7a76\u73af\u5883\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5b9e\u9a8c\u8bbe\u8ba1\uff1a(1) \u5728MareNostrum 5\u4e0a\u5efa\u7acb\u57fa\u7ebf\u6027\u80fd\uff1b(2) \u5728\u4e0d\u540c\u57fa\u7840\u8bbe\u65bd\u4e0a\u9a8c\u8bc1\u53ef\u91cd\u590d\u6027\uff1b(3) \u5728\u5b8c\u657479\u4e2a\u95ee\u9898\u4e0a\u8fdb\u884c\u6269\u5c55\u8bc4\u4f30\uff0c\u6db5\u76d68\u4e2a\u5b66\u672f\u9886\u57df\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u6269\u5c55\u5047\u8bbe\uff0c\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u5173\u952e\uff0c\u5e76\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u6a21\u578b\u9009\u62e9\u7684\u5177\u4f53\u6307\u5bfc\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u57fa\u7840\u8bbe\u65bd\u65b9\u6cd5\u548c79\u95ee\u9898\u57fa\u51c6\u6d4b\u8bd5\u80fd\u591f\u7eb5\u5411\u8ffd\u8e2a\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6846\u67b6\u3002"}}
{"id": "2510.26752", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26752", "abs": "https://arxiv.org/abs/2510.26752", "authors": ["William Overman", "Mohsen Bayati"], "title": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "comment": null, "summary": "As increasingly capable agents are deployed, a central safety question is how\nto retain meaningful human control without modifying the underlying system. We\nstudy a minimal control interface where an agent chooses whether to act\nautonomously (play) or defer (ask), while a human simultaneously chooses\nwhether to be permissive (trust) or to engage in oversight (oversee). If the\nagent defers, the human's choice determines the outcome, potentially leading to\na corrective action or a system shutdown. We model this interaction as a\ntwo-player Markov Game. Our analysis focuses on cases where this game qualifies\nas a Markov Potential Game (MPG), a class of games where we can provide an\nalignment guarantee: under a structural assumption on the human's value\nfunction, any decision by the agent to act more autonomously that benefits\nitself cannot harm the human's value. We also analyze extensions to this MPG\nframework. Theoretically, this perspective provides conditions for a specific\nform of intrinsic alignment. If the reward structures of the human-agent game\nmeet these conditions, we have a formal guarantee that the agent improving its\nown outcome will not harm the human's. Practically, this model motivates a\ntransparent control layer with predictable incentives where the agent learns to\ndefer when risky and act when safe, while its pretrained policy and the\nenvironment's reward structure remain untouched. Our gridworld simulation shows\nthat through independent learning, the agent and human discover their optimal\noversight roles. The agent learns to ask when uncertain and the human learns\nwhen to oversee, leading to an emergent collaboration that avoids safety\nviolations introduced post-training. This demonstrates a practical method for\nmaking misaligned models safer after deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u5c0f\u63a7\u5236\u63a5\u53e3\uff0c\u8ba9\u667a\u80fd\u4f53\u9009\u62e9\u81ea\u4e3b\u884c\u52a8\u6216\u5bfb\u6c42\u5e2e\u52a9\uff0c\u4eba\u7c7b\u9009\u62e9\u4fe1\u4efb\u6216\u76d1\u7763\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u52bf\u535a\u5f08\u6846\u67b6\u5b9e\u73b0\u5185\u5728\u5bf9\u9f50\u4fdd\u8bc1\uff0c\u786e\u4fdd\u667a\u80fd\u4f53\u81ea\u4e3b\u6027\u63d0\u5347\u4e0d\u4f1a\u635f\u5bb3\u4eba\u7c7b\u4ef7\u503c\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u4fdd\u6301\u7cfb\u7edf\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u63a7\u5236\u63a5\u53e3\u5b9e\u73b0\u6709\u610f\u4e49\u7684\u4eba\u7c7b\u63a7\u5236\uff0c\u89e3\u51b3\u667a\u80fd\u4f53\u90e8\u7f72\u540e\u7684\u5b89\u5168\u95ee\u9898\u3002", "method": "\u5c06\u4eba\u673a\u4ea4\u4e92\u5efa\u6a21\u4e3a\u53cc\u73a9\u5bb6\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u5728\u6ee1\u8db3\u9a6c\u5c14\u53ef\u592b\u52bf\u535a\u5f08\u6761\u4ef6\u65f6\uff0c\u5206\u6790\u7ed3\u6784\u5047\u8bbe\u4e0b\u7684\u4eba\u7c7b\u4ef7\u503c\u51fd\u6570\uff0c\u63d0\u4f9b\u5bf9\u9f50\u4fdd\u8bc1\u3002", "result": "\u7f51\u683c\u4e16\u754c\u6a21\u62df\u663e\u793a\uff0c\u901a\u8fc7\u72ec\u7acb\u5b66\u4e60\uff0c\u667a\u80fd\u4f53\u5b66\u4f1a\u5728\u4e0d\u786e\u5b9a\u65f6\u5bfb\u6c42\u5e2e\u52a9\uff0c\u4eba\u7c7b\u5b66\u4f1a\u9002\u65f6\u76d1\u7763\uff0c\u5f62\u6210\u907f\u514d\u5b89\u5168\u8fdd\u89c4\u7684\u534f\u4f5c\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u90e8\u7f72\u540e\u9519\u4f4d\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u5b89\u5168\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u900f\u660e\u63a7\u5236\u5c42\u5b9e\u73b0\u53ef\u9884\u6d4b\u7684\u6fc0\u52b1\u673a\u5236\u3002"}}
{"id": "2510.26784", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26784", "abs": "https://arxiv.org/abs/2510.26784", "authors": ["Arnab Sen Sharma", "Giordano Rogers", "Natalie Shapira", "David Bau"], "title": "LLMs Process Lists With General Filter Heads", "comment": "Code and data at https://filter.baulab.info/", "summary": "We investigate the mechanisms underlying a range of list-processing tasks in\nLLMs, and we find that LLMs have learned to encode a compact, causal\nrepresentation of a general filtering operation that mirrors the generic\n\"filter\" function of functional programming. Using causal mediation analysis on\na diverse set of list-processing tasks, we find that a small number of\nattention heads, which we dub filter heads, encode a compact representation of\nthe filtering predicate in their query states at certain tokens. We demonstrate\nthat this predicate representation is general and portable: it can be extracted\nand reapplied to execute the same filtering operation on different collections,\npresented in different formats, languages, or even in tasks. However, we also\nidentify situations where transformer LMs can exploit a different strategy for\nfiltering: eagerly evaluating if an item satisfies the predicate and storing\nthis intermediate result as a flag directly in the item representations. Our\nresults reveal that transformer LMs can develop human-interpretable\nimplementations of abstract computational operations that generalize in ways\nthat are surprisingly similar to strategies used in traditional functional\nprogramming patterns.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5b66\u4e60\u5230\u4e86\u7c7b\u4f3c\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d'filter'\u64cd\u4f5c\u7684\u7d27\u51d1\u56e0\u679c\u8868\u793a\uff0c\u901a\u8fc7\u5c11\u91cf\u6ce8\u610f\u529b\u5934\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\uff0c\u8be5\u8868\u793a\u5177\u6709\u901a\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002", "motivation": "\u63a2\u7a76LLMs\u5728\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5982\u4f55\u5b9e\u73b0\u7c7b\u4f3c\u51fd\u6570\u5f0f\u7f16\u7a0b\u7684\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\u3002", "method": "\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u5728\u591a\u6837\u5316\u7684\u5217\u8868\u5904\u7406\u4efb\u52a1\u4e0a\uff0c\u8bc6\u522b\u51fa\u7f16\u7801\u8fc7\u6ee4\u8c13\u8bcd\u7684\u6ce8\u610f\u529b\u5934\uff08\u79f0\u4e3afilter heads\uff09\u3002", "result": "\u53d1\u73b0LLMs\u80fd\u591f\u5f00\u53d1\u51fa\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\u5b9e\u73b0\uff0c\u5176\u6cdb\u5316\u65b9\u5f0f\u4e0e\u4f20\u7edf\u51fd\u6570\u5f0f\u7f16\u7a0b\u6a21\u5f0f\u60ca\u4eba\u76f8\u4f3c\u3002", "conclusion": "Transformer LMs\u80fd\u591f\u5b66\u4e60\u5e76\u6cdb\u5316\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\u8ba1\u7b97\u64cd\u4f5c\uff0c\u5c55\u73b0\u51fa\u4e0e\u51fd\u6570\u5f0f\u7f16\u7a0b\u7c7b\u4f3c\u7684\u7b56\u7565\u3002"}}
