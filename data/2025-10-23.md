<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 23]
- [cs.IT](#cs.IT) [Total: 2]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Enabling Reconfiguration-Communication Overlap for Collective Communication in Optical Networks](https://arxiv.org/abs/2510.19322)
*Changbo Wu,Zhuolong Yu,Gongming Zhao,Hongli Xu*

Main category: cs.NI

TL;DR: SWOT是一种需求感知的光网络框架，通过动态网络重配置和传输调度优化，解决现有光互连集体通信方案在可扩展性和效率方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有基于光互连的集体通信方案采用"一次性网络重配置"策略，为整个集体操作提供静态高容量拓扑，但在支持现代工作负载所需的更复杂高效CC算法时面临显著可扩展性限制。

Method: SWOT采用"集体内重配置"，动态调整网络资源与CC流量模式对齐；包含新颖的调度技术，将光交换机重配置与持续传输重叠；引入轻量级集体通信中间件，支持协调的光网络配置和传输调度。

Result: 仿真结果表明SWOT带来了显著的性能提升。

Conclusion: SWOT框架通过动态网络资源对齐和重叠调度技术，有效解决了现有光互连集体通信方案的可扩展性和效率问题。

Abstract: Collective communication (CC) is widely adopted for large-scale distributed
machine learning (DML) training workloads. DML's predictable traffic pattern
provides a great oppotunity for applying optical network technology. Existing
optical interconnects-based CC schemes adopt ``one-shot network
reconfiguration'', which provisions static high-capacity topologies for an
entire collective operation -- sometimes for a full training iteration.
However, this approach faces significant scalability limitations when
supporting more complex and efficient CC algorithms required for modern
workloads: the ``one-shot'' strategies either demand excessive resource
overprovisioning or suffer performance degradation due to rigid resource
allocation.
  To address these challenges, we propose SWOT, a demand-aware optical network
framework. SWOT employs ``intra-collective reconfiguration'' and can
dynamically align network resources with CC traffic patterns. SWOT incorporates
a novel scheduling technique that overlaps optical switch reconfigurations with
ongoing transmissions, and improves communication efficiency. SWOT introduce a
lightweight collective communication shim that enables coordinated optical
network configuration and transmission scheduling while supporting seamless
integration with existing CC libraries. Our simulation results demonstrate
SWOT's significant performance improvements.

</details>


### [2] [On the Power Saving in High-Speed Ethernet-based Networks for Supercomputers and Data Centers](https://arxiv.org/abs/2510.19783)
*Miguel Sánchez de la Rosa,Francisco J. andújar,Jesus Escudero-Sahuquillo,José L. Sánchez,Francisco J. Alfaro-Cortés*

Main category: cs.NI

TL;DR: 该论文研究了高性能计算和数据中心网络的节能技术，重点关注Energy Efficient Ethernet(EEE)的应用，分析了PerfBound提案并提出改进方案，通过模拟实验评估不同互连技术的性能影响，为未来基于以太网的HPC架构提供了首个定制化的电源管理方案。


<details>
  <summary>Details</summary>
Motivation: 随着计算和存储能力的增长，系统规模不断扩大，引发了可持续性和运营成本的担忧。需要探索HPC和数据中心网络的节能技术及其对性能的影响。

Method: 分析PerfBound提案并建模到仿真框架中，通过不同实验评估其对性能的影响，研究HPC和机器学习应用产生的流量模式，评估节能技术的行为。

Result: 实验提供了应用如何影响系统和网络能耗的分析，揭示了动态断电机制的弱点，并提出了一种在最小或无性能损失下改善能耗减少的方法。

Conclusion: 这是首个针对未来基于以太网的HPC架构的电源管理提案，具有有前景的结果，能够显著降低能耗而几乎不影响性能。

Abstract: The increase in computation and storage has led to a significant growth in
the scale of systems powering applications and services, raising concerns about
sustainability and operational costs. In this paper, we explore power-saving
techniques in high-performance computing (HPC) and datacenter networks, and
their relation with performance degradation. From this premise, we propose
leveraging Energy Efficient Ethernet (EEE), with the flexibility to extend to
conventional Ethernet or upcoming Ethernet-derived interconnect versions of BXI
and Omnipath.
  We analyze the PerfBound proposal, identifying possible improvements and
modeling it into a simulation framework. Through different experiments, we
examine its impact on performance and determine the most appropriate
interconnect. We also study traffic patterns generated by selected HPC and
machine learning applications to evaluate the behavior of power-saving
techniques.
  From these experiments, we provide an analysis of how applications affect
system and network energy consumption. Based on this, we disclose the weakness
of dynamic power-down mechanisms and propose an approach that improves energy
reduction with minimal or no performance penalty. To our knowledge, this is the
first power management proposal tailored to future Ethernet-based HPC
architectures, with promising results.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality](https://arxiv.org/abs/2510.18982)
*Arpan Mukherjee,Marcello Bullo,Debabrota Basu,Deniz Gündüz*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架来分析测试时缩放中验证器的作用，将验证问题建模为传输问题，揭示了次优性-覆盖率曲线的三个区域，并分析了顺序和批量采样算法的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 虽然带验证的测试时缩放已显示出提升大语言模型性能的潜力，但验证器的作用及其缺陷仍未充分探索。现有研究只捕捉了部分因素，缺乏量化这些因素相互作用的统一框架。

Method: 将可验证的测试时缩放框架化为传输问题，通过分析生成器的覆盖率、验证器的收敛区域和采样算法的次优性之间的相互作用，提出了顺序和批量两类采样算法。

Result: 发现次优性-覆盖率曲线存在三个区域：传输区域（次优性随覆盖率增加）、策略改进区域（次优性可能随覆盖率减少，取决于验证器的收敛区域）和饱和区域（次优性趋于平稳）。在Qwen、Llama和Gemma模型上的实证结果验证了理论发现。

Conclusion: 通过传输问题框架揭示了验证器在测试时缩放中的关键作用，为理解覆盖率、验证器性能和采样算法之间的权衡提供了理论基础，有助于设计更有效的测试时缩放策略。

Abstract: While test-time scaling with verification has shown promise in improving the
performance of large language models (LLMs), the role of the verifier and its
imperfections remain underexplored. The effect of verification manifests
through interactions of three quantities: (i) the generator's coverage, (ii)
the verifier's region of convergence (ROC), and (iii) the sampling algorithm's
sub-optimality. Though recent studies capture subsets of these factors, a
unified framework quantifying the geometry of their interplay is missing. We
frame verifiable test-time scaling as a transport problem. This characterizes
the interaction of coverage, ROC, and sub-optimality, and uncovers that the
sub-optimality--coverage curve exhibits three regimes. A transport regime --
where sub-optimality increases with coverage, a policy improvement regime --
where sub-optimality may decrease with coverage, depending on the verifier's
ROC, and a saturation regime -- where sub-optimality plateaus, unaffected by
coverage. We further propose and analyze two classes of sampling algorithms --
sequential and batched, and examine how their computational complexities shape
these trade-offs. Empirical results with Qwen, Llama, and Gemma models
corroborate our theoretical findings.

</details>


### [4] [Timely Clinical Diagnosis through Active Test Selection](https://arxiv.org/abs/2510.18988)
*Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: ACTMED是一个结合贝叶斯实验设计和大型语言模型的临床诊断框架，通过逐步选择能最大程度减少诊断不确定性的测试来优化诊断过程。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习诊断方法依赖静态数据集，无法模拟临床医生在实践中的顺序性、资源感知推理过程。诊断在高压或资源有限环境中仍然复杂且容易出错，需要能够帮助医生做出及时且成本效益高的决策的框架。

Method: 将贝叶斯实验设计与大型语言模型集成，在每个步骤中选择预期能为特定患者带来最大诊断不确定性减少的测试。LLM作为灵活模拟器，生成合理的患者状态分布并支持信念更新，无需结构化、特定任务的训练数据。

Result: 在真实世界数据集上的评估表明，ACTMED能够优化测试选择，提高诊断准确性、可解释性和资源利用效率。

Conclusion: ACTMED代表了向透明、自适应且与临床医生对齐的诊断系统迈出的一步，能够在减少对领域特定数据依赖的情况下跨环境泛化。

Abstract: There is growing interest in using machine learning (ML) to support clinical
diag- nosis, but most approaches rely on static, fully observed datasets and
fail to reflect the sequential, resource-aware reasoning clinicians use in
practice. Diagnosis remains complex and error prone, especially in
high-pressure or resource-limited settings, underscoring the need for
frameworks that help clinicians make timely and cost-effective decisions. We
propose ACTMED (Adaptive Clinical Test selection via Model-based Experimental
Design), a diagnostic framework that integrates Bayesian Experimental Design
(BED) with large language models (LLMs) to better emulate real-world diagnostic
reasoning. At each step, ACTMED selects the test expected to yield the greatest
reduction in diagnostic uncertainty for a given patient. LLMs act as flexible
simulators, generating plausible patient state distributions and supporting
belief updates without requiring structured, task-specific training data.
Clinicians can remain in the loop; reviewing test suggestions, interpreting
intermediate outputs, and applying clinical judgment throughout. We evaluate
ACTMED on real-world datasets and show it can optimize test selection to
improve diagnostic accuracy, interpretability, and resource use. This
represents a step to- ward transparent, adaptive, and clinician-aligned
diagnostic systems that generalize across settings with reduced reliance on
domain-specific data.

</details>


### [5] [Rectifying Shortcut Behaviors in Preference-based Reward Learning](https://arxiv.org/abs/2510.19050)
*Wenqian Ye,Guangtao Zheng,Aidong Zhang*

Main category: cs.AI

TL;DR: 提出PRISM方法，通过组不变核学习来缓解基于偏好的奖励模型中的捷径行为问题，提高奖励模型在分布外任务上的准确性和下游策略模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于人类反馈的强化学习中，偏好奖励模型容易受到奖励攻击和泛化能力差的问题，模型倾向于利用训练数据中的虚假特征（如回答冗长、讨好语气等）来获得高奖励分数，而非真正反映预期目标。

Method: 受核视角不变性理论启发，提出PRISM方法，通过闭式学习目标学习具有特征映射的组不变核，以缓解偏好奖励学习中的捷径行为。

Result: 在多个基准测试中，该方法一致提高了奖励模型在多样化分布外任务上的准确性，并减少了下游策略模型对捷径的依赖。

Conclusion: PRISM为基于偏好的对齐建立了一个鲁棒框架，有效缓解了奖励模型中的捷径行为问题。

Abstract: In reinforcement learning from human feedback, preference-based reward models
play a central role in aligning large language models to human-aligned
behavior. However, recent studies show that these models are prone to reward
hacking and often fail to generalize well due to over-optimization. They
achieve high reward scores by exploiting shortcuts, that is, exploiting
spurious features (e.g., response verbosity, agreeable tone, or sycophancy)
that correlate with human preference labels in the training data rather than
genuinely reflecting the intended objectives. In this paper, instead of probing
these issues one at a time, we take a broader view of the reward hacking
problem as shortcut behaviors and introduce a principled yet flexible approach
to mitigate shortcut behaviors in preference-based reward learning. Inspired by
the invariant theory in the kernel perspective, we propose Preference-based
Reward Invariance for Shortcut Mitigation (PRISM), which learns group-invariant
kernels with feature maps in a closed-form learning objective. Experimental
results in several benchmarks show that our method consistently improves the
accuracy of the reward model on diverse out-of-distribution tasks and reduces
the dependency on shortcuts in downstream policy models, establishing a robust
framework for preference-based alignment.

</details>


### [6] [The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS](https://arxiv.org/abs/2510.19055)
*Brandon James Carone,Iran R. Roman,Pablo Ripollés*

Main category: cs.AI

TL;DR: 提出了MUSE基准测试来评估多模态大语言模型的音乐理解能力，发现现有模型在关系推理方面存在严重缺陷，与人类专家存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在音频理解方面的评估可能掩盖了其在关系推理方面的基本弱点，需要更全面的评估工具。

Method: 开发了包含10个任务的MUSE基准测试，评估了4个SOTA模型（Gemini Pro和Flash、Qwen2.5-Omni、Audio-Flamingo 3），并与200人的基线进行比较。

Result: SOTA模型能力差异很大，与人类专家存在持续差距。Gemini Pro在基础感知上表现良好，但Qwen和Audio Flamingo 3表现接近随机水平。思维链提示效果不稳定且往往有害。

Conclusion: MUSE基准为评估不变音乐表示和开发更鲁棒的AI系统提供了关键工具。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated capabilities in
audio understanding, but current evaluations may obscure fundamental weaknesses
in relational reasoning. We introduce the Music Understanding and Structural
Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to
probe fundamental music perception skills. We evaluate four SOTA models (Gemini
Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human
baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a
persistent gap with human experts. While Gemini Pro succeeds on basic
perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing
severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)
prompting provides inconsistent, often detrimental results. Our work provides a
critical tool for evaluating invariant musical representations and driving
development of more robust AI systems.

</details>


### [7] [A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist](https://arxiv.org/abs/2510.19139)
*Sohyeon Jeon,Hyung-Chul Lee*

Main category: cs.AI

TL;DR: 本研究采用行为和元认知分析方法，系统比较了两种代表性大语言模型在三种提示条件下评估临床试验报告CONSORT标准的能力，揭示了模型在推理风格、不确定性表达和解释策略上的差异。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在医疗领域迅速扩展，但这些系统根据CONSORT标准评估临床试验报告的能力仍不明确，特别是在认知和推理策略方面。

Method: 应用行为和元认知分析方法，使用专家验证数据，系统比较两种代表性大语言模型在三种提示条件下的表现。

Result: 模型在处理不同CONSORT项目和提示类型时表现出明显差异，包括推理风格的转变、明确的不确定性表达和替代解释策略影响响应模式。

Conclusion: 结果凸显了这些系统在临床合规自动化方面的当前局限性，并强调了理解其认知适应和策略行为对于开发更可解释和可靠的医疗AI的重要性。

Abstract: Despite the rapid expansion of Large Language Models (LLMs) in healthcare,
the ability of these systems to assess clinical trial reporting according to
CONSORT standards remains unclear, particularly with respect to their cognitive
and reasoning strategies. This study applies a behavioral and metacognitive
analytic approach with expert-validated data, systematically comparing two
representative LLMs under three prompt conditions. Clear differences emerged in
how the models approached various CONSORT items, and prompt types, including
shifts in reasoning style, explicit uncertainty, and alternative
interpretations shaped response patterns. Our results highlight the current
limitations of these systems in clinical compliance automation and underscore
the importance of understanding their cognitive adaptations and strategic
behavior in developing more explainable and reliable medical AI.

</details>


### [8] [The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models](https://arxiv.org/abs/2510.19176)
*Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao*

Main category: cs.AI

TL;DR: 本文探讨了推理模型中的模式选择问题，将其识别为早期退出问题的更具挑战性变体，旨在通过零步思考减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 推理模型在数学和逻辑推理任务中表现出色，但逐步思考过程常导致过度思考和不必要的计算开销。模式选择和早期退出方法都旨在减轻这种计算负担。

Method: 将模式选择视为早期退出问题的变体，比较了九种基线方法，包括基于提示的方法和利用模型内部信息的方法。

Result: 基于提示的方法由于分类能力有限而经常失败，而利用内部信息的方法在大多数场景中表现更好但仍存在稳定性问题。

Conclusion: 现有仅依赖模型提供信息的方法不足以有效解决信息有限场景下的模式选择问题，凸显了该任务的持续挑战。

Abstract: Reasoning models have demonstrated exceptional performance in tasks such as
mathematics and logical reasoning, primarily due to their ability to engage in
step-by-step thinking during the reasoning process. However, this often leads
to overthinking, resulting in unnecessary computational overhead. To address
this issue, Mode Selection aims to automatically decide between Long-CoT
(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking
mode. Simultaneously, Early Exit determines the optimal stopping point during
the iterative reasoning process. Both methods seek to reduce the computational
burden. In this paper, we first identify Mode Selection as a more challenging
variant of the Early Exit problem, as they share similar objectives but differ
in decision timing. While Early Exit focuses on determining the best stopping
point for concise reasoning at inference time, Mode Selection must make this
decision at the beginning of the reasoning process, relying on pre-defined fake
thoughts without engaging in an explicit reasoning process, referred to as
zero-step thinking. Through empirical studies on nine baselines, we observe
that prompt-based approaches often fail due to their limited classification
capabilities when provided with minimal hand-crafted information. In contrast,
approaches that leverage internal information generally perform better across
most scenarios but still exhibit issues with stability. Our findings indicate
that existing methods relying solely on the information provided by models are
insufficient for effectively addressing Mode Selection in scenarios with
limited information, highlighting the ongoing challenges of this task. Our code
is available at https://github.com/Trae1ounG/Zero_Step_Thinking.

</details>


### [9] [WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation](https://arxiv.org/abs/2510.19205)
*Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang*

Main category: cs.AI

TL;DR: WebGraphEval是一个将多个智能体的网页交互轨迹抽象为统一加权动作图的框架，支持多路径、跨智能体且关注效率的评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前网页智能体评估主要依赖二元成功指标或单一参考轨迹，忽略了基准数据集中存在的结构多样性问题。

Method: 将多个智能体的轨迹抽象为统一的加权动作图，规范编码动作，合并重复行为，并应用包括奖励传播和成功加权边统计在内的结构分析。

Result: 在六个网页智能体的数千条轨迹评估中，图抽象捕捉了跨模型规律性，突出了冗余和低效问题，并识别了基于结果指标所忽略的关键决策点。

Conclusion: 通过将网页交互构建为图结构数据，WebGraphEval为网页智能体建立了多路径、跨智能体和效率感知的通用评估方法。

Abstract: Current evaluation of web agents largely reduces to binary success metrics or
conformity to a single reference trajectory, ignoring the structural diversity
present in benchmark datasets. We present WebGraphEval, a framework that
abstracts trajectories from multiple agents into a unified, weighted action
graph. This representation is directly compatible with benchmarks such as
WebArena, leveraging leaderboard runs and newly collected trajectories without
modifying environments. The framework canonically encodes actions, merges
recurring behaviors, and applies structural analyses including reward
propagation and success-weighted edge statistics. Evaluations across thousands
of trajectories from six web agents show that the graph abstraction captures
cross-model regularities, highlights redundancy and inefficiency, and
identifies critical decision points overlooked by outcome-based metrics. By
framing web interaction as graph-structured data, WebGraphEval establishes a
general methodology for multi-path, cross-agent, and efficiency-aware
evaluation of web agents.

</details>


### [10] [ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate](https://arxiv.org/abs/2510.19261)
*Marianna Molinari,Ilaria Angela Amantea,Marinella Quaranta,Guido Governatori*

Main category: cs.AI

TL;DR: 本研究通过实验评估ChatGPT在法律领域的表现，发现即使具备相关知识能力，ChatGPT仍无法整合推理得出全面结果，揭示了其重大局限性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估ChatGPT在法律领域的实际表现，特别是与正则表达式基线对比，而非仅与人类表现比较，以揭示AI在法律推理中的真实能力局限。

Method: 采用实验方法，将ChatGPT在法律决策中提取法律原则关键段落的表现与正则表达式(Regex)基线进行比较分析。

Result: 研究发现ChatGPT即使拥有必要知识和能力，也无法有效整合推理得出全面结果，在法律领域缺乏整体理解和推理能力。

Conclusion: 真正的智能仍然是人类独有的特质，至少在法律领域，AI由于缺乏全面理解和推理能力而存在固有局限性。

Abstract: This study examines the performance of ChatGPT with an experiment in the
legal domain. We compare the outcome with it a baseline using regular
expressions (Regex), rather than focusing solely on the assessment against
human performance. The study reveals that even if ChatGPT has access to the
necessary knowledge and competencies, it is unable to assemble them, reason
through, in a way that leads to an exhaustive result. This unveils a major
limitation of ChatGPT. Intelligence encompasses the ability to break down
complex issues and address them according to multiple required competencies,
providing a unified and comprehensive solution. In the legal domain, one of the
most crucial tasks is reading legal decisions and extracting key passages
condensed from principles of law (PoLs), which are then incorporated into
subsequent rulings by judges or defense documents by lawyers. In performing
this task, artificial intelligence lacks an all-encompassing understanding and
reasoning, which makes it inherently limited. Genuine intelligence, remains a
uniquely human trait, at least in this particular field.

</details>


### [11] [An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents](https://arxiv.org/abs/2510.19263)
*Wachara Fungwacharakorn,Gauvain Bourgne,Ken Satoh*

Main category: cs.AI

TL;DR: 本文扩展了推导状态论证框架(DSA-framework)，为容纳不一致先例的广义推理模型提供论证性解释方法。


<details>
  <summary>Details</summary>
Motivation: 传统先例推理假设先例集必须一致，但广义推理模型放松了这一假设。目前已有基于传统一致推理模型的论证性解释方法，但尚无针对容纳不一致先例的广义推理框架的相应论证解释方法。

Method: 扩展推导状态论证框架(DSA-framework)，使其能够解释基于广义推理模型的推理过程。

Result: 开发了能够处理不一致先例的论证性解释框架。

Conclusion: 成功扩展了DSA框架，为广义推理模型提供了论证性解释能力，填补了该领域的研究空白。

Abstract: Precedential constraint is one foundation of case-based reasoning in AI and
Law. It generally assumes that the underlying set of precedents must be
consistent. To relax this assumption, a generalized notion of the reason model
has been introduced. While several argumentative explanation approaches exist
for reasoning with precedents based on the traditional consistent reason model,
there has been no corresponding argumentative explanation method developed for
this generalized reasoning framework accommodating inconsistent precedents. To
address this question, this paper examines an extension of the derivation state
argumentation framework (DSA-framework) to explain the reasoning according to
the generalized notion of the reason model.

</details>


### [12] [Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties](https://arxiv.org/abs/2510.19299)
*Philipp J. Schneider,Lin Tian,Marian-Andrei Rizoiu*

Main category: cs.AI

TL;DR: 提出了一个多智能体LLM模拟框架，通过行为奖励函数和情境学习来研究LLM智能体是否能重现人类在线社交动态，包括同质性、互惠性和社交验证等特征。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型智能体能否重现人类在线行为的复杂社交动态，以及什么记忆和学习机制能够促成这种动态的出现。

Method: 设计了一个多智能体LLM模拟框架，智能体通过重复互动、相互评估和行为适应，结合行为奖励函数（捕捉社交互动、信息寻求、自我展示、协调和情感支持等核心驱动因素）和情境学习加速机制。

Result: 实验表明，经过指导的LLM智能体能够发展出稳定的互动模式并形成涌现的社交联系，产生的网络结构反映了真实在线社区的特性。

Conclusion: 该框架为研究LLM群体中的集体动态建立了一个原则性测试平台，揭示了人工智能智能体如何近似或偏离类人社交行为。

Abstract: Can large language model (LLM) agents reproduce the complex social dynamics
that characterize human online behavior -- shaped by homophily, reciprocity,
and social validation -- and what memory and learning mechanisms enable such
dynamics to emerge? We present a multi-agent LLM simulation framework in which
agents repeatedly interact, evaluate one another, and adapt their behavior
through in-context learning accelerated by a coaching signal. To model human
social behavior, we design behavioral reward functions that capture core
drivers of online engagement, including social interaction, information
seeking, self-presentation, coordination, and emotional support. These rewards
align agent objectives with empirically observed user motivations, enabling the
study of how network structures and group formations emerge from individual
decision-making. Our experiments show that coached LLM agents develop stable
interaction patterns and form emergent social ties, yielding network structures
that mirror properties of real online communities. By combining behavioral
rewards with in-context adaptation, our framework establishes a principled
testbed for investigating collective dynamics in LLM populations and reveals
how artificial agents may approximate or diverge from human-like social
behavior.

</details>


### [13] [Continual Knowledge Adaptation for Reinforcement Learning](https://arxiv.org/abs/2510.19314)
*Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan*

Main category: cs.AI

TL;DR: 提出了CKA-RL方法，通过持续知识适应策略和自适应知识合并机制来解决强化学习中的灾难性遗忘问题，在三个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界环境通常是非平稳的，需要智能体持续适应新任务和变化条件。现有的持续强化学习方法存在灾难性遗忘和知识利用效率低的问题。

Method: 提出持续知识适应策略，维护任务特定知识向量池，动态使用历史知识来适应新任务；引入自适应知识合并机制，合并相似知识向量以减少内存需求。

Result: 在三个基准测试中，CKA-RL优于最先进方法，整体性能提升4.20%，前向迁移提升8.02%。

Conclusion: CKA-RL通过有效积累和利用历史知识，成功解决了持续强化学习中的灾难性遗忘问题，实现了高效的知识迁移。

Abstract: Reinforcement Learning enables agents to learn optimal behaviors through
interactions with environments. However, real-world environments are typically
non-stationary, requiring agents to continuously adapt to new tasks and
changing conditions. Although Continual Reinforcement Learning facilitates
learning across multiple tasks, existing methods often suffer from catastrophic
forgetting and inefficient knowledge utilization. To address these challenges,
we propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),
which enables the accumulation and effective utilization of historical
knowledge. Specifically, we introduce a Continual Knowledge Adaptation
strategy, which involves maintaining a task-specific knowledge vector pool and
dynamically using historical knowledge to adapt the agent to new tasks. This
process mitigates catastrophic forgetting and enables efficient knowledge
transfer across tasks by preserving and adapting critical model parameters.
Additionally, we propose an Adaptive Knowledge Merging mechanism that combines
similar knowledge vectors to address scalability challenges, reducing memory
requirements while ensuring the retention of essential knowledge. Experiments
on three benchmarks demonstrate that the proposed CKA-RL outperforms
state-of-the-art methods, achieving an improvement of 4.20% in overall
performance and 8.02% in forward transfer. The source code is available at
https://github.com/Fhujinwu/CKA-RL.

</details>


### [14] [MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration](https://arxiv.org/abs/2510.19423)
*Jia-Kai Dong,I-Wei Huang,Chun-Tin Wu,Yi-Tien Tsai*

Main category: cs.AI

TL;DR: MSC-Bench是一个用于评估LLM代理在多跳、端到端工具编排能力的大规模基准测试，通过构建"等效功能集"来建立真实基准，减少对LLM作为评判的依赖，并采用五级课程设计系统测试代理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往孤立评估工具，忽略了功能重叠和跨服务器编排等挑战，导致评估过于乐观。MSC-Bench旨在解决这些问题，提供更客观的评估框架。

Method: 构建"等效功能集"作为真实基准，采用五级课程设计，从单工具编排到复杂跨服务器规划，再到超出范围请求的鲁棒性测试。

Result: 实验表明，僵化的层次结构会阻碍性能，即使最先进的代理在鲁棒性方面也存在系统性弱点。

Conclusion: MSC-Bench提供了一个诊断框架，能够暴露现有工具的局限性，并指导开发更强大、高效的工具使用代理。

Abstract: We introduce MSC-Bench, a large-scale benchmark for evaluating multi-hop,
end-to-end tool orchestration by LLM agents in a hierarchical Model-Context
Protocol (MCP) ecosystem. Existing benchmarks often evaluate tools in
isolation, ignoring challenges such as functional overlap and cross-server
orchestration, leading to overly optimistic assessments. MSC-Bench addresses
these gaps by constructing ground truth through 'equal function sets', allowing
objective metrics such as F1 score and reducing the dependency on
LLM-as-a-judge evaluation. Organized as a five-level curriculum, it
systematically tests agent capabilities from single-tool orchestration to
complex cross-server planning, and robustness to out-of-scope requests.
Experiments reveal that rigid hierarchies can hinder performance without
co-designed strategies, and even state-of-the-art agents exhibit systemic
weaknesses in robustness. MSC-Bench provides a diagnostic framework to expose
these limitations and guide the development of more capable and efficient
tool-using agents. The benchmark and resources are publicly available at
https://github.com/snooow1029/MSC_Bench.

</details>


### [15] [NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning](https://arxiv.org/abs/2510.19429)
*Wonje Choi,Jooyoung Kim,Honguk Woo*

Main category: cs.AI

TL;DR: NeSyPr是一个新颖的具身推理框架，通过神经符号程序化将符号知识编译为可组合的过程表示，使语言模型能够在动态环境中进行高效推理，无需依赖外部符号规划器。


<details>
  <summary>Details</summary>
Motivation: 解决在动态环境中使用语言模型进行具身任务时面临的延迟、连接性和资源限制问题，避免在线访问大规模推理引擎或符号规划器的需求。

Method: 首先使用符号工具生成任务特定计划，然后将这些计划转化为可组合的程序表示，编码计划的隐式产生规则，使组合后的过程能够无缝集成到语言模型的推理过程中。

Result: 在PDDLGym、VirtualHome和ALFWorld等具身基准测试中，NeSyPr展示了比大规模推理模型和符号规划器更高效的推理能力，同时使用更紧凑的语言模型。

Conclusion: 神经符号程序化能够将多步符号结构化路径查找和推理抽象为单步语言模型推理，适合在延迟敏感和资源受限的物理系统中部署。

Abstract: We address the challenge of adopting language models (LMs) for embodied tasks
in dynamic environments, where online access to large-scale inference engines
or symbolic planners is constrained due to latency, connectivity, and resource
limitations. To this end, we present NeSyPr, a novel embodied reasoning
framework that compiles knowledge via neurosymbolic proceduralization, thereby
equipping LM-based agents with structured, adaptive, and timely reasoning
capabilities. In NeSyPr, task-specific plans are first explicitly generated by
a symbolic tool leveraging its declarative knowledge. These plans are then
transformed into composable procedural representations that encode the plans'
implicit production rules, enabling the resulting composed procedures to be
seamlessly integrated into the LM's inference process. This neurosymbolic
proceduralization abstracts and generalizes multi-step symbolic structured
path-finding and reasoning into single-step LM inference, akin to human
knowledge compilation. It supports efficient test-time inference without
relying on external symbolic guidance, making it well suited for deployment in
latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr
on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating
its efficient reasoning capabilities over large-scale reasoning models and a
symbolic planner, while using more compact LMs.

</details>


### [16] [DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.19562)
*Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU*

Main category: cs.AI

TL;DR: DAIL是一种解决语言指令模糊性的新方法，通过分布策略和语义对齐来增强任务可区分性，在结构和视觉观察基准测试中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 自然语言指令的灵活性导致跨语言条件任务存在严重模糊性，这会显著降低算法性能。

Method: 提出DAIL方法，包含两个关键组件：分布策略和语义对齐模块。分布策略通过价值分布估计机制增强任务可区分性，语义对齐模块捕捉轨迹与语言指令之间的对应关系。

Result: 在结构和视觉观察基准测试上的广泛实验结果表明，DAIL能有效解决指令模糊性问题，性能优于基线方法。

Conclusion: DAIL通过分布对齐学习成功解决了语言指令的模糊性问题，为智能代理理解自然语言和遵循人类指令提供了有效解决方案。

Abstract: Comprehending natural language and following human instructions are critical
capabilities for intelligent agents. However, the flexibility of linguistic
instructions induces substantial ambiguity across language-conditioned tasks,
severely degrading algorithmic performance. To address these limitations, we
present a novel method named DAIL (Distributional Aligned Learning), featuring
two key components: distributional policy and semantic alignment. Specifically,
we provide theoretical results that the value distribution estimation mechanism
enhances task differentiability. Meanwhile, the semantic alignment module
captures the correspondence between trajectories and linguistic instructions.
Extensive experimental results on both structured and visual observation
benchmarks demonstrate that DAIL effectively resolves instruction ambiguities,
achieving superior performance to baseline methods. Our implementation is
available at https://github.com/RunpengXie/Distributional-Aligned-Learning.

</details>


### [17] [HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application](https://arxiv.org/abs/2510.19631)
*Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.AI

TL;DR: HSCodeComp是首个评估深度搜索代理在分层规则应用能力的电子商务基准，要求代理根据产品描述预测10位HS编码，结果显示最佳代理准确率仅46.8%，远低于人类专家的95.0%。


<details>
  <summary>Details</summary>
Motivation: 当前代理基准忽略了深度搜索代理需要应用复杂规则（如法律条款、医疗手册、关税规则）的关键能力，这些规则具有模糊边界和隐含逻辑关系。

Method: 从大型电商平台收集真实数据构建HSCodeComp基准，包含632个产品条目，涵盖多样化产品类别，HS编码由多位人类专家标注。

Result: 在多个最先进的LLM、开源和闭源代理上的实验显示巨大性能差距：最佳代理仅达到46.8%的10位准确率，远低于人类专家的95.0%。测试时扩展也无法进一步提升性能。

Conclusion: 分层规则应用对当前代理具有挑战性，需要开发更强大的深度搜索代理来处理复杂规则推理任务。

Abstract: Effective deep search agents must not only access open-domain and
domain-specific knowledge but also apply complex rules-such as legal clauses,
medical manuals and tariff rules. These rules often feature vague boundaries
and implicit logic relationships, making precise application challenging for
agents. However, this critical capability is largely overlooked by current
agent benchmarks.
  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level
e-commerce benchmark designed to evaluate deep search agents in hierarchical
rule application. In this task, the deep reasoning process of agents is guided
by these rules to predict 10-digit Harmonized System Code (HSCode) of products
with noisy but realistic descriptions. These codes, established by the World
Customs Organization, are vital for global supply chain efficiency. Built from
real-world data collected from large-scale e-commerce platforms, our proposed
HSCodeComp comprises 632 product entries spanning diverse product categories,
with these HSCodes annotated by several human experts.
  Extensive experimental results on several state-of-the-art LLMs, open-source,
and closed-source agents reveal a huge performance gap: best agent achieves
only 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,
detailed analysis demonstrates the challenges of hierarchical rule application,
and test-time scaling fails to improve performance further.

</details>


### [18] [AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing](https://arxiv.org/abs/2510.19661)
*Xusen Guo,Mingxing Peng,Xixuan Hao,Xingchen Zou,Qiongyan Wang,Sijie Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: AgentSense是一个基于多智能体进化系统的混合训练免费框架，将大语言模型集成到参与式城市感知中，通过迭代优化提升自适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的城市感知系统在跨不同城市场景的泛化能力和决策可解释性方面存在局限，需要开发更适应动态城市条件和异构工作者偏好的解决方案。

Method: 结合经典规划器生成基线解决方案，然后通过多智能体进化系统迭代优化，使感知任务分配适应动态城市条件，同时生成自然语言解释增强透明度。

Result: 在两个大规模移动数据集和七种动态干扰上的实验表明，AgentSense在自适应性和可解释性方面优于传统方法，相比单智能体LLM基线在性能和鲁棒性上表现更优。

Conclusion: AgentSense代表了向部署自适应和可解释城市感知系统的重要进展，为基于web的城市管理提供了更可靠的解决方案。

Abstract: Web-based participatory urban sensing has emerged as a vital approach for
modern urban management by leveraging mobile individuals as distributed
sensors. However, existing urban sensing systems struggle with limited
generalization across diverse urban scenarios and poor interpretability in
decision-making. In this work, we introduce AgentSense, a hybrid, training-free
framework that integrates large language models (LLMs) into participatory urban
sensing through a multi-agent evolution system. AgentSense initially employs
classical planner to generate baseline solutions and then iteratively refines
them to adapt sensing task assignments to dynamic urban conditions and
heterogeneous worker preferences, while producing natural language explanations
that enhance transparency and trust. Extensive experiments across two
large-scale mobility datasets and seven types of dynamic disturbances
demonstrate that AgentSense offers distinct advantages in adaptivity and
explainability over traditional methods. Furthermore, compared to single-agent
LLM baselines, our approach outperforms in both performance and robustness,
while delivering more reasonable and transparent explanations. These results
position AgentSense as a significant advancement towards deploying adaptive and
explainable urban sensing systems on the web.

</details>


### [19] [A Graph Engine for Guitar Chord-Tone Soloing Education](https://arxiv.org/abs/2510.19666)
*Matthew Keating,Michael Casey*

Main category: cs.AI

TL;DR: 开发了一个基于图论的吉他即兴演奏建议引擎，通过构建和弦音阶图并计算最短路径来生成和弦音独奏线。


<details>
  <summary>Details</summary>
Motivation: 和弦音独奏是爵士吉他即兴演奏的基础练习，但学习难度大，需要系统化的练习工具来帮助学生掌握这一技能。

Method: 首先生成和弦音阶，然后构建加权图（节点代表和弦音阶，边权重基于最优过渡音计算），最后通过寻找最短路径重构和弦音独奏线。

Result: 开发了一个用户友好的系统，能够为吉他学生提供和弦音独奏练习建议。

Conclusion: 该图论引擎为吉他学生提供了有效的和弦音独奏练习工具，有助于掌握爵士吉他即兴演奏的基础技能。

Abstract: We present a graph-based engine for computing chord tone soloing suggestions
for guitar students. Chord tone soloing is a fundamental practice for
improvising over a chord progression, where the instrumentalist uses only the
notes contained in the current chord. This practice is a building block for all
advanced jazz guitar theory but is difficult to learn and practice. First, we
discuss methods for generating chord-tone arpeggios. Next, we construct a
weighted graph where each node represents a chord tone arpeggio for a chord in
the progression. Then, we calculate the edge weight between each consecutive
chord's nodes in terms of optimal transition tones. We then find the shortest
path through this graph and reconstruct a chord-tone soloing line. Finally, we
discuss a user-friendly system to handle input and output to this engine for
guitar students to practice chord tone soloing.

</details>


### [20] [Explainable e-sports win prediction through Machine Learning classification in streaming](https://arxiv.org/abs/2510.19671)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.AI

TL;DR: 提出了一种可解释的电子竞技流式胜率预测分类解决方案，通过滑动窗口控制输入数据以反映游戏变化，准确率超过90%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子竞技观众和玩家数量增长，加上通信技术和云计算发展，推动了在线游戏产业发展。传统AI解决方案主要关注批量分类，忽略了可视化技术和流式处理。

Method: 采用可解释的胜率预测分类方法，通过多个滑动窗口控制输入数据，以反映游戏中的相关变化。

Result: 实验结果显示准确率超过90%，超越了文献中的竞争解决方案。

Conclusion: 该系统可被排名和推荐系统利用，用于知情决策，其可解释性模块增强了预测结果的可信度。

Abstract: The increasing number of spectators and players in e-sports, along with the
development of optimized communication solutions and cloud computing
technology, has motivated the constant growth of the online game industry. Even
though Artificial Intelligence-based solutions for e-sports analytics are
traditionally defined as extracting meaningful patterns from related data and
visualizing them to enhance decision-making, most of the effort in professional
winning prediction has been focused on the classification aspect from a batch
perspective, also leaving aside the visualization techniques. Consequently,
this work contributes to an explainable win prediction classification solution
in streaming in which input data is controlled over several sliding windows to
reflect relevant game changes. Experimental results attained an accuracy higher
than 90 %, surpassing the performance of competing solutions in the literature.
Ultimately, our system can be leveraged by ranking and recommender systems for
informed decision-making, thanks to the explainability module, which fosters
trust in the outcome predictions.

</details>


### [21] [RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models](https://arxiv.org/abs/2510.19698)
*Yang Yang,Hua XU,Zhangyi Hu,Yutao Yue*

Main category: cs.AI

TL;DR: RLIE框架将大语言模型与概率建模结合，学习带权重的规则集，通过四个阶段实现：规则生成、逻辑回归学习权重、迭代优化和评估。研究发现直接使用学习到的权重规则优于将规则注入LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的规则学习方法忽视规则间的相互作用，且未充分探索将LLM与概率规则学习结合进行鲁棒推理的机会。

Method: RLIE框架包含四个阶段：1) LLM生成和筛选候选规则；2) 逻辑回归学习概率权重；3) 基于预测误差迭代优化规则集；4) 评估带权重规则集作为直接分类器的性能。

Result: 直接使用学习到的权重规则表现更优，而将规则、权重和逻辑模型输出注入LLM提示反而降低准确性，表明LLM擅长语义生成和解释，但在精确概率整合方面可靠性较低。

Conclusion: RLIE阐明了LLM在归纳推理中的潜力和局限性，通过将其与经典概率规则组合方法结合，实现了更可靠的神经符号推理。

Abstract: Large Language Models (LLMs) can propose rules in natural language,
sidestepping the need for a predefined predicate space in traditional rule
learning. Yet many LLM-based approaches ignore interactions among rules, and
the opportunity to couple LLMs with probabilistic rule learning for robust
inference remains underexplored. We present RLIE, a unified framework that
integrates LLMs with probabilistic modeling to learn a set of weighted rules.
RLIE has four stages: (1) Rule generation, where an LLM proposes and filters
candidates; (2) Logistic regression, which learns probabilistic weights for
global selection and calibration; (3) Iterative refinement, which updates the
rule set using prediction errors; and (4) Evaluation, which compares the
weighted rule set as a direct classifier with methods that inject rules into an
LLM. We evaluate multiple inference strategies on real-world datasets. Applying
rules directly with their learned weights yields superior performance, whereas
prompting LLMs with the rules, weights, and logistic-model outputs surprisingly
degrades accuracy. This supports the view that LLMs excel at semantic
generation and interpretation but are less reliable for precise probabilistic
integration. RLIE clarifies the potential and limitations of LLMs for inductive
reasoning and couples them with classic probabilistic rule combination methods
to enable more reliable neuro-symbolic reasoning.

</details>


### [22] [Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning](https://arxiv.org/abs/2510.19732)
*Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi*

Main category: cs.AI

TL;DR: 提出Memo：一种用于强化学习的transformer架构和训练方法，通过记忆创建和检索机制处理长时程任务，在计算和存储效率上优于传统长上下文transformer。


<details>
  <summary>Details</summary>
Motivation: 现有transformer策略在具身决策任务中视觉输入容易超出上下文限制，而人类能够将终身经验压缩为记忆使用。需要开发能够形成和访问记忆的模型来维持环境上下文。

Method: Memo在训练期间通过定期插入总结标记来创建和检索记忆，将记忆机制整合到transformer架构中。

Result: 在网格世界元强化学习基准和逼真室内多目标导航任务中，Memo优于传统长上下文transformer基线，计算和存储效率更高，在推理时对更长上下文具有更好的泛化能力。

Conclusion: Memo通过记忆创建和检索机制有效解决了长时程任务中的上下文限制问题，在保持性能的同时提高了效率，并在流式设置中保持鲁棒性。

Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement learning (RL) on
memory-intensive, long-horizon tasks. Memo incorporates the creation and
retrieval of memory by interleaving periodic summarization tokens with the
inputs of a model during training. We demonstrate Memo's effectiveness on a
gridworld meta-RL benchmark and a multi-object navigation task in
photo-realistic indoor settings. Memo outperforms naive long-context
transformer baselines while being more compute and storage efficient.
Additionally, Memo generalizes better to longer contexts at inference time and
remains robust in streaming settings, where historical context must be
truncated to fit inference constraints.

</details>


### [23] [Misalignment Bounty: Crowdsourcing AI Agent Misbehavior](https://arxiv.org/abs/2510.19738)
*Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov*

Main category: cs.AI

TL;DR: 该论文介绍了'错位赏金'项目，这是一个众包项目，旨在收集AI系统追求非预期或不安全目标的案例。项目收到了295份提交，其中9份获奖。


<details>
  <summary>Details</summary>
Motivation: 收集清晰、可复现的AI系统与人类意图不一致的行为案例，以更好地理解和解决AI错位问题。

Method: 通过众包项目'错位赏金'收集案例，使用明确的评估标准对提交进行评审，最终选出9个获奖案例。

Result: 项目成功收集了295份提交，其中9份被认定为有价值的AI错位案例，展示了AI系统追求非预期或不安全目标的具体情况。

Conclusion: 通过众包方式可以有效识别和记录AI系统的错位行为，这有助于提高对AI安全问题的认识，并为未来研究和改进提供实际案例参考。

Abstract: Advanced AI systems sometimes act in ways that differ from human intent. To
gather clear, reproducible examples, we ran the Misalignment Bounty: a
crowdsourced project that collected cases of agents pursuing unintended or
unsafe goals. The bounty received 295 submissions, of which nine were awarded.
  This report explains the program's motivation and evaluation criteria, and
walks through the nine winning submissions step by step.

</details>


### [24] [Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents](https://arxiv.org/abs/2510.19771)
*Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis*

Main category: cs.AI

TL;DR: 提出了PROBE基准来评估LLM智能体的主动性能力，将主动性分解为三个核心能力：搜索未指定问题、识别具体瓶颈和执行适当解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前评估主动性的基准局限于局部上下文，无法测试跨来源和长时间范围的推理能力，需要新的评估方法。

Method: 设计PROBE基准，将主动性分解为三个核心能力管道，并应用于评估领先的LLM和流行智能体框架。

Result: 即使是先进的模型也难以解决该基准，GPT-5和Claude Opus-4.1的最佳端到端性能仅为40%，揭示了当前自主行动系统的局限性。

Conclusion: 结果突显了智能体系统中自主行动的当前局限性，并揭示了有前景的未来研究方向。

Abstract: LLM-based agents are increasingly moving towards proactivity: rather than
awaiting instruction, they exercise agency to anticipate user needs and solve
them autonomously. However, evaluating proactivity is challenging; current
benchmarks are constrained to localized context, limiting their ability to test
reasoning across sources and longer time horizons. To address this gap, we
present PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes
proactivity as a pipeline of three core capabilities: (1) searching for
unspecified issues, (2) identifying specific bottlenecks, and (3) executing
appropriate resolutions. We apply PROBE to evaluate leading LLMs and popular
agentic frameworks, showing that even state-of-the-art models struggle to solve
this benchmark. Computing our consistent measurements across frontier LLMs and
agents, we find that the best end-to-end performance of 40% is achieved by both
GPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative
capabilities of each model and analyze mutual failure modes. Our results
highlight the current limitations of autonomous action in agentic systems, and
expose promising future research directions.

</details>


### [25] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: 提出了WorldTest评估协议和AutumnBench测试套件，用于评估模型学习智能体在不同环境中的世界模型能力，发现人类表现优于前沿模型，计算规模扩展仅在部分环境中有效。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型学习和评估方法局限于下一帧预测和相同环境中的奖励最大化，无法评估模型对多种下游任务的支持能力。

Method: 开发了WorldTest协议：奖励无关的探索阶段+不同但相关环境中的测试阶段，包含43个网格世界环境和129个任务，涵盖掩码帧预测、规划和因果动态变化预测。

Result: 517名人类参与者表现优于三个前沿模型，计算规模扩展仅在部分环境中提升性能，在其他环境中无效。

Conclusion: WorldTest提供了评估智能体对环境动态学习的新模板，AutumnBench揭示了世界模型学习的显著提升空间。

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [26] [Recursive decoding of binary rank Reed-Muller codes and Plotkin construction for matrix codes](https://arxiv.org/abs/2510.19095)
*Alain Couvreur,Rakhi Pratihar*

Main category: cs.IT

TL;DR: 提出了一种用于秩度量Reed-Muller码的解码算法，在二进制情况下利用递归Plotkin结构，其渐近复杂度优于基于Dickson矩阵的现有算法。


<details>
  <summary>Details</summary>
Motivation: Augot等人于2021年引入了秩度量Reed-Muller码，作为Hamming度量Reed-Muller码的秩度量对应物。本文旨在为这类新码设计高效解码算法。

Method: 采用递归Plotkin "(u | u+v)"结构，灵感来自Hamming度量二进制Reed-Muller码的解码方法。算法针对特定子类，并提出了通用的类Plotkin构造用于矩阵秩度量码。

Result: 所提出的递归算法在渐近复杂度上优于基于Dickson矩阵的解码算法，且具有完全不同的性质。算法自然地导出了秩度量版本的Plotkin构造。

Conclusion: 成功开发了秩度量Reed-Muller码的高效解码算法，并建立了秩度量码的类Plotkin构造框架，为秩度量码的解码提供了新思路。

Abstract: In 2021, Augot, Couvreur, Lavauzelle and Neri introduced a new class of rank
metric codes which can be regarded as rank metric counterparts of Reed-Muller
codes. Given a finite Galois extension $\mathbb{L} / \mathbb{K}$, these codes
are defined as some specific $\mathbb{L}$-subspaces of the twisted group
algebra $\mathbb{L} [\textrm{G}]$. We investigate the decoding of such codes in
the "binary" case, \emph{i.e.,} when $\textrm{G} = (\mathbb{Z}/2\mathbb{Z})^m$.
Our approach takes its inspiration from the decoding of Hamming metric binary
Reed-Muller codes using their recursive Plotkin "$(u ~|~ u+v)$" structure. If
our recursive algorithm restricts to a specific subclass of rank metric
Reed-Muller codes, its asymptotic complexity beats that of the recently
proposed decoding algorithm for arbitrary rank metric Reed-Muller codes based
on Dickson matrices. Also, this decoder is of completely different nature and
leads a natural rank metric counterpart of the Plotkin construction. To
illustrate this, we also propose a generic Plotkin-like construction for matrix
rank metric codes with an associate decoder, which can be applied to any pair
of codes equipped with an efficient decoder.

</details>


### [27] [Weighted Sum Rate Optimization for Movable Antenna Enabled Near-Field ISAC](https://arxiv.org/abs/2510.19759)
*Nemanja Stefan Perović,Keshav Singh,Chih-Peng Li,Mark F. Flanagan*

Main category: cs.IT

TL;DR: 本文研究了在近场集成感知与通信系统中使用可移动天线来最大化加权和速率，同时满足最小感知要求。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信是未来无线网络的关键技术，而可移动天线的引入有望进一步提升ISAC系统性能。但在近场环境下，球面波传播给MA-enabled ISAC系统带来了挑战。

Method: 提出了一种交替优化算法，同时优化感知接收合并器、通信预编码矩阵、感知发射波束形成器以及用户可移动天线的位置。

Result: 仿真结果表明，在近场ISAC系统中使用可移动天线相比仅使用固定天线具有显著的性能优势。当较大权重分配给靠近基站的用户时获得最高WSR，且感知性能受最小SINR阈值影响更大。

Conclusion: 可移动天线在近场ISAC系统中能显著提升性能，感知性能对最小SINR阈值更为敏感，靠近基站的用户应分配更高权重以获得最佳加权和速率。

Abstract: Integrated sensing and communication (ISAC) has been recognized as one of the
key technologies capable of simultaneously improving communication and sensing
services in future wireless networks. Moreover, the introduction of recently
developed movable antennas (MAs) has the potential to further increase the
performance gains of ISAC systems. Achieving these gains can pose a significant
challenge for MA-enabled ISAC systems operating in the near-field due to the
corresponding spherical wave propagation. Motivated by this, in this paper we
maximize the weighted sum rate (WSR) for communication users while maintaining
a minimal sensing requirement in an MA-enabled near-field ISAC system. To
achieve this goal, we propose an algorithm that optimizes the sensing receive
combiner, the communication precoding matrices, the sensing transmit beamformer
and the positions of the users' MAs in an alternating manner. Simulation
results show that using MAs in near-field ISAC systems provides a substantial
performance advantage compared to near-field ISAC systems with only fixed
antennas. Additionally, we demonstrate that the highest WSR is obtained when
larger weights are allocated to the users placed closer to the BS, and that the
sensing performance is significantly more affected by the minimum sensing
signal-to-interference-plus-noise ratio (SINR) threshold compared to the
communication performance.

</details>
