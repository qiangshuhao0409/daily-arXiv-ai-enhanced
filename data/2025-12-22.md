<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Enhancing AIGC Service Efficiency with Adaptive Multi-Edge Collaboration in A Distributed System](https://arxiv.org/abs/2512.17158)
*Changfu Xu,Jianxiong Guo,Jiandian Zeng,Houming Qiu,Tian Wang,Xiaowen Chu,Jiannong Cao*

Main category: cs.NI

TL;DR: 提出AMCoEdge方法，通过自适应多服务器协作移动边缘计算来提升AIGC服务效率，减少处理延迟和失败率。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC服务通常采用集中式框架，导致响应时间长。当前协作MEC方法主要支持单服务器卸载或固定边缘服务器交互，限制了灵活性和资源利用率，无法满足AIGC服务变化的计算和网络需求。

Method: 提出AMCoEdge方法，通过自适应多边缘服务器选择和动态工作负载分配，充分利用所有边缘服务器的计算和网络资源。采用基于深度强化学习的在线分布式算法，具有近似线性时间复杂度。

Result: 仿真结果显示，相比现有方法至少减少11.04%的任务卸载完成时间，降低44.86%的失败率。原型系统实现显示，实际AIGC服务延迟比三种代表性方法低9.23%-31.98%。

Conclusion: AMCoEdge方法通过自适应多服务器协作MEC有效提升了AIGC服务效率，显著减少了处理延迟和失败率，具有实际应用价值。

Abstract: The Artificial Intelligence Generated Content (AIGC) technique has gained significant traction for producing diverse content. However, existing AIGC services typically operate within a centralized framework, resulting in high response times. To address this issue, we integrate collaborative Mobile Edge Computing (MEC) technology to reduce processing delays for AIGC services. Current collaborative MEC methods primarily support single-server offloading or facilitate interactions among fixed Edge Servers (ESs), limiting flexibility and resource utilization across all ESs to meet the varying computing and networking requirements of AIGC services. We propose AMCoEdge, an adaptive multi-server collaborative MEC approach to enhancing AIGC service efficiency. The AMCoEdge fully utilizes the computing and networking resources across all ESs through adaptive multi-ES selection and dynamic workload allocation, thereby minimizing the offloading make-span of AIGC services. Our design features an online distributed algorithm based on deep reinforcement learning, accompanied by theoretical analyses that confirm an approximate linear time complexity. Simulation results show that our method outperforms state-of-the-art baselines, achieving at least an 11.04% reduction in task offloading make-span and a 44.86% decrease in failure rate. Additionally, we develop a distributed prototype system to implement and evaluate our AMCoEdge method for real AIGC service execution, demonstrating service delays that are 9.23% - 31.98% lower than the three representative methods.

</details>


### [2] [Timely Information Updating for Mobile Devices Without and With ML Advice](https://arxiv.org/abs/2512.17381)
*Yu-Pin Hsu,Yi-Hsuan Tseng*

Main category: cs.NI

TL;DR: 该论文研究移动设备监控物理过程并向接入点发送状态更新的信息更新系统，提出在线算法解决信息时效性与更新成本之间的权衡，并引入机器学习建议开发ML增强算法，达到最优一致性-鲁棒性权衡。


<details>
  <summary>Details</summary>
Motivation: 移动设备监控物理过程并向接入点发送状态更新时，存在信息时效性与更新成本之间的基本权衡。需要设计在线算法来处理这种权衡，同时考虑多种不确定性来源，包括操作持续时间、信息陈旧度、更新成本和更新机会可用性。

Method: 提出基于可用观测的在线算法决定何时传输更新，该算法渐近达到最优竞争比。进一步引入未知可靠性的机器学习建议，开发ML增强算法，即使对手可以破坏ML建议，也能达到最优一致性-鲁棒性权衡。算法对ML建议呈现阈值式响应：要么完全信任，要么完全忽略。

Result: 最优竞争比与更新成本范围呈线性关系，但不受其他不确定性影响。ML增强算法在对抗环境中达到最优一致性-鲁棒性权衡，且最优竞争在线算法对ML建议呈现阈值式响应。随机环境中的广泛仿真验证了对抗环境下的理论发现。

Conclusion: 该研究为信息更新系统提供了理论保证的在线算法，有效解决了信息时效性与更新成本的权衡问题。ML增强算法在对抗环境中表现优异，且发现最优算法对ML建议应采取全信或全不信的策略，部分信任无法改善一致性而不严重损害鲁棒性。

Abstract: This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, the information staleness, the update cost, and the availability of update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other uncertainties. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.

</details>


### [3] [Binding Agent ID: Unleashing the Power of AI Agents with accountability and credibility](https://arxiv.org/abs/2512.17538)
*Zibin Lin,Shengli Zhang,Guofu Liao,Dacheng Tao,Taotao Wang*

Main category: cs.NI

TL;DR: BAID提出了一种结合生物识别、区块链和零知识证明的身份基础设施，为AI代理建立可验证的用户-代码绑定，解决自主AI系统缺乏可追溯问责机制的问题。


<details>
  <summary>Details</summary>
Motivation: 自主AI代理缺乏可追溯的问责机制，导致系统要么只能作为"降级工具"运行，要么面临现实世界滥用的风险。传统基于密钥的身份验证无法保证操作者的物理身份或代理代码的完整性。

Method: BAID整合了三种正交机制：1) 通过生物识别进行本地绑定；2) 去中心化的链上身份管理；3) 基于zkVM的代码级认证协议。该协议利用递归证明将程序二进制作为身份，提供操作者身份、代理配置完整性和完整执行来源的加密保证。

Result: 实现并评估了完整的原型系统，证明了基于区块链的身份管理和基于zkVM的认证协议的实际可行性。

Conclusion: BAID通过建立可验证的用户-代码绑定，有效防止未经授权的操作和代码替换，为自主AI系统提供了可追溯的问责机制。

Abstract: Autonomous AI agents lack traceable accountability mechanisms, creating a fundamental dilemma where systems must either operate as ``downgraded tools'' or risk real-world abuse. This vulnerability stems from the limitations of traditional key-based authentication, which guarantees neither the operator's physical identity nor the agent's code integrity. To bridge this gap, we propose BAID (Binding Agent ID), a comprehensive identity infrastructure establishing verifiable user-code binding. BAID integrates three orthogonal mechanisms: local binding via biometric authentication, decentralized on-chain identity management, and a novel zkVM-based Code-Level Authentication protocol. By leveraging recursive proofs to treat the program binary as the identity, this protocol provides cryptographic guarantees for operator identity, agent configuration integrity, and complete execution provenance, thereby effectively preventing unauthorized operation and code substitution. We implement and evaluate a complete prototype system, demonstrating the practical feasibility of blockchain-based identity management and zkVM-based authentication protocol.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases](https://arxiv.org/abs/2512.16953)
*Pietro Cofone,Giovanni Amendola,Marco Manna,Aldo Ricioppo*

Main category: cs.AI

TL;DR: 本文提出了一种高效的局部推理方法，用于在扩展图中导航，避免了完整图构建的开销，支持实体集扩展的实用应用。


<details>
  <summary>Details</summary>
Motivation: 传统的线性实体集扩展方法无法揭示知识资源中丰富的分类结构，而现有的扩展图框架虽然能支持分类扩展，但完整构建可能不切实际，需要更高效的局部导航方法。

Method: 形式化了扩展图中的推理任务，检查两个元组是否属于可比较、不可比较或相同的节点。在现实假设下（如限制输入或实体描述），这些任务可以高效实现。

Result: 研究结果表明，在现实假设下，这些推理任务可以高效实现，支持对扩展图进行局部、增量式导航，无需完整构建整个图。

Conclusion: 提出的局部推理方法使得扩展图在实际场景中可行，支持实体集扩展的实用应用，同时避免了完整图构建的计算开销。

Abstract: Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic properties with the former -- potentially repeating the process to form increasingly broader sets. However, this ``linear'' approach does not unveil the richer ``taxonomic'' structures present in knowledge resources. A recent logic-based framework introduces the notion of an expansion graph: a rooted directed acyclic graph where each node represents a semantic generalization labeled by a logical formula, and edges encode strict semantic inclusion. This structure supports taxonomic expansions of entity sets driven by knowledge bases. Yet, the potentially large size of such graphs may make full materialization impractical in real-world scenarios. To overcome this, we formalize reasoning tasks that check whether two tuples belong to comparable, incomparable, or the same nodes in the graph. Our results show that, under realistic assumptions -- such as bounding the input or limiting entity descriptions -- these tasks can be implemented efficiently. This enables local, incremental navigation of expansion graphs, supporting practical applications without requiring full graph construction.

</details>


### [5] [Security Risks of Agentic Vehicles: A Systematic Analysis of Cognitive and Cross-Layer Threats](https://arxiv.org/abs/2512.17041)
*Ali Eslami,Jiangbo Yu*

Main category: cs.AI

TL;DR: 该论文研究智能体化车辆的安全威胁，包括OWASP式风险和跨层网络攻击，提出了基于角色的架构和严重性矩阵分析框架。


<details>
  <summary>Details</summary>
Motivation: 随着智能体化AI在车辆中的应用日益增多，形成了智能体化车辆的概念，但现有安全框架（如OWASP）未针对安全关键的网络物理平台（如车辆）设计，也未考虑与感知、通信、控制等其他层的交互风险。

Method: 引入基于角色的智能体化车辆架构（个人智能体和驾驶策略智能体），分析智能体AI层和跨层风险，使用严重性矩阵和攻击链分析来展示小扰动如何升级为不安全行为。

Result: 开发了一个结构化框架，首次为分析当前和新兴车辆平台中智能体化AI的安全风险提供了基础，展示了跨层攻击如何导致车辆行为失准或不安全。

Conclusion: 该研究为智能体化车辆安全风险分析提供了首个结构化框架，强调了跨层安全考虑的重要性，对当前和未来车辆平台的安全设计具有指导意义。

Abstract: Agentic AI is increasingly being explored and introduced in both manually driven and autonomous vehicles, leading to the notion of Agentic Vehicles (AgVs), with capabilities such as memory-based personalization, goal interpretation, strategic reasoning, and tool-mediated assistance. While frameworks such as the OWASP Agentic AI Security Risks highlight vulnerabilities in reasoning-driven AI systems, they are not designed for safety-critical cyber-physical platforms such as vehicles, nor do they account for interactions with other layers such as perception, communication, and control layers. This paper investigates security threats in AgVs, including OWASP-style risks and cyber-attacks from other layers affecting the agentic layer. By introducing a role-based architecture for agentic vehicles, consisting of a Personal Agent and a Driving Strategy Agent, we will investigate vulnerabilities in both agentic AI layer and cross-layer risks, including risks originating from upstream layers (e.g., perception layer, control layer, etc.). A severity matrix and attack-chain analysis illustrate how small distortions can escalate into misaligned or unsafe behavior in both human-driven and autonomous vehicles. The resulting framework provides the first structured foundation for analyzing security risks of agentic AI in both current and emerging vehicle platforms.

</details>


### [6] [Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows](https://arxiv.org/abs/2512.16969)
*Wanghan Xu,Yuhao Zhou,Yifan Zhou,Qinglong Cao,Shuo Li,Jia Bu,Bo Liu,Yixin Chen,Xuming He,Xiangyu Zhao,Xiang Zhuang,Fengxiang Wang,Zhiwang Zhou,Qiantai Feng,Wenxuan Huang,Jiaqi Wei,Hao Wu,Yuejin Yang,Guangshuai Wang,Sheng Xu,Ziyan Huang,Xinyao Liu,Jiyao Liu,Cheng Tang,Wei Li,Ying Chen,Junzhi Ning,Pengfei Jiang,Chenglong Ma,Ye Du,Changkai Ji,Huihui Xu,Ming Hu,Jiangbin Zheng,Xin Chen,Yucheng Wu,Feifei Jiang,Xi Chen,Xiangru Tang,Yuchen Fu,Yingzhou Lu,Yuanyuan Zhang,Lihao Sun,Chengbo Li,Jinzhe Ma,Wanhao Liu,Yating Liu,Kuo-Cheng Wu,Shengdu Chai,Yizhou Wang,Ouwen Zhangjin,Chen Tang,Shufei Zhang,Wenbo Cao,Junjie Ren,Taoyong Cui,Zhouheng Yao,Juntao Deng,Yijie Sun,Feng Liu,Wangxu Wei,Jingyi Xu,Zhangrui Li,Junchao Gong,Zijie Guo,Zhiyu Yao,Zaoyu Chen,Tianhao Peng,Fangchen Yu,Bo Zhang,Dongzhan Zhou,Shixiang Tang,Jiaheng Liu,Fenghua Ling,Yan Lu,Yuchen Ren,Ben Fei,Zhen Zhao,Xinyu Gu,Rui Su,Xiao-Ming Wu,Weikang Si,Yang Liu,Hao Chen,Xiangchao Yan,Xue Yang,Junchi Yan,Jiamin Wu,Qihao Zheng,Chenhui Li,Zhiqiang Gao,Hao Kong,Junjun He,Mao Su,Tianfan Fu,Peng Ye,Chunfeng Song,Nanqing Dong,Yuqiang Li,Huazhu Fu,Siqi Sun,Lijing Cheng,Jintai Lin,Wanli Ouyang,Bowen Zhou,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: 该论文提出了科学通用智能(SGI)的操作性定义，基于实践探究模型(PIM)，并创建了包含1000多个跨学科样本的SGI-Bench基准，用于评估LLM在科学研究任务中的表现。研究发现现有模型在深度研究、实验执行和推理等方面存在显著差距，并提出了测试时强化学习(TTRL)方法来提升假设新颖性。


<details>
  <summary>Details</summary>
Motivation: 尽管科学AI取得进展，但仍缺乏一个连贯的科学通用智能(SGI)框架——即能够自主构思、调查和跨科学领域推理的能力。现有AI系统在真正参与科学发现方面存在不足。

Method: 1. 基于实践探究模型(PIM: 深思、构思、行动、感知)定义SGI；2. 通过四个科学家对齐任务(深度研究、想法生成、干/湿实验、实验推理)操作化SGI；3. 创建SGI-Bench基准，包含1000多个专家策划的跨学科样本，灵感来自《科学》杂志的125个重大问题；4. 引入测试时强化学习(TTRL)，在推理时优化检索增强的新颖性奖励。

Result: 评估最先进LLM发现：深度研究的精确匹配率低(10-20%)；生成的想法缺乏可行性和细节；干实验代码可执行性高但执行结果准确性低；湿实验协议序列保真度低；多模态比较推理存在持续挑战。TTRL方法在不依赖参考答案的情况下提升了假设新颖性。

Conclusion: 基于PIM的定义、以工作流为中心的基准和实证见解为真正参与科学发现的AI系统奠定了基础。研究揭示了当前LLM在科学任务中的局限性，并提出了改进方向。

Abstract: Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning. SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Science's 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs. Results reveal gaps: low exact match (10--20%) in deep research despite step-level alignment; ideas lacking feasibility and detail; high code executability but low execution result accuracy in dry experiments; low sequence fidelity in wet protocols; and persistent multimodal comparative-reasoning challenges. We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer. Together, our PIM-grounded definition, workflow-centric benchmark, and empirical insights establish a foundation for AI systems that genuinely participate in scientific discovery.

</details>


### [7] [Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty](https://arxiv.org/abs/2512.17145)
*Josh Barber,Rourke Young,Cameron Coombe,Will Browne*

Main category: cs.AI

TL;DR: 提出一种受Solomonoff启发的LLM假设加权方法，通过简洁性和预测拟合度评估多个候选解，在不确定性下实现更平衡的概率分布


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理稀疏数据的现实任务时，难以在准确性和简洁性之间平衡评估多个候选解决方案，特别是在不确定性推理方面存在挑战

Method: 提出Solomonoff启发的方法，对LLM生成的假设按简洁性和预测拟合度进行加权，在Mini-ARC基准任务中生成Solomonoff加权混合的逐单元预测

Result: 相比贝叶斯模型平均（BMA），Solomonoff评分在竞争假设间更均匀地分布概率，而BMA集中在最可能但可能有缺陷的候选上，产生保守、不确定性感知的输出

Conclusion: 算法信息论先验对于可解释、可靠的多假设不确定性推理具有重要价值，特别是在假设有噪声或部分错误的情况下

Abstract: Reasoning under uncertainty is a key challenge in AI, especially for real-world tasks, where problems with sparse data demands systematic generalisation. Existing approaches struggle to balance accuracy and simplicity when evaluating multiple candidate solutions. We propose a Solomonoff-inspired method that weights LLM-generated hypotheses by simplicity and predictive fit. Applied to benchmark (Mini-ARC) tasks, our method produces Solomonoff-weighted mixtures for per-cell predictions, yielding conservative, uncertainty-aware outputs even when hypotheses are noisy or partially incorrect. Compared to Bayesian Model Averaging (BMA), Solomonoff scoring spreads probability more evenly across competing hypotheses, while BMA concentrates weight on the most likely but potentially flawed candidates. Across tasks, this highlights the value of algorithmic information-theoretic priors for interpretable, reliable multi-hypothesis reasoning under uncertainty.

</details>


### [8] [PAACE: A Plan-Aware Automated Agent Context Engineering Framework](https://arxiv.org/abs/2512.16970)
*Kamer Ali Yuksel*

Main category: cs.AI

TL;DR: PAACE框架通过计划感知的上下文工程优化LLM智能体工作流，提升准确性同时大幅降低上下文负载和推理成本。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在复杂多步骤工作流中产生快速扩展的上下文，现有摘要和压缩方法忽略了多步骤、计划感知的智能体推理特性，导致注意力稀释和推理成本增加。

Method: 提出PAACE统一框架，包含：1) PAACE-Syn：生成带压缩监督标注的合成智能体工作流；2) PAACE-FT：从成功教师演示中蒸馏训练的计划感知压缩器家族，采用下一k任务相关性建模、计划结构分析、指令协同精炼和函数保留压缩。

Result: 在长视野基准测试(AppWorld、OfficeBench和8-Objective QA)上，PAACE持续提升智能体正确性并显著降低上下文负载。在AppWorld上获得更高准确性，同时降低峰值上下文和累积依赖；在OfficeBench和多跳QA上提升准确性和F1，减少步骤、峰值token和注意力依赖。蒸馏的PAACE-FT保留97%教师性能，推理成本降低超过一个数量级。

Conclusion: PAACE框架有效解决了LLM智能体工作流中的上下文管理问题，通过计划感知压缩实现了准确性提升和成本降低的平衡，使紧凑模型能够实际部署计划感知压缩技术。

Abstract: Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems. These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fidelity, avoid attention dilution, and reduce inference cost. Prior work on summarization and query-aware compression largely ignores the multi-step, plan-aware nature of agentic reasoning. In this work, we introduce PAACE (Plan-Aware Automated Context Engineering), a unified framework for optimizing the evolving state of LLM agents through next-k-task relevance modeling, plan-structure analysis, instruction co-refinement, and function-preserving compression. PAACE comprises (1) PAACE-Syn, a large-scale generator of synthetic agent workflows annotated with stepwise compression supervision, and (2) PAACE-FT, a family of distilled, plan-aware compressors trained from successful teacher demonstrations. Experiments on long-horizon benchmarks (AppWorld, OfficeBench, and 8-Objective QA) demonstrate that PAACE consistently improves agent correctness while substantially reducing context load. On AppWorld, PAACE achieves higher accuracy than all baselines while lowering peak context and cumulative dependency. On OfficeBench and multi-hop QA, PAACE improves both accuracy and F1, achieving fewer steps, lower peak tokens, and reduced attention dependency. Distilled PAACE-FT retains 97 percent of the teacher's performance while reducing inference cost by over an order of magnitude, enabling practical deployment of plan-aware compression with compact models.

</details>


### [9] [UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering](https://arxiv.org/abs/2512.17043)
*Yinxu Tang,Chengsong Huang,Jiaxin Huang,William Yeoh*

Main category: cs.AI

TL;DR: 提出关系中心的知识图谱问答框架UniRel-R1，通过子图选择、多阶段图剪枝和强化学习微调LLM来生成紧凑、信息丰富的连接子图作为答案。


<details>
  <summary>Details</summary>
Motivation: 传统KGQA主要关注返回单个实体的实体中心查询，但现实世界查询通常是关系性的，需要理解实体之间的关联。因此需要开发能够返回捕捉实体间语义连接的子图的关系中心KGQA方法。

Method: 提出UniRel-R1统一框架，整合子图选择、多阶段图剪枝，并使用强化学习微调LLM。奖励函数设计鼓励生成紧凑、具体的子图，包含更多信息丰富的关系和较低度的中间实体。

Result: 大量实验表明，UniRel-R1在连接性和奖励方面相比Vanilla基线取得显著提升，并能有效泛化到未见过的实体和关系。

Conclusion: UniRel-R1成功解决了关系中心KGQA的挑战，通过整合多种技术生成信息丰富的连接子图，为传统实体中心KGQA提供了有价值的补充。

Abstract: Knowledge Graph Question Answering (KGQA) has traditionally focused on entity-centric queries that return a single answer entity. However, real-world queries are often relational, seeking to understand how entities are associated. In this work, we introduce relation-centric KGQA, a complementary setting where the answer is a subgraph capturing the semantic connections among entities rather than an individual entity. The main challenge lies in the abundance of candidate subgraphs, where trivial or overly common connections often obscure the identification of unique and informative answers. To tackle this, we propose UniRel-R1, a unified framework that integrates subgraph selection, multi-stage graph pruning, and an LLM fine-tuned with reinforcement learning. The reward function is designed to encourage compact and specific subgraphs with more informative relations and lower-degree intermediate entities. Extensive experiments show that UniRel-R1 achieves significant gains in connectivity and reward over Vanilla baselines and generalizes effectively to unseen entities and relations.

</details>


### [10] [Realistic threat perception drives intergroup conflict: A causal, dynamic analysis using generative-agent simulations](https://arxiv.org/abs/2512.17066)
*Suhaib Abdurahman,Farzan Karimi-Malekabadi,Chenxiao Yu,Nour S. Kteily,Morteza Dehghani*

Main category: cs.AI

TL;DR: 使用LLM驱动的智能体在虚拟社会中模拟威胁与冲突，发现物质威胁直接增加敌意，而象征性威胁主要通过内群体偏见间接影响，且只在物质威胁缺失时增加敌意


<details>
  <summary>Details</summary>
Motivation: 人类冲突通常归因于物质条件和象征性价值受到的威胁，但两者如何相互作用以及哪个占主导地位尚不清楚。研究受到因果控制弱、伦理约束和时间数据稀缺的限制

Method: 使用大型语言模型驱动的智能体在虚拟社会中模拟，独立变化现实威胁和象征性威胁，同时跟踪行动、语言和态度。通过表征分析检验LLM如何编码这些状态

Result: LLM将现实威胁、象征性威胁和敌意编码为不同的内部状态；现实威胁直接增加敌意，象征性威胁效应较弱，完全通过内群体偏见中介，且只在现实威胁缺失时增加敌意；非敌对性群体间接触能缓冲冲突升级，结构性不对称使敌意集中在多数群体中

Conclusion: 通过LLM智能体模拟为威胁驱动的冲突提供了因果解释，揭示了物质威胁和象征性威胁的不同作用机制，为理解人类冲突提供了新视角

Abstract: Human conflict is often attributed to threats against material conditions and symbolic values, yet it remains unclear how they interact and which dominates. Progress is limited by weak causal control, ethical constraints, and scarce temporal data. We address these barriers using simulations of large language model (LLM)-driven agents in virtual societies, independently varying realistic and symbolic threat while tracking actions, language, and attitudes. Representational analyses show that the underlying LLM encodes realistic threat, symbolic threat, and hostility as distinct internal states, that our manipulations map onto them, and that steering these states causally shifts behavior. Our simulations provide a causal account of threat-driven conflict over time: realistic threat directly increases hostility, whereas symbolic threat effects are weaker, fully mediated by ingroup bias, and increase hostility only when realistic threat is absent. Non-hostile intergroup contact buffers escalation, and structural asymmetries concentrate hostility among majority groups.

</details>


### [11] [Value Under Ignorance in Universal Artificial Intelligence](https://arxiv.org/abs/2512.17086)
*Cole Wyeth,Marcus Hutter*

Main category: cs.AI

TL;DR: 将AIXI强化学习智能体推广到更广泛的效用函数类别，通过处理半测度损失和死亡解释，引入不精确概率理论和Choquet积分来计算期望效用。


<details>
  <summary>Details</summary>
Motivation: AIXI智能体中的某些假设只能预测有限的历史前缀，这导致半测度损失问题。传统上将其解释为死亡概率，但作者认为也可以将其视为不精确概率分布，这促使研究如何在这种不确定性下计算期望效用。

Method: 采用不精确概率理论中的Choquet积分来计算期望效用，研究其可计算性水平。将半测度损失视为完全无知而非死亡概率，并探索在这种解释下的效用分配方法。

Result: 证明了标准递归值函数是Choquet积分的一个特例。然而，在死亡解释下最一般的期望效用不能表示为这样的Choquet积分，揭示了两种解释之间的本质差异。

Conclusion: 通过将AIXI推广到更广泛的效用函数类别，并引入不精确概率理论和Choquet积分，为处理半测度损失提供了新的理论框架，但死亡解释下的期望效用需要不同的数学表征。

Abstract: We generalize the AIXI reinforcement learning agent to admit a wider class of utility functions. Assigning a utility to each possible interaction history forces us to confront the ambiguity that some hypotheses in the agent's belief distribution only predict a finite prefix of the history, which is sometimes interpreted as implying a chance of death equal to a quantity called the semimeasure loss. This death interpretation suggests one way to assign utilities to such history prefixes. We argue that it is as natural to view the belief distributions as imprecise probability distributions, with the semimeasure loss as total ignorance. This motivates us to consider the consequences of computing expected utilities with Choquet integrals from imprecise probability theory, including an investigation of their computability level. We recover the standard recursive value function as a special case. However, our most general expected utilities under the death interpretation cannot be characterized as such Choquet integrals.

</details>


### [12] [A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving](https://arxiv.org/abs/2512.17093)
*Timo Pierre Schrader,Lukas Lange,Tobias Kaminski,Simon Razniewski,Annemarie Friedrich*

Main category: cs.AI

TL;DR: 提出一种ASP求解器引导的指令微调方法，利用求解器反馈来提升LLM在答案集编程代码生成上的性能


<details>
  <summary>Details</summary>
Motivation: 当前LLM在领域特定语言（如答案集编程ASP）的代码生成方面表现不佳，主要原因是预训练阶段接触的ASP示例有限。ASP在组合搜索问题中很有效，但LLM难以生成正确的ASP代码。

Method: 提出ASP-solver-in-the-loop方法：1) 从LLM采样ASP语句作为程序延续；2) 利用ASP声明式编程的特性，根据求解器反馈将样本分为接受和拒绝实例；3) 对筛选数据进行监督微调；4) 使用求解器引导的搜索（包括best-of-N采样）进一步提高鲁棒性。

Result: 在两个数据集上的两种不同提示设置下都取得了持续改进，证明了方法的有效性。

Conclusion: 该方法通过求解器引导的指令微调，有效解决了LLM在ASP代码生成中的语义解析挑战，仅需自然语言问题描述和解决方案即可训练，为领域特定语言的代码生成提供了新思路。

Abstract: The rise of large language models (LLMs) has sparked interest in coding assistants. While general-purpose programming languages are well supported, generating code for domain-specific languages remains a challenging problem for LLMs. In this paper, we focus on the LLM-based generation of code for Answer Set Programming (ASP), a particularly effective approach for finding solutions to combinatorial search problems. The effectiveness of LLMs in ASP code generation is currently hindered by the limited number of examples seen during their initial pre-training phase.
  In this paper, we introduce a novel ASP-solver-in-the-loop approach for solver-guided instruction-tuning of LLMs to addressing the highly complex semantic parsing task inherent in ASP code generation. Our method only requires problem specifications in natural language and their solutions. Specifically, we sample ASP statements for program continuations from LLMs for unriddling logic puzzles. Leveraging the special property of declarative ASP programming that partial encodings increasingly narrow down the solution space, we categorize them into chosen and rejected instances based on solver feedback. We then apply supervised fine-tuning to train LLMs on the curated data and further improve robustness using a solver-guided search that includes best-of-N sampling. Our experiments demonstrate consistent improvements in two distinct prompting settings on two datasets.

</details>


### [13] [Reinforcement Learning for Self-Improving Agent with Skill Library](https://arxiv.org/abs/2512.17102)
*Jiongxiao Wang,Qiaojing Yan,Yawei Wang,Yijun Tian,Soumya Smruti Mishra,Zhichao Xu,Megha Gandhi,Panpan Xu,Lin Lee Cheong*

Main category: cs.AI

TL;DR: 提出SAGE框架，通过强化学习和技能库增强LLM智能体的自我改进能力，在AppWorld任务中显著提升性能并减少交互成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体在新环境中部署时难以持续改进和适应，而现有的技能库方法主要依赖LLM提示，难以实现一致的技能库实施。

Method: 提出SAGE框架：1）使用强化学习增强智能体的自我改进能力；2）引入Sequential Rollout机制，在相似任务链中迭代部署智能体；3）设计Skill-integrated Reward补充基于结果的奖励；4）技能库中积累先前任务生成的技能供后续任务使用。

Result: 在AppWorld实验中，SAGE应用于有专家经验的监督微调模型后：场景目标完成率提高8.9%，交互步骤减少26%，生成token减少59%，在准确性和效率上均显著优于现有方法。

Conclusion: SAGE框架通过强化学习和技能库的有效结合，成功增强了LLM智能体的自我改进能力，在复杂任务中实现了更高的性能和效率。

Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in complex reasoning and multi-turn interactions but struggle to continuously improve and adapt when deployed in new environments. One promising approach is implementing skill libraries that allow agents to learn, validate, and apply new skills. However, current skill library approaches rely primarily on LLM prompting, making consistent skill library implementation challenging. To overcome these challenges, we propose a Reinforcement Learning (RL)-based approach to enhance agents' self-improvement capabilities with a skill library. Specifically, we introduce Skill Augmented GRPO for self-Evolution (SAGE), a novel RL framework that systematically incorporates skills into learning. The framework's key component, Sequential Rollout, iteratively deploys agents across a chain of similar tasks for each rollout. As agents navigate through the task chain, skills generated from previous tasks accumulate in the library and become available for subsequent tasks. Additionally, the framework enhances skill generation and utilization through a Skill-integrated Reward that complements the original outcome-based rewards. Experimental results on AppWorld demonstrate that SAGE, when applied to supervised-finetuned model with expert experience, achieves 8.9% higher Scenario Goal Completion while requiring 26% fewer interaction steps and generating 59% fewer tokens, substantially outperforming existing approaches in both accuracy and efficiency.

</details>


### [14] [MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation](https://arxiv.org/abs/2512.17194)
*Shengwei Zhao,Jingwen Yao,Sitong Wei,Linhai Xu,Yuying Liu,Dong Zhang,Zhiqiang Tian,Shaoyi Du*

Main category: cs.AI

TL;DR: 提出两阶段强化学习微调框架，通过规则强化微调过滤无关多模态文档，再通过推理强化微调联合优化排序和答案生成，实现可解释的多模态检索增强生成。


<details>
  <summary>Details</summary>
Motivation: 现有MMRAG方法缺乏对检索和生成过程的推理逻辑解释，限制了结果的可解释性。需要增强多模态大语言模型的推理能力，实现可解释的多模态检索增强生成。

Method: 两阶段强化学习微调框架：第一阶段使用基于规则的强化微调进行粗粒度点式排序，过滤显著无关的多模态文档；第二阶段使用基于推理的强化微调联合优化细粒度列表式排序和答案生成，引导模型输出可解释的推理逻辑。

Result: 在WebQA和MultimodalQA两个多模态检索增强生成基准数据集上取得了最先进的结果，并通过全面的消融实验验证了方法的有效性。

Conclusion: 通过引入强化学习到多模态检索增强生成中，提出的两阶段强化微调框架成功增强了多模态大语言模型的推理能力，实现了可解释的多模态检索增强生成，在基准数据集上表现优异。

Abstract: Multi-modal Retrieval-Augmented Generation (MMRAG) enables highly credible generation by integrating external multi-modal knowledge, thus demonstrating impressive performance in complex multi-modal scenarios. However, existing MMRAG methods fail to clarify the reasoning logic behind retrieval and response generation, which limits the explainability of the results. To address this gap, we propose to introduce reinforcement learning into multi-modal retrieval-augmented generation, enhancing the reasoning capabilities of multi-modal large language models through a two-stage reinforcement fine-tuning framework to achieve explainable multi-modal retrieval-augmented generation. Specifically, in the first stage, rule-based reinforcement fine-tuning is employed to perform coarse-grained point-wise ranking of multi-modal documents, effectively filtering out those that are significantly irrelevant. In the second stage, reasoning-based reinforcement fine-tuning is utilized to jointly optimize fine-grained list-wise ranking and answer generation, guiding multi-modal large language models to output explainable reasoning logic in the MMRAG process. Our method achieves state-of-the-art results on WebQA and MultimodalQA, two benchmark datasets for multi-modal retrieval-augmented generation, and its effectiveness is validated through comprehensive ablation experiments.

</details>


### [15] [UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark](https://arxiv.org/abs/2512.17196)
*Kai Liu,Leyang Chen,Wenbo Li,Zhikai Chen,Zhixin Wang,Renjing Pei,Linghe Kong,Yulun Zhang*

Main category: cs.AI

TL;DR: UmniBench：首个针对统一多模态模型（UMMs）的全维度评估基准，能在单一评估过程中同时测试理解、生成和编辑能力，覆盖13个领域200+概念。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型的评估是分离的，理解能力和生成能力分别用不同数据集评估，缺乏综合评估框架。需要开发能够全面评估UMMs多维度能力的基准。

Method: UmniBench利用UMM自身通过人类检查的提示和问答对来评估其生成和编辑能力。采用简单有效的范式：用模型的理解能力评估其生成和编辑输出。基准覆盖13个主要领域和200多个概念。

Result: 基于UmniBench对24个流行模型进行了基准测试，包括UMMs和单能力大模型。基准能够提供细粒度评估，既可以综合评估也可以分离评估理解、生成和编辑能力。

Conclusion: UmniBench为统一多模态模型提供了更全面客观的评估视角，为社区模型性能改进提供了逻辑支持，填补了UMMs综合评估的空白。

Abstract: Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems. However, evaluations of unified multimodal models (UMMs) remain decoupled, assessing their understanding and generation abilities separately with corresponding datasets. To address this, we propose UmniBench, a benchmark tailored for UMMs with omni-dimensional evaluation. First, UmniBench can assess the understanding, generation, and editing ability within a single evaluation process. Based on human-examined prompts and QA pairs, UmniBench leverages UMM itself to evaluate its generation and editing ability with its understanding ability. This simple but effective paradigm allows comprehensive evaluation of UMMs. Second, UmniBench covers 13 major domains and more than 200 concepts, ensuring a thorough inspection of UMMs. Moreover, UmniBench can also decouple and separately evaluate understanding, generation, and editing abilities, providing a fine-grained assessment. Based on UmniBench, we benchmark 24 popular models, including both UMMs and single-ability large models. We hope this benchmark provides a more comprehensive and objective view of unified models and logistical support for improving the performance of the community model.

</details>


### [16] [Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction](https://arxiv.org/abs/2512.17250)
*Ziyang Lin,Zixuan Sun,Sanhorn Chen,Xiaoyang Chen,Roy Zhao*

Main category: cs.AI

TL;DR: 提出推测-校正框架，将推测执行思想应用于基于模型的强化学习控制，通过动作队列和轻量级校正器减少规划延迟，在保持性能的同时提升实时性


<details>
  <summary>Details</summary>
Motivation: 实时顺序控制代理常受推理延迟瓶颈，即使适度的每步规划延迟也会破坏控制稳定性并降低整体性能。需要一种方法在保持控制性能的同时减少规划延迟。

Method: 采用推测-校正框架，将推测执行的预测-验证思想应用于基于TD-MPC2的模型控制。使用预训练世界模型和潜在空间MPC规划器生成短期动作队列和潜在状态预测，允许代理执行多个规划动作而无需立即重新规划。新观测到达时，系统测量真实潜在状态与预测潜在状态之间的不匹配，通过轻量级学习校正器对推测动作应用残差更新（从重新规划教师离线蒸馏）。对于大不匹配则安全回退到完全重新规划。

Result: 在DMC Humanoid-Walk任务中，方法将规划推理次数从500减少到282，端到端步延迟提升25%，仅带来7.1%的回报减少。消融实验表明无校正的推测执行在较长时域上不可靠，突显了不匹配感知校正对稳健延迟减少的必要性。

Conclusion: 推测-校正框架成功地将推测执行思想应用于基于模型的强化学习控制，通过动作队列和轻量级校正器显著减少规划延迟，在保持控制性能的同时提升实时性，为实时控制系统的延迟优化提供了有效解决方案。

Abstract: Real-time sequential control agents are often bottlenecked by inference latency. Even modest per-step planning delays can destabilize control and degrade overall performance. We propose a speculation-and-correction framework that adapts the predict-then-verify philosophy of speculative execution to model-based control with TD-MPC2. At each step, a pretrained world model and latent-space MPC planner generate a short-horizon action queue together with predicted latent rollouts, allowing the agent to execute multiple planned actions without immediate replanning. When a new observation arrives, the system measures the mismatch between the encoded real latent state and the queued predicted latent. For small to moderate mismatch, a lightweight learned corrector applies a residual update to the speculative action, distilled offline from a replanning teacher. For large mismatch, the agent safely falls back to full replanning and clears stale action queues. We study both a gated two-tower MLP corrector and a temporal Transformer corrector to address local errors and systematic drift. Experiments on the DMC Humanoid-Walk task show that our method reduces the number of planning inferences from 500 to 282, improves end-to-end step latency by 25 percent, and maintains strong control performance with only a 7.1 percent return reduction. Ablation results demonstrate that speculative execution without correction is unreliable over longer horizons, highlighting the necessity of mismatch-aware correction for robust latency reduction.

</details>


### [17] [ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework](https://arxiv.org/abs/2512.17266)
*Miru Hong,Minho Lee,Geonhee Jo,Jae-Hee So,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: EventGPT：基于GPT架构的球员条件化价值感知下一事件预测模型，用于评估足球转会适应性


<details>
  <summary>Details</summary>
Motivation: 现有转会评估方法依赖静态统计或事后价值模型，无法捕捉球员在新战术环境中的适应性变化，需要能预测球员在不同球队中表现变化的方法

Method: 使用GPT风格的自回归transformer，将比赛视为离散token序列，联合预测下一持球动作的类型、位置、时间及其残差持球价值，通过替换球员嵌入进行反事实模拟

Result: 在英超五个赛季数据上，EventGPT在下一事件预测准确性和空间精度上优于现有序列基线，并通过案例研究展示了转会分析的实用价值

Conclusion: EventGPT为转会适应性评估提供了原则性方法，能够模拟球员在不同战术环境中的行为分布和价值变化，具有实际应用价值

Abstract: Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.

</details>


### [18] [Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation](https://arxiv.org/abs/2512.17308)
*Daksh Jain,Aarya Jain,Ashutosh Desai,Avyakt Verma,Ishan Bhanuka,Pratik Narang,Dhruv Kumar*

Main category: cs.AI

TL;DR: LLMs在宝可梦对战中的战略决策能力评估，展示了它们既能作为动态游戏对手，又能生成平衡的游戏内容，为回合制策略游戏提供了强化学习之外的实用替代方案。


<details>
  <summary>Details</summary>
Motivation: 宝可梦对战需要推理类型克制、统计权衡和风险评估，这些技能反映了人类的战略思维。本研究旨在探索LLMs是否能作为合格的对战代理，既能做出战术决策，又能生成新颖平衡的游戏内容。

Method: 开发了一个回合制宝可梦对战系统，LLMs基于对战状态而非预设逻辑选择招式。框架包含宝可梦核心机制：类型效果倍数、基于属性的伤害计算和多宝可梦队伍管理。通过多种模型架构的系统评估。

Result: 测量了胜率、决策延迟、类型对齐准确性和令牌效率。结果表明LLMs可以在没有领域特定训练的情况下作为动态游戏对手，为回合制策略游戏提供了强化学习的实用替代方案。

Conclusion: LLMs兼具战术推理和内容创造的双重能力，使其既能作为玩家又能作为设计师，对交互娱乐中的程序生成和自适应难度系统具有重要意义。

Abstract: Strategic decision-making in Pokémon battles presents a unique testbed for evaluating large language models. Pokémon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound decisions and generating novel, balanced game content. We developed a turn-based Pokémon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Pokémon mechanics: type effectiveness multipliers, stat-based damage calculations, and multi-Pokémon team management. Through systematic evaluation across multiple model architectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn-based strategic games. The dual capability of tactical reasoning and content creation, positions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive entertainment.

</details>


### [19] [Dialectics for Artificial Intelligence](https://arxiv.org/abs/2512.17373)
*Zhengmian Hu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于算法信息论的概念定义方法，将概念视为与智能体整体经验相关的信息对象，通过可逆一致性关系和冗余信息度量来形式化概念发现与演化。


<details>
  <summary>Details</summary>
Motivation: 研究AI能否在无人监督下从原始经验中发现人类概念，但面临人类概念本身具有流动性（边界会变化、分裂、合并）的挑战。需要超越字典标签的概念定义，建立可修订、可比较、可跨智能体对齐的概念结构。

Method: 采用算法信息论视角，将概念定义为与智能体整体经验相关的信息对象。核心约束是确定性：一组部分构成可逆一致性关系，即任何缺失部分都能从其他部分恢复（允许Kolmogorov式恒等式中的对数松弛）。通过冗余信息度量分解的自然性，并在此基础上将辩证法形式化为优化动力学：新信息出现时，竞争概念通过更短的描述来争夺解释权，驱动系统性扩展、收缩、分裂和合并。最后形式化低成本概念传输和多智能体对齐。

Result: 提出了一个形式化框架，使概念不再游离于经验之外，而是可检验的结构性主张。建立了概念存在性的可检查标准，定义了概念分解的自然性度量，并形式化了概念演化动力学和跨智能体对齐机制。

Conclusion: 该研究为AI自主发现和演化概念提供了理论基础，将概念定义为与经验结构相关的信息对象，通过可逆性约束防止概念脱离经验，并通过辩证法动力学驱动概念的自然演化，同时支持低成本的概念传输和多智能体对齐。

Abstract: Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of "concept" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents "concepts" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.

</details>


### [20] [Translating the Rashomon Effect to Sequential Decision-Making Tasks](https://arxiv.org/abs/2512.17470)
*Dennis Gross,Jørn Eirik Betten,Helge Spieker*

Main category: cs.AI

TL;DR: 本文将Rashomon效应从分类任务扩展到序列决策问题，定义了行为相同但内部结构不同的策略，使用形式化验证方法比较策略的完整概率行为，发现Rashomon效应在序列决策中存在，且基于Rashomon集合构建的集成策略对分布偏移更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Rashomon效应在分类任务中已被广泛研究，但在序列决策领域尚未探索。序列决策中策略的行为验证比分类更复杂，因为随机转移会导致相同策略在不同轨迹上表现不同。需要开发新的验证方法来研究序列决策中的Rashomon效应。

Method: 使用形式化验证方法构建和比较每个策略在环境中的完整概率行为。定义行为相同但内部特征归因不同的策略为Rashomon效应。通过实验验证Rashomon效应在序列决策中的存在，并基于Rashomon集合构建集成策略和宽松策略。

Result: 实验证明Rashomon效应在序列决策中存在。基于Rashomon集合构建的集成策略比单个策略对分布偏移更具鲁棒性。从Rashomon集合派生的宽松策略在保持最优性能的同时减少了验证的计算需求。

Conclusion: 成功将Rashomon效应扩展到序列决策领域，开发了适用于随机环境的验证方法。Rashomon集合不仅揭示了策略多样性，还能构建更鲁棒的集成策略和计算效率更高的宽松策略，为序列决策系统的可靠性和可解释性提供了新视角。

Abstract: The Rashomon effect describes the phenomenon where multiple models trained on the same data produce identical predictions while differing in which features they rely on internally. This effect has been studied extensively in classification tasks, but not in sequential decision-making, where an agent learns a policy to achieve an objective by taking actions in an environment. In this paper, we translate the Rashomon effect to sequential decision-making. We define it as multiple policies that exhibit identical behavior, visiting the same states and selecting the same actions, while differing in their internal structure, such as feature attributions. Verifying identical behavior in sequential decision-making differs from classification. In classification, predictions can be directly compared to ground-truth labels. In sequential decision-making with stochastic transitions, the same policy may succeed or fail on any single trajectory due to randomness. We address this using formal verification methods that construct and compare the complete probabilistic behavior of each policy in the environment. Our experiments demonstrate that the Rashomon effect exists in sequential decision-making. We further show that ensembles constructed from the Rashomon set exhibit greater robustness to distribution shifts than individual policies. Additionally, permissive policies derived from the Rashomon set reduce computational requirements for verification while maintaining optimal performance.

</details>


### [21] [Towards Explainable Conversational AI for Early Diagnosis with Large Language Models](https://arxiv.org/abs/2512.17559)
*Maliha Tabassum,M Shamim Kaiser*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（GPT-4o）的诊断聊天机器人，结合检索增强生成和可解释AI技术，通过动态对话提取症状、标准化信息，并提供透明诊断推理，在测试中达到90%准确率和100%Top-3准确率。


<details>
  <summary>Details</summary>
Motivation: 全球医疗系统面临诊断效率低下、成本上升和专家资源有限等问题，导致治疗延迟和不良健康结果。当前大多数AI诊断系统缺乏交互性和透明度，难以在实际患者中心环境中有效应用。

Method: 使用GPT-4o大语言模型构建诊断聊天机器人，结合检索增强生成（RAG）和可解释AI技术。系统通过动态对话提取和标准化症状，采用相似性匹配和自适应提问优先诊断，并通过思维链提示提供透明推理。

Result: 与传统机器学习模型（朴素贝叶斯、逻辑回归、SVM、随机森林、KNN）相比，LLM系统表现出色，达到90%的准确率和100%的Top-3准确率。

Conclusion: 该研究展示了基于大语言模型的诊断聊天机器人在医疗领域的潜力，为实现更透明、交互性强且临床相关的AI医疗系统提供了有前景的方向。

Abstract: Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or transparent, making them less effective in real-world, patient-centered environments. This research introduces a diagnostic chatbot powered by a Large Language Model (LLM), using GPT-4o, Retrieval-Augmented Generation, and explainable AI techniques. The chatbot engages patients in a dynamic conversation, helping to extract and normalize symptoms while prioritizing potential diagnoses through similarity matching and adaptive questioning. With Chain-of-Thought prompting, the system also offers more transparent reasoning behind its diagnoses. When tested against traditional machine learning models like Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, the LLM-based system delivered impressive results, achieving an accuracy of 90% and Top-3 accuracy of 100%. These findings offer a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.

</details>


### [22] [About Time: Model-free Reinforcement Learning with Timed Reward Machines](https://arxiv.org/abs/2512.17637)
*Anirban Majumdar,Ritam Raha,Rajarshi Roy,David Parker,Marta Kwiatkowska*

Main category: cs.AI

TL;DR: 提出定时奖励机(TRM)扩展传统奖励机，引入时间约束增强表达能力，开发基于Q学习的模型无关RL算法，通过时间自动机抽象和反事实想象启发式优化策略搜索。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机无法建模精确的时间约束，限制了在时间敏感应用中的使用。需要一种能够表达时间相关奖励的机制，例如延迟惩罚和及时行动奖励。

Method: 提出定时奖励机(TRM)扩展奖励机，集成时间约束到奖励结构中。开发模型无关RL框架（表格Q学习），通过时间自动机抽象将TRM融入学习过程，并使用反事实想象启发式利用TRM结构改进搜索。

Result: 实验表明算法能在流行的RL基准上学习到满足TRM时间约束的高奖励策略。比较研究展示了不同TRM语义下的性能差异，消融实验验证了反事实想象的有效性。

Conclusion: TRM为时间敏感RL应用提供了更丰富的奖励表达能力，提出的算法能有效学习满足时间约束的最优策略，反事实想象启发式显著提升学习效率。

Abstract: Reward specification plays a central role in reinforcement learning (RL), guiding the agent's behavior. To express non-Markovian rewards, formalisms such as reward machines have been introduced to capture dependencies on histories. However, traditional reward machines lack the ability to model precise timing constraints, limiting their use in time-sensitive applications. In this paper, we propose timed reward machines (TRMs), which are an extension of reward machines that incorporate timing constraints into the reward structure. TRMs enable more expressive specifications with tunable reward logic, for example, imposing costs for delays and granting rewards for timely actions. We study model-free RL frameworks (i.e., tabular Q-learning) for learning optimal policies with TRMs under digital and real-time semantics. Our algorithms integrate the TRM into learning via abstractions of timed automata, and employ counterfactual-imagining heuristics that exploit the structure of the TRM to improve the search. Experimentally, we demonstrate that our algorithm learns policies that achieve high rewards while satisfying the timing constraints specified by the TRM on popular RL benchmarks. Moreover, we conduct comparative studies of performance under different TRM semantics, along with ablations that highlight the benefits of counterfactual-imagining.

</details>


### [23] [Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally](https://arxiv.org/abs/2512.17898)
*Robin Schimmelpfennig,Mark Díaz,Vinodkumar Prabhakaran,Aida Davani*

Main category: cs.AI

TL;DR: 研究发现AI拟人化设计对用户信任和参与度的影响并非普遍一致，而是受到文化因素的调节，挑战了现有AI治理的一刀切方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统日益拟人化引发了关于拟人化可能导致不当信任或情感依赖的担忧，但现有研究缺乏基于全球用户的实际交互数据，且安全框架主要依赖西方人口的理论假设。

Method: 在10个不同国家进行了两项大规模跨国实验（N=3,500），涉及与AI系统的实时开放式交互，实验性地测试拟人化设计对用户感知和行为的影响。

Result: 用户评估AI拟人化时更关注交互线索而非理论特征；拟人化设计能增加用户感知的拟人化，但不会普遍增加用户参与度和信任；文化因素调节了拟人化设计与行为结果之间的关系。

Conclusion: AI拟人化设计的影响是复杂且文化中介的，挑战了拟人化设计必然带来风险的普遍叙事，呼吁AI治理需要超越一刀切的方法，考虑文化多样性。

Abstract: Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance.

</details>


### [24] [When Reasoning Meets Its Laws](https://arxiv.org/abs/2512.17901)
*Junyu Zhang,Yifan Sun,Tianang Leng,Jingyan Shen,Liu Ziyin,Paul Pu Liang,Huan Zhang*

Main category: cs.AI

TL;DR: 提出了推理定律(LoRe)框架，通过计算定律和准确率定律来形式化大型推理模型的理想推理行为，并创建LoRe-Bench基准来评估模型的单调性和组合性，发现大多数模型缺乏组合性，通过微调方法提升计算定律的遵循度能显著改善推理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型(LRMs)性能优越，但其推理行为常常违反直觉，导致推理能力不理想。需要理论框架来形式化理想的推理行为，以理解和改进LRMs的推理模式。

Method: 提出推理定律(LoRe)统一框架，包含计算定律（推理计算量应与问题复杂度线性相关）和准确率定律。由于问题复杂度难以量化，通过单调性和组合性两个可验证属性来检验这些假设。创建LoRe-Bench基准系统评估这些属性，并开发微调方法来增强计算定律的组合性。

Result: 评估显示大多数推理模型表现出合理的单调性但缺乏组合性。通过微调方法提升计算定律的遵循度后，在多个基准测试中推理性能得到一致改善，并发现了不同属性和定律之间的协同效应。

Conclusion: 推理定律(LoRe)框架为理解和改进大型推理模型的推理行为提供了理论基础。通过增强模型对计算定律的遵循度，特别是组合性，可以显著提升推理性能，这为未来推理模型的设计和优化提供了重要指导。

Abstract: Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Hermitian Hulls of Rational Algebraic Geometry Codes and Applications in Quantum Codes](https://arxiv.org/abs/2512.17128)
*Lin Sok,Martianus Frederic Ezerman,Ling San*

Main category: cs.IT

TL;DR: 本文提出了一种基于代数函数场工具的系统方法，用于确定广义有理代数几何码的Hermitian壳维度下界，并利用这些结果构造具有设计Hermitian壳维度的MDS码，最终得到两类新的MDS纠缠辅助量子纠错码。


<details>
  <summary>Details</summary>
Motivation: 近年来对线性码壳结构的研究日益增长，但相比欧几里得内积，Hermitian内积的研究相对较少。本文旨在开发系统方法来确定码的Hermitian壳维度和对偶距离，这些参数对于设计纠缠辅助量子纠错码(EAQECCs)至关重要。

Method: 使用单变量代数函数场工具，有效确定广义有理代数几何码的Hermitian壳维度下界。通过选择特定的评估点集，使得与Hermitian对偶码相关的Weil微分留数具有易于验证的性质，从而系统构造具有设计Hermitian壳维度的码。

Result: 成功构造了基于Reed-Solomon码及其推广的具有设计Hermitian壳维度的MDS码，并利用Hermitian方法得到了两类新的MDS纠缠辅助量子纠错码，这些量子码具有优异的参数且均为新的构造。

Conclusion: 本文提出的代数函数场方法能够系统确定广义有理代数几何码的Hermitian壳维度下界，为构造具有特定Hermitian壳维度的码提供了有效工具，并成功应用于设计新的MDS纠缠辅助量子纠错码，推动了量子纠错码参数设计的发展。

Abstract: Interest in the hulls of linear codes has been growing rapidly. More is known when the inner product is Euclidean than Hermitian. A shift to the latter is gaining traction. The focus is on a code whose Hermitian hull dimension and dual distance can be systematically determined. Such a code can serve as an ingredient in designing the parameters of entanglement-assisted quantum error-correcting codes (EAQECCs).
  We use tools from algebraic function fields of one variable to efficiently determine a good lower bound on the Hermitian hull dimensions of generalized rational algebraic geometry (AG) codes. We identify families of AG codes whose hull dimensions can be well estimated by a lower bound. Given such a code, the idea is to select a set of evaluation points for which the residues of the Weil differential associated with the Hermitian dual code has an easily verifiable property.
  The approach allows us to construct codes with designed Hermitian hull dimensions based on known results on Reed-Solomon codes and their generalization. Using the Hermitian method on these maximum distance separable (MDS) codes with designed hull dimensions yields two families of MDS EAQECCs. We confirm that the excellent parameters of the quantum codes from these families are new.

</details>


### [26] [Quasi-recursive MDS Matrices over Galois Rings](https://arxiv.org/abs/2512.17256)
*Shakir Ali,Atif Ahmad Khan,Abhishek Kesarwani,Susanta Samanta*

Main category: cs.IT

TL;DR: 本文研究Galois环上的拟递归MDS矩阵，基于斜多项式环提出多种直接构造方法，扩展了现有构造并增大了可用矩阵族，在密码学扩散层中有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有递归MDS矩阵构造主要局限于交换环环境，需要扩展到非交换设置以扩大可用矩阵族，为密码学中的高效扩散层提供更多选择。

Method: 基于Galois环上的斜多项式环GR(p^s, p^{sm})[X;σ]，利用其丰富的分解性质和扩展的多项式类定义伴随矩阵，建立三个判别准则：两个用于特征化产生递归MDS矩阵的多项式，一个基于Wedderburn多项式的右根，然后开发构造拟递归MDS矩阵的斜多项式方法。

Result: 建立了Galois环上拟递归MDS矩阵的判别准则和构造方法，将已知构造扩展到非交换设置，显著扩大了可用矩阵族，特别适用于p=2,s=1的有限域情况，在密码学实践中具有应用价值。

Conclusion: 提出的框架成功扩展了递归MDS矩阵构造到非交换环环境，为密码学扩散层设计提供了更丰富的矩阵选择，特别是在有限域F_{2^m}上的应用具有实际意义。

Abstract: Let $p$ be a prime and $s,m,n$ be positive integers. This paper studies quasi-recursive MDS matrices over Galois rings $GR(p^{s}, p^{sm})$ and proposes various direct construction methods for such matrices. The construction is based on skew polynomial rings $GR(p^{s}, p^{sm})[X;σ]$, whose rich factorization properties and enlarged class of polynomials are used to define companion matrices generating quasi-recursive MDS matrices. First, two criteria are established for characterizing polynomials that yield recursive MDS matrices, generalizing existing results, and then an additional criterion is derived in terms of the right roots of the associated Wedderburn polynomial. Using these criteria, methods are developed to construct skew polynomials that give rise to quasi-recursive MDS matrices over Galois rings. This framework extends known constructions to the non-commutative setting and significantly enlarges the family of available matrices, with potential applications to efficient diffusion layers in cryptographic primitives. The results are particularly relevant for practical implementations when $s = 1$ and $p = 2$, i.e., over the finite field $\mathbb{F}_{2^m}$, which is of central interest in real-world cryptographic applications.

</details>


### [27] [A distance-free approach to generalized weights](https://arxiv.org/abs/2512.17542)
*Andrea Di Giusto,Elisa Gorla,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 提出线性码任意距离下广义权重的统一理论，通过选择测试族定义权重，证明弱递增性、严格递增子序列和类Wei对偶定理，应用于Hamming、秩度量、和秩度量码，并探索基于MDS/MRD码的广义权重。


<details>
  <summary>Details</summary>
Motivation: 现有广义权重理论通常基于支撑或反码，缺乏统一框架处理任意距离度量。需要建立更一般的理论，能够统一处理Hamming、秩度量、和秩度量等多种度量下的广义权重，并揭示其共同数学结构。

Method: 提出基于测试族的统一框架：选择空间族作为测试族，通过码与测试族中空间的交集定义广义权重。证明权重弱递增性、严格递增子序列存在性、类Wei对偶定理。将框架应用于Hamming度量（选择最优反码）、秩度量、和秩度量码，并探索基于MDS/MRD码的测试族。

Result: 建立了广义权重的统一理论，证明了弱递增性、严格递增子序列、对偶定理等基本性质。将框架应用于Hamming和秩度量码时恢复经典结果，为和秩度量码提出新测试族，扩展了对偶定理到含Hamming分量的和秩度量码，探索了基于MDS/MRD码的广义权重。

Conclusion: 提出的统一框架为线性码任意距离下的广义权重提供了理论基础，揭示了不同度量下广义权重的共同数学结构。该框架具有灵活性，通过选择不同测试族可捕获码的不同特性，为未来研究提供了新方向。

Abstract: We propose a unified theory of generalized weights for linear codes endowed with an arbitrary distance. Instead of relying on supports or anticodes, the weights of a code are defined via the intersections of the code with a chosen family of spaces, which we call a test family. The choice of test family determines the properties of the corresponding generalized weights and the characteristics of the code that they capture. In this general framework, we prove that generalized weights are weakly increasing and that certain subsequences are strictly increasing. We also prove a duality result reminiscent of Wei's Duality Theorem. The corresponding properties of generalized Hamming and rank-metric weights follow from our general results by selecting optimal anticodes as a test family. For sum-rank metric codes, we propose a test family that results in generalized weights that are closely connected to -- but not always the same as -- the usual generalized weights. This choice allows us to extend the known duality results for generalized sum-rank weights to some sum-rank-metric codes with a nonzero Hamming component. Finally, we explore a family of generalized weights obtained by intersecting the underlying code with MDS or MRD codes.

</details>


### [28] [Locally-APN Binomials with Low Boomerang Uniformity in Odd Characteristic](https://arxiv.org/abs/2512.17603)
*Namhun Koo,Soonhak Kwon,Minwoo Ko,Byunguk Kim*

Main category: cs.IT

TL;DR: 该论文研究了有限域上特定函数F_r(x)的局部APN性质和回旋均匀性，扩展了先前结果，并分析了几个具体函数的微分谱和回旋谱。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明当q≡3(mod4)时，函数F_r(x)=x^r+x^{r+(q-1)/2}具有局部APN性质且回旋均匀性最多为2。本文旨在扩展这些结果，研究更一般的条件，并分析具体函数的微分谱和回旋谱。

Method: 通过数学分析，建立了一个更一般的条件：如果对于所有b∈F_q*，满足χ(x)=χ(x+1)=1且(x+1)^r - x^r = b的x最多只有一个，且gcd(r,q-1)∣2，则F_r是局部APN且回旋均匀性最多为2。然后具体研究了F_3和F_{(2q-1)/3}的微分谱，以及p=3时F_2的回旋谱。

Result: 扩展了先前结果，建立了更一般的局部APN和回旋均匀性条件。具体分析了F_3和F_{(2q-1)/3}的微分谱，以及在p=3时F_2的回旋谱特性。

Conclusion: 论文成功扩展了有限域上特定函数类F_r的局部APN和回旋均匀性结果，为密码学中S盒的设计和分析提供了更多理论支持，特别是在抵抗差分和回旋攻击方面。

Abstract: Recently, several studies have shown that when $q\equiv3\pmod{4}$, the function $F_r(x)=x^r+x^{r+\frac{q-1}{2}}$ defined over $\mathbb{F}_q$ is locally-APN and has boomerang uniformity at most~$2$. In this paper, we extend these results by showing that if there is at most one $x\in \mathbb{F}_q$ with $χ(x)=χ(x+1)=1$ satisfying $(x+1)^r - x^r = b$ for all $b\in \mathbb{F}_q^*$ and $\gcd(r,q-1)\mid 2$, then $F_r$ is locally-APN with boomerang uniformity at most $2$. Moreover, we study the differential spectra of $F_3$ and $F_{\frac{2q-1}{3}}$, and the boomerang spectrum of $F_2$ when $p=3$.

</details>


### [29] [Iterative Gaussian Approximation for Random Spreading Unsourced Random Access](https://arxiv.org/abs/2512.17628)
*Liandong Hu,Jian Dang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 提出一种适用于随机扩频类非授权随机接入的迭代高斯近似解码器，通过软信息迭代提升解码性能


<details>
  <summary>Details</summary>
Motivation: 大规模机器类型通信需要高效支持海量连接，非授权随机接入具有高谱效和能效优势，其中随机扩频类别具有强抗干扰能力，但需要有效的解码器

Method: 设计了一种通用的迭代高斯近似解码器，通过迭代外在和内在软信息来增强解码性能，只需少量迭代即可收敛

Result: 数值结果验证了该解码器在性能和鲁棒性方面的有效性

Conclusion: 提出的迭代高斯近似解码器为随机扩频类非授权随机接入提供了一种高效可靠的解决方案

Abstract: Massive machine-type communications (mMTC) demand robust solutions to support extensive connectivity efficiently. Unsourced random access (URA) has emerged as a promising approach, delivering high spectral and energy efficiency. Among URA code structures, the random spreading (RS) category is a key enabler, providing strong anti-interference capabilities through spectrum spreading gain. Notably, RS-URA approaches theoretical performance limits over the Gaussian multiple access channel in scenarios with few active users. In this paper, we propose an iterative Gaussian approximation decoder designed universally for RS-URA categories. The proposed receiver iterates extrinsic and intrinsic soft information to enhance decoding performance, requiring only a few iterations to converge. Numerical results validate the decoder's effectiveness in terms of performance and robustness.

</details>
