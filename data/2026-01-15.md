<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.IT](#cs.IT) [Total: 29]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Streamlined Pathway (SP) Approach: An Efficient Load Balancer to Enhance Quality of Service](https://arxiv.org/abs/2601.08887)
*Aymen Hasan Alawadi*

Main category: cs.NI

TL;DR: 提出一种基于SDN的流调度模型SP，仅需最小化统计信息（端口吞吐量和大象流信息），即可在数据中心网络中实现优于现有技术的负载均衡和QoS提升。


<details>
  <summary>Details</summary>
Motivation: 数据中心网络需要高效的负载均衡机制来最大化性能和QoS，但在最小化资源消耗的同时获得最优QoS仍然是一个重大挑战。现有方法通常需要大量数据平面统计信息。

Method: 提出SP（Streamlined Pathway）模型，这是一种基于SDN的流调度解决方案。该模型仅需要从数据中心数据平面收集最小但强大的统计数据集，包括端口吞吐量和胖树拓扑中汇聚交换机上的大象流信息。与传统哈希调度的ECMP相比，SP利用SDN范式减少信息收集需求。

Result: 实验和理论分析表明，SP模型在QoS增强方面表现出色。在二分带宽、链路利用率、丢包率和数据包传输延迟方面，SP均优于Sieve、Hedera和ECMP等领先技术。

Conclusion: SP模型通过最小化统计信息需求，实现了数据中心网络的高效负载均衡和QoS提升，为实际部署提供了实用且高效的解决方案。

Abstract: Efficient load-balancing mechanisms are critical for maximizing performance and increasing the quality of service (QoS) of data center networks (DCNs). Obtaining the optimal QoS while minimizing resource consumption remains a significant challenge. This paper proposes the streamlined pathway (SP) model, which is a flow scheduling solution that requires minimal statistical knowledge of the DCN data plane. The SP model utilizes the software-defined networks (SDN) paradigm with less information gathered from the DCN data plane, besides the traditional hash-based flow scheduling mechanism, the Equal Cost Multi-Path (ECMP). In SDN, the proposed methodology harnesses a minimal yet powerful set of statistical data extracted from the DCN data plane, including port throughput and elephant flow information on the aggregate switches of the DCN fat-tree topology. Several experiments, in addition to theoretical analysis, have been conducted to demonstrate the efficiency of the proposed SP model in terms of QoS enhancement. These results confirm that SP outperforms leading techniques such as Sieve, Hedera, and ECMP, concerning bisection bandwidth, DCN link utilization, packet loss, and packet delivery latency.

</details>


### [2] [UAV-enabled Computing Power Networks: Design and Performance Analysis under Energy Constraints](https://arxiv.org/abs/2601.09493)
*Yiqin Deng,Zhengru Fang,Senkang Hu,Yanan Ma,Xiaoyu Guo,Haixia Zhang,Yuguang Fang*

Main category: cs.NI

TL;DR: 本文提出了一种基于自适应无人机定位的无人机计算能力网络（UAV-CPN），通过无人机作为动态中继，将计算任务从请求区域外包到扩展的服务区域，以缓解通信瓶颈和边缘计算的"孤岛效应"。


<details>
  <summary>Details</summary>
Motivation: 为了解决多接入边缘计算中存在的通信瓶颈和"孤岛效应"问题，同时充分利用分布式计算资源，需要一种能够动态扩展计算服务范围并提高计算节点可访问性的创新框架。

Method: 提出UAV-CPN框架，将无人机作为动态中继，连接请求区域和包含车载单元、边缘服务器、专用强大节点等多样化计算节点的扩展服务区域。引入任务完成概率来量化计算能力性能，并在混合能源架构下联合优化无人机高度和发射功率。

Result: 广泛评估显示显著性能提升，强调了在双重能源约束下平衡通信和计算能力的重要性。混合能源架构（燃料电池和电池）能够同时为无人机推进和通信系统供电，进一步提升了系统性能。

Conclusion: UAV-CPN具有显著提升计算能力的潜力，通过动态中继和优化策略能够有效缓解通信瓶颈，克服边缘计算的"孤岛效应"，为分布式计算资源的高效利用提供了创新解决方案。

Abstract: This paper presents an innovative framework that boosts computing power by utilizing ubiquitous computing power distribution and enabling higher computing node accessibility via adaptive UAV positioning, establishing a UAV-enabled Computing Power Network (UAV-CPN). In a UAV-CPN, a UAV functions as a dynamic relay, outsourcing computing tasks from the request zone to an expanded service zone with diverse computing nodes, including vehicle onboard units, edge servers, and dedicated powerful nodes. This approach has the potential to alleviate communication bottlenecks and overcome the "island effect" observed in multi-access edge computing. A significant challenge is to quantify computing power performance under complex dynamics of communication and computing. To address this challenge, we introduce task completion probability to capture the capability of UAV-CPNs for task computing. We further enhance UAV-CPN performance under a hybrid energy architecture by jointly optimizing UAV altitude and transmit power, where fuel cells and batteries collectively power both UAV propulsion and communication systems. Extensive evaluations show significant performance gains, highlighting the importance of balancing communication and computing capabilities, especially under dual-energy constraints. These findings underscore the potential of UAV-CPNs to significantly boost computing power.

</details>


### [3] [FairShare: Auditable Geographic Fairness for Multi-Operator LEO Spectrum Sharing](https://arxiv.org/abs/2601.09641)
*Seyed Bagher Hashemi Natanzi,Hossein Mohammadi,Vuk Marojevic,Bo Tang*

Main category: cs.NI

TL;DR: 研究发现传统动态频谱共享方法会加剧城乡数字鸿沟，提出FairShare框架实现地理公平性


<details>
  <summary>Details</summary>
Motivation: 现有多运营商LEO星座动态频谱共享政策主要关注干扰抑制，但忽视了地理公平性，可能导致农村数字鸿沟加剧

Method: 通过大规模3GPP兼容的非地面网络模拟，评估标准分配政策，并提出FairShare - 基于配额的轻量级地理公平框架

Result: 传统SNR优先调度导致1.65倍城乡接入差距，增加带宽反而加剧不平等；FairShare将差距降至0.72倍，同时减少调度器运行时间3.3%

Conclusion: 算法公平性可以在不牺牲效率或复杂度的情况下实现，为下一代卫星网络提供了公平性审计指标和可执行的频谱治理机制

Abstract: Dynamic spectrum sharing (DSS) among multi-operator low Earth orbit (LEO) mega-constellations is essential for coexistence, yet prevailing policies focus almost exclusively on interference mitigation, leaving geographic equity largely unaddressed. This work investigates whether conventional DSS approaches inadvertently exacerbate the rural digital divide. Through large-scale, 3GPP-compliant non-terrestrial network (NTN) simulations with geographically distributed users, we systematically evaluate standard allocation policies. The results uncover a stark and persistent structural bias: SNR-priority scheduling induces a 1.65x urban-rural access disparity, privileging users with favorable satellite geometry. Counter-intuitively, increasing system bandwidth amplifies rather than alleviates this gap, with disparity rising from 1.0x to 1.65x as resources expand. To remedy this, we propose FairShare, a lightweight, quota-based framework that enforces geographic fairness. FairShare not only reverses the bias, achieving an affirmative disparity ratio of Delta_geo = 0.72x, but also reduces scheduler runtime by 3.3%. This demonstrates that algorithmic fairness can be achieved without trading off efficiency or complexity. Our work provides regulators with both a diagnostic metric for auditing fairness and a practical, enforceable mechanism for equitable spectrum governance in next-generation satellite networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue](https://arxiv.org/abs/2601.08950)
*Mayank Sharma,Roy Pea,Hari Subramonyam*

Main category: cs.AI

TL;DR: 该论文提出了ConvoLearn数据集，基于知识建构理论定义了六个核心教学维度，通过微调LLM使其从直接提供答案转向支持对话式学习，在教师评估中显著优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 当前教育应用中，大语言模型存在根本性教学局限性，倾向于直接揭示解决方案而非支持对话式学习。需要开发能够促进知识建构的AI导师。

Method: 1. 构建ConvoLearn数据集：基于知识建构理论定义六个教学维度（认知参与、形成性评估、责任性、文化响应性、元认知、权力动态）；2. 创建半合成数据集：通过人类教师与模拟学生的受控互动，生成1250个中学地球科学领域的师生对话（每个20轮）；3. 使用QLoRA技术对Mistral 7B模型进行微调。

Result: 31名教师的人类评估显示，微调后的Mistral 7B模型（M=4.10，SD=1.03）在整体表现上显著优于其基础版本（M=2.59，SD=1.11）和Claude Sonnet 4.5（M=2.87，SD=1.29）。训练有效将LLM行为转向知识建构策略。

Conclusion: 这项工作为未来建构主义AI导师的开发和评估建立了潜在框架，证明了基于教学理论的数据集和微调方法能够有效改善LLM在教育应用中的教学行为。

Abstract: In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.

</details>


### [5] [ART: Action-based Reasoning Task Benchmarking for Medical AI Agents](https://arxiv.org/abs/2601.08988)
*Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji*

Main category: cs.AI

TL;DR: ART是一个基于行动推理的临床任务基准，用于评估医疗AI代理在电子健康记录上的多步推理能力，揭示现有模型在聚合和阈值推理方面的显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 可靠的临床决策支持需要能够安全进行多步推理的医疗AI代理，但现有基准无法充分评估涉及阈值评估、时间聚合和条件逻辑的行动型任务性能。

Method: 通过四阶段流水线（场景识别、任务生成、质量审计和评估）从真实EHR数据中创建具有挑战性的任务，识别三种主要错误类型：检索失败、聚合错误和条件逻辑误判。

Result: 评估GPT-4o-mini和Claude 3.5 Sonnet在600个任务上显示，经过提示优化后检索近乎完美，但在聚合（28-64%）和阈值推理（32-38%）方面存在显著差距。

Conclusion: ART通过暴露行动导向的EHR推理中的失败模式，推动更可靠的临床代理发展，这是减少认知负荷和行政负担、支持高需求护理环境中工作能力的关键步骤。

Abstract: Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, we identify three dominant error categories: retrieval failures, aggregation errors, and conditional logic misjudgments. Our four-stage pipeline -- scenario identification, task generation, quality audit, and evaluation -- produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28--64%) and threshold reasoning (32--38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings

</details>


### [6] [The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments](https://arxiv.org/abs/2601.09032)
*Logan Ritchie,Sushant Mehta,Nick Heiner,Mason Yu,Edwin Chen*

Main category: cs.AI

TL;DR: 该研究评估前沿AI模型在电商RL环境中的150个工作场所任务表现，揭示了模型需掌握的五大能力层次，发现即使最佳模型仍有约40%任务失败，表明当前模型距离真实工作场景中的人类水平仍有显著差距。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体发展，AI评估已从单轮响应评估转向交互环境中的多步任务完成评估。研究旨在评估前沿AI模型在真实电商RL环境中的工作场所任务表现，识别模型在实际部署中需要掌握的关键能力层次。

Method: 采用实证研究方法，在Surge提供的真实电商RL环境中评估前沿AI模型在150个工作场所任务上的表现。引入以任务为中心的环境设计方法，强调多样性和领域专家贡献，并进行详细的失败分析。

Result: 研究发现模型需掌握五大能力层次：工具使用、规划与目标形成、适应性、接地性、常识推理。即使最佳模型仍有约40%任务失败，失败模式沿能力层次可预测分布：较弱模型在基础工具使用和规划上挣扎，较强模型主要在需要超出明确指令的上下文推理任务上失败。

Conclusion: 当前前沿模型虽能展示连贯的多步行为，但在真实工作场所环境中实现人类水平任务完成仍存在显著能力差距。研究为智能体开发提供了重要启示，强调了模型能力层次的重要性。

Abstract: The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.

</details>


### [7] [Human-AI Co-design for Clinical Prediction Models](https://arxiv.org/abs/2601.09072)
*Jean Feng,Avni Kothari,Patrick Vossler,Andrew Bishara,Lucas Zier,Newton Addo,Aaron Kornblith,Yan Shuo Tan,Chandan Singh*

Main category: cs.AI

TL;DR: HACHI是一个迭代式人机协同框架，使用AI代理加速开发可解释的临床预测模型，通过探索临床笔记中的概念，结合专家反馈提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统临床预测模型开发需要临床专家、数据科学家和信息学家的迭代协作，过程耗时耗力，且难以处理非结构化临床笔记中的大量概念，导致只有少数模型能进入临床实践。

Method: HACHI采用人机协同框架：AI代理快速探索和评估临床笔记中的候选概念，临床专家提供反馈改进学习过程。概念被定义为用于线性模型的简单是/否问题，确保模型可解释性。

Result: 在急性肾损伤和创伤性脑损伤两个真实预测任务中，HACHI优于现有方法，发现了常用临床预测模型中未包含的新临床相关概念，并提高了模型在不同临床场所和时间段的泛化能力。

Conclusion: HACHI框架有效加速了可解释临床预测模型的开发，同时揭示了临床AI团队在指导AI代理探索新概念、调整概念粒度、优化目标函数以及识别数据偏差等方面的重要作用。

Abstract: Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. This challenge intensifies when teams attempt to incorporate unstructured clinical notes, which can contain an enormous number of concepts. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between (i) an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and (ii) clinical and domain experts providing feedback to improve the CPM learning process. HACHI defines concepts as simple yes-no questions that are used in linear models, allowing the clinical AI team to transparently review, refine, and validate the CPM learned in each round. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage.

</details>


### [8] [Programming over Thinking: Efficient and Robust Multi-Constraint Planning](https://arxiv.org/abs/2601.09097)
*Derrick Goh Xin Deik,Quanyu Long,Zhengyuan Liu,Nancy F. Chen,Wenya Wang*

Main category: cs.AI

TL;DR: SCOPE框架通过分离推理与代码执行，解决了多约束规划中LLM方法的局限性，实现了高效、低成本、可复用的规划解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在多约束规划中存在根本性限制：纯推理方法容易产生不一致、错误累积和高成本；结合代码或求解器的方法缺乏灵活性，无法跨问题泛化通用逻辑。

Method: 提出SCOPE框架，将查询特定推理与通用代码执行解耦，生成一致、确定且可复用的求解器函数，仅需最小化输入参数调整。

Result: 在TravelPlanner任务上，使用GPT-4o达到93.1%成功率，比最佳基线（CoT）提升61.6%，同时降低推理成本1.4倍，减少时间约4.67倍。

Conclusion: SCOPE通过分离推理与执行，实现了多约束规划中的高效、低成本解决方案，为LLM在复杂规划任务中的应用提供了新范式。

Abstract: Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.

</details>


### [9] [DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model](https://arxiv.org/abs/2601.09100)
*Lixiang Zhang,Chenggong Zhao,Qing Gao,Xiaoke Zhao,Gengyi Bai,Jinhu Lv*

Main category: cs.AI

TL;DR: DScheLLM：基于双系统（快慢）推理架构的微调大语言模型动态调度方法，用于处理生产调度中的动态扰动


<details>
  <summary>Details</summary>
Motivation: 传统生产调度方法对动态扰动（如处理时间变化、机器可用性变化、意外任务插入）敏感，通常依赖事件特定模型和显式分析公式，限制了其适应性和对未见扰动的泛化能力

Method: 提出DScheLLM方法，利用微调大语言模型在双系统（快慢）推理架构中处理不同规模的扰动。构建统一的大语言模型框架处理动态事件，使用运筹学求解器获得的精确调度生成快慢推理模式的训练数据集，基于华为OpenPangu Embedded-7B模型使用LoRA进行微调

Result: 在标准作业车间调度基准测试中，快思考模式能高效生成高质量调度，慢思考模式能生成与求解器兼容且格式良好的决策输入。这是最早将大语言模型应用于动态环境作业车间调度的研究之一

Conclusion: 大语言模型在智能自适应调度优化方面具有巨大潜力，DScheLLM展示了其在处理生产调度动态扰动方面的有效性

Abstract: Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.

</details>


### [10] [AviationLMM: A Large Multimodal Foundation Model for Civil Aviation](https://arxiv.org/abs/2601.09105)
*Wenbin Li,Jingling Wu,Xiaoyong Lin. Jing Chen,Cong Chen*

Main category: cs.AI

TL;DR: 提出AviationLMM愿景：一个用于民航的大型多模态基础模型，旨在统一民航异构数据流，实现理解、推理、生成和智能体应用。


<details>
  <summary>Details</summary>
Motivation: 当前民航AI解决方案存在孤岛化和局限性，难以整合语音通信、雷达轨迹、传感器流和文本报告等异构数据，限制了态势感知、适应性和实时决策支持。

Method: 提出AviationLMM模型架构，能够处理空-地语音、监视、机载遥测、视频和结构化文本等多模态输入，进行跨模态对齐和融合，并产生从态势摘要、风险预警到预测性诊断和多模态事件重建的灵活输出。

Result: 识别了实现该愿景需要解决的关键研究机会，包括数据获取、对齐与融合、预训练、推理、可信度、隐私、缺失模态鲁棒性和合成场景生成。

Conclusion: 通过阐述AviationLMM的设计和挑战，旨在推动民航基础模型的发展，并促进研究界共同努力构建集成、可信和隐私保护的民航AI生态系统。

Abstract: Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.

</details>


### [11] [The AI Hippocampus: How Far are We From Human Memory?](https://arxiv.org/abs/2601.09113)
*Zixia Jia,Jiaqi Li,Yipeng Kang,Yuxuan Wang,Tong Wu,Quansen Wang,Xiaobo Wang,Shuyi Zhang,Junzhe Shen,Qing Li,Siyuan Qi,Yitao Liang,Di He,Zilong Zheng,Song-Chun Zhu*

Main category: cs.AI

TL;DR: 这篇综述系统性地分析了LLMs和MLLMs中的记忆机制，将其分为隐式、显式和代理记忆三种范式，并探讨了多模态环境下的记忆整合、关键架构进展和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和多模态大模型从静态预测器向能够持续学习和个性化推理的交互式系统转变，记忆机制已成为其架构和功能演化的核心主题。需要系统地组织和理解这一领域的研究进展。

Method: 采用文献综述方法，将现有研究组织成一个连贯的分类体系，包含隐式记忆、显式记忆和代理记忆三种范式。具体分析了每种记忆类型的特征、实现方式和应用场景。

Result: 提出了一个全面的记忆分类框架：1) 隐式记忆：预训练transformer内部参数中嵌入的知识；2) 显式记忆：外部存储和检索组件；3) 代理记忆：自主代理中的持久时间扩展记忆结构。还探讨了多模态环境下的记忆整合。

Conclusion: 记忆机制对于增强LLMs和MLLMs的推理能力、适应性和上下文保真度具有基础性作用。未来研究需要解决记忆容量、对齐、事实一致性和跨系统互操作性等关键挑战，特别是在多模态和交互式AI系统中。

Abstract: Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.

</details>


### [12] [PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?](https://arxiv.org/abs/2601.09152)
*Yiwen Tu,Xuan Liu,Lianhui Qin,Haojian Jin*

Main category: cs.AI

TL;DR: PRA是一个AI代理设计，用于模拟个体用户如何根据现实世界新闻形成隐私担忧。它超越了群体层面的情感分析，整合隐私和认知理论，基于个人评论历史和上下文线索模拟用户特定的隐私推理。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注群体层面的隐私情感分析，缺乏对个体用户隐私担忧形成机制的模拟。需要开发能够理解用户特定隐私推理模式、基于个人历史和行为动态模拟隐私担忧形成的AI代理。

Method: PRA整合隐私和认知理论，重建用户的"隐私心智"，通过上下文过滤器动态激活相关隐私记忆（模拟有限理性），生成反映用户对新隐私场景可能反应的合成评论。使用基于既定隐私担忧分类法校准的LLM-as-a-Judge评估器量化生成推理的忠实度。

Result: 在真实世界Hacker News讨论上的实验表明，PRA在隐私担忧预测方面优于基线代理，并能捕捉跨领域（包括AI、电子商务和医疗保健）的可转移推理模式。

Conclusion: PRA提供了一个有效的框架来模拟个体用户的隐私担忧形成过程，能够基于个人历史和行为模式生成忠实的隐私推理，在跨领域场景中表现出良好的可转移性。

Abstract: This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's "privacy mind", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of generated reasoning. Experiments on real-world Hacker News discussions show that \PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.

</details>


### [13] [Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback](https://arxiv.org/abs/2601.09182)
*JungMin Yun,JuneHyoung Kwon,MiHyeon Kim,YoungBin Kim*

Main category: cs.AI

TL;DR: 本文提出以LLM辅助人类审稿人而非自动生成审稿，通过教育指导提升审稿质量，解决AI研究快速发展导致的审稿人缺口问题


<details>
  <summary>Details</summary>
Motivation: AI研究的快速扩张加剧了"审稿人缺口"，威胁同行评审的可持续性，并导致低质量评审的恶性循环。现有LLM自动生成审稿的方法存在不足，需要转向更有效的人类中心化解决方案。

Method: 提出范式转变：将LLM定位为辅助和教育人类审稿人的工具。基于高质量同行评审的核心原则，设计两个互补系统：1) LLM辅助指导系统，培养审稿人长期能力；2) LLM辅助反馈系统，帮助审稿人改进评审质量。

Result: 通过人类中心化的LLM辅助方法，旨在增强审稿人专业知识，打破低质量评审循环，为构建更可持续的学术生态系统做出贡献。

Conclusion: LLM不应替代人类审稿人自动生成评审，而应作为辅助工具来教育和提升人类审稿人能力，这是解决审稿人缺口、提高同行评审质量并确保学术生态系统可持续发展的更有效途径。

Abstract: The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.

</details>


### [14] [MAXS: Meta-Adaptive Exploration with LLM Agents](https://arxiv.org/abs/2601.09259)
*Jian Zhang,Zhiyuan Wang,Zhangqi Wang,Yu He,Haoran Luo,li yuan,Lingling Zhang,Rui Mao,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: MAXS是一个基于LLM Agent的元自适应推理框架，通过前瞻策略和轨迹收敛机制，解决多工具推理中的局部短视和轨迹不稳定问题，在性能和推理效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM Agent方法存在两个主要问题：1) 局部短视生成，缺乏前瞻性；2) 轨迹不稳定，早期微小错误会导致推理路径发散。这使得难以平衡全局有效性和计算效率。

Method: 提出MAXS框架：1) 使用前瞻策略扩展推理路径几步，估计工具使用的优势值；2) 结合步骤一致性方差和步骤间趋势斜率，联合选择稳定、一致且高价值的推理步骤；3) 引入轨迹收敛机制，一旦路径一致性达成即停止进一步展开，控制计算成本。

Result: 在三个基础模型（MiMo-VL-7B、Qwen2.5-VL-7B、Qwen2.5-VL-32B）和五个数据集上的广泛实验表明，MAXS在性能和推理效率上均优于现有方法。进一步分析证实了前瞻策略和工具使用的有效性。

Conclusion: MAXS通过元自适应推理框架有效解决了LLM Agent推理中的局部短视和轨迹不稳定问题，实现了资源效率和全局有效性的平衡，在多工具推理任务中表现出色。

Abstract: Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.

</details>


### [15] [Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models](https://arxiv.org/abs/2601.09260)
*Yan Liu,Feng Zhang,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Han Liu,Yangdong Deng*

Main category: cs.AI

TL;DR: CoT-Flow：将离散推理步骤重构为连续概率流，量化每个步骤对正确答案的贡献，实现流引导解码和流强化学习，提升推理效率与性能


<details>
  <summary>Details</summary>
Motivation: 当前思维链方法将推理过程视为不可分割的序列，缺乏量化逐步信息增益的内在机制，导致推理效率低下（冗余探索）和优化困难（稀疏监督或昂贵验证器）

Method: 提出CoT-Framework，将离散推理步骤重构为连续概率流，量化每个步骤对正确答案的贡献。基于此框架开发两种方法：1）流引导解码：使用贪婪的基于流的解码策略提取信息高效的推理路径；2）流强化学习：构建无需验证器的密集奖励函数

Result: 在具有挑战性的基准测试中，CoT-Flow在推理效率和推理性能之间实现了优越的平衡

Conclusion: 通过将推理步骤建模为连续概率流，CoT-Flow提供了一种量化逐步信息增益的内在机制，解决了当前思维链方法的局限性，为高效且有效的推理提供了新框架

Abstract: High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.

</details>


### [16] [Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants](https://arxiv.org/abs/2601.09264)
*Ziyi Shi,Xusen Guo,Hongliang Lu,Mingxing Peng,Haotian Wang,Zheng Zhu,Zhenning Li,Yuxuan Liang,Xinhu Zheng,Hai Yang*

Main category: cs.AI

TL;DR: 提出基于大语言模型的多智能体政策制定框架，通过模拟和协调跨区域政策决策，实现更有效的疫情控制


<details>
  <summary>Details</summary>
Motivation: 传统疫情控制政策制定存在碎片化和反应式的问题，各地区政策孤立制定且调整滞后，缺乏主动干预和全局协调，影响疫情防控效果

Method: 为每个行政区分配一个LLM智能体作为AI政策制定助手，智能体基于区域特定流行病学动态进行推理，同时与其他智能体通信考虑跨区域相互依赖，整合真实数据、疫情演化模拟器和结构化智能体间通信

Result: 使用美国2020年4-12月州级COVID-19数据验证，相比真实疫情结果，在单个州层面累计感染和死亡分别减少63.7%和40.1%，跨州聚合层面分别减少39.0%和27.0%

Conclusion: LLM多智能体系统能够通过协调政策制定实现更有效的疫情控制，为公共卫生决策提供新方法

Abstract: Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...

</details>


### [17] [RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering](https://arxiv.org/abs/2601.09269)
*Wencheng Ye,Liang Peng,Xiaoyang Yuan,Yi Bin,Pengpeng Zeng,Hengyu Jin,Heng Tao Shen*

Main category: cs.AI

TL;DR: RISER是一个基于路由器的自适应激活干预框架，通过强化学习动态组合可复用推理向量，在零样本场景下提升LLM推理性能，同时保持高token效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活干预的方法采用静态、手动干预，无法适应复杂推理的动态特性，而训练密集型方法需要参数更新，不够高效。

Method: 构建可复用推理向量库，使用轻量级路由器动态组合这些向量，通过强化学习在任务级奖励下优化路由器，以涌现和组合方式激活潜在认知原语。

Result: 在7个多样化基准测试中，RISER相比基础模型平均零样本准确率提升3.4-6.5%，超越思维链推理，token效率提高2-3倍，并保持稳健的准确率增益。

Conclusion: RISER能够自主组合多个向量形成可解释的精确控制策略，为实现更可控、高效的LLM推理指明了方向。

Abstract: Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.

</details>


### [18] [$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation](https://arxiv.org/abs/2601.09274)
*Jian Zhang,Yu He,Zhiyuan Wang,Zhangqi Wang,Kai He,Fangzhi Xu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: A³-Bench是一个评估科学推理中记忆驱动机制的新基准，关注锚点和吸引子的激活与整合，而非仅评估最终答案或逐步一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估最终答案或逐步推理一致性，忽视了人类推理中基于记忆驱动的机制，即激活先验知识和经验结构（锚点和吸引子）并整合到多步推理中。

Method: 1. 使用SAPM过程标注2,198个跨领域科学推理问题；2. 提出基于锚点和吸引子的双尺度记忆评估框架；3. 引入AAUI指标衡量记忆激活率；4. 通过不同基础模型和范式的实验验证基准。

Result: 验证了A³-Bench基准的有效性，分析了记忆激活如何影响推理性能，为理解记忆驱动的科学推理提供了见解。

Conclusion: 该研究填补了评估科学推理中记忆驱动机制的空白，提出的A³-Bench基准和评估框架有助于深入理解记忆在推理中的作用，为改进AI推理系统提供指导。

Abstract: Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.

</details>


### [19] [M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning](https://arxiv.org/abs/2601.09278)
*Xiaohan Yu,Chao Feng,Lang Mei,Chong Chen*

Main category: cs.AI

TL;DR: M³Searcher是一个模块化多模态信息搜索代理，通过解耦信息获取与答案推导，使用检索导向的多目标奖励优化，在复杂多模态任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有DeepResearch风格代理仅限于文本模态，扩展到多模态面临两个关键挑战：规模化多模态工具使用的专业化-泛化权衡，以及复杂多步多模态搜索轨迹训练数据的严重稀缺。

Method: 提出M³Searcher模块化多模态信息搜索代理，明确解耦信息获取与答案推导；使用检索导向的多目标奖励联合优化事实准确性、推理合理性和检索保真度；开发MMSearchVQA多模态多跳数据集支持检索中心强化学习训练。

Result: 实验结果表明M³Searcher优于现有方法，在复杂多模态任务中展现出强大的迁移适应能力和有效推理能力。

Conclusion: M³Searcher通过模块化设计和多目标奖励优化，成功解决了多模态信息搜索中的专业化-泛化权衡和数据稀缺问题，为多模态自主信息获取代理提供了有效解决方案。

Abstract: Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesize from real-world web environments. However, existing approaches remain fundamentally limited to text modality. Extending autonomous information-seeking agents to multimodal settings introduces critical challenges: the specialization-generalization trade-off that emerges when training models for multimodal tool-use at scale, and the severe scarcity of training data capturing complex, multi-step multimodal search trajectories. To address these challenges, we propose M$^3$Searcher, a modular multimodal information-seeking agent that explicitly decouples information acquisition from answer derivation. M$^3$Searcher is optimized with a retrieval-oriented multi-objective reward that jointly encourages factual accuracy, reasoning soundness, and retrieval fidelity. In addition, we develop MMSearchVQA, a multimodal multi-hop dataset to support retrieval centric RL training. Experimental results demonstrate that M$^3$Searcher outperforms existing approaches, exhibits strong transfer adaptability and effective reasoning in complex multimodal tasks.

</details>


### [20] [STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models](https://arxiv.org/abs/2601.09281)
*Jingjing Zhou,Gaoxiang Cong,Li Su,Liang Li*

Main category: cs.AI

TL;DR: STaR：针对大型推理模型的参数无关推理时遗忘框架，通过语义检测、安全提示前缀、轨迹感知抑制和自适应过滤，实现推理链全过程的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）能生成复杂的思维链轨迹，但这也带来了严重的隐私风险，敏感信息可能深嵌在整个推理过程中。现有的LLM遗忘方法通常只修改最终答案，无法移除中间步骤的敏感内容，导致持续隐私泄露和安全退化。

Method: STaR框架包含四个步骤：1）语义感知检测识别敏感内容；2）通过安全提示前缀注入全局安全约束；3）轨迹感知抑制动态阻断整个推理链中的敏感内容；4）词元级自适应过滤防止生成精确和改写的敏感词元。此外还提出了MCS和MIA两种新评估指标。

Result: 在R-TOFU基准测试中，STaR实现了全面稳定的遗忘效果，同时保持了最小的效用损失，为LRMs的隐私保护推理设立了新标准。

Conclusion: STaR是一个有效的推理时遗忘框架，能够解决LRMs中复杂的隐私保护问题，通过多层次的保护机制确保推理链全过程的隐私安全，同时提出了更全面的评估方法。

Abstract: Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.

</details>


### [21] [Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing](https://arxiv.org/abs/2601.09282)
*Leszek Sliwko,Jolanta Mizeria-Pietraszko*

Main category: cs.AI

TL;DR: 论文提出基于自然语言处理的语义化意图驱动调度范式，通过LLM解析自然语言分配提示，实现集群工作负载的简化配置


<details>
  <summary>Details</summary>
Motivation: 集群工作负载分配通常需要复杂配置，存在可用性差距。需要更直观、语义化的调度方式来降低使用门槛

Method: 使用大型语言模型（LLM）通过Kubernetes调度器扩展器集成，解析自然语言分配提示注释，实现软亲和性偏好。开发原型系统包含集群状态缓存和意图分析器（使用AWS Bedrock）

Result: LLM解析准确率高（>95%子集准确率），Amazon Nova Pro/Premier和Mistral Pixtral Large模型表现最佳。在六种场景的调度质量测试中，原型系统优于或等同于标准Kubernetes配置，尤其在复杂和定量场景以及处理冲突软偏好方面表现突出

Conclusion: 验证了使用LLM进行可访问调度的可行性，但存在同步LLM延迟等限制，建议异步处理以实现生产就绪。确认了语义软亲和性简化工作负载编排的可行性

Abstract: Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.

</details>


### [22] [Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures](https://arxiv.org/abs/2601.09293)
*Sofiene Lassoued,Stefan Lier,Andreas Schwung*

Main category: cs.AI

TL;DR: 提出一个基于着色时间Petri网和可屏蔽近端策略优化的动态作业车间调度框架，用于处理随机作业到达和机器故障的不确定性，通过两种动作屏蔽策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决动态作业车间调度问题中的不确定性挑战，包括随机作业到达和意外机器故障，这些因素在真实工业环境中普遍存在但传统方法难以有效处理。

Method: 采用基于模型的方法：1) 使用着色时间Petri网表示调度环境；2) 使用可屏蔽近端策略优化进行动态决策；3) 用Gamma分布模拟动态作业到达；4) 用Weibull分布模拟机器故障；5) 研究两种动作屏蔽策略（非梯度和梯度方法）。

Result: 在动态JSSP基准测试中，该方法在最小化制造周期方面持续优于传统启发式和基于规则的方法，证明了Petri网模型与自适应强化学习策略结合的有效性。

Conclusion: 结合可解释的Petri网模型与自适应强化学习策略，创建了一个弹性、可扩展且可解释的实时调度框架，适用于动态和不确定的制造环境。

Abstract: We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, which captures complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.

</details>


### [23] [Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving](https://arxiv.org/abs/2601.09353)
*Ioannis Peridis,Dimitrios Troullinos,Georgios Chalkiadakis,Pantelis Giankoulidis,Ioannis Papamichail,Markos Papageorgiou*

Main category: cs.AI

TL;DR: 该论文提出了一种基于蒙特卡洛树搜索（MCTS）的单智能体自动驾驶规划方法，适用于无车道线交通环境，通过神经网络引导搜索过程，在计算约束下平衡安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 无车道线交通环境允许车辆更好地利用道路横向空间，不受车道保持限制，从而提高交通流量。然而，这也为自动驾驶带来了更复杂的挑战，需要新的规划方法来处理这种更灵活但更复杂的交通场景。

Method: 采用蒙特卡洛树搜索（MCTS）作为单智能体自动驾驶规划方法，结合预训练神经网络引导搜索选择阶段。该方法基于马尔可夫决策过程框架，神经网络增强了树搜索的预测能力，在计算约束下实现更智能的决策。

Result: 实验评估了安全性和效率指标，包括碰撞率和速度测量。研究发现：（a）各向同性状态信息在无车道线环境中导致"推挤行为"——车辆因后方快速车辆的存在而调整策略；（b）神经网络引导的MCTS变体加速了性能表现；（c）计算资源与解决方案质量之间存在权衡关系。

Conclusion: MCTS结合神经网络引导的方法在无车道线自动驾驶环境中是有效的，能够在计算约束下平衡安全性和效率，为复杂交通场景下的自动驾驶规划提供了有前景的解决方案。

Abstract: Lane-free traffic environments allow vehicles to better harness the lateral capacity of the road without being restricted to lane-keeping, thereby increasing the traffic flow rates. As such, we have a distinct and more challenging setting for autonomous driving. In this work, we consider a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic, where the associated Markov Decision Process we formulate is influenced from existing approaches tied to reinforcement learning frameworks. In addition, MCTS is equipped with a pre-trained neural network (NN) that guides the selection phase. This procedure incorporates the predictive capabilities of NNs for a more informed tree search process under computational constraints. In our experimental evaluation, we consider metrics that address both safety (through collision rates) and efficacy (through measured speed). Then, we examine: (a) the influence of isotropic state information for vehicles in a lane-free environment, resulting in nudging behaviour--vehicles' policy reacts due to the presence of faster tailing ones, (b) the acceleration of performance for the NN-guided variant of MCTS, and (c) the trade-off between computational resources and solution quality.

</details>


### [24] [Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments](https://arxiv.org/abs/2601.09382)
*Qinglong Shi,Donghai Wang,Hantao Zhou,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He*

Main category: cs.AI

TL;DR: 本文提出了一种面向任务的主动式智能体交互范式，通过意图条件监控和事件触发跟进能力，使智能体能在动态环境中长期适应用户意图变化，并创建了ChronosBench基准验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型智能体主要采用被动响应模式，只能在短期会话中响应用户即时查询，无法维持长期用户意图和适应动态变化的外部环境，这限制了其在复杂任务中的表现。

Method: 提出主动式任务导向智能体范式，包含两个核心能力：1) 意图条件监控 - 基于对话历史自主制定触发条件；2) 事件触发跟进 - 检测到有用环境更新时主动与用户互动。开发高质量数据合成管道构建动态环境中的复杂多轮对话数据，并创建ChronosBench基准进行评估。

Result: 使用合成数据进行监督学习的微调模型在包含用户意图转变的复杂任务中达到85.19%的任务完成率，优于其他测试模型。评估显示当前主流闭源和开源模型在长期任务导向交互中存在缺陷。

Conclusion: 提出的主动式智能体范式能有效桥接相对静态的用户需求与动态环境之间的鸿沟，数据驱动策略验证有效，为长期任务导向交互提供了新的解决方案和评估标准。

Abstract: Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.

</details>


### [25] [EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines](https://arxiv.org/abs/2601.09465)
*Shuo Zhang,Chaofa Yuan,Ryan Guo,Xiaomin Yu,Rui Xu,Zhangquan Chen,Zinuo Li,Zhi Yang,Shuhao Guan,Zhenheng Tang,Sen Hu,Liwen Zhang,Ronghao Chen,Huacan Wang*

Main category: cs.AI

TL;DR: EvoFSM：一个通过演化有限状态机（FSM）实现结构化自进化的框架，将优化空间解耦为宏观流程和微观技能，在保持控制的同时提升LLM智能体对开放问题的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体大多依赖固定工作流，难以适应现实世界的开放性问题。虽然已有研究探索通过重写代码或提示实现自进化，但无约束优化常导致不稳定、幻觉和指令漂移问题。

Method: 提出EvoFSM框架，通过演化显式有限状态机（FSM）而非自由形式重写。将优化空间解耦为宏观流程（状态转移逻辑）和微观技能（状态特定行为），在清晰行为边界下进行针对性改进。采用批评机制指导FSM演化，并通过自进化记忆系统提炼成功轨迹作为可重用先验，失败模式作为未来查询的约束。

Result: 在五个多跳QA基准测试中验证了EvoFSM的有效性，特别是在DeepSearch基准上达到58.0%的准确率。在交互式决策任务上的额外结果进一步验证了其泛化能力。

Conclusion: EvoFSM通过结构化自进化框架，在保持控制的同时实现了LLM智能体的适应性提升，为解决开放性问题提供了有效方案。

Abstract: While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.

</details>


### [26] [What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding](https://arxiv.org/abs/2601.09503)
*Siyuan Liu,Hongbang Yuan,Xinze Li,Ziyue Zhu,Yixin Cao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 论文提出T2Q评估范式，通过将任务执行与环境理解解耦来评估LLM智能体的泛化能力，发现任务成功不能有效反映环境理解水平。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在复杂决策和工具使用任务中表现出色，但其在不同环境中的泛化能力尚未得到充分研究。现有评估主要依赖基于轨迹的任务成功率指标，无法评估智能体是否真正掌握了可迁移的环境模型。

Method: 提出Task-to-Quiz (T2Q)评估范式，将任务执行与环境理解解耦，并构建T2QBench基准套件，包含30个环境和1,967个基于真实状态的问答对，涵盖多个难度级别。

Result: 实验表明任务成功率不能有效反映环境理解水平，当前记忆机制无法帮助智能体获得扎实的环境模型。主动探索和细粒度状态表示是主要瓶颈。

Conclusion: T2Q为评估LLM智能体环境理解能力提供了新范式，识别了泛化能力的关键瓶颈，为开发更具泛化能力的自主智能体奠定了基础。

Abstract: Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory machanism can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.

</details>


### [27] [Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning](https://arxiv.org/abs/2601.09536)
*Dongjie Cheng,Yongqi Li,Zhixin Ma,Hongru Cai,Yupeng Hu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.AI

TL;DR: Omni-R1提出统一的生成式多模态推理框架，通过生成中间图像统一多种多模态推理技能，无需特定任务模式即可处理多样化任务。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs要么只进行纯文本推理，要么采用单一任务特定的推理模式，限制了在各种多模态任务上的泛化能力。许多多模态任务需要多样化的推理技能（如放大特定区域、标记图像中的物体等），需要更统一的解决方案。

Method: 提出统一的生成式多模态推理范式，在推理过程中生成中间图像。具体实现为Omni-R1：两阶段SFT+RL框架，包含感知对齐损失和感知奖励，实现功能性图像生成。还提出Omni-R1-Zero，通过从纯文本推理数据中引导逐步可视化，无需多模态标注。

Result: Omni-R1在广泛的多模态任务上实现了统一的生成式推理。Omni-R1-Zero在平均性能上能够匹配甚至超越Omni-R1，显示了生成式多模态推理的潜力。

Conclusion: 统一的生成式多模态推理范式能够有效处理多样化的多模态任务，通过生成中间图像统一多种推理技能。Omni-R1-Zero的无监督方法展示了从纯文本数据引导多模态推理的可能性，为多模态推理提供了有前景的方向。

Abstract: Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.

</details>


### [28] [LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach](https://arxiv.org/abs/2601.09635)
*Kuo Liang,Yuhang Lu,Jianming Mao,Shuyi Sun,Chunwei Yang,Congcong Zeng,Xiao Jin,Hanzhang Qin,Ruihao Zhu,Chung-Piaw Teo*

Main category: cs.AI

TL;DR: LEAN-LLM-OPT：一个轻量级智能工作流框架，利用LLM代理自动构建大规模优化模型，通过分解建模任务和自动化数据处理，显著减少人工建模工作量。


<details>
  <summary>Details</summary>
Motivation: 大规模优化是现代商业决策的关键，但传统建模过程劳动密集且耗时。需要自动化方法来降低建模成本，提高效率。

Method: 提出LEAN-LLM-OPT框架，使用上游LLM代理动态构建工作流，下游LLM代理按工作流生成优化模型。将建模任务分解为结构化子任务，将机械数据处理卸载到辅助工具。

Result: 使用GPT-4.1和gpt-oss-20B的实验显示，在大规模优化建模任务上表现强劲，与最先进方法竞争。在新加坡航空收益管理案例中，在各种场景下都取得领先性能。

Conclusion: LEAN-LLM-OPT框架有效实现了大规模优化模型的自动构建，具有实际应用价值。同时贡献了首个大规模优化自动构建的基准数据集。

Abstract: Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.

</details>


### [29] [PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records](https://arxiv.org/abs/2601.09636)
*Yibo Lyu,Gongwei Chen,Rui Shao,Weili Guan,Liqiang Nie*

Main category: cs.AI

TL;DR: 本文提出了PersonalAlign任务，要求GUI代理利用长期用户记录解决模糊指令中的省略偏好，并根据用户状态预测潜在习惯提供主动协助。作者创建了AndroidIntent基准测试，并开发了HIM-Agent方法，在基准测试中显著提升了执行和主动性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在显式和完整指令下表现良好，但实际部署需要与用户更复杂的隐式意图对齐。用户通常给出模糊指令，省略了个人偏好，且需要代理能预测潜在习惯提供主动协助。

Method: 提出了Hierarchical Intent Memory Agent (HIM-Agent)，维护持续更新的个人记忆，分层组织用户偏好和习惯以实现个性化。同时创建了AndroidIntent基准测试，包含20k长期用户记录中的775个用户特定偏好和215个习惯。

Result: 在AndroidIntent基准测试中评估了多种GUI代理（包括GPT-5、Qwen3-VL、UI-TARS），HIM-Agent在执行性能和主动性能上分别显著提升了15.7%和7.3%。

Conclusion: PersonalAlign任务和HIM-Agent方法有效解决了GUI代理与用户隐式意图对齐的挑战，通过利用长期用户记录实现个性化服务，显著提升了代理在模糊指令解析和主动协助方面的能力。

Abstract: While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.

</details>


### [30] [Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning](https://arxiv.org/abs/2601.09667)
*Zhiyuan Hu,Yunhai Hu,Juncheng Liu,Shuyue Stella Li,Yucheng Wang,Zhen Xu,See-Kiong Ng,Anh Tuan Luu,Xinxing Xu,Bryan Hooi,Cynthia Breazeal,Hae Won Park*

Main category: cs.AI

TL;DR: 提出MATTRL框架，在推理时向多智能体决策注入结构化文本经验，通过多专家团队讨论、检索整合测试时经验并达成共识，无需调参即可实现分布偏移鲁棒的多智能体推理。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统虽然通过多样性和交叉验证获得鲁棒性，但多智能体强化学习训练资源密集且不稳定：队友协同适应导致非平稳性，奖励稀疏且方差高。

Method: MATTRL框架：1) 组建多专家团队进行多轮讨论；2) 检索并整合测试时经验；3) 达成共识进行最终决策。同时研究信用分配机制构建轮级经验池并重新注入对话。

Result: 在医学、数学和教育等挑战性基准测试中，MATTRL比多智能体基线平均准确率提高3.67%，比可比单智能体基线提高8.67%。消融研究分析了不同信用分配方案对训练结果的影响。

Conclusion: MATTRL提供了一条稳定、有效且高效的路径，无需调参即可实现分布偏移鲁棒的多智能体推理，解决了传统MARL训练的资源密集和不稳定问题。

Abstract: Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\% over a multi-agent baseline, and by 8.67\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.

</details>


### [31] [Automating Supply Chain Disruption Monitoring via an Agentic AI Approach](https://arxiv.org/abs/2601.09680)
*Sara AlMahri,Liming Xu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: 提出一个基于多智能体的AI框架，用于主动监控、分析和应对多层级供应链中的中断风险，相比传统人工评估将响应时间缩短了三个数量级。


<details>
  <summary>Details</summary>
Motivation: 现代供应链面临地缘政治事件、需求冲击、贸易限制和自然灾害等多种中断风险，但大多数公司缺乏对一级供应商之外的可见性，导致上游漏洞在影响下游时才能被发现，需要从被动恢复转向主动弹性。

Method: 引入一个最小监督的智能体AI框架，包含七个由大语言模型和确定性工具驱动的专门智能体，能够从非结构化新闻中检测中断信号，将其映射到多层供应商网络，基于网络结构评估暴露风险，并推荐缓解措施（如替代采购选项）。

Result: 在30个合成场景（涵盖三家汽车制造商和五类中断）中评估，系统在核心任务上达到高准确率（F1分数0.962-0.991），端到端分析平均耗时3.83分钟，每次中断成本0.0836美元。相比行业基准的多日人工评估，响应时间减少了三个数量级。2022年俄乌冲突的案例研究进一步验证了实际应用性。

Conclusion: 这项工作为构建能够管理深层网络中断的弹性、主动和自主供应链奠定了基础，实现了从被动恢复向主动弹性的转变。

Abstract: Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [32] [Two-dimensional Entanglement-assisted Quantum Quasi-cyclic Low-density Parity-check Codes](https://arxiv.org/abs/2601.08927)
*Pavan Kumar,Shayan Srinivasa Garani*

Main category: cs.IT

TL;DR: 该论文研究了二维经典QC-LDPC码的环结构条件，构建了多种girth大于4或6的码，并基于这些经典码构造了具有良好纠错能力的二维EA量子LDPC码。


<details>
  <summary>Details</summary>
Motivation: 研究二维经典QC-LDPC码的环结构条件，以构建具有较大围长(girth)的码，从而改善码的性能。进一步利用这些经典码构造具有良好纠错能力的量子LDPC码。

Method: 1. 推导二维经典QC-LDPC码Tanner图中2g-环存在的一般条件；2. 通过堆叠p×p×p张量构造girth大于4的码(p为奇素数)；3. 对于复合数p，提出两种通过类似张量堆叠构造的码族；4. 基于经典码构造两种二维EA量子LDPC码族。

Result: 1. 建立了二维经典QC-LDPC码环结构的理论条件；2. 构造了多个码族：奇素数p时girth>4的码，复合数p时girth>4和girth>6的码；3. 所有经典码具有至少p×p的纠错能力；4. 构造了两种EA量子LDPC码族，其中一种仅需1个ebit，且Tanner图无4-环。

Conclusion: 该论文系统研究了二维QC-LDPC码的环结构，构建了具有良好围长和纠错性能的经典码族，并成功将其扩展到量子领域，构造了具有相似纠错能力的EA量子LDPC码，为量子纠错码设计提供了新方法。

Abstract: For any positive integer $g \ge 2$, we derive general conditions for the existence of a $2g$-cycle in the Tanner graph of two-dimensional ($2$-D) classical quasi-cyclic (QC) low-density parity-check (LDPC) codes. Based on these conditions, we construct a family of $2$-D classical QC-LDPC codes with girth greater than $4$ by stacking $p \times p \times p$ tensors, where $p$ is an odd prime. Furthermore, for composite values of $p$, we propose two additional families of $2$-D classical LDPC codes obtained via similar tensor stacking. In this case, one family achieves girth greater than $4$, while the other attains girth greater than $6$. All the proposed $2$-D classical QC-LDPC codes exhibit an erasure correction capability of at least $p \times p$. Based on the constructed classical $2$-D QC-LDPC codes, we derive two families of $2$-D entanglement-assisted (EA) quantum low-density parity-check (QLDPC) codes. The first family of $2$-D EA-QLDPC codes is obtained from a pair of binary $2$-D classical LDPC codes and is designed such that the unassisted part of the Tanner graph of the resulting EA-QLDPC code is free of cycles of length four, while requiring only a single ebit to be shared across the quantum transceiver. The second family is constructed from a single $2$-D classical LDPC code whose Tanner graph is free from $4$-cycles. Moreover, the constructed EA-QLDPC codes inherit an erasure correction capability of $p \times p$, as the underlying classical codes possess the same erasure correction property.

</details>


### [33] [A Local Characterization of $f$-Divergences Yielding PSD Mutual-Information Matrices](https://arxiv.org/abs/2601.08929)
*Zachary Roberston*

Main category: cs.IT

TL;DR: 研究f-互信息矩阵在弱依赖条件下的正半定性，给出了局部特征：当且仅当f在1处解析且泰勒系数非负时，矩阵正半定。


<details>
  <summary>Details</summary>
Motivation: 研究变量索引的f-互信息矩阵何时是正半定的，这对于理解信息测度的几何性质和构建信息几何结构很重要。

Method: 使用复制嵌入技术将单项式项转化为Gram矩阵，结合复制强制约简为正定点积核，应用Schoenberg-Berg-Christensen-Ressel分类定理。

Result: 给出了局部特征：存在δ>0，使得对于任意n和有限字母表变量族，当两两联合-乘积比在(1-δ,1+δ)内时，M^(f)正半定当且仅当f在1处解析且泰勒系数a_m≥0。

Conclusion: f-互信息矩阵的正半定性要求f在1处解析且泰勒系数非负，这与分布间散度的希尔伯特/度量性质不同，为信息测度的几何结构提供了新见解。

Abstract: We study when the variable-indexed matrix of pairwise \(f\)-mutual informations \(M^{(f)}_{ij}=I_f(X_i;X_j)\) is positive semidefinite (PSD). Let \(f:(0,\infty)\to\mathbb{R}\) be convex with \(f(1)=0\), finite in a neighborhood of \(1\), and with \(f(0)<\infty\) so that diagonal terms are finite. We give a sharp \emph{local} characterization around independence: there exists \(δ=δ(f)>0\) such that for every \(n\) and every finite-alphabet family \((X_1,\ldots,X_n)\) whose pairwise joint-to-product ratios lie in \((1-δ,1+δ)\), the matrix \(M^{(f)}\) is PSD if and only if \(f\) is analytic at \(1\) with a convergent expansion \(f(t)=\sum_{m=2}^{\infty} a_m (t-1)^m\) and \(a_m\ge 0\) on a neighborhood of \(1\). Consequently, any negative Taylor coefficient yields an explicit finite-alphabet counterexample under arbitrarily weak dependence, and non-analytic convex divergences (e.g.\ total variation) are excluded. This PSD requirement is distinct from Hilbertian/metric properties of divergences between distributions (e.g.\ \(\sqrt{\mathrm{JS}}\)): we study PSD of the \emph{variable-indexed} mutual-information matrix. The proof combines a replica embedding that turns monomial terms into Gram matrices with a replica-forcing reduction to positive-definite dot-product kernels, enabling an application of the Schoenberg--Berg--Christensen--Ressel classification.

</details>


### [34] [On the Information Leakage Envelope of the Gaussian Mechanism](https://arxiv.org/abs/2601.08986)
*Sara Saeidian*

Main category: cs.IT

TL;DR: 本文研究了高斯机制的点态最大泄漏包络，推导了高斯秘密下的闭式解，并扩展到一般无界秘密，特别是强对数凹先验。


<details>
  <summary>Details</summary>
Motivation: 研究高斯机制的信息泄漏边界，特别是在任意后处理下以高概率成立的最小泄漏界限，这对于差分隐私和信息安全分析具有重要意义。

Method: 对于高斯秘密的高斯机制，推导了确定性PML包络的闭式表达式；对于一般无界秘密，通过Brascamp-Lieb不等式识别了使包络与高斯情况一致的充分条件，特别是强对数凹先验。

Result: 得到了高斯秘密下PML包络的闭式解；证明了强对数凹先验满足使包络与高斯情况一致的充分条件。

Conclusion: 高斯机制的PML包络在高斯秘密和强对数凹先验下具有可计算的闭式表达式，为信息泄漏分析提供了理论工具。

Abstract: We study the pointwise maximal leakage (PML) envelope of the Gaussian mechanism, which characterizes the smallest information leakage bound that holds with high probability under arbitrary post-processing. For the Gaussian mechanism with a Gaussian secret, we derive a closed-form expression for the deterministic PML envelope for sufficiently small failure probabilities. We then extend this result to general unbounded secrets by identifying a sufficient condition under which the envelope coincides with the Gaussian case. In particular, we show that strongly log-concave priors satisfy this condition via an application of the Brascamp-Lieb inequality.

</details>


### [35] [An Information-Theoretic Perspective on LLM Tokenizers](https://arxiv.org/abs/2601.09039)
*Mete Erdogan,Abhiram Gorle,Shubham Chandak,Mert Pilanci,Tsachy Weissman*

Main category: cs.IT

TL;DR: 论文研究LLM分词器作为结构化压缩器的作用，分析分词训练规模如何影响压缩效率和诱导的结构模式，并提出压缩感知的分词器设计方法。


<details>
  <summary>Details</summary>
Motivation: LLM分词器作为结构化压缩器，通过将文本映射到离散token序列，决定了token数量（计算和上下文使用）以及下游模型看到的统计结构。尽管分词器在LLM流程中处于核心地位，但分词、压缩效率和诱导结构之间的联系尚未得到充分理解。

Method: 1) 基准测试：评估GPT系列分词器作为黑盒压缩器在不同领域的表现；2) 分析学习分词器在不同配置下的行为（词汇量、训练规模、领域）；3) 将分词视为通用压缩变换，引入压缩感知的BPE变体；4) 采用信道视角，引入容量利用率指标分析分词器行为。

Result: 分词器训练规模重新分配熵：随着训练数据增加，token流在总体上变得更加多样化（更高的一元熵），但在上下文中明显更可预测（更低的高阶条件熵），表明分词吸收了大量的短程规律性，但这些增益在训练-测试领域不匹配时会下降。

Conclusion: 研究结果揭示了压缩、诱导结构和领域偏移鲁棒性之间的各种权衡，并激励了基于原则的、压缩感知的分词器设计。

Abstract: Large language model (LLM) tokenizers act as structured compressors: by mapping text to discrete token sequences, they determine token count (and thus compute and context usage) and the statistical structure seen by downstream models. Despite their central role in LLM pipelines, the link between tokenization, compression efficiency and induced structure is not well understood. We empirically demonstrate that tokenizer training scale redistributes entropy: as training data grows, the token stream becomes more diverse in aggregate (higher unigram entropy) yet markedly more predictable in-context (lower higher-order conditional entropies), indicating that tokenization absorbs substantial short-range regularity although these gains degrade under train-test domain mismatch. To ground these observations, we first benchmark i) pretrained GPT-family tokenizers as black-box compressors across various domains, and ii) learned tokenizers across configurations spanning vocabulary size, training scale, and domain. Next, we study tokenization as a transform for universal compression and introduce a compression-aware BPE variant. Finally, we adopt a channel lens and introduce capacity-utilization metrics to analyze tokenizer behaviour and outline implications for downstream modeling. Put together, our results expose various trade-offs between compression, induced structure, and robustness under domain shift, and motivate principled, compression-aware tokenizer design.

</details>


### [36] [Hybrid Mono- and Bi-static OFDM-ISAC via BS-UE Cooperation: Closed-Form CRLB and Coverage Analysis](https://arxiv.org/abs/2601.09057)
*Xiaoli Xu,Yong Zeng*

Main category: cs.IT

TL;DR: 提出了一种混合单/双基地感知框架，利用ISAC系统中基站和用户设备的协作，无需额外频谱或小区间协调，显著提升感知性能。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中，传统单基地或双基地感知模式各有局限。需要一种无需额外频谱成本或小区间协调的混合感知方案，以充分利用基站和用户设备协作来提升感知性能。

Method: 基于3GPP支持的感知模式，提出混合单/双基地感知框架。推导了目标定位和速度估计的闭式克拉美-罗下界，分析了目标与用户设备位置对性能的影响。采用有效参数估计算法和加权均方误差融合方法进行验证。

Result: 当基站-目标-用户设备形成接近直角三角形的有利几何构型时，混合感知相比纯单/双基地感知可获得显著性能增益。感知覆盖范围随基站-用户设备距离先增后减，感知精度随用户设备密度增加而提升。

Conclusion: 混合单/双基地感知框架在无需额外频谱或协调的情况下，通过基站和用户设备协作显著提升感知性能。几何构型对性能影响显著，用户设备密度增加可改善感知精度。

Abstract: This paper proposes a hybrid mono- and bi-static sensing framework, by leveraging the base station (BS) and user equipment (UE) cooperation in integrated sensing and communication (ISAC) systems. This scheme is built on 3GPP-supported sensing modes, and it does not incur any extra spectrum cost or inter-cell coordination. To reveal the fundamental performance limit of the proposed hybrid sensing mode, we derive closed-form Cramér-Rao lower bound (CRLB) for sensing target localization and velocity estimation, as functions of target and UE positions. The results reveal that significant performance gains can be achieved over the purely mono- or bi-static sensing, especially when the BS-target-UE form a favorable geometry, which is close to a right triangle. The analytical results are validated by simulations using effective parameter estimation algorithm and weighted mean square error (MSE) fusion method. Based on the derived sensing bound, we further analyze the sensing coverage by varying the UE positions, which shows that sensing coverage first improves then degrades as the BS-UE separation increases. Furthermore, the sensing accuracy for a potential target with best UE selection is derived as a function of the UE density in the network.

</details>


### [37] [Overcoming the Shadow: Bending Airy Beams for Radiative Near-Field Multi-User Access in Half-Space Blockage Scenarios](https://arxiv.org/abs/2601.09098)
*Yifeng Qin,Jing Chen,Zhi Hao Jiang,Zhi Ning Chen,Yongming Huang*

Main category: cs.IT

TL;DR: 提出利用艾里光束的自弯曲特性来缓解下一代无线通信中极大规模天线阵列面临的半空间遮挡问题，无需额外硬件即可恢复阴影区域的连接性。


<details>
  <summary>Details</summary>
Motivation: 下一代无线通信采用极大规模天线阵列，将通信带入辐射近场区域，但高频近场链路在室内环境中极易受到墙壁、角落等半空间障碍物的遮挡。传统的近场聚焦波束在视距场景中提供高增益，但在阴影区域会遭受严重的能量截断和有效秩崩溃，使得可重构智能表面等硬件解决方案不切实际。

Method: 提出一种利用艾里光束自弯曲特性的波束成形策略：1) 基于格林函数的辐射近场多用户信道模型，解析揭示刀锋障碍物后的奇异值崩溃；2) 艾里模拟波束成形方案，优化弯曲轨迹以恢复有效信道秩；3) 艾里零陷导向方法，将振荡零陷与明亮区域用户对齐以抑制混合阴影/明亮场景中的干扰。

Result: 仿真显示，与传统的辐射近场聚焦相比，提出的边缘"骑行"艾里策略在阴影链路中实现了超过20dB的信噪比改进，并恢复了全秩连接性，几乎消除了几何阴影中的中断，在典型室内极大规模天线阵列配置下将多用户频谱效率提高了约35%。

Conclusion: 该研究证明了在不依赖可重构智能表面的情况下，在半空间遮挡场景中实现稳健的辐射近场多用户接入的可行性，为下一代无线通信中的遮挡问题提供了创新的软件解决方案。

Abstract: The move to next-generation wireless communications with extremely large-scale antenna arrays (ELAAs) brings the communications into the radiative near-field (RNF) region, where distance-aware focusing is feasible. However, high-frequency RNF links are highly vulnerable to blockage in indoor environments dominated by half-space obstacles (walls, corners) that create knife-edge shadows. Conventional near-field focused beams offer high gain in line-of-sight (LoS) scenarios but suffer from severe energy truncation and effective-rank collapse in shadowed regions, making hardware remedies such as reconfigurable intelligent surfaces (RIS) impractical. We propose a beamforming strategy that exploits the auto-bending property of Airy beams to mitigate half-space blockage without additional hardware. The Airy beam is designed to ``ride'' the diffraction edge, accelerating its main lobe into the shadow to restore connectivity. Our contributions are threefold: (i) a Green's function-based RNF multi-user channel model that analytically reveals singular-value collapse behind knife-edge obstacles; (ii) an Airy analog beamforming scheme that optimizes the bending trajectory to recover the effective channel rank; and (iii) an Airy null-steering method that aligns oscillatory nulls with bright-region users to suppress interference in mixed shadow/bright scenarios. Simulations show that the proposed edge-riding Airy strategy achieves an SNR improvement of over 20 dB and restores full-rank connectivity in shadowed links compared to conventional RNF focusing, virtually eliminating outage in geometric shadows and increasing multi-user spectral efficiency by approximately 35\% under typical indoor ELAA configurations. These results demonstrate robust RNF multi-user access in half-space blockage scenarios without relying on RIS.

</details>


### [38] [The .serva Standard: One Primitive for All AI Cost Reduced, Barriers Removed](https://arxiv.org/abs/2601.09124)
*Rachel St. Clair,John Austin Cook,Peter Sutor,Victor Cavero,Garrett Mindt*

Main category: cs.IT

TL;DR: ServaStack提出通用数据格式.serva和AI计算引擎Chimera，通过全息编码实现无损压缩，直接在压缩数据上计算，显著提升AI基础设施能效和存储效率。


<details>
  <summary>Details</summary>
Motivation: AI基础设施面临两大危机：计算负载（训练和推理的能源与资本成本不可持续）和数据混乱（80%项目时间用于数据准备），现有方法将这些问题分开处理，导致生态系统复杂化。

Method: 提出ServaStack解决方案：1) 通用数据格式.serva，基于激光全息原理实现无损压缩；2) 通用AI计算引擎Chimera，将计算操作转换为表示空间，直接在.serva文件上计算而无需解压缩。

Result: 内部基准测试显示：能效提升30-374倍（减少96-99%），无损存储压缩4-34倍，计算负载减少68倍且无精度损失（在FashionMNIST和MNIST数据集上对比RNN、CNN、MLP模型）。超大规模下每PB每个训练周期可节省485万美元。

Conclusion: ServaStack通过统一数据格式和计算引擎，使任何数据能在任何模型和硬件上运行，将AI开发瓶颈从基础设施转移到想象力，实现范式转变。

Abstract: Artificial Intelligence (AI) infrastructure faces two compounding crises. Compute payload - the unsustainable energy and capital costs of training and inference - threatens to outpace grid capacity and concentrate capability among a handful of organizations. Data chaos - the 80% of project effort consumed by preparation, conversion, and preprocessing - strangles development velocity and locks datasets to single model architectures. Current approaches treat these as separate problems, managing each with incremental optimization while increasing ecosystem complexity. This paper presents ServaStack: a universal data format (.serva) paired with a universal AI compute engine (Chimera). The .serva format achieves lossless compression by encoding information using laser holography principles, while Chimera converts compute operations into a representational space where computation occurs directly on .serva files without decompression. The result is automatic data preprocessing. The Chimera engine enables any existing model to operate on .serva data without retraining, preserving infrastructure investments while revamping efficiency. Internal benchmarks demonstrate 30-374x energy efficiency improvements (96-99% reduction), 4x-34x lossless storage compression, and 68x compute payload reduction without accuracy loss when compared to RNN, CNN, and MLP models on FashionMNIST and MNIST datasets. At hyperscale with one billion daily iterations, these gains translate to $4.85M savings per petabyte per training cycle. When any data flows to any model on any hardware, the AI development paradigm shifts. The bottleneck moves from infrastructure to imagination.

</details>


### [39] [Movable Antenna Assisted Dual-Polarized Multi-Cell Cooperative AirComp: An Alternating Optimization Approach](https://arxiv.org/abs/2601.09137)
*Mingyu Hu,Nan Liu,Wei Kang*

Main category: cs.IT

TL;DR: 提出基于双极化可移动天线的多小区协作空中计算框架，通过联合优化组合矩阵、极化向量、天线位置和用户发射系数来最小化均方误差，显著提升分布式优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统空中计算系统使用固定单极化基站阵列，无法充分利用空间自由度且存在极化失配问题，限制了分布式优化的性能。无线环境敏感性也影响了空中计算的可靠性。

Method: 提出双极化可移动天线辅助的多小区协作空中计算框架，将MSE最小化问题分解为交替优化：组合矩阵和发射系数采用闭式更新，极化向量使用SCA和SDR方法优化，天线位置采用梯度法更新，并开发了基于统计信道的天线位置优化方案。

Result: 数值结果表明，所提出的可移动双极化方案在瞬时信道和统计信道下均优于可移动单极化和固定天线基线方案，性能提升显著。

Conclusion: 双极化可移动天线系统通过联合优化天线位置、极化向量和传输参数，有效克服了传统空中计算的局限性，为分布式优化提供了更可靠的通信支持。

Abstract: Over-the-air computation (AirComp) is a key enabler for distributed optimization, since it leverages analog waveform superposition to perform aggregation and thereby mitigates the communication bottleneck caused by iterative information exchange. However, AirComp is sensitive to wireless environment and conventional systems with fixed single-polarized base-station arrays cannot fully exploit spatial degrees of freedom while also suffering from polarization mismatch. To overcome these limitations, this paper proposes a multi-cell cooperative air-computation framework assisted by dual-polarized movable antennas (D-PMA), and formulates a mean squared error (MSE) minimization problem by jointly optimizing the combining matrix, polarization vectors, antenna positions, and user transmit coefficients. The resulting problem is highly nonconvex, so an alternating algorithm is developed in which closed-form updates are obtained for the combining matrix and transmit coefficients. Then a method based on successive convex approximation (SCA) and semidefinite relaxation (SDR) is proposed to refine polarization vectors, and the antenna positions are updated using a gradient-based method. In addition, we develop a statistical-channel-based scheme for optimizing the antenna locations, and we further present the corresponding algorithm to efficiently obtain the solution. Numerical results show that the proposed movable dual-polarized scheme consistently outperforms movable single-polarized and fixed-antenna baselines under both instantaneous and statistical channels.

</details>


### [40] [Reducing The Sub-packetization Level of Optimal-Access Cooperative MSR Codes](https://arxiv.org/abs/2601.09188)
*Yaqian Zhang,Jingke Xu*

Main category: cs.IT

TL;DR: 本文提出了一种降低最优访问合作MSR码子分组化的新方法，针对两个节点擦除情况，通过设计两种关键MDS阵列码作为构建模块，显著降低了子分组化大小。


<details>
  <summary>Details</summary>
Motivation: 合作MSR码能够以最优带宽修复多个节点擦除，但现有最优访问合作MSR码的子分组化较大（ℓ=r^{C(n,2)}），导致高复杂度和大量磁盘IO操作。需要降低子分组化以提高实际应用性能。

Method: 首先设计两种修复特定双擦除模式的最优访问MDS阵列码，然后将这两种码作为构建模块进行多次堆叠，构造出最优访问合作MSR码。新方法的子分组化ℓ=r^{C(n,2)-⌊n/r⌋(C(r,2)-1)}。

Result: 提出的最优访问合作MSR码将子分组化从现有最优的ℓ=r^{C(n,2)}降低到ℓ=r^{C(n,2)-⌊n/r⌋(C(r,2)-1)}，减少了1/r^{⌊n/r⌋(C(r,2)-1)}的比例，显著降低了存储复杂度。

Conclusion: 通过设计特定MDS阵列码作为构建模块并采用堆叠技术，成功降低了最优访问合作MSR码的子分组化，为实际存储系统提供了更高效的纠删码方案。

Abstract: Cooperative MSR codes are a kind of storage codes which enable optimal-bandwidth repair of any $h\geq2$ node erasures in a cooperative way, while retaining the minimum storage as an $[n,k]$ MDS code. Each code coordinate (node) is assumed to store an array of $\ell$ symbols, where $\ell$ is termed as sub-packetization. Large sub-packetization tends to induce high complexity, large input/output in practice. To address the disk IO capability, a cooperative MSR code is said to have optimal-access property, if during node repair, the amount of data accessed at each helper node meets a theoretical lower bound.
  In this paper, we focus on reducing the sub-packetization of optimal-access cooperative MSR codes with two erasures. At first, we design two crucial MDS array codes for repairing a specific repair pattern of two erasures with optimal access. Then, using the two codes as building blocks and by stacking up of the two codes for several times, we obtain an optimal-access cooperative MSR code with two erasures. The derived code has sub-packetization $\ell=r^{\binom{n}{2}-\lfloor\frac{n}{r}\rfloor(\binom{r}{2}-1)}$ where $r=n-k$, and it reduces $\ell$ by a fraction of $1/r^{\lfloor\frac{n}{r}\rfloor(\binom{r}{2}-1)}$ compared with the state of the art ($\ell=r^{\binom{n}{2}}$).

</details>


### [41] [Second-Order Asymptotics of Two-Sample Tests](https://arxiv.org/abs/2601.09196)
*K V Harsha,Jithin Ravi,Tobias Koch*

Main category: cs.IT

TL;DR: 本文提出了一种基于任意散度的两样本检验推广方法（散度检验），证明了其具有最优的一阶指数衰减率，且当使用不变散度时能达到与Gutman检验相同的二阶渐近性能。


<details>
  <summary>Details</summary>
Motivation: 两样本检验是统计学中的基本问题，需要判断两个独立样本是否来自同一分布。Gutman检验使用Jensen-Shannon散度，但研究者希望探索使用其他散度是否也能获得良好的统计性能，并建立更一般的理论框架。

Method: 提出散度检验方法，用任意散度替代JS散度来比较两个样本的经验分布。当散度值低于阈值时接受原假设（分布相同）。理论分析包括：1）证明散度检验达到最优的一阶指数衰减率；2）展示使用不变散度的散度检验与Gutman检验具有相同的二阶渐近性能；3）证明Gutman检验是两样本检验问题的广义似然比检验。

Result: 1）所有散度检验都能达到最优的一阶错误概率指数衰减率；2）使用不变散度的散度检验能达到与Gutman检验相同的二阶渐近性能；3）建立了Gutman检验与广义似然比检验的等价关系；4）建立了两样本检验与鲁棒拟合优度检验之间的联系。

Conclusion: 散度检验为两样本检验提供了一个灵活且理论保证的框架，不仅推广了Gutman检验，还建立了与经典统计检验的深刻联系。该研究为选择不同散度进行假设检验提供了理论依据。

Abstract: In two-sampling testing, one observes two independent sequences of independent and identically distributed random variables distributed according to the distributions $P_1$ and $P_2$ and wishes to decide whether $P_1=P_2$ (null hypothesis) or $P_1\neq P_2$ (alternative hypothesis). The Gutman test for this problem compares the empirical distributions of the observed sequences and decides on the null hypothesis if the Jensen-Shannon (JS) divergence between these empirical distributions is below a given threshold. This paper proposes a generalization of the Gutman test, termed \emph{divergence test}, which replaces the JS divergence by an arbitrary divergence. For this test, the exponential decay of the type-II error probability for a fixed type-I error probability is studied. First, it is shown that the divergence test achieves the optimal first-order exponent, irrespective of the choice of divergence. Second, it is demonstrated that the divergence test with an invariant divergence achieves the same second-order asymptotics as the Gutman test. In addition, it is shown that the Gutman test is the GLRT for the two-sample testing problem, and a connection between two-sample testing and robust goodness-of-fit testing is established.

</details>


### [42] [On Polar Coding with Feedback](https://arxiv.org/abs/2601.09222)
*Ling Liu,Qi Cao,Liping Li,Baoming Bai*

Main category: cs.IT

TL;DR: 研究反馈辅助下极化码的性能，反馈虽不提升信道容量，但能显著改善有限长度性能，通过genie辅助解码和更灵活的构造阈值实现。


<details>
  <summary>Details</summary>
Motivation: 虽然反馈不改善无记忆信道的容量，但研究反馈如何提升极化码的有限长度性能，通过反馈实现genie辅助解码和更灵活的极化码构造阈值。

Method: 提出反馈辅助的极化码构造方法，利用反馈实现genie辅助的连续消除(SC)解码，并分析新构造下的性能，提出准确描述genie辅助SC解码下错误事件分布的特征方法。

Result: 反馈能显著提升极化码的有限长度性能，提出的错误事件分布特征方法能准确预测genie辅助SC解码性能，也可用于预测接近容量时标准SC解码的性能。

Conclusion: 反馈虽不改变信道容量，但通过genie辅助解码和灵活构造阈值能有效提升极化码的有限长度性能，提出的错误事件分布特征为性能分析提供了准确工具。

Abstract: In this work, we investigate the performance of polar codes with the assistance of feedback in communication systems. Although it is well known that feedback does not improve the capacity of memoryless channels, we show that the finite length performance of polar codes can be significantly improved as feedback enables genie-aided decoding and allows more flexible thresholds for the polar coding construction. To analyze the performance under the new construction, we then propose an accurate characterization of the distribution of the error event under the genie-aided successive cancellation (SC) decoding. This characterization can be also used to predict the performance of the standard SC decoding of polar codes with rates close to capacity.

</details>


### [43] [A Theoretical Framework for Rate-Distortion Limits in Learned Image Compression](https://arxiv.org/abs/2601.09254)
*Changshuo Wang,Zijian Liang,Kai Niu,Ping Zhang*

Main category: cs.IT

TL;DR: 提出一个理论框架分析学习型图像压缩的率失真极限，将性能损失分解为方差估计、量化策略和上下文建模三个关键组件，提供可解释的R-D极限近似。


<details>
  <summary>Details</summary>
Motivation: 尽管神经编解码器取得了显著经验成果，但其与信息论极限的距离仍不明确。现有R-D估计器缺乏结构可解释性，无法与真实压缩模块对齐。

Method: 1) 推导高斯假设下的最优潜在方差作为二阶矩；2) 量化均匀量化与高斯测试信道之间的差距；3) 扩展框架包含上下文建模，证明准确均值预测能显著降低熵。通过联合仿真和端到端训练获得理论R-D极限的紧致近似。

Result: 提出了一个结构可解释的框架，能够精细分析学习型压缩系统的R-D性能损失，为设计更高效的压缩系统提供新见解。

Conclusion: 该框架填补了学习型图像压缩理论与实际性能之间的差距，提供了可操作的R-D极限近似，有助于指导未来压缩系统的设计优化。

Abstract: We present a novel systematic theoretical framework to analyze the rate-distortion (R-D) limits of learned image compression. While recent neural codecs have achieved remarkable empirical results, their distance from the information-theoretic limit remains unclear. Our work addresses this gap by decomposing the R-D performance loss into three key components: variance estimation, quantization strategy, and context modeling. First, we derive the optimal latent variance as the second moment under a Gaussian assumption, providing a principled alternative to hyperprior-based estimation. Second, we quantify the gap between uniform quantization and the Gaussian test channel derived from the reverse water-filling theorem. Third, we extend our framework to include context modeling, and demonstrate that accurate mean prediction yields substantial entropy reduction. Unlike prior R-D estimators, our method provides a structurally interpretable perspective that aligns with real compression modules and enables fine-grained analysis. Through joint simulation and end-to-end training, we derive a tight and actionable approximation of the theoretical R-D limits, offering new insights into the design of more efficient learned compression systems.

</details>


### [44] [Regenerating codes with minimal disk I/O cost achieving optimal tradeoff between storage and repair bandwidth](https://arxiv.org/abs/2601.09300)
*Minhan Gao,Kenneth Shum*

Main category: cs.IT

TL;DR: 本文提出了一种基于gammoids理论的分布式存储编码方案，能在单节点故障时实现存储与修复带宽之间的最优权衡，同时支持无限次节点修复迭代。


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统设计需要考虑多个性能指标：修复带宽（网络资源）和磁盘I/O成本（从辅助节点读取的数据量）。最优I/O成本方案要求发送到新节点的数据包数量等于从内存读取的数量，这种无编码修复模式计算开销最小。本文旨在设计一种既能实现存储与修复带宽最优权衡，又能支持无限次修复迭代的方案。

Method: 基于gammoids理论（一类特殊的基于图的拟阵）设计编码方案。该方案针对单节点故障情况，要求所有存活节点参与修复过程，实现了无编码修复机制。

Result: 证明了该方案能够实现存储与修复带宽之间的所有基本权衡点，并且在固定大小的域上能够容忍无限次的节点修复迭代。

Conclusion: 基于gammoids理论的编码方案为分布式存储系统提供了一种高效解决方案，既能优化存储与修复带宽的权衡，又能通过无编码修复机制最小化计算开销，同时支持长期稳定的系统运行。

Abstract: There are multiple performance metrics in the design of coding schemes for distributed storage systems. The first metric is called repair bandwidth, which measures the network resources required during the repair process. Another critical metric for repair efficiency is disk I/O cost, defined as the amount of data packets accessed at helper nodes to repair the failed node. In an encoding scheme with optimal I/O cost, the number of packets sent to the newcomer is exactly the same as the number of packets read from memory. This mode of repair is referred to as uncoded repair, as no coding operations are performed at the helper node. In addition to minimizing disk I/O cost, an uncoded repair mechanism has the advantage of incurring minimal computational overhead at the helper node. In this paper, we demonstrate that for single node failures, if all surviving nodes participate in the repair of the failed node, we can achieve all points on the fundamental tradeoff curve between storage and repair bandwidth. The design of the proposed encoding scheme is based on the theory of gammoids, a specialized class of graph-based matroids. We prove that this scheme can tolerate an unlimited number of node repair iterations over a field of fixed size.

</details>


### [45] [An Information Theoretic Proof of the Radon-Nikodym Theorem](https://arxiv.org/abs/2601.09308)
*Peter Harremoës*

Main category: cs.IT

TL;DR: 论文探讨了Radon-Nikodym定理在信息论中的基础作用，指出该定理的证明在概率论和信息论教材中常被省略。


<details>
  <summary>Details</summary>
Motivation: Radon-Nikodym定理是信息论中香农熵、f-散度等基本概念定义的核心，但在概率论和信息论教材中，该定理的存在性证明常被省略，因为被认为过于困难。

Method: 论文可能通过分析Radon-Nikodym定理在信息论中的具体应用，探讨该定理证明的重要性，并提出简化或更易理解的证明方法。

Result: 未提供具体结果，但暗示需要更易理解的Radon-Nikodym定理证明方法，以便在信息论教学中更好地涵盖这一基础理论。

Conclusion: Radon-Nikodym定理在信息论中至关重要，但其复杂证明导致教学中常被省略，需要开发更易理解的教学方法。

Abstract: The Radon-Nikodym theorem plays a significant role in the definition of Shannon entropy, f-divergences, and other basic quantities in information theory. The existence of Radon Nikodym derivates appear in many text books in measure theory but in text books on probability or information theory it is often omitted because the proof is often considered to be too difficult.

</details>


### [46] [Contraction of Rényi Divergences for Discrete Channels: Properties and Applications](https://arxiv.org/abs/2601.09328)
*Adrien Vandenbroucque,Amedeo Roberto Esposito,Michael Gastpar*

Main category: cs.IT

TL;DR: 该论文研究了Rényi散度的强数据处理常数性质，探讨了其与φ-散度的异同，特别展示了当α>1时收缩性质的显著差异，并将结果应用于马尔可夫链收敛速度分析。


<details>
  <summary>Details</summary>
Motivation: 研究Rényi散度的强数据处理常数性质，探索其与已有φ-散度理论的联系与差异，为马尔可夫链收敛分析提供新视角。

Method: 通过理论分析Rényi散度的收缩性质，比较不同阶数α下的行为差异，特别关注α>1和无穷阶情况，并与ε-本地差分隐私建立联系。

Result: 发现Rényi散度的阶数α决定其收缩性质是否与φ-散度相似，当α>1时收缩性质显著不同；揭示了无穷阶Rényi散度的特殊收缩特性及其与差分隐私的关联。

Conclusion: Rényi散度的收缩性质提供了分析马尔可夫链收敛速度的新框架，补充了传统L^α-范数收缩方法，为信息论和隐私保护应用提供了理论基础。

Abstract: This work explores properties of Strong Data-Processing constants for Rényi Divergences. Parallels are made with the well-studied $\varphi$-Divergences, and it is shown that the order $α$ of Rényi Divergences dictates whether certain properties of the contraction of $\varphi$-Divergences are mirrored or not. In particular, we demonstrate that when $α>1$, the contraction properties can deviate quite strikingly from those of $\varphi$-Divergences. We also uncover specific characteristics of contraction for the $\infty$-Rényi Divergence and relate it to $\varepsilon$-Local Differential Privacy. The results are then applied to bound the speed of convergence of Markov chains, where we argue that the contraction of Rényi Divergences offers a new perspective on the contraction of $L^α$-norms commonly studied in the literature.

</details>


### [47] [Generalized Schalkwijk-Kailath Coding for Autoregressive Gaussian Channels](https://arxiv.org/abs/2601.09329)
*Jun Su,Guangyue Han,Shlomo Shamai*

Main category: cs.IT

TL;DR: 提出了一种用于AR(p)高斯信道的SK(2)编码方案，扩展了经典的Schalkwijk-Kailath方案，并证明了SK方案并非普遍最优


<details>
  <summary>Details</summary>
Motivation: 扩展经典的Schalkwijk-Kailath编码方案到AR(p)高斯信道，检验其普遍最优性

Method: 提出了SK(2)编码方案，这是一种高斯随机编码方案，能够获得闭式可达速率表达式

Result: 证明了经典SK编码方案并非普遍最优，从而推翻了Butman在1976年提出的猜想

Conclusion: SK(2)编码方案为AR(p)高斯信道提供了新的编码方法，并解决了关于SK方案普遍最优性的长期猜想

Abstract: We propose a Gaussian random coding scheme for AR($p$) Gaussian channels that generalizes the celebrated Schalkwijk-Kailath (SK) coding scheme. This constructive coding scheme, termed the SK(2) coding scheme, yields a closed-form characterization for the corresponding achievable rate. Among many others, this result shows that the celebrated SK coding scheme is not universally optimal, and therefore, disprove the conjecture proposed by Butman in \cite{butman1976linear}.

</details>


### [48] [A Constructive Method to Minimize the Index of Coincidence under Marginal Constraints](https://arxiv.org/abs/2601.09347)
*Pierre Jean-Claude Robert Bertrand*

Main category: cs.IT

TL;DR: 提出了一种最小化联合分布重合指数的完整构造性解法，解决了边际约束下的一般情况


<details>
  <summary>Details</summary>
Motivation: 重合指数在信息论中自然出现，现有闭式解需要强可行性条件，但该条件在实践中很少满足

Method: 首先证明强可行性条件的适用性随维度增长而消失，然后分析最优耦合的单调阶梯零值结构，提出显式迭代构造方法

Result: 证明了迭代构造在有限步内收敛到最小化解，获得了重合指数最小化的完整构造性解决方案

Conclusion: 解决了边际约束下重合指数最小化的一般问题，提供了实用的构造性算法

Abstract: We consider the problem of minimizing the index of coincidence of a joint distribution under fixed marginal constraints. This objective is motivated by several applications in information theory, where the index of coincidence naturally arises. A closed-form solution is known when the marginals satisfy a strong feasibility condition, but this condition is rarely met in practice. We first show that the measure of the set of marginals for which condition applies vanishes as the dimension grows. We then characterize the structure of the optimal coupling in the general case, proving that it exhibits a monotone staircase of zero entries. Based on this structure, we propose an explicit iterative construction and prove that it converges in finitely many steps to a minimizer. Main result of the paper is a complete constructive solution of index-of-coincidence minimization.

</details>


### [49] [Asymptotic Rate Bounds and Constructions for the Inclusive Variant of Disjunct Matrices](https://arxiv.org/abs/2601.09362)
*Yuto Mizunuma,Yuichiro Fujiwara*

Main category: cs.IT

TL;DR: 本文首次建立了包容性分离矩阵的渐近正速率下界，匹配了已知上界（相差对数因子），为抑制剂复杂模型下的可扩展群体检测提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 包容性分离矩阵在抑制剂复杂模型下的群体检测中具有重要应用价值，但其渐近行为一直未被充分研究，特别是能否达到渐近正速率这一可扩展设计的关键问题。

Method: 采用概率方法构建随机化构造，然后通过去随机化技术获得确定性多项式时间构造。

Result: 首次建立了包容性分离矩阵的最大可达速率的非平凡渐近下界，该下界与已知最强上界仅相差对数因子。

Conclusion: 这些结果阐明了在一般抑制剂复杂模型下鲁棒且可扩展群体检测的渐近潜力，为实际应用提供了理论基础。

Abstract: Disjunct matrices, also known as cover-free families and superimposed codes, are combinatorial arrays widely used in group testing. Among their variants, those that satisfy an additional combinatorial property called inclusiveness form a special class suitable for computationally efficient and highly error-tolerant group testing under the general inhibitor complex model, a broad framework that subsumes practical settings such as DNA screening. Despite this relevance, the asymptotic behavior of the inclusive variant of disjunct matrices has remained largely unexplored. In particular, it was not previously known whether this variant can achieve an asymptotically positive rate, a requirement for scalable group testing designs. In this work, we establish the first nontrivial asymptotic lower bound on the maximum achievable rate of the inclusive variant, which matches the strongest known upper bound up to a logarithmic factor. Our proof is based on the probabilistic method and yields a simple and efficient randomized construction. Furthermore, we derandomize this construction to obtain a deterministic polynomial-time construction. These results clarify the asymptotic potential of robust and scalable group testing under the general inhibitor complex model.

</details>


### [50] [On Decoding First- and Second-Order BiD Codes](https://arxiv.org/abs/2601.09390)
*Devansh Jain,Lakshmi Prasad Natarajan*

Main category: cs.IT

TL;DR: 本文针对BiD码提出高效解码器：一阶码的快速ML和max-log-MAP解码器，二阶码的BP解码器性能接近ML解码器


<details>
  <summary>Details</summary>
Motivation: BiD码在擦除信道下具有优于RM码的性能，但需要高效解码算法来实现其理论优势

Method: 1. 为一阶BiD码设计快速最大似然和max-log-MAP解码器；2. 识别二阶码的最小权重奇偶校验；3. 确定RM文献中的"投影"特性；4. 基于这些结果设计置信传播解码器

Result: 1. 一阶码实现快速ML解码；2. 二阶码的BP解码器在块长度81和243时性能在ML解码器的1dB范围内

Conclusion: 提出的解码算法使BiD码在实际通信系统中具有应用可行性，为高阶BiD码的解码器设计奠定了基础

Abstract: BiD codes, which are a new family of algebraic codes of length $3^m$, achieve the erasure channel capacity under bit-MAP decoding and offer asymptotically larger minimum distance than Reed-Muller (RM) codes. In this paper we propose fast maximum-likelihood (ML) and max-log-MAP decoders for first-order BiD codes. For second-order codes, we identify their minimum-weight parity checks and ascertain a code property known as 'projection' in the RM coding literature. We use these results to design a belief propagation decoder that performs within 1 dB of ML decoder for block lengths 81 and 243.

</details>


### [51] [A Generalized Leakage Interpretation of Alpha-Mutual Information](https://arxiv.org/abs/2601.09406)
*Akira Kamatsuka,Takahiro Yoshida*

Main category: cs.IT

TL;DR: 该论文提出了α-互信息在广义g-泄露框架下的统一解释，将α参数解释为对手的风险厌恶度量


<details>
  <summary>Details</summary>
Motivation: 为α-互信息提供一个统一的解释框架，将其与定量信息流分析中的广义泄露概念联系起来，特别是在对抗性决策问题背景下

Method: 使用扩展的定量信息流框架，基于对抗性广义决策问题，采用Kolmogorov-Nagumo均值和q-对数来表征对抗性收益

Result: 证明了α-互信息可以在该框架下得到统一解释，并且参数α可以解释为对手风险厌恶程度的度量

Conclusion: 该研究为α-互信息提供了新的理论解释，建立了信息论与对抗性决策理论之间的联系，深化了对定量信息流分析的理解

Abstract: This paper presents a unified interpretation of $α$-mutual information ($α$-MI) in terms of generalized $g$-leakage. Specifically, we present a novel interpretation of $α$-MI within an extended framework for quantitative information flow based on adversarial generalized decision problems. This framework employs the Kolmogorov-Nagumo mean and the $q$-logarithm to characterize adversarial gain. Furthermore, we demonstrate that, within this framework, the parameter $α$ can be interpreted as a measure of the adversary's risk aversion.

</details>


### [52] [Dobrushin Coefficients of Private Mechanisms Beyond Local Differential Privacy](https://arxiv.org/abs/2601.09498)
*Leonhard Grosse,Sara Saeidian,Tobias J. Oechtering,Mikael Skoglund*

Main category: cs.IT

TL;DR: 研究具有有界逐点最大泄漏(PML)的离散马尔可夫核的Dobrushin系数，该定义在c→0时恢复局部差分隐私(LDP)，推导收缩界限并提供实现机制，将结果扩展到一般f-散度。


<details>
  <summary>Details</summary>
Motivation: 研究具有有界逐点最大泄漏(PML)的离散马尔可夫核的收缩性质，该定义推广了局部差分隐私(LDP)概念，允许分析更广泛的隐私机制。

Method: 使用Dobrushin系数分析离散马尔可夫核的收缩性质，推导基于PML保证的收缩界限，构造实现这些界限的机制，并应用Binette不等式将结果扩展到一般f-散度。

Result: 获得了基于核PML保证的可实现收缩界限，提供了达到这些界限的机制构造，得到了比LDP更紧的界限，并将分析扩展到任何离散核和一般f-散度。

Conclusion: 该研究为具有有界PML的离散马尔可夫核提供了收缩分析框架，推广了LDP分析，获得了更紧的界限，并将结果扩展到更一般的f-散度度量。

Abstract: We investigate Dobrushin coefficients of discrete Markov kernels that have bounded pointwise maximal leakage (PML) with respect to all distributions with a minimum probability mass bounded away from zero by a constant $c>0$. This definition recovers local differential privacy (LDP) for $c\to 0$. We derive achievable bounds on contraction in terms of a kernels PML guarantees, and provide mechanism constructions that achieve the presented bounds. Further, we extend the results to general $f$-divergences by an application of Binette's inequality. Our analysis yields tighter bounds for mechanisms satisfying LDP and extends beyond the LDP regime to any discrete kernel.

</details>


### [53] [Error Exponents for Randomised List Decoding](https://arxiv.org/abs/2601.09519)
*Henrique K. Miyamoto,Sheng Yang*

Main category: cs.IT

TL;DR: 研究随机列表解码的随机编码错误指数，分析固定列表大小和指数增长列表大小两种机制下的性能界限


<details>
  <summary>Details</summary>
Motivation: 研究随机列表解码（解码器根据解码度量随机选择L个消息）的错误指数性能，探索其相对于普通解码的性能改进潜力

Method: 分析随机列表解码的随机编码错误指数，针对不匹配和匹配解码度量，研究两种机制：固定列表大小和列表大小随块长度指数增长

Result: 对于固定列表大小，得到集合紧的随机编码错误指数，但匹配度量下不改善普通解码的错误指数；对于指数增长列表大小，得到非平凡的下界，在高码率下对匹配度量是紧的

Conclusion: 随机列表解码在固定列表大小下对匹配度量无性能改进，但在列表大小指数增长时在高码率下能提供有意义的性能提升

Abstract: This paper studies random-coding error exponents of randomised list decoding, in which the decoder randomly selects $L$ messages with probabilities proportional to the decoding metric of the codewords. The exponents (or bounds) are given for mismatched, and then particularised to matched and universal decoding metrics. Two regimes are studied: for fixed list size, we derive an ensemble-tight random-coding error exponent, and show that, for the matched metric, it does not improve the error exponent of ordinary decoding. For list sizes growing exponentially with the block-length, we provide a non-trivial lower bound to the error exponent that is tight at high rates under the matched metric.

</details>


### [54] [A Finite-Sample Strong Converse for Binary Hypothesis Testing via (Reverse) Rényi Divergence](https://arxiv.org/abs/2601.09550)
*Roberto Bruno,Adrien Vandenbroucque,Amedeo Roberto Esposito*

Main category: cs.IT

TL;DR: 本文研究有限样本下非对称错误约束的二元假设检验，利用"反向"Rényi散度推导了Type II错误概率的新非渐近界，建立了强逆定理，并展示了Type I错误以速率c指数衰减时Type II错误的指数收敛行为。


<details>
  <summary>Details</summary>
Motivation: 在有限样本和非对称错误约束下，现有假设检验理论存在局限性，需要更精确的非渐近界来刻画Type II错误概率，并建立强逆定理以完善理论框架。

Method: 采用"反向"Rényi散度作为分析工具，推导Type II错误概率的非渐近上界和下界，建立与Kullback-Leibler散度的关系，并通过数值实验验证理论结果。

Result: 1) 获得了Type II错误概率的严格非渐近界；2) 建立了强逆定理；3) 证明了当Type I错误以速率c指数衰减时，若c>D(P₁∥P₀)则Type II错误指数收敛到1，若c<D(P₁∥P₀)则指数收敛到0；4) 数值结果显示所提逆界严格优于现有有限样本结果。

Conclusion: 本文通过反向Rényi散度建立了二元假设检验的精确非渐近理论框架，所获结果不仅完善了有限样本下的错误概率分析，还提供了优于现有文献的逆界，为实际假设检验问题提供了更可靠的理论基础。

Abstract: This work investigates binary hypothesis testing between $H_0\sim P_0$ and $H_1\sim P_1$ in the finite-sample regime under asymmetric error constraints. By employing the ``reverse" Rényi divergence, we derive novel non-asymptotic bounds on the Type II error probability which naturally establish a strong converse result. Furthermore, when the Type I error is constrained to decay exponentially with a rate $c$, we show that the Type II error converges to 1 exponentially fast if $c$ exceeds the Kullback-Leibler divergence $D(P_1\|P_0)$, and vanishes exponentially fast if $c$ is smaller. Finally, we present numerical examples demonstrating that the proposed converse bounds strictly improve upon existing finite-sample results in the literature.

</details>


### [55] [On Linear Estimators for some Stable Vectors](https://arxiv.org/abs/2601.09554)
*Rayan Chouity,Charbel Hannoun,Jihad Fahs,Ibrahim Abou-Faycal*

Main category: cs.IT

TL;DR: 研究联合稳定随机变量的估计问题，在线性变换和子高斯对称α稳定向量两种依赖模型下，证明了条件均值估计器都是线性的，并找到了最优线性估计器。


<details>
  <summary>Details</summary>
Motivation: 研究稳定随机变量（特别是α稳定分布）的估计问题，这些分布在信号处理、金融和通信等领域有广泛应用。传统高斯分布的最优线性估计理论（条件均值等于最佳线性最小均方误差估计器）是否适用于更一般的稳定分布是本文的研究动机。

Method: 考虑两种具体的依赖模型：1）两个独立稳定变量的线性变换；2）子高斯对称α稳定向量。在这两种模型下分析条件均值估计器的性质，并寻找最优线性估计器。

Result: 证明了在这两种依赖模型下，条件均值估计器都是线性的。找到了最优线性估计器。特别地，对于子高斯对称α稳定向量，条件均值估计器和最优线性估计器是相同的，这推广了高斯分布中条件均值等于最佳线性最小均方误差估计器的经典结果。

Conclusion: 对于联合稳定随机变量，在特定的依赖结构下，条件均值估计器具有线性性质，并且可以找到最优线性估计器。子高斯对称α稳定向量的结果将高斯分布的最优估计理论推广到了更一般的稳定分布框架中。

Abstract: We consider the estimation problem for jointly stable random variables. Under two specific dependency models: a linear transformation of two independent stable variables and a sub-Gaussian symmetric $α$-stable (S$α$S) vector, we show that the conditional mean estimator is linear in both cases. Moreover, we find dispersion optimal linear estimators. Interestingly, for the sub-Gaussian (S$α$S) vector, both estimators are identical generalizing the well-known Gaussian result of the conditional mean being the best linear minimum-mean square estimator.

</details>


### [56] [The Spectral Representations Of The Simple Hypothesis Testing Problem](https://arxiv.org/abs/2601.09564)
*Barış Nakiboğlu*

Main category: cs.IT

TL;DR: 论文研究了假设检验问题中随机检测器的Type II错误概率（体积）关于Type I错误概率的凸共轭（Legendre变换），推导出原始熵谱表达式，并应用于乘积测度情况得到最新边界。


<details>
  <summary>Details</summary>
Motivation: 研究假设检验中Type I和Type II错误概率之间的基本关系，特别是Type II错误体积作为Type I错误函数的凸共轭性质，这对于理解假设检验的性能极限和推导最优边界具有重要意义。

Method: 利用似然比分位数的性质，推导随机检测器下Type II错误体积的凸共轭表达式。通过标准谱恒等式，将原始熵谱表示为似然比互补分布函数的积分。对于乘积测度情况，结合Berry-Esseen定理和高斯Mills比率性质进行分析，包括有倾斜和无倾斜两种情况。

Result: 确定了Type II错误体积关于Type I错误体积的凸共轭表达式，称为原始熵谱。该表达式可推广到所有非平凡情况下的σ-有限测度。对于乘积测度，通过分析得到了最先进的边界结果。

Conclusion: 论文建立了假设检验中Type II错误体积的凸共轭理论框架，提供了原始熵谱的积分表达式。该对偶表征不仅具有理论意义，而且通过结合Berry-Esseen定理，为乘积测度情况提供了最新的性能边界，展示了理论结果的实际应用价值。

Abstract: The convex conjugate (i.e., the Legendre transform) of Type II error probability (volume) as a function of Type I error probability (volume) is determined for the hypothesis testing problem with randomized detectors. The derivation relies on properties of likelihood ratio quantiles and is general enough to extend to the case of $σ$-finite measures in all non-trivial cases. The convex conjugate of the Type II error volume, called the primitive entropy spectrum, is expressed as an integral of the complementary distribution function of the likelihood ratio using a standard spectral identity. The resulting dual characterization of the Type II error volume leads to state of the art bounds for the case of product measures via Berry--Esseen theorem through a brief analysis relying on properties of the Gaussian Mills ratio, both with and without tilting.

</details>


### [57] [On the Error Probability of RPA Decoding of Reed-Muller Codes over BMS Channels](https://arxiv.org/abs/2601.09581)
*Dorsa Fathollahi,V. Arvind Rameshwar,V. Lalitha*

Main category: cs.IT

TL;DR: 本文分析了RPA解码器在一般二进制无记忆对称信道下对Reed-Muller码的性能，将之前仅适用于BSC信道的结果推广到所有BMS信道。


<details>
  <summary>Details</summary>
Motivation: 之前Rameshwar和Lalitha (2025)的工作证明了RPA解码器在二进制对称信道下对"低码率"RM码能达到渐近消失的错误概率，但该证明方法难以直接推广到一般BMS信道。本文旨在克服这一限制，建立适用于所有BMS信道的理论保证。

Method: 通过建立RPA投影操作与极化码"信道合并"阶段之间的等价关系，避免了之前方法对信道的额外限制性假设。利用这种等价性，可以在最大似然解码下对一阶RM码（RPA解码器的"基础情况"）使用通用的联合界，该界对所有BMS信道都成立。然后将这些观察结果应用到Rameshwar和Lalitha (2025)的证明框架中。

Result: 证明了对于所有BMS信道，当码长n趋于无穷大时，对于阶数大约为log log n的RM码，RPA解码器能够达到渐近消失的错误概率。这是对之前仅适用于BSC信道结果的重要推广。

Conclusion: 通过建立RPA投影与极化码信道合并的等价关系，成功将RPA解码器的性能保证从BSC信道推广到所有BMS信道，为RM码在更广泛信道模型下的解码性能提供了理论支撑。

Abstract: We analyze the performance of the Recursive Projection-Aggregation (RPA) decoder of Ye and Abbe (2020), for Reed-Muller (RM) codes, over general binary memoryless symmetric (BMS) channels. Our work is a significant generalization of a recent result of Rameshwar and Lalitha (2025) that showed that the RPA decoder provably achieves vanishing error probabilities for "low-rate" RM codes, over the binary symmetric channel (BSC). While a straightforward generalization of the proof strategy in that paper will require additional, restrictive assumptions on the BMS channel, our technique, which employs an equivalence between the RPA projection operation and a part of the "channel combining" phase in polar codes, requires no such assumptions. Interestingly, such an equivalence allows for the use of a generic union bound on the error probability of the first-order RM code (the "base case" of the RPA decoder), under maximum-likelihood decoding, which holds for any BMS channel. We then exploit these observations in the proof strategy outlined in the work of Rameshwar and Lalitha (2025), and argue that, much like in the case of the BSC, one can obtain vanishing error probabilities, in the large $n$ limit (where $n$ is the blocklength), for RM orders that scale roughly as $\log \log n$, for all BMS channels.

</details>


### [58] [Secret sharing with additive access structures from correlated random variables](https://arxiv.org/abs/2601.09640)
*David Miller,Rémi A. Chou*

Main category: cs.IT

TL;DR: 论文将基于相关随机性和公共通信的秘密共享模型从固定访问结构推广到动态访问结构序列（称为加法访问结构），证明存在策略能在每个时间步达到与固定访问结构模型相同的秘密速率，并在阈值访问结构时实现容量最优。


<details>
  <summary>Details</summary>
Motivation: 现有秘密共享模型主要针对固定访问结构设计，但实际应用中访问结构可能随时间动态变化。需要研究支持访问结构单调增长的动态秘密共享模型，其中参与者子集可以在不同时间步被添加到访问结构中。

Method: 将基于相关随机性和公共通信的秘密共享模型推广到支持动态访问结构序列（加法访问结构）。访问结构允许单调增长，参与者子集可在给定时间步被添加，分发者仅在变化发生时获知访问结构变更。

Result: 证明存在秘密共享策略能在每个时间步达到与固定访问结构模型相同的秘密速率。同时证明存在策略在访问结构为阈值访问结构的任何时间步都能实现容量最优。

Conclusion: 成功将秘密共享模型从固定访问结构扩展到动态访问结构，证明了在动态环境下仍能保持与固定模型相同的性能，并在阈值访问结构情况下达到理论最优容量。

Abstract: We generalize secret-sharing models that rely on correlated randomness and public communication, originally designed for a fixed access structure, to support a sequence of dynamic access structures, which we term an Additive Access Structure. Specifically, the access structure is allowed to monotonically grow by having any subset of participants added to it at a given time step, and the dealer only learns of these changes to the access structure on the time step that they occur. For this model, we prove the existence of a secret sharing strategy that achieves the same secret rate at each time step as the best known strategy for the fixed access structure version of this model. We also prove that there exists a strategy that is capacity-achieving at any time step where the access structure is a threshold access structure.

</details>


### [59] [Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions](https://arxiv.org/abs/2601.09674)
*Lei Huang*

Main category: cs.IT

TL;DR: 提出量化QC-SC-LDPC码设计空间的方法，通过CLLL和MT算法推导满足结构约束的可行解数量下界，为消除有害子结构提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 设计大耦合存储器QC-SC-LDPC码时，需要消除由边缘扩展和提升操作引入的有害子结构（如短环），以降低错误平层。现有方法缺乏对可行设计空间大小和结构的量化分析。

Method: 基于Clique Lovász Local Lemma (CLLL)设计原则和Moser-Tardos (MT)构造方法，推导满足结构避免约束的分区矩阵数量下界；利用Rényi熵界分析MT分布，计算MT算法可输出的不同解数量下界。

Result: 获得了满足结构约束的可行解数量下界，包括在行列置换下的非等价解数量；提供了MT算法输出解多样性的可计算下界；针对消除4环的特殊情况得到了闭式界。

Conclusion: 该工作量化了QC-SC-LDPC码的设计空间，为存储器大小/提升因子的确定和剩余搜索空间的估计提供了理论依据，增强了随机化构造的多样性保证。

Abstract: Designing large coupling memory quasi-cyclic spatially-coupled LDPC (QC-SC-LDPC) codes with low error floors requires eliminating specific harmful substructures (e.g., short cycles) induced by edge spreading and lifting. Building on our work~\cite{r15} that introduced a Clique Lovász Local Lemma (CLLL)-based design principle and a Moser--Tardos (MT)-type constructive approach, this work quantifies the size and structure of the feasible design space. Using the quantitative CLLL, we derive explicit lower bounds on the number of partition matrices satisfying a given family of structure-avoidance constraints, and further obtain bounds on the number of non-equivalent solutions under row/column permutations. Moreover, via Rényi-entropy bounds for the MT distribution, we provide a computable lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete diversity guarantee for randomized constructions. Specializations for eliminating 4-cycle candidates yield closed-form bounds as functions of system parameters, offering a principled way to size memory/lifting and to estimate the remaining search space.

</details>


### [60] [Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information](https://arxiv.org/abs/2601.09679)
*Adel Javanmard,David P. Woodruff*

Main category: cs.IT

TL;DR: 本文解决了Courtade-Kumar猜想相关的两个重要问题：1) 证明了任意布尔函数（无论偏置）的互信息和上界为1-H(α)，推广了之前仅适用于平衡函数的结果；2) 在高噪声区域建立了最优误差界O(λ²)，显著扩展了猜想成立的噪声参数范围。


<details>
  <summary>Details</summary>
Motivation: Courtade-Kumar猜想是信息论和布尔函数理论中的重要问题，研究布尔函数输出与噪声输入之间的互信息最大化问题。该猜想认为独裁函数能够最大化这种互信息，但之前的研究存在局限性：1) 仅适用于平衡布尔函数；2) 在高噪声区域的误差界不够精确。

Method: 采用信息论和傅里叶分析的方法：1) 通过推广技术证明任意布尔函数的互信息和上界；2) 在高噪声区域使用渐近熵展开技术，建立最优误差界O(λ²)，其中λ=(1-2α)²。

Result: 1) 解决了Courtade-Kumar提出的开放问题，证明任意布尔函数的互信息和上界为1-H(α)；2) 在高噪声区域建立了最优误差界O(λ²)，改进了之前已知的最佳界，并得到了尖锐的线性傅里叶集中界。

Conclusion: 本文在Courtade-Kumar猜想研究上取得了重要进展：完全解决了任意偏置布尔函数的互信息和上界问题，并在高噪声区域显著改进了误差界，扩展了猜想成立的参数范围，为最终证明该猜想提供了关键工具。

Abstract: The Courtade-Kumar conjecture posits that dictatorship functions maximize the mutual information between the function's output and a noisy version of its input over the Boolean hypercube. We present two significant advancements related to this conjecture. First, we resolve an open question posed by Courtade and Kumar, proving that for any Boolean function (regardless of bias), the sum of mutual information between the function's output and the individual noisy input coordinates is bounded by $1-H(α)$, where $α$ is the noise parameter of the Binary Symmetric Channel. This generalizes their previous result which was restricted to balanced Boolean functions. Second, we advance the study of the main conjecture in the high noise regime. We establish an optimal error bound of $O(λ^2)$ for the asymptotic entropy expansion, where $λ= (1-2α)^2$, improving upon the previous best-known bounds. This refined analysis leads to a sharp, linear Fourier concentration bound for highly informative functions and significantly extends the range of the noise parameter $λ$ for which the conjecture is proven to hold.

</details>
