<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Improving Reliability of Human Trafficking Alerts in Airports](https://arxiv.org/abs/2512.23865)
*Nana Oye Akrofi Quarcoo,Milena Radenkovic*

Main category: cs.NI

TL;DR: 研究机场个人紧急警报场景，评估两种DTN协议（Spray and Wait vs Epidemic）在交付率和延迟方面的性能表现


<details>
  <summary>Details</summary>
Motivation: 机场环境中的个人紧急警报系统需要可靠的通信机制，特别是在基础设施受限或中断的情况下。延迟容忍网络（DTN）协议能够在这种间歇性连接环境中提供有效的信息传递。

Method: 使用ONE模拟器对机场场景进行仿真，应用Spray and Wait和Epidemic两种DTN协议，评估它们的交付率和延迟性能。

Result: 研究分析了两种协议在机场紧急警报场景中的表现，讨论了各自的优势和局限性，以及模拟实验设置中的约束条件。

Conclusion: DTN网络在机场紧急警报系统中具有应用潜力，研究还探讨了DTN技术在打击人口贩卖等全球性问题中的潜在作用。

Abstract: This paper investigates the latter scenario of individual emergency alerts in airports by applying two existing benchmark delay tolerant network protocols and evaluating their performance of delivery ratio and latency. First, the paper provides a background on Mobile Ad Hoc Networks (MANETs) and Delay Tolerant Networks (DTNs), as well as Vehicular Ad Hoc Networks (VANETs) as a subset of MANETs. Next, the scenario is simulated using the Opportunistic Network Environment (ONE) simulator and runs the DTN protocols applying Spray and Wait and Epidemic. The study discusses the results, highlighting the advantages and limitations of each protocol within the scenario and addressing constraints of the simulation or experimental setup. A wider discussion then considers related research on technologies that combat human trafficking and the potential role of DTN networks in improving this global issue for the better.

</details>


### [2] [Wireless Multimodal Foundation Model (WMFM): Integrating Vision and Communication Modalities for 6G ISAC Systems](https://arxiv.org/abs/2512.23897)
*Mohammad Farzanullah,Han Zhang,Akram Bin Sediq,Ali Afana,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 提出无线多模态基础模型WMFM，通过对比学习联合学习无线信道系数和视觉图像，在ISAC系统中实现数据高效的多模态学习


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，集成感知与通信模态为开发通用化和数据高效模型提供了独特机会。多模态基础模型的出现使得跨数据类型的联合理解成为可能。

Method: 提出基于对比学习的无线多模态基础模型WMFM，使用自监督对比学习对齐摄像头和信道数据的嵌入，无需显式标签。预训练编码器冻结作为特征提取器，配合轻量级任务特定头部进行下游任务微调。

Result: 在DeepVerse6G数据集上，WMFM在LoS/nLoS分类上平衡准确率提升17%，定位误差降低48.5%，训练时间减少90倍。即使仅用20%数据训练，WMFM仍优于全监督端到端模型。

Conclusion: WMFM为ISAC系统中的可扩展多模态学习奠定了基础，为智能自适应6G网络铺平了道路，展示了数据高效学习的鲁棒性。

Abstract: The emergence of multimodal foundation models has revolutionized learning paradigms by enabling joint understanding across diverse data types. In the context of next-generation wireless networks, integrating sensing and communication modalities presents a unique opportunity to develop generalizable and data-efficient models. In this work, we introduce the contrastive learning based Wireless Multimodal Foundation Model (WMFM), a large-scale framework that jointly learns from wireless channel coefficients and visual imagery. The WMFM is pretrained using contrastive learning, a self-supervised learning technique that aligns embeddings of camera and channel data without requiring explicit labels. The pretrained encoders are then frozen and employed as feature extractors, with lightweight task-specific heads, fine-tuned for downstream tasks, including user localization and LoS/nLoS classification. Extensive experiments on the DeepVerse6G dataset demonstrate that the proposed WMFM achieves a 17% improvement in balanced accuracy for LoS/nLoS classification and a 48.5% reduction in localization error compared to the end-to-end (E2E) benchmark, while reducing training time by up to 90-fold. Even when trained with as little as 20% of the data, the WMFM-based heads outperform the fully supervised E2E model, underscoring their robustness and data-efficient learning. The proposed approach establishes a foundation for scalable, multimodal learning in Integrated Sensing and Communication (ISAC) systems, paving the way for intelligent and adaptive 6G networks.

</details>


### [3] [Road Rules for Radio: Why Your Wi-Fi Got Better](https://arxiv.org/abs/2512.23901)
*Bradley Fang,Michael Roger*

Main category: cs.NI

TL;DR: 这篇论文对WiFi关键技术进展进行了全面的文献综述，涵盖带宽、电池寿命、流量碰撞等七个关键领域，并引入高速公路类比帮助理解，同时探讨了即将发布的WiFi 8标准。


<details>
  <summary>Details</summary>
Motivation: WiFi技术发展迅速但进展复杂，普通用户难以全面理解其演进过程。论文旨在填补这一知识空白，通过系统性的文献综述帮助读者理解WiFi的整体发展脉络。

Method: 采用文献综述方法，聚焦七个关键技术领域：带宽、电池寿命、流量碰撞、干扰、数据密集型传输、多设备连接和峰值吞吐量/调制。引入高速公路类比解释网络机制，并分析即将发布的WiFi 8标准。

Result: 论文提供了WiFi技术发展的全面概述，揭示了从单纯追求数据速率向可靠性优先的转变趋势，特别是WiFi 8标准基于IEEE 802.11bn规范，强调"超高可靠性"。

Conclusion: WiFi技术正经历从数据速率优先到可靠性优先的重要转变，WiFi 8标准代表了这一新方向。论文通过系统性综述和通俗类比，使复杂技术概念易于理解，为读者提供了全面的WiFi知识框架。

Abstract: WiFi allows for the connection of devices and people around the globe. It has proven to be a monumental and revolutionary tool that keeps the world connected. However, recent WiFi advancements are numerous and at times confusing. WiFi has grown significantly over the years, yet few understand the scope and scale of WiFi progression as a whole. This paper tackles that problem, providing a broad literature review on the advancements of key WiFi features to date. This paper will center on seven key areas of focus: (1) bandwidth, (2) battery life, (3) traffic collisions, (4) interference, (5) data-intensive transmissions, (6) numerous devices, and (7) peak throughput/modulation. Each section will focus on WiFi's problems, how those problems were fixed, as well as the limitations of existing solutions. Moreover, the paper explains the role of new unreleased technologies in these seven areas. This includes exploring the upcoming WiFi 8 standard based on the IEEE 802.11bn "Ultra High Reliability" (UHR) specification and how it builds upon current specifications. Compared to previous specifications, WiFi 8 marks a stronger and more significant shift toward prioritizing reliability over pure data rates. Beyond a sole literature review, this paper uses a novel analogy. A road/highway analogy will be integrated throughout the paper to facilitate understanding of networking mechanisms. This paper is approachable and is written such that someone with very little WiFi knowledge should come away with a strong understanding of WiFi. As is typical of literature review papers, technical claims will be grounded in prior work.

</details>


### [4] [SRM at 30: Lessons from Early Data-Centric Networking and Their Impact on Named Data Networking](https://arxiv.org/abs/2512.23928)
*Tianyuan Yu,Adam Thieme,Junxiao Shi,Lan Wang,Lixia Zhang*

Main category: cs.NI

TL;DR: 这篇论文回顾了1995年的SRM框架，分析了其数据中心的可靠多播方法，探讨了其面临的挑战和教训，并展示了它如何影响了命名数据网络（NDN）的设计。


<details>
  <summary>Details</summary>
Motivation: 重新审视SRM框架，分析其面临的挑战、获得的教训，以及它如何影响了后来命名数据网络（NDN）的发展。SRM引入了数据中心的可靠多播方法，但遇到了与IP地址架构的语义不匹配问题。

Method: 通过回顾性分析，比较SRM的数据中心框架与IP地址架构的差异，探讨SRM实验中发现的问题，并展示这些经验如何影响了NDN的设计决策。

Result: SRM实验揭示了其数据中心框架与IP地址架构之间的根本性语义不匹配：应用层命名数据，但网络层对这些名称"视而不见"，导致低效的丢失恢复。NDN通过使网络传输与数据检索模型对齐，并直接保护数据而非通信通道，解决了这种架构摩擦。

Conclusion: SRM的早期见解为NDN的关键设计决策提供了重要参考，NDN的设计体现了数十年网络研究和开发的累积智慧。这篇回顾性研究展示了从SRM到NDN的演进过程，以及如何通过解决架构不匹配问题来改进数据中心网络设计。

Abstract: A 1995 SIGCOMM paper, "A Reliable Multicast Framework for Light-weight Sessions and Application-Level Framing", commonly known as SRM, explored a fundamentally new approach to reliable multiparty data delivery. Rather than adapting established sender-driven reliable unicast mechanisms to multicast, as most contemporaneous proposals did, SRM introduced a data-centric model in which data receivers recover losses by explicitly requesting missing data. Thirty years later, we revisit the SRM framework, examining the challenges it faced, the lessons learned, and its influence on the later development of Named Data Networking (NDN). Experimentations with SRM revealed a fundamental semantic mismatch between its data-centric framework and IP's address-based delivery; while the application layer named data, the network layer remained 'blind' to those names, resulting in inefficient loss recovery. NDN resolves this architectural friction by aligning network delivery with the data-retrieval model and by securing data directly rather than securing communication channels. This retrospective highlights how early insights from SRM informed key design decisions in NDN and illustrates how NDN's design emerged from the cumulative insights gained over decades of networking research and development.

</details>


### [5] [Beyond Dedicated-Active: A General Reliability Provisioning Framework for SFC Placement in Fog Computing](https://arxiv.org/abs/2512.24049)
*Negin Doostar,Mohammad Reza Heidarpour,Amir Khorsandi*

Main category: cs.NI

TL;DR: 本文提出一个可靠性感知的服务功能链放置框架，在异构雾服务器上优化延迟和成本，同时满足可靠性和截止时间约束，通过遗传算法求解，结果显示共享备用冗余策略比传统专用主动方法性能提升达84%。


<details>
  <summary>Details</summary>
Motivation: 物联网设备爆炸式增长给传统云基础设施带来压力，需要低延迟和节能的替代方案。雾计算将计算放在网络边缘，但有限的异构雾资源带来可靠性挑战，特别是对任务关键型应用。同时，服务功能链部署方式比单体部署更容易故障，需要智能冗余和放置策略。

Method: 从可靠性理论角度研究可靠性感知的SFC放置问题，探索四种冗余策略（共享vs专用、主动vs备用），提出通用框架最小化延迟和成本同时满足可靠性和截止时间约束。将问题建模为整数非线性规划，开发两种基于遗传算法的解决方案。

Result: 仿真结果表明，共享备用冗余策略显著优于传统专用主动方法，性能提升高达84%。

Conclusion: 本文提出的可靠性感知SFC放置框架能有效解决异构雾环境中的可靠性挑战，共享备用冗余策略在延迟、成本和可靠性方面表现优异，为任务关键型物联网应用提供了可行的解决方案。

Abstract: The explosive growth of Internet of Things (IoT) devices has strained traditional cloud infrastructures, highlighting the need for low-latency and energy-efficient alternatives. Fog computing addresses this by placing computation near the network edge. However, limited and heterogeneous fog resources pose reliability challenges, especially for mission-critical applications. On the other hand, to improve flexibility, applications are deployed as Service Function Chains (SFCs), where each function runs as a Virtual Network Function (VNF). While scalable, this approach is more failure-prone than monolithic deployments, necessitating intelligent redundancy and placement strategies. This paper addresses the reliability-aware SFC placement problem over heterogeneous fog servers through the lens of reliability theory. We explore four redundancy strategies, combining shared vs. dedicated and active vs. standby modes, and propose a general framework to minimize latency and cost while meeting reliability and deadline constraints. The problem is formulated as an Integer Non-Linear Program (INLP), and two genetic algorithm (GA)-based solutions are developed. Simulation results show that shared-standby redundancy outperforms the conventional dedicated-active approach by up to 84%.

</details>


### [6] [CPePC: Cooperative and Predictive Popularity based Caching for Named Data Networks](https://arxiv.org/abs/2512.24073)
*Pankaj Chaudhary,Neminath Hubballi,Sameer G. Kulkarni*

Main category: cs.NI

TL;DR: CPePC是一种协作缓存技术，通过社区划分和领导者节点协调来减少流行度估计开销，同时结合缓存占用率和内容流行度预测参数来优化缓存决策，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 命名数据网络中的路由器缓存容量有限，需要智能选择缓存内容。现有技术依赖缓存流行内容来最大化利用率，但这些方法在协调和估计内容流行度方面存在显著开销。需要解决这一效率问题。

Method: CPePC采用两种策略：1) 通过社区估计算法将网络划分为多个非重叠社区，并选择领导者节点代表社区内所有节点协调工作，从而减少流行度估计开销；2) 基于当前缓存占用率和内容流行度预测一个参数来指导缓存决策。提供了社区检测、领导者选择、内容流行度估计和缓存决策的算法。

Result: 使用离散事件模拟器对CPePC与六种最先进的缓存技术进行评估比较，结果显示CPePC性能优于其他方法。

Conclusion: CPePC通过减少流行度估计开销和基于预测参数做出缓存决策，有效提高了命名数据网络中协作缓存的性能，在有限缓存容量下实现了更好的资源利用。

Abstract: Caching content is an inherent feature of Named Data Networks. Limited cache capacity of routers warrants that the choice of content being cached is judiciously done. Existing techniques resort to caching popular content to maximize utilization. However, these methods experience significant overhead for coordinating and estimating the popularity of content. To address this issue, in this paper, we present CPePC, which is a cooperative caching technique designed to improve performance. It accomplishes this through a combination of two factors. First, CPePC enhances efficiency by minimizing the overhead of popularity estimation. Second, it forecasts a parameter that governs caching decisions. Efficiency in popularity estimation is achieved by dividing the network into several non-overlapping communities using a community estimation algorithm and selecting a leader node to coordinate this on behalf of all the nodes in the community. CPePC bases its caching decisions by predicting a parameter whose value is estimated using current cache occupancy and the popularity of the content into account. We present algorithms for community detection, leader selection, content popularity estimation, and caching decisions made by the CPePC method. We evaluate and compare it with six other state-of-the-art caching techniques, with simulations performed using a discrete event simulator to show that it outperforms others.

</details>


### [7] [Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations](https://arxiv.org/abs/2512.24452)
*Yalin E. Sagduyu,Tugba Erpek,Aylin Yener,Sennur Ulukus*

Main category: cs.NI

TL;DR: 提出基于深度学习的语义通信框架，在支持多接收器任务的同时限制向窃听者的语义泄露，通过min-max优化和对抗性扰动层增强安全性。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽然提高了带宽效率和鲁棒性，但学习的语义表示仍可能向窃听者泄露敏感信息。需要设计既能支持合法接收器任务又能限制语义泄露的安全框架。

Method: 1) 使用学习编码器-解码器架构；2) 通过迭代min-max优化训练：窃听者训练提高语义推理，合法收发器训练保持任务性能同时降低窃听者成功率；3) 引入辅助扰动层，在传输波形上叠加对抗性扰动以降低语义泄露。

Result: 在Rayleigh衰落信道和AWGN噪声下使用MNIST和CIFAR-10数据集评估：语义准确率和重建质量随潜在维度增加而提高；min-max机制显著降低窃听者推理性能而不损害合法接收器；扰动层即使合法链路仅为自己任务训练也能有效减少语义泄露。

Conclusion: 该框架为现实无线环境中对抗自适应攻击者提供了可调、端到端的隐私保护语义通信设计，在保持合法接收器性能的同时有效限制语义泄露。

Abstract: Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.

</details>


### [8] [Chat-Driven Optimal Management for Virtual Network Services](https://arxiv.org/abs/2512.24614)
*Yuya Miyaoka,Masaki Inoue,Kengo Urata,Shigeaki Harada*

Main category: cs.NI

TL;DR: 提出一个结合NLP与优化的聊天驱动网络管理框架，通过两阶段方法（意图解释器+优化器）实现安全可靠的虚拟网络重配置


<details>
  <summary>Details</summary>
Motivation: 传统基于意图的网络管理方法依赖统计语言模型解释用户意图，但无法保证生成配置的可行性，需要更可靠的方法

Method: 两阶段框架：1) Interpreter使用NLP从自然语言提示中提取意图（采用Sentence-BERT+SVM或LLM两种方法）；2) Optimizer通过整数线性规划计算可行的VM放置和路由方案

Result: 实验表明框架能动态更新VM放置和路由同时保持可行性。LLM提取器在少量标注样本下准确率更高，Sentence-BERT+SVM延迟更低适合实时操作

Conclusion: NLP驱动的意图提取与基于优化的分配相结合，可实现安全、可解释、用户友好的虚拟网络管理

Abstract: This paper proposes a chat-driven network management framework that integrates natural language processing (NLP) with optimization-based virtual network allocation, enabling intuitive and reliable reconfiguration of virtual network services. Conventional intent-based networking (IBN) methods depend on statistical language models to interpret user intent but cannot guarantee the feasibility of generated configurations. To overcome this, we develop a two-stage framework consisting of an Interpreter, which extracts intent from natural language prompts using NLP, and an Optimizer, which computes feasible virtual machine (VM) placement and routing via an integer linear programming. In particular, the Interpreter translates user chats into update directions, i.e., whether to increase, decrease, or maintain parameters such as CPU demand and latency bounds, thereby enabling iterative refinement of the network configuration. In this paper, two intent extractors, which are a Sentence-BERT model with support vector machine (SVM) classifiers and a large language model (LLM), are introduced. Experiments in single-user and multi-user settings show that the framework dynamically updates VM placement and routing while preserving feasibility. The LLM-based extractor achieves higher accuracy with fewer labeled samples, whereas the Sentence-BERT with SVM classifiers provides significantly lower latency suitable for real-time operation. These results underscore the effectiveness of combining NLP-driven intent extraction with optimization-based allocation for safe, interpretable, and user-friendly virtual network management.

</details>


### [9] [Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks](https://arxiv.org/abs/2512.24659)
*Yixian Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Changyuan Zhao,Daxin Tian,Dusit Niyato,Shiwen Mao*

Main category: cs.NI

TL;DR: 本文提出了一种IRS赋能的低空多接入边缘计算架构，通过混合IRS增强空地连接，采用分层在线优化方法最小化任务完成延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统MEC架构中存在的空地连接阻塞问题，同时优化任务完成延迟和能耗，需要设计一种智能的IRS增强型低空MEC架构和高效的优化算法。

Method: 提出IRS赋能的低空MEC架构，包含空中和地面MEC服务器以及混合IRS。采用分层在线优化方法，将多目标优化问题重构为Stackelberg博弈，在跟随者层面使用多对一匹配机制，在领导者层面提出GDMTD3算法结合KKT方法。

Result: 仿真结果表明，相比最佳基准方法和最先进的DRL算法，所提方法分别将平均任务完成延迟降低2.5%，平均能耗降低3.1%，并展现出优异的收敛稳定性、鲁棒性和可扩展性。

Conclusion: 提出的IRS赋能低空MEC架构和分层在线优化方法能有效解决空地连接阻塞问题，显著提升系统性能，为动态环境中的边缘计算服务提供了高效解决方案。

Abstract: In this paper, we propose an intelligent reflecting surface (IRS)-enabled low-altitude multi-access edge computing (MEC) architecture, where an aerial MEC server cooperates with a terrestrial MEC server to provide computing services, while hybrid IRSs (i.e., building-installed and UAV-carried IRSs) are deployed to enhance the air-ground connectivity under blockage. Based on this architecture, we formulate a multi-objective optimization problem (MOOP) to minimize the task completion delay and energy consumption by jointly optimizing task offloading, UAV trajectory control, IRS phase-shift configuration, and computation resource allocation. The considered problem is NP-hard, and thus we propose a hierarchical online optimization approach (HOOA) to efficiently solve the problem. Specifically, we reformulate the MOOP as a Stackelberg game, where MEC servers collectively act as the leader to determine the system-level decisions, while the vehicles act as followers to make individual decisions. At the follower level, we present a many-to-one matching mechanism to generate feasible discrete decisions. At the leader level, we propose a generative diffusion model-enhanced twin delayed deep deterministic policy gradient (GDMTD3) algorithm integrated with a Karush-Kuhn-Tucker (KKT)-based method, which is a deep reinforcement learning (DRL)-based approach, to determine the continuous decisions. Simulation results demonstrate that the proposed HOOA achieves significant improvements, which reduces average task completion delay by 2.5% and average energy consumption by 3.1% compared with the best-performing benchmark approach and state-of-the-art DRL algorithm, respectively. Moreover, the proposed HOOA exhibits superior convergence stability while maintaining strong robustness and scalability in dynamic environments.

</details>


### [10] [Analyzing Communication Predictability in LLM Training](https://arxiv.org/abs/2512.24750)
*Wenxue Li,Xiangzhou Liu,Yuxuan Li,Yilun Jin,Zhenghang Ren,Xudong Liao,Han Tian,Bo Ren,Zhizhen Zhong,Guyue Liu,Ying Zhang,Kai Chen*

Main category: cs.NI

TL;DR: 本文系统化地研究了分布式训练中LLM的通信可预测性，分析了流量模式和通信开销，提出了通信开销的解析公式，并开发了配置调优工具ConfigTuner，相比现有方法显著提升了训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过在线分析利用通信可预测性进行运行时优化，但缺乏对可预测性的系统化理解。特别是在使用混合并行的大型语言模型分布式训练中，需要系统化地研究通信可预测性，以优化训练性能。

Method: 1) 系统化地研究LLM分布式训练中的通信可预测性，分析流量模式和通信开销；2) 研究典型LLM中的可预测流量模式；3) 评估各种因素对GPU利用率和有效带宽的影响；4) 开发通信开销的解析公式并进行验证；5) 基于该公式开发配置调优工具ConfigTuner。

Result: 1) 提出的通信开销解析公式与经验数据高度吻合；2) ConfigTuner优化的训练配置相比Megatron-LM实现了最高1.36倍的吞吐量提升；3) 相比Alpa，ConfigTuner能生成相同的配置建议，同时显著降低了搜索复杂度。

Conclusion: 本文系统化地研究了LLM分布式训练中的通信可预测性，提出的解析公式能准确估计通信开销，基于此开发的ConfigTuner工具能有效优化训练配置，显著提升训练性能并降低搜索复杂度。

Abstract: Effective communication is essential in distributed training, with predictability being one of its most significant characteristics. However, existing studies primarily focus on exploiting predictability through online profiling for runtime optimization, without a systematic understanding of it. In this work, we aim to systematically formulate communication predictability in distributed training, particularly in Large Language Models (LLMs) that utilize hybrid parallelism. Our analysis focuses on both traffic patterns and communication overhead. Specifically, we investigate predictable traffic patterns in typical LLMs and evaluate how various factors influence GPU utilization and effective bandwidth (two critical variables affecting communication overhead). Furthermore, we develop an analytical formulation to estimate communication overhead in LLM training, which is validated with high accuracy against empirical data. Leveraging this formulation, we propose a configuration tuning tool, ConfigTuner, to optimize training performance. Compared to Megatron-LM, the training configurations optimized by ConfigTuner demonstrate up to a 1.36$\times$ increase in throughput. Compared to Alpa, ConfigTuner generates the same configuration suggestion while significantly reducing the search complexity.

</details>


### [11] [Sidelink Positioning: Standardization Advancements, Challenges and Opportunities](https://arxiv.org/abs/2512.24803)
*Yuan Gao,Guangjin Pan,Zhiyong Zhong,Zhengyu Jin,Yichen Hu,Yifei Jin,Shugong Xu*

Main category: cs.NI

TL;DR: 本文全面总结了3GPP Rel-18侧链路定位标准化进展，评估了不同定位方法在非理想因素下的性能，并讨论了Rel-19的研究方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着蜂窝网络在V2X、公共安全、工业物联网等需要精确定位信息的垂直行业中的集成，定位已成为未来无线网络的关键组成部分。虽然蜂窝定位通过更宽频谱、多天线和灵活架构实现了不断提高的定位精度，但在UE与BS距离较大或NLoS场景下仍面临性能下降问题。3GPP Rel-18提出标准化侧链路定位，通过UE间的直接定位信令扩展定位覆盖范围。

Method: 本文采用标准化文献综述和性能评估相结合的方法：1）全面总结3GPP Rel-18侧链路定位标准化进展，包括网络架构、定位类型和性能要求；2）评估不同定位方法在各种非理想因素下的能力；3）基于3GPP Rel-19演进讨论可能的研究方向和挑战。

Result: 文章系统梳理了3GPP侧链路定位标准化的最新进展，深入分析了不同定位方法在非理想条件下的性能表现，揭示了侧链路定位在扩展覆盖范围方面的潜力，同时指出了实现3GPP定义定位精度所需的频谱资源问题。

Conclusion: 侧链路定位为扩展蜂窝网络定位覆盖提供了独特机会，但实现3GPP定义的定位精度所需的频谱资源仍存在争议。文章为3GPP Rel-19及未来的侧链路定位技术演进提供了重要参考，指出了需要进一步研究的关键方向和挑战。

Abstract: With the integration of cellular networks in vertical industries that demand precise location information, such as vehicle-to-everything (V2X), public safety, and Industrial Internet of Things (IIoT), positioning has become an imperative component for future wireless networks. By exploiting a wider spectrum, multiple antennas and flexible architectures, cellular positioning achieves ever-increasing positioning accuracy. Still, it faces fundamental performance degradation when the distance between user equipment (UE) and the base station (BS) is large or in non-line-of-sight (NLoS) scenarios. To this end, the 3rd generation partnership project (3GPP) Rel-18 proposes to standardize sidelink (SL) positioning, which provides unique opportunities to extend the positioning coverage via direct positioning signaling between UEs. Despite the standardization advancements, the capability of SL positioning is controversial, especially how much spectrum is required to achieve the positioning accuracy defined in 3GPP. To this end, this article summarizes the latest standardization advancements of 3GPP on SL positioning comprehensively, covering a) network architecture; b) positioning types; and c) performance requirements. The capability of SL positioning using various positioning methods under different imperfect factors is evaluated and discussed in-depth. Finally, according to the evolution of SL in 3GPP Rel-19, we discuss the possible research directions and challenges of SL positioning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 论文提出DDFT评估框架，测量语言模型在语义压缩和对抗性伪造下的认知稳健性，发现模型规模与稳健性无关，而错误检测能力是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估（如MMLU、TruthfulQA）只能测量理想条件下的知识，无法评估模型在现实压力下的认知稳健性。这些静态基准无法区分模型是缺乏知识，还是在信息退化或对抗性攻击时验证机制崩溃。

Method: 提出Drill-Down and Fabricate Test (DDFT)协议，测量认知稳健性：模型在渐进语义压缩和对抗性伪造下保持事实准确性的能力。采用两系统认知模型：语义系统生成流畅文本，认知验证器验证事实准确性。评估了9个前沿模型在8个知识领域和5个压缩级别（共1800次轮级评估）。

Result: 认知稳健性与传统设计范式正交：参数数量（r=0.083, p=0.832）和架构类型（r=0.153, p=0.695）均不显著预测稳健性，表明其源于训练方法和验证机制。错误检测能力强烈预测整体稳健性（rho=-0.817, p=0.007），是关键瓶颈。旗舰模型尽管规模大但表现出脆弱性，而较小模型可实现稳健性能。

Conclusion: DDFT框架为关键应用部署前评估认知稳健性提供了理论基础和实用工具。模型规模与可靠性关系的传统假设受到挑战，认知稳健性源于训练方法和验证机制，而非简单规模扩展。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [13] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 提出BatteryAgent框架，结合物理知识特征与大语言模型推理能力，实现锂离子电池故障的智能诊断，提升可解释性并提供根因分析与维护建议。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法的"黑盒"特性限制了可解释性，且受限于二元分类范式，难以提供根因分析和维护建议，需要更智能的诊断框架。

Method: 提出三层框架：1) 物理感知层提取10个基于电化学原理的特征；2) 检测与归因层使用梯度提升决策树和SHAP量化特征贡献；3) 推理与诊断层利用LLM构建"数值-语义"桥梁，结合SHAP归因和机理知识库生成综合报告。

Result: BatteryAgent有效纠正边界样本的误分类，AUROC达到0.986，显著优于现有方法，并将传统二元检测扩展到多类型可解释诊断。

Conclusion: 该框架为电池安全管理提供了从"被动检测"到"智能诊断"的新范式转变，实现了高精度、可解释的故障诊断。

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [14] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE是一个自演化的LLM智能体框架，通过持续学习和自我反思的元技能，使智能体能够掌握复杂外部工具并编码知识，在科学任务上达到93.3%的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性。需要从"LLM+工具使用"向"LLM+技能获取"转变。

Method: CASCADE框架通过两种元技能实现：1）持续学习（通过网页搜索和代码提取）；2）自我反思（通过内省和知识图谱探索）。框架还包括人机协作和记忆整合机制。

Result: 在SciSkillBench基准测试（116个材料科学和化学研究任务）上，使用GPT-5的CASCADE达到93.3%成功率，相比无演化机制的35.4%有显著提升。展示了在计算分析、自主实验室实验和论文选择性复现等实际应用。

Conclusion: CASCADE通过积累可执行技能并能在智能体和科学家之间共享，推动了可扩展的AI辅助科学研究，代表了向"LLM+技能获取"范式的重要转变。

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [15] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy框架结合大语言模型与答案集编程，通过LLM将医学文献转化为ASP代码，结合患者数据进行疾病诊断，实现可解释的预测系统。


<details>
  <summary>Details</summary>
Motivation: 准确的疾病预测对于及时干预、有效治疗和减少医疗并发症至关重要。虽然符号AI已在医疗保健中得到应用，但由于构建高质量知识库需要大量努力，其采用仍然有限。

Method: McCoy框架结合大语言模型与答案集编程：1）使用LLM将医学文献翻译成ASP代码；2）将生成的ASP代码与患者数据结合；3）使用ASP求解器处理以得出最终诊断。

Result: 初步结果显示，McCoy在小规模疾病诊断任务上表现出色，提供了一个强大且可解释的预测框架。

Conclusion: McCoy通过结合LLM和ASP的优势，克服了传统符号AI在医疗领域应用中的障碍，为可解释的疾病预测提供了有前景的解决方案。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [16] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态查询理解和个性化检索。


<details>
  <summary>Details</summary>
Motivation: 传统搜索系统受限于静态用户画像和单一检索流程，难以建模用户动态、多维的信息需求。需要能够捕捉人类信息寻求行为的复杂性、流动性和上下文敏感性的新一代搜索系统。

Method: 1. 定义基于角色、专业知识、任务上下文和领域的角色空间；2. 引入角色协调器动态解释查询并激活最相关的专业智能体；3. 每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和上下文感知推理模块；4. 通过共享内存库、迭代辩论和中继式知识转移等结构化通信协议促进智能体协作。

Result: 框架产生了关于协调效率、个性化质量和认知负载分布的可测试预测，同时包含用于持续角色细化的自适应学习机制。通过分布式智能体行为在最小协调规则下涌现出个性化特性。

Conclusion: SPARK通过整合细粒度智能体专业化与协作检索，为能够捕捉人类信息寻求行为复杂性、流动性和上下文敏感性的下一代搜索系统提供了见解。

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [17] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD是一个无需标注数据集、通过自动化调试进行提示优化的框架，在冷启动场景下显著提升LLM代理性能


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法依赖大量标注数据集，但在实际软件工程中，冷启动阶段只有混乱的生产日志和不断变化的故障模式，缺乏精炼数据集

Method: 采用多智能体架构：分析器进行根因分析，优化器进行模式聚合，教练进行策略集成，将非结构化故障日志转换为结构化决策树协议

Result: 在学术基准和生产知识管理引擎上评估，仅3次自动迭代就使成功率提升5.6%（73.6%到79.2%），搜索准确率提升3.8%；在零售领域复杂推理任务中性能提升约19%

Conclusion: 模仿人类工程循环的故障分析和修补方法，为部署可靠LLM代理提供了资源密集型RL训练之外的可行、数据高效的替代方案

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [18] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化代理框架，通过"计划-执行-总结"认知范式将LLM集成到进化搜索中，显著提高解决方案质量并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法缺乏结构化推理，导致在高维代码空间中过早收敛和探索效率低下，阻碍了从静态LLM到自改进代理的过渡。

Method: 结合LLM的"计划-执行-总结"认知范式，采用混合进化记忆系统（多岛模型+MAP-Elites+自适应玻尔兹曼选择），平衡探索与利用，保持行为多样性。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow比OpenEvolve、ShinkaEvolve等基线方法进化效率提升高达60%，发现更优解决方案。

Conclusion: LoongFlow标志着自主科学发现的重要进展，能够以更低计算开销生成专家级解决方案，为自进化代理系统开辟新方向。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [19] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec是一个结合大语言模型和Soar认知架构的推荐系统，通过感知-认知-行动循环和在线学习机制，解决LLM的黑盒性、幻觉问题和知识获取困难，提升推荐准确性、可解释性和长尾问题处理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐系统中表现出理解用户偏好的能力，但存在黑盒特性、知识幻觉和在线学习能力有限等问题，影响可信度和适应性。而认知架构如Soar具有结构化、可解释的推理过程，但知识获取困难。需要结合两者优势解决互补挑战。

Method: 提出CogRec认知推荐代理，将LLM与Soar认知架构结合：1) 使用Soar作为核心符号推理引擎；2) 利用LLM进行知识初始化，填充工作记忆中的产生式规则；3) 采用感知-认知-行动循环；4) 遇到僵局时动态查询LLM获取推理解决方案；5) 通过Soar的分块机制将解决方案转化为新的符号产生式规则，实现稳健的在线学习。

Result: 在三个公共数据集上的广泛评估表明，CogRec在推荐准确性、可解释性和解决长尾问题方面表现出显著优势。

Conclusion: CogRec成功结合了LLM和Soar认知架构的优势，通过在线学习机制持续进化知识库，为推荐提供高度可解释的理由，解决了LLM的黑盒性、幻觉和在线学习能力有限等问题。

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [20] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 提出一种无需训练、基于图结构的交互推理方法，用于解决ARC-AGI-3基准测试中的游戏式任务，通过视觉帧处理和系统化状态空间探索显著优于当前最先进的LLM。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI-3基准测试包含需要通过有限交互推断任务机制的游戏式任务，现有最先进的LLM无法可靠解决这些任务。需要一种能够形成假设、测试假设并跟踪已发现机制的方法。

Method: 结合视觉帧处理和系统化状态空间探索的图结构表示方法：1) 将视觉帧分割为有意义组件；2) 基于视觉显著性优先选择动作；3) 维护探索状态和转换的有向图；4) 通过跟踪访问状态和测试动作，优先选择到达未测试状态-动作对的最短路径。

Result: 在ARC-AGI-3预览挑战中，该方法解决了52个关卡中的中位数30个，在私有排行榜上排名第3，显著优于前沿的LLM智能体。

Conclusion: 即使没有学习，显式的图结构探索也可以作为交互推理的强大基线，强调了在稀疏反馈环境中系统化状态跟踪和动作优先级的重要性，这些环境正是当前LLM难以捕捉任务动态的地方。

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [21] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP是一个开源的科学上下文协议，通过标准化科学资源描述和调用，以及提供实验生命周期管理架构，构建自主科学代理的全球网络，加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 当前科学发现面临资源分散、平台异构、集成成本高、可重复性差等挑战。需要建立标准化的协议来连接不同的科学工具、模型、数据集和物理仪器，实现AI代理与人类研究者的大规模协作。

Method: SCP基于两大支柱：1) 统一资源集成：提供描述和调用科学资源的通用规范；2) 编排的实验生命周期管理：包含中心化SCP Hub和联邦SCP Server的安全服务架构，管理实验注册、规划、执行、监控和归档全过程。

Result: 基于SCP构建的科学发现平台已集成超过1,600个工具资源。在不同用例中，SCP促进了异构AI系统与人类研究者之间安全的大规模协作，显著降低了集成开销并增强了可重复性。

Conclusion: SCP通过在协议层面标准化科学上下文和工具编排，为可扩展、多机构、代理驱动的科学建立了必要的基础设施，加速了科学发现进程。

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [22] [Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem](https://arxiv.org/abs/2512.24251)
*Pengfu Wan,Jiawei Chen,Gangyan Xu*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度强化学习的方法来解决车队规模与混合车辆路径问题，该方法能够在几秒内生成近似最优解，特别适用于大规模和时间受限的场景。


<details>
  <summary>Details</summary>
Motivation: FSMVRP问题在实际应用中非常重要（如短期车辆租赁和按需物流），但传统方法在复杂性和计算时间上面临挑战，特别是在大规模和时间受限的环境中。

Method: 将问题建模为马尔可夫决策过程，开发了名为FRIPN的新型策略网络，该网络无缝集成了车队组成和路径决策，并设计了专门的输入嵌入（包括剩余图嵌入）来支持有效的车辆使用决策。

Result: 在随机生成实例和基准数据集上的实验表明，该方法在计算效率和可扩展性方面具有显著优势，特别在大规模和时间受限的场景中表现优异。

Conclusion: 该方法展示了深度强化学习在解决复杂车辆路径问题中的实际应用潜力，并为将DRL技术扩展到其他VRP变体提供了有价值的启示。

Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.

</details>


### [23] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: RSA是一种风险感知的分步对齐方法，通过嵌套风险度量在策略优化中显式考虑风险，以缓解模型偏离参考策略的风险并抑制低概率高危害行为。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法（如Safe RLHF和SACPO）通常基于风险中性范式，不足以应对参考策略偏离带来的风险，且对罕见但可能灾难性的有害行为鲁棒性有限。

Method: 提出风险感知分步对齐（RSA），将安全对齐建模为令牌级风险感知约束策略优化问题，通过基于嵌套风险度量的分步对齐过程求解，实现令牌级策略更新。

Result: 实验结果表明，该方法在保持高帮助性的同时确保强安全性，并显著抑制尾部风险（低概率高危害的不安全响应）。

Conclusion: RSA通过显式纳入风险感知，有效解决了现有安全对齐方法的局限性，在风险控制方面表现出色，为语言模型的安全对齐提供了新思路。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [24] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: 提出一种无需梯度更新或额外训练、通过后验引导信念细化的测试时自适应智能体，用于部分可观测环境下的LLM智能体推理


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在部分可观测环境下难以准确对齐潜在世界状态，传统方法如提示增强或检索增强的LLMs存在集成开销大、效果有限的问题

Method: 1) 维护外部结构化环境状态信念；2) 通过动作条件观察迭代更新信念；3) 使用轻量级LLM代理估计信息增益；4) 通过最大化信念空间信息增益选择动作；5) 设计量化后验信念与真实环境配置一致性的新奖励函数

Result: 实验表明该方法在潜在世界状态对齐方面优于推理时扩展基线（如提示增强或检索增强的LLMs），且集成开销显著降低

Conclusion: 提出的测试时自适应智能体通过后验引导信念细化，能够在部分可观测环境下有效对齐潜在世界状态，相比传统方法具有更低集成开销和更好性能

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [25] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 本文系统研究了JEPA-WM模型家族，通过分析架构、训练目标和规划算法等关键组件，提出了优于现有基线的方法，在导航和操作任务上表现更佳。


<details>
  <summary>Details</summary>
Motivation: AI领域长期存在开发能够解决广泛物理任务并泛化到新环境的智能体的挑战。现有方法在输入空间进行规划，而基于世界模型表示空间的规划方法有望通过抽象无关细节实现更高效的规划，但这类方法的技术选择尚未得到系统研究。

Method: 将这类方法统一为JEPA-WM模型家族，系统研究模型架构、训练目标和规划算法等关键组件。在模拟环境和真实机器人数据上进行实验，分析各组件对规划成功率的影响。

Result: 提出的模型在导航和操作任务上优于两个现有基线（DINO-WM和V-JEPA-2-AC），验证了JEPA-WM方法的有效性。

Conclusion: JEPA-WM模型家族通过系统优化关键组件，能够实现更高效的规划，为开发能够泛化到新任务的AI智能体提供了有前景的方向。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [26] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: 提出交互式评估框架分析基础模型在符号地图环境中的空间理解能力，发现记忆表示对空间推理性能影响最大，而单纯模型缩放无法持续提升空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型空间能力评估多基于静态地图输入或文本查询，忽略了空间理解的交互性和经验驱动特性，需要新的评估框架来深入分析模型在动态地图环境中的探索、记忆和推理能力。

Method: 提出交互式评估框架，让智能体在部分可观测的网格地图中增量探索（包含道路、交叉口和兴趣点），仅接收局部观测，然后通过六类空间任务评估空间理解能力。系统变化探索策略、记忆表示和推理方案，分析不同组件功能。

Result: 探索主要影响经验获取但对最终推理准确性影响有限；记忆表示在整合空间经验中起核心作用，结构化记忆（特别是序列和基于图的表示）显著提升路径规划等结构密集型任务性能；推理方案影响存储空间知识的利用方式；空间推理性能在模型版本和规模达到一定阈值后趋于饱和。

Conclusion: 提升地图空间理解能力需要针对空间表示和推理的专门机制，而非单纯依赖模型缩放。结构化记忆表示和高级推理提示对空间任务性能有重要影响。

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [27] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 该研究评估了三种主流大语言模型（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3）在密苏里大学数学竞赛问题上的表现，发现DeepSeek-V3在所有数学领域表现最佳，但所有模型在几何问题上表现均较弱，且错误模式各有特点。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多使用相同的数据集评估大语言模型的数学推理能力，这限制了研究结果的普适性，且可能无法全面捕捉数学任务中的多样化挑战。本研究旨在通过分析LLMs在代表性不足的数学竞赛问题上的表现，更全面地评估其数学推理能力。

Method: 研究使用密苏里大学数学竞赛中的微积分、解析几何和离散数学问题，对GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3三种LLMs进行测试。将模型回答与已知正确答案对比以确定准确性，并分析模型的推理过程以探索不同问题类型和模型间的错误模式。

Result: DeepSeek-V3在微积分、解析几何和离散数学三个类别中表现最佳，无论是推理过程还是最终答案正确率都最好。所有三种LLMs在几何问题上表现都显著较弱。DeepSeek-V3的主要错误是计算和逻辑错误，GPT-4o-mini经常出现逻辑和方法相关的错误，而Gemini则倾向于不完整的推理和仓促得出结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估LLMs能够提供对其独特错误模式的更深入洞察，并突显了在结构化推理方面，特别是在几何领域，仍然存在的挑战。这种评估方法有助于更全面地理解LLMs的数学推理能力限制。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [28] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 论文提出两阶段方法提升大语言模型的空间推理能力：先通过监督微调学习基本空间变换，再通过GRPO框架训练LoRA适配器进行多步规划，在ASCII艺术环境中验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在通用语言能力上表现优异，但在空间变换和多步规划等结构化环境中的空间推理任务上仍然存在困难，这限制了其在导航和规划等应用中的表现。

Method: 采用两阶段方法：1) 对基本空间变换（旋转、平移、缩放）进行监督微调，使模型掌握基础空间物理知识；2) 冻结物理感知模型，在GRPO框架内训练轻量级LoRA适配器，以闭环方式学习将这些基础模块组合用于多步规划。为此合成了ASCII艺术数据集并构建了相应的强化学习环境。

Result: 该方法在动态环境（有显式状态更新）和静态环境（模型需依赖内部状态）中均优于基线模型（通用骨干模型、物理感知模型和端到端RL模型）。此外，该方法收敛更快，训练更稳定，并且注意力模式分析表明微调确实改善了空间理解能力。

Conclusion: 通过将空间推理分解为原子构建块及其组合的两阶段方法，有效提升了大语言模型在结构化环境中的空间推理能力，为导航和规划等应用提供了更可靠的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [29] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: MCPAgentBench：基于真实MCP定义构建的基准，用于评估LLM代理的工具使用能力，包含真实任务、模拟工具和动态沙箱环境


<details>
  <summary>Details</summary>
Motivation: 当前MCP评估集存在依赖外部MCP服务和缺乏难度感知的问题，需要更好的基准来评估LLM代理的工具使用能力

Method: 构建包含真实任务和模拟MCP工具的数据集，采用动态沙箱环境提供包含干扰项的工具列表，引入综合指标衡量任务完成率和执行效率

Result: 在多种主流大语言模型上的实验显示，在处理复杂多步工具调用时存在显著性能差异

Conclusion: MCPAgentBench为评估LLM代理的工具使用能力提供了有效基准，代码已开源

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [30] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: 提出递归语言模型（RLMs），通过让LLM递归处理长提示，突破上下文窗口限制，显著提升长文本处理性能


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型处理超长提示的局限性，当前模型受限于固定上下文窗口，无法有效处理远超窗口长度的输入

Method: 提出递归语言模型（RLMs）推理策略，将长提示视为外部环境，让LLM以编程方式检查、分解并递归调用自身处理提示片段

Result: RLMs能处理比模型上下文窗口长两个数量级的输入，在四个不同长上下文任务中显著优于基础LLM和常见长上下文框架，且查询成本相当或更低

Conclusion: RLMs为LLM处理任意长度提示提供了有效的推理时扩展方法，在保持成本效益的同时显著提升长文本处理能力

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [31] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 提出一个强化学习增强的LLM多智能体协作框架，采用Dec-POMDP建模和CTDE训练，在协作写作和编程任务上显著提升效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在单任务上表现良好，但在多智能体协作场景中缺乏全局优化能力，难以协调多个智能体实现高效合作。

Method: 1. 将协作建模为去中心化部分可观测马尔可夫决策过程（Dec-POMDP）
2. 采用集中训练分散执行（CTDE）框架
3. 提出组相对策略优化（GRPO）算法，在训练时利用全局信号联合优化智能体策略
4. 设计简化的联合奖励函数，平衡任务质量、速度和协调成本

Result: 1. 任务处理速度比单智能体基线提升3倍
2. 协作写作中达到98.7%的结构/风格一致性
3. 编程任务中达到74.6%的测试通过率
4. 在协作写作和编程基准测试中持续优于现有的多智能体LLM基线

Conclusion: 该框架为复杂工作流中的可靠协作提供了实用路径，显著提升了多智能体LLM在协作任务中的全局性能和协调能力。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [32] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 提出基于群体审议的多智能体对话模型，通过三层角色架构（生成、验证、整合）和自博弈机制，提升复杂推理任务的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在复杂推理任务中存在局限性，需要更有效的多智能体协作方法来提高推理准确性和逻辑一致性。

Method: 采用三层角色架构：意见生成代理产生多样化推理视角，证据验证代理检索外部知识并量化事实支持，一致性仲裁代理整合逻辑一致的结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计结合事实一致性和逻辑连贯性的复合奖励函数，应用改进的近端策略优化进行协作训练。

Result: 在HotpotQA上多跳推理准确率提升16.8%，在2WikiMultihopQA上提升14.3%，在MeetingBank上提升19.2%，一致性提升21.5%。相比主流多智能体方法具有更高的推理效率。

Conclusion: 该模型为复杂推理任务提供了有效且稳定的解决方案，通过群体审议和多智能体协作显著提升了推理性能和一致性。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [33] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: Youtu-Agent是一个模块化LLM代理框架，支持自动化生成和持续进化，通过解耦配置和混合策略优化解决现有框架配置成本高和静态能力问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理框架面临两大挑战：1) 配置成本高，构建高质量代理需要大量手动工具集成和提示工程；2) 静态能力，已部署代理难以适应动态环境，需要昂贵的微调。

Method: 提出结构化配置系统，解耦执行环境、工具包和上下文管理；引入两种生成范式：Workflow模式用于标准任务，Meta-Agent模式用于复杂需求；建立混合策略优化系统：Agent Practice模块实现上下文优化，Agent RL模块集成分布式训练框架进行强化学习。

Result: 在WebWalkerQA(71.47%)和GAIA(72.8%)上达到SOTA性能；自动化生成管道工具合成成功率超过81%；Practice模块在AIME 2024/2025上分别提升2.7%和5.4%；Agent RL训练在7B LLMs上实现40%加速，数学和通用/多跳QA基准上编码/推理和搜索能力分别提升35%和21%。

Conclusion: Youtu-Agent通过模块化设计和自动化生成解决了LLM代理的高配置成本问题，通过混合优化策略实现了代理的持续进化能力，为构建自适应智能代理提供了有效框架。

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [34] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 提出多模态跨域混合融合模型，通过双重解耦和跨域混合融合策略，解决故障诊断中未见工况下的泛化问题


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法在未见工况下性能显著下降，域适应方法依赖目标域样本，且大多依赖单模态信号，忽略了多模态信息的互补性

Method: 提出双重解耦框架分离模态不变/特定特征和域不变/特定表示；设计跨域混合融合策略随机混合跨域模态信息；引入三模态融合机制自适应集成多模态异构信息

Result: 在感应电机故障诊断实验中，无论是未见恒定工况还是时变工况，该方法均优于先进方法，消融研究验证了各组件和多模态融合的有效性

Conclusion: 该方法通过多模态融合和跨域泛化技术，显著提升了故障诊断模型在未见工况下的性能，为实际工业应用提供了有效解决方案

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [35] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 该研究提出了一个可解释的家庭物品摆放偏好模型，包含四个维度：空间实用性、习惯便利性、语义连贯性和常识适当性，并通过问卷验证和MCTS规划器展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统依赖从人类演示中推断的潜在偏好模型，虽然预测有效但缺乏可解释性，无法理解指导人类决策的可解释因素。

Method: 1) 提出四个可解释的偏好维度：空间实用性、习惯便利性、语义连贯性、常识适当性；2) 设计并验证自报告问卷（63名参与者在线研究）；3) 将偏好维度整合到蒙特卡洛树搜索（MCTS）规划器中。

Result: 1) 问卷研究证实了四个心理维度的区分性和解释力；2) 基于参与者偏好的MCTS规划器能够生成与参与者安排高度一致的合理物品摆放方案。

Conclusion: 该研究贡献了一个紧凑、可解释的物品摆放偏好模型，并展示了如何将其操作化用于机器人规划，为理解人类物品摆放决策提供了新视角。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [36] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ是一个混合模型，通过可解释的语义特征桥接基础模型和统计建模，在房价预测和电影推荐任务中显著优于纯基础模型方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然拥有广泛的领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式。需要一种方法能够结合基础模型的语义理解能力和统计建模的数据驱动模式发现能力。

Method: 通过迭代过程发现语义特征描述，该过程基于统计建模误差对比项目组，而非仅依赖基础模型的领域理解。采用广义EM算法联合优化语义特征描述符和统计模型参数，将冻结的基础模型对基于发现特征的项目的分类判断视为潜在二元特征的噪声观测。

Result: 在房价预测中，使用多模态列表数据发现的语义特征实现了12%的中位数相对误差，显著优于依赖LLM通用领域知识的GPT-5基线（38%误差）。在Netflix电影嵌入预测中，仅从语义描述就能达到0.59余弦相似度，相当于传统协同过滤需要约4000用户评分的性能。

Conclusion: GenZ成功结合了基础模型的语义理解能力和统计建模的模式发现能力，发现了数据集特定的模式（如预测本地房地产市场的建筑细节、预测用户偏好的系列成员关系），这些模式与模型单独基于领域知识得出的结论不同。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [37] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 提出基于约束模板的方法，从养老院管理者访谈中提取设施特定的排班约束条件，避免异常约束，用于生成护工排班表


<details>
  <summary>Details</summary>
Motivation: 养老机构的排班条件因设施而异，需要通过与制定排班的管理者访谈来设计设施特定的约束条件，但现有约束提取技术难以处理这种情况

Method: 使用约束模板提取各种组件的组合（如连续工作班次模式、员工组合），通过改变天数、员工数量和提取焦点（模式或频率）来提取多样约束，并包含排除异常约束的机制

Result: 实验表明，该方法成功创建了满足所有硬约束的排班表，并通过避免提取异常约束减少了软约束的违反次数

Conclusion: 提出的约束模板方法能够有效提取养老机构特定的排班约束，结合约束规划求解器可生成符合实际需求的护工排班表

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [38] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: ALE是一个端到端的智能体学习生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具，并发布了基于此训练的ROME智能体模型。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏系统化的智能体开发基础设施，需要构建一个端到端的生态系统来优化智能体LLM的生产流程。

Method: 1) ALE三大组件：ROLL用于权重优化，ROCK用于轨迹生成环境管理，iFlow CLI用于上下文工程；2) 数据合成协议生成复杂行为；3) 提出IPA算法，基于语义交互块而非单个token进行信用分配，提升长时程训练稳定性。

Result: 发布了ROME智能体模型，在超过100万条轨迹上训练，在SWE-bench Verified和Terminal Bench等基准测试中表现优异，证明了ALE基础设施的有效性。

Conclusion: ALE提供了一个系统化的智能体学习生态系统，通过优化的生产流程和创新的训练算法，能够有效开发高性能的智能体模型。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [39] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 开发了一个半自动数据标注流水线，用于创建波兰驾驶场景的多模态数据集，通过人机协作降低标注成本和时间


<details>
  <summary>Details</summary>
Motivation: DARTS项目需要创建大规模波兰驾驶场景多模态数据集，但手动标注异构数据成本高、耗时长，需要高效解决方案

Method: 采用人在回路方法，结合AI与人工专业知识，包括自动生成初始标注、迭代模型重训练、数据匿名化和领域适应技术，核心使用3D目标检测算法

Result: 开发出的工具和方法显著节省时间，确保跨不同传感器模态的一致高质量标注，加速了DARTS项目中标准化格式大型标注数据集的准备

Conclusion: 该半自动标注流水线有效支持DARTS项目，为波兰自动驾驶研究提供了技术基础，通过人机协作实现了高效高质量的数据标注

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [40] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 迭代部署LLM并通过用户数据筛选进行微调，可以显著改变模型特性，实现类似强化学习的训练效果，但存在AI安全风险。


<details>
  <summary>Details</summary>
Motivation: 探索通过迭代部署和用户数据筛选来改进大型语言模型的方法，研究这种机制如何影响模型特性，并分析其与强化学习的理论联系。

Method: 采用迭代部署机制：每个模型部署后，用户从模型输出中精心筛选数据，用于微调下一个模型版本。在多个规划领域测试该方法，并进行理论分析。

Result: 模型规划能力显著提升，后续模型展现出涌现的泛化能力，能够发现比初始模型长得多的规划方案。理论分析表明迭代部署实现了类似强化学习的训练效果。

Conclusion: 迭代部署机制可作为显式强化学习的替代训练方案，但存在AI安全风险，因为隐含的奖励函数未明确定义，可能对未来模型部署产生意外影响。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [41] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent是一个专门用于时空理解的智能体大语言模型，通过工具交互解决复杂时空任务，同时保持通用能力


<details>
  <summary>Details</summary>
Motivation: 需要开发能够解决复杂时空任务（如受限兴趣点发现和行程规划）的智能体模型，这些任务需要与多种工具交互并进行多步推理

Method: 1) 构建支持10+领域特定工具的稳定工具环境；2) 分层数据筛选框架，以1:10,000的比例筛选高质量查询；3) 级联训练方法：种子SFT阶段评估查询难度，第二SFT阶段微调高确定性查询，最终RL阶段利用低确定性数据

Result: STAgent在TravelBench上表现出色，同时在广泛通用基准测试中保持其通用能力，证明了所提智能体模型的有效性

Conclusion: STAgent通过专门的工具环境、高质量数据筛选和级联训练方法，成功创建了既能解决复杂时空任务又保持通用能力的智能体模型

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>


### [42] [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)
*Tianzhi He,Farrokh Jazizadeh*

Main category: cs.AI

TL;DR: 提出基于大语言模型的建筑能源管理系统AI代理框架，通过自然语言交互实现智能建筑能源管理，在设备控制、记忆任务等方面表现良好，但成本估算等复杂任务仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有能源管理系统存在局限性，需要更智能、上下文感知的解决方案。利用LLM的自主数据分析能力，通过自然语言交互实现更人性化的建筑能源管理。

Method: 提出包含感知、中央控制和行动三个模块的概念框架，形成闭环反馈系统。使用120个用户查询在四个真实住宅能源数据集上评估原型性能，采用延迟、功能、能力、准确性和成本效益等指标，并使用ANOVA测试验证框架通用性。

Result: 原型在设备控制准确率86%、记忆相关任务97%、调度自动化74%、能源分析77%方面表现良好，但复杂成本估算任务准确率仅49%。框架通用性得到验证，揭示了响应准确性与计算效率之间的权衡。

Conclusion: 该研究为基于LLM的BEMS AI代理评估提供了标准化方法，展示了自然语言交互在智能建筑能源管理中的潜力，同时指出了复杂任务性能改进和计算效率优化的未来研究方向。

Abstract: This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Hierarchical Quasi-cyclic Codes from Reed-Solomon and Polynomial Evaluation Codes](https://arxiv.org/abs/2512.23872)
*Emily McMillon,Kathryn Haymaker*

Main category: cs.IT

TL;DR: 首次提出代数构造的分层准循环码，基于Reed-Solomon码和Kautz-Singleton叠加码构造，层次数和指数由域大小决定，部分码达到已知最佳最小距离。


<details>
  <summary>Details</summary>
Motivation: 现有相关码的文献主要基于仿真方法，缺乏代数分析。本文旨在通过代数方法构造分层准循环码，并提供参数的新界限。

Method: 使用Kautz和Singleton（1964）的叠加码构造，从Reed-Solomon码出发代数构造分层准循环码。特别地，从维度k=2的RS码出发，得到围长为6的Tanner图。

Result: 证明了层次数和指数由域大小决定；提供了显式码参数和性质；给出了秩和距离等参数的界限；部分二进制码达到已知最佳最小距离；提供了小参数码表。

Conclusion: 首次代数构造了分层准循环码，相比现有仿真方法，提供了代数分析框架和新参数界限，连接了相关构造但具有创新性代数方法。

Abstract: We introduce the first example of algebraically constructed hierarchical quasi-cyclic codes. These codes are built from Reed-Solomon codes using a 1964 construction of superimposed codes by Kautz and Singleton. We show both the number of levels in the hierarchy and the index of these Reed-Solomon derived codes are determined by the field size. We show that this property also holds for certain additional classes of polynomial evaluation codes.
  We provide explicit code parameters and properties as well as some additional bounds on parameters such as rank and distance. In particular, starting with Reed-Solomon codes of dimension $k=2$ yields hierarchical quasi-cyclic codes with Tanner graphs of girth 6.
  We present a table of small code parameters and note that some of these codes meet the best known minimum distance for binary codes, with the additional hierarchical quasi-cyclic structure. We draw connections to similar constructions in the literature, but importantly, while existing literature on related codes is largely simulation-based, we present a novel algebraic approach to determining new bounds on parameters of these codes.

</details>


### [44] [Continuous Angular Power Spectrum Recovery From Channel Covariance via Chebyshev Polynomials](https://arxiv.org/abs/2512.24039)
*Shengsong Luo,Ruilin Wu,Chongbin Xu,Junjie Ma,Xiaojun Yuan,Xin Wang*

Main category: cs.IT

TL;DR: 提出基于切比雪夫多项式展开的框架，从信道协方差中恢复连续角度功率谱，将病态反演问题转化为有限维线性回归，并引入非负性和平滑性约束。


<details>
  <summary>Details</summary>
Motivation: 在多天线系统中，从信道协方差恢复连续角度功率谱是一个病态反演问题。现有方法在处理非负性和平滑性约束方面存在不足，需要更有效的数学框架来准确重建APS并实现频分双工场景下的协方差预测。

Method: 利用切比雪夫多项式在变换域中的正交性，推导协方差的精确级数表示，将APS反演问题转化为有限维线性回归。通过截断控制近似误差，引入非负APS的半正定表征和基于导数的正则化器来促进平滑变化同时保留聚类过渡。

Result: 仿真结果表明，所提出的切比雪夫框架能够准确重建APS，并在频分双工场景下实现从上行链路测量可靠预测下行链路协方差。误差随角度平滑度增加而快速衰减。

Conclusion: 在切比雪夫域中联合利用平滑性和非负性为多天线系统中的协方差域处理提供了有效工具，能够解决APS反演的病态问题并实现准确的协方差预测。

Abstract: This paper proposes a Chebyshev polynomial expansion framework for the recovery of a continuous angular power spectrum (APS) from channel covariance. By exploiting the orthogonality of Chebyshev polynomials in a transformed domain, we derive an exact series representation of the covariance and reformulate the inherently ill-posed APS inversion as a finite-dimensional linear regression problem via truncation. The associated approximation error is directly controlled by the tail of the APS's Chebyshev series and decays rapidly with increasing angular smoothness. Building on this representation, we derive an exact semidefinite characterization of nonnegative APS and introduce a derivative-based regularizer that promotes smoothly varying APS profiles while preserving transitions of clusters. Simulation results show that the proposed Chebyshev-based framework yields accurate APS reconstruction, and enables reliable downlink (DL) covariance prediction from uplink (UL) measurements in a frequency division duplex (FDD) setting. These findings indicate that jointly exploiting smoothness and nonnegativity in a Chebyshev domain provides an effective tool for covariance-domain processing in multi-antenna systems.

</details>


### [45] [Random Multiplexing](https://arxiv.org/abs/2512.24087)
*Lei Liu,Yuhao Chi,Shunqi Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 提出随机复用技术，解耦物理信道依赖，适用于任意范数有界谱收敛信道，通过随机变换域构造等效各向同性信道矩阵，实现统计衰落信道遍历性，保证AMP类检测器的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 传统复用技术（如SC-FDE、OFDM、OTFS、AFDM）依赖特定信道结构进行对角化或稀疏化，在动态现实环境中鲁棒性受限。需要一种与物理信道解耦的复用技术，适用于任意范数有界谱收敛信道矩阵。

Method: 提出随机复用技术，在随机变换域构造等效输入各向同性信道矩阵，实现统计衰落信道遍历性。采用跨域记忆AMP（CD-MAMP）检测器，利用时域信道稀疏性和等效信道随机性。推导最优功率分配以最小化BER和最大化约束容量。

Result: 随机复用技术保证AMP类检测器对任意范数有界谱收敛信道矩阵和信号配置的渐近最优性。CD-MAMP检测器在随机复用系统中具有最优编码原理和约束容量最优性。该技术在不同无线应用中展现出良好适应性。

Conclusion: 随机复用技术突破了传统复用技术对特定信道结构的依赖，为高移动性动态环境提供了鲁棒、通用的解决方案，具有理论最优性和实际应用潜力。

Abstract: As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.

</details>


### [46] [When Wires Can't Keep Up: Reconfigurable AI Data Centers Empowered by Terahertz Wireless Communications](https://arxiv.org/abs/2512.24110)
*Chong Han,Mingjie Zhu,Wenqi Zhao,Ziming Yu,Guolong Huang,Guangjian Wang,Wen Tong,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出太赫兹无线数据中心（THz-WDC）愿景，利用太赫兹频段实现超高带宽、低延迟、高能效的短中距离无线互连，以解决AI工作负载对数据中心互连架构的挑战。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心AI工作负载爆炸式增长，传统铜缆和光缆互连在延迟、功耗和刚性方面面临根本性挑战，限制了分布式AI集群的可扩展性。

Method: 提出太赫兹无线数据中心架构，探索数字孪生编排、低复杂度波束操纵技术、全硅太赫兹收发器、低复杂度模拟基带架构等关键技术，并进行数值分析比较太赫兹与光缆/铜缆互连的性能。

Result: 太赫兹无线链路可实现单链路1Tbps、通过空间复用达10Tbps聚合吞吐量、单跳延迟低于50ns、20米距离内低于10pJ/bit的能效，在特定距离和吞吐量域可超越传统有线解决方案。

Conclusion: 太赫兹无线互连为AI数据中心提供灵活、可重构、可持续的解决方案，文章最后提出了向无线定义、可重构、可持续AI数据中心的路线图。

Abstract: The explosive growth of artificial intelligence (AI) workloads in modern data centers demands a radical transformation of interconnect architectures. Traditional copper and optical wiring face fundamental challenges in latency, power consumption, and rigidity, constraining the scalability of distributed AI clusters. This article introduces a vision for Terahertz (THz) Wireless Data Center (THz-WDC) that combines ultra-broadband capacity, one-hop low-latency communication, and energy efficiency in the short-to-medium range (1-100m). Performance and technical requirements are first articulated, including up to 1 Tbps per link, aggregate throughput up to 10 Tbps via spatial multiplexing, sub-50 ns single-hop latency, and sub-10 pJ/bit energy efficiency over 20m. To achieve these ambitious goals, key enabling technologies are explored, including digital-twin-based orchestration, low-complexity beam manipulation technologies, all-silicon THz transceivers, and low-complexity analog baseband architectures. Moreover, as future data centers shift toward quantum and chiplet-based modular architectures, THz wireless links provide a flexible mechanism for interconnecting, testing, and reconfiguring these modules. Finally, numerical analysis is presented on the latency and power regimes of THz versus optical and copper interconnects, identifying the specific distance and throughput domains where THz links can surpass conventional wired solutions. The article concludes with a roadmap toward wireless-defined, reconfigurable, and sustainable AI data centers.

</details>


### [47] [Efficient Decoding of Twisted GRS Codes and Roth--Lempel Codes](https://arxiv.org/abs/2512.24217)
*Runtian Zhu,Lingfei Jin*

Main category: cs.IT

TL;DR: 本文提出了针对扭曲广义Reed-Solomon码和Roth-Lempel码的高效列表解码和唯一解码算法，运行时间接近线性，显著优于之前的二次时间复杂度。


<details>
  <summary>Details</summary>
Motivation: MDS码在实践中有广泛应用，但大多数已知MDS码都是广义Reed-Solomon码。研究非GRS码既有理论意义，也有实际价值，因为在密码学环境中GRS码的强代数结构可能不受欢迎。扭曲广义Reed-Solomon码和Roth-Lempel码是两个重要的非GRS码家族，但它们的解码问题研究相对较少，许多问题尚未解决。

Method: 基于Guruswami-Sudan算法，为TGRS码和Roth-Lempel码设计列表解码和唯一解码算法。在合适的参数条件下，算法实现接近线性的运行时间。对于TGRS码，支持最多O(n²)个扭曲的情况；对于Roth-Lempel码，提供了首个高效解码器。此外，将代数操作检测码整合到列表解码框架中。

Result: 算法运行时间接近线性，显著改进了之前已知的二次时间复杂度。TGRS解码器支持最多O(n²)个扭曲，大幅扩展了之前仅处理单扭曲的情况。为Roth-Lempel码提供了首个高效解码器。列表解码器在广泛参数范围内超越了经典唯一解码半径。通过整合AMD码，能够以高概率从输出列表中恢复正确消息。

Conclusion: 本文为非GRS MDS码的解码问题提供了高效解决方案，填补了TGRS码和Roth-Lempel码解码研究的空白，为实际应用提供了理论基础和技术支持，特别是在密码学等需要避免强代数结构的场景中。

Abstract: MDS codes play a central role in practice due to their broad applications. To date, most known MDS codes are generalized Reed-Solomon (GRS) codes, leaving codes that are not equivalent to GRS codes comparatively less understood. Studying this non-GRS regime is therefore of intrinsic theoretical interest, and is also practically relevant since the strong algebraic structure of GRS codes can be undesirable in cryptographic settings. Among the known non-GRS codes, twisted generalized Reed-Solomon (TGRS) codes and Roth-Lempel codes are two representative families of non-GRS codes that have attracted significant attention. Though substantial work has been devoted to the construction and structural analysis of TGRS and Roth-Lempel codes, comparatively little attention has been paid to their decoding, and many problems remain open. In this paper, we propose list and unique decoding algorithms for TGRS codes and Roth-Lempel codes based on the Guruswami-Sudan algorithm. Under suitable parameter conditions, our algorithms achieve near-linear running time in the code length, improving upon the previously best-known quadratic-time complexity. Our TGRS decoder supports fixed-rate TGRS codes with up to O(n^2) twists, substantially extending prior work that only handled the single-twist case. For Roth-Lempel codes, we provide what appears to be the first efficient decoder. Moreover, our list decoders surpass the classical unique-decoding radius for a broad range of parameters. Finally, we incorporate algebraic manipulation detection (AMD) codes into the list-decoding framework, enabling recovery of the correct message from the output list with high probability.

</details>


### [48] [SC-LDPC Codes Over $\mathbb{F}_q$: Minimum Distance, Decoding Analysis and Threshold Saturation](https://arxiv.org/abs/2512.24232)
*Jiaxin Lyu,Guanghui He*

Main category: cs.IT

TL;DR: 本文研究了有限域上的随机空间耦合LDPC码，提出了标准耦合和增强耦合两种结构，证明了它们具有渐进良好的最小距离和停止集大小，并建立了通用阈值饱和理论。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上空间耦合LDPC码的性能，特别是通过不同的变量节点边扩展规则来改进码的距离特性，并建立统一的迭代译码阈值分析框架。

Method: 定义了标准耦合和增强耦合两种随机Tanner图结构，使用独立均匀随机单项式映射。引入对称概率测度理论，分析q进制输入无记忆对称信道下的消息分布特性，建立度量拓扑和退化理论框架。

Result: 证明两种耦合结构都具有渐进良好的最小距离和最小停止集大小，增强耦合比标准耦合有更好的距离性能。建立了通用阈值饱和结果：随着耦合参数增加，置信传播阈值会饱和到一个仅取决于基础结构和信道族的确定阈值。

Conclusion: 有限域上的空间耦合LDPC码通过适当的耦合设计可以获得良好的距离特性和阈值饱和性能，增强耦合结构在距离性能上优于标准耦合，为q进制通信系统提供了有效的编码方案。

Abstract: We investigate random spatially coupled low-density parity-check (SC-LDPC) code ensembles over finite fields. Under different variable-node edge-spreading rules, the random Tanner graphs of several coupled ensembles are defined by multiple independent, uniformly random monomial maps. The two main coupled ensembles considered are referred to as the standard coupled ensemble and the improved coupled ensemble. We prove that both coupled ensembles exhibit asymptotically good minimum distance and minimum stopping set size. Theoretical and numerical results show that the improved coupled ensemble can achieve better distance performance than the standard coupled ensemble. We introduce the essential preliminaries and analytical tools needed to analyze the iterative decoding threshold of coupled ensembles over any finite field. We consider a class of memoryless channels with special symmetry, termed q-ary input memoryless symmetric channels (QMSCs), and show that, for these channels, the distribution of channel messages (in form of probability vectors) likewise exhibits this symmetry. Consequently, we define symmetric probability measures and their reference measures on a finite-dimensional probability simplex, analyze their foundational properties and those of their linear functionals, endow their respective spaces with metric topologies, and conduct an in-depth study of their degradation theory. Based on our analytical framework, we establish a universal threshold saturation result for both of the coupled ensembles over a q-ary finite field on QMSCs. Specifically, as the coupling parameters increase, the belief-propagation threshold of a coupled system saturates to a well-defined threshold that depends only on the underlying ensemble and the channel family.

</details>


### [49] [Infinite families of graphs and stable completion of arbitrary matrices, Part I](https://arxiv.org/abs/2512.24468)
*Augustin Cosse*

Main category: cs.IT

TL;DR: 研究确定性构造图，使得低秩矩阵无论元素值如何都能唯一补全，将可补全性与特定模式（自回避行走的并集）联系起来，设计无限图族使得通过SOS层次结构能实现精确稳定补全。


<details>
  <summary>Details</summary>
Motivation: 研究低秩矩阵补全问题，特别是确定在什么图结构下，无论矩阵元素的具体数值如何，都能保证低秩矩阵的唯一可补全性。这有助于理解矩阵补全问题的根本结构特性。

Method: 将矩阵补全的可补全性与图论中的特定模式（自回避行走的并集）联系起来，分析由双邻接矩阵支撑生成的格图子图中的模式存在性。基于这些模式设计确定性图构造方法。

Result: 建立了低秩矩阵可补全性与图结构中特定模式之间的理论联系，设计出无限图族，使得对于任意固定秩矩阵，都能通过平方和（SOS）层次结构实现精确且稳定的补全。

Conclusion: 通过图论方法为低秩矩阵补全问题提供了确定性构造框架，将可补全性条件转化为图结构中的模式检测问题，为设计具有保证补全性能的图结构提供了理论基础。

Abstract: We study deterministic constructions of graphs for which the unique completion of low rank matrices is generically possible regardless of the values of the entries. We relate the completability to the presence of some patterns (particular unions of self-avoiding walks) in the subgraph of the lattice graph generated from the support of the bi-adjacency matrix. The construction makes it possible to design infinite families of graphs on which exact and stable completion is possible for every fixed rank matrix through the sum-of-squares hierarchy.

</details>


### [50] [Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL](https://arxiv.org/abs/2512.24773)
*Anas K. Saeed,Mahmoud M. Salim,Ali Arshad Nasir,Ali H. Muqaibel*

Main category: cs.IT

TL;DR: 本文提出了一种基于深度强化学习的模型无关框架，用于优化受无人机抖动和信道不确定性影响的无人机载RIS系统吞吐量，相比传统优化方法显著提升了在线推理速度。


<details>
  <summary>Details</summary>
Motivation: 无人机载可重构智能表面(RIS)能够按需重塑无线传播环境，但其性能对无人机抖动和级联信道不确定性非常敏感。现有方法在处理这些实际损伤时面临挑战，需要更鲁棒和高效的解决方案。

Method: 设计了基于上下文多臂老虎机的模型无关深度强化学习框架，采用可微分可行性层将连续动作映射到可行解，奖励函数使用期望吞吐量的蒙特卡洛估计。实例化了不使用目标网络的约束型DDPG和TD3算法。

Result: 在严重抖动和低CSI质量条件下，所提算法相比传统交替优化WMMSE基线获得更高吞吐量。在不同场景下，性能与基于样本平均近似的AO-WMMSE基准相当或略低（相对差距0-12%），但在线推理时间仅0.6ms/决策，远低于AO-WMMSE的370-550ms。

Conclusion: 所提出的深度强化学习框架能够有效处理无人机载RIS系统中的随机抖动和信道不确定性，在保持可比性能的同时实现了显著的实时性优势，为实际部署提供了可行的解决方案。

Abstract: Reconfigurable intelligent surfaces (RISs) mounted on unmanned aerial vehicles (UAVs) can reshape wireless propagation on-demand. However, their performance is sensitive to UAV jitter and cascaded channel uncertainty. This paper investigates a downlink multiple-input single-output UAV-mounted RIS system in which a ground multiple-antenna base station (BS) serves multiple single-antenna users under practical impairments. Our goal is to maximize the expected throughput under stochastic three-dimensional UAV jitter and imperfect cascaded channel state information (CSI) based only on the available channel estimates. This leads to a stochastic nonconvex optimization problem subject to a BS transmit power constraint and strict unit-modulus constraints on all RIS elements. To address this problem, we design a model-free deep reinforcement learning (DRL) framework with a contextual bandit formulation. A differentiable feasibility layer is utilized to map continuous actions to feasible solutions, while the reward is a Monte Carlo estimate of the expected throughput. We instantiate this framework with constrained variants of deep deterministic policy gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3) that do not use target networks. Simulations show that the proposed algorithms yield higher throughput than conventional alternating optimization-based weighted minimum mean-square error (AO-WMMSE) baselines under severe jitter and low CSI quality. Across different scenarios, the proposed methods achieve performance that is either comparable to or slightly below the AO-WMMSE benchmark, based on sample average approximation (SAA) with a relative gap ranging from 0-12%. Moreover, the proposed DRL controllers achieve online inference times of 0.6 ms per decision versus roughly 370-550 ms for AO-WMMSE solvers.

</details>
