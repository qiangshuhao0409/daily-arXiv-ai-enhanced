<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Prediction-Guided Control in Data Center Networks](https://arxiv.org/abs/2601.03593)
*Kevin Zhao,Chenning Li,Anton A. Zabreyko,Arash Nasr-Esfahany,Anna Goncharenko,David Dai,Sidharth Lakshmanan,Claire Li,Mohammad Alizadeh,Thomas E. Anderson*

Main category: cs.NI

TL;DR: Polyphony是一个数据中心网络系统，通过闭环控制机制在分钟级别减少尾部延迟事件，相比现有方法能更好地适应动态变化的工作负载。


<details>
  <summary>Details</summary>
Motivation: 现有模型无关优化方法假设网络自由度少且工作负载稳定，但现代数据中心网络不满足这些假设。需要一种新方法来控制和减少多类数据中心网络中尾部延迟事件的频率。

Method: 1) 全网监控和聚合工作负载；2) 使用近似反事实预测引擎估计网络配置变化对服务质量的影响；3) 以闭环方式应用最佳候选配置，快速稳定地收敛到满足运营商目标的配置。

Result: 在CloudLab简单拓扑上，Polyphony能在10分钟内收敛到严格的SLO（服务水平目标），并在大工作负载变化后15分钟内重新稳定，而现有技术无法适应。

Conclusion: Polyphony为网络运营商提供了控制和减少尾部延迟事件的新方法，针对之前被认为是静态的网络操作方面，与拥塞控制和流量工程等自适应机制互补。

Abstract: In this paper, we design, implement, and evaluate Polyphony, a system to give network operators a new way to control and reduce the frequency of poor tail latency events in multi-class data center networks, on the time scale of minutes. Polyphony is designed to be complementary to other adaptive mechanisms like congestion control and traffic engineering, but targets different aspects of network operation that have previously been considered static. By contrast to Polyphony, prior model-free optimization methods work best when there are only a few relevant degrees of freedom and where workloads and measurements are stable, assumptions not present in modern data center networks.
  Polyphony develops novel methods for measuring, predicting, and controlling network quality of service metrics for a dynamically changing workload. First, we monitor and aggregate workloads on a network-wide basis; we use the result as input to an approximate counterfactual prediction engine that estimates the effect of potential network configuration changes on network quality of service; we apply the best candidate and repeat in a closed-loop manner aimed at rapidly and stably converging to a configuration that meets operator goals. Using CloudLab on a simple topology, we observe that Polyphony converges to tight SLOs within ten minutes, and re-stabilizes after large workload shifts within fifteen minutes, while the prior state of the art fails to adapt.

</details>


### [2] [Incentive Mechanism Design for Resource Management in Satellite Networks: A Comprehensive Survey](https://arxiv.org/abs/2601.03757)
*Nguyen Cong Luong,Zeping Sui,Duc Van Le,Jie Cao,Bo Ma,Nguyen Duc Hai,Ruichen Zhang,Vu Van Quang,Dusit Niyato,Shaohan Feng*

Main category: cs.NI

TL;DR: 关于卫星网络中激励机制设计的综述论文，探讨如何通过经济学视角（博弈论和拍卖理论）结合系统视角来改善资源管理，解决移动性、覆盖范围、传播距离和资源约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 卫星网络面临高移动性、广覆盖、长传播距离以及能源、通信和计算资源严格约束等挑战。传统资源分配方法仅依赖硬性系统性能指标，而激励机制能够从"经济"视角结合"系统"视角，考虑人类用户的理性行为，保证所有系统实体的利益/效用，从而提高资源分配的可扩展性、适应性和公平性。

Method: 本文是一篇综述性论文，系统性地调查了卫星网络中激励机制设计的研究。基于博弈论和拍卖理论，从经济学角度分析资源管理问题，涵盖通信资源分配、计算卸载、隐私安全和协调等关键问题。

Result: 论文对卫星网络激励机制设计进行了全面综述，总结了现有研究成果，并识别了该领域的关键问题和挑战。特别强调了激励机制在改善资源分配可扩展性、适应性和公平性方面的价值。

Conclusion: 未来研究方向包括基于学习的卫星网络机制设计。激励机制设计为卫星网络资源管理提供了新的视角和方法，有望解决传统方法难以应对的复杂动态环境下的资源分配问题。

Abstract: Resource management is one of the challenges in satellite networks due to their high mobility, wide coverage, long propagation distances, and stringent constraints on energy, communication, and computation resources. Traditional resource allocation approaches rely only on hard and rigid system performance metrics. Meanwhile, incentive mechanisms, which are based on game theory and auction theory, investigate systems from the "economic" perspective in addition to the "system" perspective. Particularly, incentive mechanisms are able to take into account rationality and other behavior of human users into account, which guarantees benefits/utility of all system entities, thereby improving the scalability, adaptability, and fairness in resource allocation. This paper presents a comprehensive survey of incentive mechanism design for resource management in satellite networks. The paper covers key issues in the satellite networks, such as communication resource allocation, computation offloading, privacy and security, and coordination. We conclude with future research directions including learning-based mechanism design for satellite networks.

</details>


### [3] [Monaas: Mobile Node as a Service for TSCH-based Industrial IoT Networks](https://arxiv.org/abs/2601.03917)
*Jinting Liu,Jingwei Li,Tengfei Chang*

Main category: cs.NI

TL;DR: 提出Monaas架构，一种面向服务、分层的物联网网络架构，通过分层设计、任务驱动调度和按需移动资源集成，解决工业物联网中动态突发任务和移动设备管理的挑战。


<details>
  <summary>Details</summary>
Motivation: 工业物联网中，随着工业4.0发展，动态突发任务和移动设备数量增长带来两大挑战：多样化QoS需求和移动设备有效管理。现有TSCH网络缺乏系统框架应对这些挑战。

Method: 提出Monaas架构，核心特征包括：分层架构平衡全局协调与本地自治、任务驱动调度实现主动资源分配、按需移动资源集成机制。在nRF52840硬件测试平台上实现并评估。

Result: 在nRF52840测试平台上，Monaas在高优先级突发流量和链路退化情况下，任务完成率持续高于98%，而所有基线方法均低于40%。按需移动资源集成服务激活仅需1.2秒，比SDN快65%以上。

Conclusion: Monaas架构通过系统化管理和调度移动节点作为按需弹性资源，在特定场景下展现出显著优势，为工业物联网中动态任务和移动设备管理提供了有效解决方案。

Abstract: The Time-Slotted Channel Hopping (TSCH) mode of IEEE802.15.4 standard provides ultra high end-to-end reliability and low-power consumption for application in field of Industrial Internet of Things (IIoT). With the evolving of Industrial 4.0, dynamic and bursty tasks with varied Quality of Service (QoS); effective management and utilization of growing number of mobile equipments become two major challenges for network solutions. The existing TSCH-based networks lack of a system framework design to handle these challenges. In this paper, we propose a novel, service-oriented, and hierarchical IoT network architecture named Mobile Node as a Service (Monaas). Monaas aims to systematically manage and schedule mobile nodes as on-demand, elastic resources through a new architectural design and protocol mechanisms. Its core features include a hierarchical architecture to balance global coordination with local autonomy, task-driven scheduling for proactive resource allocation, and an on-demand mobile resource integration mechanism. The feasibility and potential of the Monaas link layer mechanisms are validated through implementation and performance evaluation on an nRF52840 hardware testbed, demonstrating its potential advantages in specific scenarios. On a physical nRF52840 testbed, Monaas consistently achieved a Task Completion Rate (TCR) above 98% for high-priority tasks under bursty traffic and link degradation, whereas all representative baselines (Static TSCH, 6TiSCH Minimal, OST, FTS-SDN) remained below 40%.Moreover, its on-demand mobile resource integration activated services in 1.2 s, at least 65% faster than SDN (3.5 s) and OST/6TiSCH (> 5.8 s).

</details>


### [4] [Experimental Evaluation of a UAV-Mounted LEO Satellite Backhaul for Emergency Connectivity](https://arxiv.org/abs/2601.03958)
*Mattia Figaro,Francesco Rossato,Alexander Bonora,Marco Giordani,Giovanni Schembra,Michele Zorzi*

Main category: cs.NI

TL;DR: 无人机搭载星链终端为地面应急用户提供互联网连接，在无蜂窝覆盖区域通过LEO卫星实现稳定通信


<details>
  <summary>Details</summary>
Motivation: 在公共保护和灾害救援行动中，农村或基础设施受损地区需要可靠的通信连接。传统地面网络不可用时，无人机作为空中基站结合LEO卫星网络可提供按需快速连接

Method: 实现一个系统：旋翼无人机搭载星链Mini终端，作为Wi-Fi接入点，通过星链星座为地面应急用户提供互联网回传。使用ns-3网络仿真和农村环境实地飞行实验进行评估

Result: 系统在静态和动态飞行条件下能维持约30 Mbps的上行吞吐量，覆盖范围可达约200米，对无人机电池寿命影响最小

Conclusion: 将商用LEO卫星终端部署在无人机上是实现应急通信连接的可行实用解决方案

Abstract: Reliable connectivity is critical for Public Protection and Disaster Relief operations, especially in rural or compromised environments where terrestrial infrastructure is unavailable. In such scenarios, NTNs, and specifically UAVs, are promising candidates to provide on-demand and rapid connectivity on the ground, serving as aerial base stations. In this paper, we implement a setup in which a rotary-wing UAV, equipped with a Starlink Mini terminal, provides Internet connectivity to an emergency ground user in the absence of cellular coverage via LEO satellites. The UAV functions as a Wi-Fi access point, while backhauling the ground traffic through the Starlink constellation. We evaluate the system via both network simulations in ns-3 and real-world flight experiments in a rural environment, in terms of throughput, latency, coverage, and energy consumption under static and dynamic flight conditions. Our results demonstrate that the system can maintain a stable uplink throughput of approximately 30 Mbps up to approximately 200 meters, and with minimal impact on the UAV battery lifetime. These findings demonstrate the feasibility of deploying commercial LEO satellite terminals on UAVs as a practical solution for emergency connectivity.

</details>


### [5] [Badanie Sieci Massive MIMO o Architekturze Zorientowanej na Uzytkownika](https://arxiv.org/abs/2601.04042)
*Marcin Hoffmann*

Main category: cs.NI

TL;DR: 6G用户中心网络架构通过大规模天线阵列和所有基站协同服务用户，在系统级仿真中显示可将小区边缘用户吞吐量提升3倍


<details>
  <summary>Details</summary>
Motivation: 未来6G网络预计采用大规模天线阵列和用户中心架构，需要评估这种新型网络架构在实际信道环境下的性能表现

Method: 使用先进的系统级仿真器，结合精确的3D射线追踪无线电信道模型，评估用户中心网络架构的性能

Result: 结果显示，新型用户中心网络架构可以将小区边缘用户的吞吐量提高3倍

Conclusion: 用户中心架构是6G网络的重要发展方向，能显著提升边缘用户体验，验证了该架构在实际信道环境下的有效性

Abstract: The future 6G networks are expected to utilize large antenna arrays and follow the user-centric architecture, where the user is being served by all base stations. This work evaluates such a system within an advanced system-level simulator, which utilizes an accurate 3D Ray-Tracing radio channel model. Results show that the novel user-centric network architecture can increase the cell-edge users throughput by a fold of 3.

</details>


### [6] [Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning](https://arxiv.org/abs/2601.04083)
*Marvin Illian,Ramin Khalili,Antonio A. de A. Rocha,Lin Wang*

Main category: cs.NI

TL;DR: 使用强化学习框架CellPilot自动调整蜂窝网络中的小区重选参数，相比传统启发式方法提升性能达167%


<details>
  <summary>Details</summary>
Motivation: 5G网络广泛部署并与4G/LTE网络共存，为移动设备提供了多样化的候选小区连接选择。然而，如何将移动设备关联到小区以最大化整体网络性能（即小区重选）仍然是移动运营商面临的关键挑战。目前的小区重选参数通常基于运营商经验手动配置，很少根据动态网络条件进行调整。

Method: 提出了一个名为CellPilot的强化学习框架，通过学习移动网络动态的时空模式来自适应调整小区重选参数。该框架使用轻量级RL智能体来优化网络性能。

Result: 使用真实世界数据的研究表明，即使是一个轻量级的RL智能体，其性能也比传统的启发式重配置方法高出167%，并且能够有效地泛化到不同的网络场景。

Conclusion: 数据驱动方法可以显著改善小区重选配置，提升移动网络性能。这表明自动学习和适应网络动态的智能方法在优化蜂窝网络方面具有巨大潜力。

Abstract: The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance.

</details>


### [7] [Tutorial on Flow-Based Network Traffic Classification Using Machine Learning](https://arxiv.org/abs/2601.04089)
*Adrian Pekar,Richard Plny,Karel Hynek*

Main category: cs.NI

TL;DR: 这是一篇关于构建机器学习网络流量分类系统的实用教程，涵盖从流量计量到模型部署的完整工作流程，特别关注加密流量下的有效分类。


<details>
  <summary>Details</summary>
Motivation: 现代网络承载着日益多样化和加密的流量类型，传统的基于端口和负载的分类方法已不再适用，需要更先进的机器学习技术来有效分类加密流量。

Method: 提供端到端的实用指南，包括：流量计量和数据集创建、真实标签标注、特征工程、防泄漏实验设计、模型训练与评估、可解释性分析以及部署考虑。采用基于流的监督分类方法，重点关注算法选择、性能指标和现实分区策略。

Result: 教程提供了完整的机器学习流量分类系统构建框架，并配有5个Jupyter笔记本实现代码，可在真实流量捕获数据上复现关键步骤，为研究者和从业者提供可操作的指导。

Conclusion: 该教程为网络研究人员和从业者提供了构建鲁棒流量分类系统的实用指南，特别适用于加密流量环境，通过系统化的工作流程和实际代码实现，帮助用户避免常见的方法论陷阱和测量误差。

Abstract: Modern networks carry increasingly diverse and encrypted traffic types that demand classification techniques beyond traditional port-based and payload-based methods. This tutorial provides a practical, end-to-end guide to building machine-learning-based network traffic flow classification systems. We cover the workflow from flow metering and dataset creation, through ground-truth labeling and feature engineering, to leakage-resistant experimental design, model training and evaluation, explainability, and deployment considerations. The tutorial focuses on supervised flow-based classification that remains effective under encryption and provides actionable guidance on algorithm selection, performance metrics, and realistic partitioning strategies, with emphasis on common real-world measurement artifacts and methodological pitfalls. A companion set of five Jupyter notebooks on GitHub implements the data-to-model workflow on real traffic captures, enabling readers to reproduce key steps. The intended audience includes researchers and practitioners with foundational networking knowledge who aim to design and deploy robust traffic classification systems in operational environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Mastering the Game of Go with Self-play Experience Replay](https://arxiv.org/abs/2601.03306)
*Jingbin Liu,Xuechun Wang*

Main category: cs.AI

TL;DR: QZero是一种无需搜索的模型无关强化学习算法，通过自对弈和离策略经验回放学习纳什均衡策略，在有限计算资源下达到AlphaGo水平


<details>
  <summary>Details</summary>
Motivation: 围棋长期以来作为人工智能的基准测试，需要复杂的战略推理和长期规划。以往方法如AlphaGo主要依赖基于模型的蒙特卡洛树搜索(MCTS)，本研究旨在探索模型无关强化学习在围棋中的有效性。

Method: QZero基于熵正则化Q学习，使用单一Q值网络统一策略评估和改进。算法完全从零开始，无需人类数据，通过自对弈和离策略经验回放进行训练，无需搜索过程。

Result: 使用7个GPU训练5个月后，QZero达到了与AlphaGo相当的性能水平。这是首次证明模型无关强化学习能够掌握围棋游戏，并展示了离策略强化学习在大规模复杂环境中的可行性。

Conclusion: QZero展示了模型无关强化学习在围棋等复杂游戏中的有效性，为强化学习在不需要搜索的情况下解决大规模复杂问题提供了新途径。

Abstract: The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and off-policy experience replay. Built upon entropy-regularized Q-learning, QZero utilizes a single Q-value network to unify policy evaluation and improvement. Starting tabula rasa without human data and trained for 5 months with modest compute resources (7 GPUs), QZero achieved a performance level comparable to that of AlphaGo. This demonstrates, for the first time, the efficiency of using model-free reinforcement learning to master the game of Go, as well as the feasibility of off-policy reinforcement learning in solving large-scale and complex environments.

</details>


### [9] [Digital Red Queen: Adversarial Program Evolution in Core War with LLMs](https://arxiv.org/abs/2601.03335)
*Akarsh Kumar,Ryan Bahlous-Boldi,Prafull Sharma,Phillip Isola,Sebastian Risi,Yujin Tang,David Ha*

Main category: cs.AI

TL;DR: 论文提出Digital Red Queen (DRQ)算法，利用LLM在Core War游戏中通过自我对抗进化程序，模拟生物界的"红皇后"动态适应过程，发现程序会逐渐变得通用且行为趋同。


<details>
  <summary>Details</summary>
Motivation: 当前大多数LLM进化框架都是静态优化问题，忽视了真实世界进化过程中的开放对抗动态。生物进化中的"红皇后"现象（需要不断适应变化的环境）在现有LLM进化方法中被忽略。

Method: 提出Digital Red Queen (DRQ)算法：在Core War（图灵完备的虚拟环境）中，使用LLM进化类似汇编的程序（称为"战士"）。每轮中，模型进化新战士来击败所有之前的战士，形成连续的适应序列。

Result: 经过多轮进化，战士程序相对于人类编写的测试程序变得越来越通用。有趣的是，独立运行中的战士行为多样性减少，表明向通用行为策略的趋同压力，类似于自然界的趋同进化。

Conclusion: 从静态目标转向动态"红皇后"目标具有潜在价值。Core War可作为研究对抗适应的丰富可控沙盒，DRQ的简单有效性表明类似的自对弈方法可用于其他实际对抗领域（如网络安全、药物抗性）。

Abstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embraces these so-called "Red Queen" dynamics via continual adaptation to a changing objective. DRQ uses an LLM to evolve assembly-like programs, called warriors, which compete against each other for control of a virtual machine in the game of Core War, a Turing-complete environment studied in artificial life and connected to cybersecurity. In each round of DRQ, the model evolves a new warrior to defeat all previous ones, producing a sequence of adapted warriors. Over many rounds, we observe that warriors become increasingly general (relative to a set of held-out human warriors). Interestingly, warriors also become less behaviorally diverse across independent runs, indicating a convergence pressure toward a general-purpose behavioral strategy, much like convergent evolution in nature. This result highlights a potential value of shifting from static objectives to dynamic Red Queen objectives. Our work positions Core War as a rich, controllable sandbox for studying adversarial adaptation in artificial systems and for evaluating LLM-based evolution methods. More broadly, the simplicity and effectiveness of DRQ suggest that similarly minimal self-play approaches could prove useful in other more practical multi-agent adversarial domains, like real-world cybersecurity or combating drug resistance.

</details>


### [10] [Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization](https://arxiv.org/abs/2601.03359)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: 提出多智能体工作流，将主任务描述与约束条件解耦，通过定量评分反馈迭代优化提示词，显著提升LLM输出对形式约束的遵从性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常生成内容相关但不符合形式约束的输出，传统提示优化方法只关注主任务描述的重述，忽略了作为响应验收标准的细粒度约束条件

Method: 提出新颖的多智能体工作流，将主任务描述的优化与其约束条件解耦，使用定量评分作为反馈，迭代重写和改进提示词

Result: 评估表明该方法产生的修订提示词在Llama 3.1 8B和Mixtral-8x 7B等模型上获得显著更高的遵从性评分

Conclusion: 通过解耦任务描述与约束条件并使用定量反馈迭代优化，可以有效提升LLM输出对形式约束的遵从性，解决概念正确但程序错误的问题

Abstract: Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B.

</details>


### [11] [Exploration Through Introspection: A Self-Aware Reward Model](https://arxiv.org/abs/2601.03389)
*Michael Petrowski,Milica Gašić*

Main category: cs.AI

TL;DR: 论文提出了一种基于内省探索的强化学习框架，通过隐马尔可夫模型推断"疼痛信念"作为学习信号，研究自我意识对智能体学习能力的影响，并比较正常与慢性疼痛感知模型的性能差异。


<details>
  <summary>Details</summary>
Motivation: 理解人工智能如何建模内部心理状态对于推进AI中的心智理论至关重要。证据表明存在一个统一的自体-他者意识系统。本研究通过让强化学习智能体在网格世界中推断自身内部状态，探索这种自我意识。

Method: 引入受生物疼痛启发的内省探索组件，使用隐马尔可夫模型从在线观察中推断"疼痛信念"，并将该信号整合到主观奖励函数中。建立计算框架比较正常与慢性疼痛感知模型的性能差异。

Result: 内省智能体总体上显著优于标准基线智能体，能够复制复杂的人类行为模式。研究展示了自我意识模型如何提升智能体的学习能力。

Conclusion: 通过计算建模自我意识，特别是基于疼痛信念的内省探索，能够有效提升强化学习智能体的性能，并为理解AI中的心智理论提供了新视角。

Abstract: Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidden Markov model to infer "pain-belief" from online observations. This signal is integrated into a subjective reward function to study how self-awareness affects the agent's learning abilities. Further, we use this computational framework to investigate the difference in performance between normal and chronic pain perception models. Results show that introspective agents in general significantly outperform standard baseline agents and can replicate complex human-like behaviors.

</details>


### [12] [Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms](https://arxiv.org/abs/2601.03470)
*Michael C. Darling,Alan H. Hesu,Michael A. Mardikes,Brian C. McGuigan,Reed M. Milewicz*

Main category: cs.AI

TL;DR: 提出一个基于成熟度的框架，通过明确的测量机制来认证具身AI系统


<details>
  <summary>Details</summary>
Motivation: 需要可认证的具身AI系统，这要求结构化的评估框架、定量评分机制以及处理可信度评估中多目标权衡的方法

Method: 提出基于成熟度的认证框架，包含结构化评估、定量评分和权衡导航方法；以不确定性量化作为示例测量机制，通过无人机系统检测案例研究展示可行性

Result: 展示了该框架在无人机系统检测案例中的可行性，证明了通过明确测量机制认证具身AI系统的可行性

Conclusion: 基于成熟度的框架为具身AI系统认证提供了结构化方法，通过明确测量机制和案例研究验证了其可行性

Abstract: We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility through an Uncrewed Aircraft System (UAS) detection case study.

</details>


### [13] [CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support](https://arxiv.org/abs/2601.03475)
*Ruiqi Deng,Geoffrey Martin,Tony Wang,Gongbo Zhang,Yi Liu,Chunhua Weng,Yanshan Wang,Justin F Rousseau,Yifan Peng*

Main category: cs.AI

TL;DR: CPGPrompt：将临床指南转化为LLM可执行的决策树，在专科转诊决策上表现优异，但在多分类路径任务上表现有差异


<details>
  <summary>Details</summary>
Motivation: 临床实践指南(CPGs)为患者护理提供循证建议，但将其整合到人工智能中面临挑战。现有方法如基于规则的系统存在可解释性差、指南依从性不一致、领域适用性窄等限制。

Method: 开发CPGPrompt自动提示系统，将叙述性临床指南转化为结构化决策树，利用LLM动态导航这些决策树进行患者病例评估。在三个领域（头痛、腰痛、前列腺癌）生成合成病例，测试不同决策场景。

Result: 二元专科转诊分类在所有领域表现一致强劲（F1: 0.85-1.00），召回率高（1.00 ± 0.00）。多分类路径分配表现下降，领域间有差异：头痛（F1: 0.47）、腰痛（F1: 0.72）、前列腺癌（F1: 0.77）。性能差异反映了各指南的结构特点。

Conclusion: CPGPrompt能有效将临床指南转化为LLM可执行的决策树，在二元决策任务上表现优异。多分类任务性能受指南结构影响，否定处理、时间推理和可量化实验室测试是影响性能的关键因素。

Abstract: Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations, including poor interpretability, inconsistent adherence to guidelines, and narrow domain applicability. To address this, we develop and validate CPGPrompt, an auto-prompting system that converts narrative clinical guidelines into large language models (LLMs).
  Our framework translates CPGs into structured decision trees and utilizes an LLM to dynamically navigate them for patient case evaluation. Synthetic vignettes were generated across three domains (headache, lower back pain, and prostate cancer) and distributed into four categories to test different decision scenarios. System performance was assessed on both binary specialty-referral decisions and fine-grained pathway-classification tasks.
  The binary specialty referral classification achieved consistently strong performance across all domains (F1: 0.85-1.00), with high recall (1.00 $\pm$ 0.00). In contrast, multi-class pathway assignment showed reduced performance, with domain-specific variations: headache (F1: 0.47), lower back pain (F1: 0.72), and prostate cancer (F1: 0.77). Domain-specific performance differences reflected the structure of each guideline. The headache guideline highlighted challenges with negation handling. The lower back pain guideline required temporal reasoning. In contrast, prostate cancer pathways benefited from quantifiable laboratory tests, resulting in more reliable decision-making.

</details>


### [14] [Personalization of Large Foundation Models for Health Interventions](https://arxiv.org/abs/2601.03482)
*Stefan Konigorski,Johannes E. Vedder,Babajide Alamu Owoyele,İbrahim Özkan*

Main category: cs.AI

TL;DR: LFMs与N-of-1试验互补：LFMs擅长基于群体数据快速生成假设，N-of-1试验擅长个体因果验证，结合两者可解决个性化医疗中的多重悖论。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型在医疗AI中展现出潜力，但能否提供真正个性化的治疗建议仍存疑问。研究发现个性化存在多重挑战：泛化悖论（模型在某个临床研究中表现优异但在其他研究中表现随机）、隐私-性能悖论、规模-特异性悖论、自动化-同理心悖论。此外，个性化推荐需要因果理解而非仅仅预测能力，这也是未解决的问题。

Method: 提出混合框架：LFMs利用多模态数据从群体模式中快速生成假设，产生带有不确定性估计的干预候选排序；N-of-1试验（交叉自我实验，个性化医疗中个体因果推断的金标准）对特定个体进行因果验证。两者结合，LFMs生成的候选触发后续N-of-1试验。

Result: 论证LFMs不能替代N-of-1试验，但两者互补。混合框架能同时利用LFMs的预测能力和N-of-1试验的因果推断能力，解决个性化医疗中的多重悖论，实现真正的个性化治疗。

Conclusion: 明确预测与因果之间的界限，并解决个性化医疗中的悖论性张力，对于负责任地将AI整合到个性化医疗中至关重要。LFMs和N-of-1试验的互补性为这一整合提供了可行路径。

Abstract: Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and external validity exist in tension. This exemplifies broader contradictions in AI-driven healthcare: the privacy-performance paradox, scale-specificity paradox, and the automation-empathy paradox. As another challenge, the degree of causal understanding required for personalized recommendations, as opposed to mere predictive capacities of LFMs, remains an open question. N-of-1 trials -- crossover self-experiments and the gold standard for individual causal inference in personalized medicine -- resolve these tensions by providing within-person causal evidence while preserving privacy through local experimentation. Despite their impressive capabilities, this paper argues that LFMs cannot replace N-of-1 trials. We argue that LFMs and N-of-1 trials are complementary: LFMs excel at rapid hypothesis generation from population patterns using multimodal data, while N-of-1 trials excel at causal validation for a given individual. We propose a hybrid framework that combines the strengths of both to enable personalization and navigate the identified paradoxes: LFMs generate ranked intervention candidates with uncertainty estimates, which trigger subsequent N-of-1 trials. Clarifying the boundary between prediction and causation and explicitly addressing the paradoxical tensions are essential for responsible AI integration in personalized medicine.

</details>


### [15] [Evolving Programmatic Skill Networks](https://arxiv.org/abs/2601.03509)
*Haochen Shi,Xingdi Yuan,Bang Liu*

Main category: cs.AI

TL;DR: PSN是一个用于开放环境持续技能学习的框架，将技能表示为可执行的符号程序，通过LLM实现故障定位、渐进优化和结构重构，在MineDojo和Crafter上表现出强大的技能重用和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决开放环境中的持续技能获取问题，使智能体能够构建、细化和重用不断扩展的可执行技能库，实现长期的学习和适应能力。

Method: 提出程序化技能网络（PSN），将技能表示为可执行符号程序组成的组合网络，通过LLM实现三个核心机制：REFLECT故障定位、渐进优化与成熟度感知更新门控、以及回滚验证下的规范结构重构。

Result: 在MineDojo和Crafter环境中的实验表明，PSN能够实现强大的技能重用、快速适应能力，并在开放任务分布上表现出良好的泛化性能。

Conclusion: PSN框架为开放环境中的持续技能学习提供了有效的解决方案，其学习动态与神经网络训练具有结构相似性，展示了符号程序表示与LLM结合在技能获取中的潜力。

Abstract: We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\footnote{We plan to open-source the code.

</details>


### [16] [Variance Computation for Weighted Model Counting with Knowledge Compilation Approach](https://arxiv.org/abs/2601.03523)
*Kengo Nakamura,Masaaki Nishino,Norihito Yasuda*

Main category: cs.AI

TL;DR: 该论文研究了加权模型计数(WMC)的方差计算问题，提出了在结构化d-DNNF上计算方差的多项式时间算法，并证明了该问题在结构化DNNF、d-DNNF和FBDD上的计算困难性。


<details>
  <summary>Details</summary>
Motivation: 在实际推理任务中，模型参数通常从数据中学习而来，存在不确定性。为了评估推理结果的不确定性，需要将推理结果视为随机变量并计算其方差，但目前计算这种方差的可处理性尚不清楚。

Method: 1. 为结构化d-DNNF推导出多项式时间算法来计算WMC方差；2. 证明该问题在结构化DNNF、d-DNNF和FBDD上的计算困难性；3. 在贝叶斯网络推理中应用该方法来测量不确定性。

Result: 1. 成功开发了在结构化d-DNNF上计算WMC方差的多项式时间算法；2. 证明了该问题在结构化DNNF、d-DNNF和FBDD上是困难的，这很有趣，因为后两者允许多项式时间的WMC算法；3. 在真实世界贝叶斯网络上成功评估了边缘概率的方差，并分析了参数方差对边缘方差的影响。

Conclusion: 该研究填补了计算WMC方差可处理性知识的空白，为评估概率推理中的不确定性提供了理论基础和实用算法，特别是在贝叶斯网络等实际应用中。

Abstract: One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome as a random variable by introducing distributions for the parameters and evaluate the variance of the outcome. Unfortunately, the tractability of computing such a variance is hardly known. Motivated by this, we consider the problem of computing the variance of WMC and investigate this problem's tractability. First, we derive a polynomial time algorithm to evaluate the WMC variance when the input is given as a structured d-DNNF. Second, we prove the hardness of this problem for structured DNNFs, d-DNNFs, and FBDDs, which is intriguing because the latter two allow polynomial time WMC algorithms. Finally, we show an application that measures the uncertainty in the inference of Bayesian networks. We empirically show that our algorithm can evaluate the variance of the marginal probability on real-world Bayesian networks and analyze the impact of the variances of parameters on the variance of the marginal.

</details>


### [17] [STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules](https://arxiv.org/abs/2601.03537)
*Di Wu,Yanyan Zhao,Xin Lu,Mingzhe Li,Bing Qin*

Main category: cs.AI

TL;DR: STAR-S是一个通过自我教学循环学习安全规则推理的框架，用于防御大语言模型的越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 当前通过训练模型在响应前进行安全规则推理的方法存在局限性，难以明确设计或直接获取有效的安全推理形式来防御越狱攻击。

Method: 提出STAR-S框架，将安全规则推理学习整合到自我教学循环中：通过安全规则引导的推理和反思，然后利用微调增强安全推理能力，形成协同循环。

Result: 实验表明STAR-S能有效防御越狱攻击，性能优于基线方法。

Conclusion: STAR-S通过自我教学循环学习安全规则推理，为防御大语言模型越狱攻击提供了一种有效方法。

Abstract: Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \textbf{STAR-S} (\textbf{S}elf-\textbf{TA}ught \textbf{R}easoning based on \textbf{S}afety rules), a framework that integrates the learning of safety rule reasoning into a self-taught loop. The core of STAR-S involves eliciting reasoning and reflection guided by safety rules, then leveraging fine-tuning to enhance safety reasoning. Repeating this process creates a synergistic cycle. Improvements in the model's reasoning and interpretation of safety rules allow it to produce better reasoning data under safety rule prompts, which is then utilized for further training. Experiments show that STAR-S effectively defends against jailbreak attacks, outperforming baselines. Code is available at: https://github.com/pikepokenew/STAR_S.git.

</details>


### [18] [ReEfBench: Quantifying the Reasoning Efficiency of LLMs](https://arxiv.org/abs/2601.03550)
*Zhizhang Fu,Yuancheng Gu,Chenkai Hu,Hanmeng Liu,Yue Zhang*

Main category: cs.AI

TL;DR: 提出神经符号框架评估LLM推理过程，发现扩展token生成并非深度推理必要条件，混合长短CoT训练会导致过早饱和，蒸馏到小模型无法复制逻辑效能


<details>
  <summary>Details</summary>
Motivation: 当前CoT评估方法存在局限，无法区分性能提升是来自真实推理还是单纯增加输出长度，需要更全面的过程中心评估框架

Method: 提出神经符号框架进行非侵入式、全面的过程中心推理评估，识别四种行为原型并诊断失败模式，考察推理模式、训练策略和模型规模的影响

Result: 发现扩展token生成不是深度推理的必要条件；混合长短CoT训练会导致过早饱和和崩溃；蒸馏到小模型能复制行为长度但无法复制逻辑效能

Conclusion: 需要更精细的推理评估方法，模型规模、训练策略和推理模式对推理能力有重要影响，单纯增加输出长度不等于提升推理质量

Abstract: Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.

</details>


### [19] [SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models](https://arxiv.org/abs/2601.03555)
*Yuxuan Jiang,Francis Ferraro*

Main category: cs.AI

TL;DR: SCRIBE是一个强化学习框架，通过技能原型库进行中间层奖励建模，减少奖励方差，提升工具增强代理在多步推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的奖励模型在工具增强代理训练中产生噪声和不一致的信号，缺乏细粒度、任务特定的评估标准来区分高层规划和低层执行，导致信用分配困难。

Method: 引入SCRIBE框架，在中间层抽象进行干预，基于技能原型库进行奖励建模，将开放式LLM评估转化为约束验证问题，为每个子目标分配相应原型，提供精确的结构化评估标准。

Result: 在多个推理和工具使用基准测试中达到最先进性能，将Qwen3-4B模型的AIME25准确率从43.3%提升至63.3%，显著提高复杂多轮工具交互的成功率。

Conclusion: SCRIBE与低层工具优化互补，为构建更自主可靠的工具使用代理提供了可扩展的途径，中间层技能掌握先于有效高层规划行为的出现。

Abstract: Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.
  Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.
  Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.

</details>


### [20] [Controllable LLM Reasoning via Sparse Autoencoder-Based Steering](https://arxiv.org/abs/2601.03595)
*Yi Fang,Wenjie Wang,Mingfeng Xue,Boyi Deng,Fengli Xu,Dayiheng Liu,Fuli Feng*

Main category: cs.AI

TL;DR: SAE-Steering方法通过稀疏自编码器分解推理策略纠缠的隐藏状态，并识别策略特定特征作为控制向量，显著提升大型推理模型的策略控制效果和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型自主选择推理策略往往产生低效甚至错误的推理路径，现有方法难以控制细粒度推理策略，因为策略概念在隐藏状态中纠缠。

Method: 使用稀疏自编码器将策略纠缠的隐藏状态分解为解缠的特征空间，提出SAE-Steering两阶段特征识别流程：先召回放大策略特定关键词logits的特征，再按控制效果排序，最终使用识别出的策略特定特征作为控制向量。

Result: SAE-Steering在控制效果上比现有方法提升超过15%，通过控制推理策略可将模型从错误路径转向正确路径，实现7%的绝对准确率提升。

Conclusion: SAE-Steering能有效识别和控制大型推理模型的细粒度推理策略，提高推理可靠性和灵活性，为解决策略控制问题提供了新方法。

Abstract: Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods for controlling reasoning strategies. Existing methods struggle to control fine-grained reasoning strategies due to conceptual entanglement in LRMs' hidden states. To address this, we leverage Sparse Autoencoders (SAEs) to decompose strategy-entangled hidden states into a disentangled feature space. To identify the few strategy-specific features from the vast pool of SAE features, we propose SAE-Steering, an efficient two-stage feature identification pipeline. SAE-Steering first recalls features that amplify the logits of strategy-specific keywords, filtering out over 99\% of features, and then ranks the remaining features by their control effectiveness. Using the identified strategy-specific features as control vectors, SAE-Steering outperforms existing methods by over 15\% in control effectiveness. Furthermore, controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones, achieving a 7\% absolute accuracy improvement.

</details>


### [21] [Interleaved Tool-Call Reasoning for Protein Function Understanding](https://arxiv.org/abs/2601.03604)
*Chuanliu Fan,Zicheng Ma,Huanran Meng,Aijia Zhang,Wenjie Du,Jun Zhang,Yi Qin Gao,Ziqiang Cao,Guohong Fu*

Main category: cs.AI

TL;DR: PFUA：一种工具增强的蛋白质推理代理，通过整合领域特定工具而非纯文本推理，显著提升蛋白质功能预测性能


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的思维链推理在数学和编程等符号领域有效，但直接应用于蛋白质功能理解效果不佳，因为蛋白质功能预测是知识密集型的科学任务，需要外部生物先验知识和计算工具而非纯内部推理

Method: 提出PFUA工具增强蛋白质推理代理，统一问题分解、工具调用和基于证据的答案生成，整合领域特定工具产生可验证的中间证据，而非依赖长无约束的推理轨迹

Result: 在四个基准测试中，PFUA持续优于纯文本推理模型，平均性能提升103%

Conclusion: 蛋白质功能预测需要整合领域工具而非纯文本推理，PFUA通过工具增强方法有效解决了这一挑战，为生物信息学中的AI应用提供了新范式

Abstract: Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%.

</details>


### [22] [Architecting Agentic Communities using Design Patterns](https://arxiv.org/abs/2601.03624)
*Zoran Milosevic,Fethi Rabhi*

Main category: cs.AI

TL;DR: 论文提出基于企业分布式系统标准、形式化方法和行业实践的AI智能体系统架构设计模式，重点关注智能体社区层级的协调框架，通过形式化验证确保企业级部署的治理与合规性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和智能体AI技术的快速发展需要系统化的架构指导，以构建复杂的生产级系统。当前缺乏结合实践指导和形式化验证的架构方法，特别是针对企业级多智能体生态系统的协调框架。

Method: 从企业分布式系统标准、形式化方法和行业实践中提取设计模式，分为三层：LLM智能体（任务自动化）、智能体AI（自适应目标寻求者）和智能体社区（组织框架）。重点研究智能体社区，建立形式化框架，通过协作协议、角色分配和治理结构协调AI智能体与人类参与者。

Result: 提出了一个三层架构模式分类，建立了智能体社区的形式化框架，能够表达组织、法律和伦理规则，通过问责机制确保可操作的治理。通过临床试验匹配案例验证了框架的有效性。

Conclusion: 该框架为从业者提供可操作的指导，同时保持企业部署所需的形式化严谨性，支持动态多智能体生态系统中的可验证治理，有助于构建生产级的AI智能体系统。

Abstract: The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.

</details>


### [23] [How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs](https://arxiv.org/abs/2601.03662)
*Su-Hyeon Kim,Hyundong Jin,Yejin Lee,Yo-Sub Han*

Main category: cs.AI

TL;DR: SafeRemind：一种在推理步骤中动态注入安全提醒短语的解码时防御方法，通过熵触发机制在不更新参数的情况下提升大型推理模型的安全性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过显式思维步骤取得显著成功，但这些思维步骤可能放大不安全行为，而传统防御机制忽视了LRM独特的推理动态。研究发现思维步骤中出现安全提醒短语对确保LRM安全至关重要

Method: 提出SafeRemind解码时防御方法，利用熵触发在决策锁定点进行干预，动态向思维步骤注入安全提醒短语，将潜在有害轨迹重定向到更安全的结果，无需参数更新

Result: 在5个LRM和6个基准测试上的广泛评估表明，SafeRemind显著提升安全性，改进幅度高达45.5个百分点，同时保持核心推理效用

Conclusion: SafeRemind通过动态注入安全提醒短语有效解决了大型推理模型在思维步骤中的安全漏洞，提供了一种无需参数更新的高效防御机制

Abstract: Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a decoding-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while preserving core reasoning utility.

</details>


### [24] [Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction](https://arxiv.org/abs/2601.03672)
*Chen Zhang,Kepu Zhang,Jiatong Zhang,Xiao Zhang,Jun Xu*

Main category: cs.AI

TL;DR: Sandwich Reasoning (SandwichR) 提出了一种 Answer-Reasoning-Answer 范式，通过一致性感知强化学习策略，在保持推理准确性的同时显著降低查询纠正的延迟。


<details>
  <summary>Details</summary>
Motivation: 查询纠正是现代搜索管道的关键入口点，需要在实时延迟约束下保持高准确性。虽然思维链（CoT）推理能提高准确性，但其延迟过高无法满足实时需求。提前输出答案可以减少延迟，但在自回归解码下，早期答案与后续推理无关，无法利用推理能力提高准确性。

Method: 提出 Sandwich Reasoning (SandwichR) 方法，采用 Answer-Reasoning-Answer 范式：先生成初始纠正，然后进行显式推理过程，最后生成最终精炼纠正。设计一致性感知强化学习策略：专用一致性奖励强制初始和最终纠正对齐，基于边界的拒绝采样优先处理推理驱动最大纠正增益的边界样本。同时构建高质量查询纠正数据集。

Result: 实验结果表明，SandwichR 在达到与标准 CoT 相当的 SOTA 准确性的同时，实现了 40-70% 的延迟降低，解决了在线搜索中的延迟-准确性权衡问题。

Conclusion: SandwichR 通过将快速初始答案与事后推理对齐，实现了低延迟查询纠正而不牺牲推理感知的准确性，解决了实时查询纠正中的关键延迟-准确性权衡问题。

Abstract: Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search.

</details>


### [25] [Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics](https://arxiv.org/abs/2601.03687)
*Yonatan Vernik,Alexander Tuisov,David Izhaki,Hana Weitman,Gal A. Kaminka,Alexander Shleyfman*

Main category: cs.AI

TL;DR: 该论文提出使用LLM自动生成领域特定启发式函数，结合通用搜索算法（GBFS），将个性化用药规划的药物数量从最多7种扩展到至少28种，显著提高了覆盖率和规划时间。


<details>
  <summary>Details</summary>
Motivation: 个性化用药规划需要为每位患者选择药物并确定给药方案。先前基于通用领域无关启发式的方法最多只能处理7种药物，这在临床实践中远远不够。需要一种能够扩展到更多药物数量的方法，使用药规划更接近实际临床应用。

Method: 通过编程方式指定领域（定义初始状态和状态转移过程），使用大型语言模型（LLM）自动生成针对特定问题的启发式函数，然后将该启发式函数与固定的搜索算法（贪婪最佳优先搜索GBFS）结合使用。

Result: 该方法在覆盖率和规划时间方面取得了显著改进，将可处理的药物数量从最多7种扩展到至少28种，使个性化用药规划更接近实际应用。

Conclusion: 使用LLM自动生成领域特定启发式函数是扩展个性化用药规划规模的有效方法，能够处理更多药物数量，为临床应用提供了更实用的解决方案。

Abstract: Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\pddlp). Unfortunately, this process was limited in practice to consider no more than seven medications. In clinical terms, this is a non-starter. In this paper, we explore the use of automatically-generated domain- and problem-specific heuristics to be used with general search, as a method of scaling up medication planning to levels allowing closer work with clinicians. Specifically, we specify the domain programmatically (specifying an initial state and a successor generation procedure), and use an LLM to generate a problem specific heuristic that can be used by a fixed search algorithm (GBFS). The results indicate dramatic improvements in coverage and planning time, scaling up the number of medications to at least 28, and bringing medication planning one step closer to practical applications.

</details>


### [26] [EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation](https://arxiv.org/abs/2601.03769)
*Zihang Li,Yuhang Wang,Yikun Zong,Wenhan Yu,Xiaokun Yuan,Runhan Jiang,Zirui Liu,Tong Yang,Arthur Jiang*

Main category: cs.AI

TL;DR: EntroCoT：通过熵基分割和蒙特卡洛评估自动识别和优化低质量思维链监督数据，构建高质量数学推理数据集


<details>
  <summary>Details</summary>
Motivation: 现有思维链微调数据集存在"答案正确但推理错误"的问题，即最终答案正确但中间步骤存在幻觉、冗余或逻辑错误，需要自动识别和优化低质量监督数据

Method: 1. 基于熵的机制在不确定节点分割推理轨迹；2. 蒙特卡洛展开机制评估每个步骤的边际贡献；3. 准确过滤欺骗性推理样本，构建高质量数据集

Result: 在数学基准测试上的广泛实验表明，使用EntroCoT构建的子集进行微调始终优于全数据集监督的基线方法

Conclusion: EntroCoT能够有效识别和优化低质量思维链监督数据，构建高质量数据集，提升大语言模型的数学推理能力

Abstract: Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the "answer right but reasoning wrong" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.

</details>


### [27] [ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition](https://arxiv.org/abs/2601.03822)
*Muyang Zhao,Qi Qi,Hao Sun*

Main category: cs.AI

TL;DR: 论文提出ROI-Reasoning框架，通过元认知微调和理性感知强化学习，让LLM在严格token预算下进行推理任务分配，解决OS-MCKP问题


<details>
  <summary>Details</summary>
Motivation: LLM虽然具备强大推理能力，但不知道不同任务需要多少计算量。在实际应用中存在严格token预算约束，需要让LLM学会预测任务难度、估计投资回报率，并战略性地分配计算资源

Method: 提出ROI-Reasoning两阶段框架：1) 元认知微调阶段，让模型在生成前预测推理成本和预期效用，做出明确解决或跳过决策；2) 理性感知强化学习阶段，在硬token预算下优化序列决策，学习长期分配策略

Result: 在预算约束的数学推理基准测试中，ROI-Reasoning在严格计算预算下持续提高总体得分，同时显著减少遗憾

Conclusion: 该研究将预算推理形式化为OS-MCKP问题，通过赋予LLM内在的预算感知理性，使模型能够在有限计算资源下做出更优的推理决策，为资源受限环境下的LLM推理提供了有效解决方案

Abstract: Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.

</details>


### [28] [Defeasible Conditionals using Answer Set Programming](https://arxiv.org/abs/2601.03840)
*Racquel Dennison,Jesse Heyninck,Thomas Meyer*

Main category: cs.AI

TL;DR: 本文提出了一种使用答案集编程（ASP）计算理性闭包（RC）的声明式方法，实现了从知识库自动构建最小排序模型并支持查询推理，相比现有命令式实现具有更好的计算效率。


<details>
  <summary>Details</summary>
Motivation: 可废止推理涉及从不完全信息中得出合理结论，KLM框架是其基础模型。理性闭包（RC）是KLM框架中最突出的算法之一，但现有实现多为命令式方法，需要更高效、声明式的计算方法。

Method: 使用答案集编程（ASP）为理性闭包提供声明式定义，能够自动从给定知识库构建最小排序模型，并支持指定查询的推理检查。通过形式化证明验证ASP编码的正确性。

Result: 实验评估表明，ASP实现相比现有命令式实现（特别是InfOCF求解器）具有更好的计算效率，同时严格遵循理性闭包的理论基础。

Conclusion: ASP为理性闭包计算提供了一种有效的声明式方法，不仅保持了理论正确性，而且在计算效率上优于传统命令式实现，为可废止推理的实际应用提供了更好的工具支持。

Abstract: Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency.

</details>


### [29] [XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions](https://arxiv.org/abs/2601.03844)
*Agostino Dovier,Talissa Dreossi,Andrea Formisano,Benedetta Strizzolo*

Main category: cs.AI

TL;DR: 使用ASP建模意大利刑法典，通过半自动学习从司法判例中推导法律规则，支持刑事审判推理和解释


<details>
  <summary>Details</summary>
Motivation: 为法律专家在刑事审判阶段提供推理支持和可能的法律结果，使司法决策过程更加可解释

Method: 使用答案集编程（ASP）分析和编码意大利刑法典条款，包括"人身犯罪"和财产犯罪；利用基于稳定模型"支持性"的工具处理矛盾、生成决策并提供解释；集成ASP的归纳逻辑编程系统从案例中泛化法律规则

Result: 开发出能够支持法律专家推理的工具，在先前判决集上验证模型，系统能够处理编码过程中的矛盾，为新案件生成可能决策并提供解释

Conclusion: ASP方法能有效建模刑法典并学习法律规则，工具提供的自动可解释性有助于澄清司法决策逻辑，提高决策过程的可解释性

Abstract: We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including "crimes against the person" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the "supportedness" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples.

</details>


### [30] [Formally Explaining Decision Tree Models with Answer Set Programming](https://arxiv.org/abs/2601.03845)
*Akihiro Takemura,Masayuki Otani,Katsumi Inoue*

Main category: cs.AI

TL;DR: 使用ASP生成决策树模型的多类型解释（充分、对比、多数、树特定），相比SAT方法更灵活且支持枚举所有解释


<details>
  <summary>Details</summary>
Motivation: 决策树模型（如随机森林、梯度提升树）预测性能高但结构复杂难以解释，在安全关键应用中需要形式化论证模型决策

Method: 提出基于答案集编程（ASP）的方法生成多种解释类型：充分解释、对比解释、多数解释和树特定解释，相比SAT方法编码更灵活且支持枚举所有可能解释

Result: 在多样化数据集上实证评估，展示了方法的有效性和局限性，与现有方法相比具有优势

Conclusion: ASP方法为决策树模型提供灵活的多类型解释生成能力，支持用户偏好编码和完整解释枚举，在可解释AI领域具有应用价值

Abstract: Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.

</details>


### [31] [xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming](https://arxiv.org/abs/2601.03847)
*Ly Ly Trieu,Tran Cao Son*

Main category: cs.AI

TL;DR: xDNN(ASP) 是一个为深度神经网络生成全局解释的系统，它通过提取答案集语义下的逻辑程序来代表训练好的模型，提供特征重要性和隐藏节点影响等有价值信息。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法主要关注输入输出关系，忽视了网络结构在解释生成中的作用。需要一种能够提供全局解释并考虑网络结构的方法。

Method: 提出xDNN(ASP)系统，给定神经网络模型和训练数据，提取答案集语义下的逻辑程序，理想情况下该程序能一对一对应网络的输入输出对。

Result: 实验使用两个合成数据集，提取的逻辑程序不仅保持了高预测准确率，还提供了特征重要性和隐藏节点对预测影响等有价值信息。

Conclusion: xDNN(ASP)能有效生成深度神经网络的全局解释，提供模型理解信息，并可用于指导减少隐藏层节点数量，优化网络结构。

Abstract: Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their "black-box" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network.

</details>


### [32] [Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing](https://arxiv.org/abs/2601.03850)
*Veronika Semmelrock,Gerhard Friedrich*

Main category: cs.AI

TL;DR: ASP技术在电子系统配置等大规模问题上存在内存瓶颈，通过增量求解和约束感知猜测方法显著降低了内存需求


<details>
  <summary>Details</summary>
Motivation: 研究当前ASP求解技术在大规模配置问题（如包含3万多个组件的电子系统配置）上的可扩展性，特别是解决内存急剧增长的"接地瓶颈"问题

Method: 采用增量求解方法，并基于接地分析开发了约束感知猜测方法，通过减少内存需求来提升ASP在大规模问题上的处理能力

Result: 增量求解在实践中有效，但仍有内存限制；约束感知猜测方法显著降低了内存需求，提升了ASP处理大规模配置问题的能力

Conclusion: ASP技术在大规模配置问题上具有潜力，但需要解决内存瓶颈；约束感知猜测是有效的改进方法，为ASP在大规模应用中的扩展提供了可能

Abstract: Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need.

</details>


### [33] [Current Agents Fail to Leverage World Model as Tool for Foresight](https://arxiv.org/abs/2601.03905)
*Cheng Qian,Emre Can Acikgoz,Bingxuan Li,Xiusi Chen,Yuji Zhang,Bingxiang He,Qinyu Luo,Dilek Hakkani-Tür,Gokhan Tur,Yunzhu Li,Heng Ji,Heng Ji*

Main category: cs.AI

TL;DR: 研究发现当前AI代理难以有效利用生成式世界模型进行未来状态预测，存在模拟调用率低、误用预测结果、性能下降等问题


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型构建的代理面临更多需要预测未来状态的任务，生成式世界模型作为外部模拟器提供了一种解决方案。本文旨在实证研究当前代理是否能有效利用世界模型作为工具来增强认知能力。

Method: 通过多种代理任务和视觉问答任务进行实证研究，分析代理使用世界模型的行为模式，包括模拟调用频率、预测结果使用方式，并进行归因分析识别瓶颈所在。

Result: 研究发现：1）代理很少调用模拟（少于1%）；2）经常误用预测结果（约15%）；3）当模拟可用或被强制使用时，性能表现不一致甚至下降（最多5%）。归因分析表明主要瓶颈在于代理决定何时模拟、如何解释预测结果以及如何将预见整合到下游推理的能力。

Conclusion: 当前代理系统在利用世界模型进行预测性认知方面存在显著局限性，需要开发促进与世界模型进行校准、战略性交互的机制，以实现更可靠的预测性认知。

Abstract: Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.

</details>


### [34] [Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification](https://arxiv.org/abs/2601.03948)
*Rui Sun,Yifan Sun,Sheng Xu,Li Zhao,Jing Li,Daxin Jiang,Chen Hua,Zuo Bai*

Main category: cs.AI

TL;DR: Trade-R1框架通过过程级推理验证，将可验证奖励与随机金融市场连接，使用三角一致性度量和两种奖励集成策略，减少奖励黑客攻击并提升跨市场泛化能力。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在数学和编程等可验证奖励领域表现出色，但将其应用于金融决策面临挑战：市场具有随机性，奖励虽然可验证但本质上是噪声的，导致标准RL退化为奖励黑客攻击。

Method: 提出Trade-R1训练框架，通过过程级推理验证连接可验证奖励与随机环境。核心创新是将评估长篇金融文档推理转化为结构化RAG任务，构建三角一致性度量（检索证据、推理链和决策之间的两两对齐），作为噪声市场回报的有效性过滤器。探索两种奖励集成策略：固定效应语义奖励（FSR）用于稳定对齐信号，动态效应语义奖励（DSR）用于耦合幅度优化。

Result: 在不同国家资产选择实验中，该范式减少了奖励黑客攻击，其中DSR实现了优越的跨市场泛化能力，同时保持了最高的推理一致性。

Conclusion: Trade-R1框架通过过程级推理验证成功解决了金融决策中RL面临的奖励噪声问题，为随机环境中的强化学习应用提供了有效解决方案，特别是在需要处理复杂文档和噪声奖励的金融领域。

Abstract: Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training framework that bridges verifiable rewards to stochastic environments via process-level reasoning verification. Our key innovation is a verification method that transforms the problem of evaluating reasoning over lengthy financial documents into a structured Retrieval-Augmented Generation (RAG) task. We construct a triangular consistency metric, assessing pairwise alignment between retrieved evidence, reasoning chains, and decisions to serve as a validity filter for noisy market returns. We explore two reward integration strategies: Fixed-effect Semantic Reward (FSR) for stable alignment signals, and Dynamic-effect Semantic Reward (DSR) for coupled magnitude optimization. Experiments on different country asset selection demonstrate that our paradigm reduces reward hacking, with DSR achieving superior cross-market generalization while maintaining the highest reasoning consistency.

</details>


### [35] [Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models](https://arxiv.org/abs/2601.03969)
*Wei Wu,Liyi Chen,Congxi Xiao,Tianfu Wang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Hui Xiong*

Main category: cs.AI

TL;DR: 提出DOT方法解决大模型推理中的过度冗长问题，通过动态截断冗余token减少78%推理token使用，同时提升准确率


<details>
  <summary>Details</summary>
Motivation: 现有强化学习增强的大推理模型在简单查询上过度冗长，部署成本高；现有基于长度惩罚的方法存在优化冲突，且未深入探究过度思考的生成机制

Method: 提出动态异常截断(DOT)：在训练时选择性抑制冗余token，仅针对完全正确rollout组中的极端长度尾部；结合辅助KL正则化和预测性动态采样确保稳定收敛

Result: 在多个模型规模上显著扩展效率-性能帕累托前沿；在AIME-24上减少78%推理token使用，同时相比初始策略提升准确率，超越现有高效推理方法

Conclusion: DOT方法有效解决了模型在简单输入上的长度偏移现象，实现了推理效率与性能的双重提升，为高效推理提供了新思路

Abstract: Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.

</details>


### [36] [MobileDreamer: Generative Sketch World Model for GUI Agent](https://arxiv.org/abs/2601.04035)
*Yilin Cao,Yufeng Zhong,Zhixiong Zeng,Liming Zheng,Jing Huang,Haibo Qiu,Peng Shi,Wenji Mao,Wan Guanglu*

Main category: cs.AI

TL;DR: MobileDreamer是一个基于世界模型的移动GUI代理前瞻框架，通过文本草图世界模型预测动作后状态，结合前瞻想象优化动作选择，在Android World上实现了SOTA性能，任务成功率提升5.25%。


<details>
  <summary>Details</summary>
Motivation: 现有移动GUI代理大多是反应式的，主要基于当前屏幕做决策，限制了其在长视野任务上的表现。构建世界模型能够预测动作结果并支持更好的决策，但需要同时保持空间感知和部署效率。

Method: 提出MobileDreamer框架：1) 文本草图世界模型：将数字图像转换为关键任务相关草图，设计顺序不变学习策略保留GUI元素空间信息；2) GUI代理的前瞻想象策略：利用世界模型预测能力优化动作选择过程。

Result: 在Android World上的实验表明，MobileDreamer实现了最先进的性能，任务成功率提高了5.25%。世界模型评估进一步验证了文本草图建模能够准确预测关键GUI元素。

Conclusion: MobileDreamer通过高效的基于世界模型的前瞻框架，显著提升了移动GUI代理在长视野任务上的性能，解决了现有反应式代理的局限性。

Abstract: Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.

</details>


### [37] [ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows](https://arxiv.org/abs/2601.04060)
*Jinwei Su,Qizhen Lan,Zeyu Wang,Yinghui Xia,Hairu Wen,Yiqun Duan,Xi Xiao,Tianyu Shi,Yang Jingsong,Lewei He*

Main category: cs.AI

TL;DR: ComfySearch是一个基于代理的框架，用于在ComfyUI平台上探索组件空间并通过验证引导的工作流构建生成功能性管道，显著提高了执行成功率、解决方案率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: ComfyUI平台上的AI生成内容已从单一模型发展为模块化工作流，但组件数量庞大，在严格图约束下保持长时程结构一致性困难，导致通过率低和工作流质量有限。

Method: 提出了ComfySearch框架，采用代理机制探索组件空间，通过验证引导的工作流构建方法生成功能性ComfyUI管道。

Result: 实验表明，ComfySearch在复杂和创造性任务上显著优于现有方法，实现了更高的可执行性（通过）率、更高的解决方案率和更强的泛化能力。

Conclusion: ComfySearch有效解决了ComfyUI平台中组件空间探索和工作流构建的挑战，为AI生成内容的模块化工作流开发提供了更高效的方法。

Abstract: AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.

</details>


### [38] [Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions](https://arxiv.org/abs/2601.04170)
*Abhishek Rath*

Main category: cs.AI

TL;DR: 论文提出"智能体漂移"概念，指多智能体LLM系统在长期运行中行为退化、决策质量下降和协作失效的现象，并开发了量化漂移的ASI指标框架和三种缓解策略。


<details>
  <summary>Details</summary>
Motivation: 多智能体LLM系统在复杂任务分解和协作问题解决方面表现出强大能力，但其长期行为稳定性尚未得到充分研究。需要理解智能体在长时间交互序列中如何退化，以确保生产系统的可靠部署。

Method: 提出智能体漂移的理论框架，包括语义漂移、协调漂移和行为漂移三种表现形式。开发了Agent Stability Index (ASI)复合指标框架，包含12个维度来量化漂移。通过模拟分析和理论建模验证漂移影响，并提出三种缓解策略：情景记忆巩固、漂移感知路由协议和自适应行为锚定。

Result: 研究表明，未受控制的智能体漂移会导致任务完成准确率显著降低和人工干预需求增加。理论分析表明，提出的缓解策略能够显著减少漂移相关错误，同时保持系统吞吐量。

Conclusion: 这项工作为监控、测量和缓解生产性智能体AI系统中的智能体漂移建立了基础方法论，对企业部署可靠性和AI安全研究具有直接意义。为多智能体LLM系统的长期稳定性提供了理论框架和实践指导。

Abstract: Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).
  We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.
  We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [39] [LCPs of Subspace Codes](https://arxiv.org/abs/2601.03489)
*Sanjit Bhowmick*

Main category: cs.IT

TL;DR: 本文引入了子空间码的线性互补对(LCP)概念，给出了LCP子空间码的表征、存在性条件、多种构造方法，并应用于插入错误校正。


<details>
  <summary>Details</summary>
Motivation: 传统线性码的线性互补对(LCP)概念在编码理论中已有研究，但子空间码作为向量空间子空间的集合，其LCP概念尚未被探索。将LCP概念扩展到子空间码领域，可以丰富子空间码理论并开发新的应用。

Method: 1. 首先给出了子空间码形成LCP的表征条件；2. 基于子空间码上的补函数，提出了LCP存在的充分条件；3. 使用多种技术构造了子空间码的LCP；4. 将结果应用于插入错误校正问题。

Result: 建立了子空间码LCP的理论框架，包括表征定理、存在性条件、多种构造方法，并展示了在插入错误校正中的应用价值。

Conclusion: 成功将线性互补对概念从传统线性码推广到子空间码，为子空间码理论提供了新的研究方向和实际应用前景，特别是在错误校正领域。

Abstract: A subspace code is a nonempty collection of subspaces of the vector space $\mathbb{F}_q^{n}$. A pair of linear codes is called a linear complementary pair (in short LCP) of codes if their intersection is trivial and the sum of their dimensions equals the dimension of the ambient space. Equivalently, the two codes form an LCP if the direct sum of these two codes is equal to the entire space. In this paper, we introduce the concept of LCPs of subspace codes. We first provide a characterization of subspace codes that form an LCP. Furthermore, we present a sufficient condition for the existence of an LCP of subspace codes based on a complement function on a subspace code. In addition, we give several constructions of LCPs for subspace codes using various techniques and provide an application to insertion error correction.

</details>


### [40] [Hermitian LCD $2$-Quasi Abelian Codes over Finite Chain Rings](https://arxiv.org/abs/2601.03492)
*Sanjit Bhowmick,Kuntal Deka*

Main category: cs.IT

TL;DR: 本文引入了一类有限域上的Hermitian LCD 2-准阿贝尔码，并全面枚举了相对最小权重较小的这类码，证明它们在有限域上是渐近好的，并将结果推广到有限链环上。


<details>
  <summary>Details</summary>
Motivation: 研究Hermitian LCD（线性互补对偶）码在编码理论中具有重要意义，因为它们具有良好的解码特性。将这类码扩展到准阿贝尔结构和有限链环上，可以探索更广泛的编码构造和应用场景。

Method: 1. 引入有限域上的Hermitian LCD 2-准阿贝尔码类；2. 全面枚举相对最小权重较小的这类码；3. 证明这些码在有限域上是渐近好的；4. 将分析扩展到有限链环，刻画2-准阿贝尔码的特性；5. 证明在有限链环上也存在渐近好的Hermitian LCD 2-准阿贝尔码。

Result: 1. 成功构造并枚举了有限域上相对最小权重较小的Hermitian LCD 2-准阿贝尔码；2. 证明了这类码在有限域上是渐近好的；3. 在有限链环上刻画了2-准阿贝尔码的特性；4. 证明了在有限链环上也存在渐近好的Hermitian LCD 2-准阿贝尔码。

Conclusion: 本文建立了Hermitian LCD 2-准阿贝尔码的理论框架，证明了它们在有限域和有限链环上都是渐近好的，为编码理论提供了新的构造方法和理论结果，扩展了LCD码的研究范围。

Abstract: This paper introduces a class of Hermitian LCD $2$-quasi-abelian codes over finite fields and presents a comprehensive enumeration of these codes in which relative minimum weights are small. We show that such codes are asymptotically good over finite fields. Furthermore, we extend our analysis to finite chain rings by characterizing $2$-quasi-abelian codes in this setting and proving the existence of asymptotically good Hermitian LCD $2$-quasi-abelian codes over finite chain rings as well.

</details>


### [41] [Low-Complexity Planar Beyond-Diagonal RIS Architecture Design Using Graph Theory](https://arxiv.org/abs/2601.03831)
*Matteo Nerini,Zheyu Wu,Shanpu Shen,Bruno Clerckx*

Main category: cs.IT

TL;DR: 使用图论分析可实现在双层PCB上的平面连接RIS架构，识别具有最多自由度的最优设计


<details>
  <summary>Details</summary>
Motivation: 传统RIS架构有限，BD-RIS通过可调阻抗元件互连提供更大灵活性，但多层PCB设计增加制造难度，需要找到可在双层PCB上实现的最优架构

Method: 使用图论方法表征可在双层PCB上实现的BD-RIS架构（称为平面连接RIS），从可能的平面连接RIS中识别具有最多自由度的架构

Result: 确定了在双层PCB约束下具有最多自由度的平面连接RIS架构，这些架构在实际约束下预期能实现最佳性能

Conclusion: 通过图论分析找到了可在双层PCB上实现的最优BD-RIS架构，平衡了电路复杂度和性能，为实际应用提供了可行的解决方案

Abstract: Reconfigurable intelligent surfaces (RISs) enable programmable control of the wireless propagation environment and are key enablers for future networks. Beyond-diagonal RIS (BD-RIS) architectures enhance conventional RIS by interconnecting elements through tunable impedance components, offering greater flexibility with higher circuit complexity. However, excessive interconnections between BD-RIS elements require multi-layer printed circuit board (PCB) designs, increasing fabrication difficulty. In this letter, we use graph theory to characterize the BD-RIS architectures that can be realized on double-layer PCBs, denoted as planar-connected RISs. Among the possible planar-connected RISs, we identify the ones with the most degrees of freedom, expected to achieve the best performance under practical constraints.

</details>


### [42] [Unique Decoding of Hyperderivative Reed-Solomon Codes](https://arxiv.org/abs/2601.03982)
*Haojie Gu,Jun Zhang*

Main category: cs.IT

TL;DR: 提出一种用于NRT度量下超导数里德-所罗门码唯一解码的Welch-Berlekamp算法


<details>
  <summary>Details</summary>
Motivation: 纠错码旨在解决噪声信道上的可靠信息传输问题，编码理论和实践中的一个基本问题是高效解码接收到的含错字以获取传输的码字

Method: 针对NRT度量下的超导数里德-所罗门码，提出一种Welch-Berlekamp算法进行唯一解码

Result: 提出了一种适用于NRT HRS码的解码算法

Conclusion: 该工作为NRT度量下的超导数里德-所罗门码提供了一种有效的解码方法

Abstract: Error-correcting codes are combinatorial objects designed to cope with the problem of reliable transmission of information on a noisy channel. A fundamental problem in coding theory and practice is to efficiently decode the received word with errors to obtain the transmitted codeword. In this paper, we consider the decoding problem of Hyperderivative Reed-Solomon (HRS) codes with respect to the NRT metric. Specifically, we propose a Welch-Berlekamp algorithm for the unique decoding of NRT HRS codes.

</details>


### [43] [Flexible-Duplex Cell-Free Architecture for Secure Uplink Communications in Low-Altitude Wireless Networks](https://arxiv.org/abs/2601.04011)
*Wei Shi,Wei Xu,Yongming Huang,Jiacheng Yao,Wenhao Hu,Dongming Wang*

Main category: cs.IT

TL;DR: 提出一种灵活双工无小区架构，通过动态切换接入点模式（接收或发送人工噪声）来增强无人机上行链路的安全性，并开发了联合优化算法和低复杂度方案。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络中无人机上行传输由于发射功率有限、天线资源受限以及空-地传播条件高度暴露，容易受到窃听攻击，需要新的安全增强方案。

Method: 提出灵活双工无小区架构，接入点可动态切换为接收模式（收集无人机上行信号）或发送模式（生成协作人工噪声）。开发了联合优化AP模式选择、接收组合和AN协方差设计的算法，包括基于惩罚对偶分解的优化方法和低复杂度顺序方案。

Result: 仿真结果显示，所提架构相比固定AP角色的无小区系统获得显著的安全速率增益。联合优化方法达到最高安全性能，而低复杂度方案以低一个数量级的计算复杂度实现了超过90%的最优性能。

Conclusion: 灵活双工无细胞架构为低空无线网络中的安全上行通信提供了实用解决方案，通过动态AP模式切换和协作人工噪声有效增强了无人机传输的安全性。

Abstract: Low-altitude wireless networks (LAWNs) are expected to play a central role in future 6G infrastructures, yet uplink transmissions of uncrewed aerial vehicles (UAVs) remain vulnerable to eavesdropping due to their limited transmit power, constrained antenna resources, and highly exposed air-ground propagation conditions. To address this fundamental bottleneck, we propose a flexible-duplex cell-free (CF) architecture in which each distributed access point (AP) can dynamically operate either as a receive AP for UAV uplink collection or as a transmit AP that generates cooperative artificial noise (AN) for secrecy enhancement. Such AP-level duplex flexibility introduces an additional spatial degree of freedom that enables distributed and adaptive protection against wiretapping in LAWNs. Building upon this architecture, we formulate a max-min secrecy-rate problem that jointly optimizes AP mode selection, receive combining, and AN covariance design. This tightly coupled and nonconvex optimization is tackled by first deriving the optimal receive combiners in closed form, followed by developing a penalty dual decomposition (PDD) algorithm with guaranteed convergence to a stationary solution. To further reduce computational burden, we propose a low-complexity sequential scheme that determines AP modes via a heuristic metric and then updates the AN covariance matrices through closed-form iterations embedded in the PDD framework. Simulation results show that the proposed flexible-duplex architecture yields substantial secrecy-rate gains over CF systems with fixed AP roles. The joint optimization method attains the highest secrecy performance, while the low-complexity approach achieves over 90% of the optimal performance with an order-of-magnitude lower computational complexity, offering a practical solution for secure uplink communications in LAWNs.

</details>


### [44] [Serving Every Symbol: All-Symbol PIR and Batch Codes](https://arxiv.org/abs/2601.04041)
*Avital Boruchovsky,Anina Gruica,Jonathan Niemann,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 该论文研究了t-全符号PIR码和t-全符号批处理码的最小码长、结构性质以及与其他经典码族的关系


<details>
  <summary>Details</summary>
Motivation: 统一并扩展多个已知码族（如一步多数逻辑可译码、PIR码、批处理码），研究这些码的最小长度和结构性质，探索码长、维度、最小距离和t值之间的权衡关系

Method: 确定小k和t值下的最小码长，刻画达到最优的码的结构性质，推导码长、维度、最小距离和t之间的界限，研究MDS码和单纯形码在这些框架中的表现

Result: 获得了小参数下的最小码长结果，建立了码参数间的权衡界限，证明了单纯形码在某些t值下是t-函数批处理码，为相关猜想提供了新证据

Conclusion: 该研究统一了多个码族框架，提供了最小码长和结构性质的理论结果，推进了对PIR码和批处理码的理解，并为相关猜想提供了新的支持

Abstract: A $t$-all-symbol PIR code and a $t$-all-symbol batch code of dimension $k$ consist of $n$ servers storing linear combinations of $k$ linearly independent information symbols with the following recovery property: any symbol stored by a server can be recovered from $t$ pairwise disjoint subsets of servers. In the batch setting, we further require that any multiset of size $t$ of stored symbols can be recovered from $t$ disjoint subsets of servers. This framework unifies and extends several well-known code families, including one-step majority-logic decodable codes, (functional) PIR codes, and (functional) batch codes.
  In this paper, we determine the minimum code length for some small values of $k$ and $t$, characterize structural properties of codes attaining this optimum, and derive bounds that show the trade-offs between length, dimension, minimum distance, and $t$. In addition, we study MDS codes and the simplex code, demonstrating how these classical families fit within our framework, and establish new cases of an open conjecture from \cite{YAAKOBI2020} concerning the minimal $t$ for which the simplex code is a $t$-functional batch code.

</details>


### [45] [Expectation Propagation for Distributed Inference in Grant-Free Cell-Free Massive MIMO](https://arxiv.org/abs/2601.04166)
*Christian Forsch,Laura Cottatellucci*

Main category: cs.IT

TL;DR: 提出两种基于期望传播的分布式算法，用于免授权无小区大规模MIMO系统的联合活动检测、信道估计和数据检测，有效缓解导频污染并提高检测精度。


<details>
  <summary>Details</summary>
Motivation: 免授权无小区大规模MIMO系统是下一代物联网网络的关键技术，但大量连接设备导致无法使用正交导频序列，造成严重导频污染，影响信道估计和数据检测性能。同时，可扩展的GF-CF-MaMIMO网络需要分布式信号处理。

Method: 提出两种基于期望传播的分布式算法：JACD-EP使用高斯近似处理信道变量；JACD-EP-BG将信道变量建模为伯努利-高斯随机变量。通过推导BG分布的指数族表示，在因子图上实现高效消息传递。

Result: 仿真结果表明，所提分布式算法能有效缓解导频污染，其检测精度优于（理想辅助的）集中式线性检测器。该框架在接入点和用户设备数量上都具有良好的可扩展性。

Conclusion: 基于期望传播的分布式JACD算法为GF-CF-MaMIMO系统提供了一种有效的解决方案，能够处理导频污染问题并实现高精度的联合检测，同时保持系统的可扩展性。

Abstract: Grant-free cell-free massive multiple-input multiple-output (GF-CF-MaMIMO) systems are anticipated to be a key enabling technology for next-generation Internet-of-Things (IoT) networks, as they support massive connectivity without explicit scheduling. However, the large amount of connected devices prevents the use of orthogonal pilot sequences, resulting in severe pilot contamination (PC) that degrades channel estimation and data detection performance. Furthermore, scalable GF-CF-MaMIMO networks inherently rely on distributed signal processing. In this work, we consider the uplink of a GF-CF-MaMIMO system and propose two novel distributed algorithms for joint activity detection, channel estimation, and data detection (JACD) based on expectation propagation (EP). The first algorithm, denoted as JACD-EP, uses Gaussian approximations for the channel variables, whereas the second, referred to as JACD-EP-BG, models them as Bernoulli-Gaussian (BG) random variables. To integrate the BG distribution into the EP framework, we derive its exponential family representation and develop the two algorithms as efficient message passing over a factor graph constructed from the a posteriori probability (APP) distribution. The proposed framework is inherently scalable with respect to both the number of access points (APs) and user equipments (UEs). Simulation results show the efficient mitigation of PC by the proposed distributed algorithms and their superior detection accuracy compared to (genie-aided) centralized linear detectors.

</details>


### [46] [A discrete Benamou-Brenier formulation of Optimal Transport on graphs](https://arxiv.org/abs/2601.04193)
*Kieran Morris,Oliver Johnson*

Main category: cs.IT

TL;DR: 提出图上的离散输运方程，推导Wasserstein-1距离的Benamou-Brenier离散形式，分类图上所有W1测地线


<details>
  <summary>Details</summary>
Motivation: 将连续空间中的最优输运理论推广到图上，建立图上的离散Wasserstein距离和测地线理论

Method: 提出连接顶点和边分布的离散输运方程，推导Wasserstein-1距离的Benamou-Brenier离散形式

Result: 建立了图上的离散最优输运理论框架，分类了图上所有W1测地线

Conclusion: 成功将连续最优输运理论推广到离散图结构，为图上的分布比较和输运问题提供理论基础

Abstract: We propose a discrete transport equation on graphs which connects distributions on both vertices and edges. We then derive a discrete analogue of the Benamou-Brenier formulation for Wasserstein-$1$ distance on a graph and as a result classify all $W_1$ geodesics on graphs.

</details>
