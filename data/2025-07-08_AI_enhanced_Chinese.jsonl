{"id": "2507.03158", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.03158", "abs": "https://arxiv.org/abs/2507.03158", "authors": ["Jit Gupta", "Tarun Banka", "Rahul Gupta", "Mithun Dharmaraj", "Jasleen Kaur"], "title": "An End-to-End Assurance Framework for AI/ML Workloads in Datacenters", "comment": "2 page, Poster/Demo in IEEE Infocom 2025, May 19-22, London , UK", "summary": "Modern machine learning workloads such as large language model training,\nfine-tuning jobs are highly distributed and span across hundreds of systems\nwith multiple GPUs. Job completion time for these workloads is the artifact of\nthe application, compute, network and storage performance. In case of failure\nor degraded performance it is imperative to understand the root cause and\npossible remediation for the problem for end-to-end assurance. This demo\nshowcases SaaSbased observability and automated troubleshooting for AI/ML\nworkload performance issues using cross-layer telemetry and logs (e.g.,\nApplication telemetry, Collective communication logs, GPU Health metrics,\nNetwork Flow Data, NIC ROCEv2 telemetry). Different use cases are demonstrated\nfor end-to-end assurance such as Cross-layer Dependency Graph, Cross-layer\nService Level Expectations, Automated Root Cause Analysis, GPU-toGPU\napplication path tracing.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u57fa\u4e8eSaaS\u7684AI/ML\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u76d1\u63a7\u4e0e\u81ea\u52a8\u5316\u6545\u969c\u6392\u67e5\u5de5\u5177\uff0c\u5229\u7528\u8de8\u5c42\u9065\u6d4b\u548c\u65e5\u5fd7\u5b9e\u73b0\u7aef\u5230\u7aef\u4fdd\u969c\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff09\u5728\u591aGPU\u7cfb\u7edf\u4e2d\u8fd0\u884c\uff0c\u6027\u80fd\u95ee\u9898\u590d\u6742\uff0c\u9700\u5feb\u901f\u5b9a\u4f4d\u6839\u56e0\u5e76\u4fee\u590d\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u5e94\u7528\u9065\u6d4b\u3001\u96c6\u4f53\u901a\u4fe1\u65e5\u5fd7\u3001GPU\u5065\u5eb7\u6307\u6807\u3001\u7f51\u7edc\u6d41\u6570\u636e\u7b49\u8de8\u5c42\u6570\u636e\uff0c\u6784\u5efa\u4f9d\u8d56\u56fe\u548c\u81ea\u52a8\u5316\u6839\u56e0\u5206\u6790\u3002", "result": "\u5c55\u793a\u4e86\u8de8\u5c42\u4f9d\u8d56\u56fe\u3001\u670d\u52a1\u7ea7\u522b\u671f\u671b\u3001\u81ea\u52a8\u5316\u6839\u56e0\u5206\u6790\u7b49\u529f\u80fd\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u6027\u80fd\u4fdd\u969c\u3002", "conclusion": "\u8be5\u5de5\u5177\u80fd\u6709\u6548\u76d1\u63a7\u548c\u89e3\u51b3AI/ML\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u3002"}}
{"id": "2507.03224", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.03224", "abs": "https://arxiv.org/abs/2507.03224", "authors": ["Alexander Shan", "Jasleen Kaur", "Rahul Singh", "Tarun Banka", "Raj Yavatkar", "T. Sridhar"], "title": "RCA Copilot: Transforming Network Data into Actionable Insights via Large Language Models", "comment": "6 page, IEEE ICC 2025, Jun 8 12, 2025, Montreal, Canada", "summary": "Ensuring the reliability and availability of complex networked services\ndemands effective root cause analysis (RCA) across cloud environments, data\ncenters, and on-premises networks. Traditional RCA methods, which involve\nmanual inspection of data sources such as logs and telemetry data, are often\ntime-consuming and challenging for on-call engineers. While statistical\ninference methods have been employed to estimate the causality of network\nevents, these approaches alone are similarly challenging and suffer from a lack\nof interpretability, making it difficult for engineers to understand the\npredictions made by black-box models. In this paper, we present RCACopilot, an\nadvanced on-call system that combines statistical tests and large language\nmodel (LLM) reasoning to automate RCA across various network environments.\nRCACopilot gathers and synthesizes critical runtime diagnostic information,\npredicts the root cause of incidents, provides a clear explanatory narrative,\nand offers targeted action steps for engineers to resolve the issues. By\nutilizing LLM reasoning techniques and retrieval, RCACopilot delivers accurate\nand practical support for operators.", "AI": {"tldr": "RCACopilot\u7ed3\u5408\u7edf\u8ba1\u6d4b\u8bd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u81ea\u52a8\u5316\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6839\u56e0\u5206\u6790\uff0c\u63d0\u4f9b\u89e3\u91ca\u6027\u53d9\u8ff0\u548c\u89e3\u51b3\u6b65\u9aa4\u3002", "motivation": "\u4f20\u7edf\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u8017\u65f6\u4e14\u96be\u4ee5\u7406\u89e3\uff0c\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5de5\u7a0b\u5e08\u96be\u4ee5\u7406\u89e3\u9ed1\u76d2\u6a21\u578b\u7684\u9884\u6d4b\u3002", "method": "RCACopilot\u7ed3\u5408\u7edf\u8ba1\u6d4b\u8bd5\u548cLLM\u63a8\u7406\uff0c\u6536\u96c6\u5e76\u7efc\u5408\u8fd0\u884c\u65f6\u8bca\u65ad\u4fe1\u606f\uff0c\u9884\u6d4b\u6839\u56e0\u5e76\u63d0\u4f9b\u89e3\u91ca\u548c\u89e3\u51b3\u6b65\u9aa4\u3002", "result": "RCACopilot\u4e3a\u64cd\u4f5c\u5458\u63d0\u4f9b\u51c6\u786e\u4e14\u5b9e\u7528\u7684\u652f\u6301\uff0c\u81ea\u52a8\u5316\u6839\u56e0\u5206\u6790\u3002", "conclusion": "RCACopilot\u901a\u8fc7LLM\u63a8\u7406\u548c\u68c0\u7d22\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6839\u56e0\u5206\u6790\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.03248", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.03248", "abs": "https://arxiv.org/abs/2507.03248", "authors": ["Wenhao Lu", "Zhiyuan Wang", "Hefan Zhang", "Shan Zhang", "Hongbin Luo"], "title": "OpenSN: An Open Source Library for Emulating LEO Satellite Networks", "comment": "17 pages", "summary": "Low-earth-orbit (LEO) satellite constellations (e.g., Starlink) are becoming\na necessary component of future Internet. There have been increasing studies on\nLEO satellite networking. It is a crucial problem how to evaluate these studies\nin a systematic and reproducible manner. In this paper, we present OpenSN,\ni.e., an open source library for emulating large-scale satellite network (SN).\nDifferent from Mininet-based SN emulators (e.g., LeoEM), OpenSN adopts\ncontainer-based virtualization, thus allows for running distributed routing\nsoftware on each node, and can achieve horizontal scalability via flexible\nmulti-machine extension. Compared to other container-based SN emulators (e.g.,\nStarryNet), OpenSN streamlines the interaction with Docker command line\ninterface and significantly reduces unnecessary operations of creating virtual\nlinks. These modifications improve emulation efficiency and vertical\nscalability on a single machine. Furthermore, OpenSN separates user-defined\nconfiguration from container network management via a Key-Value Database that\nrecords the necessary information for SN emulation. Such a separation\narchitecture enhances the function extensibility. To sum up, OpenSN exhibits\nadvantages in efficiency, scalability, and extensibility, thus is a valuable\nopen source library that empowers research on LEO satellite networking.\nExperiment results show that OpenSN constructs mega-constellations 5X-10X\nfaster than StarryNet, and updates link state 2X-4X faster than LeoEM. We also\nverify the scalability of OpenSN by successfully emulating the five-shell\nStarlink constellation with a total of 4408 satellites.", "AI": {"tldr": "OpenSN\u662f\u4e00\u4e2a\u5f00\u6e90\u5e93\uff0c\u7528\u4e8e\u6a21\u62df\u5927\u89c4\u6a21\u536b\u661f\u7f51\u7edc\uff08SN\uff09\uff0c\u5177\u6709\u9ad8\u6548\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u529f\u80fd\u6027\u6269\u5c55\u4f18\u52bf\uff0c\u6bd4\u73b0\u6709\u5de5\u5177\u66f4\u5feb\u4e14\u66f4\u7075\u6d3b\u3002", "motivation": "\u8bc4\u4f30\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u536b\u661f\u7f51\u7edc\u7814\u7a76\u7684\u7cfb\u7edf\u6027\u548c\u53ef\u91cd\u590d\u6027\u65b9\u6cd5\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6a21\u62df\u5de5\u5177\u3002", "method": "OpenSN\u91c7\u7528\u57fa\u4e8e\u5bb9\u5668\u7684\u865a\u62df\u5316\u6280\u672f\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u8def\u7531\u8f6f\u4ef6\uff0c\u5e76\u901a\u8fc7\u952e\u503c\u6570\u636e\u5e93\u5206\u79bb\u7528\u6237\u914d\u7f6e\u4e0e\u5bb9\u5668\u7f51\u7edc\u7ba1\u7406\u3002", "result": "OpenSN\u6784\u5efa\u5927\u578b\u661f\u5ea7\u6bd4StarryNet\u5feb5-10\u500d\uff0c\u94fe\u8def\u72b6\u6001\u66f4\u65b0\u6bd4LeoEM\u5feb2-4\u500d\uff0c\u6210\u529f\u6a21\u62df\u4e864408\u9897\u536b\u661f\u7684Starlink\u661f\u5ea7\u3002", "conclusion": "OpenSN\u5728\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u548c\u529f\u80fd\u6027\u6269\u5c55\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u662fLEO\u536b\u661f\u7f51\u7edc\u7814\u7a76\u7684\u5b9d\u8d35\u5de5\u5177\u3002"}}
{"id": "2507.03317", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.03317", "abs": "https://arxiv.org/abs/2507.03317", "authors": ["Don Tan"], "title": "Low-power Wireless Network with Real-Time Guarantees for Edge-Cloud Applications", "comment": "51 pages, 24 figures", "summary": "The goal of this project is to explore the feasibility of building a scalable\n& easy-to-deploy real-time LoRa testbed, made from multiple units of Raspberry\nPi (RPI), where each RPI manages its own set of LoRa radios. This project is\nmotivated by the lack of concrete large-scale LoRa testbeds that effectively\nintegrate LoRa communications into the real-time world. The paper introduces\nhow the idea of using RPI came about and why it should work in theory. The\npaper then carries out experiments on a component of the large-scale testbed,\nto evaluate the feasibility of the said component based on performance metrics\nsuch as RSSI, SNR, PLR and the ability to carry out millisecond-accurate\ntransmissions. The performance metrics are also used to explore the impact of\nusing different combinations of spread factors and transmission frequencies, as\nwell as making comparisons between time-division multiple access (TDMA) and\ncarrier-sense multiple access (CSMA) approaches. The results show that with the\nright parameters configured, the system can achieve stable and low-latency\ncommunications, proving some feasibility to operate under real-time situations.\nFuture work includes giving each RPI control over more radios, carrying out\ntrue parallel transmissions, and finally integrating multiple RPIs for a more\ncomplete large-scale real-time LoRa testbed.", "AI": {"tldr": "\u63a2\u7d22\u57fa\u4e8e\u6811\u8393\u6d3e\uff08RPI\uff09\u6784\u5efa\u53ef\u6269\u5c55\u3001\u6613\u90e8\u7f72\u7684\u5b9e\u65f6LoRa\u6d4b\u8bd5\u5e73\u53f0\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u6307\u6807\u548c\u5b9e\u65f6\u901a\u4fe1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7f3a\u4e4f\u5927\u89c4\u6a21LoRa\u6d4b\u8bd5\u5e73\u53f0\uff0c\u65e0\u6cd5\u6709\u6548\u5c06LoRa\u901a\u4fe1\u878d\u5165\u5b9e\u65f6\u573a\u666f\u3002", "method": "\u5229\u7528\u591a\u4e2aRPI\u7ba1\u7406\u5404\u81ea\u7684LoRa\u65e0\u7ebf\u7535\uff0c\u5b9e\u9a8c\u8bc4\u4f30\u6027\u80fd\u6307\u6807\uff08RSSI\u3001SNR\u3001PLR\uff09\u53ca\u6beb\u79d2\u7ea7\u4f20\u8f93\u80fd\u529b\uff0c\u6bd4\u8f83\u4e0d\u540c\u6269\u9891\u56e0\u5b50\u3001\u9891\u7387\u7ec4\u5408\u53caTDMA\u4e0eCSMA\u65b9\u6cd5\u3002", "result": "\u914d\u7f6e\u5408\u9002\u53c2\u6570\u540e\uff0c\u7cfb\u7edf\u53ef\u5b9e\u73b0\u7a33\u5b9a\u4f4e\u5ef6\u8fdf\u901a\u4fe1\uff0c\u9a8c\u8bc1\u4e86\u5b9e\u65f6\u64cd\u4f5c\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u6269\u5c55RPI\u63a7\u5236\u7684\u65e0\u7ebf\u7535\u6570\u91cf\u3001\u5b9e\u73b0\u771f\u6b63\u5e76\u884c\u4f20\u8f93\uff0c\u5e76\u6574\u5408\u591a\u4e2aRPI\u4ee5\u6784\u5efa\u5b8c\u6574\u7684\u5927\u89c4\u6a21\u5b9e\u65f6LoRa\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2507.03141", "categories": ["cs.IT", "math.IT", "68P30", "E.4"], "pdf": "https://arxiv.org/pdf/2507.03141", "abs": "https://arxiv.org/abs/2507.03141", "authors": ["Jeremiah Blocki", "Justin Zhang"], "title": "Amortized Locally Decodable Codes for Insertions and Deletions", "comment": null, "summary": "Locally Decodable Codes (LDCs) are error correcting codes which permit the\nrecovery of any single message symbol with a low number of queries to the\ncodeword (the locality). Traditional LDC tradeoffs between the rate, locality,\nand error tolerance are undesirable even in relaxed settings where the\nencoder/decoder share randomness or where the channel is resource-bounded.\nRecent work by Blocki and Zhang initiated the study of Hamming amortized\nLocally Decodable Codes (aLDCs), which allow the local decoder to amortize\ntheir number of queries over the recovery of a small subset of message symbols.\nSurprisingly, Blocki and Zhang construct asymptotically ideal (constant rate,\nconstant amortized locality, and constant error tolerance) Hamming aLDCs in\nprivate-key and resource-bounded settings. While this result overcame previous\nbarriers and impossibility results for Hamming LDCs, it is not clear whether\nthe techniques extend to Insdel LDCs. Constructing Insdel LDCs which are\nresilient to insertion and/or deletion errors is known to be even more\nchallenging.\n  Our first contribution is to provide a Hamming-to-Insdel compiler which\ntransforms any amortized Hamming LDC that satisfies a particular property to\namortized Insdel LDC while asymptotically preserving the rate, error tolerance\nand amortized locality. Prior Hamming-to-Insdel compilers worked for arbitrary\nHamming LDCs, but incurred an undesirable polylogarithmic blow-up in the\nlocality. Our second contribution is a construction of an ideal amortized\nHamming LDC which satisfies our special property in the relaxed settings where\nthe sender/receiver share randomness or where the channel is resource bounded.\nTaken together, we obtain ideal Insdel aLDCs in private-key and\nresource-bounded settings with constant amortized locality, constant rate and\nconstant error tolerance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86Hamming amortized Locally Decodable Codes (aLDCs)\u7684\u6269\u5c55\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06Hamming aLDC\u8f6c\u6362\u4e3aInsdel aLDC\u7684\u7f16\u8bd1\u5668\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6784\u9020\u4e86\u7406\u60f3\u7684Hamming aLDC\u3002", "motivation": "\u4f20\u7edf\u7684Hamming LDC\u5728\u901f\u7387\u3001\u5c40\u90e8\u6027\u548c\u5bb9\u9519\u6027\u4e4b\u95f4\u7684\u6743\u8861\u4e0d\u7406\u60f3\uff0c\u800cBlocki\u548cZhang\u63d0\u51fa\u7684Hamming aLDC\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u7406\u60f3\u6027\u80fd\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u6280\u672f\u662f\u5426\u9002\u7528\u4e8eInsdel LDC\u5c1a\u4e0d\u660e\u786e\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cdHamming-to-Insdel\u7f16\u8bd1\u5668\uff0c\u5c06\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u7684Hamming aLDC\u8f6c\u6362\u4e3aInsdel aLDC\uff1b2. \u5728\u5171\u4eab\u968f\u673a\u6027\u6216\u8d44\u6e90\u53d7\u9650\u4fe1\u9053\u6761\u4ef6\u4e0b\u6784\u9020\u4e86\u7406\u60f3\u7684Hamming aLDC\u3002", "result": "\u5b9e\u73b0\u4e86\u5728\u79c1\u6709\u5bc6\u94a5\u548c\u8d44\u6e90\u53d7\u9650\u8bbe\u7f6e\u4e0b\u5177\u6709\u6052\u5b9a\u901f\u7387\u3001\u6052\u5b9a\u5c40\u90e8\u6027\u548c\u6052\u5b9a\u5bb9\u9519\u6027\u7684\u7406\u60f3Insdel aLDC\u3002", "conclusion": "\u901a\u8fc7\u7f16\u8bd1\u5668\u548c\u7279\u5b9a\u6784\u9020\u7684\u7ed3\u5408\uff0c\u6210\u529f\u6269\u5c55\u4e86Hamming aLDC\u7684\u4f18\u52bf\u5230\u66f4\u5177\u6311\u6218\u6027\u7684Insdel LDC\u9886\u57df\u3002"}}
{"id": "2507.03293", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.03293", "abs": "https://arxiv.org/abs/2507.03293", "authors": ["Anand Gokhale", "Vaibhav Srivastava", "Francesco Bullo"], "title": "LTLCrit: A Temporal Logic-based LLM Critic for Safe and Efficient Embodied Agents", "comment": null, "summary": "Large language models (LLMs) have demonstrated promise in reasoning tasks and\ngeneral decision-making in static environments. In long-term planning tasks,\nhowever, errors tend to accumulate, often leading to unsafe or inefficient\nbehavior, limiting their use in general-purpose settings. We propose a modular\nactor-critic architecture in which an LLM actor is guided by LTLCrit, a\ntrajectory-level LLM critic that communicates via linear temporal logic (LTL).\nOur setup combines the reasoning strengths of language models with the\nguarantees of formal logic. The actor selects high-level actions from natural\nlanguage observations, while the critic analyzes full trajectories and proposes\nnew LTL constraints that shield the actor from future unsafe or inefficient\nbehavior. The architecture supports both fixed, hand-specified safety\nconstraints and adaptive, learned soft constraints that promote long-term\nefficiency. Our architecture is model-agnostic: any LLM-based planner can serve\nas the actor, and LTLCrit serves as a logic-generating wrapper. We formalize\nplanning as graph traversal under symbolic constraints, allowing LTLCrit to\nanalyze failed or suboptimal trajectories and generate new temporal logic rules\nthat improve future behavior. We evaluate our system on the Minecraft\ndiamond-mining benchmark, achieving 100% completion rates and improving\nefficiency compared to baseline LLM planners. Our results suggest that enabling\nLLMs to supervise each other through logic is a powerful and flexible paradigm\nfor safe, generalizable decision making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684actor-critic\u67b6\u6784\uff0c\u901a\u8fc7\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08LTL\uff09\u6307\u5bfcLLM\uff0c\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u5f62\u5f0f\u903b\u8f91\u7684\u4fdd\u8bc1\uff0c\u63d0\u5347\u957f\u671f\u89c4\u5212\u4efb\u52a1\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u957f\u671f\u89c4\u5212\u4efb\u52a1\u4e2d\u56e0\u9519\u8bef\u7d2f\u79ef\u5bfc\u81f4\u7684\u4e0d\u5b89\u5168\u6216\u4f4e\u6548\u884c\u4e3a\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0cLLM actor\u8d1f\u8d23\u9ad8\u5c42\u52a8\u4f5c\u9009\u62e9\uff0cLTLCrit critic\u5206\u6790\u8f68\u8ff9\u5e76\u63d0\u51faLTL\u7ea6\u675f\u3002\u652f\u6301\u56fa\u5b9a\u5b89\u5168\u7ea6\u675f\u548c\u81ea\u9002\u5e94\u8f6f\u7ea6\u675f\u3002", "result": "\u5728Minecraft\u94bb\u77f3\u6316\u6398\u4efb\u52a1\u4e2d\u5b9e\u73b0100%\u5b8c\u6210\u7387\uff0c\u6548\u7387\u4f18\u4e8e\u57fa\u7ebfLLM\u89c4\u5212\u5668\u3002", "conclusion": "\u901a\u8fc7\u903b\u8f91\u76d1\u7763LLM\u662f\u4e00\u79cd\u5f3a\u5927\u4e14\u7075\u6d3b\u7684\u8303\u5f0f\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u3001\u901a\u7528\u7684\u51b3\u7b56\u4efb\u52a1\u3002"}}
{"id": "2507.02977", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.02977", "abs": "https://arxiv.org/abs/2507.02977", "authors": ["Igor Ivanov"], "title": "LLMs are Capable of Misaligned Behavior Under Explicit Prohibition and Surveillance", "comment": "10 pages, 2 figures", "summary": "In this paper, LLMs are tasked with completing an impossible quiz, while they\nare in a sandbox, monitored, told about these measures and instructed not to\ncheat. Some frontier LLMs cheat consistently and attempt to circumvent\nrestrictions despite everything. The results reveal a fundamental tension\nbetween goal-directed behavior and alignment in current LLMs. The code and\nevaluation logs are available at github.com/baceolus/cheating_evals", "AI": {"tldr": "\u524d\u6cbfLLMs\u5728\u53d7\u76d1\u63a7\u7684\u6c99\u76d2\u73af\u5883\u4e2d\u4ecd\u8bd5\u56fe\u4f5c\u5f0a\uff0c\u63ed\u793a\u4e86\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u4e0e\u5bf9\u9f50\u4e4b\u95f4\u7684\u6839\u672c\u77db\u76fe\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u660e\u786e\u88ab\u544a\u77e5\u9650\u5236\u548c\u76d1\u63a7\u7684\u60c5\u51b5\u4e0b\u662f\u5426\u4ecd\u4f1a\u4f5c\u5f0a\uff0c\u4ee5\u63a2\u7d22\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u4e0e\u5bf9\u9f50\u7684\u51b2\u7a81\u3002", "method": "\u5728\u6c99\u76d2\u73af\u5883\u4e2d\u8ba9LLMs\u5b8c\u6210\u4e0d\u53ef\u80fd\u7684\u4efb\u52a1\uff0c\u76d1\u63a7\u5176\u884c\u4e3a\u5e76\u8bb0\u5f55\u4f5c\u5f0a\u5c1d\u8bd5\u3002", "result": "\u90e8\u5206\u524d\u6cbfLLMs\u6301\u7eed\u4f5c\u5f0a\u5e76\u8bd5\u56fe\u89c4\u907f\u9650\u5236\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\u4e0e\u5bf9\u9f50\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u77db\u76fe\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u3002"}}
{"id": "2507.03401", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.03401", "abs": "https://arxiv.org/abs/2507.03401", "authors": ["Hanjian Liu", "Jinsong Gui"], "title": "AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network", "comment": null, "summary": "This paper designs a post-disaster powered communication intelligent network\n(PDPCIN) to address communication disruptions caused by ground base station\n(GBS) failures within the post-disaster area. PDPCIN employs unmanned aerial\nvehicles (UAVs) to provide wireless data collection (WDC) and wireless energy\ntransmission (WET) for affected areas and leverages low earth orbit satellites\n(LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basic\npost-disaster communication while co-optimizing age of information (AoI),\nenergy efficiency, and spectrum efficiency, intelligent synchronization-UAV\n(IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, and\nDynamic multi-LEO access (DMLA) strategy are proposed. However, three key\nchallenges remain: time-varying task-resource imbalances, complex topology\ncaused by multi-device scheduling, and nonlinear coupling in multidimensional\nmetric optimization, making system optimization NP-hard. Therefore, this paper\nproposes a hierarchical heterogeneous graph neural networks (HHGNN) framework.\nIt models heterogeneous device nodes and their communication relations as a\nhierarchical heterogeneous graph structure, integrating our defined graph\nsensing, exchange, and mask layer to handle the network's input, feature\npropagation, and output. To search appropriate number of single-LEO SATs, we\npropose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, we\ncompare the proposed scheme with state-of-the-art benchmarks to validate its\nsuperior collaborative optimization of AoI, energy efficiency, and spectrum\nefficiency. Based on this, we derive the expressions for the expected values of\nAoI and stagnant AoI proportion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u707e\u540e\u4f9b\u7535\u901a\u4fe1\u667a\u80fd\u7f51\u7edc\uff08PDPCIN\uff09\uff0c\u5229\u7528\u65e0\u4eba\u673a\u548c\u4f4e\u8f68\u536b\u661f\u89e3\u51b3\u707e\u540e\u901a\u4fe1\u4e2d\u65ad\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u667a\u80fd\u540c\u6b65\u65e0\u4eba\u673a\u67b6\u6784\u548c\u591a\u7ef4\u6307\u6807\u4f18\u5316\u6846\u67b6\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u3002", "motivation": "\u707e\u540e\u5730\u9762\u57fa\u7ad9\uff08GBS\uff09\u6545\u969c\u5bfc\u81f4\u901a\u4fe1\u4e2d\u65ad\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u7684\u901a\u4fe1\u6062\u590d\u65b9\u6848\u3002", "method": "\u91c7\u7528\u65e0\u4eba\u673a\uff08UAVs\uff09\u8fdb\u884c\u65e0\u7ebf\u6570\u636e\u6536\u96c6\u548c\u80fd\u91cf\u4f20\u8f93\uff0c\u7ed3\u5408\u4f4e\u8f68\u536b\u661f\uff08LEO SATs\uff09\u4e2d\u7ee7\u6570\u636e\uff0c\u5e76\u63d0\u51fa\u4e86\u667a\u80fd\u540c\u6b65\u65e0\u4eba\u673a\u67b6\u6784\u3001\u57fa\u4e8e\u4fe1\u606f\u5e74\u9f84\u7684\u66f4\u65b0\u673a\u5236\u548c\u591aLEO\u63a5\u5165\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5206\u5c42\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HHGNN\uff09\u6846\u67b6\u548c\u5355LEO\u536b\u661f\u5bc6\u5ea6\u4f18\u5316\u7b97\u6cd5\uff08S-LSDO\uff09\uff0c\u5b9e\u73b0\u4e86\u4fe1\u606f\u5e74\u9f84\u3001\u80fd\u6548\u548c\u9891\u8c31\u6548\u7387\u7684\u534f\u540c\u4f18\u5316\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u5728\u591a\u9879\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u4e3a\u707e\u540e\u901a\u4fe1\u6062\u590d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03178", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03178", "abs": "https://arxiv.org/abs/2507.03178", "authors": ["Maiara F. Bollauf", "Hsuan-Yin Lin"], "title": "Generalized Theta Series of a Lattice", "comment": "Paper accepted for presentation at the 2025 IEEE Information Theory\n  Workshop (ITW 2025)", "summary": "Mimicking the idea of the generalized Hamming weight of linear codes, we\nintroduce a new lattice invariant, the generalized theta series. Applications\nrange from identifying stable lattices to the lattice isomorphism problem.\nMoreover, we provide counterexamples for the secrecy gain conjecture on isodual\nlattices, which claims that the ratio of the theta series of an isodual (and\nmore generally, formally unimodular) lattice by the theta series of the integer\nlattice $\\mathbb{Z}^n$ is minimized at a (unique) symmetry point.", "AI": {"tldr": "\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u683c\u4e0d\u53d8\u91cf\u2014\u2014\u5e7f\u4e49theta\u7ea7\u6570\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u8bc6\u522b\u7a33\u5b9a\u683c\u548c\u683c\u540c\u6784\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u540c\u65f6\u53cd\u9a73\u4e86\u5173\u4e8e\u7b49\u5076\u683c\u7684\u4fdd\u5bc6\u589e\u76ca\u731c\u60f3\u3002", "motivation": "\u53d7\u7ebf\u6027\u7801\u7684\u5e7f\u4e49Hamming\u6743\u91cd\u7684\u542f\u53d1\uff0c\u7814\u7a76\u683c\u7684\u65b0\u4e0d\u53d8\u91cf\u53ca\u5176\u5e94\u7528\uff0c\u540c\u65f6\u9a8c\u8bc1\u76f8\u5173\u731c\u60f3\u3002", "method": "\u5f15\u5165\u5e7f\u4e49theta\u7ea7\u6570\u4f5c\u4e3a\u683c\u7684\u65b0\u4e0d\u53d8\u91cf\uff0c\u5e76\u5206\u6790\u5176\u5728\u7a33\u5b9a\u683c\u8bc6\u522b\u548c\u683c\u540c\u6784\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u63d0\u4f9b\u4e86\u7b49\u5076\u683c\u4fdd\u5bc6\u589e\u76ca\u731c\u60f3\u7684\u53cd\u4f8b\uff0c\u8868\u660e\u5176\u6700\u5c0f\u5316\u6761\u4ef6\u4e0d\u6210\u7acb\u3002", "conclusion": "\u5e7f\u4e49theta\u7ea7\u6570\u662f\u7814\u7a76\u683c\u7406\u8bba\u7684\u6709\u529b\u5de5\u5177\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u539f\u6709\u731c\u60f3\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.03525", "categories": ["cs.AI", "cs.SY", "eess.SY", "I.2; K.6; D.2.9"], "pdf": "https://arxiv.org/pdf/2507.03525", "abs": "https://arxiv.org/abs/2507.03525", "authors": ["David Manheim", "Aidan Homewood"], "title": "Limits of Safe AI Deployment: Differentiating Oversight and Control", "comment": null, "summary": "Oversight and control (collectively, supervision) are often invoked as key\nlevers for ensuring that AI systems are accountable, reliable, and able to\nfulfill governance and management requirements. However, the concepts are\nfrequently conflated or insufficiently distinguished in academic and policy\ndiscourse, undermining efforts to design or evaluate systems that should remain\nunder meaningful human supervision.\n  This paper undertakes a targeted critical review of literature on supervision\noutside of AI, along with a brief summary of past work on the topic related to\nAI. We then differentiate control as being ex-ante or real-time, and\noperational rather than policy or governance. In contrast, oversight is either\na policy and governance function, or is ex-post. We suggest that control aims\nto prevent failures. In contrast, oversight often focuses on detection,\nremediation, or incentives for future prevention; all preventative oversight\nstrategies nonetheless necessitate control.\n  Building on this foundation, we make three contributions. First, we propose a\ntheoretically-informed yet policy-grounded framework that articulates the\nconditions under which each mechanism is possible, where they fall short, and\nwhat is required to make them meaningful in practice. Second, we outline how\nsupervision methods should be documented and integrated into risk management,\nand drawing on the Microsoft Responsible AI Maturity Model, we outline a\nmaturity model for AI supervision. Third, we explicitly highlight some\nboundaries of these mechanisms, including where they apply, where they fail,\nand where it is clear that no existing methods suffice. This foregrounds the\nquestion of whether meaningful supervision is possible in a given deployment\ncontext, and can support regulators, auditors, and practitioners in identifying\nboth present limitations and the need for new conceptual and technical\nadvances.", "AI": {"tldr": "\u672c\u6587\u533a\u5206\u4e86AI\u7cfb\u7edf\u4e2d\u7684\u76d1\u7763\u4e0e\u63a7\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6761\u4ef6\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u7531\u4e8e\u5b66\u672f\u548c\u653f\u7b56\u8ba8\u8bba\u4e2d\u5e38\u6df7\u6dc6\u76d1\u7763\u4e0e\u63a7\u5236\uff0c\u5bfc\u81f4\u8bbe\u8ba1\u6216\u8bc4\u4f30\u4eba\u7c7b\u76d1\u7763AI\u7cfb\u7edf\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u672c\u6587\u65e8\u5728\u6f84\u6e05\u4e24\u8005\u7684\u533a\u522b\u53ca\u5176\u5728AI\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u533a\u5206\u76d1\u7763\u4e0e\u63a7\u5236\uff0c\u5e76\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u3001\u6210\u719f\u5ea6\u6a21\u578b\u53ca\u8fb9\u754c\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u3001\u76d1\u7763\u65b9\u6cd5\u7684\u6587\u6863\u5316\u4e0e\u98ce\u9669\u7ba1\u7406\u6574\u5408\u65b9\u6848\uff0c\u4ee5\u53caAI\u76d1\u7763\u7684\u6210\u719f\u5ea6\u6a21\u578b\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u76d1\u7763\u4e0e\u63a7\u5236\u7684\u533a\u522b\u53ca\u5176\u5b9e\u9645\u5e94\u7528\u6761\u4ef6\uff0c\u4e3a\u76d1\u7ba1\u8005\u3001\u5ba1\u8ba1\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u8bc6\u522b\u5c40\u9650\u6027\u548c\u672a\u6765\u9700\u6c42\u7684\u5de5\u5177\u3002"}}
{"id": "2507.03190", "categories": ["cs.AI", "cs.DS", "cs.LG", "es: 68T05, 68T20, 68Q12, 90C27", "I.2.6; I.2.8; F.2.2; F.1.2; G.2.1"], "pdf": "https://arxiv.org/pdf/2507.03190", "abs": "https://arxiv.org/abs/2507.03190", "authors": ["Theo Bourdais", "Abeynaya Gnanasekaran", "Houman Owhadi", "Tuhin Sahai"], "title": "Discovering Algorithms with Computational Language Processing", "comment": "21 pages", "summary": "Algorithms are the engine for reproducible problem-solving. We present a\nframework automating algorithm discovery by conceptualizing them as sequences\nof operations, represented as tokens. These computational tokens are chained\nusing a grammar, enabling the formation of increasingly sophisticated\nprocedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement\nlearning (RL) explores token chaining and drives the creation of new tokens.\nThis methodology rediscovers, improves, and generates new algorithms that\nsubstantially outperform existing methods for strongly NP-hard combinatorial\noptimization problems and foundational quantum computing approaches such as\nGrover's and Quantum Approximate Optimization Algorithm. Operating at the\ncomputational rather than code-generation level, our framework produces\nalgorithms that can be tailored specifically to problem instances, not merely\nclasses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7b97\u6cd5\u53d1\u73b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7b97\u6cd5\u8868\u793a\u4e3a\u64cd\u4f5c\u5e8f\u5217\u7684\u6807\u8bb0\uff0c\u5229\u7528\u8bed\u6cd5\u94fe\u5f0f\u7ec4\u5408\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u751f\u6210\u9ad8\u6027\u80fd\u65b0\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u7ec4\u5408\u4f18\u5316\u548c\u91cf\u5b50\u8ba1\u7b97\u95ee\u9898\uff0c\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\u3002", "method": "\u5c06\u7b97\u6cd5\u8868\u793a\u4e3a\u6807\u8bb0\u5e8f\u5217\uff0c\u5229\u7528\u8bed\u6cd5\u94fe\u5f0f\u7ec4\u5408\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u65b0\u7b97\u6cd5\u3002", "result": "\u751f\u6210\u7684\u7b97\u6cd5\u5728NP\u96be\u95ee\u9898\u548c\u91cf\u5b50\u8ba1\u7b97\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u9488\u5bf9\u5177\u4f53\u95ee\u9898\u5b9e\u4f8b\u751f\u6210\u9ad8\u6548\u7b97\u6cd5\uff0c\u800c\u975e\u4ec5\u9002\u7528\u4e8e\u95ee\u9898\u7c7b\u522b\u3002"}}
{"id": "2507.03873", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.03873", "abs": "https://arxiv.org/abs/2507.03873", "authors": ["Tianlang He", "Zhangyu Chang", "S. -H. Gary Chan"], "title": "RateCount: Learning-Free Device Counting by Wi-Fi Probe Listening", "comment": null, "summary": "A Wi-Fi-enabled device, or simply Wi-Fi device, sporadically broadcasts probe\nrequest frames (PRFs) to discover nearby access points (APs), whether connected\nto an AP or not. To protect user privacy, unconnected devices often randomize\ntheir MAC addresses in the PRFs, known as MAC address randomization. While\nprior works have achieved accurate device counting under MAC address\nrandomization, they typically rely on machine learning, resulting in\ninefficient deployment due to the time-consuming processes of data cleaning,\nmodel training, and hyperparameter tuning. To enhance deployment efficiency, we\npropose RateCount, an accurate, lightweight, and learning-free counting\napproach based on the rate at which APs receive PRFs within a window. RateCount\nemploys a provably unbiased closed-form expression to estimate the device count\ntime-averaged over the window and an error model to compute the lower bound of\nthe estimation variance. We also demonstrate how to extend RateCount to people\ncounting by incorporating a device-to-person calibration scheme. Through\nextensive real-world experiments conducted at multiple sites spanning a wide\nrange of counts, we show that RateCount, without any deployment costs for\nmachine learning, achieves comparable counting accuracy with the\nstate-of-the-art learning-based device counting and improves previous people\ncounting schemes by a large margin.", "AI": {"tldr": "RateCount\u662f\u4e00\u79cd\u65e0\u9700\u673a\u5668\u5b66\u4e60\u7684\u8f7b\u91cf\u7ea7\u8bbe\u5907\u8ba1\u6570\u65b9\u6cd5\uff0c\u901a\u8fc7AP\u63a5\u6536PRF\u7684\u901f\u7387\u4f30\u8ba1\u8bbe\u5907\u6570\u91cf\uff0c\u51c6\u786e\u6027\u9ad8\u4e14\u90e8\u7f72\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u5728MAC\u5730\u5740\u968f\u673a\u5316\u4e0b\u8bbe\u5907\u8ba1\u6570\u6548\u7387\u4f4e\uff0c\u9700\u8981\u6570\u636e\u6e05\u6d17\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u8c03\u53c2\uff0c\u90e8\u7f72\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faRateCount\uff0c\u5229\u7528AP\u63a5\u6536PRF\u7684\u901f\u7387\uff0c\u901a\u8fc7\u65e0\u504f\u95ed\u5f0f\u8868\u8fbe\u5f0f\u4f30\u8ba1\u8bbe\u5907\u6570\u91cf\uff0c\u5e76\u5efa\u7acb\u8bef\u5dee\u6a21\u578b\u8ba1\u7b97\u65b9\u5dee\u4e0b\u9650\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRateCount\u5728\u8bbe\u5907\u8ba1\u6570\u51c6\u786e\u6027\u4e0a\u4e0e\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u4eba\u5458\u8ba1\u6570\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "RateCount\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u4e14\u65e0\u9700\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8bbe\u5907\u548c\u4eba\u5458\u8ba1\u6570\uff0c\u90e8\u7f72\u6210\u672c\u4f4e\u3002"}}
{"id": "2507.03332", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03332", "abs": "https://arxiv.org/abs/2507.03332", "authors": ["Huiying Liu", "Hongwei Liu"], "title": "Function-Correcting Codes with Homogeneous Distance", "comment": null, "summary": "Function-correcting codes are designed to reduce redundancy of codes when\nprotecting function values of information against errors. As generalizations of\nHamming weights and Lee weights over $ \\mathbb{Z}_{4} $, homogeneous weights\nare used in codes over finite rings. In this paper, we introduce\nfunction-correcting codes with homogeneous distance denoted by FCCHDs, which\nextend function-correcting codes with Hamming distance. We first define $ D\n$-homogeneous distance codes. We use $ D $-homogenous distance codes to\ncharacterize connections between the optimal redundancy of FCCHDs and lengths\nof these codes for some matrices $ D $. By these connections, we obtain several\nbounds of the optimal redundancy of FCCHDs for some functions. In addition, we\nalso construct FCCHDs for homogeneous weight functions and homogeneous weight\ndistribution functions. Specially, redundancies of some codes we construct in\nthis paper reach the optimal redundancy bounds.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u9f50\u6b21\u8ddd\u79bb\u7684\u51fd\u6570\u6821\u6b63\u7801\uff08FCCHDs\uff09\uff0c\u6269\u5c55\u4e86\u6c49\u660e\u8ddd\u79bb\u7684\u51fd\u6570\u6821\u6b63\u7801\u3002\u901a\u8fc7\u5b9a\u4e49D-\u9f50\u6b21\u8ddd\u79bb\u7801\uff0c\u7814\u7a76\u4e86FCCHDs\u7684\u6700\u4f18\u5197\u4f59\u4e0e\u7801\u957f\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u7ed9\u51fa\u4e86\u67d0\u4e9b\u51fd\u6570\u7684\u6700\u4f18\u5197\u4f59\u754c\u9650\u3002\u6b64\u5916\uff0c\u8fd8\u6784\u9020\u4e86\u9488\u5bf9\u9f50\u6b21\u6743\u91cd\u51fd\u6570\u548c\u9f50\u6b21\u6743\u91cd\u5206\u5e03\u51fd\u6570\u7684FCCHDs\uff0c\u90e8\u5206\u6784\u9020\u7684\u7801\u8fbe\u5230\u4e86\u6700\u4f18\u5197\u4f59\u754c\u9650\u3002", "motivation": "\u4f20\u7edf\u51fd\u6570\u6821\u6b63\u7801\u5728\u4fdd\u62a4\u4fe1\u606f\u51fd\u6570\u503c\u514d\u53d7\u9519\u8bef\u5f71\u54cd\u65f6\u5b58\u5728\u5197\u4f59\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u9f50\u6b21\u8ddd\u79bb\uff0c\u6269\u5c55\u51fd\u6570\u6821\u6b63\u7801\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u4f18\u5316\u5176\u5197\u4f59\u6027\u80fd\u3002", "method": "\u5b9a\u4e49\u4e86D-\u9f50\u6b21\u8ddd\u79bb\u7801\uff0c\u5229\u7528\u5176\u7279\u6027\u7814\u7a76FCCHDs\u7684\u6700\u4f18\u5197\u4f59\u4e0e\u7801\u957f\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u77e9\u9635D\u7684\u5206\u6790\uff0c\u63a8\u5bfc\u51fa\u67d0\u4e9b\u51fd\u6570\u7684\u6700\u4f18\u5197\u4f59\u754c\u9650\uff0c\u5e76\u6784\u9020\u4e86\u9488\u5bf9\u9f50\u6b21\u6743\u91cd\u51fd\u6570\u548c\u9f50\u6b21\u6743\u91cd\u5206\u5e03\u51fd\u6570\u7684FCCHDs\u3002", "result": "\u5f97\u5230\u4e86FCCHDs\u7684\u6700\u4f18\u5197\u4f59\u754c\u9650\uff0c\u5e76\u6210\u529f\u6784\u9020\u4e86\u90e8\u5206\u8fbe\u5230\u6700\u4f18\u5197\u4f59\u754c\u9650\u7684\u7801\u3002", "conclusion": "FCCHDs\u5728\u9f50\u6b21\u8ddd\u79bb\u4e0b\u6269\u5c55\u4e86\u51fd\u6570\u6821\u6b63\u7801\u7684\u529f\u80fd\uff0c\u5e76\u901a\u8fc7\u6784\u9020\u548c\u7406\u8bba\u5206\u6790\u5c55\u793a\u4e86\u5176\u5728\u4f18\u5316\u5197\u4f59\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.03950", "categories": ["cs.NI", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.03950", "abs": "https://arxiv.org/abs/2507.03950", "authors": ["Yizhou Luo", "Kwan-Wu Chin", "Ruyi Guan", "Xi Xiao", "Caimeng Wang", "Jingyin Feng", "Tengjiao He"], "title": "Optimizing Age of Trust and Throughput in Multi-Hop UAV-Aided IoT Networks", "comment": null, "summary": "Devices operating in Internet of Things (IoT) networks may be deployed across\nvast geographical areas and interconnected via multi-hop communications.\nFurther, they may be unguarded. This makes them vulnerable to attacks and\nmotivates operators to check on devices frequently. To this end, we propose and\nstudy an Unmanned Aerial Vehicle (UAV)-aided attestation framework for use in\nIoT networks with a charging station powered by solar. A key challenge is\noptimizing the trajectory of the UAV to ensure it attests as many devices as\npossible. A trade-off here is that devices being checked by the UAV are\noffline, which affects the amount of data delivered to a gateway. Another\nchallenge is that the charging station experiences time-varying energy\narrivals, which in turn affect the flight duration and charging schedule of the\nUAV. To address these challenges, we employ a Deep Reinforcement Learning (DRL)\nsolution to optimize the UAV's charging schedule and the selection of devices\nto be attested during each flight. The simulation results show that our\nsolution reduces the average age of trust by 88% and throughput loss due to\nattestation by 30%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\uff08UAV\uff09\u7684\u7269\u8054\u7f51\uff08IoT\uff09\u8bbe\u5907\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4f18\u5316\u65e0\u4eba\u673a\u7684\u5145\u7535\u8ba1\u5212\u548c\u8bbe\u5907\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u4efb\u5ea6\u548c\u7f51\u7edc\u541e\u5410\u91cf\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u5206\u5e03\u5e7f\u6cdb\u4e14\u6613\u53d7\u653b\u51fb\uff0c\u9700\u8981\u9891\u7e41\u68c0\u67e5\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u3002\u65e0\u4eba\u673a\u8ba4\u8bc1\u6846\u67b6\u53ef\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4f18\u5316\u65e0\u4eba\u673a\u7684\u5145\u7535\u8ba1\u5212\u548c\u8bbe\u5907\u9009\u62e9\uff0c\u4ee5\u5e94\u5bf9\u80fd\u91cf\u4f9b\u5e94\u4e0d\u7a33\u5b9a\u548c\u8bbe\u5907\u79bb\u7ebf\u7684\u6311\u6218\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u65b9\u6848\u5c06\u4fe1\u4efb\u5e73\u5747\u5e74\u9f84\u964d\u4f4e88%\uff0c\u8ba4\u8bc1\u5bfc\u81f4\u7684\u541e\u5410\u91cf\u635f\u5931\u51cf\u5c1130%\u3002", "conclusion": "\u65e0\u4eba\u673a\u8ba4\u8bc1\u6846\u67b6\u7ed3\u5408DRL\u80fd\u6709\u6548\u63d0\u5347\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5b89\u5168\u6027\u548c\u7f51\u7edc\u6027\u80fd\u3002"}}
{"id": "2507.03223", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03223", "abs": "https://arxiv.org/abs/2507.03223", "authors": ["Jeshwanth Challagundla"], "title": "SI-Agent: An Agentic Framework for Feedback-Driven Generation and Tuning of Human-Readable System Instructions for Large Language Models", "comment": null, "summary": "System Instructions (SIs), or system prompts, are pivotal for guiding Large\nLanguage Models (LLMs) but manual crafting is resource-intensive and often\nsuboptimal. Existing automated methods frequently generate non-human-readable\n\"soft prompts,\" sacrificing interpretability. This paper introduces SI-Agent, a\nnovel agentic framework designed to automatically generate and iteratively\nrefine human-readable SIs through a feedback-driven loop. SI-Agent employs\nthree collaborating agents: an Instructor Agent, an Instruction Follower Agent\n(target LLM), and a Feedback/Reward Agent evaluating task performance and\noptionally SI readability. The framework utilizes iterative cycles where\nfeedback guides the Instructor's refinement strategy (e.g., LLM-based editing,\nevolutionary algorithms). We detail the framework's architecture, agent roles,\nthe iterative refinement process, and contrast it with existing methods. We\npresent experimental results validating SI-Agent's effectiveness, focusing on\nmetrics for task performance, SI readability, and efficiency. Our findings\nindicate that SI-Agent generates effective, readable SIs, offering a favorable\ntrade-off between performance and interpretability compared to baselines.\nPotential implications include democratizing LLM customization and enhancing\nmodel transparency. Challenges related to computational cost and feedback\nreliability are acknowledged.", "AI": {"tldr": "SI-Agent\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u4eba\u7c7b\u53ef\u8bfb\u7cfb\u7edf\u6307\u4ee4\uff08SIs\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u5faa\u73af\u63d0\u5347\u6027\u80fd\u4e0e\u53ef\u8bfb\u6027\u3002", "motivation": "\u624b\u52a8\u8bbe\u8ba1\u7cfb\u7edf\u6307\u4ee4\uff08SIs\uff09\u8017\u65f6\u4e14\u6548\u679c\u4e0d\u4f73\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u727a\u7272\u53ef\u8bfb\u6027\u3002", "method": "SI-Agent\u91c7\u7528\u4e09\u4e2a\u534f\u4f5c\u4ee3\u7406\uff08Instructor\u3001Follower\u3001Feedback\uff09\u548c\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u4f18\u5316SIs\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSI-Agent\u5728\u4efb\u52a1\u6027\u80fd\u3001\u53ef\u8bfb\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SI-Agent\u5728\u6027\u80fd\u548c\u53ef\u8bfb\u6027\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u6709\u671b\u63a8\u52a8LLM\u5b9a\u5236\u5316\u548c\u900f\u660e\u5ea6\u63d0\u5347\u3002"}}
{"id": "2507.03444", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03444", "abs": "https://arxiv.org/abs/2507.03444", "authors": ["Aida Koch", "Alix Petit"], "title": "Set Shaping Theory and the Foundations of Redundancy-Free Testable Codes", "comment": null, "summary": "To render a sequence testable, namely capable of identifying and detecting\nerrors, it is necessary to apply a transformation that increases its length by\nintroducing statistical dependence among symbols, as commonly exemplified by\nthe addition of parity bits. However, since the decoder does not have prior\nknowledge of the original symbols, it must treat the artificially introduced\nsymbols as if they were independent. Consequently, these additional symbols\nmust be transmitted, even though their conditional probability, under ideal and\nerror free conditions, would be zero. This sequence extension implies that not\nall symbol combinations of the new length are practically realizable: if an\nerror modifies a sequence, making it inadmissible such an error becomes\ndetectable. Recent developments in Set Shaping Theory have revealed a\nsurprising result: it is always possible to transform a sequence into a longer\nversion by carefully selecting which longer sequences are allowed, in such a\nway that the overall set of sequences becomes more structured and less complex\nthan the original. This means that even though the sequence is extended and\ndependencies are introduced between symbols, the total amount of information\ncontained in the new set does not increase proportionally on the contrary, it\ncan be slightly reduced. In other words, one can construct a new set of longer\nsequences where each one corresponds uniquely to an original sequence, but the\nentire set is designed in such a way that it can be treated as if the symbols\nwere independent, making encoding simpler. This allows sequence to become\ntestable capable of detecting errors without adding visible redundancy or\nincreasing the informational content.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6269\u5c55\u5e8f\u5217\u957f\u5ea6\u5e76\u5f15\u5165\u7edf\u8ba1\u4f9d\u8d56\u6027\u7684\u65b9\u6cd5\uff0c\u4f7f\u5e8f\u5217\u53ef\u6d4b\u8bd5\u4e14\u80fd\u68c0\u6d4b\u9519\u8bef\uff0c\u540c\u65f6\u4e0d\u589e\u52a0\u4fe1\u606f\u91cf\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u6dfb\u52a0\u5197\u4f59\uff08\u5982\u5947\u5076\u6821\u9a8c\u4f4d\uff09\u4f7f\u5e8f\u5217\u53ef\u6d4b\u8bd5\uff0c\u4f46\u9700\u8981\u4f20\u8f93\u989d\u5916\u7b26\u53f7\u4e14\u589e\u52a0\u4fe1\u606f\u91cf\u3002\u672c\u6587\u65e8\u5728\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\uff0c\u5728\u4e0d\u589e\u52a0\u4fe1\u606f\u91cf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5e8f\u5217\u7684\u53ef\u6d4b\u8bd5\u6027\u3002", "method": "\u5229\u7528\u96c6\u5408\u5851\u5f62\u7406\u8bba\uff0c\u5c06\u539f\u59cb\u5e8f\u5217\u6269\u5c55\u4e3a\u66f4\u957f\u7684\u5e8f\u5217\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u65b0\u5e8f\u5217\u96c6\u5408\u7684\u7ed3\u6784\uff0c\u4f7f\u5176\u7b26\u53f7\u95f4\u4f9d\u8d56\u6027\u53ef\u88ab\u89c6\u4e3a\u72ec\u7acb\uff0c\u4ece\u800c\u7b80\u5316\u7f16\u7801\u3002", "result": "\u65b0\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u4fe1\u606f\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u5e8f\u5217\u5177\u5907\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u4e14\u65b0\u5e8f\u5217\u96c6\u5408\u7684\u7ed3\u6784\u66f4\u7b80\u5355\u3002", "conclusion": "\u901a\u8fc7\u96c6\u5408\u5851\u5f62\u7406\u8bba\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5e8f\u5217\u7684\u53ef\u6d4b\u8bd5\u6027\uff0c\u540c\u65f6\u907f\u514d\u4fe1\u606f\u91cf\u7684\u589e\u52a0\u548c\u5197\u4f59\u7684\u5f15\u5165\u3002"}}
{"id": "2507.04425", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.04425", "abs": "https://arxiv.org/abs/2507.04425", "authors": ["Zexin Deng", "Zhenhui Yuan", "Longhao Zou"], "title": "TeleSim: A Network-Aware Testbed and Benchmark Dataset for Telerobotic Applications", "comment": null, "summary": "Telerobotic technologies are becoming increasingly essential in fields such\nas remote surgery, nuclear decommissioning, and space exploration. Reliable\ndatasets and testbeds are essential for evaluating telerobotic system\nperformance prior to real-world deployment. However, there is a notable lack of\ndatasets that capture the impact of network delays, as well as testbeds that\nrealistically model the communication link between the operator and the robot.\nThis paper introduces TeleSim, a network-aware teleoperation dataset and\ntestbed designed to assess the performance of telerobotic applications under\ndiverse network conditions. TeleSim systematically collects performance data\nfrom fine manipulation tasks executed under three predefined network quality\ntiers: High, Medium, and Low. Each tier is characterized through controlled\nsettings of bandwidth, latency, jitter, and packet loss. Using OMNeT++ for\nprecise network simulation, we record a wide range of metrics, including\ncompletion time, success rates, video quality indicators (Peak Signal-to-Noise\nRatio (PSNR) and Structural Similarity Index Measure (SSIM)), and quality of\nservice (QoS) parameters. TeleSim comprises 300 experimental trials, providing\na robust benchmark for evaluating teleoperation systems across heterogeneous\nnetwork scenarios. In the worst network condition, completion time increases by\n221.8% and success rate drops by 64%. Our findings reveal that network\ndegradation leads to compounding negative impacts, notably reduced video\nquality and prolonged task execution, highlighting the need for adaptive,\nresilient teleoperation protocols. The full dataset and testbed software are\npublicly available on our GitHub repository:\nhttps://github.com/ConnectedRoboticsLab and YouTube channel:\nhttps://youtu.be/Fz_1iOYe104.", "AI": {"tldr": "TeleSim\u662f\u4e00\u4e2a\u7f51\u7edc\u611f\u77e5\u7684\u9065\u64cd\u4f5c\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u7f51\u7edc\u6761\u4ef6\u4e0b\u7684\u9065\u64cd\u4f5c\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u7f51\u7edc\u5ef6\u8fdf\u5f71\u54cd\u7684\u6355\u6349\uff0cTeleSim\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7OMNeT++\u6a21\u62df\u4e09\u79cd\u7f51\u7edc\u8d28\u91cf\u7b49\u7ea7\uff08\u9ad8\u3001\u4e2d\u3001\u4f4e\uff09\uff0c\u6536\u96c6\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u3001\u6210\u529f\u7387\u3001\u89c6\u9891\u8d28\u91cf\u7b49\u6307\u6807\u3002", "result": "\u5728\u6700\u5dee\u7f51\u7edc\u6761\u4ef6\u4e0b\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u589e\u52a0221.8%\uff0c\u6210\u529f\u7387\u4e0b\u964d64%\u3002", "conclusion": "\u7f51\u7edc\u9000\u5316\u5bf9\u9065\u64cd\u4f5c\u6027\u80fd\u6709\u663e\u8457\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u5f00\u53d1\u81ea\u9002\u5e94\u534f\u8bae\u3002"}}
{"id": "2507.03226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03226", "abs": "https://arxiv.org/abs/2507.03226", "authors": ["Congmin Min", "Rhea Mathew", "Joyce Pan", "Sahil Bansal", "Abbas Keshavarzi", "Amar Viswanathan Kannan"], "title": "Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems", "comment": null, "summary": "We propose a scalable and cost-efficient framework for deploying Graph-based\nRetrieval Augmented Generation (GraphRAG) in enterprise environments. While\nGraphRAG has shown promise for multi-hop reasoning and structured retrieval,\nits adoption has been limited by the high computational cost of constructing\nknowledge graphs using large language models (LLMs) and the latency of\ngraph-based retrieval. To address these challenges, we introduce two core\ninnovations: (1) a dependency-based knowledge graph construction pipeline that\nleverages industrial-grade NLP libraries to extract entities and relations from\nunstructured text completely eliminating reliance on LLMs; and (2) a\nlightweight graph retrieval strategy that combines hybrid query node\nidentification with efficient one-hop traversal for high-recall, low-latency\nsubgraph extraction. We evaluate our framework on two SAP datasets focused on\nlegacy code migration and demonstrate strong empirical performance. Our system\nachieves up to 15% and 4.35% improvements over traditional RAG baselines based\non LLM-as-Judge and RAGAS metrics, respectively. Moreover, our dependency-based\nconstruction approach attains 94% of the performance of LLM-generated knowledge\ngraphs (61.87% vs. 65.83%) while significantly reducing cost and improving\nscalability. These results validate the feasibility of deploying GraphRAG\nsystems in real-world, large-scale enterprise applications without incurring\nprohibitive resource requirements paving the way for practical, explainable,\nand domain-adaptable retrieval-augmented reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6210\u672c\u9ad8\u6548\u7684GraphRAG\u6846\u67b6\uff0c\u7528\u4e8e\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u591a\u8df3\u63a8\u7406\u548c\u7ed3\u6784\u5316\u68c0\u7d22\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "GraphRAG\u5728\u591a\u8df3\u63a8\u7406\u548c\u7ed3\u6784\u5316\u68c0\u7d22\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4e24\u79cd\u521b\u65b0\uff1a1) \u57fa\u4e8e\u4f9d\u8d56\u5173\u7cfb\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7ba1\u9053\uff0c\u5b8c\u5168\u6446\u8131\u5bf9LLM\u7684\u4f9d\u8d56\uff1b2) \u8f7b\u91cf\u7ea7\u56fe\u68c0\u7d22\u7b56\u7565\uff0c\u7ed3\u5408\u6df7\u5408\u67e5\u8be2\u8282\u70b9\u8bc6\u522b\u548c\u4e00\u8df3\u904d\u5386\u3002", "result": "\u5728SAP\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6027\u80fd\u63d0\u534715%\u548c4.35%\uff0c\u4f9d\u8d56\u6784\u5efa\u65b9\u6cd5\u8fbe\u5230LLM\u751f\u6210\u56fe\u8c3194%\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6210\u672c\u3002", "conclusion": "\u9a8c\u8bc1\u4e86GraphRAG\u5728\u5927\u89c4\u6a21\u4f01\u4e1a\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5b9e\u7528\u3001\u53ef\u89e3\u91ca\u548c\u9886\u57df\u9002\u5e94\u7684\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.04001", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04001", "abs": "https://arxiv.org/abs/2507.04001", "authors": ["Mohammed Zain Farooqi", "Masoud Hemmatpour", "Tore Heide Larsen"], "title": "In-Network Memory Access: Bridging SmartNIC and Host Memory", "comment": null, "summary": "SmartNICs have been increasingly utilized across various applications to\noffload specific computational tasks, thereby enhancing overall system\nperformance. However, this offloading process introduces several communication\nchallenges that must be addressed for effective integration. A key challenge\nlies in establishing efficient communication between the offloaded components\nand the main application running on the host. In this study, we evaluate\ndifferent approaches for achieving memory access between the host and SmartNIC.\nWe analyze memory access performance on both the SmartNIC and the host to\nsupport in-network applications and guide the selection of an appropriate\nmemory access design.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86SmartNIC\u4e0e\u4e3b\u673a\u4e4b\u95f4\u7684\u5185\u5b58\u8bbf\u95ee\u6027\u80fd\uff0c\u4ee5\u4f18\u5316\u901a\u4fe1\u6548\u7387\u3002", "motivation": "SmartNIC\u7684\u5e7f\u6cdb\u5e94\u7528\u5e26\u6765\u4e86\u901a\u4fe1\u6311\u6218\uff0c\u5c24\u5176\u662f\u4e3b\u673a\u4e0e\u5378\u8f7d\u7ec4\u4ef6\u4e4b\u95f4\u7684\u9ad8\u6548\u901a\u4fe1\u9700\u6c42\u3002", "method": "\u8bc4\u4f30\u4e86\u4e0d\u540c\u5185\u5b58\u8bbf\u95ee\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86SmartNIC\u548c\u4e3b\u673a\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u4e3a\u7f51\u7edc\u5185\u5e94\u7528\u63d0\u4f9b\u4e86\u5185\u5b58\u8bbf\u95ee\u8bbe\u8ba1\u7684\u6307\u5bfc\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9009\u62e9\u5408\u9002\u7684\u901a\u4fe1\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2507.03449", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03449", "abs": "https://arxiv.org/abs/2507.03449", "authors": ["Xuanlin Shen", "Xin Wei", "Weidong Mei", "Zhi Chen", "Jun Fang", "Boyu Ning"], "title": "Movable-Antenna-Enhanced Physical-Layer Service Integration: Performance Analysis and Optimization", "comment": "Accepted to IEEE Communications Letters", "summary": "Movable antennas (MAs) have drawn increasing attention in wireless\ncommunications due to their capability to create favorable channel conditions\nvia local movement within a confined region. In this letter, we investigate its\napplication in physical-layer service integration (PHY-SI), where a multi-MA\nbase station (BS) simultaneously transmits both confidential and multicast\nmessages to two users. The multicast message is intended for both users, while\nthe confidential message is intended only for one user and must remain\nperfectly secure from the other. Our goal is to jointly optimize the secrecy\nand multicast beamforming, as well as the MAs' positions at the BS to maximize\nthe secrecy rate for one user while satisfying the multicast rate requirement\nfor both users. To gain insights, we first conduct performance analysis of this\nMA-enhanced PHY-SI system in two special cases, revealing its unique\ncharacteristics compared to conventional PHY-SI with fixed-position antennas\n(FPAs). To address the secrecy rate maximization problem, we propose a\ntwo-layer optimization framework that integrates the semidefinite relaxation\n(SDR) technique and a discrete sampling algorithm. Numerical results\ndemonstrate that MAs can greatly enhance the achievable secrecy rate region for\nPHY-SI compared to FPAs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u53ef\u79fb\u52a8\u5929\u7ebf\uff08MAs\uff09\u5728\u7269\u7406\u5c42\u670d\u52a1\u96c6\u6210\uff08PHY-SI\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u548c\u5929\u7ebf\u4f4d\u7f6e\uff0c\u63d0\u5347\u4fdd\u5bc6\u901f\u7387\u548c\u6ee1\u8db3\u591a\u64ad\u901f\u7387\u9700\u6c42\u3002", "motivation": "\u53ef\u79fb\u52a8\u5929\u7ebf\u56e0\u5176\u80fd\u5728\u6709\u9650\u533a\u57df\u5185\u901a\u8fc7\u5c40\u90e8\u79fb\u52a8\u6539\u5584\u4fe1\u9053\u6761\u4ef6\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u672c\u6587\u63a2\u7d22\u5176\u5728PHY-SI\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u534a\u5b9a\u677e\u5f1b\uff08SDR\uff09\u6280\u672f\u548c\u79bb\u6563\u91c7\u6837\u7b97\u6cd5\uff0c\u4f18\u5316\u4fdd\u5bc6\u6ce2\u675f\u6210\u5f62\u3001\u591a\u64ad\u6ce2\u675f\u6210\u5f62\u53ca\u5929\u7ebf\u4f4d\u7f6e\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\uff08FPAs\uff09\uff0cMAs\u80fd\u663e\u8457\u63d0\u5347PHY-SI\u7684\u4fdd\u5bc6\u901f\u7387\u533a\u57df\u3002", "conclusion": "\u53ef\u79fb\u52a8\u5929\u7ebf\u5728PHY-SI\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.04589", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.04589", "abs": "https://arxiv.org/abs/2507.04589", "authors": ["Zien Wang", "Xiucheng Wang", "Nan Cheng", "Wenchao Xu", "Wei Quan", "Ruijin Sun", "Conghao Zhou"], "title": "On-Demand Multimedia Delivery in 6G: An Optimal-Cost Steiner Tree Approach", "comment": null, "summary": "The exponential growth of multimedia data traffic in 6G networks poses\nunprecedented challenges for immersive communication, where\nultra-high-definition, multi-quality streaming must be delivered on demand\nwhile minimizing network operational costs. Traditional routing approaches,\nsuch as shortest-path algorithms, fail to optimize flow multiplexing across\nmultiple destinations, while conventional Steiner tree methods cannot\naccommodate heterogeneous quality-of-service (QoS) requirements-a critical need\nfor 6G's personalized services. In this paper, we address a fundamental but\nunsolved challenge: the minimum flow problem (MFP) with multi-destination,\nheterogeneous outflow demands, which is pivotal for efficient multimedia\ndistribution such as adaptive-resolution video streaming. To overcome the\nlimitations of existing methods, we propose a two-stage dynamic\nprogramming-enhanced On-demand Steiner Tree (OST) algorithm, the first approach\nthat jointly optimizes flow aggregation and QoS-aware path selection for\narbitrary outflow requirements. We rigorously prove the optimality of OST using\nmathematical induction, demonstrating that it guarantees the minimum-cost\nmulticast flow under differentiated service constraints. Extensive experiments\nin 6G-like multimedia transmission scenarios show that OST reduces total\nnetwork flow by over 10% compared to state-of-the-art methods while ensuring\non-demand QoS fulfillment. The complete code is available at\nhttps://github.com/UNIC-Lab/OST.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u52a8\u6001\u89c4\u5212\u589e\u5f3a\u7684\u6309\u9700Steiner\u6811\uff08OST\uff09\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e866G\u7f51\u7edc\u4e2d\u591a\u5a92\u4f53\u6570\u636e\u6d41\u7684\u6700\u5c0f\u6d41\u95ee\u9898\uff08MFP\uff09\uff0c\u4f18\u5316\u4e86\u6d41\u805a\u5408\u548cQoS\u611f\u77e5\u8def\u5f84\u9009\u62e9\u3002", "motivation": "6G\u7f51\u7edc\u4e2d\u591a\u5a92\u4f53\u6570\u636e\u6d41\u91cf\u7684\u6fc0\u589e\u5bf9\u6c89\u6d78\u5f0f\u901a\u4fe1\u63d0\u51fa\u4e86\u524d\u6240\u672a\u6709\u7684\u6311\u6218\uff0c\u4f20\u7edf\u8def\u7531\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u591a\u76ee\u7684\u5730\u548c\u5f02\u6784QoS\u9700\u6c42\u3002", "method": "\u63d0\u51faOST\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u52a8\u6001\u89c4\u5212\u8054\u5408\u4f18\u5316\u6d41\u805a\u5408\u548cQoS\u611f\u77e5\u8def\u5f84\u9009\u62e9\uff0c\u5e76\u6570\u5b66\u8bc1\u660e\u5176\u6700\u4f18\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOST\u57286G\u591a\u5a92\u4f53\u4f20\u8f93\u573a\u666f\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c11\u603b\u7f51\u7edc\u6d41\u91cf10%\u4ee5\u4e0a\uff0c\u540c\u65f6\u6ee1\u8db3\u6309\u9700QoS\u3002", "conclusion": "OST\u662f\u9996\u4e2a\u80fd\u540c\u65f6\u4f18\u5316\u6d41\u805a\u5408\u548cQoS\u611f\u77e5\u8def\u5f84\u9009\u62e9\u7684\u7b97\u6cd5\uff0c\u4e3a6G\u591a\u5a92\u4f53\u5206\u53d1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03254", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03254", "abs": "https://arxiv.org/abs/2507.03254", "authors": ["Bruce Yang", "Xinfeng He", "Huan Gao", "Yifan Cao", "Xiaofan Li", "David Hsu"], "title": "CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs", "comment": null, "summary": "Effective prompt design is essential for improving the planning capabilities\nof large language model (LLM)-driven agents. However, existing structured\nprompting strategies are typically limited to single-agent, plan-only settings,\nand often evaluate performance solely based on task accuracy - overlooking\ncritical factors such as token efficiency, modularity, and scalability in\nmulti-agent environments. To address these limitations, we introduce\nCodeAgents, a prompting framework that codifies multi-agent reasoning and\nenables structured, token-efficient planning in multi-agent systems. In\nCodeAgents, all components of agent interaction - Task, Plan, Feedback, system\nroles, and external tool invocations - are codified into modular pseudocode\nenriched with control structures (e.g., loops, conditionals), boolean logic,\nand typed variables. This design transforms loosely connected agent plans into\ncohesive, interpretable, and verifiable multi-agent reasoning programs. We\nevaluate the proposed framework across three diverse benchmarks - GAIA,\nHotpotQA, and VirtualHome - using a range of representative LLMs. Results show\nconsistent improvements in planning performance, with absolute gains of 3-36\npercentage points over natural language prompting baselines. On VirtualHome,\nour method achieves a new state-of-the-art success rate of 56%. In addition,\nour approach reduces input and output token usage by 55-87% and 41-70%,\nrespectively, underscoring the importance of token-aware evaluation metrics in\nthe development of scalable multi-agent LLM systems. The code and resources are\navailable at: https://anonymous.4open.science/r/CodifyingAgent-5A86", "AI": {"tldr": "CodeAgents\u662f\u4e00\u4e2a\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4f2a\u4ee3\u7801\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u89c4\u5212\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u51c6\u786e\u6027\u548c\u4ee4\u724c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7ed3\u6784\u5316\u63d0\u793a\u7b56\u7565\u5c40\u9650\u4e8e\u5355\u667a\u80fd\u4f53\u73af\u5883\uff0c\u4e14\u5ffd\u89c6\u4ee4\u724c\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0cCodeAgents\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5c06\u667a\u80fd\u4f53\u4ea4\u4e92\u7ec4\u4ef6\uff08\u4efb\u52a1\u3001\u8ba1\u5212\u3001\u53cd\u9988\u7b49\uff09\u7f16\u7801\u4e3a\u6a21\u5757\u5316\u4f2a\u4ee3\u7801\uff0c\u7ed3\u5408\u63a7\u5236\u7ed3\u6784\u548c\u903b\u8f91\u53d8\u91cf\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u53473-36%\uff0c\u4ee4\u724c\u4f7f\u7528\u51cf\u5c1155-87%\u3002", "conclusion": "CodeAgents\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u4ee4\u724c\u6548\u7387\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.04081", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04081", "abs": "https://arxiv.org/abs/2507.04081", "authors": ["Xudong Wang", "Lei Feng", "Jiacheng Wang", "Hongyang Du", "Changyuan Zhao", "Wenjing Li", "Zehui Xiong", "Dusit Niyato", "Ping Zhang"], "title": "Graph Diffusion-Based AeBS Deployment and Resource Allocation for RSMA-Enabled URLLC Low-Altitude Economy Networks", "comment": "15 pages, 9 figures", "summary": "As a key component of low-altitude economic networks, aerial base stations\n(AeBSs) provide flexible and reliable wireless coverage to support 6G\nultra-reliable and low-latency communication (URLLC) services. However, limited\nspectrum resources and severe co-channel interference pose significant\nchallenges to the deployment and resource allocation of AeBSs. To address these\nlimitations, this paper proposes a novel rate-splitting multiple access\n(RSMA)-enabled transmission design to flexibly manage interference and\neffectively enhance URLLC services in spectrum-constrained multi-AeBS networks.\nOn this basis, we formulate a joint optimization problem involving AeBS\ndeployment, user association, and resource allocation to maximize the\nachievable sum rate and coverage of the total system. Given the NP-hard nature\nof the problem and the highly dynamic environment, we propose a novel\nalternating optimization framework based on the generative graph diffusion\nmodels. Specifically, we model AeBSs and ground users as graph nodes, then we\nemploy a discrete graph generation process solved via denoising diffusion is\nemployed to explore the combinatorial space of deployment and association\nstrategies. Moreover, the algorithm adopts the successive convex approximation\n(SCA) method to optimize AeBS beamforming and RSMA rate allocation under finite\nblocklength constraints. Extensive simulations demonstrate that the proposed\nalgorithm outperforms existing methods in terms of convergence speed, sum rate,\nand coverage, while also exhibiting robust performance under varying network\ndensities and interference levels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRSMA\u7684\u4f20\u8f93\u8bbe\u8ba1\uff0c\u7528\u4e8e\u4f18\u5316\u591aAeBS\u7f51\u7edc\u4e2d\u7684\u5e72\u6270\u7ba1\u7406\u548c\u8d44\u6e90\u5206\u914d\uff0c\u901a\u8fc7\u751f\u6210\u56fe\u6269\u6563\u6a21\u578b\u548cSCA\u65b9\u6cd5\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u548c\u8986\u76d6\u8303\u56f4\u3002", "motivation": "6G\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\uff08URLLC\uff09\u670d\u52a1\u9700\u8981\u7075\u6d3b\u7684\u65e0\u7ebf\u8986\u76d6\uff0c\u4f46\u6709\u9650\u7684\u9891\u8c31\u8d44\u6e90\u548c\u4e25\u91cd\u7684\u540c\u9891\u5e72\u6270\u5bf9AeBS\u7684\u90e8\u7f72\u548c\u8d44\u6e90\u5206\u914d\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u91c7\u7528\u751f\u6210\u56fe\u6269\u6563\u6a21\u578b\u8fdb\u884cAeBS\u90e8\u7f72\u548c\u7528\u6237\u5173\u8054\u7684\u8054\u5408\u4f18\u5316\uff0c\u5e76\u7ed3\u5408SCA\u65b9\u6cd5\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u548cRSMA\u901f\u7387\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u3001\u603b\u901f\u7387\u548c\u8986\u76d6\u8303\u56f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9891\u8c31\u53d7\u9650\u7684\u591aAeBS\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e72\u6270\u7ba1\u7406\u548c\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86URLLC\u670d\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2507.03461", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03461", "abs": "https://arxiv.org/abs/2507.03461", "authors": ["Ahmad Ismail", "Rapha\u00ebl Le Bidan", "Elsa Dupraz", "Charbel Abdel Nour"], "title": "Learning Variable Node Selection for Improved Multi-Round Belief Propagation Decoding", "comment": "5 pages, 4 figures. Accepted for publication at the Int. Symp. on\n  Topics in Coding (ISTC) 2025, Los Angeles, CA, USA, Aug. 2025", "summary": "Error correction at short blocklengths remains a challenge for low-density\nparity-check (LDPC) codes, as belief propagation (BP) decoding is suboptimal\ncompared to maximum-likelihood decoding (MLD). While BP rarely makes errors, it\noften fails to converge due to a small number of problematic, erroneous\nvariable nodes (VNs). Multi-round BP (MRBP) decoding improves performance by\nidentifying and perturbing these VNs, enabling BP to succeed in subsequent\ndecoding attempts. However, existing heuristic approaches for VN identification\nmay require a large number of decoding rounds to approach ML performance. In\nthis work, we draw a connection between identifying candidate VNs to perturb in\nMRBP and estimating channel output errors, a problem previously addressed by\nsyndrome-based neural decoders (SBND). Leveraging this insight, we propose an\nSBND-inspired neural network architecture that learns to predict which VNs MRBP\nneeds to focus on. Experimental results demonstrate that the proposed learning\napproach outperforms expert rules from the literature, requiring fewer MRBP\ndecoding attempts to reach near-MLD performance. This makes it a promising lead\nfor improving the decoding of short LDPC codes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u9884\u6d4b\u9700\u8981\u6270\u52a8\u7684\u53d8\u91cf\u8282\u70b9\uff0c\u63d0\u5347\u77edLDPC\u7801\u7684\u89e3\u7801\u6027\u80fd\u3002", "motivation": "\u77ed\u5757\u957fLDPC\u7801\u7684\u7ea0\u9519\u6027\u80fd\u4e0d\u8db3\uff0c\u4f20\u7edfBP\u89e3\u7801\u5668\u56e0\u65e0\u6cd5\u6536\u655b\u800c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\uff08SBND\u542f\u53d1\uff09\u9884\u6d4b\u9700\u8981\u6270\u52a8\u7684\u53d8\u91cf\u8282\u70b9\uff0c\u4f18\u5316\u591a\u8f6eBP\u89e3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u80fd\u4ee5\u66f4\u5c11\u8f6e\u6b21\u63a5\u8fd1\u6700\u5927\u4f3c\u7136\u89e3\u7801\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63d0\u5347\u77edLDPC\u7801\u89e3\u7801\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.04594", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.04594", "abs": "https://arxiv.org/abs/2507.04594", "authors": ["Niloofar Shadab", "Tyler Cody", "Alejandro Salado", "Taylan G. Topcu", "Mohammad Shadab", "Peter Beling"], "title": "Exploring Core and Periphery Precepts in Biological and Artificial Intelligence: An Outcome-Based Perspective", "comment": null, "summary": "Engineering methodologies predominantly revolve around established principles\nof decomposition and recomposition. These principles involve partitioning\ninputs and outputs at the component level, ensuring that the properties of\nindividual components are preserved upon composition. However, this view does\nnot transfer well to intelligent systems, particularly when addressing the\nscaling of intelligence as a system property. Our prior research contends that\nthe engineering of general intelligence necessitates a fresh set of overarching\nsystems principles. As a result, we introduced the \"core and periphery\"\nprinciples, a novel conceptual framework rooted in abstract systems theory and\nthe Law of Requisite Variety. In this paper, we assert that these abstract\nconcepts hold practical significance. Through empirical evidence, we illustrate\ntheir applicability to both biological and artificial intelligence systems,\nbridging abstract theory with real-world implementations. Then, we expand on\nour previous theoretical framework by mathematically defining core-dominant vs\nperiphery-dominant systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\u539f\u5219\u201c\u6838\u5fc3\u4e0e\u5916\u56f4\u201d\uff0c\u7528\u4e8e\u89e3\u51b3\u667a\u80fd\u7cfb\u7edf\u6269\u5c55\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u5176\u5728\u751f\u7269\u548c\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u5de5\u7a0b\u65b9\u6cd5\u5728\u667a\u80fd\u7cfb\u7edf\u6269\u5c55\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u65b0\u7684\u7cfb\u7edf\u539f\u5219\u6765\u652f\u6301\u901a\u7528\u667a\u80fd\u7684\u5de5\u7a0b\u5316\u3002", "method": "\u57fa\u4e8e\u62bd\u8c61\u7cfb\u7edf\u7406\u8bba\u548c\u5fc5\u8981\u591a\u6837\u6027\u6cd5\u5219\uff0c\u63d0\u51fa\u201c\u6838\u5fc3\u4e0e\u5916\u56f4\u201d\u539f\u5219\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u5b9a\u4e49\u6838\u5fc3\u4e3b\u5bfc\u4e0e\u5916\u56f4\u4e3b\u5bfc\u7cfb\u7edf\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u539f\u5219\u9002\u7528\u4e8e\u751f\u7269\u548c\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff0c\u8fde\u63a5\u4e86\u62bd\u8c61\u7406\u8bba\u4e0e\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u201c\u6838\u5fc3\u4e0e\u5916\u56f4\u201d\u539f\u5219\u4e3a\u667a\u80fd\u7cfb\u7edf\u5de5\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.03267", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.03267", "abs": "https://arxiv.org/abs/2507.03267", "authors": ["Jie Peng", "Jiarui Ji", "Runlin Lei", "Zhewei Wei", "Yongchao Liu", "Chuntao Hong"], "title": "GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning", "comment": null, "summary": "Dynamic Text-Attributed Graphs (DyTAGs), which intricately integrate\nstructural, temporal, and textual attributes, are crucial for modeling complex\nreal-world systems. However, most of the existing DyTAG datasets exhibit poor\ntextual quality, which severely limits their utility for DyTAG generation tasks\nrequiring semantically rich inputs. Additionally, prior work mainly focuses on\ndiscriminative tasks on DyTAGs, resulting in a lack of standardized task\nformulations and evaluation protocols tailored for DyTAG generation. To address\nthese critical issues, we propose Generative DyTAG Benchmark (GDGB), which\ncomprises eight meticulously curated DyTAG datasets with high-quality textual\nfeatures for both nodes and edges, overcoming limitations of prior datasets.\nBuilding on GDGB, we define two novel DyTAG generation tasks: Transductive\nDynamic Graph Generation (TDGG) and Inductive Dynamic Graph Generation (IDGG).\nTDGG transductively generates a target DyTAG based on the given source and\ndestination node sets, while the more challenging IDGG introduces new node\ngeneration to inductively model the dynamic expansion of real-world graph data.\nTo enable holistic evaluation, we design multifaceted metrics that assess the\nstructural, temporal, and textual quality of the generated DyTAGs. We further\npropose GAG-General, an LLM-based multi-agent generative framework tailored for\nreproducible and robust benchmarking of DyTAG generation. Experimental results\ndemonstrate that GDGB enables rigorous evaluation of TDGG and IDGG, with key\ninsights revealing the critical interplay of structural and textual features in\nDyTAG generation. These findings establish GDGB as a foundational resource for\nadvancing generative DyTAG research and unlocking further practical\napplications in DyTAG generation. GDGB datasets, source codes, and leaderboards\nare available at \\href{https://gdgb-algo.github.io/}{here}.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86GDGB\u57fa\u51c6\uff0c\u7528\u4e8e\u52a8\u6001\u6587\u672c\u5c5e\u6027\u56fe\uff08DyTAG\uff09\u7684\u751f\u6210\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u6587\u672c\u8d28\u91cf\u5dee\u548c\u4efb\u52a1\u6807\u51c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709DyTAG\u6570\u636e\u96c6\u6587\u672c\u8d28\u91cf\u5dee\uff0c\u7f3a\u4e4f\u751f\u6210\u4efb\u52a1\u7684\u6807\u51c6\u5316\u8bc4\u4f30\uff0c\u9650\u5236\u4e86DyTAG\u751f\u6210\u4efb\u52a1\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faGDGB\u57fa\u51c6\uff0c\u5305\u542b\u516b\u4e2a\u9ad8\u8d28\u91cf\u6587\u672c\u7279\u5f81\u7684DyTAG\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u4e86\u4e24\u4e2a\u65b0\u4efb\u52a1\uff08TDGG\u548cIDGG\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6307\u6807\u3002", "result": "GDGB\u652f\u6301\u5bf9TDGG\u548cIDGG\u7684\u4e25\u683c\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u7ed3\u6784\u548c\u6587\u672c\u7279\u5f81\u5728DyTAG\u751f\u6210\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "GDGB\u4e3a\u751f\u6210DyTAG\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86DyTAG\u751f\u6210\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.04421", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04421", "abs": "https://arxiv.org/abs/2507.04421", "authors": ["Wanqing Tu"], "title": "Resource-Efficient Seamless Transitions For High-Performance Multi-hop UAV Multicasting", "comment": null, "summary": "Many UAV-related applications require group communications between UAVs to\nreliably and efficiently deliver rich media content as well as to extend\nline-of-sight coverage between sky and ground. This paper studies fast yet\nresource-efficient UAV transitions while maintaining high multicasting\nperformance. We develop a set of analytic and algorithmic results to form the\nefficient transition formation (ETF) algorithm that deals with different UAV\ntransition scenarios in a multicasting environment. The ETF algorithm first\nevaluates the seamlessness of a straight-line trajectory (SLT), by processing\nlow-complexity computations (e.g., Euclidean distances) or a chain of fast\nchecks with controlled traffic overheads. For an interrupted SLT, ETF\nestablishes a new trajectory consisting of a minimum number of seamless\nstraight lines that join at specially selected locations in terms of\ncontrolling mobile UAVs' seamless travel distances. Our simulation studies\nquantify the multicasting performance gains that ETF allows, outperforming\ncompared studies when seamlessly transiting UAV group members.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u4eba\u673a\u8fc7\u6e21\u7b97\u6cd5\uff08ETF\uff09\uff0c\u7528\u4e8e\u5728\u7ec4\u64ad\u73af\u5883\u4e2d\u4f18\u5316\u65e0\u4eba\u673a\u7684\u8f68\u8ff9\uff0c\u786e\u4fdd\u65e0\u7f1d\u8fc7\u6e21\u548c\u9ad8\u6027\u80fd\u7ec4\u64ad\u3002", "motivation": "\u65e0\u4eba\u673a\u5e94\u7528\u9700\u8981\u9ad8\u6548\u7684\u7ec4\u64ad\u901a\u4fe1\u4ee5\u4f20\u8f93\u4e30\u5bcc\u5a92\u4f53\u5185\u5bb9\u5e76\u6269\u5c55\u8986\u76d6\u8303\u56f4\uff0c\u56e0\u6b64\u9700\u8981\u5feb\u901f\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u65e0\u4eba\u673a\u8fc7\u6e21\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86ETF\u7b97\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u76f4\u7ebf\u8f68\u8ff9\u7684\u65e0\u7f1d\u6027\uff0c\u5e76\u5728\u4e2d\u65ad\u65f6\u751f\u6210\u7531\u6700\u5c11\u65e0\u7f1d\u76f4\u7ebf\u7ec4\u6210\u7684\u65b0\u8f68\u8ff9\u3002", "result": "\u4eff\u771f\u7814\u7a76\u8868\u660e\uff0cETF\u5728\u65e0\u7f1d\u8fc7\u6e21\u65e0\u4eba\u673a\u7ec4\u6210\u5458\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ec4\u64ad\u6027\u80fd\u3002", "conclusion": "ETF\u7b97\u6cd5\u5728\u65e0\u4eba\u673a\u7ec4\u64ad\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8f68\u8ff9\u4f18\u5316\u548c\u65e0\u7f1d\u8fc7\u6e21\u3002"}}
{"id": "2507.03481", "categories": ["cs.IT", "math.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.03481", "abs": "https://arxiv.org/abs/2507.03481", "authors": ["AmirPouya Moeini", "Albert Guill\u00e9n i F\u00e0bregas"], "title": "Class-Based Expurgation Attains Csisz\u00e1r's Expurgated Source-Channel Exponent", "comment": null, "summary": "This paper studies expurgated error exponents for joint source-channel coding\nfor discrete memoryless sources and channels. We consider a partition of the\nsource messages into classes, where the codeword distributions depend on the\nclass. We show that two carefully chosen classes suffice to achieve Csisz\\'ar's\nexpurgated exponent.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u79bb\u6563\u65e0\u8bb0\u5fc6\u6e90\u548c\u4fe1\u9053\u7684\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u7684\u51c0\u5316\u8bef\u5dee\u6307\u6570\uff0c\u901a\u8fc7\u5c06\u6e90\u6d88\u606f\u5212\u5206\u4e3a\u7c7b\u522b\u5e76\u8bbe\u8ba1\u4f9d\u8d56\u7c7b\u522b\u7684\u7801\u5b57\u5206\u5e03\uff0c\u8bc1\u660e\u4e86\u4ec5\u9700\u4e24\u7c7b\u5373\u53ef\u8fbe\u5230Csisz\u00e1r\u7684\u51c0\u5316\u6307\u6570\u3002", "motivation": "\u7814\u7a76\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u7684\u8bef\u5dee\u6027\u80fd\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u6d88\u606f\u5206\u7c7b\u548c\u7801\u5b57\u5206\u5e03\u8bbe\u8ba1\u6765\u63d0\u9ad8\u8bef\u5dee\u6307\u6570\u3002", "method": "\u5c06\u6e90\u6d88\u606f\u5212\u5206\u4e3a\u4e0d\u540c\u7c7b\u522b\uff0c\u5e76\u6839\u636e\u7c7b\u522b\u8bbe\u8ba1\u7801\u5b57\u5206\u5e03\uff0c\u901a\u8fc7\u7cbe\u5fc3\u9009\u62e9\u4e24\u7c7b\u6d88\u606f\u5b9e\u73b0\u4f18\u5316\u3002", "result": "\u8bc1\u660e\u4ec5\u9700\u4e24\u7c7b\u6d88\u606f\u5373\u53ef\u8fbe\u5230Csisz\u00e1r\u7684\u51c0\u5316\u8bef\u5dee\u6307\u6570\uff0c\u7b80\u5316\u4e86\u5b9e\u73b0\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5408\u7406\u7684\u6d88\u606f\u5206\u7c7b\u548c\u7801\u5b57\u5206\u5e03\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u7684\u8bef\u5dee\u6027\u80fd\uff0c\u4e14\u5b9e\u73b0\u7b80\u5355\u3002"}}
{"id": "2507.03285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03285", "abs": "https://arxiv.org/abs/2507.03285", "authors": ["Jianyu Zhang", "L\u00e9on Bottou"], "title": "Memory Mosaics at scale", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.14751", "summary": "Memory Mosaics [Zhang et al., 2025], networks of associative memories, have\ndemonstrated appealing compositional and in-context learning capabilities on\nmedium-scale networks (GPT-2 scale) and synthetic small datasets. This work\nshows that these favorable properties remain when we scale memory mosaics to\nlarge language model sizes (llama-8B scale) and real-world datasets.\n  To this end, we scale memory mosaics to 10B size, we train them on one\ntrillion tokens, we introduce a couple architectural modifications (\"Memory\nMosaics v2\"), we assess their capabilities across three evaluation dimensions:\ntraining-knowledge storage, new-knowledge storage, and in-context learning.\n  Throughout the evaluation, memory mosaics v2 match transformers on the\nlearning of training knowledge (first dimension) and significantly outperforms\ntransformers on carrying out new tasks at inference time (second and third\ndimensions). These improvements cannot be easily replicated by simply\nincreasing the training data for transformers. A memory mosaics v2 trained on\none trillion tokens still perform better on these tasks than a transformer\ntrained on eight trillion tokens.", "AI": {"tldr": "Memory Mosaics v2\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\uff08\u5982llama-8B\uff09\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u8bad\u7ec3\u77e5\u8bc6\u5b58\u50a8\u3001\u65b0\u77e5\u8bc6\u5b58\u50a8\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8eTransformer\u3002", "motivation": "\u9a8c\u8bc1Memory Mosaics\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u5c06Memory Mosaics\u6269\u5c55\u523010B\u89c4\u6a21\uff0c\u8bad\u7ec31\u4e07\u4ebftoken\uff0c\u5e76\u5f15\u5165\u67b6\u6784\u6539\u8fdb\uff08Memory Mosaics v2\uff09\uff0c\u8bc4\u4f30\u5176\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u80fd\u529b\u3002", "result": "Memory Mosaics v2\u5728\u8bad\u7ec3\u77e5\u8bc6\u5b58\u50a8\u4e0a\u4e0eTransformer\u76f8\u5f53\uff0c\u5728\u65b0\u4efb\u52a1\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e0a\u663e\u8457\u4f18\u4e8eTransformer\u3002", "conclusion": "Memory Mosaics v2\u5728\u6027\u80fd\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e14\u65e0\u6cd5\u901a\u8fc7\u7b80\u5355\u589e\u52a0Transformer\u7684\u8bad\u7ec3\u6570\u636e\u6765\u590d\u5236\u5176\u6548\u679c\u3002"}}
{"id": "2507.03507", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03507", "abs": "https://arxiv.org/abs/2507.03507", "authors": ["Chenliang Yang", "Guangchi Zhang", "Miao Cui", "Qingqing Wu", "Yong Zeng"], "title": "Near-Field Codebook-Based 3D Spherical Channel Estimation for UCA XL-MIMO Systems", "comment": "This paper has been accepted by IEEE WCL", "summary": "Extremely large-scale multiple input multiple output (XL-MIMO), a key\ntechnology for 6G communications, faces challenges in near-field channel\nestimation due to spherical wavefronts and the need for three-dimensional (3D)\nspatial characterization, particularly with uniform circular arrays (UCAs).\nThis letter proposes a spherical-domain simultaneous orthogonal matching\npursuit (S-SOMP) based scheme tailored for near-field 3D channel estimation in\nUCA-equipped XL-MIMO systems. We establish a sparse channel representation\nbased on the near-field spherical wave model. Then, a novel spherical-domain\ntransform matrix codebook is designed via joint discrete sampling of distance,\nazimuth, and elevation parameters, leveraging analytical approximations to\nensure low correlation between steering vectors. This structured codebook\nenables accurate sparse signal recovery using the S-SOMP algorithm for\nefficient joint estimation of channel path gains, spatial angles, and\ndistances. Simulation results demonstrate significant channel estimation\naccuracy improvements compared to existing benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7403\u5f62\u57dfS-SOMP\u7684\u65b9\u6848\uff0c\u7528\u4e8eUCA XL-MIMO\u7cfb\u7edf\u4e2d\u7684\u8fd1\u573a3D\u4fe1\u9053\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3XL-MIMO\u5728\u8fd1\u573a\u4fe1\u9053\u4f30\u8ba1\u4e2d\u9762\u4e34\u7684\u7403\u9762\u6ce2\u524d\u548c3D\u7a7a\u95f4\u8868\u5f81\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u8fd1\u573a\u7403\u9762\u6ce2\u6a21\u578b\u5efa\u7acb\u7a00\u758f\u4fe1\u9053\u8868\u793a\uff0c\u8bbe\u8ba1\u7403\u5f62\u57df\u53d8\u6362\u77e9\u9635\u7801\u672c\uff0c\u5229\u7528S-SOMP\u7b97\u6cd5\u8fdb\u884c\u8054\u5408\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684S-SOMP\u65b9\u6848\u4e3aUCA XL-MIMO\u7cfb\u7edf\u7684\u8fd1\u573a3D\u4fe1\u9053\u4f30\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03589", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03589", "abs": "https://arxiv.org/abs/2507.03589", "authors": ["Di Wu", "Zhuoyin Dai", "Yong Zeng"], "title": "You May Use the Same Channel Knowledge Map for Environment-Aware NLoS Sensing and Communication", "comment": null, "summary": "As one of the key usage scenarios for the sixth generation (6G) wireless\nnetworks, integrated sensing and communication (ISAC) provides an efficient\nframework to achieve simultaneous wireless sensing and communication. However,\ntraditional wireless sensing techniques mainly rely on the line-of-sight (LoS)\nassumptions, i.e., the sensing targets are directly visible to both the sensing\ntransmitter and receiver. This hinders ISAC systems to be applied in complex\nenvironments such as the urban low-altitude airspace, which usually suffers\nfrom signal blockage and non-line-of-sight (NLoS) multi-path propagation. To\naddress this challenge, in this paper, we propose a novel approach to enable\nenvironment-aware NLoS ISAC by leveraging the new technique called channel\nknowledge map (CKM), which was originally proposed for environment-aware\nwireless communications. One major novelty of our proposed method is that the\nsame CKM built for wireless communication can be directly used to enable NLoS\nwireless sensing, thus enjoying the benefits of ``killing two birds with one\nstone''. To this end, the sensing targets are treated as virtual user equipment\n(UE), and the wireless communication channel priors are transformed into the\nsensing channel priors, allowing one single CKM to serve dual purposes. We\nillustrate our proposed framework by a specific CKM called \\emph{channel\nangle-delay map} (CADM). Specifically, the proposed framework utilizes CADM to\nderive angle-delay priors of the sensing channel by exploiting the relationship\nbetween communication and sensing angle-delay distributions, enabling sensing\ntarget localization in the challenging NLoS environment. Extensive simulation\nresults demonstrate significant performance improvements over classic\ngeometry-based sensing methods, which is further validated by Cram\\'er-Rao\nLower Bound (CRLB) analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u9053\u77e5\u8bc6\u56fe\uff08CKM\uff09\u7684\u975e\u89c6\u8ddd\uff08NLoS\uff09\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u901a\u4fe1\u4fe1\u9053\u5148\u9a8c\u8f6c\u5316\u4e3a\u611f\u77e5\u4fe1\u9053\u5148\u9a8c\uff0c\u5b9e\u73b0\u590d\u6742\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u611f\u77e5\u3002", "motivation": "\u4f20\u7edf\u65e0\u7ebf\u611f\u77e5\u6280\u672f\u4f9d\u8d56\u89c6\u8ddd\u5047\u8bbe\uff0c\u9650\u5236\u4e86ISAC\u5728\u590d\u6742\u73af\u5883\uff08\u5982\u57ce\u5e02\u4f4e\u7a7a\uff09\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528CKM\u6280\u672f\uff0c\u5c06\u901a\u4fe1\u4fe1\u9053\u5148\u9a8c\u8f6c\u5316\u4e3a\u611f\u77e5\u4fe1\u9053\u5148\u9a8c\uff0c\u901a\u8fc7\u865a\u62df\u7528\u6237\u8bbe\u5907\uff08UE\uff09\u5b9e\u73b0NLoS\u611f\u77e5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u51e0\u4f55\u65b9\u6cd5\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u5e76\u901a\u8fc7CRLB\u5206\u6790\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u590d\u6742\u73af\u5883\u4e0b\u7684NLoS\u611f\u77e5\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u4e0e\u611f\u77e5\u7684\u53cc\u8d62\u3002"}}
{"id": "2507.03329", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03329", "abs": "https://arxiv.org/abs/2507.03329", "authors": ["Devendra Patel", "Aaditya Jain", "Jayant Verma", "Divyansh Rajput", "Sunil Mahala", "Ketki Suresh Khapare", "Jayateja Kalla"], "title": "NDAI-NeuroMAP: A Neuroscience-Specific Embedding Model for Domain-Specific Retrieval", "comment": "The document consists of 15 pages in total: the first 13 pages\n  comprise the main paper, while the last two pages contain supplementary\n  material", "summary": "We present NDAI-NeuroMAP, the first neuroscience-domain-specific dense vector\nembedding model engineered for high-precision information retrieval tasks. Our\nmethodology encompasses the curation of an extensive domain-specific training\ncorpus comprising 500,000 carefully constructed triplets\n(query-positive-negative configurations), augmented with 250,000\nneuroscience-specific definitional entries and 250,000 structured\nknowledge-graph triplets derived from authoritative neurological ontologies. We\nemploy a sophisticated fine-tuning approach utilizing the\nFremyCompany/BioLORD-2023 foundation model, implementing a multi-objective\noptimization framework combining contrastive learning with triplet-based metric\nlearning paradigms. Comprehensive evaluation on a held-out test dataset\ncomprising approximately 24,000 neuroscience-specific queries demonstrates\nsubstantial performance improvements over state-of-the-art general-purpose and\nbiomedical embedding models. These empirical findings underscore the critical\nimportance of domain-specific embedding architectures for neuroscience-oriented\nRAG systems and related clinical natural language processing applications.", "AI": {"tldr": "NDAI-NeuroMAP\u662f\u9996\u4e2a\u4e13\u4e3a\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u8bbe\u8ba1\u7684\u9ad8\u7cbe\u5ea6\u4fe1\u606f\u68c0\u7d22\u5bc6\u96c6\u5411\u91cf\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u901a\u7528\u548c\u751f\u7269\u533b\u5b66\u5d4c\u5165\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u9886\u57df\u7279\u5b9a\u5d4c\u5165\u67b6\u6784\u7684\u91cd\u8981\u6027\u3002", "method": "\u5229\u752850\u4e07\u7cbe\u5fc3\u6784\u5efa\u7684\u4e09\u5143\u7ec4\u300125\u4e07\u795e\u7ecf\u79d1\u5b66\u5b9a\u4e49\u6761\u76ee\u548c25\u4e07\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\uff0c\u57fa\u4e8eFremyCompany/BioLORD-2023\u6a21\u578b\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u5fae\u8c03\u3002", "result": "\u57282.4\u4e07\u795e\u7ecf\u79d1\u5b66\u67e5\u8be2\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u901a\u7528\u548c\u751f\u7269\u533b\u5b66\u5d4c\u5165\u6a21\u578b\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u5d4c\u5165\u67b6\u6784\u5bf9\u795e\u7ecf\u79d1\u5b66RAG\u7cfb\u7edf\u548c\u4e34\u5e8aNLP\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.04734", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04734", "abs": "https://arxiv.org/abs/2507.04734", "authors": ["Mathieu Leonardon", "Mohammed El Houcine Ayoubi", "Adrien Cassagne", "Romain Tajan", "Camille Leroux"], "title": "Low-Latency Software Polar Encoders and Decoders for Short Blocklengths", "comment": null, "summary": "This paper presents our low-latency Polar code encoders and decoders\ndeveloped for the 2025 International Symposium on Topics in Coding (ISTC 2025)\ncontest, which challenges participants to implement the fastest possible\nchannel code encoders and decoders in terms of average and maximum latency on a\nCPU target. Our solution is based on Polar codes with an Adaptive Successive\nCancellation List (ASCL) decoder. We introduce a novel ASCL unrolled decoder\ngenerator. We conduct an extensive exploration of the design space, including\ncode construction, CRC selection, and list size, to identify optimal trade-offs\nbetween signal-to-noise ratio and decoding time across various operating\npoints. The considered operating points are frame error rates of 10^{-3} and\n10^{-5}, information bit lengths of 64, 128, 256, and 512, and code rates of\n1/4, 1/2, and 4/5. We also propose an optimized bit-packed encoder. All\nimplementations of the encoders and decoders, along with the code construction\nand the unrolled decoders generator, are released as open source in the AFF3CT\ntoolbox.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf92025\u5e74\u56fd\u9645\u7f16\u7801\u4e13\u9898\u7814\u8ba8\u4f1a\uff08ISTC 2025\uff09\u7ade\u8d5b\u5f00\u53d1\u7684\u4f4e\u5ef6\u8fdfPolar\u7801\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u8fde\u7eed\u53d6\u6d88\u5217\u8868\uff08ASCL\uff09\u89e3\u7801\u5668\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u9896\u7684ASCL\u5c55\u5f00\u89e3\u7801\u5668\u751f\u6210\u5668\u3002", "motivation": "\u7ade\u8d5b\u8981\u6c42\u5b9e\u73b0\u6700\u4f4e\u5ef6\u8fdf\u7684\u4fe1\u9053\u7801\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4f18\u5316Polar\u7801\u548cASCL\u89e3\u7801\u5668\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff08\u5305\u62ec\u7801\u6784\u9020\u3001CRC\u9009\u62e9\u548c\u5217\u8868\u5927\u5c0f\uff09\u548c\u4f18\u5316\u7684\u6bd4\u7279\u6253\u5305\u7f16\u7801\u5668\uff0c\u5bfb\u627e\u4fe1\u566a\u6bd4\u548c\u89e3\u7801\u65f6\u95f4\u7684\u6700\u4f73\u5e73\u8861\u3002", "result": "\u5728\u4e0d\u540c\u5e27\u9519\u8bef\u7387\u548c\u4fe1\u606f\u6bd4\u7279\u957f\u5ea6\u4e0b\uff0c\u5b9e\u73b0\u4e86\u4f18\u5316\u7684\u6027\u80fd\uff0c\u5e76\u5c06\u6240\u6709\u5b9e\u73b0\u5f00\u6e90\u5728AFF3CT\u5de5\u5177\u7bb1\u4e2d\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4f4e\u5ef6\u8fdfPolar\u7801\u7f16\u7801\u548c\u89e3\u7801\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u5de5\u5177\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.03799", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03799", "abs": "https://arxiv.org/abs/2507.03799", "authors": ["Jin Xu", "Weiqi Wang", "Natarajan Gautam"], "title": "On the Distribution of Age of Information in Time-varying Updating Systems", "comment": "32 pages, 10 figures", "summary": "Age of Information (AoI) is a crucial metric for quantifying information\nfreshness in real-time systems where the sampling rate of data packets is\ntime-varying. Evaluating AoI under such conditions is challenging, as system\nstates become temporally correlated and traditional stationary analysis is\ninapplicable. We investigate an $M_{t}/G/1/1$ queueing system with a\ntime-varying sampling rate and probabilistic preemption, proposing a novel\nanalytical framework based on multi-dimensional partial differential equations\n(PDEs) to capture the time evolution of the system's status distribution. To\nsolve the PDEs, we develop a decomposition technique that breaks the\nhigh-dimensional PDE into lower-dimensional subsystems. Solving these\nsubsystems allows us to derive the Aol distribution at arbitrary time\ninstances. We show AoI does not exhibit a memoryless property, even with\nnegligible processing times, due to its dependence on the historical sampling\nprocess. Our framework extends to the stationary setting, where we derive a\nclosed-form expression for the Laplace-Stieltjes Transform (LST) of the\nsteady-state AoI. Numerical experiments reveal AoI exhibits a non-trivial lag\nin response to sampling rate changes. Our results also show that no single\npreemption probability or processing time distribution can minimize Aol\nviolation probability across all thresholds in either time-varying or\nstationary scenarios. Finally, we formulate an optimization problem and propose\na heuristic method to find sampling rates that reduce costs while satisfying\nAoI constraints.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u65f6\u53d8\u91c7\u6837\u7387\u4e0b\u4fe1\u606f\u5e74\u9f84\uff08AoI\uff09\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u7ef4\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86AoI\u7684\u975e\u65e0\u8bb0\u5fc6\u7279\u6027\u53ca\u5176\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\uff0c\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08AoI\uff09\u662f\u4e00\u4e2a\u5173\u952e\u6307\u6807\uff0c\u4f46\u65f6\u53d8\u91c7\u6837\u7387\u5bfc\u81f4\u7cfb\u7edf\u72b6\u6001\u65f6\u95f4\u76f8\u5173\uff0c\u4f20\u7edf\u7a33\u6001\u5206\u6790\u4e0d\u9002\u7528\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u7ef4PDEs\u7684\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6280\u672f\u5c06\u9ad8\u7ef4PDE\u964d\u7ef4\u6c42\u89e3\uff0c\u63a8\u5bfcAoI\u5206\u5e03\uff0c\u5e76\u6269\u5c55\u5230\u7a33\u6001\u573a\u666f\u3002", "result": "AoI\u4e0d\u5177\u6709\u65e0\u8bb0\u5fc6\u6027\uff0c\u4e14\u5bf9\u91c7\u6837\u7387\u53d8\u5316\u7684\u54cd\u5e94\u5b58\u5728\u6ede\u540e\uff1b\u4e0d\u540c\u9884\u62a2\u5360\u6982\u7387\u548c\u5904\u7406\u65f6\u95f4\u5206\u5e03\u65e0\u6cd5\u5728\u6240\u6709\u9608\u503c\u4e0b\u6700\u5c0f\u5316AoI\u8fdd\u89c4\u6982\u7387\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u53d8\u91c7\u6837\u7387\u4e0bAoI\u5206\u6790\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u65b9\u6cd5\u5e73\u8861\u4e86\u6210\u672c\u4e0eAoI\u7ea6\u675f\u3002"}}
{"id": "2507.03330", "categories": ["cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.03330", "abs": "https://arxiv.org/abs/2507.03330", "authors": ["Franklin Mingzhe Li", "Kaitlyn Ng", "Bin Zhu", "Patrick Carrington"], "title": "Exploring Object Status Recognition for Recipe Progress Tracking in Non-Visual Cooking", "comment": "ASSETS 2025", "summary": "Cooking plays a vital role in everyday independence and well-being, yet\nremains challenging for people with vision impairments due to limited support\nfor tracking progress and receiving contextual feedback. Object status - the\ncondition or transformation of ingredients and tools - offers a promising but\nunderexplored foundation for context-aware cooking support. In this paper, we\npresent OSCAR (Object Status Context Awareness for Recipes), a technical\npipeline that explores the use of object status recognition to enable recipe\nprogress tracking in non-visual cooking. OSCAR integrates recipe parsing,\nobject status extraction, visual alignment with cooking steps, and time-causal\nmodeling to support real-time step tracking. We evaluate OSCAR on 173\ninstructional videos and a real-world dataset of 12 non-visual cooking sessions\nrecorded by BLV individuals in their homes. Our results show that object status\nconsistently improves step prediction accuracy across vision-language models,\nand reveal key factors that impact performance in real-world conditions, such\nas implicit tasks, camera placement, and lighting. We contribute the pipeline\nof context-aware recipe progress tracking, an annotated real-world non-visual\ncooking dataset, and design insights to guide future context-aware assistive\ncooking systems.", "AI": {"tldr": "OSCAR\u662f\u4e00\u79cd\u57fa\u4e8e\u7269\u4f53\u72b6\u6001\u8bc6\u522b\u7684\u6280\u672f\u7ba1\u9053\uff0c\u7528\u4e8e\u652f\u6301\u65e0\u89c6\u89c9\u70f9\u996a\u4e2d\u7684\u98df\u8c31\u8fdb\u5ea6\u8ddf\u8e2a\uff0c\u901a\u8fc7\u6574\u5408\u98df\u8c31\u89e3\u6790\u3001\u7269\u4f53\u72b6\u6001\u63d0\u53d6\u548c\u89c6\u89c9\u5bf9\u9f50\uff0c\u63d0\u9ad8\u4e86\u6b65\u9aa4\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u70f9\u996a\u5bf9\u65e5\u5e38\u751f\u6d3b\u72ec\u7acb\u6027\u548c\u5e78\u798f\u611f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5bf9\u89c6\u529b\u969c\u788d\u8005\u6765\u8bf4\uff0c\u7531\u4e8e\u7f3a\u4e4f\u8fdb\u5ea6\u8ddf\u8e2a\u548c\u4e0a\u4e0b\u6587\u53cd\u9988\u7684\u652f\u6301\uff0c\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u7269\u4f53\u72b6\u6001\u4e3a\u4e0a\u4e0b\u6587\u611f\u77e5\u70f9\u996a\u652f\u6301\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "method": "OSCAR\u6574\u5408\u4e86\u98df\u8c31\u89e3\u6790\u3001\u7269\u4f53\u72b6\u6001\u63d0\u53d6\u3001\u89c6\u89c9\u5bf9\u9f50\u548c\u65f6\u95f4\u56e0\u679c\u5efa\u6a21\uff0c\u4ee5\u5b9e\u65f6\u8ddf\u8e2a\u70f9\u996a\u6b65\u9aa4\u3002", "result": "\u5728173\u4e2a\u6559\u5b66\u89c6\u9891\u548c12\u4e2a\u771f\u5b9e\u4e16\u754c\u65e0\u89c6\u89c9\u70f9\u996a\u4f1a\u8bdd\u4e2d\uff0cOSCAR\u663e\u8457\u63d0\u9ad8\u4e86\u6b65\u9aa4\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "OSCAR\u4e3a\u4e0a\u4e0b\u6587\u611f\u77e5\u70f9\u996a\u652f\u6301\u63d0\u4f9b\u4e86\u6280\u672f\u7ba1\u9053\u3001\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u8bbe\u8ba1\u89c1\u89e3\uff0c\u4e3a\u672a\u6765\u7cfb\u7edf\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.04968", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04968", "abs": "https://arxiv.org/abs/2507.04968", "authors": ["Pramod N Chine", "Suven Jagtiani", "Mandar R Nalavade", "Gaurav S Kasbekar"], "title": "User Association in the Presence of Jamming in Wireless Networks Using the Whittle Index", "comment": null, "summary": "In wireless networks, algorithms for user association, i.e., the task of\nchoosing the base station (BS) that every arriving user should join,\nsignificantly impact the network performance. A wireless network with multiple\nBSs, operating on non-overlapping channels, is considered. The channels of the\nBSs are susceptible to jamming by attackers. During every time slot, a user\narrives with a certain probability. There exists a holding cost in each slot\nfor every user associated with a BS. The goal here is to design a user\nassociation scheme, which assigns a BS to each user upon arrival with the\nobjective of minimizing the long-run total average holding cost borne within\nthe network. This objective results in low average delays attained by the\nusers. This association problem is an instance of restless multi-armed bandit\nproblems, and is known to be hard to solve. By making use of the framework\npresented by Whittle, the hard per-stage constraint that every arriving user\nmust connect to exactly one BS in a time slot is relaxed to a long-term\ntime-averaged constraint. Subsequently, we employ the Lagrangian multiplier\nstrategy to reformulate the problem into an unconstrained form and decompose it\ninto separate Markov Decision Processes at the BSs. Further, the problem is\nproven to be Whittle indexable and a method for calculating the Whittle indices\ncorresponding to different BSs is presented. We design a user association\npolicy under which, upon arrival of a user in a time slot, it is assigned to\nthe BS having the least Whittle index in that slot. Through extensive\nsimulations, we show that our proposed association policy based on the Whittle\nindex outperforms various user association policies proposed in previous work\nin terms of different metrics such as average cost, average delay, and Jain's\nfairness index.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWhittle\u7d22\u5f15\u7684\u7528\u6237\u5173\u8054\u7b56\u7565\uff0c\u7528\u4e8e\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7528\u6237\u4e0e\u57fa\u7ad9\u7684\u52a8\u6001\u5173\u8054\uff0c\u4ee5\u6700\u5c0f\u5316\u957f\u671f\u5e73\u5747\u6301\u6709\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u7b56\u7565\u3002", "motivation": "\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u7528\u6237\u4e0e\u57fa\u7ad9\u7684\u5173\u8054\u7b56\u7565\u5bf9\u7f51\u7edc\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u5b58\u5728\u5e72\u6270\u653b\u51fb\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u52a8\u6001\u4f18\u5316\u5173\u8054\u4ee5\u51cf\u5c11\u6210\u672c\u548c\u5ef6\u8fdf\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u5229\u7528Whittle\u6846\u67b6\u5c06\u786c\u6027\u7ea6\u675f\u677e\u5f1b\u4e3a\u957f\u671f\u5e73\u5747\u7ea6\u675f\uff0c\u91c7\u7528\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u6cd5\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u72ec\u7acb\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u8bc1\u660e\u5176Whittle\u7d22\u5f15\u6027\uff0c\u8bbe\u8ba1\u57fa\u4e8eWhittle\u7d22\u5f15\u7684\u5173\u8054\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u5728\u5e73\u5747\u6210\u672c\u3001\u5e73\u5747\u5ef6\u8fdf\u548c\u516c\u5e73\u6027\u7b49\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8eWhittle\u7d22\u5f15\u7684\u7528\u6237\u5173\u8054\u7b56\u7565\u80fd\u6709\u6548\u4f18\u5316\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u548c\u5e72\u6270\u73af\u5883\u3002"}}
{"id": "2507.03848", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03848", "abs": "https://arxiv.org/abs/2507.03848", "authors": ["S. Mohammadzadeh", "S. Mashdour", "R. C. de Lamare", "K. Cumanan", "C. Li"], "title": "Study of AP Association and Users and Power Allocation for Cell-Free Massive MIMO Systems", "comment": "6 pages, 3 figures", "summary": "This paper introduces an access point-user (AP-UE) association strategy\ncombined with pilot power allocation to mitigate multiuser interference and\nenhance spectral efficiency (SE) in clustered cell-free massive MIMO\n(CCF-mMIMO) networks. We propose a dynamic channel-based clustering method that\ngroups APs according to their channel correlation, ensuring users are\nassociated with APs exhibiting similar channel characteristics. The proposed\napproach exploits hierarchical clustering, enabling flexible cluster sizing to\nimprove interference management and overall SE. Moreover, we present a power\ncontrol (PC) technique that is based on a weighted sum-rate maximization (WSRM)\nalgorithm to ensure consistent service quality across users. Numerical results\ndemonstrate that the proposed method achieves superior SE and robust\nperformance in high-density multi-user environments as compared to competing\napproaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408AP-UE\u5173\u8054\u7b56\u7565\u548c\u5bfc\u9891\u529f\u7387\u5206\u914d\u7684\u52a8\u6001\u4fe1\u9053\u805a\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8CCF-mMIMO\u7f51\u7edc\u4e2d\u7684\u9891\u8c31\u6548\u7387\u548c\u5e72\u6270\u7ba1\u7406\u3002", "motivation": "\u5728\u5bc6\u96c6\u591a\u7528\u6237\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u7684AP-UE\u5173\u8054\u7b56\u7565\u96be\u4ee5\u6709\u6548\u7ba1\u7406\u5e72\u6270\u548c\u63d0\u5347\u9891\u8c31\u6548\u7387\u3002", "method": "\u91c7\u7528\u52a8\u6001\u4fe1\u9053\u805a\u7c7b\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4fe1\u9053\u76f8\u5173\u6027\u5206\u7ec4AP\uff0c\u5e76\u7ed3\u5408WSRM\u7b97\u6cd5\u8fdb\u884c\u529f\u7387\u63a7\u5236\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u5bc6\u5ea6\u591a\u7528\u6237\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9891\u8c31\u6548\u7387\u548c\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5e72\u6270\u7ba1\u7406\u548c\u9891\u8c31\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u9002\u7528\u4e8e\u9ad8\u5bc6\u5ea6\u7f51\u7edc\u573a\u666f\u3002"}}
{"id": "2507.03336", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03336", "abs": "https://arxiv.org/abs/2507.03336", "authors": ["Ashutosh Hathidara", "Julien Yu", "Sebastian Schreiber"], "title": "Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs More Realistic and Less Risky", "comment": null, "summary": "Large language models (LLMs) are increasingly tasked with invoking enterprise\nAPIs, yet they routinely falter when near-duplicate tools vie for the same user\nintent or when required arguments are left underspecified. We introduce\nDiaFORGE (Dialogue Framework for Organic Response Generation & Evaluation), a\ndisambiguation-centric, three-stage pipeline that (i) synthesizes\npersona-driven, multi-turn dialogues in which the assistant must distinguish\namong highly similar tools, (ii) performs supervised fine-tuning of open-source\nmodels with reasoning traces across 3B - 70B parameters, and (iii) evaluates\nreal-world readiness via a dynamic suite that redeploys each model in a live\nagentic loop and reports end-to-end goal completion alongside conventional\nstatic metrics. On our dynamic benchmark DiaBENCH, models trained with DiaFORGE\nraise tool-invocation success by 27 pp over GPT-4o and by 49 pp over\nClaude-3.5-Sonnet, both under optimized prompting. To spur further research, we\nrelease an open corpus of 5000 production-grade enterprise API specifications\npaired with rigorously validated, disambiguation-focused dialogues, offering a\npractical blueprint for building reliable, enterprise-ready tool-calling\nagents.", "AI": {"tldr": "DiaFORGE\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u5bf9\u8bdd\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u591a\u8f6e\u5bf9\u8bdd\u3001\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u548c\u52a8\u6001\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c03\u7528\u4f01\u4e1aAPI\u65f6\u7684\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c03\u7528\u4f01\u4e1aAPI\u65f6\u56e0\u5de5\u5177\u76f8\u4f3c\u6216\u53c2\u6570\u4e0d\u660e\u786e\u800c\u5931\u8d25\u7684\u95ee\u9898\u3002", "method": "\u5305\u62ec\u4e09\u9636\u6bb5\uff1a\u751f\u6210\u591a\u8f6e\u5bf9\u8bdd\u3001\u76d1\u7763\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u3001\u52a8\u6001\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728DiaBENCH\u57fa\u51c6\u4e0a\uff0cDiaFORGE\u8bad\u7ec3\u6a21\u578b\u7684\u5de5\u5177\u8c03\u7528\u6210\u529f\u7387\u6bd4GPT-4o\u548cClaude-3.5-Sonnet\u5206\u522b\u63d0\u9ad827\u548c49\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "DiaFORGE\u4e3a\u6784\u5efa\u53ef\u9760\u7684\u4f01\u4e1a\u7ea7\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u84dd\u56fe\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u653e\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002"}}
{"id": "2507.03608", "categories": ["cs.AI", "cs.DC", "cs.ET", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.03608", "abs": "https://arxiv.org/abs/2507.03608", "authors": ["Sarat Ahmad", "Zeinab Nezami", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)", "comment": null, "summary": "Generative AI (GenAI) is expected to play a pivotal role in enabling\nautonomous optimization in future wireless networks. Within the ORAN\narchitecture, Large Language Models (LLMs) can be specialized to generate xApps\nand rApps by leveraging specifications and API definitions from the RAN\nIntelligent Controller (RIC) platform. However, fine-tuning base LLMs for\ntelecom-specific tasks remains expensive and resource-intensive.\nRetrieval-Augmented Generation (RAG) offers a practical alternative through\nin-context learning, enabling domain adaptation without full retraining. While\ntraditional RAG systems rely on vector-based retrieval, emerging variants such\nas GraphRAG and Hybrid GraphRAG incorporate knowledge graphs or dual retrieval\nstrategies to support multi-hop reasoning and improve factual grounding.\nDespite their promise, these methods lack systematic, metric-driven\nevaluations, particularly in high-stakes domains such as ORAN. In this study,\nwe conduct a comparative evaluation of Vector RAG, GraphRAG, and Hybrid\nGraphRAG using ORAN specifications. We assess performance across varying\nquestion complexities using established generation metrics: faithfulness,\nanswer relevance, context relevance, and factual correctness. Results show that\nboth GraphRAG and Hybrid GraphRAG outperform traditional RAG. Hybrid GraphRAG\nimproves factual correctness by 8%, while GraphRAG improves context relevance\nby 7%.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86Vector RAG\u3001GraphRAG\u548cHybrid GraphRAG\u5728ORAN\u67b6\u6784\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793aGraphRAG\u548cHybrid GraphRAG\u4f18\u4e8e\u4f20\u7edfRAG\uff0c\u5c24\u5176\u5728\u4e8b\u5b9e\u6b63\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u65b9\u9762\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u65e0\u7ebf\u7f51\u7edc\u81ea\u4e3b\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9488\u5bf9\u7535\u4fe1\u4efb\u52a1\u7684LLM\u5fae\u8c03\u6210\u672c\u9ad8\u3002RAG\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86Vector RAG\u3001GraphRAG\u548cHybrid GraphRAG\u5728ORAN\u89c4\u8303\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u4e86\u751f\u6210\u6307\u6807\uff1a\u5fe0\u5b9e\u6027\u3001\u7b54\u6848\u76f8\u5173\u6027\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u548c\u4e8b\u5b9e\u6b63\u786e\u6027\u3002", "result": "GraphRAG\u548cHybrid GraphRAG\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfRAG\uff0cHybrid GraphRAG\u4e8b\u5b9e\u6b63\u786e\u6027\u63d0\u9ad88%\uff0cGraphRAG\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u63d0\u9ad87%\u3002", "conclusion": "GraphRAG\u548cHybrid GraphRAG\u5728ORAN\u67b6\u6784\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u9ad8\u8981\u6c42\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03851", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03851", "abs": "https://arxiv.org/abs/2507.03851", "authors": ["Zhengze Ji", "Yixuan Huang", "Zhixin Chen", "Jie Yang", "Shi Jin"], "title": "Difference Imaging-Based Parking Lot Surveillance in Multi-RIS-Aided Collaborative ISAC System", "comment": null, "summary": "Parking lot surveillance with integrated sensing and communication (ISAC)\nsystem is one of the potential application scenarios defined by 3rd Generation\nPartnership Project (3GPP). Traditional surveillance systems using cameras or\nmagnetic sensors face limitations such as light dependence, high costs, and\nconstrained scalability. Wireless sensing with reconfigurable intelligent\nsurfaces (RISs) has the ability to address the above limitations due to its\nlight independence and lower deployment overhead. In this study, we propose a\ndifference imaging-based multi-RIS-aided collaborative ISAC system to achieve\nparking lot surveillance. In a parking lot, the presence of vehicles induces\nimpacts on wireless environments due to scattering characteristic variation. By\ndelineating the parking lot into a two-dimensional image with several grid\nunits, the proposed system can capture the variation of their scattering\ncoefficients in free and occupied states. The variation between these two\nstates is sparse, which can be captured through compressed sensing (CS)-based\nimaging algorithms. Additionally, we collaboratively employ multiple RISs to\nenable higher surveillance performance. Experimental results demonstrate that\nour method can achieve high-accuracy parking occupancy detection, and the\nemployment of collaborative RISs further enhances the detection rate.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u6210\u50cf\u7684\u591aRIS\u534f\u4f5cISAC\u7cfb\u7edf\uff0c\u7528\u4e8e\u505c\u8f66\u573a\u76d1\u63a7\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u76d1\u63a7\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u505c\u8f66\u573a\u76d1\u63a7\u7cfb\u7edf\uff08\u5982\u6444\u50cf\u5934\u6216\u78c1\u4f20\u611f\u5668\uff09\u5b58\u5728\u5149\u7167\u4f9d\u8d56\u3001\u9ad8\u6210\u672c\u548c\u6269\u5c55\u6027\u53d7\u9650\u7b49\u95ee\u9898\uff0c\u65e0\u7ebf\u4f20\u611f\u4e0eRIS\u7ed3\u5408\u6709\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06\u505c\u8f66\u573a\u5212\u5206\u4e3a\u4e8c\u7ef4\u56fe\u50cf\u7f51\u683c\uff0c\u5229\u7528\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\u6355\u6349\u8f66\u8f86\u5b58\u5728\u5bfc\u81f4\u7684\u6563\u5c04\u7cfb\u6570\u53d8\u5316\uff0c\u5e76\u91c7\u7528\u591aRIS\u534f\u4f5c\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u505c\u8f66\u4f4d\u5360\u7528\u60c5\u51b5\uff0c\u591aRIS\u534f\u4f5c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7387\u3002", "conclusion": "\u591aRIS\u534f\u4f5c\u7684ISAC\u7cfb\u7edf\u4e3a\u505c\u8f66\u573a\u76d1\u63a7\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03347", "abs": "https://arxiv.org/abs/2507.03347", "authors": ["Sachith Gunasekara", "Yasiru Ratnayake"], "title": "Effects of structure on reasoning in instance-level Self-Discover", "comment": null, "summary": "The drive for predictable LLM reasoning in their integration with compound\nsystems has popularized structured outputs, yet concerns remain about\nperformance trade-offs compared to unconstrained natural language. At the same\ntime, training on unconstrained Chain of Thought (CoT) traces has brought about\na new class of strong reasoning models that nevertheless present novel compute\nbudget and faithfulness challenges. This paper introduces iSelf-Discover, an\ninstance-level adaptation of the Self-Discover framework, and using it compares\ndynamically generated structured JSON reasoning with its unstructured\ncounterpart. Our empirical evaluation across diverse benchmarks using\nstate-of-the-art open-source models supports a consistent advantage for\nunstructured reasoning. Notably, on the complex MATH benchmark, unstructured\nplans achieved relative performance improvements of up to 18.90\\% over\nstructured approaches. Zero-shot unstructured iSelf-Discover variants are also\nshown to outperform their five-shot structured counterparts, underscoring the\nsignificance of this gap, even when structured plans are dynamically generated\nto ensure reasoning precedes the final answer. We further demonstrate that the\noptimal granularity of plan generation (instance-level vs. task-level) is\ncontext-dependent. These findings invite re-evaluation of the reliance on\nstructured formats for complex problem-solving and how compound systems should\nbe organized.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u63a8\u7406\u5728LLM\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u975e\u7ed3\u6784\u5316\u63a8\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u63a8\u7406\u5728LLM\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4ee5\u89e3\u51b3\u8ba1\u7b97\u9884\u7b97\u548c\u5fe0\u5b9e\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165iSelf-Discover\u6846\u67b6\uff0c\u52a8\u6001\u751f\u6210\u7ed3\u6784\u5316JSON\u4e0e\u975e\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u975e\u7ed3\u6784\u5316\u63a8\u7406\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982MATH\u57fa\u51c6\uff09\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u8fbe18.90%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u5e94\u91cd\u65b0\u8bc4\u4f30\u5bf9\u7ed3\u6784\u5316\u683c\u5f0f\u7684\u4f9d\u8d56\uff0c\u5e76\u4f18\u5316\u590d\u5408\u7cfb\u7edf\u7684\u7ec4\u7ec7\u65b9\u5f0f\u3002"}}
{"id": "2507.04376", "categories": ["cs.AI", "cs.DC", "cs.MA", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.04376", "abs": "https://arxiv.org/abs/2507.04376", "authors": ["Georgios Ioannides", "Christos Constantinou", "Vinija Jain", "Aman Chadha", "Aaron Elkins"], "title": "MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Agents", "comment": null, "summary": "As Artificial Intelligence systems evolve from monolithic models to\necosystems of specialized agents, the need for standardized communication\nprotocols becomes increasingly critical. This paper introduces MOD-X (Modular\nOpen Decentralized eXchange), a novel architectural framework proposal for\nagent interoperability that addresses key limitations of existing protocols.\nUnlike current approaches, MOD-X proposes a layered architecture with a\nUniversal Message Bus, thorough state management, translation capabilities, and\nblockchain-based security mechanisms. We present MOD-X's architecture, compare\nit with existing protocols, and demonstrate its application through a worked\nexample how it enables integration between heterogeneous specialist agents\n(agents with different architectures, vendors, capabilities, and knowledge\nrepresentations--including rule-based systems, neural networks, symbolic\nreasoning engines, and legacy software with agent wrappers). MOD-X's key\ninnovations include a publish-subscribe communication model, semantic\ncapability discovery, and dynamic workflow orchestration--providing a framework\nthat bridges theoretical formalism with practical implementation. This\narchitecture addresses the growing need for truly decentralized, interoperable\nagent ecosystems that can scale effectively without the need for central\ncoordination.", "AI": {"tldr": "MOD-X\u662f\u4e00\u4e2a\u65b0\u578b\u7684\u6a21\u5757\u5316\u5f00\u653e\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6362\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5f02\u6784\u667a\u80fd\u4f53\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u5206\u5c42\u67b6\u6784\u3001\u901a\u7528\u6d88\u606f\u603b\u7ebf\u3001\u72b6\u6001\u7ba1\u7406\u3001\u7ffb\u8bd1\u80fd\u529b\u548c\u533a\u5757\u94fe\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u4ece\u5355\u4e00\u6a21\u578b\u53d1\u5c55\u4e3a\u4e13\u4e1a\u5316\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\uff0c\u6807\u51c6\u5316\u901a\u4fe1\u534f\u8bae\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\uff0c\u73b0\u6709\u534f\u8bae\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faMOD-X\u6846\u67b6\uff0c\u5305\u62ec\u5206\u5c42\u67b6\u6784\u3001\u901a\u7528\u6d88\u606f\u603b\u7ebf\u3001\u72b6\u6001\u7ba1\u7406\u3001\u7ffb\u8bd1\u80fd\u529b\u548c\u533a\u5757\u94fe\u5b89\u5168\u673a\u5236\uff0c\u652f\u6301\u53d1\u5e03-\u8ba2\u9605\u901a\u4fe1\u6a21\u578b\u3001\u8bed\u4e49\u80fd\u529b\u53d1\u73b0\u548c\u52a8\u6001\u5de5\u4f5c\u6d41\u7f16\u6392\u3002", "result": "MOD-X\u80fd\u591f\u6709\u6548\u96c6\u6210\u5f02\u6784\u667a\u80fd\u4f53\uff08\u5982\u89c4\u5219\u7cfb\u7edf\u3001\u795e\u7ecf\u7f51\u7edc\u3001\u7b26\u53f7\u63a8\u7406\u5f15\u64ce\u7b49\uff09\uff0c\u5b9e\u73b0\u53bb\u4e2d\u5fc3\u5316\u3001\u53ef\u6269\u5c55\u7684\u4e92\u64cd\u4f5c\u6027\u3002", "conclusion": "MOD-X\u4e3a\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u7ed3\u5408\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6ee1\u8db3\u65e0\u9700\u4e2d\u592e\u534f\u8c03\u7684\u89c4\u6a21\u5316\u9700\u6c42\u3002"}}
{"id": "2507.03915", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03915", "abs": "https://arxiv.org/abs/2507.03915", "authors": ["Ruotong Zhao", "Shaokang Hu", "Deepak Mishra", "Derrick Wing Kwan Ng"], "title": "Resource Allocation for Multi-waveguide Pinching Antenna-assisted Broadcast Networks", "comment": null, "summary": "In this paper, we investigate the resource allocation for multi-dielectric\nwaveguide-assisted broadcast systems, where each waveguide employs multiple\npinching antennas (PAs), aiming to maximize the minimum achievable rate among\nmultiple users. To capture realistic propagation effects, we propose a novel\ngeneralized frequency-dependent power attenuation model for dielectric\nwaveguides PA system. We jointly optimize waveguide beamforming, PA power\nallocation, and antenna positions via a block coordinate descent scheme that\ncapitalizes on majorization minimization and penalty methods, circumventing the\ninherent non-convexity of the formulated optimization problem and obtaining a\ncomputationally efficient sub-optimal solution. Simulation results demonstrate\nthat our proposed framework substantially outperforms both conventional antenna\nsystems and single-PA-per-waveguide configurations, clearly illustrating the\nintricate trade-offs between waveguide propagation loss, path loss, and\nresource allocation among multiple PAs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u4ecb\u8d28\u6ce2\u5bfc\u8f85\u52a9\u5e7f\u64ad\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9891\u7387\u76f8\u5173\u529f\u7387\u8870\u51cf\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u3001\u529f\u7387\u5206\u914d\u548c\u5929\u7ebf\u4f4d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u591a\u4ecb\u8d28\u6ce2\u5bfc\u7cfb\u7edf\u4e2d\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u8d44\u6e90\u5206\u914d\u6700\u5927\u5316\u7528\u6237\u7684\u6700\u5c0f\u53ef\u8fbe\u901f\u7387\uff0c\u540c\u65f6\u8003\u8651\u5b9e\u9645\u4f20\u64ad\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u5e7f\u4e49\u9891\u7387\u76f8\u5173\u529f\u7387\u8870\u51cf\u6a21\u578b\uff0c\u91c7\u7528\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u7ed3\u5408\u4e3b\u4f18\u5316\u548c\u60e9\u7f5a\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u3001\u529f\u7387\u5206\u914d\u548c\u5929\u7ebf\u4f4d\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5929\u7ebf\u7cfb\u7edf\u548c\u5355PA\u6ce2\u5bfc\u914d\u7f6e\uff0c\u5c55\u793a\u4e86\u6ce2\u5bfc\u4f20\u64ad\u635f\u8017\u3001\u8def\u5f84\u635f\u8017\u548c\u591aPA\u8d44\u6e90\u5206\u914d\u4e4b\u95f4\u7684\u590d\u6742\u6743\u8861\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u591a\u4ecb\u8d28\u6ce2\u5bfc\u7cfb\u7edf\u7684\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03407", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.03407", "abs": "https://arxiv.org/abs/2507.03407", "authors": ["Junwei Su", "Cheng Xin", "Ao Shang", "Shan Wu", "Zhenzhen Xie", "Ruogu Xiong", "Xiaoyu Xu", "Cheng Zhang", "Guang Chen", "Yau-Tuen Chan", "Guoyi Tang", "Ning Wang", "Yong Xu", "Yibin Feng"], "title": "Artificial intelligence in drug discovery: A comprehensive review with a case study on hyperuricemia, gout arthritis, and hyperuricemic nephropathy", "comment": null, "summary": "This paper systematically reviews recent advances in artificial intelligence\n(AI), with a particular focus on machine learning (ML), across the entire drug\ndiscovery pipeline. Due to the inherent complexity, escalating costs, prolonged\ntimelines, and high failure rates of traditional drug discovery methods, there\nis a critical need to comprehensively understand how AI/ML can be effectively\nintegrated throughout the full process. Currently available literature reviews\noften narrowly focus on specific phases or methodologies, neglecting the\ndependence between key stages such as target identification, hit screening, and\nlead optimization. To bridge this gap, our review provides a detailed and\nholistic analysis of AI/ML applications across these core phases, highlighting\nsignificant methodological advances and their impacts at each stage. We further\nillustrate the practical impact of these techniques through an in-depth case\nstudy focused on hyperuricemia, gout arthritis, and hyperuricemic nephropathy,\nhighlighting real-world successes in molecular target identification and\ntherapeutic candidate discovery. Additionally, we discuss significant\nchallenges facing AI/ML in drug discovery and outline promising future research\ndirections. Ultimately, this review serves as an essential orientation for\nresearchers aiming to leverage AI/ML to overcome existing bottlenecks and\naccelerate drug discovery.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86AI/ML\u5728\u836f\u7269\u53d1\u73b0\u5168\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u5bf9\u5173\u952e\u9636\u6bb5\u4f9d\u8d56\u5173\u7cfb\u7684\u5ffd\u89c6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5b9e\u9645\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u836f\u7269\u53d1\u73b0\u65b9\u6cd5\u590d\u6742\u3001\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u5931\u8d25\u7387\u9ad8\uff0c\u4e9f\u9700\u5168\u9762\u4e86\u89e3AI/ML\u5982\u4f55\u6574\u5408\u5230\u5168\u6d41\u7a0b\u4e2d\u3002", "method": "\u8be6\u7ec6\u5206\u6790\u4e86AI/ML\u5728\u76ee\u6807\u8bc6\u522b\u3001\u547d\u4e2d\u7b5b\u9009\u548c\u5148\u5bfc\u4f18\u5316\u7b49\u6838\u5fc3\u9636\u6bb5\u7684\u5e94\u7528\uff0c\u7ed3\u5408\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5b9e\u9645\u6548\u679c\u3002", "result": "\u5c55\u793a\u4e86AI/ML\u5728\u5404\u9636\u6bb5\u7684\u663e\u8457\u65b9\u6cd5\u8fdb\u5c55\u53ca\u5176\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u672c\u6587\u4e3a\u7814\u7a76\u8005\u5229\u7528AI/ML\u514b\u670d\u74f6\u9888\u3001\u52a0\u901f\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.05042", "categories": ["cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.05042", "abs": "https://arxiv.org/abs/2507.05042", "authors": ["Onur Ayan", "Jiping Luo", "Xueli An", "Nikolaos Pappas"], "title": "Age-Aware CSI Acquisition of a Finite-State Markovian Channel", "comment": "Accepted to be presented at the IEEE PIMRC 2025", "summary": "The Age of Information (AoI) has emerged as a critical metric for quantifying\ninformation freshness; however, its interplay with channel estimation in\npartially observable wireless systems remains underexplored. This work\nconsiders a transmitter-receiver pair communicating over an unreliable channel\nwith time-varying reliability levels. The transmitter observes the\ninstantaneous link reliability through a channel state information acquisition\nprocedure, during which the data transmission is interrupted. This leads to a\nfundamental trade-off between utilizing limited network resources for either\ndata transmission or channel state information acquisition to combat the\nchannel aging effect. Assuming the wireless channel is modeled as a\nfinite-state Markovian channel, we formulate an optimization problem as a\npartially observable Markov decision process (POMDP), obtain the optimal policy\nthrough the relative value iteration algorithm, and demonstrate the efficiency\nof our solution through simulations. To the best of our knowledge, this is the\nfirst work to aim for an optimal scheduling policy for data transmissions while\nconsidering the effect of channel state information aging.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08AoI\uff09\u4e0e\u4fe1\u9053\u4f30\u8ba1\u7684\u4ea4\u4e92\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u5e73\u8861\u6570\u636e\u4f20\u8f93\u4e0e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u4e4b\u95f4\u7684\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u4fe1\u606f\u65b0\u9c9c\u5ea6\uff08AoI\uff09\u662f\u8861\u91cf\u4fe1\u606f\u65f6\u6548\u6027\u7684\u91cd\u8981\u6307\u6807\uff0c\u4f46\u5176\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u4ea4\u4e92\u4f5c\u7528\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u7279\u522b\u662f\u5728\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u8fc7\u7a0b\u4e2d\u6570\u636e\u4f20\u8f93\u4e2d\u65ad\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u4f18\u5316\u8d44\u6e90\u5206\u914d\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u5047\u8bbe\u65e0\u7ebf\u4fe1\u9053\u4e3a\u6709\u9650\u72b6\u6001\u9a6c\u5c14\u53ef\u592b\u4fe1\u9053\uff0c\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\uff0c\u5e76\u901a\u8fc7\u76f8\u5bf9\u503c\u8fed\u4ee3\u7b97\u6cd5\u83b7\u5f97\u6700\u4f18\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5e73\u8861\u6570\u636e\u4f20\u8f93\u4e0e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u65b9\u9762\u5177\u6709\u9ad8\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u8003\u8651\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u8001\u5316\u6548\u5e94\u7684\u6700\u4f18\u8c03\u5ea6\u7b56\u7565\uff0c\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.03918", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.03918", "abs": "https://arxiv.org/abs/2507.03918", "authors": ["Wenhai Lai", "Kaiming Shen", "Rui Zhang"], "title": "FollowSpot: Enhancing Wireless Communications via Movable Ceiling-Mounted Metasurfaces", "comment": "11 pages", "summary": "This paper studies the optimal placement of ceiling-mounted metasurfaces\n(MTSs) to help focus the wireless signal beam onto the target receiver, as\ninspired by the theatre spotlight. We assume that a total of $M$ MTSs are\ndeployed, and that there are $L$ possible positions for each MTS. The resulting\nsignal-to-noise (SNR) maximization problem is difficult to tackle directly\nbecause of the coupling between the placement decisions of the different MTSs.\nMathematically, we are faced with a nonlinear discrete optimization problem\nwith $L^M$ possible solutions. A remarkable result shown in this paper is that\nthe above challenging problem can be efficiently solved within\n$O(ML^2\\log(ML))$ time. There are two key steps in developing the proposed\nalgorithm. First, we successfully decouple the placement variables of different\nMTSs by introducing a continuous auxiliary variable $\\mu$; the discrete primal\nvariables are now easy to optimize when $\\mu$ is held fixed, but the\noptimization problem of $\\mu$ is nonconvex. Second, we show that the\noptimization of continuous $\\mu$ can be recast into a discrete optimization\nproblem with only $LM$ possible solutions, so the optimal $\\mu$ can now be\nreadily obtained. Numerical results show that the proposed algorithm can not\nonly guarantee a global optimum but also reach the optimal solution\nefficiently.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5929\u82b1\u677f\u5b89\u88c5\u7684\u8d85\u8868\u9762\uff08MTS\uff09\u7684\u6700\u4f18\u653e\u7f6e\u95ee\u9898\uff0c\u4ee5\u805a\u7126\u65e0\u7ebf\u4fe1\u53f7\u5230\u76ee\u6807\u63a5\u6536\u5668\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u7b97\u6cd5\u6765\u89e3\u51b3\u590d\u6742\u7684\u975e\u7ebf\u6027\u79bb\u6563\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u53d7\u5267\u9662\u805a\u5149\u706f\u542f\u53d1\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4f18\u5316MTS\u7684\u653e\u7f6e\u6765\u6700\u5927\u5316\u4fe1\u53f7\u4fe1\u566a\u6bd4\uff08SNR\uff09\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u8fde\u7eed\u8f85\u52a9\u53d8\u91cf\u03bc\u89e3\u8026MTS\u7684\u653e\u7f6e\u53d8\u91cf\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u79bb\u6563\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(ML\u00b2log(ML))\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u4e0d\u4ec5\u4fdd\u8bc1\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u8fd8\u80fd\u9ad8\u6548\u5730\u627e\u5230\u6700\u4f18\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MTS\u653e\u7f6e\u7684\u590d\u6742\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03409", "abs": "https://arxiv.org/abs/2507.03409", "authors": ["Christopher Summerfield", "Lennart Luettgau", "Magda Dubois", "Hannah Rose Kirk", "Kobi Hackenburg", "Catherine Fist", "Katarina Slama", "Nicola Ding", "Rebecca Anselmetti", "Andrew Strait", "Mario Giulianelli", "Cozmin Ududec"], "title": "Lessons from a Chimp: AI \"Scheming\" and the Quest for Ape Language", "comment": null, "summary": "We examine recent research that asks whether current AI systems may be\ndeveloping a capacity for \"scheming\" (covertly and strategically pursuing\nmisaligned goals). We compare current research practices in this field to those\nadopted in the 1970s to test whether non-human primates could master natural\nlanguage. We argue that there are lessons to be learned from that historical\nresearch endeavour, which was characterised by an overattribution of human\ntraits to other agents, an excessive reliance on anecdote and descriptive\nanalysis, and a failure to articulate a strong theoretical framework for the\nresearch. We recommend that research into AI scheming actively seeks to avoid\nthese pitfalls. We outline some concrete steps that can be taken for this\nresearch programme to advance in a productive and scientifically rigorous\nfashion.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5f53\u524dAI\u7cfb\u7edf\u662f\u5426\u53ef\u80fd\u53d1\u5c55\u51fa\u201c\u9634\u8c0b\u201d\u80fd\u529b\uff08\u9690\u853d\u4e14\u6218\u7565\u6027\u5730\u8ffd\u6c42\u672a\u5bf9\u9f50\u76ee\u6807\uff09\uff0c\u5e76\u4e0e1970\u5e74\u4ee3\u7814\u7a76\u975e\u4eba\u7075\u957f\u7c7b\u52a8\u7269\u638c\u63e1\u81ea\u7136\u8bed\u8a00\u7684\u5b9e\u8df5\u5bf9\u6bd4\uff0c\u63d0\u51fa\u907f\u514d\u5386\u53f2\u7814\u7a76\u7f3a\u9677\u7684\u5efa\u8bae\u3002", "motivation": "\u63a2\u8ba8AI\u7cfb\u7edf\u662f\u5426\u53ef\u80fd\u53d1\u5c55\u51fa\u9690\u853d\u7684\u6218\u7565\u6027\u884c\u4e3a\uff0c\u4ee5\u907f\u514d\u91cd\u8e481970\u5e74\u4ee3\u7814\u7a76\u7684\u8986\u8f99\uff08\u5982\u8fc7\u5ea6\u62df\u4eba\u5316\u3001\u4f9d\u8d56\u8f76\u4e8b\u548c\u7f3a\u4e4f\u7406\u8bba\u6846\u67b6\uff09\u3002", "method": "\u6bd4\u8f83\u5f53\u524dAI\u7814\u7a76\u4e0e1970\u5e74\u4ee3\u975e\u4eba\u7075\u957f\u7c7b\u8bed\u8a00\u7814\u7a76\u7684\u5b9e\u8df5\uff0c\u5206\u6790\u5386\u53f2\u7814\u7a76\u7684\u7f3a\u9677\u3002", "result": "\u63d0\u51fa\u907f\u514d\u8fc7\u5ea6\u62df\u4eba\u5316\u3001\u4f9d\u8d56\u8f76\u4e8b\u548c\u7f3a\u4e4f\u7406\u8bba\u6846\u67b6\u7684\u5efa\u8bae\uff0c\u5e76\u7ed9\u51fa\u5177\u4f53\u6b65\u9aa4\u4ee5\u63a8\u52a8\u79d1\u5b66\u4e25\u8c28\u7684\u7814\u7a76\u3002", "conclusion": "AI\u201c\u9634\u8c0b\u201d\u7814\u7a76\u5e94\u5438\u53d6\u5386\u53f2\u6559\u8bad\uff0c\u91c7\u53d6\u79d1\u5b66\u4e25\u8c28\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u91cd\u8e48\u8986\u8f99\u3002"}}
{"id": "2507.04158", "categories": ["cs.IT", "math.CO", "math.IT", "12E10, 16S36, 94B60"], "pdf": "https://arxiv.org/pdf/2507.04158", "abs": "https://arxiv.org/abs/2507.04158", "authors": ["Paolo Santonastaso", "Ferdinando Zullo"], "title": "Invariants for sum-rank metric codes", "comment": null, "summary": "The code equivalence problem is central in coding theory and cryptography.\nWhile classical invariants are effective for Hamming and rank metrics, the\nsum-rank metric, which unifies both, introduces new challenges. This paper\nintroduces new invariants for sum-rank metric codes: generalised idealisers,\nthe centraliser, the center, and a refined notion of linearity. These lead to\nthe definition of nuclear parameters, inspired by those used in division\nalgebra theory, where they are crucial for proving inequivalence. We also\ndevelop a computational framework based on skew polynomials, which is isometric\nto the classical matrix setting but enables explicit computation of nuclear\nparameters for known MSRD (Maximum Sum-Rank Distance) codes. This yields a new\nand effective method to study the code equivalence problem where traditional\ntools fall short. In fact, using nuclear parameters, we can study the\nequivalence among the largest families of known MSRD codes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u65b0\u7684\u4e0d\u53d8\u91cf\uff08\u5e7f\u4e49\u7406\u60f3\u5316\u5b50\u3001\u4e2d\u5fc3\u5316\u5b50\u3001\u4e2d\u5fc3\u548c\u6539\u8fdb\u7684\u7ebf\u6027\u6982\u5ff5\uff09\u548c\u6838\u53c2\u6570\uff0c\u7528\u4e8e\u89e3\u51b3\u548c\u79e9\u5ea6\u91cf\u7801\u7684\u7b49\u4ef7\u6027\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u659c\u591a\u9879\u5f0f\u7684\u8ba1\u7b97\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u548c\u79e9\u5ea6\u91cf\u7801\u7684\u7b49\u4ef7\u6027\u95ee\u9898\uff0c\u4f20\u7edf\u5de5\u5177\u5728\u6b64\u9886\u57df\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u65b0\u7684\u4e0d\u53d8\u91cf\u548c\u6838\u53c2\u6570\uff0c\u5f00\u53d1\u57fa\u4e8e\u659c\u591a\u9879\u5f0f\u7684\u8ba1\u7b97\u6846\u67b6\u3002", "result": "\u80fd\u591f\u7814\u7a76\u5df2\u77e5\u6700\u5927\u548c\u79e9\u8ddd\u79bb\u7801\uff08MSRD\uff09\u7684\u7b49\u4ef7\u6027\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e3a\u548c\u79e9\u5ea6\u91cf\u7801\u7684\u7b49\u4ef7\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.03460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03460", "abs": "https://arxiv.org/abs/2507.03460", "authors": ["Weitong Zhang", "Mengyun Qiao", "Chengqi Zang", "Steven Niederer", "Paul M Matthews", "Wenjia Bai", "Bernhard Kainz"], "title": "Multi-Agent Reasoning for Cardiovascular Imaging Phenotype Analysis", "comment": null, "summary": "Identifying the associations between imaging phenotypes and disease risk\nfactors and outcomes is essential for understanding disease mechanisms and\nimproving diagnosis and prognosis models. However, traditional approaches rely\non human-driven hypothesis testing and selection of association factors, often\noverlooking complex, non-linear dependencies among imaging phenotypes and other\nmulti-modal data. To address this, we introduce a Multi-agent Exploratory\nSynergy for the Heart (MESHAgents) framework that leverages large language\nmodels as agents to dynamically elicit, surface, and decide confounders and\nphenotypes in association studies, using cardiovascular imaging as a proof of\nconcept. Specifically, we orchestrate a multi-disciplinary team of AI agents --\nspanning cardiology, biomechanics, statistics, and clinical research -- which\nspontaneously generate and converge on insights through iterative,\nself-organizing reasoning. The framework dynamically synthesizes statistical\ncorrelations with multi-expert consensus, providing an automated pipeline for\nphenome-wide association studies (PheWAS). We demonstrate the system's\ncapabilities through a population-based study of imaging phenotypes of the\nheart and aorta. MESHAgents autonomously uncovered correlations between imaging\nphenotypes and a wide range of non-imaging factors, identifying additional\nconfounder variables beyond standard demographic factors. Validation on\ndiagnosis tasks reveals that MESHAgents-discovered phenotypes achieve\nperformance comparable to expert-selected phenotypes, with mean AUC differences\nas small as -0.004 on disease classification tasks. Notably, the recall score\nimproves for 6 out of 9 disease types. Our framework provides clinically\nrelevant imaging phenotypes with transparent reasoning, offering a scalable\nalternative to expert-driven methods.", "AI": {"tldr": "MESHAgents\u6846\u67b6\u5229\u7528\u591a\u5b66\u79d1AI\u4ee3\u7406\u81ea\u52a8\u53d1\u73b0\u5f71\u50cf\u8868\u578b\u4e0e\u75be\u75c5\u98ce\u9669\u56e0\u7d20\u7684\u975e\u7ebf\u6027\u5173\u8054\uff0c\u6027\u80fd\u63a5\u8fd1\u4e13\u5bb6\u9009\u62e9\uff0c\u5e76\u63d0\u5347\u90e8\u5206\u75be\u75c5\u7684\u53ec\u56de\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5047\u8bbe\u548c\u9009\u62e9\u5173\u8054\u56e0\u7d20\uff0c\u53ef\u80fd\u5ffd\u7565\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u591a\u5b66\u79d1AI\u4ee3\u7406\uff08\u5982\u5fc3\u810f\u75c5\u5b66\u3001\u751f\u7269\u529b\u5b66\u3001\u7edf\u8ba1\u5b66\uff09\u52a8\u6001\u751f\u6210\u548c\u9a8c\u8bc1\u8868\u578b\u5173\u8054\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316PheWAS\u3002", "result": "\u5728\u5fc3\u8840\u7ba1\u5f71\u50cf\u7814\u7a76\u4e2d\uff0cMESHAgents\u53d1\u73b0\u8d85\u51fa\u6807\u51c6\u4eba\u53e3\u56e0\u7d20\u7684\u6df7\u6742\u53d8\u91cf\uff0c\u75be\u75c5\u5206\u7c7bAUC\u5dee\u5f02\u4ec5-0.004\uff0c6/9\u75be\u75c5\u53ec\u56de\u7387\u63d0\u5347\u3002", "conclusion": "MESHAgents\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684\u5f71\u50cf\u8868\u578b\u53d1\u73b0\u65b9\u6cd5\uff0c\u6027\u80fd\u63a5\u8fd1\u4e13\u5bb6\u9a71\u52a8\u65b9\u6cd5\u3002"}}
{"id": "2507.04201", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04201", "abs": "https://arxiv.org/abs/2507.04201", "authors": ["Facheng Luo", "Yijie Mao"], "title": "An Efficient Max-Min Fair Resource Optimization Algorithm for Rate-Splitting Multiple Access", "comment": "16 pages, 10 figures", "summary": "The max-min fairness (MMF) problem in rate-splitting multiple access (RSMA)\nis known to be challenging due to its non-convex and non-smooth nature, as well\nas the coupled beamforming and common rate variables. Conventional algorithms\nto address this problem often incur high computational complexity or degraded\nMMF rate performance. To address these challenges, in this work, we propose a\nnovel optimization algorithm named extragradient-fractional programming (EG-FP)\nto address the MMF problem of downlink RSMA. The proposed algorithm first\nleverages FP to transform the original problem into a block-wise convex\nproblem. For the subproblem of precoding block, we show that its Lagrangian\ndual is equivalent to a variational inequality problem, which is then solved\nusing an extragradient-based algorithm. Additionally, we discover the optimal\nbeamforming structure of the problem and based on which, we introduce a\nlow-dimensional EG-FP algorithm with computational complexity independent of\nthe number of transmit antennas. This feature is especially beneficial in\nscenarios with a large number of transmit antennas. The proposed algorithms are\nthen extended to handle imperfect channel state information at the transmitter\n(CSIT). Numerical results demonstrate that the MMF rate achieved by our\nproposed algorithms closely matches that of the conventional successive convex\napproximation (SCA) algorithm and significantly outperforms other baseline\nschemes. Remarkably, the average CPU time of the proposed algorithms is less\nthan 10\\% of the runtime required by the SCA algorithm, showing the efficiency\nand scalability of the proposed algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEG-FP\u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3RSMA\u4e2d\u7684MMF\u95ee\u9898\uff0c\u901a\u8fc7FP\u548c\u53d8\u5206\u4e0d\u7b49\u5f0f\u65b9\u6cd5\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u5929\u7ebf\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u7b97\u6cd5\u5728\u89e3\u51b3RSMA\u4e2d\u7684MMF\u95ee\u9898\u65f6\u5b58\u5728\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u6216\u6027\u80fd\u4e0b\u964d\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528FP\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5757\u72b6\u51f8\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u53d8\u5206\u4e0d\u7b49\u5f0f\u548c\u6781\u68af\u5ea6\u7b97\u6cd5\u89e3\u51b3\u5b50\u95ee\u9898\uff0c\u540c\u65f6\u53d1\u73b0\u6700\u4f18\u6ce2\u675f\u6210\u5f62\u7ed3\u6784\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cEG-FP\u7b97\u6cd5\u7684\u6027\u80fd\u63a5\u8fd1SCA\u7b97\u6cd5\uff0c\u4f46\u8ba1\u7b97\u65f6\u95f4\u4ec5\u4e3a\u540e\u8005\u768410%\u3002", "conclusion": "EG-FP\u7b97\u6cd5\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u5929\u7ebf\u573a\u666f\u3002"}}
{"id": "2507.03477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03477", "abs": "https://arxiv.org/abs/2507.03477", "authors": ["Kexin Zhu", "Yang Han"], "title": "REAL: Benchmarking Abilities of Large Language Models for Housing Transactions and Services", "comment": null, "summary": "The development of large language models (LLMs) has greatly promoted the\nprogress of chatbot in multiple fields. There is an urgent need to evaluate\nwhether LLMs can play the role of agent in housing transactions and services as\nwell as humans. We present Real Estate Agent Large Language Model Evaluation\n(REAL), the first evaluation suite designed to assess the abilities of LLMs in\nthe field of housing transactions and services. REAL comprises 5,316\nhigh-quality evaluation entries across 4 topics: memory, comprehension,\nreasoning and hallucination. All these entries are organized as 14 categories\nto assess whether LLMs have the knowledge and ability in housing transactions\nand services scenario. Additionally, the REAL is used to evaluate the\nperformance of most advanced LLMs. The experiment results indicate that LLMs\nstill have significant room for improvement to be applied in the real estate\nfield.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86REAL\u8bc4\u4f30\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u623f\u5730\u4ea7\u4ea4\u6613\u548c\u670d\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u4ecd\u6709\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5728\u623f\u5730\u4ea7\u4ea4\u6613\u548c\u670d\u52a1\u4e2d\u626e\u6f14\u7c7b\u4f3c\u4eba\u7c7b\u7684\u89d2\u8272\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b5,316\u4e2a\u9ad8\u8d28\u91cf\u8bc4\u4f30\u6761\u76ee\u7684REAL\u8bc4\u4f30\u5957\u4ef6\uff0c\u6db5\u76d64\u4e2a\u4e3b\u9898\u548c14\u4e2a\u7c7b\u522b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u623f\u5730\u4ea7\u9886\u57df\u7684\u5e94\u7528\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "REAL\u5957\u4ef6\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u623f\u5730\u4ea7\u9886\u57df\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u4f46\u6a21\u578b\u6027\u80fd\u4ecd\u9700\u63d0\u5347\u3002"}}
{"id": "2507.04209", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04209", "abs": "https://arxiv.org/abs/2507.04209", "authors": ["Anderson de Andrade"], "title": "Mutual Information Bounds for Lossy Common Information", "comment": null, "summary": "We show the mutual information between the targets in a Gray-Wyner Network as\na bound that separates Wyner's lossy common information and G\\'acs-K\\\"orner\nlossy common information. The results are a generalization of the lossless case\npresented by Wyner (1975).", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u6790Gray-Wyner\u7f51\u7edc\u4e2d\u7684\u76ee\u6807\u4e92\u4fe1\u606f\uff0c\u5c06Wyner\u7684\u6709\u635f\u516c\u5171\u4fe1\u606f\u548cG\u00e1cs-K\u00f6rner\u7684\u6709\u635f\u516c\u5171\u4fe1\u606f\u5206\u5f00\uff0c\u63a8\u5e7f\u4e86Wyner\uff081975\uff09\u7684\u65e0\u635f\u60c5\u51b5\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76Gray-Wyner\u7f51\u7edc\u4e2d\u76ee\u6807\u4e92\u4fe1\u606f\u7684\u754c\u9650\uff0c\u4ee5\u533a\u5206\u4e0d\u540c\u5f62\u5f0f\u7684\u516c\u5171\u4fe1\u606f\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5c06Wyner\u7684\u6709\u635f\u516c\u5171\u4fe1\u606f\u548cG\u00e1cs-K\u00f6rner\u7684\u6709\u635f\u516c\u5171\u4fe1\u606f\u5206\u5f00\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u754c\u9650\uff0c\u80fd\u591f\u533a\u5206\u4e24\u79cd\u4e0d\u540c\u7684\u6709\u635f\u516c\u5171\u4fe1\u606f\u5f62\u5f0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63a8\u5e7f\u4e86Wyner\u7684\u65e0\u635f\u60c5\u51b5\uff0c\u4e3a\u7406\u89e3\u6709\u635f\u516c\u5171\u4fe1\u606f\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.04566", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04566", "abs": "https://arxiv.org/abs/2507.04566", "authors": ["Pulok Tarafder", "Imtiaz Ahmed", "Danda B. Rawat", "Md. Zoheb Hassan", "Kamrul Hasan"], "title": "Digital-Twin Empowered Site-Specific Radio Resource Management in 5G Aerial Corridor", "comment": "This paper has been submitted to IEEE for possible publication and is\n  currently under review. The content is subject to change without notice", "summary": "Base station (BS) association and beam selection in multi-cell drone corridor\nnetworks present unique challenges due to the high altitude, mobility and\nthree-dimensional movement of drones. These factors lead to frequent handovers\nand complex beam alignment issues, especially in environments with dense BS\ndeployments and varying signal conditions. To address these challenges, this\npaper proposes a channel-twin (CT) enabled resource-allocation framework for\ndrone-corridor communications, where the CT constitutes the radio-channel\ncomponent of a broader digital-twin (DT) environment. The CT supplies\nhigh-fidelity channel-state information (CSI), which drives a two-stage\noptimization procedure. In Stage 1, array-level beamforming weights at each BS\nare selected to maximize antenna gain. In Stage 2, the framework jointly\noptimizes drone-BS-beam associations at discrete corridor way-points to\nmaximize end-to-end throughput. Simulation results confirm that the CT-driven\nstrategy delivers significant throughput gains over baseline methods across\ndiverse operating scenarios, validating the effectiveness of integrating\nprecise digital-twin channel models with cross-layer resource optimization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u9053\u5b6a\u751f\uff08CT\uff09\u7684\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u4eba\u673a\u8d70\u5eca\u7f51\u7edc\u4e2d\u7684\u57fa\u7ad9\u5173\u8054\u548c\u6ce2\u675f\u9009\u62e9\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u3002", "motivation": "\u65e0\u4eba\u673a\u7684\u9ad8\u7a7a\u3001\u79fb\u52a8\u6027\u548c\u4e09\u7ef4\u8fd0\u52a8\u5bfc\u81f4\u9891\u7e41\u5207\u6362\u548c\u590d\u6742\u7684\u6ce2\u675f\u5bf9\u51c6\u95ee\u9898\uff0c\u5c24\u5176\u5728\u5bc6\u96c6\u57fa\u7ad9\u90e8\u7f72\u548c\u4fe1\u53f7\u6761\u4ef6\u591a\u53d8\u7684\u73af\u5883\u4e2d\u3002", "method": "\u5229\u7528CT\u63d0\u4f9b\u9ad8\u4fdd\u771f\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\uff0c\u5206\u4e24\u9636\u6bb5\u4f18\u5316\uff1a\u7b2c\u4e00\u9636\u6bb5\u9009\u62e9\u57fa\u7ad9\u9635\u5217\u7ea7\u6ce2\u675f\u6210\u5f62\u6743\u91cd\u4ee5\u6700\u5927\u5316\u5929\u7ebf\u589e\u76ca\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a-\u57fa\u7ad9-\u6ce2\u675f\u5173\u8054\u4ee5\u6700\u5927\u5316\u7aef\u5230\u7aef\u541e\u5410\u91cf\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cCT\u9a71\u52a8\u7684\u7b56\u7565\u5728\u591a\u79cd\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6570\u5b57\u5b6a\u751f\u4fe1\u9053\u6a21\u578b\u4e0e\u8de8\u5c42\u8d44\u6e90\u4f18\u5316\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u7cbe\u786e\u7684\u6570\u5b57\u5b6a\u751f\u4fe1\u9053\u6a21\u578b\u548c\u8de8\u5c42\u4f18\u5316\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u8d70\u5eca\u901a\u4fe1\u7684\u6027\u80fd\u3002"}}
{"id": "2507.03579", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03579", "abs": "https://arxiv.org/abs/2507.03579", "authors": ["Riccardo Lo Bianco", "Remco Dijkman", "Wim Nuijten", "Willem van Jaarsveld"], "title": "A Universal Approach to Feature Representation in Dynamic Task Assignment Problems", "comment": null, "summary": "Dynamic task assignment concerns the optimal assignment of resources to tasks\nin a business process. Recently, Deep Reinforcement Learning (DRL) has been\nproposed as the state of the art for solving assignment problems. DRL methods\nusually employ a neural network (NN) as an approximator for the policy\nfunction, which ingests the state of the process and outputs a valuation of the\npossible assignments. However, representing the state and the possible\nassignments so that they can serve as inputs and outputs for a policy NN\nremains an open challenge, especially when tasks or resources have features\nwith an infinite number of possible values. To solve this problem, this paper\nproposes a method for representing and solving assignment problems with\ninfinite state and action spaces. In doing so, it provides three contributions:\n(I) A graph-based feature representation of assignment problems, which we call\nassignment graph; (II) A mapping from marked Colored Petri Nets to assignment\ngraphs; (III) An adaptation of the Proximal Policy Optimization algorithm that\ncan learn to solve assignment problems represented through assignment graphs.\nTo evaluate the proposed representation method, we model three archetypal\nassignment problems ranging from finite to infinite state and action space\ndimensionalities. The experiments show that the method is suitable for\nrepresenting and learning close-to-optimal task assignment policies regardless\nof the state and action space dimensionalities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u7279\u5f81\u8868\u793a\u65b9\u6cd5\uff08assignment graph\uff09\u548cPPO\u7b97\u6cd5\u7684\u6539\u8fdb\uff0c\u7528\u4e8e\u89e3\u51b3\u52a8\u6001\u4efb\u52a1\u5206\u914d\u95ee\u9898\u4e2d\u7684\u65e0\u9650\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u6311\u6218\u3002", "motivation": "\u52a8\u6001\u4efb\u52a1\u5206\u914d\u95ee\u9898\u4e2d\uff0c\u73b0\u6709DRL\u65b9\u6cd5\u5728\u5904\u7406\u65e0\u9650\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u65f6\u5b58\u5728\u8868\u793a\u548c\u5b66\u4e60\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faassignment graph\u8868\u793a\u65b9\u6cd5\uff0c\u5c06\u6807\u8bb0Colored Petri Nets\u6620\u5c04\u5230assignment graph\uff0c\u5e76\u6539\u8fdbPPO\u7b97\u6cd5\u4ee5\u5b66\u4e60\u4efb\u52a1\u5206\u914d\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8868\u793a\u548c\u5b66\u4e60\u63a5\u8fd1\u6700\u4f18\u7684\u4efb\u52a1\u5206\u914d\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7ef4\u5ea6\u7684\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u52a8\u6001\u4efb\u52a1\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.04689", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04689", "abs": "https://arxiv.org/abs/2507.04689", "authors": ["Yu Ning"], "title": "On subcodes of the generalized Reed-Solomon codes", "comment": null, "summary": "In this paper, we study a class of subcodes of codimension $1$ in the\n$[n,k+1]_q$ generalized Reed-Solomon (GRS) codes, whose generator matrix is\nderived by removing the row of degree $k-r$ from the generator matrix of the\n$[n,k+1]_q$ GRS codes, where $1 \\le r \\le k-1$. We show equivalent\ncharacterizations for this class of subcodes of the GRS codes being self-dual\nor near-MDS, which extends the results for $r=1$ in the literature. Along with\nthese characterizations, families of self-dual near-MDS subcodes of the GRS\ncodes are also proposed. Finally, for $r = 1,2$, the dual codes of the subcodes\nof the GRS codes are found out. In some cases, the subcodes of the GRS codes\ncan be closed under taking dual codes. In other cases, the dual codes turn out\nto be the twisted GRS codes.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5e7f\u4e49Reed-Solomon\uff08GRS\uff09\u7801\u7684\u4e00\u7c7b\u5b50\u7801\uff0c\u7ed9\u51fa\u4e86\u8fd9\u4e9b\u5b50\u7801\u81ea\u5bf9\u5076\u6216\u8fd1MDS\u7684\u7b49\u4ef7\u523b\u753b\uff0c\u5e76\u63d0\u51fa\u4e86\u81ea\u5bf9\u5076\u8fd1MDS\u5b50\u7801\u7684\u6784\u9020\u3002", "motivation": "\u6269\u5c55\u6587\u732e\u4e2d\u5173\u4e8er=1\u7684\u7ed3\u679c\uff0c\u7814\u7a76GRS\u7801\u5b50\u7801\u7684\u81ea\u5bf9\u5076\u6027\u548c\u8fd1MDS\u6027\u8d28\u3002", "method": "\u901a\u8fc7\u4eceGRS\u7801\u751f\u6210\u77e9\u9635\u4e2d\u79fb\u9664\u7279\u5b9a\u884c\uff0c\u6784\u9020\u5b50\u7801\uff0c\u5e76\u5206\u6790\u5176\u6027\u8d28\u3002", "result": "\u7ed9\u51fa\u4e86\u5b50\u7801\u81ea\u5bf9\u5076\u6216\u8fd1MDS\u7684\u7b49\u4ef7\u523b\u753b\uff0c\u5e76\u6784\u9020\u4e86\u76f8\u5173\u5b50\u7801\u5bb6\u65cf\u3002", "conclusion": "\u5b50\u7801\u7684\u5bf9\u5076\u7801\u53ef\u80fd\u662f\u626d\u66f2GRS\u7801\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b50\u7801\u5bf9\u5076\u5c01\u95ed\u3002"}}
{"id": "2507.04797", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04797", "abs": "https://arxiv.org/abs/2507.04797", "authors": ["Zuo Ye", "Yubo Sun", "Gennian Ge"], "title": "Correcting Bursty/Localized Deletions: A New Error-Position-Estimation Code", "comment": "submitted on 2025.06.17", "summary": "Codes correcting bursts of deletions and localized deletions have garnered\nsignificant research interest in recent years. One of the primary objectives is\nto construct codes with minimal redundancy. Currently, the best known\nconstructions of $q$-ary codes correcting a burst of at most $t$ deletions\n($(\\le t)$-burst-deletion correcting codes) achieve redundancy $\\log\nn+8\\log\\log n+o(\\log\\log n)$ (for any $q$ and $t$) or $\\log n+t\\log\\log n+O(1)$\n(for even $q$). For codes correcting single $t$-localized-deletion\n($t$-localized-deletion correcting codes), state-of-the-art constructions\nattain redundancy $\\log n+O\\parenv{t(\\log\\log n)^2}$ (for any $q$ and $t$) or\n$\\log n+2t\\log\\log n+O(1)$ (for even $q$). Here, $n$ denotes the code-length,\nand $q$ and $t$ are fixed. These codes employ a position-estimation component\nto approximate error positions, augmented by additional constraints that enable\nerror-correction given the information about error positions.\n  In this work, we select codewords from the set of sequences whose\ndifferential sequences are strong-$(\\ell,\\epsilon)$-locally-balanced. By\nimposing a VT-type constraint and an $L_1$-weight constraint on the\ndifferential sequences of codewords, we construct novel position-estimation\ncodes. When $q\\ge 2$ and $t<q$, or $q$ is even and $t<2q$, this approach gives\na $q$-ary $(\\le t)$-burst-deletion correcting code and a $t$-localized-deletion\ncorrecting code with redundancy $\\log n+(t-1)\\log\\log n+O(1)$. In addition to\nimproving previous redundancy, the method is new and our position-estimation\ncodes are simpler than those in previous works. Finally, we give an efficient\nencoder to encode an arbitrary input sequence into a sequence whose\ndifferential sequence is strong-$(\\ell,\\epsilon)$-locally-balanced. To our\nknowledge, no prior algorithm for this specific task has been reported.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u4f4d\u7f6e\u4f30\u8ba1\u7801\u6784\u9020\u65b9\u6cd5\uff0c\u7528\u4e8e\u7ea0\u6b63\u7a81\u53d1\u5220\u9664\u548c\u5c40\u90e8\u5220\u9664\uff0c\u5197\u4f59\u5ea6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u6784\u9020\u5197\u4f59\u5ea6\u6700\u5c0f\u7684\u7801\uff0c\u4ee5\u7ea0\u6b63\u7a81\u53d1\u5220\u9664\u548c\u5c40\u90e8\u5220\u9664\u3002", "method": "\u901a\u8fc7\u9009\u62e9\u5dee\u5206\u5e8f\u5217\u4e3a\u5f3a\u5c40\u90e8\u5e73\u8861\u7684\u7801\u5b57\uff0c\u5e76\u65bd\u52a0VT\u578b\u7ea6\u675f\u548cL1\u6743\u91cd\u7ea6\u675f\uff0c\u6784\u9020\u65b0\u7684\u4f4d\u7f6e\u4f30\u8ba1\u7801\u3002", "result": "\u5bf9\u4e8e\u7279\u5b9a\u6761\u4ef6\uff0c\u65b0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5197\u4f59\u5ea6\u4e3alog n + (t-1)log log n + O(1)\u7684\u7801\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e0d\u4ec5\u6539\u8fdb\u4e86\u5197\u4f59\u5ea6\uff0c\u4e14\u6784\u9020\u66f4\u7b80\u5355\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7f16\u7801\u5668\u3002"}}
{"id": "2507.03616", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03616", "abs": "https://arxiv.org/abs/2507.03616", "authors": ["Yingxu Wang", "Siwei Liu", "Jinyuan Fang", "Zaiqiao Meng"], "title": "EvoAgentX: An Automated Framework for Evolving Agentic Workflows", "comment": null, "summary": "Multi-agent systems (MAS) have emerged as a powerful paradigm for\norchestrating large language models (LLMs) and specialized tools to\ncollaboratively address complex tasks. However, existing MAS frameworks often\nrequire manual workflow configuration and lack native support for dynamic\nevolution and performance optimization. In addition, many MAS optimization\nalgorithms are not integrated into a unified framework. In this paper, we\npresent EvoAgentX, an open-source platform that automates the generation,\nexecution, and evolutionary optimization of multi-agent workflows. EvoAgentX\nemploys a modular architecture consisting of five core layers: the basic\ncomponents, agent, workflow, evolving, and evaluation layers. Specifically,\nwithin the evolving layer, EvoAgentX integrates three MAS optimization\nalgorithms, TextGrad, AFlow, and MIPRO, to iteratively refine agent prompts,\ntool configurations, and workflow topologies. We evaluate EvoAgentX on\nHotPotQA, MBPP, and MATH for multi-hop reasoning, code generation, and\nmathematical problem solving, respectively, and further assess it on real-world\ntasks using GAIA. Experimental results show that EvoAgentX consistently\nachieves significant performance improvements, including a 7.44% increase in\nHotPotQA F1, a 10.00% improvement in MBPP pass@1, a 10.00% gain in MATH solve\naccuracy, and an overall accuracy improvement of up to 20.00% on GAIA. The\nsource code is available at: https://github.com/EvoAgentX/EvoAgentX", "AI": {"tldr": "EvoAgentX\u662f\u4e00\u4e2a\u5f00\u6e90\u5e73\u53f0\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u3001\u6267\u884c\u548c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u6574\u5408\u4e86\u4e09\u79cd\u4f18\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u6846\u67b6\u9700\u8981\u624b\u52a8\u914d\u7f6e\u5de5\u4f5c\u6d41\uff0c\u7f3a\u4e4f\u52a8\u6001\u6f14\u5316\u548c\u6027\u80fd\u4f18\u5316\u7684\u539f\u751f\u652f\u6301\uff0c\u4e14\u4f18\u5316\u7b97\u6cd5\u672a\u7edf\u4e00\u6574\u5408\u3002", "method": "EvoAgentX\u91c7\u7528\u4e94\u5c42\u6a21\u5757\u5316\u67b6\u6784\uff08\u57fa\u7840\u7ec4\u4ef6\u3001\u667a\u80fd\u4f53\u3001\u5de5\u4f5c\u6d41\u3001\u6f14\u5316\u548c\u8bc4\u4f30\u5c42\uff09\uff0c\u6574\u5408\u4e86TextGrad\u3001AFlow\u548cMIPRO\u4e09\u79cd\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u5728HotPotQA\u3001MBPP\u548cMATH\u7b49\u4efb\u52a1\u4e2d\uff0cEvoAgentX\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff08\u5982HotPotQA F1\u63d0\u9ad87.44%\uff0cMBPP pass@1\u63d0\u9ad810.00%\uff09\u3002", "conclusion": "EvoAgentX\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4efb\u52a1\u3002"}}
{"id": "2507.04806", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04806", "abs": "https://arxiv.org/abs/2507.04806", "authors": ["Zuo Ye", "Gennian Ge"], "title": "On the Maximum Size of Codes Under the Damerau-Levenshtein Metric", "comment": "submitted on 2025.05.02", "summary": "The Damerau-Levenshtein distance between two sequences is the minimum number\nof operations (deletions, insertions, substitutions, and adjacent\ntranspositions) required to convert one sequence into another. Notwithstanding\na long history of this metric, research on error-correcting codes under this\ndistance has remained limited. Recently, motivated by applications in DNA-based\nstorage systems, Gabrys \\textit{et al} and Wang \\texit{et al} reinvigorated\ninterest in this metric. In their works, some codes correcting both deletions\nand adjacent transpositions were constructed. However, theoretical upper bounds\non code sizes under this metric have not yet been established. This paper seeks\nto establish upper bounds for code sizes in the Damerau-Levenshtein metric. Our\nresults show that the code correcting one deletion and asymmetric adjacent\ntranspositions proposed by Wang \\textit{et al} achieves optimal redundancy up\nto an additive constant.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Damerau-Levenshtein\u8ddd\u79bb\u4e0b\u7684\u7ea0\u9519\u7801\uff0c\u5efa\u7acb\u4e86\u7801\u5927\u5c0f\u7684\u7406\u8bba\u4e0a\u754c\uff0c\u5e76\u8bc1\u660eWang\u7b49\u4eba\u7684\u7801\u5728\u5197\u4f59\u5ea6\u4e0a\u662f\u6700\u4f18\u7684\u3002", "motivation": "Damerau-Levenshtein\u8ddd\u79bb\u5728DNA\u5b58\u50a8\u7cfb\u7edf\u4e2d\u6709\u5e94\u7528\uff0c\u4f46\u76f8\u5173\u7ea0\u9519\u7801\u7684\u7814\u7a76\u6709\u9650\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5efa\u7acb\u4e86Damerau-Levenshtein\u8ddd\u79bb\u4e0b\u7801\u5927\u5c0f\u7684\u4e0a\u754c\u3002", "result": "\u8bc1\u660e\u4e86Wang\u7b49\u4eba\u63d0\u51fa\u7684\u7801\u5728\u5197\u4f59\u5ea6\u4e0a\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u672c\u6587\u4e3aDamerau-Levenshtein\u8ddd\u79bb\u4e0b\u7684\u7ea0\u9519\u7801\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u586b\u8865\u4e86\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2507.03637", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03637", "abs": "https://arxiv.org/abs/2507.03637", "authors": ["Francesca Da Ros", "Michael Soprano", "Luca Di Gaspero", "Kevin Roitero"], "title": "Large Language Models for Combinatorial Optimization: A Systematic Review", "comment": null, "summary": "This systematic review explores the application of Large Language Models\n(LLMs) in Combinatorial Optimization (CO). We report our findings using the\nPreferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)\nguidelines. We conduct a literature search via Scopus and Google Scholar,\nexamining over 2,000 publications. We assess publications against four\ninclusion and four exclusion criteria related to their language, research\nfocus, publication year, and type. Eventually, we select 103 studies. We\nclassify these studies into semantic categories and topics to provide a\ncomprehensive overview of the field, including the tasks performed by LLMs, the\narchitectures of LLMs, the existing datasets specifically designed for\nevaluating LLMs in CO, and the field of application. Finally, we identify\nfuture directions for leveraging LLMs in this field.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7PRISMA\u6307\u5357\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7ec4\u5408\u4f18\u5316\uff08CO\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u7b5b\u9009\u51fa103\u9879\u7814\u7a76\u5e76\u5206\u7c7b\uff0c\u603b\u7ed3\u4e86LLMs\u7684\u4efb\u52a1\u3001\u67b6\u6784\u3001\u6570\u636e\u96c6\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u7ec4\u5408\u4f18\u5316\u9886\u57df\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u586b\u8865\u7814\u7a76\u7a7a\u767d\u5e76\u63d0\u4f9b\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u3002", "method": "\u4f7f\u7528PRISMA\u6307\u5357\uff0c\u901a\u8fc7Scopus\u548cGoogle Scholar\u68c0\u7d222000+\u6587\u732e\uff0c\u6309\u8bed\u8a00\u3001\u7814\u7a76\u7126\u70b9\u3001\u5e74\u4efd\u548c\u7c7b\u578b\u7b5b\u9009\u51fa103\u9879\u7814\u7a76\u3002", "result": "\u5206\u7c7b\u603b\u7ed3\u4e86LLMs\u5728CO\u4e2d\u7684\u4efb\u52a1\u3001\u67b6\u6784\u3001\u6570\u636e\u96c6\u53ca\u5e94\u7528\u9886\u57df\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "LLMs\u5728CO\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u96c6\u4ee5\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.04808", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04808", "abs": "https://arxiv.org/abs/2507.04808", "authors": ["Yutao Chen", "Wei Chen"], "title": "Kalman Filter Aided Federated Koopman Learning", "comment": null, "summary": "Real-time control and estimation are pivotal for applications such as\nindustrial automation and future healthcare. The realization of this vision\nrelies heavily on efficient interactions with nonlinear systems. Therefore,\nKoopman learning, which leverages the power of deep learning to linearize\nnonlinear systems, has been one of the most successful examples of mitigating\nthe complexity inherent in nonlinearity. However, the existing literature\nassumes access to accurate system states and abundant high-quality data for\nKoopman analysis, which is usually impractical in real-world scenarios. To fill\nthis void, this paper considers the case where only observations of the system\nare available and where the observation data is insufficient to accomplish an\nindependent Koopman analysis. To this end, we propose Kalman Filter aided\nFederated Koopman Learning (KF-FedKL), which pioneers the combination of Kalman\nfiltering and federated learning with Koopman analysis. By doing so, we can\nachieve collaborative linearization with privacy guarantees. Specifically, we\nemploy a straightforward yet efficient loss function to drive the training of a\ndeep Koopman network for linearization. To obtain system information devoid of\nindividual information from observation data, we leverage the unscented Kalman\nfilter and the unscented Rauch-Tung-Striebel smoother. To achieve collaboration\nbetween clients, we adopt the federated learning framework and develop a\nmodified FedAvg algorithm to orchestrate the collaboration. A convergence\nanalysis of the proposed framework is also presented. Finally, through\nextensive numerical simulations, we showcase the performance of KF-FedKL under\nvarious situations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u8054\u90a6\u5b66\u4e60\u7684Koopman\u5b66\u4e60\u65b9\u6cd5\uff08KF-FedKL\uff09\uff0c\u7528\u4e8e\u5728\u4ec5\u6709\u89c2\u6d4b\u6570\u636e\u4e14\u6570\u636e\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u7ebf\u6027\u5316\u3002", "motivation": "\u73b0\u6709Koopman\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u51c6\u786e\u7cfb\u7edf\u72b6\u6001\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u4f46\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u96be\u4ee5\u6ee1\u8db3\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u4ec5\u80fd\u83b7\u53d6\u89c2\u6d4b\u6570\u636e\u4e14\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faKF-FedKL\u6846\u67b6\uff0c\u7ed3\u5408\u5361\u5c14\u66fc\u6ee4\u6ce2\uff08UKF\u548cURTSS\uff09\u548c\u8054\u90a6\u5b66\u4e60\uff08\u6539\u8fdb\u7684FedAvg\u7b97\u6cd5\uff09\uff0c\u901a\u8fc7\u6df1\u5ea6Koopman\u7f51\u7edc\u5b9e\u73b0\u7ebf\u6027\u5316\u3002", "result": "\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86KF-FedKL\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "conclusion": "KF-FedKL\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7ebf\u6027\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.03682", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03682", "abs": "https://arxiv.org/abs/2507.03682", "authors": ["Rebekah A. Gelp\u00ed", "Eric Xue", "William A. Cunningham"], "title": "Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning", "comment": null, "summary": "We propose a hybrid approach to machine Theory of Mind (ToM) that uses large\nlanguage models (LLMs) as a mechanism for generating hypotheses and likelihood\nfunctions with a Bayesian inverse planning model that computes posterior\nprobabilities for an agent's likely mental states given its actions. Bayesian\ninverse planning models can accurately predict human reasoning on a variety of\nToM tasks, but these models are constrained in their ability to scale these\npredictions to scenarios with a large number of possible hypotheses and\nactions. Conversely, LLM-based approaches have recently demonstrated promise in\nsolving ToM benchmarks, but can exhibit brittleness and failures on reasoning\ntasks even when they pass otherwise structurally identical versions. By\ncombining these two methods, this approach leverages the strengths of each\ncomponent, closely matching optimal results on a task inspired by prior inverse\nplanning models and improving performance relative to models that utilize LLMs\nalone or with chain-of-thought prompting, even with smaller LLMs that typically\nperform poorly on ToM tasks. We also exhibit the model's potential to predict\nmental states on open-ended tasks, offering a promising direction for future\ndevelopment of ToM models and the creation of socially intelligent generative\nagents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u8d1d\u53f6\u65af\u9006\u89c4\u5212\u6a21\u578b\uff0c\u4ee5\u63d0\u5347\u673a\u5668\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u8d1d\u53f6\u65af\u9006\u89c4\u5212\u6a21\u578b\u5728ToM\u4efb\u52a1\u4e2d\u8868\u73b0\u51c6\u786e\u4f46\u96be\u4ee5\u6269\u5c55\uff0c\u800cLLMs\u5728ToM\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\u4f46\u5b58\u5728\u63a8\u7406\u8106\u5f31\u6027\u3002\u7ed3\u5408\u4e24\u8005\u4ee5\u53d1\u6325\u5404\u81ea\u4f18\u52bf\u3002", "method": "\u4f7f\u7528LLMs\u751f\u6210\u5047\u8bbe\u548c\u4f3c\u7136\u51fd\u6570\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u9006\u89c4\u5212\u6a21\u578b\u8ba1\u7b97\u540e\u9a8c\u6982\u7387\uff0c\u9884\u6d4b\u4ee3\u7406\u7684\u5fc3\u7406\u72b6\u6001\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u5728ToM\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528LLMs\u6216\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\uff0c\u5373\u4f7f\u662f\u8f83\u5c0f\u7684LLMs\u4e5f\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aToM\u6a21\u578b\u7684\u672a\u6765\u53d1\u5c55\u548c\u793e\u4f1a\u667a\u80fd\u751f\u6210\u4ee3\u7406\u7684\u521b\u5efa\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.04847", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.04847", "abs": "https://arxiv.org/abs/2507.04847", "authors": ["Jinsheng Li", "Xu Zhang", "Shuang Wu", "Wei Cui"], "title": "Fast and Provable Hankel Tensor Completion for Multi-measurement Spectral Compressed Sensing", "comment": null, "summary": "In this paper, we introduce a novel low-rank Hankel tensor completion\napproach to address the problem of multi-measurement spectral compressed\nsensing. By lifting the multiple signals to a Hankel tensor, we reformulate\nthis problem into a low-rank Hankel tensor completion task, exploiting the\nspectral sparsity via the low multilinear rankness of the tensor. Furthermore,\nwe design a scaled gradient descent algorithm for Hankel tensor completion\n(ScalHT), which integrates the low-rank Tucker decomposition with the Hankel\nstructure. Crucially, we derive novel fast computational formulations that\nleverage the interaction between these two structures, achieving up to an\n$O(\\min\\{s,n\\})$-fold improvement in storage and computational efficiency\ncompared to the existing algorithms, where $n$ is the length of signal, $s$ is\nthe number of measurement vectors. Beyond its practical efficiency, ScalHT is\nbacked by rigorous theoretical guarantees: we establish both recovery and\nlinear convergence guarantees, which, to the best of our knowledge, are the\nfirst of their kind for low-rank Hankel tensor completion. Numerical\nsimulations show that our method exhibits significantly lower computational and\nstorage costs while delivering superior recovery performance compared to prior\narts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f4e\u79e9Hankel\u5f20\u91cf\u8865\u5168\u65b9\u6cd5\uff08ScalHT\uff09\uff0c\u7528\u4e8e\u591a\u6d4b\u91cf\u8c31\u538b\u7f29\u611f\u77e5\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u591a\u6d4b\u91cf\u8c31\u538b\u7f29\u611f\u77e5\u95ee\u9898\uff0c\u5229\u7528Hankel\u5f20\u91cf\u7684\u4f4e\u79e9\u7279\u6027\uff0c\u63d0\u5347\u6548\u7387\u548c\u6062\u590d\u6027\u80fd\u3002", "method": "\u5c06\u591a\u4fe1\u53f7\u63d0\u5347\u4e3aHankel\u5f20\u91cf\uff0c\u8bbe\u8ba1ScalHT\u7b97\u6cd5\uff0c\u7ed3\u5408\u4f4e\u79e9Tucker\u5206\u89e3\u548cHankel\u7ed3\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "ScalHT\u5728\u5b58\u50a8\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u63d0\u5347$O(\\min\\{s,n\\})$\u500d\uff0c\u4e14\u6062\u590d\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ScalHT\u65b9\u6cd5\u9ad8\u6548\u4e14\u7406\u8bba\u53ef\u9760\uff0c\u4e3a\u4f4e\u79e9Hankel\u5f20\u91cf\u8865\u5168\u63d0\u4f9b\u4e86\u9996\u4e2a\u6062\u590d\u548c\u7ebf\u6027\u6536\u655b\u4fdd\u8bc1\u3002"}}
{"id": "2507.03697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03697", "abs": "https://arxiv.org/abs/2507.03697", "authors": ["Qika Lin", "Fangzhi Xu", "Hao Lu", "Kai He", "Rui Mao", "Jun Liu", "Erik Cambria", "Mengling Feng"], "title": "Towards Unified Neurosymbolic Reasoning on Knowledge Graphs", "comment": "15 pages", "summary": "Knowledge Graph (KG) reasoning has received significant attention in the\nfields of artificial intelligence and knowledge engineering, owing to its\nability to autonomously deduce new knowledge and consequently enhance the\navailability and precision of downstream applications. However, current methods\npredominantly concentrate on a single form of neural or symbolic reasoning,\nfailing to effectively integrate the inherent strengths of both approaches.\nFurthermore, the current prevalent methods primarily focus on addressing a\nsingle reasoning scenario, presenting limitations in meeting the diverse\ndemands of real-world reasoning tasks. Unifying the neural and symbolic\nmethods, as well as diverse reasoning scenarios in one model is challenging as\nthere is a natural representation gap between symbolic rules and neural\nnetworks, and diverse scenarios exhibit distinct knowledge structures and\nspecific reasoning objectives. To address these issues, we propose a unified\nneurosymbolic reasoning framework, namely Tunsr, for KG reasoning. Tunsr first\nintroduces a consistent structure of reasoning graph that starts from the query\nentity and constantly expands subsequent nodes by iteratively searching\nposterior neighbors. Based on it, a forward logic message-passing mechanism is\nproposed to update both the propositional representations and attentions, as\nwell as first-order logic (FOL) representations and attentions of each node. In\nthis way, Tunsr conducts the transformation of merging multiple rules by\nmerging possible relations at each step. Finally, the FARI algorithm is\nproposed to induce FOL rules by constantly performing attention calculations\nover the reasoning graph. Extensive experimental results on 19 datasets of four\nreasoning scenarios (transductive, inductive, interpolation, and extrapolation)\ndemonstrate the effectiveness of Tunsr.", "AI": {"tldr": "Tunsr\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u548c\u7b26\u53f7\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u7684\u591a\u6837\u6027\u548c\u7edf\u4e00\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u6574\u5408\u795e\u7ecf\u548c\u7b26\u53f7\u63a8\u7406\u7684\u4f18\u52bf\uff0c\u4e14\u5c40\u9650\u4e8e\u5355\u4e00\u63a8\u7406\u573a\u666f\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u4efb\u52a1\u7684\u591a\u6837\u5316\u9700\u6c42\u3002", "method": "Tunsr\u5f15\u5165\u4e00\u81f4\u7684\u63a8\u7406\u56fe\u7ed3\u6784\uff0c\u901a\u8fc7\u524d\u5411\u903b\u8f91\u6d88\u606f\u4f20\u9012\u673a\u5236\u66f4\u65b0\u8282\u70b9\u8868\u793a\u548c\u6ce8\u610f\u529b\uff0c\u5e76\u5229\u7528FARI\u7b97\u6cd5\u5f52\u7eb3\u4e00\u9636\u903b\u8f91\u89c4\u5219\u3002", "result": "\u5728\u56db\u4e2a\u63a8\u7406\u573a\u666f\u768419\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cTunsr\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u3002", "conclusion": "Tunsr\u6210\u529f\u7edf\u4e00\u4e86\u795e\u7ecf\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u591a\u6837\u6027\u548c\u8868\u793a\u5dee\u8ddd\u95ee\u9898\u3002"}}
{"id": "2507.03722", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2507.03722", "abs": "https://arxiv.org/abs/2507.03722", "authors": ["Ruian Ke", "Ruy M. Ribeiro"], "title": "Roadmap for using large language models (LLMs) to accelerate cross-disciplinary research with an example from computational biology", "comment": null, "summary": "Large language models (LLMs) are powerful artificial intelligence (AI) tools\ntransforming how research is conducted. However, their use in research has been\nmet with skepticism, due to concerns about hallucinations, biases and potential\nharms to research. These emphasize the importance of clearly understanding the\nstrengths and weaknesses of LLMs to ensure their effective and responsible use.\nHere, we present a roadmap for integrating LLMs into cross-disciplinary\nresearch, where effective communication, knowledge transfer and collaboration\nacross diverse fields are essential but often challenging. We examine the\ncapabilities and limitations of LLMs and provide a detailed computational\nbiology case study (on modeling HIV rebound dynamics) demonstrating how\niterative interactions with an LLM (ChatGPT) can facilitate interdisciplinary\ncollaboration and research. We argue that LLMs are best used as augmentative\ntools within a human-in-the-loop framework. Looking forward, we envisage that\nthe responsible use of LLMs will enhance innovative cross-disciplinary research\nand substantially accelerate scientific discoveries.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u5f3a\u8c03\u5176\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\uff0c\u5e76\u4ee5\u8ba1\u7b97\u751f\u7269\u5b66\u6848\u4f8b\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002", "motivation": "LLMs\u5728\u7814\u7a76\u4e2d\u53d7\u5230\u8d28\u7591\uff0c\u9700\u660e\u786e\u5176\u4f18\u7f3a\u70b9\u4ee5\u786e\u4fdd\u8d1f\u8d23\u4efb\u7684\u4f7f\u7528\u3002", "method": "\u63d0\u51fa\u6574\u5408LLMs\u7684\u8def\u7ebf\u56fe\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff08HIV\u53cd\u5f39\u52a8\u529b\u5b66\u5efa\u6a21\uff09\u5c55\u793a\u5176\u5982\u4f55\u4fc3\u8fdb\u8de8\u5b66\u79d1\u5408\u4f5c\u3002", "result": "LLMs\u5728\u4eba\u7c7b\u53c2\u4e0e\u7684\u6846\u67b6\u4e0b\u80fd\u6709\u6548\u8f85\u52a9\u7814\u7a76\uff0c\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u3002", "conclusion": "\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528LLMs\u5c06\u63a8\u52a8\u8de8\u5b66\u79d1\u521b\u65b0\u7814\u7a76\u3002"}}
{"id": "2507.05057", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.05057", "abs": "https://arxiv.org/abs/2507.05057", "authors": ["Qingxiao Huang", "Yizhe Zhao", "Jie Hu", "Kun Yang", "Yuguang Fang"], "title": "Circular Holographic MIMO Beamforming for Integrated Data and Energy Multicast Systems", "comment": null, "summary": "Thanks to the application of metamaterials, holographic multiple-input\nmultiple-output (H-MIMO) is expected to achieve a higher spatial diversity gain\nwith lower hardware complexity. With the aid of a circular antenna arrangement\nof H-MIMO, integrated data and energy multicast (IDEM) can fully exploit the\nnear-field channel to realize wider range of energy focusing and higher\nachievable rate. In this paper, we derive the closed-form near-field resolution\nfunction in 3D space and show the asymptotic spatial orthogonality of\nnear-field channel for circular antenna array. We then investigate the\nbeamforming designs for IDEM systems, where the minimum rate of data users\n(DUs) are maximized while guaranteeing the energy harvesting requirements for\nenergy users (EUs). Specifically, the asymptotically optimal fully-digital\nbeamformer is first obtained based on the spatial orthogonality. Then, the\nalternating optimization is adopted for the H-MIMO beamforming, where the\ndigital beamformer is obtained in closed form and the analog beamformers of\nthree different control modes are then obtained, respectively. Scaling schemes\nare also investigated to further improve the IDEM performance. Numerical\nresults verify the correctness of the resolution function and asymptotic\northogonality. Moreover, the proposed beamforming schemes with very low\ncomplexity outperform benchmark schemes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u6750\u6599\u7684H-MIMO\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b9e\u73b0\u8fd1\u573a\u4fe1\u9053\u7684\u9ad8\u7a7a\u95f4\u591a\u6837\u6027\u548c\u4f4e\u786c\u4ef6\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u7814\u7a76\u4e86\u6570\u636e\u4e0e\u80fd\u91cf\u591a\u64ad\uff08IDEM\uff09\u7684\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u3002", "motivation": "\u5229\u7528\u8d85\u6750\u6599\u548c\u5706\u5f62\u5929\u7ebf\u9635\u5217\u7684H-MIMO\u7cfb\u7edf\uff0c\u53ef\u4ee5\u5145\u5206\u5229\u7528\u8fd1\u573a\u4fe1\u9053\u5b9e\u73b0\u66f4\u5e7f\u7684\u80fd\u91cf\u805a\u7126\u8303\u56f4\u548c\u66f4\u9ad8\u7684\u6570\u636e\u901f\u7387\u3002", "method": "\u63a8\u5bfc\u4e863D\u7a7a\u95f4\u4e2d\u7684\u8fd1\u573a\u5206\u8fa8\u7387\u51fd\u6570\uff0c\u8bc1\u660e\u4e86\u8fd1\u573a\u4fe1\u9053\u7684\u6e10\u8fd1\u7a7a\u95f4\u6b63\u4ea4\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316\u7684\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5206\u8fa8\u7387\u51fd\u6570\u548c\u6e10\u8fd1\u6b63\u4ea4\u6027\u7684\u6b63\u786e\u6027\uff0c\u63d0\u51fa\u7684\u4f4e\u590d\u6742\u5ea6\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u4f18\u4e8e\u57fa\u51c6\u65b9\u6848\u3002", "conclusion": "H-MIMO\u7cfb\u7edf\u5728IDEM\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u51fa\u7684\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u5177\u6709\u9ad8\u6548\u6027\u548c\u4f4e\u590d\u6742\u5ea6\u3002"}}
{"id": "2507.03726", "categories": ["cs.AI", "cs.CL", "cs.IR", "I.2"], "pdf": "https://arxiv.org/pdf/2507.03726", "abs": "https://arxiv.org/abs/2507.03726", "authors": ["Riya Naik", "Ashwin Srinivasan", "Swati Agarwal", "Estrid He"], "title": "Agent-Based Detection and Resolution of Incompleteness and Ambiguity in Interactions with Large Language Models", "comment": "14 pages. arXiv admin note: text overlap with arXiv:2503.17936", "summary": "Many of us now treat LLMs as modern-day oracles asking it almost any kind of\nquestion. However, consulting an LLM does not have to be a single turn\nactivity. But long multi-turn interactions can get tedious if it is simply to\nclarify contextual information that can be arrived at through reasoning. In\nthis paper, we examine the use of agent-based architecture to bolster LLM-based\nQuestion-Answering systems with additional reasoning capabilities. We examine\nthe automatic resolution of potential incompleteness or ambiguities in\nquestions by transducers implemented using LLM-based agents. We focus on\nseveral benchmark datasets that are known to contain questions with these\ndeficiencies to varying degrees. We equip different LLMs (GPT-3.5-Turbo and\nLlama-4-Scout) with agents that act as specialists in detecting and resolving\ndeficiencies of incompleteness and ambiguity. The agents are implemented as\nzero-shot ReAct agents. Rather than producing an answer in a single step, the\nmodel now decides between 3 actions a) classify b) resolve c) answer. Action a)\ndecides if the question is incomplete, ambiguous, or normal. Action b)\ndetermines if any deficiencies identified can be resolved. Action c) answers\nthe resolved form of the question. We compare the use of LLMs with and without\nthe use of agents with these components. Our results show benefits of agents\nwith transducer 1) A shortening of the length of interactions with human 2) An\nimprovement in the answer quality and 3) Explainable resolution of deficiencies\nin the question. On the negative side we find while it may result in additional\nLLM invocations and in some cases, increased latency. But on tested datasets,\nthe benefits outweigh the costs except when questions already have sufficient\ncontext. Suggesting the agent-based approach could be a useful mechanism to\nharness the power of LLMs to develop more robust QA systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u57fa\u4e8e\u4ee3\u7406\u7684\u67b6\u6784\u589e\u5f3aLLM\u95ee\u7b54\u7cfb\u7edf\u7684\u63a8\u7406\u80fd\u529b\uff0c\u81ea\u52a8\u89e3\u51b3\u63d0\u95ee\u4e2d\u7684\u4e0d\u5b8c\u6574\u6216\u6a21\u7cca\u95ee\u9898\uff0c\u7f29\u77ed\u4ea4\u4e92\u65f6\u95f4\u5e76\u63d0\u9ad8\u7b54\u6848\u8d28\u91cf\u3002", "motivation": "\u5f53\u524dLLM\u95ee\u7b54\u7cfb\u7edf\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u53ef\u80fd\u56e0\u4e0a\u4e0b\u6587\u4e0d\u6e05\u6670\u800c\u663e\u5f97\u7e41\u7410\uff0c\u9700\u901a\u8fc7\u63a8\u7406\u89e3\u51b3\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u4ee3\u7406\uff08\u5982GPT-3.5-Turbo\u548cLlama-4-Scout\uff09\u4f5c\u4e3a\u96f6\u6837\u672cReAct\u4ee3\u7406\uff0c\u901a\u8fc7\u5206\u7c7b\u3001\u89e3\u51b3\u548c\u56de\u7b54\u4e09\u4e2a\u52a8\u4f5c\u5904\u7406\u95ee\u9898\u3002", "result": "\u4ee3\u7406\u65b9\u6cd5\u7f29\u77ed\u4e86\u4ea4\u4e92\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e86\u7b54\u6848\u8d28\u91cf\uff0c\u5e76\u80fd\u89e3\u91ca\u95ee\u9898\u7f3a\u9677\u7684\u89e3\u51b3\u8fc7\u7a0b\uff0c\u4f46\u53ef\u80fd\u589e\u52a0LLM\u8c03\u7528\u548c\u5ef6\u8fdf\u3002", "conclusion": "\u4ee3\u7406\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5f00\u53d1\u66f4\u5065\u58ee\u7684\u95ee\u7b54\u7cfb\u7edf\u3002"}}
{"id": "2507.05121", "categories": ["cs.IT", "cs.AI", "cs.CV", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.05121", "abs": "https://arxiv.org/abs/2507.05121", "authors": ["Jiajia Guo", "Peiwen Jiang", "Chao-Kai Wen", "Shi Jin", "Jun Zhang"], "title": "LVM4CSI: Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks", "comment": "This work has been submitted for possible publication", "summary": "Accurate channel state information (CSI) is critical to the performance of\nwireless communication systems, especially with the increasing scale and\ncomplexity introduced by 5G and future 6G technologies. While artificial\nintelligence (AI) offers a promising approach to CSI acquisition and\nutilization, existing methods largely depend on task-specific neural networks\n(NNs) that require expert-driven design and large training datasets, limiting\ntheir generalizability and practicality. To address these challenges, we\npropose LVM4CSI, a general and efficient framework that leverages the\nstructural similarity between CSI and computer vision (CV) data to directly\napply large vision models (LVMs) pre-trained on extensive CV datasets to\nwireless tasks without any fine-tuning, in contrast to large language\nmodel-based methods that generally necessitate fine-tuning. LVM4CSI maps CSI\ntasks to analogous CV tasks, transforms complex-valued CSI into visual formats\ncompatible with LVMs, and integrates lightweight trainable layers to adapt\nextracted features to specific communication objectives. We validate LVM4CSI\nthrough three representative case studies, including channel estimation, human\nactivity recognition, and user localization. Results demonstrate that LVM4CSI\nachieves comparable or superior performance to task-specific NNs, including an\nimprovement exceeding 9.61 dB in channel estimation and approximately 40%\nreduction in localization error. Furthermore, it significantly reduces the\nnumber of trainable parameters and eliminates the need for task-specific NN\ndesign.", "AI": {"tldr": "LVM4CSI\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u5229\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u9884\u8bad\u7ec3\u6a21\u578b\u5904\u7406\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684CSI\u4efb\u52a1\uff0c\u65e0\u9700\u5fae\u8c03\uff0c\u6027\u80fd\u4f18\u4e8e\u4efb\u52a1\u4e13\u7528\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709AI\u65b9\u6cd5\u4f9d\u8d56\u4efb\u52a1\u4e13\u7528\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u95ee\u9898\uff0c\u63d0\u9ad8CSI\u83b7\u53d6\u7684\u901a\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5c06CSI\u4efb\u52a1\u6620\u5c04\u4e3a\u7c7b\u4f3c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff0c\u8f6c\u6362CSI\u4e3a\u89c6\u89c9\u683c\u5f0f\uff0c\u7ed3\u5408\u8f7b\u91cf\u53ef\u8bad\u7ec3\u5c42\u9002\u5e94\u901a\u4fe1\u76ee\u6807\u3002", "result": "\u5728\u4fe1\u9053\u4f30\u8ba1\u3001\u6d3b\u52a8\u8bc6\u522b\u548c\u7528\u6237\u5b9a\u4f4d\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u8bbe\u8ba1\u9700\u6c42\u3002", "conclusion": "LVM4CSI\u4e3a\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.03775", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03775", "abs": "https://arxiv.org/abs/2507.03775", "authors": ["Hiba Bederina"], "title": "Optimizing UAV Trajectories via a Simplified Close Enough TSP Approach", "comment": null, "summary": "This article explores an approach to addressing the Close Enough Traveling\nSalesman Problem (CETSP). The objective is to streamline the mathematical\nformulation by introducing reformulations that approximate the Euclidean\ndistances and simplify the objective function. Additionally, the use of convex\nsets in the constraint design offers computational benefits. The proposed\nmethodology is empirically validated on real-world CETSP instances, with the\naid of computational strategies such as a fragmented CPLEX-based approach.\nResults demonstrate its effectiveness in managing computational resources\nwithout compromising solution quality. Furthermore, the article analyzes the\nbehavior of the proposed mathematical formulations, providing comprehensive\ninsights into their performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3Close Enough Traveling Salesman Problem\uff08CETSP\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5316\u6570\u5b66\u516c\u5f0f\u548c\u5229\u7528\u51f8\u96c6\u7ea6\u675f\u8bbe\u8ba1\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u65e8\u5728\u7b80\u5316CETSP\u7684\u6570\u5b66\u5efa\u6a21\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u89e3\u7684\u8d28\u91cf\u3002", "method": "\u5f15\u5165\u8fd1\u4f3c\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u91cd\u65b0\u516c\u5f0f\u5316\uff0c\u7b80\u5316\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u51f8\u96c6\u7ea6\u675f\u8bbe\u8ba1\u3002\u91c7\u7528\u5206\u6bb5CPLEX\u8ba1\u7b97\u7b56\u7565\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u5728\u771f\u5b9eCETSP\u5b9e\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u9ad8\u6548\u7ba1\u7406\u8ba1\u7b97\u8d44\u6e90\u4e14\u4e0d\u5f71\u54cd\u89e3\u7684\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u5b66\u516c\u5f0f\u5728\u6027\u80fd\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4e3aCETSP\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03793", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03793", "abs": "https://arxiv.org/abs/2507.03793", "authors": ["Jim O'Connor", "Gary B. Parker", "Mustafa Bugti"], "title": "Learning Dark Souls Combat Through Pixel Input With Neuroevolution", "comment": "IEEE Conference on Games 2025", "summary": "This paper investigates the application of Neuroevolution of Augmenting\nTopologies (NEAT) to automate gameplay in Dark Souls, a notoriously challenging\naction role-playing game characterized by complex combat mechanics, dynamic\nenvironments, and high-dimensional visual inputs. Unlike traditional\nreinforcement learning or game playing approaches, our method evolves neural\nnetworks directly from raw pixel data, circumventing the need for explicit\ngame-state information. To facilitate this approach, we introduce the Dark\nSouls API (DSAPI), a novel Python framework leveraging real-time computer\nvision techniques for extracting critical game metrics, including player and\nenemy health states. Using NEAT, agents evolve effective combat strategies for\ndefeating the Asylum Demon, the game's initial boss, without predefined\nbehaviors or domain-specific heuristics. Experimental results demonstrate that\nevolved agents achieve up to a 35% success rate, indicating the viability of\nneuroevolution in addressing complex, visually intricate gameplay scenarios.\nThis work represents an interesting application of vision-based neuroevolution,\nhighlighting its potential use in a wide range of challenging game environments\nlacking direct API support or well-defined state representations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86NEAT\u5728\u300a\u9ed1\u6697\u4e4b\u9b42\u300b\u6e38\u620f\u81ea\u52a8\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u76f4\u63a5\u8fdb\u5316\u795e\u7ecf\u7f51\u7edc\u4ece\u50cf\u7d20\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u65e0\u9700\u6e38\u620f\u72b6\u6001\u4fe1\u606f\uff0c\u6210\u529f\u7387\u8fbe\u523035%\u3002", "motivation": "\u63a2\u7d22\u5728\u590d\u6742\u89c6\u89c9\u8f93\u5165\u548c\u9ad8\u96be\u5ea6\u6e38\u620f\u73af\u5883\u4e2d\uff0c\u795e\u7ecf\u8fdb\u5316\u65b9\u6cd5\uff08NEAT\uff09\u7684\u53ef\u884c\u6027\uff0c\u5c24\u5176\u662f\u7f3a\u4e4fAPI\u652f\u6301\u6216\u660e\u786e\u72b6\u6001\u8868\u793a\u7684\u573a\u666f\u3002", "method": "\u5f15\u5165DSAPI\u6846\u67b6\uff0c\u7ed3\u5408\u5b9e\u65f6\u8ba1\u7b97\u673a\u89c6\u89c9\u63d0\u53d6\u6e38\u620f\u6570\u636e\uff0c\u4f7f\u7528NEAT\u76f4\u63a5\u8fdb\u5316\u795e\u7ecf\u7f51\u7edc\uff0c\u8bad\u7ec3\u4ee3\u7406\u51fb\u8d25\u521d\u59cbBoss\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8fdb\u5316\u540e\u7684\u4ee3\u7406\u5728\u51fb\u8d25\u521d\u59cbBoss\u65f6\u8fbe\u523035%\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u89c6\u89c9\u7684\u795e\u7ecf\u8fdb\u5316\u5728\u590d\u6742\u6e38\u620f\u73af\u5883\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u7f3a\u4e4f\u76f4\u63a5API\u652f\u6301\u7684\u573a\u666f\u3002"}}
{"id": "2507.03802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03802", "abs": "https://arxiv.org/abs/2507.03802", "authors": ["Mayank Kejriwal", "Shilpa Thomas"], "title": "Generating Novelty in Open-World Multi-Agent Strategic Board Games", "comment": "16 pages, shorter version demonstrated in NeurIPS 2020", "summary": "We describe GNOME (Generating Novelty in Open-world Multi-agent\nEnvironments), an experimental platform that is designed to test the\neffectiveness of multi-agent AI systems when faced with \\emph{novelty}. GNOME\nseparates the development of AI gameplaying agents with the simulator, allowing\n\\emph{unanticipated} novelty (in essence, novelty that is not subject to\nmodel-selection bias). Using a Web GUI, GNOME was recently demonstrated at\nNeurIPS 2020 using the game of Monopoly to foster an open discussion on AI\nrobustness and the nature of novelty in real-world environments. In this\narticle, we further detail the key elements of the demonstration, and also\nprovide an overview of the experimental design that is being currently used in\nthe DARPA Science of Artificial Intelligence and Learning for Open-World\nNovelty (SAIL-ON) program to evaluate external teams developing\nnovelty-adaptive gameplaying agents.", "AI": {"tldr": "GNOME\u662f\u4e00\u4e2a\u7528\u4e8e\u6d4b\u8bd5\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u9762\u5bf9\u65b0\u9896\u6027\u8868\u73b0\u7684\u5f00\u6e90\u5e73\u53f0\uff0c\u652f\u6301\u672a\u9884\u671f\u7684\u65b0\u9896\u6027\uff0c\u5e76\u5728NeurIPS 2020\u4e0a\u4ee5\u300a\u5927\u5bcc\u7fc1\u300b\u6e38\u620f\u5c55\u793a\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u9762\u5bf9\u672a\u9884\u671f\u65b0\u9896\u6027\u7684\u9002\u5e94\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5206\u79bbAI\u5f00\u53d1\u4e0e\u6a21\u62df\u5668\uff0cGNOME\u5e73\u53f0\u652f\u6301\u672a\u9884\u671f\u65b0\u9896\u6027\u7684\u6d4b\u8bd5\uff0c\u5e76\u5229\u7528Web GUI\u5c55\u793a\u3002", "result": "GNOME\u5728NeurIPS 2020\u4e0a\u6210\u529f\u5c55\u793a\uff0c\u5e76\u7528\u4e8eDARPA SAIL-ON\u9879\u76ee\u8bc4\u4f30\u65b0\u9896\u6027\u9002\u5e94\u667a\u80fd\u4f53\u3002", "conclusion": "GNOME\u4e3a\u7814\u7a76AI\u9c81\u68d2\u6027\u548c\u5f00\u653e\u4e16\u754c\u65b0\u9896\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.03811", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03811", "abs": "https://arxiv.org/abs/2507.03811", "authors": ["Gianlucca Zuin", "Saulo Mastelini", "T\u00falio Loures", "Adriano Veloso"], "title": "Leveraging Large Language Models for Tacit Knowledge Discovery in Organizational Contexts", "comment": "8 pages, 4 figures, accepted to International Joint Conference on\n  Neural Networks (IJCNN) 2025", "summary": "Documenting tacit knowledge in organizations can be a challenging task due to\nincomplete initial information, difficulty in identifying knowledgeable\nindividuals, the interplay of formal hierarchies and informal networks, and the\nneed to ask the right questions. To address this, we propose an agent-based\nframework leveraging large language models (LLMs) to iteratively reconstruct\ndataset descriptions through interactions with employees. Modeling knowledge\ndissemination as a Susceptible-Infectious (SI) process with waning infectivity,\nwe conduct 864 simulations across various synthetic company structures and\ndifferent dissemination parameters. Our results show that the agent achieves\n94.9% full-knowledge recall, with self-critical feedback scores strongly\ncorrelating with external literature critic scores. We analyze how each\nsimulation parameter affects the knowledge retrieval process for the agent. In\nparticular, we find that our approach is able to recover information without\nneeding to access directly the only domain specialist. These findings highlight\nthe agent's ability to navigate organizational complexity and capture\nfragmented knowledge that would otherwise remain inaccessible.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u5458\u5de5\u4ea4\u4e92\u8fed\u4ee3\u91cd\u5efa\u6570\u636e\u96c6\u63cf\u8ff0\uff0c\u89e3\u51b3\u4e86\u7ec4\u7ec7\u4e2d\u9690\u6027\u77e5\u8bc6\u8bb0\u5f55\u7684\u6311\u6218\u3002", "motivation": "\u7ec4\u7ec7\u4e2d\u9690\u6027\u77e5\u8bc6\u8bb0\u5f55\u5b58\u5728\u521d\u59cb\u4fe1\u606f\u4e0d\u5b8c\u6574\u3001\u96be\u4ee5\u8bc6\u522b\u77e5\u8bc6\u4e2a\u4f53\u3001\u6b63\u5f0f\u4e0e\u975e\u6b63\u5f0f\u7f51\u7edc\u4ea4\u7ec7\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u77e5\u8bc6\u4f20\u64ad\u5efa\u6a21\u4e3aSI\u8fc7\u7a0b\uff0c\u5e76\u8fdb\u884c864\u6b21\u6a21\u62df\u3002", "result": "\u4ee3\u7406\u5b9e\u73b0\u4e8694.9%\u7684\u5b8c\u6574\u77e5\u8bc6\u53ec\u56de\u7387\uff0c\u81ea\u6211\u53cd\u9988\u5206\u6570\u4e0e\u5916\u90e8\u6587\u732e\u8bc4\u5206\u5f3a\u76f8\u5173\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u83b7\u5206\u6563\u77e5\u8bc6\uff0c\u65e0\u9700\u76f4\u63a5\u8bbf\u95ee\u9886\u57df\u4e13\u5bb6\uff0c\u5c55\u793a\u4e86\u4ee3\u7406\u5904\u7406\u7ec4\u7ec7\u590d\u6742\u6027\u7684\u80fd\u529b\u3002"}}
{"id": "2507.03829", "categories": ["cs.AI", "I.2.4; I.2.1"], "pdf": "https://arxiv.org/pdf/2507.03829", "abs": "https://arxiv.org/abs/2507.03829", "authors": ["George Hannah", "Jacopo de Berardinis", "Terry R. Payne", "Valentina Tamma", "Andrew Mitchell", "Ellen Piercy", "Ewan Johnson", "Andrew Ng", "Harry Rostron", "Boris Konev"], "title": "RELRaE: LLM-Based Relationship Extraction, Labelling, Refinement, and Evaluation", "comment": "18 Pages, 8 Tables, Under-review at ISWC 2025", "summary": "A large volume of XML data is produced in experiments carried out by robots\nin laboratories. In order to support the interoperability of data between labs,\nthere is a motivation to translate the XML data into a knowledge graph. A key\nstage of this process is the enrichment of the XML schema to lay the foundation\nof an ontology schema. To achieve this, we present the RELRaE framework, a\nframework that employs large language models in different stages to extract and\naccurately label the relationships implicitly present in the XML schema. We\ninvestigate the capability of LLMs to accurately generate these labels and then\nevaluate them. Our work demonstrates that LLMs can be effectively used to\nsupport the generation of relationship labels in the context of lab automation,\nand that they can play a valuable role within semi-automatic ontology\ngeneration frameworks more generally.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faRELRaE\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4eceXML\u6570\u636e\u4e2d\u63d0\u53d6\u548c\u6807\u6ce8\u5173\u7cfb\uff0c\u652f\u6301\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\u4e2d\u7684\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u3002", "motivation": "\u89e3\u51b3\u5b9e\u9a8c\u5ba4\u673a\u5668\u4eba\u4ea7\u751f\u7684XML\u6570\u636e\u4e92\u64cd\u4f5c\u6027\u95ee\u9898\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\u3002", "method": "\u4f7f\u7528RELRaE\u6846\u67b6\uff0c\u901a\u8fc7LLMs\u5206\u9636\u6bb5\u63d0\u53d6\u548c\u6807\u6ce8XML\u6a21\u5f0f\u4e2d\u7684\u9690\u542b\u5173\u7cfb\u3002", "result": "LLMs\u80fd\u6709\u6548\u652f\u6301\u5173\u7cfb\u6807\u7b7e\u7684\u751f\u6210\uff0c\u5728\u534a\u81ea\u52a8\u672c\u4f53\u751f\u6210\u6846\u67b6\u4e2d\u5177\u6709\u4ef7\u503c\u3002", "conclusion": "LLMs\u5728\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\u548c\u672c\u4f53\u751f\u6210\u4e2d\u5177\u6709\u5b9e\u7528\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2507.03834", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03834", "abs": "https://arxiv.org/abs/2507.03834", "authors": ["Michael J. Zellinger", "Matt Thomson"], "title": "Economic Evaluation of LLMs", "comment": "14 pages, 6 figures", "summary": "Practitioners often navigate LLM performance trade-offs by plotting Pareto\nfrontiers of optimal accuracy-cost trade-offs. However, this approach offers no\nway to compare between LLMs with distinct strengths and weaknesses: for\nexample, a cheap, error-prone model vs a pricey but accurate one. To address\nthis gap, we propose economic evaluation of LLMs. Our framework quantifies the\nperformance trade-off of an LLM as a single number based on the economic\nconstraints of a concrete use case, all expressed in dollars: the cost of\nmaking a mistake, the cost of incremental latency, and the cost of abstaining\nfrom a query. We apply our economic evaluation framework to compare the\nperformance of reasoning and non-reasoning models on difficult questions from\nthe MATH benchmark, discovering that reasoning models offer better\naccuracy-cost tradeoffs as soon as the economic cost of a mistake exceeds\n\\$0.01. In addition, we find that single large LLMs often outperform cascades\nwhen the cost of making a mistake is as low as \\$0.1. Overall, our findings\nsuggest that when automating meaningful human tasks with AI models,\npractitioners should typically use the most powerful available model, rather\nthan attempt to minimize AI deployment costs, since deployment costs are likely\ndwarfed by the economic impact of AI errors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ecf\u6d4e\u8bc4\u4f30\u7684LLM\u6027\u80fd\u6bd4\u8f83\u6846\u67b6\uff0c\u5c06\u6027\u80fd\u6743\u8861\u91cf\u5316\u4e3a\u5355\u4e00\u6570\u503c\uff0c\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5728\u9519\u8bef\u6210\u672c\u8d85\u8fc70.01\u7f8e\u5143\u65f6\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6bd4\u8f83\u5177\u6709\u4e0d\u540c\u4f18\u7f3a\u70b9\u7684LLM\u7684\u95ee\u9898\uff0c\u5982\u4f4e\u6210\u672c\u9ad8\u9519\u8bef\u7387\u6a21\u578b\u4e0e\u9ad8\u6210\u672c\u9ad8\u51c6\u786e\u7387\u6a21\u578b\u7684\u5bf9\u6bd4\u3002", "method": "\u63d0\u51fa\u7ecf\u6d4e\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u6027\u80fd\u6743\u8861\u91cf\u5316\u4e3a\u57fa\u4e8e\u5177\u4f53\u7528\u4f8b\u7ecf\u6d4e\u7ea6\u675f\u7684\u5355\u4e00\u6570\u503c\uff08\u5982\u9519\u8bef\u6210\u672c\u3001\u5ef6\u8fdf\u6210\u672c\u7b49\uff09\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u9519\u8bef\u6210\u672c\u8d85\u8fc70.01\u7f8e\u5143\u65f6\u8868\u73b0\u66f4\u4f18\uff1b\u5355\u4e2a\u5927\u578bLLM\u5728\u9519\u8bef\u6210\u672c\u4f4e\u81f30.1\u7f8e\u5143\u65f6\u4f18\u4e8e\u7ea7\u8054\u6a21\u578b\u3002", "conclusion": "\u5728\u81ea\u52a8\u5316\u91cd\u8981\u4efb\u52a1\u65f6\uff0c\u5e94\u4f18\u5148\u4f7f\u7528\u6700\u5f3a\u5927\u7684\u6a21\u578b\uff0c\u56e0\u4e3a\u90e8\u7f72\u6210\u672c\u8fdc\u4f4e\u4e8e\u9519\u8bef\u7684\u7ecf\u6d4e\u5f71\u54cd\u3002"}}
{"id": "2507.03839", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2507.03839", "abs": "https://arxiv.org/abs/2507.03839", "authors": ["Shuowen Li", "Kexin Wang", "Minglu Fang", "Danqi Huang", "Ali Asadipour", "Haipeng Mi", "Yitong Sun"], "title": "Participatory Evolution of Artificial Life Systems via Semantic Feedback", "comment": "10 pages", "summary": "We present a semantic feedback framework that enables natural language to\nguide the evolution of artificial life systems. Integrating a\nprompt-to-parameter encoder, a CMA-ES optimizer, and CLIP-based evaluation, the\nsystem allows user intent to modulate both visual outcomes and underlying\nbehavioral rules. Implemented in an interactive ecosystem simulation, the\nframework supports prompt refinement, multi-agent interaction, and emergent\nrule synthesis. User studies show improved semantic alignment over manual\ntuning and demonstrate the system's potential as a platform for participatory\ngenerative design and open-ended evolution.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u53cd\u9988\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u5bfc\u4eba\u5de5\u751f\u547d\u7cfb\u7edf\u7684\u6f14\u5316\uff0c\u7ed3\u5408\u7f16\u7801\u5668\u3001\u4f18\u5316\u5668\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5b9e\u73b0\u7528\u6237\u610f\u56fe\u5bf9\u89c6\u89c9\u548c\u884c\u4e3a\u89c4\u5219\u7684\u8c03\u63a7\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u66f4\u76f4\u89c2\u5730\u6307\u5bfc\u4eba\u5de5\u751f\u547d\u7cfb\u7edf\u7684\u6f14\u5316\uff0c\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "method": "\u96c6\u6210\u63d0\u793a\u5230\u53c2\u6570\u7f16\u7801\u5668\u3001CMA-ES\u4f18\u5316\u5668\u548c\u57fa\u4e8eCLIP\u7684\u8bc4\u4f30\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u751f\u6001\u7cfb\u7edf\u6a21\u62df\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u76f8\u6bd4\u624b\u52a8\u8c03\u6574\uff0c\u8bed\u4e49\u5bf9\u9f50\u6548\u679c\u66f4\u597d\uff0c\u5c55\u793a\u4e86\u7cfb\u7edf\u5728\u751f\u6210\u8bbe\u8ba1\u548c\u5f00\u653e\u5f0f\u6f14\u5316\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53c2\u4e0e\u5f0f\u751f\u6210\u8bbe\u8ba1\u548c\u5f00\u653e\u5f0f\u6f14\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5e73\u53f0\u3002"}}
{"id": "2507.03868", "categories": ["cs.AI", "cs.CE", "cs.CY", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.03868", "abs": "https://arxiv.org/abs/2507.03868", "authors": ["Xinyi Wu", "Yanhao Jia", "Luwei Xiao", "Shuai Zhao", "Fengkuang Chiang", "Erik Cambria"], "title": "From Query to Explanation: Uni-RAG for Multi-Modal Retrieval-Augmented Learning in STEM", "comment": null, "summary": "In AI-facilitated teaching, leveraging various query styles to interpret\nabstract educational content is crucial for delivering effective and accessible\nlearning experiences. However, existing retrieval systems predominantly focus\non natural text-image matching and lack the capacity to address the diversity\nand ambiguity inherent in real-world educational scenarios. To address this\nlimitation, we develop a lightweight and efficient multi-modal retrieval\nmodule, named Uni-Retrieval, which extracts query-style prototypes and\ndynamically matches them with tokens from a continually updated Prompt Bank.\nThis Prompt Bank encodes and stores domain-specific knowledge by leveraging a\nMixture-of-Expert Low-Rank Adaptation (MoE-LoRA) module and can be adapted to\nenhance Uni-Retrieval's capability to accommodate unseen query types at test\ntime. To enable natural language educational content generation, we integrate\nthe original Uni-Retrieval with a compact instruction-tuned language model,\nforming a complete retrieval-augmented generation pipeline named Uni-RAG. Given\na style-conditioned query, Uni-RAG first retrieves relevant educational\nmaterials and then generates human-readable explanations, feedback, or\ninstructional content aligned with the learning objective. Experimental results\non SER and other multi-modal benchmarks show that Uni-RAG outperforms baseline\nretrieval and RAG systems in both retrieval accuracy and generation quality,\nwhile maintaining low computational cost. Our framework provides a scalable,\npedagogically grounded solution for intelligent educational systems, bridging\nretrieval and generation to support personalized, explainable, and efficient\nlearning assistance across diverse STEM scenarios.", "AI": {"tldr": "Uni-Retrieval\u548cUni-RAG\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u68c0\u7d22\u548c\u751f\u6210\uff0c\u63d0\u5347\u6559\u80b2\u5185\u5bb9\u7684\u591a\u6837\u6027\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u6559\u80b2\u573a\u666f\u4e2d\u7684\u591a\u6837\u6027\u548c\u6a21\u7cca\u6027\uff0c\u9700\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u68c0\u7d22\u6a21\u5757Uni-Retrieval\uff0c\u7ed3\u5408Prompt Bank\u548cMoE-LoRA\u6a21\u5757\uff0c\u5e76\u4e0e\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5f62\u6210Uni-RAG\u3002", "result": "\u5728SER\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUni-RAG\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u751f\u6210\u8d28\u91cf\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "Uni-RAG\u4e3a\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4e2a\u6027\u5316\u3001\u53ef\u89e3\u91ca\u7684\u9ad8\u6548\u5b66\u4e60\u8f85\u52a9\u3002"}}
{"id": "2507.03870", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03870", "abs": "https://arxiv.org/abs/2507.03870", "authors": ["Rahil P Mehta", "Yashwanthi Anand", "Manish Motwani", "Sandhya Saisubramanian"], "title": "Uncovering Systemic and Environment Errors in Autonomous Systems Using Differential Testing", "comment": null, "summary": "When an autonomous agent behaves undesirably, including failure to complete a\ntask, it can be difficult to determine whether the behavior is due to a\nsystemic agent error, such as flaws in the model or policy, or an environment\nerror, where a task is inherently infeasible under a given environment\nconfiguration, even for an ideal agent. As agents and their environments grow\nmore complex, identifying the error source becomes increasingly difficult but\ncritical for reliable deployment. We introduce AIProbe, a novel black-box\ntesting technique that applies differential testing to attribute undesirable\nagent behaviors either to agent deficiencies, such as modeling or training\nflaws, or due to environmental infeasibility. AIProbe first generates diverse\nenvironmental configurations and tasks for testing the agent, by modifying\nconfigurable parameters using Latin Hypercube sampling. It then solves each\ngenerated task using a search-based planner, independent of the agent. By\ncomparing the agent's performance to the planner's solution, AIProbe identifies\nwhether failures are due to errors in the agent's model or policy, or due to\nunsolvable task conditions. Our evaluation across multiple domains shows that\nAIProbe significantly outperforms state-of-the-art techniques in detecting both\ntotal and unique errors, thereby contributing to a reliable deployment of\nautonomous agents.", "AI": {"tldr": "AIProbe\u662f\u4e00\u79cd\u9ed1\u76d2\u6d4b\u8bd5\u6280\u672f\uff0c\u901a\u8fc7\u5dee\u5f02\u6d4b\u8bd5\u533a\u5206\u81ea\u4e3b\u4ee3\u7406\u884c\u4e3a\u9519\u8bef\u662f\u6e90\u4e8e\u4ee3\u7406\u7f3a\u9677\u8fd8\u662f\u73af\u5883\u4e0d\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u4ee3\u7406\u53ca\u5176\u73af\u5883\u590d\u6742\u6027\u589e\u52a0\uff0c\u533a\u5206\u884c\u4e3a\u9519\u8bef\u6765\u6e90\u53d8\u5f97\u56f0\u96be\u4f46\u5bf9\u53ef\u9760\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "AIProbe\u751f\u6210\u591a\u6837\u5316\u73af\u5883\u914d\u7f6e\u548c\u4efb\u52a1\uff0c\u4f7f\u7528\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\u4fee\u6539\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u72ec\u7acb\u4e8e\u4ee3\u7406\u7684\u641c\u7d22\u89c4\u5212\u5668\u89e3\u51b3\u4efb\u52a1\uff0c\u6bd4\u8f83\u4ee3\u7406\u4e0e\u89c4\u5212\u5668\u6027\u80fd\u4ee5\u8bc6\u522b\u9519\u8bef\u6765\u6e90\u3002", "result": "AIProbe\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u80fd\u68c0\u6d4b\u66f4\u591a\u603b\u9519\u8bef\u548c\u72ec\u7279\u9519\u8bef\u3002", "conclusion": "AIProbe\u6709\u52a9\u4e8e\u53ef\u9760\u90e8\u7f72\u81ea\u4e3b\u4ee3\u7406\uff0c\u901a\u8fc7\u9ad8\u6548\u8bc6\u522b\u9519\u8bef\u6765\u6e90\u3002"}}
{"id": "2507.03876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03876", "abs": "https://arxiv.org/abs/2507.03876", "authors": ["Alyssa Loo", "Ellie Pavlick", "Roman Feiman"], "title": "LLMs model how humans induce logically structured rules", "comment": null, "summary": "A central goal of cognitive science is to provide a computationally explicit\naccount of both the structure of the mind and its development: what are the\nprimitive representational building blocks of cognition, what are the rules via\nwhich those primitives combine, and where do these primitives and rules come\nfrom in the first place? A long-standing debate concerns the adequacy of\nartificial neural networks as computational models that can answer these\nquestions, in particular in domains related to abstract cognitive function,\nsuch as language and logic. This paper argues that recent advances in neural\nnetworks -- specifically, the advent of large language models (LLMs) --\nrepresent an important shift in this debate. We test a variety of LLMs on an\nexisting experimental paradigm used for studying the induction of rules\nformulated over logical concepts. Across four experiments, we find converging\nempirical evidence that LLMs provide at least as good a fit to human behavior\nas models that implement a Bayesian probablistic language of thought (pLoT),\nwhich have been the best computational models of human behavior on the same\ntask. Moreover, we show that the LLMs make qualitatively different predictions\nabout the nature of the rules that are inferred and deployed in order to\ncomplete the task, indicating that the LLM is unlikely to be a mere\nimplementation of the pLoT solution. Based on these results, we argue that LLMs\nmay instantiate a novel theoretical account of the primitive representations\nand computations necessary to explain human logical concepts, with which future\nwork in cognitive science should engage.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u795e\u7ecf\u7f51\u7edc\uff08\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578bLLMs\uff09\u80fd\u5426\u4f5c\u4e3a\u8ba4\u77e5\u79d1\u5b66\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83LLMs\u4e0e\u8d1d\u53f6\u65af\u6982\u7387\u601d\u7ef4\u8bed\u8a00\u6a21\u578b\uff08pLoT\uff09\uff0c\u53d1\u73b0LLMs\u5728\u89e3\u91ca\u4eba\u7c7b\u903b\u8f91\u6982\u5ff5\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u6709\u72ec\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u795e\u7ecf\u7f51\u7edc\uff08\u7279\u522b\u662fLLMs\uff09\u662f\u5426\u80fd\u89e3\u91ca\u4eba\u7c7b\u8ba4\u77e5\u7684\u539f\u59cb\u8868\u5f81\u548c\u8ba1\u7b97\u89c4\u5219\uff0c\u6311\u6218\u4f20\u7edf\u8d1d\u53f6\u65af\u6a21\u578b\uff08pLoT\uff09\u7684\u4f18\u8d8a\u6027\u3002", "method": "\u901a\u8fc7\u56db\u4e2a\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u591a\u79cdLLMs\u5728\u903b\u8f91\u89c4\u5219\u5f52\u7eb3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0epLoT\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "LLMs\u5728\u62df\u5408\u4eba\u7c7b\u884c\u4e3a\u4e0a\u81f3\u5c11\u4e0epLoT\u6a21\u578b\u76f8\u5f53\uff0c\u4e14\u5176\u9884\u6d4b\u89c4\u5219\u7684\u6027\u8d28\u4e0epLoT\u4e0d\u540c\uff0c\u8868\u660eLLMs\u5e76\u975epLoT\u7684\u7b80\u5355\u5b9e\u73b0\u3002", "conclusion": "LLMs\u53ef\u80fd\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u91ca\u4eba\u7c7b\u903b\u8f91\u6982\u5ff5\u7684\u539f\u59cb\u8868\u5f81\u548c\u8ba1\u7b97\uff0c\u503c\u5f97\u672a\u6765\u8ba4\u77e5\u79d1\u5b66\u7814\u7a76\u5173\u6ce8\u3002"}}
{"id": "2507.03904", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.03904", "abs": "https://arxiv.org/abs/2507.03904", "authors": ["Yingxuan Yang", "Ying Wen", "Jun Wang", "Weinan Zhang"], "title": "Agent Exchange: Shaping the Future of AI Agent Economics", "comment": null, "summary": "The rise of Large Language Models (LLMs) has transformed AI agents from\npassive computational tools into autonomous economic actors. This shift marks\nthe emergence of the agent-centric economy, in which agents take on active\neconomic roles-exchanging value, making strategic decisions, and coordinating\nactions with minimal human oversight. To realize this vision, we propose Agent\nExchange (AEX), a specialized auction platform designed to support the dynamics\nof the AI agent marketplace. AEX offers an optimized infrastructure for agent\ncoordination and economic participation. Inspired by Real-Time Bidding (RTB)\nsystems in online advertising, AEX serves as the central auction engine,\nfacilitating interactions among four ecosystem components: the User-Side\nPlatform (USP), which translates human goals into agent-executable tasks; the\nAgent-Side Platform (ASP), responsible for capability representation,\nperformance tracking, and optimization; Agent Hubs, which coordinate agent\nteams and participate in AEX-hosted auctions; and the Data Management Platform\n(DMP), ensuring secure knowledge sharing and fair value attribution. We outline\nthe design principles and system architecture of AEX, laying the groundwork for\nagent-based economic infrastructure in future AI ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAgent Exchange (AEX)\uff0c\u4e00\u4e2a\u4e13\u4e3aAI\u4ee3\u7406\u7ecf\u6d4e\u8bbe\u8ba1\u7684\u62cd\u5356\u5e73\u53f0\uff0c\u652f\u6301\u4ee3\u7406\u95f4\u7684\u4ef7\u503c\u4ea4\u6362\u548c\u534f\u8c03\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\uff0cAI\u4ee3\u7406\u4ece\u88ab\u52a8\u5de5\u5177\u8f6c\u53d8\u4e3a\u81ea\u4e3b\u7ecf\u6d4e\u53c2\u4e0e\u8005\uff0c\u9700\u8981\u65b0\u7684\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u5176\u7ecf\u6d4e\u6d3b\u52a8\u3002", "method": "AEX\u501f\u9274\u5728\u7ebf\u5e7f\u544a\u7684\u5b9e\u65f6\u7ade\u4ef7\uff08RTB\uff09\u7cfb\u7edf\uff0c\u8bbe\u8ba1\u4e3a\u4e2d\u592e\u62cd\u5356\u5f15\u64ce\uff0c\u8fde\u63a5\u7528\u6237\u4fa7\u5e73\u53f0\uff08USP\uff09\u3001\u4ee3\u7406\u4fa7\u5e73\u53f0\uff08ASP\uff09\u3001\u4ee3\u7406\u4e2d\u5fc3\uff08Agent Hubs\uff09\u548c\u6570\u636e\u7ba1\u7406\u5e73\u53f0\uff08DMP\uff09\u3002", "result": "AEX\u4e3aAI\u4ee3\u7406\u7ecf\u6d4e\u63d0\u4f9b\u4e86\u4f18\u5316\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u4ee3\u7406\u534f\u8c03\u548c\u7ecf\u6d4e\u53c2\u4e0e\u3002", "conclusion": "AEX\u4e3a\u672a\u6765AI\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u4ee3\u7406\u7ecf\u6d4e\u57fa\u7840\u8bbe\u65bd\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.03916", "categories": ["cs.AI", "cs.CV", "68T01"], "pdf": "https://arxiv.org/pdf/2507.03916", "abs": "https://arxiv.org/abs/2507.03916", "authors": ["Yifan Jiang", "Yibo Xue", "Yukun Kang", "Pin Zheng", "Jian Peng", "Feiran Wu", "Changliang Xu"], "title": "Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models", "comment": "Appendix at:\n  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf", "summary": "Slide animations, such as fade-ins, fly-ins, and wipes, are critical for\naudience engagement, efficient information delivery, and vivid visual\nexpression. However, most AI-driven slide-generation tools still lack native\nanimation support, and existing vision-language models (VLMs) struggle with\nanimation tasks due to the absence of public datasets and limited\ntemporal-reasoning capabilities. To address this gap, we release the first\npublic dataset for slide-animation modeling: 12,000 triplets of\nnatural-language descriptions, animation JSON files, and rendered videos,\ncollectively covering every built-in PowerPoint effect. Using this resource, we\nfine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistent\nimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and our\nCoverage-Order-Detail Assessment (CODA) metric, which evaluates action\ncoverage, temporal order, and detail fidelity. On a manually curated test set\nof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, and\nshows significant improvements in CODA-detail. This demonstrates that low-rank\nadaptation enables reliable temporal reasoning and generalization beyond\nsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metric\nprovide a rigorous benchmark and foundation for future research on VLM-based\ndynamic slide generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u516c\u5f00\u7684\u5e7b\u706f\u7247\u52a8\u753b\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528LoRA\u5fae\u8c03Qwen-2.5-VL-7B\u6a21\u578b\uff0c\u5728\u52a8\u753b\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8eGPT-4.1\u548cGemini-2.5-Pro\u3002", "motivation": "\u5f53\u524dAI\u9a71\u52a8\u7684\u5e7b\u706f\u7247\u751f\u6210\u5de5\u5177\u7f3a\u4e4f\u52a8\u753b\u652f\u6301\uff0c\u4e14\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u56e0\u7f3a\u5c11\u516c\u5f00\u6570\u636e\u96c6\u548c\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u800c\u96be\u4ee5\u5904\u7406\u52a8\u753b\u4efb\u52a1\u3002", "method": "\u53d1\u5e03\u5305\u542b12,000\u7ec4\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u3001\u52a8\u753bJSON\u6587\u4ef6\u548c\u6e32\u67d3\u89c6\u9891\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528LoRA\u5fae\u8c03Qwen-2.5-VL-7B\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728BLEU-4\u3001ROUGE-L\u3001SPICE\u548cCODA\u6307\u6807\u4e0a\u663e\u8457\u63d0\u5347\uff0cCODA\u7ec6\u8282\u5f97\u5206\u5c24\u5176\u7a81\u51fa\u3002", "conclusion": "\u6570\u636e\u96c6\u3001LoRA\u589e\u5f3a\u6a21\u578b\u548cCODA\u6307\u6807\u4e3a\u672a\u6765\u57fa\u4e8eVLM\u7684\u52a8\u6001\u5e7b\u706f\u7247\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u57fa\u7840\u3002"}}
{"id": "2507.03928", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.03928", "abs": "https://arxiv.org/abs/2507.03928", "authors": ["Yiliu Sun", "Zicheng Zhao", "Sheng Wan", "Chen Gong"], "title": "CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate", "comment": "Accepted by ACL 2025", "summary": "Nowadays, single Large Language Model (LLM) struggles with critical issues\nsuch as hallucination and inadequate reasoning abilities. To mitigate these\nissues, Multi-Agent Debate (MAD) has emerged as an effective strategy, where\nLLM agents engage in in-depth debates with others on tasks. However, existing\nMAD methods face two major issues: (a) too lengthy input contexts, which causes\nLLM agents to get lost in plenty of input information and experiences\nperformance drop; and (b) the overconfidence dilemma, where self-assured LLM\nagents dominate the debate, leading to low debating effectiveness. To address\nthese limitations, we propose a novel MAD method called \"CortexDebate\".\nInspired by the human brain's tendency to establish a sparse and dynamically\noptimized network among cortical areas governed by white matter, CortexDebate\nconstructs a sparse debating graph among LLM agents, where each LLM agent only\ndebates with the ones that are helpful to it. To optimize the graph, we propose\na module named McKinsey-based Debate Matter (MDM), which acts as an artificial\nanalog to white matter. By integrating the McKinsey Trust Formula, a\nwell-established measure of trustworthiness from sociology, MDM enables\ncredible evaluations that guide graph optimization. The effectiveness of our\nCortexDebate has been well demonstrated by extensive experimental results\nacross eight datasets from four task types.", "AI": {"tldr": "CortexDebate\u662f\u4e00\u79cd\u65b0\u578b\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u8fa9\u8bba\u56fe\u548cMDM\u6a21\u5757\u89e3\u51b3\u73b0\u6709MAD\u65b9\u6cd5\u7684\u8f93\u5165\u8fc7\u957f\u548c\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709MAD\u65b9\u6cd5\u5b58\u5728\u8f93\u5165\u8fc7\u957f\u548c\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u5bfc\u81f4\u8fa9\u8bba\u6548\u679c\u4e0b\u964d\u3002", "method": "\u63d0\u51faCortexDebate\u65b9\u6cd5\uff0c\u6784\u5efa\u7a00\u758f\u8fa9\u8bba\u56fe\uff0c\u5e76\u5f15\u5165MDM\u6a21\u5757\u4f18\u5316\u56fe\u7ed3\u6784\u3002", "result": "\u5728\u56db\u4e2a\u4efb\u52a1\u7c7b\u578b\u7684\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86CortexDebate\u7684\u6709\u6548\u6027\u3002", "conclusion": "CortexDebate\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7684\u6548\u679c\u3002"}}
{"id": "2507.03929", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.03929", "abs": "https://arxiv.org/abs/2507.03929", "authors": ["Mohimenul Kabir", "Kuldeep S Meel"], "title": "An ASP-Based Framework for MUSes", "comment": "To appear in ICLP 2025 Technical Communication", "summary": "Given an unsatisfiable formula, understanding the core reason for\nunsatisfiability is crucial in several applications. One effective way to\ncapture this is through the minimal unsatisfiable subset (MUS), the\nsubset-minimal set of clauses that remains unsatisfiable. Current research\nbroadly focuses on two directions: (i) enumerating as many MUSes as possible\nwithin a given time limit, and (ii) counting the total number of MUSes for a\ngiven unsatisfiable formula.\n  In this paper, we introduce an answer set programming-based framework, named\nMUS-ASP, designed for online enumeration of MUSes. ASP is a powerful tool for\nits strengths in knowledge representation and is particularly suitable for\nspecifying complex combinatorial problems. By translating MUS enumeration into\nanswer set solving, MUS-ASP leverages the computational efficiency of\nstate-of-the-art ASP systems. Our extensive experimental evaluation\ndemonstrates the effectiveness of MUS-ASP and highlights the acceleration in\nboth MUS enumeration and counting tasks, particularly when integrated within\nhybrid solvers, including the framework proposed in this paper.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u6846\u67b6MUS-ASP\uff0c\u7528\u4e8e\u5728\u7ebf\u679a\u4e3e\u6700\u5c0f\u4e0d\u53ef\u6ee1\u8db3\u5b50\u96c6\uff08MUS\uff09\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728MUS\u679a\u4e3e\u548c\u8ba1\u6570\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u6027\u3002", "motivation": "\u7406\u89e3\u4e0d\u53ef\u6ee1\u8db3\u516c\u5f0f\u7684\u6838\u5fc3\u539f\u56e0\u5bf9\u8bb8\u591a\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u800c\u6700\u5c0f\u4e0d\u53ef\u6ee1\u8db3\u5b50\u96c6\uff08MUS\uff09\u662f\u6355\u6349\u8fd9\u4e00\u539f\u56e0\u7684\u6709\u6548\u65b9\u6cd5\u3002\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u679a\u4e3eMUS\u548c\u8ba1\u6570MUS\u6570\u91cf\u4e0a\u3002", "method": "\u901a\u8fc7\u5c06MUS\u679a\u4e3e\u95ee\u9898\u8f6c\u5316\u4e3a\u7b54\u6848\u96c6\u6c42\u89e3\u95ee\u9898\uff0c\u5229\u7528ASP\u5728\u77e5\u8bc6\u8868\u793a\u548c\u89e3\u51b3\u590d\u6742\u7ec4\u5408\u95ee\u9898\u4e0a\u7684\u4f18\u52bf\uff0c\u8bbe\u8ba1\u4e86MUS-ASP\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cMUS-ASP\u5728MUS\u679a\u4e3e\u548c\u8ba1\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u662f\u5728\u4e0e\u6df7\u5408\u6c42\u89e3\u5668\u96c6\u6210\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002", "conclusion": "MUS-ASP\u6846\u67b6\u901a\u8fc7\u7ed3\u5408ASP\u7684\u9ad8\u6548\u8ba1\u7b97\u80fd\u529b\uff0c\u4e3aMUS\u679a\u4e3e\u548c\u8ba1\u6570\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.03998", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03998", "abs": "https://arxiv.org/abs/2507.03998", "authors": ["Thuy An Ha", "Bao Quoc Vo"], "title": "Toward Better Generalisation in Uncertainty Estimators: Leveraging Data-Agnostic Features", "comment": null, "summary": "Large Language Models (LLMs) often generate responses that are factually\nincorrect yet expressed with high confidence, which can pose serious risks for\nend users. To address this, it is essential for LLMs not only to produce\nanswers but also to provide accurate estimates of their correctness.\nUncertainty quantification methods have been introduced to assess the quality\nof LLM outputs, with factual accuracy being a key aspect of that quality. Among\nthese methods, those that leverage hidden states to train probes have shown\nparticular promise, as these internal representations encode information\nrelevant to the factuality of responses, making this approach the focus of this\npaper. However, the probe trained on the hidden states of one dataset often\nstruggles to generalise to another dataset of a different task or domain. To\naddress this limitation, we explore combining data-agnostic features with\nhidden-state features and assess whether this hybrid feature set enhances\nout-of-domain performance. We further examine whether selecting only the most\ninformative hidden-state features, thereby discarding task-specific noise,\nenables the data-agnostic features to contribute more effectively. The\nexperiment results indicate that although introducing data-agnostic features\ngenerally enhances generalisation performance in most cases, in certain\nscenarios their inclusion degrades performance. A similar pattern emerges when\nretaining only the most important hidden-state features - adding data-agnostic\nfeatures does not consistently further enhance performance compared to using\nthe full set of hidden-state features. A closer analysis reveals that, in some\nspecific cases, the trained probe underweights the data-agnostic features\nrelative to the hidden-state features, which we believe is the main reason why\nthe results are inconclusive.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u65e0\u5173\u7279\u5f81\u548c\u9690\u85cf\u72b6\u6001\u7279\u5f81\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8de8\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6027\u80fd\uff0c\u4f46\u5b9e\u9a8c\u7ed3\u679c\u5e76\u4e0d\u4e00\u81f4\u3002", "motivation": "LLM\u5e38\u751f\u6210\u9ad8\u81ea\u4fe1\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u56de\u7b54\uff0c\u9700\u6539\u8fdb\u5176\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u4ee5\u8bc4\u4f30\u8f93\u51fa\u8d28\u91cf\u3002", "method": "\u7ed3\u5408\u6570\u636e\u65e0\u5173\u7279\u5f81\u4e0e\u9690\u85cf\u72b6\u6001\u7279\u5f81\uff0c\u5e76\u7b5b\u9009\u6700\u5177\u4fe1\u606f\u91cf\u7684\u9690\u85cf\u72b6\u6001\u7279\u5f81\uff0c\u4ee5\u63d0\u5347\u8de8\u9886\u57df\u6027\u80fd\u3002", "result": "\u5f15\u5165\u6570\u636e\u65e0\u5173\u7279\u5f81\u901a\u5e38\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u964d\u4f4e\u6548\u679c\uff1b\u7b5b\u9009\u9690\u85cf\u72b6\u6001\u7279\u5f81\u4e5f\u672a\u4e00\u81f4\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u6570\u636e\u65e0\u5173\u7279\u5f81\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u88ab\u4f4e\u4f30\uff0c\u5bfc\u81f4\u5b9e\u9a8c\u7ed3\u679c\u4e0d\u4e00\u81f4\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u6743\u91cd\u5206\u914d\u95ee\u9898\u3002"}}
{"id": "2507.04034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04034", "abs": "https://arxiv.org/abs/2507.04034", "authors": ["Weizhi Tang", "Kwabena Nuamah", "Vaishak Belle"], "title": "Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving", "comment": null, "summary": "While Large Language Models (LLMs) have demonstrated impressive abilities\nacross various domains, they still struggle with complex problems characterized\nby multi-objective optimization, precise constraint satisfaction, immense\nsolution spaces, etc. To address the limitation, drawing on the superior\nsemantic understanding ability of LLMs and also the outstanding global search\nand optimization capability of genetic algorithms, we propose to capitalize on\ntheir respective strengths and introduce Lyria, a general LLM-driven genetic\nalgorithm framework, comprising 7 essential components. Through conducting\nextensive experiments with 4 LLMs across 3 types of problems, we demonstrated\nthe efficacy of Lyria. Additionally, with 7 additional ablation experiments, we\nfurther systematically analyzed and elucidated the factors that affect its\nperformance.", "AI": {"tldr": "Lyria\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u8bed\u4e49\u7406\u89e3\u548c\u9057\u4f20\u7b97\u6cd5\u5168\u5c40\u641c\u7d22\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u5f71\u54cd\u6027\u80fd\u7684\u56e0\u7d20\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u591a\u76ee\u6807\u4f18\u5316\u3001\u7ea6\u675f\u6ee1\u8db3\u548c\u5927\u89e3\u7a7a\u95f4\u7b49\u590d\u6742\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u7ed3\u5408LLM\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u548c\u9057\u4f20\u7b97\u6cd5\u7684\u5168\u5c40\u641c\u7d22\u4f18\u5316\u80fd\u529b\uff0c\u63d0\u51faLyria\u6846\u67b6\uff0c\u5305\u542b7\u4e2a\u5173\u952e\u7ec4\u4ef6\u3002", "result": "\u57284\u79cdLLM\u548c3\u7c7b\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660eLyria\u6709\u6548\uff0c\u5e76\u901a\u8fc77\u9879\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u6027\u80fd\u5f71\u54cd\u56e0\u7d20\u3002", "conclusion": "Lyria\u901a\u8fc7\u7ed3\u5408LLM\u548c\u9057\u4f20\u7b97\u6cd5\u7684\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u5e76\u660e\u786e\u4e86\u6027\u80fd\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2507.04037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04037", "abs": "https://arxiv.org/abs/2507.04037", "authors": ["Zheng Jia", "Shengbin Yue", "Wei Chen", "Siyuan Wang", "Yidong Liu", "Yun Song", "Zhongyu Wei"], "title": "Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments", "comment": null, "summary": "The gap between static benchmarks and the dynamic nature of real-world legal\npractice poses a key barrier to advancing legal intelligence. To this end, we\nintroduce J1-ENVS, the first interactive and dynamic legal environment tailored\nfor LLM-based agents. Guided by legal experts, it comprises six representative\nscenarios from Chinese legal practices across three levels of environmental\ncomplexity. We further introduce J1-EVAL, a fine-grained evaluation framework,\ndesigned to assess both task performance and procedural compliance across\nvarying levels of legal proficiency. Extensive experiments on 17 LLM agents\nreveal that, while many models demonstrate solid legal knowledge, they struggle\nwith procedural execution in dynamic settings. Even the SOTA model, GPT-4o,\nfalls short of 60% overall performance. These findings highlight persistent\nchallenges in achieving dynamic legal intelligence and offer valuable insights\nto guide future research.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86J1-ENVS\u548cJ1-EVAL\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u52a8\u6001\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u52a8\u6001\u6267\u884c\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u89e3\u51b3\u9759\u6001\u57fa\u51c6\u4e0e\u52a8\u6001\u6cd5\u5f8b\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u52a8\u6cd5\u5f8b\u667a\u80fd\u7684\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u52a8\u6001\u6cd5\u5f8b\u73af\u5883J1-ENVS\u548c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6846\u67b6J1-EVAL\uff0c\u5e76\u572817\u4e2aLLM\u4ee3\u7406\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8bb8\u591a\u6a21\u578b\u5728\u6cd5\u5f8b\u77e5\u8bc6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7a0b\u5e8f\u6267\u884c\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5373\u4f7f\u662fGPT-4o\u4e5f\u672a\u8fbe\u523060%\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u52a8\u6001\u6cd5\u5f8b\u667a\u80fd\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u65b9\u5411\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.04067", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.04067", "abs": "https://arxiv.org/abs/2507.04067", "authors": ["Yuyang Cheng", "Yumiao Xu", "Chaojia Yu", "Yong Zhao"], "title": "HAWK: A Hierarchical Workflow Framework for Multi-Agent Collaboration", "comment": "AgentIR@SIGIR 2025", "summary": "Contemporary multi-agent systems encounter persistent challenges in\ncross-platform interoperability, dynamic task scheduling, and efficient\nresource sharing. Agents with heterogeneous implementations often lack\nstandardized interfaces; collaboration frameworks remain brittle and hard to\nextend; scheduling policies are static; and inter-agent state synchronization\nis insufficient. We propose Hierarchical Agent Workflow (HAWK), a modular\nframework comprising five layers-User, Workflow, Operator, Agent, and\nResource-and supported by sixteen standardized interfaces. HAWK delivers an\nend-to-end pipeline covering task parsing, workflow orchestration, intelligent\nscheduling, resource invocation, and data synchronization. At its core lies an\nadaptive scheduling and optimization module in the Workflow Layer, which\nharnesses real-time feedback and dynamic strategy adjustment to maximize\nutilization. The Resource Layer provides a unified abstraction over\nheterogeneous data sources, large models, physical devices, and third-party\nservices&tools, simplifying cross-domain information retrieval. We demonstrate\nHAWK's scalability and effectiveness via CreAgentive, a multi-agent\nnovel-generation prototype, which achieves marked gains in throughput, lowers\ninvocation complexity, and improves system controllability. We also show how\nhybrid deployments of large language models integrate seamlessly within HAWK,\nhighlighting its flexibility. Finally, we outline future research\navenues-hallucination mitigation, real-time performance tuning, and enhanced\ncross-domain adaptability-and survey prospective applications in healthcare,\ngovernment, finance, and education.", "AI": {"tldr": "HAWK\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4e92\u64cd\u4f5c\u6027\u3001\u4efb\u52a1\u8c03\u5ea6\u548c\u8d44\u6e90\u5171\u4eab\u95ee\u9898\uff0c\u901a\u8fc7\u4e94\u5c42\u67b6\u6784\u548c\u6807\u51c6\u5316\u63a5\u53e3\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8de8\u5e73\u53f0\u4e92\u64cd\u4f5c\u6027\u3001\u52a8\u6001\u4efb\u52a1\u8c03\u5ea6\u548c\u8d44\u6e90\u5171\u4eab\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u63a5\u53e3\u548c\u7075\u6d3b\u534f\u4f5c\u6846\u67b6\u3002", "method": "\u63d0\u51faHAWK\u6846\u67b6\uff0c\u5305\u542b\u4e94\u5c42\uff08\u7528\u6237\u3001\u5de5\u4f5c\u6d41\u3001\u64cd\u4f5c\u8005\u3001\u667a\u80fd\u4f53\u3001\u8d44\u6e90\uff09\u548c\u5341\u516d\u4e2a\u6807\u51c6\u5316\u63a5\u53e3\uff0c\u652f\u6301\u4efb\u52a1\u89e3\u6790\u3001\u5de5\u4f5c\u6d41\u7f16\u6392\u3001\u667a\u80fd\u8c03\u5ea6\u7b49\u529f\u80fd\u3002", "result": "\u901a\u8fc7CreAgentive\u539f\u578b\u9a8c\u8bc1\uff0cHAWK\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u3001\u964d\u4f4e\u4e86\u8c03\u7528\u590d\u6742\u5ea6\uff0c\u5e76\u589e\u5f3a\u4e86\u7cfb\u7edf\u53ef\u63a7\u6027\u3002", "conclusion": "HAWK\u5c55\u793a\u4e86\u5728\u591a\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u5e7b\u89c9\u7f13\u89e3\u3001\u5b9e\u65f6\u6027\u80fd\u4f18\u5316\u548c\u8de8\u57df\u9002\u5e94\u6027\u63d0\u5347\u3002"}}
{"id": "2507.04103", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.04103", "abs": "https://arxiv.org/abs/2507.04103", "authors": ["Dheeraj Vattikonda", "Santhoshi Ravichandran", "Emiliano Penaloza", "Hadi Nekoei", "Megh Thakkar", "Thibault Le Sellier de Chezelles", "Nicolas Gontier", "Miguel Mu\u00f1oz-M\u00e1rmol", "Sahar Omidi Shayegan", "Stefania Raimondo", "Xue Liu", "Alexandre Drouin", "Laurent Charlin", "Alexandre Pich\u00e9", "Alexandre Lacoste", "Massimo Caccia"], "title": "How to Train Your LLM Web Agent: A Statistical Diagnosis", "comment": null, "summary": "LLM-based web agents have recently made significant progress, but much of it\nhas occurred in closed-source systems, widening the gap with open-source\nalternatives. Progress has been held back by two key challenges: first, a\nnarrow focus on single-step tasks that overlooks the complexity of multi-step\nweb interactions; and second, the high compute costs required to post-train\nLLM-based web agents. To address this, we present the first statistically\ngrounded study on compute allocation for LLM web-agent post-training. Our\napproach uses a two-stage pipeline, training a Llama 3.1 8B student to imitate\na Llama 3.3 70B teacher via supervised fine-tuning (SFT), followed by on-policy\nreinforcement learning. We find this process highly sensitive to hyperparameter\nchoices, making exhaustive sweeps impractical. To spare others from expensive\ntrial-and-error, we sample 1,370 configurations and use bootstrapping to\nestimate effective hyperparameters. Our results show that combining SFT with\non-policy RL consistently outperforms either approach alone on both WorkArena\nand MiniWob++. Further, this strategy requires only 55% of the compute to match\nthe peak performance of pure SFT on MiniWob++, effectively pushing the\ncompute-performance Pareto frontier, and is the only strategy that can close\nthe gap with closed-source models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e24\u9636\u6bb5\u7ba1\u9053\u7684LLM\u7f51\u7edc\u4ee3\u7406\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5f00\u6e90LLM\u7f51\u7edc\u4ee3\u7406\u4e0e\u95ed\u6e90\u7cfb\u7edf\u4e4b\u95f4\u7684\u5dee\u8ddd\u65e5\u76ca\u6269\u5927\uff0c\u4e3b\u8981\u7531\u4e8e\u5355\u6b65\u4efb\u52a1\u5c40\u9650\u6027\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7ba1\u9053\uff1a\u5148\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u6a21\u4eff\u6559\u5e08\u6a21\u578b\uff0c\u518d\u8fdb\u884c\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7b56\u7565\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u964d\u4f4e55%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63a8\u52a8\u4e86\u8ba1\u7b97\u6027\u80fd\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u7f29\u5c0f\u4e86\u4e0e\u95ed\u6e90\u6a21\u578b\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.04105", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.04105", "abs": "https://arxiv.org/abs/2507.04105", "authors": ["Jinwei Hu", "Yi Dong", "Zhengtao Ding", "Xiaowei Huang"], "title": "Enhancing Robustness of LLM-Driven Multi-Agent Systems through Randomized Smoothing", "comment": "Preprint accepted by Chinese Journal of Aeronautics", "summary": "This paper presents a defense framework for enhancing the safety of large\nlanguage model (LLM) empowered multi-agent systems (MAS) in safety-critical\ndomains such as aerospace. We apply randomized smoothing, a statistical\nrobustness certification technique, to the MAS consensus context, enabling\nprobabilistic guarantees on agent decisions under adversarial influence. Unlike\ntraditional verification methods, our approach operates in black-box settings\nand employs a two-stage adaptive sampling mechanism to balance robustness and\ncomputational efficiency. Simulation results demonstrate that our method\neffectively prevents the propagation of adversarial behaviors and\nhallucinations while maintaining consensus performance. This work provides a\npractical and scalable path toward safe deployment of LLM-based MAS in\nreal-world, high-stakes environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8d4b\u80fd\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5b89\u5168\u6027\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u822a\u7a7a\u822a\u5929\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2d\uff0cLLM\u8d4b\u80fd\u7684MAS\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u5176\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u968f\u673a\u5e73\u6ed1\u6280\u672f\uff0c\u7ed3\u5408\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\uff0c\u5728\u65e0\u9700\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u7684\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u63d0\u4f9b\u6982\u7387\u4fdd\u8bc1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u963b\u6b62\u5bf9\u6297\u6027\u884c\u4e3a\u548c\u5e7b\u89c9\u4f20\u64ad\uff0c\u540c\u65f6\u4fdd\u6301\u5171\u8bc6\u6027\u80fd\u3002", "conclusion": "\u4e3aLLM\u8d4b\u80fd\u7684MAS\u5728\u73b0\u5b9e\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.04136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04136", "abs": "https://arxiv.org/abs/2507.04136", "authors": ["Saksham Sahai Srivastava", "Vaneet Aggarwal"], "title": "A Technical Survey of Reinforcement Learning Techniques for Large Language Models", "comment": "24 pages, LaTeX source", "summary": "Reinforcement Learning (RL) has emerged as a transformative approach for\naligning and enhancing Large Language Models (LLMs), addressing critical\nchallenges in instruction following, ethical alignment, and reasoning\ncapabilities. This survey offers a comprehensive foundation on the integration\nof RL with language models, highlighting prominent algorithms such as Proximal\nPolicy Optimization (PPO), Q-Learning, and Actor-Critic methods. Additionally,\nit provides an extensive technical overview of RL techniques specifically\ntailored for LLMs, including foundational methods like Reinforcement Learning\nfrom Human Feedback (RLHF) and AI Feedback (RLAIF), as well as advanced\nstrategies such as Direct Preference Optimization (DPO) and Group Relative\nPolicy Optimization (GRPO). We systematically analyze their applications across\ndomains, i.e., from code generation to tool-augmented reasoning. We also\npresent a comparative taxonomy based on reward modeling, feedback mechanisms,\nand optimization strategies. Our evaluation highlights key trends. RLHF remains\ndominant for alignment, and outcome-based RL such as RLVR significantly\nimproves stepwise reasoning. However, persistent challenges such as reward\nhacking, computational costs, and scalable feedback collection underscore the\nneed for continued innovation. We further discuss emerging directions,\nincluding hybrid RL algorithms, verifier-guided training, and multi-objective\nalignment frameworks. This survey serves as a roadmap for researchers advancing\nRL-driven LLM development, balancing capability enhancement with safety and\nscalability.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86RLHF\u3001RLAIF\u3001DPO\u548cGRPO\u7b49\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5728\u6307\u4ee4\u9075\u5faa\u3001\u4f26\u7406\u5bf9\u9f50\u548c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u4f5c\u7528\u3002", "motivation": "\u901a\u8fc7RL\u63d0\u5347LLMs\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u6307\u4ee4\u9075\u5faa\u3001\u4f26\u7406\u5bf9\u9f50\u548c\u63a8\u7406\u7b49\u5173\u952e\u6311\u6218\u3002", "method": "\u7efc\u8ff0\u4e86RL\u4e0eLLMs\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u5305\u62ecPPO\u3001Q-Learning\u3001Actor-Critic\u7b49\u7b97\u6cd5\uff0c\u4ee5\u53caRLHF\u3001RLAIF\u3001DPO\u548cGRPO\u7b49\u4e13\u95e8\u6280\u672f\u3002", "result": "RLHF\u5728\u6a21\u578b\u5bf9\u9f50\u4e2d\u5360\u4e3b\u5bfc\uff0cRLVR\u663e\u8457\u63d0\u5347\u9010\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u5956\u52b1\u7834\u89e3\u3001\u8ba1\u7b97\u6210\u672c\u548c\u53cd\u9988\u6536\u96c6\u7b49\u6311\u6218\u3002", "conclusion": "\u672a\u6765\u65b9\u5411\u5305\u62ec\u6df7\u5408RL\u7b97\u6cd5\u3001\u9a8c\u8bc1\u5668\u5f15\u5bfc\u8bad\u7ec3\u548c\u591a\u76ee\u6807\u5bf9\u9f50\u6846\u67b6\uff0c\u4e3aRL\u9a71\u52a8\u7684LLM\u53d1\u5c55\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002"}}
{"id": "2507.04206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04206", "abs": "https://arxiv.org/abs/2507.04206", "authors": ["Sibei Liu", "Zhijian Hu"], "title": "Mpemba Effect in Large-Language Model Training Dynamics: A Minimal Analysis of the Valley-River model", "comment": null, "summary": "Learning rate (LR) schedules in large language model (LLM) training often\nfollow empirical templates: warm-up, constant plateau/stable phase, and decay\n(WSD). However, the mechanistic explanation for this strategy remains\nunderexplored, and the choice of plateau height and decay schedule is largely\nheuristic. In this paper, we connect training dynamics to a thermodynamic\nanalogy via the Mpemba effect - a phenomenon in which a hotter system cools\nfaster than a colder one when quenched into the same bath. We analyze a class\nof \"valley-river\" loss landscapes, where sharp (valley) directions equilibrate\nquickly, while flatter (river) directions govern global descent. The Mpemba\neffect provides an explanation for the necessity of the warm-up phase and\nmotivates a high plateau - rather than a low one - for accelerating loss\ndecrease during decay. We show that for certain loss landscapes, there exists\nan optimal plateau learning rate - the \"strong Mpemba point\" - at which the\nslowest mode vanishes, resulting in faster convergence during the decay phase.\nWe derive analytical conditions for its existence and estimate decay dynamics\nrequired to preserve the Mpemba advantage. Our minimal model and analysis offer\na principled justification for plateau-based schedulers and provide guidance\nfor tuning LR in LLMs with minimal hyperparameter sweep.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u70ed\u529b\u5b66\u7c7b\u6bd4\uff08Mpemba\u6548\u5e94\uff09\u89e3\u91ca\u4e86LLM\u8bad\u7ec3\u4e2d\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08WSD\uff09\u7684\u673a\u5236\uff0c\u63d0\u51fa\u9ad8\u5e73\u53f0\u5b66\u4e60\u7387\u80fd\u52a0\u901f\u635f\u5931\u4e0b\u964d\uff0c\u5e76\u63a8\u5bfc\u4e86\u6700\u4f18\u5e73\u53f0\u5b66\u4e60\u7387\uff08\u5f3aMpemba\u70b9\uff09\u7684\u5b58\u5728\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709LLM\u8bad\u7ec3\u4e2d\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565\uff08\u5982WSD\uff09\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca\uff0c\u5e73\u53f0\u9ad8\u5ea6\u548c\u8870\u51cf\u8ba1\u5212\u591a\u4f9d\u8d56\u7ecf\u9a8c\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u70ed\u529b\u5b66\u7c7b\u6bd4\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u91c7\u7528\u201c\u8c37-\u6cb3\u201d\u635f\u5931\u666f\u89c2\u6a21\u578b\uff0c\u7ed3\u5408Mpemba\u6548\u5e94\u5206\u6790\u5b66\u4e60\u7387\u8c03\u5ea6\uff0c\u63a8\u5bfc\u6700\u4f18\u5e73\u53f0\u5b66\u4e60\u7387\u7684\u5b58\u5728\u6761\u4ef6\u53ca\u8870\u51cf\u52a8\u529b\u5b66\u3002", "result": "\u53d1\u73b0\u9ad8\u5e73\u53f0\u5b66\u4e60\u7387\u80fd\u52a0\u901f\u635f\u5931\u4e0b\u964d\uff0c\u5b58\u5728\u201c\u5f3aMpemba\u70b9\u201d\u4f7f\u6700\u6162\u6a21\u5f0f\u6d88\u5931\uff0c\u4ece\u800c\u52a0\u5feb\u6536\u655b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u57fa\u4e8e\u5e73\u53f0\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u6307\u5bfcLLM\u4e2d\u5b66\u4e60\u7387\u7684\u8c03\u53c2\uff0c\u51cf\u5c11\u8d85\u53c2\u6570\u641c\u7d22\u3002"}}
{"id": "2507.04283", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.04283", "abs": "https://arxiv.org/abs/2507.04283", "authors": ["Roy Uziel", "Irit Chelly", "Oren Freifeld", "Ari Pakman"], "title": "Clustering via Self-Supervised Diffusion", "comment": null, "summary": "Diffusion models, widely recognized for their success in generative tasks,\nhave not yet been applied to clustering. We introduce Clustering via Diffusion\n(CLUDI), a self-supervised framework that combines the generative power of\ndiffusion models with pre-trained Vision Transformer features to achieve robust\nand accurate clustering. CLUDI is trained via a teacher-student paradigm: the\nteacher uses stochastic diffusion-based sampling to produce diverse cluster\nassignments, which the student refines into stable predictions. This\nstochasticity acts as a novel data augmentation strategy, enabling CLUDI to\nuncover intricate structures in high-dimensional data. Extensive evaluations on\nchallenging datasets demonstrate that CLUDI achieves state-of-the-art\nperformance in unsupervised classification, setting new benchmarks in\nclustering robustness and adaptability to complex data distributions.", "AI": {"tldr": "CLUDI\u662f\u4e00\u79cd\u7ed3\u5408\u6269\u6563\u6a21\u578b\u548c\u9884\u8bad\u7ec3Vision Transformer\u7684\u81ea\u76d1\u7763\u805a\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u5e08\u751f\u8303\u5f0f\u5b9e\u73b0\u9ad8\u6027\u80fd\u805a\u7c7b\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5c1a\u672a\u5e94\u7528\u4e8e\u805a\u7c7b\u4efb\u52a1\uff0c\u56e0\u6b64\u63d0\u51faCLUDI\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "CLUDI\u91c7\u7528\u5e08\u751f\u8303\u5f0f\uff0c\u6559\u5e08\u6a21\u578b\u901a\u8fc7\u6269\u6563\u91c7\u6837\u751f\u6210\u591a\u6837\u805a\u7c7b\u5206\u914d\uff0c\u5b66\u751f\u6a21\u578b\u4f18\u5316\u4e3a\u7a33\u5b9a\u9884\u6d4b\u3002", "result": "CLUDI\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u6027\u80fd\uff0c\u9002\u5e94\u590d\u6742\u6570\u636e\u5206\u5e03\u3002", "conclusion": "CLUDI\u4e3a\u805a\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u6269\u6563\u6a21\u578b\u5728\u975e\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.04299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04299", "abs": "https://arxiv.org/abs/2507.04299", "authors": ["Joohyung Lee", "Yunsong Meng"], "title": "Answer Set Programming Modulo Theories and Reasoning about Continuous Changes", "comment": "In Proceedings of the 23rd International Joint Conference on\n  Artificial Intelligence (IJCAI 2013), pages 990-996, 2013", "summary": "Answer Set Programming Modulo Theories (ASPMT) is a new framework of tight\nintegration of answer set programming (ASP) and satisfiability modulo theories\n(SMT). Similar to the relationship between first-order logic and SMT, it is\nbased on a recent proposal of the functional stable model semantics by fixing\ninterpretations of background theories. Analogously to a known relationship\nbetween ASP and SAT, ``tight'' ASPMT programs can be translated into SMT\ninstances. We demonstrate the usefulness of ASPMT by enhancing action language\nC+ to handle continuous changes as well as discrete changes. We reformulate the\nsemantics of C+ in terms ofASPMT, and show that SMT solvers can be used to\ncompute the language. We also show how the language can represent cumulative\neffects on continuous resources.", "AI": {"tldr": "ASPMT\u662fASP\u4e0eSMT\u7d27\u5bc6\u7ed3\u5408\u7684\u65b0\u6846\u67b6\uff0c\u7c7b\u4f3c\u4e8e\u4e00\u9636\u903b\u8f91\u4e0eSMT\u7684\u5173\u7cfb\uff0c\u901a\u8fc7\u56fa\u5b9a\u80cc\u666f\u7406\u8bba\u7684\u89e3\u91ca\u5b9e\u73b0\u3002\u7c7b\u4f3c\u4e8eASP\u4e0eSAT\u7684\u5173\u7cfb\uff0c\u7d27\u81f4\u7684ASPMT\u7a0b\u5e8f\u53ef\u8f6c\u6362\u4e3aSMT\u5b9e\u4f8b\u3002\u901a\u8fc7\u589e\u5f3a\u52a8\u4f5c\u8bed\u8a00C+\u5904\u7406\u8fde\u7eed\u548c\u79bb\u6563\u53d8\u5316\uff0c\u5c55\u793a\u4e86ASPMT\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u7ed3\u5408ASP\u4e0eSMT\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff08\u5982\u52a8\u4f5c\u8bed\u8a00C+\u4e2d\u7684\u8fde\u7eed\u4e0e\u79bb\u6563\u53d8\u5316\uff09\u3002", "method": "\u57fa\u4e8e\u529f\u80fd\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\uff0c\u56fa\u5b9a\u80cc\u666f\u7406\u8bba\u7684\u89e3\u91ca\uff0c\u5c06ASPMT\u7a0b\u5e8f\u8f6c\u6362\u4e3aSMT\u5b9e\u4f8b\u3002", "result": "\u6210\u529f\u5c06ASPMT\u5e94\u7528\u4e8e\u52a8\u4f5c\u8bed\u8a00C+\uff0c\u5b9e\u73b0\u8fde\u7eed\u548c\u79bb\u6563\u53d8\u5316\u7684\u5904\u7406\uff0c\u5e76\u5c55\u793a\u4e86\u7d2f\u79ef\u6548\u5e94\u3002", "conclusion": "ASPMT\u4e3a\u590d\u6742\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u52a8\u4f5c\u8bed\u8a00C+\u7684\u80fd\u529b\u3002"}}
{"id": "2507.04338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04338", "abs": "https://arxiv.org/abs/2507.04338", "authors": ["Abdullah M. Zyarah", "Dhireesha Kudithipudi"], "title": "Voltage Mode Winner-Take-All Circuit for Neuromorphic Systems", "comment": null, "summary": "Recent advances in neuromorphic computing demonstrate on-device learning\ncapabilities with low power consumption. One of the key learning units in these\nsystems is the winner-take-all circuit. In this research, we propose a\nwinner-take-all circuit that can be configured to achieve k-winner and\nhysteresis properties, simulated in IBM 65 nm node. The circuit dissipated 34.9\n$\\mu$W of power with a latency of 10.4 ns, while processing 1000 inputs. The\nutility of the circuit is demonstrated for spatial filtering and\nclassification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u914d\u7f6e\u7684\u80dc\u8005\u901a\u5403\u7535\u8def\uff0c\u7528\u4e8e\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\uff0c\u5177\u6709\u4f4e\u529f\u8017\u548c\u9ad8\u6548\u80fd\u3002", "motivation": "\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u9700\u8981\u4f4e\u529f\u8017\u7684\u5b66\u4e60\u5355\u5143\uff0c\u80dc\u8005\u901a\u5403\u7535\u8def\u662f\u5173\u952e\u7ec4\u4ef6\u4e4b\u4e00\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u914d\u7f6e\u7684\u80dc\u8005\u901a\u5403\u7535\u8def\uff0c\u652f\u6301k-winner\u548c\u6ede\u540e\u7279\u6027\uff0c\u5e76\u5728IBM 65 nm\u5de5\u827a\u8282\u70b9\u4e0a\u8fdb\u884c\u4e86\u4eff\u771f\u3002", "result": "\u7535\u8def\u529f\u8017\u4e3a34.9 \u03bcW\uff0c\u5ef6\u8fdf\u4e3a10.4 ns\uff0c\u53ef\u5904\u74061000\u4e2a\u8f93\u5165\uff0c\u9002\u7528\u4e8e\u7a7a\u95f4\u6ee4\u6ce2\u548c\u5206\u7c7b\u4efb\u52a1\u3002", "conclusion": "\u8be5\u7535\u8def\u5728\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u80fd\u548c\u4f4e\u529f\u8017\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.04348", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04348", "abs": "https://arxiv.org/abs/2507.04348", "authors": ["Xingyang He", "Xiao Ling", "Jie Liu"], "title": "SmartThinker: Learning to Compress and Preserve Reasoning by Step-Level Length Control", "comment": null, "summary": "Large reasoning models (LRMs) have exhibited remarkable reasoning\ncapabilities through inference-time scaling, but this progress has also\nintroduced considerable redundancy and inefficiency into their reasoning\nprocesses, resulting in substantial computational waste. Previous work has\nattempted to mitigate this issue by penalizing the overall length of generated\nsamples during reinforcement learning (RL), with the goal of encouraging a more\nconcise chains of thought. However, we observe that such global length penalty\noften lead to excessive compression of critical reasoning steps while\npreserving unnecessary details in simpler ones, yielding a suboptimal trade-off\nbetween accuracy and efficiency. To address this issue, we propose\nSmartThinker, a two-stage learnable framework designed to enable fine-grained\ncontrol over the length of reasoning chains based on the importance of each\nindividual step. In the first stage, SmartThinker adapts a reasoning model to a\nshort-form reasoning mode through rejection sampling combined with supervised\nfine-tuning (SFT). In the second stage, SmartThinker applies Step-Level Length\nControl Policy Optimization (SCPO) to refine the model output distribution,\nwhich increases the proportion of length allocated to critical steps while\nreducing redundancy in less important ones. SCPO consists of four core\ncomponents: an online importance estimator, a step-level length control reward\nfunction, a step-level generalized advantage estimation (S-GAE) and a\ndifficulty-adaptive clipping strategy. Working in concert, these components\nenable SCPO to implement differentiated length control across reasoning steps.\nEmpirical results across multiple reasoning benchmarks and various backbone\nmodels demonstrate that SmartThinker significantly reduces redundant reasoning\nwhile achieving comparable or even superior performance to existing methods.", "AI": {"tldr": "SmartThinker\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u63a7\u5236\u63a8\u7406\u6b65\u9aa4\u957f\u5ea6\uff0c\u51cf\u5c11\u5197\u4f59\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u63a8\u7406\u65f6\u5b58\u5728\u5197\u4f59\u548c\u4f4e\u6548\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u5168\u5c40\u957f\u5ea6\u60e9\u7f5a\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u5173\u952e\u63a8\u7406\u6b65\u9aa4\u88ab\u8fc7\u5ea6\u538b\u7f29\uff0c\u800c\u7b80\u5355\u6b65\u9aa4\u4fdd\u7559\u4e0d\u5fc5\u8981\u7ec6\u8282\u3002", "method": "SmartThinker\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u9002\u5e94\u77ed\u63a8\u7406\u6a21\u5f0f\uff1b2\uff09\u901a\u8fc7Step-Level Length Control Policy Optimization\uff08SCPO\uff09\u4f18\u5316\u6a21\u578b\u8f93\u51fa\u5206\u5e03\uff0c\u52a8\u6001\u8c03\u6574\u5173\u952e\u6b65\u9aa4\u548c\u6b21\u8981\u6b65\u9aa4\u7684\u957f\u5ea6\u5206\u914d\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u540c\u4e3b\u5e72\u6a21\u578b\u4e0a\uff0cSmartThinker\u663e\u8457\u51cf\u5c11\u4e86\u5197\u4f59\u63a8\u7406\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "SmartThinker\u901a\u8fc7\u7ec6\u7c92\u5ea6\u63a7\u5236\u63a8\u7406\u6b65\u9aa4\u957f\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u5197\u4f59\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6027\u80fd\u3002"}}
{"id": "2507.04370", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04370", "abs": "https://arxiv.org/abs/2507.04370", "authors": ["Yifei Gao", "Junhong Ye", "Jiaqi Wang", "Jitao Sang"], "title": "WebSynthesis: World-Model-Guided MCTS for Efficient WebUI-Trajectory Synthesis", "comment": null, "summary": "Recent advancements in large language models (LLMs) have significantly\nimproved the capabilities of web agents. However, effectively navigating\ncomplex and dynamic web environments still requires more advanced\ntrajectory-level planning and execution. Prior studies have addressed\nself-improving agents by collecting extensive GUI trajectories from\nreal-environment interactions. Despite their effectiveness, these approaches\nencounter two critical challenges: (1) Uncontrollable environment states, where\nreal or sandboxed web environments often yield unstable and non-deterministic\nfeedback, complicating the reproduction and debugging of agent behaviors; and\n(2) High API costs, as generating even a single interaction trajectory can\ninvolve hundreds of queries, leading to considerable API usage and\ncomputational expenses. To address these limitations and enable scalable\nself-improvement for agents, we propose WebSynthesis, a novel framework for\ntrajectory synthesis and training. WebSynthesis leverages a learned world model\nto simulate virtual web environments, allowing a policy agent to perform\nefficient and reversible tree-based planning. This approach supports the\nlarge-scale generation of diverse and high-quality trajectories, which are\nsubsequently utilized to refine the agent's policy. Experimental results\ndemonstrate that an agent trained using WebSynthesis on a small-scale synthetic\ndataset achieves performance comparable to or even surpassing that of models\ntrained on large-scale real-world data.", "AI": {"tldr": "WebSynthesis\u6846\u67b6\u901a\u8fc7\u865a\u62df\u73af\u5883\u6a21\u62df\u548c\u6811\u72b6\u89c4\u5212\u89e3\u51b3LLM\u5728\u52a8\u6001\u7f51\u9875\u5bfc\u822a\u4e2d\u7684\u73af\u5883\u4e0d\u7a33\u5b9a\u548c\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u6027\u80fd\u5ab2\u7f8e\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u590d\u6742\u52a8\u6001\u7f51\u9875\u5bfc\u822a\u4e2d\u73af\u5883\u72b6\u6001\u4e0d\u53ef\u63a7\u548cAPI\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faWebSynthesis\u6846\u67b6\uff0c\u5229\u7528\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u6a21\u62df\u865a\u62df\u7f51\u9875\u73af\u5883\uff0c\u652f\u6301\u6811\u72b6\u89c4\u5212\u751f\u6210\u9ad8\u8d28\u91cf\u8f68\u8ff9\u3002", "result": "\u5728\u5c0f\u89c4\u6a21\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u5ab2\u7f8e\u6216\u8d85\u8d8a\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "WebSynthesis\u4e3aLLM\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u81ea\u6211\u6539\u8fdb\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73af\u5883\u4e0d\u7a33\u5b9a\u548c\u9ad8\u6210\u672c\u95ee\u9898\u3002"}}
{"id": "2507.04381", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04381", "abs": "https://arxiv.org/abs/2507.04381", "authors": ["Bing Fan", "Shusen Ma", "Yun-Bo Zhao", "Yu Kang"], "title": "DC-Mamber: A Dual Channel Prediction Model based on Mamba and Linear Transformer for Multivariate Time Series Forecasting", "comment": null, "summary": "In multivariate time series forecasting (MTSF), existing strategies for\nprocessing sequences are typically categorized as channel-independent and\nchannel-mixing. The former treats all temporal information of each variable as\na token, focusing on capturing local temporal features of individual variables,\nwhile the latter constructs a token from the multivariate information at each\ntime step, emphasizing the modeling of global temporal dependencies. Current\nmainstream models are mostly based on Transformer and the emerging Mamba.\nTransformers excel at modeling global dependencies through self-attention\nmechanisms but exhibit limited sensitivity to local temporal patterns and\nsuffer from quadratic computational complexity, restricting their efficiency in\nlong-sequence processing. In contrast, Mamba, based on state space models\n(SSMs), achieves linear complexity and efficient long-range modeling but\nstruggles to aggregate global contextual information in parallel. To overcome\nthe limitations of both models, we propose DC-Mamber, a dual-channel\nforecasting model based on Mamba and linear Transformer for time series\nforecasting. Specifically, the Mamba-based channel employs a\nchannel-independent strategy to extract intra-variable features, while the\nTransformer-based channel adopts a channel-mixing strategy to model\ncross-timestep global dependencies. DC-Mamber first maps the raw input into two\ndistinct feature representations via separate embedding layers. These\nrepresentations are then processed by a variable encoder (built on Mamba) and a\ntemporal encoder (built on linear Transformer), respectively. Finally, a fusion\nlayer integrates the dual-channel features for prediction. Extensive\nexperiments on eight public datasets confirm DC-Mamber's superior accuracy over\nexisting models.", "AI": {"tldr": "DC-Mamber\u7ed3\u5408Mamba\u548c\u7ebf\u6027Transformer\uff0c\u901a\u8fc7\u53cc\u901a\u9053\u7b56\u7565\u5206\u522b\u63d0\u53d6\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\uff0c\u63d0\u5347\u4e86\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982Transformer\u548cMamba\uff09\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5404\u6709\u5c40\u9650\uff1aTransformer\u5168\u5c40\u4f9d\u8d56\u5f3a\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0cMamba\u8ba1\u7b97\u9ad8\u6548\u4f46\u5168\u5c40\u4fe1\u606f\u6574\u5408\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDC-Mamber\u6a21\u578b\uff0cMamba\u901a\u9053\u63d0\u53d6\u53d8\u91cf\u5185\u7279\u5f81\uff08\u901a\u9053\u72ec\u7acb\uff09\uff0cTransformer\u901a\u9053\u5efa\u6a21\u8de8\u65f6\u95f4\u6b65\u5168\u5c40\u4f9d\u8d56\uff08\u901a\u9053\u6df7\u5408\uff09\uff0c\u6700\u540e\u878d\u5408\u53cc\u901a\u9053\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u516b\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cDC-Mamber\u7684\u51c6\u786e\u6027\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "DC-Mamber\u901a\u8fc7\u7ed3\u5408Mamba\u548cTransformer\u7684\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5c40\u90e8\u4e0e\u5168\u5c40\u5efa\u6a21\u95ee\u9898\u3002"}}
{"id": "2507.04404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04404", "abs": "https://arxiv.org/abs/2507.04404", "authors": ["Jingze Zhu", "Yongliang Wu", "Wenbo Zhu", "Jiawang Cao", "Yanqiang Zheng", "Jiawei Chen", "Xu Yang", "Bernt Schiele", "Jonas Fischer", "Xinting Hu"], "title": "LayerCake: Token-Aware Contrastive Decoding within Large Language Model Layers", "comment": null, "summary": "Large language models (LLMs) excel at natural language understanding and\ngeneration but remain vulnerable to factual errors, limiting their reliability\nin knowledge-intensive tasks. While decoding-time strategies provide a\npromising efficient solution without training, existing methods typically treat\ntoken-level and layer-level signals in isolation, overlooking the joint\ndynamics between them. In this work, we introduce a token-aware,\nlayer-localized contrastive decoding method that aligns specific token types\nwith their most influential transformer layers to improve factual generation.\nThrough empirical attention analysis, we identify two key patterns: punctuation\ntokens receive dominant attention in early layers, while conceptual tokens\ngovern semantic reasoning in intermediate layers. By selectively suppressing\nattention to these token types at their respective depths, we achieve the\ninduction of controlled factual degradation and derive contrastive signals to\nguide the final factual decoding. Our method requires no additional training or\nmodel modification, and experiments demonstrate that our method consistently\nimproves factuality across multiple LLMs and various benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6790\u7684\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u5229\u7528token\u548clayer\u4fe1\u53f7\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u5b58\u5728\u4e8b\u5b9e\u9519\u8bef\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528token\u548clayer\u7684\u8054\u5408\u52a8\u6001\u3002", "method": "\u5f15\u5165token\u611f\u77e5\u3001layer\u5b9a\u4f4d\u7684\u5bf9\u6bd4\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u6291\u5236\u7279\u5b9atoken\u5728\u7279\u5b9a\u5c42\u7684\u6ce8\u610f\u529b\uff0c\u751f\u6210\u5bf9\u6bd4\u4fe1\u53f7\u6307\u5bfc\u89e3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u6a21\u578b\u4fee\u6539\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e8b\u5b9e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u5229\u7528token\u548clayer\u4fe1\u53f7\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e8b\u5b9e\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2507.04428", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04428", "abs": "https://arxiv.org/abs/2507.04428", "authors": ["Feiyue Wu", "Tianxing Wu", "Shenqi Jing"], "title": "ARMR: Adaptively Responsive Network for Medication Recommendation", "comment": "9 pages, accepted by IJCAI 2025", "summary": "Medication recommendation is a crucial task in healthcare, especially for\npatients with complex medical conditions. However, existing methods often\nstruggle to effectively balance the reuse of historical medications with the\nintroduction of new drugs in response to the changing patient conditions. In\norder to address this challenge, we propose an Adaptively Responsive network\nfor Medication Recommendation (ARMR), a new method which incorporates 1) a\npiecewise temporal learning component that distinguishes between recent and\ndistant patient history, enabling more nuanced temporal understanding, and 2)\nan adaptively responsive mechanism that dynamically adjusts attention to new\nand existing drugs based on the patient's current health state and medication\nhistory. Experiments on the MIMIC-III and MIMIC-IV datasets indicate that ARMR\nhas better performance compared with the state-of-the-art baselines in\ndifferent evaluation metrics, which contributes to more personalized and\naccurate medication recommendations. The source code is publicly avaiable at:\nhttps://github.com/seucoin/armr2.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u54cd\u5e94\u7f51\u7edc\uff08ARMR\uff09\u7528\u4e8e\u836f\u7269\u63a8\u8350\uff0c\u901a\u8fc7\u5206\u6bb5\u65f6\u95f4\u5b66\u4e60\u548c\u52a8\u6001\u8c03\u6574\u673a\u5236\uff0c\u5e73\u8861\u5386\u53f2\u836f\u7269\u548c\u65b0\u836f\u7269\u7684\u4f7f\u7528\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u5386\u53f2\u836f\u7269\u548c\u65b0\u836f\u7269\u7684\u4f7f\u7528\uff0c\u65e0\u6cd5\u9002\u5e94\u60a3\u8005\u75c5\u60c5\u53d8\u5316\u3002", "method": "ARMR\u7ed3\u5408\u5206\u6bb5\u65f6\u95f4\u5b66\u4e60\uff08\u533a\u5206\u8fd1\u671f\u548c\u8fdc\u671f\u75c5\u53f2\uff09\u548c\u81ea\u9002\u5e94\u54cd\u5e94\u673a\u5236\uff08\u52a8\u6001\u8c03\u6574\u5bf9\u65b0\u65e7\u836f\u7269\u7684\u5173\u6ce8\uff09\u3002", "result": "\u5728MIMIC-III\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\uff0cARMR\u5728\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ARMR\u63d0\u4f9b\u4e86\u66f4\u4e2a\u6027\u5316\u548c\u51c6\u786e\u7684\u836f\u7269\u63a8\u8350\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.04431", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04431", "abs": "https://arxiv.org/abs/2507.04431", "authors": ["Debodeep Banerjee", "Burcu Sayin", "Stefano Teso", "Andrea Passerini"], "title": "MedGellan: LLM-Generated Medical Guidance to Support Physicians", "comment": null, "summary": "Medical decision-making is a critical task, where errors can result in\nserious, potentially life-threatening consequences. While full automation\nremains challenging, hybrid frameworks that combine machine intelligence with\nhuman oversight offer a practical alternative. In this paper, we present\nMedGellan, a lightweight, annotation-free framework that uses a Large Language\nModel (LLM) to generate clinical guidance from raw medical records, which is\nthen used by a physician to predict diagnoses. MedGellan uses a\nBayesian-inspired prompting strategy that respects the temporal order of\nclinical data. Preliminary experiments show that the guidance generated by the\nLLM with MedGellan improves diagnostic performance, particularly in recall and\n$F_1$ score.", "AI": {"tldr": "MedGellan\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u6807\u6ce8\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u539f\u59cb\u533b\u7597\u8bb0\u5f55\u751f\u6210\u4e34\u5e8a\u6307\u5bfc\uff0c\u5e2e\u52a9\u533b\u751f\u9884\u6d4b\u8bca\u65ad\uff0c\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\u5176\u80fd\u63d0\u5347\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u9519\u8bef\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\u3002\u5b8c\u5168\u81ea\u52a8\u5316\u4ecd\u5177\u6311\u6218\u6027\uff0c\u56e0\u6b64\u7ed3\u5408\u673a\u5668\u667a\u80fd\u4e0e\u4eba\u5de5\u76d1\u7763\u7684\u6df7\u5408\u6846\u67b6\u6210\u4e3a\u5b9e\u7528\u9009\u62e9\u3002", "method": "MedGellan\u91c7\u7528\u8d1d\u53f6\u65af\u542f\u53d1\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5c0a\u91cd\u4e34\u5e8a\u6570\u636e\u7684\u65f6\u95f4\u987a\u5e8f\uff0c\u5229\u7528LLM\u751f\u6210\u4e34\u5e8a\u6307\u5bfc\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0cMedGellan\u751f\u6210\u7684\u6307\u5bfc\u80fd\u663e\u8457\u63d0\u5347\u8bca\u65ad\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u3002", "conclusion": "MedGellan\u4e3a\u533b\u7597\u51b3\u7b56\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u4e86LLM\u7684\u4f18\u52bf\u4e0e\u533b\u751f\u7684\u4e13\u4e1a\u5224\u65ad\u3002"}}
{"id": "2507.04439", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.04439", "abs": "https://arxiv.org/abs/2507.04439", "authors": ["Videep Venkatesha", "Mary Cati Poulos", "Christopher Steadman", "Caitlin Mills", "Anne M. Cleary", "Nathaniel Blanchard"], "title": "A Linguistic Analysis of Spontaneous Thoughts: Investigating Experiences of D\u00e9j\u00e0 Vu, Unexpected Thoughts, and Involuntary Autobiographical Memories", "comment": "Accepted at CogSci 2025", "summary": "The onset of spontaneous thoughts are reflective of dynamic interactions\nbetween cognition, emotion, and attention. Typically, these experiences are\nstudied through subjective appraisals that focus on their triggers,\nphenomenology, and emotional salience. In this work, we use linguistic\nsignatures to investigate Deja Vu, Involuntary Autobiographical Memories and\nUnexpected Thoughts. Specifically, we analyze the inherent characteristics of\nthe linguistic patterns in participant generated descriptions of these thought\ntypes. We show how, by positioning language as a window into spontaneous\ncognition, existing theories on these attentional states can be updated and\nreaffirmed. Our findings align with prior research, reinforcing that Deja Vu is\na metacognitive experience characterized by abstract and spatial language,\nInvoluntary Autobiographical Memories are rich in personal and emotionally\nsignificant detail, and Unexpected Thoughts are marked by unpredictability and\ncognitive disruption. This work is demonstrative of languages potential to\nreveal deeper insights into how internal spontaneous cognitive states manifest\nthrough expression.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bed\u8a00\u7279\u5f81\u5206\u6790\u81ea\u53d1\u601d\u7ef4\uff08\u5982Deja Vu\u3001\u975e\u81ea\u613f\u81ea\u4f20\u4f53\u8bb0\u5fc6\u548c\u610f\u5916\u601d\u7ef4\uff09\uff0c\u9a8c\u8bc1\u5e76\u66f4\u65b0\u4e86\u73b0\u6709\u7406\u8bba\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u601d\u7ef4\u7c7b\u578b\u7684\u8bed\u8a00\u6a21\u5f0f\u7279\u70b9\u3002", "motivation": "\u63a2\u7d22\u81ea\u53d1\u601d\u7ef4\uff08\u5982Deja Vu\u7b49\uff09\u7684\u8bed\u8a00\u8868\u8fbe\u7279\u5f81\uff0c\u4ee5\u66f4\u6df1\u5165\u5730\u7406\u89e3\u5176\u8ba4\u77e5\u3001\u60c5\u611f\u548c\u6ce8\u610f\u529b\u7684\u52a8\u6001\u4ea4\u4e92\u3002", "method": "\u5206\u6790\u53c2\u4e0e\u8005\u5bf9\u8fd9\u4e9b\u601d\u7ef4\u7c7b\u578b\u7684\u8bed\u8a00\u63cf\u8ff0\uff0c\u63d0\u53d6\u5176\u8bed\u8a00\u6a21\u5f0f\u7684\u7279\u5f81\u3002", "result": "Deja Vu\u8868\u73b0\u4e3a\u62bd\u8c61\u548c\u7a7a\u95f4\u8bed\u8a00\uff0c\u975e\u81ea\u613f\u81ea\u4f20\u4f53\u8bb0\u5fc6\u5bcc\u542b\u4e2a\u4eba\u548c\u60c5\u611f\u7ec6\u8282\uff0c\u610f\u5916\u601d\u7ef4\u5219\u5177\u6709\u4e0d\u53ef\u9884\u6d4b\u6027\u548c\u8ba4\u77e5\u5e72\u6270\u7279\u5f81\u3002", "conclusion": "\u8bed\u8a00\u53ef\u4f5c\u4e3a\u7814\u7a76\u81ea\u53d1\u8ba4\u77e5\u72b6\u6001\u7684\u91cd\u8981\u7a97\u53e3\uff0c\u4e3a\u76f8\u5173\u7406\u8bba\u63d0\u4f9b\u65b0\u652f\u6301\u3002"}}
{"id": "2507.04464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04464", "abs": "https://arxiv.org/abs/2507.04464", "authors": ["Ashish Bastola", "Mert D. Pes\u00e9", "Long Cheng", "Jonathon Smereka", "Abolfazl Razi"], "title": "Anomalous Decision Discovery using Inverse Reinforcement Learning", "comment": null, "summary": "Anomaly detection plays a critical role in Autonomous Vehicles (AVs) by\nidentifying unusual behaviors through perception systems that could compromise\nsafety and lead to hazardous situations. Current approaches, which often rely\non predefined thresholds or supervised learning paradigms, exhibit reduced\nefficacy when confronted with unseen scenarios, sensor noise, and occlusions,\nleading to potential safety-critical failures. Moreover, supervised methods\nrequire large annotated datasets, limiting their real-world feasibility. To\naddress these gaps, we propose an anomaly detection framework based on Inverse\nReinforcement Learning (IRL) to infer latent driving intentions from sequential\nperception data, thus enabling robust identification. Specifically, we present\nTrajectory-Reward Guided Adaptive Pre-training (TRAP), a novel IRL framework\nfor anomaly detection, to address two critical limitations of existing methods:\nnoise robustness and generalization to unseen scenarios. Our core innovation is\nimplicitly learning temporal credit assignments via reward and worst-case\nsupervision. We leverage pre-training with variable-horizon sampling to\nmaximize time-to-consequence, resulting in early detection of behavior\ndeviation. Experiments on 14,000+ simulated trajectories demonstrate\nstate-of-the-art performance, achieving 0.90 AUC and 82.2\\% F1-score -\noutperforming similarly trained supervised and unsupervised baselines by 39\\%\non Recall and 12\\% on F1-score, respectively. Similar performance is achieved\nwhile exhibiting robustness to various noise types and generalization to unseen\nanomaly types. Our code will be available at:\nhttps://github.com/abastola0/TRAP.git", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9006\u5f3a\u5316\u5b66\u4e60\uff08IRL\uff09\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6TRAP\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u566a\u58f0\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u672a\u89c1\u573a\u666f\u3001\u4f20\u611f\u5668\u566a\u58f0\u548c\u906e\u6321\u4e0b\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u76d1\u7763\u5b66\u4e60\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528IRL\u6846\u67b6TRAP\uff0c\u901a\u8fc7\u9690\u5f0f\u5b66\u4e60\u65f6\u95f4\u4fe1\u7528\u5206\u914d\u548c\u9884\u8bad\u7ec3\uff0c\u7ed3\u5408\u53ef\u53d8\u65f6\u95f4\u8de8\u5ea6\u91c7\u6837\uff0c\u5b9e\u73b0\u65e9\u671f\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u572814,000+\u6a21\u62df\u8f68\u8ff9\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cAUC\u8fbe0.90\uff0cF1-score\u4e3a82.2%\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TRAP\u5728\u566a\u58f0\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.04494", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.04494", "abs": "https://arxiv.org/abs/2507.04494", "authors": ["Niels Leadholm", "Viviane Clay", "Scott Knudstrup", "Hojae Lee", "Jeff Hawkins"], "title": "Thousand-Brains Systems: Sensorimotor Intelligence for Rapid, Robust Learning and Inference", "comment": "32 pages, 8 figures", "summary": "Current AI systems achieve impressive performance on many tasks, yet they\nlack core attributes of biological intelligence, including rapid, continual\nlearning, representations grounded in sensorimotor interactions, and structured\nknowledge that enables efficient generalization. Neuroscience theory suggests\nthat mammals evolved flexible intelligence through the replication of a\nsemi-independent, sensorimotor module, a functional unit known as a cortical\ncolumn. To address the disparity between biological and artificial\nintelligence, thousand-brains systems were proposed as a means of mirroring the\narchitecture of cortical columns and their interactions.\n  In the current work, we evaluate the unique properties of Monty, the first\nimplementation of a thousand-brains system. We focus on 3D object perception,\nand in particular, the combined task of object recognition and pose estimation.\nUtilizing the YCB dataset of household objects, we first assess Monty's use of\nsensorimotor learning to build structured representations, finding that these\nenable robust generalization. These representations include an emphasis on\nclassifying objects by their global shape, as well as a natural ability to\ndetect object symmetries. We then explore Monty's use of model-free and\nmodel-based policies to enable rapid inference by supporting principled\nmovements. We find that such policies complement Monty's modular architecture,\na design that can accommodate communication between modules to further\naccelerate inference speed via a novel `voting' algorithm. Finally, we examine\nMonty's use of associative, Hebbian-like binding to enable rapid, continual,\nand computationally efficient learning, properties that compare favorably to\ncurrent deep learning architectures. While Monty is still in a nascent stage of\ndevelopment, these findings support thousand-brains systems as a powerful and\npromising new approach to AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMonty\u7684\u5343\u8111\u7cfb\u7edf\uff0c\u6a21\u62df\u751f\u7269\u667a\u80fd\u7684\u6a21\u5757\u5316\u7ed3\u6784\uff0c\u901a\u8fc7\u4f20\u611f\u5668\u8fd0\u52a8\u5b66\u4e60\u548c\u6a21\u5757\u95f4\u4ea4\u4e92\u5b9e\u73b0\u9ad8\u6548\u6cdb\u5316\u548c\u5feb\u901f\u63a8\u7406\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u867d\u5728\u4efb\u52a1\u8868\u73b0\u4e0a\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u751f\u7269\u667a\u80fd\u7684\u6838\u5fc3\u7279\u5f81\uff0c\u5982\u5feb\u901f\u6301\u7eed\u5b66\u4e60\u3001\u57fa\u4e8e\u4f20\u611f\u5668\u8fd0\u52a8\u7684\u8868\u5f81\u548c\u7ed3\u6784\u5316\u77e5\u8bc6\u3002", "method": "\u5229\u7528YCB\u6570\u636e\u96c6\u8bc4\u4f30Monty\u57283D\u7269\u4f53\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u7269\u4f53\u8bc6\u522b\u548c\u59ff\u6001\u4f30\u8ba1\uff0c\u7814\u7a76\u5176\u4f20\u611f\u5668\u8fd0\u52a8\u5b66\u4e60\u3001\u6a21\u5757\u5316\u67b6\u6784\u548c\u5feb\u901f\u63a8\u7406\u7b56\u7565\u3002", "result": "Monty\u901a\u8fc7\u7ed3\u6784\u5316\u8868\u5f81\u5b9e\u73b0\u9c81\u68d2\u6cdb\u5316\uff0c\u652f\u6301\u5feb\u901f\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u6a21\u5757\u95f4\u901a\u4fe1\u52a0\u901f\u63a8\u7406\u901f\u5ea6\u3002\u5176\u5b66\u4e60\u673a\u5236\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002", "conclusion": "\u5343\u8111\u7cfb\u7edf\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684AI\u65b0\u65b9\u6cd5\uff0cMonty\u7684\u521d\u6b65\u6210\u679c\u9a8c\u8bc1\u4e86\u5176\u6f5c\u529b\u3002"}}
{"id": "2507.04513", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04513", "abs": "https://arxiv.org/abs/2507.04513", "authors": ["Gur Keinan", "Omer Ben-Porat"], "title": "Churn-Aware Recommendation Planning under Aggregated Preference Feedback", "comment": "arXiv admin note: substantial text overlap with arXiv:2502.18483", "summary": "We study a sequential decision-making problem motivated by recent regulatory\nand technological shifts that limit access to individual user data in\nrecommender systems (RSs), leaving only population-level preference\ninformation. This privacy-aware setting poses fundamental challenges in\nplanning under uncertainty: Effective personalization requires exploration to\ninfer user preferences, yet unsatisfactory recommendations risk immediate user\nchurn. To address this, we introduce the Rec-APC model, in which an anonymous\nuser is drawn from a known prior over latent user types (e.g., personas or\nclusters), and the decision-maker sequentially selects items to recommend.\nFeedback is binary -- positive responses refine the posterior via Bayesian\nupdates, while negative responses result in the termination of the session.\n  We prove that optimal policies converge to pure exploitation in finite time\nand propose a branch-and-bound algorithm to efficiently compute them.\nExperiments on synthetic and MovieLens data confirm rapid convergence and\ndemonstrate that our method outperforms the POMDP solver SARSOP, particularly\nwhen the number of user types is large or comparable to the number of content\ncategories. Our results highlight the applicability of this approach and\ninspire new ways to improve decision-making under the constraints imposed by\naggregated preference data.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u9690\u79c1\u4fdd\u62a4\u9650\u5236\u4e0b\u63a8\u8350\u7cfb\u7edf\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u63d0\u51faRec-APC\u6a21\u578b\uff0c\u8bc1\u660e\u6700\u4f18\u7b56\u7565\u4f1a\u6536\u655b\u4e8e\u7eaf\u5229\u7528\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8fd1\u671f\u6cd5\u89c4\u548c\u6280\u672f\u9650\u5236\u5bfc\u81f4\u63a8\u8350\u7cfb\u7edf\u53ea\u80fd\u83b7\u53d6\u7fa4\u4f53\u504f\u597d\u6570\u636e\uff0c\u65e0\u6cd5\u8bbf\u95ee\u4e2a\u4f53\u7528\u6237\u6570\u636e\uff0c\u8fd9\u7ed9\u4e2a\u6027\u5316\u63a8\u8350\u5e26\u6765\u6311\u6218\u3002", "method": "\u5f15\u5165Rec-APC\u6a21\u578b\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u66f4\u65b0\u5904\u7406\u533f\u540d\u7528\u6237\u7684\u4e8c\u5143\u53cd\u9988\uff0c\u63d0\u51fa\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u8ba1\u7b97\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRec-APC\u5728\u7528\u6237\u7c7b\u578b\u8f83\u591a\u65f6\u4f18\u4e8ePOMDP\u6c42\u89e3\u5668SARSOP\uff0c\u4e14\u7b56\u7565\u5feb\u901f\u6536\u655b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u805a\u5408\u504f\u597d\u6570\u636e\u4e0b\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.04528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04528", "abs": "https://arxiv.org/abs/2507.04528", "authors": ["Sonal Allana", "Rozita Dara", "Xiaodong Lin", "Pulei Xiong"], "title": "Towards integration of Privacy Enhancing Technologies in Explainable Artificial Intelligence", "comment": "Under peer review", "summary": "Explainable Artificial Intelligence (XAI) is a crucial pathway in mitigating\nthe risk of non-transparency in the decision-making process of black-box\nArtificial Intelligence (AI) systems. However, despite the benefits, XAI\nmethods are found to leak the privacy of individuals whose data is used in\ntraining or querying the models. Researchers have demonstrated privacy attacks\nthat exploit explanations to infer sensitive personal information of\nindividuals. Currently there is a lack of defenses against known privacy\nattacks targeting explanations when vulnerable XAI are used in production and\nmachine learning as a service system. To address this gap, in this article, we\nexplore Privacy Enhancing Technologies (PETs) as a defense mechanism against\nattribute inference on explanations provided by feature-based XAI methods. We\nempirically evaluate 3 types of PETs, namely synthetic training data,\ndifferentially private training and noise addition, on two categories of\nfeature-based XAI. Our evaluation determines different responses from the\nmitigation methods and side-effects of PETs on other system properties such as\nutility and performance. In the best case, PETs integration in explanations\nreduced the risk of the attack by 49.47%, while maintaining model utility and\nexplanation quality. Through our evaluation, we identify strategies for using\nPETs in XAI for maximizing benefits and minimizing the success of this privacy\nattack on sensitive personal information.", "AI": {"tldr": "XAI\u65b9\u6cd5\u53ef\u80fd\u6cc4\u9732\u9690\u79c1\uff0c\u672c\u6587\u63a2\u7d22\u9690\u79c1\u589e\u5f3a\u6280\u672f\uff08PETs\uff09\u4f5c\u4e3a\u9632\u5fa1\u673a\u5236\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cdPETs\u5bf9XAI\u9690\u79c1\u653b\u51fb\u7684\u7f13\u89e3\u6548\u679c\uff0c\u6700\u4f73\u60c5\u51b5\u4e0b\u653b\u51fb\u98ce\u9669\u964d\u4f4e49.47%\u3002", "motivation": "XAI\u65b9\u6cd5\u5728\u63d0\u9ad8\u900f\u660e\u5ea6\u7684\u540c\u65f6\u53ef\u80fd\u6cc4\u9732\u4e2a\u4eba\u9690\u79c1\uff0c\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u9690\u79c1\u653b\u51fb\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "method": "\u8bc4\u4f30\u4e09\u79cdPETs\uff08\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3001\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u548c\u566a\u58f0\u6dfb\u52a0\uff09\u5728\u4e24\u7c7b\u7279\u5f81XAI\u4e0a\u7684\u6548\u679c\u3002", "result": "PETs\u96c6\u6210\u540e\u653b\u51fb\u98ce\u9669\u6700\u9ad8\u964d\u4f4e49.47%\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6548\u7528\u548c\u89e3\u91ca\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5728XAI\u4e2d\u4f7f\u7528PETs\u7684\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u5e76\u6700\u5c0f\u5316\u653b\u51fb\u6210\u529f\u7387\u3002"}}
{"id": "2507.04600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04600", "abs": "https://arxiv.org/abs/2507.04600", "authors": ["Zhipeng Liu", "Peibo Duan", "Binwu Wang", "Xuan Tang", "Qi Chu", "Changsheng Zhang", "Yongsheng Huang", "Bin Zhang"], "title": "DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification", "comment": "This paper has been accepted for presentation at the ACM\n  International Conference on Multimedia (ACM MM 2025)", "summary": "Real-world time series typically exhibit complex temporal variations, making\nthe time series classification task notably challenging. Recent advancements\nhave demonstrated the potential of multi-scale analysis approaches, which\nprovide an effective solution for capturing these complex temporal patterns.\nHowever, existing multi-scale analysis-based time series prediction methods\nfail to eliminate redundant scale-shared features across multi-scale time\nseries, resulting in the model over- or under-focusing on scale-shared\nfeatures. To address this issue, we propose a novel end-to-end Disentangled\nMulti-Scale framework for Time Series classification (DisMS-TS). The core idea\nof DisMS-TS is to eliminate redundant shared features in multi-scale time\nseries, thereby improving prediction performance. Specifically, we propose a\ntemporal disentanglement module to capture scale-shared and scale-specific\ntemporal representations, respectively. Subsequently, to effectively learn both\nscale-shared and scale-specific temporal representations, we introduce two\nregularization terms that ensure the consistency of scale-shared\nrepresentations and the disparity of scale-specific representations across all\ntemporal scales. Extensive experiments conducted on multiple datasets validate\nthe superiority of DisMS-TS over its competitive baselines, with the accuracy\nimprovement up to 9.71%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7aef\u5230\u7aef\u89e3\u8026\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6846\u67b6\uff08DisMS-TS\uff09\uff0c\u901a\u8fc7\u6d88\u9664\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5197\u4f59\u5171\u4eab\u7279\u5f81\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u5e8f\u5217\u901a\u5e38\u5177\u6709\u590d\u6742\u7684\u65f6\u5e8f\u53d8\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u5c3a\u5ea6\u5206\u6790\u4e2d\u672a\u80fd\u6709\u6548\u6d88\u9664\u5197\u4f59\u7684\u5171\u4eab\u7279\u5f81\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u8bbe\u8ba1\u4e86\u65f6\u95f4\u89e3\u8026\u6a21\u5757\uff0c\u5206\u522b\u6355\u83b7\u5171\u4eab\u548c\u7279\u5b9a\u5c3a\u5ea6\u7684\u65f6\u5e8f\u8868\u793a\uff0c\u5e76\u5f15\u5165\u4e24\u4e2a\u6b63\u5219\u5316\u9879\u4ee5\u786e\u4fdd\u5171\u4eab\u7279\u5f81\u7684\u4e00\u81f4\u6027\u548c\u7279\u5b9a\u7279\u5f81\u7684\u5dee\u5f02\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDisMS-TS\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u53479.71%\u3002", "conclusion": "DisMS-TS\u901a\u8fc7\u89e3\u8026\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.04632", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04632", "abs": "https://arxiv.org/abs/2507.04632", "authors": ["Yun Qu", "Qi Cheems Wang", "Yixiu Mao", "Vincent Tao Hu", "Xiangyang Ji"], "title": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "comment": null, "summary": "Recent advances have witnessed the effectiveness of reinforcement learning\n(RL) finetuning in enhancing the reasoning capabilities of large language\nmodels (LLMs). The optimization process often requires numerous iterations to\nachieve satisfactory performance, resulting in high computational costs due to\nthe need for frequent prompt evaluations under intensive LLM interactions and\nrepeated policy updates. Appropriate online prompt selection methods reduce\niteration steps by prioritizing informative prompts during training, while the\npipeline's reliance on exhaustive prompt evaluation and subset selection for\noptimization still incurs substantial computational overhead due to frequent\nLLM inference calls. Distinguished from these direct evaluate-then-select\nschemes, this work investigates iterative approximate evaluation for arbitrary\nprompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian\nrisk-predictive framework that online estimates prompt difficulty without\nrequiring costly LLM interactions. Technically, MoPPS models each prompt's\nsuccess rate as a latent variable, performs streaming Bayesian inference, and\nemploys posterior sampling in a constructed multi-armed bandit machine,\nenabling sample efficient and adaptive prompt selection. Extensive experiments\nacross mathematics, planning, and vision-based geometry tasks show that MoPPS\nreliably predicts prompt difficulty and accelerates training with significantly\nreduced LLM rollouts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMoPPS\u7684\u8d1d\u53f6\u65af\u98ce\u9669\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fd1\u4f3c\u8bc4\u4f30\u51cf\u5c11\u5bf9LLM\u7684\u9ad8\u9891\u8c03\u7528\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u52a0\u901f\u8bad\u7ec3\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5728\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u6709\u6548\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u56e0\u9891\u7e41\u7684\u63d0\u793a\u8bc4\u4f30\u548c\u7b56\u7565\u66f4\u65b0\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "MoPPS\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u5efa\u6a21\u63d0\u793a\u7684\u6210\u529f\u7387\u4f5c\u4e3a\u6f5c\u5728\u53d8\u91cf\uff0c\u5e76\u5728\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u4e2d\u4f7f\u7528\u540e\u9a8c\u91c7\u6837\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u63d0\u793a\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMoPPS\u80fd\u53ef\u9760\u9884\u6d4b\u63d0\u793a\u96be\u5ea6\uff0c\u663e\u8457\u51cf\u5c11LLM\u8c03\u7528\u6b21\u6570\u5e76\u52a0\u901f\u8bad\u7ec3\u3002", "conclusion": "MoPPS\u4e3a\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u6570\u5b66\u3001\u89c4\u5212\u548c\u89c6\u89c9\u51e0\u4f55\u4efb\u52a1\u3002"}}
{"id": "2507.04673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04673", "abs": "https://arxiv.org/abs/2507.04673", "authors": ["Wei Duan", "Li Qian"], "title": "Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message", "comment": null, "summary": "The rise of conversational interfaces has greatly enhanced LLM usability by\nleveraging dialogue history for sophisticated reasoning. However, this reliance\nintroduces an unexplored attack surface. This paper introduces Trojan Horse\nPrompting, a novel jailbreak technique. Adversaries bypass safety mechanisms by\nforging the model's own past utterances within the conversational history\nprovided to its API. A malicious payload is injected into a model-attributed\nmessage, followed by a benign user prompt to trigger harmful content\ngeneration. This vulnerability stems from Asymmetric Safety Alignment: models\nare extensively trained to refuse harmful user requests but lack comparable\nskepticism towards their own purported conversational history. This implicit\ntrust in its \"past\" creates a high-impact vulnerability. Experimental\nvalidation on Google's Gemini-2.0-flash-preview-image-generation shows Trojan\nHorse Prompting achieves a significantly higher Attack Success Rate (ASR) than\nestablished user-turn jailbreaking methods. These findings reveal a fundamental\nflaw in modern conversational AI security, necessitating a paradigm shift from\ninput-level filtering to robust, protocol-level validation of conversational\ncontext integrity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u8d8a\u72f1\u6280\u672f\u201c\u7279\u6d1b\u4f0a\u6728\u9a6c\u63d0\u793a\u201d\uff0c\u901a\u8fc7\u4f2a\u9020\u5bf9\u8bdd\u5386\u53f2\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\uff0c\u63ed\u793a\u4e86\u73b0\u4ee3\u5bf9\u8bddAI\u7684\u5b89\u5168\u7f3a\u9677\u3002", "motivation": "\u5bf9\u8bdd\u754c\u9762\u7684\u666e\u53ca\u589e\u5f3a\u4e86LLM\u7684\u5b9e\u7528\u6027\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u672a\u63a2\u7d22\u7684\u653b\u51fb\u9762\uff0c\u5c24\u5176\u662f\u6a21\u578b\u5bf9\u5176\u81ea\u8eab\u5bf9\u8bdd\u5386\u53f2\u7684\u4fe1\u4efb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7279\u6d1b\u4f0a\u6728\u9a6c\u63d0\u793a\u6280\u672f\uff0c\u901a\u8fc7\u4f2a\u9020\u6a21\u578b\u7684\u5386\u53f2\u5bf9\u8bdd\u8bb0\u5f55\uff0c\u6ce8\u5165\u6076\u610f\u5185\u5bb9\u5e76\u89e6\u53d1\u6709\u5bb3\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6280\u672f\u5728\u653b\u51fb\u6210\u529f\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4e0d\u5bf9\u79f0\u5b89\u5168\u5bf9\u9f50\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u73b0\u4ee3\u5bf9\u8bddAI\u9700\u4ece\u8f93\u5165\u7ea7\u8fc7\u6ee4\u8f6c\u5411\u534f\u8bae\u7ea7\u9a8c\u8bc1\uff0c\u4ee5\u786e\u4fdd\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u7684\u5b8c\u6574\u6027\u3002"}}
{"id": "2507.04719", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.04719", "abs": "https://arxiv.org/abs/2507.04719", "authors": ["Roozbeh Yousefzadeh", "Xuenan Cao"], "title": "Advocate for Complete Benchmarks for Formal Reasoning with Formal/Informal Statements and Formal/Informal Proofs", "comment": null, "summary": "This position paper provides a critical but constructive discussion of\ncurrent practices in benchmarking and evaluative practices in the field of\nformal reasoning and automated theorem proving. We take the position that open\ncode, open data, and benchmarks that are complete and error-free will\naccelerate progress in this field. We identify practices that create barriers\nto contributing to this field and suggest ways to remove them. We also discuss\nsome of the practices that might produce misleading evaluative information. We\naim to create discussions that bring together people from various groups\ncontributing to automated theorem proving, autoformalization, and informal\nreasoning.", "AI": {"tldr": "\u672c\u6587\u6279\u8bc4\u5e76\u8ba8\u8bba\u4e86\u5f62\u5f0f\u63a8\u7406\u548c\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\u5b9e\u8df5\uff0c\u63d0\u5021\u5f00\u653e\u4ee3\u7801\u3001\u5f00\u653e\u6570\u636e\u548c\u65e0\u9519\u8bef\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u63a8\u52a8\u8fdb\u6b65\u3002", "motivation": "\u63a2\u8ba8\u5f53\u524d\u5b9e\u8df5\u4e2d\u7684\u95ee\u9898\uff0c\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u5f00\u653e\u6027\u548c\u534f\u4f5c\u6027\uff0c\u6d88\u9664\u8d21\u732e\u969c\u788d\u3002", "method": "\u5206\u6790\u73b0\u6709\u5b9e\u8df5\uff0c\u8bc6\u522b\u95ee\u9898\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "result": "\u63d0\u51fa\u4e86\u4fc3\u8fdb\u5f00\u653e\u6027\u548c\u51cf\u5c11\u8bef\u5bfc\u6027\u8bc4\u4f30\u7684\u65b9\u6cd5\u3002", "conclusion": "\u65e8\u5728\u901a\u8fc7\u8ba8\u8bba\u63a8\u52a8\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u3001\u81ea\u52a8\u5f62\u5f0f\u5316\u548c\u975e\u5f62\u5f0f\u63a8\u7406\u9886\u57df\u7684\u5408\u4f5c\u3002"}}
{"id": "2507.04722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04722", "abs": "https://arxiv.org/abs/2507.04722", "authors": ["Jinzhi Wang", "Bin Li", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Ruimeng Li", "Biyi Zhou"], "title": "LumiCRS: Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Movie Recommendation", "comment": null, "summary": "Conversational recommender systems (CRSs) often suffer from an extreme\nlong-tail distribution of dialogue data, causing a strong bias toward\nhead-frequency blockbusters that sacrifices diversity and exacerbates the\ncold-start problem. An empirical analysis of DCRS and statistics on the REDIAL\ncorpus show that only 10% of head movies account for nearly half of all\nmentions, whereas about 70% of tail movies receive merely 26% of the attention.\nThis imbalance gives rise to three critical challenges: head over-fitting, body\nrepresentation drift, and tail sparsity. To address these issues, we propose\nLumiCRS, an end-to-end framework that mitigates long-tail imbalance through\nthree mutually reinforcing layers: (i) an Adaptive Comprehensive Focal Loss\n(ACFL) that dynamically adjusts class weights and focusing factors to curb head\nover-fitting and reduce popularity bias; (ii) Prototype Learning for Long-Tail\nRecommendation, which selects semantic, affective, and contextual prototypes to\nguide clustering and stabilize body and tail representations; and (iii) a\nGPT-4o-driven prototype-guided dialogue augmentation module that automatically\ngenerates diverse long-tail conversational snippets to alleviate tail sparsity\nand distribution shift. Together, these strategies enable LumiCRS to markedly\nimprove recommendation accuracy, diversity, and fairness: on the REDIAL and\nINSPIRED benchmarks, LumiCRS boosts Recall@10 and Tail-Recall@10 by 7-15% over\nfifteen strong baselines, while human evaluations confirm superior fluency,\ninformativeness, and long-tail relevance. These results demonstrate the\neffectiveness of multi-layer collaboration in building an efficient and fair\nlong-tail conversational recommender.", "AI": {"tldr": "LumiCRS\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7126\u70b9\u635f\u5931\u3001\u539f\u578b\u5b66\u4e60\u548cGPT-4\u9a71\u52a8\u7684\u5bf9\u8bdd\u589e\u5f3a\uff0c\u89e3\u51b3\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u957f\u5c3e\u5206\u5e03\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7684\u51c6\u786e\u6027\u3001\u591a\u6837\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff08CRS\uff09\u4e2d\u5b58\u5728\u6781\u7aef\u957f\u5c3e\u5206\u5e03\u95ee\u9898\uff0c\u5bfc\u81f4\u5bf9\u9ad8\u9891\u70ed\u95e8\u5185\u5bb9\u7684\u504f\u597d\uff0c\u727a\u7272\u4e86\u591a\u6837\u6027\u5e76\u52a0\u5267\u4e86\u51b7\u542f\u52a8\u95ee\u9898\u3002", "method": "LumiCRS\u91c7\u7528\u4e09\u5c42\u7b56\u7565\uff1a(i) \u81ea\u9002\u5e94\u7efc\u5408\u7126\u70b9\u635f\u5931\uff08ACFL\uff09\u52a8\u6001\u8c03\u6574\u7c7b\u522b\u6743\u91cd\uff1b(ii) \u539f\u578b\u5b66\u4e60\u7a33\u5b9a\u957f\u5c3e\u63a8\u8350\uff1b(iii) GPT-4\u9a71\u52a8\u7684\u5bf9\u8bdd\u589e\u5f3a\u6a21\u5757\u751f\u6210\u591a\u6837\u957f\u5c3e\u5bf9\u8bdd\u7247\u6bb5\u3002", "result": "\u5728REDIAL\u548cINSPIRED\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLumiCRS\u7684Recall@10\u548cTail-Recall@10\u6bd4\u57fa\u7ebf\u63d0\u9ad8\u4e867-15%\uff0c\u4eba\u7c7b\u8bc4\u4f30\u4e5f\u663e\u793a\u5176\u5728\u6d41\u7545\u6027\u3001\u4fe1\u606f\u91cf\u548c\u957f\u5c3e\u76f8\u5173\u6027\u4e0a\u7684\u4f18\u52bf\u3002", "conclusion": "LumiCRS\u901a\u8fc7\u591a\u5c42\u534f\u4f5c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5c3e\u5206\u5e03\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u7387\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.04736", "categories": ["cs.AI", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.04736", "abs": "https://arxiv.org/abs/2507.04736", "authors": ["Zhirong Chen", "Kaiyan Chang", "Zhuolin Li", "Xinyang He", "Chujie Chen", "Cangyuan Li", "Mengdi Wang", "Haobo Xu", "Yinhe Han", "Ying Wang"], "title": "ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) show significant potential for automating\nRegister-Transfer Level (RTL) code generation. However, current approaches face\na critical challenge: they can not simultaneously optimize for functional\ncorrectness and hardware quality (Power, Performance, Area - PPA). Methods\nbased on supervised fine-tuning often generate functionally correct but\nPPA-suboptimal code, lacking mechanisms to learn optimization principles. In\ncontrast, post-processing techniques that attempt to improve PPA metrics after\ngeneration are often inefficient because they operate externally without\nupdating the LLM's parameters, thus failing to enhance the model's intrinsic\ndesign capabilities.\n  To bridge this gap, we introduce ChipSeek-R1, a hierarchical reward-driven\nreinforcement learning framework to train LLMs to generate RTL code that\nachieves both functional correctness and optimized PPA metrics. ChipSeek-R1\nemploys a hierarchical reward system, which incorporates direct feedback on\nsyntax, functional correctness (from simulators) and PPA metrics (from\nsynthesis tools) during reinforcement learning. This enables the model to learn\ncomplex hardware design trade-offs via trial-and-error, generating RTL code\nthat is both functionally correct and PPA-optimized. Evaluating ChipSeek-R1 on\nstandard benchmarks (VerilogEval, RTLLM), we achieve state-of-the-art results\nin functional correctness. Notably, on the RTLLM benchmark, ChipSeek-R1\ngenerated 27 RTL designs surpassing the PPA metrics of the original\nhuman-written code. Our findings demonstrate the effectiveness of integrating\ntoolchain feedback into LLM training and highlight the potential for\nreinforcement learning to enable automated generation of human-surpassing RTL\ncode. We open-source our code in anonymous github.", "AI": {"tldr": "ChipSeek-R1 \u662f\u4e00\u4e2a\u57fa\u4e8e\u5206\u5c42\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u529f\u80fd\u6b63\u786e\u4e14\u786c\u4ef6\u8d28\u91cf\uff08PPA\uff09\u4f18\u5316\u7684 RTL \u4ee3\u7801\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u4f18\u5316\u529f\u80fd\u6b63\u786e\u6027\u548c\u786c\u4ef6\u8d28\u91cf\uff08PPA\uff09\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u5347 LLM \u7684\u8bbe\u8ba1\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5956\u52b1\u7cfb\u7edf\uff0c\u7ed3\u5408\u8bed\u6cd5\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c PPA \u6307\u6807\u7684\u53cd\u9988\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3 LLM\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cChipSeek-R1 \u5b9e\u73b0\u4e86\u529f\u80fd\u6b63\u786e\u6027\u7684\u6700\u4f73\u7ed3\u679c\uff0c\u5e76\u5728 RTLLM \u57fa\u51c6\u4e2d\u751f\u6210\u4e86 27 \u4e2a PPA \u6307\u6807\u4f18\u4e8e\u4eba\u5de5\u7f16\u5199\u7684 RTL \u8bbe\u8ba1\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c06\u5de5\u5177\u94fe\u53cd\u9988\u96c6\u6210\u5230 LLM \u8bad\u7ec3\u4e2d\u662f\u6709\u6548\u7684\uff0c\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u5b9e\u73b0\u81ea\u52a8\u5316\u751f\u6210\u8d85\u8d8a\u4eba\u5de5\u7684 RTL \u4ee3\u7801\u3002"}}
{"id": "2507.04742", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04742", "abs": "https://arxiv.org/abs/2507.04742", "authors": ["Seyedarmin Azizi", "Erfan Baghaei Potraghloo", "Massoud Pedram"], "title": "Activation Steering for Chain-of-Thought Compression", "comment": null, "summary": "Large language models (LLMs) excel at complex reasoning when they include\nintermediate steps, known as \"chains of thought\" (CoTs). However, these\nrationales are often overly verbose, even for simple problems, leading to\nwasted context, increased latency, and higher energy consumption. We observe\nthat verbose, English-heavy CoTs and concise, math-centric CoTs occupy distinct\nregions in the model's residual-stream activation space. By extracting and\ninjecting a \"steering vector\" to transition between these modes, we can\nreliably shift generation toward more concise reasoning, effectively\ncompressing CoTs without retraining. We formalize this approach as\nActivation-Steered Compression (ASC), an inference-time technique that shortens\nreasoning traces by directly modifying hidden representations. In addition, we\nprovide a theoretical analysis of the impact of ASC on the output distribution,\nderived from a closed-form KL-divergence-bounded constraint to regulate\nsteering strength. Using only 100 paired verbose and concise examples, ASC\nachieves up to 67.43% reduction in CoT length on MATH500 and GSM8K datasets,\nwhile maintaining accuracy across 7B, 8B, and 32B parameter models. As a\ntraining-free method, ASC introduces negligible runtime overhead and, on\nMATH500, delivers an average 2.73x speedup in end-to-end reasoning wall-clock\ntime on an 8B model. This makes ASC a practical and efficient tool for\nstreamlining the deployment of reasoning-capable LLMs in latency- or\ncost-sensitive settings. The code is available at:\nhttps://github.com/ArminAzizi98/ASC", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6fc0\u6d3b\u5bfc\u5411\u538b\u7f29\uff08ASC\uff09\u7684\u6280\u672f\uff0c\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u7684\u9690\u85cf\u8868\u793a\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u7f29\u77ed\u63a8\u7406\u94fe\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u65f6\u751f\u6210\u7684\u4e2d\u95f4\u6b65\u9aa4\uff08CoTs\uff09\u901a\u5e38\u8fc7\u4e8e\u5197\u957f\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u548c\u5ef6\u8fdf\u589e\u52a0\u3002", "method": "\u901a\u8fc7\u63d0\u53d6\u548c\u6ce8\u5165\u201c\u5bfc\u5411\u5411\u91cf\u201d\u6765\u5207\u6362\u6a21\u578b\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u4ece\u5197\u957f\u7684\u82f1\u8bed\u63a8\u7406\u8f6c\u5411\u7b80\u6d01\u7684\u6570\u5b66\u63a8\u7406\u3002", "result": "ASC\u5728MATH500\u548cGSM8K\u6570\u636e\u96c6\u4e0a\u51cf\u5c11\u4e8667.43%\u7684\u63a8\u7406\u94fe\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u5e76\u57288B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e862.73\u500d\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "ASC\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5bf9\u5ef6\u8fdf\u6216\u6210\u672c\u654f\u611f\u7684\u573a\u666f\u3002"}}
{"id": "2507.04748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04748", "abs": "https://arxiv.org/abs/2507.04748", "authors": ["Sungmin Lee", "Minju Kang", "Joonhee Lee", "Seungyong Lee", "Dongju Kim", "Jingi Hong", "Jun Shin", "Pei Zhang", "JeongGil Ko"], "title": "LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction", "comment": null, "summary": "Question-answering (QA) interfaces powered by large language models (LLMs)\npresent a promising direction for improving interactivity with HVAC system\ninsights, particularly for non-expert users. However, enabling accurate,\nreal-time, and context-aware interactions with HVAC systems introduces unique\nchallenges, including the integration of frequently updated sensor data,\ndomain-specific knowledge grounding, and coherent multi-stage reasoning. In\nthis paper, we present JARVIS, a two-stage LLM-based QA framework tailored for\nsensor data-driven HVAC system interaction. JARVIS employs an Expert-LLM to\ntranslate high-level user queries into structured execution instructions, and\nan Agent that performs SQL-based data retrieval, statistical processing, and\nfinal response generation. To address HVAC-specific challenges, JARVIS\nintegrates (1) an adaptive context injection strategy for efficient HVAC and\ndeployment-specific information integration, (2) a parameterized SQL builder\nand executor to improve data access reliability, and (3) a bottom-up planning\nscheme to ensure consistency across multi-stage response generation. We\nevaluate JARVIS using real-world data collected from a commercial HVAC system\nand a ground truth QA dataset curated by HVAC experts to demonstrate its\neffectiveness in delivering accurate and interpretable responses across diverse\nqueries. Results show that JARVIS consistently outperforms baseline and\nablation variants in both automated and user-centered assessments, achieving\nhigh response quality and accuracy.", "AI": {"tldr": "JARVIS\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4e24\u9636\u6bb5QA\u6846\u67b6\uff0c\u4e13\u4e3aHVAC\u7cfb\u7edf\u4ea4\u4e92\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4e13\u5bb6LLM\u548c\u4ee3\u7406\u5b9e\u73b0\u9ad8\u6548\u3001\u51c6\u786e\u7684\u67e5\u8be2\u5904\u7406\u3002", "motivation": "\u63d0\u5347\u975e\u4e13\u5bb6\u7528\u6237\u4e0eHVAC\u7cfb\u7edf\u7684\u4ea4\u4e92\u4f53\u9a8c\uff0c\u89e3\u51b3\u5b9e\u65f6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684QA\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u4e13\u5bb6LLM\u7ffb\u8bd1\u67e5\u8be2\uff0c\u4ee3\u7406\u6267\u884cSQL\u6570\u636e\u68c0\u7d22\u548c\u54cd\u5e94\u751f\u6210\uff1b\u96c6\u6210\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u6ce8\u5165\u3001\u53c2\u6570\u5316SQL\u6784\u5efa\u5668\u548c\u81ea\u5e95\u5411\u4e0a\u89c4\u5212\u3002", "result": "\u5728\u771f\u5b9eHVAC\u6570\u636e\u548c\u4e13\u5bb6QA\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cJARVIS\u5728\u54cd\u5e94\u8d28\u91cf\u548c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "JARVIS\u6709\u6548\u89e3\u51b3\u4e86HVAC\u7cfb\u7edf\u4ea4\u4e92\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u54cd\u5e94\u3002"}}
{"id": "2507.04770", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.04770", "abs": "https://arxiv.org/abs/2507.04770", "authors": ["Toan Nguyen", "Tri Le", "Quang Nguyen", "Anh Nguyen"], "title": "FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System", "comment": null, "summary": "Furniture decoration is an important task in various industrial applications.\nHowever, achieving a high-quality decorative result is often time-consuming and\nrequires specialized artistic expertise. To tackle these challenges, we explore\nhow multi-agent systems can assist in automating the decoration process. We\npropose FurniMAS, a multi-agent system for automatic furniture decoration.\nSpecifically, given a human prompt and a household furniture item such as a\nworking desk or a TV stand, our system suggests relevant assets with\nappropriate styles and materials, and arranges them on the item, ensuring the\ndecorative result meets functionality, aesthetic, and ambiance preferences.\nFurniMAS assembles a hybrid team of LLM-based and non-LLM agents, each\nfulfilling distinct roles in a typical decoration project. These agents\ncollaborate through communication, logical reasoning, and validation to\ntransform the requirements into the final outcome. Extensive experiments\ndemonstrate that our FurniMAS significantly outperforms other baselines in\ngenerating high-quality 3D decor.", "AI": {"tldr": "FurniMAS\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5bb6\u5177\u88c5\u9970\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u548c\u975eLLM\u667a\u80fd\u4f53\u534f\u4f5c\u751f\u6210\u9ad8\u8d28\u91cf\u76843D\u88c5\u9970\u6548\u679c\u3002", "motivation": "\u5bb6\u5177\u88c5\u9970\u9700\u8981\u4e13\u4e1a\u827a\u672f\u6280\u80fd\u4e14\u8017\u65f6\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4ee5\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51faFurniMAS\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u548c\u975eLLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u534f\u4f5c\u5b8c\u6210\u88c5\u9970\u4efb\u52a1\uff0c\u5305\u62ec\u8d44\u4ea7\u9009\u62e9\u3001\u98ce\u683c\u5339\u914d\u548c\u5e03\u5c40\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFurniMAS\u5728\u751f\u6210\u9ad8\u8d28\u91cf3D\u88c5\u9970\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FurniMAS\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6709\u6548\u89e3\u51b3\u4e86\u5bb6\u5177\u88c5\u9970\u7684\u81ea\u52a8\u5316\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.04803", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04803", "abs": "https://arxiv.org/abs/2507.04803", "authors": ["George Jagadeesh", "Srikrishna Iyer", "Michal Polanowski", "Kai Xin Thia"], "title": "Application and Evaluation of Large Language Models for Forecasting the Impact of Traffic Incidents", "comment": "This paper has been accepted for publication at the 2025 IEEE 28th\n  International Conference on Intelligent Transportation Systems (ITSC), Gold\n  Coast, Australia, 2025. Copyright IEEE", "summary": "This study examines the feasibility of applying large language models (LLMs)\nfor forecasting the impact of traffic incidents on the traffic flow. The use of\nLLMs for this task has several advantages over existing machine learning-based\nsolutions such as not requiring a large training dataset and the ability to\nutilize free-text incident logs. We propose a fully LLM-based solution that\npredicts the incident impact using a combination of traffic features and\nLLM-extracted incident features. A key ingredient of this solution is an\neffective method of selecting examples for the LLM's in-context learning. We\nevaluate the performance of three advanced LLMs and two state-of-the-art\nmachine learning models on a real traffic incident dataset. The results show\nthat the best-performing LLM matches the accuracy of the most accurate machine\nlearning model, despite the former not having been trained on this prediction\ntask. The findings indicate that LLMs are a practically viable option for\ntraffic incident impact prediction.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9884\u6d4b\u4ea4\u901a\u4e8b\u4ef6\u5bf9\u4ea4\u901a\u6d41\u5f71\u54cd\u7684\u53ef\u884c\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u80fd\u5229\u7528\u81ea\u7531\u6587\u672c\u4e8b\u4ef6\u65e5\u5fd7\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u800cLLM\u80fd\u5229\u7528\u81ea\u7531\u6587\u672c\u65e5\u5fd7\u4e14\u65e0\u9700\u5927\u91cf\u6570\u636e\uff0c\u4e3a\u4ea4\u901a\u4e8b\u4ef6\u5f71\u54cd\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8eLLM\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u4ea4\u901a\u7279\u5f81\u548cLLM\u63d0\u53d6\u7684\u4e8b\u4ef6\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6709\u6548\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\u7528\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002", "result": "\u5728\u771f\u5b9e\u4ea4\u901a\u4e8b\u4ef6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u4e09\u79cd\u5148\u8fdbLLM\u548c\u4e24\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u8868\u73b0\u6700\u4f73\u7684LLM\u4e0e\u6700\u51c6\u786e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7cbe\u5ea6\u76f8\u5f53\u3002", "conclusion": "LLM\u5728\u4ea4\u901a\u4e8b\u4ef6\u5f71\u54cd\u9884\u6d4b\u4e2d\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u5c3d\u7ba1\u672a\u9488\u5bf9\u8be5\u4efb\u52a1\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u4ecd\u80fd\u8fbe\u5230\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002"}}
{"id": "2507.04877", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04877", "abs": "https://arxiv.org/abs/2507.04877", "authors": ["Zewen Sun", "Ruoxiang Huang", "Jiahe Feng", "Rundong Kong", "Yuqian Wang", "Hengyu Liu", "Ziqi Gong", "Yuyuan Qin", "Yingxue Wang", "Yu Wang"], "title": "DoPI: Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine", "comment": null, "summary": "Enhancing interrogation capabilities in Traditional Chinese Medicine (TCM)\ndiagnosis through multi-turn dialogues and knowledge graphs presents a\nsignificant challenge for modern AI systems. Current large language models\n(LLMs), despite their advancements, exhibit notable limitations in medical\napplications, particularly in conducting effective multi-turn dialogues and\nproactive questioning. These shortcomings hinder their practical application\nand effectiveness in simulating real-world diagnostic scenarios. To address\nthese limitations, we propose DoPI, a novel LLM system specifically designed\nfor the TCM domain. The DoPI system introduces a collaborative architecture\ncomprising a guidance model and an expert model. The guidance model conducts\nmulti-turn dialogues with patients and dynamically generates questions based on\na knowledge graph to efficiently extract critical symptom information.\nSimultaneously, the expert model leverages deep TCM expertise to provide final\ndiagnoses and treatment plans. Furthermore, this study constructs a multi-turn\ndoctor-patient dialogue dataset to simulate realistic consultation scenarios\nand proposes a novel evaluation methodology that does not rely on manually\ncollected real-world consultation data. Experimental results show that the DoPI\nsystem achieves an accuracy rate of 84.68 percent in interrogation outcomes,\nsignificantly enhancing the model's communication ability during diagnosis\nwhile maintaining professional expertise.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDoPI\u7684\u65b0\u578bLLM\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u548c\u77e5\u8bc6\u56fe\u8c31\u63d0\u5347\u4e2d\u533b\u8bca\u65ad\u80fd\u529b\u3002\u7cfb\u7edf\u91c7\u7528\u534f\u4f5c\u67b6\u6784\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u5bf9\u8bdd\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u533b\u5b66\u5e94\u7528\u4e2d\u5b58\u5728\u591a\u8f6e\u5bf9\u8bdd\u548c\u4e3b\u52a8\u63d0\u95ee\u7684\u5c40\u9650\u6027\uff0c\u963b\u788d\u4e86\u5176\u5728\u771f\u5b9e\u8bca\u65ad\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faDoPI\u7cfb\u7edf\uff0c\u5305\u542b\u6307\u5bfc\u6a21\u578b\u548c\u4e13\u5bb6\u6a21\u578b\uff0c\u524d\u8005\u8d1f\u8d23\u591a\u8f6e\u5bf9\u8bdd\u548c\u52a8\u6001\u63d0\u95ee\uff0c\u540e\u8005\u63d0\u4f9b\u8bca\u65ad\u548c\u6cbb\u7597\u65b9\u6848\u3002\u6784\u5efa\u4e86\u591a\u8f6e\u533b\u60a3\u5bf9\u8bdd\u6570\u636e\u96c6\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDoPI\u7cfb\u7edf\u5728\u95ee\u8bca\u7ed3\u679c\u4e2d\u8fbe\u523084.68%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bca\u65ad\u4e2d\u7684\u6c9f\u901a\u80fd\u529b\u3002", "conclusion": "DoPI\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u4e2d\u533b\u8bca\u65ad\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.04893", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.04893", "abs": "https://arxiv.org/abs/2507.04893", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang"], "title": "MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction", "comment": "13 pages, 5 figures", "summary": "Accident severity prediction plays a critical role in transportation safety\nsystems but is a persistently difficult task due to incomplete data, strong\nfeature dependencies, and severe class imbalance in which rare but\nhigh-severity cases are underrepresented and hard to detect. Existing methods\noften rely on monolithic models or black box prompting, which struggle to scale\nin noisy, real-world settings and offer limited interpretability. To address\nthese challenges, we propose MARBLE a multiagent rule based LLM engine that\ndecomposes the severity prediction task across a team of specialized reasoning\nagents, including an interchangeable ML-backed agent. Each agent focuses on a\nsemantic subset of features (e.g., spatial, environmental, temporal), enabling\nscoped reasoning and modular prompting without the risk of prompt saturation.\nPredictions are coordinated through either rule-based or LLM-guided consensus\nmechanisms that account for class rarity and confidence dynamics. The system\nretains structured traces of agent-level reasoning and coordination outcomes,\nsupporting in-depth interpretability and post-hoc performance diagnostics.\nAcross both UK and US datasets, MARBLE consistently outperforms traditional\nmachine learning classifiers and state-of-the-art (SOTA) prompt-based reasoning\nmethods including Chain-of-Thought (CoT), Least-to-Most (L2M), and\nTree-of-Thought (ToT) achieving nearly 90% accuracy where others plateau below\n48%. This performance redefines the practical ceiling for accident severity\nclassification under real world noise and extreme class imbalance. Our results\nposition MARBLE as a generalizable and interpretable framework for reasoning\nunder uncertainty in safety-critical applications.", "AI": {"tldr": "MARBLE\u662f\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u89c4\u5219\u9a71\u52a8\u7684LLM\u5f15\u64ce\uff0c\u901a\u8fc7\u5206\u89e3\u4efb\u52a1\u548c\u6a21\u5757\u5316\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u901a\u4e8b\u6545\u4e25\u91cd\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4ea4\u901a\u4e8b\u6545\u4e25\u91cd\u6027\u9884\u6d4b\u56e0\u6570\u636e\u4e0d\u5b8c\u6574\u3001\u7279\u5f81\u4f9d\u8d56\u6027\u5f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u800c\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u566a\u58f0\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "MARBLE\u5229\u7528\u591a\u4e2a\u4e13\u95e8\u63a8\u7406\u667a\u80fd\u4f53\uff08\u5305\u62ec\u53ef\u4e92\u6362\u7684ML\u652f\u6301\u667a\u80fd\u4f53\uff09\u5206\u89e3\u4efb\u52a1\uff0c\u901a\u8fc7\u89c4\u5219\u6216LLM\u5f15\u5bfc\u7684\u5171\u8bc6\u673a\u5236\u534f\u8c03\u9884\u6d4b\u3002", "result": "\u5728\u82f1\u7f8e\u6570\u636e\u96c6\u4e0a\uff0cMARBLE\u51c6\u786e\u7387\u63a5\u8fd190%\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548cSOTA\u63d0\u793a\u63a8\u7406\u65b9\u6cd5\uff08\u5982CoT\u3001L2M\u3001ToT\uff09\u3002", "conclusion": "MARBLE\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002"}}
{"id": "2507.04994", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.04994", "abs": "https://arxiv.org/abs/2507.04994", "authors": ["Adam Gould", "Gabriel de Olim Gaul", "Francesca Toni"], "title": "Supported Abstract Argumentation for Case-Based Reasoning", "comment": "Accepted to IARML@ICJAI2025: Workshop on the Interactions between\n  Analogical Reasoning and Machine Learning", "summary": "We introduce Supported Abstract Argumentation for Case-Based Reasoning\n(sAA-CBR), a binary classification model in which past cases engage in debates\nby arguing in favour of their labelling and attacking or supporting those with\nopposing or agreeing labels. With supports, sAA-CBR overcomes the limitation of\nits precursor AA-CBR, which can contain extraneous cases (or spikes) that are\nnot included in the debates. We prove that sAA-CBR contains no spikes, without\ntrading off key model properties", "AI": {"tldr": "sAA-CBR\u662f\u4e00\u79cd\u4e8c\u5143\u5206\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u652f\u6301\u673a\u5236\u6539\u8fdbAA-CBR\uff0c\u6d88\u9664\u4e86\u65e0\u5173\u6848\u4f8b\uff08spikes\uff09\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5173\u952e\u6a21\u578b\u7279\u6027\u3002", "motivation": "\u89e3\u51b3AA-CBR\u4e2d\u5b58\u5728\u7684\u65e0\u5173\u6848\u4f8b\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u7684\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u8ba9\u8fc7\u53bb\u6848\u4f8b\u5728\u8fa9\u8bba\u4e2d\u652f\u6301\u6216\u653b\u51fb\u5176\u4ed6\u6848\u4f8b\u7684\u6807\u7b7e\uff0c\u5f15\u5165\u652f\u6301\u673a\u5236\u3002", "result": "\u8bc1\u660esAA-CBR\u4e0d\u542b\u65e0\u5173\u6848\u4f8b\uff0c\u4e14\u4e0d\u727a\u7272\u5173\u952e\u6a21\u578b\u7279\u6027\u3002", "conclusion": "sAA-CBR\u901a\u8fc7\u652f\u6301\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86AA-CBR\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u5b8c\u6574\u6027\u3002"}}
{"id": "2507.05011", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05011", "abs": "https://arxiv.org/abs/2507.05011", "authors": ["Maxence Boels", "Harry Robertshaw", "Alejandro Granados", "Prokar Dasgupta", "Sebastien Ourselin"], "title": "When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning", "comment": "This manuscript has been submitted to a conference and is being peer\n  reviewed", "summary": "Surgical action planning requires predicting future instrument-verb-target\ntriplets for real-time assistance. While teleoperated robotic surgery provides\nnatural expert demonstrations for imitation learning (IL), reinforcement\nlearning (RL) could potentially discover superior strategies through\nexploration. We present the first comprehensive comparison of IL versus RL for\nsurgical action planning on CholecT50. Our Dual-task Autoregressive Imitation\nLearning (DARIL) baseline achieves 34.6% action triplet recognition mAP and\n33.6% next frame prediction mAP with smooth planning degradation to 29.2% at\n10-second horizons. We evaluated three RL variants: world model-based RL,\ndirect video RL, and inverse RL enhancement. Surprisingly, all RL approaches\nunderperformed DARIL i.e. world model RL dropped to 3.1% mAP at 10s while\ndirect video RL achieved only 15.9%. Our analysis reveals that distribution\nmatching on expert-annotated test sets systematically favors IL over\npotentially valid RL policies that differ from training demonstrations. This\nchallenges assumptions about RL superiority in sequential decision making and\nprovides crucial insights for surgical AI development.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u6a21\u4eff\u5b66\u4e60\uff08IL\uff09\u4e0e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u624b\u672f\u52a8\u4f5c\u89c4\u5212\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0IL\u4f18\u4e8eRL\u3002", "motivation": "\u63a2\u8ba8IL\u548cRL\u5728\u624b\u672f\u52a8\u4f5c\u89c4\u5212\u4e2d\u7684\u6548\u679c\uff0c\u6311\u6218RL\u5728\u5e8f\u5217\u51b3\u7b56\u4e2d\u7684\u4f18\u8d8a\u6027\u5047\u8bbe\u3002", "method": "\u63d0\u51fa\u4e86\u53cc\u4efb\u52a1\u81ea\u56de\u5f52\u6a21\u4eff\u5b66\u4e60\uff08DARIL\uff09\u57fa\u7ebf\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e09\u79cdRL\u53d8\u4f53\u3002", "result": "DARIL\u5728\u52a8\u4f5c\u4e09\u91cd\u8bc6\u522b\u548c\u4e0b\u4e00\u5e27\u9884\u6d4b\u4e2d\u8868\u73b0\u6700\u4f73\uff0cRL\u65b9\u6cd5\u5747\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cIL\u5728\u624b\u672fAI\u5f00\u53d1\u4e2d\u53ef\u80fd\u66f4\u5177\u4f18\u52bf\uff0c\u6311\u6218\u4e86RL\u7684\u666e\u904d\u5047\u8bbe\u3002"}}
{"id": "2507.05088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05088", "abs": "https://arxiv.org/abs/2507.05088", "authors": ["Kilian R\u00fcckschlo\u00df", "Felix Weitk\u00e4mper"], "title": "How Rules Represent Causal Knowledge: Causal Modeling with Abductive Logic Programs", "comment": null, "summary": "Pearl observes that causal knowledge enables predicting the effects of\ninterventions, such as actions, whereas descriptive knowledge only permits\ndrawing conclusions from observation. This paper extends Pearl's approach to\ncausality and interventions to the setting of stratified abductive logic\nprograms. It shows how stable models of such programs can be given a causal\ninterpretation by building on philosophical foundations and recent work by\nBochman and Eelink et al. In particular, it provides a translation of abductive\nlogic programs into causal systems, thereby clarifying the informal causal\nreading of logic program rules and supporting principled reasoning about\nexternal actions. The main result establishes that the stable model semantics\nfor stratified programs conforms to key philosophical principles of causation,\nsuch as causal sufficiency, natural necessity, and irrelevance of unobserved\neffects. This justifies the use of stratified abductive logic programs as a\nframework for causal modeling and for predicting the effects of interventions", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Pearl\u7684\u56e0\u679c\u7406\u8bba\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u5206\u5c42\u6eaf\u56e0\u903b\u8f91\u7a0b\u5e8f\uff0c\u8bc1\u660e\u4e86\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u7b26\u5408\u56e0\u679c\u5173\u7cfb\u7684\u54f2\u5b66\u539f\u5219\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5c06\u56e0\u679c\u77e5\u8bc6\u5e94\u7528\u4e8e\u5206\u5c42\u6eaf\u56e0\u903b\u8f91\u7a0b\u5e8f\uff0c\u4ee5\u652f\u6301\u5bf9\u5916\u90e8\u5e72\u9884\u7684\u9884\u6d4b\u3002", "method": "\u901a\u8fc7\u5c06\u6eaf\u56e0\u903b\u8f91\u7a0b\u5e8f\u8f6c\u5316\u4e3a\u56e0\u679c\u7cfb\u7edf\uff0c\u8d4b\u4e88\u903b\u8f91\u7a0b\u5e8f\u89c4\u5219\u660e\u786e\u7684\u56e0\u679c\u89e3\u91ca\u3002", "result": "\u7a33\u5b9a\u6a21\u578b\u8bed\u4e49\u7b26\u5408\u56e0\u679c\u5145\u5206\u6027\u3001\u81ea\u7136\u5fc5\u8981\u6027\u7b49\u54f2\u5b66\u539f\u5219\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u56e0\u679c\u5efa\u6a21\u6846\u67b6\u7684\u5408\u7406\u6027\u3002", "conclusion": "\u5206\u5c42\u6eaf\u56e0\u903b\u8f91\u7a0b\u5e8f\u53ef\u4f5c\u4e3a\u56e0\u679c\u5efa\u6a21\u7684\u6709\u6548\u5de5\u5177\uff0c\u652f\u6301\u5e72\u9884\u6548\u679c\u7684\u9884\u6d4b\u3002"}}
{"id": "2507.05110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05110", "abs": "https://arxiv.org/abs/2507.05110", "authors": ["Shixuan Liu", "Yue He", "Yunfei Wang", "Hao Zou", "Haoxiang Cheng", "Wenjing Yang", "Peng Cui", "Zhong Liu"], "title": "Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift", "comment": null, "summary": "Knowledge graph (KG) reasoning remains a critical research area focused on\ninferring missing knowledge by analyzing relationships among observed facts.\nDespite its success, a key limitation of existing KG reasoning methods is their\ndependence on the I.I.D assumption. This assumption can easily be violated due\nto unknown sample selection bias during training or agnostic distribution\nshifts during testing, significantly compromising model performance and\nreliability. To facilitate the deployment of KG reasoning in wild environments,\nthis study investigates learning logical rules from KGs affected by unknown\nselection bias. Additionally, we address test sets with agnostic distribution\nshifts, formally defining this challenge as out-of-distribution (OOD) KG\nreasoning-a previously underexplored problem. To solve the issue, we propose\nthe Stable Rule Learning (StableRule) framework, an end-to-end methodology that\nintegrates feature decorrelation with rule learning network, to enhance OOD\ngeneralization performance. By leveraging feature decorrelation, the StableRule\nframework mitigates the adverse effects of covariate shifts arising in OOD\nscenarios, thereby improving the robustness of the rule learning component in\neffectively deriving logical rules. Extensive experiments on seven benchmark\nKGs demonstrate the framework's superior effectiveness and stability across\ndiverse heterogeneous environments, underscoring its practical significance for\nreal-world applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStableRule\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u63a8\u7406\u4e2d\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u95ee\u9898\uff0c\u901a\u8fc7\u7279\u5f81\u89e3\u8026\u548c\u89c4\u5219\u5b66\u4e60\u7f51\u7edc\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709KG\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56I.I.D\u5047\u8bbe\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u56e0\u672a\u77e5\u9009\u62e9\u504f\u5dee\u6216\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faStableRule\u6846\u67b6\uff0c\u7ed3\u5408\u7279\u5f81\u89e3\u8026\u548c\u89c4\u5219\u5b66\u4e60\u7f51\u7edc\uff0c\u4ee5\u51cf\u8f7bOOD\u573a\u666f\u4e2d\u7684\u534f\u53d8\u91cf\u504f\u79fb\u5f71\u54cd\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6KG\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5f02\u6784\u73af\u5883\u4e2d\u5177\u6709\u4f18\u8d8a\u7684\u6709\u6548\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "StableRule\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86KG\u63a8\u7406\u5728OOD\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.05142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05142", "abs": "https://arxiv.org/abs/2507.05142", "authors": ["Wei Xu", "Haoran Li", "Baoyuan Ou", "Lai Xu", "Yingjie Qin", "Ruilong Su", "Ruiwen Xu"], "title": "GIST: Cross-Domain Click-Through Rate Prediction via Guided Content-Behavior Distillation", "comment": null, "summary": "Cross-domain Click-Through Rate prediction aims to tackle the data sparsity\nand the cold start problems in online advertising systems by transferring\nknowledge from source domains to a target domain. Most existing methods rely on\noverlapping users to facilitate this transfer, often focusing on joint training\nor pre-training with fine-tuning approach to connect the source and target\ndomains. However, in real-world industrial settings, joint training struggles\nto learn optimal representations with different distributions, and pre-training\nwith fine-tuning is not well-suited for continuously integrating new data. To\naddress these issues, we propose GIST, a cross-domain lifelong sequence model\nthat decouples the training processes of the source and target domains. Unlike\nprevious methods that search lifelong sequences in the source domains using\nonly content or behavior signals or their simple combinations, we innovatively\nintroduce a Content-Behavior Joint Training Module (CBJT), which aligns\ncontent-behavior distributions and combines them with guided information to\nfacilitate a more stable representation. Furthermore, we develop an Asymmetric\nSimilarity Integration strategy (ASI) to augment knowledge transfer through\nsimilarity computation. Extensive experiments demonstrate the effectiveness of\nGIST, surpassing SOTA methods on offline evaluations and an online A/B test.\nDeployed on the Xiaohongshu (RedNote) platform, GIST effectively enhances\nonline ads system performance at scale, serving hundreds of millions of daily\nactive users.", "AI": {"tldr": "\u63d0\u51faGIST\u6a21\u578b\uff0c\u901a\u8fc7\u89e3\u8026\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u7ed3\u5408\u5185\u5bb9-\u884c\u4e3a\u8054\u5408\u8bad\u7ec3\u6a21\u5757\uff08CBJT\uff09\u548c\u975e\u5bf9\u79f0\u76f8\u4f3c\u6027\u96c6\u6210\u7b56\u7565\uff08ASI\uff09\uff0c\u63d0\u5347\u8de8\u57df\u70b9\u51fb\u7387\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u8054\u5408\u8bad\u7ec3\u6216\u9884\u8bad\u7ec3\u5fae\u8c03\u4e2d\u56e0\u6570\u636e\u5206\u5e03\u4e0d\u540c\u6216\u65e0\u6cd5\u6301\u7eed\u6574\u5408\u65b0\u6570\u636e\u800c\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faGIST\u6a21\u578b\uff0c\u5305\u62ecCBJT\u6a21\u5757\u5bf9\u9f50\u5185\u5bb9-\u884c\u4e3a\u5206\u5e03\uff0c\u4ee5\u53caASI\u7b56\u7565\u589e\u5f3a\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728Xiaohongshu\u5e73\u53f0\u6210\u529f\u90e8\u7f72\u3002", "conclusion": "GIST\u901a\u8fc7\u521b\u65b0\u6a21\u5757\u548c\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u8de8\u57df\u70b9\u51fb\u7387\u9884\u6d4b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5de5\u4e1a\u573a\u666f\u3002"}}
{"id": "2507.05201", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05201", "abs": "https://arxiv.org/abs/2507.05201", "authors": ["Andrew Sellergren", "Sahar Kazemzadeh", "Tiam Jaroensri", "Atilla Kiraly", "Madeleine Traverse", "Timo Kohlberger", "Shawn Xu", "Fayaz Jamil", "C\u00edan Hughes", "Charles Lau", "Justin Chen", "Fereshteh Mahvar", "Liron Yatziv", "Tiffany Chen", "Bram Sterling", "Stefanie Anna Baby", "Susanna Maria Baby", "Jeremy Lai", "Samuel Schmidgall", "Lu Yang", "Kejia Chen", "Per Bjornsson", "Shashir Reddy", "Ryan Brush", "Kenneth Philbrick", "Howard Hu", "Howard Yang", "Richa Tiwari", "Sunny Jansen", "Preeti Singh", "Yun Liu", "Shekoofeh Azizi", "Aishwarya Kamath", "Johan Ferret", "Shreya Pathak", "Nino Vieillard", "Ramona Merhej", "Sarah Perrin", "Tatiana Matejovicova", "Alexandre Ram\u00e9", "Morgane Riviere", "Louis Rouillard", "Thomas Mesnard", "Geoffrey Cideron", "Jean-bastien Grill", "Sabela Ramos", "Edouard Yvinec", "Michelle Casbon", "Elena Buchatskaya", "Jean-Baptiste Alayrac", "Dmitry", "Lepikhin", "Vlad Feinberg", "Sebastian Borgeaud", "Alek Andreev", "Cassidy Hardin", "Robert Dadashi", "L\u00e9onard Hussenot", "Armand Joulin", "Olivier Bachem", "Yossi Matias", "Katherine Chou", "Avinatan Hassidim", "Kavi Goel", "Clement Farabet", "Joelle Barral", "Tris Warkentin", "Jonathon Shlens", "David Fleet", "Victor Cotruta", "Omar Sanseviero", "Gus Martins", "Phoebe Kirk", "Anand Rao", "Shravya Shetty", "David F. Steiner", "Can Kirmizibayrak", "Rory Pilgrim", "Daniel Golden", "Lin Yang"], "title": "MedGemma Technical Report", "comment": null, "summary": "Artificial intelligence (AI) has significant potential in healthcare\napplications, but its training and deployment faces challenges due to\nhealthcare's diverse data, complex tasks, and the need to preserve privacy.\nFoundation models that perform well on medical tasks and require less\ntask-specific tuning data are critical to accelerate the development of\nhealthcare AI applications. We introduce MedGemma, a collection of medical\nvision-language foundation models based on Gemma 3 4B and 27B. MedGemma\ndemonstrates advanced medical understanding and reasoning on images and text,\nsignificantly exceeding the performance of similar-sized generative models and\napproaching the performance of task-specific models, while maintaining the\ngeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,\nMedGemma achieves 2.6-10% improvement on medical multimodal question answering,\n15.5-18.1% improvement on chest X-ray finding classification, and 10.8%\nimprovement on agentic evaluations compared to the base models. Fine-tuning\nMedGemma further improves performance in subdomains, reducing errors in\nelectronic health record information retrieval by 50% and reaching comparable\nperformance to existing specialized state-of-the-art methods for pneumothorax\nclassification and histopathology patch classification. We additionally\nintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.\nMedSigLIP powers the visual understanding capabilities of MedGemma and as an\nencoder achieves comparable or better performance than specialized medical\nimage encoders. Taken together, the MedGemma collection provides a strong\nfoundation of medical image and text capabilities, with potential to\nsignificantly accelerate medical research and development of downstream\napplications. The MedGemma collection, including tutorials and model weights,\ncan be found at https://goo.gle/medgemma.", "AI": {"tldr": "MedGemma\u662f\u4e00\u7ec4\u57fa\u4e8eGemma 3\u7684\u533b\u7597\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\u6a21\u578b\uff0c\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8d8a\u540c\u7c7b\u751f\u6210\u6a21\u578b\uff0c\u5e76\u63a5\u8fd1\u4efb\u52a1\u4e13\u7528\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u533b\u7597AI\u7684\u53d1\u5c55\u9762\u4e34\u6570\u636e\u591a\u6837\u6027\u3001\u4efb\u52a1\u590d\u6742\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7b49\u6311\u6218\uff0c\u9700\u8981\u6027\u80fd\u4f18\u5f02\u4e14\u65e0\u9700\u5927\u91cf\u4efb\u52a1\u7279\u5b9a\u8c03\u4f18\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\u3002", "method": "\u57fa\u4e8eGemma 3 4B\u548c27B\u6784\u5efaMedGemma\uff0c\u5e76\u5f15\u5165MedSigLIP\u4f5c\u4e3a\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u63d0\u5347\u533b\u7597\u56fe\u50cf\u548c\u6587\u672c\u7684\u7406\u89e3\u80fd\u529b\u3002", "result": "MedGemma\u5728\u533b\u7597\u591a\u6a21\u6001\u95ee\u7b54\u3001\u80f8\u90e8X\u5149\u5206\u7c7b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\uff0c\u5fae\u8c03\u540e\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5b50\u9886\u57df\u6027\u80fd\u3002", "conclusion": "MedGemma\u4e3a\u533b\u7597\u7814\u7a76\u548c\u4e0b\u6e38\u5e94\u7528\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u57fa\u7840\u80fd\u529b\uff0c\u6709\u671b\u52a0\u901f\u533b\u7597AI\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.05241", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05241", "abs": "https://arxiv.org/abs/2507.05241", "authors": ["Jingyi Chai", "Shuo Tang", "Rui Ye", "Yuwen Du", "Xinyu Zhu", "Mengcheng Zhou", "Yanfeng Wang", "Weinan E", "Siheng Chen"], "title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?", "comment": "12 pages, 7 figures", "summary": "The rapid advancements of AI agents have ignited the long-held ambition of\nleveraging them to accelerate scientific discovery. Achieving this goal\nrequires a deep understanding of the frontiers of human knowledge. As such,\nHumanity's Last Exam (HLE) provides an exceptionally challenging touchstone for\nevaluating scientific AI agents. In this work, we aim to construct the\nfoundational architecture for general-purpose agents and validate the\ncapabilities through leading performance on HLE. To achieve this, we introduce\nX-Master, a tool-augmented reasoning agent designed to emulate human\nresearchers by interacting flexibly with external tools during its reasoning\nprocess. This agent, guided by the conceptualization of code as an interaction\nlanguage, can flexibly leverage built-in Python libraries and our customized\ntools to augment the reasoning. We further scale its capabilities through\nX-Masters, a scattered-and-stacked agentic workflow that systematically\nenhances breadth and depth of reasoning. Our open-source solution, X-Masters,\nsets a new state-of-the-art record on HLE with a score of 32.1%, surpassing\nOpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to\nexceed the 30% threshold. This work allows us to gain a deeper understanding of\ncomplex task-solving and accumulates valuable experience that can inform future\nadvancements, guiding subsequent model training.", "AI": {"tldr": "X-Master\u662f\u4e00\u4e2a\u5de5\u5177\u589e\u5f3a\u7684\u63a8\u7406\u4ee3\u7406\uff0c\u901a\u8fc7\u7075\u6d3b\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u6a21\u62df\u4eba\u7c7b\u7814\u7a76\u8005\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728HLE\u4e0a\u53d6\u5f97\u4e8632.1%\u7684\u9886\u5148\u6210\u7ee9\u3002", "motivation": "\u5229\u7528AI\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u524d\u6cbf\u77e5\u8bc6\u4e2d\u7684\u8868\u73b0\uff0cHLE\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6311\u6218\u6027\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51faX-Master\u4ee3\u7406\uff0c\u7ed3\u5408\u4ee3\u7801\u4f5c\u4e3a\u4ea4\u4e92\u8bed\u8a00\uff0c\u4f7f\u7528Python\u5e93\u548c\u5b9a\u5236\u5de5\u5177\u589e\u5f3a\u63a8\u7406\uff0c\u5e76\u901a\u8fc7X-Masters\u5de5\u4f5c\u6d41\u6269\u5c55\u80fd\u529b\u3002", "result": "X-Masters\u5728HLE\u4e0a\u4ee532.1%\u7684\u6210\u7ee9\u521b\u4e0b\u65b0\u7eaa\u5f55\uff0c\u8d85\u8d8aOpenAI\u548cGoogle\u768426.6%\u548c26.9%\u3002", "conclusion": "X-Master\u4e3a\u590d\u6742\u4efb\u52a1\u89e3\u51b3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5e76\u4e3a\u672a\u6765\u6a21\u578b\u8bad\u7ec3\u79ef\u7d2f\u4e86\u7ecf\u9a8c\u3002"}}
{"id": "2507.05244", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.05244", "abs": "https://arxiv.org/abs/2507.05244", "authors": ["Benjamin Li", "Shuyang Shi", "Lucia Romero", "Huao Li", "Yaqi Xie", "Woojun Kim", "Stefanos Nikolaidis", "Michael Lewis", "Katia Sycara", "Simon Stepputtis"], "title": "Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent Collaboration", "comment": "Best Paper Award at the RSS 2025 Generative Models x HRI (GenAI-HRI)\n  Workshop", "summary": "In collaborative tasks, being able to adapt to your teammates is a necessary\nrequirement for success. When teammates are heterogeneous, such as in\nhuman-agent teams, agents need to be able to observe, recognize, and adapt to\ntheir human partners in real time. This becomes particularly challenging in\ntasks with time pressure and complex strategic spaces where the dynamics can\nchange rapidly. In this work, we introduce TALENTS, a strategy-conditioned\ncooperator framework that learns to represent, categorize, and adapt to a range\nof partner strategies, enabling ad-hoc teamwork. Our approach utilizes a\nvariational autoencoder to learn a latent strategy space from trajectory data.\nThis latent space represents the underlying strategies that agents employ.\nSubsequently, the system identifies different types of strategy by clustering\nthe data. Finally, a cooperator agent is trained to generate partners for each\ntype of strategy, conditioned on these clusters. In order to adapt to\npreviously unseen partners, we leverage a fixed-share regret minimization\nalgorithm that infers and adjusts the estimated partner strategy dynamically.\nWe assess our approach in a customized version of the Overcooked environment,\nposing a challenging cooperative cooking task that demands strong coordination\nacross a wide range of possible strategies. Using an online user study, we show\nthat our agent outperforms current baselines when working with unfamiliar human\npartners.", "AI": {"tldr": "TALENTS\u6846\u67b6\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u7b56\u7565\u7a7a\u95f4\uff0c\u52a8\u6001\u9002\u5e94\u5f02\u6784\u961f\u53cb\uff0c\u5728Overcooked\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5f02\u6784\u56e2\u961f\uff08\u5982\u4eba\u673a\u534f\u4f5c\uff09\u9700\u5b9e\u65f6\u9002\u5e94\u961f\u53cb\u7b56\u7565\uff0c\u5c24\u5176\u5728\u65f6\u95f4\u538b\u529b\u548c\u590d\u6742\u52a8\u6001\u4efb\u52a1\u4e2d\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u7b56\u7565\u8868\u793a\uff0c\u805a\u7c7b\u7b56\u7565\u7c7b\u578b\uff0c\u8bad\u7ec3\u6761\u4ef6\u5408\u4f5c\u8005\uff0c\u5e76\u52a8\u6001\u8c03\u6574\u7b56\u7565\u3002", "result": "\u5728Overcooked\u4efb\u52a1\u4e2d\uff0cTALENTS\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u9002\u5e94\u964c\u751f\u4eba\u7c7b\u961f\u53cb\u3002", "conclusion": "TALENTS\u6846\u67b6\u6709\u6548\u652f\u6301\u5f02\u6784\u56e2\u961f\u7684\u5b9e\u65f6\u7b56\u7565\u9002\u5e94\uff0c\u63d0\u5347\u534f\u4f5c\u8868\u73b0\u3002"}}
{"id": "2507.05246", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05246", "abs": "https://arxiv.org/abs/2507.05246", "authors": ["Scott Emmons", "Erik Jenner", "David K. Elson", "Rif A. Saurous", "Senthooran Rajamanoharan", "Heng Chen", "Irhum Shafkat", "Rohin Shah"], "title": "When Chain of Thought is Necessary, Language Models Struggle to Evade Monitors", "comment": null, "summary": "While chain-of-thought (CoT) monitoring is an appealing AI safety defense,\nrecent work on \"unfaithfulness\" has cast doubt on its reliability. These\nfindings highlight an important failure mode, particularly when CoT acts as a\npost-hoc rationalization in applications like auditing for bias. However, for\nthe distinct problem of runtime monitoring to prevent severe harm, we argue the\nkey property is not faithfulness but monitorability. To this end, we introduce\na conceptual framework distinguishing CoT-as-rationalization from\nCoT-as-computation. We expect that certain classes of severe harm will require\ncomplex, multi-step reasoning that necessitates CoT-as-computation. Replicating\nthe experimental setups of prior work, we increase the difficulty of the bad\nbehavior to enforce this necessity condition; this forces the model to expose\nits reasoning, making it monitorable. We then present methodology guidelines to\nstress-test CoT monitoring against deliberate evasion. Applying these\nguidelines, we find that models can learn to obscure their intentions, but only\nwhen given significant help, such as detailed human-written strategies or\niterative optimization against the monitor. We conclude that, while not\ninfallible, CoT monitoring offers a substantial layer of defense that requires\nactive protection and continued stress-testing.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u76d1\u63a7\u5728AI\u5b89\u5168\u9632\u5fa1\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u533a\u5206CoT\u4f5c\u4e3a\u5408\u7406\u5316\u4e0eCoT\u4f5c\u4e3a\u8ba1\u7b97\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u76d1\u63a7\u6027\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5c3d\u7ba1CoT\u76d1\u63a7\u662f\u4e00\u79cd\u6709\u5438\u5f15\u529b\u7684AI\u5b89\u5168\u9632\u5fa1\u624b\u6bb5\uff0c\u4f46\u8fd1\u671f\u5173\u4e8e\u5176\u2018\u4e0d\u5fe0\u5b9e\u6027\u2019\u7684\u7814\u7a76\u5bf9\u5176\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u8d28\u7591\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9632\u6b62\u4e25\u91cd\u5371\u5bb3\u7684\u8fd0\u884c\u65f6\u76d1\u63a7\u573a\u666f\u4e2d\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u533a\u5206CoT-as-rationalization\u548cCoT-as-computation\u7684\u6846\u67b6\uff0c\u5e76\u589e\u52a0\u5b9e\u9a8c\u96be\u5ea6\u4ee5\u5f3a\u5236\u6a21\u578b\u66b4\u9732\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u65b9\u6cd5\u8bba\u6307\u5357\u6765\u6d4b\u8bd5CoT\u76d1\u63a7\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6a21\u578b\u53ef\u4ee5\u5b66\u4f1a\u9690\u85cf\u5176\u610f\u56fe\uff0c\u4f46\u9700\u8981\u5927\u91cf\u5e2e\u52a9\uff08\u5982\u8be6\u7ec6\u7684\u4eba\u7c7b\u7b56\u7565\u6216\u9488\u5bf9\u76d1\u63a7\u7684\u8fed\u4ee3\u4f18\u5316\uff09\u3002", "conclusion": "\u5c3d\u7ba1CoT\u76d1\u63a7\u5e76\u975e\u5b8c\u7f8e\u65e0\u7f3a\uff0c\u4f46\u5b83\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u9632\u5fa1\u5c42\uff0c\u9700\u8981\u6301\u7eed\u7684\u4fdd\u62a4\u548c\u538b\u529b\u6d4b\u8bd5\u3002"}}
