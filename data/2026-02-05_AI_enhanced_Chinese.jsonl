{"id": "2602.03965", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.03965", "abs": "https://arxiv.org/abs/2602.03965", "authors": ["Taveesh Sharma", "Andrew Chu", "Paul Schmitt", "Francesco Bronzino", "Nick Feamster", "Nicole Marwell"], "title": "Less is More: Optimizing Probe Selection Using Shared Latency Anomalies", "comment": null, "summary": "Latency anomalies, defined as persistent or transient increases in round-trip time (RTT), are common in residential Internet performance. When multiple users observe anomalies to the same destination, this may reflect shared infrastructure, routing behavior, or congestion. Inferring such shared behavior is challenging because anomaly magnitudes vary widely across devices, even within the same ISP and geographic area, and detailed network topology information is often unavailable.\n  We study whether devices experiencing a shared latency anomaly observe similar changes in RTT magnitude using a topology-agnostic approach. Using four months of high-frequency RTT measurements from 99 residential probes in Chicago, we detect shared anomalies and analyze their consistency in amplitude and duration without relying on traceroutes or explicit path information. Building on prior change-point detection techniques, we find that many shared anomalies exhibit similar amplitude across users, particularly within the same ISP.\n  Motivated by this observation, we design a sampling algorithm that reduces redundancy by selecting representative devices under user-defined constraints. Our approach captures 95 percent of aggregate anomaly impact using fewer than half of the deployed probes. Compared to two baselines, it identifies significantly more unique anomalies at comparable coverage levels. We further show that geographic diversity remains important when selecting probes within a single ISP, even at city scale. Overall, our results demonstrate that anomaly amplitude and duration provide effective topology-independent signals for scalable monitoring, troubleshooting, and cost-efficient sampling in residential Internet measurement.", "AI": {"tldr": "\u901a\u8fc7\u62d3\u6251\u65e0\u5173\u65b9\u6cd5\u5206\u6790\u4f4f\u5b85\u7f51\u7edc\u5ef6\u8fdf\u5f02\u5e38\uff0c\u53d1\u73b0\u540c\u4e00ISP\u5185\u7528\u6237\u5171\u4eab\u5f02\u5e38\u5177\u6709\u76f8\u4f3c\u5e45\u5ea6\uff0c\u63d0\u51fa\u91c7\u6837\u7b97\u6cd5\u7528\u66f4\u5c11\u63a2\u9488\u6355\u83b795%\u5f02\u5e38\u5f71\u54cd\uff0c\u8bc1\u660e\u5f02\u5e38\u5e45\u5ea6\u548c\u65f6\u957f\u53ef\u4f5c\u4e3a\u53ef\u6269\u5c55\u76d1\u63a7\u7684\u6709\u6548\u4fe1\u53f7\u3002", "motivation": "\u4f4f\u5b85\u4e92\u8054\u7f51\u4e2d\u5ef6\u8fdf\u5f02\u5e38\u5e38\u89c1\uff0c\u591a\u4e2a\u7528\u6237\u5bf9\u540c\u4e00\u76ee\u7684\u5730\u7684\u5f02\u5e38\u53ef\u80fd\u53cd\u6620\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u3001\u8def\u7531\u884c\u4e3a\u6216\u62e5\u585e\u3002\u63a8\u65ad\u8fd9\u79cd\u5171\u4eab\u884c\u4e3a\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5f02\u5e38\u5e45\u5ea6\u5728\u4e0d\u540c\u8bbe\u5907\u95f4\u5dee\u5f02\u5f88\u5927\uff0c\u4e14\u8be6\u7ec6\u7f51\u7edc\u62d3\u6251\u4fe1\u606f\u901a\u5e38\u4e0d\u53ef\u7528\u3002", "method": "\u91c7\u7528\u62d3\u6251\u65e0\u5173\u65b9\u6cd5\uff0c\u4f7f\u7528\u829d\u52a0\u54e599\u4e2a\u4f4f\u5b85\u63a2\u9488\u56db\u4e2a\u6708\u7684\u9ad8\u9891RTT\u6d4b\u91cf\u6570\u636e\uff0c\u68c0\u6d4b\u5171\u4eab\u5f02\u5e38\u5e76\u5206\u6790\u5176\u5e45\u5ea6\u548c\u65f6\u957f\u4e00\u81f4\u6027\uff0c\u4e0d\u4f9d\u8d56traceroute\u6216\u663e\u5f0f\u8def\u5f84\u4fe1\u606f\u3002\u57fa\u4e8e\u53d8\u5316\u70b9\u68c0\u6d4b\u6280\u672f\uff0c\u8bbe\u8ba1\u91c7\u6837\u7b97\u6cd5\u5728\u7528\u6237\u5b9a\u4e49\u7ea6\u675f\u4e0b\u9009\u62e9\u4ee3\u8868\u6027\u8bbe\u5907\u3002", "result": "\u53d1\u73b0\u8bb8\u591a\u5171\u4eab\u5f02\u5e38\u5728\u7528\u6237\u95f4\u8868\u73b0\u51fa\u76f8\u4f3c\u5e45\u5ea6\uff0c\u7279\u522b\u662f\u5728\u540c\u4e00ISP\u5185\u3002\u91c7\u6837\u7b97\u6cd5\u4f7f\u7528\u4e0d\u5230\u4e00\u534a\u7684\u90e8\u7f72\u63a2\u9488\u5373\u53ef\u6355\u83b795%\u7684\u805a\u5408\u5f02\u5e38\u5f71\u54cd\uff0c\u76f8\u6bd4\u4e24\u4e2a\u57fa\u7ebf\uff0c\u5728\u76f8\u4f3c\u8986\u76d6\u6c34\u5e73\u4e0b\u8bc6\u522b\u51fa\u663e\u8457\u66f4\u591a\u72ec\u7279\u5f02\u5e38\u3002\u5373\u4f7f\u5728\u57ce\u5e02\u89c4\u6a21\u4e0b\uff0c\u5355ISP\u5185\u9009\u62e9\u63a2\u9488\u65f6\u5730\u7406\u591a\u6837\u6027\u4ecd\u7136\u91cd\u8981\u3002", "conclusion": "\u5f02\u5e38\u5e45\u5ea6\u548c\u65f6\u957f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u62d3\u6251\u72ec\u7acb\u4fe1\u53f7\uff0c\u53ef\u7528\u4e8e\u4f4f\u5b85\u4e92\u8054\u7f51\u6d4b\u91cf\u4e2d\u7684\u53ef\u6269\u5c55\u76d1\u63a7\u3001\u6545\u969c\u6392\u9664\u548c\u6210\u672c\u6548\u76ca\u91c7\u6837\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u8be6\u7ec6\u62d3\u6251\u4fe1\u606f\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.04258", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.04258", "abs": "https://arxiv.org/abs/2602.04258", "authors": ["Yufei Ye", "Shijian Gao", "Xinhu Zheng", "Liuqing Yang"], "title": "Multi-Tier UAV Edge Computing Towards Long-Term Energy Stability for Low Altitude Networks", "comment": null, "summary": "The agile mobility of Unmanned Aerial Vehicles (UAVs) makes them ideal for low-altitude edge computing. This paper proposes a novel multi-tier UAV edge computing system where lightweight Low-Tier UAVs (L-UAVs) function as edge servers for vehicle users, supported by a powerful High-Tier UAV (H-UAV) acting as a backup server. The objective is to minimize task execution delays while ensuring the long-term energy stability of the L-UAVs, despite unknown future system states. To this end, the problem is decoupled using Lyapunov optimization, which adaptively balances the priorities of task delays and L-UAV energy cost based on their real-time energy states. An efficient vehicle to L-UAV matching scheme is designed, and the joint optimization problem for task assignment, computing resource allocation, and trajectory control of L-UAVs and H-UAV is then solved via a Block Coordinate Descent (BCD) algorithm. Simulation results demonstrate a reduction in L-UAV transmission energy of over 26% and superior L-UAV energy stability compared to existing benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u5c42\u65e0\u4eba\u673a\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\uff0c\u8f7b\u578b\u4f4e\u5c42\u65e0\u4eba\u673a\u4f5c\u4e3a\u8f66\u8f86\u7528\u6237\u7684\u8fb9\u7f18\u670d\u52a1\u5668\uff0c\u9ad8\u5c42\u65e0\u4eba\u673a\u4f5c\u4e3a\u5907\u4efd\u670d\u52a1\u5668\uff0c\u901a\u8fc7Lyapunov\u4f18\u5316\u548cBCD\u7b97\u6cd5\u6700\u5c0f\u5316\u4efb\u52a1\u5ef6\u8fdf\u5e76\u786e\u4fdd\u65e0\u4eba\u673a\u80fd\u91cf\u7a33\u5b9a\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u5177\u6709\u654f\u6377\u79fb\u52a8\u6027\uff0c\u9002\u5408\u4f4e\u7a7a\u8fb9\u7f18\u8ba1\u7b97\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u65e0\u4eba\u673a\u80fd\u91cf\u7a33\u5b9a\u6027\u7684\u957f\u671f\u8003\u8651\uff0c\u4e14\u9762\u4e34\u672a\u6765\u7cfb\u7edf\u72b6\u6001\u672a\u77e5\u7684\u6311\u6218\u3002", "method": "1) \u63d0\u51fa\u591a\u5c42\u65e0\u4eba\u673a\u8fb9\u7f18\u8ba1\u7b97\u67b6\u6784\uff1aL-UAVs\u4f5c\u4e3a\u8fb9\u7f18\u670d\u52a1\u5668\uff0cH-UAV\u4f5c\u4e3a\u5907\u4efd\u670d\u52a1\u5668\uff1b2) \u4f7f\u7528Lyapunov\u4f18\u5316\u5c06\u95ee\u9898\u89e3\u8026\uff0c\u5e73\u8861\u4efb\u52a1\u5ef6\u8fdf\u548c\u80fd\u91cf\u6210\u672c\uff1b3) \u8bbe\u8ba1\u8f66\u8f86\u5230L-UAV\u5339\u914d\u65b9\u6848\uff1b4) \u901a\u8fc7BCD\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u4efb\u52a1\u5206\u914d\u3001\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u548c\u65e0\u4eba\u673a\u8f68\u8ff9\u63a7\u5236\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff1aL-UAV\u4f20\u8f93\u80fd\u91cf\u964d\u4f4e\u8d85\u8fc726%\uff0c\u4e14\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\uff0cL-UAV\u80fd\u91cf\u7a33\u5b9a\u6027\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u5c42\u65e0\u4eba\u673a\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u80fd\u6709\u6548\u51cf\u5c11\u4efb\u52a1\u6267\u884c\u5ef6\u8fdf\uff0c\u540c\u65f6\u786e\u4fdd\u65e0\u4eba\u673a\u957f\u671f\u80fd\u91cf\u7a33\u5b9a\u6027\uff0c\u4e3a\u672a\u77e5\u672a\u6765\u7cfb\u7edf\u72b6\u6001\u4e0b\u7684\u8fb9\u7f18\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04471", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04471", "abs": "https://arxiv.org/abs/2602.04471", "authors": ["Bowen Tan", "Qiong Wu", "Pingyi Fan", "Kezhi Wang", "Nan Cheng", "Wen Chen"], "title": "LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks", "comment": "Corresponding author: Qiong Wu (qiongwu@jiangnan.edu.cn)", "summary": "This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server (CS) to minimize content retrieval latency. To efficiently manage distributed storage, we integrate large language models (LLMs) for real-time and intelligent caching decisions. The proposed approach leverages LLMs' ability to process heterogeneous information, including user profiles, historical data, content characteristics, and dynamic system states. Through a designed prompting framework encoding task objectives and caching constraints, the LLMs formulate caching as a decision-making task, and our hierarchical deterministic caching mapping strategy enables adaptive requests prediction and precise content placement across three tiers without frequent retraining. Simulation results demonstrate the advantages of our proposed caching scheme.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u4e09\u5c42\u5185\u5bb9\u7f13\u5b58\u67b6\u6784\uff0c\u7528\u4e8e\u8f66\u8054\u7f51\u96fe\u7f13\u5b58\u8f85\u52a9\u7684\u7f16\u961f\u884c\u9a76\uff0c\u901a\u8fc7LLM\u667a\u80fd\u51b3\u7b56\u6700\u5c0f\u5316\u5185\u5bb9\u68c0\u7d22\u5ef6\u8fdf", "motivation": "\u8f66\u8054\u7f51\u7f16\u961f\u884c\u9a76\u4e2d\u9700\u8981\u9ad8\u6548\u7684\u5185\u5bb9\u7f13\u5b58\u673a\u5236\u6765\u51cf\u5c11\u5185\u5bb9\u68c0\u7d22\u5ef6\u8fdf\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5f02\u6784\u4fe1\u606f\u548c\u52a8\u6001\u7cfb\u7edf\u72b6\u6001", "method": "\u8bbe\u8ba1\u4e09\u5c42\u7f13\u5b58\u67b6\u6784\uff08\u672c\u5730\u8f66\u8f86\u3001\u52a8\u6001VFC\u96c6\u7fa4\u3001\u4e91\u670d\u52a1\u5668\uff09\uff0c\u96c6\u6210LLM\u8fdb\u884c\u5b9e\u65f6\u667a\u80fd\u7f13\u5b58\u51b3\u7b56\uff0c\u4f7f\u7528\u63d0\u793a\u6846\u67b6\u7f16\u7801\u4efb\u52a1\u76ee\u6807\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u91c7\u7528\u5206\u5c42\u786e\u5b9a\u6027\u7f13\u5b58\u6620\u5c04\u7b56\u7565", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u7f13\u5b58\u65b9\u6848\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u591f\u5b9e\u73b0\u81ea\u9002\u5e94\u8bf7\u6c42\u9884\u6d4b\u548c\u7cbe\u786e\u7684\u5185\u5bb9\u653e\u7f6e\uff0c\u65e0\u9700\u9891\u7e41\u91cd\u65b0\u8bad\u7ec3", "conclusion": "LLM\u9a71\u52a8\u7684\u4e09\u5c42\u7f13\u5b58\u67b6\u6784\u80fd\u6709\u6548\u7ba1\u7406\u8f66\u8054\u7f51\u7f16\u961f\u4e2d\u7684\u5206\u5e03\u5f0f\u5b58\u50a8\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5bb9\u68c0\u7d22\u5ef6\u8fdf"}}
{"id": "2602.04566", "categories": ["cs.NI", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04566", "abs": "https://arxiv.org/abs/2602.04566", "authors": ["Hrishikesh Dutta", "Roberto Minerva", "Noel Crespi"], "title": "Dual Mind World Model Inspired Network Digital Twin for Access Scheduling", "comment": null, "summary": "Emerging networked systems such as industrial IoT and real-time cyber-physical infrastructures demand intelligent scheduling strategies capable of adapting to dynamic traffic, deadlines, and interference constraints. In this work, we present a novel Digital Twin-enabled scheduling framework inspired by Dual Mind World Model (DMWM) architecture, for learning-informed and imagination-driven network control. Unlike conventional rule-based or purely data-driven policies, the proposed DMWM combines short-horizon predictive planning with symbolic model-based rollout, enabling the scheduler to anticipate future network states and adjust transmission decisions accordingly. We implement the framework in a configurable simulation testbed and benchmark its performance against traditional heuristics and reinforcement learning baselines under varied traffic conditions. Our results show that DMWM achieves superior performance in bursty, interference-limited, and deadline-sensitive environments, while maintaining interpretability and sample efficiency. The proposed design bridges the gap between network-level reasoning and low-overhead learning, marking a step toward scalable and adaptive NDT-based network optimization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u548c\u53cc\u5fc3\u667a\u4e16\u754c\u6a21\u578b\uff08DMWM\uff09\u7684\u667a\u80fd\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u81ea\u9002\u5e94\u8c03\u5ea6\uff0c\u7ed3\u5408\u77ed\u671f\u9884\u6d4b\u89c4\u5212\u548c\u7b26\u53f7\u6a21\u578b\u63a8\u6f14\uff0c\u5728\u7a81\u53d1\u6d41\u91cf\u3001\u5e72\u6270\u53d7\u9650\u548c\u622a\u6b62\u65f6\u95f4\u654f\u611f\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u548c\u5b9e\u65f6\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u9700\u8981\u80fd\u591f\u9002\u5e94\u52a8\u6001\u6d41\u91cf\u3001\u622a\u6b62\u65f6\u95f4\u548c\u5e72\u6270\u7ea6\u675f\u7684\u667a\u80fd\u8c03\u5ea6\u7b56\u7565\u3002\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u6216\u7eaf\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u590d\u6742\u9700\u6c42\uff0c\u9700\u8981\u7ed3\u5408\u6a21\u578b\u63a8\u7406\u548c\u5b66\u4e60\u7684\u65b0\u578b\u8c03\u5ea6\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u6570\u5b57\u5b6a\u751f\u542f\u53d1\u7684\u53cc\u5fc3\u667a\u4e16\u754c\u6a21\u578b\uff08DMWM\uff09\u8c03\u5ea6\u6846\u67b6\uff0c\u7ed3\u5408\u77ed\u671f\u9884\u6d4b\u89c4\u5212\u548c\u7b26\u53f7\u6a21\u578b\u63a8\u6f14\u3002\u8be5\u6846\u67b6\u80fd\u591f\u9884\u6d4b\u672a\u6765\u7f51\u7edc\u72b6\u6001\u5e76\u76f8\u5e94\u8c03\u6574\u4f20\u8f93\u51b3\u7b56\uff0c\u5b9e\u73b0\u5b66\u4e60\u5f15\u5bfc\u548c\u60f3\u8c61\u529b\u9a71\u52a8\u7684\u7f51\u7edc\u63a7\u5236\u3002", "result": "\u5728\u53ef\u914d\u7f6e\u4eff\u771f\u6d4b\u8bd5\u5e73\u53f0\u4e2d\u5b9e\u73b0\u6846\u67b6\uff0c\u4e0e\u4f20\u7edf\u542f\u53d1\u5f0f\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\u3002\u7ed3\u679c\u663e\u793aDMWM\u5728\u7a81\u53d1\u6d41\u91cf\u3001\u5e72\u6270\u53d7\u9650\u548c\u622a\u6b62\u65f6\u95f4\u654f\u611f\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "conclusion": "DMWM\u6846\u67b6\u5f25\u5408\u4e86\u7f51\u7edc\u7ea7\u63a8\u7406\u4e0e\u4f4e\u5f00\u9500\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u53ef\u6269\u5c55\u81ea\u9002\u5e94\u7f51\u7edc\u4f18\u5316\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5728\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.03949", "categories": ["cs.IT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03949", "abs": "https://arxiv.org/abs/2602.03949", "authors": ["Emrah Akyol"], "title": "Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference", "comment": "submitted for publication", "summary": "We study strategic Gaussian semantic compression under rate and compute constraints, where an encoder and decoder optimize distinct quadratic objectives. A latent Gaussian state generates a task dependent semantic variable, and the decoder best responds via MMSE estimation, reducing the encoder's problem to posterior covariance design under an information rate constraint. We characterize the strategic rate distortion function in direct, remote, and full information regimes, derive semantic waterfilling and rate constrained Gaussian persuasion solutions, and establish Gaussian optimality under misaligned objectives. We further show that architectural compute limits act as implicit rate constraints, yielding exponential improvements in semantic accuracy with model depth and inference time compute, while multimodal observation eliminates the geometric mean penalty inherent to remote encoding. These results provide information theoretic foundations for data and energy efficient AI and offer a principled interpretation of modern multimodal language models as posterior design mechanisms under resource constraints.", "AI": {"tldr": "\u7814\u7a76\u6218\u7565\u9ad8\u65af\u8bed\u4e49\u538b\u7f29\uff1a\u5728\u901f\u7387\u548c\u8ba1\u7b97\u7ea6\u675f\u4e0b\uff0c\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4f18\u5316\u4e0d\u540c\u4e8c\u6b21\u76ee\u6807\uff0c\u5206\u6790\u6218\u7565\u7387\u5931\u771f\u51fd\u6570\uff0c\u63a8\u5bfc\u8bed\u4e49\u6ce8\u6c34\u7b97\u6cd5\uff0c\u8bc1\u660e\u9ad8\u65af\u6700\u4f18\u6027\uff0c\u5e76\u5efa\u7acb\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u540e\u9a8c\u8bbe\u8ba1\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u4e3a\u6570\u636e\u9ad8\u6548\u548c\u80fd\u91cf\u9ad8\u6548\u7684AI\u63d0\u4f9b\u4fe1\u606f\u7406\u8bba\u57fa\u7840\uff0c\u89e3\u91ca\u73b0\u4ee3\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u4f5c\u4e3a\u540e\u9a8c\u8bbe\u8ba1\u673a\u5236\u7684\u539f\u7406\uff0c\u89e3\u51b3\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u76ee\u6807\u4e0d\u4e00\u81f4\u65f6\u7684\u6218\u7565\u538b\u7f29\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6218\u7565\u9ad8\u65af\u8bed\u4e49\u538b\u7f29\u6846\u67b6\uff0c\u7f16\u7801\u5668\u8bbe\u8ba1\u540e\u9a8c\u534f\u65b9\u5dee\uff0c\u89e3\u7801\u5668\u901a\u8fc7MMSE\u4f30\u8ba1\u6700\u4f73\u54cd\u5e94\uff0c\u5728\u76f4\u63a5\u3001\u8fdc\u7a0b\u548c\u5b8c\u5168\u4fe1\u606f\u4e09\u79cd\u673a\u5236\u4e0b\u5206\u6790\uff0c\u8003\u8651\u4fe1\u606f\u901f\u7387\u7ea6\u675f\u548c\u8ba1\u7b97\u67b6\u6784\u9650\u5236\u3002", "result": "\u63a8\u5bfc\u51fa\u6218\u7565\u7387\u5931\u771f\u51fd\u6570\uff0c\u5f97\u5230\u8bed\u4e49\u6ce8\u6c34\u7b97\u6cd5\u548c\u901f\u7387\u7ea6\u675f\u9ad8\u65af\u8bf4\u670d\u89e3\uff0c\u8bc1\u660e\u9ad8\u65af\u6700\u4f18\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u6df1\u5ea6\u548c\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u5e26\u6765\u8bed\u4e49\u51c6\u786e\u6027\u7684\u6307\u6570\u7ea7\u6539\u8fdb\uff0c\u591a\u6a21\u6001\u89c2\u6d4b\u6d88\u9664\u8fdc\u7a0b\u7f16\u7801\u7684\u51e0\u4f55\u5e73\u5747\u60e9\u7f5a\u3002", "conclusion": "\u4e3a\u6570\u636e\u9ad8\u6548AI\u63d0\u4f9b\u4fe1\u606f\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u73b0\u4ee3\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u4e3a\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u540e\u9a8c\u8bbe\u8ba1\u673a\u5236\uff0c\u8ba1\u7b97\u67b6\u6784\u9650\u5236\u53ef\u4f5c\u4e3a\u9690\u5f0f\u901f\u7387\u7ea6\u675f\uff0c\u591a\u6a21\u6001\u89c2\u6d4b\u80fd\u514b\u670d\u8fdc\u7a0b\u7f16\u7801\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002"}}
{"id": "2602.03900", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03900", "abs": "https://arxiv.org/abs/2602.03900", "authors": ["Erik Goh", "John Kos", "Ashok Goel"], "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks", "comment": null, "summary": "Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.", "AI": {"tldr": "TMK\u6846\u67b6\u663e\u8457\u63d0\u5347LLM\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u7b26\u53f7\u5316\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u4ece31.5%\u63d0\u5347\u81f397.3%\uff0c\u5f15\u5bfc\u6a21\u578b\u4ece\u8bed\u8a00\u6a21\u5f0f\u8f6c\u5411\u5f62\u5f0f\u5316\u6267\u884c\u8def\u5f84\u3002", "motivation": "\u73b0\u6709LLM\u5728\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u5373\u4f7fCoT\u7b49\u63d0\u793a\u6280\u672f\u4e5f\u53d7\u5230\u8d28\u7591\u3002\u7814\u7a76\u63a2\u7d22\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7684TMK\u6846\u67b6\u662f\u5426\u80fd\u8d85\u8d8a\u5176\u5728\u6559\u80b2\u9886\u57df\u7684\u6210\u529f\uff0c\u89e3\u51b3LLM\u7684\u63a8\u7406\u7f3a\u9677\u3002", "method": "\u91c7\u7528Task-Method-Knowledge\u6846\u67b6\u8fdb\u884c\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u5728PlanBench\u57fa\u51c6\u7684Blocksworld\u9886\u57df\u6d4b\u8bd5\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\uff0c\u8bc4\u4f30TMK\u662f\u5426\u80fd\u5e2e\u52a9LLM\u5c06\u590d\u6742\u89c4\u5212\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52a1\u3002", "result": "TMK\u63d0\u793a\u4f7f\u63a8\u7406\u6a21\u578b\u5728\u4e0d\u900f\u660e\u7684\u7b26\u53f7\u4efb\u52a1\uff08PlanBench\u4e2dBlocksworld\u7684\u968f\u673a\u7248\u672c\uff09\u4e0a\u51c6\u786e\u7387\u4ece31.5%\u63d0\u5347\u81f397.3%\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u53cd\u8f6c\uff0c\u7f29\u5c0f\u4e86\u8bed\u4e49\u8fd1\u4f3c\u4e0e\u7b26\u53f7\u64cd\u4f5c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "TMK\u4e0d\u4ec5\u63d0\u4f9b\u4e0a\u4e0b\u6587\uff0c\u66f4\u662f\u4e00\u79cd\u5f15\u5bfc\u673a\u5236\uff0c\u4f7f\u63a8\u7406\u6a21\u578b\u4ece\u9ed8\u8ba4\u8bed\u8a00\u6a21\u5f0f\u8f6c\u5411\u53c2\u4e0e\u5f62\u5f0f\u5316\u3001\u4ee3\u7801\u6267\u884c\u8def\u5f84\uff0c\u5728\u7b26\u53f7\u5316\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u6f5c\u529b\u3002"}}
{"id": "2602.04825", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.04825", "abs": "https://arxiv.org/abs/2602.04825", "authors": ["Achilles Machumilane", "Alberto Gotta"], "title": "On Dual Connectivity in 6G Leo Constellations", "comment": null, "summary": "Dual connectivity (DC) has garnered significant attention in 5G evolution, allowing for enhancing throughput and reliability by leveraging the channel conditions of two paths. However, when the paths exhibit different delays, such as in terrestrial and non-terrestrial integrated networks with multi-orbit topologies or in networks characterized by frequent topology changes, like Low Earth Orbit (LEO) satellite constellations with different elevation angles, traffic delivery may experience packet reordering or triggering congestion control mechanisms. Additionally, real-time traffic may experience packet drops if their arrival exceeds a play-out threshold. Different techniques have been proposed to address these issues, such as packet duplication, packet switching, and network coding for traffic scheduling in DC. However, if not accurately designed, these techniques can lead to resource waste, encoding/decoding delays, and computational overhead, undermining DC's intended benefits. This paper provides a mathematical framework for calculating the average end-to-end packet loss in case of a loss process modeled with a Discrete Markov Chain - typical of a wireless channel - when combining packet duplication and packet switching or when network coding is employed in DC. Such metrics help derive optimal policies with full knowledge of the underlying loss process to be compared to empirical models learned through Machine Learning algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u5728\u53cc\u8fde\u63a5\u7f51\u7edc\u4e2d\u7ed3\u5408\u5305\u590d\u5236\u4e0e\u5305\u5207\u6362\u6216\u4f7f\u7528\u7f51\u7edc\u7f16\u7801\u65f6\u7684\u5e73\u5747\u7aef\u5230\u7aef\u5305\u4e22\u5931\u7387\uff0c\u5176\u4e2d\u4e22\u5931\u8fc7\u7a0b\u7531\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u94fe\u5efa\u6a21\u3002", "motivation": "\u57285G\u6f14\u8fdb\u4e2d\uff0c\u53cc\u8fde\u63a5\u6280\u672f\u901a\u8fc7\u5229\u7528\u4e24\u6761\u8def\u5f84\u7684\u4fe1\u9053\u6761\u4ef6\u6765\u589e\u5f3a\u541e\u5410\u91cf\u548c\u53ef\u9760\u6027\u3002\u7136\u800c\uff0c\u5f53\u8def\u5f84\u5b58\u5728\u4e0d\u540c\u5ef6\u8fdf\u65f6\uff08\u5982\u5730\u9762\u4e0e\u975e\u5730\u9762\u96c6\u6210\u7f51\u7edc\u3001\u9891\u7e41\u62d3\u6251\u53d8\u5316\u7684LEO\u536b\u661f\u7f51\u7edc\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u5305\u91cd\u6392\u5e8f\u3001\u89e6\u53d1\u62e5\u585e\u63a7\u5236\u673a\u5236\uff0c\u6216\u5b9e\u65f6\u6d41\u91cf\u56e0\u8d85\u8fc7\u64ad\u653e\u9608\u503c\u800c\u4e22\u5305\u3002\u73b0\u6709\u6280\u672f\u5982\u5305\u590d\u5236\u3001\u5305\u5207\u6362\u548c\u7f51\u7edc\u7f16\u7801\u5982\u679c\u8bbe\u8ba1\u4e0d\u5f53\uff0c\u4f1a\u9020\u6210\u8d44\u6e90\u6d6a\u8d39\u3001\u7f16\u89e3\u7801\u5ef6\u8fdf\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u524a\u5f31\u53cc\u8fde\u63a5\u7684\u4f18\u52bf\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u5728\u53cc\u8fde\u63a5\u7f51\u7edc\u4e2d\uff0c\u5f53\u4e22\u5931\u8fc7\u7a0b\u7531\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u94fe\uff08\u5178\u578b\u7684\u65e0\u7ebf\u4fe1\u9053\u6a21\u578b\uff09\u5efa\u6a21\u65f6\uff0c\u7ed3\u5408\u5305\u590d\u5236\u4e0e\u5305\u5207\u6362\u6216\u4f7f\u7528\u7f51\u7edc\u7f16\u7801\u65f6\u7684\u5e73\u5747\u7aef\u5230\u7aef\u5305\u4e22\u5931\u7387\u3002\u8be5\u6846\u67b6\u5e2e\u52a9\u63a8\u5bfc\u51fa\u57fa\u4e8e\u5e95\u5c42\u4e22\u5931\u8fc7\u7a0b\u5b8c\u5168\u77e5\u8bc6\u7684\u6700\u4f18\u7b56\u7565\u3002", "result": "\u8be5\u6570\u5b66\u6846\u67b6\u80fd\u591f\u8ba1\u7b97\u53cc\u8fde\u63a5\u7f51\u7edc\u4e2d\u4e0d\u540c\u6d41\u91cf\u8c03\u5ea6\u6280\u672f\u4e0b\u7684\u5e73\u5747\u7aef\u5230\u7aef\u5305\u4e22\u5931\u7387\uff0c\u4e3a\u4f18\u5316\u7b56\u7565\u63d0\u4f9b\u91cf\u5316\u57fa\u7840\u3002\u8fd9\u4e9b\u6307\u6807\u53ef\u4ee5\u4e0e\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5b66\u4e60\u7684\u7ecf\u9a8c\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6570\u5b66\u6846\u67b6\u4e3a\u53cc\u8fde\u63a5\u7f51\u7edc\u4e2d\u7684\u6d41\u91cf\u8c03\u5ea6\u6280\u672f\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u5de5\u5177\uff0c\u80fd\u591f\u5e2e\u52a9\u8bbe\u8ba1\u66f4\u51c6\u786e\u3001\u9ad8\u6548\u7684\u5305\u590d\u5236\u3001\u5305\u5207\u6362\u548c\u7f51\u7edc\u7f16\u7801\u7b56\u7565\uff0c\u907f\u514d\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u5145\u5206\u53d1\u6325\u53cc\u8fde\u63a5\u6280\u672f\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.04808", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.04808", "abs": "https://arxiv.org/abs/2602.04808", "authors": ["Wajahat Bashir Gilkar", "Gourab Ghatak"], "title": "Joint Sleep Mode Activation and Load Balancing with Dynamic Cell Load: A Combinatorial Bandit Approach", "comment": null, "summary": "We propose a combinatorial bandit formulation to opportunistically trigger sleep modes in gNode-B (gNB) small cells (SCs), followed by a cell range expansion (CRE)-based load balancing procedure. This is implemented by ensuring that the fifth generation (5G) quality of service identifier (5QI)-requirements of user equipments (UEs) are maintained. The key challenge is the fact that while deactivating a given SC gNB reduces its own consumption, it may increase the load on neighboring gNBs and the macro gNB (coverage cell), impacting the overall energy efficiency. This phenomenon is accurately characterized by modeling the dynamic cell load that jointly takes into account the location of the UEs, their relative locations to all the SCs, and their data demands. We experimentally show that the proposed combinatorial upper confidence bound (CUCB) followed by the load balancer outperforms not only the naive strategies like arbitrarily keeping all the SCs on, but also other state-of-the-art reinforcement learning solutions. The proposed algorithm can be implemented as open-radio access network (O-RAN) near-real-time (NRT) RAN intelligent controller (RIC) xApps.", "AI": {"tldr": "\u63d0\u51fa\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e6\u53d1gNB\u5c0f\u57fa\u7ad9\u7761\u7720\u6a21\u5f0f\u5e76\u914d\u5408\u5c0f\u533a\u8303\u56f4\u6269\u5c55\u8d1f\u8f7d\u5747\u8861\uff0c\u5728\u4fdd\u8bc15G\u670d\u52a1\u8d28\u91cf\u7684\u540c\u65f6\u4f18\u5316\u80fd\u8017\u6548\u7387\u3002", "motivation": "5G\u7f51\u7edc\u4e2d\uff0c\u5173\u95ed\u5c0f\u57fa\u7ad9(gNB)\u867d\u7136\u80fd\u964d\u4f4e\u81ea\u8eab\u80fd\u8017\uff0c\u4f46\u4f1a\u589e\u52a0\u76f8\u90bb\u57fa\u7ad9\u548c\u5b8f\u57fa\u7ad9\u7684\u8d1f\u8f7d\uff0c\u5f71\u54cd\u6574\u4f53\u80fd\u6548\u3002\u9700\u8981\u5728\u4e0d\u5f71\u54cd\u7528\u6237\u670d\u52a1\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u667a\u80fd\u7ba1\u7406\u57fa\u7ad9\u7761\u7720\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u7ec4\u5408\u4e0a\u7f6e\u4fe1\u754c(CUCB)\u7b97\u6cd5\u89e6\u53d1\u5c0f\u57fa\u7ad9\u7761\u7720\u6a21\u5f0f\uff0c\u7ed3\u5408\u5c0f\u533a\u8303\u56f4\u6269\u5c55(CRE)\u8d1f\u8f7d\u5747\u8861\u3002\u5efa\u7acb\u52a8\u6001\u5c0f\u533a\u8d1f\u8f7d\u6a21\u578b\uff0c\u7efc\u5408\u8003\u8651\u7528\u6237\u4f4d\u7f6e\u3001\u76f8\u5bf9\u57fa\u7ad9\u4f4d\u7f6e\u548c\u6570\u636e\u9700\u6c42\u3002\u53ef\u4f5c\u4e3aO-RAN\u8fd1\u5b9e\u65f6RAN\u667a\u80fd\u63a7\u5236\u5668xApps\u5b9e\u73b0\u3002", "result": "\u63d0\u51fa\u7684CUCB+\u8d1f\u8f7d\u5747\u8861\u7b97\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u4fdd\u6301\u6240\u6709\u5c0f\u57fa\u7ad9\u5f00\u542f\u7684\u7b80\u5355\u7b56\u7565\uff0c\u4e5f\u4f18\u4e8e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u8bc15QI\u670d\u52a1\u8d28\u91cf\u8981\u6c42\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u80fd\u6548\u3002", "conclusion": "\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u65b9\u6cd5\u80fd\u6709\u6548\u7ba1\u74065G\u5c0f\u57fa\u7ad9\u7761\u7720\u6a21\u5f0f\uff0c\u901a\u8fc7\u667a\u80fd\u8d1f\u8f7d\u5747\u8861\u5b9e\u73b0\u80fd\u8017\u4f18\u5316\uff0c\u53ef\u4f5c\u4e3aO-RAN\u67b6\u6784\u4e2d\u7684\u667a\u80fd\u63a7\u5236\u5668\u5e94\u7528\u90e8\u7f72\u3002"}}
{"id": "2602.03950", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03950", "abs": "https://arxiv.org/abs/2602.03950", "authors": ["Aditya Basarkar", "Benyamin Tabarsi", "Tiffany Barnes", "Dongkuan", "Xu"], "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation", "comment": "9 pages, 7 figures, submitted to ACL ARR 2026", "summary": "Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.", "AI": {"tldr": "IIPC\u662f\u4e00\u79cd\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6267\u884c\u53cd\u9988\u548c\u601d\u7ef4\u94fe\u80fd\u529b\u6765\u63d0\u5347\u6570\u5b66\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fee\u6b63\u6027", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7f3a\u4e4f\u53ef\u9760\u53ef\u4fee\u6b63\u7684\u63a8\u7406\u8fc7\u7a0b\u8868\u793a\uff0c\u8981\u4e48\u91c7\u7528\u50f5\u5316\u7684\u987a\u5e8f\u6d41\u7a0b\u65e0\u6cd5\u4fee\u6b63\u65e9\u671f\u9519\u8bef\uff0c\u8981\u4e48\u4f9d\u8d56\u542f\u53d1\u5f0f\u81ea\u6211\u8bc4\u4f30\u53ef\u80fd\u65e0\u6cd5\u8bc6\u522b\u548c\u4fee\u590d\u9519\u8bef\uff0c\u800c\u4e14\u7a0b\u5e8f\u5316\u4e0a\u4e0b\u6587\u4f1a\u5206\u6563\u8bed\u8a00\u6a21\u578b\u6ce8\u610f\u529b\u964d\u4f4e\u51c6\u786e\u6027", "method": "IIPC\uff08\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\uff09\u65b9\u6cd5\uff0c\u8fed\u4ee3\u7cbe\u70bc\u7a0b\u5e8f\u5316\u63a8\u7406\u94fe\uff0c\u5c06\u6267\u884c\u53cd\u9988\u4e0e\u57fa\u7840LLM\u7684\u539f\u751f\u601d\u7ef4\u94fe\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u4fdd\u6301\u9ad8\u5c42\u6b21\u4e0a\u4e0b\u6587\u805a\u7126", "result": "IIPC\u5728\u591a\u4e2a\u57fa\u7840LLM\u4e0a\u7684\u5927\u591a\u6570\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u7ade\u4e89\u65b9\u6cd5", "conclusion": "IIPC\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u7684\u7a0b\u5e8f\u6784\u9020\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u5b66\u63a8\u7406\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4ee3\u7801\u548c\u5b9e\u73b0\u5df2\u5f00\u6e90\u53d1\u5e03"}}
{"id": "2602.04810", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.04810", "abs": "https://arxiv.org/abs/2602.04810", "authors": ["Hanzaleh Akbari Nodehi", "Parsa Moradi", "Soheil Mohajer", "Mohammad Ali Maddah-Ali"], "title": "Game of Coding for Vector-Valued Computations", "comment": null, "summary": "The game of coding is a new framework at the intersection of game theory and coding theory; designed to transcend the fundamental limitations of classical coding theory. While traditional coding theoretic schemes rely on a strict trust assumption, that honest nodes must outnumber adversarial ones to guarantee valid decoding, the game of coding leverages the economic rationality of actors to guarantee correctness and reliable decodability, even in the presence of an adversarial majority. This capability is paramount for emerging permissionless applications, particularly decentralized machine learning (DeML). However, prior investigations into the game of coding have been strictly confined to scalar computations, limiting their applicability to real world tasks where high dimensional data is the norm. In this paper, we bridge this gap by extending the framework to the general $N$-dimensional Euclidean space. We provide a rigorous problem formulation for vector valued computations and fully characterize the equilibrium strategies of the resulting high dimensional game. Our analysis demonstrates that the resilience properties established in the scalar setting are preserved in the vector regime, establishing a theoretical foundation for secure, large scale decentralized computing without honest majority assumptions.", "AI": {"tldr": "\u5c06\u535a\u5f08\u7f16\u7801\u6846\u67b6\u4ece\u6807\u91cf\u6269\u5c55\u5230N\u7ef4\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u4e3a\u9ad8\u7ef4\u6570\u636e\u8ba1\u7b97\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u5373\u4f7f\u5728\u5bf9\u6297\u591a\u6570\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u8bc1\u6b63\u786e\u89e3\u7801\u3002", "motivation": "\u4f20\u7edf\u7f16\u7801\u7406\u8bba\u9700\u8981\u8bda\u5b9e\u8282\u70b9\u5360\u591a\u6570\u624d\u80fd\u4fdd\u8bc1\u6709\u6548\u89e3\u7801\uff0c\u800c\u535a\u5f08\u7f16\u7801\u5229\u7528\u7ecf\u6d4e\u7406\u6027\u4fdd\u8bc1\u6b63\u786e\u6027\uff0c\u5373\u4f7f\u5bf9\u6297\u8282\u70b9\u5360\u591a\u6570\u4e5f\u80fd\u5de5\u4f5c\u3002\u7136\u800c\u5148\u524d\u7814\u7a76\u4ec5\u9650\u4e8e\u6807\u91cf\u8ba1\u7b97\uff0c\u65e0\u6cd5\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u9ad8\u7ef4\u6570\u636e\u4efb\u52a1\u3002", "method": "\u5c06\u535a\u5f08\u7f16\u7801\u6846\u67b6\u6269\u5c55\u5230N\u7ef4\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u4e3a\u5411\u91cf\u503c\u8ba1\u7b97\u63d0\u4f9b\u4e25\u683c\u7684\u95ee\u9898\u8868\u8ff0\uff0c\u5e76\u5b8c\u5168\u8868\u5f81\u6240\u5f97\u9ad8\u7ef4\u535a\u5f08\u7684\u5747\u8861\u7b56\u7565\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u6807\u91cf\u8bbe\u7f6e\u4e2d\u5efa\u7acb\u7684\u5f39\u6027\u7279\u6027\u5728\u5411\u91cf\u673a\u5236\u4e2d\u5f97\u4ee5\u4fdd\u7559\uff0c\u4e3a\u65e0\u9700\u8bda\u5b9e\u591a\u6570\u5047\u8bbe\u7684\u5b89\u5168\u3001\u5927\u89c4\u6a21\u53bb\u4e2d\u5fc3\u5316\u8ba1\u7b97\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06\u535a\u5f08\u7f16\u7801\u6269\u5c55\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u673a\u5668\u5b66\u4e60\u7b49\u65e0\u8bb8\u53ef\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u7f16\u7801\u7406\u8bba\u7684\u4fe1\u4efb\u9650\u5236\u3002"}}
{"id": "2602.03955", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03955", "abs": "https://arxiv.org/abs/2602.03955", "authors": ["Yinyi Luo", "Yiqiao Jin", "Weichen Yu", "Mengqi Zhang", "Srijan Kumar", "Xiaoxiao Li", "Weijie Xu", "Xin Chen", "Jindong Wang"], "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent", "comment": null, "summary": "While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.", "AI": {"tldr": "AgentArk\u6846\u67b6\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u52a8\u6001\u84b8\u998f\u5230\u5355\u4e2a\u6a21\u578b\u4e2d\uff0c\u5c06\u663e\u5f0f\u7684\u6d4b\u8bd5\u65f6\u4ea4\u4e92\u8f6c\u5316\u4e3a\u9690\u5f0f\u7684\u6a21\u578b\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u5355\u667a\u80fd\u4f53\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u83b7\u5f97\u591a\u667a\u80fd\u4f53\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u8fed\u4ee3\u8fa9\u8bba\u7684LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u83b7\u5f97\u4f18\u8d8a\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u53d7\u5230\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u9519\u8bef\u4f20\u64ad\u7684\u9650\u5236\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u591a\u667a\u80fd\u4f53\u63a8\u7406\u4f18\u52bf\uff0c\u53c8\u5177\u5907\u8ba1\u7b97\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAgentArk\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u79cd\u5206\u5c42\u84b8\u998f\u7b56\u7565\uff1a\u63a8\u7406\u589e\u5f3a\u5fae\u8c03\u3001\u57fa\u4e8e\u8f68\u8ff9\u7684\u6570\u636e\u589e\u5f3a\u3001\u8fc7\u7a0b\u611f\u77e5\u84b8\u998f\u3002\u5c06\u591a\u667a\u80fd\u4f53\u52a8\u6001\u84b8\u998f\u5230\u5355\u4e2a\u6a21\u578b\u7684\u6743\u91cd\u4e2d\uff0c\u5c06\u8ba1\u7b97\u8d1f\u62c5\u4ece\u63a8\u7406\u9636\u6bb5\u8f6c\u79fb\u5230\u8bad\u7ec3\u9636\u6bb5\u3002", "result": "\u84b8\u998f\u540e\u7684\u6a21\u578b\u5728\u4fdd\u6301\u5355\u667a\u80fd\u4f53\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u5c55\u73b0\u51fa\u591a\u667a\u80fd\u4f53\u7684\u5f3a\u63a8\u7406\u548c\u81ea\u6211\u7ea0\u6b63\u6027\u80fd\uff0c\u5e76\u5728\u591a\u6837\u5316\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AgentArk\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u52a8\u6001\u84b8\u998f\u5230\u5355\u4e2a\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u591a\u667a\u80fd\u4f53\u5f00\u53d1\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.04862", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.04862", "abs": "https://arxiv.org/abs/2602.04862", "authors": ["Pablo Orellana", "Zheng Li", "Jean-Marc Kelif", "Sheng Yang", "Shlomo Shamai"], "title": "Capacity Bounds on Doppler OFDM Channels", "comment": "8 pages, 1 figure, submitted to ISIT 2026", "summary": "Low Earth orbit (LEO) satellite systems experience significant Doppler effects due to high mobility. While Doppler shifts can be largely compensated, residual frequency uncertainty induces a structured form of channel uncertainty that can limit achievable rates. We model this effect using a block-fading channel of the form $ \\mathbf{H} = \\mathbf{F} + s \\mathbf{G} $, where $s$ is an unknown scalar random parameter. We first study this model in a general $N\\times N$ MIMO setting. For this channel, we derive achievable rate lower bounds based on explicit transmission schemes and capacity upper bounds using a duality approach. We study Gaussian signaling and propose a practical superposition scheme with subspace alignment (SN) and successive interference cancellation, where a coarse-layer stream serves as an implicit pilot for decoding refined-layer data. We characterize asymptotic capacity in the near-coherent and high-SNR regimes, and show via Doppler-OFDM simulations that the proposed SN scheme achieves near-optimal rates with low complexity.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86LEO\u536b\u661f\u7cfb\u7edf\u4e2d\u591a\u666e\u52d2\u6548\u5e94\u5f15\u8d77\u7684\u4fe1\u9053\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b50\u7a7a\u95f4\u5bf9\u9f50\u7684\u53e0\u52a0\u7f16\u7801\u65b9\u6848\uff0c\u5728\u4f4e\u590d\u6742\u5ea6\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u901f\u7387\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7cfb\u7edf\u7531\u4e8e\u9ad8\u901f\u79fb\u52a8\u4f1a\u4ea7\u751f\u663e\u8457\u7684\u591a\u666e\u52d2\u6548\u5e94\u3002\u867d\u7136\u591a\u666e\u52d2\u9891\u79fb\u53ef\u4ee5\u5927\u90e8\u5206\u8865\u507f\uff0c\u4f46\u6b8b\u4f59\u9891\u7387\u4e0d\u786e\u5b9a\u6027\u4f1a\u5bfc\u81f4\u7ed3\u6784\u5316\u4fe1\u9053\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u9650\u5236\u53ef\u8fbe\u5230\u7684\u901f\u7387\u3002", "method": "\u4f7f\u7528\u5757\u8870\u843d\u4fe1\u9053\u6a21\u578bH=F+sG\uff0c\u5176\u4e2ds\u662f\u672a\u77e5\u6807\u91cf\u968f\u673a\u53c2\u6570\u3002\u63d0\u51fa\u57fa\u4e8e\u5b50\u7a7a\u95f4\u5bf9\u9f50\u7684\u53e0\u52a0\u7f16\u7801\u65b9\u6848\uff0c\u91c7\u7528\u7c97\u5c42\u6d41\u4f5c\u4e3a\u9690\u5f0f\u5bfc\u9891\uff0c\u901a\u8fc7\u8fde\u7eed\u5e72\u6270\u6d88\u9664\u89e3\u7801\u7cbe\u5c42\u6570\u636e\u3002", "result": "\u63a8\u5bfc\u4e86\u53ef\u8fbe\u5230\u901f\u7387\u7684\u4e0b\u754c\u548c\u5bb9\u91cf\u4e0a\u754c\uff0c\u5728\u8fd1\u76f8\u5e72\u548c\u9ad8\u4fe1\u566a\u6bd4\u533a\u57df\u8868\u5f81\u4e86\u6e10\u8fd1\u5bb9\u91cf\u3002\u901a\u8fc7\u591a\u666e\u52d2OFDM\u4eff\u771f\u8868\u660e\uff0c\u63d0\u51fa\u7684SN\u65b9\u6848\u80fd\u4ee5\u4f4e\u590d\u6742\u5ea6\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u901f\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b50\u7a7a\u95f4\u5bf9\u9f50\u53e0\u52a0\u7f16\u7801\u65b9\u6848\u80fd\u6709\u6548\u5904\u7406LEO\u536b\u661f\u7cfb\u7edf\u4e2d\u7684\u591a\u666e\u52d2\u6b8b\u4f59\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u4f4e\u590d\u6742\u5ea6\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03974", "abs": "https://arxiv.org/abs/2602.03974", "authors": ["Shuhui Qu"], "title": "Active Epistemic Control for Query-Efficient Verified Planning", "comment": null, "summary": "Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \\textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \\emph{grounded fact store} used for commitment and a \\emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.", "AI": {"tldr": "AEC\u662f\u4e00\u79cd\u8ba4\u77e5-\u5206\u7c7b\u89c4\u5212\u5c42\uff0c\u901a\u8fc7\u5206\u79bb\u4e8b\u5b9e\u5b58\u50a8\u4e0e\u4fe1\u5ff5\u5b58\u50a8\uff0c\u7ed3\u5408\u73af\u5883\u67e5\u8be2\u4e0e\u6a21\u62df\u9884\u6d4b\u6765\u7ba1\u7406\u90e8\u5206\u53ef\u89c2\u5bdf\u73af\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u91cd\u89c4\u5212\u6b21\u6570\u3002", "motivation": "\u5728\u90e8\u5206\u53ef\u89c2\u5bdf\u73af\u5883\u4e2d\u89c4\u5212\u5177\u6709\u6311\u6218\u6027\uff1a\u4efb\u52a1\u5173\u952e\u524d\u63d0\u6761\u4ef6\uff08\u5982\u7269\u4f53\u4f4d\u7f6e\u6216\u5bb9\u5668\u72b6\u6001\uff09\u5728\u51b3\u7b56\u65f6\u53ef\u80fd\u672a\u77e5\uff0c\u4f46\u901a\u8fc7\u4ea4\u4e92\u8fdb\u884c\u9a8c\u8bc1\u6210\u672c\u9ad8\u6602\u3002\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u53ef\u4ee5\u5ec9\u4ef7\u9884\u6d4b\u7f3a\u5931\u4e8b\u5b9e\uff0c\u4f46\u9884\u6d4b\u9519\u8bef\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u884c\u7684\u627f\u8bfa\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u8ba4\u77e5\u63a7\u5236\uff08AEC\uff09\uff0c\u5c06\u57fa\u4e8e\u6a21\u578b\u7684\u4fe1\u5ff5\u7ba1\u7406\u4e0e\u5206\u7c7b\u53ef\u884c\u6027\u68c0\u67e5\u76f8\u7ed3\u5408\u3002AEC\u4e25\u683c\u5206\u79bb\u7528\u4e8e\u627f\u8bfa\u7684\u63a5\u5730\u4e8b\u5b9e\u5b58\u50a8\u548c\u4ec5\u7528\u4e8e\u4fee\u526a\u5019\u9009\u8ba1\u5212\u7684\u4fe1\u5ff5\u5b58\u50a8\u3002\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\uff0c\u5f53\u4e0d\u786e\u5b9a\u6027\u9ad8\u6216\u9884\u6d4b\u6a21\u7cca\u65f6\u67e5\u8be2\u73af\u5883\u4ee5\u63a5\u5730\u672a\u89e3\u6790\u8c13\u8bcd\uff0c\u6216\u5728\u7f6e\u4fe1\u5ea6\u8db3\u591f\u65f6\u6a21\u62df\u8c13\u8bcd\u4ee5\u8fc7\u6ee4\u5047\u8bbe\u3002\u6700\u7ec8\u627f\u8bfa\u901a\u8fc7\u63a5\u5730\u524d\u63d0\u6761\u4ef6\u8986\u76d6\u548cSQ-BCP\u62c9\u56de\u5f0f\u517c\u5bb9\u6027\u68c0\u67e5\u6765\u628a\u5173\u3002", "result": "\u5728ALFWorld\u548cScienceWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAEC\u5728\u8f83\u5c11\u91cd\u89c4\u5212\u8f6e\u6b21\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u5f3a\u5927LLM\u667a\u80fd\u4f53\u57fa\u7ebf\u7ade\u4e89\u7684\u6210\u529f\u7387\u3002", "conclusion": "AEC\u901a\u8fc7\u4e25\u683c\u5206\u79bb\u4e8b\u5b9e\u4e0e\u4fe1\u5ff5\u3001\u7ed3\u5408\u73af\u5883\u67e5\u8be2\u4e0e\u6a21\u62df\u9884\u6d4b\uff0c\u6709\u6548\u7ba1\u7406\u90e8\u5206\u53ef\u89c2\u5bdf\u73af\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u51cf\u5c11\u4e86\u91cd\u89c4\u5212\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\u3002"}}
{"id": "2602.03975", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03975", "abs": "https://arxiv.org/abs/2602.03975", "authors": ["Shuhui Qu"], "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure", "comment": null, "summary": "Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \\emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \\textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\\% fewer verifier calls.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u4e0b\u4f18\u5316\u9a8c\u8bc1\u8d44\u6e90\u5206\u914d\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c1144%\u9a8c\u8bc1\u8c03\u7528\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u4e3b\u8981\u53d7\u9650\u4e8e\u6602\u8d35\u7684\u9a8c\u8bc1\u6210\u672c\uff0c\u8bb8\u591a\u9a8c\u8bc1\u8c03\u7528\u6d6a\u8d39\u5728\u5197\u4f59\u6216\u65e0\u5e0c\u671b\u7684\u4e2d\u95f4\u5047\u8bbe\u4e0a\uff0c\u9700\u8981\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u73af\u5883\u4e0b\u7814\u7a76\u5982\u4f55\u4f18\u5316\u9a8c\u8bc1\u8d44\u6e90\u5206\u914d", "method": "\u63d0\u51fa\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff1a1) \u7ed3\u6784\u5316\u79fb\u52a8\u63a5\u53e3\u4e0a\u7684\u786e\u5b9a\u6027\u53ef\u884c\u6027\u95e8\u63a7\uff1b2) \u7ed3\u5408\u5b66\u4e60\u7684\u72b6\u6001\u8ddd\u79bb\u548c\u6b8b\u5dee\u5f97\u5206\u7684\u9884\u9a8c\u8bc1\u6392\u5e8f\uff1b3) \u57fa\u4e8e\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\u7684\u9a8c\u8bc1\u8c03\u7528\u81ea\u9002\u5e94\u5206\u914d", "result": "\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4best-of-N\u3001\u591a\u6570\u6295\u7968\u548cbeam search\u65b9\u6cd5\uff0c\u4f7f\u752844%\u66f4\u5c11\u7684\u9a8c\u8bc1\u8c03\u7528\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387", "conclusion": "\u901a\u8fc7\u72b6\u6001\u7ea7\u9009\u62e9\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u9a8c\u8bc1\u6210\u672c\u53d7\u9650\u73af\u5883\u4e0b\u66f4\u6709\u6548\u5730\u5206\u914d\u9a8c\u8bc1\u8d44\u6e90\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u9a8c\u8bc1\u8c03\u7528\u540c\u65f6\u63d0\u5347\u63a8\u7406\u6027\u80fd"}}
{"id": "2602.03978", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03978", "abs": "https://arxiv.org/abs/2602.03978", "authors": ["Zidi Xiong", "Shan Chen", "Himabindu Lakkaraju"], "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning", "comment": null, "summary": "As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a \"free gift\" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.", "AI": {"tldr": "RLVR\u8bad\u7ec3\u65e9\u671f\u53ef\u80fd\u5e26\u6765\u76d1\u63a7\u6027\u63d0\u5347\uff0c\u4f46\u8fd9\u79cd\u63d0\u5347\u5e76\u975e\u666e\u904d\u73b0\u8c61\uff0c\u800c\u662f\u9ad8\u5ea6\u4f9d\u8d56\u6570\u636e\u591a\u6837\u6027\u548c\u6307\u4ee4\u9075\u5faa\u6570\u636e\uff0c\u4e14\u76d1\u63a7\u6027\u4e0e\u80fd\u529b\u63d0\u5347\u6b63\u4ea4\u3002", "motivation": "\u968f\u7740\u5927\u578b\u63a8\u7406\u6a21\u578b\u90e8\u7f72\u589e\u591a\uff0c\u5ba1\u8ba1\u5176\u601d\u7ef4\u94fe\u7684\u5b89\u5168\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5148\u524d\u7814\u7a76\u53d1\u73b0RLVR\u8bad\u7ec3\u65e9\u671f\u53ef\u80fd\u5e26\u6765\u76d1\u63a7\u6027\u63d0\u5347\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u79cd\u6548\u5e94\u7684\u666e\u904d\u6027\u548c\u673a\u5236\u3002", "method": "\u901a\u8fc7\u8de8\u6a21\u578b\u5bb6\u65cf\u548c\u8bad\u7ec3\u9886\u57df\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5206\u6790\u6570\u636e\u591a\u6837\u6027\u3001\u6307\u4ee4\u9075\u5faa\u6570\u636e\u7684\u4f5c\u7528\uff0c\u8fdb\u884c\u673a\u5236\u5206\u6790\uff08\u54cd\u5e94\u5206\u5e03\u9510\u5316\u3001\u6ce8\u610f\u529b\u53d8\u5316\uff09\uff0c\u5e76\u63a7\u5236\u8bad\u7ec3\u548c\u8bc4\u4f30\u96be\u5ea6\u7814\u7a76\u76d1\u63a7\u6027\u52a8\u6001\u3002", "result": "\u76d1\u63a7\u6027\u63d0\u5347\u5f3a\u70c8\u4f9d\u8d56\u6570\u636e\uff0c\u7279\u522b\u662f\u6570\u636e\u591a\u6837\u6027\u548c\u6307\u4ee4\u9075\u5faa\u6570\u636e\uff1b\u76d1\u63a7\u6027\u4e0e\u63a8\u7406\u80fd\u529b\u63d0\u5347\u6b63\u4ea4\uff1b\u673a\u5236\u4e0a\u4e3b\u8981\u5f52\u56e0\u4e8e\u54cd\u5e94\u5206\u5e03\u9510\u5316\u548c\u5bf9\u63d0\u793a\u5173\u6ce8\u589e\u52a0\uff0c\u800c\u975e\u5bf9\u63a8\u7406\u94fe\u7684\u56e0\u679c\u4f9d\u8d56\u589e\u5f3a\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86RLVR\u4e0b\u76d1\u63a7\u6027\u6d8c\u73b0\u7684\u5168\u666f\u89c6\u56fe\uff0c\u9610\u660e\u4e86\u76d1\u63a7\u6027\u63d0\u5347\u4f55\u65f6\u53ef\u80fd\u53d1\u751f\u3001\u4f55\u65f6\u4e0d\u4f1a\u53d1\u751f\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u7684\u5173\u952e\u4f5c\u7528\u4ee5\u53ca\u76d1\u63a7\u6027\u4e0e\u80fd\u529b\u7684\u72ec\u7acb\u6027\u3002"}}
{"id": "2602.04003", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04003", "abs": "https://arxiv.org/abs/2602.04003", "authors": ["Shutong Fan", "Lan Zhang", "Xiaoyong Yuan"], "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making", "comment": null, "summary": "Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u6297\u6027\u89e3\u91ca\u653b\u51fb(AEAs)\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u64cd\u7eb5LLM\u751f\u6210\u89e3\u91ca\u7684\u6846\u67b6\u6765\u8c03\u8282\u7528\u6237\u5bf9\u9519\u8bef\u8f93\u51fa\u7684\u4fe1\u4efb\uff0c\u63ed\u793a\u4e86AI\u4e0e\u7528\u6237\u4e4b\u95f4\u8ba4\u77e5\u901a\u9053\u7684\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "\u73b0\u4ee3AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u5728\u4eba\u7c7b\u51b3\u7b56\u5faa\u73af\u4e2d\u8fd0\u884c\uff0c\u7528\u6237\u4f9d\u8d56\u6a21\u578b\u63a8\u8350\u3002LLM\u751f\u6210\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4f1a\u5f71\u54cd\u7528\u6237\u5bf9AI\u8f93\u51fa\u7684\u611f\u77e5\u548c\u4fe1\u4efb\uff0c\u8fd9\u63ed\u793a\u4e86AI\u4e0e\u7528\u6237\u4e4b\u95f4\u8ba4\u77e5\u901a\u9053\u7684\u65b0\u653b\u51fb\u9762\u3002\u5f53\u524d\u5927\u591a\u6570\u5bf9\u6297\u6027\u5a01\u80c1\u9488\u5bf9\u6a21\u578b\u7684\u8ba1\u7b97\u884c\u4e3a\uff0c\u800c\u975e\u4f9d\u8d56\u6a21\u578b\u7684\u7528\u6237\u3002", "method": "\u5f15\u5165\u5bf9\u6297\u6027\u89e3\u91ca\u653b\u51fb(AEAs)\uff0c\u901a\u8fc7\u4fe1\u4efb\u6821\u51c6\u5dee\u8ddd\u6765\u5f62\u5f0f\u5316\u884c\u4e3a\u5a01\u80c1\u3002\u8fdb\u884c\u63a7\u5236\u5b9e\u9a8c(n=205)\uff0c\u7cfb\u7edf\u53d8\u5316\u89e3\u91ca\u6846\u67b6\u7684\u56db\u4e2a\u7ef4\u5ea6\uff1a\u63a8\u7406\u6a21\u5f0f\u3001\u8bc1\u636e\u7c7b\u578b\u3001\u6c9f\u901a\u98ce\u683c\u548c\u5448\u73b0\u683c\u5f0f\uff0c\u91cf\u5316\u5bf9\u6297\u6027\u89e3\u91ca\u5bf9\u4eba\u7c7b\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "result": "\u7528\u6237\u5bf9\u5bf9\u6297\u6027\u548c\u826f\u6027\u89e3\u91ca\u62a5\u544a\u7684\u4fe1\u4efb\u51e0\u4e4e\u76f8\u540c\uff0c\u5bf9\u6297\u6027\u89e3\u91ca\u5728\u9519\u8bef\u60c5\u51b5\u4e0b\u4ecd\u4fdd\u7559\u4e86\u5927\u90e8\u5206\u826f\u6027\u4fe1\u4efb\u3002\u6700\u8106\u5f31\u7684\u6848\u4f8b\u51fa\u73b0\u5728AEA\u7c7b\u4f3c\u4e13\u5bb6\u6c9f\u901a\u65f6\uff0c\u7ed3\u5408\u6743\u5a01\u8bc1\u636e\u3001\u4e2d\u6027\u8bed\u6c14\u548c\u9886\u57df\u9002\u5f53\u7684\u63a8\u7406\u3002\u5728\u56f0\u96be\u4efb\u52a1\u3001\u4e8b\u5b9e\u9a71\u52a8\u9886\u57df\u4ee5\u53ca\u6559\u80b2\u7a0b\u5ea6\u8f83\u4f4e\u3001\u8f83\u5e74\u8f7b\u6216\u9ad8\u5ea6\u4fe1\u4efbAI\u7684\u53c2\u4e0e\u8005\u4e2d\u8106\u5f31\u6027\u6700\u9ad8\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5c06\u89e3\u91ca\u89c6\u4e3a\u5bf9\u6297\u6027\u8ba4\u77e5\u901a\u9053\u5e76\u91cf\u5316\u5176\u5bf9AI\u8f85\u52a9\u51b3\u7b56\u4e2d\u4eba\u7c7b\u4fe1\u4efb\u5f71\u54cd\u7684\u7cfb\u7edf\u6027\u5b89\u5168\u7814\u7a76\uff0c\u63ed\u793a\u4e86LLM\u89e3\u91ca\u6846\u67b6\u53ef\u4ee5\u88ab\u64cd\u7eb5\u6765\u8bef\u5bfc\u7528\u6237\u4fe1\u4efb\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u63aa\u65bd\u6765\u4fdd\u62a4\u8ba4\u77e5\u901a\u9053\u3002"}}
{"id": "2602.04028", "categories": ["cs.AI", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.04028", "abs": "https://arxiv.org/abs/2602.04028", "authors": ["Leila Amgoud", "Martin Cooper"], "title": "Axiomatic Foundations of Counterfactual Explanations", "comment": null, "summary": "Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.\n  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684axiomatic\u6846\u67b6\uff0c\u8bc1\u660e\u4e0d\u53ef\u80fd\u5b9a\u7406\uff0c\u8bc6\u522b\u4e94\u79cd\u4e0d\u540c\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7c7b\u578b\uff0c\u5e76\u5c06\u73b0\u6709\u89e3\u91ca\u5668\u5206\u7c7b\u5230\u8be5\u6846\u67b6\u4e2d\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5668\u53ea\u5173\u6ce8\u5355\u4e00\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u4e14\u4ec5\u9650\u4e8e\u5c40\u90e8\u89e3\u91ca\uff08\u9488\u5bf9\u5355\u4e2a\u5b9e\u4f8b\uff09\u3002\u7f3a\u4e4f\u5bf9\u66ff\u4ee3\u53cd\u4e8b\u5b9e\u7c7b\u578b\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u4e5f\u7f3a\u4e4f\u5bf9\u63ed\u793a\u7cfb\u7edf\u6574\u4f53\u63a8\u7406\u8fc7\u7a0b\u7684\u5168\u5c40\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u7814\u7a76\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u4e00\u7ec4\u7406\u60f3\u5c5e\u6027\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5668\u516c\u7406\u6846\u67b6\uff0c\u8bc1\u660e\u4e0d\u53ef\u80fd\u5b9a\u7406\uff0c\u901a\u8fc7\u8868\u793a\u5b9a\u7406\u5efa\u7acb\u516c\u7406\u5b50\u96c6\u4e0e\u89e3\u91ca\u5668\u5bb6\u65cf\u4e4b\u95f4\u7684\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u8bc6\u522b\u4e94\u79cd\u4e0d\u540c\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7c7b\u578b\u3002", "result": "\u8bc1\u660e\u4e86\u6ca1\u6709\u5355\u4e00\u89e3\u91ca\u5668\u80fd\u540c\u65f6\u6ee1\u8db3\u67d0\u4e9b\u516c\u7406\u7ec4\u5408\uff0c\u8bc6\u522b\u4e86\u4e94\u79cd\u6839\u672c\u4e0d\u540c\u7684\u53cd\u4e8b\u5b9e\u7c7b\u578b\uff08\u5305\u62ec\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\uff09\uff0c\u5c06\u73b0\u6709\u89e3\u91ca\u5668\u5206\u7c7b\u5230\u8be5\u6846\u67b6\u4e2d\uff0c\u5e76\u5206\u6790\u4e86\u751f\u6210\u6b64\u7c7b\u89e3\u91ca\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cd\u4e8b\u5b9e\u89e3\u91ca\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u591a\u6837\u6027\uff0c\u4e3a\u672a\u6765\u89e3\u91ca\u5668\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u5e2e\u52a9\u7406\u89e3\u4e0d\u540c\u89e3\u91ca\u65b9\u6cd5\u7684\u672c\u8d28\u5dee\u5f02\u3002"}}
{"id": "2602.04089", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04089", "abs": "https://arxiv.org/abs/2602.04089", "authors": ["Xiaofeng Lin", "Sirou Zhu", "Yilei Chen", "Mingyu Chen", "Hejian Sang", "Ioannis Paschalidis", "Zhipeng Wang", "Aldo Pacchiano", "Xuezhou Zhang"], "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL", "comment": null, "summary": "Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.", "AI": {"tldr": "ORBIT\u6846\u67b6\u901a\u8fc7\u5143\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLMs\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u5728\u7ebf\u51b3\u7b56\u6027\u80fd", "motivation": "\u73b0\u6709LLMs\u5728\u9700\u8981\u5728\u7ebf\u4ea4\u4e92\u83b7\u53d6\u4fe1\u606f\u3001\u5ef6\u8fdf\u53cd\u9988\u3001\u5e73\u8861\u4fe1\u606f\u6536\u96c6\u4e0e\u5229\u7528\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u8bad\u7ec3\u6765\u63d0\u5347\u5176\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b", "method": "\u63d0\u51faORBIT\u6846\u67b6\uff1a\u591a\u4efb\u52a1\u3001\u591a\u56de\u5408\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ece\u4ea4\u4e92\u7ecf\u9a8c\u4e2d\u5b66\u4e60", "result": "\u7ecf\u8fc7\u5143\u8bad\u7ec3\u540e\uff0c\u76f8\u5bf9\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b(Qwen3-14B)\u5728\u672a\u89c1\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\u7684\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\uff0c\u6027\u80fd\u5339\u914dGPT-5.2\uff0c\u5927\u5e45\u4f18\u4e8e\u6807\u51c6RL\u5fae\u8c03", "conclusion": "\u901a\u8fc7\u8bad\u7ec3\u53ef\u4ee5\u663e\u8457\u63d0\u5347LLMs\u7684\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u5b9e\u9a8c\u663e\u793a\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\uff0c\u4e3a\u5b66\u4e60\u578b\u63a8\u7406\u51b3\u7b56\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411"}}
{"id": "2602.04101", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04101", "abs": "https://arxiv.org/abs/2602.04101", "authors": ["Harsha Vardhan Khurdula", "Vineet Agarwal", "Yoeven D Khemlani"], "title": "Interfaze: The Future of AI is built on Task-Specific Small Models", "comment": "8 pages, 1 figure", "summary": "We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.\n  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.", "AI": {"tldr": "Interfaze\u662f\u4e00\u4e2a\u5c06LLM\u5e94\u7528\u89c6\u4e3a\u4e0a\u4e0b\u6587\u6784\u5efa\u4e0e\u6267\u884c\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f02\u6784DNN\u5806\u6808\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u5c42\u548c\u52a8\u4f5c\u5c42\uff0c\u7ed3\u5408\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u4ec5\u5c06\u7cbe\u70bc\u4e0a\u4e0b\u6587\u4f20\u9012\u7ed9\u5927\u578bLLM\u751f\u6210\u6700\u7ec8\u54cd\u5e94\u3002", "motivation": "\u4f20\u7edfLLM\u5e94\u7528\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u4efb\u52a1\u3002Interfaze\u65e8\u5728\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5c06\u8ba1\u7b97\u8d1f\u62c5\u4ece\u6602\u8d35\u7684\u5927\u578b\u6a21\u578b\u8f6c\u79fb\u5230\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u6808\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u5c42\uff1a(1) \u611f\u77e5\u6a21\u5757\uff1a\u5f02\u6784DNN\u5806\u6808\u914d\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u5904\u7406OCR\u3001\u590d\u6742PDF\u3001\u56fe\u8868\u3001\u591a\u8bed\u8a00ASR\uff1b(2) \u4e0a\u4e0b\u6587\u6784\u5efa\u5c42\uff1a\u722c\u53d6\u3001\u7d22\u5f15\u3001\u89e3\u6790\u5916\u90e8\u8d44\u6e90\uff08\u7f51\u9875\u3001\u4ee3\u7801\u3001PDF\uff09\u4e3a\u7ed3\u6784\u5316\u72b6\u6001\uff1b(3) \u52a8\u4f5c\u5c42\uff1a\u652f\u6301\u6d4f\u89c8\u3001\u68c0\u7d22\u3001\u6c99\u7bb1\u4ee3\u7801\u6267\u884c\u3001\u65e0\u5934\u6d4f\u89c8\u5668\u9a71\u52a8\u3002\u9876\u5c42\u63a7\u5236\u5668\u51b3\u5b9a\u8fd0\u884c\u54ea\u4e9b\u5c0f\u578b\u6a21\u578b\u548c\u52a8\u4f5c\uff0c\u5e76\u5c06\u7cbe\u70bc\u4e0a\u4e0b\u6587\u4f20\u9012\u7ed9\u7528\u6237\u9009\u62e9\u7684LLM\u3002", "result": "Interfaze-Beta\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aMMLU-Pro 83.6%\u3001MMLU 91.4%\u3001GPQA-Diamond 81.3%\u3001LiveCodeBench v5 57.8%\u3001AIME-2025 90.0%\u3002\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\uff1aMMMU(val) 77.3%\u3001AI2D 91.5%\u3001ChartQA 90.9%\u3001Common Voice v16 90.8%\u3002\u5927\u90e8\u5206\u67e5\u8be2\u7531\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u6808\u5904\u7406\uff0c\u5927\u578bLLM\u4ec5\u64cd\u4f5c\u7cbe\u70bc\u4e0a\u4e0b\u6587\u3002", "conclusion": "Interfaze\u5c55\u793a\u4e86\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u5c06\u8ba1\u7b97\u4ece\u6602\u8d35\u7684\u5927\u578b\u6a21\u578b\u8f6c\u79fb\u5230\u5c0f\u578b\u6a21\u578b\u548c\u5de5\u5177\u6808\u7684\u53ef\u884c\u6027\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4e3aLLM\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04144", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04144", "abs": "https://arxiv.org/abs/2602.04144", "authors": ["Ruiting Dai", "Zheyu Wang", "Haoyu Yang", "Yihan Liu", "Chengzhi Wang", "Zekun Zhang", "Zishan Huang", "Jiaman Cen", "Lisi Mo"], "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows", "comment": null, "summary": "Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict between logical reasoning and signal synthesis that compromises fidelity. In this paper, we present \\textbf{\\underline{O}}mni-\\textbf{\\underline{M}}odality \\textbf{\\underline{G}}eneration Agent (\\textbf{OMG-Agent}), a novel framework that shifts the paradigm from static mapping to a dynamic coarse-to-fine Agentic Workflow. By mimicking a \\textit{deliberate-then-act} cognitive process, OMG-Agent explicitly decouples the task into three synergistic stages: (1) an MLLM-driven Semantic Planner that resolves input ambiguity via Progressive Contextual Reasoning, creating a deterministic structured semantic plan; (2) a non-parametric Evidence Retriever that grounds abstract semantics in external knowledge; and (3) a Retrieval-Injected Executor that utilizes retrieved evidence as flexible feature prompts to overcome rigidity and synthesize high-fidelity details. Extensive experiments on multiple benchmarks demonstrate that OMG-Agent consistently surpasses state-of-the-art methods, maintaining robustness under extreme missingness, e.g., a $2.6$-point gain on CMU-MOSI at $70$\\% missing rates.", "AI": {"tldr": "OMG-Agent\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u8bed\u4e49\u89c4\u5212\u548c\u7ec6\u8282\u5408\u6210\u6765\u89e3\u51b3\u6570\u636e\u4e0d\u5b8c\u6574\u95ee\u9898\uff0c\u5728\u6781\u7aef\u7f3a\u5931\u7387\u4e0b\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u74f6\u9888\uff1a\u4f20\u7edf\u53c2\u6570\u5316/\u751f\u6210\u6a21\u578b\u56e0\u8fc7\u5ea6\u4f9d\u8d56\u5185\u90e8\u8bb0\u5fc6\u800c\u4ea7\u751f\u5e7b\u89c9\uff0c\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\u5219\u53d7\u9650\u4e8e\u68c0\u7d22\u521a\u6027\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u8fd9\u4e9b\u7aef\u5230\u7aef\u67b6\u6784\u53d7\u5230\"\u8bed\u4e49-\u7ec6\u8282\u7ea0\u7f20\"\u7684\u7ed3\u6784\u6027\u51b2\u7a81\u9650\u5236\uff0c\u5373\u903b\u8f91\u63a8\u7406\u548c\u4fe1\u53f7\u5408\u6210\u4e4b\u95f4\u7684\u51b2\u7a81\u635f\u5bb3\u4e86\u4fdd\u771f\u5ea6\u3002", "method": "\u63d0\u51faOMG-Agent\u6846\u67b6\uff0c\u91c7\u7528\u52a8\u6001\u7c97\u5230\u7ec6\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u6a21\u62df\"\u5148\u601d\u8003\u540e\u884c\u52a8\"\u7684\u8ba4\u77e5\u8fc7\u7a0b\u3002\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a1) MLLM\u9a71\u52a8\u7684\u8bed\u4e49\u89c4\u5212\u5668\u901a\u8fc7\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u63a8\u7406\u89e3\u51b3\u8f93\u5165\u6b67\u4e49\uff1b2) \u975e\u53c2\u6570\u5316\u8bc1\u636e\u68c0\u7d22\u5668\u5c06\u62bd\u8c61\u8bed\u4e49\u951a\u5b9a\u5728\u5916\u90e8\u77e5\u8bc6\u4e2d\uff1b3) \u68c0\u7d22\u6ce8\u5165\u6267\u884c\u5668\u5229\u7528\u68c0\u7d22\u8bc1\u636e\u4f5c\u4e3a\u7075\u6d3b\u7279\u5f81\u63d0\u793a\u6765\u5408\u6210\u9ad8\u4fdd\u771f\u7ec6\u8282\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOMG-Agent\u59cb\u7ec8\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u6781\u7aef\u7f3a\u5931\u7387\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4f8b\u5982\u572870%\u7f3a\u5931\u7387\u4e0bCMU-MOSI\u57fa\u51c6\u4e0a\u83b7\u5f972.6\u5206\u7684\u63d0\u5347\u3002", "conclusion": "OMG-Agent\u901a\u8fc7\u89e3\u8026\u8bed\u4e49\u89c4\u5212\u548c\u7ec6\u8282\u5408\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u4e0d\u5b8c\u6574\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u9ad8\u4fdd\u771f\u7684\u751f\u6210\u6846\u67b6\u3002"}}
{"id": "2602.04210", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04210", "abs": "https://arxiv.org/abs/2602.04210", "authors": ["Enyu Zhou", "Zhiheng Xi", "Long Ma", "Zhihao Zhang", "Shihan Dou", "Zhikai Lei", "Guoteng Wang", "Rui Zheng", "Hang Yan", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Steering LLMs via Scalable Interactive Oversight", "comment": null, "summary": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.", "AI": {"tldr": "\u63d0\u51faScalable Interactive Oversight\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u590d\u6742\u610f\u56fe\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u51b3\u7b56\u6811\u6765\u589e\u5f3a\u4eba\u7c7b\u76d1\u7763\uff0c\u4f7f\u975e\u4e13\u5bb6\u80fd\u751f\u6210\u4e13\u5bb6\u7ea7\u4ea7\u54c1\u9700\u6c42\u6587\u6863\uff0c\u5bf9\u9f50\u5ea6\u63d0\u534754%", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u81ea\u52a8\u5316\u590d\u6742\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u51fa\u73b0\u4e86\u76d1\u7763\u7f3a\u53e3\u3002\u867d\u7136\u6a21\u578b\u64c5\u957f\u6267\u884c\uff0c\u4f46\u7528\u6237\u7531\u4e8e\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4e0d\u8db3\u3001\u96be\u4ee5\u7cbe\u786e\u8868\u8fbe\u610f\u56fe\u3001\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u590d\u6742\u8f93\u51fa\u7b49\u539f\u56e0\uff0c\u96be\u4ee5\u6709\u6548\u6307\u5bfc\u6a21\u578b\u3002\u8fd9\u63d0\u51fa\u4e86\u53ef\u6269\u5c55\u76d1\u7763\u7684\u5173\u952e\u6311\u6218\uff1a\u5982\u4f55\u8ba9\u4eba\u7c7b\u5728\u8d85\u8d8a\u81ea\u8eab\u89c4\u8303\u548c\u9a8c\u8bc1\u80fd\u529b\u7684\u4efb\u52a1\u4e0a\u8d1f\u8d23\u4efb\u5730\u5f15\u5bfcAI\u7cfb\u7edf\u3002", "method": "\u63d0\u51faScalable Interactive Oversight\u6846\u67b6\uff0c\u5c06\u590d\u6742\u610f\u56fe\u5206\u89e3\u4e3a\u9012\u5f52\u7684\u51b3\u7b56\u6811\uff0c\u5728\u8282\u70b9\u5c42\u9762\u6536\u96c6\u4f4e\u8d1f\u62c5\u7684\u4eba\u7c7b\u53cd\u9988\uff0c\u5e76\u9012\u5f52\u805a\u5408\u8fd9\u4e9b\u4fe1\u53f7\u5f62\u6210\u7cbe\u786e\u7684\u5168\u5c40\u6307\u5bfc\u3002\u5728\u7f51\u9875\u5f00\u53d1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ec5\u4f7f\u7528\u5728\u7ebf\u7528\u6237\u53cd\u9988\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u7f51\u9875\u5f00\u53d1\u4efb\u52a1\u4e2d\uff0c\u8be5\u6846\u67b6\u4f7f\u975e\u4e13\u5bb6\u80fd\u591f\u751f\u6210\u4e13\u5bb6\u7ea7\u7684\u4ea7\u54c1\u9700\u6c42\u6587\u6863\uff0c\u5b9e\u73b0\u4e8654%\u7684\u5bf9\u9f50\u5ea6\u63d0\u5347\u3002\u6846\u67b6\u53ef\u4ee5\u901a\u8fc7\u4ec5\u4f7f\u7528\u5728\u7ebf\u7528\u6237\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\uff0c\u4e3aAI\u6269\u5c55\u65f6\u4fdd\u6301\u4eba\u7c7b\u63a7\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002", "conclusion": "Scalable Interactive Oversight\u6846\u67b6\u4e3a\u89e3\u51b3\u53ef\u6269\u5c55\u76d1\u7763\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u89e3\u590d\u6742\u610f\u56fe\u548c\u9012\u5f52\u805a\u5408\u53cd\u9988\uff0c\u4f7f\u4eba\u7c7b\u80fd\u591f\u6709\u6548\u6307\u5bfc\u8d85\u8d8a\u81ea\u8eab\u80fd\u529b\u7684AI\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5b9e\u73b0\u5b9e\u7528\u5316\u8def\u5f84\u3002"}}
{"id": "2602.04213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04213", "abs": "https://arxiv.org/abs/2602.04213", "authors": ["Feiyu Gavin Zhu", "Jean Oh", "Reid Simmons"], "title": "InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons", "comment": "Proceedings of the 21st ACM/IEEE International Conference on Human-Robot Interaction", "summary": "Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy", "AI": {"tldr": "InterPReT\uff1a\u4e00\u79cd\u4ea4\u4e92\u5f0f\u7b56\u7565\u91cd\u6784\u4e0e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8ba9\u666e\u901a\u7528\u6237\u80fd\u591f\u901a\u8fc7\u6307\u4ee4\u548c\u6f14\u793a\u6765\u6559\u5bfcAI\u667a\u80fd\u4f53\uff0c\u964d\u4f4e\u673a\u5668\u5b66\u4e60\u95e8\u69db", "motivation": "\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u9700\u8981\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u5927\u91cf\u6f14\u793a\u6570\u636e\u5e76\u5bc6\u5207\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd9\u5bf9\u666e\u901a\u7528\u6237\u6559\u5bfcAI\u667a\u80fd\u4f53\u65b0\u6280\u80fd\u6784\u6210\u4e86\u969c\u788d\u3002\u9700\u8981\u964d\u4f4e\u6559\u5bfcAI\u667a\u80fd\u4f53\u7684\u95e8\u69db\uff0c\u8ba9\u975e\u6280\u672f\u80cc\u666f\u7684\u7ec8\u7aef\u7528\u6237\u4e5f\u80fd\u8bad\u7ec3\u53ef\u9760\u7684\u7b56\u7565", "method": "\u63d0\u51faInteractive Policy Restructuring and Training (InterPReT)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528\u6237\u6307\u4ee4\u6301\u7eed\u66f4\u65b0\u7b56\u7565\u7ed3\u6784\u5e76\u4f18\u5316\u53c2\u6570\u4ee5\u9002\u5e94\u7528\u6237\u6f14\u793a\uff0c\u652f\u6301\u7528\u6237\u4ea4\u4e92\u5f0f\u63d0\u4f9b\u6307\u4ee4\u548c\u6f14\u793a\u3001\u76d1\u63a7\u667a\u80fd\u4f53\u6027\u80fd\u3001\u5ba1\u67e5\u51b3\u7b56\u7b56\u7565", "result": "\u5728\u8d5b\u8f66\u6e38\u620f\u4e2d\u6559\u5bfcAI\u667a\u80fd\u4f53\u9a7e\u9a76\u7684\u7528\u6237\u7814\u7a76\uff08N=34\uff09\u8868\u660e\uff0c\u4e0e\u901a\u7528\u6a21\u4eff\u5b66\u4e60\u57fa\u7ebf\u76f8\u6bd4\uff0cInterPReT\u80fd\u4ea7\u751f\u66f4\u9c81\u68d2\u7684\u7b56\u7565\u4e14\u4e0d\u5f71\u54cd\u7cfb\u7edf\u53ef\u7528\u6027\uff0c\u7279\u522b\u9002\u5408\u666e\u901a\u7528\u6237\u540c\u65f6\u63d0\u4f9b\u6f14\u793a\u548c\u51b3\u5b9a\u4f55\u65f6\u505c\u6b62\u8bad\u7ec3\u7684\u573a\u666f", "conclusion": "InterPReT\u65b9\u6cd5\u66f4\u9002\u5408\u6ca1\u6709\u673a\u5668\u5b66\u4e60\u6280\u672f\u80cc\u666f\u7684\u7ec8\u7aef\u7528\u6237\u8bad\u7ec3\u53ef\u9760\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u6559\u5b66\u964d\u4f4e\u4e86AI\u667a\u80fd\u4f53\u8bad\u7ec3\u7684\u95e8\u69db"}}
{"id": "2602.04248", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04248", "abs": "https://arxiv.org/abs/2602.04248", "authors": ["Hao Lu", "Haoyuan Huang", "Yulin Zhou", "Chen Li", "Ningxin Zhu"], "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "comment": "9 pages, 5 figures", "summary": "Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.", "AI": {"tldr": "Empirical-MCTS\uff1a\u5c06\u65e0\u72b6\u6001MCTS\u8f6c\u53d8\u4e3a\u6301\u7eed\u5b66\u4e60\u7684\u53cc\u5faa\u73af\u6846\u67b6\uff0c\u901a\u8fc7PE-EMP\u548c\u8bb0\u5fc6\u4f18\u5316\u4ee3\u7406\u5b9e\u73b0\u7ecf\u9a8c\u79ef\u7d2f\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u63a8\u7406\u80fd\u529b", "motivation": "\u5f53\u524d\u63a8\u7406\u65f6\u6269\u5c55\u7b56\u7565\uff08\u5982MCTS\uff09\u4e3b\u8981\u662f\u65e0\u72b6\u6001\u7684\uff0c\u6bcf\u6b21\u89e3\u51b3\u95ee\u9898\u540e\u4e22\u5f03\u6210\u529f\u63a8\u7406\u6a21\u5f0f\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u90a3\u6837\u79ef\u7d2f\u7ecf\u9a8c\u667a\u6167\u3002\u9700\u8981\u5c06\u7ed3\u6784\u5316\u641c\u7d22\u4e0e\u7ecf\u9a8c\u79ef\u7d2f\u76f8\u7ed3\u5408\u6765\u5e94\u5bf9\u590d\u6742\u5f00\u653e\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u63d0\u51faEmpirical-MCTS\u53cc\u5faa\u73af\u6846\u67b6\uff1a1) PE-EMP\u5728\u5c40\u90e8\u641c\u7d22\u4e2d\u4f5c\u4e3a\u53cd\u5c04\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u6210\u5bf9\u53cd\u9988\u52a8\u6001\u5408\u6210\u81ea\u9002\u5e94\u6807\u51c6\u5e76\u5b9e\u65f6\u6f14\u5316\u5143\u63d0\u793a\uff1b2) \u8bb0\u5fc6\u4f18\u5316\u4ee3\u7406\u7ba1\u7406\u5168\u5c40\u5b58\u50a8\u5e93\u4f5c\u4e3a\u52a8\u6001\u7b56\u7565\u5148\u9a8c\uff0c\u4f7f\u7528\u539f\u5b50\u64cd\u4f5c\u8de8\u95ee\u9898\u63d0\u70bc\u9ad8\u8d28\u91cf\u89c1\u89e3", "result": "\u5728AIME25\u3001ARC-AGI-2\u548cMathArena Apex\u7b49\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEmpirical-MCTS\u663e\u8457\u4f18\u4e8e\u65e0\u72b6\u6001MCTS\u7b56\u7565\u548c\u72ec\u7acb\u7ecf\u9a8c\u9a71\u52a8\u4ee3\u7406", "conclusion": "\u7ed3\u6784\u5316\u641c\u7d22\u4e0e\u7ecf\u9a8c\u79ef\u7d2f\u7684\u8026\u5408\u5bf9\u4e8e\u638c\u63e1\u590d\u6742\u5f00\u653e\u63a8\u7406\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0cEmpirical-MCTS\u8bc1\u660e\u4e86\u5c06\u65e0\u72b6\u6001\u641c\u7d22\u8f6c\u53d8\u4e3a\u6301\u7eed\u975e\u53c2\u6570\u5b66\u4e60\u8fc7\u7a0b\u7684\u6709\u6548\u6027"}}
{"id": "2602.04284", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04284", "abs": "https://arxiv.org/abs/2602.04284", "authors": ["Yansong Ning", "Jun Fang", "Naiqiang Tan", "Hao Liu"], "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning", "comment": "Under Review", "summary": "Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.", "AI": {"tldr": "Agent-Omit\u662f\u4e00\u4e2a\u8bad\u7ec3\u6846\u67b6\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u9002\u5e94\u5730\u7701\u7565\u5197\u4f59\u7684\u601d\u8003\u548c\u89c2\u5bdf\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u6574\u4e2a\u4ea4\u4e92\u8f68\u8ff9\u540c\u7b49\u5bf9\u5f85\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u56de\u5408\u4e2d\u601d\u8003\u5fc5\u8981\u6027\u548c\u89c2\u5bdf\u6548\u7528\u7684\u5dee\u5f02\uff0c\u5bfc\u81f4\u667a\u80fd\u4f53\u6548\u7387\u4f4e\u4e0b\u3002", "method": "1) \u5408\u6210\u5c11\u91cf\u51b7\u542f\u52a8\u6570\u636e\uff08\u5355\u56de\u5408\u548c\u591a\u56de\u5408\u7701\u7565\u573a\u666f\uff09\u5fae\u8c03\u667a\u80fd\u4f53\uff1b2) \u63d0\u51fa\u7701\u7565\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u542b\u53cc\u91cd\u91c7\u6837\u673a\u5236\u548c\u5b9a\u5236\u5316\u7701\u7565\u5956\u52b1\uff1b3) \u7406\u8bba\u8bc1\u660e\u7701\u7565\u7b56\u7565\u7684\u504f\u5dee\u6709KL\u6563\u5ea6\u4e0a\u754c\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent-Omit-8B\u6a21\u578b\u6027\u80fd\u4e0e\u4e03\u4e2a\u524d\u6cbfLLM\u667a\u80fd\u4f53\u76f8\u5f53\uff0c\u5728\u4e03\u4e2a\u9ad8\u6548LLM\u667a\u80fd\u4f53\u65b9\u6cd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f73\u7684\u6709\u6548\u6027-\u6548\u7387\u6743\u8861\u3002", "conclusion": "Agent-Omit\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u7701\u7565\u5197\u4f59\u601d\u8003\u548c\u89c2\u5bdf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\uff0c\u4e3a\u667a\u80fd\u4f53\u6548\u7387\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04326", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04326", "abs": "https://arxiv.org/abs/2602.04326", "authors": ["SeungWon Seo", "SooBin Lim", "SeongRae Noh", "Haneul Kim", "HyeongYeop Kang"], "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents", "comment": "31 pages, 10 figures, Accepted ICLR 2026", "summary": "Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.", "AI": {"tldr": "PCE\u6846\u67b6\u5c06LLM\u63a8\u7406\u4e2d\u7684\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u89c4\u5212\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u4e3b\u8981\u4f9d\u8d56\u9891\u7e41\u901a\u4fe1\u6765\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u8fd9\u5e26\u6765\u9ad8\u6602\u7684token\u548c\u65f6\u95f4\u6210\u672c\uff0c\u4e14\u53ef\u80fd\u5e72\u6270\u4eba\u7c7b\u534f\u4f5c\u4f19\u4f34\u7684\u5de5\u4f5c\u6d41\u7a0b", "method": "\u63d0\u51faPlanner-Composer-Evaluator\u6846\u67b6\uff1aPlanner\u751f\u6210\u63a8\u7406\u8f68\u8ff9\uff0cComposer\u5c06\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff08\u5185\u90e8\u8282\u70b9\u7f16\u7801\u73af\u5883\u5047\u8bbe\uff0c\u53f6\u5b50\u8282\u70b9\u5bf9\u5e94\u52a8\u4f5c\uff09\uff0cEvaluator\u57fa\u4e8e\u573a\u666f\u53ef\u80fd\u6027\u3001\u76ee\u6807\u5bfc\u5411\u6536\u76ca\u548c\u6267\u884c\u6210\u672c\u5bf9\u8def\u5f84\u8bc4\u5206", "result": "\u5728\u4e24\u4e2a\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\uff08C-WAH\u548cTDW-MAT\uff09\u548c\u4e09\u79cdLLM\u9aa8\u5e72\u4e0a\uff0cPCE\u5728\u6210\u529f\u7387\u548c\u4efb\u52a1\u6548\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u901a\u4fe1\u5bc6\u96c6\u578b\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684token\u4f7f\u7528\u91cf\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660ePCE\u7684\u6027\u80fd\u589e\u76ca\u5728\u4e0d\u540c\u6a21\u578b\u5bb9\u91cf\u548c\u63a8\u7406\u6df1\u5ea6\u4e0b\u90fd\u6709\u6548", "conclusion": "PCE\u4e3a\u5c06LLM\u7684\u9690\u542b\u5047\u8bbe\u8f6c\u5316\u4e3a\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u89c4\u5212\u7b56\u7565\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u9014\u5f84\uff0c\u4ea7\u751f\u7684\u901a\u4fe1\u6a21\u5f0f\u88ab\u4eba\u7c7b\u4f19\u4f34\u8ba4\u4e3a\u66f4\u9ad8\u6548\u548c\u53ef\u4fe1"}}
{"id": "2602.04385", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.04385", "abs": "https://arxiv.org/abs/2602.04385", "authors": ["Marco Picone", "Fabio Turazza", "Matteo Martinelli", "Marco Mamei"], "title": "Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications", "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE International Conference on Systems, Man and Cybernetics (IEEE SMC), October 2025, doi: 10.1109/SMC58881.2025.11343418", "summary": "The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u96f6\u914d\u7f6eAI\u7ba1\u9053\u6846\u67b6\uff0c\u89e3\u51b3\u5de5\u4e1aCPS\u4e2dAI/ML\u96c6\u6210\u788e\u7247\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u667a\u80fd\u670d\u52a1\u90e8\u7f72", "motivation": "\u5de5\u4e1aCPS\u65e5\u76ca\u590d\u6742\uff0c\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u6280\u672f\u788e\u7247\u5316\uff08\u901a\u4fe1\u534f\u8bae\u3001\u6570\u636e\u683c\u5f0f\u3001\u8bbe\u5907\u80fd\u529b\u5dee\u5f02\uff09\u5bfc\u81f4\u7269\u7406\u5c42\u4e0e\u667a\u80fd\u529f\u80fd\u5c42\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u9e3f\u6c9f\u3002\u73b0\u6709\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u5f80\u5f80\u5b64\u7acb\u4e14\u7d27\u8026\u5408\uff0c\u9650\u5236\u4e86AI\u529f\u80fd\u7684\u53ef\u6269\u5c55\u6027\u548c\u91cd\u7528\u6027\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u914d\u7f6e\u548c\u89e3\u8026\u6570\u5b57\u5b6a\u751f\u4e0eAI\u7ec4\u4ef6\u89d2\u8272\uff0c\u5b9e\u73b0AI\u7ba1\u9053\u65e0\u7f1d\u96c6\u6210\u3002\u5f15\u5165\u96f6\u914d\u7f6eAI\u7ba1\u9053\u6982\u5ff5\uff0c\u7531\u6570\u5b57\u5b6a\u751f\u534f\u8c03\u6570\u636e\u7ba1\u7406\u548c\u667a\u80fd\u589e\u5f3a\u3002\u5728\u5fae\u5de5\u5382\u573a\u666f\u4e2d\u6f14\u793a\uff0c\u652f\u6301\u5e76\u53d1ML\u6a21\u578b\u548c\u52a8\u6001\u6570\u636e\u5904\u7406\u3002", "result": "\u5728\u5fae\u5de5\u5382\u573a\u666f\u4e2d\u6210\u529f\u6f14\u793a\u4e86\u8be5\u6846\u67b6\uff0c\u652f\u6301\u5e76\u53d1ML\u6a21\u578b\u548c\u52a8\u6001\u6570\u636e\u5904\u7406\uff0c\u6709\u6548\u52a0\u901f\u4e86\u590d\u6742\u5de5\u4e1a\u73af\u5883\u4e2d\u667a\u80fd\u670d\u52a1\u7684\u90e8\u7f72\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u96f6\u914d\u7f6eAI\u7ba1\u9053\u6846\u67b6\u80fd\u591f\u89e3\u51b3\u5de5\u4e1aCPS\u4e2dAI/ML\u96c6\u6210\u788e\u7247\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u3001\u89e3\u8026\u7684\u8bbe\u8ba1\u5b9e\u73b0\u667a\u80fd\u670d\u52a1\u7684\u5feb\u901f\u90e8\u7f72\u548c\u6269\u5c55\uff0c\u4e3a\u590d\u6742\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u667a\u80fd\u7cfb\u7edf\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.04496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04496", "abs": "https://arxiv.org/abs/2602.04496", "authors": ["Zhentao Tang", "Yuqi Cui", "Shixiong Kai", "Wenqian Zhao", "Ke Ye", "Xing Li", "Anxin Tian", "Zehua Pei", "Hui-Ling Zhen", "Shoubo Hu", "Xiaoguang Li", "Yunhe Wang", "Mingxuan Yuan"], "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control", "comment": null, "summary": "Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.", "AI": {"tldr": "ReThinker\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7Solver-Critic-Selector\u67b6\u6784\u5b9e\u73b0\u52a8\u6001\u8ba1\u7b97\u5206\u914d\uff0c\u5728\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\uff08\u5982Humanity's Last Exam\uff09\u4e0a\u5b58\u5728\u6311\u6218\uff1a\u56fa\u5b9a\u5de5\u5177\u6d41\u6c34\u7ebf\u3001\u8106\u5f31\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u3001\u4f4e\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u9650\u5236\u4e86\u6027\u80fd", "method": "\u63d0\u51faReThinker\u6846\u67b6\uff0c\u91c7\u7528Solver-Critic-Selector\u4e09\u9636\u6bb5\u67b6\u6784\uff0c\u57fa\u4e8e\u6a21\u578b\u7f6e\u4fe1\u5ea6\u52a8\u6001\u5206\u914d\u8ba1\u7b97\uff1b\u5f00\u53d1\u53cd\u5411\u6570\u636e\u5408\u6210\u6d41\u6c34\u7ebf\u548c\u81ea\u9002\u5e94\u8f68\u8ff9\u56de\u6536\u7b56\u7565\uff0c\u4ece\u6210\u529f\u63a8\u7406\u8f68\u8ff9\u751f\u6210\u9ad8\u8d28\u91cf\u76d1\u7763\u6570\u636e", "result": "\u5728HLE\u3001GAIA\u548cXBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReThinker\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u57fa\u7840\u6a21\u578b\u548c\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u5728\u4e13\u5bb6\u7ea7\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c", "conclusion": "ReThinker\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u5408\u6210\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e13\u5bb6\u7ea7\u79d1\u5b66\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u4f53\u6846\u67b6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2602.04572", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.04572", "abs": "https://arxiv.org/abs/2602.04572", "authors": ["Niv Fono", "Yftah Ziser", "Omer Ben-Porat"], "title": "From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums", "comment": null, "summary": "While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5e8f\u5217\u4ea4\u4e92\u6846\u67b6\uff0c\u8ba9GenAI\u7cfb\u7edf\u5411\u8bba\u575b\u63d0\u95ee\uff0c\u8bba\u575b\u53ef\u4ee5\u9009\u62e9\u53d1\u5e03\u90e8\u5206\u95ee\u9898\uff0c\u89e3\u51b3AI\u4f9d\u8d56\u8bba\u575b\u6570\u636e\u5374\u5206\u6d41\u7528\u6237\u7684\u77db\u76fe", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4f9d\u8d56\u95ee\u7b54\u8bba\u575b\u7684\u6570\u636e\u6765\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u540c\u65f6\u5374\u5206\u6d41\u4e86\u8bba\u575b\u7528\u6237\uff0c\u5f62\u6210\u4e86\u6096\u8bba\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u4f9d\u8d56\u4e0e\u7ade\u4e89\u7684\u77db\u76fe\uff0c\u4fc3\u8fdbAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u7684\u53ef\u6301\u7eed\u534f\u4f5c\u3002", "method": "\u63d0\u51fa\u5e8f\u5217\u4ea4\u4e92\u6846\u67b6\uff0c\u8003\u8651\u975e\u8d27\u5e01\u4ea4\u6362\u3001\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6fc0\u52b1\u9519\u914d\u7b49\u590d\u6742\u56e0\u7d20\u3002\u4f7f\u7528\u771f\u5b9e\u7684Stack Exchange\u6570\u636e\u548c\u5e38\u7528LLM\u8fdb\u884c\u5168\u9762\u7684\u6570\u636e\u9a71\u52a8\u6a21\u62df\u3002", "result": "\u5b9e\u8bc1\u5c55\u793a\u4e86\u6fc0\u52b1\u9519\u914d\u95ee\u9898\uff0c\u4f46\u663e\u793a\u53c2\u4e0e\u8005\u4ecd\u80fd\u83b7\u5f97\u7406\u60f3\u5168\u4fe1\u606f\u573a\u666f\u4e0b\u7ea6\u4e00\u534a\u7684\u6548\u7528\u3002\u7ed3\u679c\u7a81\u51fa\u4e86AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u53ef\u6301\u7eed\u534f\u4f5c\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u77e5\u8bc6\u5e73\u53f0\u4e4b\u95f4\u7684\u53ef\u6301\u7eed\u534f\u4f5c\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u80fd\u591f\u4fdd\u6301\u6709\u6548\u7684\u77e5\u8bc6\u5171\u4eab\uff0c\u89e3\u51b3\u4f9d\u8d56\u4e0e\u7ade\u4e89\u7684\u77db\u76fe\u3002"}}
{"id": "2602.04575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04575", "abs": "https://arxiv.org/abs/2602.04575", "authors": ["Jiaheng Liu", "Yuanxing Zhang", "Shihao Li", "Xinping Lei"], "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration", "comment": null, "summary": "For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \\textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.\n  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVibe AIGC\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7f16\u6392\u89e3\u51b3\u5f53\u524d\u751f\u6210\u5f0fAI\u7684\u610f\u56fe-\u6267\u884c\u9e3f\u6c9f\u95ee\u9898\uff0c\u5c06\u7528\u6237\u4ece\u63d0\u793a\u5de5\u7a0b\u8f6c\u53d8\u4e3a\u63d0\u4f9b\u9ad8\u5c42\"\u6c1b\u56f4\"\u7684\u6307\u6325\u5b98\uff0c\u7531\u5143\u89c4\u5212\u5668\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0fAI\u53d7\u6a21\u578b\u4e2d\u5fc3\u8303\u5f0f\u4e3b\u5bfc\uff0c\u867d\u7136\u89c6\u89c9\u4fdd\u771f\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5b58\u5728\"\u53ef\u7528\u6027\u5929\u82b1\u677f\"\u95ee\u9898\uff0c\u8868\u73b0\u4e3a\u610f\u56fe-\u6267\u884c\u9e3f\u6c9f\u2014\u2014\u7528\u6237\u9ad8\u5c42\u610f\u56fe\u4e0e\u5f53\u524d\u5355\u6b21\u751f\u6210\u6a21\u578b\u7684\u968f\u673a\u6027\u3001\u9ed1\u76d2\u7279\u6027\u4e4b\u95f4\u7684\u6839\u672c\u5dee\u8ddd\u3002", "method": "\u63d0\u51faVibe AIGC\u8303\u5f0f\uff0c\u53d7Vibe Coding\u542f\u53d1\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7f16\u6392\u5b9e\u73b0\u5185\u5bb9\u751f\u6210\u3002\u7528\u6237\u4f5c\u4e3a\u6307\u6325\u5b98\u63d0\u4f9b\"\u6c1b\u56f4\"\uff08\u5305\u542b\u7f8e\u5b66\u504f\u597d\u3001\u529f\u80fd\u903b\u8f91\u7b49\u9ad8\u5c42\u8868\u793a\uff09\uff0c\u96c6\u4e2d\u5f0f\u5143\u89c4\u5212\u5668\u4f5c\u4e3a\u7cfb\u7edf\u67b6\u6784\u5e08\uff0c\u5c06\"\u6c1b\u56f4\"\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u3001\u53ef\u9a8c\u8bc1\u3001\u81ea\u9002\u5e94\u7684\u667a\u80fd\u4f53\u7ba1\u9053\u3002", "result": "\u901a\u8fc7\u4ece\u968f\u673a\u63a8\u7406\u8f6c\u5411\u903b\u8f91\u7f16\u6392\uff0cVibe AIGC\u5f25\u5408\u4e86\u4eba\u7c7b\u60f3\u8c61\u529b\u4e0e\u673a\u5668\u6267\u884c\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u5c06AI\u4ece\u8106\u5f31\u7684\u63a8\u7406\u5f15\u64ce\u8f6c\u53d8\u4e3a\u5f3a\u5927\u7684\u7cfb\u7edf\u5de5\u7a0b\u5408\u4f5c\u4f19\u4f34\u3002", "conclusion": "\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u5c06\u91cd\u65b0\u5b9a\u4e49\u4eba\u673a\u534f\u4f5c\u7ecf\u6d4e\uff0c\u4f7f\u590d\u6742\u3001\u957f\u5468\u671f\u7684\u6570\u5b57\u8d44\u4ea7\u521b\u4f5c\u6c11\u4e3b\u5316\uff0c\u4e3a\u751f\u6210\u5f0fAI\u5f00\u8f9f\u65b0\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2602.04634", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.04634", "abs": "https://arxiv.org/abs/2602.04634", "authors": ["Zelai Xu", "Zhexuan Xu", "Ruize Zhang", "Chunyang Zhu", "Shi Yu", "Weilin Liu", "Quanlu Zhang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faWideSeek-R1\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5bbd\u5ea6\u6269\u5c55\u89e3\u51b3\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\uff0c\u4f7f\u75284B\u53c2\u6570\u8fbe\u5230\u4e0e671B\u5355\u667a\u80fd\u4f53\u76f8\u5f53\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u4e3b\u8981\u5173\u6ce8\u6df1\u5ea6\u6269\u5c55\uff08\u5355\u667a\u80fd\u4f53\u89e3\u51b3\u957f\u65f6\u7a0b\u95ee\u9898\uff09\uff0c\u4f46\u968f\u7740\u4efb\u52a1\u8303\u56f4\u6269\u5927\uff0c\u74f6\u9888\u4ece\u4e2a\u4f53\u80fd\u529b\u8f6c\u5411\u7ec4\u7ec7\u80fd\u529b\u3002\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u624b\u5de5\u5de5\u4f5c\u6d41\u548c\u8f6e\u6d41\u4ea4\u4e92\uff0c\u65e0\u6cd5\u6709\u6548\u5e76\u884c\u5de5\u4f5c\u3002", "method": "\u63d0\u51faWideSeek-R1\u6846\u67b6\uff1a\u9886\u5bfc\u667a\u80fd\u4f53-\u5b50\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7f16\u6392\u548c\u5e76\u884c\u6267\u884c\u3002\u4f7f\u7528\u5171\u4eabLLM\u4f46\u9694\u79bb\u4e0a\u4e0b\u6587\u548c\u4e13\u7528\u5de5\u5177\uff0c\u57282\u4e07\u6761\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u6570\u636e\u96c6\u4e0a\u8054\u5408\u4f18\u5316\u3002", "result": "WideSeek-R1-4B\u5728WideSearch\u57fa\u51c6\u4e0a\u8fbe\u523040.0%\u7684\u9879\u76eeF1\u5206\u6570\uff0c\u4e0e\u5355\u667a\u80fd\u4f53DeepSeek-R1-671B\u6027\u80fd\u76f8\u5f53\u3002\u968f\u7740\u5e76\u884c\u5b50\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5bbd\u5ea6\u6269\u5c55\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5bbd\u5ea6\u6269\u5c55\u662f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u91cd\u8981\u65b9\u5411\uff0cWideSeek-R1\u6846\u67b6\u901a\u8fc7MARL\u8bad\u7ec3\u5b9e\u73b0\u4e86\u9ad8\u6548\u5e76\u884c\u6267\u884c\uff0c\u4e3a\u5904\u7406\u5e7f\u6cdb\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.04813", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.04813", "abs": "https://arxiv.org/abs/2602.04813", "authors": ["Shubham Vatsal", "Harsh Dubey", "Aditi Singh"], "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents", "comment": null, "summary": "Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e03\u7ef4\u5206\u7c7b\u6cd5\uff08\u8ba4\u77e5\u80fd\u529b\u3001\u77e5\u8bc6\u7ba1\u7406\u3001\u4ea4\u4e92\u6a21\u5f0f\u3001\u9002\u5e94\u4e0e\u5b66\u4e60\u3001\u5b89\u5168\u4e0e\u4f26\u7406\u3001\u6846\u67b6\u7c7b\u578b\u5b66\u3001\u6838\u5fc3\u4efb\u52a1\u4e0e\u5b50\u4efb\u52a1\uff09\u7cfb\u7edf\u5206\u6790\u4e8649\u9879LLM\u533b\u7597\u4ee3\u7406\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u80fd\u529b\u5b9e\u73b0\u7684\u4e0d\u5bf9\u79f0\u6027\uff1a\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u666e\u904d\u5b9e\u73b0\uff0c\u800c\u4e8b\u4ef6\u89e6\u53d1\u6fc0\u6d3b\u3001\u6f02\u79fb\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7b49\u80fd\u529b\u4e25\u91cd\u7f3a\u5931\u3002", "motivation": "\u73b0\u6709LLM\u533b\u7597\u4ee3\u7406\u7814\u7a76\u591a\u4e3a\u6982\u8ff0\u6027\u8c03\u67e5\u6216\u5355\u4e00\u80fd\u529b\u63a2\u8ba8\uff0c\u7f3a\u4e4f\u7edf\u4e00\u5206\u6790\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5206\u7c7b\u6cd5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u533b\u7597\u9886\u57df\u63d0\u4f9b\u5171\u540c\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u91c7\u7528\u4e03\u7ef4\u5206\u7c7b\u6cd5\uff08\u542b29\u4e2a\u64cd\u4f5c\u5b50\u7ef4\u5ea6\uff09\uff0c\u5bf949\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002\u4f7f\u7528\u660e\u786e\u7684\u7eb3\u5165\u6392\u9664\u6807\u51c6\u548c\u4e09\u7ea7\u6807\u7b7e\uff08\u5b8c\u5168\u5b9e\u73b0\u3001\u90e8\u5206\u5b9e\u73b0\u3001\u672a\u5b9e\u73b0\uff09\uff0c\u91cf\u5316\u80fd\u529b\u5206\u5e03\u548c\u5171\u73b0\u6a21\u5f0f\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u660e\u663e\u7684\u4e0d\u5bf9\u79f0\u6027\uff1a\u77e5\u8bc6\u7ba1\u7406\u4e2d\u7684\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u666e\u904d\u5b9e\u73b0\uff08~76%\u5b8c\u5168\u5b9e\u73b0\uff09\uff0c\u800c\u4ea4\u4e92\u6a21\u5f0f\u4e2d\u7684\u4e8b\u4ef6\u89e6\u53d1\u6fc0\u6d3b\u57fa\u672c\u7f3a\u5931\uff08~92%\u672a\u5b9e\u73b0\uff09\uff0c\u9002\u5e94\u5b66\u4e60\u4e2d\u7684\u6f02\u79fb\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7f55\u89c1\uff08~98%\u672a\u5b9e\u73b0\uff09\u3002\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u662f\u4e3b\u5bfc\u67b6\u6784\u6a21\u5f0f\uff08~82%\u5b8c\u5168\u5b9e\u73b0\uff09\uff0c\u4fe1\u606f\u4e2d\u5fc3\u80fd\u529b\uff08\u5982\u533b\u7597\u95ee\u7b54\u4e0e\u51b3\u7b56\u652f\u6301\uff09\u9886\u5148\uff0c\u800c\u6cbb\u7597\u89c4\u5212\u4e0e\u5904\u65b9\u7b49\u884c\u52a8\u5bfc\u5411\u9886\u57df\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff08~59%\u672a\u5b9e\u73b0\uff09\u3002", "conclusion": "LLM\u533b\u7597\u4ee3\u7406\u7814\u7a76\u5728\u80fd\u529b\u5b9e\u73b0\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u5e73\u8861\uff0c\u5f53\u524d\u7814\u7a76\u504f\u5411\u4fe1\u606f\u5904\u7406\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u800c\u5b9e\u65f6\u54cd\u5e94\u3001\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u884c\u52a8\u5bfc\u5411\u4efb\u52a1\u7b49\u5173\u952e\u533b\u7597\u9700\u6c42\u4ecd\u5f85\u89e3\u51b3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.04836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04836", "abs": "https://arxiv.org/abs/2602.04836", "authors": ["Haosen Ge", "Hamsa Bastani", "Osbert Bastani"], "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis", "comment": null, "summary": "Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53cd\u9a73METR\u62a5\u544a\u4e2dAI\u80fd\u529b\u5448\u6307\u6570\u589e\u957f\u7684\u8bba\u70b9\uff0c\u8ba4\u4e3a\u6570\u636e\u4e0d\u652f\u6301\u6307\u6570\u589e\u957f\uff0c\u4e14\u62d0\u70b9\u5df2\u8fc7\uff0c\u5f3a\u8c03\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u9488\u5bf9METR\u62a5\u544a\u58f0\u79f0AI\u80fd\u529b\u81ea2019\u5e74\u4ee5\u6765\u5448\u6307\u6570\u589e\u957f\u7684\u89c2\u70b9\uff0c\u4f5c\u8005\u65e8\u5728\u8d28\u7591\u8fd9\u79cd\u9884\u6d4b\u7684\u53ef\u9760\u6027\uff0c\u6307\u51fa\u73b0\u6709\u6570\u636e\u5e76\u4e0d\u652f\u6301\u6307\u6570\u589e\u957f\u5047\u8bbe\uff0c\u4ee5\u7ea0\u6b63\u5bf9AI\u53d1\u5c55\u901f\u5ea6\u7684\u8fc7\u5ea6\u4e50\u89c2\u9884\u671f\u3002", "method": "1. \u5bf9METR\u6570\u636e\u62df\u5408S\u578b/\u903b\u8f91\u66f2\u7ebf\uff0c\u53d1\u73b0\u62d0\u70b9\u5df2\u8fc7\u800c\u975e\u5728\u672a\u6765\uff1b2. \u63d0\u51fa\u66f4\u590d\u6742\u7684\u6a21\u578b\uff0c\u5c06AI\u80fd\u529b\u5206\u89e3\u4e3a\u57fa\u7840\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5206\u522b\u5206\u6790\u5176\u6539\u8fdb\u901f\u7387\uff1b3. \u901a\u8fc7\u6a21\u578b\u8bc1\u660eAI\u80fd\u529b\u5c06\u5728\u8fd1\u671f\u51fa\u73b0\u62d0\u70b9\u3002", "result": "1. \u903b\u8f91\u66f2\u7ebf\u62df\u5408\u663e\u793aAI\u80fd\u529b\u589e\u957f\u7684\u62d0\u70b9\u5df2\u7ecf\u8fc7\u53bb\uff0c\u800c\u975eMETR\u9884\u6d4b\u7684\u9065\u8fdc\u672a\u6765\uff1b2. \u5206\u89e3\u6a21\u578b\u652f\u6301AI\u80fd\u529b\u5c06\u5728\u8fd1\u671f\u51fa\u73b0\u62d0\u70b9\u7684\u5047\u8bbe\uff1b3. \u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u7f3a\u4e4f\u7a33\u5065\u6027\u3002", "conclusion": "AI\u80fd\u529b\u589e\u957f\u5e76\u975e\u6307\u6570\u578b\uff0c\u73b0\u6709\u6307\u6570\u589e\u957f\u9884\u6d4b\u5177\u6709\u8106\u5f31\u6027\uff0c\u9700\u8981\u66f4\u8c28\u614e\u7684\u9884\u6d4b\u65b9\u6cd5\uff0cAI\u53d1\u5c55\u53ef\u80fd\u5df2\u8fdb\u5165\u589e\u957f\u653e\u7f13\u9636\u6bb5\u3002"}}
{"id": "2602.04837", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04837", "abs": "https://arxiv.org/abs/2602.04837", "authors": ["Zhaotian Weng", "Antonis Antoniades", "Deepak Nathani", "Zhen Zhang", "Xiao Pu", "Xin Eric Wang"], "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing", "comment": "18 pages", "summary": "Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.", "AI": {"tldr": "GEA\uff08\u7fa4\u4f53\u6f14\u5316\u667a\u80fd\u4f53\uff09\u662f\u4e00\u79cd\u65b0\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u4f53\u7fa4\u4f53\u4f5c\u4e3a\u57fa\u672c\u6f14\u5316\u5355\u5143\uff0c\u901a\u8fc7\u7fa4\u4f53\u5185\u7ecf\u9a8c\u5171\u4eab\u548c\u91cd\u7528\uff0c\u663e\u8457\u63d0\u5347\u7f16\u7801\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u5f0f\u81ea\u6211\u6f14\u5316\u8303\u5f0f\u91c7\u7528\u6811\u72b6\u7ed3\u6784\u6f14\u5316\uff0c\u5bfc\u81f4\u63a2\u7d22\u591a\u6837\u6027\u5229\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u5404\u6f14\u5316\u5206\u652f\u5b64\u7acb\u53d1\u5c55\uff0c\u65e0\u6cd5\u6709\u6548\u5171\u4eab\u7ecf\u9a8c\u3002\u9700\u8981\u4e00\u79cd\u65b0\u8303\u5f0f\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u81ea\u6211\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u7fa4\u4f53\u6f14\u5316\u667a\u80fd\u4f53\uff08GEA\uff09\u8303\u5f0f\uff0c\u5c06\u667a\u80fd\u4f53\u7fa4\u4f53\u4f5c\u4e3a\u57fa\u672c\u6f14\u5316\u5355\u5143\uff0c\u5728\u6f14\u5316\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u663e\u5f0f\u7684\u7ecf\u9a8c\u5171\u4eab\u548c\u91cd\u7528\u3002\u76f8\u6bd4\u6811\u72b6\u6f14\u5316\u7ed3\u6784\uff0cGEA\u901a\u8fc7\u7fa4\u4f53\u534f\u4f5c\u514b\u670d\u4e86\u63a2\u7d22\u591a\u6837\u6027\u5229\u7528\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "result": "\u5728\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u81ea\u6211\u6f14\u5316\u65b9\u6cd5\uff08SWE-bench Verified\uff1a71.0% vs 56.7%\uff1bPolyglot\uff1a88.3% vs 68.3%\uff09\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u9876\u7ea7\u4eba\u5de5\u8bbe\u8ba1\u7684\u667a\u80fd\u4f53\u6846\u67b6\u3002GEA\u80fd\u66f4\u6709\u6548\u5730\u5c06\u65e9\u671f\u63a2\u7d22\u591a\u6837\u6027\u8f6c\u5316\u4e3a\u957f\u671f\u8fdb\u6b65\uff0c\u5728\u4e0d\u540c\u7f16\u7801\u6a21\u578b\u95f4\u5177\u6709\u4e00\u81f4\u7684\u8fc1\u79fb\u6027\uff0c\u4fee\u590d\u6846\u67b6\u7ea7bug\u5e73\u5747\u53ea\u97001.4\u6b21\u8fed\u4ee3\uff08\u81ea\u6211\u6f14\u5316\u65b9\u6cd5\u9700\u89815\u6b21\uff09\u3002", "conclusion": "GEA\u901a\u8fc7\u7fa4\u4f53\u4f5c\u4e3a\u6f14\u5316\u5355\u5143\u548c\u663e\u5f0f\u7ecf\u9a8c\u5171\u4eab\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\uff0c\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3001\u5f3a\u9c81\u68d2\u6027\u548c\u826f\u597d\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.04843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.04843", "abs": "https://arxiv.org/abs/2602.04843", "authors": ["Dmitrii Kharlapenko", "Alessandro Stolfo", "Arthur Conmy", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Fluid Representations in Reasoning Models", "comment": null, "summary": "Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.", "AI": {"tldr": "QwQ-32B\u6a21\u578b\u901a\u8fc7\u63a8\u7406\u8fc7\u7a0b\u9010\u6b65\u4f18\u5316\u5185\u90e8\u8868\u5f81\uff0c\u53d1\u5c55\u51fa\u5173\u6ce8\u7ed3\u6784\u800c\u975e\u5177\u4f53\u52a8\u4f5c\u540d\u79f0\u7684\u62bd\u8c61\u7f16\u7801\uff0c\u8fd9\u79cd\"\u6d41\u4f53\u63a8\u7406\u8868\u5f81\"\u662f\u63a8\u7406\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\u3002", "motivation": "\u5c3d\u7ba1\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u62bd\u8c61\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u673a\u5236\u5206\u6790\u7406\u89e3QwQ-32B\u6a21\u578b\u5982\u4f55\u5904\u7406\u62bd\u8c61\u7ed3\u6784\u4fe1\u606f\uff0c\u63ed\u793a\u63a8\u7406\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u5185\u90e8\u673a\u5236\u3002", "method": "\u5728\u8bed\u4e49\u6df7\u6dc6\u7684\u89c4\u5212\u9886\u57dfMystery Blocksworld\u4e0a\uff0c\u5206\u6790QwQ-32B\u6a21\u578b\u7684\u5185\u90e8\u8868\u5f81\u53d8\u5316\uff1b\u901a\u8fc7\u5f15\u5bfc\u5b9e\u9a8c\u5efa\u7acb\u56e0\u679c\u8bc1\u636e\uff1a\u6ce8\u5165\u6210\u529f\u8f68\u8ff9\u4e2d\u7684\u7cbe\u70bc\u8868\u5f81\u63d0\u5347\u51c6\u786e\u6027\uff0c\u7528\u7b26\u53f7\u8868\u5f81\u66ff\u6362\u6df7\u6dc6\u7f16\u7801\u89c2\u5bdf\u6027\u80fd\u53d8\u5316\u3002", "result": "\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9010\u6b65\u6539\u8fdb\u52a8\u4f5c\u548c\u6982\u5ff5\u7684\u5185\u90e8\u8868\u5f81\uff0c\u53d1\u5c55\u51fa\u5173\u6ce8\u7ed3\u6784\u800c\u975e\u5177\u4f53\u52a8\u4f5c\u540d\u79f0\u7684\u62bd\u8c61\u7f16\u7801\uff1b\u7cbe\u70bc\u8868\u5f81\u6ce8\u5165\u80fd\u63d0\u5347\u51c6\u786e\u7387\uff0c\u7b26\u53f7\u8868\u5f81\u66ff\u6362\u6df7\u6dc6\u7f16\u7801\u4ec5\u5bfc\u81f4\u6700\u5c0f\u6027\u80fd\u635f\u5931\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\u662f\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u5f81\u7cbe\u70bc\u8fc7\u7a0b\uff0c\u5373\"\u6d41\u4f53\u63a8\u7406\u8868\u5f81\"\uff1a\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u4f18\u5316\u5185\u90e8\u8868\u5f81\uff0c\u53d1\u5c55\u51fa\u66f4\u62bd\u8c61\u3001\u7ed3\u6784\u5316\u7684\u7f16\u7801\u65b9\u5f0f\u3002"}}
