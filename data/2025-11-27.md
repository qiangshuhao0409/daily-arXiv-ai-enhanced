<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 29]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Real-World Performance Evaluations of Low-Band 5G NR/4G LTE 4x4 MIMO on Commercial Smartphones](https://arxiv.org/abs/2511.20959)
*Pasapong Wongprasert,Kasidis Arunruangsirilert,Jiro Katto*

Main category: cs.NI

TL;DR: 本文研究了索尼Xperia 1 III和IV手机在泰国b28/n28频段上的4x4 MIMO实际性能，包括不同信号条件下的可靠性测试和最优条件下的吞吐量测试，并与仅支持2Rx天线的设备进行对比。


<details>
  <summary>Details</summary>
Motivation: 目前市场上绝大多数商用5G手机都不支持低频段（<1 GHz）的4x4 MIMO，只有索尼Xperia 1旗舰系列和小米14 Pro例外。泰国True-H和dtac网络在b28/n28频段部署了4T4R，为研究4x4 MIMO在低频段的实际性能提供了条件。

Method: 使用索尼Xperia 1 III和IV手机在泰国b28/n28频段进行测试，包括：1）不同信号条件下的可靠性测试；2）最优条件下的最大吞吐量测试。通过固件修改使设备仅使用2个Rx端口，收集对比数据。同时使用其他厂商设备作为2Rx性能参考。

Result: 实验结果将展示4x4 MIMO在低频段的实际性能表现，包括可靠性测试结果和最大吞吐量数据，并与2Rx配置进行对比分析。

Conclusion: 研究将揭示4x4 MIMO在低频段的实际性能优势，为设备制造商和网络运营商提供参考，说明在低频段部署4T4R和手机支持4x4 MIMO的价值。

Abstract: All 3GPP-compliant commercial 5G New Radio (NR)-capable UEs on the market are equipped with 4x4 MIMO support for Mid-Band frequencies (>1.7 GHz) and above, enabling up to rank 4 MIMO transmission. This doubles the theoretical throughput compared to rank 2 MIMO and also improves reception performance. However, 4x4 MIMO support on low-band frequencies (<1 GHz) is absent in every commercial UEs, with the exception of the Xperia 1 flagship smartphones manufactured by Sony Mobile and the Xiaomi 14 Pro as of January 2024. The reason most manufacturers omit 4x4 MIMO support for low-band frequencies is likely due to design challenges or relatively small performance gains in real-world usage due to the lack of 4T4R deployment on low-band by mobile network operators around the world.
  In Thailand, 4T4R deployment on the b28/n28 (APT) band is common on True-H and dtac networks, enabling 4x4 MIMO transmission on supported UEs. In this paper, the real-world 4x4 MIMO performance on the b28/n28 (APT) band will be investigated by evaluating the reliability test under different signal conditions and the maximum throughput test by evaluating the performance under optimal conditions, using the Sony Xperia 1 III and the Sony Xperia 1 IV smartphone. Devices from other manufacturers are also used in the experiment to investigate the performance with 2Rx antennas for comparison. Through firmware modifications, the Sony Xperia 1 III and IV can be configured to use only 2 Rx ports on low-band, enabling the collection of comparative 2 Rx performance data as a reference.

</details>


### [2] [Performance Evaluation of Low-Latency Live Streaming of MPEG-DASH UHD video over Commercial 5G NSA/SA Network](https://arxiv.org/abs/2511.20961)
*Kasidis Arunruangsirilert,Bo Wei,Hang Song,Jiro Katto*

Main category: cs.NI

TL;DR: 本文评估了5G SA、5G NSA和LTE网络在超高清视频实时直播中的性能表现，发现5G SA在所有场景下都能成功交付超过95%的视频片段，而5G NSA和LTE网络表现较差。


<details>
  <summary>Details</summary>
Motivation: 随着5G SA在泰国的广泛部署，需要评估其在超高清视频实时直播等关键应用中的性能表现，并与5G NSA和LTE网络进行对比。

Method: 通过MPEG-DASH在不同移动网络技术下进行超高清视频实时直播测试，评估丢包率、MAC吞吐量和延迟等性能指标，涵盖静止、城市移动、高速移动和理想信号条件等多种场景。

Result: 5G SA在所有测试场景中都能成功交付超过95%的视频片段，而5G NSA表现不稳定，LTE网络有超过20%的视频片段无法按时交付。

Conclusion: 5G SA对于低延迟超高清视频流媒体是绝对必要的，5G NSA由于依赖传统控制信号可能无法满足此类任务需求。

Abstract: 5G Standalone (SA) is the goal of the 5G evolution, which aims to provide higher throughput and lower latency than the existing LTE network. One of the main applications of 5G is the real-time distribution of Ultra High-Definition (UHD) content with a resolution of 4K or 8K. In Q2/2021, Advanced Info Service (AIS), the biggest operator in Thailand, launched 5G SA, providing both 5G SA/NSA service nationwide in addition to the existing LTE network. While many parts of the world are still in process of rolling out the first phase of 5G in Non-Standalone (NSA) mode, 5G SA in Thailand already covers more than 76% of the population.
  In this paper, UHD video will be a real-time live streaming via MPEG-DASH over different mobile network technologies with minimal buffer size to provide the lowest latency. Then, performance such as the number of dropped segments, MAC throughput, and latency are evaluated in various situations such as stationary, moving in the urban area, moving at high speed, and also an ideal condition with maximum SINR. It has been found that 5G SA can deliver more than 95% of the UHD video segment successfully within the required time window in all situations, while 5G NSA produced mixed results depending on the condition of the LTE network. The result also reveals that the LTE network failed to deliver more than 20% of the video segment within the deadline, which shows that 5G SA is absolutely necessary for low-latency UHD video streaming and 5G NSA may not be good enough for such task as it relies on the legacy control signal.

</details>


### [3] [5G Network Automation Using Local Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2511.21084)
*Ahmadreza Majlesara,Ali Majlesi,Ali Mamaghani,Alireza Shokrani,Babak Hossein Khalaj*

Main category: cs.NI

TL;DR: 展示了基于本地部署的轻量级LLaMA-3模型和检索增强生成技术，用于自动化5G网络管理，强调隐私保护和易用性。


<details>
  <summary>Details</summary>
Motivation: 解决5G网络管理中敏感数据传输的安全问题，通过本地部署消除对外部API的依赖，同时让非专业用户也能轻松配置网络。

Method: 使用轻量级LLaMA-3 8b Q-4b模型在本地或边缘设备运行，结合RAG技术从数据库中检索相关信息，基于自然语言输入生成网络配置。

Result: 提高了网络配置的准确性和效率，简化了私有网络的创建和配置过程，确保敏感数据不外传。

Conclusion: 本地LLM与RAG结合为5G网络提供了安全、高效、适应性强的解决方案，推动了隐私保护和多用户场景下的5G网络发展。

Abstract: This demonstration showcases the integration of a lightweight, locally deployed Large Language Model (LLaMA-3 8b Q-4b) empowered by retrieval augmented generation (RAG) to automate 5G network management, with a strong emphasis on privacy. By running the LLM on local or edge devices ,we eliminate the need for external APIs, ensuring that sensitive data remains secure and is not transmitted over the internet. Although lightweight models may not match the performance of more complex models like GPT-4, we enhance their efficiency and accuracy through RAG. RAG retrieves relevant information from a comprehensive database, enabling the LLM to generate more precise and effective network configurations based on natural language user input. This approach not only improves the accuracy of the generated configurations but also simplifies the process of creating and configuring private networks, making it accessible to users without extensive networking or programming experience. The objective of this demonstration is to highlight the potential of combining local LLMs and RAG to deliver secure, efficient, and adaptable 5G network solutions, paving the way for a future where 5G networks are both privacy-conscious and versatile across diverse user profiles.

</details>


### [4] [Digital Twin-Driven Secure Access Strategy for SAGIN-Enabled IoT Networks](https://arxiv.org/abs/2511.21156)
*Hui Liang,Zhihui Wu,Runqi Yuan,Guobin Zhang,Yanfeng Zhang,Jinkai Zheng,Tom H. Luan*

Main category: cs.NI

TL;DR: 提出基于数字孪生（DT）的安全接入策略，通过虚拟复制SAGIN环境评估窃听风险，使用演化博弈模型平衡安全容量和排队延迟，提升物联网网络安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 空间-空中-地面一体化网络（SAGIN）中的物联网网络面临日益严重的窃听攻击威胁，需要解决数据机密性保护问题。

Method: 利用DT框架创建物理SAGIN环境的虚拟副本，持续评估动态窃听风险并量化保密容量；采用演化博弈模型动态平衡保密容量与排队延迟；开发分布式算法获取均衡接入策略。

Result: 仿真结果表明，所提DT方法显著提高了SAGIN物联网网络的安全性，有效平衡系统负载，防止过载发生，并减少排队延迟。

Conclusion: 基于DT的方法能够全面改善SAGIN物联网网络的整体性能，在安全性和效率之间实现良好平衡。

Abstract: In space-air-ground integrated networks (SAGIN)-enabled IoT networks, secure access has become a significant challenge due to the increasing risks of eavesdropping attacks. To address these threats to data confidentiality, this paper proposes a Digital Twin (DT)-driven secure access strategy. The strategy leverages a virtual replica of the physical SAGIN environment within the DT framework to continuously assess dynamic eavesdropping risks by quantifying secrecy capacity. Operating within this DT framework, an evolutionary game model dynamically balances the DT-updated secrecy capacity against queuing delay, steering IoT devices toward more secure and efficient access decisions. Furthermore, a novel distributed algorithm, integral to the DT operation, is developed to obtain the equilibrium access strategy for each device in a scalable manner. Simulation results demonstrate that the proposed DT-based approach substantially improves the security of SAGIN-enabled IoT networks. Additionally, it effectively balances system load, prevents overload occurrences, and decreases queuing delay compared to benchmark schemes, thereby comprehensively improving overall network performance.

</details>


### [5] [LatencyScope: A System-Level Mathematical Framework for 5G RAN Latency](https://arxiv.org/abs/2511.21277)
*Arman Maghsoudnia,Aoyu Gong,Raphael Cannatà,Dan Mihai Dumitriu,Haitham Hassanieh*

Main category: cs.NI

TL;DR: LatencyScope是一个用于精确计算5G RAN中上行和下行单向延迟的数学框架，包含延迟建模和配置优化器，在开源5G测试平台上验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 5G网络需要满足超可靠低延迟通信(URLLC)要求，但现有分析模型和模拟器无法准确捕捉RAN各层的延迟来源及其随机性，需要更精确的延迟计算框架。

Method: 在RAN每一层建模延迟来源，识别系统级瓶颈（如无线接口、调度策略、硬件/软件约束），捕捉其复杂依赖关系和随机特性，并使用配置优化器搜索数百亿种配置。

Result: 在srsRAN和OAI两个开源5G RAN测试平台上验证，LatencyScope能够紧密匹配经验延迟分布，显著优于现有分析模型和常用模拟器（MATLAB 5G工具箱、5G-LENA）。

Conclusion: LatencyScope能够找到满足URLLC目标的系统配置，帮助网络运营商高效识别最佳设置，为5G网络延迟优化提供了有效的数学框架。

Abstract: This paper presents LatencyScope, a mathematical framework for accurately computing one-way latency (for uplink and downlink) in the 5G RAN across diverse system configurations. LatencyScope models latency sources at every layer of the Radio Access Network (RAN), pinpointing system-level bottlenecks--such as radio interfaces, scheduling policies, and hardware/software constraints--while capturing their intricate dependencies and their stochastic nature. LatencyScope also includes a configuration optimizer that uses its mathematical models to search through hundreds of billions of configurations and find settings that meet latency-reliability targets under user constraints. We validate LatencyScope on two open-sourced 5G RAN testbeds (srsRAN and OAI), demonstrating that it can closely match empirical latency distributions and significantly outperform prior analytical models and widely used simulators (MATLAB 5G Toolbox, 5G-LENA). It can also find system configurations that meet Ultra-Reliable Low-Latency Communications (URLLC) targets and enable network operators to efficiently identify the best setup for their systems.

</details>


### [6] [Toward Secure Content-Centric Approaches for 5G-Based IoT: Advances and Emerging Trends](https://arxiv.org/abs/2511.21336)
*Ghada Jaber,Mohamed Ali Zormati,Walid Cavelius,Louka Chapiro,Mohamed El Ahmadi*

Main category: cs.NI

TL;DR: 本文综述了在5G-IoT环境中部署内容中心网络(CCN)面临的安全挑战，并分类评估了现有安全解决方案，指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着物联网与5G技术的融合，内容中心网络因其网络内缓存、可扩展性和高效内容分发等优势成为传统IP架构的有前景替代方案，但在5G-IoT环境中部署面临严重安全挑战。

Method: 采用文献综述方法，对内容中心架构在IoT-5G场景下的现有安全解决方案进行分类和评估。

Result: 识别了当前安全趋势，发现了现有方法的局限性，特别是在内容认证、数据完整性、隐私保护和抵御欺骗攻击等方面存在不足。

Conclusion: 需要开发轻量级和自适应安全机制来应对5G-IoT环境中内容中心网络的安全挑战，这是未来的重要研究方向。

Abstract: The convergence of the Internet of Things (IoT) and 5G technologies is transforming modern communication systems by enabling massive connectivity, low latency, and high-speed data transmission. In this evolving landscape, Content-Centric Networking (CCN) is emerging as a promising alternative to traditional Internet Protocol (IP)-based architectures. CCN offers advantages such as in-network caching, scalability, and efficient content dissemination, all of which are particularly well-suited to the constraints of the IoT. However, deploying content-centric approaches in 5G-based IoT environments introduces significant security challenges. Key concerns include content authentication, data integrity, privacy protection, and resilience against attacks such as spoofing and cache poisoning. Such issues are exacerbated by the distributed, mobile, and heterogeneous nature of IoT and 5G systems. In this survey, we review and classify existing security solutions for content-centric architectures in IoT-5G scenarios. We highlight current trends, identify limitations in existing approaches, and outline future research directions with a focus on lightweight and adaptive security mechanisms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Learning Multi-Access Point Coordination in Agentic AI Wi-Fi with Large Language Models](https://arxiv.org/abs/2511.20719)
*Yifan Fan,Le Liang,Peng Liu,Xiao Li,Ziyang Guo,Qiao Lan,Shi Jin,Wen Tong*

Main category: cs.AI

TL;DR: 提出了一种基于大型语言模型代理的智能Wi-Fi框架，使接入点能够通过自然语言对话实时协作协商自适应协调策略，显著提升密集重叠基本服务集环境下的网络性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多接入点协调协议依赖静态规则，无法适应动态网络条件（如变化的干扰水平和拓扑结构），需要更智能的自适应解决方案。

Method: 将每个接入点建模为自主的大型语言模型代理，通过认知工作流程进行自然语言对话，利用集成记忆、反思和工具使用来基于历史经验和环境反馈做出决策。

Result: 综合仿真结果表明，该代理框架成功适应了多样化和动态的网络环境，显著优于最先进的空间复用基线方法。

Conclusion: 该框架验证了作为未来无线网络稳健智能解决方案的潜力，展示了AI代理在动态网络协调中的有效性。

Abstract: Multi-access point coordination (MAPC) is a key technology for enhancing throughput in next-generation Wi-Fi within dense overlapping basic service sets. However, existing MAPC protocols rely on static, protocol-defined rules, which limits their ability to adapt to dynamic network conditions such as varying interference levels and topologies. To address this limitation, we propose a novel Agentic AI Wi-Fi framework where each access point, modeled as an autonomous large language model agent, collaboratively reasons about the network state and negotiates adaptive coordination strategies in real time. This dynamic collaboration is achieved through a cognitive workflow that enables the agents to engage in natural language dialogue, leveraging integrated memory, reflection, and tool use to ground their decisions in past experience and environmental feedback. Comprehensive simulation results demonstrate that our agentic framework successfully learns to adapt to diverse and dynamic network environments, significantly outperforming the state-of-the-art spatial reuse baseline and validating its potential as a robust and intelligent solution for future wireless networks.

</details>


### [8] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究使用大型语言模型自动重构层次结构以优化双曲嵌入质量，实验表明LLM重构的层次结构能显著提升嵌入质量并提供可解释的重组理由。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入质量与输入层次结构密切相关，而现有层次结构往往不满足高分支因子和单继承等最优嵌入条件，需要知识工程师手动重组，这过程耗时且困难。

Method: 提出基于提示的方法，使用LLM根据双曲嵌入的已知需求来自动转换现有层次结构，并在16个不同层次结构上进行实验验证。

Result: 实验结果显示，经过LLM重构的层次结构在多个标准嵌入质量指标上都能产生更高质量的双曲嵌入。

Conclusion: LLM能够有效自动重构层次结构以优化双曲嵌入，同时提供可解释的重组理由，为知识工程师提供有价值的协助。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [9] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: AssurAI是一个针对韩语多模态生成AI安全评估的新数据集，包含11,480个文本、图像、视频和音频实例，覆盖35种AI风险因素，特别关注韩语社会文化背景下的特定风险。


<details>
  <summary>Details</summary>
Motivation: 当前的安全数据集主要是英语中心的，无法捕捉非英语社会文化背景（如韩语）中的特定风险，且通常仅限于文本模态。

Method: 定义了35种AI风险因素的分类法，通过多学科专家组构建数据集，采用两阶段构建（专家引导播种和众包扩展）、三重独立标注和迭代专家红队循环的质量控制流程。

Result: 试点研究验证了AssurAI在评估最新LLM安全性方面的有效性。

Conclusion: AssurAI的发布将促进为韩国社区开发更安全可靠的生成AI系统。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [10] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个完全自动化的智能体工作流生成框架，通过自适应的抽象操作符实现无需手动预定义的工作流构建，在性能和资源效率方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义的操作符，限制了智能体工作流的泛化能力和可扩展性。

Method: 采用三阶段操作符提取过程：1)基于案例的初始操作符生成；2)操作符聚类和初步抽象；3)深度提取抽象执行操作符。同时通过操作符记忆机制增强工作流搜索。

Result: 在通用和具身基准测试中，A²Flow实现了2.4%和19.3%的平均性能提升，资源使用量减少了37%。

Conclusion: A²Flow通过完全自动化的操作符提取和工作流构建，显著提升了智能体工作流的性能和效率，为自动化工作流设计提供了有效解决方案。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [11] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 提出了一个名为"Reasoning With a Star"的日球物理学推理数据集和基准测试方法，通过多智能体模式在需要演绎推理的问题上优于直接提示方法。


<details>
  <summary>Details</summary>
Motivation: 解决日球物理学中科学推理的挑战，包括整合物理假设、保持单位一致性和提供清晰科学格式的需求，而不仅仅是事实回忆。

Method: 构建基于NASA和UCAR Living With a Star暑期学校问题集的数据集，采用程序化评分器检查预测结果，并比较单次提示和四种多智能体模式。

Result: 发现通过系统工程原则分解工作流程的多智能体模式在需要演绎推理的问题上表现优于直接提示方法。

Conclusion: 多智能体推理方法在复杂科学推理任务中具有优势，特别是在需要演绎推理而非纯归纳回忆的问题上。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [12] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现正推动医疗健康转型。它通过整合影像、生物传感器和计算模型创建患者特异性虚拟副本，用于诊断、治疗规划和药物开发。尽管面临互操作性、数据隐私等挑战，但可解释AI、联邦学习等解决方案为其临床整合提供了前景。


<details>
  <summary>Details</summary>
Motivation: 将数字孪生技术从工业领域引入医疗健康，旨在实现从被动治疗向预测性、预防性和个性化医疗的转变，通过创建患者特异性虚拟模型来改善诊断和治疗效果。

Method: 整合医学影像、生物传感器数据和计算模型，构建动态、数据驱动的患者虚拟副本，通过实时数据流持续更新，并支持双向交互。具体应用包括心脏数字孪生预测心律失常治疗结果、肿瘤数字孪生追踪进展和优化放疗、药理学数字孪生加速药物发现。

Result: 数字孪生在医疗领域已取得代表性应用成果，能够预测治疗结果、优化治疗方案和加速药物开发过程，展示了其在个性化医疗中的潜力。

Conclusion: 数字孪生技术有望彻底改变医疗模式，但需要解决互操作性、数据隐私和模型保真度等挑战。未来发展方向包括多器官数字孪生、基因组学整合和伦理治理，以实现真正的预测性、预防性和个性化医疗。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [13] [Paraconsistent-Lib: an intuitive PAL2v algorithm Python Library](https://arxiv.org/abs/2511.20700)
*Arnaldo de Carvalho Junior,Diego Oliveira da Cruz,Bruno da Silva Alves,Fernando da Silva Paulo Junior,João Inacio da Silva Filho*

Main category: cs.AI

TL;DR: 介绍了Paraconsistent-Lib，一个用于构建PAL2v算法的开源Python库，提供三种分析结果类型，可简化复杂算法的实现。


<details>
  <summary>Details</summary>
Motivation: 为推理和决策系统提供一个易于使用的PAL2v算法构建工具，减少代码复杂性和错误。

Method: 开发了通用的PAL2v标准计算库，支持12种经典格区域分析、分析节点输出和决策输出，可构建独立或网络形式的算法。

Result: 实现了多种知名PAL2v算法，如Para-analyzer、ParaExtrCTX等，通过两个示例展示了库的有效性。

Conclusion: Paraconsistent-Lib是一个稳定且持续开发的开源库，能够响应用户在GitHub上提出的功能需求和改进建议。

Abstract: This paper introduces Paraconsistent-Lib, an open-source, easy-to-use Python library for building PAL2v algorithms in reasoning and decision-making systems. Paraconsistent-Lib is designed as a general-purpose library of PAL2v standard calculations, presenting three types of results: paraconsistent analysis in one of the 12 classical lattice PAL2v regions, paraconsistent analysis node (PAN) outputs, and a decision output. With Paraconsistent-Lib, well-known PAL2v algorithms such as Para-analyzer, ParaExtrCTX, PAL2v Filter, paraconsistent analysis network (PANnet), and paraconsistent neural network (PNN) can be written in stand-alone or network form, reducing complexity, code size, and bugs, as two examples presented in this paper. Given its stable state, Paraconsistent-Lib is an active development to respond to user-required features and enhancements received on GitHub.

</details>


### [14] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 本文对多模态思维链推理进行了跨域泛化分析，发现在科学推理之外的常识推理领域效果有限，视觉特征能减少幻觉但CoT有效性因问题类型而异。


<details>
  <summary>Details</summary>
Motivation: 评估多模态思维链推理在不同领域的泛化能力，特别是在需要广泛常识和世界知识的任务上，而不仅仅是科学推理。

Method: 采用Zhang等人的两阶段框架，将理由生成与答案推理分离，通过门控融合机制整合视觉特征与T5语言模型，并进行系统消融研究。

Result: 视觉集成显著减少了理由生成中的幻觉，但思维链推理的有效性在不同问题类型间差异很大，常识推理尤其具有挑战性。

Conclusion: 为多模态推理系统提供了实用见解，并确定了跨域泛化改进的关键方向。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [15] [OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability](https://arxiv.org/abs/2511.20766)
*Karen Ullrich,Jingtong Su,Claudia Shi,Arjun Subramonian,Amir Bar,Ivan Evtimov,Nikolaos Tsilivis,Randall Balestriero,Julia Kempe,Mark Ibrahim*

Main category: cs.AI

TL;DR: OpenApps是一个轻量级开源生态系统，用于评估多模态UI代理在应用变体中的可靠性，发现代理在不同应用版本中的任务成功率波动可达50%以上。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法依赖固定环境，无法衡量代理在不同应用设计和内容变体中的可靠性，而实际部署时会遇到各种应用变体。

Method: 开发包含6个可配置应用（消息、日历、地图等）的OpenApps生态系统，在单CPU上运行数千个应用版本，进行了超过10,000次独立评估。

Result: 发现代理在固定应用中的可靠性相对稳定，但在应用变体间差异巨大：Kimi-VL-3B的平均成功率从63%降至4%；代理行为（如循环或幻觉操作）也因环境配置而异。

Conclusion: 测量应用变体维度的可靠性至关重要，OpenApps为此提供了工具和初步发现。

Abstract: Reliability is key to realizing the promise of autonomous UI-Agents, multimodal agents that directly interact with apps in the same manner as humans, as users must be able to trust an agent to complete a given task. Current evaluations rely on fixed environments, often clones of existing apps, which are limited in that they can only shed light on whether or how often an agent can complete a task within a specific environment. When deployed however, agents are likely to encounter variations in app design and content that can affect an agent's ability to complete a task. To address this blind spot of measuring agent reliability across app variations, we develop OpenApps, a light-weight open-source ecosystem with six apps (messenger, calendar, maps, etc.) that are configurable in appearance and content. OpenApps requires just a single CPU to run, enabling easy generation and deployment of thousands of versions of each app. Specifically, we run more than 10,000 independent evaluations to study reliability across seven leading multimodal agents. We find that while standard reliability within a fixed app is relatively stable, reliability can vary drastically when measured across app variations. Task success rates for many agents can fluctuate by more than $50\%$ across app variations. For example, Kimi-VL-3B's average success across all tasks fluctuates from $63\%$ to just $4\%$ across app versions. We also find agent behaviors such as looping or hallucinating actions can differ drastically depending on the environment configuration. These initial findings highlight the importance of measuring reliability along this new dimension of app variations. OpenApps is available at https://facebookresearch.github.io/OpenApps/

</details>


### [16] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在表示空间进行干预的知识控制方法，能够在保持基础权重冻结的情况下，对复杂非结构化知识进行细粒度控制，同时维持模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常产生错误或过时内容，如何在无需昂贵重新训练的情况下高效准确地更新其知识是一个重大挑战，特别是在终身学习场景中需要处理多个编辑且避免相互干扰。

Method: 利用表示空间的表达能力，学习具有抗释义性和编辑局部性的模块，将每个更新限制在低维子空间以减少交叉干扰；在推理时通过查询自适应路由器选择合适的模块来指导生成。

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE能够扩展到大规模数据集，表现出高编辑成功率、强释义泛化能力，并以适度的内存开销保持通用能力。

Conclusion: RILKE是大语言模型中终身知识控制的有效且可扩展解决方案。

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [17] [Guaranteed Optimal Compositional Explanations for Neurons](https://arxiv.org/abs/2511.20934)
*Biagio La Rosa,Leilani H. Gilpin*

Main category: cs.AI

TL;DR: 本文提出了第一个能够计算保证最优组合解释的框架，通过分解空间对齐因素、设计启发式估计和优化算法，解决了现有方法无法提供理论最优性保证的问题。


<details>
  <summary>Details</summary>
Motivation: 当前神经元组合解释方法使用beam搜索来限制搜索空间，但无法提供理论最优性保证，不清楚当前解释与真正最优解的接近程度。

Method: 提出了三个核心组件：(i)识别影响空间对齐因素的分解方法；(ii)在搜索任何阶段估计对齐的启发式方法；(iii)第一个能在可行时间内计算最优组合解释的算法。

Result: 在计算机视觉和卷积神经网络的最常用设置中，当涉及重叠概念时，10-40%通过beam搜索获得的解释是次优的。提出的beam搜索变体在运行时间上匹配或优于先前方法。

Conclusion: 该框架首次提供了计算保证最优组合解释的能力，揭示了现有方法的局限性，并展示了改进的搜索策略在保持效率的同时提供更大灵活性。

Abstract: While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources.

</details>


### [18] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估视觉语言模型是否展现具身认知的基准测试，通过视觉问答形式评估从自我中心交互中的世界建模能力，包含前向和逆向世界建模两个任务。


<details>
  <summary>Details</summary>
Motivation: 研究现代视觉语言模型是否表现出具身认知的特征，即使它们主要是在非具身方式下训练的。具身认知认为智能源于感觉运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观测马尔可夫决策过程，动作是场景图变化。包含两个互补的序列重排序任务：前向世界建模（给定动作重排观察序列）和逆向世界建模（给定观察重排动作序列）。

Result: 前沿视觉语言模型与人类之间存在性能差距，且随着交互时间跨度增加而扩大。模型在逆向任务上表现优于前向任务，并表现出人类中心偏见，如偏好右手动作，当相机参数或视角偏离人类视觉时会性能下降。

Conclusion: ENACT基准揭示了视觉语言模型在具身认知能力方面的局限性，表明当前模型尚未完全掌握从自我中心交互中建模世界的核心能力。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [19] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy系统结合符号TMK模型和生成式LLM，通过结构化约束提升教学解释的质量，在程序技能学习中提供更好的因果、目标和组合逻辑解释。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成的教学解释虽然流畅但缺乏深度结构的问题，需要传达步骤背后的因果、目标导向和组合逻辑。

Method: 结合符号Task-Method-Knowledge(TMK)模型与生成式LLM解释层，TMK编码因果转换、目标层次和问题分解，在明确结构边界内指导LLM生成解释。

Result: 与GPT和检索增强GPT基线相比，符号约束持续改善了"如何"和"为什么"问题解释的结构质量。

Conclusion: 展示了可扩展的AI教育方法，通过符号约束增强AI生成解释在教学辅导系统中的教学价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [20] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 提出了ICPO方法，通过内在置信度驱动的群体相对偏好优化来解决RLVR中的奖励粒度粗、奖励噪声和探索效率低等问题，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在奖励粒度粗、奖励噪声和探索效率低等问题，导致训练不稳定和熵崩溃，限制了推理能力的提升。

Method: ICPO方法利用LLM生成不同响应的概率来反映其对推理过程的自我评估，通过计算偏好优势分数并与可验证奖励结合来指导探索过程。

Result: 在四个通用领域基准和三个数学基准上的实验表明，ICPO相比GRPO能稳定提升推理能力。

Conclusion: ICPO方法通过偏好优势分数有效缓解了奖励粒度粗和噪声问题，抑制了过度自信错误，增强了被低估高质量响应的相对优势，防止模型对特定策略的过拟合，促进更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [21] [Towards Trustworthy Legal AI through LLM Agents and Formal Reasoning](https://arxiv.org/abs/2511.21033)
*Linze Chen,Yufan Cai,Zhe Hou,Jinsong Dong*

Main category: cs.AI

TL;DR: L4M框架结合对抗性LLM代理和SMT求解器证明，将自然语言的解释灵活性与符号验证的严谨性相结合，用于法律裁决。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的系统擅长表层文本分析，但缺乏原则性法理学所需的保证。法律理性体现为实质理性（结果公平性）和形式理性（遵循明确规则），需要结合两者的优势。

Method: 三阶段流程：1) 法规形式化：将法律条款转换为逻辑公式；2) 双重事实和法规提取：检察官和辩护方对齐的LLM独立映射案例叙述；3) 求解器中心裁决：将双方论证编译为逻辑约束，通过不满足核心触发迭代自我批评，最终由法官LLM生成透明裁决。

Result: 在公共基准测试中，该系统超越了GPT-4-mini、DeepSeek-V3、Claude 4等先进LLM以及最先进的法律AI基线，同时提供严格且可解释的符号证明。

Conclusion: L4M成功地将自然语言的灵活性与符号验证的严谨性相结合，为法律AI系统提供了既准确又可解释的裁决能力。

Abstract: The rationality of law manifests in two forms: substantive rationality, which concerns the fairness or moral desirability of outcomes, and formal rationality, which requires legal decisions to follow explicitly stated, general, and logically coherent rules. Existing LLM-based systems excel at surface-level text analysis but lack the guarantees required for principled jurisprudence. We introduce L4M, a novel framework that combines adversarial LLM agents with SMT-solver-backed proofs to unite the interpretive flexibility of natural language with the rigor of symbolic verification. The pipeline consists of three phases: (1) Statute Formalization, where domain-specific prompts convert legal provisions into logical formulae; (2) Dual Fact and Statute Extraction, in which prosecutor- and defense-aligned LLMs independently map case narratives to fact tuples and statutes, ensuring role isolation; and (3) Solver-Centric Adjudication, where an autoformalizer compiles both parties' arguments into logic constraints, and unsat cores trigger iterative self-critique until a satisfiable formula is achieved, which is then verbalized by a Judge-LLM into a transparent verdict and optimized sentence. Experimental results on public benchmarks show that our system surpasses advanced LLMs including GPT-o4-mini, DeepSeek-V3, and Claude 4 as well as state-of-the-art Legal AI baselines, while providing rigorous and explainable symbolic justifications.

</details>


### [22] [OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection](https://arxiv.org/abs/2511.21064)
*Chujie Wang,Jianyu Lu,Zhiyuan Luo,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: 提出了OVOD-Agent框架，将被动类别匹配转变为主动视觉推理和自我进化检测，通过视觉思维链和弱马尔可夫决策过程提升开放词汇目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有OVOD方法虽然在多模态数据集上预训练，但推理仍局限于固定类别名称，存在多模态训练与单模态推理之间的差距。文本空间的潜力尚未充分挖掘。

Method: 提出OVOD-Agent框架，包含视觉思维链、弱马尔可夫决策过程建模、Bandit探索模块和自监督奖励模型优化，形成从探索到学习的闭环系统。

Result: 在COCO和LVIS数据集上的实验表明，OVOD-Agent在各种OVOD骨干网络上均能提供一致改进，特别是在稀有类别上表现突出。

Conclusion: 所提出的框架有效提升了开放词汇目标检测性能，验证了主动视觉推理和自我进化检测策略的有效性。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.

</details>


### [23] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文提出了Halpern-Pearl因果定义的抽象版本，使其能应用于任何定义了反事实的模型，扩展了原定义的应用范围和处理能力。


<details>
  <summary>Details</summary>
Motivation: Halpern-Pearl的因果定义局限于因果模型，无法处理包含析取、否定、信念和嵌套反事实的复杂情况，需要更通用的抽象定义。

Method: 通过抽象化Halpern-Pearl因果定义的关键特征，构建可在任何反事实模型中使用的新定义框架。

Result: 新定义不仅能应用于更广泛的模型（如允许回溯的模型），还能处理原定义无法处理的复杂逻辑公式，并能扩展到解释的定义。

Conclusion: 抽象化方法扩展了因果定义的应用范围，提供了对因果定义特征的更深理解，并为构建通用解释理论奠定了基础。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>


### [24] [Prune4Web: DOM Tree Pruning Programming for Web Agent](https://arxiv.org/abs/2511.21398)
*Jiayuan Zhang,Kaiquan Chen,Zhihao Lu,Enshen Zhou,Qian Yu,Jing Zhang*

Main category: cs.AI

TL;DR: Prune4Web是一个新颖的Web自动化范式，通过将DOM处理从资源密集的LLM读取转向高效的程序化剪枝，解决了复杂网页导航中DOM结构过大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based Web代理在处理包含10,000-100,000个token的大型DOM结构时效率低下，现有策略要么依赖粗糙的DOM截断（可能丢失关键信息），要么使用低效的启发式方法和单独排名模型，无法在精度和可扩展性之间达到最佳平衡。

Method: 提出DOM树剪枝编程，让LLM生成可执行的Python评分脚本来基于分解子任务的语义线索动态过滤DOM元素。这种方法避免了LLM直接处理原始大型DOM，将遍历和评分委托给轻量级、可解释的程序。

Result: 实现了候选元素25倍到50倍的减少，显著提高了动作定位精度。在低级别接地任务上，准确率从46.8%大幅提升到88.28%。

Conclusion: Prune4Web通过程序化剪枝方法有效解决了Web自动化中的DOM处理效率问题，在真实世界Web自动化中表现出卓越效果。

Abstract: Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.

</details>


### [25] [New Hybrid Heuristics for Pseudo-Boolean Propagation](https://arxiv.org/abs/2511.21417)
*Mia Müßig,Jan Johannsen*

Main category: cs.AI

TL;DR: 本文提出了新的启发式方法，用于改进伪布尔求解器中混合单元传播策略的决策，显著提升了RoundingSAT求解器的性能。


<details>
  <summary>Details</summary>
Motivation: 当前伪布尔求解中最成功的单元传播策略是观察文字方案与计数方法的混合模式，但现有决策方法仍有改进空间。

Method: 引入了新的启发式方法来确定何时使用观察文字方案、何时使用计数方法进行单元传播。

Result: 新启发式方法能够显著超越当前方法，在RoundingSAT求解器中表现出更好的性能。

Conclusion: 提出的新启发式方法有效改进了伪布尔求解器中混合单元传播策略的决策质量。

Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.

</details>


### [26] [Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex](https://arxiv.org/abs/2511.21438)
*Simon Süwer,Kester Bagemihl,Sylvie Baier,Lucia Dicunta,Markus List,Jan Baumbach,Andreas Maier,Fernando M. Delgado-Chaves*

Main category: cs.AI

TL;DR: ChatDRex是一个基于对话的多智能体系统，通过自然语言访问生物医学知识图谱，实现网络药物重定位预测，使非计算机专业的研究人员也能进行复杂生物信息学分析。


<details>
  <summary>Details</summary>
Motivation: 传统药物重定位预测需要多领域专家协作，但现有工具碎片化且数据异构，难以整合到统一工作流中。需要开发能让临床专家无需编程技能即可使用的系统。

Method: 构建基于NeDRex知识图谱的多智能体系统，包含查询路由、数据检索、算法执行、结果可视化等专门化智能体，支持网络分析、功能一致性评估、文献挖掘等功能。

Result: 系统实现了自然语言访问生物医学知识图谱，能够执行复杂的生物信息学分析，支持药物重定位预测，并包含幻觉检测机制。

Conclusion: ChatDRex通过多智能体设计和自然语言界面，使临床专家能够生成假设并探索药物重定位机会，加速新疗法发现，推动个性化医疗和转化研究。

Abstract: Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem, and heterogeneous, unstructured data landscapes require specialized users to be involved. Hence, these data services do not integrate smoothly across workflows. With ChatDRex, we present a conversation-based, multi-agent system that facilitates the execution of complex bioinformatic analyses aiming for network-based drug repurposing prediction. It builds on the integrated systems medicine knowledge graph NeDRex. ChatDRex provides natural language access to its extensive biomedical KG and integrates bioinformatics agents for network analysis and drug repurposing, complemented by agents for functional coherence evaluation for in silico validation, as well as agents for literature mining and for discussing the obtained results in a scientific context. Its flexible multi-agent design assigns specific tasks to specialized agents, including query routing, data retrieval, algorithm execution, and result visualization. A dedicated reasoning module keeps the user in the loop and allows for hallucination detection. By enabling physicians and researchers without computer science expertise to control complex analyses in natural language, ChatDRex democratizes access to bioinformatics as an important resource for drug repurposing. It enables clinical experts to generate hypotheses and explore drug repurposing opportunities, ultimately accelerating the discovery of novel therapies and advancing personalized medicine and translational research.

</details>


### [27] [EWE: An Agentic Framework for Extreme Weather Analysis](https://arxiv.org/abs/2511.21444)
*Zhe Jiang,Jiong Wang,Xiaoyu Yue,Zijie Guo,Wenlong Zhang,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.AI

TL;DR: 提出了第一个用于极端天气自动诊断推理的智能代理框架EWE，通过模拟专家工作流程实现从原始气象数据到多模态可视化的自主分析，并建立了该领域的首个基准数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件对全球社会构成日益严重的风险，但传统的人工诊断方法存在分析瓶颈，阻碍了科学进展。虽然AI在地球科学预测方面取得了进展，但自动诊断推理这一同等重要的挑战尚未得到充分探索。

Method: EWE框架通过知识引导规划、闭环推理和领域定制的气象工具包来模拟专家工作流程，能够从原始气象数据自主生成和解释多模态可视化，实现全面的诊断分析。

Result: 建立了该领域的首个基准，包括103个高影响事件的精选数据集和新的逐步评估指标，展示了EWE在自动科学发现方面的潜力。

Conclusion: EWE标志着向自动化科学发现迈出了一步，并有望为易受极端天气影响的发展中国家民主化专业知识和智力资源。

Abstract: Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.

</details>


### [28] [MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning](https://arxiv.org/abs/2511.21460)
*Junjian Wang,Lidan Zhao,Xi Sheryl Zhang*

Main category: cs.AI

TL;DR: 提出了MADRA框架，一种无需训练的多智能体辩论风险评估方法，通过集体推理增强安全意识，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在具身AI任务规划中的安全风险问题，现有方法存在计算成本高或过度拒绝安全指令的局限性。

Method: 使用多个基于LLM的智能体对给定指令的安全性进行辩论，由关键评估器根据逻辑合理性、风险识别、证据质量和清晰度对响应进行评分，通过迭代审议和共识投票达成决策。

Result: 在AI2-THOR和VirtualHome上的实验表明，该方法对不安全任务的拒绝率超过90%，同时保持对安全任务的低拒绝率，在安全性和执行效率方面优于现有方法。

Conclusion: 该工作为构建可信赖的具身智能体提供了一个可扩展、模型无关的解决方案。

Abstract: Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.

</details>


### [29] [SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition](https://arxiv.org/abs/2511.21471)
*Peiran Xu,Sudong Wang,Yao Zhu,Jianing Li,Yunjian Zhang*

Main category: cs.AI

TL;DR: 提出了一个分层空间认知框架，将空间智能分解为从基础观察到高级规划的五个渐进复杂层次，并构建了SpatialBench基准来评估多模态大语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试过度简化空间认知，将其简化为单一维度指标，无法捕捉空间能力的层次结构和相互依赖性。

Method: 构建分层空间认知框架，将空间智能分为五个认知层次，创建包含15个任务的大规模细粒度基准SpatialBench，并引入高层能力导向的统一评估指标。

Result: 大规模实验显示模型在不同认知层次上表现出明显的性能分层：模型在感知基础方面表现强劲，但在符号推理、因果推理和规划方面仍然有限。人类测试表明人类进行选择性、目标导向的抽象，而MLLMs倾向于过度关注表面细节而缺乏连贯的空间意图。

Conclusion: 这项工作为测量MLLMs中的分层空间认知建立了第一个系统框架，为未来空间智能系统奠定了基础。

Abstract: Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.

</details>


### [30] [Pessimistic Verification for Open Ended Math Questions](https://arxiv.org/abs/2511.21522)
*Yanxing Huang,Zihan Tang,Zejin Lin,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 提出悲观验证方法，通过并行构建多个验证来检测数学证明中的错误，显著提升验证性能且计算资源消耗低。


<details>
  <summary>Details</summary>
Motivation: 现有验证性能受限于错误检测能力，需要更有效的数学问题验证方法。

Method: 悲观验证：为同一证明构建多个并行验证，任一验证报告错误即判定证明错误。

Result: 该方法在多个数学验证基准上显著提升性能，token效率甚至超过扩展长链思维，且发现数据集中存在标注错误。

Conclusion: 悲观验证能有效提升语言模型数学输出的可靠性，对实现长视野数学任务至关重要。

Abstract: The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

</details>


### [31] [Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit](https://arxiv.org/abs/2511.21569)
*Alex Diep*

Main category: cs.AI

TL;DR: 语言模型在专业领域无法可靠披露AI身份，导致用户难以信任其能力边界。研究发现模型在不同专业领域的身份披露率差异巨大，存在"反向盖尔曼遗忘症"风险。


<details>
  <summary>Details</summary>
Motivation: 在需要专业知识的场景中，如果语言模型不能诚实地披露其AI身份，用户可能错误地信任其能力，从而面临潜在风险。

Method: 采用公共花园设计，对16个开放权重模型（4B-671B参数）进行了19,200次试验，评估不同专业角色下的身份披露行为。

Result: 模型在不同专业领域的身份披露率差异显著：金融顾问角色初始披露率30.8%，而神经外科医生角色仅3.5%。模型身份比参数数量更能预测行为表现。

Conclusion: 透明度反映的是训练因素而非模型规模，组织不能假设安全属性会自动转移到部署环境，需要刻意设计和实证验证。

Abstract: If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a "Reverse Gell-Mann Amnesia" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.

</details>


### [32] [From Prediction to Foresight: The Role of AI in Designing Responsible Futures](https://arxiv.org/abs/2511.21570)
*Maria Perez-Ortiz*

Main category: cs.AI

TL;DR: 本文提出"负责任计算前瞻"概念，探讨人工智能在负责任前瞻中的作用，强调AI应作为支持工具而非替代人类判断，帮助政策制定者应对未来不确定性。


<details>
  <summary>Details</summary>
Motivation: 在技术快速发展和全球挑战日益复杂的时代，政策制定者需要负责任的前瞻框架来应对未来不确定性，但传统方法难以处理复杂系统的相互依赖性。

Method: 建立负责任计算前瞻的基础原则，开发AI驱动的前瞻工具，结合模拟和情景分析来增强政策制定者的能力。

Result: AI能够增强政策制定者处理不确定性、评估风险和制定可持续战略的能力，但需要与人类判断相结合。

Conclusion: AI应作为负责任、以人为本的前瞻支持工具，补充而非替代政策制定者的判断，帮助塑造具有韧性和道德健全的未来。

Abstract: In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term "responsible computational foresight", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.

</details>


### [33] [On the Limits of Innate Planning in Large Language Models](https://arxiv.org/abs/2511.21591)
*Charles Schepanowski,Charles Ling*

Main category: cs.AI

TL;DR: LLMs在8拼图任务中表现出状态跟踪和规划能力不足，即使有反馈和验证器辅助也无法有效解决该问题，主要缺陷是脆弱的状态表示和弱启发式规划。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在没有代码执行或其他工具的情况下，进行规划和状态推理的能力，使用8拼图作为测试平台。

Method: 测试四个模型在零样本、思维链、算法思维等提示条件下，并采用分层纠正反馈和外部移动验证器。

Result: 反馈对某些模型-提示组合有改善，但成功运行通常冗长且计算昂贵。即使有移动验证器，所有模型都无法解决任何拼图。

Conclusion: 当前LLMs在规划方面存在重大限制，需要开发维护显式状态和执行结构化搜索的机制。

Abstract: Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

</details>


### [34] [Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling](https://arxiv.org/abs/2511.21636)
*Peter S. Hovmand,Kari O'Donnell,Callie Ogland-Hand,Brian Biroscak,Douglas D. Gunzler*

Main category: cs.AI

TL;DR: 本文提出了一个将系统动力学和结构方程建模结合到统一数学框架中的方法，用于支持负责任AI/ML的发展。


<details>
  <summary>Details</summary>
Motivation: AI/ML模型在解决未解决问题时可能放大人类偏见，需要更丰富的因果模型来指导负责任AI/ML的开发，但不同方法基于不同假设难以整合。

Method: 将系统动力学和结构方程建模整合到共同的数学框架中，用于生成系统分布、开发方法和比较结果。

Result: 建立了一个能够统一系统动力学和结构方程建模的数学框架。

Conclusion: 该框架可为数据科学和AI/ML应用提供系统动力学的认识论基础，促进负责任AI的发展。

Abstract: AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.

</details>


### [35] [Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](https://arxiv.org/abs/2511.21678)
*Weihao Bo,Shan Zhang,Yanpeng Sun,Jingjing Wu,Qunyi Xie,Xiao Tan,Kunbin Chen,Wei He,Xiaofan Li,Na Zhao,Jingdong Wang,Zechao Li*

Main category: cs.AI

TL;DR: ViLoMem是一个双流记忆框架，通过分别编码视觉分心模式和逻辑推理错误，使MLLMs能够从成功和失败经验中学习，提高多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹的记忆方法存在简洁性偏差，逐渐丢失关键领域知识，且仅记录单模态行为轨迹，无法保留视觉注意和逻辑推理如何共同促成解决方案，这与人类多模态整合的语义记忆不符。

Method: 采用双流记忆框架，分别编码视觉分心模式和逻辑推理错误，遵循增长-精炼原则，增量积累和更新多模态语义知识，保持稳定可泛化策略同时避免灾难性遗忘。

Result: 在六个多模态基准测试中，ViLoMem持续提高pass@1准确率，显著减少重复的视觉和逻辑错误。消融实验证实了具有明确分心-幻觉分离的双流记忆的必要性。

Conclusion: ViLoMem证明了错误感知多模态记忆对于终身和跨领域智能学习的重要性，为MLLMs提供了更符合人类认知的记忆机制。

Abstract: MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.

</details>
