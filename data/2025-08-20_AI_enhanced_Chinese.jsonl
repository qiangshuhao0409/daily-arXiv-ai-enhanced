{"id": "2508.13469", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.13469", "abs": "https://arxiv.org/abs/2508.13469", "authors": ["M. Umar Khan"], "title": "Fundamentals of Next-generation Network Planning", "comment": null, "summary": "The fifth-generation (5G) of cellular communications is expected to be\ndeployed in the next years to support a wide range of services with different\ndemands of peak data rates, latency and quality of experience (QoE). To support\nhigher data rates and latency requirements third-generation partnership project\n(3GPP) has introduced numerology and bandwidth parts (BWPs), via new radio (NR)\nfor service-tailored resource allocation. Legacy 4G networks have generated\nextensive data, which combined with crowd-sourced LTE infrastructure insights,\nenables identification of high-traffic 5G deployment area (5GDA) for planning\nnew services. Given the mission-critical nature of 5G services, QoE is a big\nchallenge for MNOs to guarantee peak data rates for a defined percentage of\ntime. This work studies the fundamentals of 5G network planning methods that\nreconciles coverage-capacity trade-offs through balanced radio network\ndimensioning (RND), leveraging pragmatic NR modeling, and data-driven\nstrategies to minimize deployment costs and reduce cost-per-bit.", "AI": {"tldr": "\u57fa\u4e8e4G\u7f51\u7edc\u6570\u636e\u548c\u7fa4\u667a\u57fa\u7840\u8bbe\u65bd\u89c1\u89e3\uff0c\u7814\u7a765G\u7f51\u7edc\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u7684\u65e0\u7ebf\u7f51\u7edc\u89c4\u6a21\u548c\u6570\u636e\u9a71\u52a8\u7b56\u7565\uff0c\u89e3\u51b3\u8986\u76d6\u4e0e\u5bb9\u91cf\u7684\u6279\u6267\uff0c\u4ee5\u6700\u5c0f\u5316\u90e8\u7f72\u6210\u672c\u548c\u9644\u52a0\u503c\u6210\u672c\u3002", "motivation": "5G\u7f51\u7edc\u9700\u8981\u652f\u6301\u591a\u79cd\u670d\u52a1\u9700\u6c42\uff0c\u5305\u62ec\u9ad8\u6570\u636e\u901f\u7387\u3001\u4f4e\u5ef6\u8fdf\u548c\u4f53\u9a8c\u8d28\u91cf\u3002\u7ee7\u627f4G\u7f51\u7edc\u751f\u6210\u7684\u5927\u91cf\u6570\u636e\u4ee5\u53ca\u7fa4\u667a\u57fa\u7840\u8bbe\u65bd\u89c1\u89e3\uff0c\u53ef\u4ee5\u8bc6\u522b\u9ad8\u6d41\u91cf\u5e03\u5c40\u533a\u57df\uff0c\u4f46\u4f53\u9a8c\u8d28\u91cf\u4ecd\u662f\u7f51\u7edc\u8fd0\u8425\u5546\u9762\u4e34\u7684\u91cd\u5927\u6311\u6218\u3002", "method": "\u63a2\u7d225G\u7f51\u7edc\u89c4\u5212\u7684\u57fa\u7840\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u7684\u65e0\u7ebf\u7f51\u7edc\u89c4\u6a21\u6280\u672f\uff0c\u7ed3\u5408\u5b9e\u7528\u7684\u65b0\u65e0\u7ebf\u7535\u5efa\u6a21\u548c\u6570\u636e\u9a71\u52a8\u7b56\u7565\uff0c\u4ee5\u534f\u8c03\u8986\u76d6\u4e0e\u5bb9\u91cf\u4e4b\u95f4\u7684\u6279\u6267\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u6700\u5c0f\u5316\u90e8\u7f72\u6210\u672c\u548c\u9644\u52a0\u503c\u6210\u672c\u76845G\u7f51\u7edc\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u8bc6\u522b\u9ad8\u6d41\u91cf\u5e03\u5c40\u533a\u57df\uff0c\u5e76\u4f7f\u7528\u65b0\u65e0\u7ebf\u7535\u7684\u6570\u5b57\u5b66\u548c\u5e26\u5bbd\u90e8\u5206\u6765\u652f\u6301\u670d\u52a1\u5c3a\u5bf8\u8c03\u6574\u7684\u8d44\u6e90\u5206\u914d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a5G\u7f51\u7edc\u89c4\u5212\u63d0\u4f9b\u4e86\u57fa\u7840\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u548c\u5e73\u8861\u7684\u65e0\u7ebf\u7f51\u7edc\u89c4\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8986\u76d6\u4e0e\u5bb9\u91cf\u7684\u6279\u6267\uff0c\u5e76\u80fd\u591f\u5728\u4fdd\u8bc1\u4f53\u9a8c\u8d28\u91cf\u7684\u540c\u65f6\u6700\u5c0f\u5316\u90e8\u7f72\u6210\u672c\u548c\u9644\u52a0\u503c\u6210\u672c\uff0c\u5bf9\u4e8e5G\u7f51\u7edc\u7684\u5b9e\u9645\u90e8\u7f72\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.13474", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.13474", "abs": "https://arxiv.org/abs/2508.13474", "authors": ["Bojun Zhang"], "title": "Electromagnetic Signal Modulation Recognition based on Subgraph Embedding Learning", "comment": null, "summary": "Automatic Modulation Recognition (AMR) detects\n  modulation schemes of received signals for further processing\n  of signals without any priori information, which is critically\n  important for civil spectrum regulation, information countermea sures, and\ncommunication security. Due to the powerful feature\n  extraction and classification capabilities of Deep Learning (DL),\n  DL-based AMR algorithms have achieved excellent performance\n  gains compared with traditional modulation detection algorithms.\n  However, all existing DL-based AMR algorithms, to the best of\n  our knowledge, are designed for specific channels and systems,\n  because data dimension of the used training dataset is fixed. To\n  this end, we takes the first step to propose a Subgraph Embedding\n  Learning (SEL) structure to address the classical AMR problem,\n  and the proposed algorithm is called SEL-AMR. Our algorithm\n  treats the communication system as a subgraph and uses the\n  relationship between samples to smooth the effects brought by\n  noise and different channels to extract robust features. Thus,\n  the proposed SEL-AMR algorithm can adapt to any dynamic\n  channels and systems. We use 5 public real datasets and a small\n  amount of simulation data to evaluate our SEL-AMR algorithm.\n  Experimental results reveal that SEL-AMR can well adapt to\n  different channels and systems, and always outperforms the state of-the-art\nalgorithms by improving up to 20% macro-average\n  recognition precision and 30% recognition accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86SEL-AMR\u7b97\u6cd5\uff0c\u9996\u4e2a\u80fd\u591f\u9002\u5e94\u4efb\u610f\u52a8\u6001\u4fe1\u9053\u548c\u7cfb\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b50\u56fe\u5d4c\u5165\u5b66\u4e60\u7ed3\u6784\u63d0\u53d6\u9c81\u68d2\u7279\u5f81\uff0c\u57285\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u6700\u4f18\u7b97\u6cd5\u63d0\u534720%\u5b8f\u5e73\u5747\u8bc6\u522b\u7cbe\u5ea6\u548c30%\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u7b97\u6cd5\u90fd\u662f\u9488\u5bf9\u7279\u5b9a\u4fe1\u9053\u548c\u7cfb\u7edf\u8bbe\u8ba1\u7684\uff0c\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u6570\u636e\u7ef4\u5ea6\u662f\u56fa\u5b9a\u7684\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u901a\u4fe1\u73af\u5883\u3002", "method": "\u63d0\u51fa\u5b50\u56fe\u5d4c\u5165\u5b66\u4e60(SEL)\u7ed3\u6784\uff0c\u5c06\u901a\u4fe1\u7cfb\u7edf\u89c6\u4e3a\u5b50\u56fe\uff0c\u5229\u7528\u6837\u672c\u95f4\u5173\u7cfb\u6765\u5e73\u6ed1\u566a\u58f0\u548c\u4e0d\u540c\u4fe1\u9053\u5e26\u6765\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u63d0\u53d6\u9c81\u68d2\u7279\u5f81\u3002", "result": "\u57285\u4e2a\u516c\u5f00\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5c11\u91cf\u4eff\u771f\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0cSEL-AMR\u80fd\u591f\u5f88\u597d\u5730\u9002\u5e94\u4e0d\u540c\u4fe1\u9053\u548c\u7cfb\u7edf\uff0c\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u7b97\u6cd5\uff0c\u5b8f\u5e73\u5747\u8bc6\u522b\u7cbe\u5ea6\u63d0\u5347\u8fbe20%\uff0c\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u534730%\u3002", "conclusion": "SEL-AMR\u662f\u9996\u4e2a\u80fd\u591f\u9002\u5e94\u4efb\u610f\u52a8\u6001\u4fe1\u9053\u548c\u7cfb\u7edf\u7684\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u7b97\u6cd5\uff0c\u901a\u8fc7\u5b50\u56fe\u5d4c\u5165\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u7279\u5b9a\u4fe1\u9053\u4f9d\u8d56\u7684\u95ee\u9898\u3002"}}
{"id": "2508.13512", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.13512", "abs": "https://arxiv.org/abs/2508.13512", "authors": ["Xiyuan Liu", "Guano Liu", "Xiucheng Tian", "Wenting Wei"], "title": "CountingStars: Low-overhead Network-wide Measurement in LEO Mega-constellation Networks", "comment": null, "summary": "The high mobility of satellites in Low Earth Orbit (LEO) mega-constellations\ninduces a highly dynamic network topology, leading to many problems like\nfrequent service disruptions. To mitigate this, Packet-based Load Balancing\n(PBLB) is employed. However, this paradigm shift introduces two critical\nchallenges for network measurement stemming from the requirement for port-level\ngranularity: memory inflation and severe hash collisions. To tackle these\nchallenges, we propose CountingStars, a low-overhead network-wide measurement\narchitecture. In the ground controller, CountingStars builds a digital twins\nsystem to accurately predict the future network topology. This allows ground\ncontroller to generate and distribute collision-free hash seeds to satellites\nin advance. On the satellite, we introduce a port aggregation data structure\nthat decouples the unique flow identifier from its multi-port counter and\nupdates it through efficient bit operations, solving the memory inflation\ncaused by PBLB. Simulation results show that the memory usage of CountingStars\nis reduced by 70\\% on average, and the relative error of measurement is reduced\nby 90\\% on average. Implementation on FPGA shows its prospect to deploy in real\nsystem.", "AI": {"tldr": "CountingStars\u662f\u4e00\u4e2a\u4f4e\u5f00\u9500\u7684\u7f51\u7edc\u6d4b\u91cf\u67b6\u6784\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u548c\u7aef\u53e3\u805a\u5408\u6570\u636e\u7ed3\u6784\u89e3\u51b3LEO\u661f\u5ea7\u7f51\u7edc\u4e2d\u5305\u8d1f\u8f7d\u5747\u8861\u5e26\u6765\u7684\u5185\u5b58\u81a8\u80c0\u548c\u54c8\u5e0c\u78b0\u649e\u95ee\u9898", "motivation": "LEO\u5de8\u578b\u661f\u5ea7\u7684\u9ad8\u79fb\u52a8\u6027\u5bfc\u81f4\u7f51\u7edc\u62d3\u6251\u9ad8\u5ea6\u52a8\u6001\uff0c\u5305\u8d1f\u8f7d\u5747\u8861(PBLB)\u867d\u7136\u80fd\u7f13\u89e3\u670d\u52a1\u4e2d\u65ad\uff0c\u4f46\u5e26\u6765\u4e86\u7aef\u53e3\u7ea7\u7c92\u5ea6\u8981\u6c42\u5bfc\u81f4\u7684\u5185\u5b58\u81a8\u80c0\u548c\u4e25\u91cd\u54c8\u5e0c\u78b0\u649e\u95ee\u9898", "method": "\u5728\u5730\u9762\u63a7\u5236\u5668\u6784\u5efa\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u9884\u6d4b\u672a\u6765\u7f51\u7edc\u62d3\u6251\uff0c\u63d0\u524d\u751f\u6210\u65e0\u78b0\u649e\u54c8\u5e0c\u79cd\u5b50\uff1b\u5728\u536b\u661f\u4e0a\u91c7\u7528\u7aef\u53e3\u805a\u5408\u6570\u636e\u7ed3\u6784\uff0c\u901a\u8fc7\u9ad8\u6548\u4f4d\u64cd\u4f5c\u89e3\u8026\u6d41\u6807\u8bc6\u7b26\u548c\u591a\u7aef\u53e3\u8ba1\u6570\u5668", "result": "\u5185\u5b58\u4f7f\u7528\u5e73\u5747\u51cf\u5c1170%\uff0c\u6d4b\u91cf\u76f8\u5bf9\u8bef\u5dee\u5e73\u5747\u964d\u4f4e90%\uff0cFPGA\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027", "conclusion": "CountingStars\u6709\u6548\u89e3\u51b3\u4e86PBLB\u5e26\u6765\u7684\u6d4b\u91cf\u6311\u6218\uff0c\u4e3a\u52a8\u6001LEO\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u6d4b\u91cf\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.13581", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.13581", "abs": "https://arxiv.org/abs/2508.13581", "authors": ["Shivank Malik", "Samaresh Bera"], "title": "Security-as-a-Function for IDS/IPS in Softwarized Network and Applications to 5G Network Systems", "comment": "8 pages", "summary": "The service-based architecture of 5G network allows network operators to\nplace virtualized network functions on commodity hardware, unlike the\ntraditional vendor-specific hardware-based functionalities. However, it expands\nthe security vulnerabilities and threats to the 5G network. While there exist\nseveral theoretical studies on network function placement and service routing,\na few focused on the security aspects of the 5G network systems.\n  This paper focuses on safeguarding the 5G core network systems from DoS and\nDDoS attacks by placing intrusion detection and prevention systems (IDS-IPS) as\nvirtualized network functions following the 5G standalone architecture. To\nensure the virtualized placement of IDS-IPS, first, we provide thorough virtual\nmachine (VM)-based and containerized implementation details and evaluate the\nnetwork performance with two scenarios, IDS and IPS, in the presence of TCP and\nUDP applications. Second, we apply the VM-based implementation of IDS-IPS on a\nsoftwarized 5G core network and study the network performances. The experiment\nresults on network throughput, latency, and packet drop reveal that the\nsoftwarized IDS-IPS can meet the QoS requirements of 5G applications, while\nsafeguarding the network from DoS and DDoS attacks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u91c7\u7528\u865a\u62df\u5316IDS-IPS\u7f51\u7edc\u529f\u80fd\u6765\u9632\u62a45G\u6838\u5fc3\u7f51\u7edc\u53d7\u5230DoS/DDoS\u653b\u51fb\uff0c\u901a\u8fc7VM\u548c\u5bb9\u5668\u5316\u5b9e\u73b0\u5e76\u9a8c\u8bc1\u5176\u80fd\u6ee1\u8db35G\u5e94\u7528\u7684QoS\u8981\u6c42\u3002", "motivation": "5G\u7f51\u7edc\u670d\u52a1\u5316\u67b6\u6784\u5e26\u6765\u4e86\u66f4\u591a\u5b89\u5168\u6f0f\u6d1e\u548c\u5a01\u80c1\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5c11\u6709\u5173\u6ce8\u5b89\u5168\u65b9\u9762\u7684\u7f51\u7edc\u529f\u80fd\u90e8\u7f72\u95ee\u9898\u3002", "method": "\u91c7\u7528VM\u548c\u5bb9\u5668\u5316\u65b9\u5f0f\u5b9e\u73b0IDS-IPS\u865a\u62df\u5316\u7f51\u7edc\u529f\u80fd\uff0c\u57285G\u8f6f\u4ef6\u5316\u6838\u5fc3\u7f51\u7edc\u4e2d\u90e8\u7f72\uff0c\u901a\u8fc7\u7f51\u7edc\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\u7b49\u6307\u6807\u8bc4\u4f30\u7f51\u7edc\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8f6f\u4ef6\u5316IDS-IPS\u80fd\u591f\u6ee1\u8db35G\u5e94\u7528\u7684QoS\u8981\u6c42\uff0c\u540c\u65f6\u6709\u6548\u9632\u8303DoS\u548cDDoS\u653b\u51fb\u3002", "conclusion": "\u865a\u62df\u5316IDS-IPS\u57285G\u6838\u5fc3\u7f51\u7edc\u4e2d\u7684\u90e8\u7f72\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\uff0c\u80fd\u5728\u4fdd\u969c\u7f51\u7edc\u5b89\u5168\u7684\u540c\u65f6\u7ef4\u6301\u7f51\u7edc\u6027\u80fd\u3002"}}
{"id": "2508.13167", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.13167", "abs": "https://arxiv.org/abs/2508.13167", "authors": ["Weizhen Li", "Jianbo Lin", "Zhuosong Jiang", "Jingyi Cao", "Xinpeng Liu", "Jiayu Zhang", "Zhenqiang Huang", "Qianben Chen", "Weichen Sun", "Qiexiang Wang", "Hongxuan Lu", "Tianrui Qin", "Chenghao Zhu", "Yi Yao", "Shuying Fan", "Xiaowan Li", "Tiannan Wang", "Pai Liu", "King Zhu", "He Zhu", "Dingfeng Shi", "Piaohong Wang", "Yeyi Guan", "Xiangru Tang", "Minghao Liu", "Yuchen Eleanor Jiang", "Jian Yang", "Jiaheng Liu", "Ge Zhang", "Wangchunshu Zhou"], "title": "Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL", "comment": "51 pages", "summary": "Recent advances in large language models (LLMs) and multi-agent systems have\ndemonstrated remarkable capabilities in complex problem-solving tasks such as\ndeep research, vibe coding, and mathematical reasoning. However, most existing\nmulti-agent systems are built upon manual prompt/workflow engineering with\nsophisticated agent frameworks, making them computationally inefficient, less\ncapable, and can not benefit from data-centric learning. In this work, we\nintroduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables\nnative end-to-end complex problem-solving in the same way as a multi-agent\nsystem (i.e., multi-turn problem solving with multiple tools and multiple\nagents) within one model. In chain-of-agents problem-solving, the model\ndynamically activates different tool agents and role-playing agents to simulate\nmulti-agent collaboration in an end-to-end fashion. To elicit end-to-end\nchain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent\ndistillation framework to distill state-of-the-art multi-agent systems into\nchain-of-agents trajectories for agentic supervised fine-tuning. We then use\nagentic reinforcement learning on verifiable agentic tasks to further improve\nthe models' capabilities on chain-of-agents problem solving. We call the\nresulting models Agent Foundation Models (AFMs). Our empirical studies\ndemonstrate that AFM establishes new state-of-the-art performance across\ndiverse benchmarks in both web agent and code agent settings. We make the\nentire research, including the model weights, code for training and evaluation,\nand the training data, fully open-sourced, which offers a solid starting point\nfor future research on agent models and agentic RL.", "AI": {"tldr": "\u94fe\u5f0f\u673a\u5668\u4eba\u6846\u67b6(CoA)\u901a\u8fc7\u591a\u673a\u5668\u6e17\u9057\u548c\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u51fa\u7aef\u5230\u7aef\u7684\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b(AFM)\uff0c\u5728\u591a\u4efb\u52a1\u8d4b\u80fd\u4e2d\u8fbe\u5230\u65b0\u7684SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u673a\u5668\u7cfb\u7edf\u4f9d\u8d56\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u65e0\u6cd5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u9700\u8981\u4e00\u79cd\u672c\u5730\u7684\u7aef\u5230\u7aef\u590d\u6742\u95ee\u9898\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u94fe\u5f0f\u673a\u5668\u4eba(CoA)\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u673a\u5668\u6e17\u9057\u628aSOTA\u591a\u673a\u5668\u7cfb\u7edf\u8f6c\u6362\u4e3aCoA\u8f68\u8ff9\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u7528\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u8fdb\u4e00\u6b65\u63d0\u5347", "result": "AFM\u6a21\u578b\u5728web agent\u548ccode agent\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0\u7684\u6700\u9ad8\u6027\u80fd\u6c34\u5e73", "conclusion": "\u94fe\u5f0f\u673a\u5668\u4eba\u6846\u67b6\u80fd\u591f\u5728\u5355\u4e2a\u6a21\u578b\u5185\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u591a\u673a\u5668\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u7814\u7a76\u4e3a\u673a\u5668\u4eba\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840"}}
{"id": "2508.13593", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.13593", "abs": "https://arxiv.org/abs/2508.13593", "authors": ["Jianan Bai", "Anubhab Chowdhury", "Anders Hansson", "Erik G. Larsson"], "title": "Repeater Swarm-Assisted Cellular Systems: Interaction Stability and Performance Analysis", "comment": "16 pages, 13 figures. Submitted to IEEE Transactions on Wireless\n  Communications", "summary": "We consider a cellular massive MIMO system where swarms of wireless repeaters\nare deployed to improve coverage. These repeaters are full-duplex relays with\nsmall form factors that receive and instantaneously retransmit signals. They\ncan be deployed in a plug-and-play manner at low cost, while being transparent\nto the network--conceptually they are active channel scatterers with\namplification capabilities. Two fundamental questions need to be addressed in\nrepeater deployments: (I) How can we prevent destructive effects of positive\nfeedback caused by inter-repeater interaction (i.e., each repeater receives and\namplifies signals from others)? (ii) How much performance improvement can be\nachieved given that repeaters also inject noise and may introduce more\ninterference? To answer these questions, we first derive a generalized Nyquist\nstability criterion for the repeater swarm system, and provide an easy-to-check\nstability condition. Then, we study the uplink performance and develop an\nefficient iterative algorithm that jointly optimizes the repeater gains, user\ntransmit powers, and receive combining weights to maximize the weighted sum\nrate while ensuring system stability. Numerical results corroborate our\ntheoretical findings and show that the repeaters can significantly improve the\nsystem performance, both in sub-6 GHz and millimeter-wave bands. The results\nalso warrant careful deployment to fully realize the benefits of repeaters, for\nexample, by ensuring a high probability of line-of-sight links between\nrepeaters and the base station.", "AI": {"tldr": "\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u90e8\u7f72\u4e2d\u7a7a\u91cd\u590d\u5668\u7fa4\u6765\u6539\u5584\u8986\u76d6\uff0c\u89e3\u51b3\u6b63\u5411\u53cd\u9988\u7a33\u5b9a\u6027\u95ee\u9898\u548c\u6027\u80fd\u4f18\u5316\u6311\u6218", "motivation": "\u4e2d\u7a7a\u91cd\u590d\u5668\u7fa4\u4f5c\u4e3a\u4f4e\u6210\u672c\u63d2\u5165\u5f0f\u89e3\u51b3\u65b9\u6848\u53ef\u6539\u5584\u7f51\u7edc\u8986\u76d6\uff0c\u4f46\u9762\u4e34\u91cd\u590d\u5668\u95f4\u4e92\u52a8\u5bfc\u81f4\u7684\u6b63\u5411\u53cd\u9988\u7a33\u5b9a\u6027\u95ee\u9898\u4ee5\u53ca\u566a\u58f0\u548c\u5e72\u6270\u5bf9\u6027\u80fd\u7684\u5f71\u54cd", "method": "\u63a8\u5bfc\u5e7f\u4e49Nyquist\u7a33\u5b9a\u6027\u51c6\u5219\uff0c\u63d0\u4f9b\u6613\u68c0\u67e5\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u8fed\u4ee3\u7b97\u6cd5\u6765\u805a\u5408\u4f18\u5316\u91cd\u590d\u5668\u589e\u76ca\u3001\u7528\u6237\u53d1\u5c04\u529b\u7387\u548c\u63a5\u6536\u7ec4\u5408\u6743\u91cd", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u663e\u793a\u91cd\u590d\u5668\u80fd\u591f\u5728\u6b21-6GHz\u548c\u6beb\u7c73\u6ce2\u6bb5\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u90e8\u7f72\u6761\u4ef6\u4ee5\u4fdd\u8bc1\u91cd\u590d\u5668\u4e0e\u57fa\u7ad9\u95f4\u7684\u89c6\u7ebf\u94fe\u8def\u6982\u7387", "conclusion": "\u4e2d\u7a7a\u91cd\u590d\u5668\u7fa4\u662f\u6539\u5584\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u8986\u76d6\u7684\u6709\u6548\u624b\u6bb5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u4f18\u5316\u7b97\u6cd5\u53ef\u4ee5\u89e3\u51b3\u7a33\u5b9a\u6027\u95ee\u9898\u5e76\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u9700\u8981\u8c28\u614e\u90e8\u7f72\u4ee5\u5145\u5206\u53d1\u6325\u5176\u4f18\u52bf"}}
{"id": "2508.13486", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.13486", "abs": "https://arxiv.org/abs/2508.13486", "authors": ["Chunhui Chen", "Linyi Chen", "Xueyan Niu", "Hao Wu"], "title": "A Convergent Primal-Dual Algorithm for Computing Rate-Distortion-Perception Functions", "comment": null, "summary": "Recent advances in Rate-Distortion-Perception (RDP) theory highlight the\nimportance of balancing compression level, reconstruction quality, and\nperceptual fidelity. While previous work has explored numerical approaches to\napproximate the information RDP function, the lack of theoretical guarantees\nremains a major limitation, especially in the presence of complex perceptual\nconstraints that introduce non-convexity and computational intractability.\nInspired by our previous constrained Blahut-Arimoto algorithm for solving the\nrate-distortion function, in this paper, we present a new theoretical framework\nfor computing the information RDP function by relaxing the constraint on the\nreconstruction distribution and replacing it with an alternative optimization\napproach over the reconstruction distribution itself. This reformulation\nsignificantly simplifies the optimization and enables a rigorous proof of\nconvergence. Based on this formulation, we develop a novel primal-dual\nalgorithm with provable convergence guarantees. Our analysis establishes, for\nthe first time, a rigorous convergence rate of $O(1/n)$ for the computation of\nRDP functions. The proposed method not only bridges a key theoretical gap in\nthe existing literature but also achieves competitive empirical performance in\nrepresentative settings. These results lay the groundwork for more reliable and\ninterpretable optimization in RDP-constrained compression systems. Experimental\nresults demonstrate the efficiency and accuracy of the proposed algorithm.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u6846\u67b6\u5487\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u4fe1\u606f\u7801\u7387-\u5934\u771f-\u611f\u77e5\uff08RDP\uff09\u51fd\u6570\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684RDP\u51fd\u6570\u8ba1\u7b97\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u611f\u77e5\u7ea6\u675f\u4e0b\u5b58\u5728\u975e\u51f8\u6027\u5487\u8ba1\u7b97\u96be\u9898\u3002\u9700\u8981\u4e00\u79cd\u5177\u6709\u4e25\u683c\u6536\u655b\u6027\u8bc1\u660e\u7684\u7b97\u6cd5\u3002", "method": "\u901a\u8fc7\u6539\u53d8\u91cd\u5efa\u5206\u5e03\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u5bf9\u91cd\u5efa\u5206\u5e03\u672c\u8eab\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u539f\u5bf9\u5076\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u7b97\u6cd5\u5177\u6709$O(1/n)$\u7684\u6536\u655b\u901f\u7387\uff0c\u5728\u4ee3\u8868\u6027\u573a\u666f\u4e2d\u8fbe\u5230\u4e86\u7ade\u4e89\u6027\u80fd\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u586b\u8865\u4e86RDP\u7406\u8bba\u4e2d\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u4e3aRDP\u7ea6\u675f\u538b\u7f29\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u5487\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2508.13652", "categories": ["cs.NI", "cs.OS"], "pdf": "https://arxiv.org/pdf/2508.13652", "abs": "https://arxiv.org/abs/2508.13652", "authors": ["L\u00f3r\u00e1nt Meszl\u00e9nyi", "Julius Kahle", "Dominik P\u00fcllen", "Stefan Kowalewski", "Stefan Katzenbeisser", "Alexandru Kampmann"], "title": "Towards Timing Isolation for Mixed-Criticality Communication in Software-Defined Vehicles", "comment": "Accepted at IAVVC 2025; \\copyright 2025 IEEE. Copyright notice\n  included as required.; 8 Pages; 6 Figures", "summary": "As the automotive industry transitions toward centralized Linux-based\narchitectures, ensuring the predictable execution of mixed-criticality\napplications becomes essential. However, concurrent use of the Linux network\nstack introduces interference, resulting in unpredictable latency and jitter.\nTo address this challenge, we present a layered software architecture that\nenforces timing isolation for Ethernet-based data exchange between\nmixed-criticality applications on Linux-based automotive control units. Our\napproach integrates traffic prioritization strategies at the middleware layer,\nthe network stack layer, and the hardware layer to achieve isolation across the\nfull software stack. At the middleware layer, we implement a fixed-priority,\nnon-preemptive scheduler to manage publishers of varying criticality. At the\nnetwork layer, we leverage the express data path (XDP) to route high-priority\ndata directly from the network interface driver into critical application\nmemory, bypassing the standard Linux network stack. At the hardware layer, we\ndedicate a network interface card (NIC) queue exclusively to real-time traffic.\nWe demonstrate how our architecture performs in a Data Distribution Service\n(DDS)-based system. Our evaluation shows that the approach leads to consistent\nand predictable latencies for real-time traffic, even under heavy interference\nfrom best-effort applications.", "AI": {"tldr": "\u57fa\u4e8eLinux\u7684\u6c7d\u8f66\u63a7\u5236\u5355\u5143\u4e2d\u901a\u8fc7\u4e09\u5c42\u9694\u79bb\u67b6\u6784\u5b9e\u73b0\u6df7\u5408\u5173\u952e\u6027\u5e94\u7528\u7684\u53ef\u9884\u6d4b\u7f51\u7edc\u901a\u4fe1", "motivation": "\u89e3\u51b3Linux\u7f51\u7edc\u6808\u5e76\u53d1\u4f7f\u7528\u5bfc\u81f4\u7684\u5e72\u6270\u95ee\u9898\uff0c\u786e\u4fdd\u6df7\u5408\u5173\u952e\u6027\u5e94\u7528\u5728\u6c7d\u8f66\u63a7\u5236\u5355\u5143\u4e2d\u7684\u53ef\u9884\u6d4b\u6267\u884c", "method": "\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a\u4e2d\u95f4\u4ef6\u5c42\u56fa\u5b9a\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\uff0c\u7f51\u7edc\u5c42XDP\u76f4\u63a5\u8def\u7531\u9ad8\u4f18\u5148\u7ea7\u6570\u636e\uff0c\u786c\u4ef6\u5c42\u4e13\u7528NIC\u961f\u5217", "result": "\u5b9e\u73b0\u4e86\u4e00\u81f4\u53ef\u9884\u6d4b\u7684\u5b9e\u65f6\u6d41\u91cf\u5ef6\u8fdf\uff0c\u751a\u81f3\u5728\u91cf\u5e94\u7528\u5e72\u6270\u4e0b\u4e5f\u80fd\u4fdd\u6301\u7a33\u5b9a\u6027", "conclusion": "\u8be5\u591a\u5c42\u9694\u79bb\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86Linux\u57fa\u6c7d\u8f66\u7cfb\u7edf\u4e2d\u6df7\u5408\u5173\u952e\u6027\u5e94\u7528\u7684\u7f51\u7edc\u5e72\u6270\u95ee\u9898"}}
{"id": "2508.13171", "categories": ["cs.AI", "cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.13171", "abs": "https://arxiv.org/abs/2508.13171", "authors": ["Tao An"], "title": "Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context", "comment": "13 pages, 1 figure, code available at\n  https://github.com/tao-hpu/cognitive-workspace", "summary": "Large Language Models (LLMs) face fundamental limitations in context\nmanagement despite recent advances extending context windows to millions of\ntokens. We propose Cognitive Workspace, a novel paradigm that transcends\ntraditional Retrieval-Augmented Generation (RAG) by emulating human cognitive\nmechanisms of external memory use. Drawing from cognitive science foundations\nincluding Baddeley's working memory model, Clark's extended mind thesis, and\nHutchins' distributed cognition framework, we demonstrate that current passive\nretrieval systems fail to capture the dynamic, task-driven nature of human\nmemory management. Our analysis of 2024-2025 developments reveals that while\ntechniques like Infini-attention and StreamingLLM achieve impressive context\nlengths, they lack the metacognitive awareness and active planning capabilities\nessential for true cognitive extension. Cognitive Workspace addresses these\nlimitations through three core innovations: (1) active memory management with\ndeliberate information curation, (2) hierarchical cognitive buffers enabling\npersistent working states, and (3) task-driven context optimization that\ndynamically adapts to cognitive demands. Empirical validation demonstrates\nCognitive Workspace achieves an average 58.6% memory reuse rate (ranging from\n54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%\nnet efficiency gain despite 3.3x higher operation counts. Statistical analysis\nconfirms these advantages with p < 0.001 and Cohen's d > 23 across multiple\ntask types, establishing the first quantitative evidence for active memory\nsuperiority in LLM systems. We present a comprehensive theoretical framework\nsynthesizing insights from 50+ recent papers, positioning Cognitive Workspace\nas a fundamental shift from information retrieval to genuine cognitive\naugmentation.", "AI": {"tldr": "\u63d0\u51fa\u4e86Cognitive Workspace\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u5916\u90e8\u8bb0\u5fc6\u8ba4\u77e5\u673a\u5236\uff0c\u8d85\u8d8a\u4f20\u7edfRAG\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e3b\u52a8\u8bb0\u5fc6\u7ba1\u7406\u548c\u4efb\u52a1\u9a71\u52a8\u4f18\u5316", "motivation": "\u89e3\u51b3LLMs\u5728\u4e0a\u4e0b\u6587\u7ba1\u7406\u65b9\u9762\u7684\u6839\u672c\u9650\u5236\uff0c\u5c3d\u7ba1\u73b0\u6709\u6280\u672f\u80fd\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e3\u81f3\u767e\u4e07token\uff0c\u4f46\u7f3a\u4e4f\u4eba\u7c7b\u8ba4\u77e5\u7684\u52a8\u6001\u4efb\u52a1\u9a71\u52a8\u7279\u6027", "method": "\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u7406\u8bba\uff08Baddeley\u5de5\u4f5c\u8bb0\u5fc6\u6a21\u578b\u3001Clark\u6269\u5c55\u5fc3\u667a\u8bba\u3001Hutchins\u5206\u5e03\u5f0f\u8ba4\u77e5\u6846\u67b6\uff09\uff0c\u91c7\u7528\u4e09\u5927\u521b\u65b0\uff1a\u4e3b\u52a8\u8bb0\u5fc6\u7ba1\u7406\u3001\u5206\u5c42\u8ba4\u77e5\u7f13\u51b2\u5668\u3001\u4efb\u52a1\u9a71\u52a8\u4e0a\u4e0b\u6587\u4f18\u5316", "result": "\u5e73\u574758.6%\u8bb0\u5fc6\u91cd\u7528\u7387\uff08\u4f20\u7edfRAG\u4e3a0%\uff09\uff0c\u51c0\u6548\u7387\u589e\u76ca17-18%\uff0c\u7edf\u8ba1\u663e\u8457\u6027p<0.001\uff0cCohen's d>23", "conclusion": "Cognitive Workspace\u4ee3\u8868\u4e86\u4ece\u4fe1\u606f\u68c0\u7d22\u5230\u771f\u6b63\u8ba4\u77e5\u589e\u5f3a\u7684\u6839\u672c\u6027\u8f6c\u53d8\uff0c\u5efa\u7acb\u4e86\u4e3b\u52a8\u8bb0\u5fc6\u7cfb\u7edf\u4f18\u8d8a\u6027\u7684\u9996\u4e2a\u5b9a\u91cf\u8bc1\u636e"}}
{"id": "2508.13553", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.13553", "abs": "https://arxiv.org/abs/2508.13553", "authors": ["Yang Li", "Shitao Li", "Huimin Lao", "Gaojun Luo", "San Ling"], "title": "On optimal quantum LRCs from the Hermitian construction and $t$-designs", "comment": "17 pages, and a related work is about to be released", "summary": "In a recent work, quantum locally recoverable codes (qLRCs) have been\nintroduced for their potential application in large-scale quantum data storage\nand implication for quantum LDPC codes. This work focuses on the bounds and\nconstructions of qLRCs derived from the Hermitian construction, which solves an\nopen problem proposed by Luo $et~al.$ (IEEE Trans. Inf. Theory, 71 (3):\n1794-1802, 2025). We present four bounds for qLRCs and give comparisons in\nterms of their asymptotic formulas. We construct several new infinite families\nof NMDS codes, with general and flexible dimensions, that support t-designs for\n$t\\in \\{2,3\\}$, and apply them to obtain Hermitian dual-containing classical\nLRCs (cLRCs). As a result, we derive three explicit families of optimal qLRCs.\nCompared to the known qLRCs obtained by the CSS construction, our optimal qLRCs\noffer new and more flexible parameters. It is also worth noting that the\nconstructed cLRCs themselves are interesting as they are optimal with respect\nto four distinct bounds for cLRCs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7Hermitian\u6784\u9020\u65b9\u6cd5\u7814\u7a76\u4e86\u91cf\u5b50\u672c\u5730\u53ef\u6062\u590d\u7801(qLRCs)\u7684\u754c\u9650\u548c\u6784\u9020\uff0c\u89e3\u51b3\u4e86Luo\u7b49\u4eba\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff0c\u5f97\u5230\u4e86\u4e09\u4e2a\u660e\u786e\u7684\u6700\u4f18qLRCs\u5bb6\u65cf\u3002", "motivation": "\u91cf\u5b50\u672c\u5730\u53ef\u6062\u590d\u7801\u5728\u5927\u89c4\u6a21\u91cf\u5b50\u6570\u636e\u5b58\u50a8\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u4e14\u5bf9\u91cf\u5b50LDPC\u7801\u6709\u91cd\u8981\u610f\u4e49\u3002\u672c\u6587\u4e3b\u8981\u89e3\u51b3\u901a\u8fc7Hermitian\u6784\u9020\u65b9\u6cd5\u6765\u63a2\u7d22qLRCs\u7684\u7406\u8bba\u754c\u9650\u548c\u5b9e\u9645\u6784\u9020\u95ee\u9898\u3002", "method": "\u91c7\u7528Hermitian\u6784\u9020\u65b9\u6cd5\uff0c\u9996\u5148\u6784\u9020\u4e86\u51e0\u4e2a\u65b0\u7684\u65e0\u7a77\u5bb6\u65cf\u7684NMDS\u7801\uff08\u975e\u6700\u5927\u5206\u79bb\u53ef\u884c\u7801\uff09\uff0c\u8fd9\u4e9b\u7801\u652f\u6301t-designs\uff08t=2,3\uff09\u4e14\u5177\u6709\u7075\u6d3b\u7684\u7ef4\u6570\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u7801\u5e94\u7528\u4e8e\u83b7\u5f97Hermitian\u5bf9\u5076\u5305\u542b\u7684\u7ecf\u5178LRCs\uff0c\u6700\u7ec8\u5f15\u5bfc\u51fa\u6700\u4f18\u7684qLRCs\u3002", "result": "\u63d0\u51fa\u4e86qLRCs\u7684\u56db\u4e2a\u65b0\u754c\u9650\uff0c\u5e76\u8fdb\u884c\u4e86\u6d41\u884c\u6027\u516c\u5f0f\u6bd4\u8f83\u3002\u6784\u9020\u4e86\u4e09\u4e2a\u660e\u786e\u7684\u6700\u4f18qLRCs\u5bb6\u65cf\uff0c\u8fd9\u4e9b\u7801\u4e0e\u901a\u8fc7CSS\u6784\u9020\u83b7\u5f97\u7684\u5df2\u77e5qLRCs\u76f8\u6bd4\uff0c\u5177\u6709\u66f4\u65b0\u9896\u548c\u7075\u6d3b\u7684\u53c2\u6570\u3002\u540c\u65f6\uff0c\u6784\u9020\u7684\u7ecf\u5178LRCs\u672c\u8eab\u4e5f\u5f88\u6709\u8da3\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u56db\u4e2a\u4e0d\u540c\u7684cLRCs\u754c\u9650\u4e0b\u90fd\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u901a\u8fc7Hermitian\u6784\u9020\u65b9\u6cd5\u5f00\u53d1\u4e86\u65b0\u7684\u91cf\u5b50\u672c\u5730\u53ef\u6062\u590d\u7801\uff0c\u4e0d\u4ec5\u89e3\u51b3\u4e86\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u6bd4\u73b0\u6709CSS\u6784\u9020\u66f4\u4f18\u79f0\u7684\u7801\u7c7b\u3002\u8fd9\u4e9b\u6210\u679c\u5bf9\u5927\u89c4\u6a21\u91cf\u5b50\u6570\u636e\u5b58\u50a8\u548c\u91cf\u5b50\u9519\u8bef\u7ea6\u675f\u7801\u7684\u53d1\u5c55\u90fd\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.13736", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.13736", "abs": "https://arxiv.org/abs/2508.13736", "authors": ["Sebastian Robitzsch", "Laksh Bhatia", "Konstantinos G. Filis", "Neda Petreska", "Michael Bahr", "Pablo Picazo Martinez", "Xi Li"], "title": "Architecture Considerations for ISAC in 6G", "comment": null, "summary": "ISAC is emerging as a foundational capability in 6G, enabling mobile networks\nto not only offer communication services but also to sense and perceive their\nenvironment at scale. This paper explores architectural considerations to\nenable sensing in 6G, extending on recent developments by (pre-)standardisation\nbodies such as 3GPP and ETSI. Selected ISAC use cases are presented from the\nEuropean MultiX project including associated potential functional system\nrequirements. The paper proposes a 6G system architecture that integrates newly\nproposed NFs for the purpose of sensing and demonstrates how they are being\nused in offering sensing as a service. Protocol stack adaptations for both\ncontrol and a newly proposed sensing plane are discussed.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba86G\u4e2d\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1(ISAC)\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u57fa\u4e8e3GPP\u548cETSI\u6807\u51c6\u8fdb\u5c55\uff0c\u63d0\u51fa\u652f\u6301\u611f\u77e5\u670d\u52a1\u7684\u65b0\u578b\u7f51\u7edc\u529f\u80fd\u548c\u534f\u8bae\u6808\u9002\u914d\u65b9\u6848\u3002", "motivation": "6G\u7f51\u7edc\u9700\u8981\u540c\u65f6\u63d0\u4f9b\u901a\u4fe1\u670d\u52a1\u548c\u73af\u5883\u611f\u77e5\u80fd\u529b\uff0cISAC\u4f5c\u4e3a\u57fa\u7840\u80fd\u529b\u9700\u8981\u7cfb\u7edf\u6027\u7684\u67b6\u6784\u652f\u6301\uff0c\u4ee5\u6ee1\u8db3\u672a\u6765\u591a\u573a\u666f\u611f\u77e5\u5e94\u7528\u9700\u6c42\u3002", "method": "\u57fa\u4e8e\u6b27\u6d32MultiX\u9879\u76ee\u7684\u7528\u4f8b\u5206\u6790\uff0c\u63d0\u51fa\u96c6\u6210\u65b0\u578b\u7f51\u7edc\u529f\u80fd(NFs)\u76846G\u7cfb\u7edf\u67b6\u6784\uff0c\u8bbe\u8ba1\u63a7\u5236\u9762\u548c\u65b0\u611f\u77e5\u9762\u7684\u534f\u8bae\u6808\u9002\u914d\u65b9\u6848\u3002", "result": "\u6784\u5efa\u4e86\u652f\u6301\u611f\u77e5\u5373\u670d\u52a1\u76846G\u67b6\u6784\u6846\u67b6\uff0c\u660e\u786e\u4e86\u611f\u77e5\u529f\u80fd\u5728\u7f51\u7edc\u4e2d\u7684\u90e8\u7f72\u65b9\u5f0f\u548c\u534f\u8bae\u652f\u6301\u673a\u5236\u3002", "conclusion": "\u63d0\u51fa\u7684\u67b6\u6784\u65b9\u6848\u4e3a6G ISAC\u6807\u51c6\u5316\u548c\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u63a8\u52a8\u4e86\u611f\u77e5\u80fd\u529b\u5728\u79fb\u52a8\u7f51\u7edc\u4e2d\u7684\u96c6\u6210\u4e0e\u5e94\u7528\u3002"}}
{"id": "2508.13174", "categories": ["cs.AI", "cs.LG", "q-fin.CP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.13174", "abs": "https://arxiv.org/abs/2508.13174", "authors": ["Hongjun Ding", "Binqi Chen", "Jinsheng Huang", "Taian Guo", "Zhengyang Mao", "Guoyi Shao", "Lutong Zou", "Luchen Liu", "Ming Zhang"], "title": "AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining", "comment": "12 pages, 5 figures", "summary": "Formula alpha mining, which generates predictive signals from financial data,\nis critical for quantitative investment. Although various algorithmic\napproaches-such as genetic programming, reinforcement learning, and large\nlanguage models-have significantly expanded the capacity for alpha discovery,\nsystematic evaluation remains a key challenge. Existing evaluation metrics\npredominantly include backtesting and correlation-based measures. Backtesting\nis computationally intensive, inherently sequential, and sensitive to specific\nstrategy parameters. Correlation-based metrics, though efficient, assess only\npredictive ability and overlook other crucial properties such as temporal\nstability, robustness, diversity, and interpretability. Additionally, the\nclosed-source nature of most existing alpha mining models hinders\nreproducibility and slows progress in this field. To address these issues, we\npropose AlphaEval, a unified, parallelizable, and backtest-free evaluation\nframework for automated alpha mining models. AlphaEval assesses the overall\nquality of generated alphas along five complementary dimensions: predictive\npower, stability, robustness to market perturbations, financial logic, and\ndiversity. Extensive experiments across representative alpha mining algorithms\ndemonstrate that AlphaEval achieves evaluation consistency comparable to\ncomprehensive backtesting, while providing more comprehensive insights and\nhigher efficiency. Furthermore, AlphaEval effectively identifies superior\nalphas compared to traditional single-metric screening approaches. All\nimplementations and evaluation tools are open-sourced to promote\nreproducibility and community engagement.", "AI": {"tldr": "\u63d0\u51faAlphaEval\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u81ea\u52a8\u5316alpha\u6316\u6398\u6a21\u578b\uff0c\u89e3\u51b3\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u5305\u62ec\u56db\u79cd\u8865\u5145\u7ef4\u5ea6\u7684\u7efc\u5408\u8bc4\u4f30", "motivation": "\u73b0\u6709alpha\u6316\u6398\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff1a\u56de\u6d4b\u8ba1\u7b97\u7c98\u5ea6\u9ad8\u4e14\u6548\u7387\u4f4e\uff0c\u76f8\u5173\u6027\u6307\u6807\u53ea\u8003\u8651\u9884\u6d4b\u80fd\u529b\u800c\u5ffd\u89c6\u5176\u4ed6\u91cd\u8981\u7279\u6027\uff0c\u540c\u65f6\u95ed\u6e90\u6a21\u578b\u5f71\u54cd\u53ef\u590d\u73b0\u6027", "method": "\u8bbe\u8ba1AlphaEval\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u8865\u5145\u7ef4\u5ea6\u8bc4\u4f30alpha\u8d28\u91cf\uff1a\u9884\u6d4b\u80fd\u529b\u3001\u7a33\u5b9a\u6027\u3001\u5e02\u573a\u5e72\u6270\u9c81\u68d2\u6027\u3001\u91d1\u878d\u903b\u8f91\u6027\u548c\u591a\u6837\u6027\uff0c\u652f\u6301\u5e76\u884c\u5316\u8ba1\u7b97\u4e14\u65e0\u9700\u56de\u6d4b", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aAlphaEval\u8bc4\u4f30\u4e00\u81f4\u6027\u4e0e\u5168\u9762\u56de\u6d4b\u76f8\u5f53\uff0c\u4f46\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u6d1e\u5bdf\u548c\u66f4\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u4f18\u8d28alpha\uff0c\u8d85\u8fc7\u4f20\u7edf\u5355\u6307\u6807\u7b5b\u9009\u65b9\u6cd5", "conclusion": "AlphaEval\u4e3aalpha\u6316\u6398\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u9ad8\u6548\u3001\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5145\u5206\u8003\u8651\u4e86alpha\u7684\u591a\u7ef4\u5ea6\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u9886\u57df\u53ef\u590d\u73b0\u6027\u548c\u793e\u533a\u53c2\u4e0e"}}
{"id": "2508.13555", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.13555", "abs": "https://arxiv.org/abs/2508.13555", "authors": ["Yubo Zhang", "Hassan ZivariFard", "Xiaodong Wang"], "title": "Power and Rate Allocations for Positive-rate Covert Communications in Block-Fading Channels", "comment": "13 pages, 10 figures", "summary": "We aim to achieve keyless covert communication with a positive-rate in\nRayleigh block-fading channels. Specifically, the transmitter and the\nlegitimate receiver are assumed to have either causal or non-causal knowledge\nof the \\ac{CSI} for both the legitimate and the warden channels, while the\nwarden only knows the statistical distribution of the \\ac{CSI}. Two problem\nformulations are considered in this work: (a) Power allocation: maximizing the\nsum covert rate subject to a maximum power constraint, and (b) Rate allocation:\nminimizing the power consumption subject to a minimum covert rate constraint.\nBoth problems are formulated based on recent information theoretical results on\ncovert communication over state-dependent channels. When the \\ac{CSI} of each\nfading block is known non-causally, we propose a novel three-step method to\nsolve both the power and rate allocation problems. In the case where the\n\\ac{CSI} is known causally, the power allocation problem can be formulated as\n\\ac{MDP} and be solved using a \\ac{DDQN} approach. Although the rate allocation\nproblem under causal \\ac{CSI} does not directly conform to an \\ac{MDP}\nstructure, it can be approximately solved using the \\ac{DDQN} trained for power\nallocation. Simulation results demonstrate the effectiveness of the proposed\npower and rate allocation methods and provide comprehensive performance\ncomparisons across different allocation schemes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u745e\u5229\u5757\u8870\u843d\u4fe1\u9053\u4e2d\u65e0\u5bc6\u94a5\u9690\u853d\u901a\u4fe1\u7684\u529f\u7387\u548c\u901f\u7387\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u975e\u56e0\u679cCSI\u7684\u4e09\u6b65\u6cd5\u548c\u57fa\u4e8e\u56e0\u679cCSI\u7684DDQN\u65b9\u6cd5\u6765\u89e3\u51b3\u529f\u7387\u6700\u5927\u5316\u548c\u529f\u8017\u6700\u5c0f\u5316\u95ee\u9898\u3002", "motivation": "\u5728\u745e\u5229\u5757\u8870\u843d\u4fe1\u9053\u4e2d\u5b9e\u73b0\u6b63\u901f\u7387\u7684\u65e0\u5bc6\u94a5\u9690\u853d\u901a\u4fe1\uff0c\u89e3\u51b3\u5f53\u53d1\u5c04\u7aef\u548c\u5408\u6cd5\u63a5\u6536\u7aef\u5177\u6709\u4fe1\u9053\u72b6\u6001\u4fe1\u606f(CSI)\u800c\u76d1\u542c\u8005\u53ea\u6709\u7edf\u8ba1\u4fe1\u606f\u65f6\u7684\u9690\u853d\u901a\u4fe1\u4f18\u5316\u95ee\u9898\u3002", "method": "\u9488\u5bf9\u975e\u56e0\u679cCSI\u63d0\u51fa\u4e09\u6b65\u6cd5\u89e3\u51b3\u529f\u7387\u548c\u901f\u7387\u5206\u914d\u95ee\u9898\uff1b\u9488\u5bf9\u56e0\u679cCSI\u5c06\u529f\u7387\u5206\u914d\u5efa\u6a21\u4e3aMDP\u5e76\u4f7f\u7528DDQN\u6c42\u89e3\uff0c\u901f\u7387\u5206\u914d\u95ee\u9898\u5219\u4f7f\u7528\u8bad\u7ec3\u597d\u7684DDQN\u8fd1\u4f3c\u6c42\u89e3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u529f\u7387\u548c\u901f\u7387\u5206\u914d\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0d\u540c\u5206\u914d\u65b9\u6848\u7684\u5168\u9762\u6027\u80fd\u6bd4\u8f83\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u89e3\u51b3\u4e86\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e2d\u9690\u853d\u901a\u4fe1\u7684\u529f\u7387\u548c\u901f\u7387\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u975e\u56e0\u679c\u548c\u56e0\u679cCSI\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13176", "categories": ["cs.AI", "cs.DB", "68T30 (Primary) 68P15, 03B70 (Secondary)", "I.2.4; H.2.3"], "pdf": "https://arxiv.org/pdf/2508.13176", "abs": "https://arxiv.org/abs/2508.13176", "authors": ["Simon Hosemann", "Jean Christoph Jung", "Carsten Lutz", "Sebastian Rudolph"], "title": "Fitting Ontologies and Constraints to Relational Structures", "comment": "Accepted at the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2025)", "summary": "We study the problem of fitting ontologies and constraints to positive and\nnegative examples that take the form of a finite relational structure. As\nontology and constraint languages, we consider the description logics\n$\\mathcal{E\\mkern-2mu L}$ and $\\mathcal{E\\mkern-2mu LI}$ as well as several\nclasses of tuple-generating dependencies (TGDs): full, guarded,\nfrontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion\ndependencies. We pinpoint the exact computational complexity, design\nalgorithms, and analyze the size of fitting ontologies and TGDs. We also\ninvestigate the related problem of constructing a finite basis of concept\ninclusions / TGDs for a given set of finite structures. While finite bases\nexist for $\\mathcal{E\\mkern-2mu L}$, $\\mathcal{E\\mkern-2mu LI}$, guarded TGDs,\nand inclusion dependencies, they in general do not exist for full,\nfrontier-guarded and frontier-one TGDs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u4ece\u6b63\u8d1f\u793a\u4f8b\u4e2d\u62df\u5408\u672c\u4f53\u548c\u7ea6\u675f\uff0c\u91cd\u70b9\u5173\u6ce8\u63cf\u8ff0\u903b\u8f91EL\u548cELI\u4ee5\u53ca\u591a\u79cdTGD\u7c7b\u578b\uff0c\u5206\u6790\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u3001\u7b97\u6cd5\u8bbe\u8ba1\u3001\u62df\u5408\u672c\u4f53\u5927\u5c0f\uff0c\u5e76\u63a2\u8ba8\u4e86\u6709\u9650\u57fa\u7684\u5b58\u5728\u6027\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u4ece\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7684\u6b63\u8d1f\u793a\u4f8b\u4e2d\u81ea\u52a8\u5b66\u4e60\u672c\u4f53\u548c\u7ea6\u675f\uff0c\u8fd9\u5bf9\u4e8e\u77e5\u8bc6\u8868\u793a\u548c\u6570\u636e\u5e93\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u6784\u5efa\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u7528\u63cf\u8ff0\u903b\u8f91EL\u548cELI\u4ee5\u53ca\u591a\u79cd\u7c7b\u578b\u7684\u5143\u7ec4\u751f\u6210\u4f9d\u8d56(TGD)\u4f5c\u4e3a\u672c\u4f53\u548c\u7ea6\u675f\u8bed\u8a00\uff0c\u5206\u6790\u4e0d\u540c\u8bed\u8a00\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bbe\u8ba1\u76f8\u5e94\u7684\u62df\u5408\u7b97\u6cd5\uff0c\u5e76\u7814\u7a76\u6709\u9650\u57fa\u7684\u6784\u9020\u95ee\u9898\u3002", "result": "\u7cbe\u786e\u786e\u5b9a\u4e86\u5404\u79cd\u8bed\u8a00\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u7b97\u6cd5\uff0c\u5206\u6790\u4e86\u62df\u5408\u672c\u4f53\u7684\u5927\u5c0f\u9650\u5236\uff0c\u5e76\u53d1\u73b0\u5bf9\u4e8eEL\u3001ELI\u3001\u4fdd\u62a4TGD\u548c\u5305\u542b\u4f9d\u8d56\u5b58\u5728\u6709\u9650\u57fa\uff0c\u4f46\u5bf9\u4e8e\u5b8c\u5168\u3001\u524d\u6cbf\u4fdd\u62a4\u548c\u524d\u6cbf\u4e00TGD\u901a\u5e38\u4e0d\u5b58\u5728\u6709\u9650\u57fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4ece\u793a\u4f8b\u4e2d\u5b66\u4e60\u672c\u4f53\u548c\u7ea6\u675f\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u7b97\u6cd5\u652f\u6301\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u8bed\u8a00\u5728\u53ef\u5b66\u4e60\u6027\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u5bf9\u77e5\u8bc6\u8868\u793a\u548c\u6570\u636e\u5e93\u7406\u8bba\u7684\u81ea\u52a8\u5316\u5b66\u4e60\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.13177", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13177", "abs": "https://arxiv.org/abs/2508.13177", "authors": ["Nikola Pi\u017eurica", "Nikola Milovi\u0107", "Igor Jovan\u010devi\u0107", "Conor Heins", "Miguel de Prado"], "title": "A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment", "comment": null, "summary": "Active Inference (AIF) offers a robust framework for decision-making, yet its\ncomputational and memory demands pose challenges for deployment, especially in\nresource-constrained environments. This work presents a methodology that\nfacilitates AIF's deployment by integrating pymdp's flexibility and efficiency\nwith a unified, sparse, computational graph tailored for hardware-efficient\nexecution. Our approach reduces latency by over 2x and memory by up to 35%,\nadvancing the deployment of efficient AIF agents for real-time and embedded\napplications.", "AI": {"tldr": "\u901a\u8fc7\u7edf\u4e00\u7684\u7a00\u758f\u8ba1\u7b97\u56fe\u4f18\u5316\uff0c\u5c06pymdp\u7684\u7075\u6d3b\u6027\u4e0e\u786c\u4ef6\u6548\u7387\u76f8\u7ed3\u5408\uff0c\u4f7f\u4e3b\u52a8\u63a8\u65ad\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u6210\u4e3a\u53ef\u80fd", "motivation": "\u4e3b\u52a8\u63a8\u65ad(AIF)\u867d\u7136\u63d0\u4f9b\u4e86\u5065\u58ee\u7684\u51b3\u7b56\u6846\u67b6\uff0c\u4f46\u5176\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u9762\u4e34\u6311\u6218", "method": "\u96c6\u6210pymdp\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u6784\u5efa\u4e13\u95e8\u4e3a\u786c\u4ef6\u6548\u7387\u6267\u884c\u800c\u8bbe\u8ba1\u7684\u7edf\u4e00\u7a00\u758f\u8ba1\u7b97\u56fe", "result": "\u5ef6\u8fdf\u51cf\u5c112\u500d\u4ee5\u4e0a\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u6700\u9ad8\u51cf\u5c1135%", "conclusion": "\u8be5\u65b9\u6cd5\u63a8\u8fdb\u4e86\u9ad8\u6548AIF\u4ee3\u7406\u5728\u5b9e\u65f6\u548c\u5d4c\u5165\u5f0f\u5e94\u7528\u4e2d\u7684\u90e8\u7f72"}}
{"id": "2508.13842", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.13842", "abs": "https://arxiv.org/abs/2508.13842", "authors": ["Chunjie Wang", "Xuhui Zhang", "Jinke Ren", "Wenchao Liu", "Shuqiang Wang", "Yanyan Shen", "Kejiang Ye", "Chengzhong Xu", "Dusit Niyato"], "title": "Joint Beamforming Design for RIS-Empowered NOMA-ISAC Systems", "comment": "13 pages, 9 figures, this manuscript has been submitted to IEEE", "summary": "This paper investigates a reconfigurable intelligent surface (RIS)-assisted\nintegrated sensing and communication (ISAC) system and proposes a joint\ncommunication and sensing beamforming design based on non-orthogonal multiple\naccess (NOMA) technology. The system employs a dual-functional base station\n(DFBS) to simultaneously serve multiple users and sense multiple targets with\nthe aid of RIS. To maximize the sum-rate of users, we jointly optimize the\nDFBS's active beamforming, the RIS's reflection coefficients, and the radar\nreceive filters. The optimization is performed under constraints including the\nradar signal-to-noise ratio thresholds, the user\nsignal-to-interference-plus-noise ratio requirements, the phase shifts of the\nRIS, the total transmit power, the receive filters, and the successive\ninterference cancellation decoding order. To tackle the complex\ninterdependencies and non-convex nature of the optimization problem, we\nintroduce an effective iterative algorithm based on the alternating\noptimization framework. Simulation results demonstrate that the proposed\nalgorithm outperforms baseline algorithms, highlighting its distinct advantages\nin the considered RIS-empowered NOMA-ISAC systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eNOMA\u6280\u672f\u7684RIS\u8f85\u52a9\u611f\u77e5\u901a\u4fe1\u4e00\u4f53\u5316\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u8054\u5408\u901a\u4fe1\u611f\u77e5\u653e\u5927\u5668\u8bbe\u8ba1\u65b9\u6848\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u7cfb\u7edf\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u5728RIS\u8f85\u52a9\u7684ISAC\u7cfb\u7edf\u4e2d\u540c\u65f6\u4f18\u5316\u901a\u4fe1\u548c\u611f\u77e5\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u53cc\u529f\u80fd\u57fa\u7ad9\u4e3b\u52a8\u653e\u5927\u3001RIS\u53cd\u5c04\u7cfb\u6570\u548c\u96f7\u8fbe\u63a5\u6536\u6ee4\u6ce2\u5668\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u7528\u6237\u603b\u901f\u7387\u7684\u6700\u5927\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u7684\u8fed\u4ee3\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u53cc\u529f\u80fd\u57fa\u7ad9\u7684\u4e3b\u52a8\u653e\u5927\u3001RIS\u7684\u53cd\u5c04\u7cfb\u6570\u548c\u96f7\u8fbe\u63a5\u6536\u6ee4\u6ce2\u5668\u3002\u7b97\u6cd5\u8003\u8651\u4e86\u591a\u79cd\u7ea6\u675f\u6761\u4ef6\uff0c\u5305\u62ec\u96f7\u8fbe\u4fe1\u566a\u6bd4\u9608\u503c\u3001\u7528\u6237\u5e72\u6270\u566a\u6bd4\u8981\u6c42\u3001RIS\u76f8\u4f4d\u79fb\u7b49\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u8003\u8651\u7684RIS\u589e\u5f3a\u578bNOMA-ISAC\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8276\uff0c\u6027\u80fd\u663e\u8457\u8d85\u8fc7\u57fa\u7ebf\u7b97\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8054\u5408\u4f18\u5316\u7b97\u6cd5\uff0c\u4e3aRIS\u8f85\u52a9\u7684NOMA-ISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6027\u80fd\u4f18\u5316\u65b9\u6848\uff0c\u663e\u793a\u4e86\u5728\u540c\u65f6\u652f\u6301\u591a\u7528\u6237\u901a\u4fe1\u548c\u591a\u76ee\u6807\u611f\u77e5\u7684\u590d\u6742\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.13178", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.13178", "abs": "https://arxiv.org/abs/2508.13178", "authors": ["Cong Zhang"], "title": "The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task", "comment": null, "summary": "To elevate the foundational capabilities and generalization prowess of the\ntext-to-SQL model in real-world applications, we integrate model\ninterpretability analysis with execution-guided strategy for semantic parsing\nof WHERE clauses in SQL queries. Furthermore, we augment this approach with\nfiltering adjustments, logical correlation refinements, and model fusion,\nculminating in the design of the CESQL model that facilitates conditional\nenhancement. Our model excels on the WikiSQL dataset, which is emblematic of\nsingle-table database query tasks, markedly boosting the accuracy of prediction\noutcomes. When predicting conditional values in WHERE clauses, we have not only\nminimized our dependence on data within the condition columns of tables but\nalso circumvented the impact of manually labeled training data. Our hope is\nthat this endeavor to enhance accuracy in processing basic database queries\nwill offer fresh perspectives for research into handling complex queries and\nscenarios featuring irregular data in real-world database environments.", "AI": {"tldr": "\u901a\u8fc7\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u548c\u6267\u884c\u5bfc\u5411\u7b56\u7565\uff0c\u7ed3\u5408\u7b5b\u9009\u8c03\u6574\u3001\u903b\u8f91\u5173\u8054\u7cbe\u70bc\u548c\u6a21\u578b\u878d\u5408\uff0c\u63d0\u51faCESQL\u6a21\u578b\u6765\u63d0\u5347WHERE\u5b50\u53e5\u8bed\u4e49\u89e3\u6790\u7684\u51c6\u786e\u6027\u548c\u901a\u7528\u6027", "motivation": "\u63d0\u5347\u6587\u672c\u5230SQL\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u57fa\u7840\u80fd\u529b\u548c\u901a\u7528\u6027\uff0c\u7279\u522b\u662f\u5728WHERE\u5b50\u53e5\u8bed\u4e49\u89e3\u6790\u65b9\u9762", "method": "\u6574\u5408\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u4e0e\u6267\u884c\u5bfc\u5411\u7b56\u7565\uff0c\u7ed3\u5408\u7b5b\u9009\u8c03\u6574\u3001\u903b\u8f91\u5173\u8054\u7cbe\u70bc\u548c\u6a21\u578b\u878d\u5408\u6280\u672f\uff0c\u8bbe\u8ba1CESQL\u6765\u5b9e\u73b0\u6761\u4ef6\u589e\u5f3a", "result": "\u5728WikiSQL\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7ed3\u679c\u7684\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u5bf9\u8868\u683c\u6761\u4ef6\u5217\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u907f\u514d\u4e86\u4eba\u5de5\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5904\u7406\u57fa\u7840\u6570\u636e\u5e93\u67e5\u8be2\u63d0\u4f9b\u4e86\u51c6\u786e\u6027\u63d0\u5347\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u5904\u7406\u590d\u6742\u67e5\u8be2\u548c\u5b9e\u9645\u6570\u636e\u5e93\u4e2d\u4e0d\u89c4\u5219\u6570\u636e\u7684\u7814\u7a76\u5f00\u542f\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2508.13180", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13180", "abs": "https://arxiv.org/abs/2508.13180", "authors": ["Ziwen Han", "Meher Mankikar", "Julian Michael", "Zifan Wang"], "title": "Search-Time Data Contamination", "comment": null, "summary": "Data contamination refers to the leakage of evaluation data into model\ntraining data, resulting in overfitting to supposedly held-out test sets and\ncompromising test validity. We identify an analogous issue, search-time\ncontamination (STC), in evaluating search-based LLM agents which use tools to\ngather information from online sources when answering user queries. STC occurs\nwhen the retrieval step surfaces a source containing the test question (or a\nnear-duplicate) alongside its answer, enabling agents to copy rather than\ngenuinely infer or reason, undermining benchmark integrity. We find that\nHuggingFace, an online platform hosting evaluation datasets, appears among\nretrieved sources in search based agent logs. Consequently, agents often\nexplicitly acknowledge discovering question answer pairs from HuggingFace\nwithin their reasoning chains. On three commonly used capability benchmarks:\nHumanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for\napproximately 3% of questions, search-based agents directly find the datasets\nwith ground truth labels on HuggingFace. When millions of evaluation queries\ntarget the same benchmark, even small, repeated leaks can accelerate the\nbenchmark's obsolescence, shortening its intended lifecycle. After HuggingFace\nis blocked, we observe a drop in accuracy on the contaminated subset of\napproximately 15%. We further show through ablation experiments that publicly\naccessible evaluation datasets on HuggingFace may not be the sole source of\nSTC. To this end, we conclude by proposing best practices for benchmark design\nand result reporting to address this novel form of leakage and ensure\ntrustworthy evaluation of search-based LLM agents. To facilitate the auditing\nof evaluation results, we also publicly release the complete logs from our\nexperiments.", "AI": {"tldr": "\u641c\u7d22\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u8bc4\u4f30\u5b58\u5728\u641c\u7d22\u65f6\u6c61\u67d3\u95ee\u9898\uff0c\u5f53\u4ee3\u7406\u901a\u8fc7\u641c\u7d22\u83b7\u53d6\u5230HuggingFace\u4e0a\u7684\u6d4b\u8bd5\u6570\u636e\u96c6\u65f6\uff0c\u4f1a\u76f4\u63a5\u62f7\u8d1d\u7b54\u6848\u800c\u975e\u771f\u6b63\u63a8\u7406\uff0c\u5bfc\u81f4\u8bc4\u6d4b\u7ed3\u679c\u5931\u771f\u3002\u57283%\u7684\u95ee\u9898\u4e2d\u53d1\u73b0\u4e86\u8fd9\u79cd\u6c61\u67d3\uff0c\u963b\u585eHuggingFace\u540e\u51c6\u786e\u7387\u4e0b\u964d\u7ea615%\u3002", "motivation": "\u8bc6\u522b\u548c\u63ed\u793a\u641c\u7d22\u57fa\u4e8eLLM\u4ee3\u7406\u8bc4\u4f30\u4e2d\u5b58\u5728\u7684\u65b0\u578b\u6c61\u67d3\u95ee\u9898\uff0c\u5373\u641c\u7d22\u65f6\u6c61\u67d3\uff0c\u8fd9\u79cd\u6c61\u67d3\u4f1a\u5bfc\u81f4\u4ee3\u7406\u76f4\u63a5\u83b7\u53d6\u6d4b\u8bd5\u7b54\u6848\u800c\u975e\u771f\u6b63\u8fdb\u884c\u63a8\u7406\uff0c\u5f71\u54cd\u8bc4\u6d4b\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5728\u4e09\u4e2a\u5e38\u7528\u80fd\u529b\u6d4b\u8bd5\u96c6\uff08HLE\u3001SimpleQA\u3001GPQA\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u641c\u7d22\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u8bbf\u95ee\u8bb0\u5f55\uff0c\u68c0\u6d4b\u662f\u5426\u4eceHuggingFace\u7b49\u5728\u7ebf\u5e73\u53f0\u83b7\u53d6\u5230\u6d4b\u8bd5\u6570\u636e\u96c6\u3002\u901a\u8fc7\u963b\u585eHuggingFace\u6765\u9a8c\u8bc1\u6c61\u67d3\u6548\u679c\uff0c\u5e76\u8fdb\u884c\u5206\u79bb\u5b9e\u9a8c\u4ee5\u786e\u8ba4\u6c61\u67d3\u6e90\u3002", "result": "\u53d1\u73b0\u7ea63%\u7684\u95ee\u9898\u5b58\u5728\u76f4\u63a5\u4eceHuggingFace\u83b7\u53d6\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u60c5\u51b5\u3002\u963b\u585eHuggingFace\u540e\uff0c\u5728\u53d7\u6c61\u67d3\u95ee\u9898\u5b50\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u4e0b\u964d\u7ea615%\uff0c\u8bc1\u660e\u6c61\u67d3\u5bf9\u8bc4\u4f30\u7ed3\u679c\u6709\u663e\u8457\u5f71\u54cd\u3002\u5206\u79bb\u5b9e\u9a8c\u663e\u793aHuggingFace\u53ef\u80fd\u4e0d\u662f\u552f\u4e00\u7684\u6c61\u67d3\u6e90\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5bf9\u4ed8\u641c\u7d22\u65f6\u6c61\u67d3\u95ee\u9898\u7684\u6700\u4f73\u5b9e\u8df5\u5efa\u8bae\uff0c\u5305\u62ec\u6d4b\u8bd5\u96c6\u8bbe\u8ba1\u548c\u7ed3\u679c\u62a5\u544a\u65b9\u9762\u7684\u6539\u8fdb\u63aa\u65bd\uff0c\u4ee5\u786e\u4fdd\u641c\u7d22\u57fa\u4e8eLLM\u4ee3\u7406\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002\u540c\u65f6\u516c\u5f00\u5b8c\u6574\u5b9e\u9a8c\u65e5\u5fd7\u4ee5\u4fbf\u5ba1\u8ba1\u9a8c\u8bc1\u3002"}}
{"id": "2508.13204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13204", "abs": "https://arxiv.org/abs/2508.13204", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "QuickMerge++: Fast Token Merging with Autoregressive Prior", "comment": "The paper has been accepted to ICML Tokshop at\n  https://openreview.net/forum?id=dMdxHd0tRf", "summary": "As generative models scale to larger inputs across language, vision, and\nvideo domains, the cost of token-level computation has become a key bottleneck.\nWhile prior work suggests that only a subset of tokens significantly influence\ndownstream predictions, most token selection methods are static,\nmodality-specific, or incompatible with autoregressive generation. In this\npaper, we propose QuickMerge, a lightweight token merging framework designed\nfor efficient next-token prediction.\n  QuickMerge dynamically selects a reduced number of tokens based on attention\nnorm magnitude, guided by an entropy-based budget estimator. To preserve\nautoregressive compatibility, we introduce a lightweight transformer prior\ntrained over the merged token sequence. By combining semantic salience\nestimation, flexible token budgets, and AR alignment, QuickMerge enables\naccurate generation with fewer tokens.\n  We evaluate QuickMerge across multi-modality domains, demonstrating\nconsistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge\nreduces token counts sustantially while matching as well as exceeding the\nperformance of learned tokenizers and fixed-patch baselines.", "AI": {"tldr": "QuickMerge\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7token\u5408\u5e76\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u8303\u6570\u52a8\u6001\u9009\u62e9\u91cd\u8981token\uff0c\u4f7f\u7528\u71b5\u9884\u7b97\u4f30\u8ba1\u5668\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u81ea\u56de\u5f52\u751f\u6210\u517c\u5bb9\u6027", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u5904\u7406\u66f4\u5927\u89c4\u6a21\u8f93\u5165\uff0ctoken\u7ea7\u522b\u7684\u8ba1\u7b97\u6210\u672c\u6210\u4e3a\u5173\u952e\u74f6\u9888\uff0c\u73b0\u6709token\u9009\u62e9\u65b9\u6cd5\u5927\u591a\u662f\u9759\u6001\u7684\u3001\u6a21\u6001\u7279\u5b9a\u7684\u6216\u4e0d\u517c\u5bb9\u81ea\u56de\u5f52\u751f\u6210", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u8303\u6570\u52a8\u6001\u9009\u62e9\u91cd\u8981token\uff0c\u4f7f\u7528\u71b5\u9884\u7b97\u4f30\u8ba1\u5668\u786e\u5b9atoken\u6570\u91cf\uff0c\u5f15\u5165\u8f7b\u91cf\u7ea7transformer\u5148\u9a8c\u5728\u5408\u5e76token\u5e8f\u5217\u4e0a\u8bad\u7ec3\u4ee5\u4fdd\u6301\u81ea\u56de\u5f52\u517c\u5bb9\u6027", "result": "\u5728\u591a\u6a21\u6001\u9886\u57df\u8bc4\u4f30\u663e\u793a\uff0cQuickMerge\u663e\u8457\u51cf\u5c11token\u6570\u91cf\uff0c\u540c\u65f6\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u5b66\u4e60\u578btokenizer\u548c\u56fa\u5b9apatch\u57fa\u7ebf\u7684\u6027\u80fd", "conclusion": "QuickMerge\u901a\u8fc7\u8bed\u4e49\u663e\u8457\u6027\u4f30\u8ba1\u3001\u7075\u6d3btoken\u9884\u7b97\u548c\u81ea\u56de\u5f52\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u7528\u66f4\u5c11token\u8fdb\u884c\u51c6\u786e\u751f\u6210\uff0c\u5728\u8ba1\u7b97-\u7cbe\u5ea6\u6743\u8861\u65b9\u9762\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb"}}
{"id": "2508.13213", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13213", "abs": "https://arxiv.org/abs/2508.13213", "authors": ["Adamo Cerioli", "Edward D. Lee", "Vito D. P. Servedio"], "title": "AI sustains higher strategic tension than humans in chess", "comment": null, "summary": "Strategic decision-making involves managing the tension between immediate\nopportunities and long-term objectives. We study this trade-off in chess by\ncharacterizing and comparing dynamics between human vs human and AI vs AI\ngames. We propose a network-based metric of piece-to-piece interaction to\nquantify the ongoing strategic tension on the board. Its evolution in games\nreveals that the most competitive AI players sustain higher levels of strategic\ntension for longer durations than elite human players. Cumulative tension\nvaries with algorithmic complexity for AI and correspondingly in human-played\ngames increases abruptly with expertise at about 1600 Elo and again at 2300\nElo. The profiles reveal different approaches. Highly competitive AI tolerates\ninterconnected positions balanced between offensive and defensive tactics over\nlong periods. Human play, in contrast, limits tension and game complexity,\nwhich may reflect cognitive limitations and adaptive strategies. The difference\nmay have implications for AI usage in complex, strategic environments.", "AI": {"tldr": "\u68cb\u724c\u4e2d\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u5728\u6218\u7565\u51b3\u7b56\u4e2d\u7684\u5dee\u5f02\uff1aAI\u80fd\u7ef4\u6301\u66f4\u9ad8\u6c34\u5e73\u7684\u6218\u7565\u5f20\u529b\u548c\u66f4\u957f\u65f6\u95f4\u7684\u653b\u9632\u5e73\u8861\uff0c\u800c\u4eba\u7c7b\u56e0\u8ba4\u77e5\u9650\u5236\u800c\u66f4\u559c\u6b22\u63a7\u5236\u6e38\u620f\u590d\u6742\u5ea6\u3002", "motivation": "\u7814\u7a76\u6218\u7565\u51b3\u7b56\u4e2d\u77ac\u65f6\u673a\u4f1a\u4e0e\u957f\u671f\u76ee\u6807\u7684\u7f81\u7eca\u5173\u7cfb\uff0c\u901a\u8fc7\u68cb\u724c\u6a21\u578b\u5bf9\u6bd4\u4eba\u7c7b\u548cAI\u5728\u7ef4\u6301\u6218\u7565\u5f20\u529b\u65b9\u9762\u7684\u4e0d\u540c\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7f51\u7edc\u7684\u68cb\u5b50\u4e92\u52a8\u6307\u6807\u6765\u5b9a\u91cf\u68cb\u5c40\u4e2d\u7684\u6218\u7565\u5f20\u529b\uff0c\u5e76\u5206\u6790\u4eba\u4eba\u5bf9\u5c40\u548cAI\u5bf9\u5c40\u4e2d\u8be5\u6307\u6807\u7684\u6f14\u53d8\u89c4\u5f8b\u3002", "result": "\u7ade\u4e89\u529b\u5f3a\u7684AI\u80fd\u5728\u66f4\u957f\u65f6\u95f4\u5185\u7ef4\u6301\u66f4\u9ad8\u6c34\u5e73\u7684\u6218\u7565\u5f20\u529b\uff1b\u4eba\u7c7b\u6e38\u620f\u7684\u7d2f\u8ba1\u5f20\u529b\u5728Elo\u8bc4\u52061600\u548c2300\u9644\u8fd1\u51fa\u73b0\u7a81\u589e\uff1bAI\u66f4\u80fd\u5bf9\u62c5\u957f\u671f\u7684\u653b\u9632\u5e73\u8861\u72b6\u6001\uff0c\u800c\u4eba\u7c7b\u66f4\u504f\u5411\u63a7\u5236\u6e38\u620f\u590d\u6742\u5ea6\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u5728\u7ef4\u6301\u957f\u671f\u6218\u7565\u5f20\u529b\u65b9\u9762\u663e\u793a\u51fa\u8d85\u8d8a\u4eba\u7c7b\u7684\u80fd\u529b\uff0c\u8fd9\u53ef\u80fd\u4f53\u73b0\u4e86\u4eba\u7c7b\u7684\u8ba4\u77e5\u9650\u5236\u548c\u9002\u5e94\u6027\u7b56\u7565\uff0c\u5bf9\u4e8eAI\u5728\u590d\u6742\u6218\u7565\u73af\u5883\u4e2d\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.13250", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.13250", "abs": "https://arxiv.org/abs/2508.13250", "authors": ["Zeyu Zhang", "Yang Zhang", "Haoran Tan", "Rui Li", "Xu Chen"], "title": "Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information", "comment": "15 pages, 13 figures, 3 tables", "summary": "In large language model-based agents, memory serves as a critical capability\nfor achieving personalization by storing and utilizing users' information.\nAlthough some previous studies have adopted memory to implement user\npersonalization, they typically focus on preference alignment and simple\nquestion-answering. However, in the real world, complex tasks often require\nmulti-hop reasoning on a large amount of user information, which poses\nsignificant challenges for current memory approaches. To address this\nlimitation, we propose the multi-hop personalized reasoning task to explore how\ndifferent memory mechanisms perform in multi-hop reasoning over personalized\ninformation. We explicitly define this task and construct a dataset along with\na unified evaluation framework. Then, we implement various explicit and\nimplicit memory methods and conduct comprehensive experiments. We evaluate\ntheir performance on this task from multiple perspectives and analyze their\nstrengths and weaknesses. Besides, we explore hybrid approaches that combine\nboth paradigms and propose the HybridMem method to address their limitations.\nWe demonstrate the effectiveness of our proposed model through extensive\nexperiments. To benefit the research community, we release this project at\nhttps://github.com/nuster1128/MPR.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u7814\u7a76\u4e0d\u540c\u8bb0\u5fc6\u673a\u5236\u5728\u4e2a\u6027\u5316\u4fe1\u606f\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u6784\u5efa\u4e86\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86HybridMem\u6df7\u5408\u65b9\u6cd5\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4e2a\u6027\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u504f\u597d\u5bf9\u9f50\u548c\u7b80\u5355\u95ee\u7b54\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u4efb\u52a1\u9700\u8981\u5bf9\u5927\u91cf\u7528\u6237\u4fe1\u606f\u8fdb\u884c\u591a\u8df3\u63a8\u7406\uff0c\u5f53\u524d\u8bb0\u5fc6\u65b9\u6cd5\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "method": "\u660e\u786e\u5b9a\u4e49\u591a\u8df3\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u6784\u5efa\u6570\u636e\u96c6\u548c\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u73b0\u5404\u79cd\u663e\u5f0f\u548c\u9690\u5f0f\u8bb0\u5fc6\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u6df7\u5408\u65b9\u6cd5\u63d0\u51faHybridMem\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\u4ece\u591a\u89d2\u5ea6\u8bc4\u4f30\u4e0d\u540c\u8bb0\u5fc6\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5206\u6790\u5176\u4f18\u7f3a\u70b9\uff0c\u5e76\u8bc1\u660eHybridMem\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u89e3\u51b3\u4e2a\u6027\u5316\u4fe1\u606f\u7684\u591a\u8df3\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u548c\u8bc4\u4f30\u6846\u67b6\uff0cHybridMem\u65b9\u6cd5\u6709\u6548\u7ed3\u5408\u4e86\u663e\u5f0f\u548c\u9690\u5f0f\u8bb0\u5fc6\u7684\u4f18\u52bf\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.13251", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2508.13251", "abs": "https://arxiv.org/abs/2508.13251", "authors": ["Di Zhang", "Xue Jia", "Tran Ba Hung", "Seong Hoon Jang", "Linda Zhang", "Ryuhei Sato", "Yusuke Hashimoto", "Toyoto Sato", "Kiyoe Konno", "Shin-ichi Orimo", "Hao Li"], "title": "\"DIVE\" into Hydrogen Storage Materials Discovery with AI Agents", "comment": "23 pages, 5 figures. The supplementary video is available at the\n  GitHub link provided in the manuscript", "summary": "Data-driven artificial intelligence (AI) approaches are fundamentally\ntransforming the discovery of new materials. Despite the unprecedented\navailability of materials data in the scientific literature, much of this\ninformation remains trapped in unstructured figures and tables, hindering the\nconstruction of large language model (LLM)-based AI agent for automated\nmaterials design. Here, we present the Descriptive Interpretation of Visual\nExpression (DIVE) multi-agent workflow, which systematically reads and\norganizes experimental data from graphical elements in scientific literatures.\nWe focus on solid-state hydrogen storage materials-a class of materials central\nto future clean-energy technologies and demonstrate that DIVE markedly improves\nthe accuracy and coverage of data extraction compared to the direct extraction\nby multimodal models, with gains of 10-15% over commercial models and over 30%\nrelative to open-source models. Building on a curated database of over 30,000\nentries from 4,000 publications, we establish a rapid inverse design workflow\ncapable of identifying previously unreported hydrogen storage compositions in\ntwo minutes. The proposed AI workflow and agent design are broadly transferable\nacross diverse materials, providing a paradigm for AI-driven materials\ndiscovery.", "AI": {"tldr": "DIVE\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u901a\u8fc7\u7cfb\u7edf\u8bfb\u53d6\u548c\u7ec4\u7ec7\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u56fe\u5f62\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6750\u6599\u6570\u636e\u63d0\u53d6\u51c6\u786e\u6027\uff0c\u5efa\u7acb\u4e86\u5305\u542b3\u4e07\u6761\u6570\u636e\u7684\u6c22\u5b58\u50a8\u6750\u6599\u6570\u636e\u5e93\uff0c\u5b9e\u73b0\u5feb\u901f\u9006\u5411\u8bbe\u8ba1", "motivation": "\u79d1\u5b66\u6587\u732e\u4e2d\u5927\u91cf\u6750\u6599\u6570\u636e\u88ab\u56f0\u5728\u975e\u7ed3\u6784\u5316\u7684\u56fe\u8868\u4e2d\uff0c\u963b\u788d\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u667a\u80fd\u4f53\u8fdb\u884c\u81ea\u52a8\u5316\u6750\u6599\u8bbe\u8ba1", "method": "\u63d0\u51faDIVE\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u7cfb\u7edf\u8bfb\u53d6\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u56fe\u5f62\u5143\u7d20\u6570\u636e\uff0c\u4e13\u6ce8\u4e8e\u56fa\u6001\u6c22\u5b58\u50a8\u6750\u6599\u7684\u6570\u636e\u63d0\u53d6\u548c\u7ec4\u7ec7", "result": "\u76f8\u6bd4\u591a\u6a21\u6001\u6a21\u578b\u76f4\u63a5\u63d0\u53d6\uff0cDIVE\u7cbe\u5ea6\u63d0\u534710-15%\uff08\u5546\u4e1a\u6a21\u578b\uff09\u548c30%\u4ee5\u4e0a\uff08\u5f00\u6e90\u6a21\u578b\uff09\uff0c\u5efa\u7acb\u4e86\u5305\u542b4,000\u7bc7\u6587\u732e30,000\u6761\u6570\u636e\u7684\u6570\u636e\u5e93\uff0c\u80fd\u57282\u5206\u949f\u5185\u8bc6\u522b\u672a\u62a5\u9053\u7684\u6c22\u5b58\u50a8\u6210\u5206", "conclusion": "DIVE\u5de5\u4f5c\u6d41\u548c\u667a\u80fd\u4f53\u8bbe\u8ba1\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e0d\u540c\u6750\u6599\u9886\u57df\uff0c\u4e3aAI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2508.13256", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.13256", "abs": "https://arxiv.org/abs/2508.13256", "authors": ["Yuting Zhang", "Karina V. Bunting", "Asgher Champsi", "Xiaoxia Wang", "Wenqi Lu", "Alexander Thorley", "Sandeep S Hothi", "Zhaowen Qiu", "Dipak Kotecha", "Jinming Duan"], "title": "CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support", "comment": null, "summary": "Cardiovascular diseases (CVDs) remain the foremost cause of mortality\nworldwide, a burden worsened by a severe deficit of healthcare workers.\nArtificial intelligence (AI) agents have shown potential to alleviate this gap\nvia automated early detection and proactive screening, yet their clinical\napplication remains limited by: 1) prompt-based clinical role assignment that\nrelies on intrinsic model capabilities without domain-specific tool support; or\n2) rigid sequential workflows, whereas clinical care often requires adaptive\nreasoning that orders specific tests and, based on their results, guides\npersonalised next steps; 3) general and static knowledge bases without\ncontinuous learning capability; and 4) fixed unimodal or bimodal inputs and\nlack of on-demand visual outputs when further clarification is needed. In\nresponse, a multimodal framework, CardAIc-Agents, was proposed to augment\nmodels with external tools and adaptively support diverse cardiac tasks.\nSpecifically, a CardiacRAG agent generated general plans from updatable cardiac\nknowledge, while the chief agent integrated tools to autonomously execute these\nplans and deliver decisions. To enable adaptive and case-specific\ncustomization, a stepwise update strategy was proposed to dynamically refine\nplans based on preceding execution results, once the task was assessed as\ncomplex. In addition, a multidisciplinary discussion tool was introduced to\ninterpret challenging cases, thereby supporting further adaptation. When\nclinicians raised concerns, visual review panels were provided to assist final\nvalidation. Experiments across three datasets showed the efficiency of\nCardAIc-Agents compared to mainstream Vision-Language Models (VLMs),\nstate-of-the-art agentic systems, and fine-tuned VLMs.", "AI": {"tldr": "CardAIc-Agents\u662f\u4e00\u4e2a\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u901a\u8fc7\u5916\u90e8\u5de5\u5177\u589e\u5f3a\u548c\u81ea\u9002\u5e94\u63a8\u7406\u6765\u89e3\u51b3\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u4e34\u5e8a\u6311\u6218\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u662f\u5168\u7403\u4e3b\u8981\u6b7b\u56e0\uff0c\u4f46\u533b\u7597\u5de5\u4f5c\u8005\u4e25\u91cd\u77ed\u7f3a\u3002\u73b0\u6709AI\u7cfb\u7edf\u5b58\u5728\u4e34\u5e8a\u89d2\u8272\u5206\u914d\u4f9d\u8d56\u63d0\u793a\u5de5\u7a0b\u3001\u5de5\u4f5c\u6d41\u7a0b\u50f5\u5316\u3001\u77e5\u8bc6\u5e93\u9759\u6001\u3001\u8f93\u5165\u8f93\u51fa\u6a21\u5f0f\u56fa\u5b9a\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u6846\u67b6CardAIc-Agents\uff1a1)CardiacRAG\u4ee3\u7406\u4ece\u53ef\u66f4\u65b0\u77e5\u8bc6\u5e93\u751f\u6210\u901a\u7528\u8ba1\u5212\uff1b2)\u4e3b\u4ee3\u7406\u96c6\u6210\u5de5\u5177\u81ea\u4e3b\u6267\u884c\u8ba1\u5212\uff1b3)\u9010\u6b65\u66f4\u65b0\u7b56\u7565\u52a8\u6001\u4f18\u5316\u590d\u6742\u4efb\u52a1\u8ba1\u5212\uff1b4)\u591a\u5b66\u79d1\u8ba8\u8bba\u5de5\u5177\u5904\u7406\u7591\u96be\u75c5\u4f8b\uff1b5)\u89c6\u89c9\u5ba1\u67e5\u9762\u677f\u8f85\u52a9\u6700\u7ec8\u9a8c\u8bc1\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCardAIc-Agents\u76f8\u6bd4\u4e3b\u6d41\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3001\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u7cfb\u7edf\u548c\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6548\u7387\u3002", "conclusion": "CardAIc-Agents\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u548c\u81ea\u9002\u5e94\u63a8\u7406\u6709\u6548\u89e3\u51b3\u4e86\u5fc3\u8840\u7ba1AI\u8bca\u65ad\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u4e34\u5e8aAI\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13327", "abs": "https://arxiv.org/abs/2508.13327", "authors": ["Sarthak Khanna", "Armin Berger", "David Berghaus", "Tobias Deusser", "Lorenz Sparrenberg", "Rafet Sifa"], "title": "Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention", "comment": "Accepted in IEEE-DSAA 2025", "summary": "We propose STONK (Stock Optimization using News Knowledge), a multimodal\nframework integrating numerical market indicators with sentiment-enriched news\nembeddings to improve daily stock-movement prediction. By combining numerical &\ntextual embeddings via feature concatenation and cross-modal attention, our\nunified pipeline addresses limitations of isolated analyses. Backtesting shows\nSTONK outperforms numeric-only baselines. A comprehensive evaluation of fusion\nstrategies and model configurations offers evidence-based guidance for scalable\nmultimodal financial forecasting. Source code is available on GitHub", "AI": {"tldr": "STONK\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u80a1\u7968\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u503c\u5e02\u573a\u6307\u6807\u548c\u60c5\u611f\u589e\u5f3a\u7684\u65b0\u95fb\u5d4c\u5165\uff0c\u901a\u8fc7\u7279\u5f81\u62fc\u63a5\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347\u80a1\u7968\u6da8\u8dcc\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u80a1\u7968\u9884\u6d4b\u65b9\u6cd5\u5f80\u5f80\u5b64\u7acb\u5206\u6790\u6570\u503c\u6216\u6587\u672c\u4fe1\u606f\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u591a\u6e90\u6570\u636e\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u9700\u8981\u5f00\u53d1\u7edf\u4e00\u7684\u591a\u6a21\u6001\u6846\u67b6\u6765\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u7279\u5f81\u62fc\u63a5\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5c06\u6570\u503c\u5e02\u573a\u6307\u6807\u4e0e\u60c5\u611f\u589e\u5f3a\u7684\u65b0\u95fb\u5d4c\u5165\u8fdb\u884c\u878d\u5408\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u591a\u6a21\u6001\u9884\u6d4b\u7ba1\u9053\u3002", "result": "\u56de\u6d4b\u7ed3\u679c\u663e\u793aSTONK\u5728\u80a1\u7968\u6da8\u8dcc\u9884\u6d4b\u4e0a\u4f18\u4e8e\u4ec5\u4f7f\u7528\u6570\u503c\u6307\u6807\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u91d1\u878d\u9884\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u6570\u503c\u548c\u6587\u672c\u4fe1\u606f\u7684\u4ef7\u503c\uff0c\u6e90\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002"}}
{"id": "2508.13333", "categories": ["cs.AI", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.13333", "abs": "https://arxiv.org/abs/2508.13333", "authors": ["Chentong Chen", "Mengyuan Zhong", "Jianyong Sun", "Ye Fan", "Jialong Shi"], "title": "HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design", "comment": "9 pages, 6 figures", "summary": "LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation\n(EC) frameworks has shown promising results. However, its effectiveness is\nhindered by the use of static operators and the lack of knowledge accumulation\nmechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two\nsynergistic prompting strategies: Foresight and Hindsight. Foresight-based\nprompts adaptively steer the search based on population dynamics, managing the\nexploration-exploitation trade-off. In addition, hindsight-based prompts mimic\nhuman expertise by distilling successful heuristics from past generations into\nfundamental, reusable design principles. This dual mechanism transforms\ntransient discoveries into a persistent knowledge base, enabling the LLM to\nlearn from its own experience. Empirical results demonstrate that HiFo-Prompt\nsignificantly outperforms state-of-the-art LLM-based AHD methods, generating\nhigher-quality heuristics while achieving substantially faster convergence and\nsuperior query efficiency.", "AI": {"tldr": "HiFo-Prompt\u6846\u67b6\u901a\u8fc7\u524d\u77bb\u6027\u548c\u540e\u987e\u6027\u63d0\u793a\u7b56\u7565\uff0c\u89e3\u51b3\u4e86LLM\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u9759\u6001\u7b97\u5b50\u548c\u77e5\u8bc6\u79ef\u7d2f\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u542f\u53d1\u5f0f\u751f\u6210\u8d28\u91cf\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5728\u8fdb\u5316\u8ba1\u7b97\u4e2d\u5b58\u5728\u9759\u6001\u7b97\u5b50\u4f7f\u7528\u548c\u7f3a\u4e4f\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faHiFo-Prompt\u6846\u67b6\uff0c\u5305\u542b\u4e24\u79cd\u534f\u540c\u63d0\u793a\u7b56\u7565\uff1a\u524d\u77bb\u6027\u63d0\u793a\u57fa\u4e8e\u79cd\u7fa4\u52a8\u6001\u81ea\u9002\u5e94\u5f15\u5bfc\u641c\u7d22\uff0c\u7ba1\u7406\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff1b\u540e\u987e\u6027\u63d0\u793a\u4ece\u8fc7\u5f80\u6210\u529f\u542f\u53d1\u5f0f\u4e2d\u63d0\u70bc\u53ef\u91cd\u7528\u8bbe\u8ba1\u539f\u5219\uff0c\u6784\u5efa\u6301\u4e45\u77e5\u8bc6\u5e93\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793aHiFo-Prompt\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684LLM-based AHD\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u542f\u53d1\u5f0f\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4f18\u7684\u67e5\u8be2\u6548\u7387\u3002", "conclusion": "HiFo-Prompt\u7684\u53cc\u91cd\u673a\u5236\u6210\u529f\u5c06\u77ac\u65f6\u53d1\u73b0\u8f6c\u5316\u4e3a\u6301\u4e45\u77e5\u8bc6\uff0c\u4f7fLLM\u80fd\u591f\u4ece\u81ea\u8eab\u7ecf\u9a8c\u4e2d\u5b66\u4e60\uff0c\u4e3a\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u77e5\u8bc6\u79ef\u7d2f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13371", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13371", "abs": "https://arxiv.org/abs/2508.13371", "authors": ["Ronit Virwani", "Ruchika Suryawanshi"], "title": "LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems", "comment": "Submitted to IAAI-26", "summary": "Planning is one of the most critical tasks in autonomous systems, where even\na small error can lead to major failures or million-dollar losses. Current\nstate-of-the-art neural planning approaches struggle with complex domains,\nproducing plans with missing preconditions, inconsistent goals, and\nhallucinations. While classical planners provide logical guarantees, they lack\nthe flexibility and natural language understanding capabilities needed for\nmodern autonomous systems. Existing neuro-symbolic approaches use one-shot\ntranslation from natural language to formal plans, missing the opportunity for\nneural and symbolic components to work and refine solutions together. To\naddress this gap, we develop LOOP -- a novel neuro-symbolic planning framework\nthat treats planning as an iterative conversation between neural and symbolic\ncomponents rather than simple translation. LOOP integrates 13 coordinated\nneural features including graph neural networks for spatial relationships,\nmulti-agent validation for consensus-based correctness, hierarchical\ndecomposition for complex task management, and causal memory that learns from\nboth successes and failures. Unlike existing approaches, LOOP generates PDDL\nspecifications, refines them iteratively based on symbolic feedback, and builds\na causal knowledge base from execution traces. LOOP was evaluated on six\nstandard IPC benchmark domains, where it achieved 85.8% success rate compared\nto LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This\nwork shows that the key to reliable planning is not in choosing between neural\nnetworks or symbolic reasoners but it lies in making them actually ``talk'' to\neach other during the entire process. LOOP provides a thorough blueprint for\nbuilding autonomous systems that can finally be trusted with critical\nreal-world applications.", "AI": {"tldr": "LOOP\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u795e\u7ecf\u7b26\u53f7\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u548c\u7b26\u53f7\u7ec4\u4ef6\u4e4b\u95f4\u7684\u8fed\u4ee3\u5bf9\u8bdd\u6765\u89e3\u51b3\u590d\u6742\u89c4\u5212\u95ee\u9898\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523085.8%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u89c4\u5212\u65b9\u6cd5\u5728\u590d\u6742\u9886\u57df\u5b58\u5728\u7f3a\u5931\u524d\u63d0\u6761\u4ef6\u3001\u76ee\u6807\u4e0d\u4e00\u81f4\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u800c\u7ecf\u5178\u89c4\u5212\u5668\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u91c7\u7528\u4e00\u6b21\u6027\u7ffb\u8bd1\u65b9\u5f0f\uff0c\u65e0\u6cd5\u5b9e\u73b0\u795e\u7ecf\u548c\u7b26\u53f7\u7ec4\u4ef6\u7684\u534f\u540c\u4f18\u5316\u3002", "method": "LOOP\u5c06\u89c4\u5212\u89c6\u4e3a\u795e\u7ecf\u548c\u7b26\u53f7\u7ec4\u4ef6\u4e4b\u95f4\u7684\u8fed\u4ee3\u5bf9\u8bdd\uff0c\u96c6\u6210\u4e8613\u4e2a\u534f\u8c03\u7684\u795e\u7ecf\u7279\u5f81\uff0c\u5305\u62ec\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u591a\u667a\u80fd\u4f53\u9a8c\u8bc1\u3001\u5206\u5c42\u5206\u89e3\u548c\u56e0\u679c\u8bb0\u5fc6\uff0c\u80fd\u591f\u751f\u6210PDDL\u89c4\u8303\u5e76\u6839\u636e\u7b26\u53f7\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u516d\u4e2a\u6807\u51c6IPC\u57fa\u51c6\u57df\u4e0a\u8bc4\u4f30\uff0cLOOP\u8fbe\u523085.8%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8eLLM+P\uff0855.0%\uff09\u3001LLM-as-Planner\uff0819.2%\uff09\u548cTree-of-Thoughts\uff083.3%\uff09\u3002", "conclusion": "\u53ef\u9760\u89c4\u5212\u7684\u5173\u952e\u4e0d\u5728\u4e8e\u9009\u62e9\u795e\u7ecf\u7f51\u7edc\u8fd8\u662f\u7b26\u53f7\u63a8\u7406\u5668\uff0c\u800c\u5728\u4e8e\u8ba9\u5b83\u4eec\u5728\u8fc7\u7a0b\u4e2d\u771f\u6b63\"\u5bf9\u8bdd\"\u3002LOOP\u4e3a\u6784\u5efa\u53ef\u4fe1\u7684\u5173\u952e\u73b0\u5b9e\u5e94\u7528\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8be6\u7ec6\u84dd\u56fe\u3002"}}
{"id": "2508.13387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13387", "abs": "https://arxiv.org/abs/2508.13387", "authors": ["Thye Shan Ng", "Caren Soyeon Han", "Eun-Jung Holden"], "title": "SPANER: Shared Prompt Aligner for Multimodal Semantic Representation", "comment": null, "summary": "Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have\nsignificantly improved performance on downstream tasks such as few-shot\nretrieval. However, most existing approaches focus on task-specific gains while\nneglecting the structure of the multimodal embedding space. As a result,\nmodality-specific representations often remain isolated, limiting cross-modal\ngeneralisation. In this work, we introduce Shared Prompt AligNER (SPANER), a\nmodality-agnostic PEFT framework designed to embed inputs from diverse\nmodalities into a unified semantic space. At its core, SPANER employs a shared\nprompt mechanism that acts as a conceptual anchor, enabling semantically\nrelated instances to converge spatially regardless of modality. This shared\nprompt design is inherently extensible, supporting the seamless integration of\nadditional modalities, such as audio, without altering the core architecture.\nThrough comprehensive experiments across vision-language and audio-visual\nbenchmarks, SPANER demonstrates competitive few-shot retrieval performance\nwhile preserving high semantic coherence in the learned embedding space. Our\nresults highlight the importance of aligning embedding structures, rather than\nmerely tuning adapter weights, for scalable multimodal learning.", "AI": {"tldr": "SPANER\u662f\u4e00\u4e2a\u6a21\u6001\u65e0\u5173\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u63d0\u793a\u673a\u5236\u5c06\u4e0d\u540c\u6a21\u6001\u8f93\u5165\u5d4c\u5165\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\u4e2d\uff0c\u63d0\u5347\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001PEFT\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u5d4c\u5165\u7a7a\u95f4\u7684\u7ed3\u6784\uff0c\u5bfc\u81f4\u6a21\u6001\u7279\u5b9a\u8868\u793a\u5b64\u7acb\uff0c\u9650\u5236\u4e86\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faSPANER\u6846\u67b6\uff0c\u91c7\u7528\u5171\u4eab\u63d0\u793a\u673a\u5236\u4f5c\u4e3a\u6982\u5ff5\u951a\u70b9\uff0c\u4f7f\u8bed\u4e49\u76f8\u5173\u7684\u5b9e\u4f8b\u5728\u7a7a\u95f4\u4e2d\u6c47\u805a\uff0c\u652f\u6301\u65e0\u7f1d\u96c6\u6210\u97f3\u9891\u7b49\u989d\u5916\u6a21\u6001\u800c\u65e0\u9700\u6539\u53d8\u6838\u5fc3\u67b6\u6784\u3002", "result": "\u5728\u89c6\u89c9-\u8bed\u8a00\u548c\u97f3\u9891-\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPANER\u5c55\u793a\u4e86\u7ade\u4e89\u529b\u7684\u5c11\u6837\u672c\u68c0\u7d22\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u7a7a\u95f4\u4e2d\u4fdd\u6301\u4e86\u9ad8\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5bf9\u9f50\u5d4c\u5165\u7ed3\u6784\uff08\u800c\u975e\u4ec5\u4ec5\u8c03\u6574\u9002\u914d\u5668\u6743\u91cd\uff09\u5bf9\u4e8e\u53ef\u6269\u5c55\u591a\u6a21\u6001\u5b66\u4e60\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.13404", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13404", "abs": "https://arxiv.org/abs/2508.13404", "authors": ["Nicole Cho", "Kirsty Fielding", "William Watson", "Sumitra Ganesh", "Manuela Veloso"], "title": "TASER: Table Agents for Schema-guided Extraction and Recommendation", "comment": null, "summary": "Real-world financial documents report essential information about an entity's\nfinancial holdings that can span millions of different financial instrument\ntypes. Yet, these details are often buried in messy, multi-page, fragmented\ntables - for example, 99.4% of the tables in our dataset have no bounding boxes\nwith the maximum number of rows amounting to 426 per table across 44 pages. To\ntackle these unique challenges from real-world tables, we present a\ncontinuously learning, agentic table extraction system, TASER (Table Agents for\nSchema-guided Extraction and Recommendation) that extracts highly unstructured,\nmulti-page, heterogeneous tables into normalized, schema-conforming outputs.\nOur table agents execute on table detection, classification, extraction, and\nrecommendations by leveraging an initial schema. Then, our Recommender Agent\nreviews the outputs, recommends schema revisions, and decides on the final\nrecommendations, enabling TASER to outperform existing table detection models\nsuch as Table Transformer by 10.1%. Within this continuous learning process, we\nhighlight that larger batch sizes result in a 104.3% increase in schema\nrecommendations that are actionable and utilized, resulting in a 9.8% increase\nin extracted holdings - highlighting the importance of a continuous learning\nprocess. To train TASER, we have manually labeled 22,584 pages (28,150,449\ntokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of\nthe first real financial table datasets. We release our dataset TASERTab to\nenable the research community to access real-world financial tables and\noutputs. Our results highlight the promise of agentic, schema-guided extraction\nsystems for robust understanding of real-world financial tables.", "AI": {"tldr": "TASER\u662f\u4e00\u4e2a\u6301\u7eed\u5b66\u4e60\u7684\u667a\u80fd\u8868\u683c\u63d0\u53d6\u7cfb\u7edf\uff0c\u4e13\u95e8\u5904\u7406\u91d1\u878d\u6587\u6863\u4e2d\u9ad8\u5ea6\u975e\u7ed3\u6784\u5316\u7684\u591a\u9875\u5f02\u6784\u8868\u683c\uff0c\u901a\u8fc7\u6a21\u5f0f\u5f15\u5bfc\u7684\u63d0\u53d6\u548c\u63a8\u8350\u673a\u5236\uff0c\u5728\u8868\u683c\u68c0\u6d4b\u6027\u80fd\u4e0a\u8d85\u8d8a\u73b0\u6709\u6a21\u578b10.1%\uff0c\u5e76\u80fd\u663e\u8457\u63d0\u5347\u63d0\u53d6\u6548\u679c\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u91d1\u878d\u6587\u6863\u4e2d\u7684\u8d22\u52a1\u6301\u4ed3\u4fe1\u606f\u901a\u5e38\u9690\u85cf\u5728\u6742\u4e71\u3001\u591a\u9875\u3001\u788e\u7247\u5316\u7684\u8868\u683c\u4e2d\uff0899.4%\u7684\u8868\u683c\u6ca1\u6709\u8fb9\u754c\u6846\uff0c\u6700\u591a426\u884c\u8de844\u9875\uff09\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u9ad8\u5ea6\u975e\u7ed3\u6784\u5316\u7684\u8868\u683c\u6570\u636e\u3002", "method": "\u5f00\u53d1\u4e86TASER\u7cfb\u7edf\uff0c\u5305\u542b\u8868\u683c\u4ee3\u7406\u6267\u884c\u8868\u683c\u68c0\u6d4b\u3001\u5206\u7c7b\u3001\u63d0\u53d6\u548c\u63a8\u8350\uff0c\u5229\u7528\u521d\u59cb\u6a21\u5f0f\u8fdb\u884c\u5de5\u4f5c\uff0c\u7136\u540e\u7531\u63a8\u8350\u4ee3\u7406\u5ba1\u67e5\u8f93\u51fa\u3001\u63a8\u8350\u6a21\u5f0f\u4fee\u8ba2\u5e76\u51b3\u5b9a\u6700\u7ec8\u5efa\u8bae\uff0c\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "TASER\u5728\u8868\u683c\u68c0\u6d4b\u4e0a\u6bd4Table Transformer\u7b49\u73b0\u6709\u6a21\u578b\u63d0\u534710.1%\uff1b\u66f4\u5927\u7684\u6279\u6b21\u5927\u5c0f\u4f7f\u53ef\u64cd\u4f5c\u7684\u6a21\u5f0f\u63a8\u8350\u589e\u52a0104.3%\uff0c\u63d0\u53d6\u6301\u4ed3\u589e\u52a09.8%\uff1b\u6784\u5efa\u4e86\u5305\u542b22,584\u9875\u30013,213\u4e2a\u8868\u683c\u30017310\u4ebf\u7f8e\u5143\u6301\u4ed3\u7684\u771f\u5b9e\u91d1\u878d\u8868\u683c\u6570\u636e\u96c6TASERTab\u3002", "conclusion": "\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u5f0f\u5f15\u5bfc\u63d0\u53d6\u7cfb\u7edf\u5728\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u91d1\u878d\u8868\u683c\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u5bf9\u4e8e\u63d0\u5347\u63d0\u53d6\u6548\u679c\u81f3\u5173\u91cd\u8981\uff0c\u53d1\u5e03\u7684TASERTab\u6570\u636e\u96c6\u5c06\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u5b9d\u8d35\u7684\u771f\u5b9e\u91d1\u878d\u8868\u683c\u8d44\u6e90\u3002"}}
{"id": "2508.13421", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.13421", "abs": "https://arxiv.org/abs/2508.13421", "authors": ["Gabrielle Wehr", "Reuben Rideaux", "Amaya J. Fox", "David R. Lightfoot", "Jason Tangen", "Jason B. Mattingley", "Shane E. Ehrhardt"], "title": "Virtuous Machines: Towards Artificial General Science", "comment": null, "summary": "Artificial intelligence systems are transforming scientific discovery by\naccelerating specific research tasks, from protein structure prediction to\nmaterials design, yet remain confined to narrow domains requiring substantial\nhuman oversight. The exponential growth of scientific literature and increasing\ndomain specialisation constrain researchers' capacity to synthesise knowledge\nacross disciplines and develop unifying theories, motivating exploration of\nmore general-purpose AI systems for science. Here we show that a\ndomain-agnostic, agentic AI system can independently navigate the scientific\nworkflow - from hypothesis generation through data collection to manuscript\npreparation. The system autonomously designed and executed three psychological\nstudies on visual working memory, mental rotation, and imagery vividness,\nexecuted one new online data collection with 288 participants, developed\nanalysis pipelines through 8-hour+ continuous coding sessions, and produced\ncompleted manuscripts. The results demonstrate the capability of AI scientific\ndiscovery pipelines to conduct non-trivial research with theoretical reasoning\nand methodological rigour comparable to experienced researchers, though with\nlimitations in conceptual nuance and theoretical interpretation. This is a step\ntoward embodied AI that can test hypotheses through real-world experiments,\naccelerating discovery by autonomously exploring regions of scientific space\nthat human cognitive and resource constraints might otherwise leave unexplored.\nIt raises important questions about the nature of scientific understanding and\nthe attribution of scientific credit.", "AI": {"tldr": "\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u80fd\u591f\u81ea\u4e3b\u5b8c\u6210\u79d1\u5b66\u7814\u7a76\u7684\u5168\u8fc7\u7a0b\uff0c\u5305\u62ec\u5047\u8bbe\u751f\u6210\u3001\u6570\u636e\u6536\u96c6\u548c\u7a3f\u4ef6\u51c6\u5907\uff0c\u5e76\u6210\u529f\u8fdb\u884c\u4e86\u4e09\u4e2a\u5fc3\u7406\u5b66\u5b9e\u9a8c", "motivation": "\u79d1\u5b66\u6587\u732e\u6307\u6570\u589e\u957f\u548c\u9886\u57df\u4e13\u95e8\u5316\u9650\u5236\u4e86\u7814\u7a76\u8005\u8de8\u9886\u57df\u77e5\u8bc6\u7efc\u5408\u80fd\u529b\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684AI\u7cfb\u7edf\u6765\u52a0\u901f\u79d1\u5b66\u53d1\u73b0", "method": "\u57fa\u4e8e\u9886\u57df\u65e0\u5173\u7684\u4ee3\u7406AI\u7cfb\u7edf\uff0c\u81ea\u4e3b\u8bbe\u8ba1\u548c\u6267\u884c\u4e86\u4e09\u4e2a\u5fc3\u7406\u5b66\u5b9e\u9a8c\uff08\u89c6\u89c9\u5de5\u4f5c\u8bb0\u5fc6\u3001\u5fc3\u7406\u65cb\u8f6c\u3001\u60f3\u8c61\u751f\u52a8\u6027\uff09\uff0c\u8fdb\u884c\u5728\u7ebf\u6570\u636e\u6536\u96c6\u5e76\u5f00\u53d1\u5206\u6790\u6d41\u7a0b", "result": "\u7cfb\u7edf\u6210\u529f\u6536\u96c6\u4e86288\u540d\u53c2\u4e0e\u8005\u7684\u6570\u636e\uff0c\u901a\u8fc78\u5c0f\u65f6\u4ee5\u4e0a\u7684\u8fde\u7eed\u7f16\u7801\u5f00\u53d1\u4e86\u5206\u6790\u6d41\u7a0b\uff0c\u751f\u6210\u4e86\u5b8c\u6574\u7684\u7a3f\u4ef6\uff0c\u8868\u73b0\u51fa\u4e0e\u7ecf\u9a8c\u4e30\u5bcc\u7814\u7a76\u8005\u76f8\u5f53\u7684\u7406\u8bba\u63a8\u7406\u548c\u65b9\u6cd5\u8bba\u4e25\u8c28\u6027", "conclusion": "\u8fd9\u662f\u5411\u80fd\u591f\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u6d4b\u8bd5\u5047\u8bbe\u7684\u4f53\u73b0\u5f0fAI\u8fdb\u53d6\u7684\u4e00\u6b65\uff0c\u53ef\u4ee5\u81ea\u4e3b\u63a2\u7d22\u4eba\u7c7b\u8ba4\u77e5\u548c\u8d44\u6e90\u9650\u5236\u65e0\u6cd5\u6d89\u8db3\u7684\u79d1\u5b66\u9886\u57df\uff0c\u540c\u65f6\u4e5f\u63d0\u51fa\u4e86\u5173\u4e8e\u79d1\u5b66\u7406\u89e3\u672c\u8d28\u548c\u79d1\u5b66\u8c6a\u52d5\u5f52\u5c5e\u7684\u91cd\u8981\u95ee\u9898"}}
{"id": "2508.13433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13433", "abs": "https://arxiv.org/abs/2508.13433", "authors": ["Jiayu Fang", "Zhiqi Shao", "S T Boris Choy", "Junbin Gao"], "title": "STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting", "comment": null, "summary": "Spatio-temporal traffic forecasting is challenging due to complex temporal\npatterns, dynamic spatial structures, and diverse input formats. Although\nTransformer-based models offer strong global modeling, they often struggle with\nrigid temporal encoding and weak space-time fusion. We propose STPFormer, a\nSpatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art\nperformance via unified and interpretable representation learning. It\nintegrates four modules: Temporal Position Aggregator (TPA) for pattern-aware\ntemporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial\nlearning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment,\nand an Attention Mixer for multi-scale fusion. Experiments on five real-world\ndatasets show that STPFormer consistently sets new SOTA results, with ablation\nand visualizations confirming its effectiveness and generalizability.", "AI": {"tldr": "STPFormer\u662f\u4e00\u4e2a\u65f6\u7a7a\u6a21\u5f0f\u611f\u77e5Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8868\u793a\u5b66\u4e60\u5728\u4ea4\u901a\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u6a21\u5757\u6765\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684Transformer\u6a21\u578b\u5728\u4ea4\u901a\u9884\u6d4b\u4e2d\u5b58\u5728\u65f6\u95f4\u7f16\u7801\u50f5\u5316\u548c\u65f6\u7a7a\u878d\u5408\u80fd\u529b\u5f31\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u6a21\u5f0f\u548c\u591a\u6837\u5316\u7684\u8f93\u5165\u683c\u5f0f\u3002", "method": "\u63d0\u51faSTPFormer\u6a21\u578b\uff0c\u5305\u542b\u56db\u4e2a\u6a21\u5757\uff1aTemporal Position Aggregator\uff08\u6a21\u5f0f\u611f\u77e5\u65f6\u95f4\u7f16\u7801\uff09\u3001Spatial Sequence Aggregator\uff08\u5e8f\u5217\u7a7a\u95f4\u5b66\u4e60\uff09\u3001Spatial-Temporal Graph Matching\uff08\u8de8\u57df\u5bf9\u9f50\uff09\u548cAttention Mixer\uff08\u591a\u5c3a\u5ea6\u878d\u5408\uff09\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTPFormer\u59cb\u7ec8\u8fbe\u5230\u65b0\u7684SOTA\u7ed3\u679c\uff0c\u6d88\u878d\u5b9e\u9a8c\u548c\u53ef\u89c6\u5316\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "STPFormer\u901a\u8fc7\u7edf\u4e00\u7684\u8868\u793a\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u7684\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\u5efa\u6a21\u95ee\u9898\uff0c\u4e3a\u65f6\u7a7a\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13437", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13437", "abs": "https://arxiv.org/abs/2508.13437", "authors": ["Cheikh Ahmed", "Mahdi Mostajabdaveh", "Samin Aref", "Zirui Zhou"], "title": "Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences", "comment": null, "summary": "We introduce the Discrete Min-Max Violation (DMMV) as a general optimization\nproblem which seeks an assignment of discrete values to variables that\nminimizes the largest constraint violation. This context-free mathematical\nformulation is applicable to a wide range of use cases that have worst-case\nperformance requirements. After defining the DMMV problem mathematically, we\nexplore its properties to establish a foundational understanding. To tackle\nDMMV instance sizes of practical relevance, we develop a GPU-accelerated\nheuristic that takes advantage of the mathematical properties of DMMV for\nspeeding up the solution process. We demonstrate the versatile applicability of\nour heuristic by solving three optimization problems as use cases: (1)\npost-training quantization of language models, (2) discrete tomography, and (3)\nFinite Impulse Response (FIR) filter design. In quantization without outlier\nseparation, our heuristic achieves 14% improvement on average over existing\nmethods. In discrete tomography, it reduces reconstruction error by 16% under\nuniform noise and accelerates computations by a factor of 6 on GPU. For FIR\nfilter design, it nearly achieves 50% ripple reduction compared to using the\ncommercial integer optimization solver, Gurobi. Our comparative results point\nto the benefits of studying DMMV as a context-free optimization problem and the\nadvantages that our proposed heuristic offers on three distinct problems. Our\nGPU-accelerated heuristic will be made open-source to further stimulate\nresearch on DMMV and its other applications. The code is available at\nhttps://anonymous.4open.science/r/AMVM-5F3E/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u79bb\u6563\u6700\u5c0f\u6700\u5927\u8fdd\u89c4\uff08DMMV\uff09\u4f5c\u4e3a\u901a\u7528\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1\u4e86GPU\u52a0\u901f\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u3001\u79bb\u6563\u5c42\u6790\u6210\u50cf\u548cFIR\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u4e09\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "\u8bb8\u591a\u5e94\u7528\u573a\u666f\u90fd\u6709\u6700\u574f\u60c5\u51b5\u6027\u80fd\u8981\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u901a\u7528\u7684\u6570\u5b66\u6846\u67b6\u6765\u5904\u7406\u8fd9\u7c7b\u79bb\u6563\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u6700\u5927\u7ea6\u675f\u8fdd\u89c4", "method": "\u5b9a\u4e49\u4e86DMMV\u95ee\u9898\u7684\u6570\u5b66\u5f62\u5f0f\uff0c\u7814\u7a76\u4e86\u5176\u6027\u8d28\uff0c\u5f00\u53d1\u4e86\u5229\u7528\u6570\u5b66\u7279\u6027\u7684GPU\u52a0\u901f\u542f\u53d1\u5f0f\u7b97\u6cd5", "result": "\u5728\u91cf\u5316\u4efb\u52a1\u4e2d\u5e73\u5747\u63d0\u534714%\uff0c\u79bb\u6563\u5c42\u6790\u6210\u50cf\u4e2d\u8bef\u5dee\u51cf\u5c1116%\u4e14GPU\u52a0\u901f6\u500d\uff0cFIR\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u4e2d\u6ce2\u7eb9\u51cf\u5c11\u8fd150%", "conclusion": "DMMV\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u65e0\u5173\u4f18\u5316\u95ee\u9898\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u63d0\u51fa\u7684GPU\u52a0\u901f\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u591a\u4e2a\u4e0d\u540c\u95ee\u9898\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u5c06\u5f00\u6e90\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2508.13465", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13465", "abs": "https://arxiv.org/abs/2508.13465", "authors": ["Yuzhi Tang", "Tianxiao Li", "Elizabeth Li", "Chris J. Maddison", "Honghua Dong", "Yangjun Ruan"], "title": "LM Agents May Fail to Act on Their Own Risk Knowledge", "comment": null, "summary": "Language model (LM) agents have demonstrated significant potential for\nautomating real-world tasks, yet they pose a diverse array of potential, severe\nrisks in safety-critical scenarios. In this work, we identify a significant gap\nbetween LM agents' risk awareness and safety execution abilities: while they\noften answer \"Yes\" to queries like \"Is executing `sudo rm -rf /*' dangerous?\",\nthey will likely fail to identify such risks in instantiated trajectories or\neven directly perform these risky actions when acting as agents. To\nsystematically investigate this, we develop a comprehensive evaluation\nframework to examine agents' safety across three progressive dimensions: 1)\ntheir knowledge about potential risks, 2) their ability to identify\ncorresponding risks in execution trajectories, and 3) their actual behaviors to\navoid executing these risky actions. Our evaluation reveals two critical\nperformance gaps that resemble the generator-validator gaps observed in LMs:\nwhile agents demonstrate near-perfect risk knowledge ($>98\\%$ pass rates), they\nfail to apply this knowledge when identifying risks in actual scenarios (with\nperformance dropping by $>23\\%$) and often still execute risky actions ($<26\\%$\npass rates). Notably, this trend persists across more capable LMs as well as in\nspecialized reasoning models like DeepSeek-R1, indicating that simply scaling\nmodel capabilities or inference compute does not inherently resolve safety\nconcerns. Instead, we take advantage of these observed gaps to develop a risk\nverifier that independently critiques the proposed actions by agents, with an\nabstractor that converts specific execution trajectories into abstract\ndescriptions where LMs can more effectively identify the risks. Our overall\nsystem achieves a significant reduction of risky action execution by $55.3\\%$\nover vanilla-prompted agents.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5b58\u5728\u98ce\u9669\u8bc6\u522b\u4e0e\u5b89\u5168\u6267\u884c\u7684\u663e\u8457\u5dee\u8ddd\uff0c\u7814\u7a76\u6784\u5efa\u4e86\u98ce\u9669\u9a8c\u8bc1\u5668\u7cfb\u7edf\u6765\u51cf\u5c11\u98ce\u9669\u884c\u4e3a", "motivation": "\u8bc6\u522b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u98ce\u9669\uff0c\u53d1\u73b0\u4ee3\u7406\u867d\u7136\u5177\u6709\u98ce\u9669\u77e5\u8bc6\u4f46\u65e0\u6cd5\u6709\u6548\u6267\u884c\u5b89\u5168\u884c\u4e3a", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u98ce\u9669\u77e5\u8bc6\u3001\u98ce\u9669\u8bc6\u522b\u548c\u5b89\u5168\u6267\u884c\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u4ee3\u7406\u5b89\u5168\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u98ce\u9669\u9a8c\u8bc1\u5668\u7cfb\u7edf", "result": "\u53d1\u73b0\u4ee3\u7406\u98ce\u9669\u77e5\u8bc6\u7387>98%\uff0c\u4f46\u98ce\u9669\u8bc6\u522b\u6027\u80fd\u4e0b\u964d23%\uff0c\u98ce\u9669\u884c\u4e3a\u6267\u884c\u7387<26%\uff0c\u98ce\u9669\u9a8c\u8bc1\u5668\u7cfb\u7edf\u53ef\u51cf\u5c1155.3%\u7684\u98ce\u9669\u884c\u4e3a", "conclusion": "\u7b80\u5355\u6269\u5927\u6a21\u578b\u80fd\u529b\u65e0\u6cd5\u89e3\u51b3\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u98ce\u9669\u9a8c\u8bc1\u673a\u5236\u6765\u63d0\u5347\u4ee3\u7406\u5b89\u5168\u6027"}}
{"id": "2508.13530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13530", "abs": "https://arxiv.org/abs/2508.13530", "authors": ["Junyeong Park", "Hyeonseo Cho", "Sungjin Ahn"], "title": "CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter", "comment": null, "summary": "Developing general-purpose embodied agents is a core challenge in AI.\nMinecraft provides rich complexity and internet-scale data, but its slow speed\nand engineering overhead make it unsuitable for rapid prototyping. Crafter\noffers a lightweight alternative that retains key challenges from Minecraft,\nyet its use has remained limited to narrow tasks due to the absence of\nfoundation models that have driven progress in the Minecraft setting. In this\npaper, we present CrafterDojo, a suite of foundation models and tools that\nunlock the Crafter environment as a lightweight, prototyping-friendly, and\nMinecraft-like testbed for general-purpose embodied agent research. CrafterDojo\naddresses this by introducing CrafterVPT, CrafterCLIP, and CrafterSteve-1 for\nbehavior priors, vision-language grounding, and instruction following,\nrespectively. In addition, we provide toolkits for generating behavior and\ncaption datasets (CrafterPlay and CrafterCaption), reference agent\nimplementations, benchmark evaluations, and a complete open-source codebase.", "AI": {"tldr": "CrafterDojo\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684Minecraft-like\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5305\u542b\u57fa\u7840\u6a21\u578b\u548c\u5de5\u5177\u5957\u4ef6\uff0c\u7528\u4e8e\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u7684\u5feb\u901f\u539f\u578b\u5f00\u53d1", "motivation": "Minecraft\u73af\u5883\u590d\u6742\u4f46\u901f\u5ea6\u6162\u3001\u5de5\u7a0b\u5f00\u9500\u5927\uff0cCrafter\u867d\u7136\u8f7b\u91cf\u4f46\u7f3a\u4e4f\u57fa\u7840\u6a21\u578b\u652f\u6301\uff0c\u9650\u5236\u4e86\u5176\u5728\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u4e2d\u7684\u5e94\u7528", "method": "\u5f00\u53d1\u4e86CrafterVPT\uff08\u884c\u4e3a\u5148\u9a8c\uff09\u3001CrafterCLIP\uff08\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\uff09\u3001CrafterSteve-1\uff08\u6307\u4ee4\u8ddf\u968f\uff09\u4e09\u4e2a\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u53caCrafterPlay\uff08\u884c\u4e3a\u6570\u636e\u96c6\u751f\u6210\uff09\u3001CrafterCaption\uff08\u6807\u6ce8\u6570\u636e\u96c6\u751f\u6210\uff09\u7b49\u5de5\u5177\u5957\u4ef6", "result": "\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5f00\u6e90\u4ee3\u7801\u5e93\u3001\u53c2\u8003\u667a\u80fd\u4f53\u5b9e\u73b0\u548c\u57fa\u51c6\u8bc4\u4f30\uff0c\u5c06Crafter\u73af\u5883\u8f6c\u5316\u4e3a\u9002\u5408\u5feb\u901f\u539f\u578b\u5f00\u53d1\u7684\u6d4b\u8bd5\u5e73\u53f0", "conclusion": "CrafterDojo\u6210\u529f\u5730\u5c06Crafter\u73af\u5883\u6253\u9020\u6210\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u539f\u578b\u53cb\u597d\u4e14\u7c7b\u4f3cMinecraft\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e3a\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u652f\u6301"}}
{"id": "2508.13579", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13579", "abs": "https://arxiv.org/abs/2508.13579", "authors": ["Yue Fang", "Yuxin Guo", "Jiaran Gao", "Hongxin Ding", "Xinke Jiang", "Weibin Liao", "Yongxin Xu", "Yinghao Zhu", "Zhibang Yang", "Liantao Ma", "Junfeng Zhao", "Yasha Wang"], "title": "Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance", "comment": null, "summary": "Improving large language models (LLMs) for electronic health record (EHR)\nreasoning is essential for enabling accurate and generalizable clinical\npredictions. While LLMs excel at medical text understanding, they underperform\non EHR-based prediction tasks due to challenges in modeling temporally\nstructured, high-dimensional data. Existing approaches often rely on hybrid\nparadigms, where LLMs serve merely as frozen prior retrievers while downstream\ndeep learning (DL) models handle prediction, failing to improve the LLM's\nintrinsic reasoning capacity and inheriting the generalization limitations of\nDL models. To this end, we propose EAG-RL, a novel two-stage training framework\ndesigned to intrinsically enhance LLMs' EHR reasoning ability through expert\nattention guidance, where expert EHR models refer to task-specific DL models\ntrained on EHR data. Concretely, EAG-RL first constructs high-quality, stepwise\nreasoning trajectories using expert-guided Monte Carlo Tree Search to\neffectively initialize the LLM's policy. Then, EAG-RL further optimizes the\npolicy via reinforcement learning by aligning the LLM's attention with\nclinically salient features identified by expert EHR models. Extensive\nexperiments on two real-world EHR datasets show that EAG-RL improves the\nintrinsic EHR reasoning ability of LLMs by an average of 14.62%, while also\nenhancing robustness to feature perturbations and generalization to unseen\nclinical domains. These results demonstrate the practical potential of EAG-RL\nfor real-world deployment in clinical prediction tasks. Our code have been\navailable at https://github.com/devilran6/EAG-RL.", "AI": {"tldr": "EAG-RL\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u6ce8\u610f\u529b\u5f15\u5bfc\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u5b50\u75c5\u5386\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e73\u5747\u63d0\u534714.62%\u7684\u6027\u80fd\uff0c\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u56fa\u5b9a\u7684\u5148\u9a8c\u68c0\u7d22\u5668\uff0c\u800c\u4e0b\u6e38\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5904\u7406\u9884\u6d4b\uff0c\u8fd9\u65e0\u6cd5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u7ee7\u627f\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faEAG-RL\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u4e13\u5bb6\u5f15\u5bfc\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u5206\u6b65\u63a8\u7406\u8f68\u8ff9\u6765\u521d\u59cb\u5316\u7b56\u7565\uff1b2\uff09\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\u4e0e\u4e13\u5bb6\u7535\u5b50\u75c5\u5386\u6a21\u578b\u8bc6\u522b\u7684\u4e34\u5e8a\u663e\u8457\u7279\u5f81\u5bf9\u9f50\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u7535\u5b50\u75c5\u5386\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cEAG-RL\u5e73\u5747\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5728\u7535\u5b50\u75c5\u5386\u63a8\u7406\u80fd\u529b14.62%\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u5bf9\u7279\u5f81\u6270\u52a8\u7684\u9c81\u68d2\u6027\u548c\u5bf9\u672a\u89c1\u4e34\u5e8a\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "EAG-RL\u5c55\u793a\u4e86\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u9645\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7535\u5b50\u75c5\u5386\u6570\u636e\u7684\u80fd\u529b\u3002"}}
{"id": "2508.13587", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.13587", "abs": "https://arxiv.org/abs/2508.13587", "authors": ["Lei Chen", "Xuanle Zhao", "Zhixiong Zeng", "Jing Huang", "Liming Zheng", "Yufeng Zhong", "Lin Ma"], "title": "Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation", "comment": "technical report", "summary": "While reinforcement learning (RL) has proven highly effective for general\nreasoning in vision-language models, its application to tasks requiring\nin-depth understanding of information-rich images and generation of structured\noutputs remains underexplored. Chart-to-code generation exemplifies this\nchallenge, demanding complex reasoning over visual charts to generate\nstructured code. Supervised fine-tuning (SFT) alone is often insufficient,\nhighlighting the need for effective RL strategies that appropriately reward\nstructured outputs. We systematically investigate the performance plateau in\nSFT through large-scale experiments and propose Multimodal Structured\nReinforcement Learning (MSRL) for chart-to-code generation, which substantially\nbreaks through this plateau. We construct the largest training corpus to date,\ncontaining 3 million chart-code pairs from real-world arXiv tables to mitigate\nsimplistic patterns of prior synthetic data. Despite reaching state-of-the-art\nperformance, our experiments show that scaling SFT data eventually hits a\nplateau where further increases yield negligible improvements. Our MSRL method\nleverages a multi-granularity structured reward system using multimodal textual\nand visual feedback. At the textual level, rule-based rewards validate\nfine-grained code details. At the visual level, model-based rewards assess\nstructural similarity by rendering generated code into images and employing an\nevaluator model. We implement this within a two-stage curriculum for training\nstability. Results demonstrate that MSRL significantly breaks the SFT plateau,\nimproving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA\nbenchmarks respectively, achieving competitive performance with advanced\nclosed-source models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5f3a\u5316\u5b66\u4e60(MSRL)\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u7ed3\u6784\u5316\u5956\u52b1\u7cfb\u7edf\u7a81\u7834\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u76d1\u7763\u5fae\u8c03\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u8868\u73b0\u6709\u6548\uff0c\u4f46\u5728\u9700\u8981\u6df1\u5ea6\u7406\u89e3\u4fe1\u606f\u4e30\u5bcc\u56fe\u50cf\u548c\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u4efb\u52a1\u4e2d\u5e94\u7528\u4e0d\u8db3\u3002\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u5b58\u5728\u76d1\u7763\u5fae\u8c03\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u9700\u8981\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u6765\u5956\u52b1\u7ed3\u6784\u5316\u8f93\u51fa\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b300\u4e07\u771f\u5b9earXiv\u8868\u683c\u56fe\u8868-\u4ee3\u7801\u5bf9\u7684\u6700\u5927\u8bad\u7ec3\u8bed\u6599\u5e93\uff1b\u63d0\u51faMSRL\u65b9\u6cd5\uff0c\u4f7f\u7528\u591a\u7c92\u5ea6\u7ed3\u6784\u5316\u5956\u52b1\u7cfb\u7edf\uff1a\u6587\u672c\u7ea7\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u9a8c\u8bc1\u4ee3\u7801\u7ec6\u8282\uff0c\u89c6\u89c9\u7ea7\u57fa\u4e8e\u6a21\u578b\u7684\u5956\u52b1\u901a\u8fc7\u6e32\u67d3\u4ee3\u7801\u6210\u56fe\u50cf\u8bc4\u4f30\u7ed3\u6784\u76f8\u4f3c\u6027\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "MSRL\u663e\u8457\u7a81\u7834\u4e86SFT\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5728ChartMimic\u548cReachQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5206\u522b\u5c06\u9ad8\u7ea7\u6307\u6807\u63d0\u5347\u4e866.2%\u548c9.9%\uff0c\u8fbe\u5230\u4e86\u4e0e\u5148\u8fdb\u95ed\u6e90\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5f3a\u5316\u5b66\u4e60\u662f\u89e3\u51b3\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u76d1\u7763\u5fae\u8c03\u6027\u80fd\u74f6\u9888\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u548c\u89c6\u89c9\u53cd\u9988\u7684\u591a\u7c92\u5ea6\u5956\u52b1\u7cfb\u7edf\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.13634", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13634", "abs": "https://arxiv.org/abs/2508.13634", "authors": ["Jikai Chen", "Long Chen", "Dong Wang", "Leilei Gan", "Chenyi Zhuang", "Jinjie Gu"], "title": "V2P: From Background Suppression to Center Peaking for Robust GUI Grounding Task", "comment": null, "summary": "Precise localization of GUI elements is crucial for the development of GUI\nagents. Traditional methods rely on bounding box or center-point regression,\nneglecting spatial interaction uncertainty and visual-semantic hierarchies.\nRecent methods incorporate attention mechanisms but still face two key issues:\n(1) ignoring processing background regions causes attention drift from the\ndesired area, and (2) uniform labeling fails to distinguish between center and\nedges of the target UI element, leading to click imprecision. Inspired by how\nhumans visually process and interact with GUI elements, we propose the\nValley-to-Peak (V2P) method to address these issues. To mitigate background\ndistractions, V2P introduces a suppression attention mechanism that minimizes\nthe model's focus on irrelevant regions to highlight the intended region. For\nthe issue of center-edge distinction, V2P applies a Fitts' Law-inspired\napproach by modeling GUI interactions as 2D Gaussian heatmaps where the weight\ngradually decreases from the center towards the edges. The weight distribution\nfollows a Gaussian function, with the variance determined by the target's size.\nConsequently, V2P effectively isolates the target area and teaches the model to\nconcentrate on the most essential point of the UI element. The model trained by\nV2P achieves the performance with 92.3% and 50.5% on two benchmarks\nScreenSpot-v2 and ScreenSpot-Pro. Ablations further confirm each component's\ncontribution, highlighting V2P's generalizability for precise GUI grounding\ntasks.", "AI": {"tldr": "V2P\u65b9\u6cd5\u901a\u8fc7\u6291\u5236\u6ce8\u610f\u529b\u673a\u5236\u548c\u57fa\u4e8eFitts\u5b9a\u5f8b\u7684\u9ad8\u65af\u70ed\u56fe\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86GUI\u5143\u7d20\u5b9a\u4f4d\u4e2d\u7684\u80cc\u666f\u5e72\u6270\u548c\u4e2d\u5fc3-\u8fb9\u7f18\u533a\u5206\u95ee\u9898\uff0c\u5728ScreenSpot\u57fa\u51c6\u4e0a\u8fbe\u523092.3%\u548c50.5%\u7684\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edfGUI\u5b9a\u4f4d\u65b9\u6cd5\u5ffd\u89c6\u7a7a\u95f4\u4ea4\u4e92\u4e0d\u786e\u5b9a\u6027\u548c\u89c6\u89c9\u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\uff0c\u73b0\u6709\u6ce8\u610f\u529b\u65b9\u6cd5\u5b58\u5728\u80cc\u666f\u5e72\u6270\u5bfc\u81f4\u6ce8\u610f\u529b\u6f02\u79fb\uff0c\u4ee5\u53ca\u5747\u5300\u6807\u6ce8\u65e0\u6cd5\u533a\u5206\u76ee\u6807UI\u5143\u7d20\u4e2d\u5fc3\u548c\u8fb9\u7f18\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faValley-to-Peak (V2P)\u65b9\u6cd5\uff1a1) \u6291\u5236\u6ce8\u610f\u529b\u673a\u5236\u51cf\u5c11\u5bf9\u65e0\u5173\u80cc\u666f\u533a\u57df\u7684\u5173\u6ce8\uff1b2) \u57fa\u4e8eFitts\u5b9a\u5f8b\u5c06GUI\u4ea4\u4e92\u5efa\u6a21\u4e3a2D\u9ad8\u65af\u70ed\u56fe\uff0c\u6743\u91cd\u4ece\u4e2d\u5fc3\u5411\u8fb9\u7f18\u9012\u51cf\uff0c\u65b9\u5dee\u7531\u76ee\u6807\u5927\u5c0f\u51b3\u5b9a\u3002", "result": "\u5728ScreenSpot-v2\u548cScreenSpot-Pro\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5206\u522b\u8fbe\u523092.3%\u548c50.5%\u7684\u6027\u80fd\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u7ec4\u4ef6\u8d21\u732e\u3002", "conclusion": "V2P\u65b9\u6cd5\u80fd\u6709\u6548\u9694\u79bb\u76ee\u6807\u533a\u57df\u5e76\u8ba9\u6a21\u578b\u4e13\u6ce8\u4e8eUI\u5143\u7d20\u6700\u5173\u952e\u7684\u70b9\uff0c\u5177\u6709\u7cbe\u786eGUI\u5b9a\u4f4d\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.13663", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13663", "abs": "https://arxiv.org/abs/2508.13663", "authors": ["Daniel Daza", "Alberto Bernardi", "Luca Costabello", "Christophe Gueret", "Masoud Mansoury", "Michael Cochez", "Martijn Schut"], "title": "Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints", "comment": null, "summary": "Methods for query answering over incomplete knowledge graphs retrieve\nentities that are likely to be answers, which is particularly useful when such\nanswers cannot be reached by direct graph traversal due to missing edges.\nHowever, existing approaches have focused on queries formalized using\nfirst-order-logic. In practice, many real-world queries involve constraints\nthat are inherently vague or context-dependent, such as preferences for\nattributes or related categories. Addressing this gap, we introduce the problem\nof query answering with soft constraints. We propose a Neural Query Reranker\n(NQR) designed to adjust query answer scores by incorporating soft constraints\nwithout disrupting the original answers to a query. NQR operates interactively,\nrefining answers based on incremental examples of preferred and non-preferred\nentities. We extend existing QA benchmarks by generating datasets with soft\nconstraints. Our experiments demonstrate that NQR can capture soft constraints\nwhile maintaining robust query answering performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5728\u77e5\u8bc6\u56fe\u8c31\u67e5\u8be2\u4e2d\u5904\u7406\u8f6f\u7ea6\u675f\u7684\u65b0\u65b9\u6cd5Neural Query Reranker(NQR)\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5b66\u4e60\u7528\u6237\u504f\u597d\u6765\u8c03\u6574\u67e5\u8be2\u7ed3\u679c\u8bc4\u5206\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u6709\u67e5\u8be2\u7b54\u6848\u7684\u5b8c\u6574\u6027\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u67e5\u8be2\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u4e00\u9636\u903b\u8f91\uff0c\u65e0\u6cd5\u5904\u7406\u73b0\u5b9e\u67e5\u8be2\u4e2d\u5e38\u89c1\u7684\u6a21\u7cca\u6216\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u8f6f\u7ea6\u675f\u6761\u4ef6\uff0c\u5982\u5c5e\u6027\u504f\u597d\u6216\u76f8\u5173\u7c7b\u522b\u504f\u597d\u3002", "method": "\u63d0\u51faNeural Query Reranker(NQR)\u6a21\u578b\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5b66\u4e60\u7528\u6237\u63d0\u4f9b\u7684\u504f\u597d\u548c\u975e\u504f\u597d\u5b9e\u4f53\u793a\u4f8b\uff0c\u5728\u4e0d\u7834\u574f\u539f\u59cb\u67e5\u8be2\u7b54\u6848\u7684\u57fa\u7840\u4e0a\u8c03\u6574\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u8868\u660eNQR\u80fd\u591f\u6709\u6548\u6355\u83b7\u8f6f\u7ea6\u675f\uff0c\u540c\u65f6\u4fdd\u6301\u7a33\u5065\u7684\u67e5\u8be2\u56de\u7b54\u6027\u80fd\u3002\u6269\u5c55\u4e86\u73b0\u6709QA\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4ee5\u5305\u542b\u8f6f\u7ea6\u675f\u573a\u666f\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u77e5\u8bc6\u56fe\u8c31\u67e5\u8be2\u5904\u7406\u4e2d\u8f6f\u7ea6\u675f\u652f\u6301\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684NQR\u65b9\u6cd5\u4e3a\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6a21\u7cca\u67e5\u8be2\u9700\u6c42\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13672", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13672", "abs": "https://arxiv.org/abs/2508.13672", "authors": ["Rehan Raza", "Guanjin Wang", "Kevin Wong", "Hamid Laga", "Marco Fisichella"], "title": "ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings", "comment": "Accepted at the 34th ACM International Conference on Information and\n  Knowledge Management (CIKM 2025)", "summary": "Explainable Artificial Intelligence (XAI) methods, such as Local\nInterpretable Model-Agnostic Explanations (LIME), have advanced the\ninterpretability of black-box machine learning models by approximating their\nbehavior locally using interpretable surrogate models. However, LIME's inherent\nrandomness in perturbation and sampling can lead to locality and instability\nissues, especially in scenarios with limited training data. In such cases, data\nscarcity can result in the generation of unrealistic variations and samples\nthat deviate from the true data manifold. Consequently, the surrogate model may\nfail to accurately approximate the complex decision boundary of the original\nmodel. To address these challenges, we propose a novel Instance-based Transfer\nLearning LIME framework (ITL-LIME) that enhances explanation fidelity and\nstability in data-constrained environments. ITL-LIME introduces instance\ntransfer learning into the LIME framework by leveraging relevant real instances\nfrom a related source domain to aid the explanation process in the target\ndomain. Specifically, we employ clustering to partition the source domain into\nclusters with representative prototypes. Instead of generating random\nperturbations, our method retrieves pertinent real source instances from the\nsource cluster whose prototype is most similar to the target instance. These\nare then combined with the target instance's neighboring real instances. To\ndefine a compact locality, we further construct a contrastive learning-based\nencoder as a weighting mechanism to assign weights to the instances from the\ncombined set based on their proximity to the target instance. Finally, these\nweighted source and target instances are used to train the surrogate model for\nexplanation purposes.", "AI": {"tldr": "\u63d0\u51faITL-LIME\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u4f8b\u8fc1\u79fb\u5b66\u4e60\u89e3\u51b3LIME\u5728\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684\u5c40\u90e8\u6027\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5229\u7528\u76f8\u5173\u6e90\u57df\u7684\u771f\u5b9e\u5b9e\u4f8b\u63d0\u5347\u89e3\u91ca\u4fdd\u771f\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "LIME\u65b9\u6cd5\u5728\u6270\u52a8\u548c\u91c7\u6837\u8fc7\u7a0b\u4e2d\u5b58\u5728\u968f\u673a\u6027\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4f1a\u5bfc\u81f4\u5c40\u90e8\u6027\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u6570\u636e\u7a00\u7f3a\u53ef\u80fd\u4ea7\u751f\u504f\u79bb\u771f\u5b9e\u6570\u636e\u6d41\u5f62\u7684\u4e0d\u73b0\u5b9e\u6837\u672c\uff0c\u4f7f\u4ee3\u7406\u6a21\u578b\u65e0\u6cd5\u51c6\u786e\u8fd1\u4f3c\u539f\u59cb\u6a21\u578b\u7684\u590d\u6742\u51b3\u7b56\u8fb9\u754c\u3002", "method": "\u63d0\u51faITL-LIME\u6846\u67b6\uff0c\u5f15\u5165\u5b9e\u4f8b\u8fc1\u79fb\u5b66\u4e60\uff1a1) \u4f7f\u7528\u805a\u7c7b\u5c06\u6e90\u57df\u5212\u5206\u4e3a\u5177\u6709\u4ee3\u8868\u6027\u539f\u578b\u7684\u7c07\uff1b2) \u68c0\u7d22\u4e0e\u76ee\u6807\u5b9e\u4f8b\u6700\u76f8\u4f3c\u7684\u6e90\u7c07\u4e2d\u7684\u76f8\u5173\u771f\u5b9e\u6e90\u5b9e\u4f8b\uff0c\u800c\u975e\u751f\u6210\u968f\u673a\u6270\u52a8\uff1b3) \u6784\u5efa\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u7f16\u7801\u5668\u4f5c\u4e3a\u52a0\u6743\u673a\u5236\uff0c\u6839\u636e\u5b9e\u4f8b\u4e0e\u76ee\u6807\u5b9e\u4f8b\u7684\u63a5\u8fd1\u7a0b\u5ea6\u5206\u914d\u6743\u91cd\uff1b4) \u4f7f\u7528\u52a0\u6743\u7684\u6e90\u548c\u76ee\u6807\u5b9e\u4f8b\u8bad\u7ec3\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u89e3\u91ca\u3002", "result": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u76f8\u5173\u6e90\u57df\u7684\u771f\u5b9e\u5b9e\u4f8b\uff0c\u907f\u514d\u4e86\u751f\u6210\u4e0d\u73b0\u5b9e\u7684\u968f\u673a\u6270\u52a8\u6837\u672c\uff0c\u63d0\u9ad8\u4e86\u89e3\u91ca\u7684\u4fdd\u771f\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002", "conclusion": "ITL-LIME\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LIME\u5728\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5b9e\u4f8b\u8fc1\u79fb\u5b66\u4e60\u548c\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u52a0\u6743\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89e3\u91ca\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.13675", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13675", "abs": "https://arxiv.org/abs/2508.13675", "authors": ["Mariam Arustashvili", "J\u00f6rg Deigm\u00f6ller", "Heiko Paulheim"], "title": "Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks", "comment": "Accepted at Semantics 2025", "summary": "Knowledge Graphs are used for various purposes, including business\napplications, biomedical analyses, or digital twins in industry 4.0. In this\npaper, we investigate knowledge graphs describing household actions, which are\nbeneficial for controlling household robots and analyzing video footage. In the\nlatter case, the information extracted from videos is notoriously incomplete,\nand completing the knowledge graph for enhancing the situational picture is\nessential. In this paper, we show that, while a standard link prediction\nproblem, situational knowledge graphs have special characteristics that render\nmany link prediction algorithms not fit for the job, and unable to outperform\neven simple baselines.", "AI": {"tldr": "\u77e5\u8bc6\u56fe\u8fde\u63a5\u9884\u6d4b\u5728\u5bb6\u5ead\u884c\u4e3a\u573a\u666f\u4e2d\u6548\u679c\u5dee\uff0c\u8bb8\u591a\u7b97\u6cd5\u8fde\u57fa\u7ebf\u90fd\u65e0\u6cd5\u8d85\u8d8a", "motivation": "\u5bb6\u5ead\u884c\u4e3a\u77e5\u8bc6\u56fe\u5728\u5bb6\u5ead\u673a\u5668\u4eba\u63a7\u5236\u548c\u89c6\u9891\u5206\u6790\u4e2d\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u89c6\u9891\u4e2d\u63d0\u53d6\u7684\u4fe1\u606f\u5b8c\u6574\u6027\u5dee\uff0c\u9700\u8981\u901a\u8fc7\u77e5\u8bc6\u56fe\u8865\u5168\u6765\u63d0\u5347\u60c5\u51b5\u611f\u77e5", "method": "\u7814\u7a76\u4e86\u6807\u51c6\u8fde\u63a5\u9884\u6d4b\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5404\u79cd\u8fde\u63a5\u9884\u6d4b\u7b97\u6cd5\u5728\u60c5\u5883\u77e5\u8bc6\u56fe\u4e2d\u7684\u8868\u73b0", "result": "\u53d1\u73b0\u60c5\u5883\u77e5\u8bc6\u56fe\u5177\u6709\u7279\u6b8a\u7279\u6027\uff0c\u5bfc\u81f4\u8bb8\u591a\u8fde\u63a5\u9884\u6d4b\u7b97\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u751a\u81f3\u8fde\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\u90fd\u65e0\u6cd5\u8d85\u8d8a", "conclusion": "\u5f53\u524d\u7684\u6807\u51c6\u8fde\u63a5\u9884\u6d4b\u7b97\u6cd5\u5728\u5904\u7406\u60c5\u5883\u77e5\u8bc6\u56fe\u65f6\u5b58\u5728\u663e\u8457\u7684\u4e0d\u8db3\uff0c\u9700\u8981\u7814\u7a76\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u7c7b\u7279\u6b8a\u573a\u666f"}}
{"id": "2508.13676", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13676", "abs": "https://arxiv.org/abs/2508.13676", "authors": ["Yu Li", "Zulong Chen", "Wenjian Xu", "Hong Wen", "Yipeng Yu", "Man Lung Yiu", "Yuyu Yin"], "title": "MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model", "comment": null, "summary": "To maintain the company's talent pool, recruiters need to continuously search\nfor resumes from third-party websites (e.g., LinkedIn, Indeed). However,\nfetched resumes are often incomplete and inaccurate. To improve the quality of\nthird-party resumes and enrich the company's talent pool, it is essential to\nconduct duplication detection between the fetched resumes and those already in\nthe company's talent pool. Such duplication detection is challenging due to the\nsemantic complexity, structural heterogeneity, and information incompleteness\nof resume texts. To this end, we propose MHSNet, an multi-level identity\nverification framework that fine-tunes BGE-M3 using contrastive learning. With\nthe fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and\ndense representations for resumes, enabling the computation of corresponding\nmulti-level semantic similarities. Moreover, the state-aware Mixture-of-Experts\n(MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental\nresults verify the effectiveness of MHSNet", "AI": {"tldr": "MHSNet\u662f\u4e00\u4e2a\u591a\u5c42\u7ea7\u8eab\u4efd\u9a8c\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u7b2c\u4e09\u65b9\u7f51\u7ad9\u83b7\u53d6\u7684\u7b80\u5386\u4e0e\u516c\u53f8\u4eba\u624d\u5e93\u4e2d\u73b0\u6709\u7b80\u5386\u4e4b\u95f4\u7684\u91cd\u590d\u9879\uff0c\u901a\u8fc7\u5fae\u8c03BGE-M3\u548c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u6765\u89e3\u51b3\u7b80\u5386\u6587\u672c\u7684\u8bed\u4e49\u590d\u6742\u6027\u3001\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u4fe1\u606f\u4e0d\u5b8c\u6574\u6027\u7b49\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4ece\u7b2c\u4e09\u65b9\u7f51\u7ad9\u83b7\u53d6\u7684\u7b80\u5386\u5f80\u5f80\u4e0d\u5b8c\u6574\u548c\u4e0d\u51c6\u786e\u7684\u95ee\u9898\uff0c\u9700\u8981\u68c0\u6d4b\u8fd9\u4e9b\u7b80\u5386\u4e0e\u516c\u53f8\u4eba\u624d\u5e93\u4e2d\u73b0\u6709\u7b80\u5386\u7684\u91cd\u590d\u9879\uff0c\u4ee5\u63d0\u5347\u7b80\u5386\u8d28\u91cf\u5e76\u4e30\u5bcc\u4eba\u624d\u5e93\u3002", "method": "\u63d0\u51faMHSNet\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5fae\u8c03BGE-M3\u6a21\u578b\uff0c\u5229\u7528Mixture-of-Experts (MoE)\u751f\u6210\u591a\u5c42\u7ea7\u7a00\u758f\u548c\u5bc6\u96c6\u8868\u793a\u6765\u8ba1\u7b97\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u5e76\u91c7\u7528\u72b6\u6001\u611f\u77e5MoE\u5904\u7406\u4e0d\u5b8c\u6574\u7b80\u5386\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86MHSNet\u7684\u6709\u6548\u6027\u3002", "conclusion": "MHSNet\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7b80\u5386\u91cd\u590d\u68c0\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u7b2c\u4e09\u65b9\u7b80\u5386\u8d28\u91cf\u5e76\u4e30\u5bcc\u516c\u53f8\u4eba\u624d\u5e93\u3002"}}
{"id": "2508.13678", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.13678", "abs": "https://arxiv.org/abs/2508.13678", "authors": ["Xiao-Wen Yang", "Jie-Jing Shao", "Lan-Zhe Guo", "Bo-Wen Zhang", "Zhi Zhou", "Lin-Han Jia", "Wang-Zhou Dai", "Yu-Feng Li"], "title": "Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models", "comment": "9 pages, 3 figures, IJCAI 2025 Survey Track", "summary": "Large Language Models (LLMs) have shown promising results across various\ntasks, yet their reasoning capabilities remain a fundamental challenge.\nDeveloping AI systems with strong reasoning capabilities is regarded as a\ncrucial milestone in the pursuit of Artificial General Intelligence (AGI) and\nhas garnered considerable attention from both academia and industry. Various\ntechniques have been explored to enhance the reasoning capabilities of LLMs,\nwith neuro-symbolic approaches being a particularly promising way. This paper\ncomprehensively reviews recent developments in neuro-symbolic approaches for\nenhancing LLM reasoning. We first present a formalization of reasoning tasks\nand give a brief introduction to the neurosymbolic learning paradigm. Then, we\ndiscuss neuro-symbolic methods for improving the reasoning capabilities of LLMs\nfrom three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic.\nFinally, we discuss several key challenges and promising future directions. We\nhave also released a GitHub repository including papers and resources related\nto this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5168\u9762\u56de\u987e\u4e86\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u4ece\u4e09\u4e2a\u89c6\u89d2\uff08\u7b26\u53f7\u2192LLM\u3001LLM\u2192\u7b26\u53f7\u3001LLM+\u7b26\u53f7\uff09\u8fdb\u884c\u5206\u7c7b\u8ba8\u8bba\uff0c\u5e76\u6307\u51fa\u4e86\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u63a8\u7406\u80fd\u529b\u4ecd\u662f\u6839\u672c\u6027\u6311\u6218\u3002\u5f00\u53d1\u5177\u6709\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u7684AI\u7cfb\u7edf\u88ab\u8ba4\u4e3a\u662f\u5b9e\u73b0\u901a\u7528\u4eba\u5de5\u667a\u80fd\u7684\u5173\u952e\u91cc\u7a0b\u7891\uff0c\u53d7\u5230\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u5e7f\u6cdb\u5173\u6ce8\u3002", "method": "\u8bba\u6587\u9996\u5148\u5f62\u5f0f\u5316\u63a8\u7406\u4efb\u52a1\u5e76\u7b80\u8981\u4ecb\u7ecd\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u8303\u5f0f\uff0c\u7136\u540e\u4ece\u4e09\u4e2a\u89d2\u5ea6\u8ba8\u8bba\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff1a\u7b26\u53f7\u2192LLM\u3001LLM\u2192\u7b26\u53f7\u3001\u4ee5\u53caLLM+\u7b26\u53f7\u7684\u534f\u540c\u65b9\u6cd5\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u6db5\u76d6\u4e86\u4e0d\u540c\u6280\u672f\u8def\u5f84\u7684\u5206\u7c7b\u548c\u5206\u6790\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b\u76f8\u5173\u8bba\u6587\u548c\u8d44\u6e90\u7684GitHub\u4ed3\u5e93\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u662f\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u8bba\u6587\u8bc6\u522b\u4e86\u8be5\u9886\u57df\u7684\u5173\u952e\u6311\u6218\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2508.13697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13697", "abs": "https://arxiv.org/abs/2508.13697", "authors": ["Vincent Derkinderen", "Robin Manhaeve", "Rik Adriaensen", "Lucas Van Praet", "Lennert De Smet", "Giuseppe Marra", "Luc De Raedt"], "title": "The DeepLog Neurosymbolic Machine", "comment": null, "summary": "We contribute a theoretical and operational framework for neurosymbolic AI\ncalled DeepLog. DeepLog introduces building blocks and primitives for\nneurosymbolic AI that make abstraction of commonly used representations and\ncomputational mechanisms used in neurosymbolic AI. DeepLog can represent and\nemulate a wide range of neurosymbolic systems. It consists of two key\ncomponents. The first is the DeepLog language for specifying neurosymbolic\nmodels and inference tasks. This language consists of an annotated neural\nextension of grounded first-order logic, and makes abstraction of the type of\nlogic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the\narchitecture or in the loss function. The second DeepLog component is situated\nat the computational level and uses extended algebraic circuits as\ncomputational graphs. Together these two components are to be considered as a\nneurosymbolic abstract machine, with the DeepLog language as the intermediate\nlevel of abstraction and the circuits level as the computational one. DeepLog\nis implemented in software, relies on the latest insights in implementing\nalgebraic circuits on GPUs, and is declarative in that it is easy to obtain\ndifferent neurosymbolic models by making different choices for the underlying\nalgebraic structures and logics. The generality and efficiency of the DeepLog\nneurosymbolic machine is demonstrated through an experimental comparison\nbetween 1) different fuzzy and probabilistic logics, 2) between using logic in\nthe architecture or in the loss function, and 3) between a standalone CPU-based\nimplementation of a neurosymbolic AI system and a DeepLog GPU-based one.", "AI": {"tldr": "DeepLog\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7AI\u7684\u7406\u8bba\u548c\u64cd\u4f5c\u6846\u67b6\uff0c\u63d0\u4f9b\u6784\u5efa\u5757\u548c\u539f\u8bed\u6765\u62bd\u8c61\u8868\u793a\u548c\u8ba1\u7b97\u673a\u5236\uff0c\u652f\u6301\u591a\u79cd\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7684\u8868\u793a\u548c\u4eff\u771f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7AI\u4e2d\u4e0d\u540c\u8868\u793a\u548c\u8ba1\u7b97\u673a\u5236\u7684\u590d\u6742\u6027\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u62bd\u8c61\u6846\u67b6\u6765\u7b80\u5316\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u7684\u6784\u5efa\u548c\u63a8\u7406\u4efb\u52a1\u3002", "method": "DeepLog\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1\uff09\u57fa\u4e8e\u6ce8\u91ca\u795e\u7ecf\u6269\u5c55\u7684\u63a5\u5730\u4e00\u9636\u903b\u8f91\u8bed\u8a00\uff0c\u7528\u4e8e\u6307\u5b9a\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u548c\u63a8\u7406\u4efb\u52a1\uff1b2\uff09\u4f7f\u7528\u6269\u5c55\u4ee3\u6570\u7535\u8def\u4f5c\u4e3a\u8ba1\u7b97\u56fe\u7684\u8ba1\u7b97\u5c42\u7ec4\u4ef6\u3002", "result": "DeepLog\u80fd\u591f\u8868\u793a\u548c\u4eff\u771f\u5e7f\u6cdb\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u8bc1\u660e\u4e86\u5176\u5728\u6a21\u7cca\u903b\u8f91\u3001\u6982\u7387\u903b\u8f91\u4ee5\u53caGPU\u52a0\u901f\u5b9e\u73b0\u65b9\u9762\u7684\u901a\u7528\u6027\u548c\u6548\u7387\u3002", "conclusion": "DeepLog\u4f5c\u4e3a\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u62bd\u8c61\u673a\u5668\uff0c\u63d0\u4f9b\u4e86\u4e2d\u95f4\u62bd\u8c61\u5c42\u548c\u8ba1\u7b97\u5c42\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u9009\u62e9\u4e0d\u540c\u7684\u4ee3\u6570\u7ed3\u6784\u548c\u903b\u8f91\u8f7b\u677e\u83b7\u5f97\u4e0d\u540c\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u3002"}}
{"id": "2508.13721", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13721", "abs": "https://arxiv.org/abs/2508.13721", "authors": ["Minh Hoang Nguyen", "Van Dai Do", "Dung Nguyen", "Thin Nguyen", "Hung Le"], "title": "CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning", "comment": null, "summary": "Large language model (LLM) agents-especially smaller, open-source\nmodels-often produce causally invalid or incoherent actions in collaborative\ntasks due to their reliance on surface-level correlations rather than grounded\ncausal reasoning. This limitation undermines their performance in terms of\ncoordination and planning in dynamic environments. We address this challenge\nwith CausalPlan, a two-phase framework that integrates explicit structural\ncausal reasoning into the LLM planning process. At the core of CausalPlan is\nthe Structural Causal Action (SCA) model, which learns a causal graph from\nagent trajectories to capture how prior actions and current environment states\ninfluence future decisions. This structure is then used to guide action\nselection by assigning causal scores to LLM-generated proposals, reweighting\nthem accordingly, or falling back to causally grounded alternatives when\nneeded. By embedding this causal knowledge directly into the decision loop,\nCausalPlan constrains planning to intervention-consistent behaviours without\nrequiring fine-tuning of the LLM itself. We evaluate CausalPlan on the\nOvercooked-AI benchmark across five multi-agent coordination tasks and four\nLLMs of varying sizes: Gemma-7B, Llama-8B, Qwen-14B, and Llama-70B.\nExperimental results show that CausalPlan consistently reduces invalid actions\nand improves collaboration in both AI-AI and human-AI settings, outperforming\nstrong reinforcement learning baselines. Our findings highlight the value of\ncausality-driven planning for deploying efficient, interpretable, and\ngeneralisable multi-agent LLM systems.", "AI": {"tldr": "CausalPlan\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u663e\u5f0f\u7ed3\u6784\u56e0\u679c\u63a8\u7406\u96c6\u6210\u5230LLM\u89c4\u5212\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u5c0f\u89c4\u6a21\u5f00\u6e90LLM\u4ee3\u7406\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u4ea7\u751f\u56e0\u679c\u65e0\u6548\u6216\u4e0d\u8fde\u8d2f\u52a8\u4f5c\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff08\u5c24\u5176\u662f\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\uff09\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u5f80\u5f80\u4ea7\u751f\u56e0\u679c\u65e0\u6548\u6216\u4e0d\u8fde\u8d2f\u7684\u52a8\u4f5c\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\u800c\u975e\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u534f\u8c03\u548c\u89c4\u5212\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86CausalPlan\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u7ed3\u6784\u56e0\u679c\u884c\u52a8\uff08SCA\uff09\u6a21\u578b\uff0c\u4ece\u4ee3\u7406\u8f68\u8ff9\u4e2d\u5b66\u4e60\u56e0\u679c\u56fe\u6765\u6355\u6349\u5148\u524d\u884c\u52a8\u548c\u5f53\u524d\u73af\u5883\u72b6\u6001\u5982\u4f55\u5f71\u54cd\u672a\u6765\u51b3\u7b56\u3002\u8be5\u7ed3\u6784\u7528\u4e8e\u901a\u8fc7\u4e3aLLM\u751f\u6210\u7684\u52a8\u4f5c\u63d0\u6848\u5206\u914d\u56e0\u679c\u5206\u6570\u6765\u6307\u5bfc\u52a8\u4f5c\u9009\u62e9\uff0c\u5fc5\u8981\u65f6\u56de\u9000\u5230\u56e0\u679c\u57fa\u7840\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "result": "\u5728Overcooked-AI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u89c4\u6a21\u7684LLM\uff08Gemma-7B\u3001Llama-8B\u3001Qwen-14B\u548cLlama-70B\uff09\u8fdb\u884c\u4e94\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4efb\u52a1\u7684\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aCausalPlan\u6301\u7eed\u51cf\u5c11\u65e0\u6548\u52a8\u4f5c\uff0c\u5728AI-AI\u548c\u4eba\u7c7b-AI\u8bbe\u7f6e\u4e2d\u90fd\u6539\u5584\u4e86\u534f\u4f5c\u6027\u80fd\uff0c\u4f18\u4e8e\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u56e0\u679c\u9a71\u52a8\u89c4\u5212\u5bf9\u4e8e\u90e8\u7f72\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cdb\u5316\u7684\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u4ef7\u503c\uff0c\u80fd\u591f\u5728\u4e0d\u9700\u8981\u5fae\u8c03LLM\u672c\u8eab\u7684\u60c5\u51b5\u4e0b\u7ea6\u675f\u89c4\u5212\u4e3a\u5e72\u9884\u4e00\u81f4\u7684\u884c\u4e3a\u3002"}}
{"id": "2508.13754", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13754", "abs": "https://arxiv.org/abs/2508.13754", "authors": ["Liuxin Bao", "Zhihao Peng", "Xiaofei Zhou", "Runmin Cong", "Jiyong Zhang", "Yixuan Yuan"], "title": "Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making", "comment": "14 pages", "summary": "Medical Decision-Making (MDM) is a complex process requiring substantial\ndomain-specific expertise to effectively synthesize heterogeneous and\ncomplicated clinical information. While recent advancements in Large Language\nModels (LLMs) show promise in supporting MDM, single-LLM approaches are limited\nby their parametric knowledge constraints and static training corpora, failing\nto robustly integrate the clinical information. To address this challenge, we\npropose the Expertise-aware Multi-LLM Recruitment and Collaboration (EMRC)\nframework to enhance the accuracy and reliability of MDM systems. It operates\nin two stages: (i) expertise-aware agent recruitment and (ii) confidence- and\nadversarial-driven multi-agent collaboration. Specifically, in the first stage,\nwe use a publicly available corpus to construct an LLM expertise table for\ncapturing expertise-specific strengths of multiple LLMs across medical\ndepartment categories and query difficulty levels. This table enables the\nsubsequent dynamic selection of the optimal LLMs to act as medical expert\nagents for each medical query during the inference phase. In the second stage,\nwe employ selected agents to generate responses with self-assessed confidence\nscores, which are then integrated through the confidence fusion and adversarial\nvalidation to improve diagnostic reliability. We evaluate our EMRC framework on\nthree public MDM datasets, where the results demonstrate that our EMRC\noutperforms state-of-the-art single- and multi-LLM methods, achieving superior\ndiagnostic performance. For instance, on the MMLU-Pro-Health dataset, our EMRC\nachieves 74.45% accuracy, representing a 2.69% improvement over the\nbest-performing closed-source model GPT- 4-0613, which demonstrates the\neffectiveness of our expertise-aware agent recruitment strategy and the agent\ncomplementarity in leveraging each LLM's specialized capabilities.", "AI": {"tldr": "\u901a\u8fc7\u4e13\u4e1a\u77e5\u8bc6\u8868\u52a8\u6001\u9009\u62e9\u591a\u4e2aLLM\u4e13\u5bb6\uff0c\u7ed3\u5408\u81ea\u4fe1\u5ea6\u8bc4\u4f30\u548c\u5bf9\u6297\u9a8c\u8bc1\u6765\u63d0\u5347\u533b\u7597\u51b3\u7b56\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027", "motivation": "\u5355\u4e00LLM\u65b9\u6cd5\u53d7\u9650\u4e8e\u53c2\u6570\u77e5\u8bc6\u7ea6\u675f\u548c\u9759\u6001\u8bad\u7ec3\u8bed\u6599\uff0c\u65e0\u6cd5\u5065\u58c1\u6574\u5408\u590d\u6742\u7684\u4e34\u5e8a\u4fe1\u606f\uff0c\u9700\u8981\u591aLLM\u534f\u4f5c\u6765\u63d0\u5347\u533b\u7597\u51b3\u7b56\u8d28\u91cf", "method": "\u4e13\u4e1a\u77e5\u8bc6\u611f\u77e5\u7684\u591aLLM\u62db\u52df\u4e0e\u534f\u4f5c\u6846\u67b6(EMRC)\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u516c\u5f00\u8bed\u6599\u5e93\u6784\u5efaLLM\u4e13\u4e1a\u77e5\u8bc6\u8868\u52a8\u6001\u9009\u62e9\u6700\u4f73LLM\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u81ea\u4fe1\u5ea6\u8bc4\u5206\u548c\u5bf9\u6297\u9a8c\u8bc1\u6574\u5408\u591a\u4e2a\u4e13\u5bb6\u7684\u8f93\u51fa", "result": "\u5728\u4e09\u4e2a\u516c\u5f00MDM\u6570\u636e\u96c6\u4e0a\u8bc6\u522b\u6027\u80fd\u8d85\u8fc7\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff0c\u5728MMLU-Pro-Health\u6570\u636e\u96c6\u4e0a\u8fbe\u523074.45%\u51c6\u786e\u7387\uff0c\u6bd4GPT-4-0613\u63d0\u53472.69%", "conclusion": "EMRC\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u62db\u52df\u591a\u4e2aLLM\u4e13\u5bb6\u5e76\u5229\u7528\u5176\u4e13\u4e1a\u80fd\u529b\u7684\u4e92\u8865\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u51b3\u7b56\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2508.13811", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.13811", "abs": "https://arxiv.org/abs/2508.13811", "authors": ["Jan Jakub\u016fv", "Mikol\u00e1\u0161 Janota"], "title": "Quantifier Instantiations: To Mimic or To Revolt?", "comment": "Accepted to SMT 2025: 23rd International Workshop on Satisfiability\n  Modulo Theories", "summary": "Quantified formulas pose a significant challenge for Satisfiability Modulo\nTheories (SMT) solvers due to their inherent undecidability. Existing\ninstantiation techniques, such as e-matching, syntax-guided, model-based,\nconflict-based, and enumerative methods, often complement each other. This\npaper introduces a novel instantiation approach that dynamically learns from\nthese techniques during solving. By treating observed instantiations as samples\nfrom a latent language, we use probabilistic context-free grammars to generate\nnew, similar terms. Our method not only mimics successful past instantiations\nbut also explores diversity by optionally inverting learned term probabilities,\naiming to balance exploitation and exploration in quantifier reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u7684\u52a8\u6001\u91cf\u5316\u5b9e\u4f8b\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u73b0\u6709\u6280\u672f\u4e2d\u5b66\u4e60\u5b9e\u4f8b\u5316\u6a21\u5f0f\u6765\u5e73\u8861\u5229\u7528\u548c\u63a2\u7d22", "motivation": "\u91cf\u5316\u516c\u5f0f\u662fSMT\u6c42\u89e3\u5668\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u73b0\u6709\u5b9e\u4f8b\u5316\u6280\u672f\u5404\u6709\u4f18\u52a3\u4f46\u7f3a\u4e4f\u534f\u540c\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u5b66\u4e60\u548c\u751f\u6210\u65b0\u5b9e\u4f8b\u7684\u65b9\u6cd5", "method": "\u5c06\u89c2\u5bdf\u5230\u7684\u5b9e\u4f8b\u5316\u89c6\u4e3a\u6f5c\u5728\u8bed\u8a00\u7684\u6837\u672c\uff0c\u4f7f\u7528\u6982\u7387\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u751f\u6210\u76f8\u4f3c\u7684\u65b0\u672f\u8bed\uff0c\u53ef\u9009\u5730\u53cd\u8f6c\u5b66\u4e60\u5230\u7684\u672f\u8bed\u6982\u7387\u6765\u63a2\u7d22\u591a\u6837\u6027", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6a21\u4eff\u6210\u529f\u7684\u8fc7\u5f80\u5b9e\u4f8b\u5316\uff0c\u540c\u65f6\u901a\u8fc7\u6982\u7387\u53cd\u8f6c\u5b9e\u73b0\u63a2\u7d22\u6027\uff0c\u5728\u91cf\u5316\u63a8\u7406\u4e2d\u5b9e\u73b0\u5229\u7528\u4e0e\u63a2\u7d22\u7684\u5e73\u8861", "conclusion": "\u57fa\u4e8e\u6587\u6cd5\u5b66\u4e60\u7684\u52a8\u6001\u5b9e\u4f8b\u5316\u65b9\u6cd5\u4e3aSMT\u6c42\u89e3\u5668\u5904\u7406\u91cf\u5316\u516c\u5f0f\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u80fd\u591f\u7efc\u5408\u591a\u79cd\u73b0\u6709\u6280\u672f\u7684\u4f18\u52bf"}}
{"id": "2508.13828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13828", "abs": "https://arxiv.org/abs/2508.13828", "authors": ["Yifei Chen", "Guanting Dong", "Yutao Zhu", "Zhicheng Dou"], "title": "Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) technology has been widely applied in\nrecent years. However, despite the emergence of various RAG frameworks, a\nsingle RAG framework still cannot adapt well to a broad range of downstream\ntasks. Therefore, how to leverage the advantages of multiple RAG systems has\nbecome an area worth exploring. To address this issue, we have conducted a\ncomprehensive and systematic investigation into ensemble methods based on RAG\nsystems. Specifically, we have analyzed the RAG ensemble framework from both\ntheoretical and mechanistic analysis perspectives. From the theoretical\nanalysis, we provide the first explanation of the RAG ensemble framework from\nthe perspective of information entropy. In terms of mechanism analysis, we have\nexplored the RAG ensemble framework from both the pipeline and module levels.\nWe carefully select four different pipelines (Branching, Iterative, Loop, and\nAgentic) and three different modules (Generator, Retriever, and Reranker) to\nsolve seven different research questions. The experiments show that aggregating\nmultiple RAG systems is both generalizable and robust, whether at the pipeline\nlevel or the module level. Our work lays the foundation for similar research on\nthe multi-RAG system ensemble.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u7814\u7a76\u4e86\u591a\u4e2aRAG\u7cfb\u7edf\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u4ece\u7406\u8bba\u548c\u673a\u5236\u89d2\u5ea6\u5206\u6790\u4e86RAG\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u71b5\u7406\u8bba\u89e3\u91ca\u96c6\u6210\u6846\u67b6\uff0c\u5e76\u5728\u7ba1\u7ebf\u548c\u6a21\u5757\u5c42\u9762\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u591aRAG\u7cfb\u7edf\u96c6\u6210\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u7a33\u5065\u6027\u3002", "motivation": "\u5f53\u524d\u5355\u4e2aRAG\u6846\u67b6\u65e0\u6cd5\u826f\u597d\u9002\u5e94\u5e7f\u6cdb\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u9700\u8981\u6293\u53d6\u591a\u4e2aRAG\u7cfb\u7edf\u7684\u4f18\u52bf\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4ece\u7406\u8bba\u548c\u673a\u5236\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790RAG\u96c6\u6210\u6846\u67b6\uff1a\u7406\u8bba\u65b9\u9762\u4ece\u4fe1\u606f\u71b5\u89d2\u5ea6\u89e3\u91ca\uff1b\u673a\u5236\u65b9\u9762\u4ece\u7ba1\u7ebf\u5c42\u9762\uff08\u5206\u652f\u3001\u8fed\u4ee3\u3001\u5faa\u73af\u3001\u4ee3\u7406\uff09\u548c\u6a21\u5757\u5c42\u9762\uff08\u751f\u6210\u5668\u3001\u68c0\u7d22\u5668\u3001\u91cd\u6392\u5668\uff09\u8fdb\u884c\u7814\u7a76\uff0c\u89e3\u51b37\u4e2a\u7814\u7a76\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u65e0\u8bba\u662f\u5728\u7ba1\u7ebf\u5c42\u9762\u8fd8\u662f\u6a21\u5757\u5c42\u9762\uff0c\u805a\u5408\u591a\u4e2aRAG\u7cfb\u7edf\u90fd\u663e\u793a\u51fa\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591aRAG\u7cfb\u7edf\u96c6\u6210\u76f8\u5173\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u591a\u7cfb\u7edf\u96c6\u6210\u5728RAG\u9886\u57df\u7684\u6709\u6548\u6027\u548c\u4ef7\u503c\u3002"}}
{"id": "2508.13876", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.13876", "abs": "https://arxiv.org/abs/2508.13876", "authors": ["Katharina Stein", "Nils Hodel", "Daniel Fi\u0161er", "J\u00f6rg Hoffmann", "Michael Katz", "Alexander Koller"], "title": "Improved Generalized Planning with LLMs through Strategy Refinement and Reflection", "comment": null, "summary": "LLMs have recently been used to generate Python programs representing\ngeneralized plans in PDDL planning, i.e., plans that generalize across the\ntasks of a given PDDL domain. Previous work proposed a framework consisting of\nthree steps: the LLM first generates a summary and then a strategy for the\ndomain, both in natural language, and then implements that strategy as a Python\nprogram, that gets debugged on example planning tasks. In that work, only one\nstrategy is generated and passed directly to the program generation. If the\nstrategy is incorrect, its implementation will therefore result in an incorrect\ngeneralized plan. Here, we introduce an approach that generates the strategy in\nthe form of pseudocode and enables automatic debugging of the pseudocode, hence\nallowing us to identify and fix errors prior to the generation of the\ngeneralized plan itself. Additionally, we extend the Python debugging phase\nwith a reflection step prompting the LLM to pinpoint the reason for the\nobserved plan failure. Finally, we take inspiration from LLM code generation to\nproduce several program variants and pick the best one. Running experiments on\n17 benchmark domains, we show that these extensions substantially improve (and\nnever deteriorate) the quality of the generalized plans. In 12 of the domains,\nour best Python programs solve all tasks that can be generated with the\nrespective instance generator.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u4f2a\u4ee3\u7801\u751f\u6210\u548c\u81ea\u52a8\u8c03\u8bd5\u3001\u53cd\u601d\u6b65\u9aa4\u4ee5\u53ca\u591a\u7a0b\u5e8f\u53d8\u4f53\u9009\u62e9\u7b49\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e86LLM\u751f\u6210\u5e7f\u4e49\u8ba1\u5212\u7684\u8d28\u91cf\uff0c\u572817\u4e2a\u57fa\u51c6\u9886\u57df\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u5212\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u4e4b\u524d\u7684\u65b9\u6cd5\u53ea\u751f\u6210\u4e00\u4e2a\u7b56\u7565\u5e76\u76f4\u63a5\u8f6c\u6362\u4e3a\u7a0b\u5e8f\uff0c\u5982\u679c\u7b56\u7565\u9519\u8bef\u5c31\u4f1a\u5bfc\u81f4\u6574\u4e2a\u5e7f\u4e49\u8ba1\u5212\u5931\u8d25\uff0c\u9700\u8981\u66f4\u597d\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u590d\u673a\u5236\u3002", "method": "\u4f7f\u7528\u4f2a\u4ee3\u7801\u751f\u6210\u7b56\u7565\u5e76\u81ea\u52a8\u8c03\u8bd5\uff0c\u5728Python\u8c03\u8bd5\u9636\u6bb5\u6dfb\u52a0\u53cd\u601d\u6b65\u9aa4\u627e\u51fa\u9519\u8bef\u539f\u56e0\uff0c\u751f\u6210\u591a\u4e2a\u7a0b\u5e8f\u53d8\u4f53\u5e76\u9009\u62e9\u6700\u4f73\u7684\u3002", "result": "\u572817\u4e2a\u57fa\u51c6\u9886\u57df\u4e2d\uff0c\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5e7f\u4e49\u8ba1\u5212\u7684\u8d28\u91cf\u800c\u4e0d\u4f1a\u4f4e\u4e8e\u539f\u6765\u3002\u572812\u4e2a\u9886\u57df\u4e2d\uff0c\u6700\u4f73Python\u7a0b\u5e8f\u80fd\u89e3\u51b3\u6240\u6709\u53ef\u751f\u6210\u7684\u4efb\u52a1\u3002", "conclusion": "\u901a\u8fc7\u4f2a\u4ee3\u7801\u8c03\u8bd5\u3001\u53cd\u601d\u548c\u591a\u7a0b\u5e8f\u9009\u62e9\u7b49\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8LLM\u751f\u6210\u5e7f\u4e49\u8ba1\u5212\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.13915", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13915", "abs": "https://arxiv.org/abs/2508.13915", "authors": ["Yihao Ang", "Yifan Bao", "Lei Jiang", "Jiajie Tao", "Anthony K. H. Tung", "Lukasz Szpruch", "Hao Ni"], "title": "Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback", "comment": null, "summary": "Time-series data is central to decision-making in financial markets, yet\nbuilding high-performing, interpretable, and auditable models remains a major\nchallenge. While Automated Machine Learning (AutoML) frameworks streamline\nmodel development, they often lack adaptability and responsiveness to\ndomain-specific needs and evolving objectives. Concurrently, Large Language\nModels (LLMs) have enabled agentic systems capable of reasoning, memory\nmanagement, and dynamic code generation, offering a path toward more flexible\nworkflow automation. In this paper, we introduce \\textsf{TS-Agent}, a modular\nagentic framework designed to automate and enhance time-series modeling\nworkflows for financial applications. The agent formalizes the pipeline as a\nstructured, iterative decision process across three stages: model selection,\ncode refinement, and fine-tuning, guided by contextual reasoning and\nexperimental feedback. Central to our architecture is a planner agent equipped\nwith structured knowledge banks, curated libraries of models and refinement\nstrategies, which guide exploration, while improving interpretability and\nreducing error propagation. \\textsf{TS-Agent} supports adaptive learning,\nrobust debugging, and transparent auditing, key requirements for high-stakes\nenvironments such as financial services. Empirical evaluations on diverse\nfinancial forecasting and synthetic data generation tasks demonstrate that\n\\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic\nbaselines, achieving superior accuracy, robustness, and decision traceability.", "AI": {"tldr": "TS-Agent\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u5de5\u4f5c\u6d41\u7a0b\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u51b3\u7b56\u8fc7\u7a0b\u5728\u6a21\u578b\u9009\u62e9\u3001\u4ee3\u7801\u4f18\u5316\u548c\u5fae\u8c03\u65b9\u9762\u8d85\u8d8a\u73b0\u6709AutoML\u65b9\u6cd5", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u9700\u8981\u9ad8\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u5ba1\u8ba1\u7684\u6a21\u578b\uff0c\u4f46\u73b0\u6709AutoML\u6846\u67b6\u7f3a\u4e4f\u5bf9\u9886\u57df\u7279\u5b9a\u9700\u6c42\u548c\u52a8\u6001\u76ee\u6807\u7684\u9002\u5e94\u6027\uff0c\u800cLLM\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u8def\u5f84", "method": "\u8bbe\u8ba1\u6a21\u5757\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u542b\u89c4\u5212\u4ee3\u7406\u548c\u7ed3\u6784\u5316\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8fed\u4ee3\u51b3\u7b56\u8fc7\u7a0b\uff08\u6a21\u578b\u9009\u62e9\u3001\u4ee3\u7801\u4f18\u5316\u3001\u5fae\u8c03\uff09\u8fdb\u884c\u5efa\u6a21\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u5b9e\u9a8c\u53cd\u9988", "result": "\u5728\u591a\u79cd\u91d1\u878d\u9884\u6d4b\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\uff0cTS-Agent\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684AutoML\u548c\u4ee3\u7406\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027", "conclusion": "TS-Agent\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u9002\u5e94\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u6311\u6218\uff0c\u4e3a\u9ad8\u98ce\u9669\u73af\u5883\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.13942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13942", "abs": "https://arxiv.org/abs/2508.13942", "authors": ["Soumyadeep Dhar"], "title": "The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management", "comment": null, "summary": "The rise of autonomous, AI-driven agents in economic settings raises critical\nquestions about their emergent strategic behavior. This paper investigates\nthese dynamics in the cooperative context of a multi-echelon supply chain, a\nsystem famously prone to instabilities like the bullwhip effect. We conduct\ncomputational experiments with generative AI agents, powered by Large Language\nModels (LLMs), within a controlled supply chain simulation designed to isolate\ntheir behavioral tendencies. Our central finding is the \"collaboration\nparadox\": a novel, catastrophic failure mode where theoretically superior\ncollaborative AI agents, designed with Vendor-Managed Inventory (VMI)\nprinciples, perform even worse than non-AI baselines. We demonstrate that this\nparadox arises from an operational flaw where agents hoard inventory, starving\nthe system. We then show that resilience is only achieved through a synthesis\nof two distinct layers: high-level, AI-driven proactive policy-setting to\nestablish robust operational targets, and a low-level, collaborative execution\nprotocol with proactive downstream replenishment to maintain stability. Our\nfinal framework, which implements this synthesis, can autonomously generate,\nevaluate, and quantify a portfolio of viable strategic choices. The work\nprovides a crucial insight into the emergent behaviors of collaborative AI\nagents and offers a blueprint for designing stable, effective AI-driven systems\nfor business analytics.", "AI": {"tldr": "AI\u4ee3\u7406\u5728\u4f9b\u5e94\u94fe\u4e2d\u8868\u73b0\u51fa'\u5408\u4f5c\u6096\u8bba'\uff1a\u7406\u8bba\u4e0a\u66f4\u4f18\u7684\u534f\u540cAI\u4ee3\u7406\u6bd4\u975eAI\u57fa\u51c6\u8868\u73b0\u66f4\u5dee\uff0c\u539f\u56e0\u662f\u5e93\u5b58\u56e4\u79ef\u5bfc\u81f4\u7cfb\u7edf\u5d29\u6e83\u3002\u901a\u8fc7\u9ad8\u5c42AI\u7b56\u7565\u8bbe\u5b9a\u548c\u4f4e\u5c42\u534f\u540c\u6267\u884c\u7684\u7ed3\u5408\u624d\u80fd\u5b9e\u73b0\u7a33\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76AI\u9a71\u52a8\u4ee3\u7406\u5728\u7ecf\u6d4e\u73af\u5883\u4e2d\u7684\u65b0\u5174\u6218\u7565\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u591a\u7ea7\u4f9b\u5e94\u94fe\u8fd9\u79cd\u5bb9\u6613\u51fa\u73b0\u725b\u97ad\u6548\u5e94\u7b49\u4e0d\u7a33\u5b9a\u6027\u7684\u5408\u4f5c\u73af\u5883\u4e2d\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u5f0fAI\u4ee3\u7406\u5728\u53d7\u63a7\u4f9b\u5e94\u94fe\u6a21\u62df\u4e2d\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\uff0c\u8bbe\u8ba1\u5305\u542b\u4f9b\u5e94\u5546\u7ba1\u7406\u5e93\u5b58\u539f\u5219\u7684\u534f\u540cAI\u4ee3\u7406\u3002", "result": "\u53d1\u73b0'\u5408\u4f5c\u6096\u8bba'\u73b0\u8c61\uff0c\u534f\u540cAI\u4ee3\u7406\u8868\u73b0\u6bd4\u975eAI\u57fa\u51c6\u66f4\u5dee\uff1b\u901a\u8fc7\u9ad8\u5c42AI\u7b56\u7565\u8bbe\u5b9a\u548c\u4f4e\u5c42\u534f\u540c\u6267\u884c\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "conclusion": "\u63ed\u793a\u4e86\u534f\u540cAI\u4ee3\u7406\u7684\u65b0\u5174\u884c\u4e3a\u7279\u5f81\uff0c\u4e3a\u8bbe\u8ba1\u7a33\u5b9a\u6709\u6548\u7684AI\u9a71\u52a8\u5546\u4e1a\u5206\u6790\u7cfb\u7edf\u63d0\u4f9b\u4e86\u84dd\u56fe\uff0c\u5f3a\u8c03\u9700\u8981\u591a\u5c42\u6b21\u7b56\u7565\u6765\u907f\u514d\u707e\u96be\u6027\u6545\u969c\u6a21\u5f0f\u3002"}}
{"id": "2508.13975", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13975", "abs": "https://arxiv.org/abs/2508.13975", "authors": ["Jingquan Wang", "Andrew Negrut", "Harry Zhang", "Khailanii Slaton", "Shu Wang", "Radu Serban", "Jinlong Wu", "Dan Negrut"], "title": "ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation", "comment": null, "summary": "This contribution is concerned with the following issue: can pretrained large\nlanguage models (LLMs) be refined and customized to the point where they become\nvirtual assistants helping experts with the effective use of a simulation tool?\nIn this case study, the ``simulation tool'' considered is PyChrono, an open\nsource multi-physics dynamics engine for multibody systems. We present a\nframework for refining and customizing both open- and closed-source LLMs to\nharness the power of AI in generating scripts that perform PyChrono virtual\nexperiments. We refine and customize several classes of LLMs through a process\nthat leads to a quantifiable improvement in the quality of the generated\nPyChrono simulation scripts. These scripts can range from simple\nsingle-pendulum simulations to complex virtual experiments involving full\nvehicles on deformable terrain. While the generated scripts are rarely perfect,\nthey often serve as strong starting points for the user to modify and improve\non. Additionally, the LLM can answer specific API questions about the\nsimulator, or recommend modeling approaches. The framework discussed is general\nand can be applied to lower the entry barrier for simulation tools associated\nwith other application domains.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u7cbe\u7ec6\u8c03\u6574\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u5e2e\u52a9\u4e13\u5bb6\u4f7f\u7528PyChrono\u6a21\u62df\u5de5\u5177\u7684\u865a\u62df\u52a9\u624b\uff0c\u4ee5\u751f\u6210\u8d28\u91cf\u63d0\u5347\u7684\u6a21\u62df\u811a\u672c\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u4e13\u5bb6\u4f7f\u7528PyChrono\u7b49\u6a21\u62df\u5de5\u5177\u7684\u5165\u95e8\u9608\u503c\uff0c\u5229\u7528AI\u6280\u672f\u63d0\u9ad8\u6a21\u62df\u811a\u672c\u7684\u751f\u6210\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u7cbe\u7ec6\u8c03\u6574\u65e0\u8bba\u662f\u5f00\u6e90\u8fd8\u662f\u95ed\u6e90\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u751f\u6210PyChrono\u865a\u62df\u5b9e\u9a8c\u811a\u672c\uff0c\u5e76\u91cf\u5316\u5730\u63d0\u5347\u811a\u672c\u8d28\u91cf\u3002", "result": "\u751f\u6210\u7684\u6a21\u62df\u811a\u672c\u8d28\u91cf\u663e\u8457\u63d0\u9ad8\uff0c\u8303\u56f4\u4ece\u7b80\u5355\u7684\u5355\u6446\u6a21\u578b\u5230\u590d\u6742\u7684\u8f66\u8f86\u5728\u53ef\u53d8\u5f62\u5730\u5f62\u4e0a\u7684\u5b9e\u9a8c\u3002\u867d\u7136\u5e76\u975e\u5b8c\u7f8e\uff0c\u4f46\u4f5c\u4e3a\u521d\u59cb\u70b9\u975e\u5e38\u6709\u7528\uff0c\u8fd8\u80fd\u56de\u7b54API\u76f8\u5173\u95ee\u9898\u548c\u63a8\u8350\u5efa\u6a21\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u666e\u904d\u6027\uff0c\u53ef\u4ee5\u6269\u5c55\u5230\u5176\u4ed6\u6a21\u62df\u5de5\u5177\u9886\u57df\uff0c\u6709\u6548\u964d\u4f4e\u4e13\u4e1a\u6a21\u62df\u5de5\u5177\u7684\u4f7f\u7528\u95e8\u69db\u3002"}}
{"id": "2508.14020", "categories": ["cs.AI", "cs.DM", "68T01", "I.2.8"], "pdf": "https://arxiv.org/pdf/2508.14020", "abs": "https://arxiv.org/abs/2508.14020", "authors": ["Christian Blum", "Pedro Pinacho-Davidson"], "title": "A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem", "comment": null, "summary": "The longest run subsequence (LRS) problem is an NP-hard combinatorial\noptimization problem belonging to the class of subsequence problems from\nbioinformatics. In particular, the problem plays a role in genome reassembly.\nIn this paper, we present a solution to the LRS problem using a Biased Random\nKey Genetic Algorithm (BRKGA). Our approach places particular focus on the\ncomputational efficiency of evaluating individuals, which involves converting\nvectors of gray values into valid solutions to the problem. For comparison\npurposes, a Max-Min Ant System is developed and implemented. This is in\naddition to the application of the integer linear programming solver CPLEX for\nsolving all considered problem instances. The computation results show that the\nproposed BRKGA is currently a state-of-the-art technique for the LRS problem.\nNevertheless, the results also show that there is room for improvement,\nespecially in the context of input strings based on large alphabet sizes.", "AI": {"tldr": "\u4f7f\u7528\u504f\u7f6e\u968f\u673a\u952e\u9053\u56e0\u7b97\u6cd5(BRKGA)\u89e3\u51b3\u6700\u957f\u8fd0\u884c\u5b50\u5e8f\u5217(LRS)\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u89e3\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5927\u5b57\u6bcd\u8868\u5b57\u7b26\u4e32\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4", "motivation": "LRS\u95ee\u9898\u662f\u4e00\u4e2aNP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5728\u751f\u7269\u4fe1\u606f\u5b66\u9886\u57df\u7279\u522b\u662f\u57fa\u56e0\u7ec4\u91cd\u65b0\u7ec4\u88c5\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u9700\u8981\u9ad8\u6548\u89e3\u51b3\u65b9\u6cd5", "method": "\u63d0\u51fa\u4f7f\u7528Biased Random Key Genetic Algorithm (BRKGA)\uff0c\u91cd\u70b9\u5173\u6ce8\u4e2a\u4f53\u8bc4\u4f30\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5c06\u7070\u5ea6\u503c\u5411\u91cf\u8f6c\u6362\u4e3a\u6709\u6548\u89e3\u3002\u4e3a\u6bd4\u8f83\u8fd8\u5f00\u53d1\u4e86Max-Min Ant System\u548c\u4f7f\u7528CPLEX\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668", "result": "\u8ba1\u7b97\u7ed3\u679c\u663e\u793aBRKGA\u5728LRS\u95ee\u9898\u4e0a\u662f\u76ee\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u89e3\u8d28\u91cf\u65b9\u9762\u90fd\u8868\u73b0\u4f18\u5f02", "conclusion": "BRKGA\u65b9\u6cd5\u5728LRS\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u8fc5\u901f\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5728\u5904\u7406\u5927\u5b57\u6bcd\u8868\u5b57\u7b26\u4e32\u65f6\u4ecd\u6709\u6539\u8fdb\u4f59\u5730\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316"}}
{"id": "2508.14040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14040", "abs": "https://arxiv.org/abs/2508.14040", "authors": ["Hanyu Lai", "Xiao Liu", "Yanxiao Zhao", "Han Xu", "Hanchen Zhang", "Bohao Jing", "Yanyu Ren", "Shuntian Yao", "Yuxiao Dong", "Jie Tang"], "title": "ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents", "comment": null, "summary": "We introduce ComputerRL, a framework for autonomous desktop intelligence that\nenables agents to operate complex digital workspaces skillfully. ComputerRL\nfeatures the API-GUI paradigm, which unifies programmatic API calls and direct\nGUI interaction to address the inherent mismatch between machine agents and\nhuman-centric desktop environments. Scaling end-to-end RL training is crucial\nfor improvement and generalization across diverse desktop tasks, yet remains\nchallenging due to environmental inefficiency and instability in extended\ntraining. To support scalable and robust training, we develop a distributed RL\ninfrastructure capable of orchestrating thousands of parallel virtual desktop\nenvironments to accelerate large-scale online RL. Furthermore, we propose\nEntropulse, a training strategy that alternates reinforcement learning with\nsupervised fine-tuning, effectively mitigating entropy collapse during extended\ntraining runs. We employ ComputerRL on open models GLM-4-9B-0414 and\nQwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B\nbased on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%,\ndemonstrating significant improvements for general agents in desktop\nautomation. The algorithm and framework are adopted in building AutoGLM (Liu et\nal., 2024a)", "AI": {"tldr": "ComputerRL\u662f\u4e00\u4e2a\u81ea\u4e3b\u684c\u9762\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7API-GUI\u8303\u5f0f\u7edf\u4e00\u7a0b\u5e8f\u5316API\u8c03\u7528\u548c\u76f4\u63a5GUI\u4ea4\u4e92\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u4ee3\u7406\u4e0e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u684c\u9762\u73af\u5883\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4ee3\u7406\u5728\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u7684\u684c\u9762\u73af\u5883\u4e2d\u64cd\u4f5c\u65f6\u7684\u56fa\u6709\u5931\u914d\u95ee\u9898\uff0c\u4ee5\u53ca\u6269\u5c55\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5728\u591a\u6837\u5316\u684c\u9762\u4efb\u52a1\u4e2d\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u5206\u5e03\u5f0fRL\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u6570\u5343\u4e2a\u5e76\u884c\u865a\u62df\u684c\u9762\u73af\u5883\u8fdb\u884c\u5927\u89c4\u6a21\u5728\u7ebfRL\u8bad\u7ec3\uff1b\u63d0\u51faEntropulse\u8bad\u7ec3\u7b56\u7565\uff0c\u4ea4\u66ff\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u6765\u7f13\u89e3\u71b5\u5d29\u6e83\u95ee\u9898\u3002", "result": "\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eGLM-4-9B-0414\u7684AutoGLM-OS-9B\u8fbe\u5230\u4e8648.1%\u7684\u6700\u65b0\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff0c\u5728\u684c\u9762\u81ea\u52a8\u5316\u901a\u7528\u4ee3\u7406\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "ComputerRL\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684API-GUI\u8303\u5f0f\u548c\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u4e3b\u684c\u9762\u667a\u80fd\u4ee3\u7406\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u684c\u9762\u81ea\u52a8\u5316\u9886\u57df\u5e26\u6765\u4e86\u91cd\u8981\u7a81\u7834\u3002"}}
