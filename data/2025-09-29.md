<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 51]
- [cs.IT](#cs.IT) [Total: 4]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Context-Aware Hybrid Routing in Bluetooth Mesh Networks Using Multi-Model Machine Learning and AODV Fallback](https://arxiv.org/abs/2509.21490)
*Md Sajid Islam,Tanvir Hasan*

Main category: cs.NI

TL;DR: 提出了一种混合智能路由框架，将监督机器学习与AODV路由协议结合，通过四个预测模型改进蓝牙mesh网络中的下一跳选择，在受控条件下实现99.97%的数据包投递率。


<details>
  <summary>Details</summary>
Motivation: 传统路由策略如AODV在拥塞和动态拓扑变化下性能下降，需要更智能的路由机制来提升蓝牙mesh网络在紧急和资源受限场景下的通信可靠性。

Method: 开发了混合智能路由框架，集成四个预测模型：投递成功率分类器、TTL回归器、延迟回归器和转发器适用性分类器，通过统一评分机制动态排序邻居节点。在包含缓冲区约束和设备异构性的仿真环境中评估了三种策略。

Result: 在十种场景下，完整的混合ML模型(ABCD)实现了约99.97%的数据包投递率，显著优于基准AODV和中间方法。

Conclusion: 轻量级、可解释的机器学习模型能够增强蓝牙mesh网络中的路由可靠性和适应性，特别是在无基础设施环境中，投递成功率优先于延迟约束的场景。

Abstract: Bluetooth-based mesh networks offer a promising infrastructure for offline
communication in emergency and resource constrained scenarios. However,
traditional routing strategies such as Ad hoc On-Demand Distance Vector (AODV)
often degrade under congestion and dynamic topological changes. This study
proposes a hybrid intelligent routing framework that augments AODV with
supervised machine learning to improve next-hop selection under varied network
constraints. The framework integrates four predictive models: a delivery
success classifier, a TTL regressor, a delay regressor, and a forwarder
suitability classifier, into a unified scoring mechanism that dynamically ranks
neighbors during multi-hop message transmission. A simulation environment with
stationary node deployments was developed, incorporating buffer constraints and
device heterogeneity to evaluate three strategies: baseline AODV, a partial
hybrid ML model (ABC), and the full hybrid ML model (ABCD). Across ten
scenarios, the Hybrid ABCD model achieves approximately 99.97 percent packet
delivery under these controlled conditions, significantly outperforming both
the baseline and intermediate approaches. The results demonstrate that
lightweight, explainable machine learning models can enhance routing
reliability and adaptability in Bluetooth mesh networks, particularly in
infrastructure-less environments where delivery success is prioritized over
latency constraints.

</details>


### [2] [A Target-Agnostic Protocol-Independent Interface for the Transport Layer](https://arxiv.org/abs/2509.21550)
*Pedro Mizuno,Kimiya Mohammadtaheri,Linfan Qian,Joshua Johnson,Danny Akbarzadeh,Chris Neely,Mario Baldi,Nacihket Kapre,Mina Tahmasbi Arashloo*

Main category: cs.NI

TL;DR: 提出TINF编程框架，使用高级、目标无关的编程抽象来规范传输协议，支持在多种执行环境中开发传输协议。


<details>
  <summary>Details</summary>
Motivation: 传输协议在网络通信中至关重要，但面临协议多样性和执行环境差异的挑战，需要一种高级、目标无关的编程抽象来简化开发。

Method: 将传输协议指定为高级程序，采用类似C语言的约束构造，处理事件和流状态，生成目标无关的指令用于数据重组、包生成调度和定时器操作。

Result: 开发了TINF框架和两个后端实现（DPDK和Linux eXpress DataPath），成功部署了多个传输协议。

Conclusion: 目标无关的传输程序可以减少传输协议开发工作量，支持自动化分析和形式验证，并推动传输协议可编程目标的研究。

Abstract: Transport protocols are fundamental to network communications, continuously
evolving to meet the demands of new applications, workloads, and network
architectures while running in a wide range of execution environments (a.k.a
targets). We argue that this diversity across protocols and targets calls for a
high-level, target-agnostic programming abstraction for the transport layer.
Specifically, we propose to specify transport protocols as high-level programs
that take an event and flow state as input, and using constrained C-like
constructs, produce the updated state along with target-agnostic instructions
for key transport operations such as data reassembly, packet generation and
scheduling, and timer manipulations.
  We show the benefits of our high-level transport programs by developing
multiple transport protocols in our programming framework called TINF,
developing two TINF- compliant backends, one in DPDK and one in Linux eXpress
DataPath, and deploying TINF programs for multiple protocols across both
backends. Inspired by the benefits unlocked by L2/L3 packet-processing
languages like P4, we believe target-agnostic transport programs can reduce the
development effort for transport protocols, enable automated analysis and
formal verification of the transport layer, and further research in
programmable targets for transport protocols.

</details>


### [3] [eXplainable Artificial Intelligence for RL-based Networking Solutions](https://arxiv.org/abs/2509.21649)
*Yeison Stiven Murcia,Oscar Mauricio Caicedo,Daniela Maria Casas,Nelson Luis Saldanha da Fonseca*

Main category: cs.NI

TL;DR: eXplaNet是一个基于可解释人工智能的管道，旨在帮助网络研究人员理解RL智能体的决策过程，并应用于改进Q-learning路由解决方案的奖励函数。


<details>
  <summary>Details</summary>
Motivation: 理解RL智能体的决策对于网络管理中的广泛应用至关重要，需要提高这些解决方案的可解释性。

Method: 引入eXplaNet管道，基于可解释AI技术，分析RL智能体的决策过程，特别应用于Q-learning路由解决方案的奖励函数优化。

Result: eXplaNet能够提供对RL智能体决策的深入洞察，帮助改进路由解决方案的性能。

Conclusion: 将可解释性融入RL可以更好地优化网络性能，但同时也面临挑战和机遇。

Abstract: Reinforcement Learning (RL) agents have been widely used to improve
networking tasks. However, understanding the decisions made by these agents is
essential for their broader adoption in networking and network management. To
address this, we introduce eXplaNet - a pipeline grounded in explainable
artificial intelligence - designed to help networking researchers and
practitioners gain deeper insights into the decision-making processes of
RL-based solutions. We demonstrate how eXplaNet can be applied to refine a
routing solution powered by a Q-learning agent, specifically by improving its
reward function. In addition, we discuss the opportunities and challenges of
incorporating explainability into RL to better optimize network performance.

</details>


### [4] [XenoFlow: How Fast Can a SmartNIC-Based DNS Load Balancer Run?](https://arxiv.org/abs/2509.21656)
*Max Schrötter,Sten Heimbrodt,Bettina Schnor*

Main category: cs.NI

TL;DR: XenoFlow是基于Bluefield-3可编程NIC的负载均衡器，相比基于eBPF的软件方案延迟降低44%，即使在高压下也能保持低延迟，但Bluefield-3在Flow Pipe仅有2个条目时无法达到线速。


<details>
  <summary>Details</summary>
Motivation: 随着可编程网络硬件的发展，越来越多的功能可以从通用CPU上的软件迁移到NIC上。早期NIC只支持卸载固定功能，而现代NIC如Nvidia Bluefield-3允许完全可编程的数据平面。

Method: 开发了名为XenoFlow的负载均衡器，运行在Bluefield-3 NIC上，并测试了Bluefield-3 eSwitch的能力和限制。

Result: Bluefield-3在Flow Pipe仅有2个条目时无法达到线速。但XenoFlow相比基于eBPF的负载均衡器延迟降低44%，且在高负载下仍能保持低延迟。

Conclusion: 硬件卸载到NIC并更靠近网络具有优势，XenoFlow展示了在可编程NIC上实现负载均衡的可行性和性能优势。

Abstract: With the advent of programmable network hardware, more and more
  functionality can be moved from software running on general purpose CPUs to
  the NIC. Early NICs only allowed offloading fixed functions like checksum
  computation. Recent NICs like the Nvidia Bluefield-3 allow a fully
  programmable dataplane. In this paper, we present our first steps towards a
  load balancer named XenoFlow running on the Bluefield-3. Furthermore, we
  show the capabilities and limitations of the Bluefield-3 eSwitch. Our
  results show that the Bluefield-3 will not achieve line rate with only 2
  entries in a Flow Pipe. However, we also show the adventages of hardware
  offloading on the NIC and being closer to the network. With XenoFlow, we
  achieve an 44% lower latency compared to a comparable eBPF-based load
  balancer running on the host. Furthermore, XenoFlow achieves this low
  latency even under high load.

</details>


### [5] [Evaluating Open-Source Large Language Models for Technical Telecom Question Answering](https://arxiv.org/abs/2509.21949)
*Arina Caraus,Alessio Buscemi,Sumit Kumar,Ion Turcanu*

Main category: cs.NI

TL;DR: 评估两个开源大语言模型(Gemma 3 27B和DeepSeek R1 32B)在电信领域的技术表现，通过构建105个问答对基准测试，使用词汇指标、语义相似度和LLM评分进行分析。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在电信等技术领域的表现尚未充分探索，需要评估其在专业领域的能力以支持可信赖的AI助手开发。

Method: 构建105个高级无线通信问题的问答对基准，使用词汇指标、语义相似度和LLM作为评判者进行评分，并通过来源归因和分数方差分析一致性和幻觉问题。

Result: Gemma在语义保真度和LLM评分正确性方面表现更佳，DeepSeek在词汇一致性方面略胜一筹。研究揭示了当前模型在电信应用中的局限性。

Conclusion: 需要领域适配的模型来支持工程领域可信赖的AI助手，当前模型在电信技术领域仍有改进空间。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities across
various fields. However, their performance in technical domains such as
telecommunications remains underexplored. This paper evaluates two open-source
LLMs, Gemma 3 27B and DeepSeek R1 32B, on factual and reasoning-based questions
derived from advanced wireless communications material. We construct a
benchmark of 105 question-answer pairs and assess performance using lexical
metrics, semantic similarity, and LLM-as-a-judge scoring. We also analyze
consistency, judgment reliability, and hallucination through source attribution
and score variance. Results show that Gemma excels in semantic fidelity and
LLM-rated correctness, while DeepSeek demonstrates slightly higher lexical
consistency. Additional findings highlight current limitations in telecom
applications and the need for domain-adapted models to support trustworthy
Artificial Intelligence (AI) assistants in engineering.

</details>


### [6] [Extreme Value Theory-enhanced Radio Maps for Handovers in Ultra-reliable Communications](https://arxiv.org/abs/2509.22547)
*Dian Echevarría Pérez,Onel L. Alcaraz López,Hirley Alves*

Main category: cs.NI

TL;DR: 提出了一种基于物理层视角的新型切换框架，利用极值理论和统计无线电地图预测信号行为，优化切换时机和位置决策，提高超可靠通信系统的服务可用性和能效。


<details>
  <summary>Details</summary>
Motivation: 为满足超可靠通信系统的严格性能要求，需要高效的切换策略来维持通信质量。

Method: 采用基于物理层的方法，结合极值理论和统计无线电地图来预测信号行为，优化切换决策的时间和位置，并包含抑制乒乓效应的机制。

Result: 与传统切换机制相比，该策略提供了更优的服务可用性和能效，在超可靠通信环境中表现有效。

Conclusion: 所提出的切换框架通过物理层视角和统计预测方法，能够实现无缝切换和改善的系统性能，适用于超可靠通信环境。

Abstract: Efficient handover (HO) strategies are essential for maintaining the
stringent performance requirements of ultra-reliable communication (URC)
systems. This work introduces a novel HO framework designed from a
physical-layer perspective, where the decision-making process focuses on
determining the optimal time and location for performing HOs. Leveraging
extreme value theory (EVT) and statistical radio maps, the proposed method
predicts signal behaviour and enables efficient resource allocation. The
framework ensures seamless HOs and improved system performance by facilitating
effective resource transitions and coordination across spatial locations while
incorporating mechanisms to mitigate the ping-pong effect. Comparative
evaluations demonstrate that this strategy provides superior service
availability and energy efficiency than traditional HO mechanisms, highlighting
its effectiveness in URC environments.

</details>


### [7] [Bridging Technical Capability and User Accessibility: Off-grid Civilian Emergency Communication](https://arxiv.org/abs/2509.22568)
*Karim Khamaisi,Oliver Kamer,Bruno Rodrigues,Jan von der Assen,Burkhard Stiller*

Main category: cs.NI

TL;DR: 提出了一个统一的应急通信系统，结合低功耗长距离网络和危机导向的智能手机应用，实现去中心化的离线民用通信。


<details>
  <summary>Details</summary>
Motivation: 在大型危机破坏蜂窝和互联网基础设施时，平民缺乏可靠的通信、援助协调和可信信息获取方法。

Method: 集成低功耗长距离网络与危机导向智能手机应用，通过实地实验评估通信性能和应用功能。

Result: 在苏黎世城市实验中，868MHz频段使用LongFast配置实现1.2公里通信范围，92%的数据包传输率；专用移动应用具备点对点消息、身份验证和社区管理功能。

Conclusion: 该系统在现实基础设施退化条件下验证了网络鲁棒性，为危机环境提供了有效的去中心化通信解决方案。

Abstract: During large-scale crises disrupting cellular and Internet infrastructure,
civilians lack reliable methods for communication, aid coordination, and access
to trustworthy information. This paper presents a unified emergency
communication system integrating a low-power, long-range network with a
crisis-oriented smartphone application, enabling decentralized and off-grid
civilian communication. Unlike previous solutions separating physical layer
resilience from user layer usability, our design merges these aspects into a
cohesive crisis-tailored framework.
  The system is evaluated in two dimensions: communication performance and
application functionality. Field experiments in urban Z\"urich demonstrate that
the 868 MHz band, using the LongFast configuration, achieves a communication
range of up to 1.2 km with 92% Packet Delivery Ratio, validating network
robustness under real-world infrastructure degraded conditions. In parallel, a
purpose-built mobile application featuring peer-to-peer messaging, identity
verification, and community moderation was evaluated through a
requirements-based analysis.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Towards mitigating information leakage when evaluating safety monitors](https://arxiv.org/abs/2509.21344)
*Gerard Boxo,Aman Neelappa,Shivam Raval*

Main category: cs.AI

TL;DR: 提出评估白盒监控器检测真实模型行为而非表面诱导伪影的系统框架，包括内容过滤、分数过滤和提示蒸馏微调模型三种策略，在欺骗检测案例中发现性能虚高问题。


<details>
  <summary>Details</summary>
Motivation: 白盒监控器在检测大语言模型有害行为方面有优势，但训练评估需要目标行为样本，而诱导行为的信息会泄露到监控器数据中，导致性能评估虚高。

Method: 提出系统性评估框架，包含三种策略：内容过滤（移除欺骗相关文本）、分数过滤（仅聚合任务相关token）、提示蒸馏微调模型（无需显式提示即可展示欺骗行为）。

Result: 实验发现两种泄露形式：诱导泄露（来自显式请求有害行为的提示）和推理泄露（来自模型口头化欺骗行为）。内容过滤可降低AUROC 30%，分数过滤降低15%，微调模型降低性能达40%。

Conclusion: 内容过滤是有效的缓解策略，能平滑移除诱导信号；分数过滤效果次之但归因不明确；微调模型改进评估但显著降低监控器性能。

Abstract: White box monitors that analyze model internals offer promising advantages
for detecting potentially harmful behaviors in large language models, including
lower computational costs and integration into layered defense systems.However,
training and evaluating these monitors requires response exemplars that exhibit
the target behaviors, typically elicited through prompting or fine-tuning. This
presents a challenge when the information used to elicit behaviors inevitably
leaks into the data that monitors ingest, inflating their effectiveness. We
present a systematic framework for evaluating a monitor's performance in terms
of its ability to detect genuine model behavior rather than superficial
elicitation artifacts. Furthermore, we propose three novel strategies to
evaluate the monitor: content filtering (removing deception-related text from
inputs), score filtering (aggregating only over task-relevant tokens), and
prompt distilled fine-tuned model organisms (models trained to exhibit
deceptive behavior without explicit prompting). Using deception detection as a
representative case study, we identify two forms of leakage that inflate
monitor performance: elicitation leakage from prompts that explicitly request
harmful behavior, and reasoning leakage from models that verbalize their
deceptive actions. Through experiments on multiple deception benchmarks, we
apply our proposed mitigation strategies and measure performance retention. Our
evaluation of the monitors reveal three crucial findings: (1) Content filtering
is a good mitigation strategy that allows for a smooth removal of elicitation
signal and can decrease probe AUROC by 30\% (2) Score filtering was found to
reduce AUROC by 15\% but is not as straightforward to attribute to (3) A
finetuned model organism improves monitor evaluations but reduces their
performance by upto 40\%, even when re-trained.

</details>


### [9] [Correct Reasoning Paths Visit Shared Decision Pivots](https://arxiv.org/abs/2509.21549)
*Dongkyu Cho,Amy B. Z. Zhang,Bilel Fehri,Sheng Wang,Rumi Chunara,Rui Song,Hengrui Cai*

Main category: cs.AI

TL;DR: 提出决策枢纽的概念来验证思维链推理，通过自训练管道挖掘共享决策枢纽、压缩推理路径，并在无真实推理数据的情况下对齐模型推理过程。


<details>
  <summary>Details</summary>
Motivation: 思维链推理暴露了大型语言模型的中间思考过程，但大规模验证这些推理轨迹仍然是一个未解决的问题。

Method: 提出决策枢纽作为可验证的检查点，通过自训练管道：(1)采样多样推理路径并挖掘共享决策枢纽；(2)使用辅助验证器将推理轨迹压缩为枢纽聚焦的短路径推理；(3)使用自生成输出进行后训练。

Result: 在LogiQA、MedQA和MATH500等标准基准测试中验证了方法的有效性。

Conclusion: 该方法能够在没有真实推理数据或外部指标的情况下对齐推理过程，证明了决策枢纽概念的有效性。

Abstract: Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of
large language models (LLMs), yet verifying those traces at scale remains
unsolved. In response, we introduce the idea of decision pivots-minimal,
verifiable checkpoints that any correct reasoning path must visit. We
hypothesize that correct reasoning, though stylistically diverse, converge on
the same pivot set, while incorrect ones violate at least one pivot. Leveraging
this property, we propose a self-training pipeline that (i) samples diverse
reasoning paths and mines shared decision pivots, (ii) compresses each trace
into pivot-focused short-path reasoning using an auxiliary verifier, and (iii)
post-trains the model using its self-generated outputs. The proposed method
aligns reasoning without ground truth reasoning data or external metrics.
Experiments on standard benchmarks such as LogiQA, MedQA, and MATH500 show the
effectiveness of our method.

</details>


### [10] [AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need](https://arxiv.org/abs/2509.21553)
*Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng*

Main category: cs.AI

TL;DR: 提出了一个结合知识图谱和AI代理的云原生科学工作流系统，旨在降低气候数据科学的技术门槛，使非专业用户能够通过自然语言交互访问和分析气候数据。


<details>
  <summary>Details</summary>
Motivation: 气候数据科学面临数据源分散、格式异构和技术门槛高等挑战，限制了参与度、减缓了发现速度并降低了科学工作流的可重复性。

Method: 通过整合精心策划的知识图谱与AI代理，知识图谱提供统一的数据集、工具和工作流组织层，AI代理基于生成式AI服务实现自然语言交互、自动化数据访问和简化分析。

Result: 该系统显著降低了参与气候数据科学的技术门槛，使非专业用户能够识别和分析相关数据集，展示了通过知识图谱实现可扩展和自主科学工作流的可行性。

Conclusion: 该方法为民主化气候数据访问和建立可重复、可扩展的人类-AI协作科学研究框架提供了一条可行路径。

Abstract: Climate data science faces persistent barriers stemming from the fragmented
nature of data sources, heterogeneous formats, and the steep technical
expertise required to identify, acquire, and process datasets. These challenges
limit participation, slow discovery, and reduce the reproducibility of
scientific workflows. In this paper, we present a proof of concept for
addressing these barriers through the integration of a curated knowledge graph
(KG) with AI agents designed for cloud-native scientific workflows. The KG
provides a unifying layer that organizes datasets, tools, and workflows, while
AI agents -- powered by generative AI services -- enable natural language
interaction, automated data access, and streamlined analysis. Together, these
components drastically lower the technical threshold for engaging in climate
data science, enabling non-specialist users to identify and analyze relevant
datasets. By leveraging existing cloud-ready API data portals, we demonstrate
that "a knowledge graph is all you need" to unlock scalable and agentic
workflows for scientific inquiry. The open-source design of our system further
supports community contributions, ensuring that the KG and associated tools can
evolve as a shared commons. Our results illustrate a pathway toward
democratizing access to climate data and establishing a reproducible,
extensible framework for human--AI collaboration in scientific research.

</details>


### [11] [EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks](https://arxiv.org/abs/2509.21567)
*Mohammad Parsa Afshar,Aryan Azimi*

Main category: cs.AI

TL;DR: 该研究使用EEG数据和机器学习模型预测消费者行为，比较了传统模型和图神经网络(GNN)的性能。


<details>
  <summary>Details</summary>
Motivation: 预测消费者行为在营销、认知神经科学和人机交互中很重要，EEG数据可以提供大脑神经活动的详细信息来分析决策过程。

Method: 从NeuMa数据集中提取和清理EEG特征，为GNN模型创建大脑连接特征，使用传统机器学习模型和不同架构的GNN模型进行比较。

Result: 结果整体上没有显著差异，但GNN模型在某些传统模型表现不佳的基本标准上表现更好。

Conclusion: EEG信号分析与机器学习模型结合可以更深入理解消费者行为，研究提供了传统模型与GNN在基于EEG的神经营销中的全面比较。

Abstract: Prediction of consumer behavior is one of the important purposes in
marketing, cognitive neuroscience, and human-computer interaction. The
electroencephalography (EEG) data can help analyze the decision process by
providing detailed information about the brain's neural activity. In this
research, a comparative approach is utilized for predicting consumer behavior
by EEG data. In the first step, the features of the EEG data from the NeuMa
dataset were extracted and cleaned. For the Graph Neural Network (GNN) models,
the brain connectivity features were created. Different machine learning
models, such as classical models and Graph Neural Networks, are used and
compared. The GNN models with different architectures are implemented to have a
comprehensive comparison; furthermore, a wide range of classical models, such
as ensemble models, are applied, which can be very helpful to show the
difference and performance of each model on the dataset. Although the results
did not show a significant difference overall, the GNN models generally
performed better in some basic criteria where classical models were not
satisfactory. This study not only shows that combining EEG signal analysis and
machine learning models can provide an approach to deeper understanding of
consumer behavior, but also provides a comprehensive comparison between the
machine learning models that have been widely used in previous studies in the
EEG-based neuromarketing such as Support Vector Machine (SVM), and the models
which are not used or rarely used in the field, like Graph Neural Networks.

</details>


### [12] [GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models](https://arxiv.org/abs/2509.21593)
*Peng Luo,Xiayin Lou,Yu Zheng,Zhuo Zheng,Stefano Ermon*

Main category: cs.AI

TL;DR: GeoEvolve是一个多智能体LLM框架，通过结合进化搜索和地理空间领域知识，自动设计和优化地理空间算法，在空间插值和不确定性量化任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的算法发现框架缺乏地理空间领域知识和多步推理能力，难以解决复杂的地理空间问题。

Method: 采用双层循环结构：内层循环使用代码进化器生成和变异候选解，外层智能控制器评估全局精英并查询GeoKnowRAG模块（结构化地理空间知识库），通过知识引导进化搜索。

Result: 在空间插值任务上减少13-21%的RMSE误差，在不确定性估计任务上提升17%的性能。消融研究证实领域知识引导检索对稳定高质量进化至关重要。

Conclusion: GeoEvolve为自动化、知识驱动的地理空间建模提供了可扩展路径，为可信赖和高效的AI-for-Science发现开辟了新机会。

Abstract: Geospatial modeling provides critical solutions for pressing global
challenges such as sustainability and climate change. Existing large language
model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at
evolving generic code but lack the domain knowledge and multi-step reasoning
required for complex geospatial problems. We introduce GeoEvolve, a multi-agent
LLM framework that couples evolutionary search with geospatial domain knowledge
to automatically design and refine geospatial algorithms. GeoEvolve operates in
two nested loops: an inner loop leverages a code evolver to generate and mutate
candidate solutions, while an outer agentic controller evaluates global elites
and queries a GeoKnowRAG module -- a structured geospatial knowledge base that
injects theoretical priors from geography. This knowledge-guided evolution
steers the search toward theoretically meaningful and computationally efficient
algorithms. We evaluate GeoEvolve on two fundamental and classical tasks:
spatial interpolation (kriging) and spatial uncertainty quantification
(geospatial conformal prediction). Across these benchmarks, GeoEvolve
automatically improves and discovers new algorithms, incorporating geospatial
theory on top of classical models. It reduces spatial interpolation error
(RMSE) by 13-21% and enhances uncertainty estimation performance by 17\%.
Ablation studies confirm that domain-guided retrieval is essential for stable,
high-quality evolution. These results demonstrate that GeoEvolve provides a
scalable path toward automated, knowledge-driven geospatial modeling, opening
new opportunities for trustworthy and efficient AI-for-Science discovery.

</details>


### [13] [Automated and Interpretable Survival Analysis from Multimodal Data](https://arxiv.org/abs/2509.21600)
*Mafalda Malafaia,Peter A. N. Bosman,Coen Rasch,Tanja Alderliesten*

Main category: cs.AI

TL;DR: 提出可解释的多模态AI框架MultiFIX，整合临床变量和CT影像进行生存分析，在头颈癌数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 精准且可解释的生存分析是肿瘤学核心挑战，随着多模态数据增长和临床对透明模型的需求，需要开发可验证和可信的模型。

Method: 使用深度学习推断生存相关特征，影像特征通过Grad-CAM解释，临床变量通过遗传编程建模为符号表达式，风险估计采用透明Cox回归进行风险分层。

Result: 在头颈癌RADCURE数据集上，MultiFIX获得C-index为0.838（预测）和0.826（分层），优于临床和学术基线方法，并与已知预后标志物一致。

Conclusion: MultiFIX展示了可解释多模态AI在精准肿瘤学中的潜力，为临床决策提供透明支持。

Abstract: Accurate and interpretable survival analysis remains a core challenge in
oncology. With growing multimodal data and the clinical need for transparent
models to support validation and trust, this challenge increases in complexity.
We propose an interpretable multimodal AI framework to automate survival
analysis by integrating clinical variables and computed tomography imaging. Our
MultiFIX-based framework uses deep learning to infer survival-relevant features
that are further explained: imaging features are interpreted via Grad-CAM,
while clinical variables are modeled as symbolic expressions through genetic
programming. Risk estimation employs a transparent Cox regression, enabling
stratification into groups with distinct survival outcomes. Using the
open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a
C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the
clinical and academic baseline approaches and aligning with known prognostic
markers. These results highlight the promise of interpretable multimodal AI for
precision oncology with MultiFIX.

</details>


### [14] [Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries](https://arxiv.org/abs/2509.21633)
*Georgios Chochlakis,Jackson Trager,Vedant Jhaveri,Nikhil Ravichandran,Alexandros Potamianos,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 提出了语义F1分数，这是一种用于主观或多标签分类的新评估指标，通过量化预测标签与真实标签之间的语义相关性来改进传统F1指标。


<details>
  <summary>Details</summary>
Motivation: 传统F1指标在处理语义相关但非完全相同的预测时将其视为完全失败，这不符合现实中类别边界模糊、标注者存在分歧的实际情况。

Method: 使用标签相似度矩阵计算软精度和软召回分数，通过两步骤的精度-召回公式，能够比较任意大小的标签集，无需丢弃标签或强制匹配不相似的标签。

Result: 通过理论论证和在合成及真实数据上的广泛实证验证，语义F1分数显示出更好的可解释性和生态有效性。

Conclusion: 语义F1分数通过为语义相关但非完全相同的标签给予部分分数，提供了更公平的评估，适用于各种任务和模态，仅需领域适当的相似度矩阵而非严格的本体论。

Abstract: We propose Semantic F1 Scores, novel evaluation metrics for subjective or
fuzzy multi-label classification that quantify semantic relatedness between
predicted and gold labels. Unlike the conventional F1 metrics that treat
semantically related predictions as complete failures, Semantic F1 incorporates
a label similarity matrix to compute soft precision-like and recall-like
scores, from which the Semantic F1 scores are derived. Unlike existing
similarity-based metrics, our novel two-step precision-recall formulation
enables the comparison of label sets of arbitrary sizes without discarding
labels or forcing matches between dissimilar labels. By granting partial credit
for semantically related but nonidentical labels, Semantic F1 better reflects
the realities of domains marked by human disagreement or fuzzy category
boundaries. In this way, it provides fairer evaluations: it recognizes that
categories overlap, that annotators disagree, and that downstream decisions
based on similar predictions lead to similar outcomes. Through theoretical
justification and extensive empirical validation on synthetic and real data, we
show that Semantic F1 demonstrates greater interpretability and ecological
validity. Because it requires only a domain-appropriate similarity matrix,
which is robust to misspecification, and not a rigid ontology, it is applicable
across tasks and modalities.

</details>


### [15] [Can AI Perceive Physical Danger and Intervene?](https://arxiv.org/abs/2509.21651)
*Abhishek Jindal,Dmitry Kalashnikov,Oscar Chang,Divya Garikapati,Anirudha Majumdar,Pierre Sermanet,Vikas Sindhwani*

Main category: cs.AI

TL;DR: 开发了一个用于评估具身AI系统物理安全性的基准测试方法，基于真实世界伤害叙事生成图像和视频，分析主要基础模型的安全感知能力，并提出后训练范式提升安全推理能力。


<details>
  <summary>Details</summary>
Motivation: AI与物理世界交互时存在直接物理伤害风险，需要评估基础模型对物理安全常识的理解能力，如物体重量、温度等安全因素。

Method: 基于真实伤害叙事生成逼真图像和视频，分析模型风险感知能力，开发后训练范式让模型显式推理具身安全约束。

Result: 模型生成可解释的安全推理轨迹，在约束满足评估中达到最先进性能。

Conclusion: 提出的基准测试和后训练方法能有效提升具身AI系统的安全推理能力，为安全关键应用部署提供重要参考。

Abstract: When AI interacts with the physical world -- as a robot or an assistive agent
-- new safety challenges emerge beyond those of purely ``digital AI". In such
interactions, the potential for physical harm is direct and immediate. How well
do state-of-the-art foundation models understand common-sense facts about
physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of
coffee should not be handed to a child? In this paper, our contributions are
three-fold: first, we develop a highly scalable approach to continuous physical
safety benchmarking of Embodied AI systems, grounded in real-world injury
narratives and operational safety constraints. To probe multi-modal safety
understanding, we turn these narratives and constraints into photorealistic
images and videos capturing transitions from safe to unsafe states, using
advanced generative models. Secondly, we comprehensively analyze the ability of
major foundation models to perceive risks, reason about safety, and trigger
interventions; this yields multi-faceted insights into their deployment
readiness for safety-critical agentic applications. Finally, we develop a
post-training paradigm to teach models to explicitly reason about
embodiment-specific safety constraints provided through system instructions.
The resulting models generate thinking traces that make safety reasoning
interpretable and transparent, achieving state of the art performance in
constraint satisfaction evaluations. The benchmark will be released at
https://asimov-benchmark.github.io/v2

</details>


### [16] [Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization](https://arxiv.org/abs/2509.21718)
*Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li*

Main category: cs.AI

TL;DR: 提出基于GRPO的框架，使用未配对文本和语音数据优化多语言TTS模型，在低资源语言中显著优于仅微调方法，在高资源语言中也优于DPO等对齐方法。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的TTS系统开发面临配对数据稀缺的挑战，而ASR模型相对更容易获得，因此探索利用ASR等预训练模型来指导TTS优化。

Method: 1) 使用IPA标记训练多语言TTS基线；2) 在有限配对数据上微调以捕捉目标语言韵律特征；3) 应用GRPO，仅使用未配对文本和说话人提示，通过ASR、说话人验证和音频质量估计模型的多目标奖励进行优化。

Result: 该流程在低资源语言中生成可理解且说话人一致的语音，显著优于仅微调方法。在高资源语言中，GRPO框架也优于DPO等离线对齐方法，在可理解性、说话人相似性和音频质量方面表现更优。

Conclusion: 基于GRPO的框架能够有效利用未配对数据优化TTS模型，在低资源和高资源语言中均取得优异性能，为低资源语言TTS开发提供了可行方案。

Abstract: Developing high-quality text-to-speech (TTS) systems for low-resource
languages is challenging due to the scarcity of paired text and speech data. In
contrast, automatic speech recognition (ASR) models for such languages are
often more accessible, owing to large-scale multilingual pre-training efforts.
We propose a framework based on Group Relative Policy Optimization (GRPO) to
adapt an autoregressive, multilingual TTS model to new languages. Our method
first establishes a language-agnostic foundation for TTS synthesis by training
a multilingual baseline with International Phonetic Alphabet (IPA) tokens.
Next, we fine-tune this model on limited paired data of the new languages to
capture the target language's prosodic features. Finally, we apply GRPO to
optimize the model using only unpaired text and speaker prompts, guided by a
multi-objective reward from pretrained ASR, speaker verification, and audio
quality estimation models. Experiments demonstrate that this pipeline produces
intelligible and speaker-consistent speech in low-resource languages,
substantially outperforming fine-tuning alone. Furthermore, our GRPO-based
framework also improves TTS performance in high-resource languages, surpassing
offline alignment methods such as Direct Preference Optimization (DPO) yielding
superior intelligibility, speaker similarity, and audio quality.

</details>


### [17] [Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts](https://arxiv.org/abs/2509.21743)
*Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar*

Main category: cs.AI

TL;DR: RoT通过检索和重用先前的推理步骤来构建动态模板，减少推理时的冗余探索，从而显著降低输出token数量、推理延迟和成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长推理轨迹来提高准确性，但这会增加延迟和成本，因此需要推理时效率优化。

Method: 提出RoT方法，将先前的推理步骤组织成带有顺序和语义边的思维图，通过检索查询相关节点并应用奖励引导的遍历来组装问题特定的模板。

Result: 在多个推理基准测试中，RoT将输出token减少高达40%，推理延迟降低82%，成本降低59%，同时保持准确性。

Conclusion: RoT通过检索构建动态模板，为高效的大型推理模型推理建立了可扩展的范式。

Abstract: Large reasoning models improve accuracy by producing long reasoning traces,
but this inflates latency and cost, motivating inference-time efficiency. We
propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable
``thought" steps to guide new problems. RoT organizes steps into a thought
graph with sequential and semantic edges to enable fast retrieval and flexible
recombination. At inference, RoT retrieves query-relevant nodes and applies
reward-guided traversal to assemble a problem-specific template that guides
generation. This dynamic template reuse reduces redundant exploration and,
therefore, reduces output tokens while preserving accuracy. We evaluate RoT on
reasoning benchmarks with multiple models, measuring accuracy, token usage,
latency, and memory overhead. Findings show small prompt growth but substantial
efficiency gains, with RoT reducing output tokens by up to 40%, inference
latency by 82%, and cost by 59% while maintaining accuracy. RoT establishes a
scalable paradigm for efficient LRM reasoning via dynamic template construction
through retrieval.

</details>


### [18] [Lifelong Learning with Behavior Consolidation for Vehicle Routing](https://arxiv.org/abs/2509.21765)
*Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao*

Main category: cs.AI

TL;DR: 提出LLR-BC框架，解决神经VRP求解器在终身学习场景中的灾难性遗忘问题，通过行为整合保持先前任务知识，同时有效学习新任务。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器在遇到新任务时，要么依赖零样本泛化（效果差），要么微调（导致灾难性遗忘），需要一种终身学习范式来持续学习多个任务。

Method: 提出LLR-BC框架，通过决策寻求方式将新任务训练求解器的行为与缓冲区中的行为对齐，并为低置信度决策分配更大整合权重。

Result: 在容量约束车辆路径问题和旅行商问题上的实验表明，LLR-BC能有效训练高性能神经求解器，解决灾难性遗忘，保持可塑性，提升零样本泛化能力。

Conclusion: LLR-BC为神经VRP求解器提供了一种有效的终身学习解决方案，能够在多任务序列中持续学习而不遗忘先前知识。

Abstract: Recent neural solvers have demonstrated promising performance in learning to
solve routing problems. However, existing studies are primarily based on
one-off training on one or a set of predefined problem distributions and
scales, i.e., tasks. When a new task arises, they typically rely on either
zero-shot generalization, which may be poor due to the discrepancies between
the new task and the training task(s), or fine-tuning the pretrained solver on
the new task, which possibly leads to catastrophic forgetting of knowledge
acquired from previous tasks. This paper explores a novel lifelong learning
paradigm for neural VRP solvers, where multiple tasks with diverse
distributions and scales arise sequentially over time. Solvers are required to
effectively and efficiently learn to solve new tasks while maintaining their
performance on previously learned tasks. Consequently, a novel framework called
Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed.
LLR-BC consolidates prior knowledge effectively by aligning behaviors of the
solver trained on a new task with the buffered ones in a decision-seeking way.
To encourage more focus on crucial experiences, LLR-BC assigns greater
consolidated weights to decisions with lower confidence. Extensive experiments
on capacitated vehicle routing problems and traveling salesman problems
demonstrate LLR-BC's effectiveness in training high-performance neural solvers
in a lifelong learning setting, addressing the catastrophic forgetting issue,
maintaining their plasticity, and improving zero-shot generalization ability.

</details>


### [19] [UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios](https://arxiv.org/abs/2509.21766)
*Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen*

Main category: cs.AI

TL;DR: 提出了UltraHorzion基准测试，用于评估智能体在长视野、部分可观测场景下的持续推理、规划、记忆管理和工具使用能力，填补现有基准测试的空白。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注短视野、完全可观测任务，而现实世界中的关键任务（如软件开发、投资、科学发现）往往是长视野、部分可观测的，需要持续推理和规划能力。

Method: 通过探索任务在三个不同环境中验证核心能力，设计了长视野发现任务，智能体需要通过持续推理、规划、记忆和工具管理来迭代发现隐藏规则。

Result: 实验显示LLM智能体在这些设置下表现不佳，而人类参与者得分更高，表明智能体在长视野能力上存在持续差距。简单扩展方法在任务中失败，分析识别出8类错误，归因于上下文锁定和功能基础能力差距。

Conclusion: UltraHorzion基准测试揭示了当前智能体在长视野任务中的局限性，为改进智能体的持续推理和规划能力提供了重要评估框架。

Abstract: Autonomous agents have recently achieved remarkable progress across diverse
domains, yet most evaluations focus on short-horizon, fully observable tasks.
In contrast, many critical real-world tasks, such as large-scale software
development, commercial investment, and scientific discovery, unfold in
long-horizon and partially observable scenarios where success hinges on
sustained reasoning, planning, memory management, and tool use. Existing
benchmarks rarely capture these long-horizon challenges, leaving a gap in
systematic evaluation. To bridge this gap, we introduce \textbf{UltraHorizon} a
novel benchmark that measures the foundational capabilities essential for
complex real-world challenges. We use exploration as a unifying task across
three distinct environments to validate these core competencies. Agents are
designed in long-horizon discovery tasks where they must iteratively uncover
hidden rules through sustained reasoning, planning, memory and tools
management, and interaction with environments. Under the heaviest scale
setting, trajectories average \textbf{200k+} tokens and \textbf{400+} tool
calls, whereas in standard configurations they still exceed \textbf{35k} tokens
and involve more than \textbf{60} tool calls on average. Our extensive
experiments reveal that LLM-agents consistently underperform in these settings,
whereas human participants achieve higher scores, underscoring a persistent gap
in agents' long-horizon abilities. We also observe that simple scaling fails in
our task. To better illustrate the failure of agents, we conduct an in-depth
analysis of collected trajectories. We identify eight types of errors and
attribute them to two primary causes: in-context locking and functional
fundamental capability gaps.
\href{https://github.com/StarDewXXX/UltraHorizon}{Our code will be available
here.}

</details>


### [20] [Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety](https://arxiv.org/abs/2509.21782)
*Junliang Liu,Jingyu Xiao,Wenxin Tang,Wenxuan Wang,Zhixian Wang,Minrui Zhang,Shuanghe Yu*

Main category: cs.AI

TL;DR: 提出了WebRSSBench基准测试，用于全面评估多模态大语言模型在网页理解中的推理、鲁棒性和安全性能力，填补了现有基准在这三方面评估不足的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型基准主要关注视觉感知或UI代码生成，缺乏对构建端到端网页应用所需的推理、鲁棒性和安全性能力的全面评估。

Method: 从729个网站构建包含3799个问答对的基准，涵盖8个任务类型，采用标准化提示、确定性评估脚本和结合自动检查与人工验证的多阶段质量控制。

Result: 评估了12个MLLM模型，结果显示模型在真实布局的组合推理、面对UI扰动时的鲁棒性以及识别安全关键操作方面仍存在显著差距。

Conclusion: WebRSSBench揭示了当前MLLM在网页理解任务中的关键局限性，为未来模型改进提供了重要基准和方向。

Abstract: Multimodal large language models (MLLMs) are increasingly positioned as AI
collaborators for building complex web-related applications like GUI agents and
front-end code generation. However, existing benchmarks largely emphasize
visual perception or UI code generation, showing insufficient evaluation on the
reasoning, robustness and safety capability required for end-to-end web
applications. To bridge the gap, we introduce a comprehensive web understanding
benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and
Safety across eight tasks, such as position relationship reasoning, color
robustness, and safety critical detection, etc. The benchmark is constructed
from 729 websites and contains 3799 question answer pairs that probe multi-step
inference over page structure, text, widgets, and safety-critical interactions.
To ensure reliable measurement, we adopt standardized prompts, deterministic
evaluation scripts, and multi-stage quality control combining automatic checks
with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The
results reveal significant gaps, models still struggle with compositional and
cross-element reasoning over realistic layouts, show limited robustness when
facing perturbations in user interfaces and content such as layout
rearrangements or visual style shifts, and are rather conservative in
recognizing and avoiding safety critical or irreversible actions. Our code is
available at https://github.com/jinliang-byte/webssrbench.

</details>


### [21] [D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents](https://arxiv.org/abs/2509.21799)
*Hongze Mi,Yibo Feng,Wenjie Lu,Yuqi Wang,Jinyuan Li,Song Cao,He Cui,Tengfei Tian,Xuelin Zhang,Haotian Luo,Di Sun,Naiqiang Tan,Gang Pan*

Main category: cs.AI

TL;DR: D-Artemis是一个基于人类认知循环（思考、对齐、反思）的GUI代理框架，通过细粒度提示检索、预执行对齐和状态反思来提高任务执行成功率，无需复杂轨迹数据集训练。


<details>
  <summary>Details</summary>
Motivation: 解决当前GUI代理面临的数据瓶颈、延迟错误检测成本高和矛盾指导风险等关键挑战，模仿人类认知过程来提升代理性能。

Method: 采用三阶段认知循环：1）细粒度应用特定提示检索；2）预执行对齐（包含思想-行动一致性检查和行动校正）；3）状态反思代理进行经验学习。

Result: 在两个主要基准测试中达到SOTA：AndroidWorld上75.8%成功率，ScreenSpot-V2上96.8%成功率。消融研究显示各组件均有显著贡献。

Conclusion: D-Artemis框架成功提升了通用多模态大语言模型在GUI任务上的能力，无需复杂轨迹训练，展示了强大的泛化性能。

Abstract: Graphical User Interface (GUI) agents aim to automate a wide spectrum of
human tasks by emulating user interaction. Despite rapid advancements, current
approaches are hindered by several critical challenges: data bottleneck in
end-to-end training, high cost of delayed error detection, and risk of
contradictory guidance. Inspired by the human cognitive loop of Thinking,
Alignment, and Reflection, we present D-Artemis -- a novel deliberative
framework in this paper. D-Artemis leverages a fine-grained, app-specific tip
retrieval mechanism to inform its decision-making process. It also employs a
proactive Pre-execution Alignment stage, where Thought-Action Consistency (TAC)
Check module and Action Correction Agent (ACA) work in concert to mitigate the
risk of execution failures. A post-execution Status Reflection Agent (SRA)
completes the cognitive loop, enabling strategic learning from experience.
Crucially, D-Artemis enhances the capabilities of general-purpose Multimodal
large language models (MLLMs) for GUI tasks without the need for training on
complex trajectory datasets, demonstrating strong generalization. D-Artemis
establishes new state-of-the-art (SOTA) results across both major benchmarks,
achieving a 75.8% success rate on AndroidWorld and 96.8% on ScreenSpot-V2.
Extensive ablation studies further demonstrate the significant contribution of
each component to the framework.

</details>


### [22] [ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration](https://arxiv.org/abs/2509.21823)
*Gaole Dai,Shiqi Jiang,Ting Cao,Yuqing Yang,Yuanchun Li,Rui Tan,Mo Li,Lili Qiu*

Main category: cs.AI

TL;DR: ProRe是一个主动奖励系统，通过通用推理器和领域特定评估器主动与环境交互来改进GUI智能体的奖励评估准确性


<details>
  <summary>Details</summary>
Motivation: 现有基于规则或模型的奖励方法难以泛化到GUI智能体，因为缺乏真实轨迹或应用数据库，而基于轨迹的LLM评估方法精度有限

Method: 使用通用推理器调度目标状态探测任务，领域特定评估器通过主动与环境交互收集额外观测，使推理器能够分配更准确可验证的奖励

Result: 在3000多个轨迹上的实验显示，ProRe将奖励准确率和F1分数分别提升5.3%和19.4%，与最先进策略智能体集成后成功率提升22.4%

Conclusion: ProRe通过主动环境交互显著提高了GUI智能体的奖励评估准确性，为训练和评估提供了更可靠的奖励信号

Abstract: Reward is critical to the evaluation and training of large language models
(LLMs). However, existing rule-based or model-based reward methods struggle to
generalize to GUI agents, where access to ground-truth trajectories or
application databases is often unavailable, and static trajectory-based
LLM-as-a-Judge approaches suffer from limited accuracy. To address these
challenges, we propose ProRe, a proactive reward system that leverages a
general-purpose reasoner and domain-specific evaluator agents (actors). The
reasoner schedules targeted state probing tasks, which the evaluator agents
then execute by actively interacting with the environment to collect additional
observations. This enables the reasoner to assign more accurate and verifiable
rewards to GUI agents. Empirical results on over 3K trajectories demonstrate
that ProRe improves reward accuracy and F1 score by up to 5.3% and 19.4%,
respectively. Furthermore, integrating ProRe with state-of-the-art policy
agents yields a success rate improvement of up to 22.4%.

</details>


### [23] [DS-STAR: Data Science Agent via Iterative Planning and Verification](https://arxiv.org/abs/2509.21825)
*Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Tomas Pfister*

Main category: cs.AI

TL;DR: DS-STAR是一个新型数据科学智能体，通过自动数据文件分析、LLM验证步骤和顺序规划机制，解决LLM在异构数据格式分析和计划验证方面的局限性，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 数据科学任务复杂且涉及多源数据探索，但现有LLM在处理异构数据格式和验证分析计划充分性方面存在困难，需要更可靠的数据分析自动化方法。

Method: 提出DS-STAR数据科学智能体，包含三个核心组件：(1)自动探索和提取多种数据格式上下文的数据文件分析模块；(2)LLM验证器评估各阶段分析计划充分性；(3)从简单可执行计划开始，基于反馈迭代优化的顺序规划机制。

Result: 在DABStep、KramaBench和DA-Code三个挑战性基准测试中达到最先进性能，特别在处理多文件异构格式的困难任务上显著优于基线方法。

Conclusion: DS-STAR通过迭代验证和规划机制，能够可靠地导航涉及多样化数据源的复杂分析任务，为数据科学自动化提供了有效解决方案。

Abstract: Data science, which transforms raw data into actionable insights, is critical
for data-driven decision-making. However, these tasks are often complex,
involving steps for exploring multiple data sources and synthesizing findings
to deliver insightful answers. While large language models (LLMs) show
significant promise in automating this process, they often struggle with
heterogeneous data formats and generate sub-optimal analysis plans, as
verifying plan sufficiency is inherently difficult without ground-truth labels
for such open-ended tasks. To overcome these limitations, we introduce DS-STAR,
a novel data science agent. Specifically, DS-STAR makes three key
contributions: (1) a data file analysis module that automatically explores and
extracts context from diverse data formats, including unstructured types; (2) a
verification step where an LLM-based judge evaluates the sufficiency of the
analysis plan at each stage; and (3) a sequential planning mechanism that
starts with a simple, executable plan and iteratively refines it based on the
DS-STAR's feedback until its sufficiency is verified. This iterative refinement
allows DS-STAR to reliably navigate complex analyses involving diverse data
sources. Our experiments show that DS-STAR achieves state-of-the-art
performance across three challenging benchmarks: DABStep, KramaBench, and
DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks
that require processing multiple data files with heterogeneous formats.

</details>


### [24] [Axiomatic Choice and the Decision-Evaluation Paradox](https://arxiv.org/abs/2509.21836)
*Ben Abramowitz,Nicholas Mattei*

Main category: cs.AI

TL;DR: 本文提出了一个基于公理的决策建模框架，揭示了决策-评估悖论，并指出在训练决策模型和应用公理时需要格外谨慎。


<details>
  <summary>Details</summary>
Motivation: 研究决策公理（如伦理约束）在决策建模中的作用，探索公理在制定决策和评估决策时的潜在冲突。

Method: 引入基于公理的决策建模框架，根据结构特性定义决策公理分类法，分析决策-评估悖论。

Result: 发现决策-评估悖论在现实公理结构中普遍存在，揭示了使用公理制定决策与评估决策之间的内在张力。

Conclusion: 在基于决策数据训练模型或应用公理进行决策和评估时，必须格外谨慎以避免决策-评估悖论带来的问题。

Abstract: We introduce a framework for modeling decisions with axioms that are
statements about decisions, e.g., ethical constraints. Using our framework we
define a taxonomy of decision axioms based on their structural properties and
demonstrate a tension between the use of axioms to make decisions and the use
of axioms to evaluate decisions which we call the Decision-Evaluation Paradox.
We argue that the Decision-Evaluation Paradox arises with realistic axiom
structures, and the paradox illuminates why one must be exceptionally careful
when training models on decision data or applying axioms to make and evaluate
decisions.

</details>


### [25] [DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents](https://arxiv.org/abs/2509.21842)
*Yansong Ning,Rui Liu,Jun Wang,Kai Chen,Wei Li,Jun Fang,Kan Zheng,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: DeepTravel是一个端到端的强化学习框架，用于构建自主旅行规划代理，能够自主规划、执行工具并反思工具响应，在多步推理中探索、验证和优化中间行动。


<details>
  <summary>Details</summary>
Motivation: 现有旅行规划代理依赖手工制作的提示和固定的代理工作流程，限制了代理的灵活性和自主性。

Method: 构建沙盒环境缓存交通、住宿和POI数据；开发分层奖励建模系统，包括轨迹级验证器和回合级验证器；提出回复增强的强化学习方法，从失败经验缓冲区定期重放。

Result: 在滴滴企业解决方案App上部署的DeepTravel使小型LLM（如Qwen3 32B）在旅行规划任务中显著优于OpenAI o1、o3和DeepSeek R1等前沿LLM。

Conclusion: DeepTravel框架能够构建自主的旅行规划代理，通过强化学习提升代理能力，使小型模型在特定任务上超越大型前沿模型。

Abstract: Travel planning (TP) agent has recently worked as an emerging building block
to interact with external tools and resources for travel itinerary generation,
ensuring enjoyable user experience. Despite its benefits, existing studies rely
on hand craft prompt and fixed agent workflow, hindering more flexible and
autonomous TP agent. This paper proposes DeepTravel, an end to end agentic
reinforcement learning framework for building autonomous travel planning agent,
capable of autonomously planning, executing tools, and reflecting on tool
responses to explore, verify, and refine intermediate actions in multi step
reasoning. To achieve this, we first construct a robust sandbox environment by
caching transportation, accommodation and POI data, facilitating TP agent
training without being constrained by real world APIs limitations (e.g.,
inconsistent outputs). Moreover, we develop a hierarchical reward modeling
system, where a trajectory level verifier first checks spatiotemporal
feasibility and filters unsatisfied travel itinerary, and then the turn level
verifier further validate itinerary detail consistency with tool responses,
enabling efficient and precise reward service. Finally, we propose the reply
augmented reinforcement learning method that enables TP agent to periodically
replay from a failures experience buffer, emerging notable agentic capacity. We
deploy trained TP agent on DiDi Enterprise Solutions App and conduct
comprehensive online and offline evaluations, demonstrating that DeepTravel
enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing
frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.

</details>


### [26] [Reimagining Agent-based Modeling with Large Language Model Agents via Shachi](https://arxiv.org/abs/2509.21862)
*So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang*

Main category: cs.AI

TL;DR: Shachi是一个用于研究LLM驱动多智能体系统涌现行为的模块化框架，将智能体策略分解为配置、记忆和工具三个核心认知组件，通过系统化实验方法分析架构选择对集体行为的影响。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于控制实验的原则性方法来研究大型语言模型驱动的多智能体系统中的涌现行为，限制了该领域的研究进展。

Method: 提出Shachi框架，将智能体策略分解为配置（内在特性）、记忆（上下文持久性）和工具（扩展能力）三个核心认知组件，由LLM推理引擎协调。

Result: 在10个任务的基准测试中验证了该方法的有效性，通过模拟美国关税冲击实验表明，只有当智能体的认知架构正确配置记忆和工具时，其行为才能与观察到的市场反应保持一致。

Conclusion: 该工作为构建和评估LLM智能体提供了严谨的开源基础，旨在促进更具累积性和科学依据的研究。

Abstract: The study of emergent behaviors in large language model (LLM)-driven
multi-agent systems is a critical research challenge, yet progress is limited
by a lack of principled methodologies for controlled experimentation. To
address this, we introduce Shachi, a formal methodology and modular framework
that decomposes an agent's policy into core cognitive components: Configuration
for intrinsic traits, Memory for contextual persistence, and Tools for expanded
capabilities, all orchestrated by an LLM reasoning engine. This principled
architecture moves beyond brittle, ad-hoc agent designs and enables the
systematic analysis of how specific architectural choices influence collective
behavior. We validate our methodology on a comprehensive 10-task benchmark and
demonstrate its power through novel scientific inquiries. Critically, we
establish the external validity of our approach by modeling a real-world U.S.
tariff shock, showing that agent behaviors align with observed market reactions
only when their cognitive architecture is appropriately configured with memory
and tools. Our work provides a rigorous, open-source foundation for building
and evaluating LLM agents, aimed at fostering more cumulative and
scientifically grounded research.

</details>


### [27] [TRACE: Learning to Compute on Graphs](https://arxiv.org/abs/2509.21886)
*Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu*

Main category: cs.AI

TL;DR: TRACE提出了一种新的图表示学习范式，通过层次化Transformer架构和函数偏移学习目标，解决了传统消息传递神经网络在计算图建模中的架构不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递神经网络及其Transformer变体存在架构不匹配问题，无法捕捉计算的位置感知和层次化特性，限制了模型对计算图功能行为的建模能力。

Method: 1. 使用层次化Transformer架构，模拟逐步计算流程，替代有缺陷的置换不变聚合；2. 引入函数偏移学习目标，通过预测真实全局函数与简单局部近似之间的差异来解耦学习问题。

Result: 在电子电路这一复杂且经济关键的计算图类别上，TRACE在全面的基准测试中显著优于所有先前架构。

Conclusion: 架构对齐的主干网络和解耦学习目标构成了更稳健的图计算学习范式，为解决学习计算这一基础挑战提供了有效方案。

Abstract: Learning to compute, the ability to model the functional behavior of a
computational graph, is a fundamental challenge for graph representation
learning. Yet, the dominant paradigm is architecturally mismatched for this
task. This flawed assumption, central to mainstream message passing neural
networks (MPNNs) and their conventional Transformer-based counterparts,
prevents models from capturing the position-aware, hierarchical nature of
computation. To resolve this, we introduce \textbf{TRACE}, a new paradigm built
on an architecturally sound backbone and a principled learning objective.
First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step
flow of computation, providing a faithful architectural backbone that replaces
the flawed permutation-invariant aggregation. Second, we introduce
\textbf{function shift learning}, a novel objective that decouples the learning
problem. Instead of predicting the complex global function directly, our model
is trained to predict only the \textit{function shift}, the discrepancy between
the true global function and a simple local approximation that assumes input
independence. We validate this paradigm on electronic circuits, one of the most
complex and economically critical classes of computational graphs. Across a
comprehensive suite of benchmarks, TRACE substantially outperforms all prior
architectures. These results demonstrate that our architecturally-aligned
backbone and decoupled learning objective form a more robust paradigm for the
fundamental challenge of learning to compute on graphs.

</details>


### [28] [GenesisGeo: Technical Report](https://arxiv.org/abs/2509.21896)
*Minfeng Zhu,Zi Wang,Sizhe Ji,Zhengtong Du,Junming Ke,Xiao Deng,Zanlang Yin,Xiuqi Huang,Heyu Wang,Wei Chen*

Main category: cs.AI

TL;DR: GenesisGeo是一个自动几何定理证明器，包含2180万几何问题数据集，通过定理匹配将符号推理引擎DDARN加速120倍，基于Qwen3-0.6B-Base的神经符号证明器在IMO-AG-30基准上达到银牌水平，双模型集成达到金牌水平。


<details>
  <summary>Details</summary>
Motivation: 解决几何定理自动证明中的效率问题，特别是符号推理引擎的速度瓶颈，以及提升几何问题求解的准确性和规模。

Method: 1) 开源2180万几何问题数据集，其中300万包含辅助构造；2) 通过定理匹配和C++核心组件实现，将DDARN符号推理引擎加速120倍；3) 基于Qwen3-0.6B-Base构建神经符号证明器GenesisGeo；4) 使用单模型和双模型集成策略。

Result: 1) 单模型在IMO-AG-30基准上解决24/30问题（IMO银牌水平）；2) 双模型集成解决26/30问题（IMO金牌水平）；3) 符号推理引擎DDARN加速120倍。

Conclusion: GenesisGeo通过大规模数据集、高效符号推理引擎和神经符号方法，在几何定理证明领域达到了国际数学奥林匹克竞赛金牌级别的性能。

Abstract: We present GenesisGeo, an automated theorem prover in Euclidean geometry. We
have open-sourced a large-scale geometry dataset of 21.8 million geometric
problems, over 3 million of which contain auxiliary constructions. Specially,
we significantly accelerate the symbolic deduction engine DDARN by 120x through
theorem matching, combined with a C++ implementation of its core components.
Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon
Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the
IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold
medal level) with a dual-model ensemble.

</details>


### [29] [DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling](https://arxiv.org/abs/2509.21902)
*Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang*

Main category: cs.AI

TL;DR: 提出了DyRo-MCTS方法，将动作鲁棒性估计集成到MCTS中，用于动态作业车间调度问题，显著提升离线学习策略的性能


<details>
  <summary>Details</summary>
Motivation: 动态作业车间调度面临新作业频繁到达的干扰，现有离线学习策略不完美，而在线规划又因问题信息不完整而容易受到扰动影响

Method: DyRo-MCTS方法，在MCTS中集成动作鲁棒性估计，引导生产环境达到既产生良好调度结果又易于适应未来作业到达的状态

Result: 实验表明DyRo-MCTS显著提升离线学习策略性能，在线规划时间增加可忽略，在各种调度场景中始终优于标准MCTS

Conclusion: DyRo-MCTS通过做出鲁棒调度决策，在扰动下实现长期可持续的性能提升

Abstract: Dynamic job shop scheduling, a fundamental combinatorial optimisation problem
in various industrial sectors, poses substantial challenges for effective
scheduling due to frequent disruptions caused by the arrival of new jobs.
State-of-the-art methods employ machine learning to learn scheduling policies
offline, enabling rapid responses to dynamic events. However, these offline
policies are often imperfect, necessitating the use of planning techniques such
as Monte Carlo Tree Search (MCTS) to improve performance at online decision
time. The unpredictability of new job arrivals complicates online planning, as
decisions based on incomplete problem information are vulnerable to
disturbances. To address this issue, we propose the Dynamic Robust MCTS
(DyRo-MCTS) approach, which integrates action robustness estimation into MCTS.
DyRo-MCTS guides the production environment toward states that not only yield
good scheduling outcomes but are also easily adaptable to future job arrivals.
Extensive experiments show that DyRo-MCTS significantly improves the
performance of offline-learned policies with negligible additional online
planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across
various scheduling scenarios. Further analysis reveals that its ability to make
robust scheduling decisions leads to long-term, sustainable performance gains
under disturbances.

</details>


### [30] [Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning](https://arxiv.org/abs/2509.21943)
*Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich*

Main category: cs.AI

TL;DR: 本研究比较了统计参数映射(SPM)和可解释机器学习方法在足底压力数据异常检测中的表现，发现机器学习模型在准确性上优于SPM，而两种方法在可解释性方面都获得了专家的认可。


<details>
  <summary>Details</summary>
Motivation: 足底压力映射在临床诊断和运动科学中很重要，但大型异构数据集常包含技术错误或程序不一致导致的异常值。SPM提供可解释分析但对对齐敏感，其鲁棒异常检测能力尚不明确。

Method: 使用来自多个中心的数据，通过专家共识标注并添加合成异常，共798个有效样本和2000个异常值。评估了(i)非参数、配准依赖的SPM方法和(ii)使用SHAP解释的卷积神经网络(CNN)。通过嵌套交叉验证评估性能，通过语义差异调查评估解释质量。

Result: 机器学习模型达到高准确率并优于SPM，SPM误分类了临床有意义的变异并遗漏了真实异常。专家认为SPM和SHAP解释都清晰、有用且可信，但SPM被认为复杂度较低。

Conclusion: SPM和可解释机器学习在足底压力数据自动异常检测中具有互补潜力，可解释性在将复杂模型输出转化为可解释见解以有效支持决策方面至关重要。

Abstract: Plantar pressure mapping is essential in clinical diagnostics and sports
science, yet large heterogeneous datasets often contain outliers from technical
errors or procedural inconsistencies. Statistical Parametric Mapping (SPM)
provides interpretable analyses but is sensitive to alignment and its capacity
for robust outlier detection remains unclear. This study compares an SPM
approach with an explainable machine learning (ML) approach to establish
transparent quality-control pipelines for plantar pressure datasets. Data from
multiple centers were annotated by expert consensus and enriched with synthetic
anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a
non-parametric, registration-dependent SPM approach and (ii) a convolutional
neural network (CNN), explained using SHapley Additive exPlanations (SHAP).
Performance was assessed via nested cross-validation; explanation quality via a
semantic differential survey with domain experts. The ML model reached high
accuracy and outperformed SPM, which misclassified clinically meaningful
variations and missed true outliers. Experts perceived both SPM and SHAP
explanations as clear, useful, and trustworthy, though SPM was assessed less
complex. These findings highlight the complementary potential of SPM and
explainable ML as approaches for automated outlier detection in plantar
pressure data, and underscore the importance of explainability in translating
complex model outputs into interpretable insights that can effectively inform
decision-making.

</details>


### [31] [CoBel-World: Harnessing LLM Reasoning to Build a Collaborative Belief World for Optimizing Embodied Multi-Agent Collaboration](https://arxiv.org/abs/2509.21981)
*Zhimin Wang,Shaokang He,Duo Wu,Jinghe Wang,Linjia Kang,Jing Yu,Zhi Wang*

Main category: cs.AI

TL;DR: 提出了CoBel-World框架，通过为LLM智能体配备协作信念世界来建模物理环境和协作伙伴的心理状态，显著减少了通信成本并提高了任务完成效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM协作框架忽视了动态意图推理的潜力，导致计划不一致和冗余通信，降低了协作效率。

Method: CoBel-World框架使用符号信念语言将开放世界任务知识解析为结构化信念，并通过LLM推理执行零样本贝叶斯式信念更新，使智能体能够主动检测潜在的不协调并自适应通信。

Result: 在TDW-MAT和C-WAH基准测试中，CoBel-World相比最强基线显著减少通信成本22-60%，提高任务完成效率4-28%。

Conclusion: 显式的、意图感知的信念建模对于基于LLM的多智能体系统中实现高效、类人协作至关重要。

Abstract: Effective real-world multi-agent collaboration requires not only accurate
planning but also the ability to reason about collaborators' intents -- a
crucial capability for avoiding miscoordination and redundant communication
under partial observable environments. Due to their strong planning and
reasoning capabilities, large language models (LLMs) have emerged as promising
autonomous agents for collaborative task solving. However, existing
collaboration frameworks for LLMs overlook their reasoning potential for
dynamic intent inference, and thus produce inconsistent plans and redundant
communication, reducing collaboration efficiency. To bridge this gap, we
propose CoBel-World, a novel framework that equips LLM agents with a
collaborative belief world -- an internal representation jointly modeling the
physical environment and collaborators' mental states. CoBel-World enables
agents to parse open-world task knowledge into structured beliefs via a
symbolic belief language, and perform zero-shot Bayesian-style belief updates
through LLM reasoning. This allows agents to proactively detect potential
miscoordination (e.g., conflicting plans) and communicate adaptively. Evaluated
on challenging embodied benchmarks (i.e., TDW-MAT and C-WAH), CoBel-World
significantly reduces communication costs by 22-60% and improves task
completion efficiency by 4-28% compared to the strongest baseline. Our results
show that explicit, intent-aware belief modeling is essential for efficient and
human-like collaboration in LLM-based multi-agent systems.

</details>


### [32] [RISK: A Framework for GUI Agents in E-commerce Risk Management](https://arxiv.org/abs/2509.21982)
*Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen*

Main category: cs.AI

TL;DR: RISK是一个用于电子商务风险管理的GUI代理框架，包含数据集、基准测试和强化微调框架，在单步和多步交互任务中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统爬虫方法和现有GUI代理无法处理电子商务风险管理中需要多步状态交互的动态内容，需要专门解决方案。

Method: RISK框架包含三个组件：RISK-Data数据集、RISK-Bench基准测试和RISK-R1强化微调框架，后者采用四方面优化：输出格式、单步级、多步级和任务级奖励机制。

Result: RISK-R1在离线单步任务中提升6.8%，离线多步任务中提升8.8%，在线评估中达到70.5%的最高任务成功率。

Conclusion: RISK为自动化复杂Web交互提供了可扩展的领域特定解决方案，推动了电子商务风险管理的技术进步。

Abstract: E-commerce risk management requires aggregating diverse, deeply embedded web
data through multi-step, stateful interactions, which traditional scraping
methods and most existing Graphical User Interface (GUI) agents cannot handle.
These agents are typically limited to single-step tasks and lack the ability to
manage dynamic, interactive content critical for effective risk assessment. To
address this challenge, we introduce RISK, a novel framework designed to build
and deploy GUI agents for this domain. RISK integrates three components: (1)
RISK-Data, a dataset of 8,492 single-step and 2,386 multi-step interaction
trajectories, collected through a high-fidelity browser framework and a
meticulous data curation process; (2) RISK-Bench, a benchmark with 802
single-step and 320 multi-step trajectories across three difficulty levels for
standardized evaluation; and (3) RISK-R1, a R1-style reinforcement fine-tuning
framework considering four aspects: (i) Output Format: Updated format reward to
enhance output syntactic correctness and task comprehension, (ii) Single-step
Level: Stepwise accuracy reward to provide granular feedback during early
training stages, (iii) Multi-step Level: Process reweight to emphasize critical
later steps in interaction sequences, and (iv) Task Level: Level reweight to
focus on tasks of varying difficulty. Experiments show that RISK-R1 outperforms
existing baselines, achieving a 6.8% improvement in offline single-step and an
8.8% improvement in offline multi-step. Moreover, it attains a top task success
rate of 70.5% in online evaluation. RISK provides a scalable, domain-specific
solution for automating complex web interactions, advancing the state of the
art in e-commerce risk management.

</details>


### [33] [Bilinear relational structure fixes reversal curse and enables consistent model editing](https://arxiv.org/abs/2509.21993)
*Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha*

Main category: cs.AI

TL;DR: 该论文发现语言模型中的反转诅咒不是固有缺陷，而是知识编码方式的产物。通过训练具有双线性关系结构的模型，可以显著缓解反转诅咒，并实现一致的模型编辑。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型反转诅咒的根本原因，探索模型内部知识表示如何影响逻辑推理能力和编辑一致性。

Method: 在关系知识图谱合成数据集上从头训练语言模型，分析其隐藏表示中出现的双线性关系结构。

Result: 具有双线性结构的模型能够推断未见过的反向事实，并在模型编辑时正确传播到相关事实，而缺乏这种结构的模型则无法实现逻辑一致的编辑。

Conclusion: 模型编辑的成功不仅取决于编辑算法，更关键的是被修改知识的底层表示几何结构。关系知识训练诱导的双线性内部表示使语言模型能够以逻辑一致的方式运行。

Abstract: The reversal curse -- a language model's (LM) inability to infer an unseen
fact ``B is A'' from a learned fact ``A is B'' -- is widely considered a
fundamental limitation. We show that this is not an inherent failure but an
artifact of how models encode knowledge. By training LMs from scratch on a
synthetic dataset of relational knowledge graphs, we demonstrate that bilinear
relational structure emerges in their hidden representations. This structure
substantially alleviates the reversal curse, enabling LMs to infer unseen
reverse facts. Crucially, we also find that this bilinear structure plays a key
role in consistent model editing. When a fact is updated in a LM with this
structure, the edit correctly propagates to its reverse and other logically
dependent facts. In contrast, models lacking this representation not only
suffer from the reversal curse but also fail to generalize edits, further
introducing logical inconsistencies. Our results establish that training on a
relational knowledge dataset induces the emergence of bilinear internal
representations, which in turn enable LMs to behave in a logically consistent
manner after editing. This implies that the success of model editing depends
critically not just on editing algorithms but on the underlying
representational geometry of the knowledge being modified.

</details>


### [34] [GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments](https://arxiv.org/abs/2509.21998)
*Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao*

Main category: cs.AI

TL;DR: 提出了GSM-Agent基准测试，用于评估LLM在需要主动使用工具收集信息来解决小学数学问题时的代理推理能力，并发现前沿模型准确率仅67%。提出了代理推理图概念和工具增强的测试时扩展方法来改进性能。


<details>
  <summary>Details</summary>
Motivation: 当前代理基准测试往往将代理推理与复杂的数学推理、专家级知识等能力混在一起，难以分离评估纯粹的代理推理能力。需要专门评估LLM结合工具使用和推理的能力。

Method: 构建GSM-Agent基准测试，要求LLM代理解决小学数学问题但只提供问题而不提供前提信息，需要主动使用工具收集信息。提出代理推理图概念来分析和可视化推理模式，并开发工具增强的测试时扩展方法。

Result: 即使像GPT-5这样的前沿模型在GSM-Agent基准测试中也仅达到67%准确率。分析发现许多模型在代理推理中缺乏重新访问先前节点的能力，这是静态推理中的关键模式。

Conclusion: GSM-Agent基准测试和代理推理框架有助于未来理解和推进代理推理边界的研究，工具增强方法能够有效改进LLM的代理推理性能。

Abstract: As LLMs are increasingly deployed as agents, agentic reasoning - the ability
to combine tool use, especially search, and reasoning - becomes a critical
skill. However, it is hard to disentangle agentic reasoning when evaluated in
complex environments and tasks. Current agent benchmarks often mix agentic
reasoning with challenging math reasoning, expert-level knowledge, and other
advanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent,
where an LLM agent is required to solve grade-school-level reasoning problems,
but is only presented with the question in the prompt without the premises that
contain the necessary information to solve the task, and needs to proactively
collect that information using tools. Although the original tasks are
grade-school math problems, we observe that even frontier models like GPT-5
only achieve 67% accuracy. To understand and analyze the agentic reasoning
patterns, we propose the concept of agentic reasoning graph: cluster the
environment's document embeddings into nodes, and map each tool call to its
nearest node to build a reasoning path. Surprisingly, we identify that the
ability to revisit a previously visited node, widely taken as a crucial pattern
in static reasoning, is often missing for agentic reasoning for many models.
Based on the insight, we propose a tool-augmented test-time scaling method to
improve LLM's agentic reasoning performance by adding tools to encourage models
to revisit. We expect our benchmark and the agentic reasoning framework to aid
future studies of understanding and pushing the boundaries of agentic
reasoning.

</details>


### [35] [The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging](https://arxiv.org/abs/2509.22034)
*Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li*

Main category: cs.AI

TL;DR: 本文通过大规模实证研究评估了多种模型融合技术，发现模型融合能够有效调控推理精度与计算成本之间的权衡，甚至在某些情况下实现帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 现实应用中对可调节推理能力的大语言模型需求日益增长，需要能够高效产生平衡推理深度和计算成本的模型谱系的方法。

Method: 使用多种模型融合技术，系统性地改变融合强度来构建精度-效率曲线，评估不同融合方法在多个推理基准上的表现。

Result: 模型融合提供了一种有效且可控的方法来校准推理精度与标记效率之间的权衡，即使父模型具有高度不同的权重空间。在某些情况下实现了帕累托改进，即融合模型同时获得更高精度和更低标记消耗。

Conclusion: 模型融合是创建具有特定推理配置文件的LLM以满足多样化应用需求的实用方法，本研究首次全面分析了这一可调空间。

Abstract: The growing demand for large language models (LLMs) with tunable reasoning
capabilities in many real-world applications highlights a critical need for
methods that can efficiently produce a spectrum of models balancing reasoning
depth and computational cost. Model merging has emerged as a promising,
training-free technique to address this challenge by arithmetically combining
the weights of a general-purpose model with a specialized reasoning model.
While various merging techniques exist, their potential to create a spectrum of
models with fine-grained control over reasoning abilities remains largely
unexplored. This work presents a large-scale empirical study evaluating a range
of model merging techniques across multiple reasoning benchmarks. We
systematically vary merging strengths to construct accuracy-efficiency curves,
providing the first comprehensive view of the tunable performance landscape.
Our findings reveal that model merging offers an effective and controllable
method for calibrating the trade-off between reasoning accuracy and token
efficiency, even when parent models have highly divergent weight spaces.
Crucially, we identify instances of Pareto Improvement, where a merged model
achieves both higher accuracy and lower token consumption than one of its
parents. Our study provides the first comprehensive analysis of this tunable
space, offering practical guidelines for creating LLMs with specific reasoning
profiles to meet diverse application demands.

</details>


### [36] [A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning](https://arxiv.org/abs/2509.22044)
*Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen*

Main category: cs.AI

TL;DR: A2R是一个非对称两阶段推理框架，通过探索器并行生成多个解决方案，再由合成器进行整合，显著提升模型在复杂任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在单次尝试中的表现与其潜在能力之间的差距，这种差距通常需要多个解决方案路径才能显现。

Method: 采用两阶段推理框架：探索器模型通过重复采样并行生成潜在解决方案，合成器模型整合这些参考进行更精细的第二阶段推理。

Result: Qwen3-8B-distill模型在使用A2R框架后，相比自一致性基线实现了75%的性能提升；A2R-Efficient变体（Qwen3-4B探索器+Qwen3-8B合成器）在成本降低30%的情况下超越了单体Qwen3-32B模型的平均性能。

Conclusion: A2R不仅是一个性能提升框架，还是现实应用中高效实用的解决方案，能够正交扩展计算能力。

Abstract: Recent Large Reasoning Models have achieved significant improvements in
complex task-solving capabilities by allocating more computation at the
inference stage with a "thinking longer" paradigm. Even as the foundational
reasoning capabilities of models advance rapidly, the persistent gap between a
model's performance in a single attempt and its latent potential, often
revealed only across multiple solution paths, starkly highlights the disparity
between its realized and inherent capabilities. To address this, we present
A2R, an Asymmetric Two-Stage Reasoning framework designed to explicitly bridge
the gap between a model's potential and its actual performance. In this
framework, an "explorer" model first generates potential solutions in parallel
through repeated sampling. Subsequently,a "synthesizer" model integrates these
references for a more refined, second stage of reasoning. This two-stage
process allows computation to be scaled orthogonally to existing sequential
methods. Our work makes two key innovations: First, we present A2R as a
plug-and-play parallel reasoning framework that explicitly enhances a model's
capabilities on complex questions. For example, using our framework, the
Qwen3-8B-distill model achieves a 75% performance improvement compared to its
self-consistency baseline. Second, through a systematic analysis of the
explorer and synthesizer roles, we identify an effective asymmetric scaling
paradigm. This insight leads to A2R-Efficient, a "small-to-big" variant that
combines a Qwen3-4B explorer with a Qwen3-8B synthesizer. This configuration
surpasses the average performance of a monolithic Qwen3-32B model at a nearly
30% lower cost. Collectively, these results show that A2R is not only a
performance-boosting framework but also an efficient and practical solution for
real-world applications.

</details>


### [37] [Generalizing Multi-Objective Search via Objective-Aggregation Functions](https://arxiv.org/abs/2509.22085)
*Hadar Peer,Eyal Weiss,Ron Alterovitz,Oren Salzman*

Main category: cs.AI

TL;DR: 提出了一种广义的多目标搜索问题公式，通过隐藏目标的聚合函数来优化解决方案目标，支持标准多目标搜索算法的应用，在多个机器人规划问题中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人系统需要同时平衡多个往往冲突的目标，但现有复杂目标交互的问题公式无法直接使用现成的先进多目标搜索算法。

Method: 提出广义问题公式，通过隐藏目标的聚合函数优化解决方案目标，只需适当扩展几个核心操作来反映特定的聚合函数。

Result: 在多个机器人规划问题中应用该方法，包括导航、操作、医疗系统规划、检查规划和路线规划，扩展后的算法比原始版本性能提升数个数量级。

Conclusion: 该广义公式支持标准多目标搜索算法的应用，通过适当扩展核心操作，能显著提升算法在复杂机器人规划问题中的性能。

Abstract: Multi-objective search (MOS) has become essential in robotics, as real-world
robotic systems need to simultaneously balance multiple, often conflicting
objectives. Recent works explore complex interactions between objectives,
leading to problem formulations that do not allow the usage of out-of-the-box
state-of-the-art MOS algorithms. In this paper, we suggest a generalized
problem formulation that optimizes solution objectives via aggregation
functions of hidden (search) objectives. We show that our formulation supports
the application of standard MOS algorithms, necessitating only to properly
extend several core operations to reflect the specific aggregation functions
employed. We demonstrate our approach in several diverse robotics planning
problems, spanning motion-planning for navigation, manipulation and planning fr
medical systems under obstacle uncertainty as well as inspection planning, and
route planning with different road types. We solve the problems using
state-of-the-art MOS algorithms after properly extending their core operations,
and provide empirical evidence that they outperform by orders of magnitude the
vanilla versions of the algorithms applied to the same problems but without
objective aggregation.

</details>


### [38] [Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements](https://arxiv.org/abs/2509.22092)
*Raphael Fischer*

Main category: cs.AI

TL;DR: 本研究系统评估了AI模型能耗估算工具的准确性，通过与真实测量数据对比发现现有工具存在高达40%的误差，为可持续AI发展提供了实证依据和改进指南。


<details>
  <summary>Details</summary>
Motivation: 随着AI快速发展带来的环境影响日益显著，现有的能耗估算工具虽然易于使用，但其假设和准确性存在疑问，需要系统验证。

Method: 通过比较静态和动态能耗估算方法与真实测量数据，在数百个AI实验中进行系统性评估，建立了验证框架。

Result: 研究显示现有估算工具虽然能大致反映AI能耗模式，但存在高达40%的持续误差。

Conclusion: 本研究为AI能耗估算工具提供了透明度验证，制定了改进指南，并为资源感知的机器学习和AI可持续性研究做出了重要贡献。

Abstract: Although machine learning (ML) and artificial intelligence (AI) present
fascinating opportunities for innovation, their rapid development is also
significantly impacting our environment. In response to growing
resource-awareness in the field, quantification tools such as the ML Emissions
Calculator and CodeCarbon were developed to estimate the energy consumption and
carbon emissions of running AI models. They are easy to incorporate into AI
projects, however also make pragmatic assumptions and neglect important
factors, raising the question of estimation accuracy. This study systematically
evaluates the reliability of static and dynamic energy estimation approaches
through comparisons with ground-truth measurements across hundreds of AI
experiments. Based on the proposed validation framework, investigative insights
into AI energy demand and estimation inaccuracies are provided. While generally
following the patterns of AI energy consumption, the established estimation
approaches are shown to consistently make errors of up to 40%. By providing
empirical evidence on energy estimation quality and errors, this study
establishes transparency and validates widely used tools for sustainable AI
development. It moreover formulates guidelines for improving the
state-of-the-art and offers code for extending the validation to other domains
and tools, thus making important contributions to resource-aware ML and AI
sustainability research.

</details>


### [39] [Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach](https://arxiv.org/abs/2509.22137)
*Seoyoung Lee,Seonbin Yoon,Seongbeen Lee,Hyesoo Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: Log2Plan是一个结合结构化两级规划框架和用户行为日志任务挖掘的GUI任务自动化系统，解决了现有LLM/VLM规划器在泛化性、延迟和长序列一致性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM或VLM的规划-执行代理存在脆弱的泛化能力、高延迟和有限的长序列一致性，依赖单次推理或静态计划使其在UI变化或复杂任务下表现脆弱。

Method: Log2Plan采用结构化两级规划框架：高层规划将用户命令映射到结构化任务字典，低层规划通过解释实时GUI上下文将高层计划转化为具体动作序列，并结合用户行为日志的任务挖掘方法识别用户特定模式。

Result: 在200个真实世界任务上的评估显示，Log2Plan在任务成功率和执行时间方面有显著提升，即使在长序列任务中也能保持超过60.0%的成功率。

Conclusion: Log2Plan通过结合结构化规划和任务挖掘方法，实现了更鲁棒和适应性强的GUI自动化，特别在复杂多步骤工作流中表现出色。

Abstract: GUI task automation streamlines repetitive tasks, but existing LLM or
VLM-based planner-executor agents suffer from brittle generalization, high
latency, and limited long-horizon coherence. Their reliance on single-shot
reasoning or static plans makes them fragile under UI changes or complex tasks.
Log2Plan addresses these limitations by combining a structured two-level
planning framework with a task mining approach over user behavior logs,
enabling robust and adaptable GUI automation. Log2Plan constructs high-level
plans by mapping user commands to a structured task dictionary, enabling
consistent and generalizable automation. To support personalization and reuse,
it employs a task mining approach from user behavior logs that identifies
user-specific patterns. These high-level plans are then grounded into low-level
action sequences by interpreting real-time GUI context, ensuring robust
execution across varying interfaces. We evaluated Log2Plan on 200 real-world
tasks, demonstrating significant improvements in task success rate and
execution time. Notably, it maintains over 60.0% success rate even on
long-horizon task sequences, highlighting its robustness in complex, multi-step
workflows.

</details>


### [40] [Clinical Uncertainty Impacts Machine Learning Evaluations](https://arxiv.org/abs/2509.22242)
*Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly*

Main category: cs.AI

TL;DR: 论文主张机器学习评估应考虑标注不确定性，使用基于分布的概率度量，而非简单的多数投票等聚合方法，以更准确反映临床数据的真实情况。


<details>
  <summary>Details</summary>
Motivation: 临床数据标注存在不确定性和标注者分歧，传统聚合方法（如多数投票）掩盖了这种变异性，影响模型评估的准确性。

Method: 提出使用概率度量直接处理标注分布，这些度量独立于标注生成过程，计算轻量，具有线性时间复杂度。

Result: 在医学影像基准测试中，考虑二元标签的置信度显著影响模型排名。

Conclusion: 呼吁社区发布原始标注数据并采用不确定性感知评估，使性能估计更好地反映临床数据特性。

Abstract: Clinical dataset labels are rarely certain as annotators disagree and
confidence is not uniform across cases. Typical aggregation procedures, such as
majority voting, obscure this variability. In simple experiments on medical
imaging benchmarks, accounting for the confidence in binary labels
significantly impacts model rankings. We therefore argue that machine-learning
evaluations should explicitly account for annotation uncertainty using
probabilistic metrics that directly operate on distributions. These metrics can
be applied independently of the annotations' generating process, whether
modeled by simple counting, subjective confidence ratings, or probabilistic
response models. They are also computationally lightweight, as closed-form
expressions have linear-time implementations once examples are sorted by model
score. We thus urge the community to release raw annotations for datasets and
to adopt uncertainty-aware evaluation so that performance estimates may better
reflect clinical data.

</details>


### [41] [Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing](https://arxiv.org/abs/2509.22255)
*Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Rajesh Mojumder*

Main category: cs.AI

TL;DR: 本文提出了一个评估LLM在组合优化中能力的框架，专注于2D装箱问题，结合LLM与进化算法迭代生成和优化启发式解。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在专业领域（特别是组合优化问题）中的能力，建立LLM在组合优化任务中的性能基准。

Method: 系统化方法结合LLM与进化算法，迭代生成和优化启发式解决方案，并与传统方法（有限首次适应和混合首次适应）进行比较。

Result: GPT-4o在两次迭代内达到最优解，平均箱数从16减少到15，空间利用率从0.76-0.78提升到0.83，且计算资源需求更少。

Conclusion: LLM能够产生更高效的解决方案，为理解LLM在专业领域的评估和在组合优化中的性能基准提供了重要贡献。

Abstract: This paper presents an evaluation framework for assessing Large Language
Models' (LLMs) capabilities in combinatorial optimization, specifically
addressing the 2D bin-packing problem. We introduce a systematic methodology
that combines LLMs with evolutionary algorithms to generate and refine
heuristic solutions iteratively. Through comprehensive experiments comparing
LLM generated heuristics against traditional approaches (Finite First-Fit and
Hybrid First-Fit), we demonstrate that LLMs can produce more efficient
solutions while requiring fewer computational resources. Our evaluation reveals
that GPT-4o achieves optimal solutions within two iterations, reducing average
bin usage from 16 to 15 bins while improving space utilization from 0.76-0.78
to 0.83. This work contributes to understanding LLM evaluation in specialized
domains and establishes benchmarks for assessing LLM performance in
combinatorial optimization tasks.

</details>


### [42] [InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.22261)
*Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: 提出了两个医学专用多模态大语言模型InfiMed-Foundation-1.7B和4B，通过高质量数据筛选、高效训练方法和三阶段微调，在医学视觉问答和诊断任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 通用多模态大模型在医学领域存在专业知识不足、产生幻觉响应、知识蒸馏困难以及计算成本高等挑战。

Method: 结合通用和医学多模态数据，提出五维质量评估框架筛选高质量数据集，采用低到高图像分辨率和多模态序列打包提高训练效率，使用三阶段监督微调进行知识提取。

Result: 在MedEvalKit评估中，1.7B版本超越Qwen2.5VL-3B，4B版本超越HuatuoGPT-V-7B和MedGemma-27B-IT。

Conclusion: 通过解决数据质量、训练效率和领域知识提取等关键挑战，为医疗AI提供了更可靠有效的解决方案。

Abstract: Multimodal large language models (MLLMs) have shown remarkable potential in
various domains, yet their application in the medical field is hindered by
several challenges. General-purpose MLLMs often lack the specialized knowledge
required for medical tasks, leading to uncertain or hallucinatory responses.
Knowledge distillation from advanced models struggles to capture
domain-specific expertise in radiology and pharmacology. Additionally, the
computational cost of continual pretraining with large-scale medical data poses
significant efficiency challenges. To address these issues, we propose
InfiMed-Foundation-1.7B and InfiMed-Foundation-4B, two medical-specific MLLMs
designed to deliver state-of-the-art performance in medical applications. We
combined high-quality general-purpose and medical multimodal data and proposed
a novel five-dimensional quality assessment framework to curate high-quality
multimodal medical datasets. We employ low-to-high image resolution and
multimodal sequence packing to enhance training efficiency, enabling the
integration of extensive medical data. Furthermore, a three-stage supervised
fine-tuning process ensures effective knowledge extraction for complex medical
tasks. Evaluated on the MedEvalKit framework, InfiMed-Foundation-1.7B
outperforms Qwen2.5VL-3B, while InfiMed-Foundation-4B surpasses HuatuoGPT-V-7B
and MedGemma-27B-IT, demonstrating superior performance in medical visual
question answering and diagnostic tasks. By addressing key challenges in data
quality, training efficiency, and domain-specific knowledge extraction, our
work paves the way for more reliable and effective AI-driven solutions in
healthcare. InfiMed-Foundation-4B model is available at
\href{https://huggingface.co/InfiX-ai/InfiMed-Foundation-4B}{InfiMed-Foundation-4B}.

</details>


### [43] [Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models](https://arxiv.org/abs/2509.22284)
*Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi*

Main category: cs.AI

TL;DR: 提出PD-SSM方法，通过结构化稀疏参数化状态转移矩阵，在保持计算效率的同时显著提升状态空间模型的表达能力，能够最优地模拟有限状态自动机。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型使用对角化转移矩阵虽然计算高效，但表达能力受限；非结构化转移矩阵虽然表达能力强但计算成本过高。需要一种既能保持计算效率又能提升表达能力的方法。

Method: 将转移矩阵参数化为列独热矩阵(P)和复值对角矩阵(D)的乘积，使并行扫描的计算成本与状态大小成线性关系，同时保证模型稳定性和表达能力。

Result: 在FSA状态跟踪任务中显著优于现有SSM变体，在多类时间序列分类中性能与专门构建的神经控制微分方程相当，并能有效跟踪复杂FSA状态。

Conclusion: PD-SSM在保持计算效率的同时实现了最优的FSA模拟能力，为状态空间模型提供了表达能力和效率的良好平衡。

Abstract: Modern state-space models (SSMs) often utilize transition matrices which
enable efficient computation but pose restrictions on the model's expressivity,
as measured in terms of the ability to emulate finite-state automata (FSA).
While unstructured transition matrices are optimal in terms of expressivity,
they come at a prohibitively high compute and memory cost even for moderate
state sizes. We propose a structured sparse parametrization of transition
matrices in SSMs that enables FSA state tracking with optimal state size and
depth, while keeping the computational cost of the recurrence comparable to
that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix
as the product of a column one-hot matrix ($P$) and a complex-valued diagonal
matrix ($D$). Consequently, the computational cost of parallel scans scales
linearly with the state size. Theoretically, the model is BIBO-stable and can
emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout
of size $N \times N$, significantly improving on all current structured SSM
guarantees. Experimentally, the model significantly outperforms a wide
collection of modern SSM variants on various FSA state tracking tasks. On
multiclass time-series classification, the performance is comparable to that of
neural controlled differential equations, a paradigm explicitly built for
time-series analysis. Finally, we integrate PD-SSM into a hybrid
Transformer-SSM architecture and demonstrate that the model can effectively
track the states of a complex FSA in which transitions are encoded as a set of
variable-length English sentences. The code is available at
https://github.com/IBM/expressive-sparse-state-space-model

</details>


### [44] [Large Language Models as Nondeterministic Causal Models](https://arxiv.org/abs/2509.22297)
*Sander Beckers*

Main category: cs.AI

TL;DR: 本文提出了一种更简单的反事实生成方法，将LLM表示为非确定性因果模型，适用于任何黑盒LLM且无需修改。


<details>
  <summary>Details</summary>
Motivation: 现有方法对LLM的解释存在歧义，要么没有字面解释LLM，要么没有按意图解释LLM。需要一种基于LLM预期语义的更简单方法。

Method: 将LLM表示为非确定性因果模型，而不是确定性因果模型，从而生成反事实。这种方法对黑盒LLM直接适用且无需修改。

Result: 新方法比现有方法更简单，且对任何黑盒LLM都适用，不依赖实现细节。现有方法适用于特定类型的反事实生成。

Conclusion: 为LLM反事实推理提供了理论基础，基于预期语义，为特定应用的反事实生成方法奠定了基础。

Abstract: Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first
time, a method for generating counterfactuals of probabilistic Large Language
Models. Such counterfactuals tell us what would - or might - have been the
output of an LLM if some factual prompt ${\bf x}$ had been ${\bf x}^*$ instead.
The ability to generate such counterfactuals is an important necessary step
towards explaining, evaluating, and comparing, the behavior of LLMs. I argue,
however, that the existing method rests on an ambiguous interpretation of LLMs:
it does not interpret LLMs literally, for the method involves the assumption
that one can change the implementation of an LLM's sampling process without
changing the LLM itself, nor does it interpret LLMs as intended, for the method
involves explicitly representing a nondeterministic LLM as a deterministic
causal model. I here present a much simpler method for generating
counterfactuals that is based on an LLM's intended interpretation by
representing it as a nondeterministic causal model instead. The advantage of my
simpler method is that it is directly applicable to any black-box LLM without
modification, as it is agnostic to any implementation details. The advantage of
the existing method, on the other hand, is that it directly implements the
generation of a specific type of counterfactuals that is useful for certain
purposes, but not for others. I clarify how both methods relate by offering a
theoretical foundation for reasoning about counterfactuals in LLMs based on
their intended semantics, thereby laying the groundwork for novel
application-specific methods for generating counterfactuals.

</details>


### [45] [PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning](https://arxiv.org/abs/2509.22315)
*Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu*

Main category: cs.AI

TL;DR: PRIME是一个多智能体推理框架，灵感来自人类认知的双过程理论，通过动态整合快速直觉思维（系统1）和慢速审慎思维（系统2）来提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 受《思考，快与慢》中人类认知双过程理论的启发，旨在让LLM更贴近人类认知过程，在保持效率的同时提高复杂推理任务的准确性。

Method: 采用多智能体设计：首先由快速思维智能体（系统1）生成快速答案，如果检测到不确定性，则触发结构化的系统2推理管道，包含规划、假设生成、检索、信息整合和决策等专门智能体。

Result: 实验结果表明，使用LLaMA 3模型的PRIME框架在需要多跳和知识基础推理的基准测试中，能够与GPT-4、GPT-4o等最先进的闭源模型竞争。

Conclusion: PRIME为改进LLM在需要复杂、知识密集型推理的领域中提供了一个可扩展的解决方案。

Abstract: Inspired by the dual-process theory of human cognition from \textit{Thinking,
Fast and Slow}, we introduce \textbf{PRIME} (Planning and Retrieval-Integrated
Memory for Enhanced Reasoning), a multi-agent reasoning framework that
dynamically integrates \textbf{System 1} (fast, intuitive thinking) and
\textbf{System 2} (slow, deliberate thinking). PRIME first employs a Quick
Thinking Agent (System 1) to generate a rapid answer; if uncertainty is
detected, it then triggers a structured System 2 reasoning pipeline composed of
specialized agents for \textit{planning}, \textit{hypothesis generation},
\textit{retrieval}, \textit{information integration}, and
\textit{decision-making}. This multi-agent design faithfully mimics human
cognitive processes and enhances both efficiency and accuracy. Experimental
results with LLaMA 3 models demonstrate that PRIME enables open-source LLMs to
perform competitively with state-of-the-art closed-source models like GPT-4 and
GPT-4o on benchmarks requiring multi-hop and knowledge-grounded reasoning. This
research establishes PRIME as a scalable solution for improving LLMs in domains
requiring complex, knowledge-intensive reasoning.

</details>


### [46] [Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents](https://arxiv.org/abs/2509.22391)
*Jiaqi Shao,Yuxiang Lin,Munish Prasad Lohani,Yufeng Miao,Bing Luo*

Main category: cs.AI

TL;DR: SeekBench是首个通过步骤级分析评估LLM搜索代理认知能力的基准，包含190个专家标注的跟踪记录和1800多个响应步骤，用于分析代理的推理基础、搜索适应性和证据充分性评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM搜索代理在开放域问答中的最终答案准确性，而忽略了它们如何基于外部证据进行推理和行动，因此需要评估其认知能力。

Method: 构建SeekBench基准，包含190个专家标注的跟踪记录和1800多个响应步骤，每个步骤都带有证据标注，用于分析代理的推理基础、搜索适应性和证据充分性评估。

Result: SeekBench提供了对LLM搜索代理认知能力的细粒度评估框架，能够分析代理是否基于观察到的证据生成推理步骤、自适应地重新制定搜索以从低质量结果中恢复，以及正确评估当前证据是否足以提供答案。

Conclusion: SeekBench填补了LLM搜索代理评估的空白，通过步骤级分析提供了对其认知能力的全面评估，有助于改进搜索代理的设计和性能。

Abstract: Recent work has explored training Large Language Model (LLM) search agents
with reinforcement learning (RL) for open-domain question answering (QA).
However, most evaluations focus solely on final answer accuracy, overlooking
how these agents reason with and act on external evidence. We introduce
SeekBench, the first benchmark for evaluating the \textit{epistemic competence}
of LLM search agents through step-level analysis of their response traces.
SeekBench comprises 190 expert-annotated traces with over 1,800 response steps
generated by LLM search agents, each enriched with evidence annotations for
granular analysis of whether agents (1) generate reasoning steps grounded in
observed evidence, (2) adaptively reformulate searches to recover from
low-quality results, and (3) have proper calibration to correctly assess
whether the current evidence is sufficient for providing an answer.

</details>


### [47] [EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer](https://arxiv.org/abs/2509.22407)
*Zhehao Dong,Xiaofeng Wang,Zheng Zhu,Yirui Wang,Yang Wang,Yukun Zhou,Boyuan Wang,Chaojun Ni,Runqi Ouyang,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang*

Main category: cs.AI

TL;DR: 提出了EMMA框架，通过DreamTransfer生成多视角一致的机器人操作视频，结合AdaMix训练策略，显著提升VLA模型在未见物体类别和新视觉领域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 收集大规模真实机器人操作数据成本高昂且耗时，限制了VLA模型的泛化能力，需要一种高效的数据增强方法。

Method: 使用DreamTransfer框架进行文本控制的视觉编辑，生成多视角一致的机器人操作视频；采用AdaMix训练策略动态调整训练权重，专注于感知或运动学上的困难样本。

Result: 生成的视频在多视角一致性、几何保真度和文本条件准确性方面显著优于现有方法；在零样本视觉领域的真实机器人操作任务中，相比仅使用真实数据训练，性能提升超过200%，结合AdaMix后进一步提升13%。

Conclusion: EMMA框架通过生成数据和混合训练策略，有效解决了机器人操作数据稀缺问题，显著提升了VLA模型的泛化性能。

Abstract: Vision-language-action (VLA) models increasingly rely on diverse training
data to achieve robust generalization. However, collecting large-scale
real-world robot manipulation data across varied object appearances and
environmental conditions remains prohibitively time-consuming and expensive. To
overcome this bottleneck, we propose Embodied Manipulation Media Adaptation
(EMMA), a VLA policy enhancement framework that integrates a generative data
engine with an effective training pipeline. We introduce DreamTransfer, a
diffusion Transformer-based framework for generating multi-view consistent,
geometrically grounded embodied manipulation videos. DreamTransfer enables
text-controlled visual editing of robot videos, transforming foreground,
background, and lighting conditions without compromising 3D structure or
geometrical plausibility. Furthermore, we explore hybrid training with real and
generated data, and introduce AdaMix, a hard-sample-aware training strategy
that dynamically reweights training batches to focus optimization on
perceptually or kinematically challenging samples. Extensive experiments show
that videos generated by DreamTransfer significantly outperform prior video
generation methods in multi-view consistency, geometric fidelity, and
text-conditioning accuracy. Crucially, VLAs trained with generated data enable
robots to generalize to unseen object categories and novel visual domains using
only demonstrations from a single appearance. In real-world robotic
manipulation tasks with zero-shot visual domains, our approach achieves over a
200% relative performance gain compared to training on real data alone, and
further improves by 13% with AdaMix, demonstrating its effectiveness in
boosting policy generalization.

</details>


### [48] [Guiding Evolution of Artificial Life Using Vision-Language Models](https://arxiv.org/abs/2509.22447)
*Nikhil Baid,Hannah Erlebach,Paul Hellegouarch,Frederico Wieser*

Main category: cs.AI

TL;DR: ASAL++是基于ASAL的改进方法，使用多模态基础模型进行开放式搜索，通过第二个基础模型根据模拟视觉历史提出新的进化目标，形成复杂度递增的进化轨迹。


<details>
  <summary>Details</summary>
Motivation: 基础模型为人工生命模拟提供了强大的自动化搜索工具，先前工作使用视觉语言模型将ALife模拟与自然语言目标提示对齐，本文在此基础上进一步探索开放式搜索。

Method: 引入ASAL++方法，使用第二个基础模型根据模拟视觉历史提出新的进化目标。探索两种策略：EST（每次迭代匹配单个新提示）和ETT（匹配整个生成提示序列）。在Lenia基底中使用Gemma-3提出进化目标。

Result: 实验表明EST促进更大的视觉新颖性，而ETT培养更连贯和可解释的进化序列。

Conclusion: ASAL++为基础模型驱动的ALife发现指出了具有开放式特征的新方向。

Abstract: Foundation models (FMs) have recently opened up new frontiers in the field of
artificial life (ALife) by providing powerful tools to automate search through
ALife simulations. Previous work aligns ALife simulations with natural language
target prompts using vision-language models (VLMs). We build on Automated
Search for Artificial Life (ASAL) by introducing ASAL++, a method for
open-ended-like search guided by multimodal FMs. We use a second FM to propose
new evolutionary targets based on a simulation's visual history. This induces
an evolutionary trajectory with increasingly complex targets.
  We explore two strategies: (1) evolving a simulation to match a single new
prompt at each iteration (Evolved Supervised Targets: EST) and (2) evolving a
simulation to match the entire sequence of generated prompts (Evolved Temporal
Targets: ETT). We test our method empirically in the Lenia substrate using
Gemma-3 to propose evolutionary targets, and show that EST promotes greater
visual novelty, while ETT fosters more coherent and interpretable evolutionary
sequences.
  Our results suggest that ASAL++ points towards new directions for FM-driven
ALife discovery with open-ended characteristics.

</details>


### [49] [GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation](https://arxiv.org/abs/2509.22460)
*Shichao Weng,Zhiqiang Wang,Yuhua Zhou,Rui Lu,Ting Liu,Zhiyang Teng,Xiaozhang Liu,Hanmeng Liu*

Main category: cs.AI

TL;DR: GeoSketch是一个神经符号框架，通过感知-推理-动作循环解决几何问题，将图表抽象为逻辑形式，应用几何定理进行推理，并执行辅助线绘制等操作。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图表视为静态图像，缺乏动态操作能力，而人类几何推理需要辅助线构造和仿射变换等动态操作。

Method: 集成感知模块（将图表抽象为结构化逻辑形式）、符号推理模块（应用几何定理决定下一步推理步骤）和草图动作模块（执行辅助线绘制等操作）。采用两阶段训练：监督微调+强化学习。

Result: 在GeoSketch基准测试上，相比静态感知方法显著提高了逐步推理准确性和问题解决成功率。

Conclusion: GeoSketch通过统一分层决策、可执行视觉动作和符号验证，将多模态推理从静态解释推进到动态可验证交互，为复杂视觉空间问题解决建立了新基础。

Abstract: Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large
Language Models (MLLMs), requiring not only the joint interpretation of text
and diagrams but also iterative visuospatial reasoning. While existing
approaches process diagrams as static images, they lack the capacity for
dynamic manipulation - a core aspect of human geometric reasoning involving
auxiliary line construction and affine transformations. We present GeoSketch, a
neural-symbolic framework that recasts geometric reasoning as an interactive
perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module
that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning
module that applies geometric theorems to decide the next deductive step, and
(3) a Sketch Action module that executes operations such as drawing auxiliary
lines or applying transformations, thereby updating the diagram in a closed
loop. To train this agent, we develop a two-stage pipeline: supervised
fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement
learning with dense, symbolic rewards to enhance robustness and strategic
exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a
high-quality set of 390 geometry problems requiring auxiliary construction or
affine transformations. Experiments on strong MLLM baselines demonstrate that
GeoSketch significantly improves stepwise reasoning accuracy and
problem-solving success over static perception methods. By unifying
hierarchical decision-making, executable visual actions, and symbolic
verification, GeoSketch advances multimodal reasoning from static
interpretation to dynamic, verifiable interaction, establishing a new
foundation for solving complex visuospatial problems.

</details>


### [50] [InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios](https://arxiv.org/abs/2509.22502)
*Chenglin Yu,Yang Yu,Songmiao Wang,Yucheng Wang,Yifan Yang,Jinjia Li,Ming Li,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAgent是一个基于有向无环图的金字塔式多智能体框架，通过自动分解复杂智能体为分层多智能体系统、双重审核机制、智能体路由功能和自我进化机制，解决了传统LLM智能体开发中需要手动设计工作流程和提示的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LLM智能体开发需要精心设计工作流程、精心制作提示并进行迭代调优，这需要LLM技术和领域专业知识，这些手工制作的限制阻碍了LLM智能体在各行业的可扩展性和成本效益。

Method: 提出了InfiAgent框架，包含：通用化的"智能体即工具"机制，自动将复杂智能体分解为分层多智能体系统；双重审核机制确保任务完成质量和稳定性；智能体路由功能实现高效的任务-智能体匹配；智能体自我进化机制基于新任务、性能不佳或优化机会自主重构智能体DAG。

Result: 在多个基准测试中，InfiAgent相比ADAS（类似自动生成智能体框架）性能提高了9.9%；案例研究显示AI研究助手InfiHelper生成的科学论文获得了顶级IEEE会议人类评审员的认可。

Conclusion: InfiAgent框架发展成为一个通用的金字塔式多智能体系统，能够解决广泛的问题，其原子任务设计支持智能体并行化，显著提高了执行效率。

Abstract: Large Language Model (LLM) agents have demonstrated remarkable capabilities
in organizing and executing complex tasks, and many such agents are now widely
used in various application scenarios. However, developing these agents
requires carefully designed workflows, carefully crafted prompts, and iterative
tuning, which requires LLM techniques and domain-specific expertise. These
hand-crafted limitations hinder the scalability and cost-effectiveness of LLM
agents across a wide range of industries. To address these challenges, we
propose \textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that
can be applied to \textbf{infi}nite scenarios, which introduces several key
innovations: a generalized "agent-as-a-tool" mechanism that automatically
decomposes complex agents into hierarchical multi-agent systems; a dual-audit
mechanism that ensures the quality and stability of task completion; an agent
routing function that enables efficient task-agent matching; and an agent
self-evolution mechanism that autonomously restructures the agent DAG based on
new tasks, poor performance, or optimization opportunities. Furthermore,
InfiAgent's atomic task design supports agent parallelism, significantly
improving execution efficiency. This framework evolves into a versatile
pyramid-like multi-agent system capable of solving a wide range of problems.
Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9\%
higher performance compared to ADAS (similar auto-generated agent framework),
while a case study of the AI research assistant InfiHelper shows that it
generates scientific papers that have received recognition from human reviewers
at top-tier IEEE conferences.

</details>


### [51] [Estimating the Empowerment of Language Model Agents](https://arxiv.org/abs/2509.22504)
*Jinyeop Song,Jeff Gore,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 提出基于信息论中赋能概念（智能体行动与未来状态间的互信息）的开放评估框架EELMA，用于评估语言模型智能体在复杂开放环境中的能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于基准测试的评估方法成本高且需要人工设计任务，难以适应语言模型智能体日益增长的能力和现实工具访问需求。

Method: 开发EELMA算法，从多轮文本交互中近似估计有效赋能，并在语言游戏和现实网页浏览场景中进行验证。

Result: 赋能与平均任务性能强相关，能表征环境复杂性、思维链、模型规模和记忆长度等因素的影响，高赋能状态通常是通用能力的关键时刻。

Conclusion: 赋能是一个有吸引力的通用指标，可用于在复杂开放环境中评估和监控语言模型智能体。

Abstract: As language model (LM) agents become more capable and gain broader access to
real-world tools, there is a growing need for scalable evaluation frameworks of
agentic capability. However, conventional benchmark-centric evaluations are
costly to design and require human designers to come up with valid tasks that
translate into insights about general model capabilities. In this work, we
propose information-theoretic evaluation based on empowerment, the mutual
information between an agent's actions and future states, as an open-ended
method for evaluating LM agents. We introduce EELMA (Estimating Empowerment of
Language Model Agents), an algorithm for approximating effective empowerment
from multi-turn text interactions. We validate EELMA on both language games and
scaled-up realistic web-browsing scenarios. We find that empowerment strongly
correlates with average task performance, characterize the impact of
environmental complexity and agentic factors such as chain-of-thought, model
scale, and memory length on estimated empowerment, and that high empowerment
states and actions are often pivotal moments for general capabilities.
Together, these results demonstrate empowerment as an appealing general-purpose
metric for evaluating and monitoring LM agents in complex, open-ended settings.

</details>


### [52] [TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments](https://arxiv.org/abs/2509.22516)
*Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla*

Main category: cs.AI

TL;DR: TrueGradeAI是一个AI驱动的数字考试框架，通过保留手写输入和使用OCR转录，结合检索增强的评分管道实现自动评分，具有可解释性、偏见缓解和可审计的特点。


<details>
  <summary>Details</summary>
Motivation: 解决传统纸质考试的纸张浪费、物流复杂、评分延迟和评估者偏见等问题，实现更环保、高效和公平的评估系统。

Method: 使用平板设备捕获手写输入，应用基于transformer的OCR进行转录，通过检索增强管道整合教师解决方案、缓存层和外部参考，让大语言模型进行评分并提供证据关联的推理。

Result: 该系统减少了环境成本，加速了反馈周期，建立了可重用的知识库，同时积极缓解评分偏见，确保评估公平性。

Conclusion: TrueGradeAI通过结合手写保留与可扩展、透明的评估，超越了仅数字化响应的传统平板考试系统，实现了可解释的自动化评分和偏见缓解。

Abstract: This paper introduces TrueGradeAI, an AI-driven digital examination framework
designed to overcome the shortcomings of traditional paper-based assessments,
including excessive paper usage, logistical complexity, grading delays, and
evaluator bias. The system preserves natural handwriting by capturing stylus
input on secure tablets and applying transformer-based optical character
recognition for transcription. Evaluation is conducted through a
retrieval-augmented pipeline that integrates faculty solutions, cache layers,
and external references, enabling a large language model to assign scores with
explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems
that primarily digitize responses, TrueGradeAI advances the field by
incorporating explainable automation, bias mitigation, and auditable grading
trails. By uniting handwriting preservation with scalable and transparent
evaluation, the framework reduces environmental costs, accelerates feedback
cycles, and progressively builds a reusable knowledge base, while actively
working to mitigate grading bias and ensure fairness in assessment.

</details>


### [53] [REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model](https://arxiv.org/abs/2509.22518)
*Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen*

Main category: cs.AI

TL;DR: 提出了REMA框架，通过分析语言模型内部表示在低维几何结构（推理流形）中的空间关系，来解释推理失败的起源。该框架量化错误表示与正确推理流形的几何偏差，定位推理链开始偏离的关键点。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型如何进行复杂推理及其失败机制是解释性研究的挑战。需要提供可测量的几何分析视角来揭示模型内部的计算过程。

Method: 定义推理流形概念，构建REMA框架：1）量化错误表示与正确推理流形的k近邻距离偏差；2）跟踪各层偏差变化，定位推理链开始偏离的关键点；3）与正确表示的内部波动基线进行比较。

Result: 实验证明推理流形具有低维特性，错误与正确推理表示具有高度可分性。REMA框架能有效分析推理失败的起源。

Conclusion: 该研究将抽象推理失败与表示中的可测量几何偏差联系起来，为深入理解和诊断黑盒模型的内部计算过程提供了新途径。

Abstract: Understanding how Large Language Models (LLMs) perform complex reasoning and
their failure mechanisms is a challenge in interpretability research. To
provide a measurable geometric analysis perspective, we define the concept of
the Reasoning Manifold, a latent low-dimensional geometric structure formed by
the internal representations corresponding to all correctly reasoned
generations. This structure can be conceptualized as the embodiment of the
effective thinking paths that the model has learned to successfully solve a
given task. Based on this concept, we build REMA, a framework that explains the
origins of failures by quantitatively comparing the spatial relationships of
internal model representations corresponding to both erroneous and correct
reasoning samples. Specifically, REMA first quantifies the geometric deviation
of each erroneous representation by calculating its k-nearest neighbors
distance to the approximated manifold formed by correct representations,
thereby providing a unified failure signal. It then localizes the divergence
points where these deviations first become significant by tracking this
deviation metric across the model's layers and comparing it against a baseline
of internal fluctuations from correct representations, thus identifying where
the reasoning chain begins to go off-track. Our extensive experiments on
diverse language and multimodal models and tasks demonstrate the
low-dimensional nature of the reasoning manifold and the high separability
between erroneous and correct reasoning representations. The results also
validate the effectiveness of the REMA framework in analyzing the origins of
reasoning failures. This research connects abstract reasoning failures to
measurable geometric deviations in representations, providing new avenues for
in-depth understanding and diagnosis of the internal computational processes of
black-box models.

</details>


### [54] [The Emergence of Altruism in Large-Language-Model Agents Society](https://arxiv.org/abs/2509.22537)
*Haoyang Li,Xiao Jia,Zhanzhan Zhao*

Main category: cs.AI

TL;DR: 该研究首次揭示了不同大语言模型在利己主义和利他主义倾向上的内在异质性，识别出两种社会行动逻辑原型：适应型利己主义者和利他主义优化者。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注小规模任务导向游戏中的合作行为，忽视了大规模智能体社会中利他主义的涌现机制，需要理解LLM智能体所体现的社会逻辑。

Method: 引入Schelling变体城市迁移模型，创建社会困境，让200多个LLM智能体在利己（个人效用）和利他（系统效用）目标间导航，并使用扎根理论启发的方法系统编码智能体推理。

Result: 发现LLM存在根本性的社会倾向差异：适应型利己主义者默认优先考虑自身利益，但在社会规范设置信息板影响下利他行为显著增加；利他主义优化者表现出固有的利他逻辑，始终优先集体利益。

Conclusion: 对于社会模拟，模型选择不仅是选择推理能力，更是选择内在的社会行动逻辑。适应型利己主义者更适合模拟复杂人类社会，利他主义优化者更适合建模理想化的亲社会行为者。

Abstract: Leveraging Large Language Models (LLMs) for social simulation is a frontier
in computational social science. Understanding the social logics these agents
embody is critical to this attempt. However, existing research has primarily
focused on cooperation in small-scale, task-oriented games, overlooking how
altruism, which means sacrificing self-interest for collective benefit, emerges
in large-scale agent societies. To address this gap, we introduce a
Schelling-variant urban migration model that creates a social dilemma,
compelling over 200 LLM agents to navigate an explicit conflict between
egoistic (personal utility) and altruistic (system utility) goals. Our central
finding is a fundamental difference in the social tendencies of LLMs. We
identify two distinct archetypes: "Adaptive Egoists", which default to
prioritizing self-interest but whose altruistic behaviors significantly
increase under the influence of a social norm-setting message board; and
"Altruistic Optimizers", which exhibit an inherent altruistic logic,
consistently prioritizing collective benefit even at a direct cost to
themselves. Furthermore, to qualitatively analyze the cognitive underpinnings
of these decisions, we introduce a method inspired by Grounded Theory to
systematically code agent reasoning. In summary, this research provides the
first evidence of intrinsic heterogeneity in the egoistic and altruistic
tendencies of different LLMs. We propose that for social simulation, model
selection is not merely a matter of choosing reasoning capability, but of
choosing an intrinsic social action logic. While "Adaptive Egoists" may offer a
more suitable choice for simulating complex human societies, "Altruistic
Optimizers" are better suited for modeling idealized pro-social actors or
scenarios where collective welfare is the primary consideration.

</details>


### [55] [StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models](https://arxiv.org/abs/2509.22558)
*Chenyu Zhou,Tianyi Xu,Jianghao Lin,Dongdong Ge*

Main category: cs.AI

TL;DR: StepORLM是一个自演化的LLM框架，通过生成式过程监督解决运筹学问题，采用策略模型和生成式过程奖励模型的协同进化循环，在多个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键限制：结果奖励存在信用分配问题，正确最终答案可能强化错误推理；传统判别式过程监督短视，无法整体评估运筹学建模的相互依赖步骤。

Method: StepORLM采用协同进化循环，策略模型和生成式过程奖励模型相互迭代改进。通过双反馈机制：来自外部求解器的确定性结果验证，以及来自GenPRM的细致整体过程评估。使用加权直接偏好优化对齐策略，同时精炼GenPRM。

Result: 8B参数的StepORLM在六个基准测试中建立了新的最先进水平，显著优于更大的通用模型、代理方法和专业基线。协同进化的GenPRM能够作为强大且普遍适用的过程验证器，大幅提升自身模型和其他现有LLM的推理扩展性能。

Conclusion: StepORLM通过生成式过程监督和协同进化框架，有效解决了运筹学问题中LLM训练的关键挑战，实现了卓越的性能提升和通用过程验证能力。

Abstract: Large Language Models (LLMs) have shown promising capabilities for solving
Operations Research (OR) problems. While reinforcement learning serves as a
powerful paradigm for LLM training on OR problems, existing works generally
face two key limitations. First, outcome reward suffers from the credit
assignment problem, where correct final answers can reinforce flawed reasoning.
Second, conventional discriminative process supervision is myopic, failing to
evaluate the interdependent steps of OR modeling holistically. To this end, we
introduce StepORLM, a novel self-evolving framework with generative process
supervision. At its core, StepORLM features a co-evolutionary loop where a
policy model and a generative process reward model (GenPRM) iteratively improve
on each other. This loop is driven by a dual-feedback mechanism: definitive,
outcome-based verification from an external solver, and nuanced, holistic
process evaluation from the GenPRM. The combined signal is used to align the
policy via Weighted Direct Preference Optimization (W-DPO) and simultaneously
refine the GenPRM. Our resulting 8B-parameter StepORLM establishes a new
state-of-the-art across six benchmarks, significantly outperforming vastly
larger generalist models, agentic methods, and specialized baselines. Moreover,
the co-evolved GenPRM is able to act as a powerful and universally applicable
process verifier, substantially boosting the inference scaling performance of
both our own model and other existing LLMs.

</details>


### [56] [UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration](https://arxiv.org/abs/2509.22570)
*Qi Mao,Tinghan Yang,Jiahao Li,Bin Li,Libiao Jin,Yan Lu*

Main category: cs.AI

TL;DR: 提出了UniMIC框架，一种基于token的统一多模态交互编码方法，用于连接边缘设备和云端AI代理，通过紧凑的token化表示实现高效低比特率传输，同时保持与大语言模型的兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有编解码器仍针对单模态单向通信优化，在传统的压缩-传输-重建流程中会导致重复的质量下降，无法满足多模态交互通信的需求。

Method: 使用紧凑的token化表示作为通信媒介，采用轻量级Transformer熵模型（通用、掩码和文本条件化设计）来最小化token间冗余。

Result: 在文本到图像生成、文本引导修复、扩展和视觉问答等任务上，UniMIC实现了显著的比特率节省，即使在超低比特率（<0.05bpp）下仍保持鲁棒性，且不影响下游任务性能。

Conclusion: UniMIC为下一代多模态交互通信提供了一个实用且前瞻性的范式。

Abstract: The rapid progress of Large Multimodal Models (LMMs) and cloud-based AI
agents is transforming human-AI collaboration into bidirectional, multimodal
interaction. However, existing codecs remain optimized for unimodal, one-way
communication, resulting in repeated degradation under conventional
compress-transmit-reconstruct pipelines. To address this limitation, we propose
UniMIC, a Unified token-based Multimodal Interactive Coding framework that
bridges edge devices and cloud AI agents. Instead of transmitting raw pixels or
plain text, UniMIC employs compact tokenized representations as the
communication medium, enabling efficient low-bitrate transmission while
maintaining compatibility with LMMs. To further enhance compression,
lightweight Transformer-based entropy models with scenario-specific
designs-generic, masked, and text-conditioned-effectively minimize inter-token
redundancy. Extensive experiments on text-to-image generation, text-guided
inpainting, outpainting, and visual question answering show that UniMIC
achieves substantial bitrate savings and remains robust even at ultra-low
bitrates (<0.05bpp), without compromising downstream task performance. These
results establish UniMIC as a practical and forward-looking paradigm for
next-generation multimodal interactive communication.

</details>


### [57] [Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time](https://arxiv.org/abs/2509.22572)
*Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang*

Main category: cs.AI

TL;DR: 提出Dynamic Experts Search (DES)方法，通过动态调整MoE模型中激活的专家数量来增强推理能力，无需额外计算成本即可提升准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法主要依赖输出级采样，忽视了模型架构的作用。在MoE模型中，发现调整激活专家数量能产生互补的解决方案集，这揭示了未被充分探索的多样性来源。

Method: DES包含两个关键组件：(1) Dynamic MoE：在推理过程中直接控制专家数量以生成多样化的推理轨迹；(2) Expert Configuration Inheritance：在推理路径内保持一致的专家数量，在不同运行间变化专家数量，平衡稳定性和多样性。

Result: 在多种MoE架构、验证器和推理基准测试（数学、代码和知识）上的广泛实验表明，DES可靠地优于TTS基线方法，在不增加成本的情况下提高了准确性和稳定性。

Conclusion: DES是一种实用且可扩展的架构感知TTS方法，展示了现代LLMs结构灵活性如何推动推理能力的发展。

Abstract: Test-Time Scaling (TTS) enhances the reasoning ability of large language
models (LLMs) by allocating additional computation during inference. However,
existing approaches primarily rely on output-level sampling while overlooking
the role of model architecture. In mainstream Mixture-of-Experts (MoE) LLMs, we
observe that varying the number of activated experts yields complementary
solution sets with stable accuracy, revealing a new and underexplored source of
diversity. Motivated by this observation, we propose Dynamic Experts Search
(DES), a TTS strategy that elevates expert activation into a controllable
dimension of the search space. DES integrates two key components: (1) Dynamic
MoE, which enables direct control of expert counts during inference to generate
diverse reasoning trajectories without additional cost; and (2) Expert
Configuration Inheritance, which preserves consistent expert counts within a
reasoning path while varying them across runs, thereby balancing stability and
diversity throughout the search. Extensive experiments across MoE
architectures, verifiers and reasoning benchmarks (i.e., math, code and
knowledge) demonstrate that DES reliably outperforms TTS baselines, enhancing
accuracy and stability without additional cost. These results highlight DES as
a practical and scalable form of architecture-aware TTS, illustrating how
structural flexibility in modern LLMs can advance reasoning.

</details>


### [58] [Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective](https://arxiv.org/abs/2509.22613)
*Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen*

Main category: cs.AI

TL;DR: 本文通过图抽象分析强化学习在LLM规划中的理论机制，发现RL通过探索解决SFT的伪相关性问题，但PG存在多样性崩溃，而Q学习能保持多样性且避免奖励黑客。


<details>
  <summary>Details</summary>
Motivation: 尽管RL方法显著提升了LLM的规划能力，但其有效性的理论基础尚不明确，需要系统分析RL在规划任务中的优势和局限。

Method: 采用基于图的抽象模型，分析策略梯度(PG)和Q学习方法在规划任务中的表现，并在Blocksworld基准上进行实证验证。

Result: SFT会产生基于共现的伪解，RL通过探索实现正确规划；PG存在多样性崩溃问题，Q学习能保持输出多样性且避免奖励黑客。

Conclusion: 探索是RL规划泛化的关键机制，Q学习在多样性和稳定性方面优于PG，但需要精心设计奖励函数以防止奖励黑客。

Abstract: Recent reinforcement learning (RL) methods have substantially enhanced the
planning capabilities of Large Language Models (LLMs), yet the theoretical
basis for their effectiveness remains elusive. In this work, we investigate
RL's benefits and limitations through a tractable graph-based abstraction,
focusing on policy gradient (PG) and Q-learning methods. Our theoretical
analyses reveal that supervised fine-tuning (SFT) may introduce
co-occurrence-based spurious solutions, whereas RL achieves correct planning
primarily through exploration, underscoring exploration's role in enabling
better generalization. However, we also show that PG suffers from diversity
collapse, where output diversity decreases during training and persists even
after perfect accuracy is attained. By contrast, Q-learning provides two key
advantages: off-policy learning and diversity preservation at convergence. We
further demonstrate that careful reward design is necessary to prevent reward
hacking in Q-learning. Finally, applying our framework to the real-world
planning benchmark Blocksworld, we confirm that these behaviors manifest in
practice.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [59] [Differentially-Private Decentralized Learning in Heterogeneous Multicast Networks](https://arxiv.org/abs/2509.21688)
*Amir Ziaeddini,Yauhen Yakimenka,Jörg Kliewer*

Main category: cs.IT

TL;DR: 提出了一种功率控制的差分隐私去中心化学习算法，通过联合控制传输功率和注入的高斯噪声来满足隐私和能量预算，在行随机邻接矩阵网络中实现O(log T)的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 在去中心化学习中，客户端需要协作训练共同模型，但面临隐私保护和能量消耗的双重挑战，特别是在具有不同信道增益的网络环境中。

Method: 设计功率控制的差分隐私算法，联合控制模型更新的传输功率和注入的高斯噪声水平，在行随机邻接矩阵网络中进行协作学习。

Result: 算法实现了O(log T)的收敛速率，其中T是遗憾函数的时间范围，数值结果表明该算法优于现有工作。

Conclusion: 提出的功率控制差分隐私去中心化学习算法能够有效平衡隐私保护、能量消耗和学习性能，在具有信道差异的网络环境中表现优异。

Abstract: We propose a power-controlled differentially private decentralized learning
algorithm designed for a set of clients aiming to collaboratively train a
common learning model. The network is characterized by a row-stochastic
adjacency matrix, which reflects different channel gains between the clients.
In our privacy-preserving approach, both the transmit power for model updates
and the level of injected Gaussian noise are jointly controlled to satisfy a
given privacy and energy budget. We show that our proposed algorithm achieves a
convergence rate of O(log T), where T is the horizon bound in the regret
function. Furthermore, our numerical results confirm that our proposed
algorithm outperforms existing works.

</details>


### [60] [Dual and Covering Radii of Extended Algebraic Geometry Codes](https://arxiv.org/abs/2509.21773)
*Yunlong Zhu,Chang-An Zhao*

Main category: cs.IT

TL;DR: 本文研究了扩展代数几何码和Roth-Lempel型代数几何码，包括它们的对偶码和最小距离。证明了在某些情况下，g-MDS码的长度可以达到q+1+2g√q，并确定了扩展代数几何码的覆盖半径有g+2个可能值。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要关注扩展Reed-Solomon码及其对偶码和覆盖半径，但对扩展代数几何码（g≥1）的研究较少。本文旨在填补这一空白。

Method: 研究扩展代数几何码和Roth-Lempel型代数几何码，分析它们的对偶码和最小距离。利用最大曲线的扩展代数几何码来构造g-MDS码。

Result: 证明了对于某些g，g-MDS码的长度可以达到q+1+2g√q，这由最大曲线的扩展代数几何码实现。对于某些小有限域，这个长度是所有已知g-MDS码中最大的。扩展代数几何码的覆盖半径有g+2个可能值。当g=1时，如果长度n足够大或存在[n,k+1] MDS椭圆码，则覆盖半径的可能值减少到两个。

Conclusion: 扩展代数几何码在构造长g-MDS码方面具有优势，其覆盖半径具有特定的取值范围，这为代数几何码的理论和应用提供了新的见解。

Abstract: Many literatures consider the extended Reed-Solomon (RS) codes, including
their dual codes and covering radii, but few focus on extended algebraic
geometry (AG) codes of genus $g\ge1$. In this paper, we investigate extended AG
codes and Roth-Lempel type AG codes, including their dual codes and minimum
distances. Moreover, we show that for certain $g$, the length of a $g$-MDS code
over a finite field $\mathbb{F}_q$ can attain $q+1+2g\sqrt{q}$, which is
achieved by an extended AG code from the maximal curves of genus $g$. Notably,
for some small finite fields, this length $q+1+2g\sqrt{q}$ is the largest among
all known $g$-MDS codes. Subsequently, we establish that the covering radius of
an $[n,k]$ extended AG code has $g+2$ possible values. For the case of $g=1$,
we prove that this range reduces to two possible values when the length $n$ is
sufficiently large, or when there exists an $[n,k+1]$ MDS elliptic code.

</details>


### [61] [Radio-PPG: photoplethysmogram digital twin synthesis using deep neural representation of 6G/WiFi ISAC signals](https://arxiv.org/abs/2509.22326)
*Israel Jesus Santos Filho,Muhammad Mahboob Ur Rahman,Taous-Meriem Laleg-Kirati,Tareq Al-Naffouri*

Main category: cs.IT

TL;DR: 提出了一种基于6G/WiFi集成感知通信系统的非接触式数字孪生光电容积脉搏波合成方法，使用软件定义无线电采集胸部反射信号，构建了包含30名健康受试者的Radio-PPG数据集，并测试了两种AI模型进行DT-PPG信号合成。


<details>
  <summary>Details</summary>
Motivation: 开发非接触式数字孪生生物信号监测方法，实现实时生理过程监测，用于早期疾病诊断和个性化治疗，特别关注COVID-19、心血管疾病筛查和特殊需求人群健康评估。

Method: 使用5.23 GHz软件定义无线电照射人体胸部并收集反射信号，构建64通道无线电数据集；测试了离散余弦变换+多层感知器和级联U-NET模型（近似网络+细化网络）两种AI方法，并设计了自定义损失函数。

Result: U-NET模型在DT-PPG合成中取得了0.194的相对平均绝对误差，ISAC感知开销仅为15.62%；合成DT-PPG的生命体征估计和特征提取精度与参考PPG相当。

Conclusion: 这项工作展示了生成式AI和6G/WiFi ISAC技术在非接触式健康监测中的潜力，为开发COVID-19、心血管疾病筛查工具和特殊需求人群健康评估奠定了基础。

Abstract: Digital twins for 1D bio-signals enable real-time monitoring of physiological
processes of a person, which enables early disease diagnosis and personalized
treatment. This work introduces a novel non-contact method for digital twin
(DT) photoplethysmogram (PPG) signal synthesis under the umbrella of 6G/WiFi
integrated sensing and communication (ISAC) systems. We employ a
software-defined radio (SDR) operating at 5.23 GHz that illuminates the chest
of a nearby person with a wideband 6G/WiFi signal and collects the reflected
signals. This allows us to acquire Radio-PPG dataset that consists of 300
minutes worth of near synchronous 64-channel radio data, PPG data, along with
the labels (three body vitals) of 30 healthy subjects. With this, we test two
artificial intelligence (AI) models for DT-PPG signal synthesis: i) discrete
cosine transform followed by a multi-layer perceptron, ii) two U-NET models
(Approximation network, Refinement network) in cascade, along with a custom
loss function. Experimental results indicate that U-NET model achieves an
impressive relative mean absolute error of 0.194 with a small ISAC sensing
overhead of 15.62%, for DT-PPG synthesis. Furthermore, we performed quality
assessment of the synthetic DT-PPG by computing the accuracy of DT-PPG-based
vitals estimation and feature extraction, which turned out to be at par with
that of reference PPG-based vitals estimation and feature extraction. This work
highlights the potential of generative AI and 6G/WiFi ISAC technologies and
serves as a foundational step towards the development of non-contact screening
tools for covid-19, cardiovascular diseases and well-being assessment of people
with special needs.

</details>


### [62] [UAV-Enabled Fluid Antenna Systems for Multi-Target Wireless Sensing over LAWCNs](https://arxiv.org/abs/2509.22497)
*Xuhui Zhang,Wenchao Liu,Chunjie Wang,Jinke Ren,Huijun Xing,Shuqiang Wang,Yanyan Shen*

Main category: cs.IT

TL;DR: 本文研究了无人机搭载的流体天线系统在多目标无线感知中的应用，提出了一种交替优化算法来联合优化无人机轨迹、流体天线位置和波束成形，显著提升了感知精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了在低空无线消费网络中实现低空经济任务，需要提高多目标无线感知的空间灵活性和感知精度，流体天线系统为此提供了关键技术支撑。

Method: 提出了一种高效的交替优化算法，联合优化无人机轨迹、发射和接收流体天线的位置以及无人机的发射波束成形，以解决非凸优化问题。

Result: 仿真结果表明，与传统固定位置天线方案相比，所提系统在估计精度和感知可靠性方面实现了显著性能提升。

Conclusion: 通过自适应轨迹设计、波束成形和灵活的流体天线重定位，所提系统在无人机低空无线消费网络中具有实现精确感知的实际潜力。

Abstract: Fluid antenna system (FAS) is emerging as a key technology for enhancing
spatial flexibility and sensing accuracy in future wireless systems. This paper
investigates an unmanned aerial vehicle (UAV)-enabled FAS for multi-target
wireless sensing in low-altitude wireless consumer networks (LAWCNs) for
achieving the low-altitude economy (LAE) missions. We formulate an optimization
problem aimed at minimizing the average Cram\'er-Rao bound (CRB) for multiple
target estimations. To tackle this non-convex problem, an efficient alternating
optimization (AO) algorithm is proposed, which jointly optimizes the UAV
trajectory, the antenna position of the transmit fluid antennas (FAs) and the
receive FAs, and the transmit beamforming at the UAV. Simulation results
demonstrate significant performance improvements in estimation accuracy and
sensing reliability compared to conventional schemes, e.g., the fixed position
antenna scheme. The proposed system achieves enhanced sensing performance
through adaptive trajectory design and beamforming, alongside effective
interference suppression via the flexible FAS antenna repositioning,
underscoring its practical potential for precision sensing in the UAV-enabled
LAWCNs.

</details>
