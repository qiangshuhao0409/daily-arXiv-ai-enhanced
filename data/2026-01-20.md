<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.IT](#cs.IT) [Total: 17]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [X-raying the arXiv: A Large-Scale Analysis of arXiv Submissions' Source Files](https://arxiv.org/abs/2601.11385)
*Giovanni Apruzzese,Aurore Fass*

Main category: cs.NI

TL;DR: arXiv论文源文件中存在大量冗余数据（平均27%），包含不当内容和研究机密信息，需要改进数据管理


<details>
  <summary>Details</summary>
Motivation: arXiv作为最大的开放获取科学文献库，作者上传的源文件可能包含与发表论文无关的数据，这些数据可能泄露机密信息或浪费存储空间，需要了解arXiv提交源文件中存在什么内容

Method: 对2015-2025年间约60万份arXiv提交进行纵向分析，检查上传的源文件，量化并表征不需要生成PDF的数据，包括定量分析和定性检查

Result: 平均每份提交中27%的数据是不必要的，总计超过580GB冗余内容；定性检查发现存在攻击性/不当文本（如"WTF does this mean?"）和可能泄露正在进行研究的实验细节

Conclusion: arXiv源文件中存在大量冗余和敏感数据，已联系arXiv领导团队和相关作者，建议改进措施并开发自动化工具来检测和分析arXiv提交的残留数据，以改善arXiv生态系统中的数据卫生

Abstract: arXiv is the largest open-access repository for scientific literature. When submitting a paper, authors upload the manuscript's source files, from which the final PDF is compiled. These source files are also publicly downloadable, potentially exposing data unrelated to the published paper -- such as figures, documents, or comments -- that may unintentionally reveal confidential information or simply waste storage space. We thus ask ourselves: "What can be found within the source files of arXiv submissions?"
  We present a longitudinal analysis of ~600,000 submissions appeared on arXiv between 2015--2025. For each submission, we examine the uploaded source files to quantify and characterize data not required for producing the respective PDF. On average, 27% of the data in each submission are unnecessary, totaling >580 GB of redundant content across our dataset. Qualitative inspection reveals the presence of offensive/inappropriate text (e.g., "WTF does this mean?") and experimental details that could disclose ongoing research. We have contacted arXiv's leadership team, as well as the authors of affected papers to alert them of these issues. Finally, we propose recommendations and an automated tool to detect and analyze arXiv submissions residual data at scale, aiming to improve data hygiene in the arXiv's ecosystem.

</details>


### [2] [Indoor Neutral-Host Networks Over Shared Spectrum and Shared Infrastructure: A Comparison Study of Real-World Deployments](https://arxiv.org/abs/2601.11457)
*Joshua Roy Palathinkal,Muhammad Iqbal Rochman,Vanlin Sathya,Mehmet Yavuz,Monisha Ghosh*

Main category: cs.NI

TL;DR: 本文通过多站点测量研究，比较了CBRS中立主机网络与公共MNO 4G/5G宏站部署及Wi-Fi的性能，发现中立主机网络在室内覆盖、上行性能和频谱效率方面显著优于传统MNO部署。


<details>
  <summary>Details</summary>
Motivation: 室内高容量连接常受限于严重的建筑穿透损耗和室外宏站部署固有的上行功率限制。虽然移动网络运营商需要在低频段（<1 GHz）和中频段（1-7 GHz）优化频谱使用，但上行性能因链路预算不对称而严重劣化。中立主机网络通过频谱共享和基础设施共享提供可扩展的替代方案。

Method: 进行了多站点测量研究，比较了CBRS支持的中立主机网络与公共MNO 4G/5G宏站部署以及Wi-Fi的性能。测量包括建筑穿透损耗、RSRP、吞吐量、调制方案使用情况、UE发射功率等指标。

Result: 1) 建筑穿透损耗显著：低频段达15.5 dB，中频段达17.9 dB，导致MNO中频段RSRP比低频段低约10 dB；2) NH网络室内中值RSRP高30 dB，室内下行吞吐量与MNO室外性能相当，上行性能在室内外均超过MNO；3) NH邻近性带来更优的上行效率：64-QAM使用率达56%（MNO<6%），UE中值发射功率降低5 dB；4) MNO依赖低频段进行室内上行传输，而NH部署保持高性能中频段连接；5) NH在端到端吞吐量上优于MNO，但在上行吞吐量和延迟方面落后于Wi-Fi（因数据包路由到MNO核心网的开销）。

Conclusion: 中立主机网络通过近距离部署和频谱共享，显著改善了室内覆盖和上行性能，特别是在中频段连接方面表现优异。虽然在某些指标上仍落后于Wi-Fi，但为移动网络运营商提供了一种有效的室内覆盖解决方案，能够缓解建筑穿透损耗和上行功率限制的问题。

Abstract: Indoor high-capacity connectivity is frequently constrained by significant building penetration loss and the inherent uplink power limitations of a typical outdoor macro-cell deployment. While Mobile Network Operators (MNOs) must optimize spectrum across low-band (<1 GHz) and mid-band (1-7 GHz) frequencies, uplink performance remains disproportionately degraded due to link budget asymmetry. Neutral-host (NH) networking provides a scalable alternative by transparently offloading MNO subscribers via spectrum sharing and shared infrastructure. We present a multi-site measurement study comparing Citizens Broadband Radio Service (CBRS)-enabled NH networks against public MNO 4G/5G macro deployments and Wi-Fi. Our results show: (i) significant building penetration loss with up to 15.5 dB in low-bands and 17.9 dB in mid-bands, resulting in a ~10 dB RSRP deficit for MNO mid-bands compared to low-bands; (ii) NH networks provide a 30 dB higher median indoor RSRP with indoor NH normalized downlink throughput matches MNO outdoor performance, while its uplink performance exceeds MNO levels in both indoor and outdoor settings; (iii) NH proximity enables superior uplink efficiency, utilizing 64-QAM for 56% of transmissions (versus <6% for MNOs) and reducing median UE transmit power by 5 dB; (iv) MNOs rely on low-band spectrum for indoor uplink transmissions, while the NH deployment maintains high-performance mid-band connectivity; and (v) NH outperforms MNOs in end-to-end throughput but trails Wi-Fi in uplink throughput and latency due to packet routing overhead to the MNO core.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [Japanese AI Agent System on Human Papillomavirus Vaccination: System Design](https://arxiv.org/abs/2601.10718)
*Junyu Liu,Siwen Yang,Dexiu Ma,Qian Niu,Zequn Zhang,Momoko Nagai-Tanima,Tomoki Aoyama*

Main category: cs.AI

TL;DR: 开发了一个双功能AI代理系统，通过对话界面提供HPV疫苗验证信息，同时基于用户互动和社交媒体为医疗机构生成分析报告。


<details>
  <summary>Details</summary>
Motivation: 日本HPV疫苗犹豫问题严重，2013-2021年主动推荐暂停导致信息缺口，社交媒体错误信息加剧，传统方法无法同时处理个体查询和监测群体讨论。

Method: 构建包含向量数据库（整合学术论文、政府来源、新闻媒体和社交媒体）、基于ReAct代理架构的RAG聊天机器人（跨五个知识源的多工具编排），以及自动报告生成系统（新闻分析、研究综合、社交媒体情感分析、用户互动模式识别模块）。

Result: 单轮评估：相关性4.83、路由4.89、参考质量4.50、正确性4.90、专业身份4.88（总体4.80）。多轮评估：上下文保留4.94、主题连贯性5.00、总体4.98。报告生成系统：完整性4.00-5.00、正确性4.00-5.00、有用性3.67-5.00，所有时期参考有效性均为5.00。

Conclusion: 证明了集成AI代理系统用于双向HPV疫苗沟通的可行性，该架构能够提供带来源归属的验证信息，同时提供系统的公共话语分析，具有可转移到其他医疗环境的框架。

Abstract: Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts.

</details>


### [4] [Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models](https://arxiv.org/abs/2601.10719)
*Gerard Yeo,Svetlana Churina,Kokil Jaidka*

Main category: cs.AI

TL;DR: LLMs在预训练中已隐式编码了心理可信度信号，无需显式监督即可区分高/低可信度文本，为设计可信AI系统提供基础。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLMs是否以心理一致的方式表示在线信息的可信度，这对于LLMs在搜索、推荐和对话系统中的可信应用至关重要。

Method: 使用PEACE-Reviews数据集分析指令调优LLMs（Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B）在类似网络叙事中编码可信度的方式，通过层和头激活差异、探测分析和微调效果进行研究。

Result: 发现LLMs能系统地区分高/低可信度文本，可信度信号可线性解码，微调会优化而非重构这些表示。最强关联出现在公平性、确定性和自我责任等人类信任形成的关键维度。

Conclusion: 现代LLMs在无显式监督下内化了心理基础的可信度信号，这为在网络生态系统中设计可信、透明和值得信赖的AI系统提供了表征基础。

Abstract: Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM.

</details>


### [5] [Building AI Agents to Improve Job Referral Requests to Strangers](https://arxiv.org/abs/2601.10726)
*Ross Chu,Yuting Huang*

Main category: cs.AI

TL;DR: 开发AI代理帮助求职者撰写有效的职位推荐请求，通过改进代理重写请求，评估代理使用预测模型衡量质量，RAG增强的LLM能提升弱请求成功率14%且不损害强请求


<details>
  <summary>Details</summary>
Motivation: 帮助求职者在专业在线社区中撰写更有效的职位推荐请求，提高获得推荐的成功率。当前求职者在请求推荐时可能缺乏有效沟通技巧，需要AI辅助优化请求内容。

Method: 采用双代理系统：改进代理使用LLM重写推荐请求；评估代理使用训练好的模型预测请求获得推荐的概率。引入RAG增强LLM，防止对强请求的负面修改，同时放大对弱请求的改进效果。

Result: LLM修订能提升弱请求的预测成功率，但会降低强请求的成功率。RAG增强的LLM能防止对强请求的负面影响，同时将弱请求的预测成功率提升14%，且不损害强请求的表现。

Conclusion: AI代理系统能有效优化求职推荐请求，RAG增强的LLM在提升弱请求质量的同时保护强请求。虽然模型预测的改进不一定保证实际获得更多推荐，但为后续真实用户实验提供了低成本信号。

Abstract: This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.

</details>


### [6] [ORBITFLOW: SLO-Aware Long-Context LLM Serving with Fine-Grained KV Cache Reconfiguration](https://arxiv.org/abs/2601.10729)
*Xinyue Ma,Heelim Hong,Taegeon Um,Jongseop Lee,Seoyeong Choy,Woo-Yeon Lee,Myeongjae Jeon*

Main category: cs.AI

TL;DR: ORBITFLOW是一个细粒度、自适应的KV缓存管理系统，用于长上下文LLM服务，通过动态调整KV缓存位置来满足延迟SLO要求。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM服务面临挑战，因为请求长度和批次组合在token生成过程中变化，导致内存占用大幅波动。现有的静态预定义卸载策略无法适应快速变化的内存需求，导致过多的CPU-GPU KV传输，造成延迟峰值和频繁的SLO违规。

Method: ORBITFLOW采用轻量级ILP求解器为每个请求决定哪些层的KV缓存保留在GPU上（在内存容量约束内）。它基于运行时反馈持续优化KV放置策略，当活动计划在token生成过程中变得次优时进行调整。在高负载下，系统调用回退机制，暂时延迟内存占用大的飞行请求，以保持整体SLO达成。

Result: 实验表明，ORBITFLOW将TPOT和TBT的SLO达成率分别提高了66%和48%，同时将第95百分位延迟降低了38%，与现有卸载方法相比实现了高达3.3倍的吞吐量提升。

Conclusion: ORBITFLOW通过细粒度和自适应的KV缓存管理，有效解决了长上下文LLM服务中的内存波动问题，显著提升了SLO达成率、降低了延迟并提高了吞吐量。

Abstract: Serving long-context LLMs is challenging because request lengths and batch composition vary during token generation, causing the memory footprint to fluctuate significantly at runtime. Offloading KV caches to host memory limits effective memory usage, but existing static and predetermined offloading strategies cannot adapt to the rapidly shifting memory demands of long-context serving. This often leads to excessive CPU-to-GPU KV transfers that translate into latency spikes and frequent SLO violations. To address these challenges, we introduce ORBITFLOW, a fine-grained and adaptive KV cache management system that meets latency SLOs in long-context LLM serving. ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU for each request, within memory capacity constraints. It continuously refines KV placements based on runtime feedback when the active plan becomes suboptimal during token generation. Under heavy load, ORBITFLOW invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints, preserving overall SLO attainment. Our experiments demonstrate that ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, respectively, while reducing the 95th percentile latency by 38% and achieving up to 3.3x higher throughput compared to existing offloading methods.

</details>


### [7] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: CTHA是一个约束性时间分层架构，通过结构化流形投影和仲裁机制解决多时间尺度智能体中的协调稳定性问题，显著减少失败级联并提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度智能体架构虽然提升了性能，但破坏了统一智能体系统的协调稳定性，导致严重的层间冲突、无界错误传播和可扩展性受限。

Method: 提出约束性时间分层架构(CTHA)，包含三个关键约束：1)消息契约约束，通过类型化摘要、计划和策略包形式化层间信息流；2)权限流形约束，根据时间范围限制每层的决策空间；3)仲裁器解决约束，保证多层决策的无冲突组合。

Result: 实验表明CTHA在复杂任务执行中有效，相比无约束分层基线，减少47%的失败级联，提高2.3倍样本效率，并具有更优的可扩展性。

Conclusion: CTHA作为时间分层架构的原则性扩展，有助于深入理解多智能体协调，并为稳健自主系统的演进提供有前景的方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [8] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: 提出了LMEE框架和LMEE-Bench基准，通过MemoryExplorer方法增强智能体的长期记忆探索能力，在长时程具身任务中取得显著优势


<details>
  <summary>Details</summary>
Motivation: 现有具身智能体主要关注任务完成结果，忽视了探索过程和记忆利用的重要性。理想具身智能体应具备终身学习能力，利用长期情景记忆优化决策，处理长时程复杂任务

Method: 提出LMEE框架统一探索认知与决策行为；构建LMEE-Bench数据集和基准；提出MemoryExplorer方法，通过强化学习微调多模态大语言模型，鼓励主动记忆查询，采用包含动作预测、边界选择和问答的多任务奖励函数

Result: 与最先进的具身探索模型相比，该方法在长时程具身任务中取得了显著优势，实现了主动探索能力

Conclusion: LMEE框架和MemoryExplorer方法有效提升了具身智能体的长期记忆探索能力，为具身智能的终身学习提供了新思路

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [9] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 该论文使用基于启发式的趋势模型研究复杂产品创新过程，通过简单趋势（增加、减少、恒定）作为最小信息强度的量化工具，避免依赖数值或粗糙集，并用转换图表示系统行为路径。


<details>
  <summary>Details</summary>
Motivation: 研究复杂产品创新过程需要简化但有效的量化方法，传统数值方法可能过于复杂或不适用，需要一种最小信息强度的量化工具来捕捉系统动态。

Method: 使用基于启发式的趋势模型，每个启发式通过简单趋势（增加、减少、恒定）表达，构建趋势模型，解决方案定义为包含可能转换的场景集合，用转换图表示系统行为路径。

Result: 提出了一种用转换图表示系统行为的方法，任何可能的未来或过去行为都可以通过图中的路径来描绘，为复杂产品创新过程提供了有效的分析框架。

Conclusion: 基于启发式的趋势模型为复杂产品创新过程提供了一种简洁有效的分析工具，通过最小信息强度的量化方法和转换图表示，能够有效捕捉和预测系统动态行为。

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [10] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC-AGI-2竞赛显示当前AI在抽象推理上仍受限，主要依赖知识覆盖而非真正泛化，涌现了基于反馈的迭代优化方法，前沿AI实验室开始将其作为标准基准。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI基准系列是衡量AI在新型任务上少样本泛化能力的关键指标，需要评估当前AI在抽象推理和流体智能方面的真实能力，并识别现有方法的局限性。

Method: 通过分析ARC Prize 2025竞赛（1455个团队，15154个提交）和90篇论文，研究顶级方法特别是"精炼循环"（基于反馈的迭代程序优化），包括进化程序合成和商业AI系统应用层优化，以及零预训练小网络方法。

Result: 竞赛最高得分仅24%，显示当前AI抽象推理能力有限；精炼循环成为主流方法；前沿AI实验室开始将ARC-AGI作为标准基准；但分析表明当前AI推理仍主要依赖知识覆盖而非真正泛化。

Conclusion: 当前AI在抽象推理上仍受限于知识依赖过拟合，需要新基准ARC-AGI-3引入交互式推理挑战（探索、规划、记忆、目标获取、对齐能力）来推动真正泛化能力的发展。

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [11] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战赛分析多模态推理的数据策展，发现基于难度的样本选择是性能提升的主要驱动力，而数据集大小增加主要减少方差而非提升平均准确率。


<details>
  <summary>Details</summary>
Motivation: 研究多模态推理中的数据策展问题，通过固定模型和训练协议的挑战赛设置，隔离数据集选择的影响，探索如何高效构建多模态推理数据集。

Method: 使用基于Walton多模态冷启动的紧凑策展数据集参与DCVLR挑战，赛后进行消融实验，分析难度选择、数据集大小、多样性和合成增强等策展策略的效果。

Result: 基于难度的样本选择是性能提升的主要因素；增加数据集大小主要减少运行方差而非提升平均准确率；多样性和合成增强启发式方法无额外益处且常降低性能；该挑战表现为饱和状态评估。

Conclusion: DCVLR挑战揭示了多模态推理中数据策展的关键：对齐和难度是数据效率的核心因素，数据集策展应优先考虑难度选择而非单纯扩大规模或增加多样性。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [12] [AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing](https://arxiv.org/abs/2601.11007)
*Zhenhua Xu,Dongsheng Chen,Shuo Wang,Jian Li,Chengjie Wang,Meng Han,Yabiao Wang*

Main category: cs.AI

TL;DR: AdaMARP是一个自适应多智能体角色扮演框架，通过沉浸式消息格式和显式场景管理器解决现有系统沉浸感和适应性不足的问题，在角色一致性、环境基础和叙事连贯性方面显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM角色扮演系统存在沉浸感和适应性不足的问题，通常对环境动态信息建模不足，假设场景和角色基本静态，对多角色编排、场景转换和实时角色引入支持不够。

Method: 提出AdaMARP框架，包含沉浸式消息格式（交织[思考]、（行动）、<环境>和对话），以及显式场景管理器通过离散动作（初始化场景、选择说话者、切换场景、添加角色、结束）和相应理由来管理角色扮演。构建AdaRPSet训练角色模型能力，AdaSMSet监督编排决策，并引入AdaptiveBench进行轨迹级评估。

Result: 实验表明：AdaRPSet提升了角色一致性、环境基础和叙事连贯性，8B角色模型超越多个商业LLM；AdaSMSet实现了更流畅的场景转换和更自然的角色引入，仅用14B LLM就超越了Claude Sonnet 4.5。

Conclusion: AdaMARP框架通过创新的沉浸式消息格式和显式场景管理机制，显著提升了多智能体角色扮演的沉浸感、适应性和编排能力，在不同模型规模和骨干网络上均表现出一致改进。

Abstract: LLM role-playing aims to portray arbitrary characters in interactive narratives, yet existing systems often suffer from limited immersion and adaptability. They typically under-model dynamic environmental information and assume largely static scenes and casts, offering insufficient support for multi-character orchestration, scene transitions, and on-the-fly character introduction. We propose an adaptive multi-agent role-playing framework, AdaMARP, featuring an immersive message format that interleaves [Thought], (Action), <Environment>, and Speech, together with an explicit Scene Manager that governs role-playing through discrete actions (init_scene, pick_speaker, switch_scene, add_role, end) accompanied by rationales. To train these capabilities, we construct AdaRPSet for the Actor Model and AdaSMSet for supervising orchestration decisions, and introduce AdaptiveBench for trajectory-level evaluation. Experiments across multiple backbones and model scales demonstrate consistent improvements: AdaRPSet enhances character consistency, environment grounding, and narrative coherence, with an 8B actor outperforming several commercial LLMs, while AdaSMSet enables smoother scene transitions and more natural role introductions, surpassing Claude Sonnet 4.5 using only a 14B LLM.

</details>


### [13] [Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics](https://arxiv.org/abs/2601.11012)
*Jiahao Wang,Shuangjia Zheng*

Main category: cs.AI

TL;DR: HADES是一种基于贝叶斯优化的蛋白质序列设计方法，利用哈密顿动力学从结构感知的后验分布中高效采样，通过动量加速探索，采用位置离散化从连续状态生成离散蛋白质序列，在大多数指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于序列的蛋白质优化方法难以处理高维复杂性，主要因为存在上位效应（epistasis）且忽视结构约束，需要开发能够同时考虑蛋白质结构和序列相互约束的优化方法。

Method: 提出HADES方法：1）使用哈密顿动力学进行贝叶斯优化，利用动量和不确定性加速采样；2）引入位置离散化过程，从连续状态系统生成离散蛋白质序列；3）采用两阶段编码器-解码器框架构建后验代理模型，学习突变邻居间的结构-功能关系，构建平滑的搜索空间。

Result: 在广泛的计算机模拟实验中，HADES在大多数指标上优于最先进的基线方法。该方法特别擅长利用蛋白质结构和序列之间的相互约束，设计出结构相似但性质优化的蛋白质序列。

Conclusion: HADES通过结合哈密顿动力学和结构感知的贝叶斯优化，有效解决了蛋白质序列设计中的高维复杂性问题，为生物技术和医学中的蛋白质工程提供了强大的新工具。

Abstract: The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.

</details>


### [14] [BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search](https://arxiv.org/abs/2601.11037)
*Shiyu Liu,Yongjing Yin,Jianhao Yan,Yunbo Tang,Qinggang Zhang,Bei Li,Xin Chen,Jingang Wang,Xunliang Cai,Jinsong Su*

Main category: cs.AI

TL;DR: 提出BAPO框架解决RL智能搜索代理缺乏边界意识的问题，使代理能在证据不足时承认"我不知道"，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 基于RL的智能搜索代理虽然通过大规模强化学习优化策略显著提高了准确性，但存在可靠性缺陷：这些代理无法识别其推理边界，即使在证据不足或推理达到极限时也很少承认"我不知道"。这种可靠性缺失导致看似合理但不可靠的答案，在许多现实场景中带来重大风险。

Method: 提出边界感知策略优化(BAPO)框架，包含两个关键组件：(1)基于群体的边界感知奖励，鼓励代理仅在推理达到极限时做出IDK响应；(2)自适应奖励调节器，在早期探索阶段策略性地暂停此奖励，防止模型将IDK作为捷径利用。

Result: 在四个基准测试上的广泛实验表明，BAPO显著增强了智能搜索的整体可靠性。

Conclusion: BAPO框架成功解决了RL智能搜索代理的可靠性问题，在保持准确性的同时培养了可靠的边界意识，为实际应用中的风险控制提供了有效解决方案。

Abstract: RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.

</details>


### [15] [AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts](https://arxiv.org/abs/2601.11044)
*Keyu Li,Junhao Shi,Yang Xiao,Mohan Jiang,Jie Sun,Yunze Wu,Shijie Xia,Xiaojie Cai,Tianze Xu,Weiye Si,Wenjie Li,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: AgencyBench是一个全面的自主智能体基准测试，从日常AI使用中提取，评估6种核心智能体能力，包含32个真实场景、138个任务，需要大量工具调用和计算资源，采用用户模拟代理和Docker沙箱进行自动化评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单一智能体能力，无法捕捉长时程真实世界场景，且依赖人工反馈造成可扩展性瓶颈，阻碍了自动化数据收集和评估。

Method: 从日常AI使用中提取真实场景，构建包含32个场景、138个任务的基准测试，采用用户模拟代理提供迭代反馈，使用Docker沙箱进行视觉和功能评估，实现自动化评估。

Result: 闭源模型显著优于开源模型（48.4% vs 32.1%），在资源效率、反馈驱动的自我纠正和特定工具使用偏好方面存在显著差异，专有模型在其原生生态系统中表现更优。

Conclusion: AgencyBench为下一代智能体提供了关键测试平台，强调了模型架构与智能体框架协同优化的必要性，揭示了自主智能体的未来发展方向。

Abstract: Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.

</details>


### [16] [MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting](https://arxiv.org/abs/2601.11089)
*Suhan Guo,Jiahong Deng,Furao Shen*

Main category: cs.AI

TL;DR: MiCA是一个轻量级的流行病预测模块，通过因果发现推断移动关系，并将其集成到时序预测模型中，在数据有限和噪声条件下提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 人类移动性在流行病空间传播中起关键作用，但移动数据通常噪声大、间接且难以与疾病记录可靠整合。同时，流行病病例时间序列通常较短且时间分辨率粗糙，这限制了依赖干净丰富数据的参数密集型移动感知预测器的有效性。

Method: 提出Mobility-Informed Causal Adapter (MiCA)，一个轻量级且架构无关的模块。通过因果发现推断移动关系，并通过门控残差混合将其集成到时序预测模型中，避免使用图神经网络或完整注意力等重型关系组件。

Result: 在四个真实世界流行病数据集（COVID-19发病率、COVID-19死亡率、流感和登革热）上的广泛实验表明，MiCA持续改进轻量级时序骨干模型，在预测时间范围内平均相对误差降低7.5%。MiCA性能与最先进的时空模型相当，同时保持轻量级。

Conclusion: MiCA为流行病预测提供了一种轻量级、鲁棒的解决方案，能够在数据有限和噪声条件下有效利用移动性信息，避免重型关系组件的计算负担，在实际应用中具有重要价值。

Abstract: Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight.

</details>


### [17] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate：基于经验驱动的自动领域智能体创建框架，通过智能体交互历史学习成功/失败原因，实现自动创建和优化领域智能体


<details>
  <summary>Details</summary>
Motivation: 当前大多数实用智能体仍需人工设计，任务差异大导致构建成本高。现有自动创建方法将智能体生成视为黑盒过程，仅依赖最终性能指标，忽略了成功/失败的关键证据，且计算成本高

Method: 提出ReCreate框架，采用智能体即优化器范式，包含三个核心组件：1) 经验存储与检索机制；2) 推理-创建协同管道，将执行经验映射到脚手架编辑；3) 分层更新，将实例级细节抽象为可重用领域模式

Result: 在多个不同领域的实验中，ReCreate始终优于人工设计的智能体和现有自动智能体生成方法，即使从最小种子脚手架开始也能取得良好效果

Conclusion: ReCreate通过系统利用智能体交互历史中的具体信号，成功解决了自动创建和适应领域智能体的挑战，为实际应用中的智能体自动化提供了有效解决方案

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [18] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: SCALE框架通过任务级工作流生成和自预测评估，在保持性能的同时大幅降低多智能体系统的token消耗


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统工作流生成方法在任务级和查询级各有优劣，但成本效益不明确。查询级生成并非总是必要，而任务级评估又存在token消耗大和不可靠的问题

Method: 提出SCALE框架：通过少量样本校准的自预测优化器进行任务级生成，替代昂贵的完整验证执行。包括任务级工作流生成和低成本的自我评估机制

Result: SCALE在多个数据集上平均性能仅下降0.61%，同时将总体token使用量减少高达83%，实现了成本效益的显著提升

Conclusion: 任务级工作流生成配合自预测评估是高效的多智能体系统构建方法，能够在保持性能的同时大幅降低计算成本

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [19] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM是一个统一框架，将音视频仇恨检测从二元分类任务转化为结构化推理问题，通过跨模态强化学习实现精确的目标识别和时间定位，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中长格式多模态内容日益增多，有害叙事通过音频、视觉和文本线索的复杂交互构建。现有自动化系统虽然能高精度标记仇恨言论，但作为"黑盒"无法提供细粒度、可解释的证据（如精确时间戳和目标身份），难以支持有效的人机协同审核。

Method: 提出TANDEM框架，采用新颖的串联强化学习策略，让视觉-语言和音频-语言模型通过自约束的跨模态上下文相互优化，在不需要密集帧级监督的情况下稳定处理长时间序列的推理。

Result: 在三个基准数据集上的实验表明，TANDEM显著优于零样本和上下文增强基线，在HateMM数据集上目标识别F1达到0.73（比最先进方法提升30%），同时保持精确的时间定位。二元检测稳健，但在多类别设置中区分冒犯性和仇恨内容仍具挑战性。

Conclusion: 即使在复杂的多模态环境中，结构化、可解释的对齐也是可实现的，为下一代透明且可操作的在线安全审核工具提供了蓝图。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [20] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了基于LLM的预测性流程监控框架，从仅预测总时间扩展到多KPI预测，在数据稀缺场景下（仅100条轨迹）LLM超越基准方法，并利用其先验知识和训练轨迹内部相关性进行高阶推理。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测进行中流程的结果，传统方法依赖机器学习和深度学习。本文旨在扩展先前基于LLM的框架，评估其通用性、语义利用和推理机制，并扩展到多个关键绩效指标。

Method: 扩展了基于LLM的预测性流程监控框架，从仅预测总时间扩展到多KPI预测（包括总时间和活动发生预测）。通过提示工程利用LLM的能力，在三个不同事件日志上进行实证评估，特别关注数据稀缺场景（仅100条轨迹）。

Result: 在数据稀缺设置（仅100条轨迹）下，LLM在总时间和活动发生预测方面超越了基准方法。实验表明LLM既利用了其先验知识，也利用了训练轨迹之间的内部相关性。模型进行高阶推理而非简单复制现有预测方法。

Conclusion: 基于LLM的预测性流程监控框架在数据稀缺场景下表现优异，能够利用语义知识和进行高阶推理，为多KPI预测提供了有效解决方案，展示了LLM在流程挖掘领域的潜力。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [21] [Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems](https://arxiv.org/abs/2601.11189)
*Sofiene Lassoued,Asrat Gobachew,Stefan Lier,Andreas Schwung*

Main category: cs.AI

TL;DR: 提出基于策略的深度强化学习超启发式框架解决作业车间调度问题，通过动作预过滤和承诺机制提升性能，在标准测试集上优于传统方法


<details>
  <summary>Details</summary>
Motivation: 作业车间调度问题是经典的NP难优化问题，传统启发式方法效果有限。需要开发能够动态切换调度规则的智能方法，以更好地适应不同系统状态

Method: 基于策略的深度强化学习超启发式框架，包含两个关键机制：1) 动作预过滤，将决策限制在可行的低层动作；2) 承诺机制，调节启发式切换频率。比较了确定性贪婪选择和随机采样两种动作选择策略

Result: 在标准JSSP基准测试上的计算实验表明，该方法优于传统启发式、元启发式和最近的神经网络调度方法

Conclusion: 提出的超启发式框架通过动作预过滤和承诺机制有效解决了作业车间调度问题，展示了深度强化学习在复杂调度问题中的潜力

Abstract: This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. We extend the hyper-heuristic framework with two key mechanisms. First, action prefiltering restricts decision-making to feasible low-level actions, enabling low-level heuristics to be evaluated independently of environmental constraints and providing an unbiased assessment. Second, a commitment mechanism regulates the frequency of heuristic switching. We investigate the impact of different commitment strategies, from step-wise switching to full-episode commitment, on both training behavior and makespan. Additionally, we compare two action selection strategies at the policy level: deterministic greedy selection and stochastic sampling. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods

</details>


### [22] [Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning](https://arxiv.org/abs/2601.11252)
*Qianyue Wang,Jinwu Hu,Yufeng Wang,Huanxiang Lin,Bolin Chen,Zhiquan Wen,Yaofo Chen,Mingkui Tan*

Main category: cs.AI

TL;DR: Think-with-Me是一种新的测试时交互推理范式，通过在推理过程中引入外部反馈干预，解决大型推理模型存在的过度思考和推理偏差问题，在有限上下文窗口下实现准确性和推理长度的更好平衡。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在多步推理方面表现出色，但经常存在推理过程低效的问题，如过度思考和推理偏差，这些过度或错误的推理会增加计算成本并降低性能。现有的高效推理方法以闭环方式运行，缺乏外部干预机制来指导推理过程。

Method: 提出Think-with-Me范式，在推理过程中引入外部反馈干预。关键洞察是过渡连词（如"因此"、"然而"等）作为自然干预点，标志着自我验证或探索阶段。在这些点暂停推理以获取外部反馈，自适应地延长或终止推理。反馈通过多标准评估（合理性和完整性）生成，可来自人类或LLM代理。使用组相对策略优化（GRPO）训练目标模型以适应这种交互模式。

Result: 在有限上下文窗口下实现了准确性和推理长度的优越平衡。在AIME24上，Think-with-Me在8K窗口下比QwQ-32B准确率提高7.19%，同时平均推理长度减少81%。该范式也有利于安全和创造性任务。

Conclusion: Think-with-Me通过引入外部反馈干预的交互式推理范式，有效解决了大型推理模型的低效推理问题，在保持准确性的同时显著减少推理长度，为高效推理提供了新方向。

Abstract: Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.

</details>


### [23] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice是一个可解释的框架，用于评估约束决策中AI与人类的对齐度，超越传统准确率指标，通过机制建模分析决策因素、约束敏感性和权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估主要关注结果一致性（如准确率、F1分数），缺乏对决策机制的深入理解，无法诊断AI与人类在约束决策中的根本差异，特别是在不同群体间的对齐异质性。

Method: XChoice为人类数据和LLM生成的决策拟合基于机制的决策模型，提取可解释参数（决策因素重要性、约束敏感性、隐含权衡），通过比较参数向量评估对齐度，使用美国时间使用调查作为人类基准，并进行鲁棒性分析和RAG干预验证。

Result: 在美国人日常时间分配研究中，发现不同模型和活动间的对齐存在异质性，黑人和已婚群体的对齐问题尤为突出，RAG干预能有效缓解特定对齐问题。

Conclusion: XChoice提供了基于机制的评估指标，能够诊断AI与人类的对齐问题并指导针对性改进，超越了表面结果匹配的局限性。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [24] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: AstroReason-Bench是一个用于评估智能体在空间规划问题中规划能力的基准测试，该基准整合了多种调度机制，发现当前智能体在现实约束下的表现远不如专用求解器。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准主要关注符号化或弱接地环境，而在物理约束的现实世界领域中的性能尚未得到充分探索。空间规划问题具有高风险、异质目标、严格物理约束和长时程决策等特点，需要专门的评估基准。

Method: 引入AstroReason-Bench基准，整合地面站通信和敏捷地球观测等多种调度机制，提供统一的智能体导向交互协议，并在多种最先进的开源和闭源智能体LLM系统上进行评估。

Result: 评估发现，当前智能体在现实约束下的表现显著低于专用求解器，突显了通用规划在现实约束下的关键局限性。

Conclusion: AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断性的测试平台，有助于推动智能体在物理约束现实世界领域的规划能力发展。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [25] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出"探针与求解"两阶段框架，用于约束规划求解器的自动超参数优化，在CPMpy库中实现并验证了贝叶斯优化优于默认配置和汉明距离搜索。


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能对超参数选择高度敏感，手动寻找最佳配置需要专家知识且耗时，需要自动化方法来优化求解器配置。

Method: 提出两阶段框架：探针阶段使用可配置的超参数优化方法（贝叶斯优化和汉明距离搜索）探索不同超参数集；求解阶段使用找到的最佳配置在剩余时间内解决问题。

Result: 贝叶斯优化在ACE求解器上25.4%的实例中优于默认配置，57.9%持平；在Choco求解器上38.6%的实例中优于默认配置。贝叶斯优化始终优于汉明距离搜索。

Conclusion: 探针与求解算法提供了一种实用、资源感知的约束求解器调优方法，能够跨不同问题类型实现稳健的性能改进，模型化探索优于简单局部搜索。

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [26] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出LEG框架，结合LLM和优化算法，在资源有限下优先升级埃塞俄比亚卫生站，平衡人口覆盖和专家偏好


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚卫生部升级卫生站以改善基本医疗服务可及性，但资源有限需要优先选择升级设施，同时需考虑专家和利益相关者的多样化偏好

Method: 提出LEG框架：结合可证明近似算法优化人口覆盖，使用LLM驱动的迭代细化，整合人机对齐以确保解决方案反映专家定性指导同时保持覆盖保证

Result: 在埃塞俄比亚三个地区的真实数据实验中证明框架有效性，展示其支持公平、数据驱动的卫生系统规划的潜力

Conclusion: LEG框架成功桥接了传统优化方法与专家定性偏好，为资源有限的卫生系统规划提供了有效工具

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [27] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: BoxMind是一个用于拳击战术分析的闭环AI专家系统，通过定义原子击打事件、构建层次化技术战术指标，并基于图模型融合显式战术特征与隐式动态嵌入来预测比赛结果，最终将获胜概率梯度转化为可执行的战术调整建议。


<details>
  <summary>Details</summary>
Motivation: 格斗类运动如拳击在AI驱动分析方面发展不足，主要因为动作动态复杂且缺乏结构化战术表示。现有方法难以捕捉拳手对抗的动态特性，需要将非结构化视频数据转化为战略智能。

Method: 1. 定义具有精确时间边界、空间和技术属性的原子击打事件；2. 将比赛视频解析为18个层次化技术战术指标；3. 提出基于图的预测模型，融合显式技术战术特征与可学习的时间变化隐式嵌入；4. 将比赛结果建模为技术战术指标的可微函数，将获胜概率梯度转化为战术调整。

Result: 结果预测模型在BoxerGraph测试集上达到69.8%准确率，在奥运比赛上达到87.5%准确率。系统生成的战略建议达到人类专家水平。在2024年巴黎奥运会闭环部署中，直接帮助中国国家队获得3金2银的历史性成绩。

Conclusion: BoxMind建立了将非结构化视频数据转化为战略智能的可复制范式，弥合了计算机视觉与竞技体育决策支持之间的差距，为格斗类运动的战术分析提供了有效解决方案。

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [28] [Fundamental Limits of Quantum Semantic Communication via Sheaf Cohomology](https://arxiv.org/abs/2601.10958)
*Christo Kurisummoottil Thomas,Mingzhe Chen*

Main category: cs.IT

TL;DR: 提出量子语义通信的信息论框架，利用层上同调建模多智能体语义网络，证明量子纠缠可超越经典语义对齐限制，建立量子关联与语义信息的对偶关系。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，当智能体采用异构感知模态和AI架构时，完美比特级传输无法保证相互理解。现有深度学习方法虽在语义压缩方面有进展，但异构条件下的语义对齐信息论极限仍不清楚。语义模糊性与量子上下文性具有相同数学结构（上同调障碍），这促使建立量子语义通信框架。

Method: 提出量子语义通信的信息论框架，使用层上同调建模多智能体语义网络：将智能体意义空间建模为希尔伯特空间，通过量子信道连接。第一层上同调群用于表征不可约语义模糊性。证明语义对齐所需的最小通信速率与上同调空间维数的对数成正比。

Result: 1) 第一层上同调群表征不可约语义模糊性，是局部处理无法解决的基本障碍；2) 语义对齐所需最小通信速率与上同调空间维数的对数成正比，建立语义版香农极限；3) 纠缠辅助信道容量严格超越经典界限，每个共享纠缠比特可减少1比特经典通信；4) 量子上下文性可减少上同调障碍；5) 建立量子失谐与集成语义信息的对偶关系。

Conclusion: 该框架为自主多智能体系统中的量子增强语义通信提供严格理论基础，表明量子纠缠可超越经典语义对齐限制，量子关联与语义信息存在深刻联系，为异构智能体系统的高效协调开辟新途径。

Abstract: Semantic communication (SC) enables bandwidth-efficient coordination in multi-agent systems by transmitting meaning rather than raw bits. However, when agents employ heterogeneous sensing modalities and AI architectures, perfect bit-level transmission no longer guarantees mutual understanding. Although deep learning methods for semantic compression have advanced, the information-theoretic limits of semantic alignment under heterogeneity remain poorly understood. Notably, semantic ambiguity shares the same mathematical structure as quantum contextuality, as both arise from cohomological obstructions, motivating a quantum formulation of SC. In this paper, an information-theoretic framework for quantum semantic communication is proposed using sheaf cohomology. Multi-agent semantic networks are modeled as quantum sheaves, where agents meaning spaces are Hilbert spaces connected by quantum channels. The first sheaf cohomology group is shown to characterize irreducible semantic ambiguity, representing a fundamental obstruction to alignment that no local processing can resolve. The minimum communication rate required for semantic alignment is proven to scale with the logarithm of the dimension of the cohomological space, establishing a semantic analog of Shannon limits. For entanglement-assisted channels, the achievable capacity is shown to strictly exceed classical bounds, with each shared ebit reducing the required classical communication by one bit, providing a rigorous interpretation of shared context. Additionally, quantum contextuality is shown to reduce cohomological obstructions, and a duality between quantum discord and integrated semantic information is established, linking quantum correlations to irreducible semantic content. This framework provides rigorous foundations for quantum-enhanced semantic communication in autonomous multi-agent systems.

</details>


### [29] [Convergence Properties of Good Quantum Codes for Classical Communication](https://arxiv.org/abs/2601.11498)
*Alptug Aytekin,Mohamed Nomeir,Lei Hu,Sennur Ulukus*

Main category: cs.IT

TL;DR: 将经典信息论中关于容量可达码输出统计特性的结果扩展到量子编码领域，研究量子信道中经典通信码的输出分布与最优输出分布的关系


<details>
  <summary>Details</summary>
Motivation: 经典信息论中已有关于容量可达码输出统计特性的丰富结果，包括码的输出分布与信道容量问题中最优输入诱导的输出分布的比较。本文旨在将这些结果扩展到量子编码领域，特别是用于经典通信的量子码（即通过量子码字在噪声量子信道中传输经典消息的场景）。

Method: 首先证明最优输出分布的唯一性，以便更具体地讨论最优输出分布。然后使用与经典情况类似的技术，将渐近消失错误概率的结果扩展到量子情况。对于分组码，利用基于量子广义去极化半群超压缩性的二阶逆定理，将非渐近消失错误概率的结果扩展到量子情况。

Result: 成功将经典信息论中关于容量可达码输出统计特性的结果扩展到量子编码领域，包括渐近消失错误概率和非渐近消失错误概率两种情况，为量子信道中经典通信码的输出分布分析提供了理论框架。

Conclusion: 本文系统地将经典信息论中关于码输出统计特性的结果扩展到量子领域，证明了最优输出分布的唯一性，并成功建立了量子编码在渐近消失和非渐近消失错误概率情况下的输出分布理论，为量子信息论的发展提供了重要工具。

Abstract: An important part of the information theory folklore had been about the output statistics of codes that achieve the capacity and how the empirical distributions compare to the output distributions induced by the optimal input in the channel capacity problem. Results for a variety of such empirical output distributions of good codes have been known in the literature, such as the comparison of the output distribution of the code to the optimal output distribution in vanishing and non-vanishing error probability cases. Motivated by these, we aim to achieve similar results for the quantum codes that are used for classical communication, that is the setting in which the classical messages are communicated through quantum codewords that pass through a noisy quantum channel. We first show the uniqueness of the optimal output distribution, to be able to talk more concretely about the optimal output distribution. Then, we extend the vanishing error probability results to the quantum case, by using techniques that are close in spirit to the classical case. We also extend non-vanishing error probability results to the quantum case on block codes, by using the second-order converses for such codes based on hypercontractivity results for the quantum generalized depolarizing semi-groups.

</details>


### [30] [On the Entropy of a Random Geometric Graph](https://arxiv.org/abs/2601.10778)
*Praneeth Kumar Vippathalla,Justin P. Coon,Mihai-Alin Badiu*

Main category: cs.IT

TL;DR: 研究了硬随机几何图(RGG)的熵，推导了在单位立方体和环面上不同连接半径下的熵上界，并在某些情况下得到了精确的渐近特征。


<details>
  <summary>Details</summary>
Motivation: 随机几何图是空间网络的常用模型，但其熵（信息量）的量化研究不足。理解RGG的熵有助于分析空间网络的信息内容和结构复杂性。

Method: 考虑两种空间域：d维单位立方体[0,1]^d和d维单位环面𝕋^d。对于给定的连接半径r，通过随机放置m个点并连接距离小于r的点来构建RGG。推导了所有可能r值下的熵上界，并在某些情况下证明了紧下界以获得精确渐近特征。

Result: 主要结果：1) 在𝕋^d上，当0<r≤1/4时，H(G_m)∼dm log₂m；2) 在一维[0,1]上，对所有0<r<1，熵的行为类似m log m。由此可推断，在𝕋^d上未标记RGG的结构熵为Ω((d-1)m log₂m)。

Conclusion: 成功量化了硬随机几何图的熵，揭示了其与维度d、节点数m和连接半径r的关系。对于未覆盖的情况，推测熵的渐近行为与推导的上界主项一致。

Abstract: In this paper, we study the entropy of a hard random geometric graph (RGG), a commonly used model for spatial networks, where the connectivity is governed by the distances between the nodes. Formally, given a connection range $r$, a hard RGG $G_m$ on $m$ vertices is formed by drawing $m$ random points from a spatial domain, and then connecting any two points with an edge when they are within a distance $r$ from each other. The two domains we consider are the $d$-dimensional unit cube $[0,1]^d$ and the $d$-dimensional unit torus $\mathbb{T}^d$. We derive upper bounds on the entropy $H(G_m)$ for both these domains and for all possible values of $r$. In a few cases, we obtain an exact asymptotic characterization of the entropy by proving a tight lower bound. Our main results are that $H(G_m) \sim dm \log_2m$ for $0 < r \leq 1/4$ in the case of $\mathbb{T}^d$ and that the entropy of a one-dimensional RGG on $[0,1]$ behaves like $m\log m$ for all $0<r<1$. As a consequence, we can infer that the asymptotic structural entropy of an RGG on $\mathbb{T}^d$, which is the entropy of an unlabelled RGG, is $Ω((d-1)m \log_2m)$ for $0 < r \leq 1/4$. For the rest of the cases, we conjecture that the entropy behaves asymptotically as the leading order terms of our derived upper bounds.

</details>


### [31] [Efficient LLR-Domain Decoding of ABS+ Polar Codes](https://arxiv.org/abs/2601.10808)
*Mikhail Chernikov,Peter Trifonov*

Main category: cs.IT

TL;DR: ABS+极码的LLR域SCL解码器实现与优化，相比经典极码在高信噪比区域获得相同帧错误率时计算复杂度更低


<details>
  <summary>Details</summary>
Motivation: ABS+极码作为Arikan极码的推广，具有更快的极化速度，但需要高效的解码算法实现

Method: 提出了ABS+极码的LLR域SCL解码器实现，并优化了SCL算法以减少LLR计算复杂度

Result: 相比经典极码，在高信噪比区域获得相同帧错误率时，所需算术运算次数更少

Conclusion: 提出的LLR域SCL解码器为ABS+极码提供了高效实现，显著降低了计算复杂度

Abstract: ABS+ polar codes are a generalization of Arikan polar codes that provides much faster polarization. We present an LLR-domain implementation of the SCL decoder of ABS+ polar codes. Furthermore, we optimize the SCL algorithm in order to reduce the complexity requirements for the LLRs computation. In comparison with classical polar codes, the proposed approach requires less number of arithmetic operations in the SCL decoder to obtain the fixed frame error rate (FER) at high-SNR region.

</details>


### [32] [A Differential Geometry and Algebraic Topology Based Public-Key Cryptographic Algorithm in Presence of Quantum Adversaries](https://arxiv.org/abs/2601.10883)
*Andrea Rondelli*

Main category: cs.IT

TL;DR: Z-Sigil是一种基于功能分析、微分几何和代数拓扑的非对称公钥密码算法，旨在抵抗经典和量子攻击，通过Calabi-Yau流形上的切纤维丛结构实现。


<details>
  <summary>Details</summary>
Motivation: 将古代印章的信任、保密和完整性传统延续到量子计算机、经典超级计算机和人工智能时代，开发能够抵抗经典和量子攻击的新型密码算法。

Method: 在紧致Calabi-Yau流形的切纤维丛上构建密码系统，密钥是切纤维向量元素，在底流形切空间上定义二元运算形成群胚结构。采用迭代块加密，强制串行架构限制量子并行性，每个块依赖于秘密的几何和分析数据。

Result: 算法正确性和可逆性得到解析证明，无私钥恢复明文会导致对抗搜索空间指数增长，即使有量子加速。使用连续几何结构、非线性算子组合和强制块串行化，区别于基于离散代数假设的现有量子安全方案。

Conclusion: Z-Sigil提供了一种基于连续几何和分析结构的新型量子安全密码方法，通过几何复杂性、分析复杂性和强制串行化实现抗量子攻击能力。

Abstract: In antiquity, the seal embodied trust, secrecy, and integrity in safeguarding the exchange of letters and messages. The purpose of this work is to continue this tradition in the contemporary era, characterized by the presence of quantum computers, classical supercomputers, and increasingly sophisticated artificial intelligence. We introduce Z-Sigil, an asymmetric public-key cryptographic algorithm grounded in functional analysis, differential geometry, and algebraic topology, with the explicit goal of achieving resistance against both classical and quantum attacks. The construction operates over the tangent fiber bundle of a compact Calabi-Yau manifold [13], where cryptographic keys are elements of vector tangent fibers, with a binary operation defined on tangent spaces of the base manifold giving rise to a groupoid structure. Encryption and decryption are performed iteratively on message blocks, enforcing a serial architecture designed to limit quantum parallelism [9,10]. Each block depends on secret geometric and analytic data, including a randomly chosen base point on the manifold, a selected section of the tangent fiber bundle, and auxiliary analytic data derived from operator determinants and Zeta function regularization [11]. The correctness and invertibility of the proposed algorithm are proven analytically. Furthermore, any adversarial attempt to recover the plaintext without the private key leads to an exponential growth of the adversarial search space,even under quantum speedups. The use of continuous geometric structures,non-linear operator compositions,and enforced blockwise serialization distinguishes this approach from existing quantum-safe cryptographic proposals based on primary discrete algebraic assumptions.

</details>


### [33] [A PAC-Bayesian Analysis of Channel-Induced Degradation in Edge Inference](https://arxiv.org/abs/2601.10915)
*Yangshuo He,Guanding Yu,Jingge Zhu*

Main category: cs.IT

TL;DR: 论文提出了一种针对边缘推理中无线信道噪声问题的解决方案，通过将信道统计信息融入神经网络权重空间，推导出量化无线失真影响的泛化边界，并设计了一种无需端到端重训练的信道感知训练算法。


<details>
  <summary>Details</summary>
Motivation: 边缘推理中，神经网络通常部署在分布式边缘设备上通过无线传输协作执行推理。然而，标准神经网络在无噪声环境中训练，与边缘部署时的噪声信道环境存在不匹配，导致性能下降。

Method: 1. 提出增强的神经网络模型，将信道统计信息直接融入权重空间；2. 推导PAC-Bayesian泛化边界，显式量化无线失真的影响；3. 为实际信道提供闭式表达式；4. 基于理论结果提出信道感知训练算法，最小化基于推导边界的代理目标。

Result: 仿真结果表明，所提出的算法能够有效利用信道统计信息提高推理精度，且无需端到端重新训练。

Conclusion: 通过将信道统计信息融入神经网络设计和训练过程，可以缓解边缘推理中无线信道噪声导致的性能下降问题，为实际部署提供了理论指导和实用算法。

Abstract: In the emerging paradigm of edge inference, neural networks (NNs) are partitioned across distributed edge devices that collaboratively perform inference via wireless transmission. However, standard NNs are generally trained in a noiseless environment, creating a mismatch with the noisy channels during edge deployment. In this paper, we address this issue by characterizing the channel-induced performance deterioration as a generalization error against unseen channels. We introduce an augmented NN model that incorporates channel statistics directly into the weight space, allowing us to derive PAC-Bayesian generalization bounds that explicitly quantifies the impact of wireless distortion. We further provide closed-form expressions for practical channels to demonstrate the tractability of these bounds. Inspired by the theoretical results, we propose a channel-aware training algorithm that minimizes a surrogate objective based on the derived bound. Simulations show that the proposed algorithm can effectively improve inference accuracy by leveraging channel statistics, without end-to-end re-training.

</details>


### [34] [Asymmetric Encoding-Decoding Schemes for Lossless Data Compression](https://arxiv.org/abs/2601.10991)
*Hirosuke Yamamoto,Ken-ichi Iwata*

Main category: cs.IT

TL;DR: 提出了一种称为非对称编解码方案(AEDS)的新型无损数据压缩编码方案，该方案是tANS的推广，具有更广泛的码类，在某些条件下能获得比霍夫曼编码更短的平均码长。


<details>
  <summary>Details</summary>
Motivation: tANS（非对称数字系统的表格变体）在数据压缩中表现出色，但码类有限。本文旨在提出一种更通用的编码方案，扩展tANS的能力，使其在特定条件下能超越霍夫曼编码的性能。

Method: 提出AEDS方案，数据序列反向编码（从后向前），正向解码（从前向后）。分析其码类特性，推导平均码长的上界，研究状态数对性能的影响。

Result: AEDS的码类比tANS更广泛；对于i.i.d.源，2状态AEDS在霍夫曼树根节点子节点概率大于0.61803时，5状态AEDS在概率大于0.56984时，平均码长优于霍夫曼编码；最优AEDS和tANS的平均码长以O(1/N)速度收敛到源熵。

Conclusion: AEDS是tANS的有效推广，具有更广泛的码类和更好的压缩性能潜力，为无损数据压缩提供了新的编码方案选择。

Abstract: This paper proposes a new lossless data compression coding scheme named an asymmetric encoding-decoding scheme (AEDS), which can be considered as a generalization of tANS (tabled variant of asymmetric numeral systems). In the AEDS, a data sequence $\mathbf{s}=s_1s_2\cdots s_n$ is encoded in backward order $s_t, t=n, \cdots, 2,1$, while $\mathbf{s}$ is decoded in forward order $s_t, t=1, 2, \cdots, n$ in the same way as the tANS. But, the code class of the AEDS is much broader than that of the tANS. We show for i.i.d.~sources that an AEDS with 2 states (resp.~5 states) can attain a shorter average code length than the Huffman code if a child of the root in the Huffman code tree has a probability weight larger than 0.61803 (resp.~0.56984). Furthermore, we derive several upper bounds on the average code length of the AEDS, which also hold for the tANS, and we show that the average code length of the optimal AEDS and tANS with $N$ states converges to the source entropy with speed $O(1/N)$ as $N$ increases.

</details>


### [35] [PEMNet: Towards Autonomous and Enhanced Environment-Aware Mobile Networks](https://arxiv.org/abs/2601.11025)
*Lei Li,Yanqing Xu,Ye Xue,Feng Yin,Chao Shen,Rui Zhang,Tsung-Hui Chang*

Main category: cs.IT

TL;DR: 提出感知嵌入地图（PEM），一种结合无线信道统计和时空流量模式的联合表示框架，用于5G/6G网络在动态环境下的优化决策。


<details>
  <summary>Details</summary>
Motivation: 5G/6G网络需要在严格延迟、能耗和频谱约束下做出动态决策，这依赖于对无线信道时空变化和流量需求的先验知识。现有方法缺乏对信道和流量的联合表示，且构建成本高。

Method: 提出感知嵌入地图（PEM）框架，将细粒度信道统计与基站覆盖范围内的网格级时空流量模式进行联合嵌入。使用标准兼容的测量数据（如测量报告、调度/QoS日志）构建，实现低成本大规模部署。

Result: PEM能够支持跨PHY、MAC和网络层的环境感知优化，显著降低训练开销和信令。相比现有站点特定信道地图和数字孪生副本，PEM强调信道-流量联合嵌入和基于标准测量的实用构建。

Conclusion: PEM为5G/6G网络提供了一种实用的联合信道-流量表示框架，能够在保持高保真度的同时降低构建成本，支持网络自主优化决策。

Abstract: With 5G deployment and the evolution toward 6G, mobile networks must make decisions in highly dynamic environments under strict latency, energy, and spectrum constraints. Achieving this goal, however, depends on prior knowledge of spatial-temporal variations in wireless channels and traffic demands. This motivates a joint, site-specific representation of radio propagation and user demand that is queryable at low online overhead. In this work, we propose the perception embedding map (PEM), a localized framework that embeds fine-grained channel statistics together with grid-level spatial-temporal traffic patterns over a base station's coverage. PEM is built from standard-compliant measurements -- such as measurement report and scheduling/quality-of-service logs -- so it can be deployed and maintained at scale with low cost. Integrated into PEM, this joint knowledge supports enhanced environment-aware optimization across PHY, MAC, and network layers while substantially reducing training overhead and signaling. Compared with existing site-specific channel maps and digital-twin replicas, PEM distinctively emphasizes (i) joint channel-traffic embedding, which is essential for network optimization, and (ii) practical construction using standard measurements, enabling network autonomy while striking a favorable fidelity-cost balance.

</details>


### [36] [Sensing Mutual Information for Communication Signal with Deterministic Pilots and Random Data Payloads](https://arxiv.org/abs/2601.11149)
*Lei Xie,Hengtao He,Jun Tong,Fan Liu,Shenghui Song*

Main category: cs.IT

TL;DR: 本文研究了采用混合信号（包含导频和数据载荷）的ISAC系统的感知互信息与预编码设计，推导了SMI的闭式表达式并提出了最大化SMI的预编码优化方案。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究主要关注纯随机或纯确定性波形，忽略了实际通信标准中普遍使用的混合信号结构（导频+数据载荷），因此需要研究这种混合信号下的感知性能。

Method: 1. 利用随机矩阵理论推导混合信号下感知互信息的闭式表达式；2. 建立最大化SMI的预编码优化问题，考虑发射功率和通信速率约束；3. 采用交替方向乘子法框架高效求解。

Result: 仿真结果验证了理论推导的准确性，并证明所提出的预编码设计在感知性能上优于传统基准方案。

Conclusion: 本文填补了ISAC系统中混合信号感知性能研究的空白，为实际通信标准下的ISAC系统设计提供了理论指导和优化方案。

Abstract: The recent emergence of the integrated sensing and communication (ISAC) framework has sparked significant interest in quantifying the sensing capabilities inherent in communication signals. However, existing literature has mainly focused on scenarios involving either purely random or purely deterministic waveforms. This overlooks a critical reality: operational communication standards invariably utilize a hybrid structure comprising both deterministic pilots for channel estimation and random payloads for data transmission. To bridge this gap, this paper investigates the sensing mutual information (SMI) and precoding design specifically for ISAC systems employing communication signals with both pilots and data payloads. First, by utilizing random matrix theory (RMT), we derive a tractable closed-form expression for the SMI that accurately accounts for the statistical properties of the hybrid signal. Building upon this theoretical foundation, we formulate a precoding optimization problem to maximize SMI with constraints on the transmit power and communication rate, which is solved via an efficient alternating direction method of multipliers framework. Simulation results validate the accuracy of the theoretical results and demonstrate the superiority of the proposed precoding design over conventional benchmarks.

</details>


### [37] [Performance Analysis of Cell-Free Massive MIMO under Imperfect LoS Phase Tracking](https://arxiv.org/abs/2601.11179)
*Noor Ul Ain,Lorenzo Miretti,Renato L. G. Cavalcante,Sławomir Stańczak*

Main category: cs.IT

TL;DR: 研究不完美视距相位跟踪对无蜂窝大规模MIMO网络性能的影响，提出考虑相位估计误差的Rician衰落模型和线性MMSE信道估计器，推导集中式和分布式波束成形方案。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设视距相位完全已知或完全未知，但实际中由于硬件损伤、移动性和同步误差，相位估计存在残余不确定性。需要建立更现实的模型来评估无蜂窝大规模MIMO网络在实际相位跟踪条件下的性能。

Method: 提出考虑相位估计误差的Rician衰落模型，其中视距分量由不完美相位估计旋转并由确定性相位误差惩罚因子衰减。推导捕获统计相位误差的线性MMSE信道估计器，该估计器统一了先前结果。引入保留信道估计二阶统计特性的虚拟上行链路模型，推导可处理的集中式和分布式MMSE波束成形器。

Result: 数值结果表明，该框架在理想化假设和实际跟踪限制之间架起桥梁，为6G无蜂窝网络提供严格的性能基准和设计见解。当相位知识完美时，估计器退化为贝叶斯MMSE估计器；当无相位知识时，退化为零均值模型。

Conclusion: 提出的框架能够更真实地评估无蜂窝大规模MIMO网络在不完美视距相位跟踪条件下的性能，为6G网络设计提供了重要的理论基准和实用指导，填补了理想假设与实际限制之间的研究空白。

Abstract: We study the impact of imperfect line-of-sight (LoS) phase tracking on the performance of cell-free massive MIMO networks. Unlike prior works that assume perfectly known or completely unknown phases, we consider a realistic regime where LoS phases are estimated with residual uncertainty due to hardware impairments, mobility, and synchronization errors. To this end, we propose a Rician fading model where LoS components are rotated by imperfect phase estimates and attenuated by a deterministic phase-error penalty factor. We derive a linear MMSE channel estimator that captures statistical phase errors and unifies prior results, reducing to the Bayesian MMSE estimator with perfect phase knowledge and to a zero-mean model in the absence of phase knowledge. To address the non-Gaussian setting, we introduce a virtual uplink model that preserves second-order statistics of channel estimation, enabling the derivation of tractable centralized and distributed MMSE beamformers. To ensure fair assessment of the network performance, we apply these beamformers to the true uplink model and compute the spectral efficiency bounds available in the literature. Numerical results show that our framework bridges idealized assumptions and practical tracking limitations, providing rigorous performance benchmarks and design insights for 6G cell-free networks.

</details>


### [38] [Rate-Distortion-Perception Tradeoff for the Gray-Wyner Problem](https://arxiv.org/abs/2601.11257)
*Yu Yang,Yingxin Zhang,Weijie Yuan,Lin Zhou*

Main category: cs.IT

TL;DR: 论文研究了带有感知约束的Gray-Wyner有损信源编码问题，推导了速率-失真-感知区域的一阶渐近最优解，将单源系统结果推广到多终端场景。


<details>
  <summary>Details</summary>
Motivation: 图像和视频压缩等实际应用中，需要确保重建序列的分布与原始源序列接近，即感知约束。先前研究主要关注单源序列的压缩和重建，本文旨在将结果推广到Gray-Wyner问题中的多终端设置。

Method: 通过引入随机循环移位算子直接整合到编码和解码过程中，分析失真和感知约束。推导出由涉及公共信息的互信息项和两个条件速率-失真-感知函数控制的最优权衡。

Result: 得到了带有感知约束的Gray-Wyner有损信源编码问题的第一阶渐近最优速率-失真-感知区域，展示了最优权衡由互信息项和条件速率-失真-感知函数决定。

Conclusion: 成功将点对点系统的先前结果推广到具有两个相关源序列的Gray-Wyner多终端设置，为图像和视频压缩等实际应用提供了理论指导。

Abstract: We revisit the Gray-Wyner lossy source coding problem and derive the first-order asymptotic optimal rate-distortion-perception region when additional perception constraints are imposed on reproduced source sequences. The optimal trade-off is shown to be governed by a mutual information term involving common information and two conditional rate-distortion-perception functions. The perception constraint requires that the distribution of each reproduced sequence is close to that of the original source sequence, which is motivated by practical applications in image and video compression. Prior studies usually focus on the compression and reconstruction of a single source sequence. In this paper, we generalize the prior results for point-to-point systems to the representative multi-terminal setting of the Gray-Wyner problem with two correlated source sequences. In particular, we integrate the analyses of the distortion and the perception constraints by including the random circular shift operator in the encoding and decoding process directly.

</details>


### [39] [Joint Antenna Rotation and IRS Beamforming for Multi-User Uplink Communications](https://arxiv.org/abs/2601.11291)
*Guoying Zhang,Qingqing Wu,Ziyuan Zheng,Qiaoyan Peng,Yanze Zhu,Wen Chen,Penghui Huang*

Main category: cs.IT

TL;DR: 提出一种可旋转天线与智能反射面结合的无线系统，通过联合优化天线3D旋转、接收波束成形和IRS相位偏移来最大化上行链路和速率。


<details>
  <summary>Details</summary>
Motivation: 传统可旋转天线在物理遮挡下性能下降，而智能反射面在基站天线旁瓣区域部署时存在角度失配问题。需要一种新系统来解决这些限制。

Method: 提出RA-enabled IRS辅助多用户上行系统，基站天线可灵活调整3D方向使其主瓣对准IRS。采用交替优化算法：通过投影梯度上升更新天线旋转，闭式解计算接收波束成形，分数规划优化IRS相位偏移。

Result: 数值结果表明，与传统固定天线系统相比，所提系统尤其在大的角度失配情况下能带来显著的性能增益。

Conclusion: 结合可旋转天线和智能反射面的系统能有效解决角度失配和物理遮挡问题，显著提升无线覆盖性能。

Abstract: Rotatable antenna (RA) enhances wireless coverage through directional gain steering, yet suffers from performance degradation under physical blockages. Intelligent reflecting surface (IRS) establishes reflective paths to bypass obstacles, but suffers from angular mismatch when deployed in the side-lobe region of base station (BS) antennas. To address this issue, we propose a new RA-enabled IRS-assisted multi-user uplink system, in which the BS antennas are capable of flexibly adjusting their 3D orientations to align their boresights with the IRS. We formulate a sum rate maximization problem by jointly optimizing the antenna 3D rotations, receive beamforming and IRS phase shifts. To tackle this non-convex problem, we propose an efficient alternating optimization (AO) algorithm. Specifically, we iteratively update the antenna rotations via projected gradient ascent (PGA), compute the receive beamforming via a closed-form solution, and optimize the IRS phase shifts via fractional programming (FP). Numerical results demonstrate that the proposed system yields significant performance gains over conventional fixed-antenna systems, especially under large angular misalignments.

</details>


### [40] [Information Theoretic Perspective on Representation Learning](https://arxiv.org/abs/2601.11334)
*Deborah Pereg*

Main category: cs.IT

TL;DR: 提出信息论框架分析最后一层嵌入表示，针对回归任务中的学习表示，定义了表示率并推导了输入-输出信息表示可靠性的极限，进一步在扰动和压缩输出场景下定义了表示容量和表示率失真。


<details>
  <summary>Details</summary>
Motivation: 需要从信息论角度系统分析回归任务中最后一层嵌入表示的性能极限，理解学习表示如何有效编码输入-输出关系，以及在不同约束条件下的最优表示能力。

Method: 建立信息论框架，定义表示率概念，推导输入-输出信息表示的可靠性极限，分析扰动场景下的表示容量，研究压缩输出的表示率失真问题，并推导可达容量和表示率及其逆定理。

Result: 推导出表示率的理论极限，建立了扰动场景下的表示容量界限，获得了压缩输出的表示率失真关系，最终将这些结果统一到一个综合框架中。

Conclusion: 该信息论框架为分析回归任务中的学习表示提供了理论基础，揭示了表示性能的根本限制，并为设计更有效的表示学习方法提供了指导原则。

Abstract: An information-theoretic framework is introduced to analyze last-layer embedding, focusing on learned representations for regression tasks. We define representation-rate and derive limits on the reliability with which input-output information can be represented as is inherently determined by the input-source entropy. We further define representation capacity in a perturbed setting, and representation rate-distortion for a compressed output. We derive the achievable capacity, the achievable representation-rate, and their converse. Finally, we combine the results in a unified setting.

</details>


### [41] [Polar Orbit Decoding: Universal Parallel Soft Decoding via Automorphism Orbits](https://arxiv.org/abs/2601.11373)
*Pin-Jing Li,Yu-Chih Huang*

Main category: cs.IT

TL;DR: 提出Polar Orbit Decoding (POD)框架，通过并行解码二进制线性分组码的自同构轨道，在保持性能的同时显著降低解码延迟。


<details>
  <summary>Details</summary>
Motivation: 现有二进制线性分组码没有单一码族能同时优化所有性能指标，导致标准中广泛使用多码架构，增加了硬件复杂度。虽然已有基于极化变换的通用解码框架，但其并行化尚未讨论。

Method: 提出Polar Orbit Decoding (POD)框架，利用二进制线性分组码的自同构性质生成置换轨道，在极化变换后产生具有相同动态冻结约束的多样化解码轨迹。通过并行解码该自同构轨道，实现延迟-性能权衡。使用Schreier-Sims算法以基和强生成集形式表示自同构群，实现多项式时间内的离线系统计算。

Result: 在扩展BCH码和扩展Golay码上的仿真结果表明，POD能够达到最大似然性能，同时相比传统的连续消除列表解码显著降低解码延迟。

Conclusion: POD为二进制线性分组码提供了一个通用并行解码框架，通过利用自同构轨道实现高效的延迟-性能权衡，无需冻结集重新适配或额外的穷举置换搜索。

Abstract: Binary linear block codes (BLBCs) form the foundation of modern communication systems, yet no single code family simultaneously optimizes all performance aspects. This leads to the widely used multi-code architecture in the standard, significantly increasing the hardware complexity since multiple decoders are required in each piece of equipment. A universal decoding framework based on polar transformations has recently been proposed to unify BLBC decoding under polar-style decoders, but its parallelization has not yet been discussed. In this work, we propose Polar Orbit Decoding (POD), a universal parallel decoding framework for BLBCs. We identify that the automorphisms of BLBCs generate an orbit of permutations that induce diverse decoding trajectories with identical dynamic-frozen constraints after the polar transformations. By decoding over this automorphism orbit in parallel, POD achieves substantial latency-performance tradeoffs without requiring frozen-set readaptation or extra exhaustive permutation searches. Moreover, to enable efficient orbit traversal in the implementation, we represent the automorphism group in a base and strong generating set (BSGS) form using Schreier-Sims algorithms, making offline systematic computation accessible in polynomial time. Simulation results on extended BCH and extended Golay codes demonstrate that POD can achieve maximum-likelihood performance while significantly reducing the decoding latency compared to conventional successive cancellation list decoding.

</details>


### [42] [Efficient Channel Autoencoders for Wideband Communications leveraging Walsh-Hadamard interleaving](https://arxiv.org/abs/2601.11407)
*Cel Thys,Rodney Martinez Alonso,Sofie Pollin*

Main category: cs.IT

TL;DR: 该论文提出了一种基于Walsh-Hadamard变换的端到端信道自动编码器系统，用于实现高能效的宽带通信，在短块长度下接近传统Polar码性能，同时显著提升能量效率。


<details>
  <summary>Details</summary>
Motivation: 宽带通信需要高采样率的模数转换，但传统方法功耗大。Walsh-Hadamard交织转换器能以较低功耗实现高采样率转换，但需要设计适配的通信算法。研究如何让端到端训练的神经编码调制透明适应WH收发器硬件，无需算法重新设计。

Method: 提出WH域自动编码器系统，利用WH交织转换器进行模拟WH变换。在短块长度下训练WH-AE，与标准神经基线和传统基线（包括5G Polar码）进行对比。量化系统级能量权衡：基带计算、信道SNR和模拟转换器功耗。

Result: WH-AE系统能在0.14dB内接近传统Polar码的SNR性能，同时消耗相当或更低的系统功率。相比最佳神经基线，WH-AE平均实现29%更高的能量效率（bit/J）。WH域学习能有效平衡计算复杂度、SNR和模拟功耗。

Conclusion: WH域学习是实现高能效、高吞吐宽带通信的可行路径，通过显式平衡计算复杂度、SNR和模拟功耗，为下一代通信系统提供有前景的设计框架。

Abstract: This paper investigates how end-to-end (E2E) channel autoencoders (AEs) can achieve energy-efficient wideband communications by leveraging Walsh-Hadamard (WH) interleaved converters. WH interleaving enables high sampling rate analog-digital conversion with reduced power consumption using an analog WH transformation. We demonstrate that E2E-trained neural coded modulation can transparently adapt to the WH-transceiver hardware without requiring algorithmic redesign. Focusing on the short block length regime, we train WH-domain AEs and benchmark them against standard neural and conventional baselines, including 5G Polar codes. We quantify the system-level energy tradeoffs among baseband compute, channel signal-to-noise ratio (SNR), and analog converter power. Our analysis shows that the proposed WH-AE system can approach conventional Polar code SNR performance within 0.14dB while consuming comparable or lower system power. Compared to the best neural baseline, WH-AE achieves, on average, 29% higher energy efficiency (in bit/J) for the same reliability. These findings establish WH-domain learning as a viable path to energy-efficient, high-throughput wideband communications by explicitly balancing compute complexity, SNR, and analog power consumption.

</details>


### [43] [Coding Schemes for the Noisy Torn Paper Channel](https://arxiv.org/abs/2601.11501)
*Frederik Walter,Maria Abu-Sini,Nils Weinhardt,Antonia Wachter-Zeh*

Main category: cs.IT

TL;DR: 该论文研究DNA存储中的衰变过程，将其建模为概率性噪声撕纸信道，并提出使用静态标记和基于哈希函数的数据相关标记两种编码方案来应对噪声和序列断裂问题。


<details>
  <summary>Details</summary>
Motivation: 为了使DNA成为适合档案数据存储的介质，必须考虑DNA存储系统中观察到的链衰变过程。DNA衰变会导致序列损坏和断裂，需要有效的编码方案来确保数据可靠恢复。

Method: 将DNA衰变过程建模为概率性噪声撕纸信道（TPC），该信道首先通过替换概率性损坏传输序列的比特，然后将序列分解为一组无序的噪声子字符串。设计了两种编码方案：1）在传输序列中嵌入静态标记；2）使用与数据连接的标记（基于哈希函数）。

Result: 模拟显示：静态标记在较高替换概率下表现更好，而数据相关标记在较低噪声水平下更优。两种方法都能实现超过99%的重建率，且未观察到错误解码，主要受计算资源限制。

Conclusion: 该研究为DNA存储中的衰变问题提供了有效的编码解决方案，静态标记和数据相关标记在不同噪声条件下各有优势，都能实现高可靠性的数据重建，为DNA档案存储的实际应用奠定了基础。

Abstract: To make DNA a suitable medium for archival data storage, it is essential to consider the decay process of the strands observed in DNA storage systems. This paper studies the decay process as a probabilistic noisy torn paper channel (TPC), which first corrupts the bits of the transmitted sequence in a probabilistic manner by substitutions, then breaks the sequence into a set of noisy unordered substrings. The present work devises coding schemes for the noisy TPC by embedding markers in the transmitted sequence. We investigate the use of static markers and markers connected to the data in the form of hash functions. These two tools have also been recently exploited to tackle the noiseless TPC. Simulations show that static markers excel at higher substitution probabilities, while data-dependent markers are superior at lower noise levels. Both approaches achieve reconstruction rates exceeding $99\%$ with no false decodings observed, primarily limited by computational resources.

</details>


### [44] [Empirical Coordination over Markov Channel with Independent Source](https://arxiv.org/abs/2601.11520)
*Mengyuan Zhao,Maël Le Treust,Tobias J. Oechtering*

Main category: cs.IT

TL;DR: 研究马尔可夫信道下的联合信源信道编码，通过经验协调框架确定编码方案可诱导的信源与信道符号联合分布，主要贡献是建立了可达联合分布集的单字母内外界。


<details>
  <summary>Details</summary>
Motivation: 传统基于块独立的编码方案在处理马尔可夫信道时存在局限，需要直接利用马尔可夫信道结构来改进性能，特别是在严格因果编码器（无法访问过去信道状态）的情况下。

Method: 提出输入驱动的马尔可夫典型性新概念，并发展其基本性质；采用经验协调框架分析严格因果编码器，直接利用马尔可夫信道结构而非传统的块独立假设。

Result: 建立了可达联合分布集的单字母内外界，协调网络中的所有符号；新方法超越了基于独立性的论证，为马尔可夫信道提供了更优的性能界限。

Conclusion: 通过引入输入驱动的马尔可夫典型性概念，成功分析了马尔可夫信道下的联合信源信道编码问题，为严格因果编码器提供了理论框架，并超越了传统基于独立性的方法。

Abstract: We study joint source-channel coding over Markov channels through the empirical coordination framework. More specifically, we aim at determining the empirical distributions of source and channel symbols that can be induced by a coding scheme. We consider strictly causal encoders that generate channel inputs, without access to the past channel states, henceforth driving the current Markov state evolution. Our main result is the single-letter inner and outer bounds of the set of achievable joint distributions, coordinating all the symbols in the network. To establish the inner bound, we introduce a new notion of typicality, the input-driven Markov typicality, and develop its fundamental properties. Contrary to the classical block-Markov coding schemes that rely on blockwise independence for discrete memoryless channels, our analysis directly exploits the Markov channel structure and improves beyond the independence-based arguments.

</details>
