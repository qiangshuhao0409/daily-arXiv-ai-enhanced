{"id": "2511.02951", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.02951", "abs": "https://arxiv.org/abs/2511.02951", "authors": ["Sheida Rabeti", "Hessam Mahdavifar"], "title": "List Decoding and New Bicycle Code Constructions for Quantum LDPC Codes", "comment": null, "summary": "In this paper, we propose a new decoder, called the Multiple-Bases\nBelief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check\n(QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP)\nframework, originally developed for classical cyclic LDPC codes. The proposed\nmethod preserves the linear-time complexity of standard BP decoder while\nimproving the logical error rate. To further reduce the logical error rate, a\nnew decision rule is introduced for the post-processing list decoder,\noutperforming the conventional least-metric selector (LMS) criterion. For the\nrecently developed and implemented bivariate bicycle (BB) code with parameters\n\\([[144,12,12]]\\), our proposed MBBP-LD decoder achieves up to 40\\% lower\nlogical error rate compared to the state-of-the-art decoder for short QLDPC\ncodes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the\nlinear-time complexity of the plain BP decoder. In addition, we explore a new\nsubclass of BB codes, that we refer to as the univariate bicycle (UB) codes,\nspecifically with lower-weight parity checks (\\(w=6,8\\)). This reduces the\npolynomial search space for the code compared to general BB codes, i.e., by\nreducing the search space over two polynomial components in BB codes to just a\nsingle polynomial component in UB codes. Simulations demonstrate the promising\nperformance of these codes under various types of BP decoders."}
{"id": "2511.03063", "categories": ["cs.IT", "cs.CE", "math.IT", "H.1.1; J.3"], "pdf": "https://arxiv.org/pdf/2511.03063", "abs": "https://arxiv.org/abs/2511.03063", "authors": ["Margarita Geleta", "Daniel Mas Montserrat", "Alexander G. Ioannidis"], "title": "A Tsallis-Entropy Lens on Genetic Variation", "comment": "5 pages, 2 figures", "summary": "We introduce an information-theoretic generalization of the fixation\nstatistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the\nfraction of Tsallis $q$-entropy lost within subpopulations relative to the\npooled population. The family nests the classical variance-based fixation index\n$F_{\\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose\nabsolute form equals the mutual information between alleles and population\nlabels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights\nrare variants at low $q$, while $q{>}1$ increasingly emphasizes common\nvariants, providing a more fine-grained view of differentiation than\n$F_{\\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865\nOceanian genomes with 1,823,000 sites) and controlled genealogical simulations\n(seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216\nsites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes\nprovides clear attribution of which subpopulations drive regional structure,\nand sensitively timestamps isolation-migration events and founder effects.\n$F_q$ serves as finer-resolution complement for simulation audits and\npopulation-structure summaries."}
{"id": "2511.03305", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.03305", "abs": "https://arxiv.org/abs/2511.03305", "authors": ["Haoqin Zhao", "Zan Li", "Jiangbo Si", "Rui Huang", "Hang Hu", "Tony Q. S. Quek", "Naofal Al-Dhahir"], "title": "DRL-Based Robust Multi-Timescale Anti-Jamming Approaches under State Uncertainty", "comment": "13pages,12figures", "summary": "Owing to the openness of wireless channels, wireless communication systems\nare highly susceptible to malicious jamming. Most existing anti-jamming methods\nrely on the assumption of accurate sensing and optimize parameters on a single\ntimescale. However, such methods overlook two practical issues: mismatched\nexecution latencies across heterogeneous actions and measurement errors caused\nby sensor imperfections. Especially for deep reinforcement learning (DRL)-based\nmethods, the inherent sensitivity of neural networks implies that even minor\nperturbations in the input can mislead the agent into choosing suboptimal\nactions, with potentially severe consequences. To ensure reliable wireless\ntransmission, we establish a multi-timescale decision model that incorporates\nstate uncertainty. Subsequently, we propose two robust schemes that sustain\nperformance under bounded sensing errors. First, a Projected Gradient\nDescent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which\nderives worst-case perturbations under a norm-bounded error model and applies\nPGD during training for robust optimization. Second, a Nonlinear Q-Compression\nDDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that\nadaptively contracts Q-value ranges to eliminate action aliasing. Simulation\nresults indicate that, compared with the perfect-sensing baseline, the proposed\nalgorithms show only minor degradation in anti-jamming performance while\nmaintaining robustness under various perturbations, thereby validating their\npracticality in imperfect sensing conditions."}
{"id": "2511.02952", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.02952", "abs": "https://arxiv.org/abs/2511.02952", "authors": ["Zhenzhou Qi", "Yuncheng Yao", "Yiming Li", "Chung-Hsuan Tung", "Junyao Zheng", "Danyang Zhuo", "Tingjun Chen"], "title": "DecodeX: Exploring and Benchmarking of LDPC Decoding across CPU, GPU, and ASIC Platforms", "comment": null, "summary": "Emerging virtualized radio access networks (vRANs) demand flexible and\nefficient baseband processing across heterogeneous compute substrates. In this\npaper, we present DecodeX, a unified benchmarking framework for evaluating\nlow-density parity-check (LDPC) decoding acceleration across different hardware\nplatforms. DecodeX integrates a comprehensive suite of LDPC decoder\nimplementations, including kernels, APIs, and test vectors for CPUs (FlexRAN),\nGPUs (Aerial and Sionna-RK), and ASIC (ACC100), and can be readily extended to\nadditional architectures and configurations. Using DecodeX, we systematically\ncharacterize how different platforms orchestrate computation-from threading and\nmemory management to data movement and accelerator offload-and quantify the\nresulting decoding latency under varying Physical layer parameters. Our\nobservations reveal distinct trade-offs in parallel efficiency and offload\noverhead, showing that accelerator gains strongly depend on data-movement and\nworkload granularity. Building on these insights, we discuss how cross-platform\nbenchmarking can inform adaptive scheduling and co-design for future\nheterogeneous vRANs, enabling scalable and energy-efficient baseband processing\nfor NextG wireless systems."}
{"id": "2511.03323", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.03323", "abs": "https://arxiv.org/abs/2511.03323", "authors": ["Zekai Chen", "Min Sha"], "title": "Constacyclic codes with best-known parameters", "comment": null, "summary": "In this paper, we construct several infinite families of $q$-ary constacyclic\ncodes over a finite field $\\mathbb{F}_q$ with length $n$, dimension around\n$n/2$, and minimum distance at least $cn/\\log_q n$ for some positive constant\n$c$. They contain many constacyclic codes with optimal, or almost-optimal, or\nbest-known parameters. We also consider various forms of the length $n$."}
{"id": "2511.03039", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03039", "abs": "https://arxiv.org/abs/2511.03039", "authors": ["Yiming Zheng", "Haoran Qi", "Lirui Yu", "Zhan Shu", "Qing Zhao"], "title": "Distributed Incast Detection in Data Center Networks", "comment": null, "summary": "Incast traffic in data centers can lead to severe performance degradation,\nsuch as packet loss and increased latency. Effectively addressing incast\nrequires prompt and accurate detection. Existing solutions, including MA-ECN,\nBurstRadar and Pulser, typically rely on fixed thresholds of switch port egress\nqueue lengths or their gradients to identify microburst caused by incast flows.\nHowever, these queue length related methods often suffer from delayed detection\nand high error rates. In this study, we propose a distributed incast detection\nmethod for data center networks at the switch-level, leveraging a probabilistic\nhypothesis test with an optimal detection threshold. By analyzing the arrival\nintervals of new flows, our algorithm can immediately determine if a flow is\npart of an incast traffic from its initial packet. The experimental results\ndemonstrate that our method offers significant improvements over existing\napproaches in both detection speed and inference accuracy."}
{"id": "2511.02997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02997", "abs": "https://arxiv.org/abs/2511.02997", "authors": ["Jon Kutasov", "Chloe Loughridge", "Yuqi Sun", "Henry Sleight", "Buck Shlegeris", "Tyler Tracy", "Joe Benton"], "title": "Evaluating Control Protocols for Untrusted AI Agents", "comment": null, "summary": "As AI systems become more capable and widely deployed as agents, ensuring\ntheir safe operation becomes critical. AI control offers one approach to\nmitigating the risk from untrusted AI agents by monitoring their actions and\nintervening or auditing when necessary. Evaluating the safety of these\nprotocols requires understanding both their effectiveness against current\nattacks and their robustness to adaptive adversaries. In this work, we\nsystematically evaluate a range of control protocols in SHADE-Arena, a dataset\nof diverse agentic environments. First, we evaluate blue team protocols,\nincluding deferral to trusted models, resampling, and deferring on critical\nactions, against a default attack policy. We find that resampling for\nincrimination and deferring on critical actions perform best, increasing safety\nfrom 50% to 96%. We then iterate on red team strategies against these protocols\nand find that attack policies with additional affordances, such as knowledge of\nwhen resampling occurs or the ability to simulate monitors, can substantially\nimprove attack success rates against our resampling strategy, decreasing safety\nto 17%. However, deferring on critical actions is highly robust to even our\nstrongest red team strategies, demonstrating the importance of denying attack\npolicies access to protocol internals."}
{"id": "2511.03039", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03039", "abs": "https://arxiv.org/abs/2511.03039", "authors": ["Yiming Zheng", "Haoran Qi", "Lirui Yu", "Zhan Shu", "Qing Zhao"], "title": "Distributed Incast Detection in Data Center Networks", "comment": null, "summary": "Incast traffic in data centers can lead to severe performance degradation,\nsuch as packet loss and increased latency. Effectively addressing incast\nrequires prompt and accurate detection. Existing solutions, including MA-ECN,\nBurstRadar and Pulser, typically rely on fixed thresholds of switch port egress\nqueue lengths or their gradients to identify microburst caused by incast flows.\nHowever, these queue length related methods often suffer from delayed detection\nand high error rates. In this study, we propose a distributed incast detection\nmethod for data center networks at the switch-level, leveraging a probabilistic\nhypothesis test with an optimal detection threshold. By analyzing the arrival\nintervals of new flows, our algorithm can immediately determine if a flow is\npart of an incast traffic from its initial packet. The experimental results\ndemonstrate that our method offers significant improvements over existing\napproaches in both detection speed and inference accuracy."}
{"id": "2511.03398", "categories": ["cs.IT", "math.IT", "94B05, 11T71", "E.4"], "pdf": "https://arxiv.org/pdf/2511.03398", "abs": "https://arxiv.org/abs/2511.03398", "authors": ["Zhonghao Liang", "Chenlu Jia", "Qunying Liao"], "title": "The (+)-(L, P)-TGRS code", "comment": "23pages", "summary": "The construction of the non-Reed-Solomon (in short, non-RS) type linear code\nhas been one of the research hotspots in recent years. In 2025, Hu et al.\nconstructed some non-RS MDS codes by defining the (L, P)-twisted generalized\nReed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the\n(+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we\ngive a sufficient and necessary condition for C to be NMDS which partially\nanswers two open problems proposed by Hu et al. in 2025, and prove that C is\nnon-RS for 2k > n which partially improves the corresponding result given by Hu\net al. in 2025,. Thirdly, we give a sufficient condition for C not to be\nself-dual or self-orthogonal, respectively, furthermore, we construct two\nclasses of self-orthogonal codes which is a promotion of the corresponding\nresult given by Ding et al. in 2025. Finally, some examples are given."}
{"id": "2511.03081", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.03081", "abs": "https://arxiv.org/abs/2511.03081", "authors": ["Pragya Sharma", "Amanda Xiang", "Abbas Kiani", "John Kaippallimalil", "Tony Saboorian", "Haining Wang"], "title": "CRSF: Enabling QoS-Aware Beyond-Connectivity Service Sharing in 6G Local Networks", "comment": null, "summary": "Sixth-generation (6G) networks are envisioned to support interconnected local\nsubnetworks that can share specialized, beyond-connectivity services. However,\na standardized architecture for discovering and selecting these services across\nnetwork boundaries has not existed yet. To address this gap, this paper\nintroduces the Central Repository and Selection Function (CRSF), a novel\nnetwork function for the 6G core that facilitates efficient inter-subnetwork\nservice discovery and selection. We formulate the selection process as a\nQoS-aware optimization problem designed to balance service quality metrics with\nuser-defined priorities. We evaluate our system model through simulations for a\nsensing service scenario and observe a consistently higher aggregate Quality of\nService (QoS) compared to the baseline selection strategy. The proposed CRSF\nprovides a foundational and extensible mechanism for building standardized,\ncollaborative, and service-centric interconnected networks essential for the 6G\nera."}
{"id": "2511.03023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03023", "abs": "https://arxiv.org/abs/2511.03023", "authors": ["Sina Montazeri", "Yunhe Feng", "Kewei Sha"], "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework", "comment": null, "summary": "Open data repositories hold potential for evidence-based decision-making, yet\nare inaccessible to non-experts lacking expertise in dataset discovery, schema\nmapping, and statistical analysis. Large language models show promise for\nindividual tasks, but end-to-end analytical workflows expose fundamental\nlimitations: attention dilutes across growing contexts, specialized reasoning\npatterns interfere, and errors propagate undetected. We present PublicAgent, a\nmulti-agent framework that addresses these limitations through decomposition\ninto specialized agents for intent clarification, dataset discovery, analysis,\nand reporting. This architecture maintains focused attention within agent\ncontexts and enables validation at each stage. Evaluation across five models\nand 50 queries derives five design principles for multi-agent LLM systems.\nFirst, specialization provides value independent of model strength--even the\nstrongest model shows 97.5% agent win rates, with benefits orthogonal to model\nscale. Second, agents divide into universal (discovery, analysis) and\nconditional (report, intent) categories. Universal agents show consistent\neffectiveness (std dev 12.4%) while conditional agents vary by model (std dev\n20.5%). Third, agents mitigate distinct failure modes--removing discovery or\nanalysis causes catastrophic failures (243-280 instances), while removing\nreport or intent causes quality degradation. Fourth, architectural benefits\npersist across task complexity with stable win rates (86-92% analysis, 84-94%\ndiscovery), indicating workflow management value rather than reasoning\nenhancement. Fifth, wide variance in agent effectiveness across models (42-96%\nfor analysis) requires model-aware architecture design. These principles guide\nwhen and why specialization is necessary for complex analytical workflows while\nenabling broader access to public data through natural language interfaces."}
{"id": "2511.03415", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.03415", "abs": "https://arxiv.org/abs/2511.03415", "authors": ["Xusheng Zhu", "Farshad Rostami Ghadi", "Tuo Wu", "Kaitao Meng", "Chao Wang", "Gui Zhou"], "title": "On the Fundamental Scaling Laws of Fluid Antenna Systems", "comment": null, "summary": "Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless\ncommunication by exploiting spatial diversity, yet a rigorous analytical\nframework for their error probability has been notably absent. To this end,\nthis paper addresses this critical gap by unveiling the \\textbf{fundamental\nscaling laws} that govern the symbol error rate (SER) of FAS in realistic,\nspatially correlated channels. To establish these laws, we derive a tight,\nclosed-form asymptotic expression for the SER applicable to a general class of\nmodulation schemes. This result is pivotal as it establishes the fundamental\nscaling law governing the relationship between SER and the channel's spatial\ncorrelation structure. Based on this framework, we provide a complete\ncharacterization of the diversity and coding gains. The analysis culminates in\na definitive design directive: SER can be fundamentally improved by expanding\nthe antenna's movement space to increase diversity, while merely increasing\nport density within a constrained space yields diminishing returns."}
{"id": "2511.03116", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.03116", "abs": "https://arxiv.org/abs/2511.03116", "authors": ["Moinak Ghoshal", "Imran Khan", "Phuc Dinh", "Z. Jonny Kong", "Omar Basit", "Sizhe Wang", "Yufei Feng", "Y. Charlie Hu", "Dimitrios Koutsonikolas"], "title": "Handover Configurations in Operational 5G Networks: Diversity, Evolution, and Impact on Performance", "comment": null, "summary": "Mobility management in cellular networks, especially the handover (HO)\nprocess, plays a key role in providing seamless and ubiquitous Internet access.\nThe wide-scale deployment of 5G and the resulting co-existence of 4G/5G in the\npast six years have significantly changed the landscape of all mobile network\noperators and made the HO process much more complex than before. While several\nrecent works have studied the impact of HOs on user experience, why and how HOs\noccur and how HO configurations affect performance in 5G operational networks\nremains largely unknown. Through four cross-country driving trips across the US\nspread out over a 27-month period, we conduct an in-depth measurement study of\nHO configurations across all three major US operators. Our study reveals (a)\nnew types of HOs and new HO events used by operators to handle these new types\nof HOs, (b) overly aggressive HO configurations that result in unnecessarily\nhigh signaling overhead, (c) large diversity in HO configuration parameter\nvalues, which also differ across operators, but significantly lower diversity\nin 5G compared to LTE, and (d) sub-optimal HO configurations/decisions leading\nto poor pre- or post-HO performance. Our findings have many implications for\nmobile operators, as they keep fine-tuning their 5G HO configurations."}
{"id": "2511.03051", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.03051", "abs": "https://arxiv.org/abs/2511.03051", "authors": ["Tao Zhang", "Kehui Yao", "Luyi Ma", "Jiao Chen", "Reza Yousefi Maragheh", "Kai Zhao", "Jianpeng Xu", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "title": "No-Human in the Loop: Agentic Evaluation at Scale for Recommendation", "comment": "4 page, NeurIPS 2025 Workshop: Evaluating the Evolving LLM Lifecycle", "summary": "Evaluating large language models (LLMs) as judges is increasingly critical\nfor building scalable and trustworthy evaluation pipelines. We present\nScalingEval, a large-scale benchmarking study that systematically compares 36\nLLMs, including GPT, Gemini, Claude, and Llama, across multiple product\ncategories using a consensus-driven evaluation protocol. Our multi-agent\nframework aggregates pattern audits and issue codes into ground-truth labels\nvia scalable majority voting, enabling reproducible comparison of LLM\nevaluators without human annotation. Applied to large-scale complementary-item\nrecommendation, the benchmark reports four key findings: (i) Anthropic Claude\n3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers\nthe best overall performance across categories; (iii) GPT-4o provides the most\nfavorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among\nopen-source models. Category-level analysis shows strong consensus in\nstructured domains (Electronics, Sports) but persistent disagreement in\nlifestyle categories (Clothing, Food). These results establish ScalingEval as a\nreproducible benchmark and evaluation protocol for LLMs as judges, with\nactionable guidance on scaling, reliability, and model family tradeoffs."}
{"id": "2511.03632", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.03632", "abs": "https://arxiv.org/abs/2511.03632", "authors": ["Cemil Vahapoglu", "Timothy J. O'Shea", "Wan Liu", "Sennur Ulukus"], "title": "Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility Environments", "comment": null, "summary": "Beamforming has significance for enhancing spectral efficiency and mitigating\ninterference in multi-antenna wireless systems, facilitating spatial\nmultiplexing and diversity in dense and high mobility scenarios. Traditional\nbeamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean\nsquare error (MMSE) beamforming experience performance deterioration under\nadverse channel conditions. Deep learning-based beamforming offers an\nalternative with nonlinear mappings from channel state information (CSI) to\nbeamforming weights by improving robustness against dynamic channel\nenvironments. Transformer-based models are particularly effective due to their\nability to model long-range dependencies across time and frequency. However,\ntheir quadratic attention complexity limits scalability in large OFDM grids.\nRecent studies address this issue through sparse attention mechanisms that\nreduce complexity while maintaining expressiveness, yet often employ patterns\nthat disregard channel dynamics, as they are not specifically designed for\nwireless communication scenarios. In this work, we propose a Doppler-aware\nSparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that\nincorporates a channel-adaptive sparse attention mechanism in a multi-user\nsingle-input multiple-output (MU-SIMO) setting. The proposed sparsity structure\nis configurable along 2D time-frequency axes based on channel dynamics and is\ntheoretically proven to ensure full connectivity within p hops, where p is the\nnumber of attention heads. Simulation results under urban macro (UMa) channel\nconditions show that Doppler-aware Sparse NNBF significantly outperforms both a\nfixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional\nbeamforming techniques ZFBF and MMSE beamforming in high mobility scenarios,\nwhile maintaining structured sparsity with a controlled number of attended keys\nper query."}
{"id": "2511.03159", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.03159", "abs": "https://arxiv.org/abs/2511.03159", "authors": ["Shuting Qiu", "Fang Dong", "Siyu Tan", "Ruiting Zhou", "Dian Shen", "Patrick P. C. Lee", "Qilin Fan"], "title": "Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing", "comment": null, "summary": "Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near\nend-users, providing low-latency services and improving users' quality of\nexperience (QoE). However, caching all DNN models at edge servers with limited\ncapacity is difficult, and the impact of model loading time on QoE remains\nunderexplored. Hence, we introduce dynamic DNNs in edge scenarios,\ndisassembling a complete DNN model into interrelated submodels for more\nfine-grained and flexible model caching and request routing solutions. This\nraises the pressing issue of jointly deciding request routing and submodel\ncaching for dynamic DNNs to balance model inference precision and loading\nlatency for QoE optimization. In this paper, we study the joint dynamic model\ncaching and request routing problem in MEC networks, aiming to maximize user\nrequest inference precision under constraints of server resources, latency, and\nmodel loading time. To tackle this problem, we propose CoCaR, an offline\nalgorithm based on linear programming and random rounding that leverages\ndynamic DNNs to optimize caching and routing schemes, achieving near-optimal\nperformance. Furthermore, we develop an online variant of CoCaR, named\nCoCaR-OL, enabling effective adaptation to dynamic and unpredictable online\nrequest patterns. The simulation results demonstrate that the proposed CoCaR\nimproves the average inference precision of user requests by 46\\% compared to\nstate-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves\nan improvement of no less than 32.3\\% in user QoE over competitive baselines."}
{"id": "2511.03070", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.03070", "abs": "https://arxiv.org/abs/2511.03070", "authors": ["Drago Plecko", "Patrik Okanovic", "Torsten Hoefler", "Elias Bareinboim"], "title": "Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge", "comment": null, "summary": "Artificial intelligence (AI) systems hold great promise for advancing various\nscientific disciplines, and are increasingly used in real-world applications.\nDespite their remarkable progress, further capabilities are expected in order\nto achieve more general types of intelligence. A critical distinction in this\ncontext is between factual knowledge, which can be evaluated against true or\nfalse answers (e.g., \"what is the capital of England?\"), and probabilistic\nknowledge, reflecting probabilistic properties of the real world (e.g., \"what\nis the sex of a computer science graduate in the US?\"). In this paper, our goal\nis to build a benchmark for understanding the capabilities of LLMs in terms of\nknowledge of probability distributions describing the real world. Given that\nLLMs are trained on vast amounts of text, it may be plausible that they\ninternalize aspects of these distributions. Indeed, LLMs are touted as powerful\nuniversal approximators of real-world distributions. At the same time,\nclassical results in statistics, known as curse of dimensionality, highlight\nfundamental challenges in learning distributions in high dimensions,\nchallenging the notion of universal distributional learning. In this work, we\ndevelop the first benchmark to directly test this hypothesis, evaluating\nwhether LLMs have access to empirical distributions describing real-world\npopulations across domains such as economics, health, education, and social\nbehavior. Our results demonstrate that LLMs perform poorly overall, and do not\nseem to internalize real-world statistics naturally. When interpreted in the\ncontext of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that\nlanguage models do not contain knowledge on observational distributions (Layer\n1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional\n(Layer 2) and counterfactual (Layer 3) knowledge of these models is also\nlimited."}
{"id": "2511.03312", "categories": ["cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03312", "abs": "https://arxiv.org/abs/2511.03312", "authors": ["Jiali Xu", "Valeria Loscri", "Romain Rouvoy"], "title": "Integrity Under Siege: A Rogue gNodeB's Manipulation of 5G Network Slice Allocation", "comment": "15 pages, 11 figures, Elsevier journal paper layout", "summary": "The advent of 5G networks, with network slicing as a cornerstone technology,\npromises customized, high-performance services, but also introduces novel\nattack surfaces beyond traditional threats. This article investigates a\ncritical and underexplored integrity vulnerability: the manipulation of network\nslice allocation to compromise Quality of Service (QoS) and resource integrity.\nWe introduce a threat model, grounded in a risk analysis of permissible yet\ninsecure configurations like null-ciphering (5G-EA0), demonstrating how a rogue\ngNodeB acting as a Man-in-the-Middle can exploit protocol weaknesses to forge\nslice requests and hijack a User Equipment's (UE) connection. Through a\ncomprehensive experimental evaluation on a 5G testbed, we demonstrate the\nattack's versatile and severe impacts. Our findings show this integrity breach\ncan manifest as obvious QoS degradation, such as a 95% bandwidth reduction and\n150% latency increase when forcing UE to a suboptimal slice, or as stealthy\nslice manipulation that is indistinguishable from benign network operation and\ngenerates no core network errors. Furthermore, we validate a systemic resource\ncontamination attack where redirecting a crowd of UE orchestrates a\nDenial-of-Service, causing packet loss to exceed 60% and inducing measurable\nCPU saturation (~80%) on core network User Plane Functions (UPFs). Based on\nthese results, we discuss the profound implications for Service Level\nAgreements (SLAs) and critical infrastructure. We propose concrete, cross-layer\nmitigation strategies for network operators as future work, underscoring the\nurgent need to secure the integrity of dynamic resource management in 5G\nnetworks."}
{"id": "2511.03092", "categories": ["cs.AI", "cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03092", "abs": "https://arxiv.org/abs/2511.03092", "authors": ["Jonathan Li", "Nasim Farahini", "Evgenii Iuliugin", "Magnus Vesterlund", "Christian Haggstrom", "Guangtao Wang", "Shubhangi Upasani", "Ayush Sachdeva", "Rui Li", "Faline Fu", "Chen Wu", "Ayesha Siddiqua", "John Long", "Tuowen Zhao", "Matheen Musaddiq", "Hakan Zeffer", "Yun Du", "Mingran Wang", "Qinghua Li", "Bo Li", "Urmish Thakker", "Raghu Prabhakar"], "title": "SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators", "comment": null, "summary": "The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+\ncontext length support have resulted in increasing demands for on-chip memory\nto support large KV caches. Techniques such as StreamingLLM and SnapKV\ndemonstrate how to control KV cache size while maintaining model accuracy. Yet,\nthese techniques are not commonly used within industrial deployments using\nframeworks like vLLM or SGLang. The reason is twofold: on one hand, the static\ngraphs and continuous batching methodology employed by these frameworks make it\ndifficult to admit modifications to the standard multi-head attention\nalgorithm, while on the other hand, the accuracy implications of such\ntechniques on modern instruction-following and reasoning models are not well\nunderstood, obfuscating the need for implementing these techniques. In this\npaper, we explore these accuracy implications on Llama-3.1-8B-Instruct and\nDeepSeek-R1, and develop SnapStream, a KV cache compression method that can be\ndeployed at scale. We demonstrate the efficacy of SnapStream in a 16-way\ntensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators\nrunning at 128k context length and up to 1832 tokens per second in a real\nproduction setting. SnapStream enables $4\\times$ improved on-chip memory usage\nand introduces minimal accuracy degradation on LongBench-v2, AIME24 and\nLiveCodeBench. To the best of our knowledge, this is the first implementation\nof sparse KV attention techniques deployed in a production inference system\nwith static graphs and continuous batching."}
{"id": "2511.03106", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03106", "abs": "https://arxiv.org/abs/2511.03106", "authors": ["Katherine C. Kellogg", "Bingyang Ye", "Yifan Hu", "Guergana K. Savova", "Byron Wallace", "Danielle S. Bitterman"], "title": "Large language models require a new form of oversight: capability-based monitoring", "comment": "Under review", "summary": "The rapid adoption of large language models (LLMs) in healthcare has been\naccompanied by scrutiny of their oversight. Existing monitoring approaches,\ninherited from traditional machine learning (ML), are task-based and founded on\nassumed performance degradation arising from dataset drift. In contrast, with\nLLMs, inevitable model degradation due to changes in populations compared to\nthe training dataset cannot be assumed, because LLMs were not trained for any\nspecific task in any given population. We therefore propose a new organizing\nprinciple guiding generalist LLM monitoring that is scalable and grounded in\nhow these models are developed and used in practice: capability-based\nmonitoring. Capability-based monitoring is motivated by the fact that LLMs are\ngeneralist systems whose overlapping internal capabilities are reused across\nnumerous downstream tasks. Instead of evaluating each downstream task\nindependently, this approach organizes monitoring around shared model\ncapabilities, such as summarization, reasoning, translation, or safety\nguardrails, in order to enable cross-task detection of systemic weaknesses,\nlong-tail errors, and emergent behaviors that task-based monitoring may miss.\nWe describe considerations for developers, organizational leaders, and\nprofessional societies for implementing a capability-based monitoring approach.\nUltimately, capability-based monitoring will provide a scalable foundation for\nsafe, adaptive, and collaborative monitoring of LLMs and future generalist\nartificial intelligence models in healthcare."}
{"id": "2511.03108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03108", "abs": "https://arxiv.org/abs/2511.03108", "authors": ["Azim Ospanov", "Farzan Farnia", "Roozbeh Yousefzadeh"], "title": "miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward", "comment": null, "summary": "We perform a thorough analysis of the formal and informal statements in the\nminiF2F benchmark from the perspective of an AI system that is tasked to\nparticipate in a math Olympiad consisting of the problems in miniF2F. In such\nsetting, the model has to read and comprehend the problems in natural language,\nformalize them in Lean language, then proceed with proving the problems, and it\nwill get credit for each problem if the formal proof corresponds to the\noriginal informal statement presented to the model. Our evaluation results\nreveal that the best accuracy of such pipeline can be about 36% using the SoTA\nmodels in the literature, considerably lower than the individual SoTA\naccuracies, 97% and 69% reported in the autoformalization and theorem proving\nliterature. Analyzing the failure modes, we trace back a considerable portion\nof this drop to discrepancies between the formal and informal statements for\nmore than half of the problems in miniF2F. We proceed with correcting all the\nerrors, discrepancies and simplifications in formal and informal statements,\nand present the miniF2F-v2 with fully verified formal and informal statements\nand proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to\nthe best accuracy of 70%, a significant improvement from the 40% on the\noriginal miniF2F, yet indicating considerable misalignment between the\nautoformalization models and theorem provers. Our deep analysis suggests that a\nhigher quality benchmark can help the community better evaluate progress in the\nfield of formal reasoning and also better diagnose the failure and success\nmodes of autoformalization and theorem proving models. Our dataset is available\nat https://github.com/roozbeh-yz/miniF2F_v2."}
{"id": "2511.03137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03137", "abs": "https://arxiv.org/abs/2511.03137", "authors": ["Shipeng Cen", "Ying Tan"], "title": "Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks", "comment": null, "summary": "As optimization problems grow increasingly complex and diverse, advancements\nin optimization techniques and paradigm innovations hold significant\nimportance. The challenges posed by optimization problems are primarily\nmanifested in their non-convexity, high-dimensionality, black-box nature, and\nother unfavorable characteristics. Traditional zero-order or first-order\nmethods, which are often characterized by low efficiency, inaccurate gradient\ninformation, and insufficient utilization of optimization information, are\nill-equipped to address these challenges effectively. In recent years, the\nrapid development of large language models (LLM) has led to substantial\nimprovements in their language understanding and code generation capabilities.\nConsequently, the design of optimization algorithms leveraging large language\nmodels has garnered increasing attention from researchers. In this study, we\nchoose the fireworks algorithm(FWA) as the basic optimizer and propose a novel\napproach to assist the design of the FWA by incorporating multi-modal large\nlanguage model(MLLM). To put it simply, we propose the concept of Critical\nPart(CP), which extends FWA to complex high-dimensional tasks, and further\nutilizes the information in the optimization process with the help of the\nmulti-modal characteristics of large language models. We focus on two specific\ntasks: the \\textit{traveling salesman problem }(TSP) and \\textit{electronic\ndesign automation problem} (EDA). The experimental results show that FWAs\ngenerated under our new framework have achieved or surpassed SOTA results on\nmany problem instances."}
{"id": "2511.03138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03138", "abs": "https://arxiv.org/abs/2511.03138", "authors": ["Qi Li", "Jianjun Xu", "Pingtao Wei", "Jiu Li", "Peiqiang Zhao", "Jiwei Shi", "Xuan Zhang", "Yanhui Yang", "Xiaodong Hui", "Peng Xu", "Wenqin Shao"], "title": "A Proprietary Model-Based Safety Response Framework for AI Agents", "comment": null, "summary": "With the widespread application of Large Language Models (LLMs), their\nassociated security issues have become increasingly prominent, severely\nconstraining their trustworthy deployment in critical domains. This paper\nproposes a novel safety response framework designed to systematically safeguard\nLLMs at both the input and output levels. At the input level, the framework\nemploys a supervised fine-tuning-based safety classification model. Through a\nfine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused\nAttention), it performs precise risk identification and differentiated handling\nof user queries, significantly enhancing risk coverage and business scenario\nadaptability, and achieving a risk recall rate of 99.3%. At the output level,\nthe framework integrates Retrieval-Augmented Generation (RAG) with a\nspecifically fine-tuned interpretation model, ensuring all responses are\ngrounded in a real-time, trustworthy knowledge base. This approach eliminates\ninformation fabrication and enables result traceability. Experimental results\ndemonstrate that our proposed safety control model achieves a significantly\nhigher safety score on public safety evaluation benchmarks compared to the\nbaseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk\ntest set, the framework's components attained a perfect 100% safety score,\nvalidating their exceptional protective capabilities in complex risk scenarios.\nThis research provides an effective engineering pathway for building\nhigh-security, high-trust LLM applications."}
{"id": "2511.03169", "categories": ["cs.AI", "D.2.4; I.2.6; I.2.4; K.4.1; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03169", "abs": "https://arxiv.org/abs/2511.03169", "authors": ["Xuanxiang Huang", "Yacine Izza", "Alexey Ignatiev", "Joao Marques-Silva"], "title": "Uncovering Bugs in Formal Explainers: A Case Study with PyXAI", "comment": null, "summary": "Formal explainable artificial intelligence (XAI) offers unique theoretical\nguarantees of rigor when compared to other non-formal methods of\nexplainability. However, little attention has been given to the validation of\npractical implementations of formal explainers. This paper develops a novel\nmethodology for validating formal explainers and reports on the assessment of\nthe publicly available formal explainer PyXAI. The paper documents the\nexistence of incorrect explanations computed by PyXAI on most of the datasets\nanalyzed in the experiments, thereby confirming the importance of the proposed\nnovel methodology for the validation of formal explainers."}
{"id": "2511.03179", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03179", "abs": "https://arxiv.org/abs/2511.03179", "authors": ["Varun Kumar", "George Em Karniadakis"], "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework", "comment": null, "summary": "The engineering design process often demands expertise from multiple domains,\nleading to complex collaborations and iterative refinements. Traditional\nmethods can be resource-intensive and prone to inefficiencies. To address this,\nwe formalize the engineering design process through a multi-agent AI framework\nthat integrates structured design and review loops. The framework introduces\nspecialized knowledge-driven agents that collaborate to generate and refine\ndesign candidates. As an exemplar, we demonstrate its application to the\naerodynamic optimization of 4-digit NACA airfoils. The framework consists of\nthree key AI agents: a Graph Ontologist, a Design Engineer, and a Systems\nEngineer. The Graph Ontologist employs a Large Language Model (LLM) to\nconstruct two domain-specific knowledge graphs from airfoil design literature.\nThe Systems Engineer, informed by a human manager, formulates technical\nrequirements that guide design generation and evaluation. The Design Engineer\nleverages the design knowledge graph and computational tools to propose\ncandidate airfoils meeting these requirements. The Systems Engineer reviews and\nprovides feedback both qualitative and quantitative using its own knowledge\ngraph, forming an iterative feedback loop until a design is validated by the\nmanager. The final design is then optimized to maximize performance metrics\nsuch as the lift-to-drag ratio. Overall, this work demonstrates how\ncollaborative AI agents equipped with structured knowledge representations can\nenhance efficiency, consistency, and quality in the engineering design process."}
{"id": "2511.03186", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03186", "abs": "https://arxiv.org/abs/2511.03186", "authors": ["Yiru Chen", "Sally Fang", "Sai Sree Harsha", "Dan Luo", "Vaishnavi Muppala", "Fei Wu", "Shun Jiang", "Kun Qian", "Yunyao Li"], "title": "Adobe Summit Concierge Evaluation with Human in the Loop", "comment": "Accepted by 6th Workshop on Data Science with Human in the Loop @\n  VLDB 2025", "summary": "Generative AI assistants offer significant potential to enhance productivity,\nstreamline information access, and improve user experience in enterprise\ncontexts. In this work, we present Summit Concierge, a domain-specific AI\nassistant developed for Adobe Summit. The assistant handles a wide range of\nevent-related queries and operates under real-world constraints such as data\nsparsity, quality assurance, and rapid deployment. To address these challenges,\nwe adopt a human-in-the-loop development workflow that combines prompt\nengineering, retrieval grounding, and lightweight human validation. We describe\nthe system architecture, development process, and real-world deployment\noutcomes. Our experience shows that agile, feedback-driven development enables\nscalable and reliable AI assistants, even in cold-start scenarios."}
{"id": "2511.03235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03235", "abs": "https://arxiv.org/abs/2511.03235", "authors": ["Yi-Fei Liu", "Yi-Long Lu", "Di He", "Hang Zhang"], "title": "From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers", "comment": null, "summary": "Psychological constructs within individuals are widely believed to be\ninterconnected. We investigated whether and how Large Language Models (LLMs)\ncan model the correlational structure of human psychological traits from\nminimal quantitative inputs. We prompted various LLMs with Big Five Personality\nScale responses from 816 human individuals to role-play their responses on nine\nother psychological scales. LLMs demonstrated remarkable accuracy in capturing\nhuman psychological structure, with the inter-scale correlation patterns from\nLLM-generated responses strongly aligning with those from human data $(R^2 >\n0.89)$. This zero-shot performance substantially exceeded predictions based on\nsemantic similarity and approached the accuracy of machine learning algorithms\ntrained directly on the dataset. Analysis of reasoning traces revealed that\nLLMs use a systematic two-stage process: First, they transform raw Big Five\nresponses into natural language personality summaries through information\nselection and compression, analogous to generating sufficient statistics.\nSecond, they generate target scale responses based on reasoning from these\nsummaries. For information selection, LLMs identify the same key personality\nfactors as trained algorithms, though they fail to differentiate item\nimportance within factors. The resulting compressed summaries are not merely\nredundant representations but capture synergistic information--adding them to\noriginal scores enhances prediction alignment, suggesting they encode emergent,\nsecond-order patterns of trait interplay. Our findings demonstrate that LLMs\ncan precisely predict individual participants' psychological traits from\nminimal data through a process of abstraction and reasoning, offering both a\npowerful tool for psychological simulation and valuable insights into their\nemergent reasoning capabilities."}
{"id": "2511.03471", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03471", "abs": "https://arxiv.org/abs/2511.03471", "authors": ["Ming Gu", "Ziwei Wang", "Sicen Lai", "Zirui Gao", "Sheng Zhou", "Jiajun Bu"], "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots", "comment": "15 pages. Accepted by AAAI 2026 AISI", "summary": "Ensuring web accessibility is crucial for advancing social welfare, justice,\nand equality in digital spaces, yet the vast majority of website user\ninterfaces remain non-compliant, due in part to the resource-intensive and\nunscalable nature of current auditing practices. While WCAG-EM offers a\nstructured methodology for site-wise conformance evaluation, it involves great\nhuman efforts and lacks practical support for execution at scale. In this work,\nwe present an auditing framework, AAA, which operationalizes WCAG-EM through a\nhuman-AI partnership model. AAA is anchored by two key innovations: GRASP, a\ngraph-based multimodal sampling method that ensures representative page\ncoverage via learned embeddings of visual, textual, and relational cues; and\nMaC, a multimodal large language model-based copilot that supports auditors\nthrough cross-modal reasoning and intelligent assistance in high-effort tasks.\nTogether, these components enable scalable, end-to-end web accessibility\nauditing, empowering human auditors with AI-enhanced assistance for real-world\nimpact. We further contribute four novel datasets designed for benchmarking\ncore stages of the audit pipeline. Extensive experiments demonstrate the\neffectiveness of our methods, providing insights that small-scale language\nmodels can serve as capable experts when fine-tuned."}
{"id": "2511.03545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03545", "abs": "https://arxiv.org/abs/2511.03545", "authors": ["Sebastian Ordyniak", "Giacomo Paesani", "Mateusz Rychlicki", "Stefan Szeider"], "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)", "comment": "Part I of a greatly enhanced version of\n  https://doi.org/10.24963/kr.2024/53, whose full version is available on arXiv\n  under https://doi.org/10.48550/arXiv.2407.15780", "summary": "This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,\neach offering unique explanatory challenges. This research fills a significant\ngap in explainable AI (XAI) by providing a foundational understanding of the\ncomplexities of generating explanations for these models. This work provides\ninsights vital for further research in the domain of XAI, contributing to the\nbroader discourse on the necessity of transparency and accountability in AI\nsystems."}
{"id": "2511.03724", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03724", "abs": "https://arxiv.org/abs/2511.03724", "authors": ["Richard Dewey", "Janos Botyanszki", "Ciamac C. Moallemi", "Andrew T. Zheng"], "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning", "comment": null, "summary": "AI researchers have long focused on poker-like games as a testbed for\nenvironments characterized by multi-player dynamics, imperfect information, and\nreasoning under uncertainty. While recent breakthroughs have matched elite\nhuman play at no-limit Texas hold'em, the multi-player dynamics are subdued:\nmost hands converge quickly with only two players engaged through multiple\nrounds of bidding. In this paper, we present Solly, the first AI agent to\nachieve elite human play in reduced-format Liar's Poker, a game characterized\nby extensive multi-player engagement. We trained Solly using self-play with a\nmodel-free, actor-critic, deep reinforcement learning algorithm. Solly played\nat an elite human level as measured by win rate (won over 50% of hands) and\nequity (money won) in heads-up and multi-player Liar's Poker. Solly also\noutperformed large language models (LLMs), including those with reasoning\nabilities, on the same metrics. Solly developed novel bidding strategies,\nrandomized play effectively, and was not easily exploitable by world-class\nhuman players."}
