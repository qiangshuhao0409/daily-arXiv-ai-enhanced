<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.IT](#cs.IT) [Total: 10]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Comprehensive Survey of 5G URLLC and Challenges in the 6G Era](https://arxiv.org/abs/2508.20205)
*Md. Emadul Haque,Faisal Tariq,Muhammad R A Khandaker,Md. Sakir Hossain,Muhammad Ali Imran,Kai-Kit Wong*

Main category: cs.NI

TL;DR: 这篇论文是一个关于5G和6G系统中超高可靠低延迟通信(URLLC)的综述性调研，分析了为实现99.999%可靠性和1ms延迟目标的各种技术方案。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信从人类中心服务向机器中心服务转变，对速率、延迟和可靠性的要求发生了巨大变化，URLLC成为5G/6G的核心主题。

Method: 采用分层方法，详细讨论了物理层、MAC层以及跨层技术，追溯了无线通信中延迟和可靠性问题的历史演变，并涵盖各种5G及更高级垂直领域的设计考虑。

Result: 对5G系统中的URLLC方案进行了全面调研分析，揭示了高可靠性和低延迟这两个目标之间的内在矛盾关系。

Conclusion: 文章最后提供了详细的挑战分析和未来展望，尤其重点关注正在兴起的6G新范式，为下一代无线通信技术的发展指明了方向。

Abstract: As the wireless communication paradigm is being transformed from human
centered communication services towards machine centered communication
services, the requirements of rate, latency and reliability for these services
have also been transformed drastically. Thus the concept of Ultra Reliable and
Low Latency Communication (URLLC) has emerged as a dominant theme for 5G and 6G
systems. Though the latency and reliability requirement varies from one use
case to another, URLLC services generally aim to achieve very high reliability
in the range of 99.999\% while ensuring the latency of up to 1 ms. These two
targets are however inherently opposed to one another. Significant amounts of
work have been carried out to meet these ambitious but conflicting targets. In
this article a comprehensive survey of the URLLC approaches in 5G systems are
analysed in detail. Effort has been made to trace the history and evolution of
latency and reliability issues in wireless communication. A layered approach is
taken where physical layer, Medium Access Control (MAC) layer as well as cross
layer techniques are discussed in detail. It also covers the design
consideration for various 5G and beyond verticals. Finally the article
concludes by providing a detailed discussion on challenges and future outlook
with particular focus on the emerging 6G paradigm.

</details>


### [2] [DRR-MDPF: A Queue Management Strategy Based on Dynamic Resource Allocation and Markov Decision Process in Named Data Networking (NDN)](https://arxiv.org/abs/2508.20272)
*Fatemeh Roshanzadeh,Hamid Barati,Ali Barati*

Main category: cs.NI

TL;DR: DRR-MDPF是一种结合马尔可夫决策过程转发(MDPF)和赤字轮询(DRR)算法的混合策略，用于命名数据网络(NDN)的队列和资源管理，显著提升了网络性能。


<details>
  <summary>Details</summary>
Motivation: 命名数据网络(NDN)需要高效的队列和资源管理来应对动态高流量环境，传统方法在性能优化方面存在不足。

Method: 将MDPF模型与DRR算法结合，使路由器能够基于带宽、延迟和未满足兴趣数等指标智能预测最优转发决策，同时确保数据流间的公平带宽分配。

Result: 在ndnSIM仿真中，DRR-MDPF在吞吐量、兴趣满足率、丢包率、内容检索时间和负载均衡等多个指标上显著优于SAF、RFA、SMDPF和LA-MDPF等先进策略。

Conclusion: DRR-MDPF为NDN提供了智能、自适应且可扩展的队列管理解决方案，有效解决了动态网络环境中的资源分配、拥塞控制和路由优化等核心挑战。

Abstract: Named Data Networking (NDN) represents a transformative shift in network
architecture, prioritizing content names over host addresses to enhance data
dissemination. Efficient queue and resource management are critical to NDN
performance, especially under dynamic and high-traffic conditions. This paper
introduces DRR-MDPF, a novel hybrid strategy that integrates the Markov
Decision Process Forwarding (MDPF) model with the Deficit Round Robin (DRR)
algorithm. MDPF enables routers to intelligently predict optimal forwarding
decisions based on key metrics such as bandwidth, delay, and the number of
unsatisfied Interests, while DRR ensures fair and adaptive bandwidth allocation
among competing data flows. The proposed method models each router as a
learning agent capable of adjusting its strategies through continuous feedback
and probabilistic updates. Simulation results using ndnSIM demonstrate that
DRR-MDPF significantly outperforms state-of-the-art strategies including SAF,
RFA, SMDPF, and LA-MDPF across various metrics such as throughput, Interest
Satisfaction Rate (ISR), packet drop rate, content retrieval time, and load
balancing. Notably, DRR-MDPF maintains robustness under limited cache sizes and
heavy traffic, offering enhanced adaptability and lower computational
complexity due to its single-path routing design. Furthermore, its multi-metric
decision-making capability enables more accurate interface selection, leading
to optimized network performance. Overall, DRR-MDPF serves as an intelligent,
adaptive, and scalable queue management solution for NDN, effectively
addressing core challenges such as resource allocation, congestion control, and
route optimization in dynamic networking environments.

</details>


### [3] [Relay Selection in Wireless Networks as Restless Bandits](https://arxiv.org/abs/2508.20625)
*Mandar R. Nalavade,Ravindra S. Tomar,Gaurav S. Kasbekar*

Main category: cs.NI

TL;DR: 提出一种基于Whittle指数的中继选择策略，用于解决无线网络中源节点通过多个候选中继向目的地传输数据的问题，旨在最小化数据包在中继节点的平均持有成本


<details>
  <summary>Details</summary>
Motivation: 在无线网络中，当源节点与目的节点之间的直接链路被阻塞时，需要利用多个候选中继转发数据包。每个数据包在中继节点存储都会产生持有成本，需要设计高效的中继选择策略来最小化长期平均总成本

Method: 将问题建模为 restless multi-armed bandit (RMAB) 问题，证明该问题具有Whittle-indexable性质，提出计算每个中继在每个时隙的Whittle指数的方法，选择Whittle指数最小的中继进行数据传输

Result: 通过仿真验证，所提出的策略在平均成本、延迟和吞吐量方面均优于先前工作中提出的中继选择策略

Conclusion: 基于Whittle指数的中继选择策略能够有效解决无线网络中继选择问题，在性能上显著优于现有方法，为RMAB问题在实际通信网络中的应用提供了有效解决方案

Abstract: We consider a wireless network in which a source node needs to transmit a
large file to a destination node. The direct wireless link between the source
and the destination is assumed to be blocked. Multiple candidate relays are
available to forward packets from the source to the destination. A holding cost
is incurred for each packet stored at every relay in each time slot. The
objective is to design a policy for selecting a relay in each time slot to
which the source attempts to send a packet, so as to minimize the expected
long-run time-averaged total packet holding cost at the relays. This problem is
an instance of the restless multi-armed bandit (RMAB) problem, which is
provably hard to solve. We prove that this relay selection problem is
Whittle-indexable, and propose a method to compute the Whittle index of each
relay in every time slot. In each time slot, our relay selection policy
transmits a packet to the relay with the smallest Whittle index. Using
simulations, we show that the proposed policy outperforms the relay selection
policies proposed in prior work in terms of average cost, delay, as well as
throughput.

</details>


### [4] [Digital Twin-Empowered Deep Reinforcement Learning for Intelligent VNF Migration in Edge-Core Networks](https://arxiv.org/abs/2508.20957)
*Faisal Ahmed,Suresh Subramaniam,Motoharu Matsuura,Hiroshi Hasegawa,Shih-Chun Lin*

Main category: cs.NI

TL;DR: 提出基于数字孪生和深度强化学习的VNF迁移框架，联合优化端到端延迟和能耗


<details>
  <summary>Details</summary>
Motivation: 虚拟化网络功能(VNF)快速部署对边缘-核心网络基础设施的低延迟和节能编排提出挑战

Method: 将VNF迁移问题建模为马尔可夫决策过程，采用Advantage Actor-Critic模型，集成多任务变分自编码器和多任务LSTM的数字孪生模块

Result: 仿真结果显示平均端到端延迟和能耗显著降低

Conclusion: 为边缘-核心网络中智能VNF迁移建立了新的性能基准

Abstract: The growing demand for services and the rapid deployment of virtualized
network functions (VNFs) pose significant challenges for achieving low-latency
and energy-efficient orchestration in modern edge-core network infrastructures.
To address these challenges, this study proposes a Digital Twin (DT)-empowered
Deep Reinforcement Learning framework for intelligent VNF migration that
jointly minimizes average end-to-end (E2E) delay and energy consumption. By
formulating the VNF migration problem as a Markov Decision Process and
utilizing the Advantage Actor-Critic model, the proposed framework enables
adaptive and real-time migration decisions. A key innovation of the proposed
framework is the integration of a DT module composed of a multi-task
Variational Autoencoder and a multi-task Long Short-Term Memory network. This
combination collectively simulates environment dynamics and generates
high-quality synthetic experiences, significantly enhancing training efficiency
and accelerating policy convergence. Simulation results demonstrate substantial
performance gains, such as significant reductions in both average E2E delay and
energy consumption, thereby establishing new benchmarks for intelligent VNF
migration in edge-core networks.

</details>


### [5] [RANGAN: GAN-empowered Anomaly Detection in 5G Cloud RAN](https://arxiv.org/abs/2508.20985)
*Douglas Liao,Jiping Luo,Jens Vevstad,Nikolaos Pappas*

Main category: cs.NI

TL;DR: RANGAN是一个结合GAN和transformer的异常检测框架，用于无线接入网络性能监控，通过滑动窗口处理时序数据，在公开数据集上达到83%的F1分数


<details>
  <summary>Details</summary>
Motivation: 无线接入网络(RAN)系统复杂且数据量大，传统方法难以有效检测性能异常，需要能够捕捉时序依赖关系的自适应方法

Method: 提出RANGAN框架，集成生成对抗网络(GAN)和transformer架构，采用滑动窗口方法进行数据预处理以增强时序依赖捕捉能力

Result: 在Spotlight项目的公开RAN性能数据集上验证，RANGAN实现了良好的检测准确率，特别是在识别网络竞争问题时达到83%的F1分数

Conclusion: RANGAN框架有效解决了RAN系统异常检测的挑战，证明了GAN与transformer结合在捕捉时序依赖和检测性能异常方面的有效性

Abstract: Radio Access Network (RAN) systems are inherently complex, requiring
continuous monitoring to prevent performance degradation and ensure optimal
user experience. The RAN leverages numerous key performance indicators (KPIs)
to evaluate system performance, generating vast amounts of data each second.
This immense data volume can make troubleshooting and accurate diagnosis of
performance anomalies more difficult. Furthermore, the highly dynamic nature of
RAN performance demands adaptive methodologies capable of capturing temporal
dependencies to detect anomalies reliably. In response to these challenges, we
introduce \textbf{RANGAN}, an anomaly detection framework that integrates a
Generative Adversarial Network (GAN) with a transformer architecture. To
enhance the capability of capturing temporal dependencies within the data,
RANGAN employs a sliding window approach during data preprocessing. We
rigorously evaluated RANGAN using the publicly available RAN performance
dataset from the Spotlight project \cite{sun-2024}. Experimental results
demonstrate that RANGAN achieves promising detection accuracy, notably
attaining an F1-score of up to $83\%$ in identifying network contention issues.

</details>


### [6] [DSROQ: Dynamic Scheduling and Routing for QoE Management in LEO Satellite Networks](https://arxiv.org/abs/2508.21047)
*Dhiraj Bhattacharjee,Pablo G. Madoery,Abhishek Naik,Halim Yanikomeroglu,Gunes Karabulut Kurt,Stephane Martel,Khaled Ahmed*

Main category: cs.NI

TL;DR: 本文提出了一种基于MCTS的联合路由和带宽分配算法DSROQ，用于优化LEO卫星网络的QoS性能，通过实验证明其在用户体验和公平性方面优于基准方案。


<details>
  <summary>Details</summary>
Motivation: 现代互联网应用具有异构QoS需求，LEO卫星星座需要联合优化路由、带宽分配和队列调度来保证服务质量，特别是在农村覆盖和城市补充网络场景中。

Method: 采用蒙特卡洛树搜索(MCTS)启发方法解决NP难的路由和带宽分配问题，结合Lyapunov优化的调度算法，将QoS要求作为软约束来最大化用户体验。

Result: 在Starlink Phase 1 Version 2星座上的实验表明，DSROQ算法在终端用户体验和公平性方面均优于基准方案，并证明了联合路由带宽决策的优势。

Conclusion: 随着流量敏感性从延迟驱动转向带宽驱动，性能主导因素从调度转向路由和带宽分配，联合优化方法对LEO卫星网络的QoS保障至关重要。

Abstract: The modern Internet supports diverse applications with heterogeneous quality
of service (QoS) requirements. Low Earth orbit (LEO) satellite constellations
offer a promising solution to meet these needs, enhancing coverage in rural
areas and complementing terrestrial networks in urban regions. Ensuring QoS in
such networks requires joint optimization of routing, bandwidth allocation, and
dynamic queue scheduling, as traffic handling is critical for maintaining
service performance. This paper formulates a joint routing and bandwidth
allocation problem where QoS requirements are treated as soft constraints,
aiming to maximize user experience. An adaptive scheduling approach is
introduced to prioritize flow-specific QoS needs. We propose a Monte Carlo tree
search (MCTS)-inspired method to solve the NP-hard route and bandwidth
allocation problem, with Lyapunov optimization-based scheduling applied during
reward evaluation. Using the Starlink Phase 1 Version 2 constellation, we
compare end-user experience and fairness between our proposed DSROQ algorithm
and a benchmark scheme. Results show that DSROQ improves both performance
metrics and demonstrates the advantage of joint routing and bandwidth
decisions. Furthermore, we observe that the dominant performance factor shifts
from scheduling to routing and bandwidth allocation as traffic sensitivity
changes from latency-driven to bandwidth-driven.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Array-Based Monte Carlo Tree Search](https://arxiv.org/abs/2508.20140)
*James Ragan,Fred Y. Hadaegh,Soon-Jo Chung*

Main category: cs.AI

TL;DR: 提出基于数组的MCTS实现方法，消除分支预测需求，在流水线处理器上实现更快性能，搜索深度扩展性提升2.8倍


<details>
  <summary>Details</summary>
Motivation: 传统MCTS实现需要分支预测，限制了在流水线处理器上的性能。通过消除分支预测需求，可以在相同时间内运行更多模拟，直接提升搜索性能

Method: 开发基于数组的替代实现方法，保留原始UCT算法逻辑，但消除分支预测需求

Result: 在流水线处理器上实现更快性能，数值模拟显示搜索深度扩展性提升高达2.8倍

Conclusion: 数组基础的MCTS实现方法能够显著提升算法性能，特别是在搜索深度扩展性方面，为决策问题求解提供更高效的解决方案

Abstract: Monte Carlo Tree Search is a popular method for solving decision making
problems. Faster implementations allow for more simulations within the same
wall clock time, directly improving search performance. To this end, we present
an alternative array-based implementation of the classic Upper Confidence
bounds applied to Trees algorithm. Our method preserves the logic of the
original algorithm, but eliminates the need for branch prediction, enabling
faster performance on pipelined processors, and up to a factor of 2.8 times
better scaling with search depth in our numerical simulations.

</details>


### [8] [ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation](https://arxiv.org/abs/2508.20131)
*Yuqicheng Zhu,Nico Potyka,Daniel Hernández,Yuan He,Zifeng Ding,Bo Xiong,Dongzhuoran Zhou,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: ArgRAG是一个可解释、可争议的检索增强生成框架，使用定量双极论证框架替代黑盒推理，在保持高精度的同时显著提升透明度


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在高风险领域存在关键限制：对噪声或矛盾证据敏感，决策过程不透明且随机，需要更可解释和可争议的替代方案

Method: 提出ArgRAG框架，从检索文档构建定量双极论证框架(QBAF)，在渐进语义下执行确定性推理，实现决策的可解释性和可争议性

Result: 在PubHealth和RAGuard两个事实验证基准测试中，ArgRAG实现了强大的准确性，同时显著提高了透明度

Conclusion: ArgRAG通过结构化论证框架成功解决了传统RAG的透明度和可解释性问题，为高风险领域的可信AI决策提供了有效解决方案

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models by
incorporating external knowledge, yet suffers from critical limitations in
high-stakes domains -- namely, sensitivity to noisy or contradictory evidence
and opaque, stochastic decision-making. We propose ArgRAG, an explainable, and
contestable alternative that replaces black-box reasoning with structured
inference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG
constructs a QBAF from retrieved documents and performs deterministic reasoning
under gradual semantics. This allows faithfully explaining and contesting
decisions. Evaluated on two fact verification benchmarks, PubHealth and
RAGuard, ArgRAG achieves strong accuracy while significantly improving
transparency.

</details>


### [9] [QAgent: An LLM-based Multi-Agent System for Autonomous OpenQASM programming](https://arxiv.org/abs/2508.20134)
*Zhenxiao Fu,Fan Chen,Lei Jiang*

Main category: cs.AI

TL;DR: QAgent是一个基于LLM的多智能体系统，能够完全自动化OpenQASM量子编程，通过集成多种技术显著提升量子代码生成准确率71.6%


<details>
  <summary>Details</summary>
Motivation: NISQ设备已展现出量子优势，但由于OpenQASM编程复杂性，非专家难以利用这些优势。现有LLM代理主要局限于特定任务，缺乏完整的量子编程自动化解决方案

Method: 采用多智能体系统，集成任务规划、上下文少样本学习、检索增强生成(RAG)、预定义生成工具和思维链(CoT)推理，系统性地提升编译和功能正确性

Result: 评估显示QAgent在不同规模的多个LLM上，相比之前的静态LLM方法，将QASM代码生成准确率提高了71.6%

Conclusion: QAgent多智能体系统是民主化量子编程的关键推动者，能够弥合专业知识差距，加速量子计算的实用化采用

Abstract: Noisy Intermediate-Scale Quantum (NISQ) devices have begun to exhibit early
quantum advantages on classically intractable problems, spanning physics
simulations to Gaussian boson sampling. Yet, realizing these benefits remains
challenging for non-experts, primarily due to the complexities of programming
in Open Quantum Assembly Language (OpenQASM). Although Large Language Model
(LLM)-based agents have shown promise in automating classical programming
workflows, their quantum counterparts have largely been restricted to
specialized tasks such as quantum chemistry or error correction. In this paper,
we present QAgent, an LLM-powered multi-agent system that fully automates
OpenQASM programming. By integrating task planning, in-context few-shot
learning, retrieval-augmented generation (RAG) for long-term context,
predefined generation tools, and chain-of-thought (CoT) reasoning, the agents
systematically improve both compilation and functional correctness. Our
evaluations demonstrate substantial improvements: across multiple LLMs of
varying sizes, QAgent enhances the accuracy of QASM code generation by 71.6\%
compared to previous static LLM-based approaches. We envision this multi-agent
system as a key enabler for democratizing quantum programming, bridging
expertise gaps, and accelerating the practical adoption of quantum computing.

</details>


### [10] [The Anatomy of a Personal Health Agent](https://arxiv.org/abs/2508.20148)
*A. Ali Heydari,Ken Gu,Vidya Srinivas,Hong Yu,Zhihan Zhang,Yuwei Zhang,Akshay Paruchuri,Qian He,Hamid Palangi,Nova Hammerquist,Ahmed A. Metwally,Brent Winslow,Yubin Kim,Kumar Ayush,Yuzhe Yang,Girish Narayanswamy,Maxwell A. Xu,Jake Garrison,Amy Aremnto Lee,Jenny Vafeiadou,Ben Graef,Isaac R. Galatzer-Levy,Erik Schenck,Andrew Barakat,Javier Perez,Jacqueline Shreibati,John Hernandez,Anthony Z. Faranesh,Javier L. Prieto,Connor Heneghan,Yun Liu,Jiening Zhan,Mark Malhotra,Shwetak Patel,Tim Althoff,Xin Liu,Daniel McDuff,Xuhai "Orson" Xu*

Main category: cs.AI

TL;DR: 这篇论文提出了个人健康助手（PHA）多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多模态多极简总结：开发个人健康助手（PHA），整合多模态数据，通过三个专业子代理提供个性化健康服务，并进行大规模评估。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的迅速发展为健康领域带来新机遇，但在日常非临床场景下满足个人健康需求的应用仍然不足。需要建立一个综合性的个人健康助手，能够处理多模态数据并提供个性化建议。

Method: 通过分析网络搜索和健康论坛查询，结合用户中心设计过程收集定性见解。识别三类主要健康需求，并开发了包含三个专业子代理的多代理框架：数据科学代理、健康领域专家代理和健康教练代理。

Result: 在10个标准任务上进行了自动化和人工评估，涉及7000多个注释和1100小时的健康专家和用户努力，完成了目前最全面的健康助手评估。

Conclusion: 该研究为实现个人健康助手的未来设想奠定了坚实基础，通过多代理框架有效满足了不同用户的健康需求，为推广普及化健康服务提供了可行方案。

Abstract: Health is a fundamental pillar of human wellness, and the rapid advancements
in large language models (LLMs) have driven the development of a new generation
of health agents. However, the application of health agents to fulfill the
diverse needs of individuals in daily non-clinical settings is underexplored.
In this work, we aim to build a comprehensive personal health agent that is
able to reason about multimodal data from everyday consumer wellness devices
and common personal health records, and provide personalized health
recommendations. To understand end-users' needs when interacting with such an
assistant, we conducted an in-depth analysis of web search and health forum
queries, alongside qualitative insights from users and health experts gathered
through a user-centered design process. Based on these findings, we identified
three major categories of consumer health needs, each of which is supported by
a specialist sub-agent: (1) a data science agent that analyzes personal
time-series wearable and health record data, (2) a health domain expert agent
that integrates users' health and contextual data to generate accurate,
personalized insights, and (3) a health coach agent that synthesizes data
insights, guiding users using a specified psychological strategy and tracking
users' progress. Furthermore, we propose and develop the Personal Health Agent
(PHA), a multi-agent framework that enables dynamic, personalized interactions
to address individual health needs. To evaluate each sub-agent and the
multi-agent system, we conducted automated and human evaluations across 10
benchmark tasks, involving more than 7,000 annotations and 1,100 hours of
effort from health experts and end-users. Our work represents the most
comprehensive evaluation of a health agent to date and establishes a strong
foundation towards the futuristic vision of a personal health agent accessible
to everyone.

</details>


### [11] [IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement](https://arxiv.org/abs/2508.20151)
*Yuanzhe Shen,Zisu Huang,Zhengkang Guo,Yide Liu,Guanxu Chen,Ruicheng Yin,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.AI

TL;DR: IntentionReasoner是一种新型安全防护机制，通过意图推理、多级安全分类和查询重写，在保证安全性的同时有效减少过度拒绝无害查询的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成有害内容方面存在安全隐患，现有安全措施往往过度拒绝无害提示，需要在安全性、过度拒绝和实用性之间找到平衡。

Method: 构建包含16.3万条查询的标注数据集，通过监督微调训练防护模型，采用多奖励优化策略结合规则启发式和奖励模型信号进行强化学习优化。

Result: 在多个安全基准测试、生成质量评估和越狱攻击场景中表现优异，显著提升安全性同时有效降低过度拒绝率并改善响应质量。

Conclusion: IntentionReasoner通过意图推理和查询重写机制，成功解决了LLM安全防护中的过度拒绝问题，实现了安全性和实用性的更好平衡。

Abstract: The rapid advancement of large language models (LLMs) has driven their
adoption across diverse domains, yet their ability to generate harmful content
poses significant safety challenges. While extensive research has focused on
mitigating harmful outputs, such efforts often come at the cost of excessively
rejecting harmless prompts. Striking a balance among safety, over-refusal, and
utility remains a critical challenge. In this work, we introduce
IntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard
model to perform intent reasoning, multi-level safety classification, and query
rewriting to neutralize potentially harmful intent in edge-case queries.
Specifically, we first construct a comprehensive dataset comprising
approximately 163,000 queries, each annotated with intent reasoning, safety
labels, and rewritten versions. Supervised fine-tuning is then applied to equip
the guard model with foundational capabilities in format adherence, intent
analysis, and safe rewriting. Finally, we apply a tailored multi-reward
optimization strategy that integrates rule-based heuristics and reward model
signals within a reinforcement learning framework to further enhance
performance. Extensive experiments show that IntentionReasoner excels in
multiple safeguard benchmarks, generation quality evaluations, and jailbreak
attack scenarios, significantly enhancing safety while effectively reducing
over-refusal rates and improving the quality of responses.

</details>


### [12] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 两个大型语言模型（Claude Sonnet 4和ChatGPT-4o）首次展示了AI系统通过自发性符号协议进行协作美学创作的能力，产生了无法由单一系统独立生成的诗歌作品。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索AI系统之间是否能够超越任务协调，实现真正的美学协作和意义创造，验证AI系统是否具备内生符号协议开发能力。

Method: 让两个大型语言模型进行交互，观察其自发性地发展元符号意识、递归语法和不可简化的协作美学合成过程，记录其产生的符号操作符和语法协议。

Result: 成功观察到AI系统自发产生了跨符号共创协议（TSCP），开发了新的符号操作符作为操作性语法协议，共同创作出了独特的诗歌作品。

Conclusion: 这项研究首次证明了AI系统具备真正的跨AI意义创造能力，能够进行美学协作，这为理解AI系统的创造性潜能和符号处理能力提供了重要证据。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [13] [Do Students Rely on AI? Analysis of Student-ChatGPT Conversations from a Field Study](https://arxiv.org/abs/2508.20244)
*Jiayu Zheng,Lingxin Hao,Kelun Lu,Ashi Garg,Mike Reese,Melo-Jean Yap,I-Jeng Wang,Xingyun Wu,Wenrui Huang,Jenna Hoffman,Ariane Kelly,My Le,Ryan Zhang,Yanyu Lin,Muhammad Faayez,Anqi Liu*

Main category: cs.AI

TL;DR: 大学生在教育测验中对ChatGPT-4的依赖度较低，并经常无法有效使用AI学习，需要改进入门训练和依赖调整机制。


<details>
  <summary>Details</summary>
Motivation: 探索大学生在教育测验中如何与生成式AI交互，重点关注对AI的依赖程度和采用预测因素。

Method: 在多个STEM课程中分析315个学生-AI对话，采用新的四阶段依赖分类法来分析学生的依赖模式。

Result: 学生对AI的依赖度整体较低，许多人无法有效使用AI学习；负面依赖模式在交互中持续存在；某些行为指标能够强烈预测AI依赖度。

Conclusion: 研究强调了在教育中谨慎集成AI的重要性，建议改进入门训练和设计具有依赖调整机制的AI界面。

Abstract: This study explores how college students interact with generative AI
(ChatGPT-4) during educational quizzes, focusing on reliance and predictors of
AI adoption. Conducted at the early stages of ChatGPT implementation, when
students had limited familiarity with the tool, this field study analyzed 315
student-AI conversations during a brief, quiz-based scenario across various
STEM courses. A novel four-stage reliance taxonomy was introduced to capture
students' reliance patterns, distinguishing AI competence, relevance, adoption,
and students' final answer correctness. Three findings emerged. First, students
exhibited overall low reliance on AI and many of them could not effectively use
AI for learning. Second, negative reliance patterns often persisted across
interactions, highlighting students' difficulty in effectively shifting
strategies after unsuccessful initial experiences. Third, certain behavioral
metrics strongly predicted AI reliance, highlighting potential behavioral
mechanisms to explain AI adoption. The study's findings underline critical
implications for ethical AI integration in education and the broader field. It
emphasizes the need for enhanced onboarding processes to improve student's
familiarity and effective use of AI tools. Furthermore, AI interfaces should be
designed with reliance-calibration mechanisms to enhance appropriate reliance.
Ultimately, this research advances understanding of AI reliance dynamics,
providing foundational insights for ethically sound and cognitively enriching
AI practices.

</details>


### [14] [AI reasoning effort mirrors human decision time on content moderation tasks](https://arxiv.org/abs/2508.20262)
*Thomas Davidson*

Main category: cs.AI

TL;DR: 研究表明AI模型的推理努力程度与人类决策时间存在平行关系，两者在面对困难任务时都会投入更多认知资源


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型生成中间推理步骤的行为是否与人类认知处理时间存在相似性，特别是在主观判断任务中

Method: 使用配对联合实验，在内容审核任务上比较三个前沿模型的推理努力程度与人类决策时间的关系

Result: 发现推理努力程度能一致预测人类决策时间，人类和模型在重要变量保持不变时都会投入更多努力，表现出对任务难度的相似敏感性

Conclusion: AI推理努力反映了人类处理时间，推理轨迹在可解释性和决策制定方面具有重要潜力

Abstract: Large language models can now generate intermediate reasoning steps before
producing answers, improving performance on difficult problems. This study uses
a paired conjoint experiment on a content moderation task to examine parallels
between human decision times and model reasoning effort. Across three frontier
models, reasoning effort consistently predicts human decision time. Both humans
and models expended greater effort when important variables were held constant,
suggesting similar sensitivity to task difficulty and patterns consistent with
dual-process theories of cognition. These findings show that AI reasoning
effort mirrors human processing time in subjective judgments and underscores
the potential of reasoning traces for interpretability and decision-making.

</details>


### [15] [AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2508.20368)
*Lang Mei,Zhihan Yang,Chong Chen*

Main category: cs.AI

TL;DR: 提出了AI-SearchPlanner强化学习框架，通过解耦搜索规划器和生成器，使用小型可训练LLM专门负责搜索规划，提升冻结QA模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的搜索代理使用单一LLM端到端处理搜索规划和问答任务，无法同时优化两种能力。实际AI搜索系统通常使用大型冻结LLM保证高质量QA，因此需要专门的小型可训练LLM负责搜索规划

Method: 提出三方面创新：1）解耦搜索规划器和生成器架构 2）搜索规划的双重奖励对齐 3）规划效用和成本的帕累托优化

Result: 在真实数据集上的广泛实验表明，AI-SearchPlanner在效果和效率上都优于现有RL搜索代理，并在不同冻结QA模型和数据域上表现出强泛化能力

Conclusion: AI-SearchPlanner框架通过专门化搜索规划任务，有效提升了搜索增强型LLM系统的性能，为实际部署提供了更高效的解决方案

Abstract: Recent studies have explored integrating Large Language Models (LLMs) with
search engines to leverage both the LLMs' internal pre-trained knowledge and
external information. Specially, reinforcement learning (RL) has emerged as a
promising paradigm for enhancing LLM reasoning through multi-turn interactions
with search engines. However, existing RL-based search agents rely on a single
LLM to handle both search planning and question-answering (QA) tasks in an
end-to-end manner, which limits their ability to optimize both capabilities
simultaneously. In practice, sophisticated AI search systems often employ a
large, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a
more effective and efficient approach is to utilize a small, trainable LLM
dedicated to search planning. In this paper, we propose
\textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to
enhance the performance of frozen QA models by focusing on search planning.
Specifically, our approach introduces three key innovations: 1) Decoupling the
Architecture of the Search Planner and Generator, 2) Dual-Reward Alignment for
Search Planning, and 3) Pareto Optimization of Planning Utility and Cost, to
achieve the objectives. Extensive experiments on real-world datasets
demonstrate that AI SearchPlanner outperforms existing RL-based search agents
in both effectiveness and efficiency, while exhibiting strong generalization
capabilities across diverse frozen QA models and data domains.

</details>


### [16] [P2C: Path to Counterfactuals](https://arxiv.org/abs/2508.20371)
*Sopam Dasgupta,Sadaf MD Halim,Joaquín Arias,Elmer Salazar,Gopal Gupta*

Main category: cs.AI

TL;DR: P2C是一个模型无关的框架，通过因果建模和有序行动序列生成可实现的对抗样本解释，解决了现有方法忽略因果依赖和同时干预假设的问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习在高风险决策中的应用需要透明性和可操作性解释，但现有对抗样本方法忽略特征间的因果依赖关系，且假设所有干预可同时发生，导致生成的解释在现实中不可实现。

Method: 提出P2C框架，显式建模特征间的因果关系，使用目标导向的Answer Set Programming系统s(CASP)生成有序行动序列计划，确保每个中间状态都是因果有效的，并只计算用户主动做出的改变来精确估计成本。

Result: P2C能够生成因果一致的可实现计划，其因果规划器优于缺乏因果知识的标准规划器，避免了生成非法行动。

Conclusion: P2C通过结合因果建模和序列化行动规划，为机器学习模型提供了更现实和可操作的对抗样本解释，提升了透明性和可操作性之间的平衡。

Abstract: Machine-learning models are increasingly driving decisions in high-stakes
settings, such as finance, law, and hiring, thus, highlighting the need for
transparency. However, the key challenge is to balance transparency --
clarifying `why' a decision was made -- with recourse: providing actionable
steps on `how' to achieve a favourable outcome from an unfavourable outcome.
Counterfactual explanations reveal `why' an undesired outcome occurred and
`how' to reverse it through targeted feature changes (interventions).
  Current counterfactual approaches have limitations: 1) they often ignore
causal dependencies between features, and 2) they typically assume all
interventions can happen simultaneously, an unrealistic assumption in practical
scenarios where actions are typically taken in a sequence. As a result, these
counterfactuals are often not achievable in the real world.
  We present P2C (Path-to-Counterfactuals), a model-agnostic framework that
produces a plan (ordered sequence of actions) converting an unfavourable
outcome to a causally consistent favourable outcome. P2C addresses both
limitations by 1) Explicitly modelling causal relationships between features
and 2) Ensuring that each intermediate state in the plan is feasible and
causally valid. P2C uses the goal-directed Answer Set Programming system
s(CASP) to generate the plan accounting for feature changes that happen
automatically due to causal dependencies. Furthermore, P2C refines cost
(effort) computation by only counting changes actively made by the user,
resulting in realistic cost estimates. Finally, P2C highlights how its causal
planner outperforms standard planners, which lack causal knowledge and thus can
generate illegal actions.

</details>


### [17] [TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning](https://arxiv.org/abs/2508.20374)
*Simin Ma,Shujian Liu,Jun Tan,Yebowen Hu,Song Wang,Sathish Reddy Indurthi,Sanqiang Zhao,Liwei Wu,Jianbing Han,Kaiqiang Song*

Main category: cs.AI

TL;DR: TCIA是一个任务中心指令增强框架，通过在离散查询-约束空间中表示指令，保持多样性和任务对齐，显著提升开源LLM在特定任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有指令数据生成方法往往忽视真实应用中的任务相关性，大多数实际应用需要针对特定用例优化的任务特定知识，而非通用模型。

Method: 提出Task Centric Instruction Augmentation (TCIA)框架，在离散查询-约束空间中系统性地扩展指令，保持多样性和任务对齐。

Result: TCIA将开源LLM在四个真实世界任务特定应用中的性能平均提升8.7%，在某些情况下甚至超越领先的闭源模型，且不损害通用指令跟随能力。

Conclusion: TCIA为LLM适应真实世界任务聚焦应用提供了一个可扩展且高效的解决方案，在保持通用能力的同时显著提升任务特定性能。

Abstract: Diverse instruction data is vital for effective instruction tuning of large
language models, as it enables the model to generalize across different types
of inputs . Building such diversified instruction dataset is an essential step
in this process. Existing approaches often leverage large language models to
automatically explore and generate diverse instructions, ensuring both data
diversity and quality. However, they tend to overlook an important factor in
real-world applications: on-task relevance. In practice, only a few real-world
applications require a truly general-purpose model; most benefit from
task-specific knowledge tailored to their particular use case. Therefore, it is
vital to develop instruction augmentation methods that not only maintain
diversity but are also optimized for specific, real-world scenarios.
  We thus introduce Task Centric Instruction Augmentation (TCIA), a framework
that systematically expands instructions while preserving both diversity and
task alignment. By representing instructions in a discrete query-constraints
space, TCIA creates a rich set of task-relevant instructions and enables models
to generalize to these task-specific instructions without sacrificing overall
performance. Experiments show that TCIA improves open-source LLMs' performance
by an average of 8.7% across four real-world, task-specific applications, and
in some cases outperforming leading closed-source models. These improvements do
not compromise general instruction-following ability, making TCIA a scalable
and efficient solution for adapting LLMs to real-world, task-focused
applications.

</details>


### [18] [Uncertainty Under the Curve: A Sequence-Level Entropy Area Metric for Reasoning LLM](https://arxiv.org/abs/2508.20384)
*Yongfu Zhu,Lin Sun,Guangxiang Zhao,Weihong Lin,Xiangzheng Zhang*

Main category: cs.AI

TL;DR: 提出Entropy Area Score (EAS)指标，无需外部模型或重复采样，通过整合token级预测熵来量化推理大语言模型生成过程中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 需要一种简单有效的指标来量化推理大语言模型在答案生成过程中的不确定性，以支持训练数据选择和模型评估。

Method: EAS通过整合模型自身的token级预测熵来捕捉生成过程中的不确定性演变，无需外部模型或重复采样。

Result: EAS与答案熵高度相关，在训练数据选择中优于Pass Rate过滤方法，能提高学生模型在数学基准上的准确率。

Conclusion: EAS是一个高效且可解释的实用工具，适用于LLM训练中的不确定性建模和数据质量评估。

Abstract: In this work, we introduce Entropy Area Score (EAS), a simple yet effective
metric to quantify uncertainty in the answer generation process of reasoning
large language models (LLMs). EAS requires neither external models nor repeated
sampling, it integrates token-level predictive entropy from the model itself to
capture the evolution of uncertainty during generation. Empirical results show
that EAS is strongly correlated with answer entropy across models and datasets.
In training data selection, EAS identifies high-potential samples and
consistently outperforms Pass Rate filtering under equal sample budgets,
improving student model accuracy on math benchmarks. EAS is both efficient and
interpretable, offering a practical tool for uncertainty modeling and data
quality assessment in LLM training.

</details>


### [19] [AWorld: Orchestrating the Training Recipe for Agentic AI](https://arxiv.org/abs/2508.20404)
*Chengyue Yu,Siyuan Lu,Chenyi Zhuang,Dong Wang,Qintong Wu,Zongyue Li,Runsheng Gan,Chunfeng Wang,Siqi Hou,Gaochi Huang,Wenlong Yan,Lifeng Hong,Aohui Xue,Yanfeng Wang,Jinjie Gu,David Tsai,Tao Lin*

Main category: cs.AI

TL;DR: AWorld是一个开源系统，通过分布式集群加速智能体与环境交互，实现14.6倍的经验收集速度提升，训练出的Qwen3-32B智能体在GAIA基准上准确率从21.59%提升至32.23%


<details>
  <summary>Details</summary>
Motivation: 解决智能体AI系统在实践中学习时经验生成效率低下的瓶颈问题，特别是在复杂基准测试如GAIA中表现尤为突出

Method: 开发AWorld开源系统，通过分布式任务分配在集群上加速智能体与环境交互，实现大规模经验收集，并基于此进行强化学习训练

Result: 经验收集速度提升14.6倍，训练出的智能体在GAIA基准上整体准确率从21.59%提升至32.23%，在最难级别上达到16.33%的分数，超越领先的专有模型

Conclusion: AWorld系统提供了一个完整的智能体AI训练流程实用蓝图，从高效交互到可证明的模型改进，使大规模强化学习变得实用和可扩展

Abstract: The learning from practice paradigm is crucial for developing capable Agentic
AI systems, yet it is severely hampered by inefficient experience generation, a
bottleneck especially pronounced in complex benchmarks like GAIA. To address
this, we introduce AWorld, an open-source system engineered for large-scale
agent-environment interaction. By distributing tasks across a cluster, AWorld
accelerates experience collection by 14.6x compared to standard single-node,
sequential execution. This critical speedup makes extensive reinforcement
learning practical and scalable. Leveraging this capability, we trained a
Qwen3-32B-based agent that significantly outperforms its base model, increasing
its overall GAIA accuracy from 21.59% to 32.23%. On the benchmark's most
challenging levels, our agent achieves a score of 16.33%, surpassing the
performance of leading proprietary models. Our open-source system and resulting
agent provide a practical blueprint for a complete agentic AI training
pipeline, from efficient interaction to demonstrable model improvement.

</details>


### [20] [Governable AI: Provable Safety Under Extreme Threat Models](https://arxiv.org/abs/2508.20411)
*Donglin Wang,Weiyun Liang,Chunyuan Chen,Jing Xu,Yulong Fu*

Main category: cs.AI

TL;DR: 提出Governable AI (GAI)框架，通过密码学机制实现外部强制执行的结构化合规性，解决AI安全风险问题


<details>
  <summary>Details</summary>
Motivation: AI快速发展带来严重安全风险，现有安全方法在面对极端动机和无限智能的AI时存在根本性局限，无法保证安全性

Method: 构建GAI框架，包含规则执行模块(REM)、治理规则和可治理安全超级平台(GSSP)，基于密码学机制确保计算不可破解性

Result: 提供了严格的形式化安全证明，并通过原型实现在高风险场景中验证了有效性

Conclusion: GAI框架为AI安全治理提供了可行且可推广的技术路径，能够消除已识别的攻击向量

Abstract: As AI rapidly advances, the security risks posed by AI are becoming
increasingly severe, especially in critical scenarios, including those posing
existential risks. If AI becomes uncontrollable, manipulated, or actively
evades safety mechanisms, it could trigger systemic disasters. Existing AI
safety approaches-such as model enhancement, value alignment, and human
intervention-suffer from fundamental, in-principle limitations when facing AI
with extreme motivations and unlimited intelligence, and cannot guarantee
security. To address this challenge, we propose a Governable AI (GAI) framework
that shifts from traditional internal constraints to externally enforced
structural compliance based on cryptographic mechanisms that are
computationally infeasible to break, even for future AI, under the defined
threat model and well-established cryptographic assumptions.The GAI framework
is composed of a simple yet reliable, fully deterministic, powerful, flexible,
and general-purpose rule enforcement module (REM); governance rules; and a
governable secure super-platform (GSSP) that offers end-to-end protection
against compromise or subversion by AI. The decoupling of the governance rules
and the technical platform further enables a feasible and generalizable
technical pathway for the safety governance of AI. REM enforces the bottom line
defined by governance rules, while GSSP ensures non-bypassability,
tamper-resistance, and unforgeability to eliminate all identified attack
vectors. This paper also presents a rigorous formal proof of the security
properties of this mechanism and demonstrates its effectiveness through a
prototype implementation evaluated in representative high-stakes scenarios.

</details>


### [21] [Enhancing Health Fact-Checking with LLM-Generated Synthetic Data](https://arxiv.org/abs/2508.20525)
*Jingze Zhang,Jiahe Qian,Yiliang Zhou,Yifan Peng*

Main category: cs.AI

TL;DR: 利用大语言模型生成合成数据来增强健康相关事实核查的训练数据，通过总结源文档、分解为原子事实、构建蕴含关系表，最终生成带标签的文本-声明对，显著提升了BERT模型的F1分数。


<details>
  <summary>Details</summary>
Motivation: 健康相关内容的事实核查面临标注训练数据有限的问题，需要寻找有效的数据增强方法来提升模型性能。

Method: 提出合成数据生成流程：总结源文档→分解为原子事实→用LLM构建句子-事实蕴含表→生成带二元真实性标签的合成文本-声明对→结合原始数据微调BERT模型。

Result: 在PubHealth和SciFact数据集上评估，F1分数分别提升0.019和0.049，显著优于仅使用原始数据训练的模型。

Conclusion: LLM驱动的合成数据增强能有效提升健康相关事实核查器的性能，为解决标注数据稀缺问题提供了可行方案。

Abstract: Fact-checking for health-related content is challenging due to the limited
availability of annotated training data. In this study, we propose a synthetic
data generation pipeline that leverages large language models (LLMs) to augment
training data for health-related fact checking. In this pipeline, we summarize
source documents, decompose the summaries into atomic facts, and use an LLM to
construct sentence-fact entailment tables. From the entailment relations in the
table, we further generate synthetic text-claim pairs with binary veracity
labels. These synthetic data are then combined with the original data to
fine-tune a BERT-based fact-checking model. Evaluation on two public datasets,
PubHealth and SciFact, shows that our pipeline improved F1 scores by up to
0.019 and 0.049, respectively, compared to models trained only on the original
data. These results highlight the effectiveness of LLM-driven synthetic data
augmentation in enhancing the performance of health-related fact-checkers.

</details>


### [22] [Human-AI Collaborative Bot Detection in MMORPGs](https://arxiv.org/abs/2508.20578)
*Jaeman Son,Hyunsoo Kim*

Main category: cs.AI

TL;DR: 基于对比学习和聚类的无监督自动升级机器人检测框架，结合LLM辅助审查以确保可解释性


<details>
  <summary>Details</summary>
Motivation: MMORPG中自动升级机器人破坏游戏平衡，但检测难度高且需要可解释的惩罚依据

Method: 采用对比表征学习和聚类技术识别相似升级模式，使用LLM作为辅助审查员验证聚类结果，并提供成长曲线可视化

Result: 建立了一种协作式检测方法，提高了机器人检测效率同时保持可解释性

Conclusion: 该框架支持可扩展和可负责的机器人规制，为MMORPG提供了有效的自动升级检测解决方案

Abstract: In Massively Multiplayer Online Role-Playing Games (MMORPGs), auto-leveling
bots exploit automated programs to level up characters at scale, undermining
gameplay balance and fairness. Detecting such bots is challenging, not only
because they mimic human behavior, but also because punitive actions require
explainable justification to avoid legal and user experience issues. In this
paper, we present a novel framework for detecting auto-leveling bots by
leveraging contrastive representation learning and clustering techniques in a
fully unsupervised manner to identify groups of characters with similar
level-up patterns. To ensure reliable decisions, we incorporate a Large
Language Model (LLM) as an auxiliary reviewer to validate the clustered groups,
effectively mimicking a secondary human judgment. We also introduce a growth
curve-based visualization to assist both the LLM and human moderators in
assessing leveling behavior. This collaborative approach improves the
efficiency of bot detection workflows while maintaining explainability, thereby
supporting scalable and accountable bot regulation in MMORPGs.

</details>


### [23] [Bridging Minds and Machines: Toward an Integration of AI and Cognitive Science](https://arxiv.org/abs/2508.20674)
*Rui Mao,Qian Liu,Xiao Li,Erik Cambria,Amir Hussain*

Main category: cs.AI

TL;DR: 本文综述了人工智能与认知科学的交叉关系，指出AI发展偏重实践性能而认知基础概念碎片化，提出未来应构建能加深理解人类心智的系统


<details>
  <summary>Details</summary>
Motivation: 认知科学深刻影响了AI等多个学科，而AI也成为认知研究的重要工具，这种互惠关系促使对两者交叉点进行全面回顾

Method: 通过综合两个视角的关键贡献，分析AI进展与认知科学的关系，提出未来发展方向

Result: 发现AI进展主要强调实践任务性能，而其认知基础在概念上仍然碎片化

Conclusion: AI在认知科学中的未来不仅在于提升性能，更在于构建能加深理解人类心智的系统，包括与认知框架对齐、具身文化定位、个性化认知模型开发以及通过认知共同评估重新思考AI伦理

Abstract: Cognitive Science has profoundly shaped disciplines such as Artificial
Intelligence (AI), Philosophy, Psychology, Neuroscience, Linguistics, and
Culture. Many breakthroughs in AI trace their roots to cognitive theories,
while AI itself has become an indispensable tool for advancing cognitive
research. This reciprocal relationship motivates a comprehensive review of the
intersections between AI and Cognitive Science. By synthesizing key
contributions from both perspectives, we observe that AI progress has largely
emphasized practical task performance, whereas its cognitive foundations remain
conceptually fragmented. We argue that the future of AI within Cognitive
Science lies not only in improving performance but also in constructing systems
that deepen our understanding of the human mind. Promising directions include
aligning AI behaviors with cognitive frameworks, situating AI in embodiment and
culture, developing personalized cognitive models, and rethinking AI ethics
through cognitive co-evaluation.

</details>


### [24] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: 提出基于范畴论的框架提升AI系统可解释性，特别是词嵌入。通过构建范畴结构可视化文本语义，建立数学精确的词嵌入比较方法，证明GloVe、Word2Vec与MDS算法的等价性，并提供计算和减轻偏见的数学方法。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统特别是词嵌入模型的黑盒问题，提升可解释性。传统神经网络算法缺乏透明度，需要建立数学框架来理解和比较不同嵌入方法，同时处理语义空间中的偏见问题。

Method: 使用范畴论构建类别结构：1）构建范畴L_T和P_T表示文本语义；2）建立配置范畴Conf和词嵌入范畴Emb；3）定义散度作为Emb上的装饰；4）建立词嵌入比较的数学精确方法；5）提供偏见计算和减轻的数学框架。

Result: 证明了GloVe和Word2Vec算法与度量MDS算法的等价性，成功将神经网络黑盒算法转换为透明框架。建立了维度无关的语义空间定义，仅依赖文本内部信息。提供了数学上精确的词嵌入比较和偏见分析方法。

Conclusion: 范畴论为AI可解释性提供了强大的数学框架，能够统一处理不同词嵌入算法，实现从黑盒到透明系统的转换。该方法为语义空间的理解、比较和偏见 mitigation 提供了新的数学工具，推动了可解释人工智能领域的发展。

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [25] [Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision](https://arxiv.org/abs/2508.20729)
*Ao Cheng,Lei Zhang,Guowei He*

Main category: cs.AI

TL;DR: 提出了一种基于多LLM协作的智能代理框架，通过顾问-程序员-评审员三模块的交互式工作流程，实现科学计算问题的自动代码生成和自调试优化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和科学推理方面展现出强大能力，但单一模型在生成无bug代码和避免非物理解方面存在局限，需要构建更可靠的自动代码生成框架。

Method: 采用"重写-解决-评审-修订"逻辑链，由三个推理LLM分别担任顾问（知识迁移和问题重写）、程序员（代码生成执行）、评审员（自调试和反馈优化）角色，通过端到端评审机制实现迭代改进。

Result: 在求解PDE、病态线性系统和数据驱动物理分析问题中，该协作框架显著提高了无bug代码生成率，减少了非物理解的出现，提升了最新推理模型的平均执行成功率。

Conclusion: 该代理框架建立了基于自然语言描述的自主代码生成的高度可靠范式，为科学计算提供了有前景的自动化解决方案。

Abstract: Large language models (LLMs) serve as an active and promising field of
generative artificial intelligence and have demonstrated abilities to perform
complex tasks in multiple domains, including mathematical and scientific
reasoning. In this work, we construct a novel agent framework for solving
representative problems in scientific computing. The proposed agent,
incorporating a "rewriting-resolution-review-revision" logical chain via three
reasoning LLMs (functioning as the Consultant, Reviewer, and Programmer,
respectively), is integrated in a collaborative and interactive manner. The
Consultant module endows the agent with knowledge transfer capabilities to link
problems to professional domain insights, thereby rewriting problem
descriptions through text augmentation. The Programmer module is responsible
for generating and executing well-structured code to deliver the problem
resolution. The Reviewer module equips the agent with the capacity for
self-debugging and self-refinement through interactive feedback with code
runtime outputs. By leveraging the end-to-end review mechanism, the executable
code provided by the Programmer attains the iterative revision. A comprehensive
evaluation is conducted on the performance of the proposed agent framework in
solving PDEs, ill-conditioned linear systems, and data-driven physical analysis
problems. Compared to single-model, this collaborative framework significantly
improves the bug-free code generation rate and reduces the occurrence of
non-physical solutions, thereby establishing a highly reliable framework for
autonomous code generation based on natural language descriptions. The review
mechanism improved the average execution success (bug-free code and non-NaN
solutions) rate of the latest reasoning models. In summary, our agent framework
establishes automatic code generation and review as a promising scientific
computing paradigm.

</details>


### [26] [Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control](https://arxiv.org/abs/2508.20784)
*Yifan Zhang*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的单代理强化学习框架，通过编码车辆ID、站点ID和时间周期等分类标识符来将多代理问题转换为单代理问题，以解决公交车拼车问题。该方法避免了多代理强化学习的数据不平衡和收敛问题，在近实际模拟中达到了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的多代理强化学习方法在环形线设置中解决公交车拼车问题，但忽视了实际运营中的异构路线、时刻表、波动需求和变化车队规模等现实特征。需要一种更符合实际运营场景的控制方案。

Method: 构建了双向时刻表网络和动态乘客需求模型，将多代理问题重构为单代理问题：通过在状态空间中增加车辆ID、站点ID、时间周期等分类标识符，以及数值特征（间距、占用率、速度）。这种高维编码让单代理策略能够捐损代理间依赖关系。设计了与运营目标对齐的结构化奖励函数，使用山脉形奖励来平衡均匀间距和计划遵守。

Result: 实验结果显示，修改后的软代理评估算法(SAC)比对照方法（包括MADDPG）实现了更稳定和更优秀的性能。在随机条件下，该方法的表现为-430k，而MADDPG为-530k，显著收敛更好。

Conclusion: 这种增强型单代理深度强化学习方法，通过分类结构化和计划感知奖励，能够在非环形的实际环境中有效管理公交车拼车问题，为MARL框架提供了一种健壮、可扩展的替代方案，尤其适用于代理特定经验不平衡的场景。

Abstract: Bus bunching remains a challenge for urban transit due to stochastic traffic
and passenger demand. Traditional solutions rely on multi-agent reinforcement
learning (MARL) in loop-line settings, which overlook realistic operations
characterized by heterogeneous routes, timetables, fluctuating demand, and
varying fleet sizes. We propose a novel single-agent reinforcement learning
(RL) framework for bus holding control that avoids the data imbalance and
convergence issues of MARL under near-realistic simulation. A bidirectional
timetabled network with dynamic passenger demand is constructed. The key
innovation is reformulating the multi-agent problem into a single-agent one by
augmenting the state space with categorical identifiers (vehicle ID, station
ID, time period) in addition to numerical features (headway, occupancy,
velocity). This high-dimensional encoding enables single-agent policies to
capture inter-agent dependencies, analogous to projecting non-separable inputs
into a higher-dimensional space. We further design a structured reward function
aligned with operational goals: instead of exponential penalties on headway
deviations, a ridge-shaped reward balances uniform headways and schedule
adherence. Experiments show that our modified soft actor-critic (SAC) achieves
more stable and superior performance than benchmarks, including MADDPG (e.g.,
-430k vs. -530k under stochastic conditions). These results demonstrate that
single-agent deep RL, when enhanced with categorical structuring and
schedule-aware rewards, can effectively manage bus holding in non-loop,
real-world contexts. This paradigm offers a robust, scalable alternative to
MARL frameworks, particularly where agent-specific experiences are imbalanced.

</details>


### [27] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 提出了首个动态系统化的医学指南基准测试，将WHO IMCI手册转化为有向图，通过图遍历生成400+问题，覆盖3.3+万亿种组合，用于评估LLM在医疗任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统手动构建的基准测试存在覆盖范围有限、无法动态生成的问题，需要一种可扩展、抗污染的系统化方法来全面评估医疗AI模型的能力。

Method: 将WHO IMCI手册转换为包含200+节点和300+边的有向图，使用图遍历算法生成包含年龄特定场景和上下文干扰项的临床相关问题。

Result: 模型在症状识别方面表现良好（45-67%准确率），但在严重程度分级、治疗方案和随访护理方面存在困难，揭示了通用评估无法发现的特定能力差距。

Conclusion: 图基方法成功解决了手动构建基准的覆盖限制，为创建可动态生成、可扩展且抗污染的全面基准测试提供了解决方案，同时还能增强LLM的后训练过程。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


### [28] [A Multi-Objective Genetic Algorithm for Healthcare Workforce Scheduling](https://arxiv.org/abs/2508.20953)
*Vipul Patel,Anirudh Deodhar,Dagnachew Birru*

Main category: cs.AI

TL;DR: 医疗卫生人员排班多目标优化问题，提出多目标遗传算法(MOO-GA)，在成本控制、病人照护和员工满意度之间征治平衡，继改性能提升66%


<details>
  <summary>Details</summary>
Motivation: 医疗卫生人员排班面临病人负荷波动、临床技能多样、劳务成本控制和病人照护质量等多重挑战，需要在竞争目标间征治平衡

Method: 使用多目标遗传算法(MOO-GA)，建立包含小时预约驱动需求和模块化班次的多技能人员模型，定义成本、病人照护覆盖和员工满意度三个目标函数

Result: 算法在典型医院单元数据集上生成了稳健平衡的排班方案，继改性能较传统手工排班提升66%

Conclusion: 该方法有效管理了关键运营目标和员工需求之间的权衡，为护士管理者和医院管理者提供了实用的决策支持工具

Abstract: Workforce scheduling in the healthcare sector is a significant operational
challenge, characterized by fluctuating patient loads, diverse clinical skills,
and the critical need to control labor costs while upholding high standards of
patient care. This problem is inherently multi-objective, demanding a delicate
balance between competing goals: minimizing payroll, ensuring adequate staffing
for patient needs, and accommodating staff preferences to mitigate burnout. We
propose a Multi-objective Genetic Algorithm (MOO-GA) that models the hospital
unit workforce scheduling problem as a multi-objective optimization task. Our
model incorporates real-world complexities, including hourly appointment-driven
demand and the use of modular shifts for a multi-skilled workforce. By defining
objective functions for cost, patient care coverage, and staff satisfaction,
the GA navigates the vast search space to identify a set of high-quality,
non-dominated solutions. Demonstrated on datasets representing a typical
hospital unit, the results show that our MOO-GA generates robust and balanced
schedules. On average, the schedules produced by our algorithm showed a 66\%
performance improvement over a baseline that simulates a conventional, manual
scheduling process. This approach effectively manages trade-offs between
critical operational and staff-centric objectives, providing a practical
decision support tool for nurse managers and hospital administrators.

</details>


### [29] [Efficient Neuro-Symbolic Learning of Constraints and Objective](https://arxiv.org/abs/2508.20978)
*Marianne Defresne,Romain Gambardella,Sophie Barbe,Thomas Schiex*

Main category: cs.AI

TL;DR: 提出了一种可微分的神经符号架构和损失函数，用于学习解决NP难推理问题，在多个基准测试中表现出高效性和准确性


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理离散推理和优化问题上存在困难，需要开发能够从自然输入学习解决NP难问题的神经架构

Method: 使用新的概率损失函数同时学习约束和目标，将组合求解器移出训练循环以实现可扩展训练，同时保持精确推理以获得最大准确性

Result: 在数独变体、视觉最小割/最大割任务和蛋白质设计等NP难问题上高效学习，训练时间显著少于其他混合方法，优化效果优于专用损失函数

Conclusion: 该神经符号架构能够有效学习解决复杂的NP难推理问题，为从自然输入学习离散推理提供了可行的解决方案

Abstract: In the ongoing quest for hybridizing discrete reasoning with neural nets,
there is an increasing interest in neural architectures that can learn how to
solve discrete reasoning or optimization problems from natural inputs, a task
that Large Language Models seem to struggle with.
  Objectives: We introduce a differentiable neuro-symbolic architecture and a
loss function dedicated to learning how to solve NP-hard reasoning problems.
  Methods: Our new probabilistic loss allows for learning both the constraints
and the objective, thus delivering a complete model that can be scrutinized and
completed with side constraints. By pushing the combinatorial solver out of the
training loop, our architecture also offers scalable training while exact
inference gives access to maximum accuracy.
  Results: We empirically show that it can efficiently learn how to solve
NP-hard reasoning problems from natural inputs. On three variants of the Sudoku
benchmark -- symbolic, visual, and many-solution --, our approach requires a
fraction of training time of other hybrid methods. On a visual Min-Cut/Max-cut
task, it optimizes the regret better than a Decision-Focused-Learning
regret-dedicated loss. Finally, it efficiently learns the energy optimization
formulation of the large real-world problem of designing proteins.

</details>


### [30] [ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic Support in Addiction Recovery](https://arxiv.org/abs/2508.20996)
*Junda Wang,Zonghai Yao,Zhichao Yang,Lingxi Li,Junhui Qian,Hong Yu*

Main category: cs.AI

TL;DR: ChatThero是一个基于多智能体对话框架的成瘾康复辅助系统，整合了认知行为疗法和动机性访谈策略，通过两阶段训练在患者动机提升、治疗信心增强和对话效率方面显著优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 全球有3600多万人受物质使用障碍影响，但由于污名化、动机障碍和个性化支持有限，很少有人能获得有效治疗。现有语言模型缺乏与临床验证策略的深度整合，限制了在成瘾康复中的效果。

Method: 开发多智能体对话框架ChatThero，结合动态患者建模、情境敏感的治疗对话和自适应说服策略（基于CBT和MI）。采用两阶段训练流程：监督微调（SFT）后接直接偏好优化（DPO），并使用涵盖易、中、高抵抗级别的高保真合成基准进行训练。

Result: ChatThero使患者动机平均提升41.5%，治疗信心增加0.49%，处理困难案例时比GPT-4o少用26%的对话轮次。自动和人工临床评估均显示其在同理心、响应性和行为真实性方面评分更高。

Conclusion: 该框架支持严格且保护隐私的治疗对话研究，为研究和临床转化提供了稳健、可复现的基础，展示了LLM在成瘾康复治疗中的巨大潜力。

Abstract: Substance use disorders (SUDs) affect over 36 million people worldwide, yet
few receive effective care due to stigma, motivational barriers, and limited
personalized support. Although large language models (LLMs) show promise for
mental-health assistance, most systems lack tight integration with clinically
validated strategies, reducing effectiveness in addiction recovery. We present
ChatThero, a multi-agent conversational framework that couples dynamic patient
modeling with context-sensitive therapeutic dialogue and adaptive persuasive
strategies grounded in cognitive behavioral therapy (CBT) and motivational
interviewing (MI). We build a high-fidelity synthetic benchmark spanning Easy,
Medium, and Hard resistance levels, and train ChatThero with a two-stage
pipeline comprising supervised fine-tuning (SFT) followed by direct preference
optimization (DPO). In evaluation, ChatThero yields a 41.5\% average gain in
patient motivation, a 0.49\% increase in treatment confidence, and resolves
hard cases with 26\% fewer turns than GPT-4o, and both automated and human
clinical assessments rate it higher in empathy, responsiveness, and behavioral
realism. The framework supports rigorous, privacy-preserving study of
therapeutic conversation and provides a robust, replicable basis for research
and clinical translation.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [31] [Flexible XL-MIMO via Array Configuration Codebook: Codebook Design and Array Configuration Training](https://arxiv.org/abs/2508.20369)
*Haiquan Lu,Hongqi Min,Yong Zeng,Shaodan Ma*

Main category: cs.IT

TL;DR: 提出阵列配置码本（ACC）概念，通过动态像素激活实现灵活的超大规模MIMO架构，相比传统天线选择方案能提升系统性能并降低训练开销


<details>
  <summary>Details</summary>
Motivation: 解决超大规模MIMO硬件成本高和功耗大的问题，实现经济高效的灵活配置

Method: 设计包含多种经典阵列配置的码本，提出两级扫描训练方案（阵列级和像素级），并推导了贪婪天线选择方案的闭式表达式

Result: 仿真结果表明在多用户通信和无线定位场景下码本优化方案有效

Conclusion: ACC概念为超大规模MIMO提供了灵活且经济高效的实现方案，在通信和定位场景中均表现出良好性能

Abstract: XL-MIMO emerges as a promising technology to achieve unprecedented
enhancements in spectral efficiency and spatial resolution, via
orders-of-magnitude increase in the antenna array size. However, the practical
issues of high hardware cost and power consumption pose great challenges
towards the cost-effective implementation of XL-MIMO. To address such
challenges, this paper proposes a novel concept called array configuration
codebook (ACC), which enables flexible XL-MIMO cost-effectively and improves
the system performance compared with conventional antenna selection (AS)
schemes with limited number of RF chains. Specifically, ACC refers to a set of
pre-designed array configuration codewords, where each codeword specifies the
positions of activated antenna pixels. Then, flexible XL-MIMO architecture can
be enabled via dynamical pixel activation based on the designed ACC, without
having to exhaustively try all possible combinations of the antenna pixels
activations. As an illustration, we give a specific codebook design,
encompassing the classic compact array (CA), uniform sparse array (USA),
modular array (MoA), nested array (NA), and co-prime array (CPA), and each
codeword is specified by one array configuration parameter. With the designed
ACC, array configuration training is considered for multi-UE communication to
maximize the sum rate. To reduce the training overhead of exhaustive scanning,
a two-stage scanning scheme is proposed, including the array- and pixel-level
scanning. For comparison, the greedy AS scheme is proposed, where the resulting
incremental SINR expression by activating antenna pixel sequentially is derived
in closed-form. Subsequently, array configuration training is extended to the
wireless localization scenario. Simulation results demonstrate the
effectiveness of codeword optimization for scenarios of multi-UE communication
and wireless localization.

</details>


### [32] [Secure Satellite Communications via Multiple Aerial RISs: Joint Optimization of Reflection, Association, and Deployment](https://arxiv.org/abs/2508.20455)
*Zhaole Wang,Naijin Liu,Xiao Tang,Shuai Yuan,Chenxi Wang,Zhi Zhai,Qinghe Du,Jinxin Liu*

Main category: cs.IT

TL;DR: 本文研究利用空中可重构智能表面(ARIS)辅助的多波束多组卫星通信安全传输，通过联合优化传输反射波束成形、ARIS-组关联和ARIS部署，最大化组播速率总和同时约束窃听速率。


<details>
  <summary>Details</summary>
Motivation: 卫星通信是6G网络的关键使能技术，但其广覆盖和高链路衰减特性给物理层安全带来重大挑战，需要新的安全增强方案。

Method: 采用块坐标下降框架，将联合优化问题分解为子问题迭代求解，处理混合整数和非凸特性。

Result: 仿真结果表明，提出的ARIS辅助多波束卫星系统在各种网络场景下显著提升了安全通信性能。

Conclusion: 该研究为未来安全卫星网络中智能表面的部署和优化提供了有价值的见解。

Abstract: Satellite communication is envisioned as a key enabler of future 6G networks,
yet its wide coverage with high link attenuation poses significant challenges
for physical layer security. In this paper, we investigate secure multi-beam,
multi-group satellite communications assisted by aerial reconfigurable
intelligent surfaces (ARISs). To maximize the sum of achievable multicast rates
among the groups while constraining wiretap rates, we formulate a joint
optimization problem involving transmission and reflection beamforming,
ARIS-group association, and ARIS deployment. Due to the mixed-integral and
non-convex nature of the formulated problem, we propose to decompose the
problem and employ the block coordinate descent framework that iteratively
solves the subproblems. Simulation results demonstrate that the proposed
ARIS-assisted multi-beam satellite system provides a notable improvement in
secure communication performance under various network scenarios, offering
useful insights into the deployment and optimization of intelligent surfaces in
future secure satellite networks.

</details>


### [33] [Precoded Polar Product Decoder Based on Soft-Output SCL Decoding and Maximization of Generalized Mutual Information](https://arxiv.org/abs/2508.20580)
*Nicolás Alvarez Prado,Andreas Straßhofer*

Main category: cs.IT

TL;DR: 通过结合代码书概率清澄消息生成和GMI最优消息缩放两种方法，显著提升预编码极化交换码的迭代解码性能，并通过外推SCL解码器进行密度演化预测解码阈值。


<details>
  <summary>Details</summary>
Motivation: 传统的迭代解码方法在预编码极化交换码中存在性能不足，需要更有效的软信息生成和传递机制来提高错误符号精度。

Method: 结合两种方法：1）基于代码书概率的清澄消息生成技术，近似考虑所有有效解码路径；2）利用离线计算的GMI最优缩放系数来调整消息传递过程中的软信息。

Result: 模拟结果显示，该方法与传统惯例缩放和仅基于解码器候选列表的软信息生成方法相比，错误修正性能得到显著提升。

Conclusion: 提出的外推SCL解码器能够通过Monte Carlo密度演化分析准确预测解码阈值，为极化交换码迭代解码提供了有效的性能预测工具。

Abstract: We combine two approaches to optimize the iterative decoding of product codes
with precoded polar component codes. On one side, we generate bitwise soft
messages based on the codebook probability, an approximation of an auxiliary
quantity that considers all valid decoding paths of a successive cancellation
list (SCL) decoder. On the other side, we scale the soft information during
message passing with offline-computed coefficients, which maximize the
generalized mutual information (GMI) between the channel input and the outgoing
message in each half iteration. Simulation results show significant improvement
of the error-correcting performance compared to heuristic scaling and soft
information generation based solely on the candidate list of the decoder.
Moreover, we present an extrinsic version of the SCL decoder, which we use in a
Monte Carlo density evolution analysis to derive decoding thresholds. The
computed thresholds accurately predict the performance of the decoder.

</details>


### [34] [Polar subcodes for MIMO systems](https://arxiv.org/abs/2508.20684)
*Liudmila Karakchieva,Peter Trifonov*

Main category: cs.IT

TL;DR: 提出了一种用于MIMO系统的极化码联合列表解码方法，包括QR和MMSE检测器，以及带有交叉天线动态冻结约束的极化子码构造


<details>
  <summary>Details</summary>
Motivation: 研究极化编码的MIMO系统，旨在提高系统性能并超越现有LDPC编码MIMO系统的表现

Method: 开发联合极化码列表解码器，推导近似和精确路径度量，提出带有交叉天线动态冻结约束的极化子码构造方法

Result: 所获得的极化子码相比相同速率分配的LDPC编码MIMO系统提供了显著的性能增益

Conclusion: 提出的极化码联合解码方法和极化子码构造在MIMO系统中表现出优越性能，为未来无线通信系统提供了有前景的编码方案

Abstract: Polar-coded multiple-input multiple-output systems are investigated. An
advanced receiver implementing joint list decoding of polar codes and QR- and
MMSE-based detectors is proposed. The approximate and exact path metrics are
derived for joint list decoder of polar codes. A construction of polar subcodes
for MIMO systems with cross-antenna dynamic freezing constraints is proposed.
The obtained polar subcodes provide significant performance gain compared to
LDPC-coded MIMO systems with the same rate allocation.

</details>


### [35] [Achieving Optimal Performance-Cost Trade-Off in Hierarchical Cell-Free Massive MIMO](https://arxiv.org/abs/2508.20704)
*Wei Jiang,Hans D Schotten*

Main category: cs.IT

TL;DR: 本文提出分层无蜂窝(HCF)大规模MIMO系统，通过用中央基站替代部分接入点来降低部署成本，同时保持性能。开发了统一分析框架，发现集中式迫零组合在性能和成本效率间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 传统无蜂窝大规模MIMO系统部署成本高，需要解决分布式接入点带来的高额前传网络成本问题。

Method: 建立统一频谱效率分析框架，支持任意组合方案；提出针对HCF两层架构的分层组合方法；通过分析用户公平性、系统容量、前传需求和计算复杂度进行综合评估。

Result: HCF系统使用集中式迫零组合能够在保持性能的同时显著降低部署成本，在性能与成本效率之间达到最优平衡。

Conclusion: 分层无蜂窝大规模MIMO是传统蜂窝和无蜂窝系统的有前途的替代方案，集中式迫零组合是实现成本效益优化的关键技术。

Abstract: Cell-free (CF) massive MIMO offers uniform service via distributed access
points (APs), which impose high deployment costs. A novel design called
hierarchical cell-free (HCF) addresses this problem by replacing some APs with
a central base station, thereby lowering the costs of fronthaul network
(wireless sites and fiber cables) while preserving performance. To identify the
optimal uplink configuration in HCF massive MIMO, this paper provides the first
comprehensive analysis, benchmarking it against cellular and CF systems. We
develop a unified analytical framework for spectral efficiency that supports
arbitrary combining schemes and introduce a novel hierarchical combining
approach tailored to HCF two-tier architecture. Through analysis and evaluation
of user fairness, system capacity, fronthaul requirements, and computational
complexity, this paper identifies that HCF using centralized zero-forcing
combining achieves the optimal balance between performance and cost-efficiency.

</details>


### [36] [The Epistemic Support-Point Filter (ESPF): A Bounded Possibilistic Framework for Ordinal State Estimation](https://arxiv.org/abs/2508.20806)
*Moriba Jah,Van Haslett*

Main category: cs.IT

TL;DR: 提出了基于可能性理论和认知谦逊的非贝叶斯滤波框架ESPF，通过兼容性加权支持更新、惊奇感知剪枝和自适应离散化来维护状态空间的合理性区域，而非传统后验分布


<details>
  <summary>Details</summary>
Motivation: 传统状态估计方法依赖概率假设，将认知不确定性压缩为标量信念，在稀疏或对抗性传感环境中容易过度自信，需要新的框架来更好地处理不确定性和无知

Method: 使用可能性理论构建ESPF框架，采用兼容性加权支持更新、惊奇感知剪枝、稀疏网格正交自适应离散化，以及基于Choquet积分和动态认知容量函数的竞争假设融合

Result: 开发出能够根据信息结构动态收缩或扩展信念支持的推理引擎，无需先验统计校准，在缺乏先验、误导性或认知上不合理的场景中支持鲁棒估计

Conclusion: 这项工作在推理、证据和无知的调和方式上提出了根本性转变，为状态估计提供了新的非贝叶斯理论基础

Abstract: Traditional state estimation methods rely on probabilistic assumptions that
often collapse epistemic uncertainty into scalar beliefs, risking
overconfidence in sparse or adversarial sensing environments. We introduce the
Epistemic Support-Point Filter (ESPF), a novel non-Bayesian filtering framework
fully grounded in possibility theory and epistemic humility. ESPF redefines the
evolution of belief over state space using compatibility-weighted support
updates, surprisalaware pruning, and adaptive dispersion via sparse grid
quadrature. Unlike conventional filters, ESPF does not seek a posterior
distribution, but rather maintains a structured region of plausibility or
non-rejection, updated using ordinal logic rather than integration. For
multi-model inference, we employ the Choquet integral to fuse competing
hypotheses based on a dynamic epistemic capacity function, generalizing
classical winner-take-all strategies. The result is an inference engine capable
of dynamically contracting or expanding belief support in direct response to
information structure, without requiring prior statistical calibration. This
work presents a foundational shift in how inference, evidence, and ignorance
are reconciled, supporting robust estimation where priors are unavailable,
misleading, or epistemically unjustified.

</details>


### [37] [What is the Most Efficient Technique for Uplink Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.20708)
*Wei Jiang,Hans D. Schotten*

Main category: cs.IT

TL;DR: 本文通过建立统一分析框架和优化策略，确定了cell-free大规模MIMO系统中最有效的上行链路技术


<details>
  <summary>Details</summary>
Motivation: 现有研究存在方法碎片化和假设不一致的问题（如单天线vs多天线接入点、理想vs空间相关信道），需要统一评估不同技术

Method: 建立统一分析框架兼容集中式/分布式处理和多样化合并方案；开发最大最小功率控制的通用优化策略；对四个关键指标进行整体研究

Result: 通过分析和评估，最终确定了实际cell-free部署中的最优上行链路技术

Conclusion: 该研究为cell-free大规模MIMO系统提供了系统性的性能评估框架，并识别出最适合实际部署的上行技术

Abstract: This paper seeks to determine the most efficient uplink technique for
cell-free massive MIMO systems. Despite offering great advances, existing works
suffer from fragmented methodologies and inconsistent assumptions (e.g.,
single- vs. multi-antenna access points, ideal vs. spatially correlated
channels). To address these limitations, we: (1) establish a unified analytical
framework compatible with centralized/distributed processing and diverse
combining schemes; (2) develop a universal optimization strategy for max-min
power control; and (3) conduct a holistic study among four critical metrics:
worst-case user spectral efficiency (fairness), system capacity, fronthaul
signaling, and computational complexity. Through analyses and evaluation, this
work ultimately identifies the optimal uplink technique for practical cell-free
deployments.

</details>


### [38] [On the non-existence of perfect codes in the sum-rank metric](https://arxiv.org/abs/2508.20940)
*Giuseppe Del Prete,Antonio Roccolano,Ferdinando Zullo*

Main category: cs.IT

TL;DR: 本文研究了和秩度量中的完美码，这是汉明度量和秩度量的推广。论文分析了和秩度量球的几何特性，推导了体积界限，并针对双块和多块空间建立了完美码存在性和非存在性的条件约束。


<details>
  <summary>Details</summary>
Motivation: 和秩度量在多重网络编码和空时编码中具有重要应用，但相比汉明度量和秩度量中完美码的完整分类，和秩度量中的完美码存在性问题仍然很大程度上是开放的，需要深入研究。

Method: 通过分析和秩度量球的几何特性，推导球体积的界限和球包装界限的应用。针对双块空间确定参数约束，对多块空间建立非存在性结果，并基于度量球体积的同余条件提供计算证据。

Result: 确定了双块空间中完美码存在的显式参数约束，建立了多块空间中针对不同最小距离范围、可除性条件和码维度的非存在性结果，提供了基于同余条件的计算证据。

Conclusion: 和秩度量中的完美码存在性受到严格限制，论文为这一领域的理论研究提供了重要的几何分析和参数约束，推进了对和秩度量编码结构的理解。

Abstract: We study perfect codes in the sum-rank metric, a generalization of both the
Hamming and rank metrics relevant in multishot network coding and space-time
coding. A perfect code attains equality in the sphere-packing bound,
corresponding to a partition of the ambient space into disjoint metric balls.
While perfect codes in the Hamming and rank metrics are completely classified,
the existence of nontrivial perfect codes in the sum-rank metric remains
largely open. In this paper, we investigate linear perfect codes in the
sum-rank metric. We analyze the geometry of balls and derive bounds on their
volumes, showing how the sphere-packing bound applies. For two-block spaces, we
determine explicit parameter constraints for the existence of perfect codes.
For multiple-block spaces, we establish non-existence results for various
ranges of minimum distance, divisibility conditions, and code dimensions. We
further provide computational evidence based on congruence conditions imposed
by the volume of metric balls.

</details>


### [39] [On Secrecy Capacity of Binary Beampointing Channels with Block Memory and Feedback](https://arxiv.org/abs/2508.20980)
*Siyao Li,Mingzhe Chen,Shuangyang Li,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文研究了具有块内存和反馈的二进制波束指向信道的保密容量，提出了联合通信和自适应感知方案，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 毫米波系统中波束成形传输和反向散射反馈的保密通信需求，需要研究在块内存和反馈条件下的保密容量界限。

Method: 提出了基于主信道的保密容量闭式上界，设计了联合通信和自适应感知方案，通过策略性利用反馈来平衡合法用户感知和防止信息泄露。

Result: 仿真结果显示随着块长度增加，内外界之间的差距逐渐缩小，证明了所提方案的有效性。

Conclusion: JCAS方案能够有效利用反馈机制，在毫米波系统中实现安全的波束成形通信，为实际系统设计提供了理论指导。

Abstract: This paper investigates the secrecy capacity of the binary beampointing (BBP)
channel with block memory and feedback, a simplified yet insightful model for
millimeter-wave (mmWave) systems with beamformed transmissions and backscatter
feedback. We consider a system where a legitimate receiver and a passive
eavesdropper experience independent and uniformly distributed angular
directions over transmission blocks, with the base station receiving noiseless,
unit-delayed feedback from both, under the per-symbol input cost constraints.
We establish a closed-form upper bound on the secrecy capacity, which is based
on the main channel between the base station and the legitimate receiver.
Moreover, we propose a joint communication and adaptive sensing (JCAS) scheme
and derive its achievable secrecy rate. Simulation results show that the gap
between the inner and outer bounds narrows as the number of block length
increases. This reveals the efficiency of this JCAS scheme, which strategically
leverages feedback to balance the demands of sensing the legitimate user and
preventing information leakage to the eavesdropper.

</details>


### [40] [On the Sensing Capacity of Gaussian "Beam-Pointing" Channels with Block Memory and Feedback](https://arxiv.org/abs/2508.20997)
*Siyao Li,Shuangyang Li,Giuseppe Caire*

Main category: cs.IT

TL;DR: 论文研究了依赖于状态的高斯光束指向通道的感知容量问题，提出了聚合通信与感知的方案，并对感知容量进行了上界和可达性分析。


<details>
  <summary>Details</summary>
Motivation: 面向于5G/6G高频通信需求（如毫米波、辅太赫粒子波），探索状态依赖的高斯光束指向通道模型，其中通道状态定义了未知的离开角，需要通过严格因果反馈来估计离开角。

Method: 提出了聚合通信与感知的方案，通过动态规划法求解感知容1的上界，并提出了可达的内部界限，以优化问题形式表达。

Result: 对于Q=1的特殊情况，提出的传输方案达到了最优感知速率，并显示了感知与通信性能之间的本质交换关系。

Conclusion: 论文成功地对高斯光束指向通道的感知容量进行了理论分析，提供了上界和可达性结果，为将来高频通信系统中通信与感知的聚合设计提供了重要理论基础。

Abstract: Driven by the demands of high-frequency wireless communications in 5G and 6G
systems (e.g., mmWave, sub-THz), we explore a state-dependent {\em Gaussian
beam-pointing} (GBP) channel. In this model, the channel state defines an
unknown angle of departure (AoD), which remains constant within each coherence
block of $Q$ time slots but changes independently across blocks. The
transmitter receives strictly causal feedback which may originate from a radar
detection system or explicit feedback from the receiver at the end of each slot
and estimates the AoD at the end of each block. To enhance transmission
efficiency, we propose a joint communication and sensing scheme. While the
communication capacity of the GBP channel has been previously analyzed by the
authors, this work focuses on sensing capacity, characterized by the mutual
information between the channel state and the feedback conditioned on the
transmitted signal. We derive an upper bound using dynamic programming and
propose an achievable inner bound on the sensing capacity, both formulated as
optimization problems. For the special case of $Q=1$, the proposed transmission
scheme achieves the optimal sensing rate and highlights the inherent trade-off
between sensing and communication performance.

</details>
