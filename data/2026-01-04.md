<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Improving Reliability of Human Trafficking Alerts in Airports](https://arxiv.org/abs/2512.23865)
*Nana Oye Akrofi Quarcoo,Milena Radenkovic*

Main category: cs.NI

TL;DR: 该研究在机场个人紧急警报场景中评估两种DTN协议（Spray and Wait与Epidemic）的投递率和延迟性能，并探讨DTN网络在打击人口贩运中的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估延迟容忍网络（DTN）协议在机场个人紧急警报场景中的性能，特别是投递率和延迟指标，并探索DTN技术在打击人口贩运等全球性问题中的潜在应用价值。

Method: 使用Opportunistic Network Environment（ONE）模拟器构建机场场景，应用两种基准DTN协议（Spray and Wait和Epidemic）进行仿真，评估投递率和延迟性能指标。

Result: 研究分析了两种协议在机场紧急警报场景中的性能表现，讨论了各自的优势和局限性，同时指出了模拟实验设置的约束条件。

Conclusion: DTN网络在机场紧急警报等场景中具有应用潜力，不同协议各有优劣；研究还扩展讨论了DTN技术在打击人口贩运等全球社会问题中的潜在作用。

Abstract: This paper investigates the latter scenario of individual emergency alerts in airports by applying two existing benchmark delay tolerant network protocols and evaluating their performance of delivery ratio and latency. First, the paper provides a background on Mobile Ad Hoc Networks (MANETs) and Delay Tolerant Networks (DTNs), as well as Vehicular Ad Hoc Networks (VANETs) as a subset of MANETs. Next, the scenario is simulated using the Opportunistic Network Environment (ONE) simulator and runs the DTN protocols applying Spray and Wait and Epidemic. The study discusses the results, highlighting the advantages and limitations of each protocol within the scenario and addressing constraints of the simulation or experimental setup. A wider discussion then considers related research on technologies that combat human trafficking and the potential role of DTN networks in improving this global issue for the better.

</details>


### [2] [Wireless Multimodal Foundation Model (WMFM): Integrating Vision and Communication Modalities for 6G ISAC Systems](https://arxiv.org/abs/2512.23897)
*Mohammad Farzanullah,Han Zhang,Akram Bin Sediq,Ali Afana,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 提出基于对比学习的无线多模态基础模型WMFM，联合学习无线信道系数和视觉图像，在ISAC系统中实现可扩展的多模态学习，显著提升下游任务性能并大幅减少训练时间和数据需求。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中集成感知与通信模态为开发通用化、数据高效模型提供了独特机会。多模态基础模型的出现使得跨数据类型的联合理解成为可能，但需要专门针对无线通信场景的解决方案。

Method: 提出无线多模态基础模型WMFM，采用对比学习进行预训练，对齐相机和信道数据的嵌入表示而无需显式标签。预训练编码器冻结后作为特征提取器，配合轻量级任务特定头部进行下游任务微调。

Result: 在DeepVerse6G数据集上，WMFM在LoS/nLoS分类任务上平衡准确率提升17%，定位误差减少48.5%，训练时间减少高达90倍。即使仅使用20%数据训练，WMFM仍优于完全监督的端到端模型。

Conclusion: WMFM为ISAC系统中的可扩展多模态学习奠定了基础，展示了对比学习在无线多模态任务中的有效性，为智能自适应6G网络开辟了道路。

Abstract: The emergence of multimodal foundation models has revolutionized learning paradigms by enabling joint understanding across diverse data types. In the context of next-generation wireless networks, integrating sensing and communication modalities presents a unique opportunity to develop generalizable and data-efficient models. In this work, we introduce the contrastive learning based Wireless Multimodal Foundation Model (WMFM), a large-scale framework that jointly learns from wireless channel coefficients and visual imagery. The WMFM is pretrained using contrastive learning, a self-supervised learning technique that aligns embeddings of camera and channel data without requiring explicit labels. The pretrained encoders are then frozen and employed as feature extractors, with lightweight task-specific heads, fine-tuned for downstream tasks, including user localization and LoS/nLoS classification. Extensive experiments on the DeepVerse6G dataset demonstrate that the proposed WMFM achieves a 17% improvement in balanced accuracy for LoS/nLoS classification and a 48.5% reduction in localization error compared to the end-to-end (E2E) benchmark, while reducing training time by up to 90-fold. Even when trained with as little as 20% of the data, the WMFM-based heads outperform the fully supervised E2E model, underscoring their robustness and data-efficient learning. The proposed approach establishes a foundation for scalable, multimodal learning in Integrated Sensing and Communication (ISAC) systems, paving the way for intelligent and adaptive 6G networks.

</details>


### [3] [Road Rules for Radio: Why Your Wi-Fi Got Better](https://arxiv.org/abs/2512.23901)
*Bradley Fang,Michael Roger*

Main category: cs.NI

TL;DR: 本文对WiFi技术发展进行全面的文献综述，聚焦七个关键领域，使用公路类比帮助理解，并探讨即将发布的WiFi 8标准。


<details>
  <summary>Details</summary>
Motivation: WiFi技术发展迅速但进展复杂，普通用户难以全面理解其发展脉络。本文旨在填补这一知识空白，通过系统综述帮助读者理解WiFi技术演进。

Method: 采用文献综述方法，围绕七个关键领域（带宽、电池寿命、流量冲突、干扰、数据密集型传输、多设备连接、峰值吞吐量/调制）展开分析，并引入公路/高速公路类比来简化网络机制的理解。

Result: 系统梳理了WiFi技术发展历程，分析了各领域的问题、解决方案及其局限性，特别探讨了基于IEEE 802.11bn标准的WiFi 8在可靠性方面的重大转变。

Conclusion: WiFi技术正从单纯追求数据速率转向更注重可靠性，WiFi 8标准代表了这一重要转变。通过系统综述和类比方法，本文使复杂技术变得易于理解。

Abstract: WiFi allows for the connection of devices and people around the globe. It has proven to be a monumental and revolutionary tool that keeps the world connected. However, recent WiFi advancements are numerous and at times confusing. WiFi has grown significantly over the years, yet few understand the scope and scale of WiFi progression as a whole. This paper tackles that problem, providing a broad literature review on the advancements of key WiFi features to date. This paper will center on seven key areas of focus: (1) bandwidth, (2) battery life, (3) traffic collisions, (4) interference, (5) data-intensive transmissions, (6) numerous devices, and (7) peak throughput/modulation. Each section will focus on WiFi's problems, how those problems were fixed, as well as the limitations of existing solutions. Moreover, the paper explains the role of new unreleased technologies in these seven areas. This includes exploring the upcoming WiFi 8 standard based on the IEEE 802.11bn "Ultra High Reliability" (UHR) specification and how it builds upon current specifications. Compared to previous specifications, WiFi 8 marks a stronger and more significant shift toward prioritizing reliability over pure data rates. Beyond a sole literature review, this paper uses a novel analogy. A road/highway analogy will be integrated throughout the paper to facilitate understanding of networking mechanisms. This paper is approachable and is written such that someone with very little WiFi knowledge should come away with a strong understanding of WiFi. As is typical of literature review papers, technical claims will be grounded in prior work.

</details>


### [4] [SRM at 30: Lessons from Early Data-Centric Networking and Their Impact on Named Data Networking](https://arxiv.org/abs/2512.23928)
*Tianyuan Yu,Adam Thieme,Junxiao Shi,Lan Wang,Lixia Zhang*

Main category: cs.NI

TL;DR: 这篇论文回顾了1995年SRM框架及其对NDN的影响，探讨了数据为中心的网络架构演进


<details>
  <summary>Details</summary>
Motivation: 重新审视SRM框架，分析其面临的挑战、获得的经验教训，以及它如何影响后来命名数据网络（NDN）的发展

Method: 通过回顾性分析，对比SRM的数据中心模型与传统IP地址模型的差异，探讨SRM实验揭示的问题

Result: SRM实验揭示了其数据为中心框架与IP地址交付之间的语义不匹配，而NDN通过将网络交付与数据检索模型对齐来解决这一架构摩擦

Conclusion: SRM的早期见解为NDN的关键设计决策提供了信息，NDN的设计源自数十年网络研究和开发的累积洞察

Abstract: A 1995 SIGCOMM paper, "A Reliable Multicast Framework for Light-weight Sessions and Application-Level Framing", commonly known as SRM, explored a fundamentally new approach to reliable multiparty data delivery. Rather than adapting established sender-driven reliable unicast mechanisms to multicast, as most contemporaneous proposals did, SRM introduced a data-centric model in which data receivers recover losses by explicitly requesting missing data. Thirty years later, we revisit the SRM framework, examining the challenges it faced, the lessons learned, and its influence on the later development of Named Data Networking (NDN). Experimentations with SRM revealed a fundamental semantic mismatch between its data-centric framework and IP's address-based delivery; while the application layer named data, the network layer remained 'blind' to those names, resulting in inefficient loss recovery. NDN resolves this architectural friction by aligning network delivery with the data-retrieval model and by securing data directly rather than securing communication channels. This retrospective highlights how early insights from SRM informed key design decisions in NDN and illustrates how NDN's design emerged from the cumulative insights gained over decades of networking research and development.

</details>


### [5] [Beyond Dedicated-Active: A General Reliability Provisioning Framework for SFC Placement in Fog Computing](https://arxiv.org/abs/2512.24049)
*Negin Doostar,Mohammad Reza Heidarpour,Amir Khorsandi*

Main category: cs.NI

TL;DR: 本文针对异构雾计算环境中的可靠性感知服务功能链放置问题，提出基于遗传算法的解决方案，比较了四种冗余策略，发现共享-备用策略比传统专用-主动策略性能提升高达84%。


<details>
  <summary>Details</summary>
Motivation: 物联网设备爆炸式增长对传统云基础设施造成压力，需要低延迟、高能效的边缘计算方案。雾计算将计算放在网络边缘，但资源有限且异构，对关键任务应用的可靠性构成挑战。同时，服务功能链部署方式虽然灵活，但比单体部署更容易失败，需要智能的冗余和放置策略。

Method: 1. 从可靠性理论角度分析异构雾服务器上的SFC放置问题；2. 探索四种冗余策略（共享vs专用、主动vs备用）；3. 提出最小化延迟和成本的通用框架；4. 将问题建模为整数非线性规划；5. 开发两种基于遗传算法的解决方案。

Result: 仿真结果表明，共享-备用冗余策略在性能上显著优于传统的专用-主动方法，性能提升高达84%。

Conclusion: 本文为解决雾计算环境中可靠性感知的SFC放置问题提供了有效框架，通过智能的冗余策略和遗传算法优化，能够在满足可靠性和截止时间约束的同时，显著降低延迟和成本。

Abstract: The explosive growth of Internet of Things (IoT) devices has strained traditional cloud infrastructures, highlighting the need for low-latency and energy-efficient alternatives. Fog computing addresses this by placing computation near the network edge. However, limited and heterogeneous fog resources pose reliability challenges, especially for mission-critical applications. On the other hand, to improve flexibility, applications are deployed as Service Function Chains (SFCs), where each function runs as a Virtual Network Function (VNF). While scalable, this approach is more failure-prone than monolithic deployments, necessitating intelligent redundancy and placement strategies. This paper addresses the reliability-aware SFC placement problem over heterogeneous fog servers through the lens of reliability theory. We explore four redundancy strategies, combining shared vs. dedicated and active vs. standby modes, and propose a general framework to minimize latency and cost while meeting reliability and deadline constraints. The problem is formulated as an Integer Non-Linear Program (INLP), and two genetic algorithm (GA)-based solutions are developed. Simulation results show that shared-standby redundancy outperforms the conventional dedicated-active approach by up to 84%.

</details>


### [6] [Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations](https://arxiv.org/abs/2512.24452)
*Yalin E. Sagduyu,Tugba Erpek,Aylin Yener,Sennur Ulukus*

Main category: cs.NI

TL;DR: 提出一种深度学习语义通信框架，在支持多接收器任务的同时限制向窃听者的语义泄露，通过min-max优化和对抗扰动层增强安全性。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽然提高了带宽效率和鲁棒性，但学习到的语义表示仍可能向非授权接收者（窃听者）泄露敏感信息，需要设计能同时支持多任务并限制语义泄露的安全框架。

Method: 采用深度学习框架，合法链路使用学习编码器，接收器训练语义推理和数据重建解码器。通过迭代min-max优化：窃听者训练提升语义推理能力，合法收发器对训练保持任务性能同时降低窃听者成功率。还引入辅助层在传输波形上叠加对抗性扰动以降低语义泄露。

Result: 在瑞利衰落信道和加性高斯白噪声环境下，使用MNIST和CIFAR-10数据集评估。语义准确性和重建质量随潜在维度增加而提高，min-max机制显著降低窃听者推理性能而不影响合法接收器。扰动层即使合法链路仅为自己任务训练也能有效减少语义泄露。

Conclusion: 该综合框架为现实无线环境中对抗自适应对手提供了可调谐、端到端的隐私保护语义通信设计思路，实现了任务性能与安全性的平衡。

Abstract: Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.

</details>


### [7] [CPePC: Cooperative and Predictive Popularity based Caching for Named Data Networks](https://arxiv.org/abs/2512.24073)
*Pankaj Chaudhary,Neminath Hubballi,Sameer G. Kulkarni*

Main category: cs.NI

TL;DR: CPePC是一种基于社区检测和领导者协调的协作缓存技术，通过减少流行度估计开销并预测缓存决策参数来提高NDN缓存性能


<details>
  <summary>Details</summary>
Motivation: 现有NDN缓存技术依赖内容流行度估计，但协调和估计开销大。需要一种能减少开销同时保持缓存性能的方法

Method: 1) 使用社区估计算法将网络划分为非重叠社区，选择领导者节点协调社区内流行度估计；2) 基于当前缓存占用率和内容流行度预测缓存决策参数；3) 提供社区检测、领导者选择、内容流行度估计和缓存决策算法

Result: 通过离散事件模拟器与六种先进缓存技术比较，CPePC在性能上优于其他方法

Conclusion: CPePC通过减少流行度估计开销和智能预测缓存参数，有效提高了NDN缓存性能，是一种高效的协作缓存技术

Abstract: Caching content is an inherent feature of Named Data Networks. Limited cache capacity of routers warrants that the choice of content being cached is judiciously done. Existing techniques resort to caching popular content to maximize utilization. However, these methods experience significant overhead for coordinating and estimating the popularity of content. To address this issue, in this paper, we present CPePC, which is a cooperative caching technique designed to improve performance. It accomplishes this through a combination of two factors. First, CPePC enhances efficiency by minimizing the overhead of popularity estimation. Second, it forecasts a parameter that governs caching decisions. Efficiency in popularity estimation is achieved by dividing the network into several non-overlapping communities using a community estimation algorithm and selecting a leader node to coordinate this on behalf of all the nodes in the community. CPePC bases its caching decisions by predicting a parameter whose value is estimated using current cache occupancy and the popularity of the content into account. We present algorithms for community detection, leader selection, content popularity estimation, and caching decisions made by the CPePC method. We evaluate and compare it with six other state-of-the-art caching techniques, with simulations performed using a discrete event simulator to show that it outperforms others.

</details>


### [8] [Chat-Driven Optimal Management for Virtual Network Services](https://arxiv.org/abs/2512.24614)
*Yuya Miyaoka,Masaki Inoue,Kengo Urata,Shigeaki Harada*

Main category: cs.NI

TL;DR: 提出聊天驱动的网络管理框架，结合NLP与优化算法，实现直观可靠的虚拟网络服务重配置


<details>
  <summary>Details</summary>
Motivation: 传统基于意图的网络管理方法依赖统计语言模型解释用户意图，但无法保证生成配置的可行性

Method: 两阶段框架：解释器（使用Sentence-BERT+SVM或LLM提取意图）将用户聊天转换为参数更新方向；优化器通过整数线性规划计算可行的VM放置和路由

Result: 框架能在单用户和多用户场景中动态更新VM放置和路由，同时保持可行性。LLM提取器在少量标注样本下精度更高，Sentence-BERT+SVM延迟更低适合实时操作

Conclusion: NLP驱动的意图提取与基于优化的分配相结合，能实现安全、可解释、用户友好的虚拟网络管理

Abstract: This paper proposes a chat-driven network management framework that integrates natural language processing (NLP) with optimization-based virtual network allocation, enabling intuitive and reliable reconfiguration of virtual network services. Conventional intent-based networking (IBN) methods depend on statistical language models to interpret user intent but cannot guarantee the feasibility of generated configurations. To overcome this, we develop a two-stage framework consisting of an Interpreter, which extracts intent from natural language prompts using NLP, and an Optimizer, which computes feasible virtual machine (VM) placement and routing via an integer linear programming. In particular, the Interpreter translates user chats into update directions, i.e., whether to increase, decrease, or maintain parameters such as CPU demand and latency bounds, thereby enabling iterative refinement of the network configuration. In this paper, two intent extractors, which are a Sentence-BERT model with support vector machine (SVM) classifiers and a large language model (LLM), are introduced. Experiments in single-user and multi-user settings show that the framework dynamically updates VM placement and routing while preserving feasibility. The LLM-based extractor achieves higher accuracy with fewer labeled samples, whereas the Sentence-BERT with SVM classifiers provides significantly lower latency suitable for real-time operation. These results underscore the effectiveness of combining NLP-driven intent extraction with optimization-based allocation for safe, interpretable, and user-friendly virtual network management.

</details>


### [9] [Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks](https://arxiv.org/abs/2512.24659)
*Yixian Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Changyuan Zhao,Daxin Tian,Dusit Niyato,Shiwen Mao*

Main category: cs.NI

TL;DR: 提出IRS增强的低空MEC架构，通过分层在线优化方法（HOOA）联合优化任务卸载、无人机轨迹、IRS相移和计算资源分配，降低任务完成延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决低空MEC系统中由于遮挡导致的空-地连接问题，并同时优化任务完成延迟和能耗，需要设计智能的IRS增强架构和高效的优化算法。

Method: 提出IRS增强的低空MEC架构，采用分层在线优化方法（HOOA）：1）将多目标优化问题重构为Stackelberg博弈；2）在跟随者层使用多对一匹配机制生成离散决策；3）在领导者层提出GDMTD3算法（生成扩散模型增强的TD3）结合KKT方法处理连续决策。

Result: 仿真结果表明，HOOA相比最佳基准方法平均任务完成延迟降低2.5%，相比最先进DRL算法平均能耗降低3.1%，同时表现出优越的收敛稳定性、鲁棒性和可扩展性。

Conclusion: 提出的IRS增强低空MEC架构和分层优化方法能有效提升系统性能，为动态环境中的边缘计算服务提供了高效可靠的解决方案。

Abstract: In this paper, we propose an intelligent reflecting surface (IRS)-enabled low-altitude multi-access edge computing (MEC) architecture, where an aerial MEC server cooperates with a terrestrial MEC server to provide computing services, while hybrid IRSs (i.e., building-installed and UAV-carried IRSs) are deployed to enhance the air-ground connectivity under blockage. Based on this architecture, we formulate a multi-objective optimization problem (MOOP) to minimize the task completion delay and energy consumption by jointly optimizing task offloading, UAV trajectory control, IRS phase-shift configuration, and computation resource allocation. The considered problem is NP-hard, and thus we propose a hierarchical online optimization approach (HOOA) to efficiently solve the problem. Specifically, we reformulate the MOOP as a Stackelberg game, where MEC servers collectively act as the leader to determine the system-level decisions, while the vehicles act as followers to make individual decisions. At the follower level, we present a many-to-one matching mechanism to generate feasible discrete decisions. At the leader level, we propose a generative diffusion model-enhanced twin delayed deep deterministic policy gradient (GDMTD3) algorithm integrated with a Karush-Kuhn-Tucker (KKT)-based method, which is a deep reinforcement learning (DRL)-based approach, to determine the continuous decisions. Simulation results demonstrate that the proposed HOOA achieves significant improvements, which reduces average task completion delay by 2.5% and average energy consumption by 3.1% compared with the best-performing benchmark approach and state-of-the-art DRL algorithm, respectively. Moreover, the proposed HOOA exhibits superior convergence stability while maintaining strong robustness and scalability in dynamic environments.

</details>


### [10] [Analyzing Communication Predictability in LLM Training](https://arxiv.org/abs/2512.24750)
*Wenxue Li,Xiangzhou Liu,Yuxuan Li,Yilun Jin,Zhenghang Ren,Xudong Liao,Han Tian,Bo Ren,Zhizhen Zhong,Guyue Liu,Ying Zhang,Kai Chen*

Main category: cs.NI

TL;DR: 本文系统分析了分布式训练中通信可预测性，特别针对大语言模型混合并行场景，提出了通信开销分析模型和配置优化工具ConfigTuner，相比现有方法显著提升训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过在线分析利用通信可预测性进行运行时优化，但缺乏对通信可预测性的系统性理解。特别是在大语言模型混合并行训练中，需要系统性地理解和建模通信可预测性。

Method: 1. 系统分析大语言模型训练中的可预测流量模式；2. 评估各种因素对GPU利用率和有效带宽的影响；3. 开发通信开销分析模型并进行实验验证；4. 基于该模型开发配置调优工具ConfigTuner。

Result: 1. 提出的通信开销分析模型与实验数据高度吻合；2. ConfigTuner优化的训练配置相比Megatron-LM实现最高1.36倍的吞吐量提升；3. 相比Alpa，ConfigTuner能生成相同配置建议同时显著降低搜索复杂度。

Conclusion: 本文系统性地建模了分布式训练中的通信可预测性，提出的分析模型能准确估计通信开销，基于此开发的ConfigTuner工具能有效优化训练配置，显著提升大语言模型训练性能。

Abstract: Effective communication is essential in distributed training, with predictability being one of its most significant characteristics. However, existing studies primarily focus on exploiting predictability through online profiling for runtime optimization, without a systematic understanding of it. In this work, we aim to systematically formulate communication predictability in distributed training, particularly in Large Language Models (LLMs) that utilize hybrid parallelism. Our analysis focuses on both traffic patterns and communication overhead. Specifically, we investigate predictable traffic patterns in typical LLMs and evaluate how various factors influence GPU utilization and effective bandwidth (two critical variables affecting communication overhead). Furthermore, we develop an analytical formulation to estimate communication overhead in LLM training, which is validated with high accuracy against empirical data. Leveraging this formulation, we propose a configuration tuning tool, ConfigTuner, to optimize training performance. Compared to Megatron-LM, the training configurations optimized by ConfigTuner demonstrate up to a 1.36$\times$ increase in throughput. Compared to Alpa, ConfigTuner generates the same configuration suggestion while significantly reducing the search complexity.

</details>


### [11] [Sidelink Positioning: Standardization Advancements, Challenges and Opportunities](https://arxiv.org/abs/2512.24803)
*Yuan Gao,Guangjin Pan,Zhiyong Zhong,Zhengyu Jin,Yichen Hu,Yifei Jin,Shugong Xu*

Main category: cs.NI

TL;DR: 本文全面总结了3GPP Rel-18中SL定位的最新标准化进展，评估了SL定位在不同不完美因素下的性能，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着蜂窝网络在V2X、公共安全、IIoT等需要精确定位信息的垂直行业中的集成，定位已成为未来无线网络的关键组成部分。传统蜂窝定位在UE与BS距离较大或NLoS场景下性能下降，因此3GPP Rel-18提出标准化SL定位以通过UE间的直接定位信令扩展定位覆盖范围。

Method: 本文采用标准化文献综述和性能评估相结合的方法：1）全面总结3GPP Rel-18中SL定位的标准化进展，包括网络架构、定位类型和性能要求；2）评估不同定位方法在各种不完美因素下的SL定位能力；3）基于3GPP Rel-19的演进讨论SL定位的可能研究方向和挑战。

Result: 研究显示SL定位能够通过UE间的直接信令扩展定位覆盖范围，特别是在传统蜂窝定位性能下降的场景中。然而，SL定位的能力存在争议，特别是在实现3GPP定义的定位精度所需的频谱量方面。文章评估了不同定位方法在各种不完美因素下的性能表现。

Conclusion: SL定位为未来无线网络提供了重要的定位能力扩展，特别是在传统蜂窝定位受限的场景中。虽然3GPP Rel-18已取得标准化进展，但SL定位的实际能力仍需进一步研究和验证。基于3GPP Rel-19的演进，未来研究方向包括优化定位算法、频谱效率提升、多UE协同定位等挑战。

Abstract: With the integration of cellular networks in vertical industries that demand precise location information, such as vehicle-to-everything (V2X), public safety, and Industrial Internet of Things (IIoT), positioning has become an imperative component for future wireless networks. By exploiting a wider spectrum, multiple antennas and flexible architectures, cellular positioning achieves ever-increasing positioning accuracy. Still, it faces fundamental performance degradation when the distance between user equipment (UE) and the base station (BS) is large or in non-line-of-sight (NLoS) scenarios. To this end, the 3rd generation partnership project (3GPP) Rel-18 proposes to standardize sidelink (SL) positioning, which provides unique opportunities to extend the positioning coverage via direct positioning signaling between UEs. Despite the standardization advancements, the capability of SL positioning is controversial, especially how much spectrum is required to achieve the positioning accuracy defined in 3GPP. To this end, this article summarizes the latest standardization advancements of 3GPP on SL positioning comprehensively, covering a) network architecture; b) positioning types; and c) performance requirements. The capability of SL positioning using various positioning methods under different imperfect factors is evaluated and discussed in-depth. Finally, according to the evolution of SL in 3GPP Rel-19, we discuss the possible research directions and challenges of SL positioning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: BatteryAgent：融合物理知识与LLM推理的锂电池故障诊断分层框架，实现从"被动检测"到"智能诊断"的范式转变


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法的"黑盒"特性缺乏可解释性，且受限于二分类范式，难以提供根本原因分析和维护建议

Method: 提出三层框架：物理感知层（10个电化学机制特征）、检测归因层（梯度提升决策树+SHAP）、推理诊断层（LLM作为智能体核心，构建"数值-语义"桥梁）

Result: AUROC达到0.986，显著优于现有方法，有效纠正硬边界样本的误分类，实现多类型可解释诊断

Conclusion: BatteryAgent将传统二值检测扩展到多类型可解释诊断，为电池安全管理提供了从"被动检测"到"智能诊断"的新范式

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [13] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 论文提出DDFT协议评估语言模型在语义压缩和对抗攻击下的认知稳健性，发现模型规模与稳健性无关，而错误检测能力是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估（如MMLU、TruthfulQA）只测量理想条件下的知识，无法评估模型在信息退化或对抗攻击下的稳健性。需要一种能区分模型是否真正"知道"而非只是表面流畅的评估方法。

Method: 提出Drill-Down and Fabricate Test (DDFT)协议，通过渐进语义压缩和对抗性伪造来测量认知稳健性。采用两系统认知模型：语义系统生成流畅文本，认知验证器验证事实准确性。评估了9个前沿模型在8个知识领域和5个压缩级别（共1800轮评估）。

Result: 认知稳健性与传统设计范式正交：参数数量(r=0.083)和架构类型(r=0.153)均不显著预测稳健性。错误检测能力强烈预测整体稳健性(rho=-0.817, p=0.007)。旗舰模型虽大规模但表现脆弱，而小模型也能实现稳健性能。

Conclusion: 认知稳健性主要来自训练方法和验证机制，而非模型规模或架构。DDFT框架为关键应用部署前评估认知稳健性提供了理论基础和实用工具，挑战了模型规模与可靠性的传统假设。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [14] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE是一个自我进化的LLM智能体框架，通过持续学习和自我反思掌握复杂工具，在材料科学和化学任务上达到93.3%成功率


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性，需要从"LLM+工具使用"向"LLM+技能获取"转变

Method: CASCADE框架通过两种元技能实现自我进化：1) 持续学习（网络搜索和代码提取） 2) 自我反思（内省和知识图谱探索），使智能体能够掌握外部工具并将知识编码化

Result: 在包含116个材料科学和化学研究任务的SciSkillBench基准测试中，使用GPT-5的CASCADE达到93.3%成功率，相比没有进化机制的35.4%有显著提升，并在计算分析、自主实验室实验和论文复现中展示了实际应用

Conclusion: CASCADE通过积累可执行技能，支持智能体间和科学家间的技能共享，结合人机协作和记忆巩固，推动可扩展的AI辅助科学研究发展

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [15] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy框架结合大语言模型与答案集编程，通过LLM将医学文献转化为ASP代码，结合患者数据进行疾病诊断，提供可解释的预测系统。


<details>
  <summary>Details</summary>
Motivation: 准确的疾病预测对及时干预、有效治疗和减少医疗并发症至关重要。虽然符号AI已应用于医疗保健，但由于构建高质量知识库需要大量努力，其采用仍然有限。

Method: McCoy框架结合大型语言模型（LLMs）与答案集编程（ASP）。它通过LLM将医学文献翻译成ASP代码，结合患者数据，然后使用ASP求解器进行处理以得出最终诊断。

Result: 初步结果显示，McCoy在小规模疾病诊断任务上表现出色，具有强大的性能。

Conclusion: McCoy框架通过结合LLMs和ASP，克服了符号AI在医疗领域应用的知识库构建障碍，创建了一个强大且可解释的疾病预测系统。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [16] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态检索和个性化，模拟人类信息寻求行为的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统个性化搜索系统受限于静态用户画像和单一检索流程，无法捕捉用户动态、多维的信息需求变化。需要一种能够模拟人类信息寻求行为的复杂性、流动性和上下文敏感性的新一代搜索系统。

Method: 1. 定义角色空间（角色、专业领域、任务上下文、领域）；2. 引入角色协调器动态解析查询并激活相关专业智能体；3. 每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和上下文感知推理模块；4. 通过结构化通信协议（共享内存库、迭代辩论、接力式知识传递）促进智能体协作。

Result: 该框架产生了关于协调效率、个性化质量和认知负载分布的可测试预测，同时包含自适应学习机制用于持续角色优化。通过整合细粒度智能体专业化和协作检索，为下一代搜索系统提供了理论基础。

Conclusion: SPARK框架展示了如何通过分布式智能体行为和最小协调规则产生涌现的个性化特性，为能够捕捉人类信息寻求行为复杂性、流动性和上下文敏感性的下一代搜索系统提供了重要见解。

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [17] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD是一个无需标注数据的自动提示优化框架，通过模拟人类工程师的调试过程，将失败日志转化为结构化决策树协议，在冷启动场景下显著提升LLM代理性能。


<details>
  <summary>Details</summary>
Motivation: 现实软件工程中，LLM代理开发初期通常缺乏标注数据集，只有混乱的生产日志和不断变化的失败模式。传统APO方法依赖大量标注数据进行进化或强化学习，不适用于冷启动场景。

Method: ROAD采用多智能体架构：1) Analyzer进行根因分析；2) Optimizer进行模式聚合；3) Coach进行策略整合。将优化视为动态调试调查而非随机搜索，将非结构化失败日志转化为结构化决策树协议。

Result: 在学术基准和生产知识管理引擎上评估：仅3次自动迭代就使成功率提升5.6%(73.6%→79.2%)，搜索准确率提升3.8%。在零售领域复杂推理任务上，相对基线提升约19%。

Conclusion: 模拟人类工程师的失败分析和补丁循环，为部署可靠LLM代理提供了资源高效、数据高效的替代方案，避免了资源密集的强化学习训练。

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [18] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化代理框架，通过整合LLM到"计划-执行-总结"认知范式，将进化搜索映射为推理密集型过程，显著提高进化效率并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法缺乏结构化推理，导致过早收敛和高维代码空间探索效率低下，阻碍了从静态LLM到自改进代理的过渡。

Method: 1) 整合LLM到"计划-执行-总结"认知范式；2) 采用混合进化记忆系统，结合多岛模型、MAP-Elites和自适应玻尔兹曼选择；3) 实例化为通用代理（算法发现）和ML代理（管道优化）。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow比领先基线（如OpenEvolve、ShinkaEvolve）进化效率提高达60%，同时发现更优解决方案。

Conclusion: LoongFlow在自主科学发现方面迈出重要一步，能够以更低计算开销生成专家级解决方案，解决了传统进化方法的局限性。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [19] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec是一个结合大语言模型和Soar认知架构的推荐系统代理，通过符号化推理和动态知识更新解决LLM的黑盒性、幻觉问题和在线学习能力不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐系统中虽然能理解用户偏好，但存在黑盒特性、知识幻觉和在线学习能力有限的问题，影响可信度和适应性。而认知架构如Soar虽然推理过程结构化可解释，但知识获取困难。需要结合两者优势。

Method: 提出CogRec认知推荐代理，以Soar作为核心符号推理引擎，用LLM进行知识初始化填充工作记忆中的产生式规则。采用感知-认知-行动循环，遇到障碍时动态查询LLM获取推理解决方案，通过Soar的组块机制转化为新的符号产生式规则，实现在线学习。

Result: 在三个公共数据集上的广泛评估表明，CogRec在推荐准确性、可解释性和解决长尾问题方面具有显著优势。

Conclusion: CogRec成功结合了LLM和认知架构的优势，通过符号化推理和动态知识更新机制，实现了准确、可解释且能持续进化的推荐系统，有效解决了现有方法的局限性。

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [20] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 提出一种无需训练、基于图结构的探索方法，用于解决ARC-AGI-3基准中的交互推理任务，显著优于当前最先进的LLM方法


<details>
  <summary>Details</summary>
Motivation: ARC-AGI-3基准包含类似游戏的交互推理任务，需要智能体通过有限交互推断任务机制并适应复杂度递增。当前最先进的LLM无法可靠解决这类任务，因此需要探索更有效的结构化方法

Method: 结合视觉帧处理和基于图结构的系统化状态空间探索：1) 将视觉帧分割为有意义组件；2) 基于视觉显著性优先选择动作；3) 维护有向图记录探索过的状态和转移；4) 通过跟踪访问状态和测试动作，优先选择到达未测试状态-动作对的最短路径动作

Result: 在ARC-AGI-3预览挑战中，该方法在6个游戏中解决了52个关卡的中位数30个，在私有排行榜上排名第3，显著优于前沿的LLM智能体

Conclusion: 即使无需学习，显式的图结构探索也能作为交互推理的强大基线方法，突显了在稀疏反馈环境中系统化状态跟踪和动作优先级的重要性，而当前LLM无法捕捉此类任务动态

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [21] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP（科学上下文协议）是一个开源标准，旨在通过构建全球自主科学代理网络来加速科学发现。它提供统一的资源集成规范和实验生命周期管理架构，已构建包含1600多种工具资源的科学发现平台。


<details>
  <summary>Details</summary>
Motivation: 当前科学工具、模型、数据集和物理仪器分散在不同平台和机构中，缺乏统一标准，导致AI代理和应用程序难以发现、调用和组合这些资源。需要建立协议级标准化来降低集成开销、增强可重复性，并促进异构AI系统与人类研究者之间的大规模协作。

Method: SCP基于两大支柱：1）统一资源集成：提供描述和调用科学资源的通用规范；2）编排的实验生命周期管理：采用集中式SCP Hub和联邦式SCP Server的安全服务架构，管理实验的注册、规划、执行、监控和归档全过程，实施细粒度认证授权，编排可追溯的端到端工作流。

Result: 基于SCP构建的科学发现平台已集成超过1600种工具资源。在多样化用例中，SCP促进了异构AI系统与人类研究者之间的安全大规模协作，显著降低了集成开销，增强了可重复性。

Conclusion: 通过在协议层面标准化科学上下文和工具编排，SCP为可扩展、多机构、代理驱动的科学研究建立了必要的基础设施，为加速科学发现提供了关键支撑。

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [22] [Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem](https://arxiv.org/abs/2512.24251)
*Pengfu Wan,Jiawei Chen,Gangyan Xu*

Main category: cs.AI

TL;DR: 本文提出一种基于深度强化学习的方法来解决车队规模与混合车辆路径问题，能够在几秒内生成接近最优解，特别适用于大规模和时间受限的场景。


<details>
  <summary>Details</summary>
Motivation: FSMVRP（车队规模与混合车辆路径问题）是车辆路径问题的重要变体，在实际应用中具有广泛价值，如短期车辆租赁和按需物流。然而，该问题需要同时决定车队组成和路径规划，增加了复杂性，特别是在大规模和时间受限的环境中面临显著挑战。

Method: 将问题建模为马尔可夫决策过程，开发了名为FRIPN的新型策略网络，无缝整合车队组成和路径决策。方法包含专门设计的输入嵌入，用于不同的决策目标，包括剩余图嵌入以促进有效的车辆使用决策。

Result: 在随机生成实例和基准数据集上的综合实验表明，该方法在计算效率和可扩展性方面表现出显著优势，特别是在大规模和时间受限的场景中。

Conclusion: 该方法展示了在实际应用中的潜力，并为将基于DRL的技术扩展到其他VRP变体提供了有价值的启发。

Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.

</details>


### [23] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: RSA是一种风险感知的逐步对齐方法，通过嵌套风险度量在策略优化中显式纳入风险意识，以解决传统安全对齐方法在应对罕见但灾难性有害行为方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法（如Safe RLHF和SACPO）通常在风险中性范式下运行，无法充分应对参考策略偏离带来的风险，且对罕见但潜在灾难性有害行为的鲁棒性有限。

Method: RSA将安全对齐表述为令牌级风险感知约束策略优化问题，通过逐步对齐程序解决，该程序产生从嵌套风险度量导出的令牌级策略更新。

Result: 实验结果表明，该方法在确保强安全性的同时实现了高水平的帮助性，并显著抑制了尾部风险（即低概率但高影响的不安全响应）。

Conclusion: RSA通过显式纳入风险意识，有效缓解了模型过度偏离参考策略的风险，并明确抑制了低概率但高影响的有害行为，为语言模型的安全对齐提供了更稳健的方法。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [24] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: 提出一种测试时自适应智能体，通过后验引导的信念细化进行探索性推理，无需梯度更新或额外训练，在部分可观测环境下运作


<details>
  <summary>Details</summary>
Motivation: 解决LLM智能体在部分可观测环境下需要梯度更新或额外训练的问题，提出更高效的推理时适应方法

Method: 维护外部结构化环境状态信念，通过动作条件观察迭代更新，使用轻量级LLM代理估计信息增益，通过新颖的一致性奖励评估世界对齐

Result: 方法优于推理时扩展基线（如提示增强或检索增强LLM），在潜在世界状态对齐方面表现更好，集成开销显著降低

Conclusion: 提出的测试时自适应智能体通过后验引导的信念细化，在部分可观测环境下实现了高效的世界状态对齐，无需额外训练

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [25] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 本文提出JEPA-WMs模型家族，通过系统研究架构、训练目标和规划算法，开发出优于现有基线的方法，在导航和操作任务中表现更佳。


<details>
  <summary>Details</summary>
Motivation: AI领域长期挑战是开发能够解决广泛物理任务并泛化到新任务的智能体。现有方法在输入空间规划，而新兴方法在表示空间规划有望提高效率，但缺乏系统研究。

Method: 提出JEPA-WMs模型家族，系统研究模型架构、训练目标和规划算法等关键组件，结合模拟环境和真实机器人数据进行实验。

Result: 提出的模型在导航和操作任务中优于两个基线方法DINO-WM和V-JEPA-2-AC，代码、数据和检查点已开源。

Conclusion: 通过系统研究JEPA-WMs家族的关键技术选择，找到了最优方法，证明了在表示空间规划的有效性，为物理任务智能体开发提供了新方向。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [26] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: 提出交互式评估框架，分析基础模型代理在符号地图环境中的探索、记忆和推理能力，发现结构化记忆对空间理解至关重要，性能提升不能仅靠模型缩放。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型空间能力评估多基于静态地图或文本查询，忽视了空间理解的交互性和经验驱动特性，需要更全面的评估框架来理解模型在动态地图环境中的表现。

Method: 设计交互式评估框架，让代理在部分可观测的网格地图中增量探索（包含道路、交叉口和兴趣点），仅接收局部观测，然后通过六类空间任务评估空间理解能力，系统变化探索策略、记忆表示和推理方案。

Result: 探索主要影响经验获取但对最终推理准确率影响有限；记忆表示在整合空间经验中起核心作用，结构化记忆（特别是序列和图表示）显著提升路径规划等结构密集型任务性能；推理方案影响存储空间知识的利用方式；空间推理性能在模型版本和规模达到一定阈值后饱和。

Conclusion: 地图空间理解的改进需要针对空间表示和推理的专门机制，而不仅仅是模型缩放；结构化记忆对空间理解至关重要，交互式评估能更全面揭示基础模型的空间能力。

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [27] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 该研究评估了三种主流LLM（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3）在密苏里大学数学竞赛问题上的表现，发现DeepSeek-V3在所有数学领域表现最佳，但所有模型在几何问题上表现均较弱，且不同模型有各自的错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多使用相同数据集评估LLM的数学推理能力，限制了结果的普适性。本研究旨在通过分析LLM在代表性不足的数学竞赛问题上的表现，更全面地理解其数学推理的局限性。

Method: 使用密苏里大学数学竞赛的微积分、解析几何和离散数学问题测试三种主流LLM（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3），将模型回答与已知正确答案比较，并分析其推理过程中的错误模式。

Result: DeepSeek-V3在微积分、解析几何和离散数学三个领域表现最佳；所有模型在几何问题上表现显著较弱；DeepSeek-V3主要错误是计算和逻辑错误，GPT-4o-mini常犯逻辑和方法错误，Gemini则倾向于不完整推理和仓促结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估LLM能更深入揭示其独特的错误模式，突显结构化推理（特别是几何领域）的持续挑战，为未来改进提供方向。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [28] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 论文提出了一种两阶段方法，将空间推理分解为原子构建块及其组合，通过监督微调学习基本空间物理，然后训练轻量级LoRA适配器进行多步规划，在ASCII艺术环境中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在通用语言能力上表现出色，但在结构化环境中的空间变换和多步规划方面仍然存在困难。需要一种方法来提高LLMs在空间推理任务上的表现，特别是在需要物理理解和多步决策的场景中。

Method: 采用两阶段方法：1) 对基本空间变换（旋转、平移、缩放）进行监督微调，使模型具备基础空间物理知识；2) 冻结这个物理感知模型，在GRPO框架内训练轻量级LoRA适配器，学习将这些构建块组合用于谜题环境中的多步规划。为此合成了ASCII艺术数据集并构建了相应的强化学习环境。

Result: 该方法在动态环境（有显式状态更新）和静态环境（模型必须依赖内部状态）中均一致优于基线方法，包括通用骨干模型、物理感知模型和端到端RL模型。此外，该方法收敛更快，训练更稳定，注意力模式分析也显示微调确实改善了空间理解能力。

Conclusion: 通过将空间推理分解为原子构建块及其组合的两阶段方法，可以有效提升LLMs在空间推理任务上的表现，特别是在需要多步规划和物理理解的环境中。该方法不仅性能优越，而且训练更高效稳定，为LLMs的空间推理能力提供了有前景的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [29] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: 提出了MCPAgentBench基准，用于评估LLM代理在真实MCP定义下的工具使用能力，包含真实任务、模拟工具和动态沙箱环境，测试工具选择和辨别能力。


<details>
  <summary>Details</summary>
Motivation: 当前MCP评估集存在依赖外部MCP服务和缺乏难度感知的问题，需要更全面评估LLM代理工具使用能力的基准。

Method: 构建基于真实世界MCP定义的数据集，包含真实任务和模拟MCP工具；采用动态沙箱环境，提供包含干扰项的工具候选列表；引入综合指标衡量任务完成率和执行效率。

Result: 在多种最新主流大语言模型上的实验显示，在处理复杂多步骤工具调用时存在显著性能差异。

Conclusion: MCPAgentBench为评估LLM代理的工具使用能力提供了有效基准，代码已开源，有助于推动自主代理工具使用能力的研究。

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [30] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: 提出递归语言模型（RLMs）作为处理超长提示的推理策略，通过让LLM编程式地检查、分解和递归调用自身来处理长文本片段，显著超越基础LLM和常见长上下文框架的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型处理任意长提示的挑战，突破模型上下文窗口的限制，实现更有效的长文本处理能力。

Method: 提出递归语言模型（RLMs）推理策略：将长提示视为外部环境，让LLM编程式地检查、分解文本，并递归调用自身处理文本片段。

Result: RLMs能处理超出模型上下文窗口两个数量级的输入，在四个不同的长上下文任务中，即使对于较短提示，也显著优于基础LLM和常见长上下文框架，且查询成本相当或更低。

Conclusion: RLMs是一种有效的长文本处理策略，通过递归分解和编程式处理，显著提升了LLM处理超长提示的能力，具有实际应用价值。

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [31] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 提出强化学习增强的LLM多智能体协作框架，采用Dec-POMDP建模和CTDE训练，通过GRPO优化策略，在协作写作和编程任务中显著提升效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在单智能体任务中表现良好，但在多智能体协作场景中缺乏协作意识，难以优化全局性能，需要解决多智能体协同工作的问题。

Method: 1. 将协作建模为去中心化部分可观测马尔可夫决策过程（Dec-POMDP）；2. 采用集中训练分散执行（CTDE）框架；3. 提出组相对策略优化（GRPO）方法，在训练时利用全局信号联合优化智能体策略；4. 设计简化的联合奖励函数，平衡任务质量、速度和协调成本。

Result: 1. 在协作写作和编程基准测试中，任务处理速度比单智能体基线提升3倍；2. 写作任务中达到98.7%的结构/风格一致性；3. 编程任务中达到74.6%的测试通过率；4. 始终优于现有的多智能体LLM基线方法。

Conclusion: 该框架为复杂工作流中的可靠协作提供了实用路径，通过强化学习增强LLM多智能体系统，显著提升了协作效率和任务质量。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [32] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 提出基于群体审议的多智能体对话模型，通过三层角色架构（生成、验证、整合）提升复杂推理能力，在多个数据集上显著提高多跳推理准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在复杂推理任务中存在局限性，需要更有效的多智能体协作方法来提升推理准确性和逻辑一致性。

Method: 采用三层角色架构：观点生成代理产生多样化推理视角，证据验证代理检索外部知识并量化事实支持，一致性仲裁代理整合逻辑一致的结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计结合事实一致性和逻辑连贯性的复合奖励函数，应用改进的近端策略优化进行协同训练。

Result: 在HotpotQA上多跳推理准确率提升16.8%，2WikiMultihopQA提升14.3%，MeetingBank提升19.2%，一致性提升21.5%。相比主流多智能体方法具有更高的推理效率。

Conclusion: 该模型为复杂推理任务提供了有效且稳定的解决方案，通过群体审议机制显著提升了多智能体协作的推理性能。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [33] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: Youtu-Agent：一个模块化LLM智能体框架，支持自动生成和持续进化，解决现有框架配置成本高和静态能力问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体框架面临两大挑战：1）配置成本高，构建高质量智能体需要大量手动工具集成和提示工程；2）静态能力，已部署智能体难以适应动态环境，需要昂贵的微调

Method: 提出模块化框架Youtu-Agent，包含结构化配置系统（解耦执行环境、工具集和上下文管理），支持两种生成范式：Workflow模式用于标准任务，Meta-Agent模式用于复杂需求（自动生成工具代码、提示和配置）。建立混合策略优化系统：Agent Practice模块通过上下文优化积累经验，Agent RL模块集成分布式训练框架进行端到端强化学习

Result: 在WebWalkerQA（71.47%）和GAIA（72.8%）上达到SOTA性能；自动生成管道工具合成成功率超过81%；Practice模块在AIME 2024/2025上分别提升2.7%和5.4%；Agent RL训练在7B LLM上实现40%加速，数学推理和搜索能力在相关基准上分别提升35%和21%

Conclusion: Youtu-Agent通过模块化设计和自动化生成解决了LLM智能体框架的高配置成本和静态能力问题，支持智能体的持续进化和性能提升，在多个基准测试中表现出色

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [34] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 提出多模态跨域混合融合与双重解耦的故障诊断模型，解决现有方法在未见工况下性能下降和多模态信息利用不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法在真实场景中面临两个主要问题：1) 在未见工况下性能显著下降，而域自适应方法依赖目标域样本；2) 大多依赖单模态信号，忽略了多模态信息的互补性

Method: 提出多模态跨域混合融合模型，包含：1) 双重解耦框架，分离模态不变/特定特征和域不变/特定表示；2) 跨域混合融合策略，随机混合跨域模态信息增强多样性；3) 三模态融合机制，自适应集成多模态异构信息

Result: 在感应电机故障诊断实验中，无论是恒定还是时变未见工况下，该方法均优于先进方法，消融研究验证了各组件和多模态融合的有效性

Conclusion: 提出的多模态跨域混合融合模型通过双重解耦和跨域混合融合，实现了更全面的多模态表示学习和更鲁棒的域泛化能力，为智能故障诊断提供了有效解决方案

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [35] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 论文提出了一个可解释的物体排列偏好模型，包含四个维度：空间实用性、习惯便利性、语义连贯性和常识适当性，并通过问卷验证和MCTS规划器应用。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类演示的机器人系统偏好模型虽然有效，但缺乏可解释性，难以理解指导人类决策的因素。需要开发一个明确、可解释的物体排列偏好模型。

Method: 设计了包含四个可解释构念（空间实用性、习惯便利性、语义连贯性、常识适当性）的自我报告问卷，通过63名参与者的在线研究验证。然后将这些构念整合到蒙特卡洛树搜索（MCTS）规划器中。

Result: 问卷研究证实了这四个构念的心理区分度和解释力。MCTS规划器在参与者偏好指导下，能够生成与参与者排列高度一致的合理布局。

Conclusion: 该工作提出了一个紧凑、可解释的物体排列偏好模型，并展示了如何将其操作化用于机器人规划，为机器人系统提供了更透明的人类偏好理解框架。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [36] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ是一个混合模型，通过可解释的语义特征桥接基础模型和统计建模，在房价预测和电影推荐任务上显著优于纯基础模型方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具有广泛的领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式。需要一种方法能够结合基础模型的语义理解能力和统计建模的数据特定模式发现能力。

Method: 提出一个广义EM算法，通过迭代过程发现语义特征描述：基于统计建模误差对比项目组，而不是仅依赖基础模型的领域理解。使用冻结的基础模型基于发现的特征对项目进行分类，将这些判断视为预测实值目标的潜在二元特征的噪声观测。

Result: 在房价预测上，使用多模态列表数据发现的语义特征达到12%的中位数相对误差，显著优于GPT-5基线的38%误差。在Netflix电影嵌入预测上，仅从语义描述就能达到0.59的余弦相似度，相当于传统协同过滤需要约4000个用户评分才能达到的性能。

Conclusion: GenZ成功桥接了基础模型和统计建模，通过发现数据集特定模式（如预测本地房地产市场的建筑细节、预测用户偏好的系列电影成员关系）显著提升了预测性能，这些模式超越了基础模型单独的领域知识。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [37] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 提出一种基于约束模板的方法，用于从养老院管理者访谈中提取设施特定的排班约束条件，并通过排除异常约束来优化排班生成。


<details>
  <summary>Details</summary>
Motivation: 养老机构的排班条件因设施而异，需要访谈排班管理者来设计设施特定的约束条件，但现有约束提取技术难以处理异常约束。

Method: 使用约束模板提取连续工作日模式、员工组合等组件的组合，通过调整关注天数、员工数量和提取焦点（模式或频率）来提取多样化约束，并加入排除异常约束的机制。

Result: 实验表明，该方法成功生成了满足所有硬约束的排班，并通过避免提取异常约束，减少了软约束的违反次数。

Conclusion: 提出的约束模板方法能够有效提取养老院特定的排班约束，结合排除异常约束的机制，可生成更符合实际需求的护理人员排班。

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [38] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: ALE是一个端到端的智能体学习生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具，并发布了基于此训练的ROME智能体模型。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏一个原则性的端到端生态系统来简化智能体开发，需要优化智能体LLM的生产流程。

Method: 1) ALE生态系统包含三个组件：ROLL（权重优化后训练框架）、ROCK（轨迹生成沙盒环境管理器）、iFlow CLI（高效上下文工程智能体框架）；2) 发布ROME智能体模型，基于超过100万条轨迹训练；3) 采用数据组合协议合成复杂行为；4) 提出新颖的策略优化算法IPA（基于交互的策略对齐），通过语义交互块而非单个token分配信用。

Result: ROME在SWE-bench Verified和Terminal Bench等基准测试中表现出色，证明了ALE基础设施的有效性。同时引入了Terminal Bench Pro基准，具有改进的规模和污染控制。

Conclusion: ALE提供了一个完整的智能体学习生态系统，通过其组件和训练方法能够有效支持智能体开发，ROME的成功验证了该框架的实用性。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [39] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 开发了一个半自动数据标注流水线，用于在波兰驾驶条件下创建大规模多模态数据集，通过人机协同方法显著减少标注成本和时间


<details>
  <summary>Details</summary>
Motivation: 手动标注异质驾驶数据成本高、耗时长，需要开发自动化解决方案来加速大规模标注数据集的创建，支持波兰自动驾驶研究

Method: 采用人在回路方法，结合AI与人类专业知识，包括自动生成初始标注、迭代模型重训练、数据匿名化和领域适应技术，核心基于3D目标检测算法

Result: 开发的工具和方法实现了显著的时间节省，同时确保跨不同传感器模态的一致高质量标注，直接支持DARTS项目加速标准化格式标注数据集的准备

Conclusion: 半自动标注流水线成功解决了大规模驾驶数据标注的挑战，为波兰自动驾驶研究提供了技术基础，证明了人机协同方法在数据标注中的有效性

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [40] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 迭代部署LLM并通过用户数据筛选进行微调，可以显著改变模型特性，在规划任务中实现能力提升和泛化，这本质上是一种隐式强化学习机制。


<details>
  <summary>Details</summary>
Motivation: 研究迭代部署LLM时，通过用户从先前模型部署中精心筛选数据进行微调，如何影响最终模型的特性，特别是探索这种机制在规划任务中的效果及其理论意义。

Method: 采用迭代部署机制：每个LLM在部署后，用户从其输出中精心筛选数据，用于微调下一个模型。在不同规划领域测试该机制，并进行理论分析，证明这种迭代部署本质上实现了外层循环的强化学习训练。

Result: 在规划任务中观察到显著改进：后续模型展现出规划技能的提升，并出现泛化能力，能够发现比初始模型长得多的规划方案。理论分析表明迭代部署实现了隐式奖励函数的强化学习。

Conclusion: 迭代部署机制是一种替代显式强化学习的训练范式，依赖数据筛选而非显式奖励。这对AI安全有重要启示：重复部署隐含的奖励函数未明确定义，可能对未来模型部署产生意外影响。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [41] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent是一个专门用于时空理解的智能体大语言模型，能够处理受限兴趣点发现和行程规划等复杂任务，通过工具交互和分层训练方法在保持通用能力的同时提升时空推理性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决时空场景下的复杂任务（如受限兴趣点发现和行程规划），需要开发一个能够与多种时空工具交互、具备复杂推理能力的专门化智能体模型，同时保持模型的通用能力。

Method: 提出三个关键贡献：1）包含10+个领域特定工具的稳定工具环境；2）分层数据筛选框架，以1:10,000的比例筛选高质量查询数据；3）级联训练方法，包括种子SFT阶段、高确定性查询的SFT阶段和低确定性数据的RL阶段。

Result: STAgent在TravelBench上表现出色，同时在广泛的通用基准测试中保持了其通用能力，证明了所提出的智能体模型的有效性。

Conclusion: STAgent通过专门的工具环境、高质量数据筛选和级联训练方法，成功构建了一个在时空理解任务上表现优异同时保持通用能力的智能体模型，为时空智能体研究提供了有效方案。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>


### [42] [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)
*Tianzhi He,Farrokh Jazizadeh*

Main category: cs.AI

TL;DR: 提出基于大语言模型的建筑能源管理系统AI代理框架，通过自然语言交互实现智能建筑的情境感知能源管理，在设备控制、能源分析等任务上表现良好，但成本估算等复杂任务仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有能源管理系统存在局限性，需要更智能、情境感知的解决方案。利用LLM的自主数据分析能力，通过自然语言交互实现更人性化的建筑能源管理。

Method: 提出包含感知、中央控制、行动三个模块的框架，形成闭环反馈系统。使用120个用户查询在四个真实住宅能源数据集上评估原型性能，采用延迟、功能、能力、准确性、成本效益等指标，并通过ANOVA测试验证框架通用性。

Result: 设备控制准确率86%，记忆相关任务97%，调度自动化74%，能源分析77%，成本估算准确率49%。结果显示在多个任务上表现良好，但复杂任务仍有改进空间。

Conclusion: LLM-based BEMS AI代理在情境感知能源管理方面具有潜力，但需要在准确性和计算效率之间权衡。研究为评估此类系统提供了基准，并指出了未来研究方向。

Abstract: This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Hierarchical Quasi-cyclic Codes from Reed-Solomon and Polynomial Evaluation Codes](https://arxiv.org/abs/2512.23872)
*Emily McMillon,Kathryn Haymaker*

Main category: cs.IT

TL;DR: 首次提出代数构造的分层准循环码，基于Reed-Solomon码和Kautz-Singleton叠加码构造，层次数和索引由域大小决定，部分码达到已知最佳最小距离。


<details>
  <summary>Details</summary>
Motivation: 现有相关码的研究主要基于仿真，缺乏代数分析方法。本文旨在通过代数构造方法，为分层准循环码建立理论框架和参数界限。

Method: 使用Kautz-Singleton的叠加码构造方法，基于Reed-Solomon码代数构造分层准循环码。通过域大小确定层次结构和索引，分析码的参数特性。

Result: 成功构造了首个代数分层准循环码，层次数和索引由域大小决定。当k=2时，Tanner图围长为6。部分码达到已知最佳最小距离，并建立了新的参数界限。

Conclusion: 提出了代数构造分层准循环码的新方法，建立了参数界限理论框架，为相关码的设计和分析提供了代数基础，优于现有的仿真方法。

Abstract: We introduce the first example of algebraically constructed hierarchical quasi-cyclic codes. These codes are built from Reed-Solomon codes using a 1964 construction of superimposed codes by Kautz and Singleton. We show both the number of levels in the hierarchy and the index of these Reed-Solomon derived codes are determined by the field size. We show that this property also holds for certain additional classes of polynomial evaluation codes.
  We provide explicit code parameters and properties as well as some additional bounds on parameters such as rank and distance. In particular, starting with Reed-Solomon codes of dimension $k=2$ yields hierarchical quasi-cyclic codes with Tanner graphs of girth 6.
  We present a table of small code parameters and note that some of these codes meet the best known minimum distance for binary codes, with the additional hierarchical quasi-cyclic structure. We draw connections to similar constructions in the literature, but importantly, while existing literature on related codes is largely simulation-based, we present a novel algebraic approach to determining new bounds on parameters of these codes.

</details>


### [44] [Continuous Angular Power Spectrum Recovery From Channel Covariance via Chebyshev Polynomials](https://arxiv.org/abs/2512.24039)
*Shengsong Luo,Ruilin Wu,Chongbin Xu,Junjie Ma,Xiaojun Yuan,Xin Wang*

Main category: cs.IT

TL;DR: 提出基于切比雪夫多项式展开的框架，用于从信道协方差中恢复连续角功率谱，通过正交性将病态逆问题转化为有限维线性回归，并引入非负约束和导数正则化来提升重建精度。


<details>
  <summary>Details</summary>
Motivation: 在多天线系统中，从信道协方差中恢复连续角功率谱是一个病态逆问题。传统方法面临精度不足和计算复杂度高的挑战，特别是在FDD系统中需要从上行链路预测下行链路协方差时。

Method: 利用切比雪夫多项式在变换域中的正交性，推导协方差的精确级数表示，将APS反演问题转化为有限维线性回归。引入非负APS的半正定表征和基于导数的正则化器，在保持簇间过渡的同时促进平滑变化。

Result: 仿真结果表明，所提出的切比雪夫框架能够实现准确的APS重建，并在FDD设置中实现从上行链路测量到下行链路协方差的可靠预测。联合利用切比雪夫域中的平滑性和非负性为多天线系统中的协方差域处理提供了有效工具。

Conclusion: 切比雪夫多项式展开框架为连续角功率谱恢复提供了一种有效方法，通过将病态逆问题转化为可处理的线性回归，并利用平滑性和非负性约束，显著提升了重建精度和协方差预测性能。

Abstract: This paper proposes a Chebyshev polynomial expansion framework for the recovery of a continuous angular power spectrum (APS) from channel covariance. By exploiting the orthogonality of Chebyshev polynomials in a transformed domain, we derive an exact series representation of the covariance and reformulate the inherently ill-posed APS inversion as a finite-dimensional linear regression problem via truncation. The associated approximation error is directly controlled by the tail of the APS's Chebyshev series and decays rapidly with increasing angular smoothness. Building on this representation, we derive an exact semidefinite characterization of nonnegative APS and introduce a derivative-based regularizer that promotes smoothly varying APS profiles while preserving transitions of clusters. Simulation results show that the proposed Chebyshev-based framework yields accurate APS reconstruction, and enables reliable downlink (DL) covariance prediction from uplink (UL) measurements in a frequency division duplex (FDD) setting. These findings indicate that jointly exploiting smoothness and nonnegativity in a Chebyshev domain provides an effective tool for covariance-domain processing in multi-antenna systems.

</details>


### [45] [Random Multiplexing](https://arxiv.org/abs/2512.24087)
*Lei Liu,Yuhao Chi,Shunqi Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 论文提出了一种与物理信道解耦的随机复用技术，适用于任意范数有界和谱收敛的信道矩阵，通过构建随机变换域中的等效输入各向同性信道矩阵，实现统计衰落信道遍历性，并研究了低复杂度CD-MAMP检测器及其最优功率分配。


<details>
  <summary>Details</summary>
Motivation: 传统复用技术（如SC-FDE、OFDM、OTFS、AFDM）依赖特定信道结构来对角化或稀疏化有效信道，这在动态现实环境中鲁棒性有限。需要一种不依赖特定信道结构、能适应任意范数有界和谱收敛信道矩阵的复用技术。

Method: 提出随机复用技术，与物理信道解耦，通过构建随机变换域中的等效输入各向同性信道矩阵实现统计衰落信道遍历性。采用低复杂度跨域记忆AMP（CD-MAMP）检测器，利用时域信道稀疏性和等效信道随机性。推导最优功率分配以最小化复制MAP误码率和最大化复制约束容量。

Result: 随机复用技术能保证AMP型检测器在任意范数有界、谱收敛信道矩阵和信令配置下的渐近复制MAP误码率最优性（在唯一不动点假设下）。CD-MAMP检测器在随机复用系统中具有最优编码原理和复制约束容量最优性。

Conclusion: 随机复用技术突破了传统复用技术对特定信道结构的依赖，为动态无线环境提供了更鲁棒的解决方案，在多样化无线应用中具有广泛适用性，并通过CD-MAMP检测器和最优功率分配实现了性能优化。

Abstract: As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.

</details>


### [46] [When Wires Can't Keep Up: Reconfigurable AI Data Centers Empowered by Terahertz Wireless Communications](https://arxiv.org/abs/2512.24110)
*Chong Han,Mingjie Zhu,Wenqi Zhao,Ziming Yu,Guolong Huang,Guangjian Wang,Wen Tong,Wenjun Zhang*

Main category: cs.IT

TL;DR: 太赫兹无线数据中心（THz-WDC）通过超宽带容量、单跳低延迟和短中距离能效，为AI数据中心提供革命性互连架构，替代传统铜缆和光缆方案。


<details>
  <summary>Details</summary>
Motivation: AI工作负载爆炸式增长对数据中心互连架构提出新要求，传统铜缆和光缆在延迟、功耗和灵活性方面存在根本性限制，制约分布式AI集群的可扩展性。

Method: 提出太赫兹无线数据中心愿景，探索数字孪生编排、低复杂度波束操纵、全硅太赫兹收发器、低复杂度模拟基带架构等关键技术，支持量子计算和chiplet模块化架构。

Result: 太赫兹链路可实现单链路1Tbps、通过空间复用总吞吐量10Tbps、单跳延迟低于50ns、20米距离内能效低于10pJ/bit，在特定距离和吞吐量域超越传统有线方案。

Conclusion: 太赫兹无线互连为实现无线定义、可重构、可持续的AI数据中心提供了技术路线图，是未来数据中心架构的重要发展方向。

Abstract: The explosive growth of artificial intelligence (AI) workloads in modern data centers demands a radical transformation of interconnect architectures. Traditional copper and optical wiring face fundamental challenges in latency, power consumption, and rigidity, constraining the scalability of distributed AI clusters. This article introduces a vision for Terahertz (THz) Wireless Data Center (THz-WDC) that combines ultra-broadband capacity, one-hop low-latency communication, and energy efficiency in the short-to-medium range (1-100m). Performance and technical requirements are first articulated, including up to 1 Tbps per link, aggregate throughput up to 10 Tbps via spatial multiplexing, sub-50 ns single-hop latency, and sub-10 pJ/bit energy efficiency over 20m. To achieve these ambitious goals, key enabling technologies are explored, including digital-twin-based orchestration, low-complexity beam manipulation technologies, all-silicon THz transceivers, and low-complexity analog baseband architectures. Moreover, as future data centers shift toward quantum and chiplet-based modular architectures, THz wireless links provide a flexible mechanism for interconnecting, testing, and reconfiguring these modules. Finally, numerical analysis is presented on the latency and power regimes of THz versus optical and copper interconnects, identifying the specific distance and throughput domains where THz links can surpass conventional wired solutions. The article concludes with a roadmap toward wireless-defined, reconfigurable, and sustainable AI data centers.

</details>


### [47] [Efficient Decoding of Twisted GRS Codes and Roth--Lempel Codes](https://arxiv.org/abs/2512.24217)
*Runtian Zhu,Lingfei Jin*

Main category: cs.IT

TL;DR: 本文提出了针对扭曲广义Reed-Solomon码和Roth-Lempel码的高效列表解码和唯一解码算法，基于Guruswami-Sudan算法实现近线性时间复杂度，显著改进现有二次时间复杂度，并首次为Roth-Lempel码提供高效解码器。


<details>
  <summary>Details</summary>
Motivation: MDS码在实践中应用广泛，但大多数已知MDS码都是广义Reed-Solomon码，非GRS码研究相对不足。研究非GRS码既有理论意义，也有实际价值，因为GRS码的强代数结构在密码学中可能不受欢迎。扭曲广义Reed-Solomon码和Roth-Lempel码是两类重要的非GRS码，虽然已有大量构造和结构分析工作，但解码问题研究较少，许多问题仍待解决。

Method: 基于Guruswami-Sudan算法，为扭曲广义Reed-Solomon码和Roth-Lempel码设计列表解码和唯一解码算法。算法在合适参数条件下实现近线性时间复杂度。对于扭曲广义Reed-Solomon码，支持最多O(n²)个扭曲的固定速率码；对于Roth-Lempel码，首次提供高效解码器。还将代数操作检测码集成到列表解码框架中。

Result: 算法在合适参数条件下实现近线性运行时间，显著改进先前已知的二次时间复杂度。扭曲广义Reed-Solomon解码器支持最多O(n²)个扭曲，大幅扩展了先前仅处理单扭曲情况的工作。为Roth-Lempel码提供了首个高效解码器。列表解码器在广泛参数范围内超越经典唯一解码半径。通过集成代数操作检测码，能够以高概率从输出列表中恢复正确消息。

Conclusion: 本文为非GRS码的解码问题提供了系统解决方案，显著推进了扭曲广义Reed-Solomon码和Roth-Lempel码的解码技术。提出的算法具有高效性和广泛适用性，为这些重要码类的实际应用奠定了基础，特别是在需要超越经典唯一解码能力的场景中。

Abstract: MDS codes play a central role in practice due to their broad applications. To date, most known MDS codes are generalized Reed-Solomon (GRS) codes, leaving codes that are not equivalent to GRS codes comparatively less understood. Studying this non-GRS regime is therefore of intrinsic theoretical interest, and is also practically relevant since the strong algebraic structure of GRS codes can be undesirable in cryptographic settings. Among the known non-GRS codes, twisted generalized Reed-Solomon (TGRS) codes and Roth-Lempel codes are two representative families of non-GRS codes that have attracted significant attention. Though substantial work has been devoted to the construction and structural analysis of TGRS and Roth-Lempel codes, comparatively little attention has been paid to their decoding, and many problems remain open. In this paper, we propose list and unique decoding algorithms for TGRS codes and Roth-Lempel codes based on the Guruswami-Sudan algorithm. Under suitable parameter conditions, our algorithms achieve near-linear running time in the code length, improving upon the previously best-known quadratic-time complexity. Our TGRS decoder supports fixed-rate TGRS codes with up to O(n^2) twists, substantially extending prior work that only handled the single-twist case. For Roth-Lempel codes, we provide what appears to be the first efficient decoder. Moreover, our list decoders surpass the classical unique-decoding radius for a broad range of parameters. Finally, we incorporate algebraic manipulation detection (AMD) codes into the list-decoding framework, enabling recovery of the correct message from the output list with high probability.

</details>


### [48] [SC-LDPC Codes Over $\mathbb{F}_q$: Minimum Distance, Decoding Analysis and Threshold Saturation](https://arxiv.org/abs/2512.24232)
*Jiaxin Lyu,Guanghui He*

Main category: cs.IT

TL;DR: 研究随机空间耦合低密度奇偶校验码在有限域上的性能，证明两种耦合结构都具有渐进良好的最小距离和最小停止集尺寸，并建立了通用阈值饱和理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上空间耦合LDPC码的性能，特别是不同变量节点边扩展规则下的距离特性和迭代解码阈值，旨在提高编码系统的性能。

Method: 采用随机Tanner图建模，定义标准耦合和改良耦合两种结构，使用概率向量分析、对称性理论、度量拓扑和退化理论等数学工具，建立通用分析框架。

Result: 证明两种耦合结构都具有渐进良好的最小距离和最小停止集尺寸，改良耦合结构能获得更好的距离性能，建立了在QMSC信道上的通用阈值饱和结果。

Conclusion: 空间耦合LDPC码在有限域上具有优异的性能，改良耦合结构优于标准结构，建立的通用阈值饱和理论为有限域编码系统设计提供了理论基础。

Abstract: We investigate random spatially coupled low-density parity-check (SC-LDPC) code ensembles over finite fields. Under different variable-node edge-spreading rules, the random Tanner graphs of several coupled ensembles are defined by multiple independent, uniformly random monomial maps. The two main coupled ensembles considered are referred to as the standard coupled ensemble and the improved coupled ensemble. We prove that both coupled ensembles exhibit asymptotically good minimum distance and minimum stopping set size. Theoretical and numerical results show that the improved coupled ensemble can achieve better distance performance than the standard coupled ensemble. We introduce the essential preliminaries and analytical tools needed to analyze the iterative decoding threshold of coupled ensembles over any finite field. We consider a class of memoryless channels with special symmetry, termed q-ary input memoryless symmetric channels (QMSCs), and show that, for these channels, the distribution of channel messages (in form of probability vectors) likewise exhibits this symmetry. Consequently, we define symmetric probability measures and their reference measures on a finite-dimensional probability simplex, analyze their foundational properties and those of their linear functionals, endow their respective spaces with metric topologies, and conduct an in-depth study of their degradation theory. Based on our analytical framework, we establish a universal threshold saturation result for both of the coupled ensembles over a q-ary finite field on QMSCs. Specifically, as the coupling parameters increase, the belief-propagation threshold of a coupled system saturates to a well-defined threshold that depends only on the underlying ensemble and the channel family.

</details>


### [49] [Infinite families of graphs and stable completion of arbitrary matrices, Part I](https://arxiv.org/abs/2512.24468)
*Augustin Cosse*

Main category: cs.IT

TL;DR: 研究确定性构造图，使得低秩矩阵的独特补全在任意条目值下都普遍可能，通过分析支撑子图中的特定模式（自回避路径的并集）来建立可补全性条件。


<details>
  <summary>Details</summary>
Motivation: 研究在哪些图结构上，低秩矩阵补全问题能够保证对任意矩阵条目值都有唯一解，这对于矩阵补全问题的理论保证和实际应用具有重要意义。

Method: 将矩阵补全的可补全性与支撑子图中的特定模式（自回避路径的并集）联系起来，通过分析双邻接矩阵支撑生成的格图子图中的模式来建立理论条件。

Result: 建立了图结构与矩阵补全可补全性之间的理论联系，使得能够设计无限图族，在这些图上通过平方和层次结构对任意固定秩矩阵都能实现精确且稳定的补全。

Conclusion: 该研究为低秩矩阵补全问题提供了理论保证，通过图结构设计确保了对任意固定秩矩阵都能实现精确且稳定的补全，为矩阵补全算法的可靠性提供了理论基础。

Abstract: We study deterministic constructions of graphs for which the unique completion of low rank matrices is generically possible regardless of the values of the entries. We relate the completability to the presence of some patterns (particular unions of self-avoiding walks) in the subgraph of the lattice graph generated from the support of the bi-adjacency matrix. The construction makes it possible to design infinite families of graphs on which exact and stable completion is possible for every fixed rank matrix through the sum-of-squares hierarchy.

</details>


### [50] [Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL](https://arxiv.org/abs/2512.24773)
*Anas K. Saeed,Mahmoud M. Salim,Ali Arshad Nasir,Ali H. Muqaibel*

Main category: cs.IT

TL;DR: 该论文提出了一种基于深度强化学习的模型，用于优化无人机搭载可重构智能表面在存在抖动和信道不确定性情况下的通信系统性能。


<details>
  <summary>Details</summary>
Motivation: 无人机搭载的可重构智能表面(RIS)可以按需重塑无线传播，但其性能对无人机抖动和级联信道不确定性敏感。现有方法在严重抖动和低信道状态信息质量下性能受限，需要更鲁棒的优化方案。

Method: 采用模型无关的深度强化学习框架，结合上下文赌博机公式。使用可微分可行性层将连续动作映射到可行解，奖励函数为期望吞吐量的蒙特卡洛估计。具体实现了不使用目标网络的深度确定性策略梯度(DDPG)和双延迟深度确定性策略梯度(TD3)的约束变体。

Result: 在严重抖动和低信道状态信息质量下，提出的算法比传统的交替优化加权最小均方误差(AO-WMMSE)基线获得更高的吞吐量。在不同场景下，性能与基于样本平均近似的AO-WMMSE基准相当或略低，相对差距在0-12%之间。在线推理时间仅0.6毫秒，远低于AO-WMMSE求解器的370-550毫秒。

Conclusion: 提出的深度强化学习方法能够有效处理无人机抖动和信道不确定性带来的挑战，在保持接近最优性能的同时，显著降低了计算延迟，适合实时应用。

Abstract: Reconfigurable intelligent surfaces (RISs) mounted on unmanned aerial vehicles (UAVs) can reshape wireless propagation on-demand. However, their performance is sensitive to UAV jitter and cascaded channel uncertainty. This paper investigates a downlink multiple-input single-output UAV-mounted RIS system in which a ground multiple-antenna base station (BS) serves multiple single-antenna users under practical impairments. Our goal is to maximize the expected throughput under stochastic three-dimensional UAV jitter and imperfect cascaded channel state information (CSI) based only on the available channel estimates. This leads to a stochastic nonconvex optimization problem subject to a BS transmit power constraint and strict unit-modulus constraints on all RIS elements. To address this problem, we design a model-free deep reinforcement learning (DRL) framework with a contextual bandit formulation. A differentiable feasibility layer is utilized to map continuous actions to feasible solutions, while the reward is a Monte Carlo estimate of the expected throughput. We instantiate this framework with constrained variants of deep deterministic policy gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3) that do not use target networks. Simulations show that the proposed algorithms yield higher throughput than conventional alternating optimization-based weighted minimum mean-square error (AO-WMMSE) baselines under severe jitter and low CSI quality. Across different scenarios, the proposed methods achieve performance that is either comparable to or slightly below the AO-WMMSE benchmark, based on sample average approximation (SAA) with a relative gap ranging from 0-12%. Moreover, the proposed DRL controllers achieve online inference times of 0.6 ms per decision versus roughly 370-550 ms for AO-WMMSE solvers.

</details>
