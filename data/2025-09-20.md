<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.IT](#cs.IT) [Total: 12]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Software-Defined Radio Testbed for Distributed LiDAR Point Cloud Sharing with IEEE 802.11p in V2V Networks](https://arxiv.org/abs/2509.14523)
*Mario Hernandez,Elijah Bryce,Peter Stubberud,Ebrahim Saberinia,Brendan Morris*

Main category: cs.NI

TL;DR: 开发了一个基于SDR的IEEE 802.11p测试平台，用于分布式车对车通信，支持LiDAR点云共享和融合，并评估了去中心化存储系统的性能。


<details>
  <summary>Details</summary>
Motivation: 弥合网络仿真与实际部署之间的差距，为车对车通信提供成本效益高的模块化测试平台。

Method: 使用ADALM-Pluto SDR构建软件定义无线电测试平台，支持Docker容器化部署，通过ROS和Matlab实现节点通信，并集成LiDAR数据共享和IPFS/Filecoin去中心化存储系统。

Result: 成功实现了分布式V2V通信测试平台，能够共享和融合LiDAR点云数据，评估了去中心化存储系统的节点存储收敛性、延迟和可扩展性约束，并提供了信道质量研究。

Conclusion: 该测试平台为车对车通信研究提供了实用的实验环境，证明了SDR技术在V2V通信中的可行性和去中心化存储系统在协作感知中的应用潜力。

Abstract: We present a Software Defined Radio (SDR)-based IEEE 802.11p testbed for
distributed Vehicle-to-Vehicle (V2V) communication. The platform bridges the
gap between network simulation and deployment by providing a modular codebase
configured for cost-effective ADALM-Pluto SDRs. Any device capable of running a
Docker with ROS, executing Matlab and interface with a Pluto via USB can act as
a communication node. To demonstrate collaborative sensing, we share LiDAR
point clouds between nodes and fuse them into a collective perception
environment. We evaluated a theoretical model for leveraging decentralized
storage systems (IPFS and Filecoin), analyzing constraints such as node storage
convergence, latency, and scalability. In addition, we provide a channel
quality study.

</details>


### [2] [Chameleon: Integrated Sensing and Communication with Sub-Symbol Beam Switching in mmWave Networks](https://arxiv.org/abs/2509.14628)
*Zhihui Gao,Zhecun Liu,Tingjun Chen*

Main category: cs.NI

TL;DR: Chameleon框架在5G毫米波网络中通过快速切换波束成形器，在每个DMRS符号期间实现通信和感知的集成，同时维持多用户通信和高速感知成像。


<details>
  <summary>Details</summary>
Motivation: 当前5G网络的波束成形通常只为通信或感知单独设计，缺乏集成方案。需要一种能够在毫米波频谱中同时支持通信和感知的框架。

Method: 提出Chameleon框架，在每个解调参考信号(DMRS)符号期间快速切换波束成形器，在维持多用户通信波束的同时，向目标角度引入额外的感知波束。在28 GHz软件定义无线电测试床上实现，支持5G PDSCH传输。

Result: 实现了双用户总数据速率0.80 Gbps的多用户通信，波束成形器切换间隔仅0.24μs，在0.875ms内完成31x31点2D成像。通过机器学习实现0.14米距离误差、0.24度角度误差的定位，以及99.0%准确率的材料分类。

Conclusion: Chameleon成功证明了在5G毫米波网络中实现集成感知与通信的可行性，为下一代蜂窝网络提供了实用的ISAC解决方案。

Abstract: Next-generation cellular networks are envisioned to integrate sensing
capabilities with communication, particularly in the millimeter-wave (mmWave)
spectrum, where beamforming using large-scale antenna arrays enables
directional signal transmissions for improved spatial multiplexing. In current
5G networks, however, beamforming is typically designed either for
communication or sensing (e.g., beam training during link establishment). In
this paper, we present Chameleon, a novel framework that augments and rapidly
switches beamformers during each demodulation reference signal (DMRS) symbol to
achieve integrated sensing and communication (ISAC) in 5G mmWave networks. Each
beamformer introduces an additional sensing beam toward target angles while
maintaining the communication beams toward multiple users. We implement
Chameleon on a 28 GHz software-defined radio testbed supporting over-the-air 5G
physical downlink shared channel (PDSCH) transmissions. Extensive experiments
in open environments show that Chameleon achieves multi-user communication with
a sum data rate of up to 0.80 Gbps across two users. Simultaneously, Chameleon
employs a beamformer switching interval of only 0.24 {\mu}s, therefore
producing a 31x31-point 2D imaging within just 0.875 ms. Leveraging machine
learning, Chameleon further enables object localization with median errors of
0.14 m (distance) and 0.24{\deg} (angle), and material classification with
99.0% accuracy.

</details>


### [3] [1Q: First-Generation Wireless Systems Integrating Classical and Quantum Communication](https://arxiv.org/abs/2509.14731)
*Petar Popovski,Čedomir Stefanović,Beatriz Soret,Israel Leyva-Mayorga,Shashi Raj Pandey,René Bødker Christensen,Jakob Kaltoft Søndergaard,Kristian Skafte Jensen,Thomas Garm Pedersen,Angela Sara Cacciapuoti,Lajos Hanzo*

Main category: cs.NI

TL;DR: 1Q是首个无线集成经典与量子通信的框架，通过量子基站支持自由空间光链路的纠缠分发，扩展量子互联网到蜂窝无线网络


<details>
  <summary>Details</summary>
Motivation: 将量子互联网扩展到无线蜂窝网络，实现经典通信与量子通信的集成，支持量子密钥分发、盲量子计算和分布式量子传感等应用

Method: 提出量子基站(QBS)、量子小区、量子用户设备(QUE)等新组件，采用混合资源分配策略，扩展蜂窝连接管理协议以包含纠缠生成、分发和切换过程

Result: 建立了1Q框架，识别了包括退相干时间、保真度要求以及量子与经典错误概率相互作用在内的独特量子约束

Conclusion: 1Q框架成功将量子通信扩展到无线领域，为构建集成经典和量子通信的下一代无线网络奠定了基础

Abstract: We sketch out the concept of 1Q, the first wireless generation of integrated
classical and quantum communication. The 1Q framework features quantum base
stations (QBSs) that support entanglement distribution via free-space optical
links alongside traditional radio communications. Key new components include
quantum cells, quantum user equipment (QUEs), and hybrid resource allocation
spanning classical time-frequency and quantum entanglement domains. Several
application scenarios are discussed and illustrated through system design
requirements for quantum key distribution, blind quantum computing, and
distributed quantum sensing. A range of unique quantum constraints are
identified, including decoherence timing, fidelity requirements, and the
interplay between quantum and classical error probabilities. Protocol
adaptations extend cellular connection management to incorporate entanglement
generation, distribution, and handover procedures, expanding the Quantum
Internet to the cellular wireless.

</details>


### [4] [AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS in 6G Smart Cities](https://arxiv.org/abs/2509.14877)
*Rohin Gillgallon,Giacomo Bergami,Reham Almutairi,Graham Morgan*

Main category: cs.NI

TL;DR: 本文扩展了SimulatorOrchestrator模拟器，通过AI算法实现动态车辆规划和优化，在减少车辆电池消耗的同时确保通信公平性


<details>
  <summary>Details</summary>
Motivation: 现有车载物联网节点模拟器缺乏动态代理规划和优化功能，无法在最小化车辆电池消耗的同时保证公平通信时间

Method: 扩展SimulatorOrchestrator架构，集成AI算法进行交通预测和动态代理规划，引入期望区域概念

Result: 在城市数据集上的初步结果显示，车辆规划算法相比传统最短路径算法能改善电池和QoS性能，期望区域的使用使更多救护车能以更少能耗到达目的地

Conclusion: AI驱动的动态规划算法和期望区域概念能有效优化车载物联网系统的能耗和通信性能

Abstract: While simulators exist for vehicular IoT nodes communicating with the Cloud
through Edge nodes in a fully-simulated osmotic architecture, they often lack
support for dynamic agent planning and optimisation to minimise vehicular
battery consumption while ensuring fair communication times. Addressing these
challenges requires extending current simulator architectures with AI
algorithms for both traffic prediction and dynamic agent planning. This paper
presents an extension of SimulatorOrchestrator (SO) to meet these requirements.
Preliminary results over a realistic urban dataset show that utilising
vehicular planning algorithms can lead to improved battery and QoS performance
compared with traditional shortest path algorithms. The additional inclusion of
desirability areas enabled more ambulances to be routed to their target
destinations while utilising less energy to do so, compared to traditional and
weighted algorithms without desirability considerations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity](https://arxiv.org/abs/2509.14251)
*Qihang Chen*

Main category: cs.AI

TL;DR: 基于层次时空网络模型的统一优化框架，通过列生成算法解决多线路地铁班制排班和紧急重新排班问题，实现成本优化和任务完成率提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单个地铁线路，缺乏多线路协调和紧急情况下的快速重新规划能力，影响公共交通运营效率和服务可靠性。

Method: 提出层次时空网络模型表示统一的员工动作空间，建立计算高效的约束条件和数学推导，并发展基于列生成和最短路径调整的求解算法。

Result: 上海和北京地铁实际数据实验显示，该方法在成本降低和任务完成方面都超过基准算法，通过多线路协同操作特别是在故障情况下实现显著效率提升。

Conclusion: 该研究强调了全局优化和多线路协调在地铁系统运营中的重要作用，为智慧城市公共交通的高效可靠运营提供了见解。

Abstract: Metro crew planning is a key component of smart city development as it
directly impacts the operational efficiency and service reliability of public
transportation. With the rapid expansion of metro networks, effective
multi-line scheduling and emergency management have become essential for
large-scale seamless operations. However, current research focuses primarily on
individual metro lines,with insufficient attention on cross-line coordination
and rapid replanning during disruptions. Here, a unified optimization framework
is presented for multi-line metro crew planning and replanning with
heterogeneous workforce. Specifically, a hierarchical time-space network model
is proposed to represent the unified crew action space, and computationally
efficient constraints and formulations are derived for the crew's heterogeneous
qualifications and preferences. Solution algorithms based on column generation
and shortest path adjustment are further developed, utilizing the proposed
network model. Experiments with real data from Shanghai and Beijing Metro
demonstrate that the proposed methods outperform benchmark heuristics in both
cost reduction and task completion,and achieve notable efficiency gains by
incorporating cross-line operations, particularly for urgent tasks during
disruptions. This work highlights the role of global optimization and
cross-line coordination in multi-line metro system operations, providing
insights into the efficient and reliable functioning of public transportation
in smart cities.

</details>


### [6] [From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289)
*Lanxiao Huang,Daksh Dave,Ming Jin,Tyler Cody,Peter Beling*

Main category: cs.AI

TL;DR: 对多种LLM驱动的渗透测试代理进行全面评估，发现目标增强显著提升模块化代理在复杂渗透测试任务中的性能


<details>
  <summary>Details</summary>
Motivation: 评估LLM在渗透测试中的有效性和可靠性，明确不同攻击阶段的性能表现和常见失败模式

Method: 通过五种核心功能增强（全局上下文记忆、代理间消息传递、上下文条件调用、自适应规划、实时监控）来评估单代理和模块化设计的LLM代理

Result: 目标增强显著改善了模块化代理的性能，特别是在复杂、多步骤和实时渗透测试任务中

Conclusion: 虽然某些架构天然具备部分功能特性，但针对性增强对提升LLM在渗透测试中的表现至关重要

Abstract: Large language models (LLMs) are increasingly used to automate or augment
penetration testing, but their effectiveness and reliability across attack
phases remain unclear. We present a comprehensive evaluation of multiple
LLM-based agents, from single-agent to modular designs, across realistic
penetration testing scenarios, measuring empirical performance and recurring
failure patterns. We also isolate the impact of five core functional
capabilities via targeted augmentations: Global Context Memory (GCM),
Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive
Planning (AP), and Real-Time Monitoring (RTM). These interventions support,
respectively: (i) context coherence and retention, (ii) inter-component
coordination and state management, (iii) tool use accuracy and selective
execution, (iv) multi-step strategic planning, error detection, and recovery,
and (v) real-time dynamic responsiveness. Our results show that while some
architectures natively exhibit subsets of these properties, targeted
augmentations substantially improve modular agent performance, especially in
complex, multi-step, and real-time penetration testing tasks.

</details>


### [7] [Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents](https://arxiv.org/abs/2509.14382)
*Daniel Röder,Akhil Juneja,Roland Roller,Sven Schmeier*

Main category: cs.AI

TL;DR: 一个模块化评估框架，用于分解LLM网页代理的执行过程，进行细粒度错误分析，提高效能评估的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前对LLM网页代理的评估主要关注整体成功率，忽视了中间过程错误，限制了对失败模式的深入理解和系统性改进。

Method: 提出模块化评估框架，将代理流水线解构为可解释的阶段，进行详细错误分析。使用SeeAct框架和Mind2Web数据集进行案例研究。

Result: 该方法发现了标准指标没有发现的可操作弱点，提供了更深入的效能评估视角。

Conclusion: 模块化评估框架为构建更稳健和可推广的网页代理提供了新的途径，通过细粒度错误分析提升了系统性改进的可能性。

Abstract: Web agents powered by large language models (LLMs) can autonomously perform
complex, multistep tasks in dynamic web environments. However, current
evaluations mostly focus on the overall success while overlooking intermediate
errors. This limits insight into failure modes and hinders systematic
improvement. This work analyzes existing benchmarks and highlights the lack of
fine-grained diagnostic tools. To address this gap, we propose a modular
evaluation framework that decomposes agent pipelines into interpretable stages
for detailed error analysis. Using the SeeAct framework and the Mind2Web
dataset as a case study, we show how this approach reveals actionable
weaknesses missed by standard metrics - paving the way for more robust and
generalizable web agents.

</details>


### [8] [VCBench: Benchmarking LLMs in Venture Capital](https://arxiv.org/abs/2509.14448)
*Rick Chen,Joseph Ternasky,Afriyie Samuel Kwesi,Ben Griffin,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: VCBench是首个用于预测风险投资中创始人成功的基准测试，包含9000个匿名创始人资料，评估显示LLM模型表现优于人类基准和顶级投资机构


<details>
  <summary>Details</summary>
Motivation: 现有基准如SWE-bench和ARC-AGI显示共享数据集能加速AGI发展，但在风险投资领域缺乏标准化评估基准，该领域信号稀疏、结果不确定，即使顶级投资者表现也一般

Method: 创建包含9000个匿名创始人资料的VCBench数据集，进行标准化处理以保留预测特征同时防止身份泄露，使用对抗测试降低90%以上的重识别风险，评估9个最先进的LLM模型

Result: 市场指数精度1.9%，Y Combinator比指数好1.7倍，顶级机构好2.9倍。DeepSeek-V3达到基线精度的6倍以上，GPT-4o获得最高F0.5分数，大多数模型超越人类基准

Conclusion: VCBench作为公开且不断发展的资源，为早期风险预测中的AGI评估建立了社区驱动的可重复和隐私保护标准

Abstract: Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets
accelerate progress toward artificial general intelligence (AGI). We introduce
VCBench, the first benchmark for predicting founder success in venture capital
(VC), a domain where signals are sparse, outcomes are uncertain, and even top
investors perform modestly. At inception, the market index achieves a precision
of 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1
firms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,
standardized to preserve predictive features while resisting identity leakage,
with adversarial tests showing more than 90% reduction in re-identification
risk. We evaluate nine state-of-the-art large language models (LLMs).
DeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the
highest F0.5, and most models surpass human benchmarks. Designed as a public
and evolving resource available at vcbench.com, VCBench establishes a
community-driven standard for reproducible and privacy-preserving evaluation of
AGI in early-stage venture forecasting.

</details>


### [9] [From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence](https://arxiv.org/abs/2509.14474)
*Meltem Subasioglu,Nevzat Subasioglu*

Main category: cs.AI

TL;DR: 该文章提出了一种基于认知机制的真正智能(TI)定义，包含六个核心组件，并建立了五级AGI分类评价体系，为AGI研究提供了清智的发展路径。


<details>
  <summary>Details</summary>
Motivation: 解决当前AGI讨论中表现模仿与认知过程复制的分歧，现有的表现基于定义缺乏机制化研究路径，无法正确定义真正智能的本质特征。

Method: 受人脑启发，提出真正智能(TI)的六大核心组件：体验感官融合、核心指令、动态模式创建、高度联网多专家架构、协调层、以及不可测量的联结性。建立五级AGI分类评价体系。

Result: 提出了一个全面的机制基础定义，为AGI研究社群提供了清智可行的发展路径。认为实现五级AGI后，系统在功能和实践上等同于真正智能。

Conclusion: 通过综合分析心理学、模式理论、元认知、现代脑科学和AI领域的最新研究，提供了首个整体性的机制基础AGI定义，为研究社群提供了明确的研究方向。

Abstract: The debate around Artificial General Intelligence (AGI) remains open due to
two fundamentally different goals: replicating human-like performance versus
replicating human-like cognitive processes. We argue that current
performance-based definitions are inadequate because they provide no clear,
mechanism-focused roadmap for research, and they fail to properly define the
qualitative nature of genuine intelligence. Drawing inspiration from the human
brain, we propose a new paradigm that shifts the focus from external mimicry to
the development of foundational cognitive architectures. We define True
Intelligence (TI) as a system characterized by six core components: embodied
sensory fusion, core directives, dynamic schemata creation, a
highly-interconnected multi-expert architecture, an orchestration layer, and
lastly, the unmeasurable quality of Interconnectedness, which we hypothesize
results in consciousness and a subjective experience. We propose a practical,
five-level taxonomy of AGI based on the number of the first five measurable
components a system exhibits. This framework provides a clear path forward with
developmental milestones that directly address the challenge of building
genuinely intelligent systems. We contend that once a system achieves Level-5
AGI by implementing all five measurable components, the difference between it
and TI remains as a purely philosophical debate. For practical purposes - and
given theories indicate consciousness is an emergent byproduct of integrated,
higher-order cognition - we conclude that a fifth-level AGI is functionally and
practically equivalent to TI. This work synthesizes diverse insights from
analytical psychology, schema theory, metacognition, modern brain architectures
and latest works in AI to provide the first holistic, mechanism-based
definition of AGI that offers a clear and actionable path for the research
community.

</details>


### [10] [Beyond the high score: Prosocial ability profiles of multi-agent populations](https://arxiv.org/abs/2509.14485)
*Marko Tesic,Yue Zhao,Joel Z. Leibo,Rakshit S. Trivedi,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 本文应用贝叶斯测量布局方法分析Melting Pot竞赛中多智能体系统的能力特征，发现高亲社会能力并不总是带来更好表现，顶级参赛方案可能在不需要合作的场景中得分更高，揭示了评估框架的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估AI智能体的社交能力需要复杂环境，但传统方法难以控制抽象行为如约定遵循。Melting Pot竞赛旨在评估AI系统的合作能力，但需要更透明的评估方法来理解智能体的真实亲社会能力。

Method: 采用贝叶斯测量布局方法推断多智能体系统在Melting Pot竞赛中的能力特征，分析能力特征与未来表现的关系，并评估亲社会能力与性能的相关性。

Result: 能力特征不仅能预测未来表现，还揭示了智能体的亲社会能力；高亲社会能力有时与更好表现相关，但非普遍趋势；顶级参赛方案更可能在不需要亲社会能力的场景中获得高分；竞赛获胜者使用了针对特定环境的硬编码方案。

Conclusion: 测量布局方法提供了强预测准确性和可操作见解，有助于在复杂社交环境中更透明、可泛化地评估AI系统。需要改进合作需求的标注方法，并考虑不同测试环境引入的偏差。

Abstract: The development and evaluation of social capabilities in AI agents require
complex environments where competitive and cooperative behaviours naturally
emerge. While game-theoretic properties can explain why certain teams or agent
populations outperform others, more abstract behaviours, such as convention
following, are harder to control in training and evaluation settings. The
Melting Pot contest is a social AI evaluation suite designed to assess the
cooperation capabilities of AI systems. In this paper, we apply a Bayesian
approach known as Measurement Layouts to infer the capability profiles of
multi-agent systems in the Melting Pot contest. We show that these capability
profiles not only predict future performance within the Melting Pot suite but
also reveal the underlying prosocial abilities of agents. Our analysis
indicates that while higher prosocial capabilities sometimes correlate with
better performance, this is not a universal trend-some lower-scoring agents
exhibit stronger cooperation abilities. Furthermore, we find that
top-performing contest submissions are more likely to achieve high scores in
scenarios where prosocial capabilities are not required. These findings,
together with reports that the contest winner used a hard-coded solution
tailored to specific environments, suggest that at least one top-performing
team may have optimised for conditions where cooperation was not necessary,
potentially exploiting limitations in the evaluation framework. We provide
recommendations for improving the annotation of cooperation demands and propose
future research directions to account for biases introduced by different
testing environments. Our results demonstrate that Measurement Layouts offer
both strong predictive accuracy and actionable insights, contributing to a more
transparent and generalisable approach to evaluating AI systems in complex
social settings.

</details>


### [11] [DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction](https://arxiv.org/abs/2509.14507)
*Jian Chen,Zhenyan Chen,Xuming Hu,Peilin Zhou,Yining Hua,Han Fang,Cissy Hing Yee Choy,Xinmei Ke,Jingfeng Luo,Zixuan Yuan*

Main category: cs.AI

TL;DR: 提出了DeKeyNLU数据集和DeKeySQL框架，通过改进任务分解和关键词提取来提升NL2SQL性能，在BIRD和Spider数据集上显著提高了SQL生成准确率


<details>
  <summary>Details</summary>
Motivation: 现有NL2SQL方法存在任务分解不准确和关键词提取错误的问题，现有数据集存在任务过度碎片化和缺乏领域特定关键词标注的局限性

Method: 创建了包含1500个标注QA对的DeKeyNLU数据集，提出了基于RAG的DeKeySQL框架，包含三个模块：用户问题理解、实体检索和生成

Result: 在BIRD数据集上准确率从62.31%提升到69.10%，在Spider数据集上从84.2%提升到88.7%

Conclusion: DeKeyNLU数据集和DeKeySQL框架有效解决了NL2SQL中的任务分解和关键词提取问题，显著提升了SQL生成准确性

Abstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.

</details>


### [12] [Rationality Check! Benchmarking the Rationality of Large Language Models](https://arxiv.org/abs/2509.14546)
*Zhilun Zhou,Jing Yi Wang,Nicholas Sukiennik,Chen Gao,Fengli Xu,Yong Li,James Evans*

Main category: cs.AI

TL;DR: 该研究提出了第一个评估大语言模型全方位理性的基准测试，涵盖多个领域和模型，包括易用工具包、实验结果和分析，揭示了LLMs与理想人类理性的异同点。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在模拟人类和作为AI助手方面的广泛应用，人们越来越关注LLMs是否以及在什么情况下像真实人类一样思考和行动。理性是评估人类行为最重要的概念之一。

Method: 提出了一个全面的基准测试框架，包括易用的工具包，对多种LLMs在不同领域进行广泛的实验评估，分析其理性表现。

Result: 研究提供了详细的实验结果和分析，揭示了LLMs在哪些方面与理想化的人类理性趋同或分歧。

Conclusion: 该基准测试可以作为LLMs开发者和用户的基础工具，帮助评估和改进模型的理性能力。

Abstract: Large language models (LLMs), a recent advance in deep learning and machine
intelligence, have manifested astonishing capacities, now considered among the
most promising for artificial general intelligence. With human-like
capabilities, LLMs have been used to simulate humans and serve as AI assistants
across many applications. As a result, great concern has arisen about whether
and under what circumstances LLMs think and behave like real human agents.
Rationality is among the most important concepts in assessing human behavior,
both in thinking (i.e., theoretical rationality) and in taking action (i.e.,
practical rationality). In this work, we propose the first benchmark for
evaluating the omnibus rationality of LLMs, covering a wide range of domains
and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental
results, and analysis that illuminates where LLMs converge and diverge from
idealized human rationality. We believe the benchmark can serve as a
foundational tool for both developers and users of LLMs.

</details>


### [13] [(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration](https://arxiv.org/abs/2509.14547)
*Yi Lin,Lujin Zhao,Yijie Shi*

Main category: cs.AI

TL;DR: 提出了一种先验动态框架，通过Q-table学习和先验决策机制，结合历史经验和任务特性来自动构建高效的工作流，在提升性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有工作流构建方法过度依赖历史经验，缺乏对任务独特特性的灵活响应，导致效率和适应性受限。

Method: 基于Q-table学习优化决策空间，结合先验决策机制评估任务进度并选择合适的工作流结构，同时采用冷启动初始化、早停和剪枝等技术提升效率。

Result: 在四个基准数据集上平均性能提升4.05%，工作流构建和推理成本降至现有方法的30.68%-48.31%。

Conclusion: 该框架通过结合历史经验和任务特性感知，实现了更高效、自适应的工作流自动构建，在性能和成本方面均优于现有方法。

Abstract: Recent studies have shown that carefully designed workflows coordinating
large language models(LLMs) significantly enhance task-solving capabilities
compared to using a single model. While an increasing number of works focus on
autonomous workflow construction, most existing approaches rely solely on
historical experience, leading to limitations in efficiency and adaptability.
We argue that while historical experience is valuable, workflow construction
should also flexibly respond to the unique characteristics of each task. To
this end, we propose an a priori dynamic framework for automated workflow
construction. Our framework first leverages Q-table learning to optimize the
decision space, guiding agent decisions and enabling effective use of
historical experience. At the same time, agents evaluate the current task
progress and make a priori decisions regarding the next executing agent,
allowing the system to proactively select the more suitable workflow structure
for each given task. Additionally, we incorporate mechanisms such as cold-start
initialization, early stopping, and pruning to further improve system
efficiency. Experimental evaluations on four benchmark datasets demonstrate the
feasibility and effectiveness of our approach. Compared to state-of-the-art
baselines, our method achieves an average improvement of 4.05%, while reducing
workflow construction and inference costs to only 30.68%-48.31% of those
required by existing methods.

</details>


### [14] [SynBench: A Benchmark for Differentially Private Text Generation](https://arxiv.org/abs/2509.14594)
*Yidan Sun,Viktor Schlegel,Srinivasan Nandakumar,Iqra Zahid,Yuping Wu,Yulong Wu,Hao Li,Jie Zhang,Warren Del-Pinto,Goran Nenadic,Siew Kei Lam,Anil Anthony Bharath*

Main category: cs.AI

TL;DR: 这篇论文研究了在高风险领域中使用差分隐私技术生成合成文本数据的挑战，提出了评估框架、对比了各种方法的性能，并发现领域复杂性会导致性能下降以及公开数据集可能无效化隐私保证。


<details>
  <summary>Details</summary>
Motivation: 高风险领域如医疗和金融中的数据共享遇到隐私、监管和机构问题。虽然生成式AI模型在广泛任务中表现优异，但在敏感环境中采用仍受限于不可预测行为和隐私保护数据集的不足。差分隐私提供了一种有理论基础的合成数据生成方案。

Method: 首先提出了一个综合性评估框架，包含标准化的效用性和保真度指标，以9个经过精心编辑的数据集来抓取领域特定的复杂性。其次进行了大规模实验研究，对比了最先进的差分隐私文本生成方法和不同规模、不同微调策略的大语言模型。最后，开发了一种专门用于合成文本的成员推断攻击方法。

Result: 研究发现，在差分隐私约束下生成高质量领域特定合成数据仍然是一个未解决的挑战，性能随着领域复杂性的增加而下降。同时提供了首个实证证据，证明使用公开数据集（可能存在于预训练语料中）可能会使声称的隐私保证失效。

Conclusion: 这些发现强调了对严格隐私审计的紧迫需求，并展现了广泛领域与专业领域评估之间持续存在的差距，为在隐私敏感、高风险环境中负责任地部署生成式AI提供了重要信息。

Abstract: Data-driven decision support in high-stakes domains like healthcare and
finance faces significant barriers to data sharing due to regulatory,
institutional, and privacy concerns. While recent generative AI models, such as
large language models, have shown impressive performance in open-domain tasks,
their adoption in sensitive environments remains limited by unpredictable
behaviors and insufficient privacy-preserving datasets for benchmarking.
Existing anonymization methods are often inadequate, especially for
unstructured text, as redaction and masking can still allow re-identification.
Differential Privacy (DP) offers a principled alternative, enabling the
generation of synthetic data with formal privacy assurances. In this work, we
address these challenges through three key contributions. First, we introduce a
comprehensive evaluation framework with standardized utility and fidelity
metrics, encompassing nine curated datasets that capture domain-specific
complexities such as technical jargon, long-context dependencies, and
specialized document structures. Second, we conduct a large-scale empirical
study benchmarking state-of-the-art DP text generation methods and LLMs of
varying sizes and different fine-tuning strategies, revealing that high-quality
domain-specific synthetic data generation under DP constraints remains an
unsolved challenge, with performance degrading as domain complexity increases.
Third, we develop a membership inference attack (MIA) methodology tailored for
synthetic text, providing first empirical evidence that the use of public
datasets - potentially present in pre-training corpora - can invalidate claimed
privacy guarantees. Our findings underscore the urgent need for rigorous
privacy auditing and highlight persistent gaps between open-domain and
specialist evaluations, informing responsible deployment of generative AI in
privacy-sensitive, high-stakes settings.

</details>


### [15] [AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](https://arxiv.org/abs/2509.14647)
*NVJK Kartik,Garvit Sapra,Rishav Hada,Nikhil Pareek*

Main category: cs.AI

TL;DR: AgentCompass是首个专门为多智能体工作流设计的后部署监控和调试评估框架，通过结构化分析流程和双记忆系统实现持续学习，在真实部署和基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多智能体工作流中的广泛应用，现有评估方法无法有效捕捉错误、涌现行为和系统性故障等风险，需要专门的监控调试工具。

Method: 采用结构化多阶段分析流程：错误识别分类、主题聚类、量化评分和策略总结，并配备情景记忆和语义记忆的双记忆系统实现持续学习。

Result: 在真实部署和TRAIL基准测试中取得最先进结果，发现了人工标注遗漏的关键问题，证明了其实际效用。

Conclusion: AgentCompass作为面向开发者的强大工具，能够可靠地监控和改进生产环境中的智能体系统。

Abstract: With the growing adoption of Large Language Models (LLMs) in automating
complex, multi-agent workflows, organizations face mounting risks from errors,
emergent behaviors, and systemic failures that current evaluation methods fail
to capture. We present AgentCompass, the first evaluation framework designed
specifically for post-deployment monitoring and debugging of agentic workflows.
AgentCompass models the reasoning process of expert debuggers through a
structured, multi-stage analytical pipeline: error identification and
categorization, thematic clustering, quantitative scoring, and strategic
summarization. The framework is further enhanced with a dual memory
system-episodic and semantic-that enables continual learning across executions.
Through collaborations with design partners, we demonstrate the framework's
practical utility on real-world deployments, before establishing its efficacy
against the publicly available TRAIL benchmark. AgentCompass achieves
state-of-the-art results on key metrics, while uncovering critical issues
missed in human annotations, underscoring its role as a robust,
developer-centric tool for reliable monitoring and improvement of agentic
systems in production.

</details>


### [16] [Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory](https://arxiv.org/abs/2509.14662)
*Ming Li,Nan Zhang,Chenrui Fan,Hong Jiao,Yanbin Fu,Sydney Peters,Qingshu Xu,Robert Lissitz,Tianyi Zhou*

Main category: cs.AI

TL;DR: 应用Schoenfeld的Episode Theory认知框架分析大型推理模型的思维过程，创建首个细粒度机器推理分析基准，揭示LRM推理的认知状态转换模式


<details>
  <summary>Details</summary>
Motivation: 缺乏理解大型推理模型(LRMs)思维结构的理论框架，需要基于人类数学问题解决的认知理论来分析机器推理过程

Method: 应用Schoenfeld的Episode Theory认知框架，使用7个认知标签(如计划、实施、验证)对模型生成的数学问题解决方案进行句子和段落级标注

Result: 创建了首个公开可用的细粒度机器推理分析基准，包括大规模标注语料库和详细标注指南；初步分析揭示了LRM推理的独特模式，特别是认知状态间的转换动态

Conclusion: 该框架为解释LRM认知提供了理论基础，能够支持未来开发更可控和透明的推理系统

Abstract: While Large Reasoning Models (LRMs) generate extensive chain-of-thought
reasoning, we lack a principled framework for understanding how these thoughts
are structured. In this paper, we introduce a novel approach by applying
Schoenfeld's Episode Theory, a classic cognitive framework for human
mathematical problem-solving, to analyze the reasoning traces of LRMs. We
annotated thousands of sentences and paragraphs from model-generated solutions
to math problems using seven cognitive labels (e.g., Plan, Implement, Verify).
The result is the first publicly available benchmark for the fine-grained
analysis of machine reasoning, including a large annotated corpus and detailed
annotation guidebooks. Our preliminary analysis reveals distinct patterns in
LRM reasoning, such as the transition dynamics between cognitive states. This
framework provides a theoretically grounded methodology for interpreting LRM
cognition and enables future work on more controllable and transparent
reasoning systems.

</details>


### [17] [RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](https://arxiv.org/abs/2509.14693)
*Song Xu,Yilun Liu,Minggui He,Mingchen Dai,Ziang Chen,Chunguang Zhao,Jingzhou Du,Shimin Tao,Weibin Meng,Shenglin Zhang,Yongqian Sun,Boxing Chen,Daimeng Wei*

Main category: cs.AI

TL;DR: RationAnomaly是一个结合思维链微调和强化学习的日志异常检测框架，通过专家修正数据集和多方奖励函数，在准确性和逻辑一致性方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有日志异常检测方法存在局限性：传统深度学习模型缺乏可解释性和泛化能力，而基于大语言模型的方法存在不可靠性和事实错误问题

Method: 首先通过思维链引导的监督微调建立专家级推理模式，基于专家修正的高质量数据集；然后使用多方奖励函数的强化学习阶段优化准确性和逻辑一致性

Result: 在关键基准测试中实现了优越的F1分数，同时提供透明的逐步分析输出

Conclusion: RationAnomaly通过结合CoT微调和强化学习，有效解决了现有方法的局限性，在日志异常检测方面表现出色，并提供了可解释的结果

Abstract: Logs constitute a form of evidence signaling the operational status of
software systems. Automated log anomaly detection is crucial for ensuring the
reliability of modern software systems. However, existing approaches face
significant limitations: traditional deep learning models lack interpretability
and generalization, while methods leveraging Large Language Models are often
hindered by unreliability and factual inaccuracies. To address these issues, we
propose RationAnomaly, a novel framework that enhances log anomaly detection by
synergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our
approach first instills expert-like reasoning patterns using CoT-guided
supervised fine-tuning, grounded in a high-quality dataset corrected through a
rigorous expert-driven process. Subsequently, a reinforcement learning phase
with a multi-faceted reward function optimizes for accuracy and logical
consistency, effectively mitigating hallucinations. Experimentally,
RationAnomaly outperforms state-of-the-art baselines, achieving superior
F1-scores on key benchmarks while providing transparent, step-by-step
analytical outputs. We have released the corresponding resources, including
code and datasets.

</details>


### [18] [The NazoNazo Benchmark: A Cost-Effective and Extensible Test of Insight-Based Reasoning in LLMs](https://arxiv.org/abs/2509.14704)
*Masaharu Mizumoto,Dat Nguyen,Zhiheng Han,Jiyuan Fang,Heyuan Guan,Xingfu Li,Naoya Shiraishi,Xuyang Tian,Yo Nakawake,Le Minh Nguyen*

Main category: cs.AI

TL;DR: Nazonazo是一个基于日本儿童谜语构建的成本效益高、可扩展的基准测试，用于评估基于洞察力的推理能力，解决了LLM评估中的基准饱和和污染问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估面临基准饱和和污染问题，需要成本效益高、可扩展且易于更新的评估方法来测试洞察力推理能力。

Method: 使用日本儿童谜语构建基准测试，包含120个谜题（后扩展到201个），评估了38个前沿模型和126名成年人，通过候选追踪分析思维日志。

Result: 除GPT-5外，所有模型性能均不及人类（52.9%平均准确率）；推理模型显著优于非推理模型；模型大小与准确率无可靠关联；发现验证失败现象。

Conclusion: Nazonazo提供了解决当前评估危机的有效基准格式，同时揭示了模型在元认知方面的重复弱点，为未来控制和校准方法提供了明确目标。

Abstract: Benchmark saturation and contamination undermine confidence in LLM
evaluation. We present Nazonazo, a cost-effective and extensible benchmark
built from Japanese children's riddles to test insight-based reasoning. Items
are short (mostly one sentence), require no specialized domain knowledge, and
can be generated at scale, enabling rapid refresh of blind sets when leakage is
suspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No
model except for GPT-5 is comparable to human performance, which achieves a
52.9% mean accuracy. Model comparison on extended 201 items shows that
reasoning models significantly outperform non-reasoning peers, while model size
shows no reliable association with accuracy. Beyond aggregate accuracy, an
informal candidate-tracking analysis of thought logs reveals many cases of
verification failure: models often produce the correct solution among
intermediate candidates yet fail to select it as the final answer, which we
illustrate with representative examples observed in multiple models. Nazonazo
thus offers a cost-effective, scalable, and easily renewable benchmark format
that addresses the current evaluation crisis while also suggesting a recurrent
meta-cognitive weakness, providing clear targets for future control and
calibration methods.

</details>


### [19] [Enhancing Retrieval Augmentation via Adversarial Collaboration](https://arxiv.org/abs/2509.14750)
*Letian Zhang,Guanghao Meng,Xudong Ren,Yiming Wang,Shu-Tao Xia*

Main category: cs.AI

TL;DR: 通过对立合作框架，使用检测器和解决器两个异质代理来识别知识空白并提供精准解决方案，有效减少摘要幻觉现象


<details>
  <summary>Details</summary>
Motivation: 解决RAG方法中存在的"摘要幻觉"问题，即细调模型无法识别和处理质量差的摘要文档，影响性能表现

Method: 提出AC-RAG框架，使用两个异质代理：通用检测器（识别知识空白）和领域专门解决器（提供精准解决方案），通过调解员引导进行对立合作

Result: 大量实验表明AC-RAG显著提高了摘要准确性，在多个垂直领域超越了现有最优RAG方法

Conclusion: AC-RAG框架通过对立合作的方式有效解决了RAG中的摘要幻觉问题，提高了域专用LLM的性能

Abstract: Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.

</details>


### [20] [OpenLens AI: Fully Autonomous Research Agent for Health Infomatics](https://arxiv.org/abs/2509.14778)
*Yuxiao Cheng,Jinli Suo*

Main category: cs.AI

TL;DR: OpenLens AI是一个专为健康信息学设计的全自动研究框架，集成了文献综述、数据分析、代码生成和论文撰写等专业代理，通过视觉语言反馈和质控机制解决现有LLM代理在医学可视化解释和领域特定质量要求方面的不足。


<details>
  <summary>Details</summary>
Motivation: 健康信息学研究具有数据模态多样、知识快速扩展的特点，需要整合生物医学科学、数据分析和临床实践。现有基于大语言模型的代理系统在医学可视化解释和领域特定质量要求方面存在局限，无法满足健康信息学研究的需求。

Method: 开发OpenLens AI框架，集成专业代理进行文献综述、数据分析、代码生成和论文准备，通过视觉语言反馈处理医学可视化，并建立质量控制机制确保可重复性。框架自动化整个研究流程，生成可直接发表的LaTeX论文。

Result: OpenLens AI提供了一个领域适配的解决方案，能够自动化健康信息学研究流程，生成具有透明和可追溯工作流程的出版就绪论文。

Conclusion: 该框架通过专业代理集成和视觉语言反馈机制，有效解决了健康信息学研究中的自动化挑战，为推进该领域研究提供了创新的技术方案。

Abstract: Health informatics research is characterized by diverse data modalities,
rapid knowledge expansion, and the need to integrate insights across biomedical
science, data analytics, and clinical practice. These characteristics make it
particularly well-suited for agent-based approaches that can automate knowledge
exploration, manage complex workflows, and generate clinically meaningful
outputs. Recent progress in large language model (LLM)-based agents has
demonstrated promising capabilities in literature synthesis, data analysis, and
even end-to-end research execution. However, existing systems remain limited
for health informatics because they lack mechanisms to interpret medical
visualizations and often overlook domain-specific quality requirements. To
address these gaps, we introduce OpenLens AI, a fully automated framework
tailored to health informatics. OpenLens AI integrates specialized agents for
literature review, data analysis, code generation, and manuscript preparation,
enhanced by vision-language feedback for medical visualization and quality
control for reproducibility. The framework automates the entire research
pipeline, producing publication-ready LaTeX manuscripts with transparent and
traceable workflows, thereby offering a domain-adapted solution for advancing
health informatics research.

</details>


### [21] [Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition and Patient Outcomes in an Irish Hospital with Transformers](https://arxiv.org/abs/2509.14942)
*Minh-Khoi Pham,Tai Tan Mai,Martin Crane,Rob Brennan,Marie E. Ward,Una Geary,Declan Byrne,Brian O Connell,Colm Bergin,Donncha Creagh,Nick McDonald,Marija Bezbradica*

Main category: cs.AI

TL;DR: 使用Transformer模型和可解释AI框架分析医院数据，预测碱米欧姆生产菌影响的患者结果，TabTransformer模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 碱米欧姆生产菌在医院感染控制中极关重要，但使用现代深度学习方法进行预测模型研究仍少

Method: 分析爱尔兰急诊医院数据，包含诊断代码、病房转移、患者人口统计学、感染相关变量和接触网络特征，对比Transformer和传统机器学习模型

Result: TabTransformer模型在多个临床预测任务中表现最佳，尤其是碱米欧姆生产菌获得预测（AUROC和敏感度），感染相关特征和网络洞度量重要

Conclusion: 研究提供了一个健壮可解释的AI框架，证明了Transformer模型的优劢性和多样化临床特征的重要性

Abstract: Carbapenemase-Producing Enterobacteriace poses a critical concern for
infection prevention and control in hospitals. However, predictive modeling of
previously highlighted CPE-associated risks such as readmission, mortality, and
extended length of stay (LOS) remains underexplored, particularly with modern
deep learning approaches. This study introduces an eXplainable AI modeling
framework to investigate CPE impact on patient outcomes from Electronic Medical
Records data of an Irish hospital. We analyzed an inpatient dataset from an
Irish acute hospital, incorporating diagnostic codes, ward transitions, patient
demographics, infection-related variables and contact network features. Several
Transformer-based architectures were benchmarked alongside traditional machine
learning models. Clinical outcomes were predicted, and XAI techniques were
applied to interpret model decisions. Our framework successfully demonstrated
the utility of Transformer-based models, with TabTransformer consistently
outperforming baselines across multiple clinical prediction tasks, especially
for CPE acquisition (AUROC and sensitivity). We found infection-related
features, including historical hospital exposure, admission context, and
network centrality measures, to be highly influential in predicting patient
outcomes and CPE acquisition risk. Explainability analyses revealed that
features like "Area of Residence", "Admission Ward" and prior admissions are
key risk factors. Network variables like "Ward PageRank" also ranked highly,
reflecting the potential value of structural exposure information. This study
presents a robust and explainable AI framework for analyzing complex EMR data
to identify key risk factors and predict CPE-related outcomes. Our findings
underscore the superior performance of the Transformer models and highlight the
importance of diverse clinical and network features.

</details>


### [22] [Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems](https://arxiv.org/abs/2509.14956)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的多代理系统安全架构，通过切征代理和协调代理的双层设计，实现了动态适应性防御机制，成功检测了162次合成攻击。


<details>
  <summary>Details</summary>
Motivation: 解决多代理系统中的安全风险，包括提示注入、大语言模型幻觉、隐私泄漏、协同攻击等多种威胁，提高系统的可靠性和安全性。

Method: 设计了双层安全架构：Sentinel代理网络负责分布式监控，集成语义分析、行为分析、检索增强验证等技术；Coordinator代理负责政策管理、威胁响应和系统协调。通过模拟环境注入162次合成攻击进行验证。

Result: 在多代理对话环境中，Sentinel代理成功检测了所有注入的攻击尝试，证明了监控方法的实际可行性。该框架还提供了更好的系统可观测性，支持满足监管要求，并支持政策随时间演进。

Conclusion: 该研究提出的双层安全架构有效地增强了多代理系统的安全性和可靠性，能够动态适应和防御多种类型的威胁。通过Sentinel代理的持续监控和Coordinator代理的管理功能，实现了对现代多代理系统安全挑战的综合解决方案。

Abstract: This paper proposes a novel architectural framework aimed at enhancing
security and reliability in multi-agent systems (MAS). A central component of
this framework is a network of Sentinel Agents, functioning as a distributed
security layer that integrates techniques such as semantic analysis via large
language models (LLMs), behavioral analytics, retrieval-augmented verification,
and cross-agent anomaly detection. Such agents can potentially oversee
inter-agent communications, identify potential threats, enforce privacy and
access controls, and maintain comprehensive audit records. Complementary to the
idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator
Agent supervises policy implementation, and manages agent participation. In
addition, the Coordinator also ingests alerts from Sentinel Agents. Based on
these alerts, it can adapt policies, isolate or quarantine misbehaving agents,
and contain threats to maintain the integrity of the MAS ecosystem. This
dual-layered security approach, combining the continuous monitoring of Sentinel
Agents with the governance functions of Coordinator Agents, supports dynamic
and adaptive defense mechanisms against a range of threats, including prompt
injection, collusive agent behavior, hallucinations generated by LLMs, privacy
breaches, and coordinated multi-agent attacks. In addition to the architectural
design, we present a simulation study where 162 synthetic attacks of different
families (prompt injection, hallucination, and data exfiltration) were injected
into a multi-agent conversational environment. The Sentinel Agents successfully
detected the attack attempts, confirming the practical feasibility of the
proposed monitoring approach. The framework also offers enhanced system
observability, supports regulatory compliance, and enables policy evolution
over time.

</details>


### [23] [Set Contribution Functions for Quantitative Bipolar Argumentation and their Principles](https://arxiv.org/abs/2509.14963)
*Filip Naudot,Andreas Brännström,Vicenç Torra,Timotheus Kampik*

Main category: cs.AI

TL;DR: 本文提出了量化论证集合在双极论证图中对目标论证强度贡献的函数，是现有单论证贡献函数的泛化，并进行了基于原则的分析。


<details>
  <summary>Details</summary>
Motivation: 现有的论证贡献分析主要关注单个论证对目标论证的贡献，缺乏对论证集合整体贡献的量化方法，特别是在双极论证框架中需要考虑论证间的交互作用。

Method: 提出了集合贡献函数来量化论证集合对目标论证强度的贡献，泛化了现有的单论证贡献函数，建立了相应的原则框架进行分析，并引入了关注集合内论证交互特性的新原则。

Result: 开发了通用的集合贡献函数框架，能够更好地捕捉论证集合的整体贡献特性，特别是在考虑论证间相互作用时的表现。

Conclusion: 集合贡献函数为量化论证集合的整体影响提供了有效工具，新引入的原则有助于理解集合内论证的交互特性，在推荐系统等应用场景中具有实用价值。

Abstract: We present functions that quantify the contribution of a set of arguments in
quantitative bipolar argumentation graphs to (the final strength of) an
argument of interest, a so-called topic. Our set contribution functions are
generalizations of existing functions that quantify the contribution of a
single contributing argument to a topic. Accordingly, we generalize existing
contribution function principles for set contribution functions and provide a
corresponding principle-based analysis. We introduce new principles specific to
set-based functions that focus on properties pertaining to the interaction of
arguments within a set. Finally, we sketch how the principles play out across
different set contribution functions given a recommendation system application
scenario.

</details>


### [24] [A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making](https://arxiv.org/abs/2509.14998)
*Xiao Wu,Ting-Zhu Huang,Liang-Jian Deng,Yanyuan Qiao,Imran Razzak,Yutong Xie*

Main category: cs.AI

TL;DR: KAMAC是一个知识驱动的自适应多智能体协作框架，通过动态组建专家团队来解决医疗决策中的复杂问题，在癌症预后等复杂场景中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协作框架采用静态预分配角色，限制了适应性和动态知识整合能力，无法有效处理需要跨专业知识的复杂临床场景

Method: KAMAC框架从初始专家智能体开始，通过知识驱动讨论识别知识缺口，根据需要动态招募额外专家，支持灵活可扩展的协作，最终通过审查更新的智能体评论做出决策

Result: 在两个真实医疗基准测试中，KAMAC显著优于单智能体和先进多智能体方法，特别是在需要动态跨专业知识的复杂临床场景（如癌症预后）中表现突出

Conclusion: KAMAC框架通过动态组建专家团队有效解决了医疗决策中的知识整合问题，为复杂临床场景提供了更灵活和可扩展的协作解决方案

Abstract: Medical decision-making often involves integrating knowledge from multiple
clinical specialties, typically achieved through multidisciplinary teams.
Inspired by this collaborative process, recent work has leveraged large
language models (LLMs) in multi-agent collaboration frameworks to emulate
expert teamwork. While these approaches improve reasoning through agent
interaction, they are limited by static, pre-assigned roles, which hinder
adaptability and dynamic knowledge integration. To address these limitations,
we propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration
framework that enables LLM agents to dynamically form and expand expert teams
based on the evolving diagnostic context. KAMAC begins with one or more expert
agents and then conducts a knowledge-driven discussion to identify and fill
knowledge gaps by recruiting additional specialists as needed. This supports
flexible, scalable collaboration in complex clinical scenarios, with decisions
finalized through reviewing updated agent comments. Experiments on two
real-world medical benchmarks demonstrate that KAMAC significantly outperforms
both single-agent and advanced multi-agent methods, particularly in complex
clinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty
expertise. Our code is publicly available at:
https://github.com/XiaoXiao-Woo/KAMAC.

</details>


### [25] [Calibrated Generative AI as Meta-Reviewer: A Systemic Functional Linguistics Discourse Analysis of Reviews of Peer Reviews](https://arxiv.org/abs/2509.15035)
*Gabriela C. Zapata,Bill Cope,Mary Kalantzis,Duane Searsmith*

Main category: cs.AI

TL;DR: 本研究探讨了使用生成式AI通过机器生成的同行评审元评论来支持形成性评估，发现AI反馈能够近似有效人类反馈的关键修辞和关系特征。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI如何支持在线研究生课程的同行评审过程，通过AI生成的元评论来提升反馈质量和学习者参与度。

Method: 基于系统功能语言学和评价理论，分析了120个AI生成的元评论，从概念、人际和文本三个维度探讨意义构建方式。

Result: AI反馈展现出赞扬与建设性批评的平衡、与评分标准的一致性、以及强调学生主体性的结构化呈现，能够提供清晰的指导性建议同时保持支持性立场。

Conclusion: AI元反馈具有搭建反馈素养支架和增强学习者参与同行评审的潜力，能够模拟有效人类反馈的关键品质。

Abstract: This study investigates the use of generative AI to support formative
assessment through machine generated reviews of peer reviews in graduate online
courses in a public university in the United States. Drawing on Systemic
Functional Linguistics and Appraisal Theory, we analyzed 120 metareviews to
explore how generative AI feedback constructs meaning across ideational,
interpersonal, and textual dimensions. The findings suggest that generative AI
can approximate key rhetorical and relational features of effective human
feedback, offering directive clarity while also maintaining a supportive
stance. The reviews analyzed demonstrated a balance of praise and constructive
critique, alignment with rubric expectations, and structured staging that
foregrounded student agency. By modeling these qualities, AI metafeedback has
the potential to scaffold feedback literacy and enhance leaner engagement with
peer review.

</details>


### [26] [From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support](https://arxiv.org/abs/2509.15084)
*Doreen Jirak,Pieter Maes,Armeen Saroukanoff,Dirk van Rooy*

Main category: cs.AI

TL;DR: 这篇论文提出了一个专门针对海事领域的可解释人工智能调查方案，以提升海上作业中人机协作的信任和透明度。


<details>
  <summary>Details</summary>
Motivation: 随着自主技术在海事操作中日益普及，AI系统的决策理解变得至关重要。在复杂动态的海事环境中，对AI的信任不仅依赖于性能，还需要透明性和可解释性。

Method: 提出了一个领域特定的调查方案，用于收集海事专业人员对信任、易用性和可解释性的意见。

Result: 论文为开发以用户为中心的可解释AI系统提供了指导，适配海员和海事团队的需求。

Conclusion: 可解释AI（XAI）是海事领域有效人机协作的基础，通过用户中心的方法可以提高信任和透明度。

Abstract: As autonomous technologies increasingly shape maritime operations,
understanding why an AI system makes a decision becomes as crucial as what it
decides. In complex and dynamic maritime environments, trust in AI depends not
only on performance but also on transparency and interpretability. This paper
highlights the importance of Explainable AI (XAI) as a foundation for effective
human-machine teaming in the maritime domain, where informed oversight and
shared understanding are essential. To support the user-centered integration of
XAI, we propose a domain-specific survey designed to capture maritime
professionals' perceptions of trust, usability, and explainability. Our aim is
to foster awareness and guide the development of user-centric XAI systems
tailored to the needs of seafarers and maritime teams.

</details>


### [27] [Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment](https://arxiv.org/abs/2509.15172)
*Ankur Samanta,Akshayaa Magesh,Youliang Yu,Runzhe Wu,Ayush Jain,Daniel Jiang,Boris Vidolov,Paul Sajda,Yonathan Efroni,Kaveh Hassani*

Main category: cs.AI

TL;DR: MACA是一个强化学习框架，通过多智能体辩论的多数/少数结果来训练语言模型选择与内部共识一致的推理路径，显著提升模型的自一致性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型是不一致的推理者，经常对相同提示生成矛盾的回答。现有推理时方法无法解决核心问题：模型难以可靠选择能产生一致结果的推理路径。

Method: 提出多智能体共识对齐(MACA)框架，使用多智能体辩论中的多数/少数结果进行强化学习后训练，使模型偏好与其内部共识一致的推理轨迹。

Result: 在自一致性(+27.6% GSM8K)、单智能体推理(+23.7% MATH)、采样推理(+22.4% Pass@20 MATH)和多智能体决策(+42.7% MathQA)方面取得显著提升，在未见基准上也有强泛化能力。

Conclusion: MACA实现了稳健的自对齐，更可靠地释放语言模型的潜在推理能力，通过多智能体辩论产生比单轮多数投票更丰富的共识信号。

Abstract: Language Models (LMs) are inconsistent reasoners, often generating
contradictory responses to identical prompts. While inference-time methods can
mitigate these inconsistencies, they fail to address the core problem: LMs
struggle to reliably select reasoning pathways leading to consistent outcomes
under exploratory sampling. To address this, we formalize self-consistency as
an intrinsic property of well-aligned reasoning models and introduce
Multi-Agent Consensus Alignment (MACA), a reinforcement learning framework that
post-trains models to favor reasoning trajectories aligned with their internal
consensus using majority/minority outcomes from multi-agent debate. These
trajectories emerge from deliberative exchanges where agents ground reasoning
in peer arguments, not just aggregation of independent attempts, creating
richer consensus signals than single-round majority voting. MACA enables agents
to teach themselves to be more decisive and concise, and better leverage peer
insights in multi-agent settings without external supervision, driving
substantial improvements across self-consistency (+27.6% on GSM8K),
single-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4%
Pass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA).
These findings, coupled with strong generalization to unseen benchmarks (+16.3%
on GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more
reliably unlocks latent reasoning potential of language models.

</details>


### [28] [Generalizable Geometric Image Caption Synthesis](https://arxiv.org/abs/2509.15217)
*Yue Xin,Wenyuan Wang,Rui Pan,Ruida Wang,Howard Meng,Renjie Pi,Shizhe Diao,Tong Zhang*

Main category: cs.AI

TL;DR: 通过引入基于验证奖励的强化学习(RLVR)方法，该研究发展了一种生成高质量几何问题图像-文本数据的新方法，提升多模态大语言模型在几何问题解决和一般推理能力上的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂几何问题上表现尚不理惵，主要因为缺乏高质量的几何图像-文本数据集，而传统模板化数据生成方法经常无法满足模板外的问题需求。

Method: 提出RLVR方法，通过基于数学问题解决任务的奖励信号来精炼几何图像的描述文本，该方法基于50个基础几何关系来合成图像。

Result: 在MathVista和MathVerse的非几何图像任务中，统计、算术、代数和数值问题的准确率提升2.8%-4.8%；在MMMU的艺术、设计、技术和工程任务中提升2.4%-3.9%。

Conclusion: RLVR数据生成流水线能够有效提升多模态大语言模型在几何问题解决和一般推理能力上的表现，并且在分布外场景中也能够保持良好的演化效果。

Abstract: Multimodal large language models have various practical applications that
demand strong reasoning abilities. Despite recent advancements, these models
still struggle to solve complex geometric problems. A key challenge stems from
the lack of high-quality image-text pair datasets for understanding geometric
images. Furthermore, most template-based data synthesis pipelines typically
fail to generalize to questions beyond their predefined templates. In this
paper, we bridge this gap by introducing a complementary process of
Reinforcement Learning with Verifiable Rewards (RLVR) into the data generation
pipeline. By adopting RLVR to refine captions for geometric images synthesized
from 50 basic geometric relations and using reward signals derived from
mathematical problem-solving tasks, our pipeline successfully captures the key
features of geometry problem-solving. This enables better task generalization
and yields non-trivial improvements. Furthermore, even in out-of-distribution
scenarios, the generated dataset enhances the general reasoning capabilities of
multimodal large language models, yielding accuracy improvements of
$2.8\%\text{-}4.8\%$ in statistics, arithmetic, algebraic, and numerical tasks
with non-geometric input images of MathVista and MathVerse, along with
$2.4\%\text{-}3.9\%$ improvements in Art, Design, Tech, and Engineering tasks
in MMMU.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [29] [Resource Allocation for Mutualistic Symbiotic Radio with Hybrid Active-Passive Communications](https://arxiv.org/abs/2509.14567)
*Hong Guo,Yinghui Ye,Haijian Sun,Liqin Shi,Rose Qingyang Hu*

Main category: cs.IT

TL;DR: 本文提出一种新型互惜式调制后散射通信系统，通过混合主动/被动传输和动态SIC排序优化，在保障主用户性能的同时显著提升次用户的总传输速率。


<details>
  <summary>Details</summary>
Motivation: 解决传统互惜式调制后散射通信中次用户传输速率极低的问题，通过混合主动/被动传输来提升性能。

Method: 提出混合主动力消耗控制的互惜式调制后散射系统，设计了固定和动态SIC排序两种优化问题，并采用SCA和BCD迭代算法进行求解。

Result: 模拟结果显示：1)新系统在同等约束下显著提升了次用户速率；2)高主用户速率要求下动态SIC排序优于固定排序，低要求时两者性能相似。

Conclusion: 该方案通过混合传输模式和动态优化策略，有效解决了互惜式调制后散射通信中次用户速率低的问题，实现了主次用户双赢。

Abstract: Mutualistic SR is a communication paradigm that offers high spectrum
efficiency and low power consumption, where the SU transmits information by
modulating and backscattering the PT's signal, enabling shared use of spectrum
and power with PT. In return, the PT's performance can be enhanced by SU's
backscattered signal, forming a mutualistic relationship. However, the low
modulation rate causes extremely inferior transmission rates for SUs. To
improve the SU transmission rate, this paper proposes a new mutualistic SR with
HAPC to explore the tradeoff between BC and AC in terms of power consumption
and transmission rate, enabling each SU to transmit signal via passive BC and
AC alternatively. We propose two problems to maximize the total rate of all SUs
under the fixed and dynamic SIC ordering, respectively. The fixed SIC
ordering-based problem is to jointly optimize the SUs' reflection coefficients,
the transmit power of each SU during AC, and the time allocation for each SU
during BC and AC, subject to the energy causality constraint and the PT's
transmission rate gain constraint. In addition to pondering the constraints
involved in the fixed SIC ordering-based problem, the dynamic SIC
ordering-based problem, which is a mixed integer programming one, further
considers the SIC ordering constraint. The above two problems are solved by our
proposed SCA-based and BCD-based iterative algorithms, respectively. Simulation
results demonstrate that: 1) the proposed mutualistic SR system outperforms
traditional designs in terms of the rates achieved by SUs under the same
constraints; 2) the total rate of all SUs under the dynamic SIC ordering is
larger than that of the fixed one when the PT's minimum rate gain is high, and
becomes nearly identical when the PT's minimum rate gain is low.

</details>


### [30] [Joint Scheduling and Multiflow Maximization in Wireless Networks](https://arxiv.org/abs/2509.14582)
*Yanxiao Liu,Shenghao Yang,Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文研究6G移动网络中的最大多流问题，提出了一种高效算法，能够在不需要整个调度速率区域的情况下直接求解准确的最优解，充分利用网络编码咄传播延迟来提高网络性能。


<details>
  <summary>Details</summary>
Motivation: 随着6G移动网络的发展，需要整合大量多维平台设备，因此必须深入理解大规模网络的理论极限。传统方法在求解最大多流问题时需要先计算调度速率区域，而这在大型网络中是NP难问题，计算复杂度极高。

Method: 提出了一种高效算法，能够联合计算调度速率区域并解决最大多流问题，直接输出最优值而无需整个调度速率区域。算法在有限迭代次数内进行，采用图形框架来处理传播延迟较大的场景。

Result: 理论证明了算法总是能够在有限迭代次数内输出最优解。模拟实验结果显示，该方法在各种情况下都显著优于传统方法。算法适用于最一般的多源多汇网络场景，包括多播问题。

Conclusion: 该研究为6G大规模网络提供了一种高效的准确最优解决方案，能够充分利用网络编码咄传播延迟来提升网络性能，对于水下网络等传播延迟较大的环境也有良好的扩展性。

Abstract: Towards the development of 6G mobile networks, it is promising to integrate a
large number of devices from multi-dimensional platforms, and it is crucial to
have a solid understanding of the theoretical limits of large-scale networks.
We revisit a fundamental problem at the heart of network communication theory:
the maximum multiflow (MMF) problem in multi-hop networks, with network coding
performed at intermediate nodes. To derive the exact-optimal solution to the
MMF problem (as opposed to approximations), conventional methods usually
involve two steps: first calculate the scheduling rate region, and then find
the maximum multiflow that can be supported by the achievable link rates.
However, the NP-hardness of the scheduling part makes solving the MMF problem
in large networks computationally prohibitive. In this paper, while still
focusing on the exact-optimal solution, we provide efficient algorithms that
can jointly calculate the scheduling rate region and solve the MMF problem,
thereby outputting optimal values without requiring the entire scheduling rate
region. We theoretically prove that our algorithms always output optimal
solutions in a finite number of iterations, and we use various simulation
results to demonstrate our advantages over conventional approaches. Our
framework is applicable to the most general scenario in multi-source multi-sink
networks: the multiple multicast problem with network coding. Moreover, by
employing a graphical framework, we show that our algorithm can be extended to
scenarios where propagation delays are large (e.g., underwater networks), in
which recent studies have shown that the scheduling rate region can be
significantly improved by utilizing such delays.

</details>


### [31] [Inference of unknown syndrome values in the implementation of the Berlekamp-Massey-Sakata algorithm](https://arxiv.org/abs/2509.14835)
*J. J. Bernal,J. J. Simón*

Main category: cs.IT

TL;DR: 研究代数几何码中实现Berlekamp-Massey-Sakata算法所需的缺失校验子值的确定问题，并将结果应用于解决阿贝尔码中的校验子校正


<details>
  <summary>Details</summary>
Motivation: 在代数几何码中实现Feng-Rao多数投票算法需要完整的校验子值，但实际中可能存在缺失的校验子值，需要找到有效的方法来确定这些缺失值

Method: 研究确定缺失校验子值的方法，以支持Berlekamp-Massey-Sakata算法的实现，并将该方法应用于阿贝尔码的校验子校正问题

Result: 提出了确定缺失校验子值的解决方案，能够有效支持Feng-Rao多数投票算法的实现，并成功应用于阿贝尔码的校验子校正

Conclusion: 该方法为解决代数几何码中校验子缺失问题提供了有效途径，特别适用于阿贝尔码的校验子校正应用

Abstract: We study the problem of finding those missing syndrome values that are needed
to implment the Berlekamp-Massey-Sakata algorithm as the Feng-Rao Majority
Voting for algebraic geometric codes. We apply our results to solve syndrome
correction in abelian codes.

</details>


### [32] [Beam Squint Assisted Joint Angle-Distance Localization for Near-Field Communications](https://arxiv.org/abs/2509.14850)
*Aibiao Zhang,Weizheng Zhang,Chiya Zhang*

Main category: cs.IT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the advent of extremely large-scale MIMO (XL-MIMO), mmWave/THz bands and
ultra-wideband transmission, future 6G systems demand real-time positioning
with centimeter or even millimeter level accuracy. This paper addresses the
pronounced near-field beam squint problem caused by phase shifter based
beamforming in wideband near-field scenarios and proposes a beam squint
assisted joint angle-distance localization scheme. The key idea is to employ
true-time-delay (TTD) units together with phase shifters (PS) to synthesize a
controllable joint angle-distance (JAD) trajectory that establishes a unique
mapping between subcarriers and spatial locations, enabling single scan
acquisition of target angle and range. To implement this paradigm efficiently,
we design a coarse to fine two stage estimator: a low complexity coarse stage
based on subcarrier power peaks for user separation and candidate region
selection, followed by a local high resolution refinement stage that applies
spatial smoothing and near-field multiple signal classification (MUSIC) over
multiple subcarriers and fuses the resulting spectra by geometric averaging to
suppress spurious peaks. We theoretically prove the correctness and uniqueness
of the MUSIC spatial spectrum peak under the proposed near-field steering
model, and derive the Cram\'er-Rao lower bound (CRLB) for joint angle-distance
estimation. Simulation results in single and multi-user scenarios validate that
the proposed method achieves very high accuracy and robustness, significantly
outperforming conventional two-step approaches, and is promising for practical
6G sensing and localization deployments.

</details>


### [33] [On Finite-Blocklength Noisy Classical-Quantum Channel Coding With Amplitude Damping Errors](https://arxiv.org/abs/2509.14852)
*Tamás Havas,Hsuan-Yin Lin,Eirik Rosnes,Ching-Yi Lai*

Main category: cs.IT

TL;DR: 在有限块长下，朴素的无编码方法无法在量子振幅阻尼信道中获得优势，需要结合经典纠错码和量子输入态的复杂编码策略才能实现量子性能增益


<details>
  <summary>Details</summary>
Motivation: 研究有限块长下经典-量子信道编码在量子振幅阻尼信道中的实际性能，探索如何通过量子输出来可靠传输经典信息

Method: 分析比较朴素无编码方法和结合经典纠错码与量子输入态的复杂编码策略在ADC信道中的性能表现

Result: 发现对于任何有限块长，朴素方法都无法提供优于ADC信道的优势，而复杂编码策略对于在有限块长下实现量子性能增益至关重要

Conclusion: 在量子振幅阻尼信道中实现有限块长下的量子优势需要精心设计的编码方案，而非简单的无编码方法

Abstract: We investigate practical finite-blocklength classical-quantum channel coding
over the quantum amplitude damping channel (ADC), aiming to transmit classical
information reliably through quantum outputs. Our findings indicate that for
any finite blocklength, a naive (uncoded) approach fails to offer any advantage
over the ADC. Instead, sophisticated encoding strategies that leverage both
classical error-correcting codes and quantum input states are crucial for
realizing quantum performance gains at finite blocklengths.

</details>


### [34] [Four classes of LCD codes from (*)-(L,P)-twisted generalized Reed-Solomon codes](https://arxiv.org/abs/2509.14878)
*Zhonghao Liang,Qunying Liao*

Main category: cs.IT

TL;DR: 本文统一了先前关于LCD MDS码的构造方法，定义了(*)-(L,P)-TGRS码并给出了其奇偶校验矩阵，构造了四类LCD码


<details>
  <summary>Details</summary>
Motivation: 统一Yue等人和Wu等人关于LCD MDS码的构造方法，提供更通用的框架

Method: 定义(*)-(L,P)-TGRS码，推导其奇偶校验矩阵，基于此构造四类LCD码

Result: 成功统一了现有构造方法，提出了新的(*)-(L,P)-TGRS码定义，并构造了四类LCD码

Conclusion: 所提出的(*)-(L,P)-TGRS码框架能够统一现有的LCD MDS码构造方法，并扩展了可能的构造类别

Abstract: It's well-known that maximum distance separable codes (in short, MDS) and
linear complementary dual (in short, LCD) codes are very important in coding
theory and practice. In 2023, Yue et al. [25] constructed three classes of LCD
MDS codes via (*)-TGRS codes. Recently, Wu et al. [27] generalized the results
given by Yue et al. and constructed several classes of LCD MDS codes. In this
paper, we unify their constructions by defining the (*)-(L,P)-twisted
generalized Reed-Solomon (in short, (*)-(L,P)-TGRS) code, give the parity-check
matrix of (*)-(L,P)-TGRS codes, and then construct four classes of LCD codes.
Finally, some corresponding examples are given.

</details>


### [35] [Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space](https://arxiv.org/abs/2509.14905)
*Wenyan Ma,Lipeng Zhu,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于可移动天线(MA)的新型无线感知系统，通过优化天线轨迹来显著提高角度估计性能，在1D和2D情况下都实现了比固定天线更优的估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线(FPA)感知系统在角度估计性能上有限，需要开发更高性能的无线感知方案。可移动天线通过轨迹优化可以根本改善角度估计的准确性。

Method: 推导了角度到达角(AoA)估计的Cramer-Rao界(CRB)，并作为天线轨迹函数。在1D情况下求解了全局最优轨迹；在2D情况下设计了交替优化算法来实现最小最大CRB的本地最优轨迹。

Result: 数值结果显示，提出的1D/2D MA感知方案在CRB和实际AoA估计MSE方面都显著优于传统FPA感知。设计的MA轨迹在角度域具有低相关性，有效提高了角度分辨率。

Conclusion: 可移动天线通过轨迹优化可以实现更高精度的角度估计，为无线感知系统提供了一种有效的性能提升方案。

Abstract: In this paper, we present a new wireless sensing system utilizing a movable
antenna (MA) that continuously moves and receives sensing signals to enhance
sensing performance over the conventional fixed-position antenna (FPA) sensing.
We show that the angle estimation performance is fundamentally determined by
the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square
error (MSE) for angle-of-arrival (AoA) estimation as a function of the
trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna
movement. For the 1D case, a globally optimal trajectory that minimizes the CRB
is derived in closed form. Notably, the resulting CRB decreases cubically with
sensing time in the time-constrained regime, whereas it decreases linearly with
sensing time and quadratically with the movement line segment's length in the
space-constrained regime. For the 2D case, we aim to achieve the minimum of
maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the
horizontal and vertical axes. To this end, we design an efficient alternating
optimization algorithm that iteratively updates the MA's horizontal or vertical
coordinates with the other being fixed, yielding a locally optimal trajectory.
Numerical results show that the proposed 1D/2D MA-based sensing schemes
significantly reduce both the CRB and actual AoA estimation MSE compared to
conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as
well as various benchmark MA trajectories. Moreover, it is revealed that the
steering vectors of our designed 1D/2D MA trajectories have low correlation in
the angular domain, thereby effectively increasing the angular resolution for
achieving higher AoA estimation accuracy.

</details>


### [36] [Indoor Fluid Antenna Systems Enabled by Layout-Specific Modeling and Group Relative Policy Optimization](https://arxiv.org/abs/2509.15006)
*Tong Zhang,Qianren Li,Shuai Wang,Wanli Ni,Jiliang Zhang,Rui Wang,Kai-Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 室内流体天线系统的通道建模与聚合优化，提出组相对策略优化算法，计算时间减少83.3%，综合性能显著提升


<details>
  <summary>Details</summary>
Motivation: 室内环境中信号传播因结构障碍和复杂多径反射而严重恶化，需要动态优化港道条件和减轻多径衰落

Method: 提出布局特定通道模型和新的组相对策略优化(GRPO)算法，用于天线位置、放强形成和功率分配的聚合优化

Result: 计算时间比Sionna模型减少83.3%，RMSE提升3dB；GRPO算法在总速率上超过PPO等基准方法，计算资源仅需PPO的49.2%

Conclusion: 流体天线系统通过动态优化天线位置能够有效改善室内通信性能，GRPO算法在保持高性能的同时显著降低计算复杂度

Abstract: The fluid antenna system (FAS) revolutionizes wireless communications by
employing position-flexible antennas that dynamically optimize channel
conditions and mitigate multipath fading. This innovation is particularly
valuable in indoor environments, where signal propagation is severely degraded
due to structural obstructions and complex multipath reflections. In this
paper, we study the channel modeling and joint optimization of antenna
positioning, beamforming, and power allocation for indoor FAS. In particular,
we propose, for the first time, a layout-specific channel model and a novel
group relative policy optimization (GRPO) algorithm for indoor FAS. Compared to
the state-of-the-art Sionna model, our approach achieves an $83.3\%$ reduction
in computation time with an approximately $3$ dB increase in root-mean-square
error (RMSE). When simplified to a two-ray model, our channel model enables a
closed-form solution for the optimal antenna position, achieving near-optimal
performance. {For the joint optimization problem, the proposed GRPO algorithm
outperforms proximal policy optimization (PPO) and other baselines in sum-rate,
while requiring only 49.2\% computational resources of PPO, due to its
group-based advantage estimation.} Simulation results reveal that increasing
either the group size or trajectory length in GRPO does not yield significant
improvements in sum-rate, suggesting that these parameters can be selected
conservatively without sacrificing performance.

</details>


### [37] [Version Age of Information with Contact Mobility in Gossip Networks](https://arxiv.org/abs/2509.15184)
*Irtiza Hasan,Ahmed Arafa*

Main category: cs.IT

TL;DR: 该论文研究移动性对gossip网络中信息新鲜度的影响，使用版本年龄信息(VAoI)作为度量指标，通过随机混合系统(SHS)框架分析不同拓扑结构下的性能表现，并优化移动成本与信息新鲜度的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究节点移动性如何影响gossip网络中的信息传播效率，特别是在信息时效性要求高的场景下，探索移动性对网络信息新鲜度的提升作用。

Method: 采用随机混合系统(SHS)框架分析不同网络拓扑结构下的信息传播过程，通过数学建模分析平均版本年龄的缩放特性，并建立优化问题来平衡版本年龄和移动成本。

Result: 研究表明接触移动性显著改善了网络两端（断开连接和完全连接）的信息新鲜度，理论分析和仿真验证都显示移动性能够有效降低平均版本年龄。

Conclusion: 接触移动性通过优化移动成本可以显著提升网络中的信息新鲜度，为移动gossip网络的设计提供了理论依据和优化方法。

Abstract: A gossip network is considered in which a source node updates its status
while other nodes in the network aim at keeping track of it as it varies over
time. Information gets disseminated by the source sending status updates to the
nodes, and the nodes gossiping with each other. In addition, the nodes in the
network are mobile, and can move to other nodes to get information, which we
term contact mobility. The goal for the nodes is to remain as fresh as
possible, i.e., to have the same information as the source's. To evaluate the
freshness of information, we use the Version Age-of-Information (VAoI) metric,
defined as the difference between the version of information available at a
given node and that at the source. We analyze the effect of contact mobility on
information dissemination in the gossip network using a Stochastic Hybrid
System (SHS) framework for different topologies and mobility scalings with
increasing number of nodes. It is shown that with the presence of contact
mobility the freshness of the network improves in both ends of the network
connectivity spectrum: disconnected and fully connected gossip networks. We
mathematically analyze the average version age scalings and validate our
theoretical results via simulations. Finally, we incorporate the cost of
mobility for the network by formulating and solving an optimization problem
that minimizes a weighted sum of version age and mobility cost. Our results
show that contact mobility, with optimized mobility cost, improves the average
version age in the network.

</details>


### [38] [Improved Constructions and Lower Bounds for Maximally Recoverable Grid Codes](https://arxiv.org/abs/2509.15013)
*Joshua Brakensiek,Manik Dhar,Sivakanth Gopi*

Main category: cs.IT

TL;DR: 本文研究了最大可恢复网格码，针对m×n网格拓扑结构，在m和h为常数、n增长的实用场景下，提出了多个多项式字段大小的显式构造，并给出了新的字段大小下界。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注m=n的情况，此时显式构造需要指数级字段大小。本文受实际应用驱动，研究m和h为常数、n增长的实用场景，旨在找到多项式字段大小的构造方案。

Method: 研究m×n网格拓扑结构，每行每列有一个奇偶校验，加上h≥1个全局奇偶校验。在m和h为常数、n增长的设定下，提供多个新的显式构造方法。

Result: 提出了多个字段大小为n的多项式的显式构造方案，这些构造在实用场景下具有更好的可扩展性。同时给出了新的字段大小下界结果。

Conclusion: 本文在实用参数设置下为最大可恢复网格码提供了多项式字段大小的显式构造，填补了先前研究的空白，并建立了相应的理论下界。

Abstract: In this paper, we continue the study of Maximally Recoverable (MR) Grid Codes
initiated by Gopalan et al. [SODA 2017]. More precisely, we study codes over an
$m \times n$ grid topology with one parity check per row and column of the grid
along with $h \ge 1$ global parity checks. Previous works have largely focused
on the setting in which $m = n$, where explicit constructions require field
size which is exponential in $n$. Motivated by practical applications, we
consider the regime in which $m,h$ are constants and $n$ is growing. In this
setting, we provide a number of new explicit constructions whose field size is
polynomial in $n$. We further complement these results with new field size
lower bounds.

</details>


### [39] [Integrated Sensing and Communication for Vehicular Networks: A Rate-Distortion Fundamental Limits of State Estimator](https://arxiv.org/abs/2509.15025)
*Lugaoze Feng,Guocheng Lv,Xunan Li,Ye Jin*

Main category: cs.IT

TL;DR: 本文建立了状态相关无记忆通道(SDMC)模型的速率-失真函数，提出了改进的Blahut-Arimoto算法求解该函数，并首次定义了统一通信和感知的容量-速率-失真权衡区域。


<details>
  <summary>Details</summary>
Motivation: 现有工作中感知性能常被忽视，需要为车联网ISAC系统建立具有明确操作意义的信息论基础框架。

Method: 基于标准信息论原理建立速率-失真函数，提出改进的Blahut-Arimoto算法并证明其收敛性，定义容量-速率-失真权衡区域。

Result: 数值评估了容量-速率-失真区域，证明了在某些信道中编码对估计速率的益处。

Conclusion: 首次在单一优化框架内统一了通信和感知的信息论结果，为ISAC系统提供了理论基础和算法支持。

Abstract: The state-dependent memoryless channel (SDMC) is employed to model the
integrated sensing and communication (ISAC) system for connected vehicular
networks, where the transmitter conveys messages to the receiver while
simultaneously estimating the state parameter of interest via the received echo
signals. However, the performance of sensing has often been neglected in
existing works. To address this gap, we establish the rate-distortion function
for sensing performance in the SDMC model, which is defined based on standard
information-theoretic principles to ensure clear operational meaning. In
addition, we propose a modified Blahut-Arimoto type algorithm for solving the
rate-distortion function and provide convergence proofs for the algorithm. We
further define the capacity-rate-distortion tradeoff region, which, for the
first time, unifies information-theoretic results for communication and sensing
within a single optimization framework. Finally, we numerically evaluate the
capacity-rate-distortion region and demonstrate the benefit of coding in terms
of estimation rate for certain channels.

</details>


### [40] [Distributed Batch Matrix Multiplication: Trade-Offs in Download Rate, Randomness, and Privacy](https://arxiv.org/abs/2509.15047)
*Amirhosein Morteza,Remi A. Chou*

Main category: cs.IT

TL;DR: 本文研究分布式批量矩阵乘法中通信速率与隐私保护的权衡，重点关注矩阵A的隐私保护与从最快服务器获取结果的效率优化


<details>
  <summary>Details</summary>
Motivation: 随着分布式计算和云服务的普及，如何在高效执行矩阵乘法运算的同时保护敏感数据隐私成为重要问题。特别是当矩阵B公开而矩阵A需要保密时，需要设计既能确保隐私又能优化通信效率的方案

Method: 采用信息论方法分析分布式矩阵乘法系统，设置隐私参数α控制信息泄露比例，研究不同服务器数量k和合谋服务器数量ℓ下的最优通信速率，并分析编码器所需局部随机性与隐私保护的关系

Result: 建立了通信速率与隐私泄露之间的线性关系，确定了方形矩阵情况下的最优权衡边界，发现信息泄露与通信速率之间存在明确的数学关系

Conclusion: 该研究为分布式矩阵计算提供了理论框架，证明了在特定隐私约束下存在最优的通信效率方案，为实际分布式系统中的隐私保护设计提供了理论基础

Abstract: We study the trade-off between communication rate and privacy for distributed
batch matrix multiplication of two independent sequences of matrices
$\mathbf{A}$ and $\mathbf{B}$ with uniformly distributed entries. In our
setting, $\mathbf{B}$ is publicly accessible by all the servers while
$\mathbf{A}$ must remain private. A user is interested in evaluating the
product $\mathbf{AB}$ with the responses from the $k$ fastest servers. For a
given parameter $\alpha \in [0, 1]$, our privacy constraint must ensure that
any set of $\ell$ colluding servers cannot learn more than a fraction $\alpha$
of $\mathbf{A}$. Additionally, we study the trade-off between the amount of
local randomness needed at the encoder and privacy. Finally, we establish the
optimal trade-offs when the matrices are square and identify a linear
relationship between information leakage and communication rate.

</details>
