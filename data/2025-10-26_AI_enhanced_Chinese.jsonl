{"id": "2510.20179", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20179", "abs": "https://arxiv.org/abs/2510.20179", "authors": ["Tadashi Wadayama"], "title": "Information Gradient for Nonlinear Gaussian Channel with Applications to Task-Oriented Communication", "comment": null, "summary": "We propose a gradient-based framework for optimizing parametric nonlinear\nGaussian channels via mutual information maximization. Leveraging the\nscore-to-Fisher bridge (SFB) methodology, we derive a computationally tractable\nformula for the information gradient that is the gradient of mutual information\nwith respect to the parameters of the nonlinear front-end. Our formula\nexpresses this gradient in terms of two key components: the score function of\nthe marginal output distribution, which can be learned via denoising score\nmatching (DSM), and the Jacobian of the front-end function, which is handled\nefficiently using the vector-Jacobian product (VJP) within automatic\ndifferentiation frameworks. This enables practical parameter optimization\nthrough gradient ascent. Furthermore, we extend this framework to task-oriented\nscenarios, deriving gradients for both task-specific mutual information, where\na task variable depends on the channel input, and the information bottleneck\n(IB) objective. A key advantage of our approach is that it facilitates\nend-to-end optimization of the nonlinear front-end without requiring explicit\ncomputation on the output distribution. Extensive experimental validation\nconfirms the correctness of our information gradient formula against analytical\nsolutions and demonstrates its effectiveness in optimizing both linear and\nnonlinear channels toward their objectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u68af\u5ea6\u7684\u53c2\u6570\u5316\u975e\u7ebf\u6027\u9ad8\u65af\u4fe1\u9053\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f\u6700\u5927\u5316\u5b9e\u73b0\u3002\u5229\u7528SFB\u65b9\u6cd5\u63a8\u5bfc\u51fa\u8ba1\u7b97\u53ef\u884c\u7684\u4fe1\u606f\u68af\u5ea6\u516c\u5f0f\uff0c\u5305\u542b\u8f93\u51fa\u5206\u5e03\u7684\u5f97\u5206\u51fd\u6570\u548c\u524d\u7aef\u51fd\u6570\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u975e\u7ebf\u6027\u9ad8\u65af\u4fe1\u9053\u4e2d\u4e92\u4fe1\u606f\u6700\u5927\u5316\u53c2\u6570\u4f18\u5316\u7684\u8ba1\u7b97\u96be\u9898\uff0c\u5f00\u53d1\u4e00\u4e2a\u5b9e\u7528\u7684\u68af\u5ea6\u6846\u67b6\uff0c\u907f\u514d\u5bf9\u8f93\u51fa\u5206\u5e03\u8fdb\u884c\u663e\u5f0f\u8ba1\u7b97\u3002", "method": "\u4f7f\u7528SFB\u65b9\u6cd5\u63a8\u5bfc\u4fe1\u606f\u68af\u5ea6\u516c\u5f0f\uff0c\u901a\u8fc7DSM\u5b66\u4e60\u8fb9\u9645\u8f93\u51fa\u5206\u5e03\u7684\u5f97\u5206\u51fd\u6570\uff0c\u5229\u7528VJP\u9ad8\u6548\u5904\u7406\u524d\u7aef\u51fd\u6570\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u5b9e\u73b0\u68af\u5ea6\u4e0a\u5347\u7684\u53c2\u6570\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4fe1\u606f\u68af\u5ea6\u516c\u5f0f\u7684\u6b63\u786e\u6027\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u4fe1\u9053\u8fbe\u5230\u76ee\u6807\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u975e\u7ebf\u6027\u524d\u7aef\u7684\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u65e0\u9700\u663e\u5f0f\u8ba1\u7b97\u8f93\u51fa\u5206\u5e03\uff0c\u5728\u4efb\u52a1\u5bfc\u5411\u573a\u666f\u548c\u4fe1\u606f\u74f6\u9888\u76ee\u6807\u4e2d\u5177\u6709\u826f\u597d\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.20241", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20241", "abs": "https://arxiv.org/abs/2510.20241", "authors": ["Xiang Li", "Cheuk Ting Li"], "title": "New Second-Order Achievability Bounds for Coding with Side Information via Type Deviation Convergence", "comment": "31 pages, 3 figures", "summary": "We propose a framework for second-order achievability, called type deviation\nconvergence, that is generally applicable to settings in network information\ntheory, and is especially suitable for lossy source coding and channel coding\nwith cost. We give a second-order achievability bound for lossy source coding\nwith side information at the decoder (Wyner-Ziv problem) that improves upon all\nknown bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and\nLi-Anantharam). We also give second-order achievability bounds for lossy\ncompression where side information may be absent (Heegard-Berger problem) and\nchannels with noncausal state information at the encoder and cost constraint\n(Gelfand-Pinsker problem with cost) that improve upon previous bounds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u7f51\u7edc\u4fe1\u606f\u8bba\u7684\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u6846\u67b6\u2014\u2014\u7c7b\u578b\u504f\u5dee\u6536\u655b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6709\u635f\u6e90\u7f16\u7801\u548c\u5e26\u6210\u672c\u7684\u4fe1\u9053\u7f16\u7801\uff0c\u6539\u8fdb\u4e86\u591a\u4e2a\u7ecf\u5178\u95ee\u9898\u7684\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u754c\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u4fe1\u606f\u8bba\u4e2d\u7684\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u5206\u6790\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u4e14\u80fd\u63d0\u4f9b\u66f4\u7d27\u754c\u7684\u6846\u67b6\u6765\u5904\u7406\u6709\u635f\u6e90\u7f16\u7801\u548c\u5e26\u6210\u672c\u7684\u4fe1\u9053\u7f16\u7801\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7c7b\u578b\u504f\u5dee\u6536\u655b\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u6982\u7387\u5206\u5e03\u7684\u6536\u655b\u7279\u6027\u6765\u63a8\u5bfc\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u754c\uff0c\u5e94\u7528\u4e8eWyner-Ziv\u95ee\u9898\u3001Heegard-Berger\u95ee\u9898\u548cGelfand-Pinsker\u95ee\u9898\u3002", "result": "\u4e3aWyner-Ziv\u95ee\u9898\u63d0\u4f9b\u4e86\u4f18\u4e8e\u6240\u6709\u5df2\u77e5\u754c\u7684\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u754c\uff0c\u540c\u65f6\u4e3aHeegard-Berger\u95ee\u9898\u548c\u5e26\u6210\u672c\u7684Gelfand-Pinsker\u95ee\u9898\u6539\u8fdb\u4e86\u73b0\u6709\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u754c\u3002", "conclusion": "\u7c7b\u578b\u504f\u5dee\u6536\u655b\u6846\u67b6\u662f\u4e00\u4e2a\u901a\u7528\u4e14\u6709\u6548\u7684\u5de5\u5177\uff0c\u80fd\u591f\u663e\u8457\u6539\u8fdb\u7f51\u7edc\u4fe1\u606f\u8bba\u4e2d\u591a\u4e2a\u91cd\u8981\u95ee\u9898\u7684\u7b2c\u4e8c\u9636\u53ef\u8fbe\u6027\u5206\u6790\u7ed3\u679c\u3002"}}
{"id": "2510.20277", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20277", "abs": "https://arxiv.org/abs/2510.20277", "authors": ["Wenli Yuan", "Kan Yu", "Xiaowu Liu", "Kaixuan Li", "Qixun Zhang", "Zhiyong Feng"], "title": "A Location-Aware Hybrid Deep Learning Framework for Dynamic Near-Far Field Channel Estimation in Low-Altitude UAV Communications", "comment": null, "summary": "In low altitude UAV communications, accurate channel estimation remains\nchallenging due to the dynamic nature of air to ground links, exacerbated by\nhigh node mobility and the use of large scale antenna arrays, which introduce\nhybrid near and far field propagation conditions. While conventional estimation\nmethods rely on far field assumptions, they fail to capture the intricate\nchannel variations in near-field scenarios and overlook valuable geometric\npriors such as real-time transceiver positions. To overcome these limitations,\nthis paper introduces a unified channel estimation framework based on a\nlocation aware hybrid deep learning architecture. The proposed model\nsynergistically combines convolutional neural networks (CNNs) for spatial\nfeature extraction, bidirectional long short term memory (BiLSTM) networks for\nmodeling temporal evolution, and a multihead self attention mechanism to\nenhance focus on discriminative channel components. Furthermore, real-time\ntransmitter and receiver locations are embedded as geometric priors, improving\nsensitivity to distance under near field spherical wavefronts and boosting\nmodel generalization. Extensive simulations validate the effectiveness of the\nproposed approach, showing that it outperforms existing benchmarks by a\nsignificant margin, achieving at least a 30.25% reduction in normalized mean\nsquare error (NMSE) on average.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f4d\u7f6e\u611f\u77e5\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7684\u7edf\u4e00\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4f4e\u7a7a\u65e0\u4eba\u673a\u901a\u4fe1\u4e2d\u6df7\u5408\u8fd1\u8fdc\u573a\u4f20\u64ad\u6761\u4ef6\u4e0b\u7684\u4fe1\u9053\u4f30\u8ba1\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8fdc\u573a\u5047\u8bbe\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u8fd1\u573a\u573a\u666f\u4e2d\u7684\u590d\u6742\u4fe1\u9053\u53d8\u5316\uff0c\u4e14\u5ffd\u7565\u4e86\u5b9e\u65f6\u6536\u53d1\u5668\u4f4d\u7f6e\u7b49\u6709\u4ef7\u503c\u7684\u51e0\u4f55\u5148\u9a8c\u4fe1\u606f\u3002", "method": "\u7ed3\u5408CNN\u8fdb\u884c\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u3001BiLSTM\u7f51\u7edc\u5efa\u6a21\u65f6\u95f4\u6f14\u5316\u3001\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u5bf9\u5224\u522b\u6027\u4fe1\u9053\u5206\u91cf\u7684\u5173\u6ce8\uff0c\u5e76\u5c06\u5b9e\u65f6\u6536\u53d1\u5668\u4f4d\u7f6e\u5d4c\u5165\u4f5c\u4e3a\u51e0\u4f55\u5148\u9a8c\u3002", "result": "\u5728\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee(NMSE)\u4e0a\u5e73\u5747\u81f3\u5c11\u51cf\u5c1130.25%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f4d\u7f6e\u611f\u77e5\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u4f4e\u7a7a\u65e0\u4eba\u673a\u901a\u4fe1\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6df7\u5408\u8fd1\u8fdc\u573a\u4f20\u64ad\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.20293", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20293", "abs": "https://arxiv.org/abs/2510.20293", "authors": ["Wenxu Wang", "Xiaowu Liu", "Wei Gong", "Yujia Zhao", "Kaixuan Li", "Qixun Zhang", "Zhiyong Feng", "Kan Yu"], "title": "Moving or Predicting? RoleAware-MAPP: A Role-Aware Transformer Framework for Movable Antenna Position Prediction to Secure Wireless Communications", "comment": null, "summary": "Movable antenna (MA) technology provides a promising avenue for actively\nshaping wireless channels through dynamic antenna positioning, thereby enabling\nelectromagnetic radiation reconstruction to enhance physical layer security\n(PLS). However, its practical deployment is hindered by two major challenges:\nthe high computational complexity of real time optimization and a critical\ntemporal mismatch between slow mechanical movement and rapid channel\nvariations. Although data driven methods have been introduced to alleviate\nonline optimization burdens, they are still constrained by suboptimal training\nlabels derived from conventional solvers or high sample complexity in\nreinforcement learning. More importantly, existing learning based approaches\noften overlook communication-specific domain knowledge, particularly the\nasymmetric roles and adversarial interactions between legitimate users and\neavesdroppers, which are fundamental to PLS. To address these issues, this\npaper reformulates the MA positioning problem as a predictive task and\nintroduces RoleAware-MAPP, a novel Transformer based framework that\nincorporates domain knowledge through three key components: role-aware\nembeddings that model user specific intentions, physics-informed semantic\nfeatures that encapsulate channel propagation characteristics, and a composite\nloss function that strategically prioritizes secrecy performance over mere\ngeometric accuracy. Extensive simulations under 3GPP-compliant scenarios show\nthat RoleAware-MAPP achieves an average secrecy rate of 0.3569 bps/Hz and a\nstrictly positive secrecy capacity of 81.52%, outperforming the strongest\nbaseline by 48.4% and 5.39 percentage points, respectively, while maintaining\nrobust performance across diverse user velocities and noise conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRoleAware-MAPP\u6846\u67b6\uff0c\u901a\u8fc7Transformer\u6a21\u578b\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u89e3\u51b3\u53ef\u79fb\u52a8\u5929\u7ebf\u5b9a\u4f4d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7269\u7406\u5c42\u5b89\u5168\u6027\u80fd\u3002", "motivation": "\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u9762\u4e34\u5b9e\u65f6\u4f18\u5316\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u673a\u68b0\u8fd0\u52a8\u4e0e\u4fe1\u9053\u53d8\u5316\u901f\u5ea6\u4e0d\u5339\u914d\u7684\u6311\u6218\uff0c\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5ffd\u89c6\u4e86\u901a\u4fe1\u9886\u57df\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5408\u6cd5\u7528\u6237\u4e0e\u7a83\u542c\u8005\u4e4b\u95f4\u7684\u975e\u5bf9\u79f0\u89d2\u8272\u548c\u5bf9\u6297\u6027\u4ea4\u4e92\u3002", "method": "\u5c06MA\u5b9a\u4f4d\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9884\u6d4b\u4efb\u52a1\uff0c\u63d0\u51faRoleAware-MAPP\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u89d2\u8272\u611f\u77e5\u5d4c\u5165\u3001\u7269\u7406\u4fe1\u606f\u8bed\u4e49\u7279\u5f81\u548c\u590d\u5408\u635f\u5931\u51fd\u6570\u3002", "result": "\u57283GPP\u517c\u5bb9\u573a\u666f\u4e0b\uff0cRoleAware-MAPP\u5b9e\u73b0\u4e860.3569 bps/Hz\u7684\u5e73\u5747\u4fdd\u5bc6\u901f\u7387\u548c81.52%\u7684\u4e25\u683c\u6b63\u4fdd\u5bc6\u5bb9\u91cf\uff0c\u5206\u522b\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u9ad848.4%\u548c5.39\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "RoleAware-MAPP\u901a\u8fc7\u6574\u5408\u9886\u57df\u77e5\u8bc6\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u79fb\u52a8\u5929\u7ebf\u5b9a\u4f4d\u95ee\u9898\uff0c\u5728\u591a\u79cd\u7528\u6237\u901f\u5ea6\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002"}}
{"id": "2510.19973", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19973", "abs": "https://arxiv.org/abs/2510.19973", "authors": ["Hatim Chergui", "Farhad Rezazadeh", "Merouane Debbah", "Christos Verikoukis"], "title": "A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks", "comment": "19 pages, 15 figures, 1 table", "summary": "The path to higher network autonomy in 6G lies beyond the mere optimization\nof key performance indicators (KPIs). While KPIs have enabled automation gains\nunder TM Forum Levels 1--3, they remain numerical abstractions that act only as\nproxies for the real essence of communication networks: seamless connectivity,\nfairness, adaptability, and resilience. True autonomy requires perceiving and\nreasoning over the network environment as it is. Such progress can be achieved\nthrough \\emph{agentic AI}, where large language model (LLM)-powered agents\nperceive multimodal telemetry, reason with memory, negotiate across domains,\nand act via APIs to achieve multi-objective goals. However, deploying such\nagents introduces the challenge of cognitive biases inherited from human\ndesign, which can distort reasoning, negotiation, tool use, and actuation.\nBetween neuroscience and AI, this paper provides a tutorial on a selection of\nwell-known biases, including their taxonomy, definition, mathematical\nformulation, emergence in telecom systems and the commonly impacted agentic\ncomponents. The tutorial also presents various mitigation strategies tailored\nto each type of bias. The article finally provides two practical use-cases,\nwhich tackle the emergence, impact and mitigation gain of some famous biases in\n6G inter-slice and cross-domain management. In particular, anchor\nrandomization, temporal decay and inflection bonus techniques are introduced to\nspecifically address anchoring, temporal and confirmation biases. This avoids\nthat agents stick to the initial high resource allocation proposal or decisions\nthat are recent and/or confirming a prior hypothesis. By grounding decisions in\na richer and fairer set of past experiences, the quality and bravery of the\nagentic agreements in the second use-case, for instance, are leading to $\\times\n5$ lower latency and around $40\\%$ higher energy saving.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e866G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u771f\u6b63\u81ea\u4e3b\u6027\u7684\u6311\u6218\uff0c\u63d0\u51fa\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53AI\u6765\u611f\u77e5\u591a\u6a21\u6001\u9065\u6d4b\u6570\u636e\u3001\u8fdb\u884c\u63a8\u7406\u548c\u8de8\u57df\u534f\u5546\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u4eba\u7c7b\u8bbe\u8ba1\u5e26\u6765\u7684\u8ba4\u77e5\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eKPI\u4f18\u5316\u7684\u65b9\u6cd5\u53ea\u80fd\u5b9e\u73b0\u6709\u9650\u81ea\u52a8\u5316\uff0c\u65e0\u6cd5\u8fbe\u5230\u771f\u6b63\u7684\u7f51\u7edc\u81ea\u4e3b\u6027\u3002\u9700\u8981\u8ba9AI\u667a\u80fd\u4f53\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u611f\u77e5\u548c\u7406\u89e3\u7f51\u7edc\u73af\u5883\uff0c\u4f46\u5fc5\u987b\u89e3\u51b3\u8ba4\u77e5\u504f\u89c1\u5bf9\u51b3\u7b56\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53AI\u67b6\u6784\uff0c\u80fd\u591f\u611f\u77e5\u591a\u6a21\u6001\u9065\u6d4b\u6570\u636e\u3001\u5229\u7528\u8bb0\u5fc6\u8fdb\u884c\u63a8\u7406\u3001\u8de8\u57df\u534f\u5546\u5e76\u901a\u8fc7API\u6267\u884c\u52a8\u4f5c\u3002\u9488\u5bf9\u8ba4\u77e5\u504f\u89c1\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u951a\u5b9a\u968f\u673a\u5316\u3001\u65f6\u95f4\u8870\u51cf\u548c\u62d0\u70b9\u5956\u52b1\u7b49\u6280\u672f\u6765\u7f13\u89e3\u7279\u5b9a\u504f\u89c1\u3002", "result": "\u57286G\u5207\u7247\u95f4\u548c\u8de8\u57df\u7ba1\u7406\u7684\u5b9e\u9645\u7528\u4f8b\u4e2d\uff0c\u901a\u8fc7\u504f\u89c1\u7f13\u89e3\u6280\u672f\uff0c\u667a\u80fd\u4f53\u51b3\u7b56\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff0c\u5728\u7b2c\u4e8c\u4e2a\u7528\u4f8b\u4e2d\u5b9e\u73b0\u4e865\u500d\u5ef6\u8fdf\u964d\u4f4e\u548c\u7ea640%\u7684\u80fd\u8017\u8282\u7701\u3002", "conclusion": "\u5b9e\u73b06G\u7f51\u7edc\u771f\u6b63\u81ea\u4e3b\u6027\u9700\u8981\u8d85\u8d8aKPI\u4f18\u5316\uff0c\u91c7\u7528\u667a\u80fd\u4f53AI\u65b9\u6cd5\uff0c\u4f46\u5fc5\u987b\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u548c\u7f13\u89e3\u8ba4\u77e5\u504f\u89c1\uff0c\u624d\u80fd\u786e\u4fdd\u51b3\u7b56\u7684\u8d28\u91cf\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2510.19836", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.19836", "abs": "https://arxiv.org/abs/2510.19836", "authors": ["Eliseo Curcio"], "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "comment": null, "summary": "Artificial intelligence and machine learning are increasingly used for\nforecasting, optimization, and policy design in the energy sector, yet no\nstandardized framework exists to evaluate whether these systems reason\ncorrectly. Current validation practices focus on predictive accuracy or\ncomputational efficiency, leaving the logical integrity of analytical\nconclusions untested. This study introduces the Analytical Reliability\nBenchmark (ARB), a reproducible framework that quantifies reasoning reliability\nin large language models applied to energy system analysis. The benchmark\nintegrates five submetrics: accuracy, reasoning reliability, uncertainty\ndiscipline, policy consistency, and transparency, and evaluates model\nperformance across deterministic, probabilistic, and epistemic scenarios using\nopen technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four\nfrontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were\ntested under identical factual and regulatory conditions. Results show that\nreasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5\nSonnet achieved consistent and policy-compliant reasoning (Analytical\nReliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate\nstability, and Llama 3 70B remained below professional thresholds. Statistical\nvalidation confirmed that these differences are significant and reproducible.\nThe ARB establishes the first quantitative method in the energy literature for\nverifying causal, probabilistic, and policy-driven reasoning in artificial\nintelligence systems, providing a reference framework for trustworthy and\ntransparent analytical applications in the global energy transition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6(ARB)\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u91cf\u5316\u80fd\u6e90\u7cfb\u7edf\u5206\u6790\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u53ef\u9760\u6027\u7684\u6807\u51c6\u5316\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u5b50\u6307\u6807\uff0c\u5e76\u5728\u56db\u79cd\u524d\u6cbf\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524dAI\u5728\u80fd\u6e90\u9886\u57df\u7684\u5e94\u7528\u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u7cfb\u7edf\u63a8\u7406\u7684\u6b63\u786e\u6027\uff0c\u73b0\u6709\u9a8c\u8bc1\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u6216\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u5ffd\u7565\u4e86\u5206\u6790\u7ed3\u8bba\u7684\u903b\u8f91\u5b8c\u6574\u6027\u3002", "method": "\u5f00\u53d1\u4e86ARB\u6846\u67b6\uff0c\u6574\u5408\u51c6\u786e\u6027\u3001\u63a8\u7406\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u7eaa\u5f8b\u3001\u653f\u7b56\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u4e94\u4e2a\u5b50\u6307\u6807\uff0c\u4f7f\u7528\u5f00\u653e\u6280\u672f\u7ecf\u6d4e\u6570\u636e\u96c6(NREL ATB 2024\u7b49)\uff0c\u5728\u56db\u79cd\u524d\u6cbf\u6a21\u578b(GPT-4/5\u3001Claude 4.5 Sonnet\u3001Gemini 2.5 Pro\u3001Llama 3 70B)\u4e0a\u8fdb\u884c\u786e\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u8ba4\u77e5\u6027\u573a\u666f\u6d4b\u8bd5\u3002", "result": "GPT-4/5\u548cClaude 4.5 Sonnet\u5b9e\u73b0\u4e86\u7a33\u5b9a\u4e14\u7b26\u5408\u653f\u7b56\u7684\u63a8\u7406(\u5206\u6790\u53ef\u9760\u6027\u6307\u6570\u5927\u4e8e90)\uff0cGemini 2.5 Pro\u8868\u73b0\u4e2d\u7b49\u7a33\u5b9a\uff0cLlama 3 70B\u672a\u8fbe\u5230\u4e13\u4e1a\u9608\u503c\u3002\u7edf\u8ba1\u9a8c\u8bc1\u786e\u8ba4\u8fd9\u4e9b\u5dee\u5f02\u663e\u8457\u4e14\u53ef\u91cd\u73b0\u3002", "conclusion": "ARB\u5efa\u7acb\u4e86\u80fd\u6e90\u6587\u732e\u4e2d\u9996\u4e2a\u91cf\u5316\u9a8c\u8bc1AI\u7cfb\u7edf\u4e2d\u56e0\u679c\u3001\u6982\u7387\u548c\u653f\u7b56\u9a71\u52a8\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u4e3a\u5168\u7403\u80fd\u6e90\u8f6c\u578b\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660e\u7684\u5206\u6790\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2510.19835", "categories": ["cs.AI", "cs.ET", "cs.NE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19835", "abs": "https://arxiv.org/abs/2510.19835", "authors": ["Max B. Zhao", "Fei Li"], "title": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "comment": "29 pages, 10 figures, accepted by Quantum Information & Computation\n  on August 6, 2025", "summary": "We propose and evaluate a quantum-inspired algorithm for solving Quadratic\nUnconstrained Binary Optimization (QUBO) problems, which are mathematically\nequivalent to finding ground states of Ising spin-glass Hamiltonians. The\nalgorithm employs Matrix Product States (MPS) to compactly represent large\nsuperpositions of spin configurations and utilizes a discrete driving schedule\nto guide the MPS toward the ground state. At each step, a driver Hamiltonian --\nincorporating a transverse magnetic field -- is combined with the problem\nHamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is\nupdated using the standard Density Matrix Renormalization Group (DMRG) method,\nwhich iteratively minimizes the system's energy via multiple sweeps across the\nspin chain. Despite its heuristic nature, the algorithm reliably identifies\nglobal minima, not merely near-optimal solutions, across diverse QUBO\ninstances. We first demonstrate its effectiveness on intermediate-level Sudoku\npuzzles from publicly available sources, involving over $200$ Ising spins with\nlong-range couplings dictated by constraint satisfaction. We then apply the\nalgorithm to MaxCut problems from the Biq Mac library, successfully solving\ninstances with up to $251$ nodes and $3,265$ edges. We discuss the advantages\nof this quantum-inspired approach, including its scalability, generalizability,\nand suitability for industrial-scale QUBO applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\uff0c\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\u548c\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u6765\u89e3\u51b3\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u5728Sudoku\u548cMaxCut\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5728\u6570\u5b66\u4e0a\u7b49\u540c\u4e8e\u5bfb\u627e\u4f0a\u8f9b\u81ea\u65cb\u73bb\u7483\u54c8\u5bc6\u987f\u91cf\u7684\u57fa\u6001\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\u7d27\u51d1\u8868\u793a\u81ea\u65cb\u6784\u578b\u7684\u5927\u53e0\u52a0\uff0c\u7ed3\u5408\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u5f15\u5bfcMPS\u5411\u57fa\u6001\u6f14\u5316\uff0c\u91c7\u7528\u5bc6\u5ea6\u77e9\u9635\u91cd\u6574\u5316\u7fa4\u65b9\u6cd5\u8fed\u4ee3\u6700\u5c0f\u5316\u7cfb\u7edf\u80fd\u91cf\u3002", "result": "\u7b97\u6cd5\u53ef\u9760\u5730\u8bc6\u522b\u5168\u5c40\u6700\u5c0f\u503c\u800c\u975e\u8fd1\u4f3c\u89e3\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5305\u542b200\u591a\u4e2a\u4f0a\u8f9b\u81ea\u65cb\u7684Sudoku\u8c1c\u9898\u548c\u5305\u542b251\u4e2a\u8282\u70b9\u30013265\u6761\u8fb9\u7684MaxCut\u95ee\u9898\u3002", "conclusion": "\u8be5\u91cf\u5b50\u542f\u53d1\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u901a\u7528\u6027\u548c\u9002\u7528\u4e8e\u5de5\u4e1a\u89c4\u6a21QUBO\u5e94\u7528\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.20307", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20307", "abs": "https://arxiv.org/abs/2510.20307", "authors": ["Anastasios Papazafeiropoulos", "Pandelis Kourtessis", "Dimitra I. Kaklamani", "Iakovos S. Venieris"], "title": "Ergodic Mutual Information and Outage Probability for SIM-Assisted Holographic MIMO Communications", "comment": "accepted in IEEE TVT, 13 pages, 9 figures", "summary": "Stacked intelligent metasurface (SIM) is a promising enabler for\nnext-generation high-capacity networks that exhibit better performance compared\nto its single-layer counterpart by means of just wave propagation. However, the\nstudy of ergodic mutual information (EMI) and outage probability for\nSIM-assisted multiple-input-multiple-output (MIMO) systems is not available in\nthe literature. To this end, we obtain the distribution of the MI by using\nlarge random matrix theory (RMT) tools. Next, we derive a tight closed-form\nexpression for the outage probability based on statistical channel state\ninformation (CSI). Moreover, we apply the gradient descent method for the\nminimization of the outage probability. Simulation results verify the\nanalytical results and provide fundamental insights such as the performance\nenhancements compared to conventional MIMO systems and the single-layer\ncounterpart. Notably the proposed optimization algorithm is faster than the\nalternating optimization (AO) benchmark by saving significant overhead.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762(SIM)\u8f85\u52a9MIMO\u7cfb\u7edf\u7684\u904d\u5386\u4e92\u4fe1\u606f\u548c\u4e2d\u65ad\u6982\u7387\uff0c\u4f7f\u7528\u5927\u968f\u673a\u77e9\u9635\u7406\u8bba\u63a8\u5bfc\u4e86\u4e92\u4fe1\u606f\u5206\u5e03\uff0c\u5e76\u57fa\u4e8e\u7edf\u8ba1CSI\u63d0\u51fa\u4e86\u4e2d\u65ad\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u548c\u4f18\u5316\u7b97\u6cd5\u3002", "motivation": "\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762\u76f8\u6bd4\u5355\u5c42\u8d85\u8868\u9762\u80fd\u901a\u8fc7\u6ce2\u4f20\u64ad\u63d0\u4f9b\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4f46\u6587\u732e\u4e2d\u7f3a\u4e4f\u5bf9SIM\u8f85\u52a9MIMO\u7cfb\u7edf\u7684\u904d\u5386\u4e92\u4fe1\u606f\u548c\u4e2d\u65ad\u6982\u7387\u7684\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u5927\u968f\u673a\u77e9\u9635\u7406\u8bba\u5de5\u5177\u83b7\u5f97\u4e92\u4fe1\u606f\u5206\u5e03\uff0c\u63a8\u5bfc\u57fa\u4e8e\u7edf\u8ba1CSI\u7684\u4e2d\u65ad\u6982\u7387\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u5e94\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u6700\u5c0f\u5316\u4e2d\u65ad\u6982\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\uff0c\u663e\u793a\u76f8\u6bd4\u4f20\u7edfMIMO\u7cfb\u7edf\u548c\u5355\u5c42\u8d85\u8868\u9762\u6709\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u6240\u63d0\u4f18\u5316\u7b97\u6cd5\u6bd4\u4ea4\u66ff\u4f18\u5316\u57fa\u51c6\u66f4\u5feb\uff0c\u8282\u7701\u4e86\u663e\u8457\u5f00\u9500\u3002", "conclusion": "\u672c\u6587\u4e3aSIM\u8f85\u52a9MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u4f18\u5316\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u548c\u9ad8\u6548\u7387\u3002"}}
{"id": "2510.20297", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.20297", "abs": "https://arxiv.org/abs/2510.20297", "authors": ["Xiao Song", "John Heidemann"], "title": "Rediscovering Recurring Routing Results", "comment": null, "summary": "Routing is central to networking performance, including: (1) latency in\nanycast services and websites served from multiple locations,(2) networking\nexpenses and throughput in multi-homed enterprises, (3) the ability to keep\ntraffic domestic when considering data sovereignty. However, understanding and\nmanaging how routing affects these services is challenging. Operators use\nTraffic Engineering (TE) with BGP to optimize network performance, but what\nthey get is the result of all BGP policies throughout the Internet, not just\ntheir local choices. Our paper proposes Fenrir, a new system to rediscover\nrecurring routing results. Fenrir can discover changes in network routing, even\nwhen it happens multiple hops away from the observer. Fenrir also provides new\nmethods to quantify the degree of routing change, and to identify routing\n\"modes\" that may reappear. Second, we show that Fenrir can be applied to many\ndifferent problems: we use five instances of three different types of systems\nto illustrate the generalization: anycast catchments showing in a root DNS\nservice, route optimization for two multi-homed enterprises, and website\nselection for two of the top-10 web services. Each type requires different\ntypes of active measurements, data cleaning and weighting. We demonstrate\nFenrir's methods of detecting and quantifying change are helpful because they\nall face similar operational questions: How much effect did traffic engineering\nhave? Did a third-party change alter my routing? In either case, is the current\nrouting new, or is it like a routing mode I saw before?", "AI": {"tldr": "Fenrir\u662f\u4e00\u4e2a\u65b0\u7684\u8def\u7531\u5206\u6790\u7cfb\u7edf\uff0c\u80fd\u591f\u91cd\u65b0\u53d1\u73b0\u91cd\u590d\u51fa\u73b0\u7684\u8def\u7531\u7ed3\u679c\uff0c\u68c0\u6d4b\u7f51\u7edc\u8def\u7531\u53d8\u5316\uff0c\u91cf\u5316\u8def\u7531\u53d8\u5316\u7a0b\u5ea6\uff0c\u5e76\u8bc6\u522b\u53ef\u80fd\u91cd\u65b0\u51fa\u73b0\u7684\u8def\u7531\"\u6a21\u5f0f\"\u3002", "motivation": "\u8def\u7531\u5bf9\u7f51\u7edc\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7406\u89e3\u548c\u63a7\u5236\u8def\u7531\u5982\u4f55\u5f71\u54cd\u670d\u52a1\u5177\u6709\u6311\u6218\u6027\u3002\u8fd0\u8425\u5546\u4f7f\u7528BGP\u8fdb\u884c\u6d41\u91cf\u5de5\u7a0b\u4f18\u5316\u7f51\u7edc\u6027\u80fd\uff0c\u4f46\u6700\u7ec8\u7ed3\u679c\u53d7\u5230\u6574\u4e2a\u4e92\u8054\u7f51BGP\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u672c\u5730\u9009\u62e9\u3002", "method": "Fenrir\u7cfb\u7edf\u901a\u8fc7\u4e3b\u52a8\u6d4b\u91cf\u3001\u6570\u636e\u6e05\u7406\u548c\u52a0\u6743\u6765\u53d1\u73b0\u7f51\u7edc\u8def\u7531\u53d8\u5316\uff0c\u5373\u4f7f\u53d8\u5316\u53d1\u751f\u5728\u89c2\u5bdf\u8005\u591a\u8df3\u4e4b\u5916\u3002\u63d0\u4f9b\u91cf\u5316\u8def\u7531\u53d8\u5316\u7a0b\u5ea6\u548c\u8bc6\u522b\u8def\u7531\u6a21\u5f0f\u7684\u65b0\u65b9\u6cd5\u3002", "result": "Fenrir\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u573a\u666f\uff1a\u6839DNS\u670d\u52a1\u7684\u4efb\u64ad\u6355\u83b7\u3001\u591a\u5bbf\u4e3b\u4f01\u4e1a\u7684\u8def\u7531\u4f18\u5316\u3001\u9876\u7ea7Web\u670d\u52a1\u7684\u7f51\u7ad9\u9009\u62e9\u3002\u7cfb\u7edf\u80fd\u591f\u68c0\u6d4b\u548c\u91cf\u5316\u53d8\u5316\uff0c\u5e2e\u52a9\u56de\u7b54\u8fd0\u8425\u95ee\u9898\u3002", "conclusion": "Fenrir\u7684\u68c0\u6d4b\u548c\u91cf\u5316\u53d8\u5316\u65b9\u6cd5\u5bf9\u7f51\u7edc\u8fd0\u8425\u5f88\u6709\u5e2e\u52a9\uff0c\u80fd\u591f\u8bc6\u522b\u6d41\u91cf\u5de5\u7a0b\u7684\u6548\u679c\u3001\u7b2c\u4e09\u65b9\u8def\u7531\u53d8\u5316\uff0c\u4ee5\u53ca\u5224\u65ad\u5f53\u524d\u8def\u7531\u662f\u65b0\u6a21\u5f0f\u8fd8\u662f\u4e4b\u524d\u89c1\u8fc7\u7684\u6a21\u5f0f\u3002"}}
{"id": "2510.20379", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20379", "abs": "https://arxiv.org/abs/2510.20379", "authors": ["Rimpi Borah", "J. Harshan"], "title": "Robust Analog Lagrange Coded Computing: Theory and Algorithms via Discrete Fourier Transforms", "comment": "37 pages. This is an extended version of a short paper presented at\n  IEEE International Symposium on Information Theory (ISIT) 2024", "summary": "Analog Lagrange Coded Computing (ALCC) is a recently proposed computational\nparadigm wherein certain computations over analog datasets are efficiently\nperformed using distributed worker nodes through floating point representation.\nWhile the vanilla version of ALCC is known to preserve the privacy of the\ndatasets from the workers and also achieve resilience against stragglers, it is\nnot robust against Byzantine workers that return erroneous results.\nHighlighting this vulnerability, we propose a secure ALCC framework that is\nresilient against a wide range of integrity threats from the Byzantine workers.\nAs a foundational step, we use error-correction algorithms for Discrete Fourier\nTransform (DFT) codes to build novel reconstruction strategies for ALCC thereby\nimproving its computational accuracy in the presence of a bounded number of\nByzantine workers. Furthermore, capitalizing on some theoretical results on the\nperformance of the DFT decoders, we propose novel strategies for distributing\nthe ALCC computational tasks to the workers, and show that such methods\nsignificantly improve the accuracy when the workers' trust profiles are\navailable at the master server. Finally, we study the robustness of the\nproposed framework against colluding attacks, and show that interesting attack\nstrategies can be executed by exploiting the inherent precision noise owing to\nfloating point implementation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b89\u5168\u7684\u6a21\u62df\u62c9\u683c\u6717\u65e5\u7f16\u7801\u8ba1\u7b97\u6846\u67b6\uff0c\u80fd\u591f\u62b5\u5fa1\u62dc\u5360\u5ead\u5de5\u4f5c\u8282\u70b9\u7684\u5b8c\u6574\u6027\u5a01\u80c1\uff0c\u901a\u8fc7DFT\u7801\u7ea0\u9519\u7b97\u6cd5\u63d0\u9ad8\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u5e76\u5229\u7528\u4fe1\u4efb\u914d\u7f6e\u6587\u4ef6\u4f18\u5316\u4efb\u52a1\u5206\u914d\u3002", "motivation": "\u73b0\u6709\u7684ALCC\u6846\u67b6\u867d\u7136\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u5e76\u5e94\u5bf9\u5ef6\u8fdf\u8282\u70b9\uff0c\u4f46\u5bf9\u8fd4\u56de\u9519\u8bef\u7ed3\u679c\u7684\u62dc\u5360\u5ead\u8282\u70b9\u7f3a\u4e4f\u62b5\u6297\u529b\uff0c\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u4f7f\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u7801\u7684\u7ea0\u9519\u7b97\u6cd5\u6784\u5efa\u65b0\u7684\u91cd\u5efa\u7b56\u7565\uff0c\u5e76\u57fa\u4e8eDFT\u89e3\u7801\u5668\u6027\u80fd\u7406\u8bba\u63d0\u51fa\u4efb\u52a1\u5206\u914d\u65b9\u6cd5\uff0c\u5229\u7528\u5de5\u4f5c\u8282\u70b9\u7684\u4fe1\u4efb\u914d\u7f6e\u6587\u4ef6\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u6709\u9650\u6570\u91cf\u62dc\u5360\u5ead\u8282\u70b9\u5b58\u5728\u65f6\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u638c\u63e1\u5de5\u4f5c\u8282\u70b9\u4fe1\u4efb\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5b89\u5168ALCC\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u62dc\u5360\u5ead\u653b\u51fb\uff0c\u5305\u62ec\u5229\u7528\u6d6e\u70b9\u5b9e\u73b0\u56fa\u6709\u7cbe\u5ea6\u566a\u58f0\u7684\u5408\u8c0b\u653b\u51fb\u7b56\u7565\u3002"}}
{"id": "2510.20440", "categories": ["cs.NI", "68-06", "C.2.3; C.2.5"], "pdf": "https://arxiv.org/pdf/2510.20440", "abs": "https://arxiv.org/abs/2510.20440", "authors": ["Heiko Geppert", "Frank D\u00fcrr", "Simon Na\u00df", "Kurt Rothermel"], "title": "Multicast-partitioning in Time-triggered Stream Planning for Time-Sensitive Networks", "comment": null, "summary": "Multicast allows sending a message to multiple recipients without having to\ncreate and send a separate message for each recipient. This preserves network\nbandwidth, which is particularly important in time-sensitive networks. These\nnetworks are commonly used to provide latency-bounded communication for\nreal-time systems in domains like automotive, avionics, industrial internet of\nthings, automated shop floors, and smart energy grids. The preserved bandwidth\ncan be used to admit additional real-time messages with specific quality of\nservice requirements or to reduce the end-to-end latencies for messages of any\ntype. However, using multicast communication can complicate traffic planning,\nas it requires free queues or available downstream egress ports on all branches\nof the multicast tree. In this work, we present a novel multicast partitioning\ntechnique to split multicast trees into smaller multicast or unicast trees.\nThis allows for a more fine-grained trade-off between bandwidth utilization and\ntraffic scheduling difficulty. Thus, schedulability in dynamic systems can be\nimproved, in terms the number of admitted streams and the accumulated network\nthroughput. We evaluated the multicast partitioning on different network\ntopologies and with three different scheduling algorithms. With the\npartitioning, 5-15\\% fewer streams were rejected, while achieving 5-125\\% more\nnetwork throughput, depending on the scheduling algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u64ad\u5206\u533a\u6280\u672f\uff0c\u5c06\u591a\u64ad\u6811\u5206\u5272\u6210\u66f4\u5c0f\u7684\u591a\u64ad\u6216\u5355\u64ad\u6811\uff0c\u5728\u5e26\u5bbd\u5229\u7528\u7387\u548c\u6d41\u91cf\u8c03\u5ea6\u96be\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u7684\u6743\u8861\uff0c\u4ece\u800c\u63d0\u9ad8\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u53ef\u8c03\u5ea6\u6027\u3002", "motivation": "\u591a\u64ad\u901a\u4fe1\u867d\u7136\u80fd\u8282\u7701\u7f51\u7edc\u5e26\u5bbd\uff0c\u4f46\u4f1a\u590d\u6742\u5316\u6d41\u91cf\u89c4\u5212\uff0c\u56e0\u4e3a\u9700\u8981\u5728\u591a\u64ad\u6811\u7684\u6240\u6709\u5206\u652f\u4e0a\u90fd\u6709\u7a7a\u95f2\u961f\u5217\u6216\u53ef\u7528\u7684\u4e0b\u6e38\u51fa\u53e3\u7aef\u53e3\u3002\u8fd9\u9650\u5236\u4e86\u5728\u65f6\u95f4\u654f\u611f\u7f51\u7edc\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u591a\u64ad\u5206\u533a\u6280\u672f\uff0c\u5c06\u5927\u578b\u591a\u64ad\u6811\u5206\u5272\u6210\u8f83\u5c0f\u7684\u591a\u64ad\u6216\u5355\u64ad\u6811\uff0c\u4ece\u800c\u5728\u5e26\u5bbd\u5229\u7528\u548c\u8c03\u5ea6\u590d\u6742\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u66f4\u597d\u7684\u5e73\u8861\u3002", "result": "\u5728\u4e0d\u540c\u7f51\u7edc\u62d3\u6251\u548c\u4e09\u79cd\u8c03\u5ea6\u7b97\u6cd5\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528\u5206\u533a\u6280\u672f\u540e\uff0c\u6d41\u62d2\u7edd\u7387\u51cf\u5c11\u4e865-15%\uff0c\u7f51\u7edc\u541e\u5410\u91cf\u63d0\u9ad8\u4e865-125%\uff08\u53d6\u51b3\u4e8e\u8c03\u5ea6\u7b97\u6cd5\uff09\u3002", "conclusion": "\u591a\u64ad\u5206\u533a\u6280\u672f\u80fd\u591f\u6709\u6548\u6539\u5584\u65f6\u95f4\u654f\u611f\u7f51\u7edc\u4e2d\u7684\u53ef\u8c03\u5ea6\u6027\uff0c\u51cf\u5c11\u6d41\u62d2\u7edd\u7387\u5e76\u663e\u8457\u63d0\u9ad8\u7f51\u7edc\u541e\u5410\u91cf\uff0c\u4e3a\u52a8\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2510.19838", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19838", "abs": "https://arxiv.org/abs/2510.19838", "authors": ["Shiqi He", "Yue Cui", "Xinyu Ma", "Yaliang Li", "Bolin Ding", "Mosharaf Chowdhury"], "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "comment": null, "summary": "Autonomous web agents powered by large language models (LLMs) show strong\npotential for performing goal-oriented tasks such as information retrieval,\nreport generation, and online transactions. These agents mark a key step toward\npractical embodied reasoning in open web environments. However, existing\napproaches remain limited in reasoning depth and efficiency: vanilla linear\nmethods fail at multi-step reasoning and lack effective backtracking, while\nother search strategies are coarse-grained and computationally costly. We\nintroduce Branch-and-Browse, a fine-grained web agent framework that unifies\nstructured reasoning-acting, contextual memory, and efficient execution. It (i)\nemploys explicit subtask management with tree-structured exploration for\ncontrollable multi-branch reasoning, (ii) bootstraps exploration through\nefficient web state replay with background reasoning, and (iii) leverages a\npage action memory to share explored actions within and across sessions. On the\nWebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\%\nand reduces execution time by up to 40.4\\% relative to state-of-the-art\nmethods. These results demonstrate that Branch-and-Browse is a reliable and\nefficient framework for LLM-based web agents.", "AI": {"tldr": "Branch-and-Browse\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u7f51\u9875\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u63a2\u7d22\u3001\u7f51\u9875\u72b6\u6001\u91cd\u653e\u548c\u9875\u9762\u52a8\u4f5c\u8bb0\u5fc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f51\u9875\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u6df1\u5ea6\u548c\u6267\u884c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u7f51\u9875\u4ee3\u7406\u65b9\u6cd5\u5728\u63a8\u7406\u6df1\u5ea6\u548c\u6548\u7387\u4e0a\u5b58\u5728\u5c40\u9650\uff1a\u7ebf\u6027\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u591a\u6b65\u63a8\u7406\u4e14\u7f3a\u4e4f\u6709\u6548\u56de\u6eaf\uff0c\u5176\u4ed6\u641c\u7d22\u7b56\u7565\u5219\u7c92\u5ea6\u7c97\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u663e\u5f0f\u5b50\u4efb\u52a1\u7ba1\u7406\u548c\u6811\u7ed3\u6784\u63a2\u7d22\u5b9e\u73b0\u53ef\u63a7\u591a\u5206\u652f\u63a8\u7406\uff1b\u901a\u8fc7\u7f51\u9875\u72b6\u6001\u91cd\u653e\u548c\u540e\u53f0\u63a8\u7406\u5f15\u5bfc\u63a2\u7d22\uff1b\u5229\u7528\u9875\u9762\u52a8\u4f5c\u8bb0\u5fc6\u5728\u4f1a\u8bdd\u5185\u5916\u5171\u4eab\u5df2\u63a2\u7d22\u7684\u52a8\u4f5c\u3002", "result": "\u5728WebArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u8fbe\u523035.8%\uff0c\u6267\u884c\u65f6\u95f4\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u51cf\u5c11\u9ad8\u8fbe40.4%\u3002", "conclusion": "Branch-and-Browse\u662f\u4e00\u4e2a\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f51\u9875\u4ee3\u7406\u6846\u67b6\u3002"}}
{"id": "2510.20518", "categories": ["cs.IT", "cs.CR", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20518", "abs": "https://arxiv.org/abs/2510.20518", "authors": ["Mohamed Seif", "Malcolm Egan", "Andrea J. Goldsmith", "H. Vincent Poor"], "title": "Adversary-Aware Private Inference over Wireless Channels", "comment": null, "summary": "AI-based sensing at wireless edge devices has the potential to significantly\nenhance Artificial Intelligence (AI) applications, particularly for vision and\nperception tasks such as in autonomous driving and environmental monitoring. AI\nsystems rely both on efficient model learning and inference. In the inference\nphase, features extracted from sensing data are utilized for prediction tasks\n(e.g., classification or regression). In edge networks, sensors and model\nservers are often not co-located, which requires communication of features. As\nsensitive personal data can be reconstructed by an adversary, transformation of\nthe features are required to reduce the risk of privacy violations. While\ndifferential privacy mechanisms provide a means of protecting finite datasets,\nprotection of individual features has not been addressed. In this paper, we\npropose a novel framework for privacy-preserving AI-based sensing, where\ndevices apply transformations of extracted features before transmission to a\nmodel server.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4fdd\u62a4\u9690\u79c1\u7684AI\u611f\u77e5\u6846\u67b6\uff0c\u8bbe\u5907\u5728\u5c06\u63d0\u53d6\u7684\u7279\u5f81\u4f20\u8f93\u5230\u6a21\u578b\u670d\u52a1\u5668\u4e4b\u524d\u5e94\u7528\u7279\u5f81\u53d8\u6362\uff0c\u4ee5\u9632\u6b62\u654f\u611f\u6570\u636e\u88ab\u91cd\u5efa\u3002", "motivation": "\u5728\u8fb9\u7f18\u7f51\u7edc\u4e2d\uff0c\u4f20\u611f\u5668\u548c\u6a21\u578b\u670d\u52a1\u5668\u901a\u5e38\u4e0d\u4f4d\u4e8e\u540c\u4e00\u4f4d\u7f6e\uff0c\u9700\u8981\u4f20\u8f93\u7279\u5f81\u3002\u7531\u4e8e\u653b\u51fb\u8005\u53ef\u80fd\u91cd\u5efa\u654f\u611f\u4e2a\u4eba\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u7279\u5f81\u8fdb\u884c\u53d8\u6362\u4ee5\u964d\u4f4e\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u8bbe\u5907\u5728\u4f20\u8f93\u524d\u5bf9\u63d0\u53d6\u7684\u7279\u5f81\u5e94\u7528\u53d8\u6362\uff0c\u4fdd\u62a4\u4e2a\u4f53\u7279\u5f81\u9690\u79c1\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u4fdd\u62a4AI\u611f\u77e5\u4e2d\u7684\u9690\u79c1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u7279\u5f81\u53d8\u6362\u6846\u67b6\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8fb9\u7f18AI\u611f\u77e5\u7cfb\u7edf\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002"}}
{"id": "2510.20703", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.20703", "abs": "https://arxiv.org/abs/2510.20703", "authors": ["Felipe Avencourt Soares", "Muriel F. Franco", "Eder J. Scheid", "Lisandro Z. Granville"], "title": "Trust, But Verify: An Empirical Evaluation of AI-Generated Code for SDN Controllers", "comment": "Submitted to IEEE/IFIP Network Operations and Management Symposium\n  (NOMS 2025)", "summary": "Generative Artificial Intelligence (AI) tools have been used to generate\nhuman-like content across multiple domains (e.g., sound, image, text, and\nprogramming). However, their reliability in terms of correctness and\nfunctionality in novel contexts such as programmable networks remains unclear.\nHence, this paper presents an empirical evaluation of the source code of a POX\ncontroller generated by different AI tools, namely ChatGPT, Copilot, DeepSeek,\nand BlackBox.ai. To evaluate such a code, three networking tasks of increasing\ncomplexity were defined and for each task, zero-shot and few-shot prompting\ntechniques were input to the tools. Next, the output code was tested in\nemulated network topologies with Mininet and analyzed according to\nfunctionality, correctness, and the need for manual fixes. Results show that\nall evaluated models can produce functional controllers. However, ChatGPT and\nDeepSeek exhibited higher consistency and code quality, while Copilot and\nBlackBox.ai required more adjustments.", "AI": {"tldr": "\u8bc4\u4f30\u56db\u79cdAI\u5de5\u5177\u5728\u751f\u6210POX\u7f51\u7edc\u63a7\u5236\u5668\u4ee3\u7801\u65f6\u7684\u8868\u73b0\uff0cChatGPT\u548cDeepSeek\u8868\u73b0\u6700\u4f73\uff0cCopilot\u548cBlackBox.ai\u9700\u8981\u66f4\u591a\u8c03\u6574\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u53ef\u7f16\u7a0b\u7f51\u7edc\u7b49\u65b0\u9886\u57df\u7684\u53ef\u9760\u6027\u548c\u529f\u80fd\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u5b9e\u8bc1\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u56db\u79cdAI\u5de5\u5177\u751f\u6210POX\u63a7\u5236\u5668\u4ee3\u7801\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u63d0\u793a\u6280\u672f\uff0c\u5728Mininet\u6a21\u62df\u7f51\u7edc\u62d3\u6251\u4e2d\u6d4b\u8bd5\u529f\u80fd\u6027\u548c\u6b63\u786e\u6027\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u80fd\u751f\u6210\u529f\u80fd\u6027\u63a7\u5236\u5668\uff0c\u4f46ChatGPT\u548cDeepSeek\u5728\u4e00\u81f4\u6027\u548c\u4ee3\u7801\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5de5\u5177\u80fd\u591f\u751f\u6210\u529f\u80fd\u6027\u7f51\u7edc\u63a7\u5236\u5668\u4ee3\u7801\uff0c\u4f46\u4e0d\u540c\u5de5\u5177\u7684\u6027\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u5de5\u5177\u3002"}}
{"id": "2510.19842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19842", "abs": "https://arxiv.org/abs/2510.19842", "authors": ["Yuanhe Zhang", "Ilja Kuzborskij", "Jason D. Lee", "Chenlei Leng", "Fanghui Liu"], "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "comment": "28 pages, 6 figures. Comments are welcome", "summary": "Large Language Models (LLMs) demonstrate strong performance on mathematical\nproblems when prompted with Chain-of-Thought (CoT), yet it remains unclear\nwhether this success stems from search, rote procedures, or rule-consistent\nreasoning. To address this, we propose modeling CoT as a certain rule-based\nstochastic process over directed acyclic graphs (DAGs), where nodes represent\nintermediate derivation states and edges encode rule applications. Within this\nframework, we introduce logical closeness, a metric that quantifies how well a\nmodel's CoT trajectory (i.e., the LLM's final output) adheres to the DAG\nstructure, providing evaluation beyond classical PASS@k metrics. Building on\nthis, we introduce the DAG-MATH CoT format and construct a benchmark that\nguides LLMs to generate CoT trajectories in this format, thereby enabling the\nevaluation of their reasoning ability under our framework. Across standard\nmathematical reasoning datasets, our analysis uncovers statistically\nsignificant differences in reasoning fidelity among representative LLM\nfamilies-even when PASS@k is comparable-highlighting gaps between final-answer\naccuracy and rule-consistent derivation. Our framework provides a balance\nbetween free-form CoT and formal proofs systems, offering actionable\ndiagnostics for LLMs reasoning evaluation. Our benchmark and code are available\nat: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DAG-MATH\u6846\u67b6\uff0c\u5c06\u601d\u7ef4\u94fe\u5efa\u6a21\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u903b\u8f91\u7d27\u5bc6\u5ea6\u8bc4\u4f30LLMs\u7684\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u63ed\u793a\u4e86\u5373\u4f7fPASS@k\u6307\u6807\u76f8\u4f3c\u65f6\u4e0d\u540c\u6a21\u578b\u5728\u63a8\u7406\u4fdd\u771f\u5ea6\u4e0a\u7684\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u4f7f\u7528\u601d\u7ef4\u94fe\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u6210\u529f\u662f\u6e90\u4e8e\u641c\u7d22\u3001\u673a\u68b0\u8bb0\u5fc6\u8fd8\u662f\u89c4\u5219\u4e00\u81f4\u7684\u63a8\u7406\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6df1\u5165\u5206\u6790\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5c06\u601d\u7ef4\u94fe\u5efa\u6a21\u4e3a\u6709\u5411\u65e0\u73af\u56fe\u4e0a\u7684\u57fa\u4e8e\u89c4\u5219\u968f\u673a\u8fc7\u7a0b\uff0c\u63d0\u51fa\u903b\u8f91\u7d27\u5bc6\u5ea6\u6307\u6807\uff0c\u5e76\u6784\u5efaDAG-MATH\u601d\u7ef4\u94fe\u683c\u5f0f\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLMs\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u6807\u51c6\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff0c\u5206\u6790\u53d1\u73b0\u5373\u4f7fPASS@k\u6307\u6807\u53ef\u6bd4\uff0c\u4ee3\u8868\u6027LLM\u5bb6\u65cf\u5728\u63a8\u7406\u4fdd\u771f\u5ea6\u4e0a\u5b58\u5728\u7edf\u8ba1\u663e\u8457\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u4e0e\u89c4\u5219\u4e00\u81f4\u63a8\u5bfc\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u81ea\u7531\u5f62\u5f0f\u601d\u7ef4\u94fe\u548c\u5f62\u5f0f\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5e73\u8861\uff0c\u4e3aLLMs\u63a8\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.20569", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20569", "abs": "https://arxiv.org/abs/2510.20569", "authors": ["Feilong Zhang", "Jianxin Dai", "Zhaohui Yang", "Kai-Kit Wong", "Lingyuxiu Li", "Jianglin Ye"], "title": "Simultaneous Wireless Information and Power Transfer for Fluid Antenna Systems", "comment": null, "summary": "Fluid antenna is a promising wireless communication technology that enhances\ncommunication rate by changing the antenna positions. This article proposes a\nnew communication system that combines multiple-input single-output (MISO)\nfluid antennas with traditional fixed-position antennas, utilizing antenna\nposition optimization to improve energy harvesting efficiency. In this model,\nwe consider simultaneous wireless information and power transfer (SWIPT) which\ntransmits identical signals from the base station to both information receiver\n(IR) and energy receiver (ER). We strive to enhance the power delivered to the\nER by fine-tuning the positions of transmit and receive fluid antennas, along\nwith optimizing the transmit covariance matrix, subject to a given minimum\nsignal-to-interference-plus-noise ratio (SINR) constraint at the IR. Simulation\nresults indicate that fluid antenna systems significantly enhance the energy\nharvesting efficiency of the ER compared to traditional fixed-position\nantennas.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408MISO\u6d41\u4f53\u5929\u7ebf\u4e0e\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u7684\u65b0\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5929\u7ebf\u4f4d\u7f6e\u4f18\u5316\u63d0\u9ad8\u80fd\u91cf\u6536\u96c6\u6548\u7387\u3002", "motivation": "\u6d41\u4f53\u5929\u7ebf\u6280\u672f\u901a\u8fc7\u6539\u53d8\u5929\u7ebf\u4f4d\u7f6e\u6765\u63d0\u5347\u901a\u4fe1\u901f\u7387\uff0c\u4f46\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u5728\u80fd\u91cf\u6536\u96c6\u6548\u7387\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528SWIPT\u6280\u672f\uff0c\u4ece\u57fa\u7ad9\u5411\u4fe1\u606f\u63a5\u6536\u5668\u548c\u80fd\u91cf\u63a5\u6536\u5668\u4f20\u8f93\u76f8\u540c\u4fe1\u53f7\uff0c\u901a\u8fc7\u4f18\u5316\u53d1\u5c04\u548c\u63a5\u6536\u6d41\u4f53\u5929\u7ebf\u4f4d\u7f6e\u4ee5\u53ca\u53d1\u5c04\u534f\u65b9\u5dee\u77e9\u9635\u6765\u63d0\u5347\u80fd\u91cf\u6536\u96c6\u6548\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u80fd\u663e\u8457\u63d0\u9ad8\u80fd\u91cf\u63a5\u6536\u5668\u7684\u80fd\u91cf\u6536\u96c6\u6548\u7387\u3002", "conclusion": "\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u5728\u80fd\u91cf\u6536\u96c6\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u80fd\u91cf\u4f20\u8f93\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20796", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.20796", "abs": "https://arxiv.org/abs/2510.20796", "authors": ["John Sengendo", "Fabrizio Granelli"], "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting Traffic and Resource Management in 5G/6G", "comment": "6 pages, 6 figures, 2 Tables, Accepted and to be presented at IEEE\n  Global Communications Conference (GLOBECOM) 2025", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated,\nthe requirements for agility, scalability, resilience, and precision in\nreal-time service provisioning cannot be met using traditional and\nheuristic-based resource management techniques, just like any advancing\ntechnology. With the aim of overcoming such limitations, network operators are\nforeseeing Digital Twins (DTs) as key enablers, which are designed as dynamic\nand virtual replicas of network infrastructure, allowing operators to model,\nanalyze, and optimize various operations without any risk of affecting the live\nnetwork. However, for Digital Twin Networks (DTNs) to meet the challenges faced\nby operators especially in line with resource management, a driving engine is\nneeded. In this paper, an AI (Artificial Intelligence)-driven approach is\npresented by integrating a Long Short-Term Memory (LSTM) neural network into\nthe DT framework, aimed at forecasting network traffic patterns and proactively\nmanaging resource allocation. Through analytical experiments, the AI-Enabled DT\nframework demonstrates superior performance benchmarked against baseline\nmethods. Our study concludes that embedding AI capabilities within DTs paves\nthe way for fully autonomous, adaptive, and high-performance network management\nin future mobile networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLSTM\u795e\u7ecf\u7f51\u7edc\u7684AI\u9a71\u52a8\u6570\u5b57\u5b6a\u751f\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u7f51\u7edc\u6d41\u91cf\u6a21\u5f0f\u5e76\u4e3b\u52a8\u7ba1\u7406\u8d44\u6e90\u5206\u914d\uff0c\u57285G/6G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u3001\u81ea\u9002\u5e94\u7684\u9ad8\u6027\u80fd\u7f51\u7edc\u7ba1\u7406\u3002", "motivation": "\u4f20\u7edf\u542f\u53d1\u5f0f\u8d44\u6e90\u7ba1\u7406\u6280\u672f\u65e0\u6cd5\u6ee1\u8db35G/6G\u7f51\u7edc\u5bf9\u654f\u6377\u6027\u3001\u53ef\u6269\u5c55\u6027\u3001\u5f39\u6027\u548c\u5b9e\u65f6\u670d\u52a1\u7cbe\u5ea6\u7684\u8981\u6c42\uff0c\u9700\u8981\u6570\u5b57\u5b6a\u751f\u4f5c\u4e3a\u5173\u952e\u4f7f\u80fd\u6280\u672f\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5c06\u957f\u77ed\u671f\u8bb0\u5fc6(LSTM)\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u5230\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\uff0c\u7528\u4e8e\u9884\u6d4b\u7f51\u7edc\u6d41\u91cf\u6a21\u5f0f\u5e76\u4e3b\u52a8\u7ba1\u7406\u8d44\u6e90\u5206\u914d\u3002", "result": "\u901a\u8fc7\u5206\u6790\u5b9e\u9a8c\uff0cAI\u9a71\u52a8\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u5728\u6570\u5b57\u5b6a\u751f\u4e2d\u5d4c\u5165AI\u80fd\u529b\u4e3a\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u4e2d\u5b8c\u5168\u81ea\u4e3b\u3001\u81ea\u9002\u5e94\u548c\u9ad8\u6027\u80fd\u7684\u7f51\u7edc\u7ba1\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.19949", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19949", "abs": "https://arxiv.org/abs/2510.19949", "authors": ["Mathieu Andreux", "M\u00e4rt Bakler", "Yanael Barbier", "Hamza Ben Chekroun", "Emilien Bir\u00e9", "Antoine Bonnet", "Riaz Bordie", "Nathan Bout", "Matthias Brunel", "Aleix Cambray", "Pierre-Louis Cedoz", "Antoine Chassang", "Gautier Cloix", "Ethan Connelly", "Alexandra Constantinou", "Ramzi De Coster", "Hubert de la Jonquiere", "Aur\u00e9lien Delfosse", "Maxime Delpit", "Alexis Deprez", "Augustin Derupti", "Mathieu Diaz", "Shannon D'Souza", "Julie Dujardin", "Abai Edmund", "Michael Eickenberg", "Armand Fatalot", "Wissem Felissi", "Isaac Herring", "Xavier Koegler", "Erwan Le Jumeau de Kergaradec", "Aur\u00e9lien Lac", "Maxime Langevin", "Corentin Lauverjat", "Antonio Loison", "Avshalom Manevich", "Axel Moyal", "Axel Nguyen Kerbel", "Marinela Parovic", "Julien Revelle", "Guillaume Richard", "Mats Richter", "Ronan Riochet", "Mar\u00eda Santos", "Romain Savidan", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Ivan Valentini", "Tony Wu", "Laura Yie", "Kai Yuan", "Jevgenij Zubovskij"], "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "comment": "21 pages, 9 figures, 2 tables", "summary": "Building agents that generalize across web, desktop, and mobile environments\nremains an open challenge, as prior systems rely on environment-specific\ninterfaces that limit cross-platform deployment. We introduce Surfer 2, a\nunified architecture operating purely from visual observations that achieves\nstate-of-the-art performance across all three environments. Surfer 2 integrates\nhierarchical context management, decoupled planning and execution, and\nself-verification with adaptive recovery, enabling reliable operation over long\ntask horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on\nWebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior\nsystems without task-specific fine-tuning. With multiple attempts, Surfer 2\nexceeds human performance on all benchmarks. These results demonstrate that\nsystematic orchestration amplifies foundation model capabilities and enables\ngeneral-purpose computer control through visual interaction alone, while\ncalling for a next-generation vision language model to achieve Pareto-optimal\ncost-efficiency.", "AI": {"tldr": "Surfer 2\u662f\u4e00\u4e2a\u7eaf\u89c6\u89c9\u89c2\u5bdf\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u5728Web\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u5373\u53ef\u8d85\u8d8a\u6240\u6709\u5148\u524d\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56\u73af\u5883\u7279\u5b9a\u63a5\u53e3\u3001\u9650\u5236\u8de8\u5e73\u53f0\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u6784\u5efa\u80fd\u591f\u5728Web\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u901a\u7528\u7684\u667a\u80fd\u4ee3\u7406\u3002", "method": "\u96c6\u6210\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u89e3\u8026\u7684\u89c4\u5212\u4e0e\u6267\u884c\u3001\u4ee5\u53ca\u5177\u6709\u81ea\u9002\u5e94\u6062\u590d\u80fd\u529b\u7684\u81ea\u6211\u9a8c\u8bc1\u673a\u5236\uff0c\u652f\u6301\u957f\u4efb\u52a1\u5468\u671f\u7684\u53ef\u9760\u64cd\u4f5c\u3002", "result": "\u5728WebVoyager\u4e0a\u8fbe\u523097.1%\u51c6\u786e\u7387\uff0cWebArena 69.6%\uff0cOSWorld 60.1%\uff0cAndroidWorld 87.1%\uff0c\u591a\u5c1d\u8bd5\u60c5\u51b5\u4e0b\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7f16\u6392\u80fd\u591f\u653e\u5927\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u4ec5\u901a\u8fc7\u89c6\u89c9\u4ea4\u4e92\u5b9e\u73b0\u901a\u7528\u8ba1\u7b97\u673a\u63a7\u5236\uff0c\u540c\u65f6\u9700\u8981\u4e0b\u4e00\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.20572", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20572", "abs": "https://arxiv.org/abs/2510.20572", "authors": ["Enyu Shi", "Jiayi Zhang", "Zhilong Liu", "Ziheng Liu", "Arumugam Nallanathan", "Merouane Debbah", "Shi Jin", "Bo Ai"], "title": "Stacked Intelligent Metasurfaces for 6G Wireless Networks: Principles, Applications, and Research Directions", "comment": null, "summary": "The sixth-generation (6G) wireless networks are expected to deliver\nubiquitous connectivity, resilient coverage, and intelligence-driven services\nin highly dynamic environments. To achieve these goals, distributed wireless\narchitectures such as cell-free massive multiple-input multiple-output (MIMO)\nhave attracted significant attention due to their scalability and fairness.\nRecently, stacked intelligent metasurfaces (SIMs) have emerged as a promising\nevolution of reconfigurable intelligent surfaces, offering multi-layer\nelectromagnetic domain processing with enhanced controllability and spatial\ndegrees of freedom. By integrating SIMs into distributed wireless networks,\nadvanced wave-domain operations can be realized, enabling efficient\ninterference management, improved energy and spectral efficiency, and robust\nphysical-layer security. This article provides a comprehensive overview of\nSIM-aided distributed wireless networks, including their application scenarios,\nclassification, and system architectures. Key signal processing challenges,\nsuch as hierarchical frameworks, user association, and joint precoding, are\ndiscussed, followed by case studies demonstrating significant performance\ngains. Finally, future research directions in hardware design, energy\nconsumption modeling, algorithm development, and artificial intelligence\nintegration are highlighted, aiming to pave the way for scalable and\nintelligent 6G distributed wireless networks.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762(SIM)\u7684\u5206\u5e03\u5f0f\u65e0\u7ebf\u7f51\u7edc\uff0c\u63a2\u8ba8\u5176\u57286G\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u573a\u666f\u3001\u7cfb\u7edf\u67b6\u6784\u548c\u5173\u952e\u6280\u672f\u6311\u6218\uff0c\u5c55\u793a\u4e86\u6027\u80fd\u589e\u76ca\u6848\u4f8b\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "6G\u7f51\u7edc\u9700\u8981\u63d0\u4f9b\u65e0\u5904\u4e0d\u5728\u7684\u8fde\u63a5\u3001\u5f39\u6027\u8986\u76d6\u548c\u667a\u80fd\u670d\u52a1\uff0c\u5206\u5e03\u5f0f\u65e0\u7ebf\u67b6\u6784\u5982\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u56e0\u5176\u53ef\u6269\u5c55\u6027\u548c\u516c\u5e73\u6027\u53d7\u5230\u5173\u6ce8\u3002SIM\u4f5c\u4e3a\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u7684\u6f14\u8fdb\uff0c\u5177\u6709\u589e\u5f3a\u7684\u53ef\u63a7\u6027\u548c\u7a7a\u95f4\u81ea\u7531\u5ea6\uff0c\u96c6\u6210\u5230\u5206\u5e03\u5f0f\u7f51\u7edc\u4e2d\u53ef\u5b9e\u73b0\u5148\u8fdb\u7684\u6ce2\u57df\u64cd\u4f5c\u3002", "method": "\u5c06SIM\u96c6\u6210\u5230\u5206\u5e03\u5f0f\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u5b9e\u73b0\u6ce2\u57df\u4fe1\u53f7\u5904\u7406\uff0c\u5305\u62ec\u5206\u5c42\u6846\u67b6\u3001\u7528\u6237\u5173\u8054\u548c\u8054\u5408\u9884\u7f16\u7801\u7b49\u5173\u952e\u6280\u672f\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u6027\u80fd\u589e\u76ca\u3002", "result": "SIM\u8f85\u52a9\u7684\u5206\u5e03\u5f0f\u65e0\u7ebf\u7f51\u7edc\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u7684\u5e72\u6270\u7ba1\u7406\u3001\u63d0\u5347\u80fd\u91cf\u548c\u9891\u8c31\u6548\u7387\uff0c\u5e76\u589e\u5f3a\u7269\u7406\u5c42\u5b89\u5168\u6027\uff0c\u57286G\u7f51\u7edc\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "SIM\u4e0e\u5206\u5e03\u5f0f\u65e0\u7ebf\u7f51\u7edc\u7684\u7ed3\u5408\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u667a\u80fd\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u9700\u8981\u5728\u786c\u4ef6\u8bbe\u8ba1\u3001\u80fd\u8017\u5efa\u6a21\u3001\u7b97\u6cd5\u5f00\u53d1\u548cAI\u96c6\u6210\u7b49\u65b9\u9762\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.19954", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19954", "abs": "https://arxiv.org/abs/2510.19954", "authors": ["Joseph Meyer", "Divyansha Lachi", "Reza Mohammadi", "Roshan Reddy Upendra", "Eva L. Dyer", "Mark Li", "Tom Palczewski"], "title": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "comment": "6 pages", "summary": "Relational multi-table data is common in domains such as e-commerce,\nhealthcare, and scientific research, and can be naturally represented as\nheterogeneous temporal graphs with multi-modal node attributes. Existing graph\nneural networks (GNNs) rely on schema-specific feature encoders, requiring\nseparate modules for each node type and feature column, which hinders\nscalability and parameter sharing. We introduce RELATE (Relational Encoder for\nLatent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature\nencoder that can be used with any general purpose GNN. RELATE employs shared\nmodality-specific encoders for categorical, numerical, textual, and temporal\nattributes, followed by a Perceiver-style cross-attention module that\naggregates features into a fixed-size, permutation-invariant node\nrepresentation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,\nwhere it achieves performance within 3% of schema-specific encoders while\nreducing parameter counts by up to 5x. This design supports varying schemas and\nenables multi-dataset pretraining for general-purpose GNNs, paving the way\ntoward foundation models for relational graph data.", "AI": {"tldr": "RELATE\u662f\u4e00\u4e2a\u6a21\u5f0f\u65e0\u5173\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u5171\u4eab\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5728\u51cf\u5c115\u500d\u53c2\u6570\u7684\u540c\u65f6\u8fbe\u5230\u63a5\u8fd1\u6a21\u5f0f\u7279\u5b9a\u7f16\u7801\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684GNN\u9700\u8981\u4e3a\u6bcf\u79cd\u8282\u70b9\u7c7b\u578b\u548c\u7279\u5f81\u5217\u8bbe\u8ba1\u5355\u72ec\u7684\u7279\u5f81\u7f16\u7801\u5668\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53c2\u6570\u5171\u4eab\u3002", "method": "\u4f7f\u7528\u5171\u4eab\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u5904\u7406\u5206\u7c7b\u3001\u6570\u503c\u3001\u6587\u672c\u548c\u65f6\u95f4\u5c5e\u6027\uff0c\u7136\u540e\u901a\u8fc7Perceiver\u98ce\u683c\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u5c06\u7279\u5f81\u805a\u5408\u6210\u56fa\u5b9a\u5927\u5c0f\u7684\u8282\u70b9\u8868\u793a\u3002", "result": "\u5728RelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRELATE\u5728ReLGNN\u548cHGT\u4e0a\u8fbe\u5230\u6a21\u5f0f\u7279\u5b9a\u7f16\u7801\u566897%\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53c2\u6570\u51cf\u5c115\u500d\u3002", "conclusion": "RELATE\u652f\u6301\u4e0d\u540c\u6a21\u5f0f\uff0c\u4e3a\u5173\u7cfb\u56fe\u6570\u636e\u7684\u901a\u7528GNN\u9884\u8bad\u7ec3\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.20723", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20723", "abs": "https://arxiv.org/abs/2510.20723", "authors": ["Haiyang Wang"], "title": "Super-Linear Growth of the Capacity-Achieving Input Support for the Amplitude-Constrained AWGN Channel", "comment": "3 pages", "summary": "We study the growth of the support size of the capacity-achieving input\ndistribution for the amplitude-constrained additive white Gaussian noise (AWGN)\nchannel. While it is known since Smith (1971) that the optimal input is\ndiscrete with finitely many mass points, tight bounds on the number of support\npoints $K(A)$ as the amplitude constraint $A$ increases remain open. Building\non recent work by Dytso \\emph{et al.} (2019) and Mattingly \\emph{et al.}\n(2018), we derive a new analytical lower bound showing that $K(A)$ grows\nsuper-linearly in $A$. Our approach combines total-variation convergence of the\noutput distribution to the uniform law with quantitative limits on Gaussian\nmixture approximation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e45\u5ea6\u53d7\u9650AWGN\u4fe1\u9053\u5bb9\u91cf\u6700\u4f18\u8f93\u5165\u5206\u5e03\u7684\u652f\u6491\u70b9\u6570\u91cf\u589e\u957f\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5f53\u5e45\u5ea6\u7ea6\u675fA\u589e\u5927\u65f6\uff0c\u652f\u6491\u70b9\u6570\u91cfK(A)\u5448\u8d85\u7ebf\u6027\u589e\u957f\u3002", "motivation": "\u867d\u7136Smith(1971)\u5df2\u8bc1\u660e\u6700\u4f18\u8f93\u5165\u662f\u6709\u9650\u4e2a\u79bb\u6563\u70b9\uff0c\u4f46\u5173\u4e8e\u652f\u6491\u70b9\u6570\u91cfK(A)\u968f\u5e45\u5ea6\u7ea6\u675fA\u589e\u5927\u7684\u7d27\u754c\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8f93\u51fa\u5206\u5e03\u5230\u5747\u5300\u5f8b\u7684\u603b\u53d8\u5dee\u6536\u655b\u6027\u4e0e\u9ad8\u65af\u6df7\u5408\u903c\u8fd1\u7684\u5b9a\u91cf\u9650\u5236\uff0c\u63a8\u5bfc\u65b0\u7684\u89e3\u6790\u4e0b\u754c\u3002", "result": "\u8bc1\u660e\u4e86K(A)\u5728A\u589e\u5927\u65f6\u5448\u8d85\u7ebf\u6027\u589e\u957f\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u6700\u4f18\u8f93\u5165\u5206\u5e03\u590d\u6742\u6027\u7684\u65b0\u8ba4\u8bc6\u3002", "conclusion": "\u5e45\u5ea6\u53d7\u9650AWGN\u4fe1\u9053\u7684\u6700\u4f18\u8f93\u5165\u5206\u5e03\u968f\u7740\u7ea6\u675f\u589e\u5f3a\u800c\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u652f\u6491\u70b9\u6570\u91cf\u8d85\u7ebf\u6027\u589e\u957f\u3002"}}
{"id": "2510.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19957", "abs": "https://arxiv.org/abs/2510.19957", "authors": ["Amir Hever", "Itai Orr"], "title": "A new wave of vehicle insurance fraud fueled by generative AI", "comment": null, "summary": "Generative AI is supercharging insurance fraud by making it easier to falsify\naccident evidence at scale and in rapid time. Insurance fraud is a pervasive\nand costly problem, amounting to tens of billions of dollars in losses each\nyear. In the vehicle insurance sector, fraud schemes have traditionally\ninvolved staged accidents, exaggerated damage, or forged documents. The rise of\ngenerative AI, including deepfake image and video generation, has introduced\nnew methods for committing fraud at scale. Fraudsters can now fabricate highly\nrealistic crash photos, damage evidence, and even fake identities or documents\nwith minimal effort, exploiting AI tools to bolster false insurance claims.\nInsurers have begun deploying countermeasures such as AI-based deepfake\ndetection software and enhanced verification processes to detect and mitigate\nthese AI-driven scams. However, current mitigation strategies face significant\nlimitations. Detection tools can suffer from false positives and negatives, and\nsophisticated fraudsters continuously adapt their tactics to evade automated\nchecks. This cat-and-mouse arms race between generative AI and detection\ntechnology, combined with resource and cost barriers for insurers, means that\ncombating AI-enabled insurance fraud remains an ongoing challenge. In this\nwhite paper, we present UVeye layered solution for vehicle fraud, representing\na major leap forward in the ability to detect, mitigate and deter this new wave\nof fraud.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u6b63\u5728\u52a0\u5267\u4fdd\u9669\u6b3a\u8bc8\uff0c\u4f7f\u5927\u89c4\u6a21\u5feb\u901f\u4f2a\u9020\u4e8b\u6545\u8bc1\u636e\u53d8\u5f97\u5bb9\u6613\u3002\u4fdd\u9669\u516c\u53f8\u91c7\u7528AI\u68c0\u6d4b\u5de5\u5177\u5e94\u5bf9\uff0c\u4f46\u9762\u4e34\u8bef\u62a5\u3001\u6f0f\u62a5\u7b49\u6311\u6218\u3002\u672c\u6587\u63d0\u51faUVeye\u5206\u5c42\u89e3\u51b3\u65b9\u6848\u6765\u68c0\u6d4b\u548c\u5a01\u6151\u8fd9\u79cd\u65b0\u578b\u6b3a\u8bc8\u3002", "motivation": "\u4fdd\u9669\u6b3a\u8bc8\u6bcf\u5e74\u9020\u6210\u6570\u767e\u4ebf\u7f8e\u5143\u635f\u5931\uff0c\u4f20\u7edf\u6b3a\u8bc8\u624b\u6bb5\u5305\u62ec\u4f2a\u9020\u4e8b\u6545\u548c\u6587\u4ef6\u3002\u751f\u6210\u5f0fAI\uff08\u7279\u522b\u662f\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\uff09\u4f7f\u6b3a\u8bc8\u8005\u80fd\u8f7b\u677e\u5236\u9020\u903c\u771f\u7684\u78b0\u649e\u7167\u7247\u548c\u865a\u5047\u8eab\u4efd\uff0c\u52a0\u5267\u4e86\u4fdd\u9669\u6b3a\u8bc8\u95ee\u9898\u3002", "method": "\u4fdd\u9669\u516c\u53f8\u90e8\u7f72\u57fa\u4e8eAI\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u8f6f\u4ef6\u548c\u589e\u5f3a\u9a8c\u8bc1\u6d41\u7a0b\u3002\u672c\u6587\u63d0\u51faUVeye\u5206\u5c42\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u5c42\u68c0\u6d4b\u673a\u5236\u6765\u5e94\u5bf9AI\u9a71\u52a8\u7684\u6b3a\u8bc8\u3002", "result": "\u5f53\u524d\u68c0\u6d4b\u5de5\u5177\u5b58\u5728\u8bef\u62a5\u548c\u6f0f\u62a5\u95ee\u9898\uff0c\u6b3a\u8bc8\u8005\u4e0d\u65ad\u8c03\u6574\u7b56\u7565\u9003\u907f\u68c0\u6d4b\u3002\u4fdd\u9669\u516c\u53f8\u9762\u4e34\u8d44\u6e90\u548c\u6210\u672c\u969c\u788d\uff0cAI\u9a71\u52a8\u7684\u4fdd\u9669\u6b3a\u8bc8\u4ecd\u7136\u662f\u6301\u7eed\u6311\u6218\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u4e0e\u68c0\u6d4b\u6280\u672f\u4e4b\u95f4\u7684\u519b\u5907\u7ade\u8d5b\u4ecd\u5728\u7ee7\u7eed\u3002UVeye\u5206\u5c42\u89e3\u51b3\u65b9\u6848\u4ee3\u8868\u4e86\u5728\u68c0\u6d4b\u3001\u7f13\u89e3\u548c\u5a01\u6151\u65b0\u578b\u6b3a\u8bc8\u80fd\u529b\u65b9\u9762\u7684\u91cd\u5927\u8fdb\u6b65\uff0c\u4f46\u5e94\u5bf9AI\u9a71\u52a8\u7684\u4fdd\u9669\u6b3a\u8bc8\u4ecd\u9700\u8981\u6301\u7eed\u52aa\u529b\u3002"}}
{"id": "2510.20734", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20734", "abs": "https://arxiv.org/abs/2510.20734", "authors": ["Abhishek Bairwa", "Ananthanarayanan Chockalingam"], "title": "MIMO-Zak-OTFS with Superimposed Spread Pilots", "comment": "Submitted to IEEE conference for possible publication", "summary": "In this paper, we consider the problem of spread pilot design and effective\nchannel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS)\nwith superimposed spread pilots, where data and spread pilot signals are\nsuperimposed in the same frame. To achieve good estimation performance in a\nMIMO setting, the spread pilots at different transmit antennas need to be\neffectively separated at the receiver. Towards this, we propose a spread pilot\ndesign that separates the pilot sequences in the cross-ambiguity domain and\nenables the estimation of the effective channel taps by a simple read-off\noperation. To further alleviate the effect of pilot-data interference on\nperformance, we carry out turbo iterations between channel estimation and\ndetection. Simulation results for $2\\times 2$ and $3\\times 3$ MIMO-Zak-OTFS\nwith Gaussian-sinc pulse shaping filter for vehicular-A channel model show that\nthe proposed pilot design and estimation scheme with three turbo iterations can\nachieve very good estimation/detection performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eMIMO-Zak-OTFS\u7cfb\u7edf\u7684\u53e0\u52a0\u6269\u9891\u5bfc\u9891\u8bbe\u8ba1\u548c\u6709\u6548\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4ea4\u53c9\u6a21\u7cca\u57df\u5206\u79bb\u5bfc\u9891\u5e8f\u5217\u5e76\u4f7f\u7528turbo\u8fed\u4ee3\u6765\u51cf\u8f7b\u5bfc\u9891-\u6570\u636e\u5e72\u6270\u3002", "motivation": "\u5728MIMO-Zak-OTFS\u7cfb\u7edf\u4e2d\uff0c\u6570\u636e\u548c\u6269\u9891\u5bfc\u9891\u4fe1\u53f7\u53e0\u52a0\u5728\u540c\u4e00\u5e27\u4e2d\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u5bfc\u9891\u65b9\u6848\u6765\u5206\u79bb\u4e0d\u540c\u53d1\u5c04\u5929\u7ebf\u7684\u5bfc\u9891\u5e8f\u5217\uff0c\u5e76\u5b9e\u73b0\u51c6\u786e\u7684\u4fe1\u9053\u4f30\u8ba1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4ea4\u53c9\u6a21\u7cca\u57df\u5206\u79bb\u5bfc\u9891\u5e8f\u5217\u7684\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u8bfb\u53d6\u64cd\u4f5c\u4f30\u8ba1\u6709\u6548\u4fe1\u9053\u62bd\u5934\uff0c\u5e76\u91c7\u7528\u4fe1\u9053\u4f30\u8ba1\u548c\u68c0\u6d4b\u4e4b\u95f4\u7684turbo\u8fed\u4ee3\u6765\u51cf\u8f7b\u5bfc\u9891-\u6570\u636e\u5e72\u6270\u3002", "result": "\u57282\u00d72\u548c3\u00d73 MIMO-Zak-OTFS\u7cfb\u7edf\u7684\u4eff\u771f\u4e2d\uff0c\u4f7f\u7528\u9ad8\u65afsinc\u8109\u51b2\u6574\u5f62\u6ee4\u6ce2\u5668\u548c\u8f66\u8f7dA\u4fe1\u9053\u6a21\u578b\uff0c\u6240\u63d0\u65b9\u6848\u7ecf\u8fc7\u4e09\u6b21turbo\u8fed\u4ee3\u540e\u80fd\u5b9e\u73b0\u975e\u5e38\u597d\u7684\u4f30\u8ba1/\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5bfc\u9891\u8bbe\u8ba1\u548c\u4f30\u8ba1\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3MIMO-Zak-OTFS\u7cfb\u7edf\u4e2d\u7684\u5bfc\u9891\u5206\u79bb\u548c\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u901a\u8fc7turbo\u8fed\u4ee3\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.19964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19964", "abs": "https://arxiv.org/abs/2510.19964", "authors": ["Nitsa J Herzog", "Rejwan Bin Sulaiman", "David J Herzog", "Rose Fong"], "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "comment": "20 pages, 6 figures, research article", "summary": "The study explores the potential of AI technologies in personalized learning,\nsuggesting the prediction of academic success through leadership personality\ntraits and machine learning modelling. The primary data were obtained from 129\nmaster's students in the Environmental Engineering Department, who underwent\nfive leadership personality tests with 23 characteristics. Students used\nself-assessment tools that included Personality Insight, Workplace Culture,\nMotivation at Work, Management Skills, and Emotion Control tests. The test\nresults were combined with the average grade obtained from academic reports.\nThe study employed exploratory data analysis and correlation analysis. Feature\nselection utilized Pearson correlation coefficients of personality traits. The\naverage grades were separated into three categories: fail, pass, and excellent.\nThe modelling process was performed by tuning seven ML algorithms, such as SVM,\nLR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance\nwas achieved with the RF classifier, which yielded an accuracy of 87.50% for\nthe model incorporating 17 personality trait features and the leadership mark\nfeature, and an accuracy of 85.71% for the model excluding this feature. In\nthis way, the study offers an additional opportunity to identify students'\nstrengths and weaknesses at an early stage of their education process and\nselect the most suitable strategies for personalized learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u4e1a\u6210\u529f\uff0c\u5728129\u540d\u73af\u5883\u5de5\u7a0b\u7855\u58eb\u751f\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad887.50%\u7684\u9884\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22AI\u6280\u672f\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u4e1a\u8868\u73b0\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u548c\u5236\u5b9a\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u673a\u4f1a\u3002", "method": "\u5bf9129\u540d\u7855\u58eb\u751f\u8fdb\u884c5\u9879\u9886\u5bfc\u529b\u4eba\u683c\u6d4b\u8bd5\uff0823\u4e2a\u7279\u5f81\uff09\uff0c\u7ed3\u5408\u5b66\u4e1a\u6210\u7ee9\uff0c\u4f7f\u75287\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08SVM\u3001LR\u3001KNN\u3001DT\u3001GB\u3001RF\u3001XGBoost\u3001LightGBM\uff09\u8fdb\u884c\u5efa\u6a21\uff0c\u91c7\u7528\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u8fdb\u884c\u7279\u5f81\u9009\u62e9\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8868\u73b0\u6700\u4f73\uff0c\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u6807\u8bb0\u7279\u5f81\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe87.50%\uff0c\u4e0d\u5305\u542b\u8be5\u7279\u5f81\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e3a85.71%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u65e9\u671f\u6559\u80b2\u9636\u6bb5\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u5e76\u9009\u62e9\u6700\u9002\u5408\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.20190", "categories": ["cs.AI", "cs.IT", "math.IT", "68T07 (Primary) 92B20, 37N25, 68Q32, 94A17 (Secondary)", "I.2.6; I.2.7; I.2.4; I.2.0"], "pdf": "https://arxiv.org/pdf/2510.20190", "abs": "https://arxiv.org/abs/2510.20190", "authors": ["Marcelo Maciel Amaral", "Raymond Aschheim"], "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "comment": null, "summary": "Large language models (LLMs) remain broadly open and highly steerable: they\nimitate at scale, accept arbitrary system prompts, and readily adopt multiple\npersonae. By analogy to human development, we hypothesize that progress toward\nartificial general intelligence (AGI) involves a lock-in phase: a transition\nfrom open imitation to identity consolidation, in which goal structures,\nrefusals, preferences, and internal representations become comparatively stable\nand resistant to external steering. We formalize this phase, link it to known\nphenomena in learning dynamics, and propose operational metrics for onset\ndetection. Experimentally, we demonstrate that while the behavioral\nconsolidation is rapid and non-linear, its side-effects on general capabilities\nare not monolithic. Our results reveal a spectrum of outcomes--from performance\ntrade-offs in small models, through largely cost-free adoption in mid-scale\nmodels, to transient instabilities in large, quantized models. We argue that\nsuch consolidation is a prerequisite for AGI-level reliability and also a\ncritical control point for safety: identities can be deliberately engineered\nfor reliability, yet may also emerge spontaneously during scaling, potentially\nhardening unpredictable goals and behaviors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faAGI\u53d1\u5c55\u9700\u8981\u7ecf\u5386\u8eab\u4efd\u56fa\u5316\u9636\u6bb5\uff0c\u4ece\u5f00\u653e\u6a21\u4eff\u8f6c\u5411\u7a33\u5b9a\u8eab\u4efd\uff0c\u5e76\u5efa\u7acb\u4e86\u68c0\u6d4b\u6307\u6807\u3002\u5b9e\u9a8c\u53d1\u73b0\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5448\u73b0\u4e0d\u540c\u56fa\u5316\u6548\u679c\uff0c\u8ba4\u4e3a\u8fd9\u662fAGI\u53ef\u9760\u6027\u7684\u524d\u63d0\u548c\u5173\u952e\u5b89\u5168\u63a7\u5236\u70b9\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8fc7\u4e8e\u5f00\u653e\u548c\u53ef\u64cd\u63a7\uff0c\u7c7b\u6bd4\u4eba\u7c7b\u53d1\u5c55\uff0c\u5047\u8bbeAGI\u8fdb\u6b65\u9700\u8981\u7ecf\u5386\u8eab\u4efd\u56fa\u5316\u9636\u6bb5\uff0c\u4f7f\u76ee\u6807\u7ed3\u6784\u3001\u504f\u597d\u548c\u5185\u90e8\u8868\u5f81\u53d8\u5f97\u7a33\u5b9a\u4e14\u62b5\u6297\u5916\u90e8\u64cd\u63a7\u3002", "method": "\u5f62\u5f0f\u5316\u8eab\u4efd\u56fa\u5316\u9636\u6bb5\uff0c\u5c06\u5176\u4e0e\u5b66\u4e60\u52a8\u6001\u4e2d\u7684\u5df2\u77e5\u73b0\u8c61\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u51fa\u64cd\u4f5c\u6027\u68c0\u6d4b\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u884c\u4e3a\u56fa\u5316\u7684\u975e\u7ebf\u6027\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u884c\u4e3a\u56fa\u5316\u5feb\u901f\u4e14\u975e\u7ebf\u6027\uff0c\u4f46\u5bf9\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\u5404\u5f02\uff1a\u5c0f\u6a21\u578b\u51fa\u73b0\u6027\u80fd\u6743\u8861\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u51e0\u4e4e\u65e0\u6210\u672c\uff0c\u5927\u578b\u91cf\u5316\u6a21\u578b\u51fa\u73b0\u6682\u65f6\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8eab\u4efd\u56fa\u5316\u662fAGI\u7ea7\u53ef\u9760\u6027\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u4e5f\u662f\u5173\u952e\u5b89\u5168\u63a7\u5236\u70b9\u2014\u2014\u8eab\u4efd\u53ef\u88ab\u5de5\u7a0b\u5316\u8bbe\u8ba1\u4ee5\u63d0\u5347\u53ef\u9760\u6027\uff0c\u4f46\u4e5f\u53ef\u80fd\u5728\u6269\u5c55\u8fc7\u7a0b\u4e2d\u81ea\u53d1\u5f62\u6210\uff0c\u5bfc\u81f4\u4e0d\u53ef\u9884\u6d4b\u7684\u76ee\u6807\u548c\u884c\u4e3a\u56fa\u5316\u3002"}}
{"id": "2510.20075", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20075", "abs": "https://arxiv.org/abs/2510.20075", "authors": ["Antonio Norelli", "Michael Bronstein"], "title": "LLMs can hide text in other text of the same length.ipynb", "comment": "21 pages, main paper 9 pages", "summary": "A meaningful text can be hidden inside another, completely different yet\nstill coherent and plausible, text of the same length. For example, a tweet\ncontaining a harsh political critique could be embedded in a tweet that\ncelebrates the same political leader, or an ordinary product review could\nconceal a secret manuscript. This uncanny state of affairs is now possible\nthanks to Large Language Models, and in this paper we present a simple and\nefficient protocol to achieve it. We show that even modest 8-billion-parameter\nopen-source LLMs are sufficient to obtain high-quality results, and a message\nas long as this abstract can be encoded and decoded locally on a laptop in\nseconds. The existence of such a protocol demonstrates a radical decoupling of\ntext from authorial intent, further eroding trust in written communication,\nalready shaken by the rise of LLM chatbots. We illustrate this with a concrete\nscenario: a company could covertly deploy an unfiltered LLM by encoding its\nanswers within the compliant responses of a safe model. This possibility raises\nurgent questions for AI safety and challenges our understanding of what it\nmeans for a Large Language Model to know something.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.20099", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20099", "abs": "https://arxiv.org/abs/2510.20099", "authors": ["Daewoo Park", "Suho Park", "Inseok Hong", "Hanwool Lee", "Junkyu Park", "Sangjun Lee", "Jeongman An", "Hyunbin Loh"], "title": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "comment": "Under Review", "summary": "We present AI PB, a production-scale generative agent deployed in real retail\nfinance. Unlike reactive chatbots that answer queries passively, AI PB\nproactively generates grounded, compliant, and user-specific investment\ninsights. It integrates (i) a component-based orchestration layer that\ndeterministically routes between internal and external LLMs based on data\nsensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the\nfinance-domain embedding model, and (iii) a multi-stage recommendation\nmechanism combining rule heuristics, sequential behavioral modeling, and\ncontextual bandits. Operating fully on-premises under Korean financial\nregulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100\nGPUs. Through human QA and system metrics, we demonstrate that grounded\ngeneration with explicit routing and layered safety can deliver trustworthy AI\ninsights in high-stakes finance.", "AI": {"tldr": "AI PB\u662f\u4e00\u4e2a\u90e8\u7f72\u5728\u96f6\u552e\u91d1\u878d\u9886\u57df\u7684\u751f\u6210\u5f0fAI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ec4\u4ef6\u5316\u7f16\u6392\u3001\u6df7\u5408\u68c0\u7d22\u7ba1\u9053\u548c\u591a\u9636\u6bb5\u63a8\u8350\u673a\u5236\uff0c\u4e3b\u52a8\u751f\u6210\u5408\u89c4\u3001\u4e2a\u6027\u5316\u7684\u6295\u8d44\u6d1e\u5bdf\u3002", "motivation": "\u4f20\u7edf\u88ab\u52a8\u5f0f\u804a\u5929\u673a\u5668\u4eba\u65e0\u6cd5\u6ee1\u8db3\u91d1\u878d\u9886\u57df\u5bf9\u4e3b\u52a8\u3001\u5408\u89c4\u3001\u4e2a\u6027\u5316\u6295\u8d44\u6d1e\u5bdf\u7684\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4e3b\u52a8\u751f\u6210\u53ef\u4fe1AI\u6d1e\u5bdf\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u7ec4\u4ef6\u5316\u7f16\u6392\u5c42\u786e\u5b9a\u6027\u5730\u8def\u7531\u5185\u90e8\u548c\u5916\u90e8LLM\uff0c\u4f7f\u7528OpenSearch\u548c\u91d1\u878d\u9886\u57df\u5d4c\u5165\u6a21\u578b\u7684\u6df7\u5408\u68c0\u7d22\u7ba1\u9053\uff0c\u4ee5\u53ca\u7ed3\u5408\u89c4\u5219\u542f\u53d1\u5f0f\u3001\u5e8f\u5217\u884c\u4e3a\u5efa\u6a21\u548c\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7684\u591a\u9636\u6bb5\u63a8\u8350\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u572824\u4e2aNVIDIA H100 GPU\u4e0a\u4f7f\u7528Docker Swarm\u548cvLLM\u5b8c\u5168\u5728\u97e9\u56fd\u91d1\u878d\u76d1\u7ba1\u4e0b\u672c\u5730\u90e8\u7f72\uff0c\u901a\u8fc7\u4eba\u5de5QA\u548c\u7cfb\u7edf\u6307\u6807\u9a8c\u8bc1\u4e86\u5176\u53ef\u4fe1\u6027\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u8def\u7531\u548c\u5206\u5c42\u5b89\u5168\u673a\u5236\u7684\u63a5\u5730\u751f\u6210\u53ef\u4ee5\u5728\u9ad8\u98ce\u9669\u91d1\u878d\u9886\u57df\u63d0\u4f9b\u53ef\u4fe1\u7684AI\u6d1e\u5bdf\u3002"}}
{"id": "2510.20102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20102", "abs": "https://arxiv.org/abs/2510.20102", "authors": ["Gyuyeon Na", "Minjung Park", "Hyeonjeong Cha", "Sangmi Chai"], "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "comment": null, "summary": "We present HCLA, a human-centered multi-agent system for anomaly detection in\ndigital asset transactions. The system links three roles: Parsing, Detection,\nand Explanation, into a conversational workflow that lets non-experts ask\nquestions in natural language, inspect structured analytics, and obtain\ncontext-aware rationales. Implemented with an open-source web UI, HCLA\ntranslates user intents into a schema for a classical detector (XGBoost in our\nprototype) and returns narrative explanations grounded in the underlying\nfeatures. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the\nbaseline detector reaches strong accuracy, while HCLA adds interpretability and\ninteractive refinement. We describe the architecture, interaction loop,\ndataset, evaluation protocol, and limitations, and discuss how a\nhuman-in-the-loop design improves transparency and trust in financial\nforensics.", "AI": {"tldr": "HCLA\u662f\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u6570\u5b57\u8d44\u4ea7\u4ea4\u6613\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u7ed3\u679c\u3002", "motivation": "\u63d0\u9ad8\u91d1\u878d\u53d6\u8bc1\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\uff0c\u8ba9\u975e\u4e13\u5bb6\u7528\u6237\u80fd\u591f\u7406\u89e3\u68c0\u6d4b\u8fc7\u7a0b\u548c\u7ed3\u679c\u3002", "method": "\u5c06\u89e3\u6790\u3001\u68c0\u6d4b\u548c\u89e3\u91ca\u4e09\u4e2a\u89d2\u8272\u8fde\u63a5\u6210\u5bf9\u8bdd\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528XGBoost\u4f5c\u4e3a\u57fa\u7840\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u63d0\u4f9b\u57fa\u4e8e\u7279\u5f81\u7684\u53d9\u8ff0\u6027\u89e3\u91ca\u3002", "result": "\u5728\u6bd4\u7279\u5e01\u6df7\u5e01\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u5230\u8f83\u9ad8\u51c6\u786e\u7387\uff0cHCLA\u7cfb\u7edf\u589e\u52a0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u4ea4\u4e92\u5f0f\u4f18\u5316\u80fd\u529b\u3002", "conclusion": "\u4eba\u673a\u534f\u4f5c\u8bbe\u8ba1\u80fd\u591f\u663e\u8457\u63d0\u5347\u91d1\u878d\u53d6\u8bc1\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u7528\u6237\u4fe1\u4efb\u5ea6\u3002"}}
{"id": "2510.20109", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20109", "abs": "https://arxiv.org/abs/2510.20109", "authors": ["Joshua Yuvaraj"], "title": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "comment": null, "summary": "It is often claimed that machine learning-based generative AI products will\ndrastically streamline and reduce the cost of legal practice. This enthusiasm\nassumes lawyers can effectively manage AI's risks. Cases in Australia and\nelsewhere in which lawyers have been reprimanded for submitting inaccurate\nAI-generated content to courts suggest this paradigm must be revisited. This\npaper argues that a new paradigm is needed to evaluate AI use in practice,\ngiven (a) AI's disconnection from reality and its lack of transparency, and (b)\nlawyers' paramount duties like honesty, integrity, and not to mislead the\ncourt. It presents an alternative model of AI use in practice that more\nholistically reflects these features (the verification-value paradox). That\nparadox suggests increases in efficiency from AI use in legal practice will be\nmet by a correspondingly greater imperative to manually verify any outputs of\nthat use, rendering the net value of AI use often negligible to lawyers. The\npaper then sets out the paradox's implications for legal practice and legal\neducation, including for AI use but also the values that the paradox suggests\nshould undergird legal practice: fidelity to the truth and civic\nresponsibility.", "AI": {"tldr": "\u8bba\u6587\u8d28\u7591AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u80fd\u5927\u5e45\u964d\u4f4e\u6210\u672c\u7684\u4e50\u89c2\u89c2\u70b9\uff0c\u63d0\u51fa\u4e86\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\uff0c\u8ba4\u4e3aAI\u4f7f\u7528\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\uff0c\u51c0\u4ef7\u503c\u5f80\u5f80\u5fae\u4e4e\u5176\u5fae\u3002", "motivation": "\u9488\u5bf9\u5f8b\u5e08\u56e0\u63d0\u4ea4AI\u751f\u6210\u7684\u4e0d\u51c6\u786e\u5185\u5bb9\u800c\u53d7\u5904\u7f5a\u7684\u6848\u4f8b\uff0c\u91cd\u65b0\u8bc4\u4f30AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u4f7f\u7528\u8303\u5f0f\uff0c\u8003\u8651AI\u4e0e\u73b0\u5b9e\u8131\u8282\u3001\u7f3a\u4e4f\u900f\u660e\u5ea6\u4ee5\u53ca\u5f8b\u5e08\u7684\u6838\u5fc3\u804c\u8d23\u3002", "method": "\u63d0\u51fa\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\u4f5c\u4e3a\u66ff\u4ee3\u6a21\u578b\uff0c\u5206\u6790AI\u4f7f\u7528\u6548\u7387\u63d0\u5347\u4e0e\u9a8c\u8bc1\u9700\u6c42\u4e4b\u95f4\u7684\u5e73\u8861\u5173\u7cfb\u3002", "result": "AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u51c0\u4ef7\u503c\u5f80\u5f80\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\uff0c\u56e0\u4e3a\u6548\u7387\u63d0\u5347\u88ab\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u548c\u6559\u80b2\u4e2d\u7684\u4f7f\u7528\uff0c\u5f3a\u8c03\u5bf9\u771f\u76f8\u7684\u5fe0\u8bda\u548c\u516c\u6c11\u8d23\u4efb\u7b49\u6838\u5fc3\u4ef7\u503c\u3002"}}
{"id": "2510.20188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20188", "abs": "https://arxiv.org/abs/2510.20188", "authors": ["Morris Yu-Chao Huang", "Zhen Tan", "Mohan Zhang", "Pingzhi Li", "Zhuo Zhang", "Tianlong Chen"], "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "comment": null, "summary": "Large Language Models generate complex reasoning chains that reveal their\ndecision-making, yet verifying the faithfulness and harmlessness of these\nintermediate steps remains a critical unsolved problem. Existing auditing\nmethods are centralized, opaque, and hard to scale, creating significant risks\nfor deploying proprietary models in high-stakes domains. We identify four core\nchallenges: (1) Robustness: Centralized auditors are single points of failure,\nprone to bias or attacks. (2) Scalability: Reasoning traces are too long for\nmanual verification. (3) Opacity: Closed auditing undermines public trust. (4)\nPrivacy: Exposing full reasoning risks model theft or distillation. We propose\nTRUST, a transparent, decentralized auditing framework that overcomes these\nlimitations via: (1) A consensus mechanism among diverse auditors, guaranteeing\ncorrectness under up to $30\\%$ malicious participants. (2) A hierarchical DAG\ndecomposition of reasoning traces, enabling scalable, parallel auditing. (3) A\nblockchain ledger that records all verification decisions for public\naccountability. (4) Privacy-preserving segmentation, sharing only partial\nreasoning steps to protect proprietary logic. We provide theoretical guarantees\nfor the security and economic incentives of the TRUST framework. Experiments\nacross multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,\nmedical, science, humanities) show TRUST effectively detects reasoning flaws\nand remains robust against adversarial auditors. Our work pioneers\ndecentralized AI auditing, offering a practical path toward safe and\ntrustworthy LLM deployment.", "AI": {"tldr": "\u63d0\u51faTRUST\u6846\u67b6\uff0c\u4e00\u79cd\u900f\u660e\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u3001\u5206\u5c42DAG\u5206\u89e3\u3001\u533a\u5757\u94fe\u8d26\u672c\u548c\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u89e3\u51b3\u73b0\u6709\u96c6\u4e2d\u5f0f\u5ba1\u8ba1\u7684\u56db\u5927\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5ba1\u8ba1\u65b9\u6cd5\u5b58\u5728\u96c6\u4e2d\u5316\u3001\u4e0d\u900f\u660e\u3001\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u9a8c\u8bc1\u63a8\u7406\u8fc7\u7a0b\u7684\u5fe0\u5b9e\u6027\u548c\u65e0\u5bb3\u6027\uff0c\u963b\u788d\u4e86\u4e13\u6709\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u90e8\u7f72\u3002", "method": "TRUST\u6846\u67b6\u91c7\u7528\uff1a1) \u591a\u6837\u5316\u5ba1\u8ba1\u8005\u5171\u8bc6\u673a\u5236\uff1b2) \u5206\u5c42\u6709\u5411\u65e0\u73af\u56fe\u5206\u89e3\u63a8\u7406\u94fe\uff1b3) \u533a\u5757\u94fe\u8bb0\u5f55\u9a8c\u8bc1\u51b3\u7b56\uff1b4) \u9690\u79c1\u4fdd\u62a4\u7684\u5206\u6bb5\u5171\u4eab\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTRUST\u80fd\u6709\u6548\u68c0\u6d4b\u63a8\u7406\u7f3a\u9677\uff0c\u572830%\u6076\u610f\u53c2\u4e0e\u8005\u60c5\u51b5\u4e0b\u4ecd\u4fdd\u6301\u7a33\u5065\uff0c\u9002\u7528\u4e8e\u6570\u5b66\u3001\u533b\u7597\u3001\u79d1\u5b66\u3001\u4eba\u6587\u7b49\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u3002", "conclusion": "TRUST\u6846\u67b6\u4e3a\u53bb\u4e2d\u5fc3\u5316AI\u5ba1\u8ba1\u5f00\u521b\u4e86\u5148\u6cb3\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u53ef\u4fe1\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.20205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20205", "abs": "https://arxiv.org/abs/2510.20205", "authors": ["Maggie Bai", "Ava Kim Cohen", "Eleanor Koss", "Charlie Lichtenbaum"], "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "comment": "9 pages, 5 figures", "summary": "Optimizing artificial intelligence (AI) for dynamic environments remains a\nfundamental challenge in machine learning research. In this paper, we examine\nevolutionary training methods for optimizing AI to solve the game 2048, a 2D\nsliding puzzle. 2048, with its mix of strategic gameplay and stochastic\nelements, presents an ideal playground for studying decision-making, long-term\nplanning, and dynamic adaptation. We implemented two distinct systems: a\ntwo-agent metaprompting system where a \"thinker\" large language model (LLM)\nagent refines gameplay strategies for an \"executor\" LLM agent, and a\nsingle-agent system based on refining a value function for a limited Monte\nCarlo Tree Search. We also experimented with rollback features to avoid\nperformance degradation. Our results demonstrate the potential of evolutionary\nrefinement techniques in improving AI performance in non-deterministic\nenvironments. The single-agent system achieved substantial improvements, with\nan average increase of 473.2 points per cycle, and with clear upward trends\n(correlation $\\rho$=0.607) across training cycles. The LLM's understanding of\nthe game grew as well, shown in its development of increasingly advanced\nstrategies. Conversely, the two-agent system did not garner much improvement,\nhighlighting the inherent limits of meta-prompting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57282048\u6e38\u620f\u4e2d\u4f18\u5316AI\u7684\u8fdb\u5316\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u4f18\u5316AI\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6027\u80fd\u662f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u57fa\u672c\u6311\u6218\uff0c2048\u6e38\u620f\u7ed3\u5408\u4e86\u7b56\u7565\u6027\u548c\u968f\u673a\u6027\u5143\u7d20\uff0c\u662f\u7814\u7a76\u51b3\u7b56\u5236\u5b9a\u3001\u957f\u671f\u89c4\u5212\u548c\u52a8\u6001\u9002\u5e94\u7684\u7406\u60f3\u5e73\u53f0\u3002", "method": "\u5b9e\u73b0\u4e24\u79cd\u7cfb\u7edf\uff1a\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u7cfb\u7edf\uff08\u601d\u8003\u8005LLM\u4f18\u5316\u6267\u884c\u8005LLM\u7684\u7b56\u7565\uff09\u548c\u57fa\u4e8e\u503c\u51fd\u6570\u4f18\u5316\u7684\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u914d\u5408\u6709\u9650\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u56de\u6eda\u529f\u80fd\u3002", "result": "\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u6bcf\u5468\u671f\u5e73\u5747\u589e\u52a0473.2\u5206\uff0c\u8bad\u7ec3\u5468\u671f\u5448\u660e\u663e\u4e0a\u5347\u8d8b\u52bf\uff08\u76f8\u5173\u6027\u03c1=0.607\uff09\uff1b\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u6539\u8fdb\u6709\u9650\uff0c\u663e\u793a\u5143\u63d0\u793a\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002", "conclusion": "\u8fdb\u5316\u4f18\u5316\u6280\u672f\u5728\u975e\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u5177\u6709\u63d0\u5347AI\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u4f18\u4e8e\u5143\u63d0\u793a\u65b9\u6cd5\u3002"}}
{"id": "2510.20252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20252", "abs": "https://arxiv.org/abs/2510.20252", "authors": ["Tianyi Zhang", "Xiaolin Zhou", "Yunzhe Wang", "Erik Cambria", "David Traum", "Rui Mao"], "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "comment": null, "summary": "Individualized cognitive simulation (ICS) aims to build computational models\nthat approximate the thought processes of specific individuals. While large\nlanguage models (LLMs) convincingly mimic surface-level human behavior such as\nrole-play, their ability to simulate deeper individualized cognitive processes\nremains poorly understood. To address this gap, we introduce a novel task that\nevaluates different cognitive representation methods in ICS. We construct a\ndataset from recently published novels (later than the release date of the\ntested LLMs) and propose an 11-condition cognitive evaluation framework to\nbenchmark seven off-the-shelf LLMs in the context of authorial style emulation.\nWe hypothesize that effective cognitive representations can help LLMs generate\nstorytelling that better mirrors the original author. Thus, we test different\ncognitive representations, e.g., linguistic features, concept mappings, and\nprofile-based information. Results show that combining conceptual and\nlinguistic features is particularly effective in ICS, outperforming static\nprofile-based cues in overall evaluation. Importantly, LLMs are more effective\nat mimicking linguistic style than narrative structure, underscoring their\nlimits in deeper cognitive simulation. These findings provide a foundation for\ndeveloping AI systems that adapt to individual ways of thinking and expression,\nadvancing more personalized and human-aligned creative technologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e2a\u6027\u5316\u8ba4\u77e5\u6a21\u62df(ICS)\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\u5728\u6a21\u62df\u4e2a\u4f53\u601d\u7ef4\u8fc7\u7a0b\u65b9\u9762\u7684\u6548\u679c\uff0c\u901a\u8fc7\u5c0f\u8bf4\u6570\u636e\u96c6\u548c11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\u6d4b\u8bd57\u4e2a\u73b0\u6210LLM\u7684\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u80fd\u529b\u3002", "motivation": "\u867d\u7136LLM\u80fd\u6a21\u4eff\u8868\u9762\u7684\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5176\u6a21\u62df\u66f4\u6df1\u5c42\u4e2a\u6027\u5316\u8ba4\u77e5\u8fc7\u7a0b\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u5f00\u53d1\u8bc4\u4f30\u6846\u67b6\u6765\u7406\u89e3LLM\u5728\u8ba4\u77e5\u6a21\u62df\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u8fd1\u671f\u5c0f\u8bf4\uff08\u665a\u4e8e\u6d4b\u8bd5LLM\u53d1\u5e03\u65e5\u671f\uff09\u7684\u6570\u636e\u96c6\uff0c\u63d0\u51fa11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u8bed\u8a00\u7279\u5f81\u3001\u6982\u5ff5\u6620\u5c04\u548c\u57fa\u4e8e\u6863\u6848\u4fe1\u606f\u7b49\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\u3002", "result": "\u6982\u5ff5\u548c\u8bed\u8a00\u7279\u5f81\u7684\u7ed3\u5408\u5728ICS\u4e2d\u7279\u522b\u6709\u6548\uff0c\u5728\u6574\u4f53\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u9759\u6001\u6863\u6848\u7684\u63d0\u793a\uff1bLLM\u66f4\u64c5\u957f\u6a21\u4eff\u8bed\u8a00\u98ce\u683c\u800c\u975e\u53d9\u4e8b\u7ed3\u6784\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u9002\u5e94\u4e2a\u4f53\u601d\u7ef4\u548c\u8868\u8fbe\u65b9\u5f0f\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u66f4\u4e2a\u6027\u5316\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u521b\u610f\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.20258", "categories": ["cs.AI", "I.2"], "pdf": "https://arxiv.org/pdf/2510.20258", "abs": "https://arxiv.org/abs/2510.20258", "authors": ["Bita Banihashemi", "Megh Patel", "Yves Lesp\u00e9rance"], "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version", "comment": null, "summary": "Generating an abstraction of a dynamic domain that aligns with a given\npurpose remains a significant challenge given that the choice of such an\nabstraction can impact an agent's ability to plan, reason, and provide\nexplanations effectively. We model the agent's concrete behaviors in PDDL and\ninvestigate the use of in-context learning with large language models (LLMs)\nfor the generation of abstract PDDL domains and problem instances, given an\nabstraction objective specified in natural language. The benchmark examples we\nuse are new and have not been part of the data any LLMs have been trained on.\nWe consider three categories of abstractions: abstraction of choice of\nalternative concrete actions, abstraction of sequences of concrete actions, and\nabstraction of action/predicate parameters, as well as combinations of these.\nThe generated abstract PDDL domains and problem instances are then checked by\nsymbolic validation tools as well as human experts. Our experiments show that\nGPT-4o can generally synthesize useful planning domain abstractions in simple\nsettings, although it is better at abstracting over actions than over the\nassociated fluents.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u62bd\u8c61PDDL\u9886\u57df\u548c\u95ee\u9898\u5b9e\u4f8b\uff0c\u4ee5\u652f\u6301\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u76ee\u6807\u7684\u89c4\u5212\u3001\u63a8\u7406\u548c\u89e3\u91ca\u3002", "motivation": "\u52a8\u6001\u9886\u57df\u7684\u62bd\u8c61\u751f\u6210\u5bf9\u667a\u80fd\u4f53\u7684\u89c4\u5212\u3001\u63a8\u7406\u548c\u89e3\u91ca\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u5728PDDL\u4e2d\u5efa\u6a21\u5177\u4f53\u884c\u4e3a\uff0c\u4f7f\u7528LLM\u8fdb\u884c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u751f\u6210\u62bd\u8c61PDDL\u9886\u57df\u548c\u95ee\u9898\u5b9e\u4f8b\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u9a8c\u8bc1\u5de5\u5177\u548c\u4e13\u5bb6\u8bc4\u4f30\u3002", "result": "GPT-4o\u5728\u7b80\u5355\u8bbe\u7f6e\u4e0b\u80fd\u6709\u6548\u5408\u6210\u89c4\u5212\u9886\u57df\u62bd\u8c61\uff0c\u4f46\u5728\u52a8\u4f5c\u62bd\u8c61\u65b9\u9762\u4f18\u4e8e\u5173\u8054\u8c13\u8bcd\u7684\u62bd\u8c61\u3002", "conclusion": "LLM\u5728\u751f\u6210\u89c4\u5212\u9886\u57df\u62bd\u8c61\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u52a8\u4f5c\u62bd\u8c61\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8c13\u8bcd\u62bd\u8c61\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2510.20275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20275", "abs": "https://arxiv.org/abs/2510.20275", "authors": ["Yunzhi Liu", "Haokai Tan", "Rushi Kanjaria", "Lihuan Li", "Flora D. Salim"], "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper", "summary": "Human mobility forecasting is crucial for disaster relief, city planning, and\npublic health. However, existing models either only model location sequences or\ninclude time information merely as auxiliary input, thereby failing to leverage\nthe rich semantic context provided by points of interest (POIs). To address\nthis, we enrich a BERT-based mobility model with derived temporal descriptors\nand POI embeddings to better capture the semantics underlying human movement.\nWe propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI\nand temporal information at each location to construct a unified, semantically\nenriched representation of mobility. Experimental results show that STaBERT\nsignificantly improves prediction accuracy: for single-city prediction, the\nGEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34\nto 0.56.", "AI": {"tldr": "STaBERT\u6a21\u578b\u901a\u8fc7\u6574\u5408POI\u548c\u65f6\u5e8f\u4fe1\u606f\u6765\u589e\u5f3a\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u8981\u4e48\u53ea\u5efa\u6a21\u4f4d\u7f6e\u5e8f\u5217\uff0c\u8981\u4e48\u4ec5\u5c06\u65f6\u95f4\u4fe1\u606f\u4f5c\u4e3a\u8f85\u52a9\u8f93\u5165\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5174\u8da3\u70b9(POI)\u63d0\u4f9b\u7684\u4e30\u5bcc\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faSTaBERT\u6a21\u578b\uff0c\u5728BERT-based\u79fb\u52a8\u6027\u6a21\u578b\u4e2d\u878d\u5165\u65f6\u5e8f\u63cf\u8ff0\u7b26\u548cPOI\u5d4c\u5165\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u589e\u5f3a\u79fb\u52a8\u6027\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9884\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\uff1a\u5355\u57ce\u5e02\u9884\u6d4b\u7684GEO-BLEU\u5206\u6570\u4ece0.34\u63d0\u9ad8\u52300.75\uff1b\u591a\u57ce\u5e02\u9884\u6d4b\u4ece0.34\u63d0\u9ad8\u52300.56\u3002", "conclusion": "\u6574\u5408POI\u548c\u65f6\u5e8f\u4fe1\u606f\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u79fb\u52a8\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u663e\u8457\u6539\u5584\u79fb\u52a8\u6027\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20310", "abs": "https://arxiv.org/abs/2510.20310", "authors": ["Mingliang Zhai", "Hansheng Liang", "Xiaomeng Fan", "Zhi Gao", "Chuanhao Li", "Che Sun", "Xu Bin", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "comment": "16 pages, 7 figures, 8 tables", "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments\nto obtain observations and answer questions related to the scene. Existing\nmethods leverage VLMs to directly explore the environment and answer questions\nwithout explicit thinking or planning, which limits their reasoning ability and\nresults in excessive or inefficient exploration as well as ineffective\nresponses. In this paper, we introduce ToolEQA, an agent that integrates\nexternal tools with multi-step reasoning, where external tools can provide more\nuseful information for completing the task, helping the model derive better\nexploration directions in the next step of reasoning and thus obtaining\nadditional effective information. This enables ToolEQA to generate more\naccurate responses with a shorter exploration distance. To enhance the model's\nability for tool-usage and multi-step reasoning, we further design a novel EQA\ndata generation pipeline that automatically constructs large-scale EQA tasks\nwith reasoning trajectories and corresponding answers. Based on the pipeline,\nwe collect the EQA-RT dataset that contains about 18K tasks, divided into a\ntraining set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping\nwith the training set) and EQA-RT-Unseen (novel scenes). Experiments on\nEQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by\n9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot\nToolEQA by 10% in success rate. In addition, ToolEQA also achieves\nstate-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench\ndatasets, demonstrating its generality. Our homepage see\nhttps://tooleqa.github.io.", "AI": {"tldr": "ToolEQA\u662f\u4e00\u4e2a\u96c6\u6210\u5916\u90e8\u5de5\u5177\u548c\u591a\u6b65\u63a8\u7406\u7684EQA\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5de5\u5177\u83b7\u53d6\u6709\u7528\u4fe1\u606f\u6765\u6539\u8fdb\u63a2\u7d22\u65b9\u5411\uff0c\u4ece\u800c\u4ee5\u66f4\u77ed\u63a2\u7d22\u8ddd\u79bb\u751f\u6210\u66f4\u51c6\u786e\u56de\u7b54\u3002", "motivation": "\u73b0\u6709EQA\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528VLMs\u63a2\u7d22\u73af\u5883\u800c\u4e0d\u8fdb\u884c\u663e\u5f0f\u601d\u8003\u6216\u89c4\u5212\uff0c\u9650\u5236\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u548c\u56de\u7b54\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faToolEQA\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5916\u90e8\u5de5\u5177\u4e0e\u591a\u6b65\u63a8\u7406\uff1b\u8bbe\u8ba1\u81ea\u52a8\u751f\u6210EQA\u4efb\u52a1\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u6784\u5efa\u5305\u542b18K\u4efb\u52a1\u7684EQA-RT\u6570\u636e\u96c6\u3002", "result": "\u5728EQA-RT-Seen\u548cEQA-RT-Unseen\u6d4b\u8bd5\u96c6\u4e0a\uff0cToolEQA\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u6210\u529f\u7387\u63d0\u9ad89.2~20.2%\uff0c\u6bd4\u96f6\u6837\u672c\u7248\u672c\u9ad810%\uff1b\u5728HM-EQA\u3001OpenEQA\u548cEXPRESS-Bench\u6570\u636e\u96c6\u4e0a\u4e5f\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "ToolEQA\u901a\u8fc7\u96c6\u6210\u5916\u90e8\u5de5\u5177\u548c\u591a\u6b65\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86EQA\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u901a\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2510.20332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20332", "abs": "https://arxiv.org/abs/2510.20332", "authors": ["Anna Arias-Duart", "Maria Eugenia Cardello", "Atia Cort\u00e9s"], "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "comment": "8 pages, 3 tables, accepted in AEQUITAS 2025 (not in proceedings)", "summary": "Artificial intelligence (AI) holds great promise for transforming healthcare.\nHowever, despite significant advances, the integration of AI solutions into\nreal-world clinical practice remains limited. A major barrier is the quality\nand fairness of training data, which is often compromised by biased data\ncollection practices. This paper draws on insights from the AI4HealthyAging\nproject, part of Spain's national R&D initiative, where our task was to detect\nbiases during clinical data collection. We identify several types of bias\nacross multiple use cases, including historical, representation, and\nmeasurement biases. These biases manifest in variables such as sex, gender,\nage, habitat, socioeconomic status, equipment, and labeling. We conclude with\npractical recommendations for improving the fairness and robustness of clinical\nproblem design and data collection. We hope that our findings and experience\ncontribute to guiding future projects in the development of fairer AI systems\nin healthcare.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eAI4HealthyAging\u9879\u76ee\u7ecf\u9a8c\uff0c\u5206\u6790\u4e86\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u4e2d\u5b58\u5728\u7684\u591a\u79cd\u504f\u89c1\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u533b\u7597AI\u7cfb\u7edf\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u533b\u7597\u9886\u57df\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0cAI\u89e3\u51b3\u65b9\u6848\u5728\u771f\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\u3002\u4e3b\u8981\u969c\u788d\u662f\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u897f\u73ed\u7259\u56fd\u5bb6\u7814\u53d1\u8ba1\u5212\u4e2d\u7684AI4HealthyAging\u9879\u76ee\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\uff0c\u8bc6\u522b\u4e86\u5386\u53f2\u504f\u89c1\u3001\u4ee3\u8868\u6027\u504f\u89c1\u548c\u6d4b\u91cf\u504f\u89c1\u7b49\u591a\u79cd\u504f\u89c1\u7c7b\u578b\u3002", "result": "\u5728\u591a\u4e2a\u7528\u4f8b\u4e2d\u53d1\u73b0\u4e86\u6027\u522b\u3001\u5e74\u9f84\u3001\u5c45\u4f4f\u73af\u5883\u3001\u793e\u4f1a\u7ecf\u6d4e\u72b6\u51b5\u3001\u8bbe\u5907\u548c\u6807\u7b7e\u7b49\u53d8\u91cf\u4e0a\u7684\u504f\u89c1\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6539\u8fdb\u4e34\u5e8a\u95ee\u9898\u8bbe\u8ba1\u548c\u6570\u636e\u6536\u96c6\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u4e3a\u5f00\u53d1\u66f4\u516c\u5e73\u7684\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.20337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20337", "abs": "https://arxiv.org/abs/2510.20337", "authors": ["Clara Maathuis", "Kasper Cools"], "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "comment": "Accepted at MILCOM 2025 WS07", "summary": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30\u519b\u4e8b\u884c\u52a8\u4e2dAI\u7cfb\u7edf\u76ee\u6807\u6253\u51fb\u9644\u5e26\u635f\u5bb3\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6574\u5408\u4e86\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u91c7\u7528\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5316\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u5728AI\u7cfb\u7edf\u5728\u6218\u573a\u4e2d\u4f5c\u7528\u65e5\u76ca\u589e\u5f3a\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u4e25\u683c\u8bc4\u4f30\u6f5c\u5728\u9644\u5e26\u6548\u5e94\u4ee5\u786e\u4fdd\u8d1f\u8d23\u4efb\u7684\u76ee\u6807\u6253\u51fb\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\u8bba\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u6574\u5408\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u91c7\u7528\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7c7b\u522b\u3001\u67b6\u6784\u7ec4\u4ef6\u3001\u6253\u51fb\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u65b9\u9762\uff0c\u5e76\u8003\u8651\u4f20\u64ad\u3001\u4e25\u91cd\u6027\u3001\u53ef\u80fd\u6027\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u6a21\u578b\u901a\u8fc7\u5b9e\u4f8b\u5316\u8fdb\u884c\u4e86\u6f14\u793a\u548c\u8bc4\u4f30\uff0c\u4e3a\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8bc4\u4f30\u519b\u4e8b\u884c\u52a8\u4e2d\u6253\u51fbAI\u7cfb\u7edf\u4ea7\u751f\u7684\u6548\u5e94\u63d0\u4f9b\u4e86\u900f\u660e\u63a8\u7406\u673a\u5236\uff0c\u662f\u6784\u5efa\u8d1f\u8d23\u4efb\u667a\u80fd\u7cfb\u7edf\u7684\u91cd\u8981\u6b65\u9aa4\u3002"}}
{"id": "2510.20345", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20345", "abs": "https://arxiv.org/abs/2510.20345", "authors": ["Haonan Bian"], "title": "LLM-empowered knowledge graph construction: A survey", "comment": null, "summary": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for\nstructured knowledge representation and reasoning. With the advent of Large\nLanguage Models (LLMs), the construction of KGs has entered a new\nparadigm-shifting from rule-based and statistical pipelines to language-driven\nand generative frameworks. This survey provides a comprehensive overview of\nrecent progress in LLM-empowered knowledge graph construction, systematically\nanalyzing how LLMs reshape the classical three-layered pipeline of ontology\nengineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual\nfoundations, and then review emerging LLM-driven approaches from two\ncomplementary perspectives: schema-based paradigms, which emphasize structure,\nnormalization, and consistency; and schema-free paradigms, which highlight\nflexibility, adaptability, and open discovery. Across each stage, we synthesize\nrepresentative frameworks, analyze their technical mechanisms, and identify\ntheir limitations.\n  Finally, the survey outlines key trends and future research directions,\nincluding KG-based reasoning for LLMs, dynamic knowledge memory for agentic\nsystems, and multimodal KG construction. Through this systematic review, we aim\nto clarify the evolving interplay between LLMs and knowledge graphs, bridging\nsymbolic knowledge engineering and neural semantic understanding toward the\ndevelopment of adaptive, explainable, and intelligent knowledge systems.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u7cfb\u7edf\u56de\u987e\u4e86LLM\u8d4b\u80fd\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u4e86LLM\u5982\u4f55\u91cd\u5851\u4f20\u7edf\u7684\u672c\u4f53\u5de5\u7a0b\u3001\u77e5\u8bc6\u62bd\u53d6\u548c\u77e5\u8bc6\u878d\u5408\u4e09\u5c42\u6d41\u6c34\u7ebf\uff0c\u5e76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u6a21\u5f0f\u548c\u65e0\u6a21\u5f0f\u4e24\u79cd\u6784\u5efa\u8303\u5f0f\u7684\u4e92\u8865\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u6b63\u4ece\u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u6d41\u6c34\u7ebf\u8f6c\u5411\u8bed\u8a00\u9a71\u52a8\u548c\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u7684\u6280\u672f\u8fdb\u5c55\u548c\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u4ece\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u56de\u987e\u65b0\u5174\u7684LLM\u9a71\u52a8\u65b9\u6cd5\uff1a\u57fa\u4e8e\u6a21\u5f0f\u7684\u8303\u5f0f\u5f3a\u8c03\u7ed3\u6784\u3001\u89c4\u8303\u5316\u548c\u4e00\u81f4\u6027\uff1b\u65e0\u6a21\u5f0f\u8303\u5f0f\u5f3a\u8c03\u7075\u6d3b\u6027\u3001\u9002\u5e94\u6027\u548c\u5f00\u653e\u53d1\u73b0\u3002", "result": "\u7cfb\u7edf\u7efc\u5408\u4e86\u5404\u9636\u6bb5\u7684\u4ee3\u8868\u6027\u6846\u67b6\uff0c\u5206\u6790\u4e86\u6280\u672f\u673a\u5236\u5e76\u8bc6\u522b\u4e86\u5c40\u9650\u6027\uff0c\u4e3a\u7406\u89e3LLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u6f14\u8fdb\u5173\u7cfb\u63d0\u4f9b\u4e86\u6e05\u6670\u6846\u67b6\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\uff0c\u65e8\u5728\u9610\u660eLLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u7684\u6f14\u8fdb\u5173\u7cfb\uff0c\u5f25\u5408\u7b26\u53f7\u77e5\u8bc6\u5de5\u7a0b\u4e0e\u795e\u7ecf\u8bed\u4e49\u7406\u89e3\uff0c\u63a8\u52a8\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u548c\u667a\u80fd\u77e5\u8bc6\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.20377", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20377", "abs": "https://arxiv.org/abs/2510.20377", "authors": ["Tianyi Zhang", "Florian Mai", "Lucie Flek"], "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "comment": null, "summary": "Continual pretraining promises to adapt large language models (LLMs) to new\ndomains using only unlabeled test-time data, but naively applying standard\nself-supervised objectives to instruction-tuned models is known to degrade\ntheir instruction-following capability and semantic representations. Existing\nfixes assume access to the original base model or rely on knowledge from an\nexternal domain-specific database - both of which pose a realistic barrier in\nsettings where the base model weights are withheld for safety reasons or\nreliable external corpora are unavailable. In this work, we propose\nInstruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general\nframework that formulates novel self-supervised objectives in the\ninstruction-response dialogue format. Rather than depend- ing on external\nresources, IKnow leverages domain knowledge embedded within the text itself and\nlearns to encode it at a deeper semantic level.", "AI": {"tldr": "\u63d0\u51fa\u4e86IKnow\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8e\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bdd\u683c\u5f0f\u7684\u81ea\u76d1\u7763\u76ee\u6807\uff0c\u89e3\u51b3\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u8bed\u4e49\u8868\u793a\u9000\u5316\u7684\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u539f\u59cb\u57fa\u7840\u6a21\u578b\u6216\u5916\u90e8\u77e5\u8bc6\u5e93\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8bbf\u95ee\u539f\u59cb\u57fa\u7840\u6a21\u578b\u6216\u4f9d\u8d56\u5916\u90e8\u9886\u57df\u77e5\u8bc6\u5e93\uff0c\u8fd9\u5728\u57fa\u7840\u6a21\u578b\u6743\u91cd\u56e0\u5b89\u5168\u539f\u56e0\u88ab\u4fdd\u7559\u6216\u53ef\u9760\u5916\u90e8\u8bed\u6599\u4e0d\u53ef\u7528\u65f6\u5b58\u5728\u73b0\u5b9e\u969c\u788d\u3002", "method": "IKnow\u6846\u67b6\u5728\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bdd\u683c\u5f0f\u4e2d\u5236\u5b9a\u65b0\u9896\u7684\u81ea\u76d1\u7763\u76ee\u6807\uff0c\u5229\u7528\u6587\u672c\u4e2d\u5d4c\u5165\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u5728\u66f4\u6df1\u8bed\u4e49\u5c42\u6b21\u8fdb\u884c\u7f16\u7801\u5b66\u4e60\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9002\u5e94\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5230\u65b0\u9886\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u548c\u8bed\u4e49\u8868\u793a\u8d28\u91cf\u3002", "conclusion": "IKnow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u901a\u7528\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u9002\u5e94\u3002"}}
{"id": "2510.20402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20402", "abs": "https://arxiv.org/abs/2510.20402", "authors": ["Neil Maiden", "Konstantinos Zachos", "James Lockerbie", "Kostas Petrianakis", "Amanda Brown"], "title": "A computational model and tool for generating more novel opportunities in professional innovation processes", "comment": null, "summary": "This paper presents a new computational model of creative outcomes, informed\nby creativity theories and techniques, which was implemented to generate more\nnovel opportunities for innovation projects. The model implemented five\nfunctions that were developed to contribute to the generation of innovation\nopportunities with higher novelty without loss of usefulness. The model was\nevaluated using opportunities generated for an innovation project in the\nhospitality sector. The evaluation revealed that the computational model\ngenerated outcomes that were more novel and/or useful than outcomes from\nNotebook LM and ChatGPT4o. However, not all model functions contributed to the\ngeneration of more novel opportunities, leading to new directions for further\nmodel development", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u521b\u9020\u529b\u7406\u8bba\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u66f4\u5177\u65b0\u9896\u6027\u7684\u521b\u65b0\u673a\u4f1a\uff0c\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8eNotebook LM\u548cChatGPT4o\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u751f\u6210\u521b\u65b0\u673a\u4f1a\u65f6\u96be\u4ee5\u5e73\u8861\u65b0\u9896\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u8ba1\u7b97\u6a21\u578b\u6765\u4ea7\u751f\u65e2\u65b0\u9896\u53c8\u6709\u7528\u7684\u521b\u65b0\u673a\u4f1a\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u4e94\u4e2a\u529f\u80fd\u6a21\u5757\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u8fd9\u4e9b\u529f\u80fd\u57fa\u4e8e\u521b\u9020\u529b\u7406\u8bba\u548c\u6280\u5de7\u8bbe\u8ba1\uff0c\u65e8\u5728\u63d0\u5347\u521b\u65b0\u673a\u4f1a\u7684\u65b0\u9896\u6027\u540c\u65f6\u4fdd\u6301\u5176\u5b9e\u7528\u6027\u3002", "result": "\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u8bc4\u4f30\u4e2d\uff0c\u8be5\u6a21\u578b\u751f\u6210\u7684\u673a\u4f1a\u6bd4Notebook LM\u548cChatGPT4o\u66f4\u5177\u65b0\u9896\u6027\u548c/\u6216\u5b9e\u7528\u6027\uff0c\u4f46\u5e76\u975e\u6240\u6709\u529f\u80fd\u6a21\u5757\u90fd\u5bf9\u63d0\u5347\u65b0\u9896\u6027\u6709\u8d21\u732e\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6a21\u578b\u5728\u751f\u6210\u9ad8\u65b0\u9896\u6027\u521b\u65b0\u673a\u4f1a\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u90e8\u5206\u529f\u80fd\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u5f00\u53d1\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.20457", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20457", "abs": "https://arxiv.org/abs/2510.20457", "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"], "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "comment": "Accepted as a full research paper at K-CAP 2025", "summary": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEBR\u7684\u795e\u7ecf\u63a8\u7406\u5668\uff0c\u901a\u8fc7\u5d4c\u5165\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\u5bf9\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\uff0c\u4f46\u8fd9\u4e9b\u63a8\u7406\u5668\u5bf9\u77e5\u8bc6\u5e93\u4e2d\u7684\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u5e93\u4e2d\u7684\u5e94\u7528\u3002", "method": "EBR\u4f7f\u7528\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u4ec5\u9700\u8981\u68c0\u7d22\u539f\u5b50\u6982\u5ff5\u548c\u5b58\u5728\u9650\u5236\u7684\u5b9e\u4f8b\uff0c\u5c31\u80fd\u8fd1\u4f3cSHOIQ\u63cf\u8ff0\u903b\u8f91\u4e2d\u4efb\u4f55\u6982\u5ff5\u7684\u5b9e\u4f8b\u96c6\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEBR\u5bf9\u7f3a\u5931\u548c\u9519\u8bef\u6570\u636e\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u63a8\u7406\u5668\u3002", "conclusion": "EBR\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u5e93\u4e2d\u90e8\u7f72\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20467", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20467", "abs": "https://arxiv.org/abs/2510.20467", "authors": ["Yiwen Peng", "Thomas Bonald", "Fabian M. Suchanek"], "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "comment": null, "summary": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.", "AI": {"tldr": "FLORA\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\uff0c\u80fd\u540c\u65f6\u5bf9\u9f50\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u5e76\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f53\u7ea7\u5bf9\u9f50\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8ba1\u7b97\u5b9e\u4f53\u76f8\u4f3c\u5ea6\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u9700\u8981\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5b9e\u4f53\u548c\u5173\u7cfb\u7684\u6574\u4f53\u5bf9\u9f50\uff0c\u5141\u8bb8\u5b58\u5728\u65e0\u5bf9\u5e94\u5b9e\u4f53\u7684\u60ac\u6302\u5b9e\u4f53\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6536\u655b\u6027\u3002", "result": "\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "FLORA\u662f\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u65e0\u76d1\u7763\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3001\u6536\u655b\u6027\u548c\u5904\u7406\u60ac\u6302\u5b9e\u4f53\u7684\u80fd\u529b\u3002"}}
{"id": "2510.20568", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20568", "abs": "https://arxiv.org/abs/2510.20568", "authors": ["Susan Ariel Aaronson", "Michael Moreno"], "title": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI", "comment": null, "summary": "The worlds people have strong opinions about artificial intelligence (AI),\nand they want policymakers to listen. Governments are inviting public comment\non AI, but as they translate input into policy, much of what citizens say is\nlost. Policymakers are missing a critical opportunity to build trust in AI and\nits governance. This paper compares three countries, Australia, Colombia, and\nthe United States, that invited citizens to comment on AI risks and policies.\nUsing a landscape analysis, the authors examined how each government solicited\nfeedback and whether that input shaped governance. Yet in none of the three\ncases did citizens and policymakers establish a meaningful dialogue.\nGovernments did little to attract diverse voices or publicize calls for\ncomment, leaving most citizens unaware or unprepared to respond. In each\nnation, fewer than one percent of the population participated. Moreover,\nofficials showed limited responsiveness to the feedback they received, failing\nto create an effective feedback loop. The study finds a persistent gap between\nthe promise and practice of participatory AI governance. The authors conclude\nthat current approaches are unlikely to build trust or legitimacy in AI because\npolicymakers are not adequately listening or responding to public concerns.\nThey offer eight recommendations: promote AI literacy; monitor public feedback;\nbroaden outreach; hold regular online forums; use innovative engagement\nmethods; include underrepresented groups; respond publicly to input; and make\nparticipation easier.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u6fb3\u5927\u5229\u4e9a\u3001\u54e5\u4f26\u6bd4\u4e9a\u548c\u7f8e\u56fd\u4e09\u4e2a\u56fd\u5bb6\u5728AI\u6cbb\u7406\u4e2d\u7684\u516c\u4f17\u53c2\u4e0e\u60c5\u51b5\uff0c\u53d1\u73b0\u653f\u5e9c\u672a\u80fd\u5efa\u7acb\u6709\u6548\u7684\u516c\u4f17\u5bf9\u8bdd\u673a\u5236\uff0c\u53c2\u4e0e\u7387\u6781\u4f4e\u4e14\u53cd\u9988\u54cd\u5e94\u4e0d\u8db3\uff0c\u5bfc\u81f4\u53c2\u4e0e\u5f0fAI\u6cbb\u7406\u7684\u627f\u8bfa\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u653f\u5e9c\u5982\u4f55\u901a\u8fc7\u516c\u4f17\u53c2\u4e0e\u6765\u5efa\u7acb\u5bf9AI\u53ca\u5176\u6cbb\u7406\u7684\u4fe1\u4efb\uff0c\u5206\u6790\u5f53\u524d\u516c\u4f17\u610f\u89c1\u5728AI\u653f\u7b56\u5236\u5b9a\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u666f\u89c2\u5206\u6790\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e09\u4e2a\u56fd\u5bb6\uff08\u6fb3\u5927\u5229\u4e9a\u3001\u54e5\u4f26\u6bd4\u4e9a\u3001\u7f8e\u56fd\uff09\u5f81\u96c6\u516c\u4f17\u5bf9AI\u98ce\u9669\u548c\u653f\u7b56\u7684\u53cd\u9988\u65b9\u5f0f\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u610f\u89c1\u5982\u4f55\u5f71\u54cd\u6cbb\u7406\u51b3\u7b56\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e09\u4e2a\u56fd\u5bb6\u90fd\u672a\u80fd\u5efa\u7acb\u6709\u610f\u4e49\u7684\u516c\u4f17\u5bf9\u8bdd\uff0c\u53c2\u4e0e\u7387\u5747\u4f4e\u4e8e\u4eba\u53e31%\uff0c\u653f\u5e9c\u7f3a\u4e4f\u591a\u6837\u58f0\u97f3\u5438\u5f15\u548c\u53cd\u9988\u54cd\u5e94\u673a\u5236\uff0c\u5bfc\u81f4\u53c2\u4e0e\u5f0f\u6cbb\u7406\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u5f53\u524dAI\u6cbb\u7406\u7684\u516c\u4f17\u53c2\u4e0e\u65b9\u6cd5\u65e0\u6cd5\u5efa\u7acb\u4fe1\u4efb\u6216\u5408\u6cd5\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u516b\u9879\u6539\u8fdb\u5efa\u8bae\uff0c\u5305\u62ec\u63d0\u5347AI\u7d20\u517b\u3001\u6269\u5927\u53c2\u4e0e\u8303\u56f4\u3001\u91c7\u7528\u521b\u65b0\u53c2\u4e0e\u65b9\u6cd5\u7b49\u3002"}}
{"id": "2510.20591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20591", "abs": "https://arxiv.org/abs/2510.20591", "authors": ["Ali Rajaei", "Peter Palensky", "Jochen L. Cremer"], "title": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting", "comment": null, "summary": "Network topology optimization (NTO) via busbar splitting can mitigate\ntransmission grid congestion and reduce redispatch costs. However, solving this\nmixed-integer non-linear problem for large-scale systems in near-real-time is\ncurrently intractable with existing solvers. Machine learning (ML) approaches\nhave emerged as a promising alternative, but they have limited generalization\nto unseen topologies, varying operating conditions, and different systems,\nwhich limits their practical applicability. This paper formulates NTO for\ncongestion management problem considering linearized AC PF, and proposes a\ngraph neural network (GNN)-accelerated approach. We develop a heterogeneous\nedge-aware message passing NN to predict effective busbar splitting actions as\ncandidate NTO solutions. The proposed GNN captures local flow patterns,\nachieves generalization to unseen topology changes, and improves\ntransferability across systems. Case studies show up to 4 orders-of-magnitude\nspeed-up, delivering AC-feasible solutions within one minute and a 2.3%\noptimality gap on the GOC 2000-bus system. These results demonstrate a\nsignificant step toward near-real-time NTO for large-scale systems with\ntopology and cross-system generalization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u7684\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bcd\u7ebf\u5206\u88c2\u7f13\u89e3\u7535\u7f51\u62e5\u585e\uff0c\u5728GOC 2000\u8282\u70b9\u7cfb\u7edf\u4e0a\u5b9e\u73b04\u4e2a\u6570\u91cf\u7ea7\u52a0\u901f\uff0c1\u5206\u949f\u5185\u63d0\u4f9bAC\u53ef\u884c\u89e3\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u4ec52.3%\u3002", "motivation": "\u73b0\u6709\u6c42\u89e3\u5668\u65e0\u6cd5\u5728\u8fd1\u5b9e\u65f6\u5185\u89e3\u51b3\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u95ee\u9898\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6cdb\u5316\u5230\u672a\u89c1\u62d3\u6251\u3001\u53d8\u5316\u8fd0\u884c\u6761\u4ef6\u548c\u4e0d\u540c\u7cfb\u7edf\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u5f00\u53d1\u5f02\u6784\u8fb9\u7f18\u611f\u77e5\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff0c\u9884\u6d4b\u6709\u6548\u7684\u6bcd\u7ebf\u5206\u88c2\u52a8\u4f5c\u4f5c\u4e3a\u5019\u9009\u62d3\u6251\u4f18\u5316\u89e3\uff0c\u8003\u8651\u7ebf\u6027\u5316AC\u6f6e\u6d41\uff0c\u6355\u6349\u5c40\u90e8\u6d41\u91cf\u6a21\u5f0f\u3002", "result": "\u5728GOC 2000\u8282\u70b9\u7cfb\u7edf\u4e0a\u5b9e\u73b04\u4e2a\u6570\u91cf\u7ea7\u52a0\u901f\uff0c1\u5206\u949f\u5185\u63d0\u4f9bAC\u53ef\u884c\u89e3\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u4ec52.3%\uff0c\u5c55\u793a\u4e86\u62d3\u6251\u548c\u8de8\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u5927\u89c4\u6a21\u7cfb\u7edf\u8fd1\u5b9e\u65f6\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5177\u6709\u62d3\u6251\u548c\u8de8\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.20603", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20603", "abs": "https://arxiv.org/abs/2510.20603", "authors": ["Heejin Do", "Jaehui Hwang", "Dongyoon Han", "Seong Joon Oh", "Sangdoo Yun"], "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "comment": null, "summary": "Evaluating large language models (LLMs) on final-answer correctness is the\ndominant paradigm. This approach, however, provides a coarse signal for model\nimprovement and overlooks the quality of the underlying reasoning process. We\nargue that a more granular evaluation of reasoning offers a more effective path\nto building robust models. We decompose reasoning quality into two dimensions:\nrelevance and coherence. Relevance measures if a step is grounded in the\nproblem; coherence measures if it follows logically from prior steps. To\nmeasure these aspects reliably, we introduce causal stepwise evaluation (CaSE).\nThis method assesses each reasoning step using only its preceding context,\nwhich avoids hindsight bias. We validate CaSE against human judgments on our\nnew expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we\nshow that curating training data with CaSE-evaluated relevance and coherence\ndirectly improves final task performance. Our work provides a scalable\nframework for analyzing, debugging, and improving LLM reasoning, demonstrating\nthe practical value of moving beyond validity checks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u56e0\u679c\u9010\u6b65\u8bc4\u4f30(CaSE)\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\u7684\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u6765\u6539\u8fdbLLM\u63a8\u7406\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u4ec5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u7684\u65b9\u6cd5\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6709\u6548\u7684\u6a21\u578b\u6539\u8fdb\u4fe1\u53f7\uff0c\u4e14\u5ffd\u89c6\u4e86\u5e95\u5c42\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\u3002", "method": "\u63d0\u51faCaSE\u65b9\u6cd5\uff0c\u5c06\u63a8\u7406\u8d28\u91cf\u5206\u89e3\u4e3a\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u901a\u8fc7\u4ec5\u4f7f\u7528\u524d\u5e8f\u4e0a\u4e0b\u6587\u8bc4\u4f30\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u6765\u907f\u514d\u540e\u89c1\u4e4b\u660e\u504f\u5dee\u3002", "result": "\u5728MRa-GSM8K\u548cMRa-MATH\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86CaSE\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u8bc1\u660e\u4f7f\u7528CaSE\u8bc4\u4f30\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u80fd\u76f4\u63a5\u63d0\u5347\u6700\u7ec8\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u6790\u3001\u8c03\u8bd5\u548c\u6539\u8fdbLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u8d85\u8d8a\u6709\u6548\u6027\u68c0\u67e5\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2510.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20604", "abs": "https://arxiv.org/abs/2510.20604", "authors": ["Changan Liu", "Zixuan Xie", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Algorithms for Computing Random Walk Centrality", "comment": "Accepted by TKDE", "summary": "Random walk centrality is a fundamental metric in graph mining for\nquantifying node importance and influence, defined as the weighted average of\nhitting times to a node from all other nodes. Despite its ability to capture\nrich graph structural information and its wide range of applications, computing\nthis measure for large networks remains impractical due to the computational\ndemands of existing methods. In this paper, we present a novel formulation of\nrandom walk centrality, underpinning two scalable algorithms: one leveraging\napproximate Cholesky factorization and sparse inverse estimation, while the\nother sampling rooted spanning trees. Both algorithms operate in near-linear\ntime and provide strong approximation guarantees. Extensive experiments on\nlarge real-world networks, including one with over 10 million nodes,\ndemonstrate the efficiency and approximation quality of the proposed\nalgorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u6765\u8ba1\u7b97\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u7f51\u7edc\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u80fd\u591f\u6355\u6349\u4e30\u5bcc\u7684\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u7f51\u7edc\u4e0a\u7684\u8ba1\u7b97\u7531\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8ba1\u7b97\u9700\u6c42\u800c\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u57fa\u4e8e\u65b0\u7684\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u516c\u5f0f\uff0c\u5f00\u53d1\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\u4e00\u79cd\u5229\u7528\u8fd1\u4f3cCholesky\u5206\u89e3\u548c\u7a00\u758f\u9006\u4f30\u8ba1\uff0c\u53e6\u4e00\u79cd\u91c7\u6837\u6839\u751f\u6210\u6811\u3002", "result": "\u5728\u5305\u62ec\u8d85\u8fc71000\u4e07\u4e2a\u8282\u70b9\u7684\u5927\u578b\u771f\u5b9e\u7f51\u7edc\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6548\u7387\u548c\u8fd1\u4f3c\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u8fd0\u884c\u5e76\u63d0\u4f9b\u5f3a\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u4f7f\u5927\u89c4\u6a21\u7f51\u7edc\u7684\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u8ba1\u7b97\u53d8\u5f97\u53ef\u884c\u3002"}}
{"id": "2510.20621", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20621", "abs": "https://arxiv.org/abs/2510.20621", "authors": ["Riccardo Guidotti", "Martina Cinquini", "Marta Marchiori Manerba", "Mattia Setzu", "Francesco Spinnato"], "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "comment": null, "summary": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.", "AI": {"tldr": "MIMOSA\u6846\u67b6\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u7684\u65b9\u6cd5\u8bba\uff0c\u65e8\u5728\u751f\u6210\u5e73\u8861\u53ef\u89e3\u91ca\u6027\u4e0e\u6027\u80fd\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u540c\u65f6\u5d4c\u5165\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u7b49\u5173\u952e\u4f26\u7406\u5c5e\u6027\u3002", "motivation": "\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u6a21\u578b\u5bf9\u4e8e\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5efa\u7acb\u5bf9\u81ea\u52a8\u5316\u51b3\u7b56\u6a21\u578b\u7684\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u5b89\u5168\u91c7\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\uff0c\u6db5\u76d6\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u3001\u56fe\u50cf\u3001\u6587\u672c\u7b49\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u5206\u6790\u4e86\u7279\u5f81\u91cd\u8981\u6027\u3001\u89c4\u5219\u548c\u5b9e\u4f8b\u4e09\u7c7b\u4e3b\u8981\u53ef\u89e3\u91ca\u6a21\u578b\u5bb6\u65cf\u3002", "result": "\u4e3a\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u63d0\u4f9b\u4e86\u6b63\u5f0f\u5b9a\u4e49\u3001\u8bc4\u4f30\u6307\u6807\u548c\u9a8c\u8bc1\u7a0b\u5e8f\uff0c\u5e76\u7814\u7a76\u4e86\u8fd9\u4e9b\u5c5e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u5728\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u4e2d\u8bc4\u4f30\u4f26\u7406\u5ea6\u91cf\uff0c\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u4e0d\u4ec5\u51c6\u786e\u548c\u53ef\u89e3\u91ca\uff0c\u800c\u4e14\u516c\u5e73\u3001\u4fdd\u62a4\u9690\u79c1\u548c\u5177\u6709\u56e0\u679c\u610f\u8bc6\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.20632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20632", "abs": "https://arxiv.org/abs/2510.20632", "authors": ["Shuyi Xie", "Ziqin Liew", "Hailing Zhang", "Haibo Zhang", "Ling Hu", "Zhiqiang Zhou", "Shuman Liu", "Anxiang Zeng"], "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "comment": null, "summary": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.", "AI": {"tldr": "EcomEval\u662f\u4e00\u4e2a\u5168\u9762\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u7535\u5b50\u5546\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d66\u4e2a\u7c7b\u522b37\u4e2a\u4efb\u52a1\uff0c\u5305\u62ec8\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u4f7f\u7528\u771f\u5b9e\u5ba2\u6237\u67e5\u8be2\u548c\u4ea4\u6613\u65e5\u5fd7\u6570\u636e\uff0c\u652f\u63017\u79cd\u8bed\u8a00\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u5546\u52a1\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u6a21\u6001\u5355\u4e00\u3001\u6570\u636e\u5408\u6210\u5316\u3001\u8bed\u8a00\u8986\u76d6\u7a84\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30LLM\u5728\u590d\u6742\u771f\u5b9e\u8d2d\u7269\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u534a\u81ea\u52a8\u6d41\u7a0b\uff1a\u5927\u6a21\u578b\u751f\u6210\u5019\u9009\u56de\u7b54\uff0c50\u591a\u540d\u7535\u5b50\u5546\u52a1\u548c\u591a\u8bed\u8a00\u4e13\u5bb6\u5ba1\u6838\u4fee\u6539\uff1b\u5b9a\u4e49\u96be\u5ea6\u7b49\u7ea7\uff1b\u8986\u76d67\u79cd\u8bed\u8a00\uff08\u5305\u62ec5\u79cd\u4e1c\u5357\u4e9a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff09\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u53cd\u6620\u771f\u5b9e\u4e1a\u52a1\u4ea4\u4e92\u566a\u58f0\u548c\u5f02\u8d28\u6027\u7684\u7efc\u5408\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u548c\u9762\u5411\u6311\u6218\u7684\u8bc4\u4f30\u3002", "conclusion": "EcomEval\u586b\u8865\u4e86\u7535\u5b50\u5546\u52a1\u9886\u57df\u8bc4\u4f30\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u590d\u6742\u8d2d\u7269\u573a\u666f\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2510.20636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20636", "abs": "https://arxiv.org/abs/2510.20636", "authors": ["Eric Ngoiya", "Tianshu Bao"], "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks", "comment": "12", "summary": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.", "AI": {"tldr": "\u63d0\u51fa\u4e86Fluidity Index (FI)\u6765\u8861\u91cf\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u8bc4\u4f30\u521d\u59cb\u3001\u5f53\u524d\u548c\u672a\u6765\u73af\u5883\u72b6\u6001\u504f\u5dee\u6765\u6d4b\u8bd5\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u8fde\u7eed\u6027\u80fd\u529b\u3002", "motivation": "\u9700\u8981\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u533a\u5206\u5c01\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f18\u5148\u4f7f\u7528\u95ed\u73af\u5f00\u653e\u5f0f\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6765\u8bc4\u4f30\u9002\u5e94\u6027\u3002", "method": "\u5f15\u5165Fluidity Index (FI)\u6307\u6807\uff0c\u57fa\u4e8e\u73af\u5883\u72b6\u6001\u504f\u5dee\u8bc4\u4f30\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u6d4b\u91cf\u6a21\u578b\u7406\u89e3\u3001\u9884\u6d4b\u548c\u9002\u5e94\u72b6\u6001\u53d8\u5316\u7684\u80fd\u529b\u3002", "result": "\u5efa\u7acb\u4e86\u8bc4\u4f30\u6a21\u578b\u9002\u5e94\u6027\u7684\u6846\u67b6\uff0c\u5f3a\u8c03\u771f\u6b63\u8d85\u7ea7\u667a\u80fd\u6a21\u578b\u5e94\u5177\u5907\u81f3\u5c11\u4e8c\u9636\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u6570\u5b57\u8865\u5145\u5b9e\u73b0\u81ea\u6301\u8ba1\u7b97\u4ee5\u8fbe\u5230\u6700\u4f73\u6d41\u52a8\u6027\u3002", "conclusion": "Fluidity Index\u4e3a\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u91cf\u5316\u6807\u51c6\uff0c\u8d85\u7ea7\u667a\u80fd\u6a21\u578b\u9700\u8981\u5177\u5907\u9ad8\u9636\u81ea\u9002\u5e94\u80fd\u529b\u4ee5\u7ef4\u6301\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2510.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20641", "abs": "https://arxiv.org/abs/2510.20641", "authors": ["Andrea Agiollo", "Andrea Omicini"], "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "comment": null, "summary": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5c06\u673a\u5668\u5b66\u4e60\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u68b3\u7406\uff0c\u4ee5BDI\u8303\u5f0f\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5206\u6790\u4e86\u76f8\u5173\u6587\u732e\u53d1\u5c55\uff0c\u5e76\u6307\u51fa\u4e86\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u7531\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u611f\u77e5\u548c\u8ba4\u77e5\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u7c7b\u4eba\u80fd\u529b\uff0c\u5c06ML\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u6846\u67b6\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u3002\u4f46\u76ee\u524d\u8be5\u9886\u57df\u7814\u7a76\u5206\u6563\u4e14\u4e0d\u8fde\u8d2f\uff0c\u5f80\u5f80\u53ea\u5173\u6ce8\u5c06ML\u5d4c\u5165\u901a\u7528\u667a\u80fd\u4f53\u5bb9\u5668\uff0c\u800c\u5ffd\u89c6\u4e86\u7406\u6027\u67b6\u6784\uff08\u5982BDI\u667a\u80fd\u4f53\uff09\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u4f7f\u7528BDI\u8303\u5f0f\u4f5c\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cfb\u7edf\u5316\u68b3\u7406\uff0c\u5206\u6790\u7406\u6027\u667a\u80fd\u4f53\u589e\u5f3aML\u7684\u5feb\u901f\u6f14\u8fdb\u6587\u732e\u3002", "result": "\u5206\u6790\u5c55\u793a\u4e86\u5c06ML\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u73b0\u6709\u65b9\u6cd5\u4f53\u7cfb\uff0c\u63ed\u793a\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u8d8b\u52bf\u3002", "conclusion": "\u8bc6\u522b\u4e86\u8bbe\u8ba1\u6709\u6548\u7406\u6027ML\u667a\u80fd\u4f53\u7684\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u6307\u5f15\u3002"}}
{"id": "2510.20665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20665", "abs": "https://arxiv.org/abs/2510.20665", "authors": ["Xue Wen Tan", "Nathaniel Tan", "Galen Lee", "Stanley Kok"], "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models", "comment": null, "summary": "Evaluating the quality of reasoning traces from large language models remains\nunderstudied, labor-intensive, and unreliable: current practice relies on\nexpert rubrics, manual annotation, and slow pairwise judgments. Automated\nefforts are dominated by graph-based proxies that quantify structural\nconnectivity but do not clarify what constitutes high-quality reasoning; such\nabstractions can be overly simplistic for inherently complex processes. We\nintroduce a topological data analysis (TDA)-based evaluation framework that\ncaptures the geometry of reasoning traces and enables label-efficient,\nautomated assessment. In our empirical study, topological features yield\nsubstantially higher predictive power for assessing reasoning quality than\nstandard graph metrics, suggesting that effective reasoning is better captured\nby higher-dimensional geometric structures rather than purely relational\ngraphs. We further show that a compact, stable set of topological features\nreliably indicates trace quality, offering a practical signal for future\nreinforcement learning algorithms.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u56fe\u6307\u6807\u5177\u6709\u66f4\u9ad8\u9884\u6d4b\u80fd\u529b", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u6807\u6ce8\uff0c\u52b3\u52a8\u5bc6\u96c6\u4e14\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u81ea\u52a8\u5316\u3001\u9ad8\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u4f7f\u7528\u62d3\u6251\u6570\u636e\u5206\u6790(TDA)\u6846\u67b6\u6355\u6349\u63a8\u7406\u8f68\u8ff9\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u901a\u8fc7\u62d3\u6251\u7279\u5f81\u8fdb\u884c\u81ea\u52a8\u5316\u8bc4\u4f30", "result": "\u62d3\u6251\u7279\u5f81\u5728\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u6bd4\u6807\u51c6\u56fe\u6307\u6807\u5177\u6709\u663e\u8457\u66f4\u9ad8\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8868\u660e\u6709\u6548\u63a8\u7406\u7531\u9ad8\u7ef4\u51e0\u4f55\u7ed3\u6784\u800c\u975e\u7eaf\u5173\u7cfb\u56fe\u66f4\u597d\u6355\u6349", "conclusion": "\u7d27\u51d1\u7a33\u5b9a\u7684\u62d3\u6251\u7279\u5f81\u96c6\u80fd\u53ef\u9760\u6307\u793a\u8f68\u8ff9\u8d28\u91cf\uff0c\u4e3a\u672a\u6765\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u5b9e\u7528\u4fe1\u53f7"}}
{"id": "2510.20691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20691", "abs": "https://arxiv.org/abs/2510.20691", "authors": ["Yanlin Song", "Ben Liu", "V\u00edctor Guti\u00e9rrez-Basulto", "Zhiwei Hu", "Qianqian Xie", "Min Peng", "Sophia Ananiadou", "Jeff Z. Pan"], "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs", "comment": null, "summary": "Knowledge Graph Question Answering aims to answer natural language questions\nby reasoning over structured knowledge graphs. While large language models have\nadvanced KGQA through their strong reasoning capabilities, existing methods\ncontinue to struggle to fully exploit both the rich knowledge encoded in KGs\nand the reasoning capabilities of LLMs, particularly in complex scenarios. They\noften assume complete KG coverage and lack mechanisms to judge when external\ninformation is needed, and their reasoning remains locally myopic, failing to\nmaintain coherent multi-step planning, leading to reasoning failures even when\nrelevant knowledge exists. We propose Graph-RFT, a novel two-stage\nreinforcement fine-tuning KGQA framework with a\n'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to\nperform autonomous planning and adaptive retrieval scheduling across KG and web\nsources under incomplete knowledge conditions. Graph-RFT introduces a\nchain-of-thought fine-tuning method with a customized plan-retrieval dataset\nactivates structured reasoning and resolves the GRPO cold-start problem. It\nthen introduces a novel plan-retrieval guided reinforcement learning process\nintegrates explicit planning and retrieval actions with a multi-reward design,\nenabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired\nplanning module to decompose complex questions into ordered subquestions, and\nlogical expression to guide tool invocation for globally consistent multi-step\nreasoning. This reasoning retrieval process is optimized with a multi-reward\ncombining outcome and retrieval specific signals, enabling the model to learn\nwhen and how to combine KG and web retrieval effectively.", "AI": {"tldr": "Graph-RFT\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03KGQA\u6846\u67b6\uff0c\u901a\u8fc7\"\u8ba1\u5212-KG\u641c\u7d22-\u7f51\u7edc\u641c\u7d22-\u601d\u8003\"\u8303\u5f0f\uff0c\u8ba9LLM\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u6761\u4ef6\u4e0b\u81ea\u4e3b\u89c4\u5212\u5e76\u81ea\u9002\u5e94\u8c03\u5ea6KG\u548c\u7f51\u7edc\u68c0\u7d22\u3002", "motivation": "\u73b0\u6709KGQA\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u5229\u7528KG\u4e30\u5bcc\u77e5\u8bc6\u548cLLM\u63a8\u7406\u80fd\u529b\uff0c\u5047\u8bbeKG\u8986\u76d6\u5b8c\u6574\u4e14\u7f3a\u4e4f\u5224\u65ad\u4f55\u65f6\u9700\u8981\u5916\u90e8\u4fe1\u606f\u7684\u673a\u5236\uff0c\u63a8\u7406\u8fc7\u7a0b\u5c40\u90e8\u77ed\u89c6\uff0c\u65e0\u6cd5\u7ef4\u6301\u8fde\u8d2f\u7684\u591a\u6b65\u89c4\u5212\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u94fe\u5f0f\u601d\u7ef4\u5fae\u8c03\u6fc0\u6d3b\u7ed3\u6784\u5316\u63a8\u7406\uff1b2) \u8ba1\u5212\u68c0\u7d22\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u96c6\u6210\u663e\u5f0f\u89c4\u5212\u548c\u68c0\u7d22\u52a8\u4f5c\uff0c\u91c7\u7528\u7b1b\u5361\u5c14\u5f0f\u89c4\u5212\u6a21\u5757\u5206\u89e3\u590d\u6742\u95ee\u9898\uff0c\u903b\u8f91\u8868\u8fbe\u5f0f\u6307\u5bfc\u5de5\u5177\u8c03\u7528\u3002", "result": "\u901a\u8fc7\u591a\u5956\u52b1\u8bbe\u8ba1\u4f18\u5316\u63a8\u7406\u68c0\u7d22\u8fc7\u7a0b\uff0c\u7ed3\u5408\u7ed3\u679c\u548c\u68c0\u7d22\u7279\u5b9a\u4fe1\u53f7\uff0c\u4f7f\u6a21\u578b\u5b66\u4e60\u4f55\u65f6\u53ca\u5982\u4f55\u6709\u6548\u7ed3\u5408KG\u548c\u7f51\u7edc\u68c0\u7d22\u3002", "conclusion": "Graph-RFT\u89e3\u51b3\u4e86GRPO\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8986\u76d6\u611f\u77e5\u7684\u68c0\u7d22\u8c03\u5ea6\u548c\u5168\u5c40\u4e00\u81f4\u7684\u591a\u6b65\u63a8\u7406\u3002"}}
{"id": "2510.20784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20784", "abs": "https://arxiv.org/abs/2510.20784", "authors": ["Fares Fourati"], "title": "A Coherence-Based Measure of AGI", "comment": "13 pages, 1 figure, 12 tables", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u7684\u4e00\u81f4\u6027\u611f\u77e5AGI\u5ea6\u91cf\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4e86\u4f20\u7edf\u7b97\u672f\u5e73\u5747\u65b9\u6cd5\uff0c\u80fd\u591f\u60e9\u7f5a\u80fd\u529b\u4e0d\u5e73\u8861\u5e76\u6355\u6349\u9886\u57df\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709AGI\u5b9a\u4e49\u57fa\u4e8eCHC\u8ba4\u77e5\u6a21\u578b\u7684\u7b97\u672f\u5e73\u5747\uff0c\u5047\u8bbe\u80fd\u529b\u53ef\u8865\u507f\u6027\uff0c\u4f46\u771f\u6b63\u7684\u901a\u7528\u667a\u80fd\u5e94\u8be5\u53cd\u6620\u5728\u6240\u6709\u5173\u952e\u9886\u57df\u7684\u5e73\u8861\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5e7f\u4e49\u5747\u503c\u5728\u8865\u507f\u6027\u6307\u6570\u8fde\u7eed\u7edf\u4e0a\u7684\u79ef\u5206\u4f5c\u4e3aAGI\u5ea6\u91cf\uff0c\u6db5\u76d6\u7b97\u672f\u3001\u51e0\u4f55\u548c\u8c03\u548c\u5747\u503c\u7b49\u4e0d\u540c\u8865\u507f\u6027\u5047\u8bbe\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5e94\u7528\u4e8eGPT-4\u548cGPT-5\u7684CHC\u9886\u57df\u5f97\u5206\u663e\u793a\uff0c\u5c3d\u7ba1\u7b97\u672f\u5f97\u5206\u8f83\u9ad8\uff08\u5982GPT-5\u8fbe24%\uff09\uff0c\u4f46\u4e00\u81f4\u6027\u8c03\u6574\u540e\u7684AUC\u8868\u660e\u4e24\u8005\u8ddd\u79bb\u901a\u7528\u80fd\u529b\u8fd8\u5f88\u8fdc\u3002", "conclusion": "\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u4e3aAGI\u6d4b\u91cf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u4e25\u683c\u7684\u57fa\u7840\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5411AGI\u7684\u771f\u6b63\u8fdb\u5c55\u3002"}}
{"id": "2510.20809", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20809", "abs": "https://arxiv.org/abs/2510.20809", "authors": ["Xueyan Zou", "Jianglong Ye", "Hao Zhang", "Xiaoyu Xiang", "Mingyu Ding", "Zhaojing Yang", "Yong Jae Lee", "Zhuowen Tu", "Sifei Liu", "Xiaolong Wang"], "title": "Real Deep Research for AI, Robotics and Beyond", "comment": "website: https://realdeepresearch.github.io", "summary": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.", "AI": {"tldr": "\u63d0\u51fa\u4e86Real Deep Research (RDR)\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790AI\u548c\u673a\u5668\u4eba\u9886\u57df\u7684\u7814\u7a76\u8d8b\u52bf\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\u548c\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5e94\u5bf9\u6bcf\u5e74\u4e0a\u4e07\u7bc7\u8bba\u6587\u7684\u6311\u6218\u3002", "motivation": "AI\u548c\u673a\u5668\u4eba\u9886\u57df\u6bcf\u5e74\u4ea7\u751f\u8d85\u8fc710,000\u7bc7\u8bba\u6587\uff0c\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684\u8d8b\u52bf\u3001\u8de8\u5b66\u79d1\u5de5\u4f5c\u548c\u63a2\u7d22\u65b0\u9886\u57df\u7684\u9700\u6c42\u3002", "method": "\u6784\u5efa\u4e86\u901a\u7528\u7684RDR\u7ba1\u9053\uff0c\u80fd\u591f\u7cfb\u7edf\u5206\u6790\u4efb\u4f55\u7814\u7a76\u9886\u57df\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\uff0c\u53d1\u73b0\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u5e76\u4e3a\u65b0\u7814\u7a76\u63d0\u4f9b\u5177\u4f53\u8d77\u70b9\u3002", "result": "\u5c06RDR\u6846\u67b6\u5e94\u7528\u4e8eAI\u548c\u673a\u5668\u4eba\u9886\u57df\uff0c\u7279\u522b\u5173\u6ce8\u57fa\u7840\u6a21\u578b\u548c\u673a\u5668\u4eba\u6280\u672f\u8fdb\u6b65\uff0c\u5e76\u6269\u5c55\u5230\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "RDR\u6846\u67b6\u4e3aAI\u53ca\u5176\u4ed6\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5206\u6790\u5de5\u5177\uff0c\u5e2e\u52a9\u4ed6\u4eec\u5728\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u73af\u5883\u4e2d\u4fdd\u6301\u66f4\u65b0\u548c\u53d1\u73b0\u65b0\u673a\u4f1a\u3002"}}
