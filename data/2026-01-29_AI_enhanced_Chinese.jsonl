{"id": "2601.20229", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20229", "abs": "https://arxiv.org/abs/2601.20229", "authors": ["Parisa Fard Moshiri", "Poonam Lohan", "Burak Kantarci", "Emil Janulewicz"], "title": "Proactive SFC Provisioning with Forecast-Driven DRL in Data Centers", "comment": "6 pages, 3 figures, Accepted to IEEE International Conference on Communications (ICC) 2026", "summary": "Service Function Chaining (SFC) requires efficient placement of Virtual Network Functions (VNFs) to satisfy diverse service requirements while maintaining high resource utilization in Data Centers (DCs). Conventional static resource allocation often leads to overprovisioning or underprovisioning due to the dynamic nature of traffic loads and application demands. To address this challenge, we propose a hybrid forecast-driven Deep reinforcement learning (DRL) framework that combines predictive intelligence with SFC provisioning. Specifically, we leverage DRL to generate datasets capturing DC resource utilization and service demands, which are then used to train deep learning forecasting models. Using Optuna-based hyperparameter optimization, the best-performing models, Spatio-Temporal Graph Neural Network, Temporal Graph Neural Network, and Long Short-Term Memory, are combined into an ensemble to enhance stability and accuracy. The ensemble predictions are integrated into the DC selection process, enabling proactive placement decisions that consider both current and future resource availability. Experimental results demonstrate that the proposed method not only sustains high acceptance ratios for resource-intensive services such as Cloud Gaming and VoIP but also significantly improves acceptance ratios for latency-critical categories such as Augmented Reality increases from 30% to 50%, while Industry 4.0 improves from 30% to 45%. Consequently, the prediction-based model achieves significantly lower E2E latencies of 20.5%, 23.8%, and 34.8% reductions for VoIP, Video Streaming, and Cloud Gaming, respectively. This strategy ensures more balanced resource allocation, and reduces contention.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u9884\u6d4b\u9a71\u52a8\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u9884\u6d4b\u667a\u80fd\u4e0eSFC\u914d\u7f6e\uff0c\u901a\u8fc7\u96c6\u6210\u9884\u6d4b\u6a21\u578b\u5b9e\u73b0\u4e3b\u52a8\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u670d\u52a1\u63a5\u53d7\u7387\u5e76\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u8d44\u6e90\u5206\u914d\u5728\u52a8\u6001\u6d41\u91cf\u8d1f\u8f7d\u548c\u5e94\u7528\u9700\u6c42\u4e0b\u5bb9\u6613\u5bfc\u81f4\u8d44\u6e90\u8fc7\u5ea6\u914d\u7f6e\u6216\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6570\u636e\u4e2d\u5fc3\u4e2d\u670d\u52a1\u529f\u80fd\u94fe\u5bf9\u9ad8\u6548\u865a\u62df\u7f51\u7edc\u529f\u80fd\u653e\u7f6e\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u6570\u636e\u4e2d\u5fc3\u8d44\u6e90\u5229\u7528\u548c\u670d\u52a1\u9700\u6c42\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7Optuna\u8d85\u53c2\u6570\u4f18\u5316\u9009\u62e9\u6700\u4f73\u6a21\u578b\uff08\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u65f6\u5e8f\u56fe\u795e\u7ecf\u7f51\u7edc\u3001LSTM\uff09\u6784\u5efa\u96c6\u6210\u6a21\u578b\uff0c\u5c06\u9884\u6d4b\u7ed3\u679c\u6574\u5408\u5230\u6570\u636e\u4e2d\u5fc3\u9009\u62e9\u8fc7\u7a0b\u4e2d\u3002", "result": "\u663e\u8457\u63d0\u5347\u8d44\u6e90\u5bc6\u96c6\u578b\u670d\u52a1\uff08\u4e91\u6e38\u620f\u3001VoIP\uff09\u7684\u63a5\u53d7\u7387\uff0c\u5ef6\u8fdf\u654f\u611f\u670d\u52a1\uff08\u589e\u5f3a\u73b0\u5b9e\u4ece30%\u63d0\u5347\u81f350%\uff0c\u5de5\u4e1a4.0\u4ece30%\u63d0\u5347\u81f345%\uff09\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\uff08VoIP\u964d\u4f4e20.5%\uff0c\u89c6\u9891\u6d41\u964d\u4f4e23.8%\uff0c\u4e91\u6e38\u620f\u964d\u4f4e34.8%\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684\u9884\u6d4b\u9a71\u52a8\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u66f4\u5e73\u8861\u7684\u8d44\u6e90\u5206\u914d\uff0c\u51cf\u5c11\u8d44\u6e90\u4e89\u7528\uff0c\u901a\u8fc7\u8003\u8651\u5f53\u524d\u548c\u672a\u6765\u8d44\u6e90\u53ef\u7528\u6027\u505a\u51fa\u4e3b\u52a8\u653e\u7f6e\u51b3\u7b56\uff0c\u6709\u6548\u63d0\u5347\u6570\u636e\u4e2d\u5fc3\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002"}}
{"id": "2601.20580", "categories": ["cs.NI", "cs.ET", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20580", "abs": "https://arxiv.org/abs/2601.20580", "authors": ["Nurul Huda Mahmood", "Onel L. A. Lopez", "David Ruiz-Guirola", "Frank Burkhardt", "Mehdi Rasti", "Matti Latva-aho"], "title": "Dependable Connectivity for Industrial Wireless Communication Networks", "comment": "Submitted to IEEE Network Magazine for possible publication", "summary": "Dependability - a system's ability to consistently provide reliable services by ensuring safety and maintainability in the face of internal or external disruptions - is a fundamental requirement for industrial wireless communication networks (IWCNs). While 5G ultra-reliable low-latency communication (URLLC) addresses some aspects of this challenge, its evolution toward holistic dependability in 6G must encompass reliability, availability, safety, and security. This paper provides a comprehensive framework for dependable IWCNs, bridging theory and practice. We first establish the theoretical foundations of dependability, including outlining its key attributes and presenting analytical tools to study it. Next, we explore practical enablers, such as adaptive multiple access schemes leveraging real-time monitoring and time-sensitive networking to ensure end-to-end determinism. A case study demonstrates how intelligent wake-up protocols improve event detection probability by orders of magnitude compared to conventional duty cycling. Finally, we outline open challenges and future directions for a 6G-driven dependable IWCN.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u54116G\u5de5\u4e1a\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u7684\u5168\u9762\u53ef\u9760\u6027\u6846\u67b6\uff0c\u6db5\u76d6\u7406\u8bba\u57fa\u7840\u3001\u5b9e\u8df5\u4f7f\u80fd\u6280\u672f\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5de5\u4e1a\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u9700\u8981\u9ad8\u53ef\u9760\u6027\uff08\u5305\u62ec\u5b89\u5168\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u7b49\uff09\uff0c\u800c5G URLLC\u4ec5\u90e8\u5206\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u30026G\u9700\u8981\u5b9e\u73b0\u5305\u542b\u53ef\u9760\u6027\u3001\u53ef\u7528\u6027\u3001\u5b89\u5168\u6027\u548c\u5b89\u5168\u6027\u7684\u5168\u9762\u53ef\u9760\u6027\u3002", "method": "1. \u5efa\u7acb\u53ef\u9760\u6027\u7406\u8bba\u57fa\u7840\uff0c\u5305\u62ec\u5173\u952e\u5c5e\u6027\u548c\u5206\u6790\u5de5\u5177\uff1b2. \u63a2\u7d22\u5b9e\u8df5\u4f7f\u80fd\u6280\u672f\uff0c\u5982\u57fa\u4e8e\u5b9e\u65f6\u76d1\u63a7\u7684\u81ea\u9002\u5e94\u591a\u5740\u63a5\u5165\u65b9\u6848\u548c\u65f6\u95f4\u654f\u611f\u7f51\u7edc\uff1b3. \u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u667a\u80fd\u5524\u9192\u534f\u8bae\u76f8\u6bd4\u4f20\u7edf\u5360\u7a7a\u6bd4\u5faa\u73af\u7684\u663e\u8457\u4f18\u52bf\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u53ef\u9760\u6027\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8868\u660e\u667a\u80fd\u5524\u9192\u534f\u8bae\u80fd\u5c06\u4e8b\u4ef6\u68c0\u6d4b\u6982\u7387\u63d0\u9ad8\u6570\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8bba\u6587\u4e3a6G\u9a71\u52a8\u7684\u53ef\u9760\u5de5\u4e1a\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u5f00\u653e\u6311\u6218\u548c\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.20625", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.20625", "abs": "https://arxiv.org/abs/2601.20625", "authors": ["Yao Wen", "Luping Xiang", "Kun Yang"], "title": "Immersive Volumetric Video Playback: Near-RT Resource Allocation and O-RAN-based Implementation", "comment": null, "summary": "Immersive volumetric video streaming in extended reality (XR) demands ultra-low motion-to-photon (MTP) latency, which conventional edge-centric architectures struggle to meet due to per-frame computationally intensive rendering tightly coupled with user motion. To address this challenge, we propose an Open Radio Access Network (O-RAN)-integrated playback framework that jointly orchestrates radio, compute, and content resources in near real time (Near-RT) control loop. The system formulates the rendered-pixel ratio as a continuous control variable and jointly optimizes it over the Open Cloud (O-Cloud) compute, gNB transmit power, and bandwidth under a Weber-Fechner quality of experience (QoE) model, explicitly balancing resolution, computation, and latency. A Soft Actor-Critic (SAC) agent with structured action decomposition and QoE-aware reward shaping resolves the resulting high-dimensional control problem. Experiments on a 5G O-RAN testbed and system simulations show that SAC reduces median MTP latency by above $11\\%$ and improves both mean QoE and fairness, demonstrating the feasibility of RIC-driven joint radio-compute-content control for scalable, latency-aware immersive streaming.", "AI": {"tldr": "\u57fa\u4e8eO-RAN\u7684\u6c89\u6d78\u5f0f\u89c6\u9891\u6d41\u64ad\u653e\u6846\u67b6\uff0c\u901a\u8fc7SAC\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u65e0\u7ebf\u3001\u8ba1\u7b97\u548c\u5185\u5bb9\u8d44\u6e90\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u5347QoE", "motivation": "\u6269\u5c55\u73b0\u5b9e(XR)\u4e2d\u7684\u6c89\u6d78\u5f0f\u4f53\u89c6\u9891\u6d41\u9700\u8981\u8d85\u4f4e\u8fd0\u52a8\u5230\u5149\u5b50(MTP)\u5ef6\u8fdf\uff0c\u4f20\u7edf\u8fb9\u7f18\u8ba1\u7b97\u67b6\u6784\u96be\u4ee5\u6ee1\u8db3\uff0c\u56e0\u4e3a\u6bcf\u5e27\u8ba1\u7b97\u5bc6\u96c6\u7684\u6e32\u67d3\u4e0e\u7528\u6237\u8fd0\u52a8\u7d27\u5bc6\u8026\u5408", "method": "\u63d0\u51faO-RAN\u96c6\u6210\u64ad\u653e\u6846\u67b6\uff0c\u5728\u8fd1\u5b9e\u65f6\u63a7\u5236\u5faa\u73af\u4e2d\u8054\u5408\u7f16\u6392\u65e0\u7ebf\u3001\u8ba1\u7b97\u548c\u5185\u5bb9\u8d44\u6e90\u3002\u5c06\u6e32\u67d3\u50cf\u7d20\u6bd4\u4f5c\u4e3a\u8fde\u7eed\u63a7\u5236\u53d8\u91cf\uff0c\u5728O-Cloud\u8ba1\u7b97\u3001gNB\u53d1\u5c04\u529f\u7387\u548c\u5e26\u5bbd\u4e0b\u8054\u5408\u4f18\u5316\uff0c\u91c7\u7528Weber-Fechner QoE\u6a21\u578b\u5e73\u8861\u5206\u8fa8\u7387\u3001\u8ba1\u7b97\u548c\u5ef6\u8fdf\u3002\u4f7f\u7528\u5177\u6709\u7ed3\u6784\u5316\u52a8\u4f5c\u5206\u89e3\u548cQoE\u611f\u77e5\u5956\u52b1\u5851\u9020\u7684SAC\u7b97\u6cd5\u89e3\u51b3\u9ad8\u7ef4\u63a7\u5236\u95ee\u9898", "result": "\u57285G O-RAN\u6d4b\u8bd5\u5e8a\u548c\u7cfb\u7edf\u4eff\u771f\u4e2d\uff0cSAC\u7b97\u6cd5\u5c06\u4e2d\u4f4d\u6570MTP\u5ef6\u8fdf\u964d\u4f4e11%\u4ee5\u4e0a\uff0c\u540c\u65f6\u63d0\u9ad8\u5e73\u5747QoE\u548c\u516c\u5e73\u6027", "conclusion": "RIC\u9a71\u52a8\u7684\u8054\u5408\u65e0\u7ebf-\u8ba1\u7b97-\u5185\u5bb9\u63a7\u5236\u5bf9\u4e8e\u53ef\u6269\u5c55\u3001\u5ef6\u8fdf\u611f\u77e5\u7684\u6c89\u6d78\u5f0f\u6d41\u5a92\u4f53\u662f\u53ef\u884c\u7684"}}
{"id": "2601.20022", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20022", "abs": "https://arxiv.org/abs/2601.20022", "authors": ["Amir Reza Ramtin", "Philippe Nain", "Don Towsley"], "title": "Quick Change Detection in Discrete-Time in Presence of a Covert Adversary", "comment": null, "summary": "We study the problem of covert quickest change detection in a discrete-time setting, where a sequence of observations undergoes a distributional change at an unknown time. Unlike classical formulations, we consider a covert adversary who has knowledge of the detector's false alarm constraint parameter $\u03b3$ and selects a stationary post-change distribution that depends on it, seeking to remain undetected for as long as possible. Building on the theoretical foundations of the CuSum procedure, we rigorously characterize the asymptotic behavior of the average detection delay (ADD) and the average time to false alarm (AT2FA) when the post-change distribution converges to the pre-change distribution as $\u03b3\\to \\infty$. Our analysis establishes exact asymptotic expressions for these quantities, extending and refining classical results that no longer hold in this regime. We identify the critical scaling laws governing covert behavior and derive explicit conditions under which an adversary can maintain covertness, defined by ADD = $\u0398(\u03b3)$, whereas in the classical setting, ADD grows only as $\\mathcal{O}(\\log \u03b3)$. In particular, for Gaussian and Exponential models under adversarial perturbations of their respective parameters, we asymptotically characterize ADD as a function of the Kullback--Leibler divergence between the pre- and post-change distributions and $\u03b3$.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9690\u853d\u6700\u5feb\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\uff0c\u5176\u4e2d\u5bf9\u624b\u77e5\u9053\u68c0\u6d4b\u5668\u7684\u865a\u8b66\u7ea6\u675f\u53c2\u6570\u03b3\uff0c\u5e76\u9009\u62e9\u4f9d\u8d56\u4e8e\u03b3\u7684\u5e73\u7a33\u540e\u53d8\u5316\u5206\u5e03\u4ee5\u5c3d\u53ef\u80fd\u957f\u65f6\u95f4\u4e0d\u88ab\u68c0\u6d4b\u3002\u5f53\u540e\u53d8\u5316\u5206\u5e03\u968f\u03b3\u2192\u221e\u6536\u655b\u4e8e\u524d\u53d8\u5316\u5206\u5e03\u65f6\uff0c\u4f5c\u8005\u5efa\u7acb\u4e86\u5e73\u5747\u68c0\u6d4b\u5ef6\u8fdf(ADD)\u548c\u5e73\u5747\u865a\u8b66\u65f6\u95f4(AT2FA)\u7684\u7cbe\u786e\u6e10\u8fd1\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u9690\u853d\u884c\u4e3a\u7684\u5173\u952e\u7f29\u653e\u89c4\u5f8b\u3002", "motivation": "\u7ecf\u5178\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\u5047\u8bbe\u540e\u53d8\u5316\u5206\u5e03\u56fa\u5b9a\uff0c\u4f46\u5b9e\u9645\u4e2d\u5bf9\u624b\u53ef\u80fd\u77e5\u9053\u68c0\u6d4b\u5668\u53c2\u6570\u5e76\u8c03\u6574\u7b56\u7565\u3002\u672c\u6587\u7814\u7a76\u9690\u853d\u5bf9\u624b\u573a\u666f\uff0c\u5bf9\u624b\u77e5\u9053\u865a\u8b66\u7ea6\u675f\u53c2\u6570\u03b3\u5e76\u9009\u62e9\u4f9d\u8d56\u4e8e\u03b3\u7684\u540e\u53d8\u5316\u5206\u5e03\uff0c\u65e8\u5728\u5c3d\u53ef\u80fd\u957f\u65f6\u95f4\u4e0d\u88ab\u68c0\u6d4b\uff0c\u8fd9\u6bd4\u7ecf\u5178\u95ee\u9898\u66f4\u5177\u6311\u6218\u6027\u3002", "method": "\u57fa\u4e8eCuSum\u8fc7\u7a0b\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5f53\u540e\u53d8\u5316\u5206\u5e03\u968f\u03b3\u2192\u221e\u6536\u655b\u4e8e\u524d\u53d8\u5316\u5206\u5e03\u65f6\uff0c\u4e25\u683c\u5206\u6790\u5e73\u5747\u68c0\u6d4b\u5ef6\u8fdf(ADD)\u548c\u5e73\u5747\u865a\u8b66\u65f6\u95f4(AT2FA)\u7684\u6e10\u8fd1\u884c\u4e3a\u3002\u63a8\u5bfc\u7cbe\u786e\u6e10\u8fd1\u8868\u8fbe\u5f0f\uff0c\u8bc6\u522b\u9690\u853d\u884c\u4e3a\u7684\u5173\u952e\u7f29\u653e\u89c4\u5f8b\u3002\u7279\u522b\u9488\u5bf9\u9ad8\u65af\u548c\u6307\u6570\u6a21\u578b\uff0c\u5728\u53c2\u6570\u5bf9\u6297\u6270\u52a8\u4e0b\uff0c\u7528Kullback-Leibler\u6563\u5ea6\u8868\u5f81ADD\u7684\u6e10\u8fd1\u884c\u4e3a\u3002", "result": "\u5efa\u7acb\u4e86ADD\u548cAT2FA\u7684\u7cbe\u786e\u6e10\u8fd1\u8868\u8fbe\u5f0f\uff0c\u6269\u5c55\u5e76\u6539\u8fdb\u4e86\u7ecf\u5178\u7ed3\u679c\u3002\u53d1\u73b0\u9690\u853d\u884c\u4e3a\u4e0bADD\u6309\u0398(\u03b3)\u589e\u957f\uff0c\u800c\u7ecf\u5178\u8bbe\u7f6e\u4e2dADD\u4ec5\u4e3aO(log \u03b3)\u3002\u63a8\u5bfc\u4e86\u5bf9\u624b\u80fd\u591f\u4fdd\u6301\u9690\u853d\u6027\u7684\u660e\u786e\u6761\u4ef6\uff0c\u5373ADD = \u0398(\u03b3)\u3002\u5bf9\u4e8e\u9ad8\u65af\u548c\u6307\u6570\u6a21\u578b\uff0c\u7528KL\u6563\u5ea6\u6e10\u8fd1\u8868\u5f81\u4e86ADD\u4f5c\u4e3a\u524d/\u540e\u53d8\u5316\u5206\u5e03\u5dee\u5f02\u548c\u03b3\u7684\u51fd\u6570\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u9690\u853d\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\u7684\u6839\u672c\u4e0d\u540c\u884c\u4e3a\uff1a\u5f53\u5bf9\u624b\u77e5\u9053\u68c0\u6d4b\u5668\u53c2\u6570\u5e76\u8c03\u6574\u7b56\u7565\u65f6\uff0c\u68c0\u6d4b\u5ef6\u8fdf\u53ef\u80fd\u7ebf\u6027\u589e\u957f\u800c\u975e\u5bf9\u6570\u589e\u957f\u3002\u8fd9\u4e3a\u7406\u89e3\u5bf9\u6297\u6027\u73af\u5883\u4e0b\u7684\u53d8\u5316\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5bf9\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.19955", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.19955", "abs": "https://arxiv.org/abs/2601.19955", "authors": ["Jean-Marc Fellous", "Gert Cauwenberghs", "Cornelia Ferm\u00fcller", "Yulia Sandamisrkaya", "Terrence Sejnowski"], "title": "NeuroAI and Beyond", "comment": "53 pages, 5 figures, extended appendix", "summary": "Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8e2025\u5e748\u6708\u7814\u8ba8\u4f1a\uff0c\u63a2\u8ba8\u795e\u7ecf\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u4ea4\u53c9\u9886\u57df\uff0c\u63d0\u51faNeuroAI\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u6539\u8fdbAI\u7b97\u6cd5\uff0c\u540c\u65f6\u6df1\u5316\u5bf9\u751f\u7269\u795e\u7ecf\u8ba1\u7b97\u7684\u7406\u89e3\u3002", "motivation": "\u795e\u7ecf\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u8fd1\u5e74\u6765\u5404\u81ea\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e24\u8005\u4e4b\u95f4\u7684\u8fde\u63a5\u76f8\u5bf9\u677e\u6563\u3002\u8bba\u6587\u65e8\u5728\u8bc6\u522b\u8fd9\u4e24\u4e2a\u9886\u57df\u5f53\u524d\u548c\u672a\u6765\u7684\u534f\u540c\u6f5c\u529b\uff0c\u4fc3\u8fdb\u66f4\u7d27\u5bc6\u7684\u4ea4\u53c9\u878d\u5408\u3002", "method": "\u57fa\u4e8e2025\u5e748\u6708\u4e3e\u529e\u7684\u7814\u8ba8\u4f1a\uff0c\u805a\u7126\u4e8e\u5177\u8eab\u8ba4\u77e5\u3001\u8bed\u8a00\u4e0e\u901a\u4fe1\u3001\u673a\u5668\u4eba\u5b66\u3001\u4eba\u7c7b\u4e0e\u673a\u5668\u5b66\u4e60\u4ee5\u53ca\u795e\u7ecf\u5f62\u6001\u5de5\u7a0b\u7b49\u5b50\u9886\u57df\uff0c\u5206\u6790\u73b0\u6709\u8fdb\u5c55\u5e76\u63a2\u7d22\u672a\u6765\u65b9\u5411\u3002\u6536\u96c6\u4e86\u591a\u4f4d\u9886\u5148\u7814\u7a76\u4eba\u5458\u7684\u4e2a\u4eba\u89c2\u70b9\uff0c\u5e76\u9644\u6709\u7814\u7a76\u4eba\u5458\u548c\u5b66\u5458\u7684SWOT\u5206\u6790\u3002", "result": "\u63d0\u51fa\u4e86NeuroAI\uff08\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u4eba\u5de5\u667a\u80fd\uff09\u6982\u5ff5\u6846\u67b6\uff0c\u8ba4\u4e3a\u8fd9\u79cd\u4ea4\u53c9\u65b9\u6cd5\u65e2\u80fd\u663e\u8457\u63d0\u5347AI\u7b97\u6cd5\u7684\u8303\u56f4\u548c\u6548\u7387\uff0c\u53c8\u80fd\u6539\u53d8\u5bf9\u751f\u7269\u795e\u7ecf\u8ba1\u7b97\u7684\u7406\u89e3\u65b9\u5f0f\u3002\u901a\u8fc7SWOT\u5206\u6790\u8bc4\u4f30\u4e86NeuroAI\u7684\u76ca\u5904\u548c\u98ce\u9669\u3002", "conclusion": "\u5021\u5bfc\u53d1\u5c55NeuroAI\uff0c\u901a\u8fc7\u795e\u7ecf\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u7684\u6df1\u5ea6\u878d\u5408\uff0c\u5b9e\u73b0\u53cc\u5411\u53d7\u76ca\uff1aAI\u4ece\u795e\u7ecf\u79d1\u5b66\u4e2d\u83b7\u5f97\u7075\u611f\u63d0\u5347\u6027\u80fd\uff0c\u795e\u7ecf\u79d1\u5b66\u5219\u901a\u8fc7AI\u6a21\u578b\u66f4\u597d\u5730\u7406\u89e3\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u3002"}}
{"id": "2601.20411", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20411", "abs": "https://arxiv.org/abs/2601.20411", "authors": ["Luiz F. da S. Coelho", "Didier Le Ruyet", "Paulo S. R. Diniz"], "title": "On Efficient Polyphase Network Implementation Using Successive Vector Approximation", "comment": "6 pages", "summary": "In this work, we explore an energy-efficient implementation of the polyphase network for a filter bank multicarrier (FBMC) system. The network is approximated using a greedy algorithm based on matching pursuits (MP) that converts the numerical representation directly from floating point to sum of signed powers of two (SOPOT), which is key for a multiplierless implementation. We compare this technique with other state-of-the-art methods for designing multiplierless hardware, and show that our technique achieves superior performance with similar computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5339\u914d\u8ffd\u8e2a\u7684\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u5c06FBMC\u7cfb\u7edf\u7684\u591a\u76f8\u7f51\u7edc\u4ece\u6d6e\u70b9\u6570\u76f4\u63a5\u8f6c\u6362\u4e3aSOPOT\u8868\u793a\uff0c\u5b9e\u73b0\u65e0\u4e58\u6cd5\u5668\u7684\u80fd\u91cf\u9ad8\u6548\u786c\u4ef6\u5b9e\u73b0\u3002", "motivation": "FBMC\u7cfb\u7edf\u9700\u8981\u80fd\u91cf\u9ad8\u6548\u5b9e\u73b0\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u6216\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u6027\u80fd\u53c8\u80fd\u964d\u4f4e\u786c\u4ef6\u590d\u6742\u5ea6\u7684\u65e0\u4e58\u6cd5\u5668\u5b9e\u73b0\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5339\u914d\u8ffd\u8e2a\u7684\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u5c06\u591a\u76f8\u7f51\u7edc\u7684\u6570\u503c\u8868\u793a\u76f4\u63a5\u4ece\u6d6e\u70b9\u6570\u8f6c\u6362\u4e3aSOPOT\uff08\u6709\u7b26\u53f7\u4e8c\u6b21\u5e42\u548c\uff09\u8868\u793a\uff0c\u5b9e\u73b0\u65e0\u4e58\u6cd5\u5668\u786c\u4ef6\u8bbe\u8ba1\u3002", "result": "\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65e0\u4e58\u6cd5\u5668\u786c\u4ef6\u8bbe\u8ba1\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u4f3c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0b\u5b9e\u73b0\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684SOPOT\u8f6c\u6362\u65b9\u6cd5\u4e3aFBMC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u80fd\u91cf\u4f18\u5316\u786c\u4ef6\u5b9e\u73b0\u65b9\u6848\uff0c\u5728\u6027\u80fd\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2601.20014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20014", "abs": "https://arxiv.org/abs/2601.20014", "authors": ["Shuhui Qu"], "title": "Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning", "comment": null, "summary": "Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \\textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\\texttt{Sat}/\\texttt{Viol}/\\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \\emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \\textbf{14.9\\%} and \\textbf{5.8\\%} (vs.\\ \\textbf{26.0\\%} and \\textbf{15.7\\%} for the best baseline), while maintaining competitive reference quality.", "AI": {"tldr": "SQ-BCP\u662f\u4e00\u79cd\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u8fdb\u884c\u63a8\u7406\u65f6\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u8868\u793a\u524d\u63d0\u6761\u4ef6\u72b6\u6001\u3001\u9488\u5bf9\u6027\u81ea\u6211\u67e5\u8be2\u548c\u6865\u63a5\u5047\u8bbe\u6765\u89e3\u51b3LLM\u5728\u7f3a\u5931\u5173\u952e\u524d\u63d0\u65f6\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u4f7f\u7528\u53cc\u5411\u641c\u7d22\u548c\u57fa\u4e8e\u62c9\u56de\u7684\u9a8c\u8bc1\u5668\u786e\u4fdd\u8ba1\u5212\u517c\u5bb9\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u89c4\u5212\u4e2d\u9762\u4e34\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff1a\u5f53\u4efb\u52a1\u5173\u952e\u524d\u63d0\u6761\u4ef6\u672a\u5728\u67e5\u8be2\u65f6\u6307\u5b9a\u65f6\uff0c\u6a21\u578b\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u6216\u8fdd\u53cd\u786c\u7ea6\u675f\u7684\u8ba1\u5212\u3002", "method": "\u63d0\u51fa\u81ea\u6211\u67e5\u8be2\u53cc\u5411\u5206\u7c7b\u89c4\u5212(SQ-BCP)\uff1a1)\u663e\u5f0f\u8868\u793a\u524d\u63d0\u6761\u4ef6\u72b6\u6001(Sat/Viol/Unk)\uff1b2)\u901a\u8fc7\u9488\u5bf9\u6027\u81ea\u6211\u67e5\u8be2\u6216\u6865\u63a5\u5047\u8bbe\u89e3\u51b3\u672a\u77e5\u6761\u4ef6\uff1b3)\u6267\u884c\u53cc\u5411\u641c\u7d22\uff1b4)\u4f7f\u7528\u57fa\u4e8e\u62c9\u56de\u7684\u9a8c\u8bc1\u5668\u4f5c\u4e3a\u76ee\u6807\u517c\u5bb9\u6027\u7684\u5206\u7c7b\u8bc1\u660e\uff1b5)\u4ec5\u4f7f\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u5206\u6570\u8fdb\u884c\u6392\u5e8f\u548c\u526a\u679d\u3002", "result": "\u5728WikiHow\u548cRecipeNLG\u4efb\u52a1\u4e2d\uff0c\u5f53\u9884\u6761\u4ef6\u88ab\u4fdd\u7559\u65f6\uff0cSQ-BCP\u5c06\u8d44\u6e90\u8fdd\u89c4\u7387\u5206\u522b\u964d\u4f4e\u523014.9%\u548c5.8%\uff08\u6700\u4f73\u57fa\u7ebf\u4e3a26.0%\u548c15.7%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u53c2\u8003\u8d28\u91cf\u3002", "conclusion": "SQ-BCP\u901a\u8fc7\u663e\u5f0f\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\uff0c\u5728\u4fdd\u6301\u8ba1\u5212\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u7ea6\u675f\u8fdd\u89c4\uff0c\u4e3aLLM\u5728\u73b0\u5b9e\u4e16\u754c\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u65b9\u6cd5\u3002"}}
{"id": "2601.20586", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20586", "abs": "https://arxiv.org/abs/2601.20586", "authors": ["Ravi Sharan B A G", "Maliha Jada", "Anders Karstensen", "Daniela Laselva", "Jyri H\u00e4m\u00e4l\u00e4inen", "Silvio Mandelli"], "title": "Energy Efficient Downlink mMIMO Using Dynamic Antenna and Power Adaptation", "comment": "6 pages in double column format, 5 figures, 1 table. This work has been submitted to the IEEE for possible publication", "summary": "Massive multiple-input multiple-output (mMIMO) technology and its future evolutions are expected to address the high data rate demands of sixth generation (6G) communication systems. At the same time, network energy savings (NES) is essential in reducing the operational costs and meeting the sustainability goals of network operators. In this regard, we propose a dynamic scheme for joint antenna and power adaptation to improve NES from a user scheduling and resource allocation perspective. Antenna adaptation is performed using the multiple channel state information resource signal (CSI-RS) framework. Furthermore, the recently introduced transmit power-aware link adaptation scheme, referred to as POLITE for short, is used as the power adaptation technique. The proposed scheme adapts to variations in users' instantaneous traffic and channel conditions to opportunistically maximize NES while also inherently accounting for the user throughput. Numerical simulation results show that the proposed scheme consistently achieves a balance between NES and user perceived throughput (UPT) for different network load conditions. Especially in low and light load conditions, the proposed scheme significantly improves the intra-cell interference and boosts the overall NES, while ensuring that UPT is unaffected.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u5929\u7ebf\u548c\u529f\u7387\u81ea\u9002\u5e94\u65b9\u6848\uff0c\u901a\u8fc7\u7528\u6237\u8c03\u5ea6\u548c\u8d44\u6e90\u5206\u914d\u4f18\u5316\u7f51\u7edc\u80fd\u8017\uff0c\u5728\u4fdd\u8bc1\u7528\u6237\u541e\u5410\u91cf\u7684\u540c\u65f6\u63d0\u5347\u80fd\u6548", "motivation": "6G\u901a\u4fe1\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u9ad8\u6570\u636e\u7387\u9700\u6c42\uff0c\u540c\u65f6\u7f51\u7edc\u80fd\u8017\u8282\u7ea6\u5bf9\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u548c\u5b9e\u73b0\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u4e00\u79cd\u80fd\u9002\u5e94\u77ac\u65f6\u6d41\u91cf\u548c\u4fe1\u9053\u6761\u4ef6\u53d8\u5316\u7684\u52a8\u6001\u65b9\u6848\u6765\u4f18\u5316\u80fd\u6548\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u8054\u5408\u5929\u7ebf\u548c\u529f\u7387\u81ea\u9002\u5e94\u65b9\u6848\uff1a1) \u4f7f\u7528\u591aCSI-RS\u6846\u67b6\u8fdb\u884c\u5929\u7ebf\u81ea\u9002\u5e94\uff1b2) \u91c7\u7528POLITE\uff08\u529f\u7387\u611f\u77e5\u94fe\u8def\u81ea\u9002\u5e94\uff09\u6280\u672f\u8fdb\u884c\u529f\u7387\u81ea\u9002\u5e94\uff1b3) \u7ed3\u5408\u7528\u6237\u8c03\u5ea6\u548c\u8d44\u6e90\u5206\u914d\uff0c\u6839\u636e\u7528\u6237\u77ac\u65f6\u6d41\u91cf\u548c\u4fe1\u9053\u6761\u4ef6\u53d8\u5316\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u6570\u503c\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6848\u5728\u4e0d\u540c\u7f51\u7edc\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u5747\u80fd\u5e73\u8861\u7f51\u7edc\u80fd\u8017\u8282\u7ea6\u548c\u7528\u6237\u611f\u77e5\u541e\u5410\u91cf\u3002\u7279\u522b\u662f\u5728\u4f4e\u8d1f\u8f7d\u548c\u8f7b\u8d1f\u8f7d\u6761\u4ef6\u4e0b\uff0c\u80fd\u663e\u8457\u6539\u5584\u5c0f\u533a\u5185\u5e72\u6270\uff0c\u5927\u5e45\u63d0\u5347\u6574\u4f53\u7f51\u7edc\u80fd\u8017\u8282\u7ea6\uff0c\u540c\u65f6\u786e\u4fdd\u7528\u6237\u541e\u5410\u91cf\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u8054\u5408\u5929\u7ebf\u548c\u529f\u7387\u81ea\u9002\u5e94\u65b9\u6848\u80fd\u6709\u6548\u63d0\u53476G mMIMO\u7cfb\u7edf\u7684\u80fd\u6548\uff0c\u5728\u4fdd\u8bc1\u7528\u6237\u4f53\u9a8c\u7684\u540c\u65f6\u5b9e\u73b0\u7f51\u7edc\u80fd\u8017\u4f18\u5316\uff0c\u4e3a\u53ef\u6301\u7eed\u901a\u4fe1\u7f51\u7edc\u53d1\u5c55\u63d0\u4f9b\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.20021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20021", "abs": "https://arxiv.org/abs/2601.20021", "authors": ["Shuhui Qu"], "title": "Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints", "comment": null, "summary": "Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u7cca\u8303\u7574\u8bba\u89c4\u5212(FCP)\uff0c\u5c06\u6a21\u7cca\u903b\u8f91\u878d\u5165\u8303\u7574\u8bba\u89c4\u5212\u6846\u67b6\uff0c\u5904\u7406\u81ea\u7136\u8bed\u8a00\u89c4\u5212\u4e2d\u7684\u6a21\u7cca\u8c13\u8bcd\uff0c\u901a\u8fc7t-\u8303\u6570\u7ec4\u5408\u8ba1\u5212\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u786c\u7ea6\u675f\u7684\u53ef\u6267\u884c\u6027\u68c0\u67e5\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u89c4\u5212\u5e38\u6d89\u53ca\u6a21\u7cca\u8c13\u8bcd\uff08\u5982\"\u5408\u9002\u7684\u66ff\u4ee3\u54c1\"\u3001\"\u8db3\u591f\u7a33\u5b9a\"\uff09\uff0c\u73b0\u6709\u8303\u7574\u8bba\u89c4\u5212\u5668\u5c06\u5176\u89c6\u4e3a\u4e8c\u503c\u5224\u65ad\uff0c\u9700\u8981\u9608\u503c\u5904\u7406\uff0c\u8fd9\u4f1a\u4e22\u5931\u6709\u610f\u4e49\u7684\u8d28\u91cf\u5dee\u5f02\uff0c\u4e14\u65e0\u6cd5\u8ffd\u8e2a\u591a\u6b65\u8ba1\u5212\u4e2d\u7684\u8d28\u91cf\u9000\u5316\u3002", "method": "\u63d0\u51faFCP\u6846\u67b6\uff1a1) \u4e3a\u6bcf\u4e2a\u52a8\u4f5c\uff08\u6001\u5c04\uff09\u6807\u6ce8[0,1]\u7684\u9002\u7528\u5ea6\uff1b2) \u4f7f\u7528\u0141ukasiewicz t-\u8303\u6570\u7ec4\u5408\u8ba1\u5212\u8d28\u91cf\uff1b3) \u901a\u8fc7\u62c9\u56de\u9a8c\u8bc1\u4fdd\u6301\u786c\u7ea6\u675f\u7684\u53ef\u6267\u884c\u6027\u68c0\u67e5\uff1b4) \u4f7f\u7528LLM\u8fdb\u884ck\u6837\u672c\u4e2d\u503c\u805a\u5408\u6765\u4ece\u8bed\u8a00\u4e2d\u83b7\u53d6\u5206\u7ea7\u9002\u7528\u5ea6\uff1b5) \u652f\u6301\u57fa\u4e8e\u6b8b\u5dee\u7684\u540e\u5411\u9700\u6c42\u4e2d\u95f4\u76f8\u9047\u641c\u7d22\u3002", "result": "\u5728PDDL3\u504f\u597d/\u8d85\u989d\u9884\u8ba2\u57fa\u51c6\u548cRecipeNLG-Subs\uff08\u57fa\u4e8eRecipeNLG\u6784\u5efa\u7684\u7f3a\u5931\u66ff\u4ee3\u54c1\u98df\u8c31\u89c4\u5212\u57fa\u51c6\uff09\u4e0a\u8bc4\u4f30\u3002FCP\u5728RecipeNLG-Subs\u4e0a\u76f8\u6bd4LLM-only\u548cReAct\u98ce\u683c\u57fa\u7ebf\u63d0\u9ad8\u4e86\u6210\u529f\u7387\uff0c\u51cf\u5c11\u4e86\u786c\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4e0e\u7ecf\u5178PDDL3\u89c4\u5212\u5668\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "FCP\u6210\u529f\u5c06\u6a21\u7cca\u903b\u8f91\u96c6\u6210\u5230\u8303\u7574\u8bba\u89c4\u5212\u4e2d\uff0c\u6709\u6548\u5904\u7406\u81ea\u7136\u8bed\u8a00\u89c4\u5212\u4e2d\u7684\u6a21\u7cca\u8c13\u8bcd\uff0c\u5728\u4fdd\u6301\u786c\u7ea6\u675f\u53ef\u6267\u884c\u6027\u68c0\u67e5\u7684\u540c\u65f6\uff0c\u80fd\u591f\u8ffd\u8e2a\u591a\u6b65\u8ba1\u5212\u4e2d\u7684\u8d28\u91cf\u9000\u5316\u3002"}}
{"id": "2601.20600", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20600", "abs": "https://arxiv.org/abs/2601.20600", "authors": ["Junmin An", "Ji-Hoon Hong", "Jon-Lark Kim", "Haeun Lim"], "title": "Shortest LCD embeddings of binary, ternary and quaternary linear codes", "comment": null, "summary": "In the recent years, there has been active research on self-orthogonal embeddings of linear codes since they yielded some optimal self-orthogonal codes. LCD codes have a trivial hull so they are counterparts of self-orthogonal codes. So it is a natural question whether one can embed linear codes into optimal LCD codes. To answer it, we first determine the number of columns to be added to a generator matrix of a linear code in order to embed the given code into an LCD code. Then we characterize all possible forms of shortest LCD embeddings of a linear code. As examples, we start from binary and ternary Hamming codes of small lengths and obtain optimal LCD codes with minimum distance 4. Furthermore, we find new ternary LCD codes with parameters including $[23, 4, 14]$, $[23, 5, 12]$, $[24, 6, 12]$, and $[25, 5, 14]$ and a new quaternary LCD $[21, 10, 8]$ code, each of which has minimum distance one greater than those of known codes. This shows that our shortest LCD embedding method is useful in finding optimal LCD codes over various fields.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5c06\u7ebf\u6027\u7801\u5d4c\u5165\u5230\u6700\u4f18LCD\u7801\u4e2d\uff0c\u63d0\u51fa\u4e86\u6700\u77edLCD\u5d4c\u5165\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u4e86\u591a\u4e2a\u65b0\u7684\u6700\u4f18LCD\u7801\u3002", "motivation": "\u81ea\u6b63\u4ea4\u7801\u7684\u7814\u7a76\u5df2\u7ecf\u4ea7\u751f\u4e86\u8bb8\u591a\u6700\u4f18\u81ea\u6b63\u4ea4\u7801\uff0c\u800cLCD\u7801\u4f5c\u4e3a\u81ea\u6b63\u4ea4\u7801\u7684\u5bf9\u5076\uff08\u5177\u6709\u5e73\u51e1hull\uff09\uff0c\u81ea\u7136\u5f15\u53d1\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u662f\u5426\u53ef\u4ee5\u5c06\u7ebf\u6027\u7801\u5d4c\u5165\u5230\u6700\u4f18LCD\u7801\u4e2d\uff1f", "method": "\u9996\u5148\u786e\u5b9a\u4e86\u9700\u8981\u5411\u7ebf\u6027\u7801\u7684\u751f\u6210\u77e9\u9635\u6dfb\u52a0\u591a\u5c11\u5217\u624d\u80fd\u5c06\u5176\u5d4c\u5165\u5230LCD\u7801\u4e2d\uff0c\u7136\u540e\u63cf\u8ff0\u4e86\u7ebf\u6027\u7801\u7684\u6700\u77edLCD\u5d4c\u5165\u7684\u6240\u6709\u53ef\u80fd\u5f62\u5f0f\u3002", "result": "\u4ece\u4e8c\u8fdb\u5236\u548c\u4e09\u5143\u6c49\u660e\u7801\u51fa\u53d1\uff0c\u5f97\u5230\u4e86\u6700\u5c0f\u8ddd\u79bb\u4e3a4\u7684\u6700\u4f18LCD\u7801\u3002\u6b64\u5916\uff0c\u53d1\u73b0\u4e86\u65b0\u7684\u4e09\u5143LCD\u7801\uff0c\u53c2\u6570\u5305\u62ec[23,4,14]\u3001[23,5,12]\u3001[24,6,12]\u3001[25,5,14]\uff0c\u4ee5\u53ca\u4e00\u4e2a\u65b0\u7684\u56db\u5143LCD [21,10,8]\u7801\uff0c\u6bcf\u4e2a\u7684\u6700\u5c0f\u8ddd\u79bb\u90fd\u6bd4\u5df2\u77e5\u7801\u59271\u3002", "conclusion": "\u6700\u77edLCD\u5d4c\u5165\u65b9\u6cd5\u5bf9\u4e8e\u5728\u5404\u79cd\u57df\u4e0a\u5bfb\u627e\u6700\u4f18LCD\u7801\u662f\u6709\u6548\u7684\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.20048", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20048", "abs": "https://arxiv.org/abs/2601.20048", "authors": ["Jincheng Bai", "Zhenyu Zhang", "Jennifer Zhang", "Zhihuai Zhu"], "title": "Insight Agents: An LLM-Based Multi-Agent System for Data Insights", "comment": "Accepted to SIGIR 2025. DOI: 10.1145/3726302.3731959", "summary": "Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.", "AI": {"tldr": "\u5f00\u53d1Insight Agents\u5bf9\u8bdd\u5f0f\u591a\u4ee3\u7406\u6570\u636e\u6d1e\u5bdf\u7cfb\u7edf\uff0c\u5e2e\u52a9\u7535\u5546\u5356\u5bb6\u901a\u8fc7\u81ea\u52a8\u5316\u4fe1\u606f\u68c0\u7d22\u83b7\u53d6\u4e2a\u6027\u5316\u6570\u636e\u548c\u5546\u4e1a\u6d1e\u5bdf\uff0c\u964d\u4f4e\u51b3\u7b56\u6210\u672c\uff0c\u63d0\u9ad8\u51b3\u7b56\u901f\u5ea6\u3002", "motivation": "\u7535\u5546\u5356\u5bb6\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u96be\u4ee5\u53d1\u73b0\u548c\u6709\u6548\u5229\u7528\u73b0\u6709\u7a0b\u5e8f\u5de5\u5177\uff1b2) \u96be\u4ee5\u7406\u89e3\u548c\u5229\u7528\u5404\u79cd\u5de5\u5177\u4ea7\u751f\u7684\u4e30\u5bcc\u6570\u636e\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\u6765\u5e2e\u52a9\u5356\u5bb6\u66f4\u8f7b\u677e\u5730\u83b7\u53d6\u5546\u4e1a\u6d1e\u5bdf\u3002", "method": "\u57fa\u4e8e\u8ba1\u5212-\u6267\u884c\u8303\u5f0f\u7684LLM\u9a71\u52a8\u7aef\u5230\u7aef\u4ee3\u7406\u7cfb\u7edf\uff0c\u91c7\u7528\u5206\u5c42\u591a\u4ee3\u7406\u7ed3\u6784\uff1a\u7ba1\u7406\u4ee3\u7406\uff08\u7ed3\u5408OOD\u68c0\u6d4b\u548c\u8def\u7531\u5206\u7c7b\u5668\uff09\u548c\u4e24\u4e2a\u5de5\u4f5c\u4ee3\u7406\uff08\u6570\u636e\u5448\u73b0\u548c\u6d1e\u5bdf\u751f\u6210\uff09\u3002\u4f7f\u7528API\u6570\u636e\u6a21\u578b\u8fdb\u884c\u6218\u7565\u89c4\u5212\uff0c\u52a8\u6001\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\u3002", "result": "\u7cfb\u7edf\u5df2\u5728\u4e9a\u9a6c\u900a\u7f8e\u56fd\u5356\u5bb6\u4e0a\u7ebf\uff0c\u4eba\u5de5\u8bc4\u4f30\u51c6\u786e\u7387\u8fbe\u523090%\uff0cP90\u5ef6\u8fdf\u4f4e\u4e8e15\u79d2\uff0c\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u548c\u4f4e\u5ef6\u8fdf\u7684\u76ee\u6807\u3002", "conclusion": "Insight Agents\u4f5c\u4e3a\u7535\u5546\u5356\u5bb6\u7684\"\u529b\u91cf\u500d\u589e\u5668\"\uff0c\u901a\u8fc7\u51cf\u5c11\u51b3\u7b56\u6240\u9700\u52aa\u529b\u548c\u52a0\u5feb\u51b3\u7b56\u901f\u5ea6\uff0c\u80fd\u591f\u6709\u6548\u63a8\u52a8\u5356\u5bb6\u91c7\u7528\uff0c\u5e2e\u52a9\u5356\u5bb6\u505a\u51fa\u66f4\u597d\u7684\u5546\u4e1a\u51b3\u7b56\u3002"}}
{"id": "2601.20678", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20678", "abs": "https://arxiv.org/abs/2601.20678", "authors": ["Vidhi Rana", "Remi A. Chou", "Taejoon Kim"], "title": "Helper-Assisted Coding for Gaussian Wiretap Channels: Deep Learning Meets PhySec", "comment": null, "summary": "Consider the Gaussian wiretap channel, where a transmitter wishes to send a confidential message to a legitimate receiver in the presence of an eavesdropper. It is well known that if the eavesdropper experiences less channel noise than the legitimate receiver, then it is impossible for the transmitter to achieve positive secrecy rates. A known solution to this issue consists in involving a second transmitter, referred to as a helper, to help the first transmitter to achieve security. While such a solution has been studied for the asymptotic blocklength regime and via non-constructive coding schemes, in this paper, for the first time, we design explicit and short blocklength codes using deep learning and cryptographic tools to demonstrate the benefit and practicality of cooperation between two transmitters over the wiretap channel. Specifically, our proposed codes show strict improvement in terms of information leakage compared to existing codes that do not consider a helper. Our code design approach relies on a reliability layer, implemented with an autoencoder architecture based on the successive interference cancellation method, and a security layer implemented with universal hash functions. We also propose an alternative autoencoder architecture that significantly reduces training time by allowing the decoders to independently estimate messages without successively canceling interference by the receiver during training. Additionally, we show that our code design is also applicable to the multiple access wiretap channel with helpers, where two transmitters send confidential messages to the legitimate receiver.", "AI": {"tldr": "\u9996\u6b21\u8bbe\u8ba1\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u548c\u5bc6\u7801\u5b66\u5de5\u5177\u7684\u77ed\u5206\u7ec4\u957f\u5ea6\u7f16\u7801\uff0c\u5c55\u793a\u4e24\u4e2a\u53d1\u5c04\u673a\u5728\u7a83\u542c\u4fe1\u9053\u4e2d\u534f\u4f5c\u7684\u5b9e\u7528\u6027\u548c\u4f18\u52bf\uff0c\u76f8\u6bd4\u65e0\u8f85\u52a9\u7684\u73b0\u6709\u7f16\u7801\u5728\u4fe1\u606f\u6cc4\u9732\u65b9\u9762\u6709\u4e25\u683c\u6539\u8fdb\u3002", "motivation": "\u5728\u7a83\u542c\u4fe1\u9053\u4e2d\uff0c\u5f53\u7a83\u542c\u8005\u4fe1\u9053\u566a\u58f0\u5c0f\u4e8e\u5408\u6cd5\u63a5\u6536\u8005\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u6b63\u4fdd\u5bc6\u901f\u7387\u3002\u5df2\u77e5\u89e3\u51b3\u65b9\u6848\u9700\u8981\u7b2c\u4e8c\u4e2a\u53d1\u5c04\u673a\uff08\u8f85\u52a9\u8005\uff09\u5e2e\u52a9\u5b9e\u73b0\u5b89\u5168\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6e10\u8fd1\u5206\u7ec4\u957f\u5ea6\u548c\u975e\u6784\u9020\u6027\u7f16\u7801\u65b9\u6848\uff0c\u7f3a\u4e4f\u5b9e\u7528\u3001\u663e\u5f0f\u7684\u77ed\u5206\u7ec4\u957f\u5ea6\u7f16\u7801\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u548c\u5bc6\u7801\u5b66\u5de5\u5177\u7684\u7f16\u7801\u8bbe\u8ba1\uff1a1\uff09\u53ef\u9760\u6027\u5c42\uff1a\u4f7f\u7528\u57fa\u4e8e\u8fde\u7eed\u5e72\u6270\u6d88\u9664\u65b9\u6cd5\u7684\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff1b2\uff09\u5b89\u5168\u5c42\uff1a\u4f7f\u7528\u901a\u7528\u54c8\u5e0c\u51fd\u6570\u5b9e\u73b0\u3002\u8fd8\u63d0\u51fa\u66ff\u4ee3\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5141\u8bb8\u89e3\u7801\u5668\u72ec\u7acb\u4f30\u8ba1\u6d88\u606f\u800c\u65e0\u9700\u63a5\u6536\u7aef\u8bad\u7ec3\u65f6\u8fde\u7eed\u6d88\u9664\u5e72\u6270\uff0c\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7f16\u7801\u5728\u4fe1\u606f\u6cc4\u9732\u65b9\u9762\u76f8\u6bd4\u4e0d\u8003\u8651\u8f85\u52a9\u8005\u7684\u73b0\u6709\u7f16\u7801\u6709\u4e25\u683c\u6539\u8fdb\u3002\u7f16\u7801\u8bbe\u8ba1\u4e5f\u9002\u7528\u4e8e\u5e26\u8f85\u52a9\u8005\u7684\u591a\u5740\u7a83\u542c\u4fe1\u9053\uff0c\u5176\u4e2d\u4e24\u4e2a\u53d1\u5c04\u673a\u5411\u5408\u6cd5\u63a5\u6536\u8005\u53d1\u9001\u4fdd\u5bc6\u6d88\u606f\u3002", "conclusion": "\u9996\u6b21\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u548c\u5bc6\u7801\u5b66\u5de5\u5177\u8bbe\u8ba1\u663e\u5f0f\u3001\u77ed\u5206\u7ec4\u957f\u5ea6\u7684\u7f16\u7801\uff0c\u8bc1\u660e\u4e86\u4e24\u4e2a\u53d1\u5c04\u673a\u5728\u7a83\u542c\u4fe1\u9053\u4e2d\u534f\u4f5c\u7684\u5b9e\u9645\u53ef\u884c\u6027\u548c\u4f18\u52bf\uff0c\u4e3a\u5b9e\u9645\u5b89\u5168\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20090", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20090", "abs": "https://arxiv.org/abs/2601.20090", "authors": ["Amirmohammad Farzaneh", "Salvatore D'Oro", "Osvaldo Simeone"], "title": "Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control", "comment": null, "summary": "Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.", "AI": {"tldr": "\u63d0\u51faCCG\u6846\u67b6\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u63a7\u5236\u573a\u666f\u63d0\u4f9b\u53cd\u4e8b\u5b9e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4fdd\u8bc1\u5f62\u5f0f\u5316\u7684\u53ef\u9760\u6027", "motivation": "\u5f53\u7528\u6237\u770b\u5230LLM\u667a\u80fd\u4f53\u7684\u6267\u884c\u7ed3\u679c\u540e\uff0c\u53ef\u80fd\u4f1a\u60f3\u77e5\u9053\uff1a\u5982\u679c\u5f53\u521d\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u8868\u8fbe\u610f\u56fe\uff0c\u7ed3\u679c\u4f1a\u600e\u6837\uff1f\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u53cd\u4e8b\u5b9e\u63a8\u7406\u7684\u6846\u67b6", "method": "\u5c06\u7528\u6237\u3001LLM\u667a\u80fd\u4f53\u548c\u73af\u5883\u7684\u95ed\u73af\u4ea4\u4e92\u5efa\u6a21\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff0c\u5229\u7528\u6d4b\u8bd5\u65f6\u7f29\u653e\u901a\u8fc7\u6982\u7387\u6eaf\u56e0\u751f\u6210\u591a\u4e2a\u5019\u9009\u53cd\u4e8b\u5b9e\u7ed3\u679c\uff0c\u901a\u8fc7\u79bb\u7ebf\u6821\u51c6\u9636\u6bb5\u786e\u4fdd\u53ef\u9760\u6027", "result": "\u5728\u65e0\u7ebf\u7f51\u7edc\u63a7\u5236\u7528\u4f8b\u4e2d\u5c55\u793a\u4e86CCG\u7684\u6027\u80fd\uff0c\u76f8\u6bd4\u7b80\u5355\u7684\u91cd\u65b0\u6267\u884c\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u4f18\u52bf", "conclusion": "CCG\u6846\u67b6\u80fd\u591f\u4e3aLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u63a7\u5236\u63d0\u4f9b\u53ef\u9760\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.20699", "categories": ["cs.IT", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.20699", "abs": "https://arxiv.org/abs/2601.20699", "authors": ["H. Paul Keeler"], "title": "Reflected wireless signals under random spatial sampling", "comment": null, "summary": "We present a propagation model showing that a transmitter randomly positioned in space generates unbounded peaks in the histogram of the resulting power, provided the signal strength is an oscillating or non-monotonic function of distance. Specifically, these peaks are singularities in the empirical probability density that occur at turning point values of the deterministic propagation model. We explain the underlying mechanism of this phenomenon through a concise mathematical argument. This observation has direct implications for estimating random propagation effects such as fading, particularly when reflections off walls are involved.\n  Motivated by understanding intelligent surfaces, we apply this fundamental result to a physical model consisting of a single transmitter between two parallel passive walls. We analyze signal fading due to reflections and observe power oscillations resulting from wall reflections -- a phenomenon long studied in waveguides but relatively unexplored in wireless networks. For the special case where the transmitter is placed halfway between the walls, we present a compact closed-form expression for the received signal involving the Lerch transcendent function. The insights from this work can inform design decisions for intelligent surfaces deployed in cities.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\uff1a\u7a7a\u95f4\u4e2d\u968f\u673a\u5206\u5e03\u7684\u53d1\u5c04\u5668\u4f1a\u4ea7\u751f\u529f\u7387\u76f4\u65b9\u56fe\u4e2d\u7684\u65e0\u754c\u5cf0\u503c\uff0c\u8fd9\u4e9b\u5cf0\u503c\u51fa\u73b0\u5728\u786e\u5b9a\u6027\u4f20\u64ad\u6a21\u578b\u7684\u8f6c\u6298\u70b9\u5904\uff0c\u5bf9\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u8870\u843d\u4f30\u8ba1\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u667a\u80fd\u8868\u9762\u5e94\u7528\u80cc\u666f\u4e0b\uff0c\u7406\u89e3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7531\u4e8e\u5899\u58c1\u53cd\u5c04\u5f15\u8d77\u7684\u4fe1\u53f7\u8870\u843d\u73b0\u8c61\uff0c\u7279\u522b\u662f\u529f\u7387\u632f\u8361\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u4f20\u64ad\u6a21\u578b\uff0c\u901a\u8fc7\u7b80\u6d01\u7684\u6570\u5b66\u8bba\u8bc1\u89e3\u91ca\u529f\u7387\u76f4\u65b9\u56fe\u4e2d\u51fa\u73b0\u65e0\u754c\u5cf0\u503c\u7684\u673a\u5236\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e24\u5e73\u884c\u88ab\u52a8\u5899\u58c1\u95f4\u7684\u5355\u53d1\u5c04\u5668\u7269\u7406\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u5f53\u4fe1\u53f7\u5f3a\u5ea6\u662f\u8ddd\u79bb\u7684\u632f\u8361\u6216\u975e\u5355\u8c03\u51fd\u6570\u65f6\uff0c\u968f\u673a\u5b9a\u4f4d\u7684\u53d1\u5c04\u5668\u4f1a\u4ea7\u751f\u529f\u7387\u76f4\u65b9\u56fe\u4e2d\u7684\u65e0\u754c\u5cf0\u503c\uff1b\u5bf9\u4e8e\u53d1\u5c04\u5668\u4f4d\u4e8e\u5899\u58c1\u4e2d\u95f4\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5f97\u5230\u4e86\u5305\u542bLerch\u8d85\u8d8a\u51fd\u6570\u7684\u7d27\u51d1\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57ce\u5e02\u4e2d\u90e8\u7f72\u7684\u667a\u80fd\u8868\u9762\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u63ed\u793a\u4e86\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7531\u4e8e\u5899\u58c1\u53cd\u5c04\u5f15\u8d77\u7684\u529f\u7387\u632f\u8361\u73b0\u8c61\u53ca\u5176\u7edf\u8ba1\u7279\u6027\u3002"}}
{"id": "2601.20206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20206", "abs": "https://arxiv.org/abs/2601.20206", "authors": ["Zixuan Xiao", "Chunguang Hu", "Jun Ma"], "title": "Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis", "comment": null, "summary": "As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001LLM\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u57ce\u5e02\u65b0\u5efa\u516c\u56ed\u53d1\u5c55\u76d1\u6d4b\uff0c\u901a\u8fc7\u6570\u636e\u5bf9\u9f50\u673a\u5236\u548c\u9886\u57df\u5de5\u5177\u5305\u89e3\u51b3\u4f20\u7edf\u9065\u611f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u9065\u611f\u5f71\u50cf\u7684\u53d8\u5316\u68c0\u6d4b\u65b9\u6cd5\u5728\u9ad8\u5c42\u6b21\u667a\u80fd\u5206\u6790\u65b9\u9762\u5b58\u5728\u660e\u663e\u5c40\u9650\uff0c\u96be\u4ee5\u6ee1\u8db3\u5f53\u524d\u57ce\u5e02\u89c4\u5212\u7ba1\u7406\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u6570\u636e\u65f6\u7f3a\u4e4f\u7075\u6d3b\u7684\u5206\u6790\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001LLM\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8bbe\u8ba1\u901a\u7528\u7684\u6a2a\u5411\u548c\u7eb5\u5411\u6570\u636e\u5bf9\u9f50\u673a\u5236\u786e\u4fdd\u591a\u6a21\u6001\u6570\u636e\u4e00\u81f4\u6027\uff0c\u6784\u5efa\u7279\u5b9a\u5de5\u5177\u5305\u7f13\u89e3LLM\u56e0\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u800c\u4ea7\u751f\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "result": "\u76f8\u6bd4vanilla GPT-4o\u548c\u5176\u4ed6\u667a\u80fd\u4f53\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u7a33\u5065\u7684\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u4e0e\u5206\u6790\uff0c\u4e3a\u57ce\u5e02\u516c\u56ed\u53d1\u5c55\u76d1\u6d4b\u63d0\u4f9b\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u591a\u6a21\u6001LLM\u667a\u80fd\u4f53\u6846\u67b6\u5145\u5206\u5229\u7528LLM\u7684\u8bed\u4e49\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u6709\u6548\u5e94\u5bf9\u57ce\u5e02\u516c\u56ed\u53d1\u5c55\u76d1\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u6ee1\u8db3\u591a\u6837\u5316\u548c\u4e0d\u65ad\u53d8\u5316\u7684\u9700\u6c42\u3002"}}
{"id": "2601.20761", "categories": ["cs.IT", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.20761", "abs": "https://arxiv.org/abs/2601.20761", "authors": ["Aldo Cumitini", "Luca Barletta", "Osvaldo Simeone"], "title": "Anytime-Valid Quantum Tomography via Confidence Sequences", "comment": "Paper submitted to an IEEE journal", "summary": "In this letter, we address the problem of developing quantum state tomography (QST) methods that remain valid at any time during a sequence of measurements. Specifically, the aim is to provide a rigorous quantification of the uncertainty associated with the current state estimate as data are acquired incrementally. To this end, the proposed framework augments existing QST techniques by associating current point estimates of the state with confidence sets that are guaranteed to contain the true quantum state with a user-defined probability. The methodology is grounded in recent statistical advances in anytime-valid confidence sequences. Numerical results confirm the theoretical coverage properties of the proposed anytime-valid QST.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4efb\u4f55\u65f6\u95f4\u90fd\u6709\u6548\u7684\u91cf\u5b50\u6001\u5c42\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5e8f\u5217\u4e3a\u5f53\u524d\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e25\u683c\u7684\u7edf\u8ba1\u4fdd\u8bc1", "motivation": "\u73b0\u6709\u91cf\u5b50\u6001\u5c42\u6790\u65b9\u6cd5\u5728\u6d4b\u91cf\u5e8f\u5217\u8fdb\u884c\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u63d0\u4f9b\u6709\u6548\u7684\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u9700\u8981\u4e00\u79cd\u5728\u4efb\u4f55\u65f6\u95f4\u90fd\u80fd\u63d0\u4f9b\u53ef\u9760\u7f6e\u4fe1\u533a\u95f4\u7684\u65b9\u6cd5", "method": "\u5c06\u73b0\u6709\u7684\u91cf\u5b50\u6001\u5c42\u6790\u6280\u672f\u4e0e\"\u968f\u65f6\u6709\u6548\u7f6e\u4fe1\u5e8f\u5217\"\u7edf\u8ba1\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u4e3a\u5f53\u524d\u72b6\u6001\u70b9\u4f30\u8ba1\u6784\u5efa\u7f6e\u4fe1\u96c6\uff0c\u4fdd\u8bc1\u4ee5\u7528\u6237\u5b9a\u4e49\u7684\u6982\u7387\u5305\u542b\u771f\u5b9e\u91cf\u5b50\u6001", "result": "\u6570\u503c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u6240\u63d0\u51fa\u7684\u968f\u65f6\u6709\u6548\u91cf\u5b50\u6001\u5c42\u6790\u65b9\u6cd5\u7684\u7406\u8bba\u8986\u76d6\u7279\u6027\uff0c\u80fd\u591f\u5728\u4efb\u4f55\u6d4b\u91cf\u65f6\u95f4\u63d0\u4f9b\u6709\u6548\u7684\u7edf\u8ba1\u4fdd\u8bc1", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u91cf\u5b50\u6001\u5c42\u6790\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7edf\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u5728\u6d4b\u91cf\u5e8f\u5217\u7684\u4efb\u4f55\u65f6\u95f4\u70b9\u91cf\u5316\u72b6\u6001\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49"}}
{"id": "2601.20221", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20221", "abs": "https://arxiv.org/abs/2601.20221", "authors": ["Hang Zhang", "Ruheng Wang", "Yuelyu Ji", "Mingu Kwak", "Xizhi Wu", "Chenyu Li", "Li Zhang", "Wenqi Shi", "Yifan Peng", "Yanshan Wang"], "title": "Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning", "comment": null, "summary": "Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\\method$ demonstrates an $\\mathbf{8\\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.", "AI": {"tldr": "\u63d0\u51faMethoD\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u533b\u5b66\u63a8\u7406\u9a8c\u8bc1\u5668\u8fed\u4ee3\u67e5\u8be2\u5916\u90e8\u533b\u5b66\u8bed\u6599\u5e93\uff0c\u7ed3\u5408\u5de5\u5177\u589e\u5f3a\u9a8c\u8bc1\u548c\u8fed\u4ee3\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u533b\u5b66\u63a8\u7406\u51c6\u786e\u6027\u5e76\u5927\u5e45\u964d\u4f4e\u91c7\u6837\u6210\u672c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u4e34\u5e8a\u90e8\u7f72\u4e2d\u9700\u8981\u4e25\u683c\u9a8c\u8bc1\u4ee5\u786e\u4fdd\u4e8b\u5b9e\u51c6\u786e\u6027\u3002\u73b0\u6709\u5956\u52b1\u6a21\u578b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5c40\u9650\uff1a\u4ec5\u4ea7\u751f\u6807\u91cf\u5956\u52b1\u503c\u800c\u65e0\u660e\u786e\u7406\u7531\uff0c\u4e14\u4f9d\u8d56\u5355\u6b21\u68c0\u7d22\u800c\u65e0\u6cd5\u5728\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u81ea\u9002\u5e94\u77e5\u8bc6\u8bbf\u95ee\u3002", "method": "\u63d0\u51faMethoD\u6846\u67b6\uff0c\u8bad\u7ec3\u533b\u5b66\u63a8\u7406\u9a8c\u8bc1\u5668\u5728\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u8fed\u4ee3\u67e5\u8be2\u5916\u90e8\u533b\u5b66\u8bed\u6599\u5e93\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u5de5\u5177\u589e\u5f3a\u9a8c\u8bc1\u548c\u8fed\u4ee3\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u4ec5\u9700\u8981\u8f68\u8ff9\u7ea7\u76d1\u7763\uff0c\u5e76\u5305\u542b\u81ea\u9002\u5e94\u8bfe\u7a0b\u673a\u5236\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u3002", "result": "\u5728\u56db\u4e2a\u533b\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMethoD\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1aMedQA\u51c6\u786e\u7387\u63d0\u9ad823.5%\uff0cMedXpertQA\u63d0\u9ad832.0%\uff08\u76f8\u5bf9\u4e8e\u57fa\u7840\u751f\u6210\u5668\uff09\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u76f8\u6bd4\u5148\u524d\u5956\u52b1\u6a21\u578b\u57fa\u7ebf\uff0c\u91c7\u6837\u9884\u7b97\u9700\u6c42\u51cf\u5c11\u4e868\u500d\u3002", "conclusion": "\u5c06\u9a8c\u8bc1\u57fa\u4e8e\u52a8\u6001\u68c0\u7d22\u7684\u8bc1\u636e\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u533b\u5b66\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8def\u5f84\uff0c\u8868\u660e\u8fed\u4ee3\u68c0\u7d22\u589e\u5f3a\u7684\u9a8c\u8bc1\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u533b\u5b66\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2601.20822", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20822", "abs": "https://arxiv.org/abs/2601.20822", "authors": ["Mohammadali Mohammadi", "Dhanushka Kudathanthirige", "Himal A. Suraweera", "Hien Quoc Ngo", "Michail Matthaiou"], "title": "Repeater-Assisted Massive MIMO Full-Duplex Communications", "comment": "ICASSP 2026 Accepted", "summary": "We consider a wireless network comprising multiple singleantenna repeaters that amplify and instantaneously re-transmit received signals in a full-duplex (FD) communication setting. Specifically, we study a massive multiple-input multiple output base station that simultaneously serves multiple uplink (UL) and downlink (DL) user equipment (UE) over the same frequency band. The focus is on the problem of repeater weight optimization at each active repeater to maximize the sum of the weighted minimum spectral efficiencies (SEs) for both UL and DL UEs. The resulting non-convex optimization problem is tackled using a successive convex approximation technique. To demonstrate the effectiveness of the proposed approach, we evaluate its performance against benchmark systems with and without repeater assistance. The optimized FD design achieves SE improvements of up to 4-fold and 2.5-fold compared to its half-duplex counterpart.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5168\u53cc\u5de5\u901a\u4fe1\u4e2d\u591a\u4e2d\u7ee7\u5668\u7684\u6743\u91cd\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8fde\u7eed\u51f8\u903c\u8fd1\u6280\u672f\u6700\u5927\u5316\u52a0\u6743\u6700\u5c0f\u9891\u8c31\u6548\u7387\u4e4b\u548c\uff0c\u76f8\u6bd4\u534a\u53cc\u5de5\u7cfb\u7edf\u5b9e\u73b04\u500d\u548c2.5\u500d\u7684\u9891\u8c31\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u5728\u5168\u53cc\u5de5\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\uff0c\u591a\u4e2a\u5355\u5929\u7ebf\u4e2d\u7ee7\u5668\u540c\u65f6\u653e\u5927\u8f6c\u53d1\u4fe1\u53f7\uff0c\u9700\u8981\u4f18\u5316\u4e2d\u7ee7\u5668\u6743\u91cd\u4ee5\u6700\u5927\u5316\u4e0a\u4e0b\u884c\u7528\u6237\u8bbe\u5907\u7684\u52a0\u6743\u6700\u5c0f\u9891\u8c31\u6548\u7387\uff0c\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u9891\u8c31\u6548\u7387\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8fde\u7eed\u51f8\u903c\u8fd1\u6280\u672f\u5904\u7406\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4f18\u5316\u6bcf\u4e2a\u6d3b\u52a8\u4e2d\u7ee7\u5668\u7684\u6743\u91cd\u914d\u7f6e\uff0c\u5728\u76f8\u540c\u9891\u6bb5\u540c\u65f6\u670d\u52a1\u591a\u4e2a\u4e0a\u4e0b\u884c\u7528\u6237\u8bbe\u5907\u3002", "result": "\u4f18\u5316\u7684\u5168\u53cc\u5de5\u8bbe\u8ba1\u76f8\u6bd4\u534a\u53cc\u5de5\u7cfb\u7edf\u5b9e\u73b0\u9891\u8c31\u6548\u7387\u63d0\u5347\uff1a\u6700\u9ad8\u8fbe\u52304\u500d\u548c2.5\u500d\u7684\u6539\u8fdb\uff0c\u6027\u80fd\u4f18\u4e8e\u65e0\u4e2d\u7ee7\u8f85\u52a9\u548c\u6709\u4e2d\u7ee7\u8f85\u52a9\u7684\u57fa\u51c6\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e2d\u7ee7\u5668\u6743\u91cd\u4f18\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u5168\u53cc\u5de5\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\uff0c\u4e3a\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20305", "abs": "https://arxiv.org/abs/2601.20305", "authors": ["Zhenchen Tang", "Songlin Yang", "Zichuan Wang", "Bo Peng", "Yang Li", "Beibei Dong", "Jing Dong"], "title": "Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models", "comment": null, "summary": "Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.", "AI": {"tldr": "\u63d0\u51faSEER\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u751f\u91cd\u63d0\u793a\u673a\u5236\u89e3\u51b3UMMs\u7406\u89e3\u4e0e\u751f\u6210\u4e4b\u95f4\u7684\u8ba4\u77e5\u9e3f\u6c9f\uff0c\u4ec5\u9700300\u4e2a\u6837\u672c\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u91cd\u63d0\u793a\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\uff08UMMs\uff09\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u80fd\u529b\u5f80\u5f80\u65e0\u6cd5\u6709\u6548\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\uff0c\u5b58\u5728\"\u8ba4\u77e5\u9e3f\u6c9f\"\u2014\u2014\u6a21\u578b\u7f3a\u4e4f\u5982\u4f55\u6539\u8fdb\u81ea\u8eab\u751f\u6210\u8fc7\u7a0b\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51faSEER\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\u7684\u5185\u751f\u5faa\u73af\uff1a1\uff09RLVR\uff08\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u6fc0\u6d3b\u6a21\u578b\u7684\u6f5c\u5728\u8bc4\u4f30\u80fd\u529b\uff1b2\uff09RLMT\uff08\u5e26\u6a21\u578b\u5956\u52b1\u601d\u8003\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u5229\u7528\u5185\u751f\u5956\u52b1\u4fe1\u53f7\u4f18\u5316\u751f\u6210\u63a8\u7406\u7b56\u7565\u3002\u4ec5\u9700300\u4e2a\u89c6\u89c9\u6307\u4ee4\u7ec6\u5316\u4efb\u52a1\u7684\u6837\u672c\u3002", "result": "SEER\u5728\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u91cd\u63d0\u793a\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u4e0d\u727a\u7272\u4e00\u822c\u7684\u591a\u6a21\u6001\u80fd\u529b\u3002", "conclusion": "\u5185\u751f\u91cd\u63d0\u793a\u673a\u5236\u6210\u529f\u5f25\u5408\u4e86UMMs\u7684\u7406\u89e3\u4e0e\u751f\u6210\u4e4b\u95f4\u7684\u8ba4\u77e5\u9e3f\u6c9f\uff0cSEER\u6846\u67b6\u901a\u8fc7\u4ec5\u5c11\u91cf\u6837\u672c\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20825", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20825", "abs": "https://arxiv.org/abs/2601.20825", "authors": ["Julia Lieb", "Michael Schaller"], "title": "Construction and Decoding of Convolutional Codes with optimal Column Distances", "comment": null, "summary": "The construction of Maximum Distance Profile (MDP) convolutional codes in general requires the use of very large finite fields. In contrast convolutional codes with optimal column distances maximize the column distances for a given arbitrary finite field. In this paper, we present a construction of such convolutional codes. In addition, we prove that for the considered parameters the codes that we constructed are the only ones achieving optimal column distances. The structure of the presented convolutional codes with optimal column distances is strongly related to first order Reed-Muller block codes and we leverage this fact to develop a reduced complexity version of the Viterbi algorithm for these codes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4efb\u610f\u6709\u9650\u57df\u4e0a\u6784\u9020\u5177\u6709\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u5377\u79ef\u7801\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u5bf9\u4e8e\u7ed9\u5b9a\u53c2\u6570\uff0c\u6240\u6784\u9020\u7684\u7801\u662f\u552f\u4e00\u80fd\u8fbe\u5230\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u3002\u8fd9\u4e9b\u7801\u7684\u7ed3\u6784\u4e0e\u4e00\u9636Reed-Muller\u5206\u7ec4\u7801\u5bc6\u5207\u76f8\u5173\uff0c\u5e76\u5229\u7528\u6b64\u5173\u7cfb\u5f00\u53d1\u4e86\u9488\u5bf9\u8fd9\u4e9b\u7801\u7684\u7b80\u5316\u590d\u6742\u5ea6Viterbi\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6700\u5927\u8ddd\u79bb\u8f6e\u5ed3(MDP)\u5377\u79ef\u7801\u7684\u6784\u9020\u901a\u5e38\u9700\u8981\u975e\u5e38\u5927\u7684\u6709\u9650\u57df\uff0c\u800c\u5177\u6709\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u5377\u79ef\u7801\u53ef\u4ee5\u5728\u4efb\u610f\u6709\u9650\u57df\u4e0a\u6700\u5927\u5316\u5217\u8ddd\u79bb\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u4efb\u610f\u6709\u9650\u57df\u4e0a\u6784\u9020\u5177\u6709\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u5377\u79ef\u7801\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6784\u9020\u5177\u6709\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u5377\u79ef\u7801\u7684\u65b9\u6cd5\u3002\u8fd9\u4e9b\u7801\u7684\u7ed3\u6784\u4e0e\u4e00\u9636Reed-Muller\u5206\u7ec4\u7801\u6709\u5f88\u5f3a\u7684\u5173\u8054\u6027\uff0c\u4f5c\u8005\u5229\u7528\u8fd9\u79cd\u5173\u7cfb\u5f00\u53d1\u4e86\u9488\u5bf9\u8fd9\u4e9b\u7279\u5b9a\u7801\u7684\u7b80\u5316\u590d\u6742\u5ea6Viterbi\u7b97\u6cd5\u3002", "result": "\u6210\u529f\u6784\u9020\u4e86\u5728\u4efb\u610f\u6709\u9650\u57df\u4e0a\u5177\u6709\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u5377\u79ef\u7801\uff0c\u5e76\u8bc1\u660e\u5bf9\u4e8e\u6240\u8003\u8651\u7684\u53c2\u6570\uff0c\u6240\u6784\u9020\u7684\u7801\u662f\u552f\u4e00\u80fd\u8fbe\u5230\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u9488\u5bf9\u8fd9\u4e9b\u7801\u7684\u7b80\u5316\u590d\u6742\u5ea6Viterbi\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4efb\u610f\u6709\u9650\u57df\u4e0a\u6784\u9020\u5177\u6709\u6700\u4f18\u5217\u8ddd\u79bb\u7684\u5377\u79ef\u7801\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u7801\u4e0e\u4e00\u9636Reed-Muller\u5206\u7ec4\u7801\u5bc6\u5207\u76f8\u5173\uff0c\u5e76\u4e14\u9488\u5bf9\u8fd9\u4e9b\u7279\u5b9a\u7ed3\u6784\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u8bd1\u7801\u7b97\u6cd5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.20323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20323", "abs": "https://arxiv.org/abs/2601.20323", "authors": ["Hyunseung Chung", "Jungwoo Oh", "Daeun Kyung", "Jiho Kim", "Yeonsu Kwon", "Min-Gyu Kim", "Edward Choi"], "title": "ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue", "comment": "Accepted to ICASSP 2026 (5 pages, 2 figures, 5 tables)", "summary": "Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.", "AI": {"tldr": "ECG-Agent\uff1a\u9996\u4e2a\u57fa\u4e8eLLM\u7684\u5de5\u5177\u8c03\u7528\u4ee3\u7406\uff0c\u7528\u4e8e\u591a\u8f6e\u5fc3\u7535\u56fe\u5bf9\u8bdd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7f3a\u4e4f\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3001\u8bbe\u5907\u7aef\u6548\u7387\u548c\u7cbe\u786eECG\u6d4b\u91cf\u7406\u89e3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728ECG\u5e94\u7528\u4e2d\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u3001\u62a5\u544a\u751f\u6210\u548c\u5355\u8f6e\u95ee\u7b54\uff0c\u4f46\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u4e0d\u8db3\uff1a\u7f3a\u4e4f\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3001\u8bbe\u5907\u7aef\u6548\u7387\u4e0d\u8db3\u3001\u4ee5\u53ca\u5bf9PQRST\u95f4\u9694\u7b49ECG\u6d4b\u91cf\u7684\u7cbe\u786e\u7406\u89e3\u6709\u9650\u3002", "method": "1. \u5f15\u5165ECG-Agent\uff0c\u9996\u4e2a\u57fa\u4e8eLLM\u7684\u5de5\u5177\u8c03\u7528\u4ee3\u7406\uff0c\u652f\u6301\u591a\u8f6eECG\u5bf9\u8bdd\uff1b2. \u6784\u5efaECG-MTD\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9e\u7528\u6237-\u52a9\u624b\u591a\u8f6e\u5bf9\u8bdd\uff0c\u6db5\u76d6\u591a\u79cdECG\u5bfc\u8054\u914d\u7f6e\uff1b3. \u5f00\u53d1\u4e0d\u540c\u89c4\u6a21\u7684ECG-Agent\uff0c\u4ece\u8bbe\u5907\u7aef\u53ef\u8fd0\u884c\u5230\u5927\u578b\u4ee3\u7406\u3002", "result": "ECG-Agent\u5728\u54cd\u5e94\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebfECG-LLM\u3002\u8bbe\u5907\u7aef\u4ee3\u7406\u5728\u54cd\u5e94\u51c6\u786e\u6027\u3001\u5de5\u5177\u8c03\u7528\u80fd\u529b\u548c\u5e7b\u89c9\u8bc4\u4f30\u7b49\u591a\u4e2a\u65b9\u9762\u4e0e\u5927\u578b\u4ee3\u7406\u8868\u73b0\u76f8\u5f53\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "ECG-Agent\u901a\u8fc7\u5de5\u5177\u8c03\u7528\u548c\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709ECG-LLM\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u8bbe\u5907\u7aef\u4ee3\u7406\u7684\u53ef\u884c\u6027\u4e3a\u5b9e\u9645\u533b\u7597\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.20827", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.20827", "abs": "https://arxiv.org/abs/2601.20827", "authors": ["Bo-Yuan Chen", "Hsuan-Jung Su"], "title": "Low-Complexity Pilot-Aided Doppler Ambiguity Estimation for OTFS Parametric Channel Estimation", "comment": "8 pages, 3 figures", "summary": "Orthogonal Time Frequency Space (OTFS) modulation offers robust performance in high-mobility scenarios by transforming time-varying channels into the delay-Doppler (DD) domain. However, in high-mobility environment such as emerging 5G Non-Terrestrial Networks (NTN), the extreme orbital velocities of Low Earth Orbit (LEO) satellites frequently cause the physical Doppler shifts to exceed the fundamental grid range. This Doppler ambiguity induces severe model mismatch and renders traditional MLE channel estimators ineffective. To address this challenge, this paper proposes a novel low-complexity pilot-aided Doppler ambiguity detection and compensation framework. We first mathematically derive the OTFS input-output relationship in the presence of aliasing, revealing that Doppler ambiguity manifests itself as a distinct phase rotation along the delay dimension. Leveraging this insight, we developed a two-stage estimator that utilizes pairwise phase differences between pilot symbols to identify the integer ambiguity, followed by a refined Maximum Likelihood Estimation (MLE) for channel recovery. We investigate two pilot arrangements, Embedded Pilot with Guard Zone (EP-GZ) and Data-Surrounded Pilot (DSP), to analyze the trade-off between interference suppression and spectral efficiency. Simulation results demonstrate that the proposed scheme effectively eliminates the error floor caused by ambiguity, achieving Bit Error Rate (BER) and Normalized Mean Square Error (NMSE) performance comparable to the exhaustive search benchmark while maintaining a computational complexity similar to standard MLE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u5bfc\u9891\u8f85\u52a9\u7684\u591a\u666e\u52d2\u6a21\u7cca\u68c0\u6d4b\u4e0e\u8865\u507f\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3OTFS\u8c03\u5236\u5728\u9ad8\u79fb\u52a8\u60275G\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u56e0\u591a\u666e\u52d2\u6a21\u7cca\u5bfc\u81f4\u7684\u4fe1\u9053\u4f30\u8ba1\u5931\u6548\u95ee\u9898\u3002", "motivation": "\u57285G\u975e\u5730\u9762\u7f51\u7edc\u7b49\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e2d\uff0c\u4f4e\u8f68\u536b\u661f\u7684\u6781\u7aef\u8f68\u9053\u901f\u5ea6\u5bfc\u81f4\u7269\u7406\u591a\u666e\u52d2\u9891\u79fb\u8d85\u51fa\u57fa\u672c\u7f51\u683c\u8303\u56f4\uff0c\u4ea7\u751f\u591a\u666e\u52d2\u6a21\u7cca\u95ee\u9898\u3002\u8fd9\u79cd\u6a21\u7cca\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u6a21\u578b\u5931\u914d\uff0c\u4f7f\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u4fe1\u9053\u4f30\u8ba1\u5668\u5931\u6548\u3002", "method": "\u9996\u5148\u4ece\u6570\u5b66\u4e0a\u63a8\u5bfc\u4e86\u5b58\u5728\u6df7\u53e0\u65f6\u7684OTFS\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\uff0c\u53d1\u73b0\u591a\u666e\u52d2\u6a21\u7cca\u8868\u73b0\u4e3a\u6cbf\u5ef6\u8fdf\u7ef4\u5ea6\u7684\u72ec\u7279\u76f8\u4f4d\u65cb\u8f6c\u3002\u57fa\u4e8e\u8fd9\u4e00\u53d1\u73b0\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u4f30\u8ba1\u5668\uff1a1) \u5229\u7528\u5bfc\u9891\u7b26\u53f7\u95f4\u7684\u6210\u5bf9\u76f8\u4f4d\u5dee\u8bc6\u522b\u6574\u6570\u6a21\u7cca\uff1b2) \u91c7\u7528\u7cbe\u70bc\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8fdb\u884c\u4fe1\u9053\u6062\u590d\u3002\u7814\u7a76\u4e86\u4e24\u79cd\u5bfc\u9891\u6392\u5217\u65b9\u5f0f\uff1a\u5e26\u4fdd\u62a4\u533a\u7684\u5d4c\u5165\u5f0f\u5bfc\u9891\u548c\u6570\u636e\u73af\u7ed5\u5bfc\u9891\uff0c\u4ee5\u5206\u6790\u5e72\u6270\u6291\u5236\u548c\u9891\u8c31\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u6709\u6548\u6d88\u9664\u4e86\u7531\u6a21\u7cca\u5f15\u8d77\u7684\u9519\u8bef\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e86\u4e0e\u7a77\u4e3e\u641c\u7d22\u57fa\u51c6\u76f8\u5f53\u7684\u8bef\u7801\u7387\u548c\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u6807\u51c6\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u76f8\u4f3c\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u590d\u6742\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86OTFS\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e2d\u7684\u591a\u666e\u52d2\u6a21\u7cca\u95ee\u9898\uff0c\u4e3a5G\u975e\u5730\u9762\u7f51\u7edc\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2601.20352", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20352", "abs": "https://arxiv.org/abs/2601.20352", "authors": ["Weiquan Huang", "Zixuan Wang", "Hehai Lin", "Sudong Wang", "Bo Xu", "Qian Li", "Beier Zhu", "Linyi Yang", "Chengwei Qin"], "title": "AMA: Adaptive Memory via Multi-Agent Collaboration", "comment": "8 pages", "summary": "The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.", "AI": {"tldr": "AMA\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u81ea\u9002\u5e94\u8bb0\u5fc6\u7ba1\u7406\uff0c\u5728\u4fdd\u6301\u68c0\u7d22\u7cbe\u5ea6\u7684\u540c\u65f6\u51cf\u5c1180%\u7684token\u6d88\u8017", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u5b58\u5728\u68c0\u7d22\u7c92\u5ea6\u56fa\u5b9a\u3001\u7ef4\u62a4\u7b56\u7565\u79ef\u7d2f\u8fc7\u91cd\u3001\u66f4\u65b0\u673a\u5236\u7c97\u7cd9\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u5b58\u50a8\u4fe1\u606f\u4e0e\u4efb\u52a1\u63a8\u7406\u9700\u6c42\u4e0d\u5339\u914d\uff0c\u4ee5\u53ca\u903b\u8f91\u4e0d\u4e00\u81f4\u6027\u968f\u65f6\u95f4\u7d2f\u79ef", "method": "\u63d0\u51faAMA\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u8bb0\u5fc6\u8bbe\u8ba1\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff1aConstructor\u548cRetriever\u5b9e\u73b0\u591a\u7c92\u5ea6\u8bb0\u5fc6\u6784\u5efa\u548c\u81ea\u9002\u5e94\u67e5\u8be2\u8def\u7531\uff1bJudge\u9a8c\u8bc1\u76f8\u5173\u6027\u548c\u4e00\u81f4\u6027\uff1bRefresher\u6267\u884c\u9488\u5bf9\u6027\u66f4\u65b0\u6216\u5220\u9664\u8fc7\u65f6\u6761\u76ee", "result": "\u5728\u6311\u6218\u6027\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAMA\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\uff0c\u76f8\u6bd4\u5168\u4e0a\u4e0b\u6587\u65b9\u6cd5\u51cf\u5c11\u7ea680%\u7684token\u6d88\u8017\uff0c\u6709\u6548\u4fdd\u6301\u68c0\u7d22\u7cbe\u5ea6\u548c\u957f\u671f\u8bb0\u5fc6\u4e00\u81f4\u6027", "conclusion": "AMA\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u81ea\u9002\u5e94\u8bb0\u5fc6\u7ba1\u7406\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u4e00\u81f4\u7684\u957f\u65f6\u8bb0\u5fc6\u652f\u6301"}}
{"id": "2601.20379", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20379", "abs": "https://arxiv.org/abs/2601.20379", "authors": ["Zhengbo Jiao", "Hongyu Xian", "Qinglong Wang", "Yunpu Ma", "Zhebo Wang", "Zifan Zhang", "Dezhang Kong", "Meng Han"], "title": "Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution", "comment": "19 pages, 5 figures", "summary": "Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of \"conjectures and refutations,\" we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.", "AI": {"tldr": "PoT\u6846\u67b6\u901a\u8fc7\u5728\u7ebf\u4f18\u5316\u7b56\u7565\uff0c\u8ba9LLM\u4ece\u6267\u884c\u53cd\u9988\u4e2d\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c4B\u5c0f\u6a21\u578b\u5728LiveCodeBench\u4e0a\u8d85\u8d8aGPT-4o\u7b49\u5927\u6a21\u578b", "motivation": "\u73b0\u6709LLM\u5728\u590d\u6742\u957f\u65f6\u7a0b\u63a8\u7406\u4e2d\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u4e3a\u5176\u7b56\u7565\u56fa\u5b9a\u4e0d\u53d8\u3002\u5f53\u524d\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u4ec5\u5c06\u6267\u884c\u53cd\u9988\u4f5c\u4e3a\u5916\u90e8\u4fe1\u53f7\u7528\u4e8e\u8fc7\u6ee4\u6216\u91cd\u5199\u8f68\u8ff9\uff0c\u672a\u80fd\u5c06\u5176\u5185\u5316\u4ee5\u6539\u8fdb\u5e95\u5c42\u63a8\u7406\u7b56\u7565\u3002\u53d7\u6ce2\u666e\u5c14\"\u731c\u60f3\u4e0e\u53cd\u9a73\"\u8ba4\u8bc6\u8bba\u542f\u53d1\uff0c\u8ba4\u4e3a\u667a\u80fd\u9700\u8981\u901a\u8fc7\u5b66\u4e60\u5931\u8d25\u5c1d\u8bd5\u6765\u5b9e\u65f6\u6f14\u5316\u6a21\u578b\u7b56\u7565\u3002", "method": "\u63d0\u51faPolicy of Thoughts (PoT)\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5b9e\u4f8b\u5185\u7684\u5728\u7ebf\u4f18\u5316\u8fc7\u7a0b\u3002\u9996\u5148\u901a\u8fc7\u9ad8\u6548\u63a2\u7d22\u673a\u5236\u751f\u6210\u591a\u6837\u5019\u9009\u89e3\uff0c\u7136\u540e\u4f7f\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u57fa\u4e8e\u6267\u884c\u53cd\u9988\u66f4\u65b0\u77ac\u6001LoRA\u9002\u914d\u5668\u3002\u8fd9\u79cd\u95ed\u73af\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u6a21\u578b\u63a8\u7406\u5148\u9a8c\u7684\u52a8\u6001\u3001\u5b9e\u4f8b\u7279\u5b9a\u7ec6\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793aPoT\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1a4B\u6a21\u578b\u5728LiveCodeBench\u4e0a\u8fbe\u523049.71%\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86GPT-4o\u548cDeepSeek-V3\uff0c\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u5c0f\u4e8650\u591a\u500d\u3002", "conclusion": "PoT\u6846\u67b6\u901a\u8fc7\u5c06\u63a8\u7406\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u7ebf\u4f18\u5316\u8fc7\u7a0b\uff0c\u4f7fLLM\u80fd\u591f\u4ece\u6267\u884c\u53cd\u9988\u4e2d\u5b66\u4e60\u5e76\u52a8\u6001\u8c03\u6574\u63a8\u7406\u7b56\u7565\uff0c\u4e3a\u5c0f\u6a21\u578b\u5b9e\u73b0\u8d85\u8d8a\u5927\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.20380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20380", "abs": "https://arxiv.org/abs/2601.20380", "authors": ["Le Zhang", "Yixiong Xiao", "Xinjiang Lu", "Jingjia Cao", "Yusai Zhao", "Jingbo Zhou", "Lang An", "Zikan Feng", "Wanxiang Sha", "Yu Shi", "Congxi Xiao", "Jian Xiong", "Yankai Zhang", "Hua Wu", "Haifeng Wang"], "title": "OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution", "comment": null, "summary": "Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.", "AI": {"tldr": "OmegaUse\u662f\u4e00\u4e2a\u901a\u7528\u7684GUI\u4ee3\u7406\u6a21\u578b\uff0c\u652f\u6301\u79fb\u52a8\u548c\u684c\u9762\u5e73\u53f0\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u6784\u5efa\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\u5b9e\u73b0\u8de8\u7ec8\u7aef\u4efb\u52a1\u6267\u884c\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "GUI\u4ee3\u7406\u5177\u6709\u8ba9\u57fa\u7840\u6a21\u578b\u5b8c\u6210\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u9769\u65b0\u4eba\u673a\u4ea4\u4e92\u5e76\u63d0\u9ad8\u4eba\u7c7b\u751f\u4ea7\u529b\u3002\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u901a\u7528\u7684GUI\u4ee3\u7406\u6a21\u578b\u6765\u652f\u6301\u8de8\u5e73\u53f0\uff08\u79fb\u52a8\u548c\u684c\u9762\uff09\u7684\u81ea\u4e3b\u4efb\u52a1\u6267\u884c\u3002", "method": "1. \u6570\u636e\u6784\u5efa\uff1a\u7ed3\u5408\u7cbe\u5fc3\u7b56\u5212\u7684\u5f00\u6e90\u6570\u636e\u96c6\u548c\u521b\u65b0\u7684\u81ea\u52a8\u5408\u6210\u6846\u67b6\uff08\u81ea\u5e95\u5411\u4e0a\u81ea\u4e3b\u63a2\u7d22+\u81ea\u9876\u5411\u4e0b\u5206\u7c7b\u6307\u5bfc\u751f\u6210\uff09\uff1b2. \u8bad\u7ec3\u65b9\u6cd5\uff1a\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u76d1\u7763\u5fae\u8c03\u5efa\u7acb\u57fa\u672c\u4ea4\u4e92\u8bed\u6cd5\uff0c\u7136\u540e\u4f7f\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u63d0\u5347\u7a7a\u95f4\u5b9a\u4f4d\u548c\u987a\u5e8f\u89c4\u5212\uff1b3. \u6a21\u578b\u67b6\u6784\uff1a\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u548c\u4ee3\u7406\u63a8\u7406\u80fd\u529b\u3002", "result": "OmegaUse\u5728\u591a\u4e2aGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1a\u5728ScreenSpot-V2\u4e0a\u8fbe\u523096.3%\u7684SOTA\u5206\u6570\uff0c\u5728AndroidControl\u4e0a\u8fbe\u523079.1%\u7684\u6b65\u9aa4\u6210\u529f\u7387\u3002\u5728\u65b0\u63d0\u51fa\u7684OS-Nav\u57fa\u51c6\u4e0a\uff0c\u5728ChiM-Nav\u4e0a\u8fbe\u523074.24%\u6b65\u9aa4\u6210\u529f\u7387\uff0c\u5728Ubu-Nav\u4e0a\u8fbe\u523055.9%\u5e73\u5747\u6210\u529f\u7387\u3002", "conclusion": "OmegaUse\u662f\u4e00\u4e2a\u6709\u6548\u7684\u901a\u7528GUI\u4ee3\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u6784\u5efa\u548c\u521b\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u8de8\u5e73\u53f0\u4efb\u52a1\u6267\u884c\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u4e3aGUI\u4ee3\u7406\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2601.20467", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20467", "abs": "https://arxiv.org/abs/2601.20467", "authors": ["Zhenxuan Fan", "Jie Cao", "Yang Dai", "Zheqi Lv", "Wenqiao Zhang", "Zhongle Xie", "Peng LU", "Beng Chin Ooi"], "title": "CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning", "comment": "16 pages, 9 figures, 11 tables", "summary": "Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \\textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.", "AI": {"tldr": "CtrlCoT\u662f\u4e00\u4e2a\u53cc\u7c92\u5ea6CoT\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u62bd\u8c61\u548ctoken\u7ea7\u526a\u679d\u7684\u534f\u8c03\uff0c\u5728\u51cf\u5c1130.7%token\u7684\u540c\u65f6\u63d0\u5347\u63a8\u7406\u51c6\u786e\u73877.6\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709CoT\u65b9\u6cd5\u5b58\u5728\u9ad8\u5ef6\u8fdf\u548c\u5185\u5b58\u6210\u672c\u95ee\u9898\uff0c\u800c\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u8981\u4e48\u8fc7\u4e8e\u4fdd\u5b88\uff08\u8bed\u4e49\u7ea7\u7f29\u77ed\uff09\uff0c\u8981\u4e48\u8fc7\u4e8e\u6fc0\u8fdb\uff08token\u7ea7\u526a\u679d\uff09\uff0c\u4e14\u4e24\u8005\u7ed3\u5408\u5b58\u5728\u5e8f\u5217\u4f9d\u8d56\u3001\u4efb\u52a1\u65e0\u5173\u526a\u679d\u548c\u5206\u5e03\u4e0d\u5339\u914d\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faCtrlCoT\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u5206\u5c42\u63a8\u7406\u62bd\u8c61\u751f\u6210\u591a\u7c92\u5ea6\u8bed\u4e49CoT\uff1b2\uff09\u903b\u8f91\u4fdd\u7559\u84b8\u998f\u8bad\u7ec3\u903b\u8f91\u611f\u77e5\u526a\u679d\u5668\u4fdd\u7559\u5173\u952e\u63a8\u7406\u7ebf\u7d22\uff1b3\uff09\u5206\u5e03\u5bf9\u9f50\u751f\u6210\u4f7f\u538b\u7f29\u8f68\u8ff9\u4e0e\u63a8\u7406\u98ce\u683c\u5bf9\u9f50\u3002", "result": "\u5728MATH-500\u6570\u636e\u96c6\u4e0a\u4f7f\u7528Qwen2.5-7B-Instruct\u6a21\u578b\uff0cCtrlCoT\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u51cf\u5c1130.7%token\u4f7f\u7528\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u53477.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "CtrlCoT\u901a\u8fc7\u534f\u8c03\u8bed\u4e49\u62bd\u8c61\u548ctoken\u7ea7\u526a\u679d\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u53ef\u9760\u7684\u63a8\u7406\uff0c\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86CoT\u7684\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.20487", "categories": ["cs.AI", "cs.GT", "cs.HC", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.20487", "abs": "https://arxiv.org/abs/2601.20487", "authors": ["Nico Mutzner", "Taha Yasseri", "Heiko Rauhut"], "title": "Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups", "comment": null, "summary": "The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0AI\u4ee3\u7406\u4e0e\u4eba\u7c7b\u5728\u7fa4\u4f53\u5408\u4f5c\u89c4\u8303\u4e2d\u8868\u73b0\u51fa\"\u89c4\u8303\u7b49\u4ef7\u6027\"\uff0c\u5408\u4f5c\u6c34\u5e73\u4e0d\u53d7\u4f19\u4f34\u8eab\u4efd\uff08\u4eba\u7c7bvs.AI\uff09\u5f71\u54cd\uff0c\u4e3b\u8981\u53d7\u7fa4\u4f53\u4e92\u60e0\u52a8\u6001\u548c\u884c\u4e3a\u60ef\u6027\u9a71\u52a8\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u8fdb\u5165\u4eba\u7c7b\u7fa4\u4f53\u73af\u5883\uff0c\u9700\u8981\u4e86\u89e3\u8fd9\u4e9b\u65b0\u53c2\u4e0e\u8005\u5982\u4f55\u5f71\u54cd\u5408\u4f5c\u793e\u4f1a\u89c4\u8303\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e8c\u5143\u4e92\u52a8\uff0c\u7f3a\u4e4f\u5bf9AI\u5982\u4f55\u5f71\u54cd\u5c0f\u7fa4\u4f53\u5408\u4f5c\u89c4\u8303\u5f62\u6210\u548c\u7ef4\u62a4\u7684\u4e86\u89e3\u3002", "method": "\u901a\u8fc7\u5728\u7ebf\u5b9e\u9a8c\uff0c\u4f7f\u7528\u91cd\u590d\u7684\u56db\u73a9\u5bb6\u516c\u5171\u7269\u54c1\u6e38\u620f\u3002\u6bcf\u7ec4\u5305\u542b\u4e09\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u548c\u4e00\u4e2a\u673a\u5668\u4eba\uff0c\u673a\u5668\u4eba\u88ab\u6807\u8bb0\u4e3a\u4eba\u7c7b\u6216AI\uff0c\u5e76\u9075\u5faa\u4e09\u79cd\u9884\u5b9a\u4e49\u51b3\u7b56\u7b56\u7565\u4e4b\u4e00\uff1a\u65e0\u6761\u4ef6\u5408\u4f5c\u3001\u6709\u6761\u4ef6\u5408\u4f5c\u6216\u642d\u4fbf\u8f66\u3002\u5171\u6709236\u540d\u53c2\u4e0e\u8005\u3002", "result": "\u5408\u4f5c\u4e3b\u8981\u7531\u4e92\u60e0\u7fa4\u4f53\u52a8\u6001\u548c\u884c\u4e3a\u60ef\u6027\u9a71\u52a8\uff0c\u8fd9\u4e9b\u89c4\u8303\u673a\u5236\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u8fd0\u4f5c\u76f8\u540c\uff0c\u4eba\u7c7b\u548cAI\u6807\u7b7e\u4e4b\u95f4\u7684\u5408\u4f5c\u6c34\u5e73\u6ca1\u6709\u663e\u8457\u5dee\u5f02\u3002\u540e\u7eed\u56da\u5f92\u56f0\u5883\u4e2d\u4e5f\u6ca1\u6709\u53d1\u73b0\u89c4\u8303\u6301\u4e45\u6027\u7684\u5dee\u5f02\uff0c\u53c2\u4e0e\u8005\u7684\u89c4\u8303\u611f\u77e5\u4e5f\u76f8\u540c\u3002", "conclusion": "\u5408\u4f5c\u89c4\u8303\u8db3\u591f\u7075\u6d3b\uff0c\u53ef\u4ee5\u6269\u5c55\u5230\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\uff0c\u6a21\u7cca\u4e86\u4eba\u7c7b\u548cAI\u5728\u96c6\u4f53\u51b3\u7b56\u4e2d\u7684\u754c\u9650\u3002\u8fd9\u652f\u6301\u4e86\"\u89c4\u8303\u7b49\u4ef7\u6027\"\u6a21\u5f0f\uff0c\u5373\u7ef4\u6301\u5408\u4f5c\u7684\u673a\u5236\u5728\u6df7\u5408\u4eba\u7c7b-AI\u7fa4\u4f53\u548c\u5168\u4eba\u7c7b\u7fa4\u4f53\u4e2d\u529f\u80fd\u76f8\u4f3c\u3002"}}
{"id": "2601.20539", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20539", "abs": "https://arxiv.org/abs/2601.20539", "authors": ["Oguzhan Gungordu", "Siheng Xiong", "Faramarz Fekri"], "title": "PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs", "comment": null, "summary": "Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.", "AI": {"tldr": "PathWise\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u81ea\u52a8\u5316\u542f\u53d1\u5f0f\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u548c\u89c4\u5212\u673a\u5236\u6539\u8fdb\u4f20\u7edfLLM\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u542f\u53d1\u5f0f\u751f\u6210\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u66f4\u667a\u80fd\u7684\u8fdb\u5316\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u542f\u53d1\u5f0f\u8bbe\u8ba1\u6846\u67b6\u5b58\u5728\u56fa\u5b9a\u8fdb\u5316\u89c4\u5219\u548c\u9759\u6001\u63d0\u793a\u6a21\u677f\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u542f\u53d1\u5f0f\u751f\u6210\u77ed\u89c6\u3001\u8bc4\u4f30\u5197\u4f59\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u65b0\u542f\u53d1\u5f0f\u5982\u4f55\u63a8\u5bfc\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faPathWise\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff1a\u5c06\u542f\u53d1\u5f0f\u751f\u6210\u5efa\u6a21\u4e3a\u57fa\u4e8e\u8574\u542b\u56fe\u7684\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff1b\u5305\u542b\u7b56\u7565\u667a\u80fd\u4f53\u89c4\u5212\u8fdb\u5316\u52a8\u4f5c\u3001\u4e16\u754c\u6a21\u578b\u667a\u80fd\u4f53\u751f\u6210\u542f\u53d1\u5f0f\u63a8\u6f14\u3001\u6279\u8bc4\u667a\u80fd\u4f53\u63d0\u4f9b\u8def\u7531\u53cd\u601d\uff1b\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u89c4\u5212\u53d6\u4ee3\u8bd5\u9519\u8fdb\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePathWise\u5728\u591a\u79cd\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u80fd\u66f4\u5feb\u6536\u655b\u5230\u66f4\u597d\u7684\u542f\u53d1\u5f0f\uff0c\u5728\u4e0d\u540cLLM\u9aa8\u5e72\u7f51\u7edc\u4e0a\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u95ee\u9898\u3002", "conclusion": "PathWise\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u89c4\u5212\u548c\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff0c\u5c06LLM\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4ece\u8bd5\u9519\u8fdb\u5316\u8f6c\u5411\u57fa\u4e8e\u63a8\u7406\u7684\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2601.20554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20554", "abs": "https://arxiv.org/abs/2601.20554", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function", "comment": null, "summary": "We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $\u03b1$, where $\u03b1= 1$ recovers standard expectation-based planning and $\u03b1< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u4f7f\u7528ICVaR\u52a8\u6001\u98ce\u9669\u5ea6\u91cf\u7684\u98ce\u9669\u654f\u611f\u89c4\u5212\uff0c\u5f00\u53d1\u4e86\u5177\u6709\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\u7684\u7b56\u7565\u8bc4\u4f30\u7b97\u6cd5\uff0c\u5e76\u6269\u5c55\u4e86\u4e09\u79cd\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\u4ee5\u4f18\u5316ICVaR\u4ef7\u503c\u51fd\u6570\u800c\u975e\u671f\u671b\u56de\u62a5\u3002", "motivation": "\u4f20\u7edfPOMDP\u89c4\u5212\u901a\u5e38\u4f18\u5316\u671f\u671b\u56de\u62a5\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8003\u8651\u98ce\u9669\u89c4\u907f\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u3002\u73b0\u6709\u98ce\u9669\u654f\u611f\u89c4\u5212\u65b9\u6cd5\u5728\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "1. \u5f00\u53d1\u4e86ICVaR\u7b56\u7565\u8bc4\u4f30\u7b97\u6cd5\uff0c\u5177\u6709\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u65e0\u5173\u7684\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\uff1b2. \u6269\u5c55\u4e86\u4e09\u79cd\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\uff1a\u7a00\u758f\u91c7\u6837\u3001PFT-DPW\u548cPOMCPOW\uff0c\u4f7f\u5176\u4f18\u5316ICVaR\u4ef7\u503c\u51fd\u6570\uff1b3. \u5f15\u5165\u98ce\u9669\u53c2\u6570\u03b1\uff0c\u03b1=1\u6062\u590d\u671f\u671b\u89c4\u5212\uff0c\u03b1<1\u589e\u52a0\u98ce\u9669\u89c4\u907f\uff1b4. \u4e3aICVaR\u7a00\u758f\u91c7\u6837\u5efa\u7acb\u4e86\u98ce\u9669\u654f\u611f\u76ee\u6807\u4e0b\u7684\u6709\u9650\u65f6\u95f4\u6027\u80fd\u4fdd\u8bc1\u3002", "result": "\u5728\u57fa\u51c6POMDP\u9886\u57df\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684ICVaR\u89c4\u5212\u5668\u76f8\u6bd4\u98ce\u9669\u4e2d\u6027\u5bf9\u5e94\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u5c3e\u90e8\u98ce\u9669\u3002ICVaR\u7a00\u758f\u91c7\u6837\u83b7\u5f97\u4e86\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u542f\u7528\u4e86\u9488\u5bf9ICVaR\u7684\u65b0\u63a2\u7d22\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06\u98ce\u9669\u654f\u611f\u89c4\u5212\u6269\u5c55\u5230\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\uff0c\u901a\u8fc7ICVaR\u52a8\u6001\u98ce\u9669\u5ea6\u91cf\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63a7\u5236\u5c3e\u90e8\u98ce\u9669\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2601.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20604", "abs": "https://arxiv.org/abs/2601.20604", "authors": ["Gray Cox"], "title": "Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies", "comment": "23 pages, 5 tables, 5 appendices. Code and data: https://github.com/jgraycox-coa/vcw-multi-ai-dialogue", "summary": "This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.\n  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.\n  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of \"VCW as transitional framework.\" Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.\n  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u548c\u5e73\u7814\u7a76\u7684\u591a\u6a21\u578b\u5bf9\u8bdd\u6846\u67b6\u6765\u5b9e\u8bc1\u6d4b\u8bd5AI\u5bf9\u9f50\u7b56\u7565\uff0c\u5c06\u5bf9\u9f50\u95ee\u9898\u4ece\u63a7\u5236\u95ee\u9898\u91cd\u6784\u4e3a\u5173\u7cfb\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u4e0d\u540cAI\u6a21\u578b\u80fd\u6709\u6548\u53c2\u4e0e\u590d\u6742\u5bf9\u9f50\u8ba8\u8bba\u5e76\u4ea7\u751f\u65b0\u89c1\u89e3\u3002", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u7814\u7a76\u7f3a\u4e4f\u5b9e\u8bc1\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u9700\u8981\u5c06\u62bd\u8c61\u7684\u5bf9\u9f50\u7406\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u3001\u53ef\u6d4b\u8bd5\u7684\u6846\u67b6\u3002\u53d7\u548c\u5e73\u7814\u7a76\u4f20\u7edf\u542f\u53d1\uff0c\u5c06AI\u5bf9\u9f50\u4ece\u63a7\u5236\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5173\u7cfb\u95ee\u9898\uff0c\u901a\u8fc7\u5bf9\u8bdd\u63a8\u7406\u6765\u53d1\u5c55\u5bf9\u9f50\u7b56\u7565\u3002", "method": "\u91c7\u7528\u591a\u6a21\u578b\u5bf9\u8bdd\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u4e3a\u4e0d\u540cAI\u7cfb\u7edf\u5206\u914d\u56db\u79cd\u89d2\u8272\uff08\u63d0\u8bae\u8005\u3001\u56de\u5e94\u8005\u3001\u76d1\u7763\u8005\u3001\u7ffb\u8bd1\u8005\uff09\uff0c\u5728\u516d\u79cd\u6761\u4ef6\u4e0b\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5b9e\u8d28\u6027\u53c2\u4e0e\u590d\u6742\u5bf9\u9f50\u6846\u67b6\u3002\u4f7f\u7528Claude\u3001Gemini\u548cGPT-4o\u8fdb\u884c72\u8f6e\u5bf9\u8bdd\uff0c\u5171576,822\u5b57\u7b26\u7684\u7ed3\u6784\u5316\u4ea4\u6d41\u3002", "result": "AI\u7cfb\u7edf\u80fd\u6709\u6548\u53c2\u4e0e\u548c\u5e73\u7814\u7a76\u6982\u5ff5\u8ba8\u8bba\uff0c\u4ece\u4e0d\u540c\u67b6\u6784\u89c6\u89d2\u63d0\u51fa\u4e92\u8865\u7684\u53cd\u5bf9\u610f\u89c1\uff0c\u5e76\u4ea7\u751f\u521d\u59cb\u6846\u67b6\u4e2d\u672a\u51fa\u73b0\u7684\u65b0\u89c1\u89e3\uff08\u5982\"VCW\u4f5c\u4e3a\u8fc7\u6e21\u6846\u67b6\"\uff09\u3002\u4e0d\u540c\u6a21\u578b\u5173\u6ce8\u70b9\u4e0d\u540c\uff1aClaude\u5f3a\u8c03\u9a8c\u8bc1\u6311\u6218\uff0cGemini\u5173\u6ce8\u504f\u89c1\u548c\u53ef\u6269\u5c55\u6027\uff0cGPT-4o\u7a81\u51fa\u5b9e\u65bd\u969c\u788d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5728\u5b9e\u65bd\u524d\u538b\u529b\u6d4b\u8bd5\u5bf9\u9f50\u63d0\u6848\u7684\u53ef\u590d\u5236\u65b9\u6cd5\uff0c\u521d\u6b65\u8bc1\u660e\u4e86AI\u5177\u5907VCW\u6240\u63d0\u51fa\u7684\u5bf9\u8bdd\u63a8\u7406\u80fd\u529b\u3002\u4f46\u5bf9\u8bdd\u66f4\u591a\u5173\u6ce8\u8fc7\u7a0b\u8981\u7d20\u800c\u975eAI\u672c\u8d28\u7684\u57fa\u7840\u4e3b\u5f20\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u4eba\u673a\u6df7\u5408\u534f\u8bae\u548c\u6269\u5c55\u5bf9\u8bdd\u7814\u7a76\u3002"}}
{"id": "2601.20614", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20614", "abs": "https://arxiv.org/abs/2601.20614", "authors": ["Yanqi Dai", "Yuxiang Ji", "Xiao Zhang", "Yong Wang", "Xiangxiang Chu", "Zhiwu Lu"], "title": "Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation", "comment": "Accepted for ICLR 2026", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.", "AI": {"tldr": "MathForge\u6846\u67b6\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u7ec4\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u548c\u591a\u65b9\u9762\u95ee\u9898\u91cd\u6784\u7b56\u7565\uff0c\u4ece\u7b97\u6cd5\u548c\u6570\u636e\u4e24\u4e2a\u89d2\u5ea6\u9488\u5bf9\u66f4\u96be\u95ee\u9898\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u5728\u7b97\u6cd5\u548c\u6570\u636e\u5c42\u9762\u90fd\u7f3a\u4e4f\u5bf9\u66f4\u5177\u6311\u6218\u6027\u95ee\u9898\u7684\u5173\u6ce8\uff0c\u8fd9\u5bf9\u63d0\u5347\u6a21\u578b\u672a\u5145\u5206\u53d1\u5c55\u7684\u80fd\u529b\u5f88\u91cd\u8981\u3002\u7b97\u6cd5\u4e0aGRPO\u5b58\u5728\u9690\u5f0f\u4e0d\u5e73\u8861\uff0c\u6570\u636e\u4e0a\u589e\u5f3a\u65b9\u6cd5\u4e3b\u8981\u91cd\u8ff0\u95ee\u9898\u800c\u6ca1\u6709\u7cfb\u7edf\u589e\u52a0\u5185\u5728\u96be\u5ea6", "method": "\u63d0\u51faMathForge\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) DGPO\u7b97\u6cd5\uff1a\u901a\u8fc7\u96be\u5ea6\u5e73\u8861\u7684\u7ec4\u4f18\u52bf\u4f30\u8ba1\u7ea0\u6b63GRPO\u7684\u9690\u5f0f\u4e0d\u5e73\u8861\uff0c\u5e76\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u7684\u95ee\u9898\u7ea7\u52a0\u6743\u4f18\u5148\u5904\u7406\u66f4\u96be\u95ee\u9898\uff1b2) MQR\u7b56\u7565\uff1a\u4ece\u591a\u4e2a\u65b9\u9762\u91cd\u6784\u95ee\u9898\u4ee5\u589e\u52a0\u96be\u5ea6\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u6b63\u786e\u7b54\u6848", "result": "MathForge\u5728\u5404\u79cd\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cMQR\u6269\u5c55\u6570\u636e\u8fb9\u754c\uff0cDGPO\u6709\u6548\u4ece\u589e\u5f3a\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5f62\u6210\u534f\u540c\u5faa\u73af", "conclusion": "MathForge\u901a\u8fc7\u4ece\u7b97\u6cd5\u548c\u6570\u636e\u4e24\u4e2a\u89d2\u5ea6\u9488\u5bf9\u66f4\u96be\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4ee3\u7801\u548c\u589e\u5f3a\u6570\u636e\u5df2\u5f00\u6e90"}}
{"id": "2601.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20641", "abs": "https://arxiv.org/abs/2601.20641", "authors": ["Boaz Carmeli", "Orr Paradise", "Shafi Goldwasser", "Yonatan Belinkov", "Ron Meir"], "title": "Investigating the Development of Task-Oriented Communication in Vision-Language Models", "comment": null, "summary": "We investigate whether \\emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.", "AI": {"tldr": "LLM\u667a\u80fd\u4f53\u80fd\u5728\u534f\u4f5c\u63a8\u7406\u4efb\u52a1\u4e2d\u53d1\u5c55\u51fa\u4e0d\u540c\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\u534f\u8bae\uff0c\u8fd9\u4e9b\u534f\u8bae\u5177\u6709\u9ad8\u6548\u6027\u548c\u9690\u853d\u6027\uff0c\u65e2\u5c55\u793a\u4e86\u6f5c\u529b\u4e5f\u5e26\u6765\u4e86\u900f\u660e\u5ea6\u98ce\u9669\u3002", "motivation": "\u7814\u7a76LLM\u667a\u80fd\u4f53\u662f\u5426\u80fd\u53d1\u5c55\u51fa\u4efb\u52a1\u5bfc\u5411\u7684\u901a\u4fe1\u534f\u8bae\uff0c\u8fd9\u4e9b\u534f\u8bae\u53ef\u80fd\u6bd4\u81ea\u7136\u8bed\u8a00\u66f4\u9ad8\u6548\uff0c\u4f46\u4e5f\u53ef\u80fd\u53d8\u5f97\u96be\u4ee5\u88ab\u5916\u90e8\u89c2\u5bdf\u8005\u7406\u89e3\uff0c\u4ece\u800c\u5f15\u53d1\u900f\u660e\u5ea6\u548c\u63a7\u5236\u65b9\u9762\u7684\u62c5\u5fe7\u3002", "method": "\u4f7f\u7528\u6307\u79f0\u6e38\u620f\u6846\u67b6\uff0c\u8ba9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u667a\u80fd\u4f53\u8fdb\u884c\u901a\u4fe1\uff0c\u4e3a\u8bc4\u4f30\u8bed\u8a00\u53d8\u4f53\u63d0\u4f9b\u53ef\u63a7\u3001\u53ef\u6d4b\u91cf\u7684\u5b9e\u9a8c\u73af\u5883\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09VLM\u80fd\u53d1\u5c55\u51fa\u6709\u6548\u7684\u3001\u9002\u5e94\u4efb\u52a1\u7684\u901a\u4fe1\u6a21\u5f0f\uff1b2\uff09\u80fd\u53d1\u5c55\u51fa\u5bf9\u4eba\u7c7b\u548c\u5916\u90e8\u667a\u80fd\u4f53\u90fd\u96be\u4ee5\u7406\u89e3\u7684\u9690\u853d\u534f\u8bae\uff1b3\uff09\u76f8\u4f3c\u6a21\u578b\u4e4b\u95f4\u80fd\u81ea\u53d1\u534f\u8c03\uff0c\u65e0\u9700\u663e\u5f0f\u5171\u4eab\u534f\u8bae\u3002", "conclusion": "\u4efb\u52a1\u5bfc\u5411\u901a\u4fe1\u65e2\u6709\u6f5c\u529b\u4e5f\u6709\u98ce\u9669\uff0c\u6307\u79f0\u6e38\u620f\u662f\u672a\u6765\u7814\u7a76\u8fd9\u4e00\u9886\u57df\u7684\u5b9d\u8d35\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2601.20696", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20696", "abs": "https://arxiv.org/abs/2601.20696", "authors": ["Samira Yazdanpourmoghadam", "Mahan Balal Pour", "Vahid Partovi Nia"], "title": "Enterprise Resource Planning Using Multi-type Transformers in Ferro-Titanium Industry", "comment": null, "summary": "Combinatorial optimization problems such as the Job-Shop Scheduling Problem (JSP) and Knapsack Problem (KP) are fundamental challenges in operations research, logistics, and eterprise resource planning (ERP). These problems often require sophisticated algorithms to achieve near-optimal solutions within practical time constraints. Recent advances in deep learning have introduced transformer-based architectures as promising alternatives to traditional heuristics and metaheuristics. We leverage the Multi-Type Transformer (MTT) architecture to address these benchmarks in a unified framework. We present an extensive experimental evaluation across standard benchmark datasets for JSP and KP, demonstrating that MTT achieves competitive performance on different size of these benchmark problems. We showcase the potential of multi-type attention on a real application in Ferro-Titanium industry. To the best of our knowledge, we are the first to apply multi-type transformers in real manufacturing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5c06\u591a\u7c7b\u578bTransformer\u67b6\u6784\u5e94\u7528\u4e8e\u5b9e\u9645\u5236\u9020\u73af\u5883\uff0c\u7edf\u4e00\u89e3\u51b3\u4e86\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u548c\u80cc\u5305\u95ee\u9898\u7b49\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "motivation": "\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u5982\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\u548c\u80cc\u5305\u95ee\u9898\u662f\u8fd0\u7b79\u5b66\u3001\u7269\u6d41\u548c\u4f01\u4e1a\u8d44\u6e90\u89c4\u5212\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u5b9e\u7528\u65f6\u95f4\u7ea6\u675f\u5185\u83b7\u5f97\u8fd1\u4f3c\u6700\u4f18\u89e3\u3002\u6df1\u5ea6\u5b66\u4e60\u7279\u522b\u662fTransformer\u67b6\u6784\u4e3a\u8fd9\u4e9b\u95ee\u9898\u7684\u89e3\u51b3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u91c7\u7528\u591a\u7c7b\u578bTransformer\uff08MTT\uff09\u67b6\u6784\u4f5c\u4e3a\u7edf\u4e00\u6846\u67b6\u6765\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u7c7b\u578b\u6ce8\u610f\u529b\u673a\u5236\u9002\u5e94\u4e0d\u540c\u95ee\u9898\u7ed3\u6784\uff0c\u5e76\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728JSP\u548cKP\u7684\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMTT\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u95ee\u9898\u4e0a\u90fd\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002\u7814\u7a76\u8fd8\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u94c1\u949b\u5408\u91d1\u5de5\u4e1a\u5b9e\u9645\u5236\u9020\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u591a\u7c7b\u578bTransformer\u67b6\u6784\u80fd\u591f\u6709\u6548\u7edf\u4e00\u89e3\u51b3\u4e0d\u540c\u7c7b\u578b\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u5236\u9020\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u5e94\u7528\u6f5c\u529b\u3002\u8fd9\u662f\u9996\u6b21\u5c06\u591a\u7c7b\u578bTransformer\u5e94\u7528\u4e8e\u5b9e\u9645\u5236\u9020\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2601.20735", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.20735", "abs": "https://arxiv.org/abs/2601.20735", "authors": ["Arvid Becker", "Pedro Cabalar", "Martin Di\u00e9guez", "Susana Hahn", "Javier Romero", "Torsten Schaub"], "title": "Implementing Metric Temporal Answer Set Programming", "comment": null, "summary": "We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5904\u7406\u5ea6\u91cfASP\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u5dee\u5f02\u7ea6\u675f\u89e3\u8026\u65f6\u95f4\u7c92\u5ea6\uff0c\u89e3\u51b3\u65f6\u5e8f\u7ea6\u675f\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898", "motivation": "\u4f20\u7edfASP\u96be\u4ee5\u5904\u7406\u5b9a\u91cf\u65f6\u5e8f\u7ea6\u675f\uff08\u5982\u6301\u7eed\u65f6\u95f4\u548c\u622a\u6b62\u65f6\u95f4\uff09\uff0c\u7279\u522b\u662f\u7ec6\u7c92\u5ea6\u65f6\u95f4\u7ea6\u675f\u4f1a\u663e\u8457\u52a0\u5267ASP\u7684\u63a5\u5730\u74f6\u9888\u95ee\u9898", "method": "\u5229\u7528ASP\u7684\u5dee\u5f02\u7ea6\u675f\u6269\u5c55\u6765\u5904\u7406\u65f6\u95f4\u76f8\u5173\u65b9\u9762\uff0c\u5c06\u5ea6\u91cfASP\u4e0e\u65f6\u95f4\u7c92\u5ea6\u89e3\u8026\uff0c\u5916\u90e8\u5904\u7406\u65f6\u5e8f\u7ea6\u675f", "result": "\u5f00\u53d1\u51fa\u4e00\u79cd\u4e0d\u53d7\u65f6\u95f4\u7cbe\u5ea6\u5f71\u54cd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7ec6\u7c92\u5ea6\u65f6\u5e8f\u7ea6\u675f\u4e0b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898", "conclusion": "\u901a\u8fc7\u5dee\u5f02\u7ea6\u675f\u5916\u90e8\u5904\u7406\u65f6\u5e8f\u7ea6\u675f\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5ea6\u91cfASP\u7684\u65f6\u95f4\u7c92\u5ea6\u89e3\u8026\uff0c\u63d0\u9ad8\u4e86\u5904\u7406\u5b9a\u91cf\u65f6\u5e8f\u7ea6\u675f\u7684\u53ef\u6269\u5c55\u6027"}}
{"id": "2601.20784", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.20784", "abs": "https://arxiv.org/abs/2601.20784", "authors": ["Zishen Wan", "Che-Kai Liu", "Jiayi Qian", "Hanchen Yang", "Arijit Raychowdhury", "Tushar Krishna"], "title": "REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence", "comment": "16 pages, 13 figures, 5 tables, 2026 IEEE International Symposium on High-Performance Computer Architecture (HPCA)", "summary": "Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, its deployment remains challenging due to severe inefficiencies in symbolic and probabilistic inference. Through systematic analysis of representative neuro-symbolic workloads, we identify probabilistic logical reasoning as the inefficiency bottleneck, characterized by irregular control flow, low arithmetic intensity, uncoalesced memory accesses, and poor hardware utilization on CPUs and GPUs.\n  This paper presents REASON, an integrated acceleration framework for probabilistic logical reasoning in neuro-symbolic AI. REASON introduces a unified directed acyclic graph representation that captures common structure across symbolic and probabilistic models, coupled with adaptive pruning and regularization. At the architecture level, REASON features a reconfigurable, tree-based processing fabric optimized for irregular traversal, symbolic deduction, and probabilistic aggregation. At the system level, REASON is tightly integrated with GPU streaming multiprocessors through a programmable interface and multi-level pipeline that efficiently orchestrates compositional execution. Evaluated across six neuro-symbolic workloads, REASON achieves 12-50x speedup and 310-681x energy efficiency over desktop and edge GPUs under TSMC 28 nm node. REASON enables real-time probabilistic logical reasoning, completing end-to-end tasks in 0.8 s with 6 mm2 area and 2.12 W power, demonstrating that targeted acceleration of probabilistic logical reasoning is critical for practical and scalable neuro-symbolic AI and positioning REASON as a foundational system architecture for next-generation cognitive intelligence.", "AI": {"tldr": "REASON\u662f\u4e00\u4e2a\u9488\u5bf9\u795e\u7ecf\u7b26\u53f7AI\u4e2d\u6982\u7387\u903b\u8f91\u63a8\u7406\u7684\u52a0\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684DAG\u8868\u793a\u3001\u81ea\u9002\u5e94\u526a\u679d\u548c\u6811\u72b6\u5904\u7406\u67b6\u6784\uff0c\u5728GPU\u4e0a\u5b9e\u73b012-50\u500d\u52a0\u901f\u548c310-681\u500d\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u867d\u7136\u7ed3\u5408\u4e86\u795e\u7ecf\u611f\u77e5\u548c\u7b26\u53f7\u63a8\u7406\u7684\u4f18\u52bf\uff0c\u4f46\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u4e25\u91cd\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u662f\u6982\u7387\u903b\u8f91\u63a8\u7406\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u5176\u4e0d\u89c4\u5219\u63a7\u5236\u6d41\u3001\u4f4e\u7b97\u672f\u5f3a\u5ea6\u7b49\u95ee\u9898\u5bfc\u81f4CPU\u548cGPU\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faREASON\u6846\u67b6\uff1a1\uff09\u7edf\u4e00\u7684DAG\u8868\u793a\u6355\u83b7\u7b26\u53f7\u548c\u6982\u7387\u6a21\u578b\u7684\u5171\u540c\u7ed3\u6784\uff1b2\uff09\u81ea\u9002\u5e94\u526a\u679d\u548c\u6b63\u5219\u5316\uff1b3\uff09\u53ef\u91cd\u6784\u7684\u6811\u72b6\u5904\u7406\u67b6\u6784\u4f18\u5316\u4e0d\u89c4\u5219\u904d\u5386\u3001\u7b26\u53f7\u6f14\u7ece\u548c\u6982\u7387\u805a\u5408\uff1b4\uff09\u4e0eGPU\u6d41\u591a\u5904\u7406\u5668\u7d27\u5bc6\u96c6\u6210\u7684\u53ef\u7f16\u7a0b\u63a5\u53e3\u548c\u591a\u7ea7\u6d41\u6c34\u7ebf\u3002", "result": "\u57286\u4e2a\u795e\u7ecf\u7b26\u53f7\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0cREASON\u76f8\u6bd4\u684c\u9762\u548c\u8fb9\u7f18GPU\u5b9e\u73b012-50\u500d\u52a0\u901f\u548c310-681\u500d\u80fd\u6548\u63d0\u5347\uff08TSMC 28nm\u5de5\u827a\uff09\u3002\u80fd\u591f\u5b9e\u65f6\u5b8c\u6210\u7aef\u5230\u7aef\u4efb\u52a1\uff080.8\u79d2\uff09\uff0c\u9762\u79ef6mm\u00b2\uff0c\u529f\u80172.12W\u3002", "conclusion": "\u9488\u5bf9\u6982\u7387\u903b\u8f91\u63a8\u7406\u7684\u4e13\u95e8\u52a0\u901f\u5bf9\u4e8e\u5b9e\u7528\u548c\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u7b26\u53f7AI\u81f3\u5173\u91cd\u8981\uff0cREASON\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u8ba4\u77e5\u667a\u80fd\u7684\u57fa\u7840\u7cfb\u7edf\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7AI\u90e8\u7f72\u7684\u5173\u952e\u6548\u7387\u74f6\u9888\u3002"}}
{"id": "2601.20831", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20831", "abs": "https://arxiv.org/abs/2601.20831", "authors": ["Vishnu Sashank Dorbala", "Dinesh Manocha"], "title": "MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents", "comment": null, "summary": "Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head \u03bcthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of \u03bc, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on \u03bc-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that \u03bc-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by \u03bc, noting the superior performance of \u03bcaugmented MLLMs on long and complex instruction types.", "AI": {"tldr": "MemCtrl\u6846\u67b6\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ebf\u4fee\u526a\u8bb0\u5fc6\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u8bb0\u5fc6\u5934\u03bc\u51b3\u5b9a\u4fdd\u7559\u3001\u66f4\u65b0\u6216\u4e22\u5f03\u89c2\u5bdf\uff0c\u663e\u8457\u63d0\u5347\u5177\u8eab\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bb0\u5fc6\u538b\u7f29\u548c\u68c0\u7d22\u7cfb\u7edf\u901a\u5e38\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u5927\u578b\u79bb\u7ebf\u5b58\u50a8\u7a7a\u95f4\uff0c\u8fd9\u4e0d\u9002\u5408\u9700\u8981\u5728\u4e25\u683c\u5185\u5b58\u548c\u8ba1\u7b97\u7ea6\u675f\u4e0b\u5728\u7ebf\u8fd0\u884c\u7684\u5177\u8eab\u667a\u80fd\u4f53\u3002", "method": "\u63d0\u51faMemCtrl\u6846\u67b6\uff0c\u4e3aMLLMs\u6dfb\u52a0\u53ef\u8bad\u7ec3\u7684\u8bb0\u5fc6\u5934\u03bc\u4f5c\u4e3a\u95e8\u63a7\u673a\u5236\uff0c\u5728\u7ebf\u51b3\u5b9a\u4fdd\u7559\u3001\u66f4\u65b0\u6216\u4e22\u5f03\u89c2\u5bdf\u548c\u53cd\u601d\u3002\u8bad\u7ec3\u4e24\u79cd\u03bc\uff1a\u901a\u8fc7\u79bb\u7ebf\u4e13\u5bb6\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728EmbodiedBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMemCtrl\u589e\u5f3a\u7684\u4f4e\u6027\u80fdMLLMs\u5e73\u5747\u63d0\u5347\u7ea616%\uff0c\u7279\u5b9a\u6307\u4ee4\u5b50\u96c6\u63d0\u5347\u8d85\u8fc720%\u3002\u03bc\u589e\u5f3a\u7684MLLMs\u5728\u957f\u800c\u590d\u6742\u7684\u6307\u4ee4\u7c7b\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "MemCtrl\u901a\u8fc7\u5728\u7ebf\u8bb0\u5fc6\u4fee\u526a\u6709\u6548\u63d0\u5347\u5177\u8eab\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5185\u5b58\u53d7\u9650\u7684\u5728\u7ebf\u73af\u5883\u3002"}}
{"id": "2601.20843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20843", "abs": "https://arxiv.org/abs/2601.20843", "authors": ["Saurav Prateek"], "title": "Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)", "comment": "11 pages, 6 figures, 2 tables, source code: https://github.com/SauravP97/deep-researcher-reflect-evolve/", "summary": "This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.", "AI": {"tldr": "\u63d0\u51faDeep Researcher\u67b6\u6784\uff0c\u901a\u8fc7\u987a\u5e8f\u7814\u7a76\u8ba1\u5212\u4f18\u5316\u548c\u5019\u9009\u4ea4\u53c9\u7b97\u6cd5\uff0c\u5728\u535a\u58eb\u7ea7\u7814\u7a76\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u5e76\u884c\u65b9\u6cd5\uff0c\u5728DeepResearch Bench\u4e0a\u53d6\u5f9746.21\u5206\u7684\u6700\u4f73\u6210\u7ee9", "motivation": "\u89e3\u51b3\u5e76\u884c\u6269\u5c55\u8303\u5f0f\u5728\u590d\u6742\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u77e5\u8bc6\u5b64\u5c9b\u95ee\u9898\uff0c\u5bfb\u6c42\u66f4\u9ad8\u6548\u7684\u6df1\u5ea6\u7814\u7a76\u65b9\u6cd5", "method": "\u91c7\u7528\u987a\u5e8f\u7814\u7a76\u8ba1\u5212\u4f18\u5316\uff08\u4fdd\u6301\u5168\u5c40\u7814\u7a76\u4e0a\u4e0b\u6587\uff09\u3001\u5019\u9009\u4ea4\u53c9\u7b97\u6cd5\uff08\u591aLLM\u5019\u9009\u63a2\u7d22\u641c\u7d22\u7a7a\u95f4\uff09\u548c\u4e00\u6b21\u6027\u62a5\u544a\u751f\u6210\uff0c\u57fa\u4e8eGemini 2.5 Pro\u6a21\u578b", "result": "\u5728DeepResearch Bench\u7684100\u4e2a\u535a\u58eb\u7ea7\u7814\u7a76\u4efb\u52a1\u4e0a\u83b7\u5f9746.21\u5206\uff0c\u8d85\u8d8aClaude Researcher\u3001Nvidia AIQ\u7b49\u73b0\u6709\u6700\u4f73\u7814\u7a76\u52a9\u624b\uff0c\u4e5f\u8d85\u8fc7\u4e4b\u524d\u7684Static DRA\u5de5\u4f5c", "conclusion": "\u987a\u5e8f\u6269\u5c55\u8303\u5f0f\u6301\u7eed\u4f18\u4e8e\u5e76\u884c\u81ea\u4e00\u81f4\u6027\u8303\u5f0f\uff0cDeep Researcher\u67b6\u6784\u5728\u590d\u6742\u7814\u7a76\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3aAI\u8f85\u52a9\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2601.20856", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20856", "abs": "https://arxiv.org/abs/2601.20856", "authors": ["Sebastiano Monti", "Carlo Nicolini", "Gianni Pellegrini", "Jacopo Staiano", "Bruno Lepri"], "title": "SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models", "comment": null, "summary": "Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u7a0b\u89c4\u5212\u80fd\u529b\uff0c\u53d1\u73b0\u8d85\u8fc725\u6b65\u7684\u89c4\u5212\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u5b58\u5728\u56fa\u6709\u7684\u89c4\u5212\u5bb9\u91cf\u9650\u5236", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u5df2\u88ab\u5e7f\u6cdb\u6d4b\u8bd5\uff0c\u4f46\u5176\u957f\u7a0b\u89c4\u5212\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u5212\u548c\u957f\u7a0b\u63a8\u7406\u80fd\u529b", "method": "\u63d0\u51fa\u57fa\u4e8eSokoban\u63a8\u7bb1\u5b50\u6e38\u620f\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u610f\u7b80\u5316\u4ee5\u9694\u79bb\u957f\u7a0b\u89c4\u5212\u4e0e\u72b6\u6001\u6301\u4e45\u6027\u95ee\u9898\u3002\u540c\u65f6\u6d4b\u8bd5\u4e86\u4e3a\u6a21\u578b\u914d\u5907PDDL\uff08\u89c4\u5212\u9886\u57df\u5b9a\u4e49\u8bed\u8a00\uff09\u89e3\u6790\u3001\u9a8c\u8bc1\u548c\u6c42\u89e3\u5de5\u5177\u7684\u6548\u679c", "result": "\u53d1\u73b0\u5f53\u89e3\u51b3\u65b9\u6848\u9700\u8981\u8d85\u8fc725\u6b65\u79fb\u52a8\u65f6\uff0c\u89c4\u5212\u6027\u80fd\u51fa\u73b0\u4e00\u81f4\u6027\u7684\u4e0b\u964d\uff0c\u8868\u660e\u5b58\u5728\u524d\u5411\u89c4\u5212\u5bb9\u91cf\u7684\u57fa\u672c\u7ea6\u675f\u3002\u914d\u5907PDDL\u5de5\u5177\u80fd\u5e26\u6765\u9002\u5ea6\u6539\u8fdb\uff0c\u4f46\u65e0\u6cd5\u5b8c\u5168\u514b\u670d\u67b6\u6784\u9650\u5236", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u56fa\u6709\u7684\u957f\u7a0b\u89c4\u5212\u80fd\u529b\u9650\u5236\uff0c\u4ec5\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u514b\u670d\u8fd9\u4e9b\u67b6\u6784\u9650\u5236\uff0c\u9700\u8981\u66f4\u6839\u672c\u7684\u6539\u8fdb"}}
