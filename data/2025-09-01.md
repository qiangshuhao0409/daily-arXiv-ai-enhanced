<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.IT](#cs.IT) [Total: 3]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Combined Push-Pull Access Framework for Digital Twin Alignment and Anomaly Reporting](https://arxiv.org/abs/2508.21516)
*Federico Chiariotti,Fabio Saggese,Andrea Munari,Leonardo Badia,Petar Popovski*

Main category: cs.NI

TL;DR: 数字双生体中推出一种动态推-拉更新调度器(PPS)，在保持异常检测性能的同时，将错误信息浪龄(AoII)降低20%以上，最差情况异常检测延迟从70ms缩减到20ms。


<details>
  <summary>Details</summary>
Motivation: 数字双生体的准确性依赖于与物理系统的及时同步，需要在正常状态下的拉取更新和异常状态下的推送更新之间找到最优的资源分配平衡。

Method: 设计了一种动态推-拉更新调度器(PPS)中经访问框架，资源动态分配给拉取更新(减少偏移)和推送更新(异常报告)两类更新。

Result: 在保持相同异常检测保证的前提下，将错误信息浪龄(AoII)优化了20%以上，最差情况异常检测延迟从70ms降至20ms(在1ms平均偏移AoII约束下)。

Conclusion: PPS框架能够有效平衡数字双生体的正常状态同步和异常检测需求，显著提升了系统性能和响应速度。

Abstract: A digital twin (DT) contains a set of virtual models of real systems and
processes that are synchronized to their physical counterparts. This enables
experimentation and examination of counterfactuals, simulating the consequences
of decisions in real time. However, the DT accuracy relies on timely updates
that maintain alignment with the real system. We can distinguish between: (i)
pull-updates, which follow a request from the DT to the sensors, to decrease
its drift from the physical state; (ii) push-updates, which are sent directly
by the sensors since they represent urgent information, such as anomalies. In
this work, we devise a push-pull scheduler (PPS) medium access framework, which
dynamically allocates the communication resources used for these two types of
updates. Our scheme strikes a balance in the trade-off between DT alignment in
normal conditions and anomaly reporting, optimizing resource usage and reducing
the drift age of incorrect information (AoII) by over 20% with respect to
state-of-the-art solutions, while maintaining the same anomaly detection
guarantees, as well as reducing the worst-case anomaly detection AoII from 70
ms to 20 ms when considering a 1 ms average drift AoII constraint.

</details>


### [2] [QoS-Aware Proportional Fairness Scheduling for Multi-Flow 5G UEs: A Smart Factory Perspective](https://arxiv.org/abs/2508.21783)
*Mohamed Seliem,Utz Roedig,Cormac Sreenan,Dirk Pesch*

Main category: cs.NI

TL;DR: 本文扩展Simu5G模拟框架支持QFI级别的多流建模，并提出QoS-PF调度器来优化5G网络中异构流量的资源分配，在智能工厂场景中显著提升了截止时间遵守率和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有模拟框架缺乏对5G网络中多并发流量流在QoS Flow Identifier级别的高保真建模能力，无法准确模拟智能工厂中设备同时处理多种QoS要求不同的流量场景。

Method: 扩展Simu5G模拟框架支持per-QFI建模，并设计新型QoS感知比例公平调度器(QoS-PF)，动态平衡延迟、保证比特率和优先级指标来优化异构流量的资源分配。

Result: 在包含边缘托管机器视觉、实时控制回路和批量数据传输的智能工厂场景中，QoS-PF调度器在保持吞吐量的同时，显著改善了截止时间遵守率和公平性。

Conclusion: 该工作为工业5G部署中高级QoS策略的模拟和分析提供了方法论和架构基础，所有扩展都以模块化和开源方式实现以支持未来研究。

Abstract: Private 5G networks are emerging as key enablers for smart factories, where a
single device often handles multiple concurrent traffic flows with distinct
Quality of Service (QoS) requirements. Existing simulation frameworks, however,
lack the fidelity to model such multi-flow behavior at the QoS Flow Identifier
(QFI) level. This paper addresses this gap by extending Simu5G to support
per-QFI modeling and by introducing a novel QoS-aware Proportional Fairness
(QoS-PF) scheduler. The scheduler dynamically balances delay, Guaranteed Bit
Rate (GBR), and priority metrics to optimize resource allocation across
heterogeneous flows. We evaluate the proposed approach in a realistic smart
factory scenario featuring edge-hosted machine vision, real-time control loops,
and bulk data transfer. Results show that QoS-PF improves deadline adherence
and fairness without compromising throughput. All extensions are implemented in
a modular and open-source manner to support future research. Our work provides
both a methodological and architectural foundation for simulating and analyzing
advanced QoS policies in industrial 5G deployments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 研究架构归纳偏置如何影响大语言模型在教学对话中的认知行为，通过符号支架和短期记忆机制提升苏格拉底式教学的适应性结构化推理能力


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型架构中的归纳偏置对其在教学对话中认知行为的影响，旨在提升模型在教学场景中的结构化推理和适应性能力

Method: 引入符号支架机制和短期记忆模式，通过五种系统变体的对照消融实验，使用专家设计的评估标准（支架、响应性、符号推理、对话记忆）进行模型输出评估

Result: 完整系统在所有基线变体中表现最优，移除记忆或符号结构会显著降低关键认知行为（抽象、适应性探询、概念连续性）

Conclusion: 架构支架能够可靠地塑造大语言模型中涌现的教学策略，支持处理层面的解释，表明架构设计对模型认知行为具有重要影响

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [4] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 评估GraphRAG在阿尔茨海默病领域的应用效果，比较其与标准GPT-4o在回答专业问题时的质量和可追溯性差异


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学研究中面临幻觉、领域知识有限和缺乏可追溯性等挑战，需要评估GraphRAG在生物医学等知识密集型领域的实际效果

Method: 构建包含50篇论文和70个专家问题的阿尔茨海默病数据库，使用GPT-4o作为LLM，比较GraphRAG与标准GPT-4o的回答质量，并评估RAG和GraphRAG系统的可追溯性

Result: 研究评估了两种流行GraphRAG系统的性能，提供了质量对比结果和可追溯性分析

Conclusion: 研究提供了易于使用的界面和预构建数据库，供研究人员测试标准RAG和GraphRAG在阿尔茨海默病领域的表现

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [5] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI是一个创新的AI平台，用于解决产品工程中管理和集成大量不同数据源的挑战，通过生成式AI、向量化和智能编排技术提供动态、上下文感知的响应。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程领域中管理和集成大量不同数据源的挑战，提升数字生态系统中用户参与度，处理当前和新服务相关的查询需求。

Method: 采用先进的AI技术，包括生成式AI、向量化和智能编排（agentic orchestration），提供动态和上下文感知的复杂查询响应。

Result: 开发了一个能够处理不同数据源集成、增强用户参与度的AI平台，能够有效应对复杂用户查询。

Conclusion: MultiFluxAI平台通过先进的AI技术成功解决了产品工程中的数据集成和管理挑战，为数字生态系统提供了有效的查询响应解决方案。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [6] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO是一个基于大语言模型的集成本体学习框架，通过同时利用多个医学本体图谱，在异构本体系统内和跨系统进行双轴知识传播，以增强医学概念表示学习。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一本体系统或多个孤立本体系统的知识整合，缺乏跨本体连接的统一学习结构，导致概念表示学习局限于本体内部关系。

Method: 1) 使用LLM提供图检索增强的概念嵌入初始化；2) 通过双轴知识传播联合学习不同本体图谱中的医学概念：本体内部垂直传播和本体间水平传播；3) 作为插件编码器与现有EHR预测模型兼容。

Result: 在两个公共数据集上的实验验证了LINKO优于最先进基线方法的性能，在数据有限和罕见疾病预测场景中表现出更强的鲁棒性。

Conclusion: LINKO框架通过整合多本体系统和双轴知识传播，显著提升了医学概念表示学习的效果，特别是在数据稀缺和罕见疾病预测方面展现出优势。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [7] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: TiG框架通过将强化学习决策重新表述为语言建模任务，让大语言模型在游戏环境中直接交互学习程序性知识，同时保持其推理和解释能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务上表现出色，但在简单交互任务中表现不佳，这揭示了陈述性知识和程序性知识之间的关键差距

Method: TiG将基于强化学习的决策重新表述为语言建模任务：LLMs生成语言指导的策略，通过在线强化学习根据环境反馈迭代优化

Result: TiG成功弥合了陈述性和程序性知识之间的差距，以显著更低的数据和计算需求实现了与传统RL方法相竞争的性能

Conclusion: TiG框架不仅提高了LLMs在交互任务中的性能，还通过自然语言解释大大提升了复杂交互任务的透明度和可解释性

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [8] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM是一个综合性的音频-语言模型评测基准，整合了多个数据集（包括新的PARADE和CoRe-Bench数据集），从10个重要维度全面评估ALMs性能，并标准化了评测流程。


<details>
  <summary>Details</summary>
Motivation: 当前音频-语言模型评测缺乏标准化基准，大多数基准只测试一两个能力，且忽略了公平性、安全性等重要方面，不同评测之间难以进行模型比较。

Method: 创建AHELM基准，整合多个数据集（包括新开发的PARADE和CoRe-Bench数据集），标准化提示词、推理参数和评估指标，对14个开源和闭源ALMs以及3个基线系统进行全面评测。

Result: Gemini 2.5 Pro在10个维度中的5个表现最佳，但在ASR任务中显示出群体不公平性（p=0.01）。基线系统表现良好，其中一个仅具备语音转文本能力的系统总体排名第5。

Conclusion: AHELM提供了一个全面、标准化的ALMs评测框架，揭示了当前模型的优势和不足，特别是公平性问题，并展示了简单基线系统的竞争力。该基准将持续更新和发展。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [9] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文提出了AI计算的七层架构模型，从物理层到应用层，分析了AI发展的技术挑战和经济问题，并基于互联网行业发展预测AI未来轨迹。


<details>
  <summary>Details</summary>
Motivation: AI发展已从学术研究转向实际应用，但在各个层面都面临诸多挑战，需要从结构化角度分析AI的机遇与挑战。

Method: 提出七层AI计算架构模型（物理层、链路层、神经网络层、上下文层、智能体层、编排层、应用层），通过大语言模型的三阶段演进分析每层的发展轨迹和关键技术。

Result: 系统分析了各层的技术发展路径：1-2层讨论计算问题和扩展策略，3层探讨LLM发展路径，4层比较上下文内存与传统处理器内存，5-7层分析AI智能体发展趋势和生态影响。

Conclusion: AI发展不仅涉及技术挑战，还需要构建自持续的经济生态系统，基于互联网行业经验可以预测AI未来的发展轨迹。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [10] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN是一个基于AJAN多智能体框架和CARLA驾驶模拟器的半自动化交通场景生成与仿真工具，提供可视化界面和智能决策功能


<details>
  <summary>Details</summary>
Motivation: 城市交通场景中不同类型交互智能体（行人、骑行者、自动驾驶车辆）的建模和虚拟仿真仍然是一个挑战

Method: 基于AJAN多智能体工程框架和CARLA驾驶模拟器，提供可视化用户界面，采用SPARQL行为树进行智能体决策和交互

Result: 开发了CARJAN工具，实现了交互式、智能化的虚拟交通场景生成和仿真

Conclusion: CARJAN为CARLA中的虚拟交通场景提供了首个集成化的智能体生成和仿真方法

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [11] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文从认知视角研究知识管理中的遗忘操作，在Spohn排序函数的认知状态下提出了五种通用遗忘类型和七个具体操作，建立了丰富的公理体系来评估不同遗忘算子。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘操作主要基于经典逻辑，如变量消除和AGM信念修正理论中的收缩操作。本文旨在从认知角度研究具有更丰富语义结构的认知状态中的遗忘操作，探索在认知背景下遗忘的含义。

Method: 采用认知视角，在Spohn排序函数的认知状态下提出五种通用遗忘类型，并实例化为七个具体遗忘操作。借鉴逻辑编程和AGM理论的遗忘公理，构建了丰富的公理体系来评估这些操作。

Result: 对所有具体遗忘操作进行了全面的公理评估，得出了新颖的综合概览，突出了不同遗忘算子之间的差异和共同点。

Conclusion: 研究将经典逻辑中的遗忘操作提升到认知层面，为知识管理中的遗忘操作提供了更丰富的理论框架和评估体系，揭示了不同遗忘算子的特性和适用场景。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [12] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 本文提出了一种从状态-动作轨迹中学习STRIPS+模型的新方法SYNTH，用于解决滑动拼图等领域的模型学习问题，其中状态和动作信息都不完整。


<details>
  <summary>Details</summary>
Motivation: 现有的模型学习方法大多假设动作是完整的STRIPS动作或所有谓词都可观察，但现实场景中状态信息往往不完整（如缺少空白位置信息），动作参数也不完整。需要一种更现实的学习方法。

Method: 引入STRIPS+变体，允许动作参数在前提条件中隐式存在并支持有限形式的存在量化。SYNTH算法为每个动作构建分层序列的前提条件表达式（查询），用于识别状态中的唯一对象并接地隐式动作参数。

Result: 建立了SYNTH算法的正确性和完备性，并在从现有STRIPS领域衍生的STRIPS+模型生成的状态-动作轨迹上测试了其可扩展性。

Conclusion: SYNTH算法能够有效学习STRIPS+模型，解决了在状态和动作信息都不完整的现实场景下的模型学习问题，为更广泛的应用提供了理论基础和实践方法。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [13] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个包含311个任务的基准测试，专门设计来评估多模态语言模型在需要深度视觉推理、来源验证和长时程工具使用的复杂网页浏览任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态浏览基准测试往往可以通过简单的固定工作流程解决，无法真正测试模型在细粒度视觉推理、来源验证和长时程工具使用方面的能力。

Method: 采用空间-时间外推法构建任务，要求模型从空间线索（微文本、部件外观、布局、标识）和时间痕迹（广播覆盖、季节上下文）中提取信息，通过迭代的文本-图像搜索进行传播，并在检索噪声下进行交叉验证。

Result: 最强代理模型（o3）在无搜索情况下达到15.1%准确率，在框架下通过搜索达到36.0%；而最强的开源模型（Qwen-2.5-VL-72B-Instruct）在无搜索时为0.0%，经过20轮搜索后达到6.9%。

Conclusion: 该基准测试揭示了当前多模态语言模型在来源验证、基于部件的推理和长时程规划方面的显著不足，为未来模型开发提供了重要的评估标准。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [14] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 提出了一种基于模糊Z数的智慧推理计算框架，将智慧量化为包含评分和置信度的双属性表示，通过道德困境任务验证了其有效性和区分效度


<details>
  <summary>Details</summary>
Motivation: 传统智慧测量依赖自评报告，无法反映智慧固有的谦逊和不确定性特征，需要开发能同时考虑多维性和置信度的计算方法来改进心理学测量并实现人性化AI

Method: 使用模糊推理系统和Z数（智慧分数+置信分数），通过文化中性图画道德困境任务收集100名参与者的口语反应，映射到5个智慧成分，用21条规则和基于高斯核密度估计的隶属函数进行整合

Result: 概念验证研究表明，系统产生的双属性智慧表示与既有量表呈适度但显著相关，与无关特质关系可忽略，支持了聚合效度和区分效度

Conclusion: 将智慧形式化为多维、不确定性感知的构念，通过Z数操作化，不仅推进心理学测量，还为AI系统提供了可解释、置信度敏感的安全推理方法

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [15] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新型解释范式，用于自动规划领域，通过最小化修改规划问题来满足期望属性，计算复杂度与规划求解相当。


<details>
  <summary>Details</summary>
Motivation: 传统的反事实解释仅关注对现有计划的最小修改，无法捕捉问题的高层特性，需要一种能够解释规划问题本身属性的新方法。

Method: 提出基于反事实场景的解释范式，给定规划问题P和LTLf公式ψ，识别对P的最小修改使其能够生成满足ψ的计划。提出了两种基于显式量化满足ψ计划的定性实例化方法。

Result: 分析了不同类型修改下生成反事实场景的计算复杂度，证明生成反事实场景的成本通常与计算P的计划相当，具有实际可行性。

Conclusion: 该框架为构建实用算法提供了基础，能够有效解释规划问题的特性，比传统反事实解释更能捕捉问题的高层属性。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [16] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI是一个GenAI框架，通过集成多个大型语言模型(LLM)来自动解释过程挖掘结果并生成报告，简化了医疗保健领域过程挖掘的应用，使技术分析结果更容易被临床医生、数据科学家和研究人员理解。


<details>
  <summary>Details</summary>
Motivation: 过程挖掘在医疗保健工作流分析中具有强大潜力，但面临技术复杂性高、缺乏标准化方法和实践培训资源有限等障碍，需要开发更易用的解决方案。

Method: 开发了HealthProcessAI框架，作为Python(PM4PY)和R(bupaR)过程挖掘库的封装器，集成多个LLM进行自动化过程图解释和报告生成。使用脓毒症进展数据作为概念验证，通过OpenRouter平台比较了5个最先进LLM模型的输出。

Result: 框架成功处理了4个概念验证场景的脓毒症数据，展示了稳健的技术性能。LLM评估显示Claude Sonnet-4和Gemini 2.5-Pro获得最高一致性分数(3.79/4.0和3.65/4.0)。

Conclusion: 该框架通过结合结构化分析和AI驱动的解释，代表了将复杂过程挖掘结果转化为医疗保健应用可操作见解的新方法学进展，显著提高了过程挖掘在医疗领域的可访问性和实用性。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [17] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [18] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 提出了确定性分散POMDPs（Det-Dec-POMDPs）子类，并开发了IDPP求解器来处理大规模此类问题


<details>
  <summary>Details</summary>
Motivation: 许多高级多智能体规划问题（如多机器人导航）可以用确定性动作和观测有效建模，但现有Dec-POMDP求解器无法高效处理大规模问题

Method: 基于经典Joint Equilibrium Search for Policies框架，提出了Iterative Deterministic POMDP Planning (IDPP)方法，专门针对确定性转移和观测的大规模Det-Dec-POMDPs进行优化

Result: IDPP方法能够处理当前Dec-POMDP求解器无法高效解决的大规模确定性分散POMDP问题

Conclusion: Det-Dec-POMDPs为多智能体规划提供了有效的建模框架，IDPP方法为此类问题提供了实用的求解方案

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [19] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 这篇论文提出了一种集成传统网络优化模型和大语言模型的框架，为供应链规划提供交互式、可解释性和角色感知的决策支持系统。


<details>
  <summary>Details</summary>
Motivation: 平泽操作研究输出与业务参与者理解之间的洞层，需要一种能够生成自然语言摘要、上下文可视化和岚配关键性能指标的系统来提升决策支持效果。

Method: 核心优化模型采用混合整数规划解决多周期多物品的战术性库存重新分配问题。技术架构包含AI代理、RESTful API和动态用户界面，支持实时交互、配置更新和基于模拟的洞察。

Result: 案例研究证明该系统能够提升规划效果，包括预防断货、降低成本和维持服务水平。

Conclusion: 该集成框架有效地缩小了优化模型与业务理解之间的差距，未来可通过集成私有LLM、迁移学习、强化学习和贝叶斯神经网络来进一步提升可解释性、适应性和实时决策能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [20] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: 将多启发式A*（MHA*）扩展为随时算法A-MHA*，能够快速找到可行次优解并持续改进，同时保持原始的最优界限和完备性保证


<details>
  <summary>Details</summary>
Motivation: MHA*虽然能利用多个不可采纳启发式函数加速搜索，但只能一次性求解且需要精心设置膨胀因子，无法随时间持续改进解的质量

Method: 受ARA*算法启发，将ARA*的概念精确适配到MHA*框架中，开发出随时版本A-MHA*

Result: 在3D路径规划和滑块拼图问题上测试，A-MHA*相比MHA*和其他随时算法表现出更好的性能

Conclusion: A-MHA*成功将MHA*扩展为随时算法，在保持理论保证的同时实现了快速初始解和持续改进的能力

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [21] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: MEDLEY框架通过保留多个AI模型的多样性输出来利用偏见，而非消除偏见，将AI不完美性转化为临床监督下的医疗推理资源


<details>
  <summary>Details</summary>
Motivation: 传统观点认为医疗AI中的偏见是需要消除的缺陷，但人类推理本身就包含由教育、文化、经验塑造的偏见，这些偏见可能不可避免且具有价值

Method: 提出MEDLEY概念框架，协调多个AI模型同时保留其多样性输出，将模型特定偏见记录为潜在优势，将幻觉视为待临床验证的临时假设

Result: 开发了概念验证演示器，使用30多个大型语言模型，在合成病例中同时保留共识和少数观点，使诊断不确定性和潜在偏见对临床监督透明

Conclusion: MEDLEY通过重新定义AI不完美性为资源，提供了范式转变，为开发可信赖医疗AI系统开辟了新的监管、伦理和创新途径

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [22] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: PosterForest是一个无需训练的科学海报生成框架，通过层次化中间表示和多智能体协作，实现文本与视觉元素的语义整合和结构优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多忽视科学文档的层次结构和文本视觉元素的语义整合，需要一种能够同时解决这两个挑战的自动化海报生成方法。

Method: 引入Poster Tree层次化中间表示，采用多智能体协作策略，内容摘要和布局规划智能体通过迭代协调和相互反馈实现联合优化。

Result: 在多个学术领域的实验表明，该方法在定性和定量评估上均优于现有基线，生成的海报质量最接近专家设计标准。

Conclusion: PosterForest框架能够有效生成具有逻辑一致性、内容保真度和视觉连贯性的高质量科学海报，在信息保存、结构清晰度和用户偏好方面表现优异。

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [23] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 本文提出了一种用于旅行商问题的变分量子算法，采用紧凑排列编码减少量子比特需求，并通过优化-冻结-重用策略，先在训练实例上优化电路结构，然后在测试时冻结结构仅重调参数，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决传统变分量子算法在旅行商问题中需要大量量子比特和重复结构搜索的高计算成本问题，旨在开发一种适合NISQ设备的实用算法。

Method: 结合紧凑排列编码减少量子比特需求，采用优化-冻结-重用策略：先用模拟退火优化训练实例的电路结构，然后冻结该结构，在新实例上仅重新优化电路参数。

Result: 在4-7个城市的40个随机对称实例上，4城市达到100%最优路径采样概率，5城市90%，6城市80%，7城市降至约20%，显示方法在中等规模问题上的良好泛化能力。

Conclusion: 该方法在中等规模问题上表现出强大的泛化能力，冻结Ansatz策略能显著减少求解时间而不降低解质量，但存在可扩展性限制，未来可扩展到车辆路径和作业车间调度等更复杂问题。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [24] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 本文提出了在给定摘要因果图背景知识下，保证时间变量微观层面边可定向性的条件，为复杂时间系统中的因果发现提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析中理解时间变量间的因果关系是一个核心挑战，特别是当完整的因果结构未知时。专家通常能提供摘要因果图来捕捉主要因果关系，但如何利用这种高层抽象来指导微观层面的因果发现需要理论支持。

Method: 提出了在假设存在忠实且因果充分的分布条件下，给定摘要因果图的背景知识，保证微观层面时间变量间边可定向性的理论条件。

Result: 研究结果提供了即使在宏观层面存在循环或双向边的情况下，微观层面边定向的理论保证。

Conclusion: 这些发现为利用摘要因果图指导复杂时间系统中的因果发现提供了实用指导，强调了将专家知识融入观测时间序列数据因果推理的价值。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [25] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: 提出了Tree-guided Diffusion Planner (TDP)，一种零样本测试时规划框架，通过结构化轨迹生成平衡探索与利用，在非凸目标、不可微约束和多奖励结构的真实场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准梯度引导在凸可微奖励场景中表现良好，但在真实世界的非凸目标、不可微约束和多奖励结构场景中效果显著下降。现有监督规划方法需要任务特定训练或价值估计器，限制了测试时灵活性和零样本泛化能力。

Method: 将测试时规划构建为树搜索问题，采用双层采样过程：1) 通过无训练粒子引导生成多样化父轨迹以鼓励广泛探索；2) 通过任务目标引导的快速条件去噪精炼子轨迹。仅使用预训练模型和测试时奖励信号。

Result: 在三个多样化任务（迷宫金币收集、机械臂方块操作、AntMaze多目标探索）上评估，TDP在所有任务上始终优于最先进方法。

Conclusion: TDP通过探索多样化轨迹区域并利用扩展解空间中的梯度信息，有效解决了梯度引导的局限性，为测试时规划提供了灵活且强大的零样本解决方案。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


### [26] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: 提出多智能体协作系统模拟临床团队会诊，通过分层迭代辩论提升临床问题识别准确率，在心力衰竭、急性肾损伤和脓毒症诊断上表现优于单智能体基线


<details>
  <summary>Details</summary>
Motivation: 临床叙述的复杂性使得自动化解读具有挑战性，单一大型语言模型缺乏高风险临床任务所需的鲁棒性

Method: 设计协作多智能体系统，模拟临床咨询团队。Manager智能体协调动态分配的专业智能体团队，通过分层迭代辩论达成共识，仅分析SOAP笔记中的主观和客观部分

Result: 在420份MIMIC-III笔记数据集上评估，动态多智能体配置在识别充血性心力衰竭、急性肾损伤和脓毒症方面表现持续改善

Conclusion: 通过模拟临床团队推理过程，该系统为开发更准确、鲁棒和可解释的临床决策支持工具提供了有前景的路径

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [27] [A Flexible Design for Beam Squint Effect Suppression in IRS-Aided THz Communications](https://arxiv.org/abs/2508.21295)
*Yanze Zhu,Qingqing Wu,Wen Chen,Yang Liu,Ruiqi Liu*

Main category: cs.IT

TL;DR: 提出在太赫兹宽带MISO系统中使用基站和智能反射面的可移动组件来缓解双波束偏移效应，通过优化天线和子阵列位置来最大化最小接收功率


<details>
  <summary>Details</summary>
Motivation: 解决太赫兹宽带通信中基站和智能反射面耦合引起的双波束偏移效应问题，提高系统性能

Method: 采用主化最小化(MM)算法来优化可移动天线阵列和IRS子阵列的位置配置

Result: 数值结果表明所提算法能有效缓解双波束偏移效应，提升太赫兹宽带通信性能

Conclusion: 在基站和IRS上使用可移动组件能有效缓解太赫兹宽带通信中的双波束偏移效应，提出的MM算法具有良好效果

Abstract: In this paper, we study employing movable components on both base station
(BS) and intelligent reflecting surface (IRS) in a wideband terahertz (THz)
multiple-input-single-output (MISO) system, where the BS is equipped with a
movable antenna (MA) array and the IRS consists of movable subarrays. To
alleviate double beam squint effect caused by the coupling of beam squint at
the BS and IRS, we propose to maximize the minimal received power across a wide
THz spectrum by delicately configuring the positions of MAs and IRS subarrays,
which is highly challenging. By adopting majorization-minimization (MM)
methodology, we develop an algorithm to tackle the aforementioned optimization.
Numerical results demonstrate the effectiveness of our proposed algorithm and
the benefit of utilizing movable components on the BS and IRS to mitigate
double beam squint effect in wideband THz communications.

</details>


### [28] [On the Weight Distribution of Concatenated Code Ensemble Based on the Plotkin Construction](https://arxiv.org/abs/2508.21515)
*Xiao Ma*

Main category: cs.IT

TL;DR: 本文揭示了基于Plotkin构造的级联码集合的重量分布与其分量码重量分布之间的关系


<details>
  <summary>Details</summary>
Motivation: 研究级联码集合的重量分布特性，为计算包括Reed-Muller类码在内的多种码的集合重量分布提供理论基础

Method: 通过分析基于Plotkin构造的级联码集合，建立其重量分布与分量码重量分布之间的数学关系

Result: 发现了级联码集合重量分布与分量码重量分布之间的明确关系，这一关系可用于计算多种码的集合重量分布

Conclusion: 提出的关系为计算Reed-Muller类码等码的集合重量分布提供了有效方法，具有重要的理论价值和应用前景

Abstract: In this note, we reveal a relation between the weight distribution of a
concatenated code ensemble based on the Plotkin construction and those of its
component codes. The relation may find applications in the calculation of the
ensemble weight distributions for many codes, including Reed-Muller (RM)-like
codes.

</details>


### [29] [Analysis of Semantic Communication for Logic-based Hypothesis Deduction](https://arxiv.org/abs/2508.21755)
*Ahmet Faruk Saz,Siheng Xiong,Faramarz Fekri*

Main category: cs.IT

TL;DR: 该论文提出了一种基于一阶逻辑推理的语义通信分析方法，通过后验分布近似和资源分配优化，设计了单轮和多轮通信策略，在预算约束下实现了最优性能。


<details>
  <summary>Details</summary>
Motivation: 研究语义通信中发送方在不了解真实世界状态的情况下，如何通过有限信息传输帮助接收方识别最符合真实状态的假设，解决传统通信中信息冗余的问题。

Method: 使用Stirling近似将问题转化为有限时域资源分配问题，应用KKT条件得到截断注水算法解，利用对称性和置换不变性保证全局最优性，设计消息选择策略并建模为m元贝叶斯假设检验问题。

Result: 在最大后验概率规则下，所提出的通信策略在预算约束内达到最优性能，实验验证了相比随机选择和现有方法错误率显著降低。

Conclusion: 该方法为语义通信提供了理论框架和实用策略，证明了在逻辑推理场景下有限信息传输的有效性，为未来语义通信系统设计提供了重要参考。

Abstract: This work presents an analysis of semantic communication in the context of
First-Order Logic (FOL)-based deduction. Specifically, the receiver holds a set
of hypotheses about the State of the World (SotW), while the transmitter has
incomplete evidence about the true SotW but lacks access to the ground truth.
The transmitter aims to communicate limited information to help the receiver
identify the hypothesis most consistent with true SotW. We formulate the
objective as approximating the posterior distribution at the transmitter to the
receiver. Using Stirling's approximation, this reduces to a constrained,
finite-horizon resource allocation problem. Applying the Karush-Kuhn-Tucker
conditions yields a truncated water-filling solution. Despite the problem's
non-convexity, symmetry and permutation invariance ensure global optimality.
Based on this, we design message selection strategies, both for single- and
multi-round communication, and model the receiver's inference as an m-ary
Bayesian hypothesis testing problem. Under the Maximum A Posteriori (MAP) rule,
our communication strategy achieves optimal performance within budget
constraints. We further analyze convergence rates and validate the theoretical
findings through experiments, demonstrating reduced error over random selection
and prior methods.

</details>
