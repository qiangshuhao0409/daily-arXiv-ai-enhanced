{"id": "2511.16751", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16751", "abs": "https://arxiv.org/abs/2511.16751", "authors": ["Henry Shao", "Kasidis Arunruangsirilert"], "title": "Performance Comparison of 5G NR Uplink MIMO and Uplink Carrier Aggregations on Commercial Network", "comment": "IEEE Consumer Communications & Networking Conference 2026 (IEEE CCNC 2026), 9-12 January 2026, Las Vegas, NV, USA", "summary": "Demands for uplink on mobile networks are increasing with the rapid development of social media platforms, 4K/8K content creation, IoT applications, and Fixed Wireless Access (FWA) broadband. As a result, Uplink MIMO (UL-MIMO) and Uplink Carrier Aggregation (UL-CA) have been widely deployed for the first time on commercial 5G networks. UL-MIMO enables the transmission of two data streams on one frequency band in strong RF conditions, theoretically doubling throughput and efficiency. On the other hand, UL-CA allows for simultaneous upload on greater channel widths, allowing more resources to be assigned to a single UE for higher throughput. In the United States, T-Mobile USA, a mobile network operator (MNO), has deployed network-wide 5G Standalone (SA), along with UL-MIMO on Time Division Duplex (TDD) band n41 and UL-CA between TDD and Frequency Division Duplex (FDD) NR bands. In this paper, the uplink throughput performance of UL-MIMO and UL-CA will be evaluated on the commercial T-Mobile 5G network on a variety of RF environments and modes of transportation. It was found that, even with the efficiency gains, UL-MIMO yields slower uplink throughput in most scenarios. However, in stronger RF conditions, UL-MIMO can provide an adequate user experience, so capacity can be conserved by reserving UL-CA for UE in weaker RF conditions.", "AI": {"tldr": "\u8bc4\u4f30T-Mobile 5G\u7f51\u7edc\u4e2dUL-MIMO\u548cUL-CA\u7684\u4e0a\u884c\u541e\u5410\u91cf\u6027\u80fd\uff0c\u53d1\u73b0UL-MIMO\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u541e\u5410\u91cf\u8f83\u4f4e\uff0c\u4f46\u5728\u5f3aRF\u6761\u4ef6\u4e0b\u53ef\u63d0\u4f9b\u8db3\u591f\u7528\u6237\u4f53\u9a8c\uff0c\u5efa\u8bae\u5c06UL-CA\u4fdd\u7559\u7ed9\u5f31RF\u6761\u4ef6\u7684\u7528\u6237\u8bbe\u5907\u3002", "motivation": "\u968f\u7740\u793e\u4ea4\u5a92\u4f53\u30014K/8K\u5185\u5bb9\u521b\u4f5c\u3001\u7269\u8054\u7f51\u5e94\u7528\u548cFWA\u5bbd\u5e26\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u79fb\u52a8\u7f51\u7edc\u4e0a\u884c\u9700\u6c42\u4e0d\u65ad\u589e\u52a0\uff0cUL-MIMO\u548cUL-CA\u9996\u6b21\u5728\u5546\u75285G\u7f51\u7edc\u4e2d\u5e7f\u6cdb\u90e8\u7f72\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5b9e\u9645\u6027\u80fd\u3002", "method": "\u5728\u5546\u7528T-Mobile 5G\u7f51\u7edc\u4e0a\uff0c\u5728\u4e0d\u540cRF\u73af\u5883\u548c\u4ea4\u901a\u6a21\u5f0f\u4e0b\u8bc4\u4f30UL-MIMO\u548cUL-CA\u7684\u4e0a\u884c\u541e\u5410\u91cf\u6027\u80fd\u3002", "result": "\u5373\u4f7f\u6709\u6548\u7387\u589e\u76ca\uff0cUL-MIMO\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u4ea7\u751f\u8f83\u6162\u7684\u4e0a\u884c\u541e\u5410\u91cf\uff0c\u4f46\u5728\u5f3aRF\u6761\u4ef6\u4e0b\u53ef\u63d0\u4f9b\u8db3\u591f\u7684\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "UL-MIMO\u5728\u5f3aRF\u6761\u4ef6\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5efa\u8bae\u5c06\u5bb9\u91cf\u66f4\u5927\u7684UL-CA\u4fdd\u7559\u7ed9\u5f31RF\u6761\u4ef6\u7684\u7528\u6237\u8bbe\u5907\u4ee5\u4f18\u5316\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u3002"}}
{"id": "2511.16797", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16797", "abs": "https://arxiv.org/abs/2511.16797", "authors": ["Carolina Gallardo-Pavesi", "Yaime Fern\u00e1ndez", "Javier E. Soto", "Cecilia Hern\u00e1ndez", "Miguel Figueroa"], "title": "A streaming algorithm and hardware accelerator for top-K flow detection in network traffic", "comment": "8 pages, 5 figures, to be published in 2025 28th Euromicro Conference on Digital System Design (DSD)", "summary": "Identifying the largest K flows in network traffic is an important task for applications such as flow scheduling and anomaly detection, which aim to improve network efficiency and security. However, accurately estimating flow frequencies is challenging due to the large number of flows and increasing network speeds. Hardware accelerators are often used in this endeavor due to their high computational power, but their limited amount of on-chip memory constrains their performance. Various sketch-based algorithms have been proposed to estimate properties of traffic such as frequency, with lower memory usage and theoretical bounds, but they often under perform with the skewed distribution of network traffic. In this work, we propose an algorithm for top-K identification using a modified TowerSketch and a priority queue array. Tested on real traffic traces, we identify the top-K flows, with K up to 32,768, with a precision of more than 0.94, and estimate their frequency with an average relative error under 1.96%. We designed and implemented an accelerator for this algorithm on an AMD VirtexU280 UltraScale+ FPGA, which processes one packet per cycle at392 MHz, reaching a minimum line rate of more than 200 Gbps.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6539\u8fdbTowerSketch\u548c\u4f18\u5148\u7ea7\u961f\u5217\u9635\u5217\u7684top-K\u6d41\u8bc6\u522b\u7b97\u6cd5\uff0c\u5728\u771f\u5b9e\u6d41\u91cf\u8ffd\u8e2a\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8bc6\u522b\u548c\u9891\u7387\u4f30\u8ba1\uff0c\u5e76\u5728FPGA\u4e0a\u5b9e\u73b0\u9ad8\u901f\u5904\u7406\u3002", "motivation": "\u7f51\u7edc\u6d41\u91cf\u4e2d\u8bc6\u522b\u6700\u5927K\u4e2a\u6d41\u5bf9\u4e8e\u6d41\u91cf\u8c03\u5ea6\u548c\u5f02\u5e38\u68c0\u6d4b\u5f88\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u6d41\u91cf\u6570\u91cf\u5927\u3001\u7f51\u7edc\u901f\u5ea6\u5feb\uff0c\u51c6\u786e\u4f30\u8ba1\u6d41\u9891\u7387\u5177\u6709\u6311\u6218\u6027\u3002\u786c\u4ef6\u52a0\u901f\u5668\u53d7\u9650\u4e8e\u7247\u4e0a\u5185\u5b58\u5bb9\u91cf\uff0c\u73b0\u6709\u8349\u56fe\u7b97\u6cd5\u5728\u504f\u659c\u5206\u5e03\u6d41\u91cf\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684TowerSketch\u548c\u4f18\u5148\u7ea7\u961f\u5217\u9635\u5217\u8fdb\u884ctop-K\u6d41\u8bc6\u522b\uff0c\u5728FPGA\u4e0a\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u52a0\u901f\u5668\uff0c\u6bcf\u5468\u671f\u5904\u7406\u4e00\u4e2a\u6570\u636e\u5305\u3002", "result": "\u5728\u771f\u5b9e\u6d41\u91cf\u8ffd\u8e2a\u4e2d\uff0c\u8bc6\u522btop-K\u6d41\uff08K\u6700\u591a32,768\uff09\u7684\u7cbe\u5ea6\u8d85\u8fc70.94\uff0c\u9891\u7387\u4f30\u8ba1\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e1.96%\u3002FPGA\u5b9e\u73b0\u5904\u7406\u9891\u7387\u8fbe392MHz\uff0c\u6700\u5c0f\u7ebf\u901f\u7387\u8d85\u8fc7200Gbps\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u786c\u4ef6\u5b9e\u73b0\u80fd\u591f\u9ad8\u6548\u51c6\u786e\u5730\u8bc6\u522b\u7f51\u7edc\u6d41\u91cf\u4e2d\u7684top-K\u6d41\uff0c\u6ee1\u8db3\u9ad8\u901f\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2511.16902", "categories": ["cs.NI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.16902", "abs": "https://arxiv.org/abs/2511.16902", "authors": ["Michael Luby"], "title": "Adaptive Receiver-Side Scheduling for Smooth Interactive Delivery", "comment": "25 pages, 6 figures, 1 table", "summary": "Interactive applications such as cloud gaming, XR streaming, and real-time inference depend on data objects arriving at a steady cadence. In practice, network delay variation and recovery dynamics at the receiver distort this cadence even when transports deliver all packets correctly, which produces visible jitter, stalls, and unstable playback.\n  We present a lightweight receiver-side scheduling approach that regularizes release timing after recovery. The scheduler maintains an adaptive estimate of effective path delay and adjusts release times asymmetrically, responding quickly to late arrivals and only gradually to early ones. This upper-envelope behavior keeps release aligned with recent delay peaks and maintains smooth playback with minimal added latency. The scheduler runs entirely on the receiver clock and requires no feedback or synchronization.\n  As a concrete example, we integrate receiver-side scheduling into the BitRipple Tunnel (BRT) overlay, an application-layer software system that forwards traffic without altering the underlying transport protocol. Within BRT, the scheduler functions as an independent module that regulates delivery timing for forwarded objects.\n  Evaluating BRT with receiver-side scheduling on a cloud-gaming workload shows that the scheduler removes virtually all large jitter excursions and yields tightly clustered release intervals that improve visible smoothness. Broader latency improvements arise from the behavior of the full BRT overlay. Receiver-side scheduling can also be integrated modularly into transport stacks such as TCP, QUIC, WebRTC, UDP, or RTP, which are natural deployment points for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u63a5\u6536\u7aef\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4f30\u8ba1\u6709\u6548\u8def\u5f84\u5ef6\u8fdf\u5e76\u8c03\u6574\u91ca\u653e\u65f6\u95f4\uff0c\u6d88\u9664\u7f51\u7edc\u5ef6\u8fdf\u53d8\u5316\u5bfc\u81f4\u7684\u6296\u52a8\u548c\u5361\u987f\uff0c\u4fdd\u6301\u5e73\u6ed1\u64ad\u653e\u3002", "motivation": "\u4ea4\u4e92\u5f0f\u5e94\u7528\u5982\u4e91\u6e38\u620f\u3001XR\u6d41\u5a92\u4f53\u548c\u5b9e\u65f6\u63a8\u7406\u9700\u8981\u6570\u636e\u5bf9\u8c61\u4ee5\u7a33\u5b9a\u8282\u594f\u5230\u8fbe\uff0c\u4f46\u7f51\u7edc\u5ef6\u8fdf\u53d8\u5316\u548c\u63a5\u6536\u7aef\u6062\u590d\u52a8\u6001\u4f1a\u7834\u574f\u8fd9\u79cd\u8282\u594f\uff0c\u5bfc\u81f4\u53ef\u89c1\u7684\u6296\u52a8\u3001\u5361\u987f\u548c\u4e0d\u7a33\u5b9a\u64ad\u653e\u3002", "method": "\u63a5\u6536\u7aef\u8c03\u5ea6\u5668\u7ef4\u62a4\u81ea\u9002\u5e94\u6709\u6548\u8def\u5f84\u5ef6\u8fdf\u4f30\u8ba1\uff0c\u975e\u5bf9\u79f0\u8c03\u6574\u91ca\u653e\u65f6\u95f4\uff08\u5feb\u901f\u54cd\u5e94\u5ef6\u8fdf\u5230\u8fbe\uff0c\u7f13\u6162\u54cd\u5e94\u63d0\u524d\u5230\u8fbe\uff09\uff0c\u91c7\u7528\u4e0a\u5305\u7edc\u884c\u4e3a\u4fdd\u6301\u91ca\u653e\u4e0e\u6700\u8fd1\u5ef6\u8fdf\u5cf0\u503c\u5bf9\u9f50\uff0c\u65e0\u9700\u53cd\u9988\u6216\u540c\u6b65\u3002", "result": "\u5728\u4e91\u6e38\u620f\u5de5\u4f5c\u8d1f\u8f7d\u8bc4\u4f30\u4e2d\uff0c\u8c03\u5ea6\u5668\u51e0\u4e4e\u6d88\u9664\u4e86\u6240\u6709\u5927\u7684\u6296\u52a8\u504f\u79fb\uff0c\u4ea7\u751f\u7d27\u5bc6\u805a\u96c6\u7684\u91ca\u653e\u95f4\u9694\uff0c\u6539\u5584\u4e86\u89c6\u89c9\u5e73\u6ed1\u5ea6\u3002\u5b8c\u6574\u7684BRT\u8986\u76d6\u5c42\u5e26\u6765\u4e86\u66f4\u5e7f\u6cdb\u7684\u5ef6\u8fdf\u6539\u8fdb\u3002", "conclusion": "\u63a5\u6536\u7aef\u8c03\u5ea6\u53ef\u4ee5\u6a21\u5757\u5316\u96c6\u6210\u5230TCP\u3001QUIC\u3001WebRTC\u3001UDP\u6216RTP\u7b49\u4f20\u8f93\u534f\u8bae\u6808\u4e2d\uff0c\u662f\u672a\u6765\u5de5\u4f5c\u7684\u81ea\u7136\u90e8\u7f72\u70b9\u3002"}}
{"id": "2511.16966", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16966", "abs": "https://arxiv.org/abs/2511.16966", "authors": ["Yiheng Bian", "Zechen Li", "Lanqing Yang", "Hao Pan", "Yezhou Wang", "Longyuan Ge", "Jeffery Wu", "Ruiheng Liu", "Yongjian Fu", "Yichao chen", "Guangtao xue"], "title": "One Walk is All You Need: Data-Efficient 3D RF Scene Reconstruction with Human Movements", "comment": null, "summary": "Reconstructing 3D Radiance Field (RF) scenes through opaque obstacles is a long-standing goal, yet it is fundamentally constrained by a laborious data acquisition process requiring thousands of static measurements, which treats human motion as noise to be filtered. This work introduces a new paradigm with a core objective: to perform fast, data-efficient, and high-fidelity RF reconstruction of occluded 3D static scenes, using only a single, brief human walk. We argue that this unstructured motion is not noise, but is in fact an information-rich signal available for reconstruction. To achieve this, we design a factorization framework based on composite 3D Gaussian Splatting (3DGS) that learns to model the dynamic effects of human motion from the persistent static scene geometry within a raw RF stream. Trained on just a single 60-second casual walk, our model reconstructs the full static scene with a Structural Similarity Index (SSIM) of 0.96, remarkably outperforming heavily-sampled state-of-the-art (SOTA) by 12%. By transforming the human movements into its valuable signals, our method eliminates the data acquisition bottleneck and paves the way for on-the-fly 3D RF mapping of unseen environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5355\u6b21\u77ed\u6682\u7684\u4eba\u7c7b\u884c\u8d70\u6765\u5feb\u901f\u3001\u9ad8\u6548\u5730\u91cd\u5efa\u88ab\u906e\u6321\u76843D\u9759\u6001\u573a\u666f\u7684\u8f90\u5c04\u573a\uff0c\u5c06\u4eba\u7c7b\u8fd0\u52a8\u89c6\u4e3a\u4fe1\u606f\u4e30\u5bcc\u7684\u4fe1\u53f7\u800c\u975e\u566a\u58f0\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u6570\u5343\u6b21\u9759\u6001\u6d4b\u91cf\uff0c\u5c06\u4eba\u7c7b\u8fd0\u52a8\u89c6\u4e3a\u9700\u8981\u8fc7\u6ee4\u7684\u566a\u58f0\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u7e41\u7410\u3002\u672c\u6587\u65e8\u5728\u5229\u7528\u4eba\u7c7b\u8fd0\u52a8\u4f5c\u4e3a\u91cd\u5efa\u4fe1\u53f7\uff0c\u89e3\u51b3\u6570\u636e\u91c7\u96c6\u74f6\u9888\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u590d\u54083D\u9ad8\u65af\u6cfc\u6e85\u7684\u56e0\u5b50\u5316\u6846\u67b6\uff0c\u4ece\u539f\u59cb\u8f90\u5c04\u6d41\u4e2d\u5b66\u4e60\u5efa\u6a21\u4eba\u7c7b\u8fd0\u52a8\u7684\u52a8\u6001\u6548\u5e94\u548c\u9759\u6001\u573a\u666f\u51e0\u4f55\u3002", "result": "\u4ec5\u752860\u79d2\u7684\u968f\u610f\u884c\u8d70\u8bad\u7ec3\uff0c\u6a21\u578b\u91cd\u5efa\u7684\u9759\u6001\u573a\u666f\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570\u8fbe0.96\uff0c\u6bd4\u9700\u8981\u5927\u91cf\u91c7\u6837\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u9ad8\u51fa12%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4eba\u7c7b\u8fd0\u52a8\u8f6c\u5316\u4e3a\u6709\u4ef7\u503c\u4fe1\u53f7\uff0c\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u6570\u636e\u91c7\u96c6\u74f6\u9888\uff0c\u4e3a\u5b9e\u65f63D\u8f90\u5c04\u573a\u6620\u5c04\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.16814", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.16814", "abs": "https://arxiv.org/abs/2511.16814", "authors": ["Silvia Rondini", "Claudia Alvarez-Martin", "Paula Angermair-Barkai", "Olivier Penacchio", "M. Paz", "Matthew Pelowski", "Dan Dediu", "Antoni Rodriguez-Fornells", "Xim Cerda-Company"], "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity", "comment": null, "summary": "While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u89c6\u89c9\u827a\u672f\u5bb6\u6700\u5177\u521b\u9020\u529b\uff0c\u5176\u6b21\u662f\u666e\u901a\u4eba\uff0c\u7136\u540e\u662f\u53d7\u4eba\u7c7b\u542f\u53d1\u751f\u6210AI\uff0c\u6700\u540e\u662f\u81ea\u4e3b\u751f\u6210AI\u3002\u4eba\u7c7b\u6307\u5bfc\u663e\u8457\u63d0\u5347AI\u521b\u9020\u529b\uff0c\u4f46\u4eba\u7c7b\u4e0eAI\u8bc4\u4f30\u8005\u5728\u521b\u9020\u529b\u5224\u65ad\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u521b\u9020\u529b\u9886\u57df\uff0c\u6bd4\u8f83\u4eba\u7c7b\u4e0eAI\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u8bed\u8a00\u6a21\u578b\u5df2\u5c55\u73b0\u521b\u9020\u529b\u7684\u80cc\u666f\u4e0b\uff0c\u89c6\u89c9\u9886\u57df\u7684\u72ec\u7279\u6027\u503c\u5f97\u7814\u7a76\u3002", "method": "\u6bd4\u8f83\u4eba\u7c7b\u53c2\u4e0e\u8005\uff08\u89c6\u89c9\u827a\u672f\u5bb6\u548c\u666e\u901a\u4eba\uff09\u4e0e\u56fe\u50cf\u751f\u6210AI\u6a21\u578b\uff08\u4e24\u79cd\u63d0\u793a\u6761\u4ef6\uff1a\u9ad8\u4eba\u7c7b\u8f93\u5165\u7684\u4eba\u7c7b\u542f\u53d1\u6761\u4ef6\u548c\u4f4e\u4eba\u7c7b\u8f93\u5165\u7684\u81ea\u4e3b\u6307\u5bfc\u6761\u4ef6\uff09\uff0c\u7531255\u540d\u4eba\u7c7b\u8bc4\u4f30\u8005\u548cGPT4o\u8bc4\u4f30\u751f\u6210\u56fe\u50cf\u7684\u521b\u9020\u529b\u3002", "result": "\u53d1\u73b0\u6e05\u6670\u7684\u521b\u9020\u529b\u68af\u5ea6\uff1a\u89c6\u89c9\u827a\u672f\u5bb6>\u666e\u901a\u4eba>\u4eba\u7c7b\u542f\u53d1\u751f\u6210AI>\u81ea\u4e3b\u751f\u6210AI\u3002\u4eba\u7c7b\u6307\u5bfc\u663e\u8457\u63d0\u5347AI\u521b\u9020\u529b\u8f93\u51fa\uff0c\u4f7f\u5176\u63a5\u8fd1\u666e\u901a\u4eba\u6c34\u5e73\u3002\u4eba\u7c7b\u4e0eAI\u8bc4\u4f30\u8005\u5728\u521b\u9020\u529b\u5224\u65ad\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u4e0e\u8bed\u8a00\u4e2d\u5fc3\u4efb\u52a1\u4e0d\u540c\uff0c\u751f\u6210AI\u6a21\u578b\u5728\u89c6\u89c9\u9886\u57df\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u56e0\u4e3a\u89c6\u89c9\u521b\u9020\u529b\u4f9d\u8d56\u4e8e\u611f\u77e5\u7ec6\u5fae\u5dee\u522b\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u6027\uff0c\u8fd9\u4e9b\u662f\u4eba\u7c7b\u7279\u6709\u7684\u80fd\u529b\uff0c\u53ef\u80fd\u96be\u4ee5\u4ece\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u8fc1\u79fb\u3002"}}
{"id": "2511.16864", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.16864", "abs": "https://arxiv.org/abs/2511.16864", "authors": ["Leighton Barnes", "Alex Dytso"], "title": "Functional uniqueness and stability of Gaussian priors in optimal L1 estimation", "comment": null, "summary": "This paper studies the functional uniqueness and stability of Gaussian priors in optimal $L^1$ estimation. While it is well known that the Gaussian prior uniquely induces linear conditional means under Gaussian noise, the analogous question for the conditional median (i.e., the optimal estimator under absolute-error loss) has only recently been settled. Building on the prior work establishing this uniqueness, we develop a quantitative stability theory that characterizes how approximate linearity of the optimal estimator constrains the prior distribution. For $L^2$ loss, we derive explicit rates showing that near-linearity of the conditional mean implies proximity of the prior to the Gaussian in the L\u00e9vy metric. For $L^1$ loss, we introduce a Hermite expansion framework and analyze the adjoint of the linearity-defining operator to show that the Gaussian remains the unique stable solution. Together, these results provide a more complete functional-analytic understanding of linearity and stability in Bayesian estimation under Gaussian noise.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u5148\u9a8c\u5728\u6700\u4f18L1\u4f30\u8ba1\u4e2d\u7684\u51fd\u6570\u552f\u4e00\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5efa\u7acb\u4e86\u5b9a\u91cf\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u8bc1\u660e\u9ad8\u65af\u5206\u5e03\u662f\u552f\u4e00\u7a33\u5b9a\u7684\u89e3\u3002", "motivation": "\u867d\u7136\u5df2\u77e5\u9ad8\u65af\u5148\u9a8c\u5728\u9ad8\u65af\u566a\u58f0\u4e0b\u552f\u4e00\u8bf1\u5bfc\u7ebf\u6027\u6761\u4ef6\u5747\u503c\uff0c\u4f46\u5bf9\u4e8e\u6761\u4ef6\u4e2d\u4f4d\u6570\uff08\u7edd\u5bf9\u8bef\u5dee\u635f\u5931\u4e0b\u7684\u6700\u4f18\u4f30\u8ba1\u5668\uff09\u7684\u7c7b\u4f3c\u95ee\u9898\u6700\u8fd1\u624d\u89e3\u51b3\u3002\u672c\u6587\u57fa\u4e8e\u8fd9\u4e00\u552f\u4e00\u6027\u7ed3\u679c\uff0c\u7814\u7a76\u8fd1\u4f3c\u7ebf\u6027\u6700\u4f18\u4f30\u8ba1\u5668\u5982\u4f55\u7ea6\u675f\u5148\u9a8c\u5206\u5e03\u3002", "method": "\u5bf9\u4e8eL2\u635f\u5931\uff0c\u63a8\u5bfc\u663e\u5f0f\u901f\u7387\u663e\u793a\u6761\u4ef6\u5747\u503c\u7684\u8fd1\u7ebf\u6027\u610f\u5473\u7740\u5148\u9a8c\u5728L\u00e9vy\u5ea6\u91cf\u4e0b\u63a5\u8fd1\u9ad8\u65af\u5206\u5e03\uff1b\u5bf9\u4e8eL1\u635f\u5931\uff0c\u5f15\u5165Hermite\u5c55\u5f00\u6846\u67b6\u5e76\u5206\u6790\u7ebf\u6027\u5b9a\u4e49\u7b97\u5b50\u7684\u4f34\u968f\u7b97\u5b50\u3002", "result": "\u8bc1\u660e\u4e86\u9ad8\u65af\u5206\u5e03\u5728L1\u635f\u5931\u4e0b\u4ecd\u7136\u662f\u552f\u4e00\u7a33\u5b9a\u7684\u89e3\uff0c\u5e76\u5efa\u7acb\u4e86\u5b9a\u91cf\u7a33\u5b9a\u6027\u7406\u8bba\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u9ad8\u65af\u566a\u58f0\u4e0b\u8d1d\u53f6\u65af\u4f30\u8ba1\u4e2d\u7684\u7ebf\u6027\u548c\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u51fd\u6570\u5206\u6790\u7406\u89e3\u3002"}}
{"id": "2511.16837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16837", "abs": "https://arxiv.org/abs/2511.16837", "authors": ["Oliver Kramer"], "title": "Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs", "comment": "6 pages, Submitted to ESANN 2026", "summary": "Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.", "AI": {"tldr": "Cognitive BASIC\u662f\u4e00\u79cd\u57fa\u4e8eBASIC\u98ce\u683c\u7684\u63d0\u793a\u8bed\u8a00\u548c\u6a21\u578b\u5185\u89e3\u91ca\u5668\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u7ed3\u6784\u5316\u4e3a\u663e\u5f0f\u7684\u9010\u6b65\u6267\u884c\u8f68\u8ff9\uff0c\u901a\u8fc7\u7f16\u53f7\u884c\u548c\u7b80\u5355\u547d\u4ee4\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u8ba4\u77e5\u63a7\u5236\u5c42\u3002", "motivation": "\u53d7\u590d\u53e4BASIC\u7b80\u5355\u6027\u7684\u542f\u53d1\uff0c\u65e8\u5728\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u591a\u6b65\u63a8\u7406\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u53ef\u9760\u5730\u6a21\u62df\u77ed\u7a0b\u5e8f\u6267\u884c\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5668\u6587\u4ef6\u6765\u6307\u5b9a\u547d\u4ee4\u8bed\u4e49\u3001\u5185\u5b58\u66f4\u65b0\u548c\u65e5\u5fd7\u884c\u4e3a\uff0c\u901a\u8fc7\u5fc3\u7406\u6a21\u578b\u89e3\u91ca\u5668\u63d0\u53d6\u58f0\u660e\u6027\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff0c\u68c0\u6d4b\u77db\u76fe\u5e76\u5728\u5fc5\u8981\u65f6\u4ea7\u751f\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u4e09\u4e2aLLM\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u6240\u6709\u6a21\u578b\u90fd\u80fd\u6267\u884cCognitive BASIC\u7a0b\u5e8f\uff0c\u6574\u4f53\u8868\u73b0\u5f3a\u52b2\u4f46\u6027\u80fd\u4e0d\u5747\u3002", "conclusion": "Cognitive BASIC\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u900f\u660e\u53ef\u89e3\u91ca\u7684\u591a\u6b65\u63a8\u7406\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u5c55\u73b0\u51fa\u826f\u597d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.17236", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.17236", "abs": "https://arxiv.org/abs/2511.17236", "authors": ["Johan V. Dinesen", "Ragnar Freij-Hollanti", "Camilla Hollanti", "Benjamin Jany", "Alberto Ravagnani"], "title": "The Star Product of Uniformly Random Codes", "comment": null, "summary": "We consider the problem of determining the expected dimension of the star product of two uniformly random linear codes that are not necessarily of the same dimension. We achieve this by establishing a correspondence between the star product and the evaluation of bilinear forms, which we use to provide a lower bound on the expected star product dimension. We show that asymptotically in both the field size q and the dimensions of the two codes, the expected dimension reaches its maximum. Lastly, we discuss some implications related to private information retrieval, secure distributed matrix multiplication, quantum error correction, and the potential for exploiting the results in cryptanalysis.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e24\u4e2a\u968f\u673a\u7ebf\u6027\u7801\u661f\u79ef\u7684\u671f\u671b\u7ef4\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u5efa\u7acb\u661f\u79ef\u4e0e\u53cc\u7ebf\u6027\u5f62\u5f0f\u8bc4\u4f30\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u7ed9\u51fa\u4e86\u671f\u671b\u661f\u79ef\u7ef4\u5ea6\u7684\u4e0b\u754c\uff0c\u5e76\u8bc1\u660e\u5728\u57df\u5927\u5c0f\u548c\u7801\u7ef4\u6e10\u8fd1\u60c5\u51b5\u4e0b\u671f\u671b\u7ef4\u5ea6\u8fbe\u5230\u6700\u5927\u503c\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u7ebf\u6027\u7801\u661f\u79ef\u7684\u671f\u671b\u7ef4\u5ea6\u5bf9\u4e8e\u7406\u89e3\u7801\u7684\u7ec4\u5408\u6027\u8d28\u53ca\u5176\u5728\u79c1\u5bc6\u4fe1\u606f\u68c0\u7d22\u3001\u5b89\u5168\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u3001\u91cf\u5b50\u7ea0\u9519\u7b49\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u661f\u79ef\u4e0e\u53cc\u7ebf\u6027\u5f62\u5f0f\u8bc4\u4f30\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5206\u6790\u968f\u673a\u7ebf\u6027\u7801\u7684\u661f\u79ef\u7ef4\u5ea6\uff0c\u5e76\u7ed9\u51fa\u671f\u671b\u7ef4\u5ea6\u7684\u4e0b\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u57df\u5927\u5c0fq\u548c\u4e24\u4e2a\u7801\u7684\u7ef4\u5ea6\u6e10\u8fd1\u60c5\u51b5\u4e0b\uff0c\u671f\u671b\u661f\u79ef\u7ef4\u5ea6\u8fbe\u5230\u6700\u5927\u503c\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u5e94\u7528\u610f\u4e49\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u968f\u673a\u7ebf\u6027\u7801\u661f\u79ef\u7684\u7ef4\u5ea6\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u5e94\u7528\u9886\u57df\u5177\u6709\u6f5c\u5728\u4ef7\u503c\uff0c\u5305\u62ec\u5bc6\u7801\u5206\u6790\u7684\u53ef\u80fd\u6027\u5229\u7528\u3002"}}
{"id": "2511.16842", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16842", "abs": "https://arxiv.org/abs/2511.16842", "authors": ["Sang Truong", "Yuheng Tu", "Michael Hardy", "Anka Reuel", "Zeyu Tang", "Jirayu Burapacheep", "Jonathan Perera", "Chibuike Uwakwe", "Ben Domingue", "Nick Haber", "Sanmi Koyejo"], "title": "Fantastic Bugs and Where to Find Them in AI Benchmarks", "comment": null, "summary": "Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4fee\u8ba2\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u54cd\u5e94\u6a21\u5f0f\u7684\u7edf\u8ba1\u7279\u5f81\u6765\u6807\u8bb0\u53ef\u80fd\u65e0\u6548\u7684\u95ee\u9898\uff0c\u4f9b\u4e13\u5bb6\u8fdb\u4e00\u6b65\u5ba1\u67e5\uff0c\u4ece\u800c\u9ad8\u6548\u8bc6\u522b\u548c\u4fee\u6b63\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u95ee\u9898\u3002", "motivation": "\u57fa\u51c6\u6d4b\u8bd5\u5728\u63a8\u52a8AI\u8fdb\u6b65\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u65e0\u6548\u7684\u57fa\u51c6\u95ee\u9898\u7ecf\u5e38\u7834\u574f\u5176\u53ef\u9760\u6027\u3002\u624b\u52a8\u8bc6\u522b\u548c\u4fee\u6b63\u6570\u5343\u4e2a\u57fa\u51c6\u95ee\u9898\u4e2d\u7684\u9519\u8bef\u65e2\u4e0d\u53ef\u884c\uff0c\u4e5f\u662f\u53ef\u9760\u8bc4\u4f30\u7684\u5173\u952e\u74f6\u9888\u3002", "method": "\u57fa\u4e8eAI\u8bc4\u4f30\u4e2d\u5e38\u7528\u7684\u6838\u5fc3\u5047\u8bbe\u2014\u2014\u5e73\u5747\u5206\u8db3\u4ee5\u6982\u62ec\u6a21\u578b\u6027\u80fd\uff0c\u8be5\u65b9\u6cd5\u5047\u8bbe\u5b58\u5728\u4e00\u4e2a\u5355\u7ef4\u6f5c\u5728\u7ed3\u6784\uff0c\u4e3a\u6bcf\u4e2a\u9879\u76ee\u751f\u6210\u5404\u79cd\u7edf\u8ba1\u91cf\u7684\u9884\u671f\u8303\u56f4\u3002\u5f53\u8fd9\u4e9b\u7edf\u8ba1\u91cf\u7684\u7ecf\u9a8c\u4f30\u8ba1\u503c\u8d85\u51fa\u9884\u671f\u8303\u56f4\u65f6\uff0c\u8be5\u9879\u76ee\u66f4\u53ef\u80fd\u5b58\u5728\u95ee\u9898\u3002", "result": "\u5728\u4e5d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6307\u5bfc\u4e13\u5bb6\u5ba1\u67e5\u8bc6\u522b\u95ee\u9898\u95ee\u9898\u7684\u7cbe\u5ea6\u9ad8\u8fbe84%\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86LLM-judge\u521d\u6b65\u5ba1\u67e5\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u8fd9\u4e9b\u7ec4\u4ef6\u5171\u540c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5\u4fee\u8ba2\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.17239", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.17239", "abs": "https://arxiv.org/abs/2511.17239", "authors": ["Albert Fannjiang", "Weilin Li"], "title": "Structured Approximation of Toeplitz Matrices and Subspaces", "comment": "21 pages", "summary": "This paper studies two structured approximation problems: (1) Recovering a corrupted low-rank Toeplitz matrix and (2) recovering the range of a Fourier matrix from a single observation. Both problems are computationally challenging because the structural constraints are difficult to enforce directly. We show that both tasks can be solved efficiently and optimally by applying the Gradient-MUSIC algorithm for spectral estimation. For a rank $r$ Toeplitz matrix ${\\boldsymbol T}\\in {\\mathbb C}^{n\\times n}$ that satisfies a regularity assumption and is corrupted by an arbitrary ${\\boldsymbol E}\\in {\\mathbb C}^{n\\times n}$ such that $\\|{\\boldsymbol E}\\|_2\\leq \u03b1n$, our algorithm outputs a Toeplitz matrix $\\widehat{\\boldsymbol T}$ of rank exactly $r$ such that $\\|{\\boldsymbol T}-\\widehat{\\boldsymbol T}\\|_2 \\leq C \\sqrt r \\, \\|{\\boldsymbol E}\\|_2$, where $C,\u03b1>0$ are absolute constants. This performance guarantee is minimax optimal in $n$ and $\\|{\\boldsymbol E}\\|_2$. We derive optimal results for the second problem as well. Our analysis provides quantitative connections between these two problems and spectral estimation. Our results are equally applicable to Hankel matrices with superficial modifications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e24\u4e2a\u7ed3\u6784\u5316\u903c\u8fd1\u95ee\u9898\uff1a\u6062\u590d\u635f\u574f\u7684\u4f4e\u79e9Toeplitz\u77e9\u9635\u548c\u4ece\u5355\u6b21\u89c2\u6d4b\u4e2d\u6062\u590d\u5085\u91cc\u53f6\u77e9\u9635\u7684\u8303\u56f4\u3002\u901a\u8fc7\u5e94\u7528Gradient-MUSIC\u7b97\u6cd5\uff0c\u53ef\u4ee5\u9ad8\u6548\u4e14\u6700\u4f18\u5730\u89e3\u51b3\u8fd9\u4e24\u4e2a\u8ba1\u7b97\u96be\u9898\u3002", "motivation": "Toeplitz\u77e9\u9635\u6062\u590d\u548c\u5085\u91cc\u53f6\u77e9\u9635\u8303\u56f4\u6062\u590d\u662f\u8ba1\u7b97\u4e0a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u7ed3\u6784\u7ea6\u675f\u96be\u4ee5\u76f4\u63a5\u5f3a\u5236\u6267\u884c\u3002\u9700\u8981\u627e\u5230\u9ad8\u6548\u7684\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u7ed3\u6784\u5316\u903c\u8fd1\u95ee\u9898\u3002", "method": "\u4f7f\u7528Gradient-MUSIC\u7b97\u6cd5\u8fdb\u884c\u8c31\u4f30\u8ba1\u3002\u5bf9\u4e8e\u6ee1\u8db3\u6b63\u5219\u6027\u5047\u8bbe\u7684\u79e9r Toeplitz\u77e9\u9635\uff0c\u5728\u53d7\u5230\u4efb\u610f\u566a\u58f0\u77e9\u9635E\u7834\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u8f93\u51fa\u7cbe\u786e\u79e9\u4e3ar\u7684Toeplitz\u77e9\u9635\u4f30\u8ba1\u3002", "result": "\u7b97\u6cd5\u8f93\u51fa\u7684Toeplitz\u77e9\u9635\u4f30\u8ba1\u6ee1\u8db3\u2016T-\u0164\u2016\u2082 \u2264 C\u221ar\u2016E\u2016\u2082\uff0c\u5176\u4e2dC,\u03b1>0\u662f\u7edd\u5bf9\u5e38\u6570\u3002\u8be5\u6027\u80fd\u4fdd\u8bc1\u5728n\u548c\u2016E\u2016\u2082\u65b9\u9762\u662f\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7684\u3002\u7ed3\u679c\u540c\u6837\u9002\u7528\u4e8eHankel\u77e9\u9635\u3002", "conclusion": "Gradient-MUSIC\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u4e14\u6700\u4f18\u5730\u89e3\u51b3\u7ed3\u6784\u5316\u903c\u8fd1\u95ee\u9898\uff0c\u4e3aToeplitz\u77e9\u9635\u6062\u590d\u548c\u5085\u91cc\u53f6\u77e9\u9635\u8303\u56f4\u6062\u590d\u63d0\u4f9b\u4e86\u5b9a\u91cf\u8054\u7cfb\u548c\u8c31\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2511.16916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16916", "abs": "https://arxiv.org/abs/2511.16916", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving", "comment": null, "summary": "In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u5dee\u5206\u5956\u52b1\u673a\u5236\u89e3\u51b3\u591a\u8f66\u534f\u540c\u9a7e\u9a76\u4e2d\u4f20\u7edf\u72b6\u6001\u5956\u52b1\u51fd\u6570\u56e0\u5956\u52b1\u5dee\u5f02\u6d88\u5931\u5bfc\u81f4\u7684\u4f4e\u4fe1\u566a\u6bd4\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7b97\u6cd5\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u7a33\u5b9a\u6027", "motivation": "\u591a\u8f66\u534f\u540c\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u4f20\u7edf\u57fa\u4e8e\u72b6\u6001\u7684\u5956\u52b1\u51fd\u6570\u5b58\u5728\u5956\u52b1\u5dee\u5f02\u6d88\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u7b56\u7565\u68af\u5ea6\u7684\u4fe1\u566a\u6bd4\u8fc7\u4f4e\uff0c\u4e25\u91cd\u5f71\u54cd\u7b97\u6cd5\u6536\u655b\u548c\u6027\u80fd\u63d0\u5347", "method": "\u63d0\u51fa\u6df7\u5408\u5dee\u5206\u5956\u52b1\u673a\u5236\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u5168\u5c40\u52bf\u51fd\u6570\u7684\u65f6\u5e8f\u5dee\u5206\u5956\u52b1\u548c\u76f4\u63a5\u8861\u91cf\u52a8\u4f5c\u8fb9\u9645\u6548\u7528\u7684\u52a8\u4f5c\u68af\u5ea6\u5956\u52b1\uff0c\u5e76\u5728\u5177\u6709\u65f6\u53d8\u667a\u80fd\u4f53\u96c6\u7684\u591a\u667a\u80fd\u4f53\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u6846\u67b6\u4e2d\u5b9e\u73b0", "result": "\u5728\u7ebf\u89c4\u5212\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHDR\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u7a33\u5b9a\u6027\uff0c\u5f15\u5bfc\u667a\u80fd\u4f53\u5b66\u4e60\u5230\u80fd\u6709\u6548\u5e73\u8861\u4ea4\u901a\u6548\u7387\u548c\u5b89\u5168\u7684\u9ad8\u8d28\u91cf\u534f\u540c\u7b56\u7565", "conclusion": "HDR\u673a\u5236\u901a\u8fc7\u6574\u5408\u65f6\u5e8f\u5dee\u5206\u5956\u52b1\u548c\u52a8\u4f5c\u68af\u5ea6\u5956\u52b1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u8f66\u534f\u540c\u9a7e\u9a76\u4e2d\u7684\u5956\u52b1\u4fe1\u53f7\u95ee\u9898\uff0c\u4e3a\u9ad8\u9891\u7387\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.17240", "categories": ["cs.IT", "cs.DM", "cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.17240", "abs": "https://arxiv.org/abs/2511.17240", "authors": ["Hoang Ta", "Jonathan Scarlett"], "title": "Fast Decoding for Non-Adaptive Learning of Erd\u0151s--R\u00e9nyi Random Graphs", "comment": null, "summary": "We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \\(n\\) nodes and \\(k\\) edges is hard in the non-adaptive setting, requiring \\(\u03a9\\big(\\min\\{k^2\\log n,\\,n^2\\}\\big)\\) tests even when a small error probability is allowed. We focus on learning Erd\u0151s--R\u00e9nyi (ER) graphs \\(G\\sim\\ER(n,q)\\) in the non-adaptive setting, where the expected number of edges is \\(\\bar{k}=q\\binom{n}{2}\\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \\(O(\\bar{k}\\log n)\\) but incurs \\(\u03a9(n^2)\\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \\((\\log \\bar{k})(\\log n)\\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \\(O(\\bar{k}\\log n)\\) tests while attaining decoding time \\(O(\\bar{k}^{1+\u03b4}\\log n)\\) for any fixed \\(\u03b4>0\\).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u7fa4\u4f53\u67e5\u8be2\u5b66\u4e60Erd\u0151s-R\u00e9nyi\u56fe\uff0c\u4f7f\u7528O(\u0304k log n)\u6b21\u6d4b\u8bd5\u5373\u53ef\u9ad8\u6982\u7387\u6062\u590d\u8fb9\u96c6\uff0c\u540c\u65f6\u89e3\u7801\u65f6\u95f4\u4ec5\u4e3aO(\u0304k^{1+\u03b4} log n)\uff0c\u76f8\u6bd4\u4e4b\u524d\u5de5\u4f5c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u56fe\u5b66\u4e60\u65b9\u6cd5\u5728\u975e\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e0b\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff1a\u8981\u4e48\u9700\u8981\u03a9(n\u00b2)\u89e3\u7801\u65f6\u95f4\uff0c\u8981\u4e48\u9700\u8981\u989d\u5916\u6d4b\u8bd5\u6b21\u6570\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u4fdd\u6301\u6700\u4f18\u6d4b\u8bd5\u6b21\u6570\u53c8\u5b9e\u73b0\u4e9a\u7ebf\u6027\u89e3\u7801\u65f6\u95f4\u7684\u7b97\u6cd5\u3002", "method": "\u5c06\u975e\u81ea\u9002\u5e94\u7fa4\u4f53\u6d4b\u8bd5\u4e2d\u7684\u4e8c\u5206\u641c\u7d22\u65b9\u6cd5\u6269\u5c55\u5230ER\u56fe\u5b66\u4e60\u573a\u666f\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7fa4\u4f53\u67e5\u8be2\u7b56\u7565\u6765\u8bc6\u522b\u56fe\u4e2d\u7684\u8fb9\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u4ee5\u9ad8\u6982\u7387\u6062\u590dER\u56fe\u7684\u8fb9\u96c6\uff0c\u4ec5\u9700O(\u0304k log n)\u6b21\u6d4b\u8bd5\uff0c\u89e3\u7801\u65f6\u95f4\u4e3aO(\u0304k^{1+\u03b4} log n)\uff0c\u5176\u4e2d\u0304k\u4e3a\u671f\u671b\u8fb9\u6570\uff0c\u03b4\u4e3a\u4efb\u610f\u56fa\u5b9a\u6b63\u6570\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6700\u4f18\u6d4b\u8bd5\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.16961", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16961", "abs": "https://arxiv.org/abs/2511.16961", "authors": ["Erik P. Nyberg", "Steven Mascaro", "Ingrid Zukerman", "Michael Wybrow", "Duc-Minh Vo", "Ann Nicholson"], "title": "Comparing verbal, visual and combined explanations for Bayesian Network inferences", "comment": "26 pages total, 12 pages main, 14 pages for 5 appendices", "summary": "Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.\n  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u8d1d\u53f6\u65af\u7f51\u7edc\u754c\u9762\u7684\u8bed\u8a00\u548c\u89c6\u89c9\u6269\u5c55\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u6269\u5c55\u80fd\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e14\u8bed\u8a00\u548c\u89c6\u89c9\u7ed3\u5408\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1\u8d1d\u53f6\u65af\u7f51\u7edc\u88ab\u8ba4\u4e3a\u662f\u900f\u660e\u6a21\u578b\uff0c\u4f46\u7528\u6237\u4ecd\u96be\u4ee5\u7406\u89e3\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u73b0\u6709\u7528\u6237\u754c\u9762\u672a\u80fd\u6709\u6548\u6f84\u6e05\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u63a8\u7406\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u8bed\u8a00\u548c\u89c6\u89c9\u6269\u5c55\u6765\u589e\u5f3a\u6807\u51c6\u8d1d\u53f6\u65af\u7f51\u7edc\u754c\u9762\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u6bd4\u8f83\u4e86\u8bed\u8a00\u6269\u5c55\u3001\u89c6\u89c9\u6269\u5c55\u3001\u7ec4\u5408\u6269\u5c55\u4e0e\u57fa\u7ebf\u754c\u9762\u7684\u6548\u679c\u3002", "result": "\u7528\u6237\u5728\u6240\u6709\u4e09\u79cd\u6269\u5c55\u754c\u9762\u4e0a\u7684\u8868\u73b0\u5747\u4f18\u4e8e\u57fa\u7ebf\u754c\u9762\uff0c\u7279\u522b\u662f\u5728\u89c2\u5bdf\u5f71\u54cd\u3001\u5f71\u54cd\u8def\u5f84\u548c\u591a\u89c2\u5bdf\u4ea4\u4e92\u65b9\u9762\uff1b\u8bed\u8a00\u548c\u89c6\u89c9\u7ec4\u5408\u5728\u67d0\u4e9b\u95ee\u9898\u7c7b\u578b\u4e0a\u4f18\u4e8e\u5355\u4e00\u6a21\u5f0f\u3002", "conclusion": "\u8bed\u8a00\u548c\u89c6\u89c9\u6269\u5c55\u80fd\u6709\u6548\u63d0\u5347\u7528\u6237\u5bf9\u8d1d\u53f6\u65af\u7f51\u7edc\u63a8\u7406\u7684\u7406\u89e3\uff0c\u7ec4\u5408\u4f7f\u7528\u4e24\u79cd\u6a21\u5f0f\u6548\u679c\u6700\u597d\u3002"}}
{"id": "2511.17416", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.17416", "abs": "https://arxiv.org/abs/2511.17416", "authors": ["Xusheng Zhu", "Kai-Kit Wong", "Qingqing Wu", "Hyundong Shin", "Yangyang Zhang"], "title": "Fluid Antenna System-Enabled UAV-to-Ground Communications", "comment": null, "summary": "Fluid antenna systems (FAS) have emerged as a revolutionary technology offering enhanced spatial diversity within a compact form factor. Concurrently, unmanned aerial vehicles (UAVs) are integral to future networks, necessitating channel models that capture both multipath fading and shadowing. This letter presents a novel performance analysis of a UAV-to-ground link, where the receiver is equipped with an $N$-port FAS operating over the challenging double-shadowing fading channel. By adapting a tractable eigenvalue-based approximation for the correlated FAS ports, we derive new analytical expressions for the end-to-end signal-to-noise ratio statistics, namely the cumulative distribution function and the probability density function. Based on these statistics, we present exact integral expressions for the outage probability, average bit error rate, and average channel capacity. We further derive new, tractable closed-form solutions for the average bit error rate and capacity for the practical dual-rank, independent but non-identically distributed case. Finally, a key asymptotic analysis reveals that the system achieves a multiplicative diversity order of $G_d = M \\times d$, which is precisely the product of the FAS spatial rank $M$ and the intrinsic channel diversity order $d$. Simulation results are provided to validate the high accuracy of our entire theoretical framework.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u65e0\u4eba\u673a\u5230\u5730\u9762\u94fe\u8def\u4e2d\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u5728\u53cc\u9634\u5f71\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\u5206\u6790\uff0c\u63a8\u5bfc\u4e86\u7aef\u5230\u7aef\u4fe1\u566a\u6bd4\u7edf\u8ba1\u3001\u4e2d\u65ad\u6982\u7387\u3001\u8bef\u7801\u7387\u548c\u4fe1\u9053\u5bb9\u91cf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5e76\u63ed\u793a\u4e86\u7cfb\u7edf\u53ef\u83b7\u5f97M\u00d7d\u7684\u4e58\u6cd5\u5206\u96c6\u9636\u6570\u3002", "motivation": "\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u5728\u7d27\u51d1\u5c3a\u5bf8\u5185\u63d0\u4f9b\u589e\u5f3a\u7684\u7a7a\u95f4\u5206\u96c6\uff0c\u800c\u65e0\u4eba\u673a\u5728\u672a\u6765\u7f51\u7edc\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u591a\u5f84\u8870\u843d\u548c\u9634\u5f71\u6548\u5e94\u7684\u4fe1\u9053\u6a21\u578b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7279\u5f81\u503c\u7684\u76f8\u5173FAS\u7aef\u53e3\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u63a8\u5bfc\u7aef\u5230\u7aef\u4fe1\u566a\u6bd4\u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u548c\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u8fdb\u800c\u5206\u6790\u4e2d\u65ad\u6982\u7387\u3001\u5e73\u5747\u8bef\u7801\u7387\u548c\u5e73\u5747\u4fe1\u9053\u5bb9\u91cf\u3002", "result": "\u83b7\u5f97\u4e86\u7cbe\u786e\u7684\u79ef\u5206\u8868\u8fbe\u5f0f\u548c\u95ed\u5f0f\u89e3\uff0c\u7cfb\u7edf\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u6846\u67b6\u7684\u9ad8\u7cbe\u5ea6\uff0c\u5e76\u53d1\u73b0\u7cfb\u7edf\u53ef\u5b9e\u73b0M\u00d7d\u7684\u4e58\u6cd5\u5206\u96c6\u9636\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u6790\u6846\u67b6\u51c6\u786e\u63cf\u8ff0\u4e86FAS\u5728\u53cc\u9634\u5f71\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\uff0c\u4e3a\u65e0\u4eba\u673a\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2511.16997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16997", "abs": "https://arxiv.org/abs/2511.16997", "authors": ["Qingbin Zeng", "Bingbing Fan", "Zhiyu Chen", "Sijian Ren", "Zhilun Zhou", "Xuhua Zhang", "Yuanyi Zhen", "Fengli Xu", "Yong Li", "Tie-Yan Liu"], "title": "MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists", "comment": "26 pages, 4 figures", "summary": "The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.", "AI": {"tldr": "MirrorMind\u662f\u4e00\u4e2a\u5206\u5c42\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408\u53cc\u8bb0\u5fc6\u8868\u793a\u6765\u89e3\u51b3AI\u79d1\u5b66\u5bb6\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5c06\u4e2a\u4f53\u8ba4\u77e5\u8f68\u8ff9\u4e0e\u96c6\u4f53\u5b66\u79d1\u8bb0\u5fc6\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u7684\u79d1\u5b66\u63a8\u7406\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u65b9\u6cd5\u5c06\u79d1\u5b66\u53d1\u73b0\u89c6\u4e3a\u5b64\u7acb\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u5ffd\u89c6\u4e86\u77e5\u8bc6\u751f\u4ea7\u7684\u793e\u4f1a\u6027\u548c\u5386\u53f2\u6027\u672c\u8d28\u3002\u4eba\u7c7b\u79d1\u5b66\u6d1e\u5bdf\u6765\u81ea\u4e2a\u4f53\u8ba4\u77e5\u8f68\u8ff9\u548c\u96c6\u4f53\u5b66\u79d1\u8bb0\u5fc6\u4e24\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u6765\u6e90\uff0c\u800c\u73b0\u6709LLM\u96be\u4ee5\u8868\u793a\u8fd9\u4e9b\u7ed3\u6784\u5316\u7684\u8ba4\u77e5\u548c\u793e\u4f1a\u80cc\u666f\u3002", "method": "\u5f15\u5165\u4e09\u5c42\u6846\u67b6\u7684MirrorMind\u67b6\u6784\uff1a\u4e2a\u4f53\u5c42\u6784\u5efa\u7814\u7a76\u8005\u7684\u8ba4\u77e5\u6a21\u578b\uff08\u60c5\u666f\u3001\u8bed\u4e49\u548c\u4eba\u683c\u8bb0\u5fc6\uff09\uff1b\u9886\u57df\u5c42\u5c06\u96c6\u4f53\u77e5\u8bc6\u6620\u5c04\u4e3a\u7ed3\u6784\u5316\u5b66\u79d1\u6982\u5ff5\u56fe\uff1b\u8de8\u5b66\u79d1\u5c42\u4f5c\u4e3a\u6b63\u4ea4\u7f16\u6392\u5f15\u64ce\u3002\u8be5\u67b6\u6784\u5c06\u8bb0\u5fc6\u5b58\u50a8\u4e0e\u667a\u80fd\u6267\u884c\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u7efc\u5408\u4efb\u52a1\u4e2d\u8bc4\u4f30MirrorMind\uff0c\u5305\u62ec\u4f5c\u8005\u7ea7\u8ba4\u77e5\u6a21\u62df\u3001\u4e92\u8865\u63a8\u7406\u3001\u8de8\u5b66\u79d1\u534f\u4f5c\u4fc3\u8fdb\u548c\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u3002\u7ed3\u679c\u663e\u793aMirrorMind\u8d85\u8d8a\u4e86\u7b80\u5355\u4e8b\u5b9e\u68c0\u7d22\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u548c\u6d1e\u5bdf\u751f\u6210\u7684\u79d1\u5b66\u63a8\u7406\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u4e2a\u4f53\u8ba4\u77e5\u6df1\u5ea6\u4e0e\u96c6\u4f53\u5b66\u79d1\u5e7f\u5ea6\uff0cMirrorMind\u80fd\u591f\u5b9e\u73b0\u66f4\u63a5\u8fd1\u4eba\u7c7b\u79d1\u5b66\u601d\u7ef4\u7684\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u79d1\u5b66\u63a8\u7406\uff0c\u4e3aAI\u79d1\u5b66\u5bb6\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2511.17006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17006", "abs": "https://arxiv.org/abs/2511.17006", "authors": ["Tengxiao Liu", "Zifeng Wang", "Jin Miao", "I-Hung Hsu", "Jun Yan", "Jiefeng Chen", "Rujun Han", "Fangyuan Xu", "Yanfei Chen", "Ke Jiang", "Samira Daruki", "Yi Liang", "William Yang Wang", "Tomas Pfister", "Chen-Yu Lee"], "title": "Budget-Aware Tool-Use Enables Effective Agent Scaling", "comment": null, "summary": "Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u660e\u786e\u5de5\u5177\u8c03\u7528\u9884\u7b97\u7ea6\u675f\u4e0b\u5982\u4f55\u6709\u6548\u6269\u5c55\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\uff0c\u63d0\u51fa\u4e86\u9884\u7b97\u8ffd\u8e2a\u5668\u548cBATS\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u5177\u5907\u9884\u7b97\u610f\u8bc6\u5e76\u52a8\u6001\u8c03\u6574\u7b56\u7565\uff0c\u6539\u5584\u4e86\u6210\u672c-\u6027\u80fd\u7684\u6269\u5c55\u66f2\u7ebf\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u5728\u6269\u5c55\u5de5\u5177\u8c03\u7528\u9884\u7b97\u65f6\u7f3a\u4e4f\u9884\u7b97\u610f\u8bc6\uff0c\u5bfc\u81f4\u6027\u80fd\u5f88\u5feb\u8fbe\u5230\u74f6\u9888\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u5982\u4f55\u6709\u6548\u6269\u5c55\u667a\u80fd\u4f53\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u9884\u7b97\u8ffd\u8e2a\u5668\uff08\u8f7b\u91cf\u7ea7\u63d2\u4ef6\uff09\u63d0\u4f9b\u6301\u7eed\u7684\u9884\u7b97\u610f\u8bc6\uff0c\u5e76\u5f00\u53d1\u4e86BATS\u6846\u67b6\uff0c\u5229\u7528\u9884\u7b97\u610f\u8bc6\u52a8\u6001\u8c03\u6574\u89c4\u5212\u548c\u9a8c\u8bc1\u7b56\u7565\uff0c\u51b3\u5b9a\u662f\u6df1\u5165\u6316\u6398\u6709\u5e0c\u671b\u7684\u7ebf\u7d22\u8fd8\u662f\u8f6c\u5411\u65b0\u8def\u5f84\u3002", "result": "\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u4ea7\u751f\u4e86\u66f4\u6709\u5229\u7684\u6269\u5c55\u66f2\u7ebf\uff0c\u63a8\u52a8\u4e86\u6210\u672c-\u6027\u80fd\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63d0\u4f9b\u4e86\u5bf9\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u6269\u5c55\u7684\u66f4\u900f\u660e\u548c\u539f\u5219\u6027\u7406\u89e3\u3002", "conclusion": "\u9884\u7b97\u610f\u8bc6\u5bf9\u4e8e\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u7684\u6709\u6548\u6269\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u6269\u5c55\u884c\u4e3a\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u89c1\u89e3\u3002"}}
{"id": "2511.17038", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17038", "abs": "https://arxiv.org/abs/2511.17038", "authors": ["Hao Chen", "Renzheng Zhang", "Scott S. Howard"], "title": "DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing", "comment": null, "summary": "From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \\textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \\textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.", "AI": {"tldr": "\u8bba\u6587\u91cd\u65b0\u89e3\u91ca\u4e86\u6269\u6563\u6a21\u578b\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u4f5c\u7528\uff0c\u5c06\u5176\u89c6\u4e3aEM\u6846\u67b6\u4e2d\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u63d0\u51fa\u4e86DAPS++\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u6269\u6563\u9636\u6bb5\u548c\u6570\u636e\u9a71\u52a8\u4f18\u5316\u6765\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u65b9\u6cd5\u5728\u89e3\u51b3\u9006\u95ee\u9898\u65f6\uff0c\u5148\u9a8c\u63d0\u4f9b\u7684\u6307\u5bfc\u6709\u9650\uff0c\u91cd\u5efa\u4e3b\u8981\u7531\u6d4b\u91cf\u4e00\u81f4\u6027\u9879\u9a71\u52a8\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u4e0e\u6269\u6563\u52a8\u529b\u5b66\u57fa\u672c\u89e3\u8026\u3002\u9700\u8981\u6f84\u6e05\u8fd9\u79cd\u7ed3\u6784\u5e76\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u5c06\u6269\u6563\u91cd\u65b0\u89e3\u91ca\u4e3aEM\u6846\u67b6\u4e2d\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u63d0\u51faDAPS++\u65b9\u6cd5\uff0c\u8ba9\u4f3c\u7136\u9879\u66f4\u76f4\u63a5\u5730\u6307\u5bfc\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u548c\u6d4b\u91cf\u4f18\u5316\u6b65\u9aa4\u3002", "result": "DAPS++\u5b9e\u73b0\u4e86\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u5728\u591a\u79cd\u56fe\u50cf\u6062\u590d\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9700\u8981\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u66f4\u5c11\u3002", "conclusion": "\u6269\u6563\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u4e3b\u8981\u4f5c\u7528\u662f\u63d0\u4f9b\u521d\u59cb\u5316\uff0cDAPS++\u901a\u8fc7\u89e3\u8026\u6269\u6563\u548c\u6570\u636e\u9a71\u52a8\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u7edf\u4e00\u7684\u6269\u6563\u8f68\u8ff9\u5728\u5b9e\u8df5\u4e2d\u4ecd\u7136\u6709\u6548\u3002"}}
{"id": "2511.17056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17056", "abs": "https://arxiv.org/abs/2511.17056", "authors": ["Paloma Rabaey", "Adrick Tench", "Stefan Heytens", "Thomas Demeester"], "title": "Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks", "comment": null, "summary": "Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u60a3\u8005\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u8868\u683c\u7279\u5f81\uff08\u4f7f\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\uff09\u548c\u4e34\u5e8a\u6587\u672c\u6570\u636e\uff08\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\uff09\uff0c\u901a\u8fc7\u865a\u62df\u8bc1\u636e\u548c\u4e00\u81f4\u6027\u8282\u70b9\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u6982\u7387\u878d\u5408\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u65e2\u6709\u7ed3\u6784\u5316\u4fe1\u606f\u4e5f\u6709\u975e\u7ed3\u6784\u5316\u6587\u672c\u4fe1\u606f\uff0c\u9700\u8981\u6574\u5408\u8fd9\u4e24\u79cd\u6570\u636e\u6e90\u6765\u6784\u5efa\u900f\u660e\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u4e13\u5bb6\u6307\u5bfc\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u5904\u7406\u8868\u683c\u7279\u5f81\uff0c\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\u5904\u7406\u4e34\u5e8a\u6587\u672c\uff0c\u901a\u8fc7\u865a\u62df\u8bc1\u636e\u548c\u4e00\u81f4\u6027\u8282\u70b9\u8fdb\u884c\u6982\u7387\u878d\u5408\u3002", "result": "\u5728SimSUM\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e00\u81f4\u6027\u8282\u70b9\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528\u865a\u62df\u8bc1\u636e\u80fd\u6539\u5584\u9884\u6d4b\u6821\u51c6\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u7f3a\u5931\u4fe1\u606f\u5e76\u89e3\u51b3\u8868\u683c\u548c\u6587\u672c\u6570\u636e\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u4fe1\u606f\u63d0\u53d6\u65b9\u6848\u3002"}}
{"id": "2511.17162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17162", "abs": "https://arxiv.org/abs/2511.17162", "authors": ["Sara Zuppiroli", "Carmelo Fabio Longo", "Anna Sofia Lippolis", "Rocco Paolillo", "Lorenzo Giammei", "Miguel Ceriani", "Francesco Poggi", "Antonio Zinilli", "Andrea Giovanni Nuzzolese"], "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency", "comment": null, "summary": "The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684BDI\u672c\u4f53\u8bba\uff0c\u4f5c\u4e3a\u6a21\u5757\u5316\u672c\u4f53\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7528\u4e8e\u8868\u793a\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u3001\u6b32\u671b\u548c\u610f\u56fe\u8ba4\u77e5\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u4e0eLLMs\u7ed3\u5408\u548cSemas\u63a8\u7406\u5e73\u53f0\u96c6\u6210\u9a8c\u8bc1\u4e86\u5176\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "BDI\u6a21\u578b\u5728\u4eba\u5de5\u667a\u80fd\u548c\u8ba4\u77e5\u79d1\u5b66\u4e2d\u662f\u8868\u793a\u7406\u6027\u667a\u80fd\u4f53\u7684\u57fa\u77f3\uff0c\u4f46\u5176\u4e0e\u7ed3\u6784\u5316\u3001\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u77e5\u8bc6\u8868\u793a\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u5efa\u7acb\u5f62\u5f0f\u5316\u7684\u672c\u4f53\u8bba\u6765\u652f\u6301\u8ba4\u77e5\u67b6\u6784\u7684\u8bed\u4e49\u7cbe\u786e\u6027\u548c\u53ef\u91cd\u7528\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684BDI\u672c\u4f53\u8bba\u6a21\u5f0f\uff0c\u4e0e\u57fa\u7840\u672c\u4f53\u5bf9\u9f50\u786e\u4fdd\u8bed\u4e49\u7cbe\u786e\u6027\uff1b\u901a\u8fc7\u4e24\u79cd\u5b9e\u9a8c\u9a8c\u8bc1\uff1a(1) \u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u4f7f\u7528\u903b\u8f91\u589e\u5f3a\u751f\u6210\u8bc4\u4f30\u672c\u4f53\u57fa\u7840\u5bf9\u63a8\u7406\u4e00\u81f4\u6027\u7684\u8d21\u732e\uff1b(2) \u5728Semas\u63a8\u7406\u5e73\u53f0\u4e2d\u96c6\u6210\uff0c\u5b9e\u73b0RDF\u4e09\u5143\u7ec4\u4e0e\u667a\u80fd\u4f53\u5fc3\u7406\u72b6\u6001\u7684\u53cc\u5411\u8f6c\u6362\u3002", "result": "BDI\u672c\u4f53\u8bba\u80fd\u591f\u4f5c\u4e3a\u6982\u5ff5\u548c\u64cd\u4f5c\u6865\u6881\uff0c\u8fde\u63a5\u58f0\u660e\u6027\u548c\u7a0b\u5e8f\u6027\u667a\u80fd\uff0c\u652f\u6301\u8ba4\u77e5\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u4e14\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u548c\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u5728\u6570\u636e\u7f51\u7edc\u4e2d\u7684\u8fd0\u884c\u3002", "conclusion": "\u8be5BDI\u672c\u4f53\u8bba\u4e3a\u6784\u5efa\u8ba4\u77e5\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u4e14\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u4fc3\u8fdb\u4e86\u58f0\u660e\u6027\u667a\u80fd\u4e0e\u7a0b\u5e8f\u6027\u667a\u80fd\u7684\u878d\u5408\u3002"}}
{"id": "2511.17165", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17165", "abs": "https://arxiv.org/abs/2511.17165", "authors": ["Kesheng Chen", "Wenjian Luo", "Bang Zhang", "Zeping Yin", "Zipeng Ye"], "title": "MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward", "comment": null, "summary": "Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.", "AI": {"tldr": "\u63d0\u51faMIR\u65b9\u6cd5\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u901a\u8fc7\u6fc0\u52b1\u667a\u80fd\u4f53\u63a2\u7d22\u5f71\u54cd\u961f\u53cb\u7684\u52a8\u4f5c\u6765\u4fc3\u8fdb\u56e2\u961f\u63a2\u7d22", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u8054\u5408\u52a8\u4f5c\u8f68\u8ff9\u7684\u6307\u6570\u7ea7\u7a00\u758f\u6027\u548c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u8003\u8651\u5f71\u54cd\u56e2\u961f\u72b6\u6001\u7684\u8054\u5408\u52a8\u4f5c\u662f\u4e3b\u8981\u6311\u6218", "method": "\u63d0\u51fa\u76f8\u4e92\u5185\u5728\u5956\u52b1(MIR)\u65b9\u6cd5\uff0c\u6fc0\u52b1\u4e2a\u4f53\u667a\u80fd\u4f53\u63a2\u7d22\u5f71\u54cd\u961f\u53cb\u7684\u52a8\u4f5c\uff0c\u7ed3\u5408\u539f\u59cb\u7b56\u7565\u4fc3\u8fdb\u56e2\u961f\u63a2\u7d22", "result": "\u5728\u6269\u5c55\u7684MiniGrid-MA\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u4f18\u6027\u80fd", "conclusion": "MIR\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u663e\u8457\u6539\u5584\u7a00\u758f\u5956\u52b1\u573a\u666f\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6027\u80fd"}}
{"id": "2511.17198", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17198", "abs": "https://arxiv.org/abs/2511.17198", "authors": ["Kaiyu Li", "Jiayu Wang", "Zhi Wang", "Hui Qiao", "Weizhan Zhang", "Deyu Meng", "Xiangyong Cao"], "title": "Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism", "comment": "Page: https://earth-insights.github.io/EarthAgent", "summary": "LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236(HTAM)\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6EarthAgent\uff0c\u4e13\u95e8\u89e3\u51b3\u9065\u611f\u7b49\u4e13\u4e1a\u9886\u57df\u4e2d\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u6311\u6218\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "motivation": "\u901a\u7528LLM\u667a\u80fd\u4f53\u6846\u67b6\u5728\u9700\u8981\u4e25\u683c\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u4e13\u4e1a\u9886\u57df\uff08\u5982\u9065\u611f\uff09\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e9b\u9886\u57df\u9700\u8981\u4e13\u4e1a\u5de5\u5177\u548c\u591a\u6b65\u9aa4\u7a0b\u5e8f\uff0c\u6311\u6218\u4e86\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236(HTAM)\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6784\u5efa\u4e3a\u53cd\u6620\u9886\u57df\u5185\u5728\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\u7684\u903b\u8f91\u5c42\u6b21\u7ed3\u6784\uff0c\u901a\u8fc7\u4efb\u52a1\u4e2d\u5fc3\u67b6\u6784\u786e\u4fdd\u7a0b\u5e8f\u6b63\u786e\u6027\uff0c\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u987a\u5e8f\u5c42\u3002", "result": "\u6784\u5efa\u4e86EarthAgent\u7cfb\u7edf\u5e76\u5728GeoPlan-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660eEarthAgent\u5728\u5de5\u5177\u9009\u62e9\u3001\u8def\u5f84\u76f8\u4f3c\u6027\u548c\u903b\u8f91\u5b8c\u6574\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "\u5c06\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u9886\u57df\u5185\u5728\u4efb\u52a1\u7ed3\u6784\u5bf9\u9f50\u662f\u6784\u5efa\u7a33\u5065\u53ef\u9760\u7684\u4e13\u4e1a\u81ea\u6cbb\u7cfb\u7edf\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2511.17332", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17332", "abs": "https://arxiv.org/abs/2511.17332", "authors": ["Virginia Dignum", "Frank Dignum"], "title": "Agentifying Agentic AI", "comment": "10 pages; 1 figure", "summary": "Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5c06AAMAS\u793e\u533a\u5f00\u53d1\u7684BDI\u67b6\u6784\u3001\u901a\u4fe1\u534f\u8bae\u3001\u673a\u5236\u8bbe\u8ba1\u548c\u5236\u5ea6\u5efa\u6a21\u7b49\u6982\u5ff5\u5de5\u5177\u4f5c\u4e3a\u5b9e\u73b0\u667a\u80fdAI\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u5c06\u81ea\u9002\u5e94\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u534f\u8c03\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u5177\u6709\u900f\u660e\u5ea6\u3001\u5408\u4f5c\u6027\u548c\u95ee\u8d23\u6027\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u667a\u80fdAI\u7cfb\u7edf\u7684\u6301\u7eed\u81ea\u4e3b\u6027\u3001\u63a8\u7406\u548c\u4ea4\u4e92\u80fd\u529b\uff0c\u9700\u8981\u8865\u5145\u5173\u4e8e\u667a\u80fd\u4f53\u7684\u5047\u8bbe\uff0c\u5e76\u5efa\u7acb\u660e\u786e\u7684\u8ba4\u77e5\u3001\u5408\u4f5c\u548c\u6cbb\u7406\u6a21\u578b\u3002", "method": "\u5229\u7528AAMAS\u793e\u533a\u5f00\u53d1\u7684\u6982\u5ff5\u5de5\u5177\uff0c\u5305\u62ecBDI\u67b6\u6784\u3001\u901a\u4fe1\u534f\u8bae\u3001\u673a\u5236\u8bbe\u8ba1\u548c\u5236\u5ea6\u5efa\u6a21\uff0c\u5c06\u81ea\u9002\u5e94\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u534f\u8c03\u6a21\u578b\u76f8\u7ed3\u5408\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fde\u63a5\u5f62\u5f0f\u7406\u8bba\u548c\u5b9e\u8df5\u81ea\u4e3b\u6027\u7684\u667a\u80fd\u4f53\u89c6\u89d2\uff0c\u4e3a\u6784\u5efa\u4e0d\u4ec5\u80fd\u529b\u5f3a\u4e14\u7075\u6d3b\uff0c\u800c\u4e14\u900f\u660e\u3001\u5408\u4f5c\u548c\u53ef\u95ee\u8d23\u7684\u667a\u80fd\u7cfb\u7edf\u6307\u660e\u4e86\u8def\u5f84\u3002", "conclusion": "AAMAS\u793e\u533a\u7684\u6982\u5ff5\u5de5\u5177\u4e3a\u667a\u80fdAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u6574\u5408\u81ea\u9002\u5e94\u65b9\u6cd5\u548c\u7ed3\u6784\u5316\u6a21\u578b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u771f\u6b63\u5177\u6709\u667a\u80fd\u7279\u6027\u7684\u7cfb\u7edf\u3002"}}
{"id": "2511.17408", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17408", "abs": "https://arxiv.org/abs/2511.17408", "authors": ["Nathalie Kirch", "Samuel Dower", "Adrians Skapars", "Ekdeep Singh Lubana", "Dmitrii Krasheninnikov"], "title": "That's not natural: The Impact of Off-Policy Training Data on Probe Performance", "comment": "10 pages, EurIPS 2025 Workshop on Private AI Governance", "summary": "Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.", "AI": {"tldr": "\u8bc4\u4f30\u4f7f\u7528\u5408\u6210\u548c\u79bb\u7b56\u7565\u6570\u636e\u5bf9LLM\u884c\u4e3a\u63a2\u6d4b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u54cd\u5e94\u751f\u6210\u7b56\u7565\u663e\u8457\u5f71\u54cd\u63a2\u6d4b\u6027\u80fd\uff0c\u79bb\u7b56\u7565\u6570\u636e\u5230\u5728\u7ebf\u7b56\u7565\u6570\u636e\u7684\u6210\u529f\u6cdb\u5316\u53ef\u9884\u6d4b\u771f\u5b9e\u76d1\u63a7\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u7531\u4e8e\u8bb8\u591a\u884c\u4e3a\u7684\u81ea\u7136\u793a\u4f8b\u7a00\u5c11\uff0c\u7814\u7a76\u8005\u4e0d\u5f97\u4e0d\u4f9d\u8d56\u5408\u6210\u6216\u79bb\u7b56\u7565\u7684LLM\u54cd\u5e94\u6765\u8bad\u7ec3\u63a2\u6d4b\u6a21\u578b\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u6570\u636e\u5bf9\u63a2\u6d4b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u5728\u516b\u79cd\u4e0d\u540c\u7684LLM\u884c\u4e3a\u4e0a\u6d4b\u8bd5\u7ebf\u6027\u548c\u6ce8\u610f\u529b\u63a2\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528\u4e0d\u540c\u54cd\u5e94\u751f\u6210\u7b56\u7565\u7684\u6570\u636e\u8bad\u7ec3\uff0c\u8bc4\u4f30\u4ece\u79bb\u7b56\u7565\u6570\u636e\u5230\u5728\u7ebf\u7b56\u7565\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u54cd\u5e94\u751f\u6210\u7b56\u7565\u663e\u8457\u5f71\u54cd\u63a2\u6d4b\u6027\u80fd\uff0c\u6210\u529f\u4ece\u79bb\u7b56\u7565\u6570\u636e\u6cdb\u5316\u5230\u6d4b\u8bd5\u96c6\u7684\u884c\u4e3a\u53ef\u9884\u6d4b\u5728\u7ebf\u7b56\u7565\u6cdb\u5316\u6210\u529f\uff1b\u6b3a\u9a97\u548c\u6c99\u888b\u63a2\u6d4b\u53ef\u80fd\u65e0\u6cd5\u4ece\u79bb\u7b56\u7565\u6cdb\u5316\u5230\u5728\u7ebf\u7b56\u7565\u6570\u636e\uff1b\u8bad\u7ec3\u6570\u636e\u57df\u7684\u53d8\u5316\u5bfc\u81f4\u66f4\u5927\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5728\u6ca1\u6709\u5728\u7ebf\u7b56\u7565\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u540c\u57df\u7684\u79bb\u7b56\u7565\u6570\u636e\u6bd4\u4f7f\u7528\u4e0d\u540c\u57df\u7684\u5728\u7ebf\u7b56\u7565\u6570\u636e\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u63a2\u6d4b\uff0c\u5f3a\u8c03\u9700\u8981\u80fd\u66f4\u597d\u5904\u7406LLM\u76d1\u63a7\u4e2d\u5206\u5e03\u504f\u79fb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.17461", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17461", "abs": "https://arxiv.org/abs/2511.17461", "authors": ["Jiaxi Liu", "Chengyuan Ma", "Hang Zhou", "Weizhe Tang", "Shixiao Liang", "Haoyang Ding", "Xiaopeng Li", "Bin Ran"], "title": "SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception", "comment": null, "summary": "Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.", "AI": {"tldr": "\u63d0\u51fa\u4e86SRA-CP\u6846\u67b6\uff0c\u901a\u8fc7\u98ce\u9669\u611f\u77e5\u7684\u9009\u62e9\u6027\u534f\u4f5c\u611f\u77e5\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u5173\u952e\u7269\u4f53\u68c0\u6d4b\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u5927\u5e45\u51cf\u5c11\u901a\u4fe1\u5e26\u5bbd\u4f7f\u7528", "motivation": "\u89e3\u51b3\u73b0\u6709\u534f\u4f5c\u611f\u77e5\u65b9\u6cd5\u4f20\u8f93\u5927\u91cf\u65e0\u5173\u611f\u77e5\u6570\u636e\u5bfc\u81f4\u901a\u4fe1\u5e26\u5bbd\u4e0d\u8db3\uff0c\u4ee5\u53ca\u4f9d\u8d56\u9884\u5b9a\u4e49\u901a\u4fe1\u4f19\u4f34\u4e0d\u9002\u5e94\u52a8\u6001\u4ea4\u901a\u73af\u5883\u7684\u95ee\u9898", "method": "\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u534f\u8bae\uff0c\u8f66\u8f86\u6301\u7eed\u5e7f\u64ad\u8f7b\u91cf\u7ea7\u611f\u77e5\u8986\u76d6\u6458\u8981\uff0c\u4ec5\u5728\u68c0\u6d4b\u5230\u98ce\u9669\u76f8\u5173\u76f2\u533a\u65f6\u542f\u52a8\u9488\u5bf9\u6027\u534f\u4f5c\uff1b\u5305\u542b\u611f\u77e5\u98ce\u9669\u8bc6\u522b\u6a21\u5757\u548c\u9009\u62e9\u6027\u4fe1\u606f\u4ea4\u6362\u878d\u5408\u6a21\u5757", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u901a\u7528\u534f\u4f5c\u611f\u77e5\u65b9\u6cd5\uff0c\u5b89\u5168\u5173\u952e\u7269\u4f53\u68c0\u6d4b\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e1%\uff0c\u901a\u4fe1\u5e26\u5bbd\u4f7f\u7528\u4ec5\u4e3a20%\uff1b\u76f8\u6bd4\u73b0\u6709\u9009\u62e9\u6027\u534f\u4f5c\u611f\u77e5\u65b9\u6cd5\uff0c\u611f\u77e5\u6027\u80fd\u63d0\u534715%", "conclusion": "SRA-CP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u534f\u4f5c\u611f\u77e5\u4e2d\u7684\u901a\u4fe1\u5e26\u5bbd\u548c\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u98ce\u9669\u611f\u77e5\u9009\u62e9\u6027\u534f\u4f5c"}}
