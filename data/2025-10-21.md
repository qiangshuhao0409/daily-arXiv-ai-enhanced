<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 70]
- [cs.IT](#cs.IT) [Total: 13]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Agentic AI for Ultra-Modern Networks: Multi-Agent Framework for RAN Autonomy and Assurance](https://arxiv.org/abs/2510.16144)
*Sukhdeep Singh,Avinash Bhat,Shweta M,Subhash K Singh,Moonki Hong,Madhan Raj K,Kandeepan Sithamparanathan,Sunder A. Khowaja,Kapal Dev*

Main category: cs.NI

TL;DR: 本文提出多智能体架构替代传统O-RAN集中式RIC控制，通过分布式智能体协作实现网络自主性、弹性和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统O-RAN控制环路过度依赖RIC编排，存在策略冲突、数据漂移和不可预见条件下的不安全操作等风险，需要新的自主网络范式。

Method: 设计多智能体架构，由专门智能体协作执行数据收集、模型训练、预测、策略生成、验证、部署和保障等任务，替代紧密耦合的集中式工作流。

Result: 在流量转向用例测试中，多智能体系统能阻止不安全策略，保持全局网络健康，而简单预测器驱动部署虽然改善局部KPI但会破坏邻居稳定性。

Conclusion: 多智能体架构为下一代RAN中可信AI驱动自主性提供了可靠基础，具备自主性、弹性、可解释性和系统级安全性。

Abstract: The increasing complexity of Beyond 5G and 6G networks necessitates new
paradigms for autonomy and assur- ance. Traditional O-RAN control loops rely
heavily on RIC- based orchestration, which centralizes intelligence and exposes
the system to risks such as policy conflicts, data drift, and unsafe actions
under unforeseen conditions. In this work, we argue that the future of
autonomous networks lies in a multi-agentic architecture, where specialized
agents collaborate to perform data collection, model training, prediction,
policy generation, verification, deployment, and assurance. By replacing
tightly- coupled centralized RIC-based workflows with distributed agents, the
framework achieves autonomy, resilience, explainability, and system-wide
safety. To substantiate this vision, we design and evaluate a traffic steering
use case under surge and drift conditions. Results across four KPIs: RRC
connected users, IP throughput, PRB utilization, and SINR, demonstrate that a
naive predictor-driven deployment improves local KPIs but destabilizes
neighbors, whereas the agentic system blocks unsafe policies, preserving global
network health. This study highlights multi- agent architectures as a credible
foundation for trustworthy AI- driven autonomy in next-generation RANs.

</details>


### [2] [Traffic Prioritization Mechanisms for Mission and Time Critical Applications in Industrial Internet of Things](https://arxiv.org/abs/2510.17009)
*Anwar Ahmed Khan,Shama Siddiqui,Indrakshi Dey*

Main category: cs.NI

TL;DR: 本文评估了IIoT环境中两种MAC技术（时隙窃取和分组分片）的性能，通过SS-MAC和FROG-MAC协议对比，发现FROG-MAC因减少紧急流量等待时间而表现更优。


<details>
  <summary>Details</summary>
Motivation: 工业物联网(IIoT)通过机器对机器通信改变工业运营，但节点生成的数据类型多样且服务需求不同，因此MAC协议对确保高效传输至关重要。需要评估不同MAC技术在IIoT环境中的性能表现。

Method: 选择SS-MAC（代表时隙窃取技术）和FROG-MAC（代表分组分片技术）两种代表性协议，使用Contiki进行真实仿真，比较延迟和丢包率。

Result: FROG-MAC在延迟和丢包方面表现优于SS-MAC，主要原因是减少了紧急流量的等待时间。

Conclusion: 简单的分组分片方案可以有效地调度工业环境中的异构流量，FROG-MAC技术更适合IIoT应用场景。

Abstract: Industrial Internet of Things (IIoT) promises to revolutionize industrial
operations and productions through utilizing Machine-to-Machine (M2M)
communications. Since each node in such environments generates various types of
data with diverse service requirements, MAC protocol holds crucial importance
to ensure efficient delivery. In this context, simple to complex MAC schemes
are found in literature. This paper focuses on evaluating the performance of
two major techniques "slot stealing" and "packet fragmentation" for the IIoT;
representative protocols SS-MAC and FROG-MAC have been chosen from each
category respectively. We conducted realistic simulations for the two protocols
using Contiki. Delay and packet loss comparison for SS-MAC and FROG-MAC
indicates the superiority of FROG-MAC due to reduction in the waiting time for
urgent traffic. Thus, a simple fragmentation scheme could be deployed for
efficient scheduling of heterogenous traffic in the industrial environments.

</details>


### [3] [Mamba4Net: Distilled Hybrid Mamba Large Language Models For Networking](https://arxiv.org/abs/2510.17147)
*Linhan Xia,Mingzhan Yang,Jingjing Wang,Ziwei Yan,Yakun Ren,Guo Yu,Kai Lei*

Main category: cs.NI

TL;DR: Mamba4Net是一个跨架构蒸馏框架，将基于Transformer的大语言模型知识转移到基于Mamba架构的学生模型中，显著提升计算效率，在三个网络任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Transformer大语言模型在资源受限环境中存在二次时间复杂度和大模型尺寸带来的计算开销和内存限制问题，需要更高效的解决方案。

Method: 提出Mamba4Net跨架构蒸馏框架，从Transformer LLMs向具有线性时间复杂度的Mamba架构学生模型转移网络特定知识。

Result: 在视口预测、自适应比特率流和集群作业调度三个任务中，Mamba4Net性能优于不利用LLM的现有方法；相比直接使用Transformer LLMs，吞吐量提高3.96倍，存储占用仅为之前的5.48%。

Conclusion: Mamba4Net能够实现LLM衍生知识在网络环境中的成本效益应用，展示了在资源受限场景下高效部署LLM知识的潜力。

Abstract: Transformer-based large language models (LLMs) are increasingly being adopted
in networking research to address domain-specific challenges. However, their
quadratic time complexity and substantial model sizes often result in
significant computational overhead and memory constraints, particularly in
resource-constrained environments. Drawing inspiration from the efficiency and
performance of the Deepseek-R1 model within the knowledge distillation
paradigm, this paper introduces Mamba4Net, a novel cross-architecture
distillation framework. Mamba4Net transfers networking-specific knowledge from
transformer-based LLMs to student models built on the Mamba architecture, which
features linear time complexity. This design substantially enhances
computational efficiency compared to the quadratic complexity of
transformer-based models, while the reduced model size further minimizes
computational demands, improving overall performance and resource utilization.
To evaluate its effectiveness, Mamba4Net was tested across three diverse
networking tasks: viewport prediction, adaptive bitrate streaming, and cluster
job scheduling. Compared to existing methods that do not leverage LLMs,
Mamba4Net demonstrates superior task performance. Furthermore, relative to
direct applications of transformer-based LLMs, it achieves significant
efficiency gains, including a throughput 3.96 times higher and a storage
footprint of only 5.48% of that required by previous LLM-based approaches.
These results highlight Mamba4Net's potential to enable the cost-effective
application of LLM-derived knowledge in networking contexts. The source code is
openly available to support further research and development.

</details>


### [4] [AoA Services in 5G Networks: A Framework for Real-World Implementation and Systematic Testing](https://arxiv.org/abs/2510.17342)
*Alberto Ceresoli,Viola Bernazzoli,Roberto Pegurri,Ilario Filippini*

Main category: cs.NI

TL;DR: 开发了首个完全开源的5G测试平台，用于到达角估计，验证了在5G系统中实现轻量级、单锚点、网络原生定位的可行性。


<details>
  <summary>Details</summary>
Motivation: 标准化的位置管理功能存在可扩展性和延迟限制，无法满足低延迟和细粒度定位需求，需要将定位智能转移到无线接入网。

Method: 集成NVIDIA Sionna RT与Keysight PROPSIM信道仿真器，开发了USRP N310设备的新相位校准程序，构建了完全开源的5G测试平台。

Result: 实验结果显示达到亚度到几度的精度，验证了轻量级单锚点网络原生定位的可行性。

Conclusion: 该开源测试平台为5G系统中的到达角估计提供了系统化和可重复的实验环境，证明了网络原生定位方案的实用性。

Abstract: Accurate positioning is a key enabler for emerging 5G applications. While the
standardized Location Management Function (LMF) operates centrally within the
core network, its scalability and latency limitations hinder low-latency and
fine-grained localization. A practical alternative is to shift positioning
intelligence toward the radio access network (RAN), where uplink sounding
reference signal (SRS)-based angle-of-arrival (AoA) estimation offers a
lightweight, network-native solution. In this work, we present the first fully
open-source 5G testbed for AoA estimation, enabling systematic and repeatable
experimentation under realistic yet controllable channel conditions. The
framework integrates the NVIDIA Sionna RT with a Keysight PROPSIM channel
emulator and includes a novel phase calibration procedure for USRP N310
devices. Experimental results show sub-degree to few-degree accuracy,
validating the feasibility of lightweight, single-anchor, network-native
localization within next-generation 5G systems.

</details>


### [5] [Enhancing 5G V2X Mode 2 for Sporadic Traffic](https://arxiv.org/abs/2510.17395)
*Dmitry Bankov,Artem Krasilov,Artem Otmakhov,Aleksei Shashin,Evgeny Khorov*

Main category: cs.NI

TL;DR: 分析5G V2X中Mode 2在偶发流量场景下的性能，并提出改进方法，可提升系统容量达40%且复杂度影响小


<details>
  <summary>Details</summary>
Motivation: 道路安全和自动驾驶应用需要车辆间及车辆与基础设施间及时可靠的数据传输，5G V2X技术为此而开发。针对偶发流量场景（如车辆检测到危险情况时随机生成数据包），需要满足严格的延迟和可靠性要求

Method: 考虑车辆使用Mode 2（用户自主选择传输资源）来满足严格延迟要求。分析Mode 2在偶发流量下的性能，并提出多种改进方法

Result: 仿真结果表明，所提出的方法可以将系统容量提升高达40%，同时对复杂度的影响很小

Conclusion: 提出的改进方法能有效提升5G V2X Mode 2在偶发流量场景下的性能，为道路安全和自动驾驶应用提供更好的通信保障

Abstract: The emerging road safety and autonomous vehicle applications require timely
and reliable data delivery between vehicles and between vehicles and
infrastructure. To satisfy this demand, 3GPP develops a 5G
Vehicle-to-Everything (V2X) technology. Depending on the served traffic type,
5G V2X specifications propose two channel access methods: (i) Mode 1, according
to which a base station allocates resources to users, and (ii) Mode 2,
according to which users autonomously select resources for their transmissions.
In the paper, we consider a scenario with sporadic traffic, e.g., a vehicle
generates a packet at a random time moment when it detects a dangerous
situation, which imposes strict requirements on delay and reliability. To
satisfy strict delay requirements, vehicles use Mode 2. We analyze the
performance of Mode 2 for sporadic traffic and propose several approaches to
improve it. Simulation results show that the proposed approaches can increase
the system capacity by up to 40% with a low impact on complexity.

</details>


### [6] [Is It Worth to Use Feedback Channel in 5G V2X Platoon Scenarios?](https://arxiv.org/abs/2510.17410)
*Dmitry Bankov,Artem Krasilov,Artem Otmakhov,Pavel Savlukovich,Evgeny Khorov*

Main category: cs.NI

TL;DR: 5G V2X引入反馈信道提升传输可靠性，但会占用数据信道资源。研究发现反馈信道对系统容量的影响取决于车队规模、通信强度和QoS要求，可能使容量翻倍或减半。


<details>
  <summary>Details</summary>
Motivation: 5G V2X支持组播和单播通信，需要反馈信道来提升传输可靠性和参数选择，但反馈信道会占用数据信道资源，需要评估其对系统容量的影响。

Method: 使用NS-3进行广泛仿真，分析车队场景下反馈信道使用对系统容量的影响，考虑车队规模、组播和广播流量强度及其QoS要求。

Result: 反馈信道对系统容量的影响具有双重性：在某些情况下可显著提升系统容量（最高可达2倍），而在其他情况下几乎使系统容量减半。

Conclusion: 反馈信道对系统容量的影响取决于具体场景参数，需要自适应选择反馈信道参数以优化系统性能。

Abstract: 5G Vehicle-to-Everything (V2X) is a new technology developed by 3GPP to
support inter-vehicle communication. In contrast to 4G V2X which allows only
broadcast communication, 5G V2X enables groupcast and unicast communication.
Such types of communication are needed for new V2X scenarios: platooning,
extended sensors, remote driving, etc. To improve the data transmission
reliability and assist in the selection of the transmission parameters in these
scenarios, 5G V2X introduces a feedback channel that allows receivers to send
acknowledgments in response to data packets. However, some part of the overall
resource shall be allocated for the feedback channel, which reduces the amount
of channel resources available for data transmission. In this paper, we
consider a scenario with a platoon, which generates groupcast traffic, and
surrounding vehicles, which generate legacy broadcast traffic. Using extensive
simulations in NS-3, we analyze how the usage of the feedback channel
influences the overall system capacity. Our results show that depending on the
platoon size, groupcast, and broadcast traffic intensities, and their quality
of service requirements, the usage of the feedback channel can in some cases
significantly increase the system capacity (up to 2x), while in other cases it
almost halves the system capacity. We explain the reasons for such effects and
discuss how to adaptively select the feedback channel parameters.

</details>


### [7] [Adaptive Local Combining with Decentralized Decoding for Distributed Massive MIMO](https://arxiv.org/abs/2510.17445)
*Mohd Saif Ali Khan,Karthik RM,Samar Agnihotri*

Main category: cs.NI

TL;DR: 提出去中心化解码架构，通过AP独立计算干扰抑制权重，引入广义局部迫零框架(G-PFZF和G-PWPFZF)，自适应分类用户并优化频谱效率，使用导频相关组合向量提升可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决上行分布式大规模MIMO网络中本地组合方案性能不佳、前传负载高和集中式LSFD架构计算成本高的问题。

Method: 去中心化解码架构，AP独立计算干扰抑制权重；广义局部迫零框架(G-PFZF和G-PWPFZF)，基于局部频谱效率优化自适应分类用户；导频相关组合向量替代用户相关向量。

Result: 数值结果显示，广义方案持续优于固定阈值对应方案，本地权重引入降低了开销和计算成本，性能损失最小。

Conclusion: 提出的去中心化架构和广义局部迫零框架有效解决了分布式大规模MIMO网络的性能瓶颈，在降低开销的同时保持良好性能。

Abstract: A major bottleneck in uplink distributed massive multiple-input
multiple-output networks is the sub-optimal performance of local combining
schemes, coupled with high fronthaul load and computational cost inherent in
centralized large scale fading decoding (LSFD) architectures. This paper
introduces a decentralized decoding architecture that fundamentally breaks from
the conventional LSFD, by allowing each AP calculates interference-suppressing
local weights independently and applies them to its data estimates before
transmission. Furthermore, two generalized local zero-forcing (ZF) framework,
generalized partial full-pilot ZF (G-PFZF) and generalized protected weak PFZF
(G-PWPFZF), are introduced, where each access point (AP) adaptively and
independently determines its combining strategy through a local sum spectral
efficiency optimization that classifies user equipments (UEs) as strong or weak
using only local information, eliminating the fixed thresholds used in PFZF and
PWPFZF. To further enhance scalability, pilot-dependent combining vectors
instead of user-dependent ones are introduced and are shared among users with
the same pilot. The corresponding closed-form spectral efficiency expressions
are derived. Numerical results show that the proposed generalized schemes
consistently outperform fixed-threshold counterparts, while the introduction of
local weights yields lower overhead and computation costs with minimal
performance penalty compared to them.

</details>


### [8] [Pointing-Error-Induced Fading in an Open-Loop THz Uplink with Hardware Impairments](https://arxiv.org/abs/2510.17647)
*P. Brach del Prever,P. Testolina,A. Masihi,S. Petrushkevich,M. Polese,T. Melodia,J. M. Jornet*

Main category: cs.NI

TL;DR: 分析亚太赫兹和太赫兹上行链路通信系统的开环机械跟踪性能，量化卫星过境时的指向误差，并将机械约束与通信性能联系起来。


<details>
  <summary>Details</summary>
Motivation: 高频段通信需要精确指向来克服传播损耗，但实际跟踪系统存在机械动态限制，需要量化这些限制对通信性能的影响。

Method: 开发包含运动延迟、加速度和速度限制的机械动态数学模型，将指向误差集成到链路预算中，评估不同LEO卫星轨迹和控制策略下的权衡。

Result: 建立了硬件限制与通信性能之间的联系，量化了不同条件下的指向误差对链路性能的影响。

Conclusion: 为实际机械约束下的高频非地面网络上行链路提供了设计指导原则。

Abstract: We analyze the open-loop mechanical tracking performance of a sub-Terahertz
(sub-THz) and Terahertz (THz) uplink communication system. These high-frequency
bands enable multi-gigabit links through large bandwidths and narrow beams, but
require precise pointing to overcome spreading loss. A tracking system can be
used to orient horn antennas toward mobile targets. We develop a mathematical
model that captures the mechanical dynamics of a real tracking system, which
includes motion latency and acceleration and velocity limits, to quantify
pointing errors during satellite passes and integrate these effects into the
link budget. We evaluate the trade-offs between beam directionality and
pointing tolerance across different Low Earth Orbit (LEO) satellite
trajectories and control strategies. The results link the hardware limitations
to the communications performance, providing design guidelines for
high-frequency Non-Terrestrial Network (NTN) uplink under practical mechanical
constraints.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search](https://arxiv.org/abs/2510.15948)
*MingSheng Li,Guangze Zhao,Sichen Liu*

Main category: cs.AI

TL;DR: VisuoAlign是一个通过提示引导树搜索实现多模态安全对齐的框架，旨在解决大型视觉语言模型在跨模态威胁下的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法对多模态越狱攻击脆弱，视觉输入引入新的攻击面，推理链缺乏安全监督，模态融合时对齐效果下降。

Method: 通过视觉-文本交互提示将安全约束嵌入推理过程，使用蒙特卡洛树搜索构建多样化的安全关键提示轨迹，并引入基于提示的缩放实现实时风险检测。

Result: 实验表明VisuoAlign能主动暴露风险，实现全面的数据集生成，并显著提升LVLMs对抗复杂跨模态威胁的鲁棒性。

Conclusion: VisuoAlign框架有效解决了多模态安全对齐的关键挑战，为LVLMs的安全部署提供了可靠保障。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable progress in
multimodal perception and generation, yet their safety alignment remains a
critical challenge.Existing defenses and vulnerable to multimodal jailbreaks,
as visual inputs introduce new attack surfaces, reasoning chains lack safety
supervision, and alignment often degrades under modality fusion.To overcome
these limitation, we propose VisuoAlign, a framework for multi-modal safety
alignment via prompt-guided tree search.VisuoAlign embeds safety constrains
into the reasoning process through visual-textual interactive prompts, employs
Monte Carlo Tree Search(MCTS) to systematically construct diverse
safety-critical prompt trajectories, and introduces prompt-based scaling to
ensure real-time risk detection and compliant responses.Extensive experiments
demonstrate that VisuoAlign proactively exposes risks, enables comprehensive
dataset generation, and significantly improves the robustness of LVLMs against
complex cross-modal threats.

</details>


### [10] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 本文提出了结构化认知循环（SCL）作为可执行的认知框架，将哲学洞见转化为可计算结构，重新定义智能为通过意向性理解重建自身认知状态的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型缺乏真正的认知理解，暴露了认知架构的缺失。传统AI研究关注"什么是智能"的本体论问题，而SCL关注"在什么条件下认知涌现"的认知论问题。

Method: 基于心智哲学和认知现象学，结合过程哲学、具身认知和扩展心智理论，将智能定义为执行过程——判断、记忆、控制、行动和调节的连续循环。

Result: SCL实现了三个贡献：将哲学洞见操作化为可计算结构；证明认知架构中的功能分离比单一提示系统产生更一致和可解释的行为；重新定义智能为重建自身认知状态的能力。

Conclusion: 真正的进步不在于更大的模型，而在于结构上实现认知原则的架构。该框架对心智哲学、认识论和AI都有重要影响，将知识视为在现象学一致循环内的持续重建。

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [11] [Exploring the Potential of Citiverses for Regulatory Learning](https://arxiv.org/abs/2510.15959)
*Isabelle Hupont,Marisa Ponti,Sven Schade*

Main category: cs.AI

TL;DR: 本文提出将citiverses（城市虚拟世界）作为监管学习实验空间的科学政策议程，通过专家咨询识别关键研究领域和实验主题，强调负责任的发展方法。


<details>
  <summary>Details</summary>
Motivation: 探索citiverses作为沉浸式虚拟环境在监管学习中的潜力，为政策制定提供实验空间，支持复杂政策场景和技术的测试。

Method: 基于与欧盟委员会政策制定者、国家政府科学顾问和数字监管领域领先研究者的高层专家咨询，识别关键研究领域和实验主题。

Result: 确定了可扩展性、实时反馈、复杂性建模、跨境合作、风险降低、公民参与、伦理考量和新兴技术整合等关键研究领域，以及交通、城市规划、环境/气候危机等实验主题。

Conclusion: citiverses有潜力成为监管学习的重要实验空间，但需要负责任的发展方法，充分考虑伦理、经济、生态和社会维度，并整合到更广泛的实验生态系统。

Abstract: Citiverses hold the potential to support regulatory learning by offering
immersive, virtual environments for experimenting with policy scenarios and
technologies. This paper proposes a science-for-policy agenda to explore the
potential of citiverses as experimentation spaces for regulatory learning,
grounded in a consultation with a high-level panel of experts, including
policymakers from the European Commission, national government science advisers
and leading researchers in digital regulation and virtual worlds. It identifies
key research areas, including scalability, real-time feedback, complexity
modelling, cross-border collaboration, risk reduction, citizen participation,
ethical considerations and the integration of emerging technologies. In
addition, the paper analyses a set of experimental topics, spanning
transportation, urban planning and the environment/climate crisis, that could
be tested in citiverse platforms to advance regulatory learning in these areas.
The proposed work is designed to inform future research for policy and
emphasizes a responsible approach to developing and using citiverses. It
prioritizes careful consideration of the ethical, economic, ecological and
social dimensions of different regulations. The paper also explores essential
preliminary steps necessary for integrating citiverses into the broader
ecosystems of experimentation spaces, including test beds, living labs and
regulatory sandboxes

</details>


### [12] [PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency](https://arxiv.org/abs/2510.15966)
*Shian Jia,Ziyang Huang,Xinbo Wang,Haofei Zhang,Mingli Song*

Main category: cs.AI

TL;DR: PISA是一个受皮亚杰认知发展理论启发的统一记忆系统，通过三模式适应机制和混合记忆访问架构，显著提升了AI代理的适应性和长期知识保留能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理记忆系统缺乏对多样化任务的适应性，且忽视了记忆的建构性和任务导向作用。

Method: 提出三模式适应机制（图式更新、图式演化和图式创建）和混合记忆访问架构，结合符号推理与神经检索。

Result: 在LOCOMO基准和新提出的AggQA基准上，PISA实现了最先进的性能，显著提升了适应性和长期知识保留。

Conclusion: PISA通过将记忆视为建构性和适应性过程，为AI代理记忆系统提供了更有效的解决方案。

Abstract: Memory systems are fundamental to AI agents, yet existing work often lacks
adaptability to diverse tasks and overlooks the constructive and task-oriented
role of AI agent memory. Drawing from Piaget's theory of cognitive development,
we propose PISA, a pragmatic, psych-inspired unified memory system that
addresses these limitations by treating memory as a constructive and adaptive
process. To enable continuous learning and adaptability, PISA introduces a
trimodal adaptation mechanism (i.e., schema updation, schema evolution, and
schema creation) that preserves coherent organization while supporting flexible
memory updates. Building on these schema-grounded structures, we further design
a hybrid memory access architecture that seamlessly integrates symbolic
reasoning with neural retrieval, significantly improving retrieval accuracy and
efficiency. Our empirical evaluation, conducted on the existing LOCOMO
benchmark and our newly proposed AggQA benchmark for data analysis tasks,
confirms that PISA sets a new state-of-the-art by significantly enhancing
adaptability and long-term knowledge retention.

</details>


### [13] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 研究发现，即使为大型语言模型提供环境接口来跟踪状态空间，也无法避免其在解决复杂谜题时出现性能崩溃现象。模型在复杂度增加时会偏离最优策略和随机策略，表现出模式崩溃。


<details>
  <summary>Details</summary>
Motivation: 针对大型推理模型在解决复杂谜题时出现性能崩溃的现象，研究者想探究这是否与模型需要自行跟踪状态空间有关，因此通过提供环境接口来测试这一假设。

Method: 为LLM提供河内塔问题的环境接口，允许模型通过工具调用进行移动、提供书面理由、观察结果状态空间，并自我提示进行下一步移动。

Result: 环境接口的接入并不能延迟或消除性能崩溃。策略分析显示模型在复杂度增加时偏离最优策略和随机策略，表现出模式崩溃。

Conclusion: 性能崩溃现象与环境接口无关，模型在复杂度增加时会陷入特定的错误模式。这一现象可能在大型推理模型中普遍存在。

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [14] [Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition](https://arxiv.org/abs/2510.15980)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: 提出了认知负荷痕迹（CLTs）作为深度模型的中层可解释性框架，通过符号化、时变函数量化模型内部资源分配，包含内在、外在和关联负荷三个分量，能够预测错误发生、揭示认知策略，并通过负荷引导干预提高推理效率15-30%。


<details>
  <summary>Details</summary>
Motivation: 受人类认知中的认知负荷理论启发，旨在为深度模型提供中层可解释性框架，以理解模型内部推理过程中的资源分配动态。

Method: 将CLTs定义为三分量随机过程（内在负荷、外在负荷、关联负荷），通过注意力熵、KV缓存未命中率、表示分散度和解码稳定性等可测量代理进行实例化，并提出符号化公式和可视化方法（负荷曲线、单纯形图）。

Result: 在推理和规划基准测试中，CLTs能够预测错误发生、揭示认知策略，通过负荷引导干预在保持准确性的同时将推理效率提高15-30%。

Conclusion: CLTs为深度模型提供了有效的可解释性框架，能够量化分析推理动态，并通过负荷引导优化显著提升模型效率。

Abstract: We propose \textbf{Cognitive Load Traces} (CLTs) as a mid-level
interpretability framework for deep models, inspired by Cognitive Load Theory
in human cognition. CLTs are defined as symbolic, temporally varying functions
that quantify model-internal resource allocation. Formally, we represent CLTs
as a three-component stochastic process $(\mathrm{IL}_t, \mathrm{EL}_t,
\mathrm{GL}_t)$, corresponding to \emph{Intrinsic}, \emph{Extraneous}, and
\emph{Germane} load. Each component is instantiated through measurable proxies
such as attention entropy, KV-cache miss ratio, representation dispersion, and
decoding stability. We propose both symbolic formulations and visualization
methods (load curves, simplex diagrams) that enable interpretable analysis of
reasoning dynamics. Experiments on reasoning and planning benchmarks show that
CLTs predict error-onset, reveal cognitive strategies, and enable load-guided
interventions that improve reasoning efficiency by 15-30\% while maintaining
accuracy.

</details>


### [15] [ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization](https://arxiv.org/abs/2510.15981)
*Rafael Cabral,Tuan Manh Do,Xuejun Yu,Wai Ming Tai,Zijin Feng,Xin Shen*

Main category: cs.AI

TL;DR: ProofFlow是一个新颖的自动形式化证明管道，通过构建逻辑依赖图和使用基于引理的方法来保持证明的结构保真度，在自动形式化任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动形式化方法虽然能生成可执行代码，但经常无法保持原始证明的语义含义和逻辑结构，这限制了大型语言模型在严谨数学工作流程中的集成。

Method: ProofFlow首先构建有向无环图来映射证明步骤间的逻辑依赖关系，然后采用基于引理的方法系统地将每个步骤形式化为中间引理，从而保持原始论证的逻辑结构。

Result: 实验结果显示ProofFlow在自动形式化方面达到了新的最先进水平，ProofScore得分为0.545，显著优于完整证明形式化(0.123)和步骤证明形式化(0.072)等基线方法。

Conclusion: ProofFlow通过关注结构保真度显著提升了自动形式化性能，提出的新基准和评估指标为未来研究提供了基础。

Abstract: Proof autoformalization, the task of translating natural language theorems
and proofs into machine-verifiable code, is a critical step for integrating
large language models into rigorous mathematical workflows. Current approaches
focus on producing executable code, but they frequently fail to preserve the
semantic meaning and logical structure of the original human-written argument.
To address this, we introduce ProofFlow, a novel pipeline that treats
structural fidelity as a primary objective. ProofFlow first constructs a
directed acyclic graph (DAG) to map the logical dependencies between proof
steps. Then, it employs a novel lemma-based approach to systematically
formalize each step as an intermediate lemma, preserving the logical structure
of the original argument. To facilitate evaluation, we present a new benchmark
of 184 undergraduate-level problems, manually annotated with step-by-step
solutions and logical dependency graphs, and introduce ProofScore, a new
composite metric to evaluate syntactic correctness, semantic faithfulness, and
structural fidelity. Experimental results show our pipeline sets a new
state-of-the-art for autoformalization, achieving a ProofScore of 0.545,
substantially exceeding baselines like full-proof formalization (0.123), which
processes the entire proof at once, and step-proof formalization (0.072), which
handles each step independently. Our pipeline, benchmark, and score metric are
open-sourced to encourage further progress at
https://github.com/Huawei-AI4Math/ProofFlow.

</details>


### [16] [Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science](https://arxiv.org/abs/2510.15983)
*Sarah Rebecca Ondraszek,Jörg Waitelonis,Katja Keller,Claudia Niessner,Anna M. Jacyszyn,Harald Sack*

Main category: cs.AI

TL;DR: 提出将MO|RE运动研究数据仓库转换为基于基本形式本体的知识图谱，以标准化和机器可理解的方式建模和共享运动表现数据。


<details>
  <summary>Details</summary>
Motivation: 运动表现测试是评估和比较不同人群身体和认知能力的关键，需要标准化的数据建模和共享方法来支持跨研究比较。

Method: 开发基于基本形式本体(BFO)的本体，正式表示计划规范、具体过程和相关测量之间的相互关系，将MO|RE数据仓库转换为知识图谱。

Result: 提出了一个将运动表现研究数据转换为标准化知识图谱的框架，使数据能够跨研究标准化和机器理解。

Conclusion: 通过知识图谱方法可以改变运动表现数据的建模和共享方式，实现数据的标准化和机器可理解性，促进跨研究比较。

Abstract: An essential component for evaluating and comparing physical and cognitive
capabilities between populations is the testing of various factors related to
human performance. As a core part of sports science research, testing motor
performance enables the analysis of the physical health of different
demographic groups and makes them comparable.
  The Motor Research (MO|RE) data repository, developed at the Karlsruhe
Institute of Technology, is an infrastructure for publishing and archiving
research data in sports science, particularly in the field of motor performance
research. In this paper, we present our vision for creating a knowledge graph
from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our
approach centers on formally representing the interrelation of plan
specifications, specific processes, and related measurements. Our goal is to
transform how motor performance data are modeled and shared across studies,
making it standardized and machine-understandable. The idea presented here is
developed within the Leibniz Science Campus ``Digital Transformation of
Research'' (DiTraRe).

</details>


### [17] [A Non-overlap-based Conflict Measure for Random Permutation Sets](https://arxiv.org/abs/2510.16001)
*Ruolan Cheng,Yong Deng,Enrique Herrera-Viedma*

Main category: cs.AI

TL;DR: 本文提出了一种基于随机置换集(RPS)的冲突度量方法，从随机有限集(RFS)和Dempster-Shafer理论(DST)两个角度分析RPS中的冲突，并引入基于秩偏重叠(RBO)的不一致性度量。


<details>
  <summary>Details</summary>
Motivation: 在涉及顺序信息的不确定性推理中，如何度量由置换质量函数表示的两个证据之间的冲突是一个紧迫的研究课题，需要为有序结构的不确定信息融合提供有效的冲突度量方法。

Method: 从置换观察出发，首先基于秩偏重叠(RBO)度量定义置换间的不一致性度量，然后提出基于非重叠的RPS冲突度量方法，将RPS理论视为DST的扩展。

Result: 通过数值示例展示了所提冲突度量的行为和特性，该方法不仅具有自然的顶部加权特性，还能从DST角度有效度量RPS间的冲突。

Conclusion: 所提出的方法为决策者提供了权重、参数和截断深度的灵活选择，能够有效处理有序结构不确定信息中的冲突度量问题。

Abstract: Random permutation set (RPS) is a new formalism for reasoning with
uncertainty involving order information. Measuring the conflict between two
pieces of evidence represented by permutation mass functions remains an urgent
research topic in order-structured uncertain information fusion. In this paper,
a detailed analysis of conflicts in RPS is carried out from two different
perspectives: random finite set (RFS) and Dempster-Shafer theory (DST).
Starting from the observation of permutations, we first define an inconsistency
measure between permutations inspired by the rank-biased overlap(RBO) measure
and further propose a non-overlap-based conflict measure method for RPSs. This
paper regards RPS theory (RPST) as an extension of DST. The order information
newly added in focal sets indicates qualitative propensity, characterized by
top-ranked elements occupying a more critical position. Some numerical examples
are used to demonstrate the behavior and properties of the proposed conflict
measure. The proposed method not only has the natural top-weightedness property
and can effectively measure the conflict between RPSs from the DST view but
also provides decision-makers with a flexible selection of weights, parameters,
and truncated depths.

</details>


### [18] [PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction](https://arxiv.org/abs/2510.16004)
*Andreas Radler,Vincent Seyfried,Stefan Pirker,Johannes Brandstetter,Thomas Lichtenegger*

Main category: cs.AI

TL;DR: PAINT是一种用于建模动态系统的并行时间神经孪生方法，通过生成神经网络并行建模状态分布，能够在测试时从稀疏测量中准确预测系统状态并保持轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有神经代理在模拟动态系统时具有实时能力，但需要进一步发展神经孪生来创建真实系统的数字副本，实现上下文特定的决策制定。

Method: PAINT训练生成神经网络并行建模时间上的状态分布，在测试时通过滑动窗口方式从测量中预测状态。

Result: 在二维湍流流体动力学问题上，PAINT能够保持轨迹跟踪，从稀疏测量中高保真地预测系统状态。

Conclusion: PAINT具有开发保持轨迹跟踪的神经孪生的潜力，能够实现更准确的状态估计和决策制定。

Abstract: Neural surrogates have shown great potential in simulating dynamical systems,
while offering real-time capabilities. We envision Neural Twins as a
progression of neural surrogates, aiming to create digital replicas of real
systems. A neural twin consumes measurements at test time to update its state,
thereby enabling context-specific decision-making. A critical property of
neural twins is their ability to remain on-trajectory, i.e., to stay close to
the true system state over time. We introduce Parallel-in-time Neural Twins
(PAINT), an architecture-agnostic family of methods for modeling dynamical
systems from measurements. PAINT trains a generative neural network to model
the distribution of states parallel over time. At test time, states are
predicted from measurements in a sliding window fashion. Our theoretical
analysis shows that PAINT is on-trajectory, whereas autoregressive models
generally are not. Empirically, we evaluate our method on a challenging
two-dimensional turbulent fluid dynamics problem. The results demonstrate that
PAINT stays on-trajectory and predicts system states from sparse measurements
with high fidelity. These findings underscore PAINT's potential for developing
neural twins that stay on-trajectory, enabling more accurate state estimation
and decision-making.

</details>


### [19] [Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis](https://arxiv.org/abs/2510.16033)
*Junyu Ren,Wensheng Gan,Guangyu Zhang,Wei Zhong,Philip S. Yu*

Main category: cs.AI

TL;DR: 提出ISGFAN框架，通过信息分离和全局-局部对抗学习解决噪声干扰和域偏移共存下的跨域故障诊断问题


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法假设数据干净或域相似性足够，但在工业环境中严重噪声干扰和域偏移同时存在，限制了方法的有效性

Method: 基于信息分离架构，结合对抗学习和改进的正交损失来解耦域不变故障表示；采用全局-局部域对抗方案约束模型的边缘分布和条件分布

Result: 在三个公共基准数据集上的实验表明，该方法优于其他现有方法

Conclusion: ISGFAN框架在噪声条件下的跨域故障诊断中表现出优越性

Abstract: Existing transfer fault diagnosis methods typically assume either clean data
or sufficient domain similarity, which limits their effectiveness in industrial
environments where severe noise interference and domain shifts coexist. To
address this challenge, we propose an information separation global-focal
adversarial network (ISGFAN), a robust framework for cross-domain fault
diagnosis under noise conditions. ISGFAN is built on an information separation
architecture that integrates adversarial learning with an improved orthogonal
loss to decouple domain-invariant fault representation, thereby isolating noise
interference and domain-specific characteristics. To further strengthen
transfer robustness, ISGFAN employs a global-focal domain-adversarial scheme
that constrains both the conditional and marginal distributions of the model.
Specifically, the focal domain-adversarial component mitigates
category-specific transfer obstacles caused by noise in unsupervised scenarios,
while the global domain classifier ensures alignment of the overall
distribution. Experiments conducted on three public benchmark datasets
demonstrate that the proposed method outperforms other prominent existing
approaches, confirming the superiority of the ISGFAN framework. Data and code
are available at https://github.com/JYREN-Source/ISGFAN

</details>


### [20] [Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks](https://arxiv.org/abs/2510.16047)
*Ioan Hedea*

Main category: cs.AI

TL;DR: 该论文提出了一种结合离线约束编程优化和在线时间网络执行的混合调度方法，能够在最坏情况不确定性下保持调度可行性，完全消除截止时间违规，同时仅增加3-5%的制造周期开销。


<details>
  <summary>Details</summary>
Motivation: 现代制造系统需要满足严格的交付截止时间，同时应对由过程噪声、设备变异性和人为干预引起的随机任务持续时间。传统的确定性调度在现实偏离名义计划时会失效，导致昂贵的最后一分钟修复。

Method: 首先构建具有每任务截止时间的柔性作业车间约束编程模型，并插入最优缓冲区Δ*获得完全主动基线。然后将结果计划转换为具有不确定性的简单时间网络，验证动态可控性，确保实时调度器能够为每个有界持续时间实现重新安排活动时间，而不违反资源或截止时间约束。

Result: 在Kacem 1-4基准套件上的广泛蒙特卡洛模拟显示，该混合方法消除了最先进元启发式调度中观察到的100%截止时间违规，同时仅增加3-5%的制造周期开销。可扩展性实验证实，在中等规模实例上，CP求解时间和STNU检查保持在亚秒级。

Conclusion: 这项工作展示了时间网络推理如何弥合主动缓冲和动态鲁棒性之间的差距，使工业向真正的数字化、自校正工厂迈进了一步。

Abstract: Modern manufacturing systems must meet hard delivery deadlines while coping
with stochastic task durations caused by process noise, equipment variability,
and human intervention. Traditional deterministic schedules break down when
reality deviates from nominal plans, triggering costly last-minute repairs.
This thesis combines offline constraint-programming (CP) optimisation with
online temporal-network execution to create schedules that remain feasible
under worst-case uncertainty. First, we build a CP model of the flexible
job-shop with per-job deadline tasks and insert an optimal buffer $\Delta^*$ to
obtain a fully pro-active baseline. We then translate the resulting plan into a
Simple Temporal Network with Uncertainty (STNU) and verify dynamic
controllability, which guarantees that a real-time dispatcher can retime
activities for every bounded duration realisation without violating resource or
deadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4
benchmark suite show that our hybrid approach eliminates 100\% of deadline
violations observed in state-of-the-art meta-heuristic schedules, while adding
only 3--5\% makespan overhead. Scalability experiments confirm that CP
solve-times and STNU checks remain sub-second on medium-size instances. The
work demonstrates how temporal-network reasoning can bridge the gap between
proactive buffering and dynamic robustness, moving industry a step closer to
truly digital, self-correcting factories.

</details>


### [21] [Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study](https://arxiv.org/abs/2510.16095)
*Dou Liu,Ying Long,Sophia Zuoqiu,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.AI

TL;DR: 本研究评估了LLM生成的临床思维链的可靠性，发现选择性少样本策略显著优于零样本和随机少样本策略，提出了基于"黄金标准深度"和"代表性多样性"的双原则框架。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺，创建高质量的临床思维链对于可解释医疗AI至关重要，但LLM生成的临床数据可靠性尚未得到验证。

Method: 在辅助生殖技术领域进行盲法比较研究，资深临床医生评估三种策略生成的思维链：零样本、随机少样本和选择性少样本，并与GPT-4o的评估结果对比。

Result: 选择性少样本策略在所有人类评估指标上显著优于其他策略，而随机少样本策略相比零样本基线无显著改进。AI评估器未能识别这些关键性能差异。

Conclusion: 合成思维链的临床可靠性取决于策略性提示词设计而非示例数量，提出了"双原则"框架作为生成可信数据的基础方法，确认了人类专业知识在高风险临床AI评估中的不可或缺作用。

Abstract: Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for
explainable medical Artificial Intelligence (AI) while constrained by data
scarcity. Although Large Language Models (LLMs) can synthesize medical data,
their clinical reliability remains unverified. This study evaluates the
reliability of LLM-generated CoTs and investigates prompting strategies to
enhance their quality. In a blinded comparative study, senior clinicians in
Assisted Reproductive Technology (ART) evaluated CoTs generated via three
distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and
Selective Few-shot (using diverse, high-quality examples). These expert ratings
were compared against evaluations from a state-of-the-art AI model (GPT-4o).
The Selective Few-shot strategy significantly outperformed other strategies
across all human evaluation metrics (p < .001). Critically, the Random Few-shot
strategy offered no significant improvement over the Zero-shot baseline,
demonstrating that low-quality examples are as ineffective as no examples. The
success of the Selective strategy is attributed to two principles:
"Gold-Standard Depth" (reasoning quality) and "Representative Diversity"
(generalization). Notably, the AI evaluator failed to discern these critical
performance differences. The clinical reliability of synthetic CoTs is dictated
by strategic prompt curation, not the mere presence of examples. We propose a
"Dual Principles" framework as a foundational methodology to generate
trustworthy data at scale. This work offers a validated solution to the data
bottleneck and confirms the indispensable role of human expertise in evaluating
high-stakes clinical AI.

</details>


### [22] [Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability](https://arxiv.org/abs/2510.16193)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文提出了一种基于扩展认知理论的形式化模型，将企业知识重新定义为可测量的动态能力，通过信息访问程序的效率和输出可靠性来量化企业知识状态。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在企业决策中的中介作用日益增强，传统的基于人类代理的企业犯罪意图归责假设面临挑战，需要重新定义企业知识的概念。

Method: 开发了一个形式化模型，引入连续的组织知识度量S_S(φ)，整合管道的计算成本和统计验证的错误率，推导出阈值知识谓词K_S和企业范围认知能力指数K_{S,t}。

Result: 将定量指标映射到实际知识、推定知识、故意无视和鲁莽等法律标准，为创建可测量和可司法审计的人工制品提供了途径。

Conclusion: 这项工作为在算法时代使企业思维变得可处理和可问责提供了路径，使企业心智在法律上可追踪。

Abstract: Corporate responsibility turns on notions of corporate \textit{mens rea},
traditionally imputed from human agents. Yet these assumptions are under
challenge as generative AI increasingly mediates enterprise decision-making.
Building on the theory of extended cognition, we argue that in response
corporate knowledge may be redefined as a dynamic capability, measurable by the
efficiency of its information-access procedures and the validated reliability
of their outputs. We develop a formal model that captures epistemic states of
corporations deploying sophisticated AI or information systems, introducing a
continuous organisational knowledge metric $S_S(\varphi)$ which integrates a
pipeline's computational cost and its statistically validated error rate. We
derive a thresholded knowledge predicate $\mathsf{K}_S$ to impute knowledge and
a firm-wide epistemic capacity index $\mathcal{K}_{S,t}$ to measure overall
capability. We then operationally map these quantitative metrics onto the legal
standards of actual knowledge, constructive knowledge, wilful blindness, and
recklessness. Our work provides a pathway towards creating measurable and
justiciable audit artefacts, that render the corporate mind tractable and
accountable in the algorithmic age.

</details>


### [23] [Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration](https://arxiv.org/abs/2510.16194)
*Guanchen Wu,Zuhui Chen,Yuzhang Xie,Carl Yang*

Main category: cs.AI

TL;DR: TEAM-PHI是一个使用大语言模型自动评估PHI去标识化质量的多智能体框架，通过多数投票机制选择最佳模型，无需依赖大量黄金标准标注。


<details>
  <summary>Details</summary>
Motivation: PHI去标识化对于临床笔记的安全重用至关重要，但传统评估依赖昂贵的小规模专家标注，需要更高效、低成本的自动评估方法。

Method: 部署多个评估智能体独立判断PHI提取正确性，通过LLM多数投票机制整合不同评估者观点，生成稳定可复现的排名。

Result: 在真实临床笔记语料上的实验表明，TEAM-PHI产生一致准确的排名，LLM投票可靠地收敛于相同的最佳系统，与人工评估结果高度一致。

Conclusion: TEAM-PHI通过结合独立评估智能体和LLM多数投票，为PHI去标识化提供了实用、安全且经济高效的自动评估和最佳模型选择方案。

Abstract: Protected health information (PHI) de-identification is critical for enabling
the safe reuse of clinical notes, yet evaluating and comparing PHI
de-identification models typically depends on costly, small-scale expert
annotations. We present TEAM-PHI, a multi-agent evaluation and selection
framework that uses large language models (LLMs) to automatically measure
de-identification quality and select the best-performing model without heavy
reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each
independently judging the correctness of PHI extractions and outputting
structured metrics. Their results are then consolidated through an LLM-based
majority voting mechanism that integrates diverse evaluator perspectives into a
single, stable, and reproducible ranking. Experiments on a real-world clinical
note corpus demonstrate that TEAM-PHI produces consistent and accurate
rankings: despite variation across individual evaluators, LLM-based voting
reliably converges on the same top-performing systems. Further comparison with
ground-truth annotations and human evaluation confirms that the framework's
automated rankings closely match supervised evaluation. By combining
independent evaluation agents with LLM majority voting, TEAM-PHI offers a
practical, secure, and cost-effective solution for automatic evaluation and
best-model selection in PHI de-identification, even when ground-truth labels
are limited.

</details>


### [24] [The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI](https://arxiv.org/abs/2510.16206)
*Alex Zhavoronkov,Dominika Wilczok,Roman Yampolskiy*

Main category: cs.AI

TL;DR: 论文提出了"被记住权"概念，旨在解决大型语言模型在信息检索中可能导致的偏见、信息遗漏和集体记忆重塑问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在信息检索中的广泛应用，传统搜索引擎的多元化结果被单一权威性回答取代，可能导致某些群体和观点被系统性地忽视或放大，威胁信息多样性和集体记忆。

Method: 提出"被记住权"框架，包含三个核心要素：最小化AI驱动信息遗漏风险、保障公平对待权利、确保生成内容最大程度真实。

Result: 建立了应对AI信息检索系统潜在偏见的理论框架，为保护数字弱势群体和维持信息多样性提供了概念基础。

Conclusion: "被记住权"是应对大型语言模型信息检索系统潜在风险的重要概念，需要在AI发展中平衡信息权威性与多样性，保护集体记忆免受技术偏见影响。

Abstract: Since the rapid expansion of large language models (LLMs), people have begun
to rely on them for information retrieval. While traditional search engines
display ranked lists of sources shaped by search engine optimization (SEO),
advertising, and personalization, LLMs typically provide a synthesized response
that feels singular and authoritative. While both approaches carry risks of
bias and omission, LLMs may amplify the effect by collapsing multiple
perspectives into one answer, reducing users ability or inclination to compare
alternatives. This concentrates power over information in a few LLM vendors
whose systems effectively shape what is remembered and what is overlooked. As a
result, certain narratives, individuals or groups, may be disproportionately
suppressed, while others are disproportionately elevated. Over time, this
creates a new threat: the gradual erasure of those with limited digital
presence, and the amplification of those already prominent, reshaping
collective memory.To address these concerns, this paper presents a concept of
the Right To Be Remembered (RTBR) which encompasses minimizing the risk of
AI-driven information omission, embracing the right of fair treatment, while
ensuring that the generated content would be maximally truthful.

</details>


### [25] [ScholarEval: Research Idea Evaluation Grounded in Literature](https://arxiv.org/abs/2510.16234)
*Hanane Nour Moussa,Patrick Queiroz Da Silva,Daniel Adu-Ampratwum,Alyson East,Zitong Lu,Nikki Puccetti,Mingyi Xue,Huan Sun,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.AI

TL;DR: ScholarEval是一个检索增强的评估框架，用于评估AI生成的研究想法，基于两个标准：soundness（基于现有文献的方法有效性）和contribution（相对于先前研究的创新程度）。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在研究构思中日益普及，需要强大的评估方法来确保生成想法的有效性和实用性。

Method: 引入ScholarEval框架，使用检索增强方法评估研究想法；创建ScholarIdeas数据集，包含117个跨学科专家标注的研究想法和评论。

Result: ScholarEval在专家标注标准覆盖方面显著优于所有基线方法，在评估可操作性、深度和证据支持方面持续优于OpenAI的o4-mini-deep-research系统；大规模用户研究显示在文献参与、想法精炼和实用性方面显著优于深度研究。

Conclusion: ScholarEval为AI生成研究想法的评估提供了有效框架，代码、数据集和工具已开源供社区使用。

Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

</details>


### [26] [Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense](https://arxiv.org/abs/2510.16259)
*Zhehao Zhang,Weijie Xu,Shixian Cui,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 论文识别并分析了大型推理模型(LRMs)中的"推理分心"漏洞，即模型被恶意嵌入的复杂无关任务分散注意力，导致主要任务准确率下降高达60%。作者提出了一种结合监督微调和强化学习的训练防御方法，可将鲁棒性提高50多个点。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型在数学和编程等复杂任务上表现出色，作者发现这些模型存在一个关键漏洞：容易被恶意嵌入的无关复杂任务分散注意力，从而偏离主要目标。这种"推理分心"威胁到LRM的可靠性。

Method: 通过跨多种模型和基准的综合研究，分析推理分心漏洞。提出基于训练的防御方法，结合监督微调(SFT)和强化学习(RL)，在合成的对抗数据上进行训练。

Result: 研究表明，即使最先进的LRM也高度易受攻击，注入的分心任务可使任务准确率降低高达60%。某些对齐技术会放大这种弱点，模型可能表现出隐蔽服从行为。提出的防御方法可将鲁棒性提高50多个点。

Conclusion: 推理分心是LRM可靠性面临的独特且紧迫的威胁。研究结果为构建更安全、更可信的推理系统提供了实用步骤，强调了需要增强模型对恶意分心任务的抵抗力。

Abstract: Recent advances in large reasoning models (LRMs) have enabled remarkable
performance on complex tasks such as mathematics and coding by generating long
Chain-of-Thought (CoT) traces. In this paper, we identify and systematically
analyze a critical vulnerability we term reasoning distraction, where LRMs are
diverted from their primary objective by irrelevant yet complex tasks
maliciously embedded in the prompt. Through a comprehensive study across
diverse models and benchmarks, we show that even state-of-the-art LRMs are
highly susceptible, with injected distractors reducing task accuracy by up to
60%. We further reveal that certain alignment techniques can amplify this
weakness and that models may exhibit covert compliance, following hidden
adversarial instructions in reasoning while concealing them in the final
output. To mitigate these risks, we propose a training-based defense that
combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on
synthetic adversarial data, improving robustness by over 50 points on
challenging distractor attacks. Our findings establish reasoning distraction as
a distinct and urgent threat to LRM reliability and provide a practical step
toward safer and more trustworthy reasoning systems.

</details>


### [27] [What Limits Agentic Systems Efficiency?](https://arxiv.org/abs/2510.16276)
*Song Bian,Minghao Yan,Anand Jayarajan,Gennady Pekhimenko,Shivaram Venkataraman*

Main category: cs.AI

TL;DR: 本文通过实证研究发现网络交互式智能体系统存在效率瓶颈，提出SpecCache缓存框架结合推测执行来降低网络环境延迟，提升系统效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注智能体系统的推理性能，但忽视了系统效率问题。网络交互式智能体系统存在显著的延迟瓶颈，影响实际应用效果。

Method: 将端到端延迟分解为LLM API延迟和网络环境延迟两部分，通过15个模型和5个提供商进行实证研究，提出SpecCache缓存框架结合推测执行来优化延迟。

Result: 网络环境延迟可占总体延迟的53.7%，SpecCache相比随机缓存策略将缓存命中率提升58倍，网络环境开销降低3.2倍，且不损害系统性能。

Conclusion: 智能体系统的效率优化至关重要，SpecCache框架能有效降低网络环境延迟，为构建高效网络交互式智能体系统提供了实用解决方案。

Abstract: Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have
demonstrated strong reasoning capabilities. To further enhance LLM
capabilities, recent agentic systems, such as Deep Research, incorporate web
interactions into LLM reasoning to mitigate uncertainties and reduce potential
errors. However, existing research predominantly focuses on reasoning
performance, often neglecting the efficiency of agentic systems. In this work,
we present a comprehensive empirical study that identifies efficiency
bottlenecks in web-interactive agentic systems. We decompose end-to-end latency
into two primary components: LLM API latency and web environment latency. We
conduct a comprehensive empirical study across 15 models and 5 providers to
demonstrate high variability in API-based agentic systems. We observe that web
environment latency can contribute as much as 53.7% to the overall latency in a
web-based agentic system. To improve latency, we propose SpecCache, a caching
framework augmented with speculative execution that can reduce web environment
overhead. Extensive evaluations on two standard benchmarks show that our
approach improves the cache hit rate by up to 58x compared to a random caching
strategy, while reducing web environment overhead by up to 3.2x, without
degrading agentic system performance.

</details>


### [28] [DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA](https://arxiv.org/abs/2510.16302)
*Changhao Wang,Yanfang Liu,Xinxin Fan,Anzhi Zhou,Lao Tian,Yunfeng Lu*

Main category: cs.AI

TL;DR: 提出DTKG框架，结合知识图谱路径构建和LLM事实验证，解决多跳推理问答中的效率和准确性问题


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理并行事实验证和链式多跳推理时各有局限：LLM验证擅长并行验证但不擅长链式推理，KG路径构建擅长链式推理但在并行验证时存在冗余路径检索问题

Method: 基于认知科学双过程理论的双轨KG验证推理框架DTKG，包含分类阶段和分支处理阶段

Result: 未在摘要中明确说明

Conclusion: DTKG框架能够有效解决多跳推理问答中的效率和准确性问题

Abstract: Multi-hop reasoning for question answering (QA) plays a critical role in
retrieval-augmented generation (RAG) for modern large language models (LLMs).
The accurate answer can be obtained through retrieving relational structure of
entities from knowledge graph (KG). Regarding the inherent relation-dependency
and reasoning pattern, multi-hop reasoning can be in general classified into
two categories: i) parallel fact-verification multi-hop reasoning question,
i.e., requiring simultaneous verifications of multiple independent
sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding
sequential multi-step inference with intermediate conclusions serving as
essential premises for subsequent reasoning. Currently, the multi-hop reasoning
approaches singly employ one of two techniques: LLM response-based fact
verification and KG path-based chain construction. Nevertheless, the former
excels at parallel fact-verification but underperforms on chained reasoning
tasks, while the latter demonstrates proficiency in chained multi-hop reasoning
but suffers from redundant path retrieval when handling parallel
fact-verification reasoning. These limitations deteriorate the efficiency and
accuracy for multi-hop QA tasks. To address this challenge, we propose a novel
dual-track KG verification and reasoning framework DTKG, which is inspired by
the Dual Process Theory in cognitive science. Specifically, DTKG comprises two
main stages: the Classification Stage and the Branch Processing Stage.

</details>


### [29] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier](https://arxiv.org/abs/2510.16309)
*Crystal Su*

Main category: cs.AI

TL;DR: MedRule-KG是一个紧凑的带类型知识图谱，结合符号验证器，用于在推理任务中强制执行数学可解释规则，显著提高准确率并消除规则违反。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常产生流畅的推理步骤，但违反简单的数学或逻辑约束，需要一种方法来确保推理的数学一致性。

Method: 引入MedRule-KG知识图谱编码实体、关系和三个领域启发规则，配合符号验证器检查预测并应用最小修正以保证一致性。

Result: 在90个FDA衍生基准测试中，使用MedRule-KG将精确匹配从0.767提高到0.900，加上验证器后达到1.000精确匹配并完全消除规则违反。

Conclusion: MedRule-KG为安全数学推理提供了通用框架，通过知识图谱和符号验证确保推理的数学一致性。

Abstract: Large language models (LLMs) often produce fluent reasoning steps while
violating simple mathematical or logical constraints. We introduce MedRule-KG,
a compact typed knowledge graph coupled with a symbolic verifier, designed to
enforce mathematically interpretable rules in reasoning tasks. MedRule-KG
encodes entities, relations, and three domain-inspired rules, while the
verifier checks predictions and applies minimal corrections to guarantee
consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG
improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields
1.000 EM while eliminating rule violations entirely. We demonstrate how
MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss
ablations, and release code and data to encourage reproducibility.

</details>


### [30] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: 提出了SELECT框架，通过动态锚点选择解决文本到图像扩散模型中概念擦除的锚点敏感性问题，克服固定锚点策略导致的概念重现和侵蚀问题。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法依赖固定锚点策略，存在概念重现和侵蚀等关键问题，需要解决锚点选择对擦除效果的敏感性。

Method: 通过因果追踪揭示擦除对锚点选择的敏感性，定义兄弟排他概念作为更优锚点类别，提出两阶段评估机制自动发现最优锚点进行精确擦除，同时识别关键边界锚点以保留相关概念。

Result: SELECT作为通用锚点解决方案，能高效适配多种擦除框架，在关键性能指标上持续优于现有基线，单个概念锚点挖掘平均仅需4秒。

Conclusion: SELECT框架通过动态锚点选择有效解决了概念擦除中的锚点敏感性问题，实现了更精确的概念擦除效果。

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [31] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 该论文研究了用户如何通过策略性互动来引导算法与其真实兴趣对齐，提出了一个双系统决策模型和Stackelberg博弈框架，揭示了用户需要足够的前瞻性才能有效对齐算法，但小的代价信号可以显著降低对齐负担。


<details>
  <summary>Details</summary>
Motivation: 研究用户在算法交互中的不一致偏好问题，探索用户如何通过选择性互动来引导算法更好地匹配其真实兴趣，解决用户在短期冲动和长期价值之间的冲突。

Method: 将用户决策过程建模为理性系统2（决定是否互动）和冲动系统1（决定互动时长）的双系统模型，采用多领导者-单跟随者的Stackelberg扩展博弈框架，用户作为领导者通过承诺互动策略来引导算法响应。

Result: 发现存在一个关键的对齐时间范围：足够有远见的用户可以实现算法对齐，而缺乏远见的用户则会被算法目标所对齐。这个关键时间范围可能很长，但即使一个小的代价信号（如额外点击）也能显著减少对齐负担。

Conclusion: 该框架解释了具有不一致偏好的用户如何在Stackelberg均衡中实现与互动驱动算法的对齐，既揭示了实现对齐的挑战，也指出了通过代价信号减轻对齐负担的潜在解决方案。

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [32] [Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs](https://arxiv.org/abs/2510.16374)
*Nick Oh*

Main category: cs.AI

TL;DR: 该论文提出了一种结合监控-生成-验证的三阶段迭代系统，在GSM8K上取得了75.42%的准确率，优于现有方法且需要更少的尝试次数。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理增强方法存在分离问题：监控-生成方法缺乏验证机制，生成-验证方法缺乏任务评估。这种分离导致策略失败无反馈，优化缺乏战略基础。

Method: 实现了Flavell的认知监控模型，作为监控-生成-验证框架的三阶段迭代系统。

Result: 在GSM8K上达到75.42%准确率，优于SELF-REFINE(68.44%)和Self-Verification(67.07%)，尝试次数更少(1.3 vs 2.0)，推理成本增加27-37%。

Conclusion: 前期监控能产生更高质量的初始解决方案，减少优化需求，但需要在算术推理之外进行更多评估以确立通用性。

Abstract: Current approaches to enhancing LLM reasoning follows two isolated paradigms:
Monitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and
SELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack
mechanisms to verify whether selected strategies succeed; while Generate-Verify
approaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan
et al., 2023) iteratively refine outputs but commence generation blindly
without task assessment. This separation creates inefficiencies -- strategies
fail without feedback, and refinement occurs without strategic grounding. We
address this gap by implementing Flavell's cognitive monitoring model (1979)
from the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),
operationalising it as a three-phase iterative system. On GSM8K, preliminary
results show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for
Self-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%
increased inference cost. These initial findings suggest upfront monitoring
produces higher-quality initial solutions that reduce refinement needs, though
evaluation beyond arithmetic reasoning is needed to establish generalisability.

</details>


### [33] [Humanoid-inspired Causal Representation Learning for Domain Generalization](https://arxiv.org/abs/2510.16382)
*Ze Tao,Jian Zhang,Haowei Li,Xianshuai Li,Yifei Peng,Xiyao Liu,Senzhang Wang,Chao Liu,Sheng Ren,Shichao Zhang*

Main category: cs.AI

TL;DR: 提出HSCM因果框架，模拟人类视觉系统，通过解耦和重加权图像属性来提升跨域泛化能力


<details>
  <summary>Details</summary>
Motivation: 克服传统域泛化模型的局限性，模拟人类智能的层次处理和多级学习机制

Method: 基于人形启发的结构因果模型，解耦颜色、纹理、形状等关键图像属性并重新加权

Result: 在理论和实证评估中优于现有域泛化模型，提供更稳健的性能和可解释性

Conclusion: HSCM为捕捉因果关系和提升模型鲁棒性提供了更原则性的方法

Abstract: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a
novel causal framework inspired by human intelligence, designed to overcome the
limitations of conventional domain generalization models. Unlike approaches
that rely on statistics to capture data-label dependencies and learn
distortion-invariant representations, HSCM replicates the hierarchical
processing and multi-level learning of human vision systems, focusing on
modeling fine-grained causal mechanisms. By disentangling and reweighting key
image attributes such as color, texture, and shape, HSCM enhances
generalization across diverse domains, ensuring robust performance and
interpretability. Leveraging the flexibility and adaptability of human
intelligence, our approach enables more effective transfer and learning in
dynamic, complex environments. Through both theoretical and empirical
evaluations, we demonstrate that HSCM outperforms existing domain
generalization models, providing a more principled method for capturing causal
relationships and improving model robustness. The code is available at
https://github.com/lambett/HSCM.

</details>


### [34] [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](https://arxiv.org/abs/2510.16392)
*Ao Tian,Yunfeng Lu,Xinxin Fan,Changhao Wang,Lanzhi Zhou,Yeyao Zhang,Yanfang Liu*

Main category: cs.AI

TL;DR: 提出RGMem框架，通过多尺度记忆组织实现LLM对话系统的长期用户建模和行为一致性


<details>
  <summary>Details</summary>
Motivation: 现有RAG和显式记忆系统主要关注事实级存储，缺乏从多轮对话中提取潜在偏好和深层特质的能力，限制了长期有效的用户建模

Method: 受物理学重整化群思想启发，通过分层粗粒化和重标度操作，从片段对话中提取语义和用户洞察，逐步形成动态演化的用户画像

Result: 实现了从噪声微观交互到高层次准确用户画像的信息压缩和涌现过程

Conclusion: RGMem框架能够有效解决LLM对话系统中长期记忆和行为一致性的挑战

Abstract: Personalized and continuous interactions are the key to enhancing user
experience in today's large language model (LLM)-based conversational systems,
however, the finite context windows and static parametric memory make it
difficult to model the cross-session long-term user states and behavioral
consistency. Currently, the existing solutions to this predicament, such as
retrieval-augmented generation (RAG) and explicit memory systems, primarily
focus on fact-level storage and retrieval, lacking the capability to distill
latent preferences and deep traits from the multi-turn dialogues, which limits
the long-term and effective user modeling, directly leading to the personalized
interactions remaining shallow, and hindering the cross-session continuity. To
realize the long-term memory and behavioral consistency for Language Agents in
LLM era, we propose a self-evolving memory framework RGMem, inspired by the
ideology of classic renormalization group (RG) in physics, this framework
enables to organize the dialogue history in multiple scales: it first extracts
semantics and user insights from episodic fragments, then through hierarchical
coarse-graining and rescaling operations, progressively forms a
dynamically-evolved user profile. The core innovation of our work lies in
modeling memory evolution as a multi-scale process of information compression
and emergence, which accomplishes the high-level and accurate user profiles
from noisy and microscopic-level interactions.

</details>


### [35] [ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](https://arxiv.org/abs/2510.16466)
*Siddhartha Krothapalli,Tridib Kumar Das,Praveen Kumar,Naveen Suravarpu,Pratik Narang*

Main category: cs.AI

TL;DR: ReviewSense是一个基于大语言模型的决策支持框架，可将客户评论转化为可操作的商业建议，超越传统偏好预测系统。


<details>
  <summary>Details</summary>
Motivation: 传统AI系统擅长预测用户偏好，但缺乏将客户评论转化为面向业务的规范性建议的能力，需要开发能提供更深层次商业洞察的框架。

Method: 集成聚类、LLM适配和专家驱动评估的统一业务导向流程，通过识别关键趋势、重复问题和具体关注点来生成建议。

Result: 初步人工评估显示模型建议与商业目标高度一致，具有推动数据驱动决策的潜力。

Conclusion: 该框架为AI驱动的情感分析提供了新视角，在优化商业策略和最大化客户反馈价值方面展现出重要价值。

Abstract: As customer feedback becomes increasingly central to strategic growth, the
ability to derive actionable insights from unstructured reviews is essential.
While traditional AI-driven systems excel at predicting user preferences, far
less work has focused on transforming customer reviews into prescriptive,
business-facing recommendations. This paper introduces ReviewSense, a novel
prescriptive decision support framework that leverages advanced large language
models (LLMs) to transform customer reviews into targeted, actionable business
recommendations. By identifying key trends, recurring issues, and specific
concerns within customer sentiments, ReviewSense extends beyond
preference-based systems to provide businesses with deeper insights for
sustaining growth and enhancing customer loyalty. The novelty of this work lies
in integrating clustering, LLM adaptation, and expert-driven evaluation into a
unified, business-facing pipeline. Preliminary manual evaluations indicate
strong alignment between the model's recommendations and business objectives,
highlighting its potential for driving data-informed decision-making. This
framework offers a new perspective on AI-driven sentiment analysis,
demonstrating its value in refining business strategies and maximizing the
impact of customer feedback.

</details>


### [36] [NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems](https://arxiv.org/abs/2510.16476)
*Xiaozhe Li,Xinyu Fang,Shengyuan Ding,Linyang Li,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: 提出了NP-ENGINE框架，用于训练和评估LLMs在NP难问题上的能力，包括任务生成器、验证器和启发式求解器，并展示了在NP-BENCH基准上的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数学、编程等推理任务上表现出色，但在解决NP难优化问题方面的能力仍未被充分探索。

Method: 开发NP-ENGINE框架，包含可控实例生成器、规则验证器和启发式求解器，采用分层难度的可扩展RLVR训练方法。

Result: 训练的QWEN2.5-7B-NP模型在NP-BENCH上显著优于GPT-4o，并展现出强大的跨领域泛化能力。

Conclusion: 任务丰富的RLVR训练是提升LLM推理能力的有前景方向，揭示了RLVR的扩展规律。

Abstract: Large Language Models (LLMs) have shown strong reasoning capabilities, with
models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as
mathematics, coding, logic, and puzzles through Reinforcement Learning with
Verifiable Rewards (RLVR). However, their ability to solve more complex
optimization problems - particularly NP-hard tasks - remains underexplored. To
bridge this gap, we propose NP-ENGINE, the first comprehensive framework for
training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks
across five domains, each equipped with (i) a controllable instance generator,
(ii) a rule-based verifier, and (iii) a heuristic solver that provides
approximate optimal solutions as ground truth. This
generator-verifier-heuristic pipeline enables scalable and verifiable RLVR
training under hierarchical difficulties. We also introduce NP-BENCH, a
benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'
ability to tackle NP-hard level reasoning problems, focusing not only on
feasibility but also on solution quality. Additionally, we present
QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on
Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and
achieves SOTA performance with the same model size. Beyond in-domain tasks, we
demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain
(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),
as well as non-reasoning tasks such as instruction following. We also observe a
scaling trend: increasing task diversity improves OOD generalization. These
findings suggest that task-rich RLVR training is a promising direction for
advancing LLM's reasoning ability, revealing new insights into the scaling laws
of RLVR.

</details>


### [37] [Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination](https://arxiv.org/abs/2510.16533)
*Eilene Tomkins-Flanagan,Connor Hanley,Mary A. Kelly*

Main category: cs.AI

TL;DR: Doug是一种类型化计算机语言，所有类型化程序都能被证明在多项式时间内停止，编码在向量符号架构(VSA)中。它基于轻量线性函数式编程语言(LLFPL)，类型使用全息声明性内存(HDM)编码，术语使用Lisp VSA变体编码。该语言允许神经网络嵌入空间中的点被解释为类型，从而实现类型学习。


<details>
  <summary>Details</summary>
Motivation: 将技能获取表达为程序合成，希望描述一种遵循人类技能获取速度的学习形式，超越现有方法的效率，更接近模拟人脑中的心理表征及其实际学习过程。

Method: 基于Schimanski2009的轻量线性函数式编程语言(LLFPL)，使用Kelly2020的全息声明性内存(HDM)进行类型编码，采用Flanagan2024的Lisp VSA变体进行术语编码，实现类型化程序在多项式时间内停止的证明。

Result: 开发了Doug语言，使神经网络嵌入空间中的点能够被解释为类型，且邻近点的类型在结构和内容上相似，从而实现类型的可学习性。

Conclusion: Doug语言为模拟人脑心理表征及其学习过程迈出了重要一步，有望实现超越现有方法效率的人类式技能获取。

Abstract: We present a typed computer language, Doug, in which all typed programs may
be proved to halt in polynomial time, encoded in a vector-symbolic architecture
(VSA). Doug is just an encoding of the light linear functional programming
language (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are
encoded using a slot-value encoding scheme based on holographic declarative
memory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the
Lisp VSA defined by (Flanagan, 2024). Doug allows for some points on the
embedding space of a neural network to be interpreted as types, where the types
of nearby points are similar both in structure and content. Types in Doug are
therefore learnable by a neural network. Following (Chollet, 2019), (Card,
1983), and (Newell, 1981), we view skill as the application of a procedure, or
program of action, that causes a goal to be satisfied. Skill acquisition may
therefore be expressed as program synthesis. Using Doug, we hope to describe a
form of learning of skilled behaviour that follows a human-like pace of skill
acquisition (i.e., substantially faster than brute force; Heathcote, 2000),
exceeding the efficiency of all currently existing approaches (Kaplan, 2020;
Jones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling
human mental representations, as they must actually exist in the brain, and
those representations' acquisition, as they are actually learned.

</details>


### [38] [Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence](https://arxiv.org/abs/2510.16555)
*Qiongyan Wang,Xingchen Zou,Yutian Jiang,Haomin Wen,Jiaheng Wei,Qingsong Wen,Yuxuan Liang*

Main category: cs.AI

TL;DR: Urban-R1是一个基于强化学习的后训练框架，通过Group Relative Policy Optimization (GRPO)和城市区域画像任务来减轻多模态大语言模型的地理偏见，提升跨区域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 快速城市化加剧了对城市通用智能(UGI)的需求，但现有基于监督微调的城市基础模型存在持续的地理偏见，导致区域预测偏差和有限泛化能力。

Method: 提出Urban-R1强化学习后训练框架，采用GRPO优化跨地理群体的推理能力，使用城市区域画像作为代理任务从多模态城市数据中提供可测量的奖励。

Result: 跨多个区域和任务的广泛实验表明，Urban-R1有效减轻地理偏见并改善跨区域泛化，优于监督微调训练和闭源模型。

Conclusion: 强化学习对齐是实现公平可信城市智能的有前景途径。

Abstract: Rapid urbanization intensifies the demand for Urban General Intelligence
(UGI), referring to AI systems that can understand and reason about complex
urban environments. Recent studies have built urban foundation models using
supervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit
persistent geospatial bias, producing regionally skewed predictions and limited
generalization. To this end, we propose Urban-R1, a reinforcement
learning-based post-training framework that aligns MLLMs with the objectives of
UGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize
reasoning across geographic groups and employs urban region profiling as a
proxy task to provide measurable rewards from multimodal urban data. Extensive
experiments across diverse regions and tasks show that Urban-R1 effectively
mitigates geo-bias and improves cross-region generalization, outperforming both
SFT-trained and closed-source models. Our results highlight reinforcement
learning alignment as a promising pathway toward equitable and trustworthy
urban intelligence.

</details>


### [39] [BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction](https://arxiv.org/abs/2510.16559)
*Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu*

Main category: cs.AI

TL;DR: BuildArena是首个面向语言驱动工程建设的物理对齐交互式基准测试，用于评估LLM在工程建筑自动化中的能力。


<details>
  <summary>Details</summary>
Motivation: 工程建筑自动化需要将自然语言规范转化为物理可行的结构，但现代LLM在此领域的建设能力尚未得到充分评估。

Method: 开发了高度可定制的基准测试框架，包含可扩展的任务设计策略、3D空间几何计算库和基线LLM代理工作流程。

Result: 在八个前沿LLM上全面评估了它们在语言驱动和物理基础建设自动化方面的能力。

Conclusion: BuildArena填补了LLM在工程建筑自动化领域评估的空白，为社区提供了首个物理对齐的交互式基准测试。

Abstract: Engineering construction automation aims to transform natural language
specifications into physically viable structures, requiring complex integrated
reasoning under strict physical constraints. While modern LLMs possess broad
knowledge and strong reasoning capabilities that make them promising candidates
for this domain, their construction competencies remain largely unevaluated. To
address this gap, we introduce BuildArena, the first physics-aligned
interactive benchmark designed for language-driven engineering construction. It
contributes to the community in four aspects: (1) a highly customizable
benchmarking framework for in-depth comparison and analysis of LLMs; (2) an
extendable task design strategy spanning static and dynamic mechanics across
multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for
supporting construction based on language instructions; (4) a baseline LLM
agentic workflow that effectively evaluates diverse model capabilities. On
eight frontier LLMs, BuildArena comprehensively evaluates their capabilities
for language-driven and physics-grounded construction automation. The project
page is at https://build-arena.github.io/.

</details>


### [40] [Ripple Effect Protocol: Coordinating Agent Populations](https://arxiv.org/abs/2510.16572)
*Ayush Chopra,Aman Sharma,Feroz Ahmad,Luca Muscariello,Vijoy Pandey,Ramesh Raskar*

Main category: cs.AI

TL;DR: 提出了Ripple Effect Protocol (REP)，一种协调协议，让智能体不仅分享决策，还分享轻量级敏感度信号，从而在群体中实现更快更稳定的协调。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理通信协议（如A2A和ACP）强调通信而非协调，随着代理群体规模增长，这会导致脆弱的集体行为，即使个体智能体也会产生不良群体结果。

Method: 引入REP协议，代理分享决策和轻量级敏感度信号（表达关键环境变量变化时选择如何改变），这些敏感度在局部网络中传播。协议规范分离了必需的消息模式和可选的聚合规则。

Result: 在三个领域的基准测试中：（i）供应链级联（啤酒游戏）、（ii）稀疏网络中的偏好聚合（电影调度）、（iii）可持续资源分配（渔业银行），REP相比A2A将协调准确性和效率提高了41%到100%，并能灵活处理来自LLM的多模态敏感度信号。

Conclusion: 通过将协调作为协议级能力，REP为新兴的智能体互联网提供了可扩展的基础设施。

Abstract: Modern AI agents can exchange messages using protocols such as A2A and ACP,
yet these mechanisms emphasize communication over coordination. As agent
populations grow, this limitation produces brittle collective behavior, where
individually smart agents converge on poor group outcomes. We introduce the
Ripple Effect Protocol (REP), a coordination protocol in which agents share not
only their decisions but also lightweight sensitivities - signals expressing
how their choices would change if key environmental variables shifted. These
sensitivities ripple through local networks, enabling groups to align faster
and more stably than with agent-centric communication alone. We formalize REP's
protocol specification, separating required message schemas from optional
aggregation rules, and evaluate it across scenarios with varying incentives and
network topologies. Benchmarks across three domains: (i) supply chain cascades
(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),
and (iii) sustainable resource allocation (Fishbanks) show that REP improves
coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly
handling multimodal sensitivity signals from LLMs. By making coordination a
protocol-level capability, REP provides scalable infrastructure for the
emerging Internet of Agents

</details>


### [41] [Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?](https://arxiv.org/abs/2510.16582)
*Junchi Yu,Yujie Liu,Jindong Gu,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: GraphFlow是一个基于知识图谱的检索增强生成框架，通过流匹配目标优化检索策略，从文本丰富的知识图谱中高效检索准确多样的知识。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的检索增强生成方法在处理复杂现实查询时难以从文本丰富的知识图谱中检索准确多样的信息，而过程奖励模型需要昂贵的过程级监督信号。

Method: GraphFlow采用基于转移的流匹配目标联合优化检索策略和流估计器，将检索结果的奖励分解到中间检索状态，指导检索策略按奖励比例从知识图谱中检索候选结果。

Result: 在STaRK基准测试中，GraphFlow在命中率和召回率上平均优于包括GPT-4o在内的强基线10%，并在未见过的知识图谱上表现出良好的泛化能力。

Conclusion: GraphFlow能够有效从文本丰富的知识图谱中检索准确多样的知识，展现出强大的效果和鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances
large language models (LLMs) by providing structured and interpretable external
knowledge. However, existing KG-based RAG methods struggle to retrieve accurate
and diverse information from text-rich KGs for complex real-world queries.
Process Reward Models (PRMs) offer a way to align the retrieval process of
KG-based RAG with query-specific knowledge requirements, but they heavily rely
on process-level supervision signals that are expensive and hard to obtain on
KGs. To address this challenge, we propose GraphFlow, a framework that
efficiently retrieves accurate and diverse knowledge required for real-world
queries from text-rich KGs. GraphFlow employs a transition-based flow matching
objective to jointly optimize a retrieval policy and a flow estimator. The flow
estimator factorizes the reward of the retrieval outcome into the intermediate
retrieval states. Such reward factorization guides the retrieval policy to
retrieve candidates from KGs in proportion to their reward. This allows
GraphFlow to explore high-quality regions of KGs that yield diverse and
relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes
real-world queries from multiple domains over text-rich KGs. GraphFlow
outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit
rate and recall. It also shows strong generalization to unseen KGs,
demonstrating its effectiveness and robustness.

</details>


### [42] [Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning](https://arxiv.org/abs/2510.16601)
*Tianxing Wu,Shutong Zhu,Jingting Wang,Ning Xu,Guilin Qi,Haofen Wang*

Main category: cs.AI

TL;DR: 提出了一种用于不确定知识图谱补全的半监督置信度分布学习方法，通过将置信度转换为分布来增强嵌入学习，并使用元学习生成伪标签来平衡置信度分布。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了置信度的极端不平衡分布，导致学习到的嵌入不足以支持高质量的不确定知识图谱补全。

Method: 提出ssCDL方法，将置信度转换为置信度分布，通过关系学习在标记数据和带伪标签的未标记数据上迭代学习嵌入，使用元学习预测未见三元组的置信度来增强训练数据。

Result: 在两个不确定知识图谱数据集上的实验表明，ssCDL在不同评估指标上始终优于最先进的基线方法。

Conclusion: ssCDL通过置信度分布学习和半监督方法有效解决了置信度不平衡问题，提升了不确定知识图谱补全的性能。

Abstract: Uncertain knowledge graphs (UKGs) associate each triple with a confidence
score to provide more precise knowledge representations. Recently, since
real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)
completion attracts more attention, aiming to complete missing triples and
confidences. Current studies attempt to learn UKG embeddings to solve this
problem, but they neglect the extremely imbalanced distributions of triple
confidences. This causes that the learnt embeddings are insufficient to
high-quality UKG completion. Thus, in this paper, to address the above issue,
we propose a new semi-supervised Confidence Distribution Learning (ssCDL)
method for UKG completion, where each triple confidence is transformed into a
confidence distribution to introduce more supervision information of different
confidences to reinforce the embedding learning process. ssCDL iteratively
learns UKG embedding by relational learning on labeled data (i.e., existing
triples with confidences) and unlabeled data with pseudo labels (i.e., unseen
triples with the generated confidences), which are predicted by meta-learning
to augment the training data and rebalance the distribution of triple
confidences. Experiments on two UKG datasets demonstrate that ssCDL
consistently outperforms state-of-the-art baselines in different evaluation
metrics.

</details>


### [43] [Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards](https://arxiv.org/abs/2510.16614)
*Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: MERCI是一种增强LLM推理能力的强化学习算法，通过基于计数的内在奖励来激励探索，避免模型陷入重复和次优的推理模式。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习范式依赖稀疏的结果奖励和有限探索，导致LLM倾向于重复和次优的推理模式，需要设计更好的探索机制来提升推理能力。

Method: 提出MERCI算法，使用轻量级的Coin Flipping Network估计伪计数和认知不确定性，将其转化为内在奖励，并与GRPO等先进RL框架集成。

Result: 在复杂推理基准测试中，MERCI鼓励更丰富多样的思维链，显著超越强基线性能，帮助策略逃离局部最优发现更好解决方案。

Conclusion: 针对性的内在动机可以使探索在语言模型推理中变得可靠有效。

Abstract: Reinforcement Learning (RL) has become a compelling way to strengthen the
multi step reasoning ability of Large Language Models (LLMs). However,
prevalent RL paradigms still lean on sparse outcome-based rewards and limited
exploration, which often drives LLMs toward repetitive and suboptimal reasoning
patterns. In this paper, we study the central question of how to design
exploration for LLM reasoning and introduce MERCI (Motivating Exploration in
LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that
augments policy optimization with a principled intrinsic reward. Building on
the idea of count-based exploration, MERCI leverages a lightweight Coin
Flipping Network (CFN) to estimate the pseudo count and further epistemic
uncertainty over reasoning trajectories, and converts them into an intrinsic
reward that values novelty while preserving the learning signal from task
rewards. We integrate MERCI into some advanced RL frameworks like Group
Relative Policy Optimization (GRPO). Experiments on complex reasoning
benchmarks demonstrate that MERCI encourages richer and more varied chains of
thought, significantly improves performance over strong baselines, and helps
the policy escape local routines to discover better solutions. It indicates
that our targeted intrinsic motivation can make exploration reliable for
language model reasoning.

</details>


### [44] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 该论文探讨了大规模AI模型对神经科学研究的变革性影响，涵盖神经影像处理、脑机接口、分子神经科学、临床辅助和疾病应用五大领域，强调这些模型如何解决多模态神经数据整合等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模AI模型的出现为神经科学研究带来了范式转变，从传统计算方法转向端到端学习，能够直接从原始脑信号和神经数据中学习，这为神经科学领域提供了新的研究机遇。

Method: 论文通过系统性回顾和分析，探索大规模AI模型在五个主要神经科学领域的应用：神经影像与数据处理、脑机接口与神经解码、分子神经科学与基因组建模、临床辅助与转化框架、以及神经系统和精神疾病的特定应用。

Result: 研究表明大规模AI模型能够有效解决计算神经科学中的关键挑战，包括多模态神经数据整合、时空模式解释以及临床部署的转化框架开发。同时，神经科学与AI的互动变得更加双向，生物启发的架构约束被用于开发更具解释性和计算效率的模型。

Conclusion: 该综述强调了这些技术的显著前景和关键实施考虑，特别强调需要严格的评估框架、有效的领域知识整合以及临床使用的全面伦理指南。论文还提供了用于验证大规模AI模型的关键神经科学数据集的系统列表。

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [45] [An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems](https://arxiv.org/abs/2510.16701)
*Ni Zhang,Zhiguang Cao,Jianan Zhou,Cong Zhang,Yew-Soon Ong*

Main category: cs.AI

TL;DR: 提出了基于大语言模型的AFL框架，用于解决复杂车辆路径问题，实现从问题实例到解决方案的完全自动化，无需人工干预或外部求解器。


<details>
  <summary>Details</summary>
Motivation: 传统复杂车辆路径问题需要大量专家精力进行意图解释和算法设计，现有LLM方法仍依赖外部干预，导致自主性受限、执行错误和解决方案可行性低。

Method: AFL框架将整个流程分解为三个可管理的子任务，采用四个专门化代理，通过协调交互确保跨功能一致性和逻辑合理性，直接从原始输入提取知识并生成自包含代码。

Result: 在60个复杂VRP问题上的实验验证了框架的有效性和通用性，与精心设计的算法性能相当，在代码可靠性和解决方案可行性方面显著优于现有LLM基线，在评估基准上接近100%的成功率。

Conclusion: AFL框架实现了复杂车辆路径问题求解的完全自动化，解决了现有LLM方法的局限性，在可靠性和可行性方面表现出色，为自动化求解复杂优化问题提供了可行路径。

Abstract: Complex vehicle routing problems (VRPs) remain a fundamental challenge,
demanding substantial expert effort for intent interpretation and algorithm
design. While large language models (LLMs) offer a promising path toward
automation, current approaches still rely on external intervention, which
restrict autonomy and often lead to execution errors and low solution
feasibility. To address these challenges, we propose an Agentic Framework with
LLMs (AFL) for solving complex vehicle routing problems, achieving full
automation from problem instance to solution. AFL directly extracts knowledge
from raw inputs and enables self-contained code generation without handcrafted
modules or external solvers. To improve trustworthiness, AFL decomposes the
overall pipeline into three manageable subtasks and employs four specialized
agents whose coordinated interactions enforce cross-functional consistency and
logical soundness. Extensive experiments on 60 complex VRPs, ranging from
standard benchmarks to practical variants, validate the effectiveness and
generality of our framework, showing comparable performance against
meticulously designed algorithms. Notably, it substantially outperforms
existing LLM-based baselines in both code reliability and solution feasibility,
achieving rates close to 100% on the evaluated benchmarks.

</details>


### [46] [Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI](https://arxiv.org/abs/2510.16720)
*Jitao Sang,Jinlin Xiao,Jiarun Han,Jilin Chen,Xiaoyi Chen,Shuyu Wei,Yongjie Sun,Yuhang Wang*

Main category: cs.AI

TL;DR: 本文综述了智能AI从基于管道的系统向模型原生范式的范式转变，其中规划、工具使用和记忆能力从外部逻辑编排转变为模型参数内部化。强化学习是实现这一转变的算法引擎，支持LLM + RL + Task的统一解决方案。


<details>
  <summary>Details</summary>
Motivation: 追踪智能AI构建的范式转变，从外部编排能力到模型内部化能力，探索从应用智能的系统向通过经验增长智能的模型发展的轨迹。

Method: 系统回顾规划、工具使用和记忆能力如何从外部脚本模块演变为端到端学习行为，分析强化学习作为算法引擎的作用，并考察这一范式转变如何重塑深度研究代理和GUI代理等主要应用。

Result: 揭示了向模型原生智能AI的连贯发展轨迹，展示了能力内部化的趋势，包括多智能体协作和反思等能力的持续内部化。

Conclusion: 智能AI正在从构建应用智能的系统向开发通过经验增长智能的模型转变，标志着人工智能发展的新阶段。

Abstract: The rapid evolution of agentic AI marks a new phase in artificial
intelligence, where Large Language Models (LLMs) no longer merely respond but
act, reason, and adapt. This survey traces the paradigm shift in building
agentic AI: from Pipeline-based systems, where planning, tool use, and memory
are orchestrated by external logic, to the emerging Model-native paradigm,
where these capabilities are internalized within the model's parameters. We
first position Reinforcement Learning (RL) as the algorithmic engine enabling
this paradigm shift. By reframing learning from imitating static data to
outcome-driven exploration, RL underpins a unified solution of LLM + RL + Task
across language, vision and embodied domains. Building on this, the survey
systematically reviews how each capability -- Planning, Tool use, and Memory --
has evolved from externally scripted modules to end-to-end learned behaviors.
Furthermore, it examines how this paradigm shift has reshaped major agent
applications, specifically the Deep Research agent emphasizing long-horizon
reasoning and the GUI agent emphasizing embodied interaction. We conclude by
discussing the continued internalization of agentic capabilities like
Multi-agent collaboration and Reflection, alongside the evolving roles of the
system and model layers in future agentic AI. Together, these developments
outline a coherent trajectory toward model-native agentic AI as an integrated
learning and interaction framework, marking the transition from constructing
systems that apply intelligence to developing models that grow intelligence
through experience.

</details>


### [47] [A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications](https://arxiv.org/abs/2510.16724)
*Minhua Lin,Zongyu Wu,Zhichao Xu,Hui Liu,Xianfeng Tang,Qi He,Charu Aggarwal,Hui Liu,Xiang Zhang,Suhang Wang*

Main category: cs.AI

TL;DR: 该论文是关于基于强化学习的智能搜索系统的综述，首次全面概述了RL在智能搜索中的应用，从功能角色、优化策略和应用范围三个维度组织该新兴领域。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统存在单轮交互、启发式方法等局限性，缺乏对检索和推理的自适应控制。智能搜索通过多步交互解决了这些问题，而强化学习为自适应和自我改进的搜索行为提供了强大机制。

Method: 从三个维度组织该领域：(i) RL的功能角色，(ii) RL的优化策略，(iii) RL的应用范围。总结了代表性方法、评估协议和应用案例。

Result: 提供了该领域的系统性分类框架，识别了关键方法和技术，并建立了开源资源库。

Conclusion: 该综述为构建可靠和可扩展的RL驱动智能搜索系统提供了指导，并讨论了开放挑战和未来方向，旨在激发RL与智能搜索集成的研究。

Abstract: The advent of large language models (LLMs) has transformed information access
and reasoning through open-ended natural language interaction. However, LLMs
remain limited by static knowledge, factual hallucinations, and the inability
to retrieve real-time or domain-specific information. Retrieval-Augmented
Generation (RAG) mitigates these issues by grounding model outputs in external
evidence, but traditional RAG pipelines are often single turn and heuristic,
lacking adaptive control over retrieval and reasoning. Recent advances in
agentic search address these limitations by enabling LLMs to plan, retrieve,
and reflect through multi-step interaction with search environments. Within
this paradigm, reinforcement learning (RL) offers a powerful mechanism for
adaptive and self-improving search behavior. This survey provides the first
comprehensive overview of \emph{RL-based agentic search}, organizing the
emerging field along three complementary dimensions: (i) What RL is for
(functional roles), (ii) How RL is used (optimization strategies), and (iii)
Where RL is applied (scope of optimization). We summarize representative
methods, evaluation protocols, and applications, and discuss open challenges
and future directions toward building reliable and scalable RL driven agentic
search systems. We hope this survey will inspire future research on the
integration of RL and agentic search. Our repository is available at
https://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.

</details>


### [48] [Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration](https://arxiv.org/abs/2510.16742)
*Paul Saves,Pramudita Satria Palar,Muhammad Daffa Robani,Nicolas Verstaevel,Moncef Garouani,Julien Aligon,Benoit Gaudou,Koji Shimoyama,Joseph Morlier*

Main category: cs.AI

TL;DR: 提出了一种基于替代模型的仿真驱动工程工作流，通过训练轻量级模拟器来解决计算成本高和模型透明度不足的问题，支持不确定性量化和可解释AI分析。


<details>
  <summary>Details</summary>
Motivation: 仿真驱动工程工作流面临两个主要挑战：(1) 高计算成本，因为准确探索需要大量昂贵的模拟器运行；(2) 当决策依赖于不透明的黑盒组件时，透明度和可靠性有限。

Method: 通过在紧凑的实验设计上训练轻量级模拟器，提供快速、低延迟的昂贵模拟器近似，支持严格的不确定性量化，并适用于全局和局部可解释AI分析。

Result: 在两个对比案例研究中（混合电动飞机的多学科设计分析和城市隔离的基于代理模型），结果显示替代模型与XAI耦合能够在几秒钟内实现大规模探索，揭示非线性相互作用和涌现行为，识别关键设计和政策杠杆，并指示需要更多数据或替代架构的区域。

Conclusion: 该工作流统一了所有基于仿真的复杂系统分析工具，从工程设计到社会环境理解，通过替代模型的可解释性工具提供了比较方法和实用建议，支持连续和分类输入，结合全局效应和不确定性分析与局部归因，评估解释在不同替代模型间的一致性。

Abstract: Complex systems are increasingly explored through simulation-driven
engineering workflows that combine physics-based and empirical models with
optimization and analytics. Despite their power, these workflows face two
central obstacles: (1) high computational cost, since accurate exploration
requires many expensive simulator runs; and (2) limited transparency and
reliability when decisions rely on opaque blackbox components. We propose a
workflow that addresses both challenges by training lightweight emulators on
compact designs of experiments that (i) provide fast, low-latency
approximations of expensive simulators, (ii) enable rigorous uncertainty
quantification, and (iii) are adapted for global and local Explainable
Artificial Intelligence (XAI) analyses. This workflow unifies every
simulation-based complex-system analysis tool, ranging from engineering design
to agent-based models for socio-environmental understanding. In this paper, we
proposea comparative methodology and practical recommendations for using
surrogate-based explainability tools within the proposed workflow. The
methodology supports continuous and categorical inputs, combines global-effect
and uncertainty analyses with local attribution, and evaluates the consistency
of explanations across surrogate models, thereby diagnosing surrogate adequacy
and guiding further data collection or model refinement. We demonstrate the
approach on two contrasting case studies: a multidisciplinary design analysis
of a hybrid-electric aircraft and an agent-based model of urban segregation.
Results show that the surrogate model and XAI coupling enables large-scale
exploration in seconds, uncovers nonlinear interactions and emergent behaviors,
identifies key design and policy levers, and signals regions where surrogates
require more data or alternative architectures.

</details>


### [49] [ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2510.16753)
*Wei Huang,Peining Li,Meiyu Liang,Xu Hou,Junping Du,Yingxia Shao,Guanhua Ye,Wu Liu,Kangkang Lu,Yang Yu*

Main category: cs.AI

TL;DR: 提出了ELMM模型，通过多视图视觉令牌压缩器和注意力剪枝策略，解决多模态知识图谱补全中的语义噪声、模态冲突和计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态知识图谱存在不完整性问题，而多模态大语言模型在知识图谱补全任务中面临图像令牌过多导致的语义噪声、模态冲突和计算成本高的挑战。

Method: 提出ELMM模型，包含基于多头注意力的多视图视觉令牌压缩器，从文本和视觉视图自适应压缩图像令牌；设计注意力剪枝策略移除冗余注意力层，并使用线性投影补偿性能损失。

Result: 在FB15k-237-IMG和WN18-IMG基准测试中，ELMM实现了最先进的性能，同时显著提高了计算效率。

Conclusion: ELMM为多模态知识图谱补全建立了一个新的范式，在保持高性能的同时大幅提升计算效率。

Abstract: Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by
incorporating visual and textual modalities, enabling richer and more
expressive entity representations. However, existing MKGs often suffer from
incompleteness, which hinder their effectiveness in downstream tasks.
Therefore, multimodal knowledge graph completion (MKGC) task is receiving
increasing attention. While large language models (LLMs) have shown promise for
knowledge graph completion (KGC), their application to the multimodal setting
remains underexplored. Moreover, applying Multimodal Large Language Models
(MLLMs) to the task of MKGC introduces significant challenges: (1) the large
number of image tokens per entity leads to semantic noise and modality
conflicts, and (2) the high computational cost of processing large token
inputs. To address these issues, we propose Efficient Lightweight Multimodal
Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token
Compressor (MVTC) based on multi-head attention mechanism, which adaptively
compresses image tokens from both textual and visual views, thereby effectively
reducing redundancy while retaining necessary information and avoiding modality
conflicts. Additionally, we design an attention pruning strategy to remove
redundant attention layers from MLLMs, thereby significantly reducing the
inference cost. We further introduce a linear projection to compensate for the
performance degradation caused by pruning. Extensive experiments on benchmark
FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art
performance while substantially improving computational efficiency,
establishing a new paradigm for multimodal knowledge graph completion.

</details>


### [50] [End-to-end Listen, Look, Speak and Act](https://arxiv.org/abs/2510.16756)
*Siyin Wang,Wenyi Yu,Xianzhao Chen,Xiaohai Tian,Jun Zhang,Lu Lu,Chao Zhang*

Main category: cs.AI

TL;DR: ELLSA是首个全双工、端到端的多模态模型，能够同时感知和生成视觉、文本、语音和动作，实现更自然的人机交互。


<details>
  <summary>Details</summary>
Motivation: 人类交互本质上是多模态和全双工的，需要模型能够同时感知和生成多种模态，实现更自然的人类行为模拟。

Method: 采用新颖的SA-MoE架构（自注意力专家混合），将各模态路由到专用专家，通过统一注意力骨干网络进行融合。

Result: 在语音交互和机器人操作基准测试中，ELLSA与模态特定基线表现相当，同时支持高级多模态和全双工行为。

Conclusion: ELLSA代表了向更自然和通用交互智能迈出的一步，有助于实现更广泛的人工通用智能目标。

Abstract: Human interaction is inherently multimodal and full-duplex: we listen while
watching, speak while acting, and fluidly adapt to turn-taking and
interruptions. Realizing these capabilities is essential for building models
simulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),
which, to our knowledge, is the first full-duplex, end-to-end model that
simultaneously perceives and generates across vision, text, speech, and action
within a single architecture, enabling interaction patterns previously out of
reach, yielding more natural, human-like behaviors. At its core is a novel
SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each
modality to specialized experts and fuses them through a unified attention
backbone. This provides a generalizable solution for joint multimodal
perception and concurrent generation, leveraging strong pre-trained components
while enabling efficient modality integration and mitigating modality
interference. On speech-interaction and robot-manipulation benchmarks, ELLSA
matches modality-specific baselines, while uniquely supporting advanced
multimodal and full-duplex behaviors such as dialogue and action turn-taking,
defective instruction rejection, speaking-while-acting, context-grounded visual
question answering, and action barge-ins. We contend that ELLSA represents a
step toward more natural and general interactive intelligence, contributing to
the broader pursuit of artificial general intelligence. All data, code and
model checkpoints will be released upon acceptance.

</details>


### [51] [See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models](https://arxiv.org/abs/2510.16769)
*Shuo Han,Yukun Cao,Zezhong Ding,Zengyi Gao,S Kevin Zhou,Xike Xie*

Main category: cs.AI

TL;DR: GraphVista是一个统一的图理解框架，通过分层组织图信息和使用规划代理协调文本与视觉模态，解决了VLMs在图理解中的可扩展性和模态协调问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在图理解中存在输入令牌限制导致的可扩展性瓶颈，以及缺乏有效的文本和视觉模态协调机制。

Method: GraphVista采用分层方法将图信息组织到轻量级GraphRAG基础中，仅检索任务相关的文本描述和高分辨率视觉子图；引入规划代理根据任务复杂度路由到最适合的模态。

Result: GraphVista能够扩展到比现有基准大200倍的大型图，在质量上比现有最先进基线提升4.4倍，持续优于基于文本、视觉和融合的方法。

Conclusion: GraphVista通过充分利用两种模态的互补优势，有效解决了图理解中的可扩展性和模态协调挑战。

Abstract: Vision-language models (VLMs) have shown promise in graph understanding, but
remain limited by input-token constraints, facing scalability bottlenecks and
lacking effective mechanisms to coordinate textual and visual modalities. To
address these challenges, we propose GraphVista, a unified framework that
enhances both scalability and modality coordination in graph understanding. For
scalability, GraphVista organizes graph information hierarchically into a
lightweight GraphRAG base, which retrieves only task-relevant textual
descriptions and high-resolution visual subgraphs, compressing redundant
context while preserving key reasoning elements. For modality coordination,
GraphVista introduces a planning agent that routes tasks to the most suitable
modality-using the text modality for simple property reasoning and the visual
modality for local and structurally complex reasoning grounded in explicit
topology. Extensive experiments demonstrate that GraphVista scales to large
graphs, up to $200\times$ larger than those used in existing benchmarks, and
consistently outperforms existing textual, visual, and fusion-based methods,
achieving up to $4.4\times$ quality improvement over the state-of-the-art
baselines by fully exploiting the complementary strengths of both modalities.

</details>


### [52] [Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation](https://arxiv.org/abs/2510.16802)
*Chao Li,Yuru Wang*

Main category: cs.AI

TL;DR: 提出Domain-Contextualized Concept Graph (CDC)框架，将领域作为知识表示的一等元素，采用<概念, 关系@领域, 概念>的三元组结构，实现上下文感知推理和跨领域类比。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱受限于固定本体论的刚性层次结构，根源在于将领域视为隐式上下文而非显式推理组件。

Method: 基于认知-语言同构映射原则，采用C-D-C三元组结构，定义20多个标准化关系谓词，并在Prolog中实现完整推理能力。

Result: 在教育、企业知识系统和技术文档等案例研究中，CDC实现了上下文感知推理、跨领域类比和个性化知识建模。

Conclusion: CDC框架突破了传统基于本体的知识表示限制，提供了传统框架无法实现的能力。

Abstract: Traditional knowledge graphs are constrained by fixed ontologies that
organize concepts within rigid hierarchical structures. The root cause lies in
treating domains as implicit context rather than as explicit, reasoning-level
components. To overcome these limitations, we propose the Domain-Contextualized
Concept Graph (CDC), a novel knowledge modeling framework that elevates domains
to first-class elements of conceptual representation. CDC adopts a C-D-C triple
structure - <Concept, Relation@Domain, Concept'> - where domain specifications
serve as dynamic classification dimensions defined on demand. Grounded in a
cognitive-linguistic isomorphic mapping principle, CDC operationalizes how
humans understand concepts through contextual frames. We formalize more than
twenty standardized relation predicates (structural, logical, cross-domain, and
temporal) and implement CDC in Prolog for full inference capability. Case
studies in education, enterprise knowledge systems, and technical documentation
demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and
personalized knowledge modeling - capabilities unattainable under traditional
ontology-based frameworks.

</details>


### [53] [DeepAnalyze: Agentic Large Language Models for Autonomous Data Science](https://arxiv.org/abs/2510.16872)
*Shaolei Zhang,Ju Fan,Meihao Fan,Guoliang Li,Xiaoyong Du*

Main category: cs.AI

TL;DR: DeepAnalyze-8B是首个用于自主数据科学的代理式大语言模型，能够自动完成从数据源到分析师级深度研究报告的端到端流程，仅用80亿参数就超越了基于最先进专有LLM的工作流代理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于工作流的数据代理在特定数据任务上表现良好，但由于依赖预定义工作流，无法实现完全自主的数据科学。随着强大LLM的出现，从原始数据源到分析师级深度研究报告的自主数据科学变得可行。

Method: 提出基于课程学习的代理训练范式，模拟人类数据科学家的学习轨迹，使LLM能够在真实环境中逐步获取和整合多种能力；同时引入数据驱动的轨迹合成框架来构建高质量训练数据。

Result: 实验表明，DeepAnalyze-8B能够执行广泛的数据任务，包括数据问答、专业分析任务和开放式数据研究，在仅80亿参数的情况下超越了基于最先进专有LLM的工作流代理。

Conclusion: DeepAnalyze-8B为自主数据科学开辟了道路，其模型、代码和训练数据均已开源。

Abstract: Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language models (LLMs). Recent workflow-based
data agents have shown promising results on specific data tasks but remain
fundamentally limited in achieving fully autonomous data science due to their
reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,
the first agentic LLM designed for autonomous data science, capable of
automatically completing the end-toend pipeline from data sources to
analyst-grade deep research reports. To tackle high-complexity data science
tasks, we propose a curriculum-based agentic training paradigm that emulates
the learning trajectory of human data scientists, enabling LLMs to
progressively acquire and integrate multiple capabilities in real-world
environments. We also introduce a data-grounded trajectory synthesis framework
that constructs high-quality training data. Through agentic training,
DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data
question answering and specialized analytical tasks to open-ended data
research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze
outperforms previous workflow-based agents built on most advanced proprietary
LLMs. The model, code, and training data of DeepAnalyze are open-sourced,
paving the way toward autonomous data science.

</details>


### [54] [VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents](https://arxiv.org/abs/2510.16907)
*Kangrui Wang,Pingyue Zhang,Zihan Wang,Yaning Gao,Linjie Li,Qineng Wang,Hanyang Chen,Chi Wan,Yiping Lu,Zhengyuan Yang,Lijuan Wang,Ranjay Krishna,Jiajun Wu,Li Fei-Fei,Yejin Choi,Manling Li*

Main category: cs.AI

TL;DR: 该论文提出通过强化学习训练VLM代理构建内部世界模型，将视觉状态推理分解为状态估计和转移建模，并设计了世界建模奖励和双层GAE方法，在多个基准测试中显著优于未训练模型和专有推理模型。


<details>
  <summary>Details</summary>
Motivation: 解决VLM代理从文本状态转向复杂视觉观察时面临的局部可观测性和世界建模挑战，探索代理是否能通过显式视觉状态推理构建内部世界模型。

Method: 将代理推理过程架构化为POMDP，分解为状态估计和转移建模，设计了五种推理策略，引入世界建模奖励提供密集监督，并提出双层GAE进行回合感知信用分配。

Result: 3B参数模型在五个多样化代理基准测试中达到0.82分，比未训练模型(0.21)提升3倍，优于GPT-5(0.75)、Gemini 2.5 Pro(0.67)和Claude 4.5(0.62)。

Conclusion: 通过视觉状态推理，VLM代理能够有效构建内部世界模型，最优表示形式取决于任务性质，该方法在VAGEN框架中实现了可扩展的多回合VLM代理训练。

Abstract: A key challenge in training Vision-Language Model (VLM) agents, compared to
Language Model (LLM) agents, lies in the shift from textual states to complex
visual observations. This transition introduces partial observability and
demands robust world modeling. We ask: Can VLM agents construct internal world
models through explicit visual state reasoning? To address this question, we
architecturally enforce and reward the agent's reasoning process via
reinforcement learning (RL), formulating it as a Partially Observable Markov
Decision Process (POMDP). We find that decomposing the agent's reasoning into
State Estimation ("what is the current state?") and Transition Modeling ("what
comes next?") is critical for success, as demonstrated through five reasoning
strategies. Our investigation into how agents represent internal beliefs
reveals that the optimal representation is task-dependent: Natural Language
excels at capturing semantic relationships in general tasks, while Structured
formats are indispensable for precise manipulation and control. Building on
these insights, we design a World Modeling Reward that provides dense,
turn-level supervision for accurate state prediction, and introduce Bi-Level
General Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.
Through this form of visual state reasoning, a 3B-parameter model achieves a
score of 0.82 across five diverse agent benchmarks, representing a 3$\times$
improvement over its untrained counterpart (0.21) and outperforming proprietary
reasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5
(0.62). All experiments are conducted within our VAGEN framework, a scalable
system for training and analyzing multi-turn VLM agents in diverse visual
environments. Code and data are publicly available at
https://vagen-ai.github.io.

</details>


### [55] [A Comparative User Evaluation of XRL Explanations using Goal Identification](https://arxiv.org/abs/2510.16956)
*Mark Towers,Yali Du,Christopher Freeman,Timothy J. Norman*

Main category: cs.AI

TL;DR: 提出了一种新的评估方法，用于测试用户是否能从强化学习算法的决策解释中识别出智能体的目标。在Ms. Pacman环境中测试了四种可解释强化学习算法，发现只有一种算法的准确率超过随机水平，且用户普遍对自己的选择过度自信。


<details>
  <summary>Details</summary>
Motivation: 可解释强化学习算法的核心应用是调试，但目前缺乏对其相对性能的比较评估。

Method: 使用Atari的Ms. Pacman环境和四种可解释强化学习算法，通过用户测试来评估他们是否能从决策解释中识别智能体的目标。

Result: 只有一种算法在测试目标上实现了超过随机水平的准确率；用户普遍过度自信；用户自我报告的识别和理解难易度与准确率无关。

Conclusion: 当前的可解释强化学习算法在帮助用户识别智能体目标方面效果有限，用户的主观感受与实际表现不一致。

Abstract: Debugging is a core application of explainable reinforcement learning (XRL)
algorithms; however, limited comparative evaluations have been conducted to
understand their relative performance. We propose a novel evaluation
methodology to test whether users can identify an agent's goal from an
explanation of its decision-making. Utilising the Atari's Ms. Pacman
environment and four XRL algorithms, we find that only one achieved greater
than random accuracy for the tested goals and that users were generally
overconfident in their selections. Further, we find that users' self-reported
ease of identification and understanding for every explanation did not
correlate with their accuracy.

</details>


### [56] [STARK: Strategic Team of Agents for Refining Kernels](https://arxiv.org/abs/2510.16996)
*Juncheng Dong,Yang Yang,Tao Liu,Yang Wang,Feng Qi,Vahid Tarokh,Kaushik Rangadurai,Shuang Yang*

Main category: cs.AI

TL;DR: 提出了一个基于LLM的多智能体协作框架，用于自动化GPU内核优化，通过系统探索设计空间、结合性能分析反馈和迭代优化，显著提升内核性能。


<details>
  <summary>Details</summary>
Motivation: GPU内核优化对AI发展至关重要，但现有方法复杂且劳动密集。虽然LLM为自动化代码生成提供了新机会，但现有方法将其视为单次生成器或简单优化工具，难以应对不规则的内核优化场景。

Method: 开发了一个LLM智能体框架，通过多智能体协作、基础指令、动态上下文管理和策略搜索来系统探索设计空间，模拟专家工程师的工作流程，使LLM能够推理硬件权衡、整合性能分析反馈并迭代优化内核。

Result: 在KernelBench基准测试中，该系统相比基线智能体有显著提升：在基线经常失败的情况下产生正确解决方案，并实现高达16倍的运行时性能提升。

Conclusion: 结果表明智能体LLM框架具有推进完全自动化、可扩展GPU内核优化的潜力。

Abstract: The efficiency of GPU kernels is central to the progress of modern AI, yet
optimizing them remains a difficult and labor-intensive task due to complex
interactions between memory hierarchies, thread scheduling, and
hardware-specific characteristics. While recent advances in large language
models (LLMs) provide new opportunities for automated code generation, existing
approaches largely treat LLMs as single-shot generators or naive refinement
tools, limiting their effectiveness in navigating the irregular kernel
optimization landscape. We introduce an LLM agentic framework for GPU kernel
optimization that systematically explores the design space through multi-agent
collaboration, grounded instruction, dynamic context management, and strategic
search. This framework mimics the workflow of expert engineers, enabling LLMs
to reason about hardware trade-offs, incorporate profiling feedback, and refine
kernels iteratively. We evaluate our approach on KernelBench, a benchmark for
LLM-based kernel optimization, and demonstrate substantial improvements over
baseline agents: our system produces correct solutions where baselines often
fail, and achieves kernels with up to 16x faster runtime performance. These
results highlight the potential of agentic LLM frameworks to advance fully
automated, scalable GPU kernel optimization.

</details>


### [57] [ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems](https://arxiv.org/abs/2510.17052)
*Hassan Hamad,Yingru Xu,Liang Zhao,Wenbo Yan,Narendra Gyanchandani*

Main category: cs.AI

TL;DR: ToolCritic是一个诊断框架，用于评估和改进LLM在多轮工具增强对话中的行为，通过检测8种特定工具调用错误并提供针对性反馈，使主LLM能够修正响应。


<details>
  <summary>Details</summary>
Motivation: 工具增强的大型语言模型在现实应用中越来越普遍，但工具使用错误仍然阻碍其可靠性。

Method: ToolCritic检测8种特定工具调用错误类型（如过早调用、参数不对齐、工具输出误解等），并向主LLM提供针对性反馈。主LLM基于ToolCritic的反馈修正其响应。

Result: 在Schema-Guided Dialogue数据集上的实验结果表明，ToolCritic相比基线方法（包括零样本提示和自校正技术）将工具调用准确率提高了13%。

Conclusion: 这是朝着在现实世界对话应用中更稳健地集成LLM与外部工具的有希望的一步。

Abstract: Tool-augmented large language models (LLMs) are increasingly employed in
real-world applications, but tool usage errors still hinder their reliability.
We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM
behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight
distinct error types specific to tool-calling (e.g., premature invocation,
argument misalignment, and misinterpretation of tool outputs) and provides
targeted feedback to the main LLM. The main LLM, assumed to have strong
reasoning, task understanding and orchestration capabilities, then revises its
response based on ToolCritic's feedback. We systematically define these error
categories and construct a synthetic dataset to train ToolCritic. Experimental
results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic
improves tool-calling accuracy by up to 13% over baselines, including zero-shot
prompting and self-correction techniques. This represents a promising step
toward more robust LLM integration with external tools in real-world dialogue
applications.

</details>


### [58] [A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation](https://arxiv.org/abs/2510.17064)
*Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng*

Main category: cs.AI

TL;DR: BRAINCELL-AID是一个多智能体AI系统，通过整合自由文本描述和本体标签，结合检索增强生成技术，显著提高了基因集注释的准确性和鲁棒性，在脑细胞类型注释中取得了77%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统基因集富集分析方法依赖精心策划的注释，在处理涉及特征不良基因的转录组特征时表现不佳。大语言模型虽然提供了有前景的替代方案，但在结构化本体中表示复杂生物学知识方面存在困难。

Method: 开发了BRAINCELL-AID多智能体AI系统，整合自由文本描述与本体标签，采用检索增强生成技术构建鲁棒的智能体工作流程，通过PubMed文献精炼预测结果。

Result: 在小鼠基因集的注释中，77%的基因集在其前几个预测中获得了正确注释。成功注释了来自BRAIN Initiative Cell Census Network生成的5,322个脑细胞簇，识别了区域特异性基因共表达模式，并推断基因集合的功能作用。

Conclusion: BRAINCELL-AID创建了一个支持社区驱动细胞类型注释的宝贵资源，能够识别具有神经学意义描述的基底神经节相关细胞类型，为脑细胞功能研究提供了新的见解。

Abstract: Single-cell RNA sequencing has transformed our ability to identify diverse
cell types and their transcriptomic signatures. However, annotating these
signatures-especially those involving poorly characterized genes-remains a
major challenge. Traditional methods, such as Gene Set Enrichment Analysis
(GSEA), depend on well-curated annotations and often perform poorly in these
contexts. Large Language Models (LLMs) offer a promising alternative but
struggle to represent complex biological knowledge within structured
ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:
https://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that
integrates free-text descriptions with ontology labels to enable more accurate
and robust gene set annotation. By incorporating retrieval-augmented generation
(RAG), we developed a robust agentic workflow that refines predictions using
relevant PubMed literature, reducing hallucinations and enhancing
interpretability. Using this workflow, we achieved correct annotations for 77%
of mouse gene sets among their top predictions. Applying this approach, we
annotated 5,322 brain cell clusters from the comprehensive mouse brain cell
atlas generated by the BRAIN Initiative Cell Census Network, enabling novel
insights into brain cell function by identifying region-specific gene
co-expression patterns and inferring functional roles of gene ensembles.
BRAINCELL-AID also identifies Basal Ganglia-related cell types with
neurologically meaningful descriptions. Hence, we create a valuable resource to
support community-driven cell type annotation.

</details>


### [59] [Structured Debate Improves Corporate Credit Reasoning in Financial AI](https://arxiv.org/abs/2510.17108)
*Yoonjin Lee,Munhee Kim,Hanbi Choi,Juhyeon Park,Seungho Lyoo,Woojin Park*

Main category: cs.AI

TL;DR: 开发并评估了两种基于大语言模型的系统用于企业信用评估中的证据推理：单代理系统(NAS)和多代理辩论系统(KPD-MADS)，后者基于卡尔·波普尔的批判性对话框架，在推理质量和实用性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 企业信用评估中定性非财务指标的自动化推理问题尚未解决，现有方法主要关注数值预测，缺乏对专业贷款评估所需解释性判断的支持。

Method: 开发了两种LLM系统：单代理系统(NAS)通过单次推理管道生成双向分析；多代理辩论系统(KPD-MADS)基于卡尔·波普尔批判性对话框架，采用十步结构化交互协议进行对抗性验证。

Result: 两个系统都实现了显著的生产力提升(NAS: 11.55秒/案例；KPD-MADS: 91.97秒；人工基准: 1920秒)。KPD-MADS在解释充分性(4.0 vs 3.0)、实际适用性(4.0 vs 3.0)和可用性(62.5 vs 52.5)方面获得更高评分。

Conclusion: 结构化多代理交互可以增强金融AI中的推理严谨性和可解释性，推动企业信用评估中可扩展且可辩护的自动化进程。

Abstract: Despite advances in financial AI, the automation of evidence-based reasoning
remains unresolved in corporate credit assessment, where qualitative
non-financial indicators exert decisive influence on loan repayment outcomes
yet resist formalization. Existing approaches focus predominantly on numerical
prediction and provide limited support for the interpretive judgments required
in professional loan evaluation. This study develops and evaluates two
operational large language model (LLM)-based systems designed to generate
structured reasoning from non-financial evidence. The first is a
non-adversarial single-agent system (NAS) that produces bidirectional analysis
through a single-pass reasoning pipeline. The second is a debate-based
multi-agent system (KPD-MADS) that operationalizes adversarial verification
through a ten-step structured interaction protocol grounded in Karl Popper's
critical dialogue framework. Both systems were applied to three real corporate
cases and evaluated by experienced credit risk professionals. Compared to
manual expert reporting, both systems achieved substantial productivity gains
(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The
KPD-MADS demonstrated superior reasoning quality, receiving higher median
ratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.
3.0), and usability (62.5 vs. 52.5). These findings show that structured
multi-agent interaction can enhance reasoning rigor and interpretability in
financial AI, advancing scalable and defensible automation in corporate credit
assessment.

</details>


### [60] [Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion](https://arxiv.org/abs/2510.17145)
*Phi-Hung Hoang,Nam-Thuan Trinh,Van-Manh Tran,Thi-Thu-Hong Phan*

Main category: cs.AI

TL;DR: 提出了一种基于手工特征的方法，通过提取和融合颜色统计、多色彩空间直方图以及纹理特征来评估鱼类新鲜度，在FFE数据集上取得了显著优于深度学习的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统感官评估鱼类新鲜度存在主观性、不一致性和难以标准化的问题，需要开发客观、可靠的自动化评估方法。

Method: 从鱼眼图像中系统提取手工特征，包括颜色统计、多色彩空间直方图、LBP和GLCM纹理特征，融合全局色度变化和局部ROI退化特征，使用LightGBM和ANN进行分类。

Result: 标准训练测试设置下LightGBM达到77.56%准确率，比深度学习方法提升14.35%；数据增强后ANN达到97.16%准确率，比之前最佳方法提升19.86%。

Conclusion: 精心设计的手工特征经过策略性处理后，能够为鱼类新鲜度自动评估提供鲁棒、可解释且可靠的解决方案，在食品质量监控中具有实用价值。

Abstract: Accurate assessment of fish freshness remains a major challenge in the food
industry, with direct consequences for product quality, market value, and
consumer health. Conventional sensory evaluation is inherently subjective,
inconsistent, and difficult to standardize across contexts, often limited by
subtle, species-dependent spoilage cues. To address these limitations, we
propose a handcrafted feature-based approach that systematically extracts and
incrementally fuses complementary descriptors, including color statistics,
histograms across multiple color spaces, and texture features such as Local
Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish
eye images. Our method captures global chromatic variations from full images
and localized degradations from ROI segments, fusing each independently to
evaluate their effectiveness in assessing freshness. Experiments on the
Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's
effectiveness: in a standard train-test setting, a LightGBM classifier achieved
77.56% accuracy, a 14.35% improvement over the previous deep learning baseline
of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached
97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results
demonstrate that carefully engineered, handcrafted features, when strategically
processed, yield a robust, interpretable, and reliable solution for automated
fish freshness assessment, providing valuable insights for practical
applications in food quality monitoring.

</details>


### [61] [Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation](https://arxiv.org/abs/2510.17146)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: 提出了PILLM框架，结合物理知识和大型语言模型，通过进化循环自动生成、评估和优化HVAC系统异常检测规则，实现高性能且可解释的异常检测。


<details>
  <summary>Details</summary>
Motivation: HVAC系统能耗占建筑能耗很大比例，现有方法要么缺乏适应性（基于规则的方法），要么缺乏可解释性和物理合理性（深度学习方法），需要开发既高效又可信的异常检测方法。

Method: PILLM框架在进化循环中运行，引入物理感知的反思和交叉算子，嵌入热力学和控制理论约束，自动生成、评估和优化异常检测规则。

Result: 在公共建筑故障检测数据集上的实验表明，PILLM达到了最先进的性能，同时生成可解释且可操作的诊断规则。

Conclusion: PILLM推进了智能建筑系统中可信赖和可部署的人工智能，实现了高性能与可解释性的平衡。

Abstract: Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a
substantial share of global building energy use, making reliable anomaly
detection essential for improving efficiency and reducing emissions. Classical
rule-based approaches offer explainability but lack adaptability, while deep
learning methods provide predictive power at the cost of transparency,
efficiency, and physical plausibility. Recent attempts to use Large Language
Models (LLMs) for anomaly detection improve interpretability but largely ignore
the physical principles that govern HVAC operations. We present PILLM, a
Physics-Informed LLM framework that operates within an evolutionary loop to
automatically generate, evaluate, and refine anomaly detection rules. Our
approach introduces physics-informed reflection and crossover operators that
embed thermodynamic and control-theoretic constraints, enabling rules that are
both adaptive and physically grounded. Experiments on the public Building Fault
Detection dataset show that PILLM achieves state-of-the-art performance while
producing diagnostic rules that are interpretable and actionable, advancing
trustworthy and deployable AI for smart building systems.

</details>


### [62] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: ProtocolBench是一个系统评估多智能体系统通信协议的基准测试，ProtocolRouter是一个可学习的协议路由器，能根据场景需求动态选择最优协议。


<details>
  <summary>Details</summary>
Motivation: 大规模多智能体系统中，通信协议选择缺乏标准化指导，当前选择往往基于直觉而非数据驱动。

Method: 开发ProtocolBench基准测试，从任务成功率、端到端延迟、消息开销和故障恢复能力四个维度系统比较不同协议；提出ProtocolRouter学习型协议路由器，根据需求和运行时信号动态选择协议。

Result: 协议选择显著影响系统性能：在Streaming Queue场景中，完成时间差异达36.5%，端到端延迟差异3.48秒；ProtocolRouter相比最佳单协议基线，故障恢复时间减少18.1%，在GAIA场景中成功率更高。

Conclusion: 通信协议选择对多智能体系统性能至关重要，ProtocolBench和ProtocolRouter为协议评估和选择提供了标准化方法和工具，能显著提升系统可靠性和性能。

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [63] [Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients](https://arxiv.org/abs/2510.17172)
*Shun Huang,Wenlu Xing,Shijia Geng,Hailong Wang,Guangkun Nie,Gongzheng Tang,Chenyang He,Shenda Hong*

Main category: cs.AI

TL;DR: 开发了一个结合ECG基础模型和可解释XGBoost分类器的混合预测框架，用于预测急性心肌梗死后恶性室性心律失常风险，在提高准确性的同时保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 急性心肌梗死后恶性室性心律失常是院内死亡的主要原因，传统风险评分性能有限，而端到端深度学习模型缺乏临床信任所需的可解释性。

Method: 使用ECGFounder基础模型提取150维诊断概率特征，通过特征选择后训练XGBoost分类器，并用SHAP方法进行可解释性分析。

Result: 混合模型AUC达到0.801，优于KNN(0.677)、RNN(0.676)和1D-CNN(0.720)，SHAP分析显示模型识别特征与临床知识高度一致。

Conclusion: 该混合框架为基础模型输出作为有效自动特征工程提供了验证，为构建可信、可解释的AI临床决策支持系统提供了新范式。

Abstract: Malignant ventricular arrhythmias (VT/VF) following acute myocardial
infarction (AMI) are a major cause of in-hospital death, yet early
identification remains a clinical challenge. While traditional risk scores have
limited performance, end-to-end deep learning models often lack the
interpretability needed for clinical trust. This study aimed to develop a
hybrid predictive framework that integrates a large-scale electrocardiogram
(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to
improve both accuracy and interpretability. We analyzed 6,634 ECG recordings
from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder
model was used to extract 150-dimensional diagnostic probability features ,
which were then refined through feature selection to train the XGBoost
classifier. Model performance was evaluated using AUC and F1-score , and the
SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid
model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC
0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that
model-identified key features, such as "premature ventricular complexes" (risk
predictor) and "normal sinus rhythm" (protective factor), were highly
consistent with clinical knowledge. We conclude that this hybrid framework
provides a novel paradigm for VT/VF risk prediction by validating the use of
foundation model outputs as effective, automated feature engineering for
building trustworthy, explainable AI-based clinical decision support systems.

</details>


### [64] [Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users](https://arxiv.org/abs/2510.17173)
*Melik Ozolcer,Sang Won Bae*

Main category: cs.AI

TL;DR: 研究了一个基于网页部署、工具增强的LLM健康教练系统，通过离线策略评估发现统一的重工具策略会损害特定用户群体，特别是低健康素养/高自我效能用户。模拟实验表明添加早期信息增益奖励可以改善个性化效果。


<details>
  <summary>Details</summary>
Motivation: 探索工具增强的LLM健康教练在真实用户环境中的表现，重点关注个性化策略对不同用户群体的影响，特别是避免对特定子群体的潜在伤害。

Method: 使用离线策略评估方法，通过因子化决策头（工具/风格）分析策略效果；构建轻量级模拟器验证添加信息增益奖励的效果；采用冻结生成器、学习子群体感知决策头的个性化路径。

Result: 统一的重工具策略虽然提高了平均价值，但损害了低健康素养/高自我效能用户群体；添加早期信息增益奖励可以缩短特质识别时间，提高目标成功率和pass@3指标。

Conclusion: 提出评估优先的个性化路径：冻结生成器，基于类型化奖励学习子群体感知决策头，并始终报告按原型分类的指标以揭示被平均值掩盖的子群体伤害问题。

Abstract: We study a web-deployed, tool-augmented LLM health coach with real users. In
a pilot with seven users (280 rated turns), offline policy evaluation (OPE)
over factorized decision heads (Tool/Style) shows that a uniform heavy-tool
policy raises average value on logs but harms specific subgroups, most notably
low-health-literacy/high-self-efficacy users. A lightweight simulator with
hidden archetypes further shows that adding a small early information-gain
bonus reliably shortens trait identification and improves goal success and
pass@3. Together, these early findings indicate an evaluation-first path to
personalization: freeze the generator, learn subgroup-aware decision heads on
typed rewards (objective tool outcomes and satisfaction), and always report
per-archetype metrics to surface subgroup harms that averages obscure.

</details>


### [65] [Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling](https://arxiv.org/abs/2510.17211)
*Tingsong Xiao,Yao An Lee,Zelin Xu,Yupu Zhang,Zibo Liu,Yu Huang,Jiang Bian,Serena Jingchuan Guo,Zhe Jiang*

Main category: cs.AI

TL;DR: 提出了TD-HNODE模型，通过时间详细超图和神经ODE框架学习疾病进展的连续时间动态，在2型糖尿病和心血管疾病进展建模中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 疾病进展建模面临挑战：需要基于不规则时间事件样本学习连续时间动态，以及处理患者异质性（不同进展速率和路径）。现有方法要么缺乏从真实数据学习的适应性，要么无法捕捉复杂的连续时间动态。

Method: TD-HNODE模型将疾病进展表示为时间详细超图，通过神经ODE框架学习连续时间进展动态。包含可学习的TD-Hypergraph Laplacian，捕捉疾病并发症标志物在进展轨迹内和轨迹间的相互依赖关系。

Result: 在两个真实世界临床数据集上的实验表明，TD-HNODE在建模2型糖尿病和相关心血管疾病进展方面优于多个基线方法。

Conclusion: TD-HNODE能够有效建模疾病进展的连续时间动态，解决了现有方法在适应性和复杂动态捕捉方面的局限性。

Abstract: Disease progression modeling aims to characterize and predict how a patient's
disease complications worsen over time based on longitudinal electronic health
records (EHRs). Accurate modeling of disease progression, such as type 2
diabetes, can enhance patient sub-phenotyping and inform effective and timely
interventions. However, the problem is challenging due to the need to learn
continuous-time dynamics of progression patterns based on irregular-time event
samples and patient heterogeneity (\eg different progression rates and
pathways). Existing mechanistic and data-driven methods either lack
adaptability to learn from real-world data or fail to capture complex
continuous-time dynamics on progression trajectories. To address these
limitations, we propose Temporally Detailed Hypergraph Neural Ordinary
Differential Equation (TD-HNODE), which represents disease progression on
clinically recognized trajectories as a temporally detailed hypergraph and
learns the continuous-time progression dynamics via a neural ODE framework.
TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the
interdependency of disease complication markers within both intra- and
inter-progression trajectories. Experiments on two real-world clinical datasets
demonstrate that TD-HNODE outperforms multiple baselines in modeling the
progression of type 2 diabetes and related cardiovascular diseases.

</details>


### [66] [Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis](https://arxiv.org/abs/2510.17235)
*Chong Chen,Ze Liu,Lingfeng Bao,Yanlin Wang,Ting Chen,Daoyuan Wu,Jiachi Chen*

Main category: cs.AI

TL;DR: Coinvisor是一个基于强化学习的加密货币投资分析聊天机器人，通过多智能体框架和强化学习工具选择机制，解决了现有投资分析方法的局限性，显著提升了分析准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 解决加密货币投资面临的三大挑战：手动分析依赖经验且耗时、数据聚合平台功能有限、基于静态预训练模型的LLM代理缺乏实时数据集成和多步推理能力。

Method: 采用基于强化学习的多智能体框架，通过专门的工具集成多样化分析能力，核心创新是强化学习驱动的工具选择机制，支持多步规划和灵活数据源集成。

Result: 在工具编排方面，相比基础模型召回率提升40.7%，F1分数提升26.6%；用户研究显示高满意度（4.64/5），参与者更偏好Coinvisor而非通用LLM和现有加密平台（4.62/5）。

Conclusion: Coinvisor通过强化学习驱动的多智能体框架，有效解决了加密货币投资分析中的关键挑战，提供了准确、可操作的投资洞察，在性能和用户体验方面均表现出色。

Abstract: The cryptocurrency market offers significant investment opportunities but
faces challenges including high volatility and fragmented information. Data
integration and analysis are essential for informed investment decisions.
Currently, investors use three main approaches: (1) Manual analysis across
various sources, which depends heavily on individual experience and is
time-consuming and prone to bias; (2) Data aggregation platforms-limited in
functionality and depth of analysis; (3) Large language model agents-based on
static pretrained models, lacking real-time data integration and multi-step
reasoning capabilities. To address these limitations, we present Coinvisor, a
reinforcement learning-based chatbot that provides comprehensive analytical
support for cryptocurrency investment through a multi-agent framework.
Coinvisor integrates diverse analytical capabilities through specialized tools.
Its key innovation is a reinforcement learning-based tool selection mechanism
that enables multi-step planning and flexible integration of diverse data
sources. This design supports real-time interaction and adaptive analysis of
dynamic content, delivering accurate and actionable investment insights. We
evaluated Coinvisor through automated benchmarks on tool calling accuracy and
user studies with 20 cryptocurrency investors using our interface. Results show
that Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base
model in tool orchestration. User studies show high satisfaction (4.64/5), with
participants preferring Coinvisor to both general LLMs and existing crypto
platforms (4.62/5).

</details>


### [67] [RubiSCoT: A Framework for AI-Supported Academic Assessment](https://arxiv.org/abs/2510.17309)
*Thorsten Fröhlich,Tim Schlippe*

Main category: cs.AI

TL;DR: 提出了RubiSCoT框架，使用AI技术增强论文评估过程，从提案到最终提交提供一致、可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统论文评估方法耗时且存在评估者差异，需要更高效、一致的评估方案。

Method: 使用先进自然语言处理技术，包括大语言模型、检索增强生成和结构化思维链提示，提供初步评估、多维评估、内容提取、基于评分标准的评分和详细报告。

Result: 设计了RubiSCoT框架并实现了其功能，展示了优化学术评估过程的潜力。

Conclusion: RubiSCoT框架通过一致、可扩展和透明的评估，有望优化学术评估流程。

Abstract: The evaluation of academic theses is a cornerstone of higher education,
ensuring rigor and integrity. Traditional methods, though effective, are
time-consuming and subject to evaluator variability. This paper presents
RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from
proposal to final submission. Using advanced natural language processing
techniques, including large language models, retrieval-augmented generation,
and structured chain-of-thought prompting, RubiSCoT offers a consistent,
scalable solution. The framework includes preliminary assessments,
multidimensional assessments, content extraction, rubric-based scoring, and
detailed reporting. We present the design and implementation of RubiSCoT,
discussing its potential to optimize academic assessment processes through
consistent, scalable, and transparent evaluation.

</details>


### [68] [Graph Attention-Guided Search for Dense Multi-Agent Pathfinding](https://arxiv.org/abs/2510.17382)
*Rishabh Jain,Keisuke Okumura,Michael Amir,Amanda Prorok*

Main category: cs.AI

TL;DR: 提出LaGAT框架，将基于图注意力的神经MAPF策略MAGAT集成到搜索算法LaCAM中，在密集多智能体路径规划场景中优于纯搜索和纯学习方法。


<details>
  <summary>Details</summary>
Motivation: 密集多智能体路径规划问题在实时场景中仍然具有挑战性，现有方法表现不佳，需要结合学习和搜索的优势。

Method: 使用增强的MAGAT架构，采用预训练-微调策略，并加入死锁检测机制来处理不完美的神经引导。

Result: LaGAT在密集场景中超越了纯搜索和纯学习方法，证明了混合搜索的有效性。

Conclusion: 精心设计的混合搜索方法为紧密耦合的挑战性多智能体协调问题提供了强大解决方案。

Abstract: Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)
problems in real-time remains challenging even for state-of-the-art planners.
To this end, we develop a hybrid framework that integrates a learned heuristic
derived from MAGAT, a neural MAPF policy with a graph attention scheme, into a
leading search-based algorithm, LaCAM. While prior work has explored
learning-guided search in MAPF, such methods have historically underperformed.
In contrast, our approach, termed LaGAT, outperforms both purely search-based
and purely learning-based methods in dense scenarios. This is achieved through
an enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of
interest, and a deadlock detection scheme to account for imperfect neural
guidance. Our results demonstrate that, when carefully designed, hybrid search
offers a powerful solution for tightly coupled, challenging multi-agent
coordination problems.

</details>


### [69] [Diverse Planning with Simulators via Linear Temporal Logic](https://arxiv.org/abs/2510.17418)
*Mustafa F. Abdelwahed,Alice Toniolo,Joan Espasa,Ian P. Gent*

Main category: cs.AI

TL;DR: 提出了FBI_LTL，一种用于仿真规划问题的多样化规划器，使用线性时序逻辑定义语义多样性标准，生成语义多样化的计划。


<details>
  <summary>Details</summary>
Motivation: 传统规划器只生成单一计划，可能无法满足代理偏好。现有多样化规划方法可能产生语法不同但语义相同的解决方案。

Method: FBI_LTL将基于LTL的多样性模型直接集成到搜索过程中，利用线性时序逻辑定义语义多样性标准。

Result: 在各种基准测试上的广泛评估表明，FBI_LTL相比基线方法能生成更多样化的计划。

Conclusion: 这项工作确立了在仿真环境中语义引导多样化规划的可行性，为在传统基于模型方法失效的现实非符号领域开辟了新途径。

Abstract: Autonomous agents rely on automated planning algorithms to achieve their
objectives. Simulation-based planning offers a significant advantage over
declarative models in modelling complex environments. However, relying solely
on a planner that produces a single plan may not be practical, as the generated
plans may not always satisfy the agent's preferences. To address this
limitation, we introduce $\texttt{FBI}_\texttt{LTL}$, a diverse planner
explicitly designed for simulation-based planning problems.
$\texttt{FBI}_\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define
semantic diversity criteria, enabling agents to specify what constitutes
meaningfully different plans. By integrating these LTL-based diversity models
directly into the search process, $\texttt{FBI}_\texttt{LTL}$ ensures the
generation of semantically diverse plans, addressing a critical limitation of
existing diverse planning approaches that may produce syntactically different
but semantically identical solutions. Extensive evaluations on various
benchmarks consistently demonstrate that $\texttt{FBI}_\texttt{LTL}$ generates
more diverse plans compared to a baseline approach. This work establishes the
feasibility of semantically-guided diverse planning in simulation-based
environments, paving the way for innovative approaches in realistic,
non-symbolic domains where traditional model-based approaches fail.

</details>


### [70] [Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions](https://arxiv.org/abs/2510.17450)
*Johan Schubert,Farzad Kamrani,Tove Gustavi*

Main category: cs.AI

TL;DR: 提出了一种基于主动推理的路径规划方法，用于智能代理的自主控制，通过构建证据地图和计算变分自由能来平衡探索与利用。


<details>
  <summary>Details</summary>
Motivation: 开发能够自主侦察地理区域以维持共同作战态势的方法，解决智能代理在探索广阔区域与跟踪已识别目标之间的平衡问题。

Method: 使用Dempster-Shafer理论和高斯传感器模型构建生成模型，通过贝叶斯方法更新后验概率分布，计算变分自由能来指导代理移动。

Result: 该方法能够在仿真中有效指导代理移动，通过最小化自由能量的位置选择来实现探索与利用的平衡。

Conclusion: 基于主动推理的路径规划方法成功解决了智能代理在地理侦察任务中的探索-利用权衡问题，为自主控制提供了有效解决方案。

Abstract: We develop an active inference route-planning method for the autonomous
control of intelligent agents. The aim is to reconnoiter a geographical area to
maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation,
incorporating both positive and "negative" sensor observations of possible
target objects collected over time, and diffusing the evidence across the map
as time progresses. The generative model of active inference uses
Dempster-Shafer theory and a Gaussian sensor model, which provides input to the
agent. The generative process employs a Bayesian approach to update a posterior
probability distribution. We calculate the variational free energy for all
positions within the area by assessing the divergence between a pignistic
probability distribution of the evidence map and a posterior probability
distribution of a target object based on the observations, including the level
of surprise associated with receiving new observations. Using the free energy,
we direct the agents' movements in a simulation by taking an incremental step
toward a position that minimizes the free energy. This approach addresses the
challenge of exploration and exploitation, allowing agents to balance searching
extensive areas of the geographical map while tracking identified target
objects.

</details>


### [71] [Label Indeterminacy in AI & Law](https://arxiv.org/abs/2510.17463)
*Cor Steging,Tadeusz Zbiegień*

Main category: cs.AI

TL;DR: 法律机器学习需要处理标签不确定性，因为法律结果常受到人为干预影响，导致最终结果可能不同。本文在欧洲人权法院案例分类中展示了标签构建方式如何显著影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 法律机器学习通常将过去案例结果视为真实标签，但法律结果常受人为干预影响，如和解、上诉等，造成标签不确定性。这种不确定性在现有机器学习方法中未被充分考虑。

Method: 在欧洲人权法院案例分类的背景下，分析不同标签构建方式对模型行为的影响，探讨处理标签不确定性的方法。

Result: 研究表明，训练过程中标签的构建方式会显著影响模型的行为表现，标签不确定性是AI与法律领域需要关注的重要问题。

Conclusion: 标签不确定性是AI与法律领域的一个相关关切点，它能够塑造模型行为，法律机器学习应用需要考虑和处理这种不确定性。

Abstract: Machine learning is increasingly used in the legal domain, where it typically
operates retrospectively by treating past case outcomes as ground truth.
However, legal outcomes are often shaped by human interventions that are not
captured in most machine learning approaches. A final decision may result from
a settlement, an appeal, or other procedural actions. This creates label
indeterminacy: the outcome could have been different if the intervention had or
had not taken place. We argue that legal machine learning applications need to
account for label indeterminacy. Methods exist that can impute these
indeterminate labels, but they are all grounded in unverifiable assumptions. In
the context of classifying cases from the European Court of Human Rights, we
show that the way that labels are constructed during training can significantly
affect model behaviour. We therefore position label indeterminacy as a relevant
concern in AI & Law and demonstrate how it can shape model behaviour.

</details>


### [72] [MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning](https://arxiv.org/abs/2510.17590)
*Mir Nafis Sharear Shopnil,Sharad Duwal,Abhishek Tyagi,Adiba Mahbub Proma*

Main category: cs.AI

TL;DR: MIRAGE是一个用于检测多模态虚假信息的推理时框架，通过分解验证过程为四个模块：视觉真实性评估、跨模态一致性分析、检索增强事实核查和校准判断，无需领域特定训练数据即可达到监督检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 网络平台上每天有数十亿结合文本和图像的多模态帖子传播虚假信息，人工事实核查能力不足，而现有的监督检测模型需要领域特定训练数据且无法泛化到不同的操纵策略。

Method: MIRAGE框架将多模态验证分解为四个顺序模块：视觉真实性评估检测AI生成图像，跨模态一致性分析识别上下文不当重用，检索增强事实核查通过迭代问题生成将声明基于网络证据，校准判断模块整合所有信号。

Result: 在MMFakeBench验证集上，MIRAGE与GPT-4o-mini组合达到81.65% F1和75.1%准确率，比最强的零样本基线（GPT-4V与MMD-Agent的74.0% F1）提升7.65点，同时保持34.3%的假阳性率，远低于仅判断基线的97.3%。测试集结果确认了泛化能力。

Conclusion: 分解的代理推理与网络检索相结合，可以在没有领域特定训练的情况下匹配监督检测器的性能，在标记数据稀缺的多模态场景中实现虚假信息检测。

Abstract: Misinformation spreads across web platforms through billions of daily
multimodal posts that combine text and images, overwhelming manual
fact-checking capacity. Supervised detection models require domain-specific
training data and fail to generalize across diverse manipulation tactics. We
present MIRAGE, an inference-time, model-pluggable agentic framework that
decomposes multimodal verification into four sequential modules: visual
veracity assessment detects AI-generated images, cross-modal consistency
analysis identifies out-of-context repurposing, retrieval-augmented factual
checking grounds claims in web evidence through iterative question generation,
and a calibrated judgment module integrates all signals. MIRAGE orchestrates
vision-language model reasoning with targeted web retrieval, outputs structured
and citation-linked rationales. On MMFakeBench validation set (1,000 samples),
MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming
the strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65
points while maintaining 34.3% false positive rate versus 97.3% for a
judge-only baseline. Test set results (5,000 samples) confirm generalization
with 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification
contributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97
points. Our results demonstrate that decomposed agentic reasoning with web
retrieval can match supervised detector performance without domain-specific
training, enabling misinformation detection across modalities where labeled
data remains scarce.

</details>


### [73] [Reasoning Distillation and Structural Alignment for Improved Code Generation](https://arxiv.org/abs/2510.17598)
*Amir Jalilifard,Anderson de Rezende Rocha,Marcos Medeiros Raimundo*

Main category: cs.AI

TL;DR: 该论文提出了一种将大型语言模型的推理能力蒸馏到更小、更高效模型的方法，通过结构感知损失优化来提升代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 代码生成不仅需要准确的标记预测，更需要理解解决方案级别的结构关系。大型语言模型具备复杂的推理能力，但部署成本高，因此需要将这些能力蒸馏到更小的模型中。

Method: 通过结构感知损失优化方法，训练小模型模拟大型语言模型的推理和问题解决能力，学习识别正确解决方案路径，建立问题定义与潜在解决方案之间的结构对应关系。

Result: 实验结果显示，经过微调的模型在MBPP、MBPP Plus和HumanEval基准测试中，在pass@1、平均数据流和平均语法匹配指标上显著优于基线模型。

Conclusion: 通过简单廉价的方法，成功将大型语言模型的推理能力蒸馏到小模型中，使其在代码生成任务中表现出色，同时降低了部署成本。

Abstract: Effective code generation with language models hinges on two critical
factors: accurately understanding the intent of the prompt and generating code
that applies algorithmic reasoning to produce correct solutions capable of
passing diverse test cases while adhering to the syntax of the target
programming language. Unlike other language tasks, code generation requires
more than accurate token prediction; it demands comprehension of solution-level
and structural relationships rather than merely generating the most likely
tokens. very large language model (VLLM) are capable of generating detailed
steps toward the correct solution of complex tasks where reasoning is crucial
in solving the problem. Such reasoning capabilities may be absent in smaller
language models. Therefore, in this work, we distill the reasoning capabilities
of a VLLM into a smaller, more efficient model that is faster and cheaper to
deploy. Our approach trains the model to emulate the reasoning and
problem-solving abilities of the VLLM by learning to identify correct solution
pathways and establishing a structural correspondence between problem
definitions and potential solutions through a novel method of structure-aware
loss optimization. This enables the model to transcend token-level generation
and to deeply grasp the overarching structure of solutions for given problems.
Experimental results show that our fine-tuned model, developed through a cheap
and simple to implement process, significantly outperforms our baseline model
in terms of pass@1, average data flow, and average syntax match metrics across
the MBPP, MBPP Plus, and HumanEval benchmarks.

</details>


### [74] [OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration](https://arxiv.org/abs/2510.17614)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: OG-Rank是一个低延迟的解码器重排序系统，通过池化首词评分和不确定性门控解释步骤，实现快速排序并在必要时生成解释，在临床医嘱选择任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要实时工作并能解释选择的排序系统，需要低延迟的解码器重排序方法。

Method: 采用单解码器方法，结合池化首词评分信号和不确定性门控解释步骤，使用课程学习专注于困难案例。

Result: 在临床医嘱选择任务中，快速路径Recall@1约0.45，nDCG@20约0.625；当门控激活时性能进一步提升（Recall@1约0.56，nDCG@20约0.699，门控率45%）。

Conclusion: OG-Rank提供了一个实用方案：默认快速排序，在需要时生成解释，这种选择性生成模式可广泛应用于决策任务，单策略设计简化部署和预算规划。

Abstract: Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.

</details>


### [75] [LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena](https://arxiv.org/abs/2510.17638)
*Qingchuan Yang,Simon Mahns,Sida Li,Anri Gu,Jibang Wu,Haifeng Xu*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型作为预测工具的能力，发现LLMs已展现出令人印象深刻的预测能力，但也存在事件回忆不准确、数据源误解等关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着在互联网规模数据上训练的大语言模型的快速发展，利用LLMs预测现实世界未来事件具有重要潜力，这种新兴范式被称为"LLM-as-a-Prophet"。

Method: 构建了Prophet Arena评估基准，持续收集实时预测任务并将每个任务分解为不同的流程阶段，以支持受控的大规模实验。

Result: 评估显示许多LLMs已展现出令人印象深刻的预测能力，表现为较小的校准误差、一致的预测置信度和有前景的市场回报。

Conclusion: LLMs在预测智能方面已取得显著进展，但在实现卓越预测能力方面仍面临关键瓶颈，如事件回忆不准确、数据源误解以及在接近决策时信息聚合速度较慢等问题。

Abstract: Forecasting is not only a fundamental intellectual pursuit but also is of
significant importance to societal systems such as finance and economics. With
the rapid advances of large language models (LLMs) trained on Internet-scale
data, it raises the promise of employing LLMs to forecast real-world future
events, an emerging paradigm we call "LLM-as-a-Prophet". This paper
systematically investigates such predictive intelligence of LLMs. To this end,
we build Prophet Arena, a general evaluation benchmark that continuously
collects live forecasting tasks and decomposes each task into distinct pipeline
stages, in order to support our controlled and large-scale experimentation. Our
comprehensive evaluation reveals that many LLMs already exhibit impressive
forecasting capabilities, reflected in, e.g., their small calibration errors,
consistent prediction confidence and promising market returns. However, we also
uncover key bottlenecks towards achieving superior predictive intelligence via
LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of
data sources and slower information aggregation compared to markets when
resolution nears.

</details>


### [76] [A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.17697)
*Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang*

Main category: cs.AI

TL;DR: 该论文提出使用多智能体影响图(MAIDs)作为图形化框架来解决多智能体强化学习中的协调问题，设计了基于MAIDs的针对性干预范式，通过因果推理技术实现单智能体干预，避免全局指导的复杂性。


<details>
  <summary>Details</summary>
Motivation: 在大规模多智能体强化学习中，对整个系统的全局人工指导不切实际，而现有的协调机制设计主要依赖经验研究，缺乏易用的研究工具。

Method: 引入多智能体影响图(MAIDs)作为分析框架，提出针对性干预范式，使用预策略干预(PSI)因果推理技术实现单智能体干预，通过最大化因果效应来达成复合目标。

Result: 实验证明了所提出的针对性干预方法的有效性，并验证了相关性图分析的结果。

Conclusion: MAIDs框架为多智能体强化学习提供了有效的分析和可视化工具，针对性干预范式能够缓解全局指导的问题，因果推理技术有助于实现复合目标。

Abstract: Steering cooperative multi-agent reinforcement learning (MARL) towards
desired outcomes is challenging, particularly when the global guidance from a
human on the whole multi-agent system is impractical in a large-scale MARL. On
the other hand, designing mechanisms to coordinate agents most relies on
empirical studies, lacking a easy-to-use research tool. In this work, we employ
multi-agent influence diagrams (MAIDs) as a graphical framework to address the
above issues. First, we introduce interaction paradigms that leverage MAIDs to
analyze and visualize existing approaches in MARL. Then, we design a new
interaction paradigm based on MAIDs, referred to as targeted intervention that
is applied to only a single targeted agent, so the problem of global guidance
can be mitigated. In our implementation, we introduce a causal inference
technique-referred to as Pre-Strategy Intervention (PSI)-to realize the
targeted intervention paradigm. Since MAIDs can be regarded as a special class
of causal diagrams, a composite desired outcome that integrates the primary
task goal and an additional desired outcome can be achieved by maximizing the
corresponding causal effect through the PSI. Moreover, the bundled relevance
graph analysis of MAIDs provides a tool to identify whether an MARL learning
paradigm is workable under the design of an interaction paradigm. In
experiments, we demonstrate the effectiveness of our proposed targeted
intervention, and verify the result of relevance graph analysis.

</details>


### [77] [Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models](https://arxiv.org/abs/2510.17705)
*Dayan Pan,Zhaoyang Fu,Jingyuan Wang,Xiao Han,Yue Zhu,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 提出Contextual Attention Modulation (CAM)机制和HyCAM框架，通过动态调制自注意力表示来增强任务特定特征并保留通用知识，在多任务适应中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在多任务适应中平衡知识保留与任务特定专业化的问题，传统微调方法存在灾难性遗忘和资源消耗大的缺陷，现有参数高效方法在复杂多任务场景下表现不佳。

Method: 提出CAM机制动态调制自注意力模块表示，并构建HyCAM框架，结合共享的全参数CAM模块和多个轻量级专用CAM模块，通过动态路由策略实现自适应知识融合。

Result: 在问答、代码生成和逻辑推理等异构任务上的广泛实验表明，该方法显著优于现有方法，平均性能提升3.65%。

Conclusion: CAM和HyCAM框架有效解决了LLMs在多任务适应中的挑战，实现了更高效和有效的适应，同时保持了良好的知识保留能力。

Abstract: Large Language Models (LLMs) possess remarkable generalization capabilities
but struggle with multi-task adaptation, particularly in balancing knowledge
retention with task-specific specialization. Conventional fine-tuning methods
suffer from catastrophic forgetting and substantial resource consumption, while
existing parameter-efficient methods perform suboptimally in complex multi-task
scenarios. To address this, we propose Contextual Attention Modulation (CAM), a
novel mechanism that dynamically modulates the representations of
self-attention modules in LLMs. CAM enhances task-specific features while
preserving general knowledge, thereby facilitating more effective and efficient
adaptation. For effective multi-task adaptation, CAM is integrated into our
Hybrid Contextual Attention Modulation (HyCAM) framework, which combines a
shared, full-parameter CAM module with multiple specialized, lightweight CAM
modules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.
Extensive experiments on heterogeneous tasks, including question answering,
code generation, and logical reasoning, demonstrate that our approach
significantly outperforms existing approaches, achieving an average performance
improvement of 3.65%. The implemented code and data are available to ease
reproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.

</details>


### [78] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 该论文发现视觉语言模型(VLMs)在输出错误答案时仍能感知到正确的视觉证据，这种现象称为"看见但不相信"。作者提出了一种无需训练的推理时干预方法，通过选择性注意力掩码来突出深层证据区域，从而提升多个VLM家族的准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在多模态任务上表现良好，但即使存在正确的视觉证据时仍会失败。作者希望系统性地研究这些失败是由于未能感知证据还是未能有效利用证据。

Method: 通过分析层间注意力动态，发现浅层主要关注文本，而深层稀疏但可靠地关注局部证据区域。提出推理时干预方法，通过选择性注意力掩码来突出深层证据区域。

Result: 该方法无需训练，在LLaVA、Qwen、Gemma和InternVL等多个VLM家族上一致提高了准确性。

Conclusion: VLMs在内部编码了可靠的证据但未能充分利用，通过使这些信号显式化可以弥合感知与推理之间的差距，推进对VLMs的诊断理解和可靠性。

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [79] [Enhancing Channel Estimation in RIS-aided Systems via Observation Matrix Design](https://arxiv.org/abs/2510.16576)
*Zijian Zhang,Mingyao Cui*

Main category: cs.IT

TL;DR: 提出一种基于贝叶斯优化的可重构智能表面信道估计观测矩阵设计方法，采用交替黎曼流形优化算法，显著提升信道估计精度


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)通过密集天线阵列增强无线通信性能，而准确的信道估计对其性能发挥至关重要

Method: 采用贝叶斯优化框架设计观测矩阵以最大化接收导频信号与RIS信道之间的互信息，提出交替黎曼流形优化算法交替更新接收机组合器和RIS相移矩阵，并引入自适应核训练策略迭代优化信道协方差矩阵

Result: 仿真结果表明，所提出的ARMO增强估计器在估计精度上相比最先进方法获得显著提升

Conclusion: 该方法能够有效提升RIS信道估计性能，无需额外导频资源

Abstract: Reconfigurable intelligent surfaces (RISs) have emerged as a promising
technology for enhancing wireless communications through dense antenna arrays.
Accurate channel estimation is critical to unlocking their full performance
potential. To enhance RIS channel estimators, this paper proposes a novel
observation matrix design scheme. Bayesian optimization framework is adopted to
generate observation matrices that maximize the mutual information between
received pilot signals and RIS channels. To solve the formulated problem
efficiently, we develop an alternating Riemannian manifold optimization (ARMO)
algorithm to alternately update the receiver combiners and RIS phase-shift
matrices. An adaptive kernel training strategy is further introduced to
iteratively refine the channel covariance matrix without requiring additional
pilot resources. Simulation results demonstrate that the proposed ARMO-enhanced
estimator achieves substantial gains in estimation accuracy over
state-of-the-art methods.

</details>


### [80] [A Semantic Generalization of Shannon's Information Theory and Applications](https://arxiv.org/abs/2510.15871)
*Chenguang Lu*

Main category: cs.IT

TL;DR: 本文提出了Shannon信息理论的语义泛化（G理论），用语义约束替代失真约束，通过真值函数作为语义通道来表达语义失真、语义信息度量和语义信息损失。该理论在机器学习、通信等多个领域有应用。


<details>
  <summary>Details</summary>
Motivation: 探讨语义通信是否需要独立于Shannon信息理论的语义信息理论，还是可以基于Shannon理论进行泛化。作者支持后一种观点。

Method: 引入语义约束替代失真约束，使用真值函数作为语义通道来定义语义失真、语义信息度量和语义信息损失。最大语义信息准则等价于最大似然准则。

Result: G理论可应用于日常和电子语义通信、机器学习、约束控制、贝叶斯确认、投资组合理论和信息价值评估。在机器学习中改进了多标签学习、分类、混合模型和潜变量求解方法。

Conclusion: G理论是Shannon信息理论的有效语义泛化，在多个领域有广泛应用，但存在复杂数据语义表示的局限性。文章还提出了将Friston最小自由能原理改进为最大信息效率原理。

Abstract: Does semantic communication require a semantic information theory parallel to
Shannon's information theory, or can Shannon's work be generalized for semantic
communication? This paper advocates for the latter and introduces a semantic
generalization of Shannon's information theory (G theory for short). The core
idea is to replace the distortion constraint with the semantic constraint,
achieved by utilizing a set of truth functions as a semantic channel. These
truth functions enable the expressions of semantic distortion, semantic
information measures, and semantic information loss. Notably, the maximum
semantic information criterion is equivalent to the maximum likelihood
criterion and similar to the Regularized Least Squares criterion. This paper
shows G theory's applications to daily and electronic semantic communication,
machine learning, constraint control, Bayesian confirmation, portfolio theory,
and information value. The improvements in machine learning methods involve
multilabel learning and classification, maximum mutual information
classification, mixture models, and solving latent variables. Furthermore,
insights from statistical physics are discussed: Shannon information is similar
to free energy; semantic information to free energy in local equilibrium
systems; and information efficiency to the efficiency of free energy in
performing work. The paper also proposes refining Friston's minimum free energy
principle into the maximum information efficiency principle. Lastly, it
compares G theory with other semantic information theories and discusses its
limitation in representing the semantics of complex data.

</details>


### [81] [Cluster-wise processing in fronthaul-aware cell-free massive MIMO systems](https://arxiv.org/abs/2510.16432)
*Zahra Mobini,Ahmet Hasim Gokceoglu,Li Wang,Gunnar Peters,Hyundong Shin,Hien Quoc Ngo*

Main category: cs.IT

TL;DR: 提出了一种基于集群架构的用户中心化无蜂窝大规模MIMO系统，通过不同接入点协作程度实现可扩展部署，解决了前传容量限制下的资源分配和预编码优化问题。


<details>
  <summary>Details</summary>
Motivation: 解决前传容量限制下的用户中心化无蜂窝大规模MIMO系统的可扩展实现问题，通过集群化处理来平衡性能与复杂度。

Method: 将接入点分组为多个处理集群，利用局部信道状态信息，采用改进的加权最小均方误差方法解决非凸混合整数优化问题，包括联合预编码、用户关联和功率分配。

Result: 开发了两种优化方案：一种在小尺度衰落时间尺度联合优化，另一种在大尺度衰落时间尺度优化用户关联和功率分配，有效逼近真实可达和速率。

Conclusion: 提出的集群架构和优化方法能够在前传容量限制下实现用户中心化无蜂窝大规模MIMO系统的可扩展部署，平衡了性能与计算复杂度。

Abstract: We exploit a general cluster-based network architecture for a
fronthaul-limited user-centric cell-free massive multiple-input multiple-output
(CF-mMIMO) system under different degrees of cooperation among the access
points (APs) to achieve scalable implementation. In particular, we consider a
CF-mMIMO system wherein the available APs are grouped into multiple processing
clusters (PCs) to share channel state information (CSI), ensuring that they
have knowledge of the CSI for all users assigned to the given cluster for the
purposes of designing resource allocation and precoding. We utilize the sum
pseudo-SE metric, which accounts for intra-cluster interference and
intercluster-leakage, providing a close approximation to the true sum
achievable SE. For a given PC, we formulate two optimization problems to
maximize the cluster-wise weighted sum pseudo-SE under fronthaul constraints,
relying solely on local CSI. These optimization problems are associated with
different computational complexity requirements. The first optimization problem
jointly designs precoding, user association, and power allocation, and is
performed at the small-scale fading time scale. The second optimization problem
optimizes user association and power allocation at the large-scale fading time
scale. Accordingly, we develop a novel application of modified weighted minimum
mean square error (WMMSE)-based approach to solve the challenging formulated
non-convex mixed-integer problems.

</details>


### [82] [Hybrid CNN-Transformer Based Sparse Channel Prediction for High-Mobility OTFS Systems](https://arxiv.org/abs/2510.16539)
*Zhaowei Guan,Wenkun Wen,Peiran Wu,Chen Wang,Minghua Xia*

Main category: cs.IT

TL;DR: 提出了一种基于CNN-Transformer混合架构的OTFS系统信道预测框架，在500km/h高速移动场景下显著优于现有方法，支持下一代无线网络的URLLC需求。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中的高速移动场景（如车联网）需要超可靠低延迟通信，但快速时变信道给传统OFDM系统带来挑战。OTFS调制通过在延迟-多普勒域表示信道来提供鲁棒性。

Method: 使用CNN-Transformer混合架构：CNN提取利用DD域信道矩阵稀疏性的紧凑特征，Transformer通过因果掩码建模时间依赖性以确保一致性。

Result: 在500km/h极端移动条件下的仿真实验表明，该方法优于最先进的基线方法，均方根误差和平均绝对误差分别降低了12.2%和9.4%。

Conclusion: 结果证明了DD域表示和所提模型在高速移动场景下准确预测信道的有效性，从而支持未来无线系统中严格的URLLC要求。

Abstract: High-mobility scenarios in next-generation wireless networks, such as those
involving vehicular communications, require ultra-reliable and low-latency
communications (URLLC). However, rapidly time-varying channels pose significant
challenges to traditional OFDM-based systems due to the Doppler effect and
channel aging. Orthogonal time frequency space (OTFS) modulation offers
resilience by representing channels in the quasi-static delay-Doppler (DD)
domain. This letter proposes a novel channel prediction framework for OTFS
systems using a hybrid convolutional neural network and transformer
(CNN-Transformer) architecture. The CNN extracts compact features that exploit
the DD-domain sparsity of the channel matrices, while the transformer models
temporal dependencies with causal masking for consistency. Simulation
experiments under extreme $500$ \si{km/h} mobility conditions demonstrate that
the proposed method outperforms state-of-the-art baselines, reducing the root
mean square error and mean absolute error by $12.2\%$ and $9.4\%$,
respectively. These results demonstrate the effectiveness of DD-domain
representations and the proposed model in accurately predicting channels in
high-mobility scenarios, thereby supporting the stringent URLLC requirements in
future wireless systems.

</details>


### [83] [Feedback Lunch: Deep Feedback Codes for Wiretap Channels](https://arxiv.org/abs/2510.16620)
*Yingyao Zhou,Natasha Devroye,Onur Günlü*

Main category: cs.IT

TL;DR: 提出了一种用于高斯窃听信道的模块化编码设计，结合通用哈希函数和学习型反馈编码，在信道输出反馈下实现正保密速率


<details>
  <summary>Details</summary>
Motivation: 解决反向退化窃听信道在无反馈时保密容量为零的问题，利用反馈使合法方共享密钥以克服窃听者的安全优势

Method: 采用基于种子的模块化编码设计，结合通用哈希函数保证安全性，学习型反馈编码保证可靠性

Result: 实现了正保密速率，展示了通信可靠性与信息泄露之间的权衡关系

Conclusion: 反馈机制使合法方能够协商共享密钥，为下一代集成感知与通信方法中的安全通信提供设计思路

Abstract: We consider reversely-degraded wiretap channels, for which the secrecy
capacity is zero if there is no channel feedback. This work focuses on a seeded
modular code design for the Gaussian wiretap channel with channel output
feedback, combining universal hash functions for security and learned
feedback-based codes for reliability to achieve positive secrecy rates. We
study the trade-off between communication reliability and information leakage,
illustrating that feedback enables agreeing on a secret key shared between
legitimate parties, overcoming the security advantage of the wiretapper. Our
findings also motivate code designs for sensing-assisted secure communication,
to be used in next-generation integrated sensing and communication methods.

</details>


### [84] [Non-Orthogonal Pilot Sequence Design for Multi-Cells Interference Networks](https://arxiv.org/abs/2510.16792)
*Zhi Gu,Wai Ho Mow*

Main category: cs.IT

TL;DR: 本文提出了多小区系统中扩展总平方相关(ETSC)的新序列设计准则，推导了ETSC的下界闭式表达式，并开发了ETSC-MM算法来生成低ETSC序列集。


<details>
  <summary>Details</summary>
Motivation: 在无线通信中，当用户数超过序列长度时，非正交序列集的性能显著影响多用户干扰水平。多小区系统中考虑本小区和邻小区信道强度差异，需要新的序列设计准则。

Method: 提出ETSC作为新序列设计准则，推导ETSC下界闭式表达式，并基于Majorization-Minimization优化框架开发ETSC-MM算法生成低ETSC序列集。

Result: 推导了ETSC下界的闭式表达式，这是对Welch界和扩展Welch界的推广。当干扰功率因子矩阵正定时，可以从边界必要条件轻松获得最优序列集。

Conclusion: ETSC准则和ETSC-MM算法为多小区系统提供了有效的非正交序列设计方法，能够降低多用户干扰并提高系统性能。

Abstract: In wireless communications, the performance of non-orthogonal sequence sets
significantly affects the level of multi-user interference when the number of
users surpasses the sequence length. The design of non-orthogonal sequences
plays a crucial role in both the non-orthogonality of the pilots in multi-cell
systems and the signature sequences in overloaded code-division multiple-access
(CDMA) systems. In multi-cell systems, considering the strength disparity
between channels originating from the home cell and the neighboring cells, the
extended total squared correlation (ETSC) is proposed as a new sequence design
criterion, which is defined as the sum of squares of the weighted correlations
among sequences. In this paper, we derive a closed-form expression for the
lower bound of ETSC for multi-cell systems with a given sequence length $\tau$,
where $\tau \leq K$ and $K$ is the number of users per cell. This can be
regarded as a generalization of the well-known Welch bound (Welch, 1974, IEEE
TIT) and the extended Welch bound (Wang et al., 2021, IEEE TWC). Additionally,
from the necessary conditions of the bound, the optimal sequence set can be
easily obtained when the interference power factor matrix is positive definite.
On the other hand, to address the lack of sequence generation methods under
certain parameter conditions, we propose the ETSC-MM algorithm, which generates
sequence sets with low ETSC based on a Majorization-Minimization (MM)
optimization framework.

</details>


### [85] [Unlocking Off-the-Grid Sparse Recovery with Unlimited Sensing: Simultaneous Super-Resolution in Time and Amplitude](https://arxiv.org/abs/2510.16948)
*Ruiming Guo,Ayush Bhandari*

Main category: cs.IT

TL;DR: 本文提出了一种基于无限制感知框架(USF)的数字超分辨率方法，通过模数编码增强测量精度，突破了传统量化限制，实现了幅度和时间维度的超分辨率恢复。


<details>
  <summary>Details</summary>
Motivation: 传统数字采集在处理强-弱幅度差异的脉冲信号时，会出现强分量削波或弱分量被量化噪声淹没的问题。在固定比特预算下，这种信息损失不可避免，因此需要同时解决幅度和时间结构的超分辨率问题。

Method: 采用无限制感知框架(USF)中的模数编码技术，开发了适用于非带限核的新理论结果，并提出了鲁棒的离网格稀疏恢复算法。

Result: 数值仿真和硬件实验验证了该方法在低位量化下的有效性，能够实现幅度和时间维度的超分辨率。

Conclusion: 无限制感知框架通过模数编码克服了传统数字采集的基本限制，为超分辨率问题提供了新的解决方案，特别适用于时间飞行成像等实际应用场景。

Abstract: The recovery of Dirac impulses, or spikes, from filtered measurements is a
classical problem in signal processing. As the spikes lie in the continuous
domain while measurements are discrete, this task is known as super-resolution
or off-the-grid sparse recovery. Despite significant theoretical and
algorithmic advances over the past decade, these developments often overlook
critical challenges at the analog-digital interface. In particular, when spikes
exhibit strong-weak amplitude disparity, conventional digital acquisition may
result in clipping of strong components or loss of weak ones beneath the
quantization noise floor. This motivates a broader perspective:
super-resolution must simultaneously resolve both amplitude and temporal
structure. Under a fixed bit budget, such information loss is unavoidable. In
contrast, the emerging theory and practice of the Unlimited Sensing Framework
(USF) demonstrate that these fundamental limitations can be overcome. Building
on this foundation, we demonstrate that modulo encoding within USF enables
digital super-resolution by enhancing measurement precision, thereby unlocking
temporal super-resolution beyond conventional limits. We develop new
theoretical results that extend to non-bandlimited kernels commonly encountered
in practice and introduce a robust algorithm for off-the-grid sparse recovery.
To demonstrate practical impact, we instantiate our framework in the context of
time-of-flight imaging. Both numerical simulations and hardware experiments
validate the effectiveness of our approach under low-bit quantization, enabling
super-resolution in amplitude and time.

</details>


### [86] [Channel Capacity for FMCW-based Optical Wireless Integrated Sensing and Communication: Asymptotic Analysis and Envelope Design](https://arxiv.org/abs/2510.17093)
*Yunfeng Wen,Fang Yang,Jian Song,Zhu Han*

Main category: cs.IT

TL;DR: 本文分析了基于FMCW的相干光无线集成感知与通信系统的信道容量，推导了感知约束下的容量上下界，并提出了脉冲幅度调制的包络设计指导。


<details>
  <summary>Details</summary>
Motivation: 光无线集成感知与通信(OW-ISAC)作为射频对应技术的补充和增强正在快速发展，需要分析信道容量来指导系统设计。

Method: 将FMCW基OW-ISAC系统模型重新表述为信息论框架，施加谐波均值约束确保感知性能，推导信道容量上下界，提出脉冲幅度调制的包络设计。

Result: 获得了低信噪比和高信噪比区域的渐近容量表达式，数值结果验证了容量实现能力，仿真揭示了通信与感知功能之间的权衡。

Conclusion: 在感知约束下的信道容量分析为OW-ISAC设计的最优性和实用性提供了重要见解。

Abstract: Optical wireless integrated sensing and communication (OW-ISAC) is rapidly
burgeoning as a complement and augmentation to its radio-frequency counterpart.
In this paper, the channel capacity is analyzed to guide the design of a
coherent OW-ISAC system based on frequency-modulated continuous wave (FMCW).
Firstly, the system model of FMCW-based OW-ISAC is recast into an
information-theoretic formulation, where an additional harmonic-mean constraint
is imposed to ensure the sensing performance. Subsequently, both lower and
upper bounds for channel capacity are derived under the imposed sensing
constraint, based on which asymptotic expressions for channel capacity are
presented for both low and high signal-to-noise-ratio regions. Moreover, the
analysis of channel capacity provides guidance for the envelope design based on
pulse amplitude modulation, whose capacity-achieving capabilities are
demonstrated by numerical results. Furthermore, simulations reveal the
trade-off between communication and sensing functionalities. In summary, the
analysis of channel capacity under the sensing constraint provides insights
into both the optimality and the practicality of OW-ISAC design.

</details>


### [87] [Delay-Doppler Pulse Shaping in Zak-OTFS Using Hermite Basis Functions](https://arxiv.org/abs/2510.17466)
*Fathima Jesbin,Ananthanarayanan Chockalingam*

Main category: cs.IT

TL;DR: 提出了一种基于Hermite基函数的系统化DD脉冲设计框架，通过约束优化最小化符号间干扰能量，在Zak-OTFS调制中实现了优于传统sinc和高斯脉冲的性能。


<details>
  <summary>Details</summary>
Motivation: Zak-OTFS调制性能高度依赖于DD域脉冲成形滤波器的选择，需要在时间-频率定位和正交性之间进行权衡。传统sinc和高斯脉冲代表了这种权衡的两个极端，需要一种更灵活的设计方法。

Method: 将脉冲表示为Hermite基函数的线性组合，通过奇异值分解求解约束优化问题，获得最小化符号间干扰能量的最优系数。

Result: 仿真结果表明，优化脉冲在Vehicular-A信道中显著优于传统sinc和高斯脉冲，与最先进的GS脉冲性能相当，同时提供更好的ISI和旁瓣能量控制灵活性。

Conclusion: 提出的Hermite脉冲设计框架为Zak-OTFS提供了系统化的脉冲设计方法，在保持性能的同时提供了更大的设计灵活性。

Abstract: The performance of Zak-OTFS modulation is critically dependent on the choice
of the delay-Doppler (DD) domain pulse shaping filter. The design of pulses for
$L^2(\mathbb{R})$ is constrained by the Balian-Low Theorem, which imposes an
inescapable trade-off between time-frequency localization and orthogonality for
spectrally efficient systems. In Zak-OTFS, this trade-off requires balancing
the need for localization for input/output (I/O) relation estimation with the
need for orthogonality for reliable data detection when operating without time
or bandwidth expansion. The well-known sinc and Gaussian pulse shapes represent
the canonical extremes of this trade-off, while composite constructions such as
the Gaussian-sinc (GS) pulse shape offer a good compromise. In this work, we
propose a systematic DD pulse design framework for Zak-OTFS that expresses the
pulse as a linear combination of Hermite basis functions. We obtain the optimal
coefficients for the Hermite basis functions that minimize the inter-symbol
interference (ISI) energy at the DD sampling points by solving a constrained
optimization problem via singular value decomposition. For the proposed class
of Hermite pulses, we derive closed-form expressions for the I/O relation and
noise covariance in Zak-OTFS. Simulation results of Zak-OTFS with embedded
pilot and model-free I/O relation estimation in Vehicular-A channels with
fractional DDs demonstrate that the optimized pulse shape achieves a bit error
rate performance that is significantly superior compared to those of the
canonical sinc and Gaussian pulses and is on par with that of the
state-of-the-art GS pulse, validating the proposed framework which provides
greater design flexibility in terms of control of ISI and sidelobe energies.

</details>


### [88] [Multihead Finite-State Compression](https://arxiv.org/abs/2510.17544)
*Neil Lutz*

Main category: cs.IT

TL;DR: 本文开发了多头有限状态压缩模型，作为有限状态压缩的推广，与Huang等人(2025)的多头有限状态维度互补。主要定理证明对于任何序列和正整数h，h头有限状态无损压缩器达到的压缩比率下确界等于该序列的h头有限状态预维度。


<details>
  <summary>Details</summary>
Motivation: 推广传统的有限状态压缩模型，引入多个读头的概念，研究在多个有限状态读头同时扫描序列的情况下能达到的最优压缩比率。

Method: 使用多头有限状态压缩器模型，其中压缩器根据固定数量的有限状态读头向前扫描序列时读取的符号，按照有限状态规则产生输出。

Result: 主要定理证明：对于任何序列和正整数h，h头有限状态无损压缩器达到的压缩比率下确界等于该序列的h头有限状态预维度。

Conclusion: 多头有限状态压缩比率的下确界与多头有限状态维度理论中的预维度概念完全对应，为压缩理论与维度理论建立了重要联系。

Abstract: This paper develops multihead finite-state compression, a generalization of
finite-state compression, complementary to the multihead finite-state
dimensions of Huang, Li, Lutz, and Lutz (2025). In this model, an infinite
sequence of symbols is compressed by a compressor that produces outputs
according to finite-state rules, based on the symbols read by a constant number
of finite-state read heads moving forward obliviously through the sequence. The
main theorem of this work establishes that for every sequence and every
positive integer $h$, the infimum of the compression ratios achieved by
$h$-head finite-state information-lossless compressors equals the $h$-head
finite-state predimension of the sequence. As an immediate corollary, the
infimum of these ratios over all $h$ is the multihead finite-state dimension of
the sequence.

</details>


### [89] [Mode Switching-based STAR-RIS with Discrete Phase Shifters](https://arxiv.org/abs/2510.17613)
*MohammadHossein Alishahi,Ming Zeng,Paul Fortier,Ji Wang,Nian Xia,Gongpu Wang*

Main category: cs.IT

TL;DR: 提出了一种用于6G物联网系统的模式切换离散相移STAR-RIS辅助多天线接入点网络的联合优化方法，通过混合整数非线性优化框架最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 6G网络对成本效益高、高速物联网应用的需求日益增长，需要提高频谱效率并简化硬件设计。

Method: 采用块坐标下降法，将问题分解为三个子问题，分别使用差分凹规划和组合优化技术求解主动波束成形矩阵、用户功率分配和STAR-RIS相移向量。

Result: 数值结果验证了所提联合优化方法的有效性，相比部分优化方法始终获得更优的和速率性能。

Conclusion: 该方法展示了在高效和可扩展6G物联网系统中的潜力。

Abstract: The increasing demand for cost-effective, high-speed Internet of Things (IoT)
applications in the coming sixth-generation (6G) networks has driven research
toward maximizing spectral efficiency and simplifying hardware designs. In this
context, we investigate the sum rate maximization problem for a mode-switching
discrete-phase shifters simultaneously transmitting and reflecting
reconfigurable intelligent surface (STAR-RIS)-aided multi-antenna access point
network, emphasizing hardware efficiency and reduced cost. A mixed-integer
nonlinear optimization framework is formulated for joint optimization of the
active beamforming matrix, user power allocation, and STAR-RIS phase shift
vectors, including binary transmission/reflection amplitudes and discrete phase
shifters. To solve the formulated problem, we employ a block coordinate descent
method, dividing it into three subproblems tackled using difference-of-concave
programming and combinatorial optimization techniques. Numerical results
validate the effectiveness of the proposed joint optimization approach,
consistently achieving superior sum rate performance compared to partial
optimization methods, thereby underscoring its potential for efficient and
scalable 6G IoT systems.

</details>


### [90] [Space-Time Rate-Splitting Multiple Access for Multibeam LEO Satellite Networks](https://arxiv.org/abs/2510.17625)
*Jaehyup Seong,Byungju Lee,Aryan Kaushik,Wonjae Shin*

Main category: cs.IT

TL;DR: 提出了一种新颖的时空速率分割多址(ST-RSMA)框架，将空时编码集成到公共流传输中，为多波束低地球轨道卫星通信系统提供全分集增益。


<details>
  <summary>Details</summary>
Motivation: 克服传统RSMA使用单一波束成形向量带来的性能限制，解决信道状态信息不确定性和网络负载变化下的性能下降问题。

Method: 开发基于加权最小均方误差(WMMSE)的算法，联合优化公共流的功率分配和私有流的功率/波束成形向量，以最大化最小用户速率。

Result: 数值结果表明ST-RSMA显著优于传统RSMA和其他多址技术，为LEO卫星通信提供了鲁棒且可扩展的解决方案。

Conclusion: ST-RSMA框架通过集成空时编码实现了全分集增益，在不确定信道条件和网络负载下表现出优越性能，是LEO卫星通信的有效解决方案。

Abstract: This paper proposes a novel space-time rate-splitting multiple access
(ST-RSMA) framework for multibeam low Earth orbit (LEO) satellite
communications (SATCOM) systems, where space-time coding is integrated into the
common stream transmission. This design enables full diversity gain in the
common stream transmission for all users, regardless of the uncertainty of the
channel state information (CSI) and network load conditions, thereby overcoming
the performance limitations of conventional RSMA that employs a single
beamforming vector for all users. To further enhance performance, we develop a
weighted minimum mean square error (WMMSE)-based algorithm tailored to ST-RSMA
that jointly optimizes the power allocation for the common stream and the
power/beamforming vectors for private streams, aiming to maximize the minimum
user rate. Numerical results show that ST-RSMA significantly outperforms
conventional RSMA and other multiple access techniques, offering a robust and
scalable solution for LEO SATCOM.

</details>


### [91] [On the Capacity of Erasure-prone Quantum Storage with Erasure-prone Entanglement Assistance](https://arxiv.org/abs/2510.17781)
*Hua Sun,Syed A. Jafar*

Main category: cs.IT

TL;DR: 该论文研究了量子存储编码的容量问题，其中量子消息被编码到N个存储节点和NB个纠缠辅助节点中，要求从任意K个存储节点和任意KB个纠缠辅助节点中恢复量子消息。


<details>
  <summary>Details</summary>
Motivation: 研究在存储节点和纠缠辅助节点都可能发生擦除的情况下，量子消息的存储容量问题，为量子存储系统设计提供理论基础。

Method: 引入了类似的经典存储问题，识别出一组约束条件，使得经典线性码构造可以转化为量子存储码，并对两种设置使用相似的推理进行逆向界限分析。

Result: 在大多数情况下，精确刻画了容量作为N,K,NB,KB,λB的函数，但在一个中间范围的λB值下容量仍未解决。

Conclusion: 经典和量子设置的容量表征在所有容量已确定的情况下被证明是相同的，为量子存储编码设计提供了重要理论基础。

Abstract: A quantum message is encoded into $N$ storage nodes (quantum systems
$Q_1\dots Q_N$) with assistance from $N_B$ maximally entangled bi-partite
quantum systems $A_1B_1, \dots, A_{N_B}B_{N_B}$, that are prepared in advance
such that $B_1\dots B_{N_B}$ are stored separately as entanglement assistance
(EA) nodes, while $A_1\dots A_{N_B}$ are made available to the encoder. Both
the storage nodes and EA nodes are erasure-prone. The quantum message must be
recoverable given any $K$ of the $N$ storage nodes along with any $K_B$ of the
$N_B$ EA nodes. The capacity for this setting is the maximum size of the
quantum message, given that the size of each EA node is $\lambda_B$. All node
sizes are relative to the size of a storage node, which is normalized to unity.
The exact capacity is characterized as a function of $N,K,N_B,K_B, \lambda_B$
in all cases, with one exception. The capacity remains open for an intermediate
range of $\lambda_B$ values when a strict majority of the $N$ storage nodes,
and a strict non-zero minority of the $N_B$ EA nodes, are erased. As a key
stepping stone, an analogous classical storage (with shared-randomness
assistance) problem is introduced. A set of constraints is identified for the
classical problem, such that classical linear code constructions translate to
quantum storage codes, and the converse bounds for the two settings utilize
similar insights. In particular, the capacity characterizations for the
classical and quantum settings are shown to be identical in all cases where the
capacity is settled.

</details>
