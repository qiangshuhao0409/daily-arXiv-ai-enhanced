<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.IT](#cs.IT) [Total: 10]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks](https://arxiv.org/abs/2507.17188)
*Lijie Zheng,Ji He,Shih Yu Chang,Yulong Shen,Dusit Niyato*

Main category: cs.NI

TL;DR: 本文提出了一种层次化优化框架，结合大语言模型引导的启发式多智能体强化学习方法，解决异构无人机网络中在推进能耗约束下最大化保密速率的物理层安全问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设无人机能力统一或忽略能耗-安全权衡，本文考虑具有不同载荷和计算资源的异构无人机在窃听者存在情况下协作服务地面终端的现实场景，需要解决无人机运动与通信之间的复杂耦合问题。

Method: 提出层次化优化框架：内层使用基于半定松弛(SDR)的S2DC算法，结合惩罚函数和凸差分编程解决固定无人机位置下的保密预编码问题；外层引入大语言模型引导的启发式多智能体强化学习方法(LLM-HeMARL)进行轨迹优化，有效整合LLM生成的专家启发式策略。

Result: 仿真结果表明，该方法在保密速率和能效方面优于现有基准方法，在不同无人机群规模和随机种子下表现出一致的鲁棒性。

Conclusion: 所提出的层次化优化框架能够有效解决异构无人机网络中的物理层安全问题，在保密速率和能效之间实现良好平衡，LLM-HeMARL方法能够学习到能耗感知、安全驱动的轨迹策略。

Abstract: This work tackles the physical layer security (PLS) problem of maximizing the
secrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy
constraints. Unlike prior studies that assume uniform UAV capabilities or
overlook energy-security trade-offs, we consider a realistic scenario where
UAVs with diverse payloads and computation resources collaborate to serve
ground terminals in the presence of eavesdroppers. To manage the complex
coupling between UAV motion and communication, we propose a hierarchical
optimization framework. The inner layer uses a semidefinite relaxation
(SDR)-based S2DC algorithm combining penalty functions and difference-of-convex
(d.c.) programming to solve the secrecy precoding problem with fixed UAV
positions. The outer layer introduces a Large Language Model (LLM)-guided
heuristic multi-agent reinforcement learning approach (LLM-HeMARL) for
trajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics
policy generated by the LLM, enabling UAVs to learn energy-aware,
security-driven trajectories without the inference overhead of real-time LLM
calls. The simulation results show that our method outperforms existing
baselines in secrecy rate and energy efficiency, with consistent robustness
across varying UAV swarm sizes and random seeds.

</details>


### [2] [Closed-Form and Boundary Expressions for Task-Success Probability in Status-Driven Systems](https://arxiv.org/abs/2507.17195)
*Jianpeng Qi,Chao Liu,Rui Wang,Junyu Dong,Yanwei Yu*

Main category: cs.NI

TL;DR: 本文提出了一个统一的分析框架，用于建模计算优先网络系统中任务成功概率，该框架通过拉普拉斯变换处理网络延迟，并给出了闭式表达式和上下界，在各种参数下准确度达到0.01-0.016的误差范围。


<details>
  <summary>Details</summary>
Motivation: 在计算优先网络系统中，服务器状态的及时高效传播至关重要，但由于随机到达、有限服务器容量和双向链路延迟等因素，建模任务成功概率变得复杂，现有方法难以准确分析这些复杂交互因素。

Method: 提出统一分析框架，将接入点转发规则抽象为单一概率，通过拉普拉斯变换对所有网络和等待延迟进行建模，得到端到端任务成功概率的闭式表达式，并建立包含Erlang损失阻塞、信息陈旧性和随机上下行延迟的上下界。

Result: 理论预测和界限始终包围观测到的成功率，上界准确度达到0.01，下界准确度达到0.016。框架仅需要两个可互换输入（转发概率和延迟变换），使其易于适应不同的转发策略和延迟分布。

Conclusion: 该框架成功地为计算优先网络系统中的任务成功概率提供了准确的理论分析工具，具有良好的适应性和实用性，为此类系统的设计和优化提供了理论基础。

Abstract: Timely and efficient dissemination of server status is critical in
compute-first networking systems, where user tasks arrive dynamically and
computing resources are limited and stochastic. In such systems, the access
point plays a key role in forwarding tasks to a server based on its latest
received server status. However, modeling the task-success probability
suffering the factors of stochastic arrivals, limited server capacity, and
bidirectional link delays. Therefore, we introduce a unified analytical
framework that abstracts the AP forwarding rule as a single probability and
models all network and waiting delays via their Laplace transforms. This
approach yields a closed form expression for the end to end task success
probability, together with upper and lower bounds that capture Erlang loss
blocking, information staleness, and random uplink/downlink delays. We validate
our results through simulations across a wide range of parameters, showing that
theoretical predictions and bounds consistently enclose observed success rates.
Our framework requires only two interchangeable inputs (the forwarding
probability and the delay transforms), making it readily adaptable to
alternative forwarding policies and delay distributions. Experiments
demonstrate that our bounds are able to achieve accuracy within 0.01 (upper
bound) and 0.016 (lower bound) of the empirical task success probability.

</details>


### [3] [Custody Transfer and Compressed Status Reporting for Bundle Protocol Version 7](https://arxiv.org/abs/2507.17403)
*Alice Le Bihan,Felix Flentge,Juan A. Fraire*

Main category: cs.NI

TL;DR: 本文提出了一种用于BPv7的新托管传输机制，通过序列编号高效识别数据包集合，引入压缩托管信号和压缩报告扩展块，以解决空间网络中断/延迟容忍网络(DTN)的可靠性传输问题。


<details>
  <summary>Details</summary>
Motivation: 随着空间任务增加，需要用高效可靠的网络中心通信方法替代点对点通信。BPv7移除了BPv6中的托管传输机制，需要单独定义相应的可靠性扩展来确保数据包在间歇性连接和长延迟环境下的可靠传输。

Method: 设计了新的BPv7托管传输过程，包括：(1)通过序列编号高效识别数据包集合的策略；(2)新的托管传输扩展块和对应的压缩托管信号管理记录；(3)新的压缩报告扩展块，使用序列编号请求数据包处理步骤报告。

Result: 该机制已在ESA BP实现中原型化，并在地球观测和月球通信仿真场景中进行了测试。测试结果证明了该方法的有效性，为DTN可靠传输领域的未来工作提供了基础。

Conclusion: 新的BPv7托管传输机制通过序列编号和压缩信号有效解决了空间网络环境下的可靠性传输问题，预计将于2025年由CCSDS发布为实验性规范，为未来地球观测和火星通信场景提供了可行的解决方案。

Abstract: As space missions increase, there is a growing need to replace point-to-point
communication with an efficient and reliable network-centric communication
approach. Disruption/Delay Tolerant Networking (DTN) with the Bundle Protocol
(BP) has been selected as an interoperable network protocol in the LunaNet
Interoperability Specification. It is also considered for future Earth
Observation and Mars communication scenarios. In a DTN, the "bundle" -- the
fundamental data unit of BP -- requires dedicated mechanisms to ensure
reliability due to the challenges posed by intermittent connectivity and long
delays. The previous version of BP, BPv6, contained a mechanism for reliable
transfer between "custodial nodes" called "custody transfer". However, this
approach has been removed from the core protocol specification for BPv7, which
requires a corresponding BP reliability extension to be defined separately.
This paper introduces a new custody transfer process for BPv7 (expected to be
published by CCSDS as an experimental specification in 2025). The core features
of this new custody transfer method for BPv7 are: (1) A strategy to efficiently
identify sets of bundles by sequence numbering (2) A new Custody Transfer
Extension Block and a corresponding administrative record, Compressed Custody
Signal, to efficiently report on the acceptance or rejection of custody using
sequence numbering (3) A new Compressed Reporting Extension Block requesting
reporting on bundle processing steps using a corresponding administrative
record with sequence numbering for efficiency. The paper will describe those
concepts and their design, specification, and implementation in detail. These
mechanisms have been prototyped in the ESA BP implementation and tested in
Earth Observation and Lunar communication simulation scenarios. The results
will be presented, as will an outlook on future work in the DTN reliable
transfer domain.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [Our Cars Can Talk: How IoT Brings AI to Vehicles](https://arxiv.org/abs/2507.17214)
*Amod Kant Agrawal*

Main category: cs.AI

TL;DR: 本文提出将AI集成到车辆中作为感知平台，实现从被动维护向主动维护的转变，并开发能够与机器和驾驶员双向沟通的AI副驾驶系统


<details>
  <summary>Details</summary>
Motivation: 传统车辆维护模式是被动的，需要转变为主动预测性维护；同时需要AI系统能够同时理解机器语言和人类驾驶员语言，实现更好的人机交互

Method: 将AI技术集成到车辆中，使车辆成为智能感知平台，开发能够进行双语言交互（机器语言和驾驶员语言）的AI副驾驶系统

Result: 提供了智能车辆系统、预测性维护和AI驱动用户交互方面的概念性和技术性观点，为跨学科对话提供基础

Conclusion: 现在是整合AI副驾驶的关键时机，这将推动智能车辆系统、预测性维护和AI用户交互领域的未来研究和发展

Abstract: Bringing AI to vehicles and enabling them as sensing platforms is key to
transforming maintenance from reactive to proactive. Now is the time to
integrate AI copilots that speak both languages: machine and driver. This
article offers a conceptual and technical perspective intended to spark
interdisciplinary dialogue and guide future research and development in
intelligent vehicle systems, predictive maintenance, and AI-powered user
interaction.

</details>


### [5] [Towards Autonomous Sustainability Assessment via Multimodal AI Agents](https://arxiv.org/abs/2507.17012)
*Zhihan Zhang,Alexander Metzger,Yuxuan Mei,Felix Hähnlein,Zachary Englhardt,Tingyu Cheng,Gregory D. Abowd,Shwetak Patel,Adriana Schulz,Vikram Iyer*

Main category: cs.AI

TL;DR: 该研究通过多模态AI代理重新构想传统生命周期评估(LCA)，利用在线文本和图像数据快速计算电子设备的碳排放，将专家需要数周或数月的工作时间缩短至1分钟内，同时保持较高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统LCA需要大量的材料和工艺数据来评估产品从制造到处置的环境影响，但这些数据往往难以获得，导致可持续性信息评估面临数据可用性gap的挑战。

Method: 1）构建多模态AI代理模拟LCA专家与产品经理、工程师的交互；2）利用定制数据抽象和软件工具从在线文本、图像、维修社区和政府认证中提取信息；3）开发基于产品描述聚类的直接环境影响估算方法；4）开发数据驱动的排放因子生成方法，将未知材料表示为相似材料排放因子的加权和。

Result: 1）AI代理方法将LCA时间从数周/数月缩短至1分钟内；2）在零专有数据情况下，碳足迹估算误差在专家LCA的19%以内；3）直接估算方法在笔记本电脑上3毫秒内完成，电子产品MAPE为12.28%；4）数据驱动排放因子生成方法比人类专家选择最接近的LCA数据库条目提高MAPE 120.26%。

Conclusion: 该研究成功开发了基于AI的快速LCA方法，显著提高了效率并保持了较高准确性，为未来LCA工作流程提供了新的解决方案，有助于解决可持续性评估中的数据可用性问题。

Abstract: Interest in sustainability information has surged in recent years. However,
the data required for a life cycle assessment (LCA) that maps the materials and
processes from product manufacturing to disposal into environmental impacts
(EI) are often unavailable. Here we reimagine conventional LCA by introducing
multimodal AI agents that emulate interactions between LCA experts and
stakeholders like product managers and engineers to calculate the
cradle-to-gate (production) carbon emissions of electronic devices. The AI
agents iteratively generate a detailed life-cycle inventory leveraging a custom
data abstraction and software tools that extract information from online text
and images from repair communities and government certifications. This approach
reduces weeks or months of expert time to under one minute and closes data
availability gaps while yielding carbon footprint estimates within 19% of
expert LCAs with zero proprietary data. Additionally, we develop a method to
directly estimate EI by comparing an input to a cluster of products with
similar descriptions and known carbon footprints. This runs in 3 ms on a laptop
with a MAPE of 12.28% on electronic products. Further, we develop a data-driven
method to generate emission factors. We use the properties of an unknown
material to represent it as a weighted sum of emission factors for similar
materials. Compared to human experts picking the closest LCA database entry,
this improves MAPE by 120.26%. We analyze the data and compute scaling of this
approach and discuss its implications for future LCA workflows.

</details>


### [6] [New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding](https://arxiv.org/abs/2507.17054)
*Shao-Hung Chan,Thomy Phan,Jiaoyang Li,Sven Koenig*

Main category: cs.AI

TL;DR: 本文针对多智能体路径规划(MAPF)问题，改进了EECBS算法中的flex分配机制，提出了基于冲突数量和延迟估计的分配策略，以及混合策略框架，在保证有界次优解的同时提高算法效率。


<details>
  <summary>Details</summary>
Motivation: 现有EECBS算法使用贪心flex分配策略时，增加阈值可能使路径成本超出界限，导致算法在不同路径集合间频繁切换而非专注解决特定集合的冲突，从而降低效率。

Method: 提出三种新的flex分配机制：1）基于冲突的flex分配（按冲突数量比例分配）；2）基于延迟的flex分配（估计满足约束所需延迟）；3）混合策略flex分配（在层次框架中结合前两种方法）。

Result: 实验结果表明，所提出的flex分配方法在性能上优于原始的贪心flex分配策略，同时保持了算法的完整性和有界次优性。

Conclusion: 新提出的flex分配机制有效解决了原有方法的效率问题，在保证EECBS算法理论性质的前提下，显著提升了多智能体路径规划的求解效率。

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths, one for each agent in a shared environment. Its objective
is to minimize the sum of path costs (SOC), where the path cost of each agent
is defined as the travel time from its start location to its target location.
Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for
bounded-suboptimal MAPF, with the SOC of the solution being at most a
user-specified factor $w$ away from optimal. EECBS maintains sets of paths and
a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of
paths whose SOC is at most $w \cdot LB$ and introduces constraints to resolve
collisions. For each path in a set, EECBS maintains a lower bound on its
optimal path that satisfies constraints. By finding an individually
bounded-suboptimal path with cost at most a threshold of $w$ times its lower
bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up
EECBS, previous work uses flex distribution to increase the threshold. Though
EECBS with flex distribution guarantees to find a bounded-suboptimal solution,
increasing the thresholds may push the SOC beyond $w \cdot LB$, forcing EECBS
to switch among different sets of paths instead of resolving collisions on a
particular set of paths, and thus reducing efficiency. To address this issue,
we propose Conflict-Based Flex Distribution that distributes flex in proportion
to the number of collisions. We also estimate the delays needed to satisfy
constraints and propose Delay-Based Flex Distribution. On top of that, we
propose Mixed-Strategy Flex Distribution, combining both in a hierarchical
framework. We prove that EECBS with our new flex distribution mechanisms is
complete and bounded-suboptimal. Our experiments show that our approaches
outperform the original (greedy) flex distribution.

</details>


### [7] [LoRA is All You Need for Safety Alignment of Reasoning LLMs](https://arxiv.org/abs/2507.17075)
*Yihao Xue,Baharan Mirzasoleiman*

Main category: cs.AI

TL;DR: 该论文提出使用LoRA进行安全对齐微调可以在不损害推理能力的情况下有效提升大语言模型的安全性，解决了"安全税"问题


<details>
  <summary>Details</summary>
Motivation: 传统的安全对齐微调会显著降低大语言模型的推理能力，产生"安全税"现象。需要找到一种既能保证模型安全性又不损害推理能力的方法

Method: 使用LoRA（低秩适应）技术在拒绝数据集上进行监督微调，将安全权重更新限制在低秩空间中，以最小化对推理权重的干扰。还探索了通过正则化或权重合并进一步减少权重重叠的方法

Result: 在数学、科学和编程四个基准测试中的广泛实验表明，该方法能够产生高度安全的大语言模型，安全水平与全模型微调相当，但不会损害推理能力。LoRA相比全模型微调产生与初始权重重叠更小的权重更新

Conclusion: 使用LoRA进行安全对齐是一种有效的方法，可以在维持推理能力的同时实现模型安全对齐，为设计更好的推理-安全权衡方法提供了启发

Abstract: Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex
problems that were previously out of reach. To ensure LLMs do not assist with
harmful requests, safety alignment fine-tuning is necessary in the
post-training phase. However, safety alignment fine-tuning has recently been
shown to significantly degrade reasoning abilities, a phenomenon known as the
"Safety Tax". In this work, we show that using LoRA for SFT on refusal datasets
effectively aligns the model for safety without harming its reasoning
capabilities. This is because restricting the safety weight updates to a
low-rank space minimizes the interference with the reasoning weights. Our
extensive experiments across four benchmarks covering math, science, and coding
show that this approach produces highly safe LLMs -- with safety levels
comparable to full-model fine-tuning -- without compromising their reasoning
abilities. Additionally, we observe that LoRA induces weight updates with
smaller overlap with the initial weights compared to full-model fine-tuning. We
also explore methods that further reduce such overlap -- via regularization or
during weight merging -- and observe some improvement on certain tasks. We hope
this result motivates designing approaches that yield more consistent
improvements in the reasoning-safety trade-off.

</details>


### [8] [HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study](https://arxiv.org/abs/2507.17118)
*Mandar Pitale,Jelena Frtunikj,Abhinaw Priyadershi,Vasu Singh,Maria Spence*

Main category: cs.AI

TL;DR: 本文提出了HySAFE-AI框架，用于评估端到端AI系统（如大语言模型和视觉语言模型）的安全性，改进了传统的FMEA和FTA分析方法以适应基础模型的复杂性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在自动驾驶和机器人等安全关键领域的广泛应用，特别是端到端单体架构（如LLMs和VLMs）的兴起，传统的安全分析方法难以应对这些复杂基础模型的内在特性和潜在表示机制，亟需新的安全评估框架。

Method: 作者首先回顾了不同的架构解决方案，然后评估了常见安全分析技术（FMEA和FTA）的有效性。针对基础模型的复杂性，特别是其潜在表示的形成和利用方式，改进了这些传统技术，并提出了HySAFE-AI（AI系统混合安全架构分析框架）。

Result: 成功开发了HySAFE-AI混合框架，该框架能够适配传统方法来评估AI系统的安全性，为端到端AI架构提供了更有效的安全分析工具。

Conclusion: HySAFE-AI框架为AI系统安全评估提供了新的解决方案，作者还提出了未来工作的方向和建议，以指导未来AI安全标准的发展。

Abstract: AI has become integral to safety-critical areas like autonomous driving
systems (ADS) and robotics. The architecture of recent autonomous systems are
trending toward end-to-end (E2E) monolithic architectures such as large
language models (LLMs) and vision language models (VLMs). In this paper, we
review different architectural solutions and then evaluate the efficacy of
common safety analyses such as failure modes and effect analysis (FMEA) and
fault tree analysis (FTA). We show how these techniques can be improved for the
intricate nature of the foundational models, particularly in how they form and
utilize latent representations. We introduce HySAFE-AI, Hybrid Safety
Architectural Analysis Framework for AI Systems, a hybrid framework that adapts
traditional methods to evaluate the safety of AI systems. Lastly, we offer
hints of future work and suggestions to guide the evolution of future AI safety
standards.

</details>


### [9] [Improving LLMs' Generalized Reasoning Abilities by Graph Problems](https://arxiv.org/abs/2507.17168)
*Qifan Zhang,Nuo Chen,Zehua Li,Miao Peng,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: 本文提出使用图问题推理(GPR)来增强大语言模型的通用推理能力，构建了首个大规模GPR语料库GraphPile，并训练了GraphMind模型，在数学和非数学推理任务上都取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在新颖复杂问题上推理能力不足，领域特定的持续预训练方法(如数学推理)缺乏向更广泛推理任务的可迁移性，需要一种能够提升通用推理能力的方法。

Method: 首次使用图问题推理(GPR)来增强LLM的通用推理能力。构建了GraphPile数据集，包含109亿个token，涵盖23个图任务，包括路径查找、网络分析、数值计算和拓扑推理等。数据集包含思维链、程序思维、执行轨迹和真实世界图数据。使用该数据集在Llama 3/3.1和Gemma 2等基础模型上训练GraphMind。

Result: GraphMind在数学推理任务上准确率提升高达4.9%，在逻辑推理和常识推理等非数学推理任务上提升高达21.2%。这是首个利用GPR增强推理模式的工作，也是首个此类数据集。

Conclusion: 本工作通过图问题推理成功弥合了领域特定预训练与通用推理能力之间的差距，提升了大语言模型的适应性和鲁棒性，为增强LLM推理能力提供了新的有效途径。

Abstract: Large Language Models (LLMs) have made remarkable strides in reasoning tasks,
yet their performance often falters on novel and complex problems.
Domain-specific continued pretraining (CPT) methods, such as those tailored for
mathematical reasoning, have shown promise but lack transferability to broader
reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning
(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,
spanning pathfinding, network analysis, numerical computation, and topological
reasoning, require sophisticated logical and relational reasoning, making them
ideal for teaching diverse reasoning patterns. To achieve this, we introduce
GraphPile, the first large-scale corpus specifically designed for CPT using GPR
data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes
chain-of-thought, program-of-thought, trace of execution, and real-world graph
data. Using GraphPile, we train GraphMind on popular base models Llama 3 and
3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in
mathematical reasoning and up to 21.2 percent improvement in non-mathematical
reasoning tasks such as logical and commonsense reasoning. By being the first
to harness GPR for enhancing reasoning patterns and introducing the first
dataset of its kind, our work bridges the gap between domain-specific
pretraining and universal reasoning capabilities, advancing the adaptability
and robustness of LLMs.

</details>


### [10] [Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks](https://arxiv.org/abs/2507.17695)
*Ilias Chatzistefanidis,Navid Nikaein*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型(LLM)和实时优化算法的共生智能体范式，用于构建可信赖的6G网络自主管理系统，实现从专用AI向通用人工智能(AGI)驱动网络的转变。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，需要从处理孤立任务的专用AI算法转向具有更广泛推理能力的AGI驱动网络，以实现实时决策制定和网络管理。现有的基于LLM的自主智能体在网络管理中存在决策错误率高、资源开销大等问题，需要一种新的范式来提高可信度和效率。

Method: 提出了共生智能体范式，将LLM与实时优化算法相结合：(1)在LLM输入层使用优化器提供有界不确定性引导，处理数值精确任务；(2)在输出层使用LLM监督的优化器实现自适应实时控制。设计并实现了两种新型智能体：无线接入网络优化器和服务级别协议(SLA)多智能体协商器。构建了端到端的AGI网络架构。

Result: 在5G测试平台上的实验结果显示：(1)共生智能体相比独立LLM智能体将决策错误减少了5倍；(2)小型语言模型(SLM)在保持相似精度的同时，GPU资源开销减少99.9%，实现82毫秒的近实时循环；(3)多智能体协作RAN演示显示在服务级别协议和资源分配方面具有显著灵活性，RAN过度利用率降低约44%。

Conclusion: 共生智能体范式为下一代AGI驱动的网络系统奠定了基础，该系统设计为即使在LLM不断进步的情况下也能保持适应性、高效性和可信赖性。这种范式有效解决了LLM在网络管理中的局限性，为6G网络的智能化管理提供了新的技术路径。

Abstract: Large Language Model (LLM)-based autonomous agents are expected to play a
vital role in the evolution of 6G networks, by empowering real-time
decision-making related to management and service provisioning to end-users.
This shift facilitates the transition from a specialized intelligence approach,
where artificial intelligence (AI) algorithms handle isolated tasks, to
artificial general intelligence (AGI)-driven networks, where agents possess
broader reasoning capabilities and can manage diverse network functions. In
this paper, we introduce a novel agentic paradigm that combines LLMs with
real-time optimization algorithms towards Trustworthy AI, defined as symbiotic
agents. Optimizers at the LLM's input-level provide bounded uncertainty
steering for numerically precise tasks, whereas output-level optimizers
supervised by the LLM enable adaptive real-time control. We design and
implement two novel agent types including: (i) Radio Access Network optimizers,
and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We
further propose an end-to-end architecture for AGI networks and evaluate it on
a 5G testbed capturing channel fluctuations from moving vehicles. Results show
that symbiotic agents reduce decision errors fivefold compared to standalone
LLM-based agents, while smaller language models (SLM) achieve similar accuracy
with a 99.9% reduction in GPU resource overhead and in near-real-time loops of
82 ms. A multi-agent demonstration for collaborative RAN on the real-world
testbed highlights significant flexibility in service-level agreement and
resource allocation, reducing RAN over-utilization by approximately 44%.
Drawing on our findings and open-source implementations, we introduce the
symbiotic paradigm as the foundation for next-generation, AGI-driven
networks-systems designed to remain adaptable, efficient, and trustworthy even
as LLMs advance.

</details>


### [11] [Agent Identity Evals: Measuring Agentic Identity](https://arxiv.org/abs/2507.17257)
*Elija Perrier,Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 本文提出了智能体身份评估(AIE)框架，用于测量语言模型智能体在时间过程中维持稳定身份的能力，解决了大语言模型固有的无状态性、随机性等问题对智能体可信度的影响。


<details>
  <summary>Details</summary>
Motivation: 语言模型智能体(LMAs)继承了大语言模型的病理特征（无状态性、随机性、对提示敏感等），这些特征会破坏智能体的可识别性、连续性、持久性和一致性，进而削弱其可靠性、可信度和实用性，影响推理、规划和行动等智能体核心能力。

Method: 引入智能体身份评估(AIE)框架，这是一个严格的、统计驱动的实证框架，包含一套新颖的度量指标，可以与其他性能、能力和智能体鲁棒性测量相结合，用于设计最优的LMA基础设施和支撑结构（如记忆和工具）。

Result: 提出了可应用于LMA生命周期各个阶段的正式定义和方法，并提供了如何应用这些方法的工作示例。AIE框架能够测量LMA系统展现和维持其智能体身份的程度，包括其能力、属性和从状态扰动中恢复的能力。

Conclusion: AIE框架为评估和改进语言模型智能体的身份稳定性提供了系统性解决方案，有助于构建更可靠、可信的智能体系统，通过综合多种评估指标来优化智能体的基础架构设计。

Abstract: Central to agentic capability and trustworthiness of language model agents
(LMAs) is the extent they maintain stable, reliable, identity over time.
However, LMAs inherit pathologies from large language models (LLMs)
(statelessness, stochasticity, sensitivity to prompts and
linguistically-intermediation) which can undermine their identifiability,
continuity, persistence and consistency. This attrition of identity can erode
their reliability, trustworthiness and utility by interfering with their
agentic capabilities such as reasoning, planning and action. To address these
challenges, we introduce \textit{agent identity evals} (AIE), a rigorous,
statistically-driven, empirical framework for measuring the degree to which an
LMA system exhibit and maintain their agentic identity over time, including
their capabilities, properties and ability to recover from state perturbations.
AIE comprises a set of novel metrics which can integrate with other measures of
performance, capability and agentic robustness to assist in the design of
optimal LMA infrastructure and scaffolding such as memory and tools. We set out
formal definitions and methods that can be applied at each stage of the LMA
life-cycle, and worked examples of how to apply them.

</details>


### [12] [Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?](https://arxiv.org/abs/2507.17258)
*Andreas Scholl,Natalie Kiesler*

Main category: cs.AI

TL;DR: 研究团队基于ChatGPT-4o-mini开发了SCRIPT聊天机器人来支持编程初学者，通过136名学生的实验评估发现，学生的反馈请求遵循特定序列，机器人响应与学生需求的匹配度达75%，为设计基于生成式AI的学习支持系统提供了见解。


<details>
  <summary>Details</summary>
Motivation: 为编程教育中的初学者提供更好的学习支持，解决现有生成式AI工具在编程教育中指导性和灵活性之间的平衡问题，帮助学生在解决编程任务时获得个性化的反馈和指导。

Method: 基于ChatGPT-4o-mini开发SCRIPT聊天机器人，支持开放式交互和通过预定义提示进行结构化指导。在德国一所大学的入门编程课程中对136名学生进行实验评估，分析学生与SCRIPT的交互方式以及他们的反馈偏好。

Result: 发现学生的反馈请求遵循特定的序列模式；聊天机器人的响应与学生请求的反馈类型匹配度达到75%；机器人能够很好地遵守系统提示约束。这些结果为理解学生的学习模式和AI工具的响应效果提供了重要数据。

Conclusion: 研究为设计基于生成式AI的学习支持系统提供了重要见解，特别是在理解学生反馈需求模式方面。同时揭示了在AI辅助工具中平衡指导性和灵活性所面临的挑战，为未来改进此类教育工具提供了方向。

Abstract: Building on prior research on Generative AI (GenAI) and related tools for
programming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,
to support novice learners. SCRIPT allows for open-ended interactions and
structured guidance through predefined prompts. We evaluated the tool via an
experiment with 136 students from an introductory programming course at a large
German university and analyzed how students interacted with SCRIPT while
solving programming tasks with a focus on their feedback preferences. The
results reveal that students' feedback requests seem to follow a specific
sequence. Moreover, the chatbot responses aligned well with students' requested
feedback types (in 75%), and it adhered to the system prompt constraints. These
insights inform the design of GenAI-based learning support systems and
highlight challenges in balancing guidance and flexibility in AI-assisted
tools.

</details>


### [13] [Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](https://arxiv.org/abs/2507.17289)
*Shitong Zhu,Chenhao Fang,Derek Larson,Neel Reddy Pochareddy,Rajeev Rao,Sophie Zeng,Yanqing Peng,Wendy Summer,Alex Goncalves,Arya Pudota,Herve Robert*

Main category: cs.AI

TL;DR: 本文提出了合规大脑助手(CBA)，这是一个对话式AI助手，通过智能路由机制在快速模式和全代理模式之间选择，以平衡响应质量和延迟，显著提升企业合规任务效率。


<details>
  <summary>Details</summary>
Motivation: 企业合规人员日常工作中需要处理大量复杂的合规任务，现有的通用大语言模型在处理这些专业领域问题时效果有限，需要一个专门针对合规领域设计的AI助手来提高工作效率。

Method: 设计了一个用户查询路由器，可以智能地在两种模式间选择：(1)FastTrack模式：处理只需从知识库检索相关上下文的简单请求；(2)FullAgentic模式：处理需要复合操作和工具调用的复杂请求，能够主动发现各种合规文档中的上下文，并调用其他API/模型来满足请求。

Result: 在真实世界的隐私/合规相关查询上，CBA相比普通大语言模型表现显著提升：平均关键词匹配率从41.7%提升到83.7%，LLM评判通过率从20.0%提升到82.0%。路由机制设计在保持相近运行时间的同时，获得了更好的匹配率和通过率。

Conclusion: 研究验证了路由机制能够在响应质量和延迟之间实现良好平衡的假设，CBA通过智能路由设计成功提升了企业合规任务的处理效率，为专业领域AI助手的设计提供了有效的解决方案。

Abstract: This paper presents Compliance Brain Assistant (CBA), a conversational,
agentic AI assistant designed to boost the efficiency of daily compliance tasks
for personnel in enterprise environments. To strike a good balance between
response quality and latency, we design a user query router that can
intelligently choose between (i) FastTrack mode: to handle simple requests that
only need additional relevant context retrieved from knowledge corpora; and
(ii) FullAgentic mode: to handle complicated requests that need composite
actions and tool invocations to proactively discover context across various
compliance artifacts, and/or involving other APIs/models for accommodating
requests. A typical example would be to start with a user query, use its
description to find a specific entity and then use the entity's information to
query other APIs for curating and enriching the final AI response.
  Our experimental evaluations compared CBA against an out-of-the-box LLM on
various real-world privacy/compliance-related queries targeting various
personas. We found that CBA substantially improved upon the vanilla LLM's
performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and
LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full
routing-based design against the `fast-track only` and `full-agentic` modes and
found that it had a better average match-rate and pass-rate while keeping the
run-time approximately the same. This finding validated our hypothesis that the
routing mechanism leads to a good trade-off between the two worlds.

</details>


### [14] [Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning](https://arxiv.org/abs/2507.17418)
*Joobin Jin,Seokjun Hong,Gyeongseon Baek,Yeeun Kim,Byeongjoon Noh*

Main category: cs.AI

TL;DR: 提出了Ctx2TrajGen框架，这是一个基于GAIL的上下文感知轨迹生成模型，能够合成真实的城市驾驶行为，解决微观交通建模中的数据稀缺和领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 精确建模微观车辆轨迹对于交通行为分析和自动驾驶系统至关重要，但现有方法在处理非线性相互依赖关系、训练稳定性以及上下文感知方面存在不足，同时面临数据稀缺和领域偏移的挑战。

Method: 提出Ctx2TrajGen框架，结合生成对抗模仿学习(GAIL)、近端策略优化(PPO)和改进的Wasserstein GAN(WGAN-GP)技术，通过显式地对周围车辆和道路几何结构进行条件化建模，生成具有交互感知能力的轨迹。

Result: 在无人机捕获的DRIFT数据集上的实验表明，该方法在真实性、行为多样性和上下文保真度方面均优于现有方法，有效解决了数据稀缺和领域偏移问题。

Conclusion: Ctx2TrajGen为微观车辆轨迹生成提供了一个鲁棒的解决方案，能够在不依赖仿真的情况下生成高质量的上下文感知轨迹，为交通行为分析和自动驾驶系统提供了有力支持。

Abstract: Precise modeling of microscopic vehicle trajectories is critical for traffic
behavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a
context-aware trajectory generation framework that synthesizes realistic urban
driving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses
nonlinear interdependencies and training instability inherent in microscopic
settings. By explicitly conditioning on surrounding vehicles and road geometry,
Ctx2TrajGen generates interaction-aware trajectories aligned with real-world
context. Experiments on the drone-captured DRIFT dataset demonstrate superior
performance over existing methods in terms of realism, behavioral diversity,
and contextual fidelity, offering a robust solution to data scarcity and domain
shift without simulation.

</details>


### [15] [An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models](https://arxiv.org/abs/2507.17477)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.AI

TL;DR: 本文提出了一种不确定性驱动的自适应自对齐框架(UDASA)，通过量化输出不确定性来自动改善大语言模型与人类意图的对齐，无需人工标注即可显著提升模型在无害性、有用性、真实性等方面的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在指令跟随和推理方面取得了显著进展，但在没有人工标注的情况下实现与人类意图和安全规范的高质量对齐仍然是一个根本性挑战，需要一种全自动的对齐方法。

Method: 提出UDASA框架：首先为每个输入生成多个响应，然后从语义、事实性和价值对齐三个维度量化输出不确定性；基于不确定性分数构建偏好对，并根据不确定性差异将训练样本分为保守、温和和探索三个阶段；最后在这些阶段中逐步优化模型。

Result: 实验结果表明，UDASA在多个任务上优于现有对齐方法，包括无害性、有用性、真实性和受控情感生成，显著改善了模型性能。同时进行了一系列初步研究来验证核心设计假设。

Conclusion: UDASA框架成功实现了大语言模型的全自动对齐改进，通过不确定性量化和分阶段训练策略，有效提升了模型在多个关键维度上的对齐质量，为无监督模型对齐提供了新的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
instruction following and general-purpose reasoning. However, achieving
high-quality alignment with human intent and safety norms without human
annotations remains a fundamental challenge. In this work, we propose an
Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to
improve LLM alignment in a fully automated manner. UDASA first generates
multiple responses for each input and quantifies output uncertainty across
three dimensions: semantics, factuality, and value alignment. Based on these
uncertainty scores, the framework constructs preference pairs and categorizes
training samples into three stages, conservative, moderate, and exploratory,
according to their uncertainty difference. The model is then optimized
progressively across these stages. In addition, we conduct a series of
preliminary studies to validate the core design assumptions and provide strong
empirical motivation for the proposed framework. Experimental results show that
UDASA outperforms existing alignment methods across multiple tasks, including
harmlessness, helpfulness, truthfulness, and controlled sentiment generation,
significantly improving model performance.

</details>


### [16] [LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning](https://arxiv.org/abs/2507.17482)
*Luca Salvatore Lorello,Nikolaos Manginas,Marco Lippi,Stefano Melacci*

Main category: cs.AI

TL;DR: 本文提出了LTLZinc基准框架，用于生成时序推理和持续学习任务，评估神经符号AI方法在时间维度上的表现，并发现现有方法存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号AI方法主要应用于静态场景，缺乏在时间维度上进行推理的能力，而持续学习中的时序推理问题很少被探索，需要一个统一的基准框架来评估这类方法。

Method: 设计了LTLZinc基准框架，该框架通过线性时序逻辑规范和MiniZinc约束，结合任意图像分类数据集，生成表达丰富的时序推理和持续学习任务，并提供细粒度标注支持多种神经和神经符号训练设置。

Result: 在LTLZinc生成的六个神经符号序列分类任务和四个类别持续学习任务上进行实验，证明了时序学习和推理的挑战性，并揭示了当前最先进方法的局限性。

Conclusion: LTLZinc框架成功展示了时序推理任务的挑战性，暴露了现有方法的不足，为神经符号AI和持续学习社区提供了有价值的基准工具，有望推动统一时序学习和推理框架的研究发展。

Abstract: Neuro-symbolic artificial intelligence aims to combine neural architectures
with symbolic approaches that can represent knowledge in a human-interpretable
formalism. Continual learning concerns with agents that expand their knowledge
over time, improving their skills while avoiding to forget previously learned
concepts. Most of the existing approaches for neuro-symbolic artificial
intelligence are applied to static scenarios only, and the challenging setting
where reasoning along the temporal dimension is necessary has been seldom
explored. In this work we introduce LTLZinc, a benchmarking framework that can
be used to generate datasets covering a variety of different problems, against
which neuro-symbolic and continual learning methods can be evaluated along the
temporal and constraint-driven dimensions. Our framework generates expressive
temporal reasoning and continual learning tasks from a linear temporal logic
specification over MiniZinc constraints, and arbitrary image classification
datasets. Fine-grained annotations allow multiple neural and neuro-symbolic
training settings on the same generated datasets. Experiments on six
neuro-symbolic sequence classification and four class-continual learning tasks
generated by LTLZinc, demonstrate the challenging nature of temporal learning
and reasoning, and highlight limitations of current state-of-the-art methods.
We release the LTLZinc generator and ten ready-to-use tasks to the
neuro-symbolic and continual learning communities, in the hope of fostering
research towards unified temporal learning and reasoning frameworks.

</details>


### [17] [CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)](https://arxiv.org/abs/2507.17487)
*Lorenzo Marconi,Flavia Ricci,Riccardo Rosati*

Main category: cs.AI

TL;DR: 本文研究了基于本体的受控查询评估(CQE)问题，结合认识依赖(EDs)和最优GA审查器的交集来安全地回答布尔联合合取查询，并提出了一种一阶重写算法实现AC^0数据复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的受控查询评估框架需要在本体环境下处理信息披露的安全性问题，特别是如何在保证安全性的同时有效回答查询。认识依赖作为逻辑规则可以规范信息披露，但需要与最优审查器结合以实现更强的安全保障和更好的计算性能。

Method: 将认识依赖(EDs)与最优GA审查器的概念相结合，重点研究在所有最优GA审查器交集上回答布尔联合合取查询(BUCQs)的方法。针对EDs的子类和DL-Lite_R本体，设计了详细的一阶重写算法来实现查询回答。

Result: 首先刻画了基于交集方法的安全性，识别出了保持安全的完整EDs类别。然后证明了在特定EDs子类和DL-Lite_R本体下，BUCQ查询回答的数据复杂度为AC^0。实验结果显示重写函数在两种不同评估场景下都具有实用可行性。

Conclusion: 基于最优GA审查器交集的CQE方法能够为本体查询提供强安全保障，通过一阶重写算法可以达到AC^0的数据复杂度，实验验证了该方法的实用性和可行性。这为本体环境下的安全查询评估提供了理论基础和实用解决方案。

Abstract: We investigate Controlled Query Evaluation (CQE) over ontologies, where
information disclosure is regulated by epistemic dependencies (EDs), a family
of logical rules recently proposed for the CQE framework. In particular, we
combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground
atoms that are entailed by the ontology and can be safely revealed. We focus on
answering Boolean unions of conjunctive queries (BUCQs) with respect to the
intersection of all optimal GA censors - an approach that has been shown in
other contexts to ensure strong security guarantees with favorable
computational behavior. First, we characterize the security of this
intersection-based approach and identify a class of EDs (namely, full EDs) for
which it remains safe. Then, for a subclass of EDs and for DL-Lite_R
ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0
in data complexity by presenting a suitable, detailed first-order rewriting
algorithm. Finally, we report on experiments conducted in two different
evaluation scenarios, showing the practical feasibility of our rewriting
function.

</details>


### [18] [Automated Hybrid Grounding Using Structural and Data-Driven Heuristics](https://arxiv.org/abs/2507.17493)
*Alexander Beiser,Markus Hecher,Stefan Woltran*

Main category: cs.AI

TL;DR: 本文提出了自动化混合接地算法，通过数据结构启发式方法自动决定何时使用体解耦接地技术和何时使用标准接地技术，以解决答案集编程中的接地瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 答案集编程在工业界的广泛应用受到接地瓶颈的阻碍。虽然混合接地技术结合了标准自底向上接地和体解耦接地的优势，但何时使用哪种接地方法仍不明确，需要自动化的决策机制。

Method: 开发了基于数据结构启发式的分割算法，该算法能够检测何时使用体解耦接地和何时使用标准接地。启发式方法基于规则结构和结合实例数据的估计程序。

Result: 在原型实现上的实验显示了有前景的结果：在难以接地的场景中表现出改进，在难以求解的实例中接近最先进的性能水平。

Conclusion: 自动化混合接地算法成功解决了何时选择不同接地技术的问题，通过智能的启发式方法在保持求解性能的同时改善了接地效率，为缓解答案集编程的接地瓶颈提供了有效解决方案。

Abstract: The grounding bottleneck poses one of the key challenges that hinders the
widespread adoption of Answer Set Programming in industry. Hybrid Grounding is
a step in alleviating the bottleneck by combining the strength of standard
bottom-up grounding with recently proposed techniques where rule bodies are
decoupled during grounding. However, it has remained unclear when hybrid
grounding shall use body-decoupled grounding and when to use standard bottom-up
grounding. In this paper, we address this issue by developing automated hybrid
grounding: we introduce a splitting algorithm based on data-structural
heuristics that detects when to use body-decoupled grounding and when standard
grounding is beneficial. We base our heuristics on the structure of rules and
an estimation procedure that incorporates the data of the instance. The
experiments conducted on our prototypical implementation demonstrate promising
results, which show an improvement on hard-to-ground scenarios, whereas on
hard-to-solve instances we approach state-of-the-art performance.

</details>


### [19] [Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning](https://arxiv.org/abs/2507.17512)
*Yu Li,Zhuoshi Pan,Honglin Lin,Mengyuan Sun,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: 本研究系统性地探索了强化学习在多领域推理中的应用，重点关注数学推理、代码生成和逻辑推理三个核心领域，揭示了领域间相互作用的关键动力学机制，为开发具备综合多领域推理能力的大语言模型提供了重要指导。


<details>
  <summary>Details</summary>
Motivation: 现有的可验证奖励强化学习（RLVR）研究主要集中在孤立的推理领域，如数学问题求解、编程任务或逻辑推理，但现实世界的推理场景需要多种认知技能的综合应用。然而，在强化学习框架下这些推理技能之间的相互作用机制仍然缺乏深入理解。

Method: 采用GRPO算法和Qwen-2.5-7B模型族，通过四个关键组成部分进行系统研究：(1)评估单领域数据集训练的域内改进和跨域泛化能力；(2)分析联合跨域训练中的复杂交互，包括相互增强和冲突；(3)比较基础模型和指令模型在相同强化学习配置下的性能差异；(4)深入探讨关键的强化学习训练细节，包括课程学习策略、奖励设计变化和语言特定因素的影响。

Result: 通过广泛的实验，研究结果提供了关于领域间相互作用动力学的重要洞察，揭示了影响专业化和可泛化推理性能的关键因素。实验覆盖了数学推理、代码生成和逻辑谜题求解三个主要领域的全面评估。

Conclusion: 研究发现为优化强化学习方法提供了宝贵指导，有助于培养大语言模型的综合性多领域推理能力。这些发现揭示了在强化学习框架下不同推理领域之间的复杂相互作用机制，为未来开发更强大的多领域推理系统奠定了理论基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing
research has predominantly concentrated on isolated reasoning domains such as
mathematical problem-solving, coding tasks, or logical reasoning. However, real
world reasoning scenarios inherently demand an integrated application of
multiple cognitive skills. Despite this, the interplay among these reasoning
skills under reinforcement learning remains poorly understood. To bridge this
gap, we present a systematic investigation of multi-domain reasoning within the
RLVR framework, explicitly focusing on three primary domains: mathematical
reasoning, code generation, and logical puzzle solving. We conduct a
comprehensive study comprising four key components: (1) Leveraging the GRPO
algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the
models' in-domain improvements and cross-domain generalization capabilities
when trained on single-domain datasets. (2) Additionally, we examine the
intricate interactions including mutual enhancements and conflicts that emerge
during combined cross-domain training. (3) To further understand the influence
of SFT on RL, we also analyze and compare performance differences between base
and instruct models under identical RL configurations. (4) Furthermore, we
delve into critical RL training details, systematically exploring the impacts
of curriculum learning strategies, variations in reward design, and
language-specific factors. Through extensive experiments, our results offer
significant insights into the dynamics governing domain interactions, revealing
key factors influencing both specialized and generalizable reasoning
performance. These findings provide valuable guidance for optimizing RL
methodologies to foster comprehensive, multi-domain reasoning capabilities in
LLMs.

</details>


### [20] [TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment](https://arxiv.org/abs/2507.17514)
*Athanasios Davvetas,Xenia Ziouvelou,Ypatia Dami,Alexis Kaponis,Konstantina Giouvanopoulou,Michael Papademas*

Main category: cs.AI

TL;DR: 本文介绍了TAI Scan Tool，一个基于RAG的AI自我评估工具，主要用于帮助AI系统符合《AI法案》的合规要求，通过预筛选和评估两个阶段来确定AI系统的风险等级并提供相关法规条文。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统需要符合《AI法案》等法规要求，但缺乏有效的自动化评估工具来帮助确定AI系统的风险等级和合规义务，因此需要开发一个能够以最少输入实现TAI自我评估的工具。

Method: 采用基于RAG（检索增强生成）的两步骤方法：首先进行预筛选阶段，然后是评估阶段。工具能够根据《AI法案》确定AI系统的风险等级，同时检索相关法规条文来辅助合规并告知相关义务。

Result: 通过使用用例场景进行定性评估，工具在三个不同语义组中都能正确预测风险等级并检索相关条文，显示出良好的性能。结果解释表明工具的推理主要依赖于与高风险系统设置的比较。

Conclusion: TAI Scan Tool成功实现了基于RAG的AI自我评估功能，能够有效支持《AI法案》合规评估，工具的推理机制主要通过比较高风险系统来工作，这与高风险系统在《AI法案》中需要谨慎考虑部署的特点相符。

Abstract: This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool
with minimalistic input. The current version of the tool supports the legal TAI
assessment, with a particular emphasis on facilitating compliance with the AI
Act. It involves a two-step approach with a pre-screening and an assessment
phase. The assessment output of the system includes insight regarding the
risk-level of the AI system according to the AI Act, while at the same time
retrieving relevant articles to aid with compliance and notify on their
obligations. Our qualitative evaluation using use-case scenarios yields
promising results, correctly predicting risk levels while retrieving relevant
articles across three distinct semantic groups. Furthermore, interpretation of
results shows that the tool's reasoning relies on comparison with the setting
of high-risk systems, a behaviour attributed to their deployment requiring
careful consideration, and therefore frequently presented within the AI Act.

</details>


### [21] [Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning](https://arxiv.org/abs/2507.17539)
*Xinyao Liu,Diping Song*

Main category: cs.AI

TL;DR: 本文提出了FundusExpert，一个专门用于眼科诊断的多模态大语言模型，通过FundusGen数据集和Fundus-Engine系统实现了定位-诊断推理能力的整合，在眼科问答任务中超越40B MedRegA模型26.6%，在零样本报告生成中达到77.0%的临床一致性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医疗诊断领域具有巨大潜力，但在眼科等专业领域面临注释粒度碎片化和临床推理逻辑不一致的关键挑战，这阻碍了精确的跨模态理解。现有模型缺乏专门针对眼科的定位-诊断推理能力整合。

Method: 提出FundusExpert眼科专用多模态大语言模型和FundusGen数据集。通过智能Fundus-Engine系统自动化定位并利用基于MLLM的语义扩展，在单张眼底图像中整合全局疾病分类、局部目标检测和细粒度特征分析。构建临床对齐的认知链来指导模型生成可解释的推理路径。使用FundusGen的指令数据对FundusExpert进行微调。

Result: FundusExpert在眼科问答任务中表现最佳，平均准确率超越40B MedRegA模型26.6%。在零样本报告生成任务中表现优异，临床一致性达到77.0%，显著超过GPT-4o的47.6%。发现了数据质量与模型能力之间的标度定律（L ∝ N^0.068），证明FundusGen中的认知对齐注释提高了数据利用效率。

Conclusion: 通过整合区域级定位与诊断推理链，本工作开发了一个可扩展的、临床对齐的多模态大语言模型，探索了弥合特定领域多模态大语言模型中视觉-语言差距的路径。这为眼科等专业医疗领域的AI应用提供了新的解决方案。

Abstract: Multimodal large language models (MLLMs) demonstrate significant potential in
the field of medical diagnosis. However, they face critical challenges in
specialized domains such as ophthalmology, particularly the fragmentation of
annotation granularity and inconsistencies in clinical reasoning logic, which
hinder precise cross-modal understanding. This paper introduces FundusExpert,
an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning
capabilities, along with FundusGen, a dataset constructed through the
intelligent Fundus-Engine system. Fundus-Engine automates localization and
leverages MLLM-based semantic expansion to integrate global disease
classification, local object detection, and fine-grained feature analysis
within a single fundus image. Additionally, by constructing a clinically
aligned cognitive chain, it guides the model to generate interpretable
reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,
achieves the best performance in ophthalmic question-answering tasks,
surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in
zero-shot report generation tasks, achieving a clinical consistency of 77.0%,
significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling
law between data quality and model capability ($L \propto N^{0.068}$),
demonstrating that the cognitive alignment annotations in FundusGen enhance
data utilization efficiency. By integrating region-level localization with
diagnostic reasoning chains, our work develops a scalable, clinically-aligned
MLLM and explores a pathway toward bridging the visual-language gap in specific
MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.

</details>


### [22] [Simulating multiple human perspectives in socio-ecological systems using large language models](https://arxiv.org/abs/2507.17680)
*Yongchao Zeng,Calum Brown,Ioannis Kyriakou,Ronja Hotz,Mark Rounsevell*

Main category: cs.AI

TL;DR: 研究开发了HoPeS框架，使用大语言模型驱动的智能体代表不同利益相关者，让用户能够体验不同视角的转换，以更好地理解社会生态系统中的多元观点。


<details>
  <summary>Details</summary>
Motivation: 理解社会生态系统需要从多元利益相关者视角获得洞察，但这些视角往往难以获取。现有方法缺乏让用户体验和理解不同观点之间差异的有效途径。

Method: 开发HoPeS（面向人类的视角转换）建模框架，使用大语言模型驱动的智能体代表各种利益相关者，配合仿真协议作为"脚手架"来支持多视角仿真，帮助用户反思、转换和整合不同视角。

Result: 在土地利用变化的示例实验中，用户先后采用系统观察者和研究者视角，尽管努力推荐技术上合理的政策，但由于利益相关者的竞争性倡导，政策建议与实施之间仍存在差异。用户体验到作为研究者的挫折感，但表现出探索替代叙述策略的高度动机。

Conclusion: HoPeS框架展现了探索不同视角的潜力，能够反映现实世界中研究者与政策制定者观点之间的错位。通过进一步完善系统和协议，有望实现社会生态仿真中新形式的跨学科合作。

Abstract: Understanding socio-ecological systems requires insights from diverse
stakeholder perspectives, which are often hard to access. To enable
alternative, simulation-based exploration of different stakeholder
perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)
modelling framework. HoPeS employs agents powered by large language models
(LLMs) to represent various stakeholders; users can step into the agent roles
to experience perspectival differences. A simulation protocol serves as a
"scaffold" to streamline multiple perspective-taking simulations, supporting
users in reflecting on, transitioning between, and integrating across
perspectives. A prototype system is developed to demonstrate HoPeS in the
context of institutional dynamics and land use change, enabling both
narrative-driven and numerical experiments. In an illustrative experiment, a
user successively adopts the perspectives of a system observer and a researcher
- a role that analyses data from the embedded land use model to inform
evidence-based decision-making for other LLM agents representing various
institutions. Despite the user's effort to recommend technically sound
policies, discrepancies persist between the policy recommendation and
implementation due to stakeholders' competing advocacies, mirroring real-world
misalignment between researcher and policymaker perspectives. The user's
reflection highlights the subjective feelings of frustration and disappointment
as a researcher, especially due to the challenge of maintaining political
neutrality while attempting to gain political influence. Despite this, the user
exhibits high motivation to experiment with alternative narrative framing
strategies, suggesting the system's potential in exploring different
perspectives. Further system and protocol refinement are likely to enable new
forms of interdisciplinary collaboration in socio-ecological simulations.

</details>


### [23] [Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations](https://arxiv.org/abs/2507.17699)
*Zhao Song,Song Yue,Jiahao Zhang*

Main category: cs.AI

TL;DR: 本研究挑战了最近关于大型推理模型(LRMs)推理能力的质疑，通过引入工具增强(Python解释器和草稿板)，证明了LRMs在所有复杂度任务上都能持续优于非推理模型


<details>
  <summary>Details</summary>
Motivation: 近期苹果等机构的实证研究表明，大型推理模型的逐步思考过程可能并不能真正增强推理能力，在低复杂度和高复杂度任务上，没有显式推理的LLMs实际上表现更好。这引发了对推理模型有效性的质疑

Method: 研究者重新审视了这些发现，通过引入工具增强来测试LRMs的局限性是否仍然存在。具体使用了两种工具：Python解释器和草稿板，并在苹果的基准推理谜题上评估了三个代表性LLMs及其LRM对应版本

Result: 实验结果显示，在适当的工具使用下，LRMs在所有任务复杂度级别上都持续优于其非推理对应模型，表现出了显著的性能提升

Conclusion: 研究结果挑战了最近关于"推理是一种错觉"的说法，突出了工具增强LRMs在解决复杂问题方面的潜力，证明了推理模型在适当条件下确实具有价值

Abstract: Large Reasoning Models (LRMs) have become a central focus in today's large
language model (LLM) research, where models are designed to output a
step-by-step thinking process before arriving at a final answer to handle
complex reasoning tasks. Despite their promise, recent empirical studies (e.g.,
[Shojaee et al., 2025] from Apple) suggest that this thinking process may not
actually enhance reasoning ability, where LLMs without explicit reasoning
actually outperform LRMs on tasks with low or high complexity. In this work, we
revisit these findings and investigate whether the limitations of LRMs persist
when tool augmentations are introduced. We incorporate two types of tools,
Python interpreters and scratchpads, and evaluate three representative LLMs and
their LRM counterparts on Apple's benchmark reasoning puzzles. Our results show
that, with proper tool use, LRMs consistently outperform their non-reasoning
counterparts across all levels of task complexity. These findings challenge the
recent narrative that reasoning is an illusion and highlight the potential of
tool-augmented LRMs for solving complex problems.

</details>


### [24] [Online Submission and Evaluation System Design for Competition Operations](https://arxiv.org/abs/2507.17730)
*Zhe Chen,Daniel Harabor,Ryan Hechnenberger,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 本文提出了一个在线竞赛系统，用于自动化处理学术竞赛的提交和评估过程，解决了传统竞赛组织中的运营负担和兼容性问题


<details>
  <summary>Details</summary>
Motivation: 研究社区虽然开发了基准数据集来比较算法性能，但追踪研究进展困难，因为论文发表在不同场所且都声称代表最先进水平。虽然定期竞赛可以评估算法性能并追踪进展，但竞赛组织面临巨大运营负担：需要管理和评估大量提交，且参与者在不同环境中开发解决方案导致评估时出现兼容性问题

Method: 开发了一个在线竞赛系统，该系统能够自动化竞赛的提交和评估过程。系统允许组织者高效管理大量提交，并利用隔离环境来评估提交的解决方案，从而解决兼容性问题

Result: 该系统已经成功应用于多个竞赛，包括基于网格的路径规划竞赛(Grid-Based Pathfinding Competition)和机器人跑者联盟竞赛(League of Robot Runners competition)

Conclusion: 提出的在线竞赛系统有效解决了学术竞赛组织中的关键问题，通过自动化提交和评估流程，显著减轻了组织者的运营负担，并通过隔离环境解决了兼容性问题，已在实际竞赛中验证了其有效性

Abstract: Research communities have developed benchmark datasets across domains to
compare the performance of algorithms and techniques However, tracking the
progress in these research areas is not easy, as publications appear in
different venues at the same time, and many of them claim to represent the
state-of-the-art. To address this, research communities often organise periodic
competitions to evaluate the performance of various algorithms and techniques,
thereby tracking advancements in the field. However, these competitions pose a
significant operational burden. The organisers must manage and evaluate a large
volume of submissions. Furthermore, participants typically develop their
solutions in diverse environments, leading to compatibility issues during the
evaluation of their submissions. This paper presents an online competition
system that automates the submission and evaluation process for a competition.
The competition system allows organisers to manage large numbers of submissions
efficiently, utilising isolated environments to evaluate submissions. This
system has already been used successfully for several competitions, including
the Grid-Based Pathfinding Competition and the League of Robot Runners
competition.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge Low-Rank Matrices? Yes, $MAM^*$!](https://arxiv.org/abs/2507.17036)
*Edem Boahen,Simone Brugiapaglia,Hung-Hsu Chou,Mark Iwen,Felix Krahmer*

Main category: cs.IT

TL;DR: 本文提出了基于压缩感知的单次扫描算法，能够对超大规模矩阵进行稀疏特征向量近似，内存需求低且运行时间亚线性。


<details>
  <summary>Details</summary>
Motivation: 针对稀疏PCA等应用，需要处理过大而无法完全存储在内存中的超大规模矩阵的特征向量计算问题。

Method: 基于单一紧凑线性草图的压缩感知方法，通过一次扫描矩阵条目来近似计算顶部特征向量，利用压缩矩阵测量作为输入。

Result: 算法能够处理约10^16个条目的巨大矩阵，内存占用仅与所需稀疏特征向量近似的大小相关，运行时间主要取决于稀疏近似的大小而非原始大矩阵的规模。

Conclusion: 提出的压缩感知方法在理论上具有可证明的准确性，实验验证了其在处理超大规模矩阵特征向量近似方面的实用潜力，实现了亚线性时间复杂度和低内存占用。

Abstract: Motivated by applications such as sparse PCA, in this paper we present
provably-accurate one-pass algorithms for the sparse approximation of the top
eigenvectors of extremely massive matrices based on a single compact linear
sketch. The resulting compressive-sensing-based approaches can approximate the
leading eigenvectors of huge approximately low-rank matrices that are too large
to store in memory based on a single pass over its entries while utilizing a
total memory footprint on the order of the much smaller desired sparse
eigenvector approximations. Finally, the compressive sensing recovery algorithm
itself (which takes the gathered compressive matrix measurements as input, and
then outputs sparse approximations of its top eigenvectors) can also be
formulated to run in a time which principally depends on the size of the sought
sparse approximations, making its runtime sublinear in the size of the large
matrix whose eigenvectors one aims to approximate. Preliminary experiments on
huge matrices having $\sim 10^{16}$ entries illustrate the developed theory and
demonstrate the practical potential of the proposed approach.

</details>


### [26] [Secure Wireless Communication via Polarforming](https://arxiv.org/abs/2507.17129)
*Jingze Ding,Zijian Zhou,Bingli Jiao,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种极化成形技术，通过动态调整天线极化来增强无线通信系统的安全性能，特别是在存在窃听者的情况下最大化保密速率。


<details>
  <summary>Details</summary>
Motivation: 传统固定极化天线系统在电磁波传播过程中容易遭受去极化效应，且在安全通信中无法充分利用极化自由度来对抗窃听攻击，需要一种能够动态调整天线极化的技术来提升系统安全性能。

Method: 提出了一种高效的迭代算法来联合优化发射波束成形和极化成形：波束成形利用空间自由度将发射波束指向合法用户，极化成形利用极化自由度使用户接收到的电磁波极化状态与其天线极化状态对齐。基站配备可重构极化天线，能够灵活调整天线极化。

Result: 仿真结果表明，与传统固定极化天线系统相比，极化成形技术能够充分利用天线极化优化中的自由度，显著增强无线通信系统的安全性能。

Conclusion: 极化成形技术是一种有前景的方法，能够通过动态调整天线极化来缓解电磁波传播中的去极化效应，并在安全无线通信系统中显著提升保密速率和整体安全性能。

Abstract: Polarforming is a promising technique that enables dynamic adjustment of
antenna polarization to mitigate depolarization effects commonly encountered
during electromagnetic (EM) wave propagation. In this letter, we investigate
the polarforming design for secure wireless communication systems, where the
base station (BS) is equipped with polarization-reconfigurable antennas (PRAs)
and can flexibly adjust the antenna polarization to transmit confidential
information to a legitimate user in the presence of an eavesdropper. To
maximize the achievable secrecy rate, we propose an efficient iterative
algorithm to jointly optimize transmit beamforming and polarforming, where
beamforming exploits spatial degrees of freedom (DoFs) to steer the transmit
beam toward the user, while polarforming leverages polarization DoFs to align
the polarization state of the EM wave received by the user with that of its
antenna. Simulation results demonstrate that, compared to conventional
fixed-polarization antenna (FPA) systems, polarforming can fully exploit the
DoFs in antenna polarization optimization to significantly enhance the security
performance of wireless communication systems.

</details>


### [27] [Construction of Self-Orthogonal Quasi-Cyclic Codes and Their Application to Quantum Error-Correcting Codes](https://arxiv.org/abs/2507.17319)
*Mengying Gao,Yuhua Sun,Tongjiang Yan,Chun'e Zhao*

Main category: cs.IT

TL;DR: 本文研究t-生成元准循环码的自正交性条件，并基于此构造了多种具有良好参数的量子稳定子码和量子同步码


<details>
  <summary>Details</summary>
Motivation: 现有的准循环码自正交性条件研究不够完善，特别是在欧几里得、厄米特和辛内积下的统一条件缺乏，同时需要构造参数更优的量子码

Method: 通过分析2-生成元准循环码对偶码的结构，在三种不同内积（欧几里得、厄米特、辛内积）下分别推导t-生成元准循环码自正交的充要条件，并研究包含对偶的条件

Result: 得到了t-生成元准循环码在三种内积下自正交的充要条件，推广了文献中的许多已知码类，构造出多个具有良好参数的量子稳定子码和量子同步码

Conclusion: 所构造的量子码中，部分参数与Grassl码表中的最优已知码参数相同，证明了所提方法的有效性，为量子纠错码的构造提供了新的理论基础

Abstract: In this paper, necessary and sufficient conditions for the self-orthogonality
of t-generator quasi-cyclic (QC) codes are presented under the Euclidean,
Hermitian, and symplectic inner products, respectively. Particularly, by
studying the structure of the dual codes of a class of 2-generator QC codes, we
derive necessary and sufficient conditions for the QC codes to be
dual-containing under the above three inner products. This class of 2-generator
QC codes generalizes many known codes in the literature. Based on the above
conditions, we construct several quantum stabilizer codes and quantum
synchronizable codes with good parameters, some of which share parameters with
certain best-known codes listed in Grassl's code table.

</details>


### [28] [On Distributionally Robust Lossy Source Coding](https://arxiv.org/abs/2507.17366)
*Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.IT

TL;DR: 本文研究分布鲁棒信源编码问题，提出了强函数表示引理的两个扩展，并针对KL散度球约束下的信源分布导出了鲁棒率失真函数的计算算法


<details>
  <summary>Details</summary>
Motivation: 现有信源编码方法假设信源分布已知且固定，但实际应用中信源分布往往存在不确定性，因此需要研究在信源分布不确定性下的分布鲁棒信源编码问题

Method: 提出强函数表示引理(SFRL)的两个扩展：1）边际分布属于有限分布集合的情况；2）边际分布属于以固定标称分布为中心的KL散度球的情况。基于这些扩展推导分布鲁棒编码方案

Result: 导出了单次和渐近情况下的分布鲁棒编码方案，获得了KL散度球约束下鲁棒率失真函数(R-RDF)达到点的隐式特征，实现了计算R-RDF的新算法，并给出了伯努利信源R-RDF的解析表达式

Conclusion: 成功扩展了强函数表示引理，建立了分布鲁棒信源编码的理论框架，提供了实用的R-RDF计算算法，并通过伯努利信源的解析解验证了算法的有效性

Abstract: In this paper, we investigate the problem of distributionally robust source
coding, i.e., source coding under uncertainty in the source distribution,
discussing both the coding and computational aspects of the problem. We propose
two extensions of the so-called Strong Functional Representation Lemma (SFRL),
considering the cases where, for a fixed conditional distribution, the marginal
inducing the joint coupling belongs to either a finite set of distributions or
a Kullback-Leibler divergence sphere (KL-Sphere) centered at a fixed nominal
distribution. Using these extensions, we derive distributionally robust coding
schemes for both the one-shot and asymptotic regimes, generalizing previous
results in the literature. Focusing on the case where the source distribution
belongs to a given KL-Sphere, we derive an implicit characterization of the
points attaining the robust rate-distortion function (R-RDF), which we later
exploit to implement a novel algorithm for computing the R-RDF. Finally, we
characterize the analytical expression of the R-RDF for Bernoulli sources,
providing a theoretical benchmark to evaluate the estimation performance of the
proposed algorithm.

</details>


### [29] [Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning](https://arxiv.org/abs/2507.17426)
*Jaiprakash Nagar,Zheng Chen,Marios Kountouris,Photios A. Stavrou*

Main category: cs.IT

TL;DR: 本文提出了基于信息熵的节点和链路调度策略，用于资源受限网络中的分布式随机梯度下降算法，在通信预算降低60%的情况下实现更快收敛


<details>
  <summary>Details</summary>
Motivation: 在资源受限的网络环境中，分布式随机梯度下降算法面临通信效率低下的问题，需要设计有效的节点和链路调度策略来减少通信开销

Method: 提出基于信息熵的重要性度量方法来确定节点和链路的调度概率，在每次迭代中随机激活少数几个不相交的节点子集或链路子集，满足给定的通信成本约束

Result: 与现有方法相比，在节点调度中比基于介数中心性的方法收敛更快，通信预算最多可降低60%；在较高通信预算（60%以上）时保持可比或更优性能；在链路调度中，性能优于或与MATCHA方法相当

Conclusion: 基于信息熵的调度策略能够有效提高分布式随机梯度下降算法在资源受限网络中的通信效率，在节点调度和链路调度两种场景下都表现出良好的性能

Abstract: This paper addresses decentralized stochastic gradient descent (D-SGD) over
resource-constrained networks by introducing node-based and link-based
scheduling strategies to enhance communication efficiency. In each iteration of
the D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly
activated, subject to a given communication cost constraint. We propose a novel
importance metric based on information entropy to determine node and link
scheduling probabilities. We validate the effectiveness of our approach through
extensive simulations, comparing it against state-of-the-art methods, including
betweenness centrality (BC) for node scheduling and \textit{MATCHA} for link
scheduling. The results show that our method consistently outperforms the
BC-based method in the node scheduling case, achieving faster convergence with
up to 60\% lower communication budgets. At higher communication budgets (above
60\%), our method maintains comparable or superior performance. In the link
scheduling case, our method delivers results that are superior to or on par
with those of \textit{MATCHA}.

</details>


### [30] [Learning to Write on Dirty Paper](https://arxiv.org/abs/2507.17427)
*Ezgi Ozyilkan,Oğuzhan Kubilay Ülger,Elza Erkip*

Main category: cs.IT

TL;DR: 本文提出了一种基于深度学习的脏纸编码(DPC)方案，使用神经网络参数化编码器和解码器，无需先验知识即可实现有效的干扰预消除，在多种场景下超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的脏纸编码实现方案（如THP和格基方案）通常依赖于对输入、状态和信道的特定建模假设，限制了其实际应用。现代学习方法可能为DPC问题提供新的解决路径。

Method: 提出一种数据驱动的解决方案，使用神经网络参数化编码器和解码器。该模型无需先验知识（包括状态/干扰、信道或输入统计信息），通过学习恢复非线性映射来实现有效的干扰预消除。

Result: 所提出的学习方案能够恢复已建立解决方案（如THP和格基预编码）的特征特性，并在多个场景下优于这些传统方法。这是首个可解释的概念验证，证明基于学习的DPC方案的有效性。

Conclusion: 基于学习的DPC方案为传统方法提供了有效的补充路径，能够在无先验知识的情况下实现优于传统方法的性能，为实际DPC应用开辟了新的可能性。

Abstract: Dirty paper coding (DPC) is a classical problem in information theory that
considers communication in the presence of channel state known only at the
transmitter. While the theoretical impact of DPC has been substantial,
practical realizations of DPC, such as Tomlinson-Harashima precoding (THP) or
lattice-based schemes, often rely on specific modeling assumptions about the
input, state and channel. In this work, we explore whether modern
learning-based approaches can offer a complementary path forward by revisiting
the DPC problem. We propose a data-driven solution in which both the encoder
and decoder are parameterized by neural networks. Our proposed model operates
without prior knowledge of the state (also referred to as "interference"),
channel or input statistics, and recovers nonlinear mappings that yield
effective interference pre-cancellation. To the best of our knowledge, this is
the first interpretable proof-of-concept demonstrating that learning-based DPC
schemes can recover characteristic features of well-established solutions, such
as THP and lattice-based precoding, and outperform them in several regimes.

</details>


### [31] [Non-Asymptotic Achievable Rate-Distortion Region for Indirect Wyner-Ziv Source Coding](https://arxiv.org/abs/2507.17432)
*Jiahui Wei,Philippe Mary,Elsa Dupraz*

Main category: cs.IT

TL;DR: 本文研究了间接Wyner-Ziv源编码问题，其中编码器和解码器都无法观测到的潜在源S也需要在解码器端重构，推导了渐近情况下的率失真函数并提出了相应的Blahut-Arimoto算法。


<details>
  <summary>Details</summary>
Motivation: 在目标导向通信的背景下，传统的Wyner-Ziv源编码问题需要扩展到间接设置，即除了重构观测源X外，还需要重构编码器和解码器都无法直接观测的潜在源S（如语义信息），这在实际应用中越来越重要。

Method: 1) 推导间接Wyner-Ziv设置下的渐近率失真函数；2) 提供有限块长度下的可达区域；3) 针对间接Wyner-Ziv设置提出定制化的Blahut-Arimoto算法；4) 将S视为分类标签进行数值评估。

Result: 成功推导出间接Wyner-Ziv率失真函数的理论表达式，给出了有限块长度情况下的可达区域，并通过数值实验验证了当S作为分类标签时的可达间接率失真区域性能。

Conclusion: 本文为间接Wyner-Ziv源编码问题提供了完整的理论框架，包括渐近和有限块长度的分析，以及实用的算法实现，为目标导向通信中的语义信息传输提供了理论基础。

Abstract: In the Wyner-Ziv source coding problem, a source $X$ has to be encoded while
the decoder has access to side information $Y$. This paper investigates the
indirect setup, in which a latent source $S$, unobserved by both the encoder
and the decoder, must also be reconstructed at the decoder. This scenario is
increasingly relevant in the context of goal-oriented communications, where $S$
can represent semantic information obtained from $X$. This paper derives the
indirect Wyner-Ziv rate-distortion function in asymptotic regime and provides
an achievable region in finite block-length. Furthermore, a Blahut-Arimoto
algorithm tailored for the indirect Wyner-Ziv setup, is proposed. This
algorithm is then used to give a numerical evaluation of the achievable
indirect rate-distortion region when $S$ is treated as a classification label.

</details>


### [32] [Bounds and Equivalence of Skew Polycyclic Codes over Finite Fields](https://arxiv.org/abs/2507.17571)
*Hassan Ou-azzou,Anna-Lena Horlemann,Nuh Aydin*

Main category: cs.IT

TL;DR: 本文研究了有限域上的斜多环码，证明了Roos类型界限，分析了不同多环码类之间的等价关系，并提供了理论应用实例


<details>
  <summary>Details</summary>
Motivation: 需要深入理解斜多环码的结构性质和度量特征，特别是在Hamming度量和rank度量下的界限问题，以及不同多环码类之间的等价关系

Method: 通过引入斜多项式和自同构映射，建立斜多环码的数学框架；证明Roos类型界限定理；定义等价关系并描述其等价类来分析Hamming等价和rank等价

Result: 成功证明了斜多环码在Hamming度量和rank度量下的Roos类型界限；建立了两类多环码之间的等价关系理论框架；提供了具体的应用实例验证理论结果

Conclusion: 斜多环码具有良好的理论性质，Roos类型界限为其参数提供了重要约束，等价关系理论为不同码类的分类和比较提供了有效工具，相关理论在编码理论中具有实际应用价值

Abstract: We study skew polycyclic codes over a finite field $\mathbb{F}_q$, associated
with a skew polynomial $f(x) \in \mathbb{F}_q[x;\sigma]$, where $\sigma$ is an
automorphism of $\mathbb{F}_q$. We start by proving the Roos-like bound for
both the Hamming and the rank metric for this class of codes. Next, we focus on
the Hamming and rank equivalence between two classes of polycyclic codes by
introducing an equivalence relation and describing its equivalence classes.
Finally, we present examples that illustrate applications of the theory
developed in this paper.

</details>


### [33] [On Function-Correcting Codes in the Lee Metric](https://arxiv.org/abs/2507.17654)
*Gyanendra K. Verma,Abhay Kumar Singh*

Main category: cs.IT

TL;DR: 本文研究了在Lee度量下$\mathbb{Z}_m$上的函数纠错码，通过引入不规则Lee距离码来确定最优冗余度，并改进了特定函数类的界限。


<details>
  <summary>Details</summary>
Motivation: 现有的函数纠错码研究主要集中在$\mathbb{Z}_{2^l}$上使用齐次度量，需要将研究扩展到更一般的$\mathbb{Z}_m$环上使用Lee度量，以最小化冗余度的同时确保特定函数计算的可靠恢复。

Method: 引入不规则Lee距离码的概念，通过刻画这类码的最短可能长度来推导最优冗余度的上界和下界，然后将这些一般性界限简化并应用到特定的函数类别中。

Result: 对Lee-局部函数、Lee权重函数和Lee权重分布函数等特定函数类，获得了改进的界限，相比Liu和Liu在$\mathbb{Z}_4$上的结果有所提升，并将其他界限推广到了Lee度量下的$\mathbb{Z}_m$环上。

Conclusion: 通过不规则Lee距离码的理论框架，成功确定了$\mathbb{Z}_m$环上Lee度量下函数纠错码的最优冗余度界限，为多个重要函数类提供了改进的结果，推广了现有理论。

Abstract: Function-correcting codes are a coding framework designed to minimize
redundancy while ensuring that specific functions or computations of encoded
data can be reliably recovered, even in the presence of errors. The choice of
metric is crucial in designing such codes, as it determines which computations
must be protected and how errors are measured and corrected. Previous work by
Liu and Liu [6] studied function-correcting codes over $\mathbb{Z}_{2^l},\
l\geq 2$ using the homogeneous metric, which coincides with the Lee metric over
$\mathbb{Z}_4$. In this paper, we extend the study to codes over
$\mathbb{Z}_m,$ for any positive integer $m\geq 2$ under the Lee metric and aim
to determine their optimal redundancy. To achieve this, we introduce irregular
Lee distance codes and derive upper and lower bounds on the optimal redundancy
by characterizing the shortest possible length of such codes. These general
bounds are then simplified and applied to specific classes of functions,
including Lee-local functions, Lee weight functions, and Lee weight
distribution functions, leading to improved some bounds compared to those of
Liu and Liu [6] over $\mathbb{Z}_4$ and generalize the other bounds over
$\mathbb{Z}_m$ in the Lee metric.

</details>


### [34] [Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems](https://arxiv.org/abs/2507.17736)
*Shreya Meel,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文研究了在复制数据库上的对称私密信息检索（SPIR）问题，建立了基于图模型的SPIR容量下界，并为路径图和正则图导出了精确的SPIR容量。


<details>
  <summary>Details</summary>
Motivation: 现有的对称私密信息检索研究主要集中在完全复制的数据库上，但实际应用中数据通常按照某种网络拓扑结构进行部分复制。因此需要研究在图模型下的SPIR问题，其中消息根据图的边连接关系在服务器间复制。

Method: 提出了基于简单图的复制数据库SPIR模型，其中顶点对应服务器，边表示消息复制关系。引入了消息特定公共随机性的概念，即服务器端公共随机性也按照图结构进行复制。通过设计可达成的SPIR方案来建立SPIR容量的下界。

Result: 为一般图建立了SPIR容量的下界；证明了任何可行SPIR方案的消息特定随机性的最小大小必须等于消息大小；为路径图和正则图类别提供了匹配的上界，从而导出了精确的SPIR容量。

Conclusion: 本文成功将SPIR问题扩展到了图复制数据库模型，建立了理论基础并为特定图类别获得了最优结果。消息特定公共随机性的大小限制为实际系统设计提供了重要指导。

Abstract: We introduce the problem of symmetric private information retrieval (SPIR) on
replicated databases modeled by a simple graph. In this model, each vertex
corresponds to a server, and a message is replicated on two servers if and only
if there is an edge between them. We consider the setting where the server-side
common randomness necessary to accomplish SPIR is also replicated at the
servers according to the graph, and we call this as message-specific common
randomness. In this setting, we establish a lower bound on the SPIR capacity,
i.e., the maximum download rate, for general graphs, by proposing an achievable
SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the
minimum size of message-specific randomness should be equal to the size of a
message. Finally, by providing matching upper bounds, we derive the exact SPIR
capacity for the class of path and regular graphs.

</details>
