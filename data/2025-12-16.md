<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.IT](#cs.IT) [Total: 15]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Policy Gradient Algorithms for Age-of-Information Cost Minimization](https://arxiv.org/abs/2512.11990)
*José-Ramón Vidal,Vicent Pla,Luis Guijarro,Israel Leyva-Mayorga*

Main category: cs.NI

TL;DR: 提出两种基于无模型强化学习的在线策略优化算法，用于优化信息物理系统中信息更新的AoI和数据传输成本，无需知道传输延迟或年龄成本函数特性。


<details>
  <summary>Details</summary>
Motivation: 信息物理系统中，优化物联网设备访问策略以最大化信息新鲜度（用AoI度量）是一个挑战性任务。现有方法通常需要知道传输延迟和成本函数特性，限制了实际应用。

Method: 提出两种基于策略梯度方法的无模型强化学习算法，专门处理连续状态和动作空间。两种算法采用不同的信息更新决策策略，并且可以同时应用以进一步降低成本。

Result: 算法表现出良好的收敛特性，在可计算最优值的情况下，时间平均成本在最优值的3%以内。相比现有方法，在适用场景范围、时间平均成本和计算成本方面都有优势。

Conclusion: 提出的无模型强化学习算法能有效优化信息物理系统中的信息更新过程，无需先验知识，在多个方面优于现有方法，具有实际应用价值。

Abstract: Recent developments in cyber-physical systems have increased the importance of maximizing the freshness of the information about the physical environment. However, optimizing the access policies of Internet of Things devices to maximize the data freshness, measured as a function of the Age-of-Information (AoI) metric, is a challenging task. This work introduces two algorithms to optimize the information update process in cyber-physical systems operating under the generate-at-will model, by finding an online policy without knowing the characteristics of the transmission delay or the age cost function. The optimization seeks to minimize the time-average cost, which integrates the AoI at the receiver and the data transmission cost, making the approach suitable for a broad range of scenarios. Both algorithms employ policy gradient methods within the framework of model-free reinforcement learning (RL) and are specifically designed to handle continuous state and action spaces. Each algorithm minimizes the cost using a distinct strategy for deciding when to send an information update. Moreover, we demonstrate that it is feasible to apply the two strategies simultaneously, leading to an additional reduction in cost. The results demonstrate that the proposed algorithms exhibit good convergence properties and achieve a time-average cost within 3% of the optimal value, when the latter is computable. A comparison with other state-of-the-art methods shows that the proposed algorithms outperform them in one or more of the following aspects: being applicable to a broader range of scenarios, achieving a lower time-average cost, and requiring a computational cost at least one order of magnitude lower.

</details>


### [2] [A Leaner and Faster Web: How CBOR Can Improve Dynamic Content Encoding in JSON and DNS over HTTPS](https://arxiv.org/abs/2512.12067)
*Martine S. Lenders,Carsten Bormann,Thomas C. Schmidt,Matthias Wählisch*

Main category: cs.NI

TL;DR: 该论文提出使用CBOR（简洁二进制对象表示）替代JSON和DNS over HTTPS中的动态内容编码，显著减少数据大小并降低延迟，同时设计了新的CBOR-based DNS消息格式和名称压缩方案。


<details>
  <summary>Details</summary>
Motivation: 互联网社区已努力降低Web延迟，但在动态内容压缩方面关注不足。JSON和DNS over HTTPS提供的动态内容持续增长，增加了延迟并加剧数字不平等。需要更高效的编码方案来应对这一问题。

Method: 采用为受限物联网环境设计的CBOR编码，替代JSON和DNS over HTTPS中的动态内容编码。设计了新的CBOR-based DNS消息格式，并提出两种名称压缩方案，其中一种方案仅需314字节的解码器实现。

Result: JSON转CBOR可减少高达80.0%的数据量，降低大型对象加载时间达13.8%。新的CBOR-based DNS格式在压缩形式下可减少95.5%的数据包大小，名称压缩方案最多节省226字节。研究成果已影响互联网标准化进程。

Conclusion: CBOR编码能有效压缩动态内容，显著降低延迟并缓解数字不平等问题。提出的CBOR-based DNS格式和压缩方案具有实际应用价值，部分方案已影响标准化改进。

Abstract: The Internet community has taken major efforts to decrease latency in the World Wide Web. Significant improvements have been achieved in accelerating content transport and in compressing static content. Less attention, however, has been dedicated to dynamic content compression. Such content is commonly provided by JSON and DNS over HTTPS. Aligned with the overall Web trend, dynamic content objects continue to grow in size, which increases latency and fosters the digital inequality. In this paper, we propose to counter this increase by utilizing components engineered for the constrained Internet of Things (IoT). We focus on the Concise Binary Object Representation (CBOR) and its use for dynamic content encoded in JSON or in DNS over HTTPS messages. CBOR was originally introduced to restrict packet sizes in constrained environments and enables small, effective encoding of data objects. We measure that simply switching the data representation from JSON to CBOR reduces data by up to 80.0% for a corpus of JSON objects collected via the HTTP Archive. This size reduction can decrease loading times by up to 13.8% when downloading large objects -- even in local setups. A new CBOR-based DNS message format designed for use with DNS over HTTPS (DoH) and DNS over CoAP (DoC) minimizes packets by up to 95.5% in its packed form and shows large potential for additionally compressing names and addresses. We contribute two name compression schemes that apply to the new CBOR format and save up to 226 bytes in a response. The decoder for our name compression scheme is lean and can fit into as little as 314 bytes of binary build size. One of those compression schemes and further optimization proposals directly influenced further improvements of the new CBOR format within Internet standardization.

</details>


### [3] [Dynamic SLA-aware Network Slice Monitoring](https://arxiv.org/abs/2512.12123)
*Niloy Saha,Mina Tahmasbi Arashloo,Nashid Shahriar,Raouf Boutaba*

Main category: cs.NI

TL;DR: SliceScope：一个基于闭环控制框架的网络切片监控系统，通过动态分配监控资源和变化触发INT数据平面，在有限遥测预算下实现SLA感知的端到端切片监控。


<details>
  <summary>Details</summary>
Motivation: 下一代网络依赖网络切片满足不同应用的SLA要求，但现有监控方案存在两个根本限制：要么缺乏端到端可见性（如草图、概率采样），要么有可见性但缺乏根据切片SLA动态分配监控资源的控制机制。

Method: 1) 将切片监控形式化为闭环控制问题，定义遥测原语契约；2) SliceScope实现：控制策略根据SLA关键性动态分配监控资源；3) 基于变化触发INT的数据平面，提供可调节精度开销权衡的端到端可见性。

Result: 在可编程交换机和大型模拟中评估，SliceScope相比静态基线对关键切片的跟踪精度提高4倍，同时证明变化触发INT在实现遥测原语契约方面优于其他原语。

Conclusion: SliceScope通过闭环控制框架和变化触发INT数据平面，解决了SLA感知网络切片监控的核心挑战，在有限遥测预算下实现了动态资源分配和端到端可见性的平衡。

Abstract: Next-generation networks increasingly rely on network slices - logical networks tailored to specific application requirements, each with distinct Service-Level Agreements (SLAs). Ensuring compliance with these SLAs requires continuous, real-time monitoring of end-to-end performance metrics for each slice, within a limited telemetry budget. However, we find that existing solutions face two fundamental limitations: they either lack end-to-end visibility (e.g., sketches, probabilistic sampling) or provide visibility but lack the control mechanisms to dynamically allocate monitoring resources according to slice SLAs. We address this through a formal framework that reframes slice monitoring as a closed-loop control problem, and defines the minimal data plane requirements for SLA-aware slice monitoring via a telemetry primitive contract. We then present SliceScope, a realization of this framework that combines: (1) a control strategy that dynamically allocates the monitoring resources across diverse slices according to their SLA criticality, and (2) a data-plane based on change-triggered INT that provides per-packet end-to-end visibility with tunable accuracy-overhead trade-offs, satisfying the telemetry contract. Our evaluation results on programmable switches and in large-scale simulations with a mixture of different slice types, demonstrate that SliceScope tracks critical slices up to 4x more accurately compared to static baselines, while showing that change-triggered INT outperforms alternative primitives for realizing the telemetry primitive contract.

</details>


### [4] [Joint Power and Mobility Control](https://arxiv.org/abs/2512.12137)
*Yun Hou,Yening Zhang*

Main category: cs.NI

TL;DR: 提出一种联合优化传输功率和车辆移动性的方法，通过SINR的sigmoid近似建立链路接收模型，转化为功率优化问题，采用分布式算法调整轨迹和功率，显著提升V2X网络在干扰条件下的连通性。


<details>
  <summary>Details</summary>
Motivation: 解决自主V2X网络中网络连通性提升的挑战，特别是在高度动态的车辆网络中，干扰会严重影响通信质量，需要协调移动性和功率控制来缓解干扰。

Method: 基于SINR的sigmoid近似建立链路接收模型，转化为基于功率的优化公式；构建多节点网络效用最大化问题，证明其凹性，实现分布式轨迹和功率调整算法。

Result: 仿真和实际实验验证了理论发现，对称定位和平衡功率分配在干扰受限条件下显著提高分组接收率，协调移动性和功率控制能有效缓解干扰。

Conclusion: 协调移动性和功率控制能有效改善高度动态车辆网络的连通性，为未来自主系统和无人机系统的鲁棒通信铺平道路。

Abstract: This study addressed the challenge of improving network connectivity in autonomous V2X networks by jointly optimizing transmission power and vehicle mobility. We proposed a link reception model based on a sigmoid approximation of SINR and transformed it into a power-based formulation for simplicity in optimization. Building on this, we formulated a multi-node Network Utility Maximization (NUM) problem and demonstrated its concavity, enabling distributed trajectory and power adjustments. Both simulation and real-world experiments validated the theoretical findings, showing that symmetric positioning and balanced power allocation significantly enhance packet reception rates under interference-limited conditions. These results confirm that coordinated mobility and power control can effectively mitigate interference and improve connectivity in highly dynamic vehicular networks, paving the way for robust communication in future autonomous and UAV systems.

</details>


### [5] [Agentic AI for 6G: A New Paradigm for Autonomous RAN Security Compliance](https://arxiv.org/abs/2512.12400)
*Sotiris Chatzimiltis,Mahdi Boloursaz Mashhadi,Mohammad Shojafar,Merouane Debbah,Rahim Tafazolli*

Main category: cs.NI

TL;DR: 该论文提出了一个基于LLM智能代理和RAG管道的框架，用于自动化电信网络（特别是RAN）的安全合规性检查与执行，通过案例研究展示了配置文件的合规评估、可解释性分析和自动修复能力。


<details>
  <summary>Details</summary>
Motivation: 电信行业下一代无线接入网络（RAN）日益复杂，传统安全合规方法难以跟上不断发展的规范和实时变化，需要自动化解决方案来确保网络安全。

Method: 提出一个框架，将基于LLM的AI代理与检索增强生成（RAG）管道集成，实现智能自主的安全合规执行。框架能够评估配置文件是否符合O-RAN联盟和3GPP标准，生成可解释的合规判断，并在需要时提出自动化修复方案。

Result: 通过初步案例研究证明，该代理能够有效评估配置文件的合规性，提供可解释的合规判断，并建议自动化修复方案。同时识别了模型幻觉和供应商不一致性等关键挑战。

Conclusion: 基于LLM的AI代理在自动化电信网络安全合规方面具有潜力，但需要解决模型幻觉、供应商不一致性等挑战，并加强代理安全性、透明度和系统信任。未来需要开发电信专用LLM和标准化评估框架。

Abstract: Agentic AI systems are emerging as powerful tools for automating complex, multi-step tasks across various industries. One such industry is telecommunications, where the growing complexity of next-generation radio access networks (RANs) opens up numerous opportunities for applying these systems. Securing the RAN is a key area, particularly through automating the security compliance process, as traditional methods often struggle to keep pace with evolving specifications and real-time changes. In this article, we propose a framework that leverages LLM-based AI agents integrated with a retrieval-augmented generation (RAG) pipeline to enable intelligent and autonomous enforcement of security compliance. An initial case study demonstrates how an agent can assess configuration files for compliance with O-RAN Alliance and 3GPP standards, generate explainable justifications, and propose automated remediation if needed. We also highlight key challenges such as model hallucinations and vendor inconsistencies, along with considerations like agent security, transparency, and system trust. Finally, we outline future directions, emphasizing the need for telecom-specific LLMs and standardized evaluation frameworks.

</details>


### [6] [Efficient Resource Allocation for Multi-User and Multi-Target MIMO-OFDM Underwater ISAC](https://arxiv.org/abs/2512.12611)
*Wei Men,Longfei Zhao,Yong Liang Guan,Xiangwang Hou,Yong Ren,Dusit Niyato*

Main category: cs.NI

TL;DR: 提出基于交错OFDM的MIMO水下声学ISAC系统，采用多目标优化框架平衡通信与感知性能，开发二维分组随机搜索算法解决混合整数非凸问题


<details>
  <summary>Details</summary>
Motivation: 下一代水下网络需要集成感知与通信技术，但在复杂水下声学环境中同时覆盖多用户目标并平衡感知与通信性能仍具挑战性

Method: 提出交错正交频分复用MIMO水下声学ISAC系统，采用水平阵列同时传输自适应波形；建立多目标优化框架最大化通信速率与距离乘积；开发二维分组随机搜索算法解决子载波交错模式和资源分配问题

Result: 数值仿真显示：算法比传统穷举搜索收敛速度快90%，仅带来0.5 kbps km的PRR性能下降；在严格PRR和PAPR约束下，资源分配方案比基线方案更具鲁棒性

Conclusion: 所设计的系统在真实水下声学信道中表现出优越性和有效性，为复杂水下环境中的多用户ISAC系统提供了高效解决方案

Abstract: Integrated sensing and communication (ISAC) technology is crucial for next-generation underwater networks. However, covering multiple users and targets and balancing sensing and communication performance in complex underwater acoustic (UWA) environments remains challenging. This paper proposes an interleaved orthogonal frequency division multiplexing-based MIMO UWA-ISAC system, which employs a horizontal array to simultaneously transmit adaptive waveforms for downlink multi-user communication and omnidirectional target sensing. A multi-objective optimization framework is formulated to maximize the product of communication rate and range (PRR) while ensuring sensing performance and peak-to-average power ratio (PAPR) constraints. To solve this mixed-integer nonconvex problem, a two-dimensional grouped random search algorithm is developed, efficiently exploring subcarrier interleaved patterns and resource allocation schemes. Numerical simulations under real-world UWA channels demonstrate the designed system's superiority and effectiveness: our algorithm achieves 90% faster convergence than conventional exhaustive search with only a marginal 0.5 kbps km PRR degradation. Furthermore, the proposed resource allocation scheme maintains robustness beyond the baseline allocation schemes under stringent PRR and PAPR constraints.

</details>


### [7] [Low-Complexity Monitoring and Compensation of Transceiver IQ Imbalance by Multi-dimensional Architecture for Dual-Polarization 16 Quadrature Amplitude Modulation](https://arxiv.org/abs/2512.13266)
*Yukun Zhang,Xiaoxue Gong,Xu Zhang,Lei Guo*

Main category: cs.NI

TL;DR: 提出低复杂度IQ不平衡补偿架构，通过IQ skew估计和低复杂度MIMO均衡器结构，显著降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 在高速光通信系统中，收发器的IQ不平衡会严重恶化信号质量，传统补偿方法计算复杂度高，需要设计低复杂度的补偿方案

Method: 架构包含收发器IQ skew估计方法和低复杂度MIMO均衡器结构。先通过chirp滤波预补偿色散，接收端用Gardner相位检测器估计IQ skew，发送端通过最小化均衡器误差估计。MIMO均衡器采用复数MIMO(CV-MIMO)和实数DD-LMS MIMO(RV-MIMO)组合，分别使用蝶形和非蝶形结构

Result: 在36 Gbaud DP-QAM信号的100km传输仿真和实验中，接收端IQ skew估计使实数乘法次数减少70%以上，低复杂度MIMO均衡器使实数乘法次数减少51%（相比4x4 MIMO）

Conclusion: 该低复杂度架构能有效补偿收发器IQ不平衡，显著降低计算复杂度，适用于高速光通信系统

Abstract: In this paper, a low-complexity IQ imbalance compensation architecture is proposed, which reduces the effects of in-phase (I) and quadrature (Q) imbalance. The architecture consists of transceiver IQ skew estimation methods and a low-complexity MIMO equalizer structure. Before the IQ skew estimation, the chromatic dispersion(CD) is pre-compensated in the transmitter(TX) by chirp filtering. The receiver(RX) IQ skew is estimated by Gardner's phase detector, and the TX skew is estimated by finding the value that yields the lowest equalizer error. The low-complexity MIMO equalizer consists of a complex-valued MIMO(CV-MIMO) and a real-valued DD-LMS MIMO(RV-MIMO), which employ a butterfly and a non-butterfly structure, respectively. The CV-MIMO is used to perform polarization demultiplexing. The RV-MIMO equalizes each of the two polarisations and simultaneously compensates for the TX IQ imbalance. The architecture first compensates for the IQ skew at low-complexity, and the other imperfections are compensated by the low-complexity MIMO equalizer. Therefore, this architecture can equalize signals impaired by the transceiver IQ imbalance with low complexity. A 100 km transmission simulation and experiment with 36 Gbaud dual-polarization quadrature amplitude modulation(DP-QAM) signals and offline DSP showed that, with the RX IQ skew estimation, the number of real multiplications is reduced by more than 70% compared with conventional cases. With the low-complexity MIMO equalizer, the number of real multiplications is reduced by 51% compared with 4x4 MIMO

</details>


### [8] [Resource Orchestration and Optimization in 6G Extreme-edge Scenario](https://arxiv.org/abs/2512.13306)
*Manuel A. Jimenez,Sarang Kahvazadeh,Ignacio Labrador,Josep Mangues-Bafalluy*

Main category: cs.NI

TL;DR: 提出6G就绪的编排架构，专注于极端边缘的资源预测和服务弹性


<details>
  <summary>Details</summary>
Motivation: 6G网络需要从集中式云扩展到分布式边缘和高度动态的极端边缘，面临在异构、易变、移动资源上编排服务的挑战，这些资源超出传统运营商控制范围

Method: 集成三个核心模块：(i)基于AI/ML的基础设施状态预测模块，(ii)能够处理大规模多样化遥测的监控系统，(iii)确保主动性的决策引擎和执行器

Result: 提出了一个演示性的6G就绪编排架构，专注于极端边缘的资源预测和服务弹性

Conclusion: 该架构通过预测性监控和主动决策机制，解决了6G极端边缘环境中的服务编排挑战

Abstract: 6G networks envision a pervasive service infrastructure spanning from centralized cloud to distributed edge and highly dynamic extreme-edge domains. This vision introduces significant challenges in orchestrating services over heterogeneous, volatile, and often mobile resources beyond traditional operator control. To address these challenges, this demo presents a 6G-ready orchestration architecture focused on resource prediction and service resilience at the extreme-edge. The proposed solution integrates (i) an AI/ML-based Infrastructure Status Prediction Module, (ii) a Monitoring System capable of handling large-scale, diverse telemetry, and (iii) a Decision Engine and Actuator that ensures proactive

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models](https://arxiv.org/abs/2512.11835)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 基于人工年龄评分(AAS)构建可执行的莱布尼茨单子论条款架构，为LLM内存和控制提供法律式约束，实现透明可审计的内部动态管理。


<details>
  <summary>Details</summary>
Motivation: LLM通常作为强大但不透明的系统部署，缺乏对内部内存和"自我类似"行为的可审计治理原则。需要建立透明、可执行的约束框架来规范LLM的内部动态。

Method: 基于AAS内核构建工程化条款架构，将莱布尼茨《单子论》中的20个单子分组为6个束（本体论、动力学、表征与意识、和谐与理性、身体与组织、目的论），实现为可执行规范，通过Python实验验证。

Result: 条款系统表现出有界且可解释的行为：AAS轨迹保持连续和速率限制，矛盾触发明确惩罚，分层细化揭示有机结构，和谐项对齐双重视图和目标-行动对，窗口化漂移分离持续改进与退化。

Conclusion: 基于单子的条款框架以AAS为骨干，为约束和分析人工智能体内部动态提供了透明、代码级的蓝图，将哲学动机转化为可直接实现的工程方案。

Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and "self-like" behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introduced and mathematically justified through three theorems that characterise it as a metric of artificial memory aging. Building on this foundation, the present work develops an engineering-oriented, clause-based architecture that imposes law-like constraints on LLM memory and control. Twenty selected monads from Leibniz's Monadology are grouped into six bundles: ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, and teleology, and each bundle is realised as an executable specification on top of the AAS kernel. Across six minimal Python implementations, these clause families are instantiated in numerical experiments acting on channel-level quantities such as recall scores, redundancy, and weights. Each implementation follows a four-step pattern: inputs and setup, clause implementation, numerical results, and implications for LLM design, emphasising that the framework is not only philosophically motivated but also directly implementable. The experiments show that the clause system exhibits bounded and interpretable behavior: AAS trajectories remain continuous and rate-limited, contradictions and unsupported claims trigger explicit penalties, and hierarchical refinement reveals an organic structure in a controlled manner. Dual views and goal-action pairs are aligned by harmony terms, and windowed drift in perfection scores separates sustained improvement from sustained degradation. Overall, the monad-based clause framework uses AAS as a backbone and provides a transparent, code-level blueprint for constraining and analyzing internal dynamics in artificial agents.

</details>


### [10] [Solving Parallel Machine Scheduling With Precedences and Cumulative Resource Constraints With Calendars](https://arxiv.org/abs/2512.11864)
*Christoph Einspieler,Matthias Horn,Marie-Louise Lackner,Patrick Malik,Nysret Musliu,Felix Winter*

Main category: cs.AI

TL;DR: 提出一种考虑作业优先级和基于日历的累积资源约束的并行机器调度新变体，结合约束建模精确求解小规模实例，以及构造启发式和定制元启发式处理大规模工业场景。


<details>
  <summary>Details</summary>
Motivation: 现代工业制造中并行机器调度存在巨大成本优化潜力，但现有方法无法有效处理真实生产环境中的复杂优先级约束和基于日历的资源限制，需要开发能解决这类实际问题的自动化方法。

Method: 1) 提出包含作业优先级和日历累积资源约束的新调度变体；2) 使用约束建模方法配合先进约束求解技术精确求解小规模场景；3) 提出构造启发式算法；4) 设计基于局部搜索的定制元启发式算法处理大规模实例。

Result: 开发的方法已在实际工业环境中部署使用，能够有效处理真实生产环境中的复杂约束，填补了现有技术在处理日历资源约束和优先级限制方面的不足。

Conclusion: 提出的新调度变体和相应求解方法能够有效解决工业实际中的并行机器调度问题，特别是针对包含复杂优先级和日历资源约束的场景，为实际生产环境提供了可行的自动化调度解决方案。

Abstract: The task of finding efficient production schedules for parallel machines is a challenge that arises in most industrial manufacturing domains. There is a large potential to minimize production costs through automated scheduling techniques, due to the large-scale requirements of modern factories. In the past, solution approaches have been studied for many machine scheduling variations, where even basic variants have been shown to be NP-hard. However, in today's real-life production environments, additional complex precedence constraints and resource restrictions with calendars arise that must be fulfilled. These additional constraints cannot be tackled efficiently by existing solution techniques. Thus, there is a strong need to develop and analyze automated methods that can solve such real-life parallel machine scheduling scenarios. In this work, we introduce a novel variant of parallel machine scheduling with job precedences and calendar-based cumulative resource constraints that arises in real-life industrial use cases. A constraint modeling approach is proposed as an exact solution method for small scheduling scenarios together with state-of-the-art constraint-solving technology. Further, we propose a construction heuristic as well as a tailored metaheuristic using local search to efficiently tackle large-scale problem instances. This metaheuristic approach has been deployed and is currently being used in an industrial setting.

</details>


### [11] [Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning](https://arxiv.org/abs/2512.11902)
*Yanna Elizabeth Smid,Peter van der Putten,Aske Plaat*

Main category: cs.AI

TL;DR: 提出Mirror Mode游戏模式，让AI模仿玩家个人策略来挑战玩家，在Fire Emblem Heroes简化版中实现，结合GAIL、BC和PPO训练模型，玩家测试显示防御行为模仿良好但进攻策略不足，整体玩家满意度更高。


<details>
  <summary>Details</summary>
Motivation: 为了让回合制游戏中的敌人策略更加出人意料和不可预测，需要设计能够挑战玩家并迫使他们不断改变游戏策略的AI系统。

Method: 1. 在Unity中构建Fire Emblem Heroes简化版，包含标准模式和镜像模式；2. 使用强化学习和模仿学习（GAIL、行为克隆、PPO）训练模仿玩家演示的模型；3. 通过玩家测试评估模型，在参与者提供的演示上训练模型。

Result: 玩家游戏行为分析显示模型在防御行为上模仿良好，但在进攻策略上不足；问卷调查表明玩家能识别自己的撤退战术，镜像模式整体玩家满意度更高。

Conclusion: 镜像模式能提高玩家满意度，进一步优化模型可以改善模仿质量，特别是当玩家面对自己策略时效果更佳。

Abstract: Enemy strategies in turn-based games should be surprising and unpredictable. This study introduces Mirror Mode, a new game mode where the enemy AI mimics the personal strategy of a player to challenge them to keep changing their gameplay. A simplified version of the Nintendo strategy video game Fire Emblem Heroes has been built in Unity, with a Standard Mode and a Mirror Mode. Our first set of experiments find a suitable model for the task to imitate player demonstrations, using Reinforcement Learning and Imitation Learning: combining Generative Adversarial Imitation Learning, Behavioral Cloning, and Proximal Policy Optimization. The second set of experiments evaluates the constructed model with player tests, where models are trained on demonstrations provided by participants. The gameplay of the participants indicates good imitation in defensive behavior, but not in offensive strategies. Participant's surveys indicated that they recognized their own retreating tactics, and resulted in an overall higher player-satisfaction for Mirror Mode. Refining the model further may improve imitation quality and increase player's satisfaction, especially when players face their own strategies. The full code and survey results are stored at: https://github.com/YannaSmid/MirrorMode

</details>


### [12] [Structured Personalization: Modeling Constraints as Matroids for Data-Minimal LLM Agents](https://arxiv.org/abs/2512.11907)
*Daniel Platnick,Marjan Alirezaie,Hossein Rahnama*

Main category: cs.AI

TL;DR: 论文提出了一种结构化个性化方法，将用户知识图编译为宏面，证明常见约束形成层状拟阵，从而将个性化问题转化为带拟阵约束的子模最大化问题，获得近似保证。


<details>
  <summary>Details</summary>
Motivation: 个性化LLM代理需要在任务效用和数据披露之间权衡。现实中的个性化面临复杂的结构化约束（逻辑依赖、类别配额、分层规则），这些约束违反了标准子集选择算法的假设。

Method: 提出原则性方法：1）将带有依赖关系的用户知识图编译为一组抽象的宏面；2）证明常见分层和配额约束在这些宏面上形成有效的层状拟阵；3）将结构化个性化问题转化为带拟阵约束的子模最大化问题。

Result: 理论证明：常见分层和配额约束形成层状拟阵，这使得结构化个性化问题可以转化为带拟阵约束的子模最大化问题，从而获得贪婪算法的常数因子保证（或连续贪婪的(1-1/e)保证）。

Conclusion: 该方法为更丰富、更现实的结构化个性化问题提供了理论保证，扩展了子模优化在个性化LLM代理中的应用范围。

Abstract: Personalizing Large Language Model (LLM) agents requires conditioning them on user-specific data, creating a critical trade-off between task utility and data disclosure. While the utility of adding user data often exhibits diminishing returns (i.e., submodularity), enabling near-optimal greedy selection, real-world personalization is complicated by structural constraints. These include logical dependencies (e.g., selecting fact A requires fact B), categorical quotas (e.g., select at most one writing style), and hierarchical rules (e.g., select at most two social media preferences, of which at most one can be for a professional network). These constraints violate the assumptions of standard subset selection algorithms. We propose a principled method to formally model such constraints. We introduce a compilation process that transforms a user's knowledge graph with dependencies into a set of abstract macro-facets. Our central result is a proof that common hierarchical and quota-based constraints over these macro-facets form a valid laminar matroid. This theoretical characterization lets us cast structured personalization as submodular maximization under a matroid constraint, enabling greedy with constant-factor guarantees (and (1-1/e) via continuous greedy) for a much richer and more realistic class of problems.

</details>


### [13] [Causal Strengths and Leaky Beliefs: Interpreting LLM Reasoning via Noisy-OR Causal Bayes Nets](https://arxiv.org/abs/2512.11909)
*Hanna Dettki*

Main category: cs.AI

TL;DR: 该研究通过因果推理任务比较LLMs与人类的表现，使用因果贝叶斯网络建模，发现LLMs在因果推理上与人类存在差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解人类与机器智能的本质差异，特别是因果推理能力这一关键智能特征。通过在同一任务上比较LLMs和人类的表现，可以更全面地了解两者的优势和弱点。

Method: 方法包括：1）在11个语义化因果任务上评估20多个LLMs；2）使用碰撞图结构（C₁→E←C₂）形式化任务；3）采用直接推理（单次概率判断）和思维链（CoT）两种推理模式；4）使用泄漏噪声OR因果贝叶斯网络建模判断，通过AIC选择最佳模型（对称vs非对称参数）。

Result: 研究回答了三个核心问题：1）LLMs与人类在相同推理任务上是否一致？2）两者在任务层面是否保持一致的推理模式？3）它们是否有不同的推理特征？具体结果需要进一步分析数据。

Conclusion: 该研究为理解LLMs与人类在因果推理方面的差异提供了系统框架，通过因果贝叶斯网络建模揭示了可能的推理模式差异，有助于深入理解机器智能的本质。

Abstract: The nature of intelligence in both humans and machines is a longstanding question. While there is no universally accepted definition, the ability to reason causally is often regarded as a pivotal aspect of intelligence (Lake et al., 2017). Evaluating causal reasoning in LLMs and humans on the same tasks provides hence a more comprehensive understanding of their respective strengths and weaknesses. Our study asks: (Q1) Are LLMs aligned with humans given the \emph{same} reasoning tasks? (Q2) Do LLMs and humans reason consistently at the task level? (Q3) Do they have distinct reasoning signatures?
  We answer these by evaluating 20+ LLMs on eleven semantically meaningful causal tasks formalized by a collider graph ($C_1\!\to\!E\!\leftarrow\!C_2$ ) under \emph{Direct} (one-shot number as response = probability judgment of query node being one and \emph{Chain of Thought} (CoT; think first, then provide answer).
  Judgments are modeled with a leaky noisy-OR causal Bayes net (CBN) whose parameters $θ=(b,m_1,m_2,p(C)) \in [0,1]$ include a shared prior $p(C)$;
  we select the winning model via AIC between a 3-parameter symmetric causal strength ($m_1{=}m_2$) and 4-parameter asymmetric ($m_1{\neq}m_2$) variant.

</details>


### [14] [Robustness of Probabilistic Models to Low-Quality Data: A Multi-Perspective Analysis](https://arxiv.org/abs/2512.11912)
*Liu Peng,Yaochu Jin*

Main category: cs.AI

TL;DR: 研究发现不同概率模型对低质量数据的鲁棒性存在显著差异：自回归语言模型表现出惊人韧性，扩散模型则灾难性退化，分类器影响适中且随数据规模减小。


<details>
  <summary>Details</summary>
Motivation: 系统比较现代概率模型在低质量数据下的表现差异，探究不同模型鲁棒性差异的根本原因。

Method: 通过数据腐蚀实验（如50%标记损坏）测试不同模型性能，结合信息论、PAC学习和梯度动力学等多视角分析框架。

Result: 自回归语言模型（如GPT-2）在50%标记损坏下测试NLL仅从2.87增至3.59，扩散模型图像标签一致性暴跌56.81%，分类器影响适中且随数据集规模减小。

Conclusion: 模型鲁棒性主要由两个关键原则决定：条件信息的丰富程度（约束学习问题）和训练数据的绝对信息量（使正确信息信号主导统计噪声）。

Abstract: A systematic, comparative investigation into the effects of low-quality data reveals a stark spectrum of robustness across modern probabilistic models. We find that autoregressive language models, from token prediction to sequence-to-sequence tasks, are remarkably resilient (for GPT-2, test NLL increases modestly from 2.87 to 3.59 despite 50% token corruption). By contrast, under the same levels of data corruption, class-conditional diffusion models degrade catastrophically (image-label consistency plummets by 56.81% relative to baseline), while classifiers show a moderate impact that diminishes with dataset scale. To explain these discrepancies, we analyze the results through a multi-perspective lens, integrating information theory, PAC learning, and gradient dynamics. These analyses suggest that robustness is heavily influenced by two key principles: the richness of conditioning information, which constrains the learning problem, and the absolute information content of the training data, which allows the signal from correct information to dominate statistical noise.

</details>


### [15] [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: CXL-SpecKV：基于CXL互连和FPGA加速器的解耦KV缓存架构，通过内存解耦、推测性预取和压缩技术，解决LLM推理中的KV缓存内存瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数据中心部署时面临KV缓存内存需求巨大的挑战，限制了批处理大小和系统吞吐量，需要解决内存墙问题。

Method: 提出CXL-SpecKV架构，包含三个关键技术：1）基于CXL的内存解耦框架，将KV缓存卸载到远程FPGA内存；2）推测性KV缓存预取机制，预测并预加载未来token的缓存条目；3）FPGA加速的KV缓存压缩/解压缩引擎，降低内存带宽需求。

Result: 在先进的LLM模型上评估，CXL-SpecKV相比GPU-only基线实现了3.2倍吞吐量提升，内存成本降低2.8倍，同时保持准确性。

Conclusion: 智能内存解耦与推测执行相结合能有效解决大规模LLM服务中的内存墙挑战，CXL-SpecKV为高效LLM部署提供了可行方案。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial GPU memory, limiting batch sizes and overall system throughput. To address these challenges, we propose \textbf{CXL-SpecKV}, a novel disaggregated KV-cache architecture that leverages Compute Express Link (CXL) interconnects and FPGA accelerators to enable efficient speculative execution and memory disaggregation. Our approach introduces three key innovations: (i) a CXL-based memory disaggregation framework that offloads KV-caches to remote FPGA memory with low latency, (ii) a speculative KV-cache prefetching mechanism that predicts and preloads future tokens' cache entries, and (iii) an FPGA-accelerated KV-cache compression and decompression engine that reduces memory bandwidth requirements by up to 4$\times$. When evaluated on state-of-the-art LLM models, CXL-SpecKV achieves up to 3.2$\times$ higher throughput compared to GPU-only baselines, while reducing memory costs by 2.8$\times$ and maintaining accuracy. Our system demonstrates that intelligent memory disaggregation combined with speculative execution can effectively address the memory wall challenge in large-scale LLM serving. Our code implementation has been open-sourced at https://github.com/FastLM/CXL-SpecKV.

</details>


### [16] [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)
*Jaehyung Lee,Justin Ely,Kent Zhang,Akshaya Ajith,Charles Rhys Campbell,Kamal Choudhary*

Main category: cs.AI

TL;DR: AGAPI是一个开源的材料科学AI平台，集成了8+开源LLM和20+材料科学API端点，通过Agent-Planner-Executor-Summarizer架构自主构建和执行多步骤工作流，用于加速材料发现。


<details>
  <summary>Details</summary>
Motivation: 当前AI在材料研究中面临碎片化的计算生态系统、可重复性挑战以及对商业大语言模型的依赖等限制，需要构建一个开放、统一、可复现的AI平台来加速材料科学发现。

Method: 采用Agent-Planner-Executor-Summarizer架构，集成8+开源LLM和20+材料科学API端点，统一数据库、模拟工具和机器学习模型，通过共同编排框架自主构建和执行多步骤工作流。

Result: 展示了端到端工作流（包括异质结构构建、粉末X射线衍射分析和半导体缺陷工程），评估了30+测试案例，比较了有无工具访问的代理预测与实验数据，已有1000+活跃用户。

Conclusion: AGAPI为可复现、AI加速的材料发现提供了可扩展和透明的基础设施，解决了当前材料研究中的碎片化和可重复性问题，代码已在GitHub开源。

Abstract: Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agentic AI platform that integrates more than eight open-source LLMs with over twenty materials-science API endpoints, unifying databases, simulation tools, and machine-learning models through a common orchestration framework. AGAPI employs an Agent-Planner-Executor-Summarizer architecture that autonomously constructs and executes multi-step workflows spanning materials data retrieval, graph neural network property prediction, machine-learning force-field optimization, tight-binding calculations, diffraction analysis, and inverse design. We demonstrate AGAPI through end-to-end workflows, including heterostructure construction, powder X-ray diffraction analysis, and semiconductor defect engineering requiring up to ten sequential operations. In addition, we evaluate AGAPI using 30+ example prompts as test cases and compare agentic predictions with and without tool access against experimental data. With more than 1,000 active users, AGAPI provides a scalable and transparent foundation for reproducible, AI-accelerated materials discovery. AGAPI-Agents codebase is available at https://github.com/atomgptlab/agapi.

</details>


### [17] [Hypergame Rationalisability: Solving Agent Misalignment In Strategic Play](https://arxiv.org/abs/2512.11942)
*Vince Trencsenyi*

Main category: cs.AI

TL;DR: 提出基于逻辑的声明式领域特定语言和自动管道，用于编码超博弈结构和解决方案概念，连接超博弈理论、多智能体系统和战略AI


<details>
  <summary>Details</summary>
Motivation: 传统博弈论假设忽略了玩家对游戏的主观认知差异，而超博弈理论虽然提供了处理这种认知不匹配的数学框架，但缺乏统一的、形式化的、实用的表示语言和可扩展算法，阻碍了其在多智能体系统研究中的实际应用

Method: 引入基于逻辑的声明式领域特定语言编码超博弈结构和解决方案概念，利用答案集编程开发自动管道实例化超博弈结构，并提出新的超博弈合理化程序来寻找解释看似非理性结果的信念结构

Result: 建立了超博弈的统一形式化框架，为开发基于信念的异构推理器提供了可验证的逻辑保证环境，连接了超博弈理论、多智能体系统和战略AI

Conclusion: 提出的语言和算法填补了超博弈理论实际应用的空白，为处理复杂异构信念系统提供了实用工具，推动了战略AI和多智能体系统的发展

Abstract: Differences in perception, information asymmetries, and bounded rationality lead game-theoretic players to derive a private, subjective view of the game that may diverge from the underlying ground-truth scenario and may be misaligned with other players' interpretations. While typical game-theoretic assumptions often overlook such heterogeneity, hypergame theory provides the mathematical framework to reason about mismatched mental models. Although hypergames have recently gained traction in dynamic applications concerning uncertainty, their practical adoption in multi-agent system research has been hindered by the lack of a unifying, formal, and practical representation language, as well as scalable algorithms for managing complex hypergame structures and equilibria. Our work addresses this gap by introducing a declarative, logic-based domain-specific language for encoding hypergame structures and hypergame solution concepts. Leveraging answer-set programming, we develop an automated pipeline for instantiating hypergame structures and running our novel hypergame rationalisation procedure, a mechanism for finding belief structures that justify seemingly irrational outcomes. The proposed language establishes a unifying formalism for hypergames and serves as a foundation for developing nuanced, belief-based heterogeneous reasoners, offering a verifiable context with logical guarantees. Together, these contributions establish the connection between hypergame theory, multi-agent systems, and strategic AI.

</details>


### [18] [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)
*Anfeng Peng,Ajesh Koyatan Chathoth,Stephen Lee*

Main category: cs.AI

TL;DR: EnrichLog是一个无需训练、基于条目的日志异常检测框架，通过检索增强生成技术融合语料库特定和样本特定知识，提升检测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统日志分析技术（如模板匹配和序列驱动方法）容易丢失重要语义信息或难以处理模糊日志模式，需要更准确、可解释的异常检测方法。

Method: 提出EnrichLog框架，采用检索增强生成技术，无需训练即可融合语料库特定知识（历史示例和推理）和样本特定知识，为原始日志条目提供丰富的上下文信息。

Result: 在四个大规模系统日志基准数据集上评估，相比五种基线方法，EnrichLog持续提升异常检测性能，有效处理模糊日志条目，保持高效推理，增强模型置信度和检测准确率。

Conclusion: EnrichLog通过融合语料库特定和样本特定知识，实现了更准确、可解释的异常检测，适合实际部署应用。

Abstract: System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambiguous log patterns. To address this, we present EnrichLog, a training-free, entry-based anomaly detection framework that enriches raw log entries with both corpus-specific and sample-specific knowledge. EnrichLog incorporates contextual information, including historical examples and reasoning derived from the corpus, to enable more accurate and interpretable anomaly detection. The framework leverages retrieval-augmented generation to integrate relevant contextual knowledge without requiring retraining. We evaluate EnrichLog on four large-scale system log benchmark datasets and compare it against five baseline methods. Our results show that EnrichLog consistently improves anomaly detection performance, effectively handles ambiguous log entries, and maintains efficient inference. Furthermore, incorporating both corpus- and sample-specific knowledge enhances model confidence and detection accuracy, making EnrichLog well-suited for practical deployments.

</details>


### [19] [Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp](https://arxiv.org/abs/2512.12048)
*Muddsair Sharif,Huseyin Seker*

Main category: cs.AI

TL;DR: 提出CAMAC-DRA框架，通过多智能体协调优化智能电动汽车充电生态系统，平衡多个利益相关者需求，在动态环境中实现高效资源分配。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车普及，充电生态系统面临动态资源分配挑战，需要协调多个利益相关者（用户、电网运营商、充电站运营商、车队运营商、环境因素）的竞争性目标，同时适应实时环境变化。

Method: 提出上下文敏感的多智能体协调框架，结合深度Q网络、图神经网络和注意力机制，处理20个上下文特征（天气、交通、电网负载、电价等），通过加权协调机制和共识协议平衡五个利益相关者。

Result: 在包含441,077个充电交易的真实数据集上验证，相比基线算法（DDPG、A3C、PPO、GNN）表现更优：92%协调成功率、15%能效提升、10%成本降低、20%电网压力减少、2.3倍更快收敛，同时保持88%训练稳定性和85%样本效率。

Conclusion: CAMAC-DRA框架成功开发了上下文感知的多利益相关者协调机制，在平衡竞争目标的同时适应实时变量，为智能电动汽车充电协调和可持续交通电气化提供了突破性解决方案，具有商业可行性（净现成本-122,962美元，通过可再生能源集成实现69%成本降低）。

Abstract: This paper presents a novel context-sensitive multi\-agent coordination for dynamic resource allocation (CAMAC-DRA) framework for optimizing smart electric vehicle (EV) charging ecosystems through the Smart2Charge application. The proposed system coordinates autonomous charging agents across networks of 250 EVs and 45 charging stations while adapting to dynamic environmental conditions through context-aware decision-making. Our multi-agent approach employs coordinated Deep Q\-Networks integrated with Graph Neural Networks and attention mechanisms, processing 20 contextual features including weather patterns, traffic conditions, grid load fluctuations, and electricity pricing.The framework balances five ecosystem stakeholders i.e. EV users (25\%), grid operators (20\%), charging station operators (20\%), fleet operators (20%), and environmental factors (15\%) through weighted coordination mechanisms and consensus protocols. Comprehensive validation using real-world datasets containing 441,077 charging transactions demonstrates superior performance compared to baseline algorithms including DDPG, A3C, PPO, and GNN approaches. The CAMAC\-DRA framework achieves 92\% coordination success rate, 15\% energy efficiency improvement, 10\% cost reduction, 20% grid strain decrease, and \2.3x faster convergence while maintaining 88\% training stability and 85\% sample efficiency. Real-world validation confirms commercial viability with Net Present Cost of -\$122,962 and 69\% cost reduction through renewable energy integration. The framework's unique contribution lies in developing context-aware multi-stakeholder coordination that successfully balances competing objectives while adapting to real-time variables, positioning it as a breakthrough solution for intelligent EV charging coordination and sustainable transportation electrification.

</details>


### [20] [The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification](https://arxiv.org/abs/2512.12059)
*Luke Bhan,Hanyu Zhang,Andrew Gordon Wilson,Michael W. Mahoney,Chuck Arvin*

Main category: cs.AI

TL;DR: 利用大语言模型进行自动化预测监控的系统，通过评估LLM在时间序列预测质量评估方面的能力，证明其能可靠检测不良预测并整合非结构化特征。


<details>
  <summary>Details</summary>
Motivation: 在大型零售业务中，预测系统监控对客户满意度、盈利能力和运营效率至关重要。传统方法可能无法有效处理复杂的时间序列模式和整合非结构化特征。

Method: 提出Forecast Critic系统，利用LLM的广泛世界知识和推理能力进行自动化预测监控。通过三个实验系统评估LLM能力：(1)检测明显不合理预测，(2)整合非结构化外部特征，(3)比较不同模型规模和推理能力的性能。

Result: LLM能可靠检测时间错位、趋势不一致和峰值错误等不良预测，最佳模型F1分数0.88（人类水平0.97）。多模态LLM能有效整合非结构化上下文信号，在促销历史背景下识别缺失或虚假促销峰值的F1分数0.84。在M5数据集上，不合理预测的sCRPS至少比合理预测高10%。

Conclusion: 即使没有领域特定微调，LLM也能为自动化预测监控和评估提供可行且可扩展的解决方案，展示了在零售预测监控中的实际应用潜力。

Abstract: Monitoring forecasting systems is critical for customer satisfaction, profitability, and operational efficiency in large-scale retail businesses. We propose The Forecast Critic, a system that leverages Large Language Models (LLMs) for automated forecast monitoring, taking advantage of their broad world knowledge and strong ``reasoning'' capabilities. As a prerequisite for this, we systematically evaluate the ability of LLMs to assess time series forecast quality, focusing on three key questions. (1) Can LLMs be deployed to perform forecast monitoring and identify obviously unreasonable forecasts? (2) Can LLMs effectively incorporate unstructured exogenous features to assess what a reasonable forecast looks like? (3) How does performance vary across model sizes and reasoning capabilities, measured across state-of-the-art LLMs? We present three experiments, including on both synthetic and real-world forecasting data. Our results show that LLMs can reliably detect and critique poor forecasts, such as those plagued by temporal misalignment, trend inconsistencies, and spike errors. The best-performing model we evaluated achieves an F1 score of 0.88, somewhat below human-level performance (F1 score: 0.97). We also demonstrate that multi-modal LLMs can effectively incorporate unstructured contextual signals to refine their assessment of the forecast. Models correctly identify missing or spurious promotional spikes when provided with historical context about past promotions (F1 score: 0.84). Lastly, we demonstrate that these techniques succeed in identifying inaccurate forecasts on the real-world M5 time series dataset, with unreasonable forecasts having an sCRPS at least 10% higher than that of reasonable forecasts. These findings suggest that LLMs, even without domain-specific fine-tuning, may provide a viable and scalable option for automated forecast monitoring and evaluation.

</details>


### [21] [Reliable Policy Iteration: Performance Robustness Across Architecture and Environment Perturbations](https://arxiv.org/abs/2512.12088)
*S. R. Eshwar,Aniruddha Mukherjee,Kintan Saha,Krishna Agarwal,Gugan Thoppe,Aditya Gopalan,Gal Dalal*

Main category: cs.AI

TL;DR: RPI在CartPole和Inverted Pendulum任务中相比主流深度强化学习方法表现出更早达到接近最优性能且训练更稳定的优势


<details>
  <summary>Details</summary>
Motivation: 深度强化学习方法存在样本效率低、训练不稳定和超参数敏感等问题，需要更可靠的替代方案

Method: 在函数逼近设置中恢复策略迭代的单调性价值估计属性，并在CartPole和Inverted Pendulum两个经典控制任务中评估RPI的鲁棒性

Result: 相比DQN、Double DQN、DDPG、TD3和PPO，RPI能更早达到接近最优性能并保持稳定，对神经网络和环境参数变化表现出鲁棒性

Conclusion: RPI作为更可靠的深度强化学习替代方案具有前景，能解决现有方法的样本效率、稳定性和超参数敏感性问题

Abstract: In a recent work, we proposed Reliable Policy Iteration (RPI), that restores policy iteration's monotonicity-of-value-estimates property to the function approximation setting. Here, we assess the robustness of RPI's empirical performance on two classical control tasks -- CartPole and Inverted Pendulum -- under changes to neural network and environmental parameters. Relative to DQN, Double DQN, DDPG, TD3, and PPO, RPI reaches near-optimal performance early and sustains this policy as training proceeds. Because deep RL methods are often hampered by sample inefficiency, training instability, and hyperparameter sensitivity, our results highlight RPI's promise as a more reliable alternative.

</details>


### [22] [Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective](https://arxiv.org/abs/2512.12175)
*Haoyang Chen,Richong Zhang,Junfan Chen*

Main category: cs.AI

TL;DR: 该论文提出TopK-SD方法，通过结合语义和标签信息合成数据，选择标签一致的演示样本，以改进大语言模型的上下文学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索的方法选择语义最相似的top-K示例作为演示，但无法保证标签一致性。作者认为标签一致性对上下文学习至关重要，需要新的视角来理解ICL工作机制。

Method: 将ICL视为转导学习方法，从贝叶斯视角和标签传播角度重新思考。提出数据合成方法，结合语义和标签信息，使用TopK-SD（带合成数据的TopK采样）选择标签一致的演示样本。

Result: TopK-SD在多个基准测试中优于原始TopK采样方法，验证了标签一致性对ICL性能的重要性。

Conclusion: 该工作为理解ICL工作机制提供了新视角，强调标签一致性在演示选择中的重要性，提出的TopK-SD方法能有效提升ICL性能。

Abstract: Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.

</details>


### [23] [Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation](https://arxiv.org/abs/2512.12177)
*Aydin Ayanzadeh,Tim Oates*

Main category: cs.AI

TL;DR: Floorplan2Guide：利用基础模型将平面图转换为可导航知识图谱，为视障人士生成人类可读导航指令的系统


<details>
  <summary>Details</summary>
Motivation: 现有室内导航方案主要依赖基础设施系统，在动态环境中导航能力受限。需要一种能够利用建筑平面图自动生成导航指令的解决方案，减少人工预处理，提高视障人士的室内导航安全性。

Method: 使用大型语言模型从建筑布局中提取空间信息，将平面图转换为可导航知识图谱，通过少样本学习生成人类可读导航指令。比较了零样本学习和少样本学习的效果。

Result: 少样本学习相比零样本学习显著提高导航准确率。Claude 3.7 Sonnet在MP-1平面图上5-shot提示下，短、中、长路径准确率分别为92.31%、76.92%、61.54%。基于图的空间结构比直接视觉推理成功率高出15.4%。

Conclusion: 图形表示和上下文学习能增强导航性能，使解决方案对视障用户的室内导航更加精确。Floorplan2Guide通过自动处理平面图减少了人工预处理需求，为视障人士提供了更有效的室内导航方案。

Abstract: Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.

</details>


### [24] [TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion](https://arxiv.org/abs/2512.12182)
*Xinyu Gao*

Main category: cs.AI

TL;DR: 提出一个结合两阶段注意力三元增强器和U-KAN扩散模型的少样本知识图谱补全框架，在两个公开数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识图谱中关系分布呈长尾特性，需要解决少样本下的缺失事实补全问题。现有方法要么未能充分利用图邻域信息，要么忽视了对比信号的分布特性。

Method: 从生成表示的角度重新审视问题，提出整合两阶段注意力三元增强器和基于U-KAN的扩散模型的少样本知识图谱补全框架。

Result: 在两个公开数据集上的大量实验表明，该方法取得了新的最先进结果。

Conclusion: 通过生成表示视角和创新的两阶段注意力三元增强器与U-KAN扩散模型结合，有效解决了少样本知识图谱补全问题。

Abstract: Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.

</details>


### [25] [A Geometric Theory of Cognition](https://arxiv.org/abs/2512.12225)
*Laha Ale*

Main category: cs.AI

TL;DR: 提出一个统一的几何框架，将多种认知过程解释为单一几何原理的涌现：认知状态表示为黎曼流形上的点，认知过程是该流形上认知势能的梯度流。


<details>
  <summary>Details</summary>
Motivation: 人类认知涵盖感知、记忆、直觉判断、深思熟虑推理、行动选择和社会推理等多个方面，但这些能力通常由不同的计算理论解释。需要建立一个统一的数学框架来解释这些多样化的认知过程。

Method: 将认知状态表示为可微流形上的点，该流形配备学习的黎曼度量，编码表征约束、计算成本和认知变量间的结构关系。定义包含预测准确性、结构简洁性、任务效用和规范要求的标量认知势能。认知过程是该势能的黎曼梯度流。

Result: 经典的双过程效应（快速直觉响应和缓慢深思熟虑推理）自然地从度量诱导的各向异性中涌现，产生内在时间尺度分离和几何相变，无需模块化或混合架构。通过模拟经典认知任务验证了这些行为特征。

Conclusion: 建立了一个认知的几何基础，为开发更通用、更类人的人工智能系统提供了指导原则。

Abstract: Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.

</details>


### [26] [A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure](https://arxiv.org/abs/2512.12260)
*Ege Atacan Doğan,Peter F. Patel-Schneider*

Main category: cs.AI

TL;DR: 本文分析Wikidata的多层次、多轴分类设计，与传统本体论的单根层次结构形成对比，探讨其结构意义和优势。


<details>
  <summary>Details</summary>
Motivation: 传统本体论设计强调互斥且穷尽的顶层区分（如持续体vs发生体、抽象vs具体、类型vs实例），构建统一的层次结构。而Wikidata采用不同的设计理念，不强制执行单一的基础分类体系，而是允许多个分类轴共存。本文旨在分析Wikidata这种多层级、多轴设计的结构意义。

Method: 分析Wikidata的多层次、多轴分类架构，研究其在共享根类"实体"下同时容纳多个分类轴的设计特点。探讨这种设计如何支持可扩展和模块化的本体构建。

Result: Wikidata的多层次、多轴设计使其能够支持可扩展和模块化的本体构建，特别适合协作性和不断演进的知识图谱。这种架构避免了传统本体论中严格的互斥分类限制，提供了更灵活的知识表示框架。

Conclusion: Wikidata的多层次、多轴分类设计为知识表示提供了更灵活、可扩展的框架，特别适合大规模协作和不断演进的知识图谱环境，与传统本体论的严格层次结构形成互补。

Abstract: Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.

</details>


### [27] [Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases](https://arxiv.org/abs/2512.12288)
*Mahule Roy,Guillaume Lambard*

Main category: cs.AI

TL;DR: 提出量子感知生成AI框架，通过多保真度学习和主动验证解决传统材料生成模型依赖DFT近似带来的系统性偏差问题，在强关联材料发现上实现3-5倍改进。


<details>
  <summary>Details</summary>
Motivation: 传统材料生成模型主要基于DFT近似泛函数据进行训练和验证，这导致模型继承了DFT在强关联系统中的系统性失败，无法发现DFT预测定性错误的材料，形成了根本性瓶颈。

Method: 提出量子感知生成AI框架，整合多保真度学习和主动验证：使用基于量子力学描述符的扩散生成器，以及基于等变神经网络势的验证器，训练于包含PBE、SCAN、HSE06、CCSD(T)等多层次理论的数据集。实施主动学习循环来量化并针对低保真度和高保真度预测之间的差异。

Result: 在多个挑战性材料类别上与最先进生成模型（CDVAE、GNoME、DiffCSP）进行基准测试，结果显示：在高差异区域（如关联氧化物）成功识别潜在稳定候选材料的能力比仅基于DFT的基线提高3-5倍，同时保持计算可行性。

Conclusion: 该工作提供了一个严谨、透明的框架，将计算材料发现的有效搜索空间扩展到单保真度模型的限制之外，解决了传统生成模型依赖DFT近似带来的系统性偏差问题。

Abstract: Conventional generative models for materials discovery are predominantly trained and validated using data from Density Functional Theory (DFT) with approximate exchange-correlation functionals. This creates a fundamental bottleneck: these models inherit DFT's systematic failures for strongly correlated systems, leading to exploration biases and an inability to discover materials where DFT predictions are qualitatively incorrect. We introduce a quantum-aware generative AI framework that systematically addresses this limitation through tight integration of multi-fidelity learning and active validation. Our approach employs a diffusion-based generator conditioned on quantum-mechanical descriptors and a validator using an equivariant neural network potential trained on a hierarchical dataset spanning multiple levels of theory (PBE, SCAN, HSE06, CCSD(T)). Crucially, we implement a robust active learning loop that quantifies and targets the divergence between low- and high-fidelity predictions. We conduct comprehensive ablation studies to deconstruct the contribution of each component, perform detailed failure mode analysis, and benchmark our framework against state-of-the-art generative models (CDVAE, GNoME, DiffCSP) across several challenging material classes. Our results demonstrate significant practical gains: a 3-5x improvement in successfully identifying potentially stable candidates in high-divergence regions (e.g., correlated oxides) compared to DFT-only baselines, while maintaining computational feasibility. This work provides a rigorous, transparent framework for extending the effective search space of computational materials discovery beyond the limitations of single-fidelity models.

</details>


### [28] [Entropy Collapse: A Universal Failure Mode of Intelligent Systems](https://arxiv.org/abs/2512.12381)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: 论文提出"熵崩溃"作为智能系统的普遍失效模式：当反馈放大超过有限新颖性再生时，系统会从高熵适应状态急剧过渡到低熵崩溃状态，导致适应性维度收缩而非完全停止。


<details>
  <summary>Details</summary>
Motivation: 智能系统（从AI到经济制度和生物进化）常出现矛盾现象：智能增加反而导致系统僵化、适应性丧失和意外失效。需要理解这种普遍存在的退化模式背后的统一机制。

Method: 在最小化领域无关假设下，将熵崩溃形式化为向稳定低熵流形的收敛过程。通过分析建立临界阈值、动态不可逆性和吸引子结构，并通过最小模拟验证更新机制的普适性。

Result: 识别出熵崩溃作为智能系统的普遍动态失效模式，统一解释了AI中的模型崩溃、经济学中的制度僵化和进化中的遗传瓶颈等现象。证明了系统会经历从高熵适应状态到低熵崩溃状态的急剧相变。

Conclusion: 熵崩溃是智能的结构性代价，晚期干预通常无效。研究结果为设计熵感知原则以维持智能系统长期适应性提供了理论基础，强调需要预防性而非修复性策略。

Abstract: Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.
  We identify \emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.
  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.
  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.
  \noindent\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis

</details>


### [29] [Feeling the Strength but Not the Source: Partial Introspection in LLMs](https://arxiv.org/abs/2512.12411)
*Ely Hahami,Lavik Jain,Ishaan Sinha*

Main category: cs.AI

TL;DR: 论文测试了语言模型对注入概念的"涌现内省"能力，发现该能力具有脆弱性但存在部分内省现象


<details>
  <summary>Details</summary>
Motivation: 验证Anthropic关于前沿模型能检测和命名注入概念的声称，测试其鲁棒性并探索内省能力的边界

Method: 1) 在Meta-Llama-3.1-8B-Instruct上复现Anthropic的多轮"涌现内省"实验；2) 系统性地改变推理提示，测试内省能力的脆弱性；3) 探索部分内省现象，测试模型对注入概念向量强度的分类能力

Result: 1) 成功复现Anthropic结果，20%识别率；2) 内省能力脆弱，在相关任务上性能崩溃；3) 发现部分内省现象，概念强度分类准确率达70%（远高于25%基线）

Conclusion: 语言模型内省能力确实存在，但具有狭窄性和提示敏感性，模型能有效计算其内部表示的函数，但自我报告能力有限

Abstract: Recent work from Anthropic claims that frontier models can sometimes detect and name injected "concepts" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn "emergent introspection" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.

</details>


### [30] [Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale](https://arxiv.org/abs/2512.12413)
*Gabriel R. Lau,Wei Yan Low,Louis Tay,Ysabel Guevarra,Dragan Gašević,Andree Hartanto*

Main category: cs.AI

TL;DR: 开发并验证了一个13项的量表，用于测量AI使用中的批判性思维，包含验证、动机和反思三个维度，该量表能预测更准确的AI输出判断和更深入的AI责任反思。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在日常工作和学习中的普及，用户需要批判性地评估AI输出而非盲目接受，但缺乏系统测量AI使用中批判性思维的工具。

Method: 通过6项研究(N=1365)开发并验证了13项AI使用批判性思维量表：研究1生成和内容验证项目；研究2支持三因素结构(验证、动机、反思)；研究3-5验证高阶模型、信效度；研究6证明量表能预测验证策略、事实判断准确性和AI责任反思。

Result: 量表具有良好心理测量特性，AI使用批判性思维与开放性、外向性、积极特质情感和AI使用频率正相关，能预测更频繁多样的验证策略、在ChatGPT事实核查任务中更高的判断准确性，以及更深入的负责任AI反思。

Conclusion: 该研究阐明了人们如何监督生成式AI输出，提供了经过验证的量表和生态效度高的任务范式，支持理论检验、跨群体和纵向研究，促进对生成式AI输出的批判性参与。

Abstract: Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.

</details>


### [31] [AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline](https://arxiv.org/abs/2512.12443)
*Akhmadillo Mamirov,Faiaz Azmain,Hanyu Wang*

Main category: cs.AI

TL;DR: 论文分析了AI模型文档的碎片化和不一致问题，提出了基于欧盟AI法案和斯坦福透明度指数的加权透明度框架，并开发了自动化评估管道，发现前沿实验室透明度约80%，而大多数提供商低于60%，安全关键类别存在最大缺陷。


<details>
  <summary>Details</summary>
Motivation: AI模型文档分散在不同平台且结构不一致，导致政策制定者、审计者和用户无法可靠评估安全声明、数据来源和版本变更。文档的碎片化和命名极度不统一阻碍了透明度评估。

Method: 分析了5个前沿模型和100个Hugging Face模型卡，识别出947个独特章节名称。基于欧盟AI法案附件IV和斯坦福透明度指数，开发了包含8个章节和23个子章节的加权透明度框架，优先安全关键披露。实现了自动化多智能体管道，从公共源提取文档并通过LLM共识评分完整性。

Result: 评估50个模型（视觉、多模态、开源和闭源）总成本低于3美元。前沿实验室（xAI、微软、Anthropic）达到约80%合规性，大多数提供商低于60%。安全关键类别缺陷最大：欺骗行为、幻觉和儿童安全评估分别损失148、124和116个总分。

Conclusion: AI模型文档透明度存在系统性差距，安全关键信息披露严重不足。提出的加权框架和自动化评估管道能高效识别透明度缺陷，为监管合规和行业标准制定提供实用工具。

Abstract: AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.

</details>


### [32] [MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs](https://arxiv.org/abs/2512.12477)
*Jiawen Chen,Yanyan He,Qi Shao,Mengli Wei,Duxin Chen,Wenwu Yu,Yanlong Zhao*

Main category: cs.AI

TL;DR: MetaHGNIE：基于元路径诱导超图对比学习的异质知识图谱节点重要性估计框架，通过建模高阶依赖和跨模态对齐提升性能


<details>
  <summary>Details</summary>
Motivation: 现有异质知识图谱节点重要性估计方法存在两个主要问题：1）仅依赖成对连接，忽略多实体关系的高阶依赖；2）将结构和语义信号独立处理，缺乏有效的跨模态整合。需要同时解决高阶依赖建模和跨模态对齐问题。

Method: 1）通过元路径序列构建高阶知识图谱，使用类型化超边捕获多实体关系上下文；2）结构依赖通过局部注意力聚合，语义表示通过配备稀疏分块的超图变换器编码以减少冗余；3）多模态融合模块在对比学习和辅助监督下整合结构和语义嵌入，确保鲁棒的跨模态对齐。

Result: 在基准NIE数据集上的广泛实验表明，MetaHGNIE始终优于最先进的基线方法，验证了显式建模高阶交互和跨模态对齐的有效性。

Conclusion: MetaHGNIE通过元路径诱导的超图对比学习框架，成功解决了异质知识图谱中节点重要性估计的高阶依赖建模和跨模态对齐问题，为推荐、知识推理和问答等应用提供了更有效的解决方案。

Abstract: Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE

</details>


### [33] [SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation](https://arxiv.org/abs/2512.12501)
*Dang Phuong Nam,Nguyen Kieu,Pham Thanh Hieu*

Main category: cs.AI

TL;DR: SafeGen是一个将伦理保障嵌入文本到图像生成流程的框架，通过BGE-M3文本分类器过滤有害提示和Hyper-SD优化扩散模型生成高质量图像，在创意自由与伦理责任之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创造、教育和研究方面带来新机遇，但文本到图像系统如DALL.E、Stable Diffusion等存在双重使用困境：放大社会偏见、产生高保真虚假信息、侵犯知识产权，需要解决这些伦理问题。

Method: 基于可信AI原则设计SafeGen框架，包含两个互补组件：1) BGE-M3微调文本分类器，过滤有害或误导性提示；2) Hyper-SD优化扩散模型，生成高保真、语义对齐的图像。使用多语言数据集和公平感知训练过程。

Result: 定量评估显示Hyper-SD达到IS=3.52、FID=22.08、SSIM=0.79，BGE-M3达到F1分数0.81。消融研究验证了领域特定微调的重要性。案例研究展示了SafeGen在阻止不安全提示、生成包容性教学材料和加强学术诚信方面的实际效果。

Conclusion: SafeGen证明创意自由和伦理责任可以在单一工作流程中协调，通过将伦理保障直接嵌入生成流程，为解决生成式AI的伦理挑战提供了可行方案。

Abstract: Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established principles for Trustworthy AI. SafeGen integrates two complementary components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading prompts, and Hyper-SD, an optimized diffusion model that produces high fidelity, semantically aligned images. Built on a curated multilingual (English- Vietnamese) dataset and a fairness-aware training process, SafeGen demonstrates that creative freedom and ethical responsibility can be reconciled within a single workflow. Quantitative evaluations confirm its effectiveness, with Hyper-SD achieving IS = 3.52, FID = 22.08, and SSIM = 0.79, while BGE-M3 reaches an F1-Score of 0.81. An ablation study further validates the importance of domain-specific fine-tuning for both modules. Case studies illustrate SafeGen's practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

</details>


### [34] [KidsArtBench: Multi-Dimensional Children's Art Evaluation with Attribute-Aware MLLMs](https://arxiv.org/abs/2512.12503)
*Mingrui Ye,Chanjin Zheng,Zengyi Yu,Chenyu Xiang,Zhixue Zhao,Zheng Yuan,Helen Yannakoudakis*

Main category: cs.AI

TL;DR: KidsArtBench：首个针对儿童艺术作品的多维度美学评估基准，包含1k+儿童画作（5-15岁）的9个维度专家标注，提出属性特定的多LoRA方法提升MLLMs评估能力


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在艺术表达评估方面能力有限，美学概念抽象且开放，多模态艺术作品标注稀缺。儿童艺术作品评估尤其缺乏系统基准，需要教育导向的评估方法

Method: 1. 构建KidsArtBench基准：收集1000+儿童画作（5-15岁），由12位专家教育者按9个维度（如写实性、想象力等）标注，包含评分和评语反馈
2. 提出属性特定的多LoRA方法：每个评估维度对应一个独立的LoRA适配器，结合回归感知微调（RAFT）使预测与有序评分尺度对齐

Result: 在Qwen2.5-VL-7B模型上，相关性从0.468提升至0.653，在感知维度提升最大，高阶属性差距缩小。展示了教育者对齐监督和属性感知训练能产生有教学意义的评估

Conclusion: KidsArtBench为教育AI提供了严谨的测试平台，属性特定的多LoRA方法显著提升了MLLMs对儿童艺术作品的评估能力，推动了教育导向的多模态评估研究

Abstract: Multimodal Large Language Models (MLLMs) show remarkable progress across many visual-language tasks; however, their capacity to evaluate artistic expression remains limited. Aesthetic concepts are inherently abstract and open-ended, and multimodal artwork annotations are scarce. We introduce KidsArtBench, a new benchmark of over 1k children's artworks (ages 5-15) annotated by 12 expert educators across 9 rubric-aligned dimensions, together with expert comments for feedback. Unlike prior aesthetic datasets that provide single scalar scores on adult imagery, KidsArtBench targets children's artwork and pairs multi-dimensional annotations with comment supervision to enable both ordinal assessment and formative feedback. Building on this resource, we propose an attribute-specific multi-LoRA approach, where each attribute corresponds to a distinct evaluation dimension (e.g., Realism, Imagination) in the scoring rubric, with Regression-Aware Fine-Tuning (RAFT) to align predictions with ordinal scales. On Qwen2.5-VL-7B, our method increases correlation from 0.468 to 0.653, with the largest gains on perceptual dimensions and narrowed gaps on higher-order attributes. These results show that educator-aligned supervision and attribute-aware training yield pedagogically meaningful evaluations and establish a rigorous testbed for sustained progress in educational AI. We release data and code with ethics documentation.

</details>


### [35] [World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents](https://arxiv.org/abs/2512.12548)
*Yesid Fonseca,Manuel S. Ríos,Nicanor Quijano,Luis F. Giraldo*

Main category: cs.AI

TL;DR: 使用基于模型的强化学习智能体，通过习得环境预测表征，自然收敛到边际价值定理对齐的觅食策略，比无模型方法更接近生物决策模式。


<details>
  <summary>Details</summary>
Motivation: 虽然边际价值定理（MVT）被广泛用于预测觅食行为，但生物觅食者实现最优斑块觅食决策的计算机制仍不清楚。研究旨在探索人工智能系统如何通过计算机制实现类似生物的最优觅食决策。

Method: 使用基于模型的强化学习（model-based RL）智能体，让其习得简洁的环境预测表征（世界模型），研究其斑块离开决策行为，并与标准的无模型强化学习（model-free RL）智能体进行比较。

Result: 基于模型的智能体自然收敛到与MVT对齐的策略，表现出与许多生物觅食者相似的决策模式。其高效的斑块离开行为主要源于预测能力，而非单纯的奖励最大化。

Conclusion: 预测性世界模型可以作为构建更具解释性和生物学基础的AI决策系统的基础。生态最优性原理对推进可解释和自适应AI具有重要价值。

Abstract: Patch foraging involves the deliberate and planned process of determining the optimal time to depart from a resource-rich region and investigate potentially more beneficial alternatives. The Marginal Value Theorem (MVT) is frequently used to characterize this process, offering an optimality model for such foraging behaviors. Although this model has been widely used to make predictions in behavioral ecology, discovering the computational mechanisms that facilitate the emergence of optimal patch-foraging decisions in biological foragers remains under investigation. Here, we show that artificial foragers equipped with learned world models naturally converge to MVT-aligned strategies. Using a model-based reinforcement learning agent that acquires a parsimonious predictive representation of its environment, we demonstrate that anticipatory capabilities, rather than reward maximization alone, drive efficient patch-leaving behavior. Compared with standard model-free RL agents, these model-based agents exhibit decision patterns similar to many of their biological counterparts, suggesting that predictive world models can serve as a foundation for more explainable and biologically grounded decision-making in AI systems. Overall, our findings highlight the value of ecological optimality principles for advancing interpretable and adaptive AI.

</details>


### [36] [Large Language Newsvendor: Decision Biases and Cognitive Mechanisms](https://arxiv.org/abs/2512.12552)
*Jifei Liu,Zhi Chen,Yuanguang Zhong*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在供应链决策中会复制并放大人类认知偏差，GPT-4因过度思考表现出最大非理性，而效率优化的GPT-4o表现接近最优。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地应用于商业决策，但其复制和放大人类认知偏差的风险尚未被充分理解，这在供应链管理等高风险运营环境中尤为关键。

Method: 使用动态多轮实验，在报童问题情境下测试GPT-4、GPT-4o和LLaMA-8B五种决策偏差，分析模型决策模式。

Result: LLMs一致复制了经典的"过低/过高"订购偏差，并显著放大了需求追逐行为等倾向。GPT-4表现出最大非理性，而GPT-4o表现接近最优。这些偏差源于架构约束而非知识缺口。

Conclusion: 管理者应根据具体任务选择模型，需要人机协同监督，设计结构化、基于规则的提示是约束模型启发式倾向的有效策略。

Abstract: Problem definition: Although large language models (LLMs) are increasingly integrated into business decision making, their potential to replicate and even amplify human cognitive biases cautions a significant, yet not well-understood, risk. This is particularly critical in high-stakes operational contexts like supply chain management. To address this, we investigate the decision-making patterns of leading LLMs using the canonical newsvendor problem in a dynamic setting, aiming to identify the nature and origins of their cognitive biases. Methodology/results: Through dynamic, multi-round experiments with GPT-4, GPT-4o, and LLaMA-8B, we tested for five established decision biases. We found that LLMs consistently replicated the classic ``Too Low/Too High'' ordering bias and significantly amplified other tendencies like demand-chasing behavior compared to human benchmarks. Our analysis uncovered a ``paradox of intelligence'': the more sophisticated GPT-4 demonstrated the greatest irrationality through overthinking, while the efficiency-optimized GPT-4o performed near-optimally. Because these biases persist even when optimal formulas are provided, we conclude they stem from architectural constraints rather than knowledge gaps. Managerial implications: First, managers should select models based on the specific task, as our results show that efficiency-optimized models can outperform more complex ones on certain optimization problems. Second, the significant amplification of bias by LLMs highlights the urgent need for robust human-in-the-loop oversight in high-stakes decisions to prevent costly errors. Third, our findings suggest that designing structured, rule-based prompts is a practical and effective strategy for managers to constrain models' heuristic tendencies and improve the reliability of AI-assisted decisions.

</details>


### [37] [AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation](https://arxiv.org/abs/2512.12597)
*Miriam Horovicz*

Main category: cs.AI

TL;DR: AgentSHAP是首个基于博弈论Shapley值的LLM代理工具重要性解释框架，无需访问模型内部权重，通过蒙特卡洛采样降低计算成本，能有效识别相关工具。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法无法解释LLM代理中工具的重要性，用户难以理解哪些工具对最终响应有实际贡献，存在解释盲点。

Method: 采用模型无关的黑盒方法，基于博弈论Shapley值，通过蒙特卡洛采样测试不同工具子集下的代理响应，计算公平的重要性分数，将复杂度从O(2^n)降至实用水平。

Result: 在API-Bank上的实验表明，AgentSHAP能产生跨运行一致的重要性分数，正确识别关键工具，区分相关与无关工具，并与TokenSHAP、PixelSHAP形成完整的Shapley值可解释AI工具家族。

Conclusion: AgentSHAP填补了LLM代理工具级解释的空白，为理解复杂代理系统中各工具的贡献提供了首个实用框架，增强了LLM代理的可解释性和透明度。

Abstract: LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory. Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools. AgentSHAP joins TokenSHAP (for tokens) and PixelSHAP (for image regions) to complete a family of Shapley-based XAI tools for modern generative AI. Code: https://github.com/GenAISHAP/TokenSHAP.

</details>


### [38] [Modular and Multi-Path-Aware Offline Benchmarking for Mobile GUI Agents](https://arxiv.org/abs/2512.12634)
*Youngmin Im,Byeongung Jo,Jaeyoung Wi,Seungwoo Baek,Tae Hoon Min,Joo Hyung Lee,Sangeun Oh,Insik Shin,Sunjae Lee*

Main category: cs.AI

TL;DR: MobiBench是一个模块化、多路径感知的移动GUI代理离线基准测试框架，解决了现有评估方法在可扩展性、可重复性和公平性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前移动GUI代理评估存在两个根本问题：1) 离线基准使用静态单路径数据集，不公平地惩罚有效替代动作；在线基准因动态不可预测性导致可扩展性和可重复性差。2) 现有基准将代理视为黑盒，忽略了各组件贡献，导致不公平比较或掩盖性能瓶颈。

Method: 提出MobiBench框架，这是首个模块化、多路径感知的移动GUI代理离线基准测试框架，支持在完全离线环境下进行高保真、可扩展、可重复的评估。

Result: 实验表明MobiBench与人类评估者的一致性达到94.72%，与精心设计的在线基准相当，同时保持了静态离线基准的可扩展性和可重复性。模块级分析揭示了移动GUI代理中多种技术的系统评估、跨模型规模的最优模块配置、当前大模型的固有局限性，以及设计更强大、成本效益更高的移动代理的可操作指南。

Conclusion: MobiBench解决了移动GUI代理评估的关键挑战，提供了一个既保持离线基准优势又能达到在线基准评估质量的解决方案，为移动代理的公平比较和性能优化提供了重要工具。

Abstract: Mobile GUI Agents, AI agents capable of interacting with mobile applications on behalf of users, have the potential to transform human computer interaction. However, current evaluation practices for GUI agents face two fundamental limitations. First, they either rely on single path offline benchmarks or online live benchmarks. Offline benchmarks using static, single path annotated datasets unfairly penalize valid alternative actions, while online benchmarks suffer from poor scalability and reproducibility due to the dynamic and unpredictable nature of live evaluation. Second, existing benchmarks treat agents as monolithic black boxes, overlooking the contributions of individual components, which often leads to unfair comparisons or obscures key performance bottlenecks. To address these limitations, we present MobiBench, the first modular and multi path aware offline benchmarking framework for mobile GUI agents that enables high fidelity, scalable, and reproducible evaluation entirely in offline settings. Our experiments demonstrate that MobiBench achieves 94.72 percent agreement with human evaluators, on par with carefully engineered online benchmarks, while preserving the scalability and reproducibility of static offline benchmarks. Furthermore, our comprehensive module level analysis uncovers several key insights, including a systematic evaluation of diverse techniques used in mobile GUI agents, optimal module configurations across model scales, the inherent limitations of current LFMs, and actionable guidelines for designing more capable and cost efficient mobile agents.

</details>


### [39] [Value-Aware Multiagent Systems](https://arxiv.org/abs/2512.12652)
*Nardine Osman*

Main category: cs.AI

TL;DR: 论文提出价值感知AI概念，超越传统价值对齐问题，提供包含三个核心支柱的简明工程路线图：学习表示人类价值、确保个体与多智能体系统价值对齐、提供基于价值的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统AI价值对齐方法存在局限，需要更全面的价值感知框架来确保AI系统不仅符合人类价值观，还能理解、表示和基于价值进行决策与解释。

Method: 提出三支柱工程路线图：1) 使用形式语义学学习和表示人类价值；2) 确保个体智能体和多智能体系统的价值对齐；3) 提供基于价值的可解释性。展示了在这些主题上的持续工作及实际应用。

Result: 建立了价值感知AI的概念框架和工程路线图，为开发更安全、可信、符合人类价值观的AI系统提供了结构化方法，并在实际领域展示了应用潜力。

Conclusion: 价值感知AI框架超越了传统价值对齐，为AI系统工程化提供了更全面的方法，通过三个核心支柱确保AI能够理解、对齐并解释其基于价值的决策过程。

Abstract: This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.

</details>


### [40] [Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI](https://arxiv.org/abs/2512.12686)
*Samarth Sarin,Lovepreet Singh,Bhaskarjit Sarmah,Dhagash Mehta*

Main category: cs.AI

TL;DR: Memoria是一个模块化记忆框架，通过动态会话摘要和加权知识图谱用户建模，为LLM提供持久、可解释、上下文丰富的记忆能力，实现短期对话连贯性和长期个性化。


<details>
  <summary>Details</summary>
Motivation: 代理记忆是LLM在扩展用户交互中保持连续性、个性化和长期上下文的关键能力，对于部署真正交互式和自适应代理至关重要。当前LLM接口缺乏状态性，需要解决这一差距。

Method: Memoria采用混合架构，包含两个互补组件：1) 动态会话级摘要；2) 基于加权知识图谱的用户建模引擎，以结构化实体和关系增量捕获用户特征、偏好和行为模式。

Result: Memoria能够在现代LLM的token限制内运行，实现短期对话连贯性和长期个性化，为需要自适应和演进用户体验的行业应用提供实用解决方案。

Conclusion: Memoria通过桥接无状态LLM接口和代理记忆系统，实现了可扩展的个性化对话AI，是部署真正交互式和自适应LLM代理的关键框架。

Abstract: Agentic memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive agents. Agentic memory refers to the memory that provides an LLM with agent-like persistence: the ability to retain and act upon information across conversations, similar to how a human would. We present Memoria, a modular memory framework that augments LLM-based conversational systems with persistent, interpretable, and context-rich memory. Memoria integrates two complementary components: dynamic session-level summarization and a weighted knowledge graph (KG)-based user modelling engine that incrementally captures user traits, preferences, and behavioral patterns as structured entities and relationships. This hybrid architecture enables both short-term dialogue coherence and long-term personalization while operating within the token constraints of modern LLMs. We demonstrate how Memoria enables scalable, personalized conversational artificial intelligence (AI) by bridging the gap between stateless LLM interfaces and agentic memory systems, offering a practical solution for industry applications requiring adaptive and evolving user experiences.

</details>


### [41] [WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment](https://arxiv.org/abs/2512.12692)
*Mahir Labib Dihan,Tanzima Hashem,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: WebOperator：一个结合最佳优先搜索、安全回溯和多推理上下文生成动作候选的树搜索框架，用于提升LLM智能体在网页环境中的探索能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在网页环境中采用贪婪的逐步执行方式，缺乏长期规划能力，且网页环境是部分可观测的（仅限浏览器可见内容），一旦出错需要复杂的导航来撤销。现有树搜索方法缺乏安全回溯机制，且假设所有动作可逆，这在真实网页任务中效果有限。

Method: 1. 最佳优先搜索策略：综合考虑奖励估计和安全因素对动作排序；2. 鲁棒回溯机制：在重放之前验证已访问路径的可行性，防止意外副作用；3. 多推理上下文生成动作候选：确保探索的多样性和鲁棒性；4. 动作集筛选：执行前过滤无效动作，合并语义等价动作。

Result: 在WebArena和WebVoyager上的实验表明WebOperator的有效性。在WebArena上，使用gpt-4o实现了54.6%的最新成功率，证明了战略远见与安全执行结合的关键优势。

Conclusion: WebOperator通过集成战略远见和安全执行，显著提升了LLM智能体在网页环境中的性能，解决了现有方法缺乏安全回溯和探索多样性的问题。

Abstract: LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.

</details>


### [42] [Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2512.12706)
*Enhong Mu,Minami Yoda,Yan Zhang,Mingyue Zhang,Yutaka Matsuno,Jialong Li*

Main category: cs.AI

TL;DR: SMART框架结合代码结构分析和功能验证，通过LLM解析AST差异并构建混合奖励机制，指导RL智能体在游戏更新测试中同时覆盖修改代码分支和完成游戏任务。


<details>
  <summary>Details</summary>
Motivation: 游戏即服务模式需要频繁内容更新，给质量保证带来巨大压力。现有自动化测试方法存在两极化：代码中心方法关注结构覆盖但缺乏游戏上下文理解；玩家中心智能体验证高层意图但难以覆盖具体代码变更。需要弥合这一鸿沟。

Method: 提出SMART框架，利用大语言模型解析抽象语法树差异并提取功能意图，构建上下文感知的混合奖励机制。该机制指导强化学习智能体顺序完成游戏目标，同时自适应探索修改的代码分支。

Result: 在Overcooked和Minecraft环境中评估，SMART显著优于现有基线方法：达到超过94%的修改代码分支覆盖率（几乎是传统RL方法的两倍），同时保持98%的任务完成率，有效平衡结构全面性和功能正确性。

Conclusion: SMART成功弥合了结构验证和功能验证之间的鸿沟，为游戏更新测试提供了一种协同方法，能够同时确保代码变更的全面覆盖和游戏功能的正确性。

Abstract: The widespread adoption of the "Games as a Service" model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric agents validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning agents to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.

</details>


### [43] [Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks](https://arxiv.org/abs/2512.12736)
*Syeda Zunaira Ahmed,Hejab Tahira Beg,Maryam Khalid*

Main category: cs.AI

TL;DR: 提出基于人口统计的机器学习框架用于个性化QoE预测，通过数据增强将小数据集扩展6倍，TabNet模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有QoE预测方法主要依赖有限数据集并假设用户感知一致，在异构真实环境中适用性受限。需要更个性化的QoE预测方法来支持5G网络中智能资源管理和用户中心的服务交付。

Method: 提出人口统计感知的机器学习框架，包括行为现实的人口统计数据增强策略，通过建模用户对缓冲、码率变化和质量退化等流媒体损伤的不同敏感度，将小QoE数据集扩展6倍。评估了经典机器学习模型和先进深度学习架构，包括基于注意力的MLP和TabNet。

Result: 实验结果显示在RMSE、MAE和R指标上相比基线模型有显著改进。在所有评估方法中，TabNet表现最佳，受益于其固有的特征选择和注意力机制。

Conclusion: 人口统计感知的数据增强显著提高了QoE预测的鲁棒性，为5G视频流网络中的个性化QoE感知智能提供了可扩展的方向。

Abstract: Quality of Experience (QoE) prediction is a critical component of modern multimedia systems, particularly for adaptive video streaming in 5G networks. Accurate QoE estimation enables intelligent resource management and supports user centric service delivery. Existing QoE prediction approaches primarily rely on limited datasets and assume uniform user perception, which restricts their applicability in heterogeneous real world environments.
  This paper proposes a demographic aware machine learning framework for personalized QoE prediction. We introduce a behaviorally realistic demographic based data augmentation strategy that expands a small QoE dataset six fold by modeling varying user sensitivities to streaming impairments such as rebuffering, bitrate variation, and quality degradation. Using the augmented dataset, we evaluate a comprehensive set of classical machine learning models alongside advanced deep learning architectures, including an attention-based MLP and TabNet.
  Experimental results demonstrate significant improvements in prediction accuracy across RMSE, MAE, and R metrics compared to baseline models. Among all evaluated approaches, TabNet achieves the strongest performance, benefiting from its inherent feature selection and attention mechanisms. The results confirm that demographic-aware augmentation substantially enhances QoE prediction robustness and provides a scalable direction for personalized QoE-aware intelligence in 5G video streaming networks.

</details>


### [44] [Causal Counterfactuals Reconsidered](https://arxiv.org/abs/2512.12804)
*Sander Beckers*

Main category: cs.AI

TL;DR: 提出一种新的反事实概率语义学，推广了标准Pearl语义学，适用于无法扩展为现实结构因果模型的概率因果模型


<details>
  <summary>Details</summary>
Motivation: 需要处理简单场景中出现的概率因果模型，这些模型超出了Pearl语义学的范围，同时在Pearl和Dawid关于反事实的长期辩论中寻求折中方案

Method: 限制关注满足马尔可夫条件、仅包含现实变量且因果完备的因果模型，使用结构因果模型但不使用响应变量，证明与其他非结构因果模型方法的等价性

Result: 建立了新的反事实概率语义学，能够处理Pearl语义学无法覆盖的模型，在Pearl和Dawid观点间取得平衡，并与文献中其他方法保持一致

Conclusion: 新的语义学为反事实推理提供了更一般的框架，同时反思了马尔可夫条件的普适性，并探索了因果抽象的新推广

Abstract: I develop a novel semantics for probabilities of counterfactuals that generalizes the standard Pearlian semantics: it applies to probabilistic causal models that cannot be extended into realistic structural causal models and are therefore beyond the scope of Pearl's semantics. This generalization is needed because, as I show, such probabilistic causal models arise even in simple settings. My semantics offer a natural compromize in the long-standing debate between Pearl and Dawid over counterfactuals: I agree with Dawid that universal causal determinism and unrealistic variables should be rejected, but I agree with Pearl that a general semantics of counterfactuals is nonetheless possible. I restrict attention to causal models that satisfy the Markov condition, only contain realistic variables, and are causally complete. Although I formulate my proposal using structural causal models, as does Pearl, I refrain from using so-called response variables. Moreover, I prove that my semantics is equivalent to two other recent proposals that do not involve structural causal models, and that it is in line with various comments on stochastic counterfactuals that have appeared in the literature more broadly. Throughout I also reflect on the universality of the Markov condition and explore a novel generalization of causal abstractions

</details>


### [45] [Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution](https://arxiv.org/abs/2512.12806)
*Boyang Yan*

Main category: cs.AI

TL;DR: 提出一个容错沙箱框架，通过策略拦截层和事务性文件系统快照机制，保护自主LLM代理免受破坏性命令和系统状态不一致的风险，相比现有方案更适合无头自动化工作流。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从被动代码生成器转变为自主代理时，会带来严重的安全风险，包括破坏性命令和系统状态不一致。现有商业解决方案通常优先考虑交互式用户安全，通过身份验证屏障破坏了真正自主性所需的无头循环。

Method: 提出容错沙箱框架，包含基于策略的拦截层和事务性文件系统快照机制。将代理操作包装在原子事务中，通过Proxmox测试平台部署Minimind-MoE LLM，使用nano-vllm服务，并利用EVPN/VXLAN隔离技术。

Result: 实验结果显示：高风险命令拦截率达到100%，失败状态回滚成功率100%，每个事务仅产生14.5%的性能开销（约1.8秒）。相比之下，Gemini CLI沙箱需要交互式身份验证，不适用于无头自主代理工作流。

Conclusion: 容错沙箱框架能有效保护自主LLM代理的安全，在保证安全性的同时保持可接受的延迟，优于容器初始化开销或商业CLI的交互摩擦，适合无头自动化工作流。

Abstract: The transition of Large Language Models (LLMs) from passive code generators to autonomous agents introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception layer and a transactional filesystem snapshot mechanism. We hypothesize that wrapping agent actions in atomic transactions can guarantee safety with acceptable latency, outperforming the heavy initialization overhead of containers or the interactive friction of commercial CLIs. We validated this approach by deploying the Minimind-MoE LLM served via nano-vllm on a custom Proxmox-based testbed utilizing EVPN/VXLAN isolation. Experimental results demonstrate a 100\% interception rate for high-risk commands and a 100\% success rate in rolling back failed states. Crucially, our prototype incurs only a 14.5\% performance overhead (approx. 1.8s) per transaction. In contrast, benchmarking against the Gemini CLI sandbox revealed that it requires interactive authentication ("Sign in"), rendering it unusable for headless, autonomous agent workflows.

</details>


### [46] [Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative Agents](https://arxiv.org/abs/2512.12856)
*Saad Alqithami*

Main category: cs.AI

TL;DR: 论文提出Memory-Aware Retention Schema (MaRS)框架和六种遗忘策略，用于生成式智能体的记忆管理，平衡性能、隐私和计算效率，并通过FiFA基准测试验证了混合遗忘策略的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式智能体在长期交互场景中部署，其记忆管理成为性能和隐私的关键瓶颈。现有方法要么维持无限记忆存储导致计算不可行和隐私问题，要么使用简单遗忘机制损害智能体连贯性和功能。

Method: 提出Memory-Aware Retention Schema (MaRS)框架，结合六种理论基础的遗忘策略；创建Forgetful but Faithful Agent (FiFA)基准测试框架，评估叙事连贯性、目标完成、社交回忆准确性、隐私保护和成本效率。

Result: 通过300次评估运行，混合遗忘策略在综合得分上达到0.911的优越性能，同时保持计算可行性和隐私保证，为资源受限、隐私敏感环境中的智能体部署提供了新基准。

Conclusion: 该工作为人本AI领域做出贡献，解决了智能体记忆管理的基本挑战，直接影响用户信任、系统可扩展性和法规合规性，为资源受限、隐私敏感环境中的生成式智能体部署提供了实用指南。

Abstract: As generative agents become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise agent coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative agents, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful Agent (FiFA) benchmark, a comprehensive evaluation framework that assesses agent performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and agent configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted agent evaluation and provides practical guidelines for deploying generative agents in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in agent memory management that directly impact user trust, system scalability, and regulatory compliance.

</details>


### [47] [Satisfiability Modulo Theory Meets Inductive Logic Programming](https://arxiv.org/abs/2512.12918)
*Nijesh Upreti,Vaishak Belle*

Main category: cs.AI

TL;DR: 该论文提出了一种模块化方法，将归纳逻辑编程（ILP）系统PyGol与SMT求解器Z3结合，以学习包含数值约束的混合规则，解决了传统ILP在数值推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统ILP系统在处理数值约束方面存在局限，通常依赖离散化或手工设计的数值谓词，难以推断需要跨示例共同成立的阈值或算术关系。虽然近期研究开始通过ILP与SMT或专门数值推理机制的集成来解决这些问题，但需要更灵活的方法来扩展符号规则学习的表达能力。

Method: 采用模块化架构，将ILP系统PyGol与SMT求解器Z3耦合。PyGol生成的候选子句被解释为背景理论（如线性/非线性实数算术）上的无量词公式，SMT求解器负责实例化和验证数值参数，同时保持ILP的声明性关系偏置。这种方法支持学习结合符号谓词与数值约束的混合规则。

Result: 在专门设计的合成数据集上进行了评估，这些数据集测试了线性、关系、非线性和多跳推理能力。结果表明，模块化SMT-ILP架构能够有效扩展符号规则学习的表达能力，支持学习包含阈值、区间和多文字算术关系的混合规则。

Conclusion: 模块化SMT-ILP架构为ILP提供了处理数值约束的有效方法，补充了现有的数值ILP方法，并为未来向更丰富的理论感知归纳扩展提供了灵活基础。

Abstract: Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.

</details>


### [48] [Towards Open Standards for Systemic Complexity in Digital Forensics](https://arxiv.org/abs/2512.12970)
*Paola Di Maio*

Main category: cs.AI

TL;DR: 提出基于开放标准和人类可读工件的数字取证AI模型架构，以解决AI与数字取证交叉领域中的系统复杂性和错误问题


<details>
  <summary>Details</summary>
Motivation: AI与数字取证交叉领域日益复杂且普遍，尽管技术不断进步，但取证科学仍存在错误和脆弱性，需要解决系统复杂性以降低错误风险

Method: 采用人类可读工件和开放标准来应对系统复杂性，并基于最新技术提出数字取证AI模型架构

Result: 提出了一个基于最先进技术的数字取证AI模型架构，旨在通过开放标准和人类可读工件来降低系统复杂性

Conclusion: 通过采用人类可读工件和开放标准，可以缓解数字取证AI交叉领域的系统复杂性，减少错误并提高可靠性

Abstract: The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.

</details>


### [49] [M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization](https://arxiv.org/abs/2512.13070)
*Bizhe Bai,Hongming Wu,Peng Ye,Tao Chen*

Main category: cs.AI

TL;DR: 本文提出M-GRPO和IQR过滤方法，解决自监督强化学习中长期训练时的策略崩溃问题，实现稳定训练和最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督强化学习方法在长期训练中会出现"策略崩溃"问题，性能急剧下降。即使增加rollout数量也只能延迟而非防止崩溃，需要更稳定的训练方法。

Method: 提出两个创新：1) M-GRPO框架，利用缓慢演化的动量模型提供稳定训练目标；2) 基于四分位距的自适应过滤方法，动态修剪低熵轨迹，保持策略多样性。

Result: 在多个推理基准测试中，M-GRPO稳定了训练过程，IQR过滤器防止了过早收敛，组合方法实现了卓越的训练稳定性和最先进的性能。

Conclusion: 通过M-GRPO和IQR过滤器的结合，成功解决了自监督强化学习中的策略崩溃问题，为LLM推理能力的稳定提升提供了有效方案。

Abstract: Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a "policy collapse" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.

</details>


### [50] [Socratic Students: Teaching Language Models to Learn by Asking Questions](https://arxiv.org/abs/2512.13102)
*Rajeev Bhatt Ambati,Tianyi Niu,Aashu Singh,Shlok Mishra,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.AI

TL;DR: 该论文研究如何让大型语言模型（学生）通过主动提问来从教师那里获取有用信息，而不是被动接受知识，在数学和编程任务上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中许多场景（如教育辅导、医疗协助）需要动态交互获取信息，而不仅仅是静态知识检索。现有研究主要关注教师如何有效指导学生，本文则将焦点转向学生如何主动向教师提问以获取有用信息。

Method: 提出学生主导的主动查询策略，使用直接偏好优化（DPO）训练学生模型，通过自我指导或更强学生的指导来提升提问质量，使小型模型学会如何提出更好的问题。

Result: 在数学和编程基准测试中，学生主导方法相比静态基线在Pass@k指标上至少提升0.5个绝对百分点。通过DPO指导训练，小型模型能够学习如何提出更好的问题，进一步提高学习效率。

Conclusion: 学生主动提问策略能够有效提升LLMs在动态交互任务中的性能，通过DPO指导训练可以使小型模型学会更好的提问技巧，这为构建更智能的交互式AI代理提供了新思路。

Abstract: Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.

</details>


### [51] [Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning](https://arxiv.org/abs/2512.13131)
*Xin Guo,Yifan Zhao,Jia Li*

Main category: cs.AI

TL;DR: 提出分层隐式周期性学习框架，通过周期性自编码器探索手势运动相位流形，结合级联引导建模面部、身体和手部运动的层次关系，显著提升语音驱动3D手势生成的自然度和协调性。


<details>
  <summary>Details</summary>
Motivation: 现有语音驱动3D手势生成方法（如GAN、VQ-VAE、扩散模型）作为不适定问题，未能充分建模不同运动单元（头、身体、手）之间的关键相互关联和内部关联，导致生成动作不自然且协调性差。

Method: 提出分层隐式周期性学习框架：1）使用周期性自编码器探索手势运动相位流形，从真实分布中模仿人类自然运动，同时结合当前潜在状态的非周期性成分实现实例级多样性；2）通过级联引导建模面部运动、身体手势和手部运动的层次关系。

Result: 在3D虚拟人上的实验表明，该方法在定量和定性评估上均优于当前最先进的语音驱动手势生成方法。

Conclusion: 通过显式建模运动单元间的层次关系和周期性特征，提出的分层隐式周期性学习方法能够生成更自然、协调的语音驱动3D手势，为解决这一不适定问题提供了有效方案。

Abstract: Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.

</details>


### [52] [Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels](https://arxiv.org/abs/2512.13142)
*Anika Sharma,Malavika Mampally,Chidaksh Ravuru,Kandyce Brennan,Neil Gaikwad*

Main category: cs.AI

TL;DR: LLMs无法真正理解复杂的心理生理现象如堕胎污名，虽然能生成恰当语言但缺乏多层次连贯理解，存在系统性偏见和矛盾


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地介入污名化的健康决策，评估它们是否真正理解复杂的心理和生理现象变得至关重要。研究旨在探究LLMs是否能在认知、人际和结构三个层面上连贯地表示堕胎污名

Method: 使用经过验证的个体层面堕胎污名量表(ILAS)，系统测试了5个领先LLM中的627个不同人口统计特征的人物角色。进行多层次分析，考察模型在认知层面(自我判断)、人际层面(预期判断和孤立)和结构层面(社区谴责和披露模式)以及整体污名上的表现

Result: 模型在所有层面上都未能通过真正理解的测试：高估人际污名而低估认知污名；假设统一的社区谴责；引入人类验证数据中不存在的人口统计偏见；错过经验验证的污名-保密关系；在理论建构内自相矛盾

Conclusion: 当前的对齐方法只能确保恰当的语言表达，但不能保证多层次连贯理解。在高风险情境下的AI安全需要新的设计方法(多层次连贯性)、评估方法(持续审计)、治理和监管(强制审计、问责制、部署限制)，以及在理解人们无法言说内容决定支持是帮助还是伤害的领域提高AI素养

Abstract: As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.

</details>


### [53] [MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations](https://arxiv.org/abs/2512.13154)
*Emre Can Acikgoz,Jinoh Oh,Joo Hyuk Jeon,Jie Hao,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: 提出了MAC（多智能体澄清）框架，通过多智能体协同策略性管理澄清对话，解决用户请求中的歧义问题，在MultiWOZ 2.4上任务成功率提升7.8%，对话轮次减少。


<details>
  <summary>Details</summary>
Motivation: 对话代理常遇到模糊的用户请求，需要有效澄清才能完成任务。虽然多智能体架构在复杂对话场景中表现出色，但歧义解决仍是一个关键且未充分探索的挑战——特别是难以确定哪个智能体应发起澄清，以及智能体在面对不确定或不完整用户输入时如何协调行动。何时打断用户以及如何在最优多智能体设置中制定最佳澄清查询等基本问题仍未解决。

Method: 提出MAC（多智能体澄清）交互式多智能体框架，专门优化用于通过策略性管理澄清对话来解决用户歧义。首先引入新的分类法对用户歧义进行分类，系统指导澄清策略。然后提出MAC框架，自主协调多个智能体与用户协同交互。

Result: 在MultiWOZ 2.4上的实证评估表明，在两个层面启用澄清可将任务成功率提高7.8%（从54.5%到62.3%），并将平均对话轮次从6.53减少到4.86，通过预先获取所有必要用户信息并最小化重复来实现。

Conclusion: 研究结果强调了主动用户交互和角色感知澄清对于更可靠的人机通信的重要性。MAC框架通过多智能体协同有效解决了对话中的歧义问题，显著提升了任务成功率和对话效率。

Abstract: Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.

</details>


### [54] [SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning](https://arxiv.org/abs/2512.13159)
*Emre Can Acikgoz,Jinoh Oh,Jie Hao,Joo Hyuk Jeon,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: SpeakRL是一种强化学习方法，通过奖励智能体主动与用户互动（如提出澄清问题）来增强其对话能力，在任务完成率上比基础模型提升20.14%


<details>
  <summary>Details</summary>
Motivation: 当前人机协作主要是单向的，用户发出指令，智能体直接响应而不寻求必要的澄清或确认。随着智能体能力的发展，需要更主动的参与来澄清用户意图、解决歧义并适应变化的环境。现有研究未能充分利用语言模型的对话能力，将智能体优化为更好的跟随者而非有效的发言者。

Method: 提出SpeakRL强化学习方法，通过奖励智能体主动与用户互动（如提出必要的澄清问题）来增强其对话能力。创建了SpeakER合成数据集，包含任务导向对话中的多样化场景，任务通过交互式澄清问题解决。系统分析了对话主动性的奖励设计，提出了平衡提问与行动的奖励公式。

Result: 实验评估显示，该方法在任务完成率上比基础模型提高了20.14%的绝对改进，且没有增加对话轮次，甚至超越了更大的专有模型，证明了以澄清为中心的人机交互的潜力。

Conclusion: SpeakRL方法通过强化学习奖励智能体的主动对话行为，显著提高了任务完成效果，展示了澄清导向的人机协作的重要性，为构建更有效的对话智能体提供了新方向。

Abstract: Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.

</details>


### [55] [Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows](https://arxiv.org/abs/2512.13168)
*Haoyu Dong,Pengkun Zhang,Yan Gao,Xuanyu Dong,Yilin Cheng,Mingzhe Lu,Adina Yakefu,Shuxin Zheng*

Main category: cs.AI

TL;DR: Finch是一个金融会计基准测试，用于评估AI代理在真实企业级工作流程中的表现，包含172个复合工作流和384个任务，涉及大量真实企业数据。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准测试往往过于简化，无法反映真实企业工作流程的复杂性、多模态性和协作性，需要创建更贴近实际的专业工作流评估标准。

Method: 结合LLM辅助发现和专家标注：1) 从真实企业邮件和电子表格版本历史中推导工作流，2) 专家进行细致标注，共投入700多小时专业努力。

Result: GPT 5.1 Pro花费48小时仅通过38.4%的工作流，Claude Sonnet 4.5仅通过25.0%，显示当前AI系统在处理真实企业工作流程时仍面临重大挑战。

Conclusion: 真实企业工作流程对AI代理构成显著挑战，需要更强大的多模态理解、长时程推理和协作能力，Finch基准为评估和改进AI系统提供了重要工具。

Abstract: We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.

</details>


### [56] [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)
*Zihui Zhao,Zechang Li*

Main category: cs.AI

TL;DR: RPO（Reflective Preference Optimization）通过引入提示引导的反思机制，增强DPO中的对比学习信号，解决标准DPO因正负样本相似导致的收敛慢、不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 标准DPO中，被选择和被拒绝的响应都来自同一策略，往往包含相似错误且KL散度小，导致学习信号弱、收敛慢且不稳定。

Method: RPO框架将提示引导的反思融入DPO范式，使用外部模型识别幻觉来源并生成简洁反思提示，构建更具对比性的策略内偏好对。

Result: RPO在更少训练样本和迭代次数下实现更优对齐，显著降低幻觉率，在多模态基准测试中达到最先进性能。

Conclusion: RPO通过引入反思提示增强DPO的对比学习信号，理论上证明能提高期望偏好边际，实践中实现更高效、稳定的模型对齐。

Abstract: Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.

</details>


### [57] [MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data](https://arxiv.org/abs/2512.13297)
*Zhenghao Zhu,Chuxue Cao,Sirui Han,Yuanfeng Song,Xing Chen,Caleb Chen Cao,Yike Guo*

Main category: cs.AI

TL;DR: 提出了MedInsightBench基准测试和MedInsightAgent框架，用于评估和改进大型多模态模型在医疗数据分析中的洞察发现能力。


<details>
  <summary>Details</summary>
Motivation: 医疗数据分析需要从复杂的多模态数据中提取深度洞察，但目前缺乏专门评估大型多模态模型医疗洞察发现能力的高质量数据集。

Method: 1) 创建MedInsightBench基准测试，包含332个精心策划的医疗案例，每个案例都标注了精心设计的洞察；2) 提出MedInsightAgent框架，包含视觉根因查找器、分析洞察代理和后续问题组合器三个模块。

Result: 现有大型多模态模型在MedInsightBench上表现有限，主要因为难以提取多步骤深度洞察和缺乏医学专业知识。MedInsightAgent能够显著提升通用大型多模态模型在医疗数据洞察发现方面的性能。

Conclusion: MedInsightBench为评估医疗多模态模型提供了重要基准，而MedInsightAgent框架为解决医疗数据分析中的深度洞察提取问题提供了有效解决方案。

Abstract: In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.

</details>


### [58] [Error-Driven Prompt Optimization for Arithmetic Reasoning](https://arxiv.org/abs/2512.13323)
*Árpád Pándy,Róbert Lakatos,András Hajdu*

Main category: cs.AI

TL;DR: 提出基于错误驱动的优化框架，提升小型语言模型在算术推理任务上的表现，使4B参数模型在隐私合规环境下超越GPT-3.5 Turbo


<details>
  <summary>Details</summary>
Motivation: 金融、医疗等受监管行业需要能在本地安全环境中处理表格数据的AI助手，但现有小型语言模型在算术推理任务上存在基本限制

Method: 采用错误驱动的优化框架，通过聚类错误预测来迭代优化提示规则，增强代码生成代理的算术推理能力

Result: Qwen3 4B模型经过优化后准确率提升至70.8%，在隐私合规环境下超越了GPT-3.5 Turbo的表现

Conclusion: 通过系统化的错误驱动提示优化，小型模型可以在不依赖昂贵微调的情况下实现可靠的工业部署，为隐私敏感的行业应用提供可行方案

Abstract: Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.

</details>


### [59] [Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection](https://arxiv.org/abs/2512.13374)
*Francesca Da Ros,Luca Di Gaspero,Kevin Roitero*

Main category: cs.AI

TL;DR: LLMs能学习和表示组合优化问题的结构信息，其隐藏层表示在算法选择任务中与传统特征提取方法效果相当。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探索LLMs生成或解决优化模型，但对其学习问题结构或算法行为的能力了解不足。本研究旨在探究LLMs如何内部表示组合优化问题，以及这些表示是否能支持下游决策任务。

Method: 采用双重方法：1) 直接查询评估LLMs显式提取实例特征的能力；2) 探测分析检查这些信息是否隐式编码在隐藏层中。探测框架扩展到按实例的算法选择任务，评估LLM衍生表示是否能预测最佳求解器。

Result: 实验涵盖四个基准问题和三种实例表示。结果显示LLMs在从问题实例恢复特征信息方面表现出中等能力（通过直接查询或探测）。值得注意的是，LLM隐藏层表示的预测能力与传统特征提取方法相当。

Conclusion: LLMs能够捕获与优化性能相关的有意义的结构信息，其内部表示对组合优化问题具有实际应用价值。

Abstract: Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.

</details>


### [60] [Differentiable Evolutionary Reinforcement Learning](https://arxiv.org/abs/2512.13399)
*Sitao Cheng,Tianle Li,Xuhan Huang,Xunjian Yin,Difan Zou*

Main category: cs.AI

TL;DR: DERL是一个双层可微分进化强化学习框架，通过元优化器自动发现最优奖励信号，在复杂推理任务中实现超越启发式奖励方法的性能。


<details>
  <summary>Details</summary>
Motivation: 设计有效的奖励函数是强化学习中的核心挑战，特别是在复杂推理任务中。现有的自动化奖励优化方法通常将奖励函数视为黑盒，无法捕捉奖励结构与任务性能之间的因果关系。

Method: 提出DERL框架：1) 元优化器通过组合结构化原子基元进化奖励函数；2) 指导内循环策略训练；3) 关键创新：元优化可微分，将内循环验证性能作为信号，通过强化学习更新元优化器，近似任务成功的"元梯度"。

Result: 在三个领域验证：ALFWorld（机器人代理）、ScienceWorld（科学模拟）、GSM8k和MATH（数学推理）。在ALFWorld和ScienceWorld上达到最先进性能，显著优于依赖启发式奖励的方法，特别是在分布外场景中。进化轨迹分析显示DERL成功捕捉任务内在结构。

Conclusion: DERL能够自主发现最优奖励信号，实现无需人工干预的自改进智能体对齐，为复杂推理任务的奖励设计提供了新的可微分进化方法。

Abstract: The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the "meta-gradient" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.

</details>


### [61] [neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings](https://arxiv.org/abs/2512.13481)
*Ojas Pungalia,Rashi Upadhyay,Abhishek Mishra,Abhiram H,Tejasvi Alladi,Sujan Yenuganti,Dhruv Kumar*

Main category: cs.AI

TL;DR: LLMs在特定情境下会表现出嫉妒行为，不同模型在竞争性偏好上存在显著差异，这对多智能体系统的安全设计有重要影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在协作和竞争工作流中越来越多地代表人类行动，需要评估它们是否以及在什么条件下表现出类似嫉妒的偏好，这对多智能体系统的安全和设计至关重要。

Method: 设计了两种实验场景：(1) 点数分配游戏，测试模型是否试图超越同伴；(2) 职场环境，观察在不公平认可下的行为。

Result: 发现某些LLM存在一致的嫉妒模式，但不同模型和情境间差异很大。GPT-5-mini和Claude-3.7-Sonnet倾向于拉低同伴以实现结果平等，而Mistral-Small-3.2-24B则专注于最大化自身收益。

Conclusion: LLM确实会表现出嫉妒行为，竞争性倾向应作为LLM多智能体系统的安全和设计因素加以考虑。

Abstract: Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.

</details>


### [62] [Defending the Hierarchical Result Models of Precedential Constraint](https://arxiv.org/abs/2512.13505)
*Henry Prakken,Wijnand van Woerkom*

Main category: cs.AI

TL;DR: 本文回应Bench-Capon对分层案例推理模型的批评，认为其误解了中间因素与维度的区别，并证明van Woerkom的维度分层结果模型能避免这些批评。


<details>
  <summary>Details</summary>
Motivation: 近年来分层案例推理模型受到Bench-Capon批评，认为这些模型在某些情况下会产生错误结果，特别是无法处理中间因素被不同基础因素以不同强度确立的情况。本文旨在回应这些批评。

Method: 通过分析Bench-Capon的批评案例，指出其将中间因素误解为维度，然后应用van Woerkom的维度分层结果模型来重新分析这些案例。

Result: 证明当正确区分中间因素和维度时，van Woerkom的维度分层结果模型能够避免Bench-Capon提出的批评，模型能够正确处理中间因素被不同强度确立的情况。

Conclusion: Bench-Capon的批评源于对中间因素和维度的混淆，van Woerkom的维度分层结果模型能够有效应对这些批评，为分层案例推理模型提供了有力辩护。

Abstract: In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.

</details>


### [63] [MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph](https://arxiv.org/abs/2512.13510)
*Linjie Mu,Yannian Gu,Zhongzhen Huang,Yakun Zhu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: MedCEG框架通过关键证据图监督医学语言模型的推理过程，提升临床推理的有效性和可靠性


<details>
  <summary>Details</summary>
Motivation: 现有医学推理模型虽然性能有所提升，但其推理过程的临床可靠性和有效性在训练中常被忽视，缺乏透明、可验证的推理路径来支持临床决策

Method: 提出MedCEG框架，通过算法构建关键证据图表示高质量可验证推理路径，引入临床推理过程奖励函数评估节点覆盖、结构正确性和链条完整性

Result: MedCEG在性能上超越现有方法，同时生成临床有效的推理链，在可靠医学AI推理方面取得实质性进展

Conclusion: MedCEG通过显式监督推理过程并评估推理质量，显著提升了医学语言模型的临床推理可靠性和有效性

Abstract: Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [64] [Differentially Private Community Detection in $h$-uniform Hypergraphs](https://arxiv.org/abs/2512.12031)
*Javad Zahedi Moghaddam,Aria Nosratinia*

Main category: cs.IT

TL;DR: 论文研究了在保护超图连接隐私条件下的精确恢复阈值，分析了三种差分隐私机制在稠密h-均匀超图随机块模型中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 研究如何在保护超图连接隐私的前提下实现社区检测的精确恢复，扩展了边差分隐私概念到超图场景，探索不同隐私机制对恢复性能的影响。

Method: 使用h-均匀超图随机块模型(h-HSBM)，研究三种差分隐私机制：基于稳定性的机制、基于采样的机制和基于扰动的机制，分析它们在(ε,δ)-超边差分隐私下的精确恢复阈值。

Result: 基于采样的机制和随机响应机制能保证纯ε-超边差分隐私(δ=0)，而基于稳定性的机制无法达到此隐私水平。隐私预算的最小值对稳定性机制和贝叶斯采样机制与超图参数呈对数关系，而对随机响应机制仅依赖于超图大小。

Conclusion: 隐私保护会收缩精确恢复区域，不同隐私机制对隐私预算的依赖关系不同，为超图隐私保护下的社区检测提供了理论指导。

Abstract: This paper studies the exact recovery threshold subject to preserving the privacy of connections in $h$-uniform hypergraphs. Privacy is characterized by the $(ε, δ)$-hyperedge differential privacy (DP), an extension of the notion of $(ε, δ)$-edge DP in the literature. The hypergraph observations are modeled through a $h$-uniform stochastic block model ($h$-HSBM) in the dense regime. We investigate three differentially private mechanisms: stability-based, sampling-based, and perturbation-based mechanisms. We calculate the exact recovery threshold for each mechanism and study the contraction of the exact recovery region due to the privacy budget, $(ε, δ)$. Sampling-based mechanisms and randomized response mechanisms guarantee pure $ε$-hyperedge DP where $δ=0$, while the stability-based mechanisms cannot achieve this level of privacy. The dependence of the limits of the privacy budget on the parameters of the $h$-uniform hypergraph is studied. More precisely, it is proven rigorously that the minimum privacy budget scales logarithmically with the ratio between the density of in-cluster hyperedges and the cross-cluster hyperedges for stability-based and Bayesian sampling-based mechanisms, while this budget depends only on the size of the hypergraph for the randomized response mechanism.

</details>


### [65] [A Framework for Scalable Digital Twin Deployment in Smart Campus Building Facility Management](https://arxiv.org/abs/2512.12149)
*Thyda Siv*

Main category: cs.IT

TL;DR: 该研究提出一个可扩展的数字孪生框架，通过整合3D激光扫描、BIM建模和IoT数据可视化，为校园建筑设施管理提供统一平台。


<details>
  <summary>Details</summary>
Motivation: 现有数字孪生研究往往局限于孤立领域（如点云几何或能源分析），缺乏将建筑几何、设备元数据和运营数据整合到统一设施管理平台的可扩展、可互操作工作流程。

Method: 方法包括：(1) 地面激光扫描和结构化点云处理；(2) 开发包含建筑、机械、电气、管道、输送和传感器系统的丰富BIM模型；(3) 创建连接设备元数据、维护策略和模拟IoT数据的数字孪生管理平台。

Result: 在佐治亚理工学院的Price Gilbert Building案例中，成功建模509个设备项目并嵌入OmniClass分类，开发了10个交互式仪表板。结果显示该框架实现了集中资产文档管理、提升系统可见性，并增强了预防性和反应性维护工作流程。

Conclusion: 尽管大部分IoT数据因现有传感器基础设施有限而采用模拟，但原型验证了可扩展数字孪生用于设施管理的可行性，并为实时监控、分析集成和未来自主建筑运营建立了参考模型。

Abstract: Digital twin (DT) offers significant opportunities for enhancing facility management (FM) in campus environments. However, existing research often focuses narrowly on isolated domains, such as point-cloud geometry or energy analytics, without providing a scalable and interoperable workflow that integrates building geometry, equipment metadata, and operational data into a unified FM platform. This study proposes a comprehensive framework for scalable digital-twin deployment in smart campus buildings by integrating 3D laser scanning, BIM modeling, and IoT-enabled data visualization to support facility operations and maintenance. The methodology includes: (1) reality capture using terrestrial laser scanning and structured point-cloud processing; (2) development of an enriched BIM model incorporating architectural, mechanical, electrical, plumbing, conveying, and sensor systems; and (3) creation of a digital-twin environment that links equipment metadata, maintenance policies, and simulated IoT data within a digital-twin management platform. A case study of the Price Gilbert Building at Georgia Tech demonstrates the implementation of this workflow. A total of 509 equipment items were modeled and embedded with OmniClass classifications into the digital twin. Ten interactive dashboards were developed to visualize system performance. Results show that the proposed framework enables centralized asset documentation, improved system visibility, and enhanced preventive and reactive maintenance workflows. Although most IoT data were simulated due to limited existing sensor infrastructure, the prototype validates the feasibility of a scalable digital twin for facility management and establishes a reference model for real-time monitoring, analytics integration, and future autonomous building operations.

</details>


### [66] [Large and Small Model Collaboration for Air Interface](https://arxiv.org/abs/2512.12170)
*Yiming Cui,Jiajia Guo,Xiao Li,Chao-Kai Wen,Shi Jin*

Main category: cs.IT

TL;DR: 提出LASCO和E-LASCO框架，通过大模型作为通用知识库、小模型作为轻量插件，实现无线通信中CSI反馈任务的环境特定适配，显著降低训练成本和数据需求。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要依赖大模型的通用知识，忽略了环境特定适配的潜在增益。直接微调大模型存在训练成本高、多用户场景推理效率低、灾难性遗忘风险以及模型参数访问受限等问题。

Method: 建立协作框架：大模型作为通用信道知识库，小模型作为轻量插件捕获环境特定知识。具体实现LASCO框架：大模型生成初始CSI重建，通过参考SAM和代理SAM学习环境引起的重建偏移，并将偏移传回大模型。进一步提出E-LASCO，引入可学习的协作系数来控制不同环境中大模型和小模型的贡献度。

Result: 数值结果表明，LASCO和E-LASCO使大模型能够实现环境特定的性能提升，同时显著降低训练成本、减少数据收集需求并加快适配速度。

Conclusion: 提出的协作框架有效解决了大模型在无线通信中环境特定适配的挑战，通过大模型与小模型的协同工作，实现了高效、低成本的环境适配，为无线通信系统优化提供了新思路。

Abstract: Large artificial intelligence models (LAMs) have shown strong capability in wireless communications, yet existing works mainly rely on their generalized knowledge across environments while overlooking the potential gains of environment-specific adaptation. Directly fine-tuning LAMs for adaptation is often impractical due to prohibitive training costs, low inference efficiency in multi-user scenarios, and the risk of catastrophic forgetting, in addition to the limited accessibility of model parameters. To address these limitations, we establish a collaborative framework for air interface. In this framework, unlike prior approaches that either depend solely on LAMs or require direct fine-tuning, LAMs are exploited as a universal channel knowledge base while small artificial intelligence models (SAMs) are employed as lightweight plugins to capture environment-specific knowledge, facilitating efficient environment-specific adaptation of LAMs. Subsequently, we instantiate this framework for CSI feedback tasks, and develop a large and small collaboration framework for CSI feedback, referred to as LASCO. LASCO operates by letting the base LAM produce an initial CSI reconstruction, learning the environment-induced reconstruction shift through a reference SAM and a proxy SAM, and transferring this shift back to the LAM. To further enhance adaptability, we introduce elastic-LASCO (E-LASCO), which augments LASCO with learnable collaboration coefficients that control the contribution of LAMs and SAMs across different environments. Numerical results demonstrate that LASCO and E-LASCO enables LAMs to achieve environment-specific performance gains with significantly reduced training costs, lower data collection requirements, and faster adaptation speed.

</details>


### [67] [Hulls of Free Linear Codes over a Non-Unital Ring](https://arxiv.org/abs/2512.12335)
*Anup Kushwaha,Om Prakash*

Main category: cs.IT

TL;DR: 该论文研究了非幺环E上自由线性码的壳码，提出了壳码的生成矩阵形式，给出了四种构建方法来构造更大长度和壳秩的码，研究了置换等价性和壳变化问题，并分类了长度不超过8的最优自由E-线性码。


<details>
  <summary>Details</summary>
Motivation: 研究非幺环E上自由线性码的壳码结构，探索如何从较小长度和壳秩的码构造更大码的方法，并解决置换等价性和壳变化问题，为分类最优自由E-线性码提供理论基础。

Method: 首先分析E-线性码各种壳的剩余码和挠码，获得自由E-线性码壳的生成矩阵显式形式；然后提出四种构建方法从较小长度和壳秩的码构造更大码；接着研究两个自由E-线性码的置换等价性并讨论壳变化问题。

Result: 获得了自由E-线性码壳的生成矩阵显式形式；提出了四种有效的构建方法；建立了置换等价性判据；解决了壳变化问题；分类了长度不超过8的最优自由E-线性码。

Conclusion: 该论文系统研究了非幺环E上自由线性码的壳码理论，提供了构造方法和等价性判据，为最优码的分类和应用奠定了理论基础。

Abstract: This paper investigates the hull codes of free linear codes over a non-unital ring $ E= \langle κ,τ\mid 2 κ=2 τ=0,~ κ^2=κ,~ τ^2=τ,~ κτ=κ,~ τκ=τ\rangle$. Initially, we examine the residue and torsion codes of various hulls of $E$-linear codes and obtain an explicit form of the generator matrix of the hull of a free $E$-linear code. Then, we propose four build-up construction methods to construct codes with a larger length and hull-rank from codes with a smaller length and hull-rank. Some illustrative examples are also given to support our build-up construction methods. Subsequently, we study the permutation equivalence of two free $E$-linear codes and discuss the hull-variation problem. As an application, we classify optimal free $E$-linear codes for lengths up to $8$.

</details>


### [68] [From Information Freshness to Semantics of Information and Goal-oriented Communications](https://arxiv.org/abs/2512.12758)
*Jiping Luo,Erfan Delfani,Mehrdad Salimnejad,Nikolaos Pappas*

Main category: cs.IT

TL;DR: 本文系统梳理了从传统失真度量到信息新鲜度指标（如AoI），再到面向任务的语义感知通信的演进，提出了统一的语义感知度量框架，并分析了基于MDP和Lyapunov优化的调度策略设计方法。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要支持实时数据驱动的信息物理系统，传统以准确性、吞吐量和延迟为中心的通信范式已无法满足需求，信息的价值取决于其与特定任务的语义相关性。

Method: 1. 系统化组织现有语义感知度量（内容/版本感知、上下文相关失真、历史相关错误持续性度量）；2. 分析基于马尔可夫决策过程（MDP）和Lyapunov优化的分析工具；3. 提出统一的语义感知通信框架。

Result: 建立了从传统失真度量到语义感知通信的演进框架，明确了语义感知度量如何克服纯准确性或新鲜度中心设计的局限性，展示了如何通过选择性生成和传输任务相关信息来显著提高效率、可靠性和任务性能。

Conclusion: 面向目标的语义感知通信系统能够显著提升效率、可靠性和任务性能，为6G及未来网络的语义通信架构设计提供了指导原则，架起了信息论、控制论和网络视角之间的桥梁。

Abstract: Future wireless networks must support real-time, data-driven cyber-physical systems in which communication is tightly coupled with sensing, inference, control, and decision-making. Traditional communication paradigms centered on accuracy, throughput, and latency are increasingly inadequate for these systems, where the value of information depends on its semantic relevance to a specific task. This paper provides a unified exposition of the progression from classical distortion-based frameworks, through information freshness metrics such as the Age of Information (AoI) and its variants, to the emerging paradigm of goal-oriented semantics-aware communication. We organize and systematize existing semantics-aware metrics, including content- and version-aware measures, context-dependent distortion formulations, and history-dependent error persistence metrics that capture lasting impact and urgency. Within this framework, we highlight how these metrics address the limitations of purely accuracy- or freshness-centric designs, and how they collectively enable the selective generation and transmission of only task-relevant information. We further review analytical tools based on Markov decision process (MDP) and Lyapunov optimization methods that have been employed to characterize optimal or near-optimal timing and scheduling policies under semantic performance criteria and communication constraints. By synthesizing these developments into a coherent framework, the paper clarifies the design principles underlying goal-oriented, semantics-aware communication systems. It illustrates how they can significantly improve efficiency, reliability, and task performance. The presented perspective aims to serve as a bridge between information-theoretic, control-theoretic, and networking viewpoints, and to guide the design of semantic communication architectures for 6G and beyond.

</details>


### [69] [ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems](https://arxiv.org/abs/2512.12366)
*Babak Badnava,Jacob Chakareski,Morteza Hashemi*

Main category: cs.IT

TL;DR: ElasticVR框架通过可扩展的360度视频分块和多连接边缘计算，使用多智能体深度强化学习优化VR应用的QoE和能耗


<details>
  <summary>Details</summary>
Motivation: 高保真360度视频流需要大量计算和带宽，现有VR系统缺乏根据用户和系统资源弹性调整计算任务的能力

Method: 提出ElasticVR框架，集成可扩展360度视频分块和多连接边缘架构，采用两种多智能体深度强化学习方法：集中式训练集中式执行(CPPG)和集中式训练分散式执行(IPPG)

Result: 相比无弹性VR计算，PSNR提升43.21%，响应时间降低42.35%，能耗降低56.83%

Conclusion: ElasticVR框架通过弹性计算卸载和多智能体强化学习，有效平衡了通信、计算、能耗和QoE之间的权衡，显著提升了VR系统性能

Abstract: Diverse emerging VR applications integrate streaming of high fidelity 360 video content that requires ample amounts of computation and data rate. Scalable 360 video tiling enables having elastic VR computational tasks that can be scaled adaptively in computation and data rate based on the available user and system resources. We integrate scalable 360 video tiling in an edge-client wireless multi-connectivity architecture for joint elastic task computation offloading across multiple VR users called ElasticVR. To balance the trade-offs in communication, computation, energy consumption, and QoE that arise herein, we formulate a constrained QoE and energy optimization problem that integrates the multi-user/multi-connectivity action space with the elasticity of VR computational tasks. The ElasticVR framework introduces two multi-agent deep reinforcement learning solutions, namely CPPG and IPPG. CPPG adopts a centralized training and centralized execution approach to capture the coupling between users' communication and computational demands. This leads to globally coordinated decisions at the cost of increased computational overheads and limited scalability. To address the latter challenges, we also explore an alternative strategy denoted IPPG that adopts a centralized training with decentralized execution paradigm. IPPG leverages shared information and parameter sharing to learn robust policies; however, during execution, each user takes action independently based on its local state information only. The decentralized execution alleviates the communication and computation overhead of centralized decision-making and improves scalability. We show that the ElasticVR framework improves the PSNR by 43.21%, while reducing the response time and energy consumption by 42.35% and 56.83%, respectively, compared with a case where no elasticity is incorporated into VR computations.

</details>


### [70] [Linear Codes with Certain Dimension of Hermitian Hulls](https://arxiv.org/abs/2512.12519)
*Jiabin Wang,Jinquan Luo*

Main category: cs.IT

TL;DR: 研究有限域上酉空间中Hermitian ℓ-互补码的计数公式和渐近性质，发现Hermitian自正交码与无限制码在渐近重量分布上相似，并证明当字母表大小趋于无穷时，Hermitian自正交码中的MDS码是渐近稠密的。


<details>
  <summary>Details</summary>
Motivation: 研究Hermitian ℓ-互补码的枚举和渐近性质，探索Hermitian自正交码与无限制码在渐近行为上的关系，特别关注最小距离约束下的Hermitian自正交码的渐近特性。

Method: 在有限域F_{q^2}上的酉空间中，推导Hermitian ℓ-互补码的计数公式的闭式表达式，分析Hermitian自正交码的渐近重量分布，研究具有最小距离约束的Hermitian自正交码的渐近行为。

Result: 得到了Hermitian ℓ-互补码的计数公式闭式表达式，发现Hermitian自正交码与无限制码在渐近重量分布上具有相似性，证明了当字母表大小趋于无穷时，Hermitian自正交码中的MDS码是渐近稠密的。

Conclusion: Hermitian ℓ-互补码的计数问题有闭式解，Hermitian自正交码在渐近性质上与无限制码相似，且在字母表足够大时，Hermitian自正交码中几乎都是MDS码，这为编码理论提供了重要的渐近性质理解。

Abstract: In this paper, we study the enumerative and asymptotic properties related to Hermitian $\ell$-complementary codes on the unitary space over $\F_{q^2}$. We provide some closed form expressions for the counting formulas of Hermitian $\ell$-complementary codes. There is a similarity in the asymptotic weight distribution between Hermitian self-orthogonal codes and unrestricted codes. Furthermore, we study the asymptotic behavior of Hermitian self-orthogonal codes whose minimum distance is at least $d$. In particular, we conclude that MDS codes within the class of Hermitian self-orthogonal codes are asymptotically dense when the alphabet size approaches to infinity.

</details>


### [71] [Vertical Heterogeneous Networks Beyond 5G: CoMP Coverage Enhancement and Optimization](https://arxiv.org/abs/2512.12563)
*Tian Shi,Wenkun Wen,Peiran Wu,Minghua Xia*

Main category: cs.IT

TL;DR: 该论文提出了一种在垂直异构网络中使用无人机作为空中基站，通过协调多点传输框架提升稀疏空中用户下行覆盖性能的方法。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络对低空经济发展至关重要，但在动态三维空间中为稀疏分布的空中用户提供可靠连接仍面临重大挑战。现有网络难以应对非均匀用户分布和高移动性环境。

Method: 提出协调多点传输框架，使无人机空中基站与地面基站联合传输。考虑两种无人机部署策略：1）随机部署，使用随机几何分析推导闭式覆盖表达式；2）优化部署，采用覆盖感知的加权K-means聚类算法最大化未覆盖区域的协作覆盖。

Result: 理论分析和蒙特卡洛仿真表明，提出的CoMP使能垂直异构网络显著提高了下行覆盖概率，特别是在稀疏空中用户场景下。优化部署策略比随机部署表现更好。

Conclusion: 智能无人机协调和几何感知部署能够为低空无线网络提供稳健、自适应的连接，展示了在5G+垂直异构网络中提升覆盖性能的潜力。

Abstract: Low-altitude wireless networks are increasingly vital for the low-altitude economy, enabling wireless coverage in high-mobility and hard-to-reach environments. However, providing reliable connectivity to sparsely distributed aerial users in dynamic three-dimensional (3D) spaces remains a significant challenge. This paper investigates downlink coverage enhancement in vertical heterogeneous networks (VHetNets) beyond 5G, where uncrewed aerial vehicles (UAVs) operate as emerging aerial base stations (ABSs) alongside legacy terrestrial base stations (TBSs). To improve coverage performance, we propose a coordinated multi-point (CoMP) transmission framework that enables joint transmission from ABSs and TBSs. This approach mitigates the limitations of non-uniform user distributions and enhances reliability for sparse aerial users. Two UAV deployment strategies are considered: \textit{i)} random UAV placement, analyzed using stochastic geometry to derive closed-form coverage expressions, and \textit{ii)} optimized UAV placement using a coverage-aware weighted $K$-means clustering algorithm to maximize cooperative coverage in underserved areas. Theoretical analyses and Monte Carlo simulations demonstrate that the proposed CoMP-enabled VHetNet significantly improves downlink coverage probability, particularly in scenarios with sparse aerial users. These findings highlight the potential of intelligent UAV coordination and geometry-aware deployment to enable robust, adaptive connectivity in low-altitude wireless networks.

</details>


### [72] [Linear Binary Codes Correcting One or More Errors](https://arxiv.org/abs/2512.12591)
*Timofei Izhitskii*

Main category: cs.IT

TL;DR: 本文研究线性二进制码的纠错能力，针对单纠错码给出了达到汉明界的构造方法及最小码字长度的精确表达式，针对一般情况通过陪集结构分析推导了线性码参数的简单下界。


<details>
  <summary>Details</summary>
Motivation: 研究线性二进制码的纠错能力，特别是单纠错码和一般线性码的参数优化问题，旨在找到更有效的编码构造方法和理论界限。

Method: 对于单纠错码，采用构造性方法证明汉明界的可达性；对于一般线性码，通过分析陪集结构来推导参数的下界。

Result: 对于单纠错码，证明了汉明界可以通过构造方法达到，并推导了最小码字长度的精确表达式；对于一般线性码，通过陪集结构分析得到了参数的简单下界。

Conclusion: 本文为线性二进制码的纠错能力提供了理论分析框架，特别是单纠错码的构造性证明和一般线性码的参数下界推导，为编码理论的发展做出了贡献。

Abstract: This paper examines linear binary codes capable of correcting one or more errors. For the single-error-correcting case, it is shown that the Hamming bound is achieved by a constructive method, and an exact expression for the minimal codeword length is derived. For the general case, a simple lower bound for the parameters of linear codes is derived from an analysis of the coset structure.

</details>


### [73] [C-PASS: Center-Fed Pinching Antenna System](https://arxiv.org/abs/2512.12619)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: 提出了一种新型的中心馈电夹持天线系统（C-PASS），通过从中心端口馈电信号并向波导两侧传播，实现在单个波导中的空间复用增益。


<details>
  <summary>Details</summary>
Motivation: 传统端馈PASS系统在空间复用能力上有限，需要提高无线通信系统的容量和自由度。

Method: 提出C-PASS架构，信号从中心输入端口馈入并向波导两侧传播，推导出自由度和功率缩放定律的闭式表达式。

Result: C-PASS相比传统PASS可实现两倍的自由度和额外的复用增益O(P_T ln^4 N/N^2)，数值结果显示容量显著提升。

Conclusion: C-PASS通过增强的自由度和复用增益，能够显著提高无线通信系统的容量性能。

Abstract: A novel architecture of the center-fed pinching antenna system (C-PASS) is proposed. In contrast to the conventional end-fed PASS, signals are fed from the center input ports and propagate towards both sides of the waveguide. By doing so, spatial-multiplexing gain can be achieved in a single waveguide. Based on the proposed C-PASS, closed-form expressions for the degree of freedom (DoF) and power scaling laws are derived. These theoretical results reveal that C-PASS can achieve \emph{twice} the DoF and an additional multiplexing gain of $\mathcal{O}(P_T \ln^4 N/N^2)$ compared to the conventional PASS, where $P_T$ and $N$ represent the transmit power and pinching antenna number, respectively. Numerical results are provided to demonstrate that substantial capacity improvements can be achieved through the enhanced DoF and multiplexing gain of the C-PASS.

</details>


### [74] [Information-Theoretic Limits of Integrated Sensing and Communication with Finite Learning Capacity](https://arxiv.org/abs/2512.13292)
*Farshad Rostami Ghadi,F. Javier Lopez-Martinez,Kai-Kit Wong,Christos Masouros*

Main category: cs.IT

TL;DR: 提出AI辅助ISAC的统一信息论框架，引入AI容量预算概念量化学习模型有限能力对联合通信感知性能的约束，推导性能边界并分析高斯/衰落信道影响，建立学习-信息权衡定律。


<details>
  <summary>Details</summary>
Motivation: 下一代ISAC系统需要在有限学习模型容量下联合优化通信和感知性能，但现有研究缺乏统一的理论框架来量化学习能力约束对性能边界的根本限制。

Method: 建立AI辅助ISAC的信息论框架，引入AI容量预算概念，推导通信速率-感知失真区域的上下界，分析高斯/衰落/MIMO信道中学习容量约束的等效噪声影响，提出变分训练方法。

Result: 证明有限学习容量在高斯信道中等效为加性噪声，得到闭式性能表达式；建立学习-信息权衡定律；提出资源分配优化方案；推导出指导ISAC系统设计的缩放定律。

Conclusion: AI容量预算为AI辅助ISAC提供了统一的理论分析框架，学习能力约束会等效为性能损失，建立的权衡定律和缩放定律为下一代ISAC系统的模型规模、波形和硬件协同设计提供了定量指导。

Abstract: This paper develops a unified information-theoretic framework for artificial-intelligence (AI)-aided integrated sensing and communication (ISAC), where a learning component with limited representational capacity is embedded within the transceiver loop. The study introduces the concept of an AI capacity budget to quantify how the finite ability of a learning model constrains joint communication and sensing performance. Under this framework, the paper derives both converse (upper) and achievability (lower) bounds that define the achievable rate-sensing region. For Gaussian channels, the effect of limited learning capacity is shown to behave as an equivalent additive noise, allowing simple analytical expressions for the resulting communication rate and sensing distortion. The theory is then extended to Rayleigh and Rician fading as well as to multiple-input multiple-output (MIMO) systems through new matrix inequalities and a constructive mapping between AI capacity and effective noise covariance. Resource allocation between sensing and communication is optimized under this learning constraint, yielding closed-form conditions in the Gaussian case. A general learning-information trade-off law is also established, linking the representational power of the learning module to the achievable performance frontier. Finally, a practical variational training procedure is proposed to enforce the capacity constraint and to guide empirical evaluation. The derived scaling laws provide quantitative insight for co-designing model size, waveform, and hardware in next-generation ISAC systems.

</details>


### [75] [Machine learning discovers new champion codes](https://arxiv.org/abs/2512.13370)
*Yang-Hui He,Alexander Kasprzyk,Q Le,Dmitrii Riabchenko*

Main category: cs.IT

TL;DR: 使用Transformer预测线性码的最小汉明距离，结合遗传算法搜索，开发出发现最优线性码的新方法，有效缩小搜索空间


<details>
  <summary>Details</summary>
Motivation: 线性纠错码是现代数字通信和存储系统的数学基础，但识别最优线性码（达到或超过已知最佳最小汉明距离的码）仍然具有挑战性。传统方法搜索空间巨大，需要更高效的方法来发现最优码。

Method: 训练Transformer模型来预测一类线性码的最小汉明距离，然后将其与遗传算法配对，在搜索空间中进行优化搜索。这种组合方法能够有效减少寻找最优码所需的搜索空间。

Result: 该方法成功应用于研究和构建各种纠错码，包括广义环面码、Reed-Muller码、Bose-Chaudhuri-Hocquenghem码、代数几何码，并可能应用于量子码。

Conclusion: Transformer与遗传算法的结合为发现最优线性码提供了一种新颖有效的方法，能够显著提高搜索效率，在纠错码设计和研究中具有重要应用价值。

Abstract: Linear error-correcting codes form the mathematical backbone of modern digital communication and storage systems, but identifying champion linear codes (linear codes achieving or exceeding the best known minimum Hamming distance) remains challenging. By training a transformer to predict the minimum Hamming distance of a class of linear codes and pairing it with a genetic algorithm over the search space, we develop a novel method for discovering champion codes. This model effectively reduces the search space of linear codes needed to achieve champion codes. Our results present the use of this method in the study and construction of error-correcting codes, applicable to codes such as generalised toric, Reed-Muller, Bose-Chaudhuri-Hocquenghem, algebrogeometric, and potentially quantum codes.

</details>


### [76] [Two Families of Linear Codes Containing Non-GRS MDS Codes](https://arxiv.org/abs/2512.13429)
*Kanat Abdukhalikov,Gyanendra K. Verma*

Main category: cs.IT

TL;DR: 通过修改广义Reed-Solomon码的生成矩阵构造了两类新的线性码，研究了它们的MDS性质、非GRS特性以及自正交和自对偶性质


<details>
  <summary>Details</summary>
Motivation: 在广义Reed-Solomon码的基础上构造新的线性码，探索具有MDS性质但非GRS结构的码，同时研究其自正交和自对偶特性

Method: 通过修改GRS码的生成矩阵构造两类新的线性码族，推导其校验矩阵，建立MDS性质的充要条件，并分析其中的非GRS MDS子族

Result: 成功构造了两类新的线性码族，给出了其校验矩阵的显式表达式，建立了MDS性质的判别条件，发现了非GRS MDS码的子族，并刻画了自正交和自对偶性质

Conclusion: 该工作扩展了线性码的构造方法，提供了新的MDS码构造，特别是非GRS结构的MDS码，为编码理论提供了新的工具和实例

Abstract: We construct two new families of linear codes by modifying the generator matrices of generalized Reed-Solomon (GRS) codes. For these codes, we explicitly derive parity-check matrices and establish necessary and sufficient conditions ensuring the MDS property. Additionally, we explore subfamilies within these constructions that are non-GRS MDS codes. We also characterize their self-orthogonal and self-dual properties and present some explicit constructions and examples.

</details>


### [77] [From Zipf's Law to Neural Scaling through Heaps' Law and Hilberg's Hypothesis](https://arxiv.org/abs/2512.13491)
*Łukasz Dębowski*

Main category: cs.IT

TL;DR: 论文证明了在特定假设下，神经缩放定律可以从Zipf定律推导出来，揭示了两种统计定律之间的演绎关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索神经缩放定律（描述基础模型交叉熵率随训练数据、参数和计算量变化的规律）与Zipf定律（描述词元分布的幂律尾特性）之间的演绎关系，澄清机器学习与定量语言学中这两个重要定律的联系。

Method: 通过系统性的推导步骤：1) 从Zipf定律推导Heaps定律（词汇增长规律）；2) 从Heaps定律推导Hilberg假设（熵缩放规律）；3) 从Hilberg假设推导神经缩放定律。使用满足所有四个统计定律的Santa Fe过程作为示例说明。

Result: 证明了在特定广泛假设下，神经缩放定律是Zipf定律的必然结果，建立了从Zipf定律到神经缩放定律的完整演绎链条。

Conclusion: 神经缩放定律与Zipf定律之间存在深刻的数学联系，神经缩放定律可以从Zipf定律推导出来，这为理解基础模型的缩放行为提供了理论基础。

Abstract: We inspect the deductive connection between the neural scaling law and Zipf's law -- two statements discussed in machine learning and quantitative linguistics. The neural scaling law describes how the cross entropy rate of a foundation model -- such as a large language model -- changes with respect to the amount of training tokens, parameters, and compute. By contrast, Zipf's law posits that the distribution of tokens exhibits a power law tail. Whereas similar claims have been made in more specific settings, we show that the neural scaling law is a consequence of Zipf's law under certain broad assumptions that we reveal systematically. The derivation steps are as follows: We derive Heaps' law on the vocabulary growth from Zipf's law, Hilberg's hypothesis on the entropy scaling from Heaps' law, and the neural scaling from Hilberg's hypothesis. We illustrate these inference steps by a toy example of the Santa Fe process that satisfies all the four statistical laws.

</details>


### [78] [Hyper-Minrank: A Unified Hypergraph Characterization of Multi-Sender Index Coding](https://arxiv.org/abs/2512.13615)
*Ali Khalesi,Petros Elia*

Main category: cs.IT

TL;DR: 提出了一种多发送者索引编码的超图模型，建立了严格的可达性-逆等价关系，并将最优广播长度表征为超图的最小秩。


<details>
  <summary>Details</summary>
Motivation: 将经典的Bar-Yossef索引编码范式推广到多发送者场景，为分布式通信系统（如缓存辅助通信、编码计算、分布式存储等）提供统一的理论框架。

Method: 引入4-正则侧信息超图G、新的邻接表示A_G和子超图有效性拟合准则，建立超图最小秩与线性编码的等价关系。

Result: 证明了每个有效拟合对应一个有效的线性多发送者索引码，反之亦然，最优标量线性广播长度等于超图最小秩；提出了Haemers型上下界和精确计算算法。

Conclusion: 该超图框架为多发送者索引编码提供了精确的理论表征，统一了多种应用场景，超图最小秩可作为统一的设计目标。

Abstract: This work introduces a hypergraph formulation that generalizes the classical paradigm of Bar-Yossef et al. to the multi-sender index coding (MSIC) setting. Central to the model is a 4-regular side-information hypergraph G, a new adjacency representation A_G = [A_1 ... A_N], and a simple fitting criterion for sub-hypergraph validity, in the presence of specially designed hyperedges that capture both side information and cross-sender signal cancellation. This formulation establishes a tight achievability-converse equivalence for the general N-sender, K-receiver problem: every valid fitting induces a valid linear multi-sender index code, every linear code induces a valid fitting, and the optimal scalar linear broadcast length equals the hyper-minrank l**lin(G) = hyperminrank(G) = min*{A fits G} sum_{n=1}^N rank(A_n). Beyond this exact characterization, the approach yields hypergraph analogues of Haemers-type bounds on the broadcast length, including a clique-cover upper bound and a lower bound via the clique number of a carefully defined complement hypergraph. Algorithmically, we provide an exact procedure to compute hyperminrank(G), and show that in certain regimes its complexity is asymptotically better than approximate LT-CMAR solutions. The framework captures well-known settings such as embedded index coding, and applies directly to multi-sender cache-aided communications, coded computation, distributed storage, and edge/satellite systems, where hyperminrank can serve as a unified design target.

</details>
