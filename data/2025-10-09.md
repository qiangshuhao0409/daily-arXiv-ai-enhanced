<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 9]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Adaptive Semantic Communication for UAV/UGV Cooperative Path Planning](https://arxiv.org/abs/2510.06901)
*Fangzhou Zhao,Yao Sun,Jianglin Lan,Lan Zhang,Xuesong Liu,Muhammad Ali Imran*

Main category: cs.NI

TL;DR: 提出了一种语义通信框架，用于在不可靠无线条件下增强无人机/无人地面车辆协同路径规划，通过传输关键语义信息而非原始数据来减少传输量并保持规划精度。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，无人机和无人地面车辆协同工作时，由于严重干扰和非视距条件，无线通信往往不稳定，难以支持及时准确的路径规划。

Method: 通过定义路径规划的关键语义并设计专门的收发器，开发语义通信框架，仅传输路径规划所需的关键信息。

Result: 仿真结果表明，与传统语义通信收发器相比，所提出的收发器显著减少了数据传输量，同时保持了路径规划精度，提高了系统协作效率。

Conclusion: 语义通信框架能够有效解决复杂环境中无人机-无人地面车辆协同路径规划的通信可靠性问题，通过减少传输数据量来提升系统性能。

Abstract: Effective path planning is fundamental to the coordination of unmanned aerial
vehicles (UAVs) and unmanned ground vehicles (UGVs) systems, particularly in
applications such as surveillance, navigation, and emergency response.
Combining UAVs' broad field of view with UGVs' ground-level operational
capability greatly improve the likelihood of successfully achieving task
objectives such as locating victims, monitoring target areas, or navigating
hazardous terrain. In complex environments, UAVs need to provide precise
environmental perception information for UGVs to optimize their routing policy.
However, due to severe interference and non-line-of-sight conditions, wireless
communication is often unstable in such complex environments, making it
difficult to support timely and accurate path planning for UAV-UGV
coordination. To this end, this paper proposes a semantic communication
(SemCom) framework to enhance UAV/UGV cooperative path planning under
unreliable wireless conditions. Unlike traditional methods that transmit raw
data, SemCom transmits only the key information for path planning, reducing
transmission volume without sacrificing accuracy. The proposed framework is
developed by defining key semantics for path planning and designing a
transceiver for meeting the requirements of UAV-UGV cooperative path planning.
Simulation results show that, compared to conventional SemCom transceivers, the
proposed transceiver significantly reduces data transmission volume while
maintaining path planning accuracy, thereby enhancing system collaboration
efficiency.

</details>


### [2] [Dynamic Control Aware Semantic Communication Enabled Image Transmission for Lunar Landing](https://arxiv.org/abs/2510.06916)
*Fangzhou Zhao,Yao Sun,Jianglin Lan,Muhammad Ali Imran*

Main category: cs.NI

TL;DR: 提出了一种用于月球着陆器与轨道卫星间图像传输的语义通信框架，通过动态调整传输策略来提升自主着陆性能。


<details>
  <summary>Details</summary>
Motivation: 解决月球着陆任务中本地控制系统处理高动态条件能力有限的问题，利用卫星通信实现高性能自主着陆算法，但传统通信方式无法适应月球恶劣环境。

Method: 设计基于语义通信的编码器-解码器框架，根据着陆器控制算法的实时反馈动态调整传输策略，确保关键图像特征的准确传输。

Result: 仿真结果表明，相比传统通信方法，该语义通信方法显著提升了自主着陆性能。

Conclusion: 语义通信框架能够有效应对月球恶劣通信环境，提高着陆精度和控制可靠性，为未来月球探测任务提供重要技术支撑。

Abstract: The primary challenge in autonomous lunar landing missions lies in the
unreliable local control system, which has limited capacity to handle
high-dynamic conditions, severely affecting landing precision and safety.
Recent advancements in lunar satellite communication make it possible to
establish a wireless link between lunar orbit satellites and the lunar lander.
This enables satellites to run high-performance autonomous landing algorithms,
improving landing accuracy while reducing the lander's computational and
storage load. Nevertheless, traditional communication paradigms are not
directly applicable due to significant temperature fluctuations on the lunar
surface, intense solar radiation, and severe interference caused by lunar dust
on hardware. The emerging technique of semantic communication (SemCom) offers
significant advantages in robustness and resource efficiency, particularly
under harsh channel conditions. In this paper, we introduce a novel SemCom
framework for transmitting images from the lander to satellites operating the
remote landing control system. The proposed encoder-decoder dynamically adjusts
the transmission strategy based on real-time feedback from the lander's control
algorithm, ensuring the accurate delivery of critical image features and
enhancing control reliability. We provide a rigorous theoretical analysis of
the conditions that improve the accuracy of the control algorithm and reduce
end-to-end transmission time under the proposed framework. Simulation results
demonstrate that our SemCom method significantly enhances autonomous landing
performance compared to traditional communication methods.

</details>


### [3] [A Genetic Algorithm Approach to Anti-Jamming UAV Swarm Behavior](https://arxiv.org/abs/2510.07292)
*Tiago Silva,António Grilo*

Main category: cs.NI

TL;DR: 该论文使用遗传算法联合优化无人机群编队、波束成形天线和流量路由，以减轻主协调信道中的干扰影响。


<details>
  <summary>Details</summary>
Motivation: 无人机群在军事应用中面临通信干扰威胁，虽然抗干扰技术已有研究，但利用智能群行为来增强这些技术仍是开放研究问题。

Method: 采用遗传算法联合优化无人机群编队、波束成形天线和流量路由，假设使用更鲁棒的低数据率信道进行编队管理信令。

Result: 仿真结果表明所提方法的有效性，但计算成本较高。

Conclusion: 该方法能有效缓解干扰，但显著的计算成本为后续研究指明了方向。

Abstract: In recent years, Unmanned Aerial Vehicles (UAVs) have brought a new true
revolution to military tactics. While UAVs already constitute an advantage when
operating alone, multi-UAV swarms expand the available possibilities, allowing
the UAVs to collaborate and support each other as a team to carry out a given
task. This entails the capability to exchange information related with
situation awareness and action coordination by means of a suitable wireless
communication technology. In such scenario, the adversary is expected to
disrupt communications by jamming the communication channel. The latter becomes
the Achilles heel of the swarm. While anti-jamming techniques constitute a well
covered topic in the literature, the use of intelligent swarm behaviors to
leverage those techniques is still an open research issue.
  This paper explores the use of Genetic Algorithms (GAs) to jointly optimize
UAV swarm formation, beam-steering antennas and traffic routing in order to
mitigate the effect of jamming in the main coordination channel, under the
assumption that a more robust and low data rate channel is used for formation
management signaling. Simulation results show the effectiveness of proposed
approach. However, the significant computational cost paves the way for further
research.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning](https://arxiv.org/abs/2510.06261)
*Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han*

Main category: cs.AI

TL;DR: AlphaApollo是一个自演化的智能推理系统，通过整合多个模型和专业工具来解决基础模型推理能力有限和测试时迭代不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型推理能力的两个瓶颈：模型内在容量有限和测试时迭代不可靠。

Method: 协调多个模型与专业工具进行可验证推理，结合计算工具（Python数值和符号库）和检索工具（任务相关外部信息），通过共享状态图支持多轮多模型解决方案演化。

Result: 在AIME 2024/2025评估中，AlphaApollo为Qwen2.5-14B-Instruct带来+5.15% Average@32和+23.34% Pass@32提升，为Llama-3.3-70B-Instruct带来+8.91% Average@32和+26.67% Pass@32提升。超过80%的工具调用成功执行。

Conclusion: AlphaApollo通过工具集成和多模型协作，有效提升了基础模型的能力上限，在复杂推理任务中表现优异。

Abstract: We present AlphaApollo, a self-evolving agentic reasoning system that aims to
address two bottlenecks in foundation model (FM) reasoning-limited
model-intrinsic capacity and unreliable test-time iteration. AlphaApollo
orchestrates multiple models with professional tools to enable deliberate,
verifiable reasoning. It couples (i) a computation tool (Python with numerical
and symbolic libraries) and (ii) a retrieval tool (task-relevant external
information) to execute exact calculations and ground decisions. The system
further supports multi-round, multi-model solution evolution via a shared state
map that records candidates, executable checks, and feedback for iterative
refinement. In evaluations on AIME 2024/2025 across multiple models,
AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32
for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for
Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool
calls are successfully executed, with consistent outperformance of non-tool
baselines, thereby lifting the capability ceiling of FMs. More empirical
results and implementation details will be updated at
https://github.com/tmlr-group/AlphaApollo.

</details>


### [5] [Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization](https://arxiv.org/abs/2510.06274)
*Mohammad Mahdi Samiei Paqaleh,Arash Marioriyad,Arman Tahmasebi-Zadeh,Mohamadreza Fereydooni,Mahdi Ghaznavai,Mahdieh Soleymani Baghshah*

Main category: cs.AI

TL;DR: 提出了复杂性分布外泛化框架来定义和衡量推理能力，强调当测试实例所需的最小解决方案复杂性超过所有训练样本时，模型仍能保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI在逐步推理方面取得进展，但缺乏对推理能力的明确定义和度量标准。需要建立统一的框架来区分学习与推理，并指导评估和训练方法。

Method: 通过解决方案描述的柯尔莫哥洛夫复杂性和操作代理来形式化复杂性，区分表示复杂性（更丰富的解决方案结构）和计算复杂性（更多推理步骤/程序长度）。

Result: 建立了复杂性分布外泛化框架，统一了学习和推理：低复杂性时可用类似系统1处理，高复杂性时需系统2推理，系统2可视为解决方案结构的泛化。

Conclusion: 复杂性分布外泛化不能仅通过扩展数据解决，需要专门针对复杂性的架构和训练机制，包括基准设计、监督方式、归纳偏置等方面的改进。

Abstract: Recent progress has pushed AI frontiers from pattern recognition tasks toward
problems that require step by step, System2 style reasoning, especially with
large language models. Yet, unlike learning, where generalization and out of
distribution (OoD) evaluation concepts are well formalized, there is no clear,
consistent definition or metric for reasoning ability. We propose Complexity
Out of Distribution (Complexity OoD) generalization as a framework and problem
setting to define and measure reasoning. A model exhibits Complexity OoD
generalization when it maintains performance on test instances whose minimal
required solution complexity, either representational (richer solution
structure) or computational (more reasoning steps/program length), exceeds that
of all training examples. We formalize complexity via solution description
Kolmogorov complexity and operational proxies (e.g., object/relation counts;
reasoning step counts), clarifying how Complexity OoD differs from length and
compositional OoD. This lens unifies learning and reasoning: many cases
solvable with System1 like processing at low complexity become System2 like
under complexity pressure, while System2 can be viewed as generalization over
solution structures. We translate this perspective into practice with
recommendations for operationalizing Complexity OoD across the stack:
incorporating complexity into benchmark and evaluation metric design,
rethinking supervision to target solution traces, seeking and designing
inductive biases for Complexity OoD generalization, addressing learning to
reason spillovers such as spurious shortcuts, semantic robustness, catastrophic
forgetting, and step wise calibration. Because Complexity OoD cannot be solved
by scaling data alone, progress toward robust reasoning will require
architectures and training regimes that explicitly model and allocate
computation with respect to complexity.

</details>


### [6] [BuilderBench -- A benchmark for generalist agents](https://arxiv.org/abs/2510.06288)
*Raj Ghugare,Catherine Ji,Kathryn Wantlin,Jin Schofield,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: BuilderBench是一个用于加速智能体预训练研究的基准测试，专注于开放式探索，要求智能体学习使用积木构建各种结构，测试其对物理、数学和长期规划的理解。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型主要通过模仿和精炼学习，难以解决超出已有数据范围的新问题。为了应对新颖问题，智能体需要获得通过经验探索和学习的能力。

Method: BuilderBench包含硬件加速的机器人智能体与物理积木交互的模拟器，以及包含42个多样化目标结构的任务套件，智能体在训练期间需无监督地探索环境并学习通用原则。

Result: 实验表明，许多任务对当前算法构成挑战，因此提供了"训练轮"协议，让智能体训练和评估构建单个目标结构。

Conclusion: BuilderBench为研究人员提供了评估智能体预训练方法的基准，并提供了六种不同算法的单文件实现作为参考点。

Abstract: Today's AI models learn primarily through mimicry and sharpening, so it is
not surprising that they struggle to solve problems beyond the limits set by
existing data. To solve novel problems, agents should acquire skills for
exploring and learning through experience. Finding a scalable learning
mechanism for developing agents that learn through interaction remains a major
open problem. In this work, we introduce BuilderBench, a benchmark to
accelerate research into agent pre-training that centers open-ended
exploration. BuilderBench requires agents to learn how to build any structure
using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated
simulator of a robotic agent interacting with various physical blocks, and
$(2)$ a task-suite with over 42 diverse target structures that are carefully
curated to test an understanding of physics, mathematics, and long-horizon
planning. During training, agents have to explore and learn general principles
about the environment without any external supervision. During evaluation,
agents have to build the unseen target structures from the task suite. Solving
these tasks requires a sort of \emph{embodied reasoning} that is not reflected
in words but rather in actions, experimenting with different strategies and
piecing them together. Our experiments show that many of these tasks challenge
the current iteration of algorithms. Hence, we also provide a ``training
wheels'' protocol, in which agents are trained and evaluated to build a single
target structure from the task suite. Finally, we provide single-file
implementations of six different algorithms as a reference point for
researchers.

</details>


### [7] [Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration](https://arxiv.org/abs/2510.06302)
*Ksenija Lace,Marite Kirikova*

Main category: cs.AI

TL;DR: 本文探讨如何通过游戏化学习设计解决并购后信息系统集成培训中学习曲线高和学习动机低的问题，提出定制化的游戏化学习框架。


<details>
  <summary>Details</summary>
Motivation: 并购后信息系统集成面临独特挑战，现有培训方法存在学习曲线高和学习动机低的问题，需要更有效的培训方式。

Method: 分析基础学习理论、认知负荷与动机模型、严肃游戏设计框架，识别游戏化学习设计的关键要求，构建包含转换过程和结果学习体验的框架。

Result: 提出了专门针对并购后信息系统集成的游戏化学习设计框架，包含两个核心组件：转换过程和结果学习体验。

Conclusion: 计划通过迭代设计和实际验证来开发和评估所提出的框架，以改善信息系统集成培训效果。

Abstract: Post-merger integration states unique challenges for professionals
responsible for information system integration aimed on alignment and
combination diverse system architectures of merging organizations. Although the
theoretical and practical guidance exists for post-merger integration on the
business level, there is a significant gap in training for information system
integration in this context. In prior research specific methods AMILI (Support
method for informed decision identification) and AMILP (Support method for
informed decision-making) were introduced for the support of information system
integration decisions in the post-merger integration. But during the practical
application was reported high learning curve and low learner motivation. This
paper explores how game-based learning design can address these limitations by
transforming static method training into engaging learning experience. The
study analyzes foundational learning theories, cognitive load and motivation
models, and serious game design frameworks to identify the essential
requirements for a game-based learning design framework tailored to information
system integration in post-merger integration. Requirements are structured in
two components: the transformation process and resulting learning experience.
The paper concludes with a plan for developing and evaluating the proposed
framework through iterative design and real-world validation.

</details>


### [8] [Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks](https://arxiv.org/abs/2510.06307)
*Wentao Deng,Jiahuan Pei,Zhiwei Xu,Zhaochun Ren,Zhumin Chen,Pengjie Ren*

Main category: cs.AI

TL;DR: 提出了一个信念校准的共识寻求（BCCS）框架，通过选择最优合作者和校准系统内部信念来促进稳定共识，在MATH和MMLU基准测试中优于现有最佳结果。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统中的共识寻求方法通常依赖投票机制，忽视了系统内部信念的矛盾，且采用无差别的协作方式，无法为每个智能体找到最优合作者，阻碍了稳定共识的形成。

Method: 提出了一个理论框架来选择最大化共识稳定性的最优合作者，并基于此设计了BCCS框架，通过选择最优合作者和校准系统内部信念来促进稳定共识。

Result: 在MATH和MMLU基准数据集上的实验结果表明，BCCS框架在具有挑战性的任务上分别比现有最佳结果准确率提高了2.23%和3.95%。

Conclusion: BCCS框架通过选择最优合作者和校准系统内部信念，有效促进了多智能体系统中的稳定共识形成，在复杂NLP任务中表现出色。

Abstract: A multi-agent system (MAS) enhances its capacity to solve complex natural
language processing (NLP) tasks through collaboration among multiple agents,
where consensus-seeking serves as a fundamental mechanism. However, existing
consensus-seeking approaches typically rely on voting mechanisms to judge
consensus, overlooking contradictions in system-internal beliefs that
destabilize the consensus. Moreover, these methods often involve agents
updating their results through indiscriminate collaboration with every other
agent. Such uniform interaction fails to identify the optimal collaborators for
each agent, hindering the emergence of a stable consensus. To address these
challenges, we provide a theoretical framework for selecting optimal
collaborators that maximize consensus stability. Based on the theorems, we
propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate
stable consensus via selecting optimal collaborators and calibrating the
consensus judgment by system-internal beliefs. Experimental results on the MATH
and MMLU benchmark datasets demonstrate that the proposed BCCS framework
outperforms the best existing results by 2.23% and 3.95% of accuracy on
challenging tasks, respectively. Our code and data are available at
https://github.com/dengwentao99/BCCS.

</details>


### [9] [Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?](https://arxiv.org/abs/2510.06410)
*Aochong Oliver Li,Tanya Goyal*

Main category: cs.AI

TL;DR: 论文研究发现，经过标准单人推理训练的LLMs在协作推理中存在局限性：更强的模型在面对干扰推理时更脆弱，所有模型都无法有效利用超出自身能力范围的协作推理步骤。


<details>
  <summary>Details</summary>
Motivation: 研究标准单人推理训练流程是否能产生理想的离轨推理行为，即评估模型能否在共享推理轨迹中协作，包括从误导推理中恢复和基于正确推理进行构建的能力。

Method: 提出双测试框架：可恢复性测试（从误导推理痕迹中回溯）和可引导性测试（基于更强协作者的推理进行构建）。评估15个开源LLMs（1.5B-32B），并进行控制研究分析蒸馏教师选择、RL使用和数据选择策略的影响。

Result: 反直觉发现：基准测试中更强的LLMs在干扰下往往更脆弱；所有模型在超出自身能力的问题上利用引导步骤的解决率低于9.2%；教师模型的不佳恢复行为会传递给蒸馏学生。

Conclusion: 标准单人推理训练无法产生有效的协作推理能力，为训练原生强推理协作者提供了行动指南，强调了现成推理LLMs在共享推理轨迹协作中的局限性。

Abstract: Reasoning LLMs are trained to verbalize their reasoning process, yielding
strong gains on complex tasks. This transparency also opens a promising
direction: multiple reasoners can directly collaborate on each other's thinking
within a shared trajectory, yielding better inference efficiency and
exploration. A key prerequisite, however, is the ability to assess the
usefulness and build on another model's partial thinking -- we call this
off-trajectory reasoning. Our paper investigates a critical question: can
standard solo-reasoning training pipelines deliver desired off-trajectory
behaviors? We propose twin tests that capture the two extremes of the
off-trajectory spectrum, namely Recoverability, which tests whether LLMs can
backtrack from "distractions" induced by misleading reasoning traces, and
Guidability, which tests their ability to build upon correct reasoning from
stronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and
reveals a counterintuitive finding -- "stronger" LLMs on benchmarks are often
more fragile under distraction. Moreover, all models tested fail to effectively
leverage guiding steps from collaborators on problems beyond their inherent
capabilities with solve rates remaining under 9.2%. Finally, we conduct control
studies to isolate the effects of three factors in post-training on these
behaviors: the choice of distillation teacher, the use of RL, and data
selection strategy. Our results provide actionable insights for training
natively strong reasoning collaborators; e.g., we find that suboptimal
recoverability behaviors of teacher models are transferred to distilled
students even if the distillation trajectories are correct. Taken together,
this work lays the groundwork for evaluating multi-model collaborations in
shared reasoning trajectories and highlights the limitations of off-the-shelf
reasoning LLMs.

</details>


### [10] [Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health](https://arxiv.org/abs/2510.06433)
*Aryan Singh Dalal,Yinglun Zhang,Duru Doğan,Atalay Mert İleri,Hande Küçük McGinty*

Main category: cs.AI

TL;DR: 该研究创建了一个知识图谱，将食物与健康联系起来，重点关注类黄酮含量与癌症的关系，使用KNARM方法构建机器可操作的语义网络表示。


<details>
  <summary>Details</summary>
Motivation: 目前很少有研究使用标准化的机器可读格式来表示食物与健康之间的关系，这限制了有效利用这些知识的能力。

Method: 使用KNARM方法，结合USDA数据库中的类黄酮含量数据和文献中的癌症关联信息，构建知识图谱。

Result: 成功创建了一个连接食物与健康的知识图谱，为研究人员探索饮食选择与疾病管理之间的复杂关系提供了示例。

Conclusion: 该知识图谱可作为研究基础，未来工作包括扩展图谱范围、添加更多相关数据，并通过推理发现隐藏关系。

Abstract: The focus on "food as medicine" is gaining traction in the field of health
and several studies conducted in the past few years discussed this aspect of
food in the literature. However, very little research has been done on
representing the relationship between food and health in a standardized,
machine-readable format using a semantic web that can help us leverage this
knowledge effectively. To address this gap, this study aims to create a
knowledge graph to link food and health through the knowledge graph's ability
to combine information from various platforms focusing on flavonoid contents of
food found in the USDA databases and cancer connections found in the
literature. We looked closely at these relationships using KNARM methodology
and represented them in machine-operable format. The proposed knowledge graph
serves as an example for researchers, enabling them to explore the complex
interplay between dietary choices and disease management. Future work for this
study involves expanding the scope of the knowledge graph by capturing nuances,
adding more related data, and performing inferences on the acquired knowledge
to uncover hidden relationships.

</details>


### [11] [PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles](https://arxiv.org/abs/2510.06475)
*Yitao Long,Yuru Jiang,Hongjun Liu,Yilun Zhao,Jingchen Sun,Yiqiu Shen,Chen Zhao,Arman Cohan,Dennis Shasha*

Main category: cs.AI

TL;DR: 提出了PuzzlePlex基准测试，用于评估基础模型在复杂动态环境中的推理和规划能力，包含15种不同类型的谜题游戏，并分析了前沿模型在指令式和代码式两种设置下的表现。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型在复杂动态环境中的推理和规划能力及其可扩展性，需要设计一个全面的基准测试来评估这些能力。

Method: 开发了PuzzlePlex基准测试框架，包含15种不同类型的谜题游戏（包括确定性和随机性游戏、单人和双人场景），提供定制化游戏策略进行比较，并设计了细粒度性能指标。在指令式和代码式两种设置下对前沿基础模型进行深入分析。

Result: 推理模型在指令式设置中表现优于其他模型，而基于代码的执行虽然更具挑战性，但提供了可扩展且高效的替代方案。

Conclusion: PuzzlePlex能够进行针对性评估，并指导基础模型在推理、规划和泛化方面的未来改进。

Abstract: This work investigates the reasoning and planning capabilities of foundation
models and their scalability in complex, dynamic environments. We introduce
PuzzlePlex, a benchmark designed to assess these capabilities through a diverse
set of puzzles. PuzzlePlex consists of 15 types of puzzles, including
deterministic and stochastic games of varying difficulty, as well as
single-player and two-player scenarios. The PuzzlePlex framework provides a
comprehensive environment for each game, and supports extensibility to generate
more challenging instances as foundation models evolve. Additionally, we
implement customized game-playing strategies for comparison. Building on this
benchmark, we develop fine-grained metrics to measure performance and conduct
an in-depth analysis of frontier foundation models across two settings:
instruction-based and code-based. Furthermore, we systematically investigate
their scaling limits. Our findings show that reasoning models outperform others
in instruction-based settings, while code-based execution presents greater
challenges but offers a scalable and efficient alternative. PuzzlePlex enables
targeted evaluation and guides future improvements in reasoning, planning, and
generalization for foundation models.

</details>


### [12] [Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them](https://arxiv.org/abs/2510.06534)
*Jiahe Jin,Abhijay Paladugu,Chenyan Xiong*

Main category: cs.AI

TL;DR: 提出了一种名为行为引导（Behavior Priming）的技术，通过识别四种有益推理行为（信息验证、权威评估、自适应搜索、错误恢复）来训练更有效的代理搜索模型，在三个基准测试中相比直接RL训练获得超过35%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 代理搜索利用LLM解释复杂用户信息需求，通过多步骤规划、搜索和合成信息来提供答案，这对LLM的推理和代理能力提出了独特挑战。

Method: 提出推理驱动的LLM管道分析成功代理搜索轨迹，识别四种有益推理行为，然后通过行为引导技术合成展现这些行为的轨迹，通过监督微调（SFT）和强化学习（RL）集成到模型中。

Result: 在Llama3.2-3B和Qwen3-1.7B上，行为引导相比直接RL训练获得超过35%的性能提升。SFT数据中期望的推理行为比最终答案的正确性对RL后性能更关键。

Conclusion: 引入的推理行为赋予模型更有效的探索能力和测试时扩展能力，为RL提供了坚实基础。期望推理行为而非答案正确性是实现强最终性能的关键因素。

Abstract: Agentic search leverages large language models (LLMs) to interpret complex
user information needs and execute a multi-step process of planning, searching,
and synthesizing information to provide answers. This paradigm introduces
unique challenges for LLMs' reasoning and agentic capabilities when interacting
with retrieval systems and the broader web. In this paper, we propose a
reasoning-driven LLM-based pipeline to study effective reasoning behavior
patterns in agentic search. Using this pipeline, we analyze successful agentic
search trajectories and identify four beneficial reasoning behaviors:
Information Verification, Authority Evaluation, Adaptive Search, and Error
Recovery. Based on these findings, we propose a technique called Behavior
Priming to train more effective agentic search models. It synthesizes agentic
search trajectories that exhibit these four behaviors and integrates them into
the agentic search model through supervised fine-tuning (SFT), followed by
standard reinforcement learning (RL). Experiments on three benchmarks (GAIA,
WebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in
Llama3.2-3B and Qwen3-1.7B compared to directly training agentic search models
with RL. Crucially, we demonstrate that the desired reasoning behaviors in the
SFT data, rather than the correctness of the final answer, is the critical
factor for achieving strong final performance after RL: fine-tuning on
trajectories with desirable reasoning behaviors but incorrect answers leads to
better performance than fine-tuning on trajectories with correct answers. Our
analysis further reveals the underlying mechanism: the introduced reasoning
behaviors endow models with more effective exploration (higher pass@k and
entropy) and test-time scaling (longer trajectories) capabilities, providing a
strong foundation for RL. Our code will be released as open source.

</details>


### [13] [Auto-Prompt Ensemble for LLM Judge](https://arxiv.org/abs/2510.06538)
*Jiajie Li,Huayi Zhang,Peng Lin,Jinjun Xiong,Wei Xu*

Main category: cs.AI

TL;DR: 提出Auto-Prompt Ensemble (APE)框架，通过自动学习评估维度来提升LLM评判者的可靠性，在Reward Bench上将GPT-4o的零样本一致性从87.2%提升至90.5%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评判者经常遗漏关键评估维度，因为它们无法识别人类评估背后的隐含标准，导致评估可靠性不足。

Method: 提出APE自适应框架，自动从失败案例中学习评估维度，并采用基于置信度的集成机制（Collective Confidence）来决定何时采纳额外评估维度的判断。

Result: 在多个标准基准测试中，APE显著提升了LLM评判者的可靠性，特别是在Reward Bench上GPT-4o的零样本一致性提升了3.3个百分点。

Conclusion: APE为LLM评判者提供了利用测试时计算的原理性方法，弥合了人类与LLM评判者之间的评估差距。

Abstract: We present a novel framework that improves the reliability of LLM judges by
selectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM
judges often miss crucial evaluation dimensions because they fail to recognize
the implicit standards underlying human assessments. To address this challenge,
we propose the Auto-Prompt Ensemble (APE), an adaptive framework that
automatically learns evaluation dimensions from its failure cases. APE
incorporates a confidence-based ensemble mechanism to decide when to adopt the
judgments from additional evaluation dimensions through a novel confidence
estimation approach called Collective Confidence. Extensive experiments
demonstrate that APE improves the reliability of LLM Judge across diverse
standard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward
Bench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a
principled approach for LLM Judge to leverage test-time computation, and bridge
the evaluation gap between human and LLM judges.

</details>


### [14] [WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks](https://arxiv.org/abs/2510.06587)
*Jingbo Yang,Bairu Hou,Wei Wei,Shiyu Chang,Yujia Bao*

Main category: cs.AI

TL;DR: WebDART是一个LLM代理框架，通过动态分解任务为导航、信息提取和执行三个子任务，并持续重新规划，显著提升了复杂网页任务的完成成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在简单网页任务上表现良好，但在需要长时程导航、大规模信息提取和约束条件下推理的复杂任务中仍存在困难。

Method: 将目标动态分解为三个专注子任务（导航、信息提取、执行），并在发现新网页时持续重新规划分解策略。

Result: 在WebChoreArena上比之前SOTA代理提升13.7个百分点的成功率，在WebArena上保持同等性能，且导航步骤减少最多14.7步。

Conclusion: WebDART框架通过任务分解和动态重规划，有效提升了LLM代理处理复杂网页任务的能力。

Abstract: Large language model (LLM) agents are becoming competent at straightforward
web tasks, such as opening an item page or submitting a form, but still
struggle with objectives that require long horizon navigation, large scale
information extraction, and reasoning under constraints. We present WebDART, a
general framework that enables a single LLM to handle such complex chores.
WebDART (i) dynamically decomposes each objective into three focused subtasks:
navigation, information extraction, and execution, so the model concentrates on
one skill at a time, and (ii) continuously replans the decomposition as new
webpages are revealed, taking advantage of newly discovered filters or
shortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,
WebDART lifts success rates by up to 13.7 percentage points over previous SOTA
agents, while matching their performance on the easier WebArena suite and
completing tasks with up to 14.7 fewer navigation steps.

</details>


### [15] [Fine-Grained Emotion Recognition via In-Context Learning](https://arxiv.org/abs/2510.06600)
*Zhaochun Ren,Zhou Yang,Chenglong Ye,Haizhou Sun,Chao Chen,Xiaofei Zhu,Xiangwen Liao*

Main category: cs.AI

TL;DR: 该论文提出EICL方法，通过引入情感相似示例和动态软标签策略来改进细粒度情感识别中的决策过程，显著优于传统的ICL方法。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法虽然增强了情感识别的推理过程，但忽视了决策过程，且语义相似示例可能引入情感差异，导致识别错误。

Method: 提出EICL方法：1）引入情感相似示例；2）使用动态软标签策略改进查询表示；3）采用两阶段排除策略从多角度评估相似性。

Result: 在多个数据集上的广泛实验表明，EICL方法显著优于ICL方法。

Conclusion: 通过原型理论改进决策过程，EICL能够更准确地识别细粒度情感，解决了ICL方法中情感差异导致的问题。

Abstract: Fine-grained emotion recognition aims to identify the emotional type in
queries through reasoning and decision-making processes, playing a crucial role
in various systems. Recent methods use In-Context Learning (ICL), enhancing the
representation of queries in the reasoning process through semantically similar
examples, while further improving emotion recognition by explaining the
reasoning mechanisms. However, these methods enhance the reasoning process but
overlook the decision-making process. This paper investigates decision-making
in fine-grained emotion recognition through prototype theory. We show that ICL
relies on similarity matching between query representations and emotional
prototypes within the model, where emotion-accurate representations are
critical. However, semantically similar examples often introduce emotional
discrepancies, hindering accurate representations and causing errors. To
address this, we propose Emotion In-Context Learning (EICL), which introduces
emotionally similar examples and uses a dynamic soft-label strategy to improve
query representations in the emotion reasoning process. A two-stage exclusion
strategy is then employed to assess similarity from multiple angles, further
optimizing the decision-making process. Extensive experiments show that EICL
significantly outperforms ICL on multiple datasets.

</details>


### [16] [Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support](https://arxiv.org/abs/2510.06674)
*Cen,Zhao,Tiantian Zhang,Hanchen Su,Yufeng,Zhang,Shaowei Su,Mingzhi Xu,Yu,Liu,Wei Han,Jeremy Werner,Claire Na Cheng,Yashar Mehdad*

Main category: cs.AI

TL;DR: 提出了一个Agent-in-the-Loop框架，通过实时集成四种类型的标注反馈来持续改进基于LLM的客户支持系统，将重新训练周期从数月缩短到数周。


<details>
  <summary>Details</summary>
Motivation: 传统的离线批量标注方法效率低下，无法快速响应系统改进需求，需要一种能够实时集成人类反馈到运营工作流中的方法。

Method: AITL框架在实时客户运营中直接集成四种关键标注类型：响应偏好对比、代理采纳与理由、知识相关性检查、缺失知识识别，这些反馈信号直接用于模型更新。

Result: 生产试点显示检索准确率显著提升（召回率+11.7%，精确率+14.8%），生成质量提高（帮助性+8.4%），代理采纳率增加（+4.5%）。

Conclusion: 将人类反馈循环直接嵌入运营工作流能有效持续改进基于LLM的客户支持系统。

Abstract: We introduce an Agent-in-the-Loop (AITL) framework that implements a
continuous data flywheel for iteratively improving an LLM-based customer
support system. Unlike standard offline approaches that rely on batch
annotations, AITL integrates four key types of annotations directly into live
customer operations: (1) pairwise response preferences, (2) agent adoption and
rationales, (3) knowledge relevance checks, and (4) identification of missing
knowledge. These feedback signals seamlessly feed back into models' updates,
reducing retraining cycles from months to weeks. Our production pilot involving
US-based customer support agents demonstrated significant improvements in
retrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality
(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore
the effectiveness of embedding human feedback loops directly into operational
workflows to continuously refine LLM-based customer support system.

</details>


### [17] [Inefficiencies of Meta Agents for Agent Design](https://arxiv.org/abs/2510.06711)
*Batu El,Mert Yuksekgonul,James Zou*

Main category: cs.AI

TL;DR: 本文分析了元代理在自动化设计智能体系统时面临的三个关键挑战：跨迭代学习效率、行为多样性不足以及经济可行性问题。


<details>
  <summary>Details</summary>
Motivation: 现有元代理方法在自动化设计智能体系统时存在效率问题，需要研究如何改进学习机制、提升行为多样性并评估经济可行性。

Method: 通过实验比较不同学习策略（扩展上下文vs忽略历史vs进化方法），分析行为多样性，并评估设计成本与性能收益的经济平衡。

Result: 进化方法优于简单扩展上下文；设计的智能体行为多样性低；仅在少数情况下自动化设计比人工设计更经济可行。

Conclusion: 当前元代理方法在经济可行性和行为多样性方面存在局限，需要更有效的学习机制和多样性增强策略。

Abstract: Recent works began to automate the design of agentic systems using
meta-agents that propose and iteratively refine new agent architectures. In
this paper, we examine three key challenges in a common class of meta-agents.
First, we investigate how a meta-agent learns across iterations and find that
simply expanding the context with all previous agents, as proposed by previous
works, performs worse than ignoring prior designs entirely. We show that the
performance improves with an evolutionary approach. Second, although the
meta-agent designs multiple agents during training, it typically commits to a
single agent at test time. We find that the designed agents have low behavioral
diversity, limiting the potential for their complementary use. Third, we assess
when automated design is economically viable. We find that only in a few
cases--specifically, two datasets--the overall cost of designing and deploying
the agents is lower than that of human-designed agents when deployed on over
15,000 examples. In contrast, the performance gains for other datasets do not
justify the design cost, regardless of scale.

</details>


### [18] [MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models](https://arxiv.org/abs/2510.06742)
*Ali Sarabadani,Kheirolah Rahsepar Fard*

Main category: cs.AI

TL;DR: MultiCNKG是一个融合认知神经科学知识图谱、基因本体和疾病本体的创新框架，利用大语言模型进行实体对齐和图增强，构建连接基因机制、神经疾病和认知功能的统一知识图谱。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在捕捉基因、疾病和认知过程之间复杂语义关系方面存在局限，需要整合多源知识来支持生物医学和认知科学的深入研究。

Method: 使用GPT-4等大语言模型进行实体对齐、语义相似度计算和图增强，整合CNKG、GO和DO三个知识源，构建包含6.9K节点和11.3K边的统一知识图谱。

Result: 评估显示精度85.20%、召回率87.30%、覆盖率92.18%、图一致性82.50%，链接预测任务中TransE和RotatE模型表现优于FB15k-237和WN18RR基准。

Conclusion: MultiCNKG为个性化医疗、认知障碍诊断和认知神经科学假说构建提供了强大的知识基础，推动了从分子到行为层面的多层级研究。

Abstract: The advent of large language models (LLMs) has revolutionized the integration
of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming
limitations in traditional machine learning methods for capturing intricate
semantic links among genes, diseases, and cognitive processes. We introduce
MultiCNKG, an innovative framework that merges three key knowledge sources: the
Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges
across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes
and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)
comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.
Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity
computation, and graph augmentation to create a cohesive KG that interconnects
genetic mechanisms, neurological disorders, and cognitive functions. The
resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,
Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,
Associated with, Regulates), facilitating a multi-layered view from molecular
to behavioral domains. Assessments using metrics such as precision (85.20%),
recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty
detection (40.28%), and expert validation (89.50%) affirm its robustness and
coherence. Link prediction evaluations with models like TransE (MR: 391, MRR:
0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against
benchmarks like FB15k-237 and WN18RR. This KG advances applications in
personalized medicine, cognitive disorder diagnostics, and hypothesis
formulation in cognitive neuroscience.

</details>


### [19] [Verifying Memoryless Sequential Decision-making of Large Language Models](https://arxiv.org/abs/2510.06756)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: 开发了一个自动化验证工具，用于验证基于大型语言模型(LLM)的策略在无记忆顺序决策任务中的安全性。该方法通过增量构建MDP的可达部分，使用LLM生成动作，并用Storm模型检查器验证PCTL安全属性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在顺序决策任务中的应用日益增多，需要一种严格的方法来验证这些基于LLM的策略是否满足安全要求，确保其在现实世界应用中的可靠性。

Method: 给定MDP、LLM策略和PCTL安全要求，增量构建MDP的可达部分：将状态编码为自然语言提示，解析LLM响应为动作，扩展策略可达的后继状态，最后用Storm模型检查器验证安全属性。

Result: 在标准网格世界基准测试中，通过Ollama访问的开源LLM在确定性种子设置下可以被验证，但通常表现不如深度强化学习基线方法。

Conclusion: 该工具与Ollama原生集成，支持PRISM指定任务，为正式验证日益强大的LLM奠定了实用基础，支持用户指定顺序决策任务的持续基准测试。

Abstract: We introduce a tool for rigorous and automated verification of large language
model (LLM)- based policies in memoryless sequential decision-making tasks.
Given a Markov decision process (MDP) representing the sequential
decision-making task, an LLM policy, and a safety requirement expressed as a
PCTL formula, our approach incrementally constructs only the reachable portion
of the MDP guided by the LLM's chosen actions. Each state is encoded as a
natural language prompt, the LLM's response is parsed into an action, and
reachable successor states by the policy are expanded. The resulting formal
model is checked with Storm to determine whether the policy satisfies the
specified safety property. In experiments on standard grid world benchmarks, we
show that open source LLMs accessed via Ollama can be verified when
deterministically seeded, but generally underperform deep reinforcement
learning baselines. Our tool natively integrates with Ollama and supports
PRISM-specified tasks, enabling continuous benchmarking in user-specified
sequential decision-making tasks and laying a practical foundation for formally
verifying increasingly capable LLMs.

</details>


### [20] [Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration](https://arxiv.org/abs/2510.06761)
*Zhi Zhang,Yan Liu,Zhejing Hu,Gong Chen,Sheng-hua Zhong,Jiannong Cao*

Main category: cs.AI

TL;DR: 提出双循环多智能体(DLMA)框架，通过教授智能体演化研究计划，博士生智能体执行计划，实现自动化科学研究。


<details>
  <summary>Details</summary>
Motivation: 自动化端到端科学研究面临双重挑战：需要生成新颖且合理的高层计划，并在动态不确定条件下正确执行这些计划。

Method: 采用双循环结构：领导循环(教授智能体)使用进化算法通过参与、改进和整合会议演化研究计划；跟随循环(博士生智能体)通过事前和事后会议动态调整计划执行。

Result: 在ACLAward和Laboratory基准测试中，DLMA生成的研究论文在自动评估中获得最先进分数，显著优于强基线方法。

Conclusion: 消融研究证实两个循环都至关重要，进化驱动新颖性，执行确保合理性。

Abstract: Automating the end-to-end scientific research process poses a fundamental
challenge: it requires both evolving high-level plans that are novel and sound,
and executing these plans correctly amidst dynamic and uncertain conditions. To
address this bilevel challenge, we propose a novel Double-Loop Multi-Agent
(DLMA) framework to solve the given research problem automatically. The leader
loop, composed of professor agents, is responsible for evolving research plans.
It employs an evolutionary algorithm through involvement, improvement, and
integration meetings to iteratively generate and refine a pool of research
proposals, exploring the solution space effectively. The follower loop,
composed of doctoral student agents, is responsible for executing the
best-evolved plan. It dynamically adjusts the plan during implementation via
pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is
well-supported by contextual and external observations. Extensive experiments
on benchmarks like ACLAward and Laboratory show that DLMA generates research
papers that achieve state-of-the-art scores in automated evaluation,
significantly outperforming strong baselines. Ablation studies confirm the
critical roles of both loops, with evolution driving novelty and execution
ensuring soundness.

</details>


### [21] [Autoformalizer with Tool Feedback](https://arxiv.org/abs/2510.06857)
*Qi Guo,Jianing Wang,Jianfei Zhang,Deyang Kong,Xiangzhou Huang,Xiangyu Xi,Wei Wang,Jingang Wang,Xunliang Cai,Shikun Zhang,Wei Ye*

Main category: cs.AI

TL;DR: 提出ATF方法，通过集成语法检查和一致性验证工具反馈来改进自动形式化，显著提升形式化语句的语法有效性和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有形式化方法难以持续生成满足语法有效性和语义一致性的有效语句，需要改进自动形式化的质量。

Method: ATF方法整合Lean 4编译器进行语法校正，采用多LLMs作为评判者进行一致性验证，通过工具反馈自适应优化生成语句。训练包括冷启动阶段、专家迭代阶段和直接偏好优化。

Result: ATF显著优于基线形式化模型，在人类评估中表现优异，并展现出良好的推理扩展特性。开源了包含75万条合成形式化语句的Numina-ATF数据集。

Conclusion: ATF通过工具反馈机制有效提升了自动形式化的质量，为自动定理证明研究提供了重要贡献。

Abstract: Autoformalization addresses the scarcity of data for Automated Theorem
Proving (ATP) by translating mathematical problems from natural language into
formal statements. Efforts in recent work shift from directly prompting large
language models to training an end-to-end formalizer model from scratch,
achieving remarkable advancements. However, existing formalizer still struggles
to consistently generate valid statements that meet syntactic validity and
semantic consistency. To address this issue, we propose the Autoformalizer with
Tool Feedback (ATF), a novel approach that incorporates syntactic and
consistency information as tools into the formalization process. By integrating
Lean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge
approach for consistency validation, the model is able to adaptively refine
generated statements according to the tool feedback, enhancing both syntactic
validity and semantic consistency. The training of ATF involves a cold-start
phase on synthetic tool-calling data, an expert iteration phase to improve
formalization capabilities, and Direct Preference Optimization to alleviate
ineffective revisions. Experimental results show that ATF markedly outperforms
a range of baseline formalizer models, with its superior performance further
validated by human evaluations. Subsequent analysis reveals that ATF
demonstrates excellent inference scaling properties. Moreover, we open-source
Numina-ATF, a dataset containing 750K synthetic formal statements to facilitate
advancements in autoformalization and ATP research.

</details>


### [22] [TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs](https://arxiv.org/abs/2510.06878)
*Daria Ozerova,Ekaterina Trofimova*

Main category: cs.AI

TL;DR: TGPR框架结合GRPO与汤普森采样树搜索，通过主动探索失败和成功的精炼路径，在代码调试任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有迭代精炼方法依赖预定义启发式，面临探索-利用困境且无法根据过往精炼结果自适应调整

Method: 结合GRPO与基于汤普森采样的树搜索，主动探索失败和成功的精炼路径，生成更密集的训练轨迹和自适应策略

Result: 在HumanEval、MBPP和APPS基准测试中，相比GRPO基线，pass@1最高提升4.2个百分点(MBPP)，pass@10最高提升12.51个百分点(APPS)

Conclusion: TGPR为结合学习策略与结构化搜索方法提供了原则性方法，是增强LLMs迭代精炼和状态推理的通用框架

Abstract: Iterative refinement has been a promising paradigm to enable large language
models (LLMs) to resolve difficult reasoning and problem-solving tasks. One of
the key challenges, however, is how to effectively search through the enormous
search space of possible refinements. Existing methods typically fall back on
predefined heuristics, which are troubled by the exploration-exploitation
dilemma and cannot adapt based on past refinement outcomes. We introduce
Tree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with
a Thompson-Sampling-based tree search. TGPR explores both failed and successful
refinement paths actively, with denser training trajectories and more adaptive
policies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to
+4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to
+12.51 percentage points absolute improvement in pass@10 (on APPS) compared to
a competitive GRPO baseline. Apart from debugging code, TGPR focuses on a
principled approach to combining learned policies with structured search
methods, offering a general framework for enhancing iterative refinement and
stateful reasoning in LLMs.

</details>


### [23] [LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN](https://arxiv.org/abs/2510.06911)
*Hacane Hechehouche,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: 提出了一个集成开发环境来解决AJAN框架中RDF/RDFS和SPARQL建模的困难，并利用大语言模型扩展用户群体。


<details>
  <summary>Details</summary>
Motivation: AJAN框架虽然基于语义Web标准构建多智能体系统，但RDF/RDFS和SPARQL的行为定义在实践中存在困难，如URI处理容易出错、复杂SPARQL查询学习曲线高等问题。

Method: 开发了一个集成开发环境，通过利用大语言模型来简化AJAN智能体的建模过程。

Result: 该环境降低了AJAN智能体建模的技术门槛，使更多用户能够参与智能体工程。

Conclusion: 集成开发环境结合大语言模型能够有效解决AJAN框架中的建模障碍，扩展了用户群体并提升了开发效率。

Abstract: There are many established semantic Web standards for implementing
multi-agent driven applications. The AJAN framework allows to engineer
multi-agent systems based on these standards. In particular, agent knowledge is
represented in RDF/RDFS and OWL, while agent behavior models are defined with
Behavior Trees and SPARQL to access and manipulate this knowledge. However, the
appropriate definition of RDF/RDFS and SPARQL-based agent behaviors still
remains a major hurdle not only for agent modelers in practice. For example,
dealing with URIs is very error-prone regarding typos and dealing with complex
SPARQL queries in large-scale environments requires a high learning curve. In
this paper, we present an integrated development environment to overcome such
hurdles of modeling AJAN agents and at the same time to extend the user
community for AJAN by the possibility to leverage Large Language Models for
agent engineering.

</details>


### [24] [Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.06953)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.AI

TL;DR: 该研究验证了统一信息密度(UID)假设在大型语言模型推理轨迹中的应用，发现步骤级信息密度均匀性可以预测推理质量，并提出了局部和全局均匀性评分方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索统一信息密度假设是否适用于LLM推理轨迹，以及步骤级信息密度均匀性是否能反映推理质量。

Method: 提出了基于熵的步骤信息密度度量方法，并引入了局部和全局均匀性评分两种互补的均匀性衡量指标。

Result: 在六个推理基准测试中，步骤级信息密度均匀性不仅提供了理论视角，还带来了实际性能提升：选择信息密度更均匀的推理轨迹在AIME2025上相对基线提高了10-32%的准确率。正确推理轨迹避免信息密度尖峰，错误轨迹则表现出不规则的信息爆发。

Conclusion: UID启发的信息密度度量优于其他内部信号作为推理质量预测指标，信息密度均匀性是构建更可靠准确推理系统的稳健诊断和选择标准。

Abstract: The Uniform Information Density (UID) hypothesis suggests that effective
communication maintains a stable flow of information. In this work, we revisit
this principle in the context of large language model (LLM) reasoning traces,
asking whether step-level uniformity reflects reasoning quality. To this end,
we propose an entropy-based stepwise information density metric and introduce
two complementary measures of uniformity, local and global uniformity scores.
Across the experiments on six different reasoning benchmarks, we find that
step-level uniformity not only provides a strong theoretical lens but also
yields practical performance benefits; for example, selecting reasoning traces
with more uniform information density at the step-level improves accuracy by
10-32\% relative gains over baselines at AIME2025. Our analysis further reveals
that correct reasoning traces tend to avoid sharp information density spikes,
while incorrect traces exhibit irregular information bursts. These results
demonstrate that UID-inspired information density measures outperform
alternative internal signals as predictors of reasoning quality. Results
highlight the uniformity of the information density as a robust diagnostic and
selection criterion for building more reliable and accurate reasoning systems.

</details>


### [25] [Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning](https://arxiv.org/abs/2510.07038)
*Wenxun Wu,Yuanyang Li,Guhan Chen,Linyue Wang,Hongyang Chen*

Main category: cs.AI

TL;DR: 提出了TAPO框架，通过强化学习将多跳推理与自适应工具调用能力相结合，在知识密集型和计算密集型任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在需要最新知识或计算工具（如计算器、代码解释器）的复杂算术运算任务上表现不佳，需要系统性地整合推理与工具调用能力。

Method: 基于改进的DAPO强化学习框架，专门针对工具调用场景进行适配，使模型能够动态交织复杂推理与按需工具使用（包括搜索API和Python解释器）。

Result: 在Qwen2.5-3B和Qwen2.5-7B模型上的实验显示，该方法在需要外部知识和数学计算的任务上达到了可比参数方法中的最先进性能，且工具使用效率更高。

Conclusion: 结合高级推理与工具使用在知识密集型和计算密集型任务中具有显著潜力，能够有效提升模型性能。

Abstract: Recent advances in large language models (LLMs) have popularized test-time
scaling, where models generate additional reasoning tokens before producing
final answers. These approaches have demonstrated significant performance
improvements on benchmarks involving mathematical reasoning. However, language
models relying solely on direct inference still struggle with tasks demanding
up-to-date knowledge or computational tools such as calculators and code
interpreters for complex arithmetic operations. To overcome these limitations,
we propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement
learning framework that systematically integrates multi-hop reasoning with
adaptive tool-calling capabilities. Our approach employs a modified version of
Dynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,
which we adapt specifically for tool invocation scenarios, enabling models to
dynamically interleave complex reasoning with on-demand tool usage (including
search APIs and Python interpreters).
  To support this research, we introduce two new datasets: TAPO-easy-60K and
TAPO-hard-18K, specifically designed to train and evaluate both fact-based
reasoning and mathematical calculation capabilities. Our experiments on
Qwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,
with both models achieving state-of-the-art performance on tasks requiring
external knowledge and mathematical computation among methods with comparable
parameters. Notably, TAPO achieves more efficient tool utilization than
baseline methods while preventing excessive calls caused by reward hacking.
These results highlight the significant potential of combining advanced
reasoning with tool usage to enhance model performance in knowledge-intensive
and computationally demanding tasks.

</details>


### [26] [Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations](https://arxiv.org/abs/2510.07064)
*Manh Hung Nguyen,Sebastian Tschiatschek,Adish Singla*

Main category: cs.AI

TL;DR: 提出了一种新的框架，通过构建一组LLM代理来集体捕捉人类群体的多样性，而不是使用单一LLM代理。


<details>
  <summary>Details</summary>
Motivation: 获取大规模人类响应既困难又昂贵，而现有LLM往往产生同质化输出，无法捕捉人类观点和行为的丰富多样性。

Method: 通过上下文学习，为每个LLM代理提供少量人类演示（任务-响应对）来引导其行为，并使用子模优化方法从指数级大的可能代理空间中选择代表性代理集。

Result: 在众包和教育领域的广泛实验表明，该方法构建的代理比基线方法更有效地代表人类群体，并在新任务上重现了目标群体的行为模式和观点。

Conclusion: 该框架成功解决了LLM代理多样性不足的问题，能够更准确地代表人类群体的行为特征和观点多样性。

Abstract: The difficulty and expense of obtaining large-scale human responses make
Large Language Models (LLMs) an attractive alternative and a promising proxy
for human behavior. However, prior work shows that LLMs often produce
homogeneous outputs that fail to capture the rich diversity of human
perspectives and behaviors. Thus, rather than trying to capture this diversity
with a single LLM agent, we propose a novel framework to construct a set of
agents that collectively capture the diversity of a given human population.
Each agent is an LLM whose behavior is steered by conditioning on a small set
of human demonstrations (task-response pairs) through in-context learning. The
central challenge is therefore to select a representative set of LLM agents
from the exponentially large space of possible agents. We tackle this selection
problem from the lens of submodular optimization. In particular, we develop
methods that offer different trade-offs regarding time complexity and
performance guarantees. Extensive experiments in crowdsourcing and educational
domains demonstrate that our approach constructs agents that more effectively
represent human populations compared to baselines. Moreover, behavioral
analyses on new tasks show that these agents reproduce the behavior patterns
and perspectives of the students and annotators they are designed to represent.

</details>


### [27] [Inductive Learning for Possibilistic Logic Programs Under Stable Models](https://arxiv.org/abs/2510.07069)
*Hongbo Hu,Yisong Wang,Yi Huang,Kewen Wang*

Main category: cs.AI

TL;DR: 本文提出了从背景程序和示例中提取可能性逻辑程序的方法，定义了归纳任务概念并开发了ilpsm和ilpsmmin算法，实验表明在普通逻辑程序输入时性能优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 可能性逻辑程序在稳定模型下的归纳推理问题尚未被研究，需要开发从背景知识和示例中学习可能性逻辑程序的方法。

Method: 正式定义归纳任务概念，研究其性质，提出ilpsm和ilpsmmin两种计算归纳解的算法，并实现ilpsmmin原型系统。

Result: 当输入为普通逻辑程序时，原型系统在随机生成的数据集上优于基于稳定模型的正常逻辑程序主要归纳学习系统。

Conclusion: 本文首次研究了可能性逻辑程序的归纳推理问题，提出的方法在普通逻辑程序情况下表现出色，为可能性逻辑程序的学习提供了有效工具。

Abstract: Possibilistic logic programs (poss-programs) under stable models are a major
variant of answer set programming (ASP). While its semantics (possibilistic
stable models) and properties have been well investigated, the problem of
inductive reasoning has not been investigated yet. This paper presents an
approach to extracting poss-programs from a background program and examples
(parts of intended possibilistic stable models). To this end, the notion of
induction tasks is first formally defined, its properties are investigated and
two algorithms ilpsm and ilpsmmin for computing induction solutions are
presented. An implementation of ilpsmmin is also provided and experimental
results show that when inputs are ordinary logic programs, the prototype
outperforms a major inductive learning system for normal logic programs from
stable models on the datasets that are randomly generated.

</details>


### [28] [VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems](https://arxiv.org/abs/2510.07073)
*André Hottung,Federico Berto,Chuanbo Hua,Nayeli Gast Zepeda,Daniel Wetzel,Michael Römer,Haoran Ye,Davide Zago,Michael Poli,Stefano Massaroli,Jinkyoo Park,Kevin Tierney*

Main category: cs.AI

TL;DR: VRPAgent是一个将LLM生成的组件集成到元启发式算法中的框架，通过遗传搜索优化这些组件，在多个VRP问题上超越了人工设计的启发式方法和基于学习的方法。


<details>
  <summary>Details</summary>
Motivation: 设计高性能的VRP启发式算法需要深厚的领域知识，而现有的LLM代码生成方法还无法产生能与人类专家相媲美的启发式算法。

Method: 使用LLM生成问题特定的算子，将其嵌入到通用的元启发式框架中，并通过新颖的遗传搜索进行优化，确保任务可控性和正确性。

Result: 在容量约束VRP、时间窗口VRP和奖励收集VRP等多个问题上，VRPAgent发现的启发式算子超越了手工方法和近期基于学习的方法，且仅需单核CPU。

Conclusion: VRPAgent是首个在VRP领域推进最先进技术的LLM范式，为自动化启发式发现展示了有前景的未来。

Abstract: Designing high-performing heuristics for vehicle routing problems (VRPs) is a
complex task that requires both intuition and deep domain knowledge. Large
language model (LLM)-based code generation has recently shown promise across
many domains, but it still falls short of producing heuristics that rival those
crafted by human experts. In this paper, we propose VRPAgent, a framework that
integrates LLM-generated components into a metaheuristic and refines them
through a novel genetic search. By using the LLM to generate problem-specific
operators, embedded within a generic metaheuristic framework, VRPAgent keeps
tasks manageable, guarantees correctness, and still enables the discovery of
novel and powerful strategies. Across multiple problems, including the
capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our
method discovers heuristic operators that outperform handcrafted methods and
recent learning-based approaches while requiring only a single CPU core. To our
knowledge, \VRPAgent is the first LLM-based paradigm to advance the
state-of-the-art in VRPs, highlighting a promising future for automated
heuristics discovery.

</details>


### [29] [The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas](https://arxiv.org/abs/2510.07091)
*Baixuan Xu,Tianshi Zheng,Zhaowei Wang,Hong Ting Tsang,Weiqi Wang,Tianqing Fang,Yangqiu Song*

Main category: cs.AI

TL;DR: 本文系统研究了两种动作表示方法在长视野任务中的有效性：基于动作的规划(PwA)和基于模式的规划(PwS)，发现在动作空间规模扩大时存在表示选择拐点，并分析了模型能力对此拐点的影响。


<details>
  <summary>Details</summary>
Motivation: 传统基于动作的规划方法在组合爆炸的动作空间（如开放世界）中不实用，需要寻找最优的动作表示方法来支持长视野智能体的有效运作。

Method: 比较两种动作表示：PwA（提供可执行动作列表）和PwS（将动作模式实例化为动作列表），提出认知带宽视角作为概念框架，并在ALFWorld和SciWorld环境中进行实证研究。

Result: 在ALFWorld（约35个动作）和SciWorld（约500个动作）之间观察到表示选择拐点，更强的规划能力使拐点右移，更好的模式实例化能力使拐点左移。

Conclusion: 需要可扩展的动作表示方法，PwS在动作空间扩大时表现更优，但当前PwS智能体性能仍有改进空间，提供了构建更强大PwS智能体的实用指南。

Abstract: Enabling LLMs to effectively operate long-horizon task which requires
long-term planning and multiple interactions is essential for open-world
autonomy. Conventional methods adopt planning with actions where a executable
action list would be provided as reference. However, this action representation
choice would be impractical when the environment action space is combinatorial
exploded (e.g., open-ended real world). This naturally leads to a question: As
environmental action space scales, what is the optimal action representation
for long-horizon agents? In this paper, we systematically study the
effectiveness of two different action representations. The first one is
conventional planning with actions (PwA) which is predominantly adopted for its
effectiveness on existing benchmarks. The other one is planning with schemas
(PwS) which instantiate an action schema into action lists (e.g., "move [OBJ]
to [OBJ]" -> "move apple to desk") to ensure concise action space and reliable
scalability. This alternative is motivated by its alignment with human
cognition and its compliance with environment-imposed action format
restriction. We propose cognitive bandwidth perspective as a conceptual
framework to qualitatively understand the differences between these two action
representations and empirically observe a representation-choice inflection
point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve
as evidence of the need for scalable representations. We further conduct
controlled experiments to study how the location of this inflection point
interacts with different model capacities: stronger planning proficiency shifts
the inflection rightward, whereas better schema instantiation shifts it
leftward. Finally, noting the suboptimal performance of PwS agents, we provide
an actionable guide for building more capable PwS agents for better scalable
autonomy.

</details>


### [30] [The Contingencies of Physical Embodiment Allow for Open-Endedness and Care](https://arxiv.org/abs/2510.07117)
*Leonardo Christov-Moore,Arthur Juliani,Alex Kiefer,Nicco Reggente,B. Scott Rousse,Adam Safron,Nicol'as Hinrichs,Daniel Polani,Antonio Damasio*

Main category: cs.AI

TL;DR: 该论文从存在主义现象学角度定义了物理具身的两个基本条件：在世存在和向死而生，并基于此提出了稳态驱动力和内在驱动力，旨在开发更鲁棒、自适应和关怀的人工智能体。


<details>
  <summary>Details</summary>
Motivation: 理解生物体在开放物理世界中生存、繁衍和相互关怀的能力与人工代理之间的差距，通过存在主义哲学概念来开发更具适应性和关怀能力的人工智能。

Method: 基于海德格尔的存在主义现象学定义了两个物理具身条件，结合尼采的权力意志概念，在强化学习框架中形式化这些概念，研究内在驱动的具身代理如何在开放多代理环境中学习。

Result: 提出了从基本物理具身条件推导出稳态驱动力和内在驱动力的理论框架，使代理能够增强维持物理完整性的能力。

Conclusion: 通过存在主义哲学启发的物理具身条件，可以开发出具有开放性和关怀能力的人工智能体，弥合生物与人工代理之间的适应能力差距。

Abstract: Physical vulnerability and mortality are often seen as obstacles to be
avoided in the development of artificial agents, which struggle to adapt to
open-ended environments and provide aligned care. Meanwhile, biological
organisms survive, thrive, and care for each other in an open-ended physical
world with relative ease and efficiency. Understanding the role of the
conditions of life in this disparity can aid in developing more robust,
adaptive, and caring artificial agents. Here we define two minimal conditions
for physical embodiment inspired by the existentialist phenomenology of Martin
Heidegger: being-in-the-world (the agent is a part of the environment) and
being-towards-death (unless counteracted, the agent drifts toward terminal
states due to the second law of thermodynamics). We propose that from these
conditions we can obtain both a homeostatic drive - aimed at maintaining
integrity and avoiding death by expending energy to learn and act - and an
intrinsic drive to continue to do so in as many ways as possible. Drawing
inspiration from Friedrich Nietzsche's existentialist concept of will-to-power,
we examine how intrinsic drives to maximize control over future states, e.g.,
empowerment, allow agents to increase the probability that they will be able to
meet their future homeostatic needs, thereby enhancing their capacity to
maintain physical integrity. We formalize these concepts within a reinforcement
learning framework, which enables us to examine how intrinsically driven
embodied agents learning in open-ended multi-agent environments may cultivate
the capacities for open-endedness and care.ov

</details>


### [31] [Integrating Domain Knowledge into Process Discovery Using Large Language Models](https://arxiv.org/abs/2510.07161)
*Ali Norouzifar,Humam Kourani,Marcus Dees,Wil van der Aalst*

Main category: cs.AI

TL;DR: 提出了一种交互式流程挖掘框架，利用大语言模型从自然语言描述中提取声明性规则，结合事件日志数据指导流程模型发现，解决传统方法忽略领域知识的问题。


<details>
  <summary>Details</summary>
Motivation: 传统流程发现方法仅基于事件日志，但事件数据往往不完整或包含噪声，且忽略了领域知识这一重要补充资源，导致发现的模型对下游任务缺乏可靠性。

Method: 开发交互式框架，使用LLM从领域专家的自然语言描述中提取声明性规则，结合IMr发现算法递归构建流程模型，协调LLM、领域专家和后端服务之间的交互。

Result: 实现了完整工具支持该工作流，通过多LLM和提示工程策略的广泛评估，包括基于真实事件日志的案例研究，领域专家评估了框架的可用性和有效性。

Conclusion: 该框架成功将领域知识整合到流程发现中，通过LLM提取规则指导模型构建，避免了与领域知识相矛盾的问题流程结构，提高了流程模型的可靠性。

Abstract: Process discovery aims to derive process models from event logs, providing
insights into operational behavior and forming a foundation for conformance
checking and process improvement. However, models derived solely from event
data may not accurately reflect the real process, as event logs are often
incomplete or affected by noise, and domain knowledge, an important
complementary resource, is typically disregarded. As a result, the discovered
models may lack reliability for downstream tasks. We propose an interactive
framework that incorporates domain knowledge, expressed in natural language,
into the process discovery pipeline using Large Language Models (LLMs). Our
approach leverages LLMs to extract declarative rules from textual descriptions
provided by domain experts. These rules are used to guide the IMr discovery
algorithm, which recursively constructs process models by combining insights
from both the event log and the extracted rules, helping to avoid problematic
process structures that contradict domain knowledge. The framework coordinates
interactions among the LLM, domain experts, and a set of backend services. We
present a fully implemented tool that supports this workflow and conduct an
extensive evaluation of multiple LLMs and prompt engineering strategies. Our
empirical study includes a case study based on a real-life event log with the
involvement of domain experts, who assessed the usability and effectiveness of
the framework.

</details>


### [32] [NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents](https://arxiv.org/abs/2510.07172)
*Tianshi Zheng,Kelvin Kiu-Wai Tam,Newt Hue-Nam K. Nguyen,Baixuan Xu,Zhaowei Wang,Jiayang Cheng,Hong Ting Tsang,Weiqi Wang,Jiaxin Bai,Tianqing Fang,Yangqiu Song,Ginny Y. Wong,Simon See*

Main category: cs.AI

TL;DR: 牛顿基准是一个包含324个科学定律发现任务的基准测试，通过元物理变换解决评估困境，将评估从静态函数拟合提升到交互式模型发现，揭示了前沿大语言模型在复杂系统中的发现能力存在脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现基准存在方法学困境，需要在科学相关性、可扩展性和抗记忆性之间权衡，且过度简化发现过程为静态函数拟合，未能捕捉真实的科学探索过程。

Method: 使用元物理变换（系统性地改变经典定律）生成大量问题，构建包含324个任务的基准，要求智能体通过实验探索模拟复杂系统来发现隐藏原理。

Result: 前沿LLM展现出清晰但脆弱的发现能力：随着系统复杂性增加，该能力急剧下降，且对观测噪声极其敏感。工具辅助存在悖论效应，可能阻碍更有能力的模型。

Conclusion: 在复杂交互环境中实现稳健、可泛化的发现仍是核心挑战，牛顿基准为衡量真实进展和开发下一代AI科学发现智能体提供了关键工具。

Abstract: Large language models are emerging as powerful tools for scientific law
discovery, a foundational challenge in AI-driven science. However, existing
benchmarks for this task suffer from a fundamental methodological trilemma,
forcing a trade-off between scientific relevance, scalability, and resistance
to memorization. Furthermore, they oversimplify discovery as static function
fitting, failing to capture the authentic scientific process of uncovering
embedded laws through the interactive exploration of complex model systems. To
address these critical gaps, we introduce NewtonBench, a benchmark comprising
324 scientific law discovery tasks across 12 physics domains. Our design
mitigates the evaluation trilemma by using metaphysical shifts - systematic
alterations of canonical laws - to generate a vast suite of problems that are
scalable, scientifically relevant, and memorization-resistant. Moreover, we
elevate the evaluation from static function fitting to interactive model
discovery, requiring agents to experimentally probe simulated complex systems
to uncover hidden principles. Our extensive experiment reveals a clear but
fragile capability for discovery in frontier LLMs: this ability degrades
precipitously with increasing system complexity and exhibits extreme
sensitivity to observational noise. Notably, we uncover a paradoxical effect of
tool assistance: providing a code interpreter can hinder more capable models by
inducing a premature shift from exploration to exploitation, causing them to
satisfice on suboptimal solutions. These results demonstrate that robust,
generalizable discovery in complex, interactive environments remains the core
challenge. By providing a scalable, robust, and scientifically authentic
testbed, NewtonBench offers a crucial tool for measuring true progress and
guiding the development of next-generation AI agents capable of genuine
scientific discovery.

</details>


### [33] [Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences](https://arxiv.org/abs/2510.07276)
*Pulkit Rustagi,Kyle Hollins Wray,Sandhya Saisubramanian*

Main category: cs.AI

TL;DR: 提出了一种基于词典序的多目标多智能体路径规划框架LCBS，直接计算符合词典序偏好的单一解，避免构建帕累托前沿，显著提升多目标情况下的规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有MO-MAPF算法通常通过计算帕累托前沿来生成无冲突路径，但无法显式优化用户定义的偏好，且在目标数量增加时扩展性差。

Method: 提出词典序框架和LCBS算法，将优先级感知的A*搜索与基于冲突的搜索相结合，直接根据目标偏好进行高效规划。

Result: LCBS能够计算最优解，并扩展到最多10个目标的情况，远超过现有MO-MAPF方法的限制。在标准和随机MAPF基准测试中，随着目标数量增加，成功率始终高于最先进基线方法。

Conclusion: LCBS通过词典序偏好直接优化，避免了帕累托前沿构建，在多目标多智能体路径规划中实现了更好的可扩展性和性能。

Abstract: Many real-world scenarios require multiple agents to coordinate in shared
environments, while balancing trade-offs between multiple, potentially
competing objectives. Current multi-objective multi-agent path finding
(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto
frontiers. They do not explicitly optimize for user-defined preferences, even
when the preferences are available, and scale poorly with the number of
objectives. We propose a lexicographic framework for modeling MO-MAPF, along
with an algorithm \textit{Lexicographic Conflict-Based Search} (LCBS) that
directly computes a single solution aligned with a lexicographic preference
over objectives. LCBS integrates a priority-aware low-level $A^*$ search with
conflict-based search, avoiding Pareto frontier construction and enabling
efficient planning guided by preference over objectives. We provide insights
into optimality and scalability, and empirically demonstrate that LCBS computes
optimal solutions while scaling to instances with up to ten objectives -- far
beyond the limits of existing MO-MAPF methods. Evaluations on standard and
randomized MAPF benchmarks show consistently higher success rates against
state-of-the-art baselines, especially with increasing number of objectives.

</details>


### [34] [Agentic generative AI for media content discovery at the national football league](https://arxiv.org/abs/2510.07297)
*Henry Wang,Md Sirajus Salekin,Jake Lee,Ross Claytor,Shinan Zhang,Michael Chi*

Main category: cs.AI

TL;DR: 本文介绍了一个基于生成式AI的智能工作流，帮助NFL媒体研究人员通过自然语言查询历史比赛片段，替代传统的筛选界面，准确率超过95%，查询时间从10分钟缩短到30秒。


<details>
  <summary>Details</summary>
Motivation: 传统的内容发现和管理方式效率低下，用户需要通过复杂的筛选界面查找相关视频内容。生成式AI为内容发现提供了新的可能性，能够通过自然语言交互简化查询流程。

Method: 采用基于生成式AI的智能工作流，将用户自然语言查询分解为元素并转换为底层数据库查询语言，通过精心设计的语义缓存技术提高准确性和响应速度。

Result: 系统实现了超过95%的准确率，将查找相关视频的平均时间从10分钟减少到30秒，显著提升了NFL的运营效率。

Conclusion: 生成式AI工作流能够有效提升媒体内容发现和管理的效率，让用户专注于创意内容制作和故事线开发，具有重要的实际应用价值。

Abstract: Generative AI has unlocked new possibilities in content discovery and
management. Through collaboration with the National Football League (NFL), we
demonstrate how a generative-AI based workflow enables media researchers and
analysts to query relevant historical plays using natural language rather than
traditional filter-and-click interfaces. The agentic workflow takes a user
query as input, breaks it into elements, and translates them into the
underlying database query language. Accuracy and latency are further improved
through carefully designed semantic caching. The solution achieves over 95
percent accuracy and reduces the average time to find relevant videos from 10
minutes to 30 seconds, significantly increasing the NFL's operational
efficiency and allowing users to focus on producing creative content and
engaging storylines.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [35] [A doubly composite Chernoff-Stein lemma and its applications](https://arxiv.org/abs/2510.06342)
*Ludovico Lami*

Main category: cs.IT

TL;DR: 本文建立了适用于复合假设和真正相关性的广义Chernoff-Stein引理，推广了经典结果，并应用于各种假设检验场景。


<details>
  <summary>Details</summary>
Motivation: 现有Chernoff-Stein引理主要适用于简单假设或非真正相关的复合假设，缺乏对复合且真正相关假设的通用理论框架。

Method: 使用符号级模糊技术，这是广义量子Stein引理中模糊技术的精细化版本，适用于缺乏置换对称性的情况。

Result: 得到了严格包含大多数先前工作的广义Chernoff-Stein引理，提供了单字母公式来描述Stein指数。

Conclusion: 建立了一个统一的理论框架，能够处理复合且真正相关的假设检验问题，并具有广泛的应用前景。

Abstract: Given a sequence of random variables $X^n=X_1,\ldots, X_n$, discriminating
between two hypotheses on the underlying probability distribution is a key task
in statistics and information theory. Of interest here is the Stein exponent,
i.e. the largest rate of decay (in $n$) of the type II error probability for a
vanishingly small type I error probability. When the hypotheses are simple and
i.i.d., the Chernoff-Stein lemma states that this is given by the relative
entropy between the single-copy probability distributions. Generalisations of
this result exist in the case of composite hypotheses, but mostly to settings
where the probability distribution of $X^n$ is not genuinely correlated, but
rather, e.g., a convex combination of product distributions with components
taken from a base set. Here, we establish a general Chernoff-Stein lemma that
applies to the setting where both hypotheses are composite and genuinely
correlated, satisfying only generic assumptions such as convexity (on both
hypotheses) and some weak form of permutational symmetry (on either
hypothesis). Our result, which strictly subsumes most prior work, is proved
using a refinement of the blurring technique developed in the context of the
generalised quantum Stein's lemma [Lami, IEEE Trans. Inf. Theory 2025]. In this
refined form, blurring is applied symbol by symbol, which makes it both
stronger and applicable also in the absence of permutational symmetry. The
second part of the work is devoted to applications: we provide a single-letter
formula for the Stein exponent characterising the discrimination of broad
families of null hypotheses vs a composite i.i.d. or an arbitrarily varying
alternative hypothesis, and establish a 'constrained de Finetti reduction'
statement that covers a wide family of convex constraints. Applications to
quantum hypothesis testing are explored in a related paper [Lami, arXiv:today].

</details>


### [36] [$α$-leakage Interpretation of Rényi Capacity](https://arxiv.org/abs/2510.06622)
*Ni Ding,Farhad Farokhi,Tao Guo,Yinfei Xu,Xiang Zhang*

Main category: cs.IT

TL;DR: 本文揭示了Sibson互信息与α泄漏之间的关系，提出了Y-基本α泄漏的概念，并将其扩展到整个Rényi阶数范围。通过最大化所有信道输入属性U的Y-基本泄漏得到Rényi散度，并将Rényi容量解释为最大f-平均信息泄漏。


<details>
  <summary>Details</summary>
Motivation: 研究Sibson互信息与α泄漏之间的深层联系，扩展点态最大泄漏到整个Rényi阶数范围，为信息泄漏分析提供更全面的理论框架。

Method: 使用f-平均相对信息增益解释Sibson互信息，提出Y-基本α泄漏概念，通过最大化信道输入属性U的泄漏得到Rényi散度，将Rényi容量解释为最大f-平均信息泄漏。

Result: 建立了Sibson互信息与α泄漏的等价关系，推导了实现δ-近似ε-上界α泄漏的充分条件，提出了交替最大-最大实现广义Blahut-Arimoto方法。

Conclusion: Sibson互信息可解释为α泄漏的f-平均，Y-基本α泄漏扩展了点态最大泄漏的范围，Rényi容量可视为最大信息泄漏，为信息论安全分析提供了新的视角。

Abstract: For $\tilde{f}(t) = \exp(\frac{\alpha-1}{\alpha}t)$, this paper shows that
the Sibson mutual information is an $\alpha$-leakage averaged over the
adversary's $\tilde{f}$-mean relative information gain (on the secret) at
elementary event of channel output $Y$ as well as the joint occurrence of
elementary channel input $X$ and output $Y$. This interpretation is used to
derive a sufficient condition that achieves a $\delta$-approximation of
$\epsilon$-upper bounded $\alpha$-leakage. A $Y$-elementary $\alpha$-leakage is
proposed, extending the existing pointwise maximal leakage to the overall
R\'{e}nyi order range $\alpha \in [0,\infty)$. Maximizing this $Y$-elementary
leakage over all attributes $U$ of channel input $X$ gives the R\'{e}nyi
divergence. Further, the R\'{e}nyi capacity is interpreted as the maximal
$\tilde{f}$-mean information leakage over both the adversary's malicious
inference decision and the channel input $X$ (represents the adversary's prior
belief). This suggests an alternating max-max implementation of the existing
generalized Blahut-Arimoto method.

</details>


### [37] [Optimizing Fronthaul Quantization for Flexible User Load in Cell-Free Massive MIMO](https://arxiv.org/abs/2510.06734)
*Fabian Göttsch,Max Franke,Arash Pourdamghani,Giuseppe Caire,Stefan Schmid*

Main category: cs.IT

TL;DR: 研究可扩展用户中心无蜂窝大规模MIMO系统的物理层频谱效率和前传网络负载，分析量化率对前传负载和系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在用户中心无蜂窝大规模MIMO系统中，由于前传链路容量有限，需要在传输前对数据进行量化，需要研究量化率对系统性能的影响。

Method: 使用混合整数线性规划联合优化簇处理器放置和前传流量路由，基于率失真理论计算量化率参数。

Result: 优化量化率后，前传负载在广泛的用户负载范围内保持稳定，且物理层性能损失很小。

Conclusion: 无蜂窝大规模MIMO系统和前传网络对变化的用户密度具有弹性，通过优化量化率可以维持稳定的前传负载。

Abstract: We investigate the physical layer (PHY) spectral efficiency and fronthaul
network load of a scalable user-centric cell-free massive MIMO system. Each
user-centric cluster processor responsible for cluster-level signal processing
is located at one of multiple decentralized units (DUs). Thus, the radio units
in the cluster must exchange data with the corresponding DU over the fronthaul.
Because the fronthaul links have limited capacity, this data must be quantized
before it is sent over the fronthaul. We consider a routed fronthaul network,
where the cluster processor placement and fronthaul traffic routing are jointly
optimized with a mixed-integer linear program. For different numbers of users
in the network, we investigate the effect of fronthaul quantization rates, a
system parameter computed based on rate-distortion theory. Our results show
that with optimized quantization rates, the fronthaul load is quite stable for
a wide range of user loads without significant PHY performance loss. This
demonstrates that the cell-free massive MIMO PHY and fronthaul network are
resilient to varying user densities.

</details>


### [38] [Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval](https://arxiv.org/abs/2510.06868)
*Didrik Bergström,Deniz Gündüz,Onur Günlü*

Main category: cs.IT

TL;DR: 该论文提出了一种结合深度哈希蒸馏的深度联合源信道编码方法，用于多跳AWGN信道中的图像传输，通过语义聚类提高语义一致性和感知重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决经典DeepJSCC在多跳设置中可能遭受噪声积累的问题，同时增强语义一致性以支持安全导向应用，并改善感知重建质量。

Method: 训练DeepJSCC编码器-解码器对，结合预训练的深度哈希蒸馏模块进行语义聚类，同时最小化均方误差和源图像与重建图像DHD哈希之间的余弦距离。

Result: 在不同多跳设置下显著提高了感知质量，通过LPIPS指标测量显示语义对齐带来了明显改善。

Conclusion: 结合深度哈希蒸馏的DeepJSCC方法能有效缓解多跳传输中的噪声积累问题，同时提升语义一致性和感知重建质量。

Abstract: We consider image transmission via deep joint source-channel coding
(DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by
training a DeepJSCC encoder-decoder pair with a pre-trained deep hash
distillation (DHD) module to semantically cluster images, facilitating
security-oriented applications through enhanced semantic consistency and
improving the perceptual reconstruction quality. We train the DeepJSCC module
to both reduce mean square error (MSE) and minimize cosine distance between DHD
hashes of source and reconstructed images. Significantly improved perceptual
quality as a result of semantic alignment is illustrated for different
multi-hop settings, for which classical DeepJSCC may suffer from noise
accumulation, measured by the learned perceptual image patch similarity (LPIPS)
metric.

</details>


### [39] [A Stochastic Geometric Analysis on Multi-cell Pinching-antenna Systems under Blockage Effect](https://arxiv.org/abs/2510.06972)
*Yanshi Sun,Zhiguo Ding,George K. Karagiannidis*

Main category: cs.IT

TL;DR: 为多小区夹持天线系统开发了一个分析框架，考虑了连接到不同基站的波导干扰，使用随机几何工具建模，推导了中断概率表达式，并验证了夹持天线系统优于固定天线系统。


<details>
  <summary>Details</summary>
Motivation: 现有夹持天线技术研究主要集中在单小区场景，忽略了来自连接到空间分布基站的干扰波导的影响，需要填补这一知识空白。

Method: 应用随机几何工具进行系统建模，考虑连接到不同基站的空间分布波导，推导出中断概率的表达式。

Result: 仿真结果验证了分析的准确性，并证明了夹持天线系统相比固定天线系统的优越性能。

Conclusion: 该研究为多小区夹持天线系统的性能评估提供了有效的分析框架，证明了其在干扰环境下的优势。

Abstract: Recently, the study on pinching-antenna technique has attracted significant
attention. However, most relevant literature focuses on a single-cell scenario,
where the effect from the interfering pinching-antennas on waveguides connected
to spatially distributed base stations (BSs) was ignored. To fulfill this
knowledge gap, this letter aims to provide an analytical framework on
performance evaluation for multi-cell pinching-antenna systems where spatially
distributed waveguides which are connected to different BSs are considered. In
particular, tools from stochastic geometry is applied for system modeling. The
expression for the outage probability is obtained. Simulation results are
provided to verify the accuracy of the analysis and demonstrate the superior
performance of pinching-antenna system compared to fixed-antenna systems.

</details>


### [40] [Lossless Compression of Time Series Data: A Comparative Study](https://arxiv.org/abs/2510.07015)
*Jonas G. Matt,Pengcheng Huang,Balz Maag*

Main category: cs.IT

TL;DR: 本文对时间序列数据的无损压缩方法进行了大规模比较研究，提出了包含数据变换和熵编码两阶段的统一框架，通过消融实验评估不同算法在各种数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 数字时代产生了前所未有的数据量，需要高效管理、传输和存储。时间序列数据压缩技术众多，但缺乏系统性的比较研究来指导算法选择和组合。

Method: 采用两阶段压缩框架：数据变换和熵编码。在合成和真实数据集上进行评估，通过消融实验分析各组件对压缩性能的影响。

Result: 揭示了不同算法在面对多样化时间序列特性时的优缺点，强调了完整压缩流程配置的重要性。

Conclusion: 研究为针对特定数据集选择和组合最合适的压缩算法提供了全面指导，凸显了良好配置的完整压缩流程的重要性。

Abstract: Our increasingly digital and connected world has led to the generation of
unprecedented amounts of data. This data must be efficiently managed,
transmitted, and stored to preserve resources and allow scalability. Data
compression has therein been a key technology for a long time, resulting in a
vast landscape of available techniques. This largest-to-date study analyzes and
compares various lossless data compression methods for time series data. We
present a unified framework encompassing two stages: data transformation and
entropy encoding. We evaluate compression algorithms across both synthetic and
real-world datasets with varying characteristics. Through ablation studies at
each compression stage, we isolate the impact of individual components on
overall compression performance -- revealing the strengths and weaknesses of
different algorithms when facing diverse time series properties. Our study
underscores the importance of well-configured and complete compression
pipelines beyond individual components or algorithms; it offers a comprehensive
guide for selecting and composing the most appropriate compression algorithms
tailored to specific datasets.

</details>


### [41] [Robustness of Covariance Estimators with Application in Activity Detection](https://arxiv.org/abs/2510.07044)
*Hendrik Bernd Zarucha,Peter Jung,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文提出了一类通用的协方差估计器，通过函数g和模型协方差矩阵集H构建。证明了这类估计器在扰动足够小时具有鲁棒性，并将其应用于多天线随机接入中的活动检测问题，提出了基于符号核条件的码本设计。


<details>
  <summary>Details</summary>
Motivation: 研究协方差估计的鲁棒性，并将其应用于无线通信中的活动检测问题，解决大规模衰落系数的稀疏恢复问题。

Method: 第一部分：定义由函数g和模型协方差矩阵集H生成的协方差估计器类，证明其鲁棒性。第二部分：将结果应用于多天线随机接入活动检测，提出基于符号核条件的码本设计。

Result: 证明了在适当条件下，松弛最大似然估计器属于所提出的协方差估计器类。当接收天线数量足够多且活跃用户数满足S≤⌈1/2M²⌉-1时，两种估计器都能恢复大规模衰落系数。

Conclusion: 提出的协方差估计器类具有鲁棒性，在活动检测应用中能够有效恢复大规模衰落系数，为无线通信系统设计提供了理论支持。

Abstract: The first part of this work considers a general class of covariance
estimators. Each estimator of that class is generated by a real-valued function
$g$ and a set of model covariance matrices $H$. If $\bf{W}$ is a potentially
perturbed observation of a searched covariance matrix, then the estimator is
the minimizer of the sum of $g$ applied to each eigenvalue of
$\bf{W}^\frac{1}{2}\bf{Z}^{-1}\bf{W}^\frac{1}{2}$ under the constraint that
$\bf{Z}$ is from $H$. It is shown that under mild conditions on $g$ and $H$
such estimators are robust, meaning the estimation error can be made
arbitrarily small if the perturbation of $\bf{W}$ gets small enough. \par In
the second part of this work the previous results are applied to activity
detection in random access with multiple receive antennas. In activity
detection recovering the large scale fading coefficients is a sparse recovery
problem which can be reduced to a structured covariance estimation problem. The
recovery can be done with a non-negative least squares estimator or with a
relaxed maximum likelihood estimator. It is shown that under suitable
assumptions on the distributions of the noise and the channel coefficients, the
relaxed maximum likelihood estimator is from the general class of covariance
estimators considered in the first part of this work. Then, codebooks based
upon a signed kernel condition are proposed. It is shown that with the proposed
codebooks both estimators can recover the large-scale fading coefficients if
the number of receive antennas is high enough and
$S\leq\left\lceil\frac{1}{2}M^2\right\rceil-1$ where $S$ is the number of
active users and $M$ is number of pilot symbols per user.

</details>


### [42] [A Theoretically-Grounded Codebook for Digital Semantic Communications](https://arxiv.org/abs/2510.07108)
*Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan*

Main category: cs.IT

TL;DR: 提出了一种基于信息理论的语义通信码本设计方法，通过优化量化效率、传输效率和鲁棒性能，在图像重建任务中相比现有方法显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 数字语义通信系统需要将高维语义特征映射到离散符号表示，现有码本设计缺乏理论指导，需要从信息论角度优化量化映射过程。

Method: 建立了语义信息理论中的同义映射与码本Voronoi分区量化映射的等价关系，推导了语义特征与量化索引间的互信息，提出了基于经验估计的熵正则化量化损失和信道感知语义失真损失进行端到端码本训练。

Result: 在图像重建任务中，当信噪比为10dB时，相比现有码本设计，峰值信噪比提升了24.1%，学习感知图像块相似度提升了46.5%。

Conclusion: 理论指导的码本设计能够有效提升语义通信系统的性能，通过优化量化效率和信道鲁棒性，实现了更好的语义信息传输效果。

Abstract: The use of a learnable codebook provides an efficient way for semantic
communications to map vector-based high-dimensional semantic features onto
discrete symbol representations required in digital communication systems. In
this paper, the problem of codebook-enabled quantization mapping for digital
semantic communications is studied from the perspective of information theory.
Particularly, a novel theoretically-grounded codebook design is proposed for
jointly optimizing quantization efficiency, transmission efficiency, and robust
performance. First, a formal equivalence is established between the one-to-many
synonymous mapping defined in semantic information theory and the many-to-one
quantization mapping based on the codebook's Voronoi partitions. Then, the
mutual information between semantic features and their quantized indices is
derived in order to maximize semantic information carried by discrete indices.
To realize the semantic maximum in practice, an entropy-regularized
quantization loss based on empirical estimation is introduced for end-to-end
codebook training. Next, the physical channel-induced semantic distortion and
the optimal codebook size for semantic communications are characterized under
bit-flip errors and semantic distortion. To mitigate the semantic distortion
caused by physical channel noise, a novel channel-aware semantic distortion
loss is proposed. Simulation results on image reconstruction tasks demonstrate
the superior performance of the proposed theoretically-grounded codebook that
achieves a 24.1% improvement in peak signal-to-noise ratio (PSNR) and a 46.5%
improvement in learned perceptual image patch similarity (LPIPS) compared to
the existing codebook designs when the signal-to-noise ratio (SNR) is 10 dB.

</details>


### [43] [Spectral Graph Clustering under Differential Privacy: Balancing Privacy, Accuracy, and Efficiency](https://arxiv.org/abs/2510.07136)
*Mohamed Seif,Antti Koskela,H. Vincent Poor,Andrea J. Goldsmith*

Main category: cs.IT

TL;DR: 提出了三种在边差分隐私下进行谱图聚类的机制：图扰动、私有图投影和噪声幂迭代方法，提供了严格的隐私保证和误分类误差分析。


<details>
  <summary>Details</summary>
Motivation: 研究在边差分隐私约束下的谱图聚类问题，需要在保护图边隐私的同时保持图的谱特性。

Method: 1. 图扰动：通过随机边翻转和邻接矩阵洗牌；2. 私有图投影：在低维空间中添加高斯噪声；3. 噪声幂迭代：在迭代过程中分布高斯噪声。

Result: 实验在合成和真实网络数据集上验证了理论分析，展示了实际的隐私-效用权衡。

Conclusion: 提出的机制在边差分隐私下有效保护图边隐私，同时保持谱图聚类的性能，洗牌机制显著增强了隐私保证。

Abstract: We study the problem of spectral graph clustering under edge differential
privacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation
via randomized edge flipping combined with adjacency matrix shuffling, which
enforces edge privacy while preserving key spectral properties of the graph.
Importantly, shuffling considerably amplifies the guarantees: whereas flipping
edges with a fixed probability alone provides only a constant epsilon edge DP
guarantee as the number of nodes grows, the shuffled mechanism achieves
(epsilon, delta) edge DP with parameters that tend to zero as the number of
nodes increase; (ii) private graph projection with additive Gaussian noise in a
lower-dimensional space to reduce dimensionality and computational complexity;
and (iii) a noisy power iteration method that distributes Gaussian noise across
iterations to ensure edge DP while maintaining convergence. Our analysis
provides rigorous privacy guarantees and a precise characterization of the
misclassification error rate. Experiments on synthetic and real-world networks
validate our theoretical analysis and illustrate the practical privacy-utility
trade-offs.

</details>
