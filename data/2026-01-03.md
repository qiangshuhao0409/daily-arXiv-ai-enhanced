<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Improving Reliability of Human Trafficking Alerts in Airports](https://arxiv.org/abs/2512.23865)
*Nana Oye Akrofi Quarcoo,Milena Radenkovic*

Main category: cs.NI

TL;DR: 研究机场个人紧急警报场景，通过模拟评估两种DTN协议（Spray and Wait和Epidemic）在投递率和延迟方面的性能表现


<details>
  <summary>Details</summary>
Motivation: 研究在机场环境中使用延迟容忍网络（DTN）技术处理个人紧急警报的可行性，探索如何利用移动自组织网络技术改善紧急通信

Method: 使用ONE模拟器对机场场景进行仿真，应用Spray and Wait和Epidemic两种DTN协议，评估投递率和延迟性能指标

Result: 分析了两种协议在机场紧急警报场景中的表现，讨论了各自的优势和局限性，以及模拟实验设置的约束条件

Conclusion: DTN网络在机场紧急警报场景中具有应用潜力，研究还扩展讨论了DTN技术在打击人口贩运等全球性问题中的潜在作用

Abstract: This paper investigates the latter scenario of individual emergency alerts in airports by applying two existing benchmark delay tolerant network protocols and evaluating their performance of delivery ratio and latency. First, the paper provides a background on Mobile Ad Hoc Networks (MANETs) and Delay Tolerant Networks (DTNs), as well as Vehicular Ad Hoc Networks (VANETs) as a subset of MANETs. Next, the scenario is simulated using the Opportunistic Network Environment (ONE) simulator and runs the DTN protocols applying Spray and Wait and Epidemic. The study discusses the results, highlighting the advantages and limitations of each protocol within the scenario and addressing constraints of the simulation or experimental setup. A wider discussion then considers related research on technologies that combat human trafficking and the potential role of DTN networks in improving this global issue for the better.

</details>


### [2] [Wireless Multimodal Foundation Model (WMFM): Integrating Vision and Communication Modalities for 6G ISAC Systems](https://arxiv.org/abs/2512.23897)
*Mohammad Farzanullah,Han Zhang,Akram Bin Sediq,Ali Afana,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 本文提出了基于对比学习的无线多模态基础模型（WMFM），该模型联合学习无线信道系数和视觉图像，在ISAC系统中实现了可扩展的多模态学习，显著提升了定位和分类性能，同时大幅减少了训练时间和数据需求。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，感知与通信模态的集成为开发通用化和数据高效的模型提供了独特机会。多模态基础模型的出现使得跨数据类型的联合理解成为可能，但需要专门针对无线场景的解决方案。

Method: 提出无线多模态基础模型（WMFM），采用对比学习进行预训练，将相机数据和信道数据的嵌入对齐，无需显式标签。预训练编码器冻结后作为特征提取器，配合轻量级任务特定头部进行下游任务微调，包括用户定位和视距/非视距分类。

Result: 在DeepVerse6G数据集上的实验表明：1）视距/非视距分类的平衡准确率提升17%；2）定位误差减少48.5%；3）训练时间减少高达90倍；4）仅使用20%数据时，WMFM仍优于完全监督的端到端模型。

Conclusion: 该方法为集成感知与通信（ISAC）系统中的可扩展多模态学习奠定了基础，为智能自适应的6G网络开辟了道路，展示了在数据效率和性能方面的显著优势。

Abstract: The emergence of multimodal foundation models has revolutionized learning paradigms by enabling joint understanding across diverse data types. In the context of next-generation wireless networks, integrating sensing and communication modalities presents a unique opportunity to develop generalizable and data-efficient models. In this work, we introduce the contrastive learning based Wireless Multimodal Foundation Model (WMFM), a large-scale framework that jointly learns from wireless channel coefficients and visual imagery. The WMFM is pretrained using contrastive learning, a self-supervised learning technique that aligns embeddings of camera and channel data without requiring explicit labels. The pretrained encoders are then frozen and employed as feature extractors, with lightweight task-specific heads, fine-tuned for downstream tasks, including user localization and LoS/nLoS classification. Extensive experiments on the DeepVerse6G dataset demonstrate that the proposed WMFM achieves a 17% improvement in balanced accuracy for LoS/nLoS classification and a 48.5% reduction in localization error compared to the end-to-end (E2E) benchmark, while reducing training time by up to 90-fold. Even when trained with as little as 20% of the data, the WMFM-based heads outperform the fully supervised E2E model, underscoring their robustness and data-efficient learning. The proposed approach establishes a foundation for scalable, multimodal learning in Integrated Sensing and Communication (ISAC) systems, paving the way for intelligent and adaptive 6G networks.

</details>


### [3] [Road Rules for Radio: Why Your Wi-Fi Got Better](https://arxiv.org/abs/2512.23901)
*Bradley Fang,Michael Roger*

Main category: cs.NI

TL;DR: 本文是一篇关于WiFi技术发展的综合性文献综述，聚焦七个关键领域，使用公路类比帮助理解，并探讨即将发布的WiFi 8标准。


<details>
  <summary>Details</summary>
Motivation: WiFi技术发展迅速但复杂，公众对其整体进展缺乏理解。本文旨在通过全面综述帮助读者理解WiFi的关键技术进步和未来发展方向。

Method: 采用文献综述方法，聚焦七个关键领域：带宽、电池寿命、流量冲突、干扰、数据密集型传输、多设备连接和峰值吞吐量/调制。使用公路/高速公路类比解释网络机制，并分析即将发布的WiFi 8标准。

Result: 提供了WiFi技术发展的全面概述，解释了各领域的问题、解决方案和现有限制。特别指出WiFi 8标准将显著转向优先考虑可靠性而非纯粹的数据速率。

Conclusion: 本文通过系统性综述和创新的类比方法，使读者能够全面理解WiFi技术的发展历程、当前状态和未来方向，特别是WiFi 8标准带来的可靠性优先转变。

Abstract: WiFi allows for the connection of devices and people around the globe. It has proven to be a monumental and revolutionary tool that keeps the world connected. However, recent WiFi advancements are numerous and at times confusing. WiFi has grown significantly over the years, yet few understand the scope and scale of WiFi progression as a whole. This paper tackles that problem, providing a broad literature review on the advancements of key WiFi features to date. This paper will center on seven key areas of focus: (1) bandwidth, (2) battery life, (3) traffic collisions, (4) interference, (5) data-intensive transmissions, (6) numerous devices, and (7) peak throughput/modulation. Each section will focus on WiFi's problems, how those problems were fixed, as well as the limitations of existing solutions. Moreover, the paper explains the role of new unreleased technologies in these seven areas. This includes exploring the upcoming WiFi 8 standard based on the IEEE 802.11bn "Ultra High Reliability" (UHR) specification and how it builds upon current specifications. Compared to previous specifications, WiFi 8 marks a stronger and more significant shift toward prioritizing reliability over pure data rates. Beyond a sole literature review, this paper uses a novel analogy. A road/highway analogy will be integrated throughout the paper to facilitate understanding of networking mechanisms. This paper is approachable and is written such that someone with very little WiFi knowledge should come away with a strong understanding of WiFi. As is typical of literature review papers, technical claims will be grounded in prior work.

</details>


### [4] [SRM at 30: Lessons from Early Data-Centric Networking and Their Impact on Named Data Networking](https://arxiv.org/abs/2512.23928)
*Tianyuan Yu,Adam Thieme,Junxiao Shi,Lan Wang,Lixia Zhang*

Main category: cs.NI

TL;DR: SRM论文提出了一种数据中心的可靠多播框架，但存在应用层命名与网络层地址不匹配的问题。NDN通过将网络交付与数据检索模型对齐，解决了这一架构摩擦。


<details>
  <summary>Details</summary>
Motivation: 传统方法试图将发送者驱动的可靠单播机制适配到多播场景，但存在效率问题。SRM探索了一种根本不同的方法，让数据接收者通过显式请求来恢复丢失数据，实现数据中心的可靠多播。

Method: SRM引入了数据中心的模型，其中数据接收者通过显式请求缺失数据来恢复丢失。这与传统的发送者驱动机制不同，而是采用接收者驱动的恢复方法。

Result: SRM实验揭示了其数据中心框架与IP地址交付之间的根本语义不匹配：应用层命名数据，但网络层对这些名称"视而不见"，导致低效的丢失恢复。

Conclusion: NDN通过将网络交付与数据检索模型对齐，并直接保护数据而非通信通道，解决了SRM面临的架构摩擦。SRM的早期见解为NDN的关键设计决策提供了信息，展示了NDN设计如何从数十年网络研究的累积见解中产生。

Abstract: A 1995 SIGCOMM paper, "A Reliable Multicast Framework for Light-weight Sessions and Application-Level Framing", commonly known as SRM, explored a fundamentally new approach to reliable multiparty data delivery. Rather than adapting established sender-driven reliable unicast mechanisms to multicast, as most contemporaneous proposals did, SRM introduced a data-centric model in which data receivers recover losses by explicitly requesting missing data. Thirty years later, we revisit the SRM framework, examining the challenges it faced, the lessons learned, and its influence on the later development of Named Data Networking (NDN). Experimentations with SRM revealed a fundamental semantic mismatch between its data-centric framework and IP's address-based delivery; while the application layer named data, the network layer remained 'blind' to those names, resulting in inefficient loss recovery. NDN resolves this architectural friction by aligning network delivery with the data-retrieval model and by securing data directly rather than securing communication channels. This retrospective highlights how early insights from SRM informed key design decisions in NDN and illustrates how NDN's design emerged from the cumulative insights gained over decades of networking research and development.

</details>


### [5] [Beyond Dedicated-Active: A General Reliability Provisioning Framework for SFC Placement in Fog Computing](https://arxiv.org/abs/2512.24049)
*Negin Doostar,Mohammad Reza Heidarpour,Amir Khorsandi*

Main category: cs.NI

TL;DR: 本文提出了一种在异构雾服务器上可靠性感知的服务功能链放置框架，通过遗传算法优化冗余策略，相比传统专用主动冗余可提升84%性能。


<details>
  <summary>Details</summary>
Motivation: 物联网设备爆炸式增长给传统云基础设施带来压力，需要低延迟和节能的替代方案。雾计算将计算放在网络边缘，但有限的异构雾资源对可靠性构成挑战，特别是对任务关键型应用。同时，应用部署为服务功能链（SFC）虽然灵活，但比单体部署更容易失败，需要智能的冗余和放置策略。

Method: 通过可靠性理论视角研究可靠性感知的SFC放置问题，探索四种冗余策略（共享vs专用、主动vs备用），提出通用框架以最小化延迟和成本，同时满足可靠性和截止时间约束。将问题建模为整数非线性规划（INLP），并开发两种基于遗传算法（GA）的解决方案。

Result: 仿真结果表明，共享备用冗余策略相比传统的专用主动方法性能提升高达84%。

Conclusion: 本文提出的可靠性感知SFC放置框架和共享备用冗余策略能有效解决异构雾环境中的可靠性问题，显著提升性能，为任务关键型物联网应用提供了可行的解决方案。

Abstract: The explosive growth of Internet of Things (IoT) devices has strained traditional cloud infrastructures, highlighting the need for low-latency and energy-efficient alternatives. Fog computing addresses this by placing computation near the network edge. However, limited and heterogeneous fog resources pose reliability challenges, especially for mission-critical applications. On the other hand, to improve flexibility, applications are deployed as Service Function Chains (SFCs), where each function runs as a Virtual Network Function (VNF). While scalable, this approach is more failure-prone than monolithic deployments, necessitating intelligent redundancy and placement strategies. This paper addresses the reliability-aware SFC placement problem over heterogeneous fog servers through the lens of reliability theory. We explore four redundancy strategies, combining shared vs. dedicated and active vs. standby modes, and propose a general framework to minimize latency and cost while meeting reliability and deadline constraints. The problem is formulated as an Integer Non-Linear Program (INLP), and two genetic algorithm (GA)-based solutions are developed. Simulation results show that shared-standby redundancy outperforms the conventional dedicated-active approach by up to 84%.

</details>


### [6] [CPePC: Cooperative and Predictive Popularity based Caching for Named Data Networks](https://arxiv.org/abs/2512.24073)
*Pankaj Chaudhary,Neminath Hubballi,Sameer G. Kulkarni*

Main category: cs.NI

TL;DR: CPePC是一种协作缓存技术，通过社区划分和领导者节点来减少流行度估计开销，并基于缓存占用率和内容流行度预测参数来优化缓存决策，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 命名数据网络中的路由器缓存容量有限，需要智能选择缓存内容。现有技术主要缓存流行内容但存在显著的协调和流行度估计开销问题。

Method: 1) 使用社区估计算法将网络划分为非重叠社区，选择领导者节点协调社区内所有节点；2) 基于当前缓存占用率和内容流行度预测参数来制定缓存决策。

Result: 通过离散事件模拟器与六种最先进缓存技术比较，CPePC表现出更好的性能。

Conclusion: CPePC通过减少流行度估计开销和智能缓存决策，有效提高了命名数据网络的缓存性能。

Abstract: Caching content is an inherent feature of Named Data Networks. Limited cache capacity of routers warrants that the choice of content being cached is judiciously done. Existing techniques resort to caching popular content to maximize utilization. However, these methods experience significant overhead for coordinating and estimating the popularity of content. To address this issue, in this paper, we present CPePC, which is a cooperative caching technique designed to improve performance. It accomplishes this through a combination of two factors. First, CPePC enhances efficiency by minimizing the overhead of popularity estimation. Second, it forecasts a parameter that governs caching decisions. Efficiency in popularity estimation is achieved by dividing the network into several non-overlapping communities using a community estimation algorithm and selecting a leader node to coordinate this on behalf of all the nodes in the community. CPePC bases its caching decisions by predicting a parameter whose value is estimated using current cache occupancy and the popularity of the content into account. We present algorithms for community detection, leader selection, content popularity estimation, and caching decisions made by the CPePC method. We evaluate and compare it with six other state-of-the-art caching techniques, with simulations performed using a discrete event simulator to show that it outperforms others.

</details>


### [7] [Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations](https://arxiv.org/abs/2512.24452)
*Yalin E. Sagduyu,Tugba Erpek,Aylin Yener,Sennur Ulukus*

Main category: cs.NI

TL;DR: 提出一种深度学习语义通信框架，在支持多接收器任务的同时限制窃听者的语义信息泄露，通过最小最大优化和对抗扰动层实现可调隐私保护。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽然提高了带宽效率和鲁棒性，但学习到的语义表示仍可能泄露敏感信息给窃听者。需要设计既能支持合法接收器任务，又能限制语义信息泄露的安全框架。

Method: 采用深度学习语义通信框架，合法链路使用学习编码器，接收器训练解码器进行语义推理和数据重建。通过迭代最小最大优化训练窃听器提高语义推理能力，同时训练合法收发对保持任务性能并降低窃听成功率。引入辅助层在传输波形上叠加对抗性扰动以降低语义泄露。

Result: 在瑞利衰落信道和加性高斯白噪声环境下，使用MNIST和CIFAR-10数据集评估。语义准确率和重建质量随潜在维度增加而提高，最小最大机制显著降低窃听者推理性能而不影响合法接收器。扰动层即使在合法链路仅为自己任务训练时也能有效减少语义泄露。

Conclusion: 该综合框架为现实无线环境中对抗自适应对手提供了可调、端到端的隐私保护语义通信设计思路，在保持合法接收器性能的同时有效限制语义信息泄露。

Abstract: Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper's success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper's inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.

</details>


### [8] [Chat-Driven Optimal Management for Virtual Network Services](https://arxiv.org/abs/2512.24614)
*Yuya Miyaoka,Masaki Inoue,Kengo Urata,Shigeaki Harada*

Main category: cs.NI

TL;DR: 提出一个聊天驱动的网络管理框架，结合NLP与优化虚拟网络分配，实现直观可靠的虚拟网络服务重构。


<details>
  <summary>Details</summary>
Motivation: 传统基于意图的网络管理方法依赖统计语言模型解释用户意图，但无法保证生成配置的可行性，需要更可靠的解决方案。

Method: 开发两阶段框架：1) Interpreter使用NLP从自然语言提示中提取意图（采用Sentence-BERT+SVM或LLM两种提取器）；2) Optimizer通过整数线性规划计算可行的虚拟机放置和路由方案。

Result: 实验显示框架能动态更新虚拟机放置和路由同时保持可行性。LLM提取器在较少标注样本下准确率更高，而Sentence-BERT+SVM延迟显著更低，适合实时操作。

Conclusion: 结合NLP驱动的意图提取与基于优化的分配方法，可实现安全、可解释且用户友好的虚拟网络管理。

Abstract: This paper proposes a chat-driven network management framework that integrates natural language processing (NLP) with optimization-based virtual network allocation, enabling intuitive and reliable reconfiguration of virtual network services. Conventional intent-based networking (IBN) methods depend on statistical language models to interpret user intent but cannot guarantee the feasibility of generated configurations. To overcome this, we develop a two-stage framework consisting of an Interpreter, which extracts intent from natural language prompts using NLP, and an Optimizer, which computes feasible virtual machine (VM) placement and routing via an integer linear programming. In particular, the Interpreter translates user chats into update directions, i.e., whether to increase, decrease, or maintain parameters such as CPU demand and latency bounds, thereby enabling iterative refinement of the network configuration. In this paper, two intent extractors, which are a Sentence-BERT model with support vector machine (SVM) classifiers and a large language model (LLM), are introduced. Experiments in single-user and multi-user settings show that the framework dynamically updates VM placement and routing while preserving feasibility. The LLM-based extractor achieves higher accuracy with fewer labeled samples, whereas the Sentence-BERT with SVM classifiers provides significantly lower latency suitable for real-time operation. These results underscore the effectiveness of combining NLP-driven intent extraction with optimization-based allocation for safe, interpretable, and user-friendly virtual network management.

</details>


### [9] [Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks](https://arxiv.org/abs/2512.24659)
*Yixian Wang,Geng Sun,Zemin Sun,Jiacheng Wang,Changyuan Zhao,Daxin Tian,Dusit Niyato,Shiwen Mao*

Main category: cs.NI

TL;DR: 提出IRS增强的低空MEC架构，通过分层在线优化方法（HOOA）联合优化任务卸载、无人机轨迹、IRS相移和计算资源分配，显著降低任务完成延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决地面MEC服务器在遮挡环境下连接质量差的问题，同时优化任务完成延迟和能耗，本文提出IRS增强的低空MEC架构，利用空中和地面MEC服务器协同工作，并通过混合IRS（建筑安装和无人机携带）增强空地连接。

Method: 1. 提出IRS增强的低空MEC架构；2. 将多目标优化问题（MOOP）重构为Stackelberg博弈；3. 在跟随者层面使用多对一匹配机制生成离散决策；4. 在领导者层面提出GDMTD3算法（生成扩散模型增强的双延迟深度确定性策略梯度）结合KKT方法确定连续决策。

Result: 仿真结果表明，HOOA相比最佳基准方法和最先进DRL算法，分别将平均任务完成延迟降低2.5%，平均能耗降低3.1%。同时展现出优越的收敛稳定性、鲁棒性和动态环境下的可扩展性。

Conclusion: 提出的IRS增强低空MEC架构和分层在线优化方法（HOOA）能有效解决NP-hard优化问题，显著提升系统性能，为动态环境下的边缘计算服务提供了高效解决方案。

Abstract: In this paper, we propose an intelligent reflecting surface (IRS)-enabled low-altitude multi-access edge computing (MEC) architecture, where an aerial MEC server cooperates with a terrestrial MEC server to provide computing services, while hybrid IRSs (i.e., building-installed and UAV-carried IRSs) are deployed to enhance the air-ground connectivity under blockage. Based on this architecture, we formulate a multi-objective optimization problem (MOOP) to minimize the task completion delay and energy consumption by jointly optimizing task offloading, UAV trajectory control, IRS phase-shift configuration, and computation resource allocation. The considered problem is NP-hard, and thus we propose a hierarchical online optimization approach (HOOA) to efficiently solve the problem. Specifically, we reformulate the MOOP as a Stackelberg game, where MEC servers collectively act as the leader to determine the system-level decisions, while the vehicles act as followers to make individual decisions. At the follower level, we present a many-to-one matching mechanism to generate feasible discrete decisions. At the leader level, we propose a generative diffusion model-enhanced twin delayed deep deterministic policy gradient (GDMTD3) algorithm integrated with a Karush-Kuhn-Tucker (KKT)-based method, which is a deep reinforcement learning (DRL)-based approach, to determine the continuous decisions. Simulation results demonstrate that the proposed HOOA achieves significant improvements, which reduces average task completion delay by 2.5% and average energy consumption by 3.1% compared with the best-performing benchmark approach and state-of-the-art DRL algorithm, respectively. Moreover, the proposed HOOA exhibits superior convergence stability while maintaining strong robustness and scalability in dynamic environments.

</details>


### [10] [Analyzing Communication Predictability in LLM Training](https://arxiv.org/abs/2512.24750)
*Wenxue Li,Xiangzhou Liu,Yuxuan Li,Yilun Jin,Zhenghang Ren,Xudong Liao,Han Tian,Bo Ren,Zhizhen Zhong,Guyue Liu,Ying Zhang,Kai Chen*

Main category: cs.NI

TL;DR: 该论文系统化地研究了分布式训练中通信的可预测性，特别是在使用混合并行的大型语言模型训练中，提出了通信开销的分析公式，并开发了配置调优工具ConfigTuner来优化训练性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过在线分析利用通信可预测性进行运行时优化，但缺乏对其系统性的理解。分布式训练中通信可预测性是其重要特性，特别是在大型语言模型使用混合并行训练的场景下，需要系统性地理解和利用这种可预测性。

Method: 1. 系统化地形式化分布式训练中的通信可预测性，特别关注LLM的混合并行训练；2. 分析典型LLM中的可预测流量模式；3. 评估各种因素对GPU利用率和有效带宽（影响通信开销的两个关键变量）的影响；4. 开发分析公式来估计LLM训练中的通信开销；5. 基于该公式提出配置调优工具ConfigTuner来优化训练性能。

Result: 1. 提出的通信开销分析公式与经验数据验证具有高准确性；2. ConfigTuner优化的训练配置相比Megatron-LM实现了高达1.36倍的吞吐量提升；3. 相比Alpa，ConfigTuner能够生成相同的配置建议，同时显著降低了搜索复杂度。

Conclusion: 该工作系统化地形式化了分布式训练中的通信可预测性，特别是在LLM混合并行训练场景下。提出的分析公式能够准确估计通信开销，基于此开发的ConfigTuner工具能够有效优化训练配置，显著提升训练性能并降低配置搜索复杂度。

Abstract: Effective communication is essential in distributed training, with predictability being one of its most significant characteristics. However, existing studies primarily focus on exploiting predictability through online profiling for runtime optimization, without a systematic understanding of it. In this work, we aim to systematically formulate communication predictability in distributed training, particularly in Large Language Models (LLMs) that utilize hybrid parallelism. Our analysis focuses on both traffic patterns and communication overhead. Specifically, we investigate predictable traffic patterns in typical LLMs and evaluate how various factors influence GPU utilization and effective bandwidth (two critical variables affecting communication overhead). Furthermore, we develop an analytical formulation to estimate communication overhead in LLM training, which is validated with high accuracy against empirical data. Leveraging this formulation, we propose a configuration tuning tool, ConfigTuner, to optimize training performance. Compared to Megatron-LM, the training configurations optimized by ConfigTuner demonstrate up to a 1.36$\times$ increase in throughput. Compared to Alpa, ConfigTuner generates the same configuration suggestion while significantly reducing the search complexity.

</details>


### [11] [Sidelink Positioning: Standardization Advancements, Challenges and Opportunities](https://arxiv.org/abs/2512.24803)
*Yuan Gao,Guangjin Pan,Zhiyong Zhong,Zhengyu Jin,Yichen Hu,Yifei Jin,Shugong Xu*

Main category: cs.NI

TL;DR: 本文全面总结了3GPP Rel-18侧链路定位标准化进展，评估了不同定位方法在非理想因素下的性能，并讨论了Rel-19的研究方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着蜂窝网络在V2X、公共安全、工业物联网等需要精确定位信息的垂直行业中的集成，定位已成为未来无线网络的必要组成部分。虽然蜂窝定位通过更宽频谱、多天线和灵活架构实现了不断提高的定位精度，但在UE与BS距离较大或非视距场景下仍面临性能下降问题。3GPP Rel-18提出标准化侧链路定位，通过UE间的直接定位信令扩展定位覆盖范围。

Method: 本文采用标准化文献综述和性能评估相结合的方法：1）全面总结3GPP Rel-18侧链路定位标准化进展，包括网络架构、定位类型和性能要求；2）评估不同定位方法在各种非理想因素下的能力；3）基于3GPP Rel-19的演进，讨论侧链路定位的可能研究方向和挑战。

Result: 文章系统梳理了3GPP侧链路定位标准化现状，评估了不同定位方法在非理想条件下的性能表现，揭示了侧链路定位在扩展覆盖范围方面的潜力，但也指出了其能力存在的争议，特别是在实现3GPP定义的定位精度所需频谱资源方面。

Conclusion: 侧链路定位为扩展蜂窝网络定位覆盖提供了独特机会，但需要进一步研究解决频谱效率、非理想因素下的性能优化等挑战。随着3GPP Rel-19的演进，侧链路定位将在未来无线网络中发挥更重要作用，需要持续的技术创新和标准化推进。

Abstract: With the integration of cellular networks in vertical industries that demand precise location information, such as vehicle-to-everything (V2X), public safety, and Industrial Internet of Things (IIoT), positioning has become an imperative component for future wireless networks. By exploiting a wider spectrum, multiple antennas and flexible architectures, cellular positioning achieves ever-increasing positioning accuracy. Still, it faces fundamental performance degradation when the distance between user equipment (UE) and the base station (BS) is large or in non-line-of-sight (NLoS) scenarios. To this end, the 3rd generation partnership project (3GPP) Rel-18 proposes to standardize sidelink (SL) positioning, which provides unique opportunities to extend the positioning coverage via direct positioning signaling between UEs. Despite the standardization advancements, the capability of SL positioning is controversial, especially how much spectrum is required to achieve the positioning accuracy defined in 3GPP. To this end, this article summarizes the latest standardization advancements of 3GPP on SL positioning comprehensively, covering a) network architecture; b) positioning types; and c) performance requirements. The capability of SL positioning using various positioning methods under different imperfect factors is evaluated and discussed in-depth. Finally, according to the evolution of SL in 3GPP Rel-19, we discuss the possible research directions and challenges of SL positioning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 提出BatteryAgent框架，结合物理特征与大语言模型推理能力，实现锂电池故障的智能诊断与根因分析，显著提升检测性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽然检测精度高，但存在"黑盒"问题缺乏可解释性，且受限于二分类范式，无法提供根因分析和维护建议，限制了电池安全管理的发展。

Method: 提出三层框架：1) 物理感知层提取10个基于电化学原理的特征；2) 检测归因层使用梯度提升决策树和SHAP量化特征贡献；3) 推理诊断层利用LLM构建"数值-语义"桥梁，结合SHAP归因和机理知识库生成综合诊断报告。

Result: BatteryAgent有效纠正了边界样本的误分类，AUROC达到0.986，显著优于现有方法。框架将传统二分类检测扩展到多类型可解释诊断，实现了从"被动检测"到"智能诊断"的范式转变。

Conclusion: BatteryAgent通过整合物理知识与LLM推理能力，解决了现有方法可解释性不足的问题，为电池安全管理提供了从检测到诊断的完整解决方案，具有重要的实际应用价值。

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [13] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 论文提出DDFT评估框架，用于测量语言模型在语义压缩和对抗性攻击下的认知稳健性，发现模型稳健性与参数规模无关，而取决于错误检测能力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估（如MMLU、TruthfulQA）只测量理想条件下的知识，无法评估模型在信息退化或对抗性攻击下的稳健性。需要新的评估方法来区分模型是否真正"知道"知识，而不仅仅是表面流畅。

Method: 提出Drill-Down and Fabricate Test (DDFT)协议，测量认知稳健性：模型在渐进语义压缩和对抗性伪造下保持事实准确性的能力。采用两系统认知模型：语义系统（生成流畅文本）和认知验证器（验证事实准确性）。评估9个前沿模型在8个知识领域、5个压缩级别（共1800次轮级评估）。

Result: 认知稳健性与传统设计范式正交：参数数量（r=0.083）和架构类型（r=0.153）均不显著预测稳健性。错误检测能力强烈预测整体稳健性（rho=-0.817, p=0.007）。旗舰模型尽管规模大但表现出脆弱性，而较小模型也能实现稳健性能。

Conclusion: 认知稳健性主要取决于训练方法和验证机制，而非模型规模。DDFT框架为关键应用部署前评估认知稳健性提供了理论基础和实用工具，挑战了模型规模与可靠性关系的传统假设。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [14] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE是一个自演化的LLM智能体框架，实现了从"LLM+工具使用"到"LLM+技能获取"的转变，通过持续学习和自我反思掌握复杂科学工具，在材料科学和化学任务上达到93.3%成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性。需要一种能够自主学习和掌握外部工具的新框架。

Method: CASCADE框架通过两种元技能实现：1) 持续学习（网络搜索和代码提取），2) 自我反思（内省和知识图谱探索）。框架还包括人机协作和记忆巩固机制。

Result: 在包含116个材料科学和化学研究任务的SciSkillBench基准测试中，CASCADE使用GPT-5达到93.3%成功率，相比没有演化机制的35.4%有显著提升。展示了在计算分析、自主实验室实验和论文选择性复现等实际应用。

Conclusion: CASCADE能够积累可执行的技能，这些技能可以在智能体和科学家之间共享，为实现可扩展的AI辅助科学研究迈出了重要一步。

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [15] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy框架结合大语言模型与回答集编程，通过将医学文献转化为ASP代码并与患者数据结合，实现可解释的疾病预测系统


<details>
  <summary>Details</summary>
Motivation: 准确的疾病预测对于及时干预、有效治疗和减少医疗并发症至关重要。虽然符号AI已在医疗保健中应用，但由于构建高质量知识库需要大量努力，其采用仍然有限

Method: McCoy框架结合大语言模型与回答集编程：1) 使用LLM将医学文献翻译成ASP代码；2) 将生成的ASP代码与患者数据结合；3) 使用ASP求解器处理以得出最终诊断

Result: 初步结果显示McCoy在小规模疾病诊断任务上表现出色，创建了一个强大且可解释的预测框架

Conclusion: McCoy框架通过结合LLM和ASP，克服了符号AI在医疗领域应用的知识库构建障碍，为疾病预测提供了可解释且强大的解决方案

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [16] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态检索和个性化，模拟人类信息寻求的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统个性化搜索系统受限于静态用户画像和单一检索流程，无法捕捉用户动态、多维的信息需求演化。需要一种能模拟人类信息寻求复杂性和情境敏感性的新方法。

Method: 1. 定义角色空间（角色、专业知识、任务上下文、领域）；2. 引入角色协调器动态激活相关智能体；3. 每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和情境感知推理模块；4. 通过共享内存库、迭代辩论和中继式知识转移等结构化通信协议促进智能体协作。

Result: 框架产生了关于协调效率、个性化质量和认知负载分布的可测试预测，同时包含自适应学习机制用于持续角色优化。该框架为下一代搜索系统提供了理论洞察。

Conclusion: SPARK通过细粒度智能体专业化与协作检索的结合，为能够捕捉人类信息寻求行为的复杂性、流动性和情境敏感性的下一代搜索系统提供了理论基础和实践指导。

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [17] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD框架通过自动化调试而非随机搜索优化LLM提示，无需标注数据集，在冷启动场景下实现高效性能提升


<details>
  <summary>Details</summary>
Motivation: 现实软件工程中，LLM代理开发初期通常缺乏标注数据集，只有混乱的生产日志和不断变化的故障模式，需要一种无需精炼数据集的自适应优化方法

Method: 采用多智能体架构：分析器进行根因分析，优化器进行模式聚合，教练进行策略集成，将非结构化故障日志转换为结构化的决策树协议

Result: 在学术基准和生产知识管理引擎上，仅3次自动迭代就使成功率提升5.6%（73.6%到79.2%），搜索准确率提升3.8%；在零售领域复杂推理任务上，性能相对基线提升约19%

Conclusion: 模仿人类工程师的故障分析和修复循环，为部署可靠LLM代理提供了一种数据高效、资源节约的替代方案，避免了资源密集的强化学习训练

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [18] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化代理框架，通过将LLM集成到"计划-执行-总结"认知范式中，显著提高进化效率并降低计算成本，在算法发现和机器学习管道优化中优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法缺乏结构化推理，导致从静态LLM向自改进代理的过渡受阻。现有方法在高维代码空间中面临早熟收敛和探索效率低下的问题。

Method: 提出LoongFlow框架，将LLM集成到"计划-执行-总结"认知范式中，并采用混合进化记忆系统，结合多岛模型、MAP-Elites和自适应玻尔兹曼选择，平衡探索与利用。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow比OpenEvolve、ShinkaEvolve等基线方法进化效率提升高达60%，同时发现更优解决方案。

Conclusion: LoongFlow标志着自主科学发现的重要进展，能够以更低的计算开销生成专家级解决方案，为自进化代理系统提供了有效框架。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [19] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec是一个结合大语言模型和Soar认知架构的新型认知推荐代理，通过感知-认知-行动循环实现可解释的推荐，并利用LLM进行知识初始化和在线学习。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推荐系统中存在"黑箱"特性、知识幻觉和在线学习能力有限的问题，而认知架构如Soar虽然推理过程结构化且可解释，但知识获取困难。需要结合两者的优势来解决这些互补性挑战。

Method: 提出CogRec认知推荐代理，以Soar作为核心符号推理引擎，利用LLM进行知识初始化填充工作记忆中的产生式规则。采用感知-认知-行动循环，遇到僵局时动态查询LLM获取推理解决方案，然后通过Soar的分块机制将解决方案转化为新的符号产生式规则，实现强大的在线学习。

Result: 在三个公共数据集上的广泛评估表明，CogRec在推荐准确性、可解释性以及解决长尾问题方面表现出显著优势。

Conclusion: CogRec成功地将LLM与Soar认知架构相结合，创建了一个既能持续进化知识库又能提供高度可解释推荐理由的认知推荐代理，有效解决了传统方法的局限性。

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [20] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 提出一种无需训练、基于图的方法来解决ARC-AGI-3基准中的交互式推理任务，通过视觉帧处理和系统化状态空间探索，在52个关卡中解决30个，显著优于前沿LLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的LLM无法可靠解决ARC-AGI-3基准中的交互式推理任务，这些任务需要智能体通过有限交互推断任务机制并适应复杂度递增的关卡。需要一种能够形成假设、测试假设并跟踪已发现机制的方法。

Method: 结合基于视觉的帧处理和系统化状态空间探索的图结构表示方法：1) 将视觉帧分割为有意义的组件；2) 基于视觉显著性优先选择动作；3) 维护探索状态和转移的有向图；4) 通过跟踪已访问状态和测试动作，优先选择能提供最短路径到未测试状态-动作对的动作。

Result: 在ARC-AGI-3预览挑战中，该方法在6个游戏的52个关卡中解决了中位数30个关卡，在私有排行榜上排名第3，显著优于前沿LLM智能体。

Conclusion: 即使没有学习，显式的图结构探索也能作为交互式推理的强大基线，强调了在稀疏反馈环境中系统化状态跟踪和动作优先级的重要性，这些环境正是当前LLM无法捕捉任务动态的地方。

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [21] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP（科学上下文协议）是一个开源标准，旨在通过构建全球自主科学代理网络来加速科学发现。它提供统一的资源集成规范和实验生命周期管理架构，连接1600多个工具资源，促进异构AI系统与人类研究者的大规模安全协作。


<details>
  <summary>Details</summary>
Motivation: 当前科学研究面临工具、模型、数据集和物理仪器等资源分散在不同平台和机构的问题，导致AI代理和应用程序难以发现、调用和组合这些能力。缺乏统一的协议标准限制了跨平台协作和实验的可重复性，阻碍了科学发现的效率。

Method: SCP基于两大支柱：1）统一资源集成：提供描述和调用科学资源的通用规范；2）编排实验生命周期管理：采用集中式SCP Hub和联邦式SCP Server的安全服务架构，管理实验注册、规划、执行、监控和归档全过程，实施细粒度认证授权，编排端到端可追溯工作流。

Result: 基于SCP构建的科学发现平台已集成超过1600个工具资源。在多样化用例中，SCP促进了异构AI系统与人类研究者之间安全的大规模协作，显著降低了集成开销，增强了实验可重复性。

Conclusion: 通过在协议层面标准化科学上下文和工具编排，SCP为可扩展、多机构、代理驱动的科学研究建立了必要的基础设施，为全球自主科学代理网络的发展奠定了基础。

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [22] [Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem](https://arxiv.org/abs/2512.24251)
*Pengfu Wan,Jiawei Chen,Gangyan Xu*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度强化学习（DRL）的方法来解决车队规模和混合车辆路径问题（FSMVRP），该方法能在几秒内生成接近最优的解决方案。


<details>
  <summary>Details</summary>
Motivation: FSMVRP是车辆路径问题的一个重要变体，在短期车辆租赁和按需物流等现实场景中具有高度适用性。然而，该问题需要同时做出车队组成和路径规划决策，增加了复杂性，特别是在大规模和时间受限的环境中面临重大挑战。

Method: 将问题建模为马尔可夫决策过程（MDP），开发了一个名为FRIPN的新型策略网络，无缝集成了车队组成和路径决策。方法包含专门设计的输入嵌入，包括剩余图嵌入以促进有效的车辆使用决策。

Result: 在随机生成的实例和基准数据集上进行的综合实验表明，该方法在计算效率和可扩展性方面表现出显著优势，特别是在大规模和时间受限的场景中。

Conclusion: 该方法在实际应用中具有潜力，并为将基于DRL的技术扩展到VRP的其他变体提供了有价值的启发。

Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.

</details>


### [23] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: RSA是一种风险感知的逐步对齐方法，通过嵌套风险度量在策略优化中显式考虑风险，以解决现有安全对齐方法的风险中性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法（如Safe RLHF和SACPO）通常采用风险中性范式，无法充分处理参考策略偏差带来的风险，且对罕见但可能灾难性的有害行为鲁棒性有限。

Method: 提出风险感知逐步对齐（RSA），将安全对齐建模为令牌级风险感知约束策略优化问题，通过基于嵌套风险度量的逐步对齐过程进行求解，实现令牌级策略更新。

Result: 实验结果表明，该方法在保持高帮助性的同时确保强安全性，并显著抑制尾部风险（低概率但高影响的不安全响应）。

Conclusion: RSA通过显式纳入风险感知，有效解决了现有安全对齐方法的局限性，在理论分析和实验验证中均表现出优越性能。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [24] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: 提出一种测试时自适应智能体，通过后验引导的信念精化进行探索性推理，无需梯度更新或额外训练，适用于部分可观测环境下的LLM智能体。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境下，LLM智能体需要有效推断潜在世界状态，但现有方法如提示增强或检索增强LLM存在集成开销大、对齐效果有限的问题。

Method: 智能体维护外部结构化环境状态信念，通过动作条件观测迭代更新，选择最大化信念空间信息增益的动作，使用轻量级LLM代理估计信息增益，并通过量化后验信念与真实环境配置一致性的新颖奖励评估世界对齐。

Result: 实验表明，该方法在潜在世界状态对齐方面优于推理时扩展基线方法（如提示增强或检索增强LLM），且集成开销显著降低。

Conclusion: 提出的测试时自适应智能体通过后验引导的信念精化，能够在部分可观测环境下有效对齐潜在世界状态，提供了一种无需梯度更新或额外训练的高效推理方法。

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [25] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 该研究系统分析了基于JEPA世界模型的规划方法，通过实验确定了最优的模型架构、训练目标和规划算法组合，在导航和操作任务上超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: AI领域长期面临开发能够解决广泛物理任务并在新任务和环境上泛化的智能体的挑战。虽然基于世界模型的规划方法取得进展，但在表示空间进行规划的方法（JEPA-WMs）尚未得到系统研究，需要确定其最优技术选择。

Method: 将这类方法统称为JEPA-WMs，系统研究了模型架构、训练目标和规划算法三个关键组件。使用模拟环境和真实机器人数据进行实验，分析不同组合对规划成功率的影响。

Result: 通过实验找到了最优的JEPA-WM方法组合，提出的模型在导航和操作任务上超越了DINO-WM和V-JEPA-2-AC两个基准方法。

Conclusion: JEPA-WMs家族中的技术选择对规划性能有显著影响，通过系统研究确定了最优配置，为基于表示空间的规划方法提供了实用指导。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [26] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: 提出交互式评估框架，分析基础模型代理在符号地图环境中的探索、记忆和推理能力，发现结构化记忆对空间理解至关重要，性能提升不能仅靠模型缩放。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型空间能力评估多基于静态地图或文本查询，忽视了交互式和经验驱动的空间理解本质。需要评估FM代理如何在动态探索中理解地图环境。

Method: 提出交互式评估框架，让代理在部分可观测的网格地图中增量探索（包含道路、交叉口和兴趣点），仅接收局部观察。通过六类空间任务评估空间理解，系统变化探索策略、记忆表示和推理方案。

Result: 探索主要影响经验获取但对最终推理准确性影响有限；记忆表示在整合空间经验中起核心作用，结构化记忆（特别是序列和图表示）显著提升路径规划等结构密集型任务性能；推理方案影响存储空间知识的利用方式；空间推理性能在超过一定能力阈值后饱和。

Conclusion: 地图空间理解需要针对空间表示和推理的专门机制，而不仅仅是模型缩放。结构化记忆对空间理解至关重要，为开发更可靠的地图推理应用提供指导。

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [27] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 研究分析LLMs在代表性不足的数学竞赛问题上的表现，发现DeepSeek-V3在微积分、解析几何和离散数学中表现最佳，所有模型在几何领域表现最弱，不同模型有各自的错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多使用相同数据集评估LLMs的数学推理能力，限制了研究结果的普适性，无法全面捕捉数学任务中的多样化挑战。本研究旨在分析LLMs在代表性不足的数学竞赛问题上的表现。

Method: 使用密苏里大学数学竞赛题目（涵盖微积分、解析几何和离散数学）测试三个领先LLMs（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3），将模型回答与已知正确答案比较以确定准确性，并分析推理过程以探索错误模式。

Result: DeepSeek-V3在所有三个数学类别中表现最佳（推理和最终答案都最好）。所有三个LLMs在几何领域表现显著较弱。DeepSeek-V3错误主要源于计算和逻辑错误，GPT-4o-mini常见逻辑和方法相关错误，Gemini则倾向于不完整推理和草率结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估LLMs可以提供对其独特错误模式的深入洞察，并突显结构化推理方面的持续挑战，特别是在几何领域。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [28] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段方法，将空间推理分解为原子构建块及其组合，通过监督微调学习基本空间变换，再训练轻量级LoRA适配器进行多步规划，在ASCII艺术环境中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在通用语言能力上表现强大，但在结构化环境中的空间变换和多步规划方面仍然存在困难，这限制了其在导航和规划等应用中的效果。

Method: 两阶段方法：1) 对基本空间变换（旋转、平移、缩放）进行监督微调，使模型具备基础空间物理知识；2) 冻结物理感知模型，在GRPO框架内训练轻量级LoRA适配器，学习将这些构建块组合用于谜题环境中的多步闭环规划。为此合成了ASCII艺术数据集并构建了相应的强化学习环境。

Result: 该方法在动态环境（显式状态更新）和静态环境（模型必须依赖内部状态）中均一致优于基线方法，包括通用骨干模型、物理感知模型和端到端RL模型。此外，该方法收敛更快，训练更稳定，注意力模式分析显示微调确实改善了空间理解能力。

Conclusion: 通过将空间推理分解为原子构建块及其组合的两阶段方法，可以有效提升大语言模型在结构化环境中的空间推理能力，为导航和规划等应用提供了更可靠的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [29] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: MCPAgentBench：一个基于真实MCP定义构建的基准测试，用于评估LLM代理的工具使用能力，包含真实任务、模拟工具和动态沙箱环境，测试工具选择和辨别能力。


<details>
  <summary>Details</summary>
Motivation: 当前MCP评估集存在依赖外部MCP服务和缺乏难度感知的问题，需要更好的基准来评估LLM代理的工具使用能力。

Method: 构建包含真实任务和模拟MCP工具的数据集，使用动态沙箱环境，向代理提供包含干扰项的工具候选列表，测试其工具选择和辨别能力，并引入综合指标衡量任务完成率和执行效率。

Result: 实验显示不同主流大语言模型在处理复杂多步工具调用时存在显著性能差异。

Conclusion: MCPAgentBench是一个有效的基准测试，能够评估LLM代理的工具使用能力，所有代码已在GitHub开源。

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [30] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: RLMs通过递归调用LLM处理超长提示，将长提示作为外部环境，实现超出模型上下文窗口两个数量级的输入处理，在四个长上下文任务中显著优于基础LLM和常见长上下文框架。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型处理任意长提示的问题，突破模型上下文窗口的限制，提高长上下文处理的质量和效率。

Method: 提出递归语言模型（RLMs），将长提示视为外部环境，允许LLM以编程方式检查、分解并递归调用自身处理提示片段。

Result: RLMs成功处理超出模型上下文窗口两个数量级的输入，在四个多样化长上下文任务中，即使对于较短提示，也显著优于基础LLM和常见长上下文框架，同时查询成本相当或更低。

Conclusion: RLMs是一种有效的推理策略，能够显著扩展LLM处理长提示的能力，在保持成本效益的同时大幅提升处理质量。

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [31] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 提出一个强化学习增强的LLM多智能体框架，通过Dec-POMDP建模合作，采用CTDE训练，引入GRPO优化策略，在协作写作和编程任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语言任务中表现良好，但在多智能体环境中缺乏协作意识，难以优化全局性能。需要解决LLM在多智能体协作中的协调问题。

Method: 将合作建模为去中心化部分可观察马尔可夫决策过程（Dec-POMDP），采用集中训练分散执行（CTDE）框架，引入组相对策略优化（GRPO）联合优化智能体策略，使用简化的联合奖励平衡任务质量、速度和协调成本。

Result: 在协作写作和编程基准测试中：任务处理速度比单智能体基线提高3倍；写作任务达到98.7%的结构/风格一致性；编程任务达到74.6%的测试通过率。框架持续优于强大的多智能体LLM基线。

Conclusion: 该框架为复杂工作流中的可靠协作提供了实用路径，通过强化学习增强LLM多智能体协作能力，显著提升协作效率和任务质量。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [32] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 提出基于群体审议的多智能体对话模型，通过三层角色架构（生成、验证、整合）和自博弈机制，显著提升复杂推理任务的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在复杂推理任务中存在局限性，需要多智能体协作来提升推理能力和事实一致性。

Method: 采用三层角色架构：意见生成智能体产生多样化推理视角，证据验证智能体检索外部知识并量化事实支持度，一致性仲裁智能体整合逻辑连贯的结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计结合事实一致性和逻辑连贯性的复合奖励函数，应用改进的近端策略优化进行协作训练。

Result: 在HotpotQA上多跳推理准确率提升16.8%，2WikiMultihopQA提升14.3%，MeetingBank提升19.2%，一致性提升21.5%，推理效率高于主流多智能体方法。

Conclusion: 该模型为复杂推理任务提供了有效且稳定的解决方案，通过多智能体协作显著提升了推理准确性和一致性。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [33] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: Youtu-Agent：一个模块化LLM代理框架，支持自动生成和持续进化，解决高配置成本和静态能力问题，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理框架面临两大挑战：1）高配置成本 - 构建高质量代理需要大量手动工具集成和提示工程；2）静态能力 - 部署后的代理难以适应动态环境，需要昂贵的微调。

Method: 提出模块化框架Youtu-Agent，包含结构化配置系统（解耦执行环境、工具包和上下文管理），支持两种生成范式：Workflow模式用于标准任务，Meta-Agent模式用于复杂需求。建立混合策略优化系统：Agent Practice模块通过上下文优化积累经验，Agent RL模块集成分布式训练框架进行大规模强化学习。

Result: 在WebWalkerQA（71.47%）和GAIA（72.8%）上达到SOTA性能；自动化生成管道工具合成成功率超81%；Practice模块在AIME 2024/2025上分别提升2.7%和5.4%；Agent RL训练在7B LLMs上实现40%加速，数学和通用/多跳QA基准上分别提升35%和21%。

Conclusion: Youtu-Agent通过自动化生成和持续进化机制，有效解决了LLM代理的高配置成本和静态能力问题，为构建自适应智能代理提供了系统化解决方案。

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [34] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 提出多模态跨域混合融合与双重解耦的故障诊断模型，解决现有方法在未见工况下性能下降及单模态信息局限问题


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法在真实场景未见工况下性能显著下降，域适应方法依赖目标域样本，且大多依赖单模态信号，忽略了多模态信息的互补性

Method: 提出多模态跨域混合融合模型：1）双重解耦框架分离模态不变/特定特征和域不变/特定表示；2）跨域混合融合策略随机混合跨域模态信息；3）三模态融合机制自适应集成多模态异构信息

Result: 在感应电机故障诊断实验中，该方法在未见恒定和时变工况下均优于先进方法，消融研究验证了各组件和多模态融合的有效性

Conclusion: 提出的多模态跨域混合融合模型通过双重解耦和跨域融合，实现了更好的故障诊断泛化性能，解决了现有方法的局限性

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [35] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 论文提出了一种可解释的家庭物品摆放偏好模型，包含四个维度：空间实用性、习惯便利性、语义一致性和常识适当性，并通过问卷验证和MCTS规划器应用


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统依赖从人类演示中推断的潜在偏好模型，虽然预测有效但缺乏可解释性，无法理解指导人类决策的因素

Method: 设计了包含四个可解释维度的物品摆放偏好问卷，通过63名参与者的在线研究验证；将参与者偏好整合到蒙特卡洛树搜索规划器中

Result: 验证了四个心理维度的区分性和解释力；基于参与者偏好的规划器能生成与参与者摆放高度一致且合理的物品布置

Conclusion: 提出了紧凑、可解释的物品摆放偏好模型，并展示了如何将其应用于机器人规划，为可解释的家庭机器人系统提供了新方法

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [36] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ是一种混合模型，通过可解释的语义特征桥接基础模型和统计建模。它通过迭代过程发现数据集特定的语义特征，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具有广泛的领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式。基础模型依赖通用领域知识，而忽略了数据集特有的重要模式。

Method: 通过迭代过程发现语义特征描述，对比统计建模错误识别的项目组。采用广义EM算法联合优化语义特征描述符和统计模型参数，将冻结的基础模型判断作为潜在二元特征的噪声观测。

Result: 在房价预测中，使用多模态列表数据发现的语义特征实现12%中位数相对误差，显著优于GPT-5基线（38%误差）。在Netflix电影推荐中，仅从语义描述预测协同过滤表示，达到0.59余弦相似度，相当于传统协同过滤需要约4000用户评分的性能。

Conclusion: GenZ成功桥接了基础模型和统计建模，通过发现数据集特定的语义特征显著提升了预测性能，揭示了与模型领域知识不同的重要模式。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [37] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 提出一种使用约束模板从养老院管理者访谈中提取设施特定约束条件的方法，用于生成护理人员排班表


<details>
  <summary>Details</summary>
Motivation: 养老机构的排班条件因设施而异，需要从制定排班的管理者访谈中提取设施特定的约束条件，但现有约束提取技术难以处理例外约束

Method: 使用约束模板提取连续工作日排班模式、员工组合等各种组件的组合，通过改变天数、员工数量、提取焦点（模式或频率）来提取多样约束，并包含排除例外约束的机制

Result: 实验表明，该方法成功创建了满足所有硬约束的排班表，并通过避免提取例外约束，减少了软约束的违反次数

Conclusion: 提出的约束模板方法能够有效提取养老机构特定的约束条件，生成满足约束的护理人员排班表，解决了现有技术难以处理例外约束的问题

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [38] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: ALE是一个端到端的智能体学习生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具，并发布了基于ALE训练的ROME智能体模型，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏一个原则性的端到端生态系统来简化智能体开发流程，需要基础设施来优化智能体LLM的生产管道。

Method: 提出ALE生态系统，包含三个组件：ROLL（权重优化后训练框架）、ROCK（轨迹生成的沙盒环境管理器）和iFlow CLI（高效上下文工程的智能体框架）。开发了ROME智能体模型，使用超过100万条轨迹进行训练，包括数据组合协议和新的策略优化算法IPA（基于交互的策略对齐）。

Result: ROME在SWE-bench Verified和Terminal Bench等基准测试中表现出色，证明了ALE基础设施的有效性。还引入了Terminal Bench Pro基准测试，改进了规模和污染控制。

Conclusion: ALE提供了一个完整的基础设施来优化智能体LLM的生产管道，ROME智能体的成功验证了该生态系统的有效性，为开源智能体开发提供了重要工具。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [39] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 开发了一个用于波兰驾驶场景数据标注的半自动化流水线，结合AI与人工标注，显著降低标注成本和时间


<details>
  <summary>Details</summary>
Motivation: DARTS项目需要创建大规模波兰驾驶场景多模态数据集，但手动标注异构数据成本高、耗时长

Method: 采用人在回路方法，结合AI与人工专业知识，包括自动生成初始标注、迭代模型重训练、数据匿名化和领域适应技术，核心使用3D目标检测算法

Result: 工具和方法显著节省时间，确保跨不同传感器模态的一致高质量标注，加速了DARTS项目标准化格式标注数据集的准备

Conclusion: 该解决方案有效支持DARTS项目，加速大规模标注数据集的准备，为波兰自动驾驶研究强化了技术基础

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [40] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 迭代部署LLM并通过用户数据筛选进行微调，可以显著改变模型特性，在规划任务中实现能力提升和泛化，这本质上是一种隐式强化学习过程。


<details>
  <summary>Details</summary>
Motivation: 研究迭代部署大型语言模型时，用户从先前模型部署中精心筛选数据进行微调，会对后续模型产生何种影响，以及这种机制的内在原理。

Method: 在不同规划领域测试迭代部署机制：每次部署LLM后，用户从模型输出中筛选数据用于微调下一个模型，形成迭代循环。

Result: 模型规划能力显著提升，后期模型展现出泛化能力，能够发现比初始模型长得多的规划方案。

Conclusion: 迭代部署本质上是一种隐式强化学习，其奖励函数未明确定义，对AI安全有重要影响；同时这也是一种替代显式RL的训练机制，依赖数据筛选而非明确奖励。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [41] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent是一个专门用于时空理解的智能体大语言模型，能够处理受限兴趣点发现和行程规划等复杂任务，通过工具交互和分层训练方法在保持通用能力的同时提升时空任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理复杂的时空理解任务（如受限兴趣点发现和行程规划）时存在局限性，需要专门的智能体模型来更好地与时空工具交互，同时保持模型的通用能力。

Method: 1. 构建包含10个领域特定工具的稳定工具环境，支持异步部署和训练；2. 设计分层数据筛选框架，以1:10,000的比例从海量数据中筛选高质量查询，强调多样性和难度；3. 采用级联训练方法：种子SFT阶段作为"守护者"评估查询难度，第二SFT阶段针对高确定性查询微调，最终RL阶段利用低确定性数据。

Result: STAgent在TravelBench基准测试中表现出色，同时在广泛的通用基准测试中保持了其通用能力，证明了所提出的智能体模型的有效性。模型基于Qwen3-30B-A3B初始化，建立了强大的SFT基础。

Conclusion: STAgent通过专门的工具环境、高质量数据筛选和级联训练方法，成功创建了一个在时空理解任务上表现优异且保持通用能力的智能体大语言模型，为复杂时空任务提供了有效解决方案。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>


### [42] [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)
*Tianzhi He,Farrokh Jazizadeh*

Main category: cs.AI

TL;DR: 提出基于大语言模型的建筑能源管理系统AI代理框架，通过自然语言交互实现智能建筑的上下文感知能源管理，在设备控制、能源分析等任务上表现良好，但在成本估算等复杂任务上仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有能源管理系统存在局限性，需要更智能、上下文感知的解决方案。通过利用大语言模型的自主数据分析能力，为智能建筑提供自然语言交互的能源管理，解决传统系统的不足。

Method: 提出包含三个模块的概念框架：感知（传感）、中央控制（大脑）和行动（执行与用户交互），形成闭环反馈系统。使用120个用户查询在四个真实住宅能源数据集上评估原型性能，评估指标包括延迟、功能、能力、准确性和成本效益。

Result: 原型在设备控制（86%准确率）、记忆相关任务（97%）、调度与自动化（74%）和能源分析（77%）方面表现良好，但成本估算任务准确率较低（49%）。通过ANOVA测试验证了框架的普适性。

Conclusion: 该研究为基于LLM的BEMS AI代理的评估提供了框架，展示了在智能建筑能源管理中的潜力，同时指出了响应准确性与计算效率之间的权衡，为未来研究指明了方向。

Abstract: This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Hierarchical Quasi-cyclic Codes from Reed-Solomon and Polynomial Evaluation Codes](https://arxiv.org/abs/2512.23872)
*Emily McMillon,Kathryn Haymaker*

Main category: cs.IT

TL;DR: 本文首次提出代数构造的分层准循环码，基于Reed-Solomon码和Kautz-Singleton叠加码构造，展示了层次数和索引由域大小决定的性质。


<details>
  <summary>Details</summary>
Motivation: 现有相关编码构造主要基于仿真方法，缺乏代数分析。本文旨在通过代数方法为分层准循环码提供新的参数界限，建立严格的数学基础。

Method: 使用Reed-Solomon码和Kautz-Singleton（1964）的叠加码构造方法，代数构造分层准循环码。特别关注维度k=2的RS码，分析其Tanner图的周长等性质。

Result: 证明了层次数和索引由域大小决定；给出了小参数代码表，部分达到已知最佳最小距离；k=2的RS码产生Tanner图周长为6的分层准循环码；提供了秩和距离等参数的新界限。

Conclusion: 本文首次代数构造分层准循环码，建立了严格的数学框架，为相关编码提供了新的参数界限，弥补了现有文献主要依赖仿真的不足。

Abstract: We introduce the first example of algebraically constructed hierarchical quasi-cyclic codes. These codes are built from Reed-Solomon codes using a 1964 construction of superimposed codes by Kautz and Singleton. We show both the number of levels in the hierarchy and the index of these Reed-Solomon derived codes are determined by the field size. We show that this property also holds for certain additional classes of polynomial evaluation codes.
  We provide explicit code parameters and properties as well as some additional bounds on parameters such as rank and distance. In particular, starting with Reed-Solomon codes of dimension $k=2$ yields hierarchical quasi-cyclic codes with Tanner graphs of girth 6.
  We present a table of small code parameters and note that some of these codes meet the best known minimum distance for binary codes, with the additional hierarchical quasi-cyclic structure. We draw connections to similar constructions in the literature, but importantly, while existing literature on related codes is largely simulation-based, we present a novel algebraic approach to determining new bounds on parameters of these codes.

</details>


### [44] [Continuous Angular Power Spectrum Recovery From Channel Covariance via Chebyshev Polynomials](https://arxiv.org/abs/2512.24039)
*Shengsong Luo,Ruilin Wu,Chongbin Xu,Junjie Ma,Xiaojun Yuan,Xin Wang*

Main category: cs.IT

TL;DR: 提出基于切比雪夫多项式展开的连续角功率谱恢复框架，将病态反演问题转化为有限维线性回归，通过半定规划表征非负约束，实现准确的重构和频分双工场景下的协方差预测。


<details>
  <summary>Details</summary>
Motivation: 在多天线系统中，从信道协方差恢复连续角功率谱是一个病态反演问题。现有方法通常需要离散化或强假设，难以同时保证准确性和计算效率。需要一种能够有效利用角功率谱平滑性和非负性的数学框架。

Method: 利用切比雪夫多项式在变换域中的正交性，推导协方差的精确级数表示。通过截断将病态反演转化为有限维线性回归问题。提出基于导数的正则化器促进平滑变化，同时保持簇的过渡特征。使用半定规划精确表征角功率谱的非负约束。

Result: 仿真结果表明，所提出的切比雪夫框架能够准确重构角功率谱。在频分双工场景下，能够从上行链路测量可靠预测下行链路协方差。框架性能随角平滑度的增加而快速收敛。

Conclusion: 在切比雪夫域中联合利用平滑性和非负性，为多天线系统中的协方差域处理提供了有效工具。该方法将病态反演问题转化为可解的优化问题，在保持计算效率的同时实现了准确的重构和预测。

Abstract: This paper proposes a Chebyshev polynomial expansion framework for the recovery of a continuous angular power spectrum (APS) from channel covariance. By exploiting the orthogonality of Chebyshev polynomials in a transformed domain, we derive an exact series representation of the covariance and reformulate the inherently ill-posed APS inversion as a finite-dimensional linear regression problem via truncation. The associated approximation error is directly controlled by the tail of the APS's Chebyshev series and decays rapidly with increasing angular smoothness. Building on this representation, we derive an exact semidefinite characterization of nonnegative APS and introduce a derivative-based regularizer that promotes smoothly varying APS profiles while preserving transitions of clusters. Simulation results show that the proposed Chebyshev-based framework yields accurate APS reconstruction, and enables reliable downlink (DL) covariance prediction from uplink (UL) measurements in a frequency division duplex (FDD) setting. These findings indicate that jointly exploiting smoothness and nonnegativity in a Chebyshev domain provides an effective tool for covariance-domain processing in multi-antenna systems.

</details>


### [45] [Random Multiplexing](https://arxiv.org/abs/2512.24087)
*Lei Liu,Yuhao Chi,Shunqi Huang,Zhaoyang Zhang*

Main category: cs.IT

TL;DR: 提出随机复用技术，通过构建随机变换域中的等效输入各向同性信道矩阵，实现统计衰落信道遍历性，支持任意范数有界、谱收敛信道矩阵，并保证AMP类检测器的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: 传统复用技术（如SC-FDE、OFDM、OTFS、AFDM）依赖特定信道结构，在动态现实环境中鲁棒性有限。需要一种与物理信道解耦的复用技术，适用于任意范数有界、谱收敛的信道矩阵。

Method: 提出随机复用技术，在随机变换域中构建等效输入各向同性信道矩阵。采用低复杂度跨域记忆AMP（CD-MAMP）检测器，利用时域信道稀疏性和等效信道随机性。推导最优功率分配以最小化BER和最大化容量。

Result: 随机复用技术保证AMP类检测器对任意范数有界、谱收敛信道矩阵的渐近最优性。CD-MAMP检测器在随机复用系统中具有最优编码原理和容量最优性。该技术在各种无线应用中展现出良好适应性。

Conclusion: 随机复用技术提供了一种与信道结构解耦的通用框架，在动态环境中具有更好的鲁棒性和适应性，为未来无线通信系统提供了有前景的解决方案。

Abstract: As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.

</details>


### [46] [When Wires Can't Keep Up: Reconfigurable AI Data Centers Empowered by Terahertz Wireless Communications](https://arxiv.org/abs/2512.24110)
*Chong Han,Mingjie Zhu,Wenqi Zhao,Ziming Yu,Guolong Huang,Guangjian Wang,Wen Tong,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出太赫兹无线数据中心（THz-WDC）愿景，利用太赫兹频段实现超高带宽、低延迟、高能效的AI数据中心互连，以解决传统铜缆和光缆在可扩展性方面的限制。


<details>
  <summary>Details</summary>
Motivation: AI工作负载的爆炸式增长对数据中心互连架构提出了革命性需求。传统铜缆和光缆在延迟、功耗和刚性方面面临根本性挑战，限制了分布式AI集群的可扩展性。

Method: 提出太赫兹无线数据中心架构，探索数字孪生编排、低复杂度波束操纵技术、全硅太赫兹收发器、低复杂度模拟基带架构等关键技术，并进行数值分析比较太赫兹与光缆/铜缆的性能。

Result: 太赫兹无线链路可实现单链路1Tbps、通过空间复用达10Tbps总吞吐量、单跳延迟低于50ns、20米距离内低于10pJ/bit的能效，在特定距离和吞吐量领域超越传统有线解决方案。

Conclusion: 太赫兹无线互连为实现无线定义、可重构、可持续的AI数据中心提供了技术路线图，特别适用于未来量子计算和chiplet模块化架构的灵活互连需求。

Abstract: The explosive growth of artificial intelligence (AI) workloads in modern data centers demands a radical transformation of interconnect architectures. Traditional copper and optical wiring face fundamental challenges in latency, power consumption, and rigidity, constraining the scalability of distributed AI clusters. This article introduces a vision for Terahertz (THz) Wireless Data Center (THz-WDC) that combines ultra-broadband capacity, one-hop low-latency communication, and energy efficiency in the short-to-medium range (1-100m). Performance and technical requirements are first articulated, including up to 1 Tbps per link, aggregate throughput up to 10 Tbps via spatial multiplexing, sub-50 ns single-hop latency, and sub-10 pJ/bit energy efficiency over 20m. To achieve these ambitious goals, key enabling technologies are explored, including digital-twin-based orchestration, low-complexity beam manipulation technologies, all-silicon THz transceivers, and low-complexity analog baseband architectures. Moreover, as future data centers shift toward quantum and chiplet-based modular architectures, THz wireless links provide a flexible mechanism for interconnecting, testing, and reconfiguring these modules. Finally, numerical analysis is presented on the latency and power regimes of THz versus optical and copper interconnects, identifying the specific distance and throughput domains where THz links can surpass conventional wired solutions. The article concludes with a roadmap toward wireless-defined, reconfigurable, and sustainable AI data centers.

</details>


### [47] [Efficient Decoding of Twisted GRS Codes and Roth--Lempel Codes](https://arxiv.org/abs/2512.24217)
*Runtian Zhu,Lingfei Jin*

Main category: cs.IT

TL;DR: 本文提出了针对扭曲广义Reed-Solomon码和Roth-Lempel码的高效列表解码和唯一解码算法，运行时间接近线性，显著改进现有二次时间算法，并首次为Roth-Lempel码提供高效解码器。


<details>
  <summary>Details</summary>
Motivation: MDS码在实践中应用广泛，但大多数已知MDS码都是广义Reed-Solomon码，非GRS码相对研究较少。研究非GRS码既有理论意义，也有实际价值，因为GRS码的强代数结构在密码学中可能不受欢迎。扭曲GRS码和Roth-Lempel码是两类重要的非GRS码，虽然已有大量构造和结构分析工作，但解码问题研究相对不足。

Method: 基于Guruswami-Sudan算法，为扭曲GRS码和Roth-Lempel码设计列表解码和唯一解码算法。算法在合适参数条件下实现接近线性的运行时间。对于扭曲GRS码，支持最多O(n^2)个扭曲的固定速率码；对于Roth-Lempel码，首次提供高效解码器。还将代数操作检测码集成到列表解码框架中。

Result: 算法运行时间从先前已知的二次时间改进为接近线性时间。扭曲GRS解码器支持最多O(n^2)个扭曲，显著扩展了仅处理单扭曲情况的先前工作。为Roth-Lempel码提供了首个高效解码器。列表解码器在广泛参数范围内超越了经典唯一解码半径。通过集成AMD码，能以高概率从输出列表中恢复正确消息。

Conclusion: 本文为非GRS MDS码的解码问题提供了高效解决方案，显著改进了扭曲GRS码和Roth-Lempel码的解码性能，填补了Roth-Lempel码解码器的空白，并通过集成AMD码增强了列表解码的实用性。

Abstract: MDS codes play a central role in practice due to their broad applications. To date, most known MDS codes are generalized Reed-Solomon (GRS) codes, leaving codes that are not equivalent to GRS codes comparatively less understood. Studying this non-GRS regime is therefore of intrinsic theoretical interest, and is also practically relevant since the strong algebraic structure of GRS codes can be undesirable in cryptographic settings. Among the known non-GRS codes, twisted generalized Reed-Solomon (TGRS) codes and Roth-Lempel codes are two representative families of non-GRS codes that have attracted significant attention. Though substantial work has been devoted to the construction and structural analysis of TGRS and Roth-Lempel codes, comparatively little attention has been paid to their decoding, and many problems remain open. In this paper, we propose list and unique decoding algorithms for TGRS codes and Roth-Lempel codes based on the Guruswami-Sudan algorithm. Under suitable parameter conditions, our algorithms achieve near-linear running time in the code length, improving upon the previously best-known quadratic-time complexity. Our TGRS decoder supports fixed-rate TGRS codes with up to O(n^2) twists, substantially extending prior work that only handled the single-twist case. For Roth-Lempel codes, we provide what appears to be the first efficient decoder. Moreover, our list decoders surpass the classical unique-decoding radius for a broad range of parameters. Finally, we incorporate algebraic manipulation detection (AMD) codes into the list-decoding framework, enabling recovery of the correct message from the output list with high probability.

</details>


### [48] [SC-LDPC Codes Over $\mathbb{F}_q$: Minimum Distance, Decoding Analysis and Threshold Saturation](https://arxiv.org/abs/2512.24232)
*Jiaxin Lyu,Guanghui He*

Main category: cs.IT

TL;DR: 本文研究了有限域上的随机空间耦合LDPC码，提出了改进型耦合结构，证明了其具有渐进良好的最小距离和停止集尺寸，并建立了通用阈值饱和理论。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上空间耦合LDPC码的性能，特别是如何通过不同的变量节点边扩展规则来改善码的距离特性，并建立统一的迭代译码阈值分析框架。

Method: 定义了标准耦合和改进型耦合两种随机Tanner图结构，使用独立均匀随机单项式映射。建立了对称概率测度理论框架，分析了概率向量空间的性质和退化理论，用于分析q元输入对称信道的迭代译码阈值。

Result: 证明两种耦合结构都具有渐进良好的最小距离和最小停止集尺寸。改进型耦合结构比标准耦合结构具有更好的距离性能。建立了通用阈值饱和结果：随着耦合参数增加，置信传播阈值会饱和到一个仅取决于基本码集和信道族的确定阈值。

Conclusion: 有限域上的空间耦合LDPC码通过适当的耦合设计可以获得良好的距离特性，改进型耦合结构优于标准结构。建立的对称概率测度框架为分析q元对称信道上的迭代译码性能提供了理论基础，证明了阈值饱和现象的普遍性。

Abstract: We investigate random spatially coupled low-density parity-check (SC-LDPC) code ensembles over finite fields. Under different variable-node edge-spreading rules, the random Tanner graphs of several coupled ensembles are defined by multiple independent, uniformly random monomial maps. The two main coupled ensembles considered are referred to as the standard coupled ensemble and the improved coupled ensemble. We prove that both coupled ensembles exhibit asymptotically good minimum distance and minimum stopping set size. Theoretical and numerical results show that the improved coupled ensemble can achieve better distance performance than the standard coupled ensemble. We introduce the essential preliminaries and analytical tools needed to analyze the iterative decoding threshold of coupled ensembles over any finite field. We consider a class of memoryless channels with special symmetry, termed q-ary input memoryless symmetric channels (QMSCs), and show that, for these channels, the distribution of channel messages (in form of probability vectors) likewise exhibits this symmetry. Consequently, we define symmetric probability measures and their reference measures on a finite-dimensional probability simplex, analyze their foundational properties and those of their linear functionals, endow their respective spaces with metric topologies, and conduct an in-depth study of their degradation theory. Based on our analytical framework, we establish a universal threshold saturation result for both of the coupled ensembles over a q-ary finite field on QMSCs. Specifically, as the coupling parameters increase, the belief-propagation threshold of a coupled system saturates to a well-defined threshold that depends only on the underlying ensemble and the channel family.

</details>


### [49] [Infinite families of graphs and stable completion of arbitrary matrices, Part I](https://arxiv.org/abs/2512.24468)
*Augustin Cosse*

Main category: cs.IT

TL;DR: 研究确定性构造图，使得低秩矩阵在无论条目值如何的情况下都能唯一补全，将可补全性与特定模式（自避行走的并集）的存在联系起来，并设计无限图族使得固定秩矩阵可通过SOS层次结构实现精确稳定补全。


<details>
  <summary>Details</summary>
Motivation: 研究在低秩矩阵补全问题中，如何构造确定性图结构，使得无论矩阵条目值如何，都能保证唯一补全的可能性。这对于理解矩阵补全问题的图论结构基础具有重要意义。

Method: 将矩阵补全的可补全性与图结构中的特定模式（自避行走的并集）联系起来，分析这些模式在由双邻接矩阵支撑生成的格图子图中的存在性，并基于此构造无限图族。

Result: 建立了可补全性与图结构中特定模式之间的理论联系，并成功构造了无限图族，使得对于每个固定秩矩阵，都能通过和平方（SOS）层次结构实现精确且稳定的补全。

Conclusion: 通过图论方法为低秩矩阵补全问题提供了确定性构造框架，揭示了可补全性的图结构特征，并展示了如何设计图结构以保证补全的可行性和稳定性。

Abstract: We study deterministic constructions of graphs for which the unique completion of low rank matrices is generically possible regardless of the values of the entries. We relate the completability to the presence of some patterns (particular unions of self-avoiding walks) in the subgraph of the lattice graph generated from the support of the bi-adjacency matrix. The construction makes it possible to design infinite families of graphs on which exact and stable completion is possible for every fixed rank matrix through the sum-of-squares hierarchy.

</details>


### [50] [Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL](https://arxiv.org/abs/2512.24773)
*Anas K. Saeed,Mahmoud M. Salim,Ali Arshad Nasir,Ali H. Muqaibel*

Main category: cs.IT

TL;DR: 提出基于深度强化学习的无人机载RIS系统优化框架，解决三维抖动和信道不确定性下的吞吐量最大化问题，相比传统优化方法显著降低计算时间。


<details>
  <summary>Details</summary>
Motivation: 无人机载可重构智能表面(RIS)能按需重塑无线传播，但其性能对无人机抖动和级联信道不确定性敏感。现有方法在严重抖动和低信道质量下性能受限，且计算复杂度高。

Method: 采用模型无关的深度强化学习框架，结合上下文赌博机公式。使用可微分可行性层将连续动作映射到可行解，奖励函数为期望吞吐量的蒙特卡洛估计。实例化了不使用目标网络的约束型DDPG和TD3算法。

Result: 在严重抖动和低CSI质量下，所提算法比传统交替优化WMMSE基线获得更高吞吐量。在不同场景下，性能与基于样本平均近似的AO-WMMSE基准相当或略低（相对差距0-12%）。在线推理时间仅0.6ms/决策，而AO-WMMSE需要370-550ms。

Conclusion: 所提深度强化学习框架能有效处理无人机载RIS系统中的随机抖动和信道不确定性，在保持性能竞争力的同时显著降低计算时间，适合实时应用。

Abstract: Reconfigurable intelligent surfaces (RISs) mounted on unmanned aerial vehicles (UAVs) can reshape wireless propagation on-demand. However, their performance is sensitive to UAV jitter and cascaded channel uncertainty. This paper investigates a downlink multiple-input single-output UAV-mounted RIS system in which a ground multiple-antenna base station (BS) serves multiple single-antenna users under practical impairments. Our goal is to maximize the expected throughput under stochastic three-dimensional UAV jitter and imperfect cascaded channel state information (CSI) based only on the available channel estimates. This leads to a stochastic nonconvex optimization problem subject to a BS transmit power constraint and strict unit-modulus constraints on all RIS elements. To address this problem, we design a model-free deep reinforcement learning (DRL) framework with a contextual bandit formulation. A differentiable feasibility layer is utilized to map continuous actions to feasible solutions, while the reward is a Monte Carlo estimate of the expected throughput. We instantiate this framework with constrained variants of deep deterministic policy gradient (DDPG) and twin delayed deep deterministic policy gradient (TD3) that do not use target networks. Simulations show that the proposed algorithms yield higher throughput than conventional alternating optimization-based weighted minimum mean-square error (AO-WMMSE) baselines under severe jitter and low CSI quality. Across different scenarios, the proposed methods achieve performance that is either comparable to or slightly below the AO-WMMSE benchmark, based on sample average approximation (SAA) with a relative gap ranging from 0-12%. Moreover, the proposed DRL controllers achieve online inference times of 0.6 ms per decision versus roughly 370-550 ms for AO-WMMSE solvers.

</details>
