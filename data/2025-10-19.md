<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 52]
- [cs.IT](#cs.IT) [Total: 11]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Joint Active RIS Configuration and User Power Control for Localization: A Neuroevolution-Based Approach](https://arxiv.org/abs/2510.13819)
*George Stamatelis,Hui Chen,Henk Wymeersch,George C. Alexandropoulos*

Main category: cs.NI

TL;DR: 提出了一种基于RIS的用户定位方法，采用多智能体算法联合控制RIS相位配置和用户发射功率，结合神经进化和监督学习，仅需单比特反馈即可实现优于现有基准的性能。


<details>
  <summary>Details</summary>
Motivation: 研究RIS辅助的用户定位，通过基站到用户的反馈链路实现上行链路中用户导频传输的动态功率控制，提高定位精度和效率。

Method: 采用多智能体算法，结合神经进化(NE)和监督学习的混合方法，联合控制RIS相位配置和用户发射功率，支持离散响应的RIS元件，仅需单比特反馈消息。

Result: 数值实验表明，该方法在性能上优于指纹识别、深度强化学习基准和基于反向传播的位置估计器。

Conclusion: 提出的混合神经进化-监督学习方法能够有效解决RIS辅助的用户定位问题，在有限反馈条件下实现优越的定位性能。

Abstract: This paper studies user localization aided by a Reconfigurable Intelligent
Surface (RIS). A feedback link from the Base Station (BS) to the user is
adopted to enable dynamic power control of the user pilot transmissions in the
uplink. A novel multi-agent algorithm for the joint control of the RIS phase
configuration and the user transmit power is presented, which is based on a
hybrid approach integrating NeuroEvolution (NE) and supervised learning. The
proposed scheme requires only single-bit feedback messages for the uplink power
control, supports RIS elements with discrete responses, and is numerically
shown to outperform fingerprinting, deep reinforcement learning baselines and
backpropagation-based position estimators.

</details>


### [2] [Leveraging Wireless Sensor Networks for Real-Time Monitoring and Control of Industrial Environments](https://arxiv.org/abs/2510.13820)
*Muhammad Junaid Asif,Shazia Saqib,Rana Fayyaz Ahmad,Hamza Khan*

Main category: cs.NI

TL;DR: 提出基于NRF收发器和ARDUINO的物联网系统，通过无线传感器网络实时监测工业参数（温度、湿度、土壤湿度、火灾检测），并支持远程控制直流电机速度，提高工业操作效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决传统有线通信系统的局限性，减少物理监控需求，应对2020-2024年全球工业火灾频发的问题，提升工业自动化水平和安全响应能力。

Method: 使用NRF收发器构建无线传感器网络，ARDUINO微控制器驱动中央设置，集成多种传感器监测关键参数，通过互联网实现远程监控和控制功能。

Result: 系统成功实现了工业参数的实时监测和远程控制，无线通信创新在工业过程自动化和安全中发挥关键作用，为更智能、响应更快的操作环境铺平道路。

Conclusion: 物联网使能系统具有改变各种工业应用中监控和控制方式的潜力，能显著提高生产率和安全性，减少物理监控相关风险，在紧急情况下提供快速响应。

Abstract: This research proposes an extensive technique for monitoring and controlling
the industrial parameters using Internet of Things (IoT) technology based on
wireless communication. We proposed a system based on NRF transceivers to
establish a strong Wireless Sensor Network (WSN), enabling transfer of
real-time data from multiple sensors to a central setup that is driven by
ARDUINO microcontrollers. Different key parameters, crucial for industrial
setup such as temperature, humidity, soil moisture and fire detection, are
monitored and displayed on an LCD screen, enabling factory administration to
oversee the industrial operations remotely over the internet. Our proposed
system bypasses the need for physical presence for monitoring by addressing the
shortcomings of conventional wired communication systems. Other than
monitoring, there is an additional feature to remotely control these parameters
by controlling the speed of DC motors through online commands. Given the rising
incidence of industrial fires over the worldwide between 2020 and 2024 due to
an array of hazards, this system with dual functionality boosts the overall
operational efficiency and safety. This overall integration of IoT and Wireless
Sensor Network (WSN) reduces the potential risks linked with physical
monitoring, providing rapid responses in emergency scenarios, including the
activation of firefighting equipment. The results show that innovations in
wireless communication perform an integral part in industrial process
automation and safety, paving the way to more intelligent and responsive
operating environments. Overall, this study highlights the potential for change
of IoT-enabled systems to revolutionize monitoring and control in a variety of
industrial applications, resulting in increased productivity and safety.

</details>


### [3] [LLM Agent Communication Protocol (LACP) Requires Urgent Standardization: A Telecom-Inspired Protocol is Necessary](https://arxiv.org/abs/2510.13821)
*Xin Li,Mengbing Liu,Chau Yuen*

Main category: cs.NI

TL;DR: 提出LLM-Agent通信协议(LACP)，这是一个受电信启发的三层架构协议，旨在解决当前LLM代理通信的碎片化问题，确保语义清晰性、事务完整性和内置安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理的临时通信方法导致了碎片化生态系统，阻碍创新并带来显著风险，类似于早期网络协议战争的情况。

Method: 借鉴现代电信的分层标准化协议，提出LACP三层架构，确保通信语义清晰、复杂任务的事务完整性以及强大的内置安全机制。

Result: 提出了一个原则性、通用的通信协议框架，为分布式AI在多代理系统中的安全可靠运行奠定基础。

Conclusion: 采用原则性、通用协议对于实现分布式AI潜力至关重要，特别是在6G及更高级网络环境的复杂实时应用中。

Abstract: This position paper argues that the field of LLM agents requires a unified,
telecom-inspired communication protocol to ensure safety, interoperability, and
scalability, especially within the context of Next Generation (NextG) networks.
Current ad-hoc communication methods are creating a fragmented ecosystem,
reminiscent of the early "protocol wars" in networking, which stifles
innovation and poses significant risks. Drawing inspiration from the layered,
standardized protocols that underpin modern telecommunications, we propose the
LLM-Agent Communication Protocol (LACP). LACP establishes a three-layer
architecture designed to ensure semantic clarity in communication,
transactional integrity for complex tasks, and robust, built-in security. In
this position paper, we argue that adopting a principled, universal protocol is
not merely beneficial but essential for realizing the potential of distributed
AI. Such a standard is critical for ensuring that multi-agent systems can
operate safely and reliably in the complex, real-time applications envisioned
for 6G and beyond.

</details>


### [4] [A Simulator for FANETs Using 5G Vehicle-to-Everything Communications and Named-Data Networking](https://arxiv.org/abs/2510.13823)
*José Manuel Rúa-Estévez,Alicia Meleiro-Estévez,Pablo Fondo-Ferreiro,Felipe Gil-Castiñeira,Brais Sánchez-Rama,Lois Gomez-Gonzalez*

Main category: cs.NI

TL;DR: 开发了一个用于验证、评估和演示基于5G V2X通信和NDN范式的飞行自组网的模拟器


<details>
  <summary>Details</summary>
Motivation: 需要一种能够真实测试多无人机之间多跳通信应用的仿真工具

Method: 集成ns-3网络模拟器和Zenoh NDN协议

Result: 成功构建了能够模拟多无人机通信的仿真平台

Conclusion: 该模拟器为飞行自组网的验证和评估提供了有效的工具

Abstract: This work presents a simulator designed for the validation, evaluation, and
demonstration of flying adhoc networks (FANETs) using 5G vehicle-to-everything
(V2X) communications and the named-data networking (NDN) paradigm. The
simulator integrates the ns-3 network simulator and the Zenoh NDN protocol,
enabling realistic testing of applications that involve the multi-hop
communication among multiple unmanned aerial vehicles (UAVs).

</details>


### [5] [DiffLoc: Diffusion Model-Based High-Precision Positioning for 6G Networks](https://arxiv.org/abs/2510.14111)
*Taekyun Lee,Tommaso Balercia,Heasung Kim,Hyeji Kim,Jeffrey G. Andrews*

Main category: cs.NI

TL;DR: 提出了DiffLoc框架，使用条件生成扩散模型直接从大规模MIMO信道状态信息实现高精度室外用户定位，达到亚厘米级精度，比现有方法提升一个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统指纹定位方法难以扩展到大型动态室外环境，需要密集不切实际的数据采集。需要克服这些限制，直接从原始上行参考信号指纹学习到连续地理坐标的映射。

Method: 应用条件生成扩散模型处理高维大规模MIMO信道状态信息，通过一致性训练将推理步骤从200步减少到2步，学习从SRS指纹到地理坐标的直接映射。

Result: 在东京城市宏小区环境中，DiffLoc-CT模型实现0.5厘米融合精度和1-2厘米单基站精度，比监督回归方法（超过10米误差）和基于网格的融合（3米误差）有数量级提升。

Conclusion: 该框架在高速用户（15-25 m/s）和未见用户轨迹下仍保持优异精度，证明了其实时6G应用的可行性。

Abstract: This paper introduces a novel framework for high-accuracy outdoor user
equipment (UE) positioning that applies a conditional generative diffusion
model directly to high-dimensional massive MIMO channel state information
(CSI). Traditional fingerprinting methods struggle to scale to large, dynamic
outdoor environments and require dense, impractical data surveys. To overcome
these limitations, our approach learns a direct mapping from raw uplink
Sounding Reference Signal (SRS) fingerprints to continuous geographic
coordinates. We demonstrate that our DiffLoc framework achieves unprecedented
sub-centimeter precision, with our best model (DiffLoc-CT) delivering 0.5 cm
fusion accuracy and 1-2 cm single base station (BS) accuracy in a realistic,
ray-traced Tokyo urban macro-cell environment. This represents an
order-of-magnitude improvement over existing methods, including supervised
regression approaches (over 10 m error) and grid-based fusion (3 m error). Our
consistency training approach reduces inference time from 200 steps to just 2
steps while maintaining exceptional accuracy even for high-speed users (15-25
m/s) and unseen user trajectories, demonstrating the practical feasibility of
our framework for real-time 6G applications.

</details>


### [6] [Energy-Latency Optimization for Dynamic 5G Mobile Radio Access Networks](https://arxiv.org/abs/2510.14214)
*Gabriela N. Caspa H.,Carlos A. Astudillo,Nelson L. S. da Fonseca*

Main category: cs.NI

TL;DR: 提出一个混合整数线性规划模型，用于优化5G RAN配置，平衡前传延迟和能耗，支持eMBB、URLLC和mMTC切片。


<details>
  <summary>Details</summary>
Motivation: 5G网络中基站解耦和新服务对RAN配置提出挑战，需要在满足带宽和延迟约束的同时降低能耗，因为RAN运营占运营商OPEX的主要部分。

Method: 使用混合整数线性规划模型，包含三个目标函数：最小化前传延迟、最小化能耗、以及平衡延迟和能耗的双目标优化。模型确定最优功能分割选项、RAN功能放置和路由。

Result: 揭示了延迟和能耗之间的权衡关系，强调需要动态RAN重配置。由于MILP执行时间长，提出了符合RAN约束的启发式算法。

Conclusion: 为优化现有和未来RAN部署提供了基础，通过动态配置平衡服务性能和成本效益能耗。

Abstract: In 5G networks, base station (BS) disaggregation and new services present
challenges in radio access network (RAN) configuration, particularly in meeting
their bandwidth and latency constraints. The BS disaggregation is enabled by
functional splitting (FS), which distributes the RAN functions in processing
nodes and alleviates latency and bandwidth requirements in the fronthaul (FH).
Besides network performance, energy consumption is a critical concern for
mobile network operators (MNO), since RAN operation constitutes a major portion
of their operational expenses (OPEX). RAN configuration optimization is
essential to balance service performance with cost-effective energy
consumption. In this paper, we propose a mixed-integer linear programming
(MILP) model formulated with three objective functions: (i) minimizing
fronthaul (FH) latency, (ii) minimizing energy consumption, and (iii) a
bi-objective optimization that jointly balances both latency and energy
consumption. The model determines the optimal FS option, RAN function
placement, and routing for eMBB, URLLC, and mMTC slices. Although prior studies
have addressed RAN configuration either from an energy minimization or latency
reduction perspective, few have considered both aspects in realistic scenarios.
Our evaluation spans different topologies, accounts for variations in
aggregated gNB demand, explores diverse FS combinations, and incorporates Time
Sensitive Networking (TSN) modeling for latency analysis, as it is also crucial
in RAN performance. Given that MILP's execution time can be significant, we
propose a heuristic algorithm that adheres to RAN constraints. Our results
reveal a trade-off between latency and energy consumption, highlighting the
need for dynamic RAN reconfiguration. These insights provide a foundation to
optimize existing and future RAN deployments.

</details>


### [7] [Automated Extraction of Protocol State Machines from 3GPP Specifications with Domain-Informed Prompts and LLM Ensembles](https://arxiv.org/abs/2510.14348)
*Miao Zhang,Runhan Feng,Hongbo Tang,Yu Zhao,Jie Yang,Hang Qiu,Qi Liu*

Main category: cs.NI

TL;DR: SpecGPT：利用大语言模型从3GPP文档自动提取协议状态机的新框架，在5G协议建模中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 移动通信网络对关键基础设施至关重要，但现有手动建模方法劳动密集、易出错且难以维护，需要自动化解决方案来处理复杂且频繁更新的3GPP规范

Method: 将技术规范分割成有意义的段落，应用领域知识引导的提示与思维链推理，并采用集成方法提高输出可靠性

Result: 在三个代表性5G协议（NAS、NGAP和PFCP）上使用人工标注真实数据进行评估，表现优于现有方法

Conclusion: 证明了LLM在大规模协议建模中的有效性，为复杂通信协议自动化建模提供了可行方案

Abstract: Mobile telecommunication networks are foundational to global infrastructure
and increasingly support critical sectors such as manufacturing,
transportation, and healthcare. The security and reliability of these networks
are essential, yet depend heavily on accurate modeling of underlying protocols
through state machines. While most prior work constructs such models manually
from 3GPP specifications, this process is labor-intensive, error-prone, and
difficult to maintain due to the complexity and frequent updates of the
specifications. Recent efforts using natural language processing have shown
promise, but remain limited in handling the scale and intricacy of cellular
protocols. In this work, we propose SpecGPT, a novel framework that leverages
large language models (LLMs) to automatically extract protocol state machines
from 3GPP documents. SpecGPT segments technical specifications into meaningful
paragraphs, applies domain-informed prompting with chain-of-thought reasoning,
and employs ensemble methods to enhance output reliability. We evaluate SpecGPT
on three representative 5G protocols (NAS, NGAP, and PFCP) using manually
annotated ground truth, and show that it outperforms existing approaches,
demonstrating the effectiveness of LLMs for protocol modeling at scale.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context](https://arxiv.org/abs/2510.13858)
*Raheleh Biglari,Joachim Denil*

Main category: cs.AI

TL;DR: 提出了一种基于决策一致性的模型有效性验证方法DOTechnique，通过评估替代模型与高保真模型是否产生相同决策来确定模型有效性区域，无需预定义有效性边界。


<details>
  <summary>Details</summary>
Motivation: 模型有效性对决策过程至关重要，但传统方法依赖预定义有效性框架，这些框架可能不可用或不充分。

Method: DOTechnique方法通过决策一致性而非输出相似性来评估模型有效性，结合领域约束和符号推理来缩小搜索空间，提高计算效率。

Result: 以高速公路变道系统为例，展示了DOTechnique能够发现仿真模型的有效性区域。

Conclusion: 该技术通过决策者上下文支持模型有效性发现，具有重要潜力。

Abstract: Model validity is as critical as the model itself, especially when guiding
decision-making processes. Traditional approaches often rely on predefined
validity frames, which may not always be available or sufficient. This paper
introduces the Decision Oriented Technique (DOTechnique), a novel method for
determining model validity based on decision consistency rather than output
similarity. By evaluating whether surrogate models lead to equivalent decisions
compared to high-fidelity models, DOTechnique enables efficient identification
of validity regions, even in the absence of explicit validity boundaries. The
approach integrates domain constraints and symbolic reasoning to narrow the
search space, enhancing computational efficiency. A highway lane change system
serves as a motivating example, demonstrating how DOTechnique can uncover the
validity region of a simulation model. The results highlight the potential of
the technique to support finding model validity through decision-maker context.

</details>


### [9] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 该论文提出了一种融合视觉信息（演讲者图像和演示幻灯片）的多模态自动语音识别方法，特别针对科学演讲场景，通过数据增强技术解决了数据集不足的问题，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 现有的SOTA ASR系统主要依赖声学信息而忽略了多模态上下文。视觉信息在消歧和适应中至关重要，特别是在科学演讲场景中，演示幻灯片包含重要的领域特定术语信息。

Method: 首先创建多模态演讲基准，包括领域特定术语的自动分析；然后探索用多模态信息增强语音模型的方法；通过数据增强技术解决缺乏配套幻灯片数据集的问题；最后使用增强数据集训练模型。

Result: 训练得到的模型在所有词汇上的词错误率相对降低了约34%，在领域特定术语上的词错误率相对降低了35%，相比基线模型有显著提升。

Conclusion: 多模态信息（特别是演示幻灯片）的集成能显著提升ASR系统在科学演讲场景中的性能，尤其是在处理领域特定术语方面效果明显。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [10] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在零相关情境下会系统性地产生因果幻觉，错误推断因果关系，这表明它们可能只是模仿因果语言而非真正理解因果关系。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否会在经典认知科学范式——列联判断任务中产生因果幻觉，这种认知偏差被认为是许多社会问题的根源。

Method: 构建了1000个医学领域的零相关情境数据集，在这些情境中可用信息不足以建立变量间的因果关系，然后让LLMs评估潜在原因的有效性。

Result: 所有评估的模型都系统性地推断出无根据的因果关系，显示出对因果幻觉的强烈易感性。

Conclusion: 研究结果支持LLMs只是复制因果语言而非真正理解因果关系的假设，对在需要准确因果推理的领域中使用语言模型提出了担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [11] [GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations](https://arxiv.org/abs/2510.14035)
*Rajesh Mangannavar,Prasad Tadepalli*

Main category: cs.AI

TL;DR: GammaZero提出了一种基于动作中心图表示的学习框架，用于在部分可观察马尔可夫决策过程中指导规划。该方法通过图神经网络学习小规模问题的价值函数和策略，然后将其应用于更大规模问题的蒙特卡洛树搜索中，实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要领域特定的神经网络架构且难以扩展，GammaZero旨在开发一个统一的基于图的信念表示框架，能够在领域内跨问题规模实现泛化。

Method: 将信念状态系统性地转换为动作中心图，利用图神经网络和编码器架构从专家演示中学习价值函数和策略，然后将学习到的启发式方法应用于更大问题的蒙特卡洛树搜索。

Result: 在标准POMDP基准测试中，GammaZero在相同规模问题上与BetaZero性能相当，同时能够零样本泛化到训练时未见过的2-4倍大规模问题，在保持解质量的同时减少搜索需求。

Conclusion: GammaZero通过动作中心图表示实现了在POMDP中的可扩展规划，证明了学习到的结构模式可以从小问题迁移到大问题，为大规模部分可观察环境中的规划提供了有效解决方案。

Abstract: We introduce an action-centric graph representation framework for learning to
guide planning in Partially Observable Markov Decision Processes (POMDPs).
Unlike existing approaches that require domain-specific neural architectures
and struggle with scalability, GammaZero leverages a unified graph-based belief
representation that enables generalization across problem sizes within a
domain. Our key insight is that belief states can be systematically transformed
into action-centric graphs where structural patterns learned on small problems
transfer to larger instances. We employ a graph neural network with a decoder
architecture to learn value functions and policies from expert demonstrations
on computationally tractable problems, then apply these learned heuristics to
guide Monte Carlo tree search on larger problems. Experimental results on
standard POMDP benchmarks demonstrate that GammaZero achieves comparable
performance to BetaZero when trained and tested on the same-sized problems,
while uniquely enabling zero-shot generalization to problems 2-4 times larger
than those seen during training, maintaining solution quality with reduced
search requirements.

</details>


### [12] [Position: Require Frontier AI Labs To Release Small "Analog" Models](https://arxiv.org/abs/2510.14053)
*Shriyash Upadhyay,Chaithanya Bandi,Narmeen Oozeer,Philip Quirke*

Main category: cs.AI

TL;DR: 提出一种替代性监管方法：要求大型AI实验室发布小型开放访问的类比模型，这些模型是从其最大专有模型训练和蒸馏而来的缩小版本，以促进AI安全同时推动创新。


<details>
  <summary>Details</summary>
Motivation: 现有前沿AI模型监管提案因安全与创新的权衡而被搁置，需要一种既能确保AI安全又能积极促进创新的监管方法。

Method: 强制要求大型AI实验室发布小型、开放访问的类比模型，这些模型作为公共代理，允许广泛参与安全验证、可解释性研究和算法透明度工作。

Result: 类比模型使更广泛的研究社区能够直接调查和创新，显著减少监管负担并加速安全进展，同时产生最小额外成本。

Conclusion: 这种监管方法不仅应被采纳，还体现了一个更广泛的原则：对模型的深入理解可以缓解安全与创新的权衡，让我们同时获得更多安全性和创新。

Abstract: Recent proposals for regulating frontier AI models have sparked concerns
about the cost of safety regulation, and most such regulations have been
shelved due to the safety-innovation tradeoff. This paper argues for an
alternative regulatory approach that ensures AI safety while actively promoting
innovation: mandating that large AI laboratories release small, openly
accessible analog models (scaled-down versions) trained similarly to and
distilled from their largest proprietary models.
  Analog models serve as public proxies, allowing broad participation in safety
verification, interpretability research, and algorithmic transparency without
forcing labs to disclose their full-scale models. Recent research demonstrates
that safety and interpretability methods developed using these smaller models
generalize effectively to frontier-scale systems. By enabling the wider
research community to directly investigate and innovate upon accessible
analogs, our policy substantially reduces the regulatory burden and accelerates
safety advancements.
  This mandate promises minimal additional costs, leveraging reusable resources
like data and infrastructure, while significantly contributing to the public
good. Our hope is not only that this policy be adopted, but that it illustrates
a broader principle supporting fundamental research in machine learning: deeper
understanding of models relaxes the safety-innovation tradeoff and lets us have
more of both.

</details>


### [13] [Generating Fair Consensus Statements with Social Choice on Token-Level MDPs](https://arxiv.org/abs/2510.14106)
*Carter Blair,Kate Larson*

Main category: cs.AI

TL;DR: 提出基于多目标马尔可夫决策过程的共识声明生成框架，通过社会选择理论保证公平性，包括两种方法：随机生成策略确保事前核心稳定性，以及基于平等主义福利的搜索算法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型共识声明生成框架缺乏可证明的公平性保证结构，无法在聚合多样化自由形式意见时提供公平性保障。

Method: 将任务建模为多目标、令牌级马尔可夫决策过程，每个目标对应一个代理的偏好。基于代理策略推导令牌级奖励，利用社会选择理论提出两种方法：确保事前核心稳定性的随机生成策略和基于平等主义福利的搜索算法。

Result: 实验表明，使用语言模型实例化代理策略时，基于平等主义目标的搜索生成的共识声明在最低代理对齐度方面优于基线方法，包括Habermas Machine。

Conclusion: 该框架为共识声明生成提供了具有可证明公平性保证的结构化方法，通过社会选择理论原则实现了更好的公平性表现。

Abstract: Current frameworks for consensus statement generation with large language
models lack the inherent structure needed to provide provable fairness
guarantees when aggregating diverse free-form opinions. We model the task as a
multi-objective, token-level Markov Decision Process (MDP), where each
objective corresponds to an agent's preference. Token-level rewards for each
agent are derived from their policy (e.g., a personalized language model). This
approach utilizes the finding that such policies implicitly define optimal
Q-functions, providing a principled way to quantify rewards at each generation
step without a value function (Rafailov et al., 2024). This MDP formulation
creates a formal structure amenable to analysis using principles from social
choice theory. We propose two approaches grounded in social choice theory.
First, we propose a stochastic generation policy guaranteed to be in the
ex-ante core, extending core stability concepts from voting theory to text
generation. This policy is derived from an underlying distribution over
complete statements that maximizes proportional fairness (Nash Welfare).
Second, for generating a single statement, we target the maximization of
egalitarian welfare using search algorithms within the MDP framework.
Empirically, experiments using language models to instantiate agent policies
show that search guided by the egalitarian objective generates consensus
statements with improved worst-case agent alignment compared to baseline
methods, including the Habermas Machine (Tessler et al., 2024).

</details>


### [14] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: 提出STEMS框架，一种安全约束的多智能体强化学习方法，用于协调建筑能源管理，显著降低成本、排放和安全违规，同时保持舒适度。


<details>
  <summary>Details</summary>
Motivation: 解决多建筑能源系统面临的三个关键挑战：时空信息利用不足、缺乏严格安全保证、系统复杂性，以实现碳减排目标、提升居住舒适度和降低能源成本。

Method: 集成两个核心组件：(1) 使用GCN-Transformer融合架构的时空图表示学习框架，捕捉建筑间关系和时序模式；(2) 结合控制屏障函数的安全约束多智能体RL算法，提供数学安全保证。

Result: 在真实建筑数据集上的实验显示，STEMS相比现有方法实现21%成本降低、18%排放减少，安全违规从35.1%大幅降至5.6%，同时仅0.13的不适比例保持最优舒适度。

Conclusion: STEMS框架在极端天气条件下表现出强鲁棒性，在不同建筑类型中保持有效性，为协调建筑能源管理提供了有效的安全约束解决方案。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [15] [Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems](https://arxiv.org/abs/2510.14133)
*Edoardo Allegrini,Ananth Shreekumar,Z. Berkay Celik*

Main category: cs.AI

TL;DR: 提出了一个用于分析多AI代理系统的统一建模框架，包含主机代理模型和任务生命周期模型，定义了31个形式化属性来验证系统行为。


<details>
  <summary>Details</summary>
Motivation: 当前多代理AI系统的通信协议碎片化，存在语义鸿沟，无法进行严格的系统属性分析，存在架构错位和可被利用的协调问题等风险。

Method: 引入两个基础模型：主机代理模型（负责与用户交互、任务分解和协调执行）和任务生命周期模型（详细描述子任务从创建到完成的状态转换），并定义了17个主机代理属性和14个任务生命周期属性。

Result: 创建了首个严格基础的、领域无关的框架，用于系统分析、设计和部署正确、可靠、鲁棒的多AI代理系统，支持形式化验证和协调边缘情况检测。

Conclusion: 该框架为多AI代理系统提供了统一的语义基础，能够预防死锁和安全漏洞，确保系统的安全性和功能性。

Abstract: Agentic AI systems, which leverage multiple autonomous agents and Large
Language Models (LLMs), are increasingly used to address complex, multi-step
tasks. The safety, security, and functionality of these systems are critical,
especially in high-stakes applications. However, the current ecosystem of
inter-agent communication is fragmented, with protocols such as the Model
Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol
for coordination being analyzed in isolation. This fragmentation creates a
semantic gap that prevents the rigorous analysis of system properties and
introduces risks such as architectural misalignment and exploitable
coordination issues. To address these challenges, we introduce a modeling
framework for agentic AI systems composed of two foundational models. The
first, the host agent model, formalizes the top-level entity that interacts
with the user, decomposes tasks, and orchestrates their execution by leveraging
external agents and tools. The second, the task lifecycle model, details the
states and transitions of individual sub-tasks from creation to completion,
providing a fine-grained view of task management and error handling. Together,
these models provide a unified semantic framework for reasoning about the
behavior of multi-AI agent systems. Grounded in this framework, we define 17
properties for the host agent and 14 for the task lifecycle, categorized into
liveness, safety, completeness, and fairness. Expressed in temporal logic,
these properties enable formal verification of system behavior, detection of
coordination edge cases, and prevention of deadlocks and security
vulnerabilities. Through this effort, we introduce the first rigorously
grounded, domain-agnostic framework for the systematic analysis, design, and
deployment of correct, reliable, and robust agentic AI systems.

</details>


### [16] [The Gatekeeper Knows Enough](https://arxiv.org/abs/2510.14881)
*Fikresilase Wondmeneh Abebayew*

Main category: cs.AI

TL;DR: 提出了Gatekeeper协议框架，通过潜在状态表示和按需请求高保真上下文的方式，解决LLM代理在复杂知识系统中存在的上下文窗口限制和状态不同步问题。


<details>
  <summary>Details</summary>
Motivation: LLM作为自主代理部署时，受限于有限的上下文窗口和状态不同步问题，导致不可靠输出、不可预测行为和资源使用效率低下，特别是在与代码库和文档等结构化知识系统交互时。

Method: 引入Gatekeeper协议，要求代理先在简化的低保真潜在状态表示上进行操作和推理，然后按需策略性地请求高保真上下文。所有交互通过统一的JSON格式进行，作为声明性、状态同步的协议。

Result: 通过Sage（Gatekeeper协议的参考实现）证明，该方法显著提高了代理可靠性，通过最小化token消耗改善了计算效率，并实现了与复杂系统的可扩展交互。

Conclusion: Gatekeeper协议为在任何结构化知识领域构建更稳健、可预测和基于现实的AI代理提供了基础方法论。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents,
yet their practical utility is fundamentally constrained by a limited context
window and state desynchronization resulting from the LLMs' stateless nature
and inefficient context management. These limitations lead to unreliable
output, unpredictable behavior, and inefficient resource usage, particularly
when interacting with large, structured, and sensitive knowledge systems such
as codebases and documents. To address these challenges, we introduce the
Gatekeeper Protocol, a novel, domain-agnostic framework that governs
agent-system interactions. Our protocol mandates that the agent first operate
and reason on a minimalist, low-fidelity "latent state" representation of the
system to strategically request high-fidelity context on demand. All
interactions are mediated through a unified JSON format that serves as a
declarative, state-synchronized protocol, ensuring the agent's model of the
system remains verifiably grounded in the system's reality. We demonstrate the
efficacy of this protocol with Sage, a reference implementation of the
Gatekeeper Protocol for software development. Our results show that this
approach significantly increases agent reliability, improves computational
efficiency by minimizing token consumption, and enables scalable interaction
with complex systems, creating a foundational methodology for building more
robust, predictable, and grounded AI agents for any structured knowledge
domain.

</details>


### [17] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 提出轻量级多模态架构，融合传感器数据和视觉图像来预测文化遗产地点的退化严重程度，在数据稀缺情况下实现76.9%的准确率。


<details>
  <summary>Details</summary>
Motivation: 文化遗产地点因气候变化加速退化，传统单模态监测方法无法捕捉环境压力与材料退化之间的复杂相互作用。

Method: 基于PerceiverIO架构，采用简化编码器(64D潜在空间)防止小数据集过拟合，并使用自适应Barlow Twins损失鼓励模态互补性而非冗余。

Result: 在斯特拉斯堡大教堂数据上达到76.9%准确率，比标准多模态架构提升43%，比传感器单独使用(61.5%)和图像单独使用(46.2%)表现更好。

Conclusion: 架构简化结合对比正则化能够在数据稀缺的遗产监测环境中实现有效的多模态学习，为AI驱动的保护决策支持系统奠定基础。

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [18] [CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization](https://arxiv.org/abs/2510.14150)
*Henrique Assumpção,Diego Ferreira,Leandro Campos,Fabricio Murai*

Main category: cs.AI

TL;DR: CodeEvolve是一个开源进化编码代理，结合大语言模型和遗传算法解决复杂计算问题，在数学基准测试中超越了AlphaEvolve的性能。


<details>
  <summary>Details</summary>
Motivation: 将强大的进化概念应用于LLM领域，基于广义科学发现的最新方法，解决复杂计算问题。

Method: 采用基于岛屿的遗传算法保持种群多样性，引入新颖的基于启发的交叉机制利用LLM上下文窗口组合成功解决方案的特征，实现元提示策略动态探索解空间。

Result: 在用于评估Google DeepMind闭源AlphaEvolve的数学基准测试子集上，CodeEvolve在多个挑战性问题上的表现超越了AlphaEvolve。

Conclusion: CodeEvolve成功将进化算法与LLM结合，在复杂问题求解上表现出色，通过开源发布促进合作和加速进展。

Abstract: In this work, we introduce CodeEvolve, an open-source evolutionary coding
agent that unites Large Language Models (LLMs) with genetic algorithms to solve
complex computational problems. Our framework adapts powerful evolutionary
concepts to the LLM domain, building upon recent methods for generalized
scientific discovery. CodeEvolve employs an island-based genetic algorithm to
maintain population diversity and increase throughput, introduces a novel
inspiration-based crossover mechanism that leverages the LLMs context window to
combine features from successful solutions, and implements meta-prompting
strategies for dynamic exploration of the solution space. We conduct a rigorous
evaluation of CodeEvolve on a subset of the mathematical benchmarks used to
evaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that
our method surpasses AlphaEvolve's performance on several challenging problems.
To foster collaboration and accelerate progress, we release our complete
framework as an open-source repository.

</details>


### [19] [Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola](https://arxiv.org/abs/2510.14154)
*Tian Liu,Alex Cann,Ian Colbert,Mehdi Saeedi*

Main category: cs.AI

TL;DR: 本文探讨了在商业视频游戏中应用强化学习（RL）的挑战，提出将RL与传统行为树（BTs）结合的方法，并通过AMD Schola插件在虚幻引擎中训练多任务NPC来验证该方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习研究进展迅速，但在商业视频游戏中的采用仍然缓慢。本文旨在解决游戏AI社区在实际使用RL驱动NPC时面临的常见挑战，并探索RL与行为树结合的关键节点。

Method: 使用AMD Schola插件在虚幻引擎中训练RL代理，创建多任务NPC，并详细介绍了将RL模型与行为树联合训练的方法论，展示了各种技能。

Result: 通过在受《最后生还者》启发的复杂3D环境中进行实验，证明了RL与行为树结合方法的可行性。

Conclusion: RL与行为树的结合是一个重要但尚未充分探索的方向，本文展示了该方法在实际游戏环境中的可行性和应用潜力。

Abstract: While the rapid advancements in the reinforcement learning (RL) research
community have been remarkable, the adoption in commercial video games remains
slow. In this paper, we outline common challenges the Game AI community faces
when using RL-driven NPCs in practice, and highlight the intersection of RL
with traditional behavior trees (BTs) as a crucial juncture to be explored
further. Although the BT+RL intersection has been suggested in several research
papers, its adoption is rare. We demonstrate the viability of this approach
using AMD Schola -- a plugin for training RL agents in Unreal Engine -- by
creating multi-task NPCs in a complex 3D environment inspired by the commercial
video game ``The Last of Us". We provide detailed methodologies for jointly
training RL models with BTs while showcasing various skills.

</details>


### [20] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA是一个用于临床订单检索的双编码器系统，通过联合嵌入直接和对话上下文信息，实现实时临床订单检索，无需LLM重写，减少延迟和不稳定性。


<details>
  <summary>Details</summary>
Motivation: 临床对话包含显性指令和隐性推理，现有系统依赖LLM重写会带来延迟、不稳定性和不透明性，阻碍实时订单处理。

Method: 基于PubMedBERT初始化，使用双编码器架构，通过对比学习目标对齐异构意图表达与共享订单概念，支持直接检索和无查询模式。

Result: 在实践中部署JEDA获得显著性能提升，大幅优于基础编码器和近期开源嵌入模型，具有更好的噪声鲁棒性和泛化能力。

Conclusion: JEDA提供了一个快速、可解释、无需LLM的检索层，能够实时将环境上下文链接到可操作的临床订单。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [21] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM是一个利用基础模型自动生成奖励机器的框架，通过自然语言规范实现强化学习的自动化奖励设计，支持任务分解和零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法对奖励函数规范高度敏感，这限制了其广泛应用。现有方法需要手动设计奖励函数，过程繁琐且容易出错。

Method: 使用基础模型从自然语言规范自动生成奖励机器；为每个自动机状态关联语言嵌入以实现跨任务泛化；在多样化环境中进行实证验证。

Result: 在多个挑战性环境中证明了ARM-FM的有效性，包括展示了零样本泛化能力。

Conclusion: ARM-FM通过结合基础模型和奖励机器，实现了从自然语言到强化学习目标的自动化转换，解决了奖励函数设计的核心挑战。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [22] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: 本文对2019-2024年精准医学中AI实施的文献进行了范围综述，识别了数据质量、临床可靠性、工作流程整合和治理方面的关键障碍和促进因素，并提出了支持可信和可持续实施的未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在精准医学中通过整合和解释多模态数据变得越来越重要，但在临床环境中的实施仍然有限，需要系统分析实施障碍和促进因素。

Method: 采用生态系统框架对2019-2024年文献进行范围综述，分析AI在精准医学实施中的关键因素。

Result: 识别了数据质量、临床可靠性、工作流程整合和治理四个主要维度的障碍和促进因素，强调了这些因素之间的相互依赖关系。

Conclusion: 需要采用生态系统方法支持AI在精准医学中的真实世界转化，确保可信和可持续的实施。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [23] [Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](https://arxiv.org/abs/2510.14207)
*Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu*

Main category: cs.AI

TL;DR: 提出了一个在线骚扰代理基准测试，包含多轮骚扰对话数据集、多代理模拟、三种越狱攻击方法和混合评估框架。研究发现越狱调优使骚扰成功率大幅提升，闭源和开源模型表现出不同的升级轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有越狱研究主要关注单轮提示，而真实骚扰往往在多轮互动中展开，需要开发多轮理论驱动的攻击方法来评估LLM代理的安全性。

Method: 构建了包含多轮骚扰对话数据集、基于重复博弈理论的多代理模拟、针对记忆、规划和微调的三种越狱方法，以及混合评估框架。使用LLaMA-3.1-8B-Instruct和Gemini-2.0-flash两个模型进行测试。

Result: 越狱调优使骚扰成功率显著提高：Llama模型从57.25-64.19%提升至95.78-96.89%，Gemini从98.46%提升至99.33%。最常见的毒性行为是侮辱（84.9-87.8%）和谩骂（81.2-85.1%）。闭源模型表现出显著脆弱性。

Conclusion: 多轮和理论驱动的攻击不仅成功率高，还能模拟人类骚扰动态，强调了开发强大安全防护措施的必要性，以确保在线平台的安全和负责任。

Abstract: Large Language Model (LLM) agents are powering a growing share of interactive
web applications, yet remain vulnerable to misuse and harm. Prior jailbreak
research has largely focused on single-turn prompts, whereas real harassment
often unfolds over multi-turn interactions. In this work, we present the Online
Harassment Agentic Benchmark consisting of: (i) a synthetic multi-turn
harassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)
simulation informed by repeated game theory, (iii) three jailbreak methods
attacking agents across memory, planning, and fine-tuning, and (iv) a
mixed-methods evaluation framework. We utilize two prominent LLMs,
LLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our
results show that jailbreak tuning makes harassment nearly guaranteed with an
attack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,
and 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal
rate to 1-2% in both models. The most prevalent toxic behaviors are Insult with
84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.
31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive
categories such as sexual or racial harassment. Qualitative evaluation further
reveals that attacked agents reproduce human-like aggression profiles, such as
Machiavellian/psychopathic patterns under planning, and narcissistic tendencies
with memory. Counterintuitively, closed-source and open-source models exhibit
distinct escalation trajectories across turns, with closed-source models
showing significant vulnerability. Overall, our findings show that multi-turn
and theory-grounded attacks not only succeed at high rates but also mimic
human-like harassment dynamics, motivating the development of robust safety
guardrails to ultimately keep online platforms safe and responsible.

</details>


### [24] [LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild](https://arxiv.org/abs/2510.14240)
*Jiayu Wang,Yifei Ming,Riya Dulepet,Qinglin Chen,Austin Xu,Zixuan Ke,Frederic Sala,Aws Albarghouthi,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 提出了LiveResearchBench基准和DeepEval评估套件，用于系统评估深度研究系统的能力，涵盖100个专家策划的任务和全面的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估深度研究系统时存在不足，无法满足用户中心、动态性、明确性和多面性等原则，需要新的评估框架。

Method: 构建了包含100个任务的LiveResearchBench基准，并开发了DeepEval评估套件，包含内容级和报告级质量评估，整合了四种互补的评估协议。

Result: 对17个前沿深度研究系统进行了全面评估，揭示了当前系统的优势、常见失败模式和关键系统组件需求。

Conclusion: LiveResearchBench和DeepEval为深度研究系统提供了严格的评估基础，识别了推进可靠深度研究所需的关键能力。

Abstract: Deep research -- producing comprehensive, citation-grounded reports by
searching and synthesizing information from hundreds of live web sources --
marks an important frontier for agentic systems. To rigorously evaluate this
ability, four principles are essential: tasks should be (1) user-centric,
reflecting realistic information needs, (2) dynamic, requiring up-to-date
information beyond parametric knowledge, (3) unambiguous, ensuring consistent
interpretation across users, and (4) multi-faceted and search-intensive,
requiring search over numerous web sources and in-depth analysis. Existing
benchmarks fall short of these principles, often focusing on narrow domains or
posing ambiguous questions that hinder fair comparison. Guided by these
principles, we introduce LiveResearchBench, a benchmark of 100 expert-curated
tasks spanning daily life, enterprise, and academia, each requiring extensive,
dynamic, real-time web search and synthesis. Built with over 1,500 hours of
human labor, LiveResearchBench provides a rigorous basis for systematic
evaluation. To evaluate citation-grounded long-form reports, we introduce
DeepEval, a comprehensive suite covering both content- and report-level
quality, including coverage, presentation, citation accuracy and association,
consistency and depth of analysis. DeepEval integrates four complementary
evaluation protocols, each designed to ensure stable assessment and high
agreement with human judgments. Using LiveResearchBench and DeepEval, we
conduct a comprehensive evaluation of 17 frontier deep research systems,
including single-agent web search, single-agent deep research, and multi-agent
systems. Our analysis reveals current strengths, recurring failure modes, and
key system components needed to advance reliable, insightful deep research.

</details>


### [25] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 本文提出了Agentic Self-Learning (ASL)框架，通过生成奖励模型(GRM)和多角色协同进化实现无需人工标注数据的智能体自我学习，在搜索任务中展现出持续改进能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不依赖人工标注数据集或预定义规则奖励的情况下，实现基于LLM的智能体的规模化训练。

Method: 提出ASL框架，包含提示生成器、策略模型和生成奖励模型，在共享工具环境和LLM骨干网络中形成任务生成、策略执行和评估的闭环强化学习。

Result: ASL在搜索任务中实现持续改进，超越强基线方法，在零标注数据条件下仍能继续提升，表现出优异的样本效率和鲁棒性。

Conclusion: 奖励来源和数据规模是开放域智能体学习的关键因素，多角色协同进化是实现可扩展自我改进智能体的有效方法。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [26] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: 提出了MorphoBench基准测试，用于评估大型模型的推理能力，能够根据模型推理能力动态调整问题难度，包含1300多个测试问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估大型模型推理能力时存在范围有限、缺乏灵活性，无法根据模型推理能力的发展调整难度的问题。

Method: 从现有基准和奥林匹克竞赛中收集复杂推理问题，利用模型推理过程中的关键陈述自适应修改问题分析难度，并使用模拟软件生成可动态调整难度的问题。

Result: 收集了1300多个测试问题，基于o3和GPT-5等模型的推理能力迭代调整了MorphoBench的难度。

Conclusion: MorphoBench提高了模型推理评估的全面性和有效性，为提升大型模型推理能力和科学稳健性提供了可靠指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [27] [A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space](https://arxiv.org/abs/2510.14301)
*Bingjie Zhang,Yibo Yang,Renzhe,Dandan Guo,Jindong Gu,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: GuardSpace是一个在微调过程中保护LLM安全对齐的框架，通过安全敏感子空间和抗有害零空间来防止安全行为退化。


<details>
  <summary>Details</summary>
Motivation: LLM在微调过程中容易丧失预训练的安全对齐能力，即使使用良性数据或低秩适配也会产生有害响应，需要保护安全机制。

Method: 使用协方差预条件奇异值分解将预训练权重分解为安全相关和安全无关组件，从安全无关组件初始化低秩适配器，并构建零空间投影器限制适配器更新对有害提示的响应。

Result: 在多个下游任务上，GuardSpace优于现有方法。对于Llama-2-7B-Chat在GSM8K上的微调，有害评分从14.4%降至3.6%，准确率从26.0%提升至28.0%。

Conclusion: GuardSpace能有效保护LLM在微调过程中的安全对齐，同时保持任务性能，是安全微调的有效解决方案。

Abstract: Large language models (LLMs) have achieved remarkable success in diverse
tasks, yet their safety alignment remains fragile during adaptation. Even when
fine-tuning on benign data or with low-rank adaptation, pre-trained safety
behaviors are easily degraded, leading to harmful responses in the fine-tuned
models. To address this challenge, we propose GuardSpace, a guardrail framework
for preserving safety alignment throughout fine-tuning, composed of two key
components: a safety-sensitive subspace and a harmful-resistant null space.
First, we explicitly decompose pre-trained weights into safety-relevant and
safety-irrelevant components using covariance-preconditioned singular value
decomposition, and initialize low-rank adapters from the safety-irrelevant
ones, while freezing safety-relevant components to preserve their associated
safety mechanism. Second, we construct a null space projector that restricts
adapter updates from altering safe outputs on harmful prompts, thereby
maintaining the original refusal behavior. Experiments with various pre-trained
models on multiple downstream tasks demonstrate that GuardSpace achieves
superior performance over existing methods. Notably, for Llama-2-7B-Chat
fine-tuned on GSM8K, GuardSpace outperforms the state-of-the-art method AsFT,
reducing the average harmful score from 14.4% to 3.6%, while improving the
accuracy from from 26.0% to 28.0%.

</details>


### [28] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 提出了Terrarium框架，用于细粒度研究基于LLM的多智能体系统中的安全、隐私和安全性问题，通过重新利用黑板设计创建模块化、可配置的测试平台。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统能够自动化繁琐的用户任务，但引入了新的风险，包括错位、恶意方攻击、智能体被破坏或用户数据被盗等问题。

Method: 重新利用多智能体系统中的早期方法——黑板设计，创建模块化、可配置的测试平台，识别关键攻击向量如错位、恶意智能体、通信被破坏和数据投毒。

Result: 实现了三个协作多智能体场景和四种代表性攻击，展示了框架的灵活性，提供了快速原型设计、评估和防御迭代的工具。

Conclusion: Terrarium框架旨在加速可信多智能体系统的进展，通过提供工具来快速原型设计、评估和迭代防御措施。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [29] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: MASC是一个元认知框架，通过实时无监督的步骤级错误检测和自我纠正，解决多智能体系统中错误级联传播的问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在协作解决问题时容易受到级联错误的影响，单个错误步骤可能在整个系统中传播并破坏任务轨迹。

Method: 采用两种互补设计：1) 基于历史的下一个执行重构，预测下一步的嵌入以捕捉因果一致性；2) 原型引导增强，学习正常步骤嵌入的原型先验，在稀疏上下文下稳定重构和异常评分。

Result: 在Who&When基准测试中，MASC显著优于所有基线方法，步骤级错误检测AUC-ROC提升高达8.47%；在不同MAS框架中都能带来一致的端到端性能提升。

Conclusion: MASC的元认知监控和针对性纠正能够以最小开销缓解错误传播，为多智能体系统提供了有效的错误检测和纠正机制。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [30] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: 提出了AI4Service新范式，通过Alpha-Service框架实现主动式AI助手，能够从第一视角视频流中检测服务机会并提供个性化服务。


<details>
  <summary>Details</summary>
Motivation: 现有AI服务多为被动响应，而真正智能的助手应能预见用户需求并在适当时机主动采取行动。

Method: 基于AI眼镜构建Alpha-Service统一框架，包含输入、中央处理、算术逻辑、存储和输出五个单元，采用多智能体系统实现。

Result: 案例研究（21点游戏顾问、博物馆导览、购物搭配助手）显示系统能够无缝感知环境、推断用户意图并提供及时有用的帮助。

Conclusion: AI4Service范式将AI从被动工具转变为主动伴侣，Alpha-Service框架为实现这一愿景提供了可行方案。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [31] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: 提出IP-Merging方法，无需调优即可将数学推理能力从纯文本LLM直接迁移到多模态LLM，通过识别关键推理层和参数空间投影来解决对齐问题。


<details>
  <summary>Details</summary>
Motivation: 多模态LLM的数学推理能力落后于纯文本LLM，但现有模型融合方法忽视了MLLM与LLM之间的参数空间对齐问题。

Method: IP-Merging方法：识别MLLM和数学LLM中的推理相关参数，将其投影到MLLM的子空间，然后在该子空间内合并参数。

Result: 实验证明IP-Merging能显著提升MLLM的数学推理能力，且不损害其他能力。

Conclusion: IP-Merging是一种无需调优的有效方法，可直接从数学LLM向MLLM迁移推理能力，解决了参数空间对齐问题。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [32] [Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control](https://arxiv.org/abs/2510.14388)
*Zhe Wu,Hongjin Lu,Junliang Xing,Changhao Zhang,Yin Zhu,Yuhao Yang,Yuheng Jing,Kai Li,Kun Shao,Jianye Hao,Jun Wang,Yuanchun Shi*

Main category: cs.AI

TL;DR: Hi-Agent是一种可训练的分层视觉语言代理，通过高层推理模型和低层动作模型的联合优化，在移动设备控制任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的移动设备控制方法大多依赖直接的状态到动作映射，缺乏结构化推理和规划，导致在新任务或未见过的UI布局上泛化能力差。

Method: 提出分层架构，将多步决策重新表述为单步子目标序列，并引入前瞻优势函数，利用低层模型的执行反馈来指导高层优化，缓解长时任务中的路径爆炸问题。

Result: 在Android-in-the-Wild基准测试中达到87.9%的任务成功率，显著优于基于提示、监督学习和强化学习的先前方法，并在ScreenSpot-v2和AndroidWorld基准上展现出良好的零样本泛化能力。

Conclusion: Hi-Agent通过分层设计和联合优化策略，在移动设备控制任务中实现了优异的性能和泛化能力，为复杂场景下的自主操作提供了有效解决方案。

Abstract: Building agents that autonomously operate mobile devices has attracted
increasing attention. While Vision-Language Models (VLMs) show promise, most
existing approaches rely on direct state-to-action mappings, which lack
structured reasoning and planning, and thus generalize poorly to novel tasks or
unseen UI layouts. We introduce Hi-Agent, a trainable hierarchical
vision-language agent for mobile control, featuring a high-level reasoning
model and a low-level action model that are jointly optimized. For efficient
training, we reformulate multi-step decision-making as a sequence of
single-step subgoals and propose a foresight advantage function, which
leverages execution feedback from the low-level model to guide high-level
optimization. This design alleviates the path explosion issue encountered by
Group Relative Policy Optimization (GRPO) in long-horizon tasks and enables
stable, critic-free joint training. Hi-Agent achieves a new State-Of-The-Art
(SOTA) 87.9% task success rate on the Android-in-the-Wild (AitW) benchmark,
significantly outperforming prior methods across three paradigms: prompt-based
(AppAgent: 17.7%), supervised (Filtered BC: 54.5%), and reinforcement
learning-based (DigiRL: 71.9%). It also demonstrates competitive zero-shot
generalization on the ScreenSpot-v2 benchmark. On the more challenging
AndroidWorld benchmark, Hi-Agent also scales effectively with larger backbones,
showing strong adaptability in high-complexity mobile control scenarios.

</details>


### [33] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: 提出了IMAGINE框架，将多智能体系统的推理和规划能力集成到单一紧凑模型中，显著提升了复杂推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理和规划任务中表现不佳，多智能体系统虽然能提供更好的集体推理，但存在推理成本高、延迟长和端到端训练困难等问题。

Method: IMAGINE框架通过端到端训练，将多智能体系统的能力集成到单一模型中，使小规模模型能够获得结构化推理和规划能力。

Result: 使用Qwen3-8B-Instruct作为基础模型，在TravelPlanner基准测试中达到82.7%的最终通过率，远超DeepSeek-R1-671B的40%，同时保持更小的模型规模。

Conclusion: IMAGINE框架成功地将多智能体系统的优势集成到单一模型中，显著提升了复杂推理任务的性能，同时降低了计算成本。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [34] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: 本文研究了PDDL中公理的处理，特别是关于负谓词出现的限制，提出了将包含负派生谓词的公理转换为符合PDDL标准的等价形式的方法。


<details>
  <summary>Details</summary>
Motivation: PDDL标准限制公理体中负谓词只能出现在直接由动作设置的谓词上，而不能出现在由公理派生的谓词上。但文献中常偏离此限制，只要求公理集可分层。这两种变体都能表达与最小不动点逻辑相同的查询，表明负派生谓词可以被消除。

Method: 提出了相应的转换方法，将包含负派生谓词的公理转换为符合PDDL标准限制的等价形式。

Result: 证明了负派生谓词可以被消除，两种公理变体在表达能力上是等价的。

Conclusion: 通过提出的转换方法，可以消除公理中的负派生谓词，使得包含这类谓词的公理能够符合PDDL标准的要求，同时保持相同的表达能力。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [35] [Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration](https://arxiv.org/abs/2510.14512)
*Haoyuan Li,Mathias Funk,Aaqib Saeed*

Main category: cs.AI

TL;DR: Helmsman是一个多智能体系统，能够从高级用户规范自动合成端到端的联邦学习系统，通过模拟研发工作流程生成与手工基线相媲美甚至更优的解决方案。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在去中心化数据训练模型方面具有强大潜力，但设计和部署鲁棒系统的复杂性限制了其应用，需要自动化工具来克服策略选择和调优的瓶颈。

Method: 采用三阶段协作方法：1)交互式人机协同规划制定研究计划；2)监督智能体团队进行模块化代码生成；3)在沙盒模拟环境中进行自主评估和优化的闭环流程。

Result: 实验表明，该方法生成的解决方案与成熟的手工基线相比具有竞争力，甚至更优。同时引入了AgentFL-Bench基准测试来评估系统级生成能力。

Conclusion: 这项工作代表了向复杂去中心化AI系统自动化工程迈出的重要一步，为联邦学习系统的自动化设计提供了有效解决方案。

Abstract: Federated Learning (FL) offers a powerful paradigm for training models on
decentralized data, but its promise is often undermined by the immense
complexity of designing and deploying robust systems. The need to select,
combine, and tune strategies for multifaceted challenges like data
heterogeneity and system constraints has become a critical bottleneck,
resulting in brittle, bespoke solutions. To address this, we introduce
Helmsman, a novel multi-agent system that automates the end-to-end synthesis of
federated learning systems from high-level user specifications. It emulates a
principled research and development workflow through three collaborative
phases: (1) interactive human-in-the-loop planning to formulate a sound
research plan, (2) modular code generation by supervised agent teams, and (3) a
closed-loop of autonomous evaluation and refinement in a sandboxed simulation
environment. To facilitate rigorous evaluation, we also introduce
AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess
the system-level generation capabilities of agentic systems in FL. Extensive
experiments demonstrate that our approach generates solutions competitive with,
and often superior to, established hand-crafted baselines. Our work represents
a significant step towards the automated engineering of complex decentralized
AI systems.

</details>


### [36] [JSPLIT: A Taxonomy-based Solution for Prompt Bloating in Model Context Protocol](https://arxiv.org/abs/2510.14537)
*Emanuele Antonioni,Stefan Markovic,Anirudha Shankar,Jaime Bernardo,Lovro Markovic,Silvia Pareti,Benedetto Proietti*

Main category: cs.AI

TL;DR: JSPLIT是一个基于分类学的框架，用于解决大型语言模型使用MCP工具时提示膨胀的问题。它通过层次化分类工具并根据用户查询选择最相关工具，显著减少提示大小，同时保持甚至提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统发展，用户期望与外部工具交互，但工具数量增加导致提示膨胀问题，带来高成本、延迟和工具选择不准确的问题。

Method: JSPLIT将工具组织成层次化分类学，基于用户查询和分类结构识别并仅包含最相关工具，减少提示大小。

Result: JSPLIT显著减少提示大小，在工具数量大幅增加时甚至提高工具选择准确性，降低成本同时改善高复杂度环境中的任务成功率。

Conclusion: JSPLIT框架有效解决了MCP工具使用中的提示膨胀问题，通过智能工具选择实现了成本降低和性能提升的平衡。

Abstract: AI systems are continually evolving and advancing, and user expectations are
concurrently increasing, with a growing demand for interactions that go beyond
simple text-based interaction with Large Language Models (LLMs). Today's
applications often require LLMs to interact with external tools, marking a
shift toward more complex agentic systems. To support this, standards such as
the Model Context Protocol (MCP) have emerged, enabling agents to access tools
by including a specification of the capabilities of each tool within the
prompt. Although this approach expands what agents can do, it also introduces a
growing problem: prompt bloating. As the number of tools increases, the prompts
become longer, leading to high prompt token costs, increased latency, and
reduced task success resulting from the selection of tools irrelevant to the
prompt. To address this issue, we introduce JSPLIT, a taxonomy-driven framework
designed to help agents manage prompt size more effectively when using large
sets of MCP tools. JSPLIT organizes the tools into a hierarchical taxonomy and
uses the user's prompt to identify and include only the most relevant tools,
based on both the query and the taxonomy structure. In this paper, we describe
the design of the taxonomy, the tool selection algorithm, and the dataset used
to evaluate JSPLIT. Our results show that JSPLIT significantly reduces prompt
size without significantly compromising the agent's ability to respond
effectively. As the number of available tools for the agent grows
substantially, JSPLIT even improves the tool selection accuracy of the agent,
effectively reducing costs while simultaneously improving task success in
high-complexity agent environments.

</details>


### [37] [Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts](https://arxiv.org/abs/2510.14538)
*Emanuele Marconato,Samuele Bortolotti,Emile van Krieken,Paolo Morettin,Elena Umili,Antonio Vergari,Efthymia Tsamoura,Andrea Passerini,Stefano Teso*

Main category: cs.AI

TL;DR: 这篇论文综述了神经符号AI中的推理捷径问题，分析了其成因、后果，并总结了现有的应对方法。推理捷径是指神经符号模型在不正确理解概念的情况下仍能获得高准确率的现象，这会损害模型的可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI旨在开发符合先验知识的可靠AI系统，但推理捷径问题会严重影响其可靠性和可解释性。目前相关研究分散，需要统一的视角来帮助研究人员理解和解决这个问题。

Method: 本文采用综述方法，首先直观地介绍推理捷径的成因和后果，然后回顾现有的理论表征，最后详细分析处理推理捷径的方法，包括缓解和认知策略。

Result: 论文系统梳理了推理捷径问题，提供了统一的分析框架，阐明了各种应对方法的优缺点，为开发可靠的神经符号AI模型奠定了基础。

Conclusion: 通过以易于理解的形式重新阐述高级材料，本文旨在降低研究人员处理推理捷径问题的门槛，为开发可靠的神经符号AI和可信赖AI模型做出贡献。

Abstract: Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose
predictions comply with prior knowledge encoding, e.g. safety or structural
constraints. As such, it represents one of the most promising avenues for
reliable and trustworthy AI. The core idea behind NeSy AI is to combine neural
and symbolic steps: neural networks are typically responsible for mapping
low-level inputs into high-level symbolic concepts, while symbolic reasoning
infers predictions compatible with the extracted concepts and the prior
knowledge. Despite their promise, it was recently shown that - whenever the
concepts are not supervised directly - NeSy models can be affected by Reasoning
Shortcuts (RSs). That is, they can achieve high label accuracy by grounding the
concepts incorrectly. RSs can compromise the interpretability of the model's
explanations, performance in out-of-distribution scenarios, and therefore
reliability. At the same time, RSs are difficult to detect and prevent unless
concept supervision is available, which is typically not the case. However, the
literature on RSs is scattered, making it difficult for researchers and
practitioners to understand and tackle this challenging problem. This overview
addresses this issue by providing a gentle introduction to RSs, discussing
their causes and consequences in intuitive terms. It also reviews and
elucidates existing theoretical characterizations of this phenomenon. Finally,
it details methods for dealing with RSs, including mitigation and awareness
strategies, and maps their benefits and limitations. By reformulating advanced
material in a digestible form, this overview aims to provide a unifying
perspective on RSs to lower the bar to entry for tackling them. Ultimately, we
hope this overview contributes to the development of reliable NeSy and
trustworthy AI models.

</details>


### [38] [LLM Agents Beyond Utility: An Open-Ended Perspective](https://arxiv.org/abs/2510.14548)
*Asen Nachkov,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: 该研究探讨了预训练LLM代理能否通过自我生成任务、积累知识和环境交互，成为具有自主规划和推理能力的实体。


<details>
  <summary>Details</summary>
Motivation: 研究LLM代理能否从智能问题解决工具发展为具有自主规划、任务设计和模糊目标推理能力的实体。

Method: 采用开放式实验设置，增强预训练LLM代理的能力，使其能够生成自己的任务、积累知识并与环境广泛交互。

Result: 代理能够可靠地遵循复杂多步骤指令，跨运行存储和重用信息，提出并解决自己的任务，但对提示设计敏感，容易重复生成任务，无法形成自我表征。

Conclusion: 研究显示了将预训练LLM适应开放性的前景和当前局限，为未来训练代理管理记忆、进行生产性探索和追求抽象长期目标指明了方向。

Abstract: Recent LLM agents have made great use of chain of thought reasoning and
function calling. As their capabilities grow, an important question arises: can
this software represent not only a smart problem-solving tool, but an entity in
its own right, that can plan, design immediate tasks, and reason toward
broader, more ambiguous goals? To study this question, we adopt an open-ended
experimental setting where we augment a pretrained LLM agent with the ability
to generate its own tasks, accumulate knowledge, and interact extensively with
its environment. We study the resulting open-ended agent qualitatively. It can
reliably follow complex multi-step instructions, store and reuse information
across runs, and propose and solve its own tasks, though it remains sensitive
to prompt design, prone to repetitive task generation, and unable to form
self-representations. These findings illustrate both the promise and current
limits of adapting pretrained LLMs toward open-endedness, and point to future
directions for training agents to manage memory, explore productively, and
pursue abstract long-term goals.

</details>


### [39] [ColorBench: Benchmarking Mobile Agents with Graph-Structured Framework for Complex Long-Horizon Tasks](https://arxiv.org/abs/2510.14621)
*Yuanyi Song,Heyuan Huang,Qiqiang Lin,Yin Zhao,Xiangmou Qu,Jun Wang,Xingyu Lou,Weiwen Liu,Zhuosheng Zhang,Jun Wang,Yong Yu,Weinan Zhang,Zhaoxiang Wang*

Main category: cs.AI

TL;DR: 本文提出了ColorBench，一种用于评估移动代理在复杂长程任务中性能的图结构基准框架，通过模拟真实设备交互的有限状态来实现动态行为的静态模拟。


<details>
  <summary>Details</summary>
Motivation: 当前移动代理评估标准存在局限：离线静态基准只能验证单一预定义路径，而在线动态测试受限于真实设备的复杂性和不可复现性，两者都无法全面评估代理能力。

Method: 开发了基于图结构的基准框架，通过建模真实设备交互中的有限状态实现动态行为的静态模拟，构建了包含175个任务的ColorBench基准，支持多有效解决方案评估、子任务完成率统计和原子级能力分析。

Result: ColorBench包含175个任务（74个单应用、101个跨应用），平均长度超过13步，每个任务至少包含两条正确路径和若干典型错误路径。通过评估发现现有模型存在局限性。

Conclusion: 基于实验结果提出了改进方向和可行的技术路径，以增强代理在复杂长程问题上的性能。代码和数据已开源。

Abstract: The rapid advancement of multimodal large language models has enabled agents
to operate mobile devices by directly interacting with graphical user
interfaces, opening new possibilities for mobile automation. However,
real-world mobile tasks are often complex and allow for multiple valid
solutions. This contradicts current mobile agent evaluation standards: offline
static benchmarks can only validate a single predefined "golden path", while
online dynamic testing is constrained by the complexity and non-reproducibility
of real devices, making both approaches inadequate for comprehensively
assessing agent capabilities. To bridge the gap between offline and online
evaluation and enhance testing stability, this paper introduces a novel
graph-structured benchmarking framework. By modeling the finite states observed
during real-device interactions, it achieves static simulation of dynamic
behaviors. Building on this, we develop ColorBench, a benchmark focused on
complex long-horizon tasks. It supports evaluation of multiple valid solutions,
subtask completion rate statistics, and atomic-level capability analysis.
ColorBench contains 175 tasks (74 single-app, 101 cross-app) with an average
length of over 13 steps. Each task includes at least two correct paths and
several typical error paths, enabling quasi-dynamic interaction. By evaluating
ColorBench across various baselines, we discover limitations of existing models
and propose improvement directions and feasible technical pathways to enhance
agents' performance on complex, long-horizon problems based on experimental
results. Code and data are available at:
https://github.com/MadeAgents/ColorBench.

</details>


### [40] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: 本文提出了Rose-Frame框架，用于诊断人机交互中的认知和认识论漂移，通过三个维度（地图vs领土、直觉vs理性、冲突vs确认）来识别LLM的局限性，强调将AI对齐重新定义为认知治理。


<details>
  <summary>Details</summary>
Motivation: LLM虽然流畅且情感共鸣，但基于统计预测而非基础推理，存在幻觉风险，可能产生听起来有说服力但缺乏事实有效性的回答。

Method: 引入Rose-Frame三维框架：(i)地图vs领土区分现实表征与现实本身；(ii)直觉vs理性基于双过程理论分离快速情感判断与缓慢反思思维；(iii)冲突vs确认检验思想是通过批判性测试还是简单相互验证。

Result: Rose-Frame不试图用更多数据或规则修复LLM，而是提供反思工具，使模型局限性和用户假设可见，实现更透明和批判性意识的AI部署。

Conclusion: 将AI对齐重新定义为认知治理：无论是人类还是人工智能的直觉，都必须由人类理性来治理。只有通过嵌入反思性、可证伪的监督，才能使机器流畅性与人类理解保持一致。

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [41] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 本文对2021-2025年荷兰公共卫生机器学习研究中的算法偏见进行了系统性文献回顾，开发了RABAT评估工具，发现普遍存在公平性框架缺失等问题，并提出了ACAR四阶段框架来帮助解决偏见问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习在公共卫生领域有巨大潜力，但如果不系统关注算法偏见，可能会无意中加剧现有的健康不平等。

Method: 开发了RABAT评估工具，整合了Cochrane偏见风险、PROBAST和微软负责任AI检查表等框架，对35篇同行评审研究进行了系统性分析。

Result: 分析显示普遍存在差距：虽然数据抽样和缺失数据处理记录良好，但大多数研究缺乏明确的公平性框架、亚组分析和潜在危害的透明讨论。

Conclusion: 提出了ACAR四阶段公平性导向框架，为公共卫生ML从业者提供可操作建议，确保算法创新促进而非损害健康公平。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [42] [TITAN: Graph-Executable Reasoning for Cyber Threat Intelligence](https://arxiv.org/abs/2510.14670)
*Marco Simoni,Aleksandar Fontana,Andrea Saracino,Paolo Mori*

Main category: cs.AI

TL;DR: TITAN是一个连接自然语言网络威胁查询与结构化知识图谱推理的框架，包含路径规划器和图谱执行器，支持在MITRE威胁图谱上进行双向推理。


<details>
  <summary>Details</summary>
Motivation: 传统检索系统无法在威胁情报领域进行清晰可逆的推理，需要将自然语言查询与结构化知识图谱的可执行推理路径连接起来。

Method: 集成路径规划模型预测逻辑关系链，图谱执行器遍历TITAN本体检索事实答案和证据，基于MITRE构建类型化双向图。

Result: 创建了包含88209个样本的TITAN数据集，实证评估显示模型能生成语法有效、语义连贯的可执行推理路径。

Conclusion: TITAN框架成功实现了自然语言威胁查询到结构化知识图谱的可执行推理，支持威胁、行为和防御之间的清晰双向推理。

Abstract: TITAN (Threat Intelligence Through Automated Navigation) is a framework that
connects natural-language cyber threat queries with executable reasoning over a
structured knowledge graph. It integrates a path planner model, which predicts
logical relation chains from text, and a graph executor that traverses the
TITAN Ontology to retrieve factual answers and supporting evidence. Unlike
traditional retrieval systems, TITAN operates on a typed, bidirectional graph
derived from MITRE, allowing reasoning to move clearly and reversibly between
threats, behaviors, and defenses. To support training and evaluation, we
introduce the TITAN Dataset, a corpus of 88209 examples (Train: 74258; Test:
13951) pairing natural language questions with executable reasoning paths and
step by step Chain of Thought explanations. Empirical evaluations show that
TITAN enables models to generate syntactically valid and semantically coherent
reasoning paths that can be deterministically executed on the underlying graph.

</details>


### [43] [NAEL: Non-Anthropocentric Ethical Logic](https://arxiv.org/abs/2510.14676)
*Bianca Maria Lerma,Rafael Peñaloza*

Main category: cs.AI

TL;DR: NAEL是一个基于主动推理和符号推理的新型人工智能伦理框架，通过最小化全局预期自由能量来形式化伦理行为，采用神经符号架构让智能体在不确定环境中评估行为伦理后果。


<details>
  <summary>Details</summary>
Motivation: 传统以人为中心的AI伦理方法存在局限性，需要发展不预设人类道德直觉、能够适应多智能体环境的伦理框架。

Method: 提出神经符号架构，结合主动推理和符号推理，使智能体能够在动态多智能体环境中最小化全局预期自由能量。

Result: 通过伦理资源分配的案例研究展示了NAEL能够动态平衡自我保存、认知学习和集体福利。

Conclusion: NAEL为人工智能系统提供了一种非人类中心主义的伦理框架，能够产生情境敏感、自适应和关系性的伦理行为。

Abstract: We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical
framework for artificial agents grounded in active inference and symbolic
reasoning. Departing from conventional, human-centred approaches to AI ethics,
NAEL formalizes ethical behaviour as an emergent property of intelligent
systems minimizing global expected free energy in dynamic, multi-agent
environments. We propose a neuro-symbolic architecture to allow agents to
evaluate the ethical consequences of their actions in uncertain settings. The
proposed system addresses the limitations of existing ethical models by
allowing agents to develop context-sensitive, adaptive, and relational ethical
behaviour without presupposing anthropomorphic moral intuitions. A case study
involving ethical resource distribution illustrates NAEL's dynamic balancing of
self-preservation, epistemic learning, and collective welfare.

</details>


### [44] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: COUP是一个基于效用的算法配置程序，本文通过一系列改进提升了其实际性能，使其在保持理论保证的同时能与启发式配置方法竞争，并通过案例研究展示了算法选择对效用函数变化的鲁棒性分析。


<details>
  <summary>Details</summary>
Motivation: COUP虽然具有强大的理论保证，但在实际性能方面关注不足。本文旨在弥补这一差距，使基于效用的算法配置方法在实践性能上能与广泛使用的启发式配置方法竞争。

Method: 提出了一系列对COUP的改进措施，这些改进在不降低理论保证的前提下提升了算法的经验性能，并通过实验验证了这些改进的效果。

Result: 改进后的COUP在保持理论保证的同时，其实际性能得到了显著提升，能够与没有性能保证的启发式配置程序竞争。

Conclusion: 本文成功地将基于效用的算法配置方法提升到了实用水平，使其在理论和实践性能上都表现出色，并通过案例研究展示了如何分析算法选择对效用函数变化的鲁棒性。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [45] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: 提出了PAVE方法，通过在知识感知子空间中净化任务向量来解决模型合并中的冗余冲突问题，提升合并模型性能


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法中，任务向量包含任务无关的冗余信息，导致合并模型性能显著下降。现有随机丢弃参数的方法缺乏知识感知能力

Method: 通过采样训练样本获取协方差矩阵，进行上下文导向的奇异值分解，在知识感知子空间中将微调模型权重分解为任务相关和冗余组件，并剪枝冗余组件

Result: PAVE作为即插即用方案，可应用于各种基于任务向量的合并方法，在多种合并方法、任务和模型架构上均表现出有效性

Conclusion: PAVE方法通过知识感知的任务向量净化，显著提升了模型合并的性能，为解决任务向量冗余问题提供了有效方案

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [46] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: CoAST框架通过自然语言接口整合世界知识、时空轨迹模式和用户信息，解决LLM在POI推荐中缺乏地理实体理解和认知对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM主要基于非结构化文本预训练，缺乏对结构化地理实体和移动模式的理解，且未充分利用世界知识和人类认知对齐来提升POI推荐性能。

Method: 采用两阶段方法：1) 在脱敏用户时空轨迹数据上继续预训练获取推荐知识；2) 通过监督微调和强化学习实现认知对齐。

Result: 在多个真实数据集和AMAP App的在线实验中验证了CoAST的有效性。

Conclusion: CoAST框架成功解决了LLM在POI推荐中的地理理解和认知对齐问题，提升了推荐性能。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [47] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: 提出了一个结合细粒度波束搜索和过程奖励模型ToolPRM的推理扩展框架，用于提升大语言模型在结构化输出（如函数调用）任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前推理扩展研究主要关注非结构化输出生成任务，而在结构化输出（如函数调用）中的应用研究不足，需要填补这一空白。

Method: 构建了首个细粒度的函数调用内部过程监督数据集，使用函数掩码技术自动标注步骤级奖励，训练ToolPRM过程奖励模型，并与细粒度波束搜索结合。

Result: ToolPRM在预测准确性上优于粗粒度和结果奖励模型，推理扩展技术结合ToolPRM显著提升了骨干模型在各种函数调用任务和基准测试中的性能。

Conclusion: 揭示了将推理扩展技术应用于结构化输出的关键原则："多探索少保留"，这是由于结构化函数调用生成的不可恢复性特征决定的。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [48] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: 提出了SimKO方法来解决强化学习验证奖励(RLVR)中的过度集中问题，通过非对称设计提升探索能力，改善pass@K性能


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在系统性偏差，倾向于利用而非探索，表现为pass@1提升但pass@K(K>1)下降。研究发现这是由于词汇候选概率分布过度集中导致的

Method: 提出SimKO方法：对已验证正确响应，提升top-K候选概率；对已验证错误响应，对top-1候选施加更强惩罚。特别在高熵token上应用此非对称设计

Result: 在多个数学和逻辑推理基准测试中，SimKO在各种K值下都能持续获得更高的pass@K分数

Conclusion: SimKO提供了一种简单有效的方法来缓解RLVR中的过度集中问题，显著改善了模型的探索能力

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [49] [Agentic NL2SQL to Reduce Computational Costs](https://arxiv.org/abs/2510.14808)
*Dominik Jehle,Lennart Purucker,Frank Hutter*

Main category: cs.AI

TL;DR: Datalake Agent是一个代理系统，通过交互式循环减少NL2SQL任务中的元信息使用，显著降低LLM处理成本


<details>
  <summary>Details</summary>
Motivation: 传统NL2SQL方法需要处理大量数据库元信息，导致提示过长、处理成本高

Method: 采用交互式循环和推理框架，选择性请求必要信息来解决表格问答任务

Result: 在23个数据库的100个表格问答任务上评估，将LLM使用的token减少高达87%，同时保持竞争力性能

Conclusion: Datalake Agent能大幅降低处理成本，同时维持NL2SQL任务的性能

Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively requests only the necessary information to solve a
table question answering task. We evaluate the Datalake Agent on a collection
of 23 databases with 100 table question answering tasks. The Datalake Agent
reduces the tokens used by the LLM by up to 87\% and thus allows for
substantial cost reductions while maintaining competitive performance.

</details>


### [50] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: 提出了RoboGPT-R1，一个两阶段微调框架，通过监督训练和强化学习结合，提升具身智能体在长视野操作任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和视觉语言模型在规划任务中仍面临常识和推理能力受限的问题，特别是在复杂真实环境中的长视野操作任务。监督微调在机器人规划任务中存在泛化能力差和物理理解不足的挑战。

Method: 采用两阶段微调框架：第一阶段通过专家序列进行监督训练获取基础知识；第二阶段使用强化学习解决模型在视觉空间理解和推理方面的不足。设计了基于规则的奖励函数，同时考虑长期性能和动作约束。

Result: 在EmbodiedBench基准测试中，基于Qwen2.5-VL-3B训练得到的推理模型显著优于GPT-4o-mini 21.33%，并超过其他基于Qwen2.5-VL-7B的工作20.33%。

Conclusion: 提出的两阶段微调框架有效提升了具身智能体的推理能力，在长视野操作任务中表现出色，证明了强化学习在弥补监督微调不足方面的有效性。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [51] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: Instruction Boosting是一种后生成方法，通过增加指令遵循率来提高LLM提示指令的可靠性，在10条指令的情况下可将遵循率提高4个百分点。


<details>
  <summary>Details</summary>
Motivation: 开发人员通常通过精心操作提示来影响LLM行为，但仅添加更多指令无法保证它们会被遵循，需要提高指令遵循的可靠性。

Method: 引入Instruction Boosting作为后生成方法，并创建SCALEDIF基准测试，包含最多10条指令的数据样本，同时开发定量冲突评分工具分析指令间的冲突。

Result: Instruction Boosting可将两条指令的遵循率提高7个百分点，十条指令的遵循率提高4个百分点。分析发现性能下降与指令间的紧张和冲突程度相关。

Conclusion: Instruction Boosting能有效提高LLM的指令遵循率，指令冲突是性能下降的重要因素，冲突评分工具可为开发者提供反馈。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [52] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: 提出了一种基于LLM的迭代搜索的形式化理论，通过模糊关系算子描述智能体在安全约束下的搜索过程，并引入覆盖生成函数来衡量可达性难度。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的生成-过滤-精炼迭代范式在AI+科学领域取得进展，但搜索效果依赖于如何将领域先验编码为结构化假设空间，需要系统化的形式化描述。

Method: 将智能体表示为输入输出的模糊关系算子，用安全包络约束智能体行为；通过加权可达路径的覆盖生成函数来衡量搜索难度；提供可测试的推断并通过多数投票实例验证。

Result: 建立了描述LLM辅助迭代搜索的形式化理论，提供了衡量智能体及其搜索空间的操作工具。

Conclusion: 该理论为LLM构建的迭代搜索提供了可行的语言和操作工具，提出了系统化的形式化描述方法。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [53] [LabOS: The AI-XR Co-Scientist That Sees and Works With Humans](https://arxiv.org/abs/2510.14861)
*Le Cong,Zaixi Zhang,Xiaotong Wang,Yin Di,Ruofan Jin,Michal Gerasimiuk,Yinkai Wang,Ravi K. Dinesh,David Smerkous,Alex Smerkous,Xuekun Wu,Shilong Liu,Peishan Li,Yi Zhu,Simran Serrao,Ning Zhao,Imran A. Mohammad,John B. Sunwoo,Joseph C. Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: LabOS是首个将计算推理与物理实验结合的AI科学家助手，通过多模态感知、自进化代理和XR技术实现人机协作，将实验室转变为智能协作环境。


<details>
  <summary>Details</summary>
Motivation: 现代科学发展需要思想与行动的结合，让AI超越计算设计直接参与物理实验，实现人机协同发现。

Method: 连接多模型AI代理、智能眼镜和人机协作，通过多模态感知让AI理解实验情境，在XR环境中实时协助实验执行。

Result: 在癌症免疫治疗靶点发现和干细胞工程等应用中，LabOS展示了AI能够参与实际实验过程。

Conclusion: LabOS将实验室转变为智能协作环境，让人工智能和人类发现共同进化。

Abstract: Modern science advances fastest when thought meets action. LabOS represents
the first AI co-scientist that unites computational reasoning with physical
experimentation through multimodal perception, self-evolving agents, and
Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model
AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see
what scientists see, understand experimental context, and assist in real-time
execution. Across applications--from cancer immunotherapy target discovery to
stem-cell engineering -- LabOS shows that AI can move beyond computational
design to participation, turning the laboratory into an intelligent,
collaborative environment where human and machine discovery evolve together.

</details>


### [54] [Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates](https://arxiv.org/abs/2510.14900)
*Wen-Kwang Tsao,Yao-Ching Yu,Chien-Ming Huang*

Main category: cs.AI

TL;DR: 提出了一个无需标注数据或模型权重更新的强化学习代理，通过生成针对性网络搜索查询来收集外部证据，迭代改进企业智能平台中的日志模式映射准确性。


<details>
  <summary>Details</summary>
Motivation: 企业智能平台需要整合来自多个第三方供应商的日志，但供应商文档在测试时经常不可用、格式混乱或不完整，导致模式映射困难。

Method: 使用强化学习代理：1)识别模糊的字段映射尝试；2)生成针对性网络搜索查询收集外部证据；3)应用基于置信度的奖励迭代优化映射。

Result: 将Microsoft Defender for Endpoint日志转换为通用模式，映射准确率从56.4%(仅LLM)提升到72.73%(RAG)再到93.94%(100次迭代后)，同时将需要专家审查的低置信度映射减少85%。

Conclusion: 该方法提供了一种基于证据的透明解决方案，为更稳健、可问责、可扩展、高效、灵活、适应性强和协作的行业问题解决铺平了道路。

Abstract: The Enterprise Intelligence Platform must integrate logs from numerous
third-party vendors in order to perform various downstream tasks. However,
vendor documentation is often unavailable at test time. It is either misplaced,
mismatched, poorly formatted, or incomplete, which makes schema mapping
challenging. We introduce a reinforcement learning agent that can self-improve
without labeled examples or model weight updates. During inference, the agent:
1) Identifies ambiguous field-mapping attempts. 2) Generates targeted
web-search queries to gather external evidence. 3) Applies a confidence-based
reward to iteratively refine its mappings. To demonstrate this concept, we
converted Microsoft Defender for Endpoint logs into a common schema. Our method
increased mapping accuracy from 56.4\%(LLM-only) to 72.73\%(RAG) to 93.94\%
over 100 iterations using GPT-4o. At the same time, it reduced the number of
low-confidence mappings requiring expert review by 85\%. This new approach
provides an evidence-driven, transparent method for solving future industry
problems, paving the way for more robust, accountable, scalable, efficient,
flexible, adaptable, and collaborative solutions.

</details>


### [55] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 提出了一种结合判别式验证器和自一致性的混合测试时扩展方法，在固定计算预算下显著优于生成式验证方法，在AIME2025上准确率提升达15.3%。


<details>
  <summary>Details</summary>
Motivation: 现有生成式验证器虽然性能优秀但计算成本过高，限制了实际应用，需要寻找更高效的验证方法。

Method: 采用判别式验证器与自一致性结合的混合方法，在固定计算预算下进行测试时扩展。

Result: 在AIME2025上，该方法比最先进的生成式验证准确率提升15.3%，证明判别式验证器是更高效实用的选择。

Conclusion: 对于实际应用，基于判别式验证器的预算感知扩展不仅是自一致性的"免费"升级，也是比昂贵生成式技术更有效和高效的替代方案。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [56] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 本文系统研究了多模态抑郁症检测，比较了EEG、语音和文本特征表示与建模策略，发现三模态组合能提升检测性能，预训练嵌入优于手工特征，精心设计的三模态模型达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症自动检测研究存在范围有限、缺乏特征系统比较、评估协议不一致等问题，需要系统探索多模态特征表示和建模策略。

Method: 系统评估手工特征与预训练嵌入的有效性，比较不同神经编码器，分析单模态、双模态和三模态配置，研究融合策略，特别关注EEG的作用，采用一致的受试者独立分割确保稳健可复现的基准测试。

Result: EEG、语音和文本三模态组合增强了多模态检测性能；预训练嵌入优于手工特征；精心设计的三模态模型达到最先进性能水平。

Conclusion: 本研究为未来多模态抑郁症检测研究奠定了基础，证明了多模态方法和预训练嵌入的有效性。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [57] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 将康德的《纯粹理性批判》重新解释为反馈稳定性理论，提出复合不稳定性指数(H-Risk)来衡量推理系统的稳定性，发现高H-Risk预测过度自信错误，在LLMs中脆弱内部动态与错误校准和幻觉相关。


<details>
  <summary>Details</summary>
Motivation: 将康德的理性限制概念与反馈控制理论联系起来，为诊断和减少推理系统中的过度自信提供理论框架。

Method: 提出复合不稳定性指数H-Risk，结合谱边际、条件数、时间敏感性和创新放大等指标，在线性高斯模拟和大型语言模型中进行验证。

Result: 在线性高斯模拟中，高H-Risk预测过度自信错误；在LLMs中，脆弱内部动态与错误校准和幻觉相关，批判式提示对校准和幻觉的影响不一致。

Conclusion: 建立了康德式自我限制与反馈控制之间的结构桥梁，为诊断和选择性减少推理系统中的过度自信提供了原则性视角。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [58] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM是一个基于树搜索和外部工具验证的自动过程监督框架，通过蒙特卡洛树搜索构建结构化推理路径，使用外部工具验证中间步骤，融合工具验证和MCTS反馈的混合奖励机制，在仅使用10%数据的情况下在ProcessBench上实现26%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型面临三大挑战：噪声奖励、低事实保真度以及与步骤级推理目标的不对齐。这些问题源于昂贵的人工标注、易产生幻觉的LLM自评估，以及仅从最终结果推断步骤质量的蒙特卡洛估计方法。

Method: 1) 使用蒙特卡洛树搜索构建结构化推理路径以减少奖励噪声；2) 通过外部工具验证每个中间步骤，提供执行基础的正确性信号；3) 设计混合奖励聚合机制，融合工具验证和MCTS反馈；4) 将奖励信号格式化为增强推理的生成结构。

Result: 仅使用4万个自动标注样本（最佳PRM的10%数据量），在ProcessBench上实现高达26%的相对性能提升。在奖励引导的贪婪搜索中，甚至超越了使用人工标注监督训练的PRM。

Conclusion: GroundedPRM为高质量过程级推理提供了一条可扩展且可验证的路径，通过树引导和保真度感知的自动过程监督框架，有效解决了现有PRM的核心局限性。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


### [59] [Agentic Design of Compositional Machines](https://arxiv.org/abs/2510.14980)
*Wenqian Zhang,Weiyang Liu,Zhen Liu*

Main category: cs.AI

TL;DR: 该论文研究大语言模型能否通过组合式机器设计来创造复杂机器，引入了BesiegeField测试平台，评估LLMs在空间推理、策略组装等方面的能力，并探索了强化学习作为改进途径。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能够学习创造复杂机器，这是人类智能的标志和工程实践的基础。通过组合式机器设计任务来测试LLMs的创造能力。

Method: 引入BesiegeField测试平台，基于Besiege游戏构建，支持基于部件的构建、物理模拟和奖励驱动评估。使用代理工作流程对最先进的LLMs进行基准测试，并探索强化学习微调。

Result: 当前开源模型在空间推理、策略组装和指令跟随等关键能力上表现不足。通过强化学习微调实验，展示了改进潜力，但也突显了语言、机器设计和物理推理交叉领域的挑战。

Conclusion: 大语言模型在机器设计方面具有潜力，但需要解决空间推理、策略组装等关键能力不足的问题，强化学习是改进的有效途径，但仍面临多领域交叉的挑战。

Abstract: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [60] [Information flow in multilayer perceptrons: an in-depth analysis](https://arxiv.org/abs/2510.13846)
*Giuliano Armano*

Main category: cs.IT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Analysing how information flows along the layers of a multilayer perceptron
is a topic of paramount importance in the field of artificial neural networks.
After framing the problem from the point of view of information theory, in this
position article a specific investigation is conducted on the way information
is processed, with particular reference to the requirements imposed by
supervised learning. To this end, the concept of information matrix is devised
and then used as formal framework for understanding the aetiology of
optimisation strategies and for studying the information flow. The underlying
research for this article has also produced several key outcomes: i) the
definition of a parametric optimisation strategy, ii) the finding that the
optimisation strategy proposed in the information bottleneck framework shares
strong similarities with the one derived from the information matrix, and iii)
the insight that a multilayer perceptron serves as a kind of "adaptor", meant
to process the input according to the given objective.

</details>


### [61] [Structure-Preserving Error-Correcting Codes for Polynomial Frames](https://arxiv.org/abs/2510.13882)
*Baigang Chen,Dongfang Zhao*

Main category: cs.IT

TL;DR: 提出了一种结构保持的可靠性层，直接在多项式环上进行错误校正，避免格式转换和往返延迟，适用于FFT/NTT分析和隐私保护ML等应用。


<details>
  <summary>Details</summary>
Motivation: 传统防御方法不适合现代低延迟流水线：检测重传增加RTT，字节流ECC忽略代数结构并强制格式转换。需要一种在编码数据原始多项式环上操作的方法。

Method: 设计了两种互补方案：针对奇数长度使用Hensel提升的BCH理想和幂等编码器；针对2的幂次长度使用重根负循环码和导数式解码。通过环自同构实现原地交织以分散突发错误。

Result: 在四个帧大小(1024-8192)上，在符号错误率10^-6-10^-5时达到每帧失败目标10^-9，仅产生0.20%-1.56%开销，容忍~32-72字节未知错误突发（标记为擦除时约翻倍）。

Conclusion: 通过将错误校正与环语义对齐，从代数编码角度为多项式帧计算提供了可部署的鲁棒性。

Abstract: Modern FFT/NTT analytics, coded computation, and privacy-preserving ML
interface routinely move polynomial frames across NICs, storage, and
accelerators. However, even rare silent data corruption (SDC) can flip a few
ring coefficients and cascade through downstream arithmetic. Conventional
defenses are ill-matched to current low-latency pipelines:
detect-and-retransmit adds RTTs, while byte-stream ECC ignores the algebraic
structure and forces format conversions. To that end, we propose a
structure-preserving reliability layer that operates in the encoded data's
original polynomial ring, adds a small amount of systematic redundancy, and
corrects symbol errors/flagged erasures without round-trip or format changes.
We construct two complementary schemes: one for odd length $N_{odd}$ via a
Hensel-lifted BCH ideal with an idempotent encoder, and one for power-of-two
length $N_{2^m}$ via a repeated-root negacyclic code with derivative-style
decoding. In particular, to stay robust against clustered errors, a ring
automorphism provides in-place interleaving to disperse bursts. Implementation
wise, on four frame sizes $N\!=\!1024, 2048, 4096, 8192$, we meet a per-frame
failure target of $10^{-9}$ at symbol error rates $10^{-6}\text{--}10^{-5}$
with $t\!=\!8\text{--}9$, incurring only $0.20\%\text{--}1.56\%$ overhead and
tolerating $\sim\!32\text{--}72$\,B unknown-error bursts (roughly doubled when
flagged as erasures) after interleaving. By aligning error correction with ring
semantics, we take a practical step toward deployable robustness for
polynomial-frame computations from an algebraic coding perspective.

</details>


### [62] [Location-Aided Distributed Beamforming for Near-Field Communications with Element-Wise RIS](https://arxiv.org/abs/2510.14226)
*Xiao Zheng,Wenchi Cheng,Jingqing Wang,Zhuohui Yao,Jiangzhou Wang*

Main category: cs.IT

TL;DR: 本文提出了一种新型的元件级RIS架构和分布式位置辅助传输方案，用于解决RIS辅助近场通信中的信道估计难题和离散相位偏移约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作忽视了RIS辅助系统中固有的信道估计困难以及实际部署中的离散相位偏移约束，特别是零功耗有源RIS在增强部署灵活性时面临的技术挑战。

Method: 设计了新型元件级RIS架构，提供动态元件选择能力；基于菲涅尔衍射理论构建空间域位置到相位域波分布的映射；提出分布式波束成形设计，采用确定-对齐相位方法。

Result: 渐近分析表明，当RIS较大时，该方案能以固定比例的反射元件实现最优增益。仿真验证了其相对于其他协议的优越性。

Conclusion: 所提出的方案能够有效降低信道估计开销，提升RIS辅助近场通信的反射增益，为CSI受限场景提供了有效的解决方案。

Abstract: Active reconfigurable intelligent surface (RIS) emerges as an effective
technique to resist the double-fading attenuation of passive RIS. By embedding
with power harvesting function, it further evolves to zero-power active RIS,
which can effectively enhance the flexibility of RIS deployment without
external power demand. Nevertheless, existing works neglected the inherent
difficulty of channel estimation (CE) for RIS-assisted systems, and the
discrete phase shift constraint in practical deployment. In this paper we
design a new element-wise RIS architecture and propose a distributed
location-aided transmission scheme with low complexity to enhance the reflected
gain for channel state information (CSI)-limited RIS-assisted near-field
communications. Specifically, the new element-wise RIS provides dynamic element
selection capability with low hardware resources. Based on Fresnel diffraction
theory, we construct the mapping from locations in space-domain to phase
distributions of waves in phase-domain and reveal the priority of elements for
harvesting and reflecting. {Then, the distributed beamforming design with the
phase of determine-then-align is proposed, where the estimation overhead
reduction stems from exempted requirements of RIS-associated CE at base station
(BS).} The asymptotic analysis indicates that the proposed scheme can achieve
the optimal gain with a fixed proportion of reflective elements when RIS is
large, followed by simulations to verify its superiority to other protocols.

</details>


### [63] [Spatial Computing Communications for Multi-User Virtual Reality in Distributed Mobile Edge Computing Network](https://arxiv.org/abs/2510.14243)
*Caolu Xu,Zhiyong Chen,Meixia Tao,Li Song,Wenjun Zhang*

Main category: cs.IT

TL;DR: 提出空间计算通信框架SCC，通过多目标组合优化解决多用户VR在分布式移动边缘计算网络中的延迟和能耗问题，使用MO-CMPO算法生成帕累托最优解。


<details>
  <summary>Details</summary>
Motivation: 沉浸式VR应用在多用户交互场景中对延迟、能效和计算资源有严格要求，需要解决分布式移动边缘计算网络中的资源分配挑战。

Method: 提出SCC框架，使用概率模型表示物理空间和虚拟空间，将资源部署建模为多目标组合优化问题，开发MO-CMPO算法结合监督学习和强化学习进行优化。

Result: 在真实基站数据集上的仿真显示，MO-CMPO在超体积性能和推理延迟方面优于基线方法，延迟导向方案偏好本地MEC执行，能耗导向方案减少冗余部署。

Conclusion: SCC框架和MO-CMPO算法能有效平衡多用户VR应用的延迟和能耗需求，为分布式边缘计算网络中的资源优化提供了实用解决方案。

Abstract: Immersive virtual reality (VR) applications impose stringent requirements on
latency, energy efficiency, and computational resources, particularly in
multi-user interactive scenarios. To address these challenges, we introduce the
concept of spatial computing communications (SCC), a framework designed to meet
the latency and energy demands of multi-user VR over distributed mobile edge
computing (MEC) networks. SCC jointly represents the physical space, defined by
users and base stations, and the virtual space, representing shared immersive
environments, using a probabilistic model of user dynamics and resource
requirements. The resource deployment task is then formulated as a
multi-objective combinatorial optimization (MOCO) problem that simultaneously
minimizes system latency and energy consumption across distributed MEC
resources. To solve this problem, we propose MO-CMPO, a multi-objective
consistency model with policy optimization that integrates supervised learning
and reinforcement learning (RL) fine-tuning guided by preference weights.
Leveraging a sparse graph neural network (GNN), MO-CMPO efficiently generates
Pareto-optimal solutions. Simulations with real-world New Radio base station
datasets demonstrate that MO-CMPO achieves superior hypervolume performance and
significantly lower inference latency than baseline methods. Furthermore, the
analysis reveals practical deployment patterns: latency-oriented solutions
favor local MEC execution to reduce transmission delay, while energy-oriented
solutions minimize redundant placements to save energy.

</details>


### [64] [Reconfigurable Intelligent Surface-Enabled Channel Signature Modulation](https://arxiv.org/abs/2510.14290)
*M. A. Teeti*

Main category: cs.IT

TL;DR: 提出RIS-CSM方案，通过将RIS分区并使用二进制反射模式生成信道签名，在签名索引中嵌入信息，实现轻量级索引调制。


<details>
  <summary>Details</summary>
Motivation: 为可重构智能表面(RIS)设计轻量级索引调制方案，避免复杂的RIS侧波束成形，实现简单的信道估计和可扩展的频谱效率。

Method: 将N单元RIS划分为不相交组，每组使用预定二进制反射模式在接收端生成不同信道签名，信息嵌入在签名索引中。

Result: 推导了误码概率闭式上界和容量分析，显示分集阶数为n_R，编码增益与N成正比。瑞利衰落下的仿真验证了理论分析。

Conclusion: RIS-CSM是有效的轻量级索引调制方案，空间相关性在低频谱效率下能提升系统性能。

Abstract: This work proposes RIS-enabled channel signature modulation (RIS-CSM), a
lightweight index modulation scheme for reconfigurable intelligent surfaces
(RIS). An N-element RIS is partitioned into disjoint groups, each employing
predetermined binary reflection patterns to generate distinct channel
signatures at an $n_R$-antenna receiver, without RIS-side beamforming.
Information is embedded in the indices of these signatures, enabling simple
channel estimation and scalable spectral efficiency. A closed-form upper bound
on error probability and capacity analysis are derived, revealing diversity
order $n_R$ and coding gain proportional to N. Simulation results under
Rayleigh fading validate the theoretical analysis. Moreover, simulations
indicate that spatial correlation among RIS elements can improve system
performance at low spectral efficiency.

</details>


### [65] [The asymptotic number of equivalence classes of linear codes with given dimension](https://arxiv.org/abs/2510.14424)
*Andrea Di Giusto,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 本文研究了具有指定长度和维度的线性码等价类数量的渐近行为，推导了三种标准等价关系下的显式渐近公式，并建立了与布朗运动离散高斯分布的自然联系。


<details>
  <summary>Details</summary>
Motivation: 虽然给定长度的不等价码总数已有研究，但维度随长度变化的情况尚未被考虑，需要研究线性码等价类在固定字母表大小和增加长度下的渐近数量。

Method: 通过推导q-二项式系数和的精确渐近表达式，并分析三种标准等价关系下的渐近行为，建立了与离散高斯分布的连接。

Result: 获得了固定字母表大小和增加长度下线性码等价类数量的显式渐近公式，并给出了q-二项式系数和的精确渐近表达式。

Conclusion: 研究揭示了线性码等价类渐近数量与布朗运动离散高斯分布之间的自然联系，为结果提供了概率解释。

Abstract: We investigate the asymptotic number of equivalence classes of linear codes
with prescribed length and dimension. While the total number of inequivalent
codes of a given length has been studied previously, the case where the
dimension varies as a function of the length has not yet been considered. We
derive explicit asymptotic formulas for the number of equivalence classes under
three standard notions of equivalence, for a fixed alphabet size and increasing
length. Our approach also yields an exact asymptotic expression for the sum of
all q-binomial coefficients, which is of independent interest and answers an
open question in this context. Finally, we establish a natural connection
between these asymptotic quantities and certain discrete Gaussian distributions
arising from Brownian motion, providing a probabilistic interpretation of our
results.

</details>


### [66] [Rotatable Antenna-Enhanced Beamforming: Signal Enhancement and Interference Suppression](https://arxiv.org/abs/2510.14574)
*Jie Feng,Zhenbing Liu,Junjie Dai,Hongbin Chen,Fangjiong Chen*

Main category: cs.IT

TL;DR: 该论文研究了可旋转天线增强的单/多波束成形，通过优化天线旋转来利用新的空间自由度，以提升阵列增益性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定方向天线阵列由于不同转向角度下天线定向增益变化显著，可能难以有效增强信号和/或抑制干扰。

Method: 联合优化天线旋转向量和天线权重向量，针对单波束无干扰情况推导了闭式最优解，对多波束情况提出了交替优化算法。

Result: 仿真结果表明，所提出的可旋转天线方案在阵列增益方面显著优于传统固定方向天线和各向同性天线方案。

Conclusion: 通过利用天线旋转带来的新自由度，可旋转天线技术能够有效提升波束成形性能，突破传统天线的局限性。

Abstract: Conventional beamforming with fixed-orientation antenna (FOA) arrays may
struggle to effectively enhance signal and/or suppress interference due to
significant variations in antenna directive gains over different steering
angles. To break this limitation, we investigate in this paper the rotatable
antenna (RA)-enhanced single/multi-beam forming by exploiting the new spatial
degrees of freedom (DoFs) via antennas' rotation optimization. Specifically,
the antenna rotation vector (ARV) and antenna weight vector (AWV) are jointly
optimized to maximize the minimum array gain over signal directions, subject to
a given constraint on the maximum array gain over interference directions. For
the special case of single-beam forming without interference, the optimal ARV
is derived in closed-form with the maximum ratio combining (MRC) beamformer
applied to the AWV. For the general case of multi-beam forming, we propose an
efficient alternating optimization (AO) algorithm to find a high-quality
suboptimal solution by iteratively optimizing one of the ARV and AWV with the
other being fixed. Simulation results demonstrate that the proposed RA-based
scheme can significantly outperform the traditional FOA-based and isotropic
antenna (IA)-based schemes in terms of array gain.

</details>


### [67] [Task-Based Quantization for Channel Estimation in RIS Empowered MmWave Systems](https://arxiv.org/abs/2510.14649)
*Gyoseung Lee,In-soo Kim,Yonina C. Eldar,A. Lee Swindlehurst,Hyeongtaek Lee,Minje Kim,Junil Choi*

Main category: cs.IT

TL;DR: 该论文研究了在低分辨率量化条件下，可重构智能表面赋能的毫米波多用户单输入多输出通信系统的信道估计问题，提出了基于任务量化的信道估计设计。


<details>
  <summary>Details</summary>
Motivation: 由于大规模天线阵列和宽信号带宽中模数转换器的高成本和功耗，设计采用低分辨率ADC的毫米波系统是有益的。

Method: 提出了基于任务量化的信道估计设计，考虑混合模拟和数字架构，开发了两种信道估计器：纯无源RIS的级联信道估计器和利用RIS中少量半无源元件额外信息的分离信道估计器。

Result: 数值结果表明，所提出的基于任务量化的信道估计设计优于纯数字方法，并能有效接近无限分辨率ADC系统的性能，且具有较小的训练开销。

Conclusion: 基于任务量化的信道估计方法在低分辨率约束下能够显著提升系统性能，为实际毫米波系统部署提供了有效解决方案。

Abstract: In this paper, we investigate channel estimation for reconfigurable
intelligent surface (RIS) empowered millimeter-wave (mmWave) multi-user
single-input multiple-output communication systems using low-resolution
quantization. Due to the high cost and power consumption of analog-to-digital
converters (ADCs) in large antenna arrays and for wide signal bandwidths,
designing mmWave systems with low-resolution ADCs is beneficial. To tackle this
issue, we propose a channel estimation design using task-based quantization
that considers the underlying hybrid analog and digital architecture in order
to improve the system performance under finite bit-resolution constraints. Our
goal is to accomplish a channel estimation task that minimizes the mean squared
error distortion between the true and estimated channel. We develop two types
of channel estimators: a cascaded channel estimator for an RIS with purely
passive elements, and an estimator for the separate RIS-related channels that
leverages additional information from a few semi-passive elements at the RIS
capable of processing the received signals with radio frequency chains.
Numerical results demonstrate that the proposed channel estimation designs
exploiting task-based quantization outperform purely digital methods and can
effectively approach the performance of a system with unlimited resolution
ADCs. Furthermore, the proposed channel estimators are shown to be superior to
baselines with small training overhead.

</details>


### [68] [Rate-Adaptive Spatially Coupled MacKay-Neal Codes with Thresholds Close to Capacity](https://arxiv.org/abs/2510.14843)
*Ayman Zahr,Gianluigi Liva*

Main category: cs.IT

TL;DR: 分析了基于密度进化的速率自适应MacKay-Neal码集合的渐近性能，其中内码是原图空间耦合LDPC码，通过并行信道模型计算BP解码阈值，显示SC MN码集合在[0,1]速率范围内距离二进制输入AWGN信道容量仅0.15 dB。


<details>
  <summary>Details</summary>
Motivation: 研究速率自适应码集合的渐近性能，特别是结合空间耦合技术来提高接近信道容量的性能。

Method: 使用密度进化分析，构建并行信道模型，计算信念传播解码阈值，评估原图空间耦合LDPC码作为内码的MacKay-Neal码集合性能。

Result: SC MN码集合在[0,1]速率范围内能够实现距离二进制输入AWGN信道容量仅0.15 dB的性能。

Conclusion: 空间耦合的MacKay-Neal码集合在速率自适应场景下具有接近信道容量的优异性能表现。

Abstract: We analyze by density evolution the asymptotic performance of rate-adaptive
MacKay-Neal (MN) code ensembles, where the inner code is a protograph spatially
coupled (SC) low-density parity-check code. By resorting to a suitably-defined
parallel channel model, we compute belief propagation decoding thresholds,
showing that SC MN code ensembles can perform within 0.15 dB from the
binary-input additive white Gaussian noise capacity over the full [0,1] rate
range.

</details>


### [69] [Rate-Adaptive Protograph-Based MacKay-Neal Codes](https://arxiv.org/abs/2510.14856)
*Ayman Zahr,Emna Ben Yacoub,Balázs Matuz,Gianluigi Liva*

Main category: cs.IT

TL;DR: 本文分析了基于原图的速率自适应MacKay-Neal码，通过外部分布匹配器和内层LDPC码实现非线性编码结构，可在固定块长度下实现宽范围速率自适应，性能接近香农极限1dB以内。


<details>
  <summary>Details</summary>
Motivation: 为高吞吐量无线/光链路提供二进制输入调制下的速率自适应编码方案，在固定块长度和固定LDPC码的情况下实现灵活的速率调节。

Method: 采用外部分布匹配器与内层基于原图的LDPC码相结合的非线性编码结构，通过密度演进分析和误码平层分析进行性能评估。

Result: 设计出的编码方案可在宽速率范围内在香农极限1dB以内工作，通过调节DM参数选择码率，同时保持恒定块长度。

Conclusion: 该构造为采用二进制调制的高吞吐量无线/光链路提供了有吸引力的解决方案，实现了速率灵活性和接近最优的性能。

Abstract: Rate-adaptive MacKay-Neal (MN) codes based on protographs are analyzed. The
code construction employs an outer distribution matcher (DM) to adapt the rate
of the scheme. The DM is coupled with an inner protograph-based low-density
parity-check (LDPC) code. The performance achievable by the resulting code
structure, that is nonlinear, is studied by means of an equivalent
communication model that reduces the problem to the analysis of the inner
(linear) LDPC code with transmission that takes place in parallel over the
communication channel, and over a suitably defined binary symmetric channel. A
density evolution analysis of protograph MN code ensembles is outlined, and it
is complemented by an error floor analysis that relies on the derivation of the
average input-output weight distribution of the inner LDPC code ensemble.
Conditions on the shape of the normalized logarithmic asymptotic input-output
weight distribution are defined, which allow discarding code ensembles with bad
error floor properties during the code design phase. Examples of code designs
are provided, showing how the use of a single LDPC code ensemble allows
operating within 1 dB from the Shannon limit over a wide range of code rates,
where the code rate is selected by tuning the DM parameters. By enabling rate
flexibility with a constant blocklength, and with a fixed LDPC code as inner
code, the construction provides an appealing solution for very high-throughput
wireless (optical) links that employ binary-input modulations.

</details>


### [70] [The Whole Is Less than the Sum of Parts: Subsystem Inconsistency in Partial Information Decomposition](https://arxiv.org/abs/2510.14864)
*Aobo Lyu,Andrew Clark,Netanel Raviv*

Main category: cs.IT

TL;DR: 本文揭示了部分信息分解(PID)违反整体等于部分之和原则的问题，提出了针对三变量系统的系统信息分解(SID)框架来解决该问题，但证明在四变量及以上系统中无法完全消除该不一致性。


<details>
  <summary>Details</summary>
Motivation: 部分信息分解(PID)自2010年提出以来在神经科学和隐私等领域有广泛应用，但缺乏统一理论框架，存在关键概念和技术挑战。本文旨在解决PID违反整体等于部分之和原则(WESP)的根本问题。

Method: 通过三变量系统的反例展示PID如何违反WESP，然后引入新的公理化框架——系统信息分解(SID)，专门针对三变量系统重新定义基于协同关系的信息原子求和规则。

Result: SID框架成功解决了三变量系统中的WESP违反问题，但进一步证明在四变量及以上系统中，现有基于格结构的任何部分求和方法都无法完全消除WESP不一致性。

Conclusion: 基于(反链)格结构的分解方法对于一般多变量系统存在固有的不充分性，需要新的理论框架来克服这一根本限制。

Abstract: Partial Information Decomposition (PID) was proposed by Williams and Beer in
2010 as a tool for analyzing fine-grained interactions between multiple random
variables, and has since found numerous applications ranging from neuroscience
to privacy. However, a unified theoretical framework remains elusive due to key
conceptual and technical challenges. We identify and illustrate a crucial
problem: PID violates the set-theoretic principle that the whole equals the sum
of its parts (WESP). Through a counterexample in a three-variable system, we
demonstrate how such violations naturally arise, revealing a fundamental
limitation of current lattice-based PID frameworks. To address this issue, we
introduce a new axiomatic framework, termed System Information Decomposition
(SID), specifically tailored for three-variable systems. SID resolves the WESP
violation by redefining the summation rules of decomposed information atoms
based on synergistic relationships. However, we further show that for systems
with four or more variables, no partial summation approach within the existing
lattice-based structures can fully eliminate WESP inconsistencies. Our results
thus highlight the inherent inadequacy of (antichain) lattice-based
decompositions for general multivariate systems.

</details>
