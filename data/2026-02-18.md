<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Exploring Performance Tradeoffs in Age-Aware Remote Monitoring with Satellites](https://arxiv.org/abs/2602.15145)
*Sunjung Kang,Vishrant Tripathi,Christopher G. Brinton*

Main category: cs.NI

TL;DR: 研究多模态远程监控系统（IoT传感器、无人机、卫星）中信息新鲜度优化问题，分析是否应使用卫星更新数据，并提出调度策略。


<details>
  <summary>Details</summary>
Motivation: 多模态监控系统（IoT、无人机、卫星）各有优缺点：IoT覆盖小但固定，无人机可移动覆盖较大区域，卫星覆盖全区域但延迟高可靠性低。需要研究如何优化信息新鲜度，特别是是否应使用卫星数据。

Method: 将部署区域划分为单元格并建模为图，节点代表单元格，边代表无人机移动模式。采用信息年龄（AoI）度量信息新鲜度。开发了随机调度策略的闭式表达式和下界，并提出Lyapunov风格的最大权重策略。

Result: 推导出加权和AoI的闭式表达式和下界，分析了系统参数变化时的性能权衡。通过详细模拟为实际部署提供了关键见解。

Conclusion: 该研究为多模态监控系统的信息新鲜度优化提供了理论分析和实用策略，解决了是否使用卫星数据的决策问题，对实际系统部署具有指导意义。

Abstract: We investigate a remote monitoring framework with multiple sensing modalities including IoT sensors on the ground, mobile UAVs in the air, and a periodically available satellite constellation. While the IoT sensors cover small areas and remain fixed, the UAVs can move between locations and cover larger areas, and the satellites can observe the entire region but have high latency and low reliability. We divide the deployment region into cells and model it as a graph, with the nodes representing individual cells and edges representing possible UAV mobility patterns. To evaluate the freshness of collected information from this graph, we adopt the Age of Information (AoI) metric, measured separately for each cell. Under a given deployment of IoT nodes and UAV mobility patterns, our objective is to ascertain whether the system should actually utilize monitoring updates from satellites - a seemingly simple yet surprisingly elusive question. For stationary randomized scheduling policies, we develop closed-form expressions and lower bounds for the weighted-sum AoI and utilize this analysis to explore performance tradeoffs as system parameters vary. We also provide a Lyapunov style max-weight policy and detailed simulations that provide crucial insights for deploying such systems in practice.

</details>


### [2] [High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration](https://arxiv.org/abs/2602.15281)
*Merve Saimler,Mohaned Chraiti,Ozgur Ercetin*

Main category: cs.NI

TL;DR: 论文提出基于尾部风险包络（TREs）的AIaaS管理平面，通过可组合的每域描述符和随机网络演算，实现跨域AIaaS服务的性能保证和风险分解。


<details>
  <summary>Details</summary>
Motivation: 通信服务提供商正从纯连接提供商向AIaaS管理网络服务转型，需要解决多域联邦环境下AIaaS服务的端到端性能保证问题，特别是通信损伤和推理损伤的联合管理。

Method: 提出基于尾部风险包络（TREs）的保证导向AIaaS管理平面，TREs是带符号、可组合的每域描述符，结合确定性护栏和随机速率-延迟-损伤模型。使用随机网络演算推导串联域端到端延迟违规概率界限，获得优化就绪的风险预算分解。

Result: 租户级预留防止突发流量在TRE合同下膨胀尾部延迟。审计层使用运行时遥测估计极端百分位性能，量化不确定性，并将尾部风险归因于每个域以实现问责。包级蒙特卡洛模拟显示在过载情况下通过准入控制改善了p99.9合规性，并在相关突发性下实现稳健的租户隔离。

Conclusion: TRE框架为多域AIaaS服务提供了可操作的保证机制，通过风险预算分解和运行时审计实现了端到端性能保证和域间问责。

Abstract: To support the emergence of AI-as-a-Service (AIaaS), communication service providers (CSPs) are on the verge of a radical transformation-from pure connectivity providers to AIaaS a managed network service (control-and-orchestration plane that exposes AI models). In this model, the CSP is responsible not only for transport/communications, but also for intent-to-model resolution and joint network-compute orchestration, i.e., reliable and timely end-to-end delivery. The resulting end-to-end AIaaS service thus becomes governed by communications impairments (delay, loss) and inference impairments (latency, error). A central open problem is an operational AIaaS control-and-orchestration framework that enforces high fidelity, particularly under multi-domain federation. This paper introduces an assurance-oriented AIaaS management plane based on Tail-Risk Envelopes (TREs): signed, composable per-domain descriptors that combine deterministic guardrails with stochastic rate-latency-impairment models. Using stochastic network calculus, we derive bounds on end-to-end delay violation probabilities across tandem domains and obtain an optimization-ready risk-budget decomposition. We show that tenant-level reservations prevent bursty traffic from inflating tail latency under TRE contracts. An auditing layer then uses runtime telemetry to estimate extreme-percentile performance, quantify uncertainty, and attribute tail-risk to each domain for accountability. Packet-level Monte-Carlo simulations demonstrate improved p99.9 compliance under overload via admission control and robust tenant isolation under correlated burstiness.

</details>


### [3] [AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service](https://arxiv.org/abs/2602.15286)
*Merve Saimler,Mohaned Chraiti*

Main category: cs.NI

TL;DR: 提出AI-paging架构，用于6G网络中AI服务的意图解析、模型匹配和执行锚点选择，确保策略、信任和QoS约束下的服务连续性。


<details>
  <summary>Details</summary>
Motivation: 随着AIaaS在多提供商和多模型层级部署，用户难以在运行时选择合适的模型实例。6G服务提供商需要在用户仅提交意图时，帮助完成意图到模型的匹配和执行放置，同时满足策略、信任和QoS约束。

Method: 提出AI-paging控制平面事务，将意图解析为AI服务身份(AISI)、范围会话令牌(AIST)和过期准入租约(COMMIT)，授权用户平面转向选定的AI执行锚点(AEXF)。强制执行租约门控转向和先建后断锚定两个不变性。

Result: 原型实现使用现有控制平面和用户平面机制（基于服务的控制、QoS流和基于策略的转向），无需新包头，兼容现有3GPP架构。评估了事务延迟、重定位中断、租约过期时的执行正确性以及移动性和故障下的审计证据开销。

Conclusion: AI-paging架构为6G网络中的AIaaS服务提供了一种有效的控制平面解决方案，能够在动态网络条件下确保服务连续性、可靠性和策略合规性，同时保持与现有3GPP架构的兼容性。

Abstract: With AI-as-a-Service (AIaaS) now deployed across multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the intent-to-model matching (resolution) and execution placement under policy, trust, and Quality of Service (QoS) constraints. The network role becomes to discover candidate execution endpoints and selects a suitable model/anchor under policy and QoS constraints in a process referred here to as AI-paging (by analogy to cellular call paging). In the proposed architecture, AI-paging is a control-plane transaction that resolves an intent into an AI service identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under a QoS binding. AI-Paging enforces two invariants: (i) lease-gated steering (without COMMIT, no steering state is installed) and (ii) make-before-break anchoring to support continuity and reliability of AIaaS services under dynamic network conditions. We prototype AI-Paging using existing control- and user-plane mechanisms (service-based control, QoS flows, and policy-based steering) with no new packet headers, ensuring compatibility with existing 3GPP-based exposure and management architectures, and evaluate transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit-evidence overhead under mobility and failures.

</details>


### [4] [AI Sessions for Network-Exposed AI-as-a-Service](https://arxiv.org/abs/2602.15288)
*Merve Saimler,Mohaned Chraiti*

Main category: cs.NI

TL;DR: 提出Network-Exposed AI-as-a-Service (NE-AIaaS)架构，通过AI会话(AIS)和服务配置文件(ASP)实现AI推理服务的网络可保障、可移动和可计费


<details>
  <summary>Details</summary>
Motivation: 当前云AI推理服务对延迟和上下文敏感，但现有AI-as-a-Service与网络解耦，无法提供尾部延迟保障、计算感知的准入控制以及移动连续性

Method: 提出AI会话(AIS)作为服务原语，绑定模型身份、执行位置、传输QoS和计费范围；引入AI服务配置文件(ASP)表达任务特性和服务目标；设计协议级流程包括发现、AI寻呼、两阶段资源预留和迁移机制

Result: 设计了可映射到标准框架(CAPIF、MEC、5G QoS、NWDAF)的NE-AIaaS架构，实现网络可保障的AI推理服务

Conclusion: NE-AIaaS通过将AI会话作为网络可感知的服务原语，解决了云AI推理的延迟保障、移动连续性和资源协同问题，为下一代AI服务提供了标准化框架

Abstract: Cloud-based Artificial Intelligence (AI) inference is increasingly latency- and context-sensitive, yet today's AI-as-a-Service is typically consumed as an application-chosen endpoint, leaving the network to provide only best-effort transport. This decoupling prevents enforceable tail-latency guarantees, compute-aware admission control, and continuity under mobility. This paper proposes Network-Exposed AI-as-a-Service (NE-AIaaS) built around a new service primitive: the AI Session (AIS)-a contractual object that binds model identity, execution placement, transport Quality-of-Service (QoS), and consent/charging scope into a single lifecycle with explicit failure semantics. We introduce the AI Service Profile (ASP), a compact contract that expresses task modality and measurable service objectives (e.g., time-to-first-response/token, p99 latency, success probability) alongside privacy and mobility constraints. On this basis, we specify protocol-grade procedures for (i) DISCOVER (model/site discovery), (ii) AI PAGING (context-aware selection of execution anchor), (iii) two-phase PREPARE/COMMIT that atomically co-reserves compute and QoS resources, and (iv) make-before-break MIGRATION for session continuity. The design is standard-mappable to Common API Framework (CAPIF) style northbound exposure, ETSI Multi-access Edge Computing (MEC) execution substrates, 5G QoS flows for transport enforcement, and Network Data Analytics Function (NWDAF) style analytics for closed-loop paging/migration triggers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis](https://arxiv.org/abs/2602.15067)
*Rut Pate,Snehal Rajput,Mehul S. Raval,Rupal A. Kapdi,Mohendra Roy*

Main category: cs.AI

TL;DR: 该研究提出了一种基于注意力门控循环残差U-Net的三平面(2.5D)模型，用于改进脑胶质瘤分割，并在分割准确性和生存预测方面取得了良好结果。


<details>
  <summary>Details</summary>
Motivation: 脑胶质瘤作为最常见的原发性脑肿瘤，其侵袭性、预后和组织学特征差异很大，复杂且耗时的外科手术干预使得治疗具有挑战性，需要更精确的分割方法来辅助治疗规划。

Method: 提出注意力门控循环残差U-Net(R2U-Net)的三平面(2.5D)模型，整合残差、循环和三平面架构来增强特征表示和分割精度，同时保持计算效率。使用三平面网络从每个平面模型提取64个特征用于生存天数预测，并通过人工神经网络将特征减少到28个。

Result: 在BraTS2021验证集上，全肿瘤分割的Dice相似性分数达到0.900，性能与领先模型相当。生存预测方面，测试集上准确率为45.71%，均方误差为108,318.128，Spearman等级相关系数为0.338。

Conclusion: 提出的注意力门控循环残差U-Net三平面模型在脑肿瘤分割方面表现出色，分割精度高，同时能够有效提取特征用于生存预测，有助于改善治疗规划。

Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.

</details>


### [6] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个用于评估AI代理端到端研究能力的基准测试和执行环境，包含5个论文任务环境共39个子任务。GPT-5代理在15次评估中仅1次超越基线（6.7%），平均只完成26.5%的子任务，显示出能力与可靠性之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估AI代理进行完整研究流程（提出假设、运行实验、超越人类基线）的基准环境。需要了解前沿AI代理在实际研究任务中的表现、失败模式以及能力可靠性差距。

Method: 从ICML、ICLR和ACL会议中选取5篇口头报告和焦点论文，保留其数据集、评估框架和基线实现，但移除原论文提出的方法。构建5个容器化任务环境共39个子任务，要求代理提出新假设、运行实验并超越人类基线。评估了GPT-5、Claude Code和Codex等代理的表现。

Result: GPT-5代理在15次评估中仅1次（6.7%）超越基线，改进幅度为11.5%，平均只完成26.5%的子任务。发现了长期失败模式：缺乏耐心、资源管理差、对弱假设过度自信、并行实验协调困难、上下文长度限制。但在单次运行中成功超越了ICML 2025焦点任务的解决方案。

Conclusion: 前沿AI代理偶尔能达到最先进的研究性能，但可靠性很低。存在显著的能力-可靠性差距，需要系统评估和自主代理分析的基础设施。ResearchGym为闭环研究中的自主代理提供了系统评估和分析框架。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [7] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该论文研究如何通过修改教师模型的推理输出来防止未经授权的知识蒸馏，实现反蒸馏和API水印两种目标。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏被广泛用于将大语言模型能力迁移到更小的学生模型，但未经授权的蒸馏不公平地利用了前沿模型开发的巨大投入和成本。

Method: 提出了多种动态重写教师模型推理输出的方法：两种基于LLM的重写能力，其他使用基于梯度的技术，在保持答案正确性和语义连贯性的同时修改推理轨迹。

Result: 简单的基于指令的重写方法实现了强大的反蒸馏效果，同时保持甚至提高了教师模型性能；重写方法还实现了高度可靠的水印检测，几乎没有误报。

Conclusion: 通过动态重写推理输出可以有效防止未经授权的知识蒸馏，同时实现反蒸馏和API水印，保护模型开发者的知识产权。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [8] [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)
*Shreyas Rajesh,Pavan Holur,Mehmet Yigit Turali,Chenda Duan,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: Panini提出了一种非参数持续学习框架，将文档表示为生成式语义工作空间（GSW）——基于实体和事件的问答对网络，通过推理链在网络上进行知识挖掘，相比传统RAG方法更高效准确。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）方法存在两个主要问题：1）测试时计算效率低（LLM需要重复处理相同文档）；2）块检索可能引入不相关上下文，导致无依据的生成。需要一种更高效、更可靠的持续学习方法。

Method: 提出Panini框架，将文档表示为生成式语义工作空间（GSW）——基于实体和事件的问答对网络。基础模型保持不变，学习通过将每个新经验整合到外部语义记忆状态中实现。给定查询时，仅遍历持续更新的GSW（而非原始文档或块），检索最可能的推理链。

Result: 在六个QA基准测试中，Panini实现了最高平均性能，比其他竞争基线高5%-7%，同时使用2-30倍更少的答案上下文标记，支持完全开源流程，并在精心策划的不可回答查询上减少了无依据答案。

Conclusion: 在写入时高效准确地结构化经验（如GSW框架所实现的）在读取时既提高了效率又增强了可靠性。该方法展示了非参数持续学习的有效性，为语言模型处理新文档和不断发展的知识提供了更优方案。

Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.

</details>


### [9] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 提出一种基于da Costian-Tarskianism的本体异质性新方法，使用扩展后承系统和扩展开发图来关联本体


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性问题，借鉴Carnapian-Goguenism思想，为不同本体系统间的互操作提供理论基础

Method: 基于后承系统理论，引入扩展后承系统（添加本体公理），定义扩展开发图结构，通过后承系统态射、纤维化和分裂等操作关联本体

Result: 建立了da Costian-Tarskianism理论框架，提供了形式化工具来处理本体异质性，支持本体间的多种关系操作

Conclusion: 该方法为应用本体论领域提供了新的理论基础，未来可进一步探索实际应用和理论扩展

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [10] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该研究比较了20个前沿和开源大语言模型在风险决策中的表现，发现LLM可分为推理模型和对话模型两类，前者更理性，后者更接近人类但理性程度较低。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在决策支持系统和智能体工作流中的广泛应用，但对其在不确定性下的决策机制理解有限。研究旨在比较LLM在风险选择中的表现，特别关注前景表示方式（显式vs经验基础）和决策理由（解释）两个维度。

Method: 研究涉及20个前沿和开源LLM，通过匹配的人类被试实验提供参考点，同时使用期望收益最大化的理性智能体模型作为另一参考。研究比较LLM在两个维度上的表现：前景表示（显式vs经验历史）和决策理由（解释）。

Result: 发现LLM可分为两类：推理模型（RMs）倾向于理性行为，对前景顺序、得失框架和解释不敏感，在显式和经验历史前景下表现相似；对话模型（CMs）理性程度显著较低，更接近人类，对前景顺序、框架和解释敏感，且表现出较大的描述-历史差距。开源LLM的配对比较表明，区分RMs和CMs的关键因素是数学推理训练。

Conclusion: LLM在风险决策中存在明显分化，推理模型表现出更强的理性特征，而对话模型更接近人类决策模式但理性程度不足。数学推理训练是影响LLM决策理性的关键因素，这对LLM在决策支持系统中的应用具有重要意义。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [11] [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)
*Yuanyan Song,Kezhi Wang,Xinmian Xu*

Main category: cs.AI

TL;DR: 提出安全的无线智能体AI网络，通过智能体选择和友好干扰保护隐私，优化资源分配以最小化能耗，同时保证推理延迟和精度。


<details>
  <summary>Details</summary>
Motivation: 为用户的推理任务提供服务质量保障，同时确保私有知识和推理结果的机密性，并延长AI智能体的服务时间。

Method: 构建包含一个监督AI智能体和多个其他AI智能体的网络，监督智能体动态分配参与协作推理的智能体，未选中的智能体作为友好干扰器。提出ASC和LAW两种资源分配方案，分别使用ADMM、SDR、SCA和LLM优化器解决联合优化问题。

Result: 相比基准方案，提出的解决方案能减少高达59.1%的网络能耗，并在基于Qwen的实际智能体AI系统中验证了在各种公共基准测试中满意的推理精度。

Conclusion: 提出的安全无线智能体AI网络能有效保护隐私、优化能耗，并通过两种资源分配方案在实际系统中验证了性能，为AI推理任务的资源分配提供了有效解决方案。

Abstract: In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.

</details>


### [12] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 本文提出AI机器学习框架，补充确定性算法预测发票稀释，使用实时动态信用额度管理供应链金融中的非信用风险


<details>
  <summary>Details</summary>
Motivation: 发票或付款稀释（批准发票金额与实际收款之间的差距）是供应链金融中非信用风险和利润损失的重要来源。传统方法依赖买方不可撤销付款承诺（IPU），但IPU会阻碍供应链金融的采用，特别是对于次级投资级买家。

Method: 引入AI机器学习框架，补充确定性算法，使用九个关键交易字段的广泛生产数据集来预测发票稀释。采用数据驱动方法，使用实时动态信用额度，为每个买方-供应商对实时预测稀释情况。

Result: 论文评估了AI机器学习框架如何补充确定性算法来预测发票稀释，但具体结果未在摘要中说明。

Conclusion: AI机器学习框架可以补充传统确定性算法，为供应链金融中的发票稀释风险提供更有效的预测和管理方法，特别是对于传统IPU方法不适用的次级投资级买家。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [13] [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270)
*Farbod Abbasi,Zachary Patterson,Bilal Farooq*

Main category: cs.AI

TL;DR: 提出一种基于WGAN-GP的多源数据集联合学习框架，用于生成更真实、更多样化且可行的合成人口数据，显著提升ABM的输入质量。


<details>
  <summary>Details</summary>
Motivation: 现有合成人口生成方法存在两大局限：1）依赖单一数据集或采用顺序数据融合方式，无法捕捉特征间的复杂交互；2）难以处理采样零值和结构零值问题，导致生成数据多样性不足且可行性差。

Method: 提出基于Wasserstein GAN with gradient penalty的联合学习框架，通过定义生成器损失函数的正则化项（逆梯度惩罚）来同时整合多源数据集并生成合成数据。

Result: 联合方法显著优于顺序基线方法：召回率提升7%，精确率提升15%；正则化项进一步将召回率提升10%，精确率提升1%。相似性评估中，联合方法得分为88.1，优于顺序方法的84.6。

Conclusion: 提出的多源生成方法能够生成更高质量、更多样化且更可行的合成人口数据，有望显著提升基于智能体的建模（ABM）的准确性和可靠性。

Abstract: Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\% and precision by 15\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\% increase in recall and 1\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.

</details>


### [14] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究不同记忆类型在动态不确定环境中如何辅助空间导航，发现结合多种策略的架构能显著提升效率，特别是当任务难度增加时。


<details>
  <summary>Details</summary>
Motivation: 在动态变化且感知受限的环境中，智能体需要快速适应环境变化并有效导航。传统方法难以应对非平稳环境中的不确定性、感知限制和快速学习需求。

Method: 采用从简单到复杂的多种策略，包括非平稳概率学习技术更新情景记忆，利用记忆构建不完美地图（有噪声且限于经验范围），并实时规划路径。

Result: 当任务难度（如目标距离）增加时，使用记忆更新和实时地图规划的智能体效率显著高于简单（最小记忆）智能体，前提是定位和环境变化的不确定性不太大。

Conclusion: 需要能够整合多种策略的架构来处理不同性质的子任务，特别是探索搜索和路径规划。结合记忆更新和实时地图构建的方法在适度不确定性条件下能显著提升导航效率。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [15] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: EAA是一个基于视觉语言模型的代理系统，用于自动化复杂的实验显微镜工作流程，通过多模态推理和工具增强操作，支持自主程序和交互式用户引导测量。


<details>
  <summary>Details</summary>
Motivation: 传统实验显微镜工作流程复杂且需要专业知识，EAA旨在通过自动化降低操作负担和专业知识门槛，提高光束线效率。

Method: 基于灵活的任务管理器架构，集成多模态推理、工具增强操作和可选长期记忆，支持从完全代理驱动自动化到嵌入局部LLM查询的逻辑定义例程，并提供双向兼容的MCP工具生态系统。

Result: 在先进光子源的成像光束线上成功演示了自动区域板聚焦、自然语言描述特征搜索和交互式数据采集等功能。

Conclusion: 视觉能力代理系统能够显著提高光束线效率，减少操作负担，并为用户降低专业知识门槛，展示了在实验自动化中的实用价值。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [16] [X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection](https://arxiv.org/abs/2602.15298)
*Qi Zhang,Dian Chen,Lance M. Kaplan,Audun Jøsang,Dong Hyun Jeong,Feng Chen,Jin-Hee Cho*

Main category: cs.AI

TL;DR: X-MAP是一个可解释的误分类分析与分析框架，通过主题级语义模式揭示模型失败原因，结合SHAP特征归因和非负矩阵分解构建可解释主题配置文件，用于改进垃圾邮件和钓鱼检测。


<details>
  <summary>Details</summary>
Motivation: 垃圾邮件和钓鱼检测中的误分类危害很大：假阴性使用户暴露于攻击，假阳性降低信任。现有基于不确定性的检测器可以标记潜在错误，但可能被欺骗且可解释性有限。

Method: X-MAP结合SHAP特征归因和非负矩阵分解，为可靠分类的垃圾邮件/钓鱼邮件和合法邮件构建可解释的主题配置文件，使用Jensen-Shannon散度测量每条消息与这些配置文件的偏差。

Result: 实验显示误分类消息的偏差至少是正确分类消息的两倍。作为检测器，X-MAP达到0.98 AUROC，在95% TRR时将假拒绝率降至0.089。作为修复层，它能恢复高达97%的错误拒绝的正确预测。

Conclusion: X-MAP在改进垃圾邮件和钓鱼检测方面具有有效性和可解释性，能够揭示模型失败的语义模式并提供可靠的误分类分析。

Abstract: Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.

</details>


### [17] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 提出Agro-Reflective框架，通过LLM代理在农业数据环境中执行代码、观察结果、迭代优化，解决现有农业基础模型缺乏语言推理能力的问题


<details>
  <summary>Details</summary>
Motivation: 现有农业基础模型虽然能处理大规模时空数据，但缺乏语言推理和交互能力；而大语言模型擅长文本处理，却无法直接处理高维异构农业数据。需要桥接这一鸿沟

Method: 开发AgriWorld Python执行环境，提供地理空间查询、遥感时间序列分析、作物生长模拟等工具；设计Agro-Reflective多轮LLM代理，通过执行-观察-优化的循环迭代分析

Result: 在AgroBench基准测试中，涵盖查询、预测、异常检测和反事实分析等任务，性能优于纯文本和直接工具使用基线，验证了执行驱动反思的可靠性

Conclusion: 提出的代理框架成功将LLM的语言推理能力与农业数据处理能力结合，为农业科学提供了可靠的分析工具，执行驱动的反思机制是关键创新

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [18] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: WAC是一个基于多模型协作的网页智能体，通过世界模型模拟行动后果和法官模型评估风险，实现风险感知的网页任务执行。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的网页智能体存在两个主要问题：1) 难以预测环境变化，导致行动决策不合理；2) 缺乏对执行风险的全面认知，可能过早执行风险操作导致任务失败和损失。

Method: 提出WAC框架，包含三个核心组件：1) 多智能体协作流程：行动模型咨询世界模型获取战略指导，然后基于环境状态转移知识生成可执行行动；2) 两阶段推理链：世界模型模拟行动结果，法官模型评估风险并触发行动修正反馈。

Result: 在VisualWebArena上获得1.8%的绝对提升，在Online-Mind2Web上获得1.3%的绝对提升，证明了方法的有效性。

Conclusion: WAC通过模型协作、后果模拟和反馈驱动的行动优化，解决了现有网页智能体在环境变化预测和风险感知方面的局限性，实现了更稳健的网页任务执行。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [19] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 提出自适应弃权系统，通过动态调整安全阈值和层级级联机制，在保持安全性的同时减少误报和延迟，平衡LLM的安全性与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM部署面临安全性与实用性的根本权衡：严格过滤机制会阻止良性查询，而宽松控制则可能生成不安全内容。传统护栏基于静态规则或固定置信度阈值，缺乏上下文敏感性且计算成本高，导致高延迟和用户体验下降。

Method: 引入自适应弃权系统，基于实时上下文信号（如领域和用户历史）动态调整安全阈值。框架集成五路并行检测器的多维检测架构，通过层级级联机制优化速度和精度。级联设计通过渐进式过滤查询减少不必要的计算。

Result: 在混合和特定领域工作负载上的广泛评估显示，误报显著减少，特别是在医疗建议和创意写作等敏感领域。系统在严格操作模式下保持高安全精度和接近完美的召回率。与非级联模型和外部护栏系统相比，实现了显著的延迟改进。

Conclusion: 上下文感知的弃权框架有效平衡了安全性与实用性，同时保持性能，为可靠的LLM部署提供了可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [20] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 本文解决了共同信念的逻辑特征化问题，证明了在KD45个体信念下，共同信念的逻辑需要KD4加上两个额外公理，且其中一个依赖于智能体数量。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为共同信念是KD4，但研究发现当个体信念是KD45时，共同信念会失去5属性，保留D和4属性，并具有shift-reflexivity属性。这引发了一个开放性问题：KD4加上shift-reflexivity公理是否足以完全刻画共同信念？

Method: 通过逻辑分析证明KD4加上shift-reflexivity公理不足以完全刻画共同信念，需要额外公理。研究展示了共同信念的完整逻辑特征化，包括一个依赖于智能体数量的公理。

Result: 证明了KD4加上shift-reflexivity公理不足以完全刻画共同信念，需要增加一个额外公理。该额外公理依赖于智能体数量，从而得到了共同信念的完整逻辑特征化，解决了这个开放性问题。

Conclusion: 共同信念的逻辑特征化需要KD4加上两个公理：shift-reflexivity和一个依赖于智能体数量的公理。这为共同信念提供了完整的逻辑刻画，解决了长期存在的开放性问题。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [21] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: EduEVAL-DB是一个基于教师角色的数据集，用于评估和训练自动教学评估器和AI导师，包含854个解释，涵盖科学、语言和社会科学K-12年级问题，采用半自动专家标注的教学风险维度。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于评估和训练自动教学评估器和AI导师的数据集，特别是在教学解释质量评估方面。需要基于真实教育实践中的教学风格和缺陷，为AI教育系统提供可靠的评估基准。

Method: 1. 基于ScienceQA基准构建包含139个问题的数据集，涵盖科学、语言和社会科学K-12年级；2. 为每个问题提供1个人类教师解释和6个LLM模拟的教师角色解释；3. 设计包含五个维度的教学风险评估框架：事实正确性、解释深度和完整性、焦点和相关性、学生水平适当性、意识形态偏见；4. 采用半自动流程进行专家标注；5. 进行初步验证实验，比较Gemini 2.5 Pro和Llama 3.1 8B模型。

Result: 构建了包含854个解释的EduEVAL-DB数据集，所有解释都经过专家标注了教学风险标签。初步实验表明，轻量级本地模型（Llama 3.1 8B）在EduEVAL-DB上的监督微调能够支持教学风险检测，为在消费级硬件上部署教学评估模型提供了可能性。

Conclusion: EduEVAL-DB为自动教学评估器和AI导师的评估与训练提供了有价值的基准数据集，通过基于教师角色的设计和教学风险评估框架，支持开发可在消费级硬件上部署的教学风险检测模型。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [22] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 该论文提出结构化能力模型，首次从大量LLM基准测试结果中提取可解释且可泛化的能力，解决了现有潜在因子模型和缩放定律在构建效度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社区将基准测试结果等同于模型通用能力，但基准测试存在测试集污染、标注错误等问题。需要可靠的方法来评估基准测试是否能有效衡量我们想要测量的能力，即LLM基准测试的构建效度问题。

Method: 提出结构化能力模型，结合了缩放定律和潜在因子模型的优势：1）模型规模影响能力（如缩放定律）；2）能力影响观察结果并考虑测量误差（如潜在因子模型）。在OpenLLM排行榜的大规模结果样本上拟合该模型及其两种替代方案。

Result: 结构化能力模型在简约拟合指标上优于潜在因子模型，在分布外基准测试预测上优于缩放定律。该模型能更好地分离模型规模与能力，提供更好的解释和预测能力。

Conclusion: 结构化能力模型通过适当结合缩放定律和潜在因子模型的见解，为量化LLM评估中的构建效度提供了更好的解释和预测能力，是首个能从大量基准测试结果中提取可解释且可泛化能力的模型。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.
  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.
  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [23] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出首个"玻璃盒"架构，用于人类参与的记忆管理，将个人AI从向量匹配转向知识图谱推理，实现真正的隐私保护和"被遗忘权"。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI主要采用"黑盒"检索增强生成，标准向量数据库缺乏可解释性：AI产生幻觉或检索敏感数据时，用户无法检查原因或纠正错误。此外，从向量空间中"删除"概念在数学上不精确，会留下概率性"幽灵"，违反真正的隐私保护。

Method: Ruva将个人AI建立在个人知识图谱基础上，而非向量匹配。采用"玻璃盒"架构支持人类参与的记忆管理，用户可检查AI知道的内容，并对特定事实进行精确删除。通过从向量匹配转向图谱推理，确保"被遗忘权"。

Result: Ruva实现了可解释的个人AI系统，用户能够检查AI的知识并精确删除特定信息，解决了传统向量数据库的隐私和可解释性问题。项目代码和演示视频已公开。

Conclusion: Ruva通过知识图谱架构将个人AI从黑盒转变为玻璃盒，赋予用户对自己数字记忆的编辑权，真正实现了隐私保护和被遗忘权，让用户成为自己生活的编辑者。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [24] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 论文提出PID Flow框架，分析多模态Transformer中视觉和语言信息的流动模式，发现视觉信息在早期层达到峰值后衰减，语言信息在后期层主导预测（约82%），跨模态协同作用始终低于2%。


<details>
  <summary>Details</summary>
Motivation: 研究多模态Transformer在回答视觉问题时，预测是受视觉证据、语言推理还是真正的跨模态计算驱动，以及这种结构如何在不同层间演化。

Method: 提出基于部分信息分解（PID）的层间分析框架PID Flow，结合降维、归一化流高斯化和闭式高斯PID估计，应用于LLaVA-1.5-7B和LLaVA-1.6-7B模型在六个GQA推理任务上。

Result: 发现一致的模态转换模式：视觉独特信息早期达到峰值后衰减，语言独特信息在后期层激增（占最终预测约82%），跨模态协同作用始终低于2%。通过注意力敲除实验建立了因果关系。

Conclusion: 研究提供了多模态Transformer中视觉如何转换为语言的信息论因果解释，并为识别模态特定信息丢失的架构瓶颈提供了量化指导。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [25] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 提出一种预处理方法，通过发现任务覆盖集、提升覆盖不等式并注入约束，来推断额外的累积约束，以捕获多资源交互，提升调度性能


<details>
  <summary>Details</summary>
Motivation: 传统约束规划中累积约束的传播通常单独处理每个约束，忽略了多资源之间的交互作用，导致在某些基准测试中性能严重下降

Method: 将累积约束解释为占用向量上的线性不等式，通过：(1)发现覆盖集（不能并行运行的任务集合），(2)通过提升技术加强覆盖不等式，(3)将生成的约束注入调度问题实例中

Result: 在标准RCPSP和RCPSP/max测试套件上，推断的约束改善了搜索性能，在有利实例上收紧目标界限，在不利实例上几乎没有性能下降。发现了25个新的下界和5个新的最优解，其中8个下界直接来自推断的约束

Conclusion: 通过预处理推断额外的累积约束能有效捕获多资源交互，提升调度问题的求解性能，同时发现新的下界和最优解，证明了方法的有效性

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [26] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: CARE Drive框架用于评估自动驾驶中视觉语言模型是否基于人类相关原因做出决策，而非事后合理化，通过上下文扰动测量决策对人类原因（如安全、社会压力）的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶模型评估方法主要关注结果性能（如安全性、轨迹精度），但无法判断模型决策是否真正基于人类相关原因，这可能导致在安全关键领域产生虚假信心。

Method: 提出CARE Drive框架：1）提示校准确保稳定输出；2）系统上下文扰动测量决策对人类原因（安全边际、社会压力、效率约束）的敏感性，通过比较基准模型和原因增强模型在受控上下文变化下的决策。

Result: 明确的人类原因显著影响模型决策，改善与专家推荐行为的一致性；但对不同类型原因的响应性存在差异，表明模型对不同类型原因的敏感性不均匀。

Conclusion: CARE Drive提供了无需修改模型参数即可系统评估基础模型原因响应性的实证证据，有助于确保自动驾驶决策基于真实的人类相关考虑而非事后合理化。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [27] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA是一个无需训练的人格控制框架，通过在激活空间中直接操作人格向量，实现了接近微调水平的性能，支持动态和组合式人格控制。


<details>
  <summary>Details</summary>
Motivation: 当前LLM人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态和组合特性。需要一种更灵活、高效的人格控制方法。

Method: 三阶段框架：1) Persona-Base通过对比激活分析提取正交特质向量；2) Persona-Algebra通过向量算术（标量乘法控制强度、加法组合、减法抑制）实现精确控制；3) Persona-Flow在推理时动态组合向量实现上下文感知适应。

Result: 在PersonalityBench上平均得分9.60，接近监督微调上限9.61；在Persona-Evolve动态人格适应基准上，在不同模型家族中获得高达91%的胜率。

Conclusion: LLM人格特质在数学上是可处理的，表现为可提取、近似正交的表示空间方向，支持代数运算，为可解释和高效的行为控制开辟了新方向。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [28] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: RCE框架让预训练语言模型能在推理时动态修改内部表示几何，通过生成低秩概念子空间来构建新抽象，显著提升组合推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扩展token级搜索来改进推理，但保持模型的潜在表示空间固定。当所需抽象未编码在该空间中时，性能会崩溃。需要让模型能在推理时修改内部表示几何。

Method: 提出递归概念演化(RCE)框架：检测到表示不足时生成动态低秩概念子空间；通过最小描述长度准则选择；协同时合并；通过约束优化进行整合以保持稳定性。

Result: 在Mistral-7B上集成RCE，在组合推理基准上取得显著提升：ARC-AGI-2提升12-18点，GPQA和BBH提升8-14点，在MATH和HLE上持续减少深度诱导错误。

Conclusion: RCE使预训练语言模型能在推理时构建新抽象而非仅重组现有概念，显著提升组合推理能力，为解决复杂推理任务提供了新方向。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [29] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: 提出GlobeDiff算法，通过多模态扩散过程从局部观测推断全局状态，解决多智能体系统中的部分可观测性问题


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的部分可观测性是有效协调和决策的关键障碍。现有方法如信念状态估计和智能体间通信存在局限：信念方法主要依赖过去经验而未充分利用全局信息，通信方法缺乏有效利用辅助信息的鲁棒模型。

Method: 提出Global State Diffusion Algorithm (GlobeDiff)，将状态推断过程建模为多模态扩散过程，基于局部观测推断全局状态。该方法克服了状态估计中的模糊性，同时以高保真度推断全局状态。

Result: 理论证明GlobeDiff在单模态和多模态分布下的估计误差有界。大量实验结果表明，GlobeDiff实现了优越性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过多模态扩散过程有效解决了多智能体系统中的部分可观测性问题，相比现有方法在全局状态推断方面表现出色。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [30] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 论文探讨了在社会科学实验中使用LLM作为合成参与者的有效性，对比了启发式方法和统计校准两种策略，并讨论了它们在不同研究阶段（探索性vs验证性）的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着使用LLM作为合成参与者的研究增多，但缺乏关于何时这种模拟能有效推断人类行为的指导。需要明确不同方法在什么条件下适用于探索性或验证性研究。

Method: 对比两种策略：1）启发式方法：通过提示工程、模型微调等技术减少LLM的不准确性，使模拟与观察的人类行为可互换；2）统计校准：结合辅助人类数据和统计调整，在明确假设下处理观察与模拟响应之间的差异。

Result: 启发式方法适用于探索性任务，但缺乏验证性研究所需的正式统计保证；统计校准在明确假设下能保持有效性，并以更低成本提供更精确的因果效应估计。两种方法的潜力都取决于LLM对相关人群的近似程度。

Conclusion: 研究者不应仅仅关注用LLM替代人类参与者，而应考虑两种方法的适用场景。统计校准在验证性研究中更具优势，但所有方法都依赖于LLM对目标人群的近似质量。需要更全面地思考LLM在社会科学研究中的机会。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [31] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本文提出使用LLM嵌入作为编码方法，以保留建筑语义中更精细的区分，相比传统one-hot编码在建筑对象子类型分类任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 在AECO行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对AI模型训练至关重要。传统编码方法（如one-hot）无法传达密切相关的子类型之间的细微关系，限制了AI的语义理解能力。

Method: 提出使用大型语言模型（LLM）嵌入（如OpenAI GPT和Meta LLaMA）作为编码方法，保留建筑语义的精细区分。评估方法包括训练GraphSAGE模型对5个高层住宅BIM中的42个建筑对象子类型进行分类，测试不同嵌入维度（原始高维LLM嵌入和通过Matryoshka表示模型生成的1024维压缩嵌入）。

Result: LLM编码优于传统one-hot基线，其中llama-3（压缩）嵌入的加权平均F1分数达到0.8766，而one-hot编码为0.8475。结果表明LLM编码在建筑语义理解方面具有优势。

Conclusion: LLM编码方法在增强AI解释复杂领域特定建筑语义方面具有潜力，随着LLM和降维技术的发展，该方法在AECO行业的语义细化任务中有广泛应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [32] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍基于仿真的合成数据生成方法，用于解决AI训练中数据不足的问题，并提出了数字孪生AI仿真解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 现代符号AI的采用面临数据量不足和数据质量不佳的关键障碍，因此对合成数据生成技术的需求很高。仿真提供了一种系统化的方法来生成多样化的合成数据。

Method: 提出了基于仿真的合成数据生成方法，并介绍了数字孪生AI仿真解决方案的参考框架，用于描述、设计和分析此类解决方案。

Result: 本章系统介绍了仿真合成数据生成的关键概念、优势和挑战，为AI训练提供了系统化的数据生成方法。

Conclusion: 基于仿真的合成数据生成是解决AI训练数据不足问题的有效途径，数字孪生框架为设计和分析此类解决方案提供了系统化的参考。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [33] [VQ-DSC-R: Robust Vector Quantized-Enabled Digital Semantic Communication With OFDM Transmission](https://arxiv.org/abs/2602.15045)
*Jianqiao Chen,Nan Ma,Xiaodong Xu,Tingting Zhu,Huishi Song,Chen Dong,Wenkai Liu,Rui Meng,Ping Zhang*

Main category: cs.IT

TL;DR: 提出基于向量量化的数字语义通信系统VQ-DSC-R，采用Swin Transformer提取语义特征，ANDVQ方案减少量化误差，条件扩散模型增强信道鲁棒性，实现高效压缩和抗干扰传输。


<details>
  <summary>Details</summary>
Motivation: 当前语义通信研究主要集中于模拟通信和简化信道模型，缺乏与数字基础设施的互操作性。需要开发能够在实际数字传输环境中工作的鲁棒数字语义通信系统。

Method: 1. 基于Swin Transformer的骨干网络进行分层语义特征提取，结合VQ模块将特征映射到共享语义量化码本(SQC)进行索引传输；2. 提出自适应噪声方差可微向量量化(ANDVQ)方案，利用K近邻统计动态调整量化过程，指数移动平均机制稳定SQC训练；3. 使用条件扩散模型(CDM)精化信道状态信息，设计基于注意力的模块动态适应信道噪声；4. 采用三阶段训练策略优化整个系统。

Result: 大量实验表明VQ-DSC-R优于基准方案，实现高压缩比，在实际场景中表现出鲁棒性能。

Conclusion: VQ-DSC-R系统成功将语义通信与数字基础设施相结合，通过创新的量化方案和信道适应机制，实现了高效、鲁棒的数字语义通信，为语义通信的实际应用提供了可行方案。

Abstract: Digital mapping of semantic features is essential for achieving interoperability between semantic communication and practical digital infrastructure. However, current research efforts predominantly concentrate on analog semantic communication with simplified channel models. To bridge these gaps, we develop a robust vector quantized-enabled digital semantic communication (VQ-DSC-R) system built upon orthogonal frequency division multiplexing (OFDM) transmission. Our work encompasses the framework design of VQ-DSC-R, followed by a comprehensive optimization study. Firstly, we design a Swin Transformer-based backbone for hierarchical semantic feature extraction, integrated with VQ modules that map the features into a shared semantic quantized codebook (SQC) for efficient index transmission. Secondly, we propose a differentiable vector quantization with adaptive noise-variance (ANDVQ) scheme to mitigate quantization errors in SQC, which dynamically adjusts the quantization process using K-nearest neighbor statistics, while exponential moving average mechanism stabilizes SQC training. Thirdly, for robust index transmission over multipath fading channel and noise, we develop a conditional diffusion model (CDM) to refine channel state information, and design an attention-based module to dynamically adapt to channel noise. The entire VQ-DSC-R system is optimized via a three-stage training strategy. Extensive experiments demonstrate superiority of VQ-DSC-R over benchmark schemes, achieving high compression ratios and robust performance in practical scenarios.

</details>


### [34] [GRAM-DIFF: Gram Matrix Guided Diffusion for MIMO Channel Estimation](https://arxiv.org/abs/2602.15187)
*Xinyuan Wang,Krishna Narayanan*

Main category: cs.IT

TL;DR: GRAM-DIFF：一种基于Gram矩阵引导的扩散框架，用于半盲MIMO信道估计，通过结合Gram矩阵指导和似然指导，在3GPP和QuaDRiGa信道模型上相比基线方法获得4-6 dB的SNR增益。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的信道估计方法虽然利用学习到的生成先验来改进基于导频的信道估计，但未能利用从数据符号中估计得到的二阶结构信息。在实际系统中，可以从接收符号中估计信道Gram矩阵，它提供了信道子空间结构的实现级信息。

Method: 提出GRAM-DIFF框架，将预训练的角域扩散先验与两种互补的指导机制相结合：1）新颖的Gram矩阵指导项，在反向扩散过程中强制执行二阶一致性；2）来自导频观测的似然指导。采用SNR匹配初始化和自适应指导缩放确保稳定性和低推理延迟。

Result: 在3GPP和QuaDRiGa信道模型上的仿真表明，相比确定性扩散基线方法，GRAM-DIFF在归一化均方误差（NMSE）方面获得一致改进，在NMSE为0.1时相比Fest等人（2024）的基线方法获得4-6 dB的SNR增益。该框架在相干时间约束下表现出优雅退化，当基于数据的Gram估计变得不可靠时，平滑地恢复到似然指导扩散。

Conclusion: GRAM-DIFF通过有效整合信道Gram矩阵的结构信息和导频观测，为半盲MIMO信道估计提供了一个强大且稳定的框架，显著提升了估计性能，并在实际系统约束下表现出良好的鲁棒性。

Abstract: We propose GRAM-DIFF, a Gram-matrix-guided diffusion framework for semi-blind multiple input multiple output (MIMO) channel estimation. Recent diffusion-based estimators leverage learned generative priors to improve pilot-based channel estimation; but they do not exploit second-order structural information estimated from data symbols. In practical systems, the channel Gram matrix can be estimated from received symbols and it provides realization-level information about channel subspace structure. The proposed method integrates a pre-trained angular-domain diffusion prior with two complementary guidance mechanisms: a novel Gram-matrix guidance term that enforces second-order consistency during the reverse diffusion process, and likelihood guidance from pilot observations. Signal-to-noise ratio (SNR)-matched initialization and adaptive guidance scaling ensure stability and low inference latency. Simulations on 3GPP and QuaDRiGa channel models demonstrate consistent normalized mean-squared error (NMSE) improvements over deterministic diffusion baselines, achieving 4 to 6 dB SNR gains at an NMSE of 0.1 over the baseline in Fest et al. (2024). The framework exhibits graceful degradation under coherence-time constraints, smoothly reverting to likelihood-guided diffusion when data-based Gram estimates become unreliable.

</details>


### [35] [On the Entropy of General Mixture Distributions](https://arxiv.org/abs/2602.15303)
*Namyoon Lee*

Main category: cs.IT

TL;DR: 提出了一种确定性、闭式工具包，用于边界和准确近似混合分布的微分熵，通过信息论信道视角将混合熵分解为组内不确定性的平均值加上重叠项，并使用成对重叠积分来边界和近似重叠项。


<details>
  <summary>Details</summary>
Motivation: 混合分布是多模态数据建模的重要工具，但即使每个分量密度都很简单，混合熵的计算仍然非常困难，因为混合将对数与求和耦合在一起。现有方法难以直接根据分量参数计算混合熵。

Method: 采用信息论信道视角：将潜在混合标签视为输入，观测值视为输出。将混合熵分解为组内不确定性的平均值加上重叠项。使用分量密度之间的成对重叠积分来边界和近似重叠项，通过简单的族相关偏移校正Jensen重叠边界的系统偏差，并在完全重叠和近乎完美分离两个极限情况下进行校准。最后通过裁剪步骤确保估计始终遵循通用信息论边界。

Result: 为高斯、因子化拉普拉斯、均匀和混合混合提供了闭式特化公式。数值实验验证了所得边界和近似在分离度、维度、分量数量和协方差相关性方面的有效性。

Conclusion: 开发了一种确定性、闭式工具包，能够直接根据分量参数边界和准确近似混合熵，通过信息论信道视角和重叠积分方法有效解决了混合熵计算的难题。

Abstract: Mixture distributions are a workhorse model for multimodal data in information theory, signal processing, and machine learning. Yet even when each component density is simple, the differential entropy of the mixture is notoriously hard to compute because the mixture couples a logarithm with a sum. This paper develops a deterministic, closed-form toolkit for bounding and accurately approximating mixture entropy directly from component parameters. Our starting point is an information-theoretic channel viewpoint: the latent mixture label plays the role of an input, and the observation is the output. This viewpoint separates mixture entropy into an average within-component uncertainty plus an overlap term that quantifies how much the observation reveals about the hidden label. We then bound and approximate this overlap term using pairwise overlap integrals between component densities, yielding explicit expressions whenever these overlaps admit a closed form. A simple, family-dependent offset corrects the systematic bias of the Jensen overlap bound and is calibrated to be exact in the two limiting regimes of complete overlap and near-perfect separation. A final clipping step guarantees that the estimate always respects universal information-theoretic bounds. Closed-form specializations are provided for Gaussian, factorized Laplacian, uniform, and hybrid mixtures, and numerical experiments validate the resulting bounds and approximations across separation, dimension, number of components, and correlated covariances.

</details>


### [36] [Corrected-Inverse-Gaussian First-Hitting-Time Modeling for Molecular Communication Under Time-Varying Drift](https://arxiv.org/abs/2602.15335)
*Yen-Chi Lee*

Main category: cs.IT

TL;DR: 本文为时变漂移下的首次命中时间分子通信系统开发了一个可处理的解析信道模型，通过测度变换揭示了首次命中时间密度的结构分解，提出了修正逆高斯分布模型。


<details>
  <summary>Details</summary>
Motivation: 现有非平稳传输研究主要依赖数值求解对流-扩散方程或参数化脉冲响应拟合，缺乏对吸收边界轨迹级到达动力学的闭式描述，需要开发适用于动态生物和分子通信环境的物理信息、计算高效的信道模型。

Method: 采用测度变换方法，将首次命中时间密度结构分解为累积漂移位移项和随机边界通量调制因子，推导出修正逆高斯密度（C-IG）的显式解析表达式，将经典IG模型扩展到强非平稳漂移条件。

Result: 在平滑脉冲和突变切换漂移剖面下的高精度蒙特卡洛模拟证实，该模型能准确捕捉复杂传输现象，包括相位调制、多脉冲色散和瞬态回流，同时保持恒定复杂度评估。

Conclusion: 该框架为动态生物和分子通信环境提供了物理信息、计算高效的信道模型，适用于系统级分析和接收机设计，扩展了经典逆高斯模型的应用范围。

Abstract: This paper develops a tractable analytical channel model for first-hitting-time molecular communication systems under time-varying drift. While existing studies of nonstationary transport rely primarily on numerical solutions of advection--diffusion equations or parametric impulse-response fitting, they do not provide a closed-form description of trajectory-level arrival dynamics at absorbing boundaries. By adopting a change-of-measure formulation, we reveal a structural decomposition of the first-hitting-time density into a cumulative-drift displacement term and a stochastic boundary-flux modulation factor. This leads to an explicit analytical expression for the Corrected-Inverse-Gaussian (C-IG) density, extending the classical IG model to strongly nonstationary drift conditions while preserving constant-complexity evaluation. High-precision Monte Carlo simulations under both smooth pulsatile and abrupt switching drift profiles confirm that the proposed model accurately captures complex transport phenomena, including phase modulation, multi-pulse dispersion, and transient backflow. The resulting framework provides a physics-informed, computationally efficient channel model suitable for system-level analysis and receiver design in dynamic biological and molecular communication environments.

</details>


### [37] [A Universal Neural Receiver that Learns at the Speed of Wireless](https://arxiv.org/abs/2602.15458)
*Lingjia Liu,Lizhong Zheng,Yang Yi,Robert Calderbank*

Main category: cs.IT

TL;DR: 论文提出了一种基于卷积的通用神经接收器架构，旨在替代传统基于数学模型的无线网络设计方法，通过配置权重而非大量离线训练来适应快速变化的无线环境。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络复杂度增加，传统的基于数学模型的无线网络设计方法逐渐失效。移动网络运营商希望利用AI提高频谱效率、减少信令开销，但现有的离线AI算法无法适应无线环境中亚毫秒级的快速变化。

Method: 提出一种基于卷积的通用神经接收器架构，该架构将卷积反演问题分离为"反演哪个卷积"和"实际反卷积"两个部分。神经网络执行反卷积操作，通过基于领域知识配置权重来避免大量离线训练。

Result: 开发了一个简单的神经网络架构，能够处理无线频谱中任何信号的发射和接收信号处理，实现通用接收器功能，减少对离线训练的依赖。

Conclusion: 通用神经接收器架构可以简化国际标准中关于不同用例波形选择的讨论，由于接收器架构基本独立于基站引入的技术，有望提高无线领域的创新速度。

Abstract: Today we design wireless networks using mathematical models that govern communication in different propagation environments. We rely on measurement campaigns to deliver parametrized propagation models, and on the 3GPP standards process to optimize model-based performance, but as wireless networks become more complex this model-based approach is losing ground. Mobile Network Operators (MNOs) are counting on Artificial Intelligence (AI) to transform wireless by increasing spectral efficiency, reducing signaling overhead, and enabling continuous network innovation through software upgrades. They may also be interested in new use cases like integrated sensing and communications (ISAC). All we need is an AI-native physical layer, so why not simply tailor the offline AI algorithms that have revolutionized image and natural language processing to the wireless domain? We argue that these algorithms rely on off-line training that is precluded by the sub-millisecond speeds at which the wireless interference environment changes. We present an alternative architecture, a universal neural receiver based on convolution, which governs transmit and receive signal processing of any signal in any part of the wireless spectrum. Our neural receiver is designed to invert convolution, and we separate the question of which convolution to invert from the actual deconvolution. The neural network that performs deconvolution is very simple, and we configure this network by setting weights based on domain knowledge. By telling our neural network what we know, we avoid extensive offline training. By developing a universal receiver, we hope to simplify discussions about the proper choice of waveform for different use cases in the international standards. Since the receiver architecture is largely independent of technologies introduced at the base station, we hope to increase the rate of innovation in wireless.

</details>
