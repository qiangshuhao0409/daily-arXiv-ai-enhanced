<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 5]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Baton: Compensate for Missing Wi-Fi Features for Practical Device-free Tracking](https://arxiv.org/abs/2507.05597)
*Yiming Zhao,Xuanqi Meng,Xinyu Tong,Xiulong Liu,Xin Xie,Wenyu Qu*

Main category: cs.NI

TL;DR: Baton系统通过水平和垂直维度分析Wi-Fi特征矩阵相关性，提出STAP算法，显著提升Wi-Fi感知系统在特征缺失情况下的目标追踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有Wi-Fi感知系统需要持续通信且对通信中断敏感，性能易受严重影响。

Method: 探索Wi-Fi特征矩阵在水平和垂直维度的相关性，提出STAP算法实现特征无缝传递。

Result: 实验显示Baton系统在通信占空比低至20%时，追踪误差中位数仅为0.46m，较现有技术降低79.19%。

Conclusion: Baton系统显著提升了Wi-Fi感知在特征缺失情况下的鲁棒性和准确性。

Abstract: Wi-Fi contact-free sensing systems have attracted widespread attention due to
their ubiquity and convenience. The integrated sensing and communication (ISAC)
technology utilizes off-the-shelf Wi-Fi communication signals for sensing,
which further promotes the deployment of intelligent sensing applications.
However, current Wi-Fi sensing systems often require prolonged and unnecessary
communication between transceivers, and brief communication interruptions will
lead to significant performance degradation. This paper proposes Baton, the
first system capable of accurately tracking targets even under severe Wi-Fi
feature deficiencies. To be specific, we explore the relevance of the Wi-Fi
feature matrix from both horizontal and vertical dimensions. The horizontal
dimension reveals feature correlation across different Wi-Fi links, while the
vertical dimension reveals feature correlation among different time slots.
Based on the above principle, we propose the Simultaneous Tracking And
Predicting (STAP) algorithm, which enables the seamless transfer of Wi-Fi
features over time and across different links, akin to passing a baton. We
implement the system on commercial devices, and the experimental results show
that our system outperforms existing solutions with a median tracking error of
0.46m, even when the communication duty cycle is as low as 20.00%. Compared
with the state-of-the-art, our system reduces the tracking error by 79.19% in
scenarios with severe Wi-Fi feature deficiencies.

</details>


### [2] [A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation](https://arxiv.org/abs/2507.05731)
*Yuxin Zhang,Jiahao Yang,Zhe Chen,Wenjun Zhu,Jin Zhao,Yue Gao*

Main category: cs.NI

TL;DR: 论文提出了一种名为SpaceVerse的高效卫星-地面协同LVLM推理系统，用于解决低地球轨道卫星图像下载和实时分析的挑战。


<details>
  <summary>Details</summary>
Motivation: 快速卫星运动、短暂的卫星-地面站接触窗口以及大尺寸图像导致数据下载困难，限制了实时地球观测应用（如灾害和极端天气监测）的发展。

Method: 在卫星上部署紧凑型LVLM处理轻量任务，地面站运行常规LVLM处理计算密集型任务；提出计算与通信协同设计框架，包括渐进置信网络和基于注意力的多尺度预处理。

Result: 在真实LEO卫星星座和数据集上实现31.2%的平均准确率提升和51.2%的延迟降低。

Conclusion: SpaceVerse系统显著提升了卫星-地面协同LVLM推理的效率和准确性，为实时地球观测应用提供了可行解决方案。

Abstract: Recently, large vision-language models (LVLMs) unleash powerful analysis
capabilities for low Earth orbit (LEO) satellite Earth observation images in
the data center. However, fast satellite motion, brief satellite-ground station
(GS) contact windows, and large size of the images pose a data download
challenge. To enable near real-time Earth observation applications (e.g.,
disaster and extreme weather monitoring), we should explore how to deploy LVLM
in LEO satellite networks, and design SpaceVerse, an efficient satellite-ground
synergistic LVLM inference system. To this end, firstly, we deploy compact
LVLMs on satellites for lightweight tasks, whereas regular LVLMs operate on GSs
to handle computationally intensive tasks. Then, we propose a computing and
communication co-design framework comprised of a progressive confidence network
and an attention-based multi-scale preprocessing, used to identify on-satellite
inferring data, and reduce data redundancy before satellite-GS transmission,
separately. We implement and evaluate SpaceVerse on real-world LEO satellite
constellations and datasets, achieving a 31.2% average gain in accuracy and a
51.2% reduction in latency compared to state-of-the-art baselines.

</details>


### [3] [Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing](https://arxiv.org/abs/2507.05829)
*Zekai Sun,Xiuxian Guan,Zheng Lin,Zihan Fang,Xiangming Cai,Zhe Chen,Fangming Liu,Heming Cui,Jie Xiong,Wei Ni,Chau Yuen*

Main category: cs.NI

TL;DR: Intra-DP是一种针对移动边缘计算（MEC）优化的高性能协作推理系统，通过并行计算技术减少传输瓶颈，显著降低延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的移动设备上部署深度神经网络（DNN）面临实时性能和资源限制的挑战，现有方法因顺序执行DNN操作导致传输瓶颈。

Method: Intra-DP采用基于局部算子的并行计算技术，将计算分解为独立子操作，并通过并行执行重叠计算与传输。

Result: 评估显示，Intra-DP将每次推理延迟降低50%，能耗减少75%，同时保持准确性。

Conclusion: Intra-DP有效解决了MEC中的传输瓶颈问题，实现了高效且节能的DNN推理。

Abstract: Deploying deep neural networks (DNNs) on resource-constrained mobile devices
presents significant challenges, particularly in achieving real-time
performance while simultaneously coping with limited computational resources
and battery life. While Mobile Edge Computing (MEC) offers collaborative
inference with GPU servers as a promising solution, existing approaches
primarily rely on layer-wise model partitioning and undergo significant
transmission bottlenecks caused by the sequential execution of DNN operations.
To address this challenge, we present Intra-DP, a high-performance
collaborative inference system optimized for DNN inference on MEC. Intra DP
employs a novel parallel computing technique based on local operators (i.e.,
operators whose minimum unit input is not the entire input tensor, such as the
convolution kernel). By decomposing their computations (operations) into
several independent sub-operations and overlapping the computation and
transmission of different sub-operations through parallel execution, Intra-DP
mitigates transmission bottlenecks in MEC, achieving fast and energy-efficient
inference. The evaluation demonstrates that Intra-DP reduces per-inference
latency by up to 50% and energy consumption by up to 75% compared to
state-of-the-art baselines, without sacrificing accuracy.

</details>


### [4] [OLAF: Programmable Data Plane Acceleration for Asynchronous Distributed Reinforcement Learning](https://arxiv.org/abs/2507.05876)
*Nehal Baganal Krishna,Anam Tahir,Firas Khamis,Mina Tahmasbi Arashloo,Michael Zink,Amr Rizk*

Main category: cs.NI

TL;DR: 提出了一种网络数据平面加速架构，通过内联处理DRL模型更新减少陈旧性，提升异步DRL的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 异步分布式强化学习（DRL）在大规模训练中因网络拥塞和数据包丢失导致模型更新陈旧，影响收敛速度。

Method: 设计了一种新颖的队列机制，结合兼容的更新以减少冗余流量；同时提供轻量级传输控制机制，并通过Age-of-Model（AoM）指标评估模型效用。

Result: 该架构显著减少了更新陈旧性和拥塞，提升了异步DRL工作负载的收敛速度。

Conclusion: 网络数据平面加速架构有效解决了异步DRL中的更新陈旧问题，提升了训练效率。

Abstract: Asynchronous Distributed Reinforcement Learning (DRL) can suffer from
degraded convergence when model updates become stale, often the result of
network congestion and packet loss during large-scale training. This work
introduces a network data-plane acceleration architecture that mitigates such
staleness by enabling inline processing of DRL model updates as they traverse
the accelerator engine. To this end, we design and prototype a novel queueing
mechanism that opportunistically combines compatible updates sharing a network
element, reducing redundant traffic and preserving update utility.
Complementing this we provide a lightweight transmission control mechanism at
the worker nodes that is guided by feedback from the in-network accelerator. To
assess model utility at line rate, we introduce the Age-of-Model (AoM) metric
as a proxy for staleness and verify global fairness and responsiveness
properties using a formal verification method. Our evaluations demonstrate that
this architecture significantly reduces update staleness and congestion,
ultimately improving the convergence rate in asynchronous DRL workloads.

</details>


### [5] [Programmable Governance for Group-Controlled Decentralized Identifiers](https://arxiv.org/abs/2507.06001)
*Carlo Segat,Sandro Rodriguez Garzo,Axel Küpper*

Main category: cs.NI

TL;DR: 论文探讨了在去中心化身份（DID）的群体控制场景下，如何通过链上机制实现无需信任的DID文档（DDO）更新授权。


<details>
  <summary>Details</summary>
Motivation: 在群体控制DID时，现有规范未明确如何授权DDO更新，亟需一种灵活且与账本无关的技术方案。

Method: 提出一种链上机制，允许群体控制器编程其治理规则，实现DDO的更新授权。

Result: 研究表明，可以开发一种技术机制，以账本无关和可适配的方式协调群体控制的DDO更新。

Conclusion: 该机制为群体控制DID提供了一种可行的解决方案，填补了现有规范的空白。

Abstract: Self-Sovereign Identity (SSI) is a paradigm for digital identity management
that offers unique privacy advantages. A key technology in SSI is Decentralized
Identifiers (DIDs) and their associated metadata, DID Documents (DDOs). DDOs
contain crucial verification material such as the public keys of the entity
identified by the DID (i.e., the DID subject) and are often anchored on a
distributed ledger to ensure security and availability. Long-lived DIDs need to
support updates (e.g., key rotation). Ideally, only the DID subject should
authorize DDO updates. However, in practice, update capabilities may be shared
or delegated. While the DID specification acknowledges such scenarios, it does
not define how updates should be authorized when multiple entities jointly
control a DID (i.e., group control). This article examines the implementation
of an on-chain, trustless mechanism enabling DID controllers under group
control to program their governance rules. The main research question is the
following: Can a technical mechanism be developed to orchestrate on-chain group
control of a DDO in a ledger-agnostic and adaptable manner?

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Strongly Solving $7 \times 6$ Connect-Four on Consumer Grade Hardware](https://arxiv.org/abs/2507.05267)
*Markus Böck*

Main category: cs.AI

TL;DR: 本文通过符号搜索方法（基于二元决策图）为Connect-Four游戏生成强解，实现了89.6 GB的查找表，并在开源工具中加入了alpha-beta搜索以优化胜负路径。


<details>
  <summary>Details</summary>
Motivation: 尽管Connect-Four游戏已有数学解法，但强解的查找表被认为不可行。本文旨在探索符号搜索方法的高效实现。

Method: 采用基于二元决策图的符号搜索方法，高效生成查找表，并结合alpha-beta搜索优化胜负路径。

Result: 在单核CPU和128 GB内存下，47小时内生成了89.6 GB的查找表，并提供了开源工具。

Conclusion: 证明了符号搜索方法在生成强解查找表上的可行性，为类似问题提供了新思路。

Abstract: While the game Connect-Four has been solved mathematically and the best move
can be effectively computed with search based methods, a strong solution in the
form of a look-up table was believed to be infeasible. In this paper, we
revisit a symbolic search method based on binary decision diagrams to produce
strong solutions. With our efficient implementation we were able to produce a
89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main
memory for the standard $7 \times 6$ board size. In addition to this
win-draw-loss evaluation, we include an alpha-beta search in our open source
artifact to find the move which achieves the fastest win or slowest loss.

</details>


### [7] [Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management](https://arxiv.org/abs/2507.05283)
*Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma*

Main category: cs.AI

TL;DR: Chat2SPaT利用大型语言模型（LLM）将用户对交通信号控制计划的半结构化描述转换为精确的信号相位与时间（SPaT）结果，准确率超过94%。


<details>
  <summary>Details</summary>
Motivation: 传统定时交通信号控制需要繁琐的手动操作，且一个交叉口常关联多个计划，导致重复输入。Chat2SPaT旨在简化这一过程。

Method: 通过LLM理解用户描述并生成JSON格式的相位序列和属性，再通过Python脚本组装完整信号控制计划。

Result: 实验表明，Chat2SPaT在300多个测试案例中准确率超过94%。

Conclusion: Chat2SPaT为交通从业者提供了易用的计划管理工具，并为LLM在智能交通系统中的应用提供了新范例。

Abstract: Pre-timed traffic signal control, commonly used for operating signalized
intersections and coordinated arterials, requires tedious manual work for
signaling plan creating and updating. When the time-of-day or day-of-week plans
are utilized, one intersection is often associated with multiple plans, leading
to further repetitive manual plan parameter inputting. To enable a
user-friendly traffic signal control plan management process, this study
proposes Chat2SPaT, a method to convert users' semi-structured and ambiguous
descriptions on the signal control plan to exact signal phase and timing (SPaT)
results, which could further be transformed into structured stage-based or
ring-based plans to interact with intelligent transportation system (ITS)
software and traffic signal controllers. With curated prompts, Chat2SPaT first
leverages large language models' (LLMs) capability of understanding users' plan
descriptions and reformulate the plan as a combination of phase sequence and
phase attribute results in the json format. Based on LLM outputs, python
scripts are designed to locate phases in a cycle, address nuances of traffic
signal control, and finally assemble the complete traffic signal control plan.
Within a chat, the pipeline can be utilized iteratively to conduct further plan
editing. Experiments show that Chat2SPaT can generate plans with an accuracy of
over 94% for both English and Chinese cases, using a test dataset with over 300
plan descriptions. As the first benchmark for evaluating LLMs' capability of
understanding traffic signal control plan descriptions, Chat2SPaT provides an
easy-to-use plan management pipeline for traffic practitioners and researchers,
serving as a potential new building block for a more accurate and versatile
application of LLMs in the field of ITS. The source codes, prompts and test
dataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.

</details>


### [8] [Fuzzy Classification Aggregation for a Continuum of Agents](https://arxiv.org/abs/2507.05297)
*Zijun Meng*

Main category: cs.AI

TL;DR: 证明了对于连续个体分类的最优、独立且零一致的模糊分类聚合函数必须是加权算术平均。


<details>
  <summary>Details</summary>
Motivation: 研究模糊分类聚合函数的性质，特别是在多对象多类型分类中的最优性和一致性。

Method: 通过数学证明，分析满足特定条件（最优、独立、零一致）的模糊分类聚合函数。

Result: 证明了此类函数必须是加权算术平均。

Conclusion: 在给定条件下，加权算术平均是唯一满足要求的模糊分类聚合函数。

Abstract: We prove that any optimal, independent, and zero unanimous fuzzy
classification aggregation function of a continuum of individual
classifications of $m\ge 3$ objects into $2\le p\le m$ types must be a weighted
arithmetic mean.

</details>


### [9] [OLG++: A Semantic Extension of Obligation Logic Graph](https://arxiv.org/abs/2507.05488)
*Subhasis Dasgupta,Jon Stephens,Amarnath Gupta*

Main category: cs.AI

TL;DR: OLG++是Obligation Logic Graph（OLG）的语义扩展，用于建模市政和跨辖区背景下的法规和法律规则。它引入了更丰富的节点和边类型，支持复杂的法律义务、例外和层次结构表示。


<details>
  <summary>Details</summary>
Motivation: 现有法律知识表示模型（如LegalRuleML）在表达空间、时间和逻辑分组等复杂约束时存在不足，需要更灵活的建模工具。

Method: OLG++扩展了OLG，新增了空间、时间、群体、可废止性和逻辑分组等节点和边类型，支持结构化推理和复杂触发条件。

Result: 通过食品业务法规的案例，OLG++展示了其在法律问答和属性图查询中的表达能力，优于现有图模型。

Conclusion: OLG++在表达复杂法律规则方面优于现有模型，为法律知识表示提供了更强大的工具。

Abstract: We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)
for modeling regulatory and legal rules in municipal and interjurisdictional
contexts. OLG++ introduces richer node and edge types, including spatial,
temporal, party group, defeasibility, and logical grouping constructs, enabling
nuanced representations of legal obligations, exceptions, and hierarchies. The
model supports structured reasoning over rules with contextual conditions,
precedence, and complex triggers. We demonstrate its expressiveness through
examples from food business regulations, showing how OLG++ supports legal
question answering using property graph queries. OLG++ also improves over
LegalRuleML by providing native support for subClassOf, spatial constraints,
and reified exception structures. Our examples show that OLG++ is more
expressive than prior graph-based models for legal knowledge representation.

</details>


### [10] [Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents](https://arxiv.org/abs/2507.05495)
*Prahaladh Chandrahasan,Jiahe Jin,Zhihan Zhang,Tevin Wang,Andy Tang,Lucy Mo,Morteza Ziyadi,Leonardo F. R. Ribeiro,Zimeng Qiu,Markus Dreyer,Akari Asai,Chenyan Xiong*

Main category: cs.AI

TL;DR: 论文介绍了Deep Research Comparator平台，用于评估深度研究代理的生成报告，支持对比分析、细粒度反馈和排名计算。


<details>
  <summary>Details</summary>
Motivation: 解决深度研究代理生成报告的评估难题，尤其是长报告和中间步骤的详细反馈。

Method: 开发了Deep Research Comparator平台，支持代理报告对比、中间步骤评估和反馈收集；同时提出了Simple Deepresearch作为基线代理框架。

Result: 收集了17位标注者对三个深度研究代理的真实偏好数据，验证了平台的有效性。

Conclusion: 该平台为深度研究代理的开发提供了实用的评估工具，并展示了其实际应用价值。

Abstract: Effectively evaluating deep research agents that autonomously search the web,
analyze information, and generate reports remains a major challenge,
particularly when it comes to assessing long reports and giving detailed
feedback on their intermediate steps. To address these gaps, we introduce Deep
Research Comparator, a platform that offers a holistic framework for deep
research agent hosting, side-by-side comparison, fine-grained human feedback
collection, and ranking calculation. Given a user query, our platform displays
the final reports from two different agents along with their intermediate steps
during generation. Annotators can evaluate the overall quality of final reports
based on side-by-side comparison, and also provide detailed feedback separately
by assessing intermediate steps or specific text spans within the final report.
Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This
scaffold serves as a baseline that facilitates the easy integration of various
large language models to transform them into deep research agents for
evaluation. To demonstrate the platform's utility for deep research agent
development, we have collected real user preference data from 17 annotators on
three deep research agents. A demo video of our platform can be found at
https://www.youtube.com/watch?v=g4d2dnbdseg.

</details>


### [11] [Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality](https://arxiv.org/abs/2507.05515)
*Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang*

Main category: cs.AI

TL;DR: 本文介绍了专为AR训练设计的综合数据集，评估了九种先进VLM模型，发现其在细粒度任务中表现不佳，呼吁改进数据集和基准。


<details>
  <summary>Details</summary>
Motivation: 探索VLM在AR训练中的应用，填补研究空白，并为盲人和视障用户提供平等的AI学习机会。

Method: 构建系统化的视觉语言任务数据集，评估九种先进VLM模型（包括GPT-4o）在细粒度任务上的表现。

Result: 先进模型在细粒度组装任务中表现不佳，最高F1分数仅为40.54%，显示需改进视觉语言对齐。

Conclusion: 需增强数据集和基准研究，以提升VLM在AR训练中的性能，同时推动社会包容性。

Abstract: Vision-language models (VLMs) are essential for enabling AI-powered smart
assistants to interpret and reason in multimodal environments. However, their
application in augmented reality (AR) training remains largely unexplored. In
this work, we introduce a comprehensive dataset tailored for AR training,
featuring systematized vision-language tasks, and evaluate nine
state-of-the-art VLMs on it. Our results reveal that even advanced models,
including GPT-4o, struggle with fine-grained assembly tasks, achieving a
maximum F1 score of just 40.54% on state detection. These findings highlight
the demand for enhanced datasets, benchmarks, and further research to improve
fine-grained vision-language alignment. Beyond technical contributions, our
work has broader social implications, particularly in empowering blind and
visually impaired users with equitable access to AI-driven learning
opportunities. We provide all related resources, including the dataset, source
code, and evaluation results, to support the research community.

</details>


### [12] [Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System](https://arxiv.org/abs/2507.05519)
*Gopal Gupta,Abhiramon Rajasekharan,Alexis R. Tudor,Elmer Salazar,Joaquín Arias*

Main category: cs.AI

TL;DR: 论文探讨了如何在答案集编程（ASP）中优雅地实现道义模态逻辑，利用默认否定和强否定表示模态算子，并通过ASP的全局约束解决道义逻辑的悖论。


<details>
  <summary>Details</summary>
Motivation: 解决道义模态逻辑的实现问题，并探索其在答案集编程中的表达方式。

Method: 利用ASP中的默认否定和强否定表示道义模态算子，并通过全局约束表示义务和禁止。

Result: 提出的方法能够优雅地解决道义模态逻辑中的各种悖论。

Conclusion: ASP为道义模态逻辑的实现提供了有效的工具，并能解决其悖论问题。

Abstract: We consider the problem of implementing deontic modal logic. We show how
(deontic) modal operators can be expressed elegantly using default negation
(negation-as-failure) and strong negation present in answer set programming
(ASP). We propose using global constraints of ASP to represent obligations and
impermissibilities of deontic modal logic. We show that our proposed
representation results in the various paradoxes of deontic modal logic being
elegantly resolved.

</details>


### [13] [Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis](https://arxiv.org/abs/2507.05520)
*Karishma Thakrar,Shreyas Basavatia,Akshay Daftardar*

Main category: cs.AI

TL;DR: 2025 ImageCLEF MEDIQA-MAGIC挑战赛关注多模态皮肤病问答与分割，提出结合微调多模态模型、结构化推理层和代理检索增强生成的方法，取得高精度结果。


<details>
  <summary>Details</summary>
Motivation: 解决远程医疗中基于有限输入的异步诊断决策问题，提高准确性和可解释性。

Method: 结合微调开源多模态模型（Qwen、Gemma、LLaMA）、结构化推理层和代理检索增强生成（RAG）。

Result: 团队获得第二名，提交作品排名第六，表现竞争力和高准确性。

Conclusion: 该架构模拟皮肤科医生的系统推理模式，为自动化诊断支持系统提供了更可靠的路径。

Abstract: The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized
by researchers from Microsoft, Stanford University, and the Hospital Clinic of
Barcelona, focuses on multimodal dermatology question answering and
segmentation, using real-world patient queries and images. This work addresses
the Closed Visual Question Answering (CVQA) task, where the goal is to select
the correct answer to multiple-choice clinical questions based on both
user-submitted images and accompanying symptom descriptions. The proposed
approach combines three core components: (1) fine-tuning open-source multimodal
models from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)
introducing a structured reasoning layer that reconciles and adjudicates
between candidate model outputs, and (3) incorporating agentic
retrieval-augmented generation (agentic RAG), which adds relevant information
from the American Academy of Dermatology's symptom and condition database to
fill in gaps in patient context. The team achieved second place with a
submission that scored sixth, demonstrating competitive performance and high
accuracy. Beyond competitive benchmarks, this research addresses a practical
challenge in telemedicine: diagnostic decisions must often be made
asynchronously, with limited input and with high accuracy and interpretability.
By emulating the systematic reasoning patterns employed by dermatologists when
evaluating skin conditions, this architecture provided a pathway toward more
reliable automated diagnostic support systems.

</details>


### [14] [Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment](https://arxiv.org/abs/2507.05528)
*Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang*

Main category: cs.AI

TL;DR: 论文提出WikiHowAgent，一个基于大语言模型的多智能体工作流，用于模拟教学互动，评估教学效果，并开源了数据集和实现。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏可扩展性，未能充分利用大规模课程内容，且缺乏评估教学质量的框架。

Method: 提出WikiHowAgent，整合教师和学习者智能体、互动管理器和评估器，基于14,287篇教程构建数据集。

Result: 工作流在多样化场景中表现有效，揭示了大语言模型在不同领域的潜力。

Conclusion: WikiHowAgent为教学互动和评估提供了有效工具，数据集和实现已开源。

Abstract: Large language models (LLMs) have advanced virtual educators and learners,
bridging NLP with AI4Education. Existing work often lacks scalability and fails
to leverage diverse, large-scale course content, with limited frameworks for
assessing pedagogic quality. To this end, we propose WikiHowAgent, a
multi-agent workflow leveraging LLMs to simulate interactive teaching-learning
conversations. It integrates teacher and learner agents, an interaction
manager, and an evaluator to facilitate procedural learning and assess
pedagogic quality. We introduce a dataset of 114,296 teacher-learner
conversations grounded in 14,287 tutorials across 17 domains and 727 topics.
Our evaluation protocol combines computational and rubric-based metrics with
human judgment alignment. Results demonstrate the workflow's effectiveness in
diverse setups, offering insights into LLM capabilities across domains. Our
datasets and implementations are fully open-sourced.

</details>


### [15] [Red Teaming AI Red Teaming](https://arxiv.org/abs/2507.05538)
*Subhabrata Majumdar,Brian Pendleton,Abhishek Gupta*

Main category: cs.AI

TL;DR: 本文批判性地审视了AI红队测试的实践，指出其当前在AI治理中的局限性，并提出一个涵盖宏观和微观层面的综合框架。


<details>
  <summary>Details</summary>
Motivation: 探讨AI红队测试在生成式AI背景下过于关注模型级缺陷而忽视更广泛的社会技术系统的问题。

Method: 提出一个双层次框架（宏观系统级和微观模型级红队测试），并结合网络安全经验和系统理论提出建议。

Result: 强调有效的AI红队测试需要多职能团队，关注涌现风险、系统性漏洞及技术与社会因素的相互作用。

Conclusion: 呼吁更全面的红队测试方法，以应对AI系统中的复杂交互和潜在风险。

Abstract: Red teaming has evolved from its origins in military applications to become a
widely adopted methodology in cybersecurity and AI. In this paper, we take a
critical look at the practice of AI red teaming. We argue that despite its
current popularity in AI governance, there exists a significant gap between red
teaming's original intent as a critical thinking exercise and its narrow focus
on discovering model-level flaws in the context of generative AI. Current AI
red teaming efforts focus predominantly on individual model vulnerabilities
while overlooking the broader sociotechnical systems and emergent behaviors
that arise from complex interactions between models, users, and environments.
To address this deficiency, we propose a comprehensive framework
operationalizing red teaming in AI systems at two levels: macro-level system
red teaming spanning the entire AI development lifecycle, and micro-level model
red teaming. Drawing on cybersecurity experience and systems theory, we further
propose a set of recommendations. In these, we emphasize that effective AI red
teaming requires multifunctional teams that examine emergent risks, systemic
vulnerabilities, and the interplay between technical and social factors.

</details>


### [16] [SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation](https://arxiv.org/abs/2507.05541)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.AI

TL;DR: 论文探讨了利用GPT-4o-mini生成反事实解释（CFs）的方法，在零样本和三样本设置下表现优异，优于传统方法，并能提升下游分类器性能。


<details>
  <summary>Details</summary>
Motivation: 反事实解释（CFs）能为机器学习预测提供直观的干预和数据增强手段，但传统方法在生成CFs时存在局限性。

Method: 使用GPT-4o-mini在零样本和三样本设置下生成CFs，并在AI-Readi和心脏病检测数据集上评估。

Result: LLM生成的CFs在合理性（99%）、有效性（0.99）和稀疏性上表现优异，且作为增强数据能提升分类器准确率5%。

Conclusion: 基于提示的生成技术能显著提升临床和生理预测任务的可解释性和鲁棒性。

Abstract: Counterfactual explanations (CFs) offer human-centric insights into machine
learning predictions by highlighting minimal changes required to alter an
outcome. Therefore, CFs can be used as (i) interventions for abnormality
prevention and (ii) augmented data for training robust models. In this work, we
explore large language models (LLMs), specifically GPT-4o-mini, for generating
CFs in a zero-shot and three-shot setting. We evaluate our approach on two
datasets: the AI-Readi flagship dataset for stress prediction and a public
dataset for heart disease detection. Compared to traditional methods such as
DiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high
plausibility (up to 99%), strong validity (up to 0.99), and competitive
sparsity. Moreover, using LLM-generated CFs as augmented samples improves
downstream classifier performance (an average accuracy gain of 5%), especially
in low-data regimes. This demonstrates the potential of prompt-based generative
techniques to enhance explainability and robustness in clinical and
physiological prediction tasks. Code base: github.com/anonymous/SenseCF.

</details>


### [17] [SingLoRA: Low Rank Adaptation Using a Single Matrix](https://arxiv.org/abs/2507.05566)
*David Bensaïd,Noam Rotstein,Roy Velich,Daniel Bensaïd,Ron Kimmel*

Main category: cs.AI

TL;DR: SingLoRA提出了一种新的低秩适应方法，通过单低秩矩阵分解解决LoRA中的尺度冲突问题，提升训练稳定性并减少参数数量。


<details>
  <summary>Details</summary>
Motivation: LoRA在参数高效微调中存在尺度冲突导致训练不稳定，SingLoRA旨在解决这一问题。

Method: SingLoRA将权重更新分解为单低秩矩阵与其转置的乘积，消除尺度冲突并减少参数。

Result: 在多个任务中表现优异，如LLama 7B微调准确率91.3%，优于LoRA和LoRA+，且参数更少。

Conclusion: SingLoRA通过简化设计解决了LoRA的局限性，实现了更稳定和高效的微调。

Abstract: Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient
fine-tuning of large pretrained models. LoRA augments the pre-trained weights
of a model by adding the product of two smaller matrices that together form a
low-rank matrix update. Recent research has shown that scale disparities
between these two matrices often cause unstable training dynamics, leading to
suboptimal performance. In this paper, we propose SingLoRA, which reformulates
low-rank adaptation by learning the weights update as a decomposition of a
single low-rank matrix multiplied by its transpose. This simple design
inherently removes inter-matrix scale conflicts, ensuring stable optimization,
and roughly halves the parameter count. We analyze SingLoRA within the
infinite-width neural network framework, showing that it guarantees stable
feature learning by construction. Extensive experiments on multiple tasks
validate these benefits. In common sense reasoning, fine-tuning LLama 7B on
MNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+
(90.2%) - while using only 60% of their parameter budget. In image generation,
fine-tuning Stable Diffusion with SingLoRA significantly improves image
fidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to
scores of 0.148 and 0.143 for DoRA and LoRA, respectively.

</details>


### [18] [Towards Measurement Theory for Artificial Intelligence](https://arxiv.org/abs/2507.05587)
*Elija Perrier*

Main category: cs.AI

TL;DR: 提出了一个关于人工智能测量的正式理论框架，旨在通过标准化测量方法促进系统比较、风险分析及能力评估。


<details>
  <summary>Details</summary>
Motivation: 为AI研究、实践和监管提供统一的测量标准，以支持系统比较、风险分析及能力评估的客观性。

Method: 提出分层的测量框架，区分直接与间接可观测性，并构建可校准的AI现象分类体系。

Result: 为AI测量提供了一个理论框架，支持系统比较、风险分析及能力评估的标准化。

Conclusion: 标准化AI测量有助于提升研究的可比性和风险管理的科学性。

Abstract: We motivate and outline a programme for a formal theory of measurement of
artificial intelligence. We argue that formalising measurement for AI will
allow researchers, practitioners, and regulators to: (i) make comparisons
between systems and the evaluation methods applied to them; (ii) connect
frontier AI evaluations with established quantitative risk analysis techniques
drawn from engineering and safety science; and (iii) foreground how what counts
as AI capability is contingent upon the measurement operations and scales we
elect to use. We sketch a layered measurement stack, distinguish direct from
indirect observables, and signpost how these ingredients provide a pathway
toward a unified, calibratable taxonomy of AI phenomena.

</details>


### [19] [MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models](https://arxiv.org/abs/2507.05591)
*Wei Zhang,Juan Chen,En Zhu,Wenhong Cheng,YunPeng Li,Yanbo J. Wang*

Main category: cs.AI

TL;DR: 提出了一种新型多模态大语言模型（MLlm-DR），用于可解释的抑郁症诊断，结合小型LLM和轻量级查询模块（LQ-former），在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症诊断方法缺乏解释性，且直接使用多模态数据的LLM性能不佳，因此需要一种既能处理多模态信息又能提供解释的模型。

Method: MLlm-DR整合小型LLM生成抑郁症评分和评估理由，并通过LQ-former从语音和视觉数据中提取特征，结合训练数据集进行微调。

Result: 在CMDC和E-DAIC-WOZ数据集上取得最优结果，验证了模型的有效性和优越性。

Conclusion: MLlm-DR为抑郁症诊断提供了一种可解释且高效的多模态解决方案，具有临床应用的潜力。

Abstract: Automated depression diagnosis aims to analyze multimodal information from
interview videos to predict participants' depression scores. Previous studies
often lack clear explanations of how these scores were determined, limiting
their adoption in clinical practice. While the advent of LLMs provides a
possible pathway for explainable depression diagnosis, current LLMs capable of
processing multimodal data lack training on interview data, resulting in poor
diagnostic performance when used directly. In this paper, we propose a novel
multimodal large language model (MLlm-DR) that can understand multimodal
information inputs and supports explainable depression diagnosis. MLlm-DR
integrates a smaller LLMs and a lightweight query module (LQ-former).
Specifically, the smaller LLMs is designed to generate depression scores and
corresponding evaluation rationales. To enhance its logical reasoning for
domain-specific tasks while maintaining practicality, we constructed a robust
training dataset to fine-tune it. Meanwhile, the LQ-former captures
depression-related features from speech and visual data, aiding the model's
ability to process multimodal information, to achieve comprehensive depression
diagnosis. Our approach achieves state-of-the-art results on two
interview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its
effectiveness and superiority.

</details>


### [20] [Domain adaptation of large language models for geotechnical applications](https://arxiv.org/abs/2507.05613)
*Lei Fan,Fangxue Liu,Cheng Chen*

Main category: cs.AI

TL;DR: 本文综述了大语言模型（LLMs）在岩土工程中的适应与应用，总结了关键方法、应用领域及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，其在岩土工程中的潜力逐渐显现，但需领域特定适应才能有效应用。本文旨在填补这一研究空白。

Method: 通过提示工程、检索增强生成、领域自适应预训练和微调等方法，将LLMs适应于岩土工程领域。

Result: 综述了LLMs在岩土工程中的多种应用，如地质解释、地下表征、设计计算等，并分析了其优势与局限。

Conclusion: 本文为实践者提供了整合LLMs的指导，同时为学术界的进一步研究奠定了基础。

Abstract: Recent developments in large language models (LLMs) are opening up new
opportunities in geotechnical engineering and engineering geology. While
general-purpose LLMs possess broad capabilities, effective application in
geotechnics often requires domain-specific adaptation. Such tailored LLMs are
increasingly employed to streamline geotechnical workflows. This paper presents
the first survey of the adaptation and application of LLMs in geotechnical
engineering. It outlines key methodologies for adaptation to geotechnical
domain, including prompt engineering, retrieval-augmented generation,
domain-adaptive pretraining, and fine-tuning. The survey examines the
state-of-the-art applications of geotechnical-adapted LLMs, including
geological interpretation, subsurface characterization, site planning, design
calculations, numerical modeling, safety and risk assessment, and educational
tutoring. It also analyzes benefits and limitations of geotechnical-adapted
LLMs, and identifies promising directions for future research in this
interdisciplinary discipline. The findings serve as a valuable resource for
practitioners seeking to integrate LLMs into geotechnical practice, while also
providing a foundation to stimulate further investigation within the academic
community.

</details>


### [21] [ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion](https://arxiv.org/abs/2507.05624)
*Wei Zhang,Juan Chen,Yanbo J. Wang,En Zhu,Xuan Yang,Yiduo Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于注意力扩散的模型（ADMC），用于解决多模态情感和意图识别中缺失模态的问题，通过独立训练模态特征提取网络和生成缺失特征，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多模态情感和意图识别中，模态缺失是常见问题，传统方法因过度耦合和生成不精确导致效果不佳。

Method: 提出ADMC框架，独立训练各模态特征提取网络，利用注意力扩散网络（ADN）生成缺失模态特征。

Result: 在IEMOCAP和MIntRec基准测试中达到最优性能，适用于缺失和完整模态场景。

Conclusion: ADMC通过避免过度耦合和精确生成缺失特征，显著提升了多模态情感和意图识别的效果。

Abstract: Multimodal emotion and intent recognition is essential for automated
human-computer interaction, It aims to analyze users' speech, text, and visual
information to predict their emotions or intent. One of the significant
challenges is that missing modalities due to sensor malfunctions or incomplete
data. Traditional methods that attempt to reconstruct missing information often
suffer from over-coupling and imprecise generation processes, leading to
suboptimal outcomes. To address these issues, we introduce an Attention-based
Diffusion model for Missing Modalities feature Completion (ADMC). Our framework
independently trains feature extraction networks for each modality, preserving
their unique characteristics and avoiding over-coupling. The Attention-based
Diffusion Network (ADN) generates missing modality features that closely align
with authentic multimodal distribution, enhancing performance across all
missing-modality scenarios. Moreover, ADN's cross-modal generation offers
improved recognition even in full-modality contexts. Our approach achieves
state-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating
its effectiveness in both missing and complete modality scenarios.

</details>


### [22] [Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses](https://arxiv.org/abs/2507.05629)
*Yuan An,John Liu,Niyam Acharya,Ruhma Hashmi*

Main category: cs.AI

TL;DR: 研究表明，LLM生成的检索练习问题能显著提高学生知识保留率，但需人工验证质量。


<details>
  <summary>Details</summary>
Motivation: 解决教师生成高质量检索练习问题耗时的问题，探索LLM自动生成问题的有效性。

Method: 在60名学生的数据科学课程中，对比LLM生成的多选题与无练习周的学习效果。

Result: 使用LLM生成问题的学生知识保留率（89%）显著高于无练习周（73%）。

Conclusion: LLM生成问题可有效支持学习，但需人工验证以确保质量。

Abstract: Retrieval practice is a well-established pedagogical technique known to
significantly enhance student learning and knowledge retention. However,
generating high-quality retrieval practice questions is often time-consuming
and labor intensive for instructors, especially in rapidly evolving technical
subjects. Large Language Models (LLMs) offer the potential to automate this
process by generating questions in response to prompts, yet the effectiveness
of LLM-generated retrieval practice on student learning remains to be
established. In this study, we conducted an empirical study involving two
college-level data science courses, with approximately 60 students. We compared
learning outcomes during one week in which students received LLM-generated
multiple-choice retrieval practice questions to those from a week in which no
such questions were provided. Results indicate that students exposed to
LLM-generated retrieval practice achieved significantly higher knowledge
retention, with an average accuracy of 89%, compared to 73% in the week without
such practice. These findings suggest that LLM-generated retrieval questions
can effectively support student learning and may provide a scalable solution
for integrating retrieval practice into real-time teaching. However, despite
these encouraging outcomes and the potential time-saving benefits, cautions
must be taken, as the quality of LLM-generated questions can vary. Instructors
must still manually verify and revise the generated questions before releasing
them to students.

</details>


### [23] [LLMs are Introvert](https://arxiv.org/abs/2507.05638)
*Litian Zhang,Xiaoming Zhang,Bingyu Yan,Ziyi Zhou,Bo Zhang,Zhenyu Guan,Xi Zhang,Chaozhuo Li*

Main category: cs.AI

TL;DR: 论文探讨了LLM在模拟信息传播中的局限性，并提出SIP-CoT机制结合情感记忆以提升模拟的真实性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的快速发展与生成式AI的普及加剧了错误信息的传播，传统模型无法捕捉在线交互的复杂性，而现有高级方法又忽略了用户心理和行为动态。

Method: 提出基于社会信息处理理论（SIP）的SIP-CoT机制，结合情感记忆，改进LLM代理对社交线索的解释、目标个性化及反馈评估。

Result: 实验表明，SIP-CoT增强的LLM代理能更有效地处理社交信息，行为、态度和情感更接近真实人类互动。

Conclusion: 研究揭示了当前LLM模拟的局限性，并证明SIP-CoT和情感记忆的结合显著提升了LLM代理的社会智能和真实性。

Abstract: The exponential growth of social media and generative AI has transformed
information dissemination, fostering connectivity but also accelerating the
spread of misinformation. Understanding information propagation dynamics and
developing effective control strategies is essential to mitigate harmful
content. Traditional models, such as SIR, provide basic insights but
inadequately capture the complexities of online interactions. Advanced methods,
including attention mechanisms and graph neural networks, enhance accuracy but
typically overlook user psychology and behavioral dynamics. Large language
models (LLMs), with their human-like reasoning, offer new potential for
simulating psychological aspects of information spread. We introduce an
LLM-based simulation environment capturing agents' evolving attitudes,
emotions, and responses. Initial experiments, however, revealed significant
gaps between LLM-generated behaviors and authentic human dynamics, especially
in stance detection and psychological realism. A detailed evaluation through
Social Information Processing Theory identified major discrepancies in
goal-setting and feedback evaluation, stemming from the lack of emotional
processing in standard LLM training. To address these issues, we propose the
Social Information Processing-based Chain of Thought (SIP-CoT) mechanism
enhanced by emotion-guided memory. This method improves the interpretation of
social cues, personalization of goals, and evaluation of feedback. Experimental
results confirm that SIP-CoT-enhanced LLM agents more effectively process
social information, demonstrating behaviors, attitudes, and emotions closer to
real human interactions. In summary, this research highlights critical
limitations in current LLM-based propagation simulations and demonstrates how
integrating SIP-CoT and emotional memory significantly enhances the social
intelligence and realism of LLM agents.

</details>


### [24] [City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data](https://arxiv.org/abs/2507.05651)
*Tianxing Wu,Lizhe Cao,Shuang Wang,Jiming Wang,Shutong Zhu,Yerong Wu,Yuqing Feng*

Main category: cs.AI

TL;DR: 论文提出了一种基于司法数据的城市级外国直接投资（FDI）预测方法（TLJD），通过整合司法性能指标和区域差异，显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于经济数据（如GDP）的FDI预测可能因数据操纵而不可靠，因此需要更可靠的替代数据源。司法数据能反映投资安全和回报，是理想选择。

Method: 构建了一个基于1200万份公开裁决文件的司法性能评估指标体系，并提出TLJD方法，整合行数据和列数据，利用专家混合模型调整指标权重。

Result: TLJD在跨城市和跨时间任务中表现优异（R2至少0.92），优于其他十种先进基线方法。

Conclusion: 司法数据是FDI预测的有效补充，TLJD方法在准确性和可靠性上具有显著优势。

Abstract: To advance the United Nations Sustainable Development Goal on promoting
sustained, inclusive, and sustainable economic growth, foreign direct
investment (FDI) plays a crucial role in catalyzing economic expansion and
fostering innovation. Precise city-level FDI prediction is quite important for
local government and is commonly studied based on economic data (e.g., GDP).
However, such economic data could be prone to manipulation, making predictions
less reliable. To address this issue, we try to leverage large-scale judicial
data which reflects judicial performance influencing local investment security
and returns, for city-level FDI prediction. Based on this, we first build an
index system for the evaluation of judicial performance over twelve million
publicly available adjudication documents according to which a tabular dataset
is reformulated. We then propose a new Tabular Learning method on Judicial Data
(TLJD) for city-level FDI prediction. TLJD integrates row data and column data
in our built tabular dataset for judicial performance indicator encoding, and
utilizes a mixture of experts model to adjust the weights of different
indicators considering regional variations. To validate the effectiveness of
TLJD, we design cross-city and cross-time tasks for city-level FDI predictions.
Extensive experiments on both tasks demonstrate the superiority of TLJD (reach
to at least 0.92 R2) over the other ten state-of-the-art baselines in different
evaluation metrics.

</details>


### [25] [Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology](https://arxiv.org/abs/2507.05716)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 研究比较了人类专家和两种AI模型（通用型和推理型）生成的皮肤病治疗计划，发现评估者的性质显著影响结果：人类专家偏好同行计划，而AI评估者更青睐AI计划。


<details>
  <summary>Details</summary>
Motivation: 随着AI在医疗领域的扩展，评估其生成的治疗计划成为关键挑战，尤其是新型推理模型的出现。研究旨在比较人类和AI生成计划的差异及其评估标准。

Method: 十名皮肤科医生、通用AI（GPT-4o）和推理AI（o3）为五个复杂皮肤病案例生成治疗计划。计划经匿名和标准化后，由人类专家和高级AI（Gemini 2.5 Pro）分别评分。

Result: 人类专家评分显著高于AI计划（7.62 vs. 7.16），而AI评估者则相反（7.75 vs. 6.79）。推理AI（o3）被AI评估者评为最佳（8.20），但人类专家评分较低（6.97）。

Conclusion: 临床计划的质量感知取决于评估者的性质，揭示了经验启发式与数据驱动逻辑之间的差距。未来需发展协同、可解释的人机系统以弥合这一差距。

Abstract: Background: Evaluating AI-generated treatment plans is a key challenge as AI
expands beyond diagnostics, especially with new reasoning models. This study
compares plans from human experts and two AI models (a generalist and a
reasoner), assessed by both human peers and a superior AI judge.
  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI
(o3) generated treatment plans for five complex dermatology cases. The
anonymized, normalized plans were scored in two phases: 1) by the ten human
experts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical
rubric.
  Results: A profound 'evaluator effect' was observed. Human experts scored
peer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16;
p=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th
(mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI
plans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It
ranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.
  Conclusions: The perceived quality of a clinical plan is fundamentally
dependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by
human experts, was judged as superior by a sophisticated AI, revealing a deep
gap between experience-based clinical heuristics and data-driven algorithmic
logic. This paradox presents a critical challenge for AI integration,
suggesting the future requires synergistic, explainable human-AI systems that
bridge this reasoning gap to augment clinical care.

</details>


### [26] [An autonomous agent for auditing and improving the reliability of clinical AI models](https://arxiv.org/abs/2507.05755)
*Lukas Kuhn,Florian Buettner*

Main category: cs.AI

TL;DR: ModelAuditor是一个自我反思工具，用于识别和修复AI模型在临床实践中的潜在失败模式，通过模拟分布变化生成可解释报告，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在临床实践中因真实世界变化（如硬件、光照或人口统计差异）导致的性能下降问题，提供可访问且可解释的可靠性审计工具。

Method: ModelAuditor通过与用户对话、选择任务特定指标、模拟临床相关分布变化，生成解释性能下降、失败模式和缓解策略的报告。

Result: 在三种临床场景中，ModelAuditor能准确识别失败模式，并通过针对性建议恢复15-25%的性能损失，优于基线模型和增强方法。

Conclusion: ModelAuditor是一种高效、低成本且可解释的工具，显著提升AI模型在临床实践中的可靠性。

Abstract: The deployment of AI models in clinical practice faces a critical challenge:
models achieving expert-level performance on benchmarks can fail
catastrophically when confronted with real-world variations in medical imaging.
Minor shifts in scanner hardware, lighting or demographics can erode accuracy,
but currently reliability auditing to identify such catastrophic failure cases
before deployment is a bespoke and time-consuming process. Practitioners lack
accessible and interpretable tools to expose and repair hidden failure modes.
Here we introduce ModelAuditor, a self-reflective agent that converses with
users, selects task-specific metrics, and simulates context-dependent,
clinically relevant distribution shifts. ModelAuditor then generates
interpretable reports explaining how much performance likely degrades during
deployment, discussing specific likely failure modes and identifying root
causes and mitigation strategies. Our comprehensive evaluation across three
real-world clinical scenarios - inter-institutional variation in
histopathology, demographic shifts in dermatology, and equipment heterogeneity
in chest radiography - demonstrates that ModelAuditor is able correctly
identify context-specific failure modes of state-of-the-art models such as the
established SIIM-ISIC melanoma classifier. Its targeted recommendations recover
15-25% of performance lost under real-world distribution shift, substantially
outperforming both baseline models and state-of-the-art augmentation methods.
These improvements are achieved through a multi-agent architecture and execute
on consumer hardware in under 10 minutes, costing less than US$0.50 per audit.

</details>


### [27] [Real-time monitoring of the SoH of lithium-ion batteries](https://arxiv.org/abs/2507.05765)
*Bruno Jammes,Edgar Hernando Sepúlveda-Oviedo,Corinne Alonso*

Main category: cs.AI

TL;DR: 提出了一种基于充电结束阶段放电脉冲分析的新方法，用于实时监测电池健康状态（SoH），初步结果显示预测精度高且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 微电网中电池健康状态的实时监测面临挑战，传统方法受限，需要创新解决方案。

Method: 通过分析充电结束阶段的放电脉冲，利用等效电路模型参数估计SoH。

Result: 实验数据显示，预测退化电池的SoH时，平均绝对误差约1%，解释性得分接近0.9。

Conclusion: 该方法有望集成到电池管理系统中，优化持续运行下的电池管理。

Abstract: Real-time monitoring of the state of health (SoH) of batteries remains a
major challenge, particularly in microgrids where operational constraints limit
the use of traditional methods. As part of the 4BLife project, we propose an
innovative method based on the analysis of a discharge pulse at the end of the
charge phase. The parameters of the equivalent electrical model describing the
voltage evolution across the battery terminals during this current pulse are
then used to estimate the SoH. Based on the experimental data acquired so far,
the initial results demonstrate the relevance of the proposed approach. After
training using the parameters of two batteries with a capacity degradation of
around 85%, we successfully predicted the degradation of two other batteries,
cycled down to approximately 90% SoH, with a mean absolute error of around 1%
in the worst case, and an explainability score of the estimator close to 0.9.
If these performances are confirmed, this method can be easily integrated into
battery management systems (BMS) and paves the way for optimized battery
management under continuous operation.

</details>


### [28] [GTA1: GUI Test-time Scaling Agent](https://arxiv.org/abs/2507.05791)
*Yan Yang,Dongxu Li,Yutong Dai,Yuhao Yang,Ziyang Luo,Zirui Zhao,Zhiyuan Hu,Junzhe Huang,Amrita Saha,Zeyuan Chen,Ran Xu,Liyuan Pan,Caiming Xiong,Junnan Li*

Main category: cs.AI

TL;DR: 论文提出了一种名为GTA1的GUI测试时扩展代理，解决了任务规划和视觉元素交互的两大挑战，通过测试时扩展方法和强化学习提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决GUI代理在任务规划中的歧义性和复杂界面中视觉元素交互的准确性挑战。

Method: 引入测试时扩展方法选择最佳动作提案，并利用强化学习模型提高视觉元素交互的准确性。

Result: 在多个基准测试中达到最先进性能，例如在Screenspot-Pro、Screenspot-V2和OSWorld-G上的准确率分别为50.1%、92.4%和67.7%。

Conclusion: GTA1通过测试时扩展和强化学习方法显著提升了GUI代理的性能，并在实验中验证了其有效性。

Abstract: Graphical user interface (GUI) agents autonomously operate across platforms
(e.g., Linux) to complete tasks by interacting with visual elements.
Specifically, a user instruction is decomposed into a sequence of action
proposals, each corresponding to an interaction with the GUI. After each
action, the agent observes the updated GUI environment to plan the next step.
However, two main challenges arise: i) resolving ambiguity in task planning
(i.e., the action proposal sequence), where selecting an appropriate plan is
non-trivial, as many valid ones may exist; ii) accurately grounding actions in
complex and high-resolution interfaces, i.e., precisely interacting with visual
targets.
  This paper investigates the two aforementioned challenges with our GUI
Test-time Scaling Agent, namely GTA1. First, to select the most appropriate
action proposal, we introduce a test-time scaling method. At each step, we
sample multiple candidate action proposals and leverage a judge model to
evaluate and select the most suitable one. It trades off computation for better
decision quality by concurrent sampling, shortening task execution steps, and
improving overall performance. Second, we propose a model that achieves
improved accuracy when grounding the selected action proposal to its
corresponding visual elements. Our key insight is that reinforcement learning
(RL) facilitates visual grounding through inherent objective alignments,
rewarding successful clicks on interface elements.
  Experimentally, our method establishes state-of-the-art performance across
diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%
accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When
paired with a planner applying our test-time scaling strategy, it exhibits
state-of-the-art agentic performance (e.g., 45.2% task success rate on
OSWorld). We open-source our code and models here.

</details>


### [29] [Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity](https://arxiv.org/abs/2507.05816)
*Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLM）在预测早产儿视网膜病变（ROP）风险中的表现，提出了新的中文数据集CROP和评估框架Affective-ROPTester，发现外部知识增强和情感提示工程能显著提升预测效果并减少偏见。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在ROP风险预测中的潜力，填补现有研究的空白，并研究情感因素对模型预测和偏见的影响。

Method: 提出CROP数据集和Affective-ROPTester框架，采用三种提示策略（Instruction-based、CoT、ICL）并结合情感元素评估LLM的表现。

Result: LLM在仅依赖内部知识时预测效果有限，但结合外部知识后性能显著提升；情感偏见明显，积极情感提示有助于减少偏见。

Conclusion: 情感敏感的提示工程对提升诊断可靠性至关重要，Affective-ROPTester为临床语言模型评估和偏见缓解提供了有效工具。

Abstract: Despite the remarkable progress of large language models (LLMs) across
various domains, their capacity to predict retinopathy of prematurity (ROP)
risk remains largely unexplored. To address this gap, we introduce a novel
Chinese benchmark dataset, termed CROP, comprising 993 admission records
annotated with low, medium, and high-risk labels. To systematically examine the
predictive capabilities and affective biases of LLMs in ROP risk
stratification, we propose Affective-ROPTester, an automated evaluation
framework incorporating three prompting strategies: Instruction-based,
Chain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme
assesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and
ICL schemes leverage external medical knowledge to enhance predictive accuracy.
Crucially, we integrate emotional elements at the prompt level to investigate
how different affective framings influence the model's ability to predict ROP
and its bias patterns. Empirical results derived from the CROP dataset yield
two principal observations. First, LLMs demonstrate limited efficacy in ROP
risk prediction when operating solely on intrinsic knowledge, yet exhibit
marked performance gains when augmented with structured external inputs.
Second, affective biases are evident in the model outputs, with a consistent
inclination toward overestimating medium- and high-risk cases. Third, compared
to negative emotions, positive emotional framing contributes to mitigating
predictive bias in model outputs. These findings highlight the critical role of
affect-sensitive prompt engineering in enhancing diagnostic reliability and
emphasize the utility of Affective-ROPTester as a framework for evaluating and
mitigating affective bias in clinical language modeling systems.

</details>


### [30] [CogniPlay: a work-in-progress Human-like model for General Game Playing](https://arxiv.org/abs/2507.05868)
*Aloïs Rautureau,Éric Piette*

Main category: cs.AI

TL;DR: 论文探讨了AI系统在游戏中表现优异但仍缺乏人类直觉决策的问题，提出了基于认知心理学的模型CogniPlay。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在多种游戏中表现超越人类，但其决策过程缺乏人类直觉和模式识别能力，因此需要开发更接近人类认知的模型。

Method: 结合认知心理学和前人研究，提出了一种名为CogniPlay的模型，旨在模拟人类直觉决策。

Result: 论文介绍了CogniPlay模型的初步进展，但未提供具体实验结果。

Conclusion: CogniPlay是迈向更人类化AI决策的重要一步，未来需进一步验证其效果。

Abstract: While AI systems have equaled or surpassed human performance in a wide
variety of games such as Chess, Go, or Dota 2, describing these systems as
truly "human-like" remains far-fetched. Despite their success, they fail to
replicate the pattern-based, intuitive decision-making processes observed in
human cognition. This paper presents an overview of findings from cognitive
psychology and previous efforts to model human-like behavior in artificial
agents, discusses their applicability to General Game Playing (GGP) and
introduces our work-in-progress model based on these observations: CogniPlay.

</details>


### [31] [Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better](https://arxiv.org/abs/2507.05886)
*Aaron Bembenek*

Main category: cs.AI

TL;DR: 提出了一种新的计算模型——神经符号转换系统，用于构建神经符号自动推理工具，结合符号算法和大型语言模型的优势。


<details>
  <summary>Details</summary>
Motivation: 当前神经符号自动推理系统的构建缺乏原则性编程模型，无法充分发挥大型语言模型的潜力或保持符号算法的强保证。

Method: 提出神经符号转换系统，将符号状态与直觉配对，并在符号和直觉上并行执行状态转换。

Result: 该模型有望扩展逻辑推理能力，同时保留符号算法的强保证。

Conclusion: 神经符号转换系统为构建更强大的神经符号自动推理工具提供了理论基础，并可通过逻辑编程语言实现。

Abstract: There is growing excitement about building software verifiers, synthesizers,
and other Automated Reasoning (AR) tools by combining traditional symbolic
algorithms and Large Language Models (LLMs). Unfortunately, the current
practice for constructing such neurosymbolic AR systems is an ad hoc
programming model that does not have the strong guarantees of traditional
symbolic algorithms, nor a deep enough synchronization of neural networks and
symbolic reasoning to unlock the full potential of LLM-powered reasoning. I
propose Neurosymbolic Transition Systems as a principled computational model
that can underlie infrastructure for building neurosymbolic AR tools. In this
model, symbolic state is paired with intuition, and state transitions operate
over symbols and intuition in parallel. I argue why this new paradigm can scale
logical reasoning beyond current capabilities while retaining the strong
guarantees of symbolic algorithms, and I sketch out how the computational model
I propose can be reified in a logic programming language.

</details>


### [32] [Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection](https://arxiv.org/abs/2507.05891)
*Robert Leppich,Michael Stenger,André Bauer,Samuel Kounev*

Main category: cs.AI

TL;DR: 论文提出了一种分解时间序列预测流程为三个核心阶段的方法，通过评估不同模块的有效性，实现了高精度和高效计算。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列预测中取得进展，但仍需解决序列表示、信息提取和未来预测的挑战。

Method: 将预测流程分解为输入序列表示、信息提取与记忆构建、目标预测三阶段，评估不同模块配置。

Result: 模型在七个基准数据集上达到最先进的预测精度，同时显著提升计算效率。

Conclusion: 该方法通过任务分解和模块评估，有效解决了时间序列预测中的挑战。

Abstract: With the advent of Transformers, time series forecasting has seen significant
advances, yet it remains challenging due to the need for effective sequence
representation, memory construction, and accurate target projection. Time
series forecasting remains a challenging task, demanding effective sequence
representation, meaningful information extraction, and precise future
projection. Each dataset and forecasting configuration constitutes a distinct
task, each posing unique challenges the model must overcome to produce accurate
predictions. To systematically address these task-specific difficulties, this
work decomposes the time series forecasting pipeline into three core stages:
input sequence representation, information extraction and memory construction,
and final target projection. Within each stage, we investigate a range of
architectural configurations to assess the effectiveness of various modules,
such as convolutional layers for feature extraction and self-attention
mechanisms for information extraction, across diverse forecasting tasks,
including evaluations on seven benchmark datasets. Our models achieve
state-of-the-art forecasting accuracy while greatly enhancing computational
efficiency, with reduced training and inference times and a lower parameter
count. The source code is available at
https://github.com/RobertLeppich/REP-Net.

</details>


### [33] [MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation](https://arxiv.org/abs/2507.05894)
*Fathinah Izzati,Xinyue Li,Yuxuan Wu,Gus Xia*

Main category: cs.AI

TL;DR: 论文提出MusiScene模型，通过音乐场景想象任务（MSI）生成与音乐匹配的场景描述，并用于提升视频背景音乐生成（VBMG）。


<details>
  <summary>Details</summary>
Motivation: 探索音乐语言模型是否能像人类一样通过音乐想象场景，弥补现有音乐描述模型仅关注音乐元素的不足。

Method: 构建大规模视频-音频描述数据集，微调Music Understanding LLaMA以创建MusiScene模型，并进行全面评估。

Result: MusiScene在生成上下文相关描述上优于MU-LLaMA，并成功应用于VBMG任务。

Conclusion: MusiScene展示了音乐场景想象的潜力，为跨模态音乐理解与应用提供了新方向。

Abstract: Humans can imagine various atmospheres and settings when listening to music,
envisioning movie scenes that complement each piece. For example, slow,
melancholic music might evoke scenes of heartbreak, while upbeat melodies
suggest celebration. This paper explores whether a Music Language Model, e.g.
MU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),
which requires cross-modal information from video and music to train. To
improve upon existing music captioning models which focusing solely on musical
elements, we introduce MusiScene, a music captioning model designed to imagine
scenes that complement each music. In this paper, (1) we construct a
large-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music
Understanding LLaMA for the MSI task to create MusiScene, and (3) we conduct
comprehensive evaluations and prove that our MusiScene is more capable of
generating contextually relevant captions compared to MU-LLaMA. We leverage the
generated MSI captions to enhance Video Background Music Generation (VBMG) from
text.

</details>


### [34] [BlueLM-2.5-3B Technical Report](https://arxiv.org/abs/2507.05934)
*Baojiao Xiong,Boheng Chen,Chengzhi Wang,Daxiong Luo,Dongsheng Xu,Dongyang Liu,Fan Yang,Fangyuan Li,Fei Teng,Feng Wang,Fukang Qin,Fuquan Peng,Guanxin Tan,Guozhi Wang,Haibo Yu,Haohao Gao,Heng Liu,Hongbo Yang,Hongjian Zou,Houzheng Shen,Hu Meng,Huan Li,Hui Tan,Jiali Chen,Jianzhao Chen,Jinliang Zhu,Kai Wang,Lei Wu,Liangbing Liu,Liuyang Bian,Liyan He,Long Liu,Peiwen Li,Penggang Shi,Qi Ding,Rui Hu,Shuai Cao,Shuai Ren,Shuang Peng,Teng Xie,Weiji Chen,Weilin Xiang,Weixin Wu,Xi Yin,Xiaoxin Chen,Xu Chen,Yafei Wen,Yan Hu,Yanzhou Yang,Yina Xie,Yinghao Chen,Yixuan Liao,Yu Geng,Yuanjiang Ouyang,Yuanzhuo Yang,Yuehua He,Yushuai Peng,Zhaoxiong Wang,Zheng Wang,Zhibo Zhou,Ziyang Wu*

Main category: cs.AI

TL;DR: BlueLM-2.5-3B是一款紧凑的多模态大语言模型，支持思考和免思考模式，并在边缘设备上高效部署。


<details>
  <summary>Details</summary>
Motivation: 开发高性能、适用于边缘设备的多模态大语言模型，同时保持文本和多模态任务的竞争力。

Method: 通过多样化数据整理、关键数据重采样、混合异构强化学习和高效训练基础设施开发。

Result: 在文本和多模态任务中表现优异，数据效率高，性能接近或超越更大模型。

Conclusion: BlueLM-2.5-3B为高性能边缘设备MLLM提供了新思路，对研究社区有重要贡献。

Abstract: We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large
Language Model (MLLM) designed for efficient edge-device deployment, offering
strong general-purpose and reasoning capabilities. To the best of our
knowledge, this is the first 3B-scale MLLM to support both thinking and
non-thinking modes, while also enabling explicit control over thinking token
budget. BlueLM-2.5-3B is developed through diversified data curation, key data
resampling, hybrid heterogeneous reinforcement learning, and a high-performance
training infrastructure. Our model achieves superior multimodal capacity while
preserving competitive pure-text performance with only 2.9 billion parameters.
We conduct comprehensive evaluations across a broad range of multimodal and
text-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable
performance to Qwen3-4B on text-only benchmarks, and trails the larger
Kimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In
non-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal
benchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.
All of the aforementioned performance is achieved with substantially less total
training data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to
the advancement of high-performance, on-device MLLMs and provides meaningful
insights to the research community.

</details>


### [35] [A Wireless Foundation Model for Multi-Task Prediction](https://arxiv.org/abs/2507.05938)
*Yucheng Sheng,Jiacheng Wang,Xingyu Zhou,Le Liang,Hao Ye,Shi Jin,Geoffrey Ye Li*

Main category: cs.AI

TL;DR: 提出了一种用于无线网络中多任务预测的统一基础模型，支持不同预测区间，并展示了强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 移动通信网络的复杂性和动态性增加，准确预测关键系统参数（如CSI、用户位置和网络流量）对PHY和MAC层任务至关重要。传统深度学习方法难以泛化到不同场景和任务。

Method: 采用单变量分解统一异构任务，编码粒度以实现区间感知，使用因果Transformer主干进行预测，并引入补丁掩码策略支持任意输入长度。

Result: 在大规模数据集上训练后，模型在未见场景中表现出强泛化能力，并在新任务上实现零样本性能，超越传统全样本基线。

Conclusion: 提出的基础模型为无线网络中的多任务预测提供了一种高效且泛化能力强的解决方案。

Abstract: With the growing complexity and dynamics of the mobile communication
networks, accurately predicting key system parameters, such as channel state
information (CSI), user location, and network traffic, has become essential for
a wide range of physical (PHY)-layer and medium access control (MAC)-layer
tasks. Although traditional deep learning (DL)-based methods have been widely
applied to such prediction tasks, they often struggle to generalize across
different scenarios and tasks. In response, we propose a unified foundation
model for multi-task prediction in wireless networks that supports diverse
prediction intervals. The proposed model enforces univariate decomposition to
unify heterogeneous tasks, encodes granularity for interval awareness, and uses
a causal Transformer backbone for accurate predictions. Additionally, we
introduce a patch masking strategy during training to support arbitrary input
lengths. After trained on large-scale datasets, the proposed foundation model
demonstrates strong generalization to unseen scenarios and achieves zero-shot
performance on new tasks that surpass traditional full-shot baselines.

</details>


### [36] [Enhancing the Interpretability of Rule-based Explanations through Information Retrieval](https://arxiv.org/abs/2507.05976)
*Alessandro Umbrico,Guido Bologna,Luca Coraci,Francesca Fracasso,Silvia Gola,Gabriella Cortellessa*

Main category: cs.AI

TL;DR: 提出了一种基于属性的方法，用于提高可解释AI在乳腺癌淋巴结放疗后淋巴水肿风险评估中的透明度和可接受性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的AI技术缺乏透明度，限制了其在医疗决策中的可解释性和接受度。

Method: 通过信息检索技术对基于规则的预测模型中的属性进行统计分析，计算每个属性对预测的相关性。

Result: 用户研究表明，该方法生成的输出比原始可解释AI模型的输出更具可解释性和实用性。

Conclusion: 该方法有效提升了AI预测在医疗风险评估中的透明度和用户接受度。

Abstract: The lack of transparency of data-driven Artificial Intelligence techniques
limits their interpretability and acceptance into healthcare decision-making
processes. We propose an attribution-based approach to improve the
interpretability of Explainable AI-based predictions in the specific context of
arm lymphedema's risk assessment after lymph nodal radiotherapy in breast
cancer. The proposed method performs a statistical analysis of the attributes
in the rule-based prediction model using standard metrics from Information
Retrieval techniques. This analysis computes the relevance of each attribute to
the prediction and provides users with interpretable information about the
impact of risk factors. The results of a user study that compared the output
generated by the proposed approach with the raw output of the Explainable AI
model suggested higher levels of interpretability and usefulness in the context
of predicting lymphedema risk.

</details>


### [37] [Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening](https://arxiv.org/abs/2507.05984)
*Zhijun Guo,Alvina Lai,Julia Ive,Alexandru Petcu,Yutong Wang,Luyuan Qi,Johan H Thygesen,Kezhi Li*

Main category: cs.AI

TL;DR: HopeBot是一种基于大型语言模型的聊天机器人，用于抑郁症筛查，相比静态工具更具互动性和适应性。


<details>
  <summary>Details</summary>
Motivation: 静态工具如PHQ-9缺乏互动性和适应性，HopeBot旨在解决这一问题。

Method: 使用检索增强生成和实时澄清技术开发HopeBot，并在132名成年人中进行对比研究。

Result: HopeBot与自评版本得分高度一致（ICC=0.91），71%参与者更信任聊天机器人，87.1%愿意重复使用或推荐。

Conclusion: 语音驱动的LLM聊天机器人可作为抑郁症筛查的可扩展、低负担辅助工具。

Abstract: Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively
screen depression but lack interactivity and adaptability. We developed
HopeBot, a chatbot powered by a large language model (LLM) that administers the
PHQ-9 using retrieval-augmented generation and real-time clarification. In a
within-subject study, 132 adults in the United Kingdom and China completed both
self-administered and chatbot versions. Scores demonstrated strong agreement
(ICC = 0.91; 45% identical). Among 75 participants providing comparative
feedback, 71% reported greater trust in the chatbot, highlighting clearer
structure, interpretive guidance, and a supportive tone. Mean ratings (0-10)
were 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,
and 7.4 for recommendation helpfulness; the latter varied significantly by
employment status and prior mental-health service use (p < 0.05). Overall,
87.1% expressed willingness to reuse or recommend HopeBot. These findings
demonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden
adjuncts for routine depression screening.

</details>


### [38] [CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation](https://arxiv.org/abs/2507.06013)
*Kushal Gajjar,Harshit Sikchi,Arpit Singh Gautam,Marc Hammons,Saurabh Jha*

Main category: cs.AI

TL;DR: CogniSQL-R1-Zero是一个基于强化学习的框架，用于生成准确且可执行的SQL查询，在Text2SQL基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言转SQL（Text-to-SQL）任务中复杂查询生成的挑战，避免传统方法的中间监督和复杂奖励设计。

Method: 采用强化学习框架，使用轻量级奖励信号（执行正确性和格式标签合规性），无需中间监督或混合流程。

Result: 在BIRD基准测试中达到最先进的执行准确率，优于包括SFT CodeS-7B、DeepSeek-Coder 236B和Mistral 123B在内的基线模型。

Conclusion: 该方法展示了强化学习在Text-to-SQL任务中的高效性和可扩展性，并发布了两个数据集以支持进一步研究。

Abstract: Translating natural language into SQL (Text-to-SQL) remains a core challenge
at the intersection of language understanding and structured data access.
Although large language models (LLMs) have improved fluency, generating correct
and executable SQL, especially for complex queries, continues to be
challenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)
framework and model that produces accurate SQL using a lightweight reward
signal based on execution correctness and format-tag compliance. By avoiding
intermediate supervision, hybrid pipelines and complex reward shaping, our
method encourages stable learning and stronger alignment with the ultimate task
objective-producing executable programs. CogniSQL-R1-Zero achieves
state-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,
outperforming prior supervised and instruction-tuned baselines including SFT
CodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a
significantly smaller 7B backbone. This result underscores the scalability and
efficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs
(40 GB VRAM each). To support further research in efficient and interpretable
Text-to-SQL modeling, we release two curated datasets: (i) a collection of
5,024 reasoning traces with varying context lengths, and (ii) a
positive-sampled corpus of 36,356 corpus of weakly supervised queries, each
annotated with six semantically diverse reasoning paths. Together, these
contributions advance scalable, execution-aligned Text-to-SQL generation.

</details>


### [39] [Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions](https://arxiv.org/abs/2507.06029)
*Courtney Ford,Mark T. Keane*

Main category: cs.AI

TL;DR: FGNS方法通过结合局部和全局特征重要性选择代表性样本，显著提升了非专家用户对模型错误的识别能力，同时保持了与正确预测的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法对非专家用户生成清晰、可解释的输出存在困难。

Method: 提出Feature-Guided Neighbor Selection (FGNS)，一种后处理方法，通过局部和全局特征重要性选择类代表性样本。

Result: 在Kannada脚本分类的用户研究中，FGNS显著提升了非专家的决策速度和准确性，且选择的邻居更符合类别特征。

Conclusion: FGNS是迈向更人性化模型评估的一步，但解释质量与用户信任之间的差距仍需进一步研究。

Abstract: Explainable AI (XAI) methods often struggle to generate clear, interpretable
outputs for users without domain expertise. We introduce Feature-Guided
Neighbor Selection (FGNS), a post hoc method that enhances interpretability by
selecting class-representative examples using both local and global feature
importance. In a user study (N = 98) evaluating Kannada script classifications,
FGNS significantly improved non-experts' ability to identify model errors while
maintaining appropriate agreement with correct predictions. Participants made
faster and more accurate decisions compared to those given traditional k-NN
explanations. Quantitative analysis shows that FGNS selects neighbors that
better reflect class characteristics rather than merely minimizing
feature-space distance, leading to more consistent selection and tighter
clustering around class prototypes. These results support FGNS as a step toward
more human-aligned model assessment, although further work is needed to address
the gap between explanation quality and perceived trust.

</details>


### [40] [On Lockean beliefs that are deductively closed and minimal change](https://arxiv.org/abs/2507.06042)
*Tommaso Flaminio,Lluis Godo,Ramón Pino Pérez,Lluis Subirana*

Main category: cs.AI

TL;DR: 论文在Lockean理论框架下，通过概率描述置信度定义信念集，并解决其不闭合于经典逻辑推理的问题。提出两种闭合性表征及最小修正的信念更新方法。


<details>
  <summary>Details</summary>
Motivation: Lockean信念集在经典逻辑推理下通常不闭合，限制了其在信念变化理论等领域的应用。本文旨在解决这一问题。

Method: 提供两种闭合性表征，并提出一种最小修正的信念更新方法，以实现信念集的闭合。

Result: 展示了如何通过最小修正使信念集在经典逻辑下闭合。

Conclusion: 本文为Lockean信念集的闭合性和最小修正提供了理论支持，扩展了其应用范围。

Abstract: Within the formal setting of the Lockean thesis, an agent belief set is
defined in terms of degrees of confidence and these are described in
probabilistic terms. This approach is of established interest, notwithstanding
some limitations that make its use troublesome in some contexts, like, for
instance, in belief change theory. Precisely, Lockean belief sets are not
generally closed under (classical) logical deduction. The aim of the present
paper is twofold: on one side we provide two characterizations of those belief
sets that are closed under classical logic deduction, and on the other we
propose an approach to probabilistic update that allows us for a minimal
revision of those beliefs, i.e., a revision obtained by making the fewest
possible changes to the existing belief set while still accommodating the new
information. In particular, we show how we can deductively close a belief set
via a minimal revision.

</details>


### [41] [FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models](https://arxiv.org/abs/2507.06057)
*Bo Pang,Yalu Ouyang,Hangfei Xu,Ziqi Jia,Panpan Li,Shengzhao Wen,Lu Wang,Shiyong Li,Yanpeng Wang*

Main category: cs.AI

TL;DR: FEVO框架通过多阶段增强方法提升LLM在金融领域的性能，包括持续预训练、监督微调和强化学习，并在多个基准测试中取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究在金融领域应用LLM的进展有限，缺乏针对金融领域特定知识的系统性增强方法。

Method: FEVO框架采用持续预训练（CPT）、监督微调（SFT）和强化学习（RL）三阶段方法，结合高质量数据集FEVO-Train进行训练。

Result: FEVO-R32B在五个金融基准测试中表现最优，验证了金融知识扩展和结构化推理的有效性。

Conclusion: FEVO框架显著提升了LLM在金融领域的性能，为金融任务提供了更高效的解决方案。

Abstract: Advancements in reasoning for large language models (LLMs) have lead to
significant performance improvements for LLMs in various fields such as
mathematics and programming. However, research applying these advances to the
financial domain, where considerable domain-specific knowledge is necessary to
complete tasks, remains limited. To address this gap, we introduce FEVO
(Financial Evolution), a multi-stage enhancement framework developed to enhance
LLM performance in the financial domain. FEVO systemically enhances LLM
performance by using continued pre-training (CPT) to expand financial domain
knowledge, supervised fine-tuning (SFT) to instill structured, elaborate
reasoning patterns, and reinforcement learning (RL) to further integrate the
expanded financial domain knowledge with the learned structured reasoning. To
ensure effective and efficient training, we leverage frontier reasoning models
and rule-based filtering to curate FEVO-Train, high-quality datasets
specifically designed for the different post-training phases. Using our
framework, we train the FEVO series of models -- C32B, S32B, R32B -- from
Qwen2.5-32B and evaluate them on seven benchmarks to assess financial and
general capabilities, with results showing that FEVO-R32B achieves
state-of-the-art performance on five financial benchmarks against much larger
models as well as specialist models. More significantly, FEVO-R32B demonstrates
markedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct
using only RL), thus validating the effectiveness of financial domain knowledge
expansion and structured, logical reasoning distillation

</details>


### [42] [AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study](https://arxiv.org/abs/2507.06077)
*Iman Rahimi,Isha Patel*

Main category: cs.AI

TL;DR: 论文提出了一种结合LSTM、遗传算法和SHAP的AI框架，用于提升医疗设施的能源管理效率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 医疗设施能源需求波动大，传统方法效率低下且成本高，亟需更高效的解决方案。

Method: 采用LSTM进行时间序列预测，结合遗传算法优化参数和负载均衡策略，并通过SHAP增强模型可解释性。

Result: LSTM在预测复杂非线性需求时表现优异（MAE: 21.69, RMSE: 29.96），远超Prophet和ARIMA。

Conclusion: 该框架为医疗能源管理提供了高效、透明且可扩展的解决方案，未来可进一步探索实时部署和强化学习结合。

Abstract: This paper tackles the urgent need for efficient energy management in
healthcare facilities, where fluctuating demands challenge operational
efficiency and sustainability. Traditional methods often prove inadequate,
causing inefficiencies and higher costs. To address this, the study presents an
AI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm
(GA), and SHAP (Shapley Additive Explanations), specifically designed for
healthcare energy management. Although LSTM is widely used for time-series
forecasting, its application in healthcare energy prediction remains
underexplored. The results reveal that LSTM significantly outperforms ARIMA and
Prophet models in forecasting complex, non-linear demand patterns. LSTM
achieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)
of 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:
87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm
is applied to optimize model parameters and improve load balancing strategies,
enabling adaptive responses to real-time energy fluctuations. SHAP analysis
further enhances model transparency by explaining the influence of different
features on predictions, fostering trust in decision-making processes. This
integrated LSTM-GA-SHAP approach offers a robust solution for improving
forecasting accuracy, boosting energy efficiency, and advancing sustainability
in healthcare facilities. Future research may explore real-time deployment and
hybridization with reinforcement learning for continuous optimization. Overall,
the study establishes a solid foundation for using AI in healthcare energy
management, highlighting its scalability, efficiency, and resilience potential.

</details>


### [43] [OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety](https://arxiv.org/abs/2507.06134)
*Sanidhya Vijayvargiya,Aditya Bharat Soni,Xuhui Zhou,Zora Zhiruo Wang,Nouha Dziri,Graham Neubig,Maarten Sap*

Main category: cs.AI

TL;DR: OpenAgentSafety是一个模块化框架，用于评估AI代理在真实工具环境中的安全性，涵盖八类风险，支持多任务和多用户场景，结合规则分析和LLM评估，发现多个LLM存在显著安全隐患。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理安全性评估多依赖模拟环境或狭窄任务域，无法全面反映真实风险，因此需要更全面的评估框架。

Method: 提出OpenAgentSafety框架，支持真实工具交互（如浏览器、代码执行环境等），涵盖350多项任务，结合规则和LLM评估。

Result: 实验显示，多个LLM在安全脆弱任务中表现出不安全行为，比例从51.2%到72.7%。

Conclusion: OpenAgentSafety揭示了AI代理的安全漏洞，强调实际部署前需更强保障措施。

Abstract: Recent advances in AI agents capable of solving complex, everyday tasks, from
scheduling to customer service, have enabled deployment in real-world settings,
but their possibilities for unsafe behavior demands rigorous evaluation. While
prior benchmarks have attempted to assess agent safety, most fall short by
relying on simulated environments, narrow task domains, or unrealistic tool
abstractions. We introduce OpenAgentSafety, a comprehensive and modular
framework for evaluating agent behavior across eight critical risk categories.
Unlike prior work, our framework evaluates agents that interact with real
tools, including web browsers, code execution environments, file systems, bash
shells, and messaging platforms; and supports over 350 multi-turn, multi-user
tasks spanning both benign and adversarial user intents. OpenAgentSafety is
designed for extensibility, allowing researchers to add tools, tasks, websites,
and adversarial strategies with minimal effort. It combines rule-based analysis
with LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.
Empirical analysis of five prominent LLMs in agentic scenarios reveals unsafe
behavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%
with o3-mini, highlighting critical safety vulnerabilities and the need for
stronger safeguards before real-world deployment.

</details>


### [44] [The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains](https://arxiv.org/abs/2507.06187)
*Scott Geng,Hamish Ivison,Chun-Liang Li,Maarten Sap,Jerry Li,Ranjay Krishna,Pang Wei Koh*

Main category: cs.AI

TL;DR: 通过配对偏好数据（即使单个数据点较弱）可以提升语言模型性能，提出delta学习假设，验证其有效性，并在实验中匹配了先进模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在强监督数据稀缺时，如何利用弱数据点提升模型性能是一个挑战。

Method: 提出delta学习假设，利用配对偏好数据的相对质量差异进行训练，并通过实验验证。

Result: 在11个基准测试中，该方法匹配了先进模型Tulu 3的性能，且成本更低。

Conclusion: delta学习为利用弱数据提升模型性能提供了简单且经济的方法。

Abstract: Improvements in language models are often driven by improving the quality of
the data we train them on, which can be limiting when strong supervision is
scarce. In this work, we show that paired preference data consisting of
individually weak data points can enable gains beyond the strength of each
individual data point. We formulate the delta learning hypothesis to explain
this phenomenon, positing that the relative quality delta between points
suffices to drive learning via preference tuning--even when supervised
finetuning on the weak data hurts. We validate our hypothesis in controlled
experiments and at scale, where we post-train 8B models on preference data
generated by pairing a small 3B model's responses with outputs from an even
smaller 1.5B model to create a meaningful delta. Strikingly, on a standard
11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the
performance of Tulu 3, a state-of-the-art open model tuned from the same base
model while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta
learning enables simpler and cheaper open recipes for state-of-the-art
post-training. To better understand delta learning, we prove in logistic
regression that the performance gap between two weak teacher models provides
useful signal for improving a stronger student. Overall, our work shows that
models can learn surprisingly well from paired data that might typically be
considered weak.

</details>


### [45] [Identifiability in Causal Abstractions: A Hierarchy of Criteria](https://arxiv.org/abs/2507.06213)
*Clément Yvernes,Emilie Devijver,Marianne Clausel,Eric Gaussier*

Main category: cs.AI

TL;DR: 论文探讨了在观测数据中识别处理效应时因果图的不确定性，提出了一种基于因果抽象的方法，并构建了可识别性标准的层次结构。


<details>
  <summary>Details</summary>
Motivation: 在复杂或高维环境中，完整的因果图通常未知，限制了处理效应的识别。因果抽象作为一种简化表示方法，可以部分保留因果信息。

Method: 研究将因果抽象形式化为因果图的集合，并提出了几种可识别性标准，构建了这些标准的层次结构。

Result: 通过层次结构明确了不同因果知识水平下的可识别性，并提供了工具来推理在缺乏完整因果知识时的可识别性。

Conclusion: 该框架为在因果图不确定的情况下识别处理效应提供了新的视角和方法。

Abstract: Identifying the effect of a treatment from observational data typically
requires assuming a fully specified causal diagram. However, such diagrams are
rarely known in practice, especially in complex or high-dimensional settings.
To overcome this limitation, recent works have explored the use of causal
abstractions-simplified representations that retain partial causal information.
In this paper, we consider causal abstractions formalized as collections of
causal diagrams, and focus on the identifiability of causal queries within such
collections. We introduce and formalize several identifiability criteria under
this setting. Our main contribution is to organize these criteria into a
structured hierarchy, highlighting their relationships. This hierarchical view
enables a clearer understanding of what can be identified under varying levels
of causal knowledge. We illustrate our framework through examples from the
literature and provide tools to reason about identifiability when full causal
knowledge is unavailable.

</details>


### [46] [Aligned Textual Scoring Rules](https://arxiv.org/abs/2507.06221)
*Yuxuan Lu,Yifan Wu,Jason Hartline,Michael J. Curry*

Main category: cs.AI

TL;DR: 本文提出了一种对齐评分规则（ASR），通过优化与参考分数（如人类评分）的均方误差，解决了文本信息激发中评分规则与人类偏好不一致的问题，同时保持了评分规则的正确性。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型的发展，现有的评分规则虽然在数值信息激发中具有正确性，但在文本信息激发中与人类偏好不一致。本文旨在设计一种既能保持正确性又能与人类偏好对齐的评分规则。

Method: 设计了Aligned Scoring Rule（ASR），通过优化和最小化一个正确评分规则与参考分数（如人类评分）之间的均方误差。

Result: 实验表明，ASR在保持评分规则正确性的同时，优于之前的方法，更符合人类偏好。

Conclusion: ASR是一种有效的评分规则，能够在文本信息激发中同时满足正确性和人类偏好对齐的需求。

Abstract: Scoring rules elicit probabilistic predictions from a strategic agent by
scoring the prediction against a ground truth state. A scoring rule is proper
if, from the agent's perspective, reporting the true belief maximizes the
expected score. With the development of language models, Wu and Hartline (2024)
proposes a reduction from textual information elicitation to the numerical
(i.e. probabilistic) information elicitation problem, which achieves provable
properness for textual elicitation. However, not all proper scoring rules are
well aligned with human preference over text. Our paper designs the Aligned
Scoring rule (ASR) for text by optimizing and minimizing the mean squared error
between a proper scoring rule and a reference score (e.g. human score). Our
experiments show that our ASR outperforms previous methods in aligning with
human preference while maintaining properness.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [47] [Lower Bounds for Error Coefficients of Griesmer Optimal Linear Codes via Iteration](https://arxiv.org/abs/2507.05567)
*Chaofeng Guan,Shitao Li,Gaojun Luo,Zhi Ma,Hong Wang*

Main category: cs.IT

TL;DR: 本文提出了几种迭代下界方法，用于估计Griesmer最优线性码的错误系数，并在大多数维度不超过5的二进制线性码中实现了紧致性。


<details>
  <summary>Details</summary>
Motivation: 在加性高斯白噪声信道中，具有最小错误系数的最优线性码在最大似然解码下能达到最佳渐近帧错误率（AFER）。然而，确定Griesmer最优线性码的错误系数的紧致下界具有挑战性。

Method: 提出了几种迭代下界方法，特别针对二进制线性码，在维度不超过5时大多数情况下实现了紧致性。

Result: 对于维度不超过5的二进制线性码，提出的下界在大多数情况下是紧致的；对于不紧致的情况，与实际值的差距不超过2。

Conclusion: 提出的下界方法在大多数情况下表现优异，即使在不紧致时也接近实际值，验证了其有效性。

Abstract: The error coefficient of a linear code is defined as the number of
minimum-weight codewords. In an additive white Gaussian noise channel, optimal
linear codes with the smallest error coefficients achieve the best possible
asymptotic frame error rate (AFER) among all optimal linear codes under maximum
likelihood decoding. Such codes are referred to as AFER-optimal linear codes.
  The Griesmer bound is essential for determining the optimality of linear
codes. However, establishing tight lower bounds on the error coefficients of
Griesmer optimal linear codes is challenging, and the linear programming bound
often performs inadequately. In this paper, we propose several iterative lower
bounds for the error coefficients of Griesmer optimal linear codes.
Specifically, for binary linear codes, our bounds are tight in most cases when
the dimension does not exceed $5$. To evaluate the performance of our bounds
when they are not tight, we also determine the parameters of the remaining
5-dimensional AFER-optimal linear codes. Our final comparison demonstrates that
even when our bounds are not tight, they remain very close to the actual
values, with a gap of less than or equal to $2$.

</details>


### [48] [Cooperative Mapping, Localization, and Beam Management via Multi-Modal SLAM in ISAC Systems](https://arxiv.org/abs/2507.05718)
*Hang Que,Jie Yang,Tao Du,Shuqiang Xia,Chao-Kai Wen,Shi Jin*

Main category: cs.IT

TL;DR: 本文提出了一种多模态SLAM框架，通过贝叶斯估计、多模态定位策略和感知辅助波束管理，显著提升了6G毫米波网络中的定位和通信性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态ISAC系统中协同多用户SLAM的理论建模和通信层集成不足的问题。

Method: 1. 开发贝叶斯估计框架和两阶段算法；2. 引入多模态定位策略；3. 提出感知辅助波束管理方案。

Result: 仿真结果显示，系统在无线电地图精度上提升60%，定位精度提升37.5%，显著优于传统方法。

Conclusion: 该框架在多用户场景中有效提升了环境感知和通信效率。

Abstract: Simultaneous localization and mapping (SLAM) plays a critical role in
integrated sensing and communication (ISAC) systems for sixth-generation (6G)
millimeter-wave (mmWave) networks, enabling environmental awareness and precise
user equipment (UE) positioning. While cooperative multi-user SLAM has
demonstrated potential in leveraging distributed sensing, its application
within multi-modal ISAC systems remains limited, particularly in terms of
theoretical modeling and communication-layer integration. This paper proposes a
novel multi-modal SLAM framework that addresses these limitations through three
key contributions. First, a Bayesian estimation framework is developed for
cooperative multi-user SLAM, along with a two-stage algorithm for robust radio
map construction under dynamic and heterogeneous sensing conditions. Second, a
multi-modal localization strategy is introduced, fusing SLAM results with
camera-based multi-object tracking and inertial measurement unit (IMU) data via
an error-aware model, significantly improving UE localization in multi-user
scenarios. Third, a sensing-aided beam management scheme is proposed, utilizing
global radio maps and localization data to generate UE-specific prior
information for beam selection, thereby reducing inter-user interference and
enhancing downlink spectral efficiency. Simulation results demonstrate that the
proposed system improves radio map accuracy by up to 60%, enhances localization
accuracy by 37.5%, and significantly outperforms traditional methods in both
indoor and outdoor environments.

</details>


### [49] [Text-Guided Token Communication for Wireless Image Transmission](https://arxiv.org/abs/2507.05781)
*Bole Liu,Li Qiao,Ye Wang,Zhen Gao,Yu Ma,Keke Ying,Tong Qin*

Main category: cs.IT

TL;DR: 提出了一种基于预训练基础模型的文本引导令牌通信系统，用于低带宽下的无线图像传输，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络和视觉应用的普及，恶劣信道条件下的高效图像传输变得至关重要。

Method: 将图像转换为离散令牌，应用5G NR极性编码，并利用文本引导令牌预测进行重建。

Result: 在ImageNet上评估，该方法在SNR高于0 dB时在感知质量和语义保留上优于ADJSCC，并在低SNR下缓解了悬崖效应。

Conclusion: 无需场景特定重训练，具有优越的跨数据集泛化能力，为高效图像传输建立了新范式。

Abstract: With the emergence of 6G networks and proliferation of visual applications,
efficient image transmission under adverse channel conditions is critical. We
present a text-guided token communication system leveraging pre-trained
foundation models for wireless image transmission with low bandwidth. Our
approach converts images to discrete tokens, applies 5G NR polar coding, and
employs text-guided token prediction for reconstruction. Evaluations on
ImageNet show our method outperforms Deep Source Channel Coding with Attention
Modules (ADJSCC) in perceptual quality and semantic preservation at
Signal-to-Noise Ratios (SNRs) above 0 dB while mitigating the cliff effect at
lower SNRs. Our system requires no scenario-specific retraining and exhibits
superior cross-dataset generalization, establishing a new paradigm for
efficient image transmission aligned with human perceptual priorities.

</details>


### [50] [Does Movable Antenna Present A Dual-edged Nature? From the Perspective of Physical Layer Security: A Joint Design of Fixed-position Antenna and Movable Antenna](https://arxiv.org/abs/2507.05784)
*Kan Yu,Wenxu Wang,Xiaowu Liu,Yujia Zhao,Qixun Zhang,Zhiyong Feng,Dong Li*

Main category: cs.IT

TL;DR: 提出了一种混合天线部署框架（FMA co-design），结合固定位置天线（FPA）和可移动天线（MA）阵列，以提升动态无线环境中的物理层安全性能。通过优化MA位置和波束成形，显著提高了保密率。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线阵列在物理层安全系统中存在覆盖漏洞，易被移动窃听者利用。为解决这一问题，研究结合FPA和MA的混合部署框架。

Method: 提出FMA co-design框架，联合优化MA位置、FPA波束成形和MA波束成形，采用NMPGA和AO算法求解非凸优化问题。

Result: 实验表明，FMA co-design框架显著提升了保密性能，保密率分别比单独使用FPA和MA提高了42.34%和9.12%。

Conclusion: FMA co-design框架有效解决了传统静态天线阵列的安全漏洞，为动态无线环境提供了更高的安全性和灵活性。

Abstract: In conventional artificial noise (AN)-aided physical-layer security systems,
fixed-position antenna (FPA) arrays exhibit inherent vulnerability to coverage
gaps due to their static spatial configuration. Adversarial eavesdroppers can
strategically exploit their mobility to infiltrate these spatial nulls of AN
radiation patterns, thereby evading interference suppression and successfully
intercepting the confidential communication. To overcome this limitation, in
this paper, we investigate a hybrid antenna deployment framework integrating
FPA arrays and movable antenna (MA) arrays (denoted by FMA co-design) to
address the security performance in dynamic wireless environments, based on the
fact that MA arrays enable channel reconfiguration through localized antenna
repositioning, achieving more higher spatial degree of freedom (DoF). Enabled
by FMA co-design framework, FPA arrays ensure baseline connectivity for
legitimate links while MA arrays function as dynamic security enhancers,
replacing conventional static AN generation. Furthermore, we formulate a
non-convex optimization problem of the secrecy rate maximization through
jointly optimizing MA positioning, FPA beamforming, and MA beamforming under
practical constraints. the solution employs a dual-algorithm approach: Nesterov
momentum-based projected gradient ascent (NMPGA) accelerates convergence in
continuous position optimization, while alternating optimization (AO) handles
coupled beamforming design. Experimental evaluations demonstrate that the
proposed FMA co-design framework achieves significant secrecy performance gains
over individual optimization benchmarks, yielding 42.34% and 9.12% improvements
in secrecy rate compared to isolated FPA for AN generation and MA for
confidential information baselines, respectively.

</details>


### [51] [Adaptive Communication Through Exploiting RIS, SSK, and CIM for Improved Reliability and Efficiency](https://arxiv.org/abs/2507.05813)
*Ferhat Bayar,Onur Salan,Erdogan Aydin,Haci Ilhan*

Main category: cs.IT

TL;DR: 提出了一种基于RIS、SSK和CIM的新型通信系统模型RIS-CIM-TSSK，通过RIS动态适应环境，提升能效和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决现代无线网络中动态环境适应性和能效问题，同时降低系统复杂度。

Method: 结合RIS、SSK和CIM技术，利用Hadamard编码实现被动信息传输，提出低复杂度检测器。

Result: 仿真结果表明，系统在不同配置下表现良好，提升了能效和通信可靠性。

Conclusion: RIS-CIM-TSSK为现代无线网络提供了一种高效、可靠的通信解决方案。

Abstract: In this paper, we present a novel communication system model that integrates
reconfigurable intelligent surfaces (RIS), spatial shift keying (SSK), and code
index modulation (CIM) based on Hadamard coding called RIS based transmit
SSK-CIM (RIS-CIM-TSSK). By leveraging RIS, the system adapts rapidly to dynamic
environments, enhancing error rates and overall reliability. SSK facilitates
the transmission of additional passive information while eliminating the need
for multiple radio frequency (RF) chains, thereby reducing complexity. CIM
enhances passive information transmission through frequency domain spreading,
which may increase signal obfuscation. This proposed scheme not only improves
energy efficiency but also offers a robust solution for reliable communication
in modern wireless networks, paving the way for smarter and more adaptable
implementations. We consider a suboptimal, low-complexity detector for the
proposed scheme and also address the blind case for phase adjustment of the
RIS. Finally, we present the simulation results for the proposed system model
across various configurations, including different numbers of receive and
transmit antennas, varying reflecting elements of the RIS, and different code
lengths.

</details>


### [52] [An Effective Equivalence Model of Analyzing PLS of Multiple Eavesdroppers Facing Low-altitude Communication Systems](https://arxiv.org/abs/2507.05878)
*Yujia Zhao,Zhiyong Feng,Kan Yu,Qixun Zhang,Dong Li*

Main category: cs.IT

TL;DR: 论文提出了一种基于可移动天线（MAs）的物理层安全（PLS）等效模型，以解决固定位置天线（FPAs）在低空无线通信中的局限性，并通过优化问题最小化保密率差距。


<details>
  <summary>Details</summary>
Motivation: 低空无线通信中，无线信道的复杂性和窃听者（Eves）的不确定性对基于FPAs的PLS技术提出了挑战，尤其是在波束成形和空间效率方面。MAs的灵活性为信道重构提供了解决方案。

Method: 构建了一个等效模型，将多个Eves的保密率与单个虚拟Eve（配备MA阵列）的保密率等同，并通过优化等效距离和MA位置来最小化保密率差距。

Result: 数值模拟验证了等效模型的有效性，为PLS策略提供了新视角。

Conclusion: 该研究为网络设计者提供了系统参数如何影响PLS性能的重要见解。

Abstract: In low-altitude wireless communications, the increased complexity of wireless
channels and the uncertainty of eavesdroppers (Eves)--caused by diverse
altitudes, speeds, and obstacles--pose significant challenges to physical layer
security (PLS) technologies based on fixed-position antennas (FPAs),
particularly in terms of beamforming capabilities and spatial efficiency. In
contrast, movable antennas (MAs) offer a flexible solution by enabling channel
reconstruction through antenna movement, effectively compensating for the
limitations of FPAs. In this paper, we aim to derive a closed-form expression
for the secrecy rate, a key metric in PLS, which is often unattainable in
current studies due to the uncertainty of Eves. We construct an equivalent
model that leverages the reconfigurable nature of MAs, equating the secrecy
rates obtained by multiple Eves with single FPAs to those achieved by a single
virtual Eve equipped with an MA array. To minimize the gap between these two
types of secrecy rates, we formulate and solve an optimization problem by
jointly designing the equivalent distance between the transmitter and the
virtual Eve} and the antenna positions of MAs at the virtual Eve. Numerical
simulations validate the effectiveness of the proposed equivalent model,
offering a new perspective for PLS strategies. This work provides significant
insights for network designers on how system parameters affect PLS performance.

</details>
