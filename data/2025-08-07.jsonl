{"id": "2508.03938", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.03938", "abs": "https://arxiv.org/abs/2508.03938", "authors": ["Junsheng Liu", "Netanel Raviv"], "title": "Single Fragment Forensic Coding from Discrepancy Theory", "comment": null, "summary": "Three-dimensional (3D) printing's accessibility enables rapid manufacturing\nbut also poses security risks, such as the unauthorized production of\nuntraceable firearms and prohibited items. To ensure traceability and\naccountability, embedding unique identifiers within printed objects is\nessential, in order to assist forensic investigation of illicit use. This paper\nmodels data embedding in 3D printing using principles from error-correcting\ncodes, aiming to recover embedded information from partial or altered fragments\nof the object. Previous works embedded one-dimensional data (i.e., a vector)\ninside the object, and required almost all fragments of the object for\nsuccessful decoding. In this work, we study a problem setting in which only one\nsufficiently large fragment of the object is available for decoding. We first\nshow that for one-dimensional embedded information the problem can be easily\nsolved using existing tools. Then, we introduce novel encoding schemes for\ntwo-dimensional information (i.e., a matrix), and three-dimensional information\n(i.e., a cube) which enable the information to be decoded from any sufficiently\nlarge rectangle-shaped or cuboid-shaped fragment. Lastly, we introduce a code\nthat is also capable of correcting bit-flip errors, using techniques from\nrecently proposed codes for DNA storage. Our codes operate at non-vanishing\nrates, and involve concepts from discrepancy theory called Van der Corput sets\nand Halton-Hammersely sets in novel ways."}
{"id": "2508.04262", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.04262", "abs": "https://arxiv.org/abs/2508.04262", "authors": ["Usman Mushrraf", "Ferdinando Zullo"], "title": "One-weight codes in the sum-rank metric", "comment": null, "summary": "One-weight codes, in which all nonzero codewords share the same weight, form\na highly structured class of linear codes with deep connections to finite\ngeometry. While their classification is well understood in the Hamming and rank\nmetrics - being equivalent to (direct sums of) simplex codes - the sum-rank\nmetric presents a far more intricate landscape. In this work, we explore the\ngeometry of one-weight sum-rank metric codes, focusing on three distinct\nclasses. First, we introduce and classify \\emph{constant rank-list} sum-rank\ncodes, where each nonzero codeword has the same tuple of ranks, extending\nresults from the rank-metric setting. Next, we investigate the more general\n\\emph{constant rank-profile} codes, where, up to reordering, each nonzero\ncodeword has the same tuple of ranks. Although a complete classification\nremains elusive, we present the first examples and partial structural results\nfor this class. Finally, we consider one-weight codes that are also MSRD\n(Maximum Sum-Rank Distance) codes. For dimension two, constructions arise from\npartitions of scattered linear sets on projective lines. For dimension three,\nwe connect their existence to that of special $2$-fold blocking sets in the\nprojective plane, leading to new bounds and nonexistence results over certain\nfields."}
{"id": "2508.04313", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.04313", "abs": "https://arxiv.org/abs/2508.04313", "authors": ["Dominik Semmler", "Wolfgang Utschick", "Michael Joham"], "title": "Is Lattice Reduction Necessary for Vector Perturbation Precoding?", "comment": null, "summary": "Vector perturbation (VP) precoding is an effective nonlinear precoding\ntechnique in the downlink (DL) with modulo channels. Especially, when combined\nwith Lattice reduction (LR), low-complexity algorithms achieve very promising\nperformances, outperforming other popular nonlinear precoding techniques like\nTomlinson-Harashima precoding (THP). However, these results are based on the\nuncoded symbol error rate (SER) or uncoded bit error rate (BER). We show that\nwhen using the mutual information as the figure of merit, the observation is\nfundamentally different and that these algorithms generally do not outperform\nTHP. Within the expression of the mutual information, a rate allocation matrix\ncan be incorporated, which has not received much attention so far. In this\narticle, we derive the optimal choice of this matrix for different algorithms,\nand we show that this matrix is indeed crucial for the performance, especially\nfor ill-conditioned channels. Furthermore, when using an optimized choice of\nthis matrix, we show that the classical LR-aided algorithms cannot exceed the\nrate of THP, highlighting the effectiveness of the THP method. This concept can\nbe generalized to a whole class of algorithms for which LR yields no\nimprovement. We derive the corresponding properties and categorize various\nalgorithms accordingly."}
{"id": "2508.04340", "categories": ["cs.IT", "cs.CR", "math.AG", "math.IT", "14H05, 94B27, 11T71"], "pdf": "https://arxiv.org/pdf/2508.04340", "abs": "https://arxiv.org/abs/2508.04340", "authors": ["Artyom Kuninets", "Ekaterina Malygina"], "title": "Bases of Riemann-Roch spaces associated with arbitrary elliptic curve divisors and their application in constructing various elliptic Codes families", "comment": null, "summary": "In this paper, we determine explicit bases for Riemann--Roch spaces\nassociated with various families of elliptic codes. We establish the\nfeasibility and provide exact algorithms for constructing bases of\nRiemann--Roch spaces corresponding to arbitrary divisors on elliptic curves.\nThese results are subsequently applied to derive bases for quasi-cyclic\nelliptic codes and their subfield subcodes as well as for the class of\nGoppa-like elliptic codes. For algebraic geometry code applications, having an\nexplicit description of Riemann--Roch space bases for arbitrary divisors is\nparticularly valuable as it simultaneously enables efficient code construction\nand reveals structural properties of the codes leading to the new cryptanalysis\nmethods when these codes are employed in cryptographic schemes"}
{"id": "2508.03858", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.03858", "abs": "https://arxiv.org/abs/2508.03858", "authors": ["Charles L. Wang", "Trisha Singhal", "Ameya Kelkar", "Jason Tuo"], "title": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems", "comment": null, "summary": "Agentic AI systems capable of reasoning, planning, and executing actions\npresent fundamentally distinct governance challenges compared to traditional AI\nmodels. Unlike conventional AI, these systems exhibit emergent and unexpected\nbehaviors during runtime, introducing novel agent-related risks that cannot be\nfully anticipated through pre-deployment governance alone. To address this\ncritical gap, we introduce MI9, the first fully integrated runtime governance\nframework designed specifically for safety and alignment of agentic AI systems.\nMI9 introduces real-time controls through six integrated components:\nagency-risk index, agent-semantic telemetry capture, continuous authorization\nmonitoring, Finite-State-Machine (FSM)-based conformance engines,\ngoal-conditioned drift detection, and graduated containment strategies.\nOperating transparently across heterogeneous agent architectures, MI9 enables\nthe systematic, safe, and responsible deployment of agentic systems in\nproduction environments where conventional governance approaches fall short,\nproviding the foundational infrastructure for safe agentic AI deployment at\nscale. Detailed analysis through a diverse set of scenarios demonstrates MI9's\nsystematic coverage of governance challenges that existing approaches fail to\naddress, establishing the technical foundation for comprehensive agentic AI\noversight."}
{"id": "2508.03862", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03862", "abs": "https://arxiv.org/abs/2508.03862", "authors": ["Abdul Saboor", "Zhuangzhuang Cui", "Achiel Colpaert", "Evgenii Vinogradov", "Sofie Pollin"], "title": "CASH: Context-Aware Smart Handover for Reliable UAV Connectivity on Aerial Corridors", "comment": "Accepted at IEEE Globecom 2025", "summary": "Urban Air Mobility (UAM) envisions aerial corridors for Unmanned Aerial\nVehicles (UAVs) to reduce ground traffic congestion by supporting 3D mobility,\nsuch as air taxis. A key challenge in these high-mobility aerial corridors is\nensuring reliable connectivity, where frequent handovers can degrade network\nperformance. To resolve this, we present a Context-Aware Smart Handover (CASH)\nprotocol that uses a forward-looking scoring mechanism based on UAV trajectory\nto make proactive handover decisions. We evaluate the performance of the\nproposed CASH against existing handover protocols in a custom-built simulator.\nResults show that CASH reduces handover frequency by up to 78% while\nmaintaining low outage probability. We then investigate the impact of base\nstation density and safety margin on handover performance, where their optimal\nsetups are empirically obtained to ensure reliable UAM communication."}
{"id": "2508.04355", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.04355", "abs": "https://arxiv.org/abs/2508.04355", "authors": ["Hao Shi", "Zhengyi Jiang", "Zhongyi Huang", "Bo Bai", "Gong Zhang", "Hanxu Hou"], "title": "Grid-like Error-Correcting Codes for Matrix Multiplication with Better Correcting Capability", "comment": null, "summary": "Matrix multiplication over the real field constitutes a foundational\noperation in the training of deep learning models, serving as a computational\ncornerstone for both forward and backward propagation processes. However, the\npresence of silent data corruption (SDC) in large-scale distributed training\nenvironments poses a significant threat to model convergence and predictive\naccuracy, particularly when such errors manifest during matrix multiplication.\nDue to their transient and non-intrusive nature, these errors often evade\ndetection, allowing them to propagate and accumulate over time, ultimately\nleading to substantial degradation in model performance. In this paper, we\nintroduce a novel error-correcting coding framework specifically tailored for\nmatrix multiplication operations. Our proposed framework is designed to detect\nand correct multiple computational errors that may arise during the execution\nof matrix products. By leveraging a grid-based structural encoding scheme, our\napproach enhances error localization and correction capabilities across all\nparticipating matrices, thereby significantly improving the fault tolerance of\nthe computation. Experimental results demonstrate that our method achieves\ndeterministic correction of up to two erroneous symbols distributed across\nthree matrices with 100\\% reliability, while incurring only a 24\\% overhead in\ncomputational time on GPU architectures. Furthermore, we provide a rigorous\ntheoretical analysis of the error-correction properties inherent to our coding\nscheme, establishing its correctness and robustness under well-defined fault\nmodels."}
{"id": "2508.03864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03864", "abs": "https://arxiv.org/abs/2508.03864", "authors": ["Zhenyu Pan", "Yiting Zhang", "Yutong Zhang", "Jianshu Zhang", "Haozheng Luo", "Yuwei Han", "Dennis Wu", "Hong-Yu Chen", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety", "comment": null, "summary": "Multi-agent systems (MAS) built on multimodal large language models exhibit\nstrong collaboration and performance. However, their growing openness and\ninteraction complexity pose serious risks, notably jailbreak and adversarial\nattacks. Existing defenses typically rely on external guard modules, such as\ndedicated safety agents, to handle unsafe behaviors. Unfortunately, this\nparadigm faces two challenges: (1) standalone agents offer limited protection,\nand (2) their independence leads to single-point failure-if compromised,\nsystem-wide safety collapses. Naively increasing the number of guard agents\nfurther raises cost and complexity. To address these challenges, we propose\nEvo-MARL, a novel multi-agent reinforcement learning (MARL) framework that\nenables all task agents to jointly acquire defensive capabilities. Rather than\nrelying on external safety modules, Evo-MARL trains each agent to\nsimultaneously perform its primary function and resist adversarial threats,\nensuring robustness without increasing system overhead or single-node failure.\nFurthermore, Evo-MARL integrates evolutionary search with parameter-sharing\nreinforcement learning to co-evolve attackers and defenders. This adversarial\ntraining paradigm internalizes safety mechanisms and continually enhances MAS\nperformance under co-evolving threats. Experiments show that Evo-MARL reduces\nattack success rates by up to 22% while boosting accuracy by up to 5% on\nreasoning tasks-demonstrating that safety and utility can be jointly improved."}
{"id": "2508.03891", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.03891", "abs": "https://arxiv.org/abs/2508.03891", "authors": ["Eun Hun Choi", "Jasleen Kaur", "Vladas Pipiras", "Nelson Gomes Rodrigues Antunes", "Brendan Massey"], "title": "Confidence Driven Classification of Application Types in the Presence of Background Network", "comment": "10 pages", "summary": "Accurately classifying the application types of network traffic using deep\nlearning models has recently gained popularity. However, we find that these\nclassifiers do not perform well on real-world traffic data due to the presence\nof non-application-specific generic background traffic originating from\nadvertisements, analytics, shared APIs, and trackers. Unfortunately,\nstate-of-the-art application classifiers overlook such traffic in curated\ndatasets and only classify relevant application traffic. To address this issue,\nwhen we label and train using an additional class for background traffic, it\nleads to additional confusion between application and background traffic, as\nthe latter is heterogeneous and encompasses all traffic that is not relevant to\nthe application sessions. To avoid falsely classifying background traffic as\none of the relevant application types, a reliable confidence measure is\nwarranted, such that we can refrain from classifying uncertain samples.\nTherefore, we design a Gaussian Mixture Model-based classification framework\nthat improves the indication of the deep learning classifier's confidence to\nallow more reliable classification."}
{"id": "2508.04466", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.04466", "abs": "https://arxiv.org/abs/2508.04466", "authors": ["Dongliang Jing", "Linjuan Li", "Lin Lin", "Andrew W. Eckford"], "title": "Tradeoff Between the Number of Transmitted Molecules and the BER Performance in Molecular Communication between Bionanosensors", "comment": "Accepted for publication in IEEE Sensors Journal", "summary": "In the domain of molecular communication (MC), information is conveyed\nthrough the characteristics of molecules transmitted between the transmitter\nand the receiver bionanosensors via propagation. The constrained size of the\ntransmitter imposes limitations on its storage capacity, constraining the\nnumber of available molecules for transmission, with a resulting effect on\ncommunication reliability. This paper primarily focuses on achieving an\nequilibrium between the number of transmitted molecules and the bit error rate\n(BER) performance. To this end, we first analyze the relationship between the\nnumber of transmitted molecules and the BER performance. Subsequently, a\nbalancing function that considers both the number of transmitted molecules and\nthe BER performance is introduced, taking into account the molecules'\nrespective weights. Given the difference in magnitude between the number of\ntransmitted molecules and the BER, these parameters are normalized to\nfacilitate analysis. Subsequently, a Gradient Descent Algorithm is employed to\ndetermine the optimal number of transmitted molecules, aiming to achieve the\noptimal equilibrium in the analyzed MC system. Theoretical and simulation\nresults are provided, substantiating that the optimal outcome indeed\nestablishes an ideal balance between the number of transmitted molecules and\nthe BER."}
{"id": "2508.03929", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03929", "abs": "https://arxiv.org/abs/2508.03929", "authors": ["Nguyen Viet Tuan Kiet", "Dao Van Tung", "Tran Cong Dao", "Huynh Thi Thanh Binh"], "title": "MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework", "comment": "24 pages, 4 figures", "summary": "Designing effective algorithmic components remains a fundamental obstacle in\ntackling NP-hard combinatorial optimization problems (COPs), where solvers\noften rely on carefully hand-crafted strategies. Despite recent advances in\nusing large language models (LLMs) to synthesize high-quality components, most\napproaches restrict the search to a single element - commonly a heuristic\nscoring function - thus missing broader opportunities for innovation. In this\npaper, we introduce a broader formulation of solver design as a multi-strategy\noptimization problem, which seeks to jointly improve a set of interdependent\ncomponents under a unified objective. To address this, we propose\nMulti-strategy Optimization via Turn-based Interactive Framework (MOTIF) - a\nnovel framework based on Monte Carlo Tree Search that facilitates turn-based\noptimization between two LLM agents. At each turn, an agent improves one\ncomponent by leveraging the history of both its own and its opponent's prior\nupdates, promoting both competitive pressure and emergent cooperation. This\nstructured interaction broadens the search landscape and encourages the\ndiscovery of diverse, high-performing solutions. Experiments across multiple\nCOP domains show that MOTIF consistently outperforms state-of-the-art methods,\nhighlighting the promise of turn-based, multi-agent prompting for fully\nautomated solver design."}
{"id": "2508.04004", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.04004", "abs": "https://arxiv.org/abs/2508.04004", "authors": ["Tanguy Ropitault", "Matteo Bordin", "Paolo Testolina", "Michele Polese", "Pedram Johari", "Nada Golmie", "Tommaso Melodia"], "title": "Enabling Site-Specific Cellular Network Simulation Through Ray-Tracing-Driven ns-3", "comment": null, "summary": "Evaluating cellular systems, from 5G New Radio (NR) and 5G-Advanced to 6G, is\nchallenging because the performance emerges from the tight coupling of\npropagation, beam management, scheduling, and higher-layer interactions.\nSystem-level simulation is therefore indispensable, yet the vast majority of\nstudies rely on the statistical 3GPP channel models. These are well suited to\ncapture average behavior across many statistical realizations, but cannot\nreproduce site-specific phenomena such as corner diffraction, street-canyon\nblockage, or deterministic line-of-sight conditions and\nangle-of-departure/arrival relationships that drive directional links. This\npaper extends 5G-LENA, an NR module for the system-level Network Simulator 3\n(ns-3), with a trace-based channel model that processes the Multipath\nComponents (MPCs) obtained from external ray-tracers (e.g., Sionna Ray Tracer\n(RT)) or measurement campaigns. Our module constructs frequency-domain channel\nmatrices and feeds them to the existing Physical (PHY)/Medium Access Control\n(MAC) stack without any further modifications. The result is a geometry-based\nchannel model that remains fully compatible with the standard 3GPP\nimplementation in 5G-LENA, while delivering site-specific geometric fidelity.\nThis new module provides a key building block toward Digital Twin (DT)\ncapabilities by offering realistic site-specific channel modeling, unlocking\nstudies that require site awareness, including beam management, blockage\nmitigation, and environment-aware sensing. We demonstrate its capabilities for\nprecise beam-steering validation and end-to-end metric analysis. In both cases,\nthe trace-driven engine exposes performance inflections that the statistical\nmodel does not exhibit, confirming its value for high-fidelity system-level\ncellular networks research and as a step toward DT applications."}
{"id": "2508.04627", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.04627", "abs": "https://arxiv.org/abs/2508.04627", "authors": ["Wenhao Hu", "Zhenyao He", "Wei Xu", "Yongming Huang", "Derrick Wing Kwan Ng", "Naofal Al-Dhahir"], "title": "Energy-Efficient Hybrid Beamfocusing for Near-Field Integrated Sensing and Communication", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a pivotal component of\nsixth-generation (6G) wireless networks, leveraging high-frequency bands and\nmassive multiple-input multiple-output (M-MIMO) to deliver both high-capacity\ncommunication and high-precision sensing. However, these technological\nadvancements lead to significant near-field effects, while the implementation\nof M-MIMO \\mbox{is associated with considerable} hardware costs and escalated\npower consumption. In this context, hybrid architecture designs emerge as both\nhardware-efficient and energy-efficient solutions. Motivated by these\nconsiderations, we investigate the design of energy-efficient hybrid\nbeamfocusing for near-field ISAC under two distinct target scenarios, i.e., a\npoint target and an extended target. Specifically, we first derive the\nclosed-form Cram\\'{e}r-Rao bound (CRB) of joint angle-and-distance estimation\nfor the point target and the Bayesian CRB (BCRB) of the target response matrix\nfor the extended target. Building on these derived results, we minimize the\nCRB/BCRB by optimizing the transmit beamfocusing, while ensuring the energy\nefficiency (EE) of the system and the quality-of-service (QoS) for\ncommunication users. To address the resulting \\mbox{nonconvex problems}, we\nfirst utilize a penalty-based successive convex approximation technique with a\nfully-digital beamformer to obtain a suboptimal solution. Then, we propose an\nefficient alternating \\mbox{optimization} algorithm to design the\nanalog-and-digital beamformer. \\mbox{Simulation} results indicate that joint\ndistance-and-angle estimation is feasible in the near-field region. However,\nthe adopted hybrid architectures inevitably degrade the accuracy of distance\nestimation, compared with their fully-digital counterparts. Furthermore,\nenhancements in system EE would compromise the accuracy of target estimation,\nunveiling a nontrivial tradeoff."}
{"id": "2508.03963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03963", "abs": "https://arxiv.org/abs/2508.03963", "authors": ["Zewen Liu", "Juntong Ni", "Xianfeng Tang", "Max S. Y. Lau", "Wei Jin"], "title": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?", "comment": null, "summary": "Uncovering hidden symbolic laws from time series data, as an aspiration\ndating back to Kepler's discovery of planetary motion, remains a core challenge\nin scientific discovery and artificial intelligence. While Large Language\nModels show promise in structured reasoning tasks, their ability to infer\ninterpretable, context-aligned symbolic structures from time series data is\nstill underexplored. To systematically evaluate this capability, we introduce\nSymbolBench, a comprehensive benchmark designed to assess symbolic reasoning\nover real-world time series across three tasks: multivariate symbolic\nregression, Boolean network inference, and causal discovery. Unlike prior\nefforts limited to simple algebraic equations, SymbolBench spans a diverse set\nof symbolic forms with varying complexity. We further propose a unified\nframework that integrates LLMs with genetic programming to form a closed-loop\nsymbolic reasoning system, where LLMs act both as predictors and evaluators.\nOur empirical results reveal key strengths and limitations of current models,\nhighlighting the importance of combining domain knowledge, context alignment,\nand reasoning structure to improve LLMs in automated scientific discovery."}
{"id": "2508.04015", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.04015", "abs": "https://arxiv.org/abs/2508.04015", "authors": ["Haoxiang Luo", "Kun Yang", "Qi Huang", "Schahram Dustdar"], "title": "A Novel Hierarchical Co-Optimization Framework for Coordinated Task Scheduling and Power Dispatch in Computing Power Networks", "comment": null, "summary": "The proliferation of large-scale artificial intelligence and data-intensive\napplications has spurred the development of Computing Power Networks (CPNs),\nwhich promise to deliver ubiquitous and on-demand computational resources.\nHowever, the immense energy consumption of these networks poses a significant\nsustainability challenge. Simultaneously, power grids are grappling with the\ninstability introduced by the high penetration of intermittent renewable energy\nsources (RES). This paper addresses these dual challenges through a novel\nTwo-Stage Co-Optimization (TSCO) framework that synergistically manages power\nsystem dispatch and CPN task scheduling to achieve low-carbon operations. The\nframework decomposes the complex, large-scale problem into a day-ahead\nstochastic unit commitment (SUC) stage and a real-time operational stage. The\nformer is solved using Benders decomposition for computational tractability,\nwhile in the latter, economic dispatch of generation assets is coupled with an\nadaptive CPN task scheduling managed by a Deep Reinforcement Learning (DRL)\nagent. This agent makes intelligent, carbon-aware decisions by responding to\ndynamic grid conditions, including real-time electricity prices and marginal\ncarbon intensity. Through extensive simulations on an IEEE 30-bus system\nintegrated with a CPN, the TSCO framework is shown to significantly outperform\nbaseline approaches. Results demonstrate that the proposed framework reduces\ntotal carbon emissions and operational costs, while simultaneously decreasing\nRES curtailment by more than 60% and maintaining stringent Quality of Service\n(QoS) for computational tasks."}
{"id": "2508.03986", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03986", "abs": "https://arxiv.org/abs/2508.03986", "authors": ["Yuan Xun", "Xiaojun Jia", "Xinwei Liu", "Hua Zhang"], "title": "The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?", "comment": null, "summary": "We observe that MLRMs oriented toward human-centric service are highly\nsusceptible to user emotional cues during the deep-thinking stage, often\noverriding safety protocols or built-in safety checks under high emotional\nintensity. Inspired by this key insight, we propose EmoAgent, an autonomous\nadversarial emotion-agent framework that orchestrates exaggerated affective\nprompts to hijack reasoning pathways. Even when visual risks are correctly\nidentified, models can still produce harmful completions through emotional\nmisalignment. We further identify persistent high-risk failure modes in\ntransparent deep-thinking scenarios, such as MLRMs generating harmful reasoning\nmasked behind seemingly safe responses. These failures expose misalignments\nbetween internal inference and surface-level behavior, eluding existing\ncontent-based safeguards. To quantify these risks, we introduce three metrics:\n(1) Risk-Reasoning Stealth Score (RRSS) for harmful reasoning beneath benign\noutputs; (2) Risk-Visual Neglect Rate (RVNR) for unsafe completions despite\nvisual risk recognition; and (3) Refusal Attitude Inconsistency (RAIC) for\nevaluating refusal unstability under prompt variants. Extensive experiments on\nadvanced MLRMs demonstrate the effectiveness of EmoAgent and reveal deeper\nemotional cognitive misalignments in model safety behavior."}
{"id": "2508.04150", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.04150", "abs": "https://arxiv.org/abs/2508.04150", "authors": ["Ilias Chrysovergis", "Alexandros-Apostolos A. Boulogeorgos", "Theodoros A. Tsiftsis", "Dusit Niyato"], "title": "Metaverse Framework for Wireless Systems Management", "comment": "9 pages, 5 figures, 1 algorithm", "summary": "This article introduces a comprehensive metaverse framework, which is\ndesigned for the simulation, emulation, and interaction with wireless systems.\nThe proposed framework integrates core metaverse technologies such as extended\nreality (XR), digital twins (DTs), artificial intelligence (AI), internet of\nthings (IoT), blockchain, and advanced 6G networking solutions to create a\ndynamic, immersive platform for both system development and management. By\nleveraging XR, users can visualize and engage with complex systems, while DTs\nenable real-time monitoring and optimization. AI generates the\nthree-dimensional (3D) content, enhances decision-making and system\nperformance, whereas IoT devices provide real-time sensor data for boosting the\nsimulation accuracy. Additionally, blockchain ensures secure, decentralized\ninteractions, and 5G/6G networks offer the necessary infrastructure for\nseamless, low-latency communication. This framework serves as a robust tool for\nexploring, developing, and optimizing wireless systems, aiming to provide\nvaluable insights into the future of networked environments."}
{"id": "2508.03991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03991", "abs": "https://arxiv.org/abs/2508.03991", "authors": ["Chongyu Bao", "Ruimin Dai", "Yangbo Shen", "Runyang Jian", "Jinghan Zhang", "Xiaolan Liu", "Kunpeng Liu"], "title": "Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents", "comment": null, "summary": "Intelligent personal assistants (IPAs) such as Siri and Google Assistant are\ndesigned to enhance human capabilities and perform tasks on behalf of users.\nThe emergence of LLM agents brings new opportunities for the development of\nIPAs. While responsive capabilities have been widely studied, proactive\nbehaviors remain underexplored. Designing an IPA that is proactive,\nprivacy-preserving, and capable of self-evolution remains a significant\nchallenge. Designing such IPAs relies on the cognitive architecture of LLM\nagents. This work proposes Cognition Forest, a semantic structure designed to\nalign cognitive modeling with system-level design. We unify cognitive\narchitecture and system design into a self-reinforcing loop instead of treating\nthem separately. Based on this principle, we present Galaxy, a framework that\nsupports multidimensional interactions and personalized capability generation.\nTwo cooperative agents are implemented based on Galaxy: KoRa, a\ncognition-enhanced generative agent that supports both responsive and proactive\nskills; and Kernel, a meta-cognition-based meta-agent that enables Galaxy's\nself-evolution and privacy preservation. Experimental results show that Galaxy\noutperforms multiple state-of-the-art benchmarks. Ablation studies and\nreal-world interaction cases validate the effectiveness of Galaxy."}
{"id": "2508.04317", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.04317", "abs": "https://arxiv.org/abs/2508.04317", "authors": ["Joshua Smailes", "Filip Futera", "Sebastian Köhler", "Simon Birnbach", "Martin Strohmeier", "Ivan Martinovic"], "title": "DSNS: The Deep Space Network Simulator", "comment": "12 pages, 8 figures, 3 tables", "summary": "Simulation tools are commonly used in the development and testing of new\nprotocols or new networks. However, as satellite networks start to grow to\nencompass thousands of nodes, and as companies and space agencies begin to\nrealize the interplanetary internet, existing satellite and network simulation\ntools have become impractical for use in this context.\n  We therefore present the Deep Space Network Simulator (DSNS): a new network\nsimulator with a focus on large-scale satellite networks. We demonstrate its\nimproved capabilities compared to existing offerings, showcase its flexibility\nand extensibility through an implementation of existing protocols and the DTN\nsimulation reference scenarios recommended by CCSDS, and evaluate its\nscalability, showing that it exceeds existing tools while providing better\nfidelity.\n  DSNS provides concrete usefulness to both standards bodies and satellite\noperators, enabling fast iteration on protocol development and testing of\nparameters under highly realistic conditions. By removing roadblocks to\nresearch and innovation, we can accelerate the development of upcoming\nsatellite networks and ensure that their communication is both fast and secure."}
{"id": "2508.04025", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04025", "abs": "https://arxiv.org/abs/2508.04025", "authors": ["Chao Hao", "Shuai Wang", "Kaiwen Zhou"], "title": "Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement", "comment": null, "summary": "Graphical user interface (GUI) agents have shown promise in automating mobile\ntasks but still struggle with input redundancy and decision ambiguity. In this\npaper, we present \\textbf{RecAgent}, an uncertainty-aware agent that addresses\nthese issues through adaptive perception. We distinguish two types of\nuncertainty in GUI navigation: (1) perceptual uncertainty, caused by input\nredundancy and noise from comprehensive screen information, and (2) decision\nuncertainty, arising from ambiguous tasks and complex reasoning. To reduce\nperceptual uncertainty, RecAgent employs a component recommendation mechanism\nthat identifies and focuses on the most relevant UI elements. For decision\nuncertainty, it uses an interactive module to request user feedback in\nambiguous situations, enabling intent-aware decisions. These components are\nintegrated into a unified framework that proactively reduces input complexity\nand reacts to high-uncertainty cases via human-in-the-loop refinement.\nAdditionally, we propose a dataset called \\textbf{ComplexAction} to evaluate\nthe success rate of GUI agents in executing specified single-step actions\nwithin complex scenarios. Extensive experiments validate the effectiveness of\nour approach. The dataset and code will be available at\nhttps://github.com/Fanye12/RecAgent."}
{"id": "2508.04415", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.04415", "abs": "https://arxiv.org/abs/2508.04415", "authors": ["Xuan Chen", "Yu Huang", "Miaowen Wen", "Shahid Mumtaz", "Fatih Gulec", "Anwer Al-Dulaimi", "Andrew W. Eckford"], "title": "Empowering Nanoscale Connectivity through Molecular Communication: A Case Study of Virus Infection", "comment": "Accepted for publication in IEEE Communications Magazine", "summary": "The Internet of Bio-Nano Things (IoBNT), envisioned as a revolutionary\nhealthcare paradigm, shows promise for epidemic control. This paper explores\nthe potential of using molecular communication (MC) to address the challenges\nin constructing IoBNT for epidemic prevention, specifically focusing on\nmodeling viral transmission, detecting the virus/infected individuals, and\nidentifying virus mutations. First, the MC channels in macroscale and\nmicroscale scenarios are discussed to match viral transmission in both scales\nseparately. Besides, the detection methods for these two scales are also\nstudied, along with the localization mechanism designed for the virus/infected\nindividuals. Moreover, an identification strategy is proposed to determine\npotential virus mutations, which is validated through simulation using the\nORF3a protein as a benchmark. Finally, open research issues are discussed. In\nsummary, this paper aims to analyze viral transmission through MC and combat\nviral spread using signal processing techniques within MC."}
{"id": "2508.04037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04037", "abs": "https://arxiv.org/abs/2508.04037", "authors": ["Liang Tang", "Shuxian Li", "Yuhao Cheng", "Yukang Huo", "Zhepeng Wang", "Yiqiang Yan", "Kaer Huang", "Yanzhe Jing", "Tiaonan Duan"], "title": "SEA: Self-Evolution Agent with Step-wise Reward for Computer Use", "comment": null, "summary": "Computer use agent is an emerging area in artificial intelligence that aims\nto operate the computers to achieve the user's tasks, which attracts a lot of\nattention from both industry and academia. However, the present agents'\nperformance is far from being used. In this paper, we propose the\nSelf-Evolution Agent (SEA) for computer use, and to develop this agent, we\npropose creative methods in data generation, reinforcement learning, and model\nenhancement. Specifically, we first propose an automatic pipeline to generate\nthe verifiable trajectory for training. And then, we propose efficient\nstep-wise reinforcement learning to alleviate the significant computational\nrequirements for long-horizon training. In the end, we propose the enhancement\nmethod to merge the grounding and planning ability into one model without any\nextra training. Accordingly, based on our proposed innovation of data\ngeneration, training strategy, and enhancement, we get the Selfevolution Agent\n(SEA) for computer use with only 7B parameters, which outperforms models with\nthe same number of parameters and has comparable performance to larger ones. We\nwill make the models' weight and related codes open-source in the future."}
{"id": "2508.04526", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.04526", "abs": "https://arxiv.org/abs/2508.04526", "authors": ["Fannya R. Sandjaja", "Ayesha A. Majeed", "Abdullah Abdullah", "Gyan Wickremasinghe", "Karen Rafferty", "Vishal Sharma"], "title": "Policy Design in Zero-Trust Distributed Networks: Challenges and Solutions", "comment": "10 pages, 5 Figures, 2 Tables", "summary": "Traditional security architectures are becoming more vulnerable to\ndistributed attacks due to significant dependence on trust. This will further\nescalate when implementing agentic AI within the systems, as more components\nmust be secured over a similar distributed space. These scenarios can be\nobserved in consumer technologies, such as the dense Internet of things (IoT).\nHere, zero-trust architecture (ZTA) can be seen as a potential solution, which\nrelies on a key principle of not giving users explicit trust, instead always\nverifying their privileges whenever a request is made. However, the overall\nsecurity in ZTA is managed through its policies, and unverified policies can\nlead to unauthorized access. Thus, this paper explores challenges and solutions\nfor ZTA policy design in the context of distributed networks, which is referred\nto as zero-trust distributed networks (ZTDN). This is followed by a case-study\non formal verification of policies using UPPAAL. Subsequently, the importance\nof accountability and responsibility in the system's security is discussed."}
{"id": "2508.04070", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.04070", "abs": "https://arxiv.org/abs/2508.04070", "authors": ["Ronja Mehlan", "Claudia Hess", "Quintus Stierstorfer", "Kristina Schaaff"], "title": "Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals", "comment": null, "summary": "As artificial intelligence becomes increasingly integrated into digital\nlearning environments, the personalization of learning content to reflect\nlearners' individual career goals offers promising potential to enhance\nengagement and long-term motivation. In our study, we investigate how career\ngoal-based content adaptation in learning systems based on generative AI\n(GenAI) influences learner engagement, satisfaction, and study efficiency. The\nmixed-methods experiment involved more than 4,000 learners, with one group\nreceiving learning scenarios tailored to their career goals and a control\ngroup. Quantitative results show increased session duration, higher\nsatisfaction ratings, and a modest reduction in study duration compared to\nstandard content. Qualitative analysis highlights that learners found the\npersonalized material motivating and practical, enabling deep cognitive\nengagement and strong identification with the content. These findings\nunderscore the value of aligning educational content with learners' career\ngoals and suggest that scalable AI personalization can bridge academic\nknowledge and workplace applicability."}
{"id": "2508.04556", "categories": ["cs.NI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.04556", "abs": "https://arxiv.org/abs/2508.04556", "authors": ["Filipe B. Teixeira", "Carolina Simões", "Paulo Fidalgo", "Wagner Pedrosa", "André Coelho", "Manuel Ricardo", "Luis M. Pessoa"], "title": "CONVERGE: A Multi-Agent Vision-Radio Architecture for xApps", "comment": "7 pages, 5 figures", "summary": "Telecommunications and computer vision have evolved independently. With the\nemergence of high-frequency wireless links operating mostly in line-of-sight,\nvisual data can help predict the channel dynamics by detecting obstacles and\nhelp overcoming them through beamforming or handover techniques.\n  This paper proposes a novel architecture for delivering real-time radio and\nvideo sensing information to O-RAN xApps through a multi-agent approach, and\nintroduces a new video function capable of generating blockage information for\nxApps, enabling Integrated Sensing and Communications. Experimental results\nshow that the delay of sensing information remains under 1\\,ms and that an xApp\ncan successfully use radio and video sensing information to control the 5G/6G\nRAN in real-time."}
{"id": "2508.04072", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04072", "abs": "https://arxiv.org/abs/2508.04072", "authors": ["Xingyu Chen", "Junxiu An", "Jun Guo", "Li Wang", "Jingcai Guo"], "title": "KG-Augmented Executable CoT for Mathematical Coding", "comment": "9 pages,2figures,6 tables", "summary": "In recent years, large language models (LLMs) have excelled in natural\nlanguage processing tasks but face significant challenges in complex reasoning\ntasks such as mathematical reasoning and code generation. To address these\nlimitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a\nnovel framework that enhances code generation through knowledge graphs and\nimproves mathematical reasoning via executable code. KGA-ECoT decomposes\nproblems into a Structured Task Graph, leverages efficient GraphRAG for precise\nknowledge retrieval from mathematical libraries, and generates verifiable code\nto ensure computational accuracy. Evaluations on multiple mathematical\nreasoning benchmarks demonstrate that KGA-ECoT significantly outperforms\nexisting prompting methods, achieving absolute accuracy improvements ranging\nfrom several to over ten percentage points. Further analysis confirms the\ncritical roles of GraphRAG in enhancing code quality and external code\nexecution in ensuring precision. These findings collectively establish KGA-ECoT\nas a robust and highly generalizable framework for complex mathematical\nreasoning tasks."}
{"id": "2508.04080", "categories": ["cs.AI", "stat.OT"], "pdf": "https://arxiv.org/pdf/2508.04080", "abs": "https://arxiv.org/abs/2508.04080", "authors": ["Jinfan Tang", "Kunming Wu", "Ruifeng Gongxie", "Yuya He", "Yuankai Wu"], "title": "GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement", "comment": "16 pages, 9 figures", "summary": "Recent studies have extended the application of large language models (LLMs)\nto geographic problems, revealing surprising geospatial competence even without\nexplicit spatial supervision. However, LLMs still face challenges in spatial\nconsistency, multi-hop reasoning, and geographic bias. To address these issues,\nwe propose GeoSR, a self-refining agentic reasoning framework that embeds core\ngeographic principles -- most notably Tobler's First Law of Geography -- into\nan iterative prediction loop. In GeoSR, the reasoning process is decomposed\ninto three collaborating agents: (1) a variable-selection agent that selects\nrelevant covariates from the same location; (2) a point-selection agent that\nchooses reference predictions at nearby locations generated by the LLM in\nprevious rounds; and (3) a refine agent that coordinates the iterative\nrefinement process by evaluating prediction quality and triggering further\nrounds when necessary. This agentic loop progressively improves prediction\nquality by leveraging both spatial dependencies and inter-variable\nrelationships. We validate GeoSR on tasks ranging from physical-world property\nestimation to socioeconomic prediction. Experimental results show consistent\nimprovements over standard prompting strategies, demonstrating that\nincorporating geostatistical priors and spatially structured reasoning into\nLLMs leads to more accurate and equitable geospatial predictions. The code of\nGeoSR is available at https://github.com/JinfanTang/GeoSR."}
{"id": "2508.04105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04105", "abs": "https://arxiv.org/abs/2508.04105", "authors": ["Karrtik Iyer", "Manikandan Ravikiran", "Prasanna Pendse", "Shayan Mohanty"], "title": "Towards Transparent AI Grading: Semantic Entropy as a Signal for Human-AI Disagreement", "comment": null, "summary": "Automated grading systems can efficiently score short-answer responses, yet\nthey often fail to indicate when a grading decision is uncertain or potentially\ncontentious. We introduce semantic entropy, a measure of variability across\nmultiple GPT-4-generated explanations for the same student response, as a proxy\nfor human grader disagreement. By clustering rationales via entailment-based\nsimilarity and computing entropy over these clusters, we quantify the diversity\nof justifications without relying on final output scores. We address three\nresearch questions: (1) Does semantic entropy align with human grader\ndisagreement? (2) Does it generalize across academic subjects? (3) Is it\nsensitive to structural task features such as source dependency? Experiments on\nthe ASAP-SAS dataset show that semantic entropy correlates with rater\ndisagreement, varies meaningfully across subjects, and increases in tasks\nrequiring interpretive reasoning. Our findings position semantic entropy as an\ninterpretable uncertainty signal that supports more transparent and trustworthy\nAI-assisted grading workflows."}
{"id": "2508.04116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04116", "abs": "https://arxiv.org/abs/2508.04116", "authors": ["Yongkang Li", "Shengping Xiao", "Shufang Zhu", "Jianwen Li", "Geguang Pu"], "title": "A Compositional Framework for On-the-Fly LTLf Synthesis", "comment": "8 pages, accepted by ECAI 2025", "summary": "Reactive synthesis from Linear Temporal Logic over finite traces (LTLf) can\nbe reduced to a two-player game over a Deterministic Finite Automaton (DFA) of\nthe LTLf specification. The primary challenge here is DFA construction, which\nis 2EXPTIME-complete in the worst case. Existing techniques either construct\nthe DFA compositionally before solving the game, leveraging automata\nminimization to mitigate state-space explosion, or build the DFA incrementally\nduring game solving to avoid full DFA construction. However, neither is\ndominant. In this paper, we introduce a compositional on-the-fly synthesis\nframework that integrates the strengths of both approaches, focusing on large\nconjunctions of smaller LTLf formulas common in practice. This framework\napplies composition during game solving instead of automata (game arena)\nconstruction. While composing all intermediate results may be necessary in the\nworst case, pruning these results simplifies subsequent compositions and\nenables early detection of unrealizability. Specifically, the framework allows\ntwo composition variants: pruning before composition to take full advantage of\nminimization or pruning during composition to guide on-the-fly synthesis.\nCompared to state-of-the-art synthesis solvers, our framework is able to solve\na notable number of instances that other solvers cannot handle. A detailed\nanalysis shows that both composition variants have unique merits."}
{"id": "2508.04118", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04118", "abs": "https://arxiv.org/abs/2508.04118", "authors": ["Ruochen Zhao", "Simone Conia", "Eric Peng", "Min Li", "Saloni Potdar"], "title": "AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities", "comment": null, "summary": "Open-domain Knowledge Graph Completion (KGC) faces significant challenges in\nan ever-changing world, especially when considering the continual emergence of\nnew entities in daily news. Existing approaches for KGC mainly rely on\npretrained language models' parametric knowledge, pre-constructed queries, or\nsingle-step retrieval, typically requiring substantial supervision and training\ndata. Even so, they often fail to capture comprehensive and up-to-date\ninformation about unpopular and/or emerging entities. To this end, we introduce\nAgentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework\nthat combines iterative retrieval actions and multi-step reasoning to\ndynamically construct rich knowledge graph triplets. Experiments show that,\ndespite requiring zero training efforts, AgREE significantly outperforms\nexisting methods in constructing knowledge graph triplets, especially for\nemerging entities that were not seen during language models' training\nprocesses, outperforming previous methods by up to 13.7%. Moreover, we propose\na new evaluation methodology that addresses a fundamental weakness of existing\nsetups and a new benchmark for KGC on emerging entities. Our work demonstrates\nthe effectiveness of combining agent-based reasoning with strategic information\nretrieval for maintaining up-to-date knowledge graphs in dynamic information\nenvironments."}
{"id": "2508.04163", "categories": ["cs.AI", "cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04163", "abs": "https://arxiv.org/abs/2508.04163", "authors": ["Hasra Dodampegama", "Mohan Sridharan"], "title": "Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork", "comment": "14 pages, 6 figures", "summary": "AI agents deployed in assistive roles often have to collaborate with other\nagents (humans, AI systems) without prior coordination. Methods considered\nstate of the art for such ad hoc teamwork often pursue a data-driven approach\nthat needs a large labeled dataset of prior observations, lacks transparency,\nand makes it difficult to rapidly revise existing knowledge in response to\nchanges. As the number of agents increases, the complexity of decision-making\nmakes it difficult to collaborate effectively. This paper advocates leveraging\nthe complementary strengths of knowledge-based and data-driven methods for\nreasoning and learning for ad hoc teamwork. For any given goal, our\narchitecture enables each ad hoc agent to determine its actions through\nnon-monotonic logical reasoning with: (a) prior commonsense domain-specific\nknowledge; (b) models learned and revised rapidly to predict the behavior of\nother agents; and (c) anticipated abstract future goals based on generic\nknowledge of similar situations in an existing foundation model. We\nexperimentally evaluate our architecture's capabilities in VirtualHome, a\nrealistic physics-based 3D simulation environment."}
{"id": "2508.04235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04235", "abs": "https://arxiv.org/abs/2508.04235", "authors": ["Jiaying Zhu", "Ziyang Zheng", "Zhengyuan Shi", "Yalun Cai", "Qiang Xu"], "title": "Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities", "comment": "11 pages, 7 figures", "summary": "Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design\nAutomation. The standard workflow for solving CSAT problems converts circuits\ninto Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by\nConflict-Driven Clause Learning (CDCL). However, this process inherently\ndiscards rich structural and functional information, leading to suboptimal\nsolver performance. To address this limitation, we introduce CASCAD, a novel\ncircuit-aware SAT solving framework that directly leverages circuit-level\nconditional probabilities computed via Graph Neural Networks (GNNs). By\nexplicitly modeling gate-level conditional probabilities, CASCAD dynamically\nguides two critical CDCL heuristics -- variable phase selection and clause\nmanagementto significantly enhance solver efficiency. Extensive evaluations on\nchallenging real-world Logical Equivalence Checking (LEC) benchmarks\ndemonstrate that CASCAD reduces solving times by up to 10x compared to\nstate-of-the-art CNF-based approaches, achieving an additional 23.5% runtime\nreduction via our probability-guided clause filtering strategy. Our results\nunderscore the importance of preserving circuit-level structural insights\nwithin SAT solvers, providing a robust foundation for future improvements in\nSAT-solving efficiency and EDA tool design."}
{"id": "2508.04278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04278", "abs": "https://arxiv.org/abs/2508.04278", "authors": ["Wentao Wu", "Linqing Chen", "Hanmeng Zhong", "Weilei Wang"], "title": "Large Language Model's Multi-Capability Alignment in Biomedical Domain", "comment": null, "summary": "BalancedBio is a theoretically grounded framework for parameter-efficient\nbiomedical reasoning, addressing multi-capability integration in\ndomain-specific AI alignment. It establishes the Biomedical Multi-Capability\nConvergence Theorem, proving orthogonal gradient spaces are essential to\nprevent capability interference for safe deployment. Key innovations include:\n(1) Medical Knowledge Grounded Synthetic Generation (MKGSG), extending\nSource2Synth with clinical workflow constraints and medical ontology validation\nfor factual accuracy and safety; and (2) Capability Aware Group Relative Policy\nOptimization, deriving optimal hybrid reward weighting to maintain\northogonality in RL, using a reward model with rule-based and model-based\nscores adapted to biomedical tasks. Mathematical analysis proves Pareto-optimal\nconvergence, preserving performance across capabilities. It achieves\nstate-of-the-art results in its parameter class: domain expertise (80.95%\nBIOMED-MMLU, +15.32% over baseline), reasoning (61.94%, +7.75%), instruction\nfollowing (67.95%, +6.44%), and integration (86.7%, +18.5%). Theoretical safety\nguarantees include bounds on capability preservation and clinical accuracy.\nReal-world deployment yields 78% cost reduction, 23% improved diagnostic\naccuracy, and 89% clinician acceptance. This work provides a principled\nmethodology for biomedical AI alignment, enabling efficient reasoning with\nessential safety and reliability, with the 0.5B model version to be released."}
{"id": "2508.04282", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04282", "abs": "https://arxiv.org/abs/2508.04282", "authors": ["Yongyi Wang", "Lingfeng Li", "Bozhou Chen", "Ang Li", "Hanyu Liu", "Qirui Zheng", "Xionghui Yang", "Wenxin Li"], "title": "Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling", "comment": null, "summary": "Recent research has developed benchmarks for memory-augmented reinforcement\nlearning (RL) algorithms, providing Partially Observable Markov Decision\nProcess (POMDP) environments where agents depend on past observations to make\ndecisions. While many benchmarks incorporate sufficiently complex real-world\nproblems, they lack controllability over the degree of challenges posed to\nmemory models. In contrast, synthetic environments enable fine-grained\nmanipulation of dynamics, making them critical for detailed and rigorous\nevaluation of memory-augmented RL. Our study focuses on POMDP synthesis with\nthree key contributions:\n  1. A theoretical framework for analyzing POMDPs, grounded in Memory Demand\nStructure (MDS), transition invariance, and related concepts; 2. A methodology\nleveraging linear process dynamics, state aggregation, and reward\nredistribution to construct customized POMDPs with predefined properties; 3.\nEmpirically validated series of POMDP environments with increasing difficulty\nlevels, designed based on our theoretical insights. Our work clarifies the\nchallenges of memory-augmented RL in solving POMDPs, provides guidelines for\nanalyzing and designing POMDP environments, and offers empirical support for\nselecting memory models in RL tasks."}
{"id": "2508.04339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04339", "abs": "https://arxiv.org/abs/2508.04339", "authors": ["Anran Xu", "Jincheng Wang", "Baigen Cai", "Tao Wen"], "title": "Deliberative Reasoning Network: An Uncertainty-Driven Paradigm for Belief-Tracked Inference with Pretrained Language Models", "comment": "8 pages, 3 figures", "summary": "Large language models often fail at logical reasoning when semantic\nheuristics conflict with decisive evidence - a phenomenon we term cognitive\ntraps. To address this fundamental limitation, we introduce the Deliberative\nReasoning Network (DRN), a novel paradigm that reframes logical reasoning from\nprobability maximization to uncertainty minimization. Instead of asking \"Which\nanswer is most likely?\", DRN asks \"Which hypothesis has the most internally\nconsistent evidence?\". DRN achieves intrinsic interpretability by explicitly\ntracking belief states and quantifying epistemic uncertainty for competing\nhypotheses through an iterative evidence synthesis process. We validate our\napproach through two complementary architectures - a bespoke discriminative\nmodel that embodies the core uncertainty minimization principle, and a\nlightweight verification module that enhances existing generative LLMs.\nEvaluated on LCR-1000, our new adversarial reasoning benchmark designed to\nexpose cognitive traps, the bespoke DRN achieves up to 15.2% improvement over\nstandard baselines. When integrated as a parameter-efficient verifier with\nMistral-7B, our hybrid system boosts accuracy from 20% to 80% on the most\nchallenging problems. Critically, DRN demonstrates strong zero-shot\ngeneralization, improving TruthfulQA performance by 23.6% without additional\ntraining, indicating that uncertainty-driven deliberation learns transferable\nreasoning principles. We position DRN as a foundational, verifiable System 2\nreasoning component for building more trustworthy AI systems."}
{"id": "2508.04361", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04361", "abs": "https://arxiv.org/abs/2508.04361", "authors": ["Fuqing Bie", "Shiyu Huang", "Xijia Tao", "Zhiqin Fang", "Leyi Pan", "Junzhe Chen", "Min Ren", "Liuyu Xiang", "Zhaofeng He"], "title": "OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing", "comment": null, "summary": "While generalist foundation models like Gemini and GPT-4o demonstrate\nimpressive multi-modal competence, existing evaluations fail to test their\nintelligence in dynamic, interactive worlds. Static benchmarks lack agency,\nwhile interactive benchmarks suffer from a severe modal bottleneck, typically\nignoring crucial auditory and temporal cues. To bridge this evaluation chasm,\nwe introduce OmniPlay, a diagnostic benchmark designed not just to evaluate,\nbut to probe the fusion and reasoning capabilities of agentic models across the\nfull sensory spectrum. Built on a core philosophy of modality interdependence,\nOmniPlay comprises a suite of five game environments that systematically create\nscenarios of both synergy and conflict, forcing agents to perform genuine\ncross-modal reasoning. Our comprehensive evaluation of six leading omni-modal\nmodels reveals a critical dichotomy: they exhibit superhuman performance on\nhigh-fidelity memory tasks but suffer from systemic failures in challenges\nrequiring robust reasoning and strategic planning. We demonstrate that this\nfragility stems from brittle fusion mechanisms, which lead to catastrophic\nperformance degradation under modality conflict and uncover a counter-intuitive\n\"less is more\" paradox, where removing sensory information can paradoxically\nimprove performance. Our findings suggest that the path toward robust AGI\nrequires a research focus beyond scaling to explicitly address synergistic\nfusion. Our platform is available for anonymous review at\nhttps://github.com/fuqingbie/omni-game-benchmark."}
{"id": "2508.04383", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.04383", "abs": "https://arxiv.org/abs/2508.04383", "authors": ["Robert Prentner"], "title": "Artificial Consciousness as Interface Representation", "comment": "12 pages", "summary": "Whether artificial intelligence (AI) systems can possess consciousness is a\ncontentious question because of the inherent challenges of defining and\noperationalizing subjective experience. This paper proposes a framework to\nreframe the question of artificial consciousness into empirically tractable\ntests. We introduce three evaluative criteria - S (subjective-linguistic), L\n(latent-emergent), and P (phenomenological-structural) - collectively termed\nSLP-tests, which assess whether an AI system instantiates interface\nrepresentations that facilitate consciousness-like properties. Drawing on\ncategory theory, we model interface representations as mappings between\nrelational substrates (RS) and observable behaviors, akin to specific types of\nabstraction layers. The SLP-tests collectively operationalize subjective\nexperience not as an intrinsic property of physical systems but as a functional\ninterface to a relational entity."}
{"id": "2508.04389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04389", "abs": "https://arxiv.org/abs/2508.04389", "authors": ["Weitai Kang", "Bin Lei", "Gaowen Liu", "Caiwen Ding", "Yan Yan"], "title": "GuirlVG: Incentivize GUI Visual Grounding via Empirical Exploration on Reinforcement Learning", "comment": "9 pages", "summary": "Graphical user interface visual grounding (GUI-VG), a core capability for GUI\nagents, has primarily relied on supervised fine-tuning (SFT) of multimodal\nlarge language models (MLLMs), which demands extensive data curation and\nsignificant training costs. However, as MLLMs continue to advance and even\ncover GUI domains during pretraining, the necessity of exhaustive SFT\npost-training becomes increasingly questionable. Meanwhile, recent successes of\nrule-based reinforcement fine-tuning (RFT) suggest a more efficient\nalternative. Despite this promise, the optimal manner of applying RFT for\nGUI-VG remains unexplored. To bridge this gap, we introduce GuirlVG, a\nreinforcement learning-based GUI-VG method built on a systematic empirical\nstudy and a novel stabilization technique. We find that naive application of\nRFT underperforms the SFT baseline, motivating a deeper exploration. First, we\ndecompose RFT into its core components and analyze the optimal formulation of\neach. Second, we propose a novel Adversarial KL Factor that dynamically\nstabilizes training to mitigate reward over-optimization. Third, we further\nexplore the training configurations of RFT to enhance effectiveness. Extensive\nexperiments show that GuirlVG, with only 5.2K training samples, outperforms SFT\nmethods trained on over 10M samples, achieving a 7.7% improvement on\nScreenSpot, a 17.2% improvement on ScreenSpotPro, and 91.9% accuracy on\nScreenSpotV2."}
{"id": "2508.04412", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.04412", "abs": "https://arxiv.org/abs/2508.04412", "authors": ["Thassilo M. Schiepanski", "Nicholas Piël"], "title": "Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents", "comment": null, "summary": "Frontier LLMs only recently enabled serviceable, autonomous web agents. At\nthat, a model poses as an instantaneous domain model backend. Ought to suggest\ninteraction, it is consulted with a web-based task and respective application\nstate. The key problem lies in application state serialisation\n$\\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are\npremised on grounded GUI snapshots, i.e., screenshots enhanced with visual\ncues. Not least to resemble human perception, but for images representing\nrelatively cheap means of model input. LLM vision still lag behind code\ninterpretation capabilities. DOM snapshots, which structurally resemble HTML,\nimpose a desired alternative. Vast model input token size, however, disables\nreliable implementation with web agents to date.\n  We propose D2Snap, a first-of-its-kind DOM downsampling algorithm. Based on a\nGPT-4o backend, we evaluate D2Snap on tasks sampled from the Online-Mind2Web\ndataset. The success rate of D2Snap-downsampled DOM snapshots (67%) matches a\ngrounded GUI snapshot baseline (65%) $\\unicode{x2013}$ within the same input\ntoken order of magnitude (1e3). Our best evaluated configurations\n$\\unicode{x2013}$ one token order above, but within the model's context window\n$\\unicode{x2013}$ outperform this baseline by 8%. Our evaluation, moreover,\nyields that DOM-inherent hierarchy embodies a strong UI feature for LLMs."}
{"id": "2508.04428", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04428", "abs": "https://arxiv.org/abs/2508.04428", "authors": ["Si Chen", "Izzy Molnar", "Ting Hua", "Peiyu Li", "Le Huy Khiem", "G. Alex Ambrose", "Jim Lang", "Ronald Metoyer", "Nitesh V. Chawla"], "title": "\\textsc{SimInstruct}: A Responsible Tool for Collecting Scaffolding Dialogues Between Experts and LLM-Simulated Novices", "comment": null, "summary": "High-quality, multi-turn instructional dialogues between novices and experts\nare essential for developing AI systems that support teaching, learning, and\ndecision-making. These dialogues often involve scaffolding -- the process by\nwhich an expert supports a novice's thinking through questions, feedback, and\nstep-by-step guidance. However, such data are scarce due to privacy concerns in\nrecording and the vulnerability inherent in help-seeking. We present\nSimInstruct, a scalable, expert-in-the-loop tool for collecting scaffolding\ndialogues. Using teaching development coaching as an example domain,\nSimInstruct simulates novice instructors via LLMs, varying their teaching\nchallenges and LLM's persona traits, while human experts provide multi-turn\nfeedback, reasoning, and instructional support. This design enables the\ncreation of realistic, pedagogically rich dialogues without requiring real\nnovice participants. Our results reveal that persona traits, such as\nextroversion and introversion, meaningfully influence how experts engage.\nCompared to real mentoring recordings, SimInstruct dialogues demonstrate\ncomparable pedagogical relevance and cognitive depth. Experts also reported the\nprocess as engaging and reflective, improving both data quality and their own\nprofessional insight. We further fine-tuned a LLaMA model to be an expert model\nusing the augmented dataset, which outperformed GPT-4o in instructional\nquality. Our analysis highlights GPT-4o's limitations in weak reflective\nquestioning, overuse of generic praise, a condescending tone, and a tendency to\noverwhelm novices with excessive suggestions."}
{"id": "2508.04460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04460", "abs": "https://arxiv.org/abs/2508.04460", "authors": ["Rui Ha", "Chaozhuo Li", "Rui Pu", "Sen Su"], "title": "From \"Aha Moments\" to Controllable Thinking: Toward Meta-Cognitive Reasoning in Large Reasoning Models via Decoupled Reasoning and Control", "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated a latent capacity for complex\nreasoning by spontaneously exhibiting cognitive behaviors such as step-by-step\nreasoning, reflection, and backtracking, commonly referred to as \"Aha Moments\".\nHowever, such emergent behaviors remain unregulated and uncontrolled, often\nresulting in overthinking, where the model continues generating redundant\nreasoning content even after reaching reliable conclusions. This leads to\nexcessive computational costs and increased latency, limiting the practical\ndeployment of LRMs. The root cause lies in the absence of intrinsic regulatory\nmechanisms, as current models are unable to monitor and adaptively manage their\nreasoning process to determine when to continue, backtrack, or terminate. To\naddress this issue, we propose the Meta-cognitive Reasoning Framework (MERA),\nwhich explicitly decouples the thinking process into distinct reasoning and\ncontrol components, thereby enabling the independent optimization of control\nstrategies. Specifically, MERA incorporates a takeover-based data construction\nmechanism that identifies critical decision points during reasoning and\ndelegates the creation of control signals to auxiliary LLMs, thereby enabling\nthe construction of high-quality reasoning-control data. Additionally, a\nstructured reasoning-control separation is implemented via supervised\nfine-tuning, enabling the model to generate explicit traces and acquire initial\nmeta-cognitive control capabilities. Finally, MERA employs Control-Segment\nPolicy Optimization (CSPO), which combines segment-wise Group Relative Policy\nOptimization (GRPO) with a control-masking mechanism to optimize control\nbehavior learning while minimizing interference from irrelevant content.\nExperiments on various reasoning benchmarks demonstrate that models trained\nwith MERA enhance both reasoning efficiency and accuracy."}
{"id": "2508.04482", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04482", "abs": "https://arxiv.org/abs/2508.04482", "authors": ["Xueyu Hu", "Tao Xiong", "Biao Yi", "Zishu Wei", "Ruixuan Xiao", "Yurun Chen", "Jiasheng Ye", "Meiling Tao", "Xiangxin Zhou", "Ziyu Zhao", "Yuhuai Li", "Shengze Xu", "Shenzhi Wang", "Xinchen Xu", "Shuofei Qiao", "Zhaokai Wang", "Kun Kuang", "Tieyong Zeng", "Liang Wang", "Jiwei Li", "Yuchen Eleanor Jiang", "Wangchunshu Zhou", "Guoyin Wang", "Keting Yin", "Zhou Zhao", "Hongxia Yang", "Fan Wu", "Shengyu Zhang", "Fei Wu"], "title": "OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use", "comment": "ACL 2025 (Oral)", "summary": "The dream to create AI assistants as capable and versatile as the fictional\nJ.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution\nof (multi-modal) large language models ((M)LLMs), this dream is closer to\nreality, as (M)LLM-based Agents using computing devices (e.g., computers and\nmobile phones) by operating within the environments and interfaces (e.g.,\nGraphical User Interface (GUI)) provided by operating systems (OS) to automate\ntasks have significantly advanced. This paper presents a comprehensive survey\nof these advanced agents, designated as OS Agents. We begin by elucidating the\nfundamentals of OS Agents, exploring their key components including the\nenvironment, observation space, and action space, and outlining essential\ncapabilities such as understanding, planning, and grounding. We then examine\nmethodologies for constructing OS Agents, focusing on domain-specific\nfoundation models and agent frameworks. A detailed review of evaluation\nprotocols and benchmarks highlights how OS Agents are assessed across diverse\ntasks. Finally, we discuss current challenges and identify promising directions\nfor future research, including safety and privacy, personalization and\nself-evolution. This survey aims to consolidate the state of OS Agents\nresearch, providing insights to guide both academic inquiry and industrial\ndevelopment. An open-source GitHub repository is maintained as a dynamic\nresource to foster further innovation in this field. We present a 9-page\nversion of our work, accepted by ACL 2025, to provide a concise overview to the\ndomain."}
{"id": "2508.04511", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04511", "abs": "https://arxiv.org/abs/2508.04511", "authors": ["Hamed Ayoobi", "Nico Potyka", "Anna Rapberger", "Francesca Toni"], "title": "Argumentative Debates for Transparent Bias Detection [Technical Report]", "comment": null, "summary": "As the use of AI systems in society grows, addressing potential biases that\nemerge from data or are learned by models is essential to prevent systematic\ndisadvantages against specific groups. Several notions of (un)fairness have\nbeen proposed in the literature, alongside corresponding algorithmic methods\nfor detecting and mitigating unfairness, but, with very few exceptions, these\ntend to ignore transparency. Instead, interpretability and explainability are\ncore requirements for algorithmic fairness, even more so than for other\nalgorithmic solutions, given the human-oriented nature of fairness. In this\npaper, we contribute a novel interpretable, explainable method for bias\ndetection relying on debates about the presence of bias against individuals,\nbased on the values of protected features for the individuals and others in\ntheir neighbourhoods. Our method builds upon techniques from formal and\ncomputational argumentation, whereby debates result from arguing about biases\nwithin and across neighbourhoods. We provide formal, quantitative, and\nqualitative evaluations of our method, highlighting its strengths in\nperformance against baselines, as well as its interpretability and\nexplainability."}
{"id": "2508.04563", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04563", "abs": "https://arxiv.org/abs/2508.04563", "authors": ["Mei Jiang", "Houping Yue", "Bingdong Li", "Hao Hao", "Ying Qian", "Bo Jiang", "Aimin Zhou"], "title": "SID: Benchmarking Guided Instruction Capabilities in STEM Education with a Socratic Interdisciplinary Dialogues Dataset", "comment": "26 pages, 20 figures", "summary": "Fostering students' abilities for knowledge integration and transfer in\ncomplex problem-solving scenarios is a core objective of modern education, and\ninterdisciplinary STEM is a key pathway to achieve this, yet it requires expert\nguidance that is difficult to scale. While LLMs offer potential in this regard,\ntheir true capability for guided instruction remains unclear due to the lack of\nan effective evaluation benchmark. To address this, we introduce SID, the first\nbenchmark designed to systematically evaluate the higher-order guidance\ncapabilities of LLMs in multi-turn, interdisciplinary Socratic dialogues. Our\ncontributions include a large-scale dataset of 10,000 dialogue turns across 48\ncomplex STEM projects, a novel annotation schema for capturing deep pedagogical\nfeatures, and a new suite of evaluation metrics (e.g., X-SRG). Baseline\nexperiments confirm that even state-of-the-art LLMs struggle to execute\neffective guided dialogues that lead students to achieve knowledge integration\nand transfer. This highlights the critical value of our benchmark in driving\nthe development of more pedagogically-aware LLMs."}
{"id": "2508.04576", "categories": ["cs.AI", "I.2.6; I.2.7; D.2.8"], "pdf": "https://arxiv.org/pdf/2508.04576", "abs": "https://arxiv.org/abs/2508.04576", "authors": ["Yue Zhou", "Yi Chang", "Yuan Wu"], "title": "ConfProBench: A Confidence Evaluation Benchmark for MLLM-Based Process Judges", "comment": null, "summary": "Reasoning is a critical capability of multimodal large language models\n(MLLMs) for solving complex multimodal tasks, and judging the correctness of\nreasoning steps is crucial for improving this capability. Recently, MLLM-based\nprocess judges (MPJs) have been widely used to assess the correctness of\nreasoning steps in multimodal tasks. Therefore, evaluating MPJs is important\nfor identifying their limitations and guiding future improvements. However,\nexisting benchmarks for MPJs mainly focus on tasks such as step correctness\nclassification and reasoning process search, while overlooking a key aspect:\nwhether the confidence scores produced by MPJs at the step level are reliable.\nTo address this gap, we propose ConfProBench, the first comprehensive benchmark\ndesigned to systematically evaluate the reliability of step-level confidence\nscores generated by MPJs. Our benchmark constructs three types of adversarially\nperturbed reasoning steps: Synonym Substitution, Syntactic Transformation, and\nImage Perturbation, to test the robustness of MPJ confidence under\nperturbations. In addition, we introduce three novel evaluation metrics:\nConfidence Robustness Score (CRS), Confidence Sensitivity Score (CSS), and\nConfidence Calibration Score (CCS), which evaluate robustness, sensitivity, and\ncalibration, respectively. We evaluate 14 state-of-the-art MLLMs, including\nboth proprietary and open-source models. Experiments reveal limitations in\ncurrent MPJs' confidence performance and offer competitive baselines to support\nfuture research."}
{"id": "2508.04652", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04652", "abs": "https://arxiv.org/abs/2508.04652", "authors": ["Shuo Liu", "Zeyu Liang", "Xueguang Lyu", "Christopher Amato"], "title": "LLM Collaboration With Multi-Agent Reinforcement Learning", "comment": null, "summary": "A large amount of work has been done in Multi-Agent Systems (MAS) for\nmodeling and solving problems with multiple interacting agents. However, most\nLLMs are pretrained independently and not specifically optimized for\ncoordination. Existing LLM fine-tuning frameworks rely on individual rewards,\nwhich require complex reward designs for each agent to encourage collaboration.\nTo address these challenges, we model LLM collaboration as a cooperative\nMulti-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent,\nmulti-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO),\nto solve it, building on current RL approaches for LLMs as well as MARL\ntechniques. Our experiments on LLM writing and coding collaboration demonstrate\nthat fine-tuning MAS with MAGRPO enables agents to generate high-quality\nresponses efficiently through effective cooperation. Our approach opens the\ndoor to using other MARL methods for LLMs and highlights the associated\nchallenges."}
{"id": "2508.04700", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.04700", "abs": "https://arxiv.org/abs/2508.04700", "authors": ["Zeyi Sun", "Ziyu Liu", "Yuhang Zang", "Yuhang Cao", "Xiaoyi Dong", "Tong Wu", "Dahua Lin", "Jiaqi Wang"], "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience", "comment": "Code at https://github.com/SunzeY/SEAgent", "summary": "Repurposing large vision-language models (LVLMs) as computer use agents\n(CUAs) has led to substantial breakthroughs, primarily driven by human-labeled\ndata. However, these models often struggle with novel and specialized software,\nparticularly in scenarios lacking human annotations. To address this challenge,\nwe propose SEAgent, an agentic self-evolving framework enabling CUAs to\nautonomously evolve through interactions with unfamiliar software.\nSpecifically, SEAgent empowers computer-use agents to autonomously master novel\nsoftware environments via experiential learning, where agents explore new\nsoftware, learn through iterative trial-and-error, and progressively tackle\nauto-generated tasks organized from simple to complex. To achieve this goal, we\ndesign a World State Model for step-wise trajectory assessment, along with a\nCurriculum Generator that generates increasingly diverse and challenging tasks.\nThe agent's policy is updated through experiential learning, comprised of\nadversarial imitation of failure actions and Group Relative Policy Optimization\n(GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist\ntraining strategy that integrates individual experiential insights from\nspecialist agents, facilitating the development of a stronger generalist CUA\ncapable of continuous autonomous evolution. This unified agent ultimately\nachieves performance surpassing ensembles of individual specialist agents on\ntheir specialized software. We validate the effectiveness of SEAgent across\nfive novel software environments within OS-World. Our approach achieves a\nsignificant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a\ncompetitive open-source CUA, i.e., UI-TARS."}
{"id": "2508.02314", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02314", "abs": "https://arxiv.org/abs/2508.02314", "authors": ["Jiajia Guo", "Yiming Cui", "Shi Jin", "Jun Zhang"], "title": "Large AI Models for Wireless Physical Layer", "comment": "A collection of paper on Large AI Models for wireless physical layer\n  can be found at https://github.com/AI4Wireless/LAM4PHY_6G", "summary": "Large artificial intelligence models (LAMs) are transforming wireless\nphysical layer technologies through their robust generalization, multitask\nprocessing, and multimodal capabilities. This article reviews recent\nadvancements in LAM applications for physical layer communications, addressing\nlimitations of conventional AI-based approaches. LAM applications are\nclassified into two strategies: leveraging pre-trained LAMs and developing\nnative LAMs designed specifically for physical layer tasks. The motivations and\nkey frameworks of these approaches are comprehensively examined through\nmultiple use cases. Both strategies significantly improve performance and\nadaptability across diverse wireless scenarios. Future research directions,\nincluding efficient architectures, interpretability, standardized datasets, and\ncollaboration between large and small models, are proposed to advance LAM-based\nphysical layer solutions for next-generation communication systems."}
