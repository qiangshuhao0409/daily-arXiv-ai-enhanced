<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.IT](#cs.IT) [Total: 13]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [TeraRIS NOMA-MIMO Communications for 6G and Beyond Industrial Networks](https://arxiv.org/abs/2508.05130)
*Ali Raza,Muhammad Farhan Khan,Zeeshan Alam,Muhammad Saad,Ilyas Saleem,Muhammad Ahmed Mohsin,Muhammad Ali Jamshed*

Main category: cs.NI

TL;DR: 提出了一种结合可重构智能表面（RIS）、太赫兹通信和非正交多址接入（NOMA）的框架，以提升智能工业通信的性能。通过优化功率分配策略，系统在频谱效率、覆盖范围和可靠性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决未来6G网络中工业自动化和实时通信对高频谱效率、覆盖范围和可靠性的需求。

Method: 结合RIS、THz和NOMA技术，提出两种功率分配策略：优化近远节点功率分配和优先网络需求。

Result: 在30 dBm下，方案比固定功率分配方案提升了23%的总速率，并通过仿真验证了其有效性和鲁棒性。

Conclusion: RIS辅助的NOMA MIMO框架在太赫兹工业通信中表现出色，为未来网络提供了可行的解决方案。

Abstract: This paper presents a joint framework that integrates reconfigurable
intelligent surfaces (RISs) with Terahertz (THz) communications and
non-orthogonal multiple access (NOMA) to enhance smart industrial
communications. The proposed system leverages the advantages of RIS and THz
bands to improve spectral efficiency, coverage, and reliability key
requirements for industrial automation and real-time communications in future
6G networks and beyond. Within this framework, two power allocation strategies
are investigated: the first optimally distributes power between near and far
industrial nodes, and the second prioritizes network demands to enhance system
performance further. A performance evaluation is conducted to compare the sum
rate and outage probability against a fixed power allocation scheme. Our scheme
achieves up to a 23% sum rate gain over fixed PA at 30 dBm. Simulation results
validate the theoretical analysis, demonstrating the effectiveness and
robustness of the RIS-assisted NOMA MIMO framework for THz enabled industrial
communications.

</details>


### [2] [Modular Design and Experimental Evaluation of 5G Mobile Cell Architectures Based on Overlay and Integrated Models](https://arxiv.org/abs/2508.05249)
*José Ruela,Ivan Cojocaru,André Coelho,Rui Campos,Manuel Ricardo*

Main category: cs.NI

TL;DR: 本文介绍了5G移动蜂窝（MC）的概念、架构设计和性能评估，用于在固定5G基础设施有限或无线电条件较差的区域提供无线连接。讨论了两种MC设计方法（覆盖模型和IAB模型），并通过仿真测试验证了MC的性能。


<details>
  <summary>Details</summary>
Motivation: 解决固定5G基础设施不足或无线电条件恶劣区域的无线连接问题。

Method: 提出两种MC设计方法（覆盖模型和IAB模型），并使用OpenAirInterface仿真测试不同MC位置的性能。

Result: 验证了MC概念，并表明MC位置对网络性能有显著影响。

Conclusion: MC架构可用于临时覆盖扩展和容量增强，适用于港口、工业场景和公共安全等环境。

Abstract: This paper presents the concept, architectural design, and performance
evaluation of a 5G Mobile Cell (MC) used to provide 5G wireless connectivity to
User Equipment (UE) in areas with limited fixed 5G infrastructures or subject
to adverse radio conditions. We consider two main approaches to MC design: an
overlay model, where the MC obtains backhaul connectivity from a 5G overlay
network, and an Integrated Access and Backhaul (IAB)-based model, discussing
their protocol stacks and architectural implications. In order to validate the
MC's performance, we employ an emulation-based testbed using the
OpenAirInterface (OAI) implementation, considering different MC positions. The
results validate the MC concept and demonstrate that MC positioning
significantly influences network performance. This paper has the potential to
aid network operators and service providers in selecting and deploying MC
architectures for temporary coverage extension and capacity reinforcement in
different environments, including seaports, industrial scenarios, and public
safety.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以防止灾难性故障并优化运行效率，传统方法难以提供全面的维护建议。

Method: 将轴承振动数据（BPFO、BPFI、BSF、FTF频率）序列化为自然语言供LLM处理，结合多代理组件处理维护手册和网络搜索，生成结构化维护建议。

Result: 实验验证表明，系统能有效检测异常并提供上下文相关的维护指导，成功填补了状态监测与可操作维护计划之间的空白。

Conclusion: 该研究推动了LLM在工业维护中的应用，为跨机械组件和工业领域的预测性维护提供了可扩展的框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [4] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务代理工作流的方法，通过明确工具调用目标提升代理成功率6.8%，并减少令牌使用量至四分之一。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理分解中隐含API选择，缺乏对代理的明确指导，导致效率低下。

Method: 为每个代理提供详细的工具调用目标，指导运行时地理空间API的调用。

Result: 代理成功率提高6.8%，令牌使用量减少至四分之一。

Conclusion: GeoFlow通过明确目标显著提升了代理效率和性能。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [5] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 论文提出了一种通过对抗性棋盘游戏评估大型语言模型（LLMs）性能的框架，弥补了传统问答基准方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统问答基准方法依赖数据，无法全面评估LLMs的性能，因此需要一种新的评估框架。

Method: 设计了Qi Town平台，支持5种游戏和20个LLM驱动的玩家，使用Elo评分系统和性能循环图（PLG）定量评估技术能力，并通过积极情绪分数（PSS）评估心理适应性。

Result: 实验表明，LLMs在高压对抗环境中表现出比人类更强的适应性，但技能发挥存在不稳定性。

Conclusion: 该框架为LLMs的全面评估提供了新方法，但LLMs在游戏中的技能不稳定性需进一步研究。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [6] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 比较了三种实现自主网络地理信息系统（AWebGIS）的方法，发现基于小型语言模型（SLM）的客户端方法在准确性和隐私保护方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于云的大型语言模型（LLM）方法在隐私、可扩展性和网络依赖方面的不足。

Method: 比较了三种方法：1）云LLM在线方法；2）经典机器学习离线方法；3）基于微调SLM的客户端方法。

Result: 客户端SLM方法在准确性（0.93精确匹配）和效率上表现最佳，同时减轻服务器负担。

Conclusion: 客户端SLM方法为AWebGIS提供了高效、隐私友好的解决方案。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [7] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 该论文探讨了强化学习（RL）在提升大型语言模型（LLMs）推理能力中的作用，并指出现有基准测试忽略了非理想场景下的性能表现。作者定义了三种非理想场景，并通过实验发现RL微调在理想场景下有效，但在非理想场景中表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注理想场景下的模型推理能力，而忽略了实际应用中常见的非理想场景。作者希望通过研究这些场景，揭示大型模型的推理能力局限性。

Method: 作者使用策略梯度算法对三种LLMs和一种大型视觉语言模型（LVLM）进行RL微调，并在八种公共数据集上测试其性能，重点关注三种非理想场景。

Result: 实验结果显示，RL微调在理想场景下能提升推理能力，但在非理想场景中性能显著下降，表明当前方法的局限性。

Conclusion: 该研究强调大型模型的推理能力常被高估，并呼吁在非理想场景下评估模型性能。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [8] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一种自进化的AI代理，通过元级进化机制提升战略规划能力，显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 解决AI代理在医疗研究中依赖静态策略的局限性，提升其战略规划能力。

Method: 引入HealthFlow，通过元级进化机制自主优化高层问题解决策略，并开发EHRFlowBench基准进行验证。

Result: 实验表明HealthFlow在复杂医疗数据分析任务中表现显著优于现有框架。

Conclusion: HealthFlow标志着从工具使用者到自进化任务管理者的转变，为更自主的AI科学发现铺平道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [9] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 论文提出了一种基于博弈论的新型分子对接框架（Docking Game），通过LoopPlay算法显著提升了配体对接的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前多任务学习模型在配体对接中表现不佳，主要由于配体和蛋白质的结构复杂性差异。

Method: 将蛋白质-配体交互建模为双玩家博弈，开发了LoopPlay算法，通过内外循环交替训练配体和蛋白质玩家。

Result: 实验显示LoopPlay在预测结合模式上比现有方法提升约10%。

Conclusion: 该框架有望提高药物发现中分子对接的准确性。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [10] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 探讨大型语言模型（LLMs）在整合异构城市空间数据中的应用，发现其在特定条件下表现优异，但需结合人工修正。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法和机器学习在整合城市空间数据时存在局限性，LLMs提供了一种灵活且高效的替代方案。

Method: 分析LLMs的空间推理能力，提出结合特征输入和人工修正的“review-and-refine”方法。

Result: LLMs在减少对空间推理依赖时表现良好，结合修正方法能显著提升结果质量。

Conclusion: LLMs是传统方法的有效替代，未来可结合多模态和多样化数据格式进一步优化。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [11] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 论文提出了一种结合离线模仿学习和在线探索的Web导航智能体框架CogniWeb，基于人类认知的双系统理论，实现了高效且性能优越的Web导航。


<details>
  <summary>Details</summary>
Motivation: Web导航是评估通用人工智能（AGI）的重要领域，但现有方法未能有效整合离线学习和在线探索。

Method: 基于双系统认知理论，将智能体分解为快速直觉（System 1）和慢速深思（System 2）模块，并实现为CogniWeb框架。

Result: 在WebArena上的评估显示，CogniWeb成功率为43.96%，同时显著提高了效率（减少75%的token使用）。

Conclusion: CogniWeb通过双系统理论有效整合了离线与在线学习，为Web导航智能体提供了高效且性能优越的解决方案。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [12] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出了MedMKEB，首个用于评估医学多模态大语言模型知识编辑可靠性的综合基准。


<details>
  <summary>Details</summary>
Motivation: 医学知识不断更新，需高效修正模型中的过时或错误信息，但缺乏针对多模态医学知识编辑的系统性评估标准。

Method: 基于高质量医学视觉问答数据集构建MedMKEB，包含反事实修正、语义泛化、知识迁移和对抗鲁棒性等任务，并引入专家验证。

Result: 实验表明现有知识编辑方法在医学领域存在局限性，需开发专门策略。

Conclusion: MedMKEB将作为标准基准，推动可信赖且高效的医学知识编辑算法发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [13] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个基于Qwen3-8B模型的轻量级门尺寸框架，适用于不同工艺节点和电路拓扑，显著减少计算资源和人工依赖。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI方法在模拟电路门尺寸设计中通用性差、依赖大模型和跨工艺节点移植性不足的问题。

Method: 结合微调的Qwen3-8B模型和动态任务特定损失函数，通过全局差分进化和局部粒子群优化进行启发式搜索。

Result: 在180nm、45nm和22nm工艺节点上表现优异，优于AutoCkt，减少86.67%任务的计算资源。

Conclusion: EasySize能显著简化模拟电路设计流程，减少对人工和计算资源的依赖。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [14] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 论文探讨了生成式AI在高等教育中的核心作用，通过实验证明苏格拉底式AI导师能显著提升学生的批判性思维和反思能力，并提出了模块化多代理系统（MAS）的概念。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI如何重塑知识生成与验证的方式，并验证其在教育中的实际效果。

Method: 通过对照实验，比较65名德国师范生使用苏格拉底式AI导师与普通AI聊天机器人的效果。

Result: 使用苏格拉底式AI导师的学生在批判性、独立性和反思性思维方面表现更优。

Conclusion: 研究为混合学习生态系统提供了实证支持和概念框架，强调人机协作与教学对齐的重要性。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [15] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 论文提出了一种基于异构图神经网络（HGNN）的方法，用于修复过程挖掘中事件日志的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实中的事件日志常因数据采集问题导致信息缺失，现有方法依赖过程模型或机器学习模型，但无法全面修复所有属性。

Method: 开发了一种异构图神经网络模型，能够处理不完整事件并修复缺失的所有属性。

Result: 在合成日志和真实日志上评估，相比基于自动编码器的先进方法，表现更优。

Conclusion: HGNN模型在修复事件日志缺失属性方面具有显著优势，尤其在全面修复所有属性上表现突出。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [16] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一个查询感知的动态RAG系统，通过混合文本和图像检索策略提升复杂VQA任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG方法在复杂查询（如多跳推理或实时知识需求）中的局限性。

Method: 引入领域路由器和搜索路由器，动态选择检索策略，支持多模态、多轮和多跳推理。

Result: 在Meta CRAG-MM挑战中显著提升性能，单源、多源和多轮任务分别优于基线5.06%、6.35%和5.03%。

Conclusion: QA-Dragon通过动态混合检索策略有效提升复杂VQA任务的性能。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [17] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 提出了一种结合RDF图数据库和LLM的新框架，用于解决大规模维护组织中专家识别和复杂关系通信管理的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统通信方法无法有效应对信息过载和响应时间延长的问题，尤其是在复杂实体关系中识别专家和管理通信时。

Method: 结合RDF图数据库和LLM，通过自然语言查询实现精确受众定位，并采用规划-编排架构提供透明推理。

Result: 解决方案支持直观查询（如设备、制造商、维护工程师等概念），提供可解释的结果，提升通信效率。

Conclusion: 该框架在提高组织通信效率的同时，保持了系统的可信度。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [18] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种混合架构，将基于决策树的符号推理与大型语言模型的生成能力结合在多智能体框架中，提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中符号模块与神经模块松散耦合的问题，实现更紧密的集成。

Method: 在统一推理系统中嵌入决策树和随机森林作为可调用模块，结合LLM进行归纳推理和交互规划。

Result: 在多个基准测试中表现优异，如ProofWriter（+7.2%）、GSM8k（+5.3%）和ARC（+6.0%）。

Conclusion: 该架构为通用神经符号推理提供了鲁棒、可解释且可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [19] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 论文主张重新定义AI中的'agent'一词，提出一个多维框架以明确其最低要求，并建议标准化术语以提高研究清晰度和政策制定效果。


<details>
  <summary>Details</summary>
Motivation: 由于AI领域对'agent'一词的多重解释导致研究交流、系统评估和政策制定的困难，需要重新定义以消除歧义。

Method: 通过历史分析和当代使用模式，提出一个多维框架，定义'agent'的最低要求，并分类系统的环境交互、学习与适应、自主性、目标复杂性和时间一致性。

Result: 提出了一个清晰的术语框架，支持系统描述和研究可重复性，同时保留了'agent'的多面性。

Conclusion: 建议标准化术语并采用该框架，以提升研究清晰度、可重复性和政策制定的有效性。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [20] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 论文介绍了NomicLaw，一个多智能体模拟系统，用于研究LLM在开放法律和伦理困境中的行为，通过投票和语言策略分析信任与互惠。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在开放多智能体环境中的行为，尤其是涉及法律和伦理困境的讨论，目前缺乏实证理解。

Method: 使用NomicLaw模拟系统，让LLM参与协作立法，通过提出规则、论证和投票来响应法律案例，定量和定性分析行为。

Result: 实验显示LLM能自发形成联盟、背叛信任，并调整语言策略以影响集体决策，揭示了其潜在的社会推理和说服能力。

Conclusion: 研究为未来能自主协商、协调和起草法律的AI系统设计提供了见解，展示了开源LLM的社会能力。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [21] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [22] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM提出了一种结构化可验证奖励模型，用于解决多模态推理任务中部分正确性的问题，显著提升了模型在复杂任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机制仅提供整体二元评分，无法处理多子问题的复杂推理任务，限制了模型的学习效果。

Method: StructVRM通过训练模型验证器提供细粒度反馈，评估语义和数学等价性，而非依赖严格的字符串匹配。

Result: Seed-StructVRM在12个多模态基准测试中的6个及新构建的高难度STEM-Bench上达到最优性能。

Conclusion: 结构化可验证奖励训练是提升多模态模型在复杂推理任务中能力的有效方法。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [23] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 该论文提出了一种用于智能交通系统的实时数据驱动预测性维护方法，结合了样本预处理、增量分类和结果解释，实验结果显示高准确性和F-measure。


<details>
  <summary>Details</summary>
Motivation: 为智能交通系统开发一种实时预测性维护解决方案，以提前识别故障并支持主动维护决策。

Method: 采用包含样本预处理、增量分类和解释性模块的在线处理流程，结合统计和频率特征提取。

Result: 实验在Porto地铁数据集上达到98%的F-measure和99%的准确率，验证了方法的高效性和鲁棒性。

Conclusion: 该方法在铁路预测性维护中表现出色，能够平衡故障检测和减少误报，提升服务可用性和安全性。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [24] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个新的基准框架，用于评估视觉语言模型（VLMs）对物理原理的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: VLMs在复杂动态环境中缺乏细节关注和精确行动规划，导致性能不佳，而现实任务需要高级空间推理和长期规划。

Method: 通过一系列具有挑战性的模拟环境，DeepPHY系统地评估VLMs对物理原理的理解，并整合多难度环境和细粒度指标。

Result: 评估发现，即使是先进的VLMs也难以将描述性物理知识转化为精确的预测控制。

Conclusion: DeepPHY为评估VLMs的物理推理能力提供了有效工具，揭示了其在实际应用中的局限性。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [25] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: LLMs正在改变有机合成化学的方式，通过结合图神经网络、量子计算和实时光谱技术，加速发现周期并推动绿色化学。但仍存在数据集偏见、推理不透明等限制，需通过开放基准和可解释界面解决。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何成为化学实验室的实用工具，加速分子创新并推动数据驱动的绿色化学。

Method: 结合LLMs与图神经网络、量子计算和实时光谱技术，优化合成路线预测和实验执行。

Result: LLMs显著缩短了发现周期，支持更高效的合成化学，但仍需解决数据集偏见和安全性问题。

Conclusion: 通过开放基准和可解释界面，LLMs有望实现快速、可靠且包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [26] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 论文探讨了AI对齐中的地理变异性问题，强调需考虑文化、政治和法律差异，提出时空感知对齐的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 现有AI对齐研究多关注偏见和不平等，但地理变异性未被充分探索，导致模型输出可能与现实或地区规范不符。

Method: 回顾关键地理研究问题，提出未来研究方向，并概述评估对齐敏感性的方法。

Result: 指出AI输出需根据用户地理位置和上下文调整，如Google Maps对克什米尔边界的不同渲染。

Conclusion: 呼吁开发时空感知的对齐方法，而非一刀切方案，以适应全球多样性。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [27] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 研究提出Bench-2-CoP框架，量化AI评估基准与欧盟AI法案要求的差距，发现现有基准严重忽视关键功能能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估基准未能覆盖欧盟AI法案关注的系统性风险，亟需量化这一差距以改进评估工具和政策。

Method: 使用LLM-as-judge分析，将194,955个基准问题映射到欧盟AI法案的能力分类中。

Result: 发现评估生态严重偏向行为倾向（如幻觉倾向占53.7%），关键功能能力（如失控场景）几乎未被覆盖。

Conclusion: 研究揭示了评估与法规的严重脱节，为政策制定者和开发者提供了改进方向，以促进更安全合规的AI。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [28] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 使用小型高效LLM生成多样化ERC数据集，补充现有基准，提升分类器性能。


<details>
  <summary>Details</summary>
Motivation: 解决ERC数据稀缺、来源偏见和标签主观性问题，探索LLM在ERC数据生成中的应用。

Method: 利用小型通用LLM生成六种新数据集，补充三大ERC基准，评估其在分类和标签平衡中的作用。

Result: 生成数据集显著提升ERC分类器性能，增强模型鲁棒性。

Conclusion: 小型LLM生成的数据集能有效补充ERC任务，改善模型表现。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [29] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign是一种高效的后训练框架，结合监督微调（SFT）和直接偏好优化（DPO），通过多维质量指标自动筛选高质量数据，显著提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型的推理能力通常需要大量数据和计算资源，现有方法依赖启发式或任务特定策略，难以扩展。

Method: 提出InfiAlign框架，整合SFT和DPO，并设计自动数据筛选管道，从开源推理数据集中选择高质量数据。

Result: 在Qwen2.5-Math-7B-Base模型上，仅用12%的训练数据即达到与DeepSeek-R1-Distill-Qwen-7B相当的性能，数学推理任务提升3.89%。

Conclusion: 结合数据选择和全阶段后训练，InfiAlign提供了一种高效、可扩展的大模型对齐方案。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [30] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL框架通过结合LLM引导的随机探索和路径过滤，解决了现有图检索方法在结构化知识处理中的局限性，显著提升了知识图谱问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要处理非结构化数据，对结构化知识（如知识图谱）处理能力有限，且图检索方法难以平衡检索广度和精度。

Method: 提出GRAIL框架，结合LLM引导的随机探索与路径过滤，生成细粒度推理轨迹，并通过两阶段训练学习动态决策策略。

Result: 在三个知识图谱问答数据集上，GRAIL平均准确率提升21.01%，F1值提升22.43%。

Conclusion: GRAIL有效解决了图检索中的精度控制问题，显著提升了推理性能，适用于大规模知识图谱的交互式检索。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [31] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种通用、模块化的框架，用于评估代理任务完成情况，通过分解任务和验证每一步来模拟人类评估，相比现有方法（如LLM-as-a-Judge）在准确性上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法（如LLM-as-a-Judge）仅关注最终输出，忽略了逐步推理过程，且现有Agent-as-a-Judge系统局限于特定领域。需要一种通用框架来填补这一空白。

Method: 设计了一个模块化框架，将任务分解为子任务并验证每一步，利用代理的输出和推理信息，最终聚合模块结果生成评估结论。

Result: 在GAIA和BigCodeBench基准测试中，提出的Judge Agent比基于GPT-4o的LLM-as-a-Judge基线分别提高了4.76%和10.52%的评估准确性。

Conclusion: 该框架展示了通用评估方法的潜力，能够更接近人类评估效果，适用于多样化任务领域。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [32] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI是一个基于AI的工具，用于从推荐信中自动评估申请者的领导能力，采用自然语言处理和大语言模型（如RoBERTa和LLAMA），在测试数据中表现出高准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 推荐信是评估申请者能力的重要材料，但人工审阅耗时耗力。LORI旨在通过自动化分析提升效率，并为申请者的专业成长提供反馈。

Method: 利用自然语言处理技术和大语言模型（RoBERTa和LLAMA）识别推荐信中的领导力属性（如团队合作、沟通和创新）。

Result: RoBERTa模型在测试数据中表现优异，加权F1分数为91.6%，精确度为92.4%，召回率为91.6%。

Conclusion: LORI能够高效准确地评估申请者的领导能力，适合整合到研究生招生流程中，提升评估的全面性和自动化程度。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [33] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate框架通过多视角代理辩论动态检测多模态有害内容，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体多模态环境中，有害意图（如讽刺、仇恨言论）因跨模态矛盾和文化快速变化而难以识别。

Method: 提出MV-Debate框架，包含四个互补代理（表面分析、深度推理、模态对比、社会情境分析），通过迭代辩论和动态反思门控优化检测。

Result: 在三个基准数据集上，MV-Debate显著优于单模型和现有多代理辩论基线。

Conclusion: 多代理辩论框架在安全关键在线环境中提升社会意图检测的可靠性。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [34] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 论文提出主动推理（AIF）为解决自主AI代理学习中的奖励工程瓶颈问题提供了关键基础，通过最小化自由能量的内在驱动替代外部奖励信号。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖大量人工设计的奖励函数，面临可扩展性挑战，阻碍了真正自主智能的发展。

Method: 结合主动推理（AIF）和大型语言模型（LLMs），利用内在驱动替代外部奖励，实现高效学习和决策。

Result: 提出了一种能够自主制定目标、适应变化并通过统一贝叶斯目标平衡探索与利用的AI框架。

Conclusion: AIF与LLMs的结合为开发既能自主学习又符合人类价值观的AI系统提供了可行路径。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [35] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 论文提出LearnerAgent，一个基于LLM的多智能体框架，模拟真实教学环境，研究人类学习行为。通过心理特征构建学习者，跟踪动态学习过程，发现不同学习者的认知和行为模式与其心理特征一致。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉学习动态、跟踪进展或提供可解释性，因此提出LearnerAgent框架来解决这些问题。

Method: 基于LLM构建多智能体框架，设计心理特征各异的学习者（如Deep、Surface、Lazy等），通过知识获取、策略选择、测试和互动跟踪学习过程。

Result: 研究发现：1）Deep Learner持续认知增长；2）学习者行为与心理特征一致；3）General Learner自我效能感高；4）基础LLM默认行为类似“勤奋但脆弱的Surface Learner”。

Conclusion: LearnerAgent能有效模拟真实学习场景，揭示LLM行为特征，为心理学和智能系统研究提供新视角。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [36] [Energy Efficient Transmitter Creation by Consuming Free Energy in Molecular Communication](https://arxiv.org/abs/2508.04805)
*Dongliang Jing,Linjuan Li,Zhen Cheng,Lin Lin,Andrew W. Eckford*

Main category: cs.IT

TL;DR: 论文提出了一种从环境中获取分子并通过能量消耗分离混合分子的发射器设计，优化了分子通信系统的性能。


<details>
  <summary>Details</summary>
Motivation: 环境中的分子混合物和初始浓度相同限制了高保真传输技术（如MoSK）的应用，因此需要设计高效的分子分离方法。

Method: 设计了一个发射器，从环境中获取分子并存储在两个储层中，通过能量消耗将分子转移以实现分离，并研究了能量高效的转移策略。

Result: 结果表明，转移初始浓度较高的分子能提升性能，而每次转移使用较少的分子能进一步提高效率。

Conclusion: 研究为通过能量高效的分子转移技术优化分子通信系统提供了有价值的见解。

Abstract: Information molecules play a crucial role in molecular communication (MC),
acting as carriers for information transfer. A common approach to get
information molecules in MC involves harvesting them from the environment;
however, the harvested molecules are often a mixture of various environmental
molecules, and the initial concentration ratios in the reservoirs are
identical, which hampers high-fidelity transmission techniques such as
molecular shift keying (MoSK). This paper presents a transmitter design that
harvests molecules from the surrounding environment and stores them in two
reservoirs. To separate the mixed molecules, energy is consumed to transfer
them between reservoirs. Given limited energy resources, this work explores
energy-efficient strategies to optimize transmitter performance. Through
theoretical analysis and simulations, we investigate different methods for
moving molecules between reservoirs. The results demonstrate that transferring
higher initial concentration molecules enhances transmitter performance, while
using fewer molecules per transfer further improves efficiency. These findings
provide valuable insights for optimizing MC systems through energy-efficient
molecule transfer techniques.

</details>


### [37] [Energy Efficiency Optimization for Movable Antenna-Aided Communication Systems](https://arxiv.org/abs/2508.05033)
*Jingze Ding,Zijian Zhou,Yuping Zhao,Bingli Jiao*

Main category: cs.IT

TL;DR: 研究通过优化可移动天线（MA）系统的位置来提高能效，考虑移动带来的时间延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 探讨MA系统在能效方面的潜力，尽管移动会带来额外开销。

Method: 推导单用户下行链路系统的能效上限，提出基于连续凸近似的算法优化MA位置。

Result: 仿真表明，MA系统相比固定天线（FPA）系统能效更高。

Conclusion: MA系统在能效优化方面具有优势，尽管存在移动开销。

Abstract: This paper investigates the energy efficiency optimization for movable
antenna (MA) systems by considering the time delay and energy consumption
introduced by MA movement. We first derive the upper bound on energy efficiency
for a single-user downlink communication system, where the user is equipped
with a single MA. Then, the energy efficiency maximization problem is
formulated to optimize the MA position, and an efficient algorithm based on
successive convex approximation is proposed to solve this non-convex
optimization problem. Simulation results show that, despite the overhead caused
by MA movement, the MA system can still improve the energy efficiency compared
to the conventional fixed-position antenna (FPA) system.

</details>


### [38] [Two tales for a geometric Jensen--Shannon divergence](https://arxiv.org/abs/2508.05066)
*Frank Nielsen*

Main category: cs.IT

TL;DR: 论文提出了一种扩展的几何Jensen-Shannon散度（G-JSD），适用于正密度而不需归一化几何混合，并给出了其与G-JSD的差距及上下界。


<details>
  <summary>Details</summary>
Motivation: G-JSD在机器学习和信息科学中因其高斯分布间的闭式解而流行，但需归一化几何混合。本文旨在扩展其适用范围。

Method: 提出扩展的G-JSD定义，适用于正密度，并分析其与G-JSD的差距及上下界。针对多元高斯分布给出闭式解。

Result: 扩展的G-JSD与G-JSD的差距被明确量化，并提供了上下界。多元高斯分布下的闭式解被推导。

Conclusion: 扩展的G-JSD和G-JSD可视为普通JSD的正则化形式，扩展了其应用范围。

Abstract: The geometric Jensen--Shannon divergence (G-JSD) gained popularity in machine
learning and information sciences thanks to its closed-form expression between
Gaussian distributions. In this work, we introduce an alternative definition of
the geometric Jensen--Shannon divergence tailored to positive densities which
does not normalize geometric mixtures. This novel divergence is termed the
extended G-JSD as it extends to more general positive measures. We give
explicitly the gap between the extended G-JSD and G-JSD when considering
probability densities, and report both lower and upper bounds in terms of other
statistical divergences. We derive corresponding closed-form expressions when
considering the case of multivariate Gaussian distributions often met in
applications. Finally, we show that these two types of geometric JSDs, the
G-JSD and the extended G-JSD, can be interpreted as regularizations of the
ordinary JSD by additive terms.

</details>


### [39] [Necessity of Block Designs for Optimal Locally Private Distribution Estimation](https://arxiv.org/abs/2508.05110)
*Abigail Gentle*

Main category: cs.IT

TL;DR: 论文证明了在局部差分隐私下，只有基于平衡不完全区组设计的协议才能达到最优误差，并完全描述了此类最优协议的特征。


<details>
  <summary>Details</summary>
Motivation: 研究在局部差分隐私模型中，是否存在其他构造也能达到最优误差，以完善对最优协议的理解。

Method: 通过理论证明，分析协议的最优误差条件，并与平衡不完全区组设计关联。

Result: 证明只有基于平衡不完全区组设计的协议才能达到最优误差，且最优通信协议仅限于对称平衡不完全区组设计。

Conclusion: 该研究完全描述了局部差分隐私下最优协议的特征，为实际应用提供了明确指导。

Abstract: Local differential privacy represents the gold standard for preserving the
privacy of data before it leaves the device, and distribution estimation under
this model has been well studied. Recently, protocols built upon balanced
incomplete block designs were shown to achieve optimal error for this problem.
However, it remained unknown whether other constructions could also be optimal.
We resolve this question by proving that any protocol achieving optimal error
must correspond to some balanced incomplete block design. This result, combined
with prior work, completely characterises the set of optimal protocols for this
problem. As a consequence, the protocols that achieve optimal error and optimal
communication are only those based on symmetrical balanced incomplete block
designs.

</details>


### [40] [Neural Estimation of Information Leakage for Secure Communication System Design](https://arxiv.org/abs/2508.05176)
*Darius S. Heerklotz,Ingo Schroeder,Pin-Hsun Lin,Christian Deppe,Eduard A. Jorswieck*

Main category: cs.IT

TL;DR: 提出了一种基于神经网络的互信息估计器，用于量化通信系统中的信息泄漏，并设计了适用于离散和连续变量的方法。通过改进的变分对比对数比上界框架，该方法能够扩展到更高的块长度（如255），并支持通用哈希族的设计。


<details>
  <summary>Details</summary>
Motivation: 低估泄漏会危及保密性，而高估则可能导致系统设计效率低下，因此需要可靠的泄漏估计器。

Method: 基于变分对比对数比上界框架，提出了一种改进的互信息估计器，使用神经网络参数化的伯努利专家混合模型，适用于离散和连续变量。

Result: 仿真结果表明，先前的方法显著低估了互信息，尤其是在高块长度下。所提方法可将块长度扩展到255，并有望在更多训练数据和更大模型下进一步扩展。

Conclusion: 所提估计器和自适应哈希设计框架为有限块长度下的物理层安全提供了一种实用方法。

Abstract: Underestimating the leakage can compromise secrecy, while overestimating it
may lead to inefficient system design. Therefore, a reliable leakage estimator
is essential. Neural network-based estimators provide a data-driven way to
estimate mutual information without requiring full knowledge of the channel or
source distributions. In this work, we aim to scale the blocklength of a
wiretap code such that the estimator can still feasibly operate. We propose an
improved mutual information estimator based on the variational contrastive
log-ration upper bound framework, tailored for both discrete and continuous
variables. By using a mixture of Bernoulli experts parameterized by neural
networks, the estimator is able to quantify information leakage in
communication systems, which employ complex data processing like universal hash
family. We further propose a method to utilize the proposed estimator to design
the universal hash family for a wiretap code or secret key generation design.
Simulation results show thatprior methods significantly underestimate the
mutual information, particularly when using universal hash family for higher
blocklengths ($n\gg$16). The proposed method can scale the blocklength up to
255, and we conjecture that the design can scale well to even higher
blocklengths given adequate training data and model size. Additionally, we
contend that our proposed estimator and adaptive hash design framework offer a
practical approach for extending physical layer security considerations for
wiretap channels into the finite blocklength regime.

</details>


### [41] [Simultaneous Rational Function Codes: Improved Analysis Beyond Half the Minimum Distance with Multiplicities and Poles](https://arxiv.org/abs/2508.05284)
*Matteo Abbondati,Eleonora Guerrini,Romain Lebreton*

Main category: cs.IT

TL;DR: 本文扩展了Abbondati等人（2024）关于解码同时有理函数编码的工作，解决了多重性和极点（分母的零点）两种重要场景。通过多精度评估，推广了有理码的多重性结果，并利用Guerrini等人（2023）的混合模型，扩展到可能具有极点的有理函数向量。贡献包括：解码算法失败概率的严格分析、扩展到混合模型以处理非随机错误、以及在更一般的多重性背景下对极点的改进分析。


<details>
  <summary>Details</summary>
Motivation: 解决有理函数编码中多重性和极点的问题，提升解码算法的鲁棒性和适用范围。

Method: 1. 推广有理码的多重性结果，采用多精度评估；2. 利用混合模型处理极点问题；3. 提供解码算法失败概率的严格分析。

Result: 理论结果为更复杂场景下的重构失败提供了全面的概率分析，提升了有理函数编码的纠错能力。

Conclusion: 本文通过解决多重性和极点问题，显著推进了有理函数编码的纠错技术，为更复杂的应用场景提供了理论支持。

Abstract: In this paper, we extend the work of Abbondati et al. (2024) on decoding
simultaneous rational function codes by addressing two important scenarios:
multiplicities and poles (zeros of denominators). First, we generalize previous
results to rational codes with multiplicities by considering evaluations with
multi-precision. Then, using the hybrid model from Guerrini et al. (2023), we
extend our approach to vectors of rational functions that may present poles.
Our contributions include: a rigorous analysis of the decoding algorithm's
failure probability that generalizes and improves several previous results, an
extension to a hybrid model handling situations where not all errors can be
assumed random, and a new improved analysis in the more general context
handling poles within multiplicities. The theoretical results provide a
comprehensive probabilistic analysis of reconstruction failure in these more
complex scenarios, advancing the state of the art in error correction for
rational function codes.

</details>


### [42] [Fundamental limit of Sum Capacity in Pinching Antenna Assisted Multiple Access Channel](https://arxiv.org/abs/2508.05309)
*Guangji Chen,Qingqing Wu,Kangda Zhi*

Main category: cs.IT

TL;DR: 研究了PASS辅助多址信道的容量极限，发现动态pinching波束成形在理想情况下可最大化信道增益，无需NOMA方案。


<details>
  <summary>Details</summary>
Motivation: 探索PASS在多址信道中的容量极限，优化无线通信性能。

Method: 采用动态pinching波束成形和NOMA方案，分析理想和有限波束成形向量下的性能。

Result: 理想情况下，交替传输可最大化信道增益；有限情况下，提出了下界。数值结果验证了理论。

Conclusion: 动态pinching波束成形能显著提高容量，NOMA在理想情况下非必需。

Abstract: Pinching antenna systems (PASSs) have recently shown their promising ability
to flexibly reconfigure wireless channels via dynamically adjusting the
positions of pinching antennas over a dielectric waveguide, termed as pinching
beamforming. This paper studies the fundamental limit of the sum capacity for a
PASSassisted multiple access channel, in which multiple users transmit
individual messages to a BS under the average power constraint. To this end, we
consider a dynamic pinching beamforming setup, where multiple pinching
beamforming vectors are employed in a transmission period and the
capacity-achieving non-orthogonal multiple access (NOMA) based transmission
scheme is considered. For the ideal case with an asymptotically large number of
pinching beamforming vectors, we unveil that the optimal transmission scheme is
alternating transmission among each user with its channel power gain maximized
by dynamic pinching beamforming, which implies that the NOMA-based transmission
scheme is not needed. The corresponding sum-rate is derived in closed-form
expression, which serves as the upper bound of the sum-capacity. Inspired by
this result, a lower bound of the sum-rate under an arbitrarily finite number
of pinching beamforming vectors is obtained. Numerical results validate our
theoretical findings and illustrate the practical significance of using dynamic
pinching beamforming to improve the sum capacity.

</details>


### [43] [$\mathbb{F}_{2}\mathbb{F}_{4}$-Additive Complementary Dual Codes](https://arxiv.org/abs/2508.05317)
*S. Ouagagui,N. Benbelkacem,A. Batoul,T. Abualrub*

Main category: cs.IT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we investigate the structure and properties of additive
complementary dual (ACD) codes over the mixed alphabet
$\mathbb{F}_2\mathbb{F}_4$ relative to a certain inner product defined over
$\mathbb{F}_2\mathbb{F}_4$. We establish sufficient conditions under which such
codes are additive complementary dual (ACD) codes. We also show that ACD codes
over $\mathbb{F}_{2}\mathbb{F}_{4}$ can be applied to construct binary linear
complementary dual codes as their images under the linear map $W$. Notably, we
prove that if the binary image of a code is LCD, then the original code is
necessarily ACD. An example is given where the image is a distance-optimal
binary LCD code.

</details>


### [44] [On the entropy growth of sums of iid discrete random variables](https://arxiv.org/abs/2508.05348)
*Riccardo Castellano,Pavel Sekatski*

Main category: cs.IT

TL;DR: 本文推导了独立同分布离散随机变量和的香农熵的渐近下界，引入了一个新的量——不相称秩。


<details>
  <summary>Details</summary>
Motivation: 研究独立同分布离散随机变量和的熵的渐近行为，特别是如何用不相称秩来描述这种行为的界限。

Method: 通过分析多项分布和格点随机变量和的已知熵表达式，推导出一般情况下的渐近下界，而不依赖中心极限定理。

Result: 得到了熵的渐近下界表达式：$H \geq \frac{r(X)}{2}\log(N) + {\it cst}$，其中$r(X)$为不相称秩。

Conclusion: 引入的不相称秩为研究离散随机变量和的熵提供了新的工具，且推导方法不依赖中心极限定理。

Abstract: We derive an asymptotic lower bound on the Shannon entropy $H$ of sums of $N$
arbitrary iid discrete random variables. The derived bound $H \geq
\frac{r(X)}{2}\log(N) + {\it cst}$ is given in terms of the incommensurability
rank $r(X)$ of the random variable -- a positive integer quantity that we
introduce. The derivation does not rely on central limit theorems, but builds
upon the known expressions of the asymptotic entropy of the multinomial
distribution and sums of iid lattice random variables, which correspond to the
case $r(X)=1$.

</details>


### [45] [Communication-Efficient Distributed Computing Through Combinatorial Multi-Access Models](https://arxiv.org/abs/2508.05426)
*Shanuja Sasi,Onur Günlü*

Main category: cs.IT

TL;DR: 论文提出了一种多接入分布式计算（MADC）模型，利用组合设计和编码理论优化通信开销，减少计算负载。


<details>
  <summary>Details</summary>
Motivation: 传统MapReduce框架需要文件复制，MADC通过编码技术避免复制，降低通信开销。

Method: 采用组合设计（t-designs）构建高效编码方案，连接t-designs与MapReduce Arrays，优化通信负载。

Result: 方案显著减少了reducer节点数量，但通信成本有所增加。

Conclusion: MADC模型通过组合设计实现了高效的分布式计算，为未来研究提供了灵活性。

Abstract: This paper explores the multi-access distributed computing (MADC) model, a
novel distributed computing framework where mapper and reducer nodes are
distinct entities. Unlike traditional MapReduce frameworks, MADC leverages
coding-theoretic techniques to minimize communication overhead without
necessitating file replication across mapper nodes. We introduce a new approach
utilizing combinatorial designs, specifically t-designs, to construct efficient
coding schemes that achieve a computation load of 1. By establishing a
connection between t-designs and MapReduce Arrays, we characterize the
achievable communication loads and demonstrate the flexibility of our method in
selecting the number of reducer nodes. The proposed scheme significantly
reduces the number of reducer nodes relative to existing combinatorial topology
schemes, at the expense of increased communication cost.

</details>


### [46] [Long Polar vs. LDPC Codes under Complexity-Constrained Decoding](https://arxiv.org/abs/2508.05485)
*Felix Krieg,Marvin Rübenacke,Andreas Zunker,Stephan ten Brink*

Main category: cs.IT

TL;DR: 长极化码在有限迭代次数下优于LDPC码，尤其在简化连续取消解码（SSC）中表现更优。


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，即极化码在长码块下不如LDPC码，指出实际应用中迭代次数受限。

Method: 比较极化码的连续取消（SC）解码与LDPC码的置信传播（BP）解码，在固定点对数似然比（LLR）操作次数相同的情况下。

Result: 长极化码在SC解码下表现优于LDPC码，SSC解码复杂度更低且操作更少。

Conclusion: 极化码在长码块和实际约束下仍具竞争力，尤其在SSC解码中优势显著。

Abstract: The prevailing opinion in industry and academia is that polar codes are
competitive for short code lengths, but can no longer keep up with low-density
parity-check (LDPC) codes as block length increases. This view is typically
based on the assumption that LDPC codes can be decoded with a large number of
belief propagation (BP) iterations. However, in practice, the number of
iterations may be rather limited due to latency and complexity constraints. In
this paper, we show that for a similar number of fixed-point log-likelihood
ratio (LLR) operations, long polar codes under successive cancellation (SC)
decoding outperform their LDPC counterparts. In particular, simplified
successive cancellation (SSC) decoding of polar codes exhibits a better
complexity scaling than $N \log{N}$ and requires fewer operations than a single
BP iteration of an LDPC code with the same parameters.

</details>


### [47] [Multivariate Partial Information Decomposition: Constructions, Inconsistencies, and Alternative Measures](https://arxiv.org/abs/2508.05530)
*Aobo Lyu,Andrew Clark,Netanel Raviv*

Main category: cs.IT

TL;DR: 论文探讨了多元系统中信息分解的局限性，提出了新的测量方法以避免不一致性。


<details>
  <summary>Details</summary>
Motivation: 研究多元系统中复杂依赖关系的量化问题，解决现有部分信息分解（PID）框架的不足。

Method: 通过提供两源PID的闭式公式，证明三源及以上PID的不一致性，并提出新的多元独特和协同信息测量方法。

Result: 发现PID框架在三源及以上存在根本性不一致，提出新方法在理论和实验中表现良好。

Conclusion: 需要新的多元信息分解框架，以解决现有PID的局限性。

Abstract: While mutual information effectively quantifies dependence between two
variables, it cannot capture complex, fine-grained interactions that emerge in
multivariate systems.The Partial Information Decomposition (PID) framework was
introduced to address this by decomposing the mutual information between a set
of source variables and a target variable into fine-grained information atoms
such as redundant, unique, and synergistic components. In this work, we review
the axiomatic system and desired properties of the PID framework and make three
main contributions. First, we resolve the two-source PID case by providing
explicit closed-form formulas for all information atoms that satisfy the full
set of axioms and desirable properties. Second, we prove that for three or more
sources, PID suffers from fundamental inconsistencies: we present a
three-variable counterexample where the sum of atoms exceeds the total
information, and prove an impossibility theorem showing that no lattice-based
decomposition can be consistent for all subsets when the number of sources
exceeds three. Finally, we deviate from the PID lattice approach to avoid its
inconsistencies, and present explicit measures of multivariate unique and
synergistic information. Our proposed measures, which rely on new systems of
random variables that eliminate higher-order dependencies, satisfy key axioms
such as additivity and continuity, provide a robust theoretical explanation of
high-order relations, and show strong numerical performance in comprehensive
experiments on the Ising model. Our findings highlight the need for a new
framework for studying multivariate information decomposition.

</details>


### [48] [Latency Minimization for Multi-AAV-Enabled ISCC Systems with Movable Antenna](https://arxiv.org/abs/2508.05574)
*Yiyang Chen,Wenchao Liu,Chunjie Wang,Yinyu Wu,Xuhui Zhang,Yanyan Shen*

Main category: cs.IT

TL;DR: 本文研究了基于自主飞行器（AAV）的集成感知、通信与计算系统，通过引入可移动天线（MAs）提升性能。提出了一种双层迭代算法优化MA位置、资源分配和波束成形，显著降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过可移动天线（MAs）提升AAV系统的整体性能，特别是在感知、通信和计算任务中的协同优化。

Method: 提出了一种双层迭代算法，结合粒子群优化和凸优化，联合优化MA位置、计算资源分配和传输波束成形。

Result: 仿真结果表明，所提方案在延迟性能上显著优于基线方案。

Conclusion: 通过MAs的引入和联合优化，系统性能得到显著提升，验证了所提算法的有效性。

Abstract: This paper investigates an autonomous aerial vehicle (AAV)-enabled integrated
sensing, communication, and computation system, with a particular focus on
integrating movable antennas (MAs) into the system for enhancing overall system
performance. Specifically, multiple MA-enabled AVVs perform sensing tasks and
simultaneously transmit the generated computational tasks to the base station
for processing. To minimize the maximum latency under the sensing and resource
constraints, we formulate an optimization problem that jointly coordinates the
position of the MAs, the computation resource allocation, and the transmit
beamforming. Due to the non-convexity of the objective function and strong
coupling among variables, we propose a two-layer iterative algorithm leveraging
particle swarm optimization and convex optimization to address it. The
simulation results demonstrate that the proposed scheme achieves significant
latency improvements compared to the baseline schemes.

</details>
