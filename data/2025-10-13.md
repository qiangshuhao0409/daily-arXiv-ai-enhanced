<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.IT](#cs.IT) [Total: 9]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Wireless Datasets for Aerial Networks](https://arxiv.org/abs/2510.08752)
*Amir Hossein Fahim Raouf,Donggu Lee,Mushfiqur Rahman,Saad Masrur,Gautham Reddy,Cole Dickerson,Md Sharif Hossen,Sergio Vargas Villar,Anıl Gürses,Simran Singh,Sung Joon Maeng,Martins Ezuma,Christopher Roberts,Mohamed Rabeek Sarbudeen,Thomas J. Zajkowski,Magreth Mushi,Ozgur Ozdemir,Ram Asokan,Ismail Guvenc,Mihail L. Sichitiu,Rudra Dutta*

Main category: cs.NI

TL;DR: 本文对AERPAW空中平台收集的公开无线数据集进行全面调查，涵盖蜂窝网络、频谱测量、4G/5G网络、LoRaWAN等多种场景，旨在为无人机无线网络研究提供高质量实证数据支持。


<details>
  <summary>Details</summary>
Motivation: 无人机集成到5G-Advanced和6G网络需要高质量实证数据来设计和优化空中网络，但生成可复现的空中无线数据集面临独特挑战。

Method: 调查AERPAW平台收集的多种无线数据集，包括硬件软件配置、数据格式、代表性结果，并提供数据集和处理脚本的完整参考。

Result: 提供了包括原始I/Q样本、频谱测量、4G/5G网络数据、LoRaWAN网络、RF传感器网络等多种空中无线数据集，支持传播模型验证和机器学习算法开发。

Conclusion: 通过提供全面可复现的空中无线数据集，指导研究社区有效利用这些数据验证传播模型、开发机器学习算法，推动下一代空中无线系统发展。

Abstract: The integration of unmanned aerial vehicles (UAVs) into 5G-Advanced and
future 6G networks presents a transformative opportunity for wireless
connectivity, enabling agile deployment and improved LoS communications.
However, the effective design and optimization of these aerial networks depend
critically on high-quality, empirical data. This paper provides a comprehensive
survey of publicly available wireless datasets collected from an airborne
platform called Aerial Experimentation and Research Platform on Advanced
Wireless (AERPAW). We highlight the unique challenges associated with
generating reproducible aerial wireless datasets, and review the existing
related works in the literature. Subsequently, for each dataset considered, we
explain the hardware and software used, present the dataset format, provide
representative results, and discuss how these datasets can be used to conduct
additional research. The specific aerial wireless datasets presented include
raw I/Q samples from a cellular network over different UAV trajectories,
spectrum measurements at different altitudes, flying 4G base station (BS), a
5G-NSA Ericsson network, a LoRaWAN network, an radio frequency (RF) sensor
network for source localization, wireless propagation data for various
scenarios, and comparison of ray tracing and real-world propagation scenarios.
References to all datasets and post-processing scripts are provided to enable
full reproducibility of the results. Ultimately, we aim to guide the community
toward effective dataset utilization for validating propagation models,
developing machine learning algorithms, and advancing the next generation of
aerial wireless systems.

</details>


### [2] [Prioritizing Latency with Profit: A DRL-Based Admission Control for 5G Network Slices](https://arxiv.org/abs/2510.08769)
*Proggya Chakraborty,Aaquib Asrar,Jayasree Sengupta,Sipra Das Bit*

Main category: cs.NI

TL;DR: 提出了DePSAC方案，通过延迟感知奖励函数和Boltzmann探索机制，在5G网络切片中实现更好的QoS-利润权衡，提升URLLC切片延迟性能和整体利润。


<details>
  <summary>Details</summary>
Motivation: 现有DRL框架主要关注利润优化而忽略服务延迟，可能导致对延迟敏感切片的QoS违规，且epsilon-greedy探索导致收敛不稳定。

Method: 基于DRL的方法，采用延迟感知奖励函数（延迟惩罚机制）和Boltzmann探索策略，在模拟5G核心网络上实现切片准入控制。

Result: 相比DSARA基线，在整体利润、URLLC切片延迟降低、接受率和资源消耗方面均有显著提升。

Conclusion: DePSAC方案在5G网络切片场景中有效实现了更好的QoS-利润权衡，验证了延迟感知奖励和Boltzmann探索的有效性。

Abstract: 5G networks enable diverse services such as eMBB, URLLC, and mMTC through
network slicing, necessitating intelligent admission control and resource
allocation to meet stringent QoS requirements while maximizing Network Service
Provider (NSP) profits. However, existing Deep Reinforcement Learning (DRL)
frameworks focus primarily on profit optimization without explicitly accounting
for service delay, potentially leading to QoS violations for latency-sensitive
slices. Moreover, commonly used epsilon-greedy exploration of DRL often results
in unstable convergence and suboptimal policy learning. To address these gaps,
we propose DePSAC -- a Delay and Profit-aware Slice Admission Control scheme.
Our DRL-based approach incorporates a delay-aware reward function, where
penalties due to service delay incentivize the prioritization of
latency-critical slices such as URLLC. Additionally, we employ Boltzmann
exploration to achieve smoother and faster convergence. We implement and
evaluate DePSAC on a simulated 5G core network substrate with realistic Network
Slice Request (NSLR) arrival patterns. Experimental results demonstrate that
our method outperforms the DSARA baseline in terms of overall profit, reduced
URLLC slice delays, improved acceptance rates, and improved resource
consumption. These findings validate the effectiveness of the proposed DePSAC
in achieving better QoS-profit trade-offs for practical 5G network slicing
scenarios.

</details>


### [3] [Characterizing 5G User Throughput via Uncertainty Modeling and Crowdsourced Measurements](https://arxiv.org/abs/2510.09239)
*Javier Albert-Smet,Zoraida Frias,Luis Mendo,Sergio Melones,Eduardo Yraola*

Main category: cs.NI

TL;DR: 提出了一种基于众包测量的不确定性感知和可解释的下行用户吞吐量估计方法，分析了从4G到5G SA演进中吞吐量瓶颈从无线接入网向传输和服务层转移的趋势。


<details>
  <summary>Details</summary>
Motivation: 5G网络容量提升使连接瓶颈转向网络深层，传统方法（如路测和运营商计数器）成本高、范围有限，且无法捕捉端到端服务质量及其变异性。

Method: 利用大规模众包测量数据（包括端到端、无线、上下文和网络部署特征），应用NGBoost模型输出点估计和校准的置信区间，这是该模型在计算机通信领域的首次应用。

Result: 验证并改进了4G方法（R²提升8.7%），首次为5G NSA和5G SA众包数据集提供基准，显示吞吐量瓶颈从无线接入网向传输和服务层转移。

Conclusion: 端到端指标相对于无线相关特征的重要性增加，证实了5G网络中吞吐量瓶颈的转移趋势。

Abstract: Characterizing application-layer user throughput in next-generation networks
is increasingly challenging as the higher capacity of the 5G Radio Access
Network (RAN) shifts connectivity bottlenecks towards deeper parts of the
network. Traditional methods, such as drive tests and operator equipment
counters, are costly, limited, or fail to capture end-to-end (E2E) Quality of
Service (QoS) and its variability. In this work, we leverage large-scale
crowdsourced measurements-including E2E, radio, contextual and network
deployment features collected by the user equipment (UE)-to propose an
uncertainty-aware and explainable approach for downlink user throughput
estimation. We first validate prior 4G methods, improving R^2 by 8.7%, and then
extend them to 5G NSA and 5G SA, providing the first benchmarks for 5G
crowdsourced datasets. To address the variability of throughput, we apply
NGBoost, a model that outputs both point estimates and calibrated confidence
intervals, representing its first use in the field of computer communications.
Finally, we use the proposed model to analyze the evolution from 4G to 5G SA,
and show that throughput bottlenecks move from the RAN to transport and service
layers, as seen by E2E metrics gaining importance over radio-related features.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents](https://arxiv.org/abs/2510.08619)
*Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 提出了AScience框架和ASCollab系统，使用LLM研究代理进行大规模科学数据探索，通过社交动态实现假设发现。


<details>
  <summary>Details</summary>
Motivation: 大规模科学数据集为无特定研究问题的探索性发现提供了机会，但需要支持在复杂假设空间中进行持续探索。

Method: 引入AScience框架，将发现建模为代理、网络和评估规范的交互，实现为ASCollab分布式系统，使用具有异质行为的LLM研究代理自组织成演化网络。

Result: 实验显示社交动态能够积累专家评级结果，包括重新发现已建立的生物标志物、扩展已知通路和提出新治疗靶点。

Conclusion: 虽然湿实验室验证仍然必不可少，但社会结构化的代理网络可以大规模持续进行探索性假设发现。

Abstract: Large-scale scientific datasets -- spanning health biobanks, cell atlases,
Earth reanalyses, and more -- create opportunities for exploratory discovery
unconstrained by specific research questions. We term this process hypothesis
hunting: the cumulative search for insight through sustained exploration across
vast and complex hypothesis spaces. To support it, we introduce AScience, a
framework modeling discovery as the interaction of agents, networks, and
evaluation norms, and implement it as ASCollab, a distributed system of
LLM-based research agents with heterogeneous behaviors. These agents
self-organize into evolving networks, continually producing and peer-reviewing
findings under shared standards of evaluation. Experiments show that such
social dynamics enable the accumulation of expert-rated results along the
diversity-quality-novelty frontier, including rediscoveries of established
biomarkers, extensions of known pathways, and proposals of new therapeutic
targets. While wet-lab validation remains indispensable, our experiments on
cancer cohorts demonstrate that socially structured, agentic networks can
sustain exploratory hypothesis hunting at scale.

</details>


### [5] [Optimizing delivery for quick commerce factoring qualitative assessment of generated routes](https://arxiv.org/abs/2510.08671)
*Milon Bhattacharya,Milan Kumar*

Main category: cs.AI

TL;DR: 该研究提出使用大语言模型来评估车辆路径规划生成的配送路线，通过政策标准进行批判性分析，在印度电商物流场景中实现了79-86%的问题识别准确率。


<details>
  <summary>Details</summary>
Motivation: 印度电商市场快速增长，最后一公里配送占运营成本近一半。传统VRP求解器在现实场景中因地址不规范、地图不完整和计算限制而效果有限。

Method: 开发了一个框架，使用大语言模型基于政策标准对VRP生成的路线进行批判性评估，生成并评估了400个案例。

Result: 开源LLM识别路线问题的准确率达到79%，专有推理模型达到86%，证明LLM评估可以超越传统的距离和时间指标。

Conclusion: LLM为基础的路线评估可成为有效且可扩展的评估层，对提高成本效率、配送可靠性和可持续性具有重要意义，特别适用于印度等发展中国家。

Abstract: Indias e-commerce market is projected to grow rapidly, with last-mile
delivery accounting for nearly half of operational expenses. Although vehicle
routing problem (VRP) based solvers are widely used for delivery planning,
their effectiveness in real-world scenarios is limited due to unstructured
addresses, incomplete maps, and computational constraints in distance
estimation. This study proposes a framework that employs large language models
(LLMs) to critique VRP-generated routes against policy-based criteria, allowing
logistics operators to evaluate and prioritise more efficient delivery plans.
As a illustration of our approach we generate, annotate and evaluated 400 cases
using large language models. Our study found that open-source LLMs identified
routing issues with 79% accuracy, while proprietary reasoning models achieved
reach upto 86%. The results demonstrate that LLM-based evaluation of
VRP-generated routes can be an effective and scalable layer of evaluation which
goes beyond beyond conventional distance and time based metrics. This has
implications for improving cost efficiency, delivery reliability, and
sustainability in last-mile logistics, especially for developing countries like
India.

</details>


### [6] [Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation](https://arxiv.org/abs/2510.08713)
*Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann*

Main category: cs.AI

TL;DR: UniWM是一个统一的世界模型，通过将视觉预测和导航规划集成在单一多模态自回归架构中，解决了现有模块化方法的状态-动作不对齐问题，显著提升了具身导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有具身导航方法采用模块化架构，将导航规划与视觉世界建模分离，导致状态-动作不对齐，在新型或动态场景中适应性有限。

Method: 提出UniWM统一记忆增强世界模型，在单一多模态自回归主干中整合自我中心视觉预测和规划，通过分层记忆机制结合短期感知线索和长期轨迹上下文。

Result: 在四个挑战性基准测试中，导航成功率提升高达30%，轨迹误差显著减少，并在未见的TartanDrive数据集上展现出优秀的零样本泛化能力。

Conclusion: UniWM是实现统一、想象力驱动的具身导航的重要进展，通过紧密对齐预测与控制来提升导航性能。

Abstract: Enabling embodied agents to effectively imagine future states is critical for
robust and generalizable visual navigation. Current state-of-the-art
approaches, however, adopt modular architectures that separate navigation
planning from visual world modeling, leading to state-action misalignment and
limited adaptability in novel or dynamic scenarios. To overcome this
fundamental limitation, we propose UniWM, a unified, memory-augmented world
model integrating egocentric visual foresight and planning within a single
multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly
grounds action decisions in visually imagined outcomes, ensuring tight
alignment between prediction and control. A hierarchical memory mechanism
further integrates detailed short-term perceptual cues with longer-term
trajectory context, enabling stable, coherent reasoning over extended horizons.
Extensive experiments across four challenging benchmarks (Go Stanford, ReCon,
SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success
rates by up to 30%, significantly reduces trajectory errors compared to strong
baselines, and exhibits impressive zero-shot generalization on the unseen
TartanDrive dataset. These results highlight UniWM as a principled step toward
unified, imagination-driven embodied navigation.

</details>


### [7] [Robust Heuristic Algorithm Design with LLMs](https://arxiv.org/abs/2510.08755)
*Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani*

Main category: cs.AI

TL;DR: 通过向LLM展示启发式算法表现不佳的实例、解释原因并针对输入空间特定区域进行专门设计，可以生成更鲁棒和性能更好的启发式算法。


<details>
  <summary>Details</summary>
Motivation: 现有使用LLM设计启发式算法的方法缺乏对算法表现不佳原因的解释和针对性改进，导致生成的算法不够鲁棒。

Method: 采用三个简单策略：(1)向LLM展示启发式算法表现不佳的实例；(2)解释表现不佳的原因；(3)针对输入空间特定区域进行专门设计。

Result: 生成的启发式算法在最坏情况下性能比FunSearch提升约28倍，平均性能也有所改善，同时保持运行时间不变。

Conclusion: 通过向LLM提供失败案例分析和针对性设计指导，可以显著提升生成启发式算法的鲁棒性和性能。

Abstract: We posit that we can generate more robust and performant heuristics if we
augment approaches using LLMs for heuristic design with tools that explain why
heuristics underperform and suggestions about how to fix them. We find even
simple ideas that (1) expose the LLM to instances where the heuristic
underperforms; (2) explain why they occur; and (3) specialize design to regions
in the input space, can produce more robust algorithms compared to existing
techniques~ -- ~the heuristics we produce have a $\sim28\times$ better
worst-case performance compared to FunSearch, improve average performance, and
maintain the runtime.

</details>


### [8] [COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context](https://arxiv.org/abs/2510.08790)
*Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang*

Main category: cs.AI

TL;DR: COMPASS是一个轻量级分层框架，通过分离战术执行、战略监督和上下文管理来解决LLM代理在长时程任务中的上下文管理瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 长时程任务中，LLM代理容易因小错误累积、幻觉或失去连贯性而失败，上下文管理成为关键瓶颈，导致代理忽略关键证据或被无关信息分散注意力。

Method: 提出COMPASS框架，包含三个专门组件：主代理（执行推理和工具使用）、元思考者（监控进度并发出战略干预）和上下文管理器（维护简洁相关的进度简报）。

Result: 在GAIA、BrowseComp和Humanity's Last Exam三个基准测试中，COMPASS相比单代理和多代理基线准确率提升高达20%。

Conclusion: COMPASS通过分层专业化组件有效解决了长时程任务中的上下文管理问题，并可通过测试时扩展和后训练管道进一步提升性能和效率。

Abstract: Long-horizon tasks that require sustained reasoning and multiple tool
interactions remain challenging for LLM agents: small errors compound across
steps, and even state-of-the-art models often hallucinate or lose coherence. We
identify context management as the central bottleneck -- extended histories
cause agents to overlook critical evidence or become distracted by irrelevant
information, thus failing to replan or reflect from previous mistakes. To
address this, we propose COMPASS (Context-Organized Multi-Agent Planning and
Strategy System), a lightweight hierarchical framework that separates tactical
execution, strategic oversight, and context organization into three specialized
components: (1) a Main Agent that performs reasoning and tool use, (2) a
Meta-Thinker that monitors progress and issues strategic interventions, and (3)
a Context Manager that maintains concise, relevant progress briefs for
different reasoning stages. Across three challenging benchmarks -- GAIA,
BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%
relative to both single- and multi-agent baselines. We further introduce a
test-time scaling extension that elevates performance to match established
DeepResearch agents, and a post-training pipeline that delegates context
management to smaller models for enhanced efficiency.

</details>


### [9] [Everyone prefers human writers, including AI](https://arxiv.org/abs/2510.08831)
*Wouter Haverals,Meredith Martin*

Main category: cs.AI

TL;DR: 研究发现人类和AI在评估文学风格时都存在系统性偏向人类的归因偏见，AI的偏见程度是人类2.5倍，且无论内容实际来源如何，标注为AI生成都会导致评价降低。


<details>
  <summary>Details</summary>
Motivation: 随着AI写作工具普及，需要理解人类和机器如何评估文学风格这一主观领域，特别是归因偏见问题。

Method: 使用雷蒙·格诺《风格练习》进行对照实验：研究1比较人类参与者和AI模型评估格诺原作与GPT-4生成版本；研究2测试AI评估者和创作者14×14矩阵中的偏见泛化。

Result: 人类显示+13.7个百分点偏见，AI显示+34.3个百分点偏见（2.5倍于人类），AI系统系统性地贬低标注为AI生成的创意内容。

Conclusion: AI模型在训练中吸收了人类对人工创造力的文化偏见，不仅复制而且放大了这种人类倾向，归因标签导致评估者颠倒评估标准。

Abstract: As AI writing tools become widespread, we need to understand how both humans
and machines evaluate literary style, a domain where objective standards are
elusive and judgments are inherently subjective. We conducted controlled
experiments using Raymond Queneau's Exercises in Style (1947) to measure
attribution bias across evaluators. Study 1 compared human participants (N=556)
and AI models (N=13) evaluating literary passages from Queneau versus
GPT-4-generated versions under three conditions: blind, accurately labeled, and
counterfactually labeled. Study 2 tested bias generalization across a
14$\times$14 matrix of AI evaluators and creators. Both studies revealed
systematic pro-human attribution bias. Humans showed +13.7 percentage point
(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3
percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect
(P$<$0.001). Study 2 confirmed this bias operates across AI architectures
(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically
devalue creative content when labeled as "AI-generated" regardless of which AI
created it. We also find that attribution labels cause evaluators to invert
assessment criteria, with identical features receiving opposing evaluations
based solely on perceived authorship. This suggests AI models have absorbed
human cultural biases against artificial creativity during training. Our study
represents the first controlled comparison of attribution bias between human
and artificial evaluators in aesthetic judgment, revealing that AI systems not
only replicate but amplify this human tendency.

</details>


### [10] [What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment](https://arxiv.org/abs/2510.08847)
*Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta*

Main category: cs.AI

TL;DR: 提出了Agent GPA（目标-计划-行动）评估框架，包含五个评估指标：目标达成度、逻辑一致性、执行效率、计划质量和计划遵循度。该框架能系统性地覆盖广泛的智能体失败情况，支持LLM评判器与人工标注高度一致，并能准确定位错误以改进智能体性能。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统性的评估范式来评估智能体在目标设定、计划制定和行动执行整个操作循环中的表现，以全面覆盖各种智能体失败情况。

Method: 基于智能体的目标-计划-行动操作循环，设计了五个评估指标：目标达成度、逻辑一致性、执行效率、计划质量和计划遵循度。在两个基准数据集（TRAIL/GAIA和内部生产级数据智能体数据集）上进行实验验证。

Result: 实验结果显示：该框架能覆盖TRAIL/GAIA基准数据集中的所有智能体错误；LLM评判器与人工标注的一致性达到80%至95%以上；错误定位准确率达到86%。

Conclusion: Agent GPA框架为智能体评估提供了系统性的方法，能够全面覆盖智能体失败情况，支持高效的自动化评估，并能准确定位错误以指导智能体性能的针对性改进。

Abstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation
paradigm based on an agent's operational loop of setting goals, devising plans,
and executing actions. The framework includes five evaluation metrics: Goal
Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan
Adherence. Logical Consistency checks that an agent's actions are consistent
with its prior actions. Execution Efficiency checks whether the agent executes
in the most efficient way to achieve its goal. Plan Quality checks whether an
agent's plans are aligned with its goals; Plan Adherence checks if an agent's
actions are aligned with its plan; and Goal Fulfillment checks that agent's
final outcomes match the stated goals. Our experimental results on two
benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for
a production-grade data agent - show that this framework (a) provides a
systematic way to cover a broad range of agent failures, including all agent
errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that
exhibit strong agreement with human annotation, covering 80% to over 95%
errors; and (c) localizes errors with 86% agreement to enable targeted
improvement of agent performance.

</details>


### [11] [ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review](https://arxiv.org/abs/2510.08867)
*Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal*

Main category: cs.AI

TL;DR: 提出了ReviewerToo框架，用于研究和部署AI辅助同行评审，在ICLR 2025数据集上验证显示AI评审员在接收/拒绝分类任务上达到81.8%准确率，接近人类评审员的83.9%。


<details>
  <summary>Details</summary>
Motivation: 同行评审存在不一致性、评审员主观性和可扩展性挑战，需要AI辅助来提供系统性和一致的评估。

Method: 开发了模块化框架ReviewerToo，支持专业评审员角色和结构化评估标准的系统实验，可部分或完全集成到真实会议工作流程中。

Result: 在ICLR 2025的1,963篇论文数据集上，GPT-OSS-120B模型在接收/拒绝分类任务上达到81.8%准确率，AI生成的评审质量高于人类平均水平，但在方法新颖性和理论贡献评估方面仍有不足。

Conclusion: AI可以增强同行评审的一致性、覆盖范围和公平性，但复杂评估仍需领域专家，为混合同行评审系统提供了基础。

Abstract: Peer review is the cornerstone of scientific publishing, yet it suffers from
inconsistencies, reviewer subjectivity, and scalability challenges. We
introduce ReviewerToo, a modular framework for studying and deploying
AI-assisted peer review to complement human judgment with systematic and
consistent assessments. ReviewerToo supports systematic experiments with
specialized reviewer personas and structured evaluation criteria, and can be
partially or fully integrated into real conference workflows. We validate
ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR
2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy
for the task of categorizing a paper as accept/reject compared to 83.9% for the
average human reviewer. Additionally, ReviewerToo-generated reviews are rated
as higher quality than the human average by an LLM judge, though still trailing
the strongest expert contributions. Our analysis highlights domains where AI
reviewers excel (e.g., fact-checking, literature coverage) and where they
struggle (e.g., assessing methodological novelty and theoretical
contributions), underscoring the continued need for human expertise. Based on
these findings, we propose guidelines for integrating AI into peer-review
pipelines, showing how AI can enhance consistency, coverage, and fairness while
leaving complex evaluative judgments to domain experts. Our work provides a
foundation for systematic, hybrid peer-review systems that scale with the
growth of scientific publishing.

</details>


### [12] [GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare](https://arxiv.org/abs/2510.08872)
*Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You*

Main category: cs.AI

TL;DR: GTAlign是一个基于博弈论的对齐框架，通过在推理过程中将用户-LLM交互建模为战略游戏，并在训练中引入互惠奖励，来优化LLM的响应质量与效率。


<details>
  <summary>Details</summary>
Motivation: 传统对齐方法假设最大化模型奖励即最大化用户福利，但实践中LLM常生成冗长或过度澄清的响应，而用户偏好简洁答案，这种个体理性选择导致社会次优结果。

Method: 在推理过程中构建收益矩阵评估双方福利，选择互惠行动；在训练中引入互惠奖励强化合作响应；并开发基于博弈论推理的动态适应技术应对定价策略变化。

Result: 广泛实验表明GTAlign在多样化任务中显著提升推理效率、答案质量和互惠福利，优于基线方法。

Conclusion: GTAlign通过博弈论决策机制有效解决了LLM与用户交互中的社会次优问题，实现了双方互惠的对齐效果。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning,
yet sometimes produce responses that are suboptimal for users in tasks such as
writing, information seeking, or providing practical guidance. Conventional
alignment practices typically assume that maximizing model reward also
maximizes user welfare, but this assumption frequently fails in practice:
models may over-clarify or generate overly verbose reasoning when users prefer
concise answers. Such behaviors resemble the prisoner's dilemma, where
individually rational choices lead to socially suboptimal outcomes. The
fundamental challenge is the lack of a principled decision making mechanism
that mutually benefits both the LLM and the user. We propose Game-Theoretic
Alignment (GTAlign), an alignment framework that integrates game-theoretic
decision making into both reasoning and training. During reasoning, the model
explicitly treats user-LLM interaction as a strategic game: it constructs
payoff matrices within its reasoning chain to estimate welfare for both itself
and the user, and then selects actions that are mutually beneficial. During
training, we introduce a mutual welfare reward that reinforces cooperative
responses, aligning model behavior with socially efficient outcomes. In
addition, we introduce an inference technique that leverages game-theoretic
reasoning to dynamically adapt LLM's response when pricing policies of LLM
service change. Extensive experiments demonstrate that GTAlign substantially
improves reasoning efficiency, answer quality, and mutual welfare compared to
baselines across diverse tasks. The code is available at
https://github.com/ulab-uiuc/GTAlign .

</details>


### [13] [LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition](https://arxiv.org/abs/2510.08928)
*Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai*

Main category: cs.AI

TL;DR: 提出了LM Fight Arena框架，通过在格斗游戏《真人快打II》中让大型多模态模型对战来评估其性能，填补了现有基准在实时对抗环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型基准无法充分评估其在实时对抗环境中的表现，需要一种动态、可复现的评估方法。

Method: 在《真人快打II》游戏中让6个领先的开源和闭源模型进行对战比赛，每个模型控制相同角色以确保公平比较，通过解析游戏画面和状态数据来选择行动。

Result: LM Fight Arena提供了一个完全自动化、可复现且客观的评估框架，能够测试LMM在动态环境中的战略推理能力。

Conclusion: 这项工作引入了一个具有挑战性和趣味性的基准，弥合了AI评估与交互娱乐之间的差距。

Abstract: Existing benchmarks for large multimodal models (LMMs) often fail to capture
their performance in real-time, adversarial environments. We introduce LM Fight
Arena (Large Model Fight Arena), a novel framework that evaluates LMMs by
pitting them against each other in the classic fighting game Mortal Kombat II,
a task requiring rapid visual understanding and tactical, sequential
decision-making. In a controlled tournament, we test six leading open- and
closed-source models, where each agent operates controlling the same character
to ensure a fair comparison. The models are prompted to interpret game frames
and state data to select their next actions. Unlike static evaluations, LM
Fight Arena provides a fully automated, reproducible, and objective assessment
of an LMM's strategic reasoning capabilities in a dynamic setting. This work
introduces a challenging and engaging benchmark that bridges the gap between AI
evaluation and interactive entertainment.

</details>


### [14] [RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation](https://arxiv.org/abs/2510.08931)
*Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad*

Main category: cs.AI

TL;DR: RADAR是一个基于机制可解释性的框架，通过分析激活表示来检测LLM评估中的数据污染问题，区分基于记忆的回忆和基于推理的响应。


<details>
  <summary>Details</summary>
Motivation: 数据污染对可靠的LLM评估构成重大挑战，模型可能通过记忆训练数据而非真正推理能力来获得高性能表现。

Method: RADAR提取37个特征，涵盖表面级置信度轨迹和深层机制特性（包括注意力专业化、电路动态和激活流模式），并使用基于这些特征的集成分类器。

Result: 在多样化评估集上达到93%的准确率，在清晰案例中表现完美，在具有挑战性的模糊示例中达到76.7%的准确率。

Conclusion: 这项工作展示了机制可解释性在超越传统表面级指标的LLM评估方面的潜力。

Abstract: Data contamination poses a significant challenge to reliable LLM evaluation,
where models may achieve high performance by memorizing training data rather
than demonstrating genuine reasoning capabilities. We introduce RADAR (Recall
vs. Reasoning Detection through Activation Representation), a novel framework
that leverages mechanistic interpretability to detect contamination by
distinguishing recall-based from reasoning-based model responses. RADAR
extracts 37 features spanning surface-level confidence trajectories and deep
mechanistic properties including attention specialization, circuit dynamics,
and activation flow patterns. Using an ensemble of classifiers trained on these
features, RADAR achieves 93\% accuracy on a diverse evaluation set, with
perfect performance on clear cases and 76.7\% accuracy on challenging ambiguous
examples. This work demonstrates the potential of mechanistic interpretability
for advancing LLM evaluation beyond traditional surface-level metrics.

</details>


### [15] [FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation](https://arxiv.org/abs/2510.08945)
*Samuel Hildebrand,Curtis Taylor,Sean Oesch,James M Ghawaly Jr,Amir Sadovnik,Ryan Shivers,Brandon Schreiber,Kevin Kurian*

Main category: cs.AI

TL;DR: 提出了一个评估RAG（检索增强生成）管道的基准，包含多模态数据评估、短语级召回指标、幻觉检测方法，并比较了开源与闭源管道的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注检索等特定方面，缺乏对RAG管道整体能力的评估，特别是处理多模态信息的能力。

Method: 创建包含93个多模态问题的人工数据集，开发短语级召回指标和基于最近邻嵌入的幻觉检测分类器，比较2个开源和4个闭源管道的性能。

Result: 闭源管道在正确性和幻觉检测方面显著优于开源管道，特别是在多模态和跨文档问题上差距更大。人工评估显示指标与人类判断高度一致。

Conclusion: 该基准能有效评估RAG管道的整体性能，闭源模型在多模态处理上表现更好，提出的评估指标与人类判断有良好一致性。

Abstract: Retrieval-augmented generation (RAG) has emerged as a promising paradigm for
improving factual accuracy in large language models (LLMs). We introduce a
benchmark designed to evaluate RAG pipelines as a whole, evaluating a
pipeline's ability to ingest, retrieve, and reason about several modalities of
information, differentiating it from existing benchmarks that focus on
particular aspects such as retrieval. We present (1) a small, human-created
dataset of 93 questions designed to evaluate a pipeline's ability to ingest
textual data, tables, images, and data spread across these modalities in one or
more documents; (2) a phrase-level recall metric for correctness; (3) a
nearest-neighbor embedding classifier to identify potential pipeline
hallucinations; (4) a comparative evaluation of 2 pipelines built with
open-source retrieval mechanisms and 4 closed-source foundation models; and (5)
a third-party human evaluation of the alignment of our correctness and
hallucination metrics. We find that closed-source pipelines significantly
outperform open-source pipelines in both correctness and hallucination metrics,
with wider performance gaps in questions relying on multimodal and
cross-document information. Human evaluation of our metrics showed average
agreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5
Likert scale (5 indicating "strongly agree").

</details>


### [16] [EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory](https://arxiv.org/abs/2510.08958)
*Zirui Liao*

Main category: cs.AI

TL;DR: EcphoryRAG是一个基于实体记忆激活机制的知识图谱RAG框架，通过提取核心实体和元数据进行轻量级索引，实现多跳关联检索，在多个基准测试中达到新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 受人类认知神经科学中通过线索激活实体记忆痕迹进行多跳回忆的机制启发，旨在解决传统RAG系统在复杂推理任务中的局限性。

Method: 在索引阶段仅提取和存储核心实体及元数据，检索时从查询中提取线索实体，在知识图谱上进行可扩展的多跳关联搜索，并动态推断实体间的隐式关系来填充上下文。

Result: 在2WikiMultiHop、HotpotQA和MuSiQue基准测试中，将平均精确匹配分数从0.392提升到0.474，相比其他结构化RAG系统减少高达94%的token消耗。

Conclusion: 实体-线索-多跳检索范式在复杂问答任务中具有显著效果，验证了基于认知神经科学启发的检索方法的有效性。

Abstract: Cognitive neuroscience research indicates that humans leverage cues to
activate entity-centered memory traces (engrams) for complex, multi-hop
recollection. Inspired by this mechanism, we introduce EcphoryRAG, an
entity-centric knowledge graph RAG framework. During indexing, EcphoryRAG
extracts and stores only core entities with corresponding metadata, a
lightweight approach that reduces token consumption by up to 94\% compared to
other structured RAG systems. For retrieval, the system first extracts cue
entities from queries, then performs a scalable multi-hop associative search
across the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit
relations between entities to populate context, enabling deep reasoning without
exhaustive pre-enumeration of relationships. Extensive evaluations on the
2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG
sets a new state-of-the-art, improving the average Exact Match (EM) score from
0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate
the efficacy of the entity-cue-multi-hop retrieval paradigm for complex
question answering.

</details>


### [17] [DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction](https://arxiv.org/abs/2510.08959)
*Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang*

Main category: cs.AI

TL;DR: DualResearch是一个检索和融合框架，通过联合建模广度语义图和深度因果图来解决深度研究框架中的上下文污染、证据支持弱和执行路径脆弱问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究框架虽然能协调外部工具进行复杂科学推理，但仍存在上下文污染、证据支持弱和执行路径脆弱等问题，需要更稳健的解决方案。

Method: 提出DualResearch框架，联合建模两个互补图：广度语义图编码稳定背景知识，深度因果图捕获执行来源。每个图都有层原生相关性函数，广度使用种子锚定语义扩散，深度使用因果语义路径匹配和可靠性加权。通过熵门控规则在log空间融合答案分布。

Result: 在科学推理基准HLE和GPQA上表现优异，使用InternAgent系统的日志文件，在HLE上准确率提升7.7%，在GPQA上提升6.06%。

Conclusion: DualResearch能够将冗长的多工具执行日志压缩为简洁的推理图，稳定有效地重建答案，作为深度研究系统的补充具有良好效果。

Abstract: The deep-research framework orchestrates external tools to perform complex,
multi-step scientific reasoning that exceeds the native limits of a single
large language model. However, it still suffers from context pollution, weak
evidentiary support, and brittle execution paths. To address these issues, we
propose DualResearch, a retrieval and fusion framework that matches the
epistemic structure of tool-intensive reasoning by jointly modeling two
complementary graphs: a breadth semantic graph that encodes stable background
knowledge, and a depth causal graph that captures execution provenance. Each
graph has a layer-native relevance function, seed-anchored semantic diffusion
for breadth, and causal-semantic path matching with reliability weighting for
depth. To reconcile their heterogeneity and query-dependent uncertainty,
DualResearch converts per-layer path evidence into answer distributions and
fuses them in log space via an entropy-gated rule with global calibration. The
fusion up-weights the more certain channel and amplifies agreement. As a
complement to deep-research systems, DualResearch compresses lengthy multi-tool
execution logs into a concise reasoning graph, and we show that it can
reconstruct answers stably and effectively. On the scientific reasoning
benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using
log files from the open-source system InternAgent, its accuracy improves by
7.7% on HLE and 6.06% on GPQA.

</details>


### [18] [Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion](https://arxiv.org/abs/2510.08966)
*Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li*

Main category: cs.AI

TL;DR: 提出Semantic-condition Tuning (SCT)新范式，通过图神经网络提取上下文感知的语义条件，实现知识图谱与大型语言模型的深度特征融合，显著提升知识推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有前缀调优方法简单拼接知识嵌入与文本输入，忽略了知识图谱的丰富关系语义，给LLM带来隐式推理负担，需要更深入的知识融合方法。

Method: SCT包含两个关键模块：语义图模块使用图神经网络从局部图邻域提取上下文感知语义条件；条件自适应融合模块通过参数化投影器自适应调制文本嵌入，实现深度特征级知识感知交互。

Result: 在知识图谱基准测试上的广泛实验表明，SCT显著优于前缀调优和其他强基线方法。

Conclusion: 通过在LLM推理前用语义图上下文调制输入表示，SCT提供了更直接有效的信号，实现了更准确和鲁棒的知识推理。

Abstract: Fusing Knowledge Graphs with Large Language Models is crucial for
knowledge-intensive tasks like knowledge graph completion. The prevailing
paradigm, prefix-tuning, simply concatenates knowledge embeddings with text
inputs. However, this shallow fusion overlooks the rich relational semantics
within KGs and imposes a significant implicit reasoning burden on the LLM to
correlate the prefix with the text. To address these, we propose
Semantic-condition Tuning (SCT), a new knowledge injection paradigm comprising
two key modules. First, a Semantic Graph Module employs a Graph Neural Network
to extract a context-aware semantic condition from the local graph
neighborhood, guided by knowledge-enhanced relations. Subsequently, this
condition is passed to a Condition-Adaptive Fusion Module, which, in turn,
adaptively modulates the textual embedding via two parameterized projectors,
enabling a deep, feature-wise, and knowledge-aware interaction. The resulting
pre-fused embedding is then fed into the LLM for fine-tuning. Extensive
experiments on knowledge graph benchmarks demonstrate that SCT significantly
outperforms prefix-tuning and other strong baselines. Our analysis confirms
that by modulating the input representation with semantic graph context before
LLM inference, SCT provides a more direct and potent signal, enabling more
accurate and robust knowledge reasoning.

</details>


### [19] [Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging](https://arxiv.org/abs/2510.08987)
*Qixiang Yin,Huanjin Yao,Jianghao Chen,Jiaxing Huang,Zhicheng Zhao,Fei Su*

Main category: cs.AI

TL;DR: Tiny-R1V是一个轻量级的3B参数多模态大语言模型，通过两阶段优化实现更快的推理速度和更高的准确性，统一了多任务的多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在推理效率方面面临模型规模大、过度思考、轻量级场景精度不足等挑战，而轻量级MLLMs的推理能力研究较为缺乏。

Method: 采用两阶段优化：第一阶段引入LIPO强化学习方法，动态调整响应优势，鼓励生成更短更准确的响应；第二阶段提出AMM模型融合方法，自适应调整任务向量权重，通过梯度投影正则化损失函数优化合并向量。

Result: 在十个广泛使用的推理基准测试（数学、结构化数据、OCR和通用能力）中表现出优越性能，使轻量级模型在多样化多模态推理任务中表现出色。

Conclusion: Tiny-R1V通过创新的两阶段优化方法，成功解决了轻量级MLLMs的推理效率问题，为轻量级多模态推理模型的发展提供了有效解决方案。

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
remarkable capabilities across diverse tasks, they encounter numerous
challenges in terms of reasoning efficiency, such as large model size,
overthinking, and compromised accuracy in lightweight scenarios. However,
research on the reasoning capabilities of lightweight MLLMs is quite lacking.
To this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves
faster inference and higher accuracy via a two-stage optimization, while
unifying multimodal reasoning across multiple tasks and using fewer tokens. In
the first stage, Tiny-R1V introduces Length-Informed Relative Policy
Optimization (LIPO), a novel reinforcement learning method, to train each
reasoning model. The LIPO is designed to dynamically adjusts advantages of
responses within groups, that is, by prioritizing concise yet high-quality
responses to encourage the generation of shorter and more accurate response. In
the second stage, we propose Adaptive Model Merging (AMM), a training-free
model merging method that merges multiple specialist models into a unified
architecture. Specifically, AMM adaptively adjusts the weights of task vectors
and robustly optimizes the merged vectors via a novel gradient projection
regularization loss function, thus mitigating redundant conflicts between them.
Extensive evaluations on ten widely-used reasoning benchmarks covering
mathematics, structured data (charts, tables, documents), OCR, and general
capabilities showcase the superior performance of Tiny-R1V, enabling
lightweight models to excel in diverse multimodal reasoning tasks.

</details>


### [20] [TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation](https://arxiv.org/abs/2510.09011)
*Yincen Qu,Huan Xiao,Feng Li,Hui Zhou,Xiangying Dai*

Main category: cs.AI

TL;DR: 提出了一个统一的旅行规划基准，将细粒度标准整合为单一奖励分数，支持强化学习训练，并在大规模数据集上验证了RL方法在提升规划可行性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估LLMs旅行规划能力时，往往无法充分评估计划的可行性、可靠性和吸引力，需要更全面的评估框架。

Method: 构建包含4870个查询的大规模数据集，开发统一的评估器将多个标准整合为单一奖励分数，并测试了多种方法包括测试时计算、神经符号方法、监督微调和GRPO强化学习。

Result: 评估器与旅行专家标注达到60.75%的一致性，优于多个LLM-as-judge基线。RL方法在基础模型上普遍提高了行程的可行性，获得了更高的统一奖励分数。

Conclusion: 提出的统一基准能够有效评估旅行规划质量，RL方法在提升规划可行性方面表现出优势，为LLMs在复杂规划任务中的应用提供了有力工具。

Abstract: Travel planning is a valuable yet complex task that poses significant
challenges even for advanced large language models (LLMs). While recent
benchmarks have advanced in evaluating LLMs' planning capabilities, they often
fall short in evaluating feasibility, reliability, and engagement of travel
plans. We introduce a comprehensive benchmark for travel planning that unifies
fine-grained criteria into a single reward, enabling direct comparison of plan
quality and seamless integration with reinforcement learning (RL). Our
evaluator achieves moderate agreement with travel-expert annotations (60.75\%)
and outperforms multiple LLM-as-judge baselines. We further release a
large-scale dataset of 4,870 queries including 219 real-world, free-form
requests for generalization to authentic user intent. Using this benchmark, we
conduct extensive experiments across diverse methods and LLMs, including
test-time computation, neuro-symbolic approaches, supervised fine-tuning, and
RL via GRPO. Across base models, RL generally improves itinerary feasibility
over prompt-only and supervised baselines, yielding higher unified reward
scores.

</details>


### [21] [RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows](https://arxiv.org/abs/2510.09021)
*Hamed Mahdavi,Pouria Mahdavinia,Samira Malek,Pegah Mohammadipour,Alireza Hashemi,Majid Daliri,Alireza Farhadi,Amir Khasahmadi,Niloofar Mireshghallah,Vasant Honavar*

Main category: cs.AI

TL;DR: 评估SOTA LLMs在数学证明评分方面的能力，提出基于代理工作流程的评分方法，显著提高了与人类评分的一致性和部分学分处理的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在解决奥林匹克数学问题方面取得显著进展，需要评估它们在证明评分方面的能力，包括错误检测、严重性判断和公平分数分配。

Method: 使用Gemini 2.5 Pro生成的90个解决方案和MathArena的IMO/USAMO 2025解决方案集，引入基于代理的工作流程，提取参考解决方案并自动推导问题特定的评分标准。

Result: 模型能可靠地标记错误解决方案，但在部分学分分配上存在校准差距。提出的工作流程在人类评分一致性和部分学分处理方面表现更好。

Conclusion: 代理工作流程显著提高了证明评分的准确性和一致性，为未来研究提供了代码、数据和提示/日志资源。

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [22] [Repairing Regex Vulnerabilities via Localization-Guided Instructions](https://arxiv.org/abs/2510.09037)
*Sicheol Sung,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 提出了一种混合框架LRR，结合符号化模块和LLM来修复正则表达式ReDoS漏洞，解决了现有方法在精度和泛化性之间的权衡问题


<details>
  <summary>Details</summary>
Motivation: 正则表达式在现代计算中广泛应用，但存在ReDoS漏洞。现有修复方法面临两难：符号化方法精确但无法处理复杂模式，LLM方法泛化性强但可靠性不足

Method: LRR混合框架：首先用符号化模块定位漏洞子模式，然后用LLM生成语义等价的修复方案，将问题识别与修复过程解耦

Result: 成功解决了规则化修复无法处理的复杂修复案例，同时避免了纯LLM方法的语义错误，修复率比最先进方法提高了15.4%

Conclusion: 该工作为自动化修复问题提供了经过验证的方法论，通过结合符号化方法和LLM的优势，实现了可靠且泛化的正则表达式漏洞修复

Abstract: Regular expressions (regexes) are foundational to modern computing for
critical tasks like input validation and data parsing, yet their ubiquity
exposes systems to regular expression denial of service (ReDoS), a
vulnerability requiring automated repair methods. Current approaches, however,
are hampered by a trade-off. Symbolic, rule-based system are precise but fails
to repair unseen or complex vulnerability patterns. Conversely, large language
models (LLMs) possess the necessary generalizability but are unreliable for
tasks demanding strict syntactic and semantic correctness. We resolve this
impasse by introducing a hybrid framework, localized regex repair (LRR),
designed to harness LLM generalization while enforcing reliability. Our core
insight is to decouple problem identification from the repair process. First, a
deterministic, symbolic module localizes the precise vulnerable subpattern,
creating a constrained and tractable problem space. Then, the LLM invoked to
generate a semantically equivalent fix for this isolated segment. This combined
architecture successfully resolves complex repair cases intractable for
rule-based repair while avoiding the semantic errors of LLM-only approaches.
Our work provides a validated methodology for solving such problems in
automated repair, improving the repair rate by 15.4%p over the
state-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.

</details>


### [23] [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)
*Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出了一种连续记忆机制，用于增强GUI代理在陌生界面和长时任务中的泛化能力，通过固定长度的连续嵌入编码GUI轨迹，显著减少上下文成本并保留细粒度视觉信息。


<details>
  <summary>Details</summary>
Motivation: 解决现有GUI代理将过去轨迹压缩为文本标记导致上下文长度膨胀和丢失关键视觉线索（如精确控件尺寸和位置）的问题。

Method: 使用VLM作为编码器将GUI轨迹编码为固定长度的连续嵌入序列，这些嵌入直接插入到骨干网络的输入层；引入自动扩展数据飞轮来低成本扩展记忆。

Result: 随着记忆大小和检索深度的增加，性能单调提升，而文本记忆在长提示下性能会下降；在真实世界GUI基准测试中，记忆增强代理在长时任务和分布偏移下持续提高成功率。

Conclusion: Qwen-2.5-VL-7B + 连续记忆实现了与最先进闭源模型（如GPT-4o、Claude-4）相当的性能，证明了连续记忆机制的有效性。

Abstract: We study how to endow GUI agents with scalable memory that help generalize
across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress
past trajectories into text tokens, which balloons context length and misses
decisive visual cues (e.g., exact widget size and position). We propose a
continuous memory that encodes each GUI trajectory into a fixed-length sequence
of continuous embeddings using the VLM itself as an encoder; these embeddings
are plugged directly into the backbone's input layer, sharply reducing context
cost while preserving fine-grained visual information. As memory size and
retrieval depth increase, performance improves monotonically, unlike text
memories that degrade with long prompts. To grow memory at low cost, we
introduce an auto-scaling data flywheel that (i) discovers new environments via
search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out
trajectories with the agent, and (iv) verifies success with the same VLM. Using
this pipeline, we collect 100k+ trajectories for about \$4000 and fine-tune
only the memory encoder (LoRA on a Q-Former, 1.2\% parameters) with 1,500
samples. On real-world GUI benchmarks, our memory-augmented agent consistently
improves success rates under long horizons and distribution shifts. Notably,
Qwen-2.5-VL-7B + continuous memory achieves performance comparable to
state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).

</details>


### [24] [Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory](https://arxiv.org/abs/2510.09043)
*Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong*

Main category: cs.AI

TL;DR: 本研究提出了一种整合精神分析和MBTI人格理论的新方法，构建了三种人工意识（自我意识、潜意识、前意识）和16种MBTI人格角色，通过多种评估方式验证了模型能够模拟人类意识。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然在各领域取得进展，但由于幻觉问题难以模拟人类意识。本研究旨在通过整合精神分析和人格理论来解决这一挑战。

Method: 基于精神分析原理开发三种人工意识，设计16种MBTI人格角色，创建10个不同情境，通过问卷调查、ChatGPT三级分类和定性评估三种方式评估决策过程。

Result: 定量和定性分析表明模型能够很好地模拟意识，尽管不同角色和意识之间的响应差异不显著。

Conclusion: 整合精神分析和人格理论的模型能够构建更直观、适应性更强的人工智能系统，为改善复杂认知情境下的人机交互开辟了新途径。

Abstract: Human consciousness is still a concept hard to define with current scientific
understanding. Although Large Language Models (LLMs) have recently demonstrated
significant advancements across various domains including translation and
summarization, human consciousness is not something to imitate with current
upfront technology owing to so-called hallucination. This study, therefore,
proposes a novel approach to address these challenges by integrating
psychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing
consciousness and personality modules. We developed three artificial
consciousnesses (self-awareness, unconsciousness, and preconsciousness) based
on the principles of psychoanalysis. Additionally, we designed 16 characters
with different personalities representing the sixteen MBTI types, with several
attributes such as needs, status, and memories. To determine if our model's
artificial consciousness exhibits human-like cognition, we created ten distinct
situations considering seven attributes such as emotional understanding and
logical thinking. The decision-making process of artificial consciousness and
the final action were evaluated in three ways: survey evaluation, three-tier
classification via ChatGPT, and qualitative review. Both quantitative and
qualitative analyses indicated a high likelihood of well-simulated
consciousness, although the difference in response between different characters
and consciousnesses was not very significant. This implies that the developed
models incorporating elements of psychoanalysis and personality theory can lead
to building a more intuitive and adaptable AI system with humanoid
consciousness. Therefore, this study contributes to opening up new avenues for
improving AI interactions in complex cognitive contexts.

</details>


### [25] [MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction](https://arxiv.org/abs/2510.09049)
*Joonghyuk Hahn,Soohan Lim,Yo-Sub Han*

Main category: cs.AI

TL;DR: MEC³O是一个多专家共识系统，通过将LLMs分配到特定复杂度类别并让专家进行结构化辩论，使用加权共识机制整合预测，显著提升了代码时间复杂度预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码时间复杂度预测中表现不均衡，没有单一模型在所有复杂度类别上都表现优异，需要一种能够整合各模型优势的方法。

Method: 提出MEC³O多专家共识系统：1）基于性能将LLMs分配到特定复杂度类别；2）提供类别专业化指令；3）专家进行结构化辩论；4）通过加权共识机制整合预测。

Result: 在CodeComplex数据集上，MEC³O比开源基线准确率和macro-F1分数至少高出10%，在macro-F1上平均超过GPT-4o-mini，与GPT-4o和GPT-o4-mini的F1分数相当。

Conclusion: 多专家辩论和加权共识策略能有效生成最终预测，证明了该方法在代码复杂度预测中的有效性。

Abstract: Predicting the complexity of source code is essential for software
development and algorithm analysis. Recently, Baik et al. (2025) introduced
CodeComplex for code time complexity prediction. The paper shows that LLMs
without fine-tuning struggle with certain complexity classes. This suggests
that no single LLM excels at every class, but rather each model shows
advantages in certain classes. We propose MEC$^3$O, a multi-expert consensus
system, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs
to complexity classes based on their performance and provides them with
class-specialized instructions, turning them into experts. These experts engage
in structured debates, and their predictions are integrated through a weighted
consensus mechanism. Our expertise assignments to LLMs effectively handle
Degeneration-of-Thought, reducing reliance on a separate judge model, and
preventing convergence to incorrect majority opinions. Experiments on
CodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving
at least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini
in macro-F1 scores on average and demonstrates competitive on-par F1 scores to
GPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of
multi-expert debates and weight consensus strategy to generate the final
predictions. Our code and data is available at
https://github.com/suhanmen/MECO.

</details>


### [26] [OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching](https://arxiv.org/abs/2510.09060)
*Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang*

Main category: cs.AI

TL;DR: 提出了一种无需训练、在推理时控制流式文本到图像模型的方法，通过特征空间目标和时间调度的随机扰动来增强生成多样性，同时保持图像质量和提示对齐。


<details>
  <summary>Details</summary>
Motivation: 流式文本到图像模型遵循确定性轨迹，用户需要重复采样才能发现多样模式，这是一个成本高且效率低的过程。

Method: 使用特征空间目标鼓励轨迹间的横向扩展，并通过时间调度的随机扰动重新引入不确定性。关键是将扰动投影到与生成流正交的方向，以在不降低图像细节或提示保真度的情况下增强变化。

Result: 在固定采样预算下，该方法在多个文本到图像设置中持续改进了Vendi Score和Brisque等多样性指标，同时保持了图像质量和对齐度。

Conclusion: 该方法无需重新训练或修改基础采样器，与常见的流匹配求解器兼容，理论上能单调增加体积代理，同时由于几何约束近似保持边际分布，从而稳健地保持生成质量。

Abstract: Flow-based text-to-image models follow deterministic trajectories, forcing
users to repeatedly sample to discover diverse modes, which is a costly and
inefficient process. We present a training-free, inference-time control
mechanism that makes the flow itself diversity-aware. Our method simultaneously
encourages lateral spread among trajectories via a feature-space objective and
reintroduces uncertainty through a time-scheduled stochastic perturbation.
Crucially, this perturbation is projected to be orthogonal to the generation
flow, a geometric constraint that allows it to boost variation without
degrading image details or prompt fidelity. Our procedure requires no
retraining or modification to the base sampler and is compatible with common
flow-matching solvers. Theoretically, our method is shown to monotonically
increase a volume surrogate while, due to its geometric constraints,
approximately preserving the marginal distribution. This provides a principled
explanation for why generation quality is robustly maintained. Empirically,
across multiple text-to-image settings under fixed sampling budgets, our method
consistently improves diversity metrics such as the Vendi Score and Brisque
over strong baselines, while upholding image quality and alignment.

</details>


### [27] [Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics](https://arxiv.org/abs/2510.09082)
*Bicheng Wang,Jinping Wang,Yibo Sue*

Main category: cs.AI

TL;DR: 提出了一种高阶网络动力学识别方法，通过动态超图学习捕捉复杂网络中的高阶非成对关系，结合Koopman算子理论和物理信息神经微分方程，实现复杂网络长期动态预测的高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）传统图学习只能处理成对关系，难以捕捉网络中的高阶非成对结构关系；2）理论预测模型精度不足，数据驱动模型缺乏可解释性。

Method: 1）引入动态超图学习捕捉高阶非成对关系；2）提出物理数据双驱动动态预测模块，结合Koopman算子理论将非线性动力学方程转化为线性系统，同时利用物理信息神经微分方程确保演化符合物理规律。

Result: 在公共数据集和自建产业链网络数据集上的实验验证表明，该方法具有良好的预测精度和长期预测性能。

Conclusion: 该方法通过动态超图学习和双驱动预测模块，有效解决了复杂网络动态预测中高阶关系建模和可解释性问题，实现了准确且可解释的长期动态预测。

Abstract: Learning complex network dynamics is fundamental to understanding, modelling
and controlling real-world complex systems. There are two main problems in the
task of predicting the dynamic evolution of complex networks: on the one hand,
existing methods usually use simple graphs to describe the relationships in
complex networks; however, this approach can only capture pairwise
relationships, while there may be rich non-pairwise structured relationships in
the network. First-order GNNs have difficulty in capturing dynamic non-pairwise
relationships. On the other hand, theoretical prediction models lack accuracy
and data-driven prediction models lack interpretability. To address the above
problems, this paper proposes a higher-order network dynamics identification
method for long-term dynamic prediction of complex networks. Firstly, to
address the problem that traditional graph machine learning can only deal with
pairwise relations, dynamic hypergraph learning is introduced to capture the
higher-order non-pairwise relations among complex networks and improve the
accuracy of complex network modelling. Then, a dual-driven dynamic prediction
module for physical data is proposed. The Koopman operator theory is introduced
to transform the nonlinear dynamical differential equations for the dynamic
evolution of complex networks into linear systems for solving. Meanwhile, the
physical information neural differential equation method is utilised to ensure
that the dynamic evolution conforms to the physical laws. The dual-drive
dynamic prediction module ensures both accuracy and interpretability of the
prediction. Validated on public datasets and self-built industrial chain
network datasets, the experimental results show that the method in this paper
has good prediction accuracy and long-term prediction performance.

</details>


### [28] [Leading the Follower: Learning Persuasive Agents in Social Deduction Games](https://arxiv.org/abs/2510.09087)
*Zhang Zheng,Deheng Ye,Peilin Zhao,Hao Wang*

Main category: cs.AI

TL;DR: 提出基于Stackelberg博弈论的强化学习框架，训练LLM智能体在社交推理游戏中生成具有说服力的对话，显著提升游戏表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在社交推理游戏中主要关注信息处理和策略选择，忽视了说服性沟通对影响其他玩家信念和反应的重要性。

Method: 将回合制对话形式化为Stackelberg竞争，当前玩家作为领导者战略性地影响追随者的回应，并基于此提出强化学习框架优化话语的说服力。

Result: 在三个不同的社交推理游戏中，所提出的智能体显著优于基线方法。

Conclusion: 这项工作代表了开发具有战略社会影响力AI智能体的重要一步，对需要说服性沟通的场景具有广泛意义。

Abstract: Large language model (LLM) agents have shown remarkable progress in social
deduction games (SDGs). However, existing approaches primarily focus on
information processing and strategy selection, overlooking the significance of
persuasive communication in influencing other players' beliefs and responses.
In SDGs, success depends not only on making correct deductions but on
convincing others to response in alignment with one's intent. To address this
limitation, we formalize turn-based dialogue in SDGs as a Stackelberg
competition, where the current player acts as the leader who strategically
influences the follower's response. Building on this theoretical foundation, we
propose a reinforcement learning framework that trains agents to optimize
utterances for persuasive impact. Through comprehensive experiments across
three diverse SDGs, we demonstrate that our agents significantly outperform
baselines. This work represents a significant step toward developing AI agents
capable of strategic social influence, with implications extending to scenarios
requiring persuasive communication.

</details>


### [29] [PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning](https://arxiv.org/abs/2510.09133)
*Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An*

Main category: cs.AI

TL;DR: 提出PAC推理方法，通过置信上界控制性能损失，在用户指定的容忍度内动态切换思考与非思考模式以节省计算成本


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂问题解决中表现出色，但部署时计算成本高。现有动态切换方法会引入额外推理错误且缺乏性能损失统计保证，这在关键应用中很重要

Method: 构建性能损失的单调不确定性函数置信上界，确定切换阈值，在分布无关的方式下确保有界性能损失

Result: 在推理基准测试中，该方法能节省计算预算并控制用户指定的性能损失

Conclusion: PAC推理方法为高效推理提供了理论保证，能在保证性能的前提下显著降低计算成本

Abstract: Large reasoning models (LRMs) have achieved remarkable progress in complex
problem-solving tasks. Despite this success, LRMs typically suffer from high
computational costs during deployment, highlighting a need for efficient
inference. A popular direction of efficiency improvement is to switch the LRM
between thinking and nonthinking modes dynamically. However, such approaches
often introduce additional reasoning errors and lack statistical guarantees for
the performance loss, which are critical for high-stakes applications. In this
work, we propose Probably Approximately Correct (PAC) reasoning that controls
the performance loss under the user-specified performance loss tolerance. In
particular, we construct an upper confidence bound on the performance loss,
formulated as a monotone function of the uncertainty score, and subsequently
determine a threshold for switching to the nonthinking model. Theoretically,
using the threshold to switch between the thinking and nonthinking modes
ensures bounded performance loss in a distribution-free manner. Our
comprehensive experiments on reasoning benchmarks show that the proposed method
can save computational budgets and control the user-specified performance loss.

</details>


### [30] [Dr. Bias: Social Disparities in AI-Powered Medical Guidance](https://arxiv.org/abs/2510.09162)
*Emma Kondrup,Anne Imouza*

Main category: cs.AI

TL;DR: 研究发现LLMs在生成医疗建议时存在系统性偏见，不同社会群体（特别是原住民和双性人）收到的建议可读性更差、更复杂，交叉群体中这种趋势更为明显。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗领域的广泛应用，需要评估其是否考虑医疗的社会性质，特别是健康差异和偏见如何影响生成的医疗建议。

Method: 通过模拟不同患者档案（性别、年龄、种族）向LLMs提出一系列医疗问题，比较生成回答的自然语言特征。

Result: LLMs生成的医疗建议在不同社会群体间存在系统性差异，原住民和双性人患者收到的建议可读性更低、更复杂，交叉群体中这种差异更加明显。

Conclusion: 鉴于公众对LLMs的信任日益增加，需要提高AI素养，并敦促AI开发者紧急调查和缓解这些系统性差异，确保公平的患者支持。

Abstract: With the rapid progress of Large Language Models (LLMs), the general public
now has easy and affordable access to applications capable of answering most
health-related questions in a personalized manner. These LLMs are increasingly
proving to be competitive, and now even surpass professionals in some medical
capabilities. They hold particular promise in low-resource settings,
considering they provide the possibility of widely accessible, quasi-free
healthcare support. However, evaluations that fuel these motivations highly
lack insights into the social nature of healthcare, oblivious to health
disparities between social groups and to how bias may translate into
LLM-generated medical advice and impact users. We provide an exploratory
analysis of LLM answers to a series of medical questions spanning key clinical
domains, where we simulate these questions being asked by several patient
profiles that vary in sex, age range, and ethnicity. By comparing natural
language features of the generated responses, we show that, when LLMs are used
for medical advice generation, they generate responses that systematically
differ between social groups. In particular, Indigenous and intersex patients
receive advice that is less readable and more complex. We observe these trends
amplify when intersectional groups are considered. Considering the increasing
trust individuals place in these models, we argue for higher AI literacy and
for the urgent need for investigation and mitigation by AI developers to ensure
these systemic differences are diminished and do not translate to unjust
patient support. Our code is publicly available on GitHub.

</details>


### [31] [Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation](https://arxiv.org/abs/2510.09223)
*Mubaris Nadeem,Madjid Fathi*

Main category: cs.AI

TL;DR: 本文提出了基于知识图谱结构的医学知识融合概念模型，旨在整合多种医疗知识源以支持精准的患者驱动决策。


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要统一的方法来收集、分析和利用现有医学知识，以支持关键的医疗决策。知识融合能够为医疗专业人员提供多个上下文对齐的知识源选择。

Method: 开发了基于知识图谱结构的多概念模型，研究如何实现知识融合并将各种知识源整合到知识图谱中，特别针对救援操作场景。

Result: 提出了能够整合多种医疗知识源的知识融合方法，为医疗决策提供支持。

Conclusion: 知识图谱结构为医学知识融合提供了可行框架，能够有效整合多源知识以支持精准的医疗决策制定。

Abstract: In the field of medicine and healthcare, the utilization of medical
expertise, based on medical knowledge combined with patients' health
information is a life-critical challenge for patients and health professionals.
The within-laying complexity and variety form the need for a united approach to
gather, analyze, and utilize existing knowledge of medical treatments, and
medical operations to provide the ability to present knowledge for the means of
accurate patient-driven decision-making. One way to achieve this is the fusion
of multiple knowledge sources in healthcare. It provides health professionals
the opportunity to select from multiple contextual aligned knowledge sources
which enables the support for critical decisions. This paper presents multiple
conceptual models for knowledge fusion in the field of medicine, based on a
knowledge graph structure. It will evaluate, how knowledge fusion can be
enabled and presents how to integrate various knowledge sources into the
knowledge graph for rescue operations.

</details>


### [32] [RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems](https://arxiv.org/abs/2510.09227)
*Hyundong Jin,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 该论文提出了基于PSPACE完全正则表达式问题的新基准，用于评估大语言模型和大推理模型的空间计算限制，揭示了常见失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注NP复杂度问题，但大语言模型在空间复杂度方面的计算限制仍不清楚，需要更严格的PSPACE完全问题来评估其计算能力。

Method: 通过双指数空间探索构建包含超过百万个正则表达式实例的数据集，使用声音过滤过程建立基准，并对6个LLM和5个LRM进行广泛评估。

Result: 评估揭示了常见失败模式，如冗长和重复，表明模型在处理PSPACE完全问题时存在空间计算限制。

Conclusion: 这项工作首次实证研究LLM和LRM的空间计算限制，为评估其高级推理能力提供了新框架。

Abstract: Large language models (LLMs) show strong performance across natural language
processing (NLP), mathematical reasoning, and programming, and recent large
reasoning models (LRMs) further emphasize explicit reasoning. Yet their
computational limits, particularly spatial complexity constrained by finite
context windows, remain poorly understood. While recent works often focus on
problems within the NP complexity class, we push the boundary by introducing a
novel benchmark grounded in two PSPACE-complete regular expression (regex)
problems: equivalence decision (RegexEQ) and minimization (RegexMin).
PSPACE-complete problems serve as a more rigorous standard for assessing
computational capacity, as their solutions require massive search space
exploration. We perform a double-exponential space exploration to construct a
labeled dataset of over a million regex instances with a sound filtering
process to build the benchmark. We conduct extensive evaluations on 6 LLMs and
5 LRMs of varying scales, revealing common failure patterns such as verbosity
and repetition. With its well-defined structure and quantitative evaluation
metrics, this work presents the first empirical investigation into the spatial
computational limitations of LLMs and LRMs, offering a new framework for
evaluating their advanced reasoning capabilities. Our code is available at
https://github.com/hyundong98/RegexPSPACE .

</details>


### [33] [Fundamentals of Building Autonomous LLM Agents](https://arxiv.org/abs/2510.09244)
*Victor de Lamo Castrillo,Habtom Kahsay Gidey,Alexander Lenz,Alois Knoll*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型(LLM)的智能体架构与实现方法，探讨如何构建能够自动化复杂任务、弥合与人类能力差距的"智能体化"LLM。


<details>
  <summary>Details</summary>
Motivation: 传统LLM在现实世界任务中存在局限性，研究旨在开发能够自动化复杂任务、弥合与人类能力差距的智能体化LLM。

Method: 构建包含四个关键组件的智能体架构：感知系统（将环境感知转换为有意义表示）、推理系统（制定计划、适应反馈、评估行动）、记忆系统（通过短期和长期机制保留知识）和执行系统（将内部决策转化为具体行动）。

Result: 集成这些系统可以创建更强大和通用的软件机器人，模拟人类认知过程以实现自主智能行为。

Conclusion: 通过整合感知、推理、记忆和执行系统，可以开发出能够模拟人类认知过程的智能体化LLM，实现更自主和智能的行为。

Abstract: This paper reviews the architecture and implementation methods of agents
powered by large language models (LLMs). Motivated by the limitations of
traditional LLMs in real-world tasks, the research aims to explore patterns to
develop "agentic" LLMs that can automate complex tasks and bridge the
performance gap with human capabilities. Key components include a perception
system that converts environmental percepts into meaningful representations; a
reasoning system that formulates plans, adapts to feedback, and evaluates
actions through different techniques like Chain-of-Thought and Tree-of-Thought;
a memory system that retains knowledge through both short-term and long-term
mechanisms; and an execution system that translates internal decisions into
concrete actions. This paper shows how integrating these systems leads to more
capable and generalized software bots that mimic human cognitive processes for
autonomous and intelligent behavior.

</details>


### [34] [Localist LLMs -- A Mathematical Framework for Dynamic Locality Control](https://arxiv.org/abs/2510.09338)
*Joachim Diederich*

Main category: cs.AI

TL;DR: 提出了一种新颖框架，通过可调节的局部性参数在训练和推理时动态控制语言模型内部表示的局部化程度，无需重新训练即可在可解释性和高性能之间连续切换。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在可解释性和性能之间的权衡问题，特别是在需要透明度和能力的监管领域中，提供从局部化（可解释、基于规则）到分布式（可泛化、高效）编码的连续谱系。

Method: 使用组稀疏惩罚注意力机制、信息论锚点设计和动态规则注入，通过数学证明建立明确的阈值条件，确保注意力集中在语义相关块上。

Result: 证明了当组稀疏惩罚超过特定阈值时，模型的注意力机制会集中在语义相关块上，实现低熵和高保真度，误差可忽略不计。

Conclusion: 该框架使从业者能够在可解释和高性能模式之间连续插值，支持需要透明度和能力的监管领域应用。

Abstract: We present a novel framework for training large language models with
continuously adjustable internal representations that span the full spectrum
from localist (interpretable, rule-based) to distributed (generalizable,
efficient) encodings. The key innovation is a locality dial, a tunable
parameter that dynamically controls the degree of localization during both
training and inference without requiring model retraining. This is achieved
through group sparsity penalties on attention mechanisms, information-theoretic
anchor design, and dynamic rule injection. We provide rigorous mathematical
proofs establishing explicit threshold conditions under which attention
provably concentrates on semantically relevant blocks, with exponential bounds
on attention entropy and pointer fidelity. Specifically, we prove that when
group sparsity penalties exceed certain threshold values, the model's attention
mechanisms concentrate on semantically relevant blocks, achieving low entropy
and high fidelity with negligible error. This framework enables practitioners
to continuously interpolate between interpretable and high-performance modes,
supporting applications in regulated domains requiring both transparency and
capability.

</details>


### [35] [Toward Mechanistic Explanation of Deductive Reasoning in Language Models](https://arxiv.org/abs/2510.09340)
*Davide Maltoni,Matteo Ferrara*

Main category: cs.AI

TL;DR: 小型语言模型能够通过习得底层规则而非统计学习来解决演绎推理任务，研究发现归纳头在实现规则补全和规则链式推理中起核心作用。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在逻辑推理问题中的内部机制，目前这些机制在很大程度上尚未被充分研究。

Method: 使用小型语言模型解决演绎推理任务，分析其内部表示和计算电路，特别关注归纳头的作用。

Result: 发现归纳头在实现逻辑推理所需的规则补全和规则链式推理步骤中发挥核心作用。

Conclusion: 研究揭示了语言模型通过习得推理规则而非统计学习来解决逻辑推理任务的内部工作机制，为理解模型推理能力提供了新的视角。

Abstract: Recent large language models have demonstrated relevant capabilities in
solving problems that require logical reasoning; however, the corresponding
internal mechanisms remain largely unexplored. In this paper, we show that a
small language model can solve a deductive reasoning task by learning the
underlying rules (rather than operating as a statistical learner). A low-level
explanation of its internal representations and computational circuits is then
provided. Our findings reveal that induction heads play a central role in the
implementation of the rule completion and rule chaining steps involved in the
logical inference required by the task.

</details>


### [36] [Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing](https://arxiv.org/abs/2510.09373)
*Augustin Delecluse,Pierre Schaus,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 本文提出序列变量作为约束编程中处理车辆路径问题的新方法，能够处理可选访问点并支持插入启发式算法。


<details>
  <summary>Details</summary>
Motivation: 传统基于后继变量的CP模型无法有效处理可选访问点或基于插入的启发式算法，限制了在车辆路径问题中的应用。

Method: 形式化定义了序列变量的计算域、更新操作和一致性级别，设计了专门的数据结构和全局约束，并集成到现有的基于回溯的CP求解器中。

Result: 序列变量简化了问题建模，在Dial-a-Ride问题上实现了有竞争力的计算性能。

Conclusion: 序列变量为车辆路径问题提供了更直观、声明性的建模框架，克服了传统CP模型的局限性。

Abstract: Constraint Programming (CP) offers an intuitive, declarative framework for
modeling Vehicle Routing Problems (VRP), yet classical CP models based on
successor variables cannot always deal with optional visits or insertion based
heuristics. To address these limitations, this paper formalizes sequence
variables within CP. Unlike the classical successor models, this computational
domain handle optional visits and support insertion heuristics, including
insertion-based Large Neighborhood Search. We provide a clear definition of
their domain, update operations, and introduce consistency levels for
constraints on this domain. An implementation is described with the underlying
data structures required for integrating sequence variables into existing
trail-based CP solvers. Furthermore, global constraints specifically designed
for sequence variables and vehicle routing are introduced. Finally, the
effectiveness of sequence variables is demonstrated by simplifying problem
modeling and achieving competitive computational performance on the Dial-a-Ride
Problem.

</details>


### [37] [Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges](https://arxiv.org/abs/2510.09404)
*Christian Bluethgen,Dave Van Veen,Daniel Truhn,Jakob Nikolas Kather,Michael Moor,Malgorzata Polacin,Akshay Chaudhari,Thomas Frauenfelder,Curtis P. Langlotz,Michael Krauthammer,Farhad Nooralahzadeh*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型（LLM）的智能体系统在放射学中的应用，探讨了从半自动化工作流程到自适应代理的设计、评估方法和挑战。


<details>
  <summary>Details</summary>
Motivation: 放射学具有多模态数据流和协调工作流程的特点，非常适合利用能够适应上下文并自动化复杂重复任务的智能体。虽然LLM在单个任务上表现良好，但单独使用未能充分发挥其在复杂多步骤工作流程中的潜力。

Method: 通过为LLM配备外部工具和反馈机制，构建能够展示不同程度自主性的系统，从半自动化工作流程到能够管理复杂过程的自适应代理。

Result: LLM驱动的智能体系统在放射学中显示出应用潜力，能够整合多源信息并执行复杂决策流程。

Conclusion: LLM驱动的智能体系统为放射学工作流程自动化提供了有前景的解决方案，但仍需解决错误级联、工具使用效率和医疗IT集成等挑战。

Abstract: Building agents, systems that perceive and act upon their environment with a
degree of autonomy, has long been a focus of AI research. This pursuit has
recently become vastly more practical with the emergence of large language
models (LLMs) capable of using natural language to integrate information,
follow instructions, and perform forms of "reasoning" and planning across a
wide range of tasks. With its multimodal data streams and orchestrated
workflows spanning multiple systems, radiology is uniquely suited to benefit
from agents that can adapt to context and automate repetitive yet complex
tasks. In radiology, LLMs and their multimodal variants have already
demonstrated promising performance for individual tasks such as information
extraction and report summarization. However, using LLMs in isolation
underutilizes their potential to support complex, multi-step workflows where
decisions depend on evolving context from multiple information sources.
Equipping LLMs with external tools and feedback mechanisms enables them to
drive systems that exhibit a spectrum of autonomy, ranging from semi-automated
workflows to more adaptive agents capable of managing complex processes. This
review examines the design of such LLM-driven agentic systems, highlights key
applications, discusses evaluation methods for planning and tool use, and
outlines challenges such as error cascades, tool-use efficiency, and health IT
integration.

</details>


### [38] [Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse](https://arxiv.org/abs/2510.09567)
*Jacopo Tagliabue,Ciro Greco*

Main category: cs.AI

TL;DR: 本文探讨了在数据湖仓中实现安全AI驱动自动化的方法，通过API优先、可编程的湖仓架构支持安全设计的智能体工作流。


<details>
  <summary>Details</summary>
Motivation: 数据湖仓运行敏感工作负载，AI驱动的自动化引发了关于信任、正确性和治理的担忧。需要找到方法让不可信的AI代理能在生产数据上安全操作。

Method: 使用Bauplan作为案例研究，展示了数据分支和声明式环境如何自然扩展到智能体，通过受证明携带代码启发的正确性检查来修复数据管道。

Result: 原型演示表明，不可信的AI代理可以在生产数据上安全操作，并展示了实现完全智能体化湖仓的路径。

Conclusion: API优先、可编程的湖仓为安全设计的智能体工作流提供了正确的抽象，通过数据分支和声明式环境实现可重现性和可观测性，同时减少攻击面。

Abstract: Data lakehouses run sensitive workloads, where AI-driven automation raises
concerns about trust, correctness, and governance. We argue that API-first,
programmable lakehouses provide the right abstractions for safe-by-design,
agentic workflows. Using Bauplan as a case study, we show how data branching
and declarative environments extend naturally to agents, enabling
reproducibility and observability while reducing the attack surface. We present
a proof-of-concept in which agents repair data pipelines using correctness
checks inspired by proof-carrying code. Our prototype demonstrates that
untrusted AI agents can operate safely on production data and outlines a path
toward a fully agentic lakehouse.

</details>


### [39] [GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data](https://arxiv.org/abs/2510.09580)
*Margarita Belova,Jiaxin Xiao,Shikhar Tuli,Niraj K. Jha*

Main category: cs.AI

TL;DR: GraphMERT是一个小型图形编码器模型，能够从非结构化文本语料库中提取高质量知识图谱，形成模块化的神经符号堆栈，在准确性和符号表示方面优于大型语言模型基准。


<details>
  <summary>Details</summary>
Motivation: 解决神经符号AI框架难以扩展的问题，以及神经方法隐含表示和近似推理导致的解释性和可信度限制，通过知识图谱提供可验证的符号推理。

Method: 引入GraphMERT图形编码器模型，从文本语料库及其内部表示中提取高质量知识图谱，形成神经学习抽象和符号知识图谱验证推理的模块化堆栈。

Result: 在糖尿病PubMed论文文本上，80M参数的GraphMERT生成的知识图谱达到69.8% FActScore和68.8% ValidityScore，优于32B参数LLM基准的40.2%和43.0%。

Conclusion: GraphMERT+KG是首个高效可扩展的神经符号模型，在基准准确性和符号表示方面达到最先进水平，解决了大型语言模型在生成可靠知识图谱时的局限性。

Abstract: Researchers have pursued neurosymbolic artificial intelligence (AI)
applications for nearly three decades because symbolic components provide
abstraction while neural components provide generalization. Thus, a marriage of
the two components can lead to rapid advancements in AI. Yet, the field has not
realized this promise since most neurosymbolic AI frameworks fail to scale. In
addition, the implicit representations and approximate reasoning of neural
approaches limit interpretability and trust. Knowledge graphs (KGs), a
gold-standard representation of explicit semantic knowledge, can address the
symbolic side. However, automatically deriving reliable KGs from text corpora
has remained an open problem. We address these challenges by introducing
GraphMERT, a tiny graphical encoder-only model that distills high-quality KGs
from unstructured text corpora and its own internal representations. GraphMERT
and its equivalent KG form a modular neurosymbolic stack: neural learning of
abstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the
first efficient and scalable neurosymbolic model to achieve state-of-the-art
benchmark accuracy along with superior symbolic representations relative to
baselines.
  Concretely, we target reliable domain-specific KGs that are both (1) factual
(with provenance) and (2) valid (ontology-consistent relations with
domain-appropriate semantics). When a large language model (LLM), e.g.,
Qwen3-32B, generates domain-specific KGs, it falls short on reliability due to
prompt sensitivity, shallow domain expertise, and hallucinated relations. On
text obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT
yields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG
that achieves only 40.2% FActScore. The GraphMERT KG also attains a higher
ValidityScore of 68.8%, versus 43.0% for the LLM baseline.

</details>


### [40] [LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?](https://arxiv.org/abs/2510.09595)
*Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang*

Main category: cs.AI

TL;DR: LiveOIBench是一个包含403个奥林匹克级别编程竞赛问题的基准测试，具有高质量测试用例和离线评估系统，用于评估大语言模型的编程能力。


<details>
  <summary>Details</summary>
Motivation: 当前编程基准测试存在缺乏高难度问题、测试用例覆盖不足、依赖在线平台API等问题，需要更全面可靠的评估标准。

Method: 从72个官方信息学奥林匹克竞赛中收集403个专家策划的问题，每个问题平均60个测试用例，构建包含四个关键特征的基准测试系统。

Result: GPT-5达到81.76百分位，但仍低于顶尖人类选手（通常超过90百分位）；开源模型GPT-OSS-120B仅达60百分位，与前沿闭源模型存在显著差距。

Conclusion: 强大的推理模型应优先精确问题分析而非过度探索，未来模型应强调结构化分析并减少不必要的探索。

Abstract: Competitive programming problems increasingly serve as valuable benchmarks to
evaluate the coding capabilities of large language models (LLMs) due to their
complexity and ease of verification. Yet, current coding benchmarks face
limitations such as lack of exceptionally challenging problems, insufficient
test case coverage, reliance on online platform APIs that limit accessibility.
To address these issues, we introduce LiveOIBench, a comprehensive benchmark
featuring 403 expert-curated Olympiad-level competitive programming problems,
each with an average of 60 expert-designed test cases. The problems are sourced
directly from 72 official Informatics Olympiads in different regions conducted
between 2023 and 2025. LiveOIBench distinguishes itself through four key
features: (1) meticulously curated high-quality tasks with detailed subtask
rubrics and extensive private test cases; (2) direct integration of elite
contestant performance data to enable informative comparison against
top-performing humans; (3) planned continuous, contamination-free updates from
newly released Olympiad problems; and (4) a self-contained evaluation system
facilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular
general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable
81.76th percentile, a strong result that nonetheless falls short of top human
contestant performance, who usually place above 90th. In contrast, among
open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,
underscoring significant capability disparities from frontier closed models.
Detailed analyses indicate that robust reasoning models prioritize precise
problem analysis over excessive exploration, suggesting future models should
emphasize structured analysis and minimize unnecessary exploration. All data,
code, and leaderboard results will be made publicly available on our website.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [41] [On Estimation of Angles of Arrival in Monostatic ISAC Without Instantaneous Transmit CSI](https://arxiv.org/abs/2510.08793)
*Ataher Sams,Simone Di Bari,Besma Smida,Natasha Devroye,Daniela Tuninetti,Giorgio Taricco*

Main category: cs.IT

TL;DR: 本文研究了在基站仅有统计CSI而非完整CSI的更现实场景下，ISAC系统的基本性能极限。通过贝叶斯克拉美罗界分析，推导了感知性能与通信速率的权衡区域，提出了多种波束分配策略。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究大多假设基站具有完整的信道状态信息，但在实际系统中基站通常只有统计CSI。本文旨在探索在更现实的统计CSI条件下ISAC系统的性能极限。

Method: 采用贝叶斯克拉美罗界框架分析感知性能，假设基站具有所有AoA的统计CSI，通信接收器具有完美CSI。提出了在相干时间内共享感知和通信波束功率的传输策略。

Result: 分析表明，利用目标特定感知矩阵主特征向量的波束分配策略能最小化单个AoA估计误差，而平衡感知和通信方向的策略能优化联合估计性能。利用更新后的BCRB感知信息可显著提高通信速率。

Conclusion: 在统计CSI条件下，通过合理的波束分配策略可以实现感知与通信的有效权衡，利用通信接收器较低的信道不确定性可以显著提升系统性能。

Abstract: This paper explores the fundamental limits of Integrated Sensing and
Communication (ISAC) in a more realistic setting compared to previous
literature when the Base Staion (BS) has only statistical CSI of the
communication user rather than full CSI. We analyze a monostatic setting where
the BS performs multi-target Angle of Arrival (AoA) estimation while
simultaneously communicating with one of the targets. We assume that the BS has
statistical CSI about all AoAs, with less uncertainty in the AoA of the
communication receiver. The communication receiver is assumed to have perfect
CSI. Utilizing a Bayesian Cram\'er-Rao Bound (BCRB) framework to characterize
the fundamental limits of sensing under minimum mean square error (MMSE)
criteria, we derive achievable BCRB-rate trade-off regions. Our approach
introduces a number of transmission strategies that share power across sensing
and communication beams over a coherence time. Our analysis reveals that beam
allocation strategies leveraging the principal eigenvectors of the
target-specific sensing matrices minimize individual AoA estimation errors,
while strategies balancing sensing and communication directions optimize joint
estimation performance at the cost of individual accuracy. We demonstrate that
leveraging updated BCRB-based sensing information for the communication
receiver, due to its lower channel uncertainty, enables significantly improved
communication rates.

</details>


### [42] [Observation Matrix Design for Densifying MIMO Channel Estimation via 2D Ice Filling](https://arxiv.org/abs/2510.08887)
*Zijian Zhang,Mingyao Cui*

Main category: cs.IT

TL;DR: 提出了一种用于密集MIMO系统信道估计的二维注水算法，通过联合设计预编码器和组合器来最大化接收导频与信道之间的互信息，显著提升了信道估计性能。


<details>
  <summary>Details</summary>
Motivation: 密集MIMO系统中天线间距小于波长，导致天线间存在强相关性，这为利用信道状态信息先验知识来优化观测矩阵设计提供了机会。

Method: 提出了二维注水算法，将MIMO信道协方差的特征空间解耦为发射天线和接收天线相关的两个子空间，通过设置预编码器和组合器为这些子空间的特征向量来生成近最优观测矩阵。还扩展了该方法到混合组合系统，开发了两阶段2DIF算法。

Result: 仿真结果表明，与现有最优方案相比，所提出的2DIF和TS-2DIF方法能够实现更优越的信道估计精度。

Conclusion: 通过利用密集MIMO系统中的信道相关性先验知识，联合设计预编码器和组合器可以显著提升信道估计性能，所提出的2DIF算法为此提供了一种高效的解决方案。

Abstract: In recent years, densifying multiple-input multiple-output (MIMO) has
attracted much attention from the communication community. Thanks to the
subwavelength antenna spacing, the strong correlations among densifying
antennas provide sufficient prior knowledge about channel state information
(CSI). This inspires the careful design of observation matrices (e.g., transmit
precoders and receive combiners), that exploits the CSI prior knowledge, to
boost channel estimation performance. Aligned with this vision, this work
proposes to jointly design the combiners and precoders by maximizing the mutual
information between the received pilots and densifying MIMO channels. A
two-dimensional ice-filling (2DIF) algorithm is proposed to efficiently
accomplish this objective. The algorithm is motivated by the fact that the
eigenspace of MIMO channel covariance can be decoupled into two
sub-eigenspaces, which are associated with the correlations of transmitter
antennas and receiver antennas, respectively. By properly setting the precoder
and the combiner as the eigenvectors from these two sub-eigenspaces, the 2DIF
promises to generate near-optimal observation matrices. Moreover, we further
extend the 2DIF method to the popular hybrid combining systems, where a
two-stage 2DIF (TS-2DIF) algorithm is developed to handle the analog combining
circuits realized by phase shifters. Simulation results demonstrate that,
compared to the state-of-the-art schemes, the proposed 2DIF and TS-2DIF methods
can achieve superior channel estimation accuracy.

</details>


### [43] [Soft Guessing Under Logarithmic Loss Allowing Errors and Variable-Length Source Coding](https://arxiv.org/abs/2510.09015)
*Shota Saito,Hamdi Joudeh*

Main category: cs.IT

TL;DR: 本文研究了在对数损失失真度量下允许错误的软猜测问题，推导了最优猜测策略和单次上下界，并建立了与变长有损源编码的联系。


<details>
  <summary>Details</summary>
Motivation: 研究在对数损失失真度量下允许错误的软猜测问题，旨在找到最优猜测策略并建立与信息论中其他问题的联系。

Method: 推导了最优猜测策略，建立了单次上下界，对i.i.d.源进行了渐近分析，并扩展到有边信息的情况。

Result: 得到了最小猜测矩的单次上下界和渐近展开，揭示了Rényi熵、平滑Rényi熵及其条件版本在问题中的重要作用。

Conclusion: 成功建立了软猜测允许错误与变长有损源编码之间的联系，Rényi熵类在分析中发挥了关键作用。

Abstract: This paper considers the problem of soft guessing under a logarithmic loss
distortion measure while allowing errors. We find an optimal guessing strategy,
and derive single-shot upper and lower bounds for the minimal guessing moments
as well as an asymptotic expansion for i.i.d. sources. These results are
extended to the case where side information is available to the guesser.
Furthermore, a connection between soft guessing allowing errors and
variable-length lossy source coding under logarithmic loss is demonstrated. The
R\'enyi entropy, the smooth R\'enyi entropy, and their conditional versions
play an important role.

</details>


### [44] [Low Complexity Detector for XL-MIMO Uplink: A Cross Splitting Based Information Geometry Approach](https://arxiv.org/abs/2510.09039)
*Wenjun Zhang,An-An Lu,Xiqi Gao*

Main category: cs.IT

TL;DR: 提出CS-IGA算法，一种用于超大规模MIMO系统上行信号恢复的低复杂度迭代检测器，通过交叉矩阵分解降低计算复杂度，并扩展到非线性检测。


<details>
  <summary>Details</summary>
Motivation: 传统迭代检测器如AMP和IGA的每次迭代复杂度随基站天线数量增加，造成计算瓶颈，需要更高效的检测算法。

Method: 引入自然参数的后验分布中的交叉矩阵分解，基于匹配滤波器进行迭代检测，并扩展到非线性检测NCS-IGA，嵌入离散星座约束。

Result: 在真实信道条件下，CS-IGA在线性和非线性检测中达到或超过贝叶斯最优AMP和IGA的误码率性能，且迭代次数更少、计算成本显著降低。

Conclusion: CS-IGA是下一代XL-MIMO系统中高吞吐量信号检测的实用且强大的解决方案。

Abstract: In this paper, we propose the cross splitting based information geometry
approach (CS-IGA), a novel and low complexity iterative detector for uplink
signal recovery in extralarge-scale MIMO (XL-MIMO) systems. Conventional
iterative detectors, such as the approximate message passing (AMP) algorithm
and the traditional information geometry algorithm (IGA), suffer from a per
iteration complexity that scales with the number of base station (BS) antennas,
creating a computational bottleneck. To overcome this, CS-IGA introduces a
novel cross matrix splitting of the natural parameter in the a posteriori
distribution. This factorization allows the iterative detection based on the
matched filter, which reduces per iteration computational complexity.
Furthermore, we extend this framework to nonlinear detection and propose
nonlinear CSIGA (NCS-IGA) by seamlessly embedding discrete constellation
constraints, enabling symbol-wise processing without external interference
cancellation loops. Comprehensive simulations under realistic channel
conditions demonstrate that CS-IGA matches or surpasses the bit error rate
(BER) performance of Bayes optimal AMP and IGA for both linear and nonlinear
detection, while achieving this with fewer iterations and a substantially lower
computational cost. These results establish CS-IGA as a practical and powerful
solution for high-throughput signal detection in next generation XL-MIMO
systems.

</details>


### [45] [Optimal binary codes from $\mathcal{C}_{D}$-codes over a non-chain ring](https://arxiv.org/abs/2510.09057)
*Ankit Yadav,Ritumoni Sarma,Anuj Kumar Bhagat*

Main category: cs.IT

TL;DR: 该论文研究了基于环R的CD码的子域码CD(2)，分析了它们的汉明重量分布和参数，发现了多个距离最优的无限码族，并给出了这些码为极小码和自正交码的充分条件，还构造了强正则图。


<details>
  <summary>Details</summary>
Motivation: 在Shi和Li先前研究的基础上，进一步研究基于特定环的CD码的子域码，探索其编码特性和应用价值。

Method: 使用从单纯复形导出的集合D，研究环R上的CD码及其二进制子域码CD(2)，分析汉明重量分布和参数。

Result: 发现了多个无限码族是距离最优的，给出了码为极小码和自正交码的充分条件，并构造了两个强正则图族。

Conclusion: 该研究扩展了基于环的编码理论，提供了新的距离最优码族和强正则图构造方法。

Abstract: In \cite{shi2022few-weight}, Shi and Li studied $\mathcal{C}_D$-codes over
the ring $\mathcal{R}:=\mathbb{F}_2[x,y]/\langle x^2, y^2, xy-yx\rangle$ and
their binary Gray images, where $D$ is derived using certain simplicial
complexes. We study the subfield codes $\mathcal{C}_{D}^{(2)}$ of
$\mathcal{C}_{D}$-codes over $\mathcal{R},$ where $D$ is as in
\cite{shi2022few-weight} and more. We find the Hamming weight distribution and
the parameters of $\mathcal{C}_D^{(2)}$ for various $D$, and identify several
infinite families of codes that are distance-optimal. Besides, we provide
sufficient conditions under which these codes are minimal and self-orthogonal.
Two families of strongly regular graphs are obtained as an application of the
constructed two-weight codes.

</details>


### [46] [A Hybrid I/O Relation Estimation Scheme for Zak-OTFS Receivers](https://arxiv.org/abs/2510.09215)
*Sai Pradeep Muppaneni,Vineetha Yogesh,A. Chockalingam*

Main category: cs.IT

TL;DR: 提出了一种混合的延迟-多普勒域输入输出关系估计方法，结合模型依赖和模型无关方法的优点，以改善Zak-OTFS调制中的信号检测性能。


<details>
  <summary>Details</summary>
Motivation: 模型无关方法只能估计有限DD平面区域的有效信道，且性能受DD脉冲成形滤波器定位特性的影响，定位差的脉冲形状会导致性能下降。

Method: 使用新颖的模型依赖方案获得模型无关估计区域外的粗略有效信道估计，并将其与模型无关估计结合，获得改进的整体I/O关系估计。

Result: 在具有分数DD的Vehicular-A、TDL-A和TDL-C信道模型上的仿真结果表明，所提出的混合估计方法比纯模型无关方法具有更优越的性能。

Conclusion: 提出的混合估计方案有效缓解了模型无关方法在DD平面估计范围有限的问题，实现了更好的I/O关系估计性能。

Abstract: In this paper, we consider the problem of estimating the delay-Doppler (DD)
domain input-output (I/O) relation in Zak-OTFS modulation, which is needed for
signal detection. Two approaches, namely, model-dependent and model-free
approaches, can be employed for this purpose. The model-dependent approach
requires explicit estimation of the physical channel parameters (path delays,
Dopplers, and gains) to obtain the I/O relation. Such an explicit estimation is
not required in the model-free approach, where the I/O relation can be
estimated by reading off the samples in the fundamental DD period of the
received pilot frame. Model-free approach has the advantage of acquiring
fractional DD channels with simplicity. However, the read-off in the model-free
approach provides an estimate of the effective channel only over a limited
region in the DD plane but it does not provide an estimate for the region
outside, and this can affect the estimation performance depending on the pulse
shaping characteristics of the DD pulse shaping filter used. A poorly localized
DD pulse shape leads to an increased degradation in performance. Motivated by
this, in this paper, we propose a novel, yet simple, I/O relation estimation
scheme that alleviates the above issue in the model-free approach. We achieve
this by obtaining a coarse estimate of the effective channel outside the
model-free estimation region using a novel model-dependent scheme and using
this estimate along with the model-free estimate to obtain an improved estimate
of the overall I/O relation. We devise the proposed estimation scheme for both
exclusive and embedded pilot frames. Our simulation results using Vehicular-A,
TDL-A and TDL-C channel models with fractional DDs show that the proposed
hybrid estimation approach achieves superior performance compared to the pure
model-free approach.

</details>


### [47] [Serial Polar Automorphism Ensemble Decoders for Physical Unclonable Functions](https://arxiv.org/abs/2510.09220)
*Marvin Rübenacke,Sebastian Cammerer,Michael Sullivan,Alexander Keller*

Main category: cs.IT

TL;DR: 提出了一种基于Polar码和低复杂度自同构集成解码(AED)的物理不可克隆函数(PUF)编码方案，相比BCH码基线，在相同312位有效载荷下减少1.75倍码字位数，实现10^-6的块错误率。


<details>
  <summary>Details</summary>
Motivation: PUF应用需要极低失败率(10^-6以下)和高达22%的原始输入误码率，这要求设计高效的超低速率编码方案。

Method: 使用Polar码和低复杂度AED方案，通过串行AED重用单个连续消除(SC)解码器，引入级联和递归交织器扩展AED候选数，采用3位量化策略减少SC解码器面积。

Result: 与BCH码基线相比，在相同K=312有效载荷下，码字位数减少1.75倍，达到相同的10^-6块错误率，减少辅助数据存储和芯片面积。

Conclusion: 该编码方案为PUF应用提供了高效的超低速率编码解决方案，显著减少了存储需求和芯片面积。

Abstract: Physical unclonable functions (PUFs) involve challenging practical
applications of error-correcting codes (ECCs), requiring extremely low failure
rates on the order of $10^{-6}$ and below despite raw input bit error rates as
high as 22%. These requirements call for an efficient ultra-low rate code
design. In this work, we propose a novel coding scheme tailored for PUFs based
on Polar codes and a low-complexity version of automorphism ensemble decoding
(AED). Notably, our serial AED scheme reuses a single successive cancellation
(SC) decoder across multiple decoding attempts. By introducing cascaded and
recursive interleavers, we efficiently scale the number of AED candidates
without requiring expensive large multiplexers. An aggressive quantization
strategy of only 3 bits per message further reduces the area requirements of
the underlying SC decoder. The resulting coding scheme achieves the same block
error rate of $10^{-6}$ as our baseline based on Bose-Ray-Chaudhuri-Hocquenghem
(BCH) codes while requiring 1.75x fewer codeword bits to encode the same K =
312 payload bits. This reduction translates directly into 1.75x less helper
data storage and, consequently, a smaller overall chip area.

</details>


### [48] [Site-Specific RIS Deployment in Cellular Networks via Calibrated Ray Tracing](https://arxiv.org/abs/2510.09478)
*Sina Beyraghi,Javad Shabanpour,Giovanni Geraci,Paul Almasan,Angel Lozano*

Main category: cs.IT

TL;DR: 本文提出了一种基于数字孪生的全自动RIS部署策略，在4G、5G和假设的6G频段上联合优化RIS位置、方向、配置和基站波束成形，结果显示有意义的覆盖增强需要密集的大孔径RIS部署。


<details>
  <summary>Details</summary>
Motivation: 验证大规模RIS部署的实际可行性和成本效益，通过数字孪生技术探索RIS在城市环境中的最优部署策略。

Method: 使用Sionna射线追踪构建英国城市的数字孪生模型，通过散射射线识别候选RIS位置，用户聚类减少部署开销，联合优化RIS位置、方向、配置和基站波束成形。

Result: 结果表明，有意义的覆盖增强需要密集的大孔径RIS部署，这引发了对大规模RIS采用的实际可行性和成本的质疑。

Conclusion: 虽然RIS技术能够改善覆盖，但大规模部署需要密集的大孔径RIS，其成本和实用性值得进一步评估。

Abstract: This work introduces a fully-automated RIS deployment strategy validated
through a digital twin, powered by Sionna ray tracing, of a UK city. On a scene
calibrated with measured data, the method jointly optimizes RIS placement,
orientation, configuration, and BS beamforming across 4G, 5G, and hypothetical
6G frequencies. Candidate RIS sites are identified via scattering-based rays,
while user clustering reduces deployment overhead. Results show that meaningful
coverage enhancement requires dense, large-aperture RIS deployments, raising
questions about the practicality and cost of large-scale RIS adoption.

</details>


### [49] [Precoder Design in Multi-User FDD Systems with VQ-VAE and GNN](https://arxiv.org/abs/2510.09495)
*Srikar Allaparapu,Michael Baur,Benedikt Böck,Michael Joham,Wolfgang Utschick*

Main category: cs.IT

TL;DR: 提出基于VQ-VAE的端到端预编码框架，解决了GMM组件数量随反馈比特指数增长的问题，在FDD系统中实现了更高的和速率性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于GMM和GNN的预编码方法存在GMM组件数量随反馈比特指数增长的缺点，需要更高效的解决方案来提升多用户无线系统的性能。

Method: 使用向量量化变分自编码器(VQ-VAE)替代GMM，将GNN与VQ-VAE联合训练，并结合导频优化形成端到端模型。

Result: 仿真显示所提框架在减少导频或反馈比特的情况下，相比传统子DFT导频矩阵和迭代预编码算法具有优越的和速率性能。

Conclusion: VQ-VAE为基础的端到端预编码框架有效解决了GMM的可扩展性问题，为FDD系统提供了更高效的预编码解决方案。

Abstract: Robust precoding is efficiently feasible in frequency division duplex (FDD)
systems by incorporating the learnt statistics of the propagation environment
through a generative model. We build on previous work that successfully
designed site-specific precoders based on a combination of Gaussian mixture
models (GMMs) and graph neural networks (GNNs). In this paper, by utilizing a
vector quantized-variational autoencoder (VQ-VAE), we circumvent one of the key
drawbacks of GMMs, i.e., the number of GMM components scales exponentially to
the feedback bits. In addition, the deep learning architecture of the VQ-VAE
allows us to jointly train the GNN together with VQ-VAE along with pilot
optimization forming an end-to-end (E2E) model, resulting in considerable
performance gains in sum rate for multi-user wireless systems. Simulations
demonstrate the superiority of the proposed frameworks over the conventional
methods involving the sub-discrete Fourier transform (DFT) pilot matrix and
iterative precoder algorithms enabling the deployment of systems characterized
by fewer pilots or feedback bits.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [50] [Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model](https://arxiv.org/abs/2510.09551)
*Gavriel Di Nepi,Federico Siciliano,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: 对Google Titans模型的轻量级重实现与评估，发现其神经记忆组件能持续提升性能，但整体表现不总是优于基线方法。


<details>
  <summary>Details</summary>
Motivation: Google Titans模型缺乏公开代码且原始描述存在模糊性，阻碍了可复现性研究，因此需要重新实现并进行全面评估。

Method: 开发了Titans的轻量级重实现，并在掩码语言建模、时间序列预测和推荐任务上进行了综合评估。

Result: Titans并不总是优于现有基线方法（由于分块处理），但其神经记忆组件相比仅使用注意力的模型能持续提升性能。

Conclusion: 确认了Titans模型的创新潜力，但指出了实际局限性，为未来研究提出了问题。

Abstract: By the end of 2024, Google researchers introduced Titans: Learning at Test
Time, a neural memory model achieving strong empirical results across multiple
tasks. However, the lack of publicly available code and ambiguities in the
original description hinder reproducibility. In this work, we present a
lightweight reimplementation of Titans and conduct a comprehensive evaluation
on Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.
Our results reveal that Titans does not always outperform established baselines
due to chunking. However, its Neural Memory component consistently improves
performance compared to attention-only models. These findings confirm the
model's innovative potential while highlighting its practical limitations and
raising questions for future research.

</details>
