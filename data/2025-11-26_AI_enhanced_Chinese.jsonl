{"id": "2511.19699", "categories": ["cs.NI", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19699", "abs": "https://arxiv.org/abs/2511.19699", "authors": ["Charles Fleming", "Vijoy Pandey", "Ramana Kompella", "Luca Muscariello"], "title": "A Layered Protocol Architecture for the Internet of Agents", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance improvements and the ability to learn domain-specific languages (DSLs), including APIs and tool interfaces. This capability has enabled the creation of AI agents that can perform preliminary computations and act through tool calling, now being standardized via protocols like MCP. However, LLMs face fundamental limitations: their context windows cannot grow indefinitely, constraining their memory and computational capacity. Agent collaboration emerges as essential for solving increasingly complex problems, mirroring how computational systems rely on different types of memory to scale. The \"Internet of Agents\" (IoA) represents the communication stack that enables agents to scale by distributing computation across collaborating entities.\n  Current network architectural stacks (OSI and TCP/IP) were designed for data delivery between hosts and processes, not for agent collaboration with semantic understanding. To address this gap, we propose two new layers: an \\textbf{Agent Communication Layer (L8)} and an \\textbf{Agent Semantic Negotiation Layer (L9)}. L8 formalizes the \\textit{structure} of communication, standardizing message envelopes, speech-act performatives (e.g., REQUEST, INFORM), and interaction patterns (e.g., request-reply, publish-subscribe), building on protocols like MCP. L9, which does not exist today, formalizes the \\textit{meaning} of communication, enabling agents to discover, negotiate, and lock a \"Shared Context\" -- a formal schema defining the concepts, tasks, and parameters relevant to their interaction. Together, these layers provide the foundation for scalable, distributed agent collaboration, enabling the next generation of multi-agentic systems.", "AI": {"tldr": "\u63d0\u51fa\u5728\u73b0\u6709\u7f51\u7edc\u67b6\u6784\u6808\u4e0a\u589e\u52a0\u4e24\u4e2a\u65b0\u5c42(L8\u548cL9)\uff0c\u4ee5\u652f\u6301\u667a\u80fd\u4f53\u95f4\u7684\u8bed\u4e49\u5316\u534f\u4f5c\u901a\u4fe1\uff0c\u89e3\u51b3LLM\u5728\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u8ba1\u7b97\u80fd\u529b\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\uff0c\u65e0\u6cd5\u65e0\u9650\u6269\u5c55\u5185\u5b58\u548c\u8ba1\u7b97\u80fd\u529b\uff0c\u9700\u8981\u667a\u80fd\u4f53\u534f\u4f5c\u6765\u89e3\u51b3\u590d\u6742\u95ee\u9898\u3002\u73b0\u6709\u7f51\u7edc\u67b6\u6784\u662f\u4e3a\u4e3b\u673a\u95f4\u6570\u636e\u4f20\u8f93\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u5bf9\u667a\u80fd\u4f53\u8bed\u4e49\u534f\u4f5c\u7684\u652f\u6301\u3002", "method": "\u5728OSI\u548cTCP/IP\u6808\u57fa\u7840\u4e0a\u65b0\u589e\u4e24\u4e2a\u5c42\uff1aL8\u667a\u80fd\u4f53\u901a\u4fe1\u5c42\uff08\u6807\u51c6\u5316\u6d88\u606f\u7ed3\u6784\u3001\u8a00\u8bed\u884c\u4e3a\u3001\u4ea4\u4e92\u6a21\u5f0f\uff09\u548cL9\u667a\u80fd\u4f53\u8bed\u4e49\u534f\u5546\u5c42\uff08\u5efa\u7acb\u5171\u4eab\u4e0a\u4e0b\u6587\uff0c\u5b9a\u4e49\u6982\u5ff5\u3001\u4efb\u52a1\u548c\u53c2\u6570\uff09\u3002", "result": "\u6784\u5efa\u4e86\u652f\u6301\u667a\u80fd\u4f53\u53d1\u73b0\u3001\u534f\u5546\u548c\u9501\u5b9a\u5171\u4eab\u4e0a\u4e0b\u6587\u7684\u901a\u4fe1\u6846\u67b6\uff0c\u4e3a\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "L8\u548cL9\u5c42\u4e3a\u53ef\u6269\u5c55\u7684\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u4e86\u5fc5\u8981\u57fa\u7840\uff0c\u5c06\u63a8\u52a8\u4e0b\u4e00\u4ee3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.19868", "categories": ["cs.NI", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.19868", "abs": "https://arxiv.org/abs/2511.19868", "authors": ["Kasidis Arunruangsirilert"], "title": "Field Test of 5G New Radio (NR) UL-MIMO and UL-256QAM for HD Live-Streaming", "comment": "2025 IEEE International Conference on Visual Communications and Image Processing (VCIP 2025), 1-4 December 2025, Klagenfurt, Austria", "summary": "The exponential growth of User-Generated Content (UGC), especially High-Definition (HD) live video streaming, places a significant demand on the uplink capabilities of mobile networks. To address this, the 5G New Radio (NR) standard introduced key uplink enhancements, including Uplink Multi-Input Multi-Output (UL-MIMO) and Uplink 256QAM, to improve throughput and spectral efficiency. However, while the benefits of these features for raw data rates are well-documented, their practical impact on real-time applications like live-streaming is not yet well understood. This paper investigates the performance of UL-MIMO and UL-256QAM for HD live-streaming over a commercial 5G network using the Real-Time Messaging Protocol (RTMP). To ensure a fair assessment, we conduct a comparative analysis by modifying the modem firmware of commercial User Equipment (UE), allowing these features to be selectively enabled and disabled on the same device. Performance is evaluated based on key metrics, including dropped video frames and connection stability. Furthermore, this study analyzes 5G Radio Frequency (RF) parameters to quantify the spectral efficiency impact, specifically examining metrics derived from the Channel State Information (CSI) framework, including Reference Signal Received Power (CSI-RSRP), Reference Signal Received Quality (CSI-RSRQ), and Signal-to-Interference-plus-Noise Ratio (CSI-SINR).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e865G\u7f51\u7edc\u4e2dUL-MIMO\u548cUL-256QAM\u5bf9\u9ad8\u6e05\u76f4\u64ad\u6d41\u5a92\u4f53\u6027\u80fd\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u901a\u8fc7\u4fee\u6539\u5546\u7528\u8bbe\u5907\u56fa\u4ef6\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "motivation": "\u968f\u7740\u7528\u6237\u751f\u6210\u5185\u5bb9\u7279\u522b\u662f\u9ad8\u6e05\u76f4\u64ad\u89c6\u9891\u7684\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5bf9\u79fb\u52a8\u7f51\u7edc\u4e0a\u884c\u80fd\u529b\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u867d\u71365G NR\u6807\u51c6\u5f15\u5165\u4e86UL-MIMO\u548cUL-256QAM\u7b49\u4e0a\u884c\u589e\u5f3a\u529f\u80fd\uff0c\u4f46\u8fd9\u4e9b\u529f\u80fd\u5bf9\u5b9e\u65f6\u5e94\u7528\u7684\u5b9e\u9645\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u5546\u7528\u7528\u6237\u8bbe\u5907\u7684\u8c03\u5236\u89e3\u8c03\u5668\u56fa\u4ef6\uff0c\u9009\u62e9\u6027\u542f\u7528\u548c\u7981\u7528UL-MIMO\u548cUL-256QAM\u529f\u80fd\uff0c\u5728\u76f8\u540c\u8bbe\u5907\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002\u4f7f\u7528RTMP\u534f\u8bae\u5728\u5546\u75285G\u7f51\u7edc\u4e0a\u8bc4\u4f30\u9ad8\u6e05\u76f4\u64ad\u6027\u80fd\uff0c\u5e76\u5206\u67905G\u5c04\u9891\u53c2\u6570\u6765\u91cf\u5316\u9891\u8c31\u6548\u7387\u5f71\u54cd\u3002", "result": "\u8bc4\u4f30\u4e86\u4e22\u5e27\u7387\u548c\u8fde\u63a5\u7a33\u5b9a\u6027\u7b49\u5173\u952e\u6307\u6807\uff0c\u5e76\u57fa\u4e8eCSI\u6846\u67b6\u5206\u6790\u4e86CSI-RSRP\u3001CSI-RSRQ\u548cCSI-SINR\u7b49\u53c2\u6570\u6765\u91cf\u5316\u9891\u8c31\u6548\u7387\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e35G\u4e0a\u884c\u589e\u5f3a\u529f\u80fd\u5728\u5b9e\u9645\u76f4\u64ad\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u586b\u8865\u4e86\u7406\u8bba\u6570\u636e\u901f\u7387\u4e0e\u5b9e\u9645\u5e94\u7528\u6027\u80fd\u4e4b\u95f4\u7684\u8ba4\u77e5\u7a7a\u767d\u3002"}}
{"id": "2511.19870", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.19870", "abs": "https://arxiv.org/abs/2511.19870", "authors": ["Kasidis Arunruangsirilert", "Pasapong Wongprasert", "Jiro Katto"], "title": "Performance Evaluation of Uplink 256QAM on Commercial 5G New Radio (NR) Networks", "comment": "2024 IEEE Wireless Communications and Networking Conference (WCNC), 21-24 April 2024, Dubai, United Arab Emirates", "summary": "While Uplink 256QAM (UL-256QAM) has been introduced since 2016 as a part of 3GPP Release 14, the adoption was quite poor as many Radio Access Network (RAN) and User Equipment (UE) vendors didn't support this feature. With the introduction of 5G, the support of UL-256QAM has been greatly improved due to a big re-haul of RAN by Mobile Network Operators (MNOs). However, many RAN manufacturers charge MNOs for licenses to enable UL-256QAM per cell basis. This led to some MNOs hesitating to enable the feature on some of their gNodeB or cells to save cost.\n  Since it's known that 256QAM modulation requires a very good channel condition to operate, but UE has a very limited transmission power budget. In this paper, 256QAM utilization, throughput and latency impact from enabling UL-256QAM will be evaluated on commercial 5G Standalone (SA) networks in two countries: Japan and Thailand on various frequency bands, mobility characteristics, and deployment schemes. By modifying the modem firmware, UL-256QAM can be turned off and compared to the conventional UL-64QAM. The results show that UL-256QAM utilization was less than 20% when deployed on a passive antenna network resulting in an average of 8.22% improvement in throughput. However, with Massive MIMO deployment, more than 50% utilization was possible on commercial networks. Furthermore, despite a small uplink throughput gain, enabling UL-256QAM can lower the latency when the link is fully loaded with an average improvement of 7.97 ms in TCP latency observed across various test cases with two TCP congestion control algorithms.", "AI": {"tldr": "\u8bc4\u4f305G SA\u7f51\u7edc\u4e2d\u4e0a\u884c256QAM\u7684\u5b9e\u9645\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0\u5728\u88ab\u52a8\u5929\u7ebf\u7f51\u7edc\u4e2d\u5229\u7528\u7387\u4f4e\u4e8e20%\uff0c\u4f46\u5728Massive MIMO\u90e8\u7f72\u4e2d\u53ef\u8fbe50%\u4ee5\u4e0a\uff0c\u5e73\u5747\u63d0\u53478.22%\u541e\u5410\u91cf\u5e76\u964d\u4f4e7.97ms\u5ef6\u8fdf\u3002", "motivation": "\u5c3d\u7ba13GPP Release 14\u5df2\u5f15\u5165\u4e0a\u884c256QAM\uff0c\u4f46\u7531\u4e8eRAN\u548cUE\u5382\u5546\u652f\u6301\u4e0d\u8db3\u4ee5\u53ca\u8bb8\u53ef\u8d39\u7528\u95ee\u9898\uff0c\u8fd0\u8425\u5546\u90e8\u7f72\u72b9\u8c6b\u3002\u9700\u8981\u8bc4\u4f30\u5176\u5728\u5546\u75285G\u7f51\u7edc\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u8c03\u5236\u89e3\u8c03\u5668\u56fa\u4ef6\uff0c\u5728\u65e5\u672c\u548c\u6cf0\u56fd\u7684\u5546\u75285G SA\u7f51\u7edc\u4e2d\u5bf9\u6bd4\u5f00\u542f\u548c\u5173\u95ed\u4e0a\u884c256QAM\u7684\u6027\u80fd\uff0c\u6d4b\u8bd5\u4e0d\u540c\u9891\u6bb5\u3001\u79fb\u52a8\u7279\u6027\u548c\u90e8\u7f72\u65b9\u6848\u3002", "result": "\u88ab\u52a8\u5929\u7ebf\u7f51\u7edc\u4e2d256QAM\u5229\u7528\u7387\u4f4e\u4e8e20%\uff0c\u5e73\u5747\u541e\u5410\u91cf\u63d0\u53478.22%\uff1bMassive MIMO\u90e8\u7f72\u4e2d\u5229\u7528\u7387\u8d85\u8fc750%\uff1b\u5728\u94fe\u8def\u6ee1\u8f7d\u65f6\u53ef\u964d\u4f4eTCP\u5ef6\u8fdf\u5e73\u57477.97ms\u3002", "conclusion": "\u4e0a\u884c256QAM\u5728Massive MIMO\u90e8\u7f72\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u867d\u7136\u541e\u5410\u91cf\u589e\u76ca\u6709\u9650\uff0c\u4f46\u80fd\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u5bf9\u7f51\u7edc\u6027\u80fd\u6709\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2511.19446", "categories": ["cs.IT", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.19446", "abs": "https://arxiv.org/abs/2511.19446", "authors": ["Serkan G\u00fcr"], "title": "The Quality of Information: A Weighted Entropy Approach to Near-Optimal Mastermind", "comment": null, "summary": "This paper presents a novel class of information-theoretic strategies for solving the game of Mastermind, achieving state-of-the-art performance among known heuristic methods. The core contribution is the application of a weighted entropy heuristic, based on the Belis-Guias, u framework, which assigns context-dependent utility values to each of the possible feedback types. A genetic algorithm optimization approach discovers interpretable weight patterns that reflect strategic game dynamics. First, I demonstrate that a single, fixed vector of optimized weights achieves a remarkable 4.3565 average guesses with a maximum of 5. Building upon this, I introduce a stage-weighted heuristic with distinct utility vectors for each turn, achieving 4.3488 average guesses with a maximum of 6, approaching the theoretical optimum of 4.3403 by less than 0.2%. The method retains the computational efficiency of classical one-step-ahead heuristics while significantly improving performance through principled information valuation. A complete implementation and all optimized parameters are provided for full reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684Mastermind\u6e38\u620f\u6c42\u89e3\u7b56\u7565\uff0c\u4f7f\u7528\u52a0\u6743\u71b5\u542f\u53d1\u5f0f\u548c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfMastermind\u6e38\u620f\u6c42\u89e3\u65b9\u6cd5\u6027\u80fd\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u4fe1\u606f\u8bba\u7b56\u7565\u6765\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\u89e3\u3002", "method": "\u91c7\u7528\u57fa\u4e8eBelis-Guias\u6846\u67b6\u7684\u52a0\u6743\u71b5\u542f\u53d1\u5f0f\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6548\u7528\u6743\u91cd\uff0c\u5e76\u5f15\u5165\u9636\u6bb5\u52a0\u6743\u542f\u53d1\u5f0f\u3002", "result": "\u56fa\u5b9a\u6743\u91cd\u65b9\u6cd5\u5e73\u5747\u731c\u6d4b\u6b21\u65704.3565\uff0c\u6700\u59275\u6b21\uff1b\u9636\u6bb5\u52a0\u6743\u65b9\u6cd5\u5e73\u57474.3488\u6b21\uff0c\u6700\u59276\u6b21\uff0c\u63a5\u8fd1\u7406\u8bba\u6700\u4f184.3403\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u901a\u8fc7\u539f\u5219\u6027\u7684\u4fe1\u606f\u4f30\u503c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7406\u8bba\u6781\u9650\u7684Mastermind\u6e38\u620f\u6c42\u89e3\u3002"}}
{"id": "2511.19871", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.19871", "abs": "https://arxiv.org/abs/2511.19871", "authors": ["Kasidis Arunruangsirilert", "Pasapong Wongprasert", "Jiro Katto"], "title": "Evaluations of High Power User Equipment (HPUE) in Urban Environment", "comment": "2025 34th International Conference on Computer Communications and Networks (ICCCN), 04-07 August 2025, Tokyo, Japan", "summary": "While Time Division Duplexing (TDD) 5G New Radio (NR) networks offers higher downlink throughput due to the utilization of the middle frequency band, the uplink performance is negatively impacted due to higher path loss associated with higher frequencies, which degrade the users QoE in less optimal conditions. With the growing demand for high performance uplink throughput from novel applications such as Metaverse, Internet of Things (IoTs) and Smart City, 3GPP introduced High Power User Equipment (HPUE) on 5G TDD bands, allowing UEs to utilize more than 23 dBm of power for transmission to improve throughput, QoE, and reliability, especially at the cell edges. In this paper, the performance of HPUE is evaluated in the urban area on a commercial 5G network in terms of Uplink Throughput, Modulation Efficiency, Re-transmission Rate (ReTx Rate), and Power Consumption in both Standalone (SA) and Non-Standalone (NSA) modes. Through modem firmware modification, the performance is also compared across different power classes and antenna configurations.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e865G TDD\u7f51\u7edc\u4e2d\u9ad8\u529f\u7387\u7528\u6237\u8bbe\u5907(HPUE)\u5728\u57ce\u533a\u5546\u7528\u7f51\u7edc\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5305\u62ec\u4e0a\u884c\u541e\u5410\u91cf\u3001\u8c03\u5236\u6548\u7387\u3001\u91cd\u4f20\u7387\u548c\u529f\u8017\u7b49\u6307\u6807\uff0c\u5e76\u5728SA\u548cNSA\u6a21\u5f0f\u4e0b\u8fdb\u884c\u5bf9\u6bd4\u3002", "motivation": "5G TDD\u7f51\u7edc\u867d\u7136\u4e0b\u884c\u541e\u5410\u91cf\u9ad8\uff0c\u4f46\u7531\u4e8e\u9ad8\u9891\u6bb5\u8def\u5f84\u635f\u8017\u5927\uff0c\u4e0a\u884c\u6027\u80fd\u53d7\u5230\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5c0f\u533a\u8fb9\u7f18\u533a\u57df\u3002\u968f\u7740\u5143\u5b87\u5b99\u3001\u7269\u8054\u7f51\u7b49\u5e94\u7528\u5bf9\u4e0a\u884c\u6027\u80fd\u8981\u6c42\u7684\u63d0\u9ad8\uff0c3GPP\u5f15\u5165HPUE\u6765\u6539\u5584\u4e0a\u884c\u541e\u5410\u91cf\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u5728\u5546\u75285G\u7f51\u7edc\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u4f30HPUE\u5728SA\u548cNSA\u6a21\u5f0f\u4e0b\u7684\u6027\u80fd\uff0c\u5305\u62ec\u4e0a\u884c\u541e\u5410\u91cf\u3001\u8c03\u5236\u6548\u7387\u3001\u91cd\u4f20\u7387\u548c\u529f\u8017\u7b49\u6307\u6807\u3002\u901a\u8fc7\u4fee\u6539\u8c03\u5236\u89e3\u8c03\u5668\u56fa\u4ef6\uff0c\u6bd4\u8f83\u4e0d\u540c\u529f\u7387\u7b49\u7ea7\u548c\u5929\u7ebf\u914d\u7f6e\u7684\u6027\u80fd\u3002", "result": "HPUE\u80fd\u591f\u663e\u8457\u63d0\u5347\u4e0a\u884c\u541e\u5410\u91cf\u3001\u8c03\u5236\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5c0f\u533a\u8fb9\u7f18\u533a\u57df\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u91cd\u4f20\u7387\u3002\u4e0d\u540c\u529f\u7387\u7b49\u7ea7\u548c\u5929\u7ebf\u914d\u7f6e\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "HPUE\u662f\u63d0\u53475G TDD\u7f51\u7edc\u4e0a\u884c\u6027\u80fd\u7684\u6709\u6548\u6280\u672f\uff0c\u80fd\u591f\u6ee1\u8db3\u65b0\u5174\u5e94\u7528\u5bf9\u9ad8\u4e0a\u884c\u541e\u5410\u91cf\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u975e\u7406\u60f3\u7f51\u7edc\u6761\u4ef6\u4e0b\u548c\u5c0f\u533a\u8fb9\u7f18\u533a\u57df\u3002"}}
{"id": "2511.19550", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19550", "abs": "https://arxiv.org/abs/2511.19550", "authors": ["Davide Picca"], "title": "The Semiotic Channel Principle: Measuring the Capacity for Meaning in LLM Communication", "comment": null, "summary": "This paper proposes a novel semiotic framework for analyzing Large Language Models (LLMs), conceptualizing them as stochastic semiotic engines whose outputs demand active, asymmetric human interpretation. We formalize the trade-off between expressive richness (semiotic breadth) and interpretive stability (decipherability) using information-theoretic tools. Breadth is quantified as source entropy, and decipherability as the mutual information between messages and human interpretations. We introduce a generative complexity parameter (lambda) that governs this trade-off, as both breadth and decipherability are functions of lambda. The core trade-off is modeled as an emergent property of their distinct responses to $\u03bb$. We define a semiotic channel, parameterized by audience and context, and posit a capacity constraint on meaning transmission, operationally defined as the maximum decipherability by optimizing lambda. This reframing shifts analysis from opaque model internals to observable textual artifacts, enabling empirical measurement of breadth and decipherability. We demonstrate the framework's utility across four key applications: (i) model profiling; (ii) optimizing prompt/context design; (iii) risk analysis based on ambiguity; and (iv) adaptive semiotic systems. We conclude that this capacity-based semiotic approach offers a rigorous, actionable toolkit for understanding, evaluating, and designing LLM-mediated communication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7b26\u53f7\u5b66\u6846\u67b6\uff0c\u5c06\u5176\u6982\u5ff5\u5316\u4e3a\u968f\u673a\u7b26\u53f7\u5f15\u64ce\uff0c\u5176\u8f93\u51fa\u9700\u8981\u4eba\u7c7b\u4e3b\u52a8\u7684\u3001\u4e0d\u5bf9\u79f0\u7684\u89e3\u91ca\u3002\u6846\u67b6\u5f62\u5f0f\u5316\u4e86\u8868\u8fbe\u4e30\u5bcc\u6027\uff08\u7b26\u53f7\u5e7f\u5ea6\uff09\u4e0e\u89e3\u91ca\u7a33\u5b9a\u6027\uff08\u53ef\u89e3\u8bfb\u6027\uff09\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u5f53\u524dLLM\u5206\u6790\u5f80\u5f80\u5173\u6ce8\u6a21\u578b\u5185\u90e8\u673a\u5236\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6a21\u578b\u8f93\u51fa\u6587\u672c\u7b26\u53f7\u7279\u5f81\u7684\u7cfb\u7edf\u5206\u6790\u6846\u67b6\u3002\u9700\u8981\u4ece\u53ef\u89c2\u5bdf\u7684\u6587\u672c\u4ea7\u7269\u89d2\u5ea6\u6765\u7406\u89e3LLM\u7684\u7b26\u53f7\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u5de5\u5177\u91cf\u5316\u7b26\u53f7\u5e7f\u5ea6\uff08\u6e90\u71b5\uff09\u548c\u53ef\u89e3\u8bfb\u6027\uff08\u6d88\u606f\u4e0e\u4eba\u7c7b\u89e3\u91ca\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\uff09\u3002\u5f15\u5165\u751f\u6210\u590d\u6742\u5ea6\u53c2\u6570\u03bb\u6765\u5efa\u6a21\u4e24\u8005\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5b9a\u4e49\u7b26\u53f7\u901a\u9053\u548c\u5bb9\u91cf\u7ea6\u675f\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u8bc1\u6d4b\u91cf\u7b26\u53f7\u5e7f\u5ea6\u548c\u53ef\u89e3\u8bfb\u6027\uff0c\u5e76\u5728\u6a21\u578b\u5206\u6790\u3001\u63d0\u793a\u4f18\u5316\u3001\u98ce\u9669\u5206\u6790\u548c\u81ea\u9002\u5e94\u7cfb\u7edf\u7b49\u56db\u4e2a\u5173\u952e\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u5bb9\u91cf\u7684\u7b26\u53f7\u5b66\u65b9\u6cd5\u4e3a\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u8bbe\u8ba1LLM\u4ecb\u5bfc\u7684\u901a\u4fe1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u4e14\u53ef\u64cd\u4f5c\u7684\u5de5\u5177\u5305\uff0c\u5c06\u5206\u6790\u91cd\u70b9\u4ece\u6a21\u578b\u5185\u90e8\u8f6c\u5411\u53ef\u89c2\u5bdf\u7684\u6587\u672c\u4ea7\u7269\u3002"}}
{"id": "2511.19577", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.19577", "abs": "https://arxiv.org/abs/2511.19577", "authors": ["Abhay Goyal", "Navin Kumar", "Kimberly DiMeola", "Rafael Trujillo", "Soorya Ram Shimgekar", "Christian Poellabauer", "Pi Zonooz", "Ermonda Gjoni-Markaj", "Declan Barry", "Lynn Madden"], "title": "Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder", "comment": null, "summary": "Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u548cAI\u65b9\u6cd5\u9884\u6d4b\u6162\u6027\u75bc\u75db\u548c\u9e26\u7247\u4f7f\u7528\u969c\u788d\u60a3\u8005\u7684\u75bc\u75db\u5cf0\u503c\uff0c\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u826f\u597d\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u6548\u679c\u6709\u9650\u3002", "motivation": "\u6162\u6027\u75bc\u75db\u548c\u9e26\u7247\u4f7f\u7528\u969c\u788d\u662f\u76f8\u4e92\u5173\u8054\u7684\u5e38\u89c1\u75be\u75c5\uff0c\u76ee\u524d\u7f3a\u4e4f\u57fa\u4e8e\u8bc1\u636e\u7684\u7efc\u5408\u6cbb\u7597\u65b9\u6cd5\u3002\u53ef\u7a7f\u6234\u8bbe\u5907\u6709\u6f5c\u529b\u76d1\u6d4b\u590d\u6742\u60a3\u8005\u4fe1\u606f\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u6536\u96c6\u6570\u636e\uff0c\u91c7\u7528\u591a\u79cdAI\u65b9\u6cd5\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\u548cLLMs\uff09\u5206\u6790\u75bc\u75db\u5cf0\u503c\u53ca\u5176\u4e34\u5e8a\u76f8\u5173\u6027\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u75bc\u75db\u5cf0\u503c\u65b9\u9762\u8fbe\u5230\u8f83\u9ad8\u51c6\u786e\u7387\uff08>0.7\uff09\uff0c\u4f46LLMs\u5728\u63d0\u4f9b\u75bc\u75db\u5cf0\u503c\u6d1e\u5bdf\u65b9\u9762\u8868\u73b0\u6709\u9650\u3002", "conclusion": "\u53ef\u7a7f\u6234\u8bbe\u5907\u5b9e\u65f6\u76d1\u6d4b\u7ed3\u5408\u5148\u8fdbAI\u6a21\u578b\u53ef\u4fc3\u8fdb\u75bc\u75db\u5cf0\u503c\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u652f\u6301\u4e2a\u6027\u5316\u5e72\u9884\u3002\u9274\u4e8eLLMs\u6574\u4f53\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6d1e\u5bdf\u7684LLMs\u3002"}}
{"id": "2511.19745", "categories": ["cs.IT", "eess.SP", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.19745", "abs": "https://arxiv.org/abs/2511.19745", "authors": ["Yassine Afif", "Mohammed Almekhlafi", "Antoine Lesage-Landry", "Gunes Karabulut Kurt"], "title": "Joint Satellite Power Consumption and Handover Optimization for LEO Constellations", "comment": null, "summary": "In satellite constellation-based communication systems, continuous user coverage requires frequent handoffs due to the dynamic topology induced by the Low Earth Orbit (LEO) satellites. Each handoff between a satellite and ground users introduces additional signaling and power consumption, which can become a significant burden as the size of the constellation continues to increase. This work focuses on the optimization of the total transmission rate in a LEO-to-user system, by jointly considering the total transmitted power, user-satellite associations, and power consumption, the latter being handled through a penalty on handoff events. We consider a system where LEO satellites serve users located in remote areas with no terrestrial connectivity, and formulate the power allocation problem as a mixed-integer concave linear program (MICP) subject to power and association constraints. Our approach can be solved with off-the-shelf solvers and is benchmarked against a naive baseline where users associate to their closest visible satellite. Extensive Monte Carlo simulations demonstrate the effectiveness of the proposed method in controlling the handoff frequency while maintaining high user throughput. These performance gains highlight the effectiveness of our handover-aware optimization strategy, which ensures that user rates improve significantly, by about 40%, without incurring a disproportionate rise in the handoff frequency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdLEO\u536b\u661f\u901a\u4fe1\u7cfb\u7edf\u4e2d\u8003\u8651\u5207\u6362\u9891\u7387\u7684\u529f\u7387\u5206\u914d\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u4f20\u8f93\u529f\u7387\u3001\u7528\u6237-\u536b\u661f\u5173\u8054\u548c\u5207\u6362\u60e9\u7f5a\uff0c\u5728\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u7684\u540c\u65f6\u63a7\u5236\u5207\u6362\u9891\u7387\u3002", "motivation": "LEO\u536b\u661f\u661f\u5ea7\u7cfb\u7edf\u4e2d\uff0c\u7531\u4e8e\u536b\u661f\u52a8\u6001\u62d3\u6251\u5bfc\u81f4\u7684\u9891\u7e41\u5207\u6362\u4f1a\u5e26\u6765\u989d\u5916\u7684\u4fe1\u4ee4\u5f00\u9500\u548c\u529f\u8017\uff0c\u968f\u7740\u661f\u5ea7\u89c4\u6a21\u589e\u5927\uff0c\u8fd9\u6210\u4e3a\u663e\u8457\u8d1f\u62c5\u3002", "method": "\u5c06\u529f\u7387\u5206\u914d\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u51f9\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u8003\u8651\u529f\u7387\u548c\u5173\u8054\u7ea6\u675f\uff0c\u4f7f\u7528\u73b0\u6210\u6c42\u89e3\u5668\u6c42\u89e3\uff0c\u5e76\u4e0e\u7528\u6237\u5173\u8054\u6700\u8fd1\u53ef\u89c1\u536b\u661f\u7684\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u8499\u7279\u5361\u6d1b\u4eff\u771f\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u5207\u6362\u9891\u7387\u540c\u65f6\u4fdd\u6301\u9ad8\u7528\u6237\u541e\u5410\u91cf\uff0c\u7528\u6237\u901f\u7387\u63d0\u5347\u7ea640%\u4e14\u5207\u6362\u9891\u7387\u4e0d\u4f1a\u4e0d\u6210\u6bd4\u4f8b\u589e\u52a0\u3002", "conclusion": "\u63d0\u51fa\u7684\u5207\u6362\u611f\u77e5\u4f18\u5316\u7b56\u7565\u5728\u663e\u8457\u63d0\u5347\u7528\u6237\u901f\u7387\u7684\u540c\u65f6\u6709\u6548\u63a7\u5236\u5207\u6362\u9891\u7387\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20241", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.20241", "abs": "https://arxiv.org/abs/2511.20241", "authors": ["Gregory F. Stock", "Alexander Haberl", "Juan A. Fraire", "Holger Hermanns"], "title": "POMDP-Based Routing for DTNs with Partial Knowledge and Dependent Failures", "comment": "This is the authors' version of a paper that was originally presented at the Space-Terrestrial Internetworking Workshop (STINT'25), which was co-located with the IEEE WiSEE 2025 conference, see https://doi.org/10.1109/WiSEE57913.2025.11229850", "summary": "Routing in Delay-Tolerant Networks (DTNs) is inherently challenging due to sparse connectivity, long delays, and frequent disruptions. While Markov Decision Processes (MDPs) have been used to model uncertainty, they assume full state observability - an assumption that breaks down in partitioned DTNs, where each node operates with inherently partial knowledge of the network state. In this work, we investigate the role of Partially Observable Markov Decision Processes (POMDPs) for DTN routing under uncertainty. We introduce and evaluate a novel model: Dependent Node Failures (DNF), which captures correlated node failures via repairable node states modeled as Continuous-Time Markov Chains (CTMCs). We implement the model using JuliaPOMDP and integrate it with DTN simulations via DtnSim. Our evaluation demonstrates that POMDP-based routing yields improved delivery ratios and delay performance under uncertain conditions while maintaining scalability. These results highlight the potential of POMDPs as a principled foundation for decision-making in future DTN deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5ef6\u8fdf\u5bb9\u5fcd\u7f51\u7edc(DTN)\u4e2d\u4f7f\u7528\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(POMDP)\u8fdb\u884c\u8def\u7531\u51b3\u7b56\uff0c\u63d0\u51fa\u4e86\u4f9d\u8d56\u8282\u70b9\u6545\u969c(DNF)\u6a21\u578b\u6765\u6355\u6349\u76f8\u5173\u8282\u70b9\u6545\u969c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660ePOMDP\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u80fd\u63d0\u9ad8\u6295\u9012\u7387\u548c\u5ef6\u8fdf\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfMDP\u65b9\u6cd5\u5047\u8bbe\u5b8c\u5168\u72b6\u6001\u53ef\u89c2\u6d4b\u6027\uff0c\u4f46\u5728\u5206\u533aDTN\u4e2d\uff0c\u6bcf\u4e2a\u8282\u70b9\u53ea\u80fd\u83b7\u5f97\u90e8\u5206\u7f51\u7edc\u72b6\u6001\u4fe1\u606f\uff0c\u8fd9\u79cd\u5047\u8bbe\u4e0d\u6210\u7acb\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76POMDP\u5728DTN\u8def\u7531\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4f5c\u7528\u3002", "method": "\u5f15\u5165\u4f9d\u8d56\u8282\u70b9\u6545\u969c(DNF)\u6a21\u578b\uff0c\u901a\u8fc7\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe(CTMC)\u5efa\u6a21\u53ef\u4fee\u590d\u8282\u70b9\u72b6\u6001\u6765\u6355\u6349\u76f8\u5173\u8282\u70b9\u6545\u969c\u3002\u4f7f\u7528JuliaPOMDP\u5b9e\u73b0\u6a21\u578b\uff0c\u5e76\u901a\u8fc7DtnSim\u4e0eDTN\u4eff\u771f\u96c6\u6210\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u57fa\u4e8ePOMDP\u7684\u8def\u7531\u5728\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u80fd\u63d0\u9ad8\u6295\u9012\u7387\u548c\u5ef6\u8fdf\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "POMDP\u4e3a\u672a\u6765DTN\u90e8\u7f72\u4e2d\u7684\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u7684\u57fa\u7840\uff0c\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2511.19556", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19556", "abs": "https://arxiv.org/abs/2511.19556", "authors": ["Yanxiao Liu"], "title": "One-Shot Coding and Applications", "comment": "A Thesis for the Degree of Doctor of Philosophy in Information Engineering, The Chinese University of Hong Kong", "summary": "One-shot information theory addresses scenarios in source coding and channel coding where the signal blocklength is assumed to be 1. In this case, each source and channel can be used only once, and the sources and channels are arbitrary and not required to be memoryless or ergodic. We study the achievability part of one-shot information theory, i.e., we consider explicit coding schemes in the oneshot scenario. The objective is to derive one-shot achievability results that can imply existing (first-order and second-order) asymptotic results when applied to memoryless sources and channels, or applied to systems with memory that behave ergodically.\n  Poisson functional representation was first proposed as a one-shot channel simulation technique by Li and El Gamal [118] for proving a strong functional representation lemma. It was later extended to the Poisson matching lemma by Li and Anantharam [117], which provided a unified one-shot coding scheme for a broad class of information-theoretic problems. The main contribution of this thesis is to extend the applicability of Poisson functional representation to various more complicated scenarios, where the original version cannot be applied directly and further extensions must be developed.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u6cca\u677e\u51fd\u6570\u8868\u793a\u6cd5\u5728\u4e00\u6b21\u6027\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u5e94\u7528\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u66f4\u590d\u6742\u7684\u573a\u666f\uff0c\u5176\u4e2d\u539f\u59cb\u7248\u672c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u4e00\u6b21\u6027\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u53ef\u5b9e\u73b0\u6027\u90e8\u5206\uff0c\u65e8\u5728\u63a8\u5bfc\u51fa\u4e00\u6b21\u6027\u53ef\u5b9e\u73b0\u7ed3\u679c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u5728\u5e94\u7528\u4e8e\u65e0\u8bb0\u5fc6\u6e90\u548c\u4fe1\u9053\u6216\u5177\u6709\u904d\u5386\u884c\u4e3a\u7684\u8bb0\u5fc6\u7cfb\u7edf\u65f6\uff0c\u80fd\u591f\u8574\u542b\u73b0\u6709\u7684\uff08\u4e00\u9636\u548c\u4e8c\u9636\uff09\u6e10\u8fd1\u7ed3\u679c\u3002", "method": "\u6269\u5c55\u6cca\u677e\u51fd\u6570\u8868\u793a\u6cd5\u7684\u9002\u7528\u6027\uff0c\u5f00\u53d1\u8fdb\u4e00\u6b65\u6269\u5c55\u4ee5\u5904\u7406\u539f\u59cb\u7248\u672c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u7684\u66f4\u590d\u6742\u573a\u666f\u3002", "result": "\u6210\u529f\u5c06\u6cca\u677e\u51fd\u6570\u8868\u793a\u6cd5\u6269\u5c55\u5230\u5404\u79cd\u66f4\u590d\u6742\u7684\u573a\u666f\uff0c\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u4e00\u6b21\u6027\u7f16\u7801\u65b9\u6848\u3002", "conclusion": "\u6cca\u677e\u51fd\u6570\u8868\u793a\u6cd5\u5728\u4e00\u6b21\u6027\u4fe1\u606f\u7406\u8bba\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u8fdb\u4e00\u6b65\u6269\u5c55\u53ef\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u7f16\u7801\u95ee\u9898\u3002"}}
{"id": "2511.19663", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19663", "abs": "https://arxiv.org/abs/2511.19663", "authors": ["Ahmed Awadallah", "Yash Lara", "Raghav Magazine", "Hussein Mozannar", "Akshay Nambi", "Yash Pandya", "Aravind Rajeswaran", "Corby Rosset", "Alexey Taymanov", "Vibhav Vineet", "Spencer Whitehead", "Andrew Zhao"], "title": "Fara-7B: An Efficient Agentic Model for Computer Use", "comment": null, "summary": "Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.", "AI": {"tldr": "FaraGen\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6b65\u9aa4\u7f51\u9875\u4efb\u52a1\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7cfb\u7edf\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4ee5\u4f4e\u6210\u672c\u4ea7\u751f\u9a8c\u8bc1\u8f68\u8ff9\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3\u7684Fara-7B\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u751a\u81f3\u80fd\u4e0e\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u7684\u53d1\u5c55\u53d7\u5230\u7f3a\u4e4f\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u4eba\u7c7b\u4e0e\u8ba1\u7b97\u673a\u4ea4\u4e92\u6570\u636e\u96c6\u7684\u9650\u5236\uff0c\u800cLLMs\u7684\u6210\u529f\u4f9d\u8d56\u4e8e\u4e30\u5bcc\u7684\u6587\u672c\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u4e3aCUA\u8f68\u8ff9\u521b\u5efa\u7c7b\u4f3c\u7684\u6570\u636e\u96c6\u3002", "method": "\u5f00\u53d1FaraGen\u7cfb\u7edf\uff1a\u4ece\u5e38\u7528\u7f51\u7ad9\u751f\u6210\u591a\u6837\u5316\u4efb\u52a1\uff0c\u4ea7\u751f\u591a\u4e2a\u89e3\u51b3\u65b9\u6848\u5c1d\u8bd5\uff0c\u5e76\u4f7f\u7528\u591a\u4e2a\u9a8c\u8bc1\u5668\u7b5b\u9009\u6210\u529f\u8f68\u8ff9\u3002\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3Fara-7B\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4ec5\u901a\u8fc7\u622a\u56fe\u611f\u77e5\u8ba1\u7b97\u673a\uff0c\u901a\u8fc7\u9884\u6d4b\u5750\u6807\u6267\u884c\u52a8\u4f5c\uff0c\u4e14\u8db3\u591f\u5c0f\u53ef\u4ee5\u5728\u8bbe\u5907\u4e0a\u8fd0\u884c\u3002", "result": "FaraGen\u4ee5\u7ea61\u7f8e\u5143\u7684\u6210\u672c\u4ea7\u751f\u9a8c\u8bc1\u8f68\u8ff9\uff0c\u5177\u6709\u9ad8\u541e\u5410\u91cf\u3001\u4ea7\u91cf\u548c\u591a\u6837\u6027\u3002Fara-7B\u5728WebVoyager\u3001Online-Mind2Web\u548cWebTailBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u540c\u7c7b\u89c4\u6a21\u7684CUA\u6a21\u578b\uff0c\u5e76\u4e0e\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u7cfb\u7edf\u5728\u63a8\u8fdb\u5c0f\u578b\u9ad8\u6548\u4ee3\u7406\u6a21\u578b\u65b9\u9762\u5177\u6709\u5173\u952e\u4f18\u52bf\u3002Fara-7B\u4f5c\u4e3a\u5f00\u6e90\u6a21\u578b\u53d1\u5e03\uff0c\u540c\u65f6\u53d1\u5e03\u4e86WebTailBench\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2511.20305", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20305", "abs": "https://arxiv.org/abs/2511.20305", "authors": ["Changpeng He", "Yang Lu", "Yanqing Xu", "Chong-Yung Chi", "Bo Ai", "Arumugam Nallanathan"], "title": "RIS-Assisted Downlink Pinching-Antenna Systems: GNN-Enabled Optimization Approaches", "comment": null, "summary": "This paper investigates a reconfigurable intelligent surface (RIS)-assisted multi-waveguide pinching-antenna (PA) system (PASS) for multi-user downlink information transmission, motivated by the unknown impact of the integration of emerging PASS and RIS on wireless communications. First, we formulate sum rate (SR) and energy efficiency (EE) maximization problems in a unified framework, subject to constraints on the movable region of PAs, total power budget, and tunable phase of RIS elements. Then, by leveraging a graph-structured topology of the RIS-assisted PASS, a novel three-stage graph neural network (GNN) is proposed, which learns PA positions based on user locations, and RIS phase shifts according to composite channel conditions at the first two stages, respectively, and finally determines beamforming vectors. Specifically, the proposed GNN is achieved through unsupervised training, together with three implementation strategies for its integration with convex optimization, thus offering trade-offs between inference time and solution optimality. Extensive numerical results are provided to validate the effectiveness of the proposed GNN, and to support its unique attributes of viable generalization capability, good performance reliability, and real-time applicability. Moreover, the impact of key parameters on RIS-assisted PASS is illustrated and analyzed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76RIS\u8f85\u52a9\u7684\u591a\u6ce2\u5bfc\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\u7528\u4e8e\u591a\u7528\u6237\u4e0b\u884c\u4fe1\u606f\u4f20\u8f93\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e09\u9636\u6bb5\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u8054\u5408\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u3001RIS\u76f8\u4f4d\u548c\u6ce2\u675f\u6210\u5f62\u5411\u91cf\u3002", "motivation": "\u7814\u7a76\u65b0\u5174\u7684PASS\u7cfb\u7edf\u4e0eRIS\u96c6\u6210\u5bf9\u65e0\u7ebf\u901a\u4fe1\u7684\u672a\u77e5\u5f71\u54cd\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u667a\u80fd\u4f18\u5316\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u91c7\u7528\u56fe\u7ed3\u6784\u62d3\u6251\u8868\u793aRIS\u8f85\u52a9\u7684PASS\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e09\u9636\u6bb5\u56fe\u795e\u7ecf\u7f51\u7edc\uff1a\u7b2c\u4e00\u9636\u6bb5\u5b66\u4e60\u57fa\u4e8e\u7528\u6237\u4f4d\u7f6e\u7684PA\u4f4d\u7f6e\uff0c\u7b2c\u4e8c\u9636\u6bb5\u6839\u636e\u590d\u5408\u4fe1\u9053\u6761\u4ef6\u5b66\u4e60RIS\u76f8\u4f4d\u504f\u79fb\uff0c\u7b2c\u4e09\u9636\u6bb5\u786e\u5b9a\u6ce2\u675f\u6210\u5f62\u5411\u91cf\u3002\u901a\u8fc7\u65e0\u76d1\u7763\u8bad\u7ec3\u548c\u4e09\u79cd\u5b9e\u73b0\u7b56\u7565\u4e0e\u51f8\u4f18\u5316\u96c6\u6210\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0GNN\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3001\u6027\u80fd\u53ef\u9760\u6027\u548c\u5b9e\u65f6\u9002\u7528\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5173\u952e\u53c2\u6570\u5bf9RIS\u8f85\u52a9PASS\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u9636\u6bb5GNN\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4f18\u5316RIS\u8f85\u52a9PASS\u7cfb\u7edf\uff0c\u5728\u63a8\u7406\u65f6\u95f4\u548c\u89e3\u7684\u6700\u4f18\u6027\u4e4b\u95f4\u63d0\u4f9b\u6743\u8861\uff0c\u4e3a\u667a\u80fd\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.19568", "categories": ["cs.IT", "eess.SP", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.19568", "abs": "https://arxiv.org/abs/2511.19568", "authors": ["Sunder Ram Krishnan", "Junaid Farooq", "Kumar Vijay Mishra", "Xingchen Liu", "S. Unnikrishna Pillai", "Theodore S. Rappaport"], "title": "A Hybrid Dominant-Interferer Approximation for SINR Coverage in Poisson Cellular Networks", "comment": null, "summary": "Accurate radio propagation and interference modeling is essential for the design and analysis of modern cellular networks. Stochastic geometry offers a rigorous framework by treating base station locations as a Poisson point process and enabling coverage characterization through spatial averaging, but its expressions often involve nested integrals and special functions that limit general applicability. Probabilistic interference models seek closed-form characterizations through moment-based approximations, yet these expressions remain tractable only for restricted parameter choices and become unwieldy when interference moments lack closed-form representations. This work introduces a hybrid approximation framework that addresses these challenges by combining Monte Carlo sampling of a small set of dominant interferers with a Laplace functional representation of the residual far-field interference. The resulting dominant-plus-tail structure provides a modular, numerically stable, and path-loss-agnostic estimator suitable for both noise-limited and interference-limited regimes. We further derive theoretical error bounds that decrease with the number of dominant interferers and validate the approach against established stochastic geometry and probabilistic modeling benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u8fd1\u4f3c\u6846\u67b6\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u91c7\u6837\u548c\u62c9\u666e\u62c9\u65af\u6cdb\u51fd\u8868\u793a\uff0c\u7528\u4e8e\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5e72\u6270\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u968f\u673a\u51e0\u4f55\u548c\u6982\u7387\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u968f\u673a\u51e0\u4f55\u65b9\u6cd5\u6d89\u53ca\u590d\u6742\u5d4c\u5957\u79ef\u5206\u548c\u7279\u6b8a\u51fd\u6570\uff0c\u6982\u7387\u5e72\u6270\u6a21\u578b\u4ec5\u5728\u53d7\u9650\u53c2\u6570\u4e0b\u53ef\u5904\u7406\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u3001\u6570\u503c\u7a33\u5b9a\u7684\u5e72\u6270\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u91c7\u6837\u4e3b\u5bfc\u5e72\u6270\u6e90\u548c\u62c9\u666e\u62c9\u65af\u6cdb\u51fd\u8868\u793a\u6b8b\u4f59\u8fdc\u573a\u5e72\u6270\uff0c\u6784\u5efa\u4e3b\u5bfc+\u5c3e\u90e8\u7684\u6a21\u5757\u5316\u7ed3\u6784\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6570\u503c\u7a33\u5b9a\u3001\u8def\u5f84\u635f\u8017\u65e0\u5173\u7684\u4f30\u8ba1\u5668\uff0c\u9002\u7528\u4e8e\u566a\u58f0\u53d7\u9650\u548c\u5e72\u6270\u53d7\u9650\u573a\u666f\uff0c\u5e76\u63a8\u5bfc\u4e86\u7406\u8bba\u8bef\u5dee\u754c\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u7ebf\u7f51\u7edc\u5e72\u6270\u5efa\u6a21\u7684\u6311\u6218\uff0c\u9a8c\u8bc1\u4e86\u5176\u76f8\u5bf9\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2511.19669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19669", "abs": "https://arxiv.org/abs/2511.19669", "authors": ["Souradip Poddar", "Chia-Tung Ho", "Ziming Wei", "Weidong Cao", "Haoxing Ren", "David Z. Pan"], "title": "HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization", "comment": null, "summary": "Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.", "AI": {"tldr": "HeaRT\u662f\u4e00\u4e2a\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bbe\u8ba1\u5faa\u73af\uff0c\u5728\u7535\u8def\u8bbe\u8ba1\u4f18\u5316\u4e2d\u5b9e\u73b0>97%\u7684\u63a8\u7406\u51c6\u786e\u7387\u548c>98%\u7684Pass@1\u6027\u80fd\uff0c\u540c\u65f6\u6bd4SOTA\u57fa\u7ebf\u8282\u770150%\u4ee5\u4e0a\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "\u4f20\u7edfAI\u9a71\u52a8\u7684AMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u7b97\u6cd5\u53d7\u9650\u4e8e\u5bf9\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u3001\u8de8\u67b6\u6784\u8fc1\u79fb\u6027\u5dee\u4ee5\u53ca\u7f3a\u4e4f\u81ea\u9002\u5e94\u673a\u5236\uff0c\u9700\u8981\u66f4\u667a\u80fd\u3001\u81ea\u9002\u5e94\u3001\u7c7b\u4eba\u98ce\u683c\u7684\u8bbe\u8ba1\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHeaRT\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u4f5c\u4e3a\u81ea\u52a8\u5316\u5faa\u73af\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u667a\u80fd\u81ea\u9002\u5e94\u8bbe\u8ba1\u4f18\u5316\u3002", "result": "\u572840\u7535\u8def\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHeaRT\u63a8\u7406\u51c6\u786e\u7387>97%\uff0cPass@1\u6027\u80fd>98%\uff0c\u5373\u4f7f\u7535\u8def\u590d\u6742\u5ea6\u589e\u52a0\u4e5f\u80fd\u4fdd\u6301\u6027\u80fd\uff0c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4ec5\u4e3aSOTA\u57fa\u7ebf\u7684<0.5\u500d\u3002\u5728\u5c3a\u5bf8\u548c\u62d3\u6251\u8bbe\u8ba1\u9002\u5e94\u4efb\u52a1\u4e2d\uff0c\u6536\u655b\u901f\u5ea6\u63d0\u9ad83\u500d\u4ee5\u4e0a\u3002", "conclusion": "HeaRT\u662f\u5b9e\u73b0\u667a\u80fd\u81ea\u9002\u5e94\u7535\u8def\u8bbe\u8ba1\u4f18\u5316\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\u5e76\u4fdd\u6301\u539f\u6709\u8bbe\u8ba1\u610f\u56fe\u3002"}}
{"id": "2511.19639", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19639", "abs": "https://arxiv.org/abs/2511.19639", "authors": ["Niccol\u00f2 Brembilla", "Yinbin Ma", "Pietro Belotti", "Federico Malucelli", "Daniela Tuninetti"], "title": "Computer-aided Characterization of Fundamental Limits of Coded Caching with Linear Coding", "comment": null, "summary": "Inspired by prior work by Tian and by Cao and Xu, this paper presents an efficient computer-aided framework to characterize the fundamental limits of coded caching systems under the constraint of linear coding. The proposed framework considers non-Shannon-type inequalities which are valid for representable polymatroids (and hence for linear codes), and leverages symmetric structure and problem-specific constraints of coded caching to reduce the complexity of the linear program. The derived converse bounds are tighter compared to previous known analytic methods, and prove the optimality of some achievable memory-load tradeoff points under the constraint of linear coding placement and delivery. These results seem to indicate that small, structured demand subsets combined with minimal common information constructions may be sufficient to characterize optimal tradeoffs under linear coding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u8ba1\u7b97\u673a\u8f85\u52a9\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7f16\u7801\u7f13\u5b58\u7cfb\u7edf\u4e2d\u8868\u5f81\u7ebf\u6027\u7f16\u7801\u7ea6\u675f\u4e0b\u7684\u57fa\u672c\u6781\u9650\u3002\u8be5\u6846\u67b6\u8003\u8651\u975e\u9999\u519c\u578b\u4e0d\u7b49\u5f0f\uff0c\u5229\u7528\u5bf9\u79f0\u7ed3\u6784\u548c\u95ee\u9898\u7279\u5b9a\u7ea6\u675f\u6765\u964d\u4f4e\u7ebf\u6027\u89c4\u5212\u7684\u590d\u6742\u5ea6\uff0c\u5f97\u5230\u4e86\u6bd4\u5148\u524d\u5206\u6790\u65b9\u6cd5\u66f4\u7d27\u7684\u53cd\u5411\u754c\u3002", "motivation": "\u53d7Tian\u4ee5\u53caCao\u548cXu\u5148\u524d\u5de5\u4f5c\u7684\u542f\u53d1\uff0c\u672c\u6587\u65e8\u5728\u5728\u7f16\u7801\u7f13\u5b58\u7cfb\u7edf\u4e2d\u8868\u5f81\u7ebf\u6027\u7f16\u7801\u7ea6\u675f\u4e0b\u7684\u57fa\u672c\u6781\u9650\uff0c\u7279\u522b\u662f\u8003\u8651\u975e\u9999\u519c\u578b\u4e0d\u7b49\u5f0f\u4ee5\u5f97\u5230\u66f4\u7d27\u7684\u754c\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u673a\u8f85\u52a9\u6846\u67b6\uff0c\u8003\u8651\u5bf9\u53ef\u8868\u793a\u591a\u62df\u9635\u6709\u6548\u7684\u975e\u9999\u519c\u578b\u4e0d\u7b49\u5f0f\uff0c\u5e76\u5229\u7528\u7f16\u7801\u7f13\u5b58\u7684\u5bf9\u79f0\u7ed3\u6784\u548c\u95ee\u9898\u7279\u5b9a\u7ea6\u675f\u6765\u964d\u4f4e\u7ebf\u6027\u89c4\u5212\u7684\u590d\u6742\u5ea6\u3002", "result": "\u63a8\u5bfc\u7684\u53cd\u5411\u754c\u6bd4\u5148\u524d\u5df2\u77e5\u7684\u5206\u6790\u65b9\u6cd5\u66f4\u7d27\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u7ebf\u6027\u7f16\u7801\u653e\u7f6e\u548c\u4f20\u8f93\u7ea6\u675f\u4e0b\u67d0\u4e9b\u53ef\u5b9e\u73b0\u5185\u5b58-\u8d1f\u8f7d\u6743\u8861\u70b9\u7684\u6700\u4f18\u6027\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u6700\u5c0f\u516c\u5171\u4fe1\u606f\u6784\u9020\u7684\u5c0f\u578b\u7ed3\u6784\u5316\u9700\u6c42\u5b50\u96c6\u53ef\u80fd\u8db3\u4ee5\u8868\u5f81\u7ebf\u6027\u7f16\u7801\u4e0b\u7684\u6700\u4f18\u6743\u8861\u3002"}}
{"id": "2511.19671", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19671", "abs": "https://arxiv.org/abs/2511.19671", "authors": ["Rishab Sharma", "Iman Saberi", "Elham Alipour", "Jie JW Wu", "Fatemeh Fard"], "title": "FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking", "comment": "3 tables, 11 pages, 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Generative AI in Finance", "summary": "Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).", "AI": {"tldr": "\u63d0\u51fa\u4e86FISCAL\u6846\u67b6\u7528\u4e8e\u751f\u6210\u91d1\u878d\u4e8b\u5b9e\u6838\u67e5\u7684\u5408\u6210\u6570\u636e\uff0c\u5e76\u8bad\u7ec3\u4e86\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\uff0c\u5728\u591a\u4e2a\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u63a5\u8fd1\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u91d1\u878d\u5e94\u7528\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e8b\u5b9e\u53ef\u9760\u6027\u5dee\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u65e2\u80fd\u4fdd\u8bc1\u51c6\u786e\u6027\u53c8\u8f7b\u91cf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528FISCAL\u6846\u67b6\u751f\u6210\u5408\u6210\u91d1\u878d\u6570\u636eFISCAL-data\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\u8fdb\u884c\u91d1\u878d\u6570\u503c\u58f0\u660e\u9a8c\u8bc1\u3002", "result": "MiniCheck-FISCAL\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u548cGPT-3.5 Turbo\uff0c\u63a5\u8fd1Mixtral-8x22B\u7b49\u5927\u6a21\u578b\uff0820\u500d\u5927\u5c0f\uff09\u7684\u51c6\u786e\u6027\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u5ab2\u7f8eGPT-4o\u548cClaude-3.5\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u7684\u5408\u6210\u6570\u636e\u7ed3\u5408\u9ad8\u6548\u5fae\u8c03\uff0c\u53ef\u4f7f\u7d27\u51d1\u6a21\u578b\u5728\u91d1\u878dAI\u5e94\u7528\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.19749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19749", "abs": "https://arxiv.org/abs/2511.19749", "authors": ["Farzan Karimi-Malekabadi", "Pooya Razavi", "Sonya Powers"], "title": "Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions", "comment": null, "summary": "As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u7279\u522b\u662fGPT-4o-mini\uff09\u80fd\u591f\u4ee583-94%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u6559\u80b2\u8bc4\u4f30\u9879\u76ee\u4e0e\u5185\u5bb9\u6807\u51c6\u7684\u5bf9\u9f50\u72b6\u6001\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5ba1\u6838\u8d1f\u62c5\uff0c\u5efa\u8bae\u91c7\u7528LLM\u7b5b\u9009\u4e0e\u4eba\u5de5\u5ba1\u6838\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6d41\u7a0b\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u5de5\u5bf9\u9f50\u5ba1\u6838\u51c6\u786e\u4f46\u8017\u65f6\u8d39\u529b\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u9879\u76ee\u5e93\u4e2d\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLM\u80fd\u5426\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u52a0\u901f\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u4f7f\u752812,000\u591a\u4e2aK-5\u5e74\u7ea7\u9879\u76ee-\u6280\u80fd\u5bf9\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cdLLM\uff08GPT-3.5 Turbo\u3001GPT-4o-mini\u548cGPT-4o\uff09\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff1a\u8bc6\u522b\u4e0d\u5bf9\u9f50\u9879\u76ee\u3001\u4ece\u5b8c\u6574\u6807\u51c6\u96c6\u4e2d\u9009\u62e9\u6b63\u786e\u6280\u80fd\u3001\u5728\u5206\u7c7b\u524d\u7f29\u5c0f\u5019\u9009\u5217\u8868\u3002", "result": "GPT-4o-mini\u5728\u8bc6\u522b\u5bf9\u9f50\u72b6\u6001\u65b9\u9762\u8fbe\u523083-94%\u7684\u51c6\u786e\u7387\uff1b\u6570\u5b66\u8868\u73b0\u5f3a\u52b2\u4f46\u9605\u8bfb\u8f83\u4f4e\uff1b\u9884\u8fc7\u6ee4\u5019\u9009\u6280\u80fd\u4f7f\u6b63\u786e\u6280\u80fd\u51fa\u73b0\u5728\u524d\u4e94\u5efa\u8bae\u4e2d\u7684\u6982\u7387\u8d85\u8fc795%\u3002", "conclusion": "LLM\u7279\u522b\u662f\u7ed3\u5408\u5019\u9009\u8fc7\u6ee4\u7b56\u7565\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u9879\u76ee\u5ba1\u6838\u7684\u4eba\u5de5\u8d1f\u62c5\u540c\u65f6\u4fdd\u6301\u5bf9\u9f50\u51c6\u786e\u6027\uff0c\u5efa\u8bae\u5f00\u53d1LLM\u7b5b\u9009\u4e0e\u4eba\u5de5\u5ba1\u6838\u7684\u6df7\u5408\u6d41\u7a0b\u4f5c\u4e3a\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19812", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.19812", "abs": "https://arxiv.org/abs/2511.19812", "authors": ["Hao Wu", "Bocong Chen", "Guanghui Zhang", "Hongwei Liu"], "title": "Two-Step Decoding of Binary $2\\times2$ Sum-Rank-Metric Codes", "comment": "16 pages", "summary": "We resolve an open problem posed by Chen--Cheng--Qi (IEEE Trans.\\ Inf.\\ Theory, 2025): can decoding of binary sum-rank-metric codes $\\SR(C_1,C_2)$ with $2\\times2$ matrix blocks be reduced entirely to decoding the constituent Hamming-metric codes $C_1$ and $C_2$ without the additional requirement $d_1\\ge\\tfrac{2}{3}d_{\\mathrm{sr}}$ that underlies their fast decoder? We answer this in the affirmative by exhibiting a simple two-step procedure: first uniquely decode $C_2$, then apply a single error/erasure decoding of $C_1$.This shows that the restrictive hypothesis $d_1\\ge\\tfrac{2}{3}d_{\\mathrm{sr}}$ is theoretically unnecessary.The resulting decoder achieves unique decoding up to $\\lfloor (d_{\\mathrm{sr}}-1)/2\\rfloor$ with overall cost $T_2+T_1$, where $T_2$ and $T_1$ are the complexities of the Hamming decoders for $C_2$ and $C_1$, respectively. We further show that this reduction is asymptotically optimal in a black-box model, as any sum-rank decoder must inherently decode the constituent Hamming codes.For BCH or Goppa instantiations over $\\F_4$, the decoder runs in $O(\\ell^2)$ time.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86Chen-Cheng-Qi\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff0c\u8bc1\u660e\u4e8c\u8fdb\u5236\u548c\u79e9\u5ea6\u91cf\u7801\u7684\u89e3\u7801\u53ef\u4ee5\u5b8c\u5168\u7b80\u5316\u4e3a\u5176\u7ec4\u6210\u6c49\u660e\u7801\u7684\u89e3\u7801\uff0c\u65e0\u9700\u989d\u5916\u7684d1\u22652/3dsr\u6761\u4ef6\u9650\u5236\u3002", "motivation": "Chen-Cheng-Qi\u57282025\u5e74\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\uff1a\u80fd\u5426\u5c062\u00d72\u77e9\u9635\u5757\u7684\u4e8c\u8fdb\u5236\u548c\u79e9\u5ea6\u91cf\u7801\u7684\u89e3\u7801\u5b8c\u5168\u7b80\u5316\u4e3a\u7ec4\u6210\u6c49\u660e\u7801C1\u548cC2\u7684\u89e3\u7801\uff0c\u800c\u4e0d\u9700\u8981\u4ed6\u4eec\u5feb\u901f\u89e3\u7801\u5668\u4e2d\u7684\u989d\u5916\u6761\u4ef6d1\u22652/3dsr\uff1f", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u4e24\u6b65\u89e3\u7801\u8fc7\u7a0b\uff1a\u9996\u5148\u5bf9C2\u8fdb\u884c\u552f\u4e00\u89e3\u7801\uff0c\u7136\u540e\u5bf9C1\u5e94\u7528\u5355\u6b21\u9519\u8bef/\u64e6\u9664\u89e3\u7801\u3002", "result": "\u8bc1\u660e\u9650\u5236\u6027\u5047\u8bbed1\u22652/3dsr\u5728\u7406\u8bba\u4e0a\u662f\u4e0d\u5fc5\u8981\u7684\uff0c\u89e3\u7801\u5668\u53ef\u4ee5\u8fbe\u5230\u230a(dsr-1)/2\u230b\u7684\u552f\u4e00\u89e3\u7801\u80fd\u529b\uff0c\u603b\u4f53\u590d\u6742\u5ea6\u4e3aT2+T1\u3002", "conclusion": "\u8fd9\u79cd\u7b80\u5316\u5728black-box\u6a21\u578b\u4e2d\u662f\u6e10\u8fdb\u6700\u4f18\u7684\uff0c\u4efb\u4f55\u548c\u79e9\u89e3\u7801\u5668\u90fd\u5fc5\u987b\u56fa\u6709\u5730\u89e3\u7801\u7ec4\u6210\u6c49\u660e\u7801\u3002\u5bf9\u4e8eF4\u4e0a\u7684BCH\u6216Goppa\u5b9e\u4f8b\u5316\uff0c\u89e3\u7801\u5668\u8fd0\u884c\u65f6\u95f4\u4e3aO(\u2113\u00b2)\u3002"}}
{"id": "2511.19773", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19773", "abs": "https://arxiv.org/abs/2511.19773", "authors": ["Meng Lu", "Ran Xu", "Yi Fang", "Wenxuan Zhang", "Yue Yu", "Gaurav Srivastava", "Yuchen Zhuang", "Mohamed Elhoseiny", "Charles Fleming", "Carl Yang", "Zhengzhong Tu", "Yang Xie", "Guanghua Xiao", "Hanrui Wang", "Di Jin", "Wenqi Shi", "Xuan Wang"], "title": "Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs", "comment": "17 pages, 9 figures, work in progress", "summary": "While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to \"think with images\", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.", "AI": {"tldr": "VISTA-Gym\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u73af\u5883\uff0c\u65e8\u5728\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u96c6\u6210\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u7edf\u4e00\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u3001\u6807\u51c6\u5316\u89c6\u89c9\u5de5\u5177\u63a5\u53e3\u548c\u6267\u884c\u4ea4\u4e92\u5faa\u73af\u6765\u5b9e\u73b0\u89c6\u89c9\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u6b65\u9aa4\u89c6\u89c9\u4ea4\u4e92\u63a8\u7406\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u5de5\u5177\u9009\u62e9\u3001\u8c03\u7528\u548c\u534f\u8c03\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "\u5f00\u53d1VISTA-Gym\u73af\u5883\uff0c\u7edf\u4e007\u4e2a\u4efb\u52a113\u4e2a\u6570\u636e\u96c6\u7684\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u89c6\u89c9\u5de5\u5177\u63a5\u53e3\u3001\u53ef\u6267\u884c\u4ea4\u4e92\u5faa\u73af\u548c\u53ef\u9a8c\u8bc1\u53cd\u9988\u4fe1\u53f7\u3002\u901a\u8fc7\u591a\u8f6e\u8f68\u8ff9\u91c7\u6837\u548c\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3VISTA-R1\u6a21\u578b\u3002", "result": "\u572811\u4e2a\u516c\u5171\u63a8\u7406\u5bc6\u96c6\u578bVQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVISTA-R1-8B\u6a21\u578b\u6bd4\u540c\u89c4\u6a21\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u53479.51%-18.72%\u3002", "conclusion": "VISTA-Gym\u662f\u4e00\u4e2a\u6709\u6548\u7684\u8bad\u7ec3\u5e73\u53f0\uff0c\u80fd\u591f\u89e3\u9501\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u96c6\u6210\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.19947", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.19947", "abs": "https://arxiv.org/abs/2511.19947", "authors": ["Yuxuan Wu", "Linghan Ma", "Ruichen Zhang", "Yinqiu Liu", "Dusit Niyato", "Shunpu Tang", "Zehui Xiong", "Zhu Han", "Zhaohui Yang", "Kaibin Huang", "Zhaoyang Zhang", "Kai-Kit Wong"], "title": "Towards Edge General Intelligence: Knowledge Distillation for Mobile Agentic AI", "comment": "21 pages, 6 figures", "summary": "Edge General Intelligence (EGI) represents a paradigm shift in mobile edge computing, where intelligent agents operate autonomously in dynamic, resource-constrained environments. However, the deployment of advanced agentic AI models on mobile and edge devices faces significant challenges due to limited computation, energy, and storage resources. To address these constraints, this survey investigates the integration of Knowledge Distillation (KD) into EGI, positioning KD as a key enabler for efficient, communication-aware, and scalable intelligence at the wireless edge. In particular, we emphasize KD techniques specifically designed for wireless communication and mobile networking, such as channel-aware self-distillation, cross-model Channel State Information (CSI) feedback distillation, and robust modulation/classification distillation. Furthermore, we review novel architectures natively suited for KD and edge deployment, such as Mamba, RWKV (Receptance, Weight, Key, Value) and Cross-Architecture distillation, which enhance generalization capabilities. Subsequently, we examine diverse applications in which KD-driven architectures enable EGI across vision, speech, and multimodal tasks. Finally, we highlight the key challenges and future directions for KD in EGI. This survey aims to provide a comprehensive reference for researchers exploring KD-driven frameworks for mobile agentic AI in the era of EGI.", "AI": {"tldr": "\u672c\u8c03\u67e5\u63a2\u8ba8\u4e86\u77e5\u8bc6\u84b8\u998f\u5728\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u9488\u5bf9\u65e0\u7ebf\u901a\u4fe1\u548c\u79fb\u52a8\u7f51\u7edc\u7684KD\u6280\u672f\uff0c\u4ee5\u53ca\u9002\u5408\u8fb9\u7f18\u90e8\u7f72\u7684\u65b0\u578b\u67b6\u6784\uff0c\u65e8\u5728\u4e3a\u79fb\u52a8\u4ee3\u7406AI\u63d0\u4f9b\u9ad8\u6548\u7684KD\u9a71\u52a8\u6846\u67b6\u3002", "motivation": "\u79fb\u52a8\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u667a\u80fd\u4ee3\u7406AI\u9762\u4e34\u8ba1\u7b97\u3001\u80fd\u6e90\u548c\u5b58\u50a8\u8d44\u6e90\u6709\u9650\u7684\u6311\u6218\uff0c\u9700\u8981\u5bfb\u627e\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u6765\u652f\u6301\u52a8\u6001\u3001\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u667a\u80fd\u64cd\u4f5c\u3002", "method": "\u8c03\u67e5\u4e86\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5728\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u4e2d\u7684\u96c6\u6210\uff0c\u5305\u62ec\u4fe1\u9053\u611f\u77e5\u81ea\u84b8\u998f\u3001\u8de8\u6a21\u578bCSI\u53cd\u9988\u84b8\u998f\u3001\u9c81\u68d2\u8c03\u5236/\u5206\u7c7b\u84b8\u998f\u7b49\u4e13\u95e8\u9488\u5bf9\u65e0\u7ebf\u901a\u4fe1\u7684KD\u6280\u672f\uff0c\u4ee5\u53caMamba\u3001RWKV\u548c\u8de8\u67b6\u6784\u84b8\u998f\u7b49\u65b0\u578b\u67b6\u6784\u3002", "result": "KD\u6280\u672f\u80fd\u591f\u5b9e\u73b0\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u3001\u901a\u4fe1\u611f\u77e5\u548c\u53ef\u6269\u5c55\u667a\u80fd\uff0c\u652f\u6301\u89c6\u89c9\u3001\u8bed\u97f3\u548c\u591a\u6a21\u6001\u4efb\u52a1\u7684EGI\u5e94\u7528\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u662f\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u7684\u5173\u952e\u63a8\u52a8\u8005\uff0c\u4f46\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76KD\u5728EGI\u4e2d\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2511.19780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19780", "abs": "https://arxiv.org/abs/2511.19780", "authors": ["Ioannis Tzachristas", "Aifen Sui"], "title": "NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents", "comment": null, "summary": "We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u610f\u56fe\u672c\u4f53\u4e0e\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u5b9e\u73b0\u79fb\u52a8AI\u4ee3\u7406\u7684\u591a\u610f\u56fe\u7406\u89e3\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001logit\u504f\u7f6e\u548c\u53ef\u9009\u5206\u7c7b\u5934\uff0c\u5c06\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\u6ce8\u5165\u8f93\u5165\u548c\u8f93\u51fa\u8868\u793a\u4e2d\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8AI\u4ee3\u7406\u4e2d\u591a\u610f\u56fe\u7406\u89e3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\u4e2d\u6ce8\u5165\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\uff0c\u5b9e\u73b0\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u7684\u51c6\u786e\u610f\u56fe\u7406\u89e3\u3002", "method": "\u96c6\u6210\u7ed3\u6784\u5316\u610f\u56fe\u672c\u4f53\u4e0e\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001logit\u504f\u7f6e\u548c\u53ef\u9009\u5206\u7c7b\u5934\u6765\u6ce8\u5165\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\u3002", "result": "\u5728MultiWOZ 2.3\u7684\u6a21\u7cca/\u590d\u6742\u5bf9\u8bdd\u5b50\u96c6\u4e0a\uff0c3B\u53c2\u6570\u7684Llama\u6a21\u578b\u901a\u8fc7\u672c\u4f53\u589e\u5f3a\u63a5\u8fd1GPT-4\u7684\u51c6\u786e\u7387\uff0885% vs 90%\uff09\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5185\u5b58\u5360\u7528\u3002", "conclusion": "\u7b26\u53f7\u5bf9\u9f50\u662f\u5b9e\u73b0\u5728\u8bbe\u5907\u4e0a\u51c6\u786e\u9ad8\u6548\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7684\u6709\u6548\u7b56\u7565\uff0c\u672c\u4f53\u589e\u5f3a\u6a21\u578b\u80fd\u4ea7\u751f\u66f4\u63a5\u5730\u6c14\u3001\u66f4\u6e05\u6670\u7684\u591a\u610f\u56fe\u89e3\u91ca\u3002"}}
{"id": "2511.20108", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20108", "abs": "https://arxiv.org/abs/2511.20108", "authors": ["Miled Alam", "Abdul Karim Gizzini", "Laurent Clavier"], "title": "Explainable Deep Learning for Secrecy Energy-Efficiency Maximization in Ambient Backscatter Multi-User NOMA Systems", "comment": "This article has been submitted to the IEEE Transactions on Green Communications and Networking as a Regular Paper", "summary": "In this paper, we investigate the secrecy energy-efficiency (SEE) of a multi-user downlink non-orthogonal multiple access (NOMA) system assisted by multiple ambient backscatter communications (AmBC) in the presence of a passive eavesdropper. We analyze both the trade-off and the ratio between the achievable secrecy sum-rate and total power consumption. In the special case of two backscatter devices (BDs), we derive closed-form solutions for the optimal reflection coefficients and power allocation by exploiting the structure of the SEE objective and the Pareto boundary of the feasible set. When more than two BDs are present, the problem becomes analytically intractable. To address this, we propose two efficient optimization techniques: (i) an exhaustive grid-based benchmark method, and (ii) a scalable particle swarm optimization algorithm. Furthermore, we design a deep learning-based predictor using a feedforward neural network (FNN), which closely approximates the optimal solutions. Numerical results show that the inclusion of AmBC significantly improves SEE, with gains up to 615% compared to conventional NOMA in high-noise regimes. Additionally, the FNN model achieves more than 95% accuracy compared to the optimal baseline, while reducing complexity. Finally, we employ SHAP (SHapley Additive exPlanations) to interpret the learned model, revealing that the most influential features correspond to the dominant composite channel components, in accordance with the theoretical system model. This demonstrates the potential of explainable artificial intelligence to build trust in energy-efficient and secure AmBC-NOMA systems for next-generation internet of things applications.", "AI": {"tldr": "\u7814\u7a76\u591a\u7528\u6237\u4e0b\u884cNOMA\u7cfb\u7edf\u4e2d\u591a\u4e2a\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u8f85\u52a9\u4e0b\u7684\u4fdd\u5bc6\u80fd\u6548\uff0c\u63d0\u51fa\u4f18\u5316\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u5668\uff0c\u663e\u8457\u63d0\u5347\u80fd\u6548\u5e76\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "\u7814\u7a76\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u8f85\u52a9\u7684NOMA\u7cfb\u7edf\u5728\u88ab\u52a8\u7a83\u542c\u8005\u5b58\u5728\u4e0b\u7684\u4fdd\u5bc6\u80fd\u6548\uff0c\u89e3\u51b3\u591a\u8bbe\u5907\u573a\u666f\u4e0b\u7684\u4f18\u5316\u96be\u9898\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u7269\u8054\u7f51\u5e94\u7528\u63d0\u4f9b\u80fd\u6548\u548c\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u9488\u5bf9\u4e24\u4e2a\u53cd\u5411\u6563\u5c04\u8bbe\u5907\u63a8\u5bfc\u95ed\u5f0f\u89e3\uff0c\u5bf9\u591a\u8bbe\u5907\u573a\u666f\u63d0\u51fa\u7f51\u683c\u641c\u7d22\u548c\u7c92\u5b50\u7fa4\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u5668\u6765\u8fd1\u4f3c\u6700\u4f18\u89e3\u3002", "result": "AmBC\u663e\u8457\u63d0\u5347\u4fdd\u5bc6\u80fd\u6548\uff0c\u5728\u9ad8\u566a\u58f0\u73af\u5883\u4e0b\u76f8\u6bd4\u4f20\u7edfNOMA\u63d0\u5347\u8fbe615%\uff1bFNN\u6a21\u578b\u8fbe\u523095%\u4ee5\u4e0a\u51c6\u786e\u7387\u4e14\u964d\u4f4e\u590d\u6742\u5ea6\uff1bSHAP\u5206\u6790\u663e\u793a\u4e3b\u5bfc\u590d\u5408\u4fe1\u9053\u7279\u5f81\u6700\u5177\u5f71\u54cd\u529b\u3002", "conclusion": "\u8bc1\u660e\u4e86\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u5728\u6784\u5efa\u53ef\u4fe1\u8d56\u7684\u80fd\u6548\u5b89\u5168AmBC-NOMA\u7cfb\u7edf\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u7269\u8054\u7f51\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19798", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19798", "abs": "https://arxiv.org/abs/2511.19798", "authors": ["Weizhi Liu", "Xi Chen", "Zekun Jiang", "Liang Zhao", "Kunyuan Jiang", "Ruisi Tang", "Li Wang", "Mingke You", "Hanyu Zhou", "Hongyu Chen", "Qiankun Xiong", "Yong Nie", "Kang Li", "Jian Li"], "title": "KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)", "comment": null, "summary": "Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.", "AI": {"tldr": "KOM\u662f\u4e00\u4e2a\u7528\u4e8e\u819d\u9aa8\u5173\u8282\u708e\u7ba1\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\uff0c\u5728\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u819d\u9aa8\u5173\u8282\u708e\u5f71\u54cd\u5168\u74036\u4ebf\u591a\u4eba\uff0c\u4e2a\u6027\u5316\u591a\u5b66\u79d1\u5e72\u9884\u867d\u7136\u6709\u6548\u4f46\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u5b9e\u65bd\u3002", "method": "\u5f00\u53d1KOM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u81ea\u52a8\u5316KOA\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\uff0c\u652f\u6301\u57fa\u4e8e\u60a3\u8005\u4e2a\u4f53\u7279\u5f81\u751f\u6210\u5b9a\u5236\u7ba1\u7406\u8ba1\u5212\u3002", "result": "\u5728\u57fa\u51c6\u5b9e\u9a8c\u4e2d\uff0cKOM\u5728\u5f71\u50cf\u5206\u6790\u548c\u5904\u65b9\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff1b\u968f\u673a\u4e09\u81c2\u6a21\u62df\u7814\u7a76\u663e\u793a\uff0cKOM\u4e0e\u4e34\u5e8a\u533b\u751f\u5408\u4f5c\u4f7f\u8bca\u65ad\u548c\u89c4\u5212\u65f6\u95f4\u51cf\u5c1138.5%\uff0c\u6cbb\u7597\u8d28\u91cf\u63d0\u9ad8\u3002", "conclusion": "KOM\u6709\u52a9\u4e8e\u5b9e\u73b0KOA\u7ba1\u7406\u7684\u81ea\u52a8\u5316\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u4e3a\u5f00\u53d1\u5176\u4ed6\u6162\u6027\u75c5\u7684AI\u8f85\u52a9\u7ba1\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2511.20117", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20117", "abs": "https://arxiv.org/abs/2511.20117", "authors": ["Min Xu", "Xuejiao Han", "Kai Wan", "Gennian Ge"], "title": "On hierarchical secure aggregation against relay and user collusion", "comment": null, "summary": "Secure aggregation (SA) is fundamental to privacy preservation in federated learning (FL), enabling model aggregation while preventing disclosure of individual user updates. This paper addresses hierarchical secure aggregation (HSA) against relay and user collusion in homogeneous networks, where each user connects to $n$ relays and each relay serves $m$ users. In the two-phase communication framework, users transmit masked data to relays, which then process and forward compiled messages to the server for exact sum recovery. The primary objective is to devise a transmission scheme such that the server can finish the aggregation task, while any group of $T_h$ colluding relays and $T_u$ colluding users cannot reveal any information about the data owned by the non-colluding users. In this study, we establish fundamental limits on the communication load, defined as the ratio of transmitted information size to original data size, for each user-relay link and each relay-server link. Achievable thresholds for collusion resilience are also derived. When the number of colluding relays and users falls below certain critical thresholds, we construct communication-optimal schemes using methods from network function computation. A limitation of these schemes is their reliance on large random keys. To address this, we derive a lower bound on the required key size and prove its achievability in cyclic networks, where users are connected to relays in a cyclic wrap-around manner. By establishing a connection between HSA and network function computation, this work advances the theoretical limits of communication efficiency and information-theoretic security in secure aggregation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u540c\u6784\u7f51\u7edc\u4e2d\u7684\u5206\u5c42\u5b89\u5168\u805a\u5408\uff08HSA\uff09\uff0c\u9488\u5bf9\u4e2d\u7ee7\u548c\u7528\u6237\u5171\u8c0b\u653b\u51fb\uff0c\u5efa\u7acb\u4e86\u901a\u4fe1\u8d1f\u8f7d\u7684\u57fa\u672c\u754c\u9650\uff0c\u5e76\u8bbe\u8ba1\u4e86\u901a\u4fe1\u6700\u4f18\u65b9\u6848\u3002", "motivation": "\u5b89\u5168\u805a\u5408\u662f\u8054\u90a6\u5b66\u4e60\u4e2d\u4fdd\u62a4\u9690\u79c1\u7684\u57fa\u7840\u6280\u672f\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u5c42\u7ed3\u6784\u3002\u672c\u6587\u9488\u5bf9\u5206\u5c42\u7f51\u7edc\u4e2d\u7684\u4e2d\u7ee7\u548c\u7528\u6237\u5171\u8c0b\u95ee\u9898\uff0c\u65e8\u5728\u8bbe\u8ba1\u65e2\u80fd\u5b8c\u6210\u805a\u5408\u4efb\u52a1\u53c8\u80fd\u4fdd\u62a4\u975e\u5171\u8c0b\u7528\u6237\u6570\u636e\u9690\u79c1\u7684\u4f20\u8f93\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u901a\u4fe1\u6846\u67b6\uff1a\u7528\u6237\u5411\u4e2d\u7ee7\u53d1\u9001\u63a9\u7801\u6570\u636e\uff0c\u4e2d\u7ee7\u5904\u7406\u5e76\u8f6c\u53d1\u7f16\u8bd1\u6d88\u606f\u7ed9\u670d\u52a1\u5668\u8fdb\u884c\u7cbe\u786e\u6c42\u548c\u6062\u590d\u3002\u5229\u7528\u7f51\u7edc\u51fd\u6570\u8ba1\u7b97\u7684\u65b9\u6cd5\u6784\u5efa\u901a\u4fe1\u6700\u4f18\u65b9\u6848\uff0c\u5e76\u5728\u5faa\u73af\u7f51\u7edc\u4e2d\u5b9e\u73b0\u6240\u9700\u5bc6\u94a5\u5927\u5c0f\u7684\u4e0b\u754c\u3002", "result": "\u5efa\u7acb\u4e86\u7528\u6237-\u4e2d\u7ee7\u94fe\u8def\u548c\u4e2d\u7ee7-\u670d\u52a1\u5668\u94fe\u8def\u7684\u901a\u4fe1\u8d1f\u8f7d\u57fa\u672c\u754c\u9650\uff0c\u63a8\u5bfc\u4e86\u5171\u8c0b\u5f39\u6027\u7684\u53ef\u8fbe\u9608\u503c\u3002\u5f53\u5171\u8c0b\u4e2d\u7ee7\u548c\u7528\u6237\u6570\u91cf\u4f4e\u4e8e\u5173\u952e\u9608\u503c\u65f6\uff0c\u6784\u5efa\u4e86\u901a\u4fe1\u6700\u4f18\u65b9\u6848\u3002\u5728\u5faa\u73af\u7f51\u7edc\u4e2d\u8bc1\u660e\u4e86\u6240\u9700\u5bc6\u94a5\u5927\u5c0f\u4e0b\u754c\u7684\u53ef\u8fbe\u6027\u3002", "conclusion": "\u901a\u8fc7\u5efa\u7acbHSA\u4e0e\u7f51\u7edc\u51fd\u6570\u8ba1\u7b97\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u672c\u6587\u63a8\u8fdb\u4e86\u5b89\u5168\u805a\u5408\u4e2d\u901a\u4fe1\u6548\u7387\u548c\u4fe1\u606f\u8bba\u5b89\u5168\u7684\u7406\u8bba\u754c\u9650\uff0c\u4e3a\u5206\u5c42\u7f51\u7edc\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2511.19829", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19829", "abs": "https://arxiv.org/abs/2511.19829", "authors": ["Ke Chen", "Yifeng Wang", "Hassan Almosapeeh", "Haohan Wang"], "title": "A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization", "comment": null, "summary": "Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc4\u4f30\u6307\u5bfc\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\u548c\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\u6765\u6307\u5bfc\u67e5\u8be2\u76f8\u5173\u7684\u63d0\u793a\u91cd\u5199\uff0c\u5b9e\u73b0\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u7684\u8de8\u6a21\u578b\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u9759\u6001\u6a21\u677f\uff0c\u5728\u590d\u6742\u52a8\u6001\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff1b\u67e5\u8be2\u76f8\u5173\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u7684\u6587\u672c\u53cd\u9988\u6216\u9ed1\u76d2\u5956\u52b1\u6a21\u578b\uff0c\u63d0\u4f9b\u5f31\u4e14\u4e0d\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u4fe1\u53f7\uff1b\u63d0\u793a\u8d28\u91cf\u672c\u8eab\u7f3a\u4e4f\u7edf\u4e00\u7cfb\u7edf\u5b9a\u4e49\u3002", "method": "\u9996\u5148\u5efa\u7acb\u9762\u5411\u6027\u80fd\u7684\u7cfb\u7edf\u5316\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\uff0c\u5f00\u53d1\u5e76\u5fae\u8c03\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\u76f4\u63a5\u9884\u6d4b\u591a\u7ef4\u8d28\u91cf\u5206\u6570\uff0c\u7136\u540e\u8ba9\u8bc4\u4f30\u5668\u6307\u5bfc\u5ea6\u91cf\u611f\u77e5\u7684\u4f18\u5316\u5668\u4ee5\u53ef\u89e3\u91ca\u3001\u67e5\u8be2\u76f8\u5173\u7684\u65b9\u5f0f\u8bca\u65ad\u5931\u8d25\u6a21\u5f0f\u5e76\u91cd\u5199\u63d0\u793a\u3002", "result": "\u8bc4\u4f30\u5668\u5728\u9884\u6d4b\u63d0\u793a\u6027\u80fd\u65b9\u9762\u8fbe\u5230\u6700\u5f3a\u51c6\u786e\u5ea6\uff0c\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u57288\u4e2a\u6570\u636e\u96c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u6301\u7eed\u8d85\u8d8a\u9759\u6001\u6a21\u677f\u548c\u67e5\u8be2\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7edf\u4e00\u3001\u57fa\u4e8e\u5ea6\u91cf\u7684\u63d0\u793a\u8d28\u91cf\u89c6\u89d2\uff0c\u8bc1\u660e\u4e86\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u7ba1\u9053\u80fd\u591f\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u4e14\u6a21\u578b\u65e0\u5173\u7684\u6539\u8fdb\u3002"}}
{"id": "2511.20127", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20127", "abs": "https://arxiv.org/abs/2511.20127", "authors": ["Ali Khalesi"], "title": "General Multi-User Distributed Computing", "comment": null, "summary": "This work develops a unified {learning- and information-theoretic} framework for distributed computation and inference across multiple users and servers. The proposed \\emph{General Multi-User Distributed Computing (GMUDC)} model characterizes how computation, communication, and accuracy can be jointly optimized when users demand heterogeneous target functions that are arbitrary transformations of shared real-valued subfunctions. Without any separability assumption, and requiring only that each target function lies in a reproducing-kernel Hilbert space associated with a shift-invariant kernel, the framework remains valid for arbitrary connectivity and task-assignment topologies. A dual analysis is introduced: the \\emph{quenched design} considers fixed assignments of subfunctions and network topology, while the \\emph{annealed design} captures the averaged performance when assignments and links are drawn uniformly at random from a given ensemble. These formulations reveal the fundamental limits governing the trade-offs among computing load, communication load, and reconstruction distortion under computational and communication budgets~$\u0393$ and~$\u0394$. The analysis establishes a spectral-coverage duality linking generalization capability with network topology and resource allocation, leading to provably efficient and topology-aware distributed designs. The resulting principles provide an \\emph{information-energy foundation} for scalable and resource-optimal distributed and federated learning systems, with direct applications to aeronautical, satellite, and edge-intelligent networks where energy and data efficiency are critical.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5b66\u4e60\u548c\u4fe1\u606f\u7406\u8bba\u6846\u67b6GMUDC\uff0c\u7528\u4e8e\u591a\u7528\u6237\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u63a8\u7406\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8ba1\u7b97\u3001\u901a\u4fe1\u548c\u7cbe\u5ea6\u6765\u6ee1\u8db3\u5f02\u6784\u76ee\u6807\u51fd\u6570\u9700\u6c42\u3002", "motivation": "\u4e3a\u5206\u5e03\u5f0f\u548c\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u5efa\u7acb\u53ef\u6269\u5c55\u4e14\u8d44\u6e90\u6700\u4f18\u7684\u4fe1\u606f\u80fd\u91cf\u57fa\u7840\uff0c\u7279\u522b\u9002\u7528\u4e8e\u822a\u7a7a\u3001\u536b\u661f\u548c\u8fb9\u7f18\u667a\u80fd\u7f51\u7edc\u7b49\u80fd\u6e90\u548c\u6570\u636e\u6548\u7387\u81f3\u5173\u91cd\u8981\u7684\u573a\u666f\u3002", "method": "\u5f15\u5165\u53cc\u91cd\u5206\u6790\uff1a\u6dec\u706b\u8bbe\u8ba1\u8003\u8651\u56fa\u5b9a\u7684\u5b50\u51fd\u6570\u5206\u914d\u548c\u7f51\u7edc\u62d3\u6251\uff0c\u9000\u706b\u8bbe\u8ba1\u6355\u83b7\u4ece\u7ed9\u5b9a\u96c6\u5408\u4e2d\u5747\u5300\u968f\u673a\u62bd\u53d6\u5206\u914d\u548c\u94fe\u63a5\u65f6\u7684\u5e73\u5747\u6027\u80fd\u3002", "result": "\u63ed\u793a\u4e86\u5728\u8ba1\u7b97\u548c\u901a\u4fe1\u9884\u7b97\u4e0b\uff0c\u8ba1\u7b97\u8d1f\u8f7d\u3001\u901a\u4fe1\u8d1f\u8f7d\u548c\u91cd\u6784\u5931\u771f\u4e4b\u95f4\u6743\u8861\u7684\u57fa\u672c\u9650\u5236\uff0c\u5efa\u7acb\u4e86\u8fde\u63a5\u6cdb\u5316\u80fd\u529b\u4e0e\u7f51\u7edc\u62d3\u6251\u548c\u8d44\u6e90\u5206\u914d\u7684\u5149\u8c31\u8986\u76d6\u5bf9\u5076\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u548c\u8d44\u6e90\u6700\u4f18\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u4e14\u62d3\u6251\u611f\u77e5\u7684\u5206\u5e03\u5f0f\u8bbe\u8ba1\u3002"}}
{"id": "2511.19849", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19849", "abs": "https://arxiv.org/abs/2511.19849", "authors": ["Dominik Wagner", "Leon Witzman", "Luke Ong"], "title": "Reinforcement Learning with $\u03c9$-Regular Objectives and Constraints", "comment": null, "summary": "Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $\u03c9$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.\n  We address both limitations simultaneously by combining $\u03c9$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $\u03c9$-regular objective while also adhering to $\u03c9$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u03c9-\u6b63\u5219\u76ee\u6807\u4e0e\u663e\u5f0f\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ebf\u6027\u89c4\u5212\u7b97\u6cd5\u5728\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u4e0b\u6700\u5927\u5316\u76ee\u6807\u8fbe\u6210\u6982\u7387", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7684\u6807\u91cf\u5956\u52b1\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u5bb9\u6613\u5bfc\u81f4\u5956\u52b1\u7834\u89e3\uff0c\u4e14\u5355\u4e00\u6027\u80fd\u6307\u6807\u63a9\u76d6\u4e86\u5b89\u5168\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861", "method": "\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5c06\u03c9-\u6b63\u5219\u76ee\u6807\u4e0e\u7ea6\u675f\u5206\u5f00\u5904\u7406\uff0c\u5efa\u7acb\u5230\u7ea6\u675f\u6781\u9650\u5e73\u5747\u95ee\u9898\u7684\u8f6c\u6362", "result": "\u7b97\u6cd5\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u80fd\u4ea7\u751f\u5728\u6307\u5b9a\u9608\u503c\u5185\u6ee1\u8db3\u03c9-\u6b63\u5219\u7ea6\u675f\u7684\u540c\u65f6\u6700\u5927\u5316\u03c9-\u6b63\u5219\u76ee\u6807\u8fbe\u6210\u6982\u7387\u7684\u7b56\u7565", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u540c\u65f6\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5b89\u5168-\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u5177\u6709\u6700\u4f18\u6027\u4fdd\u6301\u4fdd\u8bc1"}}
{"id": "2511.20160", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.20160", "abs": "https://arxiv.org/abs/2511.20160", "authors": ["Francisco D\u00edaz-Ruiz", "Francisco J. Mart\u00edn-Vega", "Jose A. Cort\u00e9s", "Gerardo G\u00f3mez", "Mari Carmen Aguayo"], "title": "CSI Prediction Frameworks for Enhanced 5G Link Adaptation: Performance-Complexity Trade-offs", "comment": null, "summary": "Accurate and timely channel state information (CSI) is fundamental for efficient link adaptation. However, challenges such as channel aging, user mobility, and feedback delays significantly impact the performance of adaptive modulation and coding (AMC). This paper proposes and evaluates two CSI prediction frameworks applicable to both time division duplexing (TDD) and frequency division duplexing (FDD) systems. The proposed methods operate in the effective signal to interference plus noise ratio (SINR) domain to reduce complexity while preserving predictive accuracy. A comparative analysis is conducted between a classical Wiener filter and state-of-the-art deep learning frameworks based on gated recurrent units (GRUs), long short-term memory (LSTM) networks, and a delayed deep neural network (DNN). The evaluation considers the accuracy of the prediction in terms of mean squared error (MSE), the performance of the system, and the complexity of the implementation regarding floating point operations (FLOPs). Furthermore, we investigate the generalizability of both approaches under various propagation conditions. The simulation results show that the Wiener filter performs close to GRU in terms of MSE and throughput with lower computational complexity, provided that the second-order statistics of the channel are available. However, the GRU model exhibits enhanced generalization across different channel scenarios. These findings suggest that while learningbased solutions are well-suited for TDD systems where the base station (BS) handles the computation, the lower complexity of classical methods makes them a preferable choice for FDD setups, where prediction occurs at the power-constrained user equipment (UE).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e24\u79cd\u9002\u7528\u4e8eTDD\u548cFDD\u7cfb\u7edf\u7684CSI\u9884\u6d4b\u6846\u67b6\uff0c\u5728\u6709\u6548SINR\u57df\u5de5\u4f5c\u4ee5\u964d\u4f4e\u590d\u6742\u5ea6\u3002\u6bd4\u8f83\u4e86\u7ecf\u5178\u7ef4\u7eb3\u6ee4\u6ce2\u5668\u548c\u57fa\u4e8eGRU\u3001LSTM\u3001DNN\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u679c\u663e\u793a\u7ef4\u7eb3\u6ee4\u6ce2\u5668\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u63a5\u8fd1GRU\uff0c\u4f46GRU\u5728\u4e0d\u540c\u4fe1\u9053\u573a\u666f\u4e0b\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u51c6\u786e\u7684CSI\u5bf9\u4e8e\u9ad8\u6548\u94fe\u8def\u81ea\u9002\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4fe1\u9053\u8001\u5316\u3001\u7528\u6237\u79fb\u52a8\u6027\u548c\u53cd\u9988\u5ef6\u8fdf\u7b49\u6311\u6218\u663e\u8457\u5f71\u54cd\u81ea\u9002\u5e94\u8c03\u5236\u7f16\u7801\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u5728\u6709\u6548SINR\u57df\u5de5\u4f5c\u7684CSI\u9884\u6d4b\u6846\u67b6\uff0c\u6bd4\u8f83\u7ef4\u7eb3\u6ee4\u6ce2\u5668\u4e0e\u57fa\u4e8eGRU\u3001LSTM\u3001DNN\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u53ef\u83b7\u5f97\u4fe1\u9053\u4e8c\u9636\u7edf\u8ba1\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u7ef4\u7eb3\u6ee4\u6ce2\u5668\u5728MSE\u548c\u541e\u5410\u91cf\u65b9\u9762\u6027\u80fd\u63a5\u8fd1GRU\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\u3002\u4f46GRU\u6a21\u578b\u5728\u4e0d\u540c\u4fe1\u9053\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\u66f4\u9002\u5408TDD\u7cfb\u7edf\uff08\u57fa\u7ad9\u5904\u7406\u8ba1\u7b97\uff09\uff0c\u800c\u7ecf\u5178\u65b9\u6cd5\u7684\u4f4e\u590d\u6742\u5ea6\u4f7f\u5176\u6210\u4e3aFDD\u8bbe\u7f6e\uff08\u529f\u7387\u53d7\u9650\u7684\u7528\u6237\u8bbe\u5907\u8fdb\u884c\u9884\u6d4b\uff09\u7684\u4f18\u9009\u65b9\u6848\u3002"}}
{"id": "2511.19864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19864", "abs": "https://arxiv.org/abs/2511.19864", "authors": ["Valerie Lockhart", "Dan McCreary", "Troy A. Peterson"], "title": "MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support", "comment": "42 pages, 4 figures", "summary": "Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.", "AI": {"tldr": "MicroSims\u662f\u4e00\u4e2a\u7528\u4e8e\u5feb\u901f\u751f\u6210\u8f7b\u91cf\u7ea7\u4ea4\u4e92\u5f0f\u6559\u80b2\u6a21\u62df\u7684AI\u6846\u67b6\uff0c\u5177\u6709\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u3001iframe\u67b6\u6784\u548c\u53ef\u4fee\u6539\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u62df\u5f00\u53d1\u6210\u672c\u9ad8\u3001\u6280\u672f\u590d\u6742\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6559\u80b2\u6a21\u62df\u5f00\u53d1\u9700\u8981\u5927\u91cf\u8d44\u6e90\u548c\u6280\u672f\u4e13\u957f\uff0c\u963b\u788d\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002MicroSims\u65e8\u5728\u901a\u8fc7AI\u8f85\u52a9\u751f\u6210\u3001\u901a\u7528\u5d4c\u5165\u548c\u65e0\u7f16\u7a0b\u5b9a\u5236\uff0c\u964d\u4f4e\u6559\u80b2\u6a21\u62df\u7684\u521b\u5efa\u95e8\u69db\u3002", "method": "\u91c7\u7528\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u652f\u6301AI\u751f\u6210\uff0ciframe\u67b6\u6784\u5b9e\u73b0\u901a\u7528\u5d4c\u5165\u548c\u5b89\u5168\u6c99\u7bb1\uff0c\u900f\u660e\u53ef\u4fee\u6539\u4ee3\u7801\u652f\u6301\u5b9a\u5236\u548c\u6559\u5b66\u900f\u660e\u5ea6\uff0c\u5305\u542b\u8bbe\u8ba1\u539f\u5219\u3001\u6280\u672f\u67b6\u6784\u3001\u5143\u6570\u636e\u6807\u51c6\u548c\u5f00\u53d1\u6d41\u7a0b\u3002", "result": "\u57fa\u4e8e\u7269\u7406\u6559\u80b2\u7814\u7a76\u548cSTEM\u5143\u5206\u6790\uff0c\u4ea4\u4e92\u6a21\u62df\u53ef\u5c06\u6982\u5ff5\u7406\u89e3\u63d0\u534730-40%\u3002MicroSims\u5728\u4fdd\u6301\u8fd9\u4e9b\u76ca\u5904\u7684\u540c\u65f6\u89e3\u51b3\u4e86\u6210\u672c\u3001\u6280\u672f\u590d\u6742\u6027\u548c\u5e73\u53f0\u4f9d\u8d56\u7b49\u969c\u788d\u3002", "conclusion": "MicroSims\u6846\u67b6\u5bf9\u6559\u80b2\u516c\u5e73\u6709\u91cd\u8981\u610f\u4e49\uff0c\u80fd\u591f\u652f\u6301\u5168\u7403\u6559\u80b2\u5de5\u4f5c\u8005\u6309\u9700\u521b\u5efa\u5b9a\u5236\u5316\u3001\u4e0e\u8bfe\u7a0b\u5bf9\u9f50\u7684\u6a21\u62df\uff0c\u5e76\u4e3a\u57fa\u4e8eAI\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.20364", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20364", "abs": "https://arxiv.org/abs/2511.20364", "authors": ["Wenkun Wen", "Tierui Min", "Long Yuan", "Minghua Xia"], "title": "Unified Block Signal Processing Framework for LPWANs: Sequence Index Modulation Spreading", "comment": "13 pages, 9 figures, 5 tables; submitted for possible publication", "summary": "Low-power wide-area networks (LPWANs) demand high receiver sensitivity and efficient physical-layer signal processing. This paper introduces a unified framework for generalized block signal transmission in LPWANs, addressing the limitations of conventional symbol-by-symbol approaches. The framework comprises three key components: the signal block vector, the intra-block structure generator, and the signal basis matrix, and leverages quasi-orthogonal codewords formed through cyclically shifted spreading sequences. The resulting quasi-orthogonality enables reliable multi-user separation, particularly under asynchronous access. The framework establishes a conceptual foundation for block synchronization and provides a unified demodulation structure based on block correlation matching. It further supports flexible and systematic implementation, as demonstrated through applications to frequency-shift keying and chirp spread spectrum. This work advances scalable and efficient physical-layer design for next-generation LPWANs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eLPWAN\u7684\u901a\u7528\u5757\u4fe1\u53f7\u4f20\u8f93\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u9010\u7b26\u53f7\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u652f\u6301\u51c6\u6b63\u4ea4\u7801\u5b57\u548c\u5f02\u6b65\u591a\u7528\u6237\u5206\u79bb\u3002", "motivation": "\u4f4e\u529f\u8017\u5e7f\u57df\u7f51\u9700\u8981\u9ad8\u63a5\u6536\u7075\u654f\u5ea6\u548c\u9ad8\u6548\u7684\u7269\u7406\u5c42\u4fe1\u53f7\u5904\u7406\uff0c\u4f20\u7edf\u9010\u7b26\u53f7\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5757\u4f20\u8f93\u6846\u67b6\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u4fe1\u53f7\u5757\u5411\u91cf\u3001\u5757\u5185\u7ed3\u6784\u751f\u6210\u5668\u548c\u4fe1\u53f7\u57fa\u7840\u77e9\u9635\uff0c\u5229\u7528\u5faa\u73af\u79fb\u4f4d\u6269\u9891\u5e8f\u5217\u5f62\u6210\u51c6\u6b63\u4ea4\u7801\u5b57\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u5f02\u6b65\u591a\u7528\u6237\u5206\u79bb\uff0c\u5efa\u7acb\u4e86\u5757\u540c\u6b65\u6982\u5ff5\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5757\u76f8\u5173\u5339\u914d\u7684\u7edf\u4e00\u89e3\u8c03\u7ed3\u6784\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u8fdb\u4e86\u4e0b\u4e00\u4ee3LPWAN\u7684\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7269\u7406\u5c42\u8bbe\u8ba1\uff0c\u652f\u6301\u7075\u6d3b\u7cfb\u7edf\u5b9e\u73b0\u3002"}}
{"id": "2511.19865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19865", "abs": "https://arxiv.org/abs/2511.19865", "authors": ["Mingkai Chen", "Zijie Feng", "Lei Wang", "Yaser Khamayseh"], "title": "Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G", "comment": "7 pages, 8 figures. Preprint submitted to IEEE Vehicle Technology Magazine", "summary": "In the 6G era, semantic collaboration among multiple embodied intelligent devices (MEIDs) becomes crucial for complex task execution. However, existing systems face challenges in multimodal information fusion, adaptive communication, and decision interpretability. To address these limitations, we propose a collaborative Conversational Embodied Intelligence Network (CC-EIN) integrating multimodal feature fusion, adaptive semantic communication, task coordination, and interpretability. PerceptiNet performs cross-modal fusion of image and radar data to generate unified semantic representations. An adaptive semantic communication strategy dynamically adjusts coding schemes and transmission power according to task urgency and channel quality. A semantic-driven collaboration mechanism further supports task decomposition and conflict-free coordination among heterogeneous devices. Finally, the InDec module enhances decision transparency through Grad-CAM visualization. Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN achieves 95.4% task completion rate and 95% transmission efficiency while maintaining strong semantic consistency and energy efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u534f\u4f5c\u5bf9\u8bdd\u5177\u8eab\u667a\u80fd\u7f51\u7edc\uff08CC-EIN\uff09\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u3001\u81ea\u9002\u5e94\u8bed\u4e49\u901a\u4fe1\u3001\u4efb\u52a1\u534f\u8c03\u548c\u53ef\u89e3\u91ca\u6027\u6a21\u5757\uff0c\u89e3\u51b36G\u65f6\u4ee3\u591a\u5177\u8eab\u667a\u80fd\u8bbe\u5907\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u534f\u4f5c\u6311\u6218\u3002", "motivation": "\u57286G\u65f6\u4ee3\uff0c\u591a\u5177\u8eab\u667a\u80fd\u8bbe\u5907\uff08MEIDs\uff09\u7684\u8bed\u4e49\u534f\u4f5c\u5bf9\u590d\u6742\u4efb\u52a1\u6267\u884c\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u3001\u81ea\u9002\u5e94\u901a\u4fe1\u548c\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "CC-EIN\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u6a21\u5757\uff1aPerceptiNet\u8fdb\u884c\u56fe\u50cf\u548c\u96f7\u8fbe\u6570\u636e\u7684\u8de8\u6a21\u6001\u878d\u5408\u751f\u6210\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff1b\u81ea\u9002\u5e94\u8bed\u4e49\u901a\u4fe1\u7b56\u7565\u6839\u636e\u4efb\u52a1\u7d27\u6025\u6027\u548c\u4fe1\u9053\u8d28\u91cf\u52a8\u6001\u8c03\u6574\u7f16\u7801\u65b9\u6848\u548c\u4f20\u8f93\u529f\u7387\uff1b\u8bed\u4e49\u9a71\u52a8\u534f\u4f5c\u673a\u5236\u652f\u6301\u4efb\u52a1\u5206\u89e3\u548c\u5f02\u6784\u8bbe\u5907\u95f4\u7684\u65e0\u51b2\u7a81\u534f\u8c03\uff1bInDec\u6a21\u5757\u901a\u8fc7Grad-CAM\u53ef\u89c6\u5316\u589e\u5f3a\u51b3\u7b56\u900f\u660e\u5ea6\u3002", "result": "\u5728\u5730\u9707\u540e\u6551\u63f4\u573a\u666f\u7684\u4eff\u771f\u4e2d\uff0cCC-EIN\u5b9e\u73b0\u4e8695.4%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u548c95%\u7684\u4f20\u8f93\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u80fd\u6e90\u6548\u7387\u3002", "conclusion": "CC-EIN\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5177\u8eab\u667a\u80fd\u8bbe\u5907\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a6G\u65f6\u4ee3\u7684\u667a\u80fd\u534f\u4f5c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20642", "categories": ["cs.IT", "math.CO", "math.FA", "math.MG"], "pdf": "https://arxiv.org/pdf/2511.20642", "abs": "https://arxiv.org/abs/2511.20642", "authors": ["Joseph W. Iverson", "Kaysie Rose O"], "title": "Dimension-counting bounds for equi-isoclinic subspaces", "comment": null, "summary": "We make four contributions to the theory of optimal subspace packings and equi-isoclinic subspaces: (1) a new lower bound for block coherence, (2) an exact count of equi-isoclinic subspaces of even dimension $r$ in $\\mathbb{R}^{2r+1}$ with parameter $\u03b1\\neq \\tfrac{1}{2}$, (3) a new upper bound for the number of $r$-dimensional equi-isoclinic subspaces in $\\mathbb{R}^d$ or $\\mathbb{C}^d$, and (4) a proof that when $d=2r$, a further refinement of this bound is attained for every $r$ in the complex case and every $r=2^k$ in the real case. For each of these contributions, the proof ultimately relies on a dimension count.", "AI": {"tldr": "\u672c\u6587\u5728\u6700\u4f18\u5b50\u7a7a\u95f4\u586b\u5145\u548c\u7b49\u659c\u5b50\u7a7a\u95f4\u7406\u8bba\u4e2d\u505a\u51fa\u4e86\u56db\u4e2a\u8d21\u732e\uff1a\u65b0\u7684\u5757\u76f8\u5e72\u6027\u4e0b\u754c\u3001\u5076\u6570\u7ef4\u7b49\u659c\u5b50\u7a7a\u95f4\u7cbe\u786e\u8ba1\u6570\u3001\u7b49\u659c\u5b50\u7a7a\u95f4\u6570\u91cf\u65b0\u4e0a\u754c\uff0c\u4ee5\u53ca\u7279\u5b9a\u7ef4\u5ea6\u4e0b\u4e0a\u754c\u53ef\u8fbe\u6027\u7684\u8bc1\u660e\u3002", "motivation": "\u7814\u7a76\u6700\u4f18\u5b50\u7a7a\u95f4\u586b\u5145\u548c\u7b49\u659c\u5b50\u7a7a\u95f4\u7684\u7406\u8bba\u95ee\u9898\uff0c\u65e8\u5728\u6539\u8fdb\u76f8\u5173\u53c2\u6570\u7684\u4e0b\u754c\u548c\u4e0a\u754c\uff0c\u5e76\u7cbe\u786e\u8ba1\u7b97\u7279\u5b9a\u60c5\u51b5\u4e0b\u7684\u7b49\u659c\u5b50\u7a7a\u95f4\u6570\u91cf\u3002", "method": "\u4e3b\u8981\u91c7\u7528\u7ef4\u5ea6\u8ba1\u6570\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u5b66\u5206\u6790\u548c\u51e0\u4f55\u8bba\u8bc1\u6765\u63a8\u5bfc\u5404\u79cd\u754c\u9650\u548c\u8ba1\u6570\u7ed3\u679c\u3002", "result": "\u83b7\u5f97\u4e86\u5757\u76f8\u5e72\u6027\u7684\u65b0\u4e0b\u754c\u3001\u5076\u6570\u7ef4\u7b49\u659c\u5b50\u7a7a\u95f4\u7684\u7cbe\u786e\u8ba1\u6570\u3001\u7b49\u659c\u5b50\u7a7a\u95f4\u6570\u91cf\u7684\u65b0\u4e0a\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u7ef4\u5ea6\u4e0b\u8be5\u4e0a\u754c\u53ef\u8fbe\u3002", "conclusion": "\u7ef4\u5ea6\u8ba1\u6570\u65b9\u6cd5\u5728\u6700\u4f18\u5b50\u7a7a\u95f4\u586b\u5145\u548c\u7b49\u659c\u5b50\u7a7a\u95f4\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u80fd\u591f\u6709\u6548\u63a8\u5bfc\u5404\u79cd\u754c\u9650\u548c\u7cbe\u786e\u8ba1\u6570\u7ed3\u679c\u3002"}}
{"id": "2511.19872", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19872", "abs": "https://arxiv.org/abs/2511.19872", "authors": ["Daniel I Jackson", "Emma L Jensen", "Syed-Amad Hussain", "Emre Sezgin"], "title": "Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy", "comment": "25 pages,5 tables, 3 figures", "summary": "Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.", "AI": {"tldr": "LLMs\u5728\u81ea\u6211\u6548\u80fd\u611f\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u56de\u7b54\u6a21\u5f0f\uff0c\u4f46\u81ea\u6211\u8bc4\u4f30\u4e0e\u5b9e\u9645\u80fd\u529b\u4e0d\u5339\u914d\uff0c\u9ad8\u81ea\u4fe1\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u5dee\uff0c\u4f4e\u81ea\u4fe1\u6a21\u578b\u53cd\u800c\u51c6\u786e\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u56e0\u4e3a\u81ea\u6211\u8bc4\u4f30\u662f\u53ef\u9760\u667a\u80fd\u7684\u5173\u952e\u65b9\u9762\uff0c\u800c\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u752810\u9879\u4e00\u822c\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868(GSES)\u5728\u56db\u79cd\u6761\u4ef6\u4e0b\u6d4b\u8bd5\u5341\u4e2aLLM\uff1a\u65e0\u4efb\u52a1\u3001\u8ba1\u7b97\u63a8\u7406\u3001\u793e\u4f1a\u63a8\u7406\u548c\u6458\u8981\u4efb\u52a1\uff0c\u5e76\u5206\u6790\u56de\u7b54\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u81ea\u6211\u6548\u80fd\u6c34\u5e73\uff0c\u603b\u4f53\u5f97\u5206\u4f4e\u4e8e\u4eba\u7c7b\u6807\u51c6\u3002\u6240\u6709\u6a21\u578b\u5728\u8ba1\u7b97\u548c\u793e\u4f1a\u95ee\u9898\u4e0a\u90fd\u8fbe\u5230\u5b8c\u7f8e\u51c6\u786e\u7387\uff0c\u4f46\u6458\u8981\u8868\u73b0\u5dee\u5f02\u5f88\u5927\u3002\u81ea\u6211\u8bc4\u4f30\u4e0d\u80fd\u53ef\u9760\u53cd\u6620\u5b9e\u9645\u80fd\u529b\u3002", "conclusion": "\u5fc3\u7406\u6d4b\u91cf\u63d0\u793a\u63d0\u4f9b\u4e86\u5bf9LLM\u6c9f\u901a\u884c\u4e3a\u7684\u7ed3\u6784\u5316\u6d1e\u5bdf\uff0c\u4f46\u4e0d\u80fd\u63d0\u4f9b\u6821\u51c6\u7684\u6027\u80fd\u4f30\u8ba1\uff0c\u81ea\u6211\u8bc4\u4f30\u4e0e\u5b9e\u9645\u80fd\u529b\u5b58\u5728\u8131\u8282\u3002"}}
{"id": "2511.19895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19895", "abs": "https://arxiv.org/abs/2511.19895", "authors": ["Yuanyuan Lin", "Xiangyu Ouyang", "Teng Zhang", "Kaixin Sui"], "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation", "comment": "Accepted at AAAI 2026", "summary": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.", "AI": {"tldr": "RPM-MCTS\u662f\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6765\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u9700\u590d\u6742\u8bad\u7ec3\uff0c\u540c\u65f6\u5229\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u548c\u4fee\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u5728\u51cf\u5c1115%token\u6d88\u8017\u7684\u540c\u65f6\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u6cd5\u53ca\u65f6\u5b9a\u4f4d\u548c\u4fee\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u5bfc\u81f4\u751f\u6210\u9519\u8bef\u4ee3\u7801\u4e14\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u3002", "method": "\u63d0\u51faRPM-MCTS\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\uff1b2) \u5728\u6269\u5c55\u9636\u6bb5\u91c7\u7528\u76f8\u4f3c\u6027\u8fc7\u6ee4\u53bb\u9664\u5197\u4f59\u8282\u70b9\uff1b3) \u5229\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u9519\u8bef\u6b65\u9aa4\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u4fee\u6b63\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRPM-MCTS\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u7ea615%\u7684token\u6d88\u8017\u51cf\u5c11\u3002\u4f7f\u7528RPM-MCTS\u6784\u5efa\u7684\u6570\u636e\u5bf9\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5168\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u5347\u5176\u4ee3\u7801\u80fd\u529b\u3002", "conclusion": "RPM-MCTS\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u548c\u6c99\u7bb1\u53cd\u9988\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7801\u751f\u6210\u4e2d\u4e2d\u95f4\u6b65\u9aa4\u8bc4\u4f30\u548c\u9519\u8bef\u4fee\u6b63\u7684\u95ee\u9898\uff0c\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.19925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19925", "abs": "https://arxiv.org/abs/2511.19925", "authors": ["Qiyao Wei", "Edward Morrell", "Lea Goetz", "Mihaela van der Schaar"], "title": "Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity", "comment": null, "summary": "Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u8f93\u51fa\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u3001\u6210\u672c\u9ad8\u3001\u9886\u57df\u9002\u7528\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLM\u6587\u672c\u8f93\u51fa\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u53ef\u80fd\u66f4\u5173\u6ce8\u53e5\u6cd5\u800c\u975e\u8bed\u4e49\u5185\u5bb9\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u4f9d\u8d56\u4e3b\u89c2\u4eba\u5de5\u5224\u65ad\u3001\u751f\u6210\u6210\u672c\u9ad8\u3001\u9886\u57df\u9002\u7528\u6027\u6709\u9650\u3001\u7b49\u4ef7\u5b9a\u4e49\u4e0d\u660e\u786e\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u8bed\u4e49\u76f8\u4f3c\u6216\u4e0d\u76f8\u4f3c\u7684\u81ea\u7136\u8bed\u8a00\u9648\u8ff0\u5bf9\uff0c\u5176\u4e2d\u4e0d\u76f8\u4f3c\u5bf9\u5206\u4e3a\u56db\u79cd\u5b50\u7c7b\u578b\u3002\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4f20\u7edfNLP\u8bc4\u5206\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u3002", "result": "\u8bed\u4e49\u53d8\u5316\u7684\u5b50\u7c7b\u578b\u548c\u57fa\u51c6\u9886\u57df\u90fd\u4f1a\u5f71\u54cd\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u59cb\u7ec8\u8868\u73b0\u6700\u4f18\u3002LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5728\u68c0\u6d4b\u6587\u672c\u8bed\u4e49\u5185\u5bb9\u65b9\u9762\u5b58\u5728\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bc4\u4f30LLM\u8f93\u51fa\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u57fa\u51c6\u751f\u6210\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u548c\u5c40\u9650\u6027\uff0c\u7279\u522b\u662fLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u5e94\u7528\u6548\u679c\u3002"}}
{"id": "2511.19933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19933", "abs": "https://arxiv.org/abs/2511.19933", "authors": ["Vaishali Vinay"], "title": "A System-Level Taxonomy of Failure Modes in Large Language Model Applications", "comment": null, "summary": "Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u768415\u79cd\u9690\u85cf\u6545\u969c\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u4f9b\u4e86\u6784\u5efa\u53ef\u9760LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u5feb\u901f\u96c6\u6210\u5230\u51b3\u7b56\u652f\u6301\u5de5\u5177\u548c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4f46\u5176\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u4e14\u6545\u969c\u6a21\u5f0f\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6709\u6839\u672c\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u7ea7\u7684\u6545\u969c\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u8bc4\u4f30\u4e0e\u76d1\u63a7\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u8003\u5bdf\u90e8\u7f72\u6311\u6218\uff0c\u5e76\u5236\u5b9a\u8bbe\u8ba1\u539f\u5219\u3002", "result": "\u8bc6\u522b\u4e8615\u79cd\u9690\u85cf\u6545\u969c\u6a21\u5f0f\uff0c\u5305\u62ec\u591a\u6b65\u63a8\u7406\u6f02\u79fb\u3001\u6f5c\u5728\u4e0d\u4e00\u81f4\u6027\u3001\u4e0a\u4e0b\u6587\u8fb9\u754c\u9000\u5316\u7b49\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u53ef\u9760\u6027\u6846\u67b6\u5316\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u95ee\u9898\u800c\u975e\u7eaf\u6a21\u578b\u4e2d\u5fc3\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u8bc4\u4f30\u65b9\u6cd5\u3001AI\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u53ef\u9760LLM\u90e8\u7f72\u7814\u7a76\u63d0\u4f9b\u4e86\u5206\u6790\u57fa\u7840\u3002"}}
{"id": "2511.19969", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19969", "abs": "https://arxiv.org/abs/2511.19969", "authors": ["Weizi Shao", "Taolin Zhang", "Zijie Zhou", "Chen Chen", "Chengyu Wang", "Xiaofeng He"], "title": "M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation", "comment": null, "summary": "Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.", "AI": {"tldr": "\u63d0\u51fa\u4e86M^3Prune\u6846\u67b6\uff0c\u901a\u8fc7\u4fee\u526a\u591a\u6a21\u6001\u591a\u4ee3\u7406\u5c42\u6b21\u901a\u4fe1\u56fe\u4e2d\u7684\u5197\u4f59\u8fb9\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4etoken\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u867d\u7136\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u663e\u8457\u7684token\u5f00\u9500\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u5206\u5c42\u901a\u4fe1\u56fe\u4fee\u526a\u65b9\u6cd5\uff1a\u9996\u5148\u8fdb\u884c\u6a21\u6001\u5185\u56fe\u7a00\u758f\u5316\u8bc6\u522b\u5173\u952e\u8fb9\uff0c\u7136\u540e\u6784\u5efa\u52a8\u6001\u901a\u4fe1\u62d3\u6251\u8fdb\u884c\u6a21\u6001\u95f4\u56fe\u7a00\u758f\u5316\uff0c\u6700\u540e\u9010\u6b65\u4fee\u526a\u5197\u4f59\u8fb9\u3002", "result": "\u5728\u901a\u7528\u548c\u9886\u57df\u7279\u5b9a\u7684mRAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u5355\u4ee3\u7406\u548c\u9c81\u68d2\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u6d88\u8017\u3002", "conclusion": "M^3Prune\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4efb\u52a1\u6027\u80fd\u4e0etoken\u5f00\u9500\u4e4b\u95f4\u7684\u6700\u4f73\u5e73\u8861\u3002"}}
{"id": "2511.20048", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.20048", "abs": "https://arxiv.org/abs/2511.20048", "authors": ["Zixiao Huang", "Wen Zeng", "Tianyu Fu", "Tengxuan Liu", "Yizhou Sun", "Ke Hong", "Xinhao Yang", "Chengchun Liu", "Yan Li", "Quanlu Zhang", "Guohao Dai", "Zhenhua Zhu", "Yu Wang"], "title": "Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design", "comment": null, "summary": "LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.", "AI": {"tldr": "SPAgent\u901a\u8fc7\u63a8\u6d4b\u6267\u884c\u673a\u5236\u51cf\u5c11LLM\u641c\u7d22\u4ee3\u7406\u7684\u5ef6\u8fdf\uff0c\u91c7\u7528\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b01.65\u500d\u52a0\u901f", "motivation": "\u73b0\u6709LLM\u641c\u7d22\u4ee3\u7406\u5b58\u5728\u4e25\u91cd\u5ef6\u8fdf\u95ee\u9898\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6b65\u9aa4\u90fd\u9700\u8981\u4e32\u884c\u63a8\u7406\u548c\u5de5\u5177\u6267\u884c\u3002\u4f20\u7edf\u63a8\u6d4b\u6267\u884c\u8303\u5f0f\u867d\u7136\u80fd\u6253\u7834\u4e32\u884c\u6267\u884c\uff0c\u4f46\u6536\u76ca\u6709\u9650", "method": "\u63d0\u51faSPAgent\u6846\u67b6\uff1a\u7b97\u6cd5\u5c42\u9762\u5f15\u5165\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u63a8\u6d4b\u673a\u5236\uff0c\u5728\u5b89\u5168\u65f6\u9009\u62e9\u6027\u7701\u7565\u9a8c\u8bc1\uff1b\u7cfb\u7edf\u5c42\u9762\u4f7f\u7528\u4e24\u7ea7\u8c03\u5ea6\u5668\u6839\u636e\u5f15\u64ce\u8d1f\u8f7d\u8c03\u8282\u63a8\u6d4b\u8bf7\u6c42", "result": "\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0cSPAgent\u5b9e\u73b0\u4e86\u6700\u9ad81.65\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u751a\u81f3\u66f4\u9ad8\u7684\u51c6\u786e\u6027", "conclusion": "SPAgent\u80fd\u591f\u663e\u8457\u964d\u4f4e\u591a\u6b65\u9aa4\u641c\u7d22\u4ee3\u7406\u7684\u5ef6\u8fdf\uff0c\u4f7f\u5176\u5177\u5907\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027"}}
{"id": "2511.20067", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20067", "abs": "https://arxiv.org/abs/2511.20067", "authors": ["Marta Sumyk", "Oleksandr Kosovan"], "title": "\"Are We Done Yet?\": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents", "comment": "This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5c4f\u5e55\u622a\u56fe\u548c\u4efb\u52a1\u63cf\u8ff0\u76f4\u63a5\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u4efb\u52a1\u6210\u529f\u7387\u548c\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u81ea\u4e3b\u64cd\u4f5c\u6570\u5b57\u754c\u9762\u65f6\uff0c\u5f80\u5f80\u96be\u4ee5\u53ef\u9760\u5730\u5224\u65ad\u7ed9\u5b9a\u4efb\u52a1\u662f\u5426\u5df2\u5b8c\u6210\uff0c\u9700\u8981\u6709\u6548\u7684\u8bc4\u4f30\u548c\u53cd\u9988\u673a\u5236\u6765\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u5c4f\u5e55\u622a\u56fe\u548c\u4efb\u52a1\u63cf\u8ff0\u4e2d\u76f4\u63a5\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u6784\u5efa\u4e86\u5305\u542b42\u4e2amacOS\u5e94\u7528\u7a0b\u5e8f\u548c1,260\u4e2a\u4eba\u5de5\u6807\u6ce8\u4efb\u52a1\u7684\u6570\u636e\u96c6\u3002", "result": "\u6846\u67b6\u5728\u4efb\u52a1\u6210\u529f\u68c0\u6d4b\u4e2d\u8fbe\u523073%\u7684\u51c6\u786e\u7387\uff0c\u5f53\u5e94\u7528\u8bc4\u4f30\u5668\u53cd\u9988\u65f6\uff0c\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u5e73\u5747\u76f8\u5bf9\u63d0\u9ad8\u4e8627%\u3002", "conclusion": "\u57fa\u4e8e\u89c6\u89c9\u7684\u8bc4\u4f30\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u53cd\u9988\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u81ea\u4e3b\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u3002"}}
{"id": "2511.20085", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20085", "abs": "https://arxiv.org/abs/2511.20085", "authors": ["Chujie Wang", "Zhiyuan Luo", "Ruiqi Liu", "Can Ran", "Shenghua Fan", "Xi Chen", "Chu He"], "title": "VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis", "comment": null, "summary": "The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86VICoT\u591a\u6a21\u6001\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u89c6\u89c9\u5de5\u5177\u5230\u601d\u7ef4\u94fe\u4e2d\u5b9e\u73b0\u663e\u5f0f\u591a\u8f6e\u63a8\u7406\uff0c\u5728\u9065\u611f\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u6846\u67b6\u3002", "motivation": "\u9065\u611f\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u6b63\u4ece\u4f20\u7edf\u76ee\u6807\u8bc6\u522b\u5411\u590d\u6742\u667a\u80fd\u63a8\u7406\u6f14\u8fdb\uff0c\u5bf9\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548c\u5de5\u5177\u8c03\u7528\u7075\u6d3b\u6027\u63d0\u51fa\u66f4\u9ad8\u8981\u6c42\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5806\u6808\u7684\u63a8\u7406\u7ed3\u6784\u548c\u6a21\u5757\u5316MCP\u517c\u5bb9\u5de5\u5177\u5957\u4ef6\uff0c\u5b9e\u73b0\u591a\u8f6e\u4ea4\u9519\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\uff1b\u63d0\u51fa\u63a8\u7406\u5806\u6808\u84b8\u998f\u65b9\u6cd5\u5c06\u590d\u6742\u4ee3\u7406\u884c\u4e3a\u8fc1\u79fb\u5230\u8f7b\u91cf\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u9065\u611f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVICoT\u5728\u63a8\u7406\u900f\u660e\u5ea6\u3001\u6267\u884c\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u6846\u67b6\u3002", "conclusion": "VICoT\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u591a\u8f6e\u63a8\u7406\u548c\u5de5\u5177\u52a8\u6001\u6574\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u9065\u611f\u56fe\u50cf\u5206\u6790\u7684\u63a8\u7406\u80fd\u529b\u548c\u7075\u6d3b\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8f7b\u91cf\u5316\u90e8\u7f72\u3002"}}
{"id": "2511.20138", "categories": ["cs.AI", "cs.DM", "cs.LG", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.20138", "abs": "https://arxiv.org/abs/2511.20138", "authors": ["Jason Lo", "Mohammadnima Jafari"], "title": "From data to concepts via wiring diagrams", "comment": "19 pages", "summary": "A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u51c6\u9aa8\u67b6\u5e03\u7ebf\u56fe\u7684\u6982\u5ff5\uff0c\u8bc1\u660e\u4e86\u5176\u4e0eHasse\u56fe\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u5e03\u7ebf\u56fe\u7684\u7b97\u6cd5\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u81ea\u4e3b\u4ee3\u7406\u5728\u7535\u8111\u6e38\u620f\u4e2d\u7684\u884c\u4e3a\u5206\u6790\u3002", "motivation": "\u5e03\u7ebf\u56fe\u662f\u8868\u793a\u62bd\u8c61\u6982\u5ff5\uff08\u5982\u65f6\u5e8f\u8fc7\u7a0b\uff09\u7684\u6807\u8bb0\u6709\u5411\u56fe\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u81ea\u52a8\u63d0\u53d6\u5e03\u7ebf\u56fe\u7684\u7b97\u6cd5\uff0c\u4ee5\u5206\u6790\u590d\u6742\u7cfb\u7edf\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u51c6\u9aa8\u67b6\u5e03\u7ebf\u56fe\u6982\u5ff5\uff0c\u8bc1\u660e\u5176\u4e0eHasse\u56fe\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u6b64\u7684\u5e03\u7ebf\u56fe\u63d0\u53d6\u7b97\u6cd5\uff0c\u5e76\u4e0eDBSCAN\u548c\u51dd\u805a\u5c42\u6b21\u805a\u7c7b\u7b49\u6807\u51c6\u805a\u7c7b\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7b97\u6cd5\u6210\u529f\u8bc6\u522b\u4e86\u81ea\u4e3b\u4ee3\u7406\u5728\u7535\u8111\u6e38\u620f\u4e2d\u7684\u83b7\u80dc\u7b56\u7565\uff0c\u5728\u6570\u636e\u6270\u52a8\u60c5\u51b5\u4e0b\u4ecd\u8868\u73b0\u826f\u597d\uff0c\u4f18\u4e8e\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u8303\u7574\u8bba\u3001\u56fe\u8bba\u3001\u805a\u7c7b\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u636e\u5de5\u7a0b\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u4e3a\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u8868\u793a\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.20196", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20196", "abs": "https://arxiv.org/abs/2511.20196", "authors": ["Zhen Zeng", "Leijiang Gu", "Zhangling Duan", "Feng Li", "Zenglin Shi", "Cees G. M. Snoek", "Meng Wang"], "title": "Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.", "AI": {"tldr": "\u63d0\u51fa\u4e86SMFA\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bb0\u5fc6\u9057\u5fd8\u9002\u914d\u5668\u548c\u4fdd\u7559\u951a\u70b9\u5f15\u5bfc\u7684\u63a9\u7801\u673a\u5236\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9690\u79c1\u654f\u611f\u4fe1\u606f\u7684\u7cbe\u786e\u53ef\u63a7\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u901a\u7528\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u4f1a\u65e0\u610f\u4e2d\u8bb0\u5fc6\u9690\u79c1\u654f\u611f\u4fe1\u606f\uff0c\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u5728\u79fb\u9664\u8fd9\u4e9b\u77e5\u8bc6\u65f6\u5f80\u5f80\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u901a\u7528\u56fe\u50cf\u7406\u89e3\u6027\u80fd\u3002", "method": "SMFA\u9996\u5148\u5fae\u8c03\u6a21\u578b\u5c06\u654f\u611f\u54cd\u5e94\u66ff\u6362\u4e3a\u62d2\u7edd\u56de\u7b54\uff0c\u751f\u6210\u8bb0\u5fc6\u9057\u5fd8\u9002\u914d\u5668\uff0c\u7136\u540e\u5e94\u7528\u4fdd\u7559\u951a\u70b9\u5f15\u5bfc\u7684\u63a9\u7801\u673a\u5236\u6765\u9632\u6b62\u5bf9\u65e0\u5173\u77e5\u8bc6\u548c\u7406\u89e3\u80fd\u529b\u7684\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0cSMFA\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u53ef\u63a7\u7684\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u57fa\u7840\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "SMFA\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u654f\u611f\u4fe1\u606f\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u79fb\u9664\u654f\u611f\u77e5\u8bc6\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u901a\u7528\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2511.20200", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20200", "abs": "https://arxiv.org/abs/2511.20200", "authors": ["Yitian Huang", "Yuxuan Lei", "Jianxun Lian", "Hao Liao"], "title": "Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025", "comment": null, "summary": "This report presents the solution and results of our team MSRA\\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution", "AI": {"tldr": "\u56e2\u961fMSRA_SC\u5728CPDC 2025\u6311\u6218\u8d5b\u4e2d\u63d0\u51fa\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5de5\u7a0b\u548cGRPO\u8bad\u7ec3\u5728\u4e24\u4e2a\u8d5b\u9053\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u89e3\u51b3\u5de5\u5177\u8c03\u7528\u7a33\u5b9a\u6027\u3001\u6267\u884c\u53ef\u9760\u6027\u548c\u89d2\u8272\u626e\u6f14\u6307\u5bfc\u7684\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u5c0f\u6837\u672c\u8fc7\u62df\u5408\uff0c\u63d0\u5347\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u6027\u80fd\u3002", "method": "1. \u4e0a\u4e0b\u6587\u5de5\u7a0b\uff1a\u52a8\u6001\u5de5\u5177\u526a\u679d\u548c\u89d2\u8272\u88c1\u526a\u8fdb\u884c\u8f93\u5165\u538b\u7f29\uff0c\u7ed3\u5408\u53c2\u6570\u5f52\u4e00\u5316\u548c\u51fd\u6570\u5408\u5e76\u7b49\u540e\u5904\u7406\u6280\u672f\uff1b2. GPU\u8d5b\u9053\u91c7\u7528GRPO\u8bad\u7ec3\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u6700\u7ec8\u8bc4\u4f30\u4e2d\uff1aTask 2 API\u7b2c1\u540d\uff0cTask 1 API\u7b2c2\u540d\uff0cTask 3 API\u548cGPU\u8d5b\u9053\u5747\u7b2c3\u540d\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5355\u800c\u6709\u6548\u7684\u6846\u67b6\u5728\u4e24\u4e2a\u8d5b\u9053\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20216", "categories": ["cs.AI", "cs.CE", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20216", "abs": "https://arxiv.org/abs/2511.20216", "authors": ["Haebin Seong", "Sungmin Kim", "Minchan Kim", "Yongjun Cho", "Myunchul Joe", "Suhwan Choi", "Jaeyoon Jung", "Jiyong Youn", "Yoonshik Kim", "Samwoo Seong", "Yubeen Park", "Youngjae Yu", "Yunsung Lee"], "title": "CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents", "comment": null, "summary": "Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.", "AI": {"tldr": "CostNav\u662f\u9996\u4e2a\u5fae\u5bfc\u822a\u7ecf\u6d4e\u6d4b\u8bd5\u5e73\u53f0\uff0c\u901a\u8fc7\u6210\u672c\u6536\u76ca\u5206\u6790\u8bc4\u4f30\u81ea\u4e3b\u9001\u8d27\u673a\u5668\u4eba\u7684\u5546\u4e1a\u53ef\u884c\u6027\uff0c\u63ed\u793a\u4e86\u5bfc\u822a\u7814\u7a76\u6307\u6807\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u57fa\u51c6\u53ea\u5173\u6ce8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5ffd\u7565\u4e86\u5546\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u7ecf\u6d4e\u53ef\u884c\u6027\u3002\u4e3a\u4e86\u586b\u8865\u5bfc\u822a\u7814\u7a76\u4e0e\u5b9e\u9645\u5546\u4e1a\u5e94\u7528\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u9700\u8981\u8bc4\u4f30\u5b8c\u6574\u7684\u7ecf\u6d4e\u751f\u547d\u5468\u671f\u3002", "method": "CostNav\u5efa\u6a21\u5b8c\u6574\u7684\u7ecf\u6d4e\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u786c\u4ef6\u3001\u8bad\u7ec3\u3001\u80fd\u6e90\u3001\u7ef4\u62a4\u6210\u672c\u548c\u914d\u9001\u6536\u5165\uff0c\u4f7f\u7528\u884c\u4e1a\u53c2\u6570\uff0c\u5e76\u5c06\u7f29\u5c0f\u89c4\u6a21\u7684\u6a21\u62df\u6295\u5f71\u5230\u5b9e\u9645\u914d\u9001\u573a\u666f\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a43.0%\u7684\u670d\u52a1\u6c34\u5e73\u534f\u8bae\u5408\u89c4\u7387\uff0c\u4f46\u5546\u4e1a\u4e0a\u4e0d\u53ef\u884c\uff1a\u6bcf\u6b21\u8fd0\u884c\u4e8f\u635f30.009\u7f8e\u5143\uff0c\u65e0\u76c8\u4e8f\u5e73\u8861\u70b9\uff0c99.7%\u7684\u8fd0\u884c\u6210\u672c\u6765\u81ea\u78b0\u649e\u5bfc\u81f4\u7684\u7ef4\u62a4\u8d39\u7528\u3002", "conclusion": "CostNav\u586b\u8865\u4e86\u5bfc\u822a\u7814\u7a76\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u8bc4\u4f30\u57fa\u4e8e\u89c4\u5219\u7684\u5bfc\u822a\u3001\u6a21\u4eff\u5b66\u4e60\u548c\u6210\u672c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u652f\u6301\u8de8\u5bfc\u822a\u8303\u5f0f\u7684\u7ecf\u6d4e\u6743\u8861\u51b3\u7b56\u3002"}}
{"id": "2511.20236", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20236", "abs": "https://arxiv.org/abs/2511.20236", "authors": ["Szymon Bobek", "\u0141ukasz Ba\u0142ec", "Grzegorz J. Nalepa"], "title": "Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints", "comment": null, "summary": "Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.", "AI": {"tldr": "\u63d0\u51faDANCE\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u548c\u56e0\u679c\u7ea6\u675f\u6765\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u64cd\u4f5c\u4e14\u7b26\u5408\u77e5\u8bc6\u7ea6\u675f\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u73b0\u5b9e\u6570\u636e\u96c6\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u4ea7\u751f\u4e0d\u73b0\u5b9e\u6216\u4e0d\u5b9e\u7528\u7684\u4fee\u6539\u3002\u53d7\u7f51\u7edc\u5b89\u5168\u5728\u7535\u5b50\u90ae\u4ef6\u8425\u9500\u9886\u57df\u5e94\u7528\u7684\u542f\u53d1\uff0c\u9700\u8981\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "method": "\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7ea6\u675f\uff0c\u6216\u6574\u5408\u4e13\u5bb6\u63d0\u4f9b\u7684\u4f9d\u8d56\u56fe\uff0c\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u3002\u901a\u8fc7\u4fdd\u6301\u7279\u5f81\u5173\u7cfb\u7684\u4e00\u81f4\u6027\uff0c\u751f\u6210\u7b26\u5408\u73b0\u5b9e\u7ea6\u675f\u7684\u89e3\u91ca\u3002\u540c\u65f6\u5e73\u8861\u5408\u7406\u6027\u3001\u591a\u6837\u6027\u548c\u7a00\u758f\u6027\u3002", "result": "\u5728140\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u6709\u610f\u4e49\u3001\u9886\u57df\u76f8\u5173\u7684\u53cd\u4e8b\u5b9e\uff0c\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DANCE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u5728\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u5904\u7406\u65b9\u9762\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u80fd\u591f\u751f\u6210\u65e2\u5408\u7406\u53c8\u5b9e\u7528\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002"}}
{"id": "2511.20285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20285", "abs": "https://arxiv.org/abs/2511.20285", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho"], "title": "SMoG: Schema Matching on Graph", "comment": null, "summary": "Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.", "AI": {"tldr": "SMoG\u662f\u4e00\u4e2a\u7528\u4e8e\u533b\u7597\u9886\u57df\u6a21\u5f0f\u5339\u914d\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u6267\u884c\u7b80\u5355\u76841\u8df3SPARQL\u67e5\u8be2\uff0c\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3aLLM\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u591a\u8df3\u67e5\u8be2\u590d\u6742\u6027\u548c\u5b58\u50a8\u5bc6\u96c6\u95ee\u9898\u3002", "motivation": "\u533b\u7597\u9886\u57df\u4e2d\u4e0d\u540c\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\u9700\u8981\u4e0e\u6807\u51c6\u6a21\u578b\uff08\u5982OMOP CDM\uff09\u5bf9\u9f50\uff0c\u4f46\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u7f3a\u4e4f\u6700\u65b0\u9886\u57df\u77e5\u8bc6\uff0c\u800c\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u53c8\u5b58\u5728\u67e5\u8be2\u590d\u6742\u548c\u5b58\u50a8\u5bc6\u96c6\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSMoG\u6846\u67b6\uff0c\u91c7\u7528\u8fed\u4ee3\u6267\u884c\u7b80\u53551\u8df3SPARQL\u67e5\u8be2\u7684\u7b56\u7565\uff0c\u76f4\u63a5\u4eceSPARQL\u7aef\u70b9\u67e5\u8be2\uff0c\u65e0\u9700\u5411\u91cf\u68c0\u7d22\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "\u5728\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSMoG\u8fbe\u5230\u4e86\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u6a21\u5f0f\u5339\u914d\u4e2d\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "SMoG\u901a\u8fc7\u7b80\u5355\u9ad8\u6548\u76841\u8df3SPARQL\u67e5\u8be2\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u6a21\u5f0f\u5339\u914d\u4e2d\u7684\u590d\u6742\u6027\u548c\u5b58\u50a8\u95ee\u9898\uff0c\u4e3a\u533b\u7597\u6570\u636e\u96c6\u6210\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20297", "abs": "https://arxiv.org/abs/2511.20297", "authors": ["Shashank Kirtania", "Param Biyani", "Priyanshu Gupta", "Yasharth Bajpai", "Roshni Iyer", "Sumit Gulwani", "Gustavo Soares"], "title": "Improving Language Agents through BREW", "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $\u03c4^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.", "AI": {"tldr": "BREW\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u548c\u7cbe\u5316\u7ecf\u9a8c\u5b66\u4e60\u77e5\u8bc6\u5e93\u6765\u4f18\u5316LLM\u667a\u80fd\u4f53\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4efb\u52a1\u7cbe\u5ea6\u5e76\u51cf\u5c11API\u8c03\u7528\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8ePPO\u548cGRPO\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u4e14\u751f\u6210\u7684\u7b56\u7565\u96be\u4ee5\u89e3\u91ca\u3001\u9002\u5e94\u6216\u589e\u91cf\u6539\u8fdb\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u7684\u4f18\u5316\u65b9\u6848\u3002", "method": "\u5f15\u5165BREW\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u6784\u5efa\u548c\u7cbe\u5316\u6765\u4f18\u5316\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u4efb\u52a1\u5206\u7ea7\u5668\u548c\u884c\u4e3a\u51c6\u5219\u5b66\u4e60\u6d1e\u5bdf\uff0c\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u786e\u4fdd\u9c81\u68d2\u6027\uff0c\u5e76\u6709\u6548\u5206\u533a\u667a\u80fd\u4f53\u8bb0\u5fc6\u4ee5\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\u3002", "result": "\u5728OSWorld\u3001\u03c4\u00b2Bench\u548cSpreadsheetBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBREW\u5b9e\u73b0\u4e8610-20%\u7684\u4efb\u52a1\u7cbe\u5ea6\u63d0\u5347\uff0c10-15%\u7684API/\u5de5\u5177\u8c03\u7528\u51cf\u5c11\uff0c\u6267\u884c\u65f6\u95f4\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u5c06\u77e5\u8bc6\u5e93\u786e\u7acb\u4e3a\u6a21\u5757\u5316\u3001\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u4f18\u5316\u57fa\u5e95\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u884c\u4e3a\u5851\u9020\u673a\u5236\uff0c\u4e0e\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u9759\u6001\u4e0a\u4e0b\u6587\u7684\u5148\u524d\u5de5\u4f5c\u5f62\u6210\u5bf9\u6bd4\u3002"}}
{"id": "2511.20312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20312", "abs": "https://arxiv.org/abs/2511.20312", "authors": ["Alexander Beiser", "Flavio Martinelli", "Wulfram Gerstner", "Johanni Brea"], "title": "Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries", "comment": "Proceedings of the III edition of the Workshop on Unifying Representations in Neural Models (UniReps 2025)", "summary": "Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u6765\u6539\u8fdb\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u7684\u53cd\u5411\u5de5\u7a0b\uff0c\u80fd\u591f\u6062\u590d\u53c2\u6570\u6570\u91cf\u662f\u8bad\u7ec3\u6570\u636e100\u500d\u7684\u7f51\u7edc", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u6570\u91cf\u8d85\u8fc7\u8bad\u7ec3\u6570\u636e\u65f6\u5931\u6548\uff0c\u56e0\u4e3a\u5b66\u751f\u4f1a\u8fc7\u5ea6\u62df\u5408\u67e5\u8be2\u6570\u636e\u800c\u4e0d\u662f\u5bf9\u9f50\u6559\u5e08\u53c2\u6570", "method": "\u8bbe\u8ba1\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u9690\u85cf\u5c42\u8868\u793a\u7a7a\u95f4\u91c7\u6837\u7684\u65b0\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u800c\u975e\u4f7f\u7528\u6807\u51c6\u7684\u65cb\u8f6c\u3001\u7ffb\u8f6c\u7b49\u589e\u5f3a\u65b9\u6cd5", "result": "\u6269\u5c55\u4e86\u53ef\u6062\u590d\u7f51\u7edc\u5927\u5c0f\u7684\u6700\u5148\u8fdb\u8303\u56f4\uff0c\u80fd\u591f\u6062\u590d\u53c2\u6570\u6570\u91cf\u662f\u8bad\u7ec3\u6570\u636e100\u500d\u7684\u7f51\u7edc", "conclusion": "\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u9690\u85cf\u5c42\u8868\u793a\u7a7a\u95f4\u8bbe\u8ba1\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u80fd\u663e\u8457\u6539\u8fdb\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u7684\u53cd\u5411\u5de5\u7a0b\u6548\u679c"}}
{"id": "2511.20321", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20321", "abs": "https://arxiv.org/abs/2511.20321", "authors": ["Patrick Kenny"], "title": "Active Inference in Discrete State Spaces from First Principles", "comment": "56 pages", "summary": "We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.", "AI": {"tldr": "\u672c\u6587\u6f84\u6e05\u4e86\u4e3b\u52a8\u63a8\u7406\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e3b\u52a8\u63a8\u7406\u7684\u4f18\u5316\u95ee\u9898\u53ef\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\u3002", "motivation": "\u6f84\u6e05\u4e3b\u52a8\u63a8\u7406\u6982\u5ff5\uff0c\u5c06\u5176\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u5206\u79bb\uff0c\u5c55\u793a\u4e3b\u52a8\u63a8\u7406\u53ef\u901a\u8fc7\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u5b9e\u73b0\uff0c\u800c\u4e0d\u5fc5\u8bc9\u8bf8\u671f\u671b\u81ea\u7531\u80fd\u3002", "method": "\u5c06\u4e3b\u52a8\u63a8\u7406\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u6c42\u89e3\u3002\u611f\u77e5\u5efa\u6a21\u65f6\u4f7f\u7528\u53d8\u5206\u81ea\u7531\u80fd\uff0c\u884c\u52a8\u5efa\u6a21\u65f6\u4f7f\u7528\u5e26\u6709\u71b5\u6b63\u5219\u5316\u7684\u4e0d\u540c\u6cdb\u51fd\u3002", "result": "\u8bc1\u660e\u4e86\u4e3b\u52a8\u63a8\u7406\u53ef\u901a\u8fc7\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u5b9e\u73b0\uff0c\u611f\u77e5\u5efa\u6a21\u4e0e\u53d8\u5206\u81ea\u7531\u80fd\u4e00\u81f4\uff0c\u884c\u52a8\u5efa\u6a21\u4e0e\u671f\u671b\u81ea\u7531\u80fd\u6cdb\u51fd\u76f8\u5dee\u4e00\u4e2a\u71b5\u6b63\u5219\u5316\u9879\u3002", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u53ef\u4ee5\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u5206\u79bb\uff0c\u901a\u8fc7\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u6846\u67b6\u5b9e\u73b0\uff0c\u4e3a\u7406\u89e3\u4e3b\u52a8\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.20333", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.20333", "abs": "https://arxiv.org/abs/2511.20333", "authors": ["Roman Kochnev", "Waleed Khalid", "Tolgay Atinc Uzun", "Xi Zhang", "Yashkumar Sanjaybhai Dhameliya", "Furui Qin", "Chandini Vysyaraju", "Raghuvir Duvvuri", "Avi Goyal", "Dmitry Ignatov", "Radu Timofte"], "title": "NNGPT: Rethinking AutoML with Large Language Models", "comment": null, "summary": "Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.", "AI": {"tldr": "NNGPT\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u81ea\u6539\u8fdb\u7684AutoML\u5f15\u64ce\uff0c\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u5f00\u53d1\u3002\u5b83\u901a\u8fc7\u751f\u6210\u65b0\u6a21\u578b\u6269\u5c55\u795e\u7ecf\u7f51\u7edc\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u57fa\u4e8e\u751f\u6210-\u8bc4\u4f30-\u81ea\u6539\u8fdb\u95ed\u73af\u7cfb\u7edf\u7684\u6301\u7eed\u5fae\u8c03\u3002", "motivation": "\u6784\u5efa\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u662fAI\u9886\u57df\u7684\u6839\u672c\u6311\u6218\u3002\u4f20\u7edf\u6846\u67b6\u65e0\u6cd5\u5b9e\u73b0\u6301\u7eed\u7684\u81ea\u6539\u8fdb\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u3001\u8bc4\u4f30\u548c\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u7cfb\u7edf\u3002", "method": "\u96c6\u6210\u4e94\u4e2a\u534f\u540c\u7684LLM\u7ba1\u9053\uff1a\u96f6\u6837\u672c\u67b6\u6784\u5408\u6210\u3001\u8d85\u53c2\u6570\u4f18\u5316\u3001\u4ee3\u7801\u611f\u77e5\u7cbe\u5ea6\u9884\u6d4b\u3001\u68c0\u7d22\u589e\u5f3a\u7684PyTorch\u5757\u5408\u6210\u3001\u5f3a\u5316\u5b66\u4e60\u3002\u57fa\u4e8eLEMUR\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5355\u4e00\u63d0\u793a\u751f\u6210\u5e76\u9a8c\u8bc1\u7f51\u7edc\u67b6\u6784\u3001\u9884\u5904\u7406\u4ee3\u7801\u548c\u8d85\u53c2\u6570\uff0c\u7aef\u5230\u7aef\u6267\u884c\u5e76\u5b66\u4e60\u7ed3\u679c\u3002", "result": "NN-RAG\u57281,289\u4e2a\u76ee\u6807\u4e0a\u8fbe\u523073%\u53ef\u6267\u884c\u6027\uff1b3-shot\u63d0\u793a\u63d0\u5347\u5e38\u89c1\u6570\u636e\u96c6\u7cbe\u5ea6\uff1b\u54c8\u5e0c\u53bb\u91cd\u8282\u7701\u6570\u767e\u6b21\u8fd0\u884c\uff1b\u5355\u6b21\u9884\u6d4b\u5339\u914d\u57fa\u4e8e\u641c\u7d22\u7684AutoML\uff1bHPO\u5728LEMUR\u4e0aRMSE 0.60\u4f18\u4e8eOptuna\uff1b\u4ee3\u7801\u611f\u77e5\u9884\u6d4b\u5668RMSE 0.14\uff0cPearson r=0.78\uff1b\u5df2\u751f\u6210\u8d85\u8fc75K\u9a8c\u8bc1\u6a21\u578b\u3002", "conclusion": "NNGPT\u88ab\u8bc1\u660e\u662f\u4e00\u4e2a\u81ea\u4e3b\u7684AutoML\u5f15\u64ce\uff0c\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u52a8\u5316\u5f00\u53d1\u548c\u81ea\u6539\u8fdb\u3002\u4ee3\u7801\u3001\u63d0\u793a\u548c\u68c0\u67e5\u70b9\u5c06\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u548c\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2511.20422", "categories": ["cs.AI", "cs.CV", "cs.GR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20422", "abs": "https://arxiv.org/abs/2511.20422", "authors": ["Bo Pang", "Chenxi Xu", "Jierui Ren", "Guoping Wang", "Sheng Li"], "title": "VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning", "comment": null, "summary": "Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.", "AI": {"tldr": "VibraVerse\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u51e0\u4f55-\u58f0\u5b66\u5bf9\u9f50\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u660e\u786e\u7684\u56e0\u679c\u94fe\uff083D\u51e0\u4f55\u2192\u7269\u7406\u5c5e\u6027\u2192\u6a21\u6001\u53c2\u6570\u2192\u58f0\u5b66\u4fe1\u53f7\uff09\u8fde\u63a5\u7269\u7406\u4e16\u754c\u7684\u611f\u77e5\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86CLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u6765\u5b9e\u73b0\u8de8\u6a21\u6001\u7684\u7269\u7406\u4e00\u81f4\u6027\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\u7f3a\u4e4f\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5ffd\u89c6\u4e86\u7269\u4f53\u51e0\u4f55\u3001\u6750\u6599\u3001\u632f\u52a8\u6a21\u5f0f\u548c\u4ea7\u751f\u58f0\u97f3\u4e4b\u95f4\u7684\u5185\u5728\u56e0\u679c\u5173\u7cfb\u3002\u9700\u8981\u5efa\u7acb\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b\u800c\u975e\u7edf\u8ba1\u76f8\u5173\u6027\u7684\u611f\u77e5\u6a21\u578b\u3002", "method": "\u6784\u5efaVibraVerse\u6570\u636e\u96c6\uff0c\u5305\u542b3D\u6a21\u578b\u7684\u7269\u7406\u5c5e\u6027\uff08\u5bc6\u5ea6\u3001\u6768\u6c0f\u6a21\u91cf\u3001\u6cca\u677e\u6bd4\uff09\u548c\u4f53\u79ef\u51e0\u4f55\uff0c\u8ba1\u7b97\u6a21\u6001\u7279\u5f81\u9891\u7387\u548c\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u51b2\u51fb\u58f0\u5408\u6210\uff1b\u63d0\u51faCLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u8de8\u6a21\u6001\u5bf9\u9f50\u3002", "result": "\u5728\u51e0\u4f55\u5230\u58f0\u97f3\u9884\u6d4b\u3001\u58f0\u97f3\u5f15\u5bfc\u5f62\u72b6\u91cd\u5efa\u548c\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u7b49\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0c\u57fa\u4e8eVibraVerse\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "VibraVerse\u4e3a\u7269\u7406\u4e00\u81f4\u6027\u548c\u56e0\u679c\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u7acb\u4e86\u57fa\u51c6\uff0c\u4e3a\u58f0\u97f3\u5f15\u5bfc\u7684\u5177\u8eab\u611f\u77e5\u548c\u7269\u7406\u4e16\u754c\u6df1\u5ea6\u7406\u89e3\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.20468", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20468", "abs": "https://arxiv.org/abs/2511.20468", "authors": ["Yuanhao Li", "Mingshan Liu", "Hongbo Wang", "Yiding Zhang", "Yifei Ma", "Wei Tan"], "title": "DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs", "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed", "AI": {"tldr": "DRAFT-RL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u94fe\u5f0f\u8349\u7a3f\u63a8\u7406\uff0c\u8ba9\u6bcf\u4e2a\u667a\u80fd\u4f53\u751f\u6210\u591a\u4e2a\u63a8\u7406\u8349\u7a3f\uff0c\u901a\u8fc7\u540c\u884c\u8bc4\u4f30\u548c\u5956\u52b1\u6a21\u578b\u9009\u62e9\u6700\u4f18\u8def\u5f84\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u53cd\u601d\u7684LLM\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u5355\u6b21\u54cd\u5e94\uff0c\u7f3a\u4e4f\u63a8\u7406\u63a2\u7d22\u7684\u7ed3\u6784\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7684\u7a33\u5065\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faDRAFT-RL\u6846\u67b6\uff0c\u5c06\u94fe\u5f0f\u8349\u7a3f\u63a8\u7406\u96c6\u6210\u5230\u591a\u667a\u80fd\u4f53RL\u8bad\u7ec3\u4e2d\uff1a\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u751f\u6210\u591a\u4e2a\u8349\u7a3f\uff0c\u901a\u8fc7\u540c\u884c\u667a\u80fd\u4f53\u548c\u5b66\u4e60\u7684\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\uff0c\u9009\u62e9\u6700\u6709\u5e0c\u671b\u7684\u8f68\u8ff9\uff0c\u5e76\u901a\u8fc7actor-critic\u5b66\u4e60\u4f18\u5316\u672a\u6765\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5728\u4ee3\u7801\u5408\u6210\u3001\u7b26\u53f7\u6570\u5b66\u548c\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u7b54\u7b49\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cDRAFT-RL\u5728\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u53cd\u601d\u548c\u57fa\u4e8eRL\u7684\u667a\u80fd\u4f53\u3002", "conclusion": "DRAFT-RL\u901a\u8fc7\u663e\u5f0f\u7684\u591a\u8def\u5f84\u63a2\u7d22\u3001\u540c\u884c\u5f15\u5bfc\u7684\u53cd\u601d\u548c\u5956\u52b1\u5bf9\u9f50\u7684\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5065\u548c\u53ef\u89e3\u91ca\u7684LLM\u667a\u80fd\u4f53\u884c\u4e3a\u3002"}}
{"id": "2511.20471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20471", "abs": "https://arxiv.org/abs/2511.20471", "authors": ["Yuto Suzuki", "Farnoush Banaei-Kashani"], "title": "Universe of Thoughts: Enabling Creative Reasoning with Large Language Models", "comment": null, "summary": "Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \\textit{combinational}, \\textit{exploratory}, and \\textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \\textit{Universe of Thoughts} (or \\textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u521b\u9020\u6027\u63a8\u7406\u6846\u67b6\uff0c\u5305\u542b\u7ec4\u5408\u3001\u63a2\u7d22\u548c\u8f6c\u5316\u4e09\u79cd\u63a8\u7406\u8303\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86UoT\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e9b\u521b\u9020\u6027\u8fc7\u7a0b\uff0c\u5728\u9700\u8981\u521b\u65b0\u95ee\u9898\u89e3\u51b3\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5e38\u89c4\u95ee\u9898\u89e3\u51b3\uff0c\u7f3a\u4e4f\u521b\u9020\u6027\u63a8\u7406\u80fd\u529b\u3002\u5728\u836f\u7269\u53d1\u73b0\u3001\u5546\u4e1a\u7b56\u7565\u7b49\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u5e7f\u9614\u4e14\u5e38\u89c4\u65b9\u6848\u6b21\u4f18\u7684\u9886\u57df\uff0c\u53d1\u73b0\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u7684\u521b\u9020\u6027\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u539f\u7406\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5305\u542b\u7ec4\u5408\u3001\u63a2\u7d22\u548c\u8f6c\u5316\u4e09\u79cd\u521b\u9020\u6027\u63a8\u7406\u8303\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86Universe of Thoughts (UoT)\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e9b\u521b\u9020\u6027\u8fc7\u7a0b\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6280\u672f\u548c\u4ee3\u8868\u6027\u5546\u4e1a\u6a21\u578b\u76f8\u6bd4\uff0cUoT\u5728\u521b\u9020\u6027\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u521b\u65b0\u95ee\u9898\u89e3\u51b3\u7684\u4efb\u52a1\u4e2d\u3002", "conclusion": "UoT\u6846\u67b6\u4e3aLLMs\u63d0\u4f9b\u4e86\u7cfb\u7edf\u63a2\u7d22\u601d\u7ef4\u5b87\u5b99\u4ee5\u751f\u6210\u521b\u9020\u6027\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u6709\u63a8\u7406\u6a21\u578b\u5728\u521b\u9020\u6027\u63a8\u7406\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2511.20497", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20497", "abs": "https://arxiv.org/abs/2511.20497", "authors": ["Van Tran", "Shinan Liu", "Tian Li", "Nick Feamster"], "title": "Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic", "comment": "14 pages, 13 Figures, 6 Tables", "summary": "To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u7684\u9690\u79c1\u5ea6\u91cf\u65b9\u6cd5\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u751f\u6210\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\uff0c\u53d1\u73b0MIA\u653b\u51fb\u6210\u529f\u7387\u53ef\u8fbe88%\uff0c\u7f51\u7edc\u6807\u8bc6\u7b26\u6062\u590d\u7387\u53ef\u8fbe100%\uff0c\u5e76\u8bc6\u522b\u4e86\u5f71\u54cd\u653b\u51fb\u6210\u529f\u7387\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u89e3\u51b3\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u7684\u7a00\u7f3a\u6027\u548c\u9690\u79c1\u62c5\u5fe7\uff0c\u4f46\u73b0\u6709\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u5bf9\u9690\u79c1\u6cc4\u9732\u7a0b\u5ea6\u7684\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u5957\u5168\u9762\u7684\u9690\u79c1\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7ed3\u5408\u6807\u51c6\u65b9\u6cd5\uff08\u5982\u6210\u5458\u63a8\u7406\u653b\u51fbMIA\u548c\u6570\u636e\u63d0\u53d6\u653b\u51fb\uff09\u4e0e\u7f51\u7edc\u7279\u5b9a\u6807\u8bc6\u7b26\u548c\u5c5e\u6027\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u4ee3\u8868\u6027\u751f\u6210\u6a21\u578b\u7684\u8106\u5f31\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u95f4\u9690\u79c1\u98ce\u9669\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1aMIA\u6210\u529f\u73870%-88%\uff0c\u7f51\u7edc\u6807\u8bc6\u7b26\u6062\u590d\u7387\u53ef\u8fbe100%\uff0c\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u548c\u751f\u6210\u6a21\u578b\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u62df\u5408\u7a0b\u5ea6\u662f\u5f71\u54cd\u653b\u51fb\u7ed3\u679c\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u548c\u90e8\u7f72\u6700\u5c0f\u5316\u9690\u79c1\u6cc4\u9732\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u4e3a\u66f4\u5b89\u5168\u7684\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u751f\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.20510", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20510", "abs": "https://arxiv.org/abs/2511.20510", "authors": ["Yuto Suzuki", "Paul Awolade", "Daniel V. LaBarbera", "Farnoush Banaei-Kashani"], "title": "FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization", "comment": null, "summary": "Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a \"vocabulary selection\" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.", "AI": {"tldr": "FRAGMENTA\u662f\u4e00\u4e2a\u7528\u4e8e\u836f\u7269\u5148\u5bfc\u5316\u5408\u7269\u4f18\u5316\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8eQ\u5b66\u4e60\u7684\u751f\u6210\u6a21\u578b\u548c\u901a\u8fc7\u5bf9\u8bdd\u53cd\u9988\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728\u764c\u75c7\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5206\u5b50\u751f\u6210\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u7c7b\u522b\u7279\u5f02\u6027\u6570\u636e\u96c6\u901a\u5e38\u53ea\u6709\u4e0d\u5230100\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u73b0\u6709\u7247\u6bb5\u5316\u65b9\u6cd5\u591a\u6837\u6027\u4e0d\u8db3\u4e14\u9519\u8fc7\u5173\u952e\u7247\u6bb5\uff0c\u6a21\u578b\u8c03\u4f18\u9700\u8981\u5316\u5b66\u5bb6\u548cAI\u5de5\u7a0b\u5e08\u4e4b\u95f4\u7f13\u6162\u7684\u95f4\u63a5\u534f\u4f5c\u3002", "method": "1) \u5c06\u7247\u6bb5\u5316\u91cd\u6784\u4e3a\"\u8bcd\u6c47\u9009\u62e9\"\u95ee\u9898\uff0c\u4f7f\u7528\u52a8\u6001Q\u5b66\u4e60\u8054\u5408\u4f18\u5316\u7247\u6bb5\u5316\u548c\u751f\u6210\uff1b2) \u667a\u80fd\u4f53AI\u7cfb\u7edf\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u7684\u5bf9\u8bdd\u53cd\u9988\u6765\u7cbe\u70bc\u76ee\u6807\uff0c\u9010\u6b65\u5b66\u4e60\u9886\u57df\u77e5\u8bc6\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u8c03\u4f18\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u764c\u75c7\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u4e2d\uff0cFRAGMENTA\u7684\u4eba\u7c7b-\u667a\u80fd\u4f53\u914d\u7f6e\u8bc6\u522b\u7684\u9ad8\u5206\u5206\u5b50\u6570\u91cf\u662f\u57fa\u7ebf\u7684\u8fd1\u4e24\u500d\uff0c\u5b8c\u5168\u81ea\u4e3b\u7684\u667a\u80fd\u4f53-\u667a\u80fd\u4f53\u7cfb\u7edf\u4f18\u4e8e\u4f20\u7edf\u7684\u4eba\u7c7b-\u4eba\u7c7b\u8c03\u4f18\u3002", "conclusion": "FRAGMENTA\u8bc1\u660e\u4e86\u667a\u80fd\u4f53\u8c03\u4f18\u5728\u6355\u6349\u4e13\u5bb6\u610f\u56fe\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u4ece\u5faa\u73af\u4e2d\u79fb\u9664AI\u5de5\u7a0b\u5e08\u5e76\u6700\u7ec8\u5b9e\u73b0\u81ea\u52a8\u5316\u8c03\u4f18\u3002"}}
{"id": "2511.20526", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20526", "abs": "https://arxiv.org/abs/2511.20526", "authors": ["Xinran Wang", "Boran Zhu", "Shujuan Zhou", "Ziwen Long", "Dehua Zhou", "Shu Zhang"], "title": "Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam", "comment": "15 pages, 4 figures", "summary": "Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86ChatGPT-4o\u548cDeepSeek-R1\u5728\u4e2d\u56fd\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DeepSeek-R1\u5728\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8eChatGPT-4o\uff0890.0% vs 76.1%\uff09\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u5065\u5eb7\u6559\u80b2\u548c\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u4e13\u4e1a\u8ba4\u8bc1\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002\u4e2d\u56fd\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4f5c\u4e3a\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u9002\u5408\u8bc4\u4f30\u6a21\u578b\u5728\u4e34\u5e8a\u548c\u7406\u8bba\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u6536\u96c62017-2021\u5e74\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u76842,306\u9053\u7eaf\u6587\u672c\u9009\u62e9\u9898\uff0c\u6392\u9664\u5305\u542b\u8868\u683c\u6216\u56fe\u50cf\u7684\u95ee\u9898\u3002\u5c06\u4e2d\u6587\u539f\u9898\u8f93\u5165\u4e24\u4e2a\u6a21\u578b\uff0c\u8bc4\u4f30\u51c6\u786e\u7387\uff0c\u4f7f\u7528\u5361\u65b9\u68c0\u9a8c\u548cFisher\u7cbe\u786e\u68c0\u9a8c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "DeepSeek-R1\u603b\u4f53\u51c6\u786e\u7387\u663e\u8457\u9ad8\u4e8eChatGPT-4o\uff0890.0% vs 76.1%\uff0cp < 0.001\uff09\u3002\u5728\u57fa\u7840\u548c\u4e34\u5e8a\u7efc\u5408\u6a21\u5757\u4e2d\uff0cDeepSeek-R1\u8868\u73b0\u4e00\u81f4\u66f4\u4f18\u3002\u867d\u7136\u9010\u5e74\u6bd4\u8f83\u4e5f\u663e\u793aDeepSeek-R1\u4f18\u52bf\uff0c\u4f46\u5177\u4f53\u5e74\u4efd\u5355\u5143\u5dee\u5f02\u672a\u8fbe\u7edf\u8ba1\u663e\u8457\u6027\u3002", "conclusion": "DeepSeek-R1\u5728\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8868\u660e\u9886\u57df\u7279\u5b9a\u6a21\u578b\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u5728\u6cd5\u5f8b\u548c\u4f26\u7406\u654f\u611f\u573a\u666f\u4e2d\u4fdd\u6301\u4eba\u5de5\u76d1\u7763\u3002"}}
{"id": "2511.20531", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20531", "abs": "https://arxiv.org/abs/2511.20531", "authors": ["Shamima Hossain"], "title": "Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models", "comment": "Accepted as poster at NewInML Workshop ICML, 2025", "summary": "Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u9a8c\u8bc1\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u7ecf\u5e38\u4ea7\u751f\u4e8b\u5b9e\u4e0d\u51c6\u786e\u7684\u8f93\u51fa\uff0c\u7f3a\u4e4f\u7a33\u5065\u7684\u63a8\u7406\u80fd\u529b\u3002\u5728\u591a\u6a21\u6001\u73af\u5883\u4e2d\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u7684\u7814\u7a76\u4ecd\u7136\u4e0d\u8db3", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u591a\u8df3\u9a8c\u8bc1\uff0c\u5305\u62ec\u89c6\u89c9\u5b9e\u4f53\u8bc6\u522b\u3001\u77e5\u8bc6\u56fe\u8c31\u904d\u5386\u548c\u57fa\u4e8e\u4e8b\u5b9e\u7684\u6807\u9898\u4f18\u5316\u3002\u8bc4\u4f30\u4e86\u5c42\u6b21\u5316\u3001\u4e09\u5143\u7ec4\u548c\u9879\u76ee\u7b26\u53f7\u4e09\u79cd\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5", "result": "\u5728\u6df7\u5408\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5c06\u4e8b\u5b9e\u51c6\u786e\u6027\u63d0\u9ad8\u4e86\u7ea631%\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u5f0f\u548c\u5931\u8d25\u6848\u4f8b\u7684\u5173\u952e\u89c1\u89e3", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u6765\u63a8\u8fdbVLM\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u4e3a\u66f4\u53ef\u9760\u548c\u77e5\u8bc6\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def"}}
{"id": "2511.20586", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20586", "abs": "https://arxiv.org/abs/2511.20586", "authors": ["Koffi Ismael Ouattara", "Ioannis Krontiris", "Theo Dimitrakos", "Dennis Eisermann", "Frank Kargl"], "title": "PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic", "comment": null, "summary": "Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.", "AI": {"tldr": "\u63d0\u51faPaTAS\u6846\u67b6\uff0c\u4f7f\u7528\u4e3b\u89c2\u903b\u8f91\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5efa\u6a21\u548c\u4f20\u64ad\u4fe1\u4efb\u5ea6\uff0c\u901a\u8fc7\u4fe1\u4efb\u8282\u70b9\u548c\u4fe1\u4efb\u51fd\u6570\u5e76\u884c\u8bc4\u4f30\u6a21\u578b\u53ef\u9760\u6027\uff0c\u80fd\u591f\u533a\u5206\u826f\u6027\u8f93\u5165\u548c\u5bf9\u6297\u6027\u8f93\u5165\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u5982\u51c6\u786e\u7387\u548c\u7cbe\u5ea6\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6027\u6216\u9000\u5316\u6761\u4ef6\u4e0b\u3002\u9700\u8981\u53ef\u91cf\u5316\u7684\u4fe1\u4efb\u8bc4\u4f30\u7cfb\u7edf\u6765\u786e\u4fddAI\u7cfb\u7edf\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528\u4e3b\u89c2\u903b\u8f91\uff0c\u901a\u8fc7\u4fe1\u4efb\u8282\u70b9\u548c\u4fe1\u4efb\u51fd\u6570\u5e76\u884c\u4f20\u64ad\u8f93\u5165\u3001\u53c2\u6570\u548c\u6fc0\u6d3b\u4fe1\u4efb\uff1b\u5b9a\u4e49\u53c2\u6570\u4fe1\u4efb\u66f4\u65b0\u673a\u5236\u5728\u8bad\u7ec3\u4e2d\u4f18\u5316\u53c2\u6570\u53ef\u9760\u6027\uff1b\u91c7\u7528\u63a8\u7406\u8def\u5f84\u4fe1\u4efb\u8bc4\u4f30\u65b9\u6cd5\u8ba1\u7b97\u5b9e\u4f8b\u7279\u5b9a\u4fe1\u4efb\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5bf9\u6297\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPaTAS\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u5bf9\u79f0\u4e14\u6536\u655b\u7684\u4fe1\u4efb\u4f30\u8ba1\uff0c\u6709\u6548\u533a\u5206\u826f\u6027\u8f93\u5165\u548c\u5bf9\u6297\u6027\u8f93\u5165\uff0c\u8bc6\u522b\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u5b9e\u9645\u53ef\u9760\u6027\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u3002", "conclusion": "PaTAS\u4e3a\u5728\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u5b9e\u73b0\u900f\u660e\u548c\u53ef\u91cf\u5316\u7684\u4fe1\u4efb\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\uff0c\u80fd\u591f\u5728\u6574\u4e2aAI\u751f\u547d\u5468\u671f\u4e2d\u8bc4\u4f30\u6a21\u578b\u53ef\u9760\u6027\u3002"}}
{"id": "2511.20610", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20610", "abs": "https://arxiv.org/abs/2511.20610", "authors": ["Gaspard Merten", "Mahmoud Sakr", "Gilles Dejaegere"], "title": "Building a Foundation Model for Trajectory from Scratch", "comment": null, "summary": "Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.", "AI": {"tldr": "\u672c\u6559\u7a0b\u5c55\u793a\u4e86\u4eceGPT-2\u5f00\u59cb\u6784\u5efa\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u6700\u5c0f\u5b9e\u73b0\u6b65\u9aa4\u548c\u4ee3\u7801\uff0c\u6bd4\u8f83\u4e86TrajFM\u548cTrajGPT\u7b49\u4ee3\u8868\u6027\u6a21\u578b\uff0c\u5e76\u4ecb\u7ecd\u4e86TimesFM\u7684\u8865\u4e01\u65b9\u6cd5\uff0c\u65e8\u5728\u652f\u6301SIGSPATIAL\u793e\u533a\u6784\u5efa\u548c\u8bc4\u4f30\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u5177\u6709\u53d8\u9769\u6027\uff0c\u4f46\u4e3a\u79fb\u52a8\u8f68\u8ff9\u4ece\u5934\u5f00\u59cb\u6784\u5efa\u57fa\u7840\u6a21\u578b\u7684\u65b9\u6cd5\u5c1a\u4e0d\u660e\u786e\u6216\u7f3a\u4e4f\u6587\u6863\u8bb0\u5f55\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u9010\u6b65\u4ee3\u7801\u9a71\u52a8\u8fc7\u7a0b\u6f14\u793a\u5982\u4f55\u5c06GPT-2\u9002\u914d\u65f6\u7a7a\u6570\u636e\uff0c\u56de\u987e\u6bd4\u8f83\u4ee3\u8868\u6027\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u76f8\u5173\u9886\u57df\u7684\u8865\u5145\u6280\u672f\u3002", "result": "\u63d0\u4f9b\u4e86\u6784\u5efa\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u5b9e\u73b0\u6307\u5357\u548c\u4ee3\u7801\u793a\u4f8b\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u67b6\u6784\u521b\u65b0\u548c\u5dee\u5f02\u3002", "conclusion": "\u521b\u5efa\u8fd9\u4e9b\u6559\u80b2\u6750\u6599\u5bf9\u4e8e\u652f\u6301SIGSPATIAL\u793e\u533a\u6784\u5efa\u548c\u8bc4\u4f30\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\u3001\u63d0\u9ad8\u79fb\u52a8AI\u7814\u7a76\u6e05\u6670\u5ea6\u548c\u540c\u884c\u8bc4\u5ba1\u6548\u679c\u662f\u53ca\u65f6\u4e14\u5fc5\u8981\u7684\u3002"}}
{"id": "2511.20623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20623", "abs": "https://arxiv.org/abs/2511.20623", "authors": ["David Szczecina", "Senan Gaffori", "Edmond Li"], "title": "Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development", "comment": "4 pages, 3 figures", "summary": "The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u7248\u6743\u68c0\u6d4b\u5e73\u53f0\uff0c\u5e2e\u52a9\u5185\u5bb9\u521b\u4f5c\u8005\u9a8c\u8bc1\u5176\u4f5c\u54c1\u662f\u5426\u88ab\u7528\u4e8eLLM\u8bad\u7ec3\u6570\u636e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c11\u4e8610-30%\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "LLM\u5e7f\u6cdb\u4f7f\u7528\u5f15\u53d1\u7248\u6743\u5185\u5bb9\u672a\u7ecf\u6388\u6743\u4f7f\u7528\u7684\u62c5\u5fe7\uff0c\u73b0\u6709\u68c0\u6d4b\u6846\u67b6\u8ba1\u7b97\u5bc6\u96c6\u4e14\u5bf9\u72ec\u7acb\u521b\u4f5c\u8005\u4e0d\u53cb\u597d\uff0c\u9700\u8981\u53ef\u6269\u5c55\u3001\u900f\u660e\u4e14\u7528\u6237\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4f18\u5316API\u8c03\u7528\u63d0\u9ad8\u6548\u7387\uff0c\u6539\u8fdb\u76f8\u4f3c\u6027\u68c0\u6d4b\uff0c\u4f18\u5316\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u5e76\u63d0\u4f9b\u76f4\u89c2\u7528\u6237\u754c\u9762\u548c\u53ef\u6269\u5c55\u540e\u7aef\u3002", "result": "\u5b9e\u73b0\u4e86\u8ba1\u7b97\u5f00\u9500\u51cf\u5c1110-30%\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u63d0\u9ad8AI\u5f00\u53d1\u7684\u900f\u660e\u5ea6\uff0c\u4fc3\u8fdb\u8d1f\u8d23\u4efbAI\u53d1\u5c55\u548c\u7248\u6743\u6267\u6cd5\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.20627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20627", "abs": "https://arxiv.org/abs/2511.20627", "authors": ["Anastasia Mavridou", "Divya Gopinath", "Corina S. P\u0103s\u0103reanu"], "title": "Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems", "comment": null, "summary": "The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.", "AI": {"tldr": "\u63d0\u51faREACT\u548cSemaLens\u4e24\u4e2aAI\u9a71\u52a8\u7ec4\u4ef6\uff0c\u89e3\u51b3\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2dAI\u7ec4\u4ef6\u96c6\u6210\u7684\u9a8c\u8bc1\u6311\u6218\uff0c\u901a\u8fc7LLM\u548cVLM\u6865\u63a5\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0e\u5f62\u5f0f\u5316\u89c4\u8303\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u3002", "motivation": "AI\u7ec4\u4ef6\uff08\u7279\u522b\u662fDNN\uff09\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u9762\u4e34\u6839\u672c\u6027\u9a8c\u8bc1\u6311\u6218\uff0cAI\u7cfb\u7edf\u7684\u4e0d\u900f\u660e\u6027\u4ee5\u53ca\u9ad8\u5c42\u9700\u6c42\u4e0e\u4f4e\u5c42\u7f51\u7edc\u8868\u793a\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u963b\u788d\u4e86\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "REACT\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fde\u63a5\u975e\u6b63\u5f0f\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0e\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u5b9e\u73b0\u65e9\u671f\u9a8c\u8bc1\uff1bSemaLens\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u4eba\u7c7b\u53ef\u7406\u89e3\u6982\u5ff5\u5bf9DNN\u611f\u77e5\u7cfb\u7edf\u8fdb\u884c\u63a8\u7406\u3001\u6d4b\u8bd5\u548c\u76d1\u63a7\u3002", "result": "\u6784\u5efa\u4e86\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u5230\u9a8c\u8bc1\u5b9e\u73b0\u7684\u5168\u6d41\u7a0b\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86AI\u7cfb\u7edf\u9a8c\u8bc1\u4e2d\u7684\u8bed\u4e49\u9e3f\u6c9f\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "conclusion": "\u5229\u7528AI\u81ea\u8eab\u80fd\u529b\u89e3\u51b3AI\u7cfb\u7edf\u9a8c\u8bc1\u6311\u6218\u662f\u53ef\u884c\u7684\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2dAI\u7ec4\u4ef6\u7684\u53ef\u4fe1\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
