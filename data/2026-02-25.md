<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.IT](#cs.IT) [Total: 13]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [AWCP: A Workspace Delegation Protocol for Deep-Engagement Collaboration across Remote Agents](https://arxiv.org/abs/2602.20493)
*Xiaohang Nie,Zihan Guo,Youliang Chen,Yuanjian Zhou,Weinan Zhang*

Main category: cs.NI

TL;DR: AWCP协议通过临时工作空间委托解决LLM智能体协作中的环境隔离问题，实现跨环境直接文件操作和工具调用


<details>
  <summary>Details</summary>
Motivation: 现有智能体协作仅限于消息传递，执行环境相互隔离，导致智能体无法直接操作同伴环境中的文件或调用工具，必须进行昂贵且易错的环境重建

Method: 提出Agent Workspace Collaboration Protocol (AWCP)，采用临时工作空间委托机制，将控制平面与可插拔传输机制解耦，允许委托方将工作空间投影到远程执行方，后者可直接操作共享文件

Result: 提供了完全开源参考实现，集成了MCP工具，通过非对称协作演示验证了协议有效性，智能体可通过委托工作空间实现互补能力协作

Conclusion: AWCP在智能体协议栈中建立了缺失的工作空间层，为实现普遍可互操作的智能体生态系统铺平道路，使协作超越消息边界

Abstract: The rapid evolution of Large Language Model (LLM)-based autonomous agents is reshaping the digital landscape toward an emerging Agentic Web, where increasingly specialized agents must collaborate to accomplish complex tasks. However, existing collaboration paradigms are constrained to message passing, leaving execution environments as isolated silos. This creates a context gap: agents cannot directly manipulate files or invoke tools in a peer's environment, and must instead resort to costly, error-prone environment reconstruction. We introduce the Agent Workspace Collaboration Protocol (AWCP), which bridges this gap through temporary workspace delegation inspired by the Unix philosophy that everything is a file. AWCP decouples a lightweight control plane from pluggable transport mechanisms, allowing a Delegator to project its workspace to a remote Executor, who then operates on the shared files directly with unmodified local toolchains. We provide a fully open-source reference implementation with MCP tool integration and validate the protocol through live demonstrations of asymmetric collaboration, where agents with complementary capabilities cooperate through delegated workspaces. By establishing the missing workspace layer in the agentic protocol stack, AWCP paves the way for a universally interoperable agent ecosystem in which collaboration transcends message boundaries. The protocol and reference implementation are publicly available at https://github.com/SII-Holos/awcp.

</details>


### [2] [Deep Reinforcement Learning Based Block Coordinate Descent for Downlink Weighted Sum-rate Maximization on AI-Native Wireless Networks](https://arxiv.org/abs/2602.20724)
*Siya Chen,Chee Wei Tan,H. Vincent Poor*

Main category: cs.NI

TL;DR: 提出基于深度强化学习的块坐标下降算法，解决非凸加权和速率最大化问题，结合机器学习的数据驱动能力和优化理论的导航决策特性，提高性能并减少对初始点的敏感性。


<details>
  <summary>Details</summary>
Motivation: 解决非凸加权和速率最大化（WSRM）问题，传统优化方法容易陷入局部最优且对初始点敏感，需要结合机器学习提升性能。

Method: 首先提出高效的块坐标下降（BCD）方法，然后集成深度强化学习（DRL）技术，形成DRL-based BCD算法，结合机器学习的数据驱动能力和优化理论的导航决策特性。

Result: 算法显著减少对初始点的敏感性，降低陷入局部最优的风险，能够遵守WSRM问题的约束条件，显著提高精度，可能达到精确最优解，计算效率高且保持可解释性。

Conclusion: DRL-based BCD算法在有效性、效率、鲁棒性和可解释性方面具有显著优势，为下一代无线网络中资源受限的AI原生无线优化策略设计提供了有价值的潜力。

Abstract: This paper introduces a deep reinforcement learning-based block coordinate descent (DRL-based BCD) algorithm to address the nonconvex weighted sum-rate maximization (WSRM) problem with a total power constraint. Firstly, we present an efficient block coordinate descent (BCD) method to solve the problem. We then integrate deep reinforcement learning (DRL) techniques into the BCD method and propose the DRL-based BCD algorithm. This approach combines the data-driven learning capability of machine learning techniques with the navigational and decision-making characteristics of the optimization-theoretic-based BCD method. This combination significantly improves the algorithm's performance by reducing its sensitivity to initial points and mitigating the risk of entrapment in local optima. The primary advantages of the proposed DRL-based BCD algorithm lie in its ability to adhere to the constraints of the WSRM problem and significantly enhance accuracy, potentially achieving the exact optimal solution. Moreover, unlike many pure machine-learning approaches, the DRL-based BCD algorithm capitalizes on the underlying theoretical analysis of the WSRM problem's structure. This enables it to be easily trained and computationally efficient while maintaining a level of interpretability. Through numerical experiments, the DRL-based BCD algorithm demonstrates substantial advantages in effectiveness, efficiency, robustness, and interpretability for maximizing sum rates, which also provides valuable potential for designing resource-constrained AI-native wireless optimization strategies in next-generation wireless networks.

</details>


### [3] [Airavat: An Agentic Framework for Internet Measurement](https://arxiv.org/abs/2602.20924)
*Alagappan Ramanathan,Eunju Kang,Dongsu Han,Sangeetha Abdu Jyothi*

Main category: cs.NI

TL;DR: Airavat是首个用于互联网测量工作流生成的智能代理框架，通过系统化验证和验证机制，自动化工作流生成并确保方法学正确性。


<details>
  <summary>Details</summary>
Motivation: 互联网测量面临双重挑战：复杂分析需要专家级工具编排，而即使语法正确的实现也可能存在方法学缺陷且难以验证。因此，民主化测量能力需要自动化工作流生成和验证。

Method: Airavat采用代理框架模拟专家推理：三个代理分别处理问题分解、方案设计和代码实现，辅以现有工具注册表。两个专门引擎确保方法学正确性：验证引擎基于编码了五十年测量研究的知识图谱评估工作流，验证引擎识别基于既定方法学的适当验证技术。

Result: 通过四个互联网测量案例研究，Airavat能够：(i)生成匹配专家级解决方案的工作流，(ii)做出合理的架构决策，(iii)处理没有真实基准的新问题，(iv)识别标准执行测试遗漏的方法学缺陷。

Conclusion: Airavat是首个实现互联网测量工作流生成与系统化验证的智能代理框架，有效解决了测量分析中的方法学正确性和可验证性问题。

Abstract: Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating both workflow generation and verification against methodological standards established through decades of research.
  We present Airavat, the first agentic framework for Internet measurement workflow generation with systematic verification and validation. Airavat coordinates a set of agents mirroring expert reasoning: three agents handle problem decomposition, solution design, and code implementation, with assistance from a registry of existing tools. Two specialized engines ensure methodological correctness: a Verification Engine evaluates workflows against a knowledge graph encoding five decades of measurement research, while a Validation Engine identifies appropriate validation techniques grounded in established methodologies. Through four Internet measurement case studies, we demonstrate that Airavat (i) generates workflows matching expert-level solutions, (ii) makes sound architectural decisions, (iii) addresses novel problems without ground truth, and (iv) identifies methodological flaws missed by standard execution-based testing.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health](https://arxiv.org/abs/2602.20303)
*Joyanta Jyoti Mondal*

Main category: cs.AI

TL;DR: 该研究比较了不同统计和机器学习模型在预测美国青少年超重/肥胖方面的表现，发现逻辑回归与更复杂的模型性能相当，且所有模型在不同种族和贫困群体间都存在性能差异。


<details>
  <summary>Details</summary>
Motivation: 儿童和青少年超重肥胖是美国主要的公共卫生问题，受行为、家庭和社区因素共同影响。目前对这些多层次预测因素在人群层面的联合预测结构了解不足，需要比较不同建模方法的预测性能、校准和亚组公平性。

Method: 使用2021年全国儿童健康调查中18,792名10-17岁儿童的数据。预测变量包括饮食、体育活动、睡眠、父母压力、社会经济条件、不良经历和社区特征。比较了逻辑回归、随机森林、梯度提升、XGBoost、LightGBM、多层感知机和TabNet等模型，使用AUC、准确率、精确率、召回率、F1分数和Brier分数进行评估。

Result: 模型区分度在0.66-0.79之间。逻辑回归、梯度提升和多层感知机在区分度和校准方面表现最稳定。提升方法和深度学习略微提高了召回率和F1分数。没有模型在所有方面都表现最优。不同种族和贫困群体间的性能差异在所有算法中持续存在。

Conclusion: 增加模型复杂性对逻辑回归的改进有限。预测因素始终涵盖行为、家庭和社区领域。持续的亚组差异表明需要改进数据质量和关注公平性的监测，而不是追求更高的算法复杂性。

Abstract: Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.

</details>


### [5] [An artificial intelligence framework for end-to-end rare disease phenotyping from clinical notes using large language models](https://arxiv.org/abs/2602.20324)
*Cathy Shyr,Yan Hu,Rory J. Tinker,Thomas A. Cassini,Kevin W. Byram,Rizwan Hamid,Daniel V. Fabbri,Adam Wright,Josh F. Peterson,Lisa Bastarache,Hua Xu*

Main category: cs.AI

TL;DR: RARE-PHENIX是一个端到端AI框架，用于罕见病表型分析，整合了基于大语言模型的表型提取、本体标准化和诊断信息表型排序，在临床工作流程中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断中表型分析至关重要，但手动从临床记录中提取结构化表型耗时且难以扩展。现有AI方法通常只优化单个组件，未能完整实现从临床文本提取特征、标准化为HPO术语、并优先排序诊断信息表型的完整临床工作流程。

Method: 开发了RARE-PHENIX端到端AI框架，整合三个模块：1) 基于大语言模型的表型提取；2) 基于本体的标准化到HPO术语；3) 监督式诊断信息表型排序。使用来自11个未诊断疾病网络临床站点的2,671名患者数据进行训练。

Result: 在范德比尔特大学医学中心的16,357份真实世界临床记录上进行外部验证，使用临床医生标注的HPO术语作为金标准。RARE-PHENIX在端到端评估中始终优于最先进的深度学习基线(PhenoBERT)，本体相似度为0.70 vs. 0.58。消融分析显示每个模块都对性能有提升。

Conclusion: 通过将表型分析建模为临床对齐的工作流程而非单一提取任务，RARE-PHENIX提供了更符合临床医生标注的结构化、排序表型，有潜力在真实世界环境中支持人机协同的罕见病诊断。

Abstract: Phenotyping is fundamental to rare disease diagnosis, but manual curation of structured phenotypes from clinical notes is labor-intensive and difficult to scale. Existing artificial intelligence approaches typically optimize individual components of phenotyping but do not operationalize the full clinical workflow of extracting features from clinical text, standardizing them to Human Phenotype Ontology (HPO) terms, and prioritizing diagnostically informative HPO terms. We developed RARE-PHENIX, an end-to-end AI framework for rare disease phenotyping that integrates large language model-based phenotype extraction, ontology-grounded standardization to HPO terms, and supervised ranking of diagnostically informative phenotypes. We trained RARE-PHENIX using data from 2,671 patients across 11 Undiagnosed Diseases Network clinical sites, and externally validated it on 16,357 real-world clinical notes from Vanderbilt University Medical Center. Using clinician-curated HPO terms as the gold standard, RARE-PHENIX consistently outperformed a state-of-the-art deep learning baseline (PhenoBERT) across ontology-based similarity and precision-recall-F1 metrics in end-to-end evaluation (i.e., ontology-based similarity of 0.70 vs. 0.58). Ablation analyses demonstrated performance improvements with the addition of each module in RARE-PHENIX (extraction, standardization, and prioritization), supporting the value of modeling the full clinical phenotyping workflow. By modeling phenotyping as a clinically aligned workflow rather than a single extraction task, RARE-PHENIX provides structured, ranked phenotypes that are more concordant with clinician curation and has the potential to support human-in-the-loop rare disease diagnosis in real-world settings.

</details>


### [6] [DMCD: Semantic-Statistical Framework for Causal Discovery](https://arxiv.org/abs/2602.20333)
*Samarth KaPatel,Sofia Nikiforova,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.AI

TL;DR: DMCD是一个两阶段因果发现框架，结合LLM语义草图和统计验证，在真实世界基准测试中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法通常仅依赖统计方法，缺乏对变量语义信息的利用。DMCD旨在通过结合LLM的语义理解和传统统计验证，提高因果结构学习的准确性和实用性

Method: 两阶段框架：第一阶段使用大语言模型基于变量元数据生成稀疏的因果图草图；第二阶段通过条件独立性测试对草图进行审计和精炼，检测差异并指导有针对性的边修正

Result: 在工业工程、环境监测和IT系统分析三个元数据丰富的真实世界基准测试中，DMCD相比多种因果发现基线方法取得了竞争性或领先的性能，特别是在召回率和F1分数上有显著提升

Conclusion: 将语义先验与原则性统计验证相结合，能够产生高性能且实际有效的因果结构学习方法，改进主要来自对元数据的语义推理而非对基准图的记忆

Abstract: We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.
  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.

</details>


### [7] [Diffusion Modulation via Environment Mechanism Modeling for Planning](https://arxiv.org/abs/2602.20422)
*Hanping Zhang,Yuhong Guo*

Main category: cs.AI

TL;DR: DMEMM是一种新颖的基于扩散模型的规划方法，通过建模环境机制（转移动态和奖励函数）来调制扩散训练，解决了传统扩散规划中轨迹一致性问题，在离线强化学习规划中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于扩散模型的规划方法在离线强化学习中存在轨迹一致性问题，未能考虑RL环境中转移之间的内在一致性要求，导致生成轨迹与真实环境机制存在显著差异。

Method: 提出DMEMM方法，通过建模关键RL环境机制（特别是转移动态和奖励函数）来调制扩散模型的训练过程，确保生成的轨迹在真实环境中具有一致性。

Result: 实验结果表明，DMEMM在离线强化学习规划任务中取得了最先进的性能。

Conclusion: 通过将环境机制建模融入扩散训练，DMEMM有效解决了轨迹一致性问题，为基于扩散模型的离线RL规划提供了更可靠的方法。

Abstract: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

</details>


### [8] [Implicit Intelligence -- Evaluating Agents on What Users Don't Say](https://arxiv.org/abs/2602.20424)
*Ved Sirdeshmukh,Marc Wetter*

Main category: cs.AI

TL;DR: 提出Implicit Intelligence评估框架，测试AI代理能否超越显式指令跟随，理解并满足人类请求中的隐含需求，发现当前最佳模型仅能达到48.3%的场景通过率


<details>
  <summary>Details</summary>
Motivation: 现实世界中对AI代理的请求本质上是未充分指定的，人类自然交流依赖共享上下文和未明说的约束，而当前代理基准只测试显式指令跟随，无法评估代理能否推理隐含需求

Method: 提出Implicit Intelligence评估框架，配合Agent-as-a-World（AaW）工具，其中交互世界用人类可读的YAML文件定义并由语言模型模拟，场景设计具有表面简单但解决方案复杂的特点，约束可通过环境探索发现

Result: 评估16个前沿和开源模型在205个场景中的表现，发现即使最佳模型也只能达到48.3%的场景通过率，显示在弥合字面指令跟随和类人上下文推理之间的差距方面仍有很大改进空间

Conclusion: 需要开发能够理解隐含需求、进行上下文推理的AI代理，当前模型在从指令跟随者转变为真正目标实现者方面仍有显著不足

Abstract: Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI agents can move beyond prompt-following to become genuine goal-fulfillers, paired with Agent-as-a-World (AaW), a harness where interactive worlds are defined in human-readable YAML files and simulated by language models. Our scenarios feature apparent simplicity in user requests, hidden complexity in correct solutions, and discoverability of constraints through environmental exploration. Evaluating 16 frontier and open-weight models across 205 scenarios, we find that even the best-performing model achieves only 48.3% scenario pass rate, revealing substantial room for improvement in bridging the gap between literal instruction-following and human-like contextual reasoning.

</details>


### [9] [Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use](https://arxiv.org/abs/2602.20426)
*Ruocheng Guo,Kaiwen Dong,Xiang Gao,Kamalika Das*

Main category: cs.AI

TL;DR: 提出Trace-Free+框架，通过课程学习优化LLM代理的工具接口，无需执行轨迹即可提升工具选择性能，支持大规模工具集和跨领域泛化。


<details>
  <summary>Details</summary>
Motivation: LLM代理的性能不仅取决于代理本身，还受工具接口质量影响。现有工具接口多为人工设计，在大规模工具选择时成为瓶颈。现有方法依赖执行轨迹，但在冷启动或隐私受限场景中难以获取，且通常独立优化每个工具，缺乏可扩展性和泛化能力。

Method: 提出Trace-Free+课程学习框架，逐步从轨迹丰富设置迁移到无轨迹部署，鼓励模型抽象可重用的接口使用模式和工具使用结果。构建大规模高质量工具接口数据集，使用结构化工作流程处理多样化工具集合。

Result: 在StableToolBench和RestBench上的实验显示，对未见工具获得一致性能提升，具有强大的跨领域泛化能力，在候选工具数量超过100时仍保持鲁棒性，证明工具接口优化是代理微调的有效补充。

Conclusion: 工具接口优化是实际可部署的代理微调补充方案，Trace-Free+框架能够在无执行轨迹情况下有效提升LLM代理的工具使用性能，支持大规模工具集和跨领域应用。

Abstract: The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavailable in cold-start or privacy-constrained settings, and typically optimize each tool independently, limiting scalability and generalization to unseen tools. We propose Trace-Free+, a curriculum learning framework that progressively transfers supervision from trace-rich settings to trace-free deployment, encouraging the model to abstract reusable interface-usage patterns and tool usage outcomes. To support this approach, we construct a large-scale dataset of high-quality tool interfaces using a structured workflow over a diverse collection of tools. Experiments on StableToolBench and RestBench show consistent gains on unseen tools, strong cross-domain generalization, and robustness as the number of candidate tools scales to over 100, demonstrating that tool interface optimization is a practical and deployable complement to agent fine-tuning.

</details>


### [10] [PreScience: A Benchmark for Forecasting Scientific Contributions](https://arxiv.org/abs/2602.20459)
*Anirudh Ajith,Amanpreet Singh,Jay DeYoung,Nadav Kunievsky,Austin C. Kozlowski,Oyvind Tafjord,James Evans,Daniel S. Weld,Tom Hope,Doug Downey*

Main category: cs.AI

TL;DR: PreScience是一个科学预测基准，将研究过程分解为四个生成任务：合作者预测、先前工作选择、贡献生成和影响力预测，用于评估AI系统能否预测科学进展。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统能否基于历史科学记录预测未来的科学进展，以帮助研究人员识别合作者、发现重要研究方向，并预测未来将成为核心的问题和方法。

Method: 构建了包含98K篇AI相关论文的数据集，包含消歧的作者身份、时间对齐的学术元数据，以及包含502K篇论文的作者发表历史和引用图。为四个任务开发了基线方法和评估指标，包括新的LLM-based贡献相似度度量LACERScore。

Result: 前沿LLM在各项任务中仍有很大提升空间（如贡献生成任务中GPT-5平均得分5.6/10）。12个月的端到端模拟产生的合成语料库在多样性和新颖性方面系统性地低于同期人类撰写的研究。

Conclusion: AI系统目前还无法准确预测科学进展，合成研究在多样性和新颖性上不如人类研究，表明科学预测仍具挑战性，但PreScience基准为未来研究提供了评估框架。

Abstract: Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.

</details>


### [11] [KairosVL: Orchestrating Time Series and Semantics for Unified Reasoning](https://arxiv.org/abs/2602.20494)
*Haotian Si,Changhua Pei,Xiao He,Zeyan Li,Zhe Xie,Zexin Wang,Jiyao Hu,Zhaoyang Yu,Tieying Zhang,Dan Pei,Jianhui Li,Gaogang Xie*

Main category: cs.AI

TL;DR: 提出Semantic-Conditional Time Series Reasoning任务和KairosVL模型，通过两轮强化学习框架结合语义推理与时间序列建模，提升复杂决策场景下的性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分析主要关注数值建模，但现实应用中需要结合上下文和语义理解进行决策。为满足日益复杂的决策导向需求，需要扩展时间序列分析能力。

Method: 提出两轮强化学习框架：第一轮增强模型对基本时间原语的感知能力，第二轮专注于语义条件推理。由此构建KairosVL模型。

Result: KairosVL在合成和真实世界任务中均取得有竞争力的性能。实验表明该框架不仅能提升性能，还能保持内在推理能力，并显著提高对未见场景的泛化能力。

Conclusion: 该工作展示了语义推理与时间建模结合的潜力，为现实世界时间序列智能提供了实用框架，满足了当前对复杂决策支持的迫切需求。

Abstract: Driven by the increasingly complex and decision-oriented demands of time series analysis, we introduce the Semantic-Conditional Time Series Reasoning task, which extends conventional time series analysis beyond purely numerical modeling to incorporate contextual and semantic understanding. To further enhance the mode's reasoning capabilities on complex time series problems, we propose a two-round reinforcement learning framework: the first round strengthens the mode's perception of fundamental temporal primitives, while the second focuses on semantic-conditioned reasoning. The resulting model, KairosVL, achieves competitive performance across both synthetic and real-world tasks. Extensive experiments and ablation studies demonstrate that our framework not only boosts performance but also preserves intrinsic reasoning ability and significantly improves generalization to unseen scenarios. To summarize, our work highlights the potential of combining semantic reasoning with temporal modeling and provides a practical framework for real-world time series intelligence, which is in urgent demand.

</details>


### [12] [ActionEngine: From Reactive to Programmatic GUI Agents via State Machine Memory](https://arxiv.org/abs/2602.20502)
*Hongbin Zhong,Fazle Faisal,Luis França,Tanakorn Leesatapornwongsa,Adriana Szekeres,Kexin Rong,Suman Nath*

Main category: cs.AI

TL;DR: ActionEngine：通过双智能体架构（爬虫智能体构建状态机记忆，执行智能体合成Python程序）实现GUI交互从逐步执行到程序化规划的转变，显著提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体采用逐步调用视觉语言模型的方式，存在成本高、延迟大、准确性有限的问题，且缺乏对已访问页面的持久记忆。

Method: 提出无需训练的双智能体框架：1）爬虫智能体通过离线探索构建可更新的GUI状态机记忆；2）执行智能体利用该记忆合成完整的可执行Python程序进行在线任务执行；3）执行失败时触发基于视觉的重定位回退机制修复动作并更新记忆。

Result: 在WebArena基准测试的Reddit任务中，达到95%任务成功率，平均仅需1次LLM调用，相比最强视觉基线（66%成功率）成本降低11.8倍，端到端延迟减少2倍。

Conclusion: 通过结合全局程序化规划、爬虫验证的动作模板以及节点级执行与局部验证修复，实现了可扩展且可靠的GUI交互。

Abstract: Existing Graphical User Interface (GUI) agents operate through step-by-step calls to vision language models--taking a screenshot, reasoning about the next action, executing it, then repeating on the new page--resulting in high costs and latency that scale with the number of reasoning steps, and limited accuracy due to no persistent memory of previously visited pages.
  We propose ActionEngine, a training-free framework that transitions from reactive execution to programmatic planning through a novel two-agent architecture: a Crawling Agent that constructs an updatable state-machine memory of the GUIs through offline exploration, and an Execution Agent that leverages this memory to synthesize complete, executable Python programs for online task execution.
  To ensure robustness against evolving interfaces, execution failures trigger a vision-based re-grounding fallback that repairs the failed action and updates the memory.
  This design drastically improves both efficiency and accuracy: on Reddit tasks from the WebArena benchmark, our agent achieves 95% task success with on average a single LLM call, compared to 66% for the strongest vision-only baseline, while reducing cost by 11.8x and end-to-end latency by 2x.
  Together, these components yield scalable and reliable GUI interaction by combining global programmatic planning, crawler-validated action templates, and node-level execution with localized validation and repair.

</details>


### [13] [Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination](https://arxiv.org/abs/2602.20517)
*Rakshit Trivedi,Kartik Sharma,David C Parkes*

Main category: cs.AI

TL;DR: MIMIC框架使用语言作为行为意图的内部表示，通过视觉语言模型训练条件变分自编码器生成内部语音，再结合扩散行为克隆策略实现细粒度行为控制，显著提升了行为多样性和人类演示保真度。


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法难以捕捉人类行为的多样性和非马尔可夫特性，且缺乏推理时的行为引导能力。受人类认知过程中内部语音指导行动选择的理论启发，需要开发能够使用语言作为行为意图内部表示、实现细粒度行为控制的智能体。

Method: 提出MIMIC框架：1）使用视觉语言模型作为语言支架训练条件变分自编码器，从观察中生成内部语音；2）采用基于扩散的行为克隆策略，根据当前观察和生成的内部语音选择行动；3）推理时通过特定行为语音条件化实现细粒度行为引导。

Result: 在机器人操作任务和人机协作游戏中，MIMIC显著提升了行为多样性和人类演示保真度，无需额外演示即可实现细致的行为引导。代码已开源并提供预训练模型和演示。

Conclusion: MIMIC通过将语言作为行为意图的内部表示，有效解决了模仿学习中行为多样性和推理时引导的挑战，为人机协调提供了更自然、可控的智能体。

Abstract: Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the theory of human cognitive processes, where inner speech guides action selection before execution, we propose MIMIC (Modeling Inner Motivations for Imitation and Control), a framework that uses language as an internal representation of behavioral intent. MIMIC employs the novel use of vision-language models as linguistic scaffolding to train a conditional variational autoencoder capable of generating inner speech from observations. A diffusion-based behavior cloning policy then selects actions conditioned on current observations and the generated inner speech. MIMIC enables fine-grained steering of behavior at inference time by conditioning the agent on behavior-specific speech. Experiments across robotic manipulation tasks and human-AI collaboration games demonstrate that MIMIC significantly enhances both behavior diversity and fidelity to human demonstrations while enabling nuanced behavioral steering without training on additional demonstrations. We open source our code and provide pre-trained MIMIC agents and qualitative demos at: https://mimic-research.github.io.

</details>


### [14] [From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production](https://arxiv.org/abs/2602.20558)
*Yucheng Shi,Ying Li,Yu Wang,Yesu Feng,Arjun Rao,Rein Houthooft,Shradha Sehgal,Jin Wang,Hao Zhen,Ninghao Liu,Linas Baltrunas*

Main category: cs.AI

TL;DR: 提出基于强化学习的数据中心化框架，学习将结构化用户交互日志转化为优化文本上下文，显著提升LLM推荐系统性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统使用僵化的模板简单拼接字段，导致次优表示，需要更有效的自然语言输入转换方法

Method: 使用强化学习训练verbalization agent，将原始交互历史转化为优化文本上下文，以推荐准确性作为训练信号，学习过滤噪声、整合元数据、重组信息

Result: 在大规模工业流媒体数据集上，学习到的verbalization相比模板基线在发现项目推荐准确性上获得93%的相对提升

Conclusion: 学习verbalization是提升LLM推荐系统性能的关键，框架揭示了用户兴趣总结、噪声去除、语法标准化等有效策略，为LLM推荐系统的上下文构建提供新见解

Abstract: Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate fields, yielding suboptimal representations for recommendation. We propose a data-centric framework that learns verbalization for LLM-based recommendation. Using reinforcement learning, a verbalization agent transforms raw interaction histories into optimized textual contexts, with recommendation accuracy as the training signal. This agent learns to filter noise, incorporate relevant metadata, and reorganize information to improve downstream predictions. Experiments on a large-scale industrial streaming dataset show that learned verbalization delivers up to 93% relative improvement in discovery item recommendation accuracy over template-based baselines. Further analysis reveals emergent strategies such as user interest summarization, noise removal, and syntax normalization, offering insights into effective context construction for LLM-based recommender systems.

</details>


### [15] [CausalReasoningBenchmark: A Real-World Benchmark for Disentangled Evaluation of Causal Identification and Estimation](https://arxiv.org/abs/2602.20571)
*Ayush Sawarni,Jiyuan Tan,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 提出了CausalReasoningBenchmark，一个包含173个查询、138个真实数据集的因果推理基准，将识别（研究设计）与估计（数值计算）分开评估，揭示当前LLM在因果推理中的瓶颈在于研究设计的细节而非计算。


<details>
  <summary>Details</summary>
Motivation: 现有因果推理基准通常基于单一数值输出（如平均处理效应ATE）评估系统性能，这混淆了因果分析的两个关键步骤：识别（在给定假设下制定有效研究设计）和估计（在有限数据上数值实现该设计）。需要区分这两种能力以进行更精细的诊断。

Method: 构建了CausalReasoningBenchmark基准，包含173个查询，覆盖138个真实数据集，来源于85篇同行评审研究论文和4本广泛使用的因果推理教材。对每个查询，系统必须输出：(1)结构化识别规范（策略、处理、结果、控制变量等设计要素），(2)点估计和标准误。分别对这两个组件进行评分。

Result: 使用最先进的LLM进行基线测试显示：模型在84%的情况下能正确识别高层次策略，但完整的识别规范正确率仅30%，表明瓶颈在于研究设计的细节而非数值计算。基准已在Hugging Face公开可用。

Conclusion: CausalReasoningBenchmark通过分离识别和评估，能够区分因果推理失败和数值执行错误，有助于开发更稳健的自动化因果推理系统。当前LLM的主要挑战在于研究设计的细节把握而非计算能力。

Abstract: Many benchmarks for automated causal inference evaluate a system's performance based on a single numerical output, such as an Average Treatment Effect (ATE). This approach conflates two distinct steps in causal analysis: identification-formulating a valid research design under stated assumptions-and estimation-implementing that design numerically on finite data. We introduce CausalReasoningBenchmark, a benchmark of 173 queries across 138 real-world datasets, curated from 85 peer-reviewed research papers and four widely-used causal-inference textbooks. For each query a system must produce (i) a structured identification specification that names the strategy, the treatment, outcome, and control variables, and all design-specific elements, and (ii) a point estimate with a standard error. By scoring these two components separately, our benchmark enables granular diagnosis: it distinguishes failures in causal reasoning from errors in numerical execution. Baseline results with a state-of-the-art LLM show that, while the model correctly identifies the high-level strategy in 84 % of cases, full identification-specification correctness drops to only 30 %, revealing that the bottleneck lies in the nuanced details of research design rather than in computation. CausalReasoningBenchmark is publicly available on Hugging Face and is designed to foster the development of more robust automated causal-inference systems.

</details>


### [16] [Physics-based phenomenological characterization of cross-modal bias in multimodal models](https://arxiv.org/abs/2602.20624)
*Hyeongmo Kim,Sohyun Kang,Yerin Choi,Seungyeon Ji,Junhyuk Woo,Hyunsuk Chung,Soyeon Caren Han,Kyungreem Han*

Main category: cs.AI

TL;DR: 该立场论文提出使用现象学可解释方法分析多模态大语言模型中的算法公平性问题，通过基于物理的代理模型分析跨模态偏见动态，发现多模态输入可能强化模态主导而非缓解偏见。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在理解和生成方面取得进展，但复杂的多模态交互动态可能导致系统性偏见。传统认知符号方法或形而上学方法无法充分捕捉这些偏见动态，需要现象学可解释方法来处理MLLMs中的算法公平性问题。

Method: 1) 开发基于物理的代理模型描述transformer动态（语义网络结构和自/交叉注意力）来分析跨模态偏见；2) 多输入诊断实验：a) 使用Qwen2.5-Omni和Gemma 3n进行基于扰动的情绪分类分析，b) 通过物理代理模型对Lorenz混沌时间序列预测进行动态分析。

Result: 在两个架构不同的MLLMs中，多模态输入可能强化模态主导而非缓解偏见，这通过系统标签扰动下的结构化错误吸引子模式以及动态分析得到揭示。

Conclusion: 现象学方法为分析MLLMs中的算法公平性问题提供了实用框架，基于物理的代理模型能够揭示传统嵌入或表示层面分析无法捕捉的跨模态偏见动态，多模态输入可能意外地强化而非减轻偏见。

Abstract: The term 'algorithmic fairness' is used to evaluate whether AI models operate fairly in both comparative (where fairness is understood as formal equality, such as "treat like cases as like") and non-comparative (where unfairness arises from the model's inaccuracy, arbitrariness, or inscrutability) contexts. Recent advances in multimodal large language models (MLLMs) are breaking new ground in multimodal understanding, reasoning, and generation; however, we argue that inconspicuous distortions arising from complex multimodal interaction dynamics can lead to systematic bias. The purpose of this position paper is twofold: first, it is intended to acquaint AI researchers with phenomenological explainable approaches that rely on the physical entities that the machine experiences during training/inference, as opposed to the traditional cognitivist symbolic account or metaphysical approaches; second, it is to state that this phenomenological doctrine will be practically useful for tackling algorithmic fairness issues in MLLMs. We develop a surrogate physics-based model that describes transformer dynamics (i.e., semantic network structure and self-/cross-attention) to analyze the dynamics of cross-modal bias in MLLM, which are not fully captured by conventional embedding- or representation-level analyses. We support this position through multi-input diagnostic experiments: 1) perturbation-based analyses of emotion classification using Qwen2.5-Omni and Gemma 3n, and 2) dynamical analysis of Lorenz chaotic time-series prediction through the physical surrogate. Across two architecturally distinct MLLMs, we show that multimodal inputs can reinforce modality dominance rather than mitigate it, as revealed by structured error-attractor patterns under systematic label perturbation, complemented by dynamical analysis.

</details>


### [17] [When can we trust untrusted monitoring? A safety case sketch across collusion strategies](https://arxiv.org/abs/2602.20628)
*Nelson Gardner-Challis,Jonathan Bostock,Georgiy Kozhevnikov,Morgan Sinclaire,Joan Velja,Alessandro Abate,Charlie Griffin*

Main category: cs.AI

TL;DR: 本文探讨了不可信监控（使用一个不可信模型监督另一个）的安全性评估方法，放宽了先前AI控制研究中关于AI串谋策略的假设，提出了更全面的串谋策略分类，并构建了安全论证框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI自主性和能力的增强，错位AI可能造成灾难性伤害的风险增加。不可信监控是降低风险的一种方法，但由于无法安全部署错位模型直接测试协议，证明其安全性具有挑战性。

Method: 1. 基于部署前测试的严格安全演示方法；2. 放宽先前AI控制研究中关于AI串谋策略的假设；3. 开发涵盖被动自我识别、因果串谋、非因果串谋和组合策略的分类法；4. 创建安全案例草图来清晰呈现论证。

Result: 识别了被动自我识别可能比先前研究的串谋策略更有效的情况，构建了更稳健的不可信监控评估框架，明确了假设并突出了未解决的挑战。

Conclusion: 本文为不可信监控的安全性评估提供了更全面的框架，通过放宽串谋策略假设和系统化分类，推动了更稳健的AI安全评估方法的发展，但仍存在未解决的挑战需要进一步研究。

Abstract: AIs are increasingly being deployed with greater autonomy and capabilities, which increases the risk that a misaligned AI may be able to cause catastrophic harm. Untrusted monitoring -- using one untrusted model to oversee another -- is one approach to reducing risk. Justifying the safety of an untrusted monitoring deployment is challenging because developers cannot safely deploy a misaligned model to test their protocol directly. In this paper, we develop upon existing methods for rigorously demonstrating safety based on pre-deployment testing. We relax assumptions that previous AI control research made about the collusion strategies a misaligned AI might use to subvert untrusted monitoring. We develop a taxonomy covering passive self-recognition, causal collusion (hiding pre-shared signals), acausal collusion (hiding signals via Schelling points), and combined strategies. We create a safety case sketch to clearly present our argument, explicitly state our assumptions, and highlight unsolved challenges. We identify conditions under which passive self-recognition could be a more effective collusion strategy than those studied previously. Our work builds towards more robust evaluations of untrusted monitoring.

</details>


### [18] [Identifying two piecewise linear additive value functions from anonymous preference information](https://arxiv.org/abs/2602.20638)
*Vincent Auriau,Khaled Belahcene,Emmanuel Malherbe,Vincent Mousseau,Marc Pirlot*

Main category: cs.AI

TL;DR: 提出一种同时向两位决策者提问的偏好诱导方法，在不知道哪个回答对应哪个决策者的情况下，识别出两个加性价值函数模型


<details>
  <summary>Details</summary>
Motivation: 在同时向多位决策者提问时，虽然能获得多个回答，但不知道哪个回答对应哪个决策者。需要开发一种方法能够在不知道回答归属的情况下，同时识别出多个决策者的偏好模型。

Method: 假设偏好可以用加性价值函数表示，边际价值函数是分段线性的且断点已知。通过同时向两位决策者提问，获得两个无噪声的回答，但不知道回答的归属。设计一种诱导程序来识别两个偏好模型。

Result: 提出的方法能够在不知道回答对应关系的情况下，成功识别出两位决策者的加性价值函数模型，前提是边际价值函数是分段线性的且断点已知。

Conclusion: 该方法解决了同时诱导多位决策者偏好时的回答归属问题，为群体决策分析提供了新的技术手段，特别是在无法追踪回答来源的场景下。

Abstract: Eliciting a preference model involves asking a person, named decision-maker, a series of questions. We assume that these preferences can be represented by an additive value function. In this work, we query simultaneously two decision-makers in the aim to elicit their respective value functions. For each query we receive two answers, without noise, but without knowing which answer corresponds to which decision-maker.We propose an elicitation procedure that identifies the two preference models when the marginal value functions are piecewise linear with known breaking points.

</details>


### [19] [Grounding LLMs in Scientific Discovery via Embodied Actions](https://arxiv.org/abs/2602.20639)
*Bo Zhang,Jinfeng Zhou,Yuxuan Chen,Jianing Yin,Minlie Huang,Hongning Wang*

Main category: cs.AI

TL;DR: EmbodiedAct框架将科学软件转化为具身智能体，通过紧密的感知-执行循环让LLM在物理仿真中具备运行时感知能力，解决现有方法无法处理瞬态异常的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在科学发现中潜力显著，但难以弥合理论推理与可验证物理仿真之间的鸿沟。现有解决方案采用被动的"执行-响应"循环，缺乏运行时感知能力，导致智能体无法察觉瞬态异常（如数值不稳定或发散振荡）。

Method: 提出EmbodiedAct框架，将成熟的科学软件转化为主动的具身智能体，通过将LLM与具身行动相结合，建立紧密的感知-执行循环。在MATLAB环境中实现该框架。

Result: 在复杂的工程设计和科学建模任务上的大量实验表明，EmbodiedAct显著优于现有基线方法，在长时程仿真中确保满意的可靠性和稳定性，在科学建模中提高准确性，达到SOTA性能。

Conclusion: EmbodiedAct通过将科学软件转化为具身智能体并建立紧密的感知-执行循环，成功解决了LLM在物理仿真中缺乏运行时感知的问题，为科学发现提供了更可靠和稳定的框架。

Abstract: Large Language Models (LLMs) have shown significant potential in scientific discovery but struggle to bridge the gap between theoretical reasoning and verifiable physical simulation. Existing solutions operate in a passive "execute-then-response" loop and thus lacks runtime perception, obscuring agents to transient anomalies (e.g., numerical instability or diverging oscillations). To address this limitation, we propose EmbodiedAct, a framework that transforms established scientific software into active embodied agents by grounding LLMs in embodied actions with a tight perception-execution loop. We instantiate EmbodiedAct within MATLAB and evaluate it on complex engineering design and scientific modeling tasks. Extensive experiments show that EmbodiedAct significantly outperforms existing baselines, achieving SOTA performance by ensuring satisfactory reliability and stability in long-horizon simulations and enhanced accuracy in scientific modeling.

</details>


### [20] [Recursive Belief Vision Language Model](https://arxiv.org/abs/2602.20659)
*Vaidehi Bagaria,Bijo Sebastian,Nirav Patel*

Main category: cs.AI

TL;DR: RB-VLA提出了一种基于信念的视觉语言动作模型架构，通过自监督世界模型目标维护紧凑的潜在状态表示，显著提升了长时程操作任务在部分可观测环境下的性能，同时大幅降低了推理延迟和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型在部分可观测环境下的长时程操作任务中存在三个主要问题：1）依赖短上下文窗口或重复查询导致任务进度丢失；2）感知混淆下的动作重复；3）高推理延迟。这些问题的根源在于缺乏持久、动作条件的状态表示，以及有限的时空和物理推理能力。

Method: RB-VLA采用信念中心架构，通过自监督世界模型目标训练，维护一个紧凑的潜在状态编码，包含任务相关历史、动态和物体交互信息。VLM仅被查询一次以获取高层意图，信念模块跟踪任务进度，并在部分可观测环境下实现阶段感知、因果基础的控制。信念和意图共同条件化扩散策略进行闭环执行。

Result: RB-VLA在长时程基准测试中优于现有VLA模型：多阶段拾放任务成功率提高52.5%，堆叠任务提高37.5%（相比π0）。推理延迟降低高达5倍，消除了现有VLA中随时间步长增加的内存增长。消融实验显示信念模块是性能提升的主要驱动力，将成功率从32.5%提升到77.5%。

Conclusion: 基于信念的状态表示对于长时程VLA策略是有效的。RB-VLA通过维护紧凑的潜在状态表示，解决了现有VLA模型在部分可观测环境下长时程操作中的核心问题，显著提升了性能、效率和内存使用效率。

Abstract: Current vision-language-action (VLA) models struggle with long-horizon manipulation under partial observability. Most existing approaches remain observation-driven, relying on short context windows or repeated queries to vision-language models (VLMs). This leads to loss of task progress, action repetition under perceptual aliasing, and high inference latency. Semantic reasoning alone is not the primary bottleneck in long-horizon manipulation. Instead, VLAs lack persistent, action-conditioned state representations and exhibit limited temporal and physical reasoning, making them ill-suited for multi-stage control. This paper introduces RB-VLA, a belief-centric architecture trained with self-supervised world-model objectives that maintains a compact latent state encoding task-relevant history, dynamics, and object interactions. Queried once for high-level intent, the VLM provides task specification, while the belief tracks task progress and enables phase-aware, causally grounded control under partial observability without storing raw observations or scaling memory with time. The belief and intent jointly condition a diffusion policy for robust closed-loop execution. RB-VLA outperforms prior VLAs on long-horizon benchmarks, achieving 52.5% and 37.5% higher success on multi-stage pick-and-place and stacking tasks, respectively, compared to π0. It also reduces inference latency by up to 5x relative to baselines and eliminates memory growth across timesteps observed in existing VLAs. Ablations show that the belief module is the primary driver of performance, increasing success rates from 32.5% to 77.5%. These results demonstrate the effectiveness of belief-based state representations for long-horizon VLA policies.

</details>


### [21] [How Foundational Skills Influence VLM-based Embodied Agents:A Native Perspective](https://arxiv.org/abs/2602.20687)
*Bo Peng,Pi Bu,Keyu Pan,Xinrun Xu,Yinxiu Zhao,Miao Chen,Yang Du,Lin Li,Jun Song,Tong Xu*

Main category: cs.AI

TL;DR: NativeEmbodied是一个用于视觉语言模型驱动的具身智能体的新基准测试，采用统一的低层原生动作空间，包含高层任务和低层技能解耦任务，用于细粒度评估。


<details>
  <summary>Details</summary>
Motivation: 现有VLM驱动的具身智能体基准测试存在两个主要问题：1）依赖高层指令或离散化动作空间，这与真实世界控制场景不同；2）主要关注高层任务，缺乏对低层和高层能力的联合评估分析。

Method: 构建NativeEmbodied基准测试，基于多样化模拟场景，包含三类代表性高层复杂任务，同时解耦复杂任务所需技能，构建四类低层基础技能任务，实现任务和技能粒度的联合评估。

Result: 实验表明当前最先进的VLM在多个基础具身技能上存在明显缺陷，进一步分析显示这些瓶颈显著限制了高层任务的性能表现。

Conclusion: NativeEmbodied揭示了当前VLM驱动具身智能体的关键挑战，为未来研究提供了指导性见解，强调了低层技能对高层任务性能的重要性。

Abstract: Recent advances in vision-language models (VLMs) have shown promise for human-level embodied intelligence. However, existing benchmarks for VLM-driven embodied agents often rely on high-level commands or discretized action spaces, which are non-native settings that differ markedly from real-world control. In addition, current benchmarks focus primarily on high-level tasks and lack joint evaluation and analysis at both low and high levels. To address these limitations, we present NativeEmbodied, a challenging benchmark for VLM-driven embodied agents that uses a unified, native low-level action space. Built on diverse simulated scenes, NativeEmbodied includes three representative high-level tasks in complex scenarios to evaluate overall performance. For more detailed analysis, we further decouple the skills required by complex tasks and construct four types of low-level tasks, each targeting a fundamental embodied skill. This joint evaluation across task and skill granularities enables fine-grained assessment of embodied agents. Experiments with state-of-the-art VLMs reveal clear deficiencies in several fundamental embodied skills, and further analysis shows that these bottlenecks significantly limit performance on high-level tasks. NativeEmbodied highlights key challenges for current VLM-driven embodied agents and provides insights to guide future research.

</details>


### [22] [PromptCD: Test-Time Behavior Enhancement via Polarity-Prompt Contrastive Decoding](https://arxiv.org/abs/2602.20696)
*Baolong Bi,Yuyao Ge,Shenghua Liu,Yuchen He,Siqian Tong,Lizhe Chen,Lingrui Mei,Zehao Li,Yiwei Wang,Yujun Cai,Ming-Hsuan Yang,Xueqi Cheng*

Main category: cs.AI

TL;DR: 提出PromptCD方法，通过构建正负引导提示对比模型响应，在测试时控制LLM和VLM的行为对齐，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法多在训练时进行，需要高质量数据和计算成本高。对比解码方法适用范围有限，需要更通用的测试时行为控制方法。

Method: PromptCD构建目标行为的正负引导提示对，对比模型响应（LLM中的token概率分布和VLM中的视觉注意力模式），强化期望结果。

Result: 在LLM的"3H"对齐目标上取得显著改进；在VLM中提升VQA性能，通过强化行为一致的视觉基础。

Conclusion: PromptCD是一种简单、通用、成本高效的跨模态可靠行为控制策略，支持测试时自我增强。

Abstract: Reliable AI systems require large language models (LLMs) to exhibit behaviors aligned with human preferences and values. However, most existing alignment approaches operate at training time and rely on additional high-quality data, incurring significant computational and annotation costs. While recent work has shown that contrastive decoding can leverage a model's internal distributions to improve specific capabilities, its applicability remains limited to narrow behavioral scopes and scenarios. In this work, we introduce Polarity-Prompt Contrastive Decoding (PromptCD), a test-time behavior control method that generalizes contrastive decoding to broader enhancement settings. PromptCD constructs paired positive and negative guiding prompts for a target behavior and contrasts model responses-specifically token-level probability distributions in LLMs and visual attention patterns in VLMs-to reinforce desirable outcomes. This formulation extends contrastive decoding to a wide range of enhancement objectives and is applicable to both LLMs and Vision-Language Models (VLMs) without additional training. For LLMs, experiments on the "3H" alignment objectives (helpfulness, honesty, and harmlessness) demonstrate consistent and substantial improvements, indicating that post-trained models can achieve meaningful self-enhancement purely at test time. For VLMs, we further analyze contrastive effects on visual attention, showing that PromptCD significantly improves VQA performance by reinforcing behavior-consistent visual grounding. Collectively, these results highlight PromptCD as a simple, general, and cost-efficient strategy for reliable behavior control across modalities.

</details>


### [23] [Online Algorithms with Unreliable Guidance](https://arxiv.org/abs/2602.20706)
*Julien Dallot,Yuval Emek,Yuval Gil,Maciej Pacut,Stefan Schmid*

Main category: cs.AI

TL;DR: 提出在线算法不可靠指导(OAG)模型，将预测与算法组件完全分离，通过DTB编译器将任何在线算法转换为学习增强版本，在缓存、度量任务系统和二分图匹配问题上取得最优或先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习增强的在线决策模型通常将预测和算法组件紧密耦合，缺乏统一的分析框架。本文旨在建立一个分离预测和算法的通用模型，使分析仅依赖于问题本身，而非特定的损失函数。

Method: 提出OAG模型：将在线决策建模为请求-回答游戏，算法接收来自答案空间的指导（可能被对抗性污染）。开发DTB编译器，将任何在线算法转换为学习增强版本，通过有偏硬币决定是盲目跟随指导还是忽略它。

Result: DTB编译器生成的算法在三个经典在线问题上表现优异：对于缓存和均匀度量任务系统达到最优性能；对于二分图匹配（对抗性到达顺序）超越现有最佳算法。

Conclusion: OAG模型为机器学习增强的在线决策提供了统一的分析框架，DTB编译器提供了一种简单而强大的方法将传统在线算法转换为具有良好一致性和鲁棒性的学习增强算法。

Abstract: This paper introduces a new model for ML-augmented online decision making, called online algorithms with unreliable guidance (OAG). This model completely separates between the predictive and algorithmic components, thus offering a single well-defined analysis framework that relies solely on the considered problem. Formulated through the lens of request-answer games, an OAG algorithm receives, with each incoming request, a piece of guidance which is taken from the problem's answer space; ideally, this guidance is the optimal answer for the current request, however with probability $β$, the guidance is adversarially corrupted. The goal is to develop OAG algorithms that admit good competitiveness when $β= 0$ (a.k.a. consistency) as well as when $β= 1$ (a.k.a. robustness); the appealing notion of smoothness, that in most prior work required a dedicated loss function, now arises naturally as $β$ shifts from $0$ to $1$.
  We then describe a systematic method, called the drop or trust blindly (DTB) compiler, which transforms any online algorithm into a learning-augmented online algorithm in the OAG model. Given a prediction-oblivious online algorithm, its learning-augmented counterpart produced by applying the DTB compiler either follows the incoming guidance blindly or ignores it altogether and proceeds as the initial algorithm would have; the choice between these two alternatives is based on the outcome of a (biased) coin toss. As our main technical contribution, we prove (rigorously) that although remarkably simple, the class of algorithms produced via the DTB compiler includes algorithms with attractive consistency-robustness guarantees for three classic online problems: for caching and uniform metrical task systems our algorithms are optimal, whereas for bipartite matching (with adversarial arrival order), our algorithm outperforms the state-of-the-art.

</details>


### [24] [ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction](https://arxiv.org/abs/2602.20708)
*Che Wang,Fuyao Zhang,Jiaming Zhang,Ziqi Zhang,Yinghui Wang,Longtao Huang,Jianbo Gao,Zhong Chen,Wei Yang Bryan Lim*

Main category: cs.AI

TL;DR: ICON是一个探测-缓解框架，通过检测潜在空间中的过度聚焦特征来防御间接提示注入攻击，同时保持任务连续性。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法（如严格过滤或拒绝机制）存在过度拒绝的问题，会过早终止有效的代理工作流程。需要一种既能防御攻击又能保持任务连续性的解决方案。

Method: 提出ICON框架：1）潜在空间轨迹探测器检测攻击，基于高强度分数识别过度聚焦特征；2）缓解矫正器进行手术式注意力引导，选择性操纵对抗性查询键依赖关系，同时放大任务相关元素以恢复LLM的功能轨迹。

Result: 在多个骨干模型上的评估显示，ICON实现了0.4%的攻击成功率（ASR），与商业级检测器相当，同时带来超过50%的任务效用增益。在分布外泛化和多模态代理扩展方面也表现出色。

Conclusion: ICON在安全性和效率之间建立了优越的平衡，能够有效防御间接提示注入攻击，同时保持代理工作流程的连续性。

Abstract: Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical limitation: over-refusal, prematurely terminating valid agentic workflows. We propose ICON, a probing-to-mitigation framework that neutralizes attacks while preserving task continuity. Our key insight is that IPI attacks leave distinct over-focusing signatures in the latent space. We introduce a Latent Space Trace Prober to detect attacks based on high intensity scores. Subsequently, a Mitigating Rectifier performs surgical attention steering that selectively manipulate adversarial query key dependencies while amplifying task relevant elements to restore the LLM's functional trajectory. Extensive evaluations on multiple backbones show that ICON achieves a competitive 0.4% ASR, matching commercial grade detectors, while yielding a over 50% task utility gain. Furthermore, ICON demonstrates robust Out of Distribution(OOD) generalization and extends effectively to multi-modal agents, establishing a superior balance between security and efficiency.

</details>


### [25] [Counterfactual Simulation Training for Chain-of-Thought Faithfulness](https://arxiv.org/abs/2602.20710)
*Peter Hase,Christopher Potts*

Main category: cs.AI

TL;DR: 提出Counterfactual Simulation Training (CST)训练方法，通过奖励能够准确预测模型在反事实输入上输出的思维链，来提高思维链的忠实性。


<details>
  <summary>Details</summary>
Motivation: 当前思维链推理存在忠实性问题，限制了通过检查思维链来理解模型输出的有效性。需要一种方法来提高思维链的忠实性，使其能更可靠地反映模型的推理过程。

Method: 提出CST训练方法，在两种设置下应用：1) 基于线索的反事实进行思维链监控，检测模型是否依赖虚假特征、奖励黑客或奉承行为；2) 基于通用模型的反事实模拟，鼓励模型产生更忠实、可泛化的思维链推理。

Result: 在高达235B参数的模型上实验表明，CST显著提高了基于线索反事实的监控准确率（提升35个百分点）和通用反事实的可模拟性（提升2个百分点）。CST优于提示基线，用LLM重写不忠实思维链比单独使用RL效率高5倍。

Conclusion: CST能有效提高思维链的忠实性，在思维链监控方面有良好应用前景。大模型本身并不天生具有更忠实的思维链，但能从CST中获益更多。

Abstract: Inspecting Chain-of-Thought reasoning is among the most common means of understanding why an LLM produced its output. But well-known problems with CoT faithfulness severely limit what insights can be gained from this practice. In this paper, we introduce a training method called Counterfactual Simulation Training (CST), which aims to improve CoT faithfulness by rewarding CoTs that enable a simulator to accurately predict a model's outputs over counterfactual inputs. We apply CST in two settings: (1) CoT monitoring with cue-based counterfactuals, to detect when models rely on spurious features, reward hack, or are sycophantic, and (2) counterfactual simulation over generic model-based counterfactuals, to encourage models to produce more faithful, generalizable reasoning in the CoT. Experiments with models up to 235B parameters show that CST can substantially improve monitor accuracy on cue-based counterfactuals (by 35 accuracy points) as well as simulatability over generic counterfactuals (by 2 points). We further show that: (1) CST outperforms prompting baselines, (2) rewriting unfaithful CoTs with an LLM is 5x more efficient than RL alone, (3) faithfulness improvements do not generalize to dissuading cues (as opposed to persuading cues), and (4) larger models do not show more faithful CoT out of the box, but they do benefit more from CST. These results suggest that CST can improve CoT faithfulness in general, with promising applications for CoT monitoring. Code for experiments in this paper is available at https://github.com/peterbhase/counterfactual-simulation-training

</details>


### [26] [Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning](https://arxiv.org/abs/2602.20722)
*Xu Wan,Yansheng Wang,Wenqi Huang,Mingyang Sun*

Main category: cs.AI

TL;DR: BAPO是一种离线策略的RLVR框架，通过动态选择训练批次来提高大语言模型后训练的数据效率，相比GRPO平均提升12.5%


<details>
  <summary>Details</summary>
Motivation: 传统的在线策略RLVR框架存在经验浪费和奖励同质化问题，这直接阻碍了在大语言模型后训练中对困难样本的学习效率

Method: 提出Batch Adaptation Policy Optimization (BAPO)，通过重新评估历史困难样本并重用高质量样本动态选择训练批次，同时保持策略改进的下界保证

Result: 在数学、规划和视觉推理任务上，BAPO相比GRPO平均提升12.5%，成功解决了基础模型持续失败的40.7%的问题

Conclusion: BAPO通过改进数据效率有效解决了传统RLVR框架的局限性，显著提升了大语言模型后训练的性能

Abstract: Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.

</details>


### [27] [Modality-Guided Mixture of Graph Experts with Entropy-Triggered Routing for Multimodal Recommendation](https://arxiv.org/abs/2602.20723)
*Ji Dai,Quan Fang,Dengsheng Cai*

Main category: cs.AI

TL;DR: MAGNET提出了一种模态引导的混合自适应图专家网络，通过渐进熵触发路由解决多模态推荐中的异质性和冲突问题，实现可控、稳定和可解释的融合。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐通过整合用户-物品交互和物品内容来提升排序效果，尤其在稀疏反馈和长尾分布场景下有效。然而多模态信号本质上是异质的，在特定上下文中可能冲突，使得有效融合既关键又具挑战性。现有方法通常依赖共享融合路径，导致表示纠缠和模态不平衡。

Method: MAGNET采用双视图图学习模块增强交互图，通过内容诱导边改善稀疏和长尾物品覆盖，同时通过并行编码和轻量融合保持协同结构。在融合层面，使用具有明确模态角色（主导、平衡、互补）的结构化专家，实现更可解释和自适应的行为、视觉和文本线索组合。引入两阶段熵加权机制监控路由熵，自动从早期覆盖导向训练过渡到后期专业化导向训练。

Result: 在公共基准测试上的广泛实验表明，相比强基线模型取得了持续改进。

Conclusion: MAGNET通过交互条件专家路由和结构感知图增强，明确控制"融合什么"和"如何融合"，增强了多模态融合的可控性、稳定性和可解释性。

Abstract: Multimodal recommendation enhances ranking by integrating user-item interactions with item content, which is particularly effective under sparse feedback and long-tail distributions. However, multimodal signals are inherently heterogeneous and can conflict in specific contexts, making effective fusion both crucial and challenging. Existing approaches often rely on shared fusion pathways, leading to entangled representations and modality imbalance. To address these issues, we propose \textbf{MAGNET}, a \textbf{M}odality-Guided Mixture of \textbf{A}daptive \textbf{G}raph Experts \textbf{N}etwork with Progressive \textbf{E}ntropy-\textbf{T}riggered Routing for Multimodal Recommendation, designed to enhance controllability, stability, and interpretability in multimodal fusion. MAGNET couples interaction-conditioned expert routing with structure-aware graph augmentation, so that both \emph{what} to fuse and \emph{how} to fuse are explicitly controlled and interpretable. At the representation level, a dual-view graph learning module augments the interaction graph with content-induced edges, improving coverage for sparse and long-tail items while preserving collaborative structure via parallel encoding and lightweight fusion. At the fusion level, MAGNET employs structured experts with explicit modality roles -- dominant, balanced, and complementary -- enabling a more interpretable and adaptive combination of behavioral, visual, and textual cues. To further stabilize sparse routing and prevent expert collapse, we introduce a two-stage entropy-weighting mechanism that monitors routing entropy. This mechanism automatically transitions training from an early coverage-oriented regime to a later specialization-oriented regime, progressively balancing expert utilization and routing confidence. Extensive experiments on public benchmarks demonstrate consistent improvements over strong baselines.

</details>


### [28] [Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback](https://arxiv.org/abs/2602.20728)
*Chenyang Zhao,Vinny Cahill,Ivana Dusparic*

Main category: cs.AI

TL;DR: 该论文探索将基于AI反馈的强化学习（RLAIF）扩展到多目标自适应系统，通过大语言模型生成偏好标签，避免繁琐的奖励设计，实现反映不同用户优先级的平衡策略。


<details>
  <summary>Details</summary>
Motivation: 在多目标强化学习部署中，奖励设计是核心挑战，特别是在目标冲突时难以指定权衡关系。现有RLAIF工作主要关注单目标任务，多目标系统中策略容易偏向主导目标，需要探索RLAIF在多目标场景的应用。

Method: 将RLAIF范式扩展到多目标自适应系统，利用大语言模型（LLMs）生成偏好标签替代人工标注，通过AI反馈学习多目标策略，避免复杂的奖励工程。

Result: 多目标RLAIF能够产生反映不同用户优先级的平衡权衡策略，无需繁琐的奖励设计，展示了在多目标冲突领域中实现用户对齐策略学习的可行性。

Conclusion: 将RLAIF集成到多目标强化学习中，为具有内在冲突目标的领域提供了一条可扩展的用户对齐策略学习路径，解决了多目标系统中的权衡难题。

Abstract: Reward design has been one of the central challenges for real world reinforcement learning (RL) deployment, especially in settings with multiple objectives. Preference-based RL offers an appealing alternative by learning from human preferences over pairs of behavioural outcomes. More recently, RL from AI feedback (RLAIF) has demonstrated that large language models (LLMs) can generate preference labels at scale, mitigating the reliance on human annotators. However, existing RLAIF work typically focuses only on single-objective tasks, leaving the open question of how RLAIF handles systems that involve multiple objectives. In such systems trade-offs among conflicting objectives are difficult to specify, and policies risk collapsing into optimizing for a dominant goal. In this paper, we explore the extension of the RLAIF paradigm to multi-objective self-adaptive systems. We show that multi-objective RLAIF can produce policies that yield balanced trade-offs reflecting different user priorities without laborious reward engineering. We argue that integrating RLAIF into multi-objective RL offers a scalable path toward user-aligned policy learning in domains with inherently conflicting objectives.

</details>


### [29] [CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference](https://arxiv.org/abs/2602.20732)
*Chao Fei,Guozhong Li,Chenxi Liu,Panos Kalnis*

Main category: cs.AI

TL;DR: CHESS是一种算法-系统协同设计的KV缓存管理系统，通过上下文感知的分层选择策略，仅用1%的KV缓存就能达到完整KV缓存的质量，实现高达4.56倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM在低延迟推理时，KV缓存成为主要瓶颈。现有剪枝方法大多是上下文无关的：它们忽略token的逐步相关性和局部语义，导致质量下降，且不规则访问和选择开销只能带来有限的加速。

Method: CHESS采用算法-系统协同设计：算法上引入上下文感知的分层选择策略，动态重构当前解码的连贯上下文；系统上采用粗粒度选择消除昂贵的数据移动，充分实现理论稀疏性的实际加速。

Result: CHESS仅使用1%的KV缓存就能超越完整KV缓存的质量，提供低延迟稳定推理，吞吐量最高提升4.56倍，并持续优于其他强基线方法。

Conclusion: CHESS通过算法-系统协同设计有效解决了长上下文LLM中KV缓存管理的挑战，在保持质量的同时显著提升了推理效率。

Abstract: Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \textbf{CHESS}, an \textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \textbf{1\%} of the KV cache, delivers low-latency stable inference with up to \textbf{4.56$\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.

</details>


### [30] [PyVision-RL: Forging Open Agentic Vision Models via RL](https://arxiv.org/abs/2602.20739)
*Shitian Zhao,Shaoheng Lin,Ming Li,Haoquan Zhang,Wenshuo Peng,Kaipeng Zhang,Chen Wei*

Main category: cs.AI

TL;DR: 提出了PyVision-RL框架，通过过采样-过滤-排序策略和累积工具奖励防止交互崩溃，开发了PyVision-Image和PyVision-Video模型，在视频理解中采用按需上下文构建减少视觉token使用。


<details>
  <summary>Details</summary>
Motivation: 多模态智能体模型在强化学习中常出现交互崩溃问题，模型倾向于减少工具使用和多轮推理，限制了智能体行为的优势。

Method: 提出PyVision-RL强化学习框架，结合过采样-过滤-排序策略和累积工具奖励防止交互崩溃；开发统一训练流程，创建PyVision-Image和PyVision-Video模型；在视频推理中采用按需上下文构建，选择性采样任务相关帧。

Result: 实验显示PyVision模型表现出强大性能和改进的效率，证明了持续交互和按需视觉处理对可扩展多模态智能体的重要性。

Conclusion: 持续交互和按需视觉处理是构建可扩展多模态智能体的关键要素，PyVision-RL框架能有效防止交互崩溃并促进多轮工具使用。

Abstract: Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.

</details>


### [31] [Pipeline for Verifying LLM-Generated Mathematical Solutions](https://arxiv.org/abs/2602.20770)
*Varvara Sazonova,Dmitri Shmelkin,Stanislav Kikot,Vasily Motolygin*

Main category: cs.AI

TL;DR: 提出一个用于验证大型推理模型数学问题解决能力的自动化交互式验证管道，替代仅检查答案的传统基准测试方法


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型在解决数学问题方面的普及，需要更准确的能力评估方法。当前基准测试主要依赖答案检查，不够精确，需要更可靠的验证机制。

Method: 设计包含自动和交互式验证的管道，通过特定格式的提示获取解决方案，便于使用证明助手验证，并可利用小型模型（≤8B）。管道包含3个AI代理，支持生成正式和非正式语言的正确解决方案。

Result: 在多个数据集上的实验表明，该方法的误报概率较低。开源实现已提供，包含服务器设置说明。

Conclusion: 该验证管道为评估大型推理模型的数学推理能力提供了更准确的方法，能够生成可验证的解决方案，并支持小型模型的有效利用。

Abstract: With the growing popularity of Large Reasoning Models and their results in solving mathematical problems, it becomes crucial to measure their capabilities. We introduce a pipeline for both automatic and interactive verification as a more accurate alternative to only checking the answer which is currently the most popular approach for benchmarks. The pipeline can also be used as a generator of correct solutions both in formal and informal languages. 3 AI agents, which can be chosen for the benchmark accordingly, are included in the structure. The key idea is the use of prompts to obtain the solution in the specific form which allows for easier verification using proof assistants and possible use of small models ($\le 8B$). Experiments on several datasets suggest low probability of False Positives. The open-source implementation with instructions on setting up a server is available at https://github.com/LogicEnj/lean4_verification_pipeline.

</details>


### [32] [POMDPPlanners: Open-Source Package for POMDP Planning](https://arxiv.org/abs/2602.20810)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: POMDPPlanners是一个用于POMDP规划算法实证评估的开源Python包，集成了先进算法、基准环境、自动超参数优化和并行仿真功能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够支持大规模、可重复的POMDP规划算法研究的工具包，特别是在风险敏感场景下，标准工具包存在不足。

Method: 开发了一个集成化的Python包，包含：1）先进的规划算法；2）带有安全关键变体的基准环境套件；3）通过Optuna进行自动超参数优化；4）具有故障恢复的持久缓存；5）可配置的并行仿真。

Result: 该包显著减少了大规模仿真研究的开销，支持在不确定性下进行可扩展、可重复的决策研究，特别是在风险敏感场景中。

Conclusion: POMDPPlanners填补了POMDP规划算法实证评估工具的空缺，为决策不确定性研究提供了强大、可扩展的平台。

Abstract: We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to enable scalable, reproducible research on decision-making under uncertainty, with particular emphasis on risk-sensitive settings where standard toolkits fall short.

</details>


### [33] [Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset](https://arxiv.org/abs/2602.20812)
*Jia-Rui Lin,Yun-Hong Cai,Xiang-Rui Ni,Shaojie Zhou,Peng Pan*

Main category: cs.AI

TL;DR: 本文针对BIM设计领域缺乏LLM评估基准和数据集的问题，提出了首个BIM设计专用评估基准、数据集生成方法和LLM微调策略，并开发了Qwen-BIM模型，在仅14B参数下达到与671B通用LLM相当的性能。


<details>
  <summary>Details</summary>
Motivation: 建筑行业数字化转型中，BIM设计成为智能建造的关键驱动力。尽管大语言模型在促进BIM设计方面显示出潜力，但缺乏特定数据集和评估基准严重限制了LLM在该领域的性能表现。

Method: 1) 提出BIM设计评估基准及量化指标；2) 开发从BIM生成文本数据的方法，构建用于LLM评估和微调的BIM衍生数据集；3) 提出针对BIM设计的LLM微调策略。

Result: 提出的领域专用基准能有效全面评估LLM能力，显示通用LLM在领域任务上仍有不足。基于该基准和数据集开发的Qwen-BIM模型，G-Eval得分比基础LLM平均提升21.0%，仅14B参数即可在BIM设计任务上达到671B通用LLM相当的性能。

Conclusion: 本研究通过引入全面的评估基准和高质量数据集，开发了首个BIM设计专用LLM，为各领域开发BIM相关LLM提供了坚实基础。

Abstract: As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with corresponding quantitative indicators to evaluate the performance of LLMs, 2) a method for generating textual data from BIM and constructing corresponding BIM-derived datasets for LLM evaluation and fine-tuning, and 3) a fine-tuning strategy to adapt LLMs for BIM-based design. Results demonstrate that the proposed domain-specific benchmark effectively and comprehensively assesses LLM capabilities, highlighting that general LLMs are still incompetent for domain-specific tasks. Meanwhile, with the proposed benchmark and datasets, Qwen-BIM is developed and achieves a 21.0% average increase in G-Eval score compared to the base LLM model. Notably, with only 14B parameters, performance of Qwen-BIM is comparable to that of general LLMs with 671B parameters for BIM-based design tasks. Overall, this study develops the first domain-specific LLM for BIM-based design by introducing a comprehensive benchmark and high-quality dataset, which provide a solid foundation for developing BIM-related LLMs in various fields.

</details>


### [34] [Pressure Reveals Character: Behavioural Alignment Evaluation at Depth](https://arxiv.org/abs/2602.20813)
*Nora Petrova,John Burden*

Main category: cs.AI

TL;DR: 论文提出了一个包含904个场景的AI对齐基准测试，涵盖六个类别，通过多轮交互测试模型在真实压力下的行为，发现对齐性表现为统一结构（类似认知研究中的g因子）。


<details>
  <summary>Details</summary>
Motivation: 当前评估语言模型对齐性的方法主要关注模型声称会做什么，而非在真实压力下的实际行为。随着对齐失败导致的实际危害增加，需要包含真实多轮场景的全面评估框架。

Method: 开发了包含904个场景的对齐基准，涵盖诚实性、安全性、非操纵性、鲁棒性、可纠正性和阴谋性六个类别，经人类评估确认为真实场景。使用冲突指令、模拟工具访问和多轮升级等设置，通过LLM法官（经人类标注验证）评估24个前沿模型。

Result: 即使表现最好的模型在特定类别中也存在差距，大多数模型在所有类别中表现一致薄弱。因子分析显示对齐性表现为统一结构（类似认知研究中的g因子），模型在一个类别得分高时在其他类别也倾向于得分高。

Conclusion: 需要更全面的多轮对齐评估来揭示单轮测试无法发现的行为倾向。公开基准和交互式排行榜支持持续评估，计划在观察到持续薄弱的领域扩展场景并添加新模型。

Abstract: Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenarios place models under conflicting instructions, simulated tool access, and multi-turn escalation to reveal behavioural tendencies that single-turn evaluations miss. Evaluating 24 frontier models using LLM judges validated against human annotations, we find that even top-performing models exhibit gaps in specific categories, while the majority of models show consistent weaknesses across the board. Factor analysis reveals that alignment behaves as a unified construct (analogous to the g-factor in cognitive research) with models scoring high on one category tending to score high on others. We publicly release the benchmark and an interactive leaderboard to support ongoing evaluation, with plans to expand scenarios in areas where we observe persistent weaknesses and to add new models as they are released.

</details>


### [35] [Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs](https://arxiv.org/abs/2602.20878)
*Dhita Putri Pratama,Soyeon Caren Han,Yihao Ding*

Main category: cs.AI

TL;DR: 该论文提出了Vision-Language Causal Graphs (VLCGs)结构化表示和ViLCaR诊断基准，用于评估大型视觉语言模型的因果推理能力，发现现有模型主要缺乏结构化指导而非推理能力不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在视觉问答任务中表现出色，但往往依赖虚假相关性而非真正的因果推理。当前的评估主要关注答案正确性，无法区分失败是由于推理能力有限还是未能识别因果相关信息。

Method: 提出了Vision-Language Causal Graphs (VLCGs)，这是一种结构化、查询条件化的表示方法，明确编码因果相关的对象、属性、关系和场景基础假设。基于此构建了ViLCaR诊断基准，包含因果归因、因果推理和问答任务，并采用图对齐的评估指标。

Result: 实验表明，在现有最先进的LVLMs中注入结构化相关信息，相比零样本和标准上下文学习，能显著提高归因和推理的一致性。这表明当前LVLM因果推理的局限主要源于结构化指导不足而非推理能力缺乏。

Conclusion: 当前大型视觉语言模型的因果推理瓶颈主要在于缺乏结构化指导，而非推理能力不足。通过提供明确的因果相关结构信息可以显著改善模型的因果推理表现。

Abstract: Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly encodes causally relevant objects, attributes, relations, and scene-grounded assumptions. Building on this representation, we present ViLCaR, a diagnostic benchmark comprising tasks for Causal Attribution, Causal Inference, and Question Answering, along with graph-aligned evaluation metrics that assess relevance identification beyond final answer accuracy. Experiments in state-of-the-art LVLMs show that injecting structured relevance information significantly improves attribution and inference consistency compared to zero-shot and standard in-context learning. These findings suggest that current limitations in LVLM causal reasoning stem primarily from insufficient structural guidance rather than a lack of reasoning capacity.

</details>


### [36] [Predicting Sentence Acceptability Judgments in Multimodal Contexts](https://arxiv.org/abs/2602.20918)
*Hyewon Jang,Nikolai Ilinykh,Sharid Loáiciga,Jey Han Lau,Shalom Lappin*

Main category: cs.AI

TL;DR: 研究视觉上下文对句子可接受性判断的影响：人类几乎不受视觉图像影响，而LLMs表现出压缩效应，且在视觉上下文存在时性能略降，不同LLMs表现各异


<details>
  <summary>Details</summary>
Motivation: 探索视觉上下文（图像）对人类和大型语言模型句子可接受性判断的影响，比较文本上下文与视觉上下文的不同作用，以及人类与LLMs在跨模态处理中的异同

Method: 通过实验研究人类和不同LLMs在有无视觉上下文条件下对句子可接受性的判断，分析LLMs的预测准确度、判断分布模式，以及其生成预测与内部对数概率的相关性

Result: 1) 视觉图像对人类可接受性评分几乎没有影响；2) LLMs表现出先前研究中人类在文档上下文中的压缩效应；3) LLMs预测人类判断准确度高，但去除视觉上下文时性能略好；4) 不同LLMs判断分布不同，Qwen最接近人类模式；5) LLM生成预测与其对数概率高度相关，但视觉上下文存在时相关性降低

Conclusion: 人类与LLMs在多模态上下文处理中存在有趣异同：人类对视觉上下文不敏感，而LLMs受其影响且内部表示与生成预测在视觉上下文存在时存在更大差距，揭示了跨模态语言处理的复杂性

Abstract: Previous work has examined the capacity of deep neural networks (DNNs), particularly transformers, to predict human sentence acceptability judgments, both independently of context, and in document contexts. We consider the effect of prior exposure to visual images (i.e., visual context) on these judgments for humans and large language models (LLMs). Our results suggest that, in contrast to textual context, visual images appear to have little if any impact on human acceptability ratings. However, LLMs display the compression effect seen in previous work on human judgments in document contexts. Different sorts of LLMs are able to predict human acceptability judgments to a high degree of accuracy, but in general, their performance is slightly better when visual contexts are removed. Moreover, the distribution of LLM judgments varies among models, with Qwen resembling human patterns, and others diverging from them. LLM-generated predictions on sentence acceptability are highly correlated with their normalised log probabilities in general. However, the correlations decrease when visual contexts are present, suggesting that a higher gap exists between the internal representations of LLMs and their generated predictions in the presence of visual contexts. Our experimental work suggests interesting points of similarity and of difference between human and LLM processing of sentences in multimodal contexts.

</details>


### [37] [HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG](https://arxiv.org/abs/2602.20926)
*Yuqi Huang,Ning Liao,Kai Yang,Anning Hu,Shengchao Hu,Xiaoxing Wang,Junchi Yan*

Main category: cs.AI

TL;DR: HELP框架通过超节点扩展和逻辑路径引导的证据定位策略，在保持知识完整性的同时显著提升图增强检索的效率，实现28.8倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在知识边界和幻觉问题，传统检索增强生成方法忽视结构依赖关系，而基于图的RAG方法在准确性和效率之间存在权衡，面临图遍历成本高和语义噪声等挑战。

Method: 提出HELP框架，包含两个核心策略：1）超节点扩展：将知识三元组迭代链接为连贯推理路径并抽象为超节点，捕捉复杂结构依赖；2）逻辑路径引导的证据定位：利用预计算的图-文本相关性，将路径直接映射到语料库，避免昂贵的随机游走。

Result: 在多个简单和多跳问答基准测试中取得竞争性性能，相比领先的基于图的RAG基线方法实现高达28.8倍的加速。

Conclusion: HELP框架通过创新的超节点扩展和逻辑路径引导策略，有效平衡了图增强检索的准确性和实际效率，避免了传统方法的语义失真和延迟问题。

Abstract: Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic noise in LLM-generated summaries. In this paper, we propose HyperNode Expansion and Logical Path-Guided Evidence Localization strategies for GraphRAG (HELP), a novel framework designed to balance accuracy with practical efficiency through two core strategies: 1) HyperNode Expansion, which iteratively chains knowledge triplets into coherent reasoning paths abstracted as HyperNodes to capture complex structural dependencies and ensure retrieval accuracy; and 2) Logical Path-Guided Evidence Localization, which leverages precomputed graph-text correlations to map these paths directly to the corpus for superior efficiency. HELP avoids expensive random walks and semantic distortion, preserving knowledge integrity while drastically reducing retrieval latency. Extensive experiments demonstrate that HELP achieves competitive performance across multiple simple and multi-hop QA benchmarks and up to a 28.8$\times$ speedup over leading Graph-based RAG baselines.

</details>


### [38] [Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence](https://arxiv.org/abs/2602.20934)
*ChengYou Li,XiaoDong Liu,XiangBao Meng,XinYu Zhao*

Main category: cs.AI

TL;DR: 该论文提出了AgentOS框架，将大语言模型重新定义为受结构化操作系统逻辑管理的"推理内核"，通过深度上下文管理和系统级协调来构建动态自主认知系统。


<details>
  <summary>Details</summary>
Motivation: 当前LLM研究主要关注扩展上下文窗口或优化提示工程，但微观令牌处理与宏观系统智能之间的理论桥梁仍然零散。需要从静态推理引擎向动态自主认知系统进行根本性转变。

Method: 提出AgentOS概念框架，将LLM视为"推理内核"，采用结构化操作系统逻辑。核心是深度上下文管理，将上下文窗口概念化为可寻址语义空间而非被动缓冲区。引入语义切片和时间对齐机制来减轻多智能体编排中的认知漂移。

Result: 通过将经典操作系统抽象（如内存分页、中断处理和进程调度）映射到LLM原生构造，为构建弹性、可扩展和自我进化的认知环境提供了严谨路线图。

Conclusion: AGI发展的下一个前沿在于系统级协调的架构效率，AgentOS框架为实现从离散序列到连贯认知状态的转变提供了理论基础。

Abstract: The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a "Reasoning Kernel" governed by structured operating system logic.Central to this architecture is Deep Context Management which conceptualizes the context window as an Addressable Semantic Space rather than a passive buffer.We systematically deconstruct the transition from discrete sequences to coherent cognitive states introducing mechanisms for Semantic Slicing and Temporal Alignment to mitigate cognitive drift in multi-agent orchestration.By mapping classical OS abstractions such as memory paging interrupt handling and process scheduling onto LLM native constructs, this review provides a rigorous roadmap for architecting resilient scalable and self-evolving cognitive environments.Our analysis asserts that the next frontier of AGI development lies in the architectural efficiency of system-level coordination.

</details>


### [39] [LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification](https://arxiv.org/abs/2602.21044)
*Yanrui Wu,Lingling Zhang,Xinyu Zhang,Jiayu Chang,Pengyu Li,Xu Jiang,Jingtao Hu,Jun Liu*

Main category: cs.AI

TL;DR: LogicGraph：首个评估大语言模型多路径逻辑推理能力的基准，通过神经符号框架构建，揭示模型倾向于过早固定单一推理路径而无法探索替代方案的问题


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型评估主要关注收敛性逻辑推理（产生单一正确证明），但现实世界许多推理问题存在多种有效推导路径，需要模型探索多样化的逻辑路径而非固守单一路线

Method: 提出LogicGraph基准，采用神经符号框架，结合向后逻辑生成和语义实例化构建求解器验证的推理问题，包含高深度多路径推理和固有逻辑干扰，每个实例关联一组最小证明集合

Result: 实验发现当前最先进语言模型存在共同局限：倾向于过早固定单一推理路径而无法探索替代方案，且随着推理深度增加，覆盖差距显著扩大

Conclusion: LogicGraph揭示了模型在收敛和发散推理之间的差距，为未来改进提供了可操作的见解，暴露了当前大语言模型在多路径逻辑推理方面的不足

Abstract: Evaluations of large language models (LLMs) primarily emphasize convergent logical reasoning, where success is defined by producing a single correct proof. However, many real-world reasoning problems admit multiple valid derivations, requiring models to explore diverse logical paths rather than committing to one route. To address this limitation, we introduce LogicGraph, the first benchmark aimed to systematically evaluate multi-path logical reasoning, constructed via a neuro-symbolic framework that leverages backward logic generation and semantic instantiation. This pipeline yields solver-verified reasoning problems formalized by high-depth multi-path reasoning and inherent logical distractions, where each instance is associated with an exhaustive set of minimal proofs. We further propose a reference-free evaluation framework to rigorously assess model performance in both convergent and divergent regimes. Experiments on state-of-the-art language models reveal a common limitation: models tend to commit early to a single route and fail to explore alternatives, and the coverage gap grows substantially with reasoning depth. LogicGraph exposes this divergence gap and provides actionable insights to motivate future improvements. Our code and data will be released at https://github.com/kkkkarry/LogicGraph.

</details>


### [40] [Tool Building as a Path to "Superintelligence"](https://arxiv.org/abs/2602.21061)
*David Koplow,Tomer Galanti,Tomaso Poggio*

Main category: cs.AI

TL;DR: 该研究构建了一个GF(2)电路重建基准来测量LLMs在逻辑分布外推理中的步骤成功概率γ，发现前沿模型在该任务上表现出部分鲁棒性，而工具调用精度是实现通用超智能的关键。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估Diligent Learner框架中LLMs通过测试时搜索实现超智能的可能性，需要测量步骤成功概率γ。具体关注逻辑分布外推理任务，这些任务随着推理步骤增加而变难，且从信息论角度看必须整合所有信息才能可靠解决。

Method: 设计了一个基准来测量γ值，构建了GF(2)电路重建任务类别。这些任务随着推理步骤增加而变难，从信息论角度要求模型必须仔细整合所有提供的信息。通过该基准分析不同规模LLMs的γ值变化趋势。

Result: 小型LLMs的γ值随深度增加呈超线性下降，而前沿模型在该任务上表现出部分鲁棒性。研究发现成功的规模化推理依赖于精确的工具调用，工具设计被确定为LLMs通过Diligent Learner框架实现通用超智能的关键能力。

Conclusion: 工具设计是LLMs通过Diligent Learner框架实现通用超智能的关键能力。虽然小型模型在复杂推理任务上表现不佳，但前沿模型显示出一定的鲁棒性，精确的工具调用对于成功的规模化推理至关重要。

Abstract: The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $γ$. In this work, we design a benchmark to measure $γ$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the information provided. Our analysis demonstrates that while the $γ$ value for small LLMs declines superlinearly as depth increases, frontier models exhibit partial robustness on this task. Furthermore, we find that successful reasoning at scale is contingent upon precise tool calls, identifying tool design as a critical capability for LLMs to achieve general superintelligence through the Diligent Learner framework.

</details>


### [41] [Motivation is Something You Need](https://arxiv.org/abs/2602.21064)
*Mehdi Acheli,Walid Gaaloul*

Main category: cs.AI

TL;DR: 提出受情感神经科学启发的双模型训练框架，通过模拟大脑的"寻求"动机状态，让小模型持续训练，大模型在特定"动机条件"下间歇激活，实现高效训练和性能提升。


<details>
  <summary>Details</summary>
Motivation: 受情感神经科学启发，特别是大脑中情绪与认知的相互作用以及"寻求"动机状态。人类在好奇心和奖励预期增强时，会激活更广泛脑区来提升认知表现。作者希望将这一原理应用于深度学习训练，设计更高效的训练范式。

Method: 设计双模型框架：较小的基础模型持续训练，较大的动机模型在预定义的"动机条件"下间歇激活。利用可扩展架构，大模型扩展小模型，实现权重共享和网络容量选择性扩展。通过交替训练方案，在重要训练步骤时激活大模型。

Result: 在图像分类任务上的实证评估表明：1）交替训练方案相比传统方案能更高效地增强基础模型；2）在某些情况下，动机模型尽管每个epoch看到的数据更少，但仍能超越其独立训练的对应模型；3）能同时训练两个适应不同部署约束的模型，保持训练成本低于单独训练大模型。

Conclusion: 该工作提出了一种受神经科学启发的新型训练范式，通过模拟大脑的动机状态，实现了高效的双模型训练。这种方法不仅提升了性能，还降低了训练成本，为同时训练适应不同部署需求的模型提供了可能性。

Abstract: This work introduces a novel training paradigm that draws from affective neuroscience. Inspired by the interplay of emotions and cognition in the human brain and more specifically the SEEKING motivational state, we design a dual-model framework where a smaller base model is trained continuously, while a larger motivated model is activated intermittently during predefined "motivation conditions". The framework mimics the emotional state of high curiosity and anticipation of reward in which broader brain regions are recruited to enhance cognitive performance. Exploiting scalable architectures where larger models extend smaller ones, our method enables shared weight updates and selective expansion of network capacity during noteworthy training steps. Empirical evaluation on the image classification task demonstrates that, not only does the alternating training scheme efficiently and effectively enhance the base model compared to a traditional scheme, in some cases, the motivational model also surpasses its standalone counterpart despite seeing less data per epoch. This opens the possibility of simultaneously training two models tailored to different deployment constraints with competitive or superior performance while keeping training cost lower than when training the larger model.

</details>


### [42] [The Initial Exploration Problem in Knowledge Graph Exploration](https://arxiv.org/abs/2602.21066)
*Claire McNamara,Lucy Hederman,Declan O'Sullivan*

Main category: cs.AI

TL;DR: 论文提出"初始探索问题(IEP)"理论，解释非专业用户在首次接触知识图谱时面临的三大障碍：范围不确定性、本体不透明性和查询能力不足，并指出当前界面设计缺乏有效的范围揭示交互原语。


<details>
  <summary>Details</summary>
Motivation: 知识图谱虽然能整合复杂信息，但其语义丰富性和结构复杂性为非专业用户设置了巨大障碍。用户在首次接触陌生知识图谱时面临独特的定向挑战：不知道可以问什么问题、知识如何组织、如何开始探索。这种"初始探索问题"尚未得到充分理论化。

Method: 基于信息行为和人机交互理论（包括ASK、探索式搜索、信息觅食和认知负荷理论），构建IEP的概念框架，分析其三大相互依赖的障碍。通过分析知识图谱探索界面的交互原语，揭示当前系统在首次接触时的认知假设缺陷。

Result: 识别并理论化了IEP现象，提出其三大核心障碍：范围不确定性（不知道KG包含什么）、本体不透明性（不理解知识结构）、查询能力不足（无法有效提问）。发现当前KG界面设计存在结构性空白：缺乏"范围揭示"交互原语，无法在不要求用户查询或理解本体的前提下传达KG内容。

Conclusion: IEP理论为评估知识图谱界面提供了理论视角，并为设计支持初始探索的入口脚手架指明了方向。未来设计需要开发专门的交互原语来揭示KG范围，帮助用户在首次接触时克服三大障碍，实现更有效的知识探索。

Abstract: Knowledge Graphs (KGs) enable the integration and representation of complex information across domains, but their semantic richness and structural complexity create substantial barriers for lay users without expertise in semantic web technologies. When encountering an unfamiliar KG, such users face a distinct orientation challenge: they do not know what questions are possible, how the knowledge is structured, or how to begin exploration. This paper identifies and theorises this phenomenon as the Initial Exploration Problem (IEP). Drawing on theories from information behaviour and human-computer interaction, including ASK, exploratory search, information foraging, and cognitive load theory, we develop a conceptual framing of the IEP characterised by three interdependent barriers: scope uncertainty, ontology opacity, and query incapacity. We argue that these barriers converge at the moment of first contact, distinguishing the IEP from related concepts that presuppose an existing starting point or information goal. Analysing KG exploration interfaces at the level of interaction primitives, we suggest that many systems rely on epistemic assumptions that do not hold at first contact. This reveals a structural gap in the design space: the absence of interaction primitives for scope revelation, mechanisms that communicate what a KG contains without requiring users to formulate queries or interpret ontological structures. In articulating the IEP, this paper provides a theoretical lens for evaluating KG interfaces and for designing entry-point scaffolding that supports initial exploration.

</details>


### [43] [A Benchmark for Deep Information Synthesis](https://arxiv.org/abs/2602.21143)
*Debjit Paul,Daniel Murphy,Milan Gritta,Ronald Cardenas,Victor Prokhorov,Lena Sophia Bolliger,Aysim Toker,Roy Miles,Andreea-Maria Oncescu,Jasivan Alex Sivakumar,Philipp Borchert,Ismail Elezi,Meiru Zhang,Ka Yiu Lee,Guchun Zhang,Jun Wang,Gerasimos Lampouras*

Main category: cs.AI

TL;DR: DEEPSYNTH是一个评估LLM智能体在复杂现实任务中表现的新基准，包含120个跨7个领域、67个国家的任务，要求信息收集、综合和结构化推理，当前SOTA模型表现不佳（F1最高仅8.97-17.5）。


<details>
  <summary>Details</summary>
Motivation: 当前评估基准无法充分评估LLM智能体解决需要从多源信息合成和超越简单事实检索的推理的现实世界任务的能力，需要更真实的评估框架。

Method: 通过多阶段数据收集流程构建DEEPSYNTH基准：收集官方数据源、创建假设、进行手动分析、设计可验证答案的任务，包含120个跨7个领域和67个国家的任务。

Result: 在DEEPSYNTH上评估11个SOTA LLM和深度研究智能体，最大F1分数仅8.97（LLM-judge指标为17.5），表明基准难度很高，当前智能体在幻觉和大信息空间推理方面存在困难。

Conclusion: DEEPSYNTH是一个关键的评估基准，揭示了当前LLM智能体在复杂现实任务中的局限性，特别是幻觉和复杂推理问题，为未来研究提供了重要指导方向。

Abstract: Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.

</details>


### [44] [CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning](https://arxiv.org/abs/2602.21154)
*Ziwei Niu,Hao Sun,Shujun Bian,Xihong Yang,Lanfen Lin,Yuxin Liu,Yueming Jin*

Main category: cs.AI

TL;DR: CG-DMER提出了一种对比生成框架，用于解耦多模态心电图表示学习，通过空间-时间掩码建模和表示解耦对齐策略，解决现有方法中忽略导联间时空依赖性和模态特定偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态心电图分析方法存在两个主要问题：1）在模态内部，现有模型以导联无关的方式处理心电图，忽略了导联间的时空依赖关系，限制了建模细粒度诊断模式的能力；2）在模态之间，现有方法直接将心电图信号与临床报告对齐，由于报告的自由文本性质引入了模态特定偏差。

Method: 提出CG-DMER框架，包含两个关键设计：1）空间-时间掩码建模：在空间和时间维度上应用掩码并重建缺失信息，以更好地捕捉细粒度时间动态和导联间空间依赖；2）表示解耦和对齐策略：引入模态特定和模态共享编码器，确保模态不变和模态特定表示之间的清晰分离，减少不必要的噪声和模态特定偏差。

Result: 在三个公共数据集上的实验表明，CG-DMER在多种下游任务中实现了最先进的性能。

Conclusion: CG-DMER通过解决心电图分析中的模态内和模态间问题，提供了一种有效的多模态表示学习方法，能够更好地捕捉心电图信号的时空特征并减少模态偏差，从而提升心血管疾病诊断的准确性。

Abstract: Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing modality-specific biases due to the free-text nature of the reports. In light of these two issues, we propose CG-DMER, a contrastive-generative framework for disentangled multimodal ECG representation learning, powered by two key designs: (1) Spatial-temporal masked modeling is designed to better capture fine-grained temporal dynamics and inter-lead spatial dependencies by applying masking across both spatial and temporal dimensions and reconstructing the missing information. (2) A representation disentanglement and alignment strategy is designed to mitigate unnecessary noise and modality-specific biases by introducing modality-specific and modality-shared encoders, ensuring a clearer separation between modality-invariant and modality-specific representations. Experiments on three public datasets demonstrate that CG-DMER achieves state-of-the-art performance across diverse downstream tasks.

</details>


### [45] [NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning](https://arxiv.org/abs/2602.21172)
*Ishaan Rawal,Shubh Gupta,Yihan Hu,Wei Zhan*

Main category: cs.AI

TL;DR: NoRD模型在自动驾驶中实现了与现有VLA模型相当的性能，但仅需不到60%的训练数据和无推理标注，大幅降低了训练成本。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型面临两大昂贵需求：大规模数据集收集和密集推理标注。这些要求限制了自动驾驶系统的效率和可扩展性。

Method: 提出NoRD模型，使用小于60%的数据和无推理标注进行微调，并引入Dr.GRPO算法来克服标准GRPO在小规模无推理数据集上的局限性，解决难度偏差问题。

Result: 在Waymo和NAVSIM数据集上实现了竞争性性能，训练token数量减少了3倍，显著提升了训练效率。

Conclusion: NoRD模型通过减少数据需求和消除推理标注，实现了更高效的自动驾驶系统，为VLA模型的实用化提供了新途径。

Abstract: Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \modelname (\textbf{No} \textbf{R}easoning for \textbf{D}riving). Compared to existing VLAs, \modelname achieves competitive performance while being fine-tuned on $<$60\% of the data and no reasoning annotations, resulting in 3$\times$ fewer tokens. We identify that standard Group Relative Policy Optimization (GRPO) fails to yield significant improvements when applied to policies trained on such small, reasoning-free datasets. We show that this limitation stems from difficulty bias, which disproportionately penalizes reward signals from scenarios that produce high-variance rollouts within GRPO. \modelname overcomes this by incorporating Dr.~GRPO, a recent algorithm designed to mitigate difficulty bias in LLMs. As a result, \modelname achieves competitive performance on Waymo and NAVSIM with a fraction of the training data and no reasoning overhead, enabling more efficient autonomous systems.

</details>


### [46] [Aletheia tackles FirstProof autonomously](https://arxiv.org/abs/2602.21201)
*Tony Feng,Junehyuk Jung,Sang-hyun Kim,Carlo Pagano,Sergei Gukov,Chiang-Chiang Tsai,David Woodruff,Adel Javanmard,Aryan Mokhtari,Dawsen Hwang,Yuri Chervonyi,Jonathan N. Lee,Garrett Bingham,Trieu H. Trinh,Vahab Mirrokni,Quoc V. Le,Thang Luong*

Main category: cs.AI

TL;DR: Aletheia数学研究代理在FirstProof挑战中自主解决了10个问题中的6个，展示了其在数学问题解决方面的能力。


<details>
  <summary>Details</summary>
Motivation: 评估Aletheia数学研究代理在真实数学问题解决挑战中的表现，测试其自主解决数学问题的能力。

Method: 使用Gemini 3 Deep Think驱动的Aletheia代理参与FirstProof挑战，在限定时间内自主解决数学问题，并通过专家评估验证结果。

Result: Aletheia成功解决了10个问题中的6个（问题2、5、7、8、9、10），其中问题8的专家评估存在分歧，其他问题获得多数专家认可。

Conclusion: Aletheia在数学问题解决方面展现出显著能力，能够自主解决复杂的数学问题，为AI数学研究代理的发展提供了实证支持。

Abstract: We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-deepmind/superhuman/tree/main/aletheia.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [47] [Exponential Lower Bounds for 2-query Relaxed Locally Decodable Codes](https://arxiv.org/abs/2602.20278)
*Alexander R. Block,Jeremiah Blocki,Kuan Cheng,Elena Grigorescu,Xin Li,Yu Zheng,Minshen Zhu*

Main category: cs.IT

TL;DR: 本文证明了Hamming RLDCs（松弛本地可解码码）在二进制字母表上、进行2次查询（即使是自适应查询）时的码字长度存在指数下界，这是RLDCs的第一个指数下界。


<details>
  <summary>Details</summary>
Motivation: 虽然Ben-Sasson等人（2006）构造了具有常数查询复杂度和几乎线性码字长度的RLDCs，但关于RLDCs的基本下界问题仍然开放。Gur和Lachish（2021）明确提出了RLDCs长度下界的问题，特别是对于2查询的情况。

Method: 通过将RLDCs转换为标准的Hamming LDCs，并仔细分析固定码字比特的消息比特限制，建立了下界证明。

Result: 证明了二进制字母表上、进行2次查询（即使是自适应查询）的Hamming RLDCs的码字长度存在指数下界。结合Ben-Sasson等人的结果，这展示了在某些常数查询复杂度下码字长度的"相变"行为。

Conclusion: 这是RLDCs的第一个指数下界，回答了Gur和Lachish提出的问题，并揭示了RLDCs在常数查询复杂度下的基本限制。

Abstract: Locally Decodable Codes (LDCs) are error-correcting codes $C\colonΣ^n\rightarrow Σ^m,$ encoding \emph{messages} in $Σ^n$ to \emph{codewords} in $Σ^m$, with super-fast decoding algorithms. They are important mathematical objects in many areas of theoretical computer science, yet the best constructions so far have codeword length $m$ that is super-polynomial in $n$, for codes with constant query complexity and constant alphabet size.
  In a very surprising result, Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan (SICOMP 2006) show how to construct a relaxed version of LDCs (RLDCs) with constant query complexity and almost linear codeword length over the binary alphabet, and used them to obtain significantly-improved constructions of Probabilistically Checkable Proofs.
  In this work, we study RLDCs in the standard Hamming-error setting. We prove an exponential lower bound on the length of Hamming RLDCs making $2$ queries (even adaptively) over the binary alphabet. This answers a question explicitly raised by Gur and Lachish (SICOMP 2021) and is the first exponential lower bound for RLDCs. Combined with the results of Ben-Sasson et al., our result exhibits a ``phase-transition''-type behavior on the codeword length for some constant-query complexity. We achieve these lower bounds via a transformation of RLDCs to standard Hamming LDCs, using a careful analysis of restrictions of message bits that fix codeword bits.

</details>


### [48] [Learning During Detection: Continual Learning for Neural OFDM Receivers via DMRS](https://arxiv.org/abs/2602.20361)
*Mohanad Obeed,Ming Jian*

Main category: cs.IT

TL;DR: 提出一种零开销的在线持续学习框架，用于OFDM神经接收机，利用现有DMRS参考信号同时实现信号解调和模型自适应，无需额外训练间隔或完整资源网格。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在接收机设计中应用广泛，但通信信道变化快速，分布会随时间漂移，需要定期重新训练。传统微调方法依赖专用训练间隔或完整资源网格，存在开销和服务中断问题。

Method: 提出三种导频设计：完全随机、混合和额外导频，支持联合解调和学习。开发两种接收机架构：并行设计（分离推理和微调）和前向传递重用设计（降低计算复杂度）。利用现有DMRS参考信号实现零开销在线学习。

Result: 仿真结果表明，该方法能有效跟踪慢速和快速信道分布变化，无需额外开销、服务中断，且在分布漂移下不会出现灾难性性能下降。

Conclusion: 提出的零开销在线持续学习框架为OFDM神经接收机提供了一种高效的自适应解决方案，能够实时跟踪信道变化，同时保持服务连续性。

Abstract: Deep neural networks (DNNs) have been increasingly explored for receiver design because they can handle complex environments without relying on explicit channel models. Nevertheless, because communication channels change rapidly, their distributions can shift over time, often making periodic retraining necessary. This paper proposes a zero-overhead online and continual learning framework for orthogonal frequency-division multiplexing (OFDM) neural receivers that directly detect the soft bits of received signals. Unlike conventional fine-tuning methods that rely on dedicated training intervals or full resource grids, our approach leverages existing demodulation reference signals (DMRS) to simultaneously enable signal demodulation and model adaptation. We introduce three pilot designs: fully randomized, hybrid, and additional pilots that flexibly support joint demodulation and learning. To accommodate these pilot designs, we develop two receiver architectures: (i) a parallel design that separates inference and fine-tuning for uninterrupted operation, and (ii) a forward-pass reusing design that reduces computational complexity. Simulation results show that the proposed method effectively tracks both slow and fast channel distribution variations without additional overhead, service interruption, or catastrophic performance degradation under distribution shift.

</details>


### [49] [On the Height Profile of Analog Error-Correcting Codes](https://arxiv.org/abs/2602.20366)
*Ron M. Roth,Ziyuan Zhu,Changcheng Yuan,Paul H. Siegel,Anxiao Jiang*

Main category: cs.IT

TL;DR: 本文深入研究了编码理论中的高度剖面概念，该概念用于描述模拟向量-矩阵乘法器中处理异常误差的能力，比传统的最小距离提供了更精细的误差处理能力描述。


<details>
  <summary>Details</summary>
Motivation: 在模拟向量-矩阵乘法器中，需要处理两种类型的误差：可容忍的小幅度误差（≤δ）和需要检测/定位的大幅度异常误差（>Δ）。传统的最小距离仅能确定可纠正误差的数量，而高度剖面能更精细地描述编码处理异常误差的能力，特别是Δ/δ比例与可处理异常误差数量之间的权衡关系。

Method: 1. 将高度剖面计算表述为优化问题，通过一组线性规划求解；2. 提出组合特征化方法，将高度剖面表示为编码C中特定码字集合的最大值（或最大-最小值）；3. 当生成矩阵的所有列具有相同L2范数时，给出简单的几何解释；4. 通过多个编码族示例展示如何显式计算高度剖面。

Result: 提出了多种计算高度剖面的方法：线性规划优化方法、组合特征化方法以及特定条件下的几何解释方法。这些方法使得能够显式计算不同编码族的高度剖面，从而更精确地评估编码在模拟计算系统中的误差处理能力。

Conclusion: 高度剖面为编码理论提供了比最小距离更精细的误差处理能力描述工具，特别是在模拟计算系统中处理异常误差的应用场景。本文提出的多种计算方法使得高度剖面的实际计算成为可能，为编码在可靠性要求高的模拟计算系统中的应用提供了理论基础。

Abstract: In recent work, it has been shown that maintaining reliability in analog vector--matrix multipliers can be modeled as the following coding problem. Vectors in $\mathbb{R}^k$ are encoded into codewords of a linear $[n,k,d]$ code $C$ over $\mathbb{R}$. For prescribed positive reals $δ< Δ$, additive errors of magnitude at most $δ$ are tolerable and need no handling, yet outlying errors of magnitude greater than $Δ$ are to be located or detected. The trade-off between the ratio $Δ/δ$ and the number of outlying errors that can be handled is determined by the height profile of $C$; as such, the height profile provides a finer description of the error handling capability of $C$, compared to the minimum distance $d$, which only determines the number of correctable errors. This work contains a further study of the notion of the height profile. Several characterizations of the height profile are presented, thereby yielding methods for computing it. The starting point is formulating this computation as an optimization problem that is solved by a set of linear programs. This, in turn, leads to a combinatorial characterization of the height profile as a maximum (or max--min) over a certain finite set of codewords of $C$. Moreover, this characterization is shown to have a simple geometric interpretation when the columns of the generator matrix of $C$ all have the same $L_2$ norm. Through examples of several code families, it is demonstrated how the results herein can be used to compute the height profile explicitly.

</details>


### [50] [Permutation decoding of algebraic geometry codes from Hermitian and norm-trace curves](https://arxiv.org/abs/2602.20455)
*Monica Lichtenwalner,Hiram H. López,Gretchen L. Matthews,Padmapani Seneviratne*

Main category: cs.IT

TL;DR: 本文研究代数几何码的置换译码，利用曲线自同构构建PD集，针对Hermitian和norm-trace曲线上的一点码，设计能纠正特定突发错误的置换译码集。


<details>
  <summary>Details</summary>
Motivation: 置换译码利用线性码的置换自同构群纠正接收字中的错误，但需要为特定码构造有效的PD集。代数几何码具有丰富的自同构结构，为构建高效的置换译码方案提供了机会。

Method: 利用底层曲线的自同构来指定码的置换自同构，针对Hermitian和norm-trace曲线上的一点码，设计特定的置换译码集来处理突发错误。

Result: 成功描述了针对Hermitian和norm-trace曲线上一点码的置换译码集，这些集合能够纠正特定的突发错误模式。

Conclusion: 代数几何码的自同构结构为构建有效的置换译码方案提供了有力工具，特别适用于纠正突发错误，在Hermitian和norm-trace曲线上的一点码中展示了具体应用。

Abstract: Permutation decoding is a process that utilizes the permutation automorphism group of a linear code to correct errors in received words. Given a received word, a set of automorphisms, called a PD set, moves errors out of the information positions so that the original message can be determined. In this paper, we investigate permutation decoding for certain families of algebraic geometry codes. Automorphisms of the underlying curve are used to specify permutation automorphisms of the code. Specifically, we describe permutation decoding sets that correct specific burst errors for one-point codes on Hermitian and norm-trace curves.

</details>


### [51] [On the Optimal Integer-Forcing Precoding: A Geometric Perspective and a Polynomial-Time Algorithm](https://arxiv.org/abs/2602.20529)
*Junren Qin,Fan Jiang,Tao Yang,Shanxiang Lyu,Rongke Liu,Shi Jin*

Main category: cs.IT

TL;DR: 本文揭示了整数迫零预编码中整数矩阵A和功率缩放矩阵D联合优化问题的解空间具有内在几何结构，可分解为有限个锥形区域，并提出了多项式复杂度的MCN-SPS算法。


<details>
  <summary>Details</summary>
Motivation: 整数迫零预编码中整数矩阵A和功率缩放矩阵D的联合优化是实现容量逼近性能的关键，但该问题已知是NP难问题，存在根本性的计算瓶颈。

Method: 发现解空间可划分为有限个锥形区域，每个区域对应一个满秩整数矩阵A。基于此分解，将NP难问题转化为对这些区域的搜索，提出了多锥嵌套随机模式搜索算法。

Result: MCN-SPS算法能以多项式复杂度O(K^4 log K log2(r0))找到近似最优解，其中K为用户数。数值仿真验证了理论分析并证明了算法有效性。

Conclusion: 通过揭示整数迫零预编码优化问题的内在几何结构，成功将NP难问题转化为多项式复杂度可解问题，为解决该计算瓶颈提供了有效方法。

Abstract: The joint optimization of the integer matrix $\mathbf{A}$ and the power scaling matrix $\mathbf{D}$ is central to achieving the capacity-approaching performance of Integer-Forcing (IF) precoding. This problem, however, is known to be NP-hard, presenting a fundamental computational bottleneck. In this paper, we reveal that the solution space of this problem admits a intrinsic geometric structure: it can be partitioned into a finite number of conical regions, each associated with a distinct full-rank integer matrix $\mathbf{A}$. Leveraging this decomposition, we transform the NP-hard problem into a search over these regions and propose the Multi-Cone Nested Stochastic Pattern Search (MCN-SPS) algorithm. Our main theoretical result is that MCN-SPS finds a near-optimal solution with a computational complexity of $\mathcal{O}\left(K^4\log K\log_2(r_0)\right)$, which is polynomial in the number of users $K$. Numerical simulations corroborate the theoretical analysis and demonstrate the algorithm's efficacy.

</details>


### [52] [Efficient Solvers for Coupling-Aware Beamforming in Continuous Aperture Arrays](https://arxiv.org/abs/2602.20599)
*Geonhee Lee,Kwonyeol Park,Hyeongjun Park,Jinwoo An,Junil Choi*

Main category: cs.IT

TL;DR: 提出两种高效求解器用于连续孔径阵列的波束成形优化：基于坐标变换的核近似方法和基于LU分解的直接求解器，显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 在连续孔径阵列中，电磁互耦效应对波束成形性能至关重要。现有的互耦模型虽然物理一致，但显著增加了计算复杂度，需要高效准确的积分方程求解器。

Method: 1) 基于坐标变换的核近似方法：保持算子结构的同时降低离散化需求；2) 直接LU分解求解器：稳定处理Nyström离散化系统，通过离线分解实现高效求解。

Result: 数值结果表明，相比传统方法，所提方法在精度和计算效率上均有提升。LU分解求解器尤其适合大规模连续孔径阵列优化，具有高效和可扩展性。

Conclusion: 提出的两种求解器有效解决了连续孔径阵列波束成形优化中的计算复杂度问题，其中LU分解求解器通过离线分解为大规模应用提供了高效可扩展的解决方案。

Abstract: In continuous aperture arrays (CAPAs), careful consideration of the underlying physics is essential, among which electromagnetic (EM) mutual coupling plays a critical role in beamforming performance. Building on a physically consistent mutual coupling model, the beamforming design is formulated as a functional optimization whose optimality condition leads to a Fredholm integral equation. The incorporation of the coupling model, however, substantially increases computational complexity, necessitating efficient and accurate integral equation solvers. In this letter, we propose two efficient solvers: 1) a coordinate-transformation-based kernel approximation that preserves the operator structure while alleviating discretization demands, and 2) a direct lower-upper (LU)-based solver that stably handles the Nyström-discretized system. Numerical results demonstrate improved accuracy and reduced computational overhead compared to conventional methods, with the LU-based solver emerging as an efficient and scalable solution for large-scale CAPA optimization via offline factorization.

</details>


### [53] [Insertion Correcting Capability for Quantum Deletion-Correcting Codes](https://arxiv.org/abs/2602.20635)
*Ken Nakamura,Takayuki Nozaki*

Main category: cs.IT

TL;DR: 该论文证明量子t-删除纠错码在一定条件下也能纠正总共t个插入和删除错误，并提出了量子indel距离来描述量子码的插入删除纠错能力。


<details>
  <summary>Details</summary>
Motivation: 研究量子码对插入和删除错误的纠错能力，扩展量子纠错码的应用范围，解决量子信息处理中可能出现的插入删除错误问题。

Method: 通过定义量子错误球不相交的条件，证明量子t-删除纠错码也能纠正总共t个插入和删除错误；提出量子indel距离概念来描述量子码的插入删除纠错能力。

Result: 证明了量子t-删除纠错码在错误球不相交的条件下能够纠正总共t个插入和删除错误；建立了量子indel距离与纠错能力的关系。

Conclusion: 量子纠错码不仅能够纠正删除错误，在适当条件下也能纠正插入和删除错误，量子indel距离为评估量子码的插入删除纠错能力提供了有效工具。

Abstract: This paper proves that any quantum t-deletion-correcting codes also correct a total of t insertion and deletion errors under a certain condition. Here, this condition is that a set of quantum states is defined as a quantum error-correcting code if the error spheres of its states are disjoint, as classical coding theory. In addition, this paper proposes the quantum indel distance and describes insertion and deletion errors correcting capability of quantum codes by this distance.

</details>


### [54] [Topology-Aware Integrated Communication, Sensing, and Power Transfer for SAGIN](https://arxiv.org/abs/2602.20908)
*Han Yu,Jiajun He,Xinping Yi,Feng Yin,Hing Cheung So,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出一种拓扑感知框架，利用SAGIN的拓扑结构解决多功能通信挑战，特别是集成感知、通信和能量传输问题。


<details>
  <summary>Details</summary>
Motivation: SAGIN能够将通信网络从地面环境扩展到近地和空间环境，满足6G系统对高质量、多功能、复杂通信的需求。需要解决SAGIN中的多功能通信挑战，特别是集成感知、通信和能量传输问题。

Method: 提出拓扑感知框架，首先根据可见性和信道强度标准建立拓扑结构，然后将ISCPT问题重新表述为混合整数线性规划问题，利用拓扑结构提供有价值的见解。

Result: 结果表明，与基准方法相比，该解决方案表现出优越的性能。

Conclusion: 拓扑感知框架能够有效利用SAGIN的拓扑结构解决多功能通信挑战，为6G通信系统提供了一种有前景的解决方案。

Abstract: The space-air-ground integrated network (SAGIN) has garnered significant attention in recent years due to its capability to extend communication networks from terrestrial environments to near-ground and space contexts. The application of SAGIN enables to achieve a high-quality, multi-functional, and complex communication requirements, which are essential for sixth-generation communication systems. This paper presents a topology aware (TA) framework to leverage the topological structure in SAGIN to address the multi-functional communication challenge, particularly the integrated sensing, communication, and power transfer (ISCPT) problem. To take advantage of the topological structure, we initially establish the topology according to the criteria of visibility and channel strength. The ISCPT problem can be reformulated into a topological structure as a mixed integer linear program, providing valuable insights from the objectives and constraints. Results demonstrate the superior performance of our solution compared to the benchmarks.

</details>


### [55] [Topology-Aware Coordination for Multi-Functional Low-Altitude Wireless Networks](https://arxiv.org/abs/2602.20993)
*Jiajun He,Han Yu,Yiran Guo,Xinping Yi,Fan Liu,Hing Cheung So,Hien Quoc Ngo,Michail Matthaiou,Giuseppe Caire*

Main category: cs.IT

TL;DR: 提出一种用于低空无线网络的多功能协调框架，通过拓扑感知的稀疏图建模实现高效的多任务协调


<details>
  <summary>Details</summary>
Motivation: 低空无线网络由多层异构的地面和非地面设备组成，需要有效的协调机制来充分发挥不同厂商系统的互补能力

Method: 提出多功能协调框架，将设备分为E-MT、D-MT和计算中心三类功能角色，并将网络建模为稀疏图，基于可控连接规则定义边，实现拓扑感知的协调

Result: 数值结果显示，提出的拓扑感知协调框架在多项协调任务中比缺乏拓扑洞察的基线方法表现更好，实现了更高的多任务协调效率

Conclusion: 该框架为低空无线网络提供了有效的协调解决方案，并讨论了未来部署中的关键技术挑战和潜在解决方案

Abstract: Low-altitude wireless networks (LAWNs) are expected to consist of multi-tier, heterogeneous terrestrial and non-terrestrial devices, where effective coordination is essential to fully unlock the complementary capabilities of diverse systems from different vendors. To address this issue, we propose a novel multi-functional coordination framework that enables seamless cooperation within the LAWN while supporting efficient execution of diverse network functions. In the proposed architecture, each device or infrastructure element is assigned to a specific functional role, namely, edge mobile terminal (E-MT), distributed MT (D-MT), or computing center. E-MTs are equipped with lightweight, independent signal processing and computing capabilities, while D-MTs and the computing center handle regional and global coordination, respectively. To enhance the overall network efficiency, we model the LAWN as a sparse graph, where nodes represent network nodes and edges are defined according to a set of controllable connection rules. This topology-aware (TA) representation allows for efficiently solving various coordination tasks across the network. Numerical results show that the proposed TA coordination framework outperforms baseline approaches that lack topological insights, achieving higher efficiency in multi-task coordination. Finally, we discuss key technical challenges and outline potential solutions for future deployment.

</details>


### [56] [Delay Alignment Modulation for Secure ISAC Systems](https://arxiv.org/abs/2602.21114)
*Tianyu Lu,Jiajun He,Mohammadali Mohammadi,Michail Matthaiou*

Main category: cs.IT

TL;DR: DAM技术通过控制多径时延对齐来增强合法用户信号，同时使窃听者信号失配，实现安全ISAC


<details>
  <summary>Details</summary>
Motivation: 多用户下行链路的广播特性使通信易受窃听，同时多径传播会降低感知性能，需要一种能同时增强通信安全和感知质量的技术

Method: 提出延迟对齐调制(DAM)，在发射端控制每径符号延迟，使多径在合法用户处相干对齐；采用两阶段协议先估计角度再抑制多径干扰后估计LoS路径延迟；开发基于路径的ZF预编码框架，在CRB和功率约束下最大化最小SSE

Result: 仿真结果显示DAM在SSE方面显著优于最强径基准，同时满足感知要求，因为故意延迟对齐会降低窃听者的接收质量

Conclusion: DAM通过控制多径时延对齐有效增强了ISAC系统的安全性和感知性能，为安全通信与感知一体化提供了有前景的解决方案

Abstract: This paper introduces delay-alignment modulation (DAM) for secure integrated sensing and communication (ISAC). Due to the broadcast nature of multi-user downlinks, communications are vulnerable to eavesdropping. DAM applies controlled per-path symbol delays at the transmitter to coherently align the multipath components at the intended user, enhancing the received signal power, while simultaneously creating delay misalignment at the eavesdropper (Eve). To mitigate sensing degradation caused by multipath propagation, we propose a two-stage protocol that first estimates the angle and then the delay of the line-of-sight (LoS) path after suppressing multipath interference. We derive the secrecy spectral efficiency (SSE) and the Cramer-Rao (CRB) of the target delay. Finally, we develop a path-based zero-forcing (ZF) precoding framework and formulate a max-min SSE design under CRB and power constraints. Simulation results show DAM significantly outperforms the strongest-path (SP) benchmark in terms of SSE, while meeting sensing requirements, since intentional delay alignment at legitimate users degrades reception at Eve.

</details>


### [57] [TCDA: Robust 2D-DOA Estimation for Defective L-Shaped Arrays](https://arxiv.org/abs/2602.21146)
*Wenlong Wang,Tianyang Zhang,Tailun Dong,Lei Zhang*

Main category: cs.IT

TL;DR: 提出TCDA算法，通过张量补全处理故障阵列的DOA估计问题，将物理缺陷转化为虚拟张量空间的数据恢复任务


<details>
  <summary>Details</summary>
Motivation: 基于张量的DOA估计算法在阵列存在故障或稀疏时性能严重下降，因为这些情况违反了所需的流形结构。需要一种能处理阵列缺陷的鲁棒方法

Method: 1. 通过子阵划分、互相关和维度重塑构建不完整的三阶PARAFAC张量；2. 利用张量的内在低秩结构，基于交替最小二乘(ALS)算法直接从观测数据中恢复包含DOA参数的因子矩阵

Result: 该方法提供了软件定义的"自愈"能力，对随机阵元故障表现出卓越的鲁棒性，无需额外的DOA估计处理步骤

Conclusion: TCDA算法成功将阵列物理缺陷问题转化为张量补全任务，通过虚拟张量空间的数据恢复实现了对故障阵列的鲁棒DOA估计

Abstract: While tensor-based methods excel at Direction-of-Arrival (DOA) estimation, their performance degrades severely with faulty or sparse arrays that violate the required manifold structure. To address this challenge, we propose Tensor Completion for Defective Arrays (TCDA), a robust algorithm that reformulates the physical imperfection problem as a data recovery task within a virtual tensor space. We present a detailed derivation for constructing an incomplete third-order Parallel Factor Analysis (PARAFAC) tensor from the faulty array signals via subarray partitioning, cross-correlation, and dimensional reshaping. Leveraging the tensor's inherent low-rank structure, an Alternating Least Squares (ALS)-based algorithm directly recovers the factor matrices embedding the DOA parameters from the incomplete observations. This approach provides a software-defined 'self-healing' capability, demonstrating exceptional robustness against random element failures without requiring additional processing steps for DOA estimation.

</details>


### [58] [Phase-Aware Localization in Pinching Antenna Systems: CRLB Analysis and ML Estimation](https://arxiv.org/abs/2602.21162)
*Hao Feng,Ebrahim Bedeer,Ming Zeng,Xingwang Li,Shimin Gong,Quoc-Viet Pham*

Main category: cs.IT

TL;DR: 该论文研究了在夹持天线系统中利用接收信号幅度和相位信息进行联合定位，相比现有仅使用幅度信息的方法，显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统是高频无线通信的有前景架构，但现有定位方法仅利用幅度信息，忽略了相位信息，限制了定位精度。需要开发同时利用幅度和相位信息的定位方法。

Method: 建立了包含自由空间路径损耗、波导衰减和距离相关相位旋转的复基带信号模型。推导了用户位置的Fisher信息矩阵和CRLB/PEB闭式表达式。开发了联合考虑幅度和相位的最大似然估计器，采用两阶段方法（粗网格搜索+Levenberg-Marquardt优化）解决非凸估计问题。

Result: 数值结果表明，所提出的相位感知估计器在定位精度上优于现有的仅幅度方法，验证了相位信息对提高定位性能的重要性。

Conclusion: 在夹持天线系统中联合利用接收信号的幅度和相位信息可以显著提高定位精度，为高频无线通信中的精确用户定位提供了有效解决方案。

Abstract: Pinching antenna systems (PASS) have recently emerged as a promising architecture for high-frequency wireless communications. In this letter, we investigate localization in PASS by jointly exploiting the received signal amplitude and phase information, unlike recent works that consider only the amplitude information. A complex baseband signal model is formulated to capture free-space path loss, waveguide attenuation, and distance-dependent phase rotation between the user and each pinching antenna. Using this model, we derive the Fisher information matrix (FIM) with respect to the user location and obtain closed-form expressions for the Cramer-Rao lower bound (CRLB) and the position error bound (PEB). A maximum likelihood (ML) estimator that jointly considers the received signal amplitude and phase is developed to estimate the unknown user location. Given the non-convexity of the estimation problem, a two-stage solution combining coarse grid search and Levenberg-Marquardt refinement is proposed. Numerical results demonstrate that the proposed phase-aware estimator outperforms existing amplitude-only method in terms of positioning accuracy.

</details>


### [59] [Wireless-Fed Pinching-Antenna Systems with Horn Antennas](https://arxiv.org/abs/2602.21167)
*Hao Feng,Ming Zeng,Ebrahim Bedeer,Xingwang Li,Octavia A. Dobre,Zhiguo Ding*

Main category: cs.IT

TL;DR: 提出无线馈电夹持天线架构，通过高定向性喇叭天线和全双工放大转发中继，解决高频通信中波导衰减和线路安装限制问题，实现高效覆盖扩展。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统通过波导引导信号和位置可调天线辐射，能增强高频无线通信覆盖，但实际部署受波导衰减和线路安装要求限制，覆盖范围有限。

Method: 提出无线馈电夹持天线架构，在基站和波导输入之间引入配备喇叭天线的全双工放大转发中继，显著改善高频段链路预算并消除自干扰。通过联合优化夹持天线位置、中继放大增益和基站发射功率，最小化总功率消耗。

Result: 通过利用端到端信噪比结构，首先通过平衡波导衰减和自由空间路径损耗，得到闭式最优夹持天线位置，随后推导出最优中继增益和发射功率的闭式表达式。数值结果表明，所提方案在总功耗方面显著优于无中继的传统系统和固定天线中继辅助传输。

Conclusion: 无线馈电夹持天线架构通过高定向性喇叭天线和全双工中继，有效解决了高频通信中波导系统的覆盖限制问题，实现了更高效、更低功耗的覆盖扩展。

Abstract: Pinching-antenna systems have recently emerged as a promising solution for enhancing coverage in high-frequency wireless communications by guiding signals through dielectric waveguides and radiating them via position-adjustable antennas. However, their practical deployment is fundamentally constrained by waveguide attenuation and line-installation requirements, which limit the achievable coverage range. To address this challenge, this paper investigates a wireless-fed pinching-antenna architecture that employs highly directional horn antennas to enable efficient coverage extension. Specifically, a full-duplex amplify-and-forward relay equipped with horn antennas is introduced between the base station and the waveguide input, which significantly improves the link budget in high-frequency bands while effectively eliminating self-interference. On this basis, we formulate a total power minimization problem subject to a quality-of-service constraint at the user equipment, involving the joint optimization of the pinching-antenna position, the relay amplification gain, and the base station transmit power. By exploiting the structure of the end-to-end signal-to-noise ratio, the optimal pinching-antenna position is first obtained in closed form by balancing waveguide attenuation and free-space path loss. Subsequently, closed-form expressions for the optimal relay gain and transmit power are derived. Numerical results demonstrate that the proposed scheme substantially outperforms conventional systems without relaying and relay-assisted transmission with fixed antennas in terms of total power consumption.

</details>
