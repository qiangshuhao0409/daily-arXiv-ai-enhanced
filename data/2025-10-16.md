<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Towards xApp Conflict Evaluation with Explainable Machine Learning and Causal Inference in O-RAN](https://arxiv.org/abs/2510.13031)
*Pragya Sharma,Shihua Sun,Shachi Deshpande,Angelos Stavrou,Haining Wang*

Main category: cs.NI

TL;DR: 提出了一个结合可解释机器学习和因果推理的xApp冲突管理框架，用于识别和量化O-RAN中多个xApp并发操作导致的控制冲突对网络性能的影响。


<details>
  <summary>Details</summary>
Motivation: O-RAN架构支持第三方xApps进行近实时RAN控制，但多个xApps的并发操作可能导致控制动作冲突，造成网络性能下降。

Method: 使用SHAP等模型可解释性工具识别共同影响同一KPI的RAN控制参数，构建因果有向无环图，并通过ATE和CATE等指标估计这些参数对相关KPIs的因果影响。

Result: 该方法能够识别潜在冲突并量化其影响，为网络运营商提供指导性见解。

Conclusion: 该框架使网络运营商能够更明智地制定冲突解决策略，提高不同xApp部署的有效性。

Abstract: The Open Radio Access Network (O-RAN) architecture enables a flexible,
vendor-neutral deployment of 5G networks by disaggregating base station
components and supporting third-party xApps for near real-time RAN control.
However, the concurrent operation of multiple xApps can lead to conflicting
control actions, which may cause network performance degradation. In this work,
we propose a framework for xApp conflict management that combines explainable
machine learning and causal inference to evaluate the causal relationships
between RAN Control Parameters (RCPs) and Key Performance Indicators (KPIs). We
use model explainability tools such as SHAP to identify RCPs that jointly
affect the same KPI, signaling potential conflicts, and represent these
interactions as a causal Directed Acyclic Graph (DAG). We then estimate the
causal impact of each of these RCPs on their associated KPIs using metrics such
as Average Treatment Effect (ATE) and Conditional Average Treatment Effect
(CATE). This approach offers network operators guided insights into identifying
conflicts and quantifying their impacts, enabling more informed and effective
conflict resolution strategies across diverse xApp deployments.

</details>


### [2] [Toward Hyper-Dimensional Connectivity in Beyond 6G: A Conceptual Framework](https://arxiv.org/abs/2510.12896)
*Ekram Hossain,Angelo Vera-Rivera*

Main category: cs.NI

TL;DR: 本文提出了超越6G(B6G)系统的愿景框架，通过集成通信、认知、计算和网络物理能力实现超维连接，支持超沉浸式互联网技术。


<details>
  <summary>Details</summary>
Motivation: 随着5G部署和6G研究进行，需要为B6G系统制定愿景，推动移动宽带技术的未来发展。

Method: 提出了概念框架、技术定义、潜在技术使能器映射以及前瞻性研究议程。

Result: 建立了B6G系统的综合框架，明确了核心连接维度和系统级要求。

Conclusion: 该概念讨论有助于识别创新驱动因素、制定长期技术目标，并为移动宽带技术的未来定义研究议程。

Abstract: Cellular wireless networks enable mobile broadband connectivity for
Internet-based applications through their radio access and core network
infrastructure. While Fifth-Generation (5G) cellular systems are currently
being deployed, ongoing research on cellular technologies primarily focuses on
Sixth-Generation (6G) networks to set the stage for developing standards for
these systems. Therefore, the time has come to articulate the visions for
beyond 6G (B6G) systems. In this article, we present a visionary framework
toward hyper-dimensional connectivity in B6G that enables wireless access to
hyper-immersive Internet technologies. Our contributions include a conceptual
framework for B6G cellular systems with jointly integrated communication,
cognition, computing, and cyber-physical capabilities as core connectivity
dimensions, a set of technical definitions outlining potential use cases and
system-level requirements, a mapping of prospective technology enablers, and a
forward-looking research agenda for B6G systems. The conceptual discussions in
this article would be helpful for identifying innovation drivers, shaping
long-term technical goals, and defining research agendas for the future of
mobile broadband technologies.

</details>


### [3] [Automated Network Protocol Testing with LLM Agents](https://arxiv.org/abs/2510.13248)
*Yunze Wei,Kaiwen Wei,Shibo Du,Jianyu Wang,Zhangzhong Liu,Yawen Wang,Zhanyou Li,Congcong Miao,Xiaohui Xie,Yong Cui*

Main category: cs.NI

TL;DR: NeTestLLM是一个基于多智能体大语言模型的端到端自动化网络协议测试系统，通过分层协议理解、迭代测试用例生成和运行时反馈分析，显著提高了测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统网络协议测试方法劳动密集且容易出错，每个测试用例需要一个人日的工作量。现有基于模型的方法虽然提供部分自动化，但仍需要大量人工建模和专家干预，成本高且难以适应多样化和不断演进的协议。

Method: 采用多智能体LLM进行端到端自动化测试，包括分层协议理解捕获复杂规范、迭代测试用例生成提高覆盖率、任务特定工作流生成可执行工件、运行时反馈分析用于调试和优化。

Result: 在生产环境中部署数月获得领域专家积极反馈。实验中生成了4,632个OSPF、RIP和BGP测试用例，覆盖41个历史FRRouting bug，而国家标准仅覆盖11个。生成可执行工件的效率比人工方法提高8.65倍。

Conclusion: NeTestLLM为异构网络协议的自动化端到端测试提供了首个实用的LLM驱动解决方案。

Abstract: Network protocol testing is fundamental for modern network infrastructure.
However, traditional network protocol testing methods are labor-intensive and
error-prone, requiring manual interpretation of specifications, test case
design, and translation into executable artifacts, typically demanding one
person-day of effort per test case. Existing model-based approaches provide
partial automation but still involve substantial manual modeling and expert
intervention, leading to high costs and limited adaptability to diverse and
evolving protocols. In this paper, we propose a first-of-its-kind system called
NeTestLLM that takes advantage of multi-agent Large Language Models (LLMs) for
end-to-end automated network protocol testing. NeTestLLM employs hierarchical
protocol understanding to capture complex specifications, iterative test case
generation to improve coverage, a task-specific workflow for executable
artifact generation, and runtime feedback analysis for debugging and
refinement. NeTestLLM has been deployed in a production environment for several
months, receiving positive feedback from domain experts. In experiments,
NeTestLLM generated 4,632 test cases for OSPF, RIP, and BGP, covering 41
historical FRRouting bugs compared to 11 by current national standards. The
process of generating executable artifacts also improves testing efficiency by
a factor of 8.65x compared to manual methods. NeTestLLM provides the first
practical LLM-powered solution for automated end-to-end testing of
heterogeneous network protocols.

</details>


### [4] [NetMCP: Network-Aware Model Context Protocol Platform for LLM Capability Extension](https://arxiv.org/abs/2510.13467)
*Enhan Li,Hongyang Du,Kaibin Huang*

Main category: cs.NI

TL;DR: 提出NetMCP平台和SONAR算法，通过结合语义相似性和网络QoS指标来增强MCP工具路由，解决现有系统在网络延迟波动或服务器故障时的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM扩展功能依赖MCP协议，但现有实现仅基于语义匹配，在网络延迟波动或服务器故障时表现脆弱，需要增强实时网络状态感知能力。

Method: 构建异构实验平台NetMCP，提供五种代表性网络状态，并提出SONAR算法联合优化语义相似性和网络QoS指标进行自适应工具路由。

Result: SONAR相比仅基于语义或LLM的基线方法，持续提高了任务成功率，减少了完成时间和失败次数。

Conclusion: 网络感知设计对生产级LLM系统具有重要价值，SONAR算法能有效提升系统在动态网络环境下的鲁棒性。

Abstract: Large Language Models (LLMs) remain static in functionality after training,
and extending their capabilities requires integration with external data,
computation, and services. The Model Context Protocol (MCP) has emerged as a
standard interface for such extensions, but current implementations rely solely
on semantic matching between users' requests and server function descriptions,
which makes current deployments and simulation testbeds fragile under latency
fluctuations or server failures. We address this gap by enhancing MCP tool
routing algorithms with real-time awareness of network and server status. To
provide a controlled test environment for development and evaluation, we
construct a heterogeneous experimental platform, namely Network-aware MCP
(NetMCP), which offers five representative network states and build a benchmark
for latency sequence generation and MCP server datasets. On top of NetMCP
platform, we analyze latency sequences and propose a Semantic-Oriented and
Network-Aware Routing (SONAR) algorithm, which jointly optimizes semantic
similarity and network Quality of Service (QoS) metrics for adaptive tool
routing. Results show that SONAR consistently improves task success rate and
reduces completion time and failure number compared with semantic-only,
LLM-based baselines, demonstrating the value of network-aware design for
production-scale LLM systems. The code for NetMCP is available at
https://github.com/NICE-HKU/NetMCP.

</details>


### [5] [Fair Ordering](https://arxiv.org/abs/2510.13664)
*Muhammad Haseeb,Jinkun Geng,Radhika Mittal,Aurojit Panda,Srinivas Narayana,Anirudh Sivaraman*

Main category: cs.NI

TL;DR: Tommy系统通过概率模型比较噪声时间戳，提出likely-happened-before关系来解决事件公平排序问题，而非消除时钟误差。


<details>
  <summary>Details</summary>
Motivation: 传统事件排序受限于时钟同步问题，无法保证先发生的事件被优先处理。需要一种能够容忍时钟变化的方法来实现公平排序。

Method: 使用统计模型学习每个时钟的偏移分布，通过概率比较两个噪声时间戳，计算一个事件在另一个事件之前发生的概率。

Result: 提出了likely-happened-before关系(→p)，为原本在happened-before关系中并发的事件提供排序基础。

Conclusion: 接受而非消除时钟变化是解决公平排序问题的可行方向，但面临→p关系不可传递等挑战，需要进一步研究在线公平排序、随机公平全序等问题。

Abstract: A growing class of applications demands \emph{fair ordering/sequencing} of
events which ensures that events generated earlier by one client are processed
before later events from other clients. However, achieving such sequencing is
fundamentally challenging due to the inherent limitations of clock
synchronization. We advocate for an approach that embraces, rather than
eliminates, clock variability. Instead of attempting to remove error from a
timestamp, Tommy, our proposed system, leverages a statistical model to compare
two noisy timestamps probabilistically by learning per-clock offset
distributions. Our preliminary statistical model computes the probability that
one event precedes another w.r.t. the wall-clock time without access to the
wall-clock. This serves as a foundation for a new relation:
\emph{likely-happened-before} denoted by $\xrightarrow{p}$ where $p$ represents
the probability of an event to have happened before another. The
$\xrightarrow{p}$ relation provides a basis for ordering multiple events which
are otherwise considered \emph{concurrent} by the typical
\emph{happened-before} ($\rightarrow$) relation. We highlight various related
challenges including intransitivity of $\xrightarrow{p}$ relation as opposed to
the transitive $\rightarrow$ relation. We also outline several research
directions: online fair sequencing, stochastically fair total ordering,
host-level support for fairness and more.

</details>


### [6] [Optimize Replica Server Placement in a Satellite Network](https://arxiv.org/abs/2510.13689)
*Zhiyuan He,Yi Xu,Cheng Luo,Lili Qiu,Yuqing Yang*

Main category: cs.NI

TL;DR: 提出在卫星网络中部署内容副本服务器，优化副本放置以降低延迟、传输和存储成本，支持LEO、MEO、GEO等不同类型卫星网络，特别考虑了LEO和MEO卫星的移动性挑战。


<details>
  <summary>Details</summary>
Motivation: 卫星通信为偏远地区提供互联网连接，但传输成本远高于传统互联网，需要降低内容传输成本。

Method: 在卫星网络中放置内容副本服务器，考虑卫星移动轨迹，优化客户端性能和卫星间内容传输成本。

Result: 通过模拟流量轨迹和原型系统验证了方法的有效性。

Conclusion: 提出的方法能有效优化卫星网络中的内容副本放置，降低传输成本并提升性能。

Abstract: Satellite communication offers Internet connectivity to remote locations,
such as villages, deserts, mountains, and at sea. However, transmitting content
over satellite networks is significantly more expensive than traditional
Internet. To address this issue, we propose placing content replica servers
within satellite networks and optimizing replica placement for important
performance metrics, such as latency, transmission, and storage cost. Our
approach can support different types of satellite networks, including Low Earth
Orbit (LEO), Medium Earth Orbit (MEO), Geostationary Orbit (GEO), and their
combinations. An important challenge for supporting content replicas in such
networks is that LEO and MEO satellites are constantly moving. We address this
challenge by explicitly considering their moving trajectories and strategically
optimizing not only client performance, but also the cost of transferring
content from one satellite to another as needed. We demonstrate the
effectiveness of our approach using both simulated traffic traces and a
prototype system.

</details>


### [7] [Investigating Web Content Delivery Performance over Starlink](https://arxiv.org/abs/2510.13710)
*Rohan Bose,Jinwei Zhao,Tanya Shreedhar,Jianping Pan,Nitinder Mohan*

Main category: cs.NI

TL;DR: 该研究首次全面测量分析了Starlink卫星互联网在PoP、DNS和CDN层的网页内容分发性能，发现基础设施密度决定性能表现，卫星覆盖并非主要影响因素。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星互联网提供商承诺提供全球互联网连接，但其与内容分发系统的交互机制尚未被充分理解，需要系统性的性能测量分析。

Method: 通过两年时间结合22.5万次Cloudflare AIM测试、M-Lab数据，以及从99个RIPE Atlas和受控Starlink探针进行主动探测，收集了610万条路由追踪和1080万次DNS查询。

Result: 识别出三种性能模式：基础设施密集区域接近地面网络延迟；基础设施稀疏区域因远程PoP导致CDN定位错误，延迟超过200ms；利用2025年初Starlink基础设施扩张实验显示，将PoP靠近用户可将页面获取时间中位数减少60%。

Conclusion: 基础设施邻近性而非卫星覆盖是影响网页性能的关键因素，需要对卫星ISP的CDN映射和DNS解析进行根本性改变。

Abstract: Low Earth Orbit (LEO) satellite ISPs promise universal Internet connectivity,
yet their interaction with content delivery remains poorly understood. We
present the first comprehensive measurement study decomposing Starlink's web
content delivery performance decomposed across Point of Presence (PoP), DNS,
and CDN layers. Through two years of measurements combining 225K Cloudflare AIM
tests, M-Lab data, and active probing from 99 RIPE Atlas and controlled
Starlink probes, we collect 6.1M traceroutes and 10.8M DNS queries to quantify
how satellite architecture disrupts terrestrial CDN assumptions. We identify
three distinct performance regimes based on infrastructure density. Regions
with local content-rich PoPs achieve near-terrestrial latencies with the
satellite segment dominating 80-90% of RTT. Infrastructure-sparse regions
suffer cascading penalties: remote PoPs force distant resolver selection, which
triggers CDN mis-localization, pushing latencies beyond 200 ms.
Dense-infrastructure regions show minimal sensitivity to PoP changes.
Leveraging Starlink's infrastructure expansion in early 2025 as a natural
experiment, we demonstrate that relocating PoPs closer to user location reduces
median page-fetch times by 60%. Our findings reveal that infrastructure
proximity, not satellite coverage, influences web performance, requiring
fundamental changes to CDN mapping and DNS resolution for satellite ISPs.

</details>


### [8] [Scalable Pilot Assignment for Distributed Massive MIMO using Channel Estimation Error](https://arxiv.org/abs/2510.13732)
*Mohd Saif Ali Khan,Karthik RM,Samar Agnihotri*

Main category: cs.NI

TL;DR: 提出了两种动态可扩展的导频分配策略来解决分布式大规模MIMO系统中的导频污染问题：一种是低复杂度的集中式算法，另一种是完全分布式的优先级导频选择算法。


<details>
  <summary>Details</summary>
Motivation: 导频污染是分布式大规模MIMO系统实现其全部潜力的主要瓶颈，需要设计实用的导频分配策略来改善信道估计质量并减少用户间干扰。

Method: 1. 集中式算法：顺序为用户设备分配导频以最小化全局信道估计误差；2. 分布式算法：基于优先级的导频选择，每个接入点使用本地信息最小化估计误差，用户根据接入点优先级选择合适的导频。

Result: 数值仿真表明，所提出的方案在网络吞吐量方面优于其他最先进的基准方案，显著减少了导频污染。

Conclusion: 提出的两种导频分配策略能够有效解决导频污染问题，提高频谱效率，其中分布式算法无需全局协调，保持了低信令开销并能动态适应用户部署。

Abstract: Pilot contamination remains a major bottleneck in realizing the full
potential of distributed massive MIMO systems. We propose two dynamic and
scalable pilot assignment strategies designed for practical deployment in such
networks. First, we present a low complexity centralized algorithm that
sequentially assigns pilots to user equipments (UEs) to minimize the global
channel estimation errors across serving access points (APs). This improves the
channel estimation quality and reduces interference among UEs, enhancing the
spectral efficiency. Second, we develop a fully distributed algorithm that uses
a priority-based pilot selection approach. In this algorithm, each selected AP
minimizes estimation error using only local information and offers candidate
pilots to the UEs. Every UE then selects a suitable pilot based on AP priority.
This approach ensures consistency and minimizes interference while
significantly reducing pilot contamination. The method requires no global
coordination, maintains low signaling overhead, and adapts dynamically to the
UE deployment. Numerical simulations demonstrate the superiority of our
proposed schemes in terms of network throughput when compared to other
state-of-the-art benchmark schemes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models](https://arxiv.org/abs/2510.12864)
*Imran Khan*

Main category: cs.AI

TL;DR: 提出了Rule-Intent Distinction (RID)框架，一种零样本元提示技术，通过结构化认知模式帮助LLM处理规则冲突，实现与人类意图对齐的决策。


<details>
  <summary>Details</summary>
Motivation: 现有LLM存在规则刚性缺陷，过度依赖显式规则导致决策与人类常识和意图不符。监督微调虽然有效但计算成本高，需要更实用的解决方案。

Method: RID框架通过元提示技术，为模型提供结构化认知模式，包括任务解构、规则分类、冲突结果权衡和决策论证四个步骤。

Result: 在20个需要细微判断的场景基准测试中，RID框架达到95%的人类对齐分数，显著优于基线(80%)和思维链提示(75%)，并产生更高质量的意图驱动推理。

Conclusion: RID框架提供了一种实用、易用且有效的方法，引导LLM从字面指令遵循转向灵活的目标导向推理，为构建更可靠和实用的AI智能体铺平道路。

Abstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning
engines for agentic AI systems, yet they exhibit a critical flaw: a rigid
adherence to explicit rules that leads to decisions misaligned with human
common sense and intent. This "rule-rigidity" is a significant barrier to
building trustworthy autonomous agents. While prior work has shown that
supervised fine-tuning (SFT) with human explanations can mitigate this issue,
SFT is computationally expensive and inaccessible to many practitioners. To
address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a
novel, low-compute meta-prompting technique designed to elicit human-aligned
exception handling in LLMs in a zero-shot manner. The RID framework provides
the model with a structured cognitive schema for deconstructing tasks,
classifying rules, weighing conflicting outcomes, and justifying its final
decision. We evaluated the RID framework against baseline and Chain-of-Thought
(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced
judgment across diverse domains. Our human-verified results demonstrate that
the RID framework significantly improves performance, achieving a 95% Human
Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT.
Furthermore, it consistently produces higher-quality, intent-driven reasoning.
This work presents a practical, accessible, and effective method for steering
LLMs from literal instruction-following to liberal, goal-oriented reasoning,
paving the way for more reliable and pragmatic AI agents.

</details>


### [10] [DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping](https://arxiv.org/abs/2510.12979)
*Wei Fan,Wenlin Yao,Zheng Li,Feng Yao,Xin Liu,Liang Qiu,Qingyu Yin,Yangqiu Song,Bing Yin*

Main category: cs.AI

TL;DR: DeepPlanner是一个端到端的强化学习框架，通过熵基优势函数和选择性样本加权来增强深度研究代理的规划能力，在多个基准测试中实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖推理阶段的隐式规划，要么引入显式规划器但没有系统优化规划阶段。研究发现规划标记的熵显著高于其他动作标记，表明存在未优化的不确定决策点。

Method: 提出DeepPlanner框架，通过熵基优势函数为高熵标记分配更大更新，并为规划密集型rollout选择性加权样本级优势。

Result: 在七个深度研究基准测试上的广泛实验表明，DeepPlanner提高了规划质量，并在显著降低训练预算的情况下实现了最先进的结果。

Conclusion: DeepPlanner通过系统优化规划阶段，有效增强了深度研究代理的规划能力，为复杂任务的长时程规划提供了有效解决方案。

Abstract: Large language models (LLMs) augmented with multi-step reasoning and action
generation abilities have shown promise in leveraging external tools to tackle
complex tasks that require long-horizon planning. However, existing approaches
either rely on implicit planning in the reasoning stage or introduce explicit
planners without systematically addressing how to optimize the planning stage.
As evidence, we observe that under vanilla reinforcement learning (RL),
planning tokens exhibit significantly higher entropy than other action tokens,
revealing uncertain decision points that remain under-optimized. To address
this, we propose DeepPlanner, an end-to-end RL framework that effectively
enhances the planning capabilities of deep research agents. Our approach shapes
token-level advantage with an entropy-based term to allocate larger updates to
high entropy tokens, and selectively upweights sample-level advantages for
planning-intensive rollouts. Extensive experiments across seven deep research
benchmarks demonstrate that DeepPlanner improves planning quality and achieves
state-of-the-art results under a substantially lower training budget.

</details>


### [11] [SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents](https://arxiv.org/abs/2510.12985)
*Simon Sinong Zhan,Yao Liu,Philip Wang,Zinan Wang,Qineng Wang,Zhian Ruan,Xiangyu Shi,Xinyu Cao,Frank Yang,Kangrui Wang,Huajie Shao,Manling Li,Qi Zhu*

Main category: cs.AI

TL;DR: Sentinel是首个基于形式化时序逻辑的LLM具身智能体物理安全评估框架，通过语义、规划和轨迹三个层次的多级验证流程，系统性地评估智能体在物理环境中的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式规则或主观的LLM判断，缺乏对物理安全的严格形式化定义和验证，无法精确检测LLM具身智能体在物理环境中的安全隐患。

Method: 使用时序逻辑形式化安全需求，建立三级验证管道：语义层验证LLM对安全需求的理解，规划层验证高层动作计划，轨迹层验证执行轨迹的物理安全性。

Result: 在VirtualHome和ALFRED环境中的实验表明，Sentinel能够发现先前方法忽略的安全违规，提供对失败模式的深入洞察。

Conclusion: 通过将物理安全基于时序逻辑并在多个层次应用验证方法，Sentinel为系统评估LLM具身智能体在物理环境中的安全性提供了严格基础。

Abstract: We present Sentinel, the first framework for formally evaluating the physical
safety of Large Language Model(LLM-based) embodied agents across the semantic,
plan, and trajectory levels. Unlike prior methods that rely on heuristic rules
or subjective LLM judgments, Sentinel grounds practical safety requirements in
formal temporal logic (TL) semantics that can precisely specify state
invariants, temporal dependencies, and timing constraints. It then employs a
multi-level verification pipeline where (i) at the semantic level, intuitive
natural language safety requirements are formalized into TL formulas and the
LLM agent's understanding of these requirements is probed for alignment with
the TL formulas; (ii) at the plan level, high-level action plans and subgoals
generated by the LLM agent are verified against the TL formulas to detect
unsafe plans before execution; and (iii) at the trajectory level, multiple
execution trajectories are merged into a computation tree and efficiently
verified against physically-detailed TL specifications for a final safety
check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate
multiple LLM-based embodied agents against diverse safety requirements. Our
experiments show that by grounding physical safety in temporal logic and
applying verification methods across multiple levels, Sentinel provides a
rigorous foundation for systematically evaluating LLM-based embodied agents in
physical environments, exposing safety violations overlooked by previous
methods and offering insights into their failure modes.

</details>


### [12] [From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model](https://arxiv.org/abs/2510.13002)
*Boyou Chen,Gerui Xu,Zifei Wang,Huizhong Guo,Ananna Ahmed,Zhaonan Sun,Zhen Hu,Kaihan Zhang,Shan Bao*

Main category: cs.AI

TL;DR: 提出基于微调大语言模型的框架，自动从交通事故文本叙述中推断驾驶员危险行为，提高分类的有效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 两车事故占道路事故约70%，但人工编码驾驶员危险行为数据存在不一致性和劳动密集型问题，需要自动化解决方案。

Method: 使用MTCF五年两车事故数据，微调Llama 3.2 1B模型处理详细事故叙述，并与随机森林、XGBoost、CatBoost和神经网络等传统机器学习分类器进行基准比较。

Result: 微调LLM达到80%的整体准确率，优于所有基线模型，在数据不平衡场景中表现尤为突出。通过概率推理方法分析模型输出变化，发现分心驾驶和青少年驾驶对特定危险行为概率的显著影响。

Conclusion: 该框架为大规模自动DHA检测提供了稳健且可解释的解决方案，为交通安全分析和干预开辟了新机会。

Abstract: Vehicle crashes involve complex interactions between road users, split-second
decisions, and challenging environmental conditions. Among these, two-vehicle
crashes are the most prevalent, accounting for approximately 70% of roadway
crashes and posing a significant challenge to traffic safety. Identifying
Driver Hazardous Action (DHA) is essential for understanding crash causation,
yet the reliability of DHA data in large-scale databases is limited by
inconsistent and labor-intensive manual coding practices. Here, we present an
innovative framework that leverages a fine-tuned large language model to
automatically infer DHAs from textual crash narratives, thereby improving the
validity and interpretability of DHA classifications. Using five years of
two-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on
detailed crash narratives and benchmarked its performance against conventional
machine learning classifiers, including Random Forest, XGBoost, CatBoost, and a
neural network. The fine-tuned LLM achieved an overall accuracy of 80%,
surpassing all baseline models and demonstrating pronounced improvements in
scenarios with imbalanced data. To increase interpretability, we developed a
probabilistic reasoning approach, analyzing model output shifts across original
test sets and three targeted counterfactual scenarios: variations in driver
distraction and age. Our analysis revealed that introducing distraction for one
driver substantially increased the likelihood of "General Unsafe Driving";
distraction for both drivers maximized the probability of "Both Drivers Took
Hazardous Actions"; and assigning a teen driver markedly elevated the
probability of "Speed and Stopping Violations." Our framework and analytical
methods provide a robust and interpretable solution for large-scale automated
DHA detection, offering new opportunities for traffic safety analysis and
intervention.

</details>


### [13] [Toward Reasoning-Centric Time-Series Analysis](https://arxiv.org/abs/2510.13029)
*Xinlei Wang,Mingtian Tan,Jing Qiu,Junhua Zhao,Jinjin Gu*

Main category: cs.AI

TL;DR: 本文主张将时间序列分析重新构想为推理任务，利用LLMs的深层推理潜力而非数值回归能力，强调因果结构和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列分析需要超越表面趋势，揭示驱动因素。现有LLM方法大多忽视其深层推理潜力，仅使用数值回归能力。

Method: 将时间序列分析作为推理任务，利用LLMs整合多模态输入，优先考虑因果结构和可解释性。

Result: 该方法使时间序列分析更接近人类对齐的理解，在复杂现实环境中提供透明和上下文感知的洞察。

Conclusion: 重新思考时间序列与LLMs作为推理任务，能够实现更透明、上下文感知的分析，推动时间序列分析向人类对齐理解发展。

Abstract: Traditional time series analysis has long relied on pattern recognition,
trained on static and well-established benchmarks. However, in real-world
settings -- where policies shift, human behavior adapts, and unexpected events
unfold -- effective analysis must go beyond surface-level trends to uncover the
actual forces driving them. The recent rise of Large Language Models (LLMs)
presents new opportunities for rethinking time series analysis by integrating
multimodal inputs. However, as the use of LLMs becomes popular, we must remain
cautious, asking why we use LLMs and how to exploit them effectively. Most
existing LLM-based methods still employ their numerical regression ability and
ignore their deeper reasoning potential. This paper argues for rethinking time
series with LLMs as a reasoning task that prioritizes causal structure and
explainability. This shift brings time series analysis closer to human-aligned
understanding, enabling transparent and context-aware insights in complex
real-world environments.

</details>


### [14] [Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking](https://arxiv.org/abs/2510.13036)
*Stephane Hatgis-Kessell,Logan Mondal Bhamidipaty,Emma Brunskill*

Main category: cs.AI

TL;DR: 提出了一种基于偏好的奖励修复框架，通过从人类偏好中学习一个加性的、状态转移相关的修正项来自动修复人工设计的代理奖励函数，解决了奖励函数错配和奖励黑客问题。


<details>
  <summary>Details</summary>
Motivation: 人工设计的奖励函数经常与人类真实目标不一致，作为代理函数容易导致奖励黑客问题；而从零开始学习奖励函数需要大量人类偏好数据，成本高昂。

Method: 提出PBRR框架：使用目标探索策略识别关键状态转移，通过新的偏好学习目标学习加性修正项，逐步修复代理奖励函数。

Result: 在表格域中证明了PBRR的累积遗憾与现有偏好学习RL方法相当；在奖励黑客基准测试中，PBRR始终优于基线方法，需要更少的偏好数据就能学习到高性能策略。

Conclusion: PBRR框架有效解决了奖励函数错配问题，通过少量偏好数据就能修复代理奖励函数，在性能和效率上都优于现有方法。

Abstract: Human-designed reward functions for reinforcement learning (RL) agents are
frequently misaligned with the humans' true, unobservable objectives, and thus
act only as proxies. Optimizing for a misspecified proxy reward function often
induces reward hacking, resulting in a policy misaligned with the human's true
objectives. An alternative is to perform RL from human feedback, which involves
learning a reward function from scratch by collecting human preferences over
pairs of trajectories. However, building such datasets is costly. To address
the limitations of both approaches, we propose Preference-Based Reward Repair
(PBRR): an automated iterative framework that repairs a human-specified proxy
reward function by learning an additive, transition-dependent correction term
from preferences. A manually specified reward function can yield policies that
are highly suboptimal under the ground-truth objective, yet corrections on only
a few transitions may suffice to recover optimal performance. To identify and
correct for those transitions, PBRR uses a targeted exploration strategy and a
new preference-learning objective. We prove in tabular domains PBRR has a
cumulative regret that matches, up to constants, that of prior preference-based
RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR
consistently outperforms baselines that learn a reward function from scratch
from preferences or modify the proxy reward function using other approaches,
requiring substantially fewer preferences to learn high performing policies.

</details>


### [15] [Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation](https://arxiv.org/abs/2510.13195)
*Qun Ma,Xiao Xue,Xuwen Zhang,Zihan Zhao,Yuwei Guo,Ming Zhang*

Main category: cs.AI

TL;DR: 提出了一个情感认知框架，通过欲望生成和目标管理实现LLM智能体与人类的情感对齐，在决策过程中模拟状态演化、欲望生成、目标优化、决策生成和行动执行。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在情感认知方面存在严重局限：无法模拟连接虚拟与现实服务的有限理性；缺乏经过实证验证的情感整合机制。

Method: 构建情感认知框架，包含欲望生成和目标管理，在专有多智能体交互环境中实现完整决策过程。

Result: 实验显示，采用该框架的智能体不仅表现出与情感状态一致的行为，而且在比较评估中展现出更高的生态效度，决策结果更接近人类行为模式。

Conclusion: 该情感认知框架成功提升了LLM智能体在情感认知和决策模拟方面的能力，使其行为更符合人类模式。

Abstract: The advent of large language models (LLMs) has enabled agents to represent
virtual humans in societal simulations, facilitating diverse interactions
within complex social systems. However, existing LLM-based agents exhibit
severe limitations in affective cognition: They fail to simulate the bounded
rationality essential for bridging virtual and real-world services; They lack
empirically validated integration mechanisms embedding emotions within agent
decision architectures. This paper constructs an emotional cognition framework
incorporating desire generation and objective management, designed to achieve
emotion alignment between LLM-based agents and humans, modeling the complete
decision-making process of LLM-based agents, encompassing state evolution,
desire generation, objective optimization, decision generation, and action
execution. This study implements the proposed framework within our proprietary
multi-agent interaction environment. Experimental results demonstrate that
agents governed by our framework not only exhibit behaviors congruent with
their emotional states but also, in comparative assessments against other agent
types, demonstrate superior ecological validity and generate decision outcomes
that significantly more closely approximate human behavioral patterns.

</details>


### [16] [Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning](https://arxiv.org/abs/2510.13214)
*Zehui Ling,Deshu Chen,Yichi Zhang,Yuchen Liu,Xigui Li,Xin Guo,Yuan Cheng*

Main category: cs.AI

TL;DR: 提出了一种结合小型和大型语言模型的互补代理系统，通过小型LLM生成初始答案，大型LLM进行验证，仅在必要时进行深度推理，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的深度推理虽然能提升复杂任务性能，但计算成本高昂。需要一种方法在保持性能的同时降低计算开销。

Method: 使用小型LLM生成初始答案，大型LLM进行验证，仅在答案错误时进行深度推理，避免对所有问题都使用昂贵的深度推理。

Result: 在简单问题上，大型LLM的计算成本降低超过50%，准确率损失可忽略，同时在复杂任务上保持稳健性能。

Conclusion: 该互补代理系统有效平衡了计算成本与性能，为LLM的实际应用提供了经济高效的解决方案。

Abstract: Recent advances in Large Language Models (LLMs) demonstrate that
chain-of-thought prompting and deep reasoning substantially enhance performance
on complex tasks, and multi-agent systems can further improve accuracy by
enabling model debates. However, applying deep reasoning to all problems is
computationally expensive. To mitigate these costs, we propose a complementary
agent system integrating small and large LLMs. The small LLM first generates an
initial answer, which is then verified by the large LLM. If correct, the answer
is adopted directly; otherwise, the large LLM performs in-depth reasoning.
Experimental results show that, for simple problems, our approach reduces the
computational cost of the large LLM by more than 50% with negligible accuracy
loss, while consistently maintaining robust performance on complex tasks.

</details>


### [17] [Mobile Coverage Analysis using Crowdsourced Data](https://arxiv.org/abs/2510.13459)
*Timothy Wong,Tom Freeman,Joseph Feehily*

Main category: cs.AI

TL;DR: 提出了一种基于众包QoE数据的移动网络覆盖和弱信号点分析框架，使用OC-SVM算法计算覆盖范围并识别服务弱区


<details>
  <summary>Details</summary>
Motivation: 准确评估移动网络覆盖和识别服务弱区对于提升用户体验质量至关重要

Method: 在单个小区级别进行覆盖分析，然后聚合到站点级别，使用OC-SVM算法建模覆盖边界，并将相同方法扩展到分析众包服务丢失报告

Result: 该框架能准确映射移动网络覆盖，特别是在复杂城市环境中突出显示信号不足的细粒度区域

Conclusion: 该新颖框架在移动网络覆盖映射和弱信号点识别方面表现出高效性

Abstract: Effective assessment of mobile network coverage and the precise
identification of service weak spots are paramount for network operators
striving to enhance user Quality of Experience (QoE). This paper presents a
novel framework for mobile coverage and weak spot analysis utilising
crowdsourced QoE data. The core of our methodology involves coverage analysis
at the individual cell (antenna) level, subsequently aggregated to the site
level, using empirical geolocation data. A key contribution of this research is
the application of One-Class Support Vector Machine (OC-SVM) algorithm for
calculating mobile network coverage. This approach models the decision
hyperplane as the effective coverage contour, facilitating robust calculation
of coverage areas for individual cells and entire sites. The same methodology
is extended to analyse crowdsourced service loss reports, thereby identifying
and quantifying geographically localised weak spots. Our findings demonstrate
the efficacy of this novel framework in accurately mapping mobile coverage and,
crucially, in highlighting granular areas of signal deficiency, particularly
within complex urban environments.

</details>


### [18] [Personalized Learning Path Planning with Goal-Driven Learner State Modeling](https://arxiv.org/abs/2510.13215)
*Joy Jia Yin Lim,Ye He,Jifan Yu,Xin Cong,Daniel Zhang-Li,Zhiyuan Liu,Huiqin Liu,Lei Hou,Juanzi Li,Bin Xu*

Main category: cs.AI

TL;DR: Pxplore是一个个性化学习路径规划框架，结合强化学习训练范式和LLM驱动的教育架构，通过结构化学习者状态模型和自动奖励函数实现目标对齐的个性化学习路径生成。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的个性化学习方法缺乏目标对齐规划机制，无法有效设计符合个人目标的自适应学习路径。

Method: 设计结构化学习者状态模型和自动奖励函数，结合监督微调(SFT)和组相对策略优化(GRPO)训练策略，并在真实学习平台中部署。

Result: 大量实验验证了Pxplore在生成连贯、个性化和目标驱动的学习路径方面的有效性。

Conclusion: Pxplore框架能够有效实现目标对齐的个性化学习路径规划，为未来研究提供了代码和数据集支持。

Abstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning
paths that align with individual goals. While large language models (LLMs) show
potential in personalizing learning experiences, existing approaches often lack
mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework
for PLPP that integrates a reinforcement-based training paradigm and an
LLM-driven educational architecture. We design a structured learner state model
and an automated reward function that transforms abstract objectives into
computable signals. We train the policy combining supervised fine-tuning (SFT)
and Group Relative Policy Optimization (GRPO), and deploy it within a
real-world learning platform. Extensive experiments validate Pxplore's
effectiveness in producing coherent, personalized, and goal-driven learning
paths. We release our code and dataset to facilitate future research.

</details>


### [19] [EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems](https://arxiv.org/abs/2510.13220)
*Yufei He,Juncheng Liu,Yue Liu,Yibo Li,Tri Cao,Zhiyuan Hu,Xinxing Xu,Bryan Hooi*

Main category: cs.AI

TL;DR: 提出了J-TTL基准测试来衡量AI代理在测试时学习复杂技能的能力，并开发了EvoTest进化框架，通过演化整个代理系统来提升性能，无需微调或梯度计算。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理无法在测试时动态学习复杂技能，限制了实际应用价值。需要系统性地衡量和推动这一挑战的进展。

Method: 引入J-TTL基准测试，要求代理在连续多轮游戏中提升表现。提出EvoTest框架，包含执行游戏的Actor代理和分析改进的Evolver代理，通过演化配置（提示重写、记忆更新、超参数调优、工具使用学习）来提升性能。

Result: EvoTest在J-TTL基准上持续提升性能，优于反思、记忆和在线微调等方法。是唯一能赢得Detective和Library两个游戏的方法，而所有基线方法都无法赢得任何游戏。

Conclusion: EvoTest证明了通过演化整个代理系统可以在测试时有效学习复杂技能，为解决AI代理在未知环境中的适应性问题提供了有前景的方向。

Abstract: A fundamental limitation of current AI agents is their inability to learn
complex skills on the fly at test time, often behaving like "clever but
clueless interns" in novel environments. This severely limits their practical
utility. To systematically measure and drive progress on this challenge, we
first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a
new evaluation setup where an agent must play the same game for several
consecutive episodes, attempting to improve its performance from one episode to
the next. On J-TTL, we find that existing adaptation methods like reflection,
memory, or reinforcement learning struggle. To address the challenges posed by
our benchmark, we present EvoTest, an evolutionary test-time learning framework
that improves an agent without any fine-tuning or gradients-by evolving the
entire agentic system after every episode. EvoTest has two roles: the Actor
Agent, which plays the game, and the Evolver Agent, which analyzes the episode
transcript to propose a revised configuration for the next run. This
configuration rewrites the prompt, updates memory by logging effective
state-action choices, tunes hyperparameters, and learns the tool-use routines.
On our J-TTL benchmark, EvoTest consistently increases performance,
outperforming not only reflection and memory-only baselines but also more
complex online fine-tuning methods. Notably, our method is the only one capable
of winning two games (Detective and Library), while all baselines fail to win
any.

</details>


### [20] [An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities](https://arxiv.org/abs/2510.13230)
*Jalal Khan,Manzoor Khan,Sherzod Turaev,Sumbal Malik,Hesham El-Sayed,Farman Ullah*

Main category: cs.AI

TL;DR: 提出了一种基于效用的分析模型，用于自动驾驶车辆的环境感知系统，通过YOLOv8s目标检测模型和自定义数据集来评估感知服务的效用。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要准确感知道路上的多个物体并预测驾驶员感知，以控制车辆运动，需要开发能够理解驾驶环境的感知系统。

Method: 使用自定义数据集（包含摩托车手、三轮车等独特物体），采用YOLOv8s深度学习模型进行目标检测，并基于训练模型实例的性能值来测量感知服务的效用。

Result: 实验结果显示三个性能最佳的YOLOv8s实例：SGD-based (mAP@0.5=0.832)、Adam-based (0.810)和AdamW-based (0.822)。AdamW模型在类别级别性能上表现更好（汽车：0.921，摩托车手：0.899，卡车：0.793等）。

Conclusion: 提出的感知模型能够有效评估学习模型的效用，并为自动驾驶车辆确定合适的感知方案。

Abstract: The driving environment perception has a vital role for autonomous driving
and nowadays has been actively explored for its realization. The research
community and relevant stakeholders necessitate the development of Deep
Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles
(AVs) for smart mobility. There is a need to develop a model that accurately
perceives multiple objects on the road and predicts the driver's perception to
control the car's movements. This article proposes a novel utility-based
analytical model that enables perception systems of AVs to understand the
driving environment. The article consists of modules: acquiring a custom
dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a
DL-based model (YOLOv8s) for object detection; and a module to measure the
utility of perception service from the performance values of trained model
instances. The perception model is validated based on the object detection
task, and its process is benchmarked by state-of-the-art deep learning models'
performance metrics from the nuScense dataset. The experimental results show
three best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,
SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the
AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)
still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,
truck: 0.781, etc.) because it has better class-level performance values,
confirmed by the proposed perception model. We validate that the proposed
function is capable of finding the right perception for AVs. The results above
encourage using the proposed perception model to evaluate the utility of
learning models and determine the appropriate perception for AVs.

</details>


### [21] [SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2510.13262)
*Weiqi Guo,Guanjun Liu,Ziyuan Zhou*

Main category: cs.AI

TL;DR: 提出了SAJA框架，通过联合状态和动作攻击来增强多智能体深度强化学习的攻击效果，相比单独的状态或动作攻击更有效且更隐蔽。


<details>
  <summary>Details</summary>
Motivation: 现有研究只关注状态或动作的单独攻击，没有考虑如何有效联合两者。简单组合状态和动作扰动无法发挥它们的协同效应。

Method: SAJA框架包含两个阶段：状态攻击阶段使用多步梯度上升方法结合actor和critic网络计算对抗状态；动作攻击阶段基于扰动状态使用critic网络生成最终对抗动作，并添加启发式正则化器增强效果。

Result: 在Multi-Agent Particle Environment中的评估显示，SAJA优于单独的状态或动作攻击，更隐蔽，且现有防御方法无法防御其攻击。

Conclusion: SAJA框架通过有效联合状态和动作攻击，显著提升了多智能体深度强化学习模型的攻击效果，证明了联合攻击的重要性。

Abstract: Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for
cooperative and competitive tasks such as autonomous driving and strategic
gaming. However, models trained by MADRL are vulnerable to adversarial
perturbations on states and actions. Therefore, it is essential to investigate
the robustness of MADRL models from an attack perspective. Existing studies
focus on either state-only attacks or action-only attacks, but do not consider
how to effectively joint them. Simply combining state and action perturbations
such as randomly perturbing states and actions does not exploit their potential
synergistic effects. In this paper, we propose the State-Action Joint Attack
(SAJA) framework that has a good synergistic effects. SAJA consists of two
important phases: (1) In the state attack phase, a multi-step gradient ascent
method utilizes both the actor network and the critic network to compute an
adversarial state, and (2) in the action attack phase, based on the perturbed
state, a second gradient ascent uses the critic network to craft the final
adversarial action. Additionally, a heuristic regularizer measuring the
distance between the perturbed actions and the original clean ones is added
into the loss function to enhance the effectiveness of the critic's guidance.
We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating
that (1) it outperforms and is more stealthy than state-only or action-only
attacks, and (2) existing state or action defense methods cannot defend its
attacks.

</details>


### [22] [Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization](https://arxiv.org/abs/2510.13393)
*Yunxiao Zhao,Zhiqiang Wang,Xingtong Yu,Xiaoli Li,Jiye Liang,Ru Li*

Main category: cs.AI

TL;DR: 本文提出PORAT方法，从博弈论视角解决合理化中的模式崩溃问题，通过策略干预引导模型达到更优均衡状态。


<details>
  <summary>Details</summary>
Motivation: 传统合理化方法存在模式崩溃问题，即预测器能正确预测但生成器持续输出崩溃模式的理由，现有研究缺乏统一考虑。

Method: 提出PORAT方法，从博弈论角度分析合作合理化，通过逐步引入策略干预来解决合作博弈过程中的均衡问题。

Result: 在9个真实数据集和2个合成设置上验证，PORAT相比现有最优方法性能提升达8.1%。

Conclusion: PORAT能有效解决模式崩溃问题，引导合理化模型达到更优的博弈均衡状态。

Abstract: Rationalization, a data-centric framework, aims to build self-explanatory
models to explain the prediction outcome by generating a subset of
human-intelligible pieces of the input data. It involves a cooperative game
model where a generator generates the most human-intelligible parts of the
input (i.e., rationales), followed by a predictor that makes predictions based
on these generated rationales. Conventional rationalization methods typically
impose constraints via regularization terms to calibrate or penalize undesired
generation. However, these methods are suffering from a problem called mode
collapse, in which the predictor produces correct predictions yet the generator
consistently outputs rationales with collapsed patterns. Moreover, existing
studies are typically designed separately for specific collapsed patterns,
lacking a unified consideration. In this paper, we systematically revisit
cooperative rationalization from a novel game-theoretic perspective and
identify the fundamental cause of this problem: the generator no longer tends
to explore new strategies to uncover informative rationales, ultimately leading
the system to converge to a suboptimal game equilibrium (correct predictions
v.s collapsed rationales). To solve this problem, we then propose a novel
approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),
which progressively introduces policy interventions to address the game
equilibrium in the cooperative game process, thereby guiding the model toward a
more optimal solution state. We theoretically analyse the cause of such a
suboptimal equilibrium and prove the feasibility of the proposed method.
Furthermore, we validate our method on nine widely used real-world datasets and
two synthetic settings, where PORAT achieves up to 8.1% performance
improvements over existing state-of-the-art methods.

</details>


### [23] [Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse](https://arxiv.org/abs/2510.13417)
*Liesbeth Allein,Nataly Pineda-Castañeda,Andrea Rocci,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 该研究评估了大型语言模型在隐式因果链发现任务中的机制性因果推理能力，发现LLMs能生成逻辑连贯的因果链，但主要依赖关联模式匹配而非真正的因果推理。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何理解因果关系，以及它们能否识别连接因果对的中间因果步骤，特别是在气候变化等争议性话题的论证环境中。

Method: 使用诊断评估框架，让9个LLMs为给定的因果对生成所有可能的中间因果步骤，这些因果对来自气候变化论证研究资源。

Result: LLMs在生成的因果步骤数量和粒度上存在差异，虽然生成的因果链具有逻辑连贯性，但其判断主要基于关联模式匹配而非真正的因果推理。

Conclusion: 研究为推进论证环境中隐式机制性因果推理的未来工作奠定了坚实基础，包括基线方法、诊断见解和基准数据集。

Abstract: How does a cause lead to an effect, and which intermediate causal steps
explain their connection? This work scrutinizes the mechanistic causal
reasoning capabilities of large language models (LLMs) to answer these
questions through the task of implicit causal chain discovery. In a diagnostic
evaluation framework, we instruct nine LLMs to generate all possible
intermediate causal steps linking given cause-effect pairs in causal chain
structures. These pairs are drawn from recent resources in argumentation
studies featuring polarized discussion on climate change. Our analysis reveals
that LLMs vary in the number and granularity of causal steps they produce.
Although they are generally self-consistent and confident about the
intermediate causal connections in the generated chains, their judgments are
mainly driven by associative pattern matching rather than genuine causal
reasoning. Nonetheless, human evaluations confirmed the logical coherence and
integrity of the generated chains. Our baseline causal chain discovery
approach, insights from our diagnostic evaluation, and benchmark dataset with
causal chains lay a solid foundation for advancing future work in implicit,
mechanistic causal reasoning in argumentation settings.

</details>


### [24] [Confidence as a Reward: Transforming LLMs into Reward Models](https://arxiv.org/abs/2510.13501)
*He Du,Bowen Li,Chengxing Xie,Chang Gao,Kai Chen,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出了Confidence-as-a-Reward (CRew)方法，利用LLM对最终答案的token级置信度作为奖励信号，无需训练即可在数学推理任务中超越现有训练免费方法，甚至优于大多数训练过的奖励模型。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型需要大量标注数据和昂贵训练，而训练免费方法如LLM-as-a-Judge虽有效但未系统研究模型置信度作为奖励的潜力。

Method: 提出CRew方法，使用模型对最终答案的token级置信度作为奖励代理，特别适用于封闭式任务。进一步提出CRew-DPO训练策略，结合置信度和正确性信号构建偏好数据。

Result: 在MATH500和RewardMATH基准测试中，CRew优于现有训练免费奖励方法，甚至超过大多数训练过的奖励模型。置信度分数与实际推理性能强相关，并能有效筛选高质量训练数据。

Conclusion: CRew是一种简单而强大的训练免费奖励方法，CRew-DPO进一步提升了模型的判断能力，持续优于现有自训练方法。

Abstract: Reward models can significantly enhance the reasoning capabilities of large
language models (LLMs), but they typically require extensive curated data and
costly training. To mitigate these challenges, training-free approaches such as
LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate
responses, achieving promising results. Recent works have also indicated that
model confidence can serve effectively as a reward metric, distinguishing
between chain-of-thought (CoT) and non-CoT paths. However, the concept of using
confidence as a reward has not been comprehensively studied. In this work, we
systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful
training-free method that utilizes token-level confidence in the model's final
answers as a proxy for reward, especially suitable for close-ended tasks.
Through extensive experiments on mathematical reasoning tasks, we demonstrate
that CRew outperforms existing training-free reward approaches on the MATH500
and RewardMATH benchmarks, and even surpasses most trained reward models. We
further identify a strong correlation between CRew scores and the actual
reasoning performance of the model. Additionally, we find that CRew can
effectively filter high-quality training data. Building upon these insights, we
propose CRew-DPO, a training strategy that constructs preference data from
confidence scores combined with correctness signals. Finetuning with CRew-DPO
further enhances the model's judging capabilities and consistently outperforms
existing self-training methods.

</details>


### [25] [A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain](https://arxiv.org/abs/2510.13524)
*William Flanagan,Mukunda Das,Rajitha Ramanyake,Swaunja Maslekar,Meghana Manipuri,Joong Ho Choi,Shruti Nair,Shambhavi Bhusan,Sanjana Dulam,Mouni Pendharkar,Nidhi Singh,Vashisth Doshi,Sachi Shah Paresh*

Main category: cs.AI

TL;DR: 本文分析了生成式AI在金融服务行业应用中的性能评估挑战，提出了一个风险评估框架来改进专家评估和机器学习指标的应用。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在金融服务行业的应用面临性能评估困难，传统机器学习指标难以适用，专家评估也存在局限性，且现有基准测试无法很好地适应工业应用场景。

Method: 提出了一个风险评估框架，旨在更好地结合领域专家评估和机器学习指标，解决特定指标选择中的独特风险。

Result: 该框架有助于更有效地评估生成式AI在金融服务中的性能，克服传统评估方法的局限性。

Conclusion: 通过提出的风险评估框架，可以改进生成式AI在金融服务行业的性能评估，促进其更广泛的采用和应用。

Abstract: As Generative Artificial Intelligence is adopted across the financial
services industry, a significant barrier to adoption and usage is measuring
model performance. Historical machine learning metrics can oftentimes fail to
generalize to GenAI workloads and are often supplemented using Subject Matter
Expert (SME) Evaluation. Even in this combination, many projects fail to
account for various unique risks present in choosing specific metrics.
Additionally, many widespread benchmarks created by foundational research labs
and educational institutions fail to generalize to industrial use. This paper
explains these challenges and provides a Risk Assessment Framework to allow for
better application of SME and machine learning Metrics

</details>


### [26] [Tandem Training for Language Models](https://arxiv.org/abs/2510.13551)
*Robert West,Ashton Anderson,Ece Kamar,Eric Horvitz*

Main category: cs.AI

TL;DR: 提出串联训练方法，通过随机切换强弱模型来确保强模型的解决方案对弱模型可理解，同时保持任务准确性


<details>
  <summary>Details</summary>
Motivation: 随着语言模型快速发展，其推理过程可能超出弱模型和人类的理解范围，影响可解释性和监督。需要确保强模型的解决方案对弱合作者可理解

Method: 引入串联训练：在强化学习中，随机从冻结的弱模型而非正在训练的强模型中采样token。只有当强模型的推理过程可被弱模型继续时，才能成功完成rollout

Result: 在GSM8K数学推理任务中，串联训练可靠地教会模型放弃专业术语，适应弱合作者的语言，同时保持高任务准确率

Conclusion: 串联训练为构建可被弱模型审计的AI系统提供了有前景的途径，对人与AI协作和多智能体通信具有重要意义

Abstract: As language models continue to rapidly improve, we can expect their actions
and reasoning to become difficult or impossible for weaker agents and humans to
follow, undermining interpretability and oversight. With an eye on long-term
futures, we pursue methods that encourage models to produce solutions that
remain intelligible to weaker collaborators. We formalize intelligibility as
handoff robustness: a strong model's solution is intelligible to a weaker model
if randomly handing off control to the weaker model along the solution path
does not cause failure. Building on this criterion, we introduce tandem
training for language models, a reinforcement learning (RL) paradigm in which
rollout tokens are intermittently and randomly sampled from a frozen weak model
rather than the strong model being trained. Because rollouts succeed only when
the strong model's actions and reasoning process can be continued by the weak
model -- when the two can co-construct a successful solution -- optimizing
standard RL objectives with tandem training implicitly incentivizes both
correctness and intelligibility. In the GSM8K math reasoning task, tandem
training reliably teaches models to abandon jargon and adapt their language to
weaker partners while keeping task accuracy high. Our results demonstrate a
promising route to building AI systems that remain auditable by weaker agents,
with implications for human--AI collaboration and multi-agent communication.

</details>


### [27] [A Modal Logic for Temporal and Jurisdictional Classifier Models](https://arxiv.org/abs/2510.13691)
*Cecilia Di Florio,Huimin Dong,Antonino Rotolo*

Main category: cs.AI

TL;DR: 提出一种用于形式化法律案例推理的分类器模态逻辑，结合时间维度和法院层级来解决先例冲突


<details>
  <summary>Details</summary>
Motivation: 基于逻辑的模型可用于构建法律领域机器学习分类器的验证工具，ML分类器基于先前案例预测新案件结果，执行案例推理

Method: 引入分类器模态逻辑，在逻辑中纳入案件时间维度和法律系统内法院层级的原则来解决先例冲突

Result: 开发出能够形式化捕捉法律案例推理的逻辑框架

Conclusion: 该逻辑框架为验证法律领域机器学习分类器提供了形式化基础

Abstract: Logic-based models can be used to build verification tools for machine
learning classifiers employed in the legal field. ML classifiers predict the
outcomes of new cases based on previous ones, thereby performing a form of
case-based reasoning (CBR). In this paper, we introduce a modal logic of
classifiers designed to formally capture legal CBR. We incorporate principles
for resolving conflicts between precedents, by introducing into the logic the
temporal dimension of cases and the hierarchy of courts within the legal
system.

</details>


### [28] [Training LLM Agents to Empower Humans](https://arxiv.org/abs/2510.13709)
*Evan Ellis,Vivek Myers,Jens Tuyls,Sergey Levine,Anca Dragan,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 提出了一种基于最大化人类赋权（empowerment）的辅助语言模型调优方法Empower，该方法仅需离线文本数据，无需额外人工反馈即可训练更好的辅助AI助手。


<details>
  <summary>Details</summary>
Motivation: 现有辅助代理方法往往鼓励AI自行完成任务而非真正辅助人类达成目标，且需要昂贵的人工反馈。需要一种仅用离线数据就能训练真正辅助人类AI的方法。

Method: 基于最大化人类赋权（影响环境的能力）的目标，使用离线文本数据进行自监督微调语言模型，无需额外人工反馈或可验证奖励。

Result: 用户研究中78%的参与者偏好Empower助手（p=0.015），接受率提高31%，建议减少38%。在代码辅助环境中，模拟程序员成功率比SFT基线平均提高192%。

Conclusion: Empower提供了一个仅使用离线数据就能训练有用对齐AI代理的框架，无需额外人工反馈或可验证奖励。

Abstract: Assistive agents should not only take actions on behalf of a human, but also
step out of the way and cede control when there are important decisions to be
made. However, current methods for building assistive agents, whether via
mimicking expert humans or via RL finetuning on an inferred reward, often
encourage agents to complete tasks on their own rather than truly assisting the
human attain their objectives. Additionally, these methods often require costly
explicit human feedback to provide a training signal. We propose a new approach
to tuning assistive language models based on maximizing the human's
empowerment, their ability to effect desired changes in the environment. Our
empowerment-maximizing method, Empower, only requires offline text data,
providing a self-supervised method for fine-tuning language models to better
assist humans. To study the efficacy of our approach, we conducted an 18-person
user study comparing our empowerment assistant with a strong baseline.
Participants preferred our assistant 78% of the time (p=0.015), with a 31%
higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a
new environment for evaluating multi-turn code assistance using simulated
humans. Using this environment, we show that agents trained with Empower
increase the success rate of a simulated human programmer on challenging coding
questions by an average of 192% over an SFT baseline. With this empowerment
objective, we provide a framework for useful aligned AI agents at scale using
only offline data without the need for any additional human feedback or
verifiable rewards.

</details>


### [29] [From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails](https://arxiv.org/abs/2510.13727)
*Ravi Pandya,Madison Bland,Duy P. Nguyen,Changliu Liu,Jaime Fernández Fisac,Andrea Bajcsy*

Main category: cs.AI

TL;DR: 本文提出了一种基于控制理论的安全护栏方法，用于预防AI代理在交互过程中可能造成的下游危害，通过实时监控和主动修正风险输出来替代传统的标记-阻断式安全机制。


<details>
  <summary>Details</summary>
Motivation: 现有的AI安全护栏主要依赖基于标签数据集的输出分类，无法应对新的危险情况，且检测到不安全时通常只是拒绝行动，这本身可能不安全。需要一种能主动预防下游危害的动态安全方法。

Method: 将AI代理安全建模为序列决策问题，借鉴安全关键控制理论，在AI模型的潜在表示空间中构建预测性护栏，实时监控输出并主动修正风险行为，采用安全关键强化学习进行大规模训练。

Result: 在模拟驾驶和电子商务场景中的实验表明，控制理论护栏能可靠地引导LLM代理避免灾难性后果（如碰撞、破产），同时保持任务性能。

Conclusion: 控制理论护栏为当前标记-阻断式护栏提供了原则性的动态替代方案，能够主动预防AI代理在交互过程中可能造成的下游危害。

Abstract: Generative AI systems are increasingly assisting and acting on behalf of end
users in practical settings, from digital shopping assistants to
next-generation autonomous cars. In this context, safety is no longer about
blocking harmful content, but about preempting downstream hazards like
financial or physical harm. Yet, most AI guardrails continue to rely on output
classification based on labeled datasets and human-specified criteria,making
them brittle to new hazardous situations. Even when unsafe conditions are
flagged, this detection offers no path to recovery: typically, the AI system
simply refuses to act--which is not always a safe choice. In this work, we
argue that agentic AI safety is fundamentally a sequential decision problem:
harmful outcomes arise from the AI system's continually evolving interactions
and their downstream consequences on the world. We formalize this through the
lens of safety-critical control theory, but within the AI model's latent
representation of the world. This enables us to build predictive guardrails
that (i) monitor an AI system's outputs (actions) in real time and (ii)
proactively correct risky outputs to safe ones, all in a model-agnostic manner
so the same guardrail can be wrapped around any AI model. We also offer a
practical training recipe for computing such guardrails at scale via
safety-critical reinforcement learning. Our experiments in simulated driving
and e-commerce settings demonstrate that control-theoretic guardrails can
reliably steer LLM agents clear of catastrophic outcomes (from collisions to
bankruptcy) while preserving task performance, offering a principled dynamic
alternative to today's flag-and-block guardrails.

</details>


### [30] [Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math](https://arxiv.org/abs/2510.13744)
*Shrey Pandit,Austin Xu,Xuan-Phi Nguyen,Yifei Ming,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 提出了Hard2Verify基准，用于评估数学推理中步骤级验证器的性能，发现开源验证器普遍落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 在需要步骤级验证的开放数学推理任务中，需要强大的验证器来捕捉步骤级错误，但目前缺乏合适的评估基准。

Method: 构建了Hard2Verify基准，包含500多小时人工标注的步骤级验证数据，评估了29个生成式批评器和过程奖励模型。

Result: 除了少数表现优异者外，开源验证器在步骤级验证任务上普遍落后于闭源模型。

Conclusion: 步骤级验证是数学推理中的关键挑战，需要进一步研究验证器计算规模、自验证和验证-生成动态等基本问题。

Abstract: Large language model (LLM)-based reasoning systems have recently achieved
gold medal-level performance in the IMO 2025 competition, writing mathematical
proofs where, to receive full credit, each step must be not only correct but
also sufficiently supported. To train LLM-based reasoners in such challenging,
open-ended settings, strong verifiers capable of catching step-level mistakes
are necessary prerequisites. We introduce Hard2Verify, a human-annotated,
step-level verification benchmark produced with over 500 hours of human labor.
Hard2Verify is designed to rigorously assess step-level verifiers at the
frontier: Verifiers must provide step-level annotations or identify the first
error in responses generated by frontier LLMs for very recent, challenging, and
open-ended math questions. We evaluate 29 generative critics and process reward
models, demonstrating that, beyond a few standouts, open-source verifiers lag
closed source models. We subsequently analyze what drives poor performance in
step-level verification, the impacts of scaling verifier compute, as well as
fundamental questions such as self-verification and verification-generation
dynamics.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [31] [On the performance of Active STAR-RIS-Assisted Cell-Free Massive MIMO Systems with Phase Errors and Channel Aging](https://arxiv.org/abs/2510.13171)
*Jun Qian,Ross Murch,Khaled B. Letaief*

Main category: cs.IT

TL;DR: 分析主动可重构智能表面在细胞自由大规模MIMO系统中的性能，研究相位误差和信道老化对系统的影响，并提出资源块长度设计指南。


<details>
  <summary>Details</summary>
Motivation: 主动STAR-RIS使用放大来克服级联链路衰减，但面临相位误差和信道老化问题，需要分析这些因素对系统性能的影响。

Method: 利用空间相关瑞利衰落模型，推导基于最小均方误差估计的信道估计，并制定下行链路频谱效率的闭式表达式。

Result: 主动STAR-RIS能有效补偿相位误差和信道老化的不利影响，增加AP和STAR-RIS元素数量以及更大的放大因子可以缓解性能下降。

Conclusion: 提出了资源块长度设计指南，主动STAR-RIS在细胞自由大规模MIMO系统中能有效应对相位误差和信道老化挑战。

Abstract: Active reconfigurable intelligent surfaces (RISs) employ amplification to
overcome attenuation caused by the RIS cascaded link. In this paper, we analyze
the effects of phase errors and channel aging in active simultaneously
transmitting and reflecting (STAR) RIS-assisted cell-free massive
multiple-input multiple-output (MIMO) systems. By leveraging a spatially
correlated Rayleigh fading model, this paper derives minimum mean square error
estimate-based channel estimates and formulates closed-form expressions for
downlink spectral efficiency. This analytical framework enables a comprehensive
evaluation of the effects of channel aging and uniformly distributed phase
errors on system performance. The results demonstrate that active STAR-RISs can
effectively compensate for the adverse effects of phase errors and channel
aging. To counteract the impact of channel aging, we propose practical
guidelines for resource-block-length design. Also, an increase in APs and
STAR-RIS elements, along with a larger amplification factor, can alleviate
performance degradation.

</details>


### [32] [A Dimension-Keeping Semi-Tensor Product Framework for Compressed Sensing](https://arxiv.org/abs/2510.13180)
*Qi Qi,Abdelhamid Tayebi,Daizhan Cheng,Jun-e Feng*

Main category: cs.IT

TL;DR: 提出了一种新的维度保持半张量积压缩感知方法(DK-STP-CS)，通过利用组内相关性同时保持组间不相干性来增强测量矩阵设计，在图像压缩重建任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知框架依赖测量矩阵列的不相干性来保证重建性能，但未能充分利用信号的结构特性。本文旨在通过结合组内相关性和组间不相干性来改进测量矩阵设计。

Method: 将DK-STP算法集成到感知矩阵设计中，实现降维同时保持信号恢复能力，利用组内相关性增强性能。

Result: 实验结果表明DK-STP-CS在图像压缩重建任务中显著优于传统CS和STP-CS方法，具有更高的PSNR值，在噪声条件和不同采样率下表现出鲁棒性。

Conclusion: DK-STP-CS方法在资源受限环境中具有实际应用潜力，能够有效抑制噪声并提高视觉保真度。

Abstract: In compressed sensing (CS), sparse signals can be reconstructed from
significantly fewer samples than required by the Nyquist-Shannon sampling
theorem. While non-sparse signals can be sparsely represented in appropriate
transformation domains, conventional CS frameworks rely on the incoherence of
the measurement matrix columns to guarantee reconstruction performance. This
paper proposes a novel method termed Dimension-Keeping Semi-Tensor Product
Compressed Sensing (DK-STP-CS), which leverages intra-group correlations while
maintaining inter-group incoherence to enhance the measurement matrix design.
Specifically, the DK-STP algorithm is integrated into the design of the sensing
matrix, enabling dimensionality reduction while preserving signal recovery
capability. For image compression and reconstruction tasks, the proposed method
achieves notable noise suppression and improves visual fidelity. Experimental
results demonstrate that DK-STP-CS significantly outperforms traditional CS and
STP-CS approaches, as evidenced by higher Peak Signal-to-Noise Ratio (PSNR)
values between the reconstructed and original images. The robustness of
DK-STP-CS is further validated under noisy conditions and varying sampling
rates, highlighting its potential for practical applications in
resource-constrained environments.

</details>


### [33] [Movable and Reconfigurable Antennas for 6G: Unlocking Electromagnetic-Domain Design and Optimization](https://arxiv.org/abs/2510.13209)
*Lipeng Zhu,Haobin Mao,Ge Yan,Wenyan Ma,Zhenyu Xiao,Rui Zhang*

Main category: cs.IT

TL;DR: 本文综述了可移动天线和可重构天线在6G移动通信网络中的应用，包括其硬件架构、设计方法以及性能优势。


<details>
  <summary>Details</summary>
Motivation: 6G移动通信网络的日益增长需求需要先进的天线技术，可移动天线和可重构天线能够动态控制天线位置、方向、辐射、极化和频率响应，为无线系统设计提供丰富的电磁域自由度。

Method: 通过概述应用场景、硬件架构和设计方法，结合现场测试和仿真结果来评估性能。

Result: 现场测试和仿真结果表明，可移动天线和可重构天线在性能上优于传统的固定/不可重构天线。

Conclusion: 可移动天线和可重构天线为6G网络提供了重要的技术支撑，能够显著提升无线系统的性能。

Abstract: The growing demands of 6G mobile communication networks necessitate advanced
antenna technologies. Movable antennas (MAs) and reconfigurable antennas (RAs)
enable dynamic control over antenna's position, orientation, radiation,
polarization, and frequency response, introducing rich electromagnetic-domain
degrees of freedom for the design and performance enhancement of wireless
systems. This article overviews their application scenarios, hardware
architectures, and design methods. Field test and simulation results highlight
their performance benefits over conventional fixed/non-reconfigurable antennas.

</details>


### [34] [Non-Linear Precoding via Dirty Paper Coding for Near-Field Downlink MISO Communications](https://arxiv.org/abs/2510.13485)
*Akash Kulkarni,Rajshekhar V Bhat*

Main category: cs.IT

TL;DR: 提出基于脏纸编码的非线性预编码框架，用于6G近场通信系统，通过预消除已知干扰来最大化和速率性能。


<details>
  <summary>Details</summary>
Motivation: 现有近场通信系统主要采用线性预编码技术如迫零，需要高发射功率来抑制干扰，导致性能下降。

Method: 基于脏纸编码的非线性预编码框架，制定并解决相应的和速率最大化问题，推导出DPC和ZF方案的最优功率分配策略。

Result: 广泛仿真表明，DPC在各种近场配置下相比ZF实现了显著的和速率增益，在用户间距较小时改进最为明显。

Conclusion: 脏纸编码在6G近场通信系统中能够有效提升性能，特别是在用户密集部署场景下优势更加突出。

Abstract: In 6G systems, extremely large-scale antenna arrays operating at terahertz
frequencies extend the near-field region to typical user distances from the
base station, enabling near-field communication (NFC) with fine spatial
resolution through beamfocusing. Existing multiuser NFC systems predominantly
employ linear precoding techniques such as zero-forcing (ZF), which suffer from
performance degradation due to the high transmit power required to suppress
interference. This paper proposes a nonlinear precoding framework based on
Dirty Paper Coding (DPC), which pre-cancels known interference to maximize the
sum-rate performance. We formulate and solve the corresponding sum-rate
maximization problems, deriving optimal power allocation strategies for both
DPC and ZF schemes. Extensive simulations demonstrate that DPC achieves
substantial sum-rate gains over ZF across various near-field configurations,
with the most pronounced improvements observed for closely spaced users.

</details>


### [35] [Simulating Mediumband Wireless Communication Systems: A Concise Description](https://arxiv.org/abs/2510.13532)
*Dushyantha A Basnayaka*

Main category: cs.IT

TL;DR: 本文描述了在MATLAB中准确模拟中频无线通信系统的必要步骤，特别关注物理层操作的详细模拟，包括脉冲整形、上变频、混频、载波同步和符号定时同步等关键子系统。


<details>
  <summary>Details</summary>
Motivation: 现有文献通常忽略中频通信中的关键物理层操作，这些简化假设在大多数情况下足够，但要准确捕捉中频通信的本质，需要对这些PHY操作进行详细模拟。

Method: 使用MATLAB从单个发射器到单个接收器详细模拟中频无线通信场景，详细阐述关键PHY子系统的操作，包括脉冲整形、上变频、混频、载波同步和符号定时同步。

Result: 所描述的模拟方法能够准确捕捉中频无线通信的微妙动态，包括深度衰落避免效应。

Conclusion: 通过详细模拟物理层操作，可以更准确地再现中频无线通信系统的行为，这对于理解和优化中频通信性能至关重要。

Abstract: In this paper, we describe the necessary procedures for accurately simulating
digital wireless communication systems operating in the mediumband, aimed at
both beginners and experts. In the research literature, digital wireless
communication systems are typically simulated in the discrete-time complex
baseband domain, where pulse shaping, upconversion, mixing, carrier
synchronization, and symbol timing synchronization are often ignored. These
assumptions are indeed sufficient in most cases, but to capture the essence of
communication in the mediumband, certain physical layer (PHY) operations should
be simulated in detail. In this paper, we concisely describe how to simulate a
mediumband wireless communication scenario from a single transmitter (TX) to a
single receiver (RX) in MATLAB, elaborating the operation of key PHY
subsystems. The approach described here ensures that the simulated system
captures the delicate dynamics of mediumband wireless communication, including
the effect of deep fading avoidance.

</details>


### [36] [Local Information-Theoretic Security via Euclidean Geometry](https://arxiv.org/abs/2510.13661)
*Emmanouil M. Athanasakos,Nicholas Kalouptsidis,Hariprasad Manjunath*

Main category: cs.IT

TL;DR: 提出基于欧几里得信息论的方法来研究离散无记忆窃听信道的安全通信局部特性，通过局部几何近似将非凸优化问题转化为可处理的二次规划，并定义了新的秘密局部收缩系数来衡量信道的内在局部泄漏效率。


<details>
  <summary>Details</summary>
Motivation: 研究离散无记忆窃听信道安全通信的局部特性，旨在在保证合法用户信息率的同时，限制信息泄露给窃听者和编码秘密消息的信息成本。

Method: 采用欧几里得信息论方法，将非凸优化问题通过局部几何近似转化为二次规划结构，利用KKT条件和信道矩阵的广义特征值来求解最优拉格朗日乘子，并定义秘密局部收缩系数作为矩阵铅笔的最大广义特征值。

Result: 推导出近似局部保密容量的解析公式，建立了局部系数与全局对应物之间的界限联系，并通过多模式信道和二进制对称窃听信道的数值分析验证了框架的有效性。

Conclusion: 所提出的框架能够有效分析窃听信道的局部安全特性，为安全通信系统的设计和分析提供了新的理论工具和见解。

Abstract: This paper introduces a methodology based on Euclidean information theory to
investigate local properties of secure communication over discrete memoryless
wiretap channels. We formulate a constrained optimization problem that
maximizes a legitimate user's information rate while imposing explicit upper
bounds on both the information leakage to an eavesdropper and the informational
cost of encoding the secret message. By leveraging local geometric
approximations, this inherently non-convex problem is transformed into a
tractable quadratic programming structure. It is demonstrated that the optimal
Lagrange multipliers governing this approximated problem can be found by
solving a linear program. The constraints of this linear program are derived
from Karush-Kuhn-Tucker conditions and are expressed in terms of the
generalized eigenvalues of channel-derived matrices. This framework facilitates
the derivation of an analytical formula for an approximate local secrecy
capacity. Furthermore, we define and analyze a new class of secret local
contraction coefficients. These coefficients, characterized as the largest
generalized eigenvalues of a matrix pencil, quantify the maximum achievable
ratio of approximate utility to approximate leakage, thus measuring the
intrinsic local leakage efficiency of the channel. We establish bounds
connecting these local coefficients to their global counterparts defined over
true mutual information measures. The efficacy of the proposed framework is
demonstrated through detailed analysis and numerical illustrations for both
general multi-mode channels and the canonical binary symmetric wiretap channel.

</details>


### [37] [Combinatorial Bounds for List Recovery via Discrete Brascamp--Lieb Inequalities](https://arxiv.org/abs/2510.13775)
*Joshua Brakensiek,Yeyuan Chen,Manik Dhar,Zihan Zhang*

Main category: cs.IT

TL;DR: 本文研究了编码理论中的列表恢复问题，给出了随机线性码、随机Reed-Solomon码、显式折叠Reed-Solomon码和显式单变量重数码的列表大小上界。主要结果表明当ρ接近容量时，列表大小L最多为(ℓ/(R+ε))^{O(R/ε)}，解决了L是否可以用ℓ的多项式界定的长期开放问题。


<details>
  <summary>Details</summary>
Motivation: 列表恢复问题是编码理论中的核心问题，旨在找到码字中至少1-ρ比例的符号落在预定集合中的码字。关键问题是确定给定码的最大列表大小L的上界，特别是L是否可以用ℓ的多项式界定。

Method: 主要技术是离散熵Brascamp-Lieb不等式在列表恢复问题中的新应用，通过该不等式将每个坐标的局部结构与恢复列表的全局结构联系起来。

Result: 对于速率为R的码，当ρ=1-R-ε接近容量时，列表大小L最多为(ℓ/(R+ε))^{O(R/ε)}。在零错误机制下，该上界与已知下界完全匹配。

Conclusion: 本文证明了列表大小L可以用ℓ的多项式界定，解决了长期开放问题。同时将Chen和Zhang关于折叠Reed-Solomon码列表可解码性的结果推广为新的Brascamp-Lieb型不等式。

Abstract: In coding theory, the problem of list recovery asks one to find all codewords
$c$ of a given code $C$ which such that at least $1-\rho$ fraction of the
symbols of $c$ lie in some predetermined set of $\ell$ symbols for each
coordinate of the code. A key question is bounding the maximum possible list
size $L$ of such codewords for the given code $C$.
  In this paper, we give novel combinatorial bounds on the list recoverability
of various families of linear and folded linear codes, including random linear
codes, random Reed--Solomon codes, explicit folded Reed--Solomon codes, and
explicit univariate multiplicity codes. Our main result is that in all of these
settings, we show that for code of rate $R$, when $\rho = 1 - R - \epsilon$
approaches capacity, the list size $L$ is at most
$(\ell/(R+\epsilon))^{O(R/\epsilon)}$. These results also apply in the
average-radius regime. Our result resolves a long-standing open question on
whether $L$ can be bounded by a polynomial in $\ell$. In the zero-error regime,
our bound on $L$ perfectly matches known lower bounds.
  The primary technique is a novel application of a discrete entropic
Brascamp--Lieb inequality to the problem of list recovery, allowing us to
relate the local structure of each coordinate with the global structure of the
recovered list. As a result of independent interest, we show that a recent
result by Chen and Zhang (STOC 2025) on the list decodability of folded
Reed--Solomon codes can be generalized into a novel Brascamp--Lieb type
inequality.

</details>


### [38] [From Random to Explicit via Subspace Designs With Applications to Local Properties and Matroids](https://arxiv.org/abs/2510.13777)
*Joshua Brakensiek,Yeyuan Chen,Manik Dhar,Zihan Zhang*

Main category: cs.IT

TL;DR: 本文扩展了Levi等人的统一框架，用于研究子空间可设计码的局部性质，包括显式折叠Reed-Solomon码和单变量重数码。主要结果包括：随机线性码与最优子空间设计码的局部等价性，以及在拟阵理论中的应用。


<details>
  <summary>Details</summary>
Motivation: 扩展Levi等人的统一框架，研究子空间可设计码的局部性质，为编码理论和拟阵理论提供新的联系和应用。

Method: 扩展统一框架，分析子空间可设计码的局部性质，建立随机线性码与子空间设计码的局部等价性，并应用于拟阵理论中的可纠正擦除模式识别问题。

Result: 证明了随机线性码与最优子空间设计码的局部等价性；给出了第一个同时具有随机线性码所有局部性质的显式折叠线性码构造；在拟阵理论中改进了Jackson和Tanigawa的结果。

Conclusion: 子空间可设计码与随机线性码在局部性质上具有等价性，这一结果为编码理论和拟阵理论提供了新的联系，并改进了现有结果。

Abstract: In coding theory, a common question is to understand the threshold rates of
various local properties of codes, such as their list decodability and list
recoverability. A recent work Levi, Mosheiff, and Shagrithaya (FOCS 2025) gave
a novel unified framework for calculating the threshold rates of local
properties for random linear and random Reed--Solomon codes.
  In this paper, we extend their framework to studying the local properties of
subspace designable codes, including explicit folded Reed-Solomon and
univariate multiplicity codes. Our first main result is a local equivalence
between random linear codes and (nearly) optimal subspace design codes up to an
arbitrarily small rate decrease. We show any local property of random linear
codes applies to all subspace design codes. As such, we give the first explicit
construction of folded linear codes that simultaneously attain all local
properties of random linear codes. Conversely, we show that any local property
which applies to all subspace design codes also applies to random linear codes.
  Our second main result is an application to matroid theory. We show that the
correctable erasure patterns in a maximally recoverable tensor code can be
identified in deterministic polynomial time, assuming a positive answer to a
matroid-theoretic question due to Mason (1981). This improves on a result of
Jackson and Tanigawa (JCTB 2024) who gave a complexity characterization of
$\mathsf{RP} \cap \mathsf{coNP}$ assuming a stronger conjecture. Our result
also applies to the generic bipartite rigidity and matrix completion matroids.
  As a result of additional interest, we study the existence and limitations of
subspace designs. In particular, we tighten the analysis of family of subspace
designs constructioned by Guruswami and Kopparty (Combinatorica 2016) and show
that better subspace designs do not exist over algebraically closed fields.

</details>
