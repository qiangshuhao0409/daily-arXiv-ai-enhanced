{"id": "2602.06626", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.06626", "abs": "https://arxiv.org/abs/2602.06626", "authors": ["Hadiseh Rezaei", "Rahim Taheri", "Mohammad Shojafar"], "title": "IE-RAP: An Intelligence and Efficient Reader Anti-Collision Protocol for Dense RFID Networks", "comment": null, "summary": "An advanced technology known as a radio frequency identification (RFID) system enables seamless wireless communication between tags and readers. This system operates in what is referred to as a dense reader environment, where readers are placed close to each other to optimize coverage. However, this setup comes with its challenges, as it increases the likelihood of collisions between readers and tags (reader-to-reader and reader-to-tag), leading to reduced network performance. To address this issue, various protocols have been proposed, with centralized solutions emerging as promising options due to their ability to deliver higher throughput. In this paper, we propose the Intelligence and Efficient Reader Anti-collision Protocol (IE-RAP) that improves network performance such as throughput, average waiting time, and energy consumption, which employs a powerful combination of Time Division Multiple Access (TDMA) and Frequency Division Multiple Access (FDMA) mechanisms. IE-RAP improves the efficiency of RFID networks through techniques such as the SIFT function and distance calculation between readers. By preventing re-read tags and ensuring the on-time release of the communication channel, we effectively eliminate unnecessary collisions. Our simulations emphasize the superiority of our proposed method, it increases 26% throughput, reduces 74% the average waiting time, and lower by 52% the energy consumption compared to existing approaches. Importantly, our solution supports the seamless integration of mobile readers within the network.", "AI": {"tldr": "\u63d0\u51faIE-RAP\u534f\u8bae\uff0c\u7ed3\u5408TDMA\u548cFDMA\u673a\u5236\uff0c\u901a\u8fc7SIFT\u51fd\u6570\u548c\u8ddd\u79bb\u8ba1\u7b97\u4f18\u5316RFID\u5bc6\u96c6\u9605\u8bfb\u5668\u73af\u5883\u6027\u80fd\uff0c\u63d0\u5347\u541e\u5410\u91cf26%\uff0c\u964d\u4f4e\u7b49\u5f85\u65f6\u95f474%\uff0c\u51cf\u5c11\u80fd\u801752%", "motivation": "RFID\u7cfb\u7edf\u5728\u5bc6\u96c6\u9605\u8bfb\u5668\u73af\u5883\u4e2d\u5b58\u5728\u9605\u8bfb\u5668\u95f4\u548c\u9605\u8bfb\u5668\u4e0e\u6807\u7b7e\u95f4\u7684\u78b0\u649e\u95ee\u9898\uff0c\u5bfc\u81f4\u7f51\u7edc\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u6709\u6548\u7684\u9632\u78b0\u649e\u534f\u8bae\u6765\u63d0\u5347\u7cfb\u7edf\u6548\u7387", "method": "\u63d0\u51fa\u667a\u80fd\u9ad8\u6548\u9605\u8bfb\u5668\u9632\u78b0\u649e\u534f\u8bae(IE-RAP)\uff0c\u7ed3\u5408TDMA\u548cFDMA\u673a\u5236\uff0c\u91c7\u7528SIFT\u51fd\u6570\u548c\u9605\u8bfb\u5668\u95f4\u8ddd\u79bb\u8ba1\u7b97\u6280\u672f\uff0c\u9632\u6b62\u6807\u7b7e\u91cd\u590d\u8bfb\u53d6\u5e76\u786e\u4fdd\u901a\u4fe1\u4fe1\u9053\u53ca\u65f6\u91ca\u653e", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u541e\u5410\u91cf\u63d0\u534726%\uff0c\u5e73\u5747\u7b49\u5f85\u65f6\u95f4\u964d\u4f4e74%\uff0c\u80fd\u8017\u51cf\u5c1152%\uff0c\u5e76\u652f\u6301\u79fb\u52a8\u9605\u8bfb\u5668\u7684\u65e0\u7f1d\u96c6\u6210", "conclusion": "IE-RAP\u534f\u8bae\u80fd\u6709\u6548\u89e3\u51b3RFID\u5bc6\u96c6\u73af\u5883\u4e2d\u7684\u78b0\u649e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u6307\u6807\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u96c6\u4e2d\u5f0f\u9632\u78b0\u649e\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.06636", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.06636", "abs": "https://arxiv.org/abs/2602.06636", "authors": ["Samara Mayhoub", "Chuan Heng Foh", "Mahdi Boloursaz Mashhadi", "Mohammad Shojafar", "Rahim Tafazolli"], "title": "Talk Like a Packet: Rethinking Network Traffic Analysis with Transformer Foundation Models", "comment": "Accepted for publication in IEEE Communications Magazine", "summary": "Inspired by the success of Transformer-based models in natural language processing, this paper investigates their potential as foundation models for network traffic analysis. We propose a unified pre-training and fine-tuning pipeline for traffic foundation models. Through fine-tuning, we demonstrate the generalizability of the traffic foundation models in various downstream tasks, including traffic classification, traffic characteristic prediction, and traffic generation. We also compare against non-foundation baselines, demonstrating that the foundation-model backbones achieve improved performance. Moreover, we categorize existing models based on their architecture, input modality, and pre-training strategy. Our findings show that these models can effectively learn traffic representations and perform well with limited labeled datasets, highlighting their potential in future intelligent network analysis systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u5c06Transformer\u67b6\u6784\u4f5c\u4e3a\u7f51\u7edc\u6d41\u91cf\u5206\u6790\u7684\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u9884\u8bad\u7ec3-\u5fae\u8c03\u6d41\u7a0b\uff0c\u5e76\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u53d7Transformer\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u6210\u529f\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5176\u5728\u7f51\u7edc\u6d41\u91cf\u5206\u6790\u4e2d\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6d41\u7a0b\uff0c\u6784\u5efa\u6d41\u91cf\u57fa\u7840\u6a21\u578b\uff1b\u5bf9\u73b0\u6709\u6a21\u578b\u6309\u67b6\u6784\u3001\u8f93\u5165\u6a21\u6001\u548c\u9884\u8bad\u7ec3\u7b56\u7565\u8fdb\u884c\u5206\u7c7b\uff1b\u901a\u8fc7\u5fae\u8c03\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff08\u6d41\u91cf\u5206\u7c7b\u3001\u7279\u5f81\u9884\u6d4b\u3001\u751f\u6210\uff09\u4e2d\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6d41\u91cf\u57fa\u7840\u6a21\u578b\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u975e\u57fa\u7840\u6a21\u578b\u57fa\u7ebf\u6709\u6027\u80fd\u63d0\u5347\uff1b\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b66\u4e60\u6d41\u91cf\u8868\u793a\uff0c\u5e76\u5728\u6709\u9650\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "conclusion": "Transformer\u67b6\u6784\u7684\u7f51\u7edc\u6d41\u91cf\u57fa\u7840\u6a21\u578b\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u4e3a\u672a\u6765\u667a\u80fd\u7f51\u7edc\u5206\u6790\u7cfb\u7edf\u63d0\u4f9b\u6709\u6548\u652f\u6301\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2602.06693", "categories": ["cs.NI", "cs.CC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06693", "abs": "https://arxiv.org/abs/2602.06693", "authors": ["Robert Ganian", "Fionn Mc Inerney", "Dimitra Tsigkari"], "title": "Makespan Minimization in Split Learning: From Theory to Practice", "comment": "This paper will appear at IEEE INFOCOM 2026", "summary": "Split learning recently emerged as a solution for distributed machine learning with heterogeneous IoT devices, where clients can offload part of their training to computationally-powerful helpers. The core challenge in split learning is to minimize the training time by jointly devising the client-helper assignment and the schedule of tasks at the helpers. We first study the model where each helper has a memory cardinality constraint on how many clients it may be assigned, which represents the case of homogeneous tasks. Through complexity theory, we rule out exact polynomial-time algorithms and approximation schemes even for highly restricted instances of this problem. We complement these negative results with a non-trivial polynomial-time 5-approximation algorithm. Building on this, we then focus on the more general heterogeneous task setting considered by Tirana et al. [INFOCOM 2024], where helpers have memory capacity constraints and clients have variable memory costs. In this case, we prove that, unless P=NP, the problem cannot admit a polynomial-time approximation algorithm for any approximation factor. However, by adapting our aforementioned 5-approximation algorithm, we develop a novel heuristic for the heterogeneous task setting and show that it outperforms heuristics from prior works through extensive experiments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u5272\u5b66\u4e60\u95ee\u9898\uff0c\u9488\u5bf9\u5f02\u6784IoT\u8bbe\u5907\u573a\u666f\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef-\u52a9\u624b\u5206\u914d\u548c\u4efb\u52a1\u8c03\u5ea6\u4f18\u5316\u8bad\u7ec3\u65f6\u95f4\u3002\u8bba\u6587\u9996\u5148\u7814\u7a76\u540c\u6784\u4efb\u52a1\u6a21\u578b\uff0c\u63d0\u51fa5-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7136\u540e\u6269\u5c55\u5230\u5f02\u6784\u4efb\u52a1\u6a21\u578b\uff0c\u8bc1\u660e\u4e0d\u5b58\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u4f46\u63d0\u51fa\u65b0\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5206\u5272\u5b66\u4e60\u4f5c\u4e3a\u5f02\u6784IoT\u8bbe\u5907\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u5c06\u90e8\u5206\u8bad\u7ec3\u4efb\u52a1\u5378\u8f7d\u5230\u8ba1\u7b97\u80fd\u529b\u66f4\u5f3a\u7684\u52a9\u624b\u8bbe\u5907\u3002\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5ba2\u6237\u7aef-\u52a9\u624b\u5206\u914d\u548c\u52a9\u624b\u4efb\u52a1\u8c03\u5ea6\u6765\u6700\u5c0f\u5316\u8bad\u7ec3\u65f6\u95f4\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8003\u8651\u540c\u6784\u4efb\u52a1\u573a\u666f\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4efb\u52a1\u901a\u5e38\u662f\u5f02\u6784\u7684\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u7814\u7a76\u540c\u6784\u4efb\u52a1\u6a21\u578b\uff08\u6bcf\u4e2a\u52a9\u624b\u6709\u5185\u5b58\u57fa\u6570\u7ea6\u675f\uff09\uff0c\u901a\u8fc7\u590d\u6742\u6027\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e0d\u5b58\u5728\u7cbe\u786e\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u548c\u8fd1\u4f3c\u65b9\u6848\uff0c\u4f46\u63d0\u51fa\u4e86\u975e\u5e73\u51e1\u7684\u591a\u9879\u5f0f\u65f6\u95f45-\u8fd1\u4f3c\u7b97\u6cd5\u3002\u7136\u540e\u5c06\u7814\u7a76\u6269\u5c55\u5230\u5f02\u6784\u4efb\u52a1\u6a21\u578b\uff08\u52a9\u624b\u6709\u5185\u5b58\u5bb9\u91cf\u7ea6\u675f\uff0c\u5ba2\u6237\u7aef\u6709\u53ef\u53d8\u5185\u5b58\u6210\u672c\uff09\uff0c\u8bc1\u660e\u4e0d\u5b58\u5728\u4efb\u4f55\u8fd1\u4f3c\u56e0\u5b50\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u4f46\u901a\u8fc7\u8c03\u65745-\u8fd1\u4f3c\u7b97\u6cd5\u5f00\u53d1\u4e86\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u7ed3\u679c\uff1a1) \u540c\u6784\u4efb\u52a1\u6a21\u578b\u4e0b\uff0c\u6392\u9664\u4e86\u7cbe\u786e\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u548c\u8fd1\u4f3c\u65b9\u6848\uff0c\u4f46\u63d0\u51fa\u4e865-\u8fd1\u4f3c\u7b97\u6cd5\uff1b2) \u5f02\u6784\u4efb\u52a1\u6a21\u578b\u4e0b\uff0c\u8bc1\u660e\u9664\u975eP=NP\uff0c\u5426\u5219\u4e0d\u5b58\u5728\u4efb\u4f55\u8fd1\u4f3c\u56e0\u5b50\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u7b97\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u5f02\u6784\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u5206\u5272\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u7aef-\u52a9\u624b\u5206\u914d\u548c\u4efb\u52a1\u8c03\u5ea6\u95ee\u9898\u3002\u5bf9\u4e8e\u540c\u6784\u4efb\u52a1\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u754c\u9650\u548c\u5b9e\u7528\u7b97\u6cd5\uff1b\u5bf9\u4e8e\u66f4\u73b0\u5b9e\u7684\u5f02\u6784\u4efb\u52a1\u6a21\u578b\uff0c\u867d\u7136\u7406\u8bba\u4e0a\u5b58\u5728\u8ba1\u7b97\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u542f\u53d1\u5f0f\u65b9\u6cd5\u4ecd\u80fd\u83b7\u5f97\u826f\u597d\u6027\u80fd\u3002\u7814\u7a76\u4e3a\u5b9e\u9645\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.06061", "categories": ["cs.IT", "cs.MM", "cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.06061", "abs": "https://arxiv.org/abs/2602.06061", "authors": ["Faisal Al-Kamali", "Francois Chan", "Hussein A. Ammar", "James H. Bayes", "Claude D'Amours"], "title": "UAV-Mounted Aerial Relays in Military Communications: A Comprehensive Survey", "comment": "To appear in IEEE Open Journal of the Communications Society", "summary": "Relays are pivotal in military communication networks, expanding coverage and ensuring reliable connectivity in challenging operational environments. While traditional terrestrial relays (TR) are constrained by fixed locations and vulnerability to physical obstructions, unmanned aerial vehicle (UAV)-mounted aerial relays (AR) offer a dynamic and flexible alternative by operating above obstacles and adapting to changing battlefield conditions. This paper provides a comprehensive survey of AR systems in military communications, presenting a detailed comparison between AR and TR paradigms and examining two specific AR technologies: active aerial relays (AAR) and aerial reconfigurable intelligent surface (ARIS) relays. The survey delves into their operation, benefits, challenges, and military applications, supported by a qualitative analysis across metrics such as coverage, flexibility, security, and cost. A novel multi-dimensional metric, the mission-critical relay effectiveness score (MCRES), is introduced as a quantitative method for evaluating relay suitability based on mission-specific weights for critical attributes like mobility, jamming resilience, deployment speed, stealth, coverage, and autonomy. Furthermore, we present Algorithm 1, a decision-making framework that leverages the MCRES to guide the systematic selection of the optimal relay type, AR or TR, and subsequently AAR or ARIS, tailored to the unique demands of a given military scenario, such as dynamic battlefield operations, electronic warfare, or covert missions. Finally, the paper addresses current implementation challenges and outlines promising future research directions to advance the deployment of robust and resilient UAV-mounted relay systems in contested military environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u519b\u4e8b\u901a\u4fe1\u4e2d\u7684\u7a7a\u4e2d\u4e2d\u7ee7\u7cfb\u7edf\uff0c\u6bd4\u8f83\u4e86\u7a7a\u4e2d\u4e2d\u7ee7\u4e0e\u5730\u9762\u4e2d\u7ee7\u7684\u4f18\u52a3\uff0c\u4ecb\u7ecd\u4e86AAR\u548cARIS\u4e24\u79cd\u6280\u672f\uff0c\u63d0\u51fa\u4e86MCRES\u8bc4\u4f30\u6307\u6807\u548c\u51b3\u7b56\u7b97\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u5730\u9762\u4e2d\u7ee7\u5728\u519b\u4e8b\u901a\u4fe1\u4e2d\u5b58\u5728\u4f4d\u7f6e\u56fa\u5b9a\u3001\u6613\u53d7\u7269\u7406\u969c\u788d\u9650\u5236\u7684\u7f3a\u9677\uff0c\u800c\u65e0\u4eba\u673a\u642d\u8f7d\u7684\u7a7a\u4e2d\u4e2d\u7ee7\u7cfb\u7edf\u5177\u6709\u52a8\u6001\u7075\u6d3b\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u9002\u5e94\u590d\u6742\u6218\u573a\u73af\u5883\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u548c\u9009\u62e9\u6700\u9002\u5408\u519b\u4e8b\u4efb\u52a1\u7684\u4e2d\u7ee7\u65b9\u6848\u3002", "method": "1. \u5bf9\u7a7a\u4e2d\u4e2d\u7ee7\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\u548c\u5b9a\u6027\u5206\u6790\uff1b2. \u63d0\u51fa\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6307\u6807MCRES\uff08\u4efb\u52a1\u5173\u952e\u4e2d\u7ee7\u6548\u80fd\u8bc4\u5206\uff09\uff1b3. \u5f00\u53d1\u51b3\u7b56\u7b97\u6cd5\uff08Algorithm 1\uff09\u7528\u4e8e\u7cfb\u7edf\u9009\u62e9\u6700\u4f18\u4e2d\u7ee7\u7c7b\u578b\uff1b4. \u6bd4\u8f83\u4e3b\u52a8\u7a7a\u4e2d\u4e2d\u7ee7\uff08AAR\uff09\u548c\u7a7a\u4e2d\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08ARIS\uff09\u4e24\u79cd\u6280\u672f\u3002", "result": "\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u7a7a\u4e2d\u4e2d\u7ee7\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7MCRES\u6307\u6807\u80fd\u591f\u5b9a\u91cf\u8bc4\u4f30\u4e2d\u7ee7\u7cfb\u7edf\u5728\u673a\u52a8\u6027\u3001\u6297\u5e72\u6270\u3001\u90e8\u7f72\u901f\u5ea6\u3001\u9690\u853d\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u81ea\u4e3b\u6027\u7b49\u5173\u952e\u5c5e\u6027\u4e0a\u7684\u8868\u73b0\uff0c\u4e3a\u4e0d\u540c\u519b\u4e8b\u573a\u666f\u63d0\u4f9b\u79d1\u5b66\u7684\u4e2d\u7ee7\u9009\u62e9\u4f9d\u636e\u3002", "conclusion": "\u65e0\u4eba\u673a\u642d\u8f7d\u7684\u7a7a\u4e2d\u4e2d\u7ee7\u7cfb\u7edf\u5728\u519b\u4e8b\u901a\u4fe1\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662fAAR\u548cARIS\u6280\u672f\u3002\u901a\u8fc7\u63d0\u51fa\u7684MCRES\u8bc4\u4f30\u6846\u67b6\u548c\u51b3\u7b56\u7b97\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9700\u6c42\u9009\u62e9\u6700\u4f18\u4e2d\u7ee7\u65b9\u6848\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u5347\u5728\u5bf9\u6297\u6027\u519b\u4e8b\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u5f39\u6027\u3002"}}
{"id": "2602.06045", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06045", "abs": "https://arxiv.org/abs/2602.06045", "authors": ["Zheng Wang", "Zhiye Yang", "Yang Yang", "Avik Ranjan Adhikary", "Keqin Feng"], "title": "Asymptotically Optimal Aperiodic Doppler Resilient Complementary Sequence Sets Via Generalized Quasi-Florentine Rectangles", "comment": null, "summary": "Doppler-resilient complementary sequence (DRCS) sets play a vital role in modern communication and sensing systems, particularly in high-mobility environments. This work makes two primary contributions. First, we refine the definition of quasi-Florentine rectangles to a more general form,termed generalized quasi-Florentine rectangles, and propose a systematic method for their construction. Second, we propose several sets of aperiodic DRCS based on generalized quasi Florentine rectangles and Butson-type Hadamard matrices. The proposed aperiodic DRCS sets are shown to be asymptotically optimal with respect to the lower bound of aperiodic DRCS sets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49\u51c6Florentine\u77e9\u5f62\u548cButson\u578bHadamard\u77e9\u9635\u6784\u5efa\u975e\u5468\u671f\u6027\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u6e10\u8fd1\u6700\u4f18\u6027", "motivation": "\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\u5728\u73b0\u4ee3\u901a\u4fe1\u548c\u611f\u77e5\u7cfb\u7edf\u4e2d\uff0c\u7279\u522b\u662f\u5728\u9ad8\u79fb\u52a8\u6027\u73af\u5883\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u6784\u5efa\u6027\u80fd\u66f4\u4f18\u7684\u5e8f\u5217\u96c6", "method": "1. \u5c06\u51c6Florentine\u77e9\u5f62\u7684\u5b9a\u4e49\u7cbe\u70bc\u4e3a\u66f4\u4e00\u822c\u5316\u7684\u5e7f\u4e49\u51c6Florentine\u77e9\u5f62\uff0c\u5e76\u63d0\u51fa\u7cfb\u7edf\u5316\u6784\u9020\u65b9\u6cd5\uff1b2. \u57fa\u4e8e\u5e7f\u4e49\u51c6Florentine\u77e9\u5f62\u548cButson\u578bHadamard\u77e9\u9635\u6784\u5efa\u591a\u7ec4\u975e\u5468\u671f\u6027\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6", "result": "\u63d0\u51fa\u7684\u975e\u5468\u671f\u6027\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\u76f8\u5bf9\u4e8e\u975e\u5468\u671f\u6027\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\u7684\u4e0b\u754c\u5177\u6709\u6e10\u8fd1\u6700\u4f18\u6027", "conclusion": "\u901a\u8fc7\u63a8\u5e7f\u51c6Florentine\u77e9\u5f62\u6982\u5ff5\u5e76\u7ed3\u5408Butson\u578bHadamard\u77e9\u9635\uff0c\u6210\u529f\u6784\u5efa\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u975e\u5468\u671f\u6027\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\uff0c\u4e3a\u9ad8\u79fb\u52a8\u6027\u73af\u5883\u4e0b\u7684\u901a\u4fe1\u548c\u611f\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5e8f\u5217\u8bbe\u8ba1\u65b9\u6848"}}
{"id": "2602.06107", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06107", "abs": "https://arxiv.org/abs/2602.06107", "authors": ["Zhuoming Chen", "Hongyi Liu", "Yang Zhou", "Haizhong Zheng", "Beidi Chen"], "title": "Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning", "comment": "ICLR 2026", "summary": "Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to directly reduce the discrepancy between the rollout model and the evolving policy. Jackpot integrates a principled OBRS procedure, a unified training objective that jointly updates the policy and rollout models, and an efficient system implementation enabled by top-$k$ probability estimation and batch-level bias correction. Our theoretical analysis shows that OBRS consistently moves the rollout distribution closer to the target distribution under a controllable acceptance budget. Empirically, \\sys substantially improves training stability compared to importance-sampling baselines, achieving performance comparable to on-policy RL when training Qwen3-8B-Base for up to 300 update steps of batchsize 64. Taken together, our results show that OBRS-based alignment brings us a step closer to practical and effective decoupling of rollout generation from policy optimization for RL for LLMs.", "AI": {"tldr": "Jackpot\u6846\u67b6\u4f7f\u7528\u6700\u4f18\u9884\u7b97\u62d2\u7edd\u91c7\u6837\u6765\u51cf\u5c11rollout\u6a21\u578b\u4e0e\u7b56\u7565\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684LLM\u5f3a\u5316\u5b66\u4e60", "motivation": "LLM\u7684\u5f3a\u5316\u5b66\u4e60\u6210\u672c\u9ad8\u6602\uff0c\u7279\u522b\u662frollout\u9636\u6bb5\u3002\u5c06rollout\u751f\u6210\u4e0e\u7b56\u7565\u4f18\u5316\u89e3\u8026\u53ef\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u7834\u574f\u5b66\u4e60\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faJackpot\u6846\u67b6\uff0c\u91c7\u7528\u6700\u4f18\u9884\u7b97\u62d2\u7edd\u91c7\u6837\u6765\u76f4\u63a5\u51cf\u5c11rollout\u6a21\u578b\u4e0e\u6f14\u5316\u7b56\u7565\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u5305\u62ec\u539f\u5219\u6027\u7684OBRS\u7a0b\u5e8f\u3001\u8054\u5408\u66f4\u65b0\u7b56\u7565\u548crollout\u6a21\u578b\u7684\u7edf\u4e00\u8bad\u7ec3\u76ee\u6807\uff0c\u4ee5\u53ca\u901a\u8fc7top-k\u6982\u7387\u4f30\u8ba1\u548c\u6279\u6b21\u7ea7\u504f\u5dee\u6821\u6b63\u5b9e\u73b0\u7684\u9ad8\u6548\u7cfb\u7edf\u5b9e\u73b0\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eOBRS\u5728\u53ef\u63a7\u63a5\u53d7\u9884\u7b97\u4e0b\u6301\u7eed\u5c06rollout\u5206\u5e03\u79fb\u5411\u76ee\u6807\u5206\u5e03\u3002\u5b9e\u8bc1\u663e\u793a\u76f8\u6bd4\u91cd\u8981\u6027\u91c7\u6837\u57fa\u7ebf\uff0cJackpot\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5728Qwen3-8B-Base\u4e0a\u8bad\u7ec3300\u6b65\uff08\u6279\u6b21\u5927\u5c0f64\uff09\u65f6\u8fbe\u5230\u4e0eon-policy RL\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8eOBRS\u7684\u5bf9\u9f50\u65b9\u6cd5\u4f7frollout\u751f\u6210\u4e0e\u7b56\u7565\u4f18\u5316\u7684\u89e3\u8026\u66f4\u63a5\u8fd1\u5b9e\u7528\u548c\u6709\u6548\uff0c\u4e3aLLM\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.06176", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06176", "abs": "https://arxiv.org/abs/2602.06176", "authors": ["Peiyang Song", "Pengrui Han", "Noah Goodman"], "title": "Large Language Model Reasoning Failures", "comment": "Repository: https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures. Published at TMLR 2026 with Survey Certification", "summary": "Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distinguishes reasoning into embodied and non-embodied types, with the latter further subdivided into informal (intuitive) and formal (logical) reasoning. In parallel, we classify reasoning failures along a complementary axis into three types: fundamental failures intrinsic to LLM architectures that broadly affect downstream tasks; application-specific limitations that manifest in particular domains; and robustness issues characterized by inconsistent performance across minor variations. For each reasoning failure, we provide a clear definition, analyze existing studies, explore root causes, and present mitigation strategies. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities. We additionally release a comprehensive collection of research works on LLM reasoning failures, as a GitHub repository at https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures, to provide an easy entry point to this area.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9LLM\u63a8\u7406\u5931\u8d25\u8fdb\u884c\u5168\u9762\u8c03\u67e5\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u5206\u4e3a\u5177\u8eab\u4e0e\u975e\u5177\u8eab\u7c7b\u578b\uff0c\u5e76\u5c06\u63a8\u7406\u5931\u8d25\u5206\u4e3a\u57fa\u7840\u6027\u3001\u5e94\u7528\u7279\u5b9a\u548c\u9c81\u68d2\u6027\u4e09\u7c7b\uff0c\u4e3a\u7406\u89e3LLM\u7cfb\u7edf\u6027\u5f31\u70b9\u63d0\u4f9b\u7ed3\u6784\u5316\u89c6\u89d2\u3002", "motivation": "\u5c3d\u7ba1LLM\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u770b\u4f3c\u7b80\u5355\u7684\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u663e\u8457\u7684\u63a8\u7406\u5931\u8d25\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u5931\u8d25\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u548c\u5206\u7c7b\uff0c\u9700\u8981\u7edf\u4e00\u5206\u6563\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u3001\u66f4\u53ef\u9760\u3001\u66f4\u9c81\u68d2\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5206\u7c7b\u6846\u67b6\uff1a\u5c06\u63a8\u7406\u5206\u4e3a\u5177\u8eab\u63a8\u7406\u548c\u975e\u5177\u8eab\u63a8\u7406\uff0c\u975e\u5177\u8eab\u63a8\u7406\u8fdb\u4e00\u6b65\u7ec6\u5206\u4e3a\u975e\u6b63\u5f0f\uff08\u76f4\u89c9\uff09\u63a8\u7406\u548c\u6b63\u5f0f\uff08\u903b\u8f91\uff09\u63a8\u7406\u3002\u540c\u65f6\uff0c\u5c06\u63a8\u7406\u5931\u8d25\u5206\u4e3a\u4e09\u7c7b\uff1a1\uff09\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u7684\u57fa\u7840\u6027\u5931\u8d25\uff1b2\uff09\u7279\u5b9a\u9886\u57df\u8868\u73b0\u7684\u5e94\u7528\u7279\u5b9a\u9650\u5236\uff1b3\uff09\u5fae\u5c0f\u53d8\u5316\u5bfc\u81f4\u6027\u80fd\u4e0d\u4e00\u81f4\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002\u5bf9\u6bcf\u79cd\u5931\u8d25\u63d0\u4f9b\u660e\u786e\u5b9a\u4e49\u3001\u5206\u6790\u73b0\u6709\u7814\u7a76\u3001\u63a2\u7d22\u6839\u672c\u539f\u56e0\u5e76\u63d0\u51fa\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u5168\u9762\u7684LLM\u63a8\u7406\u5931\u8d25\u8c03\u67e5\uff0c\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u89c6\u89d2\u6765\u7406\u89e3LLM\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u3002\u53d1\u5e03\u4e86GitHub\u5b58\u50a8\u5e93\uff08https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures\uff09\uff0c\u6536\u96c6\u4e86LLM\u63a8\u7406\u5931\u8d25\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4fbf\u6377\u5165\u53e3\u3002", "conclusion": "\u8be5\u8c03\u67e5\u7edf\u4e00\u4e86\u5206\u6563\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u4e3aLLM\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u5206\u7c7b\u548c\u7406\u89e3\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5f3a\u3001\u66f4\u53ef\u9760\u3001\u66f4\u9c81\u68d2\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.06062", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06062", "abs": "https://arxiv.org/abs/2602.06062", "authors": ["Anh Thi Bui", "Robert-Jeron Reifert", "Hayssam Dahrouj", "Aydin Sezgin"], "title": "Deep Unfolded Fractional Optimization for Maximizing Robust Throughput in 6G Networks", "comment": "6 pages, 5 figures", "summary": "The sixth-generation (6G) of wireless communication networks aims to leverage artificial intelligence tools for efficient and robust network optimization. This is especially the case since traditional optimization methods often face high computational complexity, motivating the use of deep learning (DL)-based optimization frameworks. In this context, this paper considers a multi-antenna base station (BS) serving multiple users simultaneously through transmit beamforming in downlink mode. To account for robustness, this work proposes an uncertainty-injected deep unfolded fractional programming (UI-DUFP) framework for weighted sum rate (WSR) maximization under imperfect channel conditions. The proposed method unfolds fractional programming (FP) iterations into trainable neural network layers refined by projected gradient descent (PGD) steps, while robustness is introduced by injecting sampled channel uncertainties during training and optimizing a quantile-based objective. Simulation results show that the proposed UI-DUFP achieves higher WSR and improved robustness compared to classical weighted minimum mean square error, FP, and DL baselines, while maintaining low inference time and good scalability. These findings highlight the potential of deep unfolding combined with uncertainty-aware training as a powerful approach for robust optimization in 6G networks.", "AI": {"tldr": "\u63d0\u51faUI-DUFP\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5c55\u5f00\u5206\u5f0f\u89c4\u5212\u548c\u4e0d\u786e\u5b9a\u6027\u6ce8\u5165\u8bad\u7ec3\uff0c\u5b9e\u73b06G\u7f51\u7edc\u4e0b\u884c\u6ce2\u675f\u8d4b\u5f62\u4e2d\u52a0\u6743\u548c\u901f\u7387\u7684\u6700\u5927\u5316\uff0c\u5728\u4fe1\u9053\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "6G\u7f51\u7edc\u9700\u8981\u5229\u7528AI\u5de5\u5177\u8fdb\u884c\u9ad8\u6548\u9c81\u68d2\u7684\u4f18\u5316\u3002\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u4fe1\u9053\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5904\u7406\u4fe1\u9053\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u4f18\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u6ce8\u5165\u6df1\u5ea6\u5c55\u5f00\u5206\u5f0f\u89c4\u5212(UI-DUFP)\u6846\u67b6\uff1a1)\u5c06\u5206\u5f0f\u89c4\u5212\u8fed\u4ee3\u5c55\u5f00\u4e3a\u53ef\u8bad\u7ec3\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\uff1b2)\u7528\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u6b65\u9aa4\u8fdb\u884c\u7cbe\u70bc\uff1b3)\u8bad\u7ec3\u65f6\u6ce8\u5165\u91c7\u6837\u7684\u4fe1\u9053\u4e0d\u786e\u5b9a\u6027\uff1b4)\u4f18\u5316\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u76ee\u6807\u51fd\u6570\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cUI-DUFP\u76f8\u6bd4\u4f20\u7edf\u52a0\u6743\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u3001\u5206\u5f0f\u89c4\u5212\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u52a0\u6743\u548c\u901f\u7387\u548c\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u63a8\u7406\u65f6\u95f4\u548c\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u6df1\u5ea6\u5c55\u5f00\u4e0e\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bad\u7ec3\u76f8\u7ed3\u5408\uff0c\u662f6G\u7f51\u7edc\u4e2d\u9c81\u68d2\u4f18\u5316\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e3aAI\u8d4b\u80fd\u7684\u65e0\u7ebf\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.06227", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.06227", "abs": "https://arxiv.org/abs/2602.06227", "authors": ["Pierriccardo Olivieri", "Fausto Lasca", "Alessandro Gianola", "Matteo Papini"], "title": "Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)", "comment": "This is the extended version of a paper accepted at AAAI 2026", "summary": "In this work, we propose a novel framework for the logical specification of non-Markovian rewards in Markov Decision Processes (MDPs) with large state spaces. Our approach leverages Linear Temporal Logic Modulo Theories over finite traces (LTLfMT), a more expressive extension of classical temporal logic in which predicates are first-order formulas of arbitrary first-order theories rather than simple Boolean variables. This enhanced expressiveness enables the specification of complex tasks over unstructured and heterogeneous data domains, promoting a unified and reusable framework that eliminates the need for manual predicate encoding. However, the increased expressive power of LTLfMT introduces additional theoretical and computational challenges compared to standard LTLf specifications. We address these challenges from a theoretical standpoint, identifying a fragment of LTLfMT that is tractable but sufficiently expressive for reward specification in an infinite-state-space context. From a practical perspective, we introduce a method based on reward machines and Hindsight Experience Replay (HER) to translate first-order logic specifications and address reward sparsity. We evaluate this approach to a continuous-control setting using Non-Linear Arithmetic Theory, showing that it enables natural specification of complex tasks. Experimental results show how a tailored implementation of HER is fundamental in solving tasks with complex goals.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLTLfMT\u7684\u903b\u8f91\u89c4\u8303\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4MDP\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\uff0c\u901a\u8fc7\u7406\u8bba\u7247\u6bb5\u8bc6\u522b\u548c\u57fa\u4e8e\u5956\u52b1\u673a\u5668+Hindsight Experience Replay\u7684\u5b9e\u8df5\u65b9\u6cd5\u89e3\u51b3\u8868\u8fbe\u529b\u589e\u5f3a\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u975e\u7ed3\u6784\u5316\u3001\u5f02\u6784\u6570\u636e\u57df\u4e0a\u7684\u590d\u6742\u4efb\u52a1\u65f6\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u624b\u52a8\u8c13\u8bcd\u7f16\u7801\u3002\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u3001\u53ef\u91cd\u7528\u7684\u6846\u67b6\u6765\u6307\u5b9a\u590d\u6742\u4efb\u52a1\uff0c\u540c\u65f6\u5904\u7406\u65e0\u9650\u72b6\u6001\u7a7a\u95f4\u73af\u5883\u3002", "method": "1) \u4f7f\u7528LTLfMT\uff08\u57fa\u4e8e\u7406\u8bba\u7684\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff09\u4f5c\u4e3a\u89c4\u8303\u8bed\u8a00\uff1b2) \u8bc6\u522b\u7406\u8bba\u53ef\u5904\u7406\u7684LTLfMT\u7247\u6bb5\uff1b3) \u7ed3\u5408\u5956\u52b1\u673a\u5668\u548cHindsight Experience Replay\u5c06\u4e00\u9636\u903b\u8f91\u89c4\u8303\u8f6c\u5316\u4e3a\u53ef\u5b66\u4e60\u5f62\u5f0f\uff1b4) \u5728\u975e\u7ebf\u6027\u7b97\u672f\u7406\u8bba\u4e0b\u7684\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5b9a\u5236\u7684HER\u5b9e\u73b0\u5bf9\u4e8e\u89e3\u51b3\u590d\u6742\u76ee\u6807\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u81ea\u7136\u5730\u6307\u5b9a\u590d\u6742\u4efb\u52a1\uff0c\u5e76\u5728\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\u6709\u6548\u5de5\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u7684LTLfMT\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4MDP\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\u63d0\u4f9b\u4e86\u4e00\u79cd\u8868\u8fbe\u80fd\u529b\u5f3a\u3001\u7edf\u4e00\u7684\u89c4\u8303\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u7247\u6bb5\u8bc6\u522b\u548cHER\u6280\u672f\u89e3\u51b3\u4e86\u8868\u8fbe\u529b\u589e\u5f3a\u5e26\u6765\u7684\u8ba1\u7b97\u6311\u6218\u3002"}}
{"id": "2602.06206", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06206", "abs": "https://arxiv.org/abs/2602.06206", "authors": ["Xusheng Zhu", "Kai-Kit Wong", "Hanjiang Hong", "Han Xiao", "Hao Xu", "Tuo Wu", "Chan-Byoung Chae"], "title": "UAV-Enabled Short-Packet Communication via Fluid Antenna Systems", "comment": null, "summary": "This paper develops a framework for analyzing UAV-enabled short-packet communication, leveraging fluid antenna system (FAS)-assisted relaying networks. Operating in the short-packet regime and focusing on challenging urban environments, we derive novel, closed-form expressions for the block error rate (BLER). This is achieved by modeling the spatially correlated Nakagami-$m$ fading link via a tractable eigenvalue-based approach. A high-signal-to-noise ratio (SNR) asymptotic analysis is also presented, revealing the system's fundamental diversity order. Building on this analysis, we formulate a novel energy efficiency (EE) maximization problem that, unlike idealized models, uniquely incorporates the non-trivial time and energy overheads of FAS port selection. An efficient hierarchical algorithm is proposed to jointly optimize key system parameters. Numerical results validate our analysis, demonstrating that while FAS provides substantial power gains, the operational overhead creates a critical trade-off. This trade-off dictates an optimal number of FAS ports and a non-trivial optimal UAV deployment altitude, governed by the balance between blockage and path loss. This work provides key insights for FAS-aided UAV communications.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u65e0\u4eba\u673a\u4f7f\u80fd\u7684\u77ed\u5305\u901a\u4fe1\u6846\u67b6\uff0c\u5229\u7528\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u8f85\u52a9\u4e2d\u7ee7\u7f51\u7edc\uff0c\u5728\u77ed\u5305\u673a\u5236\u4e0b\u63a8\u5bfc\u4e86\u5757\u9519\u8bef\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u8003\u8651FAS\u7aef\u53e3\u9009\u62e9\u5f00\u9500\u7684\u80fd\u6548\u6700\u5927\u5316\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u57ce\u5e02\u73af\u5883\u4e2d\u65e0\u4eba\u673a\u77ed\u5305\u901a\u4fe1\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5982\u4f55\u5229\u7528\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u8003\u8651\u5b9e\u9645\u7cfb\u7edf\u4e2dFAS\u7aef\u53e3\u9009\u62e9\u7684\u975e\u7406\u60f3\u5f00\u9500\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7279\u5f81\u503c\u7684\u53ef\u5904\u7406\u65b9\u6cd5\u6765\u5efa\u6a21\u7a7a\u95f4\u76f8\u5173\u7684Nakagami-m\u8870\u843d\u94fe\u8def\uff0c\u63a8\u5bfcBLER\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u8fdb\u884c\u9ad8\u4fe1\u566a\u6bd4\u6e10\u8fd1\u5206\u6790\uff0c\u5e76\u8bbe\u8ba1\u5206\u5c42\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u7cfb\u7edf\u53c2\u6570\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5206\u6790\u7684\u6b63\u786e\u6027\uff0c\u663e\u793aFAS\u80fd\u63d0\u4f9b\u663e\u8457\u529f\u7387\u589e\u76ca\uff0c\u4f46\u64cd\u4f5c\u5f00\u9500\u5e26\u6765\u4e86\u5173\u952e\u6743\u8861\uff0c\u8fd9\u51b3\u5b9a\u4e86FAS\u7aef\u53e3\u7684\u6700\u4f18\u6570\u91cf\u548c\u65e0\u4eba\u673a\u90e8\u7f72\u7684\u6700\u4f73\u9ad8\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aFAS\u8f85\u52a9\u7684\u65e0\u4eba\u673a\u901a\u4fe1\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u63ed\u793a\u4e86\u5728\u529f\u7387\u589e\u76ca\u548c\u64cd\u4f5c\u5f00\u9500\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4ee5\u53ca\u7531\u906e\u6321\u548c\u8def\u5f84\u635f\u8017\u5e73\u8861\u51b3\u5b9a\u7684\u6700\u4f18\u90e8\u7f72\u7b56\u7565\u3002"}}
{"id": "2602.06286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06286", "abs": "https://arxiv.org/abs/2602.06286", "authors": ["Khurram Yamin", "Jingjing Tang", "Santiago Cortes-Gomez", "Amit Sharma", "Eric Horvitz", "Bryan Wilder"], "title": "Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult to interpret. We study whether LLMs are rational utility maximizers with coherent beliefs and stable preferences. We consider behaviors of models for diagnosis challenge problems. The results provide insights about the relationship of LLM inferences to ideal Bayesian utility maximization for elicited probabilities and observed actions. Our approach provides falsifiable conditions under which the reported probabilities \\emph{cannot} correspond to the true beliefs of any rational agent. We apply this methodology to multiple medical diagnostic domains with evaluations across several LLMs. We discuss implications of the results and directions forward for uses of LLMs in guiding high-stakes decisions.", "AI": {"tldr": "\u7814\u7a76LLMs\u5728\u533b\u7597\u8bca\u65ad\u7b49\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u662f\u5426\u4f5c\u4e3a\u7406\u6027\u6548\u7528\u6700\u5927\u5316\u8005\uff0c\u63d0\u51fa\u53ef\u8bc1\u4f2a\u6761\u4ef6\u68c0\u9a8cLLM\u62a5\u544a\u6982\u7387\u662f\u5426\u5bf9\u5e94\u771f\u5b9e\u4fe1\u5ff5", "motivation": "LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4f5c\u4e3a\u667a\u80fd\u4f53\uff0c\u5176\u51b3\u7b56\u903b\u8f91\u96be\u4ee5\u89e3\u91ca\uff0c\u9700\u8981\u7814\u7a76\u5b83\u4eec\u662f\u5426\u5177\u6709\u4e00\u81f4\u7684\u4fe1\u5ff5\u548c\u7a33\u5b9a\u7684\u504f\u597d\uff0c\u4ee5\u7406\u6027\u6548\u7528\u6700\u5927\u5316\u8005\u7684\u65b9\u5f0f\u8fd0\u4f5c", "method": "\u901a\u8fc7\u8bca\u65ad\u6311\u6218\u95ee\u9898\u7814\u7a76\u6a21\u578b\u884c\u4e3a\uff0c\u63d0\u51fa\u53ef\u8bc1\u4f2a\u6761\u4ef6\u6765\u68c0\u9a8c\u62a5\u544a\u6982\u7387\u662f\u5426\u5bf9\u5e94\u4efb\u4f55\u7406\u6027\u667a\u80fd\u4f53\u7684\u771f\u5b9e\u4fe1\u5ff5\uff0c\u5e76\u5728\u591a\u4e2a\u533b\u7597\u8bca\u65ad\u9886\u57df\u8bc4\u4f30\u591a\u4e2aLLMs", "result": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5173\u4e8eLLM\u63a8\u7406\u4e0e\u7406\u60f3\u8d1d\u53f6\u65af\u6548\u7528\u6700\u5927\u5316\u4e4b\u95f4\u5173\u7cfb\u7684\u89c1\u89e3\uff0c\u63ed\u793a\u4e86LLM\u62a5\u544a\u6982\u7387\u4e0e\u7406\u6027\u667a\u80fd\u4f53\u771f\u5b9e\u4fe1\u5ff5\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027", "conclusion": "\u7814\u7a76\u4e3aLLM\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u4f7f\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\uff0c\u6307\u51fa\u4e86\u5f53\u524dLLM\u5728\u7406\u6027\u51b3\u7b56\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411"}}
{"id": "2602.06238", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.06238", "abs": "https://arxiv.org/abs/2602.06238", "authors": ["Remi A. Chou", "Joerg Kliewer", "Aylin Yener"], "title": "Private Sum Computation: Trade-Offs between Communication, Randomness, and Privacy", "comment": "11 pages, two-column, accepted to IEEE Transactions on Information Theory", "summary": "Consider multiple users and a fusion center. Each user possesses a sequence of bits and can communicate with the fusion center through a one-way public channel. The fusion center's task is to compute the sum of all the sequences under the privacy requirement that a set of colluding users, along with the fusion center, cannot gain more than a predetermined amount $\u03b4$ of information, measured through mutual information, about the sequences of other users. Our first contribution is to characterize the minimum amount of necessary communication between the users and the fusion center, as well as the minimum amount of necessary randomness at the users. Our second contribution is to establish a connection between private sum computation and secret sharing by showing that secret sharing is necessary to generate the local randomness needed for private sum computation, and prove that it holds true for any $\u03b4\\geq 0$.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u7528\u6237\u4e0e\u878d\u5408\u4e2d\u5fc3\u4e4b\u95f4\u7684\u9690\u79c1\u4fdd\u62a4\u6c42\u548c\u8ba1\u7b97\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u901a\u4fe1\u548c\u968f\u673a\u6027\u5f00\u9500\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u79d8\u5bc6\u5171\u4eab\u7684\u8054\u7cfb\u3002", "motivation": "\u5728\u591a\u7528\u6237\u7cfb\u7edf\u4e2d\uff0c\u878d\u5408\u4e2d\u5fc3\u9700\u8981\u8ba1\u7b97\u6240\u6709\u7528\u6237\u6bd4\u7279\u5e8f\u5217\u7684\u548c\uff0c\u540c\u65f6\u8981\u4fdd\u62a4\u7528\u6237\u6570\u636e\u7684\u9690\u79c1\uff0c\u9632\u6b62\u7528\u6237\u4e0e\u878d\u5408\u4e2d\u5fc3\u5408\u8c0b\u83b7\u53d6\u5176\u4ed6\u7528\u6237\u7684\u654f\u611f\u4fe1\u606f\u3002\u8fd9\u9700\u8981\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6548\u7387\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "method": "\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u5206\u6790\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u901a\u4fe1\u548c\u968f\u673a\u6027\u9700\u6c42\uff0c\u5efa\u7acb\u9690\u79c1\u6c42\u548c\u8ba1\u7b97\u4e0e\u79d8\u5bc6\u5171\u4eab\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8bc1\u660e\u79d8\u5bc6\u5171\u4eab\u662f\u751f\u6210\u672c\u5730\u968f\u673a\u6027\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "result": "1. \u8868\u5f81\u4e86\u7528\u6237\u4e0e\u878d\u5408\u4e2d\u5fc3\u4e4b\u95f4\u6240\u9700\u7684\u6700\u5c0f\u901a\u4fe1\u91cf\u4ee5\u53ca\u7528\u6237\u6240\u9700\u7684\u6700\u5c0f\u968f\u673a\u6027\u91cf\uff1b2. \u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f\u03b4\u22650\uff0c\u79d8\u5bc6\u5171\u4eab\u662f\u751f\u6210\u9690\u79c1\u6c42\u548c\u8ba1\u7b97\u6240\u9700\u672c\u5730\u968f\u673a\u6027\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "conclusion": "\u9690\u79c1\u6c42\u548c\u8ba1\u7b97\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u4fe1\u606f\u8bba\u6846\u67b6\u8fdb\u884c\u5206\u6790\uff0c\u79d8\u5bc6\u5171\u4eab\u662f\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u5173\u952e\u673a\u5236\uff0c\u8fd9\u4e00\u8054\u7cfb\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u5206\u5e03\u5f0f\u8ba1\u7b97\u534f\u8bae\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.06319", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06319", "abs": "https://arxiv.org/abs/2602.06319", "authors": ["Qifan Zhang", "Jianhao Ruan", "Aochuan Chen", "Kang Zeng", "Nuo Chen", "Jing Tang", "Jia Li"], "title": "Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems", "comment": null, "summary": "Large Reasoning Models (LRMs) have advanced rapidly; however, existing benchmarks in mathematics, code, and common-sense reasoning remain limited. They lack long-context evaluation, offer insufficient challenge, and provide answers that are difficult to verify programmatically. We introduce GrAlgoBench, a benchmark designed to evaluate LRMs through graph algorithm problems. Such problems are particularly well suited for probing reasoning abilities: they demand long-context reasoning, allow fine-grained control of difficulty levels, and enable standardized, programmatic evaluation. Across nine tasks, our systematic experiments reveal two major weaknesses of current LRMs. First, accuracy deteriorates sharply as context length increases, falling below 50% once graphs exceed 120 nodes. This degradation is driven by frequent execution errors, weak memory, and redundant reasoning. Second, LRMs suffer from an over-thinking phenomenon, primarily caused by extensive yet largely ineffective self-verification, which inflates reasoning traces without improving correctness. By exposing these limitations, GrAlgoBench establishes graph algorithm problems as a rigorous, multidimensional, and practically relevant testbed for advancing the study of reasoning in LRMs. Code is available at https://github.com/Bklight999/GrAlgoBench.", "AI": {"tldr": "GrAlgoBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7b97\u6cd5\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u51c6\u786e\u7387\u4e0b\u964d\u548c\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u3001\u4ee3\u7801\u548c\u5e38\u8bc6\u63a8\u7406\u57fa\u51c6\u5b58\u5728\u5c40\u9650\uff1a\u7f3a\u4e4f\u957f\u4e0a\u4e0b\u6587\u8bc4\u4f30\u3001\u6311\u6218\u6027\u4e0d\u8db3\u3001\u7b54\u6848\u96be\u4ee5\u7a0b\u5e8f\u5316\u9a8c\u8bc1\u3002\u9700\u8981\u66f4\u4e25\u683c\u7684\u6d4b\u8bd5\u5e73\u53f0\u6765\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165GrAlgoBench\u57fa\u51c6\uff0c\u5305\u542b9\u4e2a\u56fe\u7b97\u6cd5\u4efb\u52a1\u3002\u56fe\u7b97\u6cd5\u95ee\u9898\u7279\u522b\u9002\u5408\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\uff1a\u9700\u8981\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3001\u96be\u5ea6\u53ef\u7cbe\u7ec6\u63a7\u5236\u3001\u652f\u6301\u6807\u51c6\u5316\u7a0b\u5e8f\u5316\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u5f53\u524d\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e24\u5927\u5f31\u70b9\uff1a1) \u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u65f6\u51c6\u786e\u7387\u6025\u5267\u4e0b\u964d\uff08\u8d85\u8fc7120\u4e2a\u8282\u70b9\u65f6\u4f4e\u4e8e50%\uff09\uff0c\u4e3b\u8981\u7531\u4e8e\u6267\u884c\u9519\u8bef\u3001\u5f31\u8bb0\u5fc6\u548c\u5197\u4f59\u63a8\u7406\uff1b2) \u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5927\u91cf\u65e0\u6548\u7684\u81ea\u6211\u9a8c\u8bc1\u589e\u52a0\u4e86\u63a8\u7406\u75d5\u8ff9\u4f46\u4e0d\u6539\u5584\u6b63\u786e\u6027\u3002", "conclusion": "GrAlgoBench\u901a\u8fc7\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u786e\u7acb\u4e86\u56fe\u7b97\u6cd5\u95ee\u9898\u4f5c\u4e3a\u4e25\u683c\u3001\u591a\u7ef4\u4e14\u5b9e\u9645\u76f8\u5173\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u7814\u7a76\u3002"}}
{"id": "2602.06247", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06247", "abs": "https://arxiv.org/abs/2602.06247", "authors": ["Farshad Rostami Ghadi", "Kai-Kit Wong", "F. Javier Lopez-Martinez", "Zhentian Zhang", "Hyundong Shin", "Christos Masouros"], "title": "AI-Limited Fluid Antenna-Aided Integrated Sensing and Communication Systems", "comment": null, "summary": "This paper characterizes the fundamental limits of integrated sensing and communication (ISAC) when the transmitter is subject to an artificial intelligence (AI) representation bottleneck and the receiver employs a fluid antenna system (FAS). Specifically, the message is first encoded into an ideal Gaussian waveform and mapped by an AI encoder into a finite-capacity latent representation that constitutes the physical channel input, while the FAS receiver selects the port experiencing the most favorable channel conditions. We reveal that the AI bottleneck is equivalent to an additive representation noise, which reduces both the communication and sensing signal-to-noise ratios (SNRs) at the selected port. We then derive the resulting ISAC capacitydistortion region and establish tight converse and achievability bounds under general fading models, including Jakes-correlated channels. Leveraging the spatial degrees of freedom (DoF) characterization of the Jakes' model, we furthermore prove that the port-selection gain is fundamentally constrained by the physical length of the FAS region: the effective diversity order equals the numerical rank of the Jakes' correlation matrix and increases only with the FAS length. Consequently, enlarging the FAS length allows the selected-port SNR to approach the AI-imposed ceiling, driving the achievable communication rate and sensing mean square error (MSE) toward their AI-limited fundamental bounds. Numerical results corroborate the analysis and scaling laws.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u5728AI\u8868\u793a\u74f6\u9888\u548c\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf(FAS)\u4e0b\u7684\u57fa\u672c\u6781\u9650\uff0c\u63ed\u793a\u4e86AI\u74f6\u9888\u7b49\u6548\u4e8e\u52a0\u6027\u8868\u793a\u566a\u58f0\uff0c\u5e76\u63a8\u5bfc\u4e86ISAC\u5bb9\u91cf-\u5931\u771f\u533a\u57df\uff0c\u8bc1\u660e\u4e86FAS\u957f\u5ea6\u51b3\u5b9a\u4e86\u7aef\u53e3\u9009\u62e9\u589e\u76ca\u7684\u591a\u6837\u6027\u9636\u6570\u3002", "motivation": "\u7814\u7a76\u5728AI\u8868\u793a\u74f6\u9888\u7ea6\u675f\u4e0b\uff0c\u7ed3\u5408\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf(FAS)\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u7cfb\u7edf\u7684\u6027\u80fd\u6781\u9650\u3002AI\u7f16\u7801\u5668\u5c06\u7406\u60f3\u9ad8\u65af\u6ce2\u5f62\u6620\u5c04\u4e3a\u6709\u9650\u5bb9\u91cf\u7684\u6f5c\u5728\u8868\u793a\uff0c\u800cFAS\u63a5\u6536\u5668\u9009\u62e9\u4fe1\u9053\u6761\u4ef6\u6700\u4f73\u7684\u7aef\u53e3\uff0c\u9700\u8981\u5206\u6790\u8fd9\u79cd\u67b6\u6784\u4e0b\u7684\u57fa\u672c\u6027\u80fd\u8fb9\u754c\u3002", "method": "\u9996\u5148\u5c06AI\u74f6\u9888\u5efa\u6a21\u4e3a\u52a0\u6027\u8868\u793a\u566a\u58f0\uff0c\u964d\u4f4e\u901a\u4fe1\u548c\u611f\u77e5\u7684\u4fe1\u566a\u6bd4\u3002\u7136\u540e\u63a8\u5bfcISAC\u5bb9\u91cf-\u5931\u771f\u533a\u57df\uff0c\u5efa\u7acb\u7d27\u5bc6\u7684\u9006\u754c\u548c\u53ef\u8fbe\u754c\u3002\u5229\u7528Jakes\u76f8\u5173\u4fe1\u9053\u7684\u7a7a\u95f4\u81ea\u7531\u5ea6\u7279\u6027\uff0c\u5206\u6790FAS\u957f\u5ea6\u5bf9\u7aef\u53e3\u9009\u62e9\u589e\u76ca\u7684\u5f71\u54cd\uff0c\u8bc1\u660e\u6709\u6548\u591a\u6837\u6027\u9636\u6570\u7b49\u4e8eJakes\u76f8\u5173\u77e9\u9635\u7684\u6570\u503c\u79e9\u3002", "result": "AI\u74f6\u9888\u7b49\u6548\u4e8e\u52a0\u6027\u8868\u793a\u566a\u58f0\uff0c\u964d\u4f4e\u901a\u4fe1\u548c\u611f\u77e5SNR\u3002\u7aef\u53e3\u9009\u62e9\u589e\u76ca\u53d7FAS\u7269\u7406\u957f\u5ea6\u9650\u5236\uff0c\u6709\u6548\u591a\u6837\u6027\u9636\u6570\u7b49\u4e8eJakes\u76f8\u5173\u77e9\u9635\u7684\u6570\u503c\u79e9\u3002\u589e\u5927FAS\u957f\u5ea6\u53ef\u4f7f\u9009\u62e9\u7aef\u53e3SNR\u63a5\u8fd1AI\u65bd\u52a0\u7684\u5929\u82b1\u677f\uff0c\u4f7f\u901a\u4fe1\u901f\u7387\u548c\u611f\u77e5MSE\u8d8b\u8fd1AI\u9650\u5236\u7684\u57fa\u672c\u8fb9\u754c\u3002", "conclusion": "\u5728AI\u8868\u793a\u74f6\u9888\u548cFAS\u7684ISAC\u7cfb\u7edf\u4e2d\uff0cFAS\u957f\u5ea6\u662f\u51b3\u5b9a\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002\u589e\u5927FAS\u957f\u5ea6\u53ef\u63d0\u5347\u7aef\u53e3\u9009\u62e9\u589e\u76ca\uff0c\u4f7f\u7cfb\u7edf\u6027\u80fd\u63a5\u8fd1AI\u9650\u5236\u7684\u57fa\u672c\u8fb9\u754c\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2602.06351", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.06351", "abs": "https://arxiv.org/abs/2602.06351", "authors": ["Longhui Ma", "Di Zhao", "Siwei Wang", "Zhao Lv", "Miao Wang"], "title": "Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion", "comment": "17 pages, 10 figures", "summary": "GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale GUI datasets to predict target element coordinates, which is data-intensive and generalizes poorly to unseen interfaces. Recent attention-based alternatives exploit localization signals in MLLMs attention mechanisms without task-specific fine-tuning, but suffer from low reliability due to the lack of explicit and complementary spatial anchors in GUI images. To address this limitation, we propose Trifuse, an attention-based grounding framework that explicitly integrates complementary spatial anchors. Trifuse integrates attention, OCR-derived textual cues, and icon-level caption semantics via a Consensus-SinglePeak (CS) fusion strategy that enforces cross-modal agreement while retaining sharp localization peaks. Extensive evaluations on four grounding benchmarks demonstrate that Trifuse achieves strong performance without task-specific fine-tuning, substantially reducing the reliance on expensive annotated data. Moreover, ablation studies reveal that incorporating OCR and caption cues consistently improves attention-based grounding performance across different backbones, highlighting its effectiveness as a general framework for GUI grounding.", "AI": {"tldr": "Trifuse\u662f\u4e00\u4e2a\u57fa\u4e8e\u6ce8\u610f\u529b\u7684GUI grounding\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6ce8\u610f\u529b\u673a\u5236\u3001OCR\u6587\u672c\u7ebf\u7d22\u548c\u56fe\u6807\u7ea7\u8bed\u4e49\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u5b9e\u73b0\u5f3a\u5927\u7684\u754c\u9762\u5143\u7d20\u5b9a\u4f4d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GUI grounding\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5fae\u8c03MLLMs\u6765\u9884\u6d4b\u5750\u6807\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6570\u636e\u5bc6\u96c6\u4e14\u5bf9\u672a\u89c1\u754c\u9762\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u66ff\u4ee3\u65b9\u6cd5\u867d\u7136\u65e0\u9700\u5fae\u8c03\uff0c\u4f46\u7f3a\u4e4f\u660e\u786e\u7684\u7a7a\u95f4\u951a\u70b9\u5bfc\u81f4\u53ef\u9760\u6027\u4f4e\u3002", "method": "Trifuse\u6846\u67b6\u660e\u786e\u6574\u5408\u4e86\u4e92\u8865\u7684\u7a7a\u95f4\u951a\u70b9\uff0c\u901a\u8fc7Consensus-SinglePeak\u878d\u5408\u7b56\u7565\u5c06\u6ce8\u610f\u529b\u673a\u5236\u3001OCR\u63d0\u53d6\u7684\u6587\u672c\u7ebf\u7d22\u548c\u56fe\u6807\u7ea7\u8bed\u4e49\u63cf\u8ff0\u7ed3\u5408\u8d77\u6765\uff0c\u5f3a\u5236\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u540c\u65f6\u4fdd\u6301\u5c16\u9510\u7684\u5b9a\u4f4d\u5cf0\u503c\u3002", "result": "\u5728\u56db\u4e2agrounding\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cTrifuse\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u5c31\u80fd\u5b9e\u73b0\u5f3a\u5927\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u5bf9\u6602\u8d35\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6574\u5408OCR\u548c\u8bed\u4e49\u7ebf\u7d22\u80fd\u6301\u7eed\u63d0\u5347\u57fa\u4e8e\u6ce8\u610f\u529b\u7684grounding\u6027\u80fd\u3002", "conclusion": "Trifuse\u901a\u8fc7\u6574\u5408\u4e92\u8865\u7684\u7a7a\u95f4\u951a\u70b9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u6ce8\u610f\u529b\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4e3aGUI grounding\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2602.06377", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06377", "abs": "https://arxiv.org/abs/2602.06377", "authors": ["Chun'e Zhao", "Wenping Ma"], "title": "Hermitian Self-dual Generalized Reed-Solomon Codes", "comment": null, "summary": "Maximum Distance Separable (MDS) self-dual codes are of significant theoretical and practical importance. Generalized Reed-Solomon (GRS) codes are the most prominent MDS codes. Correspondingly there have been many research on constructions of Euclidean self-dual MDS codes by using GRS codes. However, the study on Hermitian self-dual GRS codes is relatively limited. Since Hermitian self-dual GRS codes do not exist for $n>q+1$, this paper is devoted to an investigation of GRS codes in the case where $n\\le q+1$. First, we prove that when $n\\leq q+1$, there are only two classes of Hermitian self-dual GRS codes, confirming the conjecture in [13] and providing its proof simultaneously. Second, we present two explicit construction methods. Thus, the existence and construction of Hermitian self-dual GRS codes are fully solved.", "AI": {"tldr": "\u672c\u6587\u5b8c\u5168\u89e3\u51b3\u4e86Hermitian\u81ea\u5bf9\u5076GRS\u7801\u7684\u5b58\u5728\u6027\u548c\u6784\u9020\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5f53n\u2264q+1\u65f6\u53ea\u6709\u4e24\u7c7bHermitian\u81ea\u5bf9\u5076GRS\u7801\uff0c\u5e76\u7ed9\u51fa\u4e86\u4e24\u79cd\u663e\u5f0f\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "MDS\u81ea\u5bf9\u5076\u7801\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\uff0cGRS\u7801\u662f\u6700\u91cd\u8981\u7684MDS\u7801\u3002\u867d\u7136\u6b27\u51e0\u91cc\u5f97\u81ea\u5bf9\u5076MDS\u7801\u7684\u7814\u7a76\u5f88\u591a\uff0c\u4f46Hermitian\u81ea\u5bf9\u5076GRS\u7801\u7684\u7814\u7a76\u76f8\u5bf9\u6709\u9650\u3002\u7531\u4e8eHermitian\u81ea\u5bf9\u5076GRS\u7801\u5728n>q+1\u65f6\u4e0d\u5b58\u5728\uff0c\u672c\u6587\u81f4\u529b\u4e8e\u7814\u7a76n\u2264q+1\u60c5\u51b5\u4e0b\u7684GRS\u7801\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4e86\u5f53n\u2264q+1\u65f6\uff0c\u53ea\u5b58\u5728\u4e24\u7c7bHermitian\u81ea\u5bf9\u5076GRS\u7801\uff0c\u8bc1\u5b9e\u4e86\u6587\u732e[13]\u4e2d\u7684\u731c\u60f3\u5e76\u540c\u65f6\u63d0\u4f9b\u4e86\u8bc1\u660e\u3002\u5176\u6b21\u63d0\u51fa\u4e86\u4e24\u79cd\u663e\u5f0f\u6784\u9020\u65b9\u6cd5\u3002", "result": "\u5b8c\u5168\u89e3\u51b3\u4e86Hermitian\u81ea\u5bf9\u5076GRS\u7801\u7684\u5b58\u5728\u6027\u548c\u6784\u9020\u95ee\u9898\uff0c\u786e\u5b9a\u4e86\u5728n\u2264q+1\u6761\u4ef6\u4e0b\u53ea\u6709\u4e24\u7c7b\u8fd9\u6837\u7684\u7801\u5b58\u5728\uff0c\u5e76\u7ed9\u51fa\u4e86\u5177\u4f53\u7684\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u5bf9Hermitian\u81ea\u5bf9\u5076GRS\u7801\u7684\u7814\u7a76\u505a\u51fa\u4e86\u5b8c\u6574\u8d21\u732e\uff0c\u89e3\u51b3\u4e86\u5b58\u5728\u6027\u95ee\u9898\u548c\u6784\u9020\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.06375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06375", "abs": "https://arxiv.org/abs/2602.06375", "authors": ["Yu Zhao", "Fan Jiang", "Tianle Liu", "Bo Zeng", "Yu Liu", "Longyue Wang", "Weihua Luo"], "title": "Difficulty-Estimated Policy Optimization", "comment": null, "summary": "Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are either too trivial or overly complex. In these scenarios, the disappearance of inter-group advantages makes the gradient signal susceptible to noise, thereby jeopardizing convergence stability. While variants like DAPO attempt to rectify gradient vanishing, they do not alleviate the substantial computational overhead incurred by exhaustive rollouts on low-utility samples. In this paper, we propose Difficulty-Estimated Policy Optimization (DEPO), a novel framework designed to optimize the efficiency and robustness of reasoning alignment. DEPO integrates an online Difficulty Estimator that dynamically assesses and filters training data before the rollout phase. This mechanism ensures that computational resources are prioritized for samples with high learning potential. Empirical results demonstrate that DEPO achieves up to a 2x reduction in rollout costs without compromising model performance. Our approach significantly lowers the computational barrier for training high-performance reasoning models, offering a more sustainable path for reasoning scaling. Code and data will be released upon acceptance.", "AI": {"tldr": "DEPO\u901a\u8fc7\u52a8\u6001\u96be\u5ea6\u8bc4\u4f30\u7b5b\u9009\u8bad\u7ec3\u6570\u636e\uff0c\u51cf\u5c11\u4f4e\u6548\u6837\u672c\u7684rollout\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5c06\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u964d\u4f4e2\u500d\u3002", "motivation": "\u73b0\u6709\u7684Group Relative Policy Optimization\uff08GRPO\uff09\u5728\u8bad\u7ec3\u63a8\u7406\u6a21\u578b\u65f6\u9762\u4e34\u68af\u5ea6\u4fe1\u53f7\u8870\u51cf\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8fc7\u4e8e\u7b80\u5355\u6216\u8fc7\u4e8e\u590d\u6742\u7684\u95ee\u9898\u65f6\u3002\u867d\u7136DAPO\u7b49\u53d8\u4f53\u5c1d\u8bd5\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u4f46\u65e0\u6cd5\u7f13\u89e3\u5728\u4f4e\u6548\u7528\u6837\u672c\u4e0a\u8fdb\u884c\u5927\u91cfrollout\u5e26\u6765\u7684\u5de8\u5927\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51faDifficulty-Estimated Policy Optimization\uff08DEPO\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e00\u4e2a\u5728\u7ebf\u96be\u5ea6\u8bc4\u4f30\u5668\uff0c\u5728rollout\u9636\u6bb5\u524d\u52a8\u6001\u8bc4\u4f30\u548c\u7b5b\u9009\u8bad\u7ec3\u6570\u636e\uff0c\u4f18\u5148\u5c06\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u7ed9\u5177\u6709\u9ad8\u5b66\u4e60\u6f5c\u529b\u7684\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDEPO\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06rollout\u6210\u672c\u964d\u4f4e\u4e86\u6700\u591a2\u500d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u9ad8\u6027\u80fd\u63a8\u7406\u6a21\u578b\u7684\u8ba1\u7b97\u95e8\u69db\u3002", "conclusion": "DEPO\u4e3a\u63a8\u7406\u6a21\u578b\u7684\u89c4\u6a21\u5316\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u53ef\u6301\u7eed\u7684\u8def\u5f84\uff0c\u901a\u8fc7\u667a\u80fd\u6570\u636e\u7b5b\u9009\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6536\u655b\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.06464", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06464", "abs": "https://arxiv.org/abs/2602.06464", "authors": ["Shuao Chen", "Junyuan Gao", "Yuxuan Shi", "Yongpeng Wu", "Giuseppe Caire", "H. Vincent Poor", "Wenjun Zhang"], "title": "Joint Lossy Compression for a Vector Gaussian Source under Individual Distortion Criteria", "comment": "To appear in IEEE GLOBECOM 2025", "summary": "This paper investigates the joint compression problem of a vector Gaussian source, where an individual distortion constraint is imposed on each source component. It is known that the rate-distortion function (RDF) is lower-bounded by the rate derived from the Hadamard inequality, which becomes exact when the semidefinite condition (SDC) holds. However, existing works often overlook the case where the SDC is not satisfied. Moreover, even when the SDC holds, a quantitative characterization of how correlations enable more efficient compression is lacking. In this work, we refine the results when the SDC is satisfied and derive new theoretical results when the SDC is not satisfied, thereby establishing theoretical limits for practical source compression with correlations. Specifically, we examine the properties of optimal source reconstruction and provide upper bounds on its dimension, showing that lower-dimensional reconstructions are essential for efficient compression when the SDC does not hold. Within a scalable two-type correlation (2TC) covariance framework, we prove that the probability of satisfying the SDC decays exponentially with source length, emphasizing the importance of exploring theoretical limits when the SDC is not met. Additional, we determine the component-wise correlations that a vector source should possess to achieve the Hadamard compression rate, revealing the trade-off between distortion constraints and correlations. More importantly, by deriving an explicit RDF with correlations incorporated, we quantitatively characterize the gain in compression efficiency achieved by fully leveraging source correlations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5411\u91cf\u9ad8\u65af\u6e90\u7684\u8054\u5408\u538b\u7f29\u95ee\u9898\uff0c\u6539\u8fdb\u4e86\u534a\u5b9a\u6761\u4ef6\u6ee1\u8db3\u65f6\u7684\u7ed3\u679c\uff0c\u5e76\u63a8\u5bfc\u4e86\u534a\u5b9a\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u7684\u65b0\u7406\u8bba\u754c\u9650\uff0c\u91cf\u5316\u4e86\u76f8\u5173\u6027\u5bf9\u538b\u7f29\u6548\u7387\u7684\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5f80\u5f80\u5ffd\u7565\u534a\u5b9a\u6761\u4ef6\u4e0d\u6ee1\u8db3\u7684\u60c5\u51b5\uff0c\u4e14\u5373\u4f7f\u534a\u5b9a\u6761\u4ef6\u6ee1\u8db3\u65f6\uff0c\u4e5f\u7f3a\u4e4f\u5bf9\u76f8\u5173\u6027\u5982\u4f55\u5b9e\u73b0\u66f4\u9ad8\u6548\u538b\u7f29\u7684\u5b9a\u91cf\u523b\u753b\u3002\u9700\u8981\u5efa\u7acb\u9002\u7528\u4e8e\u5b9e\u9645\u76f8\u5173\u6e90\u538b\u7f29\u7684\u7406\u8bba\u754c\u9650\u3002", "method": "\u5206\u6790\u6700\u4f18\u6e90\u91cd\u6784\u7684\u6027\u8d28\u5e76\u7ed9\u51fa\u5176\u7ef4\u5ea6\u7684\u4e0a\u754c\uff1b\u5728\u53ef\u6269\u5c55\u7684\u4e24\u7c7b\u76f8\u5173\u6027\u534f\u65b9\u5dee\u6846\u67b6\u4e0b\uff0c\u8bc1\u660e\u6ee1\u8db3\u534a\u5b9a\u6761\u4ef6\u7684\u6982\u7387\u968f\u6e90\u957f\u5ea6\u6307\u6570\u8870\u51cf\uff1b\u786e\u5b9a\u5411\u91cf\u6e90\u5e94\u5177\u5907\u7684\u7ec4\u4ef6\u95f4\u76f8\u5173\u6027\u4ee5\u5b9e\u73b0Hadamard\u538b\u7f29\u7387\uff1b\u63a8\u5bfc\u5305\u542b\u76f8\u5173\u6027\u7684\u663e\u5f0f\u7387\u5931\u771f\u51fd\u6570\u3002", "result": "\u5f53\u534a\u5b9a\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\uff0c\u4f4e\u7ef4\u91cd\u6784\u5bf9\u9ad8\u6548\u538b\u7f29\u81f3\u5173\u91cd\u8981\uff1b\u6ee1\u8db3\u534a\u5b9a\u6761\u4ef6\u7684\u6982\u7387\u968f\u6e90\u957f\u5ea6\u6307\u6570\u8870\u51cf\uff1b\u786e\u5b9a\u4e86\u5b9e\u73b0Hadamard\u538b\u7f29\u7387\u6240\u9700\u7684\u76f8\u5173\u6027\u6743\u8861\uff1b\u5b9a\u91cf\u523b\u753b\u4e86\u5145\u5206\u5229\u7528\u6e90\u76f8\u5173\u6027\u5e26\u6765\u7684\u538b\u7f29\u6548\u7387\u589e\u76ca\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5b8c\u5584\u4e86\u534a\u5b9a\u6761\u4ef6\u6ee1\u8db3\u65f6\u7684\u7ed3\u679c\uff0c\u5e76\u5efa\u7acb\u4e86\u534a\u5b9a\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u7684\u7406\u8bba\u754c\u9650\uff0c\u5b9a\u91cf\u63ed\u793a\u4e86\u76f8\u5173\u6027\u5728\u538b\u7f29\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u4e3a\u5b9e\u9645\u76f8\u5173\u6e90\u538b\u7f29\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.06394", "categories": ["cs.AI", "cs.CE", "q-bio.GN", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.06394", "abs": "https://arxiv.org/abs/2602.06394", "authors": ["Arvid E. Gollwitzer", "Paridhi Latawa", "David de Gruijl", "Deepak A. Subramanian", "Adri\u00e1n Noriega de la Colina"], "title": "Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization", "comment": null, "summary": "Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization. Our experimental evaluation demonstrates consistent improvements: genomics (6.7 percentage point F1 gain in variant calling over BPE), finance (30% Sharpe ratio improvement). At foundation scale, we tokenize a pretraining corpus comprising 1.7 trillion base-pairs and achieve state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. We unlock noisy real-world corpora, spanning petabases of genomic sequences and terabytes of financial time series, for foundation model training with zero inference overhead.", "AI": {"tldr": "QA-Token\u662f\u4e00\u79cd\u8d28\u91cf\u611f\u77e5\u7684\u5206\u8bcd\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u53c2\u6570\u5b66\u4e60\uff0c\u5c06\u6570\u636e\u53ef\u9760\u6027\u76f4\u63a5\u878d\u5165\u8bcd\u6c47\u8868\u6784\u5efa\uff0c\u5728\u57fa\u56e0\u7ec4\u5b66\u548c\u91d1\u878d\u9886\u57df\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u51cf\u5c1115%\u7684token\u6570\u91cf\u3002", "motivation": "\u5f53\u524d\u7684\u5206\u8bcd\u65b9\u6cd5\u5728\u5904\u7406\u5e8f\u5217\u6570\u636e\u65f6\u6ca1\u6709\u8003\u8651\u4fe1\u53f7\u8d28\u91cf\uff0c\u9650\u5236\u4e86\u5176\u5728\u5608\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u8bed\u6599\u5e93\u4e2d\u7684\u6709\u6548\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u7ed3\u5408\u6570\u636e\u53ef\u9760\u6027\u7684\u5206\u8bcd\u65b9\u6cd5\u3002", "method": "\u63d0\u51faQA-Token\uff08\u8d28\u91cf\u611f\u77e5\u5206\u8bcd\uff09\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a1\uff09\u53cc\u5c42\u4f18\u5316\u516c\u5f0f\uff0c\u8054\u5408\u4f18\u5316\u8bcd\u6c47\u8868\u6784\u5efa\u548c\u4e0b\u6e38\u6027\u80fd\uff1b2\uff09\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d28\u91cf\u611f\u77e5\u5956\u52b1\u5b66\u4e60\u5408\u5e76\u7b56\u7565\u5e76\u4fdd\u8bc1\u6536\u655b\uff1b3\uff09\u901a\u8fc7Gumbel-Softmax\u677e\u5f1b\u7684\u81ea\u9002\u5e94\u53c2\u6570\u5b66\u4e60\u673a\u5236\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\u4e00\u81f4\u6539\u8fdb\uff1a\u57fa\u56e0\u7ec4\u5b66\uff08\u53d8\u5f02\u68c0\u6d4bF1\u5206\u6570\u6bd4BPE\u63d0\u9ad86.7\u4e2a\u767e\u5206\u70b9\uff09\u3001\u91d1\u878d\uff08\u590f\u666e\u6bd4\u7387\u63d0\u9ad830%\uff09\u3002\u5728\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u4e0a\uff0c\u5bf91.7\u4e07\u4ebf\u78b1\u57fa\u5bf9\u7684\u9884\u8bad\u7ec3\u8bed\u6599\u8fdb\u884c\u5206\u8bcd\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u75c5\u539f\u4f53\u68c0\u6d4b\uff0894.53 MCC\uff09\uff0c\u540c\u65f6\u51cf\u5c1115%\u7684token\u6570\u91cf\u3002", "conclusion": "QA-Token\u89e3\u9501\u4e86\u5608\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u8bed\u6599\u5e93\uff08\u5305\u62ecpetabase\u89c4\u6a21\u7684\u57fa\u56e0\u7ec4\u5e8f\u5217\u548cterabyte\u89c4\u6a21\u7684\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\uff09\uff0c\u7528\u4e8e\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\uff0c\u4e14\u63a8\u7406\u65f6\u65e0\u989d\u5916\u5f00\u9500\u3002"}}
{"id": "2602.06467", "categories": ["cs.IT", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.06467", "abs": "https://arxiv.org/abs/2602.06467", "authors": ["Johannes Bund", "Christoph Lenzen", "Moti Medina"], "title": "Codes for Metastability-Containing Addition", "comment": "This work has been accepted for publication at IEEE Transactions on Computers", "summary": "We investigate the fundamental task of addition under uncertainty, namely, addends that are represented as intervals of numbers rather than single values. One potential source of such uncertainty can occur when obtaining discrete-valued measurements of analog values, which are prone to metastability. Naturally, unstable bits impact gate-level and, consequently, circuit-level computations. Using Binary encoding for such an addition produces a sum with an amplified imprecision. Hence, the challenge is to devise an encoding that does not amplify the imprecision caused by unstable bits. We call such codes recoverable. While this challenge is easily met for unary encoding, no suitable codes of high rates are known. In this work, we prove an upper bound on the rate of preserving and recoverable codes for a given bound on the addends' combined uncertainty. We then design an asymptotically optimal code that preserves the addends' combined uncertainty. We then discuss how to obtain adders for our code. The approach can be used with any known or future construction for containing metastability of the inputs. We conjecture that careful design based on existing techniques can lead to significant latency reduction.", "AI": {"tldr": "\u7814\u7a76\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u52a0\u6cd5\u95ee\u9898\uff0c\u5176\u4e2d\u52a0\u6570\u4ee5\u533a\u95f4\u800c\u975e\u7cbe\u786e\u503c\u8868\u793a\uff0c\u63d0\u51fa\u53ef\u6062\u590d\u7f16\u7801\u6982\u5ff5\u4ee5\u63a7\u5236\u4e0d\u786e\u5b9a\u6027\u653e\u5927\uff0c\u8bbe\u8ba1\u6e10\u8fdb\u6700\u4f18\u7f16\u7801\u5e76\u8ba8\u8bba\u76f8\u5e94\u52a0\u6cd5\u5668\u5b9e\u73b0\u3002", "motivation": "\u5f53\u6a21\u62df\u503c\u8f6c\u6362\u4e3a\u6570\u5b57\u6d4b\u91cf\u65f6\u53ef\u80fd\u51fa\u73b0\u4e9a\u7a33\u6001\uff0c\u5bfc\u81f4\u6bd4\u7279\u4e0d\u7a33\u5b9a\uff0c\u8fdb\u800c\u5f71\u54cd\u7535\u8def\u7ea7\u8ba1\u7b97\u3002\u4f7f\u7528\u4e8c\u8fdb\u5236\u7f16\u7801\u8fdb\u884c\u52a0\u6cd5\u4f1a\u653e\u5927\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u8bbe\u8ba1\u4e0d\u653e\u5927\u4e0d\u786e\u5b9a\u6027\u7684\u7f16\u7801\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u53ef\u6062\u590d\u7f16\u7801\u6982\u5ff5\uff0c\u8bc1\u660e\u5728\u7ed9\u5b9a\u52a0\u6570\u7ec4\u5408\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\u4e0b\u53ef\u4fdd\u6301\u548c\u53ef\u6062\u590d\u7f16\u7801\u7684\u901f\u7387\u4e0a\u754c\uff0c\u8bbe\u8ba1\u6e10\u8fdb\u6700\u4f18\u7684\u4fdd\u6301\u52a0\u6570\u7ec4\u5408\u4e0d\u786e\u5b9a\u6027\u7684\u7f16\u7801\uff0c\u5e76\u8ba8\u8bba\u5982\u4f55\u5b9e\u73b0\u8be5\u7f16\u7801\u7684\u52a0\u6cd5\u5668\u3002", "result": "\u8bc1\u660e\u4e86\u53ef\u4fdd\u6301\u548c\u53ef\u6062\u590d\u7f16\u7801\u7684\u901f\u7387\u4e0a\u754c\uff0c\u8bbe\u8ba1\u4e86\u6e10\u8fdb\u6700\u4f18\u7684\u7f16\u7801\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u80fd\u591f\u4fdd\u6301\u52a0\u6570\u7684\u7ec4\u5408\u4e0d\u786e\u5b9a\u6027\u800c\u4e0d\u653e\u5927\u3002", "conclusion": "\u63d0\u51fa\u7684\u7f16\u7801\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63a7\u5236\u4e0d\u786e\u5b9a\u6027\u52a0\u6cd5\u4e2d\u7684\u8bef\u5dee\u653e\u5927\u95ee\u9898\uff0c\u7ed3\u5408\u73b0\u6709\u6280\u672f\u53ef\u5b9e\u73b0\u663e\u8457\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0c\u9002\u7528\u4e8e\u5305\u542b\u8f93\u5165\u4e9a\u7a33\u6001\u7684\u5404\u79cd\u5df2\u77e5\u6216\u672a\u6765\u6784\u9020\u3002"}}
{"id": "2602.06413", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06413", "abs": "https://arxiv.org/abs/2602.06413", "authors": ["Hsien-Jyh Liao"], "title": "Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution", "comment": "16 Pages, 7 figures, Keyworda: Autoregressive Reasoning, Long-Horizon Stability, Chain-of-Thought Reasoning, Information-Theoretic Analysis, Structured Reasoning, Inference Dynamics", "summary": "Large language models (LLMs) demonstrate remarkable reasoning capabilities, yet their performance often deteriorates sharply in long-horizon tasks, exhibiting systematic breakdown beyond certain scales. Conventional explanations primarily attribute this phenomenon to task complexity, such as combinatorial search explosion or long-term credit assignment challenges. In this work, we argue that these explanations are incomplete: even in linear, unbranched tasks without semantic ambiguity, autoregressive execution is subject to an intrinsic stability limit.\n  We propose that the fundamental constraint on long-horizon reasoning arises from process-level instability in autoregressive generation rather than solely from search or task complexity, reframing long-horizon reasoning as a problem of structural governance. We derive Theorem~A, showing that decision advantage in single-path autoregressive reasoning decays exponentially with execution length, imposing a fundamental bound on maintainable reasoning chains. This result implies a structural consequence: stable long-horizon reasoning requires discrete segmentation, naturally inducing graph-like execution structures such as directed acyclic graphs (DAGs).\n  Empirical studies in both synthetic environments and real TextWorld tasks reveal observable performance cliffs consistent with theoretical predictions. Our findings provide a dynamical perspective on long-horizon reasoning failure and suggest new limitations on maintaining long-term coherence under purely autoregressive architectures. Furthermore, we highlight that short-horizon evaluation protocols may obscure structural instability, indicating a potential shift from scaling toward structured governance in future reasoning systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u81ea\u56de\u5f52\u751f\u6210\u5b58\u5728\u5185\u5728\u7a33\u5b9a\u6027\u6781\u9650\uff0c\u5373\u4f7f\u5728\u7ebf\u6027\u65e0\u5206\u652f\u4efb\u52a1\u4e2d\uff0c\u51b3\u7b56\u4f18\u52bf\u4f1a\u968f\u6267\u884c\u957f\u5ea6\u6307\u6570\u8870\u51cf\uff0c\u5bfc\u81f4\u957f\u89c6\u91ce\u63a8\u7406\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u9700\u8981\u79bb\u6563\u5206\u6bb5\u548c\u56fe\u7ed3\u6784\u6267\u884c\u6765\u7ef4\u6301\u7a33\u5b9a\u3002", "motivation": "\u4f20\u7edf\u89e3\u91ca\u5c06LLMs\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u5f52\u56e0\u4e8e\u4efb\u52a1\u590d\u6742\u6027\uff08\u5982\u7ec4\u5408\u641c\u7d22\u7206\u70b8\u6216\u957f\u671f\u4fe1\u7528\u5206\u914d\uff09\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e9b\u89e3\u91ca\u4e0d\u5b8c\u6574\u3002\u5373\u4f7f\u5728\u65e0\u8bed\u4e49\u6a21\u7cca\u7684\u7ebf\u6027\u65e0\u5206\u652f\u4efb\u52a1\u4e2d\uff0c\u81ea\u56de\u5f52\u6267\u884c\u4e5f\u5b58\u5728\u5185\u5728\u7a33\u5b9a\u6027\u6781\u9650\uff0c\u9700\u8981\u4ece\u7ed3\u6784\u6cbb\u7406\u89d2\u5ea6\u91cd\u65b0\u7406\u89e3\u957f\u89c6\u91ce\u63a8\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u5b9a\u7406A\u8bc1\u660e\u5355\u8def\u5f84\u81ea\u56de\u5f52\u63a8\u7406\u4e2d\u7684\u51b3\u7b56\u4f18\u52bf\u968f\u6267\u884c\u957f\u5ea6\u6307\u6570\u8870\u51cf\u3002\u901a\u8fc7\u5408\u6210\u73af\u5883\u548c\u771f\u5b9eTextWorld\u4efb\u52a1\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u7684\u53ef\u89c2\u6d4b\u6027\u80fd\u60ac\u5d16\u73b0\u8c61\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u663e\u793a\u6027\u80fd\u4e0b\u964d\u4e0e\u7406\u8bba\u9884\u6d4b\u4e00\u81f4\uff0c\u63ed\u793a\u4e86\u81ea\u56de\u5f52\u67b6\u6784\u5728\u7ef4\u6301\u957f\u671f\u4e00\u81f4\u6027\u65b9\u9762\u7684\u7ed3\u6784\u6027\u9650\u5236\u3002\u77ed\u89c6\u91ce\u8bc4\u4f30\u534f\u8bae\u53ef\u80fd\u63a9\u76d6\u7ed3\u6784\u4e0d\u7a33\u5b9a\u6027\uff0c\u8868\u660e\u672a\u6765\u63a8\u7406\u7cfb\u7edf\u9700\u8981\u4ece\u5355\u7eaf\u6269\u5c55\u8f6c\u5411\u7ed3\u6784\u5316\u6cbb\u7406\u3002", "conclusion": "\u957f\u89c6\u91ce\u63a8\u7406\u7684\u6839\u672c\u7ea6\u675f\u6e90\u4e8e\u81ea\u56de\u5f52\u751f\u6210\u7684\u8fc7\u7a0b\u7ea7\u4e0d\u7a33\u5b9a\u6027\u800c\u975e\u5355\u7eaf\u7684\u4efb\u52a1\u590d\u6742\u6027\u3002\u7a33\u5b9a\u957f\u89c6\u91ce\u63a8\u7406\u9700\u8981\u79bb\u6563\u5206\u6bb5\uff0c\u81ea\u7136\u8bf1\u5bfc\u51fa\u6709\u5411\u65e0\u73af\u56fe\u7b49\u56fe\u7ed3\u6784\u6267\u884c\u3002\u8fd9\u4e3a\u7406\u89e3\u957f\u89c6\u91ce\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e86\u52a8\u529b\u5b66\u89c6\u89d2\uff0c\u5e76\u6307\u51fa\u4e86\u7eaf\u81ea\u56de\u5f52\u67b6\u6784\u5728\u7ef4\u6301\u957f\u671f\u4e00\u81f4\u6027\u65b9\u9762\u7684\u65b0\u9650\u5236\u3002"}}
{"id": "2602.06479", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06479", "abs": "https://arxiv.org/abs/2602.06479", "authors": ["Shuao Chen", "Junyuan Gao", "Yuxuan Shi", "Yongpeng Wu", "Giuseppe Caire", "H. Vincent Poor", "Wenjun Zhang"], "title": "FDD CSI Feedback under Finite Downlink Training: A Rate-Distortion Perspective", "comment": "To appear in IEEE ICC 2026", "summary": "This paper establishes the theoretical limits of channel state information (CSI) feedback in frequency-division duplexing (FDD) multi-antenna orthogonal frequency-division multiplexing (OFDM) systems under finite-length training with Gaussian pilots. The user employs minimum mean-squared error (MMSE) channel estimation followed by asymptotically optimal uplink feedback. Specifically, we derive a general rate-distortion function (RDF) of the overall CSI feedback system. We then provide both non-asymptotic bounds and asymptotic scaling for the RDF under arbitrary downlink signal-to-noise ratio (SNR) when the number of training symbols exceeds the antenna dimension. A key observation is that, with sufficient training, the overall RDF converges to the direct RDF corresponding to the case where the user has full access to the downlink CSI. More importantly, we demonstrate that even at a fixed downlink SNR, the convergence rate is inversely proportional to the training length. The simulation results show that our bounds are tight, and under very limited training, the deviation between the overall RDF and the direct RDF is substantial.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86FDD\u591a\u5929\u7ebfOFDM\u7cfb\u7edf\u4e2dCSI\u53cd\u9988\u7684\u7406\u8bba\u6781\u9650\uff0c\u63a8\u5bfc\u4e86\u5728\u6709\u9650\u957f\u5ea6\u8bad\u7ec3\u4e0b\u7684\u6574\u4f53\u901f\u7387\u5931\u771f\u51fd\u6570\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6536\u655b\u7279\u6027\u3002", "motivation": "\u5728FDD\u591a\u5929\u7ebfOFDM\u7cfb\u7edf\u4e2d\uff0c\u7528\u6237\u9700\u8981\u901a\u8fc7\u4e0a\u884c\u94fe\u8def\u53cd\u9988CSI\uff0c\u4f46\u5b9e\u9645\u7cfb\u7edf\u4e2d\u8bad\u7ec3\u957f\u5ea6\u6709\u9650\u4e14\u5b58\u5728\u4f30\u8ba1\u8bef\u5dee\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5728\u6709\u9650\u8bad\u7ec3\u957f\u5ea6\u4e0bCSI\u53cd\u9988\u7684\u7406\u8bba\u6027\u80fd\u6781\u9650\u5206\u6790\uff0c\u9700\u8981\u5efa\u7acb\u5b8c\u6574\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u7cfb\u7edf\u6027\u80fd\u8fb9\u754c\u3002", "method": "\u91c7\u7528MMSE\u4fe1\u9053\u4f30\u8ba1\u7ed3\u5408\u6e10\u8fdb\u6700\u4f18\u4e0a\u884c\u53cd\u9988\u7b56\u7565\uff0c\u63a8\u5bfc\u6574\u4f53CSI\u53cd\u9988\u7cfb\u7edf\u7684\u901f\u7387\u5931\u771f\u51fd\u6570\u3002\u63d0\u4f9b\u975e\u6e10\u8fdb\u8fb9\u754c\u548c\u6e10\u8fdb\u7f29\u653e\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8\u8bad\u7ec3\u7b26\u53f7\u6570\u8d85\u8fc7\u5929\u7ebf\u7ef4\u5ea6\u7684\u60c5\u51b5\uff0c\u5206\u6790\u4e0d\u540c\u4e0b\u884cSNR\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u5f53\u8bad\u7ec3\u7b26\u53f7\u8db3\u591f\u591a\u65f6\uff0c\u6574\u4f53RDF\u6536\u655b\u5230\u7528\u6237\u5b8c\u5168\u83b7\u53d6\u4e0b\u884cCSI\u65f6\u7684\u76f4\u63a5RDF\u3002\u5173\u952e\u53d1\u73b0\uff1a\u5728\u56fa\u5b9a\u4e0b\u884cSNR\u4e0b\uff0c\u6536\u655b\u901f\u7387\u4e0e\u8bad\u7ec3\u957f\u5ea6\u6210\u53cd\u6bd4\u3002\u4eff\u771f\u9a8c\u8bc1\u8fb9\u754c\u7d27\u81f4\uff0c\u6709\u9650\u8bad\u7ec3\u4e0b\u6574\u4f53RDF\u4e0e\u76f4\u63a5RDF\u5b58\u5728\u663e\u8457\u504f\u5dee\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86FDD\u591a\u5929\u7ebfOFDM\u7cfb\u7edf\u4e2dCSI\u53cd\u9988\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8bad\u7ec3\u957f\u5ea6\u5bf9\u53cd\u9988\u6027\u80fd\u7684\u5173\u952e\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2602.06485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06485", "abs": "https://arxiv.org/abs/2602.06485", "authors": ["Haotian Chen", "Xin Cong", "Shengda Fan", "Yuyang Fu", "Ziqin Gong", "Yaxi Lu", "Yishan Li", "Boye Niu", "Chengjun Pan", "Zijun Song", "Huadong Wang", "Yesai Wu", "Yueying Wu", "Zihao Xie", "Yukun Yan", "Zhong Zhang", "Yankai Lin", "Zhiyuan Liu", "Maosong Sun"], "title": "AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents", "comment": null, "summary": "While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on training agentic models at the 4B-parameter scale. We identify three primary bottlenecks hindering the performance of edge-scale models: catastrophic forgetting during Supervised Fine-Tuning (SFT), sensitivity to reward signal noise during Reinforcement Learning (RL), and reasoning degradation caused by redundant information in long-context scenarios. To address the issues, we propose AgentCPM-Explore, a compact 4B agent model with high knowledge density and strong exploration capability. We introduce a holistic training framework featuring parameter-space model fusion, reward signal denoising, and contextual information refinement. Through deep exploration, AgentCPM-Explore achieves state-of-the-art (SOTA) performance among 4B-class models, matches or surpasses 8B-class SOTA models on four benchmarks, and even outperforms larger-scale models such as Claude-4.5-Sonnet or DeepSeek-v3.2 in five benchmarks. Notably, AgentCPM-Explore achieves 97.09% accuracy on GAIA text-based tasks under pass@64. These results provide compelling evidence that the bottleneck for edge-scale models is not their inherent capability ceiling, but rather their inference stability. Based on our well-established training framework, AgentCPM-Explore effectively unlocks the significant, yet previously underestimated, potential of edge-scale models.", "AI": {"tldr": "AgentCPM-Explore\u662f\u9996\u4e2a\u7cfb\u7edf\u7814\u7a764B\u53c2\u6570\u89c4\u6a21\u667a\u80fd\u4f53\u6a21\u578b\u7684\u6210\u679c\uff0c\u901a\u8fc7\u89e3\u51b3SFT\u707e\u96be\u6027\u9057\u5fd8\u3001RL\u5956\u52b1\u4fe1\u53f7\u566a\u58f0\u548c\u957f\u4e0a\u4e0b\u6587\u5197\u4f59\u4fe1\u606f\u4e09\u5927\u74f6\u9888\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a8B\u6a21\u578b\u751a\u81f3\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u7cfb\u7edf\u8fc7\u5ea6\u4f9d\u8d56\u5927\u89c4\u6a21\u6a21\u578b\uff0c\u8fb9\u7f18\u89c4\u6a21\u6a21\u578b\uff084B\u53c2\u6570\uff09\u7684\u6f5c\u529b\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5982\u4f55\u514b\u670d\u5c0f\u89c4\u6a21\u6a21\u578b\u5728\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u3002", "method": "\u63d0\u51faAgentCPM-Explore\u6846\u67b6\uff0c\u5305\u542b\u53c2\u6570\u7a7a\u95f4\u6a21\u578b\u878d\u5408\u3001\u5956\u52b1\u4fe1\u53f7\u53bb\u566a\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u7cbe\u70bc\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff0c\u89e3\u51b3SFT\u707e\u96be\u6027\u9057\u5fd8\u3001RL\u5956\u52b1\u4fe1\u53f7\u566a\u58f0\u548c\u957f\u4e0a\u4e0b\u6587\u5197\u4f59\u4fe1\u606f\u95ee\u9898\u3002", "result": "\u57284B\u89c4\u6a21\u6a21\u578b\u4e2d\u8fbe\u5230SOTA\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914d\u6216\u8d85\u8d8a8B SOTA\u6a21\u578b\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aClaude-4.5-Sonnet\u548cDeepSeek-v3.2\u7b49\u66f4\u5927\u6a21\u578b\uff0c\u5728GAIA\u6587\u672c\u4efb\u52a1\u4e0a\u8fbe\u523097.09%\u51c6\u786e\u7387\uff08pass@64\uff09\u3002", "conclusion": "\u8fb9\u7f18\u89c4\u6a21\u6a21\u578b\u7684\u74f6\u9888\u4e0d\u5728\u4e8e\u56fa\u6709\u80fd\u529b\u4e0a\u9650\uff0c\u800c\u5728\u4e8e\u63a8\u7406\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u7cfb\u7edf\u8bad\u7ec3\u6846\u67b6\uff0cAgentCPM-Explore\u6210\u529f\u89e3\u9501\u4e86\u8fb9\u7f18\u89c4\u6a21\u6a21\u578b\u88ab\u4f4e\u4f30\u7684\u6f5c\u529b\uff0c\u4e3a\u9ad8\u6548\u667a\u80fd\u4f53\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.06601", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06601", "abs": "https://arxiv.org/abs/2602.06601", "authors": ["Kaan Okumus", "Khac-Hoang Ngo", "Unnikrishnan Kunnath Ganesan", "Giuseppe Durisi", "Erik G. Str\u00f6m", "Shashi Raj Pandey"], "title": "Type-Based Unsourced Federated Learning With Client Self-Selection", "comment": "6 pages, 4 figures, accepted at the IEEE International Conference on Communications", "summary": "We address the client-selection problem in federated learning over wireless networks under data heterogeneity. Existing client-selection methods often rely on server-side knowledge of client-specific information, thus compromising privacy. To overcome this issue, we propose a client self-selection strategy based solely on the comparison between locally computed training losses and a centrally updated selection threshold. Furthermore, to support robust aggregation of clients' updates over wireless channels, we integrate this client self-selection strategy into the recently proposed type-based unsourced multiple-access framework over distributed multiple-input multiple-output (D-MIMO) networks. The resulting scheme is completely unsourced: the server does not need to know the identity of the clients. Moreover, no channel state information is required, neither at the clients nor at the server side. Simulation results conducted over a D-MIMO wireless network show that the proposed self-selection strategy matches the performance of a comparable state-of-the-art server-side selection method and consistently outperforms random client selection.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u672c\u5730\u8bad\u7ec3\u635f\u5931\u4e0e\u4e2d\u5fc3\u9608\u503c\u7684\u5ba2\u6237\u7aef\u81ea\u9009\u62e9\u7b56\u7565\uff0c\u7ed3\u5408\u65e0\u6e90\u591a\u5740\u63a5\u5165\u6846\u67b6\uff0c\u5b9e\u73b0\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u5ba2\u6237\u7aef\u9009\u62e9", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u670d\u52a1\u5668\u7aef\u638c\u63e1\u5ba2\u6237\u7aef\u7279\u5b9a\u4fe1\u606f\uff0c\u8fd9\u4f1a\u635f\u5bb3\u9690\u79c1\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u670d\u52a1\u5668\u7aef\u77e5\u8bc6\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u65b9\u6cd5", "method": "\u63d0\u51fa\u5ba2\u6237\u7aef\u81ea\u9009\u62e9\u7b56\u7565\uff1a\u5ba2\u6237\u7aef\u4ec5\u901a\u8fc7\u6bd4\u8f83\u672c\u5730\u8ba1\u7b97\u7684\u8bad\u7ec3\u635f\u5931\u4e0e\u4e2d\u5fc3\u66f4\u65b0\u7684\u9009\u62e9\u9608\u503c\u6765\u51b3\u5b9a\u662f\u5426\u53c2\u4e0e\u8bad\u7ec3\u3002\u5c06\u8be5\u7b56\u7565\u96c6\u6210\u5230\u57fa\u4e8e\u7c7b\u578b\u7684\u65e0\u6e90\u591a\u5740\u63a5\u5165\u6846\u67b6\u4e2d\uff0c\u5728\u5206\u5e03\u5f0fMIMO\u7f51\u7edc\u4e0a\u5b9e\u73b0\u9c81\u68d2\u805a\u5408", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u81ea\u9009\u62e9\u7b56\u7565\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u670d\u52a1\u5668\u7aef\u9009\u62e9\u65b9\u6cd5\u76f8\u5f53\uff0c\u5e76\u4e14\u59cb\u7ec8\u4f18\u4e8e\u968f\u673a\u5ba2\u6237\u7aef\u9009\u62e9", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5b8c\u5168\u65e0\u6e90\u7684\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u670d\u52a1\u5668\u65e0\u9700\u77e5\u9053\u5ba2\u6237\u7aef\u8eab\u4efd\uff0c\u4e14\u4e0d\u9700\u8981\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd"}}
{"id": "2602.06486", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06486", "abs": "https://arxiv.org/abs/2602.06486", "authors": ["Lanbo Lin", "Jiayao Liu", "Tianyuan Yang", "Li Cai", "Yuanwu Xu", "Lei Wei", "Sicong Xie", "Guannan Zhang"], "title": "JADE: Expert-Grounded Dynamic Evaluation for Open-Ended Professional Tasks", "comment": null, "summary": "Evaluating agentic AI on open-ended professional tasks faces a fundamental dilemma between rigor and flexibility. Static rubrics provide rigorous, reproducible assessment but fail to accommodate diverse valid response strategies, while LLM-as-a-judge approaches adapt to individual responses yet suffer from instability and bias. Human experts address this dilemma by combining domain-grounded principles with dynamic, claim-level assessment. Inspired by this process, we propose JADE, a two-layer evaluation framework. Layer 1 encodes expert knowledge as a predefined set of evaluation skills, providing stable evaluation criteria. Layer 2 performs report-specific, claim-level evaluation to flexibly assess diverse reasoning strategies, with evidence-dependency gating to invalidate conclusions built on refuted claims. Experiments on BizBench show that JADE improves evaluation stability and reveals critical agent failure modes missed by holistic LLM-based evaluators. We further demonstrate strong alignment with expert-authored rubrics and effective transfer to a medical-domain benchmark, validating JADE across professional domains. Our code is publicly available at https://github.com/smiling-world/JADE.", "AI": {"tldr": "JADE\u662f\u4e00\u4e2a\u4e24\u5c42\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u5b9a\u4e49\u8bc4\u4f30\u6280\u80fd\u548c\u62a5\u544a\u7279\u5b9a\u7684\u58f0\u660e\u7ea7\u8bc4\u4f30\uff0c\u89e3\u51b3\u4e86\u5f00\u653e\u4e13\u4e1a\u4efb\u52a1\u4e2d\u8bc4\u4f30\u7684\u4e25\u8c28\u6027\u4e0e\u7075\u6d3b\u6027\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "motivation": "\u8bc4\u4f30\u667a\u80fd\u4f53AI\u5728\u5f00\u653e\u5f0f\u4e13\u4e1a\u4efb\u52a1\u65f6\u9762\u4e34\u57fa\u672c\u56f0\u5883\uff1a\u9759\u6001\u8bc4\u4f30\u6807\u51c6\u867d\u7136\u4e25\u8c28\u53ef\u91cd\u590d\uff0c\u4f46\u65e0\u6cd5\u9002\u5e94\u591a\u6837\u5316\u7684\u6709\u6548\u54cd\u5e94\u7b56\u7565\uff1b\u800c\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u65b9\u6cd5\u867d\u7136\u80fd\u9002\u5e94\u4e2a\u4f53\u54cd\u5e94\uff0c\u4f46\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u548c\u504f\u89c1\u95ee\u9898\u3002", "method": "JADE\u91c7\u7528\u4e24\u5c42\u8bc4\u4f30\u6846\u67b6\uff1a\u7b2c\u4e00\u5c42\u5c06\u4e13\u5bb6\u77e5\u8bc6\u7f16\u7801\u4e3a\u9884\u5b9a\u4e49\u7684\u8bc4\u4f30\u6280\u80fd\uff0c\u63d0\u4f9b\u7a33\u5b9a\u7684\u8bc4\u4f30\u6807\u51c6\uff1b\u7b2c\u4e8c\u5c42\u8fdb\u884c\u62a5\u544a\u7279\u5b9a\u7684\u58f0\u660e\u7ea7\u8bc4\u4f30\uff0c\u7075\u6d3b\u8bc4\u4f30\u591a\u6837\u5316\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u8bc1\u636e\u4f9d\u8d56\u6027\u95e8\u63a7\u6765\u4f7f\u57fa\u4e8e\u88ab\u53cd\u9a73\u58f0\u660e\u7684\u7ed3\u8bba\u65e0\u6548\u3002", "result": "\u5728BizBench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJADE\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6574\u4f53\u6027LLM\u8bc4\u4f30\u5668\u9057\u6f0f\u7684\u5173\u952e\u667a\u80fd\u4f53\u5931\u8d25\u6a21\u5f0f\u3002\u540c\u65f6\u4e0e\u4e13\u5bb6\u5236\u5b9a\u7684\u8bc4\u4f30\u6807\u51c6\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u533b\u5b66\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "JADE\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u57fa\u7840\u539f\u5219\u548c\u52a8\u6001\u58f0\u660e\u7ea7\u8bc4\u4f30\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u4e13\u4e1a\u4efb\u52a1\u8bc4\u4f30\u4e2d\u7684\u4e25\u8c28\u6027\u4e0e\u7075\u6d3b\u6027\u77db\u76fe\uff0c\u5728\u4e0d\u540c\u4e13\u4e1a\u9886\u57df\u90fd\u8868\u73b0\u51fa\u826f\u597d\u7684\u9a8c\u8bc1\u6548\u679c\u3002"}}
{"id": "2602.06767", "categories": ["cs.IT", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.06767", "abs": "https://arxiv.org/abs/2602.06767", "authors": ["Pin-Han Ho", "Haoran Mei", "Limei Peng", "Yiming Miao", "Xu Fan", "Kairan Liang", "Tong Wei", "Wei Duan"], "title": "FaA-CAF: Modular Single-RF-Chain Near-Field mmWave Sensing via Clip-On Antenna Fabric", "comment": null, "summary": "Near field mmWave sensing is poised to play a key role in future wireless systems, enabling environment-aware, embodied, and application adaptive operation under stringent form-factor and hardware constraints. However, achieving high spatial resolution in the near field typically requires large antenna arrays, multiple radio frequency (RF) chains, or mechanical scanning, creating a fundamental tension between spatial observability and system simplicity. This paper presents frequency as aperture clip on antenna fabric (FaACAF), a hardware efficient sensing by design architecture that synthesizes spatial aperture through the FaA paradigm using a single RF chain. FaACAF realizes a modular clip on aperture fabric, in which frequency selective clip on modules (CMs) are attached to a shared guided-wave substrate and implicitly coordinated by the instantaneous frequency modulated continuous wave (FMCW) excitation frequency. In this fabric, FMCW signaling simultaneously indexes the sensing aperture and orchestrates uplink/downlink signal distribution and echo multiplexing in a switch free, fully passive, and all analog manner, eliminating RF switching and multichannel front ends. An online self calibration mechanism stabilizes the frequency to aperture mapping under practical attachment variability without requiring full matrix calibration. Two case studies illustrate the robustness of the proposed approach and quantify the predictable sensing margin tradeoffs introduced by modular deployment. Overall, FaACAF demonstrates that near field spatial observability can be scaled through architectural coordination in the frequency domain rather than hardware expansion, providing a reconfigurable and hardware efficient pathway toward embodied sensing and integrated sensing and communication (ISAC) in future wireless systems.", "AI": {"tldr": "FaACAF\u662f\u4e00\u79cd\u786c\u4ef6\u9ad8\u6548\u611f\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u9891\u7387\u9009\u62e9\u6a21\u5757\u5728\u5171\u4eab\u6ce2\u5bfc\u4e0a\u5408\u6210\u7a7a\u95f4\u5b54\u5f84\uff0c\u4f7f\u7528\u5355\u5c04\u9891\u94fe\u5b9e\u73b0\u8fd1\u573a\u6beb\u7c73\u6ce2\u611f\u77e5\uff0c\u65e0\u9700\u5c04\u9891\u5f00\u5173\u548c\u591a\u901a\u9053\u524d\u7aef\u3002", "motivation": "\u8fd1\u573a\u6beb\u7c73\u6ce2\u611f\u77e5\u5bf9\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u578b\u5929\u7ebf\u9635\u5217\u3001\u591a\u5c04\u9891\u94fe\u6216\u673a\u68b0\u626b\u63cf\uff0c\u5bfc\u81f4\u7a7a\u95f4\u53ef\u89c2\u6d4b\u6027\u4e0e\u7cfb\u7edf\u7b80\u5355\u6027\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u77db\u76fe\u3002", "method": "\u63d0\u51faFaACAF\u67b6\u6784\uff0c\u91c7\u7528\u9891\u7387\u4f5c\u4e3a\u5b54\u5f84\u8303\u5f0f\uff0c\u5728\u5171\u4eab\u6ce2\u5bfc\u57fa\u677f\u4e0a\u9644\u52a0\u9891\u7387\u9009\u62e9\u6a21\u5757\uff0c\u901a\u8fc7FMCW\u4fe1\u53f7\u540c\u65f6\u7d22\u5f15\u611f\u77e5\u5b54\u5f84\u5e76\u534f\u8c03\u4e0a\u4e0b\u884c\u4fe1\u53f7\u5206\u5e03\u548c\u56de\u6ce2\u590d\u7528\uff0c\u5b9e\u73b0\u5168\u88ab\u52a8\u3001\u5168\u6a21\u62df\u7684\u65e0\u5f00\u5173\u64cd\u4f5c\u3002", "result": "\u5b9e\u73b0\u4e86\u5728\u7ebf\u81ea\u6821\u51c6\u673a\u5236\u7a33\u5b9a\u9891\u7387\u5230\u5b54\u5f84\u6620\u5c04\uff0c\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u5e76\u91cf\u5316\u4e86\u6a21\u5757\u5316\u90e8\u7f72\u5e26\u6765\u7684\u53ef\u9884\u6d4b\u611f\u77e5\u88d5\u5ea6\u6743\u8861\u3002", "conclusion": "FaACAF\u8bc1\u660e\u8fd1\u573a\u7a7a\u95f4\u53ef\u89c2\u6d4b\u6027\u53ef\u4ee5\u901a\u8fc7\u9891\u57df\u67b6\u6784\u534f\u8c03\u800c\u975e\u786c\u4ef6\u6269\u5c55\u6765\u6269\u5c55\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u5177\u8eab\u611f\u77e5\u548c\u96c6\u6210\u611f\u77e5\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u91cd\u6784\u4e14\u786c\u4ef6\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2602.06525", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06525", "abs": "https://arxiv.org/abs/2602.06525", "authors": ["Finn Rietz", "Mart Karta\u0161ev", "Johannes A. Stork", "Petter \u00d6gren"], "title": "Progress Constraints for Reinforcement Learning in Behavior Trees", "comment": null, "summary": "Behavior Trees (BTs) provide a structured and reactive framework for decision-making, commonly used to switch between sub-controllers based on environmental conditions. Reinforcement Learning (RL), on the other hand, can learn near-optimal controllers but sometimes struggles with sparse rewards, safe exploration, and long-horizon credit assignment. Combining BTs with RL has the potential for mutual benefit: a BT design encodes structured domain knowledge that can simplify RL training, while RL enables automatic learning of the controllers within BTs. However, naive integration of BTs and RL can lead to some controllers counteracting other controllers, possibly undoing previously achieved subgoals, thereby degrading the overall performance. To address this, we propose progress constraints, a novel mechanism where feasibility estimators constrain the allowed action set based on theoretical BT convergence results. Empirical evaluations in a 2D proof-of-concept and a high-fidelity warehouse environment demonstrate improved performance, sample efficiency, and constraint satisfaction, compared to prior methods of BT-RL integration.", "AI": {"tldr": "\u63d0\u51fa\u8fdb\u5ea6\u7ea6\u675f\u673a\u5236\uff0c\u5c06\u884c\u4e3a\u6811\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u901a\u8fc7\u53ef\u884c\u6027\u4f30\u8ba1\u5668\u9650\u5236\u52a8\u4f5c\u96c6\uff0c\u9632\u6b62\u5b50\u63a7\u5236\u5668\u76f8\u4e92\u62b5\u6d88\uff0c\u63d0\u5347\u6574\u4f53\u6027\u80fd", "motivation": "\u884c\u4e3a\u6811\uff08BTs\uff09\u63d0\u4f9b\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u80fd\u5b66\u4e60\u6700\u4f18\u63a7\u5236\u5668\u4f46\u9762\u4e34\u7a00\u758f\u5956\u52b1\u3001\u5b89\u5168\u63a2\u7d22\u548c\u957f\u671f\u4fe1\u7528\u5206\u914d\u95ee\u9898\u3002\u4e24\u8005\u7ed3\u5408\u6709\u6f5c\u529b\u76f8\u4e92\u8865\u5145\uff1aBT\u7f16\u7801\u9886\u57df\u77e5\u8bc6\u7b80\u5316RL\u8bad\u7ec3\uff0cRL\u81ea\u52a8\u5b66\u4e60BT\u5185\u63a7\u5236\u5668\u3002\u4f46\u7b80\u5355\u7ed3\u5408\u53ef\u80fd\u5bfc\u81f4\u63a7\u5236\u5668\u76f8\u4e92\u62b5\u6d88\uff0c\u7834\u574f\u5df2\u5b9e\u73b0\u5b50\u76ee\u6807\uff0c\u964d\u4f4e\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u8fdb\u5ea6\u7ea6\u675f\u673a\u5236\uff0c\u57fa\u4e8e\u884c\u4e3a\u6811\u6536\u655b\u7406\u8bba\u7ed3\u679c\uff0c\u4f7f\u7528\u53ef\u884c\u6027\u4f30\u8ba1\u5668\u9650\u5236\u5141\u8bb8\u7684\u52a8\u4f5c\u96c6\uff0c\u9632\u6b62\u63a7\u5236\u5668\u76f8\u4e92\u62b5\u6d88\uff0c\u786e\u4fdd\u5b66\u4e60\u8fc7\u7a0b\u4fdd\u6301\u5df2\u53d6\u5f97\u7684\u8fdb\u5c55\u3002", "result": "\u57282D\u6982\u5ff5\u9a8c\u8bc1\u548c\u9ad8\u4fdd\u771f\u4ed3\u5e93\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5148\u524d\u7684BT-RL\u96c6\u6210\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u3001\u6837\u672c\u6548\u7387\u548c\u7ea6\u675f\u6ee1\u8db3\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8fdb\u5ea6\u7ea6\u675f\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u884c\u4e3a\u6811\u4e0e\u5f3a\u5316\u5b66\u4e60\u96c6\u6210\u4e2d\u7684\u63a7\u5236\u5668\u51b2\u7a81\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u7684\u53ef\u884c\u6027\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3001\u6837\u672c\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u4e3aBT-RL\u96c6\u6210\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6846\u67b6\u3002"}}
{"id": "2602.06527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06527", "abs": "https://arxiv.org/abs/2602.06527", "authors": ["Shengxuan Qiu", "Haochen Huang", "Shuzhang Zhong", "Pengfei Zuo", "Meng Li"], "title": "HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction", "comment": null, "summary": "Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansion rules that interfere with post-trained reasoning, while parallel reasoning over-explores redundant hypothesis paths and relies on weak answer selection. Motivated by the observation that the optimal balance is phase-dependent and that correct and incorrect reasoning paths often diverge only at late stages, we reformulate test-time scaling as a dynamic expand-reduce control problem over a pool of hypotheses. We propose HyPER, a training-free online control policy for multi-path decoding in mixture-of-experts models that reallocates computation under a fixed budget using lightweight path statistics. HyPER consists of an online controller that transitions from exploration to exploitation as the hypothesis pool evolves, a token-level refinement mechanism that enables efficient generation-time exploitation without full-path resampling, and a length- and confidence-aware aggregation strategy for reliable answer-time exploitation. Experiments on four mixture-of-experts language models across diverse reasoning benchmarks show that HyPER consistently achieves a superior accuracy-compute trade-off, improving accuracy by 8 to 10 percent while reducing token usage by 25 to 40 percent.", "AI": {"tldr": "HyPER\u662f\u4e00\u79cd\u7528\u4e8e\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u7684\u591a\u8def\u5f84\u89e3\u7801\u8bad\u7ec3\u514d\u8d39\u5728\u7ebf\u63a7\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u52a8\u6001\u6269\u5c55-\u7f29\u51cf\u63a7\u5236\u91cd\u65b0\u5206\u914d\u8ba1\u7b97\u9884\u7b97\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u65b9\u6cd5\u5728\u63a2\u7d22-\u5229\u7528\u6743\u8861\u4e0a\u5b58\u5728\u5c40\u9650\uff1a\u6811\u72b6\u641c\u7d22\u901a\u8fc7\u8106\u5f31\u7684\u6269\u5c55\u89c4\u5219\u786c\u7f16\u7801\u63a2\u7d22\uff0c\u5e72\u6270\u540e\u8bad\u7ec3\u63a8\u7406\uff1b\u5e76\u884c\u63a8\u7406\u5219\u8fc7\u5ea6\u63a2\u7d22\u5197\u4f59\u5047\u8bbe\u8def\u5f84\u4e14\u4f9d\u8d56\u5f31\u7b54\u6848\u9009\u62e9\u3002\u7814\u7a76\u53d1\u73b0\u6700\u4f18\u5e73\u8861\u662f\u9636\u6bb5\u4f9d\u8d56\u7684\uff0c\u6b63\u786e\u4e0e\u9519\u8bef\u63a8\u7406\u8def\u5f84\u5f80\u5f80\u5728\u540e\u671f\u624d\u5206\u53c9\u3002", "method": "\u5c06\u6d4b\u8bd5\u65f6\u6269\u5c55\u91cd\u65b0\u8868\u8ff0\u4e3a\u5047\u8bbe\u6c60\u4e0a\u7684\u52a8\u6001\u6269\u5c55-\u7f29\u51cf\u63a7\u5236\u95ee\u9898\u3002\u63d0\u51faHyPER\uff1a1) \u5728\u7ebf\u63a7\u5236\u5668\u6839\u636e\u5047\u8bbe\u6c60\u6f14\u5316\u4ece\u63a2\u7d22\u8f6c\u5411\u5229\u7528\uff1b2) \u4ee4\u724c\u7ea7\u7ec6\u5316\u673a\u5236\u5b9e\u73b0\u65e0\u9700\u5b8c\u6574\u8def\u5f84\u91cd\u91c7\u6837\u7684\u751f\u6210\u65f6\u9ad8\u6548\u5229\u7528\uff1b3) \u957f\u5ea6\u548c\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u805a\u5408\u7b56\u7565\u5b9e\u73b0\u53ef\u9760\u7684\u7b54\u6848\u65f6\u5229\u7528\u3002", "result": "\u5728\u56db\u4e2a\u4e13\u5bb6\u6df7\u5408\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6837\u5316\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyPER\u59cb\u7ec8\u5b9e\u73b0\u66f4\u4f18\u7684\u51c6\u786e\u7387-\u8ba1\u7b97\u6743\u8861\uff0c\u51c6\u786e\u7387\u63d0\u9ad88-10%\uff0c\u540c\u65f6\u4ee4\u724c\u4f7f\u7528\u91cf\u51cf\u5c1125-40%\u3002", "conclusion": "HyPER\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u91cd\u65b0\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e3a\u591a\u8def\u5f84\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2602.06533", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06533", "abs": "https://arxiv.org/abs/2602.06533", "authors": ["Brian Rabern", "Philipp Mondorf", "Barbara Plank"], "title": "LogicSkills: A Structured Benchmark for Formal Reasoning in Large Language Models", "comment": "13 pages, 5 figures", "summary": "Large language models have demonstrated notable performance across various logical reasoning benchmarks. However, it remains unclear which core logical skills they truly master. To address this, we introduce LogicSkills, a unified benchmark designed to isolate three fundamental skills in formal reasoning: (i) $\\textit{formal symbolization}\\unicode{x2014}$translating premises into first-order logic; (ii) $\\textit{countermodel construction}\\unicode{x2014}$formulating a finite structure in which all premises are true while the conclusion is false; and (iii) $\\textit{validity assessment}\\unicode{x2014}$deciding whether a conclusion follows from a given set of premises. Items are drawn from the two-variable fragment of first-order logic (without identity) and are presented in both natural English and a Carroll-style language with nonce words. All examples are verified for correctness and non-triviality using the SMT solver Z3. Across leading models, performance is high on validity but substantially lower on symbolization and countermodel construction, suggesting reliance on surface-level patterns rather than genuine symbolic or rule-based reasoning.", "AI": {"tldr": "LogicSkills\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u63a8\u7406\u4e2d\u7684\u4e09\u9879\u6838\u5fc3\u6280\u80fd\uff1a\u5f62\u5f0f\u7b26\u53f7\u5316\u3001\u53cd\u6a21\u578b\u6784\u5efa\u548c\u6709\u6548\u6027\u8bc4\u4f30\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u6709\u6548\u6027\u8bc4\u4f30\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7b26\u53f7\u5316\u548c\u53cd\u6a21\u578b\u6784\u5efa\u4e0a\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5b83\u4eec\u771f\u6b63\u638c\u63e1\u4e86\u54ea\u4e9b\u6838\u5fc3\u903b\u8f91\u6280\u80fd\u3002\u4e3a\u4e86\u63a2\u7a76\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u9694\u79bb\u548c\u8bc4\u4f30\u5f62\u5f0f\u63a8\u7406\u4e2d\u7684\u57fa\u672c\u6280\u80fd\u3002", "method": "\u5f15\u5165LogicSkills\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u4e09\u9879\u6838\u5fc3\u903b\u8f91\u6280\u80fd\uff1a1) \u5f62\u5f0f\u7b26\u53f7\u5316\uff08\u5c06\u524d\u63d0\u7ffb\u8bd1\u4e3a\u4e00\u9636\u903b\u8f91\uff09\uff1b2) \u53cd\u6a21\u578b\u6784\u5efa\uff08\u6784\u5efa\u4e00\u4e2a\u6709\u9650\u7ed3\u6784\uff0c\u4f7f\u6240\u6709\u524d\u63d0\u4e3a\u771f\u800c\u7ed3\u8bba\u4e3a\u5047\uff09\uff1b3) \u6709\u6548\u6027\u8bc4\u4f30\uff08\u5224\u65ad\u7ed3\u8bba\u662f\u5426\u4ece\u7ed9\u5b9a\u524d\u63d0\u4e2d\u5f97\u51fa\uff09\u3002\u6d4b\u8bd5\u9879\u76ee\u6765\u81ea\u4e0d\u5e26\u6052\u7b49\u5f0f\u7684\u4e24\u53d8\u91cf\u4e00\u9636\u903b\u8f91\u7247\u6bb5\uff0c\u4ee5\u81ea\u7136\u82f1\u8bed\u548cCarroll\u98ce\u683c\u7684\u975e\u8bcd\u8bed\u8a00\u5448\u73b0\uff0c\u5e76\u4f7f\u7528SMT\u6c42\u89e3\u5668Z3\u9a8c\u8bc1\u6b63\u786e\u6027\u548c\u975e\u5e73\u51e1\u6027\u3002", "result": "\u5728\u9886\u5148\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u6709\u6548\u6027\u8bc4\u4f30\u7684\u8868\u73b0\u8f83\u9ad8\uff0c\u4f46\u5f62\u5f0f\u7b26\u53f7\u5316\u548c\u53cd\u6a21\u578b\u6784\u5efa\u7684\u8868\u73b0\u663e\u8457\u8f83\u4f4e\u3002\u8fd9\u8868\u660e\u6a21\u578b\u53ef\u80fd\u4f9d\u8d56\u8868\u9762\u6a21\u5f0f\u800c\u975e\u771f\u6b63\u7684\u7b26\u53f7\u6216\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u66f4\u64c5\u957f\u6a21\u5f0f\u5339\u914d\u5f0f\u7684\u6709\u6548\u6027\u5224\u65ad\uff0c\u4f46\u5728\u9700\u8981\u6df1\u5165\u7b26\u53f7\u5904\u7406\u548c\u53cd\u4f8b\u6784\u5efa\u7684\u63a8\u7406\u4efb\u52a1\u4e0a\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u903b\u8f91\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.06540", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06540", "abs": "https://arxiv.org/abs/2602.06540", "authors": ["Yishan Li", "Wentong Chen", "Yukun Yan", "Mingwei Li", "Sen Mei", "Xiaorong Wang", "Kunpeng Liu", "Xin Cong", "Shuo Wang", "Zhong Zhang", "Yaxi Lu", "Zhenghao Liu", "Yankai Lin", "Zhiyuan Liu", "Maosong Sun"], "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research", "comment": null, "summary": "Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose performance heavily depends on the quality of the initial outline. However, constructing a comprehensive outline itself demands strong reasoning ability, causing current deep research systems to rely almost exclusively on closed-source or online large models. This reliance raises practical barriers to deployment and introduces safety and privacy concerns for user-authored data. In this work, we present AgentCPM-Report, a lightweight yet high-performing local solution composed of a framework that mirrors the human writing process and an 8B-parameter deep research agent. Our framework uses a Writing As Reasoning Policy (WARP), which enables models to dynamically revise outlines during report generation. Under this policy, the agent alternates between Evidence-Based Drafting and Reasoning-Driven Deepening, jointly supporting information acquisition, knowledge refinement, and iterative outline evolution. To effectively equip small models with this capability, we introduce a Multi-Stage Agentic Training strategy, consisting of cold-start, atomic skill RL, and holistic pipeline RL. Experiments on DeepResearch Bench, DeepConsult, and DeepResearch Gym demonstrate that AgentCPM-Report outperforms leading closed-source systems, with substantial gains in Insight.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentCPM-Report\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u9ad8\u6027\u80fd\u7684\u672c\u5730\u6df1\u5ea6\u7814\u7a76\u62a5\u544a\u751f\u6210\u7cfb\u7edf\uff0c\u91c7\u75288B\u53c2\u6570\u6a21\u578b\u548c\u4eff\u4eba\u7c7b\u5199\u4f5c\u8fc7\u7a0b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5927\u7eb2\u4fee\u8ba2\u548c\u4ea4\u66ff\u7684\u8bc1\u636e\u8d77\u8349\u4e0e\u63a8\u7406\u6df1\u5316\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u95ed\u6e90\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u62a5\u544a\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u8ba1\u5212-\u5199\u4f5c\u8303\u5f0f\uff0c\u5176\u6027\u80fd\u4e25\u91cd\u4f9d\u8d56\u521d\u59cb\u5927\u7eb2\u8d28\u91cf\uff0c\u800c\u6784\u5efa\u5168\u9762\u5927\u7eb2\u9700\u8981\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u5f53\u524d\u7cfb\u7edf\u51e0\u4e4e\u5b8c\u5168\u4f9d\u8d56\u95ed\u6e90\u6216\u5728\u7ebf\u5927\u6a21\u578b\uff0c\u8fd9\u5e26\u6765\u4e86\u90e8\u7f72\u969c\u788d\u4ee5\u53ca\u7528\u6237\u6570\u636e\u7684\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86AgentCPM-Report\u7cfb\u7edf\uff0c\u5305\u542b\uff1a1\uff09\u4eff\u4eba\u7c7b\u5199\u4f5c\u8fc7\u7a0b\u7684\u6846\u67b6\uff0c\u91c7\u7528\u5199\u4f5c\u5373\u63a8\u7406\u7b56\u7565\uff08WARP\uff09\uff0c\u5141\u8bb8\u5728\u62a5\u544a\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u4fee\u8ba2\u5927\u7eb2\uff1b2\uff098B\u53c2\u6570\u7684\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\uff0c\u4ea4\u66ff\u8fdb\u884c\u8bc1\u636e\u8d77\u8349\u548c\u63a8\u7406\u6df1\u5316\uff1b3\uff09\u591a\u9636\u6bb5\u667a\u80fd\u4f53\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u62ec\u51b7\u542f\u52a8\u3001\u539f\u5b50\u6280\u80fd\u5f3a\u5316\u5b66\u4e60\u548c\u6574\u4f53\u7ba1\u9053\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728DeepResearch Bench\u3001DeepConsult\u548cDeepResearch Gym\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentCPM-Report\u4f18\u4e8e\u9886\u5148\u7684\u95ed\u6e90\u7cfb\u7edf\uff0c\u5728Insight\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "AgentCPM-Report\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6027\u80fd\u7684\u672c\u5730\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5199\u4f5c\u5373\u63a8\u7406\u7b56\u7565\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6df1\u5ea6\u7814\u7a76\u62a5\u544a\uff0c\u89e3\u51b3\u4e86\u5bf9\u95ed\u6e90\u5927\u6a21\u578b\u7684\u4f9d\u8d56\u95ee\u9898\u3002"}}
{"id": "2602.06554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06554", "abs": "https://arxiv.org/abs/2602.06554", "authors": ["Tianyi Hu", "Qingxu Fu", "Yanxi Chen", "Zhaoyang Liu", "Bolin Ding"], "title": "SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees", "comment": null, "summary": "Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.\n  In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.\n  To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.\n  Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.", "AI": {"tldr": "\u63d0\u51faSeeUPO\u7b97\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709RL\u7b97\u6cd5\u5728\u591a\u8f6e\u4ea4\u4e92\u573a\u666f\u4e2d\u7f3a\u4e4f\u6536\u655b\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5e8f\u5217\u7ea7\u987a\u5e8f\u66f4\u65b0\u7b56\u7565\u4f18\u5316\u5b9e\u73b0\u5355\u8c03\u6539\u8fdb\u548c\u5168\u5c40\u6700\u4f18\u6536\u655b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u667a\u80fd\u4f53\u4e3b\u8981\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u4f46\u4e3b\u6d41RL\u7b97\u6cd5\u5728\u591a\u8f6e\u4ea4\u4e92\u573a\u666f\u4e2d\u7f3a\u4e4f\u9a8c\u8bc1\u7684\u6536\u655b\u4fdd\u8bc1\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u65e0\u6cd5\u6536\u655b\u5230\u6700\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51faSeeUPO\u7b97\u6cd5\uff1a\u5c06\u591a\u8f6e\u4ea4\u4e92\u5efa\u6a21\u4e3a\u987a\u5e8f\u6267\u884c\u7684\u591a\u667a\u80fd\u4f53\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u91c7\u7528\u53cd\u5411\u6267\u884c\u987a\u5e8f\u7684\u9010\u8f6e\u987a\u5e8f\u7b56\u7565\u66f4\u65b0\uff0c\u901a\u8fc7\u9006\u5411\u5f52\u7eb3\u786e\u4fdd\u5355\u8c03\u6539\u8fdb\u548c\u5168\u5c40\u6700\u4f18\u6536\u655b\u3002", "result": "\u5728AppWorld\u548cBFCL v4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSeeUPO\u76f8\u6bd4\u73b0\u6709\u9aa8\u5e72\u7b97\u6cd5\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1aQwen3-14B\u4e0a\u76f8\u5bf9\u589e\u76ca43.3%-54.6%\uff0cQwen2.5-14B\u4e0a24.1%-41.9%\uff0c\u4e14\u8bad\u7ec3\u7a33\u5b9a\u6027\u66f4\u4f18\u3002", "conclusion": "SeeUPO\u89e3\u51b3\u4e86\u591a\u8f6e\u4ea4\u4e92\u573a\u666f\u4e2dRL\u7b97\u6cd5\u7684\u6536\u655b\u4fdd\u8bc1\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u8bc4\u8bba\u5bb6\u4e14\u5177\u6709\u6536\u655b\u4fdd\u8bc1\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.06652", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.06652", "abs": "https://arxiv.org/abs/2602.06652", "authors": ["Farooq Ahmad Wani", "Alessandro Suglia", "Rohit Saxena", "Aryo Pradipta Gema", "Wai-Chung Kwan", "Fazl Barez", "Maria Sofia Bucarelli", "Fabrizio Silvestri", "Pasquale Minervini"], "title": "Same Answer, Different Representations: Hidden instability in VLMs", "comment": null, "summary": "The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions reflect stable multimodal processing. In this work, we argue that this assumption is insufficient. We introduce a representation-aware and frequency-aware evaluation framework that measures internal embedding drift, spectral sensitivity, and structural smoothness (spatial consistency of vision tokens), alongside standard label-based metrics. Applying this framework to modern VLMs across the SEEDBench, MMMU, and POPE datasets reveals three distinct failure modes. First, models frequently preserve predicted answers while undergoing substantial internal representation drift; for perturbations such as text overlays, this drift approaches the magnitude of inter-image variability, indicating that representations move to regions typically occupied by unrelated inputs despite unchanged outputs. Second, robustness does not improve with scale; larger models achieve higher accuracy but exhibit equal or greater sensitivity, consistent with sharper yet more fragile decision boundaries. Third, we find that perturbations affect tasks differently: they harm reasoning when they disrupt how models combine coarse and fine visual cues, but on the hallucination benchmarks, they can reduce false positives by making models generate more conservative answers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u8868\u793a\u611f\u77e5\u548c\u9891\u7387\u611f\u77e5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0VLMs\u5728\u4fdd\u6301\u9884\u6d4b\u4e0d\u53d8\u65f6\u5185\u90e8\u8868\u793a\u4f1a\u53d1\u751f\u663e\u8457\u6f02\u79fb\uff0c\u6a21\u578b\u89c4\u6a21\u589e\u5927\u4e0d\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u6270\u52a8\u5bf9\u4e0d\u540c\u4efb\u52a1\u6709\u4e0d\u540c\u5f71\u54cd\u3002", "motivation": "\u5f53\u524dVLMs\u9c81\u68d2\u6027\u8bc4\u4f30\u4e3b\u8981\u57fa\u4e8e\u8f93\u51fa\u5c42\u9762\u7684\u4e0d\u53d8\u6027\uff0c\u9690\u542b\u5047\u8bbe\u7a33\u5b9a\u9884\u6d4b\u53cd\u6620\u7a33\u5b9a\u7684\u591a\u6a21\u6001\u5904\u7406\u3002\u672c\u6587\u8ba4\u4e3a\u8fd9\u4e00\u5047\u8bbe\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u6df1\u5165\u8bc4\u4f30\u5185\u90e8\u8868\u793a\u7684\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u8868\u793a\u611f\u77e5\u548c\u9891\u7387\u611f\u77e5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u91cf\u5185\u90e8\u5d4c\u5165\u6f02\u79fb\u3001\u9891\u8c31\u654f\u611f\u6027\u548c\u7ed3\u6784\u5e73\u6ed1\u6027\uff08\u89c6\u89c9token\u7684\u7a7a\u95f4\u4e00\u81f4\u6027\uff09\uff0c\u7ed3\u5408\u6807\u51c6\u6807\u7b7e\u6307\u6807\u3002\u5728SEEDBench\u3001MMMU\u548cPOPE\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u73b0\u4ee3VLMs\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u5931\u6548\u6a21\u5f0f\uff1a1) \u6a21\u578b\u4fdd\u6301\u9884\u6d4b\u7b54\u6848\u65f6\u5185\u90e8\u8868\u793a\u53d1\u751f\u663e\u8457\u6f02\u79fb\uff1b2) \u6a21\u578b\u89c4\u6a21\u589e\u5927\u4e0d\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u66f4\u5927\u6a21\u578b\u66f4\u654f\u611f\uff1b3) \u6270\u52a8\u5bf9\u4e0d\u540c\u4efb\u52a1\u5f71\u54cd\u4e0d\u540c\uff1a\u635f\u5bb3\u63a8\u7406\u4f46\u51cf\u5c11\u5e7b\u89c9\u8bef\u62a5\u3002", "conclusion": "\u4ec5\u4f9d\u8d56\u8f93\u51fa\u4e0d\u53d8\u6027\u8bc4\u4f30VLMs\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u7ed3\u5408\u5185\u90e8\u8868\u793a\u5206\u6790\u3002\u6a21\u578b\u89c4\u6a21\u589e\u5927\u4e0d\u5fc5\u7136\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u6270\u52a8\u5bf9\u4e0d\u540c\u4efb\u52a1\u6709\u590d\u6742\u5f71\u54cd\uff0c\u4e3aVLMs\u9c81\u68d2\u6027\u8bc4\u4f30\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.06707", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06707", "abs": "https://arxiv.org/abs/2602.06707", "authors": ["Thiviyan Thanapalasingam", "Antonis Vozikis", "Peter Bloem", "Paul Groth"], "title": "Autoregressive Models for Knowledge Graph Generation", "comment": null, "summary": "Knowledge Graph (KG) generation requires models to learn complex semantic dependencies between triples while maintaining domain validity constraints. Unlike link prediction, which scores triples independently, generative models must capture interdependencies across entire subgraphs to produce semantically coherent structures. We present ARK (Auto-Regressive Knowledge Graph Generation), a family of autoregressive models that generate KGs by treating graphs as sequences of (head, relation, tail) triples. ARK learns implicit semantic constraints directly from data, including type consistency, temporal validity, and relational patterns, without explicit rule supervision. On the IntelliGraphs benchmark, our models achieve 89.2% to 100.0% semantic validity across diverse datasets while generating novel graphs not seen during training. We also introduce SAIL, a variational extension of ARK that enables controlled generation through learned latent representations, supporting both unconditional sampling and conditional completion from partial graphs. Our analysis reveals that model capacity (hidden dimensionality >= 64) is more critical than architectural depth for KG generation, with recurrent architectures achieving comparable validity to transformer-based alternatives while offering substantial computational efficiency. These results demonstrate that autoregressive models provide an effective framework for KG generation, with practical applications in knowledge base completion and query answering.", "AI": {"tldr": "ARK\u662f\u4e00\u79cd\u81ea\u56de\u5f52\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u6a21\u578b\uff0c\u5c06\u56fe\u8c31\u89c6\u4e3a\u4e09\u5143\u7ec4\u5e8f\u5217\uff0c\u65e0\u9700\u663e\u5f0f\u89c4\u5219\u76d1\u7763\u5373\u53ef\u5b66\u4e60\u8bed\u4e49\u7ea6\u675f\uff0c\u5728IntelliGraphs\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523089.2%-100%\u8bed\u4e49\u6709\u6548\u6027\uff0c\u5e76\u80fd\u751f\u6210\u672a\u89c1\u8fc7\u7684\u56fe\u8c31\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u9700\u8981\u6a21\u578b\u5b66\u4e60\u4e09\u5143\u7ec4\u95f4\u7684\u590d\u6742\u8bed\u4e49\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u6301\u9886\u57df\u6709\u6548\u6027\u7ea6\u675f\u3002\u4e0e\u72ec\u7acb\u8bc4\u5206\u4e09\u5143\u7ec4\u7684\u94fe\u63a5\u9884\u6d4b\u4e0d\u540c\uff0c\u751f\u6210\u6a21\u578b\u5fc5\u987b\u6355\u6349\u6574\u4e2a\u5b50\u56fe\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u4ee5\u4ea7\u751f\u8bed\u4e49\u8fde\u8d2f\u7684\u7ed3\u6784\u3002", "method": "\u63d0\u51faARK\uff08\u81ea\u56de\u5f52\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\uff09\u6a21\u578b\u5bb6\u65cf\uff0c\u5c06\u56fe\u8c31\u89c6\u4e3a(head, relation, tail)\u4e09\u5143\u7ec4\u5e8f\u5217\u8fdb\u884c\u81ea\u56de\u5f52\u751f\u6210\u3002\u6a21\u578b\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u9690\u5f0f\u8bed\u4e49\u7ea6\u675f\uff08\u7c7b\u578b\u4e00\u81f4\u6027\u3001\u65f6\u95f4\u6709\u6548\u6027\u3001\u5173\u7cfb\u6a21\u5f0f\uff09\uff0c\u65e0\u9700\u663e\u5f0f\u89c4\u5219\u76d1\u7763\u3002\u8fd8\u63d0\u51faSAIL\uff0cARK\u7684\u53d8\u5206\u6269\u5c55\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u6f5c\u5728\u8868\u793a\u5b9e\u73b0\u53ef\u63a7\u751f\u6210\u3002", "result": "\u5728IntelliGraphs\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u8fbe\u523089.2%\u5230100.0%\u7684\u8bed\u4e49\u6709\u6548\u6027\uff0c\u540c\u65f6\u80fd\u751f\u6210\u8bad\u7ec3\u4e2d\u672a\u89c1\u7684\u65b0\u56fe\u8c31\u3002\u5206\u6790\u663e\u793a\u6a21\u578b\u5bb9\u91cf\uff08\u9690\u85cf\u7ef4\u5ea6\u226564\uff09\u6bd4\u67b6\u6784\u6df1\u5ea6\u66f4\u91cd\u8981\uff0c\u5faa\u73af\u67b6\u6784\u5728\u8fbe\u5230\u4e0e\u57fa\u4e8eTransformer\u7684\u66ff\u4ee3\u65b9\u6848\u76f8\u5f53\u6709\u6548\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u663e\u8457\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u81ea\u56de\u5f52\u6a21\u578b\u4e3a\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u5728\u77e5\u8bc6\u5e93\u8865\u5168\u548c\u67e5\u8be2\u56de\u7b54\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.06746", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06746", "abs": "https://arxiv.org/abs/2602.06746", "authors": ["Alessandro Abate", "Giuseppe De Giacomo", "Mathias Jackermeier", "Jan Kret\u00ednsk\u00fd", "Maximilian Prokop", "Christoph Weinhuber"], "title": "Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions", "comment": null, "summary": "We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are commonly used in formal methods to specify properties of systems, and have recently been successfully adopted in RL. In this setting, we present a novel task embedding technique leveraging a new generation of semantic LTL-to-automata translations, originally developed for temporal synthesis. The resulting semantically labelled automata contain rich, structured information in each state that allow us to (i) compute the automaton efficiently on-the-fly, (ii) extract expressive task embeddings used to condition the policy, and (iii) naturally support full LTL. Experimental results in a variety of domains demonstrate that our approach achieves state-of-the-art performance and is able to scale to complex specifications where existing methods fail.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49LTL\u5230\u81ea\u52a8\u673a\u8f6c\u6362\u7684\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u7ed3\u6784\u5316\u4efb\u52a1\u5d4c\u5165\u63d0\u5347\u7b56\u7565\u6cdb\u5316\u80fd\u529b", "motivation": "\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u9700\u8981\u5b66\u4e60\u4e00\u4e2a\u80fd\u591f\u6cdb\u5316\u5230\u4efb\u610f\uff08\u53ef\u80fd\u672a\u89c1\uff09\u4efb\u52a1\u7684\u901a\u7528\u7b56\u7565\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742LTL\u89c4\u8303\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4efb\u52a1\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u65b0\u4e00\u4ee3\u8bed\u4e49LTL\u5230\u81ea\u52a8\u673a\u8f6c\u6362\u6280\u672f\uff0c\u6784\u5efa\u8bed\u4e49\u6807\u8bb0\u7684\u81ea\u52a8\u673a\uff0c\u4ece\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4efb\u52a1\u5d4c\u5165\u6765\u6761\u4ef6\u5316\u7b56\u7565\uff0c\u652f\u6301\u5b8c\u6574\u7684LTL\u89c4\u8303\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u80fd\u591f\u6269\u5c55\u5230\u73b0\u6709\u65b9\u6cd5\u5931\u8d25\u7684\u590d\u6742\u89c4\u8303\u573a\u666f\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u4e49LTL\u5230\u81ea\u52a8\u673a\u8f6c\u6362\u7684\u4efb\u52a1\u5d4c\u5165\u6280\u672f\u80fd\u591f\u6709\u6548\u652f\u6301\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\uff0c\u5904\u7406\u590d\u6742LTL\u89c4\u8303\uff0c\u63d0\u5347\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.06774", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06774", "abs": "https://arxiv.org/abs/2602.06774", "authors": ["Jiali Wu", "Abhinav Anand", "Shweta Verma", "Mira Mezini"], "title": "Towards Understanding What State Space Models Learn About Code", "comment": null, "summary": "State Space Models (SSMs) have emerged as an efficient alternative to the transformer architecture. Recent studies show that SSMs can match or surpass Transformers on code understanding tasks, such as code retrieval, when trained under similar conditions. However, their internal mechanisms remain a black box. We present the first systematic analysis of what SSM-based code models actually learn and perform the first comparative analysis of SSM and Transformer-based code models. Our analysis reveals that SSMs outperform Transformers at capturing code syntax and semantics in pretraining but forgets certain syntactic and semantic relations during fine-tuning on task, especially when the task emphasizes short-range dependencies. To diagnose this, we introduce SSM-Interpret, a frequency-domain framework that exposes a spectral shift toward short-range dependencies during fine-tuning. Guided by these findings, we propose architectural modifications that significantly improve the performance of SSM-based code model, validating that our analysis directly enables better models.", "AI": {"tldr": "SSM\u4ee3\u7801\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u4e2d\u4f18\u4e8eTransformer\u6355\u6349\u4ee3\u7801\u8bed\u6cd5\u8bed\u4e49\uff0c\u4f46\u5728\u5fae\u8c03\u65f6\u4f1a\u9057\u5fd8\u67d0\u4e9b\u8bed\u6cd5\u8bed\u4e49\u5173\u7cfb\uff0c\u5c24\u5176\u662f\u5728\u77ed\u8ddd\u79bb\u4f9d\u8d56\u4efb\u52a1\u4e2d\u3002\u4f5c\u8005\u63d0\u51faSSM-Interpret\u8bca\u65ad\u6846\u67b6\u548c\u67b6\u6784\u6539\u8fdb\u6765\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSMs)\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u4e0d\u900f\u660e\u3002\u9700\u8981\u7cfb\u7edf\u5206\u6790SSM\u4ee3\u7801\u6a21\u578b\u5b66\u4e60\u7684\u5185\u5bb9\uff0c\u5e76\u4e0eTransformer\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4ee5\u7406\u89e3\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "method": "1. \u5bf9SSM\u548cTransformer\u4ee3\u7801\u6a21\u578b\u8fdb\u884c\u9996\u6b21\u7cfb\u7edf\u6027\u6bd4\u8f83\u5206\u6790\uff1b2. \u63d0\u51faSSM-Interpret\u9891\u7387\u57df\u6846\u67b6\uff0c\u8bca\u65ad\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u9891\u8c31\u53d8\u5316\uff1b3. \u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u63d0\u51fa\u67b6\u6784\u6539\u8fdb\u65b9\u6848\u3002", "result": "SSMs\u5728\u9884\u8bad\u7ec3\u4e2d\u6bd4Transformers\u66f4\u597d\u5730\u6355\u6349\u4ee3\u7801\u8bed\u6cd5\u548c\u8bed\u4e49\uff0c\u4f46\u5728\u4efb\u52a1\u5fae\u8c03\u65f6\u4f1a\u9057\u5fd8\u67d0\u4e9b\u8bed\u6cd5\u8bed\u4e49\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u5f3a\u8c03\u77ed\u8ddd\u79bb\u4f9d\u8d56\u7684\u4efb\u52a1\u4e2d\u3002SSM-Interpret\u63ed\u793a\u4e86\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u9891\u8c31\u5411\u77ed\u8ddd\u79bb\u4f9d\u8d56\u7684\u504f\u79fb\u3002", "conclusion": "\u901a\u8fc7SSM-Interpret\u6846\u67b6\u7684\u8bca\u65ad\uff0c\u63d0\u51fa\u7684\u67b6\u6784\u6539\u8fdb\u663e\u8457\u63d0\u5347\u4e86SSM\u4ee3\u7801\u6a21\u578b\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5206\u6790\u80fd\u591f\u76f4\u63a5\u6307\u5bfc\u66f4\u597d\u7684\u6a21\u578b\u8bbe\u8ba1\u3002"}}
{"id": "2602.06818", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06818", "abs": "https://arxiv.org/abs/2602.06818", "authors": ["Anirudh Chari", "Neil Pattanaik"], "title": "Wild Guesses and Mild Guesses in Active Concept Learning", "comment": null, "summary": "Human concept learning is typically active: learners choose which instances to query or test in order to reduce uncertainty about an underlying rule or category. Active concept learning must balance informativeness of queries against the stability of the learner that generates and scores hypotheses. We study this trade-off in a neuro-symbolic Bayesian learner whose hypotheses are executable programs proposed by a large language model (LLM) and reweighted by Bayesian updating. We compare a Rational Active Learner that selects queries to maximize approximate expected information gain (EIG) and the human-like Positive Test Strategy (PTS) that queries instances predicted to be positive under the current best hypothesis. Across concept-learning tasks in the classic Number Game, EIG is effective when falsification is necessary (e.g., compound or exception-laden rules), but underperforms on simple concepts. We trace this failure to a support mismatch between the EIG policy and the LLM proposal distribution: highly diagnostic boundary queries drive the posterior toward regions where the generator produces invalid or overly specific programs, yielding a support-mismatch trap in the particle approximation. PTS is information-suboptimal but tends to maintain proposal validity by selecting \"safe\" queries, leading to faster convergence on simple rules. Our results suggest that \"confirmation bias\" may not be a cognitive error, but rather a rational adaptation for maintaining tractable inference in the sparse, open-ended hypothesis spaces characteristic of human thought.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u7406\u6027\u4e3b\u52a8\u5b66\u4e60\uff08\u6700\u5927\u5316\u671f\u671b\u4fe1\u606f\u589e\u76ca\uff09\u4e0e\u4eba\u7c7b\u6b63\u5411\u6d4b\u8bd5\u7b56\u7565\u5728\u6982\u5ff5\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u524d\u8005\u5728\u590d\u6742\u89c4\u5219\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u7b80\u5355\u6982\u5ff5\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\"\u786e\u8ba4\u504f\u8bef\"\u53ef\u80fd\u662f\u7ef4\u6301\u53ef\u5904\u7406\u63a8\u7406\u7684\u7406\u6027\u9002\u5e94\u3002", "motivation": "\u7814\u7a76\u4eba\u7c7b\u4e3b\u52a8\u6982\u5ff5\u5b66\u4e60\u4e2d\u67e5\u8be2\u9009\u62e9\u7b56\u7565\u7684\u6743\u8861\uff1a\u5982\u4f55\u5728\u67e5\u8be2\u7684\u4fe1\u606f\u91cf\u4e0e\u5b66\u4e60\u8005\u751f\u6210\u548c\u8bc4\u5206\u5047\u8bbe\u7684\u7a33\u5b9a\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u63a2\u7d22\u4eba\u7c7b\"\u786e\u8ba4\u504f\u8bef\"\uff08\u6b63\u5411\u6d4b\u8bd5\u7b56\u7565\uff09\u662f\u5426\u662f\u4e00\u79cd\u8ba4\u77e5\u9519\u8bef\uff0c\u8fd8\u662f\u7ef4\u6301\u53ef\u5904\u7406\u63a8\u7406\u7684\u7406\u6027\u9002\u5e94\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7b26\u53f7\u8d1d\u53f6\u65af\u5b66\u4e60\u5668\uff0c\u5176\u4e2d\u5047\u8bbe\u662f\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u66f4\u65b0\u91cd\u65b0\u52a0\u6743\u3002\u6bd4\u8f83\u4e24\u79cd\u7b56\u7565\uff1a\u7406\u6027\u4e3b\u52a8\u5b66\u4e60\uff08\u9009\u62e9\u6700\u5927\u5316\u8fd1\u4f3c\u671f\u671b\u4fe1\u606f\u589e\u76ca\u7684\u67e5\u8be2\uff09\u548c\u4eba\u7c7b\u6b63\u5411\u6d4b\u8bd5\u7b56\u7565\uff08\u67e5\u8be2\u5f53\u524d\u6700\u4f73\u5047\u8bbe\u9884\u6d4b\u4e3a\u6b63\u7684\u5b9e\u4f8b\uff09\u3002\u5728\u7ecf\u5178\u6570\u5b57\u6e38\u620f\u7684\u6982\u5ff5\u5b66\u4e60\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u671f\u671b\u4fe1\u606f\u589e\u76ca\u7b56\u7565\u5728\u9700\u8981\u8bc1\u4f2a\u7684\u590d\u6742\u89c4\u5219\uff08\u5982\u590d\u5408\u89c4\u5219\u6216\u4f8b\u5916\u89c4\u5219\uff09\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u7b80\u5355\u6982\u5ff5\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u8fd9\u79cd\u5931\u8d25\u6e90\u4e8eEIG\u7b56\u7565\u4e0eLLM\u63d0\u8bae\u5206\u5e03\u4e4b\u95f4\u7684\u652f\u6301\u4e0d\u5339\u914d\uff1a\u9ad8\u5ea6\u8bca\u65ad\u6027\u7684\u8fb9\u754c\u67e5\u8be2\u5c06\u540e\u9a8c\u63a8\u5411\u751f\u6210\u5668\u4ea7\u751f\u65e0\u6548\u6216\u8fc7\u4e8e\u5177\u4f53\u7a0b\u5e8f\u7684\u533a\u57df\uff0c\u5bfc\u81f4\u7c92\u5b50\u8fd1\u4f3c\u4e2d\u7684\u652f\u6301\u4e0d\u5339\u914d\u9677\u9631\u3002\u6b63\u5411\u6d4b\u8bd5\u7b56\u7565\u867d\u7136\u4fe1\u606f\u6b21\u4f18\uff0c\u4f46\u901a\u8fc7\u9009\u62e9\"\u5b89\u5168\"\u67e5\u8be2\u503e\u5411\u4e8e\u4fdd\u6301\u63d0\u8bae\u6709\u6548\u6027\uff0c\u5728\u7b80\u5355\u89c4\u5219\u4e0a\u6536\u655b\u66f4\u5feb\u3002", "conclusion": "\u4eba\u7c7b\u7684\"\u786e\u8ba4\u504f\u8bef\"\uff08\u6b63\u5411\u6d4b\u8bd5\u7b56\u7565\uff09\u53ef\u80fd\u4e0d\u662f\u8ba4\u77e5\u9519\u8bef\uff0c\u800c\u662f\u5728\u4eba\u7c7b\u601d\u7ef4\u7279\u6709\u7684\u7a00\u758f\u3001\u5f00\u653e\u5047\u8bbe\u7a7a\u95f4\u4e2d\u7ef4\u6301\u53ef\u5904\u7406\u63a8\u7406\u7684\u7406\u6027\u9002\u5e94\u3002\u8fd9\u79cd\u7b56\u7565\u901a\u8fc7\u907f\u514d\u652f\u6301\u4e0d\u5339\u914d\u9677\u9631\uff0c\u5728\u7b80\u5355\u6982\u5ff5\u5b66\u4e60\u4e2d\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2602.06820", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06820", "abs": "https://arxiv.org/abs/2602.06820", "authors": ["Dunwei Tu", "Hongyan Hao", "Hansi Yang", "Yihao Chen", "Yi-Kai Zhang", "Zhikang Xia", "Yu Yang", "Yueqing Sun", "Xingchen Liu", "Furao Shen", "Qi Gu", "Hui Su", "Xunliang Cai"], "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training", "comment": null, "summary": "Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration. However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations regarding environmental diversity and scalability. To address these challenges, we introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. Specifically, ScaleEnv ensures environment reliability through procedural testing, and guarantees task completeness and solvability via tool dependency graph expansion and executable action verification. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $\u03c4^2$-Bench and VitaBench, highlighting strong generalization capabilities. Furthermore, we investigate the relationship between increasing number of domains and model generalization performance, providing empirical evidence that scaling environmental diversity is critical for robust agent learning.", "AI": {"tldr": "ScaleEnv\u6846\u67b6\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u5b8c\u5168\u4ea4\u4e92\u5f0f\u73af\u5883\u548c\u53ef\u9a8c\u8bc1\u4efb\u52a1\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5316\u6d4b\u8bd5\u786e\u4fdd\u73af\u5883\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u5de5\u5177\u4f9d\u8d56\u56fe\u6269\u5c55\u548c\u53ef\u6267\u884c\u52a8\u4f5c\u9a8c\u8bc1\u4fdd\u8bc1\u4efb\u52a1\u5b8c\u6574\u6027\u548c\u53ef\u89e3\u6027\uff0c\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u5728\u672a\u89c1\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u8bad\u7ec3\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u573a\u666f\u7684\u901a\u7528\u667a\u80fd\u4f53\u9700\u8981\u4ea4\u4e92\u5f0f\u73af\u5883\u8fdb\u884c\u81ea\u6211\u63a2\u7d22\uff0c\u4f46\u5f53\u524d\u4ea4\u4e92\u73af\u5883\u4e25\u91cd\u4e0d\u8db3\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5728\u73af\u5883\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u9650\u5236\u3002", "method": "ScaleEnv\u6846\u67b6\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u5b8c\u5168\u4ea4\u4e92\u5f0f\u73af\u5883\u548c\u53ef\u9a8c\u8bc1\u4efb\u52a1\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5316\u6d4b\u8bd5\u786e\u4fdd\u73af\u5883\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u5de5\u5177\u4f9d\u8d56\u56fe\u6269\u5c55\u548c\u53ef\u6267\u884c\u52a8\u4f5c\u9a8c\u8bc1\u4fdd\u8bc1\u4efb\u52a1\u5b8c\u6574\u6027\u548c\u53ef\u89e3\u6027\u3002", "result": "\u5728\u672a\u89c1\u7684\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\uff08\u5982\u03c4\u00b2-Bench\u548cVitaBench\uff09\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5b9e\u8bc1\u8bc1\u660e\u4e86\u73af\u5883\u591a\u6837\u6027\u6269\u5c55\u5bf9\u667a\u80fd\u4f53\u5b66\u4e60\u9c81\u68d2\u6027\u7684\u91cd\u8981\u6027\u3002", "conclusion": "ScaleEnv\u901a\u8fc7\u4ece\u96f6\u6784\u5efa\u4ea4\u4e92\u5f0f\u73af\u5883\u89e3\u51b3\u4e86\u73af\u5883\u7a00\u7f3a\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u6269\u5c55\u73af\u5883\u591a\u6837\u6027\u5bf9\u667a\u80fd\u4f53\u6cdb\u5316\u80fd\u529b\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u901a\u7528\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.06822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06822", "abs": "https://arxiv.org/abs/2602.06822", "authors": ["Yi Chen", "Wonjin Shin", "Shuhong Liu", "Tho Mai", "Jeongmo Lee", "Chuanbo Hua", "Kun Wang", "Jun Liu", "Joo-Young Kim"], "title": "POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models", "comment": null, "summary": "Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions during inference, overlooking sparsity patterns that emerge in the autoregressive token generation. In this paper, we propose POP (Partition-guided Online Pruning), an efficient online structural pruning framework that enables context-conditioned dynamic pruning with minimal computational overhead. POP partitions model channels into retained, candidate, and pruned regions, where prefilling defines a coarse pruning partition, and the decoding stage generates a fine-grained mask within the candidate region, avoiding full-channel re-evaluation. The coarse pruning partition preserves consistently important weights, while the fine-grained masking provides context-conditioned variation during decoding. Moreover, POP is a lightweight, plug-and-play method that requires no preprocessing, including offline calibration, retraining, or learning predictors. Extensive evaluations across diverse LFMs, including large language models (LLMs), mixture-of-experts models (MoEs), and vision-language models (VLMs), demonstrate that POP consistently delivers higher accuracy than existing pruning approaches while incurring smaller computational overhead and minimizing inference latency.", "AI": {"tldr": "POP\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5728\u7ebf\u7ed3\u6784\u5316\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u533a\u673a\u5236\u5b9e\u73b0\u4e0a\u4e0b\u6587\u6761\u4ef6\u5316\u7684\u52a8\u6001\u526a\u679d\uff0c\u5728\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u65e0\u9700\u9884\u5904\u7406\u6216\u91cd\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u91c7\u7528\u56fa\u5b9a\u7684\u526a\u679d\u51b3\u7b56\uff0c\u5ffd\u7565\u4e86\u81ea\u56de\u5f52token\u751f\u6210\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u7a00\u758f\u6a21\u5f0f\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u8fdb\u884c\u52a8\u6001\u4f18\u5316\u3002", "method": "POP\u5c06\u6a21\u578b\u901a\u9053\u5212\u5206\u4e3a\u4fdd\u7559\u533a\u3001\u5019\u9009\u533a\u548c\u526a\u679d\u533a\uff1a\u9884\u586b\u5145\u9636\u6bb5\u5b9a\u4e49\u7c97\u7c92\u5ea6\u526a\u679d\u5206\u533a\uff0c\u89e3\u7801\u9636\u6bb5\u5728\u5019\u9009\u533a\u5185\u751f\u6210\u7ec6\u7c92\u5ea6\u63a9\u7801\uff0c\u907f\u514d\u5168\u901a\u9053\u91cd\u65b0\u8bc4\u4f30\u3002\u7c97\u7c92\u5ea6\u5206\u533a\u4fdd\u7559\u6301\u7eed\u91cd\u8981\u7684\u6743\u91cd\uff0c\u7ec6\u7c92\u5ea6\u63a9\u7801\u63d0\u4f9b\u89e3\u7801\u65f6\u7684\u4e0a\u4e0b\u6587\u6761\u4ef6\u5316\u53d8\u5316\u3002", "result": "\u5728\u591a\u79cd\u5927\u578b\u57fa\u7840\u6a21\u578b\uff08LLMs\u3001MoEs\u3001VLMs\uff09\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cPOP\u6bd4\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u63d0\u4f9b\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\u5e76\u6700\u5c0f\u5316\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "POP\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528\u7684\u5728\u7ebf\u526a\u679d\u6846\u67b6\uff0c\u65e0\u9700\u9884\u5904\u7406\uff08\u79bb\u7ebf\u6821\u51c6\u3001\u91cd\u8bad\u7ec3\u6216\u5b66\u4e60\u9884\u6d4b\u5668\uff09\uff0c\u80fd\u591f\u5728\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e0a\u4e0b\u6587\u6761\u4ef6\u5316\u7684\u52a8\u6001\u526a\u679d\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u3002"}}
{"id": "2602.06836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06836", "abs": "https://arxiv.org/abs/2602.06836", "authors": ["Tonghan Wang", "Yuqi Pan", "Xinyi Yang", "Yanchen Jiang", "Milind Tambe", "David C. Parkes"], "title": "LLM Active Alignment: A Nash Equilibrium Perspective", "comment": null, "summary": "We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent's action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an interpretable and behaviorally substantive policy class. We derive closed-form NE characterizations, adopting standard concave-utility assumptions to enable analytical system-level predictions and give explicit, actionable guidance for shifting alignment targets toward socially desirable outcomes. The method functions as an active alignment layer on top of existing alignment pipelines such as RLHF. In a social-media setting, we show that a population of LLMs, especially reasoning-based models, may exhibit political exclusion, pathologies where some subpopulations are ignored by all LLM agents, which can be avoided by our method, illustrating the promise of applying the method to regulate multi-agent LLM dynamics across domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u7eb3\u4ec0\u5747\u8861\u5206\u6790\u7684\u535a\u5f08\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u5f15\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7fa4\u4f53\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u5c06\u4ee3\u7406\u884c\u4e3a\u5efa\u6a21\u4e3a\u4eba\u7c7b\u5b50\u7fa4\u4f53\u7684\u6df7\u5408\u9009\u62e9\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u7cfb\u7edf\u7ea7\u9884\u6d4b\u548c\u793e\u4f1a\u671f\u671b\u7ed3\u679c\u7684\u5f15\u5bfc\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5f00\u653e\u6587\u672c\u7a7a\u95f4\u4e2d\u8ba1\u7b97\u5747\u8861\u7684\u56f0\u96be\uff0c\u5e76\u9884\u6d4b\u548c\u5f15\u5bfcLLM\u7fa4\u4f53\u7684\u884c\u4e3a\uff0c\u7279\u522b\u662f\u907f\u514d\u653f\u6cbb\u6392\u65a5\u7b49\u793e\u4f1a\u75c5\u7406\u73b0\u8c61\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5206\u6790\u591a\u667a\u80fd\u4f53LLM\u52a8\u6001\u5e76\u5b9e\u73b0\u793e\u4f1a\u671f\u671b\u7ed3\u679c\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u6bcf\u4e2a\u4ee3\u7406\u7684\u884c\u4e3a\u5efa\u6a21\u4e3a\u4eba\u7c7b\u5b50\u7fa4\u4f53\u7684\u6df7\u5408\u9009\u62e9\uff0c\u4ee3\u7406\u4e3b\u52a8\u6218\u7565\u6027\u5730\u9009\u62e9\u4e0e\u54ea\u4e9b\u7fa4\u4f53\u5bf9\u9f50\uff1b\u91c7\u7528\u6807\u51c6\u51f9\u6548\u7528\u5047\u8bbe\u63a8\u5bfc\u95ed\u5f0f\u7eb3\u4ec0\u5747\u8861\u7279\u5f81\uff1b\u4f5c\u4e3a\u73b0\u6709\u5bf9\u9f50\u6d41\u7a0b\uff08\u5982RLHF\uff09\u4e4b\u4e0a\u7684\u4e3b\u52a8\u5bf9\u9f50\u5c42\u3002", "result": "\u5728\u793e\u4ea4\u5a92\u4f53\u8bbe\u7f6e\u4e2d\uff0cLLM\u7fa4\u4f53\uff08\u7279\u522b\u662f\u57fa\u4e8e\u63a8\u7406\u7684\u6a21\u578b\uff09\u53ef\u80fd\u8868\u73b0\u51fa\u653f\u6cbb\u6392\u65a5\u73b0\u8c61\uff0c\u5373\u67d0\u4e9b\u5b50\u7fa4\u4f53\u88ab\u6240\u6709LLM\u4ee3\u7406\u5ffd\u7565\uff1b\u8be5\u65b9\u6cd5\u80fd\u591f\u907f\u514d\u8fd9\u79cd\u75c5\u7406\u73b0\u8c61\uff0c\u5c55\u793a\u4e86\u5728\u591a\u9886\u57df\u8c03\u8282\u591a\u667a\u80fd\u4f53LLM\u52a8\u6001\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u535a\u5f08\u8bba\u6846\u67b6\u4e3a\u9884\u6d4b\u548c\u5f15\u5bfcLLM\u7fa4\u4f53\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u884c\u4e3a\u5b9e\u8d28\u6027\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u660e\u786e\u7684\u884c\u52a8\u6307\u5bfc\u5c06\u5bf9\u9f50\u76ee\u6807\u8f6c\u5411\u793e\u4f1a\u671f\u671b\u7ed3\u679c\uff0c\u5728\u8c03\u8282\u591a\u667a\u80fd\u4f53LLM\u52a8\u6001\u65b9\u9762\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.06838", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06838", "abs": "https://arxiv.org/abs/2602.06838", "authors": ["Jin Wang", "Hui Ma", "Fei Xing", "Ming Yan"], "title": "An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization", "comment": "submited to a conference", "summary": "Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When differential privacy is enforced, conventional fixed gradient clipping and Gaussian noise injection may further amplify gradient perturbations, resulting in training oscillation and performance degradation and degraded model performance. To address these challenges, we propose an adaptive differentially private federated learning framework that explicitly targets model efficiency under heterogeneous and privacy-constrained settings. On the client side, a lightweight local compressed module is introduced to regularize intermediate representations and constrain gradient variability, thereby mitigating noise amplification during local optimization. On the server side, an adaptive gradient clipping strategy dynamically adjusts clipping thresholds based on historical update statistics to avoid over-clipping and noise domination. Furthermore, a constraint-aware aggregation mechanism is designed to suppress unreliable or noise-dominated client updates and stabilize global optimization. Extensive experiments on CIFAR-10 and SVHN demonstrate improved convergence stability and classification accuracy.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u8f7b\u91cf\u538b\u7f29\u6a21\u5757\u3001\u670d\u52a1\u5668\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u548c\u7ea6\u675f\u611f\u77e5\u805a\u5408\u673a\u5236\uff0c\u89e3\u51b3\u5f02\u6784\u6570\u636e\u548c\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u8bbe\u5907\u5f02\u6784\u6027\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5bfc\u81f4\u7684\u68af\u5ea6\u66f4\u65b0\u4e0d\u7a33\u5b9a\u548c\u504f\u5dee\u95ee\u9898\u3002\u5f53\u5f3a\u5236\u5b9e\u65bd\u5dee\u5206\u9690\u79c1\u65f6\uff0c\u4f20\u7edf\u7684\u56fa\u5b9a\u68af\u5ea6\u88c1\u526a\u548c\u9ad8\u65af\u566a\u58f0\u6ce8\u5165\u4f1a\u8fdb\u4e00\u6b65\u653e\u5927\u68af\u5ea6\u6270\u52a8\uff0c\u5bfc\u81f4\u8bad\u7ec3\u632f\u8361\u548c\u6027\u80fd\u4e0b\u964d\u3002", "method": "1. \u5ba2\u6237\u7aef\uff1a\u5f15\u5165\u8f7b\u91cf\u7ea7\u672c\u5730\u538b\u7f29\u6a21\u5757\uff0c\u6b63\u5219\u5316\u4e2d\u95f4\u8868\u793a\u5e76\u7ea6\u675f\u68af\u5ea6\u53d8\u5f02\u6027\uff0c\u51cf\u8f7b\u672c\u5730\u4f18\u5316\u671f\u95f4\u7684\u566a\u58f0\u653e\u5927\n2. \u670d\u52a1\u5668\uff1a\u57fa\u4e8e\u5386\u53f2\u66f4\u65b0\u7edf\u8ba1\u52a8\u6001\u8c03\u6574\u88c1\u526a\u9608\u503c\u7684\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u7b56\u7565\uff0c\u907f\u514d\u8fc7\u5ea6\u88c1\u526a\u548c\u566a\u58f0\u4e3b\u5bfc\n3. \u670d\u52a1\u5668\uff1a\u8bbe\u8ba1\u7ea6\u675f\u611f\u77e5\u805a\u5408\u673a\u5236\uff0c\u6291\u5236\u4e0d\u53ef\u9760\u6216\u566a\u58f0\u4e3b\u5bfc\u7684\u5ba2\u6237\u7aef\u66f4\u65b0\uff0c\u7a33\u5b9a\u5168\u5c40\u4f18\u5316", "result": "\u5728CIFAR-10\u548cSVHN\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u6536\u655b\u7a33\u5b9a\u6027\u548c\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u548c\u9690\u79c1\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u6a21\u578b\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u6b63\u5219\u5316\u3001\u81ea\u9002\u5e94\u88c1\u526a\u548c\u667a\u80fd\u805a\u5408\u673a\u5236\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.06841", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06841", "abs": "https://arxiv.org/abs/2602.06841", "authors": ["Sindhuja Chaduvula", "Jessee Ho", "Kina Kim", "Aravind Narayanan", "Mahshid Alinoori", "Muskan Garg", "Dhanesh Ramachandram", "Shaina Raza"], "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems", "comment": null, "summary": "Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks (TAU-bench Airline and AssistantBench). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman $\u03c1= 0.86$), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories. In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7$\\times$ more prevalent in failed runs and reduces success probability by 49\\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour.\n  Resources:\n  https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u9759\u6001\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u5c5e\u6027\u89e3\u91ca\u4e0e\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u8f68\u8ff9\u8bca\u65ad\uff0c\u53d1\u73b0\u4f20\u7edf\u5c5e\u6027\u89e3\u91ca\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u8bca\u65ad\u667a\u80fd\u4f53\u6267\u884c\u5931\u8d25\uff0c\u800c\u57fa\u4e8e\u8f68\u8ff9\u7684\u8bc4\u4f30\u65b9\u6cd5\u80fd\u6709\u6548\u5b9a\u4f4d\u884c\u4e3a\u6545\u969c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0cAI\u7cfb\u7edf\u4ece\u9759\u6001\u9884\u6d4b\u8f6c\u5411\u591a\u6b65\u9aa4\u51b3\u7b56\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u4f20\u7edf\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u6b21\u9884\u6d4b\uff0c\u4e0d\u6e05\u695a\u8fd9\u4e9b\u65b9\u6cd5\u5982\u4f55\u9002\u7528\u4e8e\u884c\u4e3a\u968f\u65f6\u95f4\u6f14\u5316\u7684\u667a\u80fd\u4f53\u8bbe\u7f6e\u3002\u9700\u8981\u5f25\u5408\u9759\u6001\u53ef\u89e3\u91ca\u6027\u4e0e\u667a\u80fd\u4f53\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5728\u9759\u6001\u5206\u7c7b\u4efb\u52a1\u4e2d\u6bd4\u8f83\u5c5e\u6027\u89e3\u91ca\u65b9\u6cd5\uff0c\u5728\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\uff08TAU-bench Airline\u548cAssistantBench\uff09\u4e2d\u6bd4\u8f83\u57fa\u4e8e\u8f68\u8ff9\u7684\u8bca\u65ad\u65b9\u6cd5\u3002\u4f7f\u7528\u57fa\u4e8e\u8f68\u8ff9\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u5b9a\u4f4d\u884c\u4e3a\u6545\u969c\u3002", "result": "\u5c5e\u6027\u65b9\u6cd5\u5728\u9759\u6001\u8bbe\u7f6e\u4e2d\u7279\u5f81\u6392\u5e8f\u7a33\u5b9a\uff08Spearman \u03c1=0.86\uff09\uff0c\u4f46\u65e0\u6cd5\u53ef\u9760\u8bca\u65ad\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u7684\u6267\u884c\u7ea7\u6545\u969c\u3002\u57fa\u4e8e\u8f68\u8ff9\u7684\u8bc4\u4f30\u80fd\u4e00\u81f4\u5b9a\u4f4d\u884c\u4e3a\u6545\u969c\uff0c\u53d1\u73b0\u72b6\u6001\u8ddf\u8e2a\u4e0d\u4e00\u81f4\u5728\u5931\u8d25\u8fd0\u884c\u4e2d\u9ad8\u51fa2.7\u500d\uff0c\u5e76\u5c06\u6210\u529f\u6982\u7387\u964d\u4f4e49%\u3002", "conclusion": "\u9700\u8981\u4ece\u9759\u6001\u89e3\u91ca\u8f6c\u5411\u8f68\u8ff9\u7ea7\u53ef\u89e3\u91ca\u6027\u6765\u8bc4\u4f30\u548c\u8bca\u65ad\u81ea\u4e3bAI\u884c\u4e3a\u3002\u57fa\u4e8e\u8f68\u8ff9\u7684\u8bca\u65ad\u65b9\u6cd5\u66f4\u9002\u5408\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u884c\u4e3a\u6545\u969c\u7684\u6839\u672c\u539f\u56e0\u3002"}}
{"id": "2602.06855", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06855", "abs": "https://arxiv.org/abs/2602.06855", "authors": ["Alisia Lupidi", "Bhavul Gauri", "Thomas Simon Foster", "Bassel Al Omari", "Despoina Magka", "Alberto Pepe", "Alexis Audran-Reiss", "Muna Aghamelu", "Nicolas Baldwin", "Lucia Cipolina-Kun", "Jean-Christophe Gagnon-Audet", "Chee Hau Leow", "Sandra Lefdal", "Hossam Mossalam", "Abhinav Moudgil", "Saba Nazir", "Emanuel Tewolde", "Isabel Urrego", "Jordi Armengol Estape", "Amar Budhiraja", "Gaurav Chaurasia", "Abhishek Charnalia", "Derek Dunfield", "Karen Hambardzumyan", "Daniel Izcovich", "Martin Josifoski", "Ishita Mediratta", "Kelvin Niu", "Parth Pathak", "Michael Shvartsman", "Edan Toledo", "Anton Protopopov", "Roberta Raileanu", "Alexander Miller", "Tatiana Shavrina", "Jakob Foerster", "Yoram Bachrach"], "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents", "comment": "49 pages, 14 figures, 10 tables", "summary": "LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds. Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.", "AI": {"tldr": "AIRS-Bench\u662f\u4e00\u4e2a\u5305\u542b20\u4e2a\u4efb\u52a1\u7684AI\u7814\u7a76\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u5b8c\u6574\u79d1\u7814\u751f\u547d\u5468\u671f\u4e2d\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u4ee3\u7406\u57284\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8fc7\u4eba\u7c7bSOTA\uff0c\u4f46\u572816\u4e2a\u4efb\u52a1\u4e0a\u672a\u80fd\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u4e3a\u4e86\u52a0\u901fLLM\u4ee3\u7406\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u4ee3\u7406\u5728\u5b8c\u6574\u79d1\u7814\u751f\u547d\u5468\u671f\u4e2d\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u4ece\u60f3\u6cd5\u751f\u6210\u5230\u5b9e\u9a8c\u5206\u6790\u548c\u8fed\u4ee3\u4f18\u5316\u7684\u5168\u8fc7\u7a0b\u3002", "method": "\u4ece\u9876\u7ea7\u673a\u5668\u5b66\u4e60\u8bba\u6587\u4e2d\u9009\u53d620\u4e2a\u4efb\u52a1\u6784\u5efaAIRS-Bench\u5957\u4ef6\uff0c\u6db5\u76d6\u8bed\u8a00\u5efa\u6a21\u3001\u6570\u5b66\u3001\u751f\u7269\u4fe1\u606f\u5b66\u548c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7b49\u591a\u4e2a\u9886\u57df\u3002\u91c7\u7528\u7075\u6d3b\u7684\u57fa\u51c6\u683c\u5f0f\uff0c\u652f\u6301\u65b0\u4efb\u52a1\u7684\u96c6\u6210\u548c\u4e0d\u540c\u4ee3\u7406\u6846\u67b6\u7684\u4e25\u683c\u6bd4\u8f83\u3002\u4f7f\u7528\u524d\u6cbf\u6a21\u578b\u914d\u5408\u987a\u5e8f\u548c\u5e76\u884c\u67b6\u6784\u5efa\u7acb\u57fa\u7ebf\u3002", "result": "\u4ee3\u7406\u57284\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8fc7\u4e86\u4eba\u7c7bSOTA\uff0c\u4f46\u572816\u4e2a\u4efb\u52a1\u4e0a\u672a\u80fd\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002\u5373\u4f7f\u4ee3\u7406\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u4eba\u7c7b\u57fa\u51c6\uff0c\u4e5f\u672a\u80fd\u8fbe\u5230\u8be5\u4efb\u52a1\u7684\u7406\u8bba\u6027\u80fd\u4e0a\u9650\uff0c\u8868\u660eAIRS-Bench\u8fdc\u672a\u9971\u548c\uff0c\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "AIRS-Bench\u662f\u4e00\u4e2a\u6709\u6548\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u80fd\u591f\u63a8\u52a8\u81ea\u4e3b\u79d1\u5b66\u7814\u7a76\u7684\u53d1\u5c55\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5f53\u524dLLM\u4ee3\u7406\u5728\u79d1\u5b66\u7814\u7a76\u80fd\u529b\u4e0a\u4ecd\u6709\u663e\u8457\u63d0\u5347\u7a7a\u95f4\uff0c\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u5c06\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2602.06948", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06948", "abs": "https://arxiv.org/abs/2602.06948", "authors": ["Jean Kaddour", "Srijan Patel", "Gb\u00e8tondji Dovonon", "Leo Richter", "Pasquale Minervini", "Matt J. Kusner"], "title": "Agentic Uncertainty Reveals Agentic Overconfidence", "comment": null, "summary": "Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.", "AI": {"tldr": "AI\u4ee3\u7406\u5728\u4efb\u52a1\u6267\u884c\u524d\u3001\u4e2d\u3001\u540e\u9884\u6d4b\u6210\u529f\u7387\u65f6\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u6210\u529f\u7387\u4ec522%\u7684\u4ee3\u7406\u9884\u6d4b77%\u6210\u529f\u7387\u3002\u53cd\u76f4\u89c9\u7684\u662f\uff0c\u4fe1\u606f\u66f4\u5c11\u7684\u6267\u884c\u524d\u8bc4\u4f30\u6bd4\u6267\u884c\u540e\u8bc4\u4f30\u6709\u66f4\u597d\u7684\u533a\u5206\u80fd\u529b\uff0c\u800c\u5bf9\u6297\u6027\u63d0\u793a\uff08\u91cd\u6784\u4e3abug\u67e5\u627e\uff09\u5b9e\u73b0\u4e86\u6700\u4f73\u6821\u51c6\u3002", "motivation": "\u7814\u7a76AI\u4ee3\u7406\u662f\u5426\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u81ea\u5df1\u5728\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\uff0c\u63a2\u7d22\u4ee3\u7406\u6027\u4e0d\u786e\u5b9a\u6027\uff08agentic uncertainty\uff09\u7684\u8868\u73b0\u5f62\u5f0f\uff0c\u4e86\u89e3AI\u4ee3\u7406\u5bf9\u81ea\u8eab\u80fd\u529b\u7684\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "method": "\u5728\u4efb\u52a1\u6267\u884c\u524d\u3001\u6267\u884c\u4e2d\u548c\u6267\u884c\u540e\u4e09\u4e2a\u9636\u6bb5\u6536\u96c6AI\u4ee3\u7406\u7684\u6210\u529f\u6982\u7387\u4f30\u8ba1\uff1b\u6bd4\u8f83\u4e0d\u540c\u4fe1\u606f\u91cf\u4e0b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff1b\u4f7f\u7528\u5bf9\u6297\u6027\u63d0\u793a\u65b9\u6cd5\uff0c\u5c06\u8bc4\u4f30\u91cd\u6784\u4e3abug\u67e5\u627e\u4efb\u52a1\u3002", "result": "\u53d1\u73b0\u4ee3\u7406\u6027\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\uff1a\u4e00\u4e9b\u5b9e\u9645\u6210\u529f\u7387\u4ec522%\u7684\u4ee3\u7406\u9884\u6d4b\u6210\u529f\u7387\u4e3a77%\uff1b\u53cd\u76f4\u89c9\u5730\uff0c\u4fe1\u606f\u66f4\u5c11\u7684\u6267\u884c\u524d\u8bc4\u4f30\u6bd4\u6807\u51c6\u6267\u884c\u540e\u8bc4\u4f30\u6709\u66f4\u597d\u7684\u533a\u5206\u80fd\u529b\uff08\u5c3d\u7ba1\u5dee\u5f02\u4e0d\u603b\u662f\u663e\u8457\uff09\uff1b\u5bf9\u6297\u6027\u63d0\u793a\uff08bug\u67e5\u627e\u65b9\u6cd5\uff09\u5b9e\u73b0\u4e86\u6700\u4f73\u6821\u51c6\u6548\u679c\u3002", "conclusion": "AI\u4ee3\u7406\u5728\u8bc4\u4f30\u81ea\u8eab\u4efb\u52a1\u6210\u529f\u7387\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\uff1b\u51cf\u5c11\u4fe1\u606f\u91cf\u53ef\u80fd\u6539\u5584\u9884\u6d4b\u533a\u5206\u80fd\u529b\uff1b\u5bf9\u6297\u6027\u63d0\u793a\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6821\u51c6\u8d28\u91cf\uff0c\u8fd9\u5bf9AI\u7cfb\u7edf\u7684\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u5f00\u53d1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
