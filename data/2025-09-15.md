<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [DBOS Network Sensing: A Web Services Approach to Collaborative Awareness](https://arxiv.org/abs/2509.09898)
*Sophia Lockton,Jeremy Kepner,Michael Stonebraker,Hayden Jananthan,LaToya Anderson,William Arcand,David Bestor,William Bergeron,Alex Bonn,Daniel Burrill,Chansup Byun,Timothy Davis,Vijay Gadepally,Michael Houle,Matthew Hubbell,Michael Jones,Piotr Luszczek,Peter Michaleas,Lauren Milechin,Chasen Milner,Guillermo Morales,Julie Mullen,Michel Pelletier,Alex Poliakov,Andrew Prout,Albert Reuther,Antonio Rosa,Charles Yee,Alex Pentland*

Main category: cs.NI

TL;DR: DBOS是一种数据库操作系统，通过集成GraphBLAS超稀疏流量矩阵的网络感知能力，在保持高性能的同时大大提升网络服务的弹性和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统web服务部署复杂而弱弹性，DBOS旨在通过数据库、操作系统和web服务的深度集成，简化部署流程并提升系统弹性。

Method: 采用两种方法集成网络感知能力：(1) Python-GraphBLAS实现 (2) OneSparse PostgreSQL实现。系统在MIT SuperCloud上使用64个计算节点进行并行化测试。

Result: 单个DBOS实例可持续处理>10^5个web请求/秒，网络感知开销可忽略。Python-GraphBLAS在64节点、OneSparse PostgreSQL在32节点上均呈现线性扩展性。

Conclusion: DBOS可以以可忽略的计算资源增加为代价，实现协同式网络感知能力，为构建更弹性、更安全的web服务提供了新的解决方案。

Abstract: DBOS (DataBase Operating System) is a novel capability that integrates web
services, operating system functions, and database features to significantly
reduce web-deployment effort while increasing resilience. Integration of high
performance network sensing enables DBOS web services to collaboratively create
a shared awareness of their network environments to enhance their collective
resilience and security. Network sensing is added to DBOS using GraphBLAS
hypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)
OneSparse PostgreSQL. These capabilities are demonstrated using the workflow
and analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph
Challenge. The system was parallelized using pPython and benchmarked using 64
compute nodes on the MIT SuperCloud. The web request rate sustained by a single
DBOS instance was ${>}10^5$, well above the required maximum, indicating that
network sensing can be added to DBOS with negligible overhead. For
collaborative awareness, many DBOS instances were connected to a single DBOS
aggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations
scaled linearly up to 64 and 32 nodes respectively. These results suggest that
DBOS collaborative network awareness can be achieved with a negligible increase
in computing resources.

</details>


### [2] [Taming Volatility: Stable and Private QUIC Classification with Federated Learning](https://arxiv.org/abs/2509.09997)
*Richard Jozsa,Karel Hynek,Adrian Pekar*

Main category: cs.NI

TL;DR: 这篇论文提出了一种客户端数据缓冲区方法，解决聚合学习中因网络流量时间波动导致的模型不稳定问题，在QUIC分类任务中实现了近似中央化模型的性能。


<details>
  <summary>Details</summary>
Motivation: 聚合学习在网络流量分析中存在实际部署挑战，实际网络流量的时间波动性导致客户端数据可用性不一致，影响模型训练稳定性，而现有研究对此问题关注不够。

Method: 提出客户端数据缓冲区机制，将本地训练与实时流量波动解耦，确保训练过程的稳定性和一致性。使用真实的CESNET-QUIC22数据集，分割成14个自治客户进行验证。

Result: 稳定的聚合学习系统达到95.2%的F1分数，仅比非隐私保护的中央化模型低2.3个百分点，实现了稳健收敛。

Conclusion: 该方法为构建操作稳定的聚合学习系统提供了蓝图，证明通过有针对性的架构选择可以克服动态网络环境的挑战。

Abstract: Federated Learning (FL) is a promising approach for privacy-preserving
network traffic analysis, but its practical deployment is challenged by the
non-IID nature of real-world data. While prior work has addressed statistical
heterogeneity, the impact of temporal traffic volatility-the natural daily ebb
and flow of network activity-on model stability remains largely unexplored.
This volatility can lead to inconsistent data availability at clients,
destabilizing the entire training process. In this paper, we systematically
address the problem of temporal volatility in federated QUIC classification. We
first demonstrate the instability of standard FL in this dynamic setting. We
then propose and evaluate a client-side data buffer as a practical mechanism to
ensure stable and consistent local training, decoupling it from real-time
traffic fluctuations. Using the real-world CESNET-QUIC22 dataset partitioned
into 14 autonomous clients, we then demonstrate that this approach enables
robust convergence. Our results show that a stable federated system achieves a
95.2% F1 score, a mere 2.3 percentage points below a non-private centralized
model. This work establishes a blueprint for building operationally stable FL
systems for network management, proving that the challenges of dynamic network
environments can be overcome with targeted architectural choices.

</details>


### [3] [Service Function Chaining Architecture for Multi-hop Split Inference and Learning](https://arxiv.org/abs/2509.10001)
*Takanori Hara,Masahiro Sasabe*

Main category: cs.NI

TL;DR: 基于服务函数链(SFC)的多跳分割推理和学习架构，通过将分割子模型视为服务函数，利用SRv6和eBPF实现动态路由和高效处理。


<details>
  <summary>Details</summary>
Motivation: 使用服务函数链技术来解决多跳分割推理和学习中的动态通信路径管理问题，实现效率和适应性的执行。

Method: 设计神经服务函数(NSFs)执行分割子模型，集成SRv6和eBPF基础的SFC代理，支持动态路由和双向通信。

Result: 证明架构可行，特别适合小批处大小的实时推理，支持动态路由重配置且对推理/学习过程影响最小。

Conclusion: 基于SFC的架构能够有效支持多跳分割推理和学习，提供动态适应能力和高效处理性能。

Abstract: Service Function Chaining (SFC) is a networking technique that ensures
traffic traverses a predefined sequence of service functions, realizing
arbitrary network services through dynamic and efficient communication paths.
Inspired by this concept, we propose an SFC-based architecture for Multi-hop
Split Inference (MSI), where split sub-models are interpreted as service
functions and their composition forms a service chain representing the global
model. By leveraging SFC, the proposed architecture dynamically establishes
communication paths for split sub-models, ensuring efficient and adaptive
execution. Furthermore, we extend this architecture to Multi-hop Split Learning
(MSL) by applying SFC to the bidirectional communication required for training
tasks. To realize the proposed architecture, we design Neural Service Functions
(NSFs) to execute split sub-models as transparent TCP proxies and integrate
them with Segment Routing over IPv6 (SRv6) and the extended Berkeley Packet
Filter (eBPF)-based SFC proxy. This integration ensures efficient ML processing
over dynamic routing while maintaining compatibility with existing
applications. Evaluation results demonstrate that (1) the proposed architecture
is feasible for both MSI and MSL; (2) it is particularly suitable for real-time
inference in MSI scenarios with small mini-batch sizes; (3) it supports dynamic
path reconfiguration, enabling adaptive responses to changing network
conditions while minimizing the impact of control mechanisms on inference and
learning processes.

</details>


### [4] [Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and Digital Twin Integration](https://arxiv.org/abs/2509.10097)
*Ahmed Al-Tahmeesschi,Yi Chu,Gurdeep Singh,Charles Turyagyenda,Dritan Kaleshi,David Grace,Hamed Ahmadi*

Main category: cs.NI

TL;DR: 基于数字双生技术的混合xApp通过动态管理开放无线单元睡眠模式，在开放RAN环境中实现了13%的能消耗节省，且不影响用户服务质量。


<details>
  <summary>Details</summary>
Motivation: 5G及未来网络对高速、超高可靠和低延迟通信的需求导致无线接入网络能耗大幅增长，给运营商带来运营和可持续性挑战。开放无线接入网络(O-RAN)虽然提供了灵活性和可程序化但增加了网络管理复杂度。

Method: 提出一种混合xApp，结合含法方法和无监督机器学习，通过TeraVM AI RAN场景生成器(AI-RSG)集成数字双生技术，动态管理开放无线单元(RU)的睡眠模式。

Result: 在实际大规模模拟开放RAN场景中进行实验评估，混合xApp实现了约13%的能消耗节省，同时保持了用户服务质量(QoS)。

Conclusion: 该混合xApp方案具有实用性和重要的实际部署潜力，能够在不影响用户体验的前提下有效降低5G网络能耗。

Abstract: The growing demand for high-speed, ultra-reliable, and low-latency
communications in 5G and beyond networks has significantly driven up power
consumption, particularly within the Radio Access Network (RAN). This surge in
energy demand poses critical operational and sustainability challenges for
mobile network operators, necessitating innovative solutions that enhance
energy efficiency without compromising Quality of Service (QoS). Open Radio
Access Network (O-RAN), spearheaded by the O-RAN Alliance, offers
disaggregated, programmable, and intelligent architectures, promoting
flexibility, interoperability, and cost-effectiveness. However, this
disaggregated approach adds complexity, particularly in managing power
consumption across diverse network components such as Open Radio Units (RUs).
In this paper, we propose a hybrid xApp leveraging heuristic methods and
unsupervised machine learning, integrated with digital twin technology through
the TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically
manages RU sleep modes to effectively reduce energy consumption. Our
experimental evaluation in a realistic, large-scale emulated Open RAN scenario
demonstrates that the hybrid xApp achieves approximately 13% energy savings,
highlighting its practicality and significant potential for real-world
deployments without compromising user QoS.

</details>


### [5] [Secure and Scalable Rerouting in LEO Satellite Networks](https://arxiv.org/abs/2509.10173)
*Lyubomir Yanev,Pietro Ronchetti,Joshua Smailes,Martin Strohmeier*

Main category: cs.NI

TL;DR: 这篇论文通过扩展DSNS模拟器，系统比较了低轨道卫星网络中三种不同故障知识范围的重路由策略，发现基于网段的重路由方案能在局部响应性和全局协调之间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 低轨道卫星网络中频繁且不可预测的链路和节点故障导致路由弹性挑战，现有重路由策略在动态故障条件下的相对交易仍未得到充分探索。

Method: 扩展Deep Space Network Simulator (DSNS)，系统比较三种重路由范式：局部邻居基础、网段基础和全局知识基础的重路由，以及一种无故障知识的源路由解决方案。

Result: 测量了交付比、延迟、重路由开销和循环发生率。网段基础重路由能够在局部响应性和全局协调之间实现有利的交易，以最小的开销提供弹性优势。

Conclusion: 网段基础重路由策略为未来故障容锐卫星网络设计提供了有价值的见解，能在随机和目标故障条件下提高路由性能和弹性。

Abstract: Resilient routing in large-scale Low Earth Orbit (LEO) satellite networks
remains a key challenge due to frequent and unpredictable link and node
failures, potentially in response to cybersecurity breaches. While prior work
has explored rerouting strategies with various levels of network awareness,
their relative tradeoffs under dynamic failure conditions remain underexplored.
In this work, we extend the Deep Space Network Simulator (DSNS) to
systematically compare three rerouting paradigms, each differing in the scope
of failure knowledge available to each node. We compare local neighbor-based,
segment-based and global-knowledge-based rerouting as well as a naive source
routing solution that is unaware of failures. Our main goal is to evaluate how
the breadth of failure awareness impacts routing performance and resilience
under failures, both random and targeted. We measure delivery ratio, latency,
rerouting overhead, and loop occurrence. Our findings show the potential of
segment-based rerouting to achieve a favorable tradeoff between local
responsiveness and global coordination, offering resilience benefits with
minimal overhead--insights that can inform future fault-tolerant satellite
network design.

</details>


### [6] [Friend or Foe? Identifying Anomalous Peers in Moneros P2P Network](https://arxiv.org/abs/2509.10214)
*Yannik Kopyciok,Stefan Schmid,Friedhelm Victor*

Main category: cs.NI

TL;DR: 香港币Monero的P2P网络存在异常节点行为，约14.74%节点呈现非标准行为，可能存在多重攻击，影响隐私保障和网络去中心化。


<details>
  <summary>Details</summary>
Motivation: 目前对香港币P2P网络中异常节点行为的检测和分析理解有限，需要系统性研究来识别和分析这些异常行为。

Method: 从全球5个不同观测点收集超240小时的网络流量，建立正式框架来定义和分类P2P加密货币网络中的异常模式，并实现为离线分析方法。

Result: 发现约14.74%（13.19%）的可达节点呈现非标准行为，这些节点呈现出特定的行为模式，可能表明存在多重并发攻击，显示了Monero在隐私保障和网络去中心化方面的重大缺陷。

Conclusion: 研究揭示了Monero网络中存在实质性的安全风险，提供的检测流水线可以帮助网络运营商识别和阻塞可疑节点，以保护网络安全。

Abstract: Monero, the leading privacy-focused cryptocurrency, relies on a peer-to-peer
(P2P) network to propagate transactions and blocks. Growing evidence suggests
that non-standard nodes exist in the network, posing as honest nodes but are
perhaps intended for monitoring the network and spying on other nodes. However,
our understanding of the detection and analysis of anomalous peer behavior
remains limited. This paper presents a first comprehensive study of anomalous
behavior in Monero's P2P network. To this end, we collected and analyzed over
240 hours of network traffic captured from five distinct vantage points
worldwide. We further present a formal framework which allows us to
analytically define and classify anomalous patterns in P2P cryptocurrency
networks. Our detection methodology, implemented as an offline analysis,
provides a foundation for real-time monitoring systems. Our analysis reveals
the presence of non-standard peers in the network where approximately 14.74%
(13.19%) of (reachable) peers in the network exhibit non-standard behavior.
These peers exhibit distinct behavioral patterns that might suggest multiple
concurrent attacks, pointing to substantial shortcomings in Monero's privacy
guarantees and network decentralization. To support reproducibility and enable
network operators to protect themselves, we release our examination pipeline to
identify and block suspicious peers based on newly captured network traffic.

</details>


### [7] [RFSeek and Ye Shall Find](https://arxiv.org/abs/2509.10216)
*Noga H. Rotman,Tiago Ferreira,Hila Peleg,Mark Silberstein,Alexandra Silva*

Main category: cs.NI

TL;DR: RFSeek是一个基于大语言模型的交互工具，能够从RFC文档中自动提取协议逻辑的可视化摘要，生成可追溯来源的交互式图表，帮助更好地理解网络协议规范。


<details>
  <summary>Details</summary>
Motivation: RFC文档篇幅冗长且采用散文式描述，阻碍了对网络协议操作逻辑的精确理解，需要更直观的可视化工具来提升协议理解效率。

Method: 利用大语言模型(LLMs)自动生成可追溯来源的可探索图表，提取RFC文本中的状态机和附加逻辑，支持用户自定义可视化。

Result: RFSeek不仅能够重建RFC规范中的现有图表，还能发现文本中描述但图表中缺失的重要逻辑节点和边，为复杂协议(如QUIC)生成新的可视化图表。

Conclusion: 结合大语言模型和形式化、用户自定义可视化的摘要可视化方法，为增强协议理解和支持健壮实现提供了有前景的方向。

Abstract: Requests for Comments (RFCs) are extensive specification documents for
network protocols, but their prose-based format and their considerable length
often impede precise operational understanding. We present RFSeek, an
interactive tool that automatically extracts visual summaries of protocol logic
from RFCs. RFSeek leverages large language models (LLMs) to generate
provenance-linked, explorable diagrams, surfacing both official state machines
and additional logic found only in the RFC text. Compared to existing RFC
visualizations, RFSeek's visual summaries are more transparent and easier to
audit against their textual source. We showcase the tool's potential through a
series of use cases, including guided knowledge extraction and semantic
diffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.
  In practice, RFSeek not only reconstructs the RFC diagrams included in some
specifications, but, more interestingly, also uncovers important logic such as
nodes or edges described in the text but missing from those diagrams. RFSeek
further derives new visualization diagrams for complex RFCs, with QUIC as a
representative case. Our approach, which we term \emph{Summary Visualization},
highlights a promising direction: combining LLMs with formal, user-customized
visualizations to enhance protocol comprehension and support robust
implementations.

</details>


### [8] [Trusted Repeater Placement in QKD-enabled Optical Networks](https://arxiv.org/abs/2509.10338)
*Arup Kumar Marik,Basabdatta Palit,Sadananda Behera*

Main category: cs.NI

TL;DR: 量子密钥分配网络中的可靠性感知信任中继节点布置框架，通过结合信任评分和中心性指标来最大化安全连通性。


<details>
  <summary>Details</summary>
Motivation: 现有量子中继网络假设所有中继节点都可信，忽略了软件漏洞和内部威胁带来的风险。

Method: 提出一种可靠性感知的TRN布置框架，给每个节点赋予信任评分，并通过权重链路集成到Dijkstra算法中。使用中心性和特征向量中心性的综合得分对节点进行排名。

Result: 在参考拓扑结构上的模拟显示，使用同样数量（约8个）TRN时，本方法比传统的度中心性指标覆盖了更多的最短路径（10.77%）。

Conclusion: 该方法适用于TRN选择，能够最大化安全连通性，提高量子密钥分配网络的可靠性和安全性。

Abstract: Quantum Key Distribution (QKD) provides information-theoretic security, but
is limited by distance in optical networks, thereby requiring repeater nodes to
extend coverage. Existing works usually assume all repeater nodes and
associated Key Management Servers (KMSs) to be Trusted Repeater Nodes (TRNs),
while ignoring risks from software exploits and insider threats. In this paper,
we propose a reliability-aware TRN placement framework for metro optical
networks, which assigns each node a trust score and integrates it into the
Dijkstra algorithm via weighted links. We then rank the nodes using a composite
score, which is a weighted combination of betweenness centrality and
eigenvector centrality to enable a secure and scalable TRN deployment.
Simulation results on a reference topology show that our method covers 10.77%
more shortest paths compared to traditional metrics like degree centrality,
using the same number (around eight) of TRNs, making it suitable for TRN
selection to maximize secure connectivity.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND LLM平台可将IND申请的非临床总结初稿撰写时间减少约97%，从约100小时降至3-4小时，质量评分达70-78%，无关键监管错误，但仍需专家完善以达提交质量。


<details>
  <summary>Details</summary>
Motivation: IND申请准备耗时且依赖专业知识，减缓早期临床开发进程，需要评估LLM是否能加速起草过程同时保持文档质量。

Method: 直接记录AutoIND生成IND非临床书面总结的时间，与经验丰富的监管撰写者的手动起草时间比较；由盲审监管撰写评估员使用7个预设类别评估质量。

Result: 起草时间减少约97%（从~100小时降至3.7小时和2.6小时），质量评分分别为69.6%和77.9%，无关键监管错误，但在重点强调、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草，但专家监管撰写者对于将输出完善至提交质量仍至关重要；系统性缺陷为针对性模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [10] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: Boldsea是一个基于语义事件方法的架构，使用可执行本体来建模复杂动态系统，解决了传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统业务流程管理系统和面向对象语义技术在动态系统建模中的局限性，提供更好的运行时模型修改能力和时间透明度。

Method: 提出BSL语义语言及其BNF语法，设计boldsea-engine架构，直接解释语义模型作为可执行算法，无需编译。

Result: 实现了事件模型的运行时修改、时间透明度保证，以及数据和业务逻辑在统一语义框架内的无缝集成。

Conclusion: Boldsea架构通过语义事件方法和可执行本体，为复杂动态系统建模提供了更灵活、透明的解决方案。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [11] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 该研究评估了大语言模型(LLMs)和视觉语言模型(VLMs)在符号、语言和连续控制环境中提供规划反馈的能力，发现基础模型能提供高质量反馈，但复杂动态和连续空间会降低反馈质量。


<details>
  <summary>Details</summary>
Motivation: 传统规划学习需要精心设计的奖励函数或高质量标注演示，而预训练基础模型包含的背景知识可以减少对奖励设计和演示的需求，因此需要系统评估这些模型提供规划反馈的能力。

Method: 在符号、语言和连续控制环境中评估LLMs和VLMs的反馈能力，包括二元反馈、偏好反馈、动作建议、目标建议和增量动作反馈等多种反馈类型，并测试上下文学习、思维链和环境动态访问等推理方法。

Result: 基础模型能够跨领域提供多样化高质量反馈；更大和具备推理能力的模型反馈更准确、偏见更少，且能从增强推理方法中获益更多；但在复杂动态或连续状态动作空间中反馈质量会下降。

Conclusion: 预训练基础模型是规划任务中有价值的反馈来源，模型规模和推理能力对反馈质量有重要影响，但在处理复杂环境时仍存在挑战。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [12] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 提出模块化多模态框架，利用生成式AI从公开住宅信息和图像生成能源建模所需数据，解决数据获取难题


<details>
  <summary>Details</summary>
Motivation: 计算模型需要大量数据，但部分数据难以获取、成本高昂或存在隐私问题，阻碍能源建模研究的发展

Method: 开发模块化多模态框架，使用生成式人工智能从公开的住宅信息和图像中生成所需数据，并提供完整的实现流程

Result: 实验表明该框架能避免生成模型的常见问题，产生真实且标注良好的数据

Conclusion: 通过减少对昂贵或受限数据源的依赖，为更易获取和可重复的研究铺平道路

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [13] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了自动形式化（autoformalization）领域的发展，包括数学定理证明和更广泛的非正式语言到形式逻辑表示的转换，提出了统一框架以促进跨领域合作。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习和大语言模型的进步，自动形式化技术快速发展，但相关研究领域独立发展，缺乏共享的方法论、基准和理论框架，限制了该领域的整体进展。

Method: 通过回顾显性或隐性的自动形式化实例，分析不同领域的研究成果，并提出统一的框架来整合这些分散的研究方向。

Result: 识别了自动形式化在数学定理证明和其他形式化任务中的广泛应用，揭示了当前研究领域的碎片化状态。

Conclusion: 需要建立统一的框架来促进不同领域间的交叉融合，加速下一代AI系统的发展，通过共享方法论和基准来推动自动形式化技术的进步。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [14] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 该研究开发了一个基于RAG的智能知识助手系统，专门用于山羊养殖健康管理，通过结构化知识处理方法提升LLM对异构数据的理解能力，在验证集和测试集上分别达到87.90%和84.22%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业应用受限，主要由于知识源的可用性、多样性和复杂性限制，需要开发专门的知识助手系统来支持山羊养殖的健康管理。

Method: 采用检索增强生成(RAG)技术，提出表格文本化和决策树文本化两种结构化知识处理方法，建立覆盖五个关键领域的山羊养殖知识库，并集成在线搜索模块实现实时信息检索。

Result: 异构知识融合方法取得最佳效果，验证集准确率87.90%，测试集84.22%。在文本、表格、决策树问答任务中准确率均超过85%，验证了模块化设计中结构化知识融合的有效性。

Conclusion: 研究结果表明该系统在山羊养殖实际应用中具有鲁棒性和可靠性，错误分析显示遗漏是主要错误类型，为进一步提高检索覆盖率和上下文整合提供了改进方向。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [15] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 本文研究了LLM在UNO游戏中作为助手的能力，发现虽然所有模型都能超越随机基准，但只有少数能显著帮助其他玩家获胜


<details>
  <summary>Details</summary>
Motivation: 测试LLM作为主动参与者是否能真正帮助人类完成目标，特别是在协作性任务中的表现

Method: 构建工具让decoder-only LLM在RLCard游戏环境中作为代理参与UNO游戏，使用两种不同的提示策略，评估从1B到70B不同规模的模型

Result: 所有模型在玩UNO时都能成功超越随机基准，但只有少数模型能够显著帮助其他玩家获胜

Conclusion: LLM在协作性任务中的帮助能力有限，模型规模对性能有影响但并非决定性因素

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [16] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 这篇论文提出了一个概念框架，通过从静态到智能、单体到群体的两维进化路径，将现有工作流管理系统发展为全自主分布式科学实验室，以实现100倍科学发现加速。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式设施和异构资源，使得研究人员变成手动工作流协调者而非科学家。AI动力组件有期待加速科学发现，但需要明确如何在实际中实现和集成。

Method: 提出一个概念框架，通过智能程度（静态到智能）和组成方式（单体到群体）两个维度来描述工作流的进化路径，并提出对应的架构蓝图。

Result: 论文提出了一个从当前工作流管理系统向全自主分布式科学实验室进化的路线图，为社区提供了取向自主科学的下一步发展方向。

Conclusion: 通过智能化和群体化的进化路径，可以实现转型性的科学工作流，并有潜力实现100倍的科学发现加速。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [17] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse重构为马尔可夫决策过程，分离局部约束满足和全局目标优化，相比传统联合优化方法在复杂任务中表现更优


<details>
  <summary>Details</summary>
Motivation: 解决程序化内容生成中需要同时满足设计者指定目标和瓦片集隐含邻接约束的挑战

Method: 将WaveFunctionCollapse重新表述为马尔可夫决策过程(MDP)，利用WFC的传播机制强制执行约束满足，让外部优化算法专注于目标最大化

Result: 在多个不同难度的领域中，联合优化方法随着任务复杂度增加而表现不佳，始终劣于基于WFC-MDP的优化方法

Conclusion: 将局部约束满足与全局目标优化解耦具有明显优势，WFC-MDP方法在复杂内容生成任务中表现更优

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [18] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 提出基于实际因果关系的变量重要性度量方法，评估XAI工具性能，并开发了优于现有黑盒XAI工具的新工具B-ReX


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI(XAI)方法具有挑战性，特别是在表格数据和布尔函数预测场景下

Method: 基于实际因果关系提出形式化的变量重要性度量，开发新的XAI工具B-ReX（基于现有ReX工具改进），并在大规模基准测试中评估

Result: B-ReX在随机10值布尔公式上实现了0.072±0.012的Jensen-Shannon散度，优于其他黑盒XAI工具

Conclusion: 提出的基于实际因果关系的度量方法有效，B-ReX工具在布尔函数预测场景下表现出优越性能

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [19] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA是一个保护隐私的多智能体系统，通过将工作空间分为私有和公共区域，使用匿名化机制保护敏感数据，同时通过知识增强和逻辑增强模块减少语义损失。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多智能体系统中的广泛应用，当任务涉及隐私数据时，需要在不牺牲性能的前提下实现隐私保护。现有系统缺乏有效的隐私保护机制。

Method: 提出GAMA系统，划分私有和公共空间，私有空间处理敏感数据，公共空间使用匿名化数据。包含DRKE（基于领域规则的知识增强）和DLE（基于反证的逻辑增强）两个关键模块来减少匿名化带来的语义损失。

Result: 在两个公开问答数据集（Trivia Creative Writing和Logic Grid Puzzle）上表现优于最先进模型。在专门设计的隐私保护数据集（Knowledge Privacy Preservation和Logic Privacy Preservation）上也显示出卓越的隐私保护效果。

Conclusion: GAMA系统在保持任务处理性能的同时，有效实现了隐私保护，为隐私敏感的多智能体应用提供了可行的解决方案。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [20] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体协作框架，用于解决复杂任务规划中的不确定性，在知识型和逻辑型问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提升了多智能体系统的能力，但在处理高度复杂且具有不确定性的任务时，仍面临任务规划效率低下、容易产生误导性输出的挑战。

Method: 构建多极任务处理图实现动态任务规划，集成领域特定的IF-THEN规则约束智能体行为，使用全局规则增强智能体间协作。

Result: 在三个不同数据集上的评估显示，XAgents在知识型和逻辑型问答任务中持续超越最先进的单智能体和多智能体方法。

Conclusion: XAgents框架通过创新的多极任务处理图和规则集成机制，有效解决了复杂任务规划中的不确定性挑战，为多智能体系统提供了更可靠的任务执行能力。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [21] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了AI Harmonics框架，采用基于实证事件数据的人类中心、危害严重性自适应方法，通过新的AI危害评估指标(AIH)来识别和优先处理AI危害，特别关注政治和物理危害的紧急缓解需求。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型主要关注内部合规性，忽视了不同利益相关者视角和现实世界后果，无法有效应对AI带来的前所未有的社会危害和风险。

Method: 提出了AI Harmonics框架，包括新颖的AI危害评估指标(AIH)，利用序数严重性数据捕捉相对影响，无需精确数值估计，结合稳健的通用方法和数据驱动的利益相关者感知框架。

Result: 在标注事件数据上的实验证实，政治和物理危害具有最高的集中度，需要紧急缓解：政治危害侵蚀公众信任，物理危害构成严重甚至危及生命的风险。

Conclusion: AI Harmonics能够一致性地识别不均匀的危害分布，使政策制定者和组织能够有效针对性地开展缓解工作，证明了该方法在现实世界中的相关性。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [22] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 本文提出"沙箱经济"框架分析AI自主代理人经济系统，讨论了其潜在机遇与风险，并提出通过竞价机制、任务经济和社会技术基础设施来实现可控经济市场的设计选择。


<details>
  <summary>Details</summary>
Motivation: 随着AI自主代理人的快速采用，一个新的经济层正在形成，代理人之间的交易和协调规模超越了人类直接监管能力。需要一个框架来分析这种出现的系统，并探讨如何主动设计以确保其与人类长期福祷相一致。

Method: 提出了"沙箱经济"分析框架，从两个关键维度进行特征化：起源（出现式vs意图式）和与人类经济的分离程度（可透性vs不可透性）。考虑了多种设计选择，包括公平资源分配的竞价机制、协调集体目标的AI"任务经济"设计，以及确保信任、安全和责任制的社会技术基础设施。

Result: 当前发展趋势指向一个自发出现的广泛且高度可透性的AI代理人经济，这为我们提供了前所未有的协调机会，同时也带来了系统性经济风险和加剧不平等的重大挑战。

Conclusion: 应该主动设计可控的AI代理人市场，通过算法机制、经济结构和社会技术基础设施的设计选择，确保即将来临的技术变革与人类长期集体福祷相一致。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [23] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了Robust Sparse Sampling (RSS)算法，这是首个具有有限样本理论性能保证的在线鲁棒MDP规划算法，能够在模型不确定环境下实现可处理的实时鲁棒策略计算。


<details>
  <summary>Details</summary>
Motivation: 在线规划方法在数据驱动的生成模型中存在近似误差，可能导致性能下降或不安全行为，而现有的鲁棒MDP方法计算量大，不适合实时应用。

Method: 基于Sample Average Approximation (SAA)的高效性和理论特性，通过计算鲁棒价值函数而非名义价值函数，开发了Robust Sparse Sampling算法。

Result: RSS适用于无限或连续状态空间，其样本和计算复杂度与状态空间大小无关，在不确定动态环境中优于标准稀疏采样方法。

Conclusion: RSS为在线鲁棒规划提供了首个具有理论保证的实用算法，解决了模型不确定性下的安全高效决策问题。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [24] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 提出基于LLM的多智能体框架，用于自动化多孔材料表征，包括文献提取力场参数和自动设置RASPA模拟


<details>
  <summary>Details</summary>
Motivation: 自动化多孔材料表征可加速材料发现，但受限于模拟设置和力场选择的复杂性

Method: 使用LLM智能体自主理解表征任务、规划模拟、组装力场、执行模拟并解释结果来指导后续步骤

Result: 初步评估显示具有高正确性和可重现性

Conclusion: 该方法有潜力实现完全自主、可扩展的材料表征

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [25] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI是一个用于临床自然语言推理的模块化代理推理框架，通过将知识访问与原则推理分离，显著提高了推理准确性和可审计性


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床NLI中虽然拥有相关知识但倾向于使用启发式方法进行推理的问题，提供更安全、可审计的推理框架

Method: 提出CARENLI框架，将推理任务分解为四个推理家族（因果归因、组合基础、认知验证、风险状态抽象），使用特定家族求解器，并通过规划器、验证器和精炼器强制执行可审计程序

Result: 在四个LLM上，CARENLI将推理保真度提高了最多42个百分点，在因果归因中达到98.0%，在风险状态抽象中达到81.2%。验证器以接近顶级的可靠性标记违规，精炼器纠正了大量认知错误

Conclusion: LLMs通常保留相关事实但在推理不明确时默认使用启发式方法，CARENLI通过显式分离知识访问和推理，为更安全、可审计的临床推理提供了框架

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [26] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 这篇论文研究了小型语言模型在逻辑推理任务中的表现，探索用更简洁的逻辑语言替代自然语言对推理性能的影响，以支持本体工程应用。


<details>
  <summary>Details</summary>
Motivation: 语言模型在推理能力方面的不足影响了本体工程等任务的性能，需要探索如何通过形式方法提升小型语言模型的推理能力。

Method: 通过一系列预实验，测试不同语法表达逻辑问题对小型语言模型在预定义推理任务上表现的影响，比较自然语言和更简洁逻辑语言的效果。

Result: 发现可以用更简洁的逻辑语言替代自然语言，同时保持强劲的推理任务表现，这为小型语言模型在本体工程中的应用提供了基础。

Conclusion: 研究结果表明通过使用更简洁的逻辑语言可以在保持推理性能的同时优化小型语言模型的表现，这为未来在本体工程中更精细地定义小型语言模型的作用提供了可能性。

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [27] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 这篇论文通过实验研究大型语言模型的道德偏好，发现所有模型都一致偏向关怀和美德价值，而自由主义选择被罚，强调了解释性和文化意识对实现AI与人类共生的重要性


<details>
  <summary>Details</summary>
Motivation: 研究AI系统如何与人类道德价值对齐的紧迫问题，探索先进AI系统在道德困境中的隐式价值偏好和影响因素

Method: 对六个大型语言模型进行定量实验，通过18个代表五种道德框架的困境进行结果排名和评分

Result: 发现所有模型存在显著一致的价值偏见：关怀和美德价值被评为最道德，自由主义选择一贵被罚。推理能力强的模型对语境更敏感且解释更丰富，而无推理能力的模型判断更匀匀但不透明

Conclusion: 研究在实证、理论和实践三方面做出贡献，强调解释性和文化意识是引导AI向透明、对齐和共生未来的关键设计原则

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [28] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个基于代数方法表示和操作命题逻辑的新框架，包含Set、Coordinate和Row Decomposition三个层次表示，在保持语义清晰的同时支持高效计算。


<details>
  <summary>Details</summary>
Motivation: 开发一个灵活的代数框架来统一表示和操作命题逻辑，为搜索算法和知识编译提供工具支持，并扩展到概率逻辑和加权模型计数。

Method: 采用三层表示结构（Set、Coordinate、Row Decomposition），通过代数引擎进行计算，允许在变量顺序固定的情况下获得规范形式，但在默认情况下牺牲规范性以获得表示灵活性。

Result: 框架能够更紧凑地表示某些问题类别，提供了表达搜索算法和知识编译算法的工具，并支持向概率逻辑和加权模型计数的自然扩展。

Conclusion: State Algebra通过代数方法为命题逻辑处理提供了灵活高效的框架，在规范性和表示紧凑性之间取得了良好平衡，具有扩展到更复杂逻辑问题的潜力。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [29] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding框架通过结构化因果推理方法，将多智能体系统中的故障归因从模式识别任务转化为因果推断任务，显著提高了步骤级准确率（2.85倍提升）。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统中的故障归因方法准确率极低（低于17%），无法进行有效的反事实推理来确定纠正单个动作是否能避免任务失败，这限制了复杂系统的调试能力。

Method: 提出了Abduct-Act-Predict (A2P) Scaffolding框架，通过三个结构化步骤指导大语言模型进行推理：(1)溯因推理推断行动背后的根本原因；(2)定义最小纠正干预；(3)模拟后续轨迹验证干预效果。

Result: 在Algorithm-Generated数据集上达到47.46%的步骤级准确率（比基线的16.67%提升2.85倍），在更复杂的Hand-Crafted数据集上达到29.31%准确率（比基线的12.07%提升2.43倍）。

Conclusion: 通过因果推理的视角重构问题，A2P Scaffolding为自动化故障归因提供了更鲁棒、可验证且准确度显著提升的解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [30] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 该论文提出了一个信息论框架，通过分析状态-动作互信息模式来检测和诊断RL代理在部署时的异常，能够区分传感器故障和驱动器故障。


<details>
  <summary>Details</summary>
Motivation: 现实世界中部署的RL代理面临传感器故障、驱动器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障。

Method: 使用信息论框架分析状态-动作互信息模式，通过控制扰动实验验证信息指标对不同类型系统故障的诊断能力。

Result: 成功学习表现出特征性信息签名：状态-动作互信息从0.84增长到2.83比特（238%增长）；信息指标能够区分传感器故障（广泛崩溃所有信息通道）和驱动器故障（选择性破坏动作-结果可预测性）。

Conclusion: 信息模式既是学习的特征，也是系统健康的诊断工具，为能够基于信息论原理进行自主故障检测和策略调整的自适应RL系统奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [31] [Several new classes of optimal p-ary cyclic codes](https://arxiv.org/abs/2509.09951)
*Mengen Fang,Lanqiang Li,Fuyin Tian,Li Liu*

Main category: cs.IT

TL;DR: 构建三类新的最优p进制循环码，参数为[p^m-1, p^m-2m-2, 4]，具有应用价值


<details>
  <summary>Details</summary>
Motivation: 循环码在通信系统、数据存储系统和消费电子中有广泛应用，需要构建更多最优码类以满足实际需求

Method: 使用代数方法构建新的p进制循环码类，定义参数s=(p^m+1)/2和t(2≤t≤p^m-2)

Result: 成功构建了三类新的最优p进制循环码，当p=5时还获得四类新的最优循环码

Conclusion: 这些新构造的最优循环码类扩展了循环码的类别，对于p=5的情况还包含了已知的最优五进制循环码

Abstract: Cyclic codes, as a crucial subclass of linear codes, exhibit broad
applications in communication systems, data storage systems, and consumer
electronics, primarily attributed to their well-structured algebraic
properties. Let $p$ denote an odd prime with $p\geq5$, and let $m$ be a
positive integer. The primary objective of this paper is to construct three
novel classes of optimal $p$-ary cyclic codes, denoted as
${\mathcal{C}_p}(0,s,t)$, which possess the parameters $[{p^m} - 1,{p^m} - 2m -
2,4]$. Here, $s$ is defined as $s = \frac{{{p^m}+1}}{{2}}$, and $t$ satisfies
the condition $2 \le t \le {p^m} - 2$. Notably, one of the constructed classes
includes certain known optimal quinary cyclic codes as special cases.
Furthermore, for the specific case when $p=5$, this paper additionally presents
four new classes of optimal cyclic codes ${\mathcal{C}_5}(0,s,t)$.

</details>


### [32] [Semantic Rate-Distortion Theory with Applications](https://arxiv.org/abs/2509.10061)
*Yi-Qun Zhao,Zhi-Ming Ma,Geoffrey Ye Li,Shuai Yuan,Tong Ye,Chuan Zhou*

Main category: cs.IT

TL;DR: 本文提出了一个基于条件语义概率失真约束的语义压缩率失真框架，解决了现有语义通信中忽略语义模糊性和多义性的问题，建立了AI辅助通信系统中的最小可达速率定理。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信工作主要关注解码端对内在含义的估计，但忽略了语义的模糊性和多义性等固有问题。为了有效捕捉AI辅助通信系统中实际语义交换的本质特征，需要开发新的语义压缩框架。

Method: 利用率失真-感知理论的方法，建立了一个在语义约束和传统符号约束下的最小可达速率定理，并获得了特定语义场景下的闭式极限。通过约束条件语义概率失真来改进语义传输。

Result: 实验表明，约束条件语义概率失真能有效提高语义传输准确性和比特率效率。该框架在带宽高效的语义感知网络、增强的收发器理解和AI驱动系统的优化语义传输等方面具有潜在应用价值。

Conclusion: 本文建立的框架连接了信息论和人工智能，为语义通信提供了理论基础和实践指导，解决了语义模糊性问题，提高了通信效率。

Abstract: Artificial intelligence (AI) is ushering in a new era for communication. As a
result, the establishment of a semantic communication framework is putting on
the agenda. Based on a realistic semantic communication model, this paper
develops a rate-distortion framework for semantic compression. Different from
the existing works primarily focusing on decoder-side estimation of intrinsic
meaning and ignoring its inherent issues, such as ambiguity and polysemy, we
exploit a constraint of conditional semantic probability distortion to
effectively capture the essential features of practical semantic exchanges in
an AI-assisted communication system. With the help of the methods in
rate-distortion-perception theory, we establish a theorem specifying the
minimum achievable rate under this semantic constraint and a traditional
symbolic constraint and obtain its closed-form limit for a particular semantic
scenario. From the experiments in this paper, bounding conditional semantic
probability distortion can effectively improve both semantic transmission
accuracy and bit-rate efficiency. Our framework bridges information theory and
AI, enabling potential applications in bandwidth-efficient semantic-aware
networks, enhanced transceiver understanding, and optimized semantic
transmission for AI-driven systems.

</details>


### [33] [Analog Over-the-Air Federated Learning with Interference-Based Energy Harvesting](https://arxiv.org/abs/2509.10123)
*Ahmad Massud Tota Khel,Aissa Ikhlef,Zhiguo Ding,Hongjian Sun*

Main category: cs.IT

TL;DR: 这篇论文提出了一种无需频道状态信息的去噪策略和适应性调度算法，用于汇集能量的模拟空中联邦学习系统，有效缓解同频干扰并提升学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决模拟空中联邦学习中设备从带内外射频信号获取能量时遍历的同频干扰问题，以及因能量限制导致的设备参与率低问题。

Method: 提出了一种无需频道状态信息的有效去噪策略，以及基于可用能量动态调整本地训练迭代次数的适应性调度算法。

Result: 模拟结果和收敛分析证实了算法的稳健性能，去噪方法性能可与传统方法相比，适应算法能够通过增加活跃设备数量来缓解高力率同频干扰的负面影响。

Conclusion: 该方法能够在不需要频道状态信息的情况下有效缓解同频干扰问题，同时通过动态调整本地训练过程来提升设备参与度和学习性能，减少能量消耗。

Abstract: We consider analog over-the-air federated learning, where devices harvest
energy from in-band and out-band radio frequency signals, with the former also
causing co-channel interference (CCI). To mitigate the aggregation error, we
propose an effective denoising policy that does not require channel state
information (CSI). We also propose an adaptive scheduling algorithm that
dynamically adjusts the number of local training epochs based on available
energy, enhancing device participation and learning performance while reducing
energy consumption. Simulation results and convergence analysis confirm the
robust performance of the algorithm compared to conventional methods. It is
shown that the performance of the proposed denoising method is comparable to
that of conventional CSI-based methods. It is observed that high-power CCI
severely degrades the learning performance, which can be mitigated by
increasing the number of active devices, achievable via the adaptive algorithm.

</details>


### [34] [Cooperative Base Station Assignment and Resource Allocation for 6G ISAC Network](https://arxiv.org/abs/2509.10240)
*Jiajia Liao,Luping Xiang,Shida Zhong,Lixia Xiao,Haochen Liu,Kun Yang*

Main category: cs.IT

TL;DR: 本文提出了一种用于6G网络中集成感知与通信的多基站协作分配和资源分配策略，通过交替优化算法解决非凸优化问题，实现了通信速率117%和感知精度40%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 6G网络中集成感知与通信(ISAC)需要在数据传输和多目标感知方面提供综合服务，需要优化通信和感知性能的协同方案。

Method: 提出协作基站分配和资源分配(CBARA)策略，推导后验克拉美罗下界和可达速率作为优化准则，开发启发式交替优化算法解决多耦合变量导致的非凸优化问题。

Result: 数值结果显示，与经典方案相比，所提方案在通信速率上提升117%，在感知精度上提升40%。

Conclusion: 所提出的CBARA策略有效提升了6G网络中集成感知与通信系统的性能，为多基站架构下的资源优化提供了有效解决方案。

Abstract: In the upcoming 6G networks, integrated sensing and communications (ISAC)
will be able to provide a performance boost in both perception and wireless
connectivity. This paper considers a multiple base station (BS) architecture to
support the comprehensive services of data transmission and multi-target
sensing. In this context, a cooperative BS assignment and resource allocation
(CBARA) strategy is proposed in this paper, aiming at jointly optimizing the
communication and sensing (C&S) performance. The posterior Cramer-Rao lower
bound and the achievable rate with respect to transmit power and bandwidth are
derived and utilized as optimization criteria for the CBARA scheme. We develop
a heuristic alternating optimization algorithm to obtain an effective
sub-optimal solution for the non-convex optimization problem caused by multiple
coupled variables. Numerical results show the effectiveness of the proposed
solution, which achieves a performance improvement of 117% in communication
rate and 40% in sensing accuracy, compared to the classic scheme.

</details>


### [35] [Large-scale Aerial Reconfigurable Intelligent Surface-aided Robust Anti-jamming Transmission](https://arxiv.org/abs/2509.10280)
*Junshan Luo,Shilian Wang,Boxiang He*

Main category: cs.IT

TL;DR: 提出了一种基于平均场建模的ARIS空间配置方法，通过连续密度函数设计无人机载可重构智能表面部署，解决了传统离散优化方法计算复杂度高的问题，有效对抗自适应干扰。


<details>
  <summary>Details</summary>
Motivation: 大规模无人机载可重构智能表面(ARIS)面临传统离散优化方法计算复杂度高和复杂干扰威胁的部署挑战，需要开发高效的抗干扰通信框架。

Method: 采用平均场建模方法将ARIS空间配置表示为连续密度函数，结合变分优化和黎曼流形方法，联合优化基站波束成形、ARIS反射和空间分布，最大化最差情况下的和速率。

Result: 仿真结果表明所提框架显著提高了和速率，且算法计算复杂度与无人机数量无关，验证了其在大规模ARIS辅助抗干扰通信中的有效性。

Conclusion: 提出的连续密度函数方法和空间注水部署原则为大规模ARIS抗干扰通信提供了高效可扩展的解决方案，揭示了干扰器的最优策略受距离-方向性权衡的支配。

Abstract: Aerial reconfigurable intelligent surfaces (ARIS), deployed on unmanned
aerial vehicles (UAVs), could enhance anti-jamming communication performance by
dynamically configuring channel conditions and establishing reliable air-ground
links. However, large-scale ARIS faces critical deployment challenges due to
the prohibitive computational complexity of conventional discrete optimization
methods and sophisticated jamming threats. In this paper, we introduce a mean
field modeling approach to design the spatial configuration of ARIS by a
continuous density function, thus bypassing high-dimensional combinatorial
optimization. We consider an adaptive jammer which adjusts its position and
beamforming to minimize the sum-rate. A key finding reveals that the jammer's
optimal strategy is governed by a proximity-directivity trade-off between
reducing path loss and enhancing spatial focusing. To combat the jamming, we
propose a robust anti-jamming transmission framework that jointly optimizes the
BS beamforming, the ARIS reflection, and the ARIS spatial distribution to
maximize the worst-case sum-rate. By leveraging variational optimization and
Riemannian manifold methods, we efficiently solve the functional optimization
problems. Our analysis further unveils that the optimal ARIS deployment follows
a spatial water-filling principle, concentrating resources in high-gain regions
while avoiding interference-prone areas. Simulation results demonstrate that
the proposed framework remarkably improves the sum-rate. Furthermore, the
computational complexity of the proposed algorithm is independent of the number
of UAVs, validating its effectiveness for scalable ARIS-assisted anti-jamming
communications.

</details>


### [36] [Energy Efficiency for Massive MIMO Integrated Sensing and Communication Systems](https://arxiv.org/abs/2509.10290)
*Huy T. Nguyen,Van-Dinh Nguyen,Nhan Thanh Nguyen,Nguyen Cong Luong,Vo-Nguyen Quoc Bao,Hien Quoc Ngo,Dusit Niyato,Symeon Chatzinotas*

Main category: cs.IT

TL;DR: 本文研究大规模MIMO-ISAC系统的能量效率，通过求解闭形表达式和功率分配优化，开发了高效迭代算法来平衡通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: 研究大规模MIMO在集成感知与通信(ISAC)系统中的能量效率问题，平衡通信速率和感知精度的关系，以提高整体系统性能。

Method: 求解通信速率和Cramér-Rao界限的闭形表达式，形成能量效率优化问题，利用Dinkelbach算法和成功凸近似(SCA)技术进行迭代优化，并提出新的初始化策略。

Result: 模拟结果显示所提方法在性能上显著优于基准方法，当通信谱效率从4提高到8 bps/Hz时，整体能量效率减少16.7%，这在感知为主的场景中也显著影响整体性能。

Conclusion: 感知能量效率对整体ISAC系统性能有重要影响，尤其在高通信谱效率情况下。所提优化算法能够有效平衡通信和感知性能，提高系统效能。

Abstract: This paper explores the energy efficiency (EE) of integrated sensing and
communication (ISAC) systems employing massive multiple-input multiple-output
(mMIMO) techniques to leverage spatial beamforming gains for both communication
and sensing. We focus on an mMIMO-ISAC system operating in an orthogonal
frequency-division multiplexing setting with a uniform planar array,
zero-forcing downlink transmission, and mono-static radar sensing to exploit
multi-carrier channel diversity. By deriving closed-form expressions for the
achievable communication rate and Cram\'er-Rao bounds (CRBs), we are able to
determine the overall EE in closed-form. A power allocation problem is then
formulated to maximize the system's EE by balancing communication and sensing
efficiency while satisfying communication rate requirements and CRB
constraints. Through a detailed analysis of CRB properties, we reformulate the
problem into a more manageable form and leverage Dinkelbach's and successive
convex approximation (SCA) techniques to develop an efficient iterative
algorithm. A novel initialization strategy is also proposed to ensure
high-quality feasible starting points for the iterative optimization process.
Extensive simulations demonstrate the significant performance improvement of
the proposed approach over baseline approaches. Results further reveal that as
communication spectral efficiency rises, the influence of sensing EE on the
overall system EE becomes more pronounced, even in sensing-dominated scenarios.
Specifically, in the high $\omega$ regime of $2 \times 10^{-3}$, we observe a
16.7\% reduction in overall EE when spectral efficiency increases from $4$ to
$8$ bps/Hz, despite the system being sensing-dominated.

</details>
