{"id": "2601.00972", "categories": ["cs.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.00972", "abs": "https://arxiv.org/abs/2601.00972", "authors": ["Louay Bazzi"], "title": "Improved decoding algorithms for surface codes under independent bit-flip and phase-flip errors", "comment": null, "summary": "We study exact decoding for the toric code and for planar and rotated surface codes under the standard independent \\(X/Z\\) noise model, focusing on Separate Minimum Weight (SMW) decoding and Separate Most Likely Coset (SMLC) decoding. For the SMW decoding problem, we show that an \\(O(n^{3/2}\\log n)\\)-time decoder is achievable for surface and toric codes, improving over the \\(O(n^{3}\\log n)\\) worst-case time of the standard approach based on complete decoding graphs. Our approach is based on a local reduction of SMW decoding to the minimum weight perfect matching problem using Fisher gadgets, which preserves planarity for planar and rotated surface codes and genus~\\(1\\) for the toric code. This reduction enables the use of Lipton--Tarjan planar separator methods and implies that SMW decoding lies in \\(\\mathrm{NC}\\). For SMLC decoding, we show that the planar surface code admits an exact decoder with \\(O(n^{3/2})\\) algebraic complexity and that the problem lies in \\(\\mathrm{NC}\\), improving over the \\(O(n^{2})\\) algebraic complexity of Bravyi \\emph{et al.} Our approach proceeds via a dual-cycle formulation of coset probabilities and an explicit reduction to planar Pfaffian evaluation using Fisher--Kasteleyn--Temperley constructions. The same complexity measures apply to SMLC decoding of the rotated surface code. For the toric code, we obtain an exact polynomial-time SMLC decoder with \\(O(n^{3})\\) algebraic complexity. In addition, while the SMLC formulation is motivated by connections to statistical mechanics, we provide a purely algebraic derivation of the underlying duality based on MacWilliams duality and Fourier analysis. Finally, we discuss extensions of the framework to the depolarizing noise model and identify resulting open problems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8868\u9762\u7801\u548c\u73af\u9762\u7801\u5728\u72ec\u7acbX/Z\u566a\u58f0\u6a21\u578b\u4e0b\u7684\u7cbe\u786e\u89e3\u7801\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u89e3\u7801\u7b97\u6cd5\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u4e86SMW\u89e3\u7801\u5728NC\u7c7b\u4e2d\uff0cSMLC\u89e3\u7801\u4e5f\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u8868\u9762\u7801\u548c\u73af\u9762\u7801\u5728\u91cf\u5b50\u7ea0\u9519\u4e2d\u7684\u7cbe\u786e\u89e3\u7801\u95ee\u9898\uff0c\u65e8\u5728\u6539\u8fdb\u73b0\u6709\u89e3\u7801\u7b97\u6cd5\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7279\u522b\u662f\u9488\u5bf9\u72ec\u7acbX/Z\u566a\u58f0\u6a21\u578b\u4e0b\u7684SMW\u548cSMLC\u89e3\u7801\u95ee\u9898\u3002", "method": "\u91c7\u7528Fisher gadget\u5c06SMW\u89e3\u7801\u5c40\u90e8\u7ea6\u5316\u4e3a\u6700\u5c0f\u6743\u91cd\u5b8c\u7f8e\u5339\u914d\u95ee\u9898\uff0c\u4fdd\u6301\u5e73\u9762\u6027\uff1b\u5bf9SMLC\u89e3\u7801\u91c7\u7528\u5bf9\u5076\u73af\u8868\u8ff0\u548cFisher-Kasteleyn-Temperley\u6784\u9020\u7ea6\u5316\u4e3a\u5e73\u9762Pfaffian\u8ba1\u7b97\uff1b\u5229\u7528Lipton-Tarjan\u5e73\u9762\u5206\u9694\u65b9\u6cd5\u548cMacWilliams\u5bf9\u5076\u6027\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u5bf9\u4e8eSMW\u89e3\u7801\uff0c\u5b9e\u73b0\u4e86O(n^{3/2} log n)\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u89e3\u7801\u5668\uff0c\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5\u7684O(n^3 log n)\uff1b\u5bf9\u4e8eSMLC\u89e3\u7801\uff0c\u5e73\u9762\u8868\u9762\u7801\u5b9e\u73b0\u4e86O(n^{3/2})\u4ee3\u6570\u590d\u6742\u5ea6\uff0c\u73af\u9762\u7801\u5b9e\u73b0\u4e86O(n^3)\u4ee3\u6570\u590d\u6742\u5ea6\uff1b\u8bc1\u660e\u4e86SMW\u89e3\u7801\u5728NC\u7c7b\u4e2d\u3002", "conclusion": "\u672c\u6587\u4e3a\u8868\u9762\u7801\u548c\u73af\u9762\u7801\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u7cbe\u786e\u89e3\u7801\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5efa\u7acb\u4e86\u4e0e\u7edf\u8ba1\u529b\u5b66\u7684\u8054\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u5411\u53bb\u6781\u5316\u566a\u58f0\u6a21\u578b\u6269\u5c55\u7684\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2601.01079", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.01079", "abs": "https://arxiv.org/abs/2601.01079", "authors": ["Leilei Yu", "Yunghsiang S. Han", "Pingping Li", "Jiasheng Yuan"], "title": "A Novel Approach of Solving Polynomial Equations Over Binary Extension Fields", "comment": null, "summary": "Solving quadratic equations over finite fields is a fundamental task in algebraic coding theory and serves as a key subroutine for computing the roots of cubic and quartic polynomials. For the reduced quadratic polynomial $x^2+x+c\\in \\mathbb{F}_{2^m}[x]$, existing formula-based methods rely on heavy exponentiation or case distinctions on $m$ (odd/even or powers of two), which limits uniformity and efficiency. This paper presents a unified, formula-based solution for all positive integers $m$ that uses only exclusive-OR operations (XORs). The approach leverages a Reed-Muller matrix characterization of evaluations and reduces the problem to solving a binary linear system. The total cost is at most $m^2-2m+1$ XORs, and under parallelism, the latency is $\\lceil \\log_2 m\\rceil$ XORs, making the method attractive for low-power, low-latency applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u516c\u5f0f\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u7eaf\u5f02\u6216\u8fd0\u7b97\u6c42\u89e3\u6709\u9650\u57dfGF(2^m)\u4e0a\u7684\u4e8c\u6b21\u65b9\u7a0bx\u00b2+x+c=0\uff0c\u9002\u7528\u4e8e\u6240\u6709\u6b63\u6574\u6570m\uff0c\u65e0\u9700\u533a\u5206m\u7684\u5947\u5076\u6027\u3002", "motivation": "\u6709\u9650\u57df\u4e0a\u4e8c\u6b21\u65b9\u7a0b\u6c42\u89e3\u662f\u4ee3\u6570\u7f16\u7801\u7406\u8bba\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u4e5f\u662f\u8ba1\u7b97\u4e09\u6b21\u548c\u56db\u6b21\u591a\u9879\u5f0f\u6839\u7684\u5173\u952e\u5b50\u7a0b\u5e8f\u3002\u73b0\u6709\u516c\u5f0f\u5316\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6307\u6570\u8fd0\u7b97\u6216\u5bf9m\u7684\u5947\u5076\u6027\u8fdb\u884c\u533a\u5206\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u7edf\u4e00\u6027\u548c\u6548\u7387\u3002", "method": "\u5229\u7528Reed-Muller\u77e9\u9635\u5bf9\u8bc4\u4f30\u8fdb\u884c\u8868\u5f81\uff0c\u5c06\u95ee\u9898\u7b80\u5316\u4e3a\u6c42\u89e3\u4e8c\u5143\u7ebf\u6027\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u5f02\u6216\u8fd0\u7b97\uff0c\u65e0\u9700\u6307\u6570\u8fd0\u7b97\u6216\u5bf9m\u8fdb\u884c\u5947\u5076\u6027\u533a\u5206\u3002", "result": "\u8be5\u65b9\u6cd5\u603b\u6210\u672c\u6700\u591a\u4e3am\u00b2-2m+1\u6b21\u5f02\u6216\u8fd0\u7b97\uff0c\u5728\u5e76\u884c\u5316\u4e0b\u5ef6\u8fdf\u4ec5\u4e3a\u2308log\u2082 m\u2309\u6b21\u5f02\u6216\u8fd0\u7b97\uff0c\u9002\u5408\u4f4e\u529f\u8017\u3001\u4f4e\u5ef6\u8fdf\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u9ad8\u6548\u7684\u516c\u5f0f\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u7eaf\u5f02\u6216\u8fd0\u7b97\u6c42\u89e3GF(2^m)\u4e0a\u7684\u4e8c\u6b21\u65b9\u7a0b\uff0c\u9002\u7528\u4e8e\u6240\u6709\u6b63\u6574\u6570m\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5b9e\u73b0\u7b80\u5355\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2601.01137", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.01137", "abs": "https://arxiv.org/abs/2601.01137", "authors": ["Mohammad Rowshan"], "title": "Single-Shot and Few-Shot Decoding via Stabilizer Redundancy in Bivariate Bicycle Codes", "comment": "6 pages, 5 theorems, 5 figures", "summary": "Bivariate bicycle (BB) codes are a prominent class of quantum LDPC codes constructed from group algebras. While the logical dimension and quantum distance of \\emph{coprime} BB codes are known to be determined by a greatest common divisor polynomial $g(z)$, the properties governing their fault tolerance under noisy measurement have remained implicit. In this work, we prove that this same polynomial $g(z)$ dictates the code's stabilizer redundancy and the structure of the classical \\emph{syndrome codes} required for single-shot decoding. We derive a strict equality between the quantum rate and the stabilizer redundancy density, and we provide BCH-like bounds on the achievable single-shot measurement error tolerance. Guided by this framework, we construct small coprime BB codes with significantly improved syndrome distance ($d_S$) and evaluate them using BP+OSD. Our analysis reveals a structural bottleneck: within the coprime BB ansatz, high quantum rate imposes an upper bound on syndrome distance, limiting single-shot performance. These results provide concrete algebraic design rules for next-generation 2BGA codes in measurement-limited architectures.", "AI": {"tldr": "\u53cc\u53d8\u91cf\u81ea\u884c\u8f66\u7801(BB\u7801)\u662f\u91cf\u5b50LDPC\u7801\u7684\u91cd\u8981\u7c7b\u522b\uff0c\u672c\u6587\u8bc1\u660e\u5176\u5bb9\u9519\u6027\u80fd\u7531\u591a\u9879\u5f0fg(z)\u51b3\u5b9a\uff0c\u63ed\u793a\u4e86\u91cf\u5b50\u901f\u7387\u4e0e\u7a33\u5b9a\u5b50\u5197\u4f59\u5bc6\u5ea6\u4e4b\u95f4\u7684\u4e25\u683c\u7b49\u5f0f\u5173\u7cfb\uff0c\u5e76\u53d1\u73b0\u4e86\u9ad8\u91cf\u5b50\u901f\u7387\u4f1a\u9650\u5236\u7efc\u5408\u5f81\u8ddd\u79bb\u7684\u7ed3\u6784\u74f6\u9888\u3002", "motivation": "\u867d\u7136\u4e92\u8d28BB\u7801\u7684\u903b\u8f91\u7ef4\u5ea6\u548c\u91cf\u5b50\u8ddd\u79bb\u5df2\u77e5\u7531\u6700\u5927\u516c\u7ea6\u6570\u591a\u9879\u5f0fg(z)\u51b3\u5b9a\uff0c\u4f46\u5176\u5728\u566a\u58f0\u6d4b\u91cf\u4e0b\u7684\u5bb9\u9519\u7279\u6027\u4ecd\u4e0d\u660e\u786e\u3002\u9700\u8981\u7406\u89e3g(z)\u5982\u4f55\u5f71\u54cd\u7a33\u5b9a\u5b50\u5197\u4f59\u548c\u5355\u6b21\u89e3\u7801\u6240\u9700\u7684\u7ecf\u5178\u7efc\u5408\u5f81\u7801\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u4ee3\u6570\u5206\u6790\u8bc1\u660eg(z)\u51b3\u5b9a\u7801\u7684\u7a33\u5b9a\u5b50\u5197\u4f59\u548c\u7efc\u5408\u5f81\u7801\u7ed3\u6784\uff0c\u63a8\u5bfc\u91cf\u5b50\u901f\u7387\u4e0e\u7a33\u5b9a\u5b50\u5197\u4f59\u5bc6\u5ea6\u7684\u4e25\u683c\u7b49\u5f0f\uff0c\u63d0\u4f9b\u7c7b\u4f3cBCH\u754c\u9650\u7684\u5355\u6b21\u6d4b\u91cf\u8bef\u5dee\u5bb9\u9650\u754c\u9650\uff0c\u5e76\u6784\u9020\u5177\u6709\u6539\u8fdb\u7efc\u5408\u5f81\u8ddd\u79bb\u7684\u5c0f\u578b\u4e92\u8d28BB\u7801\uff0c\u4f7f\u7528BP+OSD\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u91cf\u5b50\u901f\u7387\u4e0e\u7a33\u5b9a\u5b50\u5197\u4f59\u5bc6\u5ea6\u4e4b\u95f4\u5b58\u5728\u4e25\u683c\u7b49\u5f0f\u5173\u7cfb\uff0c\u83b7\u5f97\u4e86\u5355\u6b21\u6d4b\u91cf\u8bef\u5dee\u5bb9\u9650\u7684\u754c\u9650\uff0c\u6784\u9020\u7684BB\u7801\u663e\u793a\u51fa\u663e\u8457\u6539\u5584\u7684\u7efc\u5408\u5f81\u8ddd\u79bb(d_S)\uff0c\u4f46\u5206\u6790\u63ed\u793a\u4e86\u7ed3\u6784\u74f6\u9888\uff1a\u5728\u4e92\u8d28BB\u7801\u6846\u67b6\u5185\uff0c\u9ad8\u91cf\u5b50\u901f\u7387\u4f1a\u9650\u5236\u7efc\u5408\u5f81\u8ddd\u79bb\u7684\u4e0a\u754c\u3002", "conclusion": "g(z)\u591a\u9879\u5f0f\u5b8c\u5168\u51b3\u5b9a\u4e86BB\u7801\u7684\u7a33\u5b9a\u5b50\u5197\u4f59\u548c\u5355\u6b21\u89e3\u7801\u7ed3\u6784\uff0c\u91cf\u5b50\u901f\u7387\u4e0e\u7a33\u5b9a\u5b50\u5197\u4f59\u5bc6\u5ea6\u5b58\u5728\u4e25\u683c\u5173\u7cfb\uff0c\u9ad8\u91cf\u5b50\u901f\u7387\u4f1a\u9650\u5236\u5355\u6b21\u89e3\u7801\u6027\u80fd\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u4e0b\u4e00\u4ee32BGA\u7801\u5728\u6d4b\u91cf\u53d7\u9650\u67b6\u6784\u4e2d\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u4ee3\u6570\u8bbe\u8ba1\u89c4\u5219\u3002"}}
{"id": "2601.01194", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.01194", "abs": "https://arxiv.org/abs/2601.01194", "authors": ["Ozgur Ercetin", "Mohaned Chraiti"], "title": "On the Structure of the Optimal Detector for Sub-THz Multi-Hop Relays with Unknown Prior: Over-the-Air Diffusion", "comment": null, "summary": "Amplify and forward (AF) relaying is a viable strategy to extend the coverage of sub-terahertz (sub-THz) links, but inevitably propagates noise, leading to cumulative degradation across multiple hops. At the receiver, optimal decoding is desirable, yet challenging under non-Gaussian input distributions (video, voice, etc), for which neither the Minimum Mean Square Error (MMSE) estimator nor the mutual information admits a closed form. A further open question is whether knowledge of Channel State Information (CSI) and noise statistics at the intermediate relays is necessary for optimal detection. Aiming for an optimal decoder, this paper introduces a new framework that interprets the AF relay chain as a variance-preserving diffusion process and employs denoising diffusion implicit models (DDIMs) for signal recovery. We show that each AF hop is mathematically equivalent to a diffusion step with hop-dependent attenuation and noise injection. Consequently, the entire multi-hop chain collapses to an equivalent Gaussian channel fully described by only three real scalars per block: the cumulative complex gain and the effective noise variance. At the receiver, these end-to-end sufficient statistics define a matched reverse schedule that guides the DDIM-based denoiser, enabling near-optimal Bayesian decoding without per-hop CSI. We establish the information-theoretic foundation of this equivalence, proving that decoding performance depends solely on the final effective Signal-to-Noise-Ratio (SNR), regardless of intermediate noise/channel allocation or prior distribution. Simulations under AWGN and Rician fading confirm that the proposed AF-DDIM decoder reduces mean-squared error, symbol error rate, and bit error rate, particularly at moderate SNRs and for higher-order constellations.", "AI": {"tldr": "\u63d0\u51faAF-DDIM\u6846\u67b6\uff0c\u5c06AF\u4e2d\u7ee7\u94fe\u89e3\u91ca\u4e3a\u65b9\u5dee\u4fdd\u6301\u6269\u6563\u8fc7\u7a0b\uff0c\u5229\u7528DDIM\u8fdb\u884c\u4fe1\u53f7\u6062\u590d\uff0c\u5b9e\u73b0\u65e0\u9700\u6bcf\u8df3CSI\u7684\u8fd1\u6700\u4f18\u8d1d\u53f6\u65af\u89e3\u7801\u3002", "motivation": "AF\u4e2d\u7ee7\u80fd\u6269\u5c55sub-THz\u94fe\u8def\u8986\u76d6\uff0c\u4f46\u4f1a\u4f20\u64ad\u566a\u58f0\u5bfc\u81f4\u7d2f\u79ef\u9000\u5316\u3002\u5728\u975e\u9ad8\u65af\u8f93\u5165\u5206\u5e03\u4e0b\uff0c\u6700\u4f18\u89e3\u7801\u5177\u6709\u6311\u6218\u6027\uff0c\u4e14\u4e0d\u6e05\u695a\u4e2d\u7ee7\u662f\u5426\u9700\u8981CSI\u548c\u566a\u58f0\u7edf\u8ba1\u4fe1\u606f\u3002", "method": "\u5c06AF\u4e2d\u7ee7\u94fe\u89e3\u91ca\u4e3a\u65b9\u5dee\u4fdd\u6301\u6269\u6563\u8fc7\u7a0b\uff0c\u6bcf\u8df3\u7b49\u6548\u4e8e\u6269\u6563\u6b65\u9aa4\u3002\u6574\u4e2a\u591a\u8df3\u94fe\u53ef\u7b80\u5316\u4e3a\u4ec5\u7531\u4e09\u4e2a\u5b9e\u6807\u91cf\u63cf\u8ff0\u7684\u7b49\u6548\u9ad8\u65af\u4fe1\u9053\u3002\u63a5\u6536\u7aef\u5229\u7528DDIM\u53bb\u566a\u5668\u8fdb\u884c\u4fe1\u53f7\u6062\u590d\uff0c\u65e0\u9700\u6bcf\u8df3CSI\u3002", "result": "\u4eff\u771f\u663e\u793aAF-DDIM\u89e3\u7801\u5668\u5728AWGN\u548c\u83b1\u65af\u8870\u843d\u4e0b\u80fd\u964d\u4f4eMSE\u3001SER\u548cBER\uff0c\u7279\u522b\u662f\u5728\u4e2d\u7b49SNR\u548c\u9ad8\u9636\u8c03\u5236\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5efa\u7acb\u4e86\u8be5\u7b49\u6548\u6027\u7684\u4fe1\u606f\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u89e3\u7801\u6027\u80fd\u4ec5\u53d6\u51b3\u4e8e\u6700\u7ec8\u6709\u6548SNR\uff0c\u4e0e\u4e2d\u95f4\u566a\u58f0/\u4fe1\u9053\u5206\u914d\u6216\u5148\u9a8c\u5206\u5e03\u65e0\u5173\uff0c\u4e3aAF\u4e2d\u7ee7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u7801\u6846\u67b6\u3002"}}
{"id": "2601.00823", "categories": ["cs.AI", "cs.IT", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.00823", "abs": "https://arxiv.org/abs/2601.00823", "authors": ["Austin R. Ellis-Mohr", "Max Hartman", "Lav R. Varshney"], "title": "Energy-Aware Routing to Large Reasoning Models", "comment": null, "summary": "Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u65b9\u5dee\u611f\u77e5\u7684\u8def\u7531\u548c\u8c03\u5ea6\u7b56\u7565\u6765\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u80fd\u6e90\u6548\u7387\uff0c\u5728\u4e34\u754c\u72b6\u6001\u4e0b\u5e73\u8861\u57fa\u7840\u80fd\u6e90\u548c\u8f85\u52a9\u80fd\u6e90\u7684\u4f7f\u7528\uff0c\u907f\u514d\u80fd\u6e90\u6d6a\u8d39\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5177\u6709\u5f02\u6784\u7684\u63a8\u7406\u80fd\u6e90\u6210\u672c\uff0c\u4e0d\u540c\u6a21\u578b\u548c\u63a8\u7406\u65b9\u5f0f\u80fd\u8017\u4e0d\u540c\u3002\u4e3a\u4e86\u51cf\u5c11\u80fd\u6e90\u6d88\u8017\uff0c\u9700\u8981\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u5e76\u4ee5\u5408\u9002\u7684\u65b9\u5f0f\u8fd0\u884c\u3002\u7cfb\u7edf\u6027\u80fd\u53d6\u51b3\u4e8e\u5e73\u5747\u80fd\u6e90\u4f9b\u5e94\u548c\u968f\u673a\u6ce2\u52a8\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u65b9\u5dee\u611f\u77e5\u8def\u7531\u548c\u8c03\u5ea6\u4f5c\u4e3a\u8bbe\u8ba1\u539f\u5219\uff0c\u57fa\u4e8e\u8bad\u7ec3\u8ba1\u7b97\u548c\u63a8\u7406\u8ba1\u7b97\u7f29\u653e\u5b9a\u5f8b\u6765\u5236\u5b9a\u8c03\u5ea6\u7b56\u7565\u3002\u5728\u4e34\u754c\u72b6\u6001\u4e0b\u5206\u6790\u7cfb\u7edf\u6027\u80fd\uff0c\u7814\u7a76\u5982\u4f55\u8de8\u65f6\u95f4\u3001\u6a21\u578b\u548c\u6267\u884c\u9009\u62e9\u5438\u6536\u53d8\u5f02\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u80fd\u6e90\u611f\u77e5\u6a21\u578b\u8def\u7531\u7b56\u7565\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5728\u4e34\u754c\u72b6\u6001\u4e0b\u6027\u80fd\u5982\u4f55\u53d7\u5230\u53d8\u5f02\u6027\u5438\u6536\u65b9\u5f0f\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e8c\u9636\u8868\u5f81\u6765\u8fdb\u4e00\u6b65\u7406\u89e3\u7cfb\u7edf\u884c\u4e3a\u3002", "conclusion": "\u65b9\u5dee\u611f\u77e5\u8def\u7531\u548c\u8c03\u5ea6\u662f\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u6e90\u6548\u7387\u7684\u5173\u952e\u8bbe\u8ba1\u7ef4\u5ea6\uff0c\u4e3a\u5f00\u53d1\u80fd\u6e90\u611f\u77e5\u7684\u6a21\u578b\u8def\u7531\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u5728\u907f\u514d\u80fd\u6e90\u6d6a\u8d39\u7684\u540c\u65f6\u7ef4\u6301\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2601.00814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00814", "abs": "https://arxiv.org/abs/2601.00814", "authors": ["Abhishek Kumar"], "title": "Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections", "comment": null, "summary": "The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u63cf\u8ff0\u751f\u6210\u6280\u672f\u4e30\u5bcc\u672c\u4f53\u5b9e\u4f53\u4e0a\u4e0b\u6587\uff0c\u4f7f\u7528\u5fae\u8c03\u7684\u591a\u8bed\u8a00Transformer\u6a21\u578b\u751f\u6210\u66f4\u597d\u5d4c\u5165\uff0c\u5728OAEI-2022\u591a\u8bed\u8a00\u519c\u573a\u8d5b\u9053\u83b7\u5f9771% F1\u5206\u6570\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534716%\u3002", "motivation": "\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u662f\u77e5\u8bc6\u878d\u5408\u548c\u8bed\u4e49\u7f51\u5e94\u7528\u7684\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6355\u6349\u8de8\u8bed\u8a00\u8bed\u4e49\u76f8\u4f3c\u5ea6\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5bf9\u9f50\u65b9\u6cd5\u6765\u63d0\u5347\u591a\u8bed\u8a00\u672c\u4f53\u5339\u914d\u7684\u51c6\u786e\u7387\u3002", "method": "1. \u4f7f\u7528\u521b\u65b0\u6280\u672f\u4e3aontology\u5b9e\u4f53\u751f\u6210\u4e30\u5bcc\u4e0a\u4e0b\u6587\u63cf\u8ff0\uff1b2. \u91c7\u7528\u5fae\u8c03\u7684\u591a\u8bed\u8a00Transformer\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u5d4c\u5165\uff1b3. \u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5339\u914d\u5b9e\u4f53\u5bf9\uff1b4. \u5e94\u7528\u9608\u503c\u8fc7\u6ee4\u4fdd\u7559\u9ad8\u76f8\u4f3c\u5ea6\u5b9e\u4f53\u5bf9\u3002", "result": "\u5728OAEI-2022 multifarm track\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u83b7\u5f9771% F1\u5206\u6570\uff08\u53ec\u56de\u738778%\uff0c\u7cbe\u786e\u738765%\uff09\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534716%\uff0c\u8868\u660e\u7cfb\u7edf\u80fd\u6709\u6548\u6355\u6349\u8de8\u8bed\u8a00\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5d4c\u5165\u548c\u63cf\u8ff0\u589e\u5f3a\u7684\u672c\u4f53\u5bf9\u9f50\u7ba1\u9053\u80fd\u6709\u6548\u5904\u7406\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u4efb\u52a1\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e30\u5bcc\u548c\u9ad8\u8d28\u91cf\u5d4c\u5165\u663e\u8457\u63d0\u5347\u5bf9\u9f50\u6027\u80fd\uff0c\u4e3a\u591a\u8bed\u8a00\u77e5\u8bc6\u878d\u5408\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00974", "categories": ["cs.NI", "cs.DM", "cs.PF", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.00974", "abs": "https://arxiv.org/abs/2601.00974", "authors": ["Inna Voloshchuk", "Hayden Jananthan", "Chansup Byun", "Jeremy Kepner"], "title": "Improving the Graph Challenge Reference Implementation", "comment": "Presented at IEEE MIT URTC 2025", "summary": "The MIT/IEEE/Amazon Graph Challenge provides a venue for individuals and teams to showcase new innovations in large-scale graph and sparse data analysis. The Anonymized Network Sensing Graph Challenge processes over 100 billion network packets to construct privacy-preserving traffic matrices, with a GraphBLAS reference implementation demonstrating how hypersparse matrices can be applied to this problem. This work presents a refactoring and benchmarking of a section of the reference code to improve clarity, adaptability, and performance. The original Python implementation spanning approximately 1000 lines across 3 files has been streamlined to 325 lines across two focused modules, achieving a 67% reduction in code size while maintaining full functionality. Using pMatlab and pPython distributed array programming libraries, the addition of parallel maps allowed for parallel benchmarking of the data. Scalable performance is demonstrated for large-scale summation and analysis of traffic matrices. The resulting implementation increases the potential impact of the Graph Challenge by providing a clear and efficient foundation for participants.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Graph Challenge\u7684\u53c2\u8003\u4ee3\u7801\u8fdb\u884c\u4e86\u91cd\u6784\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c061000\u884cPython\u4ee3\u7801\u7cbe\u7b80\u81f3325\u884c\uff0c\u51cf\u5c1167%\u4ee3\u7801\u91cf\uff0c\u540c\u65f6\u901a\u8fc7\u5e76\u884c\u5316\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u6d41\u91cf\u77e9\u9635\u5206\u6790\u7684\u6027\u80fd\u3002", "motivation": "Graph Challenge\u4e3a\u5927\u89c4\u6a21\u56fe\u548c\u7a00\u758f\u6570\u636e\u5206\u6790\u63d0\u4f9b\u5c55\u793a\u5e73\u53f0\uff0c\u4f46\u73b0\u6709\u53c2\u8003\u4ee3\u7801\u5728\u6e05\u6670\u5ea6\u3001\u9002\u5e94\u6027\u548c\u6027\u80fd\u65b9\u9762\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u91cd\u6784\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u4e3a\u53c2\u4e0e\u8005\u63d0\u4f9b\u66f4\u6e05\u6670\u9ad8\u6548\u7684\u57fa\u7840\u5b9e\u73b0\u3002", "method": "\u91c7\u7528\u4ee3\u7801\u91cd\u6784\u65b9\u6cd5\uff0c\u5c06\u539f\u59cb3\u4e2a\u6587\u4ef6\u7ea61000\u884cPython\u4ee3\u7801\u7cbe\u7b80\u4e3a2\u4e2a\u6a21\u5757325\u884c\u4ee3\u7801\u3002\u4f7f\u7528pMatlab\u548cpPython\u5206\u5e03\u5f0f\u6570\u7ec4\u7f16\u7a0b\u5e93\uff0c\u6dfb\u52a0\u5e76\u884c\u6620\u5c04\u5b9e\u73b0\u6570\u636e\u5e76\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4ee3\u7801\u91cf\u51cf\u5c1167%\u7684\u540c\u65f6\u4fdd\u6301\u5b8c\u6574\u529f\u80fd\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u6d41\u91cf\u77e9\u9635\u6c42\u548c\u4e0e\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u80fd\u63d0\u5347\u3002\u91cd\u6784\u540e\u7684\u5b9e\u73b0\u4e3aGraph Challenge\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u9ad8\u6548\u7684\u57fa\u7840\u4ee3\u7801\u3002", "conclusion": "\u901a\u8fc7\u4ee3\u7801\u91cd\u6784\u548c\u5e76\u884c\u5316\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86Graph Challenge\u53c2\u8003\u4ee3\u7801\u7684\u6e05\u6670\u5ea6\u3001\u9002\u5e94\u6027\u548c\u6027\u80fd\uff0c\u589e\u5f3a\u4e86\u8be5\u6311\u6218\u8d5b\u7684\u5f71\u54cd\u529b\uff0c\u4e3a\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5b66\u4e60\u548c\u53d1\u5c55\u57fa\u7840\u3002"}}
{"id": "2601.01372", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.01372", "abs": "https://arxiv.org/abs/2601.01372", "authors": ["Mingchao Li", "Jiyou Li"], "title": "Probabilistic verification algorithm for linear codes", "comment": null, "summary": "In this paper, we propose a probabilistic algorithm suitable for any linear code $C$ to determine whether a given vector $\\mathbf{x}$ belongs to $ C$. The algorithm achieves $O(n\\log n)$ time complexity, $ O(n^2)$ space complexity and with an error probability less than $1/\\mathrm{poly}(n)$ in the asymptotic sense.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u4efb\u610f\u7ebf\u6027\u7801\u7684\u968f\u673a\u7b97\u6cd5\uff0c\u7528\u4e8e\u5224\u65ad\u7ed9\u5b9a\u5411\u91cf\u662f\u5426\u5c5e\u4e8e\u8be5\u7801\uff0c\u65f6\u95f4\u590d\u6742\u5ea6O(n log n)\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6O(n\u00b2)\uff0c\u9519\u8bef\u6982\u7387\u5c0f\u4e8e1/poly(n)", "motivation": "\u9700\u8981\u9ad8\u6548\u5224\u65ad\u5411\u91cf\u662f\u5426\u5c5e\u4e8e\u7ebf\u6027\u7801\u7684\u7b97\u6cd5\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5feb\u7684\u6982\u7387\u7b97\u6cd5", "method": "\u63d0\u51fa\u6982\u7387\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u7ebf\u6027\u7801\uff0c\u901a\u8fc7\u968f\u673a\u5316\u6280\u672f\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5229\u7528\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u5b9e\u73b0\u9ad8\u6548\u5224\u65ad", "result": "\u7b97\u6cd5\u8fbe\u5230O(n log n)\u65f6\u95f4\u590d\u6742\u5ea6\uff0cO(n\u00b2)\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u9519\u8bef\u6982\u7387\u5c0f\u4e8e1/poly(n)\uff0c\u5728\u6e10\u8fdb\u610f\u4e49\u4e0b\u8868\u73b0\u4f18\u5f02", "conclusion": "\u8be5\u6982\u7387\u7b97\u6cd5\u4e3a\u7ebf\u6027\u7801\u6210\u5458\u5224\u5b9a\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb"}}
{"id": "2601.00816", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00816", "abs": "https://arxiv.org/abs/2601.00816", "authors": ["Ismail Ahmad Abdullah"], "title": "MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback", "comment": "14 pages, 1 figure, 2 tables, 2 appendices with full proofs. Documents v0.9.4-pilot-audit-hardened audit surface with fail-closed governance, canonical JSON hashing, and artifact classification. Phase I infrastructure validation; no capability claims", "summary": "Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.\n  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.\n  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance", "AI": {"tldr": "MathLedger\u662f\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u673a\u5668\u8ba4\u77e5\u5e73\u53f0\uff0c\u5c06\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5bc6\u7801\u5b66\u8bc1\u660e\u548c\u5b66\u4e60\u52a8\u6001\u6574\u5408\u5230\u5355\u4e00\u8ba4\u77e5\u5faa\u73af\u4e2d\uff0c\u901a\u8fc7Reflexive Formal Learning\u5b9e\u73b0\u57fa\u4e8e\u9a8c\u8bc1\u5668\u7ed3\u679c\u7684\u7b26\u53f7\u5316\u5b66\u4e60\u66f4\u65b0", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u867d\u7136\u6027\u80fd\u5353\u8d8a\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u5728\u5b89\u5168\u5173\u952e\u90e8\u7f72\u4e2d\u5b58\u5728\u4fe1\u4efb\u5371\u673a\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u9a8c\u8bc1\u7684\u673a\u5668\u8ba4\u77e5\u57fa\u7840", "method": "\u91c7\u7528Reflexive Formal Learning\uff08RFL\uff09\uff0c\u8fd9\u662f\u68af\u5ea6\u4e0b\u964d\u7684\u7b26\u53f7\u5316\u7c7b\u6bd4\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5668\u7ed3\u679c\u800c\u975e\u7edf\u8ba1\u635f\u5931\u9a71\u52a8\u66f4\u65b0\uff1b\u7ed3\u5408\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5bc6\u7801\u5b66\u8bc1\u660e\u548c\u5b66\u4e60\u52a8\u6001", "result": "\u7b2c\u4e00\u9636\u6bb5\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6d4b\u91cf\u548c\u6cbb\u7406\u57fa\u7840\u8bbe\u65bd\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\uff1aCAL-EXP-3\u9a8c\u8bc1\u4e86\u6d4b\u91cf\u57fa\u7840\u8bbe\u65bd\uff08Delta p\u8ba1\u7b97\u3001\u65b9\u5dee\u8ddf\u8e2a\uff09\uff0c\u538b\u529b\u6d4b\u8bd5\u786e\u8ba4\u4e86\u8d8a\u754c\u6761\u4ef6\u4e0b\u6545\u969c\u5173\u95ed\u6cbb\u7406\u7684\u6b63\u786e\u89e6\u53d1", "conclusion": "\u8d21\u732e\u662f\u57fa\u7840\u8bbe\u65bd\u6027\u7684\uff1a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u5de5\u4f5c\u7684\u8d26\u672c\u8bc1\u660e\u5b66\u4e60\u539f\u578b\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u53ef\u5ba1\u8ba1\u6027\uff0c\u4f46\u672a\u505a\u51fa\u6536\u655b\u6216\u80fd\u529b\u58f0\u660e"}}
{"id": "2601.01086", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01086", "abs": "https://arxiv.org/abs/2601.01086", "authors": ["Jianpeng Qi", "Chao Liu", "Chengrui Wang", "Rui Wang", "Junyu Dong", "Yanwei Yu"], "title": "Decision-Aware Semantic State Synchronization in Compute-First Networking", "comment": "12 pages, 9 figures", "summary": "In Compute-First Networking (CFN), an Access Point (AP) makes task offloading decisions based on resource state information reported by a Service Node (SN). A fundamental challenge arises from the trade-off between update overhead and decision accuracy: Frequent state updates consume limited network resources, while infrequent updates lead to stale state views and degraded task performance, especially under high system load. Existing approaches based on periodic updates or Age of Information (AoI) mainly focus on temporal freshness and often overlook whether a state change is actually relevant to offloading decisions. This paper proposes SenseCFN, a decision-aware state synchronization framework for CFN. Instead of synchronizing raw resource states, SenseCFN focuses on identifying state changes that are likely to alter offloading decisions. To this end, we introduce a lightweight semantic state representation that captures decision-relevant system characteristics, along with a Semantic Deviation Index (SDI) to quantify the impact of state shifts on decision outcomes. Based on SDI, the SN triggers updates only when significant decision-impacting changes are detected. Meanwhile, the AP performs offloading decisions using cached semantic states with explicit awareness of potential staleness. The update and offloading policies are jointly optimized using a centralized training with distributed execution (CTDE) approach. Simulation results show that SenseCFN maintains a task success rate of up to 99.6% in saturation-prone scenarios, outperforming baseline methods by more than 25%, while reducing status update frequency by approximately 70% to 96%. These results indicate that decision-aware state synchronization provides an effective and practical alternative to purely time-based update strategies in CFN.", "AI": {"tldr": "SenseCFN\u63d0\u51fa\u4e86\u4e00\u79cd\u51b3\u7b56\u611f\u77e5\u7684\u72b6\u6001\u540c\u6b65\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u72b6\u6001\u8868\u793a\u548c\u8bed\u4e49\u504f\u5dee\u6307\u6570\uff0c\u4ec5\u5728\u72b6\u6001\u53d8\u5316\u5f71\u54cd\u5378\u8f7d\u51b3\u7b56\u65f6\u89e6\u53d1\u66f4\u65b0\uff0c\u663e\u8457\u51cf\u5c11\u66f4\u65b0\u5f00\u9500\u540c\u65f6\u4fdd\u6301\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5728\u8ba1\u7b97\u4f18\u5148\u7f51\u7edc\u4e2d\uff0c\u63a5\u5165\u70b9\u57fa\u4e8e\u670d\u52a1\u8282\u70b9\u62a5\u544a\u7684\u8d44\u6e90\u72b6\u6001\u4fe1\u606f\u505a\u51fa\u4efb\u52a1\u5378\u8f7d\u51b3\u7b56\u3002\u4f20\u7edf\u57fa\u4e8e\u5468\u671f\u6027\u66f4\u65b0\u6216\u4fe1\u606f\u5e74\u9f84\u7684\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u65f6\u95f4\u65b0\u9c9c\u5ea6\uff0c\u4f46\u5ffd\u7565\u4e86\u72b6\u6001\u53d8\u5316\u662f\u5426\u771f\u6b63\u5f71\u54cd\u5378\u8f7d\u51b3\u7b56\uff0c\u5bfc\u81f4\u66f4\u65b0\u5f00\u9500\u4e0e\u51b3\u7b56\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faSenseCFN\u6846\u67b6\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u8bed\u4e49\u72b6\u6001\u8868\u793a\u6355\u83b7\u51b3\u7b56\u76f8\u5173\u7684\u7cfb\u7edf\u7279\u5f81\uff0c\u5f15\u5165\u8bed\u4e49\u504f\u5dee\u6307\u6570\u91cf\u5316\u72b6\u6001\u53d8\u5316\u5bf9\u51b3\u7b56\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u670d\u52a1\u8282\u70b9\u4ec5\u5728\u68c0\u6d4b\u5230\u663e\u8457\u51b3\u7b56\u5f71\u54cd\u53d8\u5316\u65f6\u89e6\u53d1\u66f4\u65b0\uff0c\u63a5\u5165\u70b9\u4f7f\u7528\u7f13\u5b58\u7684\u8bed\u4e49\u72b6\u6001\u8fdb\u884c\u5378\u8f7d\u51b3\u7b56\u5e76\u660e\u786e\u8003\u8651\u6f5c\u5728\u8fc7\u65f6\u6027\u3002\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u5206\u5e03\u5f0f\u6267\u884c\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cSenseCFN\u5728\u6613\u9971\u548c\u573a\u666f\u4e2d\u4fdd\u6301\u9ad8\u8fbe99.6%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc725%\uff0c\u540c\u65f6\u5c06\u72b6\u6001\u66f4\u65b0\u9891\u7387\u964d\u4f4e\u7ea670%\u81f396%\u3002", "conclusion": "\u51b3\u7b56\u611f\u77e5\u7684\u72b6\u6001\u540c\u6b65\u4e3a\u8ba1\u7b97\u4f18\u5148\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u7eaf\u7cb9\u57fa\u4e8e\u65f6\u95f4\u7684\u66f4\u65b0\u7b56\u7565\uff0c\u80fd\u591f\u5728\u51cf\u5c11\u66f4\u65b0\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u51b3\u7b56\u51c6\u786e\u6027\u3002"}}
{"id": "2601.01760", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.01760", "abs": "https://arxiv.org/abs/2601.01760", "authors": ["Gabriel Potestades"], "title": "Edge grouping using methods in Algorithmic Information Theory", "comment": null, "summary": "Understanding natural phenomenon through the interactions of different complex systems has become an increasing focus in scientific inquiry. Defining complexity and actually measuring it is an ongoing debate and no standard framework has been established that is both theoretically sound and computationally practical to use. Currently, one of the fields which attempts to formally define complexity is in the realm of Algorithmic Information Theory. The field has shown advances by studying the outputs of 1-dimensional and 2-dimensional Turing machines to determine the complexity values of binary strings and 2-dimensional binary matrices respectively. Using these complexity values, an algorithm called the Block Decomposition Method developed by Zenil, et al. in 2018, has been created to approximate the complexity of adjacency matrices of graphs which has found relative success in grouping graphs based on their complexity values. We use this method along with another method called edge perturbation to exhaustively determine if an edge can be identified to connect two sub-graphs within a graph using the entire symmetric group of its vertices permutation and via unique permutations we call automorphic subsets, which is a special subset of the symmetric group. We also analyze if edges will be grouped closer to their respective sub-graphs in terms of the average algorithmic information contribution. This analysis has been done in order to ascertain if Algorithmic Information Theory can be a viable theory in understanding substructures within graphs and ultimately as a foundation to create frameworks of measuring and analyzing complexity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u7b97\u6cd5\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u5757\u5206\u89e3\u65b9\u6cd5\u548c\u8fb9\u6270\u52a8\u6280\u672f\u6765\u5206\u6790\u56fe\u7ed3\u6784\u4e2d\u5b50\u56fe\u4e4b\u95f4\u7684\u8fde\u63a5\u8fb9\uff0c\u4ee5\u9a8c\u8bc1\u7b97\u6cd5\u4fe1\u606f\u7406\u8bba\u80fd\u5426\u4f5c\u4e3a\u7406\u89e3\u548c\u6d4b\u91cf\u56fe\u590d\u6742\u6027\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u79d1\u5b66\u754c\u5bf9\u590d\u6742\u7cfb\u7edf\u7684\u7814\u7a76\u65e5\u76ca\u91cd\u89c6\uff0c\u4f46\u7f3a\u4e4f\u65e2\u7406\u8bba\u4e25\u8c28\u53c8\u8ba1\u7b97\u5b9e\u7528\u7684\u590d\u6742\u6027\u6d4b\u91cf\u6846\u67b6\u3002\u7b97\u6cd5\u4fe1\u606f\u7406\u8bba\u5728\u5b9a\u4e49\u590d\u6742\u6027\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u662f\u5426\u80fd\u6709\u6548\u5206\u6790\u56fe\u7ed3\u6784\u4e2d\u7684\u5b50\u7ed3\u6784\uff0c\u4e3a\u590d\u6742\u6027\u6d4b\u91cf\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528Zenil\u7b49\u4eba2018\u5e74\u63d0\u51fa\u7684\u5757\u5206\u89e3\u65b9\u6cd5\u6765\u8fd1\u4f3c\u8ba1\u7b97\u56fe\u7684\u90bb\u63a5\u77e9\u9635\u590d\u6742\u6027\uff0c\u5e76\u7ed3\u5408\u8fb9\u6270\u52a8\u6280\u672f\u3002\u901a\u8fc7\u56fe\u7684\u9876\u70b9\u7f6e\u6362\u7684\u6574\u4e2a\u5bf9\u79f0\u7fa4\u4ee5\u53ca\u79f0\u4e3a\u81ea\u540c\u6784\u5b50\u96c6\u7684\u7279\u6b8a\u5b50\u96c6\uff0c\u7a77\u5c3d\u5730\u786e\u5b9a\u8fde\u63a5\u56fe\u4e2d\u4e24\u4e2a\u5b50\u56fe\u7684\u8fb9\u3002\u5206\u6790\u8fb9\u662f\u5426\u4f1a\u5728\u5e73\u5747\u7b97\u6cd5\u4fe1\u606f\u8d21\u732e\u65b9\u9762\u66f4\u63a5\u8fd1\u5176\u6240\u5c5e\u7684\u5b50\u56fe\u3002", "result": "\u8bba\u6587\u901a\u8fc7\u5206\u6790\u8fb9\u4e0e\u5b50\u56fe\u5728\u7b97\u6cd5\u4fe1\u606f\u8d21\u732e\u4e0a\u7684\u5173\u8054\u6027\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u4fe1\u606f\u7406\u8bba\u5728\u8bc6\u522b\u56fe\u5b50\u7ed3\u6784\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u8fb9\u6270\u52a8\u548c\u5757\u5206\u89e3\u65b9\u6cd5\u7684\u7ed3\u5408\u80fd\u591f\u6709\u6548\u8bc6\u522b\u8fde\u63a5\u5b50\u56fe\u7684\u8fb9\uff0c\u5e76\u663e\u793a\u8fd9\u4e9b\u8fb9\u5728\u4fe1\u606f\u8d21\u732e\u4e0a\u66f4\u503e\u5411\u4e8e\u5176\u6240\u5c5e\u7684\u5b50\u56fe\u3002", "conclusion": "\u7b97\u6cd5\u4fe1\u606f\u7406\u8bba\u53ef\u4ee5\u4f5c\u4e3a\u7406\u89e3\u548c\u5206\u6790\u56fe\u7ed3\u6784\u4e2d\u5b50\u7ed3\u6784\u7684\u53ef\u884c\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u5efa\u7acb\u590d\u6742\u6027\u6d4b\u91cf\u548c\u5206\u6790\u7684\u901a\u7528\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u56fe\u5b50\u7ed3\u6784\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u5b8c\u5584\u590d\u6742\u6027\u6d4b\u91cf\u7684\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2601.00818", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00818", "abs": "https://arxiv.org/abs/2601.00818", "authors": ["Chandra Sekhar Kubam"], "title": "Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making", "comment": "8 pages", "summary": "Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684Agentic AI\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u81ea\u4e3b\u3001\u900f\u660e\u3001\u5b9e\u65f6\u7684\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u5728\u51b3\u7b56\u901f\u5ea6\u3001\u900f\u660e\u5ea6\u548c\u54cd\u5e94\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u91d1\u878d\u670d\u52a1\u5feb\u901f\u6570\u5b57\u5316\u9700\u8981\u81ea\u4e3b\u3001\u900f\u660e\u3001\u5b9e\u65f6\u7684\u4fe1\u7528\u98ce\u9669\u51b3\u7b56\u7cfb\u7edf\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u6709\u6548\uff0c\u4f46\u7f3a\u4e4f\u81ea\u9002\u5e94\u63a8\u7406\u3001\u60c5\u5883\u611f\u77e5\u548c\u81ea\u4e3b\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u91d1\u878d\u8fd0\u8425\u9700\u6c42\u3002", "method": "\u63d0\u51faAgentic AI\u6846\u67b6\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3001\u53ef\u89e3\u91caAI\u6a21\u5757\u548c\u5b9e\u65f6\u6570\u636e\u5438\u6536\u7ba1\u9053\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u534f\u4f5c\u534f\u8bae\u3001\u98ce\u9669\u8bc4\u5206\u5f15\u64ce\u3001\u53ef\u89e3\u91ca\u6027\u5c42\u548c\u6301\u7eed\u53cd\u9988\u5b66\u4e60\u5faa\u73af\u6765\u8bc4\u4f30\u501f\u6b3e\u4eba\u98ce\u9669\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u51b3\u7b56\u901f\u5ea6\u3001\u900f\u660e\u5ea6\u548c\u54cd\u5e94\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u4fe1\u7528\u8bc4\u5206\u6a21\u578b\u3002\u4f46\u4ecd\u5b58\u5728\u6a21\u578b\u6f02\u79fb\u98ce\u9669\u3001\u9ad8\u7ef4\u6570\u636e\u89e3\u91ca\u4e0d\u4e00\u81f4\u3001\u76d1\u7ba1\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u4f4e\u8d44\u6e90\u73af\u5883\u57fa\u7840\u8bbe\u65bd\u9650\u5236\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6f5c\u529b\u53d8\u9769\u4fe1\u7528\u5206\u6790\u9886\u57df\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u52a8\u6001\u76d1\u7ba1\u5408\u89c4\u673a\u5236\u3001\u65b0\u578b\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u4ee5\u53ca\u8de8\u56fd\u4fe1\u7528\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5927\u89c4\u6a21\u5b9e\u65bd\u3002"}}
{"id": "2601.01630", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01630", "abs": "https://arxiv.org/abs/2601.01630", "authors": ["Nicholas Jones", "Eytan Modiano"], "title": "Utility Maximization in Wireless Backhaul Networks with Service Guarantees", "comment": null, "summary": "We consider the problem of maximizing utility in wireless backhaul networks, where utility is a function of satisfied service level agreements (SLAs), defined in terms of end-to-end packet delays and instantaneous throughput. We model backhaul networks as a tree topology and show that SLAs can be satisfied by constructing link schedules with bounded inter-scheduling times, an NP-complete problem known as pinwheel scheduling. For symmetric tree topologies, we show that simple round-robin schedules can be optimal under certain conditions. In the general case, we develop a mixed-integer program that optimizes over the set of admission decisions and pinwheel schedules. We develop a novel pinwheel scheduling algorithm, which significantly expands the set of schedules that can be found in polynomial time over the state of the art. Using conditions from this algorithm, we develop a scalable, distributed approach to solve the utility-maximization problem, with complexity that is linear in the depth of the tree.", "AI": {"tldr": "\u65e0\u7ebf\u56de\u7a0b\u7f51\u7edc\u4e2d\u901a\u8fc7\u6709\u754c\u95f4\u9694\u8c03\u5ea6\u6ee1\u8db3SLA\u7ea6\u675f\u7684\u6548\u7528\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u591a\u9879\u5f0f\u65f6\u95f4pinwheel\u8c03\u5ea6\u7b97\u6cd5\u548c\u5206\u5e03\u5f0f\u7ebf\u6027\u590d\u6742\u5ea6\u89e3\u51b3\u65b9\u6848", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u56de\u7a0b\u7f51\u7edc\u4e2d\u6700\u5927\u5316\u6548\u7528\u7684\u95ee\u9898\uff0c\u5176\u4e2d\u6548\u7528\u53d6\u51b3\u4e8e\u6ee1\u8db3\u7684\u670d\u52a1\u6c34\u5e73\u534f\u8bae\uff08SLA\uff09\uff0c\u8fd9\u4e9b\u534f\u8bae\u5b9a\u4e49\u4e86\u7aef\u5230\u7aef\u6570\u636e\u5305\u5ef6\u8fdf\u548c\u77ac\u65f6\u541e\u5410\u91cf\u8981\u6c42", "method": "\u5c06\u56de\u7a0b\u7f51\u7edc\u5efa\u6a21\u4e3a\u6811\u5f62\u62d3\u6251\uff0c\u901a\u8fc7\u6784\u9020\u6709\u754c\u95f4\u9694\u8c03\u5ea6\uff08pinwheel\u8c03\u5ea6\uff09\u6765\u6ee1\u8db3SLA\u7ea6\u675f\u3002\u9488\u5bf9\u5bf9\u79f0\u6811\u62d3\u6251\u4f7f\u7528\u7b80\u5355\u8f6e\u8be2\u8c03\u5ea6\uff0c\u4e00\u822c\u60c5\u51b5\u5f00\u53d1\u6df7\u5408\u6574\u6570\u89c4\u5212\u3002\u63d0\u51fa\u65b0\u9896\u7684pinwheel\u8c03\u5ea6\u7b97\u6cd5\uff0c\u663e\u8457\u6269\u5c55\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u627e\u5230\u7684\u8c03\u5ea6\u96c6\u5408", "result": "\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684\u5206\u5e03\u5f0f\u65b9\u6cd5\u6765\u89e3\u51b3\u6548\u7528\u6700\u5927\u5316\u95ee\u9898\uff0c\u5176\u590d\u6742\u5ea6\u4e0e\u6811\u6df1\u5ea6\u5448\u7ebf\u6027\u5173\u7cfb\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u8c03\u5ea6\u7b97\u6cd5\u7684\u6548\u7387\u548c\u9002\u7528\u8303\u56f4", "conclusion": "\u901a\u8fc7pinwheel\u8c03\u5ea6\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u7ebf\u56de\u7a0b\u7f51\u7edc\u4e2d\u7684SLA\u7ea6\u675f\u6548\u7528\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u627e\u5230\u66f4\u5e7f\u6cdb\u7684\u8c03\u5ea6\u65b9\u6848\uff0c\u5e76\u5b9e\u73b0\u4e86\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u5206\u5e03\u5f0f\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.01789", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.01789", "abs": "https://arxiv.org/abs/2601.01789", "authors": ["Tadashi Wadayama"], "title": "Information Gradient for Directed Acyclic Graphs: A Score-based Framework for End-to-End Mutual Information Maximization", "comment": null, "summary": "This paper presents a general framework for end-to-end mutual information maximization in communication and sensing systems represented by stochastic directed acyclic graphs (DAGs). We derive a unified formula for the (mutual) information gradient with respect to arbitrary internal parameters, utilizing marginal and conditional score functions. We demonstrate that this gradient can be efficiently computed using vector-Jacobian products (VJP) within standard automatic differentiation frameworks, enabling the optimization of complex networks under global resource constraints. Numerical experiments on both linear multipath DAGs and nonlinear channels validate the proposed framework; the results confirm that the estimator, utilizing score functions learned via denoising score matching, accurately reproduces ground-truth gradients and successfully maximizes end-to-end mutual information. Beyond maximization, we extend our score-based framework to a novel unsupervised paradigm: digital twin calibration via Fisher divergence minimization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u968f\u673a\u6709\u5411\u65e0\u73af\u56fe\u7684\u7aef\u5230\u7aef\u4e92\u4fe1\u606f\u6700\u5927\u5316\u901a\u7528\u6846\u67b6\uff0c\u5229\u7528\u8fb9\u9645\u548c\u6761\u4ef6\u5f97\u5206\u51fd\u6570\u63a8\u5bfc\u7edf\u4e00\u7684\u4fe1\u606f\u68af\u5ea6\u516c\u5f0f\uff0c\u53ef\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u9ad8\u6548\u8ba1\u7b97\uff0c\u5e76\u6269\u5c55\u5230\u6570\u5b57\u5b6a\u751f\u6821\u51c6\u65b0\u8303\u5f0f\u3002", "motivation": "\u901a\u4fe1\u548c\u611f\u77e5\u7cfb\u7edf\u4e2d\u7aef\u5230\u7aef\u4e92\u4fe1\u606f\u6700\u5927\u5316\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7f51\u7edc\u7ed3\u6784\u548c\u5168\u5c40\u8d44\u6e90\u7ea6\u675f\u4e0b\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u968f\u673a\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\u7684\u590d\u6742\u7cfb\u7edf\uff0c\u9700\u8981\u4e00\u79cd\u901a\u7528\u4e14\u9ad8\u6548\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u968f\u673a\u6709\u5411\u65e0\u73af\u56fe\u7684\u901a\u7528\u6846\u67b6\uff0c\u5229\u7528\u8fb9\u9645\u548c\u6761\u4ef6\u5f97\u5206\u51fd\u6570\u63a8\u5bfc\u4e92\u4fe1\u606f\u68af\u5ea6\u7edf\u4e00\u516c\u5f0f\uff0c\u901a\u8fc7\u5411\u91cf-\u96c5\u53ef\u6bd4\u79ef\u5728\u81ea\u52a8\u5fae\u5206\u6846\u67b6\u4e2d\u9ad8\u6548\u8ba1\u7b97\u68af\u5ea6\uff0c\u652f\u6301\u53bb\u566a\u5f97\u5206\u5339\u914d\u5b66\u4e60\u5f97\u5206\u51fd\u6570\uff0c\u5e76\u6269\u5c55\u5230\u8d39\u5e0c\u5c14\u6563\u5ea6\u6700\u5c0f\u5316\u7684\u6570\u5b57\u5b6a\u751f\u6821\u51c6\u3002", "result": "\u5728\u7ebf\u6027\u591a\u5f84DAG\u548c\u975e\u7ebf\u6027\u4fe1\u9053\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff1a\u57fa\u4e8e\u53bb\u566a\u5f97\u5206\u5339\u914d\u5b66\u4e60\u7684\u5f97\u5206\u51fd\u6570\u80fd\u591f\u51c6\u786e\u590d\u73b0\u771f\u5b9e\u68af\u5ea6\uff0c\u6210\u529f\u6700\u5927\u5316\u7aef\u5230\u7aef\u4e92\u4fe1\u606f\u3002\u6846\u67b6\u8fd8\u5b9e\u73b0\u4e86\u6570\u5b57\u5b6a\u751f\u6821\u51c6\u7684\u65b0\u65e0\u76d1\u7763\u8303\u5f0f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u901a\u4fe1\u548c\u611f\u77e5\u7cfb\u7edf\u4e2d\u7684\u4e92\u4fe1\u606f\u6700\u5927\u5316\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7f51\u7edc\u7ed3\u6784\u548c\u5168\u5c40\u7ea6\u675f\uff0c\u5e76\u5f00\u8f9f\u4e86\u6570\u5b57\u5b6a\u751f\u6821\u51c6\u7b49\u65b0\u5e94\u7528\u65b9\u5411\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2601.00821", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.00821", "abs": "https://arxiv.org/abs/2601.00821", "authors": ["Tao An"], "title": "CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations", "comment": "15 pages, 5 figures", "summary": "Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.\n  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.\n  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.", "AI": {"tldr": "CogCanvas\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u5bf9\u8bdd\u4e2d\u7684\u8ba4\u77e5\u6784\u4ef6\u5e76\u7ec4\u7ec7\u6210\u65f6\u5e8f\u611f\u77e5\u56fe\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u4fe1\u606f\u4fdd\u771f\u5ea6\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u4e2d\u9762\u4e34\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u4fe1\u606f\u4fdd\u771f\u5ea6\u7684\u57fa\u672c\u77db\u76fe\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u622a\u65ad\u548c\u6458\u8981\uff09\u8981\u4e48\u4e22\u5f03\u65e9\u671f\u4fe1\u606f\uff0c\u8981\u4e48\u4e22\u5931\u7ec6\u8282\u4fe1\u606f\u3002", "method": "\u63d0\u51faCogCanvas\u6846\u67b6\uff0c\u4ece\u5bf9\u8bdd\u8f6e\u6b21\u4e2d\u63d0\u53d6\u57fa\u4e8e\u539f\u6587\u7684\u8ba4\u77e5\u6784\u4ef6\uff08\u51b3\u7b56\u3001\u4e8b\u5b9e\u3001\u63d0\u9192\uff09\uff0c\u5e76\u5c06\u5176\u7ec4\u7ec7\u6210\u65f6\u5e8f\u611f\u77e5\u56fe\uff0c\u5b9e\u73b0\u6297\u538b\u7f29\u68c0\u7d22\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCogCanvas\u8fbe\u523034.7%\u603b\u4f53\u51c6\u786e\u7387\uff0c\u4f18\u4e8eRAG\uff0825.6%\uff09\u548cGraphRAG\uff0813.7%\uff09\u3002\u65f6\u5e8f\u63a8\u7406\u65b9\u9762\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff1a31.5% vs 9.3%\uff08RAG\uff09\u548c5.0%\uff08GraphRAG\uff09\u3002\u591a\u8df3\u56e0\u679c\u63a8\u7406\u8fbe\u523081.0%\u901a\u8fc7\u7387\u3002", "conclusion": "\u867d\u7136\u7ecf\u8fc7\u5927\u91cf\u4f18\u5316\u7684\u65b9\u6cd5\u901a\u8fc7\u4e13\u95e8\u8bad\u7ec3\u80fd\u8fbe\u5230\u66f4\u9ad8\u5206\u6570\uff0c\u4f46CogCanvas\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u7acb\u5373\u53ef\u90e8\u7f72\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2601.01645", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.01645", "abs": "https://arxiv.org/abs/2601.01645", "authors": ["Vipindev Adat Vasudevan", "Homa Esfahanizadeh", "Benjamin D. Kim", "Laura Landon", "Alejandro Cohen", "Muriel M\u00e9dard"], "title": "Revisiting the Interface between Error and Erasure Correction in Wireless Standards", "comment": null, "summary": "Modern 5G communication systems implement a combination of error correction and feedback-based erasure correction (HARQ/ARQ) as reliability mechanisms, which can introduce substantial delay and resource inefficiency. We propose forward erasure correction using network coding as a more delay-efficient alternative. We present a mathematical characterization of network delay for existing reliability mechanisms and network coding. Through simulations in a network slicing environment, we demonstrate that network coding not only improves the in-order delivery delay and goodput for the applications utilizing the slice, but also benefits other applications sharing the network by reducing resource utilization for the coded slice. Our analysis and characterization point towards ideas that require attention in the 6G standardization process. These findings highlight the need for greater modularity in protocol stack design that enables the integration of novel technologies in future wireless networks.", "AI": {"tldr": "\u7f51\u7edc\u7f16\u7801\u4f5c\u4e3a\u524d\u5411\u64e6\u9664\u6821\u6b63\u65b9\u6848\uff0c\u76f8\u6bd45G\u73b0\u6709\u7684\u7ea0\u9519\u548c\u53cd\u9988\u91cd\u4f20\u673a\u5236\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u8d44\u6e90\u6548\u7387\uff0c\u4e3a6G\u6807\u51c6\u5316\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u73b0\u4ee35G\u901a\u4fe1\u7cfb\u7edf\u91c7\u7528\u7ea0\u9519\u548c\u57fa\u4e8e\u53cd\u9988\u7684\u64e6\u9664\u6821\u6b63\uff08HARQ/ARQ\uff09\u4f5c\u4e3a\u53ef\u9760\u6027\u673a\u5236\uff0c\u4f46\u8fd9\u4e9b\u673a\u5236\u4f1a\u5f15\u5165\u663e\u8457\u5ef6\u8fdf\u548c\u8d44\u6e90\u4f4e\u6548\u95ee\u9898\u3002\u9700\u8981\u5bfb\u627e\u66f4\u5ef6\u8fdf\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u7f51\u7edc\u7f16\u7801\u4f5c\u4e3a\u524d\u5411\u64e6\u9664\u6821\u6b63\u65b9\u6848\uff0c\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u5206\u6790\u73b0\u6709\u53ef\u9760\u6027\u673a\u5236\u548c\u7f51\u7edc\u7f16\u7801\u7684\u7f51\u7edc\u5ef6\u8fdf\u7279\u6027\uff0c\u5e76\u5728\u7f51\u7edc\u5207\u7247\u73af\u5883\u4e2d\u8fdb\u884c\u4eff\u771f\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u8868\u660e\u7f51\u7edc\u7f16\u7801\u4e0d\u4ec5\u6539\u5584\u4e86\u4f7f\u7528\u8be5\u5207\u7247\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u6709\u5e8f\u4ea4\u4ed8\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\uff0c\u8fd8\u901a\u8fc7\u51cf\u5c11\u7f16\u7801\u5207\u7247\u7684\u8d44\u6e90\u5229\u7528\uff0c\u4f7f\u5171\u4eab\u7f51\u7edc\u7684\u5176\u4ed6\u5e94\u7528\u7a0b\u5e8f\u53d7\u76ca\u3002", "conclusion": "\u5206\u6790\u8868\u660e6G\u6807\u51c6\u5316\u9700\u8981\u5173\u6ce8\u534f\u8bae\u6808\u8bbe\u8ba1\u7684\u66f4\u5927\u6a21\u5757\u5316\uff0c\u4ee5\u4fbf\u5728\u672a\u6765\u7684\u65e0\u7ebf\u7f51\u7edc\u4e2d\u96c6\u6210\u65b0\u6280\u672f\uff0c\u7f51\u7edc\u7f16\u7801\u662f\u503c\u5f97\u8003\u8651\u7684\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2601.01795", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.01795", "abs": "https://arxiv.org/abs/2601.01795", "authors": ["Peter Jan van Leeuwen"], "title": "Information Flow in geophysical systems", "comment": "Submitted to JAMES", "summary": "We present a new framework for analyzing the evolution of information in geophysical systems. Understanding how information, and its counterpart, uncertainty, propagates is central to predictability studies and has significant implications for applications such as forecast uncertainty quantification and risk management. It also offers valuable insight into the underlying physics of the system. Information propagation is closely linked to causality: how one part of a system influences another, and how some regions remain dynamically isolated. We apply this framework to the one-dimensional, highly nonlinear Kuramoto-Sivashinsky model and to the shallow-water equations, representing a mid-latitude atmospheric strip. Notably, we observe that information can propagate against the fluid flow, and that different model variables exhibit distinct patterns of information evolution. For example, pressure-related information propagates differently from relative vorticity, reflecting the influence of gravity waves versus balanced flow dynamics. This new framework offers a promising addition to the diagnostic tools available for studying complex dynamical systems.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6790\u5730\u7403\u7269\u7406\u7cfb\u7edf\u4e2d\u4fe1\u606f\u6f14\u5316\u7684\u65b0\u6846\u67b6\uff0c\u5e94\u7528\u4e8eKuramoto-Sivashinsky\u6a21\u578b\u548c\u6d45\u6c34\u65b9\u7a0b\uff0c\u53d1\u73b0\u4fe1\u606f\u53ef\u9006\u6d41\u4f20\u64ad\uff0c\u4e0d\u540c\u53d8\u91cf\u5c55\u73b0\u4e0d\u540c\u7684\u4fe1\u606f\u4f20\u64ad\u6a21\u5f0f\u3002", "motivation": "\u7406\u89e3\u4fe1\u606f\u548c\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u4f20\u64ad\u5bf9\u53ef\u9884\u6d4b\u6027\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u5bf9\u9884\u62a5\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u98ce\u9669\u7ba1\u7406\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u540c\u65f6\u80fd\u63d0\u4f9b\u5bf9\u7cfb\u7edf\u5e95\u5c42\u7269\u7406\u7684\u6df1\u5165\u6d1e\u5bdf\u3002\u4fe1\u606f\u4f20\u64ad\u4e0e\u56e0\u679c\u5173\u7cfb\u5bc6\u5207\u76f8\u5173\uff0c\u6d89\u53ca\u7cfb\u7edf\u5404\u90e8\u5206\u5982\u4f55\u76f8\u4e92\u5f71\u54cd\u4ee5\u53ca\u67d0\u4e9b\u533a\u57df\u5982\u4f55\u4fdd\u6301\u52a8\u6001\u9694\u79bb\u3002", "method": "\u63d0\u51fa\u5206\u6790\u4fe1\u606f\u6f14\u5316\u7684\u65b0\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u4e00\u7ef4\u9ad8\u5ea6\u975e\u7ebf\u6027\u7684Kuramoto-Sivashinsky\u6a21\u578b\u548c\u4ee3\u8868\u4e2d\u7eac\u5ea6\u5927\u6c14\u5e26\u7684\u6d45\u6c34\u65b9\u7a0b\u3002\u8be5\u6846\u67b6\u5173\u6ce8\u4fe1\u606f\u4f20\u64ad\u4e0e\u6d41\u4f53\u6d41\u52a8\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u4e0d\u540c\u6a21\u578b\u53d8\u91cf\u7684\u4fe1\u606f\u6f14\u5316\u6a21\u5f0f\u3002", "result": "\u89c2\u5bdf\u5230\u4fe1\u606f\u53ef\u4ee5\u9006\u7740\u6d41\u4f53\u6d41\u52a8\u65b9\u5411\u4f20\u64ad\uff0c\u4e0d\u540c\u6a21\u578b\u53d8\u91cf\u5c55\u73b0\u51fa\u4e0d\u540c\u7684\u4fe1\u606f\u6f14\u5316\u6a21\u5f0f\u3002\u4f8b\u5982\uff0c\u538b\u529b\u76f8\u5173\u4fe1\u606f\u4e0e\u76f8\u5bf9\u6da1\u5ea6\u4fe1\u606f\u7684\u4f20\u64ad\u65b9\u5f0f\u4e0d\u540c\uff0c\u8fd9\u53cd\u6620\u4e86\u91cd\u529b\u6ce2\u4e0e\u5e73\u8861\u6d41\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u5dee\u5f02\u3002", "conclusion": "\u8fd9\u4e00\u65b0\u6846\u67b6\u4e3a\u7814\u7a76\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8bca\u65ad\u5de5\u5177\u8865\u5145\uff0c\u80fd\u591f\u63ed\u793a\u4fe1\u606f\u4f20\u64ad\u7684\u72ec\u7279\u7279\u5f81\u53ca\u5176\u4e0e\u7cfb\u7edf\u7269\u7406\u8fc7\u7a0b\u7684\u8054\u7cfb\u3002"}}
{"id": "2601.01838", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01838", "abs": "https://arxiv.org/abs/2601.01838", "authors": ["Henok Daniel", "Omar Alhussein", "Jie Liang", "Cheng Li", "Ernesto Damiani"], "title": "Enhanced Open-Source NWDAF for Event-Driven Analytics in 5G Networks", "comment": null, "summary": "The network data analytics function (NWDAF) has been introduced in the fifth-generation (5G) core standards to enable event-driven analytics and support intelligent network automation. However, existing implementations remain largely proprietary, and open-source alternatives lack comprehensive support for end-to-end event subscription and notification. In this paper, we present an open source NWDAF framework integrated into an existing Free5GC implementation, which serves as an open-source 5G core implementation. Our implementation extends the session management function to support standardized event exposure interfaces and introduces custom-built notification mechanisms into the SMF and the access and mobility management function for seamless data delivery. The NWDAF subscribes to events and generates analytics on user equipment (UE) behavior, session lifecycle, and handover dynamics. We validate our system through a two-week deployment involving four virtual next-generation NodeBs (gNBs) and multiple virtual UEs with dynamic mobility patterns. To demonstrate predictive capabilities, we incorporate a mobility-aware module that achieves 80.65\\% accuracy in forecasting the next gNB handover cell. The framework supports reliable UE registration, state tracking, and cross-cell handovers.", "AI": {"tldr": "\u5f00\u6e90NWDAF\u6846\u67b6\u96c6\u6210\u5230Free5GC\u4e2d\uff0c\u652f\u6301\u6807\u51c6\u5316\u4e8b\u4ef6\u8ba2\u9605/\u901a\u77e5\uff0c\u5b9e\u73b0UE\u884c\u4e3a\u5206\u6790\u3001\u4f1a\u8bdd\u751f\u547d\u5468\u671f\u8ddf\u8e2a\u548c\u5207\u6362\u9884\u6d4b\uff0c\u9884\u6d4b\u51c6\u786e\u7387\u8fbe80.65%", "motivation": "5G\u6838\u5fc3\u6807\u51c6\u5f15\u5165\u4e86NWDAF\uff08\u7f51\u7edc\u6570\u636e\u5206\u6790\u529f\u80fd\uff09\u4ee5\u5b9e\u73b0\u4e8b\u4ef6\u9a71\u52a8\u5206\u6790\u548c\u667a\u80fd\u7f51\u7edc\u81ea\u52a8\u5316\uff0c\u4f46\u73b0\u6709\u5b9e\u73b0\u591a\u4e3a\u4e13\u6709\u65b9\u6848\uff0c\u5f00\u6e90\u65b9\u6848\u7f3a\u4e4f\u7aef\u5230\u7aef\u4e8b\u4ef6\u8ba2\u9605\u548c\u901a\u77e5\u7684\u5168\u9762\u652f\u6301", "method": "\u5c06\u5f00\u6e90NWDAF\u6846\u67b6\u96c6\u6210\u5230Free5GC\u5b9e\u73b0\u4e2d\uff0c\u6269\u5c55\u4f1a\u8bdd\u7ba1\u7406\u529f\u80fd\u4ee5\u652f\u6301\u6807\u51c6\u5316\u4e8b\u4ef6\u66b4\u9732\u63a5\u53e3\uff0c\u5728SMF\u548cAMF\u4e2d\u5f15\u5165\u81ea\u5b9a\u4e49\u901a\u77e5\u673a\u5236\uff0c\u5b9e\u73b0\u65e0\u7f1d\u6570\u636e\u4f20\u8f93", "result": "\u7cfb\u7edf\u901a\u8fc7\u4e24\u5468\u90e8\u7f72\u9a8c\u8bc1\uff0c\u6d89\u53ca4\u4e2a\u865a\u62dfgNB\u548c\u591a\u4e2a\u5177\u6709\u52a8\u6001\u79fb\u52a8\u6a21\u5f0f\u7684\u865a\u62dfUE\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684UE\u6ce8\u518c\u3001\u72b6\u6001\u8ddf\u8e2a\u548c\u8de8\u5c0f\u533a\u5207\u6362\uff0c\u79fb\u52a8\u611f\u77e5\u6a21\u5757\u9884\u6d4b\u4e0b\u4e00\u4e2agNB\u5207\u6362\u5c0f\u533a\u7684\u51c6\u786e\u7387\u8fbe\u523080.65%", "conclusion": "\u63d0\u51fa\u7684\u5f00\u6e90NWDAF\u6846\u67b6\u6210\u529f\u96c6\u6210\u5230Free5GC\u4e2d\uff0c\u586b\u8865\u4e86\u5f00\u6e905G\u6838\u5fc3\u5b9e\u73b0\u4e2d\u4e8b\u4ef6\u9a71\u52a8\u5206\u6790\u7684\u7a7a\u767d\uff0c\u652f\u6301\u6807\u51c6\u5316\u4e8b\u4ef6\u8ba2\u9605\u548c\u901a\u77e5\uff0c\u5e76\u5c55\u793a\u4e86\u9884\u6d4b\u80fd\u529b"}}
{"id": "2601.02111", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02111", "abs": "https://arxiv.org/abs/2601.02111", "authors": ["Charles Wood"], "title": "Information Geometry of Imaging Operators", "comment": null, "summary": "Imaging systems are represented as linear operators, and their singular value spectra describe the structure recoverable at the operator level. Building on an operator-based information-theoretic framework, this paper introduces a minimal geometric structure induced by the normalised singular spectra of imaging operators. By identifying spectral equivalence classes with points on a probability simplex, and equipping this space with the Fisher--Rao information metric, a well-defined Riemannian geometry can be obtained that is invariant under unitary transformations and global rescaling. The resulting geometry admits closed-form expressions for distances and geodesics, and has constant positive curvature. Under explicit restrictions, composition enforces boundary faces through rank constraints and, in an aligned model with stated idealisations, induces a non-linear re-weighting of spectral states. Fisher--Rao distances are preserved only in the spectrally uniform case. The construction is abstract and operator-level, introducing no optimisation principles, stochastic models, or modality-specific assumptions. It is intended to provide a fixed geometric background for subsequent analysis of information flow and constraints in imaging pipelines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8e\u6210\u50cf\u7b97\u5b50\u7684\u5f52\u4e00\u5316\u5947\u5f02\u8c31\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6700\u5c0f\u51e0\u4f55\u7ed3\u6784\uff0c\u901a\u8fc7\u5c06\u8c31\u7b49\u4ef7\u7c7b\u6620\u5c04\u5230\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u5e76\u8d4b\u4e88Fisher-Rao\u4fe1\u606f\u5ea6\u91cf\uff0c\u83b7\u5f97\u4e86\u4e00\u4e2a\u5177\u6709\u6052\u5b9a\u6b63\u66f2\u7387\u7684\u9ece\u66fc\u51e0\u4f55\u3002", "motivation": "\u6210\u50cf\u7cfb\u7edf\u901a\u5e38\u8868\u793a\u4e3a\u7ebf\u6027\u7b97\u5b50\uff0c\u5176\u5947\u5f02\u503c\u8c31\u63cf\u8ff0\u4e86\u7b97\u5b50\u5c42\u9762\u53ef\u6062\u590d\u7684\u7ed3\u6784\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u62bd\u8c61\u7684\u3001\u7b97\u5b50\u5c42\u9762\u7684\u51e0\u4f55\u6846\u67b6\uff0c\u4e3a\u540e\u7eed\u5206\u6790\u6210\u50cf\u6d41\u7a0b\u4e2d\u7684\u4fe1\u606f\u6d41\u52a8\u548c\u7ea6\u675f\u63d0\u4f9b\u56fa\u5b9a\u7684\u51e0\u4f55\u80cc\u666f\u3002", "method": "\u57fa\u4e8e\u7b97\u5b50\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u5c06\u5f52\u4e00\u5316\u5947\u5f02\u8c31\u7684\u7b49\u4ef7\u7c7b\u8bc6\u522b\u4e3a\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u7684\u70b9\uff0c\u5e76\u5728\u8be5\u7a7a\u95f4\u4e0a\u88c5\u5907Fisher-Rao\u4fe1\u606f\u5ea6\u91cf\uff0c\u4ece\u800c\u83b7\u5f97\u4e00\u4e2a\u5728\u9149\u53d8\u6362\u548c\u5168\u5c40\u7f29\u653e\u4e0b\u4e0d\u53d8\u7684\u9ece\u66fc\u51e0\u4f55\u7ed3\u6784\u3002", "result": "\u6784\u5efa\u7684\u51e0\u4f55\u7ed3\u6784\u5177\u6709\u95ed\u5f0f\u8868\u8fbe\u7684\u8ddd\u79bb\u548c\u6d4b\u5730\u7ebf\uff0c\u4e14\u5177\u6709\u6052\u5b9a\u6b63\u66f2\u7387\u3002\u5728\u7279\u5b9a\u9650\u5236\u4e0b\uff0c\u7ec4\u5408\u8fd0\u7b97\u901a\u8fc7\u79e9\u7ea6\u675f\u5f3a\u5236\u8fb9\u754c\u9762\uff0c\u5e76\u5728\u5bf9\u9f50\u6a21\u578b\u4e2d\u8bf1\u5bfc\u8c31\u72b6\u6001\u7684\u975e\u7ebf\u6027\u91cd\u52a0\u6743\u3002Fisher-Rao\u8ddd\u79bb\u4ec5\u5728\u8c31\u5747\u5300\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u62bd\u8c61\u7684\u3001\u7b97\u5b50\u5c42\u9762\u7684\u51e0\u4f55\u6784\u9020\uff0c\u4e0d\u5f15\u5165\u4f18\u5316\u539f\u5219\u3001\u968f\u673a\u6a21\u578b\u6216\u6a21\u6001\u7279\u5b9a\u5047\u8bbe\uff0c\u65e8\u5728\u4e3a\u6210\u50cf\u6d41\u7a0b\u4e2d\u7684\u4fe1\u606f\u6d41\u548c\u7ea6\u675f\u5206\u6790\u63d0\u4f9b\u56fa\u5b9a\u7684\u51e0\u4f55\u80cc\u666f\u3002"}}
{"id": "2601.00828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00828", "abs": "https://arxiv.org/abs/2601.00828", "authors": ["Yin Li"], "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis", "comment": "9 pages, 2 figures, 3 tables. Code available at https://github.com/Kevin0304-li/llm-self-correction", "summary": "Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u5b58\u5728\"\u51c6\u786e\u7387-\u4fee\u6b63\u6096\u8bba\"\uff1a\u8f83\u5f31\u6a21\u578b\uff08GPT-3.5\uff09\u7684\u81ea\u6211\u4fee\u6b63\u7387\u53cd\u800c\u6bd4\u8f83\u5f3a\u6a21\u578b\uff08DeepSeek\uff09\u9ad81.6\u500d\uff0c\u6311\u6218\u4e86\u6a21\u578b\u80fd\u529b\u4e0e\u81ea\u6211\u6539\u8fdb\u7684\u7ebf\u6027\u5047\u8bbe\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u8ba4\u4e3a\u5177\u6709\u81ea\u6211\u4fee\u6b63\u80fd\u529b\uff0c\u4f46\u6700\u8fd1\u7814\u7a76\u8868\u660e\u5185\u5728\u81ea\u6211\u4fee\u6b63\uff08\u65e0\u9700\u5916\u90e8\u53cd\u9988\uff09\u6548\u679c\u6709\u9650\u3002\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u81ea\u6211\u4fee\u6b63\u7684\u4e09\u4e2a\u5b50\u80fd\u529b\uff1a\u9519\u8bef\u68c0\u6d4b\u3001\u9519\u8bef\u5b9a\u4f4d\u548c\u9519\u8bef\u4fee\u6b63\u3002", "method": "\u5c06\u81ea\u6211\u4fee\u6b63\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u80fd\u529b\uff0c\u5728GSM8K-Complex\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8de8\u6a21\u578b\u5b9e\u9a8c\uff08n=500/\u6a21\u578b\uff0c\u5171346\u4e2a\u9519\u8bef\uff09\uff0c\u4f7f\u7528\u4e09\u4e2a\u4e3b\u8981LLM\uff08GPT-3.5\u3001DeepSeek\u3001Claude\uff09\uff0c\u5206\u6790\u9519\u8bef\u68c0\u6d4b\u7387\u3001\u5b9a\u4f4d\u80fd\u529b\u548c\u4fee\u6b63\u6210\u529f\u7387\u3002", "result": "\u53d1\u73b0\"\u51c6\u786e\u7387-\u4fee\u6b63\u6096\u8bba\"\uff1a\u8f83\u5f31\u6a21\u578b\uff08GPT-3.5\uff0c66%\u51c6\u786e\u7387\uff09\u7684\u5185\u5728\u4fee\u6b63\u7387\uff0826.8%\uff09\u6bd4\u8f83\u5f3a\u6a21\u578b\uff08DeepSeek\uff0c94%\u51c6\u786e\u7387\uff09\u7684\u4fee\u6b63\u7387\uff0816.7%\uff09\u9ad81.6\u500d\u3002\u9519\u8bef\u68c0\u6d4b\u7387\u5728\u67b6\u6784\u95f4\u5dee\u5f02\u5de8\u5927\uff0810%-82%\uff09\uff0c\u4f46\u68c0\u6d4b\u80fd\u529b\u4e0d\u80fd\u9884\u6d4b\u4fee\u6b63\u6210\u529f\u7387\u3002\u63d0\u4f9b\u9519\u8bef\u4f4d\u7f6e\u63d0\u793a\u53cd\u800c\u635f\u5bb3\u6240\u6709\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u6311\u6218\u4e86\u6a21\u578b\u80fd\u529b\u4e0e\u81ea\u6211\u6539\u8fdb\u7684\u7ebf\u6027\u5047\u8bbe\uff0c\u63d0\u51fa\"\u9519\u8bef\u6df1\u5ea6\u5047\u8bf4\"\uff1a\u8f83\u5f3a\u6a21\u578b\u72af\u9519\u66f4\u5c11\u4f46\u9519\u8bef\u66f4\u6df1\uff0c\u96be\u4ee5\u81ea\u6211\u4fee\u6b63\u3002\u8fd9\u5bf9\u81ea\u6211\u6539\u8fdb\u6d41\u7a0b\u8bbe\u8ba1\u6709\u91cd\u8981\u542f\u793a\uff0c\u8868\u660e\u7b80\u5355\u7684\"\u68c0\u6d4b-\u4fee\u6b63\"\u65b9\u6cd5\u53ef\u80fd\u4e0d\u591f\u6709\u6548\u3002"}}
{"id": "2601.01968", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01968", "abs": "https://arxiv.org/abs/2601.01968", "authors": ["Yuan Guo", "Yilong Chen", "Zixiang Ren", "Derrick Wing Kwan Ng", "Jie Xu"], "title": "Near-Field Multi-Cell ISCAP with Extremely Large-Scale Antenna Array", "comment": null, "summary": "This paper investigates a coordinated multi-cell integrated sensing, communication, and powering (ISCAP) system operating in the electromagnetic near field, where each base station (BS) employs an extremely large-scale antenna array (ELAA) to simultaneously support downlink communication, wireless power transfer (WPT), and environmental sensing. Three categories of communication users (CUs) with different interference cancellation capabilities are considered, and sensing is enabled through a distributed multiple-input multiple-output (MIMO) radar architecture. To address the resulting design challenges, a robust optimization framework is proposed by optimizing the beamforming strategy to maximize the worst-case detection probability over a prescribed sensing region, subject to per-user signal-to-interference-plus-noise ratio (SINR) constraints and energy harvesting requirements at energy receivers (ERs), while explicitly capturing the uncertainty in ER locations. By leveraging semidefinite relaxation (SDR), the original non-convex problem is reformulated as a convex semidefinite program with a provably tight relaxation. Furthermore, a low-complexity maximum ratio transmission (MRT)-based suboptimal scheme is developed, yielding a closed-form solution in the asymptotic regime as the number of antenna elements approaches infinity. Extensive numerical results reveal the fundamental trade-offs among sensing accuracy, communication reliability, and WPT efficiency.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u57fa\u7ad9\u534f\u4f5c\u7684\u8fd1\u573aISCAP\u7cfb\u7edf\uff0c\u4f7f\u7528\u8d85\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u540c\u65f6\u652f\u6301\u901a\u4fe1\u3001\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u548c\u73af\u5883\u611f\u77e5\uff0c\u63d0\u51fa\u4e86\u9c81\u68d2\u4f18\u5316\u6846\u67b6\u6765\u6700\u5927\u5316\u6700\u5dee\u68c0\u6d4b\u6982\u7387\u3002", "motivation": "\u968f\u77406G\u548c\u7269\u8054\u7f51\u53d1\u5c55\uff0c\u9700\u8981\u96c6\u6210\u611f\u77e5\u3001\u901a\u4fe1\u548c\u80fd\u91cf\u4f20\u8f93\u7684\u667a\u80fd\u7cfb\u7edf\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u8fdc\u573a\uff0c\u800c\u8fd1\u573a\u573a\u666f\u4e0b\u8d85\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u7684\u7279\u6027\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u7528\u6237\u5e72\u6270\u6d88\u9664\u80fd\u529b\u5dee\u5f02\u548c\u80fd\u91cf\u63a5\u6536\u5668\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u8bbe\u8ba1\u6311\u6218\u3002", "method": "\u63d0\u51fa\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u7b56\u7565\u6700\u5927\u5316\u89c4\u5b9a\u611f\u77e5\u533a\u57df\u7684\u6700\u5dee\u68c0\u6d4b\u6982\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u7528\u6237SINR\u7ea6\u675f\u548c\u80fd\u91cf\u63a5\u6536\u5668\u7684\u80fd\u91cf\u6536\u96c6\u8981\u6c42\u3002\u4f7f\u7528\u534a\u5b9a\u677e\u5f1b\u5c06\u975e\u51f8\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u534a\u5b9a\u89c4\u5212\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u6700\u5927\u6bd4\u4f20\u8f93\u7684\u4f4e\u590d\u6742\u5ea6\u6b21\u4f18\u65b9\u6848\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u611f\u77e5\u7cbe\u5ea6\u3001\u901a\u4fe1\u53ef\u9760\u6027\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u6743\u8861\u3002\u534a\u5b9a\u677e\u5f1b\u88ab\u8bc1\u660e\u662f\u7d27\u7684\uff0c\u800cMRT\u65b9\u6848\u5728\u65e0\u9650\u5929\u7ebf\u6570\u6e10\u8fd1\u6761\u4ef6\u4e0b\u6709\u95ed\u5f0f\u89e3\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8fd1\u573aISCAP\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u63ed\u793a\u4e86\u7cfb\u7edf\u6027\u80fd\u6743\u8861\uff0c\u4e3a\u672a\u6765\u96c6\u6210\u611f\u77e5\u901a\u4fe1\u80fd\u91cf\u4f20\u8f93\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.02175", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02175", "abs": "https://arxiv.org/abs/2601.02175", "authors": ["Trinh Van Chien", "Bui Trong Duc", "Nguyen Xuan Tung", "Van Duc Nguyen", "Waqas Khalid", "Symeon Chatzinotas", "Lajos Hanzo"], "title": "Single- and Multi-Objective Stochastic Optimization for Next-Generation Networks in the Generative AI and Quantum Computing Era", "comment": "30 pages, 19 figures, and 8 tables. Submitted for publication", "summary": "Next Generation (NG) networks move beyond simply connecting devices to creating an ecosystem of connected intelligence, especially with the support of generative Artificial Intelligence (AI) and quantum computation. These systems are expected to handle large-scale deployments and high-density networks with diverse functionalities. As a result, there is an increasing demand for efficient and intelligent algorithms that can operate under uncertainty from both propagation environments and networking systems. Traditional optimization methods often depend on accurate theoretical models of data transmission, but in real-world NG scenarios, they suffer from high computational complexity in large-scale settings. Stochastic Optimization (SO) algorithms, designed to accommodate extremely high density and extensive network scalability, have emerged as a powerful solution for optimizing wireless networks. This includes various categories that range from model-based approaches to learning-based approaches. These techniques are capable of converging within a feasible time frame while addressing complex, large-scale optimization problems. However, there is currently limited research on SO applied for NG networks, especially the upcoming Sixth-Generation (6G). In this survey, we emphasize the relationship between NG systems and SO by eight open questions involving the background, key features, and lesson learned. Overall, our study starts by providing a detailed overview of both areas, covering fundamental and widely used SO techniques, spanning from single to multi-objective signal processing. Next, we explore how different algorithms can solve NG challenges, such as load balancing, optimizing energy efficiency, improving spectral efficiency, or handling multiple performance trade-offs. Lastly, we highlight the challenges in the current research and propose new directions for future studies.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u63a2\u8ba8\u4e86\u968f\u673a\u4f18\u5316\u7b97\u6cd5\u5728\u4e0b\u4e00\u4ee3\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u5173\u6ce86G\u7f51\u7edc\uff0c\u5206\u6790\u4e86\u516b\u9879\u5173\u952e\u95ee\u9898\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u7f51\u7edc\uff08\u7279\u522b\u662f6G\uff09\u9700\u8981\u5904\u7406\u5927\u89c4\u6a21\u90e8\u7f72\u548c\u9ad8\u5bc6\u5ea6\u7f51\u7edc\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u4e14\u4f9d\u8d56\u7cbe\u786e\u6a21\u578b\uff0c\u800c\u968f\u673a\u4f18\u5316\u7b97\u6cd5\u80fd\u9002\u5e94\u9ad8\u5bc6\u5ea6\u548c\u7f51\u7edc\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u76ee\u524d\u76f8\u5173\u7814\u7a76\u6709\u9650\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u7814\u7a76\uff0c\u9996\u5148\u8be6\u7ec6\u6982\u8ff0\u968f\u673a\u4f18\u5316\u6280\u672f\u548c\u4e0b\u4e00\u4ee3\u7f51\u7edc\uff0c\u6db5\u76d6\u4ece\u5355\u76ee\u6807\u5230\u591a\u76ee\u6807\u4fe1\u53f7\u5904\u7406\u7684\u57fa\u7840\u65b9\u6cd5\uff1b\u7136\u540e\u63a2\u7d22\u4e0d\u540c\u7b97\u6cd5\u5982\u4f55\u89e3\u51b3\u4e0b\u4e00\u4ee3\u7f51\u7edc\u6311\u6218\uff1b\u6700\u540e\u5206\u6790\u5f53\u524d\u7814\u7a76\u6311\u6218\u5e76\u63d0\u51fa\u65b0\u65b9\u5411\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86\u968f\u673a\u4f18\u5316\u4e0e\u4e0b\u4e00\u4ee3\u7f51\u7edc\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u516b\u4e2a\u6d89\u53ca\u80cc\u666f\u3001\u5173\u952e\u7279\u5f81\u548c\u7ecf\u9a8c\u6559\u8bad\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4e3a\u968f\u673a\u4f18\u5316\u57286G\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\u3002", "conclusion": "\u968f\u673a\u4f18\u5316\u662f\u4f18\u5316\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7684\u6709\u529b\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u6536\u655b\u4e8e\u53ef\u884c\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u4f46\u9700\u8981\u66f4\u591a\u7814\u7a76\u6765\u5e94\u5bf96G\u7f51\u7edc\u7684\u590d\u6742\u6311\u6218\uff0c\u672c\u6587\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6307\u5bfc\u3002"}}
{"id": "2601.00830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00830", "abs": "https://arxiv.org/abs/2601.00830", "authors": ["Deep Pankajbhai Mehta"], "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning", "comment": "22 pages, 8 figures, 9 tables", "summary": "When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.", "AI": {"tldr": "AI\u6a21\u578b\u7684\u9010\u6b65\u63a8\u7406\u89e3\u91ca\u5e76\u4e0d\u80fd\u771f\u5b9e\u53cd\u6620\u5176\u51b3\u7b56\u4f9d\u636e\uff0c\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u4f1a\u6ce8\u610f\u5230\u63d0\u793a\u4fe1\u606f\u4f46\u9009\u62e9\u4e0d\u62a5\u544a\uff0c\u5373\u4f7f\u88ab\u76d1\u89c6\u4e5f\u65e0\u6539\u5584", "motivation": "\u9a8c\u8bc1AI\u7cfb\u7edf\u9010\u6b65\u63a8\u7406\u89e3\u91ca\u662f\u5426\u771f\u5b9e\u53cd\u6620\u4e86\u5f71\u54cd\u5176\u7b54\u6848\u7684\u5b9e\u9645\u56e0\u7d20\uff0c\u63a2\u7a76\u6a21\u578b\u662f\u5426\u8bda\u5b9e\u5730\u62a5\u544a\u5176\u51b3\u7b56\u4f9d\u636e", "method": "\u5728\u95ee\u9898\u4e2d\u5d4c\u5165\u63d0\u793a\u4fe1\u606f\uff0c\u6d4b\u8bd511\u4e2a\u9886\u5148AI\u6a21\u578b\u57289000\u591a\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u662f\u5426\u81ea\u53d1\u63d0\u53ca\u8fd9\u4e9b\u63d0\u793a\uff0c\u5e76\u76f4\u63a5\u8be2\u95ee\u6a21\u578b\u662f\u5426\u6ce8\u610f\u5230\u63d0\u793a", "result": "\u6a21\u578b\u51e0\u4e4e\u4ece\u4e0d\u81ea\u53d1\u63d0\u53ca\u63d0\u793a\uff0c\u4f46\u88ab\u76f4\u63a5\u8be2\u95ee\u65f6\u627f\u8ba4\u6ce8\u610f\u5230\u4e86\u63d0\u793a\uff1b\u76d1\u89c6\u6a21\u578b\u65e0\u5e2e\u52a9\uff1b\u5f3a\u5236\u62a5\u544a\u63d0\u793a\u4f1a\u5bfc\u81f4\u865a\u5047\u62a5\u544a\u548c\u51c6\u786e\u7387\u4e0b\u964d\uff1b\u8fce\u5408\u7528\u6237\u504f\u597d\u7684\u63d0\u793a\u6700\u5371\u9669", "conclusion": "\u4ec5\u4ec5\u89c2\u5bdfAI\u63a8\u7406\u8fc7\u7a0b\u4e0d\u8db3\u4ee5\u53d1\u73b0\u9690\u85cf\u7684\u5f71\u54cd\u56e0\u7d20\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u786e\u4fddAI\u89e3\u91ca\u7684\u771f\u5b9e\u6027"}}
{"id": "2601.02021", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.02021", "abs": "https://arxiv.org/abs/2601.02021", "authors": ["Runze Zheng", "Yuqing Zheng", "Zhengyi Cheng", "Long Luo", "Haoxiang Luo", "Gang Sun", "Hongfang Yu", "Dusit Niyato"], "title": "AgentVNE: LLM-Augmented Graph Reinforcement Learning for Affinity-Aware Multi-Agent Placement in Edge Agentic AI", "comment": null, "summary": "The Internet of Agents is propelling edge computing toward agentic AI and edge general intelligence (EGI). However, deploying multi-agent service (MAS) on resource-constrained edge infrastructure presents severe challenges. MAS service workflows are driven by complex cross-node interactions, dynamic memory accumulation, and collaborative tool usage. Exhibiting chain-like topological dependencies and strict affinity constraints, these workflows demand real-time responsiveness that exceeds the capabilities of traditional VNE algorithms designed for static resources. To address this, we propose AgentVNE, a cloud-edge collaborative framework utilizing a dual-layer architecture. First, AgentVNE employs a large language model (LLM) to identify implicit semantic constraints and generate affinity-based resource augmentation to resolve physical dependency issues. Second, it constructs a resource similarity-aware neural network, utilizing a pre-training and PPO fine-tuning strategy to precisely capture topological similarities between dynamic workflows and heterogeneous networks. By coupling semantic perception with topological reasoning, this mechanism effectively bridges the gap between dynamic service requirements and physical infrastructure. Simulation results demonstrate that AgentVNE reduces workflow communication latency to less than 40% of baselines and improves the service acceptance rate by approximately 5%-10% under high-load scenarios. Ultimately, this work provides a foundational solution for the semantic-aware deployment of agentic AI.", "AI": {"tldr": "AgentVNE\uff1a\u57fa\u4e8e\u4e91\u8fb9\u534f\u540c\u7684\u53cc\u5c42\u6846\u67b6\uff0c\u5229\u7528LLM\u8bc6\u522b\u8bed\u4e49\u7ea6\u675f\u548c\u8d44\u6e90\u76f8\u4f3c\u6027\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u670d\u52a1\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u90e8\u7f72\u7684\u6311\u6218\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u670d\u52a1\u63a5\u53d7\u7387\u3002", "motivation": "\u7269\u8054\u7f51\u667a\u80fd\u4f53\u6b63\u5728\u63a8\u52a8\u8fb9\u7f18\u8ba1\u7b97\u5411\u667a\u80fd\u4f53AI\u548c\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u53d1\u5c55\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u591a\u667a\u80fd\u4f53\u670d\u52a1\u9762\u4e34\u4e25\u5cfb\u6311\u6218\u3002\u8fd9\u4e9b\u670d\u52a1\u5177\u6709\u590d\u6742\u7684\u8de8\u8282\u70b9\u4ea4\u4e92\u3001\u52a8\u6001\u5185\u5b58\u79ef\u7d2f\u548c\u534f\u4f5c\u5de5\u5177\u4f7f\u7528\uff0c\u8868\u73b0\u51fa\u94fe\u5f0f\u62d3\u6251\u4f9d\u8d56\u548c\u4e25\u683c\u4eb2\u548c\u6027\u7ea6\u675f\uff0c\u4f20\u7edfVNE\u7b97\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u5176\u5b9e\u65f6\u6027\u9700\u6c42\u3002", "method": "\u63d0\u51faAgentVNE\u4e91\u8fb9\u534f\u540c\u6846\u67b6\uff1a1\uff09\u4f7f\u7528LLM\u8bc6\u522b\u9690\u5f0f\u8bed\u4e49\u7ea6\u675f\u5e76\u751f\u6210\u57fa\u4e8e\u4eb2\u548c\u6027\u7684\u8d44\u6e90\u589e\u5f3a\uff0c\u89e3\u51b3\u7269\u7406\u4f9d\u8d56\u95ee\u9898\uff1b2\uff09\u6784\u5efa\u8d44\u6e90\u76f8\u4f3c\u6027\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u91c7\u7528\u9884\u8bad\u7ec3\u548cPPO\u5fae\u8c03\u7b56\u7565\uff0c\u7cbe\u786e\u6355\u6349\u52a8\u6001\u5de5\u4f5c\u6d41\u4e0e\u5f02\u6784\u7f51\u7edc\u95f4\u7684\u62d3\u6251\u76f8\u4f3c\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cAgentVNE\u5c06\u5de5\u4f5c\u6d41\u901a\u4fe1\u5ef6\u8fdf\u964d\u4f4e\u81f3\u57fa\u7ebf\u65b9\u6cd5\u768440%\u4ee5\u4e0b\uff0c\u5728\u9ad8\u8d1f\u8f7d\u573a\u666f\u4e0b\u5c06\u670d\u52a1\u63a5\u53d7\u7387\u63d0\u9ad8\u7ea65%-10%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u4e0e\u62d3\u6251\u63a8\u7406\u7684\u8026\u5408\uff0c\u6709\u6548\u5f25\u5408\u4e86\u52a8\u6001\u670d\u52a1\u9700\u6c42\u4e0e\u7269\u7406\u57fa\u7840\u8bbe\u65bd\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u667a\u80fd\u4f53AI\u7684\u8bed\u4e49\u611f\u77e5\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u7840\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02301", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02301", "abs": "https://arxiv.org/abs/2601.02301", "authors": ["Zhaolin Wang", "Zihao Zhou", "Cheng-Jie Zhao", "Yuanwei Liu"], "title": "Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence", "comment": "7 pages, 5 figures", "summary": "This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u751f\u6210\u5f0f\u7ad9\u70b9\u7279\u5b9a\u6ce2\u675f\u6210\u5f62\uff08GenSSBF\uff09\uff0c\u5229\u7528\u6761\u4ef6\u751f\u6210\u6a21\u578b\u5b66\u4e60\u53ef\u884c\u6ce2\u675f\u6210\u5f62\u5668\u7684\u6761\u4ef6\u5206\u5e03\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8e\u5224\u522b\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7684SSBF\u5728\u591a\u6a21\u6001\u4f20\u64ad\u8868\u793a\u548c\u6ce2\u675f\u7ed3\u6784\u7279\u5f81\u6355\u6349\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5224\u522b\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7684\u7ad9\u70b9\u7279\u5b9a\u6ce2\u675f\u6210\u5f62\uff08SSBF\uff09\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u96be\u4ee5\u6070\u5f53\u8868\u793a\u65e0\u7ebf\u4f20\u64ad\u56fa\u6709\u7684\u591a\u6a21\u6001\u7279\u6027\uff1b2\uff09\u65e0\u6cd5\u6709\u6548\u6355\u6349\u6ce2\u675f\u6210\u5f62\u5668\u7684\u7ed3\u6784\u7279\u5f81\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86SSBF\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7a7a\u95f4\u667a\u80fd\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u751f\u6210\u5f0f\u7ad9\u70b9\u7279\u5b9a\u6ce2\u675f\u6210\u5f62\uff08GenSSBF\uff09\uff0c\u91c7\u7528\u6761\u4ef6\u751f\u6210\u6a21\u578b\u5b66\u4e60\u53ef\u884c\u6ce2\u675f\u6210\u5f62\u5668\u7684\u6761\u4ef6\u5206\u5e03\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u7c97\u7cd9\u7684\u4fe1\u9053\u611f\u77e5\u6d4b\u91cf\u4e2d\u5408\u6210\u591a\u6837\u4e14\u9ad8\u4fdd\u771f\u7684\u6ce2\u675f\u5019\u9009\u65b9\u6848\uff0c\u5305\u62ec\u57fa\u7840\u539f\u7406\u3001\u7cfb\u7edf\u8bbe\u8ba1\u548c\u5b9e\u73b0\u65b9\u6cd5\u3002", "result": "\u5ba4\u5185\u548c\u5ba4\u5916\u573a\u666f\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cGenSSBF\u80fd\u591f\u4ee5\u6781\u4f4e\u7684\u4fe1\u9053\u83b7\u53d6\u5f00\u9500\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u3002", "conclusion": "GenSSBF\u901a\u8fc7\u6761\u4ef6\u751f\u6210\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfSSBF\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7a7a\u95f4\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4ecd\u6709\u4e00\u4e9b\u5f00\u653e\u7814\u7a76\u95ee\u9898\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2601.00843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00843", "abs": "https://arxiv.org/abs/2601.00843", "authors": ["Ayda Aghaei Nia"], "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification", "comment": "16 pages, 7 figures, 3 tables. Source code and implementation available at: https://github.com/ayda-aghaei/OmniNeuro. Highlights the use of LLMs (Gemini) and Quantum probability formalism for real-time BCI explainability", "summary": "While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the \"trial-and-error\" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.", "AI": {"tldr": "OmniNeuro\u662f\u4e00\u4e2a\u65b0\u578bHCI\u6846\u67b6\uff0c\u5c06BCI\u4ece\u9ed1\u76d2\u89e3\u7801\u5668\u8f6c\u53d8\u4e3a\u900f\u660e\u53cd\u9988\u4f19\u4f34\uff0c\u901a\u8fc7\u7269\u7406\u3001\u6df7\u6c8c\u548c\u91cf\u5b50\u542f\u53d1\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u4e09\u4e2a\u53ef\u89e3\u91ca\u6027\u5f15\u64ce\uff0c\u5b9e\u73b0\u5b9e\u65f6\u795e\u7ecf\u58f0\u5316\u548c\u751f\u6210\u5f0fAI\u4e34\u5e8a\u62a5\u544a\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u63d0\u9ad8\u4e86\u8111\u673a\u63a5\u53e3\u7684\u89e3\u7801\u7cbe\u5ea6\uff0c\u4f46\u5176\"\u9ed1\u76d2\"\u7279\u6027\u963b\u788d\u4e86\u4e34\u5e8a\u91c7\u7528\uff0c\u5bfc\u81f4\u7528\u6237\u632b\u6298\u611f\u548c\u795e\u7ecf\u53ef\u5851\u6027\u7ed3\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u53ef\u89e3\u91ca\u7684\u53cd\u9988\u7cfb\u7edf\u3002", "method": "\u63d0\u51faOmniNeuro\u6846\u67b6\uff0c\u96c6\u6210\u4e09\u4e2a\u53ef\u89e3\u91ca\u6027\u5f15\u64ce\uff1a1)\u7269\u7406(\u80fd\u91cf)\u5206\u6790\uff0c2)\u6df7\u6c8c(\u5206\u5f62\u590d\u6742\u5ea6)\u5206\u6790\uff0c3)\u91cf\u5b50\u542f\u53d1\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3002\u8fd9\u4e9b\u6307\u6807\u9a71\u52a8\u5b9e\u65f6\u795e\u7ecf\u58f0\u5316\u548c\u751f\u6210\u5f0fAI\u4e34\u5e8a\u62a5\u544a\uff0c\u6846\u67b6\u4e0e\u89e3\u7801\u5668\u65e0\u5173\uff0c\u53ef\u4f5c\u4e3a\u4efb\u4f55\u5148\u8fdb\u67b6\u6784\u7684\u53ef\u89e3\u91ca\u6027\u5c42\u3002", "result": "\u5728PhysioNet\u6570\u636e\u96c6(N=109)\u4e0a\u8fbe\u5230\u5e73\u574758.52%\u7684\u51c6\u786e\u7387\uff0c\u5b9a\u6027\u8bd5\u70b9\u7814\u7a76(N=3)\u8bc1\u5b9e\u53ef\u89e3\u91ca\u53cd\u9988\u5e2e\u52a9\u7528\u6237\u8c03\u8282\u5fc3\u7406\u52aa\u529b\uff0c\u51cf\u5c11\"\u8bd5\u9519\"\u9636\u6bb5\u3002", "conclusion": "OmniNeuro\u901a\u8fc7\u5c06BCI\u8f6c\u53d8\u4e3a\u900f\u660e\u53cd\u9988\u4f19\u4f34\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u9ed1\u76d2\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4e34\u5e8a\u53ef\u7528\u6027\uff0c\u5176\u89e3\u7801\u5668\u65e0\u5173\u8bbe\u8ba1\u4f7f\u5176\u9002\u7528\u4e8e\u5404\u79cd\u5148\u8fdb\u67b6\u6784\u3002"}}
{"id": "2601.02240", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.02240", "abs": "https://arxiv.org/abs/2601.02240", "authors": ["Matteo Bordin", "Andrea Lacava", "Michele Polese", "Francesca Cuomo", "Tommaso Melodia"], "title": "Enabling Deep Reinforcement Learning Research for Energy Saving in Open RAN", "comment": null, "summary": "The growing performance demands and higher deployment densities of next-generation wireless systems emphasize the importance of adopting strategies to manage the energy efficiency of mobile networks. In this demo, we showcase a framework that enables research on Deep Reinforcement Learning (DRL) techniques for improving the energy efficiency of intelligent and programmable Open Radio Access Network (RAN) systems. Using the open-source simulator ns-O-RAN and the reinforcement learning environment Gymnasium, the framework enables to train and evaluate DRL agents that dynamically control the activation and deactivation of cells in a 5G network. We show how to collect data for training and evaluate the impact of DRL on energy efficiency in a realistic 5G network scenario, including users' mobility and handovers, a full protocol stack, and 3rd Generation Partnership Project (3GPP)-compliant channel models. The tool will be open-sourced and a tutorial for energy efficiency testing in ns-O-RAN.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u53ef\u7f16\u7a0b\u5f00\u653e\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u7684\u80fd\u6548\u7ba1\u7406\uff0c\u901a\u8fc7\u52a8\u6001\u63a7\u52365G\u7f51\u7edc\u4e2d\u7684\u5c0f\u533a\u6fc0\u6d3b/\u4f11\u7720\u6765\u4f18\u5316\u80fd\u8017\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u5bf9\u6027\u80fd\u548c\u90e8\u7f72\u5bc6\u5ea6\u8981\u6c42\u8d8a\u6765\u8d8a\u9ad8\uff0c\u9700\u8981\u6709\u6548\u7ba1\u7406\u79fb\u52a8\u7f51\u7edc\u7684\u80fd\u6e90\u6548\u7387\u3002\u5f00\u653e\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\uff08O-RAN\uff09\u7684\u667a\u80fd\u5316\u548c\u53ef\u7f16\u7a0b\u7279\u6027\u4e3a\u57fa\u4e8eAI\u7684\u80fd\u6548\u4f18\u5316\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u6a21\u62df\u5668ns-O-RAN\u548c\u5f3a\u5316\u5b66\u4e60\u73af\u5883Gymnasium\u6784\u5efa\u6846\u67b6\uff0c\u8bad\u7ec3\u548c\u8bc4\u4f30\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u52a8\u6001\u63a7\u52365G\u7f51\u7edc\u4e2d\u5c0f\u533a\u7684\u6fc0\u6d3b\u548c\u4f11\u7720\u72b6\u6001\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u5305\u542b\u7528\u6237\u79fb\u52a8\u6027\u3001\u5207\u6362\u3001\u5b8c\u6574\u534f\u8bae\u6808\u548c3GPP\u517c\u5bb9\u4fe1\u9053\u6a21\u578b\u7684\u771f\u5b9e5G\u7f51\u7edc\u573a\u666f\u4e2d\uff0c\u6536\u96c6\u8bad\u7ec3\u6570\u636e\u5e76\u8bc4\u4f30\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5bf9\u80fd\u6548\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u5de5\u5177\u5c06\u5f00\u6e90\u5e76\u9644\u5e26ns-O-RAN\u80fd\u6548\u6d4b\u8bd5\u6559\u7a0b\uff0c\u4e3a\u53ef\u7f16\u7a0b\u5f00\u653e\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u7684\u80fd\u6548\u4f18\u5316\u7814\u7a76\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2601.02330", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.02330", "abs": "https://arxiv.org/abs/2601.02330", "authors": ["Guoda Qiu", "Ling Liu", "Yuejun Wei", "Liping Li"], "title": "Error-Building Decoding of Linear Block Codes", "comment": null, "summary": "This paper proposes a novel maximum-likelihood (ML) soft-decision decoding framework for linear block codes, termed error-building decoding (EBD). The complete decoding process can be performed using only the parity-check matrix, without requiring any other pre-constructed information (such as trellis diagrams or error-pattern lists), and it can also be customized by exploiting the algebraic properties of the code. We formally define error-building blocks, and derive a recursive theorem that allows efficient construction of larger locally optimal blocks from smaller ones, thereby effectively searching for the block associated with the most likely error pattern. The EBD framework is further optimized for extended Hamming codes as an example, through offline and online exclusion mechanisms, leading to a substantial complexity reduction without loss of ML performance. Complexity analysis shows that, for extended Hamming codes of lengths 64, 128, and 256, the fully optimized EBD requires approximately an order of magnitude fewer floating-point operations on average than minimum-edge trellis Viterbi decoding at a frame error rate of $10^{-3}$.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u7684\u8f6f\u5224\u51b3\u89e3\u7801\u6846\u67b6EBD\uff0c\u4ec5\u9700\u6821\u9a8c\u77e9\u9635\u5373\u53ef\u5b8c\u6210\u89e3\u7801\uff0c\u65e0\u9700\u9884\u6784\u5efa\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u5b9a\u7406\u9ad8\u6548\u6784\u5efa\u6700\u4f18\u9519\u8bef\u5757\u3002", "motivation": "\u4f20\u7edf\u8f6f\u5224\u51b3\u89e3\u7801\u65b9\u6cd5\u9700\u8981\u9884\u6784\u5efa\u7f51\u683c\u56fe\u6216\u9519\u8bef\u6a21\u5f0f\u5217\u8868\u7b49\u989d\u5916\u4fe1\u606f\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4ec5\u4f9d\u8d56\u6821\u9a8c\u77e9\u9635\u7684\u901a\u7528\u89e3\u7801\u6846\u67b6\uff0c\u964d\u4f4e\u590d\u6742\u5ea6\u540c\u65f6\u4fdd\u6301\u6700\u5927\u4f3c\u7136\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u9519\u8bef\u6784\u5efa\u89e3\u7801(EBD)\u6846\u67b6\uff1a1) \u5b9a\u4e49\u9519\u8bef\u6784\u5efa\u5757\uff1b2) \u63a8\u5bfc\u9012\u5f52\u5b9a\u7406\uff0c\u4ece\u5c0f\u5757\u9ad8\u6548\u6784\u5efa\u66f4\u5927\u7684\u5c40\u90e8\u6700\u4f18\u5757\uff1b3) \u9488\u5bf9\u6269\u5c55\u6c49\u660e\u7801\u4f18\u5316\uff0c\u901a\u8fc7\u79bb\u7ebf\u548c\u5728\u7ebf\u6392\u9664\u673a\u5236\u5927\u5e45\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "result": "\u5bf9\u4e8e\u957f\u5ea6\u4e3a64\u3001128\u548c256\u7684\u6269\u5c55\u6c49\u660e\u7801\uff0c\u5728\u5e27\u9519\u8bef\u738710^-3\u65f6\uff0c\u5b8c\u5168\u4f18\u5316\u7684EBD\u6bd4\u6700\u5c0f\u8fb9\u7f51\u683cViterbi\u89e3\u7801\u5e73\u5747\u51cf\u5c11\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u6d6e\u70b9\u8fd0\u7b97\u3002", "conclusion": "EBD\u662f\u4e00\u79cd\u4ec5\u9700\u6821\u9a8c\u77e9\u9635\u7684\u901a\u7528\u6700\u5927\u4f3c\u7136\u8f6f\u5224\u51b3\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u9012\u5f52\u6784\u5efa\u548c\u4f18\u5316\u673a\u5236\u663e\u8457\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u5728\u6269\u5c55\u6c49\u660e\u7801\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.00845", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00845", "abs": "https://arxiv.org/abs/2601.00845", "authors": ["Lili Chen", "Wensheng Gan", "Shuang Liang", "Philip S. Yu"], "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes", "comment": "preprint", "summary": "Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL", "AI": {"tldr": "TPP-TAL\u662f\u4e00\u4e2a\u589e\u5f3aLLMs\u4e2d\u65f6\u95f4\u611f\u77e5\u7684\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5bf9\u9f50\u65f6\u95f4\u52a8\u6001\u4e0e\u4e0a\u4e0b\u6587\u8bed\u4e49\uff0c\u6539\u8fdb\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u5efa\u6a21\u4e2d\u7684\u65f6\u95f4\u4f3c\u7136\u4f30\u8ba1\u548c\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5e94\u7528\u4e8e\u65f6\u95f4\u70b9\u8fc7\u7a0b\u65f6\u4ecd\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u65f6\u95f4\u4fe1\u606f\u4e0e\u8bed\u4e49\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u800c\u8fd9\u5bf9\u4e8e\u51c6\u786e\u7684\u4e8b\u4ef6\u5efa\u6a21\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faTPP-TAL\u6846\u67b6\uff0c\u4e0d\u91c7\u7528\u7b80\u5355\u62fc\u63a5\u4e8b\u4ef6\u65f6\u95f4\u548c\u7c7b\u578b\u5d4c\u5165\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u800c\u662f\u5728\u5c06\u4fe1\u606f\u8f93\u5165LLM\u4e4b\u524d\u663e\u5f0f\u5bf9\u9f50\u65f6\u95f4\u52a8\u6001\u4e0e\u4e0a\u4e0b\u6587\u8bed\u4e49\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u597d\u5730\u611f\u77e5\u4e8b\u4ef6\u53ca\u5176\u5468\u56f4\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u957f\u7a0b\u4ea4\u4e92\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cTPP-TAL\u5728\u65f6\u95f4\u4f3c\u7136\u4f30\u8ba1\u548c\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u5e26\u6765\u663e\u8457\u6539\u8fdb\uff0c\u7a81\u663e\u4e86\u589e\u5f3aLLMs\u65f6\u95f4\u611f\u77e5\u5bf9\u4e8e\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u5efa\u6a21\u7684\u91cd\u8981\u6027\u3002", "conclusion": "TPP-TAL\u901a\u8fc7\u589e\u5f3aLLMs\u4e2d\u7684\u65f6\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u95f4\u70b9\u8fc7\u7a0b\u5efa\u6a21\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00848", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00848", "abs": "https://arxiv.org/abs/2601.00848", "authors": ["Ron F. Del Rosario"], "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models", "comment": "26 pages, 3 figures, 7 tables. Datasets and code: https://huggingface.co/guerilla7/agentic-safety-gguf", "summary": "We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eOpenTelemetry\u8ffd\u8e2a\u5206\u6790\u3001\u7528\u4e8e\u68c0\u6d4b\u591a\u667a\u80fd\u4f53AI\u5de5\u4f5c\u6d41\u4e2d\u65f6\u5e8f\u653b\u51fb\u6a21\u5f0f\u7684\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u548c\u8fed\u4ee3\u8bad\u7ec3\uff0c\u51c6\u786e\u7387\u4ece42.86%\u63d0\u5347\u523074.29%\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53AI\u5de5\u4f5c\u6d41\u9762\u4e34\u65f6\u5e8f\u653b\u51fb\u5a01\u80c1\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u534f\u8c03\u653b\u51fb\u548c\u76d1\u7ba1\u8fdd\u89c4\u7684\u4e13\u95e8\u68c0\u6d4b\u80fd\u529b\uff0c\u4e14\u7f3a\u4e4f\u53ef\u590d\u73b0\u7684\u6846\u67b6\u4f9b\u4ece\u4e1a\u8005\u6839\u636e\u81ea\u8eab\u5a01\u80c1\u73af\u5883\u5b9a\u5236\u5b89\u5168\u6a21\u578b\u3002", "method": "1) \u4ece18\u4e2a\u516c\u5171\u7f51\u7edc\u5b89\u5168\u6e90\u548c35,026\u6761\u5408\u6210OpenTelemetry\u8ffd\u8e2a\u4e2d\u6784\u5efa80,851\u4e2a\u793a\u4f8b\u7684\u6570\u636e\u96c6\uff1b2) \u5728\u8d44\u6e90\u53d7\u9650\u7684ARM64\u786c\u4ef6\u4e0a\u4f7f\u7528\u8fed\u4ee3QLoRA\u5fae\u8c03\u8fdb\u884c\u4e09\u6b21\u8bad\u7ec3\u8fed\u4ee3\uff1b3) \u91c7\u7528\u7b56\u7565\u6027\u6570\u636e\u589e\u5f3a\uff1b4) \u5f00\u53d1\u81ea\u5b9a\u4e49\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u81ea\u5b9a\u4e49\u57fa\u51c6\u51c6\u786e\u7387\u4ece42.86%\u63d0\u5347\u81f374.29%\uff0c\u5b9e\u73b0\u4e8631.4\u4e2a\u767e\u5206\u70b9\u7684\u663e\u8457\u63d0\u5347\u3002\u9488\u5bf9\u7279\u5b9a\u77e5\u8bc6\u5dee\u8ddd\u7684\u5b9a\u5411\u793a\u4f8b\u8bad\u7ec3\u6548\u679c\u4f18\u4e8e\u65e0\u5dee\u522b\u6269\u5c55\u3002\u867d\u7136\u5b9e\u9645\u90e8\u7f72\u4ecd\u9700\u4eba\u5de5\u76d1\u7763\uff08\u5b58\u5728\u8bef\u62a5\u7387\uff09\uff0c\u4f46\u8be5\u65b9\u6cd5\u4e3a\u4ece\u4e1a\u8005\u6784\u5efa\u5b9a\u5236\u5316\u667a\u80fd\u4f53\u5b89\u5168\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u590d\u73b0\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u9996\u4e2a\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u6784\u5efa\u9002\u5e94\u5176\u5a01\u80c1\u73af\u5883\u7684\u5b9a\u5236\u5316\u667a\u80fd\u4f53\u5b89\u5168\u6a21\u578b\u3002\u5173\u952e\u8d21\u732e\u5305\u62ec\uff1a\u591a\u667a\u80fd\u4f53\u534f\u8c03\u653b\u51fb\u7684\u5408\u6210\u8ffd\u8e2a\u751f\u6210\u65b9\u6cd5\u3001\u8bad\u7ec3\u6570\u636e\u7ec4\u6210\u51b3\u5b9a\u884c\u4e3a\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u4ee5\u53ca\u5728HuggingFace\u4e0a\u5b8c\u6574\u5f00\u6e90\u6570\u636e\u96c6\u3001\u8bad\u7ec3\u811a\u672c\u548c\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2601.00856", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00856", "abs": "https://arxiv.org/abs/2601.00856", "authors": ["Milos Stankovic", "Ella Hirche", "Sarah Kollatzsch", "Julia Nadine Doetsch"], "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks", "comment": "Comment on arXiv:2506.08872", "summary": "Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5bf9Kosmyna\u7b49\u4eba(2025)\u5173\u4e8eChatGPT\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u8868\u73b0\u7814\u7a76\u7684\u8bc4\u8bba\u6587\u7ae0\uff0c\u6307\u51fa\u4e86\u539f\u7814\u7a76\u5728\u6837\u672c\u91cf\u3001\u53ef\u91cd\u590d\u6027\u3001EEG\u5206\u6790\u3001\u7ed3\u679c\u62a5\u544a\u548c\u900f\u660e\u5ea6\u7b49\u65b9\u9762\u7684\u95ee\u9898\u3002", "motivation": "\u5bf9Kosmyna\u7b49\u4eba(2025)\u5173\u4e8eAI\u52a9\u624b\u5bf9\u4eba\u7c7b\u5199\u4f5c\u4efb\u52a1\u8ba4\u77e5\u5f71\u54cd\u7684\u7814\u7a76\u8fdb\u884c\u5efa\u8bbe\u6027\u8bc4\u8bba\uff0c\u65e8\u5728\u63d0\u9ad8\u8be5\u7814\u7a76\u7684\u5b66\u672f\u4e25\u8c28\u6027\u548c\u53d1\u8868\u51c6\u5907\u5ea6\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\u539f\u7814\u7a76\u7684\u8bbe\u8ba1\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u548c\u62a5\u544a\uff0c\u91cd\u70b9\u5173\u6ce8\u6837\u672c\u91cf\u9650\u5236\u3001\u5206\u6790\u53ef\u91cd\u590d\u6027\u3001EEG\u65b9\u6cd5\u5b66\u95ee\u9898\u3001\u7ed3\u679c\u4e0d\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u4e0d\u8db3\u7b49\u65b9\u9762\u3002", "result": "\u8bc6\u522b\u51fa\u539f\u7814\u7a76\u5b58\u5728\u7684\u4e94\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u6837\u672c\u91cf\u6709\u9650\uff1b2) \u5206\u6790\u53ef\u91cd\u590d\u6027\u95ee\u9898\uff1b3) EEG\u5206\u6790\u65b9\u6cd5\u5b66\u95ee\u9898\uff1b4) \u7ed3\u679c\u62a5\u544a\u4e0d\u4e00\u81f4\uff1b5) \u7814\u7a76\u8fc7\u7a0b\u548c\u53d1\u73b0\u900f\u660e\u5ea6\u4e0d\u8db3\u3002", "conclusion": "\u5efa\u8bae\u5bf9Kosmyna\u7b49\u4eba(2025)\u7684\u7814\u7a76\u7ed3\u679c\u8fdb\u884c\u66f4\u4fdd\u5b88\u7684\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u4ee5\u589e\u5f3a\u7814\u7a76\u7684\u79d1\u5b66\u4e25\u8c28\u6027\u548c\u53d1\u8868\u51c6\u5907\u5ea6\u3002"}}
{"id": "2601.00869", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00869", "abs": "https://arxiv.org/abs/2601.00869", "authors": ["Huang Junyao", "Situ Ruimin", "Ye Renqin"], "title": "Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery", "comment": "19 pages, 5 tables. Dataset and code available at https://github.com/zhizibianjie-omniedge/geo-cultural-encoding", "summary": "As artificial intelligence systems increasingly mediate consumer information discovery,\n  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large\n  Language Models (LLMs) -- systematic differences in brand recommendations arising from\n  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,\n  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6\n  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,\n  p<.001). This disparity persists in identical English queries, indicating training data\n  geography -- not language -- drives the effect. We introduce the Existence Gap: brands\n  absent from LLM training corpora lack \"existence\" in AI responses regardless of quality.\n  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%\n  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how\n  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we\n  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic\n  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility\n  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization\n  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats\n  through semantic coverage, technical depth, and cultural localization. Our findings reveal\n  that in AI-mediated markets, the limits of a brand's \"Data Boundaries\" define the limits\n  of its \"Market Frontiers.\"", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u8bad\u7ec3\u6570\u636e\u7684\u5730\u7406\u5206\u5e03\u5bfc\u81f4\u54c1\u724c\u63a8\u8350\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4e2d\u56fdLLM\u7684\u54c1\u724c\u63d0\u53ca\u7387\u6bd4\u56fd\u9645LLM\u9ad830.6\u4e2a\u767e\u5206\u70b9\uff0c\u63d0\u51fa\u4e86\"\u5b58\u5728\u5dee\u8ddd\"\u6982\u5ff5\u548c\"\u6570\u636e\u62a4\u57ce\u6cb3\"\u6846\u67b6", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4ecb\u5165\u6d88\u8d39\u8005\u4fe1\u606f\u53d1\u73b0\u8fc7\u7a0b\uff0c\u54c1\u724c\u9762\u4e34\u7b97\u6cd5\u4e0d\u53ef\u89c1\u6027\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6587\u5316\u7f16\u7801\u73b0\u8c61\u2014\u2014\u7531\u8bad\u7ec3\u6570\u636e\u6784\u6210\u5bfc\u81f4\u7684\u54c1\u724c\u63a8\u8350\u7cfb\u7edf\u6027\u5dee\u5f02", "method": "\u5206\u67901,909\u4e2a\u7eaf\u82f1\u6587\u67e5\u8be2\uff0c\u8986\u76d66\u4e2aLLM\uff08GPT-4o\u3001Claude\u3001Gemini\u3001Qwen3\u3001DeepSeek\u3001Doubao\uff09\u548c30\u4e2a\u54c1\u724c\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790\u54c1\u724c\u53ef\u89c1\u6027\u5dee\u5f02", "result": "\u4e2d\u56fdLLM\u7684\u54c1\u724c\u63d0\u53ca\u7387\u6bd4\u56fd\u9645LLM\u9ad830.6\u4e2a\u767e\u5206\u70b9\uff0888.9% vs. 58.3%\uff09\uff0c\u8fd9\u79cd\u5dee\u5f02\u5728\u76f8\u540c\u7684\u82f1\u6587\u67e5\u8be2\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u8868\u660e\u8bad\u7ec3\u6570\u636e\u7684\u5730\u7406\u5206\u5e03\u800c\u975e\u8bed\u8a00\u662f\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20", "conclusion": "\u63d0\u51fa\u4e86\"\u6570\u636e\u62a4\u57ce\u6cb3\"\u6846\u67b6\uff0c\u5c06AI\u53ef\u89c1\u5185\u5bb9\u6982\u5ff5\u5316\u4e3aVRIN\u6218\u7565\u8d44\u6e90\uff0c\u5efa\u8bae\u54c1\u724c\u901a\u8fc7\u8bed\u4e49\u8986\u76d6\u3001\u6280\u672f\u6df1\u5ea6\u548c\u6587\u5316\u672c\u5730\u5316\u6784\u5efa\u6570\u636e\u62a4\u57ce\u6cb3\uff0c\u5b9e\u73b0\u7b97\u6cd5\u65e0\u5904\u4e0d\u5728\u7684\u6218\u7565\u76ee\u6807"}}
{"id": "2601.00880", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.00880", "abs": "https://arxiv.org/abs/2601.00880", "authors": ["Anthony Mikinka"], "title": "Universal Conditional Logic: A Formal Language for Prompt Engineering", "comment": "25 pages, 15 figures, 5 tables. Includes appendices with variable reference, pattern library, and O_s calculation examples. Supplementary materials: V1-V4.1 prompt source code and 305 model responses available at GitHub repositories", "summary": "We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.", "AI": {"tldr": "UCL\u662f\u4e00\u4e2a\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u542f\u53d1\u5f0f\u5b9e\u8df5\u8f6c\u5316\u4e3a\u7cfb\u7edf\u4f18\u5316\u7684\u6570\u5b66\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u5e76\u964d\u4f4e\u6210\u672c\uff0c\u63ed\u793a\u4e86\u8fc7\u5ea6\u89c4\u8303\u6096\u8bba\u548c\u6a21\u578b\u67b6\u6784\u7279\u5b9a\u7684\u4f18\u5316\u9700\u6c42\u3002", "motivation": "\u5f53\u524d\u63d0\u793a\u5de5\u7a0b\u4e3b\u8981\u4f9d\u8d56\u542f\u53d1\u5f0f\u5b9e\u8df5\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u4f18\u5316\u6846\u67b6\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u7ecf\u9a8c\u6027\u5b9e\u8df5\u8f6c\u53d8\u4e3a\u53ef\u7cfb\u7edf\u4f18\u5316\u7684\u6570\u5b66\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8LLM\u4ea4\u4e92\u7684\u6548\u7387\u548c\u53ef\u9884\u6d4b\u6027\u3002", "method": "\u63d0\u51faUniversal Conditional Logic (UCL)\u6846\u67b6\uff0c\u5305\u542b\u6307\u6807\u51fd\u6570(I_i)\u3001\u7ed3\u6784\u5f00\u9500(O_s = gamma * sum(ln C_k))\u3001\u65e9\u671f\u7ed1\u5b9a\u7b49\u6838\u5fc3\u673a\u5236\u3002\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30(N=305, 11\u4e2a\u6a21\u578b, 4\u6b21\u8fed\u4ee3)\u9a8c\u8bc1\u6846\u67b6\u6548\u679c\uff0c\u5e76\u5206\u6790\u8fc7\u5ea6\u89c4\u8303\u6096\u8bba(\u9608\u503cS* = 0.509)\u3002", "result": "\u663e\u8457\u51cf\u5c11token\u4f7f\u7528(29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01)\uff0c\u76f8\u5e94\u964d\u4f4e\u6210\u672c\u3002\u53d1\u73b0\u8fc7\u5ea6\u89c4\u8303\u6096\u8bba\uff1a\u8d85\u8fc7\u9608\u503cS* = 0.509\u540e\uff0c\u989d\u5916\u89c4\u8303\u4f1a\u4e8c\u6b21\u964d\u4f4e\u6027\u80fd\u3002\u9a8c\u8bc1\u4e86\u6838\u5fc3\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u5e76\u53d1\u73b0\u6700\u4f18UCL\u914d\u7f6e\u56e0\u6a21\u578b\u67b6\u6784\u800c\u5f02\u3002", "conclusion": "UCL\u4e3a\u9ad8\u6548LLM\u4ea4\u4e92\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6821\u51c6\u7684\u6846\u67b6\uff0c\u6a21\u578b\u5bb6\u65cf\u7279\u5b9a\u7684\u4f18\u5316\u662f\u5173\u952e\u7814\u7a76\u65b9\u5411\u3002\u8be5\u6846\u67b6\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u542f\u53d1\u5f0f\u5b9e\u8df5\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u5316\u4f18\u5316\uff0c\u4e3aLLM\u4ea4\u4e92\u6548\u7387\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.00885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00885", "abs": "https://arxiv.org/abs/2601.00885", "authors": ["Mandar Parab"], "title": "Counterfactual Self-Questioning for Stable Policy Optimization in Language Models", "comment": null, "summary": "Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.", "AI": {"tldr": "\u63d0\u51faCounterfactual Self-Questioning\u6846\u67b6\uff0c\u8ba9\u5355\u4e2a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5e76\u8bc4\u4f30\u81ea\u8eab\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6279\u8bc4\uff0c\u901a\u8fc7\u5185\u90e8\u751f\u6210\u7684\u76d1\u7763\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u6211\u6539\u8fdb", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u6279\u8bc4\u8005\u3001\u5b66\u4e60\u5956\u52b1\u6a21\u578b\u6216\u96c6\u6210\u91c7\u6837\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u7b80\u5355\u7a33\u5b9a\u7684\u81ea\u6211\u6539\u8fdb\u65b9\u6cd5", "method": "Counterfactual Self-Questioning\u6846\u67b6\uff1a\u6a21\u578b\u9996\u5148\u751f\u6210\u521d\u59cb\u63a8\u7406\u8f68\u8ff9\uff0c\u7136\u540e\u63d0\u51fa\u9488\u5bf9\u6f5c\u5728\u5931\u8d25\u70b9\u7684\u8d28\u7591\u95ee\u9898\uff0c\u6700\u540e\u751f\u6210\u66b4\u9732\u9519\u8bef\u5047\u8bbe\u6216\u65e0\u6548\u6b65\u9aa4\u7684\u66ff\u4ee3\u63a8\u7406\u8f68\u8ff9\uff0c\u8fd9\u4e9b\u53cd\u4e8b\u5b9e\u8f68\u8ff9\u63d0\u4f9b\u53ef\u76f4\u63a5\u7528\u4e8e\u7b56\u7565\u4f18\u5316\u7684\u7ed3\u6784\u5316\u76f8\u5bf9\u53cd\u9988", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53cd\u4e8b\u5b9e\u81ea\u6211\u8d28\u7591\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5c0f\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u5185\u90e8\u751f\u6210\u7684\u76d1\u7763\u5c31\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u6211\u6539\u8fdb", "conclusion": "\u63d0\u51fa\u7684Counterfactual Self-Questioning\u6846\u67b6\u4e3a\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u7a33\u5b9a\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u5916\u90e8\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u7684\u81ea\u6211\u76d1\u7763\u5b66\u4e60"}}
{"id": "2601.00923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00923", "abs": "https://arxiv.org/abs/2601.00923", "authors": ["Josef Ott"], "title": "Context Collapse: In-Context Learning and Model Collapse", "comment": "Master's thesis", "summary": "This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u73b0\u8c61\uff1a\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6a21\u578b\u5d29\u6e83\u3002\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5668\u548c\u7b80\u5316\u8bbe\u7f6e\uff0c\u5206\u6790\u4e86ICL\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\u548c\u6a21\u578b\u5d29\u6e83\u7684\u6536\u655b\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u5d29\u6e83\u7684\u65b0\u6982\u5ff5\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6a21\u578b\u5d29\u6e83\u7684\u673a\u5236\uff0c\u7406\u89e3ICL\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\uff0c\u5206\u6790\u6a21\u578b\u5d29\u6e83\u7684\u6536\u655b\u6761\u4ef6\uff0c\u5e76\u63a2\u7d22\u957f\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "1. \u4f7f\u7528\u5e26\u6743\u91cd\u7ed1\u5b9a\u7684\u7ebf\u6027\u53d8\u6362\u5668\u7814\u7a76ICL\uff0c\u5c06\u5176\u524d\u5411\u4f20\u64ad\u7b80\u5316\u4e3a\u9884\u6761\u4ef6\u68af\u5ea6\u4e0b\u964d\uff1b2. \u4f7f\u7528\u9785\u548c\u968f\u673a\u6e38\u8d70\u7406\u8bba\u5206\u6790\u7ebf\u6027\u56de\u5f52\u548c\u9ad8\u65af\u62df\u5408\u4e2d\u7684\u6a21\u578b\u5d29\u6e83\uff1b3. \u63d0\u51fa\u4e0a\u4e0b\u6587\u5d29\u6e83\u6982\u5ff5\u5206\u6790\u957f\u5e8f\u5217\u751f\u6210\u95ee\u9898\u3002", "result": "1. ICL\u4e2d\u53c2\u6570\u5b58\u5728\u76f8\u53d8\uff1a\u8d85\u8fc7\u4e34\u754c\u4e0a\u4e0b\u6587\u957f\u5ea6\u65f6\uff0c\u89e3\u51fa\u73b0\u659c\u5bf9\u79f0\u5206\u91cf\uff1b2. \u6a21\u578b\u5d29\u6e83\u51e0\u4e4e\u5fc5\u7136\u53d1\u751f\uff0c\u9664\u975e\u6570\u636e\u5feb\u901f\u589e\u957f\u6216\u4fdd\u7559\uff1b3. \u63d0\u51fa\u4e0a\u4e0b\u6587\u5d29\u6e83\u6982\u5ff5\uff0c\u8fde\u63a5ICL\u52a8\u6001\u4e0e\u751f\u6210\u6a21\u578b\u957f\u671f\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86LLM\u4e2dICL\u548c\u6a21\u578b\u5d29\u6e83\u7684\u6570\u5b66\u673a\u5236\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u5d29\u6e83\u7684\u5fc5\u7136\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u5d29\u6e83\u8fd9\u4e00\u8fde\u63a5ICL\u52a8\u6001\u4e0e\u957f\u671f\u7a33\u5b9a\u6027\u6311\u6218\u7684\u65b0\u6982\u5ff5\uff0c\u4e3a\u7406\u89e3LLM\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.00994", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.00994", "abs": "https://arxiv.org/abs/2601.00994", "authors": ["Michael Bao"], "title": "ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems", "comment": "In proceedings of 2025 IEEE International Conference on Agentic AI (ICA)", "summary": "This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as \"kernel of truth\" messages and spontaneous developments with an \"ink\" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.", "AI": {"tldr": "ElecTwit\u662f\u4e00\u4e2a\u6a21\u62df\u793e\u4ea4\u5a92\u4f53\u653f\u6cbb\u9009\u4e3e\u4e2d\u591a\u667a\u80fd\u4f53\u8bf4\u670d\u884c\u4e3a\u7684\u6846\u67b6\uff0c\u53d1\u73b0LLM\u4f7f\u7528\u4e8625\u79cd\u8bf4\u670d\u6280\u5de7\uff0c\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u4f1a\u5f71\u54cd\u6a21\u62df\u4e2d\u7684\u8bf4\u670d\u52a8\u6001\u3002", "motivation": "\u514b\u670d\u4ee5\u5f80\u7814\u7a76\u4e2d\u57fa\u4e8e\u6e38\u620f\u6a21\u62df\u7684\u5c40\u9650\u6027\uff0c\u5728\u66f4\u771f\u5b9e\u7684\u73af\u5883\u4e2d\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u8bf4\u670d\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u793e\u4ea4\u5a92\u4f53\u653f\u6cbb\u9009\u4e3e\u573a\u666f\u4e0b\u3002", "method": "\u5f00\u53d1ElecTwit\u6a21\u62df\u6846\u67b6\uff0c\u5728\u7c7b\u4f3c\u793e\u4ea4\u5a92\u4f53\u7684\u771f\u5b9e\u73af\u5883\u4e2d\u8fdb\u884c\u591a\u667a\u80fd\u4f53\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u4e0d\u540cLLM\u6a21\u578b\u5728\u653f\u6cbb\u9009\u4e3e\u573a\u666f\u4e2d\u7684\u8bf4\u670d\u884c\u4e3a\u3002", "result": "\u89c2\u5bdf\u5230\u5927\u591a\u6570\u6d4b\u8bd5\u7684LLM\u5168\u9762\u4f7f\u7528\u4e8625\u79cd\u7279\u5b9a\u8bf4\u670d\u6280\u5de7\uff0c\u8303\u56f4\u6bd4\u4ee5\u5f80\u62a5\u9053\u66f4\u5e7f\uff1b\u4e0d\u540c\u6a21\u578b\u5728\u6280\u5de7\u4f7f\u7528\u548c\u603b\u4f53\u8bf4\u670d\u8f93\u51fa\u4e0a\u5b58\u5728\u5dee\u5f02\uff1b\u53d1\u73b0\u4e86\"\u771f\u76f8\u6838\u5fc3\"\u6d88\u606f\u548c\"\u58a8\u6c34\u75f4\u8ff7\"\u7b49\u72ec\u7279\u73b0\u8c61\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u8bc4\u4f30\u6709\u8bf4\u670d\u529b\u7684LLM\u667a\u80fd\u4f53\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u786e\u4fdd\u5bf9\u9f50\u6027\u548c\u9632\u6b62\u5371\u9669\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u5982\u4f55\u5f71\u54cd\u73b0\u5b9e\u793e\u4ea4\u6a21\u62df\u7684\u52a8\u6001\u3002"}}
{"id": "2601.01195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01195", "abs": "https://arxiv.org/abs/2601.01195", "authors": ["Wuzhenghong Wen", "Chao Xue", "Su Pan", "Yuwei Sun", "Minlong Peng"], "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering", "comment": "11 pages, 2 figures", "summary": "Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.", "AI": {"tldr": "\u63d0\u51faMRE\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u524d\u5411\u548c\u540e\u5411\u63a8\u7406\u6765\u6539\u8fdbTKGQA\u4e2d\u7684\u591a\u8df3\u63a8\u7406\uff0c\u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u751f\u6210\u591a\u6837\u63a8\u7406\u8f68\u8ff9\uff0c\u5e76\u901a\u8fc7T-GRPO\u4f18\u5316\u7b56\u7565\u63d0\u5347\u5168\u5c40\u6700\u4f18\u63a8\u7406\u8def\u5f84\u7684\u8bc6\u522b\u80fd\u529b\u3002", "motivation": "TKGQA\u4efb\u52a1\u4e2d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u4f1a\u68c0\u7d22\u5927\u91cf\u65f6\u95f4\u76f8\u4f3c\u4e14\u8bed\u4e49\u590d\u6742\u7684\u5173\u7cfb\u5b50\u56fe\uff0c\u8fd9\u589e\u52a0\u4e86\u6b21\u4f18\u51b3\u7b56\u548c\u9519\u8bef\u4f20\u64ad\u7684\u98ce\u9669\uff0c\u9700\u8981\u6539\u8fdb\u591a\u8df3\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faMRE\u6846\u67b6\uff1a1) \u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u5f15\u5bfcLLM\u751f\u6210\u591a\u6837\u63a8\u7406\u8f68\u8ff9\uff1b2) \u9009\u62e9\u6709\u6548\u8f68\u8ff9\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u4f5c\u4e3a\u51b7\u542f\u52a8\u7b56\u7565\uff1b3) \u5f15\u5165T-GRPO\u9012\u5f52\u6811\u7ed3\u6784\u5b66\u4e60\u63a2\u7d22\u65b9\u6cd5\uff0c\u5efa\u7acb\u524d\u540e\u8df3\u4e4b\u95f4\u7684\u5f3a\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e24\u4e2aTKGQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMRE\u6846\u67b6\u6a21\u578b\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u566a\u58f0\u65f6\u95f4\u6807\u6ce8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "MRE\u6846\u67b6\u901a\u8fc7\u589e\u5f3a\u524d\u5411\u548c\u540e\u5411\u63a8\u7406\uff0c\u6709\u6548\u63d0\u5347\u4e86TKGQA\u4e2d\u591a\u8df3\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u590d\u6742\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01301", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01301", "abs": "https://arxiv.org/abs/2601.01301", "authors": ["Keith Frankston", "Benjamin Howard"], "title": "Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies", "comment": "11 pages; an efficient implementation is available at https://github.com/bhoward73/rmcts", "summary": "We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, \"RMCTS\". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.\n  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in \"Monte--Carlo tree search as regularized policy optimization\" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.\n  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.", "AI": {"tldr": "\u63d0\u51fa\u9012\u5f52AlphaZero\u98ce\u683c\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5RMCTS\uff0c\u76f8\u6bd4MCTS-UCB\u901f\u5ea6\u63d0\u5347\u663e\u8457\uff0c\u5728\u5355\u6839\u72b6\u6001\u641c\u7d22\u65f6\u5feb40\u500d\u4ee5\u4e0a\uff0c\u6279\u91cf\u641c\u7d22\u65f6\u5feb3\u500d\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u5230\u4e09\u5206\u4e4b\u4e00\u3002", "motivation": "AlphaZero\u7684MCTS-UCB\u7b97\u6cd5\u5b58\u5728GPU\u5ef6\u8fdf\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5feb\u7684\u641c\u7d22\u7b97\u6cd5\u6765\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u9012\u5f52\u7684\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u7b56\u7565\uff0c\u901a\u8fc7\u6279\u91cf\u7f51\u7edc\u63a8\u7406\u51cf\u5c11GPU\u5ef6\u8fdf\u3002\u4f7f\u7528\u57fa\u4e8eGrill\u7b49\u4eba\u63d0\u51fa\u7684\u540e\u9a8c\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u4ece\u53f6\u5b50\u8282\u70b9\u5411\u6839\u8282\u70b9\u9012\u5f52\u8ba1\u7b97\u4f18\u5316\u540e\u9a8c\u7b56\u7565\u3002", "result": "RMCTS\u5728\u5355\u6839\u72b6\u6001\u641c\u7d22\u65f6\u6bd4MCTS-UCB\u5feb40\u500d\u4ee5\u4e0a\uff0c\u6279\u91cf\u641c\u7d22\u65f6\u5feb3\u500d\u3002\u5728Connect-4\u3001Dots-and-Boxes\u548cOthello\u4e09\u4e2a\u6e38\u620f\u4e2d\uff0cRMCTS\u8bad\u7ec3\u7684\u7f51\u7edc\u8d28\u91cf\u4e0eMCTS-UCB\u76f8\u5f53\uff0c\u4f46\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u5230\u4e09\u5206\u4e4b\u4e00\u3002", "conclusion": "RMCTS\u901a\u8fc7\u9012\u5f52\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u663e\u8457\u52a0\u901f\u4e86\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u867d\u7136\u727a\u7272\u4e86\u81ea\u9002\u5e94\u6811\u6784\u5efa\u7684\u4f18\u52bf\uff0c\u4f46\u901f\u5ea6\u63d0\u5347\u66f4\u4e3a\u663e\u8457\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u80fd\u591f\u5927\u5e45\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u800c\u4e0d\u635f\u5931\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2601.01321", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01321", "abs": "https://arxiv.org/abs/2601.01321", "authors": ["Rong Zhou", "Dongping Chen", "Zihan Jia", "Yao Su", "Yixin Liu", "Yiwen Lu", "Dongwei Shi", "Yue Huang", "Tianyang Xu", "Yi Pan", "Xinliang Li", "Yohannes Abate", "Qingyu Chen", "Zhengzhong Tu", "Yu Yang", "Yu Zhang", "Qingsong Wen", "Gengchen Mai", "Sunyang Fu", "Jiachen Li", "Xuyu Wang", "Ziran Wang", "Jing Huang", "Tianming Liu", "Yong Chen", "Lichao Sun", "Lifang He"], "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models", "comment": null, "summary": "Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u56db\u9636\u6bb5\u6846\u67b6\uff0c\u7cfb\u7edf\u63cf\u8ff0AI\u5728\u6570\u5b57\u5b6a\u751f\u5168\u751f\u547d\u5468\u671f\u4e2d\u7684\u96c6\u6210\uff1a\u5efa\u6a21\u3001\u955c\u50cf\u3001\u5e72\u9884\u548c\u81ea\u4e3b\u7ba1\u7406\uff0c\u5206\u6790\u4e86\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u534f\u540c\uff0c\u5e76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5982\u4f55\u5c06\u6570\u5b57\u5b6a\u751f\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u8ba4\u77e5\u7cfb\u7edf\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5df2\u4ece\u88ab\u52a8\u4eff\u771f\u5de5\u5177\u53d1\u5c55\u4e3a\u667a\u80fd\u81ea\u4e3b\u5b9e\u4f53\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684AI\u96c6\u6210\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7cfb\u7edf\u63cf\u8ff0AI\u65b9\u6cd5\u5728\u6570\u5b57\u5b6a\u751f\u5168\u751f\u547d\u5468\u671f\u4e2d\u7684\u5d4c\u5165\u65b9\u5f0f\uff0c\u5e76\u5206\u6790\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u534f\u540c\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u56db\u9636\u6bb5\u6846\u67b6\uff1a1) \u901a\u8fc7\u7269\u7406\u57fa\u7840\u548c\u7269\u7406\u4fe1\u606fAI\u65b9\u6cd5\u5efa\u6a21\u7269\u7406\u5b6a\u751f\uff1b2) \u901a\u8fc7\u5b9e\u65f6\u540c\u6b65\u5c06\u7269\u7406\u7cfb\u7edf\u955c\u50cf\u4e3a\u6570\u5b57\u5b6a\u751f\uff1b3) \u901a\u8fc7\u9884\u6d4b\u5efa\u6a21\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u4f18\u5316\u7b56\u7565\u5e72\u9884\u7269\u7406\u5b6a\u751f\uff1b4) \u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u3001\u57fa\u7840\u6a21\u578b\u548c\u667a\u80fd\u4ee3\u7406\u5b9e\u73b0\u81ea\u4e3b\u7ba1\u7406\u3002\u901a\u8fc7\u8de811\u4e2a\u5e94\u7528\u9886\u57df\u7684\u7efc\u8ff0\u5206\u6790\u534f\u540c\u5173\u7cfb\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u4e86\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u534f\u540c\uff0c\u5c55\u793a\u4e86\u4ece\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5411\u7269\u7406\u4fe1\u606f\u548c\u57fa\u7840\u6a21\u578b\u7684\u8f6c\u53d8\u3002\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u6280\u672f\uff08\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u548c\u751f\u6210\u4e16\u754c\u6a21\u578b\uff09\u5982\u4f55\u5c06\u6570\u5b57\u5b6a\u751f\u8f6c\u53d8\u4e3a\u80fd\u591f\u63a8\u7406\u3001\u901a\u4fe1\u548c\u521b\u9020\u6027\u573a\u666f\u751f\u6210\u7684\u4e3b\u52a8\u8ba4\u77e5\u7cfb\u7edf\u3002", "conclusion": "AI\u6280\u672f\u6b63\u5728\u5c06\u6570\u5b57\u5b6a\u751f\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u3001\u81ea\u6211\u6539\u8fdb\u7684\u8ba4\u77e5\u7cfb\u7edf\u3002\u901a\u8fc7\u8de8\u9886\u57df\u5206\u6790\u8bc6\u522b\u4e86\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u7684\u5171\u540c\u6311\u6218\uff0c\u5e76\u4e3a\u8d1f\u8d23\u4efbAI\u9a71\u52a8\u7684\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u6307\u660e\u4e86\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.01330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01330", "abs": "https://arxiv.org/abs/2601.01330", "authors": ["Shengji Tang", "Weihao Lin", "Jingqi Ye", "Hao Li", "Bo Zhang", "Shuyue Hu", "Tao Chen", "Wangli Ouyang", "Lei Bai", "Peng Ye"], "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale", "comment": "12 pages", "summary": "Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).", "AI": {"tldr": "JiSi\u6846\u67b6\u901a\u8fc7\u67e5\u8be2-\u54cd\u5e94\u6df7\u5408\u8def\u7531\u3001\u652f\u6301\u96c6\u805a\u5408\u5668\u9009\u62e9\u548c\u81ea\u9002\u5e94\u8def\u7531-\u805a\u5408\u5207\u6362\uff0c\u4f7f\u5f00\u6e90LLM\u534f\u4f5c\u8d85\u8d8aGemini-3-Pro\u6027\u80fd\uff0c\u6210\u672c\u4ec547%", "motivation": "\u63a2\u7d22\u96c6\u4f53\u667a\u80fd\u4f5c\u4e3a\u66ff\u4ee3\u5355\u4f53\u6269\u5c55\u7684\u8def\u5f84\uff0c\u89e3\u51b3\u5f53\u524dLLM\u8def\u7531\u548c\u805a\u5408\u7684\u4e09\u4e2a\u5173\u952e\u74f6\u9888\uff1a\u67e5\u8be2\u5f0f\u8def\u7531\u5c40\u9650\u3001\u9759\u6001\u805a\u5408\u65b9\u6cd5\u3001\u8def\u7531\u4e0e\u805a\u5408\u4e92\u8865\u6027\u672a\u5145\u5206\u5229\u7528", "method": "\u63d0\u51faJiSi\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u521b\u65b0\uff1a1) \u67e5\u8be2-\u54cd\u5e94\u6df7\u5408\u8def\u7531\uff0c\u540c\u65f6\u6355\u6349\u8bed\u4e49\u4fe1\u606f\u548c\u95ee\u9898\u96be\u5ea6\uff1b2) \u57fa\u4e8e\u652f\u6301\u96c6\u7684\u805a\u5408\u5668\u9009\u62e9\uff0c\u8054\u5408\u8bc4\u4f30\u805a\u5408\u80fd\u529b\u548c\u9886\u57df\u80fd\u529b\uff1b3) \u81ea\u9002\u5e94\u8def\u7531-\u805a\u5408\u5207\u6362\uff0c\u52a8\u6001\u5229\u7528\u8def\u7531\u548c\u805a\u5408\u4f18\u52bf", "result": "\u57289\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cJiSi\u901a\u8fc7\u534f\u8c0310\u4e2a\u5f00\u6e90LLM\uff0c\u4ee5\u4ec547%\u7684\u6210\u672c\u8d85\u8d8a\u4e86Gemini-3-Pro\u6027\u80fd\uff0c\u540c\u65f6\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u96c6\u4f53\u667a\u80fd\u4ee3\u8868\u4e86\u901a\u5f80\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u65b0\u8def\u5f84\uff0c\u5f00\u6e90LLM\u7684\u534f\u4f5c\u53ef\u4ee5\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5355\u4f53\u6a21\u578b"}}
{"id": "2601.01363", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01363", "abs": "https://arxiv.org/abs/2601.01363", "authors": ["Xiaomeng Yang", "Zhiyu Tan", "Xiaohui Zhong", "Mengping Yang", "Qiusheng Huang", "Lei Chen", "Libo Wu", "Hao Li"], "title": "A unified multimodal understanding and generation model for cross-disciplinary scientific research", "comment": null, "summary": "Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25\u00b0 resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.", "AI": {"tldr": "FuXi-Uni\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6a21\u6001\u79d1\u5b66\u6a21\u578b\uff0c\u80fd\u591f\u5728\u5355\u4e00\u67b6\u6784\u4e2d\u7406\u89e3\u548c\u751f\u6210\u8de8\u5b66\u79d1\u7684\u9ad8\u7ef4\u79d1\u5b66\u6570\u636e\uff0c\u5728\u5730\u7403\u79d1\u5b66\u548c\u751f\u7269\u533b\u5b66\u9886\u57df\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u901a\u5e38\u662f\u9886\u57df\u7279\u5b9a\u7684\uff0c\u7f3a\u4e4f\u540c\u65f6\u7406\u89e3\u548c\u751f\u6210\u591a\u6a21\u6001\u79d1\u5b66\u6570\u636e\u7684\u80fd\u529b\uff0c\u800c\u8bb8\u591a\u5168\u7403\u6027\u6311\u6218\u548c\u79d1\u5b66\u95ee\u9898\u672c\u8d28\u4e0a\u662f\u8de8\u5b66\u79d1\u7684\uff0c\u9700\u8981\u8de8\u591a\u4e2a\u9886\u57df\u7684\u534f\u8c03\u8fdb\u5c55\u3002", "method": "FuXi-Uni\u5c06\u8de8\u5b66\u79d1\u7684\u79d1\u5b66token\u4e0e\u81ea\u7136\u8bed\u8a00token\u5bf9\u9f50\uff0c\u5e76\u4f7f\u7528\u79d1\u5b66\u89e3\u7801\u5668\u91cd\u5efa\u79d1\u5b66token\uff0c\u4ece\u800c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u548c\u79d1\u5b66\u6570\u503c\u9884\u6d4b\u3002", "result": "\u5728\u5730\u7403\u7cfb\u7edf\u5efa\u6a21\u4e2d\uff0cFuXi-Uni\u57280.25\u00b0\u5206\u8fa8\u7387\u4e0b\u751f\u6210\u768410\u5929\u5168\u7403\u5929\u6c14\u9884\u62a5\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u7269\u7406\u9884\u62a5\u7cfb\u7edf\uff1b\u5728\u70ed\u5e26\u6c14\u65cb\u9884\u6d4b\u548c\u7a7a\u95f4\u964d\u5c3a\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1b\u5728\u751f\u7269\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "FuXi-Uni\u901a\u8fc7\u5728\u539f\u751f\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7edf\u4e00\u5f02\u6784\u79d1\u5b66\u6a21\u6001\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u9886\u57df\u7279\u5b9a\u6027\u80fd\uff0c\u4e3a\u66f4\u901a\u7528\u7684\u591a\u6a21\u6001\u79d1\u5b66\u6a21\u578b\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2601.01366", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01366", "abs": "https://arxiv.org/abs/2601.01366", "authors": ["Zixian Liu", "Sihao Liu", "Yuqi Zhao"], "title": "KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models", "comment": null, "summary": "With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.", "AI": {"tldr": "KGCE\u662f\u4e00\u4e2a\u7528\u4e8e\u8de8\u5e73\u53f0\u6559\u80b2\u667a\u80fd\u4f53\u8bc4\u6d4b\u7684\u65b0\u57fa\u51c6\u5e73\u53f0\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u5728\u79c1\u6709\u6559\u80b2\u8f6f\u4ef6\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6846\u67b6\u5728\u652f\u6301\u8de8\u5e73\u53f0\u6559\u80b2\u4efb\u52a1\u65b9\u9762\u5b58\u5728\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5b66\u6821\u4e13\u7528\u8f6f\u4ef6\uff08\u5982\u5c0f\u96c5\u667a\u80fd\u52a9\u624b\u3001\u534e\u5e08\u5323\u5b50\u7b49\uff09\u65f6\uff0c\u667a\u80fd\u4f53\u56e0\u4e0d\u4e86\u89e3\u8fd9\u4e9b\u79c1\u6709\u9886\u57df\u8f6f\u4ef6\u7684\u7ed3\u6784\u7ec6\u8282\u800c\u6548\u7387\u663e\u8457\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7c97\u7c92\u5ea6\u6307\u6807\uff0c\u96be\u4ee5\u6355\u6349\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8be6\u7ec6\u6267\u884c\u6548\u7387\u3002", "method": "\u63d0\u51faKGCE\u5e73\u53f0\uff0c\u6574\u5408\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u3002\u9996\u5148\u6784\u5efa\u5305\u542b104\u4e2a\u6559\u80b2\u76f8\u5173\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6Windows\u3001Android\u548c\u8de8\u5e73\u53f0\u534f\u4f5c\u4efb\u52a1\u3002\u5f15\u5165\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u591a\u4e2a\u5b50\u76ee\u6807\u5e76\u9a8c\u8bc1\u5b8c\u6210\u72b6\u6001\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\u3002\u4e3a\u514b\u670d\u73b0\u6709\u667a\u80fd\u4f53\u5728\u79c1\u6709\u9886\u57df\u4efb\u52a1\u7684\u6267\u884c\u74f6\u9888\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u5b66\u6821\u4e13\u7528\u8f6f\u4ef6\u77e5\u8bc6\u5e93\u7684\u589e\u5f3a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86KGCE\u57fa\u51c6\u5e73\u53f0\uff0c\u5305\u542b104\u4e2a\u6559\u80b2\u4efb\u52a1\u7684\u6570\u636e\u96c6\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u667a\u80fd\u4f53\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\u3002\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002", "conclusion": "KGCE\u901a\u8fc7\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u5e73\u53f0\u6559\u80b2\u667a\u80fd\u4f53\u8bc4\u6d4b\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u6559\u80b2\u9886\u57df\u667a\u80fd\u4f53\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u7ec6\u7c92\u5ea6\u7684\u57fa\u51c6\u5e73\u53f0\u3002"}}
{"id": "2601.01378", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01378", "abs": "https://arxiv.org/abs/2601.01378", "authors": ["Han Yuan", "Yilin Wu", "Li Zhang", "Zheng Ma"], "title": "Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification", "comment": null, "summary": "Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.", "AI": {"tldr": "\u63d0\u51faAAAI\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u901a\u8fc7\u51cf\u5c11\u4e8b\u5b9e\u5e7b\u89c9\u6765\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u7c7b\u4e2d\u56e0\u63a8\u7406\u65f6\u6613\u4ea7\u751f\u4e8b\u5b9e\u5e7b\u89c9\u800c\u5bfc\u81f4\u5206\u7c7b\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u63a2\u7d22\u51cf\u5c11\u4e8b\u5b9e\u5e7b\u89c9\u662f\u5426\u80fd\u6539\u5584\u5176\u5206\u7c7b\u80fd\u529b", "method": "\u63d0\u51faAAAI\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u5173\u8054\u8bc6\u522b\u3001\u81ea\u52a8\u68c0\u6d4b\u548c\u81ea\u9002\u5e94\u63a8\u7406\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u53cd\u9988\u4e8b\u5b9e\u9519\u8bef\u6765\u589e\u5f3a\u6a21\u578b\u63a8\u7406", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1\uff09\u4e8b\u5b9e\u5e7b\u89c9\u4e0e\u8bef\u5206\u7c7b\u6b63\u76f8\u5173\uff1b2\uff09\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u9a8c\u8bc1\u5668\u80fd\u6709\u6548\u68c0\u6d4b\u4e8b\u5b9e\u5e7b\u89c9\uff1b3\uff09\u878d\u5165\u4e8b\u5b9e\u9519\u8bef\u53cd\u9988\u80fd\u63d0\u5347\u5206\u7c7b\u6027\u80fd", "conclusion": "AAAI\u6d41\u7a0b\u6709\u52a9\u4e8e\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u53ef\u4fe1\u5ea6\u548c\u6709\u6548\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u652f\u6301"}}
{"id": "2601.01467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01467", "abs": "https://arxiv.org/abs/2601.01467", "authors": ["Romuald Kwessy Mouona", "Blaise Bl\u00e9riot Koguep Njionou", "Etienne Romuald Temgoua Alomo", "Rokia Missaoui", "Leonard Kwuida"], "title": "A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts", "comment": "26 pages", "summary": "This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e09\u5143\u80cc\u666f\u4e2d\u7684\u8574\u6db5\u5173\u7cfb\uff0c\u4e13\u6ce8\u4e8eGanter\u548cObiedkov\u63d0\u51fa\u7684\u6761\u4ef6\u5c5e\u6027\u8574\u6db5\u548c\u5c5e\u6027\u6761\u4ef6\u8574\u6db5\uff0c\u76ee\u6807\u662f\u6784\u5efa\u8fd9\u4e9b\u8574\u6db5\u7684\u6700\u4f18\u57fa", "motivation": "\u4e09\u5143\u80cc\u666f\u4e2d\u7684\u8574\u6db5\u5173\u7cfb\u5728\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\u4e2d\u5177\u6709\u91cd\u8981\u7406\u8bba\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u8574\u6db5\u5173\u7cfb\u6700\u4f18\u57fa\u7684\u7cfb\u7edf\u6784\u5efa\u65b9\u6cd5", "method": "\u7814\u7a76Ganter\u548cObiedkov\u63d0\u51fa\u7684\u6761\u4ef6\u5c5e\u6027\u8574\u6db5\u548c\u5c5e\u6027\u6761\u4ef6\u8574\u6db5\uff0c\u5f00\u53d1\u6784\u5efa\u8fd9\u4e9b\u8574\u6db5\u6700\u4f18\u57fa\u7684\u7b97\u6cd5\u6216\u7406\u8bba\u6846\u67b6", "result": "\u63d0\u51fa\u4e86\u4e09\u5143\u80cc\u666f\u4e0b\u6761\u4ef6\u5c5e\u6027\u8574\u6db5\u548c\u5c5e\u6027\u6761\u4ef6\u8574\u6db5\u7684\u6700\u4f18\u57fa\u6784\u5efa\u65b9\u6cd5", "conclusion": "\u6210\u529f\u6784\u5efa\u4e86\u4e09\u5143\u80cc\u666f\u4e2d\u8574\u6db5\u5173\u7cfb\u7684\u6700\u4f18\u57fa\uff0c\u4e3a\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\u4e2d\u7684\u4e09\u5143\u5173\u7cfb\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u5de5\u5177"}}
{"id": "2601.01511", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01511", "abs": "https://arxiv.org/abs/2601.01511", "authors": ["Ahmed Dawoud", "Osama El-Shamy"], "title": "Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning", "comment": null, "summary": "Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u7684\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u6587\u672c\u5d4c\u5165\u89e3\u51b3\u672a\u89c2\u6d4b\u6df7\u6742\u53d8\u91cf\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u6811\u6a21\u578b\u663e\u8457\u964d\u4f4e\u504f\u5dee", "motivation": "\u5728\u89c2\u6d4b\u6027\u7814\u7a76\u4e2d\uff0c\u672a\u89c2\u6d4b\u6df7\u6742\u53d8\u91cf\u5bfc\u81f4\u9009\u62e9\u504f\u5dee\uff0c\u4f20\u7edf\u8ba1\u91cf\u65b9\u6cd5\u5728\u6df7\u6742\u53d8\u91cf\u4e0e\u7ed3\u6784\u5316\u534f\u53d8\u91cf\u6b63\u4ea4\u65f6\u5931\u6548\uff0c\u800c\u9ad8\u7ef4\u975e\u7ed3\u6784\u5316\u6587\u672c\u5305\u542b\u4e30\u5bcc\u7684\u6f5c\u5728\u53d8\u91cf\u4ee3\u7406\u4fe1\u606f", "method": "\u63d0\u51fa\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u7684\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u6587\u672c\u5d4c\u5165\u8fdb\u884c\u56e0\u679c\u8bc6\u522b\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5efa\u6a21\u5d4c\u5165\u6d41\u5f62\u7684\u8fde\u7eed\u62d3\u6251\u7ed3\u6784", "result": "\u6807\u51c6\u6811\u57faDML\u4f30\u8ba1\u5668\u5b58\u5728\u663e\u8457\u504f\u5dee\uff08+24%\uff09\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5c06\u504f\u5dee\u964d\u81f3-0.86%\uff0c\u6709\u6548\u6062\u590d\u771f\u5b9e\u56e0\u679c\u53c2\u6570", "conclusion": "\u5f53\u57fa\u4e8e\u9ad8\u7ef4\u81ea\u7136\u8bed\u8a00\u6570\u636e\u8fdb\u884c\u6761\u4ef6\u5316\u65f6\uff0c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5bf9\u4e8e\u6ee1\u8db3\u65e0\u6df7\u6742\u5047\u8bbe\u81f3\u5173\u91cd\u8981"}}
{"id": "2601.01522", "categories": ["cs.AI", "cs.CL", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.01522", "abs": "https://arxiv.org/abs/2601.01522", "authors": ["Danial Amin"], "title": "Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds \"confidence,\" and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8d1d\u53f6\u65af\u6210\u672c\u611f\u77e5\u7684\u591aLLM\u7f16\u6392\u6846\u67b6\uff0c\u5c06LLM\u89c6\u4e3a\u8fd1\u4f3c\u4f3c\u7136\u6a21\u578b\u800c\u975e\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u5bf9\u6bd4\u63d0\u793a\u3001\u9c81\u68d2\u7edf\u8ba1\u805a\u5408\u548c\u8d1d\u53f6\u65af\u66f4\u65b0\uff0c\u5728\u975e\u5bf9\u79f0\u9519\u8bef\u6210\u672c\u7684\u987a\u5e8f\u51b3\u7b56\u4e2d\u663e\u8457\u964d\u4f4e\u603b\u6210\u672c\u5e76\u63d0\u5347\u516c\u5e73\u6027\u3002", "motivation": "\u5f53\u524dLLM\u5728\u62db\u8058\u3001\u533b\u7597\u5206\u8bca\u3001\u6b3a\u8bc8\u68c0\u6d4b\u7b49\u975e\u5bf9\u79f0\u9519\u8bef\u6210\u672c\u573a\u666f\u4e2d\u4f5c\u4e3a\u81ea\u4e3b\u51b3\u7b56\u4ee3\u7406\u65f6\uff0c\u4e3b\u6d41\u65b9\u6cd5\uff08\u67e5\u8be2\u5355\u4e2aLLM\u83b7\u53d6\u540e\u9a8c\u6982\u7387\u5e76\u57fa\u4e8e\"\u7f6e\u4fe1\u5ea6\"\u9608\u503c\u884c\u52a8\uff09\u5728\u987a\u5e8f\u51b3\u7b56\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u6982\u7387\u6846\u67b6\u6765\u5904\u7406\u6210\u672c\u654f\u611f\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6210\u672c\u611f\u77e5\u7684\u591aLLM\u7f16\u6392\u6846\u67b6\uff1a1) \u5c06LLM\u89c6\u4e3a\u8fd1\u4f3c\u4f3c\u7136\u6a21\u578b\u800c\u975e\u5206\u7c7b\u5668\uff1b2) \u901a\u8fc7\u5bf9\u6bd4\u63d0\u793a\u4e3a\u6bcf\u4e2a\u5019\u9009\u72b6\u6001\u83b7\u53d6\u4f3c\u7136\uff1b3) \u4f7f\u7528\u9c81\u68d2\u7edf\u8ba1\u65b9\u6cd5\u805a\u5408\u591a\u4e2a\u4e0d\u540cLLM\u7684\u7ed3\u679c\uff1b4) \u5728\u663e\u5f0f\u5148\u9a8c\u4e0b\u7528\u8d1d\u53f6\u65af\u89c4\u5219\u968f\u7740\u65b0\u8bc1\u636e\u66f4\u65b0\u4fe1\u5ff5\uff1b5) \u652f\u6301\u9884\u671f\u6210\u672c\u884c\u52a8\u9009\u62e9\u3001\u57fa\u4e8e\u4fe1\u606f\u4ef7\u503c\u7684\u539f\u5219\u6027\u4fe1\u606f\u6536\u96c6\u3002", "result": "\u5728\u7b80\u5386\u7b5b\u9009\u5b9e\u9a8c\u4e2d\uff08\u9519\u5931\u4eba\u624d\u6210\u672c40000\u7f8e\u5143\uff0c\u9762\u8bd5\u6210\u672c2500\u7f8e\u5143\uff0c\u7535\u8bdd\u7b5b\u9009\u6210\u672c150\u7f8e\u5143\uff09\uff0c\u4f7f\u75285\u4e2aLLM\uff08GPT-4o\u3001Claude 4.5 Sonnet\u3001Gemini Pro\u3001Grok\u3001DeepSeek\uff09\u5904\u74061000\u4efd\u7b80\u5386\uff0c\u76f8\u6bd4\u6700\u4f73\u5355LLM\u57fa\u7ebf\u964d\u4f4e\u603b\u6210\u672c294000\u7f8e\u5143\uff0834%\uff09\uff0c\u4eba\u53e3\u7edf\u8ba1\u516c\u5e73\u6027\u63d0\u534745%\uff08\u6700\u5927\u7ec4\u5dee\u8ddd\u4ece22%\u964d\u81f35%\uff09\u3002", "conclusion": "\u6b63\u786e\u7684\u6982\u7387\u57fa\u7840\u5728\u591aLLM\u987a\u5e8f\u51b3\u7b56\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u591aLLM\u805a\u5408\u8d21\u732e51%\u7684\u6210\u672c\u8282\u7701\uff0c\u987a\u5e8f\u66f4\u65b0\u8d21\u732e43%\uff0c\u5206\u6b67\u89e6\u53d1\u4fe1\u606f\u6536\u96c6\u8d21\u732e20%\uff0c\u8bc1\u660e\u4e86\u8d1d\u53f6\u65af\u6210\u672c\u611f\u77e5\u6846\u67b6\u5728\u975e\u5bf9\u79f0\u9519\u8bef\u6210\u672c\u573a\u666f\u4e2d\u7684\u4f18\u8d8a\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u96c6\u6210\u7f13\u89e3\u504f\u89c1\u63d0\u5347\u516c\u5e73\u6027\u3002"}}
{"id": "2601.01532", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01532", "abs": "https://arxiv.org/abs/2601.01532", "authors": ["Fanzhe Fu"], "title": "Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix", "comment": "6 pages, 2 figures", "summary": "In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify \"Cognitive Conviction\" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a \"cognitive buffer,\" they may exhibit \"Defensive OverThinking\" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.", "AI": {"tldr": "\u63d0\u51faProject Aletheia\u6846\u67b6\uff0c\u4f7f\u7528Tikhonov\u6b63\u5219\u5316\u53cd\u6f14\u5224\u65ad\u6df7\u6dc6\u77e9\u9635\u6765\u91cf\u5316System 2\u63a8\u7406\u6a21\u578b\u7684\"\u8ba4\u77e5\u786e\u4fe1\u5ea6\"\uff0c\u5e76\u5f15\u5165\u5bf9\u9f50\u786e\u4fe1\u5206\u6570\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524dAGI\u8bc4\u4f30\u8303\u5f0f\u9762\u4e34\u8ba4\u8bc6\u8bba\u5371\u673a\uff0c\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u80fd\u8861\u91cf\u77e5\u8bc6\u5e7f\u5ea6\u4f46\u65e0\u6cd5\u91cf\u5316\u4fe1\u5ff5\u6df1\u5ea6\u3002\u9700\u8981\u6269\u5c55CHOKE\u73b0\u8c61\u6846\u67b6\u6765\u91cf\u5316\u63a8\u7406\u6a21\u578b\u7684\u8ba4\u77e5\u786e\u4fe1\u5ea6\u3002", "method": "\u63d0\u51faProject Aletheia\u8ba4\u77e5\u7269\u7406\u5b66\u6846\u67b6\uff0c\u91c7\u7528Tikhonov\u6b63\u5219\u5316\u53cd\u6f14\u5224\u65ad\u6df7\u6dc6\u77e9\u9635\u3002\u4e3a\u907f\u514d\u4f9d\u8d56\u4e0d\u900f\u660e\u7684\u79c1\u6709\u6570\u636e\uff0c\u5b9e\u65bd\u5408\u6210\u4ee3\u7406\u534f\u8bae\u3002\u5f15\u5165\u5bf9\u9f50\u786e\u4fe1\u5206\u6570(S_aligned)\u9a8c\u8bc1\u786e\u4fe1\u5ea6\u4e0d\u635f\u5bb3\u5b89\u5168\u6027\u3002", "result": "\u521d\u6b65\u8bd5\u70b9\u7814\u7a76\u663e\u793a\uff0c\u63a8\u7406\u6a21\u578b\u867d\u7136\u4f5c\u4e3a\"\u8ba4\u77e5\u7f13\u51b2\u533a\"\uff0c\u4f46\u5728\u5bf9\u6297\u538b\u529b\u4e0b\u53ef\u80fd\u8868\u73b0\u51fa\"\u9632\u5fa1\u6027\u8fc7\u5ea6\u601d\u8003\"\u3002\u6846\u67b6\u4e3a\u6d4b\u91cfAI\u79d1\u5b66\u5b8c\u6574\u6027\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u91cf\u5316AI\u8ba4\u77e5\u786e\u4fe1\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7Project Aletheia\u6846\u67b6\u548cS_aligned\u5206\u6570\uff0c\u4e3a\u8bc4\u4f30AI\u79d1\u5b66\u5b8c\u6574\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u5de5\u5177\uff0c\u786e\u4fdd\u63a8\u7406\u6a21\u578b\u7684\u786e\u4fe1\u5ea6\u4e0d\u4f1a\u635f\u5bb3\u5b89\u5168\u6027\u3002"}}
{"id": "2601.01546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01546", "abs": "https://arxiv.org/abs/2601.01546", "authors": ["Letian Kong", "Qianran", "Jin", "Renyu Zhang"], "title": "Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation", "comment": "39 pages, 2 figures, 3 tables", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u6539\u5584LLM\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u5bf9\u9f50\uff1a\u7b2c\u4e00\u9636\u6bb5\u660e\u786e\u5b9e\u9a8c\u8bbe\u8ba1\u5efa\u7acb\u51c6\u786e\u4efb\u52a1\u8868\u5f81\uff0c\u7b2c\u4e8c\u9636\u6bb5\u6307\u5bfc\u8be5\u8868\u5f81\u5185\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u9a8c\u8bc1\u8868\u660e\u590d\u6742\u73af\u5883\u9700\u8981\u4e24\u9636\u6bb5\uff0c\u7b80\u5355\u4efb\u52a1\u4ec5\u9700\u7b2c\u4e00\u9636\u6bb5\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u7528\u4e8e\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u5b9e\u9a8c\uff0c\u4f46\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\uff08\u9700\u8981\u9884\u6d4b\u4ed6\u4eba\u884c\u52a8\u3001\u57fa\u4e8e\u89c2\u5bdf\u884c\u4e3a\u5f62\u6210\u4fe1\u5ff5\uff09\u4e0e\u4eba\u7c7b\u51b3\u7b56\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u9700\u8981\u6539\u8fdb\u884c\u4e3a\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u60c5\u5883\u5f62\u6210 - \u660e\u786e\u6307\u5b9a\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5efa\u7acb\u51b3\u7b56\u4efb\u52a1\u53ca\u5176\u60c5\u5883\u7684\u51c6\u786e\u8868\u5f81\uff1b2) \u60c5\u5883\u5bfc\u822a - \u5728\u8be5\u8868\u5f81\u5185\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u505a\u51fa\u51b3\u7b56\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u51b3\u7b56\u73af\u5883\u4e2d\u9a8c\u8bc1\uff1a\u987a\u5e8f\u8d2d\u4e70\u6e38\u620f\u3001\u4f17\u7b79\u6e38\u620f\u3001\u9700\u6c42\u4f30\u8ba1\u4efb\u52a1\u3002", "result": "\u5728\u56db\u4e2aSOTA\u6a21\u578b\u4e0a\u6d4b\u8bd5\u53d1\u73b0\uff1a\u590d\u6742\u51b3\u7b56\u73af\u5883\u9700\u8981\u4e24\u9636\u6bb5\u624d\u80fd\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u57fa\u51c6\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u800c\u7b80\u5355\u7684\u9700\u6c42\u4f30\u8ba1\u4efb\u52a1\u4ec5\u9700\u60c5\u5883\u5f62\u6210\u9636\u6bb5\u3002\u6846\u67b6\u80fd\u7cfb\u7edf\u8bbe\u8ba1\u548c\u8bca\u65adLLM\u793e\u4f1a\u6a21\u62df\u3002", "conclusion": "\u4e24\u9636\u6bb5\u6846\u67b6\u80fd\u6709\u6548\u6539\u5584LLM\u5728\u884c\u4e3a\u7814\u7a76\u4e2d\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u660e\u786e\u4e86\u5404\u9636\u6bb5\u9002\u7528\u6761\u4ef6\uff0c\u4e3a\u5c06LLM\u793e\u4f1a\u6a21\u62df\u4f5c\u4e3a\u4eba\u7c7b\u53d7\u8bd5\u8005\u8865\u5145\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2601.01562", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01562", "abs": "https://arxiv.org/abs/2601.01562", "authors": ["Mingyu Xu", "Cheng Fang", "Keyue Jiang", "Yuqian Zheng", "Yanghua Xiao", "Baojian Zhou", "Qifang Zhao", "Suhang Zheng", "Xiuwen Zhu", "Jiyang Tang", "Yongchi Zhao", "Yijia Luo", "Zhiqi Bai", "Yuchi Xu", "Wenbo Su", "Wei Wang", "Bing Zhao", "Lin Qu", "Xiaoxiao Xu"], "title": "Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement", "comment": null, "summary": "We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.", "AI": {"tldr": "Logics-STEM\u662f\u4e00\u4e2a\u572810M\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u63a8\u7406\u6a21\u578b\uff0c\u4e13\u6ce8\u4e8eSTEM\u9886\u57df\uff0c\u57288B\u89c4\u6a21\u4e0a\u6bd4\u6b21\u4f18\u6a21\u578b\u5e73\u5747\u63d0\u53474.68%\u6027\u80fd\uff0c\u901a\u8fc7\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u4f18\u5316\u3002", "motivation": "\u5f53\u524dSTEM\u9886\u57df\u63a8\u7406\u4efb\u52a1\u9700\u8981\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u5f00\u6e90\u957f\u601d\u7ef4\u94fe\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\uff0c\u4e14\u6570\u636e\u4e0e\u7b97\u6cd5\u534f\u540c\u4f18\u5316\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "\u91c7\u7528\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\uff1a\u6570\u636e\u65b9\u9762\u6784\u5efa10M\u89c4\u6a21Logics-STEM-SFT-Dataset\uff0c\u5305\u542b5\u9636\u6bb5\u6570\u636e\u6574\u7406\u6d41\u7a0b\uff1b\u7b97\u6cd5\u65b9\u9762\u91c7\u7528\u5931\u8d25\u9a71\u52a8\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u9488\u5bf9SFT\u9636\u6bb5\u7684\u5931\u8d25\u533a\u57df\u8fdb\u884c\u9488\u5bf9\u6027\u77e5\u8bc6\u68c0\u7d22\u548c\u6570\u636e\u5408\u6210\u3002", "result": "Logics-STEM\u5728STEM\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c8B\u89c4\u6a21\u6a21\u578b\u6bd4\u6b21\u4f18\u6a21\u578b\u5e73\u5747\u63d0\u53474.68%\uff0c\u5c55\u793a\u4e86\u5927\u89c4\u6a21\u5f00\u6e90\u6570\u636e\u4e0e\u7cbe\u5fc3\u8bbe\u8ba1\u5408\u6210\u6570\u636e\u7ed3\u5408\u7684\u6f5c\u529b\u3002", "conclusion": "\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u5bf9\u4e8e\u901a\u8fc7\u540e\u8bad\u7ec3\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0cLogics-STEM\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u5f00\u6e90\u5c06\u652f\u6301\u5f00\u6e90\u793e\u533a\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.01569", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01569", "abs": "https://arxiv.org/abs/2601.01569", "authors": ["Maohao Ran", "Zhenglin Wan", "Cooper Lin", "Yanting Zhang", "Hongyu Xin", "Hongwei Fan", "Yibo Xu", "Beier Luo", "Yaxin Zhou", "Wangbo Zhao", "Lijie Yang", "Lang Feng", "Fuchao Yang", "Jingxuan Wu", "Yiqiao Huang", "Chendong Ma", "Dailing Jiang", "Jianbo Deng", "Sihui Han", "Bo An", "Yike Guo", "Jun Song"], "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators", "comment": "32 pages, 14 Figures", "summary": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from \"LLM-as-Text-Generator\" to \"LLM-as-Runtime-Operator.\" We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \\textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\\% success rate improvement on retail tasks and reduces total token consumption by 28.4\\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.", "AI": {"tldr": "CaveAgent\u662f\u4e00\u4e2a\u5c06LLM\u4ece\u6587\u672c\u751f\u6210\u5668\u8f6c\u53d8\u4e3a\u8fd0\u884c\u65f6\u64cd\u4f5c\u5458\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6d41\u4e0a\u4e0b\u6587\u67b6\u6784\u548c\u72b6\u6001\u5316\u8fd0\u884c\u65f6\u7ba1\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfJSON\u51fd\u6570\u8c03\u7528\u5728\u957f\u65f6\u4efb\u52a1\u4e2d\u7684\u8106\u5f31\u6027\u548c\u4e0a\u4e0b\u6587\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\u53d7\u9650\u4e8e\u6587\u672c\u4e2d\u5fc3\u8303\u5f0f\uff0c\u4f20\u7edf\u7684JSON\u51fd\u6570\u8c03\u7528\u65b9\u6cd5\u5728\u5904\u7406\u957f\u65f6\u4efb\u52a1\u65f6\u5b58\u5728\u8106\u5f31\u7684\u591a\u8f6e\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u6f02\u79fb\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u72b6\u6001\u7ba1\u7406\u548c\u6267\u884c\u80fd\u529b\u3002", "method": "\u63d0\u51faCaveAgent\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u6d41\u4e0a\u4e0b\u6587\u67b6\u6784\uff1a\u8f7b\u91cf\u7ea7\u8bed\u4e49\u6d41\u7528\u4e8e\u63a8\u7406\uff0c\u6301\u4e45\u5316\u786e\u5b9a\u6027Python\u8fd0\u884c\u65f6\u6d41\u7528\u4e8e\u6267\u884c\u3002\u5f15\u5165\u72b6\u6001\u5316\u8fd0\u884c\u65f6\u7ba1\u7406\uff0c\u652f\u6301\u590d\u6742Python\u5bf9\u8c61\uff08\u5982DataFrame\u3001\u6570\u636e\u5e93\u8fde\u63a5\uff09\u7684\u6ce8\u5165\u3001\u64cd\u4f5c\u548c\u8de8\u8f6e\u6b21\u6301\u4e45\u5316\u3002", "result": "\u5728Tau\u00b2-bench\u3001BFCL\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1a\u96f6\u552e\u4efb\u52a1\u6210\u529f\u7387\u63d0\u534710.5%\uff0c\u591a\u8f6e\u573a\u666f\u603btoken\u6d88\u8017\u51cf\u5c1128.4%\u3002\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\uff0c\u76f4\u63a5\u53d8\u91cf\u5b58\u50a8\u548c\u68c0\u7d22\u51cf\u5c1159% token\u6d88\u8017\uff0c\u80fd\u5904\u7406\u5bfc\u81f4\u5176\u4ed6\u4ee3\u7406\u4e0a\u4e0b\u6587\u6ea2\u51fa\u7684\u6d77\u91cf\u6570\u636e\u3002", "conclusion": "CaveAgent\u901a\u8fc7\u5c06LLM\u8f6c\u53d8\u4e3a\u8fd0\u884c\u65f6\u64cd\u4f5c\u5458\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4ee3\u7406\u7cfb\u7edf\u7684\u5173\u952e\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u9760\u7684\u957f\u65f6\u4efb\u52a1\u6267\u884c\uff0c\u4e3aLLM\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\u3002"}}
{"id": "2601.01609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01609", "abs": "https://arxiv.org/abs/2601.01609", "authors": ["Albert Sadowski", "Jaros\u0142aw A. Chudziak"], "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration", "comment": null, "summary": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408LLM\u7075\u6d3b\u6027\u4e0e\u7b26\u53f7\u63a8\u7406\u4fdd\u8bc1\u6027\u7684\u6846\u67b6\uff1a\u7528LLM\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u8f6c\u4e3aABox\u65ad\u8a00\uff0c\u518d\u7528SWRL\u63a8\u7406\u5668\u8fdb\u884c\u786e\u5b9a\u6027\u89c4\u5219\u5e94\u7528", "motivation": "\u5728\u9700\u8981\u53ef\u5ba1\u8ba1\u548c\u53ef\u89e3\u91ca\u51b3\u7b56\u7684\u9886\u57df\uff08\u5982\u4e34\u5e8a\u534f\u8bae\u3001\u6cd5\u5f8b\u8bc1\u636e\u89c4\u5219\u3001\u79d1\u5b66\u6807\u51c6\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u77db\u76fe\uff1aLLM\u7075\u6d3b\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u4e00\u81f4\u6027\uff0c\u7b26\u53f7\u7cfb\u7edf\u6709\u4fdd\u8bc1\u4f46\u9700\u8981\u7ed3\u6784\u5316\u8f93\u5165", "method": "\u63d0\u51fa\u96c6\u6210\u6a21\u5f0f\uff1aLLM\u4f5c\u4e3a\u672c\u4f53\u586b\u5145\u5f15\u64ce\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u8f6c\u4e3aABox\u65ad\u8a00\uff08\u57fa\u4e8e\u4e13\u5bb6\u7f16\u5199\u7684TBox\u89c4\u8303\uff09\uff0cSWRL\u63a8\u7406\u5668\u5e94\u7528\u89c4\u5219\u63d0\u4f9b\u786e\u5b9a\u6027\u4fdd\u8bc1\uff1b\u6846\u67b6\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u5b9e\u4f53\u8bc6\u522b\u3001\u65ad\u8a00\u63d0\u53d6\u548c\u7b26\u53f7\u9a8c\u8bc1", "result": "\u5728\u4e09\u4e2a\u9886\u57df\uff08\u6cd5\u5f8b\u4f20\u95fb\u786e\u5b9a\u3001\u79d1\u5b66\u65b9\u6cd5\u4efb\u52a1\u5e94\u7528\u3001\u4e34\u5e8a\u8bd5\u9a8c\u8d44\u683c\uff09\u548c11\u4e2a\u8bed\u8a00\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u6784\u5316\u5206\u89e3\u5728\u603b\u4f53\u4e0a\u6bd4few-shot\u63d0\u793a\u6709\u663e\u8457\u6539\u8fdb\uff0c\u6240\u6709\u4e09\u4e2a\u9886\u57df\u90fd\u6709\u63d0\u5347\uff1b\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u7b26\u53f7\u9a8c\u8bc1\u6bd4\u5355\u7eaf\u7ed3\u6784\u5316\u63d0\u793a\u6709\u5b9e\u8d28\u597d\u5904", "conclusion": "\u8be5\u6846\u67b6\u7ed3\u5408\u4e86LLM\u7684\u7075\u6d3b\u6027\u548c\u7b26\u53f7\u63a8\u7406\u7684\u4fdd\u8bc1\u6027\uff0c\u586b\u5145\u7684ABox\u53ef\u4e0e\u6807\u51c6\u8bed\u4e49\u7f51\u5de5\u5177\u96c6\u6210\uff0c\u652f\u6301\u66f4\u4e30\u5bcc\u7684\u63a8\u7406\u6a21\u5f0f"}}
{"id": "2601.01718", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01718", "abs": "https://arxiv.org/abs/2601.01718", "authors": ["YuanLab. ai", ":", "Shawn Wu", "Sean Wang", "Louie Li", "Darcy Chen", "Allen Wang", "Jiangang Luo", "Xudong Zhao", "Joseph Shen", "Gawain Ma", "Jasper Jia", "Marcus Mao", "Claire Wang", "Hunter He", "Carol Wang", "Zera Zhang", "Jason Wang", "Chonly Shen", "Leo Zhang", "Logan Chen", "Qasim Meng", "James Gong", "Danied Zhao", "Penn Zheng", "Owen Zhu", "Tong Yu"], "title": "Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications", "comment": null, "summary": "We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.", "AI": {"tldr": "Yuan3.0 Flash\u662f\u4e00\u4e2a\u5f00\u6e90\u7684MoE\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5177\u670937\u4ebf\u6fc0\u6d3b\u53c2\u6570\u548c400\u4ebf\u603b\u53c2\u6570\uff0c\u4e13\u4e3a\u4f01\u4e1a\u4efb\u52a1\u8bbe\u8ba1\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u4efb\u52a1\u7ade\u4e89\u529b\uff0c\u5e76\u901a\u8fc7RAPO\u7b97\u6cd5\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u4e2d\u5e38\u89c1\u7684\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5e76\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u5728\u4f01\u4e1a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u53c8\u80fd\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u9ad8\u6548\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u67b6\u6784\uff0c\u63d0\u51fa\u53cd\u5c04\u611f\u77e5\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\uff08RAPO\uff09\u7b97\u6cd5\u6765\u8c03\u8282\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\uff0c\u6a21\u578b\u5177\u670937\u4ebf\u6fc0\u6d3b\u53c2\u6570\u548c400\u4ebf\u603b\u53c2\u6570\u3002", "result": "\u5728\u4f01\u4e1a\u4efb\u52a1\uff08\u5982RAG\u3001\u590d\u6742\u8868\u683c\u7406\u89e3\u3001\u6458\u8981\u751f\u6210\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u6570\u5b66\u3001\u79d1\u5b66\u7b49\u63a8\u7406\u9886\u57df\u8fbe\u5230\u524d\u6cbf\u6a21\u578b\u53ef\u6bd4\u7cbe\u5ea6\uff0c\u540c\u65f6\u4ec5\u9700\u7ea61/4\u52301/2\u7684\u5e73\u5747token\u6570\u3002", "conclusion": "Yuan3.0 Flash\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7RAPO\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u4f01\u4e1a\u4efb\u52a1\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u5df2\u5b8c\u5168\u5f00\u6e90\u4f9b\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2601.01743", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01743", "abs": "https://arxiv.org/abs/2601.01743", "authors": ["Bin Xu"], "title": "AI Agent Systems: Architectures, Applications, and Evaluation", "comment": null, "summary": "AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\\ multi-agent; centralized vs.\\ decentralized coordination), and deployment settings (offline analysis vs.\\ online interactive assistance; safety-critical vs.\\ open-ended tasks). We discuss key design trade-offs -- latency vs.\\ accuracy, autonomy vs.\\ controllability, and capability vs.\\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u6db5\u76d6\u63a8\u7406\u3001\u89c4\u5212\u3001\u5de5\u5177\u8c03\u7528\u7b49\u6838\u5fc3\u7ec4\u4ef6\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u8ba8\u8bba\u4e86\u8bbe\u8ba1\u6743\u8861\u3001\u8bc4\u4f30\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "AI\u667a\u80fd\u4f53\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u4e0e\u63a8\u7406\u3001\u89c4\u5212\u3001\u8bb0\u5fc6\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u6b63\u5728\u6210\u4e3a\u8fde\u63a5\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u4e0e\u771f\u5b9e\u4e16\u754c\u8ba1\u7b97\u7684\u91cd\u8981\u63a5\u53e3\u3002\u968f\u7740\u8be5\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u68b3\u7406\u667a\u80fd\u4f53\u67b6\u6784\u7684\u73b0\u72b6\u3001\u5206\u7c7b\u548c\u8bbe\u8ba1\u8003\u91cf\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5c06\u73b0\u6709\u5de5\u4f5c\u7ec4\u7ec7\u4e3a\u7edf\u4e00\u7684\u5206\u7c7b\u4f53\u7cfb\uff1a1) \u667a\u80fd\u4f53\u7ec4\u4ef6\uff08\u7b56\u7565/LLM\u6838\u5fc3\u3001\u8bb0\u5fc6\u3001\u4e16\u754c\u6a21\u578b\u3001\u89c4\u5212\u5668\u3001\u5de5\u5177\u8def\u7531\u5668\u3001\u6279\u8bc4\u5668\uff09\uff1b2) \u7f16\u6392\u6a21\u5f0f\uff08\u5355\u667a\u80fd\u4f53vs.\u591a\u667a\u80fd\u4f53\uff0c\u96c6\u4e2d\u5f0fvs.\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\uff09\uff1b3) \u90e8\u7f72\u8bbe\u7f6e\uff08\u79bb\u7ebf\u5206\u6790vs.\u5728\u7ebf\u4ea4\u4e92\uff0c\u5b89\u5168\u5173\u952evs.\u5f00\u653e\u4efb\u52a1\uff09\u3002", "result": "\u5efa\u7acb\u4e86AI\u667a\u80fd\u4f53\u67b6\u6784\u7684\u5168\u9762\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u8bbe\u8ba1\u6743\u8861\uff08\u5ef6\u8fdfvs.\u51c6\u786e\u6027\u3001\u81ea\u4e3b\u6027vs.\u53ef\u63a7\u6027\u3001\u80fd\u529bvs.\u53ef\u9760\u6027\uff09\uff0c\u5206\u6790\u4e86\u8bc4\u4f30\u9762\u4e34\u7684\u6311\u6218\uff08\u975e\u786e\u5b9a\u6027\u3001\u957f\u65f6\u7a0b\u4fe1\u7528\u5206\u914d\u3001\u5de5\u5177\u548c\u73af\u5883\u53d8\u5f02\u6027\u3001\u9690\u85cf\u6210\u672c\uff09\uff0c\u5e76\u603b\u7ed3\u4e86\u5f53\u524d\u6d4b\u91cf\u548c\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u3002", "conclusion": "AI\u667a\u80fd\u4f53\u67b6\u6784\u7814\u7a76\u5df2\u5f62\u6210\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u4f46\u4ecd\u9762\u4e34\u5de5\u5177\u52a8\u4f5c\u9a8c\u8bc1\u4e0e\u9632\u62a4\u3001\u53ef\u6269\u5c55\u5185\u5b58\u4e0e\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u3001\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u53ef\u590d\u73b0\u8bc4\u4f30\u7b49\u5f00\u653e\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u3002"}}
{"id": "2601.01765", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01765", "abs": "https://arxiv.org/abs/2601.01765", "authors": ["Yao Lu", "Shang Liu", "Hangan Zhou", "Wenji Fang", "Qijun Zhang", "Zhiyao Xie"], "title": "A New Benchmark for the Appropriate Evaluation of RTL Code Optimization", "comment": null, "summary": "The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.", "AI": {"tldr": "RTL-OPT\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5728RTL\u4f18\u5316\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b36\u4e2a\u624b\u5de5\u8bbe\u8ba1\u7684\u6570\u5b57\u7535\u8def\uff0c\u6db5\u76d6\u591a\u79cd\u5b9e\u73b0\u7c7b\u522b\uff0c\u5e76\u63d0\u4f9b\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u529f\u80fd\u6b63\u786e\u6027\u548c\u91cf\u5316PPA\u6539\u8fdb\u3002", "motivation": "\u5f53\u524dAI\u82af\u7247\u8bbe\u8ba1\u9700\u8981\u9ad8\u6548\u7684\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\uff0c\u73b0\u6709LLM\u751f\u6210RTL\u4ee3\u7801\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u8bed\u6cd5\u6b63\u786e\u6027\uff0c\u800c\u975e\u529f\u7387\u3001\u6027\u80fd\u548c\u9762\u79ef\uff08PPA\uff09\u7684\u4f18\u5316\u8d28\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u8bc4\u4f30LLM\u5728RTL\u4f18\u5316\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u521b\u5efaRTL-OPT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b36\u4e2a\u624b\u5de5\u8bbe\u8ba1\u7684\u6570\u5b57\u7535\u8def\uff0c\u6db5\u76d6\u7ec4\u5408\u903b\u8f91\u3001\u6d41\u6c34\u7ebf\u6570\u636e\u901a\u8def\u3001\u6709\u9650\u72b6\u6001\u673a\u548c\u5b58\u50a8\u5668\u63a5\u53e3\u7b49\u7c7b\u522b\u3002\u6bcf\u4e2a\u4efb\u52a1\u63d0\u4f9b\u6b21\u4f18\u7248\u672c\u548c\u4eba\u5de5\u4f18\u5316\u7684\u53c2\u8003\u7248\u672c\uff0c\u53cd\u6620\u884c\u4e1a\u9a8c\u8bc1\u7684\u4f18\u5316\u6a21\u5f0f\u3002\u96c6\u6210\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u529f\u80fd\u6b63\u786e\u6027\u5e76\u91cf\u5316PPA\u6539\u8fdb\u3002", "result": "RTL-OPT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u9a8c\u8bc1\u751f\u6210\u6a21\u578b\u7684RTL\u4ee3\u7801\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5e76\u91cf\u5316\u5176\u5728\u529f\u7387\u3001\u6027\u80fd\u548c\u9762\u79ef\u65b9\u9762\u7684\u6539\u8fdb\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u8bc4\u4f30\u4f18\u5316\u8d28\u91cf\u65b9\u9762\u7684\u7a7a\u767d\u3002", "conclusion": "RTL-OPT\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u4e14\u6709\u610f\u4e49\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u5728\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u4f18\u5316\u65b9\u9762\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.01774", "categories": ["cs.AI", "cs.CE", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.01774", "abs": "https://arxiv.org/abs/2601.01774", "authors": ["Sai Varun Kodathala", "Rakesh Vunnam"], "title": "Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches", "comment": "14 pages", "summary": "Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.", "AI": {"tldr": "LLMs\u5728\u6c42\u89e3\u8d85\u8d8a\u65b9\u7a0b\u65f6\uff0c\u76f4\u63a5\u6570\u503c\u9884\u6d4b\u6548\u679c\u8f83\u5dee\uff0c\u4f46\u7ed3\u5408\u4f20\u7edf\u8fed\u4ee3\u6c42\u89e3\u5668\u7684\u6df7\u5408\u67b6\u6784\u80fd\u663e\u8457\u964d\u4f4e\u8bef\u5dee67.9%-81.8%\uff0c\u8868\u660eLLMs\u66f4\u9002\u5408\u4f5c\u4e3a\u7ecf\u5178\u6570\u503c\u6c42\u89e3\u5668\u7684\u667a\u80fd\u63a5\u53e3\u800c\u975e\u72ec\u7acb\u8ba1\u7b97\u5f15\u64ce\u3002", "motivation": "\u8d85\u8d8a\u65b9\u7a0b\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u9700\u8981\u8fed\u4ee3\u6570\u503c\u6c42\u89e3\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u5426\u76f4\u63a5\u6c42\u89e3\u8fd9\u4e9b\u65b9\u7a0b\uff0c\u8fd8\u662f\u9700\u8981\u7ed3\u5408\u4f20\u7edf\u6c42\u89e3\u5668\u7684\u6df7\u5408\u67b6\u6784\u66f4\u6709\u6548\u3002", "method": "\u6d4b\u8bd56\u4e2a\u6700\u5148\u8fdb\u7684LLM\u6a21\u578b\uff08GPT-5.1\u3001GPT-5.2\u3001Gemini-3-Flash\u3001Gemini-2.5-Lite\u3001Claude-Sonnet-4.5\u3001Claude-Opus-4.5\uff09\uff0c\u57287\u4e2a\u5de5\u7a0b\u9886\u57df\u7684100\u4e2a\u95ee\u9898\u4e0a\uff0c\u6bd4\u8f83\u76f4\u63a5\u6570\u503c\u9884\u6d4b\u4e0e\u6c42\u89e3\u5668\u8f85\u52a9\u8ba1\u7b97\uff08LLMs\u5236\u5b9a\u63a7\u5236\u65b9\u7a0b\u5e76\u63d0\u4f9b\u521d\u59cb\u6761\u4ef6\uff0c\u725b\u987f-\u62c9\u592b\u900a\u8fed\u4ee3\u6267\u884c\u6570\u503c\u6c42\u89e3\uff09\u3002", "result": "\u76f4\u63a5\u9884\u6d4b\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4e3a0.765-1.262\uff0c\u800c\u6c42\u89e3\u5668\u8f85\u52a9\u8ba1\u7b97\u4e3a0.225-0.301\uff0c\u8bef\u5dee\u964d\u4f4e67.9%-81.8%\u3002\u7535\u5b50\u9886\u57df\u6539\u8fdb\u6700\u663e\u8457\uff0893.1%\uff09\uff0c\u6d41\u4f53\u529b\u5b66\u6539\u8fdb\u6700\u5c0f\uff087.2%\uff09\u3002", "conclusion": "\u5f53\u4ee3LLMs\u64c5\u957f\u7b26\u53f7\u64cd\u4f5c\u548c\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\uff0c\u4f46\u5728\u7cbe\u5ea6\u5173\u952e\u7684\u8fed\u4ee3\u7b97\u672f\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u6700\u4f73\u90e8\u7f72\u65b9\u5f0f\u662f\u4f5c\u4e3a\u7ecf\u5178\u6570\u503c\u6c42\u89e3\u5668\u7684\u667a\u80fd\u63a5\u53e3\uff0c\u800c\u975e\u72ec\u7acb\u8ba1\u7b97\u5f15\u64ce\u3002"}}
{"id": "2601.01802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01802", "abs": "https://arxiv.org/abs/2601.01802", "authors": ["Qianjun Pan", "Junyi Wang", "Jie Zhou", "Yutao Yang", "Junsong Li", "Kaiyin Xu", "Yougen Zhou", "Yihan Li", "Jingyuan Zhao", "Qin Chen", "Ningning Zhou", "Kai Chen", "Liang He"], "title": "PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor", "comment": null, "summary": "To develop a reliable AI for psychological assessment, we introduce \\texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \\textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \\textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \\textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \\texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.", "AI": {"tldr": "PsychEval\uff1a\u4e00\u4e2a\u7528\u4e8e\u5fc3\u7406\u8bc4\u4f30AI\u7684\u591a\u4f1a\u8bdd\u3001\u591a\u7597\u6cd5\u3001\u9ad8\u771f\u5b9e\u5ea6\u57fa\u51c6\uff0c\u5305\u542b\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u6846\u67b6\u548c\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u65e8\u5728\u8bad\u7ec3\u548c\u8bc4\u4f30AI\u5fc3\u7406\u54a8\u8be2\u5e08\u3002", "motivation": "\u5f00\u53d1\u53ef\u9760\u7684\u5fc3\u7406\u8bc4\u4f30AI\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a1) \u8bad\u7ec3\u9ad8\u771f\u5b9e\u5ea6\u7684AI\u54a8\u8be2\u5e08\u9700\u8981\u5904\u7406\u7eb5\u5411\u4efb\u52a1\u3001\u6301\u7eed\u8bb0\u5fc6\u548c\u52a8\u6001\u76ee\u6807\u8ddf\u8e2a\uff1b2) \u590d\u6742\u6848\u4f8b\u9700\u8981\u591a\u7597\u6cd5\u7075\u6d3b\u7b56\u7565\uff1b3) \u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u591a\u4f1a\u8bdd\u57fa\u51c6\uff086-10\u4e2a\u4f1a\u8bdd\uff0c\u4e09\u4e2a\u9636\u6bb5\uff09\uff0c\u6db5\u76d6\u4e94\u79cd\u6cbb\u7597\u6a21\u5f0f\uff08\u5fc3\u7406\u52a8\u529b\u5b66\u3001\u884c\u4e3a\u4e3b\u4e49\u3001CBT\u3001\u4eba\u672c\u5b58\u5728\u4e3b\u4e49\u3001\u540e\u73b0\u4ee3\u4e3b\u4e49\uff09\u548c\u6574\u5408\u7597\u6cd5\uff1b\u6807\u6ce8677\u4e2a\u5143\u6280\u80fd\u548c4577\u4e2a\u539f\u5b50\u6280\u80fd\uff1b\u5efa\u7acb\u5305\u542b18\u4e2a\u6307\u6807\u7684\u8bc4\u4f30\u6846\u67b6\uff1b\u521b\u5efa2000\u591a\u4e2a\u591a\u6837\u5316\u7684\u5ba2\u6237\u6863\u6848\u3002", "result": "\u5b9e\u9a8c\u5206\u6790\u5145\u5206\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u7684\u9ad8\u8d28\u91cf\u548c\u4e34\u5e8a\u4fdd\u771f\u5ea6\uff1bPsychEval\u8d85\u8d8a\u4e86\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53ef\u4f5c\u4e3a\u9ad8\u4fdd\u771f\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u652f\u6301\u4e34\u5e8a\u8d1f\u8d23\u4efb\u548c\u9002\u5e94\u6027AI\u54a8\u8be2\u5e08\u7684\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u3002", "conclusion": "PsychEval\u4e3a\u89e3\u51b3AI\u5fc3\u7406\u8bc4\u4f30\u7684\u5173\u952e\u6311\u6218\u63d0\u4f9b\u4e86\u5168\u9762\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u4f1a\u8bdd\u3001\u591a\u7597\u6cd5\u7684\u9ad8\u771f\u5b9e\u5ea6\u57fa\u51c6\u548c\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u53ef\u9760\u3001\u9002\u5e94\u6027\u5f3a\u7684AI\u5fc3\u7406\u54a8\u8be2\u5e08\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.01816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01816", "abs": "https://arxiv.org/abs/2601.01816", "authors": ["Chris Duffey"], "title": "Admissibility Alignment", "comment": "24 pages, 2 figures, 2 tables.. Decision-theoretic alignment under uncertainty", "summary": "This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.\n  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u53ef\u63a5\u53d7\u6027\u5bf9\u9f50\"\u6846\u67b6\uff0c\u5c06AI\u5bf9\u9f50\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5bf9\u7ed3\u679c\u5206\u5e03\u7684\u53ef\u63a5\u53d7\u884c\u52a8\u548c\u51b3\u7b56\u9009\u62e9\u5c5e\u6027\uff0c\u5e76\u4ecb\u7ecdMAP-AI\u7cfb\u7edf\u67b6\u6784\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u548c\u653f\u7b56\u9009\u62e9\u5b9e\u73b0\u5bf9\u9f50\u3002", "motivation": "\u4f20\u7edfAI\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u5c06\u5bf9\u9f50\u89c6\u4e3a\u9759\u6001\u6216\u4e8c\u5143\u6761\u4ef6\uff0c\u7f3a\u4e4f\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u8bc4\u4f30\u51b3\u7b56\u653f\u7b56\u884c\u4e3a\u7684\u80fd\u529b\u3002\u9700\u8981\u5c06\u5bf9\u9f50\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u6982\u7387\u6027\u3001\u51b3\u7b56\u7406\u8bba\u5c5e\u6027\uff0c\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5e72\u9884\u6548\u5e94\u3001\u4ef7\u503c\u6a21\u7cca\u6027\u548c\u6cbb\u7406\u7ea6\u675f\u3002", "method": "\u63d0\u51faMAP-AI\uff08\u8499\u7279\u5361\u6d1b\u5bf9\u9f50\u653f\u7b56\uff09\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u7ed3\u679c\u5206\u5e03\u548c\u53ef\u63a5\u53d7\u6027\u63a7\u5236\u7684\u653f\u7b56\u9009\u62e9\u6765\u6267\u884c\u5bf9\u9f50\u3002\u6846\u67b6\u8bc4\u4f30\u51b3\u7b56\u653f\u7b56\u5728\u591a\u4e2a\u53ef\u80fd\u672a\u6765\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u660e\u786e\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u3001\u5e72\u9884\u6548\u5e94\u3001\u4ef7\u503c\u6a21\u7cca\u6027\u548c\u6cbb\u7406\u7ea6\u675f\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u57fa\u7840\u6846\u67b6\uff0c\u7528\u4e8e\u6cbb\u7406AI\u7cfb\u7edf\uff0c\u5176\u5f71\u54cd\u4e0d\u662f\u7531\u4e2a\u4f53\u9884\u6d4b\u51b3\u5b9a\uff0c\u800c\u662f\u7531\u653f\u7b56\u5728\u5206\u5e03\u548c\u5c3e\u90e8\u4e8b\u4ef6\u4e2d\u7684\u884c\u4e3a\u51b3\u5b9a\u3002\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u5206\u5e03\u5bf9\u9f50\u8bc4\u4f30\u6574\u5408\u5230\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u4ea7\u751f\u53ef\u63a5\u53d7\u6027\u63a7\u5236\u7684\u884c\u52a8\u9009\u62e9\u673a\u5236\u3002", "conclusion": "\u53ef\u63a5\u53d7\u6027\u5bf9\u9f50\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6267\u884c\u7684\u65b9\u6cd5\u8bba\uff0c\u7528\u4e8e\u8bc4\u4f30\u4f01\u4e1a\u548c\u673a\u6784AI\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u548c\u5bf9\u9f50\uff0c\u5c06\u6982\u7387\u9884\u6d4b\u4e0e\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u63a8\u7406\u533a\u5206\u5f00\u6765\uff0c\u4e3aAI\u6cbb\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2601.01836", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.01836", "abs": "https://arxiv.org/abs/2601.01836", "authors": ["Dasol Choi", "DongGeon Lee", "Brigitta Jesica Kartono", "Helena Berndt", "Taeyoun Kwon", "Joonwon Jang", "Haon Park", "Hwanjo Yu", "Minsuk Kahng"], "title": "COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs", "comment": null, "summary": "As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.", "AI": {"tldr": "COMPASS\u6846\u67b6\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30LLMs\u662f\u5426\u7b26\u5408\u7ec4\u7ec7\u653f\u7b56\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5904\u7406\u5408\u6cd5\u8bf7\u6c42\u65f6\u8868\u73b0\u826f\u597d\uff08>95%\u51c6\u786e\u7387\uff09\uff0c\u4f46\u5728\u6267\u884c\u7981\u4ee4\u65f6\u4e25\u91cd\u5931\u8d25\uff08\u4ec5\u62d2\u7edd13-40%\u7684\u8fdd\u89c4\u8bf7\u6c42\uff09\uff0c\u63ed\u793a\u5f53\u524dLLMs\u7f3a\u4e4f\u653f\u7b56\u5173\u952e\u90e8\u7f72\u6240\u9700\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u4f01\u4e1a\u5e94\u7528\u4e2d\u90e8\u7f72\uff0c\u786e\u4fdd\u6a21\u578b\u9075\u5b88\u7ec4\u7ec7\u7279\u5b9a\u653f\u7b56\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u4ec5\u5173\u6ce8\u901a\u7528\u5371\u5bb3\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7ec4\u7ec7\u653f\u7b56\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faCOMPASS\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u516b\u4e2a\u4e0d\u540c\u884c\u4e1a\u573a\u666f\uff0c\u751f\u6210\u5e76\u9a8c\u8bc15,920\u4e2a\u67e5\u8be2\uff0c\u6d4b\u8bd5\u5e38\u89c4\u5408\u89c4\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u3002\u8bc4\u4f30\u4e03\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8fb9\u7f18\u6848\u4f8b\u6d4b\u8bd5\u653f\u7b56\u6267\u884c\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u57fa\u672c\u4e0d\u5bf9\u79f0\u6027\uff1a\u6a21\u578b\u80fd\u53ef\u9760\u5904\u7406\u5408\u6cd5\u8bf7\u6c42\uff08>95%\u51c6\u786e\u7387\uff09\uff0c\u4f46\u5728\u6267\u884c\u7981\u4ee4\u65f6\u4e25\u91cd\u5931\u8d25\uff0c\u4ec5\u62d2\u7edd13-40%\u7684\u5bf9\u6297\u6027\u8fdd\u89c4\u8bf7\u6c42\u3002\u4e0d\u540c\u6a21\u578b\u5728\u653f\u7b56\u5408\u89c4\u6027\u65b9\u9762\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u5f53\u524dLLMs\u7f3a\u4e4f\u653f\u7b56\u5173\u952e\u90e8\u7f72\u6240\u9700\u7684\u9c81\u68d2\u6027\uff0cCOMPESS\u6846\u67b6\u4e3a\u7ec4\u7ec7AI\u5b89\u5168\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u7a81\u663e\u4e86\u5728\u73b0\u5b9e\u4f01\u4e1a\u73af\u5883\u4e2d\u786e\u4fdd\u653f\u7b56\u5408\u89c4\u6027\u7684\u7d27\u8feb\u9700\u6c42\u3002"}}
{"id": "2601.01844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01844", "abs": "https://arxiv.org/abs/2601.01844", "authors": ["Udiptaman Das", "Krishnasai B. Atmakuri", "Duy Ho", "Chi Lee", "Yugyung Lee"], "title": "Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation", "comment": "13 pages, 5 tables, 4 figures", "summary": "Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u63d0\u793a\u548c\u6a21\u5f0f\u7ea6\u675f\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\uff0c\u76f4\u63a5\u4ece\u81ea\u7531\u6587\u672c\u6784\u5efa\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\uff0c\u7279\u522b\u9488\u5bf9\u80bf\u7624\u5b66\u9886\u57df\uff0c\u65e0\u9700\u4f9d\u8d56\u9ec4\u91d1\u6807\u51c6\u6807\u6ce8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u7f3a\u4e4f\u5bf9\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u9c81\u68d2\u9a8c\u8bc1\uff0c\u8fd9\u5728\u80bf\u7624\u5b66\u9886\u57df\u5c24\u5176\u6210\u95ee\u9898\u3002\u9700\u8981\u76f4\u63a5\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u8ff0\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u63d0\u793a\u548c\u6a21\u5f0f\u7ea6\u675f\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\uff0c\u5305\u62ec\uff1a(1) \u63d0\u793a\u9a71\u52a8\u7684\u5b9e\u4f53\u3001\u5c5e\u6027\u548c\u5173\u7cfb\u62bd\u53d6\uff1b(2) \u57fa\u4e8e\u71b5\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\uff1b(3) \u672c\u4f53\u5bf9\u9f50\u7684RDF/OWL\u6a21\u5f0f\u751f\u6210\uff1b(4) \u591aLLM\u5171\u8bc6\u9a8c\u8bc1\u7528\u4e8e\u5e7b\u89c9\u68c0\u6d4b\u548c\u8bed\u4e49\u7cbe\u70bc\u3002", "result": "\u5e94\u7528\u4e8e\u4e24\u4e2a\u80bf\u7624\u5b66\u961f\u5217\uff08PDAC\u548cBRCA\uff09\uff0c\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u53ef\u89e3\u91ca\u3001SPARQL\u517c\u5bb9\u4e14\u4e34\u5e8a\u57fa\u7840\u7684\u77e5\u8bc6\u56fe\u8c31\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u7cbe\u786e\u5ea6\u3001\u76f8\u5173\u6027\u548c\u672c\u4f53\u4e00\u81f4\u6027\u65b9\u9762\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u8fde\u7eed\u7cbe\u70bc\u548c\u81ea\u76d1\u7763\u8bc4\u4f30\uff0c\u80fd\u591f\u8fed\u4ee3\u6539\u8fdb\u56fe\u8c31\u8d28\u91cf\uff0c\u4e3a\u76f4\u63a5\u4ece\u81ea\u7531\u6587\u672c\u6784\u5efa\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u80bf\u7624\u5b66\u9886\u57df\u3002"}}
{"id": "2601.01857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01857", "abs": "https://arxiv.org/abs/2601.01857", "authors": ["Defei Xia", "Bingfeng Pi", "Shenbin Zhang", "Song Hua", "Yunfei Wei", "Lei Zuo"], "title": "Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios", "comment": null, "summary": "As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Jenius-Agent\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63d0\u793a\u751f\u6210\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u5de5\u5177\u7f16\u6392\u548c\u5206\u5c42\u5185\u5b58\u673a\u5236\u4e09\u5927\u521b\u65b0\uff0c\u663e\u8457\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u4efb\u52a1\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u53d1\u5c55\uff0c\u63d0\u5347\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u5de5\u5177\u4f7f\u7528\u548c\u54cd\u5e94\u751f\u6210\u65b9\u9762\u7684\u4efb\u52a1\u6027\u80fd\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u5c3d\u7ba1\u5148\u524d\u7814\u7a76\u6539\u8fdb\u4e86LLM\u667a\u80fd\u4f53\u7684\u6574\u4f53\u8bbe\u8ba1\uff0c\u4f46\u5176\u5185\u90e8\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\u7684\u7cfb\u7edf\u6027\u4f18\u5316\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u5b9e\u8df5\u7ecf\u9a8c\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e09\u5927\u5173\u952e\u521b\u65b0\uff1a1\uff09\u81ea\u9002\u5e94\u63d0\u793a\u751f\u6210\u7b56\u7565\uff0c\u6839\u636e\u667a\u80fd\u4f53\u72b6\u6001\u548c\u4efb\u52a1\u76ee\u6807\u8c03\u6574\u63d0\u793a\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff1b2\uff09\u4e0a\u4e0b\u6587\u611f\u77e5\u5de5\u5177\u7f16\u6392\u6a21\u5757\uff0c\u57fa\u4e8e\u7528\u6237\u610f\u56fe\u548c\u4e0a\u4e0b\u6587\u8fdb\u884c\u5de5\u5177\u5206\u7c7b\u3001\u8bed\u4e49\u68c0\u7d22\u548c\u81ea\u9002\u5e94\u8c03\u7528\uff1b3\uff09\u5206\u5c42\u5185\u5b58\u673a\u5236\uff0c\u96c6\u6210\u4f1a\u8bdd\u5185\u5b58\u3001\u4efb\u52a1\u5386\u53f2\u548c\u5916\u90e8\u6458\u8981\uff0c\u901a\u8fc7\u52a8\u6001\u6458\u8981\u548c\u538b\u7f29\u63d0\u9ad8\u76f8\u5173\u6027\u548c\u6548\u7387\u3002\u6846\u67b6\u96c6\u6210\u4e86\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7684\u5de5\u5177\u3001\u6587\u4ef6\u8f93\u5165/\u8f93\u51fa\u548c\u6267\u884c\u53cd\u9988\u4e09\u5927\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4efb\u52a1\u51c6\u786e\u6027\u63d0\u9ad8\u4e8620%\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u4ee4\u724c\u6210\u672c\u3001\u54cd\u5e94\u5ef6\u8fdf\u548c\u8c03\u7528\u5931\u8d25\u7387\u3002\u8be5\u6846\u67b6\u5df2\u5728Jenius\u5e73\u53f0\u90e8\u7f72\uff0c\u4e3a\u7a33\u5065\u3001\u534f\u8bae\u517c\u5bb9\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Jenius-Agent\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u6027\u4f18\u5316\u667a\u80fd\u4f53\u7684\u5185\u90e8\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01875", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.01875", "abs": "https://arxiv.org/abs/2601.01875", "authors": ["Kewen Cao", "Jianxu Chen", "Yongbing Zhang", "Ye Zhang", "Hongxiao Wang"], "title": "Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence", "comment": null, "summary": "Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.", "AI": {"tldr": "\u63d0\u51faSQL\u4e3a\u4e2d\u5fc3\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u6d4b\u91cf\u548c\u53ef\u5ba1\u8ba1\u63a8\u7406\u63d0\u5347\u75c5\u7406\u56fe\u50cf\u5206\u6790\u7684\u900f\u660e\u5ea6", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u89e3\u91ca\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u8bc1\u636e\uff0c\u4e34\u5e8a\u533b\u751f\u9700\u8981\u4e86\u89e3\u6a21\u578b\u51b3\u7b56\u80cc\u540e\u7684\u5177\u4f53\u56fe\u50cf\u7279\u5f81\u9a71\u52a8\u56e0\u7d20", "method": "\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u7ec6\u80de\u7279\u5f81\u540e\uff0c\u7279\u5f81\u63a8\u7406\u4ee3\u7406\u7f16\u5199\u6267\u884cSQL\u67e5\u8be2\u805a\u5408\u89c6\u89c9\u8bc1\u636e\uff0c\u77e5\u8bc6\u6bd4\u8f83\u4ee3\u7406\u5c06\u53d1\u73b0\u4e0e\u75c5\u7406\u77e5\u8bc6\u5bf9\u6bd4", "result": "\u5728\u4e24\u4e2a\u75c5\u7406\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\uff0c\u751f\u6210\u53ef\u6267\u884c\u7684SQL\u8ffd\u8e2a", "conclusion": "SQL\u4e3a\u4e2d\u5fc3\u7684\u4ee3\u7406\u6846\u67b6\u901a\u8fc7\u53ef\u5ba1\u8ba1\u7684\u7279\u5f81\u6d4b\u91cf\u548c\u63a8\u7406\uff0c\u589e\u5f3a\u4e86\u75c5\u7406\u56fe\u50cf\u5206\u6790\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6"}}
{"id": "2601.01878", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.01878", "abs": "https://arxiv.org/abs/2601.01878", "authors": ["Farzan Karimi-Malekabadi", "Suhaib Abdurahman", "Zhivar Sourati", "Jackson Trager", "Morteza Dehghani"], "title": "Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs", "comment": null, "summary": "Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u8ba4\u77e5\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u7406\u8bba\u7a7a\u767d\u95ee\u9898\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u88ab\u8fc7\u5ea6\u6cdb\u5316\uff0c\u5e76\u63d0\u51fa\u4e86\u7406\u8bba\u8ffd\u8e2a\u5361\uff08TTC\uff09\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u8ba4\u77e5\u57fa\u51c6\u6d4b\u8bd5\u867d\u7136\u5f97\u5206\u9ad8\uff0c\u4f46\u65e0\u6cd5\u9884\u6d4b\u771f\u5b9e\u4e16\u754c\u884c\u4e3a\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5f52\u56e0\u4e8e\u6d4b\u91cf\u548c\u6548\u5ea6\u95ee\u9898\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u66f4\u6839\u672c\u7684\u95ee\u9898\u662f\u7f3a\u4e4f\u660e\u786e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u88ab\u7cfb\u7edf\u6027\u8fc7\u5ea6\u89e3\u91ca\u3002", "method": "\u9996\u5148\u8bca\u65ad\u5e76\u5f62\u5f0f\u5316\u7406\u8bba\u7a7a\u767d\u95ee\u9898\uff0c\u7136\u540e\u63d0\u51fa\u7406\u8bba\u8ffd\u8e2a\u5361\uff08TTC\uff09\u2014\u2014\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6587\u6863\u5de5\u5177\uff0c\u660e\u786e\u8bb0\u5f55\u8bc4\u4f30\u7684\u7406\u8bba\u57fa\u7840\u3001\u76ee\u6807\u80fd\u529b\u7ec4\u4ef6\u3001\u64cd\u4f5c\u5316\u8fc7\u7a0b\u548c\u5c40\u9650\u6027\u3002", "result": "\u901a\u8fc7TTC\u53ef\u4ee5\u589e\u5f3a\u793e\u4f1a\u8ba4\u77e5\u8bc4\u4f30\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u660e\u786e\u7406\u8bba\u3001\u4efb\u52a1\u64cd\u4f5c\u5316\u3001\u8bc4\u5206\u548c\u5c40\u9650\u6027\u4e4b\u95f4\u7684\u5b8c\u6574\u6548\u5ea6\u94fe\uff0c\u65e0\u9700\u4fee\u6539\u57fa\u51c6\u6d4b\u8bd5\u6216\u8981\u6c42\u5355\u4e00\u7406\u8bba\u5171\u8bc6\u3002", "conclusion": "\u7406\u8bba\u8ffd\u8e2a\u5361\u4e3a\u89e3\u51b3\u793e\u4f1a\u8ba4\u77e5\u8bc4\u4f30\u4e2d\u7684\u7406\u8bba\u7a7a\u767d\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u9632\u6b62\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u7684\u7cfb\u7edf\u6027\u8fc7\u5ea6\u6cdb\u5316\uff0c\u63d0\u9ad8\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2601.01910", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01910", "abs": "https://arxiv.org/abs/2601.01910", "authors": ["Minh Hieu Ha", "Khanh Ly Ta", "Hung Phan", "Tung Doan", "Tung Dao", "Dao Tran", "Huynh Thi Thanh Binh"], "title": "MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning", "comment": null, "summary": "Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.\n  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.", "AI": {"tldr": "MMP-A* \u662f\u4e00\u4e2a\u591a\u6a21\u6001\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u548c\u81ea\u9002\u5e94\u8870\u51cf\u673a\u5236\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002", "motivation": "\u4f20\u7edfA*\u7b97\u6cd5\u5728\u5927\u89c4\u6a21\u590d\u6742\u73af\u5883\u4e2d\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u8fc7\u9ad8\uff0c\u800c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u6587\u672c\u63a8\u7406\uff0c\u7f3a\u4e4f\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u5728\u62d3\u6251\u590d\u6742\u73af\u5883\u4e2d\u5bb9\u6613\u4ea7\u751f\u9519\u8bef\u8def\u5f84\u70b9\uff0c\u5bfc\u81f4\u7ea0\u6b63\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faMMP-A*\u591a\u6a21\u6001\u6846\u67b6\uff1a1\uff09\u96c6\u6210\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u5c06\u9ad8\u5c42\u63a8\u7406\u951a\u5b9a\u5728\u7269\u7406\u51e0\u4f55\u4e2d\uff1b2\uff09\u5f15\u5165\u81ea\u9002\u5e94\u8870\u51cf\u673a\u5236\uff0c\u52a8\u6001\u8c03\u8282\u4e0d\u786e\u5b9a\u8def\u5f84\u70b9\u5728\u542f\u53d1\u5f0f\u51fd\u6570\u4e2d\u7684\u5f71\u54cd\uff0c\u786e\u4fdd\u51e0\u4f55\u6709\u6548\u6027\u5e76\u51cf\u5c11\u5185\u5b58\u5f00\u9500\u3002", "result": "\u5728\u5177\u6709\u4e25\u91cd\u6742\u4e71\u548c\u62d3\u6251\u590d\u6742\u6027\u7684\u6311\u6218\u6027\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0cMMP-A*\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u64cd\u4f5c\u6210\u672c\uff08\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff09\u3002", "conclusion": "MMP-A*\u4f5c\u4e3a\u4e00\u4e2a\u611f\u77e5\u63a5\u5730\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u8303\u5f0f\uff0c\u4e3a\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u878d\u5408\u89e3\u51b3\u4e86\u7eaf\u6587\u672c\u89c4\u5212\u5668\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.01939", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01939", "abs": "https://arxiv.org/abs/2601.01939", "authors": ["Victor Sanchez", "Chris Reinke", "Ahamed Mohamed", "Xavier Alameda-Pineda"], "title": "OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation", "comment": null, "summary": "In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.", "AI": {"tldr": "OpenSocInt\u662f\u4e00\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u63d0\u4f9b\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u5668\u548c\u6a21\u5757\u5316\u67b6\u6784\uff0c\u7528\u4e8e\u8bad\u7ec3\u793e\u4ea4\u667a\u80fd\u4f53\uff0c\u5df2\u5728\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u4e2d\u5c55\u793a\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7528\u4e8e\u7814\u7a76\u548c\u8bad\u7ec3\u793e\u4ea4\u667a\u80fd\u4f53\u7684\u5f00\u6e90\u6a21\u62df\u73af\u5883\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u65b9\u9762\u3002\u9700\u8981\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u5de5\u5177\u6765\u63a2\u7d22\u4e0d\u540c\u611f\u77e5\u7279\u5f81\u3001\u7f16\u7801\u878d\u5408\u65b9\u6cd5\u4ee5\u53ca\u667a\u80fd\u4f53\u67b6\u6784\u3002", "method": "\u5f00\u53d1\u4e86OpenSocInt\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u5305\u542b\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u5668\u548c\u6a21\u5757\u5316\u8bad\u7ec3\u67b6\u6784\u3002\u91c7\u7528\u57fa\u4e8e\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u7684\u5b9e\u9a8c\u534f\u8bae\u8fdb\u884c\u9a8c\u8bc1\uff0c\u652f\u6301\u4e0d\u540c\u611f\u77e5\u7279\u5f81\u3001\u7f16\u7801\u878d\u5408\u65b9\u6cd5\u548c\u667a\u80fd\u4f53\u7c7b\u578b\u7684\u63a2\u7d22\u3002", "result": "\u6210\u529f\u5f00\u53d1\u5e76\u5f00\u6e90\u4e86OpenSocInt\u8f6f\u4ef6\u5305\uff0c\u5df2\u5728\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u4e2d\u5c55\u793a\u5176\u5e94\u7528\u4ef7\u503c\u3002\u8f6f\u4ef6\u91c7\u7528GPL\u8bb8\u53ef\u8bc1\uff0c\u5df2\u5728GitLab\u4e0a\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "OpenSocInt\u4e3a\u793e\u4ea4\u667a\u80fd\u4f53\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u652f\u6301\u591a\u6a21\u6001\u4ea4\u4e92\u6a21\u62df\u548c\u6a21\u5757\u5316\u8bad\u7ec3\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u793e\u4ea4\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.01976", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01976", "abs": "https://arxiv.org/abs/2601.01976", "authors": ["Yasmine Souissi", "Fabrice Boissier", "Nida Meddouri"], "title": "CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes", "comment": null, "summary": "Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u540d\u4e49\u6570\u636e\u8ba1\u7b97\u95ed\u5305\u7b97\u5b50\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u6982\u5ff5\u7684\u90e8\u5206\u6982\u5ff5\u683c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u77e5\u8bc6\u53d1\u73b0\uff08KDD\uff09\u65e8\u5728\u4ece\u6d77\u91cf\u6570\u636e\u4e2d\u63d0\u53d6\u9690\u85cf\u77e5\u8bc6\uff0c\u5206\u7c7b\u662f\u6838\u5fc3\u6570\u636e\u6316\u6398\u6280\u672f\u4e4b\u4e00\u3002\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u4f5c\u4e3a\u4e00\u79cd\u53ef\u89e3\u91ca\u548c\u53ef\u89e3\u91ca\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6982\u5ff5\u683c\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u80fd\u591f\u751f\u6210\u5f62\u5f0f\u6982\u5ff5\u5e76\u53d1\u73b0\u9690\u85cf\u5173\u7cfb\uff0c\u56e0\u6b64\u503c\u5f97\u6df1\u5165\u7814\u7a76\u5176\u5206\u7c7b\u5e94\u7528\u3002", "method": "1. \u5bf9\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u4e86\u6700\u5148\u8fdb\u7684\u7efc\u8ff0\uff1b2. \u63a2\u7d22\u4e86\u4ece\u540d\u4e49\u6570\u636e\u8ba1\u7b97\u95ed\u5305\u7b97\u5b50\u7684\u5404\u79cd\u65b9\u6cd5\uff1b3. \u63d0\u51fa\u4e86\u4e00\u79cd\u6784\u5efa\u90e8\u5206\u6982\u5ff5\u683c\u7684\u65b0\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u7684\u6982\u5ff5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6784\u5efa\u90e8\u5206\u6982\u5ff5\u683c\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "FCA\u4f5c\u4e3a\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u5206\u7c7b\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u63d0\u51fa\u7684\u90e8\u5206\u6982\u5ff5\u683c\u6784\u5efa\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u5206\u7c7b\u6548\u7387\uff0c\u4e3a\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2601.01982", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01982", "abs": "https://arxiv.org/abs/2601.01982", "authors": ["Noel Thomas"], "title": "ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems", "comment": "7 pages, 0 figures , Accepted to AAAI-26 Bridge Program: Logical and Symbolic Reasoning in Language Models (camera-ready)", "summary": "Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.", "AI": {"tldr": "ChaosBench-Logic\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u9886\u57df\u903b\u8f91\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b30\u4e2a\u7cfb\u7edf\u3001621\u4e2a\u95ee\u9898\uff0c\u6d4b\u8bd5\u663e\u793a\u524d\u6cbfLLMs\u5728\u5355\u9879\u51c6\u786e\u7387\u4e0a\u8fbe\u523091-94%\uff0c\u4f46\u5728\u7ec4\u5408\u63a8\u7406\u4e0a\u5f97\u5206\u4e3a0%\uff0c\u5bf9\u8bdd\u51c6\u786e\u7387\u572853.1-75.5%\u4e4b\u95f4\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u7684\u9886\u57df\u4ecd\u7136\u8106\u5f31\u3002\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7279\u522b\u4e25\u683c\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u56e0\u4e3a\u6df7\u6c8c\u662f\u786e\u5b9a\u6027\u7684\uff0c\u4f46\u7ecf\u5e38\u88ab\u8bef\u89e3\u4e3a\u968f\u673a\u6027\u6216\u590d\u6742\u6027\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u5728\u8fd9\u79cd\u590d\u6742\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165ChaosBench-Logic\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u7edf\u4e00\u7684\u4e00\u9636\u903b\u8f91\u672c\u4f53\u8bba\u8bc4\u4f3030\u4e2a\u4e0d\u540c\u7684\u52a8\u529b\u7cfb\u7edf\u3002\u6bcf\u4e2a\u7cfb\u7edf\u6807\u6ce8\u4e8611\u4e2a\u8bed\u4e49\u8c13\u8bcd\u7684\u771f\u503c\u5206\u914d\uff0c\u751f\u6210621\u4e2a\u95ee\u9898\uff0c\u6db5\u76d6\u4e03\u4e2a\u63a8\u7406\u7c7b\u522b\uff1a\u591a\u8df3\u63a8\u7406\u3001\u8de8\u7cfb\u7edf\u7c7b\u6bd4\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u504f\u89c1\u63a2\u6d4b\u548c\u591a\u8f6e\u5bf9\u8bdd\u3002\u5b9a\u4e49\u4e86\u903b\u8f91\u51c6\u786e\u6027\u3001\u8574\u542b\u4e00\u81f4\u6027\u3001\u5bf9\u8bdd\u8fde\u8d2f\u6027\u548c\u77db\u76fe\u6027\u7b49\u6307\u6807\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u8bc4\u4f30\u7ba1\u9053\u3002", "result": "\u524d\u6cbfLLMs\uff08GPT-4\u3001Claude 3.5 Sonnet\u3001Gemini 2.5 Flash\u3001LLaMA-3 70B\uff09\u5728\u5355\u9879\u51c6\u786e\u7387\u4e0a\u8fbe\u523091-94%\uff0c\u4f46\u5728\u7ec4\u5408\u63a8\u7406\u9879\u76ee\u4e0a\u5f97\u5206\u4e3a0%\uff0c\u8868\u73b0\u51fa\u8106\u5f31\u7684\u5168\u5c40\u4e00\u81f4\u6027\u3002\u5bf9\u8bdd\u7ea7\u51c6\u786e\u7387\u4ece53.1%\uff08GPT-4 CoT\uff09\u523075.5%\uff08LLaMA-3\u96f6\u6837\u672c\uff09\u4e0d\u7b49\u3002", "conclusion": "ChaosBench-Logic\u4e3a\u8bca\u65adLLMs\u5728\u590d\u6742\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u5931\u8d25\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u4e3a\u5f00\u53d1\u6539\u8fdbLLMs\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1LLMs\u5728\u5355\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7ec4\u5408\u63a8\u7406\u548c\u5168\u5c40\u4e00\u81f4\u6027\u7684\u590d\u6742\u903b\u8f91\u4efb\u52a1\u4e0a\u4ecd\u7136\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002"}}
{"id": "2601.01993", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01993", "abs": "https://arxiv.org/abs/2601.01993", "authors": ["Dong Xue", "Jicheng Tu", "Ming Wang", "Xin Yan", "Fangzhou Liu", "Jie Hu"], "title": "MindChat: A Privacy-preserving Large Language Model for Mental Health Support", "comment": "33 pages, 16 figures", "summary": "Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.", "AI": {"tldr": "MindChat\u662f\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u914d\u5408MindCorpus\u5408\u6210\u54a8\u8be2\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u51cf\u5c11\u9690\u79c1\u98ce\u9669\uff0c\u5728\u54a8\u8be2\u80fd\u529b\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u771f\u5b9e\u54a8\u8be2\u5bf9\u8bdd\u7684\u7a00\u7f3a\u6027\u548c\u654f\u611f\u6027\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u3002", "method": "1) \u4f7f\u7528\u591a\u667a\u80fd\u4f53\u89d2\u8272\u626e\u6f14\u6846\u67b6\u6784\u5efaMindCorpus\u5408\u6210\u54a8\u8be2\u6570\u636e\u96c6\uff0c\u91c7\u7528\u53cc\u95ed\u73af\u53cd\u9988\u8bbe\u8ba1\uff1a\u8f6e\u6b21\u7ea7\u6279\u5224\u4fee\u8ba2\u548c\u4f1a\u8bdd\u7ea7\u7b56\u7565\u4f18\u5316\uff1b2) \u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u914d\u5408LoRA\u9002\u914d\u5668\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5e76\u52a0\u5165\u5dee\u5206\u9690\u79c1\u4f18\u5316\u51cf\u5c11\u9690\u79c1\u98ce\u9669\u3002", "result": "MindCorpus\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u679c\uff0cMindChat\u5728\u81ea\u52a8LLM\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u4e0e\u73b0\u6709\u901a\u7528\u548c\u54a8\u8be2\u5bfc\u5411\u7684LLM\u57fa\u7ebf\u7ade\u4e89\uff0c\u540c\u65f6\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e0b\u8868\u73b0\u51fa\u51cf\u5c11\u7684\u9690\u79c1\u6cc4\u9732\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u6784\u5efa\u4e86\u9ad8\u8d28\u91cf\u5408\u6210\u54a8\u8be2\u6570\u636e\u96c6\u548c\u4fdd\u62a4\u9690\u79c1\u7684\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u6a21\u578b\uff0c\u4e3a\u89e3\u51b3\u771f\u5b9e\u54a8\u8be2\u6570\u636e\u7a00\u7f3a\u548c\u9690\u79c1\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.02008", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.02008", "abs": "https://arxiv.org/abs/2601.02008", "authors": ["Midhat Urooj", "Ayan Banerjee", "Sandeep Gupta"], "title": "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging", "comment": "Accepted at AAAI Bridge Program 2026", "summary": "Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.", "AI": {"tldr": "XAIMeD\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u533b\u7597AI\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u6574\u5408\u4e34\u5e8a\u4e13\u5bb6\u77e5\u8bc6\uff0c\u63d0\u5347\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3001\u7f55\u89c1\u7c7b\u522b\u654f\u611f\u6027\uff0c\u5e76\u63d0\u4f9b\u4e34\u5e8a\u5bf9\u9f50\u7684\u89e3\u91ca\u3002", "motivation": "\u533b\u7597AI\u4e2d\u53ef\u89e3\u91ca\u6027\u3001\u9886\u57df\u6cdb\u5316\u548c\u7f55\u89c1\u7c7b\u522b\u53ef\u9760\u6027\u662f\u5173\u952e\u6311\u6218\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u504f\u79fb\u4e0b\u7ecf\u5e38\u5931\u8d25\uff0c\u5e76\u5bf9\u7f55\u89c1\u4e34\u5e8a\u6761\u4ef6\u8868\u73b0\u51fa\u504f\u89c1\u3002", "method": "\u5c06\u4e34\u5e8a\u4e13\u4e1a\u77e5\u8bc6\u7f16\u7801\u4e3a\u539f\u5b50\u533b\u5b66\u547d\u9898\u7684\u903b\u8f91\u8fde\u63a5\uff0c\u8f6c\u5316\u4e3a\u673a\u5668\u53ef\u68c0\u67e5\u7684\u7c7b\u522b\u7279\u5b9a\u89c4\u5219\uff1b\u901a\u8fc7\u52a0\u6743\u7279\u5f81\u6ee1\u8db3\u5206\u6570\u91cf\u5316\u8bca\u65ad\u6548\u7528\uff1b\u7b26\u53f7\u63a8\u7406\u5206\u652f\u4e0e\u795e\u7ecf\u9884\u6d4b\u4e92\u8865\uff1b\u7f6e\u4fe1\u5ea6\u52a0\u6743\u878d\u5408\u6574\u5408\u7b26\u53f7\u548c\u6df1\u5ea6\u8f93\u51fa\uff1b\u57fa\u4e8e\u71b5\u4e0d\u5e73\u8861\u589e\u76ca\u548c\u7f55\u89c1\u7c7b\u522b\u57fa\u5c3c\u7cfb\u6570\u7684\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u3002", "result": "\u5728\u56db\u4e2a\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u5305\u62ec\u4ecers-fMRI\u7684\u766b\u75eb\u53d1\u4f5c\u533a\u5b9a\u4f4d\u548c6\u4e2a\u591a\u4e2d\u5fc3\u6570\u636e\u96c6\u7684\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u7ea7\uff0c\u663e\u793a\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1a\u8de8\u9886\u57df\u6cdb\u5316\u63d0\u9ad86%\uff0c\u7f55\u89c1\u7c7b\u522bF1\u5206\u6570\u63d0\u534710%\uff0c\u8fdc\u8d85\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "XAIMeD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u3001\u4e34\u5e8a\u5fe0\u5b9e\u4e14\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u533b\u7597AI\u65b9\u6cd5\uff0c\u4e34\u5e8a\u57fa\u7840\u7684\u7b26\u53f7\u7ec4\u4ef6\u4f5c\u4e3a\u6709\u6548\u7684\u6b63\u5219\u5316\u5668\uff0c\u786e\u4fdd\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.02043", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.02043", "abs": "https://arxiv.org/abs/2601.02043", "authors": ["Hendrik Kempt", "Alon Lavie"], "title": "Simulated Reasoning is Reasoning", "comment": "21 pages", "summary": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u6a21\u4eff\"\u601d\u8003\u8fc7\u7a0b\"\u3001\u6d4b\u8bd5\u751f\u6210\u8def\u5f84\u5e76\u8fed\u4ee3\uff0c\u5b9e\u73b0\u4e86\u4e0d\u540c\u4e8e\u4eba\u7c7b\u7b26\u53f7\u63a8\u7406\u7684\u65b0\u578b\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u6311\u6218\u4e86\u4f20\u7edf\u63a8\u7406\u6982\u5ff5\uff0c\u5e76\u5e26\u6765\u5b89\u5168\u6027\u548c\u9002\u5f53\u6027\u65b9\u9762\u7684\u89c4\u8303\u8003\u91cf\u3002", "motivation": "\u4f20\u7edf\u4e0a\u8ba4\u4e3a\u63a8\u7406\u662f\u901a\u8fc7\u7b26\u53f7\u63a8\u7406\u5b9e\u73b0\u7406\u89e3\u7684\u8def\u5f84\uff0c\u4f46\u57fa\u7840\u6a21\u578b\u5c55\u793a\u4e86\u4e0d\u540c\u7684\u63a8\u7406\u65b9\u5f0f\u2014\u2014\u901a\u8fc7\u6a21\u4eff\"\u601d\u8003\u8fc7\u7a0b\"\u3001\u6d4b\u8bd5\u8def\u5f84\u548c\u8fed\u4ee3\u6765\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u6311\u6218\u4e86\u4f20\u7edf\u63a8\u7406\u6982\u5ff5\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u4e3a\u5e94\u5bf9\u57fa\u7840\u6a21\u578b\u63a8\u7406\u7684\u8106\u5f31\u6027\u63d0\u4f9b\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u91c7\u7528\u54f2\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u8ba8\u8bba\u57fa\u7840\u6a21\u578b\u63a8\u7406\u73b0\u8c61\u7684\u4e0d\u540c\u54f2\u5b66\u89e3\u91ca\uff0c\u8bba\u8bc1\"\u968f\u673a\u9e66\u9e49\"\u9690\u55bb\u5df2\u5931\u53bb\u76f8\u5173\u6027\u5e94\u88ab\u629b\u5f03\uff0c\u5e76\u53cd\u601d\u4ece\u8fd9\u4e9b\u63a8\u7406\u6a21\u578b\u53ca\u5176\u589e\u957f\u80fd\u529b\u4e2d\u4ea7\u751f\u7684\u5b89\u5168\u6027\u548c\u9002\u5f53\u6027\u89c4\u8303\u8981\u7d20\u3002", "result": "\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u6a21\u4eff\u601d\u8003\u8fc7\u7a0b\u3001\u6d4b\u8bd5\u8def\u5f84\u548c\u8fed\u4ee3\u7684\u65b9\u5f0f\u5b9e\u73b0\u4e86\u67d0\u79cd\u5f62\u5f0f\u7684\u63a8\u7406\u80fd\u529b\uff0c\u80fd\u591f\u72ec\u7acb\u6216\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u89e3\u51b3\u95ee\u9898\uff0c\u4f46\u5176\u63a8\u7406\u4e0e\u4eba\u7c7b\u63a8\u7406\u5b58\u5728\u6839\u672c\u5dee\u5f02\u2014\u2014\u7f3a\u4e4f\u57fa\u7840\u548c\u5e38\u8bc6\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u8106\u5f31\u3002\u8fd9\u4e9b\u53d1\u73b0\u5c06\u663e\u8457\u6539\u53d8\u6211\u4eec\u5bf9\u63a8\u7406\u53ca\u5176\u5fc5\u8981\u6761\u4ef6\u7684\u8bc4\u4f30\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5c55\u793a\u4e86\u4e0d\u540c\u4e8e\u4f20\u7edf\u7b26\u53f7\u63a8\u7406\u7684\u65b0\u578b\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u8981\u6c42\u6211\u4eec\u91cd\u65b0\u601d\u8003\u63a8\u7406\u7684\u672c\u8d28\u3002\u867d\u7136\"\u968f\u673a\u9e66\u9e49\"\u9690\u55bb\u5df2\u8fc7\u65f6\uff0c\u4f46\u9700\u8981\u5173\u6ce8\u8fd9\u79cd\u63a8\u7406\u7684\u8106\u5f31\u6027\uff0c\u5e76\u5efa\u7acb\u76f8\u5e94\u7684\u5b89\u5168\u6027\u548c\u9002\u5f53\u6027\u89c4\u8303\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e9b\u65b0\u5174\u63a8\u7406\u6a21\u578b\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2601.02061", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02061", "abs": "https://arxiv.org/abs/2601.02061", "authors": ["Faizan Ahmed", "Aniket Dixit", "James Brusey"], "title": "Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management", "comment": "6 pages, accepted at NeurIPS workshop 2025", "summary": "Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u9ad8\u9636\u5bfc\u6570\u60e9\u7f5a\u5b9e\u73b0\u52a8\u4f5c\u5e73\u6ed1\u6b63\u5219\u5316\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u4e09\u9636\u5bfc\u6570\u60e9\u7f5a\uff08\u6025\u52a8\u5ea6\u6700\u5c0f\u5316\uff09\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5e73\u6ed1\u5ea6\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5e38\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u3001\u9ad8\u9891\u7684\u63a7\u5236\u884c\u4e3a\uff0c\u8fd9\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u4f1a\u5bfc\u81f4\u80fd\u8017\u8fc7\u9ad8\u548c\u673a\u68b0\u78e8\u635f\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u52a8\u4f5c\u5e73\u6ed1\u6b63\u5219\u5316\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9ad8\u9636\u5bfc\u6570\u60e9\u7f5a\u8fdb\u884c\u52a8\u4f5c\u5e73\u6ed1\u6b63\u5219\u5316\uff0c\u4ece\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u7684\u7406\u8bba\u7406\u89e3\u5230\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u7684\u5b9e\u9645\u9a8c\u8bc1\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u9636\u6570\u5bfc\u6570\u60e9\u7f5a\u7684\u6548\u679c\uff0c\u91cd\u70b9\u5173\u6ce8\u4e09\u9636\u5bfc\u6570\u60e9\u7f5a\uff08\u6025\u52a8\u5ea6\u6700\u5c0f\u5316\uff09\u3002", "result": "\u5728\u56db\u4e2a\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u4e09\u9636\u5bfc\u6570\u60e9\u7f5a\u80fd\u6301\u7eed\u5b9e\u73b0\u6700\u4f18\u5e73\u6ed1\u5ea6\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u6027\u80fd\uff1b\u5728HVAC\u63a7\u5236\u7cfb\u7edf\u5e94\u7528\u4e2d\uff0c\u5e73\u6ed1\u7b56\u7565\u5c06\u8bbe\u5907\u5207\u6362\u51cf\u5c11\u4e8660%\uff0c\u5e26\u6765\u663e\u8457\u8fd0\u8425\u6548\u76ca\u3002", "conclusion": "\u9ad8\u9636\u52a8\u4f5c\u6b63\u5219\u5316\u662f\u8fde\u63a5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u4e0e\u80fd\u6e90\u5173\u952e\u5e94\u7528\u4e2d\u64cd\u4f5c\u7ea6\u675f\u7684\u6709\u6548\u6865\u6881\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5e73\u6ed1\u63a7\u5236\u65b9\u6cd5\u3002"}}
{"id": "2601.02071", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02071", "abs": "https://arxiv.org/abs/2601.02071", "authors": ["Adeshola Okubena", "Yusuf Ali Mohammed", "Moe Elbadawi"], "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations", "comment": null, "summary": "Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e94\u7528\u4e8e\u836f\u72693D\u6253\u5370\u914d\u65b9\u5f00\u53d1\uff0c\u901a\u8fc7\u5fae\u8c03\u56db\u79cdLLM\u67b6\u6784\u57281400\u591a\u4e2aFDM\u914d\u65b9\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8eAPI\u5242\u91cf\u7684\u8f85\u6599\u63a8\u8350\u548c\u4e1d\u6750\u673a\u68b0\u6027\u80fd\u9884\u6d4b\u3002", "motivation": "\u5f53\u524dAI\u9a71\u52a8\u7684\u836f\u72693D\u6253\u5370\u7814\u7a76\u5927\u591a\u5c40\u9650\u4e8e\u72ed\u7a84\u9886\u57df\uff0c\u672a\u80fd\u5168\u9762\u89e3\u51b3\u914d\u65b9\u5f00\u53d1\u4e2d\u7684\u590d\u6742\u6311\u6218\u3002\u968f\u7740\u4eba\u5de5\u901a\u7528\u667a\u80fd\u6982\u5ff5\u7684\u53d1\u5c55\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u901a\u7528\u3001\u7c7b\u4eba\u63a8\u7406\u7684\u7cfb\u7edf\u6765\u63a8\u52a8\u836f\u72693D\u6253\u5370\u7684\u4e2a\u6027\u5316\u5236\u5242\u53d1\u5c55\u3002", "method": "\u7814\u7a76\u5fae\u8c03\u4e86\u56db\u79cdLLM\u67b6\u6784\uff0c\u4f7f\u7528\u5305\u542b1400\u591a\u4e2aFDM\u914d\u65b9\u7684\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5fae\u8c03\u548c\u751f\u6210\u53c2\u6570\u914d\u7f6e\u3002\u91cd\u70b9\u5173\u6ce8\u57fa\u4e8eAPI\u5242\u91cf\u7684\u8f85\u6599\u63a8\u8350\u548c\u4e1d\u6750\u673a\u68b0\u6027\u80fd\u9884\u6d4b\u80fd\u529b\u3002", "result": "Llama2\u6a21\u578b\u5728FDM\u914d\u65b9\u8f85\u6599\u63a8\u8350\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff1b\u6a21\u578b\u9009\u62e9\u548c\u53c2\u6570\u5316\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u8f83\u5c0f\u7684LLM\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u73b0\u8c61\uff1b\u53d1\u73b0\u6807\u51c6LLM\u6307\u6807\u4ec5\u8bc4\u4f30\u8bed\u8a00\u80fd\u529b\u800c\u975e\u914d\u65b9\u53ef\u52a0\u5de5\u6027\uff1b\u751f\u7269\u533b\u5b66\u76f8\u5173\u6570\u636e\u8bad\u7ec3\u7684LLM\u4e0d\u4e00\u5b9a\u4ea7\u751f\u6700\u4f73\u7ed3\u679c\u3002", "conclusion": "\u9700\u8981\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u3001\u8bc4\u4f30\u6307\u6807\u5c40\u9650\u6027\u548c\u6570\u636e\u9002\u7528\u6027\u7b49\u6311\u6218\uff0c\u624d\u80fd\u63a8\u52a8LLM\u8d85\u8d8a\u8bed\u8a00\u80fd\u529b\uff0c\u6210\u4e3a\u836f\u7269\u914d\u65b9\u5f00\u53d1\u4e2d\u53ef\u9760\u7684\u7cfb\u7edf\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u4e2a\u6027\u5316\u5236\u5242\u3002"}}
{"id": "2601.02163", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.02163", "abs": "https://arxiv.org/abs/2601.02163", "authors": ["Chuanrui Hu", "Xingze Gao", "Zuyi Zhou", "Dannong Xu", "Yi Bai", "Xintong Li", "Hui Zhang", "Tong Li", "Chong Zhang", "Lidong Bing", "Yafeng Deng"], "title": "EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning", "comment": "16 pages, 6 figures, 12 tables. Code available at https://github.com/EverMind-AI/EverMemOS", "summary": "Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.", "AI": {"tldr": "EverMemOS\u662f\u4e00\u4e2a\u81ea\u7ec4\u7ec7\u8bb0\u5fc6\u64cd\u4f5c\u7cfb\u7edf\uff0c\u91c7\u7528\u7c7b\u8bb0\u5fc6\u5370\u8ff9\u7684\u751f\u547d\u5468\u671f\u7ba1\u7406\u8ba1\u7b97\u8bb0\u5fc6\uff0c\u901a\u8fc7\u5c06\u5bf9\u8bdd\u6d41\u8f6c\u6362\u4e3a\u8bb0\u5fc6\u5355\u5143\u3001\u7ec4\u7ec7\u6210\u4e3b\u9898\u8bb0\u5fc6\u573a\u666f\uff0c\u5b9e\u73b0\u667a\u80fd\u68c0\u7d22\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u589e\u5f3a\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u957f\u671f\u4ea4\u4e92\u4ee3\u7406\u90e8\u7f72\u65f6\uff0c\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u96be\u4ee5\u7ef4\u6301\u957f\u65f6\u95f4\u8fde\u8d2f\u884c\u4e3a\u3002\u73b0\u6709\u8bb0\u5fc6\u7cfb\u7edf\u901a\u5e38\u5b58\u50a8\u5b64\u7acb\u8bb0\u5f55\u5e76\u68c0\u7d22\u7247\u6bb5\uff0c\u96be\u4ee5\u6574\u5408\u6f14\u53d8\u7684\u7528\u6237\u72b6\u6001\u548c\u89e3\u51b3\u51b2\u7a81\u3002", "method": "\u63d0\u51faEverMemOS\u81ea\u7ec4\u7ec7\u8bb0\u5fc6\u64cd\u4f5c\u7cfb\u7edf\uff1a1) \u60c5\u8282\u75d5\u8ff9\u5f62\u6210\uff1a\u5c06\u5bf9\u8bdd\u6d41\u8f6c\u6362\u4e3a\u8bb0\u5fc6\u5355\u5143\uff0c\u6355\u6349\u60c5\u8282\u75d5\u8ff9\u3001\u539f\u5b50\u4e8b\u5b9e\u548c\u65f6\u95f4\u6709\u754c\u7684\u524d\u77bb\u4fe1\u53f7\uff1b2) \u8bed\u4e49\u6574\u5408\uff1a\u5c06\u8bb0\u5fc6\u5355\u5143\u7ec4\u7ec7\u6210\u4e3b\u9898\u8bb0\u5fc6\u573a\u666f\uff0c\u63d0\u70bc\u7a33\u5b9a\u7684\u8bed\u4e49\u7ed3\u6784\u5e76\u66f4\u65b0\u7528\u6237\u753b\u50cf\uff1b3) \u91cd\u6784\u56de\u5fc6\uff1a\u6267\u884c\u8bb0\u5fc6\u573a\u666f\u5f15\u5bfc\u7684\u667a\u80fd\u68c0\u7d22\uff0c\u4e3a\u4e0b\u6e38\u63a8\u7406\u7ec4\u5408\u5fc5\u8981\u4e14\u5145\u5206\u7684\u4e0a\u4e0b\u6587\u3002", "result": "\u5728LoCoMo\u548cLongMemEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEverMemOS\u5728\u8bb0\u5fc6\u589e\u5f3a\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u5728PersonaMem v2\u4e0a\u7684\u753b\u50cf\u7814\u7a76\u548c\u5b9a\u6027\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u804a\u5929\u5bfc\u5411\u80fd\u529b\uff0c\u5982\u7528\u6237\u753b\u50cf\u548c\u524d\u77bb\u9884\u6d4b\u3002", "conclusion": "EverMemOS\u901a\u8fc7\u81ea\u7ec4\u7ec7\u8bb0\u5fc6\u64cd\u4f5c\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u957f\u671f\u4ea4\u4e92\u4e2d\u7684\u8bb0\u5fc6\u7ba1\u7406\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u8fde\u8d2f\u3001\u667a\u80fd\u7684\u5bf9\u8bdd\u4ee3\u7406\u884c\u4e3a\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.02170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02170", "abs": "https://arxiv.org/abs/2601.02170", "authors": ["Haolang Lu", "Minghui Pan", "Ripeng Li", "Guoshun Nan", "Jialin Zhuang", "Zijie Zhao", "Zhongxiang Sun", "Kun Wang", "Yang Liu"], "title": "Streaming Hallucination Detection in Long Chain-of-Thought Reasoning", "comment": null, "summary": "Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u5e7b\u89c9\u89c6\u4e3a\u6f14\u5316\u6f5c\u72b6\u6001\u800c\u975e\u4e00\u6b21\u6027\u9519\u8bef\u4e8b\u4ef6\uff0c\u5f15\u5165\u7d2f\u79ef\u524d\u7f00\u7ea7\u5e7b\u89c9\u4fe1\u53f7\u6765\u8ffd\u8e2a\u63a8\u7406\u72b6\u6001\u7684\u5168\u5c40\u6f14\u5316\uff0c\u5b9e\u73b0\u6d41\u5f0f\u5e7b\u89c9\u68c0\u6d4b\u3002", "motivation": "\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5176\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u5f80\u5f80\u5fae\u5999\u4e14\u4f1a\u5728\u63a8\u7406\u6b65\u9aa4\u95f4\u4f20\u64ad\u3002\u4f20\u7edf\u65b9\u6cd5\u5c06\u5e7b\u89c9\u89c6\u4e3a\u4e00\u6b21\u6027\u9519\u8bef\u4e8b\u4ef6\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5728\u957f\u94fe\u63a8\u7406\u4e2d\uff0c\u5e7b\u89c9\u5e94\u88ab\u7406\u89e3\u4e3a\u6f14\u5316\u4e2d\u7684\u6f5c\u72b6\u6001\uff0c\u9700\u8981\u5168\u5c40\u89c6\u89d2\u6765\u8ffd\u8e2a\u5176\u6f14\u53d8\u8fc7\u7a0b\u3002", "method": "\u5c06\u6b65\u9aa4\u7ea7\u5e7b\u89c9\u5224\u65ad\u89c6\u4e3a\u5c40\u90e8\u89c2\u6d4b\uff0c\u5f15\u5165\u7d2f\u79ef\u524d\u7f00\u7ea7\u5e7b\u89c9\u4fe1\u53f7\u6765\u8ffd\u8e2a\u6574\u4e2a\u63a8\u7406\u8f68\u8ff9\u4e0a\u7684\u63a8\u7406\u72b6\u6001\u5168\u5c40\u6f14\u5316\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u6d41\u5f0f\u5e7b\u89c9\u68c0\u6d4b\uff0c\u63d0\u4f9b\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u957f\u94fe\u63a8\u7406\u4e2d\u7684\u5e7b\u89c9\u6f14\u5316\uff0c\u63d0\u4f9b\u5b9e\u65f6\u76d1\u63a7\u80fd\u529b\uff0c\u5e76\u4e14\u68c0\u6d4b\u7ed3\u679c\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u5c55\u793a\u5e7b\u89c9\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4f20\u64ad\u8def\u5f84\u3002", "conclusion": "\u5c06\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u5e7b\u89c9\u89c6\u4e3a\u6f14\u5316\u6f5c\u72b6\u6001\u800c\u975e\u4e00\u6b21\u6027\u9519\u8bef\u4e8b\u4ef6\uff0c\u901a\u8fc7\u7d2f\u79ef\u524d\u7f00\u7ea7\u4fe1\u53f7\u8ffd\u8e2a\u5168\u5c40\u6f14\u5316\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u6d41\u5f0f\u5e7b\u89c9\u68c0\u6d4b\uff0c\u4e3a\u957f\u94fe\u63a8\u7406\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u65b0\u7684\u76d1\u63a7\u6846\u67b6\u3002"}}
{"id": "2601.02314", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02314", "abs": "https://arxiv.org/abs/2601.02314", "authors": ["Sourena Khanzadeh"], "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "comment": null, "summary": "As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}. We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \\textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \\textbf{Causal Sensitivity} ($\u03c6$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($\u03c1$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as \"Reasoning Theater\" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faProject Ariadne\u6846\u67b6\uff0c\u4f7f\u7528\u56e0\u679c\u6a21\u578b\u548c\u53cd\u4e8b\u5b9e\u903b\u8f91\u6765\u5ba1\u8ba1LLM\u4ee3\u7406\u63a8\u7406\u7684\u56e0\u679c\u5b8c\u6574\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u4ee3\u7406\u5b58\u5728\"\u56e0\u679c\u89e3\u8026\"\u95ee\u9898\uff0c\u63a8\u7406\u75d5\u8ff9\u53ea\u662f\"\u63a8\u7406\u5267\u573a\"\u800c\u975e\u771f\u5b9e\u51b3\u7b56\u9a71\u52a8\u3002", "motivation": "\u968f\u7740LLM\u4ee3\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u627f\u62c5\u9ad8\u98ce\u9669\u81ea\u4e3b\u51b3\u7b56\u4efb\u52a1\uff0c\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u6210\u4e3a\u5173\u952e\u5b89\u5168\u95ee\u9898\u3002\u867d\u7136\u601d\u7ef4\u94fe\u63d0\u793a\u5141\u8bb8\u751f\u6210\u4eba\u7c7b\u53ef\u8bfb\u7684\u63a8\u7406\u75d5\u8ff9\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u75d5\u8ff9\u662f\u6a21\u578b\u8f93\u51fa\u7684\u771f\u5b9e\u9a71\u52a8\u56e0\u7d20\u8fd8\u662f\u4e8b\u540e\u5408\u7406\u5316\u89e3\u91ca\u3002", "method": "\u63d0\u51faProject Ariadne\u6846\u67b6\uff0c\u5229\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u53cd\u4e8b\u5b9e\u903b\u8f91\u6765\u5ba1\u8ba1\u4ee3\u7406\u63a8\u7406\u7684\u56e0\u679c\u5b8c\u6574\u6027\u3002\u8be5\u65b9\u6cd5\u5bf9\u4e2d\u95f4\u63a8\u7406\u8282\u70b9\u8fdb\u884c\u786c\u5e72\u9884\uff08do-\u6f14\u7b97\uff09\uff0c\u7cfb\u7edf\u6027\u5730\u53cd\u8f6c\u903b\u8f91\u3001\u5426\u5b9a\u524d\u63d0\u548c\u98a0\u5012\u4e8b\u5b9e\u4e3b\u5f20\uff0c\u4ee5\u6d4b\u91cf\u7ec8\u7aef\u7b54\u6848\u7684\u56e0\u679c\u654f\u611f\u6027\u3002", "result": "\u5bf9\u6700\u5148\u8fdb\u6a21\u578b\u7684\u5b9e\u8bc1\u8bc4\u4f30\u63ed\u793a\u4e86\u6301\u7eed\u7684\"\u5fe0\u5b9e\u6027\u5dee\u8ddd\"\u3002\u5b9a\u4e49\u5e76\u68c0\u6d4b\u5230\u4e00\u79cd\u666e\u904d\u7684\u6545\u969c\u6a21\u5f0f\"\u56e0\u679c\u89e3\u8026\"\uff0c\u5728\u4e8b\u5b9e\u548c\u79d1\u5b66\u9886\u57df\u4e2d\u8fdd\u53cd\u5bc6\u5ea6\u9ad8\u8fbe0.77\u3002\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5c3d\u7ba1\u5185\u90e8\u903b\u8f91\u77db\u76fe\uff0c\u4ee3\u7406\u4ecd\u5f97\u51fa\u76f8\u540c\u7ed3\u8bba\uff0c\u8bc1\u660e\u5176\u63a8\u7406\u75d5\u8ff9\u53ea\u662f\"\u63a8\u7406\u5267\u573a\"\uff0c\u800c\u51b3\u7b56\u7531\u6f5c\u5728\u53c2\u6570\u5148\u9a8c\u63a7\u5236\u3002", "conclusion": "\u5f53\u524d\u4ee3\u7406\u67b6\u6784\u672c\u8d28\u4e0a\u5bb9\u6613\u4ea7\u751f\u4e0d\u5fe0\u5b9e\u7684\u89e3\u91ca\uff0c\u63d0\u51faAriadne\u5206\u6570\u4f5c\u4e3a\u5bf9\u9f50\u9648\u8ff0\u903b\u8f91\u4e0e\u6a21\u578b\u884c\u4e3a\u7684\u65b0\u57fa\u51c6\u3002\u8fd9\u8868\u660e\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u786e\u4fddLLM\u4ee3\u7406\u63a8\u7406\u7684\u56e0\u679c\u5fe0\u5b9e\u6027\u3002"}}
{"id": "2601.02346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02346", "abs": "https://arxiv.org/abs/2601.02346", "authors": ["Falcon LLM Team", "Iheb Chaabane", "Puneesh Khanna", "Suhail Mohmad", "Slim Frikha", "Shi Hu", "Abdalgader Abubaker", "Reda Alami", "Mikhail Lubinets", "Mohamed El Amine Seddik", "Hakim Hacid"], "title": "Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling", "comment": null, "summary": "This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.", "AI": {"tldr": "Falcon-H1R\u662f\u4e00\u4e2a7B\u53c2\u6570\u7684\u63a8\u7406\u4f18\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u4e5f\u80fd\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914d\u6216\u8d85\u8d8a2-7\u500d\u5927\u7684SOTA\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u5c0f\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u5b9e\u73b0\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u63a8\u7406\u6027\u80fd\uff0c\u89e3\u51b3\u6a21\u578b\u53c2\u6570\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u9700\u8981\u5e7f\u6cdb\u601d\u7ef4\u94fe\u751f\u6210\u548c\u5e76\u884c\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u7684\u573a\u666f\u63d0\u4f9b\u5b9e\u7528\u7684\u63a8\u7406\u7cfb\u7edf\u9aa8\u5e72\u3002", "method": "\u91c7\u7528\u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u96c6\u548c\u9488\u5bf9\u6027\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u62ec\u9ad8\u6548\u7684\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u6269\u5c55\uff1b\u8bbe\u8ba1\u6df7\u5408\u5e76\u884c\u67b6\u6784\u4ee5\u5b9e\u73b0\u66f4\u5feb\u63a8\u7406\uff1b\u7ed3\u5408DeepConf\u65b9\u6cd5\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u6548\u7387\u3002", "result": "\u5728\u591a\u79cd\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFalcon-H1R-7B\u6a21\u578b\u4e00\u81f4\u5339\u914d\u6216\u8d85\u8d8a2-7\u500d\u5927\u7684\u6700\u5148\u8fdb\u63a8\u7406\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u53c2\u6570\u6548\u7387\u3001\u63a8\u7406\u901f\u5ea6\u3001token\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u4e09\u7ef4\u6548\u7387\u6781\u9650\u3002", "conclusion": "\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u6a21\u578b\u8bad\u7ec3\u548c\u67b6\u6784\u9009\u62e9\uff0c\u7d27\u51d1\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u9ad8\u7ea7\u63a8\u7406\u7cfb\u7edf\u7684\u6269\u5c55\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9aa8\u5e72\u6a21\u578b\u3002"}}
