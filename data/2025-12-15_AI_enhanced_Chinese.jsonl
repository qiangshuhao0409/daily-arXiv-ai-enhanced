{"id": "2512.11195", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11195", "abs": "https://arxiv.org/abs/2512.11195", "authors": ["Zheng Wang", "Cong Ling", "Shi Jin", "Yongming Huang", "Feifei Gao"], "title": "Sphere Decoding Revisited", "comment": null, "summary": "In this paper, the paradigm of sphere decoding (SD) for solving the integer least square problem (ILS) is revisited, where extra degrees of freedom are introduced to exploit the decoding potential. Firstly, the equivalent sphere decoding (ESD) is proposed, which is essentially the same with the classic Fincke-Pohst sphere decoding but characterizes the sphere radius $D>0$ with two new parameters named as initial searching size $K>1$ and deviation factor $\u03c3>0$. By fixing $\u03c3$ properly, we show that given the sphere radius $D\\triangleq\u03c3\\sqrt{2\\ln K}$, the complexity of ESD in terms of the number of visited nodes is upper bounded by $|S|<nK$, thus resulting in an explicit and tractable decoding trade-off solely controlled by $K$. To the best of our knowledge, this is the first time that the complexity of sphere decoding is exactly specified, where considerable decoding potential can be explored from it. After that, two enhancement mechanisms named as normalized weighting and candidate protection are proposed to further upgrade the ESD algorithm. On one hand, given the same setups of $K$ and $\u03c3$, a larger sphere radius is achieved, indicating a better decoding trade-off. On the other hand, the proposed ESD algorithm is generalized, which bridges suboptimal and optimal decoding performance through the flexible choice of $K$. Finally, further performance optimization and complexity reduction with respect to ESD are also derived, and the introduced tractable and flexible decoding trade-off is verified through large-scale MIMO detection.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u7403\u89e3\u7801\u8303\u5f0f\uff0c\u63d0\u51fa\u7b49\u6548\u7403\u89e3\u7801(ESD)\uff0c\u901a\u8fc7\u5f15\u5165\u521d\u59cb\u641c\u7d22\u5927\u5c0fK\u548c\u504f\u5dee\u56e0\u5b50\u03c3\u4e24\u4e2a\u53c2\u6570\uff0c\u9996\u6b21\u7cbe\u786e\u6307\u5b9a\u7403\u89e3\u7801\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u89e3\u7801\u6743\u8861\u3002", "motivation": "\u4f20\u7edf\u7403\u89e3\u7801(Fincke-Pohst\u7b97\u6cd5)\u7684\u590d\u6742\u5ea6\u96be\u4ee5\u7cbe\u786e\u63a7\u5236\u548c\u5206\u6790\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u660e\u786e\u6307\u5b9a\u590d\u6742\u5ea6\u5e76\u63d0\u4f9b\u7075\u6d3b\u89e3\u7801\u6743\u8861\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7b49\u6548\u7403\u89e3\u7801(ESD)\uff0c\u5f15\u5165\u521d\u59cb\u641c\u7d22\u5927\u5c0fK\u548c\u504f\u5dee\u56e0\u5b50\u03c3\u4e24\u4e2a\u53c2\u6570\uff0c\u5c06\u7403\u534a\u5f84D\u5b9a\u4e49\u4e3a\u03c3\u221a(2lnK)\u3002\u901a\u8fc7\u5f52\u4e00\u5316\u52a0\u6743\u548c\u5019\u9009\u4fdd\u62a4\u4e24\u79cd\u589e\u5f3a\u673a\u5236\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\uff0c\u5b9e\u73b0\u4ece\u6b21\u4f18\u5230\u6700\u4f18\u89e3\u7801\u6027\u80fd\u7684\u7075\u6d3b\u8c03\u8282\u3002", "result": "ESD\u7684\u590d\u6742\u5ea6\u4e0a\u754c\u4e3a|S|<nK\uff0c\u9996\u6b21\u7cbe\u786e\u6307\u5b9a\u4e86\u7403\u89e3\u7801\u590d\u6742\u5ea6\u3002\u901a\u8fc7\u8c03\u8282K\u53ef\u4ee5\u5b9e\u73b0\u53ef\u63a7\u7684\u89e3\u7801\u6743\u8861\uff0c\u5728\u5927\u89c4\u6a21MIMO\u68c0\u6d4b\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u7075\u6d3b\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "ESD\u7b97\u6cd5\u9996\u6b21\u5b9e\u73b0\u4e86\u7403\u89e3\u7801\u590d\u6742\u5ea6\u7684\u7cbe\u786e\u63a7\u5236\uff0c\u901a\u8fc7\u53c2\u6570K\u63d0\u4f9b\u7075\u6d3b\u7684\u89e3\u7801\u6743\u8861\uff0c\u4e3a\u5927\u89c4\u6a21MIMO\u68c0\u6d4b\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6027\u80fd\u53ef\u63a7\u7684\u89e3\u7801\u65b9\u6848\u3002"}}
{"id": "2512.11279", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11279", "abs": "https://arxiv.org/abs/2512.11279", "authors": ["Bruno Macchiavello"], "title": "Information-Theoretic Equivalences Across Rate-Distortion, Quantization, and Decoding", "comment": "This is a preprint version. It has not been peer-reviewed", "summary": "We propose a unified mathematical framework for rate-distortion theory, lattice quantization, and modern error-correcting codes by emphasizing their variational and convex-analytic structure. First, we establish a Gibbs-type variational formulation of the rate-distortion function and show that optimal test channels form an exponential family, with Fullback-Leibler divergence acting as a Bregman divergence. This yields a generalized Pythagorean theorem for projections and a Legendre duality that couples distortion constraints with inverse temperature parameters. Second, the reverse water-filling metaphor is extended to distributed lattice quantization, deriving distortion allocation bounds across eigenmodes of conditional covariance matrices. Third, inference is formalized as decoding by showing that belief propagation in LDPC ensembles and polarization in polar codes can be interpreted as recursive variational inference procedures. These results unify compression, quantization, and decoding as convex projections of continuous information onto discrete manifolds. Extensions to neural compression and quantum information are sketched as corollaries, illustrating the universality of the framework. Illustrative connections to other scientific fields are also presented. Finally, complementary numerical examples and scripts are located in the appendix", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c06\u7387\u5931\u771f\u7406\u8bba\u3001\u683c\u70b9\u91cf\u5316\u548c\u73b0\u4ee3\u7ea0\u9519\u7801\u8054\u7cfb\u8d77\u6765\uff0c\u5f3a\u8c03\u5b83\u4eec\u7684\u53d8\u5206\u548c\u51f8\u5206\u6790\u7ed3\u6784\uff0c\u5c55\u793a\u4e86\u538b\u7f29\u3001\u91cf\u5316\u548c\u89e3\u7801\u4f5c\u4e3a\u8fde\u7eed\u4fe1\u606f\u5230\u79bb\u6563\u6d41\u5f62\u7684\u51f8\u6295\u5f71\u7684\u7edf\u4e00\u6027\u3002", "motivation": "\u5efa\u7acb\u7387\u5931\u771f\u7406\u8bba\u3001\u683c\u70b9\u91cf\u5316\u548c\u73b0\u4ee3\u7ea0\u9519\u7801\u4e4b\u95f4\u7684\u7edf\u4e00\u6570\u5b66\u6846\u67b6\uff0c\u63ed\u793a\u5b83\u4eec\u5171\u6709\u7684\u53d8\u5206\u548c\u51f8\u5206\u6790\u7ed3\u6784\uff0c\u4e3a\u4fe1\u606f\u7406\u8bba\u7684\u4e0d\u540c\u5206\u652f\u63d0\u4f9b\u7edf\u4e00\u7684\u89c6\u89d2\u3002", "method": "1. \u5efa\u7acb\u7387\u5931\u771f\u51fd\u6570\u7684Gibbs\u578b\u53d8\u5206\u516c\u5f0f\uff0c\u8bc1\u660e\u6700\u4f18\u6d4b\u8bd5\u4fe1\u9053\u5f62\u6210\u6307\u6570\u65cf\uff1b2. \u5c06\u53cd\u5411\u6ce8\u6c34\u9690\u55bb\u6269\u5c55\u5230\u5206\u5e03\u5f0f\u683c\u70b9\u91cf\u5316\uff1b3. \u5c06LDPC\u7801\u7684\u7f6e\u4fe1\u4f20\u64ad\u548c\u6781\u5316\u7801\u7684\u6781\u5316\u8fc7\u7a0b\u5f62\u5f0f\u5316\u4e3a\u9012\u5f52\u53d8\u5206\u63a8\u7406\u3002", "result": "1. \u5efa\u7acb\u4e86\u7387\u5931\u771f\u51fd\u6570\u7684\u53d8\u5206\u516c\u5f0f\uff0c\u63ed\u793a\u4e86\u6700\u4f18\u6d4b\u8bd5\u4fe1\u9053\u7684\u6307\u6570\u65cf\u7ed3\u6784\uff1b2. \u63a8\u5bfc\u4e86\u6761\u4ef6\u534f\u65b9\u5dee\u77e9\u9635\u7279\u5f81\u6a21\u4e0a\u7684\u5931\u771f\u5206\u914d\u754c\u9650\uff1b3. \u5c55\u793a\u4e86\u7f6e\u4fe1\u4f20\u64ad\u548c\u6781\u5316\u8fc7\u7a0b\u4f5c\u4e3a\u53d8\u5206\u63a8\u7406\u7684\u7edf\u4e00\u89e3\u91ca\uff1b4. \u5c06\u538b\u7f29\u3001\u91cf\u5316\u548c\u89e3\u7801\u7edf\u4e00\u4e3a\u51f8\u6295\u5f71\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u4fe1\u606f\u7406\u8bba\u4e2d\u7684\u538b\u7f29\u3001\u91cf\u5316\u548c\u89e3\u7801\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u4f5c\u4e3a\u8fde\u7eed\u4fe1\u606f\u5230\u79bb\u6563\u6d41\u5f62\u51f8\u6295\u5f71\u7684\u5171\u540c\u672c\u8d28\uff0c\u5e76\u53ef\u4ee5\u6269\u5c55\u5230\u795e\u7ecf\u538b\u7f29\u548c\u91cf\u5b50\u4fe1\u606f\u9886\u57df\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u666e\u9002\u6027\u3002"}}
{"id": "2512.11322", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11322", "abs": "https://arxiv.org/abs/2512.11322", "authors": ["Neri Merhav"], "title": "Refinements and Generalizations of the Shannon Lower Bound via Extensions of the Kraft Inequality", "comment": "25 pages, submitted for publication", "summary": "We derive a few extended versions of the Kraft inequality for lossy compression, which pave the way to the derivation of several refinements and extensions of the well known Shannon lower bound in a variety of instances of rate-distortion coding. These refinements and extensions include sharper bounds for one-to-one codes and $D$-semifaithful codes, a Shannon lower bound for distortion measures based on sliding-window functions, and an individual-sequence counterpart of the Shannon lower bound.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a8\u5bfc\u4e86\u65e0\u635f\u538b\u7f29\u4e2dKraft\u4e0d\u7b49\u5f0f\u7684\u6269\u5c55\u7248\u672c\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u6539\u8fdb\u4e86\u9999\u519c\u4e0b\u754c\uff0c\u5305\u62ec\u4e00\u5bf9\u4e00\u7f16\u7801\u3001D-\u534a\u5fe0\u5b9e\u7f16\u7801\u3001\u6ed1\u52a8\u7a97\u53e3\u5931\u771f\u5ea6\u91cf\u548c\u4e2a\u4f53\u5e8f\u5217\u7684\u9999\u519c\u4e0b\u754c\u3002", "motivation": "\u73b0\u6709\u7684\u9999\u519c\u4e0b\u754c\u5728\u7387\u5931\u771f\u7f16\u7801\u4e2d\u867d\u7136\u91cd\u8981\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u4e0d\u591f\u7d27\u81f4\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u6269\u5c55Kraft\u4e0d\u7b49\u5f0f\u6765\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u7387\u5931\u771f\u4e0b\u754c\uff0c\u4ee5\u8986\u76d6\u66f4\u5e7f\u6cdb\u7684\u7f16\u7801\u573a\u666f\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u4e86\u65e0\u635f\u538b\u7f29\u4e2dKraft\u4e0d\u7b49\u5f0f\u7684\u51e0\u4e2a\u6269\u5c55\u7248\u672c\uff0c\u7136\u540e\u5229\u7528\u8fd9\u4e9b\u6269\u5c55\u7248\u672c\u7cfb\u7edf\u5730\u63a8\u5bfc\u51fa\u9999\u519c\u4e0b\u754c\u7684\u591a\u79cd\u6539\u8fdb\u548c\u6269\u5c55\u5f62\u5f0f\u3002", "result": "\u83b7\u5f97\u4e86\u591a\u4e2a\u7387\u5931\u771f\u4e0b\u754c\u7684\u6539\u8fdb\u7248\u672c\uff1a1\uff09\u4e00\u5bf9\u4e00\u7f16\u7801\u7684\u66f4\u7d27\u81f4\u4e0b\u754c\uff1b2\uff09D-\u534a\u5fe0\u5b9e\u7f16\u7801\u7684\u6539\u8fdb\u4e0b\u754c\uff1b3\uff09\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u51fd\u6570\u7684\u5931\u771f\u5ea6\u91cf\u7684\u9999\u519c\u4e0b\u754c\uff1b4\uff09\u4e2a\u4f53\u5e8f\u5217\u5bf9\u5e94\u7684\u9999\u519c\u4e0b\u754c\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55Kraft\u4e0d\u7b49\u5f0f\uff0c\u8bba\u6587\u6210\u529f\u63a8\u5bfc\u51fa\u9999\u519c\u4e0b\u754c\u7684\u591a\u79cd\u6539\u8fdb\u548c\u6269\u5c55\u5f62\u5f0f\uff0c\u4e3a\u7387\u5931\u771f\u7f16\u7801\u7406\u8bba\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u7406\u8bba\u4e0b\u754c\u5de5\u5177\u3002"}}
{"id": "2512.11169", "categories": ["cs.AI", "cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.11169", "abs": "https://arxiv.org/abs/2512.11169", "authors": ["Akhil S Anand", "Elias Aarekol", "Martin Mziray Dalseg", "Magnus Stalhane", "Sebastien Gros"], "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound", "comment": null, "summary": "Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.", "AI": {"tldr": "\u63d0\u51faCORL\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\uff0c\u5c06\u5206\u652f\u5b9a\u754c\u6c42\u89e3\u7684MILP\u8f6c\u5316\u4e3a\u53ef\u5fae\u968f\u673a\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u5b9e\u9645\u64cd\u4f5c\u6027\u80fd\u800c\u975e\u7cbe\u786e\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edfMILP\u5efa\u6a21\u96be\u4ee5\u51c6\u786e\u8868\u793a\u968f\u673a\u73b0\u5b9e\u95ee\u9898\uff0c\u5bfc\u81f4\u5b9e\u9645\u6027\u80fd\u4e0d\u4f73\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\u3001\u5047\u8bbe\u80fd\u83b7\u53d6\u6700\u4f18\u51b3\u7b56\u771f\u503c\u3001\u4f7f\u7528MILP\u68af\u5ea6\u7684\u4ee3\u7406\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faCORL\u6846\u67b6\uff0c\u5c06\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u6c42\u89e3\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u8f6c\u5316\u4e3a\u53ef\u5fae\u968f\u673a\u7b56\u7565\uff0c\u4f7f\u5176\u4e0e\u5f3a\u5316\u5b66\u4e60\u517c\u5bb9\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\u3002", "result": "\u5728\u7b80\u5355\u7684\u7ec4\u5408\u5e8f\u8d2f\u51b3\u7b56\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86CORL\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u53ef\u884c\u6027\u3002", "conclusion": "CORL\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u4f18\u5316MILP\u65b9\u6848\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u5efa\u6a21\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u76f4\u63a5\u6700\u5927\u5316\u5b9e\u9645\u64cd\u4f5c\u6027\u80fd\uff0c\u4e3a\u7ec4\u5408\u5e8f\u8d2f\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.11331", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11331", "abs": "https://arxiv.org/abs/2512.11331", "authors": ["Chenyiming Wen", "Binpu Shi", "Min Li", "Ming-Min Zhao", "Min-Jian Zhao", "Jiangzhou Wang"], "title": "AMBER: An Adaptive Multimodal Mask Transformer for Beam Prediction with Missing Modalities", "comment": "12 pages, 9 figures", "summary": "With the widespread adoption of millimeter-wave (mmWave) massive multi-input-multi-output (MIMO) in vehicular networks, accurate beam prediction and alignment have become critical for high-speed data transmission and reliable access. While traditional beam prediction approaches primarily rely on in-band beam training, recent advances have started to explore multimodal sensing to extract environmental semantics for enhanced prediction. However, the performance of existing multimodal fusion methods degrades significantly in real-world settings because they are vulnerable to missing data caused by sensor blockage, poor lighting, or GPS dropouts. To address this challenge, we propose AMBER ({A}daptive multimodal {M}ask transformer for {BE}am p{R}ediction), a novel end-to-end framework that processes temporal sequences of image, LiDAR, radar, and GPS data, while adaptively handling arbitrary missing-modality cases. AMBER introduces learnable modality tokens and a missing-modality-aware mask to prevent cross-modal noise propagation, along with a learnable fusion token and multihead attention to achieve robust modality-specific information distillation and feature-level fusion. Furthermore, a class-former-aided modality alignment (CMA) module and temporal-aware positional embedding are incorporated to preserve temporal coherence and ensure semantic alignment across modalities, facilitating the learning of modality-invariant and temporally consistent representations for beam prediction. Extensive experiments on the real-world DeepSense6G dataset demonstrate that AMBER significantly outperforms existing multimodal learning baselines. In particular, it maintains high beam prediction accuracy and robustness even under severe missing-modality scenarios, validating its effectiveness and practical applicability.", "AI": {"tldr": "AMBER\uff1a\u4e00\u79cd\u7528\u4e8e\u6beb\u7c73\u6ce2\u5927\u89c4\u6a21MIMO\u6ce2\u675f\u9884\u6d4b\u7684\u81ea\u9002\u5e94\u591a\u6a21\u6001\u63a9\u7801Transformer\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u56fe\u50cf\u3001LiDAR\u3001\u96f7\u8fbe\u548cGPS\u6570\u636e\uff0c\u5e76\u5728\u4efb\u610f\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u591a\u6a21\u6001\u611f\u77e5\u7684\u6ce2\u675f\u9884\u6d4b\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u4f20\u611f\u5668\u906e\u6321\u3001\u5149\u7167\u4e0d\u826f\u6216GPS\u4e22\u5931\u7b49\u5bfc\u81f4\u7684\u6a21\u6001\u7f3a\u5931\u6570\u636e\u975e\u5e38\u8106\u5f31\u3002", "method": "\u63d0\u51faAMBER\u6846\u67b6\uff0c\u5305\u542b\u53ef\u5b66\u4e60\u7684\u6a21\u6001token\u548c\u7f3a\u5931\u6a21\u6001\u611f\u77e5\u63a9\u7801\u4ee5\u9632\u6b62\u8de8\u6a21\u6001\u566a\u58f0\u4f20\u64ad\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u878d\u5408token\u548c\u591a\u5934\u6ce8\u610f\u529b\u5b9e\u73b0\u9c81\u68d2\u7684\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u84b8\u998f\u548c\u7279\u5f81\u7ea7\u878d\u5408\uff0c\u5e76\u5f15\u5165\u7c7bformer\u8f85\u52a9\u7684\u6a21\u6001\u5bf9\u9f50\u6a21\u5757\u548c\u65f6\u95f4\u611f\u77e5\u4f4d\u7f6e\u5d4c\u5165\u6765\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u8de8\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754cDeepSense6G\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAMBER\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u6a21\u6001\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u4e25\u91cd\u6a21\u6001\u7f3a\u5931\u573a\u666f\u4e0b\u4e5f\u80fd\u4fdd\u6301\u9ad8\u6ce2\u675f\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "AMBER\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5904\u7406\u4efb\u610f\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u591a\u6a21\u6001\u6ce2\u675f\u9884\u6d4b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u73b0\u5b9e\u8f66\u8f7d\u7f51\u7edc\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\u3002"}}
{"id": "2512.11187", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11187", "abs": "https://arxiv.org/abs/2512.11187", "authors": ["Haohui Zhang", "Wouter van Heeswijk", "Xinyu Hu", "Neil Yorke-Smith", "Martijn Mes"], "title": "Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling", "comment": null, "summary": "Online Freight Exchange Systems (OFEX) play a crucial role in modern freight logistics by facilitating real-time matching between shippers and carrier. However, efficient combinatorial bundling of transporation jobs remains a bottleneck. We model the OFEX combinatorial bundling problem as a multi-commodity one-to-one pickup-and-delivery selective traveling salesperson problem (m1-PDSTSP), which optimizes revenue-driven freight bundling under capacity, precedence, and route-length constraints. The key challenge is to couple combinatorial bundle selection with pickup-and-delivery routing under sub-second latency. We propose a learning--accelerated hybrid search pipeline that pairs a Transformer Neural Network-based constructive policy with an innovative Multi-Start Large Neighborhood Search (MSLNS) metaheuristic within a rolling-horizon scheme in which the platform repeatedly freezes the current marketplace into a static snapshot and solves it under a short time budget. This pairing leverages the low-latency, high-quality inference of the learning-based constructor alongside the robustness of improvement search; the multi-start design and plausible seeds help LNS to explore the solution space more efficiently. Across benchmarks, our method outperforms state-of-the-art neural combinatorial optimization and metaheuristic baselines in solution quality with comparable time, achieving an optimality gap of less than 2\\% in total revenue relative to the best available exact baseline method. To our knowledge, this is the first work to establish that a Deep Neural Network-based constructor can reliably provide high-quality seeds for (multi-start) improvement heuristics, with applicability beyond the \\textit{m1-PDSTSP} to a broad class of selective traveling salesperson problems and pickup and delivery problems.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u641c\u7d22\u6846\u67b6\uff0c\u7ed3\u5408Transformer\u795e\u7ecf\u7f51\u7edc\u6784\u9020\u7b56\u7565\u4e0e\u591a\u8d77\u70b9\u5927\u90bb\u57df\u641c\u7d22\uff0c\u89e3\u51b3\u5728\u7ebf\u8d27\u8fd0\u4ea4\u6613\u7cfb\u7edf\u7684\u7ec4\u5408\u6346\u7ed1\u95ee\u9898\uff0c\u5728\u4e9a\u79d2\u5ef6\u8fdf\u5185\u5b9e\u73b0\u9ad8\u8d28\u91cf\u89e3\u3002", "motivation": "\u5728\u7ebf\u8d27\u8fd0\u4ea4\u6613\u7cfb\u7edf\u9700\u8981\u5b9e\u65f6\u5339\u914d\u8d27\u4e3b\u4e0e\u627f\u8fd0\u5546\uff0c\u4f46\u9ad8\u6548\u7ec4\u5408\u6346\u7ed1\u8fd0\u8f93\u4efb\u52a1\u4ecd\u662f\u74f6\u9888\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u4e9a\u79d2\u5ef6\u8fdf\u5185\u540c\u65f6\u5904\u7406\u7ec4\u5408\u6346\u7ed1\u9009\u62e9\u548c\u53d6\u9001\u8d27\u8def\u5f84\u89c4\u5212\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u591a\u5546\u54c1\u4e00\u5bf9\u4e00\u53d6\u9001\u8d27\u9009\u62e9\u6027\u65c5\u884c\u5546\u95ee\u9898(m1-PDSTSP)\u3002\u63d0\u51fa\u5b66\u4e60\u52a0\u901f\u6df7\u5408\u641c\u7d22\u7ba1\u9053\uff1aTransformer\u795e\u7ecf\u7f51\u7edc\u6784\u9020\u7b56\u7565\u751f\u6210\u521d\u59cb\u89e3\uff0c\u7ed3\u5408\u521b\u65b0\u7684\u591a\u8d77\u70b9\u5927\u90bb\u57df\u641c\u7d22\u5143\u542f\u53d1\u5f0f\uff0c\u5728\u6eda\u52a8\u65f6\u57df\u6846\u67b6\u4e0b\u91cd\u590d\u51bb\u7ed3\u5e02\u573a\u5feb\u7167\u5e76\u6c42\u89e3\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\u548c\u5143\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u53ef\u6bd4\u65f6\u95f4\u5185\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u89e3\uff0c\u76f8\u5bf9\u4e8e\u6700\u4f73\u7cbe\u786e\u57fa\u7ebf\u65b9\u6cd5\u7684\u603b\u6536\u5165\u6700\u4f18\u6027\u5dee\u8ddd\u5c0f\u4e8e2%\u3002", "conclusion": "\u9996\u6b21\u8bc1\u660e\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u9020\u5668\u80fd\u591f\u4e3a\uff08\u591a\u8d77\u70b9\uff09\u6539\u8fdb\u542f\u53d1\u5f0f\u63d0\u4f9b\u9ad8\u8d28\u91cf\u79cd\u5b50\u89e3\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8em1-PDSTSP\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u9009\u62e9\u6027\u65c5\u884c\u5546\u95ee\u9898\u548c\u53d6\u9001\u8d27\u95ee\u9898\u3002"}}
{"id": "2512.11094", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11094", "abs": "https://arxiv.org/abs/2512.11094", "authors": ["Shengkai Lin", "Kairui Zhou", "Yibo Wu", "Hongtao Zhang", "Qinwei Yang", "Wei Zhang", "Arvind Krishnamurthy", "Shizhen Zhao"], "title": "SHIFT: An RDMA Failure-Resilient Layer for Distributed Training", "comment": null, "summary": "With gang scheduling in large-scale distributed Large Language Model training, a single network anomaly can propagate and cause complete task failure. The frequency of such anomalies increases with network scale. However, existing fault-tolerance mechanisms, such as checkpointing and runtime resilience methods, primarily operate at the application layer and inevitably cause disruptions in training progress.\n  We propose to address this challenge by introducing fault tolerance at the Remote Direct Memory Access (RDMA) layer and integrating it with existing application-layer techniques. We present SHIFT, a fault-resilient layer over RDMA that enables seamless redirection of RDMA traffic across different intra-host NICs. By allowing applications to continue execution in the presence of network anomalies until the next checkpoint, SHIFT effectively minimizes training progress loss. SHIFT is designed to be application-agnostic, transparent to applications, and low-overhead.\n  Through a carefully designed failure state machine and control flow, unmodified applications such as PyTorch with NCCL can run with RDMA-level fault tolerance. Experimental results demonstrate that SHIFT introduces minimal data path overhead while ensuring application continuity under network failures.", "AI": {"tldr": "SHIFT\uff1a\u5728RDMA\u5c42\u5b9e\u73b0\u5bb9\u9519\uff0c\u901a\u8fc7\u8de8\u4e3b\u673aNIC\u91cd\u5b9a\u5411RDMA\u6d41\u91cf\uff0c\u51cf\u5c11\u5927\u6a21\u578b\u8bad\u7ec3\u4e2d\u7f51\u7edc\u5f02\u5e38\u5bfc\u81f4\u7684\u8bad\u7ec3\u4e2d\u65ad", "motivation": "\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\uff0c\u5355\u4e2a\u7f51\u7edc\u5f02\u5e38\u4f1a\u901a\u8fc7gang scheduling\u4f20\u64ad\u5bfc\u81f4\u6574\u4e2a\u4efb\u52a1\u5931\u8d25\u3002\u73b0\u6709\u5bb9\u9519\u673a\u5236\uff08\u5982\u68c0\u67e5\u70b9\uff09\u5728\u5e94\u7528\u5c42\u8fd0\u884c\uff0c\u4ecd\u4f1a\u9020\u6210\u8bad\u7ec3\u4e2d\u65ad\u3002", "method": "\u5728RDMA\u5c42\u5f15\u5165\u5bb9\u9519\u673a\u5236\uff0c\u8bbe\u8ba1SHIFT\u4f5c\u4e3aRDMA\u4e0a\u7684\u5bb9\u9519\u5c42\uff0c\u652f\u6301\u5728\u4e0d\u540c\u4e3b\u673a\u5185NIC\u95f4\u65e0\u7f1d\u91cd\u5b9a\u5411RDMA\u6d41\u91cf\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6545\u969c\u72b6\u6001\u673a\u548c\u63a7\u5236\u6d41\u5b9e\u73b0\u3002", "result": "SHIFT\u5f15\u5165\u7684\u6570\u636e\u8def\u5f84\u5f00\u9500\u6781\u5c0f\uff0c\u80fd\u5728\u7f51\u7edc\u6545\u969c\u4e0b\u786e\u4fdd\u5e94\u7528\u8fde\u7eed\u6027\uff0c\u672a\u4fee\u6539\u7684PyTorch+NCCL\u5e94\u7528\u53ef\u76f4\u63a5\u8fd0\u884c\u5e76\u83b7\u5f97RDMA\u7ea7\u5bb9\u9519\u80fd\u529b\u3002", "conclusion": "SHIFT\u901a\u8fc7RDMA\u5c42\u5bb9\u9519\u4e0e\u73b0\u6709\u5e94\u7528\u5c42\u6280\u672f\u7ed3\u5408\uff0c\u6700\u5c0f\u5316\u8bad\u7ec3\u8fdb\u5ea6\u635f\u5931\uff0c\u5177\u6709\u5e94\u7528\u65e0\u5173\u3001\u5bf9\u5e94\u7528\u900f\u660e\u3001\u4f4e\u5f00\u9500\u7684\u7279\u70b9\u3002"}}
{"id": "2512.11443", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11443", "abs": "https://arxiv.org/abs/2512.11443", "authors": ["Yuan Li"], "title": "Capacity-Achieving Codes with Inverse-Ackermann-Depth Encoders", "comment": null, "summary": "For any symmetric discrete memoryless channel with input and output alphabet of size $q$, where $q$ is a prime power, we prove that there exist error-correcting codes approaching channel capacity encodable by arithmetic circuits (with weighted addition gates) over $\\mathbb{F}_q$ of size $O(n)$ and depth $\u03b1(n)$, where $\u03b1(n)$ is a version of the inverse Ackermann function. Our results suggest that certain capacity-achieving codes admit highly efficient encoding circuits that are both in linear size and of inverse-Ackermann depth. Our construction composes a linear code with constant rate and relative distance, based on the constructions of G\u00e1l, Hansen, Kouck\u00fd, Pudl\u00e1k, and Viola [IEEE Trans. Inform. Theory 59(10), 2013] and Drucker and Li [COCOON 2023], with an additional layer formed by a disperser graph whose edge weights are chosen uniformly at random.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f\u5bf9\u79f0\u79bb\u6563\u65e0\u8bb0\u5fc6\u4fe1\u9053\uff0c\u5b58\u5728\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u7684\u7ea0\u9519\u7801\uff0c\u8fd9\u4e9b\u7801\u53ef\u4ee5\u901a\u8fc7\u5927\u5c0f\u4e3aO(n)\u3001\u6df1\u5ea6\u4e3a\u9006Ackermann\u51fd\u6570\u7684\u7b97\u672f\u7535\u8def\u8fdb\u884c\u7f16\u7801\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u6784\u5efa\u65e2\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u53c8\u5177\u6709\u9ad8\u6548\u7f16\u7801\u7535\u8def\u7684\u7ea0\u9519\u7801\u3002\u4f20\u7edf\u5bb9\u91cf\u903c\u8fd1\u7801\u901a\u5e38\u7f16\u7801\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u9700\u8981\u63a2\u7d22\u662f\u5426\u5b58\u5728\u540c\u65f6\u5177\u6709\u7ebf\u6027\u5927\u5c0f\u548c\u6781\u6d45\u6df1\u5ea6\u7684\u7f16\u7801\u7535\u8def\u3002", "method": "\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e09\u4e2a\u7ec4\u4ef6\uff1a1) \u57fa\u4e8eG\u00e1l\u7b49\u4eba\u548cDrucker-Li\u6784\u9020\u7684\u5177\u6709\u6052\u5b9a\u7801\u7387\u548c\u76f8\u5bf9\u8ddd\u79bb\u7684\u7ebf\u6027\u7801\uff1b2) \u4f7f\u7528\u968f\u673a\u9009\u62e9\u8fb9\u6743\u91cd\u7684\u6269\u5c55\u56fe\uff1b3) \u901a\u8fc7\u7b97\u672f\u7535\u8def\uff08\u5e26\u52a0\u6743\u52a0\u6cd5\u95e8\uff09\u5728\u6709\u9650\u57dfF_q\u4e0a\u5b9e\u73b0\u7f16\u7801\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u8f93\u5165\u8f93\u51fa\u5b57\u6bcd\u8868\u5927\u5c0f\u4e3a\u7d20\u6570\u5e42q\u7684\u5bf9\u79f0\u79bb\u6563\u65e0\u8bb0\u5fc6\u4fe1\u9053\uff0c\u5b58\u5728\u63a5\u8fd1\u4fe1\u9053\u5bb9\u91cf\u7684\u7ea0\u9519\u7801\uff0c\u5176\u7f16\u7801\u7535\u8def\u5927\u5c0f\u4e3aO(n)\uff0c\u6df1\u5ea6\u4e3a\u9006Ackermann\u51fd\u6570\u03b1(n)\u3002", "conclusion": "\u67d0\u4e9b\u5bb9\u91cf\u903c\u8fd1\u7801\u786e\u5b9e\u5141\u8bb8\u540c\u65f6\u5177\u6709\u7ebf\u6027\u5927\u5c0f\u548c\u9006Ackermann\u6df1\u5ea6\u7684\u6781\u5176\u9ad8\u6548\u7684\u7f16\u7801\u7535\u8def\uff0c\u8fd9\u4e3a\u9ad8\u6548\u7f16\u7801\u5668\u7684\u5b9e\u9645\u5b9e\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.11213", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11213", "abs": "https://arxiv.org/abs/2512.11213", "authors": ["Dongwon Jung", "Peng Shi", "Yi Zhang"], "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration", "comment": null, "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.", "AI": {"tldr": "FutureWeaver\uff1a\u4e00\u4e2a\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u89c4\u5212\u548c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u53cc\u7ea7\u89c4\u5212\u63d0\u5347\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6027\u80fd", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6280\u672f\uff08\u5982\u91cd\u590d\u91c7\u6837\u3001\u81ea\u6211\u9a8c\u8bc1\u3001\u81ea\u6211\u53cd\u601d\uff09\u5728\u5355\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u96be\u4ee5\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u7f3a\u4e4f\u539f\u5219\u6027\u673a\u5236\u6765\u5206\u914d\u8ba1\u7b97\u4ee5\u4fc3\u8fdb\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\uff0c\u5c06\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6269\u5c55\u5230\u534f\u4f5c\u4ea4\u4e92\uff0c\u6216\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u8de8\u667a\u80fd\u4f53\u5206\u914d\u8ba1\u7b97\u3002", "method": "1. \u5f15\u5165\u6a21\u5757\u5316\u534f\u4f5c\uff0c\u5b9a\u4e49\u4e3a\u5c01\u88c5\u53ef\u91cd\u7528\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u53ef\u8c03\u7528\u51fd\u6570\uff1b2. \u901a\u8fc7\u81ea\u6211\u53cd\u601d\u4ece\u8fc7\u53bb\u8f68\u8ff9\u4e2d\u62bd\u8c61\u51fa\u91cd\u590d\u4ea4\u4e92\u6a21\u5f0f\uff0c\u81ea\u52a8\u63a8\u5bfc\u8fd9\u4e9b\u6a21\u5757\uff1b3. \u57fa\u4e8e\u8fd9\u4e9b\u6a21\u5757\uff0c\u91c7\u7528\u53cc\u7ea7\u89c4\u5212\u67b6\u6784\uff0c\u5728\u63a8\u7406\u5f53\u524d\u4efb\u52a1\u72b6\u6001\u7684\u540c\u65f6\u63a8\u6d4b\u672a\u6765\u6b65\u9aa4\uff0c\u4f18\u5316\u8ba1\u7b97\u5206\u914d\u3002", "result": "\u5728\u590d\u6742\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFutureWeaver\u5728\u4e0d\u540c\u9884\u7b97\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u63a8\u7406\u65f6\u4f18\u5316\u4e2d\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6709\u6548\u6027\u3002", "conclusion": "FutureWeaver\u586b\u8865\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\u7684\u539f\u5219\u6027\u673a\u5236\u7a7a\u767d\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u524d\u77bb\u6027\u89c4\u5212\uff0c\u5728\u56fa\u5b9a\u9884\u7b97\u7ea6\u675f\u4e0b\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6027\u80fd\uff0c\u4e3a\u63a8\u7406\u65f6\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2512.11156", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11156", "abs": "https://arxiv.org/abs/2512.11156", "authors": ["Mostafa Abdollahi", "Wenjun Yang", "Jianping Pan"], "title": "BIER-Star: Stateless Geographic Multicast for Scalable Satellite-Terrestrial Integration", "comment": "Accepted to present at IEEE CCNC 2026", "summary": "The rapid expansion of LEO satellite constellations has enabled an integrated terrestrial network and non-terrestrial network (TN-NTN), connecting diverse users such as aircraft, ships, and remote communities. These networks increasingly need a scalable and efficient multicast protocol for critical applications like emergency alerts, large-scale software updates, and real-time broadcasting. However, traditional multicast protocols, such as IP-based multicast and software-defined multicast approaches, introduce significant control overhead and struggle to adapt to the dynamic and mobile nature of satellite topologies. This paper presents BIER-Star, a stateless multicast protocol designed for the integrated TN-NTN. BIER-Star uses a two-layer geospatial gridding scheme (i.e., H3) to encode destinations as Earth- and space-cell identifiers rather than per-terminal addresses. This cell-based abstraction shortens the header bitstring, simplifies forwarding, and eliminates per-flow state and complex signaling. Our simulations indicate that BIER-Star reduces header size versus BIER and avoids geographic path-finding failures seen in greedy methods.", "AI": {"tldr": "BIER-Star\uff1a\u4e00\u79cd\u7528\u4e8e\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u7684\u65e0\u72b6\u6001\u7ec4\u64ad\u534f\u8bae\uff0c\u91c7\u7528\u5730\u7406\u7a7a\u95f4\u7f51\u683c\u7f16\u7801\u76ee\u7684\u5730\uff0c\u51cf\u5c11\u5934\u90e8\u5f00\u9500\u5e76\u9002\u5e94\u536b\u661f\u52a8\u6001\u62d3\u6251", "motivation": "\u968f\u7740LEO\u536b\u661f\u661f\u5ea7\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u9700\u8981\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u7684\u7ec4\u64ad\u534f\u8bae\u6765\u652f\u6301\u7d27\u6025\u8b66\u62a5\u3001\u8f6f\u4ef6\u66f4\u65b0\u7b49\u5173\u952e\u5e94\u7528\u3002\u4f20\u7edfIP\u7ec4\u64ad\u548c\u8f6f\u4ef6\u5b9a\u4e49\u7ec4\u64ad\u5728\u536b\u661f\u52a8\u6001\u62d3\u6251\u4e2d\u5b58\u5728\u63a7\u5236\u5f00\u9500\u5927\u3001\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faBIER-Star\u65e0\u72b6\u6001\u7ec4\u64ad\u534f\u8bae\uff0c\u91c7\u7528\u4e24\u5c42\u5730\u7406\u7a7a\u95f4\u7f51\u683c\u65b9\u6848\uff08H3\uff09\uff0c\u5c06\u76ee\u7684\u5730\u7f16\u7801\u4e3a\u5730\u7403\u548c\u7a7a\u95f4\u5355\u5143\u6807\u8bc6\u7b26\u800c\u975e\u7ec8\u7aef\u5730\u5740\u3002\u8fd9\u79cd\u57fa\u4e8e\u5355\u5143\u7684\u62bd\u8c61\u7f29\u77ed\u4e86\u5934\u90e8\u6bd4\u7279\u4e32\uff0c\u7b80\u5316\u4e86\u8f6c\u53d1\uff0c\u6d88\u9664\u4e86\u6bcf\u6d41\u72b6\u6001\u548c\u590d\u6742\u4fe1\u4ee4\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0cBIER-Star\u76f8\u6bd4BIER\u51cf\u5c11\u4e86\u5934\u90e8\u5927\u5c0f\uff0c\u907f\u514d\u4e86\u8d2a\u5a6a\u65b9\u6cd5\u4e2d\u7684\u5730\u7406\u8def\u5f84\u67e5\u627e\u5931\u8d25\u95ee\u9898\u3002", "conclusion": "BIER-Star\u4e3a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u7ec4\u64ad\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5730\u7406\u7a7a\u95f4\u7f51\u683c\u7f16\u7801\u6709\u6548\u5e94\u5bf9\u536b\u661f\u7f51\u7edc\u7684\u52a8\u6001\u6027\u548c\u79fb\u52a8\u6027\u6311\u6218\u3002"}}
{"id": "2512.11642", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.11642", "abs": "https://arxiv.org/abs/2512.11642", "authors": ["Timm Gilles"], "title": "Stable low-rank matrix recovery from 3-designs", "comment": null, "summary": "We study the recovery of low-rank Hermitian matrices from rank-one measurements obtained by uniform sampling from complex projective 3-designs, using nuclear-norm minimization. This framework includes phase retrieval as a special case via the PhaseLift method. In general, complex projective $t$-designs provide a practical means of partially derandomizing Gaussian measurement models. While near-optimal recovery guarantees are known for $4$-designs, and it is known that $2$-designs do not permit recovery with a subquadratic number of measurements, the case of $3$-designs has remained open. In this work, we close this gap by establishing recovery guarantees for (exact and approximate) $3$-designs that parallel the best-known results for $4$-designs. In particular, we derive bounds on the number of measurements sufficient for stable and robust low-rank recovery via nuclear-norm minimization. Our results are especially relevant in practice, as explicit constructions of $4$-designs are significantly more challenging than those of $3$-designs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ece\u590d\u5c04\u5f713-designs\u7684\u79e9\u4e00\u6d4b\u91cf\u4e2d\u6062\u590d\u4f4e\u79e9\u5384\u7c73\u7279\u77e9\u9635\u7684\u95ee\u9898\uff0c\u4f7f\u7528\u6838\u8303\u6570\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u586b\u8865\u4e863-designs\u6062\u590d\u4fdd\u8bc1\u7684\u7406\u8bba\u7a7a\u767d\u3002", "motivation": "\u867d\u7136\u5df2\u77e54-designs\u53ef\u4ee5\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6062\u590d\u4fdd\u8bc1\uff0c\u4e142-designs\u65e0\u6cd5\u7528\u4e9a\u4e8c\u6b21\u6d4b\u91cf\u5b9e\u73b0\u6062\u590d\uff0c\u4f463-designs\u7684\u60c5\u51b5\u4e00\u76f4\u672a\u89e3\u51b3\u3002\u7531\u4e8e4-designs\u7684\u663e\u5f0f\u6784\u9020\u6bd43-designs\u56f0\u96be\u5f97\u591a\uff0c\u89e3\u51b33-designs\u7684\u6062\u590d\u95ee\u9898\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u610f\u4e49\u3002", "method": "\u4f7f\u7528\u6838\u8303\u6570\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u4ece\u590d\u5c04\u5f713-designs\u7684\u5747\u5300\u91c7\u6837\u4e2d\u83b7\u53d6\u79e9\u4e00\u6d4b\u91cf\uff0c\u7814\u7a76\u4f4e\u79e9\u5384\u7c73\u7279\u77e9\u9635\u7684\u6062\u590d\u95ee\u9898\u3002\u8be5\u6846\u67b6\u901a\u8fc7PhaseLift\u65b9\u6cd5\u5c06\u76f8\u4f4d\u6062\u590d\u4f5c\u4e3a\u7279\u4f8b\u5305\u542b\u5728\u5185\u3002", "result": "\u5efa\u7acb\u4e86\u4e0e4-designs\u6700\u4f73\u5df2\u77e5\u7ed3\u679c\u5e73\u884c\u76843-designs\u6062\u590d\u4fdd\u8bc1\uff0c\u63a8\u5bfc\u4e86\u901a\u8fc7\u6838\u8303\u6570\u6700\u5c0f\u5316\u5b9e\u73b0\u7a33\u5b9a\u548c\u9c81\u68d2\u4f4e\u79e9\u6062\u590d\u6240\u9700\u7684\u6d4b\u91cf\u6570\u91cf\u754c\u9650\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e863-designs\u6062\u590d\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u8bc1\u660e\u4e863-designs\u53ef\u4ee5\u5b9e\u73b0\u4e0e4-designs\u76f8\u5f53\u7684\u6062\u590d\u6027\u80fd\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u7279\u522b\u91cd\u8981\uff0c\u56e0\u4e3a3-designs\u7684\u663e\u5f0f\u6784\u9020\u6bd44-designs\u5bb9\u6613\u5f97\u591a\u3002"}}
{"id": "2512.11270", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11270", "abs": "https://arxiv.org/abs/2512.11270", "authors": ["Hong Je-Gal", "Chan-Bin Yi", "Hyun-Suk Lee"], "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation", "comment": "NeurIPS 2025 Workshop: Multi-Turn Interactions in Large Language Models. 26 pages, 8 figures", "summary": "Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.", "AI": {"tldr": "A-LAMP\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u81ea\u52a8\u8f6c\u6362\u4e3aMDP\u5efa\u6a21\u548c\u8bad\u7ec3\u597d\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u5206\u89e3\u5efa\u6a21\u3001\u7f16\u7801\u548c\u8bad\u7ec3\u4e3a\u53ef\u9a8c\u8bc1\u9636\u6bb5\u6765\u786e\u4fdd\u8bed\u4e49\u5bf9\u9f50\u3002", "motivation": "\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u73b0\u5b9e\u4efb\u52a1\u9700\u8981\u5c06\u975e\u6b63\u5f0f\u63cf\u8ff0\u8f6c\u6362\u4e3a\u6b63\u5f0f\u7684MDP\u3001\u5b9e\u73b0\u53ef\u6267\u884c\u73af\u5883\u5e76\u8bad\u7ec3\u7b56\u7565\u4ee3\u7406\u3002\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u9762\u4e34\u5efa\u6a21\u9519\u8bef\u3001\u8106\u5f31\u4ee3\u7801\u548c\u76ee\u6807\u4e0d\u5bf9\u9f50\u7b49\u6311\u6218\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5e38\u5e38\u963b\u788d\u7b56\u7565\u8bad\u7ec3\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316MDP\u5efa\u6a21\u548c\u7b56\u7565\u751f\u6210\u6846\u67b6(A-LAMP)\uff0c\u5c06\u81ea\u7531\u5f62\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u81ea\u52a8\u8f6c\u6362\u4e3aMDP\u516c\u5f0f\u548c\u8bad\u7ec3\u597d\u7684\u7b56\u7565\u3002\u8be5\u6846\u67b6\u5c06\u5efa\u6a21\u3001\u7f16\u7801\u548c\u8bad\u7ec3\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u9636\u6bb5\uff0c\u786e\u4fdd\u6574\u4e2a\u6d41\u7a0b\u7684\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u7ecf\u5178\u63a7\u5236\u548c\u81ea\u5b9a\u4e49RL\u9886\u57df\u4e2d\uff0cA-LAMP\u59cb\u7ec8\u6bd4\u5355\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u7684\u7b56\u7565\u751f\u6210\u80fd\u529b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u662f\u57fa\u4e8e\u8f83\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u53d8\u4f53\uff0c\u4e5f\u80fd\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002\u5931\u8d25\u5206\u6790\u63ed\u793a\u4e86\u8fd9\u4e9b\u6539\u8fdb\u7684\u539f\u56e0\u3002", "conclusion": "A-LAMP\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u751f\u6210\u73af\u5883\u548c\u7b56\u7565\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u7684\u6700\u4f18\u6027\uff0c\u8bc1\u5b9e\u4e86\u5176\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11230", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11230", "abs": "https://arxiv.org/abs/2512.11230", "authors": ["Antoine Bernard", "Antoine Legrain", "Maroua Ben Attia", "Abdo Shabah"], "title": "Distributed Resource Allocation and Application Deployment in Mesh Edge Networks", "comment": "7 pages, 4 figures, 2 tables, 10 equations, workshop, STWiMob", "summary": "Virtual Network Embedding (VNE) approaches typically assume static or slowly-changing network topologies, but emerging applications require deployment in mobile environments where traditional methods become insufficient. This work extends VNE to constrained mesh networks of mobile edge devices, addressing the unique challenges of rapid topology changes and limited resources. We develop models incorporating device capabilities, connectivity, mobility and energy constraints to evaluate optimal deployment strategies for mobile edge environments. Our approach handles the dynamic nature of mobile networks through three allocation strategies: an integer linear program for optimal allocation, a greedy heuristic for immediate deployment, and a multi-objective genetic algorithm for balanced optimization. Our initial evaluation analyzes application acceptance rates, resource utilization, and latency performance under resource limitations. Results demonstrate improvements over traditional approaches, providing a foundation for VNE deployment in highly mobile environments.", "AI": {"tldr": "\u5c06\u865a\u62df\u7f51\u7edc\u5d4c\u5165\u6269\u5c55\u5230\u79fb\u52a8\u8fb9\u7f18\u8bbe\u5907\u7f51\u7edc\uff0c\u89e3\u51b3\u62d3\u6251\u5feb\u901f\u53d8\u5316\u548c\u8d44\u6e90\u53d7\u9650\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e09\u79cd\u5206\u914d\u7b56\u7565\u5e76\u9a8c\u8bc1\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edfVNE\u65b9\u6cd5\u5047\u8bbe\u9759\u6001\u6216\u7f13\u6162\u53d8\u5316\u7684\u7f51\u7edc\u62d3\u6251\uff0c\u4f46\u65b0\u5174\u79fb\u52a8\u5e94\u7528\u9700\u8981\u5728\u62d3\u6251\u5feb\u901f\u53d8\u5316\u7684\u79fb\u52a8\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u4f20\u7edf\u65b9\u6cd5\u5df2\u4e0d\u9002\u7528", "method": "\u5f00\u53d1\u5305\u542b\u8bbe\u5907\u80fd\u529b\u3001\u8fde\u63a5\u6027\u3001\u79fb\u52a8\u6027\u548c\u80fd\u91cf\u7ea6\u675f\u7684\u6a21\u578b\uff0c\u63d0\u51fa\u4e09\u79cd\u5206\u914d\u7b56\u7565\uff1a\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08\u6700\u4f18\u5206\u914d\uff09\u3001\u8d2a\u5fc3\u542f\u53d1\u5f0f\uff08\u5373\u65f6\u90e8\u7f72\uff09\u548c\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\uff08\u5e73\u8861\u4f18\u5316\uff09", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u5728\u5e94\u7528\u63a5\u53d7\u7387\u3001\u8d44\u6e90\u5229\u7528\u7387\u548c\u5ef6\u8fdf\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e3a\u9ad8\u5ea6\u79fb\u52a8\u73af\u5883\u4e2d\u7684VNE\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u7840", "conclusion": "\u6210\u529f\u5c06VNE\u6269\u5c55\u5230\u79fb\u52a8\u8fb9\u7f18\u7f51\u7edc\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u79fb\u52a8\u7f51\u7edc\u7684\u52a8\u6001\u7279\u6027\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u6027\u80fd\u6539\u8fdb"}}
{"id": "2512.11271", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11271", "abs": "https://arxiv.org/abs/2512.11271", "authors": ["Yuxing Chen", "Basem Suleiman", "Qifan Chen"], "title": "TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning", "comment": "4 pages, 3 figures", "summary": "Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.", "AI": {"tldr": "TriFlow\u662f\u4e00\u4e2a\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u884c\u7a0b\u89c4\u5212\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22-\u89c4\u5212-\u6cbb\u7406\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u548c\u8bed\u8a00\u7075\u6d3b\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ea6\u675f\u6ee1\u8db3\u80fd\u529b\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u884c\u7a0b\u89c4\u5212\u4e2d\u5b58\u5728\u7ea6\u675f\u6ee1\u8db3\u56f0\u96be\u3001\u5de5\u5177\u534f\u8c03\u4e0d\u8db3\u548c\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u7ecf\u5e38\u4ea7\u751f\u4e0d\u53ef\u884c\u6216\u6210\u672c\u8fc7\u9ad8\u7684\u8ba1\u5212\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faTriFlow\u6e10\u8fdb\u5f0f\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u68c0\u7d22\u9636\u6bb5\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u89c4\u5212\u9636\u6bb5\u901a\u8fc7\u89c4\u5219-LLM\u534f\u4f5c\u7ec4\u88c5\u7ea6\u675f\u4e00\u81f4\u7684\u884c\u7a0b\uff0c\u6cbb\u7406\u9636\u6bb5\u8fdb\u884c\u6709\u754c\u8fed\u4ee3\u4f18\u5316\u786e\u4fdd\u5168\u5c40\u53ef\u884c\u6027\u548c\u4e2a\u6027\u5316\u3002", "result": "\u5728TravelPlanner\u548cTripTailor\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5206\u522b\u83b7\u5f9791.1%\u548c97%\u7684\u6700\u7ec8\u901a\u8fc7\u7387\uff0c\u76f8\u6bd4\u5f53\u524dSOTA\u5b9e\u73b0\u4e86\u8d85\u8fc710\u500d\u7684\u8fd0\u884c\u65f6\u6548\u7387\u63d0\u5347\u3002", "conclusion": "TriFlow\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u548c\u8bed\u8a00\u7075\u6d3b\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u771f\u5b9e\u4e16\u754c\u884c\u7a0b\u89c4\u5212\u4e2d\u7684\u7ea6\u675f\u6ee1\u8db3\u3001\u5de5\u5177\u534f\u8c03\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5f00\u653e\u7aef\u7528\u6237\u8bf7\u6c42\u5230\u53ef\u6267\u884c\u884c\u7a0b\u7684\u8f6c\u6362\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11667", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11667", "abs": "https://arxiv.org/abs/2512.11667", "authors": ["Gabriel Almeida", "Jo\u00e3o Paulo Esper", "Cleverson Nahum", "Audebaro Klautau", "Kleber Vieira Cardoso"], "title": "Toward Scalable VR-Cloud Gaming: An Attention-aware Adaptive Resource Allocation Framework for 6G Networks", "comment": null, "summary": "Virtual Reality Cloud Gaming (VR-CG) represents a demanding class of immersive applications, requiring high bandwidth, ultra-low latency, and intelligent resource management to ensure optimal user experience. In this paper, we propose a scalable and QoE-aware multi-stage optimization framework for resource allocation in VR-CG over 6G networks. Our solution decomposes the joint resource allocation problem into three interdependent stages: (i) user association and communication resource allocation; (ii) VR-CG game engine placement with adaptive multipath routing; and (iii) attention-aware scheduling and wireless resource allocation based on motion-to-photon latency. For each stage, we design specialized heuristic algorithms that achieve near-optimal performance while significantly reducing computational time. We introduce a novel user-centric QoE model based on visual attention to virtual objects, guiding adaptive resolution and frame rate selection. A dataset-driven evaluation demonstrates that, when compared against state-of-the-art approaches, our framework improves QoE by up to 50\\%, reduces communication resource usage by 75\\%, and achieves up to 35\\% cost savings, while maintaining an average optimality gap of 5\\%. Our proposed heuristics solve large-scale scenarios in under 0.1 seconds, highlighting their potential for real-time deployment in next-generation mobile networks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9762\u54116G\u7f51\u7edc\u7684VR\u4e91\u6e38\u620f\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u4f18\u5316\u663e\u8457\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\uff0c\u540c\u65f6\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u548c\u6210\u672c\u3002", "motivation": "VR\u4e91\u6e38\u620f\u5bf9\u5e26\u5bbd\u3001\u5ef6\u8fdf\u548c\u8d44\u6e90\u7ba1\u7406\u8981\u6c42\u6781\u9ad8\uff0c\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u4e14QoE\u611f\u77e5\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u5c06\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5206\u89e3\u4e3a\u4e09\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u9636\u6bb5\uff1a\u7528\u6237\u5173\u8054\u4e0e\u901a\u4fe1\u8d44\u6e90\u5206\u914d\u3001VR\u6e38\u620f\u5f15\u64ce\u653e\u7f6e\u4e0e\u81ea\u9002\u5e94\u591a\u8def\u5f84\u8def\u7531\u3001\u57fa\u4e8e\u8fd0\u52a8\u5230\u5149\u5b50\u5ef6\u8fdf\u7684\u6ce8\u610f\u529b\u611f\u77e5\u8c03\u5ea6\u4e0e\u65e0\u7ebf\u8d44\u6e90\u5206\u914d\u3002\u4e3a\u6bcf\u4e2a\u9636\u6bb5\u8bbe\u8ba1\u4e13\u95e8\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u7528\u6237\u4e2d\u5fc3QoE\u6a21\u578b\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cQoE\u63d0\u5347\u9ad8\u8fbe50%\uff0c\u901a\u4fe1\u8d44\u6e90\u4f7f\u7528\u51cf\u5c1175%\uff0c\u6210\u672c\u8282\u7701\u8fbe35%\uff0c\u5e73\u5747\u6700\u4f18\u6027\u5dee\u8ddd\u4ec5\u4e3a5%\u3002\u542f\u53d1\u5f0f\u7b97\u6cd5\u80fd\u57280.1\u79d2\u5185\u89e3\u51b3\u5927\u89c4\u6a21\u573a\u666f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a6G\u7f51\u7edc\u4e2d\u7684VR\u4e91\u6e38\u620f\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u65f6\u90e8\u7f72\u6f5c\u529b\uff0c\u80fd\u663e\u8457\u6539\u5584\u7528\u6237\u4f53\u9a8c\u5e76\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002"}}
{"id": "2512.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11323", "abs": "https://arxiv.org/abs/2512.11323", "authors": ["Jianyi Zhang", "Ziyin Zhou", "Xu Ji", "Shizhao Liu", "Zhangchi Zhao"], "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving", "comment": null, "summary": "Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.", "AI": {"tldr": "\u9996\u6b21\u4e3a\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u8bbe\u8ba1\u7684CAPTCHA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d64\u79cd\u4e3b\u8981\u7c7b\u578b\u548c25\u79cd\u5b50\u7c7b\u578b\uff0c\u6765\u81ea31\u4e2a\u4f9b\u5e94\u5546\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LVLMs\u89e3\u51b3\u9a8c\u8bc1\u7801\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u9a8c\u8bc1\u7801\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5168\u9762\u8986\u76d6\u6240\u6709\u9a8c\u8bc1\u7801\u7c7b\u578b\uff0c\u4e14\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9LVLMs\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u521b\u5efa\u540d\u4e3aCAPTURE\uff08CAPTCHA for Testing Under Real-world Experiments\uff09\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b4\u79cd\u4e3b\u8981\u9a8c\u8bc1\u7801\u7c7b\u578b\u548c25\u79cd\u5b50\u7c7b\u578b\uff0c\u6765\u81ea31\u4e2a\u4f9b\u5e94\u5546\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u7c7b\u522b\u591a\u6837\u6027\u3001\u5927\u89c4\u6a21\u6570\u636e\u548c\u4e13\u95e8\u4e3aLVLMs\u5b9a\u5236\u7684\u6807\u7b7e\u3002", "result": "\u4f7f\u7528\u8be5\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u5f53\u524dLVLMs\u65f6\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u89e3\u51b3\u9a8c\u8bc1\u7801\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u663e\u793a\u51faLVLMs\u5728\u5b9e\u9645\u9a8c\u8bc1\u7801\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "CAPTURE\u57fa\u51c6\u6d4b\u8bd5\u586b\u8865\u4e86\u5148\u524d\u7814\u7a76\u5728\u6570\u636e\u5168\u9762\u6027\u548c\u6807\u7b7e\u9488\u5bf9\u6027\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3aLVLMs\u63d0\u4f9b\u4e86\u591a\u7ef4\u5ea6\u7684\u5168\u9762\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524dLVLMs\u5728\u9a8c\u8bc1\u7801\u89e3\u51b3\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2512.11421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11421", "abs": "https://arxiv.org/abs/2512.11421", "authors": ["Gonca G\u00fcrsun"], "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance", "comment": "Accepted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.\n  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2aLLM\u667a\u80fd\u4f53\u4efb\u52a1\u5b8c\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u5316\u63cf\u8ff0\u73af\u5883\uff0c\u7ed3\u5408\u4efb\u52a1\u5206\u6790\u5668\u3001\u63a8\u7406\u6a21\u5757\u548c\u751f\u6210\u6a21\u5757\uff0c\u786e\u4fdd\u884c\u4e3a\u53ef\u9760\u53ef\u9a8c\u8bc1", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u4efb\u52a1\u4e2d\u884c\u4e3a\u7f3a\u4e4f\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u9700\u8981\u4e00\u79cd\u6846\u67b6\u4f7fLLM\u667a\u80fd\u4f53\u80fd\u5728\u660e\u786e\u5b9a\u4e49\u7684\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u53ef\u4fe1\u884c\u4e3a", "method": "1) \u8f7b\u91cf\u7ea7\u4efb\u52a1\u5206\u6790\u5668\u9009\u62e9\u63a8\u7406\u548c\u751f\u6210\u7b56\u7565\uff1b2) \u63a8\u7406\u6a21\u5757\u5b66\u4e60\u53ef\u9a8c\u8bc1\u7684\u89c2\u5bdf-\u52a8\u4f5c\u6620\u5c04\uff1b3) \u751f\u6210\u6a21\u5757\u901a\u8fc7\u9a8c\u8bc1\u6216\u786e\u5b9a\u6027\u5408\u6210\u786e\u4fdd\u7ea6\u675f\u5408\u89c4\u8f93\u51fa\u3002\u4e09\u4e2a\u7ec4\u4ef6\u5728\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\u4e2d\u534f\u540c\u6f14\u5316", "result": "\u6846\u67b6\u4f7fLLM\u667a\u80fd\u4f53\u80fd\u591f\u5728\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u5316\u63cf\u8ff0\u7684\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u53ef\u4fe1\u884c\u4e3a\uff0c\u5404\u7ec4\u4ef6\u534f\u540c\u6f14\u5316\u4ea7\u751f\u53ef\u9760\u884c\u4e3a", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u4efb\u52a1\u5206\u6790\u3001\u53ef\u9a8c\u8bc1\u63a8\u7406\u548c\u7ea6\u675f\u5408\u89c4\u751f\u6210\uff0c\u89e3\u51b3\u4e86LLM\u5728\u591a\u8f6e\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u4fe1\u7684\u667a\u80fd\u4f53\u884c\u4e3a"}}
{"id": "2512.11426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11426", "abs": "https://arxiv.org/abs/2512.11426", "authors": ["Shuowei Cai", "Yansong Ning", "Hao Liu"], "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints", "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance", "AI": {"tldr": "AgentBalance\u662f\u4e00\u4e2a\u5728\u660e\u786etoken\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u91c7\u7528\"\u5148\u9aa8\u5e72\u540e\u62d3\u6251\"\u8bbe\u8ba1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u76f8\u540c\u9884\u7b97\u4e0b\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728web\u89c4\u6a21\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u6210\u672c\u6548\u76ca\u6210\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u4e3b\u8981\u7ea6\u675f\u3002\u73b0\u6709\u5de5\u4f5c\u5f88\u5c11\u5728\u660e\u786e\u7684token\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u8fdb\u884c\u5efa\u6a21\u548c\u4f18\u5316\uff0c\u5bfc\u81f4\u9884\u7b97\u7ea6\u675f\u65f6\u6210\u672c\u6548\u76ca\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\"\u5148\u9aa8\u5e72\u540e\u62d3\u6251\"\u8bbe\u8ba1\uff1a1) \u9aa8\u5e72\u5bfc\u5411\u7684\u667a\u80fd\u4f53\u751f\u6210\uff1a\u901a\u8fc7LLM\u6c60\u6784\u5efa\u3001\u6c60\u9009\u62e9\u548c\u89d2\u8272-\u9aa8\u5e72\u5339\u914d\u6784\u5efa\u5f02\u6784\u9aa8\u5e72\u667a\u80fd\u4f53\uff1b2) \u81ea\u9002\u5e94MAS\u62d3\u6251\u751f\u6210\uff1a\u901a\u8fc7\u667a\u80fd\u4f53\u8868\u793a\u5b66\u4e60\u3001\u95e8\u63a7\u548c\u5ef6\u8fdf\u611f\u77e5\u62d3\u6251\u5408\u6210\u6307\u5bfc\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3002", "result": "\u5728\u5305\u542b14\u4e2a\u5019\u9009LLM\u9aa8\u5e72\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentBalance\u5728\u5339\u914d\u7684token\u6210\u672c\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe10%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe22%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u6027\u80fd-\u9884\u7b97\u66f2\u7ebf\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684AUC\u3002", "conclusion": "AgentBalance\u662f\u4e00\u4e2a\u6709\u6548\u7684\u6846\u67b6\uff0c\u53ef\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709MAS\u7684\u63d2\u4ef6\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684LLM\uff0c\u5b9e\u73b0\u5b9e\u7528\u7684\u9884\u7b97\u611f\u77e5\u90e8\u7f72\u3002"}}
{"id": "2512.11433", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11433", "abs": "https://arxiv.org/abs/2512.11433", "authors": ["Agustin Martin Picard", "Thibaut Boissin", "Varshini Subhash", "R\u00e9mi Cad\u00e8ne", "Thomas Fel"], "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics", "comment": null, "summary": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u5f53\u524dXAI\u4e2d\u57fa\u4e8e\u57fa\u51c6\u7ebf\u7684\u4fdd\u771f\u5ea6\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u95ee\u9898\uff0c\u4e0d\u540c\u57fa\u51c6\u7ebf\u4f1a\u504f\u5411\u4e0d\u540c\u7684\u5f52\u56e0\u65b9\u6cd5\uff0c\u751a\u81f3\u7ebf\u6027\u6a21\u578b\u4e5f\u4f1a\u5f97\u51fa\u77db\u76fe\u7ed3\u679c\u3002\u4f5c\u8005\u63d0\u51fa\u7406\u60f3\u57fa\u51c6\u7ebf\u5e94\u5177\u5907\u79fb\u9664\u4fe1\u606f\u4e14\u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\u7684\u7279\u6027\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u51c6\u7ebf\u6765\u6539\u8fdb\u8fd9\u4e00\u6743\u8861\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f52\u56e0\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u63d2\u5165\u548c\u5220\u9664\u7b49\u4fdd\u771f\u5ea6\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6307\u6807\u4f9d\u8d56\u4e8e\u57fa\u51c6\u7ebf\u51fd\u6570\u6765\u4fee\u6539\u8f93\u5165\u56fe\u50cf\u50cf\u7d20\uff0c\u800c\u57fa\u51c6\u7ebf\u7684\u9009\u62e9\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u504f\u5411\u67d0\u4e9b\u5f52\u56e0\u65b9\u6cd5\uff0c\u751a\u81f3\u5bfc\u81f4\u77db\u76fe\u7ed3\u679c\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u5e94\u8be5\u4f7f\u7528\u54ea\u4e2a\u57fa\u51c6\u7ebf\uff1f", "method": "\u4f5c\u8005\u9996\u5148\u63d0\u51fa\u7406\u60f3\u57fa\u51c6\u7ebf\u5e94\u6ee1\u8db3\u4e24\u4e2a\u5c5e\u6027\uff1a(1) \u80fd\u591f\u79fb\u9664\u4fe1\u606f\uff0c(2) \u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\u3002\u901a\u8fc7\u6d4b\u8bd5\u73b0\u6709\u57fa\u51c6\u7ebf\u53d1\u73b0\u5b83\u4eec\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e24\u4e2a\u6807\u51c6\uff0c\u5b58\u5728\u6743\u8861\u53d6\u820d\u3002\u7136\u540e\uff0c\u4f5c\u8005\u5229\u7528\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u51c6\u7ebf\uff0c\u80fd\u591f\u79fb\u9664\u4fe1\u606f\u800c\u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u7ebf\u90fd\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u79fb\u9664\u4fe1\u606f\u548c\u4e0d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\u7684\u8981\u6c42\uff0c\u5b58\u5728\u660e\u663e\u7684\u6743\u8861\u5173\u7cfb\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u65b0\u57fa\u51c6\u7ebf\u5728\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u7ebf\uff0c\u80fd\u591f\u66f4\u597d\u5730\u79fb\u9664\u4fe1\u606f\u540c\u65f6\u907f\u514d\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\u56fe\u50cf\u3002", "conclusion": "\u57fa\u51c6\u7ebf\u9009\u62e9\u5bf9XAI\u5f52\u56e0\u65b9\u6cd5\u7684\u8bc4\u4f30\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u73b0\u6709\u57fa\u51c6\u7ebf\u5b58\u5728\u56fa\u6709\u7f3a\u9677\u3002\u901a\u8fc7\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u6784\u5efa\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u51c6\u7ebf\u80fd\u591f\u6539\u8fdb\u8fd9\u4e00\u6743\u8861\uff0c\u4e3a\u66f4\u516c\u5e73\u7684\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u57fa\u51c6\u7ebf\u9009\u62e9\u3002"}}
{"id": "2512.11463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11463", "abs": "https://arxiv.org/abs/2512.11463", "authors": ["Junghwan Lim", "Sungmin Lee", "Dongseok Kim", "Taehyun Kim", "Eunhwan Park", "Jeesoo Lee", "Jeongdoo Lee", "Junhyeok Lee", "Wai Ting Cheung", "Dahye Choi", "Minsu Ha", "Jaeheui Her", "Jaeyeon Huh", "Hanbin Jung", "Changjin Kang", "Beomgyu Kim", "Minjae Kim", "Taewhan Kim", "Youngrok Kim", "Hyukjin Kweon", "Haesol Lee", "Kungyu Lee", "Dongpin Oh", "Yeongjae Park", "Bokki Ryu", "Dongjoo Weon"], "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes", "comment": null, "summary": "We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.", "AI": {"tldr": "Motif-2-12.7B-Reasoning\u662f\u4e00\u4e2a12.7B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u8fbe\u5230\u63a5\u8fd1\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u8bad\u7ec3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u524d\u6cbf\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u540c\u65f6\u5e94\u5bf9\u63a8\u7406\u9002\u5e94\u8fc7\u7a0b\u4e2d\u5e38\u89c1\u7684\u6a21\u578b\u5d29\u6e83\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u3001\u6570\u636e\u548c\u7b97\u6cd5\u4f18\u5316\u7684\u7efc\u5408\u8bad\u7ec3\u65b9\u6848\uff1a1\uff09\u4f7f\u7528\u6df7\u5408\u5e76\u884c\u548c\u5185\u6838\u7ea7\u4f18\u5316\u7684\u5185\u5b58\u9ad8\u6548\u57fa\u7840\u8bbe\u65bd\u652f\u630164K\u4ee4\u724c\u4e0a\u4e0b\u6587\uff1b2\uff09\u4e24\u9636\u6bb5\u76d1\u7763\u5fae\u8c03\u8bfe\u7a0b\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5bf9\u9f50\u7684\u5408\u6210\u6570\u636e\u7f13\u89e3\u5206\u5e03\u4e0d\u5339\u914d\uff1b3\uff09\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7ba1\u9053\uff0c\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u6570\u636e\u8fc7\u6ee4\u548c\u6df7\u5408\u7b56\u7565\u8f68\u8ff9\u91cd\u7528\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "Motif-2-12.7B-Reasoning\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u4e0e\u53c2\u6570\u6570\u91cf\u663e\u8457\u66f4\u5927\u7684\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5728\u73b0\u5b9e\u8ba1\u7b97\u7ea6\u675f\u4e0b\u63d0\u4f9b\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6027\u80fd\u4f18\u5f02\u7684\u5f00\u6e90\u63a8\u7406\u6a21\u578b\uff0c\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u8bad\u7ec3\u84dd\u56fe\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u6269\u5c55\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2512.11469", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11469", "abs": "https://arxiv.org/abs/2512.11469", "authors": ["Pranav Ramanathan", "Thomas Prellberg", "Matthew Lewis", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line", "comment": null, "summary": "The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u4e0eAI\u65b9\u6cd5\u5728No-Three-In-Line\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0ILP\u572819\u00d719\u7f51\u683c\u5185\u53ef\u83b7\u6700\u4f18\u89e3\uff0cPatternBoost\u572814\u00d714\u7f51\u683c\u5185\u5339\u914d\u6700\u4f18\u6027\u80fd\uff0cPPO\u572810\u00d710\u7f51\u683c\u8868\u73b0\u5b8c\u7f8e\u4f46\u572811\u00d711\u5931\u8d25\u3002", "motivation": "No-Three-In-Line\u662f\u7ec4\u5408\u51e0\u4f55\u4e2d\u7684\u8457\u540d\u95ee\u9898\uff0c\u7ecf\u5178\u65b9\u6cd5\u5982\u6574\u6570\u7ebf\u6027\u89c4\u5212(ILP)\u80fd\u4fdd\u8bc1\u6700\u4f18\u89e3\u4f46\u9762\u4e34\u6307\u6570\u7ea7\u6269\u5c55\u95ee\u9898\uff0c\u800c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e3a\u6a21\u5f0f\u8fd1\u4f3c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u9996\u6b21\u5c06PatternBoost\u53d8\u538b\u5668\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60(PPO)\u5e94\u7528\u4e8e\u8be5\u95ee\u9898\uff0c\u5e76\u4e0e\u4f20\u7edfILP\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002ILP\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u6700\u4f18\u89e3\uff0cPatternBoost\u901a\u8fc7\u53d8\u538b\u5668\u5b66\u4e60\u6a21\u5f0f\uff0cPPO\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u89e3\u7a7a\u95f4\u3002", "result": "ILP\u572819\u00d719\u7f51\u683c\u5185\u83b7\u5f97\u53ef\u8bc1\u660e\u7684\u6700\u4f18\u89e3\uff1bPatternBoost\u572814\u00d714\u7f51\u683c\u5185\u5339\u914d\u6700\u4f18\u6027\u80fd\uff0c\u6d4b\u8bd5\u635f\u5931\u51cf\u5c1196%\uff1bPPO\u572810\u00d710\u7f51\u683c\u83b7\u5f97\u5b8c\u7f8e\u89e3\u4f46\u572811\u00d711\u7f51\u683c\u5931\u8d25\uff08\u7ea6\u675f\u8fdd\u53cd\uff09\u3002", "conclusion": "\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u5bf9\u4e8e\u7cbe\u786e\u89e3\u4ecd\u7136\u81f3\u5173\u91cd\u8981\uff0c\u800cAI\u65b9\u6cd5\u5728\u8f83\u5c0f\u5b9e\u4f8b\u4e0a\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u6df7\u5408\u65b9\u6cd5\u4e3a\u6269\u5c55\u5230\u66f4\u5927\u95ee\u9898\u89c4\u6a21\u63d0\u4f9b\u4e86\u6700\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2512.11474", "categories": ["cs.AI", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.11474", "abs": "https://arxiv.org/abs/2512.11474", "authors": ["Kris A. G. Wyckhuys"], "title": "General-purpose AI models can generate actionable knowledge on agroecological crop protection", "comment": "33 pages, 3 figures, 3 tables, 1 supplementary table", "summary": "Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86DeepSeek\u548cChatGPT\u5728\u519c\u4e1a\u751f\u6001\u4f5c\u7269\u4fdd\u62a4\u9886\u57df\u7684\u79d1\u5b66\u77e5\u8bc6\u751f\u6210\u80fd\u529b\uff0c\u53d1\u73b0DeepSeek\u5728\u6587\u732e\u8986\u76d6\u3001\u89e3\u51b3\u65b9\u6848\u6570\u91cf\u548c\u6548\u679c\u8bc4\u4f30\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u4e24\u8005\u90fd\u5b58\u5728\u5e7b\u89c9\u3001\u547d\u540d\u6df7\u6dc6\u7b49\u95ee\u9898\uff0c\u9700\u7ed3\u5408\u4eba\u5de5\u76d1\u7763\u624d\u80fd\u6709\u6548\u652f\u6301\u519c\u573a\u51b3\u7b56\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u6c11\u4e3b\u5316\u79d1\u5b66\u77e5\u8bc6\u548c\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u4fe1\u606f\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u519c\u4e1a\u98df\u54c1\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u519c\u4e1a\u751f\u6001\u4f5c\u7269\u4fdd\u62a4\u9886\u57df\u7684\u79d1\u5b66\u77e5\u8bc6\u751f\u6210\u80fd\u529b\u3002", "method": "\u9488\u5bf99\u79cd\u5168\u7403\u9650\u5236\u6027\u75c5\u866b\u5bb3\u548c\u6742\u8349\uff0c\u8bc4\u4f30DeepSeek\uff08\u57fa\u4e8e\u7f51\u7edc\uff09\u548cChatGPT\u514d\u8d39\u7248\uff08\u975e\u57fa\u4e8e\u7f51\u7edc\uff09\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6570\u636e\u4e00\u81f4\u6027\u548c\u77e5\u8bc6\u5e7f\u5ea6\u3002\u6bd4\u8f83\u4e24\u8005\u7684\u6587\u732e\u8986\u76d6\u8303\u56f4\u3001\u751f\u7269\u63a7\u5236\u5242/\u7ba1\u7406\u65b9\u6848\u6570\u91cf\u3001\u6548\u679c\u8bc4\u4f30\u7b49\u6307\u6807\u3002", "result": "DeepSeek\u5728\u5404\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff1a\u6587\u732e\u8986\u76d6\u8303\u56f4\u662fChatGPT\u76844.8-49.7\u500d\uff0c\u62a5\u544a\u7684\u751f\u7269\u63a7\u5236\u5242/\u7ba1\u7406\u65b9\u6848\u591a1.6-2.4\u500d\uff0c\u6548\u679c\u8bc4\u4f30\u9ad821.6%\uff0c\u5b9e\u9a8c\u5ba4\u5230\u7530\u95f4\u6570\u636e\u4e00\u81f4\u6027\u66f4\u597d\uff0c\u5bf9\u75c5\u866b\u5bb3\u8eab\u4efd\u548c\u7ba1\u7406\u7b56\u7565\u7684\u5f71\u54cd\u8bc4\u4f30\u66f4\u73b0\u5b9e\u3002\u4f46\u4e24\u8005\u90fd\u5b58\u5728\u5e7b\u89c9\u3001\u865a\u6784\u53c2\u8003\u6587\u732e\u3001\u6df7\u6dc6\u65b0\u65e7\u79d1\u5b66\u547d\u540d\u3001\u9057\u6f0f\u5173\u952e\u4fe1\u606f\u7b49\u95ee\u9898\u3002", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e24\u79cdLLM\u90fd\u80fd\u6b63\u786e\u62a5\u544a\u4f4e\u5206\u8fa8\u7387\u7684\u6548\u679c\u8d8b\u52bf\u3002\u7ed3\u5408\u4e25\u683c\u7684\u4eba\u5de5\u76d1\u7763\uff0cLLM\u53ef\u80fd\u6210\u4e3a\u652f\u6301\u519c\u573a\u5c42\u9762\u51b3\u7b56\u548c\u91ca\u653e\u79d1\u5b66\u521b\u9020\u529b\u7684\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2512.11505", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11505", "abs": "https://arxiv.org/abs/2512.11505", "authors": ["Priyam Basu", "Yunfeng Zhang", "Vipul Raheja"], "title": "BAID: A Benchmark for Bias Assessment of AI Detectors", "comment": "Accepted at the workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks at AAAI 2026", "summary": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.", "AI": {"tldr": "BAID\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u6587\u672c\u68c0\u6d4b\u5668\u504f\u89c1\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b\u8d85\u8fc720\u4e07\u6837\u672c\u8986\u76d67\u4e2a\u793e\u4f1a\u8bed\u8a00\u5b66\u7c7b\u522b\uff0c\u53d1\u73b0\u73b0\u6709\u68c0\u6d4b\u5668\u5bf9\u5c11\u6570\u7fa4\u4f53\u6587\u672c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "motivation": "\u73b0\u6709AI\u6587\u672c\u68c0\u6d4b\u5668\u5728\u6559\u80b2\u548c\u5de5\u4f5c\u573a\u666f\u4e2d\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u53ea\u53d1\u73b0\u4e86\u96f6\u6563\u7684\u504f\u89c1\u6848\u4f8b\uff08\u7279\u522b\u662f\u9488\u5bf9\u82f1\u8bed\u5b66\u4e60\u8005\uff09\uff0c\u7f3a\u4e4f\u5bf9\u793e\u4f1a\u8bed\u8a00\u5b66\u56e0\u7d20\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u63d0\u51faBAID\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b7\u4e2a\u4e3b\u8981\u7c7b\u522b\uff08\u4eba\u53e3\u7edf\u8ba1\u3001\u5e74\u9f84\u3001\u6559\u80b2\u6c34\u5e73\u3001\u65b9\u8a00\u3001\u6b63\u5f0f\u7a0b\u5ea6\u3001\u653f\u6cbb\u503e\u5411\u3001\u4e3b\u9898\uff09\u768420\u591a\u4e07\u4e2a\u6837\u672c\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u4fdd\u7559\u539f\u59cb\u5185\u5bb9\u4f46\u53cd\u6620\u7279\u5b9a\u7fa4\u4f53\u5199\u4f5c\u98ce\u683c\u7684\u5408\u6210\u7248\u672c\uff0c\u7136\u540e\u8bc4\u4f304\u4e2a\u5f00\u6e90\u7684\u6700\u5148\u8fdbAI\u6587\u672c\u68c0\u6d4b\u5668\u3002", "result": "\u53d1\u73b0\u68c0\u6d4b\u6027\u80fd\u5b58\u5728\u4e00\u81f4\u7684\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5bf9\u6765\u81ea\u4ee3\u8868\u6027\u4e0d\u8db3\u7fa4\u4f53\u7684\u6587\u672c\u53ec\u56de\u7387\u8f83\u4f4e\uff0c\u8868\u660e\u73b0\u6709AI\u68c0\u6d4b\u5668\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "conclusion": "BAID\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684AI\u68c0\u6d4b\u5668\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5728\u8fd9\u4e9b\u5de5\u5177\u90e8\u7f72\u5230\u516c\u5171\u4f7f\u7528\u4e4b\u524d\u9700\u8981\u8fdb\u884c\u504f\u89c1\u611f\u77e5\u7684\u8bc4\u4f30\u3002"}}
{"id": "2512.11506", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11506", "abs": "https://arxiv.org/abs/2512.11506", "authors": ["Georgios Kaoukis", "Ioannis Aris Koufopoulos", "Psaroudaki Eleni", "Danae Pla Karidi", "Evaggelia Pitoura", "George Papastefanatos", "Panayiotis Tsaparas"], "title": "EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection", "comment": null, "summary": "As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress. To address this challenge, we introduce EmeraldMind, a fact-centric framework integrating a domain-specific knowledge graph with retrieval-augmented generation to automate greenwashing detection. EmeraldMind builds the EmeraldGraph from diverse corporate ESG (environmental, social, and governance) reports, surfacing verifiable evidence, often missing in generic knowledge bases, and supporting large language models in claim assessment. The framework delivers justification-centric classifications, presenting transparent, evidence-backed verdicts and abstaining responsibly when claims cannot be verified. Experiments on a new greenwashing claims dataset demonstrate that EmeraldMind achieves competitive accuracy, greater coverage, and superior explanation quality compared to generic LLMs, without the need for fine-tuning or retraining.", "AI": {"tldr": "EmeraldMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e8b\u5b9e\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u81ea\u52a8\u68c0\u6d4b\u4f01\u4e1a\u7eff\u8272\u6d17\u767d\u884c\u4e3a\u3002", "motivation": "\u968f\u7740AI\u548c\u7f51\u7edc\u4ee3\u7406\u5728\u51b3\u7b56\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u8bbe\u8ba1\u65e2\u80fd\u652f\u6301\u53ef\u6301\u7eed\u53d1\u5c55\u53c8\u80fd\u9632\u8303\u9519\u8bef\u4fe1\u606f\u7684\u667a\u80fd\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u7eff\u8272\u6d17\u767d\uff08\u8bef\u5bfc\u6027\u7684\u4f01\u4e1a\u53ef\u6301\u7eed\u53d1\u5c55\u58f0\u660e\uff09\u5bf9\u73af\u5883\u8fdb\u6b65\u6784\u6210\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f15\u5165EmeraldMind\u6846\u67b6\uff0c\u6784\u5efaEmeraldGraph\u77e5\u8bc6\u56fe\u8c31\uff08\u4ece\u591a\u6837\u5316\u7684\u4f01\u4e1aESG\u62a5\u544a\u4e2d\u63d0\u53d6\uff09\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u58f0\u660e\u8bc4\u4f30\u548c\u900f\u660e\u89e3\u91ca\u3002", "result": "\u5728\u65b0\u7eff\u8272\u6d17\u767d\u58f0\u660e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEmeraldMind\u5728\u51c6\u786e\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u89e3\u91ca\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e14\u65e0\u9700\u5fae\u8c03\u6216\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "EmeraldMind\u6846\u67b6\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7eff\u8272\u6d17\u767d\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2512.11544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11544", "abs": "https://arxiv.org/abs/2512.11544", "authors": ["Yuan Shen", "Xiaojun Wu", "Linghua Yu"], "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives", "comment": "47 pages, 2 figures", "summary": "This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of \"AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)\". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\uff0c\u53d1\u73b0\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u542b\u566a\u58f0\u5197\u4f59\u7684\u60a3\u8005\u4e3b\u8bc9\u65f6\u51fa\u73b0\u529f\u80fd\u7f3a\u9677\uff0c\u63d0\u51fa\"AI-MASLD\"\u6982\u5ff5\uff0c\u8b66\u544aAI\u533b\u7597\u5e94\u7528\u9700\u4eba\u7c7b\u4e13\u5bb6\u76d1\u7763\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u542b\u566a\u58f0\u548c\u5197\u4f59\u7684\u60a3\u8005\u4e3b\u8bc9\u4e2d\u63d0\u53d6\u6838\u5fc3\u533b\u7597\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u9a8c\u8bc1\u5176\u662f\u5426\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u76f8\u5173\u8102\u80aa\u6027\u809d\u75c5\u7684\u529f\u80fd\u8870\u9000\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6807\u51c6\u5316\u533b\u7597\u63a2\u9488\u7684\u6a2a\u65ad\u9762\u5206\u6790\u8bbe\u8ba1\uff0c\u9009\u53d6GPT-4o\u3001Gemini 2.5\u3001DeepSeek 3.1\u548cQwen3-Max\u56db\u79cd\u4e3b\u6d41LLM\uff0c\u4f7f\u7528\u5305\u542b20\u4e2a\u533b\u7597\u63a2\u9488\u7684\u8bc4\u4f30\u7cfb\u7edf\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u6c9f\u901a\u73af\u5883\uff0c\u7531\u4e24\u4f4d\u72ec\u7acb\u4e34\u5e8a\u533b\u751f\u8fdb\u884c\u53cc\u76f2\u53cd\u5411\u8bc4\u5206\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u5747\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u529f\u80fd\u7f3a\u9677\uff0cQwen3-Max\u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0cGemini 2.5\u6700\u5dee\uff1b\u6781\u7aef\u566a\u58f0\u4e0b\u591a\u6570\u6a21\u578b\u529f\u80fd\u5d29\u6e83\uff1bGPT-4o\u5728\u6df1\u9759\u8109\u8840\u6813\u7ee7\u53d1\u80ba\u6813\u585e\u98ce\u9669\u8bc4\u4f30\u4e2d\u51fa\u73b0\u4e25\u91cd\u8bef\u5224\u3002", "conclusion": "\u9996\u6b21\u5b9e\u8bc1\u786e\u8ba4LLM\u5904\u7406\u4e34\u5e8a\u4fe1\u606f\u65f6\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7684\u7279\u5f81\uff0c\u63d0\u51fa\"AI-MASLD\"\u521b\u65b0\u6982\u5ff5\uff0c\u5f3a\u8c03\u5f53\u524dLLM\u5fc5\u987b\u4f5c\u4e3a\u4eba\u7c7b\u4e13\u5bb6\u76d1\u7763\u4e0b\u7684\u8f85\u52a9\u5de5\u5177\u4f7f\u7528\u3002"}}
{"id": "2512.11588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11588", "abs": "https://arxiv.org/abs/2512.11588", "authors": ["Gregor von Laszewski", "Wesley Brewer", "Jeyan Thiyagalingam", "Juri Papay", "Armstrong Foundjem", "Piotr Luszczek", "Murali Emani", "Shirley V. Moore", "Vijay Janapa Reddi", "Matthew D. Sinclair", "Sebastian Lobentanzer", "Sujata Goswami", "Benjamin Hawks", "Marco Colombo", "Nhan Tran", "Christine R. Kirkpatrick", "Abdulkareem Alsudais", "Gregg Barrett", "Tianhao Li", "Kirsten Morehouse", "Shivaram Venkataraman", "Rutwik Jain", "Kartik Mathur", "Victor Lu", "Tejinder Singh", "Khojasteh Z. Mirza", "Kongtao Chen", "Sasidhar Kunapuli", "Gavin Farrell", "Renato Umeton", "Geoffrey C. Fox"], "title": "AI Benchmark Democratization and Carpentry", "comment": "43 pages, 2 figures, 7 tables", "summary": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.\n  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.\n  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAI\u57fa\u51c6\u6d4b\u8bd5\u9700\u8981\u4ece\u9759\u6001\u8f6c\u5411\u52a8\u6001\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9AI\u5feb\u901f\u53d1\u5c55\u548c\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\uff0c\u5e76\u5021\u5bfc\u5efa\u7acb\"AI\u57fa\u51c6\u6d4b\u8bd5\u5de5\u827a\"\u7684\u6559\u80b2\u4f53\u7cfb\u3002", "motivation": "\u5f53\u524dAI\u57fa\u51c6\u6d4b\u8bd5\u9762\u4e34\u591a\u91cd\u6311\u6218\uff1a\u6a21\u578b\u67b6\u6784\u5feb\u901f\u6f14\u8fdb\u3001\u89c4\u6a21\u6269\u5927\u3001\u6570\u636e\u96c6\u66f4\u65b0\u548c\u90e8\u7f72\u73af\u5883\u591a\u6837\u5316\uff0c\u4f7f\u5f97\u8bc4\u4f30\u6210\u4e3a\u79fb\u52a8\u76ee\u6807\u3002\u9759\u6001\u57fa\u51c6\u5bb9\u6613\u88ab\u5927\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\uff0c\u5bfc\u81f4\u57fa\u51c6\u7ed3\u679c\u4e0e\u5b9e\u9645\u6027\u80fd\u8131\u8282\u3002\u9700\u8981\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u6765\u89e3\u51b3\u8d44\u6e90\u9700\u6c42\u9ad8\u3001\u4e13\u4e1a\u786c\u4ef6\u8bbf\u95ee\u6709\u9650\u3001\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u7f3a\u4e4f\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u81ea\u9002\u5e94\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u6301\u7eed\u6f14\u8fdb\u7684\u6a21\u578b\u3001\u66f4\u65b0\u6570\u636e\u548c\u5f02\u6784\u5e73\u53f0\uff0c\u540c\u65f6\u4fdd\u6301\u900f\u660e\u5ea6\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u5021\u5bfc\u5efa\u7acb\"AI\u57fa\u51c6\u6d4b\u8bd5\u5de5\u827a\"\u6559\u80b2\u4f53\u7cfb\uff0c\u901a\u8fc7\u6280\u672f\u521b\u65b0\u548c\u7cfb\u7edf\u5316\u6559\u80b2\u76f8\u7ed3\u5408\uff0c\u57f9\u517b\u57fa\u51c6\u8bbe\u8ba1\u548c\u4f7f\u7528\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002", "result": "\u8bc6\u522b\u4e86\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u7684\u5173\u952e\u969c\u788d\uff1a\u9ad8\u8d44\u6e90\u9700\u6c42\u3001\u4e13\u4e1a\u786c\u4ef6\u8bbf\u95ee\u9650\u5236\u3001\u57fa\u51c6\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u7f3a\u4e4f\u3001\u7ed3\u679c\u4e0e\u5e94\u7528\u9886\u57df\u5173\u8054\u4e0d\u786e\u5b9a\u6027\u3002\u5f3a\u8c03\u57fa\u51c6\u6d4b\u8bd5\u9700\u8981\u652f\u6301\u5e94\u7528\u76f8\u5173\u7684\u6bd4\u8f83\uff0c\u4e3a\u4e0d\u540c\u573a\u666f\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u6307\u5bfc\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u9876\u7ea7\u786c\u4ef6\u4e0a\u7684\u5cf0\u503c\u6027\u80fd\u3002", "conclusion": "\u52a8\u6001\u5305\u5bb9\u7684\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u4e8e\u786e\u4fdd\u8bc4\u4f30\u8ddf\u4e0aAI\u53d1\u5c55\u6b65\u4f10\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u652f\u6301\u8d1f\u8d23\u4efb\u3001\u53ef\u590d\u73b0\u548c\u53ef\u8bbf\u95ee\u7684AI\u90e8\u7f72\u3002\u793e\u533a\u52aa\u529b\u53ef\u4ee5\u4e3a\"AI\u57fa\u51c6\u6d4b\u8bd5\u5de5\u827a\"\u63d0\u4f9b\u57fa\u7840\uff0c\u901a\u8fc7\u6280\u672f\u9769\u65b0\u548c\u6559\u80b2\u4f53\u7cfb\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u57fa\u51c6\u6d4b\u8bd5\u7684\u6c11\u4e3b\u5316\u3002"}}
{"id": "2512.11653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11653", "abs": "https://arxiv.org/abs/2512.11653", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Causal Inference in Energy Demand Prediction", "comment": null, "summary": "Energy demand prediction is critical for grid operators, industrial energy\n  consumers, and service providers. Energy demand is influenced by multiple\n  factors, including weather conditions (e.g. temperature, humidity, wind\n  speed, solar radiation), and calendar information (e.g. hour of day and\n  month of year), which further affect daily work and life schedules. These\n  factors are causally interdependent, making the problem more complex than\n  simple correlation-based learning techniques satisfactorily allow for. We\n  propose a structural causal model that explains the causal relationship\n  between these variables. A full analysis is performed to validate our causal\n  beliefs, also revealing important insights consistent with prior studies.\n  For example, our causal model reveals that energy demand responds to\n  temperature fluctuations with season-dependent sensitivity. Additionally, we\n  find that energy demand exhibits lower variance in winter due to the\n  decoupling effect between temperature changes and daily activity patterns.\n  We then build a Bayesian model, which takes advantage of the causal insights\n  we learned as prior knowledge. The model is trained and tested on unseen\n  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on\n  the test set. The model also demonstrates strong robustness, as the\n  cross-validation across two years of data yields an average MAPE of 3.88 percent.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u56e0\u679c\u6d1e\u5bdf\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u52303.84% MAPE\u7684\u5148\u8fdb\u6027\u80fd", "motivation": "\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u5bf9\u7535\u7f51\u8fd0\u8425\u5546\u3001\u5de5\u4e1a\u80fd\u6e90\u6d88\u8d39\u8005\u548c\u670d\u52a1\u63d0\u4f9b\u5546\u81f3\u5173\u91cd\u8981\u3002\u80fd\u6e90\u9700\u6c42\u53d7\u5929\u6c14\u6761\u4ef6\uff08\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u98ce\u901f\u3001\u592a\u9633\u8f90\u5c04\uff09\u548c\u65e5\u5386\u4fe1\u606f\uff08\u5c0f\u65f6\u3001\u6708\u4efd\uff09\u7b49\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u8fd9\u4e9b\u56e0\u7d20\u56e0\u679c\u76f8\u4e92\u4f9d\u8d56\uff0c\u6bd4\u7b80\u5355\u7684\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5b66\u4e60\u6280\u672f\u66f4\u590d\u6742", "method": "\u63d0\u51fa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u89e3\u91ca\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u901a\u8fc7\u5b8c\u6574\u5206\u6790\u9a8c\u8bc1\u56e0\u679c\u4fe1\u5ff5\u3002\u7136\u540e\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u5c06\u5b66\u5230\u7684\u56e0\u679c\u6d1e\u5bdf\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u672a\u89c1\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u52303.84% MAPE\u7684\u5148\u8fdb\u6027\u80fd\uff0c\u8de8\u4e24\u5e74\u6570\u636e\u7684\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747MAPE\u4e3a3.88%\uff0c\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\u3002\u56e0\u679c\u5206\u6790\u53d1\u73b0\uff1a1\uff09\u80fd\u6e90\u9700\u6c42\u5bf9\u6e29\u5ea6\u6ce2\u52a8\u7684\u54cd\u5e94\u5177\u6709\u5b63\u8282\u4f9d\u8d56\u6027\u654f\u611f\u6027\uff1b2\uff09\u51ac\u5b63\u80fd\u6e90\u9700\u6c42\u65b9\u5dee\u8f83\u4f4e\uff0c\u56e0\u4e3a\u6e29\u5ea6\u53d8\u5316\u4e0e\u65e5\u5e38\u6d3b\u52a8\u6a21\u5f0f\u89e3\u8026", "conclusion": "\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u56e0\u679c\u5173\u7cfb\uff0c\u5c06\u56e0\u679c\u6d1e\u5bdf\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u6784\u5efa\u7684\u8d1d\u53f6\u65af\u6a21\u578b\u5b9e\u73b0\u4e86\u5148\u8fdb\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u56e0\u679c\u5206\u6790\u65b9\u6cd5"}}
{"id": "2512.11682", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11682", "abs": "https://arxiv.org/abs/2512.11682", "authors": ["Tim Cofala", "Christian Kalfar", "Jingge Xiao", "Johanna Schrader", "Michelle Tang", "Wolfgang Nejdl"], "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition", "comment": "7 pages, 3 figures", "summary": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.", "AI": {"tldr": "TxAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u7684AI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fed\u4ee3\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6574\u5408\u591a\u79cd\u751f\u7269\u533b\u5b66\u5de5\u5177\uff0c\u5728CURE-Bench\u6311\u6218\u8d5b\u4e2d\u56e0\u6539\u8fdb\u5de5\u5177\u68c0\u7d22\u7b56\u7565\u83b7\u5f97\u6027\u80fd\u63d0\u5347\uff0c\u8363\u83b7\u5f00\u653e\u79d1\u5b66\u5353\u8d8a\u5956\u3002", "motivation": "\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u662f\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u9700\u8981AI\u7cfb\u7edf\u5728\u60a3\u8005\u7279\u5f81\u3001\u75be\u75c5\u8fc7\u7a0b\u548c\u836f\u7269\u4e4b\u95f4\u8fdb\u884c\u590d\u6742\u4ea4\u4e92\u7684\u7a33\u5065\u591a\u6b65\u63a8\u7406\u3002\u533b\u7597\u5e94\u7528\u5177\u6709\u4e25\u683c\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u8981\u6c42\u63a8\u7406\u8f68\u8ff9\u548c\u5de5\u5177\u8c03\u7528\u5e8f\u5217\u7684\u51c6\u786e\u6027\uff0c\u8fd9\u4fc3\u4f7f\u9700\u8981\u5c06token\u7ea7\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u884c\u4e3a\u4f5c\u4e3a\u663e\u5f0f\u76d1\u7763\u4fe1\u53f7\u8fdb\u884c\u8bc4\u4f30\u3002", "method": "TxAgent\u91c7\u7528\u5fae\u8c03\u7684Llama-3.1-8B\u6a21\u578b\uff0c\u901a\u8fc7\u8fed\u4ee3\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u52a8\u6001\u751f\u6210\u548c\u6267\u884c\u51fd\u6570\u8c03\u7528\uff0c\u8bbf\u95ee\u7edf\u4e00\u7684\u751f\u7269\u533b\u5b66\u5de5\u5177\u5957\u4ef6(ToolUniverse)\uff0c\u6574\u5408FDA Drug API\u3001OpenTargets\u548cMonarch\u8d44\u6e90\u4ee5\u786e\u4fdd\u83b7\u53d6\u6700\u65b0\u7684\u6cbb\u7597\u4fe1\u606f\u3002", "result": "\u8be5\u5de5\u4f5c\u5206\u6790\u4e86\u51fd\u6570(\u5de5\u5177)\u8c03\u7528\u7684\u68c0\u7d22\u8d28\u91cf\u5982\u4f55\u5f71\u54cd\u6574\u4f53\u6a21\u578b\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u6539\u8fdb\u5de5\u5177\u68c0\u7d22\u7b56\u7565\u5b9e\u73b0\u7684\u6027\u80fd\u63d0\u5347\u3002\u5728CURE-Bench NeurIPS 2025\u6311\u6218\u8d5b\u4e2d\uff0c\u8be5\u5de5\u4f5c\u56e0\u8bc4\u4f30\u6cbb\u7597\u63a8\u7406\u7cfb\u7edf\u7684\u6b63\u786e\u6027\u3001\u5de5\u5177\u5229\u7528\u548c\u63a8\u7406\u8d28\u91cf\u800c\u83b7\u5f97\u5f00\u653e\u79d1\u5b66\u5353\u8d8a\u5956\u3002", "conclusion": "TxAgent\u901a\u8fc7\u8fed\u4ee3RAG\u548c\u7edf\u4e00\u751f\u7269\u533b\u5b66\u5de5\u5177\u5957\u4ef6\uff0c\u4e3a\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u63d0\u4f9b\u4e86\u7a33\u5065\u7684AI\u6307\u5bfc\u7cfb\u7edf\u3002\u6539\u8fdb\u7684\u5de5\u5177\u68c0\u7d22\u7b56\u7565\u5bf9\u63d0\u5347\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u8be5\u5de5\u4f5c\u5728CURE-Bench\u6311\u6218\u8d5b\u4e2d\u7684\u8868\u73b0\u9a8c\u8bc1\u4e86\u5176\u5728\u6cbb\u7597\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
