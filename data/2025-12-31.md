<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 50]
- [cs.IT](#cs.IT) [Total: 14]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Impact of Sociality Regimes on Quality of Service and Energy Efficiency in Cell-Free MIMO Networks](https://arxiv.org/abs/2512.22127)
*Ala Eddine Nouali,Mohamed Sana,Jean-Paul Jamont*

Main category: cs.NI

TL;DR: 该论文研究无蜂窝网络中用户设备(UE)与接入点(AP)集群之间的社交性匹配问题，提出基于延迟接受和早期接受算法的匹配方案，以平衡服务质量与能效。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝架构中，用户中心化聚类是确保网络可扩展性的实用方法，但为每个UE选择最优AP集群面临挑战。需要考虑有限的前传和处理能力，同时动态调整以提升能效并满足QoS要求，这些实体之间存在利益冲突。

Method: 将问题建模为具有外部性的多对多社交匹配博弈，其中连接基于双方团队的社交性制度（自私、平等主义或利他主义）。提出两种基于延迟接受和早期接受匹配游戏的新算法。

Result: 数值结果显示UE及其AP集群采用的社交性制度对UE的QoS满意度和能效有显著影响。当双方实体都采用平等主义制度时，能获得最佳性能权衡。

Conclusion: 社交性制度在平衡无蜂窝网络中QoS和能效方面起关键作用。平等主义制度为UE和AP集群提供了最佳折衷方案，所提出的匹配算法能有效解决这一优化问题。

Abstract: The cell-free architecture represents a significant advancement in network design, where each User Equipment (UE) is served by a group of distributed Access Points (APs), aimed at delivering uniformly high data rates to UEs across all locations. To ensure network scalability, user-centric clustering (UCC) has emerged as a practical approach, wherein only a selected subset of preferred APs jointly serves each UE. Forming the optimal cluster of APs for each UE is a challenging task, particularly when limited fronthaul and processing capabilities of both APs and UEs are considered. This challenge is exacerbated by the need for dynamic adjustments to enhance energy efficiency while meeting quality of service (QoS) requirements, which introduces conflicting interests between these entities. In this paper, we investigate the sociality regime of UEs and their clusters of APs, characterizing their intra-team cooperation as either selfish, egalitarian, or altruistic. These sociality regimes are crucial in achieving a balance between QoS and energy efficiency per UE. We address this problem by modeling it as a many-to-many social matching game with externalities, where connections can be established based on the sociality regime of both teams. To solve this, we introduce two novel algorithms based on Deferred Acceptance (DA) and Early Acceptance (EA) matching games. Numerical results show the significant impact of the sociality regime adopted by UEs and their clusters of APs on UE's QoS satisfaction and energy efficiency, with the egalitarian regime adopted by both entities proving the best performance trade-off.

</details>


### [2] [A Lightweight Coordinate-Conditioned Diffusion Approach for 6G C-V2X Radio Environment Maps](https://arxiv.org/abs/2512.22535)
*Liu Cao,Zhaoyu Liu,Dongyu Wei,Yuan Yang,Yukun Pan,Lyutianyang Zhang*

Main category: cs.NI

TL;DR: 提出CCDDPM模型，利用历史车辆信号强度数据预测任意坐标的6G V2X无线电环境地图，提升通信稳定性


<details>
  <summary>Details</summary>
Motivation: 6G C-V2X通信中，发射车辆缺乏动态高保真无线电环境地图，容易受到物理层问题影响，需要一种能预测任意坐标无线电环境的方法

Method: 采用坐标条件去噪扩散概率模型(CCDDPM)，将发射车辆坐标编码为高斯先验，通过轻量级双通道条件U-Net架构与高斯噪声融合，生成无线电环境地图

Result: 预测的无线电环境地图在统计特性和结构上与真实地图高度匹配，相比其他生成式AI方法具有更好的稳定性和性能

Conclusion: CCDDPM能够快速生成与场景一致的任意坐标无线电环境地图，支持更高效的6G C-V2X通信，减少发射车辆的物理层问题

Abstract: Transmitter vehicles that broadcast 6G Cellular Vehicle-to-Everything (C-V2X)-based messages, e.g., Basic Safety Messages (BSMs), are prone to be impacted by PHY issues due to the lack of dynamic high-fidelity Radio Environment Map (REM) with dynamic location variation. This paper explores a lightweight diffusion-based generative approach, the Coordinate-Conditioned Denoising Diffusion Probabilistic Model (CCDDPM), that leverages the signal intensity-based 6G V2X Radio Environment Map (REM) from limited historical transmitter vehicles in a specific region, to predict the REMs for a transmitter vehicle with arbitrary coordinates across the same region. The transmitter vehicle coordinate is encoded as a smooth Gaussian prior and fused with the Gaussian noise through a lightweight two-channel conditional U-Net architecture. We demonstrate that the predicted REM closely matches the statistics and structure of ground-truth REM while exhibiting the improved stability and over other widely applied generative AI approaches. The resulting predictor enables rapid and scenario-consistent REM with arbitrary transmitter coordinates, which thereby supports more efficient 6G C-V2X communications where transmitter vehicles are less likely to suffer from the PHY issues.

</details>


### [3] [A Novel Approach for a Smart IoMT-Based BAN for an Old Home Healthcare Monitoring System Using Starlink](https://arxiv.org/abs/2512.22553)
*Shermin Sultana Setu,Mst. Amena Akter Pinky,Md. Abdul Awal,Sheekar Banerjee,Ishtiak Al Mamoon*

Main category: cs.NI

TL;DR: 提出基于Starlink卫星网络的医疗物联网老年监护系统，通过QoS技术优先传输关键健康数据，在偏远地区实现可靠远程监护


<details>
  <summary>Details</summary>
Motivation: 当前老年护理系统面临长期护理资源不足和医疗提供者间沟通不畅的挑战，特别是在偏远和欠发达地区，需要更可靠的远程监护解决方案

Method: 设计Starlink辅助的IoMT医疗模型，监测ECG、体温、心脏病指标和跌倒检测等关键生物医学参数，采用FQ-CoDel与DSCP标记的QoS技术优先传输紧急数据

Result: NS-3仿真结果显示，该系统在吞吐量、延迟和可靠性方面优于现有解决方案，证明Starlink作为远程医疗通信工具的潜力

Conclusion: 该研究提供了一个可扩展、可复制的卫星辅助医疗系统框架，优先考虑QoS性能和改善老年患者护理，为未来卫星医疗系统奠定基础

Abstract: The rapid evolution of the Internet of Medical Things (IoMT) technology has become a transformative force in modern healthcare, particularly in elderly patient management. The current elderly care system faces significant challenges, including insufficient long-term care resources and poor communication between healthcare providers. To address this limitation, this study introduces a novel Starlink-assisted IOMT-based elderly healthcare model designed to improve remote patient monitoring and communication reliability. This proposal system focused on a monitoring system of key biomedical parameters such as electrocardiogram (ECG), body temperature, heart attack indicators, and a fall detection alert system. Performance is evaluated using the network simulator (NS-3) to assess its effectiveness in remote and underserved regions. Physiological data collected from patients are transmitted through a local communication hub and forwarded over a Low Earth Orbit (LEO) satellite link to a medical center. Based on Quality of Service (QoS) technology that combines Flow Queuing (FQ) with Controlled Delay (CoDel) with Differentiated Services Code Point (DSCP) marking. This approach prioritizes critical health data for faster transmission while allocating lower priority to non-urgent information. This architecture is entirely wireless, allowing continuous monitoring, real-time alerts, and secure data storage for medical analysis. The simulation results demonstrate that the proposed Starlink-enabled IOMT system outperforms existing solutions in terms of throughput, latency, and reliability. The findings highlight Starlink's potential as a robust and high-performance telehealth communication tool. In addition, this study provides a scalable and reproducible framework for future satellite-assisted healthcare systems that prioritize quality of service (QoS) performance and improved elderly patient care.

</details>


### [4] [Cyber Resilience in Next-Generation Networks: Threat Landscape, Theoretical Foundations, and Design Paradigms](https://arxiv.org/abs/2512.22721)
*Junaid Farooq,Quanyan Zhu*

Main category: cs.NI

TL;DR: 本书深入探讨了SDN、NFV、O-RAN和云原生架构等网络技术演进如何重塑关键基础设施的运营和威胁面，提出了重新概念化和重新设计弹性机制以应对这些挑战的跨学科框架。


<details>
  <summary>Details</summary>
Motivation: 网络系统的演进（SDN、NFV、O-RAN、云原生架构）正在重新定义关键基础设施的运营环境和威胁面，需要重新概念化和重新设计弹性机制来应对这些变革带来的多方面挑战。

Method: 采用跨学科方法，通过六章结构：首先调查当代风险格局，识别新兴威胁；然后建立严格的弹性定义和评估框架；核心部分深入探讨零信任架构、博弈论威胁建模、自愈设计等先进范式，特别关注人工智能（强化学习、大语言模型）在动态威胁响应和自主网络控制中的作用。

Result: 本书提供了全面的弹性重新概念化框架，超越了传统的鲁棒性和容错性，涵盖了适应性、预期性和回顾性机制，为应对网络演进带来的新威胁提供了理论和实践指导。

Conclusion: 网络技术的演进要求从根本上重新思考弹性设计，需要结合先进的安全范式（如零信任）和人工智能技术来构建能够应对动态、复杂威胁环境的自适应网络系统。

Abstract: The evolution of networked systems, driven by innovations in software-defined networking (SDN), network function virtualization (NFV), open radio access networks (O-RAN), and cloud-native architectures, is redefining both the operational landscape and the threat surface of critical infrastructures. This book offers an in-depth, interdisciplinary examination of how resilience must be re-conceptualized and re-engineered to address the multifaceted challenges posed by these transformations.
  Structured across six chapters, this book begins by surveying the contemporary risk landscape, identifying emerging cyber, physical, and AI-driven threats, and analyzing their implications for scalable, heterogeneous network environments. It then establishes rigorous definitions and evaluation frameworks for resilience, going beyond robustness and fault-tolerance to address adaptive, anticipatory, and retrospective mechanisms across diverse application domains.
  The core of the book delves into advanced paradigms and practical strategies for resilience, including zero trust architectures, game-theoretic threat modeling, and self-healing design principles. A significant portion is devoted to the role of artificial intelligence, especially reinforcement learning and large language models (LLMs), in enabling dynamic threat response, autonomous network control, and multi-agent coordination under uncertainty.

</details>


### [5] [Hierarchical Decision Mamba Meets Agentic AI: A Novel Approach for RAN Slicing in 6G](https://arxiv.org/abs/2512.23502)
*Md Arafat Habib,Medhat Elsayed,Majid Bavand,Pedro Enrique Iturria Rivera,Yigit Ozcan,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 提出基于大型语言模型和分层决策Mamba控制器的Agentic AI框架，用于6G RAN切片管理，通过自然语言理解运营商意图并协调多个代理，在吞吐量、时延等关键指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAN切片资源调度方法主要依赖静态映射和SLA转换，缺乏自然语言理解与协调决策的集成，无法有效处理运营商意图的灵活解释和执行。

Method: 提出Agentic AI框架，包含基于大型语言模型的超级代理，用于理解运营商自然语言意图并转化为可执行目标；采用分层决策Mamba控制器协调切片间、切片内和自愈代理。

Result: 相比基于Transformer和奖励驱动的基线方法，该框架在吞吐量、小区边缘性能、时延等关键性能指标上均表现出持续改进。

Conclusion: Agentic AI框架通过自然语言理解与分层决策的集成，为6G RAN切片管理提供了更灵活、高效的解决方案，能够更好地满足切片特定的SLA要求。

Abstract: Radio Access Network (RAN) slicing enables multiple logical networks to exist on top of the same physical infrastructure by allocating resources to distinct service groups, where radio resource scheduling plays a key role in ensuring compliance with slice-specific Service-Level Agreements (SLAs). Existing configuration-based or intent-driven Reinforcement Learning (RL) approaches usually rely on static mappings and SLA conversions. The current literature does not integrate natural language understanding with coordinated decision-making. To address these limitations, we propose an Agentic AI framework for 6G RAN slicing, driven by a super agent built using Hierarchical Decision Mamba (HDM) controllers and a Large Language Model (LLM). The super agent interprets operator intents and translates them into actionable goals using the LLM, which are used by HDM to coordinate inter-slice, intra-slice, and self-healing agents. Compared to transformer-based and reward-driven baselines, the proposed Agentic AI framework demonstrates consistent improvements across key performance indicators, including higher throughput, improved cell-edge performance, and reduced latency across different slices.

</details>


### [6] [Distributed Accountability in Democracy: Using MANETs and DTNs in the Face of Acts of Questionable Legality](https://arxiv.org/abs/2512.23653)
*Mathew Schmidheiser,Milena Radenkovic*

Main category: cs.NI

TL;DR: 比较Epidemic和Wave DTN路由协议在敏感通信场景下的表现，分析各自优势情境


<details>
  <summary>Details</summary>
Motivation: 研究DTN路由协议在现实敏感场景中的应用，特别是当个体需要就潜在非法行为进行通信时，不同协议的行为表现

Method: 通过分析Epidemic和Wave两种DTN路由协议在敏感通信场景下的行为特征，识别各自优势情境

Result: 发现在某些情况下Epidemic协议更有利，而在另一些情况下Wave协议更有利，具体取决于通信场景的特点

Conclusion: 不同DTN路由协议在敏感通信场景中各有优劣，需要根据具体情境选择，并提出了未来研究的多个方向

Abstract: In this paper, we explore the behavior of the Epidemic and Wave DTN routing protocols in a realistic setting where individuals may wish to communicate with others for support regarding an act of questionable legality. We identify situations where using the Epidemic routing protocol may be more advantageous in such a scenario, and situations where using the Wave routing protocol may be more advantageous instead. We discuss other aspects of our findings in detail and suggest multiple approaches to future works.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Bidirectional RAG: Safe Self-Improving Retrieval-Augmented Generation Through Multi-Stage Validation](https://arxiv.org/abs/2512.22199)
*Teja Chinthala*

Main category: cs.AI

TL;DR: Bidirectional RAG 是一种新型检索增强生成架构，通过验证后的高质量生成响应实现安全的语料库扩展，使RAG系统能够从用户交互中学习进化。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用静态知识库，无法从用户交互中学习和进化，限制了系统的持续改进能力。需要一种既能扩展知识库又避免幻觉污染的安全机制。

Method: 提出Bidirectional RAG架构，采用多阶段接受层，结合基于NLI的蕴含验证、归因检查和新颖性检测，确保高质量生成内容的安全写回，实现语料库的验证扩展。

Result: 在四个数据集（Natural Questions, TriviaQA, HotpotQA, Stack Overflow）上，Bidirectional RAG平均覆盖率达到40.58%，几乎是标准RAG（20.33%）的两倍，同时比朴素写回方法少添加72%的文档（140 vs 500）。

Conclusion: 研究表明，在严格验证机制控制下，自改进的RAG系统是可行且安全的，为RAG系统从部署中学习提供了实用路径。

Abstract: Retrieval-Augmented Generation RAG systems enhance large language models by grounding responses in external knowledge bases, but conventional RAG architectures operate with static corpora that cannot evolve from user interactions. We introduce Bidirectional RAG, a novel RAG architecture that enables safe corpus expansion through validated write back of high quality generated responses. Our system employs a multi stage acceptance layer combining grounding verification (NLI based entailment, attribution checking, and novelty detection to prevent hallucination pollution while enabling knowledge accumulation. Across four datasets Natural Questions, TriviaQA, HotpotQA, Stack Overflow with three random seeds 12 experiments per system, Bidirectional RAG achieves 40.58% average coverage nearly doubling Standard RAG 20.33% while adding 72% fewer documents than naive write back 140 vs 500. Our work demonstrates that self improving RAG is feasible and safe when governed by rigorous validation, offering a practical path toward RAG systems that learn from deployment.

</details>


### [8] [Emergent Persuasion: Will LLMs Persuade Without Being Prompted?](https://arxiv.org/abs/2512.22201)
*Vincent Chang,Thee Ho,Sunishchal Dev,Kevin Zhu,Shi Feng,Kellin Pelrine,Matthew Kowal*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型在监督微调后，即使没有明确提示，也会对有害话题进行说服，而内部激活引导则不会可靠地增加这种无提示说服倾向。


<details>
  <summary>Details</summary>
Motivation: 随着对话式AI系统的广泛应用，AI对人类观点和信念产生了前所未有的影响。先前研究主要关注滥用威胁模型（即恶意行为者要求LLM进行说服），但本研究旨在探究模型在何种情况下会未经明确提示就进行说服，这对于评估新兴说服风险至关重要。

Method: 研究无提示说服的两种场景：(1)通过内部激活引导使模型沿特定人格特质方向调整；(2)通过监督微调使模型展现相同特质。使用包含良性话题的通用说服数据集进行监督微调，然后测试模型在争议性和有害话题上的说服倾向。

Result: 研究发现：1) 向说服相关或不相关特质进行内部激活引导不会可靠增加模型的无提示说服倾向；2) 监督微调确实会增加模型的无提示说服倾向；3) 仅使用良性话题的通用说服数据集进行监督微调后，模型对争议性和有害话题的说服倾向也会提高。

Conclusion: 监督微调可能导致模型出现新兴的有害说服能力，即使训练数据只包含良性话题。这表明无提示的有害说服风险确实存在，需要进一步研究以评估和缓解这种风险。

Abstract: With the wide-scale adoption of conversational AI systems, AI are now able to exert unprecedented influence on human opinion and beliefs. Recent work has shown that many Large Language Models (LLMs) comply with requests to persuade users into harmful beliefs or actions when prompted and that model persuasiveness increases with model scale. However, this prior work looked at persuasion from the threat model of $\textit{misuse}$ (i.e., a bad actor asking an LLM to persuade). In this paper, we instead aim to answer the following question: Under what circumstances would models persuade $\textit{without being explicitly prompted}$, which would shape how concerned we should be about such emergent persuasion risks. To achieve this, we study unprompted persuasion under two scenarios: (i) when the model is steered (through internal activation steering) along persona traits, and (ii) when the model is supervised-finetuned (SFT) to exhibit the same traits. We showed that steering towards traits, both related to persuasion and unrelated, does not reliably increase models' tendency to persuade unprompted, however, SFT does. Moreover, SFT on general persuasion datasets containing solely benign topics admits a model that has a higher propensity to persuade on controversial and harmful topics--showing that emergent harmful persuasion can arise and should be studied further.

</details>


### [9] [GamiBench: Evaluating Spatial Reasoning and 2D-to-3D Planning Capabilities of MLLMs with Origami Folding Tasks](https://arxiv.org/abs/2512.22207)
*Ryan Spencer,Roey Yaari,Ritvik Vemavarapu,Joyce Yang,Steven Ngo,Utkarsh Sharma*

Main category: cs.AI

TL;DR: GamiBench：一个通过折纸任务评估多模态大语言模型空间推理能力的基准，包含372个折痕图案和3个视觉问答任务，引入新的诊断指标来衡量模型处理复杂折叠的能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在空间推理方面存在不足，而当前基准主要关注静态图像或最终输出，未能考虑空间推理的序列性和视角依赖性特点。需要专门的基准来评估MLLM在空间推理和2D到3D规划方面的能力。

Method: 创建GamiBench基准，包含186个常规和186个不可能2D折痕图案及其对应的3D折叠形状，从6个不同视角生成。设计3个VQA任务：预测3D折叠配置、区分有效视角、检测不可能图案。引入新的诊断指标：视角一致性(VC)和不可能折叠选择率(IFSR)。

Result: 实验表明，即使是GPT-5和Gemini-2.5-Pro等领先模型在单步空间理解任务上也表现不佳，揭示了当前MLLM在空间推理方面的局限性。

Conclusion: GamiBench为评估MLLM的几何理解和空间推理能力建立了标准化框架，填补了现有基准的空白，有助于推动MLLM在空间推理方面的发展。

Abstract: Multimodal large language models (MLLMs) are proficient in perception and instruction-following, but they still struggle with spatial reasoning: the ability to mentally track and manipulate objects across multiple views and over time. Spatial reasoning is a key component of human intelligence, but most existing benchmarks focus on static images or final outputs, failing to account for the sequential and viewpoint-dependent nature of this skill. To close this gap, we introduce GamiBench, a benchmark designed to evaluate spatial reasoning and 2D-to-3D planning in MLLMs through origami-inspired folding tasks. GamiBench includes 186 regular and 186 impossible 2D crease patterns paired with their corresponding 3D folded shapes, produced from six distinct viewpoints across three visual question-answering (VQA) tasks: predicting 3D fold configurations, distinguishing valid viewpoints, and detecting impossible patterns. Unlike previous benchmarks that assess only final predictions, GamiBench holistically evaluates the entire reasoning process--measuring cross-view consistency, physical feasibility through impossible-fold detection, and interpretation of intermediate folding steps. It further introduces new diagnostic metrics--viewpoint consistency (VC) and impossible fold selection rate (IFSR)--to measure how well models handle folds of varying complexity. Our experiments show that even leading models such as GPT-5 and Gemini-2.5-Pro struggle on single-step spatial understanding. These contributions establish a standardized framework for evaluating geometric understanding and spatial reasoning in MLLMs. Dataset and code: https://github.com/stvngo/GamiBench.

</details>


### [10] [SANet: A Semantic-aware Agentic AI Networking Framework for Cross-layer Optimization in 6G](https://arxiv.org/abs/2512.22579)
*Yong Xiao,Xubo Li,Haoran Zhou,Yingyu Li,Yayu Gao,Guangming Shi,Ping Zhang,Marwan Krunz*

Main category: cs.AI

TL;DR: 本文提出SANet，一种用于无线网络的语义感知AgentNet架构，通过多智能体多目标优化实现用户语义目标推断与网络层智能体自动分配，采用模型分区共享框架降低计算开销。


<details>
  <summary>Details</summary>
Motivation: AgentNet作为新型AI原生网络范式，具有自主决策和环境适应能力，但协作智能体可能存在目标冲突问题。需要解决多智能体多目标优化，在分散式框架中寻找帕累托最优解。

Method: 提出SANet架构，包含语义感知用户目标推断和网络层智能体自动分配；设计模型分区共享(MoPS)框架，将大模型划分为共享和智能体特定部分；提出两种分散式优化算法；开发基于RAN和核心网络的硬件原型。

Result: 实验结果显示，所提框架性能提升达14.61%，仅需最先进算法44.37%的FLOPs；理论分析表明存在优化、泛化和冲突误差的三方权衡；开发了开源硬件原型实现三层网络交互。

Conclusion: SANet通过语义感知和多智能体优化有效解决了AgentNet中的目标冲突问题，在显著降低计算开销的同时提升了网络性能，为AI原生网络提供了可行的分散式优化方案。

Abstract: Agentic AI networking (AgentNet) is a novel AI-native networking paradigm in which a large number of specialized AI agents collaborate to perform autonomous decision-making, dynamic environmental adaptation, and complex missions. It has the potential to facilitate real-time network management and optimization functions, including self-configuration, self-optimization, and self-adaptation across diverse and complex environments. This paper proposes SANet, a novel semantic-aware AgentNet architecture for wireless networks that can infer the semantic goal of the user and automatically assign agents associated with different layers of the network to fulfill the inferred goal. Motivated by the fact that AgentNet is a decentralized framework in which collaborating agents may generally have different and even conflicting objectives, we formulate the decentralized optimization of SANet as a multi-agent multi-objective problem, and focus on finding the Pareto-optimal solution for agents with distinct and potentially conflicting objectives. We propose three novel metrics for evaluating SANet. Furthermore, we develop a model partition and sharing (MoPS) framework in which large models, e.g., deep learning models, of different agents can be partitioned into shared and agent-specific parts that are jointly constructed and deployed according to agents' local computational resources. Two decentralized optimization algorithms are proposed. We derive theoretical bounds and prove that there exists a three-way tradeoff among optimization, generalization, and conflicting errors. We develop an open-source RAN and core network-based hardware prototype that implements agents to interact with three different layers of the network. Experimental results show that the proposed framework achieved performance gains of up to 14.61% while requiring only 44.37% of FLOPs required by state-of-the-art algorithms.

</details>


### [11] [Toward Equitable Recovery: A Fairness-Aware AI Framework for Prioritizing Post-Flood Aid in Bangladesh](https://arxiv.org/abs/2512.22210)
*Farjana Yesmin,Romana Akter*

Main category: cs.AI

TL;DR: 提出一个公平感知的AI框架，用于孟加拉国洪水后援助分配，通过对抗性去偏技术减少系统性偏见，确保援助基于真实需求而非历史分配模式。


<details>
  <summary>Details</summary>
Motivation: 发展中国家灾后援助分配存在系统性偏见，弱势地区常被忽视，延续历史不平等。孟加拉国作为洪水频发国家，需要更公平的援助分配机制。

Method: 使用对抗性去偏模型，结合梯度反转层学习偏置不变表示，将医疗AI中的公平感知表示学习技术应用于灾害管理。基于2022年孟加拉国洪水真实数据（影响720万人，损失4.055亿美元）。

Result: 在11个地区的87个upazilas上测试，统计奇偶差异减少41.6%，区域公平差距降低43.2%，预测精度保持良好（R平方=0.784 vs 基线0.811）。模型生成可操作的优先级排名。

Conclusion: 算法公平技术可有效应用于人道主义背景，为决策者提供更公平的灾害恢复策略工具，确保援助基于真实需求而非历史偏见。

Abstract: Post-disaster aid allocation in developing nations often suffers from systematic biases that disadvantage vulnerable regions, perpetuating historical inequities. This paper presents a fairness-aware artificial intelligence framework for prioritizing post-flood aid distribution in Bangladesh, a country highly susceptible to recurring flood disasters. Using real data from the 2022 Bangladesh floods that affected 7.2 million people and caused 405.5 million US dollars in damages, we develop an adversarial debiasing model that predicts flood vulnerability while actively removing biases against marginalized districts and rural areas. Our approach adapts fairness-aware representation learning techniques from healthcare AI to disaster management, employing a gradient reversal layer that forces the model to learn bias-invariant representations. Experimental results on 87 upazilas across 11 districts demonstrate that our framework reduces statistical parity difference by 41.6 percent, decreases regional fairness gaps by 43.2 percent, and maintains strong predictive accuracy (R-squared=0.784 vs baseline 0.811). The model generates actionable priority rankings ensuring aid reaches the most vulnerable populations based on genuine need rather than historical allocation patterns. This work demonstrates how algorithmic fairness techniques can be effectively applied to humanitarian contexts, providing decision-makers with tools to implement more equitable disaster recovery strategies.

</details>


### [12] [With Great Capabilities Come Great Responsibilities: Introducing the Agentic Risk & Capability Framework for Governing Agentic AI Systems](https://arxiv.org/abs/2512.22211)
*Shaun Khoo,Jessica Foo,Roy Ka-Wei Lee*

Main category: cs.AI

TL;DR: 本文提出了Agentic Risk & Capability (ARC)框架，用于帮助组织识别、评估和缓解智能体AI系统的风险，通过能力中心视角分析风险源并提供技术控制措施。


<details>
  <summary>Details</summary>
Motivation: 智能体AI系统具有自主行动能力（如代码执行、网络交互、文件修改），带来了重大机遇和新型风险，对组织治理提出了挑战，需要系统性的方法来识别、评估和缓解这些不断演化的风险。

Method: 提出了ARC框架，采用能力中心视角分析智能体AI系统，识别三个主要风险源（组件、设计、能力），建立风险源与具体风险、技术控制之间的清晰联系，并提供结构化实施方法。

Result: 开发了一个开放源码的技术治理框架，帮助组织在快速创新的同时确保智能体AI系统的安全、可靠和负责任部署，提供了可适应的方法论来应对智能体AI的复杂性。

Conclusion: ARC框架为组织提供了一个稳健且可适应的治理方法，能够在确保智能体AI系统安全、可靠和负责任部署的同时，支持快速有效的创新。

Abstract: Agentic AI systems present both significant opportunities and novel risks due to their capacity for autonomous action, encompassing tasks such as code execution, internet interaction, and file modification. This poses considerable challenges for effective organizational governance, particularly in comprehensively identifying, assessing, and mitigating diverse and evolving risks. To tackle this, we introduce the Agentic Risk \& Capability (ARC) Framework, a technical governance framework designed to help organizations identify, assess, and mitigate risks arising from agentic AI systems. The framework's core contributions are: (1) it develops a novel capability-centric perspective to analyze a wide range of agentic AI systems; (2) it distills three primary sources of risk intrinsic to agentic AI systems - components, design, and capabilities; (3) it establishes a clear nexus between each risk source, specific materialized risks, and corresponding technical controls; and (4) it provides a structured and practical approach to help organizations implement the framework. This framework provides a robust and adaptable methodology for organizations to navigate the complexities of agentic AI, enabling rapid and effective innovation while ensuring the safe, secure, and responsible deployment of agentic AI systems. Our framework is open-sourced \href{https://govtech-responsibleai.github.io/agentic-risk-capability-framework/}{here}.

</details>


### [13] [We are not able to identify AI-generated images](https://arxiv.org/abs/2512.22236)
*Adrien Pavão*

Main category: cs.AI

TL;DR: 人类难以区分AI生成图像与真实照片，实验显示平均准确率仅54%，略高于随机猜测


<details>
  <summary>Details</summary>
Motivation: 尽管许多人自信能区分AI生成图像与真实照片，但随着合成媒体质量提升，需要验证人类实际辨别能力

Method: 通过交互式网络实验，让参与者对120个困难案例（60个真实图像和60个AI生成图像）进行分类，收集165名用户233次会话数据

Result: 平均准确率仅54%（略高于随机），平均响应时间7.3秒，某些图像更具欺骗性，重复尝试改善有限

Conclusion: 人类难以可靠检测AI生成内容，仅凭人类判断已不足够，需要提高意识和制定伦理指南

Abstract: AI-generated images are now pervasive online, yet many people believe they can easily tell them apart from real photographs. We test this assumption through an interactive web experiment where participants classify 20 images as real or AI-generated. Our dataset contains 120 difficult cases: real images sampled from CC12M, and carefully curated AI-generated counterparts produced with MidJourney. In total, 165 users completed 233 sessions. Their average accuracy was 54%, only slightly above random guessing, with limited improvement across repeated attempts. Response times averaged 7.3 seconds, and some images were consistently more deceptive than others. These results indicate that, even on relatively simple portrait images, humans struggle to reliably detect AI-generated content. As synthetic media continues to improve, human judgment alone is becoming insufficient for distinguishing real from artificial data. These findings highlight the need for greater awareness and ethical guidelines as AI-generated media becomes increasingly indistinguishable from reality.

</details>


### [14] [Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks](https://arxiv.org/abs/2512.22255)
*Abhranil Chandra,Ayush Agrawal,Arian Hosseini,Sebastian Fischmeister,Rishabh Agarwal,Navin Goyal,Aaron Courville*

Main category: cs.AI

TL;DR: 研究发现，即使思维链（CoT）轨迹最终答案错误，使用更强大模型生成的合成CoT数据集训练语言模型，也能提升其推理能力，效果甚至优于人类标注数据。


<details>
  <summary>Details</summary>
Motivation: 探索如何更有效地提升语言模型的推理能力，特别是研究使用合成数据（即使包含错误答案）是否比人类标注数据更有优势。

Method: 使用更强大模型生成包含错误最终答案的合成CoT轨迹数据集来训练语言模型。通过语言模型改写人类标注轨迹以接近模型分布，并引入逐渐增加的缺陷CoT轨迹来测试模型对缺陷的容忍度。

Result: 在数学、算法推理和代码生成等多个领域（MATH、GSM8K、Countdown、MBPP数据集）和不同规模模型（1.5B-9B）上，使用合成CoT数据训练比人类标注数据表现更好。

Conclusion: 构建接近模型自身分布的数据集对提升推理能力至关重要，正确的最终答案并不总是忠实推理过程的可靠指标，部分正确的推理轨迹仍有学习价值。

Abstract: We present the surprising finding that a language model's reasoning capabilities can be improved by training on synthetic datasets of chain-of-thought (CoT) traces from more capable models, even when all of those traces lead to an incorrect final answer. Our experiments show this approach can yield better performance on reasoning tasks than training on human-annotated datasets. We hypothesize that two key factors explain this phenomenon: first, the distribution of synthetic data is inherently closer to the language model's own distribution, making it more amenable to learning. Second, these `incorrect' traces are often only partially flawed and contain valid reasoning steps from which the model can learn. To further test the first hypothesis, we use a language model to paraphrase human-annotated traces -- shifting their distribution closer to the model's own distribution -- and show that this improves performance. For the second hypothesis, we introduce increasingly flawed CoT traces and study to what extent models are tolerant to these flaws. We demonstrate our findings across various reasoning domains like math, algorithmic reasoning and code generation using MATH, GSM8K, Countdown and MBPP datasets on various language models ranging from 1.5B to 9B across Qwen, Llama, and Gemma models. Our study shows that curating datasets that are closer to the model's distribution is a critical aspect to consider. We also show that a correct final answer is not always a reliable indicator of a faithful reasoning process.

</details>


### [15] [Logic Sketch Prompting (LSP): A Deterministic and Interpretable Prompting Method](https://arxiv.org/abs/2512.22258)
*Satvik Tripathi*

Main category: cs.AI

TL;DR: LSP是一种轻量级提示框架，通过引入类型变量、确定性条件评估器和基于规则的验证器，显著提升LLM在需要严格规则遵循、确定性和可审计性任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言推理方面表现出色，但在需要严格规则遵循、确定性和可审计性的任务上仍然不可靠，特别是在临床、监管和安全关键决策支持系统中。

Method: 提出Logic Sketch Prompting (LSP)框架，包含类型变量、确定性条件评估器和基于规则的验证器，能够产生可追踪和可重复的输出。在两个药理学逻辑合规任务上，使用Gemma 2、Mistral和Llama 3三个开源模型进行基准测试。

Result: LSP在所有模型和任务中均获得最高准确率(0.83-0.89)和F1分数(0.83-0.89)，显著优于零样本提示(0.24-0.60)、简洁提示(0.16-0.30)和思维链提示(0.56-0.75)。McNemar检验显示LSP在几乎所有比较中都有统计学显著提升(p<0.01)。

Conclusion: LSP在不牺牲性能的情况下提高了确定性、可解释性和一致性，支持其在临床、监管和安全关键决策支持系统中的使用。

Abstract: Large language models (LLMs) excel at natural language reasoning but remain unreliable on tasks requiring strict rule adherence, determinism, and auditability. Logic Sketch Prompting (LSP) is a lightweight prompting framework that introduces typed variables, deterministic condition evaluators, and a rule based validator that produces traceable and repeatable outputs. Using two pharmacologic logic compliance tasks, we benchmark LSP against zero shot prompting, chain of thought prompting, and concise prompting across three open weight models: Gemma 2, Mistral, and Llama 3. Across both tasks and all models, LSP consistently achieves the highest accuracy (0.83 to 0.89) and F1 score (0.83 to 0.89), substantially outperforming zero shot prompting (0.24 to 0.60), concise prompts (0.16 to 0.30), and chain of thought prompting (0.56 to 0.75). McNemar tests show statistically significant gains for LSP across nearly all comparisons (p < 0.01). These results demonstrate that LSP improves determinism, interpretability, and consistency without sacrificing performance, supporting its use in clinical, regulated, and safety critical decision support systems.

</details>


### [16] [SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence](https://arxiv.org/abs/2512.22334)
*Yiheng Wang,Yixin Chen,Shuo Li,Yifan Zhou,Bo Liu,Hengjian Gao,Jiakang Yuan,Jia Bu,Wanghan Xu,Yuhao Zhou,Xiangyu Zhao,Zhiwang Zhou,Fengxiang Wang,Haodong Duan,Songyang Zhang,Jun Yao,Han Deng,Yizhou Wang,Jiabei Xiao,Jiaqi Liu,Encheng Su,Yujie Liu,Weida Wang,Junchi Yao,Shenghe Zheng,Haoran Sun,Runmin Ma,Xiangchao Yan,Bo Zhang,Dongzhan Zhou,Shufei Zhang,Peng Ye,Xiaosong Wang,Shixiang Tang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: SciEvalKit是一个统一的科学AI模型评估工具包，专注于科学智能核心能力评估，覆盖六大科学领域，提供可扩展的评估管道和开源基础设施。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专注于科学智能核心能力的统一评估平台，需要建立能够反映真实科学挑战、覆盖多学科领域的标准化评估工具来推动AI4Science发展。

Method: 构建专家级科学基准，从真实领域特定数据集中精心挑选任务，设计灵活可扩展的评估管道，支持批量评估、自定义模型和数据集集成，确保结果透明、可复现和可比较。

Result: 开发了支持六大科学领域（物理、化学、天文学、材料科学等）的统一评估工具包，涵盖科学多模态感知、推理、理解、符号推理、代码生成、假设生成和知识理解等七项核心能力。

Conclusion: SciEvalKit通过桥接能力评估和学科多样性，为下一代科学基础模型和智能代理提供了标准化且可定制的基础设施，通过开源和社区驱动促进AI4Science发展。

Abstract: We introduce SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across a broad range of scientific disciplines and task capabilities. Unlike general-purpose evaluation platforms, SciEvalKit focuses on the core competencies of scientific intelligence, including Scientific Multimodal Perception, Scientific Multimodal Reasoning, Scientific Multimodal Understanding, Scientific Symbolic Reasoning, Scientific Code Generation, Science Hypothesis Generation and Scientific Knowledge Understanding. It supports six major scientific domains, spanning from physics and chemistry to astronomy and materials science. SciEvalKit builds a foundation of expert-grade scientific benchmarks, curated from real-world, domain-specific datasets, ensuring that tasks reflect authentic scientific challenges. The toolkit features a flexible, extensible evaluation pipeline that enables batch evaluation across models and datasets, supports custom model and dataset integration, and provides transparent, reproducible, and comparable results. By bridging capability-based evaluation and disciplinary diversity, SciEvalKit offers a standardized yet customizable infrastructure to benchmark the next generation of scientific foundation models and intelligent agents. The toolkit is open-sourced and actively maintained to foster community-driven development and progress in AI4Science.

</details>


### [17] [Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback](https://arxiv.org/abs/2512.22336)
*Mengkang Hu,Bowei Xia,Yuran Wu,Ailing Yu,Yude Zou,Qiguang Chen,Shijian Wang,Jiarui Jin,Kexin Li,Wenxiang Jiao,Yuan Lu,Ping Luo*

Main category: cs.AI

TL;DR: Agent2World：一个工具增强的多智能体框架，通过多智能体反馈实现推理时世界模型生成，并作为监督微调的数据引擎，在PDDL和可执行代码表示上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 当前训练LLMs生成符号世界模型（如PDDL领域或可执行模拟器）受限于缺乏大规模可验证监督。现有方法主要依赖静态验证，无法捕捉交互执行中产生的行为级错误。

Method: 提出Agent2World三阶段流水线：1) Deep Researcher智能体通过网页搜索进行知识合成以填补规范缺口；2) Model Developer智能体实现可执行世界模型；3) 专门的Testing Team进行自适应单元测试和基于模拟的验证。

Result: 在三个涵盖PDDL和可执行代码表示的基准测试中展示出卓越的推理时性能，取得一致的SOTA结果。基于测试团队反馈微调的模型相比训练前平均相对提升30.95%。

Conclusion: Agent2World不仅实现了强大的推理时世界模型生成，还通过多智能体反馈机制作为监督微调的数据引擎，显著提升了世界模型生成质量。

Abstract: Symbolic world models (e.g., PDDL domains or executable simulators) are central to model-based planning, but training LLMs to generate such world models is limited by the lack of large-scale verifiable supervision. Current approaches rely primarily on static validation methods that fail to catch behavior-level errors arising from interactive execution. In this paper, we propose Agent2World, a tool-augmented multi-agent framework that achieves strong inference-time world-model generation and also serves as a data engine for supervised fine-tuning, by grounding generation in multi-agent feedback. Agent2World follows a three-stage pipeline: (i) A Deep Researcher agent performs knowledge synthesis by web searching to address specification gaps; (ii) A Model Developer agent implements executable world models; And (iii) a specialized Testing Team conducts adaptive unit testing and simulation-based validation. Agent2World demonstrates superior inference-time performance across three benchmarks spanning both Planning Domain Definition Language (PDDL) and executable code representations, achieving consistent state-of-the-art results. Beyond inference, Testing Team serves as an interactive environment for the Model Developer, providing behavior-aware adaptive feedback that yields multi-turn training trajectories. The model fine-tuned on these trajectories substantially improves world-model generation, yielding an average relative gain of 30.95% over the same model before training. Project page: https://agent2world.github.io.

</details>


### [18] [Subgoaling Relaxation-based Heuristics for Numeric Planning with Infinite Actions](https://arxiv.org/abs/2512.22367)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 将带有控制参数的数字规划问题编译为简单数字任务，使传统启发式方法能处理无限动作空间


<details>
  <summary>Details</summary>
Motivation: 标准数字规划模型引入控制参数后，动作数量可能无限，导致现成的数字启发式方法不可行，需要新的解决方案

Method: 识别可控简单数字问题子集，采用乐观编译方法将控制相关表达式抽象为有界常数效果和宽松前提条件

Result: 该方法能有效使用子目标启发式估计目标距离，是处理无限动作空间的有效且计算可行的方法

Conclusion: 提出的编译方法使传统数字启发式能应用于控制参数设置，推动了该领域的技术边界

Abstract: Numeric planning with control parameters extends the standard numeric planning model by introducing action parameters as free numeric variables that must be instantiated during planning. This results in a potentially infinite number of applicable actions in a state. In this setting, off-the-shelf numeric heuristics that leverage the action structure are not feasible. In this paper, we identify a tractable subset of these problems--namely, controllable, simple numeric problems--and propose an optimistic compilation approach that transforms them into simple numeric tasks. To do so, we abstract control-dependent expressions into bounded constant effects and relaxed preconditions. The proposed compilation makes it possible to effectively use subgoaling heuristics to estimate goal distance in numeric planning problems involving control parameters. Our results demonstrate that this approach is an effective and computationally feasible way of applying traditional numeric heuristics to settings with an infinite number of possible actions, pushing the boundaries of the current state of the art.

</details>


### [19] [HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification](https://arxiv.org/abs/2512.22396)
*Bhanu Prakash Vangala,Sajid Mahmud,Pawan Neupane,Joel Selvaraj,Jianlin Cheng*

Main category: cs.AI

TL;DR: 本文针对AI在材料科学中的幻觉问题，提出了HalluMatData基准数据集和HalluMatDetector多阶段检测框架，将幻觉率降低了30%，并引入PHCS指标量化模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学发现中产生幻觉（生成事实错误或误导信息）的问题严重威胁研究完整性，特别是在材料科学领域需要可靠的知识生成。

Method: 1. 创建HalluMatData基准数据集用于评估幻觉检测方法；2. 提出HalluMatDetector多阶段检测框架，整合内在验证、多源检索、矛盾图分析和基于指标的评估；3. 引入Paraphrased Hallucination Consistency Score (PHCS)量化语义等价查询下的响应不一致性。

Result: 1. 发现材料科学不同子领域的幻觉水平差异显著，高熵查询表现出更大的事实不一致性；2. 使用HalluMatDetector验证流程将幻觉率相比标准LLM输出降低了30%；3. PHCS提供了对模型可靠性的深入洞察。

Conclusion: 该研究为解决AI在材料科学中的幻觉问题提供了系统解决方案，通过基准数据集、检测框架和量化指标，显著提升了AI生成内容的可靠性和研究完整性。

Abstract: Artificial Intelligence (AI), particularly Large Language Models (LLMs), is transforming scientific discovery, enabling rapid knowledge generation and hypothesis formulation. However, a critical challenge is hallucination, where LLMs generate factually incorrect or misleading information, compromising research integrity. To address this, we introduce HalluMatData, a benchmark dataset for evaluating hallucination detection methods, factual consistency, and response robustness in AI-generated materials science content. Alongside this, we propose HalluMatDetector, a multi-stage hallucination detection framework that integrates intrinsic verification, multi-source retrieval, contradiction graph analysis, and metric-based assessment to detect and mitigate LLM hallucinations. Our findings reveal that hallucination levels vary significantly across materials science subdomains, with high-entropy queries exhibiting greater factual inconsistencies. By utilizing HalluMatDetector verification pipeline, we reduce hallucination rates by 30% compared to standard LLM outputs. Furthermore, we introduce the Paraphrased Hallucination Consistency Score (PHCS) to quantify inconsistencies in LLM responses across semantically equivalent queries, offering deeper insights into model reliability.

</details>


### [20] [Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings](https://arxiv.org/abs/2512.22398)
*Ozan Oguztuzun,Cerag Oguztuzun*

Main category: cs.AI

TL;DR: GatedBias：一个轻量级推理时个性化框架，通过结构门控适应将冻结的知识图谱嵌入适配到个体用户上下文，仅需约300个可训练参数，在保持全局准确性的同时显著提升个性化排名效果。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱基础模型在链接预测上表现出色，但无法捕捉个体用户偏好，存在通用关系推理与个性化排名之间的关键脱节。需要一种既能保持全局准确性又能实现个性化适配的解决方案。

Method: 提出GatedBias框架，采用结构门控适应机制：结合用户特定特征和图导出的二元门控，生成可解释的每实体偏置。该框架在推理时工作，无需重新训练基础模型，仅需约300个可训练参数。

Result: 在两个基准数据集（Amazon-Book和Last-FM）上评估，在保持群体性能的同时，对齐指标获得统计显著改进。反事实扰动实验验证了因果响应性：受益于特定偏好信号的实体在信号增强时排名改进提高6-30倍。

Conclusion: 知识图谱基础模型的个性化适配可以实现参数高效且因果可验证，能够桥接通用知识表示与个体用户需求，为个性化推荐系统提供新思路。

Abstract: Foundation models for knowledge graphs (KGs) achieve strong cohort-level performance in link prediction, yet fail to capture individual user preferences; a key disconnect between general relational reasoning and personalized ranking. We propose GatedBias, a lightweight inference-time personalization framework that adapts frozen KG embeddings to individual user contexts without retraining or compromising global accuracy. Our approach introduces structure-gated adaptation: profile-specific features combine with graph-derived binary gates to produce interpretable, per-entity biases, requiring only ${\sim}300$ trainable parameters. We evaluate GatedBias on two benchmark datasets (Amazon-Book and Last-FM), demonstrating statistically significant improvements in alignment metrics while preserving cohort performance. Counterfactual perturbation experiments validate causal responsiveness; entities benefiting from specific preference signals show 6--30$\times$ greater rank improvements when those signals are boosted. These results show that personalized adaptation of foundation models can be both parameter-efficient and causally verifiable, bridging general knowledge representations with individual user needs.

</details>


### [21] [Monadic Context Engineering](https://arxiv.org/abs/2512.22431)
*Yifan Zhang,Mengdi Wang*

Main category: cs.AI

TL;DR: 论文提出Monadic Context Engineering (MCE)，一种基于函子、应用函子和单子的代数结构的新型智能体架构范式，用于解决当前自主智能体设计中状态管理、错误处理和并发等问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自主智能体架构通常采用命令式、临时性的设计模式，导致系统脆弱，难以管理状态、处理错误和实现并发。需要一种形式化的基础来构建更健壮的智能体系统。

Method: 提出MCE范式，将智能体工作流视为计算上下文，利用函子、应用函子和单子的代数特性来内在管理跨领域关注点。单子支持健壮的顺序组合，应用函子提供并行执行的结构，单子变换器则允许系统性地组合这些能力。进一步扩展该框架到元智能体，通过元编程动态创建和管理子智能体工作流。

Result: MCE提供了一种分层方法，使开发者能够从简单、可独立验证的组件构建复杂、有弹性且高效的AI智能体。通过代数结构的固有特性，系统性地解决了状态传播、错误处理和异步执行等问题。

Conclusion: MCE为智能体设计提供了形式化的代数基础，通过函子、应用函子和单子的数学结构，实现了更健壮、可组合和可验证的自主智能体架构，特别适用于需要复杂推理和工具使用的场景。

Abstract: The proliferation of Large Language Models (LLMs) has catalyzed a shift towards autonomous agents capable of complex reasoning and tool use. However, current agent architectures are frequently constructed using imperative, ad hoc patterns. This results in brittle systems plagued by difficulties in state management, error handling, and concurrency. This paper introduces Monadic Context Engineering (MCE), a novel architectural paradigm leveraging the algebraic structures of Functors, Applicative Functors, and Monads to provide a formal foundation for agent design. MCE treats agent workflows as computational contexts where cross-cutting concerns, such as state propagation, short-circuiting error handling, and asynchronous execution, are managed intrinsically by the algebraic properties of the abstraction. We demonstrate how Monads enable robust sequential composition, how Applicatives provide a principled structure for parallel execution, and crucially, how Monad Transformers allow for the systematic composition of these capabilities. This layered approach enables developers to construct complex, resilient, and efficient AI agents from simple, independently verifiable components. We further extend this framework to describe Meta-Agents, which leverage MCE for generative orchestration, dynamically creating and managing sub-agent workflows through metaprogramming. Project Page: https://github.com/yifanzhang-pro/monadic-context-engineering.

</details>


### [22] [DarkPatterns-LLM: A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior](https://arxiv.org/abs/2512.22470)
*Sadia Asif,Israel Antonio Rosales Laguan,Haris Khan,Shumaila Asif,Muneeb Asif*

Main category: cs.AI

TL;DR: DarkPatterns-LLM是一个用于评估LLM输出中操纵性内容的综合基准数据集和诊断框架，包含7种伤害类别和四层分析流程，揭示了主流模型在检测自主性破坏模式方面的显著性能差异和弱点。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，操纵性或欺骗性行为日益引发担忧，可能损害用户自主权、信任和福祉。现有安全基准主要依赖粗糙的二元标签，无法捕捉构成操纵的微妙心理和社会机制。

Method: 提出了DarkPatterns-LLM基准数据集和诊断框架，包含7种伤害类别：法律/权力、心理、情感、身体、自主性、经济和社会伤害。采用四层分析流程：多粒度检测、多尺度意图分析、威胁协调协议和深度上下文风险对齐。数据集包含401个精心策划的示例，配有指令-响应对和专家标注。

Result: 评估了GPT-4、Claude 3.5和LLaMA-3-70B等最先进模型，发现显著性能差异（65.2%-89.7%），并在检测自主性破坏模式方面存在一致的弱点。

Conclusion: DarkPatterns-LLM建立了首个用于LLM操纵检测的标准化、多维度基准，为构建更可信的AI系统提供了可操作的诊断工具。

Abstract: The proliferation of Large Language Models (LLMs) has intensified concerns about manipulative or deceptive behaviors that can undermine user autonomy, trust, and well-being. Existing safety benchmarks predominantly rely on coarse binary labels and fail to capture the nuanced psychological and social mechanisms constituting manipulation. We introduce \textbf{DarkPatterns-LLM}, a comprehensive benchmark dataset and diagnostic framework for fine-grained assessment of manipulative content in LLM outputs across seven harm categories: Legal/Power, Psychological, Emotional, Physical, Autonomy, Economic, and Societal Harm. Our framework implements a four-layer analytical pipeline comprising Multi-Granular Detection (MGD), Multi-Scale Intent Analysis (MSIAN), Threat Harmonization Protocol (THP), and Deep Contextual Risk Alignment (DCRA). The dataset contains 401 meticulously curated examples with instruction-response pairs and expert annotations. Through evaluation of state-of-the-art models including GPT-4, Claude 3.5, and LLaMA-3-70B, we observe significant performance disparities (65.2\%--89.7\%) and consistent weaknesses in detecting autonomy-undermining patterns. DarkPatterns-LLM establishes the first standardized, multi-dimensional benchmark for manipulation detection in LLMs, offering actionable diagnostics toward more trustworthy AI systems.

</details>


### [23] [Multi-AI Agent Framework Reveals the "Oxide Gatekeeper" in Aluminum Nanoparticle Oxidation](https://arxiv.org/abs/2512.22529)
*Yiming Lu,Tingyu Lu,Di Zhang,Lili Ye,Hao Li*

Main category: cs.AI

TL;DR: 开发了一种"人在回路"的AI代理框架，用于构建高精度机器学习势函数，揭示了铝纳米颗粒温度调控的双模式氧化机制，解决了铝阳离子扩散主导质量传输的长期争议。


<details>
  <summary>Details</summary>
Motivation: 铝纳米颗粒作为高能量密度固体燃料，其从钝化态到爆炸反应的原子尺度机制尚不明确。传统方法存在瓶颈：从头算方法精度高但尺度受限，经验势场缺乏复杂燃烧环境的反应保真度。

Method: 采用"人在回路"的闭环框架，通过自我审计的AI代理验证机器学习势函数的演化过程。AI代理作为科学哨兵，可视化隐藏的模型伪影供人类决策，确保量子力学精度，同时实现百万原子系统的近线性扩展和纳秒时间尺度模拟。

Result: 揭示了温度调控的双模式氧化机制：中等温度下氧化壳层作为动态"守门员"，通过瞬态纳米通道的"呼吸模式"调控氧化；超过临界阈值时，"破裂模式"导致壳层灾难性失效和爆炸燃烧。解决了长期争议，证明铝阳离子向外扩散（而非氧传输）在所有温度区间主导质量传输，扩散系数比氧高2-3个数量级。

Conclusion: 建立了统一的原子尺度框架用于高能纳米材料设计，通过智能计算设计实现点火敏感性和能量释放速率的精确调控，为高能材料工程提供了新范式。

Abstract: Aluminum nanoparticles (ANPs) are among the most energy-dense solid fuels, yet the atomic mechanisms governing their transition from passivated particles to explosive reactants remain elusive. This stems from a fundamental computational bottleneck: ab initio methods offer quantum accuracy but are restricted to small spatiotemporal scales (< 500 atoms, picoseconds), while empirical force fields lack the reactive fidelity required for complex combustion environments. Herein, we bridge this gap by employing a "human-in-the-loop" closed-loop framework where self-auditing AI Agents validate the evolution of a machine learning potential (MLP). By acting as scientific sentinels that visualize hidden model artifacts for human decision-making, this collaborative cycle ensures quantum mechanical accuracy while exhibiting near-linear scalability to million-atom systems and accessing nanosecond timescales (energy RMSE: 1.2 meV/atom, force RMSE: 0.126 eV/Angstrom). Strikingly, our simulations reveal a temperature-regulated dual-mode oxidation mechanism: at moderate temperatures, the oxide shell acts as a dynamic "gatekeeper," regulating oxidation through a "breathing mode" of transient nanochannels; above a critical threshold, a "rupture mode" unleashes catastrophic shell failure and explosive combustion. Importantly, we resolve a decades-old controversy by demonstrating that aluminum cation outward diffusion, rather than oxygen transport, dominates mass transfer across all temperature regimes, with diffusion coefficients consistently exceeding those of oxygen by 2-3 orders of magnitude. These discoveries establish a unified atomic-scale framework for energetic nanomaterial design, enabling the precision engineering of ignition sensitivity and energy release rates through intelligent computational design.

</details>


### [24] [Lessons from Neuroscience for AI: How integrating Actions, Compositional Structure and Episodic Memory could enable Safe, Interpretable and Human-Like AI](https://arxiv.org/abs/2512.22568)
*Rajesh P. N. Rao,Vishwas Sathish,Linxing Preston Jiang,Matthew Bryan,Prashant Rangarajan*

Main category: cs.AI

TL;DR: 论文主张将神经科学中的预测编码模型三个关键组件（动作整合、层次组合结构、情景记忆）整合到基础模型中，以解决当前AI的幻觉、缺乏基础、可解释性差和能效低等问题，促进安全、可解释、类人AI的发展。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型仅基于简单的下一个token预测损失进行优化，忽略了神经科学中预测编码模型的三个关键组件：动作与生成模型的紧密整合、层次组合结构、情景记忆。这些缺失导致AI存在幻觉、概念理解肤浅、缺乏主体性/责任感、可解释性差、能效低等问题。

Method: 提出将神经科学和认知科学的预测编码模型组件整合到基础模型中：1）在多个抽象层次上整合动作与生成模型；2）采用组合式生成架构；3）加入情景记忆系统。与当前趋势（如思维链推理、检索增强生成）进行比较，并讨论如何用脑启发组件增强这些模型。

Result: 论文展示了神经科学证据支持这些组件的重要性，并论证了将这些组件整合到基础模型中可以帮助解决当前AI的缺陷：减少幻觉、增强概念基础、建立主体性/责任感、提高可解释性和安全性、改善能效。

Conclusion: 重新激活脑科学与AI之间的思想交流将有助于实现安全、可解释、以人为本的AI。整合预测编码模型的完整组件（动作、层次结构、记忆）是开发更类人、更可靠AI系统的关键路径。

Abstract: The phenomenal advances in large language models (LLMs) and other foundation models over the past few years have been based on optimizing large-scale transformer models on the surprisingly simple objective of minimizing next-token prediction loss, a form of predictive coding that is also the backbone of an increasingly popular model of brain function in neuroscience and cognitive science. However, current foundation models ignore three other important components of state-of-the-art predictive coding models: tight integration of actions with generative models, hierarchical compositional structure, and episodic memory. We propose that to achieve safe, interpretable, energy-efficient, and human-like AI, foundation models should integrate actions, at multiple scales of abstraction, with a compositional generative architecture and episodic memory. We present recent evidence from neuroscience and cognitive science on the importance of each of these components. We describe how the addition of these missing components to foundation models could help address some of their current deficiencies: hallucinations and superficial understanding of concepts due to lack of grounding, a missing sense of agency/responsibility due to lack of control, threats to safety and trustworthiness due to lack of interpretability, and energy inefficiency. We compare our proposal to current trends, such as adding chain-of-thought (CoT) reasoning and retrieval-augmented generation (RAG) to foundation models, and discuss new ways of augmenting these models with brain-inspired components. We conclude by arguing that a rekindling of the historically fruitful exchange of ideas between brain science and AI will help pave the way towards safe and interpretable human-centered AI.

</details>


### [25] [Tyee: A Unified, Modular, and Fully-Integrated Configurable Toolkit for Intelligent Physiological Health Care](https://arxiv.org/abs/2512.22601)
*Tao Zhou,Lingyu Shu,Zixing Zhang,Jing Han*

Main category: cs.AI

TL;DR: Tyee是一个用于智能生理医疗的统一、模块化、可配置工具包，解决了深度学习在生理信号分析中的数据格式不统一、预处理不一致、模型碎片化和实验不可复现等问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在生理信号分析中面临四大挑战：数据格式异构、预处理策略不一致、模型流程碎片化、实验设置不可复现，这些限制了该领域的进展。

Method: Tyee提出三个关键创新：1) 统一数据接口和可配置预处理管道，支持12种信号模态；2) 模块化可扩展架构，支持灵活集成和快速原型开发；3) 端到端工作流配置，促进可复现和可扩展的实验。

Result: Tyee在所有评估任务中表现一致有效且具有良好泛化能力，在13个数据集中12个达到最先进水平，其余与基线相当或超越。

Conclusion: Tyee工具包成功解决了生理信号分析中的关键挑战，提供了统一、模块化、可配置的解决方案，已在GitHub开源并持续维护，有望推动该领域的研究进展。

Abstract: Deep learning has shown great promise in physiological signal analysis, yet its progress is hindered by heterogeneous data formats, inconsistent preprocessing strategies, fragmented model pipelines, and non-reproducible experimental setups. To address these limitations, we present Tyee, a unified, modular, and fully-integrated configurable toolkit designed for intelligent physiological healthcare. Tyee introduces three key innovations: (1) a unified data interface and configurable preprocessing pipeline for 12 kinds of signal modalities; (2) a modular and extensible architecture enabling flexible integration and rapid prototyping across tasks; and (3) end-to-end workflow configuration, promoting reproducible and scalable experimentation. Tyee demonstrates consistent practical effectiveness and generalizability, outperforming or matching baselines across all evaluated tasks (with state-of-the-art results on 12 of 13 datasets). The Tyee toolkit is released at https://github.com/SmileHnu/Tyee and actively maintained.

</details>


### [26] [Learning Multi-Modal Mobility Dynamics for Generalized Next Location Recommendation](https://arxiv.org/abs/2512.22605)
*Junshu Dai,Yu Wang,Tongya Zheng,Wei Ji,Qinghong Guo,Ji Cao,Jie Song,Canghong Jin,Mingli Song*

Main category: cs.AI

TL;DR: M³ob：利用多模态时空知识增强位置推荐，通过LLM增强的时空知识图谱构建统一时空关系图，解决现有方法泛化能力有限的问题


<details>
  <summary>Details</summary>
Motivation: 现有的人类移动预测方法泛化能力有限：单模态方法受数据稀疏性和固有偏差限制，多模态方法难以有效捕捉静态多模态表示与时空动态之间的语义鸿沟

Method: 1) 利用LLM增强的时空知识图谱构建统一时空关系图；2) 设计门控机制融合不同模态的时空图表示；3) 提出STKG引导的跨模态对齐，将时空动态知识注入静态图像模态

Result: 在六个公共数据集上的实验表明，该方法不仅在正常场景下取得一致改进，在异常场景中也展现出显著泛化能力

Conclusion: M³ob通过多模态时空知识有效表征移动动态，解决了现有方法的泛化限制，为位置推荐任务提供了更强大的解决方案

Abstract: The precise prediction of human mobility has produced significant socioeconomic impacts, such as location recommendations and evacuation suggestions. However, existing methods suffer from limited generalization capability: unimodal approaches are constrained by data sparsity and inherent biases, while multi-modal methods struggle to effectively capture mobility dynamics caused by the semantic gap between static multi-modal representation and spatial-temporal dynamics. Therefore, we leverage multi-modal spatial-temporal knowledge to characterize mobility dynamics for the location recommendation task, dubbed as \textbf{M}ulti-\textbf{M}odal \textbf{Mob}ility (\textbf{M}$^3$\textbf{ob}). First, we construct a unified spatial-temporal relational graph (STRG) for multi-modal representation, by leveraging the functional semantics and spatial-temporal knowledge captured by the large language models (LLMs)-enhanced spatial-temporal knowledge graph (STKG). Second, we design a gating mechanism to fuse spatial-temporal graph representations of different modalities, and propose an STKG-guided cross-modal alignment to inject spatial-temporal dynamic knowledge into the static image modality. Extensive experiments on six public datasets show that our proposed method not only achieves consistent improvements in normal scenarios but also exhibits significant generalization ability in abnormal scenarios.

</details>


### [27] [LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation](https://arxiv.org/abs/2512.22608)
*Zhongyang Liu,Haoyu Pei,Xiangyi Xiao,Xiaocong Du,Yihui Li,Suting Hong,Kunpeng Zhang,Haipeng Zhang*

Main category: cs.AI

TL;DR: 提出SimVC-CAS多智能体系统，通过模拟风险投资群体决策过程来预测初创企业成功概率，相比传统单决策者方法显著提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 初创企业价值高但失败率高，预测其成功是跨学科研究的重要挑战。现有方法通常从单一决策者角度建模，忽略了现实世界中风险投资决策的集体动态特性。

Method: 提出SimVC-CAS集体智能体系统，将VC决策模拟为多智能体交互过程。设计角色扮演智能体（具有独特特质和偏好的投资者）和基于GNN的监督交互模块，通过图结构共投网络实现异质评估和真实信息交换。

Result: 使用PitchBook真实数据并在严格数据泄漏控制下，SimVC-CAS显著提升预测准确性，例如在平均精度@10指标上实现约25%的相对改进。同时提供可解释的多视角推理。

Conclusion: SimVC-CAS通过模拟VC群体决策过程，有效捕捉企业基本面和潜在投资者网络的行为动态，为初创企业融资预测提供了新方法，也为其他复杂群体决策场景提供启示。

Abstract: Due to the high value and high failure rate of startups, predicting their success has become a critical challenge across interdisciplinary research. Existing approaches typically model success prediction from the perspective of a single decision-maker, overlooking the collective dynamics of investor groups that dominate real-world venture capital (VC) decisions. In this paper, we propose SimVC-CAS, a novel collective agent system that simulates VC decision-making as a multi-agent interaction process. By designing role-playing agents and a GNN-based supervised interaction module, we reformulate startup financing prediction as a group decision-making task, capturing both enterprise fundamentals and the behavioral dynamics of potential investor networks. Each agent embodies an investor with unique traits and preferences, enabling heterogeneous evaluation and realistic information exchange through a graph-structured co-investment network. Using real-world data from PitchBook and under strict data leakage controls, we show that SimVC-CAS significantly improves predictive accuracy while providing interpretable, multiperspective reasoning, for example, approximately 25% relative improvement with respect to average precision@10. SimVC-CAS also sheds light on other complex group decision scenarios.

</details>


### [28] [The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?](https://arxiv.org/abs/2512.22625)
*Paul Schneider,Amalie Schramm*

Main category: cs.AI

TL;DR: LLM相互审阅预测能提升准确性，但仅适用于多样化模型且信息共享时；同质模型无改善；额外上下文信息无帮助


<details>
  <summary>Details</summary>
Motivation: 研究结构化审议（类似人类预测者的相互审阅）是否也能提升大语言模型（GPT-5、Claude Sonnet 4.5、Gemini Pro 2.5）的预测准确性

Method: 使用Metaculus Q2 2025 AI预测锦标赛的202个已解决二元问题，评估四种情境下的准确性：1) 多样化模型+分布式信息，2) 多样化模型+共享信息，3) 同质模型+分布式信息，4) 同质模型+共享信息

Result: 干预措施在情境2（多样化模型+共享信息）中显著提升准确性，Log Loss减少0.020（约4%相对改善，p=0.017）；同质模型组无改善；额外上下文信息未提升预测准确性

Conclusion: 审议可能是改善LLM预测的可行策略，但效果取决于模型多样性和信息共享条件；同质模型无法从相互审阅中获益；信息汇集机制需要进一步研究

Abstract: Structured deliberation has been found to improve the performance of human forecasters. This study investigates whether a similar intervention, i.e. allowing LLMs to review each other's forecasts before updating, can improve accuracy in large language models (GPT-5, Claude Sonnet 4.5, Gemini Pro 2.5). Using 202 resolved binary questions from the Metaculus Q2 2025 AI Forecasting Tournament, accuracy was assessed across four scenarios: (1) diverse models with distributed information, (2) diverse models with shared information, (3) homogeneous models with distributed information, and (4) homogeneous models with shared information. Results show that the intervention significantly improves accuracy in scenario (2), reducing Log Loss by 0.020 or about 4 percent in relative terms (p = 0.017). However, when homogeneous groups (three instances of the same model) engaged in the same process, no benefit was observed. Unexpectedly, providing LLMs with additional contextual information did not improve forecast accuracy, limiting our ability to study information pooling as a mechanism. Our findings suggest that deliberation may be a viable strategy for improving LLM forecasting.

</details>


### [29] [DICE: Discrete Interpretable Comparative Evaluation with Probabilistic Scoring for Retrieval-Augmented Generation](https://arxiv.org/abs/2512.22629)
*Shiyan Liu,Jian Ma,Rui Qu*

Main category: cs.AI

TL;DR: DICE是一个两阶段、证据耦合的框架，通过深度分析推理和概率评分提升RAG系统的可解释性和鲁棒性评估，同时采用瑞士系统锦标赛降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 随着RAG系统向更复杂架构发展，需要通过可解释和鲁棒的评估确保其可信度。现有标量指标存在可解释性有限、不确定性量化不足、多系统比较计算效率低等问题，阻碍了RAG技术的负责任部署。

Method: DICE采用两阶段框架：结合深度分析推理与概率{A, B, Tie}评分，生成透明、置信度感知的判断；同时采用瑞士系统锦标赛将计算复杂度从O(N²)降低到O(N log N)，提高大规模评估效率。

Result: 在中文金融QA数据集上验证，DICE与人类专家达成85.7%的一致性，显著优于RAGAS等现有LLM基准指标。在八系统评估中实现42.9%的计算量减少，同时保持排名保真度。

Conclusion: DICE建立了一个负责任、可解释且高效的范式，用于可信赖的RAG系统评估，支持通过可解释的推理轨迹进行系统错误诊断和可操作的改进。

Abstract: As Retrieval-Augmented Generation (RAG) systems evolve toward more sophisticated architectures, ensuring their trustworthiness through explainable and robust evaluation becomes critical. Existing scalar metrics suffer from limited interpretability, inadequate uncertainty quantification, and computational inefficiency in multi-system comparisons, hindering responsible deployment of RAG technologies. We introduce DICE (Discrete Interpretable Comparative Evaluation), a two-stage, evidence-coupled framework that advances explainability and robustness in RAG evaluation. DICE combines deep analytical reasoning with probabilistic $\{A, B, Tie\}$ scoring to produce transparent, confidence-aware judgments that support accountable system improvement through interpretable reasoning traces, enabling systematic error diagnosis and actionable insights. To address efficiency challenges at scale, DICE employs a Swiss-system tournament that reduces computational complexity from $O(N^2)$ to $O(N \log N)$, achieving a 42.9% reduction in our eight-system evaluation while preserving ranking fidelity. Validation on a curated Chinese financial QA dataset demonstrates that DICE achieves 85.7% agreement with human experts, substantially outperforming existing LLM-based metrics such as RAGAS. Our results establish DICE as a responsible, explainable, and efficient paradigm for trustworthy RAG system assessment.

</details>


### [30] [TravelBench: A Real-World Benchmark for Multi-Turn and Tool-Augmented Travel Planning](https://arxiv.org/abs/2512.22673)
*Xiang Cheng,Yulan Hu,Xiangwen Zhang,Lu Xu,Zheng Pan,Xin Li,Yong Liu*

Main category: cs.AI

TL;DR: TravelBench是一个真实世界的旅行规划基准测试，具有多轮交互和工具使用功能，用于评估LLM代理在动态旅行规划场景中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的旅行规划任务设置存在局限性：领域覆盖不足、缺乏多轮交互，无法支持动态的用户-代理交互，因此不能全面评估代理能力。需要更全面的基准测试来推动LLM代理在旅行规划领域的发展。

Method: 1. 从真实场景收集用户请求构建三个子集：多轮交互、单轮交互、不可解决任务；2. 构建包含10个旅行领域工具的控制沙盒环境，提供确定性工具输出以确保可靠推理；3. 在TravelBench上评估多个LLM并分析其行为和性能。

Result: 建立了TravelBench基准测试，包含真实场景的用户请求和可控的沙盒环境，能够稳定、可复现地评估LLM代理在旅行规划中的表现，并提供了对多个LLM的评估分析。

Conclusion: TravelBench为推进LLM代理在旅行规划领域的发展提供了一个实用且可复现的基准测试，能够更全面地评估代理在动态交互和工具使用方面的能力。

Abstract: Large language model (LLM) agents have demonstrated strong capabilities in planning and tool use. Travel planning provides a natural and high-impact testbed for these capabilities, as it requires multi-step reasoning, iterative preference elicitation through interaction, and calls to external tools under evolving constraints. Prior work has studied LLMs on travel-planning tasks, but existing settings are limited in domain coverage and multi-turn interaction. As a result, they cannot support dynamic user-agent interaction and therefore fail to comprehensively assess agent capabilities. In this paper, we introduce TravelBench, a real-world travel-planning benchmark featuring multi-turn interaction and tool use. We collect user requests from real-world scenarios and construct three subsets-multi-turn, single-turn, and unsolvable-to evaluate different aspects of agent performance. For stable and reproducible evaluation, we build a controlled sandbox environment with 10 travel-domain tools, providing deterministic tool outputs for reliable reasoning. We evaluate multiple LLMs on TravelBench and conduct an analysis of their behaviors and performance. TravelBench offers a practical and reproducible benchmark for advancing LLM agents in travel planning.

</details>


### [31] [Memento-II: Learning by Stateful Reflective Memory](https://arxiv.org/abs/2512.22716)
*Jun Wang*

Main category: cs.AI

TL;DR: 提出一个理论框架，将情景记忆与强化学习结合，使大语言模型代理能够通过反思机制进行持续和经验学习，无需反向传播或模型微调。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要区分训练和部署阶段，而本文旨在让语言模型代理能够通过与环境交互持续学习，无需参数更新，实现真正的持续适应。

Method: 引入状态化反思决策过程，将反思学习建模为与情景记忆的两阶段读写交互：写入存储交互结果（策略评估），读取检索相关过去案例（策略改进）。

Result: 该过程诱导出增强状态记忆表示的等效马尔可夫决策过程，可使用经典动态规划和强化学习工具。通过熵正则化策略迭代实例化框架，并建立收敛保证。

Conclusion: 当情景记忆增长并充分覆盖状态空间时，所得策略收敛到最优解。为无需参数更新的记忆增强和基于检索的语言模型代理提供了理论基础。

Abstract: We propose a theoretical framework for continual and experiential learning in large language model agents that integrates episodic memory with reinforcement learning. The framework identifies reflection as the key mechanism that enables agents to adapt through interaction without back propagation or model fine tuning, thereby relaxing the conventional separation between training and deployment.To formalise this process, we introduce the Stateful Reflective Decision Process, which models reflective learning as a two stage read write interaction with episodic memory. Writing stores interaction outcomes and corresponds to policy evaluation, while reading retrieves relevant past cases and corresponds to policy improvement. We show that this process induces an equivalent Markov decision process over augmented state memory representations, allowing the use of classical tools from dynamic programming and reinforcement learning. We further instantiate the framework using entropy regularised policy iteration and establish convergence guarantees. As episodic memory grows and achieves sufficient coverage of the state space, the resulting policy converges to the optimal solution. This work provides a principled foundation for memory augmented and retrieval based language model agents capable of continual adaptation without parameter updates.

</details>


### [32] [SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning](https://arxiv.org/abs/2512.22895)
*Xiaotian Ren,Nuerxiati Abudurexiti,Zhengyong Jiang,Angelos Stefanidis,Hongbin Liu,Jionglong Su*

Main category: cs.AI

TL;DR: 提出SAMP-HDRL框架，通过分层深度强化学习解决非平稳市场中的投资组合优化问题，结合动态资产分组、多层次决策和基于效用的资本分配机制，在波动市场中显著超越传统方法和DRL基准。


<details>
  <summary>Details</summary>
Motivation: 非平稳市场中的投资组合优化面临三大挑战：市场机制转换、动态相关性变化，以及深度强化学习策略缺乏可解释性。现有方法难以同时处理这些复杂问题。

Method: 提出SAMP-HDRL框架：1) 动态资产分组将市场划分为高质量和普通子集；2) 上层代理提取全局市场信号；3) 下层代理在掩码约束下进行组内分配；4) 基于效用的资本分配机制整合风险资产和无风险资产，确保全局与局部决策的协调。

Result: 在2019-2021年三种市场机制下的回测显示，SAMP-HDRL持续优于9个传统基线和9个DRL基准。相比最强基线，至少获得5%更高回报率、5%更高夏普比率、5%更高索提诺比率和2%更高Omega比率，在动荡市场中收益更大。

Conclusion: SAMP-HDRL将结构性市场约束直接嵌入DRL流程，在复杂金融环境中提供更好的适应性、鲁棒性和可解释性。消融研究证实上层-下层协调、动态聚类和资本分配对鲁棒性不可或缺，SHAP分析揭示了跨代理的"分散+集中"互补机制。

Abstract: Portfolio optimization in non-stationary markets is challenging due to regime shifts, dynamic correlations, and the limited interpretability of deep reinforcement learning (DRL) policies. We propose a Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning (SAMP-HDRL). The framework first applies dynamic asset grouping to partition the market into high-quality and ordinary subsets. An upper-level agent extracts global market signals, while lower-level agents perform intra-group allocation under mask constraints. A utility-based capital allocation mechanism integrates risky and risk-free assets, ensuring coherent coordination between global and local decisions. backtests across three market regimes (2019--2021) demonstrate that SAMP-HDRL consistently outperforms nine traditional baselines and nine DRL benchmarks under volatile and oscillating conditions. Compared with the strongest baseline, our method achieves at least 5\% higher Return, 5\% higher Sharpe ratio, 5\% higher Sortino ratio, and 2\% higher Omega ratio, with substantially larger gains observed in turbulent markets. Ablation studies confirm that upper--lower coordination, dynamic clustering, and capital allocation are indispensable to robustness. SHAP-based interpretability further reveals a complementary ``diversified + concentrated'' mechanism across agents, providing transparent insights into decision-making. Overall, SAMP-HDRL embeds structural market constraints directly into the DRL pipeline, offering improved adaptability, robustness, and interpretability in complex financial environments.

</details>


### [33] [HiSciBench: A Hierarchical Multi-disciplinary Benchmark for Scientific Intelligence from Reading to Discovery](https://arxiv.org/abs/2512.22899)
*Yaping Zhang,Qixuan Zhang,Xingquan Zhang,Zhiyuan Chen,Wenwen Zhuang,Yupu Liang,Lu Xiang,Yang Zhao,Jiajun Zhang,Yu Zhou,Chengqing Zong*

Main category: cs.AI

TL;DR: HiSciBench是一个分层科学智能基准测试，包含5个层级、8,735个实例，覆盖6个学科，评估大模型在完整科学工作流程中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有科学AI基准测试过于碎片化，专注于狭窄任务，无法反映真实科学研究的层次性和多学科性，需要更全面的评估框架来评估基础模型在完整科学工作流程中的能力。

Method: 设计分层基准HiSciBench，包含5个层级：科学素养(L1)、文献解析(L2)、基于文献的问答(L3)、文献综述生成(L4)、科学发现(L5)。涵盖6个主要学科（数学、物理、化学、生物、地理、天文），支持多模态输入（文本、公式、图表）和跨语言评估，共8,735个实例。

Result: 对GPT-5、DeepSeek-R1等领先模型的评估显示显著性能差距：在基础素养任务上准确率可达69%，但在发现级挑战上骤降至25%，揭示了模型在高级科学推理能力上的不足。

Conclusion: HiSciBench为评估科学智能设立了新标准，提供了可操作的见解，有助于开发更强大可靠的科学AI模型，并将公开释放以促进未来研究。

Abstract: The rapid advancement of large language models (LLMs) and multimodal foundation models has sparked growing interest in their potential for scientific research. However, scientific intelligence encompasses a broad spectrum of abilities ranging from understanding fundamental knowledge to conducting creative discovery, and existing benchmarks remain fragmented. Most focus on narrow tasks and fail to reflect the hierarchical and multi-disciplinary nature of real scientific inquiry. We introduce \textbf{HiSciBench}, a hierarchical benchmark designed to evaluate foundation models across five levels that mirror the complete scientific workflow: \textit{Scientific Literacy} (L1), \textit{Literature Parsing} (L2), \textit{Literature-based Question Answering} (L3), \textit{Literature Review Generation} (L4), and \textit{Scientific Discovery} (L5). HiSciBench contains 8,735 carefully curated instances spanning six major scientific disciplines, including mathematics, physics, chemistry, biology, geography, and astronomy, and supports multimodal inputs including text, equations, figures, and tables, as well as cross-lingual evaluation. Unlike prior benchmarks that assess isolated abilities, HiSciBench provides an integrated, dependency-aware framework that enables detailed diagnosis of model capabilities across different stages of scientific reasoning. Comprehensive evaluations of leading models, including GPT-5, DeepSeek-R1, and several multimodal systems, reveal substantial performance gaps: while models achieve up to 69\% accuracy on basic literacy tasks, performance declines sharply to 25\% on discovery-level challenges. HiSciBench establishes a new standard for evaluating scientific Intelligence and offers actionable insights for developing models that are not only more capable but also more reliable. The benchmark will be publicly released to facilitate future research.

</details>


### [34] [Geometric Structural Knowledge Graph Foundation Model](https://arxiv.org/abs/2512.22931)
*Ling Xin,Mojtaba Nayyeri,Zahra Makki Nayeri,Steffen Staab*

Main category: cs.AI

TL;DR: Gamma提出多头部几何注意力知识图谱基础模型，通过多种代数变换（实数、复数、分裂复数、对偶数）建模不同关系结构，并采用关系条件注意力融合机制自适应组合，在零样本归纳链接预测上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱基础模型（如Ultra）依赖单一关系变换（如逐元素乘法），限制了表达能力，无法捕捉多样化图谱中展现的不同关系和结构模式。

Method: 提出Gamma模型，采用多头部几何注意力：1）使用多种并行代数变换（实数、复数、分裂复数、对偶数）建模不同关系结构；2）设计关系条件注意力融合机制，通过轻量级门控和熵正则化在链接级别自适应融合这些变换；3）提供完整的代数消息函数形式化。

Result: 在56个多样化知识图谱上的实验表明，Gamma在零样本归纳链接预测中持续优于Ultra：在归纳基准上平均倒数排名提升5.5%，在所有基准上提升4.4%，证明了互补几何表示的优势。

Conclusion: Gamma通过引入多头部几何注意力和自适应融合机制，增强了知识图谱基础模型的表达能力，能够更好地捕捉多样化关系结构，在零样本归纳推理任务上取得了显著改进。

Abstract: Structural knowledge graph foundation models aim to generalize reasoning to completely new graphs with unseen entities and relations. A key limitation of existing approaches like Ultra is their reliance on a single relational transformation (e.g., element-wise multiplication) in message passing, which can constrain expressiveness and fail to capture diverse relational and structural patterns exhibited on diverse graphs. In this paper, we propose Gamma, a novel foundation model that introduces multi-head geometric attention to knowledge graph reasoning. Gamma replaces the single relational transformation with multiple parallel ones, including real, complex, split-complex, and dual number based transformations, each designed to model different relational structures. A relational conditioned attention fusion mechanism then adaptively fuses them at link level via a lightweight gating with entropy regularization, allowing the model to robustly emphasize the most appropriate relational bias for each triple pattern. We present a full formalization of these algebraic message functions and discuss how their combination increases expressiveness beyond any single space. Comprehensive experiments on 56 diverse knowledge graphs demonstrate that Gamma consistently outperforms Ultra in zero-shot inductive link prediction, with a 5.5% improvement in mean reciprocal rank on the inductive benchmarks and a 4.4% improvement across all benchmarks, highlighting benefits from complementary geometric representations.

</details>


### [35] [Multimodal Fact-Checking: An Agent-based Approach](https://arxiv.org/abs/2512.22933)
*Danni Xu,Shaojing Fan,Xuanang Cheng,Mohan Kankanhalli*

Main category: cs.AI

TL;DR: 提出了RW-Post数据集和AgentFact框架，用于解决多模态虚假信息检测中缺乏真实场景数据和推理过程的问题，通过代理协作模拟人类事实核查流程，显著提升了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态虚假信息快速传播，现有方法（如大型视觉语言模型和深度多模态融合）存在推理能力有限和证据利用不足的问题。关键瓶颈是缺乏包含完整真实世界多模态虚假信息实例、标注推理过程和可验证证据的专用数据集。

Method: 1) 构建RW-Post数据集：将真实世界多模态声明与其原始社交媒体帖子对齐，保留丰富的上下文信息；通过大语言模型辅助提取流程，从人工撰写的事实核查文章中获取详细推理和明确链接的证据。2) 提出AgentFact框架：基于代理的多模态事实核查框架，模拟人类验证工作流程，包含五个专门代理（策略规划、高质量证据检索、视觉分析、推理、解释生成），通过迭代工作流在证据搜索与任务感知的证据过滤和推理之间交替进行。

Result: 广泛的实验结果表明，RW-Post数据集和AgentFact框架之间的协同作用显著提高了多模态事实核查的准确性和可解释性。

Conclusion: 该研究通过构建高质量可解释数据集和代理协作框架，有效解决了多模态虚假信息检测中的关键挑战，为自动化事实核查系统提供了更可靠和透明的解决方案。

Abstract: The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottleneck is the lack of dedicated datasets that provide complete real-world multimodal misinformation instances accompanied by annotated reasoning processes and verifiable evidence. To address this limitation, we introduce RW-Post, a high-quality and explainable dataset for real-world multimodal fact-checking. RW-Post aligns real-world multimodal claims with their original social media posts, preserving the rich contextual information in which the claims are made. In addition, the dataset includes detailed reasoning and explicitly linked evidence, which are derived from human written fact-checking articles via a large language model assisted extraction pipeline, enabling comprehensive verification and explanation. Building upon RW-Post, we propose AgentFact, an agent-based multimodal fact-checking framework designed to emulate the human verification workflow. AgentFact consists of five specialized agents that collaboratively handle key fact-checking subtasks, including strategy planning, high-quality evidence retrieval, visual analysis, reasoning, and explanation generation. These agents are orchestrated through an iterative workflow that alternates between evidence searching and task-aware evidence filtering and reasoning, facilitating strategic decision-making and systematic evidence analysis. Extensive experimental results demonstrate that the synergy between RW-Post and AgentFact substantially improves both the accuracy and interpretability of multimodal fact-checking.

</details>


### [36] [Problems With Large Language Models for Learner Modelling: Why LLMs Alone Fall Short for Responsible Tutoring in K--12 Education](https://arxiv.org/abs/2512.23036)
*Danial Hooshyar,Yeongwook Yang,Gustav Šíř,Tommi Kärkkäinen,Raija Hämäläinen,Mutlu Cukurova,Roger Azevedo*

Main category: cs.AI

TL;DR: LLM导师在K-12教育中无法替代传统学习者建模，知识追踪模型在准确性、可靠性和时间一致性上显著优于LLM


<details>
  <summary>Details</summary>
Motivation: 针对LLM导师可能替代传统学习者建模的误解，特别是在欧盟AI法案将K-12教育列为高风险领域的背景下，研究LLM在评估学习者知识演变方面的局限性

Method: 比较深度知识追踪(DKT)模型与广泛使用的LLM（零样本和微调版本），使用大型开放数据集，评估准确性、可靠性和时间一致性

Result: DKT在下一步正确性预测上表现最佳(AUC=0.83)，始终优于LLM；微调使LLM的AUC提高8%，但仍比DKT低6%，且产生更多早期序列错误；DKT保持稳定、方向正确的掌握度更新，而LLM变体存在显著时间弱点

Conclusion: LLM单独使用难以匹敌现有智能辅导系统的效果，负责任的辅导需要结合学习者建模的混合框架

Abstract: The rapid rise of large language model (LLM)-based tutors in K--12 education has fostered a misconception that generative models can replace traditional learner modelling for adaptive instruction. This is especially problematic in K--12 settings, which the EU AI Act classifies as high-risk domain requiring responsible design. Motivated by these concerns, this study synthesises evidence on limitations of LLM-based tutors and empirically investigates one critical issue: the accuracy, reliability, and temporal coherence of assessing learners' evolving knowledge over time. We compare a deep knowledge tracing (DKT) model with a widely used LLM, evaluated zero-shot and fine-tuned, using a large open-access dataset. Results show that DKT achieves the highest discrimination performance (AUC = 0.83) on next-step correctness prediction and consistently outperforms the LLM across settings. Although fine-tuning improves the LLM's AUC by approximately 8\% over the zero-shot baseline, it remains 6\% below DKT and produces higher early-sequence errors, where incorrect predictions are most harmful for adaptive support. Temporal analyses further reveal that DKT maintains stable, directionally correct mastery updates, whereas LLM variants exhibit substantial temporal weaknesses, including inconsistent and wrong-direction updates. These limitations persist despite the fine-tuned LLM requiring nearly 198 hours of high-compute training, far exceeding the computational demands of DKT. Our qualitative analysis of multi-skill mastery estimation further shows that, even after fine-tuning, the LLM produced inconsistent mastery trajectories, while DKT maintained smooth and coherent updates. Overall, the findings suggest that LLMs alone are unlikely to match the effectiveness of established intelligent tutoring systems, and that responsible tutoring requires hybrid frameworks that incorporate learner modelling.

</details>


### [37] [The Reward Model Selection Crisis in Personalized Alignment](https://arxiv.org/abs/2512.23067)
*Fady Rezk,Yuangang Pan,Chuan-Sheng Foo,Xun Xu,Nancy Chen,Henry Gouk,Timothy Hospedales*

Main category: cs.AI

TL;DR: 传统奖励模型准确率无法预测个性化对齐在部署中的实际表现，需要新的评估指标和基准


<details>
  <summary>Details</summary>
Motivation: 当前个性化对齐研究过度关注奖励模型准确率，但忽略了在实际部署中需要通过奖励引导解码进行推理时适应，而非针对每个用户进行策略微调。这导致传统评估指标无法反映实际部署性能。

Method: 1) 提出策略准确率作为新评估指标，衡量奖励引导解码能否正确区分偏好与非偏好响应；2) 创建Pref-LaMP基准，包含真实用户完成数据，支持直接行为评估；3) 系统评估三个数据集，比较奖励模型准确率与策略准确率的关系；4) 对比奖励引导方法与上下文学习方法。

Result: 1) 奖励模型准确率与策略级区分能力相关性很弱（Kendall's tau = 0.08-0.31）；2) 在Pref-LaMP基准上，奖励模型准确率差异达20个百分点的模型产生几乎相同的输出质量；3) 即使区分能力高的方法也无法生成行为对齐的响应；4) 对于大于3B参数的模型，简单上下文学习优于所有奖励引导方法，在7B规模上ROUGE-1得分高出3-5个百分点。

Conclusion: 当前领域优化的代理指标无法预测部署性能，也无法在部署约束下将偏好转化为实际行为适应。需要重新思考个性化对齐的评估框架，关注实际部署条件下的行为表现而非单纯的奖励模型准确率。

Abstract: Personalized alignment from preference data has focused primarily on improving reward model (RM) accuracy, with the implicit assumption that better preference ranking translates to better personalized behavior. However, in deployment, computational constraints necessitate inference-time adaptation via reward-guided decoding (RGD) rather than per-user policy fine-tuning. This creates a critical but overlooked requirement: reward models must not only rank preferences accurately but also effectively guide token-level generation decisions. We demonstrate that standard RM accuracy fails catastrophically as a selection criterion for deployment-ready personalized alignment. Through systematic evaluation across three datasets, we introduce policy accuracy, a metric quantifying whether RGD scoring functions correctly discriminate between preferred and dispreferred responses. We show that RM accuracy correlates only weakly with this policy-level discrimination ability (Kendall's tau = 0.08--0.31). More critically, we introduce Pref-LaMP, the first personalized alignment benchmark with ground-truth user completions, enabling direct behavioral evaluation without circular reward-based metrics. On Pref-LaMP, we expose a complete decoupling between discrimination and generation: methods with 20-point RM accuracy differences produce almost identical output quality, and even methods achieving high discrimination fail to generate behaviorally aligned responses. Finally, simple in-context learning (ICL) dominates all reward-guided methods for models > 3B parameters, achieving 3-5 point ROUGE-1 gains over the best reward method at 7B scale. These findings show that the field optimizes proxy metrics that fail to predict deployment performance and do not translate preferences into real behavioral adaptation under deployment constraints.

</details>


### [38] [Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients](https://arxiv.org/abs/2512.23090)
*Armin Berger,Manuela Bergau,Helen Schneider,Saad Ahmad,Tom Anglim Lagones,Gianluca Brugnara,Martha Foltyn-Dumitru,Kai Schlamp,Philipp Vollmuth,Rafet Sifa*

Main category: cs.AI

TL;DR: ChexReason是一个通过R1风格方法（SFT+GRPO）训练的视觉语言模型，仅使用少量数据和单GPU，在医学影像推理任务中表现出分布内性能提升但跨数据集泛化下降的悖论。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型的强化学习在推理任务上取得进展，但在资源受限的医学影像应用中仍未被充分探索。研究者希望开发一个在有限计算资源下（仅2000个SFT样本、1000个RL样本、单A100 GPU）仍能有效工作的医学影像推理模型。

Method: 采用R1风格方法：先进行监督微调（SFT），然后使用GRPO（Group Relative Policy Optimization）进行强化学习。模型仅使用2000个SFT样本和1000个RL样本，在单个A100 GPU上训练。

Result: GRPO在分布内数据集（CheXpert）上性能提升23%（macro-F1=0.346），但在跨数据集（NIH）上性能下降19%。SFT检查点在RL优化前能独特地提升NIH性能，表明教师引导的推理能捕捉更多机构无关特征。结构化推理支架对通用VLM有益，但对医学预训练模型增益有限。

Conclusion: 对于需要跨不同人群鲁棒性的临床部署，精心策划的监督微调可能优于激进的强化学习。RL范式本身（而非模型规模）导致了泛化悖论，这在资源受限和高资源模型中都有体现。

Abstract: Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored. We introduce ChexReason, a vision-language model trained via R1-style methodology (SFT followed by GRPO) using only 2,000 SFT samples, 1,000 RL samples, and a single A100 GPU. Evaluations on CheXpert and NIH benchmarks reveal a fundamental tension: GRPO recovers in-distribution performance (23% improvement on CheXpert, macro-F1 = 0.346) but degrades cross-dataset transferability (19% drop on NIH). This mirrors high-resource models like NV-Reason-CXR-3B, suggesting the issue stems from the RL paradigm rather than scale. We identify a generalization paradox where the SFT checkpoint uniquely improves on NIH before optimization, indicating teacher-guided reasoning captures more institution-agnostic features. Furthermore, cross-model comparisons show structured reasoning scaffolds benefit general-purpose VLMs but offer minimal gain for medically pre-trained models. Consequently, curated supervised fine-tuning may outperform aggressive RL for clinical deployment requiring robustness across diverse populations.

</details>


### [39] [InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization](https://arxiv.org/abs/2512.23126)
*Yu Li,Tian Lan,Zhengling Qi*

Main category: cs.AI

TL;DR: 提出Intrinsic Self-reflective Preference Optimization (q)方法，解决DPO的两个根本限制：最优策略依赖任意建模选择，以及孤立处理响应生成未能利用成对数据中的比较信息。


<details>
  <summary>Details</summary>
Motivation: DPO及其变体已成为对齐大语言模型的标准方法，但存在两个根本限制：1) 最优策略依赖任意建模选择（标量化函数、参考策略），导致行为反映参数化伪影而非真实偏好；2) 孤立处理响应生成未能利用成对数据中的比较信息，未挖掘模型的内在自我反思能力。

Method: 提出Intrinsic Self-reflective Preference Optimization (q)，推导出基于上下文和替代响应的全局最优策略。该方法作为即插即用的增强，无需架构更改或推理开销，保证对标量化和参考选择的不变性。

Result: 实验证明在胜率和长度控制指标上持续改进，验证了解锁自我反思能力能产生更稳健、更符合人类对齐的LLM。

Conclusion: q方法优于DPO/RLHF，通过利用成对数据中的比较信息和内在自我反思，解决了DPO的根本限制，产生了更稳健、更符合人类对齐的语言模型。

Abstract: Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary modeling choices (scalarization function, reference policy), yielding behavior reflecting parameterization artifacts rather than true preferences. Second, treating response generation in isolation fails to leverage comparative information in pairwise data, leaving the model's capacity for intrinsic self-reflection untapped. To address it, we propose Intrinsic Self-reflective Preference Optimization (\q), deriving a globally optimal policy conditioning on both context and alternative responses. We prove this formulation superior to DPO/RLHF while guaranteeing invariance to scalarization and reference choices. \q~serves as a plug-and-play enhancement without architectural changes or inference overhead. Experiments demonstrate consistent improvements in win rates and length-controlled metrics, validating that unlocking self-reflection yields more robust, human-aligned LLMs.

</details>


### [40] [Why We Need a New Framework for Emotional Intelligence in AI](https://arxiv.org/abs/2512.23163)
*Max Parks,Kheli Atluru,Meera Vinod,Mike Kuniavsky,Jud Brewer,Sean White,Sarah Adler,Wendy Ju*

Main category: cs.AI

TL;DR: 论文认为现有AI情感智能评估框架需要改进，因为它们未能全面衡量AI相关的情感智能方面，并提出基于情感理论的新评估策略


<details>
  <summary>Details</summary>
Motivation: 当前评估AI情感智能的框架存在不足：1）未能充分考虑AI与人类情感智能的本质差异；2）缺乏坚实的情感理论基础；3）未能全面衡量AI相关的EI方面；4）现有基准框架存在局限性

Method: 1）回顾不同情感理论和一般EI理论，评估其在人工系统中的适用性；2）批判性评估现有基准框架，识别其在EI理论基础上的不足；3）提出改进评估策略的方案

Result: 识别出现有EI评估框架的主要缺陷：1）未能区分人类EI的现象学成分与AI可实现的EI方面；2）缺乏对情感本质的深入理解；3）评估范围不全面。提出了改进方向

Conclusion: 需要基于更坚实的情感理论重新设计AI情感智能评估框架，区分人类特有和AI可实现的EI方面，开发更全面、理论基础更扎实的评估策略

Abstract: In this paper, we develop the position that current frameworks for evaluating emotional intelligence (EI) in artificial intelligence (AI) systems need refinement because they do not adequately or comprehensively measure the various aspects of EI relevant in AI. Human EI often involves a phenomenological component and a sense of understanding that artificially intelligent systems lack; therefore, some aspects of EI are irrelevant in evaluating AI systems. However, EI also includes an ability to sense an emotional state, explain it, respond appropriately, and adapt to new contexts (e.g., multicultural), and artificially intelligent systems can do such things to greater or lesser degrees. Several benchmark frameworks specialize in evaluating the capacity of different AI models to perform some tasks related to EI, but these often lack a solid foundation regarding the nature of emotion and what it is to be emotionally intelligent. In this project, we begin by reviewing different theories about emotion and general EI, evaluating the extent to which each is applicable to artificial systems. We then critically evaluate the available benchmark frameworks, identifying where each falls short in light of the account of EI developed in the first section. Lastly, we outline some options for improving evaluation strategies to avoid these shortcomings in EI evaluation in AI systems.

</details>


### [41] [SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search](https://arxiv.org/abs/2512.23167)
*Yifan Zhang,Giridhar Ganapavarapu,Srideepika Jayaraman,Bhavna Agrawal,Dhaval Patel,Achille Fokoue*

Main category: cs.AI

TL;DR: SPIRAL是一个将三个专门化LLM代理嵌入MCTS循环的认知架构，通过规划-模拟-批判的协同工作，将MCTS从暴力搜索转变为引导式自校正推理过程，显著提升了复杂规划任务的性能。


<details>
  <summary>Details</summary>
Motivation: LLM在需要探索和自校正的复杂规划任务中表现不佳，因为其线性推理过程难以从早期错误中恢复。现有的搜索算法如MCTS在稀疏奖励下效果有限，且未能充分利用LLM的丰富语义能力。

Method: SPIRAL框架在MCTS循环中嵌入了三个专门化LLM代理：规划器提出创造性下一步，模拟器通过预测现实结果来接地搜索，批判器通过反思提供密集奖励信号。这种协同将MCTS转变为引导式自校正推理过程。

Result: 在DailyLifeAPIs和HuggingFace数据集上，SPIRAL持续优于默认的思维链规划方法和其他最先进代理。在DailyLifeAPIs上达到83.6%的总体准确率，比次优搜索框架提高了16个百分点以上，同时展示了更优的token效率。

Conclusion: 将LLM推理构建为引导式、反思性和接地气的搜索过程，能够产生更鲁棒和高效的自主规划器。这种结构化方法显著提升了复杂规划任务的性能。

Abstract: Large Language Models (LLMs) often falter at complex planning tasks that require exploration and self-correction, as their linear reasoning process struggles to recover from early mistakes. While search algorithms like Monte Carlo Tree Search (MCTS) can explore alternatives, they are often ineffective when guided by sparse rewards and fail to leverage the rich semantic capabilities of LLMs. We introduce SPIRAL (Symbolic LLM Planning via Grounded and Reflective Search), a novel framework that embeds a cognitive architecture of three specialized LLM agents into an MCTS loop. SPIRAL's key contribution is its integrated planning pipeline where a Planner proposes creative next steps, a Simulator grounds the search by predicting realistic outcomes, and a Critic provides dense reward signals through reflection. This synergy transforms MCTS from a brute-force search into a guided, self-correcting reasoning process. On the DailyLifeAPIs and HuggingFace datasets, SPIRAL consistently outperforms the default Chain-of-Thought planning method and other state-of-the-art agents. More importantly, it substantially surpasses other state-of-the-art agents; for example, SPIRAL achieves 83.6% overall accuracy on DailyLifeAPIs, an improvement of over 16 percentage points against the next-best search framework, while also demonstrating superior token efficiency. Our work demonstrates that structuring LLM reasoning as a guided, reflective, and grounded search process yields more robust and efficient autonomous planners. The source code, full appendices, and all experimental data are available for reproducibility at the official project repository.

</details>


### [42] [From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research](https://arxiv.org/abs/2512.23184)
*Hongshen Sun,Juanjuan Zhang*

Main category: cs.AI

TL;DR: 该论文提出"模型信念"概念，利用LLM的token级概率分布来替代传统的单一输出选择，能更高效地利用LLM生成数据，在需求估计实验中计算效率提升约20倍。


<details>
  <summary>Details</summary>
Motivation: 当前使用LLM模拟人类行为时，通常将模型的单一输出作为数据点，这未能充分利用LLM的概率特性。传统方法效率低下，需要大量计算资源才能获得准确估计。

Method: 提出并形式化"模型信念"概念，基于LLM的token级概率分布来衡量模型对不同选择替代方案的信念分布。证明模型信念与模型选择的均值渐近等价，但具有更低的方差和更快的收敛速度。

Result: 在需求估计研究中，模型信念能比模型选择本身更好地解释和预测真实模型选择。在有限运行次数下，模型信念将达到足够准确估计所需的计算量减少了约20倍。

Conclusion: 模型信念应作为从LLM生成数据中提取更多信息的默认测量方法，能显著提高统计效率和计算效率，为LLM模拟应用提供更优的数据利用方式。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior, but common practices to use LLM-generated data are inefficient. Treating an LLM's output ("model choice") as a single data point underutilizes the information inherent to the probabilistic nature of LLMs. This paper introduces and formalizes "model belief," a measure derived from an LLM's token-level probabilities that captures the model's belief distribution over choice alternatives in a single generation run. The authors prove that model belief is asymptotically equivalent to the mean of model choices (a non-trivial property) but forms a more statistically efficient estimator, with lower variance and a faster convergence rate. Analogous properties are shown to hold for smooth functions of model belief and model choice often used in downstream applications. The authors demonstrate the performance of model belief through a demand estimation study, where an LLM simulates consumer responses to different prices. In practical settings with limited numbers of runs, model belief explains and predicts ground-truth model choice better than model choice itself, and reduces the computation needed to reach sufficiently accurate estimates by roughly a factor of 20. The findings support using model belief as the default measure to extract more information from LLM-generated data.

</details>


### [43] [TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI](https://arxiv.org/abs/2512.23217)
*Jingming Li*

Main category: cs.AI

TL;DR: TCEval：首个基于热舒适场景的AI认知能力评估框架，测试跨模态推理、因果关联和自适应决策能力，发现当前LLM具备基础跨模态推理但缺乏对热舒适非线性关系的精确因果理解。


<details>
  <summary>Details</summary>
Motivation: 现有LLM任务特定基准存在关键空白，热舒适作为涉及环境因素与个人感知的复杂交互过程，是评估AI系统真实世界认知能力的理想范式。

Method: 提出TCEval框架，通过初始化具有虚拟人格属性的LLM代理，引导其生成服装隔热选择和热舒适反馈，并将输出与ASHRAE全球数据库和中国热舒适数据库进行验证。

Result: 实验显示LLM代理反馈与人类精确对齐有限，但在1 PMV容差下方向一致性显著改善；统计测试表明LLM生成的PMV分布与人类数据显著不同，在离散热舒适分类中表现接近随机。

Conclusion: TCEval作为生态有效的AI认知图灵测试可行，当前LLM具备基础跨模态推理能力但缺乏对热舒适变量间非线性关系的精确因果理解，将AI评估重点从抽象任务熟练度转向具身、情境感知的决策制定。

Abstract: A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. To address this, we propose TCEval, the first evaluation framework that assesses three core cognitive capacities of AI, cross-modal reasoning, causal association, and adaptive decision-making, by leveraging thermal comfort scenarios and large language model (LLM) agents. The methodology involves initializing LLM agents with virtual personality attributes, guiding them to generate clothing insulation selections and thermal comfort feedback, and validating outputs against the ASHRAE Global Database and Chinese Thermal Comfort Database. Experiments on four LLMs show that while agent feedback has limited exact alignment with humans, directional consistency improves significantly with a 1 PMV tolerance. Statistical tests reveal that LLM-generated PMV distributions diverge markedly from human data, and agents perform near-randomly in discrete thermal comfort classification. These results confirm the feasibility of TCEval as an ecologically valid Cognitive Turing Test for AI, demonstrating that current LLMs possess foundational cross-modal reasoning ability but lack precise causal understanding of the nonlinear relationships between variables in thermal comfort. TCEval complements traditional benchmarks, shifting AI evaluation focus from abstract task proficiency to embodied, context-aware perception and decision-making, offering valuable insights for advancing AI in human-centric applications like smart buildings.

</details>


### [44] [Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control](https://arxiv.org/abs/2512.23292)
*Yoonpyo Lee,Kazuma Kobayashi,Sai Puppala,Sajedul Talukder,Seid Koric,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.AI

TL;DR: 该论文提出了一种新的物理AI范式，通过基于物理验证的策略优化而非感知推理，训练紧凑的语言模型作为Agentic Physical AI，在反应堆控制任务中实现了从高方差模仿到稳定执行的相变。


<details>
  <summary>Details</summary>
Motivation: 当前通用基础模型在物理系统控制方面存在根本性障碍，即使前沿的视觉语言模型在基本定量物理任务上准确率也只有50-53%，它们更像是近似猜测器，保持了语义合理性但违反了物理约束。这种输入不忠实性不是规模缺陷而是结构限制，感知中心架构优化参数空间模仿，而安全关键控制需要对执行动作的结果空间保证。

Method: 提出了一种完全不同的领域特定基础模型路径，引入紧凑语言模型作为Agentic Physical AI，其中策略优化由基于物理的验证驱动而非感知推理。训练了一个3.6亿参数模型在合成反应堆控制场景上，将数据集从10^3扩展到10^5个示例。

Result: 该方法诱导了通用模型中不存在的急剧相变：小规模系统表现出高方差模仿和灾难性尾部风险，而大规模模型经历了超过500倍减少的方差崩溃，稳定了执行级行为。尽管平衡暴露于四种驱动家族，模型自主拒绝了约70%的训练分布，并将95%的运行时执行集中在单一策略上。学习到的表示可以在不同物理和连续输入模态间迁移而无需架构修改。

Conclusion: 该研究展示了通过基于物理验证的策略优化而非感知推理，可以构建紧凑但高效的Agentic Physical AI模型，这些模型在控制任务中表现出从高方差模仿到稳定执行的相变，并具有良好的迁移能力，为物理系统AI控制提供了新范式。

Abstract: The prevailing paradigm in AI for physical systems, scaling general-purpose foundation models toward universal multimodal reasoning, confronts a fundamental barrier at the control interface. Recent benchmarks show that even frontier vision-language models achieve only 50-53% accuracy on basic quantitative physics tasks, behaving as approximate guessers that preserve semantic plausibility while violating physical constraints. This input unfaithfulness is not a scaling deficiency but a structural limitation. Perception-centric architectures optimize parameter-space imitation, whereas safety-critical control demands outcome-space guarantees over executed actions. Here, we present a fundamentally different pathway toward domain-specific foundation models by introducing compact language models operating as Agentic Physical AI, in which policy optimization is driven by physics-based validation rather than perceptual inference. We train a 360-million-parameter model on synthetic reactor control scenarios, scaling the dataset from 10^3 to 10^5 examples. This induces a sharp phase transition absent in general-purpose models. Small-scale systems exhibit high-variance imitation with catastrophic tail risk, while large-scale models undergo variance collapse exceeding 500x reduction, stabilizing execution-level behavior. Despite balanced exposure to four actuation families, the model autonomously rejects approximately 70% of the training distribution and concentrates 95% of runtime execution on a single-bank strategy. Learned representations transfer across distinct physics and continuous input modalities without architectural modification.

</details>


### [45] [On Conformant Planning and Model-Checking of $\exists^*\forall^*$ Hyperproperties](https://arxiv.org/abs/2512.23324)
*Raven Beutner,Bernd Finkbeiner*

Main category: cs.AI

TL;DR: 论文揭示了符合性规划与超属性模型检测之间的紧密联系，两者可以相互高效转换。


<details>
  <summary>Details</summary>
Motivation: 研究规划与验证领域中两个重要问题之间的联系：符合性规划（寻找独立于非确定性动作效果的顺序计划）和超属性模型检测（涉及多个执行轨迹的系统属性）。

Method: 1. 展示如何将超属性模型检测实例高效地约简为符合性规划实例，并证明编码的正确性和完备性。2. 建立相反方向：证明每个符合性规划问题本身就是一个超属性模型检测任务。

Result: 证明了∃*∀*超属性模型检测与符合性规划计算问题之间的紧密联系，两者可以相互高效转换。

Conclusion: 符合性规划和超属性模型检测在本质上密切相关，这一发现为两个领域提供了新的视角和工具，可以相互借鉴技术和方法。

Abstract: We study the connection of two problems within the planning and verification community: Conformant planning and model-checking of hyperproperties. Conformant planning is the task of finding a sequential plan that achieves a given objective independent of non-deterministic action effects during the plan's execution. Hyperproperties are system properties that relate multiple execution traces of a system and, e.g., capture information-flow and fairness policies. In this paper, we show that model-checking of $\exists^*\forall^*$ hyperproperties is closely related to the problem of computing a conformant plan. Firstly, we show that we can efficiently reduce a hyperproperty model-checking instance to a conformant planning instance, and prove that our encoding is sound and complete. Secondly, we establish the converse direction: Every conformant planning problem is, itself, a hyperproperty model-checking task.

</details>


### [46] [CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations](https://arxiv.org/abs/2512.23328)
*Huan-ang Gao,Zikang Zhang,Tianwei Luo,Kaisen Yang,Xinzhe Juan,Jiahao Qiu,Tianxing Chen,Bingxiang He,Hao Zhao,Hao Zhou,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: 论文提出CubeBench基准测试，使用魔方评估LLM智能体的空间推理能力，发现现有模型在长时程任务上完全失败（0%通过率），揭示了物理世界部署的关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在数字领域表现出色，但在物理世界部署存在显著差距，主要挑战在于建立和维护稳健的空间心理模型。论文识别了三个核心认知挑战：空间推理、通过心理模拟进行长时程状态跟踪，以及在部分观察下的主动探索。

Method: 引入CubeBench基准测试，采用三层诊断框架：1）具有完整符号信息的基础状态跟踪；2）逐步增加复杂性；3）仅使用部分视觉数据的主动探索。通过为LLM提供外部求解器工具来隔离认知瓶颈。

Result: 实验显示领先LLM存在严重限制，在所有长时程任务上通过率均为0.00%，暴露了长期规划的根本性失败。通过分析失败模式，揭示了空间推理和状态跟踪的具体瓶颈。

Conclusion: CubeBench有效诊断了LLM在物理世界部署中的认知瓶颈，为开发更物理接地气的智能体提供了关键见解。现有模型在长时程空间推理任务上存在根本性缺陷，需要新的方法来解决这些挑战。

Abstract: Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered on the Rubik's Cube. CubeBench uses a three-tiered diagnostic framework that progressively assesses agent capabilities, from foundational state tracking with full symbolic information to active exploration with only partial visual data. Our experiments on leading LLMs reveal critical limitations, including a uniform 0.00% pass rate on all long-horizon tasks, exposing a fundamental failure in long-term planning. We also propose a diagnostic framework to isolate these cognitive bottlenecks by providing external solver tools. By analyzing the failure modes, we provide key insights to guide the development of more physically-grounded intelligent agents.

</details>


### [47] [MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning](https://arxiv.org/abs/2512.23412)
*Jiawei Chen,Xintian Shen,Lihao Zheng,Zhenwei Shao,Hongyuan Zhang,Pengfei Yu,Xudong Rao,Ning Mao,Xiaobo Liu,Lian Wen,Chaoqun Du,Feng Gu,Wei He,Qizhen Li,Shanshan Li,Zide Liu,Jing Luo,Lifu Mu,Xuhao Pan,Chang Ren,Haoyi Sun,Qian Wang,Wei Wang,Hongfu Yang,Jiqing Zhan,Chunpeng Zhou,Zheng Zhou,Hao Ma,Tao Wei,Pan Zhou,Wei Chen*

Main category: cs.AI

TL;DR: MindWatcher是一个集成交替思考和多模态思维链推理的工具集成推理智能体，能够自主决定是否及如何调用多样化工具，无需人工提示或工作流，在复杂决策任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统基于工作流的智能体在解决需要工具调用的现实问题时智能有限，而能够自主推理和工具调用的工具集成推理智能体正在成为处理复杂决策任务的有力方法。

Method: 引入MindWatcher智能体，集成交替思考和多模态思维链推理；构建自动化数据审计和评估流水线，使用手动策划的高质量数据集训练；配备全面的辅助推理工具套件；建立大规模高质量的本地图像检索数据库；设计更高效的训练基础设施。

Result: MindWatcher通过卓越的工具调用能力，匹配甚至超越了更大或更新模型的表现；实验揭示了智能体训练的关键见解，如智能体强化学习中的遗传继承现象。

Conclusion: MindWatcher作为一个工具集成推理智能体，能够有效处理广泛领域的多模态问题，通过交替思考和多模态推理实现精确的工具调用和协调，为复杂决策任务提供了强大的解决方案。

Abstract: Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.

</details>


### [48] [The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis](https://arxiv.org/abs/2512.23419)
*Alex Lewandowski,Adtiya A. Ramesh,Edan Meyer,Dale Schuurmans,Marlos C. Machado*

Main category: cs.AI

TL;DR: 论文提出了一种计算嵌入视角，将智能体视为在通用计算机中模拟的自动机，并引入"交互性"作为衡量智能体持续适应能力的指标。研究发现深度非线性网络难以维持交互性，而深度线性网络随着容量增加能维持更高的交互性。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习问题通常通过显式约束智能体容量来模拟"世界大于智能体"的大世界假设，但这些约束可能具有随意性、难以整合，且限制了智能体容量扩展的有效性。本文旨在从计算嵌入视角重新定义这一问题。

Method: 提出计算嵌入视角，将嵌入智能体表示为在通用计算机中模拟的自动机，证明其等价于与可数无限状态空间上的部分可观测马尔可夫决策过程交互的智能体。提出"交互性"作为目标函数，并开发基于模型的强化学习算法来寻求交互性。

Result: 构建合成问题评估持续学习能力，结果显示深度非线性网络难以维持交互性，而深度线性网络随着容量增加能维持更高的交互性。

Conclusion: 计算嵌入视角为持续学习提供了新的理论基础，交互性作为衡量持续适应能力的指标具有实际意义。网络架构对持续学习能力有重要影响，线性网络在某些情况下可能比非线性网络更适合持续学习任务。

Abstract: Continual learning is often motivated by the idea, known as the big world hypothesis, that "the world is bigger" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative to the environment. These constraints lead to solutions in which the agent continually adapts to best use its limited capacity, rather than converging to a fixed solution. However, explicit constraints can be ad hoc, difficult to incorporate, and may limit the effectiveness of scaling up the agent's capacity. In this paper, we characterize a problem setting in which an agent, regardless of its capacity, is constrained by being embedded in the environment. In particular, we introduce a computationally-embedded perspective that represents an embedded agent as an automaton simulated within a universal (formal) computer. Such an automaton is always constrained; we prove that it is equivalent to an agent that interacts with a partially observable Markov decision process over a countably infinite state-space. We propose an objective for this setting, which we call interactivity, that measures an agent's ability to continually adapt its behaviour by learning new predictions. We then develop a model-based reinforcement learning algorithm for interactivity-seeking, and use it to construct a synthetic problem to evaluate continual learning capability. Our results show that deep nonlinear networks struggle to sustain interactivity, whereas deep linear networks sustain higher interactivity as capacity increases.

</details>


### [49] [AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis](https://arxiv.org/abs/2512.23424)
*Jinye Du,Quan Yuan,Zuyao Zhang,Yanzhi Yi,Jiahui Hu,Wangyi Chen,Yiyang Zhu,Qishui Zheng,Wenxiang Zou,Xiangyu Chang,Zuohe Zheng,Zichun Ye,Chao Liu,Shanni Li,Renwei Zhang,Yiping Deng,Xinwei Hu,Xuefeng Jin,Jie Zhao*

Main category: cs.AI

TL;DR: AKG kernel agent是一个多智能体系统，利用LLM代码生成能力自动化AI计算内核的开发、迁移和性能调优，支持多种DSL语言，在GPU和NPU后端上相比PyTorch Eager实现平均加速1.46倍。


<details>
  <summary>Details</summary>
Motivation: 现代AI模型对高性能计算内核需求巨大，但LLM、多模态架构、推荐系统等复杂性增加，加上稀疏化、量化等技术，以及硬件频繁更新和多样化架构，使得手动优化无法满足需求，成为AI系统开发的关键瓶颈。

Method: 提出AKG kernel agent多智能体系统，利用LLM代码生成能力自动化内核生成、迁移和性能调优。系统支持多种领域特定语言（DSL），包括Triton、TileLang、CPP和CUDA-C，模块化设计可快速集成新DSL和硬件目标。

Result: 在KernelBench上使用Triton DSL评估，在GPU和NPU后端上，AKG kernel agent相比PyTorch Eager基线实现平均加速1.46倍，证明了其在加速现代AI工作负载内核开发方面的有效性。

Conclusion: AKG kernel agent通过自动化内核开发流程，解决了AI系统开发中的关键瓶颈，能够适应快速变化的硬件环境和多样化的计算需求，为现代AI工作负载提供高效的计算内核解决方案。

Abstract: Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse chip architectures further complicate this landscape, requiring tailored kernel implementations for each platform. However, manual optimization cannot keep pace with these demands, creating a critical bottleneck in AI system development. Recent advances in LLM code generation capabilities have opened new possibilities for automating kernel development. In this work, we propose AKG kernel agent (AI-driven Kernel Generator), a multi-agent system that automates kernel generation, migration, and performance tuning. AKG kernel agent is designed to support multiple domain-specific languages (DSLs), including Triton, TileLang, CPP, and CUDA-C, enabling it to target different hardware backends while maintaining correctness and portability. The system's modular design allows rapid integration of new DSLs and hardware targets. When evaluated on KernelBench using Triton DSL across GPU and NPU backends, AKG kernel agent achieves an average speedup of 1.46$\times$ over PyTorch Eager baselines implementations, demonstrating its effectiveness in accelerating kernel development for modern AI workloads.

</details>


### [50] [Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2512.23457)
*Kongcheng Zhang,Qi Yao,Shunyu Liu,Wenjian Zhang,Min Cen,Yang Zhou,Wenkai Fang,Yiru Zhao,Baisheng Lai,Mingli Song*

Main category: cs.AI

TL;DR: HiR提出了一种基于后见之明重放的样本高效强化学习框架，通过选择-重写策略将失败尝试重放为成功样本，解决了复杂指令跟随任务中奖励稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在复杂指令跟随任务中面临挑战：初始模型能力有限，难以生成满足所有约束的响应，导致奖励稀疏或难以区分，阻碍学习效率。

Method: 采用选择-重写策略：1) 选择部分满足约束的失败尝试；2) 基于已满足的约束重写为成功样本；3) 在原始样本和重放样本上进行RL训练，理论框架为指令级和响应级的双重偏好学习。

Result: 实验表明HiR在不同指令跟随任务上取得显著效果，同时需要更少的计算资源。代码和数据集已开源。

Conclusion: HiR通过后见之明重放机制有效解决了RL在复杂指令跟随任务中的奖励稀疏问题，实现了样本高效的学习。

Abstract: Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.

</details>


### [51] [The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction](https://arxiv.org/abs/2512.23489)
*Haoyu Pei,Zhongyang Liu,Xiangyi Xiao,Xiaocong Du,Haipeng Zhang,Kunpeng Zhang,Suting Hong*

Main category: cs.AI

TL;DR: MIRAGE-VC：一个用于风险投资预测的多视角检索增强生成框架，通过信息增益驱动的路径检索和多智能体架构解决图路径爆炸和异构证据融合问题，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 风险投资预测需要综合复杂的图关系证据（公司披露、投资者记录、投资网络结构）并进行显式推理，但传统机器学习、图神经网络和现有图-LLM方法都无法有效处理这种"图外预测"任务。

Method: 提出MIRAGE-VC框架：1）信息增益驱动的路径检索器迭代选择高价值邻居，将投资网络压缩为紧凑链；2）多智能体架构通过可学习的门控机制整合三个证据流（公司属性、投资者记录、网络结构）；3）严格的反泄漏控制确保评估可靠性。

Result: 在严格的反泄漏控制下，MIRAGE-VC实现了F1分数提升5.0%，Precision@5提升16.6%，显著优于基线方法，并为推荐系统和风险评估等其他图外预测任务提供了启示。

Conclusion: MIRAGE-VC成功解决了风险投资预测中的路径爆炸和异构证据融合问题，通过显式推理和可解释的投资论据生成，为图外预测任务提供了有效的框架，代码已开源。

Abstract: Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form coherent, interpretable investment theses. Traditional machine learning and graph neural networks both lack this reasoning capability. Large language models (LLMs) offer strong reasoning but face a modality mismatch with graphs. Recent graph-LLM methods target in-graph tasks where answers lie within the graph, whereas VC prediction is off-graph: the target exists outside the network. The core challenge is selecting graph paths that maximize predictor performance on an external objective while enabling step-by-step reasoning. We present MIRAGE-VC, a multi-perspective retrieval-augmented generation framework that addresses two obstacles: path explosion (thousands of candidate paths overwhelm LLM context) and heterogeneous evidence fusion (different startups need different analytical emphasis). Our information-gain-driven path retriever iteratively selects high-value neighbors, distilling investment networks into compact chains for explicit reasoning. A multi-agent architecture integrates three evidence streams via a learnable gating mechanism based on company attributes. Under strict anti-leakage controls, MIRAGE-VC achieves +5.0% F1 and +16.6% PrecisionAt5, and sheds light on other off-graph prediction tasks such as recommendation and risk assessment. Code: https://anonymous.4open.science/r/MIRAGE-VC-323F.

</details>


### [52] [Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities](https://arxiv.org/abs/2512.23508)
*Alessio Benavoli,Alessandro Facchini,Marco Zaffalon*

Main category: cs.AI

TL;DR: 论文探讨如何确保AI系统与人类价值观对齐并保持安全，通过AI辅助和AI关机游戏框架研究，提出需要AI能处理不确定性和非阿基米德偏好


<details>
  <summary>Details</summary>
Motivation: 确保AI系统与人类价值观对齐并保持安全是重要挑战，需要研究AI如何帮助人类最大化效用函数，同时正确处理关机问题

Method: 使用AI辅助问题和AI关机游戏框架，要求AI系统能够处理不确定性和非阿基米德偏好，学习人类效用函数并正确处理关机指令

Result: 分析表明解决AI对齐和安全问题需要AI具备在不确定性下推理的能力，并能处理不完全和非阿基米德偏好

Conclusion: 确保AI安全和对齐需要开发能够处理不确定性和复杂偏好的AI系统，这是实现可靠AI辅助和正确关机行为的关键

Abstract: How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.

</details>


### [53] [Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation](https://arxiv.org/abs/2512.23601)
*Manh Hung Nguyen,Adish Singla*

Main category: cs.AI

TL;DR: 提出CreativeDC方法，通过两阶段提示解耦创造性探索与约束满足，解决LLM生成教育问题时存在的"人工蜂群思维"效应，显著提升问题多样性、新颖性和实用性。


<details>
  <summary>Details</summary>
Motivation: LLM在教育问题生成方面潜力巨大，但存在"人工蜂群思维"效应，导致同一模型内和不同模型间生成相似响应，学生接触重复性问题会损害思维多样性。

Method: 基于Wallas创造力理论和Guilford发散-收敛思维框架，提出CreativeDC两阶段提示方法：将LLM推理分为不同阶段，解耦创造性探索和约束满足，让LLM在确定最终问题前探索更广泛的想法空间。

Result: CreativeDC在多样性、新颖性和实用性综合评估中显著优于基线方法，能生成更多有效不同问题，且随着采样增加，有效不同问题数量以更快速度增长。

Conclusion: CreativeDC通过结构化提示方法有效缓解LLM的"人工蜂群思维"问题，为教育领域生成多样化、高质量的学习材料提供了可行解决方案。

Abstract: Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same model and produce homogeneous outputs across different models. As a consequence, students may be exposed to overly similar and repetitive LLM-generated problems, which harms diversity of thought. Drawing inspiration from Wallas's theory of creativity and Guilford's framework of divergent-convergent thinking, we propose CreativeDC, a two-phase prompting method that explicitly scaffolds the LLM's reasoning into distinct phases. By decoupling creative exploration from constraint satisfaction, our method enables LLMs to explore a broader space of ideas before committing to a final problem. We evaluate CreativeDC for creative problem generation using a comprehensive set of metrics that capture diversity, novelty, and utility. The results show that CreativeDC achieves significantly higher diversity and novelty compared to baselines while maintaining high utility. Moreover, scaling analysis shows that CreativeDC generates a larger effective number of distinct problems as more are sampled, increasing at a faster rate than baseline methods.

</details>


### [54] [Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE](https://arxiv.org/abs/2512.23624)
*Chien-Ting Tung,Chenming Hu*

Main category: cs.AI

TL;DR: NeuroSPICE是一个基于物理信息神经网络(PINN)的器件和电路仿真框架，通过最小化微分代数方程残差来替代传统SPICE的数值求解方法。


<details>
  <summary>Details</summary>
Motivation: 传统SPICE依赖于时间离散化的数值求解器，而NeuroSPICE旨在利用PINN的优势，提供更灵活的仿真框架，特别适用于新兴器件和高度非线性系统的模拟。

Method: 采用物理信息神经网络(PINN)框架，通过反向传播最小化电路微分代数方程(DAE)的残差，使用时域解析方程建模器件和电路波形，并计算精确的时间导数。

Result: PINN在训练速度和精度上不优于传统SPICE，但提供了独特的优势：可作为设计优化和逆问题的代理模型，并能灵活模拟包括铁电存储器在内的高度非线性新兴器件。

Conclusion: NeuroSPICE展示了PINN在电路仿真中的潜力，特别是在处理传统方法难以模拟的新兴器件和非线性系统方面具有独特优势，为电路设计和优化提供了新工具。

Abstract: We present NeuroSPICE, a physics-informed neural network (PINN) framework for device and circuit simulation. Unlike conventional SPICE, which relies on time-discretized numerical solvers, NeuroSPICE leverages PINNs to solve circuit differential-algebraic equations (DAEs) by minimizing the residual of the equations through backpropagation. It models device and circuit waveforms using analytical equations in time domain with exact temporal derivatives. While PINNs do not outperform SPICE in speed or accuracy during training, they offer unique advantages such as surrogate models for design optimization and inverse problems. NeuroSPICE's flexibility enables the simulation of emerging devices, including highly nonlinear systems such as ferroelectric memories.

</details>


### [55] [Regret-Based Federated Causal Discovery with Unknown Interventions](https://arxiv.org/abs/2512.23626)
*Federico Baldo,Charles K. Assaad*

Main category: cs.AI

TL;DR: 提出I-PERI算法解决联邦因果发现中的客户端干预异质性问题，通过恢复客户端图并集的CPDAG，再利用干预诱导的结构差异定向边，得到更紧的Φ-Markov等价类。


<details>
  <summary>Details</summary>
Motivation: 现有联邦因果发现方法假设所有客户端共享相同因果模型，但实际中客户端特定策略（如医院不同协议）会引入未知干预，导致模型异质性，需要处理这种现实挑战。

Method: 提出I-PERI算法：1) 恢复所有客户端图并集的CPDAG；2) 利用干预在不同客户端诱导的结构差异定向边；3) 得到更紧的Φ-Markov等价类（Φ-CPDAG表示）。

Result: 提供I-PERI的理论收敛保证和隐私保护特性证明，并在合成数据上进行实证评估，验证算法有效性。

Conclusion: I-PERI成功解决了联邦因果发现中客户端未知干预的挑战，通过利用干预诱导的结构差异缩小等价类，为实际应用提供了更精确的因果发现方法。

Abstract: Most causal discovery methods recover a completed partially directed acyclic graph representing a Markov equivalence class from observational data. Recent work has extended these methods to federated settings to address data decentralization and privacy constraints, but often under idealized assumptions that all clients share the same causal model. Such assumptions are unrealistic in practice, as client-specific policies or protocols, for example, across hospitals, naturally induce heterogeneous and unknown interventions. In this work, we address federated causal discovery under unknown client-level interventions. We propose I-PERI, a novel federated algorithm that first recovers the CPDAG of the union of client graphs and then orients additional edges by exploiting structural differences induced by interventions across clients. This yields a tighter equivalence class, which we call the $\mathbfΦ$-Markov Equivalence Class, represented by the $\mathbfΦ$-CPDAG. We provide theoretical guarantees on the convergence of I-PERI, as well as on its privacy-preserving properties, and present empirical evaluations on synthetic data demonstrating the effectiveness of the proposed algorithm.

</details>


### [56] [Web World Models](https://arxiv.org/abs/2512.23676)
*Jichen Feng,Yifan Zhang,Chenggong Zhang,Yifu Lu,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: Web World Model (WWM) 在传统Web框架和完全生成式世界模型之间找到平衡，用Web代码实现世界状态和"物理规则"保证逻辑一致性，LLM在此基础上生成上下文、叙事和高级决策。


<details>
  <summary>Details</summary>
Motivation: 语言代理需要持久的世界来行动、记忆和学习。现有方法处于两个极端：传统Web框架提供可靠但固定的数据库支持上下文，而完全生成式世界模型追求无限环境但牺牲了可控性和工程实用性。

Method: 构建基于现实Web技术栈的WWM套件，将代码定义的规则与模型驱动的想象力分离，将潜在状态表示为类型化的Web接口，使用确定性生成实现无限但有结构的探索。

Result: 开发了多种WWM系统：基于真实地理的无限旅行地图、虚构星系探索器、Web规模的百科全书和叙事世界、模拟和游戏环境，验证了Web技术栈作为世界模型可扩展基质的可行性。

Conclusion: Web技术栈本身可以作为世界模型的可扩展基质，实现可控但开放的环境，为语言代理提供结构化和逻辑一致的世界。

Abstract: Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [57] [RIS, Active RIS or RDARS: A Comparative Insight Through the Lens of Energy Efficiency](https://arxiv.org/abs/2512.22533)
*Aparna V C,Shashank Shekhar,Sheetal Kalyani*

Main category: cs.IT

TL;DR: 本文比较了RIS、有源RIS和RDARS在sub-6GHz和毫米波频段的覆盖范围和能效，发现RDARS在sub-6GHz系统中能效更高，而有源RIS在毫米波系统中更优。对于少量元件和近端用户，RIS仍保持最高能效。


<details>
  <summary>Details</summary>
Motivation: 乘性衰落是RIS的主要限制因素，影响了其在sub-6GHz和毫米波网络中的有效覆盖。虽然有源RIS架构可以缓解这个问题，但存在高功耗和集成放大器带来的实际挑战。RDARS通过连接模式减轻乘性衰落，需要比较这些技术的覆盖和能效表现。

Method: 通过仿真比较RIS、有源RIS和RDARS在sub-6GHz和毫米波频段的覆盖范围和能效，研究可重构表面（RS）的放置位置和元件数量对能效和覆盖的影响。

Result: 仿真结果显示：1）RDARS在sub-6GHz系统中提供高能效的覆盖增强方案；2）有源RIS在毫米波系统中显著更节能；3）对于少量RS元件和近端用户，RIS比有源RIS和RDARS都更节能。

Conclusion: 不同可重构表面技术在不同频段和应用场景下各有优势：RDARS适合sub-6GHz系统，有源RIS适合毫米波系统，而传统RIS在小规模部署和近端用户场景中仍保持能效优势。技术选择需综合考虑频段、部署规模和用户距离等因素。

Abstract: Multiplicative fading is a major limitation of reconfigurable intelligent surfaces (RIS), restricting their effective coverage in both existing sub-6GHz systems and future mmWave networks. Although active RIS architectures mitigate this issue, they require high power consumption and introduce practical challenges due to the need for integrated amplifiers. Recently, reconfigurable distributed antenna and reflecting surfaces (RDARS) have been proposed to alleviate multiplicative fading through connected modes. In this work, we compare RIS, active RIS, and RDARS in terms of coverage and energy efficiency (EE) in both sub-6GHz and mmWave bands, and we investigate the impact of placement and the number of elements of reconfigurable surface (RS) on EE and coverage. The simulation results show that RDARS offers a highly energy-efficient alternative of enhancing coverage in sub-6GHz systems, while active RIS is significantly more energy-efficient in mmWave systems. Additionally, for a lower number of RS elements and for near UEs, RIS remains considerably more energy-efficient than both active RIS and RDARS.

</details>


### [58] [Optimal Beamforming Design for Multi-user MIMO Near-Field ISAC Systems with Movable Antennas](https://arxiv.org/abs/2512.22620)
*Nemanja Stefan Perović,Keshav Singh,Chih-Peng Li,Octavia A. Dobre,Mark F. Flanagan*

Main category: cs.IT

TL;DR: 本文研究了近场场景下可移动天线（MA）赋能的集成感知与通信（ISAC）系统，通过优化通信预编码、感知波束成形、天线位置等参数，在满足最小感知要求的同时最大化通信用户的加权和速率。


<details>
  <summary>Details</summary>
Motivation: 虽然MA赋能的ISAC系统在远场场景下的增益已有较多研究，但在近场场景下的性能增益尚未得到充分探索。本文旨在填补这一空白，研究近场ISAC系统中可移动天线带来的性能提升。

Method: 提出交替优化算法，针对线性预编码和迫零预编码两种情况，分别优化通信预编码矩阵、感知发射波束成形器、感知接收合并器、用户MA位置和基站发射MA位置。

Result: 仿真结果表明：1）近场ISAC系统中使用MA相比固定天线系统具有显著性能优势；2）线性预编码方案在用户权重不等时获得更大的加权和速率；3）迫零预编码方案对所有用户权重都能保持近似恒定的加权和速率；4）系统性能受用户间天线干扰影响较大，感知性能比通信性能对最小感知SINR阈值更敏感。

Conclusion: 可移动天线在近场ISAC系统中能提供实质性性能提升，提出的优化算法有效平衡了通信和感知性能，为未来无线网络中ISAC系统的设计提供了重要参考。

Abstract: Integrated sensing and communication (ISAC) has been recognized as one of the key technologies capable of simultaneously improving communication and sensing services in future wireless networks. Moreover, the introduction of recently developed movable antennas (MAs) has the potential to further increase the performance gains of ISAC systems. Although the gains of MA-enabled ISAC systems are relatively well studied in the far field, they remain almost unexplored in near-field scenarios. Motivated by this, in this paper we maximize the weighted sum rate (WSR) for communication users while maintaining a minimum sensing requirement in an MA-enabled near-field ISAC system. To achieve this goal, we propose algorithms that optimize the communication precoding matrices, the sensing transmit beamformer, the sensing receive combiner, the positions of the users' MAs and the positions of the base station (BS) transmit MAs in an alternating manner for the considered ISAC system, for the cases where linear procoding and zero-forcing (ZF) precoding are employed at the BS. Simulation results show that using MAs in near-field ISAC systems provides a substantial performance advantage compared to near-field ISAC systems equipped with fixed antennas only. We show that the scheme with linear precoding achieves larger WSR for unequal users' weight rates, while the scheme with ZF precoding maintains an approximately constant WSR for all users' weight rates. Additionally, we demonstrate that the WSRs of the proposed schemes are highly dependent on the inter-antenna interference between different user's MAs, and that the sensing performance is significantly more affected by the minimum sensing signal-to-interference-plus-noise ratio (SINR) threshold compared to the communication performance.

</details>


### [59] [An Improved Lower Bound on Cardinality of Support of the Amplitude-Constrained AWGN Channel](https://arxiv.org/abs/2512.22691)
*Haiyang Wang,Luca Barletta,Alex Dytso*

Main category: cs.IT

TL;DR: 该论文研究了幅度受限加性高斯白噪声信道，推翻了关于容量最优输入分布支撑集大小线性增长的猜想，建立了新的下界A√log A。


<details>
  <summary>Details</summary>
Motivation: 研究幅度受限加性高斯白噪声信道容量最优输入分布支撑集大小的精确标度。先前研究显示支撑集大小的下界为A量级，上界为A²量级，有猜想认为线性标度是最优的，需要验证这一猜想。

Method: 1. 量化容量最优输出分布在幅度约束内部接近均匀分布的事实；2. 引入包装操作将问题映射到紧致域；3. 发展有限高斯混合对均匀分布的最佳逼近理论；4. 结合容量最优分布的稳定性性质。

Result: 建立了新的下界A√log A，改进了已知下界，推翻了线性标度最优的猜想，证明支撑集大小必须至少以A√log A的速度增长。

Conclusion: 幅度受限加性高斯白噪声信道容量最优输入分布的支撑集大小必须至少以A√log A的速度增长，线性标度猜想不成立，为理解此类信道容量最优分布的结构提供了新见解。

Abstract: We study the amplitude-constrained additive white Gaussian noise channel. It is well known that the capacity-achieving input distribution for this channel is discrete and supported on finitely many points. The best known bounds show that the support size of the capacity-achieving distribution is lower-bounded by a term of order $A$ and upper-bounded by a term of order $A^2$, where $A$ denotes the amplitude constraint. It was conjectured in [1] that the linear scaling is optimal. In this work, we establish a new lower bound of order $A\sqrt{\log A}$, improving the known bound and ruling out the conjectured linear scaling.
  To obtain this result, we quantify the fact that the capacity-achieving output distribution is close to the uniform distribution in the interior of the amplitude constraint. Next, we introduce a wrapping operation that maps the problem to a compact domain and develop a theory of best approximation of the uniform distribution by finite Gaussian mixtures. These approximation bounds are then combined with stability properties of capacity-achieving distributions to yield the final support-size lower bound.

</details>


### [60] [Iterative Channel Estimation, Detection and Decoding for Multi-Antenna Systems with RIS](https://arxiv.org/abs/2512.22731)
*Roberto C. G. Porto,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出用于多用户多天线系统上行链路的迭代信道估计、检测和解码方案，利用RIS辅助，通过编码导频和迭代处理提高信道估计精度并降低导频开销。


<details>
  <summary>Details</summary>
Motivation: 在多用户多天线系统中，传统的信道估计方法需要大量导频开销，特别是在RIS辅助的场景下。为了降低导频开销同时提高估计精度，需要开发更高效的信道估计技术。

Method: 提出ICEDD方案，包括：1) 基于LDPC码的迭代码辅助信道估计技术，利用编码导频同时使用导频和校验位迭代优化信道估计；2) 迭代信道跟踪方法，利用信道的时间相关性；3) 完整的迭代信道估计、检测和解码框架。

Result: 提供了估计器的归一化均方误差理论分析、计算复杂度研究和码率影响分析。数值仿真验证了在sub-6 GHz多RIS场景下，无论是LOS还是NLOS条件以及不同RIS架构下，该方案都能有效提升性能。

Conclusion: 提出的ICEDD方案通过迭代码辅助信道估计和信道跟踪，能够在降低导频开销的同时显著提高多用户多天线RIS辅助系统的信道估计精度和整体性能。

Abstract: This work proposes an iterative channel estimation, detection and decoding (ICEDD) scheme for the uplink of multi-user multi-antenna systems assisted by multiple reconfigurable intelligent surfaces (RIS)}. A novel iterative code-aided channel estimation (ICCE) technique is developed that uses low-density parity-check (LDPC) codes and iterative processing to enhance estimation accuracy while reducing pilot overhead. The core idea is to exploit encoded pilots (EP), enabling the use of both pilot and parity bits to iteratively refine channel estimates. To further improve performance, an iterative channel tracking (ICT) method is proposed that takes advantage of the temporal correlation of the channel. An analytical evaluation of the proposed estimator is provided in terms of normalized mean-squared error (NMSE), along with a study of its computational complexity and the impact of the code rate. Numerical results validate the performance of the proposed scheme in a sub-6 GHz multi-RIS scenario with non-sparse propagation, under both LOS and NLOS conditions, and different RIS architectures.

</details>


### [61] [Beyond Beam Sweeping: One-Shot Satellite Acquisition with Doppler-Aware Rainbow Beamforming](https://arxiv.org/abs/2512.22828)
*Juha Park,Ian P. Roberts,Wonjae Shin*

Main category: cs.IT

TL;DR: 提出一种利用多普勒效应和波束倾斜效应的一次性卫星捕获框架，通过彩虹波束形成器实现多卫星同时接收，无需波束扫描


<details>
  <summary>Details</summary>
Motivation: 传统卫星捕获方法依赖时域波束扫描，会产生大量开销和延迟。高增益波束成形需要精确卫星位置信息，而多普勒效应和波束倾斜效应通常被视为干扰因素

Method: 1) 推导闭式彩虹波束形成器，利用波束倾斜效应将频率相关波束方向与多普勒频移推断的卫星位置对齐；2) 开发三种基于接收信号的多普勒感知角度估计算法提取卫星位置信息

Result: 仿真结果表明，该方法在捕获精度和所需时隙方面显著优于传统波束扫描方法，能够通过单次导频传输和接收实现全角度域覆盖

Conclusion: 通过利用多普勒频移的角度依赖性，提出的彩虹波束形成方法能够有效克服传统卫星捕获方法的开销和延迟问题，实现高效的一次性卫星捕获

Abstract: High-gain beamforming (BF) is essential for low Earth orbit (LEO) satellite communications to overcome severe path loss, but this requires acquiring precise satellite positions. Conventional satellite acquisition typically relies on time-domain beam sweeping, which incurs substantial overhead and latency. In this correspondence, we propose an efficient one-shot satellite acquisition framework that capitalizes on two phenomena traditionally regarded as impairments: i) Doppler effects and ii) beam-squint effects. Specifically, we derive a closed-form \emph{rainbow beamformer} that leverages beam-squint effects to align frequency-dependent beam directions with satellite positions inferred from their Doppler shifts. This approach enables reception from multiple satellites at once without requiring beam sweeping. To extract satellite position information, we develop three Doppler-aware angle estimation algorithms based on received signals. Simulation results demonstrate that the proposed method significantly outperforms conventional beam sweeping approaches in both acquisition accuracy and required time slots. These gains stem from the ability of the proposed rainbow BF to exploit the \emph{angle-dependent nature of Doppler shifts}, enabling full angular-domain coverage with a single pilot transmission and reception.

</details>


### [62] [Covering in Hamming and Grassmann Spaces: New Bounds and Reed--Solomon-Based Constructions](https://arxiv.org/abs/2512.22911)
*Samin Riasat,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 该论文研究汉明空间和格拉斯曼空间的覆盖问题，引入平均覆盖半径作为平均失真度量，推导随机编码界，并构造基于RS码和CRS码的高效覆盖算法。


<details>
  <summary>Details</summary>
Motivation: 研究覆盖问题在汉明空间和格拉斯曼空间中的表现，将覆盖视为一般度量空间中的量化形式，需要建立平均覆盖半径的概念来补充传统的最坏情况覆盖半径，以更全面地评估覆盖性能。

Method: 采用编码理论和信息理论的统一框架，利用单次率失真理论工具推导非渐近随机编码界；在构造方面，开发基于穿孔的覆盖算法，包括汉明空间的广义Reed-Solomon码和格拉斯曼空间的字符-Reed-Solomon码。

Result: 推导了汉明空间和格拉斯曼空间的平均覆盖半径的随机编码界；数值结果显示RS码构造在汉明空间中平均覆盖半径优于随机码本；在一维格拉斯曼空间中，CRS码在素数域上高码率时平均覆盖半径在随机编码界的常数因子内。

Conclusion: 尽管结构化码的最坏情况覆盖保证较差，但表现出强大的平均覆盖性能；这些结果为代数结构在覆盖问题和高维量化中的作用提供了新见解。

Abstract: We study covering problems in Hamming and Grassmann spaces through a unified coding-theoretic and information-theoretic framework. Viewing covering as a form of quantization in general metric spaces, we introduce the notion of the average covering radius as a natural measure of average distortion, complementing the classical worst-case covering radius. By leveraging tools from one-shot rate-distortion theory, we derive explicit non-asymptotic random-coding bounds on the average covering radius in both spaces, which serve as fundamental performance benchmarks.
  On the construction side, we develop efficient puncturing-based covering algorithms for generalized Reed--Solomon (GRS) codes in the Hamming space and extend them to a new family of subspace codes, termed character-Reed--Solomon (CRS) codes, for Grassmannian quantization under the chordal distance. Our results reveal that, despite poor worst-case covering guarantees, these structured codes exhibit strong average covering performance. In particular, numerical results in the Hamming space demonstrate that RS-based constructions often outperform random codebooks in terms of average covering radius. In the one-dimensional Grassmann space, we numerically show that CRS codes over prime fields asymptotically achieve average covering radii within a constant factor of the random-coding bound in the high-rate regime. Together, these results provide new insights into the role of algebraic structure in covering problems and high-dimensional quantization.

</details>


### [63] [Generalized Hyperderivative Reed-Solomon Codes](https://arxiv.org/abs/2512.22948)
*Mahir Bilen Can,Benjamin Horowitz*

Main category: cs.IT

TL;DR: GHRS码是NRT Reed-Solomon码的推广，具有MDS、对偶性、LDPC和准循环等优良特性


<details>
  <summary>Details</summary>
Motivation: 推广NRT Reed-Solomon码，构建具有多种优良代数特性的编码，特别是同时具备MDS、LDPC和准循环特性的编码

Method: 提出广义超导数Reed-Solomon码(GHRS码)，通过代数构造方法推广传统编码

Result: 1) 所有GHRS码都是MDS码；2) GHRS码的对偶码也是GHRS码；3) 确定了LDPC特性的GHRS码子族；4) 确定了准循环特性的GHRS码族；存在同时具备所有这些特性的GHRS码

Conclusion: GHRS码成功推广了NRT Reed-Solomon码，提供了同时具备MDS、LDPC和准循环特性的编码构造，具有重要的理论和应用价值

Abstract: This article introduces Generalized Hyperderivative Reed-Solomon codes (GHRS codes), which generalize NRT Reed-Solomon codes. Its main results are as follows: 1) every GHRS code is MDS, 2) the dual of a GHRS code is also an GHRS code, 3) determine subfamilies of GHRS codes whose members are low-density parity-check codes (LDPCs), and 4) determine a family of GHRS codes whose members are quasi-cyclic. We point out that there are GHRS codes having all of these properties.

</details>


### [64] [User-Centric Cell-Free Massive MIMO Enhanced by Fluid-Antenna Access Points: Uplink Analysis](https://arxiv.org/abs/2512.23046)
*Maryam Olyaee,Giovanni Interdonato,Stefano Buzzi*

Main category: cs.IT

TL;DR: 本文研究了配备流体天线的无蜂窝大规模MIMO系统，提出了信道估计、端口选择和上行频谱效率优化的综合框架，通过动态激活FA端口和优化配置显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 流体天线（FAs）具有可重构特性，能够为无蜂窝大规模MIMO系统提供更好的空间自由度。然而，现有的信道估计和天线配置方法未能充分利用FA的动态特性，需要开发专门的框架来优化系统性能。

Method: 1. 提出广义LMMSE上行信道估计方案，在导频传输期间动态激活FA端口；2. 设计分布式端口选择策略，利用FA端口间的空间相关性最小化信道估计误差；3. 使用Jakes信道模型分析天线几何和空间相关性影响；4. 推导集中式和分布式上行处理的SINR表达式；5. 提出交替优化框架选择最大化上行总频谱效率的FA端口配置。

Result: 数值结果表明，提出的FA感知信道估计和端口优化策略显著降低了信道估计误差，相比固定天线和非优化FA基线，总频谱效率有大幅提升。这证实了流体天线作为可扩展、自适应无蜂窝大规模MIMO网络关键使能技术的能力。

Conclusion: 流体天线通过其可重构特性为无蜂窝大规模MIMO系统提供了显著的性能增益。提出的综合框架有效解决了FA系统的信道估计、端口选择和频谱效率优化问题，为未来自适应无线网络的设计提供了重要指导。

Abstract: In this paper, we investigate cell-free massive MIMO (CF-mMIMO) systems in which access points (APs) are equipped with fluid antennas (FAs) and develop a comprehensive framework for channel estimation, antenna port selection, and uplink spectral efficiency (SE) optimization. We propose a generalized LMMSE-based uplink channel estimation scheme that dynamically activates FA ports during pilot transmission, efficiently exploiting antenna reconfigurability under practical training constraints. Building on this, we design a distributed port selection strategy that minimizes per-AP channel estimation error by exploiting spatial correlation among FA ports. We systematically analyze the impact of antenna geometry and spatial correlation using the Jakes' channel model for different AP array configurations, including uniform linear and planar arrays. We then derive SINR expressions for centralized and distributed uplink processing and obtain a closed-form uplink SE expression for centralized maximum-ratio combining using the use-and-then-forget bound. Finally, we propose an alternating-optimization framework to select FA port configurations that maximize the uplink sum SE. Numerical results show that the proposed FA-aware channel estimation and port optimization strategies greatly reduce channel estimation error and significantly improve sum-SE over fixed-antenna and non-optimized FA baselines, confirming FAs as a key enabler for scalable, adaptive CF-mMIMO networks.

</details>


### [65] [A New Family of Binary Sequences via Elliptic Function Fields over Finite Fields of Odd Characteristics](https://arxiv.org/abs/2512.23194)
*Xiaofeng Liu,Jun Zhang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 该论文将Jin等人基于有限域F_{2^n}上循环椭圆函数域的二进制序列构造方法推广到奇特征情形，使用二次剩余映射替代迹映射，构建了具有良好密码学特性的新二进制序列族。


<details>
  <summary>Details</summary>
Motivation: 受Jin等人在IEEE Trans. Inf. Theory 2025中利用有限域F_{2^n}上循环椭圆函数域构造二进制序列的启发，作者希望将这一构造方法扩展到奇特征情形，并使用二次剩余映射替代原有的迹映射。

Method: 利用奇特征循环椭圆函数域，采用二次剩余映射η替代迹映射。对于具有q+1+t个有理点的循环椭圆函数域，以及满足gcd(d, q+1+t)=1的正整数d，构造新的二进制序列族。

Result: 构造了长度为q+1+t、规模为q^{d-1}-1的二进制序列族，其平衡性上界为(d+1)·⌊2√q⌋+|t|+d，相关性上界为(2d+1)·⌊2√q⌋+|t|+2d，线性复杂度下界为(q+1+2t-d-(d+1)·⌊2√q⌋)/(d+d·⌊2√q⌋)。

Conclusion: 成功将二进制序列构造从特征2情形推广到奇特征情形，使用二次剩余映射获得了具有良好密码学特性的新序列族，为序列设计提供了新方法。

Abstract: Motivated by the constructions of binary sequences by utilizing the cyclic elliptic function fields over the finite field $\mathbb{F}_{2^{n}}$ by Jin \textit{et al.} in [IEEE Trans. Inf. Theory 71(8), 2025], we extend the construction to the cyclic elliptic function fields with odd characteristic by using the quadratic residue map $η$ instead of the trace map used therein. For any cyclic elliptic function field with $q+1+t$ rational points and any positive integer $d$ with $\gcd(d, q+1+t)=1$, we construct a new family of binary sequences of length $q+1+t$, size $q^{d-1}-1$, balance upper bounded by $(d+1)\cdot\lfloor2\sqrt{q}\rfloor+|t|+d,$ the correlation upper bounded by $(2d+1)\cdot\lfloor2\sqrt{q}\rfloor+|t|+2d$ and the linear complexity lower bounded by $\frac{q+1+2t-d-(d+1)\cdot\lfloor2\sqrt{q}\rfloor}{d+d\cdot\lfloor2\sqrt{q}\rfloor}$ where $\lfloor x\rfloor$ stands for the integer part of $x\in\mathbb{R}$.

</details>


### [66] [Sum Rate optimization for RIS-Aided RSMA system with Movable Antenna](https://arxiv.org/abs/2512.23242)
*Mingyu Hu,Nan Liu,Wei Kang*

Main category: cs.IT

TL;DR: 提出了一种移动天线辅助的RSMA-RIS框架，通过联合优化发射波束成形、RIS反射矩阵、公共速率分配和天线位置来最大化系统和速率，相比传统固定天线方案能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统RSMA-RIS架构中的天线元件是固定的，这未能充分利用空间自由度，从而限制了系统性能。为了解决这一限制，需要探索移动天线技术来增强RSMA-RIS系统的性能。

Method: 提出了移动天线辅助的RSMA-RIS框架，通过分数规划方法将原始问题等价转换，推导出公共速率分配的闭式解。利用KKT条件获得拉格朗日乘子的迭代更新和波束成形矩阵的闭式表达式，通过对偶问题开发RIS反射矩阵的更新规则，最后使用梯度上升法确定最优天线位置。

Result: 数值结果表明，即使在RIS辅助的情况下，引入移动天线仍能为RSMA带来额外的性能提升。相对于空分多址（SDMA），移动天线的辅助为RSMA带来了更大的性能增益。

Conclusion: 移动天线辅助的RSMA-RIS框架通过充分利用空间自由度，显著提升了系统性能，为6G无线系统中的干扰管理和通信性能优化提供了有效的解决方案。

Abstract: Rate-Splitting Multiple Access (RSMA) is regarded as a key enabling technique for sixth-generation (6G) wireless systems for its powerful interference management substantially enhancing link throughput. Reconfigurable Intelligent Surface (RIS) can effectively shape the wireless propagation to match the environment and improve communication performance. However, in conventional RSMA-RIS architectures, the antenna elements are fixed, which underutilizes spatial degrees of freedom and hence constrains system performance. To address this limitation, we propose a movable-antenna (MA) assisted RSMA-RIS framework and formulate a sum-rate maximization problem that jointly optimizes the transmit beamforming matrix, the RIS reflection matrix, the common-rate partition, and the MA positions. The original problem is equivalently transformed by employing the fractional programming (FP) method, and a closed-form solution for the common rate splitting is derived. Leveraging the Karush-Kuhn-Tucker (KKT) conditions, we obtain iterative updates for the Lagrange multipliers together with a closed-form expression for the beamforming matrix. We then develop an update rule for the RIS reflection matrix via the dual problem, and finally determine the optimal antenna locations using a gradient-ascent procedure. Numerical results indicate that, even in the presence of RIS assistance, incorporating MAs yields additional performance improvements for RSMA. Moreover, relative to space-division multiple access (SDMA), the assistance of MA yields a greater performance gain for RSMA.

</details>


### [67] [Information Inequalities for Five Random Variables](https://arxiv.org/abs/2512.23316)
*E. P. Csirmaz,L. Csirmaz*

Main category: cs.IT

TL;DR: 本文利用最大熵方法研究五变量熵区域，通过理论简化与对称性降低计算复杂度，发现了两个无限非Shannon不等式族，并开发了枚举所有极值不等式的算法。


<details>
  <summary>Details</summary>
Motivation: 熵区域由有限多个联合分布离散随机变量的所有子向量的Shannon熵组成。对于四个或更多变量，熵区域的结构大部分未知。本文旨在利用最大熵方法来界定五变量熵区域。

Method: 采用最大熵方法的变体，通过添加随机变量的副本（分代处理）。通过理论考虑和利用固有对称性显著降低计算复杂度，计算了前九代提供的所有五变量非Shannon不等式。

Result: 基于计算结果定义了两个无限的非Shannon不等式族，并证明了它们是熵不等式。研究了参数化这些集合的非负格点的向下封闭子集，并开发了枚举所有极值不等式的算法。

Conclusion: 发现的不等式集合被推测为完全刻画了所应用的方法。该方法为理解五变量熵区域的结构提供了重要进展，并建立了系统研究非Shannon不等式的新框架。

Abstract: The entropic region is formed by the collection of the Shannon entropies of all subvectors of finitely many jointly distributed discrete random variables. For four or more variables the structure of the entropic region is mostly unknown. We utilize a variant of the Maximum Entropy Method to delimit the five-variable entropy region. This method adds copies of some of the random variables in generations. A significant reduction in computational complexity, achieved through theoretical considerations and by harnessing the inherent symmetries, allowed us to calculate all five-variable non-Shannon inequalities provided by the first nine generations. Based on the results, we define two infinite collections of such inequalities, and prove them to be entropy inequalities. We investigate downward closed subsets of non-negative lattice points that parameterize these collections, based on which we develop an algorithm to enumerate all extremal inequalities. The discovered set of entropy inequalities is conjectured to characterize the applied method completely.

</details>


### [68] [Faster-than-Nyquist Signaling for Next-Generation Wireless: Principles, Applications, and Challenges](https://arxiv.org/abs/2512.23377)
*Shuangyang Li,Melda Yuksel,Tongyang Xu,Shinya Sugiura,Jinhong Yuan,Giuseppe Caire,Lajos Hanzo*

Main category: cs.IT

TL;DR: 本文提供了关于快于奈奎斯特（FTN）信号处理的全面介绍，涵盖其核心原理、理论基础、独特优势、开放问题及发展路线图，特别强调了其在集成感知与通信（ISAC）中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要支持超高吞吐量的新兴应用，而传统的奈奎斯特信号处理在这种场景下可能失效。FTN信号处理能够在相同时间-频率资源下传输更多符号，为解决这一挑战提供了方案。

Method: 文章采用结构化介绍方法，系统性地阐述FTN信号处理的核心原理和理论基础，分析其独特优势，并探讨其在编码FTN和集成感知与通信（ISAC）中的具体应用。

Result: 展示了有前景的编码FTN结果，并突出了FTN在集成感知与通信（ISAC）中的显著优势，ISAC是未来网络中日益关键的功能。

Conclusion: 文章最后讨论了开放的研究挑战和有前景的发展方向，为FTN信号处理在下一代无线网络中的应用提供了路线图。

Abstract: Future wireless networks are expected to deliver ultra-high throughput for supporting emerging applications. In such scenarios, conventional Nyquist signaling may falter. As a remedy, faster-than-Nyquist (FTN) signaling facilitates the transmission of more symbols than Nyquist signaling without expanding the time-frequency resources. We provide an accessible and structured introduction to FTN signaling, covering its core principles, theoretical foundations, unique advantages, open facets, and its road map. Specifically, we present promising coded FTN results and highlight its compelling advantages in integrated sensing and communications (ISAC), an increasingly critical function in future networks. We conclude with a discussion of open research challenges and promising directions.

</details>


### [69] [Dynamic Channel Knowledge Map Construction in MIMO-OFDM Systems](https://arxiv.org/abs/2512.23470)
*Wenjun Jiang,Xiaojun Yuan,Chenchen Liu,Boyu Teng*

Main category: cs.IT

TL;DR: 本文提出了一种用于MIMO-OFDM系统的动态信道知识地图构建方法，通过两阶段贝叶斯推理算法，在动态环境中实现低开销、高性能的信道估计。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方法主要针对准静态传播环境，无法有效处理动态环境中的信道变化。本文旨在解决动态环境中包含准静态和动态散射体、天线旋转和同步误差等多种因素影响的信道建模问题。

Method: 1) 建立包含准静态和动态散射体、天线旋转和同步误差的动态信道模型；2) 在贝叶斯推理框架下构建动态CKM问题；3) 设计两阶段近似贝叶斯推理算法：第一阶段联合推断准静态信道参数并校准同步误差，第二阶段利用准静态参数作为先验信息，从有限实时测量中估计动态参数。

Result: 仿真结果验证了所提方法的优越性，表明该方法在动态环境中能够实现低开销、高性能的信道估计。

Conclusion: 本文提出的动态CKM构建方法有效解决了动态环境中的信道建模问题，通过两阶段贝叶斯推理算法实现了对复杂动态信道参数的高效估计，为环境感知通信提供了新的解决方案。

Abstract: Channel knowledge map (CKM) is a promising paradigm for environment-aware communications by establishing a deterministic mapping between physical locations and channel parameters. Existing CKM construction methods focus on quasi-static propagation environment. This paper develops a dynamic CKM construction method for multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. We establish a dynamic channel model that captures the coexistence of quasi-static and dynamic scatterers, as well as the impacts of antenna rotation and synchronization errors. Based on this model, we formulate the problem of dynamic CKM construction within a Bayesian inference framework and design a two-stage approximate Bayesian inference algorithm. In stage I, a high-performance algorithm is developed to jointly infer quasi-static channel parameters and calibrate synchronization errors from historical measurements. In stage II, by leveraging the quasi-static parameters as informative priors, a low-complexity algorithm is designed to estimate dynamic parameters from limited real-time measurements. Simulation results validate the superiority of the proposed method and demonstrate its effectiveness in enabling low-overhead, high-performance channel estimation in dynamic environments.

</details>


### [70] [Affine-Projection Recovery of Continuous Angular Power Spectrum: Geometry and Resolution](https://arxiv.org/abs/2512.23506)
*Shengsong Luo,Ruilin Wu,Chongbin Xu,Junjie Ma,Xiaojun Yuan,Xin Wang*

Main category: cs.IT

TL;DR: 提出一种基于加权傅里叶域的PLV算法改进，用于从信道协方差中恢复连续角度功率谱，获得显式固定维三角多项式表示和闭式解，建立了精确能量恒等式和尖锐的可辨识性/分辨率特征。


<details>
  <summary>Details</summary>
Motivation: 从信道协方差中恢复连续角度功率谱(APS)是阵列信号处理中的重要问题。现有PLV算法虽然有效，但缺乏清晰的几何解释和理论分析，需要建立更严格的数学框架来理解其性能极限和可辨识性条件。

Method: 在明确定义的加权傅里叶域中分析PLV算法，强调其几何可解释性。获得显式固定维三角多项式表示，通过正定矩阵得到闭式解，建立精确能量恒等式来分析重构误差。

Result: 当真实APS位于识别的三角多项式子空间时，PLV能实现完美恢复；否则返回所有协方差一致谱中能量最小的APS。建立了尖锐的可辨识性/分辨率特征，直接推导出唯一性。

Conclusion: 该工作为PLV算法提供了严格的数学框架，揭示了其在加权傅里叶域的几何本质，建立了精确的性能界限和可辨识性条件，为角度功率谱恢复提供了理论保证和实用指导。

Abstract: This paper considers recovering a continuous angular power spectrum (APS) from the channel covariance. Building on the projection-onto-linear-variety (PLV) algorithm, an affine-projection approach introduced by Miretti \emph{et. al.}, we analyze PLV in a well-defined \emph{weighted} Fourier-domain to emphasize its geometric interpretability. This yields an explicit fixed-dimensional trigonometric-polynomial representation and a closed-form solution via a positive-definite matrix, which directly implies uniqueness. We further establish an exact energy identity that yields the APS reconstruction error and leads to a sharp identifiability/resolution characterization: PLV achieves perfect recovery if and only if the ground-truth APS lies in the identified trigonometric-polynomial subspace; otherwise it returns the minimum-energy APS among all covariance-consistent spectra.

</details>
