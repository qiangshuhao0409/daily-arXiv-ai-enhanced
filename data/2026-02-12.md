<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 10]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Supercharging Packet-level Network Simulation of Large Model Training via Memoization and Fast-Forwarding](https://arxiv.org/abs/2602.10615)
*Fei Long,Kaihui Gao,Li Chen,Dan Li,Yiwei Zhang,Fei Gui,Yitao Xing,Wenjia Wei,Bingyang Liu*

Main category: cs.NI

TL;DR: Wormhole 提出了一种新的 PLDES 优化方法，通过识别和跳过冗余的离散事件（特别是稳态流量），在保持高保真度的同时显著加速模拟，实现744倍加速，误差小于1%。


<details>
  <summary>Details</summary>
Motivation: PLDES（包级离散事件模拟）是评估大规模模型训练性能的重要工具，但现有优化方法要么简化网络模型导致大误差，要么并行执行但加速上限有限。需要一种既能保持高保真度又能显著加速的新方法。

Method: Wormhole 采用网络分区、状态记忆化和重用、基于速率的稳态识别技术，自动记忆非稳态并跳过稳态期间的冗余事件，在快速转发后保持模拟一致性。

Result: 实验显示 Wormhole 相比原始 ns-3 实现744倍加速（MoE工作负载为510倍），误差小于1%。结合现有多线程并行技术可实现1012倍加速，将128 GPU下GPT-13B训练模拟时间从9小时减少到5分钟。

Conclusion: Wormhole 通过识别和跳过分布式LLM训练中的冗余离散事件，在保持高保真度的同时实现了数量级的加速，为大规模训练模拟提供了实用高效的解决方案。

Abstract: Packet-level discrete-event simulation (PLDES) is a prevalent tool for evaluating detailed performance of large model training. Although PLDES offers high fidelity and generality, its slow performance has plagued networking practitioners. Existing optimization techniques either simplify the network model, resulting in large errors; or execute it in parallel using multiple processors, with an upper bound on speedup. This paper explores an alternative optimization direction that reduces the computational loads of PLDES while maintaining high fidelity. Our key insight is that, in distributed LLM training, packet-level traffic behaviors often exhibit repetitive contention patterns and steady-states where flow rates stabilize, ignoring these redundant discrete events speeds up the simulation considerably and the error is negligible. We realize this idea by proposing Wormhole, a user-transparent PLDES kernel capable of automatically memoization for unsteady-states and skipping for steady-states. Wormhole adopts network partitioning, state memoization and reuse, and rate-based steady-state identification to accurately determine the periods of each flow's steady-state, while maintaining simulation consistency after fast-forwarding. Experiments demonstrate that Wormhole can achieve a 744x speedup over the original ns-3 (510x for MoE workload), with a bounded error of <1%. Applying current multithreading parallel techniques and Wormhole together allows a 1012x speedup, reducing the simulation time for one GPT-13B training under 128 GPUs from 9 hours to 5 minutes.

</details>


### [2] [Bring Your Own Objective: Inter-operability of Network Objectives in Datacenters](https://arxiv.org/abs/2602.10252)
*Sanjoli Narang,Anup Agarwal,Venkat Arun,Manya Ghobadi*

Main category: cs.NI

TL;DR: DMart是一个去中心化的数据中心网络调度框架，将带宽视为竞争性市场，通过应用自主出价实现多种性能目标的共存，无需集中调度器或复杂优先级队列。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心网络被"单一目标的暴政"所困，现有网络架构通常针对单一性能指标硬编码，当应用需求与网络目标不一致时性能急剧下降。现代工作负载需要多样化的性能目标（如coflow完成时间、流公平性、短流延迟等），但现有网络无法同时满足这些需求。

Method: DMart采用去中心化的调度框架，将网络带宽视为竞争性市场。应用独立地将网络流量的紧急性和重要性编码为自主出价，实现多种目标在同一网络上的原生共存。为满足现代数据中心的极端规模和亚微秒级要求，DMart实现了分布式、每链路、每RTT的拍卖机制，不依赖整数线性规划、集中调度器或复杂优先级队列。

Result: 通过包级仿真评估，DMart在专用调度器各自的"主场"上能匹配其性能，同时优化次要指标。相比pFabric和Sincronia，DMart将截止时间错过率降低2倍，将coflow完成时间减少1.6倍，同时匹配pFabric的短流完成时间。

Conclusion: DMart通过市场化的带宽分配机制，打破了数据中心网络的"单一目标暴政"，实现了多种性能目标的和谐共存，为现代多样化工作负载提供了灵活高效的网络调度解决方案。

Abstract: Datacenter networks are currently locked in a "tyranny of the single objective". While modern workloads demand diverse performance goals, ranging from coflow completion times, per-flow fairness, short-flow latencies, existing fabrics are typically hardcoded for a single metric. This rigid coupling ensures peak performance when application and network objectives align, but results in abysmal performance when they diverge.
  We propose DMart, a decentralized scheduling framework that treats network bandwidth as a competitive marketplace. In DMart, applications independently encode the urgency and importance of their network traffic into autonomous bids, allowing diverse objectives to co-exist natively on the same fabric. To meet the extreme scale and sub-microsecond requirements of modern datacenters, DMart implements distributed, per-link, per-RTT auctions, without relying on ILPs, centralized schedulers, or complex priority queues.
  We evaluate DMart using packet-level simulations and compare it against network schedulers designed for individual metrics, e.g., pFabric and Sincronia. DMart matches the performance of specialized schedulers on their own "home turf" while simultaneously optimizing secondary metrics. Compared to pFabric and Sincronia, DMart reduces deadline misses by 2x and coflow completion times by 1.6x respectively, while matching pFabric short-flow completion times.

</details>


### [3] [To Reconfigure or Not to Reconfigure: Optimizing All-to-All Collectives in Circuit-Switched Photonic Interconnects](https://arxiv.org/abs/2602.10468)
*Anchengcheng Zhou,Vamsi Addanki,Maria Apostolaki*

Main category: cs.NI

TL;DR: 提出一种基于矩阵分解的抽象方法，将全对全通信中的拓扑序列和流调度优化问题表达为邻接矩阵及其幂次的和，从而高效构建近优解，避免组合空间枚举。


<details>
  <summary>Details</summary>
Motivation: 随着分布式机器学习和高性能计算中全对全通信需求增长，电互连的带宽和能耗限制日益突出，光子互连成为有前景的替代方案。然而，利用光子互连进行全对全通信面临核心挑战：需要在拓扑序列和流调度之间进行联合优化，权衡重配置成本与传输节省，而现有方法因对重配置成本做出不切实际的假设而无法有效解决这一问题。

Method: 提出一种数学抽象方法，将候选的拓扑序列和流调度表达为邻接矩阵及其幂次的和，这种抽象能捕捉整个解空间并提供全对全完成时间的下界。在此基础上，识别出一类具有强对称性和高扩展性的拓扑序列族，该族允许带宽高效的调度，并设计算法以低计算开销构建这些调度。

Result: 评估显示，该方法在广泛的网络参数、消息大小和工作负载类型下，平均减少全对全完成时间达44%。

Conclusion: 通过将全对全通信优化问题抽象为矩阵分解形式，能够高效构建近优解，避免组合设计空间的枚举，显著提升光子互连网络中的通信性能。

Abstract: All-to-all collective communication is a core primitive in distributed machine learning and high-performance computing. At the server scale, the communication demands of these workloads are increasingly outstripping the bandwidth and energy limits of electrical interconnects, driving a growing interest in photonic interconnects. However, leveraging these interconnects for all-to-all communication is nontrivial. The core challenge lies in jointly optimizing a sequence of topologies and flow schedules, reconfiguring only when the transmission savings from traversing shorter paths outweigh the reconfiguration cost. Yet the search space of this joint optimization is enormous. Existing work sidesteps this challenge by making unrealistic assumptions on reconfiguration costs so that it is never or always worthwhile to reconfigure. In this paper, we show that any candidate sequence of topologies and flow schedules can be expressed as a sum of adjacency matrices and their powers. This abstraction captures the entire solution space and yields a lower bound on all-to-all completion time. Building on this formulation, we identify a family of topology sequences with strong symmetry and high expansion that admits bandwidth-efficient schedules, which our algorithm constructs with low computational overhead. Together, these insights allow us to efficiently construct near-optimal solutions, effectively avoiding enumeration of the combinatorial design space. Evaluation shows that our approach reduces all-to-all completion time by up to 44% on average across a wide range of network parameters, message sizes and workload types.

</details>


### [4] [Scaling Routers with In-Package Optics and High-Bandwidth Memories](https://arxiv.org/abs/2602.10505)
*Isaac Keslassy,Ilay Yavlovich,Jose Yallouz,Tzu-Chien Hsueh,Yeshaiahu Fainman,Bill Lin*

Main category: cs.NI

TL;DR: 将计算封装行业的两大扩展技术（HBM/芯粒异构集成和封装内光学）应用于互联网路由器，提出单封装内实现Petabit/s路由器的创新架构


<details>
  <summary>Details</summary>
Motivation: 传统互联网路由器面临扩展瓶颈，需要利用先进封装技术实现更高带宽和能效的路由器架构

Method: 提出分裂并行交换架构（被动空间分割光纤）+ HBM共享内存架构 + 并行帧交错算法，实现无OEO转换的粗粒度负载均衡

Result: 通过骨干网流量评估，证明与精细负载均衡方法差异很小，能够实现单封装内Petabit/s路由器

Conclusion: 这些新技术代表未来互联网路由器设计的范式转变，但功耗可能成为扩展的主要瓶颈

Abstract: This paper aims to apply two major scaling transformations from the computing packaging industry to internet routers: the heterogeneous integration of high-bandwidth memories (HBMs) and chiplets, as well as in-package optics. We propose a novel internet router architecture that employs these technologies to achieve a petabit/sec router within a single integrated package. At the top-level, we introduce a novel split-parallel switch architecture that spatially divides (without processing) the incoming fibers and distributes them across smaller independent switches without intermediate OEO conversions or fine-tuned per-packet load-balancing. This passive spatial division enables scaling at the cost of a coarser traffic load balancing. Yet, through extensive evaluations of backbone network traffic, we demonstrate that differences with fine-tuned approaches are small. In addition, we propose a novel HBM-based shared-memory architecture for the implementation of the smaller independent switches, and we introduce a novel parallel frame interleaving algorithm that packs traffic into frames so that HBM banks are accessed at peak HBM data rates in a cyclical interleaving manner. We further discuss why these new technologies represent a paradigm shift in the design of future internet routers. Finally, we emphasize that power consumption may constitute the primary bottleneck to scaling.

</details>


### [5] [SplitCom: Communication-efficient Split Federated Fine-tuning of LLMs via Temporal Compression](https://arxiv.org/abs/2602.10564)
*Tao Li,Yulin Tang,Yiyang Song,Cong Wu,Xihui Liu,Pan Li,Xianhao Chen*

Main category: cs.NI

TL;DR: SplitCom：一种通信高效的联邦学习框架，通过利用连续训练周期中激活的时序冗余，选择性上传显著变化的激活，减少LLM联邦微调中的通信开销。


<details>
  <summary>Details</summary>
Motivation: 在设备端大语言模型联邦微调中，虽然避免了原始数据共享保护了隐私，但计算和内存需求对资源受限的边缘设备构成挑战。分割联邦学习将模型划分为轻量级客户端和计算密集型服务器端子模型，但高维激活交换导致通信开销过大。

Method: 1）利用视频压缩思想，仅当激活与先前周期出现显著偏差时才选择性上传；2）引入两种自适应阈值控制方案（bang-bang控制或DDPG强化学习）平衡通信效率和学习性能；3）实施降维技术减轻客户端内存需求；4）扩展到U型架构确保服务器不访问客户端标签。

Result: 实验表明，SplitCom在标准配置下将上行通信成本降低高达98.6%，在U型变体中将总通信成本降低高达95.8%，且不明显影响模型性能。

Conclusion: SplitCom通过利用激活的时序冗余和自适应阈值控制，有效解决了分割联邦学习中大语言模型的高通信开销问题，在保持模型性能的同时显著降低了通信成本。

Abstract: Federated fine-tuning of on-device large language models (LLMs) mitigates privacy concerns by preventing raw data sharing. However, the intensive computational and memory demands pose significant challenges for resource-constrained edge devices. To overcome these limitations, split federated learning (SFL) emerges as a promising solution that partitions the model into lightweight client-side and compute-intensive server-side sub-models, thus offloading the primary training workload to a powerful server. Nevertheless, high-dimensional activation exchanges in SFL lead to excessive communication overhead. To overcome this, we propose SplitCom, a communication-efficient SFL framework for LLMs that exploits temporal redundancy in activations across consecutive training epochs. Inspired by video compression, the core innovation of our framework lies in selective activation uploading only when a noticeable deviation from previous epochs occurs. To balance communication efficiency and learning performance, we introduce two adaptive threshold control schemes based on 1) bang-bang control or 2) deep deterministic policy gradient (DDPG)-based reinforcement learning. Moreover, we implement dimensionality reduction techniques to alleviate client-side memory requirements. Furthermore, we extend SplitCom to the U-shape architecture, ensuring the server never accesses clients' labels. Extensive simulations and laboratory experiments demonstrate that SplitCom reduces uplink communication costs by up to 98.6\,\% in its standard configuration and total communication costs by up to 95.8\,\% in its U-shape variant without noticeably compromising model performance.

</details>


### [6] [Security, Privacy and System-Level Resillience of 6G End-to-End System: Hexa-X-II Perspective](https://arxiv.org/abs/2602.10734)
*Pawani Porambage,Diego Lopez,Antonio Pastor,Bin Han,José María Jorquera Valero,Manuel Gil Pérez,Noelia Pérez Palma,Antonio Skarmeta,Prajnamaya Dass,Stefan Köpsell,Sonika Ujjwal,Javier José Díaz Rivera,Pol Alemany,Raul Muñoz,Jafar Mohammadi,Chaitanya Aggarwal,Betul Guvenc Paltun,Ferhat Karakoc*

Main category: cs.NI

TL;DR: Hexa-X-II项目总结了6G网络的安全、隐私和弹性控制措施及其验证框架


<details>
  <summary>Details</summary>
Motivation: 6G网络需要克服前几代网络的限制并满足新兴用户需求，Hexa-X-II项目作为欧洲6G旗舰项目，在开发技术和锚定端到端系统方面发挥主导作用

Method: 识别安全、隐私和弹性控制措施，并建立相应的验证框架

Result: 总结了Hexa-X-II项目确定的安全、隐私和弹性控制措施及其验证框架

Conclusion: 该项目为6G网络的安全、隐私和弹性提供了重要的控制措施和验证方法，有助于6G系统的整体发展

Abstract: The sixth generation (6G) of mobile networks are being developed to overcome limitations in previous generations and meet emerging user demands. As a European project, the Smart Networks and Services Joint Undertaking (SNS JU) 6G Flagship project Hexa-X-II has a leading role for developing technologies and anchoring 6G end-to-end system. This paper summarizes the security, privacy and resilient (SPR) controls identified by Hexa-X-II project and their validation frameworks.

</details>


### [7] [Less is More: The Dilution Effect in Multi-Link Wireless Sensing](https://arxiv.org/abs/2602.10823)
*Bruno Rodrigues,Karim Khamaisi*

Main category: cs.NI

TL;DR: 研究发现，在无线传感中，单个精心布置的链路比密集的多链路网络性能更好，因为多链路融合会产生"稀释效应"，噪声会淹没有用信号。


<details>
  <summary>Details</summary>
Motivation: 无线传感技术有望成为隐私保护的运动检测器，但商业应用有限。传统假设认为密集传感器部署能提高准确性，本研究旨在验证这一假设。

Method: 在住宅环境中进行为期12天的自然研究，使用9节点ESP32-C3网状网络（72个传感链路），比较单个链路与完整网络的性能。

Result: 单个精心布置的链路（AUC 0.541）优于完整的72链路网络（AUC 0.489），效果差异显著（Cohen's d=0.86）。随机链路选择与优化选择无显著差异（p=0.35）。

Conclusion: 无线传感中链路战略布置比分类器选择重要2.7倍，多链路融合会产生"稀释效应"，噪声会淹没有用信号。研究发布了312小时标记数据供验证。

Abstract: Wireless sensing approaches promise to transform smart infrastructures into privacy-preserving motion detectors, yet commercial adoption remains limited. A common assumption may explain this gap: that denser sensor deployments yield better accuracy. We tested this assumption with a 12-day naturalistic study using a 9-node ESP32-C3 mesh (72 sensing links) in a residential environment. Our results show that a single well-placed link outperformed the full 72-link mesh (AUC 0.541 vs. 0.489, Cohen's $d$=0.86). Even a random link selection matched optimized selection ($p$=0.35). The benefit comes from avoiding multi-link fusion, not from choosing the right link. We attribute this to a "dilution effect": links whose Fresnel zones miss activity regions contribute noise that overwhelms signal from informative links. In our deployment, strategic link placement mattered 2.7$\times$ more than classifier choice. We release 312 hours of labeled CSI data, firmware, and analysis code to enable validation across diverse environments.

</details>


### [8] [AI Infrastructure Sovereignty](https://arxiv.org/abs/2602.10900)
*Sergio Cruzes*

Main category: cs.NI

TL;DR: AI主权已从软件控制转向基础设施控制，需要数据中心、光网络和自动化框架的协同设计，在能源和可持续性约束下实现可操作的主权。


<details>
  <summary>Details</summary>
Motivation: AI已从软件为中心转向基础设施驱动，仅控制数据和算法已不足以实现真正的AI主权。实际主权取决于在能源可用性、可持续性目标和网络覆盖等约束下部署、运营和适应AI基础设施的能力。

Method: 提出AI基础设施主权概念，分析三个协同设计层：AI导向的数据中心（考虑功率密度、冷却、能源耦合）、光传输网络（延迟、容量、故障域、管辖控制）、以及提供实时可见性和控制的自动化框架（遥测、智能AI、数字孪生）。

Result: 构建了主权AI基础设施的参考架构，整合遥测管道、基于代理的控制和数字孪生，将可持续性作为首要设计约束，实现跨计算、网络和能源领域的闭环控制。

Conclusion: AI主权现在取决于基础设施控制能力，需要通过数据中心、光网络和自动化框架的协同设计，在物理和环境限制下实现可操作的主权，将可持续性作为核心设计原则。

Abstract: Artificial intelligence has shifted from a software-centric discipline to an infrastructure-driven system. Large-scale training and inference increasingly depend on tightly coupled data centers, high-capacity optical networks, and energy systems operating close to physical and environmental limits. As a result, control over data and algorithms alone is no longer sufficient to achieve meaningful AI sovereignty. Practical sovereignty now depends on who can deploy, operate, and adapt AI infrastructure under constraints imposed by energy availability, sustainability targets, and network reach. This tutorial-survey introduces the concept of AI infrastructure sovereignty, defined as the ability of a region, operator, or nation to exercise operational control over AI systems within physical and environmental limits. The paper argues that sovereignty emerges from the co-design of three layers: AI-oriented data centers, optical transport networks, and automation frameworks that provide real-time visibility and control. We analyze how AI workloads reshape data center design, driving extreme power densities, advanced cooling requirements, and tighter coupling to local energy systems, with sustainability metrics such as carbon intensity and water usage acting as hard deployment boundaries. We then examine optical networks as the backbone of distributed AI, showing how latency, capacity, failure domains, and jurisdictional control define practical sovereignty limits. Building on this foundation, the paper positions telemetry, agentic AI, and digital twins as enablers of operational sovereignty through validated, closed-loop control across compute, network, and energy domains. The tutorial concludes with a reference architecture for sovereign AI infrastructure that integrates telemetry pipelines, agent-based control, and digital twins, framing sustainability as a first-order design constraint.

</details>


### [9] [A Robust Optimization Approach for Regenerator Placement in Fault-Tolerant Networks Under Discrete Cost Uncertainty](https://arxiv.org/abs/2602.11058)
*Mohammad Khosravi,Setareh Maghsudi*

Main category: cs.NI

TL;DR: 研究鲁棒可生存通信网络中的再生器放置问题，考虑链路故障和成本不确定性，提出两种整数规划方法


<details>
  <summary>Details</summary>
Motivation: 在鲁棒可生存通信网络中，链路和节点可能故障，信号传输距离有限需要再生器，且安装维护成本存在不确定性，需要找到最小成本的再生器放置方案

Method: 提出两种解决方案：基于流的整数规划公式和基于割的整数规划公式，以及它们的迭代精确方法

Result: 理论和实验结果表明所提方法的有效性

Conclusion: 成功解决了鲁棒通信网络中的再生器放置问题，提出的整数规划方法能够有效找到最小成本的再生器配置方案

Abstract: We focus on robust, survivable communication networks, where network links and nodes are affected by an uncertainty set. In this sense, any network links might fail. Besides, a signal can only travel a maximum distance before its quality falls below a certain threshold, necessitating its regeneration by regenerators installed at network nodes. In addition, the price of installing and maintaining regenerators belongs to a discrete uncertainty set. Robust optimization seeks a solution with guaranteed performance against all scenarios modeled in an uncertainty set. Thus, the problem is to find a subset of nodes with minimum cost for the placement of the regenerator, ensuring that all nodes can communicate even if a subset of network links fails. To solve the problem optimally, we propose two solution approaches, including one flow-based and one cut-based integer programming formulation, as well as their iterative exact method. Our theoretical and experimental results show the effectiveness of our methods.

</details>


### [10] [WHEREIS: IP Address Registration Geo-Consistency](https://arxiv.org/abs/2602.11102)
*Robert Beverly,Amreesh Phokeer,Oliver Gasser*

Main category: cs.NI

TL;DR: 开发WHEREIS系统测量IP前缀在RIR区域级别的实际使用位置，发现注册信息存在不一致性，特别是在AFRINIC区域，IPv6与IPv4同样存在问题，影响商业地理位置数据库准确性。


<details>
  <summary>Details</summary>
Motivation: RIR系统负责IP地址资源分配和注册，注册数据的准确性直接影响互联网运营、管理、安全和优化。IP地址稀缺加剧了RIR政策与IP注册所有权和使用之间的冲突，自由市场分配与公平区域政策之间的紧张关系已导致法律诉讼，威胁RIR系统的存在。

Method: 开发WHEREIS测量方法，在RIR区域粒度上定位已分配的IPv4和IPv6前缀。定义"地理一致性"分类法，比较前缀的测量地理位置与分配RIR覆盖区域以及注册组织位置。收集不一致前缀的额外信息，与网络运营商、IP租赁提供商合作，并与三个RIR协作验证。

Result: 总体上超过98%的前缀与地理位置推断一致，但各RIR间存在显著差异，以AFRINIC为案例研究。IPv6注册并不比IPv4更一致，表明结构性问题而非技术问题在分配中起重要作用。发现的不一致性也体现在三个商业地理位置数据库中。

Conclusion: 通过提高分配后前缀使用的透明度，希望改进使用IP注册数据的应用程序，并为正在进行的区域内地址使用和政策讨论提供信息。测量方法揭示了注册数据准确性的问题，特别是结构性问题对IP分配的影响。

Abstract: The five Regional Internet Registries (RIRs) provide the critical function of IP address resource del egation and registration. The accuracy of registration data directly impacts Internet operation, management, security, and optimization. In addition, the scarcity of IP addresses has brought into focus conflicts between RIR policy and IP registration ownership and use. The tension between a free-market based approach to address allocation versus policies to promote fairness and regional equity has resulted in court litigation that threatens the very existence of the RIR system.
  We develop WHEREIS, a measurement-based approach to geolocate delegated IPv4 and IPv6 prefixes at an RIR-region granularity and systematically study where addresses are used post-allocation and the extent to which registration information is accurate. We define a taxonomy of registration ``geo-consistency'' that compares a prefix's measured geolocation to the allocating RIR's coverage region as well as the registered organization's location. While in aggregate over 98% of the prefixes we examine are consistent with our geolocation inferences, there is substantial variation across RIRs and we focus on AFRINIC as a case study. IPv6 registrations are no more consistent than IPv4, suggesting that structural, rather than technical, issues play an important role in allocations. We solicit additional information on inconsistent prefixes from network operators, IP leasing providers, and collaborate with three RIRs to obtain validation. We further show that the inconsistencies we discover manifest in three commercial geolocation databases. By improving the transparency around post-allocation prefix use, we hope to improve applications that use IP registration data and inform ongoing discussions over in-region address use and policy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [Discovering Differences in Strategic Behavior Between Humans and LLMs](https://arxiv.org/abs/2602.10324)
*Caroline Wang,Daniel Kasenberg,Kim Stachenfeld,Pablo Samuel Castro*

Main category: cs.AI

TL;DR: 使用AlphaEvolve工具发现可解释模型，分析人类与LLM在迭代剪刀石头布游戏中的战略行为差异，发现前沿LLM比人类表现出更深层的战略能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在社交和战略场景中的部署增加，需要理解其行为与人类的差异。现有行为博弈论模型无法完全捕捉人类或LLM等黑箱非人类代理的独特行为。

Method: 采用AlphaEvolve这一前沿程序发现工具，直接从数据中发现人类和LLM行为的可解释模型，实现对人类和LLM行为驱动因素的开源发现。

Result: 在迭代剪刀石头布游戏中，前沿LLM展现出比人类更深层的战略行为能力，揭示了人类与LLM在战略互动中的结构性差异。

Conclusion: 研究为理解人类与LLM在战略互动中行为差异的结构性驱动因素奠定了基础，表明需要新的建模方法来捕捉LLM的战略行为特征。

Abstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to directly discover interpretable models of human and LLM behavior from data, thereby enabling open-ended discovery of structural factors driving human and LLM behavior. Our analysis on iterated rock-paper-scissors reveals that frontier LLMs can be capable of deeper strategic behavior than humans. These results provide a foundation for understanding structural differences driving differences in human and LLM behavior in strategic interactions.

</details>


### [12] [LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation](https://arxiv.org/abs/2602.10367)
*Zhiling Yan,Dingjie Song,Zhe Fang,Yisheng Ji,Xiang Li,Quanzheng Li,Lichao Sun*

Main category: cs.AI

TL;DR: LiveMedBench：一个持续更新、无数据污染、基于评分标准的临床医学基准，通过每周从在线医疗社区收集真实病例，解决现有医学基准的静态性、数据污染和时间错位问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学基准存在两个关键局限：1) 数据污染（测试集泄露到训练数据中导致性能估计虚高）；2) 时间错位（无法捕捉医学知识的快速演进）。此外，当前开放式临床推理评估指标要么依赖浅层词汇重叠（如ROUGE），要么依赖主观的LLM-as-a-Judge评分，都不足以验证临床正确性。

Method: 1) 构建LiveMedBench基准：每周从在线医疗社区收集真实临床病例，确保与模型训练数据的严格时间分离；2) 多智能体临床筛选框架：过滤原始数据噪声，基于循证医学原则验证临床完整性；3) 自动化基于评分标准的评估框架：将医生回答分解为细粒度的病例特定标准，比LLM-as-a-Judge评分与专家医生更一致。

Result: LiveMedBench包含2,756个真实病例，涵盖38个医学专科和多种语言，配有16,702个独特评估标准。对38个LLM的广泛评估显示：最佳模型仅达到39.2%的准确率；84%的模型在截止日期后的病例上表现下降，证实了普遍的数据污染风险；错误分析表明35-48%的失败源于无法将医学知识适应患者特定约束，上下文应用而非事实知识是主要瓶颈。

Conclusion: LiveMedBench提供了一个可靠、动态的临床医学评估基准，揭示了LLM在临床推理中的实际局限性，特别是数据污染问题和上下文应用能力不足，为未来临床AI系统的开发提供了重要指导。

Abstract: The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.

</details>


### [13] [Found-RL: foundation model-enhanced reinforcement learning for autonomous driving](https://arxiv.org/abs/2602.10458)
*Yansong Qu,Zihao Sheng,Zilin Huang,Jiancong Chen,Yuhao Luo,Tianyi Wang,Yiheng Feng,Samuel Labi,Sikai Chen*

Main category: cs.AI

TL;DR: Found-RL平台通过异步批量推理框架解决VLM在RL训练中的延迟问题，使用VMR和AWAG机制将VLM知识蒸馏到RL策略中，并采用改进的CLIP进行奖励塑造，使轻量RL模型达到接近VLM的性能。


<details>
  <summary>Details</summary>
Motivation: RL在自动驾驶中存在样本效率低和语义可解释性不足的问题，而基础模型（特别是VLM）能提供丰富的上下文知识，但其高推理延迟阻碍了在高频RL训练循环中的部署。

Method: 1) 异步批量推理框架解耦VLM推理与仿真循环；2) VMR和AWAG机制将VLM动作建议蒸馏到RL策略；3) 采用高吞吐量CLIP进行密集奖励塑造，并通过条件对比动作对齐解决CLIP的动态盲点问题。

Result: 轻量RL模型能达到接近数十亿参数VLM的性能，同时保持实时推理（约500 FPS），解决了VLM延迟瓶颈问题。

Conclusion: Found-RL为自动驾驶中的RL提供了高效的基础模型集成平台，通过创新的异步推理和知识蒸馏机制，实现了高性能与实时性的平衡。

Abstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.

</details>


### [14] [MERIT Feedback Elicits Better Bargaining in LLM Negotiators](https://arxiv.org/abs/2602.10467)
*Jihwan Oh,Murad Aghazada,Yooju Shin,Se-Young Yun,Taehyeon Kim*

Main category: cs.AI

TL;DR: 提出AgoraBench基准测试框架，通过效用反馈机制增强LLM在复杂谈判场景中的战略深度和人类偏好对齐能力


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在谈判场景中战略深度不足，难以适应复杂的人类因素，现有基准测试未能充分捕捉这一局限

Method: 提出基于效用反馈的框架：1) AgoraBench基准，涵盖9个挑战性场景；2) 基于效用理论的人类对齐经济指标；3) 人类偏好数据集和学习管道，通过提示和微调增强LLM谈判能力

Result: 基线LLM策略常偏离人类偏好，而提出的机制显著提升谈判性能，产生更深层的战略行为和更强的对手意识

Conclusion: 通过效用反馈框架和人类偏好对齐，可以显著增强LLM在复杂谈判场景中的战略能力和适应性

Abstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.

</details>


### [15] [Abstraction Generation for Generalized Planning with Pretrained Large Language Models](https://arxiv.org/abs/2602.10485)
*Zhenhe Cui,Huaxiang Xia,Hangjun Shen,Kailun Luo,Yong He,Wei Liang*

Main category: cs.AI

TL;DR: LLMs可作为QNP抽象生成器，通过自动调试方法修复抽象错误，为广义规划问题生成有用的QNP抽象


<details>
  <summary>Details</summary>
Motivation: 探索LLMs能否作为QNP抽象生成器为广义规划问题服务，并研究如何通过自动调试修复抽象错误

Method: 提出提示协议：输入GP领域和训练任务给LLMs，让其生成抽象特征并进一步抽象初始状态、动作集和目标为QNP问题；设计自动调试方法检测抽象错误，指导LLMs修复抽象

Result: 实验表明，在自动调试的适当指导下，某些LLMs能够生成有用的QNP抽象

Conclusion: LLMs可以作为QNP抽象生成器，结合自动调试方法能够有效生成和修复抽象，为广义规划问题提供支持

Abstract: Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: input a GP domain and training tasks to LLMs, prompting them to generate abstract features and further abstract the initial state, action set, and goal into QNP problems. An automated debugging method is designed to detect abstraction errors, guiding LLMs to fix abstractions. Experiments demonstrate that under properly guided by automated debugging, some LLMs can generate useful QNP abstractions.

</details>


### [16] [Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets](https://arxiv.org/abs/2602.10583)
*Bo Xue,Yunchong Song,Fanghao Shao,Xuekai Zhu,Lin Chen,Luoyi Fu,Xinbing Wang,Zhouhan Lin*

Main category: cs.AI

TL;DR: FoSS提出基于生成流网络的跨度生成框架，通过动态跨度词汇和DAG状态空间提升文本生成多样性和质量


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型使用固定词汇表，形成树状状态空间，限制了生成灵活性和表达能力。现有动态词汇方法虽然引入检索文本跨度，但忽略了同一句子可由不同长度跨度组成，缺乏对DAG状态空间的显式建模，导致组合路径探索受限和路径选择偏差。

Method: 提出Flow of SpanS (FoSS)框架：1) 通过灵活分割检索文本构建动态跨度词汇表；2) 确保DAG结构状态空间，使生成流网络能够探索多样组合路径；3) 使用专门的奖励模型指导生成过程。

Result: FoSS在文本生成任务上比Transformer提升MAUVE分数达12.5%，在知识密集型任务上获得3.5%的增益，持续优于最先进方法。扩展实验显示FoSS受益于更大模型、更多数据和更丰富的检索语料库。

Conclusion: FoSS通过将生成流网络应用于跨度生成，解决了传统方法在状态空间结构上的限制，实现了更灵活、多样和高质量的文本生成，为语言模型生成能力提供了新方向。

Abstract: Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.

</details>


### [17] [Neuro-symbolic Action Masking for Deep Reinforcement Learning](https://arxiv.org/abs/2602.10598)
*Shuai Han,Mehdi Dastani,Shihan Wang*

Main category: cs.AI

TL;DR: 提出NSAM框架，通过自动学习符号模型来约束DRL中的不可行动作，提高样本效率并减少约束违反


<details>
  <summary>Details</summary>
Motivation: 现有方法需要手动指定符号基础函数和动作掩码技术，这限制了DRL在实际约束环境中的应用。需要一种能自动学习符号模型并约束动作的方法。

Method: 提出神经符号动作掩码（NSAM）框架，在DRL过程中以最小监督方式自动学习与高维状态域约束一致的符号模型，基于学习的符号模型生成动作掩码排除不可行动作，实现符号推理与深度策略优化的端到端集成。

Result: 在多个约束域上的实验表明，NSAM显著提高了DRL智能体的样本效率，同时大幅减少了约束违反。

Conclusion: NSAM框架成功实现了符号推理与深度强化学习的有效集成，通过自动学习符号模型和动作掩码，解决了DRL在约束环境中的动作可行性问题，具有实际应用价值。

Abstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.

</details>


### [18] [To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks](https://arxiv.org/abs/2602.10625)
*Nanxu Gong,Haotian Li,Sixun Dong,Jianxun Lian,Yanjie Fu,Xing Xie*

Main category: cs.AI

TL;DR: 研究发现推理模型在心理理论任务上并不比非推理模型表现更好，有时甚至更差，揭示了推理模型在社交推理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在数学和编程等正式推理任务上取得了进展，但尚不清楚这些优势是否能转移到心理理论这样的社交认知技能上。本研究旨在系统评估推理模型在心理理论任务上的表现。

Method: 对9个先进的大型语言模型进行系统研究，比较推理模型与非推理模型在三个代表性心理理论基准测试上的表现。通过细粒度分析揭示问题，并设计了两种干预方法：慢到快自适应推理和思考到匹配捷径预防。

Result: 推理模型在心理理论任务上并不一致优于非推理模型，有时表现更差。分析发现：1）慢思考崩溃：回答越长准确率越低；2）适度自适应推理有益；3）选项匹配捷径：移除选项后推理模型表现显著提升。干预方法验证并缓解了这些问题。

Conclusion: 推理模型在正式推理任务上的进步不能完全转移到心理理论这样的社交推理任务中。实现稳健的心理理论需要开发超越现有推理方法的独特能力。

Abstract: Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.

</details>


### [19] [OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization](https://arxiv.org/abs/2602.10635)
*Keane Ong,Sabri Boughorbel,Luwei Xiao,Chanakya Ekbote,Wei Dai,Ao Qu,Jingyao Wu,Rui Mao,Ehsan Hoque,Erik Cambria,Gianmarco Mengaldo,Paul Pu Liang*

Main category: cs.AI

TL;DR: HARPO是一种新的强化学习方法，通过调节优势函数来平衡异构任务和样本的学习，开发了Omnisapiens-7B 2.0社交行为基础模型，在多项行为任务上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常孤立地建模人类行为维度（如情感、认知或社会属性），虽然有用但任务特定建模会增加训练成本并限制跨行为设置的泛化能力。最近的推理RL方法虽然能在多个行为任务上训练统一模型，但没有明确解决跨异构行为数据的学习问题。

Method: 提出了异构感知相对策略优化（HARPO），这是一种RL方法，通过调节优势函数来确保在策略优化过程中没有任何单个任务或样本产生不成比例的影响，从而平衡跨异构任务和样本的学习。

Result: 使用HARPO开发了Omnisapiens-7B 2.0社交行为处理基础模型。相对于现有行为基础模型，在多项行为任务上取得了最强性能，多任务和保留设置分别提升了+16.85%和+9.37%，同时产生更明确和鲁棒的推理轨迹。HARPO在与其他RL方法的比较中也表现出最一致强大的性能。

Conclusion: HARPO方法有效解决了跨异构行为数据学习的挑战，开发出的Omnisapiens-7B 2.0模型在社交行为处理任务上表现出色，为开发社会智能AI提供了有效的技术路径。

Abstract: To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.

</details>


### [20] [Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation](https://arxiv.org/abs/2602.10699)
*Jie Jiang,Yangru Huang,Zeyu Wang,Changping Wang,Yuling Xiong,Jun Zhang,Huan Yu*

Main category: cs.AI

TL;DR: V-STAR框架通过价值引导采样和树状优势强化学习，解决生成式推荐中RL训练的概率-奖励不匹配问题，提升探索效率和多样性。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐中的强化学习存在概率-奖励不匹配问题：传统基于似然的解码偏向局部高概率前缀，导致探索不足和优势压缩，限制了模型发现高奖励但低概率物品的能力。

Method: 提出V-STAR框架，包含两个协同组件：1) 价值引导高效解码(VED)，识别关键节点并选择性深化高潜力前缀；2) Sibling-GRPO，利用树状拓扑计算兄弟相对优势，集中学习信号于关键分支决策。

Result: 在离线和在线数据集上的实验表明，V-STAR在严格延迟约束下，在准确性和候选集多样性方面均优于现有最先进基线方法。

Conclusion: V-STAR通过价值引导采样和树状优势强化学习的协同设计，有效解决了生成式推荐中RL训练的概率-奖励不匹配问题，实现了更好的探索效率和推荐质量。

Abstract: Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.

</details>


### [21] [Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act](https://arxiv.org/abs/2602.10802)
*Da-Lun Chen,Prasasthy Balasubramanian,Lauri Lovén,Susanna Pirttikangas,Jaakko Sauvola,Panagiotis Kostakos*

Main category: cs.AI

TL;DR: 研究调查了高等教育中生成式AI的感知情况，重点关注ITEE领域，通过混合方法识别了共同和学科特定的主题，提出了负责任整合的框架和高级要求。


<details>
  <summary>Details</summary>
Motivation: 高等教育中生成式AI工具已被广泛采用，但利益相关者的看法存在分歧，受文化、学科和制度背景影响。欧盟AI法案要求大学确保认知系统的合规性，因此需要了解利益相关者需求并定制AI整合方案。

Method: 采用混合方法，对奥卢大学ITEE学院的61名教职员工和37名学生进行调查，分析他们对生成式AI的感知和需求。

Result: 研究揭示了共同和学科特定的主题：对编程支持的强烈兴趣，以及对响应质量、隐私和学术诚信的担忧。识别了高级要求并提出了负责任整合的概念框架。

Conclusion: 学科特定要求强调了利益相关者参与的重要性。高级要求和框架为大学利用生成式AI提供了实用指导，同时解决利益相关者关切并确保合规性。

Abstract: Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.

</details>


### [22] [See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch](https://arxiv.org/abs/2602.10814)
*Xingyi Zhang,Yulei Ye,Kaifeng Huang,Wenhao Li,Xiangfeng Wang*

Main category: cs.AI

TL;DR: ScratchWorld：一个用于评估多模态GUI代理在Scratch中通过图形界面构建程序能力的基准测试，包含83个任务，采用两种交互模式来诊断代理失败原因。


<details>
  <summary>Details</summary>
Motivation: 虽然Scratch等基于块的编程环境在低代码教育中扮演核心角色，但评估AI代理通过图形用户界面构建程序的能力仍然研究不足。需要系统评估多模态GUI代理在程序构建任务中的表现。

Method: 基于Use-Modify-Create教学框架设计83个任务，涵盖Create、Debug、Extend、Compute四类问题。采用两种交互模式：primitive模式（细粒度拖放操作）评估视觉运动控制，composite模式（高级语义API）分离程序推理和GUI执行。提出基于执行的评估协议，在浏览器环境中通过运行时测试验证程序功能正确性。

Result: 对最先进的多模态语言模型和GUI代理进行广泛实验，揭示了显著的推理-行动差距，表明尽管规划能力强，但在细粒度GUI操作方面仍存在持续挑战。

Conclusion: ScratchWorld基准测试为评估多模态GUI代理的程序构建能力提供了系统框架，揭示了当前代理在GUI操作方面的局限性，为未来研究指明了方向。

Abstract: Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.

</details>


### [23] [SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy](https://arxiv.org/abs/2602.10845)
*Xuecheng Zou,Yu Tang,Bingbing Wang*

Main category: cs.AI

TL;DR: SynergyKGC通过跨模态协同专家和密度依赖的身份锚定策略，解决知识图谱补全中的结构分辨率不匹配问题，显著提升命中率。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全方法面临"结构分辨率不匹配"问题：无法协调不同图密度下的表示需求，导致密集簇中的结构噪声干扰和稀疏区域的表示崩溃。

Method: 提出SynergyKGC框架：1) 将传统邻居聚合提升为主动的跨模态协同专家，使用关系感知的交叉注意力和语义意图驱动的门控；2) 结合密度依赖的身份锚定策略和双塔一致性架构，协调拓扑异质性并确保表示稳定性。

Result: 在两个公共基准测试上的系统评估验证了方法的优越性，显著提升了KGC命中率，为非均匀结构化数据中的弹性信息整合提供了经验证据。

Conclusion: SynergyKGC通过自适应框架有效解决了知识图谱补全中的结构异质性问题，实现了预训练实体语义与异构拓扑结构的协同融合，为关系推理提供了稳健的解决方案。

Abstract: Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical "structural resolution mismatch," failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.

</details>


### [24] [Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics](https://arxiv.org/abs/2602.10885)
*Leheng Sheng,Wenchang Ma,Ruixin Hong,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: RLCER：无需人工标注的自主奖励方法，通过自提出和自演进的评分标准来奖励CoT推理，超越基于结果的RLVR方法


<details>
  <summary>Details</summary>
Motivation: 传统奖励CoT推理的方法面临两大挑战：1）训练奖励模型需要大量人工标注；2）静态奖励模型难以适应不断演化的CoT分布且容易受到奖励攻击。因此需要一种无需人工标注且能自主演进的CoT奖励方法。

Method: 提出RLCER方法，在基于结果的RLVR基础上，通过自提出和自演进的评分标准来奖励CoT推理。该方法能够自主生成评分标准并随时间演进，即使在没有结果奖励的情况下也能提供可靠的CoT监督信号。

Result: RLCER在性能上超越了基于结果的RLVR方法。此外，当将这些自提出的评分标准作为提示中的提示信息时，还能进一步提升推理时的性能表现。

Conclusion: RLCER提供了一种有效的自主奖励CoT推理的方法，无需人工标注且能适应演化，为LLM推理训练提供了新的解决方案。

Abstract: Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \textbf{RLCER} (\textbf{R}einforcement \textbf{L}earning with \textbf{C}oT Supervision via Self-\textbf{E}volving \textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.

</details>


### [25] [Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation](https://arxiv.org/abs/2602.10964)
*F. Carichon,R. Rampa,G. Farnadi*

Main category: cs.AI

TL;DR: LLMs在文化适应方面存在根本性缺陷：尽管能生成流畅内容，但无法根据文化距离产生有意义的适应，在烹饪食谱生成中表现出与人类不同的模式，文化信息在模型内部表征中保存较弱。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地用于生成和塑造文化内容，但先前研究表明它们存在系统性文化偏见，可能引发刻板印象、同质化和文化特定表达形式的抹除。理解LLMs是否能超越主流文化而有意义地适应多元文化仍然是一个关键挑战。

Method: 通过烹饪食谱这一文化、传统和创造力紧密交织的领域研究LLMs的文化适应能力。使用GlobalFusion数据集，该数据集根据文化距离测量配对不同国家的人类食谱。使用相同国家配对，用多个LLMs生成文化适应食谱，从而直接比较人类和LLM在跨文化内容创作中的行为。

Result: LLMs无法产生具有文化代表性的适应。与人类不同，它们生成的食谱差异与文化距离不相关。文化信息在模型内部表征中保存较弱；模型通过误解创造性和传统等概念来夸大新颖性；无法将适应与相关国家联系起来，也无法将其建立在文化显著元素（如食材）上。

Conclusion: 当前LLMs在文化导向生成方面存在根本性限制，这对它们在文化敏感应用中的使用具有重要影响。研究揭示了LLMs在文化适应方面的系统性缺陷，需要更深入理解模型如何编码和处理文化信息。

Abstract: Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.

</details>


### [26] [CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion](https://arxiv.org/abs/2602.10999)
*Yusong Lin,Haiyang Wang,Shuzhe Wu,Lue Fan,Feiyang Pan,Sanyuan Zhao,Dandan Tu*

Main category: cs.AI

TL;DR: 提出CLI-Gym方法，通过模拟环境历史来大规模生成环境密集型任务，并训练出LiberCoder模型在终端任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 代理编码需要与环境有效交互，但缺乏大规模的环境密集型任务来增强代理能力。现有方法难以获取这类任务

Method: 基于Dockerfile与代理任务的类比，让代理模拟探索环境历史，通过执行反馈引导。从健康环境的历史中回溯到早期有运行时故障的状态，将错误状态和相应错误信息打包生成任务

Result: 生成了1,655个环境密集型任务，是目前同类任务中最大的集合。训练出的LiberCoder模型在Terminal-Bench上取得+21.1%的绝对提升（达到46.1%），优于多个强基线

Conclusion: 提出了首个公开的可扩展环境密集型任务生成管道CLI-Gym，通过大规模任务生成和轨迹微调显著提升了代理在终端任务上的性能

Abstract: Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.

</details>


### [27] [GameDevBench: Evaluating Agentic Capabilities Through Game Development](https://arxiv.org/abs/2602.11103)
*Wayne Chi,Yixiong Fang,Arnav Yayavaram,Siddharth Yayavaram,Seth Karten,Qiuhong Anna Wei,Runkun Chen,Alexander Wang,Valerie Chen,Ameet Talwalkar,Chris Donahue*

Main category: cs.AI

TL;DR: 提出了GameDevBench基准测试，用于评估多模态AI在游戏开发任务中的能力，包含132个复杂任务，当前最佳AI仅能解决54.5%的任务


<details>
  <summary>Details</summary>
Motivation: 当前编码智能体发展迅速，但多模态智能体进展滞后，缺乏结合软件开发复杂性和深度多模态理解的评估基准。游戏开发提供了理想的测试场景，需要处理大型代码库和多种多模态资源

Method: 从网络和视频教程中提取132个游戏开发任务构建GameDevBench基准，包含游戏玩法、2D图形等不同类型任务。引入两种简单的图像和视频反馈机制来增强智能体的多模态能力

Result: 游戏开发任务非常复杂，平均解决方案需要比先前软件基准多3倍的代码行数和文件修改。最佳智能体仅能解决54.5%的任务，任务难度与多模态复杂性强相关（游戏玩法任务46.9%成功率 vs 2D图形任务31.6%）。反馈机制显著提升性能，Claude Sonnet 4.5从33.3%提升到47.7%

Conclusion: 游戏开发是多模态智能体评估的重要测试平台，当前AI仍面临挑战。简单的多模态反馈机制能有效提升性能，GameDevBench的发布将支持智能体游戏开发的进一步研究

Abstract: Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.

</details>


### [28] [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](https://arxiv.org/abs/2602.11136)
*Jiayi Zhou,Yang Sheng,Hantao Lou,Yaodong Yang,Jie Fu*

Main category: cs.AI

TL;DR: 提出FoT框架，使用双向形式思维架构，将自然语言需求转化为可验证的形式化规范，为LLM智能体提供数学保证而非概率评分


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体在现实世界高风险领域应用增多，确保其行为安全至关重要。当前主流的LLM-as-a-Judge监督范式面临根本困境：概率系统如何可靠监督其他概率系统而不继承其失败模式？形式化验证提供了原则性解决方案，但自然语言需求到形式化规范的转换成为关键瓶颈。

Method: 提出FoT神经符号框架，采用双向形式思维架构：LLM作为规范编译器，自上而下将高层人类意图分解为原子化、可验证的约束，然后自下而上使用Dafny规范和Z3可满足性模理论求解器证明合规性，产生数学保证而非概率评分。

Result: 在三个基准测试（行为安全、多领域约束遵守、智能体向上欺骗检测）上验证，实验涉及7个智能体模型。FoT相比LLM-as-a-Judge基线平均提升16.6%，实现弱到强泛化（7B模型检测72B智能体欺骗准确率超90%），通过迭代细化提供接近线性的安全改进。

Conclusion: FoT框架通过形式化验证解决了LLM智能体监督的根本困境，将自然语言需求转化为可验证的形式化规范，为智能体行为安全提供数学保证，显著优于概率评分方法，并展示了弱到强泛化的潜力。

Abstract: As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [29] [Robust Semantic Transmission for Low-Altitude UAVs: Predictive Channel-Aware Scheduling and Generative Reconstruction](https://arxiv.org/abs/2602.10482)
*Jijia Tian,Junting Chen,Pooi-Yuen Kam*

Main category: cs.IT

TL;DR: 提出一种无人机下行视觉传输框架，将语义内容解耦为确定性的结构组件和随机性的纹理组件，通过预测性传输和信道感知调度优先传输结构信息，显著提升抗信道衰落能力。


<details>
  <summary>Details</summary>
Motivation: 无人机下行视觉传输面临带宽稀缺和动态信道损伤的挑战，传统深度联合信源信道编码方法在特定时隙深度衰落时会导致全局重建失败，需要更鲁棒的传输方案。

Method: 将语义内容解耦为确定性结构组件和随机性纹理组件，开发预测性传输框架，采用分流变分编解码器和信道感知调度器，优先在可靠时隙传输结构布局信息。

Result: 相比单流基线方法，该方法在峰值信噪比上获得5.6 dB增益，并在显著预测失配情况下保持结构保真度。

Conclusion: 通过语义内容解耦和差异化错误保护策略，能够有效应对无人机下行链路的不确定性，显著提升视觉传输的鲁棒性和重建质量。

Abstract: Unmanned aerial vehicle (UAV) downlink transmission facilitates critical time-sensitive visual applications but is fundamentally constrained by bandwidth scarcity and dynamic channel impairments. The rapid fluctuation of the air-to-ground (A2G) link creates a regime where reliable transmission slots are intermittent and future channel quality can only be predicted with uncertainty. Conventional deep joint source-channel coding (DeepJSCC) methods transmit coupled feature streams, causing global reconstruction failure when specific time slots experience deep fading. Decoupling semantic content into a deterministic structure component and a stochastic texture component enables differentiated error protection strategies aligned with channel reliability. A predictive transmission framework is developed that utilizes a split-stream variational codec and a channel-aware scheduler to prioritize the delivery of structural layout over reliable slots. Experimental evaluations indicate that this approach achieves a 5.6 dB gain in peak signal-to-noise (SNR) ratio over single-stream baselines and maintains structural fidelity under significant prediction mismatch.

</details>


### [30] [Predictive-State Communication: Innovation Coding and Reconciliation under Delay](https://arxiv.org/abs/2602.10542)
*Ozgur Ercetin,Mohaned Chraiti*

Main category: cs.IT

TL;DR: 论文提出预测状态通信(PSC)框架，用共享预测状态和传输创新信息替代传统符号传输，形成感知-容量带而非单边阈值


<details>
  <summary>Details</summary>
Motivation: 当通信两端都拥有强大预测器（如大语言模型）时，传统基于符号可靠传输的香农理论不再是最佳操作范式，需要新的通信框架来利用预测能力

Method: 提出预测状态通信(PSC)：收发端维护显式共享预测状态，物理信道主要传输创新信息（接收端预测轨迹与发送端实际轨迹的校正信息），引入状态标识符、锚点、有界回滚和基于补丁的更新等协议架构

Result: PSC将熵率计算替换为模型失配下的交叉熵计算，引入依赖容量、延迟和感知连续性要求的可行性约束，形成有界的感知-容量带而非单边阈值，通过示例展示了可行性区域及其对预测质量的依赖

Conclusion: 预测状态通信为利用现代预测器能力提供了新框架，改变了传统通信的性能边界概念，为未来通信系统设计提供了新的理论基础和架构方向

Abstract: Shannon theory models communication as the reliable transfer of symbol sequences, with performance governed by capacity and rate-distortion limits. When both endpoints possess strong predictors -- as in modern large language models and related generative priors -- literal symbol transport is no longer the only operational regime. We propose predictive-state communication (PSC), in which the transmitter and receiver maintain an explicit shared predictive state, and the physical channel is used primarily to convey innovations, i.e., corrective information that reconciles the receiver's provisional trajectory with the transmitter's realized trajectory. This viewpoint replaces entropy-rate accounting by cross-entropy accounting under model mismatch, and it introduces feasibility constraints that depend jointly on capacity, delay, and perceptual continuity requirements; the resulting operating set is typically a bounded perception-capacity band rather than a one-sided threshold. We outline the protocol and architectural implications (state identifiers, anchors, bounded rollback, and patch-based updates) and provide a stylized illustrative example to visualize the induced feasibility region and its dependence on predictive quality.

</details>


### [31] [Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band](https://arxiv.org/abs/2602.10813)
*Pradyumna Kumar Bishoyi,Chia Chia Lee,Navid Keshtiarast,Marina Petrova*

Main category: cs.IT

TL;DR: 论文提出了一种基于强化学习的优化框架，通过联合控制地面网络的下行功率、上行功率和天线倾角来保护非地面网络链路，同时保持地面网络性能，解决了FR3频段共存中的干扰问题。


<details>
  <summary>Details</summary>
Motivation: 在FR3频段上，地面网络（TN）和非地面网络（NTN）共存存在严重干扰问题，密集的TN部署会严重降低NTN下行性能。现有方法依赖干扰消除波束成形、预编码或排除区域，需要准确的信道状态信息和静态协调，不适用于动态NTN场景。

Method: 开发了一个优化框架，联合控制TN下行功率、上行功率和天线倾角来保护NTN链路。采用基于近端策略优化（PPO）的强化学习方法来解决TN和NTN参数之间的非凸耦合问题，开发自适应功率和倾角控制策略。

Result: 仿真结果显示，该方法能将中值干扰噪声比（INR）降低高达8dB，同时保持超过87%的TN基站活动率，优于传统基线方法，验证了所提策略在FR3共存中的可行性。

Conclusion: 提出的基于强化学习的优化框架有效解决了FR3频段TN和NTN共存中的干扰问题，通过自适应功率和倾角控制策略，在保护NTN链路的同时保持了TN性能，为动态NTN场景提供了可行的解决方案。

Abstract: The coexistence of terrestrial networks (TN) and non-terrestrial networks (NTN) in the frequency range 3 (FR3) upper mid-band presents considerable interference concerns, as dense TN deployments can severely degrade NTN downlink performance. Existing studies rely on interference-nulling beamforming, precoding, or exclusion zones that require accurate channel state information (CSI) and static coordination, making them unsuitable for dynamic NTN scenarios. To overcome these limitations, we develop an optimization framework that jointly controls TN downlink power, uplink power, and antenna downtilt to protect NTN links while preserving terrestrial performance. The resultant non-convex coupling between TN and NTN parameters is addressed by a Proximal Policy Optimization (PPO)-based reinforcement learning method that develops adaptive power and tilt control strategies. Simulation results demonstrate a reduction up to 8 dB in the median interference-to-noise ratio (INR) while maintaining over 87% TN basestation activity, outperforming conventional baseline methods and validating the feasibility of the proposed strategy for FR3 coexistence.

</details>


### [32] [MacWilliams identities for the generalized rank weights](https://arxiv.org/abs/2602.10929)
*Julien Molina*

Main category: cs.IT

TL;DR: 本文研究线性码的广义秩重量分布，建立了MacWilliams型恒等式，给出了枚举多项式公式，并计算了MRD码的分布


<details>
  <summary>Details</summary>
Motivation: 研究线性码的广义秩重量分布对于理解码的结构和性能具有重要意义，特别是在秩度量码的背景下

Method: 1. 建立广义秩重量分布的MacWilliams型恒等式，将码与其对偶码的分布联系起来
2. 推导广义秩重量分布的枚举多项式公式
3. 针对最大秩距离码（MRD码）进行具体的分布计算

Result: 1. 成功建立了广义秩重量分布的MacWilliams型恒等式
2. 得到了广义秩重量分布的枚举多项式公式
3. 明确计算出了MRD码的广义秩重量分布

Conclusion: 本文系统研究了线性码的广义秩重量分布，建立了理论框架，为秩度量码的分析提供了重要工具，特别是对MRD码的分布计算具有实际应用价值

Abstract: We study the generalized rank weight distribution of a linear code. First, we provide a MacWilliams-type identity which relates the distributions of a code and its dual. Then, we give a formula for the enumerator polynomial. Finally, we explicitly compute the distribution of an MRD code.

</details>


### [33] [Information Abstraction for Data Transmission Networks based on Large Language Models](https://arxiv.org/abs/2602.11022)
*Haoyuan Zhu,Haonan Hu,Jie Zhang*

Main category: cs.IT

TL;DR: 提出信息抽象度(DIA)这一量化指标，用于衡量表示在压缩输入数据的同时保留任务相关语义的能力，并在LLM引导的视频传输任务中实现99.75%的传输量减少。


<details>
  <summary>Details</summary>
Motivation: 生物系统（特别是人脑）通过多层次的信息抽象实现卓越的能效，而现代人工智能和通信系统在传输低层数据时消耗大量能量，缺乏对抽象的重视。目前缺乏形式化和计算化的信息抽象理论。

Method: 引入信息抽象度(DIA)这一通用度量标准，推导出可处理的信息论公式，并提出基于DIA的信息抽象框架。以LLM引导的视频传输任务为案例研究，应用DIA进行抽象感知编码。

Result: 在LLM引导的视频传输任务中，基于DIA的抽象感知编码将传输量减少了99.75%，同时保持了语义保真度。

Conclusion: DIA为智能系统中能量与信息的重新平衡提供了原则性工具，为神经网络设计、神经形态计算、语义通信和联合感知-通信架构开辟了新方向。

Abstract: Biological systems, particularly the human brain, achieve remarkable energy efficiency by abstracting information across multiple hierarchical levels. In contrast, modern artificial intelligence and communication systems often consume significant energy overheads in transmitting low-level data, with limited emphasis on abstraction. Despite its implicit importance, a formal and computational theory of information abstraction remains absent. In this work, we introduce the Degree of Information Abstraction (DIA), a general metric that quantifies how well a representation compresses input data while preserving task-relevant semantics. We derive a tractable information-theoretic formulation of DIA and propose a DIA-based information abstraction framework. As a case study, we apply DIA to a large language model (LLM)-guided video transmission task, where abstraction-aware encoding significantly reduces transmission volume by $99.75\%$, while maintaining semantic fidelity. Our results suggest that DIA offers a principled tool for rebalancing energy and information in intelligent systems and opens new directions in neural network design, neuromorphic computing, semantic communication, and joint sensing-communication architectures.

</details>


### [34] [Enormous Fluid Antenna Systems (E-FAS) for Multiuser MIMO: Channel Modeling and Analysis](https://arxiv.org/abs/2602.11099)
*Farshad Rostami Ghadi,Kai-Kit Wong,Masoud Kaveh,Wee Kiat New,Chan-Byoung Chae,Lajos Hanzo*

Main category: cs.IT

TL;DR: E-FAS将智能表面从被动反射器转变为多功能电磁接口，支持表面波和空间波传播，本文建立了其端到端信道模型并分析了单用户和多用户场景下的性能。


<details>
  <summary>Details</summary>
Motivation: E-FAS作为一种新的架构范式，将智能表面重新定位为多功能电磁接口，能够通过墙壁、天花板和建筑立面引导表面波，同时发射空间波到目标接收器。这种扩展功能引入了新的信号传播模式，需要对其性能进行理论分析。

Method: 首先开发了物理一致性的端到端信道模型，将表面阻抗波公式与小尺度衰落耦合。针对单用户场景推导了中断概率和遍历容量的闭式解；针对多用户场景推导了SINR分布和遍历和速率的可处理近似。

Result: 分析表明E-FAS保持了小尺度衰落决定的多样性阶数，同时通过圆柱表面波传播提高了编码增益。高信噪比渐近分析量化了E-FAS相对于纯空间波传播的增益。

Conclusion: E-FAS在保持小尺度衰落多样性的同时，通过表面波传播显著提升了系统性能，为无线通信提供了新的架构范式。

Abstract: Enormous fluid antenna systems (E-FAS), the system concept that utilizes position reconfigurability in the large scale, have emerged as a new architectural paradigm where intelligent surfaces are repurposed from passive smart reflectors into multi-functional electromagnetic (EM) interfaces that can route guided surface waves over walls, ceilings, and building facades, as well as emit space waves to target receivers. This expanded functionality introduces a new mode of signal propagation, enabling new forms of wireless communication. In this paper, we provide an analytical performance characterization of an E-FAS-enabled wireless link. We first develop a physics-consistent end-to-end channel model that couples a surface-impedance wave formulation with small-scale fading on both the base station (BS)-surface and launcher-user segments. We illustrate that the resulting effective BS-user channel remains circularly symmetric complex Gaussian, with an enhanced average power that explicitly captures surface-wave attenuation and junction losses. For single-user cases with linear precoding, we derive the outage probability and ergodic capacity in closed forms, together with high signal-to-noise ratio (SNR) asymptotics that quantify the gain of E-FAS over purely space-wave propagation. For the multiuser case with zero-forcing (ZF) precoding, we derive the distribution of the signal-to-interference-plus-noise ratio (SINR) and obtain tractable approximations for the ergodic sum-rate, explicitly revealing how the E-FAS macro-gain interacts with the BS spatial degrees of freedom (DoF). In summary, our analysis shows that E-FAS preserves the diversity order dictated by small-scale fading while improving the coding gain enabled by cylindrical surface-wave propagation.

</details>
