{"id": "2511.14284", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14284", "abs": "https://arxiv.org/abs/2511.14284", "authors": ["Ran Tamir", "Nir Weinberger", "Albert Guill\u00e9n i F\u00e0bregas"], "title": "DNA Storage in the Short Molecule Regime", "comment": null, "summary": "We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.", "AI": {"tldr": "\u672c\u6587\u5b8c\u6210\u4e86DNA\u5b58\u50a8\u7cfb\u7edf\u4e2d\u77edDNA\u5206\u5b50\u53ef\u5b58\u50a8\u4fe1\u606f\u91cf\u7684\u731c\u60f3\u8bc1\u660e\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7f16\u7801\u65b9\u6848\uff0c\u5176\u4e2d\u968f\u673a\u7f16\u7801\u65b9\u6848\u5b9e\u73b0\u4e86\u4e0e\u5df2\u6709\u4e0b\u754c\u5339\u914d\u7684\u53ef\u8fbe\u6027\u754c\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6848\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\u4f46\u5728\u6781\u77ed\u5206\u5b50\u8303\u56f4\u5185\u672a\u8fbe\u6700\u4f18\u3002", "motivation": "\u7814\u7a76DNA\u5b58\u50a8\u7cfb\u7edf\u4e2d\u77edDNA\u5206\u5b50\u80fd\u591f\u53ef\u9760\u5b58\u50a8\u7684\u4fe1\u606f\u91cf\uff0c\u9a8c\u8bc1Shomorony\u548c Heckel (2022)\u63d0\u51fa\u7684\u5173\u4e8e\u4fe1\u606f\u4f4d\u6570\u7f29\u653e\u89c4\u5f8b\u7684\u731c\u60f3\u3002", "method": "\u5206\u6790\u4e86\u968f\u673a\u7f16\u7801\u65b9\u6848\uff0c\u5176\u4e2d\u7801\u5b57\u901a\u8fc7\u91cf\u5316\u4ece\u6982\u7387\u5355\u7eaf\u5f62\u4e2d\u968f\u673a\u751f\u6210\u7684\u6982\u7387\u8d28\u91cf\u51fd\u6570\u83b7\u5f97\uff0c\u5e76\u5206\u6790\u4e86\u6700\u4f18\u6700\u5927\u4f3c\u7136\u89e3\u7801\u5668\uff1b\u8fd8\u63d0\u51fa\u4e86\u7b2c\u4e8c\u79cd\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\u7684\u7f16\u7801\u65b9\u6848\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86\u4e0e\u6700\u8fd1\u5efa\u7acb\u7684\u4e0b\u754c\u5728\u6574\u4e2a\u77ed\u5206\u5b50\u8303\u56f4\u5185\u5339\u914d\u7684\u53ef\u8fbe\u6027\u754c\uff1b\u7b2c\u4e8c\u79cd\u65b9\u6848\u5728\u9664\u7279\u5b9a\u6781\u77ed\u5206\u5b50\u8303\u56f4\u5916\u5b9e\u73b0\u4e86\u6700\u4f18\u7f29\u653e\u3002", "conclusion": "\u5b8c\u6210\u4e86DNA\u5b58\u50a8\u7cfb\u7edf\u77ed\u5206\u5b50\u4fe1\u606f\u5bb9\u91cf\u731c\u60f3\u7684\u8bc1\u660e\uff0c\u63d0\u4f9b\u4e86\u4e24\u79cd\u7f16\u7801\u65b9\u6848\uff0c\u5176\u4e2d\u968f\u673a\u7f16\u7801\u65b9\u6848\u5b8c\u5168\u5339\u914d\u7406\u8bba\u754c\u9650\uff0c\u800c\u4f4e\u590d\u6742\u5ea6\u65b9\u6848\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2511.14444", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14444", "abs": "https://arxiv.org/abs/2511.14444", "authors": ["Zhou Li", "Xiang Zhang", "Yizhou Zhao", "Haiqiang Chen", "Jihao Fan", "Giuseppe Caire"], "title": "The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys", "comment": "13 pages, 2 pages", "summary": "This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\\ge K-T$. Otherwise, when $2\\le G<K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5b9e\u7528\u5206\u7ec4\u5bc6\u94a5\u548c\u6297\u4e32\u8c0b\u6761\u4ef6\u4e0b\u7684\u53bb\u4e2d\u5fc3\u5316\u5b89\u5168\u805a\u5408\u95ee\u9898\uff0c\u786e\u5b9a\u4e86\u6700\u4f18\u7684\u901a\u4fe1\u901f\u7387\u548c\u5bc6\u94a5\u901f\u7387\u533a\u57df\u3002", "motivation": "\u53d7\u9ad8\u6548\u5206\u7ec4\u5bc6\u94a5\u751f\u6210\u534f\u8bae\u7684\u542f\u53d1\uff0c\u7814\u7a76\u5728\u5bf9\u79f0\u5206\u7ec4\u5bc6\u94a5\u8bbe\u7f6e\u4e0b\u7684\u5b89\u5168\u805a\u5408\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u7ec4G\u4e2a\u7528\u6237\u5171\u4eab\u72ec\u7acb\u7684\u5206\u7ec4\u5bc6\u94a5\uff0c\u65e8\u5728\u4e3a\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u901a\u4fe1\u548c\u5bc6\u94a5\u9ad8\u6548\u7684\u5b89\u5168\u805a\u5408\u8bbe\u8ba1\u601d\u8def\u3002", "method": "\u8003\u8651K\u4e2a\u7528\u6237\u901a\u8fc7\u65e0\u5dee\u9519\u5e7f\u64ad\u4fe1\u9053\u4e92\u8fde\uff0c\u6bcf\u4e2a\u7528\u6237\u6301\u6709\u79c1\u6709\u8f93\u5165\uff0c\u4f7f\u7528\u5206\u7ec4\u5bc6\u94a5\u6765\u63a9\u76d6\u8f93\u5165\uff0c\u540c\u65f6\u6ee1\u8db3\u6062\u590d\u548c\u5b89\u5168\u7ea6\u675f\u3002\u5206\u6790\u5728\u5206\u7ec4\u5bc6\u94a5\u7ed3\u6784\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u901f\u7387\u533a\u57df\u3002", "result": "\u5f53G=1\u6216G\u2265K-T\u65f6\uff0c\u5206\u7ec4\u5bc6\u94a5DSA\u4e0d\u53ef\u884c\uff1b\u5f532\u2264G<K-T\u65f6\uff0c\u4e3a\u5b89\u5168\u8ba1\u7b97\u4e00\u4e2a\u671f\u671b\u548c\u7b26\u53f7\uff0c\u6bcf\u4e2a\u7528\u6237\u5fc5\u987b\u5e7f\u64ad\u81f3\u5c11\u4e00\u4e2a\u7b26\u53f7\uff0c\u6bcf\u4e2a\u5206\u7ec4\u5bc6\u94a5\u5fc5\u987b\u5305\u542b\u81f3\u5c11(K-T-2)/C(K-T-1,G)\u4e2a\u72ec\u7acb\u7b26\u53f7\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5206\u7ec4\u5bc6\u94a5DSA\u7684\u57fa\u672c\u6781\u9650\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u901a\u4fe1\u548c\u5bc6\u94a5\u9ad8\u6548\u5b89\u5168\u805a\u5408\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u89c1\u89e3\u3002"}}
{"id": "2511.14480", "categories": ["cs.IT", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.14480", "abs": "https://arxiv.org/abs/2511.14480", "authors": ["Ananda Chakraborty"], "title": "Monimial Matrix Analogue of Yoshida's theorem", "comment": null, "summary": "In this paper, we study variants of weight enumerators of linear codes over $\\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6709\u9650\u57df\u4e0a\u7ebf\u6027\u7801\u7684\u6743\u91cd\u679a\u4e3e\u5668\u53d8\u4f53\uff0c\u63a8\u5e7f\u4e86\u5e73\u5747\u5b8c\u5168\u8054\u5408\u6743\u91cd\u679a\u4e3e\u5668\u7684\u6982\u5ff5\uff0c\u5efa\u7acb\u4e86MacWilliams\u578b\u6052\u7b49\u5f0f\u548cYoshida\u5b9a\u7406\u7684\u5355\u9879\u5f0f\u7c7b\u4f3c\u7269\u3002", "motivation": "\u7814\u7a76\u6709\u9650\u57df\u4e0a\u7ebf\u6027\u7801\u7684\u6743\u91cd\u679a\u4e3e\u5668\u53d8\u4f53\uff0c\u7279\u522b\u662f\u63a8\u5e7f\u5e73\u5747\u5b8c\u5168\u8054\u5408\u6743\u91cd\u679a\u4e3e\u5668\u7684\u6982\u5ff5\uff0c\u4ee5\u6df1\u5316\u5bf9\u7f16\u7801\u7406\u8bba\u4e2d\u6743\u91cd\u5206\u5e03\u6027\u8d28\u7684\u7406\u89e3\u3002", "method": "\u63a8\u5e7f\u5e73\u5747\u5b8c\u5168\u8054\u5408\u6743\u91cd\u679a\u4e3e\u5668\u6982\u5ff5\uff0c\u5efa\u7acbMacWilliams\u578b\u6052\u7b49\u5f0f\uff0c\u5e76\u53d1\u5c55Yoshida\u5b9a\u7406\u7684\u5355\u9879\u5f0f\u77e9\u9635\u7c7b\u4f3c\u7269\u3002", "result": "\u63d0\u51fa\u4e86\u5e73\u5747\u5b8c\u5168\u8054\u5408\u6743\u91cd\u679a\u4e3e\u5668\u7684\u5e7f\u4e49\u8868\u793a\uff0c\u5e76\u5efa\u7acb\u4e86\u76f8\u5e94\u7684Yoshida\u5b9a\u7406\u5355\u9879\u5f0f\u7c7b\u4f3c\u7269\u3002", "conclusion": "\u6210\u529f\u63a8\u5e7f\u4e86\u5e73\u5747\u5b8c\u5168\u8054\u5408\u6743\u91cd\u679a\u4e3e\u5668\u7406\u8bba\uff0c\u5efa\u7acb\u4e86\u76f8\u5173\u6052\u7b49\u5f0f\u548c\u5b9a\u7406\uff0c\u4e3a\u7f16\u7801\u7406\u8bba\u4e2d\u7684\u6743\u91cd\u5206\u5e03\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2511.14520", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14520", "abs": "https://arxiv.org/abs/2511.14520", "authors": ["Haoyu Liang", "Zhentian Zhang", "Jian Dang", "Hao Jiang", "Zaichen Zhang"], "title": "Neural Networks-Enabled Channel Reconstruction for Fluid Antenna Systems: A Data-Driven Approach", "comment": null, "summary": "Fluid antenna systems (FASs) offer substantial spatial diversity by exploiting the electromagnetic port correlation within compact array spaces, thereby generating favorable small-scale fading conditions with beneficial channel gain envelope fluctuations. This unique capability opens new opportunities for a wide range of communication applications and emerging technologies. However, accurate channel state information (CSI) must be acquired before a fluid antenna can be effectively utilized. Although several efforts have been made toward channel reconstruction in FASs, a generally applicable solution to both model-based or model-free scenario with both high precision and efficient computational flow remains lacking. In this work, we propose a data-driven channel reconstruction approach enabled by neural networks. The proposed framework not only achieves significantly enhanced reconstruction accuracy but also requires substantially lower computational complexity compared with existing model-free methods. Numerical results further demonstrate the rapid convergence and robust reconstruction capability of the proposed scheme, outperforming current state-of-the-art techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u636e\u9a71\u52a8\u4fe1\u9053\u91cd\u5efa\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\uff0c\u5728\u63d0\u9ad8\u91cd\u5efa\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u5229\u7528\u7d27\u51d1\u9635\u5217\u7a7a\u95f4\u5185\u7684\u7535\u78c1\u7aef\u53e3\u76f8\u5173\u6027\u63d0\u4f9b\u7a7a\u95f4\u5206\u96c6\uff0c\u4f46\u9700\u8981\u51c6\u786e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u3002\u73b0\u6709\u4fe1\u9053\u91cd\u5efa\u65b9\u6cd5\u7f3a\u4e4f\u540c\u65f6\u9002\u7528\u4e8e\u6a21\u578b\u9a71\u52a8\u548c\u65e0\u6a21\u578b\u573a\u666f\u7684\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7f51\u7edc\u9a71\u52a8\u7684\u6570\u636e\u9a71\u52a8\u4fe1\u9053\u91cd\u5efa\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u9a71\u52a8\u548c\u65e0\u6a21\u578b\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u5728\u91cd\u5efa\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6280\u672f\uff0c\u5177\u6709\u5feb\u901f\u6536\u655b\u548c\u9c81\u68d2\u7684\u91cd\u5efa\u80fd\u529b\u3002", "conclusion": "\u8be5\u795e\u7ecf\u7f51\u7edc\u9a71\u52a8\u7684\u4fe1\u9053\u91cd\u5efa\u65b9\u6cd5\u4e3a\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7cbe\u786e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u89e3\u51b3\u65b9\u6848\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.14098", "categories": ["cs.AI", "cs.MA", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14098", "abs": "https://arxiv.org/abs/2511.14098", "authors": ["Adit Jain", "Vikram Krishnamurthy", "Yiming Zhang"], "title": "Collaborative QA using Interacting LLMs. Impact of Network Structure, Node Capability and Distributed Data", "comment": null, "summary": "In this paper, we model and analyze how a network of interacting LLMs performs collaborative question-answering (CQA) in order to estimate a ground truth given a distributed set of documents. This problem is interesting because LLMs often hallucinate when direct evidence to answer a question is lacking, and these effects become more pronounced in a network of interacting LLMs. The hallucination spreads, causing previously accurate LLMs to hallucinate. We study interacting LLMs and their hallucination by combining novel ideas of mean-field dynamics (MFD) from network science and the randomized utility model from economics to construct a useful generative model. We model the LLM with a latent state that indicates if it is truthful or not with respect to the ground truth, and extend a tractable analytical model considering an MFD to model the diffusion of information in a directed network of LLMs. To specify the probabilities that govern the dynamics of the MFD, we propose a randomized utility model. For a network of LLMs, where each LLM has two possible latent states, we posit sufficient conditions for the existence and uniqueness of a fixed point and analyze the behavior of the fixed point in terms of the incentive (e.g., test-time compute) given to individual LLMs. We experimentally study and analyze the behavior of a network of $100$ open-source LLMs with respect to data heterogeneity, node capability, network structure, and sensitivity to framing on multiple semi-synthetic datasets.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u7f51\u7edc\u4e2d\u7684\u534f\u4f5c\u95ee\u7b54\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5e7b\u89c9\u5728LLM\u7f51\u7edc\u4e2d\u7684\u4f20\u64ad\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5e73\u5747\u573a\u52a8\u529b\u5b66\u548c\u968f\u673a\u6548\u7528\u6a21\u578b\u7684\u751f\u6210\u6a21\u578b\u6765\u5efa\u6a21\u8fd9\u4e00\u8fc7\u7a0b\u3002", "motivation": "LLM\u5728\u7f3a\u4e4f\u76f4\u63a5\u8bc1\u636e\u65f6\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u800c\u5728\u4ea4\u4e92\u7684LLM\u7f51\u7edc\u4e2d\uff0c\u8fd9\u79cd\u5e7b\u89c9\u6548\u5e94\u4f1a\u6269\u6563\uff0c\u5bfc\u81f4\u539f\u672c\u51c6\u786e\u7684LLM\u4e5f\u5f00\u59cb\u4ea7\u751f\u5e7b\u89c9\u3002", "method": "\u7ed3\u5408\u7f51\u7edc\u79d1\u5b66\u4e2d\u7684\u5e73\u5747\u573a\u52a8\u529b\u5b66\u548c\u7ecf\u6d4e\u5b66\u4e2d\u7684\u968f\u673a\u6548\u7528\u6a21\u578b\uff0c\u6784\u5efa\u751f\u6210\u6a21\u578b\u3002\u5c06LLM\u5efa\u6a21\u4e3a\u5177\u6709\u6f5c\u5728\u72b6\u6001\uff08\u771f\u5b9e\u6216\u5e7b\u89c9\uff09\u7684\u8282\u70b9\uff0c\u5206\u6790\u6709\u5411\u7f51\u7edc\u4e2d\u4fe1\u606f\u6269\u6563\u7684\u52a8\u6001\u8fc7\u7a0b\u3002", "result": "\u4e3a\u5177\u6709\u4e24\u79cd\u6f5c\u5728\u72b6\u6001\u7684LLM\u7f51\u7edc\u5efa\u7acb\u4e86\u56fa\u5b9a\u70b9\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u6fc0\u52b1\u5bf9\u56fa\u5b9a\u70b9\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u5728100\u4e2a\u5f00\u6e90LLM\u7f51\u7edc\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u7814\u7a76\u3002", "conclusion": "\u901a\u8fc7\u5e73\u5747\u573a\u52a8\u529b\u5b66\u548c\u968f\u673a\u6548\u7528\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u5efa\u6a21LLM\u7f51\u7edc\u4e2d\u7684\u5e7b\u89c9\u4f20\u64ad\uff0c\u4e3a\u7406\u89e3\u548c\u7ba1\u7406LLM\u534f\u4f5c\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2511.13782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13782", "abs": "https://arxiv.org/abs/2511.13782", "authors": ["Xiaoxing Lian", "Aidong Yang", "Jun Zhu", "Peng Wang", "Yue Zhang"], "title": "Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models", "comment": "10 pages,a detail and effective benchmark for spatial reasoning", "summary": "Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances", "AI": {"tldr": "SpatiaLite\u662f\u4e00\u4e2a\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u5148\u8fdbVLM\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u8868\u793a\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\uff0c\u5728\u89c6\u89c9\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u3002\u4f5c\u8005\u63d0\u51fa\u4e86IDF\u6846\u67b6\u6765\u6539\u8fdbVLM\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u3001\u95ee\u9898\u89e3\u51b3\u548c\u51b3\u7b56\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7a7a\u95f4\u63a8\u7406\uff08\u5305\u62ec\u5fc3\u7406\u65cb\u8f6c\u3001\u5bfc\u822a\u548c\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\uff09\u4ecd\u7136\u662f\u5f53\u524d\u5148\u8fdbVLM\u7684\u91cd\u5927\u6311\u6218\u3002\u4f5c\u8005\u5047\u8bbe\u60f3\u8c61\u529b\u662f\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u4e3b\u5bfc\u63a8\u7406\u673a\u5236\u3002", "method": "\u5f15\u5165SpatiaLite\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8054\u5408\u6d4b\u91cf\u7a7a\u95f4\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\u5206\u6790VLM\u7684\u7a7a\u95f4\u63a8\u7406\u673a\u5236\uff0c\u5e76\u63d0\u51faImagery Driven Framework\uff08IDF\uff09\u7528\u4e8e\u6570\u636e\u5408\u6210\u548c\u8bad\u7ec3\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u7ed3\u679c\uff1a1\uff09\u5148\u8fdbVLM\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u8868\u793a\uff0c\u5728\u89c6\u89c9\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1b2\uff09VLM\u7a7a\u95f4\u63a8\u7406\u6548\u7387\u4e25\u91cd\u4f4e\u4e0b\uff0ctoken\u4f7f\u7528\u968f\u8f6c\u6362\u590d\u6742\u5ea6\u5feb\u901f\u589e\u52a0\uff1b3\uff09IDF\u6846\u67b6\u53ef\u4ee5\u9690\u5f0f\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63cf\u7ed8\u4e86\u5148\u8fdbVLM\u7684\u7a7a\u95f4\u63a8\u7406\u9650\u5236\u548c\u6a21\u5f0f\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u7f3a\u9677\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002IDF\u6846\u67b6\u4e3a\u6784\u5efa\u5177\u6709\u66f4\u597d\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684VLM\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.14457", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14457", "abs": "https://arxiv.org/abs/2511.14457", "authors": ["Michael Gundall", "Jan Herbst", "Robin M\u00fcller", "Hans D. Schotten"], "title": "Benchmarking OpenWiFiSync on ESP32: Towards Cost-Effective Wireless Time Synchronization", "comment": null, "summary": "Wireless time synchronization of mobile devices is a key enabler for numerous Industry 4.0 applications, such as coordinated and synchronized tasks or the generation of high-precision timestamps for machine learning or artificial intelligence algorithms. Traditional wireline clock synchronization protocols, however, cannot achieve the performance in wireless environments without significant modifications. To address this challenge, we make use of the Reference Broadcast Infrastructure Synchronization protocol, which leverages the broadcast nature of wireless communications and remains both non-invasive and standard-compliant. We implement and validate this protocol on a low-cost testbed using ESP32 modules and a commercial Wi-Fi access point. To support further research and development, we release our implementation as open-source software under the GNU General Public License Version 3 license via the OpenWifiSync project on GitHub.\n  Our results demonstrate that synchronization accuracies within +/-30 microseconds are achievable using energy-efficient and affordable hardware, making this approach suitable for a wide range of use cases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWi-Fi\u5e7f\u64ad\u7684\u65e0\u7ebf\u65f6\u95f4\u540c\u6b65\u534f\u8bae\uff0c\u5728\u4f4e\u6210\u672cESP32\u786c\u4ef6\u4e0a\u5b9e\u73b0\u4e86\u00b130\u5fae\u79d2\u7684\u540c\u6b65\u7cbe\u5ea6\uff0c\u5e76\u5f00\u6e90\u4e86\u5b9e\u73b0\u4ee3\u7801\u3002", "motivation": "\u65e0\u7ebf\u79fb\u52a8\u8bbe\u5907\u7684\u65f6\u95f4\u540c\u6b65\u662f\u5de5\u4e1a4.0\u5e94\u7528\u7684\u5173\u952e\u9700\u6c42\uff0c\u4f46\u4f20\u7edf\u6709\u7ebf\u65f6\u949f\u540c\u6b65\u534f\u8bae\u5728\u65e0\u7ebf\u73af\u5883\u4e2d\u6027\u80fd\u4e0d\u4f73\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53c2\u8003\u5e7f\u64ad\u57fa\u7840\u8bbe\u65bd\u540c\u6b65\u534f\u8bae\uff0c\u5229\u7528\u65e0\u7ebf\u901a\u4fe1\u7684\u5e7f\u64ad\u7279\u6027\uff0c\u5728ESP32\u6a21\u5757\u548c\u5546\u7528Wi-Fi\u63a5\u5165\u70b9\u4e0a\u5b9e\u73b0\u975e\u4fb5\u5165\u5f0f\u3001\u6807\u51c6\u517c\u5bb9\u7684\u540c\u6b65\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u8282\u80fd\u4e14\u7ecf\u6d4e\u5b9e\u60e0\u7684\u786c\u4ef6\u53ef\u4ee5\u5b9e\u73b0\u00b130\u5fae\u79d2\u7684\u540c\u6b65\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\uff0c\u5e76\u901a\u8fc7OpenWifiSync\u9879\u76ee\u5f00\u6e90\u4e86\u5b9e\u73b0\u4ee3\u7801\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u5f00\u53d1\u3002"}}
{"id": "2511.14524", "categories": ["cs.IT", "cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.14524", "abs": "https://arxiv.org/abs/2511.14524", "authors": ["Venkat Chandar", "Aslan Tchamkerten", "Shashank Vatedka"], "title": "Compression with Privacy-Preserving Random Access", "comment": null, "summary": "It is shown that an i.i.d. binary source sequence $X_1, \\ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \\emph{no} information about the other bits $\\{X_j : j \\neq i\\}$.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86\u4e00\u4e2ai.i.d.\u4e8c\u8fdb\u5236\u6e90\u5e8f\u5217\u53ef\u4ee5\u5728\u4efb\u610f\u9ad8\u4e8e\u71b5\u7387\u7684\u901f\u7387\u4e0b\u8fdb\u884c\u65e0\u635f\u538b\u7f29\uff0c\u4f7f\u5f97\u5bf9\u4efb\u4f55\u5355\u4e2a\u6bd4\u7279\u7684\u89e3\u7801\u4e0d\u4f1a\u6cc4\u9732\u5176\u4ed6\u6bd4\u7279\u7684\u4fe1\u606f\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u538b\u7f29\u6570\u636e\u7684\u540c\u65f6\u4fdd\u62a4\u5355\u4e2a\u6bd4\u7279\u7684\u9690\u79c1\uff0c\u9632\u6b62\u5728\u89e3\u7801\u67d0\u4e2a\u6bd4\u7279\u65f6\u6cc4\u9732\u5176\u4ed6\u6bd4\u7279\u7684\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u65b9\u6cd5\u5206\u6790i.i.d.\u4e8c\u8fdb\u5236\u6e90\u5e8f\u5217\u7684\u538b\u7f29\uff0c\u786e\u4fdd\u5728\u65e0\u635f\u538b\u7f29\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5355\u4e2a\u6bd4\u7279\u89e3\u7801\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u5b58\u5728\u8fd9\u6837\u7684\u538b\u7f29\u65b9\u6848\uff0c\u53ef\u4ee5\u5728\u4efb\u610f\u9ad8\u4e8e\u71b5\u7387\u7684\u538b\u7f29\u901f\u7387\u4e0b\u5b9e\u73b0\uff0c\u4f7f\u5f97\u89e3\u7801\u5355\u4e2a\u6bd4\u7279\u4e0d\u4f1a\u6cc4\u9732\u5176\u4ed6\u6bd4\u7279\u7684\u4efb\u4f55\u4fe1\u606f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5728\u65e0\u635f\u538b\u7f29\u4e2d\u5b9e\u73b0\u5f3a\u9690\u79c1\u4fdd\u62a4\u7684\u53ef\u80fd\u6027\uff0c\u4e3a\u5b89\u5168\u6570\u636e\u538b\u7f29\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.13798", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13798", "abs": "https://arxiv.org/abs/2511.13798", "authors": ["Mohammad Reza Shafie", "Morteza Hajiabadi", "Hamed Khosravi", "Mobina Noori", "Imtiaz Ahmed"], "title": "KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention for 3D Modeling of Complex Structures", "comment": null, "summary": "Microbial Fuel Cells (MFCs) offer a promising pathway for sustainable energy generation by converting organic matter into electricity through microbial processes. A key factor influencing MFC performance is the anode structure, where design and material properties play a crucial role. Existing predictive models struggle to capture the complex geometric dependencies necessary to optimize these structures. To solve this problem, we propose KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention. KANGURA introduces a new approach to three-dimensional (3D) machine learning modeling. It formulates prediction as a function decomposition problem, where Kolmogorov-Arnold Network (KAN)- based representation learning reconstructs geometric relationships without a conventional multi- layer perceptron (MLP). To refine spatial understanding, geometry-disentangled representation learning separates structural variations into interpretable components, while unified attention mechanisms dynamically enhance critical geometric regions. Experimental results demonstrate that KANGURA outperforms over 15 state-of-the-art (SOTA) models on the ModelNet40 benchmark dataset, achieving 92.7% accuracy, and excels in a real-world MFC anode structure problem with 97% accuracy. This establishes KANGURA as a robust framework for 3D geometric modeling, unlocking new possibilities for optimizing complex structures in advanced manufacturing and quality-driven engineering applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86KANGURA\u6846\u67b6\uff0c\u4f7f\u7528Kolmogorov-Arnold\u7f51\u7edc\u8fdb\u884c3D\u51e0\u4f55\u5efa\u6a21\uff0c\u5728MFC\u9633\u6781\u7ed3\u6784\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728ModelNet40\u6570\u636e\u96c6\u4e0a\u8fbe\u523092.7%\u51c6\u786e\u7387\u3002", "motivation": "\u5fae\u751f\u7269\u71c3\u6599\u7535\u6c60\u9633\u6781\u7ed3\u6784\u7684\u51e0\u4f55\u590d\u6742\u6027\u4f7f\u5f97\u73b0\u6709\u9884\u6d4b\u6a21\u578b\u96be\u4ee5\u6355\u6349\u5173\u952e\u51e0\u4f55\u4f9d\u8d56\u5173\u7cfb\uff0c\u9700\u8981\u65b0\u76843D\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u4f18\u5316\u8fd9\u4e9b\u7ed3\u6784\u3002", "method": "KANGURA\u91c7\u7528Kolmogorov-Arnold\u7f51\u7edc\u8fdb\u884c\u51fd\u6570\u5206\u89e3\uff0c\u901a\u8fc7\u51e0\u4f55\u89e3\u8026\u8868\u793a\u5b66\u4e60\u5206\u79bb\u7ed3\u6784\u53d8\u5316\uff0c\u5e76\u4f7f\u7528\u7edf\u4e00\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u5173\u952e\u51e0\u4f55\u533a\u57df\u3002", "result": "\u5728ModelNet40\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a15\u4e2aSOTA\u6a21\u578b\uff0c\u8fbe\u523092.7%\u51c6\u786e\u7387\uff1b\u5728\u771f\u5b9eMFC\u9633\u6781\u7ed3\u6784\u95ee\u9898\u4e0a\u8fbe\u523097%\u51c6\u786e\u7387\u3002", "conclusion": "KANGURA\u4e3a3D\u51e0\u4f55\u5efa\u6a21\u63d0\u4f9b\u4e86\u5f3a\u5927\u6846\u67b6\uff0c\u4e3a\u5148\u8fdb\u5236\u9020\u548c\u8d28\u91cf\u9a71\u52a8\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u590d\u6742\u7ed3\u6784\u4f18\u5316\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.14462", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14462", "abs": "https://arxiv.org/abs/2511.14462", "authors": ["Michael Gundall", "Hans D. Schotten"], "title": "Cracking the Microsecond: An Efficient and Precise Time Synchronization Scheme for Hybrid 5G-TSN Networks", "comment": null, "summary": "Achieving precise time synchronization in wireless systems is essential for both industrial applications and 5G, where sub-microsecond accuracy is required. However, since the Industrial Internet of Things (IIoT) market is negligible compared to the consumer electronics market, the so-called IIoT enhancements have not yet been implemented in silicon. Moreover, there is no guarantee that this situation will change soon. Thus, alternative solutions must be explored. This paper addresses this challenge by introducing a scheme that uses a protocol capable of leveraging existing infrastructure to synchronize User Equipments (UEs), with one of the UEs serving as the master. If this master is connected via a wired link to the factory network, it can also function as a boundary clock for the factory network, including any Time-Sensitive Networking (TSN) network. Furthermore, the 5G Core Network (5GC) and 5G Base Station (gNB) can also be synchronized if they are connected either to the factory network or to the master UE. The proposed solution is implemented and evaluated on a hardware testbed using OpenAirInterface (OAI) and Software Defined Radios (SDRs). Time offset and clock skew are analyzed using a moving average filter with various window sizes. Results show that a filter size of 1024 provides the best accuracy for offset prediction between UEs. In a controlled lab environment, the approach consistently achieves synchronization within +/-50 ns, leaving sufficient margin for synchronization errors in real deployments while still maintaining sub-microsecond accuracy. These findings demonstrate the feasibility and high performance of the proposed protocol for stringent industrial use cases.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\u65e0\u7ebf\u8bbe\u5907\u65f6\u95f4\u540c\u6b65\u7684\u65b9\u6848\uff0c\u5176\u4e2d\u4e00\u4e2a\u7528\u6237\u8bbe\u5907\u4f5c\u4e3a\u4e3b\u65f6\u949f\uff0c\u53ef\u4e3a\u5de5\u5382\u7f51\u7edc\u63d0\u4f9b\u8fb9\u754c\u65f6\u949f\u529f\u80fd\uff0c\u5728\u5b9e\u9a8c\u5ba4\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u00b150\u7eb3\u79d2\u7684\u540c\u6b65\u7cbe\u5ea6\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u5e02\u573a\u76f8\u5bf9\u4e8e\u6d88\u8d39\u7535\u5b50\u5e02\u573a\u8f83\u5c0f\uff0c\u5bfc\u81f4IIoT\u589e\u5f3a\u529f\u80fd\u5c1a\u672a\u5728\u82af\u7247\u4e2d\u5b9e\u73b0\uff0c\u9700\u8981\u63a2\u7d22\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u65e0\u7ebf\u7cfb\u7edf\u7684\u7cbe\u786e\u65f6\u95f4\u540c\u6b65\u3002", "method": "\u4f7f\u7528\u534f\u8bae\u5229\u7528\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u540c\u6b65\u7528\u6237\u8bbe\u5907\uff0c\u5176\u4e2d\u4e00\u4e2aUE\u4f5c\u4e3a\u4e3b\u65f6\u949f\uff1b\u5982\u679c\u4e3bUE\u901a\u8fc7\u6709\u7ebf\u8fde\u63a5\u5230\u5de5\u5382\u7f51\u7edc\uff0c\u53ef\u5145\u5f53\u8fb9\u754c\u65f6\u949f\uff1b\u4f7f\u7528OpenAirInterface\u548c\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\u5728\u786c\u4ef6\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u5b9e\u73b0\u548c\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528\u7a97\u53e3\u5927\u5c0f\u4e3a1024\u7684\u79fb\u52a8\u5e73\u5747\u6ee4\u6ce2\u5668\u53ef\u83b7\u5f97\u6700\u4f73\u504f\u79fb\u9884\u6d4b\u7cbe\u5ea6\uff1b\u5728\u53d7\u63a7\u5b9e\u9a8c\u5ba4\u73af\u5883\u4e2d\uff0c\u540c\u6b65\u7cbe\u5ea6\u59cb\u7ec8\u4fdd\u6301\u5728\u00b150\u7eb3\u79d2\u8303\u56f4\u5185\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u534f\u8bae\u5728\u4e25\u683c\u7684\u5de5\u4e1a\u7528\u4f8b\u4e2d\u5177\u6709\u53ef\u884c\u6027\u548c\u9ad8\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u8db3\u591f\u7684\u540c\u6b65\u8bef\u5dee\u4f59\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e9a\u5fae\u79d2\u7ea7\u7cbe\u5ea6\u3002"}}
{"id": "2511.14595", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14595", "abs": "https://arxiv.org/abs/2511.14595", "authors": ["Yuan An", "Ruhma Hashmi", "Michelle Rogers", "Jane Greenberg", "Brian K. Smith"], "title": "Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport", "comment": "Accepted in the 5th Workshop on Knowledge Graphs and Big Data in Conjunction with IEEE Big Data 2025", "summary": "Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7387\u5931\u771f\u7406\u8bba\u548c\u6700\u4f18\u4f20\u8f93\u51e0\u4f55\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7FGW\u8026\u5408\u91cf\u5316\u8bed\u4e49\u5931\u771f\uff0c\u4f7f\u7528\u7cbe\u70bc\u64cd\u4f5c\u6700\u5c0f\u5316\u7387\u5931\u771f\u62c9\u683c\u6717\u65e5\u51fd\u6570\uff0c\u751f\u6210\u7d27\u51d1\u4e14\u4fdd\u7559\u4fe1\u606f\u7684\u77e5\u8bc6\u56fe\u8c31\u3002", "motivation": "\u5c06\u975e\u7ed3\u6784\u5316\u6559\u80b2\u6750\u6599\uff08\u5982\u8bb2\u4e49\u548c\u5e7b\u706f\u7247\uff09\u8f6c\u6362\u4e3a\u6355\u6349\u5173\u952e\u6559\u5b66\u5185\u5bb9\u7684\u77e5\u8bc6\u56fe\u8c31\u4ecd\u7136\u5f88\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u548c\u4f18\u5316\u4efb\u52a1\u5bfc\u5411\u7684\u77e5\u8bc6\u56fe\u8c31\u3002", "method": "\u5c06\u8bb2\u4e49\u5185\u5bb9\u5efa\u6a21\u4e3a\u5ea6\u91cf-\u6d4b\u5ea6\u7a7a\u95f4\uff0c\u4f7f\u7528Fused Gromov-Wasserstein\u8026\u5408\u5bf9\u9f50\u5019\u9009\u77e5\u8bc6\u56fe\u8c31\u4ee5\u91cf\u5316\u8bed\u4e49\u5931\u771f\uff0c\u901a\u8fc7\u6dfb\u52a0\u3001\u5408\u5e76\u3001\u62c6\u5206\u3001\u79fb\u9664\u548c\u91cd\u8fde\u7b49\u7cbe\u70bc\u64cd\u4f5c\u6700\u5c0f\u5316\u7387\u5931\u771f\u62c9\u683c\u6717\u65e5\u51fd\u6570\u3002", "result": "\u5728\u6570\u636e\u79d1\u5b66\u8bb2\u4e49\u4e0a\u7684\u539f\u578b\u5e94\u7528\u663e\u793a\uff0c\u4ece\u4f18\u5316\u540e\u7684\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u7684\u591a\u9009\u9898\u572815\u4e2a\u8d28\u91cf\u6807\u51c6\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u4ece\u539f\u59cb\u7b14\u8bb0\u751f\u6210\u7684\u591a\u9009\u9898\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4e2a\u6027\u5316\u6559\u80b2\u548cAI\u8f85\u52a9\u6559\u80b2\u4e2d\u7684\u4fe1\u606f\u8bba\u77e5\u8bc6\u56fe\u8c31\u4f18\u5316\u5efa\u7acb\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2511.13825", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13825", "abs": "https://arxiv.org/abs/2511.13825", "authors": ["Humza Nusrat", "Omar Nusrat"], "title": "When AI Does Science: Evaluating the Autonomous AI Scientist KOSMOS in Radiation Biology", "comment": "13 pages, 3 figures, preprint", "summary": "Agentic AI \"scientists\" now use language models to search the literature, run analyses, and generate hypotheses. We evaluate KOSMOS, an autonomous AI scientist, on three problems in radiation biology using simple random-gene null benchmarks. Hypothesis 1: baseline DNA damage response (DDR) capacity across cell lines predicts the p53 transcriptional response after irradiation (GSE30240). Hypothesis 2: baseline expression of OGT and CDO1 predicts the strength of repressed and induced radiation-response modules in breast cancer cells (GSE59732). Hypothesis 3: a 12-gene expression signature predicts biochemical recurrence-free survival after prostate radiotherapy plus androgen deprivation therapy (GSE116918). The DDR-p53 hypothesis was not supported: DDR score and p53 response were weakly negatively correlated (Spearman rho = -0.40, p = 0.76), indistinguishable from random five-gene scores. OGT showed only a weak association (r = 0.23, p = 0.34), whereas CDO1 was a clear outlier (r = 0.70, empirical p = 0.0039). The 12-gene signature achieved a concordance index of 0.61 (p = 0.017) but a non-unique effect size. Overall, KOSMOS produced one well-supported discovery, one plausible but uncertain result, and one false hypothesis, illustrating that AI scientists can generate useful ideas but require rigorous auditing against appropriate null models.", "AI": {"tldr": "\u8bc4\u4f30KOSMOS\u81ea\u4e3bAI\u79d1\u5b66\u5bb6\u5728\u8f90\u5c04\u751f\u7269\u5b66\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u4ea7\u751f\u4e86\u4e00\u4e2a\u660e\u786e\u53d1\u73b0\u3001\u4e00\u4e2a\u4e0d\u786e\u5b9a\u7ed3\u679c\u548c\u4e00\u4e2a\u9519\u8bef\u5047\u8bbe\uff0c\u8868\u660eAI\u79d1\u5b66\u5bb6\u80fd\u751f\u6210\u6709\u7528\u60f3\u6cd5\u4f46\u9700\u8981\u4e25\u683c\u9a8c\u8bc1\u3002", "motivation": "\u8bc4\u4f30\u81ea\u4e3bAI\u79d1\u5b66\u5bb6KOSMOS\u5728\u8f90\u5c04\u751f\u7269\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u68c0\u9a8c\u5176\u751f\u6210\u5047\u8bbe\u548c\u53d1\u73b0\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u968f\u673a\u57fa\u56e0\u96f6\u57fa\u51c6\u6d4b\u8bd5KOSMOS\u5728\u4e09\u4e2a\u8f90\u5c04\u751f\u7269\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff1aDNA\u635f\u4f24\u54cd\u5e94\u4e0ep53\u8f6c\u5f55\u54cd\u5e94\u5173\u7cfb\u3001OGT\u548cCDO1\u57fa\u56e0\u8868\u8fbe\u4e0e\u8f90\u5c04\u54cd\u5e94\u6a21\u5757\u5173\u7cfb\u300112\u57fa\u56e0\u7279\u5f81\u9884\u6d4b\u524d\u5217\u817a\u764c\u653e\u7597\u540e\u751f\u5b58\u3002", "result": "\u5047\u8bbe1\u4e0d\u652f\u6301\uff08DDR\u8bc4\u5206\u4e0ep53\u54cd\u5e94\u5f31\u8d1f\u76f8\u5173\uff09\uff1bOGT\u5f31\u76f8\u5173\uff0cCDO1\u662f\u660e\u663e\u5f02\u5e38\u503c\uff1b12\u57fa\u56e0\u7279\u5f81\u4e00\u81f4\u6027\u6307\u65700.61\u4f46\u6548\u5e94\u5927\u5c0f\u4e0d\u552f\u4e00\u3002", "conclusion": "AI\u79d1\u5b66\u5bb6\u80fd\u751f\u6210\u6709\u7528\u60f3\u6cd5\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u9002\u5f53\u96f6\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u5ba1\u8ba1\uff0c\u4ee5\u907f\u514d\u865a\u5047\u53d1\u73b0\u3002"}}
{"id": "2511.14467", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.14467", "abs": "https://arxiv.org/abs/2511.14467", "authors": ["Heng Zhao", "Ruoyu Wang", "Tianhang Zheng", "Qi Li", "Bo Lv", "Yuyi Wang", "Wenliang Du"], "title": "From Topology to Behavioral Semantics: Enhancing BGP Security by Understanding BGP's Language with LLMs", "comment": "18 pages, 10 figures", "summary": "The trust-based nature of Border Gateway Protocol (BGP) makes it vulnerable to disruptions like prefix hijacking and misconfigurations, threatening routing stability. Traditional detection relies on manual inspection with limited scalability. Machine/Deep Learning (M/DL) approaches automate detection but suffer from suboptimal precision, limited generalizability, and high retraining costs. This is because existing methods focus on topological structures rather than comprehensive semantic characteristics of Autonomous Systems (ASes), often misinterpreting functionally similar but topologically distant ASes.\n  To address this, we propose BGPShield, an anomaly detection framework built on LLM embeddings that captures the Behavior Portrait and Routing Policy Rationale of each AS beyond topology, such as operational scale and global role. We propose a segment-wise aggregation scheme to transform AS descriptions into LLM representations without information loss, and a lightweight contrastive reduction network to compress them into a semantic-consistent version. Using these representations, our AR-DTW algorithm aligns and accumulates semantic distances to reveal behavioral inconsistencies. Evaluated on 16 real-world datasets, BGPShield detects 100% of verified anomalies with a false discovery rate below 5%. Notably, the employed LLMs were released prior to evaluation events, verifying generalizability. Furthermore, BGPShield constructs representations for unseen ASes within one second, significantly outperforming BEAM which demands costly retraining (averaging 65 hours).", "AI": {"tldr": "BGPShield\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u5d4c\u5165\u7684BGP\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6355\u6349AS\u7684\u884c\u4e3a\u753b\u50cf\u548c\u8def\u7531\u7b56\u7565\u539f\u7406\u6765\u68c0\u6d4b\u524d\u7f00\u52ab\u6301\u548c\u914d\u7f6e\u9519\u8bef\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u548c\u6548\u7387\u3002", "motivation": "BGP\u7684\u4fe1\u4efb\u673a\u5236\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u524d\u7f00\u52ab\u6301\u548c\u914d\u7f6e\u9519\u8bef\u7684\u5a01\u80c1\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\u4e14\u6269\u5c55\u6027\u6709\u9650\uff0c\u800c\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u4e0d\u8db3\u3001\u6cdb\u5316\u6027\u5dee\u548c\u91cd\u8bad\u7ec3\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faBGPShield\u6846\u67b6\uff0c\u4f7f\u7528LLM\u5d4c\u5165\u6355\u6349AS\u7684\u884c\u4e3a\u753b\u50cf\u548c\u8def\u7531\u7b56\u7565\u539f\u7406\uff1b\u91c7\u7528\u5206\u6bb5\u805a\u5408\u65b9\u6848\u5c06AS\u63cf\u8ff0\u8f6c\u6362\u4e3aLLM\u8868\u793a\uff1b\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5bf9\u6bd4\u538b\u7f29\u7f51\u7edc\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u7248\u672c\uff1b\u901a\u8fc7AR-DTW\u7b97\u6cd5\u5bf9\u9f50\u548c\u7d2f\u79ef\u8bed\u4e49\u8ddd\u79bb\u6765\u68c0\u6d4b\u884c\u4e3a\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u572816\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cBGPShield\u68c0\u6d4b\u5230100%\u7684\u5df2\u9a8c\u8bc1\u5f02\u5e38\uff0c\u8bef\u62a5\u7387\u4f4e\u4e8e5%\uff1b\u5bf9\u672a\u89c1\u8fc7\u7684AS\u80fd\u57281\u79d2\u5185\u6784\u5efa\u8868\u793a\uff0c\u663e\u8457\u4f18\u4e8eBEAM\u65b9\u6cd5\uff08\u5e73\u5747\u9700\u898165\u5c0f\u65f6\u91cd\u8bad\u7ec3\uff09\u3002", "conclusion": "BGPShield\u901a\u8fc7\u8d85\u8d8a\u62d3\u6251\u7684\u8bed\u4e49\u7279\u5f81\u5206\u6790\uff0c\u6709\u6548\u89e3\u51b3\u4e86BGP\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u7cbe\u5ea6\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86LLM\u5728\u8def\u7531\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.13852", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13852", "abs": "https://arxiv.org/abs/2511.13852", "authors": ["Anna Rodum Bj\u00f8ru", "Rafael Caba\u00f1as", "Helge Langseth", "Antonio Salmer\u00f3n"], "title": "Causal computations in Semi Markovian Structural Causal Models using divide and conquer", "comment": "36 pages, 7 figures, 1 appendix", "summary": "Recently, Bj\u00f8ru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \\textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Bj\u00f8ru\u7b49\u4eba\u7684\u5206\u6cbb\u7b97\u6cd5\uff0c\u4ece\u9a6c\u5c14\u53ef\u592b\u56e0\u679c\u6a21\u578b\u63a8\u5e7f\u5230\u534a\u9a6c\u5c14\u53ef\u592b\u56e0\u679c\u6a21\u578b\uff0c\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u6df7\u6dc6\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u9a6c\u5c14\u53ef\u592b\u56e0\u679c\u6a21\u578b\uff0c\u5176\u4e2d\u5916\u751f\u53d8\u91cf\u4ec5\u5f71\u54cd\u5355\u4e2a\u5185\u751f\u53d8\u91cf\u3002\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5916\u751f\u53d8\u91cf\u53ef\u80fd\u5f71\u54cd\u591a\u4e2a\u5185\u751f\u53d8\u91cf\uff0c\u5f62\u6210\u6df7\u6dc6\u5173\u7cfb\uff0c\u9700\u8981\u6269\u5c55\u5230\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u5206\u6cbb\u7b56\u7565\u5c06\u9ad8\u57fa\u6570\u5916\u751f\u53d8\u91cf\u7684\u56e0\u679c\u6a21\u578b\u5206\u89e3\u4e3a\u591a\u4e2a\u4f4e\u57fa\u6570\u5b50\u6a21\u578b\uff0c\u8fd9\u4e9b\u5b50\u6a21\u578b\u5177\u6709\u7cbe\u786e\u7684\u5916\u751f\u53d8\u91cf\u8fb9\u9645\u5206\u5e03\uff0c\u5141\u8bb8\u9ad8\u6548\u7cbe\u786e\u63a8\u7406\u3002\u901a\u8fc7\u805a\u5408\u7ed3\u679c\u6765\u754c\u5b9a\u539f\u59cb\u6a21\u578b\u4e2d\u7684\u53cd\u4e8b\u5b9e\u6982\u7387\u3002", "result": "\u901a\u8fc7\u6700\u5c0f\u793a\u4f8b\u8bf4\u660e\u4e86\u6269\u5c55\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u7b56\u7565\u3002\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u8ba1\u7b97\u7814\u7a76\u6765\u9a8c\u8bc1\u65b9\u6cd5\u3002", "conclusion": "\u6210\u529f\u5c06\u5206\u6cbb\u7b97\u6cd5\u6269\u5c55\u5230\u534a\u9a6c\u5c14\u53ef\u592b\u56e0\u679c\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7684\u6df7\u6dc6\u5173\u7cfb\uff0c\u4e3a\u53cd\u4e8b\u5b9e\u6982\u7387\u7684\u754c\u5b9a\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.14550", "categories": ["cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.14550", "abs": "https://arxiv.org/abs/2511.14550", "authors": ["Dimitrios Dimopoulos", "Apostolis K. Salkintzis", "Dimitris Tsolkas", "Nikos Passas", "Lazaros Merakos"], "title": "Evaluating the Impact of Packet Scheduling and Congestion Control Algorithms on MPTCP Performance over Heterogeneous Networks", "comment": null, "summary": "Modern mobile and stationary devices are equipped with multiple network interfaces aiming to provide wireless and wireline connectivity either in a local LAN or the Internet. Multipath TCP (MPTCP) protocol has been developed on top of legacy TCP to allow the simultaneous use of multiple network paths in the communication route between two end-systems. Although the combination of multiple paths is beneficial in case of links with similar network characteristics, MPTCP performance is challenged as heterogeneity among the used paths increases. This work provides an overview of the MPTCP protocol operation, analyzes the state-of-art packet scheduling and congestion control algorithms available in literature, and examines the impact of the various algorithm combinations on MPTCP performance, by conducting an extensive experimental evaluation under diverse path-heterogeneity conditions.", "AI": {"tldr": "MPTCP\u534f\u8bae\u5728\u5f02\u6784\u7f51\u7edc\u8def\u5f84\u4e0b\u7684\u6027\u80fd\u5206\u6790\uff0c\u5305\u62ec\u5305\u8c03\u5ea6\u548c\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\u7684\u7ec4\u5408\u5f71\u54cd", "motivation": "\u73b0\u4ee3\u8bbe\u5907\u914d\u5907\u591a\u7f51\u7edc\u63a5\u53e3\uff0cMPTCP\u65e8\u5728\u540c\u65f6\u5229\u7528\u591a\u6761\u7f51\u7edc\u8def\u5f84\uff0c\u4f46\u5728\u8def\u5f84\u5f02\u6784\u6027\u589e\u52a0\u65f6\u6027\u80fd\u9762\u4e34\u6311\u6218", "method": "\u5206\u6790MPTCP\u534f\u8bae\u64cd\u4f5c\uff0c\u7814\u7a76\u73b0\u6709\u5305\u8c03\u5ea6\u548c\u62e5\u585e\u63a7\u5236\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u4e0d\u540c\u8def\u5f84\u5f02\u6784\u6761\u4ef6\u4e0b\u7684\u6027\u80fd", "result": "\u4e0d\u540c\u7b97\u6cd5\u7ec4\u5408\u5728\u8def\u5f84\u5f02\u6784\u6761\u4ef6\u4e0b\u5bf9MPTCP\u6027\u80fd\u4ea7\u751f\u663e\u8457\u5f71\u54cd", "conclusion": "MPTCP\u6027\u80fd\u53d7\u8def\u5f84\u5f02\u6784\u6027\u5f71\u54cd\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u7f51\u7edc\u6761\u4ef6\u4f18\u5316\u7b97\u6cd5\u7ec4\u5408"}}
{"id": "2511.13892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13892", "abs": "https://arxiv.org/abs/2511.13892", "authors": ["Badhan Chandra Das", "Md Tasnim Jawad", "Md Jueal Mia", "M. Hadi Amini", "Yanzhao Wu"], "title": "Jailbreaking Large Vision Language Models in Intelligent Transportation Systems", "comment": null, "summary": "Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8d8a\u72f1\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u50cf\u6392\u7248\u64cd\u7eb5\u548c\u591a\u8f6e\u63d0\u793a\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u5c42\u54cd\u5e94\u8fc7\u6ee4\u9632\u5fa1\u6280\u672f\u3002", "motivation": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u6781\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\u3002\u7279\u522b\u662f\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7b49\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u8fd9\u79cd\u5b89\u5168\u6f0f\u6d1e\u53ef\u80fd\u5e26\u6765\u4e25\u91cd\u540e\u679c\u3002", "method": "1) \u6784\u5efa\u4e0e\u4ea4\u901a\u76f8\u5173\u7684\u6709\u5bb3\u67e5\u8be2\u6570\u636e\u96c6\uff1b2) \u63d0\u51fa\u5229\u7528\u56fe\u50cf\u6392\u7248\u64cd\u7eb5\u548c\u591a\u8f6e\u63d0\u793a\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff1b3) \u8bbe\u8ba1\u591a\u5c42\u54cd\u5e94\u8fc7\u6ee4\u9632\u5fa1\u6280\u672f\u6765\u963b\u6b62\u6a21\u578b\u751f\u6210\u4e0d\u5f53\u54cd\u5e94\u3002", "result": "\u5728\u6700\u5148\u8fdb\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u4f7f\u7528GPT-4\u5224\u65ad\u548c\u4eba\u5de5\u9a8c\u8bc1\u8bc4\u4f30\u653b\u51fb\u65b9\u6cd5\u548c\u9632\u5fa1\u6280\u672f\u7684\u6548\u679c\u3002\u4e0e\u73b0\u6709\u8d8a\u72f1\u6280\u672f\u76f8\u6bd4\uff0c\u56fe\u50cf\u6392\u7248\u64cd\u7eb5\u548c\u591a\u8f6e\u63d0\u793a\u653b\u51fb\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5e26\u6765\u4e86\u66f4\u4e25\u91cd\u7684\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u6765\u9632\u6b62\u8d8a\u72f1\u653b\u51fb\u3002\u63d0\u51fa\u7684\u591a\u5c42\u54cd\u5e94\u8fc7\u6ee4\u9632\u5fa1\u6280\u672f\u80fd\u591f\u6709\u6548\u51cf\u8f7b\u8fd9\u4e9b\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2511.13942", "categories": ["cs.AI", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13942", "abs": "https://arxiv.org/abs/2511.13942", "authors": ["Daniel Weitekamp"], "title": "CORGI: Efficient Pattern Matching With Quadratic Guarantees", "comment": null, "summary": "Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $\u03b2$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.", "AI": {"tldr": "CORGI\u662f\u4e00\u79cd\u65b0\u7684\u6a21\u5f0f\u5339\u914d\u7b97\u6cd5\uff0c\u4e3a\u5b9e\u65f6AI\u7cfb\u7edf\u548c\u6570\u636e\u5e93\u67e5\u8be2\u63d0\u4f9b\u4e8c\u6b21\u65f6\u95f4\u548c\u7a7a\u95f4\u4fdd\u8bc1\uff0c\u907f\u514d\u4f20\u7edfRETE\u7b97\u6cd5\u5728\u590d\u6742\u5339\u914d\u65f6\u7684\u6307\u6570\u7ea7\u5185\u5b58\u6d88\u8017\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u9762\u4e34\u6307\u6570\u7ea7\u65f6\u95f4\u548c\u7a7a\u95f4\u6d88\u8017\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5177\u6709\u591a\u4e2a\u672a\u7ea6\u675f\u53d8\u91cf\u7684\u89c4\u5219\u65f6\u3002\u81ea\u52a8\u751f\u6210\u7684\u89c4\u5219\u5bb9\u6613\u4ea7\u751f\u6700\u574f\u60c5\u51b5\u5339\u914d\u6a21\u5f0f\uff0c\u5bfc\u81f4\u7cfb\u7edf\u53d8\u6162\u6216\u5185\u5b58\u6ea2\u51fa\u3002", "method": "CORGI\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u6b63\u5411\u6784\u5efa/\u7ef4\u62a4\u5173\u7cfb\u56fe\uff0c\u53cd\u5411\u901a\u8fc7\u8fed\u4ee3\u5668\u6309\u9700\u751f\u6210\u5339\u914d\u3002\u4e0e\u4f20\u7edfRETE\u4e0d\u540c\uff0c\u5b83\u6ca1\u6709\u03b2-\u5185\u5b58\u6765\u6536\u96c6\u90e8\u5206\u5339\u914d\uff0c\u800c\u662f\u6d41\u5f0f\u751f\u6210\u540e\u7eed\u5339\u914d\u3002", "result": "\u6027\u80fd\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u7b80\u5355\u7ec4\u5408\u5339\u914d\u4efb\u52a1\u4e0a\uff0cCORGI\u663e\u8457\u4f18\u4e8eSOAR\u548cOPS5\u4e2d\u7684RETE\u5b9e\u73b0\uff0c\u6d88\u9664\u4e86\u9ad8\u5ef6\u8fdf\u5ef6\u8fdf\u548c\u5185\u5b58\u6ea2\u51fa\u95ee\u9898\u3002", "conclusion": "CORGI\u7b97\u6cd5\u901a\u8fc7\u63d0\u4f9b\u53ef\u9884\u6d4b\u7684\u6027\u80fd\u4fdd\u8bc1\uff0c\u4f7f\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u52a0\u53ef\u9760\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4ece\u793a\u4f8b\u5b66\u4e60\u81ea\u52a8\u751f\u6210\u89c4\u5219\u7684\u8ba4\u77e5\u7cfb\u7edf\u3002"}}
{"id": "2511.13970", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13970", "abs": "https://arxiv.org/abs/2511.13970", "authors": ["Sanjay Acharjee", "Abir Khan Ratul", "Diego Patino", "Md Nazmus Sakib"], "title": "Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios", "comment": null, "summary": "Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u573a\u666f\u56fe\u5f15\u5bfc\u7684\u751f\u6210AI\u6846\u67b6\uff0c\u5229\u7528OSHA\u4e8b\u6545\u62a5\u544a\u751f\u6210\u903c\u771f\u7684\u5de5\u4f5c\u573a\u6240\u5371\u9669\u573a\u666f\u56fe\u50cf\uff0c\u5e76\u901a\u8fc7VQA\u6846\u67b6\u8bc4\u4f30\u751f\u6210\u6570\u636e\u7684\u771f\u5b9e\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "motivation": "\u83b7\u53d6\u771f\u5b9e\u7684\u5de5\u4f5c\u573a\u6240\u5371\u9669\u573a\u666f\u56fe\u50cf\u6570\u636e\u96c6\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u6355\u6349\u5b9e\u9645\u53d1\u751f\u7684\u4e8b\u6545\u89e6\u53d1\u573a\u666f\u51e0\u4e4e\u4e0d\u53ef\u80fd\u3002", "method": "\u4f7f\u7528GPT-4o\u5206\u6790OSHA\u53d9\u8ff0\u63d0\u53d6\u7ed3\u6784\u5316\u5371\u9669\u63a8\u7406\uff0c\u8f6c\u6362\u4e3a\u5bf9\u8c61\u7ea7\u573a\u666f\u56fe\uff0c\u7136\u540e\u6307\u5bfc\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u751f\u6210\u6784\u56fe\u51c6\u786e\u7684\u5371\u9669\u573a\u666f\uff0c\u5e76\u901a\u8fc7VQA\u6846\u67b6\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\u3002", "result": "\u63d0\u51fa\u7684VQA\u56fe\u8bc4\u5206\u5728\u56db\u4e2a\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u57fa\u4e8e\u71b5\u9a8c\u8bc1\u4f18\u4e8eCLIP\u548cBLIP\u6307\u6807\uff0c\u8bc1\u5b9e\u4e86\u5176\u66f4\u9ad8\u7684\u5224\u522b\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u903c\u771f\u7684\u5de5\u4f5c\u573a\u6240\u5371\u9669\u573a\u666f\u56fe\u50cf\uff0c\u4e3a\u5b89\u5168\u57f9\u8bad\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c6\u89c9\u6570\u636e\u8d44\u6e90\u3002"}}
{"id": "2511.13987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13987", "abs": "https://arxiv.org/abs/2511.13987", "authors": ["Antonio Manuel Mart\u00ednez-Heredia", "Dolores Godrid Rodr\u00edguez", "Andr\u00e9s Ortiz Garc\u00eda"], "title": "Artificial Intelligence Agents in Music Analysis: An Integrative Perspective Based on Two Use Cases", "comment": "Extended version of the conference paper presented at SATMUS 2025", "summary": "This paper presents an integrative review and experimental validation of artificial intelligence (AI) agents applied to music analysis and education. We synthesize the historical evolution from rule-based models to contemporary approaches involving deep learning, multi-agent architectures, and retrieval-augmented generation (RAG) frameworks. The pedagogical implications are evaluated through a dual-case methodology: (1) the use of generative AI platforms in secondary education to foster analytical and creative skills; (2) the design of a multiagent system for symbolic music analysis, enabling modular, scalable, and explainable workflows.\n  Experimental results demonstrate that AI agents effectively enhance musical pattern recognition, compositional parameterization, and educational feedback, outperforming traditional automated methods in terms of interpretability and adaptability. The findings highlight key challenges concerning transparency, cultural bias, and the definition of hybrid evaluation metrics, emphasizing the need for responsible deployment of AI in educational environments.\n  This research contributes to a unified framework that bridges technical, pedagogical, and ethical considerations, offering evidence-based guidance for the design and application of intelligent agents in computational musicology and music education.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86AI\u4ee3\u7406\u5728\u97f3\u4e50\u5206\u6790\u548c\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u4ece\u57fa\u4e8e\u89c4\u5219\u7684\u6a21\u578b\u53d1\u5c55\u5230\u6df1\u5ea6\u5b66\u4e60\u3001\u591a\u4ee3\u7406\u67b6\u6784\u548cRAG\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u53cc\u6848\u4f8b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22AI\u4ee3\u7406\u5728\u97f3\u4e50\u5206\u6790\u548c\u6559\u80b2\u4e2d\u7684\u6f5c\u529b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5173\u6ce8\u6559\u80b2\u73af\u5883\u4e2d\u7684\u4f26\u7406\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53cc\u6848\u4f8b\u65b9\u6cd5\uff1a(1)\u5728\u4e2d\u5b66\u6559\u80b2\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\u5e73\u53f0\u57f9\u517b\u5206\u6790\u521b\u9020\u80fd\u529b\uff1b(2)\u8bbe\u8ba1\u7528\u4e8e\u7b26\u53f7\u97f3\u4e50\u5206\u6790\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aAI\u4ee3\u7406\u5728\u97f3\u4e50\u6a21\u5f0f\u8bc6\u522b\u3001\u4f5c\u66f2\u53c2\u6570\u5316\u548c\u6559\u80b2\u53cd\u9988\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u8fde\u63a5\u6280\u672f\u3001\u6559\u5b66\u548c\u4f26\u7406\u8003\u91cf\uff0c\u4e3a\u8ba1\u7b97\u97f3\u4e50\u5b66\u548c\u97f3\u4e50\u6559\u80b2\u4e2d\u667a\u80fd\u4ee3\u7406\u7684\u8bbe\u8ba1\u5e94\u7528\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u6307\u5bfc\u3002"}}
{"id": "2511.14018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14018", "abs": "https://arxiv.org/abs/2511.14018", "authors": ["Minghu Wang", "Shuliang Zhao", "Yuanyuan Zhao", "Hongxia Xu"], "title": "ALEX:A Light Editing-knowledge Extractor", "comment": null, "summary": "The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.", "AI": {"tldr": "ALEX\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u77e5\u8bc6\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u5185\u5b58\u67b6\u6784\u5c06\u77e5\u8bc6\u66f4\u65b0\u7ec4\u7ec7\u6210\u8bed\u4e49\u7c07\uff0c\u5c06\u68c0\u7d22\u590d\u6742\u5ea6\u4eceO(N)\u964d\u4f4e\u5230O(K+N/C)\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u8def\u5f84\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u77e5\u8bc6\u662f\u9759\u6001\u7684\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u9700\u8981\u591a\u6b65\u63a8\u7406\u7684\u590d\u6742\u591a\u8df3\u95ee\u9898\u65f6\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u68c0\u7d22\u6548\u7387\u7684\u6311\u6218\u3002", "method": "ALEX\u91c7\u7528\u5206\u5c42\u5185\u5b58\u67b6\u6784\u7ec4\u7ec7\u77e5\u8bc6\u66f4\u65b0\uff0c\u5305\u542b\u63a8\u7406\u67e5\u8be2\u5408\u6210\u6a21\u5757\u6765\u5f25\u5408\u67e5\u8be2\u4e0e\u4e8b\u5b9e\u4e4b\u95f4\u7684\u8bed\u4e49\u5dee\u8ddd\uff0c\u4ee5\u53ca\u52a8\u6001\u8bc1\u636e\u88c1\u51b3\u5f15\u64ce\u6267\u884c\u9ad8\u6548\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728MQUAKE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cALEX\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u7b54\u6848\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u8def\u5f84\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5c06\u6240\u9700\u641c\u7d22\u7a7a\u95f4\u51cf\u5c11\u4e8680%\u4ee5\u4e0a\u3002", "conclusion": "ALEX\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u77e5\u8bc6\u7f16\u8f91\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2511.14023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14023", "abs": "https://arxiv.org/abs/2511.14023", "authors": ["Chiharu Hagiwara", "Naoki Nonaka", "Yuhta Hashimoto", "Ryu Uchimido", "Jun Seita"], "title": "Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation", "comment": "Introducing an open dataset", "summary": "Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.", "AI": {"tldr": "\u5f00\u53d1\u4e86Syn-STARTS\u6846\u67b6\uff0c\u4f7f\u7528LLM\u751f\u6210\u5927\u89c4\u6a21\u5206\u7c7b\u6848\u4f8b\uff0c\u89e3\u51b3\u4e86\u771f\u5b9e\u4e16\u754c\u5927\u89c4\u6a21\u4f24\u4ea1\u4e8b\u4ef6\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u5408\u6210\u6570\u636e\u5728\u533b\u7597AI\u5f00\u53d1\u4e2d\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u4f24\u4ea1\u4e8b\u4ef6\u4e2d\u7684\u5206\u7c7b\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u771f\u5b9e\u6570\u636e\u96be\u4ee5\u6536\u96c6\uff0c\u963b\u788d\u4e86AI\u6a21\u578b\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528LLM\u751f\u6210\u5206\u7c7b\u6848\u4f8b\u7684Syn-STARTS\u6846\u67b6\uff0c\u5e76\u4e0e\u624b\u52a8\u6574\u7406\u7684TRIAGE\u5f00\u653e\u6570\u636e\u96c6\u8fdb\u884c\u5b9a\u6027\u6bd4\u8f83\u3002", "result": "Syn-STARTS\u751f\u6210\u7684\u6848\u4f8b\u5728\u8d28\u91cf\u4e0a\u4e0e\u4eba\u5de5\u6574\u7406\u7684\u6570\u636e\u96c6\u65e0\u6cd5\u533a\u5206\uff0c\u4e14\u5728\u4e0d\u540c\u5206\u7c7b\u7c7b\u522b\uff08\u7eff\u3001\u9ec4\u3001\u7ea2\u3001\u9ed1\uff09\u7684\u8bc4\u4f30\u4e2d\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u5728\u5f00\u53d1\u9ad8\u6027\u80fd\u533b\u7597AI\u6a21\u578b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u4e25\u91cd\u548c\u5371\u6025\u533b\u7597\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2511.14043", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.14043", "abs": "https://arxiv.org/abs/2511.14043", "authors": ["Chandrachur Bhattacharya", "Sibendu Som"], "title": "AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance", "comment": null, "summary": "AI Scientific Assistant Core (AISAC) is an integrated multi-agent system developed at Argonne National Laboratory for scientific and engineering workflows. AISAC builds on established technologies - LangGraph for orchestration, FAISS for vector search, and SQLite for persistence - and integrates them into a unified system prototype focused on transparency, provenance tracking, and scientific adaptability.\n  The system implements a Router-Planner-Coordinator workflow and an optional Evaluator role, using prompt-engineered agents coordinated via LangGraph's StateGraph and supported by helper agents such as a Researcher. Each role is defined through custom system prompts that enforce structured JSON outputs. A hybrid memory approach (FAISS + SQLite) enables both semantic retrieval and structured conversation history. An incremental indexing strategy based on file hashing minimizes redundant re-embedding when scientific corpora evolve. A configuration-driven project bootstrap layer allows research teams to customize tools, prompts, and data sources without modifying core code.\n  All agent decisions, tool invocations, and retrievals are logged and visualized through a custom Gradio interface, providing step-by-step transparency for each reasoning episode. The authors have applied AISAC to multiple research areas at Argonne, including specialized deployments for waste-to-products research and energy process safety, as well as general-purpose scientific assistance, demonstrating its cross-domain applicability.", "AI": {"tldr": "AISAC\u662f\u963f\u8d21\u56fd\u5bb6\u5b9e\u9a8c\u5ba4\u5f00\u53d1\u7684\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u52a9\u624b\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86LangGraph\u3001FAISS\u548cSQLite\u6280\u672f\uff0c\u4e13\u6ce8\u4e8e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u900f\u660e\u6027\u3001\u6eaf\u6e90\u8ddf\u8e2a\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u96c6\u6210\u5316\u7684\u79d1\u5b66\u5de5\u4f5c\u6d41\u7cfb\u7edf\uff0c\u89e3\u51b3\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u900f\u660e\u6027\u3001\u6eaf\u6e90\u8ddf\u8e2a\u548c\u8de8\u9886\u57df\u9002\u5e94\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528Router-Planner-Coordinator\u5de5\u4f5c\u6d41\u548c\u53ef\u9009Evaluator\u89d2\u8272\uff0c\u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u667a\u80fd\u4f53\u534f\u8c03\uff0c\u7ed3\u5408FAISS\u5411\u91cf\u641c\u7d22\u548cSQLite\u6301\u4e45\u5316\u7684\u6df7\u5408\u5185\u5b58\u65b9\u6cd5\uff0c\u652f\u6301\u589e\u91cf\u7d22\u5f15\u548c\u914d\u7f6e\u9a71\u52a8\u7684\u9879\u76ee\u5f15\u5bfc\u3002", "result": "\u7cfb\u7edf\u5df2\u5e94\u7528\u4e8e\u963f\u8d21\u5b9e\u9a8c\u5ba4\u7684\u591a\u4e2a\u7814\u7a76\u9886\u57df\uff0c\u5305\u62ec\u5e9f\u7269\u8f6c\u5316\u4ea7\u54c1\u548c\u80fd\u6e90\u8fc7\u7a0b\u5b89\u5168\u7b49\u4e13\u4e1a\u90e8\u7f72\uff0c\u4ee5\u53ca\u901a\u7528\u79d1\u5b66\u8f85\u52a9\uff0c\u5c55\u793a\u4e86\u8de8\u9886\u57df\u9002\u7528\u6027\u3002", "conclusion": "AISAC\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u53ef\u8ffd\u8e2a\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u79d1\u5b66\u5de5\u4f5c\u6d41\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u914d\u7f6e\u9a71\u52a8\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2511.14052", "categories": ["cs.AI", "cs.CE", "stat.AP", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.14052", "abs": "https://arxiv.org/abs/2511.14052", "authors": ["Amirreza Mehrabi", "Jason W. Morphew", "Breejha Quezada", "N. Sanjay Rebello"], "title": "Making Evidence Actionable in Adaptive Learning", "comment": null, "summary": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7531\u6559\u5e08\u4e3b\u5bfc\u7684\u53cd\u9988\u5faa\u73af\u7cfb\u7edf\uff0c\u5c06\u6982\u5ff5\u7ea7\u8bc4\u4f30\u8bc1\u636e\u8f6c\u5316\u4e3a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5fae\u5e72\u9884\u63aa\u65bd\uff0c\u901a\u8fc7\u4e8c\u5143\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u5b9e\u73b0\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u7684\u4f18\u5316\u5206\u914d\u3002", "motivation": "\u4f20\u7edf\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u8bca\u65ad\u51c6\u786e\u4f46\u5e72\u9884\u8584\u5f31\uff0c\u5bfc\u81f4\u5e2e\u52a9\u65f6\u673a\u4e0d\u5f53\u6216\u5185\u5bb9\u4e0d\u5339\u914d\u3002\u9700\u8981\u5efa\u7acb\u8bca\u65ad\u4e0e\u6559\u5b66\u4e4b\u95f4\u7684\u95ed\u73af\uff0c\u5b9e\u73b0\u516c\u5e73\u4e14\u8d1f\u8f7d\u611f\u77e5\u7684\u4e2a\u6027\u5316\u6559\u5b66\u3002", "method": "\u91c7\u7528\u4e8c\u5143\u6574\u6570\u89c4\u5212\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u4fdd\u969c\u673a\u5236\uff1a\u5145\u5206\u6027\u4fdd\u8bc1\u77e5\u8bc6\u5dee\u8ddd\u95ed\u5408\u3001\u6ce8\u610f\u529b\u4f5c\u4e3a\u65f6\u95f4\u548c\u5197\u4f59\u7684\u9884\u7b97\u7ea6\u675f\u3001\u591a\u6837\u6027\u9632\u6b62\u5bf9\u5355\u4e00\u8d44\u6e90\u7684\u8fc7\u62df\u5408\u3002\u4f7f\u7528\u8d2a\u5a6a\u9009\u62e9\u3001\u68af\u5ea6\u677e\u5f1b\u548c\u6df7\u5408\u65b9\u6cd5\u4e09\u79cd\u6c42\u89e3\u5668\u3002", "result": "\u57281204\u540d\u5b66\u751f\u7684\u7269\u7406\u8bfe\u7a0b\u90e8\u7f72\u4e2d\uff0c\u4e24\u79cd\u6c42\u89e3\u5668\u90fd\u80fd\u5728\u6709\u9650\u89c2\u770b\u65f6\u95f4\u5185\u4e3a\u51e0\u4e4e\u6240\u6709\u5b66\u4e60\u8005\u5b9e\u73b0\u5b8c\u6574\u7684\u6280\u80fd\u8986\u76d6\u3002\u68af\u5ea6\u65b9\u6cd5\u6bd4\u8d2a\u5a6a\u65b9\u6cd5\u51cf\u5c11\u7ea612%\u7684\u5197\u4f59\u8986\u76d6\uff0c\u5e76\u5728\u96be\u5ea6\u4e0a\u66f4\u5747\u8861\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u8ffd\u8e2a\u4e14\u53ef\u5ba1\u8ba1\u7684\u63a7\u5236\u5668\uff0c\u95ed\u5408\u4e86\u8bca\u65ad-\u6559\u5b66\u5faa\u73af\uff0c\u5728\u8bfe\u5802\u89c4\u6a21\u4e0a\u5b9e\u73b0\u4e86\u516c\u5e73\u4e14\u8d1f\u8f7d\u611f\u77e5\u7684\u4e2a\u6027\u5316\u6559\u5b66\u3002"}}
{"id": "2511.14101", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14101", "abs": "https://arxiv.org/abs/2511.14101", "authors": ["Xinpeng Chen", "Xiaofeng Han", "Kaihao Zhang", "Guochao Ren", "Yujie Wang", "Wenhao Cao", "Yang Zhou", "Jianfeng Lu", "Zhenbo Song"], "title": "APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design", "comment": null, "summary": "Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.", "AI": {"tldr": "APD-agents\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u79fb\u52a8\u5e94\u7528\u9875\u9762\u8bbe\u8ba1\uff0c\u901a\u8fc7\u591a\u4e2a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u7528\u6237\u63cf\u8ff0\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u5e03\u5c40\u8bbe\u8ba1\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u9875\u9762\u5e03\u5c40\u8bbe\u8ba1\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u6280\u80fd\uff0c\u73b0\u6709\u8bbe\u8ba1\u8f6f\u4ef6\u9700\u8981\u5927\u91cf\u57f9\u8bad\uff0c\u8de8\u9875\u9762\u534f\u4f5c\u8bbe\u8ba1\u8fd8\u9700\u8981\u989d\u5916\u65f6\u95f4\u7edf\u4e00\u6807\u51c6\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1aOrchestratorAgent\u534f\u8c03\u4efb\u52a1\uff0cSemanticParserAgent\u89e3\u6790\u7528\u6237\u63cf\u8ff0\uff0cPrimaryLayoutAgent\u751f\u6210\u521d\u59cb\u5e03\u5c40\uff0cTemplateRetrievalAgent\u68c0\u7d22\u76f8\u5173\u793a\u4f8b\uff0cRecursiveComponentAgent\u9012\u5f52\u751f\u6210\u7ec6\u7c92\u5ea6\u5b50\u5143\u7d20\u3002", "result": "\u5728RICO\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cAPD-agents\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5145\u5206\u5229\u7528\u4e86\u5927\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u81ea\u52a8\u534f\u4f5c\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u9875\u9762\u8bbe\u8ba1\u3002"}}
{"id": "2511.14130", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14130", "abs": "https://arxiv.org/abs/2511.14130", "authors": ["Chun Chet Ng", "Jia Yu Lim", "Wei Zeng Low"], "title": "PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval", "comment": "3rd-place solution for the ACM ICAIF 2025 Agentic Retrieval Grand Challenge", "summary": "With the rapid progress of large language models (LLMs), financial information retrieval has become a critical industrial application. Extracting task-relevant information from lengthy financial filings is essential for both operational and analytical decision-making. The FinAgentBench dataset formalizes this problem through two tasks: document ranking and chunk ranking. We present PRISM, a training-free framework that integrates refined system prompting, in-context learning (ICL), and a lightweight multi-agent system. Each component is examined extensively to reveal their synergies: prompt engineering provides precise task instructions, ICL supplies semantically relevant few-shot examples, and the multi-agent system models coordinated scoring behaviour. Our best configuration achieves an NDCG@5 of 0.71818 on the restricted validation split. We further demonstrate that PRISM is feasible and robust for production-scale financial retrieval. Its modular, inference-only design makes it practical for real-world use cases. The source code is released at https://bit.ly/prism-ailens.", "AI": {"tldr": "\u63d0\u51fa\u4e86PRISM\u6846\u67b6\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u8f7b\u91cf\u7ea7\u591a\u4ee3\u7406\u7cfb\u7edf\u6765\u89e3\u51b3\u91d1\u878d\u4fe1\u606f\u68c0\u7d22\u95ee\u9898\uff0c\u5728FinAgentBench\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e860.71818\u7684NDCG@5\u5206\u6570\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u91d1\u878d\u4fe1\u606f\u68c0\u7d22\u6210\u4e3a\u5173\u952e\u5de5\u4e1a\u5e94\u7528\u3002\u4ece\u5197\u957f\u7684\u8d22\u52a1\u6587\u4ef6\u4e2d\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u5bf9\u4e8e\u8fd0\u8425\u548c\u5206\u6790\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "PRISM\u6846\u67b6\u6574\u5408\u4e86\u7cbe\u70bc\u7684\u7cfb\u7edf\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u8f7b\u91cf\u7ea7\u591a\u4ee3\u7406\u7cfb\u7edf\u3002\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u7cbe\u786e\u4efb\u52a1\u6307\u4ee4\uff0c\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u8bed\u4e49\u76f8\u5173\u7684\u5c11\u6837\u672c\u793a\u4f8b\uff0c\u591a\u4ee3\u7406\u7cfb\u7edf\u6a21\u62df\u534f\u8c03\u8bc4\u5206\u884c\u4e3a\u3002", "result": "\u6700\u4f73\u914d\u7f6e\u5728\u53d7\u9650\u9a8c\u8bc1\u96c6\u4e0a\u5b9e\u73b0\u4e860.71818\u7684NDCG@5\u5206\u6570\uff0c\u8bc1\u660ePRISM\u5728\u751f\u4ea7\u89c4\u6a21\u91d1\u878d\u68c0\u7d22\u4e2d\u53ef\u884c\u4e14\u7a33\u5065\u3002", "conclusion": "PRISM\u7684\u6a21\u5757\u5316\u3001\u4ec5\u63a8\u7406\u8bbe\u8ba1\u4f7f\u5176\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\uff0c\u4e3a\u91d1\u878d\u4fe1\u606f\u68c0\u7d22\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14131", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14131", "abs": "https://arxiv.org/abs/2511.14131", "authors": ["Yu Zhong", "Zihao Zhang", "Rui Zhang", "Lingdong Huang", "Haihan Gao", "Shuo Wang", "Da Li", "Ruijian Han", "Jiaming Guo", "Shaohui Peng", "Di Huang", "Yunji Chen"], "title": "Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation", "comment": null, "summary": "Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.", "AI": {"tldr": "R3\u662f\u4e00\u4e2a\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u7684\u53cc\u8fc7\u7a0b\u601d\u8003\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u8f7b\u91cf\u7ea7\u4e13\u5bb6\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\u548c\u590d\u6742\u63a8\u7406\u7684\u534f\u8c03\u3002", "motivation": "\u89e3\u51b3VLN\u4efb\u52a1\u4e2dLLM\u65b9\u6cd5\u5728\u7a7a\u95f4\u7406\u89e3\u3001\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u5ef6\u8fdf\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u540c\u65f6\u4fdd\u6301LLM\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faR3\u6846\u67b6\uff0c\u5305\u542bRunner\uff08\u8f7b\u91cf\u7ea7\u4e13\u5bb6\u6a21\u578b\uff09\u3001Ruminator\uff08\u591a\u6a21\u6001LLM\u63a8\u7406\u6a21\u5757\uff09\u548cRegulator\uff08\u6a21\u5f0f\u5207\u6362\u63a7\u5236\u5668\uff09\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u534f\u8c03\u8fd0\u884c\u3002", "result": "\u5728REVERIE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPL\u548cRGSPL\u5206\u522b\u8d85\u8fc7\u73b0\u6709\u6700\u4f73\u65b9\u6cd53.28%\u548c3.30%\u3002", "conclusion": "R3\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86VLN\u4efb\u52a1\u7684\u6311\u6218\uff0c\u901a\u8fc7\u53cc\u8fc7\u7a0b\u601d\u8003\u673a\u5236\u5b9e\u73b0\u4e86\u5bfc\u822a\u6027\u80fd\u548c\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.14136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14136", "abs": "https://arxiv.org/abs/2511.14136", "authors": ["Sushant Mehta"], "title": "Beyond Accuracy: A Multi-Dimensional Framework for Evaluating Enterprise Agentic AI Systems", "comment": null, "summary": "Current agentic AI benchmarks predominantly evaluate task completion accuracy, while overlooking critical enterprise requirements such as cost-efficiency, reliability, and operational stability. Through systematic analysis of 12 main benchmarks and empirical evaluation of state-of-the-art agents, we identify three fundamental limitations: (1) absence of cost-controlled evaluation leading to 50x cost variations for similar precision, (2) inadequate reliability assessment where agent performance drops from 60\\% (single run) to 25\\% (8-run consistency), and (3) missing multidimensional metrics for security, latency, and policy compliance. We propose \\textbf{CLEAR} (Cost, Latency, Efficacy, Assurance, Reliability), a holistic evaluation framework specifically designed for enterprise deployment. Evaluation of six leading agents on 300 enterprise tasks demonstrates that optimizing for accuracy alone yields agents 4.4-10.8x more expensive than cost-aware alternatives with comparable performance. Expert evaluation (N=15) confirms that CLEAR better predicts production success (correlation $\u03c1=0.83$) compared to accuracy-only evaluation ($\u03c1=0.41$).", "AI": {"tldr": "\u63d0\u51fa\u4e86CLEAR\u8bc4\u4f30\u6846\u67b6\uff0c\u9488\u5bf9\u4f01\u4e1aAI\u4ee3\u7406\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u6db5\u76d6\u6210\u672c\u3001\u5ef6\u8fdf\u3001\u6548\u80fd\u3001\u4fdd\u969c\u548c\u53ef\u9760\u6027\u4e94\u4e2a\u7ef4\u5ea6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u53ea\u5173\u6ce8\u51c6\u786e\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u51c6\u786e\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u4f01\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u5173\u952e\u8981\u6c42\uff0c\u5982\u6210\u672c\u6548\u7387\u3001\u53ef\u9760\u6027\u548c\u64cd\u4f5c\u7a33\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u679012\u4e2a\u4e3b\u8981\u57fa\u51c6\u548c\u5b9e\u8bc1\u8bc4\u4f30\u6700\u5148\u8fdb\u4ee3\u7406\uff0c\u8bc6\u522b\u51fa\u4e09\u4e2a\u6839\u672c\u9650\u5236\uff0c\u5e76\u63d0\u51faCLEAR\u8bc4\u4f30\u6846\u67b6\u8fdb\u884c\u591a\u7ef4\u8bc4\u4f30\u3002", "result": "\u5728300\u4e2a\u4f01\u4e1a\u4efb\u52a1\u4e0a\u8bc4\u4f30\u516d\u4e2a\u9886\u5148\u4ee3\u7406\uff0c\u53d1\u73b0\u4ec5\u4f18\u5316\u51c6\u786e\u6027\u7684\u4ee3\u7406\u6bd4\u6210\u672c\u611f\u77e5\u66ff\u4ee3\u65b9\u6848\u8d354.4-10.8\u500d\uff1b\u4e13\u5bb6\u8bc4\u4f30\u786e\u8ba4CLEAR\u80fd\u66f4\u597d\u9884\u6d4b\u751f\u4ea7\u6210\u529f\uff08\u03c1=0.83 vs 0.41\uff09\u3002", "conclusion": "CLEAR\u6846\u67b6\u4e3a\u4f01\u4e1aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u663e\u8457\u4f18\u4e8e\u4ec5\u5173\u6ce8\u51c6\u786e\u6027\u7684\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2511.14199", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14199", "abs": "https://arxiv.org/abs/2511.14199", "authors": ["Jiazhuo Tian", "Yachao Yuan"], "title": "HFL-FlowLLM: Large Language Models for Network Traffic Flow Classification in Heterogeneous Federated Learning", "comment": null, "summary": "In modern communication networks driven by 5G and the Internet of Things (IoT), effective network traffic flow classification is crucial for Quality of Service (QoS) management and security. Traditional centralized machine learning struggles with the distributed data and privacy concerns in these heterogeneous environments, while existing federated learning approaches suffer from high costs and poor generalization. To address these challenges, we propose HFL-FlowLLM, which to our knowledge is the first framework to apply large language models to network traffic flow classification in heterogeneous federated learning. Compared to state-of-the-art heterogeneous federated learning methods for network traffic flow classification, the proposed approach improves the average F1 score by approximately 13%, demonstrating compelling performance and strong robustness. When compared to existing large language models federated learning frameworks, as the number of clients participating in each training round increases, the proposed method achieves up to a 5% improvement in average F1 score while reducing the training costs by about 87%. These findings prove the potential and practical value of HFL-FlowLLM in modern communication networks security.", "AI": {"tldr": "HFL-FlowLLM\u662f\u9996\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u4e2d\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u7684\u6846\u67b6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747F1\u5206\u6570\u63d0\u5347\u7ea613%\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e\u7ea687%\u3002", "motivation": "\u89e3\u51b35G\u548c\u7269\u8054\u7f51\u73af\u5883\u4e2d\u4f20\u7edf\u96c6\u4e2d\u5f0f\u673a\u5668\u5b66\u4e60\u9762\u4e34\u7684\u6570\u636e\u5206\u5e03\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faHFL-FlowLLM\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e73\u5747F1\u5206\u6570\u63d0\u5347\u7ea613%\uff1b\u76f8\u6bd4\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u968f\u7740\u5ba2\u6237\u7aef\u6570\u91cf\u589e\u52a0\uff0c\u5e73\u5747F1\u5206\u6570\u63d0\u5347\u8fbe5%\uff0c\u540c\u65f6\u8bad\u7ec3\u6210\u672c\u964d\u4f4e\u7ea687%\u3002", "conclusion": "HFL-FlowLLM\u5728\u73b0\u4ee3\u901a\u4fe1\u7f51\u7edc\u5b89\u5168\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.14214", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14214", "abs": "https://arxiv.org/abs/2511.14214", "authors": ["Pattaraphon Kenny Wongchamcharoen", "Paul Glasserman"], "title": "Do Large Language Models (LLMs) Understand Chronology?", "comment": "47 pages", "summary": "Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.", "AI": {"tldr": "\u6d4b\u8bd5LLMs\u5bf9\u65f6\u95f4\u987a\u5e8f\u7684\u7406\u89e3\u80fd\u529b\uff0c\u53d1\u73b0\u5728\u590d\u6742\u65f6\u5e8f\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u4f46\u589e\u52a0\u63a8\u7406\u9884\u7b97\u80fd\u663e\u8457\u63d0\u5347GPT-5\u548cClaude-3.7 Sonnet\u7684\u8868\u73b0\u3002", "motivation": "\u9a8c\u8bc1LLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u65f6\u95f4\u987a\u5e8f\uff0c\u8fd9\u5bf9\u91d1\u878d\u7ecf\u6d4e\u5e94\u7528\u4e2d\u907f\u514d\u524d\u77bb\u6027\u504f\u5dee\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8bbe\u8ba1\u4e09\u79cd\u65f6\u5e8f\u4efb\u52a1\uff1a\u65f6\u95f4\u6392\u5e8f\u3001\u6761\u4ef6\u6392\u5e8f\uff08\u5148\u7b5b\u9009\u540e\u6392\u5e8f\uff09\u548c\u65f6\u4ee3\u9519\u7f6e\u68c0\u6d4b\uff0c\u5728\u591a\u79cd\u63a8\u7406\u8bbe\u7f6e\u4e0b\u6d4b\u8bd5GPT-4.1\u3001Claude-3.7 Sonnet\u548cGPT-5\u3002", "result": "\u968f\u7740\u5e8f\u5217\u53d8\u957f\uff0c\u51c6\u786e\u7387\u6025\u5267\u4e0b\u964d\uff1b\u6761\u4ef6\u6392\u5e8f\u5931\u8d25\u4e3b\u8981\u6765\u81ea\u7b5b\u9009\u6b65\u9aa4\uff1b\u65f6\u4ee3\u9519\u7f6e\u68c0\u6d4b\u76f8\u5bf9\u5bb9\u6613\u4f46\u6027\u80fd\u4ecd\u4f1a\u4e0b\u964d\uff1b\u589e\u52a0\u63a8\u7406\u9884\u7b97\u80fd\u663e\u8457\u6539\u5584\u8868\u73b0\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u65f6\u5e8f\u4efb\u52a1\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u4f46\u660e\u786e\u5206\u914d\u63a8\u7406\u9884\u7b97\u80fd\u5e2e\u52a9\u6539\u5584\u8868\u73b0\uff0c\u8fd9\u5bf9LLMs\u5728\u91d1\u878d\u9886\u57df\u7684\u5b9e\u65f6\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.14219", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.14219", "abs": "https://arxiv.org/abs/2511.14219", "authors": ["Kumud Tripathi", "Aditya Srinivas Menon", "Aman Gaurav", "Raj Prakash Gohil", "Pankaj Wasnik"], "title": "Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation", "comment": "Accepted at AAAI 2026 - Main Technical Track", "summary": "The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u67b6\u6784\u6765\u51cf\u5c11Whisper\u6a21\u578b\u7684\u5e7b\u89c9\u9519\u8bef\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u81ea\u9002\u5e94\u5c42\u6ce8\u610f\u529b\u589e\u5f3a\u7f16\u7801\u5668\u9c81\u68d2\u6027\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u591a\u76ee\u6807\u77e5\u8bc6\u84b8\u998f\u6291\u5236\u5e7b\u89c9\u3002", "motivation": "Whisper\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7ecf\u5e38\u4ea7\u751f\u5e7b\u89c9\u9519\u8bef\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u97f3\u9891\u9884\u5904\u7406\u6216\u8f6c\u5f55\u540e\u5904\u7406\uff0c\u5bf9\u6a21\u578b\u672c\u8eab\u7684\u4fee\u6539\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "1. \u81ea\u9002\u5e94\u5c42\u6ce8\u610f\u529b(ALA)\uff1a\u901a\u8fc7\u5c42\u95f4\u76f8\u5173\u6027\u5206\u6790\u5c06\u7f16\u7801\u5668\u5c42\u5206\u7ec4\u4e3a\u8bed\u4e49\u8fde\u8d2f\u5757\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u591a\u5934\u6ce8\u610f\u529b\u878d\u5408\u5757\u8868\u793a\uff1b2. \u591a\u76ee\u6807\u77e5\u8bc6\u84b8\u998f(KD)\uff1a\u5728\u566a\u58f0\u97f3\u9891\u4e0a\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\uff0c\u4f7f\u5176\u8bed\u4e49\u548c\u6ce8\u610f\u529b\u5206\u5e03\u4e0e\u5904\u7406\u5e72\u51c0\u8f93\u5165\u7684\u6559\u5e08\u6a21\u578b\u5bf9\u9f50\u3002", "result": "\u5728\u566a\u58f0\u8bed\u97f3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\u548c\u8bcd\u9519\u8bef\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5728\u5e72\u51c0\u8bed\u97f3\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "ALA\u548cKD\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u566a\u58f0\u6761\u4ef6\u4e0b\u63d0\u9ad8Whisper\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7b56\u7565\u3002"}}
{"id": "2511.14227", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14227", "abs": "https://arxiv.org/abs/2511.14227", "authors": ["Yuxiang Wang", "Siwen Wang", "Haowei Han", "Ao Wang", "Boya Liu", "Yong Zhao", "Chengbo Wu", "Bin Zhu", "Bin Qin", "Xiaokai Zhou", "Xiao Yan", "Jiawei Jiang", "Bo Du"], "title": "DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home", "comment": null, "summary": "Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.", "AI": {"tldr": "DevPiolt\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u591a\u4efb\u52a1\u5fae\u8c03\u3001\u504f\u597d\u4f18\u5316\u548c\u7f6e\u4fe1\u5ea6\u63a7\u5236\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u5e76\u5728\u5c0f\u7c73\u5bb6\u5ead\u5e94\u7528\u4e2d\u6210\u529f\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u8350\u6a21\u578b\u5728\u5904\u7406\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u65f6\u9762\u4e34\u590d\u6742\u64cd\u4f5c\u903b\u8f91\u3001\u591a\u6837\u5316\u7528\u6237\u504f\u597d\u548c\u5bf9\u6b21\u4f18\u5efa\u8bae\u654f\u611f\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u63a8\u8350\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "1) \u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u591a\u4efb\u52a1\u5fae\u8c03\u4e3aLLM\u6ce8\u5165\u7269\u8054\u7f51\u64cd\u4f5c\u9886\u57df\u77e5\u8bc6\uff1b2) \u4f7f\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u5c06\u5fae\u8c03\u540e\u7684LLM\u4e0e\u7279\u5b9a\u7528\u6237\u504f\u597d\u5bf9\u9f50\uff1b3) \u8bbe\u8ba1\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u66dd\u5149\u63a7\u5236\u673a\u5236\u907f\u514d\u4f4e\u8d28\u91cf\u63a8\u8350\u5e26\u6765\u7684\u8d1f\u9762\u7528\u6237\u4f53\u9a8c\u3002", "result": "\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u6240\u6709\u6307\u6807\u5e73\u5747\u63d0\u534769.5%\u3002\u5728\u5c0f\u7c73\u5bb6\u5ead\u5e94\u7528\u4e2d\u90e8\u7f72\u4e00\u4e2a\u5b63\u5ea6\uff0c\u670d\u52a125.5\u4e07\u7528\u6237\uff0c\u5728\u7ebf\u5b9e\u9a8c\u663e\u793a\u552f\u4e00\u8bbf\u5ba2\u8bbe\u5907\u8986\u76d6\u7387\u63d0\u534721.6%\uff0c\u9875\u9762\u6d4f\u89c8\u63a5\u53d7\u7387\u63d0\u534729.1%\u3002", "conclusion": "DevPiolt\u6210\u529f\u89e3\u51b3\u4e86\u7269\u8054\u7f51\u8bbe\u5907\u64cd\u4f5c\u63a8\u8350\u7684\u6311\u6218\uff0c\u901a\u8fc7LLM\u6280\u672f\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4f18\u5316\u7b56\u7565\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.14248", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14248", "abs": "https://arxiv.org/abs/2511.14248", "authors": ["Hongju Lee", "Youngjun Park", "Jisun An", "Dongman Lee"], "title": "Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility", "comment": "Accepted at ASONAM 2025", "summary": "The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u533a\u57dfAirbnb\u5e02\u573a\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u623f\u6e90\u7279\u5f81\u548c\u5916\u90e8\u56e0\u7d20\u6784\u5efa\u533a\u57df\u8868\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5c06RMSE\u548cMAE\u964d\u4f4e\u7ea648%\u3002", "motivation": "Airbnb\u7b49\u77ed\u79df\u5e73\u53f0\u7684\u6269\u5f20\u6270\u4e71\u4e86\u5f53\u5730\u4f4f\u623f\u5e02\u573a\uff0c\u5bfc\u81f4\u79df\u91d1\u4e0a\u6da8\u548c\u4f4f\u623f\u53ef\u8d1f\u62c5\u6027\u95ee\u9898\u3002\u51c6\u786e\u9884\u6d4b\u533a\u57dfAirbnb\u5e02\u573a\u8d8b\u52bf\u53ef\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u5173\u952e\u6d1e\u5bdf\u3002", "method": "\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u9884\u6d4b1-3\u4e2a\u6708\u8d8b\u52bf\uff0c\u5c06\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3a\u57fa\u4e8e\u63d0\u793a\u7684LLM\u8f93\u5165\u751f\u6210\u533a\u57df\u5d4c\u5165\uff0c\u518d\u8f93\u5165\u5230\u65f6\u5e8f\u6a21\u578b\uff08RNN\u3001LSTM\u3001Transformer\uff09\u4e2d\u6355\u6349\u590d\u6742\u65f6\u7a7a\u52a8\u6001\u3002", "result": "\u5728\u9996\u5c14Airbnb\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e73\u5747RMSE\u548cMAE\u964d\u4f4e\u4e86\u7ea648%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u4e3a\u68c0\u6d4b\u4f9b\u5e94\u8fc7\u5269\u533a\u57df\u548c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u57ce\u5e02\u653f\u7b56\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2511.14256", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.14256", "abs": "https://arxiv.org/abs/2511.14256", "authors": ["Yu Liu", "Xixun Lin", "Yanmin Shang", "Yangxi Li", "Shi Wang", "Yanan Cao"], "title": "PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models", "comment": "AAAI 2026, Long Paper, Oral", "summary": "Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a \"Retrieve-Prioritize-Reason\" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.", "AI": {"tldr": "PathMind\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5f15\u5bfcLLM\u4f7f\u7528\u91cd\u8981\u63a8\u7406\u8def\u5f84\u6765\u589e\u5f3a\u5fe0\u5b9e\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u91c7\u7528\u201c\u68c0\u7d22-\u4f18\u5148\u6392\u5e8f-\u63a8\u7406\u201d\u8303\u5f0f\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709LLM-based\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u65b9\u6cd5\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1) \u65e0\u5dee\u522b\u63d0\u53d6\u63a8\u7406\u8def\u5f84\u53ef\u80fd\u5f15\u5165\u65e0\u5173\u566a\u58f0\u8bef\u5bfcLLM\uff1b2) \u52a8\u6001\u63a2\u7d22\u63a8\u7406\u8def\u5f84\u9700\u8981\u9ad8\u68c0\u7d22\u9700\u6c42\u548c\u9891\u7e41LLM\u8c03\u7528\u3002", "method": "\u91c7\u7528\u201c\u68c0\u7d22-\u4f18\u5148\u6392\u5e8f-\u63a8\u7406\u201d\u8303\u5f0f\uff1a\u9996\u5148\u901a\u8fc7\u68c0\u7d22\u6a21\u5757\u4eceKG\u4e2d\u68c0\u7d22\u67e5\u8be2\u5b50\u56fe\uff1b\u7136\u540e\u5f15\u5165\u8def\u5f84\u4f18\u5148\u6392\u5e8f\u673a\u5236\uff0c\u4f7f\u7528\u8bed\u4e49\u611f\u77e5\u7684\u8def\u5f84\u4f18\u5148\u7ea7\u51fd\u6570\u8bc6\u522b\u91cd\u8981\u63a8\u7406\u8def\u5f84\uff1b\u6700\u540e\u901a\u8fc7\u53cc\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u751f\u6210\u51c6\u786e\u54cd\u5e94\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPathMind\u6301\u7eed\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u63a8\u7406\u8def\u5f84\u4ee5\u66f4\u5c11\u7684\u8f93\u5165token\u5b9e\u73b0\u66f4\u597d\u6027\u80fd\u3002", "conclusion": "PathMind\u901a\u8fc7\u9009\u62e9\u6027\u8def\u5f84\u5f15\u5bfc\u548c\u53cc\u9636\u6bb5\u8bad\u7ec3\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3aLLM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14299", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.14299", "abs": "https://arxiv.org/abs/2511.14299", "authors": ["Xiaochuan Liu", "Yuanfeng Song", "Xiaoming Yin", "Xing Chen"], "title": "DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning", "comment": null, "summary": "In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.", "AI": {"tldr": "DataSage\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u3001\u591a\u89d2\u8272\u8fa9\u8bba\u673a\u5236\u548c\u591a\u8def\u5f84\u63a8\u7406\u6765\u89e3\u51b3\u73b0\u6709\u6570\u636e\u6d1e\u5bdf\u4ee3\u7406\u5728\u9886\u57df\u77e5\u8bc6\u5229\u7528\u3001\u5206\u6790\u6df1\u5ea6\u548c\u4ee3\u7801\u751f\u6210\u51c6\u786e\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5728\u6570\u636e\u9a71\u52a8\u65f6\u4ee3\uff0c\u5168\u81ea\u52a8\u7aef\u5230\u7aef\u6570\u636e\u5206\u6790\u5bf9\u4e8e\u53d1\u73b0\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6570\u636e\u6d1e\u5bdf\u4ee3\u7406\u5b58\u5728\u9886\u57df\u77e5\u8bc6\u5229\u7528\u4e0d\u8db3\u3001\u5206\u6790\u6df1\u5ea6\u6d45\u3001\u4ee3\u7801\u751f\u6210\u6613\u51fa\u9519\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faDataSage\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u521b\u65b0\u7279\u6027\uff1a\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u4e30\u5bcc\u5206\u6790\u4e0a\u4e0b\u6587\u3001\u591a\u89d2\u8272\u8fa9\u8bba\u673a\u5236\u6a21\u62df\u591a\u6837\u5316\u5206\u6790\u89c6\u89d2\u3001\u591a\u8def\u5f84\u63a8\u7406\u63d0\u9ad8\u4ee3\u7801\u548c\u6d1e\u5bdf\u751f\u6210\u51c6\u786e\u6027\u3002", "result": "\u5728InsightBench\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDataSage\u5728\u6240\u6709\u96be\u5ea6\u7ea7\u522b\u4e0a\u90fd\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u6d1e\u5bdf\u4ee3\u7406\u3002", "conclusion": "DataSage\u4e3a\u81ea\u52a8\u5316\u6570\u636e\u6d1e\u5bdf\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14334", "abs": "https://arxiv.org/abs/2511.14334", "authors": ["Alessio Pellegrino", "Jacopo Mauro"], "title": "When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling", "comment": null, "summary": "One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.", "AI": {"tldr": "LLMs\u5728\u81ea\u52a8\u751f\u6210\u4f18\u5316\u548c\u7ea6\u675f\u7f16\u7a0b\u6a21\u578b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9762\u5bf9\u91cd\u65b0\u8868\u8ff0\u548c\u6270\u52a8\u7684\u7ecf\u5178\u95ee\u9898\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u5176\u6210\u529f\u53ef\u80fd\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u68c0\u9a8cLLMs\u81ea\u52a8\u751f\u6210\u4f18\u5316\u6a21\u578b\u7684\u80fd\u529b\u662f\u5426\u771f\u6b63\u57fa\u4e8e\u63a8\u7406\uff0c\u8fd8\u662f\u4ec5\u4ec5\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u4e2d\u5305\u542b\u4e86\u7ecf\u5178\u95ee\u9898\u800c\u8868\u73b0\u826f\u597d\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u91cd\u65b0\u8868\u8ff0\u548c\u6270\u52a8CSPLib\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u4fdd\u6301\u7ed3\u6784\u4e0d\u53d8\u4f46\u4fee\u6539\u4e0a\u4e0b\u6587\u5e76\u5f15\u5165\u8bef\u5bfc\u5143\u7d20\uff0c\u7136\u540e\u6bd4\u8f83\u4e09\u4e2a\u4ee3\u8868\u6027LLM\u5728\u539f\u59cb\u548c\u4fee\u6539\u63cf\u8ff0\u4e0b\u7684\u6a21\u578b\u751f\u6210\u8868\u73b0\u3002", "result": "LLMs\u80fd\u591f\u751f\u6210\u8bed\u6cd5\u6709\u6548\u4e14\u8bed\u4e49\u5408\u7406\u7684\u6a21\u578b\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u548c\u8bed\u8a00\u53d8\u5316\u4e0b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u663e\u793a\u51fa\u6d45\u5c42\u7406\u89e3\u548c\u5bf9\u63aa\u8f9e\u7684\u654f\u611f\u6027\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u751f\u6210\u4f18\u5316\u6a21\u578b\u65b9\u9762\u7684\u6210\u529f\u53ef\u80fd\u4e3b\u8981\u6e90\u4e8e\u6570\u636e\u6c61\u67d3\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5176\u7406\u89e3\u6df1\u5ea6\u6709\u9650\u4e14\u5bf9\u8868\u8ff0\u53d8\u5316\u654f\u611f\u3002"}}
{"id": "2511.14476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14476", "abs": "https://arxiv.org/abs/2511.14476", "authors": ["Dalia Ali", "Dora Zhao", "Allison Koenecke", "Orestis Papakyriakopoulos"], "title": "Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior", "comment": null, "summary": "Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728LLM\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7eb3\u5165\u591a\u5143\u5316\u4ef7\u503c\u89c2\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\u548c\u8bbe\u8ba1\u53c2\u6570\uff0c\u53d1\u73b0\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u597d\u4f1a\u5bfc\u81f4\u6a21\u578b\u884c\u4e3a\u5dee\u5f02\uff0c\u6280\u672f\u8bbe\u8ba1\u9009\u62e9\u5bf9\u6bd2\u6027\u964d\u4f4e\u6548\u679c\u663e\u8457\u3002", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u51b3\u7b56\u5f80\u5f80\u5ffd\u89c6\u4eba\u7c7b\u793e\u4f1a\u7684\u591a\u6837\u6027\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5c06\u591a\u5143\u5316\u4ef7\u503c\u89c2\u7eb3\u5165\u5bf9\u9f50\u8fc7\u7a0b\uff0c\u4ee5\u5e73\u8861\u5b89\u5168\u6027\u548c\u516c\u5e73\u4ee3\u8868\u6027\u3002", "method": "\u6536\u96c6\u7f8e\u56fd\u548c\u5fb7\u56fd\u53c2\u4e0e\u8005\u7684\u5bf9\u9f50\u6570\u636e\uff0c\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u8bc4\u4f30LLM\u54cd\u5e94\uff0c\u4f7f\u7528\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u597d\u5fae\u8c03\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\uff0c\u5e76\u6539\u53d8\u8bc4\u5206\u5c3a\u5ea6\u3001\u5206\u6b67\u5904\u7406\u65b9\u6cd5\u548c\u4f18\u5316\u6280\u672f\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u4eba\u53e3\u7edf\u8ba1\u6548\u5e94\uff1a\u7537\u6027\u53c2\u4e0e\u8005\u5bf9\u6bd2\u6027\u7684\u8bc4\u5206\u6bd4\u5973\u6027\u4f4e18%\uff1b\u4fdd\u5b88\u6d3e\u548c\u9ed1\u4eba\u53c2\u4e0e\u8005\u5bf9\u60c5\u611f\u610f\u8bc6\u7684\u8bc4\u5206\u5206\u522b\u6bd4\u81ea\u7531\u6d3e\u548c\u767d\u4eba\u53c2\u4e0e\u8005\u9ad827.9%\u548c44%\u3002\u6280\u672f\u8bbe\u8ba1\u9009\u62e9\u663e\u793a\u5f3a\u70c8\u6548\u679c\uff1a\u4fdd\u7559\u8bc4\u5206\u8005\u5206\u6b67\u6bd4\u591a\u6570\u6295\u7968\u5b9e\u73b0\u7ea653%\u66f4\u5927\u7684\u6bd2\u6027\u964d\u4f4e\uff1b5\u70b9\u91cf\u8868\u6bd4\u4e8c\u5143\u683c\u5f0f\u4ea7\u751f\u7ea622%\u66f4\u591a\u964d\u4f4e\uff1bDPO\u5728\u591a\u503c\u4f18\u5316\u4e2d\u59cb\u7ec8\u4f18\u4e8eGRPO\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u56de\u7b54\u5173\u952e\u95ee\u9898\u63d0\u4f9b\u4e86\u521d\u6b65\u6b65\u9aa4\uff1a\u5bf9\u9f50\u5e94\u5982\u4f55\u5e73\u8861\u4e13\u5bb6\u9a71\u52a8\u548c\u7528\u6237\u9a71\u52a8\u4fe1\u53f7\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u548c\u516c\u5e73\u4ee3\u8868\u6027\u3002"}}
{"id": "2511.14533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14533", "abs": "https://arxiv.org/abs/2511.14533", "authors": ["Jiahao Wu", "Shengwen Yu"], "title": "A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning", "comment": "29 pages, 10 figures, 12 tables", "summary": "Bridging continuous perceptual signals and discrete symbolic reasoning is a fundamental challenge in AI systems that must operate under uncertainty. We present a neuro-symbolic framework that explicitly models and propagates uncertainty from perception to planning, providing a principled connection between these two abstraction levels. Our approach couples a transformer-based perceptual front-end with graph neural network (GNN) relational reasoning to extract probabilistic symbolic states from visual observations, and an uncertainty-aware symbolic planner that actively gathers information when confidence is low. We demonstrate the framework's effectiveness on tabletop robotic manipulation as a concrete application: the translator processes 10,047 PyBullet-generated scenes (3--10 objects) and outputs probabilistic predicates with calibrated confidences (overall F1=0.68). When embedded in the planner, the system achieves 94\\%/90\\%/88\\% success on Simple Stack, Deep Stack, and Clear+Stack benchmarks (90.7\\% average), exceeding the strongest POMDP baseline by 10--14 points while planning within 15\\,ms. A probabilistic graphical-model analysis establishes a quantitative link between calibrated uncertainty and planning convergence, providing theoretical guarantees that are validated empirically. The framework is general-purpose and can be applied to any domain requiring uncertainty-aware reasoning from perceptual input to symbolic planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u548c\u4f20\u64ad\u4ece\u611f\u77e5\u5230\u89c4\u5212\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fde\u63a5\u8fde\u7eed\u611f\u77e5\u4fe1\u53f7\u548c\u79bb\u6563\u7b26\u53f7\u63a8\u7406\u3002\u5728\u684c\u9762\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523090.7%\u5e73\u5747\u6210\u529f\u7387\uff0c\u6bd4\u6700\u5f3aPOMDP\u57fa\u7ebf\u63d0\u9ad810-14\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u89e3\u51b3\u8fde\u7eed\u611f\u77e5\u4fe1\u53f7\u4e0e\u79bb\u6563\u7b26\u53f7\u63a8\u7406\u4e4b\u95f4\u7684\u6865\u6881\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u8fd0\u884c\u7684AI\u7cfb\u7edf\u9700\u8981\u5efa\u7acb\u8fd9\u4e24\u4e2a\u62bd\u8c61\u5c42\u6b21\u4e4b\u95f4\u7684\u539f\u5219\u6027\u8fde\u63a5\u3002", "method": "\u7ed3\u5408\u57fa\u4e8etransformer\u7684\u611f\u77e5\u524d\u7aef\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u5173\u7cfb\u63a8\u7406\uff0c\u4ece\u89c6\u89c9\u89c2\u5bdf\u4e2d\u63d0\u53d6\u6982\u7387\u7b26\u53f7\u72b6\u6001\uff0c\u5e76\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u7b26\u53f7\u89c4\u5212\u5668\u5728\u7f6e\u4fe1\u5ea6\u4f4e\u65f6\u4e3b\u52a8\u6536\u96c6\u4fe1\u606f\u3002", "result": "\u572810,047\u4e2aPyBullet\u751f\u6210\u7684\u573a\u666f\uff083-10\u4e2a\u7269\u4f53\uff09\u4e0a\u5904\u7406\uff0c\u8f93\u51fa\u5177\u6709\u6821\u51c6\u7f6e\u4fe1\u5ea6\u7684\u6982\u7387\u8c13\u8bcd\uff08\u603b\u4f53F1=0.68\uff09\u3002\u5728\u89c4\u5212\u5668\u4e2d\u5d4c\u5165\u540e\uff0c\u5728Simple Stack\u3001Deep Stack\u548cClear+Stack\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8fbe\u523094%/90%/88%\u6210\u529f\u7387\uff08\u5e73\u574790.7%\uff09\uff0c\u6bd4\u6700\u5f3aPOMDP\u57fa\u7ebf\u63d0\u9ad810-14\u4e2a\u767e\u5206\u70b9\uff0c\u89c4\u5212\u65f6\u95f4\u572815\u6beb\u79d2\u5185\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u4e0e\u89c4\u5212\u6536\u655b\u4e4b\u95f4\u7684\u5b9a\u91cf\u8054\u7cfb\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u5e76\u7ecf\u9a8c\u9a8c\u8bc1\u3002\u8be5\u6846\u67b6\u662f\u901a\u7528\u7684\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u9700\u8981\u4ece\u611f\u77e5\u8f93\u5165\u5230\u7b26\u53f7\u89c4\u5212\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a8\u7406\u7684\u9886\u57df\u3002"}}
{"id": "2511.14650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14650", "abs": "https://arxiv.org/abs/2511.14650", "authors": ["Jingyi Jia", "Qinbin Li"], "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "comment": "Accepted by AAAI 2026, 18 pages, 11 figures, Code: https://github.com/jiajingyyyyyy/AutoTool", "summary": "Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.", "AI": {"tldr": "AutoTool\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u5de5\u5177\u4f7f\u7528\u60ef\u6027\u6765\u51cf\u5c11LLM\u4ee3\u7406\u4e2d\u7684\u63a8\u7406\u6210\u672c\uff0c\u65e0\u9700\u91cd\u590d\u8c03\u7528LLM\u8fdb\u884c\u5de5\u5177\u9009\u62e9", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u6846\u67b6\u5728\u5de5\u5177\u9009\u62e9\u65f6\u5b58\u5728\u9ad8\u63a8\u7406\u6210\u672c\u95ee\u9898\uff0c\u7279\u522b\u662f\u50cfReAct\u8fd9\u6837\u9700\u8981\u53cd\u590d\u8c03\u7528LLM\u786e\u5b9a\u6bcf\u4e2a\u6b65\u9aa4\u4f7f\u7528\u4ec0\u4e48\u5de5\u5177\u7684\u65b9\u6cd5", "method": "\u6784\u5efa\u57fa\u4e8e\u5386\u53f2\u4ee3\u7406\u8f68\u8ff9\u7684\u6709\u5411\u56fe\uff0c\u8282\u70b9\u4ee3\u8868\u5de5\u5177\uff0c\u8fb9\u6355\u6349\u8f6c\u79fb\u6982\u7387\uff0c\u5efa\u6a21\u5de5\u5177\u9009\u62e9\u60ef\u6027\uff0c\u5e76\u96c6\u6210\u53c2\u6570\u7ea7\u4fe1\u606f\u6765\u4f18\u5316\u5de5\u5177\u8f93\u5165\u751f\u6210", "result": "\u5728\u591a\u6837\u5316\u4ee3\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAutoTool\u5c06\u63a8\u7406\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe30%\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u4efb\u52a1\u5b8c\u6210\u7387", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5c06\u7edf\u8ba1\u7ed3\u6784\u6574\u5408\u5230LLM\u4ee3\u7406\u8bbe\u8ba1\u4e2d\u7684\u524d\u666f\uff0c\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u7684\u6548\u7387"}}
{"id": "2511.14670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14670", "abs": "https://arxiv.org/abs/2511.14670", "authors": ["Ruomeng Ding", "Wei Cheng", "Minglai Shao", "Chen Zhao"], "title": "SkillGen: Learning Domain Skills for In-Context Sequential Decision Making", "comment": null, "summary": "Large language models (LLMs) are increasingly applied to sequential decision-making through in-context learning (ICL), yet their effectiveness is highly sensitive to prompt quality. Effective prompts should meet three principles: focus on decision-critical information, provide step-level granularity, and minimize reliance on expert annotations through label efficiency. However, existing ICL methods often fail to satisfy all three criteria simultaneously. Motivated by these challenges, we introduce SkillGen, a skill-based ICL framework for structured sequential reasoning. It constructs an action-centric, domain-level graph from sampled trajectories, identifies high-utility actions via temporal-difference credit assignment, and retrieves step-wise skills to generate fine-grained, context-aware prompts. We further present a theoretical analysis showing that focusing on high-utility segments supports task identifiability and informs more effective ICL prompt design. Experiments on ALFWorld, BabyAI, and ScienceWorld, using both open-source and proprietary LLMs, show that SkillGen achieves consistent gains, improving progress rate by 5.9%-16.5% on average across models.", "AI": {"tldr": "SkillGen\u662f\u4e00\u4e2a\u57fa\u4e8e\u6280\u80fd\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u52a8\u4f5c\u4e2d\u5fc3\u56fe\u3001\u8bc6\u522b\u9ad8\u6548\u7528\u52a8\u4f5c\u548c\u68c0\u7d22\u6b65\u9aa4\u6280\u80fd\uff0c\u4e3a\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u63d0\u793a\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347LLM\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u63d0\u793a\u8d28\u91cf\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u5173\u6ce8\u51b3\u7b56\u5173\u952e\u4fe1\u606f\u3001\u63d0\u4f9b\u6b65\u9aa4\u7ea7\u7c92\u5ea6\u548c\u51cf\u5c11\u4e13\u5bb6\u6807\u6ce8\u4f9d\u8d56\u8fd9\u4e09\u4e2a\u539f\u5219\u3002", "method": "SkillGen\u6784\u5efa\u52a8\u4f5c\u4e2d\u5fc3\u7684\u9886\u57df\u7ea7\u56fe\uff0c\u901a\u8fc7\u65f6\u95f4\u5dee\u5206\u4fe1\u7528\u5206\u914d\u8bc6\u522b\u9ad8\u6548\u7528\u52a8\u4f5c\uff0c\u5e76\u68c0\u7d22\u6b65\u9aa4\u7ea7\u6280\u80fd\u6765\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u3002", "result": "\u5728ALFWorld\u3001BabyAI\u548cScienceWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSkillGen\u5e73\u5747\u63d0\u5347\u8fdb\u5ea6\u73875.9%-16.5%\uff0c\u5728\u5f00\u6e90\u548c\u4e13\u6709LLM\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u589e\u76ca\u3002", "conclusion": "\u5173\u6ce8\u9ad8\u6548\u7528\u7247\u6bb5\u652f\u6301\u4efb\u52a1\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u4e3a\u66f4\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u793a\u8bbe\u8ba1\u63d0\u4f9b\u4fe1\u606f\uff0cSkillGen\u6846\u67b6\u5728\u987a\u5e8f\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.14730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14730", "abs": "https://arxiv.org/abs/2511.14730", "authors": ["Parya Dolatyabi", "Mahdi Khodayar"], "title": "Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration", "comment": "6 pages, 4 figures, TPEC 2025 Conference", "summary": "Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges make conventional optimization and value-based RL approaches computationally inefficient and difficult to scale. This paper applies a Heterogeneous-Agent Reinforcement Learning (HARL) framework, instantiated through Heterogeneous-Agent Proximal Policy Optimization (HAPPO), to enable coordinated restoration across interconnected microgrids. Each agent controls a distinct microgrid with different loads, DER capacities, and switch counts, introducing practical structural heterogeneity. Decentralized actor policies are trained with a centralized critic to compute advantage values for stable on-policy updates. A physics-informed OpenDSS environment provides full power flow feedback and enforces operational limits via differentiable penalty signals rather than invalid action masking. The total DER generation is capped at 2400 kW, and each microgrid must satisfy local supply-demand feasibility. Experiments on the IEEE 123-bus and IEEE 8500-node systems show that HAPPO achieves faster convergence, higher restored power, and smoother multi-seed training than DQN, PPO, MAES, MAGDPG, MADQN, Mean-Field RL, and QMIX. Results demonstrate that incorporating microgrid-level heterogeneity within the HARL framework yields a scalable, stable, and constraint-aware solution for complex PDS restoration.", "AI": {"tldr": "\u672c\u6587\u5e94\u7528\u5f02\u6784\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u7535\u529b\u914d\u7535\u7f51\u5927\u89c4\u6a21\u505c\u7535\u540e\u7684\u6062\u590d\u95ee\u9898\uff0c\u901a\u8fc7HAPPO\u7b97\u6cd5\u5b9e\u73b0\u4e92\u8054\u5fae\u7535\u7f51\u7684\u534f\u8c03\u6062\u590d\uff0c\u5728IEEE\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u548c\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u914d\u7535\u7f51\u6062\u590d\u95ee\u9898\u65f6\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u89e3\u51b3\u975e\u7ebf\u6027\u7ea6\u675f\u4e0b\u7684\u987a\u5e8f\u5f00\u5173\u64cd\u4f5c\u548c\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u534f\u8c03\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5f02\u6784\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u6784\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u8bad\u7ec3\u53bb\u4e2d\u5fc3\u5316\u7684\u6267\u884c\u5668\u7b56\u7565\uff0c\u914d\u5408\u96c6\u4e2d\u5f0f\u8bc4\u8bba\u5bb6\u8ba1\u7b97\u4f18\u52bf\u503c\u8fdb\u884c\u7a33\u5b9a\u7684\u7b56\u7565\u66f4\u65b0\uff0c\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u5316\u7684OpenDSS\u73af\u5883\u63d0\u4f9b\u5b8c\u6574\u6f6e\u6d41\u53cd\u9988\u3002", "result": "\u5728IEEE 123\u603b\u7ebf\u548cIEEE 8500\u8282\u70b9\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHAPPO\u76f8\u6bd4DQN\u3001PPO\u3001MAES\u3001MAGDPG\u3001MADQN\u3001Mean-Field RL\u548cQMIX\u7b49\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u9ad8\u7684\u6062\u590d\u529f\u7387\u548c\u66f4\u5e73\u6ed1\u7684\u591a\u79cd\u5b50\u8bad\u7ec3\u8fc7\u7a0b\u3002", "conclusion": "\u5c06\u5fae\u7535\u7f51\u7ea7\u522b\u7684\u5f02\u6784\u6027\u7eb3\u5165HARL\u6846\u67b6\uff0c\u4e3a\u590d\u6742\u914d\u7535\u7f51\u6062\u590d\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u7a33\u5b9a\u4e14\u7ea6\u675f\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
