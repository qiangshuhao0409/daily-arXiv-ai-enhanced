<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.IT](#cs.IT) [Total: 7]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [DecodeX: Exploring and Benchmarking of LDPC Decoding across CPU, GPU, and ASIC Platforms](https://arxiv.org/abs/2511.02952)
*Zhenzhou Qi,Yuncheng Yao,Yiming Li,Chung-Hsuan Tung,Junyao Zheng,Danyang Zhuo,Tingjun Chen*

Main category: cs.NI

TL;DR: DecodeX是一个统一的基准测试框架，用于评估不同硬件平台上的LDPC解码加速性能，揭示了并行效率和卸载开销之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 虚拟化无线接入网络需要跨异构计算基板进行灵活高效的基带处理，但缺乏统一的基准测试方法来评估不同硬件平台的LDPC解码性能。

Method: 开发DecodeX框架，集成CPU、GPU和ASIC等多种硬件平台的LDPC解码器实现，包括内核、API和测试向量，系统性地分析不同平台的计算编排方式。

Result: 研究发现加速器性能增益强烈依赖于数据移动和工作负载粒度，揭示了并行效率和卸载开销之间的明显权衡关系。

Conclusion: 跨平台基准测试可以为未来异构vRAN的自适应调度和协同设计提供指导，实现下一代无线系统的可扩展和节能基带处理。

Abstract: Emerging virtualized radio access networks (vRANs) demand flexible and
efficient baseband processing across heterogeneous compute substrates. In this
paper, we present DecodeX, a unified benchmarking framework for evaluating
low-density parity-check (LDPC) decoding acceleration across different hardware
platforms. DecodeX integrates a comprehensive suite of LDPC decoder
implementations, including kernels, APIs, and test vectors for CPUs (FlexRAN),
GPUs (Aerial and Sionna-RK), and ASIC (ACC100), and can be readily extended to
additional architectures and configurations. Using DecodeX, we systematically
characterize how different platforms orchestrate computation-from threading and
memory management to data movement and accelerator offload-and quantify the
resulting decoding latency under varying Physical layer parameters. Our
observations reveal distinct trade-offs in parallel efficiency and offload
overhead, showing that accelerator gains strongly depend on data-movement and
workload granularity. Building on these insights, we discuss how cross-platform
benchmarking can inform adaptive scheduling and co-design for future
heterogeneous vRANs, enabling scalable and energy-efficient baseband processing
for NextG wireless systems.

</details>


### [2] [Distributed Incast Detection in Data Center Networks](https://arxiv.org/abs/2511.03039)
*Yiming Zheng,Haoran Qi,Lirui Yu,Zhan Shu,Qing Zhao*

Main category: cs.NI

TL;DR: 提出了一种基于概率假设测试的分布式数据中心网络拥塞检测方法，通过分析新流到达间隔来快速识别incast流量


<details>
  <summary>Details</summary>
Motivation: 数据中心incast流量会导致严重性能下降，现有基于队列长度阈值的检测方法存在延迟检测和高错误率问题

Method: 在交换机层面使用概率假设测试和最优检测阈值，通过分析新流到达间隔从初始数据包立即判断是否为incast流量

Result: 实验结果显示该方法在检测速度和推理准确性方面相比现有方法有显著提升

Conclusion: 该方法能够有效解决incast流量检测的延迟和准确性问题，为数据中心网络性能优化提供了新思路

Abstract: Incast traffic in data centers can lead to severe performance degradation,
such as packet loss and increased latency. Effectively addressing incast
requires prompt and accurate detection. Existing solutions, including MA-ECN,
BurstRadar and Pulser, typically rely on fixed thresholds of switch port egress
queue lengths or their gradients to identify microburst caused by incast flows.
However, these queue length related methods often suffer from delayed detection
and high error rates. In this study, we propose a distributed incast detection
method for data center networks at the switch-level, leveraging a probabilistic
hypothesis test with an optimal detection threshold. By analyzing the arrival
intervals of new flows, our algorithm can immediately determine if a flow is
part of an incast traffic from its initial packet. The experimental results
demonstrate that our method offers significant improvements over existing
approaches in both detection speed and inference accuracy.

</details>


### [3] [CRSF: Enabling QoS-Aware Beyond-Connectivity Service Sharing in 6G Local Networks](https://arxiv.org/abs/2511.03081)
*Pragya Sharma,Amanda Xiang,Abbas Kiani,John Kaippallimalil,Tony Saboorian,Haining Wang*

Main category: cs.NI

TL;DR: 本文提出了CRSF（中央存储库和选择功能），这是6G核心网中的一个新型网络功能，用于实现跨子网络的服务发现和选择，通过QoS感知优化提升服务质量。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要支持互联的本地子网络共享专业化服务，但目前缺乏跨网络边界的标准化服务发现和选择架构。

Method: 将服务选择过程建模为QoS感知优化问题，平衡服务质量指标和用户定义优先级，通过仿真评估系统模型。

Result: 在感知服务场景的仿真中，相比基线选择策略，观察到持续更高的聚合服务质量（QoS）。

Conclusion: CRSF为构建6G时代所需的标准化、协作式、以服务为中心的互联网络提供了基础且可扩展的机制。

Abstract: Sixth-generation (6G) networks are envisioned to support interconnected local
subnetworks that can share specialized, beyond-connectivity services. However,
a standardized architecture for discovering and selecting these services across
network boundaries has not existed yet. To address this gap, this paper
introduces the Central Repository and Selection Function (CRSF), a novel
network function for the 6G core that facilitates efficient inter-subnetwork
service discovery and selection. We formulate the selection process as a
QoS-aware optimization problem designed to balance service quality metrics with
user-defined priorities. We evaluate our system model through simulations for a
sensing service scenario and observe a consistently higher aggregate Quality of
Service (QoS) compared to the baseline selection strategy. The proposed CRSF
provides a foundational and extensible mechanism for building standardized,
collaborative, and service-centric interconnected networks essential for the 6G
era.

</details>


### [4] [Handover Configurations in Operational 5G Networks: Diversity, Evolution, and Impact on Performance](https://arxiv.org/abs/2511.03116)
*Moinak Ghoshal,Imran Khan,Phuc Dinh,Z. Jonny Kong,Omar Basit,Sizhe Wang,Yufei Feng,Y. Charlie Hu,Dimitrios Koutsonikolas*

Main category: cs.NI

TL;DR: 本文通过在美国进行的27个月跨州驾驶测试，对三大运营商的5G网络切换配置进行了深入测量研究，揭示了新的切换类型、过度激进的配置导致高信令开销、参数值多样性以及次优配置导致性能问题。


<details>
  <summary>Details</summary>
Motivation: 5G大规模部署和4G/5G共存使得切换过程比以往更加复杂，但现有研究对5G运营网络中切换发生的原因、方式以及配置如何影响性能仍知之甚少。

Method: 通过在美国进行的四次跨州驾驶旅行，历时27个月，对三大主要运营商的切换配置进行深入测量研究。

Result: 研究发现：(a)运营商使用新的切换类型和事件处理这些新类型；(b)过度激进的切换配置导致不必要的高信令开销；(c)切换配置参数值存在巨大差异，运营商间也不同，但5G的多样性显著低于LTE；(d)次优的切换配置/决策导致切换前后性能不佳。

Conclusion: 研究结果对移动运营商在持续优化5G切换配置方面具有重要意义，揭示了当前配置存在的问题和改进方向。

Abstract: Mobility management in cellular networks, especially the handover (HO)
process, plays a key role in providing seamless and ubiquitous Internet access.
The wide-scale deployment of 5G and the resulting co-existence of 4G/5G in the
past six years have significantly changed the landscape of all mobile network
operators and made the HO process much more complex than before. While several
recent works have studied the impact of HOs on user experience, why and how HOs
occur and how HO configurations affect performance in 5G operational networks
remains largely unknown. Through four cross-country driving trips across the US
spread out over a 27-month period, we conduct an in-depth measurement study of
HO configurations across all three major US operators. Our study reveals (a)
new types of HOs and new HO events used by operators to handle these new types
of HOs, (b) overly aggressive HO configurations that result in unnecessarily
high signaling overhead, (c) large diversity in HO configuration parameter
values, which also differ across operators, but significantly lower diversity
in 5G compared to LTE, and (d) sub-optimal HO configurations/decisions leading
to poor pre- or post-HO performance. Our findings have many implications for
mobile operators, as they keep fine-tuning their 5G HO configurations.

</details>


### [5] [Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing](https://arxiv.org/abs/2511.03159)
*Shuting Qiu,Fang Dong,Siyu Tan,Ruiting Zhou,Dian Shen,Patrick P. C. Lee,Qilin Fan*

Main category: cs.NI

TL;DR: 提出CoCaR算法，通过动态DNN分解和联合优化模型缓存与请求路由，在移动边缘计算中提升用户请求推理精度和QoE


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算中缓存所有DNN模型困难，且模型加载时间对用户体验质量的影响未被充分研究，需要更细粒度的模型缓存和路由解决方案

Method: 将完整DNN模型分解为相互关联的子模型，提出基于线性规划和随机舍入的离线CoCaR算法，以及适应动态请求模式的在线CoCaR-OL算法

Result: CoCaR相比现有方法平均推理精度提升46%，CoCaR-OL在在线场景下用户QoE提升不低于32.3%

Conclusion: 动态DNN分解和联合优化缓存路由策略能有效平衡推理精度和加载延迟，显著提升移动边缘计算中的用户体验质量

Abstract: Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near
end-users, providing low-latency services and improving users' quality of
experience (QoE). However, caching all DNN models at edge servers with limited
capacity is difficult, and the impact of model loading time on QoE remains
underexplored. Hence, we introduce dynamic DNNs in edge scenarios,
disassembling a complete DNN model into interrelated submodels for more
fine-grained and flexible model caching and request routing solutions. This
raises the pressing issue of jointly deciding request routing and submodel
caching for dynamic DNNs to balance model inference precision and loading
latency for QoE optimization. In this paper, we study the joint dynamic model
caching and request routing problem in MEC networks, aiming to maximize user
request inference precision under constraints of server resources, latency, and
model loading time. To tackle this problem, we propose CoCaR, an offline
algorithm based on linear programming and random rounding that leverages
dynamic DNNs to optimize caching and routing schemes, achieving near-optimal
performance. Furthermore, we develop an online variant of CoCaR, named
CoCaR-OL, enabling effective adaptation to dynamic and unpredictable online
request patterns. The simulation results demonstrate that the proposed CoCaR
improves the average inference precision of user requests by 46\% compared to
state-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves
an improvement of no less than 32.3\% in user QoE over competitive baselines.

</details>


### [6] [Integrity Under Siege: A Rogue gNodeB's Manipulation of 5G Network Slice Allocation](https://arxiv.org/abs/2511.03312)
*Jiali Xu,Valeria Loscri,Romain Rouvoy*

Main category: cs.NI

TL;DR: 本文揭露了5G网络切片分配中的完整性漏洞，攻击者可通过恶意gNodeB伪造切片请求，导致服务质量严重下降或隐蔽的资源污染攻击。


<details>
  <summary>Details</summary>
Motivation: 5G网络切片技术虽然提供了定制化服务，但也引入了新的攻击面。本文旨在研究切片分配操纵对服务质量和资源完整性的威胁。

Method: 建立了基于风险分析的威胁模型，在5G测试床上进行实验评估，包括利用null-ciphering等不安全配置，通过恶意gNodeB实施中间人攻击。

Result: 实验显示攻击可导致95%带宽下降和150%延迟增加，或实施隐蔽的切片操纵而不产生核心网错误。资源污染攻击可造成60%以上丢包率和80%CPU饱和。

Conclusion: 5G动态资源管理的完整性安全亟需加强，提出了跨层缓解策略，强调了保护服务等级协议和关键基础设施的重要性。

Abstract: The advent of 5G networks, with network slicing as a cornerstone technology,
promises customized, high-performance services, but also introduces novel
attack surfaces beyond traditional threats. This article investigates a
critical and underexplored integrity vulnerability: the manipulation of network
slice allocation to compromise Quality of Service (QoS) and resource integrity.
We introduce a threat model, grounded in a risk analysis of permissible yet
insecure configurations like null-ciphering (5G-EA0), demonstrating how a rogue
gNodeB acting as a Man-in-the-Middle can exploit protocol weaknesses to forge
slice requests and hijack a User Equipment's (UE) connection. Through a
comprehensive experimental evaluation on a 5G testbed, we demonstrate the
attack's versatile and severe impacts. Our findings show this integrity breach
can manifest as obvious QoS degradation, such as a 95% bandwidth reduction and
150% latency increase when forcing UE to a suboptimal slice, or as stealthy
slice manipulation that is indistinguishable from benign network operation and
generates no core network errors. Furthermore, we validate a systemic resource
contamination attack where redirecting a crowd of UE orchestrates a
Denial-of-Service, causing packet loss to exceed 60% and inducing measurable
CPU saturation (~80%) on core network User Plane Functions (UPFs). Based on
these results, we discuss the profound implications for Service Level
Agreements (SLAs) and critical infrastructure. We propose concrete, cross-layer
mitigation strategies for network operators as future work, underscoring the
urgent need to secure the integrity of dynamic resource management in 5G
networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Evaluating Control Protocols for Untrusted AI Agents](https://arxiv.org/abs/2511.02997)
*Jon Kutasov,Chloe Loughridge,Yuqi Sun,Henry Sleight,Buck Shlegeris,Tyler Tracy,Joe Benton*

Main category: cs.AI

TL;DR: 本文系统评估了AI控制协议在SHADE-Arena环境中的安全性，发现关键行动延迟协议对红队攻击具有高度鲁棒性，而重采样策略在红队获得协议内部信息时安全性会大幅下降。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统作为智能体广泛部署，确保其安全运行变得至关重要。AI控制通过监控AI代理行为并在必要时干预或审计来降低风险，需要评估这些协议的有效性和对自适应攻击的鲁棒性。

Method: 在SHADE-Arena多样化智能体环境中系统评估控制协议：包括信任模型延迟、重采样和关键行动延迟等蓝队协议，以及针对这些协议的红队攻击策略迭代。

Result: 重采样和关键行动延迟协议将安全性从50%提升到96%；但当红队策略获得重采样发生时机或模拟监控器能力时，攻击成功率大幅提高，安全性降至17%；关键行动延迟协议对最强红队策略仍保持高度鲁棒性。

Conclusion: 关键行动延迟协议对自适应攻击具有显著鲁棒性，而重采样策略在攻击者了解协议内部信息时易受攻击，强调了拒绝攻击策略访问协议内部信息的重要性。

Abstract: As AI systems become more capable and widely deployed as agents, ensuring
their safe operation becomes critical. AI control offers one approach to
mitigating the risk from untrusted AI agents by monitoring their actions and
intervening or auditing when necessary. Evaluating the safety of these
protocols requires understanding both their effectiveness against current
attacks and their robustness to adaptive adversaries. In this work, we
systematically evaluate a range of control protocols in SHADE-Arena, a dataset
of diverse agentic environments. First, we evaluate blue team protocols,
including deferral to trusted models, resampling, and deferring on critical
actions, against a default attack policy. We find that resampling for
incrimination and deferring on critical actions perform best, increasing safety
from 50% to 96%. We then iterate on red team strategies against these protocols
and find that attack policies with additional affordances, such as knowledge of
when resampling occurs or the ability to simulate monitors, can substantially
improve attack success rates against our resampling strategy, decreasing safety
to 17%. However, deferring on critical actions is highly robust to even our
strongest red team strategies, demonstrating the importance of denying attack
policies access to protocol internals.

</details>


### [8] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: PublicAgent是一个多智能体框架，通过将端到端数据分析工作流分解为专门的智能体（意图澄清、数据集发现、分析和报告），解决了LLM在复杂分析任务中的注意力稀释、推理模式干扰和错误传播问题。


<details>
  <summary>Details</summary>
Motivation: 开放数据仓库对非专家用户难以访问，需要数据集发现、模式映射和统计分析的专业知识。虽然LLM在单个任务上表现良好，但在端到端分析工作流中存在根本性限制。

Method: 采用多智能体框架，将工作流分解为四个专门的智能体：意图澄清、数据集发现、分析和报告，每个智能体保持专注的注意力范围并支持阶段验证。

Result: 评估显示：1) 专业化独立于模型强度提供价值；2) 智能体分为通用型（发现、分析）和条件型（报告、意图）；3) 不同智能体缓解不同的失败模式；4) 架构优势在不同任务复杂度下持续存在；5) 智能体有效性在不同模型间差异显著。

Conclusion: 该研究提出了多智能体LLM系统的五个设计原则，指导了在复杂分析工作流中何时以及为何需要专业化，同时通过自然语言接口实现更广泛的公共数据访问。

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [9] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval是一个大规模基准测试研究，系统比较了36个LLM作为评估者的性能，发现Gemini 1.5 Pro在跨类别表现最佳，GPT-4o在延迟-准确性-成本权衡最优，Claude 3.5 Sonnet决策置信度最高。


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为评估者的应用日益重要，需要可扩展且可信赖的评估流程，因此需要系统比较不同LLM作为评估者的性能。

Method: 采用多智能体框架，通过可扩展的多数投票将模式审计和问题代码聚合成真实标签，无需人工标注即可进行可复现的LLM评估者比较。

Result: 在互补商品推荐基准测试中：Claude 3.5 Sonnet决策置信度最高；Gemini 1.5 Pro跨类别表现最佳；GPT-4o在延迟-准确性-成本权衡最优；GPT-OSS 20B在开源模型中领先。结构化领域（电子、体育）共识强，生活方式类别（服装、食品）存在持续分歧。

Conclusion: ScalingEval建立了可复现的LLM作为评估者的基准测试和评估协议，为扩展性、可靠性和模型家族权衡提供了可操作的指导。

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [10] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文构建了首个基准测试来评估LLMs是否内化了真实世界的概率分布知识，结果显示LLMs在理解现实世界统计数据方面表现不佳，且缺乏因果层次中的观测分布知识。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在事实性知识方面表现优异，但在概率性知识（反映现实世界概率分布）方面能力有限。本文旨在测试LLMs是否真正内化了描述现实世界人口分布的概率知识。

Method: 开发首个基准测试，评估LLMs在经济学、健康、教育和社会行为等领域获取经验分布的能力，通过测试LLMs对现实世界统计数据的理解来验证其分布学习能力。

Result: LLMs整体表现不佳，似乎没有自然内化现实世界统计数据。在Pearl因果层次框架下，语言模型缺乏观测分布知识（第一层），因此干预性和反事实性知识也受到限制。

Conclusion: LLMs在获取现实世界概率分布知识方面存在根本性局限，无法自然内化真实世界的统计数据，这对其作为通用分布近似器的能力提出了挑战。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [11] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: SnapStream是一种KV缓存压缩方法，可在保持模型精度的同时实现4倍片上内存使用改进，并在实际生产环境中部署于DeepSeek-671B模型。


<details>
  <summary>Details</summary>
Motivation: 随着100B+参数大语言模型和100k+上下文长度的普及，对片上内存支持大KV缓存的需求增加。现有技术如StreamingLLM和SnapKV难以在工业部署框架中应用，且对现代指令跟随和推理模型的精度影响不明确。

Method: 开发SnapStream KV缓存压缩方法，可在静态图和连续批处理框架中部署，探索其在Llama-3.1-8B-Instruct和DeepSeek-R1上的精度影响。

Result: 在16路张量并行部署的DeepSeek-671B上，SnapStream实现了4倍片上内存使用改进，在128k上下文长度下达到1832 tokens/秒，在LongBench-v2、AIME24和LiveCodeBench上引入最小精度下降。

Conclusion: SnapStream是首个在具有静态图和连续批处理的生产推理系统中部署的稀疏KV注意力技术，成功解决了大KV缓存的内存需求问题。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [12] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 提出基于能力的监控方法，用于医疗领域大语言模型的监督，替代传统基于任务的监控方式。


<details>
  <summary>Details</summary>
Motivation: 传统基于任务的监控方法假设模型性能会因数据漂移而下降，但大语言模型并非针对特定任务训练，这种假设不成立。需要一种更适应通用模型特性的监控方法。

Method: 基于能力的监控：围绕模型共享的内部能力（如摘要、推理、翻译、安全防护）组织监控，而非独立评估每个下游任务。

Result: 该方法能够跨任务检测系统性弱点、长尾错误和涌现行为，这些是基于任务的监控可能遗漏的。

Conclusion: 基于能力的监控为医疗领域大语言模型和未来通用人工智能模型提供了可扩展、安全、自适应和协作的监控基础。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [13] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 对miniF2F基准测试中形式化与非形式化陈述进行全面分析，发现现有AI系统在数学奥林匹克竞赛问题上的准确率仅为36%，远低于自动形式化和定理证明文献中报告的97%和69%。通过修正错误和差异，创建了miniF2F-v2，将准确率提升至70%。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统在数学奥林匹克竞赛中从自然语言理解到形式化证明的完整流程性能，发现现有基准测试中存在大量形式化与非形式化陈述之间的差异，影响了准确评估。

Method: 分析miniF2F基准测试中的形式化与非形式化陈述差异，修正所有错误、差异和简化，创建miniF2F-v2数据集，并在修正后的数据集上重新评估完整的定理证明流程。

Result: 原始miniF2F上最佳准确率为36%，修正后的miniF2F-v2上最佳准确率提升至70%，表明基准测试质量对评估结果有显著影响。

Conclusion: 高质量基准测试对于评估形式推理领域进展和诊断自动形式化与定理证明模型的失败与成功模式至关重要，miniF2F-v2数据集有助于更好地评估该领域进展。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [14] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 提出了一种利用多模态大语言模型辅助设计烟花算法的新方法，通过引入关键部分概念扩展烟花算法到复杂高维任务，在旅行商问题和电子设计自动化问题上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在处理非凸、高维、黑箱等复杂优化问题时效率低下且梯度信息不准确，而大语言模型在语言理解和代码生成方面的进步为优化算法设计提供了新思路。

Method: 以烟花算法为基础优化器，结合多模态大语言模型，提出关键部分概念来扩展烟花算法处理复杂高维任务的能力，并利用大语言模型的多模态特性充分挖掘优化过程中的信息。

Result: 实验结果表明，在新框架下生成的烟花算法在多个问题实例上达到或超越了当前最优结果。

Conclusion: 将大语言模型与优化算法结合是解决复杂优化问题的有效途径，提出的方法在旅行商问题和电子设计自动化问题上展现了优越性能。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [15] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 提出一个新颖的LLM安全响应框架，在输入和输出两个层面系统保护大语言模型，通过细粒度风险分类和RAG增强，显著提升安全性和可信度。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，其安全问题日益突出，严重制约了在关键领域的可信部署，需要系统性的安全保障方案。

Method: 输入层采用基于监督微调的安全分类模型，通过四层级分类（安全、不安全、条件安全、专注注意）进行精确风险识别；输出层结合检索增强生成和专门微调的解释模型，确保响应基于可信知识库。

Result: 风险召回率达到99.3%，在公开安全评估基准上显著优于基线模型TinyR1-Safety-8B，在专有高风险测试集上组件获得100%安全分。

Conclusion: 该研究为构建高安全性、高可信度的LLM应用提供了有效的工程路径。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [16] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了一种验证形式化可解释AI（XAI）的新方法，并评估了公开可用的形式化解释器PyXAI，发现其在大多数数据集上产生了错误解释。


<details>
  <summary>Details</summary>
Motivation: 形式化XAI相比非形式化方法具有理论严谨性保证，但对其实际实现的验证关注不足。

Method: 开发了一种验证形式化解释器的新方法，并对PyXAI进行了评估。

Result: 实验发现PyXAI在大多数分析的数据集上计算出了错误的解释。

Conclusion: 验证形式化解释器的重要性得到确认，提出的新验证方法具有必要性。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [17] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 提出一个多智能体AI框架来形式化工程设计过程，通过专门的知识驱动智能体协作生成和优化设计候选方案，并以NACA翼型气动优化为例验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统工程设计方法需要多领域专业知识，导致复杂的协作和迭代优化过程，资源密集且效率低下。

Method: 构建包含三个关键AI智能体的框架：图本体学家使用LLM构建领域知识图谱，系统工程师制定技术要求，设计工程师基于知识图谱和计算工具提出候选设计，形成迭代反馈循环。

Result: 该框架成功应用于4位数NACA翼型的气动优化，通过智能体协作生成并优化设计，最终实现了性能指标如升阻比的最大化。

Conclusion: 研究表明，配备结构化知识表示的协作AI智能体能够提高工程设计过程的效率、一致性和质量。

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [18] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 本文介绍了Summit Concierge，一个为Adobe Summit开发的领域特定AI助手，采用人在回路开发流程，结合提示工程、检索增强和轻量级人工验证，以应对数据稀疏、质量保证和快速部署等现实约束。


<details>
  <summary>Details</summary>
Motivation: 生成式AI助手在企业环境中具有提升生产力、简化信息访问和改善用户体验的潜力，但面临数据稀疏、质量保证和快速部署等现实约束。

Method: 采用人在回路开发流程，结合提示工程、检索增强和轻量级人工验证，构建系统架构并实施敏捷、反馈驱动的开发方法。

Result: 成功开发并部署了Summit Concierge，该助手能够处理广泛的活动相关查询，在冷启动场景下实现了可扩展且可靠的AI助手。

Conclusion: 敏捷、反馈驱动的开发方法能够在冷启动场景下实现可扩展且可靠的AI助手，为类似企业应用提供了可行的开发范式。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [19] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 大型语言模型能够仅从大五人格量表的最小输入中，准确模拟人类心理特质的关联结构，其生成的跨量表相关性模式与人类数据高度一致（R² > 0.89），表现优于基于语义相似度的预测，接近直接在数据集上训练的机器学习算法。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否能够从最小量化输入中建模人类心理特质之间的关联结构，以及它们如何实现这种能力。

Method: 使用816名人类个体的大五人格量表反应提示各种LLMs，让它们模拟在其他9个心理量表上的反应，并分析其推理过程。

Result: LLMs在零样本设置下表现出色，跨量表相关性模式与人类数据高度一致（R² > 0.89），超过了语义相似度预测，接近机器学习算法的性能。分析显示LLMs采用两阶段过程：首先将原始大五反应转化为自然语言人格摘要，然后基于这些摘要推理生成目标量表反应。

Conclusion: LLMs能够通过抽象和推理过程从最小数据中精确预测个体的心理特质，这既为心理模拟提供了强大工具，也为理解其涌现推理能力提供了宝贵见解。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [20] [Towards Scalable Web Accessibility Audit with MLLMs as Copilots](https://arxiv.org/abs/2511.03471)
*Ming Gu,Ziwei Wang,Sicen Lai,Zirui Gao,Sheng Zhou,Jiajun Bu*

Main category: cs.AI

TL;DR: 提出了一个名为AAA的自动化网页可访问性审计框架，通过人类-AI合作模式实现WCAG-EM标准的可扩展执行，包含GRASP采样方法和MaC多模态助手两大创新组件。


<details>
  <summary>Details</summary>
Motivation: 当前网页可访问性审计方法资源密集且难以扩展，大多数网站界面不符合标准，阻碍了数字空间的社会福利、正义和平等发展。

Method: AAA框架包含：1) GRASP - 基于图的多模态采样方法，通过视觉、文本和关系线索的嵌入学习确保代表性页面覆盖；2) MaC - 基于多模态大语言模型的助手，支持跨模态推理和复杂任务智能辅助。

Result: 实验证明该方法有效，提供了四个新数据集用于基准测试，并发现经过微调的小规模语言模型可以作为专家使用。

Conclusion: 该框架实现了可扩展的端到端网页可访问性审计，通过AI增强辅助为人类审计员提供实际影响。

Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice,
and equality in digital spaces, yet the vast majority of website user
interfaces remain non-compliant, due in part to the resource-intensive and
unscalable nature of current auditing practices. While WCAG-EM offers a
structured methodology for site-wise conformance evaluation, it involves great
human efforts and lacks practical support for execution at scale. In this work,
we present an auditing framework, AAA, which operationalizes WCAG-EM through a
human-AI partnership model. AAA is anchored by two key innovations: GRASP, a
graph-based multimodal sampling method that ensures representative page
coverage via learned embeddings of visual, textual, and relational cues; and
MaC, a multimodal large language model-based copilot that supports auditors
through cross-modal reasoning and intelligent assistance in high-effort tasks.
Together, these components enable scalable, end-to-end web accessibility
auditing, empowering human auditors with AI-enhanced assistance for real-world
impact. We further contribute four novel datasets designed for benchmarking
core stages of the audit pipeline. Extensive experiments demonstrate the
effectiveness of our methods, providing insights that small-scale language
models can serve as capable experts when fine-tuned.

</details>


### [21] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 本文对多种机器学习模型中的解释问题进行了参数化复杂性理论分析，重点关注具有透明内部机制的模型。


<details>
  <summary>Details</summary>
Motivation: 填补可解释AI领域的理论空白，为理解生成机器学习模型解释的计算复杂性提供理论基础，推动AI系统的透明度和问责制。

Method: 采用参数化复杂性理论框架，分析决策树、决策集、决策列表、布尔电路及其集成模型中的溯因和对比解释问题（包括局部和全局变体）。

Result: 为不同ML模型的解释问题建立了计算复杂性理论基础，揭示了各种模型在解释生成方面的独特挑战。

Conclusion: 这项工作为XAI领域的进一步研究提供了重要见解，强调了AI系统透明度和问责制的必要性。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>


### [22] [Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](https://arxiv.org/abs/2511.03724)
*Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng*

Main category: cs.AI

TL;DR: Solly是首个在简化版Liar's Poker中达到精英人类水平的AI智能体，使用无模型、演员-评论家深度强化学习算法训练，在单挑和多玩家游戏中均表现出色，并超越了大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在德州扑克等游戏中取得了突破，但这些游戏的多玩家动态较弱，大多数手牌很快收敛为两个玩家参与。研究旨在开发能在具有广泛多玩家参与的Liar's Poker中达到精英水平的AI。

Method: 使用无模型、演员-评论家深度强化学习算法进行自对弈训练。

Result: Solly在胜率（超过50%的手牌获胜）和权益（赢得的资金）方面达到精英人类水平，在单挑和多玩家Liar's Poker中均表现出色，超越了具有推理能力的大型语言模型，开发了新颖的叫牌策略并有效随机化游戏。

Conclusion: Solly证明了深度强化学习能够在具有复杂多玩家动态的游戏中达到精英人类水平，为AI在复杂多玩家环境中的发展提供了重要进展。

Abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [List Decoding and New Bicycle Code Constructions for Quantum LDPC Codes](https://arxiv.org/abs/2511.02951)
*Sheida Rabeti,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 提出了一种用于量子LDPC码的多基置信传播列表解码器(MBBP-LD)，在保持线性时间复杂度的同时显著降低逻辑错误率，并对新型单变量自行车码进行了探索。


<details>
  <summary>Details</summary>
Motivation: 量子LDPC码需要高效的解码器来降低逻辑错误率，同时保持计算效率。现有的BP-OSD解码器虽然性能较好但计算复杂度较高，需要开发在保持线性时间复杂度的同时提升性能的解码方法。

Method: 扩展了经典循环LDPC码的多基置信传播框架到量子领域，并引入新的后处理列表解码器决策规则，替代传统的LMS准则。同时探索了单变量自行车码这一新子类。

Result: 对于[[144,12,12]]双变量自行车码，MBBP-LD解码器相比最先进的BP-OSD解码器实现了高达40%的逻辑错误率降低，同时保持了普通BP解码器的线性时间复杂度。

Conclusion: MBBP-LD解码器为量子LDPC码提供了一种高效且高性能的解码解决方案，在保持线性时间复杂度的同时显著提升了纠错性能，同时单变量自行车码展现了良好的解码潜力。

Abstract: In this paper, we propose a new decoder, called the Multiple-Bases
Belief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check
(QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP)
framework, originally developed for classical cyclic LDPC codes. The proposed
method preserves the linear-time complexity of standard BP decoder while
improving the logical error rate. To further reduce the logical error rate, a
new decision rule is introduced for the post-processing list decoder,
outperforming the conventional least-metric selector (LMS) criterion. For the
recently developed and implemented bivariate bicycle (BB) code with parameters
\([[144,12,12]]\), our proposed MBBP-LD decoder achieves up to 40\% lower
logical error rate compared to the state-of-the-art decoder for short QLDPC
codes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the
linear-time complexity of the plain BP decoder. In addition, we explore a new
subclass of BB codes, that we refer to as the univariate bicycle (UB) codes,
specifically with lower-weight parity checks (\(w=6,8\)). This reduces the
polynomial search space for the code compared to general BB codes, i.e., by
reducing the search space over two polynomial components in BB codes to just a
single polynomial component in UB codes. Simulations demonstrate the promising
performance of these codes under various types of BP decoders.

</details>


### [24] [A Tsallis-Entropy Lens on Genetic Variation](https://arxiv.org/abs/2511.03063)
*Margarita Geleta,Daniel Mas Montserrat,Alexander G. Ioannidis*

Main category: cs.IT

TL;DR: 本文提出了Tsallis q阶F统计量F_q，作为经典F_ST统计量的信息论推广，通过调节q值可以精细分析群体遗传结构中的稀有和常见变异。


<details>
  <summary>Details</summary>
Motivation: 经典F_ST统计量主要基于方差分析，对等位基因频率谱偏斜的情况分析不够精细，需要一种能同时考虑稀有和常见变异的更通用统计量。

Method: 引入Tsallis q熵概念，构建F_q统计量家族，其中q=2对应经典F_ST，q=1对应香农熵版本。通过调节q值，可以分别强调稀有变异(q<1)或常见变异(q>1)。

Result: 在真实数据(865个大洋洲基因组)和模拟数据上的应用表明，F_q在One-vs-Rest和Leave-One-Out模式下能清晰识别驱动区域结构的亚群体，并敏感地检测隔离迁移事件和奠基者效应。

Conclusion: F_q统计量作为F_ST的精细分辨率补充，为模拟验证和群体结构分析提供了更全面的工具，特别适用于等位基因频率谱偏斜的情况。

Abstract: We introduce an information-theoretic generalization of the fixation
statistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the
fraction of Tsallis $q$-entropy lost within subpopulations relative to the
pooled population. The family nests the classical variance-based fixation index
$F_{\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose
absolute form equals the mutual information between alleles and population
labels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights
rare variants at low $q$, while $q{>}1$ increasingly emphasizes common
variants, providing a more fine-grained view of differentiation than
$F_{\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865
Oceanian genomes with 1,823,000 sites) and controlled genealogical simulations
(seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216
sites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes
provides clear attribution of which subpopulations drive regional structure,
and sensitively timestamps isolation-migration events and founder effects.
$F_q$ serves as finer-resolution complement for simulation audits and
population-structure summaries.

</details>


### [25] [DRL-Based Robust Multi-Timescale Anti-Jamming Approaches under State Uncertainty](https://arxiv.org/abs/2511.03305)
*Haoqin Zhao,Zan Li,Jiangbo Si,Rui Huang,Hang Hu,Tony Q. S. Quek,Naofal Al-Dhahir*

Main category: cs.IT

TL;DR: 提出了两种鲁棒抗干扰方案：PGD-DDQN和NQC-DDQN，在存在感知误差的情况下保持抗干扰性能，解决了多时间尺度决策和状态不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有抗干扰方法假设精确感知且忽略异构动作执行延迟不匹配和传感器误差问题，特别是DRL方法对输入扰动敏感，可能导致次优决策。

Method: 建立包含状态不确定性的多时间尺度决策模型，提出PGD-DDQN（使用投影梯度下降进行鲁棒优化）和NQC-DDQN（引入非线性压缩机制消除动作混淆）。

Result: 仿真结果表明，相比完美感知基线，所提算法在抗干扰性能上仅有轻微下降，在各种扰动下保持鲁棒性。

Conclusion: 所提算法在非完美感知条件下具有实用性，验证了其在有界感知误差下的鲁棒性能。

Abstract: Owing to the openness of wireless channels, wireless communication systems
are highly susceptible to malicious jamming. Most existing anti-jamming methods
rely on the assumption of accurate sensing and optimize parameters on a single
timescale. However, such methods overlook two practical issues: mismatched
execution latencies across heterogeneous actions and measurement errors caused
by sensor imperfections. Especially for deep reinforcement learning (DRL)-based
methods, the inherent sensitivity of neural networks implies that even minor
perturbations in the input can mislead the agent into choosing suboptimal
actions, with potentially severe consequences. To ensure reliable wireless
transmission, we establish a multi-timescale decision model that incorporates
state uncertainty. Subsequently, we propose two robust schemes that sustain
performance under bounded sensing errors. First, a Projected Gradient
Descent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which
derives worst-case perturbations under a norm-bounded error model and applies
PGD during training for robust optimization. Second, a Nonlinear Q-Compression
DDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that
adaptively contracts Q-value ranges to eliminate action aliasing. Simulation
results indicate that, compared with the perfect-sensing baseline, the proposed
algorithms show only minor degradation in anti-jamming performance while
maintaining robustness under various perturbations, thereby validating their
practicality in imperfect sensing conditions.

</details>


### [26] [Constacyclic codes with best-known parameters](https://arxiv.org/abs/2511.03323)
*Zekai Chen,Min Sha*

Main category: cs.IT

TL;DR: 本文构造了多个无限族的q元常循环码，这些码在有限域F_q上具有长度n、维度约n/2、最小距离至少为cn/log_q n（c为正常数），包含许多参数最优或接近最优的常循环码。


<details>
  <summary>Details</summary>
Motivation: 研究具有良好参数（特别是最小距离）的常循环码构造，以提供更多最优或接近最优的编码选择。

Method: 通过构造多个无限族的q元常循环码，考虑不同长度n的形式，确保维度约为n/2且最小距离满足特定下界。

Result: 成功构造了多个无限族的常循环码，这些码包含许多参数最优、几乎最优或已知最佳的常循环码实例。

Conclusion: 所构造的常循环码家族在编码理论中具有重要意义，提供了丰富的编码资源，特别是在参数优化方面表现出色。

Abstract: In this paper, we construct several infinite families of $q$-ary constacyclic
codes over a finite field $\mathbb{F}_q$ with length $n$, dimension around
$n/2$, and minimum distance at least $cn/\log_q n$ for some positive constant
$c$. They contain many constacyclic codes with optimal, or almost-optimal, or
best-known parameters. We also consider various forms of the length $n$.

</details>


### [27] [The (+)-(L, P)-TGRS code](https://arxiv.org/abs/2511.03398)
*Zhonghao Liang,Chenlu Jia,Qunying Liao*

Main category: cs.IT

TL;DR: 本文研究了(L,P)-扭曲广义Reed-Solomon码的NMDS性质、非RS性质以及自正交性，部分解决了Hu等人在2025年提出的两个开放问题。


<details>
  <summary>Details</summary>
Motivation: 非Reed-Solomon类型线性码的构造是近年研究热点，Hu等人在2025年通过定义(L,P)-TGRS码构造了非RS MDS码，本文在此基础上深入研究其性质。

Method: 首先给出了码的校验矩阵，然后研究了码的NMDS条件、非RS性质以及自正交性，并通过构造实例验证理论结果。

Result: 给出了C为NMDS码的充要条件，证明了当2k>n时C是非RS码，给出了C不自对偶或不自正交的充分条件，并构造了两类自正交码。

Conclusion: 本文部分解决了Hu等人提出的开放问题，改进了相关结果，并推广了Ding等人的工作，为构造非RS码提供了新的理论支撑。

Abstract: The construction of the non-Reed-Solomon (in short, non-RS) type linear code
has been one of the research hotspots in recent years. In 2025, Hu et al.
constructed some non-RS MDS codes by defining the (L, P)-twisted generalized
Reed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the
(+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we
give a sufficient and necessary condition for C to be NMDS which partially
answers two open problems proposed by Hu et al. in 2025, and prove that C is
non-RS for 2k > n which partially improves the corresponding result given by Hu
et al. in 2025,. Thirdly, we give a sufficient condition for C not to be
self-dual or self-orthogonal, respectively, furthermore, we construct two
classes of self-orthogonal codes which is a promotion of the corresponding
result given by Ding et al. in 2025. Finally, some examples are given.

</details>


### [28] [On the Fundamental Scaling Laws of Fluid Antenna Systems](https://arxiv.org/abs/2511.03415)
*Xusheng Zhu,Farshad Rostami Ghadi,Tuo Wu,Kaitao Meng,Chao Wang,Gui Zhou*

Main category: cs.IT

TL;DR: 本文首次建立了流体天线系统在空间相关信道下的符号错误率基本缩放定律，揭示了天线移动空间扩展对性能提升的关键作用。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统利用空间分集增强无线通信，但缺乏严格的错误概率分析框架，需要建立基本缩放定律来指导系统设计。

Method: 推导了适用于通用调制方案的紧致闭式渐近符号错误率表达式，建立了符号错误率与信道空间相关结构的基本缩放关系。

Result: 完全表征了分集增益和编码增益，发现扩展天线移动空间可显著改善符号错误率，而仅在受限空间内增加端口密度收益递减。

Conclusion: 系统设计的关键指导原则是扩展天线移动空间以增加分集，而不是在受限空间内单纯增加端口密度。

Abstract: Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless
communication by exploiting spatial diversity, yet a rigorous analytical
framework for their error probability has been notably absent. To this end,
this paper addresses this critical gap by unveiling the \textbf{fundamental
scaling laws} that govern the symbol error rate (SER) of FAS in realistic,
spatially correlated channels. To establish these laws, we derive a tight,
closed-form asymptotic expression for the SER applicable to a general class of
modulation schemes. This result is pivotal as it establishes the fundamental
scaling law governing the relationship between SER and the channel's spatial
correlation structure. Based on this framework, we provide a complete
characterization of the diversity and coding gains. The analysis culminates in
a definitive design directive: SER can be fundamentally improved by expanding
the antenna's movement space to increase diversity, while merely increasing
port density within a constrained space yields diminishing returns.

</details>


### [29] [Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility Environments](https://arxiv.org/abs/2511.03632)
*Cemil Vahapoglu,Timothy J. O'Shea,Wan Liu,Sennur Ulukus*

Main category: cs.IT

TL;DR: 提出了一种基于多普勒感知的稀疏神经网络波束成形模型，在MU-SIMO系统中通过通道自适应稀疏注意力机制，在高移动性场景下显著优于传统波束成形方法和固定模式稀疏方法。


<details>
  <summary>Details</summary>
Motivation: 传统波束成形方法在恶劣信道条件下性能下降，而现有Transformer模型由于二次注意力复杂度难以扩展到大型OFDM网格，且稀疏注意力模式未考虑无线通信特有的信道动态特性。

Method: 提出Doppler-aware Sparse NNBF模型，在MU-SIMO设置中采用通道自适应稀疏注意力机制，该稀疏结构可沿2D时频轴根据信道动态配置，理论上保证在p个注意力头内实现全连接。

Result: 在UMa信道条件下的仿真结果表明，该模型在高移动性场景下显著优于标准稀疏NNBF基线以及传统ZFBF和MMSE波束成形方法，同时保持结构化稀疏性和可控的每个查询关注键数量。

Conclusion: 所提出的多普勒感知稀疏神经网络波束成形模型能够有效应对高移动性场景，在保持计算效率的同时显著提升性能，为动态信道环境下的波束成形提供了有效解决方案。

Abstract: Beamforming has significance for enhancing spectral efficiency and mitigating
interference in multi-antenna wireless systems, facilitating spatial
multiplexing and diversity in dense and high mobility scenarios. Traditional
beamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean
square error (MMSE) beamforming experience performance deterioration under
adverse channel conditions. Deep learning-based beamforming offers an
alternative with nonlinear mappings from channel state information (CSI) to
beamforming weights by improving robustness against dynamic channel
environments. Transformer-based models are particularly effective due to their
ability to model long-range dependencies across time and frequency. However,
their quadratic attention complexity limits scalability in large OFDM grids.
Recent studies address this issue through sparse attention mechanisms that
reduce complexity while maintaining expressiveness, yet often employ patterns
that disregard channel dynamics, as they are not specifically designed for
wireless communication scenarios. In this work, we propose a Doppler-aware
Sparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that
incorporates a channel-adaptive sparse attention mechanism in a multi-user
single-input multiple-output (MU-SIMO) setting. The proposed sparsity structure
is configurable along 2D time-frequency axes based on channel dynamics and is
theoretically proven to ensure full connectivity within p hops, where p is the
number of attention heads. Simulation results under urban macro (UMa) channel
conditions show that Doppler-aware Sparse NNBF significantly outperforms both a
fixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional
beamforming techniques ZFBF and MMSE beamforming in high mobility scenarios,
while maintaining structured sparsity with a controlled number of attended keys
per query.

</details>
