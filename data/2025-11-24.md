<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Performance Comparison of 5G NR Uplink MIMO and Uplink Carrier Aggregations on Commercial Network](https://arxiv.org/abs/2511.16751)
*Henry Shao,Kasidis Arunruangsirilert*

Main category: cs.NI

TL;DR: 评估T-Mobile 5G网络中UL-MIMO和UL-CA的上行吞吐量性能，发现UL-MIMO在大多数场景下吞吐量较低，但在强RF条件下可提供足够用户体验，建议将UL-CA保留给弱RF条件的用户设备。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体、4K/8K内容创作、物联网应用和FWA宽带的快速发展，移动网络上行需求不断增加，UL-MIMO和UL-CA首次在商用5G网络中广泛部署，需要评估其实际性能。

Method: 在商用T-Mobile 5G网络上，在不同RF环境和交通模式下评估UL-MIMO和UL-CA的上行吞吐量性能。

Result: 即使有效率增益，UL-MIMO在大多数场景下产生较慢的上行吞吐量，但在强RF条件下可提供足够的用户体验。

Conclusion: UL-MIMO在强RF条件下表现良好，建议将容量更大的UL-CA保留给弱RF条件的用户设备以优化网络资源分配。

Abstract: Demands for uplink on mobile networks are increasing with the rapid development of social media platforms, 4K/8K content creation, IoT applications, and Fixed Wireless Access (FWA) broadband. As a result, Uplink MIMO (UL-MIMO) and Uplink Carrier Aggregation (UL-CA) have been widely deployed for the first time on commercial 5G networks. UL-MIMO enables the transmission of two data streams on one frequency band in strong RF conditions, theoretically doubling throughput and efficiency. On the other hand, UL-CA allows for simultaneous upload on greater channel widths, allowing more resources to be assigned to a single UE for higher throughput. In the United States, T-Mobile USA, a mobile network operator (MNO), has deployed network-wide 5G Standalone (SA), along with UL-MIMO on Time Division Duplex (TDD) band n41 and UL-CA between TDD and Frequency Division Duplex (FDD) NR bands. In this paper, the uplink throughput performance of UL-MIMO and UL-CA will be evaluated on the commercial T-Mobile 5G network on a variety of RF environments and modes of transportation. It was found that, even with the efficiency gains, UL-MIMO yields slower uplink throughput in most scenarios. However, in stronger RF conditions, UL-MIMO can provide an adequate user experience, so capacity can be conserved by reserving UL-CA for UE in weaker RF conditions.

</details>


### [2] [A streaming algorithm and hardware accelerator for top-K flow detection in network traffic](https://arxiv.org/abs/2511.16797)
*Carolina Gallardo-Pavesi,Yaime Fernández,Javier E. Soto,Cecilia Hernández,Miguel Figueroa*

Main category: cs.NI

TL;DR: 提出了一种基于改进TowerSketch和优先级队列阵列的top-K流识别算法，在真实流量追踪中实现高精度识别和频率估计，并在FPGA上实现高速处理。


<details>
  <summary>Details</summary>
Motivation: 网络流量中识别最大K个流对于流量调度和异常检测很重要，但由于流量数量大、网络速度快，准确估计流频率具有挑战性。硬件加速器受限于片上内存容量，现有草图算法在偏斜分布流量下性能不佳。

Method: 使用改进的TowerSketch和优先级队列阵列进行top-K流识别，在FPGA上设计并实现加速器，每周期处理一个数据包。

Result: 在真实流量追踪中，识别top-K流（K最多32,768）的精度超过0.94，频率估计的平均相对误差低于1.96%。FPGA实现处理频率达392MHz，最小线速率超过200Gbps。

Conclusion: 提出的算法和硬件实现能够高效准确地识别网络流量中的top-K流，满足高速网络环境下的性能需求。

Abstract: Identifying the largest K flows in network traffic is an important task for applications such as flow scheduling and anomaly detection, which aim to improve network efficiency and security. However, accurately estimating flow frequencies is challenging due to the large number of flows and increasing network speeds. Hardware accelerators are often used in this endeavor due to their high computational power, but their limited amount of on-chip memory constrains their performance. Various sketch-based algorithms have been proposed to estimate properties of traffic such as frequency, with lower memory usage and theoretical bounds, but they often under perform with the skewed distribution of network traffic. In this work, we propose an algorithm for top-K identification using a modified TowerSketch and a priority queue array. Tested on real traffic traces, we identify the top-K flows, with K up to 32,768, with a precision of more than 0.94, and estimate their frequency with an average relative error under 1.96%. We designed and implemented an accelerator for this algorithm on an AMD VirtexU280 UltraScale+ FPGA, which processes one packet per cycle at392 MHz, reaching a minimum line rate of more than 200 Gbps.

</details>


### [3] [Adaptive Receiver-Side Scheduling for Smooth Interactive Delivery](https://arxiv.org/abs/2511.16902)
*Michael Luby*

Main category: cs.NI

TL;DR: 提出了一种轻量级接收端调度方法，通过自适应估计有效路径延迟并调整释放时间，消除网络延迟变化导致的抖动和卡顿，保持平滑播放。


<details>
  <summary>Details</summary>
Motivation: 交互式应用如云游戏、XR流媒体和实时推理需要数据对象以稳定节奏到达，但网络延迟变化和接收端恢复动态会破坏这种节奏，导致可见的抖动、卡顿和不稳定播放。

Method: 接收端调度器维护自适应有效路径延迟估计，非对称调整释放时间（快速响应延迟到达，缓慢响应提前到达），采用上包络行为保持释放与最近延迟峰值对齐，无需反馈或同步。

Result: 在云游戏工作负载评估中，调度器几乎消除了所有大的抖动偏移，产生紧密聚集的释放间隔，改善了视觉平滑度。完整的BRT覆盖层带来了更广泛的延迟改进。

Conclusion: 接收端调度可以模块化集成到TCP、QUIC、WebRTC、UDP或RTP等传输协议栈中，是未来工作的自然部署点。

Abstract: Interactive applications such as cloud gaming, XR streaming, and real-time inference depend on data objects arriving at a steady cadence. In practice, network delay variation and recovery dynamics at the receiver distort this cadence even when transports deliver all packets correctly, which produces visible jitter, stalls, and unstable playback.
  We present a lightweight receiver-side scheduling approach that regularizes release timing after recovery. The scheduler maintains an adaptive estimate of effective path delay and adjusts release times asymmetrically, responding quickly to late arrivals and only gradually to early ones. This upper-envelope behavior keeps release aligned with recent delay peaks and maintains smooth playback with minimal added latency. The scheduler runs entirely on the receiver clock and requires no feedback or synchronization.
  As a concrete example, we integrate receiver-side scheduling into the BitRipple Tunnel (BRT) overlay, an application-layer software system that forwards traffic without altering the underlying transport protocol. Within BRT, the scheduler functions as an independent module that regulates delivery timing for forwarded objects.
  Evaluating BRT with receiver-side scheduling on a cloud-gaming workload shows that the scheduler removes virtually all large jitter excursions and yields tightly clustered release intervals that improve visible smoothness. Broader latency improvements arise from the behavior of the full BRT overlay. Receiver-side scheduling can also be integrated modularly into transport stacks such as TCP, QUIC, WebRTC, UDP, or RTP, which are natural deployment points for future work.

</details>


### [4] [One Walk is All You Need: Data-Efficient 3D RF Scene Reconstruction with Human Movements](https://arxiv.org/abs/2511.16966)
*Yiheng Bian,Zechen Li,Lanqing Yang,Hao Pan,Yezhou Wang,Longyuan Ge,Jeffery Wu,Ruiheng Liu,Yongjian Fu,Yichao chen,Guangtao xue*

Main category: cs.NI

TL;DR: 提出一种新范式，通过单次短暂的人类行走来快速、高效地重建被遮挡的3D静态场景的辐射场，将人类运动视为信息丰富的信号而非噪声。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要数千次静态测量，将人类运动视为需要过滤的噪声，数据采集过程繁琐。本文旨在利用人类运动作为重建信号，解决数据采集瓶颈。

Method: 设计基于复合3D高斯泼溅的因子化框架，从原始辐射流中学习建模人类运动的动态效应和静态场景几何。

Result: 仅用60秒的随意行走训练，模型重建的静态场景结构相似性指数达0.96，比需要大量采样的最先进方法高出12%。

Conclusion: 通过将人类运动转化为有价值信号，该方法消除了数据采集瓶颈，为实时3D辐射场映射开辟了新途径。

Abstract: Reconstructing 3D Radiance Field (RF) scenes through opaque obstacles is a long-standing goal, yet it is fundamentally constrained by a laborious data acquisition process requiring thousands of static measurements, which treats human motion as noise to be filtered. This work introduces a new paradigm with a core objective: to perform fast, data-efficient, and high-fidelity RF reconstruction of occluded 3D static scenes, using only a single, brief human walk. We argue that this unstructured motion is not noise, but is in fact an information-rich signal available for reconstruction. To achieve this, we design a factorization framework based on composite 3D Gaussian Splatting (3DGS) that learns to model the dynamic effects of human motion from the persistent static scene geometry within a raw RF stream. Trained on just a single 60-second casual walk, our model reconstructs the full static scene with a Structural Similarity Index (SSIM) of 0.96, remarkably outperforming heavily-sampled state-of-the-art (SOTA) by 12%. By transforming the human movements into its valuable signals, our method eliminates the data acquisition bottleneck and paves the way for on-the-fly 3D RF mapping of unseen environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Stable diffusion models reveal a persisting human and AI gap in visual creativity](https://arxiv.org/abs/2511.16814)
*Silvia Rondini,Claudia Alvarez-Martin,Paula Angermair-Barkai,Olivier Penacchio,M. Paz,Matthew Pelowski,Dan Dediu,Antoni Rodriguez-Fornells,Xim Cerda-Company*

Main category: cs.AI

TL;DR: 研究发现人类视觉艺术家最具创造力，其次是普通人，然后是受人类启发生成AI，最后是自主生成AI。人类指导显著提升AI创造力，但人类与AI评估者在创造力判断上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索视觉创造力领域，比较人类与AI在图像生成任务中的表现差异，特别是在语言模型已展现创造力的背景下，视觉领域的独特性值得研究。

Method: 比较人类参与者（视觉艺术家和普通人）与图像生成AI模型（两种提示条件：高人类输入的人类启发条件和低人类输入的自主指导条件），由255名人类评估者和GPT4o评估生成图像的创造力。

Result: 发现清晰的创造力梯度：视觉艺术家>普通人>人类启发生成AI>自主生成AI。人类指导显著提升AI创造力输出，使其接近普通人水平。人类与AI评估者在创造力判断上存在显著差异。

Conclusion: 与语言中心任务不同，生成AI模型在视觉领域面临独特挑战，因为视觉创造力依赖于感知细微差别和上下文敏感性，这些是人类特有的能力，可能难以从语言模型直接迁移。

Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.

</details>


### [6] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: Cognitive BASIC是一种基于BASIC风格的提示语言和模型内解释器，将大语言模型的推理过程结构化为显式的逐步执行轨迹，通过编号行和简单命令作为可解释的认知控制层。


<details>
  <summary>Details</summary>
Motivation: 受复古BASIC简单性的启发，旨在为LLM推理提供透明、可解释的多步推理框架，使模型能够可靠地模拟短程序执行。

Method: 设计了一个自然语言解释器文件来指定命令语义、内存更新和日志行为，通过心理模型解释器提取声明性和程序性知识，检测矛盾并在必要时产生解决方案。

Result: 在三个LLM上的基准测试显示，所有模型都能执行Cognitive BASIC程序，整体表现强劲但性能不均。

Conclusion: Cognitive BASIC为LLM推理提供了有效的结构化方法，实现了透明可解释的多步推理，在不同模型上展现出良好的适用性。

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [7] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出了一个系统性的基准测试修订框架，通过分析响应模式的统计特征来标记可能无效的问题，供专家进一步审查，从而高效识别和修正基准测试中的问题。


<details>
  <summary>Details</summary>
Motivation: 基准测试在推动AI进步中至关重要，但无效的基准问题经常破坏其可靠性。手动识别和修正数千个基准问题中的错误既不可行，也是可靠评估的关键瓶颈。

Method: 基于AI评估中常用的核心假设——平均分足以概括模型性能，该方法假设存在一个单维潜在结构，为每个项目生成各种统计量的预期范围。当这些统计量的经验估计值超出预期范围时，该项目更可能存在问题。

Result: 在九个广泛使用的基准测试中，该方法指导专家审查识别问题问题的精度高达84%。此外，引入了LLM-judge初步审查问题，进一步减少了人工工作量。

Conclusion: 这些组件共同提供了一个高效且可扩展的系统性基准测试修订框架，能够显著提高基准测试的可靠性。

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


### [8] [Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving](https://arxiv.org/abs/2511.16916)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 提出混合差分奖励机制解决多车协同驾驶中传统状态奖励函数因奖励差异消失导致的低信噪比问题，显著提升算法收敛速度和策略稳定性


<details>
  <summary>Details</summary>
Motivation: 多车协同驾驶任务中，传统基于状态的奖励函数存在奖励差异消失问题，导致策略梯度的信噪比过低，严重影响算法收敛和性能提升

Method: 提出混合差分奖励机制，包含两个互补组件：基于全局势函数的时序差分奖励和直接衡量动作边际效用的动作梯度奖励，并在具有时变智能体集的多智能体部分可观测马尔可夫博弈框架中实现

Result: 在线规划和多智能体强化学习算法的广泛实验表明，HDR机制显著提高了收敛速度和策略稳定性，引导智能体学习到能有效平衡交通效率和安全的高质量协同策略

Conclusion: HDR机制通过整合时序差分奖励和动作梯度奖励，成功解决了多车协同驾驶中的奖励信号问题，为高频率连续控制任务提供了有效的解决方案

Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.

</details>


### [9] [Comparing verbal, visual and combined explanations for Bayesian Network inferences](https://arxiv.org/abs/2511.16961)
*Erik P. Nyberg,Steven Mascaro,Ingrid Zukerman,Michael Wybrow,Duc-Minh Vo,Ann Nicholson*

Main category: cs.AI

TL;DR: 本文设计了贝叶斯网络界面的语言和视觉扩展，通过用户研究发现这些扩展能帮助用户更好地理解推理过程，且语言和视觉结合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管贝叶斯网络被认为是透明模型，但用户仍难以理解其推理过程，现有用户界面未能有效澄清贝叶斯网络的推理机制。

Method: 设计了语言和视觉扩展来增强标准贝叶斯网络界面，通过用户研究比较了语言扩展、视觉扩展、组合扩展与基线界面的效果。

Result: 用户在所有三种扩展界面上的表现均优于基线界面，特别是在观察影响、影响路径和多观察交互方面；语言和视觉组合在某些问题类型上优于单一模式。

Conclusion: 语言和视觉扩展能有效提升用户对贝叶斯网络推理的理解，组合使用两种模式效果最好。

Abstract: Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.
  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.

</details>


### [10] [MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists](https://arxiv.org/abs/2511.16997)
*Qingbin Zeng,Bingbing Fan,Zhiyu Chen,Sijian Ren,Zhilun Zhou,Xuhua Zhang,Yuanyi Zhen,Fengli Xu,Yong Li,Tie-Yan Liu*

Main category: cs.AI

TL;DR: MirrorMind是一个分层认知架构，通过整合双记忆表示来解决AI科学家在科学发现中的局限性，将个体认知轨迹与集体学科记忆相结合，实现结构化的科学推理。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学方法将科学发现视为孤立的优化过程，忽视了知识生产的社会性和历史性本质。人类科学洞察来自个体认知轨迹和集体学科记忆两个相互关联的来源，而现有LLM难以表示这些结构化的认知和社会背景。

Method: 引入三层框架的MirrorMind架构：个体层构建研究者的认知模型（情景、语义和人格记忆）；领域层将集体知识映射为结构化学科概念图；跨学科层作为正交编排引擎。该架构将记忆存储与智能执行分离。

Result: 在四个综合任务中评估MirrorMind，包括作者级认知模拟、互补推理、跨学科协作促进和多智能体科学问题解决。结果显示MirrorMind超越了简单事实检索，实现了结构化、个性化和洞察生成的科学推理。

Conclusion: 通过整合个体认知深度与集体学科广度，MirrorMind能够实现更接近人类科学思维的结构化、个性化科学推理，为AI科学家的发展提供了新的方向。

Abstract: The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.

</details>


### [11] [Budget-Aware Tool-Use Enables Effective Agent Scaling](https://arxiv.org/abs/2511.17006)
*Tengxiao Liu,Zifeng Wang,Jin Miao,I-Hung Hsu,Jun Yan,Jiefeng Chen,Rujun Han,Fangyuan Xu,Yanfei Chen,Ke Jiang,Samira Daruki,Yi Liang,William Yang Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 本文研究了在明确工具调用预算约束下如何有效扩展工具增强智能体，提出了预算追踪器和BATS框架，使智能体具备预算意识并动态调整策略，改善了成本-性能的扩展曲线。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强智能体在扩展工具调用预算时缺乏预算意识，导致性能很快达到瓶颈。本文旨在解决在明确预算约束下如何有效扩展智能体的问题。

Method: 提出了预算追踪器（轻量级插件）提供持续的预算意识，并开发了BATS框架，利用预算意识动态调整规划和验证策略，决定是深入挖掘有希望的线索还是转向新路径。

Result: 预算感知方法产生了更有利的扩展曲线，推动了成本-性能的帕累托前沿，提供了对工具增强智能体扩展的更透明和原则性理解。

Conclusion: 预算意识对于工具增强智能体的有效扩展至关重要，本文提出的方法为理解智能体在预算约束下的扩展行为提供了系统性的实证见解。

Abstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only "thinking" in tokens but also "acting" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack "budget awareness" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to "dig deeper" on a promising lead or "pivot" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.

</details>


### [12] [DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing](https://arxiv.org/abs/2511.17038)
*Hao Chen,Renzheng Zhang,Scott S. Howard*

Main category: cs.AI

TL;DR: 论文重新解释了扩散模型在逆问题求解中的作用，将其视为EM框架中的初始化阶段，提出了DAPS++方法，通过解耦扩散阶段和数据驱动优化来提高计算效率和重建性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于分数的扩散方法在解决逆问题时，先验提供的指导有限，重建主要由测量一致性项驱动，导致推理过程与扩散动力学基本解耦。需要澄清这种结构并改进方法。

Method: 将扩散重新解释为EM框架中的初始化阶段，提出DAPS++方法，让似然项更直接地指导推理，同时保持数值稳定性，减少函数评估次数和测量优化步骤。

Result: DAPS++实现了高计算效率和鲁棒的重建性能，在多种图像恢复任务中表现优异，需要的函数评估次数更少。

Conclusion: 扩散在逆问题求解中的主要作用是提供初始化，DAPS++通过解耦扩散和数据驱动优化，实现了更高效的推理过程，解释了为什么统一的扩散轨迹在实践中仍然有效。

Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.

</details>


### [13] [Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks](https://arxiv.org/abs/2511.17056)
*Paloma Rabaey,Adrick Tench,Stefan Heytens,Thomas Demeester*

Main category: cs.AI

TL;DR: 提出了一种多模态患者信息提取方法，结合结构化表格特征（使用贝叶斯网络）和临床文本数据（使用神经网络分类器），通过虚拟证据和一致性节点实现可解释的概率融合。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中既有结构化信息也有非结构化文本信息，需要整合这两种数据源来构建透明的临床决策支持系统。

Method: 使用专家指导的贝叶斯网络处理表格特征，神经网络分类器处理临床文本，通过虚拟证据和一致性节点进行概率融合。

Result: 在SimSUM模拟数据集上验证了方法的有效性，一致性节点相比单独使用虚拟证据能改善预测校准度。

Conclusion: 该方法能够处理缺失信息并解决表格和文本数据之间的矛盾，为临床决策支持提供可解释的多模态信息提取方案。

Abstract: Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.

</details>


### [14] [The Belief-Desire-Intention Ontology for modelling mental reality and agency](https://arxiv.org/abs/2511.17162)
*Sara Zuppiroli,Carmelo Fabio Longo,Anna Sofia Lippolis,Rocco Paolillo,Lorenzo Giammei,Miguel Ceriani,Francesco Poggi,Antonio Zinilli,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: 本文提出了一个形式化的BDI本体论，作为模块化本体设计模式，用于表示智能体的信念、欲望和意图认知架构，并通过与LLMs结合和Semas推理平台集成验证了其应用价值。


<details>
  <summary>Details</summary>
Motivation: BDI模型在人工智能和认知科学中是表示理性智能体的基石，但其与结构化、语义可互操作的知识表示的整合仍然有限，需要建立形式化的本体论来支持认知架构的语义精确性和可重用性。

Method: 设计了一个模块化的BDI本体论模式，与基础本体对齐确保语义精确性；通过两种实验验证：(1) 与大型语言模型结合使用逻辑增强生成评估本体基础对推理一致性的贡献；(2) 在Semas推理平台中集成，实现RDF三元组与智能体心理状态的双向转换。

Result: BDI本体论能够作为概念和操作桥梁，连接声明性和程序性智能，支持认知基础、可解释且语义可互操作的多智能体和神经符号系统在数据网络中的运行。

Conclusion: 该BDI本体论为构建认知基础、可解释且语义可互操作的多智能体系统提供了重要基础，促进了声明性智能与程序性智能的融合。

Abstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.

</details>


### [15] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: 提出MIR方法解决多智能体强化学习中稀疏奖励问题，通过激励智能体探索影响队友的动作来促进团队探索


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，联合动作轨迹的指数级稀疏性和现有方法未能考虑影响团队状态的联合动作是主要挑战

Method: 提出相互内在奖励(MIR)方法，激励个体智能体探索影响队友的动作，结合原始策略促进团队探索

Result: 在扩展的MiniGrid-MA环境中验证，相比最先进方法表现出更优性能

Conclusion: MIR是一种简单有效的增强策略，能显著改善稀疏奖励场景下的多智能体强化学习性能

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


### [16] [Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism](https://arxiv.org/abs/2511.17198)
*Kaiyu Li,Jiayu Wang,Zhi Wang,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.AI

TL;DR: 提出了基于分层任务抽象机制(HTAM)的多智能体框架EarthAgent，专门解决遥感等专业领域中结构化工作流程的挑战，显著优于现有的单智能体和多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体框架在需要严格结构化工作流程的专业领域（如遥感）表现不佳，这些领域需要专业工具和多步骤程序，挑战了通用方法。

Method: 引入分层任务抽象机制(HTAM)，将多智能体系统构建为反映领域内在任务依赖关系的逻辑层次结构，通过任务中心架构确保程序正确性，将复杂问题分解为顺序层。

Result: 构建了EarthAgent系统并在GeoPlan-bench基准测试中评估，实验表明EarthAgent在工具选择、路径相似性和逻辑完整性方面显著优于现有系统。

Conclusion: 将智能体架构与领域内在任务结构对齐是构建稳健可靠的专业自治系统的关键步骤。

Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.

</details>


### [17] [Agentifying Agentic AI](https://arxiv.org/abs/2511.17332)
*Virginia Dignum,Frank Dignum*

Main category: cs.AI

TL;DR: 本文主张将AAMAS社区开发的BDI架构、通信协议、机制设计和制度建模等概念工具作为实现智能AI系统的基础，通过将自适应数据驱动方法与结构化推理协调模型相结合，构建具有透明度、合作性和问责性的智能系统。


<details>
  <summary>Details</summary>
Motivation: 为了实现智能AI系统的持续自主性、推理和交互能力，需要补充关于智能体的假设，并建立明确的认知、合作和治理模型。

Method: 利用AAMAS社区开发的概念工具，包括BDI架构、通信协议、机制设计和制度建模，将自适应数据驱动方法与结构化推理协调模型相结合。

Result: 提出了一个连接形式理论和实践自主性的智能体视角，为构建不仅能力强且灵活，而且透明、合作和可问责的智能系统指明了路径。

Conclusion: AAMAS社区的概念工具为智能AI系统提供了必要的基础，通过整合自适应方法和结构化模型，可以实现真正具有智能特性的系统。

Abstract: Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.

</details>


### [18] [That's not natural: The Impact of Off-Policy Training Data on Probe Performance](https://arxiv.org/abs/2511.17408)
*Nathalie Kirch,Samuel Dower,Adrians Skapars,Ekdeep Singh Lubana,Dmitrii Krasheninnikov*

Main category: cs.AI

TL;DR: 评估使用合成和离策略数据对LLM行为探测泛化能力的影响，发现响应生成策略显著影响探测性能，离策略数据到在线策略数据的成功泛化可预测真实监控场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 由于许多行为的自然示例稀少，研究者不得不依赖合成或离策略的LLM响应来训练探测模型，需要系统评估这些数据对探测泛化能力的影响。

Method: 在八种不同的LLM行为上测试线性和注意力探测模型，使用不同响应生成策略的数据训练，评估从离策略数据到在线策略数据的泛化能力。

Result: 响应生成策略显著影响探测性能，成功从离策略数据泛化到测试集的行为可预测在线策略泛化成功；欺骗和沙袋探测可能无法从离策略泛化到在线策略数据；训练数据域的变化导致更大的性能下降。

Conclusion: 在没有在线策略数据的情况下，使用同域的离策略数据比使用不同域的在线策略数据产生更可靠的探测，强调需要能更好处理LLM监控中分布偏移的方法。

Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

</details>


### [19] [SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception](https://arxiv.org/abs/2511.17461)
*Jiaxi Liu,Chengyuan Ma,Hang Zhou,Weizhe Tang,Shixiao Liang,Haoyang Ding,Xiaopeng Li,Bin Ran*

Main category: cs.AI

TL;DR: 提出了SRA-CP框架，通过风险感知的选择性协作感知，在保持安全关键物体检测精度的同时，大幅减少通信带宽使用


<details>
  <summary>Details</summary>
Motivation: 解决现有协作感知方法传输大量无关感知数据导致通信带宽不足，以及依赖预定义通信伙伴不适应动态交通环境的问题

Method: 采用去中心化协议，车辆持续广播轻量级感知覆盖摘要，仅在检测到风险相关盲区时启动针对性协作；包含感知风险识别模块和选择性信息交换融合模块

Result: 在公共数据集上评估，相比通用协作感知方法，安全关键物体检测精度损失小于1%，通信带宽使用仅为20%；相比现有选择性协作感知方法，感知性能提升15%

Conclusion: SRA-CP框架有效解决了协作感知中的通信带宽和动态环境适应性问题，实现了高效的风险感知选择性协作

Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [20] [Functional uniqueness and stability of Gaussian priors in optimal L1 estimation](https://arxiv.org/abs/2511.16864)
*Leighton Barnes,Alex Dytso*

Main category: cs.IT

TL;DR: 本文研究了高斯先验在最优L1估计中的函数唯一性和稳定性，建立了定量稳定性理论，证明高斯分布是唯一稳定的解。


<details>
  <summary>Details</summary>
Motivation: 虽然已知高斯先验在高斯噪声下唯一诱导线性条件均值，但对于条件中位数（绝对误差损失下的最优估计器）的类似问题最近才解决。本文基于这一唯一性结果，研究近似线性最优估计器如何约束先验分布。

Method: 对于L2损失，推导显式速率显示条件均值的近线性意味着先验在Lévy度量下接近高斯分布；对于L1损失，引入Hermite展开框架并分析线性定义算子的伴随算子。

Result: 证明了高斯分布在L1损失下仍然是唯一稳定的解，并建立了定量稳定性理论。

Conclusion: 这些结果为高斯噪声下贝叶斯估计中的线性和稳定性提供了更完整的函数分析理解。

Abstract: This paper studies the functional uniqueness and stability of Gaussian priors in optimal $L^1$ estimation. While it is well known that the Gaussian prior uniquely induces linear conditional means under Gaussian noise, the analogous question for the conditional median (i.e., the optimal estimator under absolute-error loss) has only recently been settled. Building on the prior work establishing this uniqueness, we develop a quantitative stability theory that characterizes how approximate linearity of the optimal estimator constrains the prior distribution. For $L^2$ loss, we derive explicit rates showing that near-linearity of the conditional mean implies proximity of the prior to the Gaussian in the Lévy metric. For $L^1$ loss, we introduce a Hermite expansion framework and analyze the adjoint of the linearity-defining operator to show that the Gaussian remains the unique stable solution. Together, these results provide a more complete functional-analytic understanding of linearity and stability in Bayesian estimation under Gaussian noise.

</details>


### [21] [The Star Product of Uniformly Random Codes](https://arxiv.org/abs/2511.17236)
*Johan V. Dinesen,Ragnar Freij-Hollanti,Camilla Hollanti,Benjamin Jany,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 本文研究了两个随机线性码星积的期望维度问题，通过建立星积与双线性形式评估的对应关系，给出了期望星积维度的下界，并证明在域大小和码维渐近情况下期望维度达到最大值。


<details>
  <summary>Details</summary>
Motivation: 研究随机线性码星积的期望维度对于理解码的组合性质及其在私密信息检索、安全分布式矩阵乘法、量子纠错等应用中的表现具有重要意义。

Method: 通过建立星积与双线性形式评估的对应关系，分析随机线性码的星积维度，并给出期望维度的下界。

Result: 证明了在域大小q和两个码的维度渐近情况下，期望星积维度达到最大值，并讨论了相关应用意义。

Conclusion: 该研究为随机线性码星积的维度分析提供了理论框架，在多个应用领域具有潜在价值，包括密码分析的可能性利用。

Abstract: We consider the problem of determining the expected dimension of the star product of two uniformly random linear codes that are not necessarily of the same dimension. We achieve this by establishing a correspondence between the star product and the evaluation of bilinear forms, which we use to provide a lower bound on the expected star product dimension. We show that asymptotically in both the field size q and the dimensions of the two codes, the expected dimension reaches its maximum. Lastly, we discuss some implications related to private information retrieval, secure distributed matrix multiplication, quantum error correction, and the potential for exploiting the results in cryptanalysis.

</details>


### [22] [Structured Approximation of Toeplitz Matrices and Subspaces](https://arxiv.org/abs/2511.17239)
*Albert Fannjiang,Weilin Li*

Main category: cs.IT

TL;DR: 本文研究了两个结构化逼近问题：恢复损坏的低秩Toeplitz矩阵和从单次观测中恢复傅里叶矩阵的范围。通过应用Gradient-MUSIC算法，可以高效且最优地解决这两个计算难题。


<details>
  <summary>Details</summary>
Motivation: Toeplitz矩阵恢复和傅里叶矩阵范围恢复是计算上具有挑战性的问题，因为结构约束难以直接强制执行。需要找到高效的算法来解决这些结构化逼近问题。

Method: 使用Gradient-MUSIC算法进行谱估计。对于满足正则性假设的秩r Toeplitz矩阵，在受到任意噪声矩阵E破坏的情况下，算法输出精确秩为r的Toeplitz矩阵估计。

Result: 算法输出的Toeplitz矩阵估计满足‖T-Ť‖₂ ≤ C√r‖E‖₂，其中C,α>0是绝对常数。该性能保证在n和‖E‖₂方面是极小极大最优的。结果同样适用于Hankel矩阵。

Conclusion: Gradient-MUSIC算法能够高效且最优地解决结构化逼近问题，为Toeplitz矩阵恢复和傅里叶矩阵范围恢复提供了定量联系和谱估计方法。

Abstract: This paper studies two structured approximation problems: (1) Recovering a corrupted low-rank Toeplitz matrix and (2) recovering the range of a Fourier matrix from a single observation. Both problems are computationally challenging because the structural constraints are difficult to enforce directly. We show that both tasks can be solved efficiently and optimally by applying the Gradient-MUSIC algorithm for spectral estimation. For a rank $r$ Toeplitz matrix ${\boldsymbol T}\in {\mathbb C}^{n\times n}$ that satisfies a regularity assumption and is corrupted by an arbitrary ${\boldsymbol E}\in {\mathbb C}^{n\times n}$ such that $\|{\boldsymbol E}\|_2\leq αn$, our algorithm outputs a Toeplitz matrix $\widehat{\boldsymbol T}$ of rank exactly $r$ such that $\|{\boldsymbol T}-\widehat{\boldsymbol T}\|_2 \leq C \sqrt r \, \|{\boldsymbol E}\|_2$, where $C,α>0$ are absolute constants. This performance guarantee is minimax optimal in $n$ and $\|{\boldsymbol E}\|_2$. We derive optimal results for the second problem as well. Our analysis provides quantitative connections between these two problems and spectral estimation. Our results are equally applicable to Hankel matrices with superficial modifications.

</details>


### [23] [Fast Decoding for Non-Adaptive Learning of Erdős--Rényi Random Graphs](https://arxiv.org/abs/2511.17240)
*Hoang Ta,Jonathan Scarlett*

Main category: cs.IT

TL;DR: 本文提出了一种非自适应图学习算法，通过群体查询学习Erdős-Rényi图，使用O(̄k log n)次测试即可高概率恢复边集，同时解码时间仅为O(̄k^{1+δ} log n)，相比之前工作显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有图学习方法在非自适应设置下存在计算效率问题：要么需要Ω(n²)解码时间，要么需要额外测试次数。本文旨在设计一个既保持最优测试次数又实现亚线性解码时间的算法。

Method: 将非自适应群体测试中的二分搜索方法扩展到ER图学习场景，通过精心设计的群体查询策略来识别图中的边。

Result: 算法能够以高概率恢复ER图的边集，仅需O(̄k log n)次测试，解码时间为O(̄k^{1+δ} log n)，其中̄k为期望边数，δ为任意固定正数。

Conclusion: 该方法在保持最优测试复杂度的同时，显著降低了计算复杂度，为大规模图学习提供了实用解决方案。

Abstract: We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \(n\) nodes and \(k\) edges is hard in the non-adaptive setting, requiring \(Ω\big(\min\{k^2\log n,\,n^2\}\big)\) tests even when a small error probability is allowed. We focus on learning Erdős--Rényi (ER) graphs \(G\sim\ER(n,q)\) in the non-adaptive setting, where the expected number of edges is \(\bar{k}=q\binom{n}{2}\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \(O(\bar{k}\log n)\) but incurs \(Ω(n^2)\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \((\log \bar{k})(\log n)\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \(O(\bar{k}\log n)\) tests while attaining decoding time \(O(\bar{k}^{1+δ}\log n)\) for any fixed \(δ>0\).

</details>


### [24] [Fluid Antenna System-Enabled UAV-to-Ground Communications](https://arxiv.org/abs/2511.17416)
*Xusheng Zhu,Kai-Kit Wong,Qingqing Wu,Hyundong Shin,Yangyang Zhang*

Main category: cs.IT

TL;DR: 该论文提出了无人机到地面链路中流体天线系统在双阴影衰落信道下的性能分析，推导了端到端信噪比统计、中断概率、误码率和信道容量的解析表达式，并揭示了系统可获得M×d的乘法分集阶数。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统在紧凑尺寸内提供增强的空间分集，而无人机在未来网络中至关重要，需要同时考虑多径衰落和阴影效应的信道模型。

Method: 采用基于特征值的相关FAS端口近似方法，推导端到端信噪比的累积分布函数和概率密度函数，进而分析中断概率、平均误码率和平均信道容量。

Result: 获得了精确的积分表达式和闭式解，系统仿真验证了理论框架的高精度，并发现系统可实现M×d的乘法分集阶数。

Conclusion: 提出的分析框架准确描述了FAS在双阴影衰落信道下的性能，为无人机通信系统设计提供了理论指导。

Abstract: Fluid antenna systems (FAS) have emerged as a revolutionary technology offering enhanced spatial diversity within a compact form factor. Concurrently, unmanned aerial vehicles (UAVs) are integral to future networks, necessitating channel models that capture both multipath fading and shadowing. This letter presents a novel performance analysis of a UAV-to-ground link, where the receiver is equipped with an $N$-port FAS operating over the challenging double-shadowing fading channel. By adapting a tractable eigenvalue-based approximation for the correlated FAS ports, we derive new analytical expressions for the end-to-end signal-to-noise ratio statistics, namely the cumulative distribution function and the probability density function. Based on these statistics, we present exact integral expressions for the outage probability, average bit error rate, and average channel capacity. We further derive new, tractable closed-form solutions for the average bit error rate and capacity for the practical dual-rank, independent but non-identically distributed case. Finally, a key asymptotic analysis reveals that the system achieves a multiplicative diversity order of $G_d = M \times d$, which is precisely the product of the FAS spatial rank $M$ and the intrinsic channel diversity order $d$. Simulation results are provided to validate the high accuracy of our entire theoretical framework.

</details>
