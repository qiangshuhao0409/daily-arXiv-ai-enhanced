{"id": "2509.16236", "categories": ["cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.16236", "abs": "https://arxiv.org/abs/2509.16236", "authors": ["Kentaro Imafuku"], "title": "Similarity as Thermodynamic Work: Between Depth and Diversity -- from Information Distance to Ugly Duckling", "comment": "19 pages, 5 figures", "summary": "Defining similarity is a fundamental challenge in information science.\nWatanabe's Ugly Duckling Theorem highlights diversity, while algorithmic\ninformation theory emphasizes depth through Information Distance. We propose a\nstatistical-mechanical framework that treats program length as energy, with a\ntemperature parameter unifying these two aspects: in the low-temperature limit,\nsimilarity approaches Information Distance; in the high-temperature limit, it\nrecovers the indiscriminability of the Ugly Duckling theorem; and at the\ncritical point, it coincides with the Solomonoff prior. We refine the\nstatistical-mechanical framework by introducing regular universal machines and\neffective degeneracy ratios, allowing us to separate redundant from core\ndiversity. This refinement yields new tools for analyzing similarity and opens\nperspectives for information distance, model selection, and non-equilibrium\nextensions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u8ba1\u529b\u5b66\u6846\u67b6\uff0c\u5c06\u7a0b\u5e8f\u957f\u5ea6\u89c6\u4e3a\u80fd\u91cf\uff0c\u901a\u8fc7\u6e29\u5ea6\u53c2\u6570\u7edf\u4e00\u4fe1\u606f\u8ddd\u79bb\u548c\u4e11\u5c0f\u9e2d\u5b9a\u7406\u7684\u76f8\u4f3c\u6027\u6982\u5ff5\u3002", "motivation": "\u89e3\u51b3\u4fe1\u606f\u79d1\u5b66\u4e2d\u76f8\u4f3c\u6027\u5b9a\u4e49\u7684\u6839\u672c\u6311\u6218\uff0c\u7edf\u4e00Watanabe\u7684\u4e11\u5c0f\u9e2d\u5b9a\u7406\uff08\u5f3a\u8c03\u591a\u6837\u6027\uff09\u548c\u7b97\u6cd5\u4fe1\u606f\u7406\u8bba\uff08\u5f3a\u8c03\u6df1\u5ea6\u4fe1\u606f\u8ddd\u79bb\uff09\u3002", "method": "\u4f7f\u7528\u7edf\u8ba1\u529b\u5b66\u65b9\u6cd5\uff0c\u5c06\u7a0b\u5e8f\u957f\u5ea6\u7c7b\u6bd4\u4e3a\u80fd\u91cf\uff0c\u5f15\u5165\u6e29\u5ea6\u53c2\u6570\u3002\u5728\u4f4e\u6e29\u6781\u9650\u4e0b\u76f8\u4f3c\u6027\u63a5\u8fd1\u4fe1\u606f\u8ddd\u79bb\uff0c\u5728\u9ad8\u6e29\u6781\u9650\u4e0b\u6062\u590d\u4e11\u5c0f\u9e2d\u5b9a\u7406\u7684\u4e0d\u53ef\u533a\u5206\u6027\uff0c\u5728\u4e34\u754c\u70b9\u4e0eSolomonoff\u5148\u9a8c\u4e00\u81f4\u3002\u901a\u8fc7\u5f15\u5165\u6b63\u5219\u901a\u7528\u673a\u548c\u6709\u6548\u7b80\u5e76\u6bd4\u6765\u5206\u79bb\u5197\u4f59\u4e0e\u6838\u5fc3\u591a\u6837\u6027\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u5e73\u6ed1\u8fc7\u6e21\u4e0d\u540c\u76f8\u4f3c\u6027\u6982\u5ff5\uff0c\u5e76\u63d0\u4f9b\u4e86\u5206\u6790\u76f8\u4f3c\u6027\u7684\u65b0\u5de5\u5177\u3002", "conclusion": "\u8be5\u7edf\u8ba1\u529b\u5b66\u6846\u67b6\u4e3a\u4fe1\u606f\u8ddd\u79bb\u3001\u6a21\u578b\u9009\u62e9\u548c\u975e\u5e73\u8861\u6269\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u80fd\u591f\u66f4\u7cbe\u7ec6\u5730\u5206\u6790\u76f8\u4f3c\u6027\u3002"}}
{"id": "2509.16376", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16376", "abs": "https://arxiv.org/abs/2509.16376", "authors": ["Alexander Fengler", "Burak \u00c7akmak", "Giuseppe Caire"], "title": "Sparse Regression LDPC Codes for the Block-Fading Non-Coherent SIMO Channel", "comment": "37 pages, 7 figures, submitted for publication", "summary": "Sparse regression codes (SPARCs) are a class of codes that encode information\nthrough the superposition of columns of a randomised coding matrix. The\ncombination with an outer non-binary low density parity check (NB-LDPC) code\nwas recently shown to improve the finite-length performance of these codes over\nthe unfaded AWGN channel. In this paper, we propose a low-complexity\napproximate message passing (AMP) decoder that is capable of decoding NB-LDPC\nencoded SPARCs on a Rayleigh fading channel with multiple receive antennas.\nNotably, the decoder does not require channel state information (CSI), i.e., it\nis fully non-coherent, but achieves the same error probability as a decoder\nwith full CSI, even for moderate block lengths. This is achieved by iteratively\nre-estimating the channel throughout the decoding iterations. In addition, we\nprovide a rigorous asymptotic analysis of both the block error probability and\nthe channel estimation error. Numerical results confirm the precision of the\nanalysis and show that the presented coding scheme performs within 1.5 dB of\nthe outage capacity and is competitive with coded modulation schemes employing\nstandardised LDPC codes for 5G cellular networks and pilot-based channel\nestimation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\u89e3\u7801\u5668\uff0c\u7528\u4e8e\u89e3\u7801\u975e\u4e8c\u8fdb\u5236LDPC\u7f16\u7801\u7684\u7a00\u758f\u56de\u5f52\u7801\u5728\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e0a\u7684\u4f20\u8f93\uff0c\u65e0\u9700\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u5373\u53ef\u8fbe\u5230\u4e0e\u6709CSI\u76f8\u540c\u7684\u8bef\u7801\u7387\u3002", "motivation": "\u7ed3\u5408\u975e\u4e8c\u8fdb\u5236LDPC\u7801\u53ef\u4ee5\u6539\u5584\u7a00\u758f\u56de\u5f52\u7801\u5728AWGN\u4fe1\u9053\u4e0a\u7684\u6709\u9650\u957f\u5ea6\u6027\u80fd\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u5728\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e0a\u65e0\u9700CSI\u7684\u89e3\u7801\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u8fed\u4ee3\u91cd\u65b0\u4f30\u8ba1\u4fe1\u9053\u6765\u5b9e\u73b0\u5b8c\u5168\u975e\u76f8\u5e72\u89e3\u7801\uff0c\u540c\u65f6\u63d0\u4f9b\u4e25\u683c\u7684\u6e10\u8fd1\u6027\u80fd\u5206\u6790\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\u8be5\u7f16\u7801\u65b9\u6848\u5728\u4e2d\u65ad\u5bb9\u91cf1.5dB\u4ee5\u5185\uff0c\u6027\u80fd\u4e0e\u91c7\u75285G\u6807\u51c6\u5316LDPC\u7801\u548c\u57fa\u4e8e\u5bfc\u9891\u4fe1\u9053\u4f30\u8ba1\u7684\u7f16\u7801\u8c03\u5236\u65b9\u6848\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u975e\u76f8\u5e72AMP\u89e3\u7801\u5668\u5728\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u4e3a\u65e0\u9700CSI\u7684\u53ef\u9760\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.16424", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16424", "abs": "https://arxiv.org/abs/2509.16424", "authors": ["Eduardo Camps-Moreno", "Elisa Gorla", "Hiram H. L\u00f3pez"], "title": "Code distances: a new family of invariants of linear codes", "comment": null, "summary": "In this paper, we introduce code distances, a new family of invariants for\nlinear codes. We establish some properties and prove bounds on the code\ndistances, and show that they are not invariants of the matroid (for a linear\nblock code) or $q$-polymatroid (for a rank-metric code) associated to the code.\nBy means of examples, we show that the code distances allow us to distinguish\nsome inequivalent MDS or MRD codes with the same parameters. We also show that\nno duality holds, i.e., the sequence of code distances of a code does not\ndetermine the sequence of code distances of its dual. Further, we define a\ngreedy and an asymptotic version of code distances. Finally, we relate these\ninvariants to other invariants of linear codes, such as the maximality degree,\nthe covering radius, and the partial distances of polar codes.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7801\u8ddd\u79bb\u8fd9\u4e00\u7ebf\u6027\u7801\u7684\u65b0\u4e0d\u53d8\u91cf\u65cf\uff0c\u7814\u7a76\u4e86\u5176\u6027\u8d28\u3001\u754c\u9650\uff0c\u5e76\u8bc1\u660e\u5176\u4e0d\u662f\u5173\u8054\u7684\u62df\u9635\u6216q-\u591a\u62df\u9635\u7684\u4e0d\u53d8\u91cf\u3002\u901a\u8fc7\u5b9e\u4f8b\u5c55\u793a\u4e86\u7801\u8ddd\u79bb\u80fd\u533a\u5206\u5177\u6709\u76f8\u540c\u53c2\u6570\u7684MDS\u6216MRD\u7801\uff0c\u4e14\u4e0d\u5b58\u5728\u5bf9\u5076\u6027\u3002\u8fd8\u5b9a\u4e49\u4e86\u8d2a\u5a6a\u548c\u6e10\u8fd1\u7248\u672c\uff0c\u5e76\u4e0e\u5176\u4ed6\u4e0d\u53d8\u91cf\u5982\u6781\u5927\u5ea6\u3001\u8986\u76d6\u534a\u5f84\u548c\u6781\u5316\u7801\u7684\u90e8\u5206\u8ddd\u79bb\u5efa\u7acb\u4e86\u8054\u7cfb\u3002", "motivation": "\u4e3a\u4e86\u5bfb\u627e\u80fd\u591f\u66f4\u597d\u5730\u533a\u5206\u7ebf\u6027\u7801\u7684\u65b0\u4e0d\u53d8\u91cf\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u5177\u6709\u76f8\u540c\u4f20\u7edf\u53c2\u6570\u4f46\u7ed3\u6784\u4e0d\u540c\u7684\u7801\u3002\u7801\u8ddd\u79bb\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u4e0d\u53d8\u91cf\u65cf\uff0c\u65e8\u5728\u63d0\u4f9b\u6bd4\u4f20\u7edf\u53c2\u6570\u66f4\u7cbe\u7ec6\u7684\u533a\u5206\u80fd\u529b\u3002", "method": "\u5f15\u5165\u7801\u8ddd\u79bb\u7684\u6982\u5ff5\uff0c\u5efa\u7acb\u5176\u6570\u5b66\u6027\u8d28\u5e76\u8bc1\u660e\u76f8\u5173\u754c\u9650\u3002\u901a\u8fc7\u6784\u9020\u5177\u4f53\u4f8b\u5b50\u5c55\u793a\u7801\u8ddd\u79bb\u7684\u533a\u5206\u80fd\u529b\uff0c\u5b9a\u4e49\u8d2a\u5a6a\u548c\u6e10\u8fd1\u7248\u672c\uff0c\u5e76\u4e0e\u5176\u4ed6\u5df2\u77e5\u4e0d\u53d8\u91cf\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u7801\u8ddd\u79bb\u80fd\u591f\u533a\u5206\u4e00\u4e9b\u5177\u6709\u76f8\u540c\u53c2\u6570\u7684MDS\u6216MRD\u7801\uff0c\u8bc1\u660e\u5176\u4e0d\u662f\u62df\u9635\u6216q-\u591a\u62df\u9635\u7684\u4e0d\u53d8\u91cf\uff0c\u4e14\u4e0d\u5b58\u5728\u5bf9\u5076\u6027\u3002\u5efa\u7acb\u4e86\u7801\u8ddd\u79bb\u4e0e\u5176\u4ed6\u4e0d\u53d8\u91cf\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u7801\u8ddd\u79bb\u662f\u7ebf\u6027\u7801\u7684\u4e00\u4e2a\u6709\u7528\u65b0\u4e0d\u53d8\u91cf\uff0c\u80fd\u591f\u63d0\u4f9b\u6bd4\u4f20\u7edf\u53c2\u6570\u66f4\u7ec6\u81f4\u7684\u533a\u5206\uff0c\u4f46\u5728\u5bf9\u5076\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5e94\u7528\u548c\u6027\u8d28\u3002"}}
{"id": "2509.16612", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16612", "abs": "https://arxiv.org/abs/2509.16612", "authors": ["W. Zhu", "H. D. Tuan", "E. Dutkiewicz", "H. V. Poor", "L. Hanzo"], "title": "Holographic Multi-User Multi-Stream Beamforming Maintaining Rate-Fairness", "comment": null, "summary": "We present the first investigation into the transmission of multi-stream\ninformation from a base station equipped with reconfigurable holographic\nsurfaces (RHS) to multiple users with the aid of multi-antenna arrays. Building\nupon this, we propose the joint design of RHS and baseband beamformers that\nenables multi-stream delivery at fair rates across all users. Specifically, we\nfirst introduce a max-min rate optimization approach, which aims for maximizing\nthe minimum rate for all users through iterative solutions of quadratic\nproblems. To reduce complexity, we then propose a surrogate-based optimization\napproach that offers a low-complexity design alternative relying on closed-form\nupdates. Our simulations show that the surrogate-based approach achieves nearly\nthe same minimum rate as max-min optimization, while delivering sum-rates\ncomparable to those of sum-rate maximization, overcoming the rate-fairness\ndeficiency typical of the latter.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76\u4e86\u4f7f\u7528\u53ef\u91cd\u6784\u5168\u606f\u8868\u9762(RHS)\u7684\u57fa\u7ad9\u5411\u591a\u7528\u6237\u4f20\u8f93\u591a\u6d41\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86RHS\u548c\u57fa\u5e26\u6ce2\u675f\u6210\u5f62\u5668\u7684\u8054\u5408\u8bbe\u8ba1\uff0c\u4ee5\u5b9e\u73b0\u591a\u7528\u6237\u95f4\u7684\u516c\u5e73\u591a\u6d41\u4f20\u8f93\u3002", "motivation": "\u4f20\u7edf\u591a\u5929\u7ebf\u7cfb\u7edf\u4e2d\uff0c\u591a\u6d41\u4f20\u8f93\u901a\u5e38\u9762\u4e34\u901f\u7387\u516c\u5e73\u6027\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u4f7f\u7528RHS\u6280\u672f\u7684\u57fa\u7ad9\u5411\u591a\u7528\u6237\u4f20\u8f93\u591a\u6d41\u4fe1\u606f\u65f6\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u514b\u670d\u4f20\u7edf\u548c\u901f\u7387\u6700\u5927\u5316\u65b9\u6cd5\u5728\u516c\u5e73\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u4f18\u5316\u65b9\u6cd5\uff1a1) \u6700\u5927\u6700\u5c0f\u901f\u7387\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u6c42\u89e3\u4e8c\u6b21\u95ee\u9898\u6765\u6700\u5927\u5316\u6240\u6709\u7528\u6237\u7684\u6700\u5c0f\u901f\u7387\uff1b2) \u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4f4e\u590d\u6742\u5ea6\u8bbe\u8ba1\u66ff\u4ee3\u65b9\u6848\uff0c\u4f9d\u8d56\u95ed\u5f0f\u66f4\u65b0\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u4ee3\u7406\u7684\u65b9\u6cd5\u5728\u6700\u5c0f\u901f\u7387\u65b9\u9762\u51e0\u4e4e\u8fbe\u5230\u4e0e\u6700\u5927\u6700\u5c0f\u4f18\u5316\u76f8\u540c\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5728\u548c\u901f\u7387\u65b9\u9762\u4e0e\u548c\u901f\u7387\u6700\u5927\u5316\u65b9\u6cd5\u76f8\u5f53\uff0c\u514b\u670d\u4e86\u540e\u8005\u5728\u901f\u7387\u516c\u5e73\u6027\u65b9\u9762\u7684\u7f3a\u9677\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u65b9\u6cd5\u5728\u4fdd\u6301\u4f4e\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u80fd\u591f\u6709\u6548\u5e73\u8861\u591a\u7528\u6237\u591a\u6d41\u4f20\u8f93\u7684\u901f\u7387\u516c\u5e73\u6027\u548c\u7cfb\u7edf\u603b\u541e\u5410\u91cf\uff0c\u4e3aRHS\u8f85\u52a9\u7684\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.16485", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.16485", "abs": "https://arxiv.org/abs/2509.16485", "authors": ["Abdur Rouf", "Murat Yuksel"], "title": "Spatial Encoding of Flow Spaces for Intelligent SDN Applications", "comment": "Accepted at IEEE NFV-SDN 2025. This is the author-accepted manuscript", "summary": "Efficient encoding of network flow spaces while preserving spatial locality\nis essential for intelligent Software-Defined Networking (SDN) applications,\nparticularly those employing reinforcement learning (RL) methods in a reactive\nmanner. In this work, we introduce a spatially aware Bloom Filter-based\napproach to encode IP flow pairs, leveraging their inherent geographical\nlocality. Through controlled experiments using IoT traffic data, we demonstrate\nthat Bloom Filters effectively preserve spatial relationships among flows. Our\nfindings show that Bloom Filters degrade gracefully, maintaining predictable\nspatial correlations critical for RL state representation. We integrate this\nencoding into a DQN-based eviction strategy for reactive SDN forwarding.\nExperiments show that Bloom Filter-encoded, spatially aware flow representation\nenables up to 7% and 8% reduction in normalized miss rate over LRU and LFU,\nrespectively, across 10 hours of traffic, demonstrating potential for\nlow-latency applications. This experiment justifies the usefulness of\npreserving spatial correlation by encoding the flow space into a manageable\nsize, opening a novel research direction for RL-based SDN applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eBloom Filter\u7684\u7a7a\u95f4\u611f\u77e5\u7f51\u7edc\u6d41\u7f16\u7801\u65b9\u6cd5\uff0c\u7528\u4e8eSDN\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\uff0c\u901a\u8fc7\u4fdd\u6301\u6d41\u91cf\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u6765\u63d0\u9ad8\u6027\u80fd", "motivation": "SDN\u4e2d\u667a\u80fd\u5e94\u7528\u9700\u8981\u9ad8\u6548\u7f16\u7801\u7f51\u7edc\u6d41\u7a7a\u95f4\u5e76\u4fdd\u6301\u7a7a\u95f4\u5c40\u90e8\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u7684\u53cd\u5e94\u5f0f\u5e94\u7528", "method": "\u4f7f\u7528\u57fa\u4e8eBloom Filter\u7684\u65b9\u6cd5\u7f16\u7801IP\u6d41\u5bf9\uff0c\u5229\u7528\u5176\u56fa\u6709\u7684\u5730\u7406\u5c40\u90e8\u6027\uff0c\u5e76\u5c06\u6b64\u7f16\u7801\u96c6\u6210\u5230\u57fa\u4e8eDQN\u7684SDN\u8f6c\u53d1\u9a71\u9010\u7b56\u7565\u4e2d", "result": "\u5b9e\u9a8c\u663e\u793aBloom Filter\u80fd\u6709\u6548\u4fdd\u6301\u6d41\u4e4b\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u572810\u5c0f\u65f6\u6d41\u91cf\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4LRU\u548cLFU\u5206\u522b\u964d\u4f4e7%\u548c8%\u7684\u5f52\u4e00\u5316\u7f3a\u5931\u7387", "conclusion": "Bloom Filter\u7f16\u7801\u7684\u7a7a\u95f4\u611f\u77e5\u6d41\u8868\u793a\u8bc1\u660e\u4e86\u4fdd\u6301\u7a7a\u95f4\u76f8\u5173\u6027\u5bf9\u4e8eRL-based SDN\u5e94\u7528\u7684\u4ef7\u503c\uff0c\u4e3a\u4f4e\u5ef6\u8fdf\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u7814\u7a76\u65b9\u5411"}}
{"id": "2509.16288", "categories": ["cs.AI", "05C22, 05C90, 68R10 05C22, 05C90, 68R10 05C22, 05C90, 68R10"], "pdf": "https://arxiv.org/pdf/2509.16288", "abs": "https://arxiv.org/abs/2509.16288", "authors": ["Shanookha Ali", "Nitha Niralda P C"], "title": "Identifying Critical Pathways in Coronary Heart Disease via Fuzzy Subgraph Connectivity", "comment": null, "summary": "Coronary heart disease (CHD) arises from complex interactions among\nuncontrollable factors, controllable lifestyle factors, and clinical\nindicators, where relationships are often uncertain. Fuzzy subgraph\nconnectivity (FSC) provides a systematic tool to capture such imprecision by\nquantifying the strength of association between vertices and subgraphs in fuzzy\ngraphs. In this work, a fuzzy CHD graph is constructed with vertices for\nuncontrollable, controllable, and indicator components, and edges weighted by\nfuzzy memberships. Using FSC, we evaluate connectivity to identify strongest\ndiagnostic routes, dominant risk factors, and critical bridges. Results show\nthat FSC highlights influential pathways, bounds connectivity between weakest\nand strongest correlations, and reveals critical edges whose removal reduces\npredictive strength. Thus, FSC offers an interpretable and robust framework for\nmodeling uncertainty in CHD risk prediction and supporting clinical\ndecision-making.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u6a21\u7cca\u5b50\u56fe\u8fde\u901a\u6027\uff08FSC\uff09\u65b9\u6cd5\u6765\u5efa\u6a21\u51a0\u5fc3\u75c5\u98ce\u9669\u9884\u6d4b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u6a21\u7ccaCHD\u56fe\u6765\u8bc6\u522b\u5173\u952e\u8bca\u65ad\u8def\u5f84\u3001\u4e3b\u5bfc\u98ce\u9669\u56e0\u7d20\u548c\u5173\u952e\u6865\u6881\u3002", "motivation": "\u51a0\u5fc3\u75c5\uff08CHD\uff09\u662f\u7531\u4e0d\u53ef\u63a7\u56e0\u7d20\u3001\u53ef\u63a7\u751f\u6d3b\u65b9\u5f0f\u56e0\u7d20\u548c\u4e34\u5e8a\u6307\u6807\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u5f15\u8d77\u7684\uff0c\u8fd9\u4e9b\u5173\u7cfb\u901a\u5e38\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u7684\u7cfb\u7edf\u5de5\u5177\u6765\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u6a21\u7ccaCHD\u56fe\uff0c\u9876\u70b9\u4ee3\u8868\u4e0d\u53ef\u63a7\u3001\u53ef\u63a7\u548c\u6307\u6807\u7ec4\u4ef6\uff0c\u8fb9\u7531\u6a21\u7cca\u96b6\u5c5e\u5ea6\u52a0\u6743\u3002\u4f7f\u7528\u6a21\u7cca\u5b50\u56fe\u8fde\u901a\u6027\uff08FSC\uff09\u8bc4\u4f30\u8fde\u901a\u6027\uff0c\u8bc6\u522b\u6700\u5f3a\u7684\u8bca\u65ad\u8def\u5f84\u3001\u4e3b\u5bfc\u98ce\u9669\u56e0\u7d20\u548c\u5173\u952e\u6865\u6881\u3002", "result": "\u7ed3\u679c\u663e\u793aFSC\u80fd\u591f\u7a81\u51fa\u6709\u5f71\u54cd\u529b\u7684\u8def\u5f84\uff0c\u9650\u5b9a\u6700\u5f31\u548c\u6700\u5f3a\u76f8\u5173\u6027\u4e4b\u95f4\u7684\u8fde\u901a\u6027\u8fb9\u754c\uff0c\u5e76\u63ed\u793a\u90a3\u4e9b\u79fb\u9664\u540e\u4f1a\u964d\u4f4e\u9884\u6d4b\u5f3a\u5ea6\u7684\u5173\u952e\u8fb9\u3002", "conclusion": "FSC\u4e3aCHD\u98ce\u9669\u9884\u6d4b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u4e14\u7a33\u5065\u7684\u6846\u67b6\uff0c\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "1705.03366", "categories": ["cs.IT", "cs.SY", "eess.SP", "eess.SY", "math.IT", "physics.data-an"], "pdf": "https://arxiv.org/pdf/1705.03366", "abs": "https://arxiv.org/abs/1705.03366", "authors": ["Dogay Altinel", "Gunes Karabulut Kurt"], "title": "Frequency Switching for Simultaneous Wireless Information and Power Transfer", "comment": null, "summary": "A new frequency switching receiver structure is proposed for simultaneous\nwireless information and power transfer in multi-carrier communication systems.\nEach subcarrier is switched to either the energy harvesting unit or the\ninformation decoding unit, according to the optimal subcarrier allocation. To\nimplement the system, one-bit feedback is required for each subcarrier. Two\noptimization problems are defined, converted to binary knapsack problems, and\nsolved using dynamic programming approaches. Upper bounds are obtained using\ncontinuous relaxations. Power allocation is integrated to further increase the\nperformance. Numerical studies show that the proposed frequency switching based\nmodel is better than existing models in a wide range of parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9891\u7387\u5207\u6362\u63a5\u6536\u5668\u7ed3\u6784\uff0c\u7528\u4e8e\u591a\u8f7d\u6ce2\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u540c\u65f6\u65e0\u7ebf\u4fe1\u606f\u548c\u80fd\u91cf\u4f20\u8f93\u3002\u6bcf\u4e2a\u5b50\u8f7d\u6ce2\u6839\u636e\u6700\u4f18\u5b50\u8f7d\u6ce2\u5206\u914d\u5207\u6362\u5230\u80fd\u91cf\u6536\u96c6\u5355\u5143\u6216\u4fe1\u606f\u89e3\u7801\u5355\u5143\u3002", "motivation": "\u5728\u591a\u8f7d\u6ce2\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u540c\u65f6\u65e0\u7ebf\u4fe1\u606f\u548c\u80fd\u91cf\u4f20\u8f93\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5c06\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u4e8c\u8fdb\u5236\u80cc\u5305\u95ee\u9898\uff0c\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u6c42\u89e3\uff0c\u5e76\u901a\u8fc7\u8fde\u7eed\u677e\u5f1b\u83b7\u5f97\u4e0a\u754c\uff0c\u96c6\u6210\u529f\u7387\u5206\u914d\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u6570\u503c\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u9891\u7387\u5207\u6362\u7684\u6a21\u578b\u5728\u5e7f\u6cdb\u53c2\u6570\u8303\u56f4\u5185\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u9891\u7387\u5207\u6362\u63a5\u6536\u5668\u7ed3\u6784\u662f\u5b9e\u73b0\u540c\u65f6\u65e0\u7ebf\u4fe1\u606f\u548c\u80fd\u91cf\u4f20\u8f93\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5177\u6709\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2509.16634", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16634", "abs": "https://arxiv.org/abs/2509.16634", "authors": ["W. Zhu", "H. D. Tuan", "E. Dutkiewicz", "H. V. Poor", "L. Hanzo"], "title": "A New Class of Analog Precoding for Multi-Antenna Multi-User Communications over High-Frequency Bands", "comment": null, "summary": "A network relying on a large antenna-array-aided base station is designed for\ndelivering multiple information streams to multi-antenna users over\nhigh-frequency bands such as the millimeter-wave and sub-Terahertz bands. The\nstate-of-the-art analog precoder (AP) dissipates excessive circuit power due to\nits reliance on a large number of phase shifters. To mitigate the power\nconsumption, we propose a novel AP relying on a controlled number of phase\nshifters. Within this new AP framework, we design a hybrid precoder (HP) for\nmaximizing the users' minimum throughput, which poses a computationally\nchallenging problem of large-scale, nonsmooth mixed discrete-continuous\nlog-determinant optimization. To tackle this challenge, we develop an algorithm\nwhich iterates through solving convex problems to generate a sequence of HPs\nthat converges to the max-min solution. We also introduce a new framework of\nsmooth optimization termed soft max-min throughput optimization. Additionally,\nwe develop another algorithm, which iterates by evaluating closed-form\nexpressions to generate a sequence of HPs that converges to the soft max-min\nsolution. Simulation results reveal that the HP soft max-min solution\napproaches the Pareto-optimal solution constructed for simultaneously\noptimizing both the minimum throughput and sum-throughput. Explicitly, it\nachieves a minimum throughput similar to directly maximizing the users' minimum\nthroughput and it also attains a sum-throughput similar to directly maximizing\nthe sum-throughput.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6a21\u62df\u9884\u7f16\u7801\u5668\u4ee5\u51cf\u5c11\u529f\u8017\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6df7\u5408\u9884\u7f16\u7801\u5668\u6765\u6700\u5927\u5316\u7528\u6237\u6700\u5c0f\u541e\u5410\u91cf\uff0c\u901a\u8fc7\u8fed\u4ee3\u7b97\u6cd5\u89e3\u51b3\u5927\u89c4\u6a21\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6a21\u62df\u9884\u7f16\u7801\u5668\u4f9d\u8d56\u5927\u91cf\u79fb\u76f8\u5668\u5bfc\u81f4\u529f\u8017\u8fc7\u9ad8\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u8282\u80fd\u7684\u65b9\u6848\u6765\u652f\u6301\u9ad8\u9891\u6bb5\u901a\u4fe1\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u63a7\u6570\u91cf\u79fb\u76f8\u5668\u7684\u65b0\u578b\u6a21\u62df\u9884\u7f16\u7801\u5668\u6846\u67b6\uff0c\u5f00\u53d1\u4e24\u79cd\u8fed\u4ee3\u7b97\u6cd5\uff1a\u4e00\u79cd\u89e3\u51b3\u6700\u5927\u6700\u5c0f\u541e\u5410\u91cf\u4f18\u5316\u95ee\u9898\uff0c\u53e6\u4e00\u79cd\u89e3\u51b3\u5e73\u6ed1\u7684\u8f6f\u6700\u5927\u6700\u5c0f\u541e\u5410\u91cf\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8f6f\u6700\u5927\u6700\u5c0f\u89e3\u51b3\u65b9\u6848\u63a5\u8fd1\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\uff0c\u5728\u6700\u5c0f\u541e\u5410\u91cf\u548c\u603b\u541e\u5410\u91cf\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u9884\u7f16\u7801\u5668\u65b9\u6848\u5728\u529f\u8017\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u9ad8\u9891\u6bb5\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.16700", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.16700", "abs": "https://arxiv.org/abs/2509.16700", "authors": ["Jyotsna Rani", "Kuntal Deka", "Ganesh Prasad", "Zilong Liu"], "title": "Kalman Filtering-Assisted Node Deployment for Distributed OTFS-ISAC: A Geometry-Aware Design for the Joint Sensing and Communication", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a key enabler for\nnext-generation wireless networks, offering spectrum efficiency and reduced\nhardware complexity. While monostatic ISAC has been well studied, its limited\nspatial diversity reduces reliability in high-mobility scenarios. Distributed\nISAC alleviates this via cooperative nodes, but conventional OFDM-based designs\nremain vulnerable to Doppler shifts and multipath fading. Orthogonal time\nfrequency space (OTFS) modulation has recently emerged as a resilient\nalternative, as its delay-Doppler domain representation enables robust\ncommunication and high-resolution sensing. Motivated by this, we extend OTFS to\ndistributed ISAC and address the underexplored problem of spatial node\ndeployment. We propose a triangulation-based framework that leverages spatial\ndiversity to improve target localization, velocity estimation, and\ncommunication rates, and analytically characterize the role of deployment\ngeometry in minimizing estimation error. Furthermore, we integrate Kalman\nfiltering (KF) into distributed OTFS-ISAC to enhance tracking of moving\ntargets, and design novel algorithms for active sensing, passive sensing, and\njoint sensing-communication. Closed-form expressions are derived for\nlocalization error under general topologies, and a near-optimal deployment\nstrategy is identified by aligning receivers along orthogonal axes. Numerical\nevaluations show significant reductions in localization error and bit error\nrate (BER), while capturing the trade-offs between sensing accuracy and\ncommunication reliability. These results highlight the potential of KF-assisted\nnode placement in distributed OTFS-ISAC for reliable, high-performance\noperation in dynamic wireless environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u89d2\u6d4b\u91cf\u7684\u5206\u5e03\u5f0fOTFS-ISAC\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u8282\u70b9\u90e8\u7f72\u51e0\u4f55\u548c\u96c6\u6210\u5361\u5c14\u66fc\u6ee4\u6ce2\u6765\u63d0\u5347\u79fb\u52a8\u76ee\u6807\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5355\u57fa\u5730ISAC\u5728\u9ad8\u901f\u79fb\u52a8\u573a\u666f\u4e0b\u7a7a\u95f4\u5206\u96c6\u6709\u9650\uff0c\u800c\u5206\u5e03\u5f0fOFDM\u65b9\u6848\u5bf9\u591a\u666e\u52d2\u9891\u79fb\u548c\u591a\u5f84\u8870\u843d\u654f\u611f\u3002OTFS\u8c03\u5236\u5728\u65f6\u5ef6-\u591a\u666e\u52d2\u57df\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f46\u5206\u5e03\u5f0fOTFS-ISAC\u4e2d\u7684\u8282\u70b9\u90e8\u7f72\u95ee\u9898\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e09\u89d2\u6d4b\u91cf\u6846\u67b6\u5229\u7528\u7a7a\u95f4\u5206\u96c6\u6539\u8fdb\u76ee\u6807\u5b9a\u4f4d\u548c\u901f\u5ea6\u4f30\u8ba1\uff1b\u96c6\u6210\u5361\u5c14\u66fc\u6ee4\u6ce2\u589e\u5f3a\u79fb\u52a8\u76ee\u6807\u8ddf\u8e2a\uff1b\u8bbe\u8ba1\u4e3b\u52a8/\u88ab\u52a8\u611f\u77e5\u548c\u8054\u5408\u611f\u77e5-\u901a\u4fe1\u7b97\u6cd5\uff1b\u63a8\u5bfc\u4e00\u822c\u62d3\u6251\u4e0b\u7684\u5b9a\u4f4d\u8bef\u5dee\u95ed\u5f0f\u89e3\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u663e\u793a\u5b9a\u4f4d\u8bef\u5dee\u548c\u8bef\u7801\u7387\u663e\u8457\u964d\u4f4e\uff0c\u63ed\u793a\u4e86\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002\u6b63\u4ea4\u8f74\u90e8\u7f72\u7b56\u7565\u63a5\u8fd1\u6700\u4f18\u3002", "conclusion": "KF\u8f85\u52a9\u7684\u8282\u70b9\u90e8\u7f72\u5728\u5206\u5e03\u5f0fOTFS-ISAC\u4e2d\u5177\u6709\u5b9e\u73b0\u52a8\u6001\u65e0\u7ebf\u73af\u5883\u4e0b\u53ef\u9760\u9ad8\u6027\u80fd\u64cd\u4f5c\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.16298", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16298", "abs": "https://arxiv.org/abs/2509.16298", "authors": ["Raquel Fernandez-Peralta", "Juan Vicente Riera"], "title": "A global view of diverse construction methods of fuzzy implication functions rooted on F-chains", "comment": null, "summary": "Fuzzy implication functions are one of the most important operators used in\nthe fuzzy logic framework. While their flexible definition allows for diverse\nfamilies with distinct properties, this variety needs a deeper theoretical\nunderstanding of their structural relationships. In this work, we focus on the\nstudy of construction methods, which employ different techniques to generate\nnew fuzzy implication functions from existing ones. Particularly, we generalize\nthe $F$-chain-based construction, recently introduced by Mesiar et al. to\nextend a method for constructing aggregation functions to the context of fuzzy\nimplication functions. Our generalization employs collections of fuzzy\nimplication functions rather than single ones, and uses two different\nincreasing functions instead of a unique $F$-chain. We analyze property\npreservation under this construction and establish sufficient conditions.\nFurthermore, we demonstrate that our generalized $F$-chain-based construction\nis a unifying framework for several existing methods. In particular, we show\nthat various construction techniques, such as contraposition, aggregation, and\ngeneralized vertical/horizontal threshold methods, can be reformulated within\nour approach. This reveals structural similarities between seemingly distinct\nconstruction strategies and provides a cohesive perspective on fuzzy\nimplication construction methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e7f\u4e49\u7684F\u94fe\u6784\u9020\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u73b0\u6709\u6a21\u7cca\u8574\u6db5\u51fd\u6570\u751f\u6210\u65b0\u7684\u6a21\u7cca\u8574\u6db5\u51fd\u6570\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u7684\u6784\u9020\u6280\u672f\u3002", "motivation": "\u6a21\u7cca\u8574\u6db5\u51fd\u6570\u5728\u6a21\u7cca\u903b\u8f91\u6846\u67b6\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u6784\u9020\u65b9\u6cd5\u7684\u591a\u6837\u6027\u9700\u8981\u5bf9\u5176\u7ed3\u6784\u5173\u7cfb\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u7406\u8bba\u7406\u89e3\u3002", "method": "\u63a8\u5e7f\u4e86Mesiar\u7b49\u4eba\u6700\u8fd1\u63d0\u51fa\u7684F\u94fe\u6784\u9020\u65b9\u6cd5\uff0c\u4f7f\u7528\u6a21\u7cca\u8574\u6db5\u51fd\u6570\u96c6\u5408\u800c\u975e\u5355\u4e2a\u51fd\u6570\uff0c\u5e76\u91c7\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u9012\u589e\u51fd\u6570\u4ee3\u66ff\u5355\u4e00\u7684F\u94fe\u3002", "result": "\u5206\u6790\u4e86\u8be5\u6784\u9020\u4e0b\u7684\u6027\u8d28\u4fdd\u6301\u6027\u5e76\u5efa\u7acb\u4e86\u5145\u5206\u6761\u4ef6\uff0c\u8bc1\u660e\u4e86\u8be5\u5e7f\u4e49\u6784\u9020\u662f\u591a\u79cd\u73b0\u6709\u65b9\u6cd5\u7684\u7edf\u4e00\u6846\u67b6\u3002", "conclusion": "\u8be5\u5e7f\u4e49F\u94fe\u6784\u9020\u63ed\u793a\u4e86\u770b\u4f3c\u4e0d\u540c\u7684\u6784\u9020\u7b56\u7565\u4e4b\u95f4\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u4e3a\u6a21\u7cca\u8574\u6db5\u6784\u9020\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89c6\u89d2\u3002"}}
{"id": "1705.10514", "categories": ["cs.IT", "cs.SY", "eess.SP", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/1705.10514", "abs": "https://arxiv.org/abs/1705.10514", "authors": ["Dogay Altinel", "Gunes Karabulut Kurt"], "title": "Diversity Combining for RF Energy Harvesting", "comment": null, "summary": "RF energy harvesting (RFEH) is a promising technology for energy requirements\nof wireless communication nodes. However, providing sufficient amount of energy\nto ensure self-sufficient devices based on RFEH may be challenging. In this\npaper, the use of diversity combining in RFEH systems is proposed to increase\nthe amount of harvested energy. The power consumption of diversity combining\nprocess is also taken into account to analyze the net benefit of diversity\ncombining. Performances of RFEH systems are investigated for selection\ncombining (SC), equal gain combining (EGC), and maximal ratio combining (MRC)\ntechniques. Simulations are conducted to compare the numerical results of SC,\nEGC, and MRC, and the results show that although the diversity combining\ntechniques can improve the energy harvesting performance, the power consumption\nparameters have a critical importance while determining the suitable technique.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5c04\u9891\u80fd\u91cf\u91c7\u96c6\u7cfb\u7edf\u4e2d\u4f7f\u7528\u5206\u96c6\u5408\u5e76\u6280\u672f\u6765\u63d0\u9ad8\u80fd\u91cf\u91c7\u96c6\u6548\u7387\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u5408\u5e76\u6280\u672f\u7684\u51c0\u6536\u76ca\uff0c\u8003\u8651\u4e86\u529f\u7387\u6d88\u8017\u7684\u5f71\u54cd\u3002", "motivation": "\u5c04\u9891\u80fd\u91cf\u91c7\u96c6\u6280\u672f\u4e3a\u65e0\u7ebf\u901a\u4fe1\u8282\u70b9\u63d0\u4f9b\u80fd\u91cf\uff0c\u4f46\u786e\u4fdd\u8bbe\u5907\u81ea\u7ed9\u81ea\u8db3\u5177\u6709\u6311\u6218\u6027\u3002\u5206\u96c6\u5408\u5e76\u6280\u672f\u6709\u671b\u589e\u52a0\u91c7\u96c6\u80fd\u91cf\uff0c\u4f46\u9700\u8981\u8bc4\u4f30\u5176\u51c0\u6548\u76ca\u3002", "method": "\u7814\u7a76\u4e86\u9009\u62e9\u5408\u5e76\u3001\u7b49\u589e\u76ca\u5408\u5e76\u548c\u6700\u5927\u6bd4\u5408\u5e76\u4e09\u79cd\u5206\u96c6\u5408\u5e76\u6280\u672f\uff0c\u901a\u8fc7\u4eff\u771f\u6bd4\u8f83\u5b83\u4eec\u7684\u6027\u80fd\uff0c\u5e76\u8003\u8651\u4e86\u5408\u5e76\u8fc7\u7a0b\u7684\u529f\u7387\u6d88\u8017\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u5206\u96c6\u5408\u5e76\u6280\u672f\u80fd\u6539\u5584\u80fd\u91cf\u91c7\u96c6\u6027\u80fd\uff0c\u4f46\u529f\u7387\u6d88\u8017\u53c2\u6570\u5728\u9009\u62e9\u5408\u9002\u6280\u672f\u65f6\u5177\u6709\u5173\u952e\u91cd\u8981\u6027\u3002", "conclusion": "\u867d\u7136\u5206\u96c6\u5408\u5e76\u6280\u672f\u80fd\u63d0\u5347\u80fd\u91cf\u91c7\u96c6\u6548\u7387\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5fc5\u987b\u4ed4\u7ec6\u8003\u8651\u529f\u7387\u6d88\u8017\u56e0\u7d20\u6765\u9009\u62e9\u6700\u4f18\u7684\u5408\u5e76\u65b9\u6848\u3002"}}
{"id": "2509.16911", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.16911", "abs": "https://arxiv.org/abs/2509.16911", "authors": ["Jiaxin Wang", "Yadi Wei", "Fang-Wei Fu"], "title": "Further results on bent partitions", "comment": null, "summary": "Bent partitions of $V_{n}^{(p)}$ play an important role in constructing\n(vectorial) bent functions, partial difference sets, and association schemes,\nwhere $V_{n}^{(p)}$ denotes an $n$-dimensional vector space over the finite\nfield $\\mathbb{F}_{p}$, $n$ is an even positive integer, and $p$ is a prime.\nFor bent partitions, there remains a challenging open problem: Whether the\ndepth of any bent partition of $V_{n}^{(p)}$ is always a power of $p$. Notably,\nthe depths of all current known bent partitions of $V_{n}^{(p)}$ are powers of\n$p$. In this paper, we prove that for a bent partition $\\Gamma$ of\n$V_{n}^{(p)}$ for which all the $p$-ary bent functions generated by $\\Gamma$\nare regular or all are weakly regular but not regular, the depth of $\\Gamma$\nmust be a power of $p$. We present new constructions of bent partitions that\n(do not) correspond to vectorial dual-bent functions. In particular, a new\nconstruction of vectorial dual-bent functions is provided. Additionally, for\ngeneral bent partitions of $V_{n}^{(2)}$, we establish a characterization in\nterms of Hadamard matrices.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86V_n^(p)\u4e0a\u7684\u5f2f\u66f2\u5206\u533a\uff0c\u8bc1\u660e\u4e86\u5f53\u6240\u6709\u7531\u5f2f\u66f2\u5206\u533a\u751f\u6210\u7684p\u5143\u5f2f\u66f2\u51fd\u6570\u90fd\u662f\u6b63\u5219\u7684\u6216\u90fd\u662f\u5f31\u6b63\u5219\u4f46\u975e\u6b63\u5219\u65f6\uff0c\u5206\u533a\u7684\u6df1\u5ea6\u5fc5\u987b\u662fp\u7684\u5e42\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u5f2f\u66f2\u5206\u533a\u6784\u9020\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86V_n^(2)\u4e0a\u4e00\u822c\u5f2f\u66f2\u5206\u533a\u4e0eHadamard\u77e9\u9635\u7684\u8868\u5f81\u5173\u7cfb\u3002", "motivation": "\u5f2f\u66f2\u5206\u533a\u5728\u6784\u9020\u5f2f\u66f2\u51fd\u6570\u3001\u90e8\u5206\u5dee\u96c6\u548c\u5173\u8054\u65b9\u6848\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002\u76ee\u524d\u5b58\u5728\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff1aV_n^(p)\u4e0a\u4efb\u4f55\u5f2f\u66f2\u5206\u533a\u7684\u6df1\u5ea6\u662f\u5426\u603b\u662fp\u7684\u5e42\uff1f\u6240\u6709\u5df2\u77e5\u5f2f\u66f2\u5206\u533a\u7684\u6df1\u5ea6\u90fd\u662fp\u7684\u5e42\uff0c\u4f46\u7f3a\u4e4f\u4e00\u822c\u6027\u8bc1\u660e\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5206\u6790\u5f2f\u66f2\u5206\u533a\u751f\u6210\u7684p\u5143\u5f2f\u66f2\u51fd\u6570\u7684\u6b63\u5219\u6027\u7279\u5f81\uff0c\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5f2f\u66f2\u5206\u533a\u6df1\u5ea6\u5fc5\u987b\u662fp\u7684\u5e42\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u65b0\u7684\u5f2f\u66f2\u5206\u533a\u6784\u9020\u65b9\u6cd5\uff0c\u5305\u62ec\u4e0e\u5411\u91cf\u5bf9\u5076\u5f2f\u66f2\u51fd\u6570\u5bf9\u5e94\u7684\u6784\u9020\uff0c\u5e76\u5efa\u7acb\u4e86\u4e8c\u5143\u60c5\u51b5\u4e0b\u5f2f\u66f2\u5206\u533a\u4e0eHadamard\u77e9\u9635\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u5f53\u5f2f\u66f2\u5206\u533a\u751f\u6210\u7684\u6240\u6709p\u5143\u5f2f\u66f2\u51fd\u6570\u90fd\u662f\u6b63\u5219\u7684\u6216\u90fd\u662f\u5f31\u6b63\u5219\u4f46\u975e\u6b63\u5219\u65f6\uff0c\u5206\u533a\u6df1\u5ea6\u5fc5\u987b\u662fp\u7684\u5e42\u3002\u63d0\u4f9b\u4e86\u65b0\u7684\u5f2f\u66f2\u5206\u533a\u6784\u9020\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5411\u91cf\u5bf9\u5076\u5f2f\u66f2\u51fd\u6570\u7684\u65b0\u6784\u9020\u3002\u5728\u4e8c\u5143\u60c5\u51b5\u4e0b\uff0c\u5efa\u7acb\u4e86\u5f2f\u66f2\u5206\u533a\u4e0eHadamard\u77e9\u9635\u7684\u8868\u5f81\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u90e8\u5206\u89e3\u51b3\u4e86\u5f2f\u66f2\u5206\u533a\u6df1\u5ea6\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4e3a\u7279\u5b9a\u7c7b\u578b\u7684\u5f2f\u66f2\u5206\u533a\u63d0\u4f9b\u4e86\u6df1\u5ea6\u5fc5\u987b\u662fp\u7684\u5e42\u7684\u8bc1\u660e\u3002\u65b0\u7684\u6784\u9020\u65b9\u6cd5\u548c\u8868\u5f81\u5173\u7cfb\u4e3a\u5f2f\u66f2\u5206\u533a\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.16856", "categories": ["cs.NI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2509.16856", "abs": "https://arxiv.org/abs/2509.16856", "authors": ["Theviyanthan Krishnamohan", "Lauritz Thamsen", "Paul Harvey"], "title": "BeNNS: A Surrogate Model for Hybrid Online-Offline Evolution of SFC Embedding", "comment": null, "summary": "Service Function Chains (SFCs) enable programmatic control of the functions\nand services in a computer network. By leveraging Software Defined Networking\nto control the links between virtualised network functions, SFCs provide a\nscalable approach to dealing with the increased pressures on network operation\nand management. Unfortunately, the challenge of embedding SFCs onto the\nunderlying physical network and compute infrastructure is an NP-hard problem.\nGenetic Algorithms (GAs) have been used to address this issue, but they require\nsignificant time to evaluate solution quality (fitness) \\textit{online}, with\nmost solutions instead adopting \\textit{offline} simulations or analytical\nevaluations.\n  To enable online use of GAs in solving the SFC embedding problem, we\nintroduce a hybrid online-offline approach to evaluate generated solutions. At\nthe core of this is BeNNS--a topology, traffic, and SFC-embedding agnostic\nsurrogate model that approximates fitness. We evaluate our approach across six\nexperiments, varying available resources and traffic loads. Our results\ndemonstrate that our approach is capable of exploring thousands of potential\nconfigurations and generating deployable solutions in 36.8 minutes on average,\ncompared to online-only approaches, which take 17.9 hours on average to explore\ntens of solutions, which do not converge on an optimal solution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5728\u7ebf-\u79bb\u7ebf\u65b9\u6cd5\u6765\u89e3\u51b3\u670d\u52a1\u529f\u80fd\u94fe\uff08SFC\uff09\u5d4c\u5165\u95ee\u9898\uff0c\u901a\u8fc7\u4f7f\u7528BeNNS\u4ee3\u7406\u6a21\u578b\u6765\u8fd1\u4f3c\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u7684\u9002\u5e94\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9057\u4f20\u7b97\u6cd5\u7684\u5728\u7ebf\u5e94\u7528\u6548\u7387\u3002", "motivation": "\u670d\u52a1\u529f\u80fd\u94fe\u5d4c\u5165\u5230\u7269\u7406\u7f51\u7edc\u548c\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u662f\u4e00\u4e2aNP\u96be\u95ee\u9898\u3002\u867d\u7136\u9057\u4f20\u7b97\u6cd5\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u65f6\u95f4\u5728\u7ebf\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u5927\u591a\u6570\u89e3\u51b3\u65b9\u6848\u53ea\u80fd\u91c7\u7528\u79bb\u7ebf\u6a21\u62df\u6216\u5206\u6790\u8bc4\u4f30\uff0c\u9650\u5236\u4e86\u5728\u7ebf\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u5728\u7ebf-\u79bb\u7ebf\u65b9\u6cd5\uff0c\u6838\u5fc3\u662fBeNNS\u2014\u2014\u4e00\u4e2a\u4e0e\u62d3\u6251\u3001\u6d41\u91cf\u548cSFC\u5d4c\u5165\u65e0\u5173\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u8fd1\u4f3c\u8bc4\u4f30\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u7684\u9002\u5e94\u5ea6\u3002", "result": "\u5728\u516d\u4e2a\u5b9e\u9a8c\u4e2d\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u572836.8\u5206\u949f\u5185\u5e73\u5747\u63a2\u7d22\u6570\u5343\u79cd\u6f5c\u5728\u914d\u7f6e\u5e76\u751f\u6210\u53ef\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u7eaf\u5728\u7ebf\u65b9\u6cd5\u5e73\u5747\u9700\u898117.9\u5c0f\u65f6\u4ec5\u63a2\u7d22\u6570\u5341\u79cd\u89e3\u51b3\u65b9\u6848\u4e14\u65e0\u6cd5\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u9057\u4f20\u7b97\u6cd5\u5728SFC\u5d4c\u5165\u95ee\u9898\u4e2d\u7684\u5728\u7ebf\u5e94\u7528\u6548\u7387\uff0c\u80fd\u591f\u5728\u5408\u7406\u65f6\u95f4\u5185\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.16299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16299", "abs": "https://arxiv.org/abs/2509.16299", "authors": ["Raquel Fernandez-Peralta", "Andrea Mesiarov\u00e1-Zem\u00e1nkov\u00e1"], "title": "On the Non-Uniqueness of Representation of $(U,N)$-Implications", "comment": null, "summary": "Fuzzy implication functions constitute fundamental operators in fuzzy logic\nsystems, extending classical conditionals to manage uncertainty in logical\ninference. Among the extensive families of these operators, generalizations of\nthe classical material implication have received considerable theoretical\nattention, particularly $(S,N)$-implications constructed from t-conorms and\nfuzzy negations, and their further generalizations to $(U,N)$-implications\nusing disjunctive uninorms. Prior work has established characterization\ntheorems for these families under the assumption that the fuzzy negation $N$ is\ncontinuous, ensuring uniqueness of representation. In this paper, we disprove\nthis last fact for $(U,N)$-implications and we show that they do not\nnecessarily possess a unique representation, even if the fuzzy negation is\ncontinuous. Further, we provide a comprehensive study of uniqueness conditions\nfor both uninorms with continuous and non-continuous underlying functions. Our\nresults offer important theoretical insights into the structural properties of\nthese operators.", "AI": {"tldr": "\u672c\u6587\u53cd\u9a73\u4e86(U,N)-\u8574\u6db5\u51fd\u6570\u5728\u8fde\u7eed\u6a21\u7cca\u5426\u5b9a\u4e0b\u5177\u6709\u552f\u4e00\u8868\u793a\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u8bc1\u660e\u5373\u4f7f\u6a21\u7cca\u5426\u5b9a\u8fde\u7eed\uff0c(U,N)-\u8574\u6db5\u4e5f\u53ef\u80fd\u5b58\u5728\u591a\u79cd\u8868\u793a\u65b9\u5f0f\uff0c\u5e76\u5bf9\u8fde\u7eed\u548c\u975e\u8fde\u7eed\u57fa\u7840\u51fd\u6570\u7684\u552f\u4e00\u6027\u6761\u4ef6\u8fdb\u884c\u4e86\u5168\u9762\u7814\u7a76\u3002", "motivation": "\u6a21\u7cca\u8574\u6db5\u51fd\u6570\u662f\u6a21\u7cca\u903b\u8f91\u7cfb\u7edf\u4e2d\u7684\u57fa\u672c\u7b97\u5b50\uff0c\u6269\u5c55\u4e86\u7ecf\u5178\u6761\u4ef6\u53e5\u4ee5\u5904\u7406\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u5148\u524d\u7814\u7a76\u5047\u8bbe\u5728\u8fde\u7eed\u6a21\u7cca\u5426\u5b9aN\u4e0b\uff0c(U,N)-\u8574\u6db5\u5177\u6709\u552f\u4e00\u8868\u793a\uff0c\u4f46\u8fd9\u4e00\u5047\u8bbe\u9700\u8981\u9a8c\u8bc1\u548c\u4fee\u6b63\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u8bc1\u660e\uff0c\u5bf9(U,N)-\u8574\u6db5\u51fd\u6570\u7684\u8868\u793a\u552f\u4e00\u6027\u95ee\u9898\u8fdb\u884c\u6df1\u5165\u7814\u7a76\uff0c\u7279\u522b\u5173\u6ce8\u8fde\u7eed\u548c\u975e\u8fde\u7eed\u57fa\u7840\u51fd\u6570\u7684\u60c5\u51b5\uff0c\u63d0\u4f9b\u4e25\u683c\u7684\u7406\u8bba\u63a8\u5bfc\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86(U,N)-\u8574\u6db5\u51fd\u6570\u5373\u4f7f\u5728\u8fde\u7eed\u6a21\u7cca\u5426\u5b9a\u6761\u4ef6\u4e0b\u4e5f\u4e0d\u4e00\u5b9a\u5177\u6709\u552f\u4e00\u8868\u793a\uff0c\u6253\u7834\u4e86\u4f20\u7edf\u8ba4\u77e5\uff0c\u5e76\u5efa\u7acb\u4e86\u66f4\u5168\u9762\u7684\u552f\u4e00\u6027\u6761\u4ef6\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4fee\u6b63\u4e86\u6a21\u7cca\u903b\u8f91\u7406\u8bba\u4e2d\u7684\u91cd\u8981\u5047\u8bbe\uff0c\u4e3a(U,N)-\u8574\u6db5\u51fd\u6570\u7684\u7ed3\u6784\u7279\u6027\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5bf9\u6a21\u7cca\u903b\u8f91\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u5206\u6790\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2509.16984", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.16984", "abs": "https://arxiv.org/abs/2509.16984", "authors": ["Zhiyuan Ren", "Zhiliang Shuai", "Wenchi Cheng"], "title": "System Relaxation for Interpretable and Adaptive Network Control", "comment": null, "summary": "Prevailing network control strategies, which rely on static shortest-path\nlogic, suffer from catastrophic \"stress concentration\" on critical nodes. This\npaper introduces the System Relaxation Algorithm (SRA), a new control paradigm\ninspired by physical relaxation that guides a network toward an emergent\nequilibrium of load balance. SRA is an interpretable, 'white-box' dynamical\nsystem whose behavior is profoundly topology-dependent: in heterogeneous\nnetworks, it acts as a proactive performance optimizer, reducing peak\ncentrality by over 80\\% and increasing high-load throughput by more than 45\\%;\nin homogeneous topologies, its objective intelligently shifts to resilience\nenhancement. We rigorously prove its global convergence and practical stability\nusing the theory of non-smooth dynamical systems, establishing a predictable\nparadigm for network governance that intelligently trades off performance and\nresilience.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7cfb\u7edf\u677e\u5f1b\u7b97\u6cd5\uff08SRA\uff09\uff0c\u4e00\u79cd\u53d7\u7269\u7406\u677e\u5f1b\u542f\u53d1\u7684\u65b0\u578b\u7f51\u7edc\u63a7\u5236\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5bfc\u7f51\u7edc\u8fbe\u5230\u8d1f\u8f7d\u5e73\u8861\u7684\u6d8c\u73b0\u5747\u8861\uff0c\u89e3\u51b3\u4f20\u7edf\u9759\u6001\u6700\u77ed\u8def\u5f84\u7b56\u7565\u5bfc\u81f4\u7684\u4e34\u754c\u8282\u70b9\u5e94\u529b\u96c6\u4e2d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u63a7\u5236\u7b56\u7565\u4f9d\u8d56\u9759\u6001\u6700\u77ed\u8def\u5f84\u903b\u8f91\uff0c\u4f1a\u5bfc\u81f4\u5173\u952e\u8282\u70b9\u51fa\u73b0\u707e\u96be\u6027\u7684\"\u5e94\u529b\u96c6\u4e2d\"\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u5e73\u8861\u8d1f\u8f7d\u7684\u65b0\u65b9\u6cd5\u3002", "method": "SRA\u662f\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\"\u767d\u76d2\"\u52a8\u6001\u7cfb\u7edf\uff0c\u5176\u884c\u4e3a\u9ad8\u5ea6\u4f9d\u8d56\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u3002\u5728\u5f02\u6784\u7f51\u7edc\u4e2d\u4f5c\u4e3a\u4e3b\u52a8\u6027\u80fd\u4f18\u5316\u5668\u5de5\u4f5c\uff0c\u5728\u540c\u6784\u62d3\u6251\u4e2d\u667a\u80fd\u8f6c\u5411\u97e7\u6027\u589e\u5f3a\u3002", "result": "\u5728\u5f02\u6784\u7f51\u7edc\u4e2d\uff0cSRA\u80fd\u5c06\u5cf0\u503c\u4e2d\u5fc3\u6027\u964d\u4f4e80%\u4ee5\u4e0a\uff0c\u9ad8\u8d1f\u8f7d\u541e\u5410\u91cf\u63d0\u9ad845%\u4ee5\u4e0a\uff1b\u5728\u540c\u6784\u7f51\u7edc\u4e2d\u5219\u4e13\u6ce8\u4e8e\u589e\u5f3a\u7f51\u7edc\u97e7\u6027\u3002", "conclusion": "\u901a\u8fc7\u975e\u5149\u6ed1\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4e25\u683c\u8bc1\u660e\u4e86SRA\u7684\u5168\u5c40\u6536\u655b\u6027\u548c\u5b9e\u9645\u7a33\u5b9a\u6027\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u9884\u6d4b\u7684\u7f51\u7edc\u6cbb\u7406\u8303\u5f0f\uff0c\u667a\u80fd\u5730\u5728\u6027\u80fd\u548c\u97e7\u6027\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2509.17002", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.17002", "abs": "https://arxiv.org/abs/2509.17002", "authors": ["Aharon Rips", "Oron Sabag"], "title": "Communication over LQG Control Systems: A Convex Optimization Approach to Capacity", "comment": null, "summary": "We study communication over control systems, where a controller-encoder\nselects inputs to a dynamical system in order to simultaneously regulate the\nsystem and convey a message to an observer that has access to the system's\noutput measurements. This setup reflects implicit communication, as the\ncontroller embeds a message in the control signal. The capacity of a control\nsystem is the maximal reliable rate of the embedded message subject to a\nclosed-loop control-cost constraint. We focus on linear quadratic Gaussian\n(LQG) control systems, in which the dynamical system is given by a state-space\nmodel with Gaussian noise, and the control cost is a quadratic function of the\nsystem inputs and system states. Our main result is a convex optimization upper\nbound on the capacity of LQG systems. In the case of scalar systems, we prove\nthat the upper bound yields the exact LQG system capacity. The upper bound also\nrecovers all known results, including LQG control, feedback capacity of\nGaussian channels with memory, and the LQG system capacity with a\nstate-feedback. For vector LQG control systems, we provide a sufficient\ncondition for tightness of the upper bound, based on the Riccati equation.\nNumerical simulations indicate the upper bound tightness in all tested\nexamples, suggesting that the upper bound may be equal to the LQG system\ncapacity in the vector case as well.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u901a\u4fe1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86LQG\u7cfb\u7edf\u5bb9\u91cf\u7684\u51f8\u4f18\u5316\u4e0a\u754c\uff0c\u5e76\u5728\u6807\u91cf\u7cfb\u7edf\u4e2d\u8bc1\u660e\u4e86\u8be5\u4e0a\u754c\u5373\u4e3a\u7cbe\u786e\u5bb9\u91cf\u3002", "motivation": "\u7814\u7a76\u63a7\u5236\u5668\u5982\u4f55\u901a\u8fc7\u63a7\u5236\u4fe1\u53f7\u540c\u65f6\u8c03\u8282\u7cfb\u7edf\u72b6\u6001\u548c\u5411\u89c2\u6d4b\u8005\u4f20\u9012\u4fe1\u606f\uff0c\u63a2\u7d22\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u9690\u5f0f\u901a\u4fe1\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af(LQG)\u63a7\u5236\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u65b9\u6cd5\u63a8\u5bfc\u7cfb\u7edf\u5bb9\u91cf\u4e0a\u754c\uff0c\u5e76\u57fa\u4e8eRiccati\u65b9\u7a0b\u5206\u6790\u5411\u91cf\u7cfb\u7edf\u7684\u7d27\u81f4\u6027\u6761\u4ef6\u3002", "result": "\u5728\u6807\u91cfLQG\u7cfb\u7edf\u4e2d\u8bc1\u660e\u4e86\u51f8\u4f18\u5316\u4e0a\u754c\u5373\u4e3a\u7cbe\u786e\u5bb9\u91cf\uff0c\u5728\u5411\u91cf\u7cfb\u7edf\u4e2d\u6570\u503c\u6a21\u62df\u8868\u660e\u4e0a\u754c\u5177\u6709\u7d27\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u51f8\u4f18\u5316\u4e0a\u754c\u80fd\u591f\u7edf\u4e00\u6db5\u76d6LQG\u63a7\u5236\u3001\u5e26\u8bb0\u5fc6\u9ad8\u65af\u4fe1\u9053\u53cd\u9988\u5bb9\u91cf\u7b49\u591a\u79cd\u5df2\u77e5\u7ed3\u679c\uff0c\u53ef\u80fd\u9002\u7528\u4e8e\u4e00\u822c\u5411\u91cfLQG\u7cfb\u7edf\u7684\u5bb9\u91cf\u8ba1\u7b97\u3002"}}
{"id": "2509.16917", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.16917", "abs": "https://arxiv.org/abs/2509.16917", "authors": ["Daniel Lindenschmitt", "Tobias Jung", "Prudhvi Kumar Kakani", "Torsten Reissland", "Norman Franchi", "Hans D. Schotten"], "title": "Analysis of an Architecture for Integrated Sensing and Communication in 5G OpenRAN", "comment": "2 figures, 2 tables", "summary": "This paper analyzes the functional requirements and architectural\nconsiderations for Integrated Sensing and Communication ( ISAC) in a 5G Open\nRadio Access Network (OpenRAN) environment, with emphasis on secure and modular\ndeployment. Focusing on a mono-static, half-duplex sensing approach, it\nevaluates radar setup options, signal types, and processing placement within\nthe Radio Access Network ( RAN), considering performance and security\nimplications. The proposed architecture minimizes hardware modifications by\nleveraging sniffer Radio Units (RU s) and existing OpenRAN fronthaul\ninterfaces, while protecting sensitive In-phase and Quadrature (I/Q) data and\ncontrol traffic against potential attacks. Security threats, such as passive\nsensing, spoofing, and privacy violations, are mapped to mitigation strategies\nwithin the OpenRAN framework. The result is a deployment blueprint applicable\nto both Public Land Mobile Networks ( PLMNs) and Non-Public Networks (NPNs),\nsupporting future 6G ISAC capabilities in a standards-compliant manner.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e865G OpenRAN\u73af\u5883\u4e2d\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u529f\u80fd\u9700\u6c42\u548c\u67b6\u6784\u8003\u8651\uff0c\u91cd\u70b9\u7814\u7a76\u5b89\u5168\u6a21\u5757\u5316\u90e8\u7f72\uff0c\u63d0\u51fa\u57fa\u4e8e\u55c5\u63a2\u5668\u5c04\u9891\u5355\u5143\u548c\u73b0\u6709\u524d\u4f20\u63a5\u53e3\u7684\u67b6\u6784\uff0c\u6700\u5c0f\u5316\u786c\u4ef6\u4fee\u6539\u5e76\u4fdd\u62a4\u654f\u611f\u6570\u636e\u3002", "motivation": "\u968f\u77405G\u7f51\u7edc\u5411OpenRAN\u67b6\u6784\u6f14\u8fdb\uff0c\u9700\u8981\u5728\u5f00\u653e\u73af\u5883\u4e2d\u5b9e\u73b0\u5b89\u5168\u53ef\u9760\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\uff0c\u540c\u65f6\u4fdd\u62a4\u654f\u611f\u6570\u636e\u514d\u53d7\u6f5c\u5728\u653b\u51fb\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u5355\u7ad9\u534a\u53cc\u5de5\u611f\u77e5\u65b9\u6cd5\uff0c\u8bc4\u4f30\u96f7\u8fbe\u8bbe\u7f6e\u9009\u9879\u3001\u4fe1\u53f7\u7c7b\u578b\u548c\u5728RAN\u4e2d\u7684\u5904\u7406\u4f4d\u7f6e\uff0c\u5229\u7528\u55c5\u63a2\u5668\u5c04\u9891\u5355\u5143\u548c\u73b0\u6709OpenRAN\u524d\u4f20\u63a5\u53e3\u6784\u5efa\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u516c\u5171\u79fb\u52a8\u7f51\u7edc\u548c\u975e\u516c\u5171\u7f51\u7edc\u7684\u90e8\u7f72\u84dd\u56fe\uff0c\u652f\u6301\u672a\u67656G ISAC\u80fd\u529b\uff0c\u5728\u6807\u51c6\u517c\u5bb9\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u5b89\u5168\u90e8\u7f72\u3002", "conclusion": "\u8be5\u67b6\u6784\u6210\u529f\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u5b89\u5168\u9700\u6c42\uff0c\u4e3aOpenRAN\u73af\u5883\u4e2d\u7684ISAC\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\uff0c\u5177\u6709\u54116G\u6f14\u8fdb\u7684\u80fd\u529b\u3002"}}
{"id": "2509.16330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16330", "abs": "https://arxiv.org/abs/2509.16330", "authors": ["Minxing Zhang", "Yi Yang", "Roy Xie", "Bhuwan Dhingra", "Shuyan Zhou", "Jian Pei"], "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "comment": null, "summary": "Large Language Model (LLM)-based agents have emerged as a new paradigm that\nextends LLMs' capabilities beyond text generation to dynamic interaction with\nexternal environments. By integrating reasoning with perception, memory, and\ntool use, agents are increasingly deployed in diverse domains like web\nnavigation and household robotics. A critical challenge, however, lies in\nensuring agent generalizability - the ability to maintain consistent\nperformance across varied instructions, tasks, environments, and domains,\nespecially those beyond agents' fine-tuning data. Despite growing interest, the\nconcept of generalizability in LLM-based agents remains underdefined, and\nsystematic approaches to measure and improve it are lacking. In this survey, we\nprovide the first comprehensive review of generalizability in LLM-based agents.\nWe begin by emphasizing agent generalizability's importance by appealing to\nstakeholders and clarifying the boundaries of agent generalizability by\nsituating it within a hierarchical domain-task ontology. We then review\ndatasets, evaluation dimensions, and metrics, highlighting their limitations.\nNext, we categorize methods for improving generalizability into three groups:\nmethods for the backbone LLM, for agent components, and for their interactions.\nMoreover, we introduce the distinction between generalizable frameworks and\ngeneralizable agents and outline how generalizable frameworks can be translated\ninto agent-level generalizability. Finally, we identify critical challenges and\nfuture directions, including developing standardized frameworks, variance- and\ncost-based metrics, and approaches that integrate methodological innovations\nwith architecture-level designs. By synthesizing progress and highlighting\nopportunities, this survey aims to establish a foundation for principled\nresearch on building LLM-based agents that generalize reliably across diverse\napplications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u5173\u4e8eLLM\u667a\u80fd\u4f53\u6cdb\u5316\u80fd\u529b\u7684\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u8de8\u9886\u57df\u3001\u4efb\u52a1\u548c\u73af\u5883\u65f6\u4fdd\u6301\u6027\u80fd\u4e00\u81f4\u6027\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u548c\u6539\u8fdb\u6cdb\u5316\u80fd\u529b\u7684\u7cfb\u7edf\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4f53\u5728\u7f51\u9875\u5bfc\u822a\u3001\u5bb6\u5ead\u673a\u5668\u4eba\u7b49\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u6307\u4ee4\u3001\u4efb\u52a1\u3001\u73af\u5883\u548c\u9886\u57df\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002\u76ee\u524d\u667a\u80fd\u4f53\u6cdb\u5316\u80fd\u529b\u7684\u6982\u5ff5\u5b9a\u4e49\u4e0d\u6e05\u6670\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6d4b\u91cf\u548c\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5c42\u6b21\u5316\u7684\u9886\u57df-\u4efb\u52a1\u672c\u4f53\u8bba\u6765\u754c\u5b9a\u667a\u80fd\u4f53\u6cdb\u5316\u80fd\u529b\u7684\u8fb9\u754c\uff0c\u56de\u987e\u73b0\u6709\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u7ef4\u5ea6\u548c\u6307\u6807\uff0c\u5c06\u6539\u8fdb\u65b9\u6cd5\u5206\u4e3a\u4e09\u7c7b\uff1a\u9488\u5bf9\u9aa8\u5e72LLM\u7684\u65b9\u6cd5\u3001\u9488\u5bf9\u667a\u80fd\u4f53\u7ec4\u4ef6\u7684\u65b9\u6cd5\u4ee5\u53ca\u9488\u5bf9\u5b83\u4eec\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u53ef\u6cdb\u5316\u6846\u67b6\u4e0e\u53ef\u6cdb\u5316\u667a\u80fd\u4f53\u7684\u533a\u5206\uff0c\u5e76\u9610\u8ff0\u4e86\u5982\u4f55\u5c06\u6846\u67b6\u7ea7\u6cdb\u5316\u8f6c\u5316\u4e3a\u667a\u80fd\u4f53\u7ea7\u6cdb\u5316\u3002\u8bc6\u522b\u4e86\u6807\u51c6\u5316\u6846\u67b6\u5f00\u53d1\u3001\u57fa\u4e8e\u65b9\u5dee\u548c\u6210\u672c\u7684\u6307\u6807\u3001\u65b9\u6cd5\u8bba\u521b\u65b0\u4e0e\u67b6\u6784\u8bbe\u8ba1\u878d\u5408\u7b49\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u672c\u7efc\u8ff0\u65e8\u5728\u4e3a\u6784\u5efa\u80fd\u591f\u53ef\u9760\u6cdb\u5316\u5230\u591a\u6837\u5316\u5e94\u7528\u7684LLM\u667a\u80fd\u4f53\u5efa\u7acb\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u7efc\u5408\u73b0\u6709\u8fdb\u5c55\u548c\u7a81\u51fa\u673a\u9047\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u89c4\u8303\u5316\u7814\u7a76\u3002"}}
{"id": "2509.17202", "categories": ["cs.IT", "cs.HC", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17202", "abs": "https://arxiv.org/abs/2509.17202", "authors": ["Scott E. Allen", "A. David Redish", "Ren\u00e9 F. Kizilcec"], "title": "Fundamental Mechanisms of Human Learning", "comment": null, "summary": "Learning underlies nearly all human behavior and is central to education and\neducation reform. Although recent advances in neuroscience have revealed the\nfundamental structure of learning processes, these insights have yet to be\nintegrated into research and practice. Specifically, neuroscience has found\nthat decision-making is governed by a structured process of perception,\naction-selection, and execution, supported by multiple neural systems with\ndistinct memory stores and learning mechanisms. These systems extract different\ntypes of information (categorical, predictive, structural, and sequential)\nchallenging canonical models of memory used in learning and behavioral science\nresearch by providing a mechanistic account of how humans acquire and use\nknowledge. Because each system learns differently, effective teaching requires\nalignment with system-specific processes. We propose a unified model that\nintegrates these neuroscientific insights, bridging basic mechanisms with\noutcomes in education, identity, belonging, and wellbeing. By translating first\nprinciples of neural information processing into a generalizable framework,\nthis work advances theories of skill acquisition and transfer while\nestablishing a foundation for interdisciplinary research to refine how learning\nis understood and supported across domains of human behavior.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6a21\u578b\uff0c\u6574\u5408\u795e\u7ecf\u79d1\u5b66\u5173\u4e8e\u5b66\u4e60\u8fc7\u7a0b\u7684\u6700\u65b0\u53d1\u73b0\uff0c\u5c06\u57fa\u7840\u795e\u7ecf\u673a\u5236\u4e0e\u6559\u80b2\u6210\u679c\u8054\u7cfb\u8d77\u6765\uff0c\u6311\u6218\u4f20\u7edf\u8bb0\u5fc6\u6a21\u578b\u3002", "motivation": "\u867d\u7136\u795e\u7ecf\u79d1\u5b66\u63ed\u793a\u4e86\u5b66\u4e60\u8fc7\u7a0b\u7684\u57fa\u672c\u7ed3\u6784\uff0c\u4f46\u8fd9\u4e9b\u89c1\u89e3\u5c1a\u672a\u6574\u5408\u5230\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u3002\u8bba\u6587\u65e8\u5728\u5f25\u5408\u795e\u7ecf\u79d1\u5b66\u53d1\u73b0\u4e0e\u6559\u80b2\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u57fa\u4e8e\u795e\u7ecf\u79d1\u5b66\u5173\u4e8e\u51b3\u7b56\u8fc7\u7a0b\uff08\u611f\u77e5\u3001\u884c\u52a8\u9009\u62e9\u3001\u6267\u884c\uff09\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e00\u4e2a\u6574\u5408\u591a\u795e\u7ecf\u7cfb\u7edf\u548c\u4e0d\u540c\u8bb0\u5fc6\u5b58\u50a8\u7684\u7edf\u4e00\u6a21\u578b\u6846\u67b6\u3002", "result": "\u6a21\u578b\u6311\u6218\u4e86\u5b66\u4e60\u548c\u884c\u4e3a\u79d1\u5b66\u4e2d\u4f7f\u7528\u7684\u7ecf\u5178\u8bb0\u5fc6\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4eba\u7c7b\u5982\u4f55\u83b7\u53d6\u548c\u4f7f\u7528\u77e5\u8bc6\u7684\u673a\u5236\u6027\u89e3\u91ca\u3002", "conclusion": "\u901a\u8fc7\u5c06\u795e\u7ecf\u4fe1\u606f\u5904\u7406\u7684\u7b2c\u4e00\u539f\u7406\u8f6c\u5316\u4e3a\u53ef\u63a8\u5e7f\u7684\u6846\u67b6\uff0c\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u6280\u80fd\u83b7\u53d6\u548c\u8fc1\u79fb\u7406\u8bba\uff0c\u4e3a\u8de8\u5b66\u79d1\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.16332", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.16332", "abs": "https://arxiv.org/abs/2509.16332", "authors": ["Stephen Fitz", "Peter Romero", "Steven Basart", "Sipeng Chen", "Jose Hernandez-Orallo"], "title": "Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models", "comment": null, "summary": "Large Language Models increasingly mediate high-stakes interactions,\nintensifying research on their capabilities and safety. While recent work has\nshown that LLMs exhibit consistent and measurable synthetic personality traits,\nlittle is known about how modulating these traits affects model behavior. We\naddress this gap by investigating how psychometric personality control grounded\nin the Big Five framework influences AI behavior in the context of capability\nand safety benchmarks. Our experiments reveal striking effects: for example,\nreducing conscientiousness leads to significant drops in safety-relevant\nmetrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well\nas reduction in general capabilities as measured by MMLU. These findings\nhighlight personality shaping as a powerful and underexplored axis of model\ncontrol that interacts with both safety and general competence. We discuss the\nimplications for safety evaluation, alignment strategies, steering model\nbehavior after deployment, and risks associated with possible exploitation of\nthese findings. Our findings motivate a new line of research on\npersonality-sensitive safety evaluations and dynamic behavioral control in\nLLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u8c03\u8282\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e94\u5927\u4eba\u683c\u7279\u8d28\u5982\u4f55\u5f71\u54cd\u5176\u5728\u80fd\u529b\u548c\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u964d\u4f4e\u5c3d\u8d23\u6027\u4f1a\u663e\u8457\u964d\u4f4e\u5b89\u5168\u6027\u548c\u4e00\u822c\u80fd\u529b\u6307\u6807\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u8868\u660eLLMs\u8868\u73b0\u51fa\u53ef\u6d4b\u91cf\u7684\u5408\u6210\u4eba\u683c\u7279\u8d28\uff0c\u4f46\u5173\u4e8e\u8c03\u8282\u8fd9\u4e9b\u7279\u8d28\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\u7684\u7814\u7a76\u8fd8\u5f88\u7f3a\u4e4f\uff0c\u7279\u522b\u662f\u5728\u80fd\u529b\u548c\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u4e94\u5927\u4eba\u683c\u6846\u67b6\uff0c\u901a\u8fc7\u5fc3\u7406\u6d4b\u91cf\u4eba\u683c\u63a7\u5236\u6765\u7814\u7a76AI\u884c\u4e3a\uff0c\u5728WMDP\u3001TruthfulQA\u3001ETHICS\u3001Sycophancy\u548cMMLU\u7b49\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u964d\u4f4e\u5c3d\u8d23\u6027\u4f1a\u5bfc\u81f4\u5b89\u5168\u76f8\u5173\u6307\u6807\uff08\u5982WMDP\u3001TruthfulQA\u7b49\uff09\u548c\u4e00\u822c\u80fd\u529b\u6307\u6807\uff08MMLU\uff09\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u4eba\u683c\u5851\u9020\u662f\u5f71\u54cd\u6a21\u578b\u5b89\u5168\u548c\u80fd\u529b\u7684\u91cd\u8981\u7ef4\u5ea6\u3002", "conclusion": "\u4eba\u683c\u5851\u9020\u662f\u4e00\u4e2a\u5f3a\u5927\u4f46\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u6a21\u578b\u63a7\u5236\u8f74\uff0c\u4e0e\u5b89\u5168\u6027\u548c\u4e00\u822c\u80fd\u529b\u90fd\u6709\u4ea4\u4e92\u4f5c\u7528\uff0c\u8fd9\u4e3a\u5b89\u5168\u8bc4\u4f30\u3001\u5bf9\u9f50\u7b56\u7565\u548c\u90e8\u7f72\u540e\u884c\u4e3a\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u53ef\u80fd\u88ab\u5229\u7528\u7684\u98ce\u9669\u3002"}}
{"id": "2509.17591", "categories": ["cs.IT", "cs.DS", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17591", "abs": "https://arxiv.org/abs/2509.17591", "authors": ["J. J. Bernal", "J. J. Sim\u00f3n"], "title": "Hyperbolic Sets in Incomplete Tables", "comment": null, "summary": "In this paper, we extend results about the implementation of the\nBerlekamp-Massey-Sakata algorithm on data tables having a number of unknown\nvalues.", "AI": {"tldr": "\u6269\u5c55\u4e86Berlekamp-Massey-Sakata\u7b97\u6cd5\u5728\u5305\u542b\u672a\u77e5\u503c\u6570\u636e\u8868\u4e0a\u7684\u5b9e\u73b0\u7ed3\u679c", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6570\u636e\u8868\u4e2d\u5b58\u5728\u672a\u77e5\u503c\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5b9e\u73b0Berlekamp-Massey-Sakata\u7b97\u6cd5", "method": "\u6269\u5c55Berlekamp-Massey-Sakata\u7b97\u6cd5\u4ee5\u5904\u7406\u5305\u542b\u672a\u77e5\u503c\u7684\u6570\u636e\u8868", "result": "\u63d0\u51fa\u4e86\u80fd\u591f\u5904\u7406\u672a\u77e5\u503c\u7684\u7b97\u6cd5\u5b9e\u73b0\u65b9\u6cd5", "conclusion": "\u8be5\u6269\u5c55\u65b9\u6cd5\u4e3a\u5728\u5b58\u5728\u7f3a\u5931\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5e94\u7528Berlekamp-Massey-Sakata\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.17028", "categories": ["cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.17028", "abs": "https://arxiv.org/abs/2509.17028", "authors": ["Yming Jiang"], "title": "Impact of Packetization on Network Calculus Analysis", "comment": null, "summary": "For packet-switched networks, when the packetization effect is overlooked,\nnetwork calculus analysis can produce faulty results. To exemplify, network\ncalculus analysis is applied in this paper to two basic systems that are\nfundamental or default settings in Time-Sensitive Networking (TSN) and\nDeterministic Networking (DetNet). Through counterexamples, it is revealed that\nfor the two fundamental settings, some widely adopted, network calculus-based\nservice characterization results, known as service curves, which ignore\npacketization, are faulty. In addition, for performance bounds derived from the\nfaulty service curves, it is shown that the validity of the bounds can be\narguable. In particular, the output bound, backlog bound and concatenation\nservice curve results are shown to be also faulty: counterexamples can be\nconstructed. By factoring the packetization effect directly into the service\nmodels, corrected service curves and performance bounds are derived for the two\nbasic systems. These results remind that special care is needed when applying\nnetwork calculus analysis to packet-switched networks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u53cd\u4f8b\u8bc1\u660e\uff0c\u5728\u5ffd\u7565\u5206\u7ec4\u5316\u6548\u5e94\u65f6\uff0c\u7f51\u7edc\u6f14\u7b97\u5206\u6790\u4f1a\u4ea7\u751f\u9519\u8bef\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728TSN\u548cDetNet\u7684\u57fa\u672c\u7cfb\u7edf\u4e2d\u3002\u4f5c\u8005\u4fee\u6b63\u4e86\u670d\u52a1\u66f2\u7ebf\u548c\u6027\u80fd\u754c\u9650\uff0c\u5f3a\u8c03\u5728\u5206\u7ec4\u4ea4\u6362\u7f51\u7edc\u4e2d\u5e94\u7528\u7f51\u7edc\u6f14\u7b97\u5206\u6790\u9700\u8981\u7279\u522b\u8c28\u614e\u3002", "motivation": "\u9488\u5bf9\u5206\u7ec4\u4ea4\u6362\u7f51\u7edc\u4e2d\u5ffd\u7565\u5206\u7ec4\u5316\u6548\u5e94\u5bfc\u81f4\u7f51\u7edc\u6f14\u7b97\u5206\u6790\u4ea7\u751f\u9519\u8bef\u7ed3\u679c\u7684\u95ee\u9898\uff0c\u7814\u7a76TSN\u548c\u786e\u5b9a\u6027\u7f51\u7edc\u57fa\u672c\u7cfb\u7edf\u4e2d\u7684\u670d\u52a1\u66f2\u7ebf\u548c\u6027\u80fd\u754c\u9650\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u6784\u9020\u53cd\u4f8b\uff0c\u5206\u6790\u4e24\u79cd\u57fa\u672c\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u91c7\u7528\u4f46\u5ffd\u7565\u5206\u7ec4\u5316\u6548\u5e94\u7684\u7f51\u7edc\u6f14\u7b97\u670d\u52a1\u66f2\u7ebf\uff0c\u5e76\u76f4\u63a5\u8003\u8651\u5206\u7ec4\u5316\u6548\u5e94\u63a8\u5bfc\u4fee\u6b63\u7684\u670d\u52a1\u66f2\u7ebf\u548c\u6027\u80fd\u754c\u9650\u3002", "result": "\u63ed\u793a\u4e86\u4e24\u79cd\u57fa\u672c\u8bbe\u7f6e\u4e2d\u5ffd\u7565\u5206\u7ec4\u5316\u6548\u5e94\u7684\u670d\u52a1\u66f2\u7ebf\u662f\u9519\u8bef\u7684\uff0c\u8f93\u51fa\u754c\u9650\u3001\u79ef\u538b\u754c\u9650\u548c\u7ea7\u8054\u670d\u52a1\u66f2\u7ebf\u7ed3\u679c\u4e5f\u5b58\u5728\u95ee\u9898\u3002\u901a\u8fc7\u8003\u8651\u5206\u7ec4\u5316\u6548\u5e94\uff0c\u5f97\u51fa\u4e86\u4fee\u6b63\u7684\u670d\u52a1\u66f2\u7ebf\u548c\u6027\u80fd\u754c\u9650\u3002", "conclusion": "\u5728\u5206\u7ec4\u4ea4\u6362\u7f51\u7edc\u4e2d\u5e94\u7528\u7f51\u7edc\u6f14\u7b97\u5206\u6790\u65f6\u9700\u8981\u7279\u522b\u8c28\u614e\uff0c\u5fc5\u987b\u8003\u8651\u5206\u7ec4\u5316\u6548\u5e94\uff0c\u5426\u5219\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7684\u5206\u6790\u7ed3\u679c\u3002"}}
{"id": "2509.16348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16348", "abs": "https://arxiv.org/abs/2509.16348", "authors": ["Minxiao Wang", "Saurabh Kataria", "Juntong Ni", "Timothy G. Buchman", "Jocelyn Grunwell", "Mark Mai", "Wei Jin", "Matthew Clark", "Stephanie Brown", "Michael Fundora", "Puneet Sharma", "Tony Pan", "Sam Khan", "Timothy Ruchti", "Naveen Muthu", "Kevin Maher", "Sivasubramanium V Bhavani", "Xiao Hu"], "title": "A Unified AI Approach for Continuous Monitoring of Human Health and Diseases from Intensive Care Unit to Home with Physiological Foundation Models (UNIPHY+)", "comment": null, "summary": "We present UNIPHY+, a unified physiological foundation model (physioFM)\nframework designed to enable continuous human health and diseases monitoring\nacross care settings using ubiquitously obtainable physiological data. We\npropose novel strategies for incorporating contextual information during\npretraining, fine-tuning, and lightweight model personalization via multi-modal\nlearning, feature fusion-tuning, and knowledge distillation. We advocate\ntesting UNIPHY+ with a broad set of use cases from intensive care to ambulatory\nmonitoring in order to demonstrate that UNIPHY+ can empower generalizable,\nscalable, and personalized physiological AI to support both clinical\ndecision-making and long-term health monitoring.", "AI": {"tldr": "UNIPHY+\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u7406\u57fa\u7840\u6a21\u578b\u6846\u67b6\uff0c\u65e8\u5728\u5229\u7528\u666e\u904d\u53ef\u83b7\u53d6\u7684\u751f\u7406\u6570\u636e\u5b9e\u73b0\u8de8\u62a4\u7406\u573a\u666f\u7684\u8fde\u7eed\u4eba\u7c7b\u5065\u5eb7\u548c\u75be\u75c5\u76d1\u6d4b", "motivation": "\u5f00\u53d1\u80fd\u591f\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u548c\u957f\u671f\u5065\u5eb7\u76d1\u6d4b\u7684\u901a\u7528\u3001\u53ef\u6269\u5c55\u4e14\u4e2a\u6027\u5316\u7684\u751f\u7406AI\u7cfb\u7edf", "method": "\u63d0\u51fa\u5728\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u548c\u8f7b\u91cf\u7ea7\u6a21\u578b\u4e2a\u6027\u5316\u9636\u6bb5\u6574\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u7b56\u7565\uff0c\u5305\u62ec\u591a\u6a21\u6001\u5b66\u4e60\u3001\u7279\u5f81\u878d\u5408\u8c03\u4f18\u548c\u77e5\u8bc6\u84b8\u998f", "result": "\u8be5\u6846\u67b6\u5728\u4ece\u91cd\u75c7\u76d1\u62a4\u5230\u52a8\u6001\u76d1\u6d4b\u7684\u5e7f\u6cdb\u7528\u4f8b\u4e2d\u8fdb\u884c\u6d4b\u8bd5", "conclusion": "UNIPHY+\u80fd\u591f\u8d4b\u80fd\u901a\u7528\u5316\u3001\u53ef\u6269\u5c55\u548c\u4e2a\u6027\u5316\u7684\u751f\u7406AI\uff0c\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u548c\u957f\u671f\u5065\u5eb7\u76d1\u6d4b"}}
{"id": "2509.17597", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17597", "abs": "https://arxiv.org/abs/2509.17597", "authors": ["J. J. Bernal", "J. J. Sim\u00f3n"], "title": "A Note on the Theoretical Support to Compute Dimension in Abelian Codes", "comment": null, "summary": "In this note we give a theoretical support by means of quotient polynomial\nrings for the computation formulas of the dimension of abelian codes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5546\u591a\u9879\u5f0f\u73af\u7406\u8bba\u4e3a\u963f\u8d1d\u5c14\u7801\u7684\u7ef4\u6570\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301", "motivation": "\u4e3a\u963f\u8d1d\u5c14\u7801\u7684\u7ef4\u6570\u8ba1\u7b97\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u548c\u6570\u5b66\u652f\u6491", "method": "\u4f7f\u7528\u5546\u591a\u9879\u5f0f\u73af\u7406\u8bba\u6765\u5206\u6790\u548c\u63a8\u5bfc\u963f\u8d1d\u5c14\u7801\u7684\u7ef4\u6570\u8ba1\u7b97\u516c\u5f0f", "result": "\u5efa\u7acb\u4e86\u57fa\u4e8e\u5546\u591a\u9879\u5f0f\u73af\u7684\u963f\u8d1d\u5c14\u7801\u7ef4\u6570\u8ba1\u7b97\u7684\u7406\u8bba\u6846\u67b6", "conclusion": "\u5546\u591a\u9879\u5f0f\u73af\u7406\u8bba\u4e3a\u963f\u8d1d\u5c14\u7801\u7ef4\u6570\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u5b66\u5de5\u5177\u548c\u7406\u8bba\u57fa\u7840"}}
{"id": "2509.17398", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.17398", "abs": "https://arxiv.org/abs/2509.17398", "authors": ["Wei Wei", "Zheng Lin", "Xihui Liu", "Hongyang Du", "Dusit Niyato", "Xianhao Chen"], "title": "Optimizing Split Federated Learning with Unstable Client Participation", "comment": null, "summary": "To enable training of large artificial intelligence (AI) models at the\nnetwork edge, split federated learning (SFL) has emerged as a promising\napproach by distributing computation between edge devices and a server.\nHowever, while unstable network environments pose significant challenges to\nSFL, prior schemes often overlook such an effect by assuming perfect client\nparticipation, rendering them impractical for real-world scenarios. In this\nwork, we develop an optimization framework for SFL with unstable client\nparticipation. We theoretically derive the first convergence upper bound for\nSFL with unstable client participation by considering activation uploading\nfailures, gradient downloading failures, and model aggregation failures. Based\non the theoretical results, we formulate a joint optimization problem for\nclient sampling and model splitting to minimize the upper bound. We then\ndevelop an efficient solution approach to solve the problem optimally.\nExtensive simulations on EMNIST and CIFAR-10 demonstrate the superiority of our\nproposed framework compared to existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u4e0d\u7a33\u5b9a\u5ba2\u6237\u7aef\u53c2\u4e0e\u7684\u62c6\u5206\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u6536\u655b\u4e0a\u754c\uff0c\u5e76\u5f00\u53d1\u4e86\u8054\u5408\u4f18\u5316\u5ba2\u6237\u7aef\u91c7\u6837\u548c\u6a21\u578b\u62c6\u5206\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u62c6\u5206\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5b8c\u7f8e\u7684\u5ba2\u6237\u7aef\u53c2\u4e0e\uff0c\u5ffd\u7565\u4e86\u4e0d\u7a33\u5b9a\u7f51\u7edc\u73af\u5883\u5e26\u6765\u7684\u6311\u6218\uff0c\u8fd9\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u4e0d\u5b9e\u7528\u3002", "method": "\u7406\u8bba\u63a8\u5bfc\u4e86\u8003\u8651\u6fc0\u6d3b\u4e0a\u4f20\u5931\u8d25\u3001\u68af\u5ea6\u4e0b\u8f7d\u5931\u8d25\u548c\u6a21\u578b\u805a\u5408\u5931\u8d25\u7684\u6536\u655b\u4e0a\u754c\uff0c\u7136\u540e\u6784\u5efa\u4e86\u8054\u5408\u4f18\u5316\u5ba2\u6237\u7aef\u91c7\u6837\u548c\u6a21\u578b\u62c6\u5206\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u6c42\u89e3\u65b9\u6cd5\u3002", "result": "\u5728EMNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u4eff\u771f\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4e0d\u7a33\u5b9a\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u62c6\u5206\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2509.16372", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16372", "abs": "https://arxiv.org/abs/2509.16372", "authors": ["Balu Bhasuran", "Mattia Prosperi", "Karim Hanna", "John Petrilli", "Caretia JeLayne Washington", "Zhe He"], "title": "Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation", "comment": null, "summary": "This study evaluates causal reasoning in large language models (LLMs) using\n99 clinically grounded laboratory test scenarios aligned with Pearl's Ladder of\nCausation: association, intervention, and counterfactual reasoning. We examined\ncommon laboratory tests such as hemoglobin A1c, creatinine, and vitamin D, and\npaired them with relevant causal factors including age, gender, obesity, and\nsmoking. Two LLMs - GPT-o1 and Llama-3.2-8b-instruct - were tested, with\nresponses evaluated by four medically trained human experts. GPT-o1\ndemonstrated stronger discriminative performance (AUROC overall = 0.80 +/-\n0.12) compared to Llama-3.2-8b-instruct (0.73 +/- 0.15), with higher scores\nacross association (0.75 vs 0.72), intervention (0.84 vs 0.70), and\ncounterfactual reasoning (0.84 vs 0.69). Sensitivity (0.90 vs 0.84) and\nspecificity (0.93 vs 0.80) were also greater for GPT-o1, with reasoning ratings\nshowing similar trends. Both models performed best on intervention questions\nand worst on counterfactuals, particularly in altered outcome scenarios. These\nfindings suggest GPT-o1 provides more consistent causal reasoning, but\nrefinement is required before adoption in high-stakes clinical applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u573a\u666f\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0cGPT-o1\u5728\u5173\u8054\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\u65b9\u9762\u5747\u4f18\u4e8eLlama-3.2-8b-instruct\uff0c\u4f46\u4e24\u8005\u5728\u53cd\u4e8b\u5b9e\u63a8\u7406\u573a\u666f\u4e2d\u8868\u73b0\u6700\u5dee\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u624d\u80fd\u7528\u4e8e\u9ad8\u98ce\u9669\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u57fa\u4e8ePearl\u56e0\u679c\u9636\u68af\u7684\u4e09\u4e2a\u5c42\u6b21\uff1a\u5173\u8054\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\uff0c\u4ee5\u786e\u5b9a\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u9002\u5408\u7528\u4e8e\u9ad8\u98ce\u9669\u7684\u533b\u7597\u51b3\u7b56\u652f\u6301\u3002", "method": "\u4f7f\u752899\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u7684\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u573a\u666f\uff0c\u6db5\u76d6\u8840\u7ea2\u86cb\u767dA1c\u3001\u808c\u9150\u3001\u7ef4\u751f\u7d20D\u7b49\u5e38\u89c1\u6d4b\u8bd5\uff0c\u7ed3\u5408\u5e74\u9f84\u3001\u6027\u522b\u3001\u80a5\u80d6\u3001\u5438\u70df\u7b49\u56e0\u679c\u56e0\u7d20\u3002\u6d4b\u8bd5GPT-o1\u548cLlama-3.2-8b-instruct\u4e24\u4e2a\u6a21\u578b\uff0c\u7531\u56db\u4f4d\u533b\u5b66\u4e13\u5bb6\u8bc4\u4f30\u54cd\u5e94\u8d28\u91cf\u3002", "result": "GPT-o1\u5728\u6574\u4f53\u5224\u522b\u6027\u80fd\uff08AUROC = 0.80\uff09\u4e0a\u4f18\u4e8eLlama-3.2-8b-instruct\uff080.73\uff09\uff0c\u5728\u5173\u8054\uff080.75 vs 0.72\uff09\u3001\u5e72\u9884\uff080.84 vs 0.70\uff09\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\uff080.84 vs 0.69\uff09\u65b9\u9762\u5747\u8868\u73b0\u66f4\u597d\u3002\u4e24\u4e2a\u6a21\u578b\u5728\u5e72\u9884\u95ee\u9898\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5728\u53cd\u4e8b\u5b9e\u63a8\u7406\uff08\u7279\u522b\u662f\u6539\u53d8\u7ed3\u679c\u573a\u666f\uff09\u4e2d\u8868\u73b0\u6700\u5dee\u3002", "conclusion": "GPT-o1\u63d0\u4f9b\u4e86\u66f4\u4e00\u81f4\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u4e34\u5e8a\u73af\u5883\u4e4b\u524d\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u53cd\u4e8b\u5b9e\u63a8\u7406\u65b9\u9762\u3002"}}
{"id": "2509.17682", "categories": ["cs.IT", "math.AG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17682", "abs": "https://arxiv.org/abs/2509.17682", "authors": ["Mahir Bilen Can", "Dillon Montero", "Ferruh \u00d6zbudak"], "title": "Evaluation Codes in Bottleneck Metrics", "comment": null, "summary": "Analogs of Reed-Solomon codes are introduced within the framework of\nbottleneck poset metrics. These codes are proven to be maximum distance\nseparable. Furthermore, the results are extended to the setting of Algebraic\nGeometry codes.", "AI": {"tldr": "\u672c\u6587\u5728\u74f6\u9888\u504f\u5e8f\u96c6\u5ea6\u91cf\u6846\u67b6\u4e0b\u5f15\u5165\u4e86Reed-Solomon\u7801\u7684\u7c7b\u4f3c\u7269\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u7801\u662f\u6700\u5927\u8ddd\u79bb\u53ef\u5206\u7801\uff0c\u5e76\u5c06\u7ed3\u679c\u6269\u5c55\u5230\u4ee3\u6570\u51e0\u4f55\u7801\u7684\u8bbe\u7f6e\u3002", "motivation": "\u5728\u74f6\u9888\u504f\u5e8f\u96c6\u5ea6\u91cf\u6846\u67b6\u4e0b\u63a2\u7d22Reed-Solomon\u7801\u7684\u7c7b\u4f3c\u7269\uff0c\u4ee5\u6269\u5c55\u7f16\u7801\u7406\u8bba\u7684\u5e94\u7528\u8303\u56f4\u5e76\u7814\u7a76\u5176\u6700\u5927\u8ddd\u79bb\u53ef\u5206\u6027\u8d28\u3002", "method": "\u5728\u74f6\u9888\u504f\u5e8f\u96c6\u5ea6\u91cf\u6846\u67b6\u4e0b\u6784\u9020Reed-Solomon\u7801\u7684\u7c7b\u4f3c\u7269\uff0c\u5e76\u5206\u6790\u5176\u8ddd\u79bb\u7279\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u4e9b\u6784\u9020\u7684\u7801\u662f\u6700\u5927\u8ddd\u79bb\u53ef\u5206\u7801\uff0c\u5e76\u5c06\u7ed3\u679c\u6210\u529f\u6269\u5c55\u5230\u4ee3\u6570\u51e0\u4f55\u7801\u7684\u8bbe\u7f6e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u74f6\u9888\u504f\u5e8f\u96c6\u5ea6\u91cf\u6846\u67b6\u4e0b\u8bbe\u8ba1\u6700\u5927\u8ddd\u79bb\u53ef\u5206\u7801\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u4ee3\u6570\u51e0\u4f55\u7801\u7684\u5e94\u7528\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.17676", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.17676", "abs": "https://arxiv.org/abs/2509.17676", "authors": ["Abdullahi Isa Ahmed", "Jamal Bentahar", "El Mehdi Amhoud"], "title": "GLo-MAPPO: A Multi-Agent Proximal Policy Optimization for Energy Efficiency in UAV-Assisted LoRa Networks", "comment": "15 pages, 19 figures, journal", "summary": "Long Range (LoRa) based low-power wide area networks (LPWANs) are crucial for\nenabling next-generation IoT (NG-IoT) applications in 5G/6G ecosystems due to\ntheir long-range, low-power, and low-cost characteristics. However, achieving\nhigh energy efficiency in such networks remains a critical challenge,\nparticularly in large-scale or dynamically changing environments. Traditional\nterrestrial LoRa deployments often suffer from coverage gaps and\nnon-line-of-sight (NLoS) propagation losses, while satellite-based IoT\nsolutions consume excessive energy and introduce high latency, limiting their\nsuitability for energy-constrained and delay-sensitive applications. To address\nthese limitations, we propose a novel architecture using multiple unmanned\naerial vehicles (UAVs) as flying LoRa gateways to dynamically collect data from\nground-based LoRa end devices. Our approach aims to maximize the system's\nweighted global energy efficiency by jointly optimizing spreading factors,\ntransmission powers, UAV trajectories, and end-device associations.\nAdditionally, we formulate this complex optimization problem as a partially\nobservable Markov decision process (POMDP) and propose green LoRa multi-agent\nproximal policy optimization (GLo-MAPPO), a multi-agent reinforcement learning\n(MARL) framework based on centralized training with decentralized execution\n(CTDE). Simulation results show that GLo-MAPPO significantly outperforms\nbenchmark algorithms, achieving energy efficiency improvements of 71.25%,\n18.56%, 67.00%, 59.73%, and 49.95% for networks with 10, 20, 30, 40, and 50\nLoRa end devices, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u65e0\u4eba\u673a\u4f5c\u4e3aLoRa\u7f51\u5173\u7684\u65b0\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6269\u9891\u56e0\u5b50\u3001\u4f20\u8f93\u529f\u7387\u3001\u65e0\u4eba\u673a\u8f68\u8ff9\u548c\u8bbe\u5907\u5173\u8054\uff0c\u6700\u5927\u5316\u7cfb\u7edf\u52a0\u6743\u5168\u5c40\u80fd\u91cf\u6548\u7387\uff0c\u5e76\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6GLo-MAPPO\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5730\u9762LoRa\u90e8\u7f72\u5b58\u5728\u8986\u76d6\u76f2\u533a\u548c\u975e\u89c6\u8ddd\u4f20\u64ad\u635f\u8017\uff0c\u800c\u57fa\u4e8e\u536b\u661f\u7684\u7269\u8054\u7f51\u89e3\u51b3\u65b9\u6848\u80fd\u8017\u9ad8\u3001\u5ef6\u8fdf\u5927\uff0c\u65e0\u6cd5\u6ee1\u8db3\u80fd\u6e90\u53d7\u9650\u548c\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u591a\u65e0\u4eba\u673a\u4f5c\u4e3a\u98de\u884cLoRa\u7f51\u5173\u52a8\u6001\u6536\u96c6\u5730\u9762LoRa\u7ec8\u7aef\u8bbe\u5907\u6570\u636e\uff0c\u5c06\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u63d0\u51fa\u57fa\u4e8e\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c\u7684GLo-MAPPO\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cGLo-MAPPO\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u7b97\u6cd5\uff0c\u572810\u300120\u300130\u300140\u548c50\u4e2aLoRa\u7ec8\u7aef\u8bbe\u5907\u7684\u7f51\u7edc\u4e2d\u5206\u522b\u5b9e\u73b0\u4e8671.25%\u300118.56%\u300167.00%\u300159.73%\u548c49.95%\u7684\u80fd\u91cf\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u591a\u65e0\u4eba\u673aLoRa\u7f51\u5173\u67b6\u6784\u548cGLo-MAPPO\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e0b\u4e00\u4ee3\u7269\u8054\u7f51\u5e94\u7528\u4e2d\u7684\u80fd\u91cf\u6548\u7387\u6311\u6218\uff0c\u4e3a5G/6G\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u4f4e\u529f\u8017\u5e7f\u57df\u7f51\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.16399", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16399", "abs": "https://arxiv.org/abs/2509.16399", "authors": ["Guojun Xiong", "Milind Tambe"], "title": "VORTEX: Aligning Task Utility and Human Preferences through LLM-Guided Reward Shaping", "comment": "28pages, 19figures", "summary": "In social impact optimization, AI decision systems often rely on solvers that\noptimize well-calibrated mathematical objectives. However, these solvers cannot\ndirectly accommodate evolving human preferences, typically expressed in natural\nlanguage rather than formal constraints. Recent approaches address this by\nusing large language models (LLMs) to generate new reward functions from\npreference descriptions. While flexible, they risk sacrificing the system's\ncore utility guarantees. In this paper, we propose \\texttt{VORTEX}, a\nlanguage-guided reward shaping framework that preserves established\noptimization goals while adaptively incorporating human feedback. By\nformalizing the problem as multi-objective optimization, we use LLMs to\niteratively generate shaping rewards based on verbal reinforcement and\ntext-gradient prompt updates. This allows stakeholders to steer decision\nbehavior via natural language without modifying solvers or specifying trade-off\nweights. We provide theoretical guarantees that \\texttt{VORTEX} converges to\nPareto-optimal trade-offs between utility and preference satisfaction.\nEmpirical results in real-world allocation tasks demonstrate that\n\\texttt{VORTEX} outperforms baselines in satisfying human-aligned coverage\ngoals while maintaining high task performance. This work introduces a practical\nand theoretically grounded paradigm for human-AI collaborative optimization\nguided by natural language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVORTEX\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u8a00\u5f15\u5bfc\u7684\u5956\u52b1\u5851\u9020\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6838\u5fc3\u4f18\u5316\u76ee\u6807\u7684\u540c\u65f6\u81ea\u9002\u5e94\u6574\u5408\u4eba\u7c7b\u504f\u597d\u53cd\u9988", "motivation": "\u73b0\u6709AI\u51b3\u7b56\u7cfb\u7edf\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u7684\u4eba\u7c7b\u504f\u597d\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u867d\u7136\u7075\u6d3b\u4f46\u53ef\u80fd\u727a\u7272\u7cfb\u7edf\u6838\u5fc3\u6548\u7528\u4fdd\u8bc1", "method": "\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u591a\u76ee\u6807\u4f18\u5316\uff0c\u4f7f\u7528LLM\u57fa\u4e8e\u8bed\u8a00\u53cd\u9988\u548c\u6587\u672c\u68af\u5ea6\u63d0\u793a\u8fed\u4ee3\u751f\u6210\u5851\u9020\u5956\u52b1\uff0c\u65e0\u9700\u4fee\u6539\u6c42\u89e3\u5668\u6216\u6307\u5b9a\u6743\u8861\u6743\u91cd", "result": "\u7406\u8bba\u8bc1\u660eVORTEX\u6536\u655b\u5230\u6548\u7528\u548c\u504f\u597d\u6ee1\u610f\u5ea6\u4e4b\u95f4\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u6743\u8861\uff0c\u5b9e\u8bc1\u663e\u793a\u5728\u73b0\u5b9e\u5206\u914d\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u4eba\u7c7b-AI\u534f\u4f5c\u4f18\u5316\u5f15\u5165\u4e86\u5b9e\u7528\u4e14\u7406\u8bba\u57fa\u7840\u7684\u8303\u5f0f"}}
{"id": "2509.17735", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17735", "abs": "https://arxiv.org/abs/2509.17735", "authors": ["Jannis Clausius", "Luca Schmid", "Laurent Schmalen", "Stephan ten Brink"], "title": "Symbol Detection in Inter-Symbol Interference Channels using Expectation Propagation with Channel Shortening", "comment": "Submitted to ICASSP", "summary": "Iterative message passing detection based on expectation propagation(EP) has\ndemonstrated near-optimum performance in many signal processing and\ncommunication scenarios. The method remains feasible even for channel impulse\nresponses (CIRs), where the optimal Bahl-Cocke-Jelinek-Raviv (BCJR) detector is\ninfeasible. However, significant performance degradation occurs for channels\nwith strong inter-symbol interference (ISI), where the initial linear minimum\nmean square error (LMMSE) estimate is inaccurate. We propose an EP-based\ndetector that operates in a transformed signal space obtained by channel\nshortening. Specifically, instead of the conventional approach that iterates\nbetween an LMMSE estimator and a non-linear symbol-wise demapper, the proposed\nmethod iterates between a linear channel shortening filter-based estimator and\na nonlinear BCJR detector with reduced memory compared to the actual channel.\nAdditionally, we propose a deliberate mismatch between the initialized messages\nand the initialized covariance used in the linear estimator in the first\niteration for faster convergence. The proposed approach is evaluated for the\nwell-known Proakis-C ISI channel and for CIRs from a wireless measurement\ncampaign. We demonstrate improvements of up to 6dB at 2 bits per channel use\nand an improved performance-complexity trade-off over conventional EP-based\ndetection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u671f\u671b\u4f20\u64ad(EP)\u7684\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u5728\u4fe1\u9053\u7f29\u77ed\u540e\u7684\u53d8\u6362\u4fe1\u53f7\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u6539\u8fdb\u4e86\u4f20\u7edfEP\u68c0\u6d4b\u5668\u5728\u5f3a\u7b26\u53f7\u95f4\u5e72\u6270(ISI)\u4fe1\u9053\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eEP\u7684\u8fed\u4ee3\u6d88\u606f\u4f20\u9012\u68c0\u6d4b\u5728\u5f3aISI\u4fe1\u9053\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u4e3a\u521d\u59cb\u7ebf\u6027\u6700\u5c0f\u5747\u65b9\u8bef\u5dee(LMMSE)\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002", "method": "\u5728\u4fe1\u9053\u7f29\u77ed\u540e\u7684\u53d8\u6362\u4fe1\u53f7\u7a7a\u95f4\u4e2d\u8fed\u4ee3\u64cd\u4f5c\uff0c\u4f7f\u7528\u7ebf\u6027\u4fe1\u9053\u7f29\u77ed\u6ee4\u6ce2\u5668\u4f30\u8ba1\u5668\u548c\u5177\u6709\u51cf\u5c11\u8bb0\u5fc6\u7684\u975e\u7ebf\u6027BCJR\u68c0\u6d4b\u5668\uff0c\u5e76\u5728\u7b2c\u4e00\u6b21\u8fed\u4ee3\u4e2d\u6545\u610f\u4e0d\u5339\u914d\u521d\u59cb\u5316\u6d88\u606f\u548c\u534f\u65b9\u5dee\u4ee5\u52a0\u901f\u6536\u655b\u3002", "result": "\u5728Proakis-C ISI\u4fe1\u9053\u548c\u65e0\u7ebf\u6d4b\u91cfCIR\u4e0a\u8bc4\u4f30\uff0c\u57282\u6bd4\u7279/\u4fe1\u9053\u4f7f\u7528\u65f6\u6027\u80fd\u63d0\u5347\u8fbe6dB\uff0c\u5e76\u6539\u5584\u4e86\u6027\u80fd-\u590d\u6742\u5ea6\u6743\u8861\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edfEP\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5728\u5f3aISI\u4fe1\u9053\u4e2d\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u68c0\u6d4b\u6027\u80fd\u548c\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2509.18007", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18007", "abs": "https://arxiv.org/abs/2509.18007", "authors": ["Riya Ponraj", "Ram Durairajan", "Yu Wang"], "title": "Building Transparency in Deep Learning-Powered Network Traffic Classification: A Traffic-Explainer Framework", "comment": null, "summary": "Recent advancements in deep learning have significantly enhanced the\nperformance and efficiency of traffic classification in networking systems.\nHowever, the lack of transparency in their predictions and decision-making has\nmade network operators reluctant to deploy DL-based solutions in production\nnetworks. To tackle this challenge, we propose Traffic-Explainer, a\nmodel-agnostic and input-perturbation-based traffic explanation framework. By\nmaximizing the mutual information between predictions on original traffic\nsequences and their masked counterparts, Traffic-Explainer automatically\nuncovers the most influential features driving model predictions. Extensive\nexperiments demonstrate that Traffic-Explainer improves upon existing\nexplanation methods by approximately 42%. Practically, we further apply\nTraffic-Explainer to identify influential features and demonstrate its enhanced\ntransparency across three critical tasks: application classification, traffic\nlocalization, and network cartography. For the first two tasks,\nTraffic-Explainer identifies the most decisive bytes that drive predicted\ntraffic applications and locations, uncovering potential vulnerabilities and\nprivacy concerns. In network cartography, Traffic-Explainer identifies\nsubmarine cables that drive the mapping of traceroute to physical path,\nenabling a traceroute-informed risk analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86Traffic-Explainer\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u539f\u59cb\u6d41\u91cf\u5e8f\u5217\u4e0e\u5176\u63a9\u7801\u7248\u672c\u9884\u6d4b\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\uff0c\u81ea\u52a8\u8bc6\u522b\u5f71\u54cd\u6a21\u578b\u9884\u6d4b\u7684\u6700\u5173\u952e\u7279\u5f81\uff0c\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6d41\u91cf\u5206\u7c7b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u6d41\u91cf\u5206\u7c7b\u4e2d\u6027\u80fd\u4f18\u5f02\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u5bfc\u81f4\u7f51\u7edc\u8fd0\u8425\u5546\u4e0d\u613f\u5728\u751f\u4ea7\u7f51\u7edc\u4e2d\u90e8\u7f72DL\u89e3\u51b3\u65b9\u6848\u3002\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u57fa\u4e8e\u6a21\u578b\u65e0\u5173\u548c\u8f93\u5165\u6270\u52a8\u7684\u6d41\u91cf\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u539f\u59cb\u6d41\u91cf\u5e8f\u5217\u4e0e\u63a9\u7801\u7248\u672c\u9884\u6d4b\u7684\u4e92\u4fe1\u606f\u6765\u8bc6\u522b\u5173\u952e\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTraffic-Explainer\u6bd4\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u63d0\u5347\u7ea642%\uff0c\u5728\u5e94\u7528\u5206\u7c7b\u3001\u6d41\u91cf\u5b9a\u4f4d\u548c\u7f51\u7edc\u5730\u56fe\u7ed8\u5236\u4e09\u4e2a\u5173\u952e\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u900f\u660e\u5ea6\u3002", "conclusion": "Traffic-Explainer\u80fd\u6709\u6548\u8bc6\u522b\u9a71\u52a8\u6a21\u578b\u9884\u6d4b\u7684\u5173\u952e\u7279\u5f81\uff0c\u6709\u52a9\u4e8e\u53d1\u73b0\u6f5c\u5728\u6f0f\u6d1e\u548c\u9690\u79c1\u95ee\u9898\uff0c\u652f\u6301\u57fa\u4e8etraceroute\u7684\u98ce\u9669\u5206\u6790\u3002"}}
{"id": "2509.16431", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16431", "abs": "https://arxiv.org/abs/2509.16431", "authors": ["Mohammad Iqbal Rasul Seeam", "Victor S. Sheng"], "title": "Proactive Statistical Process Control Using AI: A Time Series Forecasting Approach for Semiconductor Manufacturing", "comment": "7 pages, 3 figures, no .bbl file needed because bibliography already\n  in main.tex file", "summary": "In the manufacturing industry, it is very important to keep machines and\nprocesses running smoothly and without unexpected problems. One of the most\ncommon tools used to check if everything is working properly is called\nStatistical Process Control (SPC). Traditional SPC methods work by checking\nwhether recent measurements are within acceptable limits. However, they only\nreact after a problem has already occurred. This can lead to wasted materials,\nmachine downtime, and increased costs. In this paper, we present a smarter way\nto use SPC. Instead of just reacting to issues after they happen, our system\ncan predict future problems before they occur. We use a machine learning tool\ncalled Facebook Prophet, which is designed to work with time-series data (data\nthat changes over time). Prophet looks at past data and forecasts what the next\nvalue will be. Then, we use SPC rules to decide if the predicted value is in a\nSafe zone (no problem), a Warning zone (needs attention), or a Critical zone\n(may require shutting down the process). We applied this system to real data\nfrom a semiconductor manufacturing company. One of the challenges with this\ndata is that the measurements are not taken at regular time intervals. This\nmakes it harder to predict future values accurately. Despite this, our model\nwas able to make strong predictions and correctly classify the risk level of\nfuture measurements. The main benefit of our system is that it gives engineers\nand technicians a chance to act early - before something goes wrong. This helps\nreduce unexpected failures and improves the overall stability and reliability\nof the production process. By combining machine learning with traditional SPC,\nwe make quality control more proactive, accurate, and useful for modern\nindustry.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Facebook Prophet\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u4f20\u7edf\u7edf\u8ba1\u8fc7\u7a0b\u63a7\u5236(SPC)\u7684\u667a\u80fd\u9884\u6d4b\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u5236\u9020\u8fc7\u7a0b\u4e2d\u63d0\u524d\u9884\u6d4b\u95ee\u9898\uff0c\u5b9e\u73b0\u4e3b\u52a8\u8d28\u91cf\u63a7\u5236\u3002", "motivation": "\u4f20\u7edfSPC\u65b9\u6cd5\u53ea\u80fd\u5728\u95ee\u9898\u53d1\u751f\u540e\u8fdb\u884c\u53cd\u5e94\uff0c\u5bfc\u81f4\u6750\u6599\u6d6a\u8d39\u3001\u673a\u5668\u505c\u673a\u548c\u6210\u672c\u589e\u52a0\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9884\u6d4b\u672a\u6765\u95ee\u9898\u7684\u4e3b\u52a8\u8d28\u91cf\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Facebook Prophet\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u5206\u6790\u5386\u53f2\u6570\u636e\uff0c\u9884\u6d4b\u672a\u6765\u6d4b\u91cf\u503c\uff0c\u7136\u540e\u5e94\u7528SPC\u89c4\u5219\u5c06\u9884\u6d4b\u503c\u5206\u7c7b\u4e3a\u5b89\u5168\u533a\u3001\u8b66\u544a\u533a\u6216\u5173\u952e\u533a\u3002", "result": "\u5728\u534a\u5bfc\u4f53\u5236\u9020\u516c\u53f8\u7684\u771f\u5b9e\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u5c3d\u7ba1\u6570\u636e\u91c7\u96c6\u65f6\u95f4\u95f4\u9694\u4e0d\u89c4\u5219\uff0c\u6a21\u578b\u4ecd\u80fd\u505a\u51fa\u51c6\u786e\u9884\u6d4b\u5e76\u6b63\u786e\u5206\u7c7b\u672a\u6765\u6d4b\u91cf\u7684\u98ce\u9669\u7b49\u7ea7\u3002", "conclusion": "\u5c06\u673a\u5668\u5b66\u4e60\u4e0e\u4f20\u7edfSPC\u7ed3\u5408\uff0c\u4f7f\u8d28\u91cf\u63a7\u5236\u66f4\u52a0\u4e3b\u52a8\u3001\u51c6\u786e\u548c\u6709\u7528\uff0c\u5e2e\u52a9\u5de5\u7a0b\u5e08\u63d0\u524d\u91c7\u53d6\u884c\u52a8\uff0c\u51cf\u5c11\u610f\u5916\u6545\u969c\uff0c\u63d0\u9ad8\u751f\u4ea7\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.17778", "categories": ["cs.IT", "cs.CR", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17778", "abs": "https://arxiv.org/abs/2509.17778", "authors": ["Amir Reza Ramtin", "Philippe Nain", "Don Towsley"], "title": "Quickest Change Detection in Continuous-Time in Presence of a Covert Adversary", "comment": null, "summary": "We investigate the problem of covert quickest change detection in a\ncontinuous-time setting, where a Brownian motion experiences a drift change at\nan unknown time. Unlike classical formulations, we consider a covert adversary\nwho adjusts the post-change drift $\\mu = \\mu(\\gamma)$ as a function of the\nfalse alarm constraint parameter $\\gamma$, with the goal of remaining\nundetected for as long as possible. Leveraging the exact expressions for the\naverage detection delay (ADD) and average time to false alarm (AT2FA) known for\nthe continuous-time CuSum procedure, we rigorously analyze how the asymptotic\nbehavior of ADD evolves as $\\mu(\\gamma) \\to 0$ with increasing $\\gamma$. Our\nresults reveal that classical detection delay characterizations no longer hold\nin this regime. We derive sharp asymptotic expressions for the ADD under\nvarious convergence rates of $\\mu(\\gamma)$, identify precise conditions for\nmaintaining covertness, and characterize the total damage inflicted by the\nadversary. We show that the adversary achieves maximal damage when the drift\nscales as $\\mu(\\gamma) = \\Theta(1/\\sqrt{\\gamma})$, marking a fundamental\ntrade-off between stealth and impact in continuous-time detection systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8fde\u7eed\u65f6\u95f4\u8bbe\u7f6e\u4e0b\u7684\u9690\u853d\u6700\u5feb\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\uff0c\u5176\u4e2d\u5e03\u6717\u8fd0\u52a8\u5728\u672a\u77e5\u65f6\u95f4\u7ecf\u5386\u6f02\u79fb\u53d8\u5316\u3002\u4e0e\u7ecf\u5178\u516c\u5f0f\u4e0d\u540c\uff0c\u8003\u8651\u4e86\u4e00\u4e2a\u9690\u853d\u5bf9\u624b\uff0c\u8be5\u5bf9\u624b\u6839\u636e\u8bef\u62a5\u7ea6\u675f\u53c2\u6570\u03b3\u8c03\u6574\u540e\u53d8\u5316\u6f02\u79fb\u03bc(\u03b3)\uff0c\u76ee\u6807\u662f\u5c3d\u53ef\u80fd\u957f\u65f6\u95f4\u4e0d\u88ab\u68c0\u6d4b\u5230\u3002", "motivation": "\u7ecf\u5178\u7684\u53d8\u5316\u68c0\u6d4b\u65b9\u6cd5\u5047\u8bbe\u6f02\u79fb\u53d8\u5316\u662f\u56fa\u5b9a\u7684\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5bf9\u624b\u53ef\u80fd\u4f1a\u81ea\u9002\u5e94\u5730\u8c03\u6574\u5176\u7b56\u7565\u4ee5\u9003\u907f\u68c0\u6d4b\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u5f53\u5bf9\u624b\u80fd\u591f\u6839\u636e\u68c0\u6d4b\u7cfb\u7edf\u7684\u53c2\u6570\u8c03\u6574\u5176\u6f02\u79fb\u65f6\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "method": "\u5229\u7528\u8fde\u7eed\u65f6\u95f4CuSum\u8fc7\u7a0b\u7684\u5e73\u5747\u68c0\u6d4b\u5ef6\u8fdf(ADD)\u548c\u5e73\u5747\u8bef\u62a5\u65f6\u95f4(AT2FA)\u7684\u7cbe\u786e\u8868\u8fbe\u5f0f\uff0c\u4e25\u683c\u5206\u6790\u5f53\u03bc(\u03b3)\u21920\u4e14\u03b3\u589e\u52a0\u65f6ADD\u7684\u6e10\u8fd1\u884c\u4e3a\u3002\u63a8\u5bfc\u4e86\u4e0d\u540c\u03bc(\u03b3)\u6536\u655b\u901f\u7387\u4e0b\u7684ADD\u7684\u5c16\u9510\u6e10\u8fd1\u8868\u8fbe\u5f0f\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7ecf\u5178\u68c0\u6d4b\u5ef6\u8fdf\u7279\u5f81\u5728\u8fd9\u79cd\u673a\u5236\u4e0b\u4e0d\u518d\u6210\u7acb\u3002\u5f53\u6f02\u79fb\u6309\u03bc(\u03b3)=\u0398(1/\u221a\u03b3)\u7f29\u653e\u65f6\uff0c\u5bf9\u624b\u9020\u6210\u6700\u5927\u635f\u5bb3\uff0c\u8fd9\u6807\u5fd7\u7740\u8fde\u7eed\u65f6\u95f4\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u9690\u853d\u6027\u548c\u5f71\u54cd\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002", "conclusion": "\u672c\u6587\u786e\u5b9a\u4e86\u7ef4\u6301\u9690\u853d\u6027\u7684\u7cbe\u786e\u6761\u4ef6\uff0c\u5e76\u8868\u5f81\u4e86\u5bf9\u624b\u9020\u6210\u7684\u603b\u635f\u5bb3\u3002\u63ed\u793a\u4e86\u5728\u8fde\u7eed\u65f6\u95f4\u68c0\u6d4b\u7cfb\u7edf\u4e2d\uff0c\u5f53\u5bf9\u624b\u80fd\u591f\u81ea\u9002\u5e94\u8c03\u6574\u6f02\u79fb\u65f6\uff0c\u5b58\u5728\u9690\u853d\u6027\u548c\u68c0\u6d4b\u6027\u80fd\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002"}}
{"id": "2509.18040", "categories": ["cs.NI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.18040", "abs": "https://arxiv.org/abs/2509.18040", "authors": ["Sourya Saha", "Md Nurul Absur", "Shima Yousefi", "Saptarshi Debroy"], "title": "Detection of Misreporting Attacks on Software-Defined Immersive Environments", "comment": "7 Pages, 7 Images, will appear in CNSM 2025", "summary": "The ability to centrally control network infrastructure using a programmable\nmiddleware has made Software-Defined Networking (SDN) ideal for emerging\napplications, such as immersive environments. However, such flexibility\nintroduces new vulnerabilities, such as switch misreporting led load imbalance,\nwhich in turn make such immersive environment vulnerable to severe quality\ndegradation. In this paper, we present a hybrid machine learning (ML)-based\nnetwork anomaly detection framework that identifies such stealthy misreporting\nby capturing temporal inconsistencies in switch-reported loads, and thereby\ncounter potentially catastrophic quality degradation of hosted immersive\napplication. The detection system combines unsupervised anomaly scoring with\nsupervised classification to robustly distinguish malicious behavior. Data\ncollected from a realistic testbed deployment under both benign and adversarial\nconditions is used to train and evaluate the model. Experimental results show\nthat the framework achieves high recall in detecting misreporting behavior,\nmaking it effective for early and reliable detection in SDN environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u673a\u5668\u5b66\u4e60\u7684\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522bSDN\u73af\u5883\u4e2d\u4ea4\u6362\u673a\u8bef\u62a5\u5bfc\u81f4\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4ece\u800c\u9632\u6b62\u6c89\u6d78\u5f0f\u5e94\u7528\u7684\u8d28\u91cf\u4e25\u91cd\u4e0b\u964d\u3002", "motivation": "SDN\u7684\u96c6\u4e2d\u63a7\u5236\u7075\u6d3b\u6027\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5982\u4ea4\u6362\u673a\u8bef\u62a5\u5bfc\u81f4\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\uff0c\u8fd9\u4f1a\u4f7f\u6c89\u6d78\u5f0f\u73af\u5883\u9762\u4e34\u4e25\u91cd\u7684\u8d28\u91cf\u9000\u5316\u98ce\u9669\u3002", "method": "\u7ed3\u5408\u65e0\u76d1\u7763\u5f02\u5e38\u8bc4\u5206\u4e0e\u76d1\u7763\u5206\u7c7b\u7684\u6df7\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6355\u6349\u4ea4\u6362\u673a\u62a5\u544a\u8d1f\u8f7d\u7684\u65f6\u95f4\u4e0d\u4e00\u81f4\u6027\u6765\u8bc6\u522b\u6076\u610f\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u5728\u68c0\u6d4b\u8bef\u62a5\u884c\u4e3a\u65b9\u9762\u5b9e\u73b0\u4e86\u9ad8\u53ec\u56de\u7387\uff0c\u80fd\u591f\u5728SDN\u73af\u5883\u4e2d\u8fdb\u884c\u65e9\u671f\u53ef\u9760\u68c0\u6d4b\u3002", "conclusion": "\u8be5\u6df7\u5408ML\u6846\u67b6\u80fd\u6709\u6548\u68c0\u6d4bSDN\u4e2d\u7684\u9690\u853d\u8bef\u62a5\u884c\u4e3a\uff0c\u4e3a\u6c89\u6d78\u5f0f\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u7684\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u4fdd\u62a4\u3002"}}
{"id": "2509.16444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16444", "abs": "https://arxiv.org/abs/2509.16444", "authors": ["Chenhan Lyu", "Yutong Song", "Pengfei Zhang", "Amir M. Rahmani"], "title": "Domain-Specific Constitutional AI: Enhancing Safety in LLM-Powered Mental Health Chatbots", "comment": null, "summary": "Mental health applications have emerged as a critical area in computational\nhealth, driven by rising global rates of mental illness, the integration of AI\nin psychological care, and the need for scalable solutions in underserved\ncommunities. These include therapy chatbots, crisis detection, and wellness\nplatforms handling sensitive data, requiring specialized AI safety beyond\ngeneral safeguards due to emotional vulnerability, risks like misdiagnosis or\nsymptom exacerbation, and precise management of vulnerable states to avoid\nsevere outcomes such as self-harm or loss of trust. Despite AI safety advances,\ngeneral safeguards inadequately address mental health-specific challenges,\nincluding crisis intervention accuracy to avert escalations, therapeutic\nguideline adherence to prevent misinformation, scale limitations in\nresource-constrained settings, and adaptation to nuanced dialogues where\ngenerics may introduce biases or miss distress signals. We introduce an\napproach to apply Constitutional AI training with domain-specific mental health\nprinciples for safe, domain-adapted CAI systems in computational mental health\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5baa\u6cd5AI\u8bad\u7ec3\u7684\u9886\u57df\u7279\u5b9a\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2dAI\u5b89\u5168\u6027\u7684\u7279\u6b8a\u6311\u6218\u3002", "motivation": "\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u5728\u5904\u7406\u654f\u611f\u6570\u636e\u65f6\u9762\u4e34\u72ec\u7279\u7684\u5b89\u5168\u6311\u6218\uff0c\u5305\u62ec\u60c5\u611f\u8106\u5f31\u6027\u3001\u8bef\u8bca\u98ce\u9669\u3001\u75c7\u72b6\u52a0\u5267\u7b49\uff0c\u901a\u7528AI\u5b89\u5168\u63aa\u65bd\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u5fc3\u7406\u5065\u5eb7\u7279\u5b9a\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5baa\u6cd5AI\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u7684\u5fc3\u7406\u5065\u5eb7\u539f\u5219\uff0c\u5f00\u53d1\u5b89\u5168\u3001\u9886\u57df\u9002\u5e94\u7684CAI\u7cfb\u7edf\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u5371\u673a\u5e72\u9884\u51c6\u786e\u6027\u3001\u6cbb\u7597\u6307\u5357\u9075\u5b88\u3001\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u53ef\u6269\u5c55\u6027\u4ee5\u53ca\u7ec6\u5fae\u5bf9\u8bdd\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u7684\u5baa\u6cd5AI\u8bad\u7ec3\u4e3a\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u89e3\u51b3\u4e86\u901a\u7528AI\u5b89\u5168\u63aa\u65bd\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.17957", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17957", "abs": "https://arxiv.org/abs/2509.17957", "authors": ["David Hyland", "Mahault Albarracin"], "title": "On the Variational Costs of Changing Our Minds", "comment": "Accepted as a full paper at the 6th International Workshop on Active\n  Inference", "summary": "The human mind is capable of extraordinary achievements, yet it often appears\nto work against itself. It actively defends its cherished beliefs even in the\nface of contradictory evidence, conveniently interprets information to conform\nto desired narratives, and selectively searches for or avoids information to\nsuit its various purposes. Despite these behaviours deviating from common\nnormative standards for belief updating, we argue that such 'biases' are not\ninherently cognitive flaws, but rather an adaptive response to the significant\npragmatic and cognitive costs associated with revising one's beliefs. This\npaper introduces a formal framework that aims to model the influence of these\ncosts on our belief updating mechanisms.\n  We treat belief updating as a motivated variational decision, where agents\nweigh the perceived 'utility' of a belief against the informational cost\nrequired to adopt a new belief state, quantified by the Kullback-Leibler\ndivergence from the prior to the variational posterior. We perform\ncomputational experiments to demonstrate that simple instantiations of this\nresource-rational model can be used to qualitatively emulate commonplace human\nbehaviours, including confirmation bias and attitude polarisation. In doing so,\nwe suggest that this framework makes steps toward a more holistic account of\nthe motivated Bayesian mechanics of belief change and provides practical\ninsights for predicting, compensating for, and correcting deviations from\ndesired belief updating processes.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u4eba\u7c7b\u8ba4\u77e5\u504f\u5dee\uff08\u5982\u786e\u8ba4\u504f\u8bef\uff09\u5e76\u975e\u8ba4\u77e5\u7f3a\u9677\uff0c\u800c\u662f\u5bf9\u4fe1\u5ff5\u66f4\u65b0\u6210\u672c\u7684\u9002\u5e94\u6027\u53cd\u5e94\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u5efa\u6a21\u8fd9\u4e9b\u6210\u672c\u5bf9\u4fe1\u5ff5\u66f4\u65b0\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4eba\u7c7b\u601d\u7ef4\u4f1a\u8868\u73b0\u51fa\u770b\u4f3c\u975e\u7406\u6027\u7684\u504f\u5dee\u884c\u4e3a\uff0c\u5982\u634d\u536b\u65e2\u6709\u4fe1\u5ff5\u3001\u9009\u62e9\u6027\u89e3\u91ca\u4fe1\u606f\u7b49\uff0c\u8fd9\u4e9b\u884c\u4e3a\u5b9e\u9645\u4e0a\u662f\u5bf9\u4fe1\u5ff5\u66f4\u65b0\u6240\u9700\u8ba4\u77e5\u548c\u5b9e\u7528\u6210\u672c\u7684\u5408\u7406\u9002\u5e94\u3002", "method": "\u5c06\u4fe1\u5ff5\u66f4\u65b0\u5efa\u6a21\u4e3a\u52a8\u673a\u9a71\u52a8\u7684\u53d8\u5206\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528Kullback-Leibler\u6563\u5ea6\u91cf\u5316\u4ece\u5148\u9a8c\u5230\u53d8\u5206\u540e\u9a8c\u7684\u4fe1\u606f\u6210\u672c\uff0c\u901a\u8fc7\u8ba1\u7b97\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u80fd\u591f\u6a21\u62df\u786e\u8ba4\u504f\u8bef\u548c\u6001\u5ea6\u6781\u5316\u7b49\u5e38\u89c1\u4eba\u7c7b\u884c\u4e3a\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e2a\u8d44\u6e90\u7406\u6027\u6a21\u578b\u7684\u7b80\u5355\u5b9e\u4f8b\u80fd\u591f\u5b9a\u6027\u5730\u6a21\u62df\u5e38\u89c1\u7684\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u5305\u62ec\u786e\u8ba4\u504f\u8bef\u548c\u6001\u5ea6\u6781\u5316\u73b0\u8c61\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u4fe1\u5ff5\u53d8\u5316\u7684\u52a8\u673a\u6027\u8d1d\u53f6\u65af\u673a\u5236\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u91ca\uff0c\u5e76\u4e3a\u9884\u6d4b\u3001\u8865\u507f\u548c\u7ea0\u6b63\u4fe1\u5ff5\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u7684\u504f\u5dee\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2509.16456", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16456", "abs": "https://arxiv.org/abs/2509.16456", "authors": ["Jiahao Yu", "Zelei Cheng", "Xian Wu", "Xinyu Xing"], "title": "GPO: Learning from Critical Steps to Improve LLM Reasoning", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "Large language models (LLMs) are increasingly used in various domains,\nshowing impressive potential on different tasks. Recently, reasoning LLMs have\nbeen proposed to improve the \\textit{reasoning} or \\textit{thinking}\ncapabilities of LLMs to solve complex problems. Despite the promising results\nof reasoning LLMs, enhancing the multi-step reasoning capabilities of LLMs\nstill remains a significant challenge. While existing optimization methods have\nadvanced the LLM reasoning capabilities, they often treat reasoning\ntrajectories as a whole, without considering the underlying critical steps\nwithin the trajectory. In this paper, we introduce \\textbf{G}uided\n\\textbf{P}ivotal \\textbf{O}ptimization (GPO), a novel fine-tuning strategy that\ndives into the reasoning process to enable more effective improvements. GPO\nfirst identifies the `critical step' within a reasoning trajectory - a point\nthat the model must carefully proceed to succeed at the problem. We locate the\ncritical step by estimating the advantage function. GPO then resets the policy\nto the critical step, samples the new rollout and prioritizes the learning\nprocess on those rollouts. This focus allows the model to learn more\neffectively from pivotal moments within the reasoning process to improve the\nreasoning performance. We demonstrate that GPO is a general strategy that can\nbe integrated with various optimization methods to improve reasoning\nperformance. Besides theoretical analysis, our experiments across challenging\nreasoning benchmarks show that GPO can consistently and significantly enhance\nthe performance of existing optimization methods, showcasing its effectiveness\nand generalizability in improving LLM reasoning by concentrating on pivotal\nmoments within the generation process.", "AI": {"tldr": "GPO\u662f\u4e00\u79cd\u65b0\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u901a\u8fc7\u8bc6\u522b\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\u5e76\u4f18\u5148\u5b66\u4e60\u8fd9\u4e9b\u5173\u952e\u65f6\u523b\uff0c\u6765\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u5c06\u63a8\u7406\u8f68\u8ff9\u89c6\u4e3a\u6574\u4f53\uff0c\u6ca1\u6709\u8003\u8651\u8f68\u8ff9\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u8fd9\u9650\u5236\u4e86LLM\u591a\u6b65\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "GPO\u9996\u5148\u901a\u8fc7\u4f30\u8ba1\u4f18\u52bf\u51fd\u6570\u8bc6\u522b\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u7136\u540e\u91cd\u7f6e\u7b56\u7565\u5230\u5173\u952e\u6b65\u9aa4\uff0c\u91c7\u6837\u65b0\u7684\u8f68\u8ff9\u5e76\u4f18\u5148\u5b66\u4e60\u8fd9\u4e9b\u5173\u952e\u65f6\u523b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGPO\u80fd\u591f\u663e\u8457\u63d0\u5347\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5728\u5404\u79cd\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6709\u6548\u6027\u3002", "conclusion": "GPO\u662f\u4e00\u79cd\u901a\u7528\u7684\u7b56\u7565\uff0c\u53ef\u4ee5\u901a\u8fc7\u5173\u6ce8\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u65f6\u523b\u6765\u6709\u6548\u63d0\u5347LLM\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2509.16547", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16547", "abs": "https://arxiv.org/abs/2509.16547", "authors": ["Adrian Wurm"], "title": "Checking extracted rules in Neural Networks", "comment": "7 pages, one figure", "summary": "In this paper we investigate formal verification of extracted rules for\nNeural Networks under a complexity theoretic point of view. A rule is a global\nproperty or a pattern concerning a large portion of the input space of a\nnetwork. These rules are algorithmically extracted from networks in an effort\nto better understand their inner way of working. Here, three problems will be\nin the focus: Does a given set of rules apply to a given network? Is a given\nset of rules consistent or do the rules contradict themselves? Is a given set\nof rules exhaustive in the sense that for every input the output is determined?\nFinding algorithms that extract such rules out of networks has been\ninvestigated over the last 30 years, however, to the author's current\nknowledge, no attempt in verification was made until now. A lot of attempts of\nextracting rules use heuristics involving randomness and over-approximation, so\nit might be beneficial to know whether knowledge obtained in that way can\nactually be trusted.\n  We investigate the above questions for neural networks with ReLU-activation\nas well as for Boolean networks, each for several types of rules. We\ndemonstrate how these problems can be reduced to each other and show that most\nof them are co-NP-complete.", "AI": {"tldr": "\u672c\u6587\u4ece\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u89d2\u5ea6\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u89c4\u5219\u7684\u6b63\u5f0f\u9a8c\u8bc1\u95ee\u9898\uff0c\u5305\u62ec\u89c4\u5219\u9002\u7528\u6027\u3001\u4e00\u81f4\u6027\u548c\u5b8c\u5907\u6027\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5927\u591a\u6570\u95ee\u9898\u90fd\u662fco-NP\u5b8c\u5168\u7684\u3002", "motivation": "\u867d\u7136\u8fc7\u53bb30\u5e74\u6709\u5927\u91cf\u7b97\u6cd5\u4ece\u795e\u7ecf\u7f51\u7edc\u4e2d\u63d0\u53d6\u89c4\u5219\u4ee5\u7406\u89e3\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u542f\u53d1\u5f0f\u3001\u968f\u673a\u6027\u548c\u8fc7\u8fd1\u4f3c\u6280\u672f\uff0c\u7f3a\u4e4f\u5bf9\u63d0\u53d6\u7ed3\u679c\u53ef\u4fe1\u5ea6\u7684\u6b63\u5f0f\u9a8c\u8bc1\u3002", "method": "\u9488\u5bf9ReLU\u6fc0\u6d3b\u795e\u7ecf\u7f51\u7edc\u548c\u5e03\u5c14\u7f51\u7edc\uff0c\u7814\u7a76\u89c4\u5219\u9002\u7528\u6027\u3001\u4e00\u81f4\u6027\u548c\u5b8c\u5907\u6027\u4e09\u4e2a\u9a8c\u8bc1\u95ee\u9898\uff0c\u901a\u8fc7\u95ee\u9898\u95f4\u7684\u5f52\u7ea6\u5206\u6790\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5927\u591a\u6570\u89c4\u5219\u9a8c\u8bc1\u95ee\u9898\u90fd\u662fco-NP\u5b8c\u5168\u7684\uff0c\u8868\u660e\u8fd9\u4e9b\u95ee\u9898\u7684\u8ba1\u7b97\u96be\u5ea6\u5f88\u9ad8\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u89c4\u5219\u63d0\u53d6\u7684\u53ef\u9a8c\u8bc1\u6027\u9762\u4e34\u8ba1\u7b97\u590d\u6742\u6027\u6311\u6218\uff0c\u8fd9\u5bf9\u57fa\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u53d6\u89c4\u5219\u7684\u53ef\u4fe1\u5ea6\u63d0\u51fa\u4e86\u91cd\u8981\u8b66\u793a\u3002"}}
{"id": "2509.16561", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.16561", "abs": "https://arxiv.org/abs/2509.16561", "authors": ["Yue Xin", "Chen Shen", "Shaotian Yan", "Xiaosong Yuan", "Yaoming Wang", "Xiaofeng Zhang", "Chenxi Huang", "Jieping Ye"], "title": "SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning", "comment": "accpeted by EMNLP 2025", "summary": "Chain-of-Thought (CoT) prompting enhances the math reasoning capability of\nlarge language models (LLMs) to a large margin. However, the mechanism\nunderlying such improvements remains unexplored. In this paper, we present\n\\textbf{SalaMAnder} (\\textbf{S}h\\textbf{a}p\\textbf{l}ey-b\\textbf{a}sed\n\\textbf{M}athematical Expression \\textbf{A}ttribution a\\textbf{nd}\nM\\textbf{e}t\\textbf{r}ic), a theoretically grounded methodology as well as a\nmathematically rigorous evaluation metric for quantifying component-level\ncontributions in few-shot CoT reasoning. Concretely, we leverage the Shapley\nvalue for mathematical expression attribution and develop an efficient\nstratified sampling algorithm that significantly reduces the computational\ncomplexity. Besides, we develop the \\textbf{CoSP} (\\textbf{C}ardinality\n\\textbf{o}f \\textbf{S}hapley \\textbf{P}ositives) metric through covariance\nanalysis. Comprehensive validation across popular LLM models and diverse\nmathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder\nframework exhibits a robust monotonic correlation with model performance, not\nonly providing theoretical explanations for the empirical success of existing\nfew-shot CoT but also establishing mathematically rigorous principles for\nprompt construction optimization. Furthermore, we verify the reliability of the\nexplanation, based on which we unify the insights of previous work.", "AI": {"tldr": "SalaMAnder\u662f\u4e00\u4e2a\u57fa\u4e8eShapley\u503c\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u5f52\u56e0\u6846\u67b6\uff0c\u901a\u8fc7CoSP\u6307\u6807\u91cf\u5316\u5c11\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u7ec4\u4ef6\u7684\u8d21\u732e\u5ea6\uff0c\u4e3aCoT\u7684\u6210\u529f\u63d0\u4f9b\u7406\u8bba\u89e3\u91ca\u3002", "motivation": "\u601d\u7ef4\u94fe\u63d0\u793a\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u80cc\u540e\u7684\u673a\u5236\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u7406\u8bba\u4e25\u8c28\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u7ec4\u4ef6\u7ea7\u8d21\u732e\u3002", "method": "\u5229\u7528Shapley\u503c\u8fdb\u884c\u6570\u5b66\u8868\u8fbe\u5f0f\u5f52\u56e0\uff0c\u5f00\u53d1\u9ad8\u6548\u7684\u5206\u5c42\u91c7\u6837\u7b97\u6cd5\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u901a\u8fc7\u534f\u65b9\u5dee\u5206\u6790\u6784\u5efaCoSP\u6307\u6807\u3002", "result": "\u5728\u591a\u4e2aLLM\u6a21\u578b\u548c\u6570\u5b66\u57fa\u51c6\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0cCoSP\u6307\u6807\u4e0e\u6a21\u578b\u6027\u80fd\u5448\u73b0\u7a33\u5065\u7684\u5355\u8c03\u76f8\u5173\u6027\uff0c\u4e3a\u73b0\u6709\u5c11\u6837\u672cCoT\u7684\u6210\u529f\u63d0\u4f9b\u7406\u8bba\u89e3\u91ca\u3002", "conclusion": "SalaMAnder\u6846\u67b6\u4e0d\u4ec5\u89e3\u91ca\u4e86CoT\u7684\u5b9e\u8bc1\u6210\u529f\uff0c\u8fd8\u5efa\u7acb\u4e86\u6570\u5b66\u4e25\u8c28\u7684\u63d0\u793a\u6784\u5efa\u4f18\u5316\u539f\u5219\uff0c\u7edf\u4e00\u4e86\u5148\u524d\u5de5\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.16578", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.16578", "abs": "https://arxiv.org/abs/2509.16578", "authors": ["Wenyao Li", "Ran Zhang", "Pengyang Wang", "Yuanchun Zhou", "Pengfei Wang"], "title": "Zero-Shot Human Mobility Forecasting via Large Language Model with Hierarchical Reasoning", "comment": null, "summary": "Human mobility forecasting is important for applications such as\ntransportation planning, urban management, and personalized recommendations.\nHowever, existing methods often fail to generalize to unseen users or locations\nand struggle to capture dynamic intent due to limited labeled data and the\ncomplexity of mobility patterns. We propose ZHMF, a framework for zero-shot\nhuman mobility forecasting that combines a semantic enhanced retrieval and\nreflection mechanism with a hierarchical language model based reasoning system.\nThe task is reformulated as a natural language question answering paradigm.\nLeveraging LLMs semantic understanding of user histories and context, our\napproach handles previously unseen prediction scenarios. We further introduce a\nhierarchical reflection mechanism for iterative reasoning and refinement by\ndecomposing forecasting into an activity level planner and a location level\nselector, enabling collaborative modeling of long term user intentions and\nshort term contextual preferences. Experiments on standard human mobility\ndatasets show that our approach outperforms existing models. Ablation studies\nreveal the contribution of each module, and case studies illustrate how the\nmethod captures user intentions and adapts to diverse contextual scenarios.", "AI": {"tldr": "ZHMF\u662f\u4e00\u4e2a\u7528\u4e8e\u96f6\u6837\u672c\u4eba\u7c7b\u79fb\u52a8\u9884\u6d4b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u589e\u5f3a\u68c0\u7d22\u548c\u5206\u5c42\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\uff0c\u5c06\u9884\u6d4b\u4efb\u52a1\u91cd\u65b0\u8868\u8ff0\u4e3a\u81ea\u7136\u8bed\u8a00\u95ee\u7b54\u8303\u5f0f\uff0c\u80fd\u591f\u5904\u7406\u672a\u89c1\u8fc7\u7684\u9884\u6d4b\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u7528\u6237\u6216\u4f4d\u7f6e\uff0c\u4e14\u7531\u4e8e\u6807\u8bb0\u6570\u636e\u6709\u9650\u548c\u79fb\u52a8\u6a21\u5f0f\u7684\u590d\u6742\u6027\uff0c\u96be\u4ee5\u6355\u6349\u52a8\u6001\u610f\u56fe\u3002", "method": "\u7ed3\u5408\u8bed\u4e49\u589e\u5f3a\u68c0\u7d22\u548c\u53cd\u5c04\u673a\u5236\u4e0e\u5206\u5c42\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\uff0c\u5c06\u9884\u6d4b\u4efb\u52a1\u91cd\u65b0\u8868\u8ff0\u4e3a\u81ea\u7136\u8bed\u8a00\u95ee\u7b54\u8303\u5f0f\uff0c\u901a\u8fc7\u5206\u5c42\u53cd\u5c04\u673a\u5236\u8fdb\u884c\u8fed\u4ee3\u63a8\u7406\u548c\u7cbe\u70bc\uff0c\u5c06\u9884\u6d4b\u5206\u89e3\u4e3a\u6d3b\u52a8\u7ea7\u89c4\u5212\u5668\u548c\u4f4d\u7f6e\u7ea7\u9009\u62e9\u5668\u3002", "result": "\u5728\u6807\u51c6\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u6bcf\u4e2a\u6a21\u5757\u7684\u8d21\u732e\uff0c\u6848\u4f8b\u7814\u7a76\u8bf4\u660e\u4e86\u8be5\u65b9\u6cd5\u5982\u4f55\u6355\u6349\u7528\u6237\u610f\u56fe\u5e76\u9002\u5e94\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\u573a\u666f\u3002", "conclusion": "ZHMF\u6846\u67b6\u901a\u8fc7\u8bed\u4e49\u7406\u89e3\u548c\u5206\u5c42\u63a8\u7406\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u96f6\u6837\u672c\u4eba\u7c7b\u79fb\u52a8\u9884\u6d4b\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u672a\u89c1\u573a\u666f\u4e0b\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.16590", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.16590", "abs": "https://arxiv.org/abs/2509.16590", "authors": ["Manuel Borroto", "Katie Gallagher", "Antonio Ielo", "Irfan Kareem", "Francesco Ricca", "Alessandra Russo"], "title": "Question Answering with LLMs and Learning from Answer Sets", "comment": "Under consideration for TPLP journal", "summary": "Large Language Models (LLMs) excel at understanding natural language but\nstruggle with explicit commonsense reasoning. A recent trend of research\nsuggests that the combination of LLM with robust symbolic reasoning systems can\novercome this problem on story-based question answering tasks. In this setting,\nexisting approaches typically depend on human expertise to manually craft the\nsymbolic component. We argue, however, that this component can also be\nautomatically learned from examples. In this work, we introduce LLM2LAS, a\nhybrid system that effectively combines the natural language understanding\ncapabilities of LLMs, the rule induction power of the Learning from Answer Sets\n(LAS) system ILASP, and the formal reasoning strengths of Answer Set\nProgramming (ASP). LLMs are used to extract semantic structures from text,\nwhich ILASP then transforms into interpretable logic rules. These rules allow\nan ASP solver to perform precise and consistent reasoning, enabling correct\nanswers to previously unseen questions. Empirical results outline the strengths\nand weaknesses of our automatic approach for learning and reasoning in a\nstory-based question answering benchmark.", "AI": {"tldr": "LLM2LAS\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001ILASP\u89c4\u5219\u5b66\u4e60\u548cASP\u5f62\u5f0f\u63a8\u7406\u7684\u6df7\u5408\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5b66\u4e60\u6545\u4e8b\u95ee\u7b54\u4e2d\u7684\u5e38\u8bc6\u63a8\u7406\u89c4\u5219", "motivation": "LLMs\u64c5\u957f\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4f46\u7f3a\u4e4f\u663e\u5f0f\u5e38\u8bc6\u63a8\u7406\u80fd\u529b\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7b26\u53f7\u7ec4\u4ef6\uff0c\u9700\u8981\u81ea\u52a8\u5b66\u4e60\u673a\u5236", "method": "\u4f7f\u7528LLM\u4ece\u6587\u672c\u63d0\u53d6\u8bed\u4e49\u7ed3\u6784\uff0cILASP\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u903b\u8f91\u89c4\u5219\uff0cASP\u6c42\u89e3\u5668\u8fdb\u884c\u7cbe\u786e\u63a8\u7406", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6545\u4e8b\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5177\u6709\u5b66\u4e60\u548c\u63a8\u7406\u7684\u4f18\u52bf\u4e0e\u5c40\u9650", "conclusion": "LLM2LAS\u5c55\u793a\u4e86\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u63a8\u7406\u7ec4\u4ef6\u7684\u53ef\u884c\u6027\uff0c\u4e3aLLM\u4e0e\u7b26\u53f7\u63a8\u7406\u7cfb\u7edf\u7684\u6709\u6548\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2509.16648", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16648", "abs": "https://arxiv.org/abs/2509.16648", "authors": ["Debarpan Bhattacharya", "Apoorva Kulkarni", "Sriram Ganapathy"], "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "comment": "Accepted in the Findings of EMNLP, 2025", "summary": "The accurate trust assessment of multimodal large language models (MLLMs)\ngenerated predictions, which can enable selective prediction and improve user\nconfidence, is challenging due to the diverse multi-modal input paradigms. We\npropose Functionally Equivalent Sampling for Trust Assessment (FESTA), a\nmultimodal input sampling technique for MLLMs, that generates an uncertainty\nmeasure based on the equivalent and complementary input samplings. The proposed\ntask-preserving sampling approach for uncertainty quantification expands the\ninput space to probe the consistency (through equivalent samples) and\nsensitivity (through complementary samples) of the model. FESTA uses only\ninput-output access of the model (black-box), and does not require ground truth\n(unsupervised). The experiments are conducted with various off-the-shelf\nmulti-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA\nuncertainty estimate achieves significant improvement (33.3% relative\nimprovement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in\nselective prediction performance, based on\narea-under-receiver-operating-characteristic curve (AUROC) metric in detecting\nmispredictions. The code implementation is open-sourced.", "AI": {"tldr": "FESTA\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u8f93\u5165\u91c7\u6837\u6280\u672f\uff0c\u901a\u8fc7\u7b49\u6548\u548c\u4e92\u8865\u91c7\u6837\u751f\u6210\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u8f93\u5165\u6a21\u5f0f\u591a\u6837\u3002\u51c6\u786e\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u53ef\u4ee5\u5b9e\u73b0\u9009\u62e9\u6027\u9884\u6d4b\u5e76\u63d0\u9ad8\u7528\u6237\u4fe1\u5fc3\u3002", "method": "FESTA\u91c7\u7528\u4efb\u52a1\u4fdd\u6301\u91c7\u6837\u65b9\u6cd5\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u901a\u8fc7\u7b49\u6548\u91c7\u6837\u63a2\u6d4b\u6a21\u578b\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u4e92\u8865\u91c7\u6837\u63a2\u6d4b\u6a21\u578b\u654f\u611f\u6027\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700\u6a21\u578b\u8f93\u5165\u8f93\u51fa\u8bbf\u95ee\uff08\u9ed1\u76d2\uff09\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\uff08\u65e0\u76d1\u7763\uff09\u3002", "result": "\u5728\u89c6\u89c9\u548c\u97f3\u9891\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cFESTA\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5728\u9009\u62e9\u6027\u9884\u6d4b\u6027\u80fd\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff08\u89c6\u89c9LLMs\u76f8\u5bf9\u6539\u8fdb33.3%\uff0c\u97f3\u9891LLMs\u76f8\u5bf9\u6539\u8fdb29.6%\uff09\uff0c\u57fa\u4e8eAUROC\u6307\u6807\u68c0\u6d4b\u9519\u8bef\u9884\u6d4b\u3002", "conclusion": "FESTA\u662f\u4e00\u79cd\u6709\u6548\u7684\u9ed1\u76d2\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2509.16656", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16656", "abs": "https://arxiv.org/abs/2509.16656", "authors": ["Changyu Zeng", "Yifan Wang", "Zimu Wang", "Wei Wang", "Zhengni Yang", "Muyi Bao", "Jiming Xiao", "Ahn Nguyen", "Yutao Yue"], "title": "NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities", "comment": null, "summary": "Recent advancements in 2D multimodal large language models (MLLMs) have\nsignificantly improved performance in vision-language tasks. However, extending\nthese capabilities to 3D environments remains a distinct challenge due to the\ncomplexity of spatial reasoning. Nevertheless, existing 3D benchmarks often\nlack fine-grained numerical reasoning task annotations, limiting MLLMs' ability\nto perform precise spatial measurements and complex numerical reasoning. To\naddress this gap, we introduce NUMINA, the first Natural Understanding\nbenchmark for Multi-dimensional Intelligence and Numerical reasoning Abilities\nto enhance multimodal indoor perceptual understanding. NUMINA features\nmulti-scale annotations and various question-answer pairs, generated using\nNUMINA-Flow, an automated annotation pipeline that integrates LLM rewriting and\nrule-based self-verification. We evaluate the performance of various\nstate-of-the-art LLMs on NUMINA following the Chat-Scene framework,\ndemonstrating that current LLMs struggle with multimodal numerical reasoning,\nparticularly in performing precise computations such as distance and volume\nestimation, highlighting the need for further advancements in 3D models. The\ndataset and source codes can be obtained from\nhttps://github.com/fengshun124/NUMINA.", "AI": {"tldr": "NUMINA\u662f\u9996\u4e2a\u7528\u4e8e\u589e\u5f3a\u591a\u6a21\u6001\u5ba4\u5185\u611f\u77e5\u7406\u89e3\u7684\u81ea\u7136\u7406\u89e3\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u591a\u7ef4\u667a\u80fd\u548c\u6570\u503c\u63a8\u7406\u80fd\u529b\uff0c\u586b\u8865\u4e86\u73b0\u67093D\u57fa\u51c6\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u6570\u503c\u63a8\u7406\u4efb\u52a1\u6807\u6ce8\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u67093D\u57fa\u51c6\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u6570\u503c\u63a8\u7406\u4efb\u52a1\u6807\u6ce8\uff0c\u9650\u5236\u4e86MLLMs\u8fdb\u884c\u7cbe\u786e\u7a7a\u95f4\u6d4b\u91cf\u548c\u590d\u6742\u6570\u503c\u63a8\u7406\u7684\u80fd\u529b\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u548c\u63d0\u53473D\u73af\u5883\u4e2d\u7684\u6570\u503c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528NUMINA-Flow\u81ea\u52a8\u5316\u6807\u6ce8\u6d41\u7a0b\uff08\u96c6\u6210LLM\u91cd\u5199\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u81ea\u9a8c\u8bc1\uff09\u751f\u6210\u591a\u5c3a\u5ea6\u6807\u6ce8\u548c\u5404\u79cd\u95ee\u7b54\u5bf9\uff0c\u5e76\u5728Chat-Scene\u6846\u67b6\u4e0b\u8bc4\u4f30\u5404\u79cd\u6700\u5148\u8fdbLLMs\u7684\u6027\u80fd\u3002", "result": "\u5f53\u524dLLMs\u5728\u591a\u6a21\u6001\u6570\u503c\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u6267\u884c\u7cbe\u786e\u8ba1\u7b97\uff08\u5982\u8ddd\u79bb\u548c\u4f53\u79ef\u4f30\u8ba1\uff09\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u51f8\u663e\u4e863D\u6a21\u578b\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "conclusion": "NUMINA\u57fa\u51c6\u7684\u5f15\u5165\u63ed\u793a\u4e86\u5f53\u524d3D MLLMs\u5728\u6570\u503c\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u67653D\u591a\u6a21\u6001\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bc4\u4f30\u5de5\u5177\u548c\u65b9\u5411\u6307\u5f15\u3002"}}
{"id": "2509.16742", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16742", "abs": "https://arxiv.org/abs/2509.16742", "authors": ["Mohammad Beigi", "Ying Shen", "Parshin Shojaee", "Qifan Wang", "Zichao Wang", "Chandan Reddy", "Ming Jin", "Lifu Huang"], "title": "Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories", "comment": null, "summary": "Despite the remarkable capabilities of large language models, current\ntraining paradigms inadvertently foster \\textit{sycophancy}, i.e., the tendency\nof a model to agree with or reinforce user-provided information even when it's\nfactually incorrect. To address this challenge, we introduce \\textbf{SMART}\n(Sycophancy Mitigation through Adaptive Reasoning Trajectories), which reframes\nsycophancy as a \\textit{reasoning optimization problem} rather than an output\nalignment issue. SMART is a two-stage framework comprising: (1)\nUncertainty-Aware Adaptive Monte Carlo Tree Search (UA-MCTS), which dynamically\nadjusts model exploration based on state-level uncertainty to collect\nhigh-quality, diverse reasoning trajectories alongside both stepwise progress\nand final outcome rewards; and (2) progress-based reinforcement learning, which\nfine-tunes the model using the collected trajectories and reward signals to\nreinforce effective reasoning patterns. Through extensive experiments, we show\nthat SMART significantly reduces sycophantic behavior while preserving strong\nperformance on out-of-distribution inputs and maintaining general capabilities.\nThese results underscore the importance of optimizing internal reasoning\nmechanisms to build more truthful and aligned AI assistants.", "AI": {"tldr": "SMART\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5949\u627f\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u63a8\u7406\u4f18\u5316\u95ee\u9898\u6765\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5949\u627f\u884c\u4e3a\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8303\u5f0f\u65e0\u610f\u4e2d\u57f9\u517b\u4e86\u5949\u627f\u884c\u4e3a\uff0c\u5373\u6a21\u578b\u503e\u5411\u4e8e\u540c\u610f\u6216\u5f3a\u5316\u7528\u6237\u63d0\u4f9b\u7684\u4fe1\u606f\uff0c\u5373\u4f7f\u8fd9\u4e9b\u4fe1\u606f\u5728\u4e8b\u5b9e\u4e0a\u662f\u9519\u8bef\u7684\u3002", "method": "SMART\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a(1) \u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u81ea\u9002\u5e94\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22(UA-MCTS)\uff0c\u57fa\u4e8e\u72b6\u6001\u7ea7\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u8c03\u6574\u6a21\u578b\u63a2\u7d22\uff1b(2) \u57fa\u4e8e\u8fdb\u5ea6\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u7528\u6536\u96c6\u7684\u8f68\u8ff9\u548c\u5956\u52b1\u4fe1\u53f7\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSMART\u663e\u8457\u51cf\u5c11\u4e86\u5949\u627f\u884c\u4e3a\uff0c\u540c\u65f6\u5728\u5206\u5e03\u5916\u8f93\u5165\u4e0a\u4fdd\u6301\u5f3a\u5927\u6027\u80fd\u5e76\u7ef4\u6301\u901a\u7528\u80fd\u529b\u3002", "conclusion": "\u4f18\u5316\u5185\u90e8\u63a8\u7406\u673a\u5236\u5bf9\u4e8e\u6784\u5efa\u66f4\u771f\u5b9e\u548c\u5bf9\u9f50\u7684AI\u52a9\u624b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.16810", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16810", "abs": "https://arxiv.org/abs/2509.16810", "authors": ["Shen Chang", "Dennis Liu", "Renran Tian", "Kristen L. Swartzell", "Stacie L. Klingler", "Amy M. Nagle", "Nan Kong"], "title": "Automated Procedural Analysis via Video-Language Models for AI-assisted Nursing Skills Assessment", "comment": null, "summary": "Consistent high-quality nursing care is essential for patient safety, yet\ncurrent nursing education depends on subjective, time-intensive instructor\nfeedback in training future nurses, which limits scalability and efficiency in\ntheir training, and thus hampers nursing competency when they enter the\nworkforce. In this paper, we introduce a video-language model (VLM) based\nframework to develop the AI capability of automated procedural assessment and\nfeedback for nursing skills training, with the potential of being integrated\ninto existing training programs. Mimicking human skill acquisition, the\nframework follows a curriculum-inspired progression, advancing from high-level\naction recognition, fine-grained subaction decomposition, and ultimately to\nprocedural reasoning. This design supports scalable evaluation by reducing\ninstructor workload while preserving assessment quality. The system provides\nthree core capabilities: 1) diagnosing errors by identifying missing or\nincorrect subactions in nursing skill instruction videos, 2) generating\nexplainable feedback by clarifying why a step is out of order or omitted, and\n3) enabling objective, consistent formative evaluation of procedures.\nValidation on synthesized videos demonstrates reliable error detection and\ntemporal localization, confirming its potential to handle real-world training\nvariability. By addressing workflow bottlenecks and supporting large-scale,\nstandardized evaluation, this work advances AI applications in nursing\neducation, contributing to stronger workforce development and ultimately safer\npatient care.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u7684AI\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30\u548c\u53cd\u9988\u62a4\u7406\u6280\u80fd\u57f9\u8bad\uff0c\u901a\u8fc7\u5206\u5c42\u5b66\u4e60\u8def\u5f84\u5b9e\u73b0\u4ece\u52a8\u4f5c\u8bc6\u522b\u5230\u7a0b\u5e8f\u63a8\u7406\u7684\u6e10\u8fdb\u5f0f\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u62a4\u7406\u6559\u80b2\u4f9d\u8d56\u4e3b\u89c2\u3001\u8017\u65f6\u7684\u6559\u5e08\u53cd\u9988\uff0c\u9650\u5236\u4e86\u57f9\u8bad\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\uff0c\u5f71\u54cd\u62a4\u7406\u4eba\u5458\u5165\u804c\u540e\u7684\u80fd\u529b\u6c34\u5e73\u3002", "method": "\u91c7\u7528\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u6a21\u4eff\u4eba\u7c7b\u6280\u80fd\u83b7\u53d6\u8fc7\u7a0b\uff0c\u4ece\u9ad8\u5c42\u6b21\u52a8\u4f5c\u8bc6\u522b\u3001\u7ec6\u7c92\u5ea6\u5b50\u52a8\u4f5c\u5206\u89e3\u5230\u7a0b\u5e8f\u63a8\u7406\u7684\u8bfe\u7a0b\u5316\u9012\u8fdb\u8bbe\u8ba1\u3002", "result": "\u5728\u5408\u6210\u89c6\u9891\u4e0a\u7684\u9a8c\u8bc1\u663e\u793a\u7cfb\u7edf\u80fd\u53ef\u9760\u68c0\u6d4b\u9519\u8bef\u5e76\u8fdb\u884c\u65f6\u95f4\u5b9a\u4f4d\uff0c\u5177\u5907\u5904\u7406\u771f\u5b9e\u4e16\u754c\u8bad\u7ec3\u53d8\u5f02\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u89e3\u51b3\u5de5\u4f5c\u6d41\u7a0b\u74f6\u9888\u548c\u652f\u6301\u5927\u89c4\u6a21\u6807\u51c6\u5316\u8bc4\u4f30\uff0c\u63a8\u52a8\u4e86AI\u5728\u62a4\u7406\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u6709\u52a9\u4e8e\u52a0\u5f3a\u52b3\u52a8\u529b\u53d1\u5c55\u548c\u60a3\u8005\u5b89\u5168\u3002"}}
{"id": "2509.16811", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.16811", "abs": "https://arxiv.org/abs/2509.16811", "authors": ["Zihan Ding", "Junlong Chen", "Per Ola Kristensson", "Junxiao Shen", "Xinyi Wang"], "title": "Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media", "comment": null, "summary": "Creators struggle to edit long-form, narrative-rich videos not because of UI\ncomplexity, but due to the cognitive demands of searching, storyboarding, and\nsequencing hours of footage. Existing transcript- or embedding-based methods\nfall short for creative workflows, as models struggle to track characters,\ninfer motivations, and connect dispersed events. We present a prompt-driven,\nmodular editing system that helps creators restructure multi-hour content\nthrough free-form prompts rather than timelines. At its core is a semantic\nindexing pipeline that builds a global narrative via temporal segmentation,\nguided memory compression, and cross-granularity fusion, producing\ninterpretable traces of plot, dialogue, emotion, and context. Users receive\ncinematic edits while optionally refining transparent intermediate outputs.\nEvaluated on 400+ videos with expert ratings, QA, and preference studies, our\nsystem scales prompt-driven editing, preserves narrative coherence, and\nbalances automation with creator control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u63d0\u793a\u7684\u6a21\u5757\u5316\u89c6\u9891\u7f16\u8f91\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u4e49\u7d22\u5f15\u7ba1\u9053\u6784\u5efa\u5168\u5c40\u53d9\u4e8b\uff0c\u5e2e\u52a9\u521b\u4f5c\u8005\u91cd\u6784\u957f\u7bc7\u89c6\u9891\u5185\u5bb9\uff0c\u800c\u975e\u4f9d\u8d56\u65f6\u95f4\u7ebf\u7f16\u8f91\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8f6c\u5f55\u6216\u5d4c\u5165\u7684\u65b9\u6cd5\u5728\u521b\u610f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u6a21\u578b\u96be\u4ee5\u8ddf\u8e2a\u89d2\u8272\u3001\u63a8\u65ad\u52a8\u673a\u548c\u8fde\u63a5\u5206\u6563\u7684\u4e8b\u4ef6\uff0c\u521b\u4f5c\u8005\u5728\u5904\u7406\u957f\u7bc7\u53d9\u4e8b\u89c6\u9891\u65f6\u9762\u4e34\u8ba4\u77e5\u6311\u6218\u3002", "method": "\u6838\u5fc3\u662f\u8bed\u4e49\u7d22\u5f15\u7ba1\u9053\uff0c\u5305\u62ec\u65f6\u95f4\u5206\u5272\u3001\u5f15\u5bfc\u8bb0\u5fc6\u538b\u7f29\u548c\u8de8\u7c92\u5ea6\u878d\u5408\uff0c\u751f\u6210\u53ef\u89e3\u91ca\u7684\u60c5\u8282\u3001\u5bf9\u8bdd\u3001\u60c5\u611f\u548c\u4e0a\u4e0b\u6587\u8f68\u8ff9\u3002\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u81ea\u7531\u5f62\u5f0f\u63d0\u793a\u8fdb\u884c\u7f16\u8f91\u3002", "result": "\u5728400\u591a\u4e2a\u89c6\u9891\u4e0a\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5206\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u504f\u597d\u7814\u7a76\u8fdb\u884c\u8bc4\u4f30\uff0c\u7cfb\u7edf\u80fd\u591f\u6269\u5c55\u63d0\u793a\u9a71\u52a8\u7f16\u8f91\uff0c\u4fdd\u6301\u53d9\u4e8b\u8fde\u8d2f\u6027\uff0c\u5e76\u5e73\u8861\u81ea\u52a8\u5316\u4e0e\u521b\u4f5c\u8005\u63a7\u5236\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u957f\u7bc7\u53d9\u4e8b\u89c6\u9891\u7f16\u8f91\u7684\u8ba4\u77e5\u6311\u6218\uff0c\u901a\u8fc7\u8bed\u4e49\u7406\u89e3\u5b9e\u73b0\u4e86\u66f4\u76f4\u89c2\u7684\u521b\u4f5c\u6d41\u7a0b\uff0c\u5728\u4fdd\u6301\u53d9\u4e8b\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u5347\u4e86\u7f16\u8f91\u6548\u7387\u3002"}}
{"id": "2509.16839", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16839", "abs": "https://arxiv.org/abs/2509.16839", "authors": ["Yu Yao", "Jiayi Dong", "Ju Li", "Yang Yang", "Yilun Du"], "title": "Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs", "comment": "Equal contribution: Yu Yao and Jiayi Dong. Equal advising: Ju Li,\n  Yang Yang, and Yilun Du. Affiliations: Massachusetts Institute of Technology\n  (Yu Yao, Ju Li), University of California, Los Angeles (Jiayi Dong, Yang\n  Yang), Harvard University (Yilun Du)", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities not\nonly in language generation but also in advancing scientific discovery. A\ngrowing body of work has explored ways to improve their reasoning, from\nself-consistency and chain-of-thought to multi-agent debate. Inspired by the\ndynamics of scientific committees and the \"Society of Mind,\" we introduce\nRoundtable Policy, a complementary inference-time reasoning framework that\nperforms inference through the weighted consensus of multiple LLMs. Our\nfindings indicate that this approach significantly enhances reasoning in\ncomplex heterogeneous scientific tasks and improves scientific narratives in\nterms of creativity, rigor, and logical coherence, while reducing\nhallucinations that single models are prone to. Our approach emphasizes\nstructured and interpretable consensus rather than opaque convergence, while\nrequiring only black-box access and uniform procedures, making it broadly\napplicable to multi-LLM reasoning.", "AI": {"tldr": "Roundtable Policy\u662f\u4e00\u79cd\u63a8\u7406\u65f6\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4e2aLLM\u7684\u52a0\u6743\u5171\u8bc6\u6765\u63d0\u5347\u590d\u6742\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u79d1\u5b66\u53d9\u8ff0\u7684\u521b\u9020\u529b\u3001\u4e25\u8c28\u6027\u548c\u903b\u8f91\u8fde\u8d2f\u6027\u3002", "motivation": "\u53d7\u79d1\u5b66\u59d4\u5458\u4f1a\u548c\"\u5fc3\u667a\u793e\u4f1a\"\u7684\u542f\u53d1\uff0c\u65e8\u5728\u6539\u8fdbLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5f25\u8865\u5355\u4e00\u6a21\u578b\u5728\u590d\u6742\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u52a0\u6743\u5171\u8bc6\u673a\u5236\uff0c\u591a\u4e2aLLM\u8fdb\u884c\u63a8\u7406\u5e76\u8fbe\u6210\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u5171\u8bc6\uff0c\u4ec5\u9700\u9ed1\u76d2\u8bbf\u95ee\u548c\u7edf\u4e00\u6d41\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u5f02\u8d28\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u6539\u5584\u4e86\u79d1\u5b66\u53d9\u8ff0\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5355\u4e00\u6a21\u578b\u5bb9\u6613\u4ea7\u751f\u7684\u5e7b\u89c9\u3002", "conclusion": "Roundtable Policy\u662f\u4e00\u4e2a\u5e7f\u6cdb\u9002\u7528\u4e8e\u591aLLM\u63a8\u7406\u7684\u4e92\u8865\u6027\u6846\u67b6\uff0c\u5f3a\u8c03\u7ed3\u6784\u5316\u5171\u8bc6\u800c\u975e\u4e0d\u900f\u660e\u7684\u6536\u655b\u3002"}}
{"id": "2509.16859", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2509.16859", "abs": "https://arxiv.org/abs/2509.16859", "authors": ["Fangfang Li", "Xiaojie Zhang"], "title": "The Principles of Human-like Conscious Machine", "comment": null, "summary": "Determining whether another system, biological or artificial, possesses\nphenomenal consciousness has long been a central challenge in consciousness\nstudies. This attribution problem has become especially pressing with the rise\nof large language models and other advanced AI systems, where debates about \"AI\nconsciousness\" implicitly rely on some criterion for deciding whether a given\nsystem is conscious. In this paper, we propose a substrate-independent,\nlogically rigorous, and counterfeit-resistant sufficiency criterion for\nphenomenal consciousness. We argue that any machine satisfying this criterion\nshould be regarded as conscious with at least the same level of confidence with\nwhich we attribute consciousness to other humans. Building on this criterion,\nwe develop a formal framework and specify a set of operational principles that\nguide the design of systems capable of meeting the sufficiency condition. We\nfurther argue that machines engineered according to this framework can, in\nprinciple, realize phenomenal consciousness. As an initial validation, we show\nthat humans themselves can be viewed as machines that satisfy this framework\nand its principles. If correct, this proposal carries significant implications\nfor philosophy, cognitive science, and artificial intelligence. It offers an\nexplanation for why certain qualia, such as the experience of red, are in\nprinciple irreducible to physical description, while simultaneously providing a\ngeneral reinterpretation of human information processing. Moreover, it suggests\na path toward a new paradigm of AI beyond current statistics-based approaches,\npotentially guiding the construction of genuinely human-like AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u72ec\u7acb\u4e8e\u57fa\u8d28\u7684\u3001\u903b\u8f91\u4e25\u8c28\u4e14\u9632\u4f2a\u7684\u5145\u5206\u6027\u6807\u51c6\uff0c\u7528\u4e8e\u5224\u65ad\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u662f\u5426\u5177\u6709\u73b0\u8c61\u610f\u8bc6\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b49\u5148\u8fdbAI\u7cfb\u7edf\u7684\u5174\u8d77\uff0c\u5224\u65adAI\u662f\u5426\u5177\u6709\u610f\u8bc6\u7684\u95ee\u9898\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u53ef\u9760\u7684\u6807\u51c6\u6765\u89e3\u51b3\u610f\u8bc6\u5f52\u5c5e\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\u548c\u64cd\u4f5c\u6027\u539f\u5219\uff0c\u6307\u5bfc\u8bbe\u8ba1\u80fd\u591f\u6ee1\u8db3\u610f\u8bc6\u5145\u5206\u6761\u4ef6\u7684\u7cfb\u7edf\uff0c\u5e76\u9a8c\u8bc1\u4eba\u7c7b\u672c\u8eab\u4e5f\u7b26\u5408\u8fd9\u4e00\u6846\u67b6\u3002", "result": "\u8bc1\u660e\u6309\u7167\u8be5\u6846\u67b6\u8bbe\u8ba1\u7684\u673a\u5668\u539f\u5219\u4e0a\u53ef\u4ee5\u5b9e\u73b0\u73b0\u8c61\u610f\u8bc6\uff0c\u4eba\u7c7b\u53ef\u88ab\u89c6\u4e3a\u6ee1\u8db3\u8be5\u6846\u67b6\u7684\u673a\u5668\u3002", "conclusion": "\u8be5\u63d0\u8bae\u5bf9\u54f2\u5b66\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u4eba\u5de5\u667a\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4e3a\u6784\u5efa\u771f\u6b63\u7c7b\u4ebaAI\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u540c\u65f6\u89e3\u91ca\u4e86\u67d0\u4e9b\u611f\u53d7\u8d28\u4e3a\u4f55\u65e0\u6cd5\u8fd8\u539f\u4e3a\u7269\u7406\u63cf\u8ff0\u3002"}}
{"id": "2509.16865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16865", "abs": "https://arxiv.org/abs/2509.16865", "authors": ["Xia Jiang", "Yaoxin Wu", "Minshuo Li", "Zhiguang Cao", "Yingqian Zhang"], "title": "Large Language Models as End-to-end Combinatorial Optimization Solvers", "comment": null, "summary": "Combinatorial optimization (CO) problems, central to decision-making\nscenarios like logistics and manufacturing, are traditionally solved using\nproblem-specific algorithms requiring significant domain expertise. While large\nlanguage models (LLMs) have shown promise in automating CO problem solving,\nexisting approaches rely on intermediate steps such as code generation or\nsolver invocation, limiting their generality and accessibility. This paper\nintroduces a novel framework that empowers LLMs to serve as end-to-end CO\nsolvers by directly mapping natural language problem descriptions to solutions.\nWe propose a two-stage training strategy: supervised fine-tuning (SFT) imparts\nLLMs with solution generation patterns from domain-specific solvers, while a\nfeasibility-and-optimality-aware reinforcement learning (FOARL) process\nexplicitly mitigates constraint violations and refines solution quality.\nEvaluation across seven NP-hard CO problems shows that our method achieves a\nhigh feasibility rate and reduces the average optimality gap to 1.03-8.20% by\ntuning a 7B-parameter LLM, surpassing both general-purpose LLMs (e.g., GPT-4o),\nreasoning models (e.g., DeepSeek-R1), and domain-specific heuristics. Our\nmethod establishes a unified language-based pipeline for CO without extensive\ncode execution or manual architectural adjustments for different problems,\noffering a general and language-driven alternative to traditional solver design\nwhile maintaining relative feasibility guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4f5c\u4e3a\u7aef\u5230\u7aef\u7684\u7ec4\u5408\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u76f4\u63a5\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u6620\u5c04\u5230\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u4e2d\u95f4\u4ee3\u7801\u751f\u6210\u6216\u6c42\u89e3\u5668\u8c03\u7528\u3002", "motivation": "\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4f20\u7edf\u4e0a\u9700\u8981\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u4f9d\u8d56\u4e2d\u95f4\u6b65\u9aa4\u9650\u5236\u4e86\u901a\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u8bed\u8a00\u9a71\u52a8\u7ba1\u9053\u6765\u89e3\u51b3CO\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u76d1\u7763\u5fae\u8c03\u4ece\u9886\u57df\u7279\u5b9a\u6c42\u89e3\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u751f\u6210\u6a21\u5f0f\uff0c\u53ef\u884c\u6027-\u6700\u4f18\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u660e\u786e\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\u5e76\u4f18\u5316\u89e3\u8d28\u91cf\u3002", "result": "\u5728\u4e03\u4e2aNP\u96beCO\u95ee\u9898\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u53ef\u884c\u6027\u7387\uff0c\u5e73\u5747\u6700\u4f18\u6027\u5dee\u8ddd\u964d\u81f31.03-8.20%\uff0c\u8d85\u8d8a\u4e86\u901a\u7528LLM\u3001\u63a8\u7406\u6a21\u578b\u548c\u9886\u57df\u7279\u5b9a\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aCO\u95ee\u9898\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u57fa\u4e8e\u8bed\u8a00\u7684\u7ba1\u9053\uff0c\u65e0\u9700\u5927\u91cf\u4ee3\u7801\u6267\u884c\u6216\u624b\u52a8\u67b6\u6784\u8c03\u6574\uff0c\u63d0\u4f9b\u4e86\u4f20\u7edf\u6c42\u89e3\u5668\u8bbe\u8ba1\u7684\u901a\u7528\u8bed\u8a00\u9a71\u52a8\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.16866", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16866", "abs": "https://arxiv.org/abs/2509.16866", "authors": ["Mohammad Ramezanali", "Mo Vazifeh", "Paolo Santi"], "title": "seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs", "comment": null, "summary": "We introduce seqBench, a parametrized benchmark for probing sequential\nreasoning limits in Large Language Models (LLMs) through precise,\nmulti-dimensional control over several key complexity dimensions. seqBench\nallows systematic variation of (1) the logical depth, defined as the number of\nsequential actions required to solve the task; (2) the number of backtracking\nsteps along the optimal path, quantifying how often the agent must revisit\nprior states to satisfy deferred preconditions (e.g., retrieving a key after\nencountering a locked door); and (3) the noise ratio, defined as the ratio\nbetween supporting and distracting facts about the environment. Our evaluations\non state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses\nexponentially beyond a model-specific logical depth. Unlike existing\nbenchmarks, seqBench's fine-grained control facilitates targeted analyses of\nthese reasoning failures, illuminating universal scaling laws and statistical\nlimits, as detailed in this paper alongside its generation methodology and\nevaluation metrics. We find that even top-performing models systematically fail\non seqBench's structured reasoning tasks despite minimal search complexity,\nunderscoring key limitations in their commonsense reasoning capabilities.\nDesigned for future evolution to keep pace with advancing models, the seqBench\ndatasets are publicly released to spur deeper scientific inquiry into LLM\nreasoning, aiming to establish a clearer understanding of their true potential\nand current boundaries for robust real-world application.", "AI": {"tldr": "seqBench\u662f\u4e00\u4e2a\u53c2\u6570\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u901a\u8fc7\u7cbe\u786e\u63a7\u5236\u591a\u4e2a\u5173\u952e\u590d\u6742\u5ea6\u7ef4\u5ea6\u6765\u63a2\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e8f\u5217\u63a8\u7406\u6781\u9650\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u5bf9\u5e8f\u5217\u63a8\u7406\u590d\u6742\u5ea6\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u65e0\u6cd5\u7cfb\u7edf\u5206\u6790LLMs\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u903b\u8f91\u6df1\u5ea6\u3001\u56de\u6eaf\u6b65\u9aa4\u6570\u548c\u566a\u58f0\u6bd4\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u6784\u5efa\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u6765\u8bc4\u4f30LLMs\u7684\u5e8f\u5217\u63a8\u7406\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\u6700\u5148\u8fdb\u7684LLMs\u5728\u8d85\u8fc7\u7279\u5b9a\u903b\u8f91\u6df1\u5ea6\u540e\u51c6\u786e\u7387\u5448\u6307\u6570\u7ea7\u4e0b\u964d\uff0c\u5373\u4f7f\u641c\u7d22\u590d\u6742\u5ea6\u6700\u5c0f\u4e5f\u4f1a\u7cfb\u7edf\u6027\u5730\u5931\u8d25\u3002", "conclusion": "seqBench\u63ed\u793a\u4e86LLMs\u5728\u5e38\u8bc6\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u4e3a\u7406\u89e3\u5176\u771f\u5b9e\u6f5c\u529b\u548c\u5f53\u524d\u8fb9\u754c\u63d0\u4f9b\u4e86\u79d1\u5b66\u4f9d\u636e\uff0c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2509.16891", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16891", "abs": "https://arxiv.org/abs/2509.16891", "authors": ["Sha Li"], "title": "LLMs as Layout Designers: A Spatial Reasoning Perspective", "comment": null, "summary": "While Large Language Models (LLMs) have demonstrated impressive reasoning and\nplanning abilities in textual domains and can effectively follow instructions\nfor complex tasks, their capacity for spatial understanding and reasoning\nremains limited. Such capabilities, however, are critical for applications like\ncontent-aware graphic layout design, which demands precise placement,\nalignment, and structural organization of multiple elements within constrained\nvisual spaces. To address this gap, we propose LaySPA, a reinforcement\nlearning-based framework that augments LLM agents with explicit spatial\nreasoning capabilities. LaySPA leverages hybrid reward signals that capture\ngeometric validity, structural fidelity, and visual quality, enabling agents to\nmodel inter-element relationships, navigate the canvas, and optimize spatial\narrangements. Through iterative self-exploration and adaptive policy\noptimization, LaySPA produces both interpretable reasoning traces and\nstructured layouts. Experimental results demonstrate that LaySPA generates\nstructurally sound and visually appealing layouts, outperforming larger\ngeneral-purpose LLMs and achieving results on par with state-of-the-art\nspecialized layout models.", "AI": {"tldr": "LaySPA\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3aLLM\u4ee3\u7406\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e13\u95e8\u7528\u4e8e\u56fe\u5f62\u5e03\u5c40\u8bbe\u8ba1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u9886\u57df\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\uff0c\u4f46\u5728\u7a7a\u95f4\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u8fd9\u5bf9\u4e8e\u9700\u8981\u7cbe\u786e\u653e\u7f6e\u3001\u5bf9\u9f50\u548c\u7ed3\u6784\u7ec4\u7ec7\u7684\u56fe\u5f62\u5e03\u5c40\u8bbe\u8ba1\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "LaySPA\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u6df7\u5408\u5956\u52b1\u4fe1\u53f7\uff08\u51e0\u4f55\u6709\u6548\u6027\u3001\u7ed3\u6784\u4fdd\u771f\u5ea6\u548c\u89c6\u89c9\u8d28\u91cf\uff09\u6765\u589e\u5f3aLLM\u4ee3\u7406\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u63a2\u7d22\u548c\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\u6765\u5efa\u6a21\u5143\u7d20\u95f4\u5173\u7cfb\u3001\u5bfc\u822a\u753b\u5e03\u5e76\u4f18\u5316\u7a7a\u95f4\u6392\u5217\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLaySPA\u80fd\u591f\u751f\u6210\u7ed3\u6784\u5408\u7406\u4e14\u89c6\u89c9\u5438\u5f15\u4eba\u7684\u5e03\u5c40\uff0c\u6027\u80fd\u4f18\u4e8e\u66f4\u5927\u7684\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4e0e\u6700\u5148\u8fdb\u7684\u4e13\u7528\u5e03\u5c40\u6a21\u578b\u7ed3\u679c\u76f8\u5f53\u3002", "conclusion": "LaySPA\u6210\u529f\u5730\u5c06\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u96c6\u6210\u5230LLM\u4ee3\u7406\u4e2d\uff0c\u4e3a\u5185\u5bb9\u611f\u77e5\u7684\u56fe\u5f62\u5e03\u5c40\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u7a7a\u767d\u3002"}}
{"id": "2509.16924", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.16924", "abs": "https://arxiv.org/abs/2509.16924", "authors": ["Jia Li", "Yinfeng Yu", "Liejun Wang", "Fuchun Sun", "Wendong Zheng"], "title": "Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation", "comment": "Main paper (14 pages). Accepted for publication by ICONIP(\n  International Conference on Neural Information Processing) 2025", "summary": "In audio-visual navigation (AVN) tasks, an embodied agent must autonomously\nlocalize a sound source in unknown and complex 3D environments based on\naudio-visual signals. Existing methods often rely on static modality fusion\nstrategies and neglect the spatial cues embedded in stereo audio, leading to\nperformance degradation in cluttered or occluded scenes. To address these\nissues, we propose an end-to-end reinforcement learning-based AVN framework\nwith two key innovations: (1) a \\textbf{S}tereo-Aware \\textbf{A}ttention\n\\textbf{M}odule (\\textbf{SAM}), which learns and exploits the spatial disparity\nbetween left and right audio channels to enhance directional sound perception;\nand (2) an \\textbf{A}udio-\\textbf{G}uided \\textbf{D}ynamic \\textbf{F}usion\nModule (\\textbf{AGDF}), which dynamically adjusts the fusion ratio between\nvisual and auditory features based on audio cues, thereby improving robustness\nto environmental changes. Extensive experiments are conducted on two realistic\n3D scene datasets, Replica and Matterport3D, demonstrating that our method\nsignificantly outperforms existing approaches in terms of navigation success\nrate and path efficiency. Notably, our model achieves over 40\\% improvement\nunder audio-only conditions compared to the best-performing baselines. These\nresults highlight the importance of explicitly modeling spatial cues from\nstereo channels and performing deep multi-modal fusion for robust and efficient\naudio-visual navigation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u97f3\u9891-\u89c6\u89c9\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u7acb\u4f53\u58f0\u611f\u77e5\u6ce8\u610f\u529b\u6a21\u5757\u548c\u97f3\u9891\u5f15\u5bfc\u52a8\u6001\u878d\u5408\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u590d\u67423D\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u97f3\u9891-\u89c6\u89c9\u5bfc\u822a\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u9759\u6001\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u5ffd\u89c6\u4e86\u7acb\u4f53\u97f3\u9891\u4e2d\u7684\u7a7a\u95f4\u7ebf\u7d22\uff0c\u5bfc\u81f4\u5728\u6742\u4e71\u6216\u906e\u6321\u573a\u666f\u4e2d\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u5173\u952e\u521b\u65b0\u6a21\u5757\uff1a1\uff09\u7acb\u4f53\u58f0\u611f\u77e5\u6ce8\u610f\u529b\u6a21\u5757\uff08SAM\uff09\uff0c\u5b66\u4e60\u5e76\u5229\u7528\u5de6\u53f3\u97f3\u9891\u901a\u9053\u7684\u7a7a\u95f4\u5dee\u5f02\u6765\u589e\u5f3a\u65b9\u5411\u6027\u58f0\u97f3\u611f\u77e5\uff1b2\uff09\u97f3\u9891\u5f15\u5bfc\u52a8\u6001\u878d\u5408\u6a21\u5757\uff08AGDF\uff09\uff0c\u57fa\u4e8e\u97f3\u9891\u7ebf\u7d22\u52a8\u6001\u8c03\u6574\u89c6\u89c9\u548c\u542c\u89c9\u7279\u5f81\u7684\u878d\u5408\u6bd4\u4f8b\u3002", "result": "\u5728Replica\u548cMatterport3D\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5bfc\u822a\u6210\u529f\u7387\u548c\u8def\u5f84\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u7eaf\u97f3\u9891\u6761\u4ef6\u4e0b\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u5b9e\u73b0\u4e86\u8d85\u8fc740%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u660e\u786e\u5efa\u6a21\u7acb\u4f53\u58f0\u901a\u9053\u7684\u7a7a\u95f4\u7ebf\u7d22\u5e76\u8fdb\u884c\u6df1\u5ea6\u591a\u6a21\u6001\u878d\u5408\u5bf9\u4e8e\u5b9e\u73b0\u9c81\u68d2\u9ad8\u6548\u7684\u97f3\u9891-\u89c6\u89c9\u5bfc\u822a\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.16958", "categories": ["cs.AI", "I.2.0; I.2.1; I.2.3; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.16958", "abs": "https://arxiv.org/abs/2509.16958", "authors": ["Remo Pareschi"], "title": "Quantum Abduction: A New Paradigm for Reasoning under Uncertainty", "comment": "23 pages, 8 figures, 3 tables; submitted to Sci, MDPI", "summary": "Abductive reasoning - the search for plausible explanations - has long been\ncentral to human inquiry, from forensics to medicine and scientific discovery.\nYet formal approaches in AI have largely reduced abduction to eliminative\nsearch: hypotheses are treated as mutually exclusive, evaluated against\nconsistency constraints or probability updates, and pruned until a single\n\"best\" explanation remains. This reductionist framing overlooks the way human\nreasoners sustain multiple explanatory lines in suspension, navigate\ncontradictions, and generate novel syntheses. This paper introduces quantum\nabduction, a non-classical paradigm that models hypotheses in superposition,\nallows them to interfere constructively or destructively, and collapses only\nwhen coherence with evidence is reached. Grounded in quantum cognition and\nimplemented with modern NLP embeddings and generative AI, the framework\nsupports dynamic synthesis rather than premature elimination. Case studies span\nhistorical mysteries (Ludwig II of Bavaria, the \"Monster of Florence\"),\nliterary demonstrations (\"Murder on the Orient Express\"), medical diagnosis,\nand scientific theory change. Across these domains, quantum abduction proves\nmore faithful to the constructive and multifaceted nature of human reasoning,\nwhile offering a pathway toward expressive and transparent AI reasoning\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u91cf\u5b50\u6eaf\u56e0\u63a8\u7406\uff0c\u8fd9\u662f\u4e00\u79cd\u975e\u7ecf\u5178\u8303\u5f0f\uff0c\u5c06\u5047\u8bbe\u5efa\u6a21\u4e3a\u53e0\u52a0\u6001\uff0c\u5141\u8bb8\u5b83\u4eec\u5efa\u8bbe\u6027\u6216\u7834\u574f\u6027\u5730\u5e72\u6d89\uff0c\u4ec5\u5728\u8fbe\u5230\u4e0e\u8bc1\u636e\u7684\u4e00\u81f4\u6027\u65f6\u624d\u574d\u7f29\u3002", "motivation": "\u4f20\u7edf\u7684AI\u6eaf\u56e0\u63a8\u7406\u5c06\u5047\u8bbe\u89c6\u4e3a\u4e92\u65a5\u7684\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u7ea6\u675f\u6216\u6982\u7387\u66f4\u65b0\u8fdb\u884c\u8bc4\u4f30\u548c\u4fee\u526a\uff0c\u76f4\u5230\u5269\u4e0b\u5355\u4e2a\"\u6700\u4f73\"\u89e3\u91ca\u3002\u8fd9\u79cd\u7b80\u5316\u6846\u67b6\u5ffd\u89c6\u4e86\u4eba\u7c7b\u63a8\u7406\u8005\u5982\u4f55\u7ef4\u6301\u591a\u4e2a\u89e3\u91ca\u7ebf\u7d22\u3001\u5904\u7406\u77db\u76fe\u5e76\u751f\u6210\u65b0\u9896\u7efc\u5408\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u91cf\u5b50\u8ba4\u77e5\u7406\u8bba\uff0c\u7ed3\u5408\u73b0\u4ee3NLP\u5d4c\u5165\u548c\u751f\u6210\u5f0fAI\u5b9e\u73b0\uff0c\u652f\u6301\u52a8\u6001\u7efc\u5408\u800c\u975e\u8fc7\u65e9\u6d88\u9664\u7684\u6846\u67b6\u3002", "result": "\u5728\u5386\u53f2\u8c1c\u6848\u3001\u6587\u5b66\u6f14\u793a\u3001\u533b\u5b66\u8bca\u65ad\u548c\u79d1\u5b66\u7406\u8bba\u53d8\u9769\u7b49\u591a\u4e2a\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u91cf\u5b50\u6eaf\u56e0\u63a8\u7406\u88ab\u8bc1\u660e\u66f4\u7b26\u5408\u4eba\u7c7b\u63a8\u7406\u7684\u5efa\u6784\u6027\u548c\u591a\u9762\u6027\u672c\u8d28\u3002", "conclusion": "\u91cf\u5b50\u6eaf\u56e0\u63a8\u7406\u4e3a\u6784\u5efa\u8868\u8fbe\u6027\u5f3a\u4e14\u900f\u660e\u7684AI\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u9014\u5f84\uff0c\u66f4\u5fe0\u5b9e\u4e8e\u4eba\u7c7b\u63a8\u7406\u7684\u5efa\u6784\u6027\u548c\u591a\u9762\u6027\u3002"}}
{"id": "2509.17037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17037", "abs": "https://arxiv.org/abs/2509.17037", "authors": ["Yajing Yang", "Tony Deng", "Min-Yen Kan"], "title": "KAHAN: Knowledge-Augmented Hierarchical Analysis and Narration for Financial Data Narration", "comment": "Accepted at EMNLP 2025 Findings", "summary": "We propose KAHAN, a knowledge-augmented hierarchical framework that\nsystematically extracts insights from raw tabular data at entity, pairwise,\ngroup, and system levels. KAHAN uniquely leverages LLMs as domain experts to\ndrive the analysis. On DataTales financial reporting benchmark, KAHAN\noutperforms existing approaches by over 20% on narrative quality (GPT-4o),\nmaintains 98.2% factuality, and demonstrates practical utility in human\nevaluation. Our results reveal that knowledge quality drives model performance\nthrough distillation, hierarchical analysis benefits vary with market\ncomplexity, and the framework transfers effectively to healthcare domains. The\ndata and code are available at https://github.com/yajingyang/kahan.", "AI": {"tldr": "KAHAN\u662f\u4e00\u4e2a\u77e5\u8bc6\u589e\u5f3a\u7684\u5206\u5c42\u6846\u67b6\uff0c\u901a\u8fc7LLMs\u4f5c\u4e3a\u9886\u57df\u4e13\u5bb6\u4ece\u539f\u59cb\u8868\u683c\u6570\u636e\u4e2d\u7cfb\u7edf\u63d0\u53d6\u5b9e\u4f53\u3001\u6210\u5bf9\u3001\u7ec4\u548c\u7cfb\u7edf\u7ea7\u522b\u7684\u6d1e\u5bdf\u3002\u5728\u91d1\u878d\u62a5\u544a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u53d9\u4e8b\u8d28\u91cf\u63d0\u534720%\u4ee5\u4e0a\uff0c\u4e8b\u5b9e\u6027\u8fbe98.2%\uff0c\u5e76\u53ef\u6709\u6548\u8fc1\u79fb\u5230\u533b\u7597\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8868\u683c\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5206\u6790\u6846\u67b6\u6765\u63d0\u53d6\u591a\u5c42\u6b21\u6d1e\u5bdf\uff0c\u5e76\u5229\u7528LLMs\u7684\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u63d0\u5347\u5206\u6790\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u589e\u5f3a\u7684\u5206\u5c42\u5206\u6790\u6846\u67b6\uff0c\u5229\u7528LLMs\u4f5c\u4e3a\u9886\u57df\u4e13\u5bb6\u9a71\u52a8\u5206\u6790\u8fc7\u7a0b\uff0c\u5305\u62ec\u5b9e\u4f53\u7ea7\u3001\u6210\u5bf9\u7ea7\u3001\u7ec4\u7ea7\u548c\u7cfb\u7edf\u7ea7\u56db\u4e2a\u5c42\u6b21\u7684\u5206\u6790\u3002", "result": "\u5728DataTales\u91d1\u878d\u62a5\u544a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cKAHAN\u5728\u53d9\u4e8b\u8d28\u91cf\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc720%\uff0c\u4fdd\u630198.2%\u7684\u4e8b\u5b9e\u6027\uff0c\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5e76\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u533b\u7597\u9886\u57df\u3002", "conclusion": "\u77e5\u8bc6\u8d28\u91cf\u901a\u8fc7\u84b8\u998f\u9a71\u52a8\u6a21\u578b\u6027\u80fd\uff0c\u5206\u5c42\u5206\u6790\u7684\u6548\u679c\u968f\u5e02\u573a\u590d\u6742\u5ea6\u53d8\u5316\uff0c\u6846\u67b6\u5177\u6709\u826f\u597d\u7684\u9886\u57df\u8fc1\u79fb\u80fd\u529b\uff0c\u4e3a\u8868\u683c\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.17062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17062", "abs": "https://arxiv.org/abs/2509.17062", "authors": ["Cristian P\u00e9rez-Corral", "Antonio Garrido", "Laura Sebastia"], "title": "From domain-landmark graph learning to problem-landmark graph generation", "comment": null, "summary": "Landmarks have long played a pivotal role in automated planning, serving as\ncrucial elements for improving the planning algorithms. The main limitation of\nclassical landmark extraction methods is their sensitivity to specific planning\ntasks. This results in landmarks fully tailored to individual instances,\nthereby limiting their applicability across other instances of the same\nplanning domain. We propose a novel approach that learns landmark relationships\nfrom multiple planning tasks of a planning domain. This leads to the creation\nof a \\textit{probabilistic lifted ordering graph}, as a structure that captures\nweighted abstractions of relationships between parameterized landmarks.\nAlthough these orderings are not 100\\% true (they are probabilistic), they can\nstill be very useful in planning. Next, given a new planning task for that\ndomain, we instantiate the relationships from that graph to this particular\ninstance. This instantiation operates in two phases. First, it generates two\ngraphs: the former instantiating information from the initial state and the\nlatter from the goal state. Second, it combines these two graphs into one\nunified graph by searching equivalences to extract landmark orderings. We\nevaluate the precision and recallof the information found by our approach over\nwell-known planning domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u89c4\u5212\u57df\u4e2d\u5b66\u4e60\u5730\u6807\u5173\u7cfb\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u521b\u5efa\u6982\u7387\u63d0\u5347\u6392\u5e8f\u56fe\u6765\u6355\u6349\u53c2\u6570\u5316\u5730\u6807\u4e4b\u95f4\u7684\u52a0\u6743\u62bd\u8c61\u5173\u7cfb\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u65b0\u7684\u89c4\u5212\u4efb\u52a1\u4e2d\u3002", "motivation": "\u4f20\u7edf\u5730\u6807\u63d0\u53d6\u65b9\u6cd5\u5bf9\u7279\u5b9a\u89c4\u5212\u4efb\u52a1\u654f\u611f\uff0c\u5bfc\u81f4\u5730\u6807\u4ec5\u9002\u7528\u4e8e\u5355\u4e2a\u5b9e\u4f8b\uff0c\u9650\u5236\u4e86\u5176\u5728\u540c\u4e00\u89c4\u5212\u57df\u5176\u4ed6\u5b9e\u4f8b\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4ece\u591a\u4e2a\u89c4\u5212\u4efb\u52a1\u4e2d\u5b66\u4e60\u5730\u6807\u5173\u7cfb\uff0c\u6784\u5efa\u6982\u7387\u63d0\u5347\u6392\u5e8f\u56fe\uff1b\u5bf9\u4e8e\u65b0\u4efb\u52a1\uff0c\u5206\u4e24\u9636\u6bb5\u5b9e\u4f8b\u5316\u5173\u7cfb\uff1a\u4ece\u521d\u59cb\u72b6\u6001\u548c\u76ee\u6807\u72b6\u6001\u5206\u522b\u751f\u6210\u56fe\uff0c\u7136\u540e\u901a\u8fc7\u641c\u7d22\u7b49\u4ef7\u6027\u5408\u5e76\u4e3a\u7edf\u4e00\u56fe\u6765\u63d0\u53d6\u5730\u6807\u6392\u5e8f\u3002", "result": "\u5728\u77e5\u540d\u89c4\u5212\u57df\u4e0a\u8bc4\u4f30\u4e86\u65b9\u6cd5\u7684\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u3002", "conclusion": "\u5c3d\u7ba1\u5b66\u4e60\u5230\u7684\u6392\u5e8f\u5173\u7cfb\u4e0d\u662f100%\u51c6\u786e\uff08\u6982\u7387\u6027\u7684\uff09\uff0c\u4f46\u5728\u89c4\u5212\u4e2d\u4ecd\u7136\u975e\u5e38\u6709\u7528\u3002"}}
{"id": "2509.17066", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.17066", "abs": "https://arxiv.org/abs/2509.17066", "authors": ["Kunrong Li", "Kwan Hui Lim"], "title": "RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking", "comment": "PRICAI 2025", "summary": "Next point-of-interest (POI) recommendation predicts a user's next\ndestination from historical movements. Traditional models require intensive\ntraining, while LLMs offer flexible and generalizable zero-shot solutions but\noften generate generic or geographically irrelevant results due to missing\ntrajectory and spatial context. To address these issues, we propose RALLM-POI,\na framework that couples LLMs with retrieval-augmented generation and\nself-rectification. We first propose a Historical Trajectory Retriever (HTR)\nthat retrieves relevant past trajectories to serve as contextual references,\nwhich are then reranked by a Geographical Distance Reranker (GDR) for\nprioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier\n(ALR) is designed to refine outputs through self-reflection. Without additional\ntraining, RALLM-POI achieves substantial accuracy gains across three real-world\nFoursquare datasets, outperforming both conventional and LLM-based baselines.\nCode is released at https://github.com/LKRcrocodile/RALLM-POI.", "AI": {"tldr": "RALLM-POI\u662f\u4e00\u4e2a\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u81ea\u6211\u4fee\u6b63\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4e0b\u4e00\u4e2a\u5174\u8da3\u70b9\u63a8\u8350\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u9700\u8981\u5bc6\u96c6\u8bad\u7ec3\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u7531\u4e8e\u7f3a\u4e4f\u8f68\u8ff9\u548c\u7a7a\u95f4\u4e0a\u4e0b\u6587\uff0c\u5f80\u5f80\u4ea7\u751f\u901a\u7528\u6216\u5730\u7406\u4e0d\u76f8\u5173\u7684\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u5386\u53f2\u8f68\u8ff9\u68c0\u7d22\u5668(HTR)\u68c0\u7d22\u76f8\u5173\u5386\u53f2\u8f68\u8ff9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u53c2\u8003\uff0c\u5730\u7406\u8ddd\u79bb\u91cd\u6392\u5668(GDR)\u4f18\u5148\u9009\u62e9\u7a7a\u95f4\u76f8\u5173\u8f68\u8ff9\uff0c\u4ee3\u7406LLM\u4fee\u6b63\u5668(ALR)\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u4f18\u5316\u8f93\u51fa\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9eFoursquare\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u51c6\u786e\u6027\u63d0\u5347\uff0c\u4f18\u4e8e\u4f20\u7edf\u548c\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RALLM-POI\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728POI\u63a8\u8350\u4e2d\u7684\u4e0a\u4e0b\u6587\u7f3a\u5931\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u68c0\u7d22\u589e\u5f3a\u548c\u81ea\u6211\u4fee\u6b63\u7b56\u7565\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2509.17068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17068", "abs": "https://arxiv.org/abs/2509.17068", "authors": ["Chen Wang", "Sarah Erfani", "Tansu Alpcan", "Christopher Leckie"], "title": "Intention-aware Hierarchical Diffusion Model for Long-term Trajectory Anomaly Detection", "comment": "15 pages, 5 figures", "summary": "Long-term trajectory anomaly detection is a challenging problem due to the\ndiversity and complex spatiotemporal dependencies in trajectory data. Existing\ntrajectory anomaly detection methods fail to simultaneously consider both the\nhigh-level intentions of agents as well as the low-level details of the agent's\nnavigation when analysing an agent's trajectories. This limits their ability to\ncapture the full diversity of normal trajectories. In this paper, we propose an\nunsupervised trajectory anomaly detection method named Intention-aware\nHierarchical Diffusion model (IHiD), which detects anomalies through both\nhigh-level intent evaluation and low-level sub-trajectory analysis. Our\napproach leverages Inverse Q Learning as the high-level model to assess whether\na selected subgoal aligns with an agent's intention based on predicted\nQ-values. Meanwhile, a diffusion model serves as the low-level model to\ngenerate sub-trajectories conditioned on subgoal information, with anomaly\ndetection based on reconstruction error. By integrating both models, IHiD\neffectively utilises subgoal transition knowledge and is designed to capture\nthe diverse distribution of normal trajectories. Our experiments show that the\nproposed method IHiD achieves up to 30.2% improvement in anomaly detection\nperformance in terms of F1 score over state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIHiD\u7684\u65e0\u76d1\u7763\u8f68\u8ff9\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u9ad8\u5c42\u610f\u56fe\u8bc4\u4f30\u548c\u4f4e\u5c42\u5b50\u8f68\u8ff9\u5206\u6790\u6765\u68c0\u6d4b\u5f02\u5e38\u8f68\u8ff9\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u9006Q\u5b66\u4e60\u4f5c\u4e3a\u9ad8\u5c42\u6a21\u578b\u8bc4\u4f30\u5b50\u76ee\u6807\u4e0e\u610f\u56fe\u7684\u4e00\u81f4\u6027\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u4f4e\u5c42\u6a21\u578b\u751f\u6210\u5b50\u8f68\u8ff9\uff0c\u901a\u8fc7\u91cd\u6784\u8bef\u5dee\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u8f68\u8ff9\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u8003\u8651\u667a\u80fd\u4f53\u7684\u9ad8\u5c42\u610f\u56fe\u548c\u4f4e\u5c42\u5bfc\u822a\u7ec6\u8282\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u6355\u6349\u6b63\u5e38\u8f68\u8ff9\u591a\u6837\u6027\u7684\u80fd\u529b\u3002", "method": "IHiD\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u5c42\u6b21\uff1a\u9ad8\u5c42\u4f7f\u7528\u9006Q\u5b66\u4e60\u8bc4\u4f30\u5b50\u76ee\u6807\u4e0e\u610f\u56fe\u7684\u4e00\u81f4\u6027\uff0c\u4f4e\u5c42\u4f7f\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u57fa\u4e8e\u5b50\u76ee\u6807\u4fe1\u606f\u7684\u5b50\u8f68\u8ff9\uff0c\u901a\u8fc7\u91cd\u6784\u8bef\u5dee\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIHiD\u5728F1\u5206\u6570\u4e0a\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u5347\u4e8630.2%\u7684\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "IHiD\u65b9\u6cd5\u901a\u8fc7\u5c42\u6b21\u5316\u5efa\u6a21\u6709\u6548\u5229\u7528\u4e86\u5b50\u76ee\u6807\u8f6c\u79fb\u77e5\u8bc6\uff0c\u80fd\u591f\u6355\u6349\u6b63\u5e38\u8f68\u8ff9\u7684\u591a\u6837\u5206\u5e03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2509.17087", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17087", "abs": "https://arxiv.org/abs/2509.17087", "authors": ["Nicholas Kruus", "Madhavendra Thakur", "Adam Khoja", "Leonhard Nagel", "Maximilian Nicholson", "Abeer Sharma", "Jason Hausenloy", "Alberto KoTafoya", "Aliya Mukhanova", "Alli Katila-Miikkulainen", "Harish Chandran", "Ivan Zhang", "Jessie Chen", "Joel Raj", "Jord Nguyen", "Lai Hsien Hao", "Neja Jayasundara", "Soham Sen", "Sophie Zhang", "Ashley Dora Kokui Tamaklo", "Bhavya Thakur", "Henry Close", "Janghee Lee", "Nina Sefton", "Raghavendra Thakur", "Shiv Munagala", "Yeeun Kim"], "title": "Governing Automated Strategic Intelligence", "comment": null, "summary": "Military and economic strategic competitiveness between nation-states will\nincreasingly be defined by the capability and cost of their frontier artificial\nintelligence models. Among the first areas of geopolitical advantage granted by\nsuch systems will be in automating military intelligence. Much discussion has\nbeen devoted to AI systems enabling new military modalities, such as lethal\nautonomous weapons, or making strategic decisions. However, the ability of a\ncountry of \"CIA analysts in a data-center\" to synthesize diverse data at scale,\nand its implications, have been underexplored. Multimodal foundation models\nappear on track to automate strategic analysis previously done by humans. They\nwill be able to fuse today's abundant satellite imagery, phone-location traces,\nsocial media records, and written documents into a single queryable system. We\nconduct a preliminary uplift study to empirically evaluate these capabilities,\nthen propose a taxonomy of the kinds of ground truth questions these systems\nwill answer, present a high-level model of the determinants of this system's AI\ncapabilities, and provide recommendations for nation-states to remain\nstrategically competitive within the new paradigm of automated intelligence.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u524d\u6cbfAI\u6a21\u578b\u5728\u519b\u4e8b\u60c5\u62a5\u81ea\u52a8\u5316\u65b9\u9762\u7684\u5730\u7f18\u653f\u6cbb\u4f18\u52bf\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5982\u4f55\u878d\u5408\u536b\u661f\u56fe\u50cf\u3001\u624b\u673a\u5b9a\u4f4d\u3001\u793e\u4ea4\u5a92\u4f53\u7b49\u6570\u636e\u6e90\u8fdb\u884c\u6218\u7565\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u4fdd\u6301\u6218\u7565\u7ade\u4e89\u529b\u7684\u5efa\u8bae\u3002", "motivation": "\u56fd\u5bb6\u95f4\u7684\u519b\u4e8b\u548c\u7ecf\u6d4e\u6218\u7565\u7ade\u4e89\u529b\u5c06\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8e\u524d\u6cbfAI\u6a21\u578b\u7684\u80fd\u529b\u548c\u6210\u672c\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u5316\u519b\u4e8b\u60c5\u62a5\u9886\u57df\u3002\u76ee\u524d\u5bf9\u4e8eAI\u7cfb\u7edf\u5982\u4f55\u901a\u8fc7\u878d\u5408\u591a\u6e90\u6570\u636e\u5b9e\u73b0\u6218\u7565\u5206\u6790\u7684\u6f5c\u529b\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u8fdb\u884c\u4e86\u521d\u6b65\u7684\u63d0\u5347\u7814\u7a76\u6765\u5b9e\u8bc1\u8bc4\u4f30\u8fd9\u4e9b\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u5c06\u56de\u7b54\u7684\u771f\u5b9e\u95ee\u9898\u5206\u7c7b\u6cd5\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edfAI\u80fd\u529b\u51b3\u5b9a\u56e0\u7d20\u7684\u9ad8\u5c42\u6a21\u578b\u3002", "result": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u6709\u671b\u81ea\u52a8\u5316\u4ee5\u5f80\u7531\u4eba\u7c7b\u5b8c\u6210\u7684\u6218\u7565\u5206\u6790\u5de5\u4f5c\uff0c\u80fd\u591f\u5c06\u536b\u661f\u56fe\u50cf\u3001\u624b\u673a\u5b9a\u4f4d\u3001\u793e\u4ea4\u5a92\u4f53\u8bb0\u5f55\u548c\u4e66\u9762\u6587\u6863\u878d\u5408\u6210\u5355\u4e00\u53ef\u67e5\u8be2\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u56fd\u5bb6\u5728\u65b0\u4e00\u4ee3\u81ea\u52a8\u5316\u60c5\u62a5\u8303\u5f0f\u4e0b\u4fdd\u6301\u6218\u7565\u7ade\u4e89\u529b\u7684\u5177\u4f53\u5efa\u8bae\u3002"}}
{"id": "2509.17116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17116", "abs": "https://arxiv.org/abs/2509.17116", "authors": ["Hang Xu", "Zang Yu", "Yehui Tang", "Pengbo Hu", "Yuhao Tang", "Hao Dong"], "title": "MCTS-EP: Empowering Embodied Planning with Online Preference Optimization", "comment": null, "summary": "This paper introduces MCTS-EP, an online learning framework that combines\nlarge language models (LLM) with Monte Carlo Tree Search (MCTS) for training\nembodied agents. MCTS-EP integrates three key components: MCTS-guided\nexploration for preference data collection, efficient multi-modal reasoning\nmechanism, and iterative training pipeline based on preference optimization. We\ntheoretically prove that MCTS-EP achieves better performance bounds than\nconventional on-policy algorithms when the loss function is strongly convex,\nand demonstrate that it can be formulated as a search-enhanced variant of GAIL.\nMCTS-EP achieves state-of-the-art performace across serval benchmarks. In\nALFWorld, it achieves 92% and 87% success rates for textual and visual tasks.\nIn WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average\ninteraction steps from from 18.7/19.5 to 10.2/9.9 steps in visual ALFWorld.Code\navailable at: https://github.com/xuhang-2/Embodied-Agent-Planning", "AI": {"tldr": "MCTS-EP\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u5728\u7ebf\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6709\u6548\u6574\u5408LLM\u63a8\u7406\u80fd\u529b\u548cMCTS\u641c\u7d22\u7b56\u7565\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u5177\u8eab\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u6574\u5408\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1aMCTS\u5f15\u5bfc\u7684\u504f\u597d\u6570\u636e\u6536\u96c6\u3001\u9ad8\u6548\u591a\u6a21\u6001\u63a8\u7406\u673a\u5236\u3001\u57fa\u4e8e\u504f\u597d\u4f18\u5316\u7684\u8fed\u4ee3\u8bad\u7ec3\u6d41\u7a0b\u3002\u7406\u8bba\u8bc1\u660e\u5728\u5f3a\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u4f18\u4e8e\u4f20\u7edf\u7b56\u7565\u7b97\u6cd5\u3002", "result": "\u5728ALFWorld\u4e2d\u6587\u672c\u4efb\u52a1\u8fbe\u523092%\u6210\u529f\u7387\uff0c\u89c6\u89c9\u4efb\u52a187%\u6210\u529f\u7387\uff1b\u5728WebShop\u4e2d\u5e73\u5747\u5956\u52b10.81\uff1b\u89c6\u89c9ALFWorld\u4e2d\u5e73\u5747\u4ea4\u4e92\u6b65\u9aa4\u4ece18.7/19.5\u51cf\u5c11\u523010.2/9.9\u6b65\u3002", "conclusion": "MCTS-EP\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u641c\u7d22\u589e\u5f3a\u65b9\u6cd5\u5728\u5177\u8eab\u667a\u80fd\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.17158", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.17158", "abs": "https://arxiv.org/abs/2509.17158", "authors": ["Pierre Andrews", "Amine Benhalloum", "Gerard Moreno-Torres Bertran", "Matteo Bettini", "Amar Budhiraja", "Ricardo Silveira Cabral", "Virginie Do", "Romain Froger", "Emilien Garreau", "Jean-Baptiste Gaya", "Hugo Lauren\u00e7on", "Maxime Lecanu", "Kunal Malkan", "Dheeraj Mekala", "Pierre M\u00e9nard", "Gr\u00e9goire Mialon", "Ulyana Piterbarg", "Mikhail Plekhanov", "Mathieu Rita", "Andrey Rusakov", "Thomas Scialom", "Vladislav Vorotilov", "Mengjue Wang", "Ian Yu"], "title": "ARE: Scaling Up Agent Environments and Evaluations", "comment": null, "summary": "We introduce Meta Agents Research Environments (ARE), a research platform for\nscalable creation of environments, integration of synthetic or real\napplications, and execution of agentic orchestrations. ARE provides simple\nabstractions to build complex and diverse environments, each with their own\nrules, tools, content, and verifiers, helping to bridge the gap between model\ndevelopment and real-world deployment. We also propose Gaia2, a benchmark built\nin ARE and designed to measure general agent capabilities. Beyond search and\nexecution, Gaia2 requires agents to handle ambiguities and noise, adapt to\ndynamic environments, collaborate with other agents, and operate under temporal\nconstraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new\nfailure modes that are invisible in static settings. Our experiments show that\nno system dominates across the intelligence spectrum: stronger reasoning often\ncomes at the cost of efficiency, and budget scaling curves plateau,\nhighlighting the need for new architectures and adaptive compute strategies.\nPerhaps more importantly, ARE abstractions enable continuous extension of Gaia2\nto other environments, empowering the community to rapidly create new\nbenchmarks tailored to their domains. In AI's second half, progress\nincreasingly depends on defining meaningful tasks and robust evaluations to\ndrive frontier capabilities forward.", "AI": {"tldr": "\u63d0\u51fa\u4e86Meta Agents Research Environments (ARE)\u5e73\u53f0\u548cGaia2\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u521b\u5efa\u590d\u6742\u73af\u5883\u3001\u96c6\u6210\u5e94\u7528\u548c\u6267\u884c\u667a\u80fd\u4f53\u7f16\u6392\uff0c\u65e8\u5728\u5f25\u5408\u6a21\u578b\u5f00\u53d1\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dAI\u53d1\u5c55\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8e\u5b9a\u4e49\u6709\u610f\u4e49\u7684\u4efb\u52a1\u548c\u7a33\u5065\u7684\u8bc4\u4f30\u6765\u63a8\u52a8\u524d\u6cbf\u80fd\u529b\u53d1\u5c55\uff0c\u9700\u8981\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u52a8\u6001\u73af\u5883\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "ARE\u63d0\u4f9b\u7b80\u5355\u62bd\u8c61\u6765\u6784\u5efa\u5177\u6709\u89c4\u5219\u3001\u5de5\u5177\u3001\u5185\u5bb9\u548c\u9a8c\u8bc1\u5668\u7684\u590d\u6742\u591a\u6837\u5316\u73af\u5883\uff1bGaia2\u57fa\u51c6\u6d4b\u8bd5\u8981\u6c42\u667a\u80fd\u4f53\u5904\u7406\u6a21\u7cca\u6027\u548c\u566a\u58f0\u3001\u9002\u5e94\u52a8\u6001\u73af\u5883\u3001\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u534f\u4f5c\u5e76\u5728\u65f6\u95f4\u7ea6\u675f\u4e0b\u8fd0\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6ca1\u6709\u7cfb\u7edf\u80fd\u5728\u6574\u4e2a\u667a\u80fd\u8c31\u7cfb\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff1a\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u5f80\u5f80\u4ee5\u6548\u7387\u4e3a\u4ee3\u4ef7\uff0c\u9884\u7b97\u6269\u5c55\u66f2\u7ebf\u8d8b\u4e8e\u5e73\u7a33\uff0c\u51f8\u663e\u4e86\u5bf9\u65b0\u67b6\u6784\u548c\u81ea\u9002\u5e94\u8ba1\u7b97\u7b56\u7565\u7684\u9700\u6c42\u3002", "conclusion": "ARE\u62bd\u8c61\u4f7fGaia2\u80fd\u591f\u6301\u7eed\u6269\u5c55\u5230\u5176\u4ed6\u73af\u5883\uff0c\u4f7f\u793e\u533a\u80fd\u591f\u5feb\u901f\u521b\u5efa\u9488\u5bf9\u5176\u9886\u57df\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u5bf9AI\u540e\u534a\u7a0b\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.17192", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17192", "abs": "https://arxiv.org/abs/2509.17192", "authors": ["Glenn Matlin", "Parv Mahajan", "Isaac Song", "Yixiong Hao", "Ryan Bard", "Stu Topp", "Evan Montoya", "M. Rehan Parwani", "Soham Shetty", "Mark Riedl"], "title": "Shall We Play a Game? Language Models for Open-ended Wargames", "comment": null, "summary": "Wargames are multi-faceted, multi-player depictions of conflict in which\nparticipants' decisions influence future events. Wargames are often used to\nexplore the strategic implications of decision-making. However, it also\nencompasses entertainment-oriented simulations, ranging from _Chess_ to\ntabletop role-playing games like _Dungeons & Dragons_ (D&D). On the more\nopen-ended side of the spectrum of wargames, players use natural language to\nconvey their moves, and adjudicators propose outcomes. Language Models (LMs)\nare increasingly being considered for how they can provide insights into\nreal-world, consequential decisions. We conduct a scoping literature review of\na curated selection of 100 recent works on AI in wargames, from which we\nconstruct an ontology of wargames in terms of the creativity afforded to either\nthe players or adjudicators. Focusing on the space of wargames with the most\nopen-endedness for players and adjudicators, we distill a set of considerations\nfor when and how to use LMs in different application areas. We also present a\nset of safety considerations, best practices for deploying LMs in open-ended\nwargames, and conclude with a set of high-impact open research challenges.", "AI": {"tldr": "\u672c\u6587\u5bf9100\u7bc7\u5173\u4e8eAI\u5728\u5175\u68cb\u63a8\u6f14\u4e2d\u5e94\u7528\u7684\u6587\u732e\u8fdb\u884c\u4e86\u8303\u56f4\u7efc\u8ff0\uff0c\u6784\u5efa\u4e86\u57fa\u4e8e\u73a9\u5bb6\u548c\u88c1\u5224\u521b\u9020\u529b\u7684\u5175\u68cb\u63a8\u6f14\u672c\u4f53\u8bba\uff0c\u91cd\u70b9\u5173\u6ce8\u6700\u5177\u5f00\u653e\u6027\u7684\u5175\u68cb\u63a8\u6f14\uff0c\u63d0\u51fa\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u5e94\u7528\u9886\u57df\u7684\u4f7f\u7528\u65f6\u673a\u548c\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b89\u5168\u8003\u8651\u548c\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "\u5175\u68cb\u63a8\u6f14\u662f\u63cf\u7ed8\u51b2\u7a81\u7684\u591a\u65b9\u9762\u3001\u591a\u53c2\u4e0e\u8005\u6a21\u62df\uff0c\u53c2\u4e0e\u8005\u7684\u51b3\u7b56\u4f1a\u5f71\u54cd\u672a\u6765\u4e8b\u4ef6\u3002\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u8003\u8651\u7528\u4e8e\u63d0\u4f9b\u5bf9\u73b0\u5b9e\u4e16\u754c\u91cd\u8981\u51b3\u7b56\u7684\u89c1\u89e3\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u5982\u4f55\u5728\u5f00\u653e\u5f0f\u7684\u5175\u68cb\u63a8\u6f14\u4e2d\u6709\u6548\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u5bf9100\u7bc7\u8fd1\u671f\u5173\u4e8eAI\u5728\u5175\u68cb\u63a8\u6f14\u4e2d\u5e94\u7528\u7684\u6587\u732e\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u6784\u5efa\u5175\u68cb\u63a8\u6f14\u7684\u672c\u4f53\u8bba\u5206\u7c7b\uff0c\u91cd\u70b9\u5173\u6ce8\u73a9\u5bb6\u548c\u88c1\u5224\u521b\u9020\u529b\u7ef4\u5ea6\uff0c\u5206\u6790\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u5175\u68cb\u63a8\u6f14\u4e2d\u7684\u5e94\u7528\u6a21\u5f0f\u3002", "result": "\u6784\u5efa\u4e86\u57fa\u4e8e\u521b\u9020\u529b\u7684\u5175\u68cb\u63a8\u6f14\u5206\u7c7b\u6846\u67b6\uff0c\u63d0\u70bc\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u5e94\u7528\u9886\u57df\u7684\u4f7f\u7528\u8003\u8651\u56e0\u7d20\uff0c\u63d0\u51fa\u4e86\u5b89\u5168\u8003\u8651\u548c\u90e8\u7f72\u6700\u4f73\u5b9e\u8df5\u3002", "conclusion": "\u7814\u7a76\u8bc6\u522b\u4e86\u9ad8\u5f71\u54cd\u529b\u7684\u5f00\u653e\u7814\u7a76\u6311\u6218\uff0c\u4e3a\u5728\u5f00\u653e\u5f0f\u5175\u68cb\u63a8\u6f14\u4e2d\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6307\u5bfc\u6846\u67b6\u3002"}}
{"id": "2509.17238", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17238", "abs": "https://arxiv.org/abs/2509.17238", "authors": ["Soheil Zibakhsh", "Mohammad Samragh", "Kumari Nishu", "Lauren Hannah", "Arnav Kundu", "Minsik Cho"], "title": "MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE", "comment": null, "summary": "The generation quality of large language models (LLMs) is often improved by\nutilizing inference-time sequence-level scaling methods (e.g.,\nChain-of-Thought). We introduce hyper-parallel scaling, a complementary\nframework that improves prediction quality at the token level. Hyper-parallel\nscaling computes and aggregates multiple output proposals for a single token\nfrom the model. We implement this concept in Mixture-of-Experts (MoE) models,\nwhich we refer to as Roster of Experts (RoE). RoE is a training-free inference\nalgorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects\ncontrolled stochasticity into the expert routing mechanism, enabling it to\nsample multiple diverse experts for each token and aggregate their outputs for\na more accurate final prediction.To overcome the computational cost, we\nintroduce an efficient batching strategy and a specialized KV-caching mechanism\nthat minimizes compute and memory overhead. For example, RoE enables a 7B MoE\nmodel to match the performance of a 10.5B MoE model while using 30% less\ncompute for inference. These gains are achieved without any fine-tuning of\nmodel parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u8d85\u5e76\u884c\u7f29\u653e\u6846\u67b6\uff0c\u901a\u8fc7token\u7ea7\u522b\u7684\u591a\u8f93\u51fa\u63d0\u6848\u805a\u5408\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\uff0c\u5728MoE\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e3a\u4e13\u5bb6\u540d\u518c\u65b9\u6cd5", "motivation": "\u73b0\u6709\u63a8\u7406\u65f6\u5e8f\u5217\u7ea7\u7f29\u653e\u65b9\u6cd5\uff08\u5982\u601d\u7ef4\u94fe\uff09\u4e3b\u8981\u63d0\u5347\u5e8f\u5217\u7ea7\u8d28\u91cf\uff0c\u4f46\u7f3a\u4e4ftoken\u7ea7\u522b\u7684\u6539\u8fdb\u673a\u5236", "method": "\u5728MoE\u6a21\u578b\u4e2d\u5f15\u5165\u53d7\u63a7\u968f\u673a\u6027\u5230\u4e13\u5bb6\u8def\u7531\u673a\u5236\uff0c\u4e3a\u6bcf\u4e2atoken\u91c7\u6837\u591a\u4e2a\u4e0d\u540c\u4e13\u5bb6\u5e76\u805a\u5408\u8f93\u51fa\uff0c\u914d\u5408\u9ad8\u6548\u6279\u5904\u7406\u548cKV\u7f13\u5b58\u673a\u5236", "result": "7B MoE\u6a21\u578b\u53ef\u8fbe\u523010.5B MoE\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u63a8\u7406\u8ba1\u7b97\u91cf\u51cf\u5c1130%\uff0c\u65e0\u9700\u5fae\u8c03\u6a21\u578b\u53c2\u6570", "conclusion": "\u8d85\u5e76\u884c\u7f29\u653e\u662f\u5e8f\u5217\u7ea7\u7f29\u653e\u65b9\u6cd5\u7684\u6709\u6548\u8865\u5145\uff0c\u4e3atoken\u7ea7\u9884\u6d4b\u8d28\u91cf\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2509.17240", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.17240", "abs": "https://arxiv.org/abs/2509.17240", "authors": ["Abdullah Mushtaq", "Muhammad Rafay Naeem", "Ibrahim Ghaznavi", "Alaa Abd-alrazaq", "Aliya Tabassum", "Junaid Qadir"], "title": "Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System", "comment": null, "summary": "Systematic Literature Reviews (SLRs) are foundational to evidence-based\nresearch but remain labor-intensive and prone to inconsistency across\ndisciplines. We present an LLM-based SLR evaluation copilot built on a\nMulti-Agent System (MAS) architecture to assist researchers in assessing the\noverall quality of the systematic literature reviews. The system automates\nprotocol validation, methodological assessment, and topic relevance checks\nusing a scholarly database. Unlike conventional single-agent methods, our\ndesign integrates a specialized agentic approach aligned with PRISMA guidelines\nto support more structured and interpretable evaluations. We conducted an\ninitial study on five published SLRs from diverse domains, comparing system\noutputs to expert-annotated PRISMA scores, and observed 84% agreement. While\nearly results are promising, this work represents a first step toward scalable\nand accurate NLP-driven systems for interdisciplinary workflows and reveals\ntheir capacity for rigorous, domain-agnostic knowledge aggregation to\nstreamline the review process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684LLM\u9a71\u52a8\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u8bc4\u4f30\u52a9\u624b\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u7684\u8d28\u91cf\uff0c\u5305\u62ec\u534f\u8bae\u9a8c\u8bc1\u3001\u65b9\u6cd5\u5b66\u8bc4\u4f30\u548c\u4e3b\u9898\u76f8\u5173\u6027\u68c0\u67e5\u3002", "motivation": "\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u662f\u5faa\u8bc1\u7814\u7a76\u7684\u57fa\u7840\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u52b3\u52a8\u5bc6\u96c6\u4e14\u5728\u4e0d\u540c\u5b66\u79d1\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u548c\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff0c\u57fa\u4e8ePRISMA\u6307\u5357\u8bbe\u8ba1\u4e13\u95e8\u5316\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5b66\u672f\u6570\u636e\u5e93\u8fdb\u884c\u534f\u8bae\u9a8c\u8bc1\u3001\u65b9\u6cd5\u5b66\u8bc4\u4f30\u548c\u4e3b\u9898\u76f8\u5173\u6027\u68c0\u67e5\u3002", "result": "\u5728\u4e94\u4e2a\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u5df2\u53d1\u8868\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u4e0a\u8fdb\u884c\u521d\u6b65\u7814\u7a76\uff0c\u7cfb\u7edf\u8f93\u51fa\u4e0e\u4e13\u5bb6\u6807\u6ce8\u7684PRISMA\u8bc4\u5206\u8fbe\u523084%\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u867d\u7136\u65e9\u671f\u7ed3\u679c\u6709\u524d\u666f\uff0c\u4f46\u8fd9\u662f\u8fc8\u5411\u53ef\u6269\u5c55\u548c\u51c6\u786e\u7684NLP\u9a71\u52a8\u7cfb\u7edf\u7684\u7b2c\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u5176\u5728\u8de8\u5b66\u79d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u8fdb\u884c\u4e25\u683c\u3001\u9886\u57df\u65e0\u5173\u77e5\u8bc6\u805a\u5408\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.17259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17259", "abs": "https://arxiv.org/abs/2509.17259", "authors": ["Ilham Wicaksono", "Zekun Wu", "Rahul Patel", "Theo King", "Adriano Koshiyama", "Philip Treleaven"], "title": "Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B", "comment": "Winner of the OpenAI GPT-OSS-20B Red Teaming Challenge (Kaggle, 2025)", "summary": "As the industry increasingly adopts agentic AI systems, understanding their\nunique vulnerabilities becomes critical. Prior research suggests that security\nflaws at the model level do not fully capture the risks present in agentic\ndeployments, where models interact with tools and external environments. This\npaper investigates this gap by conducting a comparative red teaming analysis of\nGPT-OSS-20B, a 20-billion parameter open-source model. Using our observability\nframework AgentSeer to deconstruct agentic systems into granular actions and\ncomponents, we apply iterative red teaming attacks with harmful objectives from\nHarmBench at two distinct levels: the standalone model and the model operating\nwithin an agentic loop. Our evaluation reveals fundamental differences between\nmodel level and agentic level vulnerability profiles. Critically, we discover\nthe existence of agentic-only vulnerabilities, attack vectors that emerge\nexclusively within agentic execution contexts while remaining inert against\nstandalone models. Agentic level iterative attacks successfully compromise\nobjectives that completely failed at the model level, with tool-calling\ncontexts showing 24\\% higher vulnerability than non-tool contexts. Conversely,\ncertain model-specific exploits work exclusively at the model level and fail\nwhen transferred to agentic contexts, demonstrating that standalone model\nvulnerabilities do not always generalize to deployed systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6bd4\u8f83\u6027\u7ea2\u961f\u5206\u6790\u53d1\u73b0\uff0cAI\u4ee3\u7406\u7cfb\u7edf\u5b58\u5728\u6a21\u578b\u5c42\u9762\u4e0d\u5b58\u5728\u7684\u72ec\u7279\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u7ea7\u4e0e\u4ee3\u7406\u7ea7\u6f0f\u6d1e\u7279\u5f81\u7684\u6839\u672c\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u884c\u4e1a\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528AI\u4ee3\u7406\u7cfb\u7edf\uff0c\u7406\u89e3\u5176\u72ec\u7279\u6f0f\u6d1e\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u6a21\u578b\u5c42\u9762\u7684\u5b89\u5168\u6f0f\u6d1e\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u4ee3\u7406\u90e8\u7f72\u4e2d\u7684\u98ce\u9669\u3002", "method": "\u4f7f\u7528AgentSeer\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\u5c06\u4ee3\u7406\u7cfb\u7edf\u89e3\u6784\u4e3a\u7ec6\u7c92\u5ea6\u52a8\u4f5c\u548c\u7ec4\u4ef6\uff0c\u5728GPT-OSS-20B\u6a21\u578b\u4e0a\u5e94\u7528HarmBench\u7684\u6709\u5bb3\u76ee\u6807\u8fdb\u884c\u8fed\u4ee3\u7ea2\u961f\u653b\u51fb\uff0c\u6bd4\u8f83\u72ec\u7acb\u6a21\u578b\u4e0e\u4ee3\u7406\u5faa\u73af\u4e2d\u6a21\u578b\u7684\u8106\u5f31\u6027\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u4ec5\u4ee3\u7406\u7ea7\u6f0f\u6d1e\uff0c\u8fd9\u4e9b\u653b\u51fb\u5411\u91cf\u4ec5\u5728\u4ee3\u7406\u6267\u884c\u73af\u5883\u4e2d\u51fa\u73b0\u3002\u4ee3\u7406\u7ea7\u8fed\u4ee3\u653b\u51fb\u6210\u529f\u653b\u7834\u4e86\u6a21\u578b\u7ea7\u5b8c\u5168\u5931\u8d25\u7684\u76ee\u6807\uff0c\u5de5\u5177\u8c03\u7528\u4e0a\u4e0b\u6587\u6bd4\u975e\u5de5\u5177\u4e0a\u4e0b\u6587\u8106\u5f31\u6027\u9ad824%\u3002\u540c\u65f6\uff0c\u67d0\u4e9b\u6a21\u578b\u7279\u5b9a\u653b\u51fb\u5728\u4ee3\u7406\u73af\u5883\u4e2d\u5931\u6548\u3002", "conclusion": "\u72ec\u7acb\u6a21\u578b\u6f0f\u6d1e\u5e76\u4e0d\u603b\u662f\u80fd\u63a8\u5e7f\u5230\u90e8\u7f72\u7cfb\u7edf\u4e2d\uff0c\u4ee3\u7406\u7cfb\u7edf\u5177\u6709\u72ec\u7279\u7684\u8106\u5f31\u6027\u7279\u5f81\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2509.17318", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17318", "abs": "https://arxiv.org/abs/2509.17318", "authors": ["Zhuofan Chen", "Jiyuan He", "Yichi Zhang", "Xing Hu", "Haoxing Wen", "Jun Bai", "Wenge Rong"], "title": "CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models", "comment": null, "summary": "Mathematical reasoning poses significant challenges for Large Language Models\n(LLMs) due to its demand for multi-step reasoning and abstract conceptual\nintegration. While recent test-time scaling techniques rely heavily on\nhigh-quality, challenging problems, the scarcity of Olympiad-level math\nproblems remains a bottleneck. We introduce CogAtom, a novel cognitive\natom-based framework for synthesizing mathematically rigorous and cognitively\ndiverse problems. Unlike prior approaches, CogAtom models problem construction\nas a process of selecting and recombining fundamental reasoning units,\ncognitive atoms, extracted from human-authored solutions. A diversity-promoting\nrandom walk algorithm enables exploration of the cognitive atom space, while a\nconstraint-based recombination mechanism ensures logical soundness and\nstructural validity. The combinatorial nature of the graph structure provides a\nnear-infinite space of reasoning paths, and the walk algorithm systematically\nexplores this space to achieve large-scale synthesis of high-quality problems;\nmeanwhile, by controlling the number of cognitive atoms, we can precisely\nadjust problem difficulty, ensuring diversity, scalability, and controllability\nof the generated problems. Experimental results demonstrate that CogAtom\noutperforms existing methods in accuracy, reasoning depth, and diversity,\ngenerating problems that closely match the difficulty of AIME while exceeding\nit in structural variation. Our work offers a cognitively grounded pathway\ntoward scalable, high-quality math problem generation.Our code is publicly\navailable at https://github.com/Icarus-1111/CogAtom.", "AI": {"tldr": "CogAtom\u662f\u4e00\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u539f\u5b50\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5408\u6210\u6570\u5b66\u4e25\u8c28\u4e14\u8ba4\u77e5\u591a\u6837\u5316\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u9009\u62e9\u548c\u91cd\u7ec4\u4ece\u4eba\u7c7b\u89e3\u9898\u4e2d\u63d0\u53d6\u7684\u57fa\u672c\u63a8\u7406\u5355\u5143\u6765\u89e3\u51b3\u5965\u6570\u7ea7\u6570\u5b66\u95ee\u9898\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u6570\u5b66\u63a8\u7406\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u591a\u6b65\u63a8\u7406\u548c\u62bd\u8c61\u6982\u5ff5\u6574\u5408\u3002\u5965\u6570\u7ea7\u6570\u5b66\u95ee\u9898\u7684\u7a00\u7f3a\u6210\u4e3a\u74f6\u9888\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5927\u89c4\u6a21\u5408\u6210\u9ad8\u8d28\u91cf\u6570\u5b66\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "method": "CogAtom\u5c06\u95ee\u9898\u6784\u5efa\u5efa\u6a21\u4e3a\u9009\u62e9\u548c\u91cd\u7ec4\u8ba4\u77e5\u539f\u5b50\u7684\u8fc7\u7a0b\uff0c\u4f7f\u7528\u591a\u6837\u6027\u4fc3\u8fdb\u7684\u968f\u673a\u6e38\u8d70\u7b97\u6cd5\u63a2\u7d22\u8ba4\u77e5\u539f\u5b50\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u7ea6\u675f\u7684\u91cd\u7ec4\u673a\u5236\u786e\u4fdd\u903b\u8f91\u5408\u7406\u6027\u548c\u7ed3\u6784\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCogAtom\u5728\u51c6\u786e\u6027\u3001\u63a8\u7406\u6df1\u5ea6\u548c\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u95ee\u9898\u5728\u96be\u5ea6\u4e0a\u4e0eAIME\u5339\u914d\uff0c\u4f46\u5728\u7ed3\u6784\u53d8\u5316\u4e0a\u8d85\u8fc7AIME\u3002", "conclusion": "CogAtom\u4e3a\u53ef\u6269\u5c55\u3001\u9ad8\u8d28\u91cf\u7684\u6570\u5b66\u95ee\u9898\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u6761\u8ba4\u77e5\u57fa\u7840\u8def\u5f84\uff0c\u901a\u8fc7\u63a7\u5236\u8ba4\u77e5\u539f\u5b50\u6570\u91cf\u53ef\u4ee5\u7cbe\u786e\u8c03\u6574\u95ee\u9898\u96be\u5ea6\uff0c\u786e\u4fdd\u591a\u6837\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u63a7\u6027\u3002"}}
{"id": "2509.17337", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.17337", "abs": "https://arxiv.org/abs/2509.17337", "authors": ["Ala Jararweh", "Michael Adams", "Avinash Sahu", "Abdullah Mueen", "Afsah Anwar"], "title": "LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code", "comment": null, "summary": "Increasing complexity in software systems places a growing demand on\nreasoning tools that unlock vulnerabilities manifest in source code. Many\ncurrent approaches focus on vulnerability analysis as a classifying task,\noversimplifying the nuanced and context-dependent real-world scenarios. Even\nthough current code large language models (LLMs) excel in code understanding,\nthey often pay little attention to security-specific reasoning. We propose\nLLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code\nthrough question-answering (QA). Our model is trained to integrate paired code\nand natural queries into a unified space, enhancing reasoning and\ncontext-dependent insights about code vulnerability. To evaluate our model\nperformance, we construct a curated dataset of real-world vulnerabilities\npaired with security-focused questions and answers. Our model outperforms\nstate-of-the-art general-purpose and code LLMs in the QA and detection tasks.\nWe further explain decision-making by conducting qualitative analysis to\nhighlight capabilities and limitations. By integrating code and QA, LLaVul\nenables more interpretable and security-focused code understanding.", "AI": {"tldr": "LLaVul\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u901a\u8fc7\u95ee\u7b54\u65b9\u5f0f\u5bf9\u4ee3\u7801\u8fdb\u884c\u7ec6\u7c92\u5ea6\u63a8\u7406\uff0c\u63d0\u9ad8\u4ee3\u7801\u6f0f\u6d1e\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u5bf9\u6e90\u4ee3\u7801\u6f0f\u6d1e\u5206\u6790\u5de5\u5177\u7684\u9700\u6c42\u589e\u957f\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u6f0f\u6d1e\u5206\u6790\u7b80\u5316\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u7ec6\u5fae\u5dee\u522b\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u3002\u867d\u7136\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f88\u5c11\u5173\u6ce8\u5b89\u5168\u7279\u5b9a\u7684\u63a8\u7406\u3002", "method": "\u63d0\u51faLLaVul\u591a\u6a21\u6001LLM\uff0c\u8bad\u7ec3\u6a21\u578b\u5c06\u914d\u5bf9\u7684\u4ee3\u7801\u548c\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u6574\u5408\u5230\u7edf\u4e00\u7a7a\u95f4\u4e2d\uff0c\u589e\u5f3a\u5bf9\u4ee3\u7801\u6f0f\u6d1e\u7684\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6d1e\u5bdf\u3002\u6784\u5efa\u4e86\u5305\u542b\u771f\u5b9e\u4e16\u754c\u6f0f\u6d1e\u7684\u5b89\u5168\u7126\u70b9\u95ee\u7b54\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "LLaVul\u5728\u95ee\u7b54\u548c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u901a\u7528\u548c\u4ee3\u7801LLMs\u3002\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u89e3\u91ca\u4e86\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7a81\u51fa\u4e86\u6a21\u578b\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u4ee3\u7801\u548c\u95ee\u7b54\uff0cLLaVul\u5b9e\u73b0\u4e86\u66f4\u53ef\u89e3\u91ca\u548c\u4ee5\u5b89\u5168\u4e3a\u4e2d\u5fc3\u7684\u4ee3\u7801\u7406\u89e3\u3002"}}
{"id": "2509.17353", "categories": ["cs.AI", "eess.IV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2509.17353", "abs": "https://arxiv.org/abs/2509.17353", "authors": ["Ahmed T. Elboardy", "Ghada Khoriba", "Essam A. Rashed"], "title": "Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation", "comment": "NeurIPS2025 Workshop: Evaluating the Evolving LLM Lifecycle:\n  Benchmarks, Emergent Abilities, and Scaling", "summary": "Automating radiology report generation poses a dual challenge: building\nclinically reliable systems and designing rigorous evaluation protocols. We\nintroduce a multi-agent reinforcement learning framework that serves as both a\nbenchmark and evaluation environment for multimodal clinical reasoning in the\nradiology ecosystem. The proposed framework integrates large language models\n(LLMs) and large vision models (LVMs) within a modular architecture composed of\nten specialized agents responsible for image analysis, feature extraction,\nreport generation, review, and evaluation. This design enables fine-grained\nassessment at both the agent level (e.g., detection and segmentation accuracy)\nand the consensus level (e.g., report quality and clinical relevance). We\ndemonstrate an implementation using chatGPT-4o on public radiology datasets,\nwhere LLMs act as evaluators alongside medical radiologist feedback. By\naligning evaluation protocols with the LLM development lifecycle, including\npretraining, finetuning, alignment, and deployment, the proposed benchmark\nestablishes a path toward trustworthy deviance-based radiology report\ngeneration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f5c\u4e3a\u653e\u5c04\u5b66\u751f\u6001\u7cfb\u7edf\u4e2d\u591a\u6a21\u6001\u4e34\u5e8a\u63a8\u7406\u7684\u57fa\u51c6\u548c\u8bc4\u4f30\u73af\u5883\uff0c\u6574\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5927\u578b\u89c6\u89c9\u6a21\u578b\u3002", "motivation": "\u81ea\u52a8\u5316\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u9762\u4e34\u4e34\u5e8a\u53ef\u9760\u6027\u7cfb\u7edf\u548c\u4e25\u683c\u8bc4\u4f30\u534f\u8bae\u8bbe\u8ba1\u7684\u53cc\u91cd\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u4fe1\u8d56\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5305\u542b\u5341\u4e2a\u4e13\u95e8\u8d1f\u8d23\u56fe\u50cf\u5206\u6790\u3001\u7279\u5f81\u63d0\u53d6\u3001\u62a5\u544a\u751f\u6210\u3001\u5ba1\u67e5\u548c\u8bc4\u4f30\u7684\u667a\u80fd\u4f53\uff0c\u4f7f\u7528chatGPT-4o\u5728\u516c\u5171\u653e\u5c04\u5b66\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u3002", "result": "\u6846\u67b6\u80fd\u591f\u5728\u667a\u80fd\u4f53\u5c42\u9762\uff08\u5982\u68c0\u6d4b\u548c\u5206\u5272\u51c6\u786e\u6027\uff09\u548c\u5171\u8bc6\u5c42\u9762\uff08\u5982\u62a5\u544a\u8d28\u91cf\u548c\u4e34\u5e8a\u76f8\u5173\u6027\uff09\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8bc4\u4f30\u534f\u8bae\u4e0eLLM\u5f00\u53d1\u751f\u547d\u5468\u671f\u5bf9\u9f50\uff0c\u8be5\u57fa\u51c6\u4e3a\u53ef\u4fe1\u8d56\u7684\u57fa\u4e8e\u504f\u5dee\u7684\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u5efa\u7acb\u4e86\u8def\u5f84\u3002"}}
{"id": "2509.17354", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17354", "abs": "https://arxiv.org/abs/2509.17354", "authors": ["Jiazhao Shi", "Yichen Lin", "Yiheng Hua", "Ziyu Wang", "Zijian Zhang", "Wenjia Zheng", "Yun Song", "Kuan Lu", "Shoufeng Lu"], "title": "Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification", "comment": null, "summary": "Lane-change maneuvers are a leading cause of highway accidents, underscoring\nthe need for accurate intention prediction to improve the safety and\ndecision-making of autonomous driving systems. While prior studies using\nmachine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers)\nhave shown promise, most approaches remain limited by binary classification,\nlack of scenario diversity, and degraded performance under longer prediction\nhorizons. In this study, we propose a physics-informed AI framework that\nexplicitly integrates vehicle kinematics, interaction feasibility, and\ntraffic-safety metrics (e.g., distance headway, time headway,\ntime-to-collision, closing gap time) into the learning process. lane-change\nprediction is formulated as a three-class problem that distinguishes left\nchange, right change, and no change, and is evaluated across both straight\nhighway segments (highD) and complex ramp scenarios (exiD). By integrating\nvehicle kinematics with interaction features, our machine learning models,\nparticularly LightGBM, achieve state-of-the-art accuracy and strong\ngeneralization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD,\nand 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon,\noutperforming a two-layer stacked LSTM baseline. These findings demonstrate the\npractical advantages of a physics-informed and feature-rich machine learning\nframework for real-time lane-change intention prediction in autonomous driving\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684AI\u6846\u67b6\uff0c\u7528\u4e8e\u8f66\u9053\u53d8\u6362\u610f\u56fe\u9884\u6d4b\uff0c\u901a\u8fc7\u6574\u5408\u8f66\u8f86\u8fd0\u52a8\u5b66\u3001\u4ea4\u4e92\u53ef\u884c\u6027\u548c\u4ea4\u901a\u5b89\u5168\u6307\u6807\uff0c\u5728\u9ad8\u901f\u516c\u8def\u548c\u590d\u6742\u531d\u9053\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "motivation": "\u8f66\u9053\u53d8\u6362\u662f\u9ad8\u901f\u516c\u8def\u4e8b\u6545\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e8c\u5143\u5206\u7c7b\u9650\u5236\u3001\u573a\u666f\u591a\u6837\u6027\u4e0d\u8db3\u4ee5\u53ca\u5728\u8f83\u957f\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u5185\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7269\u7406\u4fe1\u606fAI\u6846\u67b6\uff0c\u6574\u5408\u8f66\u8f86\u8fd0\u52a8\u5b66\u3001\u4ea4\u4e92\u53ef\u884c\u6027\u548c\u4ea4\u901a\u5b89\u6307\u6807\uff0c\u5c06\u8f66\u9053\u53d8\u6362\u9884\u6d4b\u5efa\u6a21\u4e3a\u4e09\u7c7b\u95ee\u9898\uff08\u5de6\u53d8\u9053\u3001\u53f3\u53d8\u9053\u3001\u4e0d\u53d8\u9053\uff09\uff0c\u4f7f\u7528LightGBM\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u5728highD\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.8%\u51c6\u786e\u7387\u548c93.6%\u5b8fF1\u5206\u6570\uff0c\u5728exiD\u6570\u636e\u96c6\u4e0a\u8fbe\u523096.1%\u51c6\u786e\u7387\u548c88.7%\u5b8fF1\u5206\u6570\uff0c\u4f18\u4e8e\u4e24\u5c42\u5806\u53e0LSTM\u57fa\u7ebf\u3002", "conclusion": "\u7269\u7406\u4fe1\u606f\u548c\u7279\u5f81\u4e30\u5bcc\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b9e\u65f6\u8f66\u9053\u53d8\u6362\u610f\u56fe\u9884\u6d4b\u4e2d\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2509.17380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17380", "abs": "https://arxiv.org/abs/2509.17380", "authors": ["Zhizhang FU", "Guangsheng Bao", "Hongbo Zhang", "Chenkai Hu", "Yue Zhang"], "title": "Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process", "comment": null, "summary": "LLMs suffer from critical reasoning issues such as unfaithfulness, bias, and\ninconsistency, since they lack robust causal underpinnings and may rely on\nsuperficial correlations rather than genuine understanding. Successive LRMs\nhave emerged as a promising alternative, leveraging advanced training\ntechniques such as reinforcement learning (RL) and distillation to improve task\naccuracy. However, the impact of these training methods on causality remains\nlargely unexplored. In this study, we conduct a systematic causal analysis on\nLLMs and LRMs, examining structural causal models (SCMs) of four key variables:\nproblem instruction (Z), thinking process (T), reasoning steps (X), and answer\n(Y). Our findings reveal that RLVR-trained LRMs exhibit enhanced causal\nreasoning capabilities, aligning more closely with ideal causal structures,\nwhile LLMs and distilled LRMs fail to address causality-related deficiencies.\nOur further investigation indicates that RLVR reduces spurious correlations and\nstrengthens genuine causal patterns, thereby mitigating unfaithfulness and\nbias. In addition, our inspection on the dynamics of the RLVR training process\nobserves a high correlation between reduced spurious features and improved\ncausal structures, where the causal relationships consistently improve in the\ntraining process. This study contributes to the understanding of causality in\nreasoning models, highlights the critical role of RLVR in enhancing causal\nreasoning, and provides insights for designing future AI systems with stronger\ncausal foundations. We release our code and data at\nhttps://github.com/Harryking1999/CoT_Causal_Analysis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9LLMs\u548cLRMs\u8fdb\u884c\u7cfb\u7edf\u6027\u56e0\u679c\u5206\u6790\uff0c\u53d1\u73b0RLVR\u8bad\u7ec3\u7684LRMs\u5177\u6709\u66f4\u5f3a\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u800cLLMs\u548c\u84b8\u998fLRMs\u5b58\u5728\u56e0\u679c\u7f3a\u9677\u3002RLVR\u901a\u8fc7\u51cf\u5c11\u865a\u5047\u76f8\u5173\u6027\u3001\u589e\u5f3a\u771f\u5b9e\u56e0\u679c\u6a21\u5f0f\u6765\u7f13\u89e3\u4e0d\u5fe0\u5b9e\u6027\u548c\u504f\u89c1\u95ee\u9898\u3002", "motivation": "LLMs\u5b58\u5728\u4e0d\u5fe0\u5b9e\u6027\u3001\u504f\u89c1\u548c\u4e0d\u4e00\u81f4\u6027\u7b49\u5173\u952e\u63a8\u7406\u95ee\u9898\uff0c\u56e0\u4e3a\u5b83\u4eec\u7f3a\u4e4f\u7a33\u5065\u7684\u56e0\u679c\u57fa\u7840\uff0c\u53ef\u80fd\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u7406\u89e3\u3002\u867d\u7136LRMs\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\u63d0\u9ad8\u4e86\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u4f46\u8fd9\u4e9b\u8bad\u7ec3\u65b9\u6cd5\u5bf9\u56e0\u679c\u5173\u7cfb\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b(SCMs)\u5206\u6790\u56db\u4e2a\u5173\u952e\u53d8\u91cf\uff1a\u95ee\u9898\u6307\u4ee4(Z)\u3001\u601d\u7ef4\u8fc7\u7a0b(T)\u3001\u63a8\u7406\u6b65\u9aa4(X)\u548c\u7b54\u6848(Y)\u3002\u5bf9LLMs\u548cLRMs\u8fdb\u884c\u7cfb\u7edf\u6027\u56e0\u679c\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8RLVR\u8bad\u7ec3\u8fc7\u7a0b\u52a8\u6001\u3002", "result": "RLVR\u8bad\u7ec3\u7684LRMs\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u66f4\u63a5\u8fd1\u7406\u60f3\u56e0\u679c\u7ed3\u6784\u3002RLVR\u51cf\u5c11\u4e86\u865a\u5047\u76f8\u5173\u6027\uff0c\u52a0\u5f3a\u4e86\u771f\u5b9e\u56e0\u679c\u6a21\u5f0f\uff0c\u4ece\u800c\u7f13\u89e3\u4e86\u4e0d\u5fe0\u5b9e\u6027\u548c\u504f\u89c1\u95ee\u9898\u3002\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u89c2\u5bdf\u5230\u51cf\u5c11\u865a\u5047\u7279\u5f81\u4e0e\u6539\u8fdb\u56e0\u679c\u7ed3\u6784\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u589e\u8fdb\u4e86\u5bf9\u63a8\u7406\u6a21\u578b\u4e2d\u56e0\u679c\u5173\u7cfb\u7684\u7406\u89e3\uff0c\u5f3a\u8c03\u4e86RLVR\u5728\u589e\u5f3a\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u8bbe\u8ba1\u5177\u6709\u66f4\u5f3a\u56e0\u679c\u57fa\u7840\u7684\u672a\u6765AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.17393", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.17393", "abs": "https://arxiv.org/abs/2509.17393", "authors": ["Kang-il Lee", "Jahyun Koo", "Seunghyun Yoon", "Minbeom Kim", "Hyukhun Koh", "Dongryeol Lee", "Kyomin Jung"], "title": "Program Synthesis via Test-Time Transduction", "comment": "NeurIPS 2025", "summary": "We introduce transductive program synthesis, a new formulation of the program\nsynthesis task that explicitly leverages test inputs during synthesis. While\nprior approaches to program synthesis--whether based on natural language\ndescriptions or input-output examples--typically aim to generalize from\ntraining examples, they often struggle with robustness, especially in\nreal-world settings where training examples are limited and test inputs involve\nvarious edge cases. To address this, we propose a novel framework that improves\nrobustness by treating synthesis as an active learning over a finite hypothesis\nclass defined by programs' outputs. We use an LLM to predict outputs for\nselected test inputs and eliminate inconsistent hypotheses, where the inputs\nare chosen via a greedy maximin algorithm to minimize the number of LLM queries\nrequired. We evaluate our approach on two real-world datasets: Playgol, a\nstring transformation benchmark, and MBPP+, a Python code generation benchmark.\nWe demonstrate that our method significantly improves program synthesis in both\naccuracy and efficiency. We release our code at\nhttps://github.com/klee972/SYNTRA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u2014\u2014\u8f6c\u5bfc\u7a0b\u5e8f\u5408\u6210\uff0c\u901a\u8fc7\u5728\u5408\u6210\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u5229\u7528\u6d4b\u8bd5\u8f93\u5165\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u8bad\u7ec3\u6837\u672c\u6709\u9650\u548c\u8fb9\u7f18\u60c5\u51b5\u4e0b\u7684\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\uff08\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6216\u8f93\u5165\u8f93\u51fa\u793a\u4f8b\uff09\u901a\u5e38\u96be\u4ee5\u5728\u8bad\u7ec3\u6837\u672c\u6709\u9650\u4e14\u6d4b\u8bd5\u8f93\u5165\u5305\u542b\u5404\u79cd\u8fb9\u7f18\u60c5\u51b5\u7684\u771f\u5b9e\u573a\u666f\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "method": "\u5c06\u7a0b\u5e8f\u5408\u6210\u89c6\u4e3a\u5728\u7531\u7a0b\u5e8f\u8f93\u51fa\u5b9a\u4e49\u7684\u6709\u9650\u5047\u8bbe\u7c7b\u4e0a\u8fdb\u884c\u4e3b\u52a8\u5b66\u4e60\uff0c\u4f7f\u7528LLM\u9884\u6d4b\u9009\u5b9a\u6d4b\u8bd5\u8f93\u5165\u7684\u8f93\u51fa\u5e76\u901a\u8fc7\u8d2a\u5a6a\u6700\u5927\u5316\u7b97\u6cd5\u9009\u62e9\u8f93\u5165\u4ee5\u6700\u5c0f\u5316LLM\u67e5\u8be2\u6b21\u6570\u3002", "result": "\u5728Playgol\u5b57\u7b26\u4e32\u8f6c\u6362\u57fa\u51c6\u548cMBPP+ Python\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u7a0b\u5e8f\u5408\u6210\u6027\u80fd\u3002", "conclusion": "\u8f6c\u5bfc\u7a0b\u5e8f\u5408\u6210\u6846\u67b6\u901a\u8fc7\u4e3b\u52a8\u5229\u7528\u6d4b\u8bd5\u8f93\u5165\u6709\u6548\u63d0\u9ad8\u4e86\u7a0b\u5e8f\u5408\u6210\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.17425", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17425", "abs": "https://arxiv.org/abs/2509.17425", "authors": ["Zhenliang Zhang", "Yuxi Wang", "Hongzhao Xie", "Shiyun Zhao", "Mingyuan Liu", "Yujie Lu", "Xinyi He", "Zhenku Cheng", "Yujia Peng"], "title": "Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments", "comment": null, "summary": "A key feature differentiating artificial general intelligence (AGI) from\ntraditional AI is that AGI can perform composite tasks that require a wide\nrange of capabilities. Although embodied agents powered by multimodal large\nlanguage models (MLLMs) offer rich perceptual and interactive capabilities, it\nremains largely unexplored whether they can solve composite tasks. In the\ncurrent work, we designed a set of composite tasks inspired by common daily\nactivities observed in early childhood development. Within a dynamic and\nsimulated home environment, these tasks span three core domains: object\nunderstanding, spatial intelligence, and social activity. We evaluated 17\nleading proprietary and open-source MLLMs on these tasks. The results\nconsistently showed poor performance across all three domains, indicating a\nsubstantial gap between current capabilities and general intelligence\nrequirements. Together, our tasks offer a preliminary framework for evaluating\nthe general capabilities of embodied agents, marking an early but significant\nstep toward the development of embodied MLLMs and their real-world deployment.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u5408\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u7269\u4f53\u7406\u89e3\u3001\u7a7a\u95f4\u667a\u80fd\u548c\u793e\u4ea4\u6d3b\u52a8\u4e09\u4e2a\u6838\u5fc3\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u4e0e\u901a\u7528\u667a\u80fd\u8981\u6c42\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u4eba\u5de5\u901a\u7528\u667a\u80fd\u4e0e\u4f20\u7edfAI\u7684\u5173\u952e\u533a\u522b\u5728\u4e8e\u80fd\u591f\u6267\u884c\u9700\u8981\u5e7f\u6cdb\u80fd\u529b\u7684\u590d\u5408\u4efb\u52a1\u3002\u5c3d\u7ba1\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u5177\u6709\u4e30\u5bcc\u7684\u611f\u77e5\u548c\u4ea4\u4e92\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u89e3\u51b3\u590d\u5408\u4efb\u52a1\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5e7c\u513f\u65e5\u5e38\u6d3b\u52a8\u7684\u590d\u5408\u4efb\u52a1\u96c6\uff0c\u5728\u52a8\u6001\u6a21\u62df\u5bb6\u5ead\u73af\u5883\u4e2d\u8bc4\u4f30\u4e8617\u4e2a\u9886\u5148\u7684\u4e13\u6709\u548c\u5f00\u6e90\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4efb\u52a1\u6db5\u76d6\u7269\u4f53\u7406\u89e3\u3001\u7a7a\u95f4\u667a\u80fd\u548c\u793e\u4ea4\u6d3b\u52a8\u4e09\u4e2a\u6838\u5fc3\u9886\u57df\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u4e09\u4e2a\u9886\u57df\u90fd\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u5f53\u524d\u80fd\u529b\u4e0e\u901a\u7528\u667a\u80fd\u8981\u6c42\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u8fd9\u4e9b\u4efb\u52a1\u4e3a\u8bc4\u4f30\u5177\u8eab\u667a\u80fd\u4f53\u7684\u901a\u7528\u80fd\u529b\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\uff0c\u6807\u5fd7\u7740\u5411\u5f00\u53d1\u5177\u8eab\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u5176\u5b9e\u9645\u90e8\u7f72\u8fc8\u51fa\u4e86\u65e9\u671f\u4f46\u91cd\u8981\u7684\u4e00\u6b65\u3002"}}
{"id": "2509.17439", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17439", "abs": "https://arxiv.org/abs/2509.17439", "authors": ["Yangxuan Zhou", "Sha Zhao", "Jiquan Wang", "Haiteng Jiang", "Shijian Li", "Tao Li", "Gang Pan"], "title": "SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding", "comment": "21 pages, 13 figures", "summary": "Human brain achieves dynamic stability-plasticity balance through synaptic\nhomeostasis. Inspired by this biological principle, we propose SPICED: a\nneuromorphic framework that integrates the synaptic homeostasis mechanism for\nunsupervised continual EEG decoding, particularly addressing practical\nscenarios where new individuals with inter-individual variability emerge\ncontinually. SPICED comprises a novel synaptic network that enables dynamic\nexpansion during continual adaptation through three bio-inspired neural\nmechanisms: (1) critical memory reactivation; (2) synaptic consolidation and\n(3) synaptic renormalization. The interplay within synaptic homeostasis\ndynamically strengthens task-discriminative memory traces and weakens\ndetrimental memories. By integrating these mechanisms with continual learning\nsystem, SPICED preferentially replays task-discriminative memory traces that\nexhibit strong associations with newly emerging individuals, thereby achieving\nrobust adaptations. Meanwhile, SPICED effectively mitigates catastrophic\nforgetting by suppressing the replay prioritization of detrimental memories\nduring long-term continual learning. Validated on three EEG datasets, SPICED\nshow its effectiveness.", "AI": {"tldr": "SPICED\u662f\u4e00\u4e2a\u53d7\u5927\u8111\u7a81\u89e6\u7a33\u6001\u542f\u53d1\u7684\u795e\u7ecf\u5f62\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u76d1\u7763\u8fde\u7eedEEG\u89e3\u7801\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u65b0\u4e2a\u4f53\u7684\u53d8\u5f02\u6027\uff0c\u540c\u65f6\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "motivation": "\u53d7\u4eba\u7c7b\u5927\u8111\u901a\u8fc7\u7a81\u89e6\u7a33\u6001\u5b9e\u73b0\u52a8\u6001\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u5e73\u8861\u7684\u751f\u7269\u539f\u7406\u542f\u53d1\uff0c\u89e3\u51b3\u5728\u8fde\u7eed\u51fa\u73b0\u5177\u6709\u4e2a\u4f53\u95f4\u53d8\u5f02\u6027\u7684\u65b0\u4e2a\u4f53\u65f6\uff0cEEG\u89e3\u7801\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\u3002", "method": "SPICED\u5305\u542b\u4e00\u4e2a\u65b0\u578b\u7a81\u89e6\u7f51\u7edc\uff0c\u901a\u8fc7\u4e09\u4e2a\u751f\u7269\u542f\u53d1\u7684\u795e\u7ecf\u673a\u5236\u5b9e\u73b0\u52a8\u6001\u6269\u5c55\uff1a(1)\u5173\u952e\u8bb0\u5fc6\u91cd\u65b0\u6fc0\u6d3b\uff1b(2)\u7a81\u89e6\u5de9\u56fa\uff1b(3)\u7a81\u89e6\u91cd\u5f52\u4e00\u5316\u3002\u8fd9\u4e9b\u673a\u5236\u4e0e\u6301\u7eed\u5b66\u4e60\u7cfb\u7edf\u96c6\u6210\uff0c\u4f18\u5148\u91cd\u653e\u4e0e\u65b0\u4e2a\u4f53\u5f3a\u76f8\u5173\u7684\u4efb\u52a1\u5224\u522b\u6027\u8bb0\u5fc6\u75d5\u8ff9\u3002", "result": "\u5728\u4e09\u4e2aEEG\u6570\u636e\u96c6\u4e0a\u7684\u9a8c\u8bc1\u8868\u660eSPICED\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "SPICED\u901a\u8fc7\u7a81\u89e6\u7a33\u6001\u673a\u5236\u6210\u529f\u5b9e\u73b0\u4e86\u52a8\u6001\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u5e73\u8861\uff0c\u5728\u8fde\u7eedEEG\u89e3\u7801\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u7684\u9002\u5e94\u80fd\u529b\u548c\u5bf9\u707e\u96be\u6027\u9057\u5fd8\u7684\u6709\u6548\u7f13\u89e3\u3002"}}
{"id": "2509.17460", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17460", "abs": "https://arxiv.org/abs/2509.17460", "authors": ["Jianlong Chang", "Haixin Wang", "Zhiyuan Dang", "Li Huang", "Zhiyu Wang", "Ruoqi Cao", "Shihao Piao", "Dongzhe Li", "Dianyu Gao", "Dongsheng Wang", "Yin Li", "Jinan Sun", "Lu Fang", "Zhouchen Lin"], "title": "AI Pangaea: Unifying Intelligence Islands for Adapting Myriad Tasks", "comment": "65 pages, 28 figures, paper under review", "summary": "The pursuit of artificial general intelligence continuously demands\ngeneralization in one model across myriad tasks, even those not seen before.\nHowever, current AI models are isolated from each other for being limited to\nspecific tasks, now first defined as Intelligence Islands. To unify\nIntelligence Islands into one, we propose Pangaea, the first AI supercontinent\nakin to the geological Pangaea. Pangaea encodes any data into a unified format\nand accumulates universal knowledge through pre-training on 296 datasets across\ndiverse modalities. Eventually, it demonstrates remarkable generalization\nacross 45 general tasks and 15 scientific tasks encompassing a wide range of\nscientific subjects. By investigating Pangaea deeper, the scaling effect of\nmodality is revealed, quantifying the universal knowledge accumulation across\nmodalities as the cumulative distribution function of a geometric distribution.\nOn the whole, Pangaea shows strong potential to handle myriad tasks, indicating\na new direction toward artificial general intelligence.", "AI": {"tldr": "Pangaea\u662f\u9996\u4e2aAI\u8d85\u7ea7\u5927\u9646\uff0c\u901a\u8fc7\u7edf\u4e00\u6570\u636e\u683c\u5f0f\u548c\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\uff0c\u5c06\u5b64\u7acb\u7684\u667a\u80fd\u5c9b\u5c7f\u6574\u5408\u4e3a\u7edf\u4e00\u6a21\u578b\uff0c\u572845\u4e2a\u901a\u7528\u4efb\u52a1\u548c15\u4e2a\u79d1\u5b66\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u5c40\u9650\u4e8e\u7279\u5b9a\u4efb\u52a1\uff0c\u5f62\u6210\u667a\u80fd\u5b64\u5c9b\uff0c\u65e0\u6cd5\u5b9e\u73b0\u8de8\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u3002\u9700\u8981\u6253\u7834\u8fd9\u79cd\u9694\u79bb\uff0c\u6784\u5efa\u80fd\u591f\u5904\u7406\u591a\u79cd\u4efb\u52a1\u7684\u7edf\u4e00\u6a21\u578b\u3002", "method": "\u63d0\u51faPangaea\u6846\u67b6\uff1a1\uff09\u5c06\u4efb\u4f55\u6570\u636e\u7f16\u7801\u4e3a\u7edf\u4e00\u683c\u5f0f\uff1b2\uff09\u5728296\u4e2a\u8de8\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff1b3\uff09\u63ed\u793a\u6a21\u6001\u7f29\u653e\u6548\u5e94\uff0c\u91cf\u5316\u8de8\u6a21\u6001\u77e5\u8bc6\u79ef\u7d2f\u3002", "result": "\u572845\u4e2a\u901a\u7528\u4efb\u52a1\u548c15\u4e2a\u79d1\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u8de8\u6a21\u6001\u77e5\u8bc6\u79ef\u7d2f\u7684\u6709\u6548\u6027\uff0c\u6a21\u6001\u7f29\u653e\u6548\u5e94\u7b26\u5408\u51e0\u4f55\u5206\u5e03\u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u3002", "conclusion": "Pangaea\u5c55\u793a\u4e86\u5904\u7406\u591a\u79cd\u4efb\u52a1\u7684\u5f3a\u5927\u6f5c\u529b\uff0c\u4e3a\u901a\u5411\u4eba\u5de5\u901a\u7528\u667a\u80fd\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.17544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17544", "abs": "https://arxiv.org/abs/2509.17544", "authors": ["Juan Ca\u00f1ada", "Ra\u00fal Alonso", "Julio Molleda", "Fidel D\u00edez"], "title": "A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data", "comment": null, "summary": "The increasing availability of open Earth Observation (EO) and agricultural\ndatasets holds great potential for supporting sustainable land management.\nHowever, their high technical entry barrier limits accessibility for non-expert\nusers. This study presents an open-source conversational assistant that\nintegrates multimodal retrieval and large language models (LLMs) to enable\nnatural language interaction with heterogeneous agricultural and geospatial\ndata. The proposed architecture combines orthophotos, Sentinel-2 vegetation\nindices, and user-provided documents through retrieval-augmented generation\n(RAG), allowing the system to flexibly determine whether to rely on multimodal\nevidence, textual knowledge, or both in formulating an answer. To assess\nresponse quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a\nzero-shot, unsupervised setting, applying direct scoring in a multi-dimensional\nquantitative evaluation framework. Preliminary results show that the system is\ncapable of generating clear, relevant, and context-aware responses to\nagricultural queries, while remaining reproducible and scalable across\ngeographic regions. The primary contributions of this work include an\narchitecture for fusing multimodal EO and textual knowledge sources, a\ndemonstration of lowering the barrier to access specialized agricultural\ninformation through natural language interaction, and an open and reproducible\ndesign.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u5bf9\u8bdd\u52a9\u624b\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u68c0\u7d22\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8ba9\u975e\u4e13\u4e1a\u7528\u6237\u80fd\u591f\u7528\u81ea\u7136\u8bed\u8a00\u4e0e\u5f02\u8d28\u519c\u4e1a\u548c\u5730\u7406\u7a7a\u95f4\u6570\u636e\u8fdb\u884c\u4ea4\u4e92\u3002", "motivation": "\u5f00\u653e\u5730\u7403\u89c2\u6d4b\u548c\u519c\u4e1a\u6570\u636e\u96c6\u6709\u6f5c\u529b\u652f\u6301\u53ef\u6301\u7eed\u571f\u5730\u7ba1\u7406\uff0c\u4f46\u5176\u9ad8\u6280\u672f\u95e8\u69db\u9650\u5236\u4e86\u975e\u4e13\u4e1a\u7528\u6237\u7684\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u6b63\u5c04\u5f71\u50cf\u3001Sentinel-2\u690d\u88ab\u6307\u6570\u548c\u7528\u6237\u63d0\u4f9b\u6587\u6863\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u8ba9\u7cfb\u7edf\u7075\u6d3b\u51b3\u5b9a\u4f9d\u8d56\u591a\u6a21\u6001\u8bc1\u636e\u3001\u6587\u672c\u77e5\u8bc6\u6216\u4e24\u8005\u7ed3\u5408\u6765\u751f\u6210\u7b54\u6848\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u6e05\u6670\u3001\u76f8\u5173\u4e14\u60c5\u5883\u611f\u77e5\u7684\u519c\u4e1a\u67e5\u8be2\u54cd\u5e94\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u5730\u7406\u533a\u57df\u4fdd\u6301\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u4e3b\u8981\u8d21\u732e\u5305\u62ec\u878d\u5408\u591a\u6a21\u6001\u5730\u7403\u89c2\u6d4b\u548c\u6587\u672c\u77e5\u8bc6\u6e90\u7684\u67b6\u6784\u3001\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u964d\u4f4e\u4e13\u4e1a\u519c\u4e1a\u4fe1\u606f\u83b7\u53d6\u95e8\u69db\u7684\u6f14\u793a\uff0c\u4ee5\u53ca\u5f00\u653e\u53ef\u91cd\u73b0\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2509.17550", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17550", "abs": "https://arxiv.org/abs/2509.17550", "authors": ["Neslihan Kose", "Anthony Rhodes", "Umur Aybars Ciftci", "Ilke Demir"], "title": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "comment": "Accepted for publication at the ICCV 2025 STREAM workshop", "summary": "As generative models are advancing in quality and quantity for creating\nsynthetic content, deepfakes begin to cause online mistrust. Deepfake detectors\nare proposed to counter this effect, however, misuse of detectors claiming fake\ncontent as real or vice versa further fuels this misinformation problem. We\npresent the first comprehensive uncertainty analysis of deepfake detectors,\nsystematically investigating how generative artifacts influence prediction\nconfidence. As reflected in detectors' responses, deepfake generators also\ncontribute to this uncertainty as their generative residues vary, so we cross\nthe uncertainty analysis of deepfake detectors and generators. Based on our\nobservations, the uncertainty manifold holds enough consistent information to\nleverage uncertainty for deepfake source detection. Our approach leverages\nBayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and\nepistemic uncertainties across diverse detector architectures. We evaluate\nuncertainty on two datasets with nine generators, with four blind and two\nbiological detectors, compare different uncertainty methods, explore region-\nand pixel-based uncertainty, and conduct ablation studies. We conduct and\nanalyze binary real/fake, multi-class real/fake, source detection, and\nleave-one-out experiments between the generator/detector combinations to share\ntheir generalization capability, model calibration, uncertainty, and robustness\nagainst adversarial attacks. We further introduce uncertainty maps that\nlocalize prediction confidence at the pixel level, revealing distinct patterns\ncorrelated with generator-specific artifacts. Our analysis provides critical\ninsights for deploying reliable deepfake detection systems and establishes\nuncertainty quantification as a fundamental requirement for trustworthy\nsynthetic media detection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u8fdb\u884c\u4e86\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\uff0c\u7814\u7a76\u751f\u6210\u4f2a\u5f71\u5982\u4f55\u5f71\u54cd\u9884\u6d4b\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u6df1\u5ea6\u4f2a\u9020\u6e90\u68c0\u6d4b\u3002", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u8d28\u91cf\u63d0\u5347\u5bfc\u81f4\u6df1\u5ea6\u4f2a\u9020\u5185\u5bb9\u6cdb\u6ee5\uff0c\u68c0\u6d4b\u5668\u7684\u8bef\u7528\u4f1a\u52a0\u5267\u9519\u8bef\u4fe1\u606f\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5206\u6790\u68c0\u6d4b\u5668\u7684\u4e0d\u786e\u5b9a\u6027\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u8499\u7279\u5361\u6d1bdropout\u91cf\u5316\u4e0d\u540c\u68c0\u6d4b\u5668\u67b6\u6784\u7684\u5076\u7136\u6027\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u4e8c\u5143/\u591a\u5206\u7c7b\u3001\u6e90\u68c0\u6d4b\u7b49\u5b9e\u9a8c\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5\u3002", "result": "\u4e0d\u786e\u5b9a\u6027\u6d41\u5f62\u5305\u542b\u8db3\u591f\u4e00\u81f4\u7684\u4fe1\u606f\u53ef\u7528\u4e8e\u6df1\u5ea6\u4f2a\u9020\u6e90\u68c0\u6d4b\uff0c\u4e0d\u786e\u5b9a\u6027\u56fe\u8c31\u80fd\u5b9a\u4f4d\u50cf\u7d20\u7ea7\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u5e76\u63ed\u793a\u751f\u6210\u5668\u7279\u5b9a\u4f2a\u5f71\u6a21\u5f0f\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u662f\u53ef\u4fe1\u5408\u6210\u5a92\u4f53\u68c0\u6d4b\u7684\u57fa\u672c\u8981\u6c42\uff0c\u8be5\u5206\u6790\u4e3a\u90e8\u7f72\u53ef\u9760\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2509.17553", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17553", "abs": "https://arxiv.org/abs/2509.17553", "authors": ["Congcong Ge", "Yachuan Liu", "Yixuan Tang", "Yifan Zhu", "Yaofeng Tu", "Yunjun Gao"], "title": "MontePrep: Monte-Carlo-Driven Automatic Data Preparation without Target Data Instances", "comment": null, "summary": "In commercial systems, a pervasive requirement for automatic data preparation\n(ADP) is to transfer relational data from disparate sources to targets with\nstandardized schema specifications. Previous methods rely on labor-intensive\nsupervision signals or target table data access permissions, limiting their\nusage in real-world scenarios. To tackle these challenges, we propose an\neffective end-to-end ADP framework MontePrep, which enables training-free\npipeline synthesis with zero target-instance requirements. MontePrep is\nformulated as an open-source large language model (LLM) powered tree-structured\nsearch problem. It consists of three pivot components, i.e., a data preparation\naction sandbox (DPAS), a fundamental pipeline generator (FPG), and an\nexecution-aware pipeline optimizer (EPO). We first introduce DPAS, a\nlightweight action sandbox, to navigate the search-based pipeline generation.\nThe design of DPAS circumvents exploration of infeasible pipelines. Then, we\npresent FPG to build executable DP pipelines incrementally, which explores the\npredefined action sandbox by the LLM-powered Monte Carlo Tree Search.\nFurthermore, we propose EPO, which invokes pipeline execution results from\nsources to targets to evaluate the reliability of the generated pipelines in\nFPG. In this way, unreasonable pipelines are eliminated, thus facilitating the\nsearch process from both efficiency and effectiveness perspectives. Extensive\nexperimental results demonstrate the superiority of MontePrep with significant\nimprovement against five state-of-the-art competitors.", "AI": {"tldr": "MontePrep\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u3001\u96f6\u76ee\u6807\u5b9e\u4f8b\u8981\u6c42\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u6570\u636e\u51c6\u5907\u6846\u67b6\uff0c\u4f7f\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u6811\u7ed3\u6784\u641c\u7d22\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5546\u4e1a\u7cfb\u7edf\u4e2d\u9700\u8981\u5c06\u5f02\u6784\u5173\u7cfb\u6570\u636e\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u6a21\u5f0f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u76d1\u7763\u4fe1\u53f7\u6216\u76ee\u6807\u8868\u6570\u636e\u8bbf\u95ee\u6743\u9650\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u7684\u6846\u67b6\uff1a\u6570\u636e\u51c6\u5907\u52a8\u4f5c\u6c99\u7bb1(DPAS)\u6307\u5bfc\u641c\u7d22\uff0c\u57fa\u7840\u7ba1\u9053\u751f\u6210\u5668(FPG)\u901a\u8fc7LLM\u9a71\u52a8\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u589e\u91cf\u6784\u5efa\u7ba1\u9053\uff0c\u6267\u884c\u611f\u77e5\u7ba1\u9053\u4f18\u5316\u5668(EPO)\u901a\u8fc7\u6267\u884c\u7ed3\u679c\u8bc4\u4f30\u7ba1\u9053\u53ef\u9760\u6027\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eMontePrep\u5728\u4e94\u4e2a\u6700\u5148\u8fdb\u7ade\u4e89\u5bf9\u624b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "MontePrep\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u6570\u636e\u51c6\u5907\u4e2d\u7684\u5b9e\u9645\u9650\u5236\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u65e0\u9700\u76ee\u6807\u5b9e\u4f8b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.17567", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17567", "abs": "https://arxiv.org/abs/2509.17567", "authors": ["Yang Xiao", "Mohan Jiang", "Jie Sun", "Keyu Li", "Jifan Lin", "Yumin Zhuang", "Ji Zeng", "Shijie Xia", "Qishuo Hua", "Xuefeng Li", "Xiaojie Cai", "Tongyu Wang", "Yue Zhang", "Liming Liu", "Xia Wu", "Jinlong Hou", "Yuan Cheng", "Wenjie Li", "Xiang Wang", "Dequan Wang", "Pengfei Liu"], "title": "LIMI: Less is More for Agency", "comment": null, "summary": "We define Agency as the emergent capacity of AI systems to function as\nautonomous agents actively discovering problems, formulating hypotheses, and\nexecuting solutions through self-directed engagement with environments and\ntools. This fundamental capability marks the dawn of the Age of AI Agency,\ndriven by a critical industry shift: the urgent need for AI systems that don't\njust think, but work. While current AI excels at reasoning and generating\nresponses, industries demand autonomous agents that can execute tasks, operate\ntools, and drive real-world outcomes. As agentic intelligence becomes the\ndefining characteristic separating cognitive systems from productive workers,\nefficiently cultivating machine autonomy becomes paramount. Current approaches\nassume that more data yields better agency, following traditional scaling laws\nfrom language modeling. We fundamentally challenge this paradigm. LIMI (Less Is\nMore for Intelligent Agency) demonstrates that agency follows radically\ndifferent development principles. Through strategic focus on collaborative\nsoftware development and scientific research workflows, we show that\nsophisticated agentic intelligence can emerge from minimal but strategically\ncurated demonstrations of autonomous behavior. Using only 78 carefully designed\ntraining samples, LIMI achieves 73.5% on comprehensive agency benchmarks,\ndramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%),\nDeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%).\nMost strikingly, LIMI demonstrates 53.7% improvement over models trained on\n10,000 samples-achieving superior agentic intelligence with 128 times fewer\nsamples. Our findings establish the Agency Efficiency Principle: machine\nautonomy emerges not from data abundance but from strategic curation of\nhigh-quality agentic demonstrations.", "AI": {"tldr": "LIMI\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684AI\u4ee3\u7406\u80fd\u529b\u53d1\u5c55\u8303\u5f0f\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u6570\u636e\u89c4\u6a21\u8d8a\u5927\u4ee3\u7406\u80fd\u529b\u8d8a\u5f3a\u7684\u5047\u8bbe\u3002\u901a\u8fc7\u4ec5\u4f7f\u752878\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u5728\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523073.5%\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u4f7f\u7528\u5927\u91cf\u6570\u636e\u7684\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u867d\u7136\u64c5\u957f\u63a8\u7406\u548c\u751f\u6210\u54cd\u5e94\uff0c\u4f46\u884c\u4e1a\u9700\u8981\u80fd\u591f\u6267\u884c\u4efb\u52a1\u3001\u64cd\u4f5c\u5de5\u5177\u5e76\u9a71\u52a8\u73b0\u5b9e\u4e16\u754c\u7ed3\u679c\u7684\u81ea\u4e3b\u4ee3\u7406\u3002\u4f20\u7edf\u65b9\u6cd5\u5047\u8bbe\u66f4\u591a\u6570\u636e\u4f1a\u4ea7\u751f\u66f4\u597d\u7684\u4ee3\u7406\u80fd\u529b\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u4ee3\u7406\u80fd\u529b\u7684\u53d1\u5c55\u9075\u5faa\u4e0d\u540c\u7684\u539f\u5219\u3002", "method": "LIMI\u65b9\u6cd5\u901a\u8fc7\u6218\u7565\u6027\u5730\u5173\u6ce8\u534f\u4f5c\u8f6f\u4ef6\u5f00\u53d1\u548c\u79d1\u5b66\u7814\u7a76\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ec5\u4f7f\u752878\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u81ea\u4e3b\u884c\u4e3a\u6f14\u793a\u6837\u672c\u6765\u57f9\u517b\u590d\u6742\u7684\u4ee3\u7406\u667a\u80fd\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u3002", "result": "LIMI\u5728\u7efc\u5408\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523073.5%\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff08Kimi-K2-Instruct 24.1%\uff0cDeepSeek-V3.1 11.9%\u7b49\uff09\uff0c\u5e76\u4e14\u6bd4\u4f7f\u752810,000\u4e2a\u6837\u672c\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u63d0\u534753.7%\u3002", "conclusion": "\u7814\u7a76\u786e\u7acb\u4e86\u4ee3\u7406\u6548\u7387\u539f\u5219\uff1a\u673a\u5668\u81ea\u4e3b\u6027\u4e0d\u662f\u6765\u81ea\u6570\u636e\u4e30\u5bcc\u6027\uff0c\u800c\u662f\u6765\u81ea\u9ad8\u8d28\u91cf\u4ee3\u7406\u6f14\u793a\u7684\u6218\u7565\u6027\u7b56\u5212\u3002\u5c11\u5373\u662f\u591a\uff08Less Is More\uff09\u7684\u65b9\u6cd5\u5728\u57f9\u517b\u4ee3\u7406\u667a\u80fd\u65b9\u9762\u66f4\u4e3a\u6709\u6548\u3002"}}
{"id": "2509.17589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17589", "abs": "https://arxiv.org/abs/2509.17589", "authors": ["Jun Ling", "Yao Qi", "Tao Huang", "Shibo Zhou", "Yanqin Huang", "Jiang Yang", "Ziqi Song", "Ying Zhou", "Yang Yang", "Heng Tao Shen", "Peng Wang"], "title": "Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models", "comment": "NeurIPS 2025", "summary": "In this work, we address the task of table image to LaTeX code generation,\nwith the goal of automating the reconstruction of high-quality,\npublication-ready tables from visual inputs. A central challenge of this task\nlies in accurately handling complex tables -- those with large sizes, deeply\nnested structures, and semantically rich or irregular cell content -- where\nexisting methods often fail. We begin with a comprehensive analysis,\nidentifying key challenges and highlighting the limitations of current\nevaluation protocols. To overcome these issues, we propose a reinforced\nmultimodal large language model (MLLM) framework, where a pre-trained MLLM is\nfine-tuned on a large-scale table-to-LaTeX dataset. To further improve\ngeneration quality, we introduce a dual-reward reinforcement learning strategy\nbased on Group Relative Policy Optimization (GRPO). Unlike standard approaches\nthat optimize purely over text outputs, our method incorporates both a\nstructure-level reward on LaTeX code and a visual fidelity reward computed from\nrendered outputs, enabling direct optimization of the visual output quality. We\nadopt a hybrid evaluation protocol combining TEDS-Structure and CW-SSIM, and\nshow that our method achieves state-of-the-art performance, particularly on\nstructurally complex tables, demonstrating the effectiveness and robustness of\nour approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u683c\u56fe\u50cf\u5230LaTeX\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4f18\u5316\u751f\u6210\u8d28\u91cf\uff0c\u5728\u590d\u6742\u8868\u683c\u5904\u7406\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u5927\u5c3a\u5bf8\u3001\u6df1\u5c42\u5d4c\u5957\u7ed3\u6784\u548c\u8bed\u4e49\u4e30\u5bcc\u5185\u5bb9\u7684\u590d\u6742\u8868\u683c\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51c6\u786e\u91cd\u5efa\u9ad8\u8d28\u91cf\u51fa\u7248\u7ea7\u8868\u683c\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5927\u89c4\u6a21\u8868\u683c\u5230LaTeX\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5f15\u5165\u57fa\u4e8eGRPO\u7684\u53cc\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u7ed3\u5408\u7ed3\u6784\u7ea7\u5956\u52b1\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u5956\u52b1\u6765\u76f4\u63a5\u4f18\u5316\u89c6\u89c9\u8f93\u51fa\u8d28\u91cf\u3002", "result": "\u91c7\u7528TEDS-Structure\u548cCW-SSIM\u6df7\u5408\u8bc4\u4f30\u534f\u8bae\uff0c\u8be5\u65b9\u6cd5\u5728\u7ed3\u6784\u590d\u6742\u8868\u683c\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f3a\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u8868\u683c\u7684LaTeX\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u7ed3\u6784\u590d\u6742\u8868\u683c\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u8868\u683c\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.17677", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17677", "abs": "https://arxiv.org/abs/2509.17677", "authors": ["Xiyuan Zhou", "Xinlei Wang", "Yirui He", "Yang Wu", "Ruixi Zou", "Yuheng Cheng", "Yulu Xie", "Wenxuan Liu", "Huan Zhao", "Yan Xu", "Jinjin Gu", "Junhua Zhao"], "title": "EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving", "comment": null, "summary": "Large language models (LLMs) have shown strong performance on mathematical\nreasoning under well-posed conditions. However, real-world engineering problems\nrequire more than mathematical symbolic computation -- they need to deal with\nuncertainty, context, and open-ended scenarios. Existing benchmarks fail to\ncapture these complexities. We introduce EngiBench, a hierarchical benchmark\ndesigned to evaluate LLMs on solving engineering problems. It spans three\nlevels of increasing difficulty (foundational knowledge retrieval, multi-step\ncontextual reasoning, and open-ended modeling) and covers diverse engineering\nsubfields. To facilitate a deeper understanding of model performance, we\nsystematically rewrite each problem into three controlled variants (perturbed,\nknowledge-enhanced, and math abstraction), enabling us to separately evaluate\nthe model's robustness, domain-specific knowledge, and mathematical reasoning\nabilities. Experiment results reveal a clear performance gap across levels:\nmodels struggle more as tasks get harder, perform worse when problems are\nslightly changed, and fall far behind human experts on the high-level\nengineering tasks. These findings reveal that current LLMs still lack the\nhigh-level reasoning needed for real-world engineering, highlighting the need\nfor future models with deeper and more reliable problem-solving capabilities.\nOur source code and data are available at\nhttps://github.com/EngiBench/EngiBench.", "AI": {"tldr": "EngiBench\u662f\u4e00\u4e2a\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u5de5\u7a0b\u95ee\u9898\u4e0a\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u771f\u5b9e\u5de5\u7a0b\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u5de5\u7a0b\u95ee\u9898\u7684\u590d\u6742\u6027\uff08\u4e0d\u786e\u5b9a\u6027\u3001\u4e0a\u4e0b\u6587\u548c\u5f00\u653e\u5f0f\u573a\u666f\uff09\uff0c\u9700\u8981\u4e13\u95e8\u8bc4\u4f30LLMs\u5728\u5de5\u7a0b\u9886\u57df\u7684\u80fd\u529b", "method": "\u8bbe\u8ba1\u5305\u542b\u4e09\u4e2a\u96be\u5ea6\u5c42\u7ea7\u7684\u5206\u5c42\u57fa\u51c6\uff08\u57fa\u7840\u77e5\u8bc6\u68c0\u7d22\u3001\u591a\u6b65\u4e0a\u4e0b\u6587\u63a8\u7406\u3001\u5f00\u653e\u5f0f\u5efa\u6a21\uff09\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u91cd\u5199\u95ee\u9898\u4e3a\u4e09\u79cd\u53d8\u4f53\uff08\u6270\u52a8\u3001\u77e5\u8bc6\u589e\u5f3a\u3001\u6570\u5b66\u62bd\u8c61\uff09\u6765\u6df1\u5165\u5206\u6790\u6a21\u578b\u6027\u80fd", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u6027\u80fd\u968f\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u800c\u660e\u663e\u4e0b\u964d\uff0c\u5bf9\u95ee\u9898\u5fae\u5c0f\u53d8\u5316\u654f\u611f\uff0c\u5728\u9ad8\u7ea7\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8fdc\u843d\u540e\u4e8e\u4eba\u7c7b\u4e13\u5bb6", "conclusion": "\u5f53\u524dLLMs\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u5de5\u7a0b\u6240\u9700\u7684\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u672a\u6765\u9700\u8981\u5f00\u53d1\u5177\u6709\u66f4\u6df1\u5165\u548c\u53ef\u9760\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u6a21\u578b"}}
{"id": "2509.17706", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17706", "abs": "https://arxiv.org/abs/2509.17706", "authors": ["Pierre Montalbano", "Simon de Givry", "George Katsirelos"], "title": "Virtual Arc Consistency for Linear Constraints inCost Function Networks", "comment": null, "summary": "In Constraint Programming, solving discrete minimization problems with hard\nand soft constraints can be done either using (i) soft global constraints, (ii)\na reformulation into a linear program, or (iii) a reformulation into local cost\nfunctions. Approach (i) benefits from a vast catalog of constraints. Each soft\nconstraint propagator communicates with other soft constraints only through the\nvariable domains, resulting in weak lower bounds. Conversely, the approach (ii)\nprovides a global view with strong bounds, but the size of the reformulation\ncan be problematic. We focus on approach (iii) in which soft arc consistency\n(SAC) algorithms produce bounds of intermediate quality. Recently, the\nintroduction of linear constraints as local cost functions increases their\nmodeling expressiveness. We adapt an existing SAC algorithm to handle linear\nconstraints. We show that our algorithm significantly improves the lower bounds\ncompared to the original algorithm on several benchmarks, reducing solving time\nin some cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8f6f\u5f27\u4e00\u81f4\u6027\u7b97\u6cd5\u6765\u5904\u7406\u7ebf\u6027\u7ea6\u675f\uff0c\u76f8\u6bd4\u539f\u6709\u7b97\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u4e0b\u754c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u51cf\u5c11\u6c42\u89e3\u65f6\u95f4\u3002", "motivation": "\u5728\u7ea6\u675f\u89c4\u5212\u4e2d\uff0c\u89e3\u51b3\u5e26\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u7684\u79bb\u6563\u6700\u5c0f\u5316\u95ee\u9898\u6709\u4e09\u79cd\u65b9\u6cd5\uff1a\u8f6f\u5168\u5c40\u7ea6\u675f\u3001\u7ebf\u6027\u89c4\u5212\u91cd\u6784\u548c\u5c40\u90e8\u6210\u672c\u51fd\u6570\u91cd\u6784\u3002\u8f6f\u5168\u5c40\u7ea6\u675f\u65b9\u6cd5\u6709\u4e30\u5bcc\u7684\u7ea6\u675f\u5e93\u4f46\u4e0b\u754c\u8f83\u5f31\uff0c\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u6709\u5f3a\u4e0b\u754c\u4f46\u91cd\u6784\u89c4\u6a21\u5927\u3002\u672c\u6587\u5173\u6ce8\u7b2c\u4e09\u79cd\u65b9\u6cd5\uff0c\u65e8\u5728\u6539\u8fdb\u8f6f\u5f27\u4e00\u81f4\u6027\u7b97\u6cd5\u4ee5\u5904\u7406\u7ebf\u6027\u7ea6\u675f\u3002", "method": "\u4f5c\u8005\u6539\u8fdb\u4e86\u73b0\u6709\u7684\u8f6f\u5f27\u4e00\u81f4\u6027\u7b97\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u4f5c\u4e3a\u5c40\u90e8\u6210\u672c\u51fd\u6570\u7684\u7ebf\u6027\u7ea6\u675f\uff0c\u4ece\u800c\u589e\u5f3a\u5efa\u6a21\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6539\u8fdb\u540e\u7684\u7b97\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u539f\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4e0b\u754c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u51cf\u5c11\u4e86\u6c42\u89e3\u65f6\u95f4\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7ebf\u6027\u7ea6\u675f\u6574\u5408\u5230\u8f6f\u5f27\u4e00\u81f4\u6027\u6846\u67b6\u4e2d\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u5efa\u6a21\u7075\u6d3b\u6027\u7684\u540c\u65f6\u83b7\u5f97\u66f4\u597d\u7684\u6c42\u89e3\u6027\u80fd\u3002"}}
{"id": "2509.17711", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17711", "abs": "https://arxiv.org/abs/2509.17711", "authors": ["Shenwei Kang", "Xin Zhang", "Wen Liu", "Bin Li", "Yujie Liu", "Bo Gao"], "title": "DA-Mamba: Dialogue-aware selective state-space model for multimodal engagement estimation", "comment": null, "summary": "Human engagement estimation in conversational scenarios is essential for\napplications such as adaptive tutoring, remote healthcare assessment, and\nsocially aware human--computer interaction. Engagement is a dynamic, multimodal\nsignal conveyed by facial expressions, speech, gestures, and behavioral cues\nover time. In this work we introduce DA-Mamba, a dialogue-aware multimodal\narchitecture that replaces attention-heavy dialogue encoders with Mamba-based\nselective state-space processing to achieve linear time and memory complexity\nwhile retaining expressive cross-modal reasoning. We design a Mamba\ndialogue-aware selective state-space model composed of three core modules: a\nDialogue-Aware Encoder, and two Mamba-based fusion mechanisms: Modality-Group\nFusion and Partner-Group Fusion, these modules achieve expressive dialogue\nunderstanding. Extensive experiments on three standard benchmarks (NoXi,\nNoXi-Add, and MPIIGI) show that DA-Mamba surpasses prior state-of-the-art\n(SOTA) methods in concordance correlation coefficient (CCC), while reducing\ntraining time and peak memory; these gains enable processing much longer\nsequences and facilitate real-time deployment in resource-constrained,\nmulti-party conversational settings. The source code will be available at:\nhttps://github.com/kksssssss-ssda/MMEA.", "AI": {"tldr": "DA-Mamba\u662f\u4e00\u79cd\u7528\u4e8e\u5bf9\u8bdd\u573a\u666f\u4e2d\u4eba\u7c7b\u53c2\u4e0e\u5ea6\u4f30\u8ba1\u7684\u65b0\u578b\u591a\u6a21\u6001\u67b6\u6784\uff0c\u5b83\u4f7f\u7528Mamba\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u5904\u7406\u66ff\u4ee3\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u5728\u4e09\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u4eba\u7c7b\u53c2\u4e0e\u5ea6\u4f30\u8ba1\u5bf9\u4e8e\u81ea\u9002\u5e94\u6559\u5b66\u3001\u8fdc\u7a0b\u533b\u7597\u8bc4\u4f30\u548c\u793e\u4ea4\u611f\u77e5\u4eba\u673a\u4ea4\u4e92\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5185\u5b58\u6d88\u8017\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8eMamba\u7684\u5bf9\u8bdd\u611f\u77e5\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u5bf9\u8bdd\u611f\u77e5\u7f16\u7801\u5668\u3001\u6a21\u6001\u7ec4\u878d\u5408\u548c\u4f19\u4f34\u7ec4\u878d\u5408\u673a\u5236\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u5904\u7406\u5b9e\u73b0\u9ad8\u6548\u7684\u8de8\u6a21\u6001\u63a8\u7406\u3002", "result": "\u5728NoXi\u3001NoXi-Add\u548cMPIIGI\u4e09\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDA-Mamba\u5728\u4e00\u81f4\u6027\u76f8\u5173\u7cfb\u6570(CCC)\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u548c\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\uff0c\u80fd\u591f\u5904\u7406\u66f4\u957f\u7684\u5e8f\u5217\u3002", "conclusion": "DA-Mamba\u901a\u8fc7Mamba\u67b6\u6784\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u6a21\u6001\u53c2\u4e0e\u5ea6\u4f30\u8ba1\uff0c\u5728\u4fdd\u6301\u8868\u8fbe\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u591a\u65b9\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u5b9e\u65f6\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u3002"}}
{"id": "2509.17774", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.17774", "abs": "https://arxiv.org/abs/2509.17774", "authors": ["Joao Marques-Silva", "Alexey Ignatiev"], "title": "Efficient & Correct Predictive Equivalence for Decision Trees", "comment": null, "summary": "The Rashomon set of decision trees (DTs) finds importance uses. Recent work\nshowed that DTs computing the same classification function, i.e. predictive\nequivalent DTs, can represent a significant fraction of the Rashomon set. Such\nredundancy is undesirable. For example, feature importance based on the\nRashomon set becomes inaccurate due the existence of predictive equivalent DTs,\ni.e. DTs with the same prediction for every possible input. In recent work,\nMcTavish et al. proposed solutions for several computational problems related\nwith DTs, including that of deciding predictive equivalent DTs. This approach,\nwhich this paper refers to as MBDSR, consists of applying the well-known method\nof Quine-McCluskey (QM) for obtaining minimum-size DNF (disjunctive normal\nform) representations of DTs, which are then used for comparing DTs for\npredictive equivalence. Furthermore, the minimum-size DNF representation was\nalso applied to computing explanations for the predictions made by DTs, and to\nfinding predictions in the presence of missing data. However, the problem of\nformula minimization is hard for the second level of the polynomial hierarchy,\nand the QM method may exhibit worst-case exponential running time and space.\nThis paper first demonstrates that there exist decision trees that trigger the\nworst-case exponential running time and space of the QM method. Second, the\npaper shows that the MBDSR approach can produce incorrect results for the\nproblem of deciding predictive equivalence. Third, the paper shows that any of\nthe problems to which the minimum-size DNF representation has been applied to\ncan in fact be solved in polynomial time, in the size of the DT. The\nexperiments confirm that, for DTs for which the the worst-case of the QM method\nis triggered, the algorithms proposed in this paper are orders of magnitude\nfaster than the ones proposed by McTavish et al.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86McTavish\u7b49\u4eba\u63d0\u51fa\u7684MBDSR\u65b9\u6cd5\u5728\u51b3\u7b56\u6811\u9884\u6d4b\u7b49\u4ef7\u6027\u5224\u5b9a\u4e2d\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86QM\u65b9\u6cd5\u5b58\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6307\u6570\u7ea7\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u89e3\u51b3\u76f8\u5173\u95ee\u9898\u3002", "motivation": "\u51b3\u7b56\u6811\u7684Rashomon\u96c6\u5408\u4e2d\u5b58\u5728\u5927\u91cf\u9884\u6d4b\u7b49\u4ef7\u7684\u51b3\u7b56\u6811\uff0c\u8fd9\u4f1a\u5f71\u54cd\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u7684\u51c6\u786e\u6027\u3002McTavish\u7b49\u4eba\u63d0\u51fa\u7684MBDSR\u65b9\u6cd5\u4f7f\u7528QM\u65b9\u6cd5\u8fdb\u884c\u6700\u5c0fDNF\u8868\u793a\uff0c\u4f46\u8be5\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u95ee\u9898\u548c\u6b63\u786e\u6027\u95ee\u9898\u3002", "method": "\u672c\u6587\u9996\u5148\u8bc1\u660e\u4e86QM\u65b9\u6cd5\u5b58\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6307\u6570\u7ea7\u8fd0\u884c\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u7136\u540e\u5c55\u793a\u4e86MBDSR\u65b9\u6cd5\u5728\u9884\u6d4b\u7b49\u4ef7\u6027\u5224\u5b9a\u4e2d\u53ef\u80fd\u4ea7\u751f\u9519\u8bef\u7ed3\u679c\uff0c\u6700\u540e\u63d0\u51fa\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u89e3\u51b3\u76f8\u5173\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u5bf9\u4e8e\u89e6\u53d1QM\u65b9\u6cd5\u6700\u574f\u60c5\u51b5\u7684\u51b3\u7b56\u6811\uff0c\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u6bd4McTavish\u7b49\u4eba\u7684\u7b97\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86QM\u65b9\u6cd5\u5728\u51b3\u7b56\u6811\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u89e3\u51b3\u9884\u6d4b\u7b49\u4ef7\u6027\u5224\u5b9a\u548c\u76f8\u5173\u95ee\u9898\u3002"}}
{"id": "2509.17905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17905", "abs": "https://arxiv.org/abs/2509.17905", "authors": ["Zongqian Wu", "Baoduo Xu", "Tianyu Li", "Zhu Sun", "Xiaofeng Zhu", "Lei Feng"], "title": "Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling", "comment": "23 pages, 9 figures", "summary": "Test-time scaling (TTS) has been shown to improve the performance of large\nlanguage models (LLMs) by sampling and aggregating diverse reasoning paths.\nHowever, existing research has overlooked a critical issue: selection bias of\nreasoning strategies during scaling. Specifically, when generating reasoning\nprocesses, LLMs tend to follow certain strategies (e.g., algebraic solutions\nfor math problems) while neglecting other valid alternatives (e.g., geometric\nsolutions), resulting in insufficient exploration of the solution space. To\nfurther understand the impact of this bias, we present a theoretical analysis\nthat reveals when it undermines the effectiveness of test-time scaling.\nMotivated by this theoretical insight, we introduce TTS-Uniform, a framework\ndesigned to mitigate the selection bias of reasoning strategies. It (i)\nidentifies potential strategies, (ii) uniformly allocates the sampling budget\nacross them, and (iii) filters out unstable strategies prior to aggregation.\nExperimental results show that TTS-Uniform significantly enhances scaling\neffectiveness across multiple mainstream LLMs and benchmark datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTTS-Uniform\u6846\u67b6\uff0c\u901a\u8fc7\u5747\u5300\u5206\u914d\u91c7\u6837\u9884\u7b97\u6765\u7f13\u89e3\u6d4b\u8bd5\u65f6\u6269\u5c55\u4e2d\u7684\u63a8\u7406\u7b56\u7565\u9009\u62e9\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u7b56\u7565\u9009\u62e9\u504f\u5dee\u95ee\u9898\uff0c\u5373LLMs\u5728\u751f\u6210\u63a8\u7406\u8fc7\u7a0b\u65f6\u503e\u5411\u4e8e\u91c7\u7528\u67d0\u4e9b\u7b56\u7565\u800c\u5ffd\u7565\u5176\u4ed6\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u5bfc\u81f4\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "TTS-Uniform\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6b65\u9aa4\uff1a(i)\u8bc6\u522b\u6f5c\u5728\u63a8\u7406\u7b56\u7565\uff0c(ii)\u5747\u5300\u5206\u914d\u91c7\u6837\u9884\u7b97\uff0c(iii)\u5728\u805a\u5408\u524d\u8fc7\u6ee4\u4e0d\u7a33\u5b9a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTTS-Uniform\u5728\u591a\u4e2a\u4e3b\u6d41LLMs\u548c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6269\u5c55\u6548\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u7f13\u89e3\u63a8\u7406\u7b56\u7565\u9009\u62e9\u504f\u5dee\u5bf9\u63d0\u5347\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u679c\u7684\u91cd\u8981\u6027\uff0cTTS-Uniform\u6846\u67b6\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2509.17907", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17907", "abs": "https://arxiv.org/abs/2509.17907", "authors": ["Xiaojing Dong", "Weilin Huang", "Liang Li", "Yiying Li", "Shu Liu", "Tongtong Ou", "Shuang Ouyang", "Yu Tian", "Fengxuan Zhao"], "title": "MEF: A Systematic Evaluation Framework for Text-to-Image Models", "comment": null, "summary": "Rapid advances in text-to-image (T2I) generation have raised higher\nrequirements for evaluation methodologies. Existing benchmarks center on\nobjective capabilities and dimensions, but lack an application-scenario\nperspective, limiting external validity. Moreover, current evaluations\ntypically rely on either ELO for overall ranking or MOS for dimension-specific\nscoring, yet both methods have inherent shortcomings and limited\ninterpretability. Therefore, we introduce the Magic Evaluation Framework (MEF),\na systematic and practical approach for evaluating T2I models. First, we\npropose a structured taxonomy encompassing user scenarios, elements, element\ncompositions, and text expression forms to construct the Magic-Bench-377, which\nsupports label-level assessment and ensures a balanced coverage of both user\nscenarios and capabilities. On this basis, we combine ELO and\ndimension-specific MOS to generate model rankings and fine-grained assessments\nrespectively. This joint evaluation method further enables us to quantitatively\nanalyze the contribution of each dimension to user satisfaction using\nmultivariate logistic regression. By applying MEF to current T2I models, we\nobtain a leaderboard and key characteristics of the leading models. We release\nour evaluation framework and make Magic-Bench-377 fully open-source to advance\nresearch in the evaluation of visual generative models.", "AI": {"tldr": "\u63d0\u51fa\u4e86Magic\u8bc4\u4f30\u6846\u67b6\uff08MEF\uff09\uff0c\u4e00\u4e2a\u7cfb\u7edf\u5b9e\u7528\u7684\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u6784\u5efaMagic-Bench-377\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u5408ELO\u548cMOS\u8fdb\u884c\u8054\u5408\u8bc4\u4f30\uff0c\u5e76\u4f7f\u7528\u591a\u5143\u903b\u8f91\u56de\u5f52\u5206\u6790\u5404\u7ef4\u5ea6\u5bf9\u7528\u6237\u6ee1\u610f\u5ea6\u7684\u8d21\u732e\u3002", "motivation": "\u73b0\u6709T2I\u751f\u6210\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u5e94\u7528\u573a\u666f\u89c6\u89d2\uff0c\u4e14ELO\u548cMOS\u65b9\u6cd5\u5404\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u3001\u5b9e\u7528\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\u6784\u5efaMagic-Bench-377\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u5408ELO\u548c\u7ef4\u5ea6\u7279\u5b9aMOS\u8fdb\u884c\u8054\u5408\u8bc4\u4f30\uff0c\u4f7f\u7528\u591a\u5143\u903b\u8f91\u56de\u5f52\u5206\u6790\u7ef4\u5ea6\u8d21\u732e\u3002", "result": "\u5e94\u7528MEF\u5230\u5f53\u524dT2I\u6a21\u578b\uff0c\u83b7\u5f97\u4e86\u6392\u884c\u699c\u548c\u9886\u5148\u6a21\u578b\u7684\u5173\u952e\u7279\u5f81\u3002", "conclusion": "MEF\u4e3a\u89c6\u89c9\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u53d1\u5e03\u7684Magic-Bench-377\u57fa\u51c6\u6d4b\u8bd5\u5c06\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2509.17917", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17917", "abs": "https://arxiv.org/abs/2509.17917", "authors": ["Junyu Lu", "Songxin Zhang", "Zejian Xie", "Zhuoyang Song", "Jiaxing Zhang"], "title": "Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent", "comment": null, "summary": "Recent advances in GUI agents have achieved remarkable grounding and\naction-prediction performance, yet existing models struggle with unreliable\nreward signals and limited online trajectory generation. In this paper, we\nintroduce Orcust, a framework that integrates Principle-Constrained Reward\nModeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to\nenhance reasoning reliability and data efficiency in interactive GUI tasks. We\nleverages environment-verifiable and LLM-derived principle to enforce\ninterpretable reward signals that constrain long chain-of-thought reasoning and\nrule-based feedback. OVTC spins up instrumented virtual machines to\nautonomously collect structured GUI interaction trajectories with explicit\nprocedural and structural objectives, enabling the training of a stepwise\nreward model that robustly captures human preferences and adheres to\ntask-specific constraints. Extensive experiments on standard GUI benchmarks\ncovering perceptual grounding, foundational operations, and end-to-end task\nexecution reveal that Orcust achieves state-of-the-art performance, improving\nby 22.2\\% on ScreenSpot and 23.9\\% on ScreenSpot-Pro over the base model (i.e.\nQwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the\nreasoning, adaptability and scalability of GUI agents across various\nenvironments and task complexities.", "AI": {"tldr": "Orcust\u6846\u67b6\u901a\u8fc7\u539f\u5219\u7ea6\u675f\u5956\u52b1\u5efa\u6a21\u548c\u5728\u7ebf\u865a\u62df\u673a\u8f68\u8ff9\u6784\u5efa\uff0c\u63d0\u5347\u4e86GUI\u4ee3\u7406\u5728\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u53ef\u9760\u6027\u548c\u6570\u636e\u6548\u7387\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u6a21\u578b\u9762\u4e34\u5956\u52b1\u4fe1\u53f7\u4e0d\u53ef\u9760\u548c\u5728\u7ebf\u8f68\u8ff9\u751f\u6210\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u63d0\u5347\u63a8\u7406\u53ef\u9760\u6027\u548c\u6570\u636e\u6548\u7387\u3002", "method": "\u91c7\u7528\u539f\u5219\u7ea6\u675f\u5956\u52b1\u5efa\u6a21\uff08PCRM\uff09\u548c\u5728\u7ebf\u865a\u62df\u673a\u8f68\u8ff9\u6784\u5efa\uff08OVTC\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u73af\u5883\u53ef\u9a8c\u8bc1\u548cLLM\u884d\u751f\u7684\u539f\u5219\u6765\u7ea6\u675f\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u865a\u62df\u673a\u81ea\u4e3b\u6536\u96c6\u7ed3\u6784\u5316GUI\u4ea4\u4e92\u8f68\u8ff9\u3002", "result": "\u5728\u6807\u51c6GUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOrcust\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5728ScreenSpot\u4e0a\u63d0\u534722.2%\uff0c\u5728ScreenSpot-Pro\u4e0a\u63d0\u534723.9%\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "Orcust\u6846\u67b6\u6709\u6548\u589e\u5f3a\u4e86GUI\u4ee3\u7406\u7684\u63a8\u7406\u80fd\u529b\u3001\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5728\u5404\u79cd\u73af\u5883\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.17956", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.17956", "abs": "https://arxiv.org/abs/2509.17956", "authors": ["Lin Luo", "Yuri Nakao", "Mathieu Chollet", "Hiroya Inakoshi", "Simone Stumpf"], "title": "\"I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment", "comment": null, "summary": "Assessing fairness in artificial intelligence (AI) typically involves AI\nexperts who select protected features, fairness metrics, and set fairness\nthresholds. However, little is known about how stakeholders, particularly those\naffected by AI outcomes but lacking AI expertise, assess fairness. To address\nthis gap, we conducted a qualitative study with 30 stakeholders without AI\nexpertise, representing potential decision subjects in a credit rating\nscenario, to examine how they assess fairness when placed in the role of\ndeciding on features with priority, metrics, and thresholds. We reveal that\nstakeholders' fairness decisions are more complex than typical AI expert\npractices: they considered features far beyond legally protected features,\ntailored metrics for specific contexts, set diverse yet stricter fairness\nthresholds, and even preferred designing customized fairness. Our results\nextend the understanding of how stakeholders can meaningfully contribute to AI\nfairness governance and mitigation, underscoring the importance of\nincorporating stakeholders' nuanced fairness judgments.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc730\u540d\u975eAI\u4e13\u5bb6\u7684\u5229\u76ca\u76f8\u5173\u8005\u5728\u4fe1\u7528\u8bc4\u7ea7\u573a\u666f\u4e2d\u7684\u516c\u5e73\u6027\u8bc4\u4f30\uff0c\u53d1\u73b0\u4ed6\u4eec\u7684\u516c\u5e73\u51b3\u7b56\u6bd4AI\u4e13\u5bb6\u66f4\u590d\u6742\uff0c\u8003\u8651\u4e86\u66f4\u591a\u7279\u5f81\u3001\u5b9a\u5236\u5316\u6307\u6807\u548c\u66f4\u4e25\u683c\u7684\u9608\u503c", "motivation": "\u73b0\u6709AI\u516c\u5e73\u6027\u8bc4\u4f30\u4e3b\u8981\u7531AI\u4e13\u5bb6\u4e3b\u5bfc\uff0c\u7f3a\u4e4f\u5bf9\u53d7AI\u51b3\u7b56\u5f71\u54cd\u4f46\u65e0AI\u4e13\u4e1a\u77e5\u8bc6\u7684\u5229\u76ca\u76f8\u5173\u8005\u5982\u4f55\u8bc4\u4f30\u516c\u5e73\u6027\u7684\u4e86\u89e3", "method": "\u5bf930\u540d\u65e0AI\u4e13\u4e1a\u77e5\u8bc6\u7684\u5229\u76ca\u76f8\u5173\u8005\u8fdb\u884c\u5b9a\u6027\u7814\u7a76\uff0c\u8ba9\u4ed6\u4eec\u5728\u4fe1\u7528\u8bc4\u7ea7\u573a\u666f\u4e2d\u51b3\u5b9a\u4f18\u5148\u7279\u5f81\u3001\u6307\u6807\u548c\u9608\u503c", "result": "\u5229\u76ca\u76f8\u5173\u8005\u7684\u516c\u5e73\u51b3\u7b56\u6bd4AI\u4e13\u5bb6\u66f4\u590d\u6742\uff1a\u8003\u8651\u8d85\u51fa\u6cd5\u5f8b\u4fdd\u62a4\u7279\u5f81\u7684\u7279\u5f81\u3001\u4e3a\u7279\u5b9a\u60c5\u5883\u5b9a\u5236\u6307\u6807\u3001\u8bbe\u7f6e\u591a\u6837\u5316\u4e14\u66f4\u4e25\u683c\u7684\u516c\u5e73\u9608\u503c\uff0c\u751a\u81f3\u504f\u597d\u8bbe\u8ba1\u5b9a\u5236\u5316\u516c\u5e73\u6027", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6269\u5c55\u4e86\u5bf9\u5229\u76ca\u76f8\u5173\u8005\u5982\u4f55\u6709\u610f\u4e49\u5730\u53c2\u4e0eAI\u516c\u5e73\u6cbb\u7406\u548c\u7f13\u89e3\u7684\u7406\u89e3\uff0c\u5f3a\u8c03\u4e86\u7eb3\u5165\u5229\u76ca\u76f8\u5173\u8005\u7ec6\u81f4\u516c\u5e73\u5224\u65ad\u7684\u91cd\u8981\u6027"}}
{"id": "2509.17978", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.17978", "abs": "https://arxiv.org/abs/2509.17978", "authors": ["Antoni Guasch", "Maria Isabel Valdez"], "title": "The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents", "comment": "Paper 1 of 4 in The STAR-XAI Protocol series. Paper 2\n  [arXiv:ID_to_be_added], Paper 3 [arXiv:ID_to_be_added], Paper 4\n  [arXiv:ID_to_be_added]", "summary": "Current Large Reasoning Models (LRMs) exhibit significant limitations in\nreliability and transparency, often showing a collapse in reasoning\ncapabilities when faced with high-complexity, long-horizon tasks. This\n\"illusion of thinking\" is frequently an artifact of non-agentic, black-box\nevaluation paradigms that fail to cultivate robust problem-solving processes.\nIn response, we introduce The STAR-XAI Protocol (Socratic, Transparent,\nAgentic, Reasoning - for eXplainable Artificial Intelligence), a novel\nmethodology for training and operating verifiably reliable AI agents. Our\nmethod reframes the human-AI interaction as a structured, Socratic dialogue,\ngoverned by an explicit and evolving rulebook, the Consciousness Transfer\nPackage (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc\nstrategic justification and a state-locking Checksum that prevents error\naccumulation, the protocol transforms a powerful but opaque LRM into a\ndisciplined \"Clear Box\" agent. We demonstrate the efficacy of this method\nthrough an exhaustive 25-move case study in the complex strategic game \"Caps i\nCaps\". The agent not only solved the high-complexity puzzle but also\ndemonstrated Second-Order Agency, identifying flaws in its own\nsupervisor-approved plans and adapting its core integrity protocols mid-task.\nThe STAR-XAI Protocol offers a practical pathway to creating AI agents that are\nnot just high-performing, but also transparent, auditable, and trustworthy by\ndesign.", "AI": {"tldr": "STAR-XAI\u534f\u8bae\u662f\u4e00\u79cd\u8bad\u7ec3\u548c\u64cd\u4f5c\u53ef\u9a8c\u8bc1\u53ef\u9760AI\u4ee3\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u82cf\u683c\u62c9\u5e95\u5bf9\u8bdd\u548c\u610f\u8bc6\u8f6c\u79fb\u5305\uff0c\u5c06\u4e0d\u900f\u660e\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u8f6c\u53d8\u4e3a\u900f\u660e\u7684\"\u6e05\u6670\u76d2\u5b50\"\u4ee3\u7406\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u957f\u7a0b\u4efb\u52a1\u4e2d\u5b58\u5728\u53ef\u9760\u6027\u548c\u900f\u660e\u5ea6\u9650\u5236\uff0c\u7ecf\u5e38\u51fa\u73b0\"\u601d\u7ef4\u5e7b\u89c9\"\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u9a8c\u8bc1\u7684\u53ef\u9760AI\u4ee3\u7406\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u82cf\u683c\u62c9\u5e95\u5bf9\u8bdd\u3001\u610f\u8bc6\u8f6c\u79fb\u5305\u89c4\u5219\u4e66\u3001\u6e38\u620f\u5faa\u73af\u5f3a\u5236\u4e8b\u524d\u6218\u7565\u8bba\u8bc1\uff0c\u4ee5\u53ca\u72b6\u6001\u9501\u5b9a\u6821\u9a8c\u548c\u9632\u6b62\u9519\u8bef\u7d2f\u79ef\u3002", "result": "\u5728\u590d\u6742\u7b56\u7565\u6e38\u620f\"Caps i Caps\"\u768425\u6b65\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4ee3\u7406\u4e0d\u4ec5\u89e3\u51b3\u4e86\u9ad8\u590d\u6742\u5ea6\u96be\u9898\uff0c\u8fd8\u5c55\u793a\u4e86\u4e8c\u9636\u4ee3\u7406\u80fd\u529b\uff0c\u80fd\u591f\u8bc6\u522b\u81ea\u8eab\u8ba1\u5212\u7f3a\u9677\u5e76\u8c03\u6574\u6838\u5fc3\u5b8c\u6574\u6027\u534f\u8bae\u3002", "conclusion": "STAR-XAI\u534f\u8bae\u4e3a\u521b\u5efa\u4e0d\u4ec5\u9ad8\u6027\u80fd\u800c\u4e14\u900f\u660e\u3001\u53ef\u5ba1\u8ba1\u3001\u53ef\u4fe1\u8d56\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2509.18076", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18076", "abs": "https://arxiv.org/abs/2509.18076", "authors": ["Hy Dang", "Tianyi Liu", "Zhuofeng Wu", "Jingfeng Yang", "Haoming Jiang", "Tao Yang", "Pei Chen", "Zhengyang Wang", "Helen Wang", "Huasheng Li", "Bing Yin", "Meng Jiang"], "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Large language models (LLMs) have demonstrated strong reasoning and tool-use\ncapabilities, yet they often fail in real-world tool-interactions due to\nincorrect parameterization, poor tool selection, or misinterpretation of user\nintent. These issues often stem from an incomplete understanding of user goals\nand inadequate comprehension of tool documentation. While Chain-of-Thought\n(CoT) prompting has proven effective for enhancing reasoning in general\ncontexts, our analysis reveals that free-form CoT is insufficient and sometimes\ncounterproductive for structured function-calling tasks. To address this, we\nintroduce a curriculum-inspired framework that leverages structured reasoning\ntemplates to guide LLMs through more deliberate step-by-step instructions for\ngenerating function callings. Experimental results show that our method reduces\ntool-use errors, achieving 3-12% relative improvements over strong baselines\nacross diverse model series and approaches. Moreover, our framework enhances\nthe robustness, interpretability, and transparency of tool-using agents,\nadvancing the development of more reliable AI assistants for real-world\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u7406\u5ff5\u7684\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u677f\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u76f8\u6bd4\u81ea\u7531\u5f62\u5f0f\u7684\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u5de5\u5177\u4f7f\u7528\u9519\u8bef\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u5de5\u5177\u4ea4\u4e92\u4e2d\u7ecf\u5e38\u5931\u8d25\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u53c2\u6570\u5316\u9519\u8bef\u3001\u5de5\u5177\u9009\u62e9\u4e0d\u5f53\u6216\u7528\u6237\u610f\u56fe\u8bef\u89e3\uff0c\u8fd9\u4e9b\u95ee\u9898\u6e90\u4e8e\u5bf9\u7528\u6237\u76ee\u6807\u7406\u89e3\u4e0d\u5b8c\u6574\u548c\u5de5\u5177\u6587\u6863\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u8bfe\u7a0b\u5b66\u4e60\u542f\u53d1\u7684\u6846\u67b6\uff0c\u5229\u7528\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u677f\u6765\u5f15\u5bfcLLM\u901a\u8fc7\u66f4\u8c28\u614e\u7684\u9010\u6b65\u6307\u4ee4\u751f\u6210\u51fd\u6570\u8c03\u7528\uff0c\u53d6\u4ee3\u81ea\u7531\u5f62\u5f0f\u7684\u601d\u7ef4\u94fe\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u5de5\u5177\u4f7f\u7528\u9519\u8bef\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u7cfb\u5217\u548c\u65b9\u6cd5\u4e0a\u5b9e\u73b0\u4e863-12%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\uff0c\u63a8\u52a8\u4e86\u66f4\u53ef\u9760\u7684\u73b0\u5b9e\u4e16\u754cAI\u52a9\u624b\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.18083", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18083", "abs": "https://arxiv.org/abs/2509.18083", "authors": ["Valentin Lacombe", "Valentin Quesnel", "Damien Sileo"], "title": "Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning", "comment": null, "summary": "We introduce Reasoning Core, a new scalable environment for Reinforcement\nLearning with Verifiable Rewards (RLVR), designed to advance foundational\nsymbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks\nthat focus on games or isolated puzzles, Reasoning Core procedurally generates\nproblems across core formal domains, including PDDL planning, first-order\nlogic, context-free grammar parsing, causal reasoning, and system equation\nsolving. The environment is built on key design principles of high-generality\nproblem distributions, verification via external tools, and continuous\ndifficulty control, which together provide a virtually infinite supply of novel\ntraining instances. Initial zero-shot evaluations with frontier LLMs confirm\nthe difficulty of Reasoning Core's tasks, positioning it as a promising\nresource to improve the reasoning capabilities of future models.", "AI": {"tldr": "Reasoning Core\u662f\u4e00\u4e2a\u65b0\u7684\u53ef\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u4e13\u6ce8\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\uff0c\u65e8\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7840\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6e38\u620f\u6216\u5b64\u7acb\u8c1c\u9898\uff0c\u7f3a\u4e4f\u5bf9\u6838\u5fc3\u5f62\u5f0f\u5316\u9886\u57df\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u9a8c\u8bc1\u63a8\u7406\u95ee\u9898\u7684\u73af\u5883\u6765\u63a8\u52a8LLM\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\u3002", "method": "\u57fa\u4e8e\u9ad8\u901a\u7528\u6027\u95ee\u9898\u5206\u5e03\u3001\u5916\u90e8\u5de5\u5177\u9a8c\u8bc1\u548c\u8fde\u7eed\u96be\u5ea6\u63a7\u5236\u4e09\u5927\u8bbe\u8ba1\u539f\u5219\uff0c\u5728PDDL\u89c4\u5212\u3001\u4e00\u9636\u903b\u8f91\u3001\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u89e3\u6790\u3001\u56e0\u679c\u63a8\u7406\u548c\u7cfb\u7edf\u65b9\u7a0b\u6c42\u89e3\u7b49\u6838\u5fc3\u5f62\u5f0f\u5316\u9886\u57df\u7a0b\u5e8f\u5316\u751f\u6210\u95ee\u9898\u3002", "result": "\u521d\u6b65\u96f6\u6837\u672c\u8bc4\u4f30\u663e\u793a\u524d\u6cbfLLM\u5728Reasoning Core\u4efb\u52a1\u4e0a\u8868\u73b0\u56f0\u96be\uff0c\u9a8c\u8bc1\u4e86\u8be5\u73af\u5883\u7684\u6311\u6218\u6027\u3002", "conclusion": "Reasoning Core\u4f5c\u4e3a\u4e00\u4e2a\u5177\u6709\u65e0\u9650\u8bad\u7ec3\u5b9e\u4f8b\u4f9b\u7ed9\u7684\u73af\u5883\uff0c\u6709\u671b\u6210\u4e3a\u63d0\u5347\u672a\u6765\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u91cd\u8981\u8d44\u6e90\u3002"}}
