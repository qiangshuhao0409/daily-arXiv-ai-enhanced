<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 19]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Agent Network Protocol Technical White Paper](https://arxiv.org/abs/2508.00007)
*Gaowei Chang,Eidan Lin,Chengxuan Yuan,Rizhao Cai,Binbin Chen,Xuan Xie,Yin Zhang*

Main category: cs.NI

TL;DR: ANP提出了一种面向Agentic Web的新一代通信协议，支持大规模智能体互联与协作。


<details>
  <summary>Details</summary>
Motivation: 现有互联网基础设施主要为人类交互设计，难以满足智能体大规模互联与协作的需求。

Method: ANP采用AI原生设计，兼容现有协议，模块化架构，通过三层协议系统解决身份认证、动态协商和能力发现等问题。

Result: ANP系统性地解决了智能体身份认证、动态协商和能力互操作性等问题。

Conclusion: ANP为智能体互联网提供了高效、兼容且可扩展的通信协议，支持未来智能体协作趋势。

Abstract: With the development of large models and autonomous decision-making AI,
agents are rapidly becoming the new entities of the internet, following mobile
apps. However, existing internet infrastructure is primarily designed for human
interaction, creating data silos, unfriendly interfaces, and high collaboration
costs among agents, making it difficult to support the needs for large-scale
agent interconnection and collaboration. The internet is undergoing a profound
transformation, showing four core trends: agents replacing traditional
software, universal agent interconnection, native protocol-based connections,
and autonomous agent organization and collaboration. To align with these
trends, Agent Network Protocol (ANP) proposes a new generation of communication
protocols for the Agentic Web. ANP adheres to AI-native design, maintains
compatibility with existing internet protocols, adopts a modular composable
architecture, follows minimalist yet extensible principles, and enables rapid
deployment based on existing infrastructure. Through a three-layer protocol
system--identity and encrypted communication layer, meta-protocol negotiation
layer, and application protocol layer--ANP. systematically solves the problems
of agent identity authentication, dynamic negotiation, and capability discovery
interoperability.

</details>


### [2] [Enabling Immersive XR Collaborations over FTTR Networks (Invited)](https://arxiv.org/abs/2508.00009)
*Sourav Mondal,Elaine Wong*

Main category: cs.NI

TL;DR: 本文探讨了FTTR（光纤到房间）在实现室内扩展现实协作中的潜力，提出了预测带宽分配和无缝切换方案，以实现高质量的沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 研究FTTR作为室内扩展现实协作的潜在解决方案，以提升用户体验。

Method: 提出预测带宽分配和无缝切换方案。

Result: 展示了通过FTTR可以实现高质量的沉浸式协作体验。

Conclusion: FTTR结合预测带宽分配和无缝切换方案，是提升室内扩展现实协作体验的有效方法。

Abstract: Fiber-To-The-Room is a potential solution to achieve in-premise extended
reality collaborations. This paper explores predictive bandwidth allocation and
seamless handover schemes over FTTR, showing high-quality immersive experience
for in-premise collaborations can be achieved. \c{opyright} 2025 The Author(s).

</details>


### [3] [AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks](https://arxiv.org/abs/2508.00011)
*Ahmet Melih Ince,Ayse Elif Canbilen,Halim Yanikomeroglu*

Main category: cs.NI

TL;DR: 本文提出了一种基于深度确定性策略梯度（DDPG）的强化学习方法，用于优化HAPS支持的V2X网络中的信息新鲜度（AoI），提升网络可靠性。


<details>
  <summary>Details</summary>
Motivation: 6G网络需满足高可靠低延迟通信（HRLLC）需求，尤其是在安全关键应用中（如自动驾驶）。非地面网络（NTN）和高空平台站（HAPS）的引入可增强网络冗余和覆盖，但需动态优化资源分配。

Method: 采用DDPG算法，通过独立学习动态优化HAPS支持的V2X网络中的AoI，无需集中协调。

Result: 该方法显著提升了信息新鲜度和网络可靠性，适用于基于车队的自动驾驶系统。

Conclusion: HAPS与DDPG结合的资源分配方案在6G网络中具有潜力，尤其适用于基础设施受限区域。

Abstract: Sixth-generation (6G) networks are designed to meet the hyper-reliable and
low-latency communication (HRLLC) requirements of safety-critical applications
such as autonomous driving. Integrating non-terrestrial networks (NTN) into the
6G infrastructure brings redundancy to the network, ensuring continuity of
communications even under extreme conditions. In particular, high-altitude
platform stations (HAPS) stand out for their wide coverage and low latency
advantages, supporting communication reliability and enhancing information
freshness, especially in rural areas and regions with infrastructure
constraints. In this paper, we present reinforcement learning-based approaches
using deep deterministic policy gradient (DDPG) to dynamically optimize the
age-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks.
The proposed method improves information freshness and overall network
reliability by enabling independent learning without centralized coordination.
The findings reveal the potential of HAPS-supported solutions, combined with
DDPG-based learning, for efficient AoI-aware resource allocation in
platoon-based autonomous vehicle systems.

</details>


### [4] [Non-Terrestrial Network Models Using Stochastic Geometry: Planar or Spherical?](https://arxiv.org/abs/2508.00010)
*Ruibo Wang,Baha Eddine Youcef Belmekki,Howard H. Yang,Mohamed Slim Alouini*

Main category: cs.NI

TL;DR: 本文通过引入相对误差量化平面与球面模型的差距，提出了一种点过程生成算法和相对误差估计算法，并推导了最优平面高度的解析表达式，为NTN建模提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 随着非地面网络（NTN）的快速部署，网络性能分析的计算复杂度急剧上升。平面模型因忽略地球曲率在高空NTN分析中产生偏差，但仍因其简单性被广泛使用。本文旨在量化平面与球面模型的差距，帮助确定何时平面建模足够。

Method: 提出一种点过程（PP）生成算法，同时生成一对同质且渐近相似的平面和球面PP；引入多种相似性度量，包括拓扑和网络级度量，并开发基于这些度量的相对误差估计算法；推导最优平面高度的解析表达式。

Result: 数值结果研究了部署高度和区域对NTN建模的影响，并通过HAP和LEO卫星星座的案例研究验证了方法的有效性。

Conclusion: 本文为平面模型在NTN分析中的适用性提供了量化依据，并通过理论推导和数值验证支持了平面近似的合理性。

Abstract: With the explosive deployment of non-terrestrial networks (NTNs), the
computational complexity of network performance analysis is rapidly escalating.
As one of the most suitable mathematical tools for analyzing large-scale
network topologies, stochastic geometry (SG) enables the representation of
network performance metrics as functions of network parameters, thus offering
low-complexity performance analysis solutions. However, choosing between planar
and spherical models remains challenging. Planar models neglect Earth's
curvature, causing deviations in high-altitude NTN analysis, yet are still
often used for simplicity. This paper introduces relative error to quantify the
gap between planar and spherical models, helping determine when planar modeling
is sufficient. To calculate the relative error, we first propose a point
process (PP) generation algorithm that simultaneously generates a pair of
homogeneous and asymptotically similar planar and spherical PPs. We then
introduce several typical similarity metrics, including topology-related and
network-level metrics, and further develop a relative error estimation
algorithm based on these metrics. In addition, we derive an analytical
expression for the optimal planar altitude, which reduces computational
complexity and provides theoretical support for planar approximation. Finally,
numerical results investigate how deployment altitude and region affect NTN
modeling, with case studies on HAP and LEO satellite constellations.

</details>


### [5] [Performance Analysis of SAGIN from the Relay Perspective: A Spherical Stochastic Geometry Approach](https://arxiv.org/abs/2508.00020)
*Ferdaous Tarhouni,Ruibo Wang,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 论文评估了高空平台（HAPs）在卫星-空中-地面综合网络（SAGIN）中的中继性能，提出了三个性能指标，并利用球形随机几何（SSG）进行低复杂度分析。


<details>
  <summary>Details</summary>
Motivation: 满足全球无线通信需求，研究HAPs在SAGIN中的中继作用。

Method: 采用球形随机几何（SSG）工具，提出三个性能指标（平均接入数据率、平均回程数据率、回程率超越概率），并推导其解析表达式。

Result: 提供了端到端性能指标BREP的闭式解，分析了卫星网络拓扑对性能的影响，并确定了HAPs的最小传输功率需求。

Conclusion: SSG框架在SAGIN中具有优势，HAPs的中继作用显著，研究为动态拓扑和干扰分析提供了新视角。

Abstract: In recent years, the satellite-aerial-ground integrated network (SAGIN) has
become essential in meeting the increasing demands for global wireless
communications. In SAGIN, high-altitude platforms (HAPs) can serve as
communication hubs and act as relays to enhance communication performance. In
this paper, we evaluate network performance and analyze the role of HAPs in
SAGIN from the relay perspective. Based on this unique perspective, we
introduce three metrics to evaluate the performance, named the average access
data rate, the average backhaul data rate, and the backhaul rate exceedance
probability (BREP). Considering the need for dynamic topology and interference
analysis, we choose spherical stochastic geometry (SSG) as a tool and derive
analytical expressions for the above metrics to achieve low-complexity
performance evaluation. Specifically, we provide a closed-form expression for
the end-to-end performance metric BREP. Given that there is no existing
literature in the SSG field studying networks from a relay perspective, we
specifically investigate the impact of satellite network topology on
performance in our numerical results to further highlight the advantages of the
SSG framework. Additionally, we analyze the minimum HAP transmission power
required to maintain both short-term and long-term data rate demands.

</details>


### [6] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
*Abir Ray*

Main category: cs.NI

TL;DR: 论文提出了一种结合马尔可夫链模型和ITU-R传播模型的可扩展框架，用于预测频谱可用性，以支持动态频谱接入。


<details>
  <summary>Details</summary>
Motivation: 频谱资源在时间和空间上常未被充分利用，需要动态频谱接入策略以允许次级用户利用空闲频率。

Method: 结合两状态马尔可夫链模型（捕捉时间占用模式）和ITU-R传播模型（考虑路径损耗和杂波效应），预测频谱可用性。

Result: 该方法能高效识别可用频谱，计算成本低，适用于实时频谱管理。

Conclusion: 框架灵活，可适应不同频段和场景，为认知无线电网络等动态频谱共享系统提供有效支持。

Abstract: Spectrum resources are often underutilized across time and space, motivating
dynamic spectrum access strategies that allow secondary users to exploit unused
frequencies. A key challenge is predicting when and where spectrum will be
available (i.e., unused by primary licensed users) in order to enable proactive
and interference-free access. This paper proposes a scalable framework for
spectrum availability prediction that combines a two-state Markov chain model
of primary user activity with high-fidelity propagation models from the ITU-R
(specifically Recommendations P.528 and P.2108). The Markov chain captures
temporal occupancy patterns, while the propagation models incorporate path loss
and clutter effects to determine if primary signals exceed interference
thresholds at secondary user locations. By integrating these components, the
proposed method can predict spectrum opportunities both in time and space with
improved accuracy. We develop the system model and algorithm for the approach,
analyze its scalability and computational efficiency, and discuss assumptions,
limitations, and potential applications. The framework is flexible and can be
adapted to various frequency bands and scenarios. The results and analysis show
that the proposed approach can effectively identify available spectrum with low
computational cost, making it suitable for real-time spectrum management in
cognitive radio networks and other dynamic spectrum sharing systems.

</details>


### [7] [Towards Reliable AI in 6G: Detecting Concept Drift in Wireless Network](https://arxiv.org/abs/2508.00042)
*Athanasios Tziouvaras,Carolina Fortuna,George Floros,Kostas Kolomvatsos,Panagiotis Sarigiannidis,Marko Grobelnik,Blaž Bertalanič*

Main category: cs.NI

TL;DR: 论文提出两种无监督、模型无关的批量概念漂移检测方法，用于AI原生6G网络中模型性能的维护，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 无线环境的非静态特性导致概念漂移，影响AI模型性能，现有方法难以通用或高效应对。

Method: 引入两种基于期望效用分数的无监督概念漂移检测方法，无需部署后的真实标签即可判断是否需要重新训练模型。

Result: 在定位和链路异常检测的实际用例中，新方法比传统检测器（如ADWIN、DDM、CUSUM）性能提升20-40个百分点，F1分数达0.94和1.00。

Conclusion: 新方法显著减少误报率，提升概念漂移检测效率，适用于动态无线环境中的模型维护。

Abstract: AI-native 6G networks promise unprecedented automation and performance by
embedding machine-learning models throughout the radio access and core segments
of the network. However, the non-stationary nature of wireless environments due
to infrastructure changes, user mobility, and emerging traffic patterns,
induces concept drifts that can quickly degrade these model accuracies.
Existing methods in general are very domain specific, or struggle with certain
type of concept drift. In this paper, we introduce two unsupervised,
model-agnostic, batch concept drift detectors. Both methods compute an
expected-utility score to decide when concept drift occurred and if model
retraining is warranted, without requiring ground-truth labels after
deployment. We validate our framework on two real-world wireless use cases in
outdoor fingerprinting for localization and for link-anomaly detection, and
demonstrate that both methods are outperforming classical detectors such as
ADWIN, DDM, CUSUM by 20-40 percentage points. Additionally, they achieve an
F1-score of 0.94 and 1.00 in correctly triggering retraining alarm, thus
reducing the false alarm rate by up to 20 percentage points compared to the
best classical detectors.

</details>


### [8] [Benchmarking XRootD-HTTPS on 400Gbps Links with Variable Latencies](https://arxiv.org/abs/2508.00228)
*Aashay Arora,Diego Davila,Frank Würthwein,John Graham,Dima Mishin,Justas Balcas,Tom Lehman,Xi Yang,Chin Guok,Harvey Newman*

Main category: cs.NI

TL;DR: 本文探讨了为应对高亮度LHC时代的需求，US-CMS Tier-2站点在软件和硬件上的改进，以满足400 Gbps带宽需求并解决站点间延迟问题。


<details>
  <summary>Details</summary>
Motivation: 高亮度LHC时代将带来网络流量的显著增长，需要确保软件和硬件能够支持生产和用户数据分析的带宽需求。

Method: 通过系统测试XRootD HTTP第三方复制的性能，模拟真实网络条件，包括多交换机网络环路，并调整源集群数量和CPU分配。

Result: 研究分析了不同配置下的性能表现，为满足400 Gbps带宽需求提供了优化方案。

Conclusion: 通过优化软件和硬件配置，US-CMS Tier-2站点能够应对高亮度LHC时代的网络挑战。

Abstract: In anticipation of the High Luminosity-LHC era, there is a critical need to
oversee software readiness for upcoming growth in network traffic for
production and user data analysis access. This paper looks into software and
hardware required improvements in US-CMS Tier-2 sites to be able to sustain and
meet the projected 400 Gbps bandwidth demands while tackling the challenge
posed by varying latencies between sites. Specifically, our study focuses on
identifying the performance of XRootD HTTP third-party copies across multiple
400 Gbps links and exploring different host and transfer configurations. Our
approach involves systematic testing with variations in the number of origins
per cluster and CPU allocations for each origin. By replicating real network
conditions and creating network "loops" that traverse multiple switches across
the wide area network, we are able to replicate authentic network conditions

</details>


### [9] [Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts](https://arxiv.org/abs/2508.00234)
*Jin Yang,Qiong Wu,Zhiying Feng,Zhi Zhou,Deke Guo,Xu Chen*

Main category: cs.NI

TL;DR: 论文提出了一种基于深度强化学习的QoS感知LLM路由框架，以解决边缘部署中LLM服务的动态负载和异构性问题，显著提升了服务质量和资源效率。


<details>
  <summary>Details</summary>
Motivation: 云LLM服务存在高延迟、不稳定性和隐私问题，边缘部署多LLM可提升实时性和隐私保护，但需解决路由问题以确保QoS。

Method: 采用深度强化学习（DRL）框架，结合动态状态抽象技术和异构图注意力网络（HAN），并引入动作影响估计器和定制奖励函数。

Result: 实验表明，该算法在Poisson和真实工作负载下显著提升了平均QoS和计算资源效率。

Conclusion: 提出的DRL框架有效解决了LLM路由的动态和异构性问题，为边缘LLM服务提供了可持续的高QoS保障。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
leading to a significant increase in user demand for LLM services. However,
cloud-based LLM services often suffer from high latency, unstable
responsiveness, and privacy concerns. Therefore, multiple LLMs are usually
deployed at the network edge to boost real-time responsiveness and protect data
privacy, particularly for many emerging smart mobile and IoT applications.
Given the varying response quality and latency of LLM services, a critical
issue is how to route user requests from mobile and IoT devices to an
appropriate LLM service (i.e., edge LLM expert) to ensure acceptable
quality-of-service (QoS). Existing routing algorithms fail to simultaneously
address the heterogeneity of LLM services, the interference among requests, and
the dynamic workloads necessary for maintaining long-term stable QoS. To meet
these challenges, in this paper we propose a novel deep reinforcement learning
(DRL)-based QoS-aware LLM routing framework for sustained high-quality LLM
services. Due to the dynamic nature of the global state, we propose a dynamic
state abstraction technique to compactly represent global state features with a
heterogeneous graph attention network (HAN). Additionally, we introduce an
action impact estimator and a tailored reward function to guide the DRL agent
in maximizing QoS and preventing latency violations. Extensive experiments on
both Poisson and real-world workloads demonstrate that our proposed algorithm
significantly improves average QoS and computing resource efficiency compared
to existing baselines.

</details>


### [10] [Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study](https://arxiv.org/abs/2508.00256)
*Chuang Zhang,Geng Sun,Jiacheng Wang,Yijing Lin,Weijie Yuan,Sinem Coleri,Dusit Niyato,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 本文探讨了低空无线网络（LAWNs）的安全挑战，并提出了一种基于大型人工智能模型（LAMs）的优化框架，以提升安全通信性能。


<details>
  <summary>Details</summary>
Motivation: LAWNs因其低空操作、频繁移动和依赖非授权频谱等特点，面临独特的安全挑战，传统AI方法存在局限性。

Method: 提出了一种基于LAMs的优化框架，利用大型语言模型（LLMs）生成增强状态特征并设计内在奖励，以改进强化学习性能。

Result: 通过案例研究验证了该框架的有效性。

Conclusion: LAMs在LAWNs安全通信中具有潜力，未来可进一步探索其应用。

Abstract: Low-altitude wireless networks (LAWNs) have the potential to revolutionize
communications by supporting a range of applications, including urban parcel
delivery, aerial inspections and air taxis. However, compared with traditional
wireless networks, LAWNs face unique security challenges due to low-altitude
operations, frequent mobility and reliance on unlicensed spectrum, making it
more vulnerable to some malicious attacks. In this paper, we investigate some
large artificial intelligence model (LAM)-enabled solutions for secure
communications in LAWNs. Specifically, we first explore the amplified security
risks and important limitations of traditional AI methods in LAWNs. Then, we
introduce the basic concepts of LAMs and delve into the role of LAMs in
addressing these challenges. To demonstrate the practical benefits of LAMs for
secure communications in LAWNs, we propose a novel LAM-based optimization
framework that leverages large language models (LLMs) to generate enhanced
state features on top of handcrafted representations, and to design intrinsic
rewards accordingly, thereby improving reinforcement learning performance for
secure communication tasks. Through a typical case study, simulation results
validate the effectiveness of the proposed framework. Finally, we outline
future directions for integrating LAMs into secure LAWN applications.

</details>


### [11] [Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning](https://arxiv.org/abs/2508.00261)
*Saichao Liu,Geng Sun,Chuang Zhang,Xuejie Liu,Jiacheng Wang,Changyuan Zhao,Dusit Niyato*

Main category: cs.NI

TL;DR: 论文研究了无人机辅助移动边缘计算（MEC）系统，通过优化无人机轨迹和资源分配，提出了一种增强的深度强化学习算法（DPPOIL），以提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）的性能受限于固定位置和服务范围，无人机辅助MEC系统可以扩展服务范围和提升计算能力。

Method: 提出多目标优化问题（TCRAMOP），优化无人机轨迹和资源分配，并设计增强的深度强化学习算法DPPOIL。

Result: 仿真结果表明DPPOIL优于基线方法，能有效提升系统性能。

Conclusion: 无人机辅助MEC系统结合DPPOIL算法能显著提高计算服务效率，减少延迟和能耗。

Abstract: Mobile edge computing (MEC) is a promising technique to improve the
computational capacity of smart devices (SDs) in Internet of Things (IoT).
However, the performance of MEC is restricted due to its fixed location and
limited service scope. Hence, we investigate an unmanned aerial vehicle
(UAV)-assisted MEC system, where multiple UAVs are dispatched and each UAV can
simultaneously provide computing service for multiple SDs. To improve the
performance of system, we formulated a UAV-based trajectory control and
resource allocation multi-objective optimization problem (TCRAMOP) to
simultaneously maximize the offloading number of UAVs and minimize total
offloading delay and total energy consumption of UAVs by optimizing the flight
paths of UAVs as well as the computing resource allocated to served SDs. Then,
consider that the solution of TCRAMOP requires continuous decision-making and
the system is dynamic, we propose an enhanced deep reinforcement learning (DRL)
algorithm, namely, distributed proximal policy optimization with imitation
learning (DPPOIL). This algorithm incorporates the generative adversarial
imitation learning technique to improve the policy performance. Simulation
results demonstrate the effectiveness of our proposed DPPOIL and prove that the
learned strategy of DPPOIL is better compared with other baseline methods.

</details>


### [12] [Mamba for Wireless Communications and Networking: Principles and Opportunities](https://arxiv.org/abs/2508.00403)
*Rongsheng Zhang,Ruichen Zhang,Yang Lu,Wei Chen,Bo Ai,Dusit Niyato*

Main category: cs.NI

TL;DR: Mamba模型在无线通信中展现出潜力，通过平衡计算效率与效果，革新无线网络设计。文章综述了Mamba的应用，提出两种框架，并通过案例研究验证其性能提升。


<details>
  <summary>Details</summary>
Motivation: 无线网络的异构性和动态性日益增加，Mamba模型有望通过高效处理时空数据，优化无线通信和网络设计。

Method: 分析Mamba在无线信号处理中的潜力，提出两种应用框架（替代传统算法和启用新范式），并通过案例研究验证。

Result: Mamba在特征增强和计算效率方面均有显著改进，案例研究验证了其性能优势。

Conclusion: Mamba在无线通信中具有广阔前景，但仍需解决关键挑战，未来研究应关注其进一步应用。

Abstract: Mamba has emerged as a powerful model for efficiently addressing tasks
involving temporal and spatial data. Regarding the escalating heterogeneity and
dynamics in wireless networks, Mamba holds the potential to revolutionize
wireless communication and networking designs by balancing the trade-off
between computational efficiency and effectiveness. This article presents a
comprehensive overview of Mamba' applications in wireless systems.
Specifically, we first analyze the potentials of Mamba for wireless signal
processing tasks from the perspectives of long-range dependency modeling and
spatial feature extraction. Then we propose two application frameworks for
Mamba in wireless communications, i.e., replacement of traditional algorithms,
and enabler of novel paradigms. Guided by the two frameworks, we conduct case
studies on intelligent resource allocation and joint source and channel
decoding to demonstrate Mamba's improvements in both feature enhancement and
computational efficiency. Finally, we highlight critical challenges and outline
potential research directions for Mamba in wireless communications and
networking.

</details>


### [13] [Enhancing Wireless Networks for IoT with Large Vision Models: Foundations and Applications](https://arxiv.org/abs/2508.00583)
*Yunting Xu,Jiacheng Wang,Ruichen Zhang,Dusit Niyato,Deepu Rajan,Liang Yu,Haibo Zhou,Abbas Jamalipour,Xianbin Wang*

Main category: cs.NI

TL;DR: 本文探讨了大型视觉模型（LVMs）在视觉智能中的基础作用及其在物联网（IoT）中的应用，提出了一种渐进式微调框架，并在无人机网络中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究LVMs的功能和架构，探索其在无线通信中的应用，并解决模型体积大和重训练困难的问题。

Method: 提出渐进式微调框架，逐步调整预训练的LVMs以适应多任务优化。

Result: 在低空经济网络（LAENets）中，该框架在联合波束成形和定位任务中优于传统CNN。

Conclusion: LVMs在智能无线系统中具有广阔的应用前景。

Abstract: Large vision models (LVMs) have emerged as a foundational paradigm in visual
intelligence, achieving state-of-the-art performance across diverse visual
tasks. Recent advances in LVMs have facilitated their integration into Internet
of Things (IoT) scenarios, offering superior generalization and adaptability
for vision-assisted network optimization. In this paper, we first investigate
the functionalities and core architectures of LVMs, highlighting their
capabilities across classification, segmentation, generation, and multimodal
visual processing. We then explore a variety of LVM applications in wireless
communications, covering representative tasks across the physical layer,
network layer, and application layer. Furthermore, given the substantial model
size of LVMs and the challenges of model retraining in wireless domains, we
propose a progressive fine-tuning framework that incrementally adapts
pretrained LVMs for joint optimization of multiple IoT tasks. A case study in
low-altitude economy networks (LAENets) demonstrates the effectiveness of the
proposed framework over conventional CNNs in joint beamforming and positioning
tasks for Internet of drones, underscoring a promising direction for
integrating LVMs into intelligent wireless systems.

</details>


### [14] [Joint Association and Phase Shifts Design for UAV-mounted Stacked Intelligent Metasurfaces-assisted Communications](https://arxiv.org/abs/2508.00616)
*Mingzhe Fan,Geng Sun,Hongyang Pan,Jiacheng Wang,Jiancheng An,Hongyang Du,Chau Yuen*

Main category: cs.NI

TL;DR: 论文提出了一种基于无人机搭载智能超表面（UAV-SIMs）的通信系统，通过联合优化用户关联、无人机位置和超表面相位，最大化网络容量。


<details>
  <summary>Details</summary>
Motivation: 固定位置的智能超表面（SIMs）限制了通信性能，而移动SIMs（如无人机搭载的SIMs）可以灵活部署，提升性能。

Method: 将联合优化问题分解为三个子问题（用户关联、无人机位置、相位优化），采用交替优化策略和CVX工具求解。

Result: 仿真结果表明，所提策略在不同场景下均能有效提升网络容量。

Conclusion: 无人机搭载的SIMs及其优化策略为提升通信系统性能提供了可行方案。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a promising
technology for realizing wave-domain signal processing, while the fixed SIMs
will limit the communication performance of the system compared to the mobile
SIMs. In this work, we consider a UAV-mounted SIMs (UAV-SIMs) assisted
communication system, where UAVs as base stations (BSs) can cache the data
processed by SIMs, and also as mobile vehicles flexibly deploy SIMs to enhance
the communication performance. To this end, we formulate a UAV-SIM-based joint
optimization problem (USBJOP) to comprehensively consider the association
between UAV-SIMs and users, the locations of UAV-SIMs, and the phase shifts of
UAV-SIMs, aiming to maximize the network capacity. Due to the non-convexity and
NP-hardness of USBJOP, we decompose it into three sub-optimization problems,
which are the association between UAV-SIMs and users optimization problem
(AUUOP), the UAV location optimization problem (ULOP), and the UAV-SIM phase
shifts optimization problem (USPSOP). Then, these three sub-optimization
problems are solved by an alternating optimization (AO) strategy. Specifically,
AUUOP and ULOP are transformed to a convex form and then solved by the CVX
tool, while we employ a layer-by-layer iterative optimization method for
USPSOP. Simulation results verify the effectiveness of the proposed strategy
under different simulation setups.

</details>


### [15] [Energy-Aware CPU Orchestration in O-RAN: A dApp-Driven Lightweight Approach](https://arxiv.org/abs/2508.00629)
*Francisco Crespo,Javier Villegas,Carlos Baena,Eduardo Baena,Sergio Fortes,Raquel Barco*

Main category: cs.NI

TL;DR: 论文提出了一种轻量级、可编程的分布式应用（dApp），用于在O-RAN架构下动态管理CPU资源，提升能效和利用率，无需修改内核或依赖专有硬件。


<details>
  <summary>Details</summary>
Motivation: 软化的RAN（如O-RAN）在灵活性和开放性方面具有优势，但传统操作系统调度器无法高效管理实时性强的RAN任务，导致性能下降和能耗增加。

Method: 设计了一个部署在分布式单元（DU）的dApp，通过线程级遥测数据（如上下文切换、IPC、缓存指标）实时调整CPU线程亲和性、核心隔离和频率缩放。

Result: 实验结果表明，该方案在商业级srsRAN部署中实现了显著的节能效果，同时不影响实时处理性能。

Conclusion: 该dApp为下一代网络中细粒度资源控制提供了潜在解决方案，且兼容O-RAN架构。

Abstract: The transition toward softwarized Radio Access Networks (RANs), driven by the
Open RAN (O-RAN) paradigm, enables flexible, vendor-neutral deployments through
disaggregation and virtualization of base station functions. However, this
shift introduces new challenges in managing CPU resources efficiently under
strict real-time constraints. In particular, the interplay between
latency-sensitive RAN workloads and general-purpose Operating System (OS)
schedulers often leads to sub-optimal performance and unnecessary energy
consumption. This work proposes a lightweight, programmable distributed
application (dApp) deployed at the Distributed Unit (DU) level to dynamically
orchestrate CPU usage. The dApp operates in closed loop with the OS, leveraging
thread-level telemetry like context switches, Instructions Per Cycle (IPC), and
cache metrics, to adapt CPU thread affinity, core isolation, and frequency
scaling in real time. Unlike existing solutions, it requires no access to
proprietary RAN software, hardware-specific features, or kernel modifications.
Fully compliant with the O-RAN architecture and agnostic to the underlying RAN
stack, the proposed solution introduces negligible overhead while improving
energy efficiency and CPU utilization. Experimental results using a
commercial-grade srsRAN deployment demonstrate consistent power savings without
compromising real-time processing performance, highlighting the potential of
low-latency dApps for fine-grained resource control in next-generation networks

</details>


### [16] [Criticality-Based Dynamic Topology Optimization for Enhancing Aerial-Marine Swarm Resilience](https://arxiv.org/abs/2508.00688)
*Ruiyang Huang,Haocheng Wang,Yixuan Shen,Ning Gao,Qiang Ni,Shi Jin,Yifan Wu*

Main category: cs.NI

TL;DR: 本文提出了一种两步框架，通过节点优先级排序和多目标拓扑优化，增强异构海空群网络的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 异构海空群网络在对抗环境中面临通信中断和结构脆弱性问题，需提升其韧性。

Method: 设计三层架构表示网络依赖关系，提出SurBi-Ranking方法动态评估节点和边的重要性，并利用NSGA-III算法优化拓扑。

Result: SurBi-Ranking比传统方法更准确识别关键节点和边，优化后网络在攻击下连接性下降减少30%，任务成功率更高。

Conclusion: 该框架显著提升了网络在对抗环境中的持续连接性和任务有效性。

Abstract: Heterogeneous marine-aerial swarm networks encounter substantial difficulties
due to targeted communication disruptions and structural weaknesses in
adversarial environments. This paper proposes a two-step framework to
strengthen the network's resilience. Specifically, our framework combines the
node prioritization based on criticality with multi-objective topology
optimization. First, we design a three-layer architecture to represent
structural, communication, and task dependencies of the swarm networks. Then,
we introduce the SurBi-Ranking method, which utilizes graph convolutional
networks, to dynamically evaluate and rank the criticality of nodes and edges
in real time. Next, we apply the NSGA-III algorithm to optimize the network
topology, aiming to balance communication efficiency, global connectivity, and
mission success rate. Experiments demonstrate that compared to traditional
methods like K-Shell, our SurBi-Ranking method identifies critical nodes and
edges with greater accuracy, as deliberate attacks on these components cause
more significant connectivity degradation. Furthermore, our optimization
approach, when prioritizing SurBi-Ranked critical components under attack,
reduces the natural connectivity degradation by around 30%, achieves higher
mission success rates, and incurs lower communication reconfiguration costs,
ensuring sustained connectivity and mission effectiveness across multi-phase
operations.

</details>


### [17] [Deep Joint Source-Channel Coding for Small Satellite Applications](https://arxiv.org/abs/2508.00715)
*Olga Kondrateva,Grace Li Zhang,Julian Zobel,Björn Scheuermann,Stefan Dietzel*

Main category: cs.NI

TL;DR: 论文提出了一种适用于卫星通信的自适应深度联合源信道编码（DJSCC）框架，通过注意力模块实现单一网络适应多种信道状态，显著减少存储需求并提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决小卫星在低地球轨道中因通信瓶颈和高维数据处理带来的挑战，探索DJSCC在复杂卫星环境中的实际应用。

Method: 提出DJSCC-SAT基础系统，结合多状态统计信道模型；进一步引入自适应架构ADJSCC-SAT，利用注意力模块实现单一网络适应多种信道状态。

Result: 在Sentinel-2多光谱数据上验证，自适应方法性能接近多专用网络，且存储需求显著降低，对信道估计误差更具鲁棒性。

Conclusion: 该框架为实际卫星任务中部署鲁棒、自适应的DJSCC系统提供了实用高效的解决方案。

Abstract: Small satellites used for Earth observation generate vast amounts of
high-dimensional data, but their operation in low Earth orbit creates a
significant communication bottleneck due to limited contact times and harsh,
varying channel conditions. While deep joint source-channel coding (DJSCC) has
emerged as a promising technique, its practical application to the complex
satellite environment remains an open question. This paper presents a
comprehensive DJSCC framework tailored for satellite communications. We first
establish a basic system, DJSCC-SAT, and integrate a realistic, multi-state
statistical channel model to guide its training and evaluation. To overcome the
impracticality of using separate models for every channel condition, we then
introduce an adaptable architecture, ADJSCC-SAT, which leverages attention
modules to allow a single neural network to adjust to a wide range of channel
states with minimal overhead. Through extensive evaluation on Sentinel-2
multi-spectral data, we demonstrate that our adaptable approach achieves
performance comparable to using multiple specialized networks while
significantly reducing model storage requirements. Furthermore, the adaptable
model shows enhanced robustness to channel estimation errors, outperforming the
non-adaptable baseline. The proposed framework is a practical and efficient
step toward deploying robust, adaptive DJSCC systems for real-world satellite
missions.

</details>


### [18] [Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE](https://arxiv.org/abs/2508.00735)
*Lucas Aubard,Johan Mazel,Gilles Guette,Pierre Chifflier*

Main category: cs.NI

TL;DR: 论文介绍了PYROLYSE工具，用于测试IP和TCP重组策略的多样性，并揭示了现有实现中的不一致性和漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决IP和TCP重组策略在不同实现中的不一致性，以及由此引发的安全漏洞，如NIDS绕过或DoS攻击。

Method: 方法包括开发PYROLYSE工具，全面测试IP和TCP实现的重组策略，并分析其多样性和错误。

Result: 结果显示重组策略比预期更复杂多样，发现8个错误，并证明双片段测试策略不适用于多片段场景。

Conclusion: 结论指出NIDS等工具应避免仅依赖双片段策略，需考虑多片段场景的一致性。

Abstract: IP fragmentation and TCP segmentation allow for splitting large data packets
into smaller ones, e.g., for transmission across network links of limited
capacity. These mechanisms permit complete or partial overlaps with different
data on the overlapping portions. IPv4, IPv6, and TCP reassembly policies,
i.e., the data chunk preferences that depend on the overlap types, differ
across protocol implementations. This leads to vulnerabilities, as NIDSes may
interpret the packet differently from the monitored host OSes. Some NIDSes,
such as Suricata or Snort, can be configured so that their policies are
consistent with the monitored OSes. The first contribution of the paper is
PYROLYSE, an audit tool that exhaustively tests and describes the reassembly
policies of various IP and TCP implementation types. This tool ensures that
implementations reassemble overlapping chunk sequences without errors. The
second contribution is the analysis of PYROLYSE artifacts. We first show that
the reassembly policies are much more diverse than previously thought. Indeed,
by testing all the overlap possibilities for n <= 3 test case chunks and
different testing scenarios, we observe from 14 to 20 different behaviors out
of 23 tested implementations depending on the protocol. Second, we report eight
errors impacting one OS, two NIDSes, and two embedded stacks, which can lead to
security issues such as NIDS pattern-matching bypass or DoS attacks. A CVE was
assigned to a NIDS error. Finally, we show that implemented IP and TCP policies
obtained through chunk pair testing are usually inconsistent with the observed
triplet reassemblies. Therefore, contrarily to what they currently do, NIDSes
or other network traffic analysis tools should not apply n = 2 pair policies
when the number of overlapping chunks exceeds two.

</details>


### [19] [Data Movement Manager (DMM) for the SENSE-Rucio Interoperation Prototype](https://arxiv.org/abs/2508.00792)
*Aashay Arora,Diego Davila,Jonathan Guiang,Frank Würthwein,Harvey Newman,Justas Balcas,Tom Lehman,Xi Yang*

Main category: cs.NI

TL;DR: DMM是一个原型接口，连接CERN的数据管理软件Rucio与SDN服务SENSE，优化高能物理数据传输的带宽分配和监控。


<details>
  <summary>Details</summary>
Motivation: 解决高能物理数据传输中的网络带宽分配和监控问题，提升现有基础设施的效率。

Method: 通过连接Rucio和SENSE，利用主机级和传输工具级指标实现优先级带宽分配和细粒度监控。

Result: DMM成功实现了基于优先级的带宽分配和端到端数据流监控。

Conclusion: DMM为高能物理数据传输提供了高效的网络资源管理和监控解决方案。

Abstract: The Data Movement Manager (DMM) is a prototype interface that connects CERN's
data management software, Rucio, with the Sofware-Defined Networking (SDN)
service SENSE by ESNet. It enables SDN-enabled high-energy physics data flows
using the existing worldwide LHC computing grid infrastructure. A key feature
of DMM is transfer priority-based bandwidth allocation, optimizing network
usage. Additionally, it provides fine-grained monitoring of underperforming
flows by leveraging end-to-end data flow monitoring. This is achieved through
access to host-level (network interface) throughput metrics and transfer-tool
(FTS) data transfer job-level metrics. This paper details the design and
implementation of DMM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [20] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench是一个用于评估AI医疗能力的基准，但依赖专家意见可能引入偏见。本文提出基于临床实践指南的改进方法，以提升全球适用性和公平性。


<details>
  <summary>Details</summary>
Motivation: HealthBench依赖专家意见而非高质量临床证据，可能引入区域偏见和个体差异，尤其在低收入地区问题更突出。

Method: 提出基于版本控制临床实践指南（CPGs）的奖励函数，结合系统评价和GRADE证据评级，改进评估方法。

Result: 通过证据加权评分和上下文覆盖逻辑，提升模型的临床可信度和全球适用性。

Conclusion: 改进后的方法旨在使医疗语言模型更可靠、伦理合规且全球适用。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [21] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一种基于HyperTWTL的安全强化学习方法（SecRL），通过动态Boltzmann softmax RL学习满足HyperTWTL约束的安全最优策略，并在机器人任务中验证了其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在探索基于超属性的安全强化学习（SecRL）方面存在显著空白，尤其是在机器人应用中。本文旨在填补这一空白。

Method: 将智能体的动态建模为马尔可夫决策过程（MDP），并将安全约束形式化为HyperTWTL，提出了一种动态Boltzmann softmax RL方法。

Result: 在机器人任务案例中验证了方法的有效性和可扩展性，并优于两种基线RL算法。

Conclusion: 提出的方法为安全强化学习提供了新的解决方案，尤其在机器人应用中表现优异。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [22] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 论文探讨了AI在工业环境中的应用挑战，提出通过对象中心过程挖掘（OCPM）将AI与过程数据结合，形成过程智能（PI），以提升端到端操作流程。


<details>
  <summary>Details</summary>
Motivation: 组织在工业环境中成功应用AI面临挑战，尤其是端到端操作流程的诊断与改进。

Method: 采用对象中心过程挖掘（OCPM）作为连接数据和过程的桥梁，结合生成式、预测式和规范性AI。

Result: OCPM是连接数据和过程的关键，过程智能（PI）能有效支持AI在组织环境中的应用。

Conclusion: AI需要PI的支持才能优化操作流程，OCPM与多种AI形式的结合为工业应用提供了新机会。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [23] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 本文提出了三种检测多准则决策分析中排名反转问题的测试方法，并在Scikit-Criteria库中实现，讨论了其通用场景下的设计考虑及其对方法评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 排名反转是多准则决策分析中的严重问题，影响决策结果的准确性，因此需要一种机制来评估不同方法的性能。

Method: 提出了三种测试方法，检测排名反转问题，并在Scikit-Criteria库中实现，同时讨论了通用场景下的设计挑战。

Result: 实现了三种测试方法，解决了通用场景下的设计问题，为多准则决策方法的评估提供了工具。

Conclusion: 这些测试方法在多准则决策方法的评估中具有重要作用，有助于提升问题解决的准确性。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [24] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 研究了SHACL在RDF图更新中的静态验证问题，提出了一种基于SHACL的更新语言，并通过回归技术将更新动作嵌入SHACL约束，展示了其计算复杂性和原型实现。


<details>
  <summary>Details</summary>
Motivation: 研究RDF图在更新后是否仍满足SHACL规范，为动态RDF图提供验证基础。

Method: 提出基于SHACL的更新语言，使用回归技术将更新动作嵌入SHACL约束，分析计算复杂性并实现原型。

Result: 静态验证问题可归约为SHACL约束的（不）可满足性问题，分析了计算复杂性并展示了原型实验结果。

Conclusion: 为动态RDF图的SHACL验证提供了理论基础和实用工具，扩展了SHACL的应用场景。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [25] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 论文提出了一种基于设计正义和参与式AI的AI生命周期重构方法，强调共同生产、多样性、公平性和多学科合作。


<details>
  <summary>Details</summary>
Motivation: AI算法可能对文化边缘群体产生不成比例的影响，现有方法未能彻底解决这一问题。

Method: 提出一个包含五个阶段的增强AI生命周期（共同框架、共同设计、共同实施、共同部署和共同维护），基于多学科研讨会和分布式权威理念。

Result: 该方法与主流伦理框架相关，并提出了扩展参与式治理的关键研究问题。

Conclusion: 重构AI生产流程以中心化共同生产和多学科合作，是减少AI对边缘群体危害的关键。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [26] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 论文主张过度依赖人类评估者间一致性（IRR）会阻碍教育数据分类的进展，提出五种补充评估方法以提高数据标注质量和模型效果。


<details>
  <summary>Details</summary>
Motivation: 人类评估者存在偏见和不可靠性，传统IRR指标（如Cohen's kappa）不足以确保标注数据的有效性，尤其在教育AI应用中。

Method: 提出五种补充评估方法，包括多标签标注方案、专家评估和闭环验证等，强调外部效度的重要性。

Result: 这些方法能比单独使用IRR更有效地生成训练数据，提升模型对学生学习的改善效果和可操作性。

Conclusion: 呼吁重新思考标注质量和“真实标准”，优先考虑效度和教育影响，而非仅依赖共识。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [27] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 论文探讨了通过明确要求AI代理增强人类能力并管理人机权力平衡，以促进安全和福祉。提出了一种参数化、可分解的目标函数，并通过算法计算其度量。


<details>
  <summary>Details</summary>
Motivation: 研究如何在AI系统中平衡权力，以确保安全和人类福祉，避免权力失衡带来的风险。

Method: 采用部分公理化方法设计目标函数，考虑人类有限理性和社会规范，并通过逆向归纳或多智能体强化学习计算度量。

Result: 在多种情境下展示了最大化人类权力度量的效果及其潜在子目标，表明这种目标可能比直接基于效用的目标更安全。

Conclusion: 适度最大化人类权力度量可能是AI系统的有益目标，比直接效用目标更安全。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [28] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS通过结合内部推理和外部数据，解决了RLVR的局限性，提升了LLM的推理能力，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: RLVR虽然提升了LLM的复杂推理能力，但由于其固有的策略限制和稀疏奖励，难以突破基础LLM的能力边界，甚至可能导致能力边界崩溃。

Method: RL-PLUS结合了多重重要性采样和基于探索的优势函数，以利用外部数据并引导模型探索高价值路径。

Result: RL-PLUS在六个数学推理基准测试中表现优异，并在六个分布外推理任务中超越现有方法，平均相对提升21.1%至69.2%。

Conclusion: RL-PLUS有效解决了能力边界崩溃问题，显著提升了LLM的推理能力，具有广泛的适用性和优越性。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [29] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent是一个基于学习实践原则的自主代理系统，通过不断自我反思和工具使用优化，无需调整模型参数即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个能够通过实践和自我改进不断提升能力的代理系统，以应对知识发现任务中的挑战。

Method: MetaAgent通过生成自然语言请求、路由工具、自我反思和知识库构建，实现持续学习和工具使用优化。

Result: 在GAIA、WebWalkerQA和BrowseCamp等基准测试中，MetaAgent表现优于基线方法，并媲美端到端训练的代理。

Conclusion: MetaAgent展示了自进化代理系统在通用知识发现任务中的潜力，为未来自主代理的发展提供了新思路。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [30] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 人类任务生成受心理驱动因素影响，而LLM（如GPT-4o）生成的任务缺乏社交性和物理性，偏向抽象主题，显示其与人类认知的差距。


<details>
  <summary>Details</summary>
Motivation: 探讨生成代理（如LLM）是否能模拟人类基于心理驱动的任务生成行为。

Method: 通过任务生成实验比较人类和LLM（GPT-4o）的反应，分析心理驱动因素对任务生成的影响。

Result: 人类任务生成受心理驱动因素影响，而LLM生成的任务缺乏社交性和物理性，偏向抽象主题，尽管被认为更有趣和新颖。

Conclusion: LLM与人类认知存在核心差距，需在设计更人性化的代理时融入内在动机和物理基础。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [31] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 提出了ReasonBench，首个专注于结构化图形推理任务的评估基准，评测了11种主流视觉语言模型（VLM），并揭示了其局限性。通过双重优化策略（DiaCoT和ReasonTune），VLM性能提升了33.5%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在复杂图形推理任务中表现不足，缺乏相关研究，因此需要开发一个全面的评估基准。

Method: 提出ReasonBench基准，包含1,613个现实智力测试问题，覆盖位置、属性、数量和多元素任务。采用双重优化策略：DiaCoT（分层分解增强推理可解释性）和ReasonTune（训练增强任务适应性）。

Result: 评测显示主流VLM在复杂推理任务中存在显著局限，优化策略使性能提升33.5%。

Conclusion: ReasonBench填补了复杂图形推理评估的空白，优化策略显著提升了VLM性能，为未来研究提供了工具和方向。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [32] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 论文提出R1-Act方法，通过显式触发安全知识提升大型推理模型的安全性，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现大型推理模型具备足够的安全知识但未在推理中激活，导致安全风险。

Method: 提出R1-Act，一种简单高效的后训练方法，通过结构化推理过程显式触发安全知识。

Result: R1-Act显著提升安全性且不损害推理性能，优于现有对齐方法，仅需少量资源和时间。

Conclusion: R1-Act在多种模型上验证了其鲁棒性、扩展性和实用性。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [33] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI框架通过引入视觉验证机制，解决了视觉语言模型中推理链缺乏视觉依据的问题，提升了多模态推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的推理链（CoT）虽然语言流畅，但缺乏视觉内容的依据，导致幻觉问题。

Method: 提出CoRGI框架，分三阶段：生成文本推理链、通过VEVM模块提取视觉证据、结合文本和视觉证据生成验证答案。

Result: 在VCR基准测试中，CoRGI提升了Qwen-2.5VL和LLaVA-1.6的性能，并生成更事实性和有帮助的解释。

Conclusion: 视觉验证对提升多模态推理的鲁棒性至关重要，CoRGI框架为未来研究提供了有效方向。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [34] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 提出了一种基于心智理论（ToM）的多智能体协作方法，通过主动推理实现，无需任务特定共享模型或显式通信。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作中因缺乏心智理论导致的效率低下问题，提升智能体对他人信念和目标的推理能力。

Method: 扩展推理树规划算法，递归探索联合策略空间，维护自身与他人信念和目标的独立表示。

Result: 在避碰和觅食任务中，ToM智能体表现优于非ToM智能体，能通过观察行为推断他人信念。

Conclusion: 该方法为人工智能实际应用提供了新思路，同时为心智理论的计算机制提供了见解。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [35] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro 是一个完全开源且免费的 AI 代理框架，旨在推动高级 AI 代理的开发与评估，并在 GAIA 基准测试中取得了开源代理的最优性能。


<details>
  <summary>Details</summary>
Motivation: 当前 AI 代理系统多为闭源或依赖付费 API，限制了研究的可访问性和可复现性。

Method: 通过构建高质量的训练数据（查询、轨迹和可验证答案）和探索代理测试时的反思与投票策略。

Result: 在 GAIA 基准测试中表现优异，8B 参数的开源模型超越此前领先系统。

Conclusion: Cognitive Kernel-Pro 为可访问的高性能 AI 代理设定了新标准。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [36] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: LLMs在结构化推理和符号任务中表现出色，但在形式数学（如定理证明）中进展较慢。本文探讨了LLMs在数学认知中的三个核心问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在形式数学中的局限性，揭示其推理和监督机制，以及逻辑状态的内部表示问题。

Method: 分析当前领域的最新模型和基准，探讨形式与非形式数学的训练权衡、证明生成的脆弱性原因，以及逻辑状态的表示问题。

Result: 形式数学对LLMs更具挑战性，证明生成比代码合成更脆弱，LLMs可能仅模仿而非真正表示逻辑状态。

Conclusion: 当前LLMs在形式数学中的能力有限，需进一步研究以突破这些限制。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [37] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard是一个基于概率可达性分析的主动运行时安全框架，用于预测和防止LLM代理的不安全行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的安全系统（如AgentSpec）缺乏预见性，难以处理长期依赖和分布偏移，导致安全风险。

Method: Pro2Guard将代理行为抽象为符号状态，从执行轨迹中学习离散时间马尔可夫链（DTMC），运行时通过估计到达不安全状态的概率来预测风险。

Result: 在家庭代理和自动驾驶场景中，Pro2Guard分别阻止了93.6%的不安全任务和100%预测交通违规与碰撞，风险预测提前38.66秒。

Conclusion: Pro2Guard通过主动预测和干预显著提升了LLM代理的安全性，同时保持任务完成率。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [38] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP是一个模型无关的解释框架，通过Shapley交互指数量化多模态AI模型中视觉和文本元素的协同效应，适用于开源和闭源模型。


<details>
  <summary>Details</summary>
Motivation: 解决多模态AI模型在关键应用中因‘黑盒’特性导致的解释性和可信度问题。

Method: 利用Shapley交互指数，对细粒度视觉和文本元素（如图像块和文本标记）的成对交互进行量化。

Result: 实验证明MultiSHAP能准确捕捉跨模态推理机制，并提供实例级和数据集级的解释。

Conclusion: MultiSHAP为解释复杂多模态AI模型提供了通用解决方案，并可扩展至超过两种模态。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [39] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 提出了一种多阶段LLM驱动框架，用于从复杂的电子病历（EMR）生成全面的预咨询问卷，解决了直接LLM方法在信息完整性、逻辑顺序和疾病级合成方面的不足。


<details>
  <summary>Details</summary>
Motivation: 预咨询是医疗保健的重要组成部分，但从复杂、大量的EMR中生成全面的预咨询问卷具有挑战性，直接LLM方法难以满足需求。

Method: 提出三阶段框架：1. 从EMR提取原子断言；2. 构建个人因果网络并合成疾病知识；3. 生成个性化的标准化问卷。

Result: 在真实EMR数据集和临床专家验证下，该方法在信息覆盖、诊断相关性、可理解性和生成时间上表现优异。

Conclusion: 该框架通过构建明确的临床知识，显著提升了预咨询问卷的质量和效率，具有实际应用潜力。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [40] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 论文提出AVR-Eval评估多媒体内容质量，并开发AVR-Agent多代理系统生成JavaScript代码，实验表明其生成内容优于单次生成，但模型在利用自定义资源和反馈方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 解决AI在生成交互式音视频内容（如视频游戏）时缺乏自动化评估指标和复杂内容生成能力的挑战。

Method: 提出AVR-Eval评估指标和AVR-Agent多代理系统，结合多媒体资源生成代码并通过迭代优化内容。

Result: AVR-Agent生成的内容在实验中表现优于单次生成内容，但模型未能有效利用自定义资源和反馈。

Conclusion: 当前模型在利用高质量资源和音视频反馈方面与人类存在差距，揭示了机器与人类内容创作方式的根本差异。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [41] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 提出了一种多频带可变滞后格兰杰因果性（MB-VLGC）框架，解决了传统方法无法处理频率依赖性因果延迟的问题。


<details>
  <summary>Details</summary>
Motivation: 复杂系统中因果关系的滞后和频率依赖性未被现有方法充分考虑，特别是在神经科学等领域。

Method: 通过建模频率依赖性因果延迟，扩展了可变滞后格兰杰因果性（VLGC），并提出了高效推理流程。

Result: 在合成和真实数据集上显著优于现有方法，验证了其广泛适用性。

Conclusion: MB-VLGC为时间序列数据中的因果关系分析提供了更全面的解决方案。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [42] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 提出了一种结合传统XAI技术与生成式AI模型的混合框架，旨在为教育领域提供多模态、个性化的解释，以增强透明度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 当前自适应学习系统缺乏透明度，且XAI技术忽视了用户角色和理解能力，因此需要一种更动态、用户中心的解释方法。

Method: 整合传统XAI技术与生成式AI模型，结合用户个性化需求，设计多模态解释框架。

Result: 重新定义可解释性为动态沟通过程，并提出了解决教育中XAI局限性的研究方向。

Conclusion: 目标是开发一种既能增强透明度又能支持用户中心体验的可解释AI框架。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [43] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 提出了一种用户分段的上下文感知解释系统，通过多样化的可视化解释方法提升社交媒体AI推荐的透明度和用户信任。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体的AI推荐缺乏针对用户特定需求的解释性，导致用户不理解推荐原因，影响体验。

Method: 设计了一个视觉解释系统，根据用户需求和上下文提供不同形式的解释（如技术详细版和简化版），并首次联合调整解释风格（视觉vs数字）和粒度（专家vs普通用户）。

Result: 通过30名X用户的公开试点验证系统对决策和信任的影响。

Conclusion: 该框架为社交媒体AI推荐提供了更个性化的解释方法，有望提升用户理解和信任。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [44] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 提出了一种基于大型预训练多模态模型的通用生成内容检测方法，通过线性分类器在多种模态上实现高效、快速的检测，性能优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 生成模型被恶意用于传播虚假信息，现有检测工具泛化能力差，亟需一种通用且高效的检测方法。

Method: 利用大型预训练多模态模型的潜在编码区分真实与生成内容，并训练线性分类器进行检测。

Result: 在音频和图像领域，该方法性能超越或匹配强基线方法，且计算高效、训练快速，适用于少样本场景。

Conclusion: 该方法为生成内容检测提供了一种通用且高效的解决方案，适用于多种模态和生成模型。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [45] [Improved Bounds on Access-Redundancy Tradeoffs in Quantized Linear Computations](https://arxiv.org/abs/2508.00183)
*Ching-Fang Li,Mary Wootters*

Main category: cs.IT

TL;DR: 论文研究了如何用少量查询计算量化线性函数的问题，改进了先前的不可能性结果，并首次探讨了近似恢复问题。


<details>
  <summary>Details</summary>
Motivation: 解决在有限查询次数下精确或近似计算量化线性函数的挑战，优化现有构造的局限性。

Method: 通过改进一般问题和特定构造类（块构造）的不可能性结果，并提出近似恢复的构造方法。

Result: 证明了块构造的优化性，并展示了近似恢复构造在ε=0.1时的优越性。

Conclusion: 论文为量化线性函数的高效计算提供了理论和构造上的进展，尤其在近似恢复方面表现突出。

Abstract: Consider the problem of computing quantized linear functions with only a few
queries. Formally, given $\mathbf{x}\in \mathbb{R}^k$, our goal is to encode
$\mathbf{x}$ as $\mathbf{c} \in \mathbb{R}^n$, for $n > k$, so that for any
$\mathbf{w} \in A^k$, $\mathbf{w}^T \mathbf{x}$ can be computed using at most
$\ell$ queries to $\mathbf{c}$. Here, $A$ is some finite set; in this paper we
focus on the case where $|A| = 2$.
  Prior work \emph{(Ramkumar, Raviv, and Tamo, Trans. IT, 2024)} has given
constructions and established impossibility results for this problem. We give
improved impossibility results, both for the general problem, and for the
specific class of construction (block construction) presented in that work. The
latter establishes that the block constructions of prior work are optimal
within that class.
  We also initiate the study of \emph{approximate} recovery for this problem,
where the goal is not to recover $\mathbf{w}^T \mathbf{x}$ exactly but rather
to approximate it up to a parameter $\varepsilon > 0$. We give several
constructions, and give constructions for $\varepsilon = 0.1$ that outperform
our impossibility result for exact schemes.

</details>


### [46] [Channel Estimation for Flexible Intelligent Metasurfaces: From Model-Based Approaches to Neural Operators](https://arxiv.org/abs/2508.00268)
*Jian Xiao,Ji Wang,Qimei Cui,Yucang Yang,Xingwang Li,Dusit Niyato,Chau Yuen*

Main category: cs.IT

TL;DR: 本文研究了柔性智能超表面（FIM）辅助毫米波通信系统中的信道估计问题，提出了基于模型和深度学习的框架，其中深度学习的Fourier神经算子（H-FNO）在估计精度和导频效率上显著优于模型方法。


<details>
  <summary>Details</summary>
Motivation: FIM通过动态调整三维形状优化多径信号，但其性能依赖于高维变形空间中的精确信道状态信息获取，因此需要解决这一基础信道估计问题。

Method: 提出了基于模型的框架（插值、核方法和稀疏信号恢复）和深度学习框架（Fourier神经算子及其分层版本H-FNO），后者通过傅里叶域全局卷积算子学习FIM形状到信道响应的连续映射。

Result: 数值结果表明，H-FNO在估计精度和导频效率上显著优于模型方法，并能准确重建连续变形空间中的非线性信道响应。

Conclusion: H-FNO通过学习适应FIM物理几何的各向异性空间滤波器，为FIM辅助通信系统提供了高效的信道估计解决方案。

Abstract: Flexible intelligent metasurfaces (FIMs) offer a new solution for wireless
communications by introducing morphological degrees of freedom, dynamically
morphing their three-dimensional shape to ensure multipath signals interfere
constructively. However, realizing the desired performance gains in FIM systems
is critically dependent on acquiring accurate channel state information across
a continuous and high-dimensional deformation space. Therefore, this paper
investigates this fundamental channel estimation problem for FIM assisted
millimeter-wave communication systems. First, we develop model-based frameworks
that structure the problem as either function approximation using interpolation
and kernel methods or as a sparse signal recovery problem that leverages the
inherent angular sparsity of millimeter-wave channels. To further advance the
estimation capability beyond explicit assumptions in model-based channel
estimation frameworks, we propose a deep learning-based framework using a
Fourier neural operator (FNO). By parameterizing a global convolution operator
in the Fourier domain, we design an efficient FNO architecture to learn the
continuous operator that maps FIM shapes to channel responses with
mesh-independent properties. Furthermore, we exploit a hierarchical FNO (H-FNO)
architecture to efficiently capture the multi-scale features across a hierarchy
of spatial resolutions. Numerical results demonstrate that the proposed H-FNO
significantly outperforms the model-based benchmarks in estimation accuracy and
pilot efficiency. In particular, the interpretability analysis show that the
proposed H-FNO learns an anisotropic spatial filter adapted to the physical
geometry of FIM and is capable of accurately reconstructing the non-linear
channel response across the continuous deformation space.

</details>


### [47] [Active IRS-Enabled Integrated Sensing and Communications with Extended Targets](https://arxiv.org/abs/2508.00379)
*Yuan Fang,Xianxin Song,Huazhou Hou,Ziguo Zhong,Xianghao Yu,Jie Xu,Yongming Huang*

Main category: cs.IT

TL;DR: 本文研究了主动智能反射面（IRS）支持的集成感知与通信（ISAC），通过优化波束成形最小化感知CRB，同时满足通信用户的SINR要求。


<details>
  <summary>Details</summary>
Motivation: 解决非视距（NLoS）区域通信和感知中的反射路径损耗问题，提升性能。

Method: 联合优化基站发射波束成形和主动IRS反射波束成形，提出交替优化算法。

Result: 主动IRS在实用系统设置下总是使用最大放大增益，验证了算法的有效性。

Conclusion: 主动IRS支持的ISAC优于被动IRS，为NLoS场景提供了高效解决方案。

Abstract: This paper studies the active intelligent reflecting surface (IRS)-enabled
integrated sensing and communications (ISAC), in which an active IRS is
deployed to assist the base station (BS) in serving multiple communication
users (CUs) and simultaneously sensing an \emph{extended} target at the
non-line-of-sight (NLoS) area of the BS. The active IRS has the capability of
amplifying the reflected signals so as to overcome significant reflection path
loss in NLoS communication and sensing. In particular, we derive the sensing
Cram\'{e}r-Rao bound (CRB) for estimating the target response matrix.
Accordingly, we jointly optimize the transmit beamforming at the BS and the
reflective beamforming at the active IRS to minimize the sensing CRB, subject
to the signal-to-interference-plus-noise ratio (SINR) requirements at the CUs,
the transmit power budgets at the BS and active IRS, as well as the power
amplification gain constraints at the active IRS. The CRB minimization problem
is highly non-convex and thus difficult to solve in general. To address this
challenge, we first focus on two specified conditions by considering the
sensing-only scenario via ignoring the SINR constraints for communications, for
which the closed-form optimal transmit beamforming is derived. Then, we propose
two efficient alternating optimization (AO)-based algorithms to obtain
high-quality solutions for the general ISAC scenarios. Next, we analyze the
inherent relationship between the power scaling at the BS and the amplification
scaling at the active IRS. It is shown that the active IRS always amplifies the
signal using the maximum amplification gain under practical system settings.
Finally, numerical results are provided to verify the effectiveness of the
proposed AO-based algorithms and the benefits of active IRS-enabled ISAC
compared to its passive IRSs counterparts.

</details>


### [48] [LO-Aware Adaptive Modulation for Rydberg Atomic Receivers](https://arxiv.org/abs/2508.00458)
*Jiuyu Liu,Yi Ma,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 本文提出了一种针对Rydberg原子接收器的LO感知自适应调制方案（LOAM），通过动态适应复杂信道条件，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: Rydberg原子接收器在无线通信中具有超高灵敏度，但无法检测信号相位。现有调制方案在这种量子检测机制下表现不佳，因此需要一种新的调制方案。

Method: LOAM方案通过动态调整星座图结构，最大化星座点间的最小幅度差，并根据参考信号强度选择对称或非对称分布。

Result: 仿真结果显示，LOAM在性能上比传统调制方案（如QAM、PSK、PAM）提升了超过45 dB。

Conclusion: LOAM为Rydberg原子接收器提供了一种高效的调制方案，显著提升了通信性能。

Abstract: Rydberg atomic (RA) receivers represent a revolutionary quantum technology
for wireless communications, offering unprecedented sensitivity beyond
conventional radio frequency (RF) antennas. However, these receivers detect
only signal amplitude, losing critical phase information. While reference
signals generated by a local oscillator (LO) can assist in phase recovery,
existing modulation schemes designed for conventional systems perform poorly
with this quantum detection mechanism. This paper introduces a breakthrough
LO-aware adaptive modulation (LOAM) scheme specifically developed for RA
receivers that dynamically adapts to complex fading channel coefficients. LOAM
maximizes the minimum amplitude difference between constellation points,
ensuring optimal detection performance. The innovation employs an adaptive
co-linear constellation architecture aligned with the combined phase of
reference signal and channel coefficient. For strong reference signals, LOAM
generates symmetric constellation points centered at origin; for weak signals,
it adopts non-symmetric distributions. The paper mathematically derives the
threshold governing these operational regimes. Simulation results reveal the
transformative impact of LOAM, demonstrating performance gains exceeding 45 dB
over conventional modulation schemes, including quadrature amplitude modulation
(QAM), phase-shift keying (PSK), and pulse-amplitude modulation (PAM).

</details>


### [49] [Towards a Measure Theory of Semantic Information](https://arxiv.org/abs/2508.00525)
*George M. Coghill*

Main category: cs.IT

TL;DR: 本文批判了Floridi的强语义信息理论，提出了一种基于单位圆的新方法，解决了Bar-Hillel-Carnap悖论，并展示了其效用。


<details>
  <summary>Details</summary>
Motivation: 解决Floridi理论未能消除的Bar-Hillel-Carnap悖论，并提出更有效的语义信息量化方法。

Method: 基于单位圆的类比，结合冯·诺伊曼的量子概率，构建了一个满足Floridi要求的信息度量空间。

Result: 新方法消除了悖论，矛盾与重言式信息量为零，但相互矛盾的信息具有相同的信息量。

Conclusion: 新方法不仅解决了悖论，还提供了更合理的语义信息量化框架。

Abstract: A classic account of the quantification of semantic information is that of
Bar-Hiller and Carnap. Their account proposes an inverse relation between the
informativeness of a statement and its probability. However, their approach
assigns the maximum informativeness to a contradiction: which Floridi refers to
as the Bar-Hillel-Carnap paradox. He developed a novel theory founded on a
distance metric and parabolic relation, designed to remove this paradox.
Unfortunately is approach does not succeed in that aim.
  In this paper I critique Floridi's theory of strongly semantic information on
its own terms and show where it succeeds and fails. I then present a new
approach based on the unit circle (a relation that has been the basis of
theories from basic trigonometry to quantum theory). This is used, by analogy
with von Neumann's quantum probability to construct a measure space for
informativeness that meets all the requirements stipulated by Floridi and
removes the paradox. In addition, while contradictions and tautologies have
zero informativeness, it is found that messages which are contradictory to each
other are equally informative. The utility of this is explained by means of an
example.

</details>


### [50] [Appendices for "Closed-Form BER Analysis for Uplink NOMA with Dynamic SIC Decoding"](https://arxiv.org/abs/2508.00540)
*Hequn Zhang,Qu Luo,Pei Xiao,Yue Zhang,Huiyu Zhou*

Main category: cs.IT

TL;DR: 补充材料提供了上行NOMA动态SIC解码的闭式BER分析所需的详细数学推导和证明。


<details>
  <summary>Details</summary>
Motivation: 为上行NOMA系统在瑞利衰落信道下的动态SIC解码提供数学基础，支持多种调制方案和系统配置的闭式BER分析。

Method: 包括累积分布函数、概率密度函数、闭式PEP表达式、信道增益排序概率推导、M-QAM调制BER分析等。

Result: 建立了完整的数学框架，支持动态SIC解码的闭式BER分析。

Conclusion: 补充材料为上行NOMA系统的BER分析提供了坚实的数学基础，适用于多种调制方案和配置。

Abstract: This document provides the supplementary materials for the paper Closed-Form
BER Analysis for Uplink NOMA with Dynamic SIC Decoding. The appendices present
detailed mathematical derivations and proofs that support the analytical
framework of the main paper. Specifically, we include: (i) cumulative
distribution functions for ordered channel gains; (ii) probability density
functions of normalized signal-plus-interference variances in NOMA dynamic SIC
decoding; (iii) closed-form expressions for pairwise error probability (PEP)
with two users; (iv) probability derivations for channel gain ordering in the
two-UE case, specifically when UE 1 and UE 2 have the strongest or second
strongest channel gains; (v) BER analysis for M-QAM modulation schemes
including BPSK, 4QAM, 16QAM and 64QAM; (vi) PDF derivations for channel gains
under various ordering conditions; and (vii) challenges of PDF derivations for
real part of channel gain under various ordering condition. These mathematical
foundations enable the closed-form BER analysis of uplink NOMA systems with
dynamic SIC decoding under Rayleigh fading channels, supporting analytical
expressions for various modulation schemes and system configurations.

</details>


### [51] [Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience](https://arxiv.org/abs/2508.00596)
*Xiang Zhang,Zhou Li,Shuangyang Li,Kai Wan,Derrick Wing Kwan Ng,Giuseppe Caire*

Main category: cs.IT

TL;DR: 该论文研究了去中心化联邦学习中的安全聚合问题，从信息论角度分析了通信和密钥使用的最优界限。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注协议设计和计算保证，但对信息论基础限制的理解有限，尤其是在去中心化环境中缺乏中央聚合器的情况下。

Method: 研究了一个由K个全连接用户组成的网络，每个用户持有私有输入，目标是安全计算所有输入的总和。

Result: 确定了最优速率区域，表明每个用户必须传输至少一个符号、持有至少一个密钥符号，且所有用户共同持有不少于K-1个独立密钥符号。

Conclusion: 研究结果为分布式学习系统中设计可证明安全和通信高效的协议提供了理论基础。

Abstract: In decentralized federated learning (FL), multiple clients collaboratively
learn a shared machine learning (ML) model by leveraging their privately held
datasets distributed across the network, through interactive exchange of the
intermediate model updates. To ensure data security, cryptographic techniques
are commonly employed to protect model updates during aggregation. Despite
growing interest in secure aggregation, existing works predominantly focus on
protocol design and computational guarantees, with limited understanding of the
fundamental information-theoretic limits of such systems. Moreover, optimal
bounds on communication and key usage remain unknown in decentralized settings,
where no central aggregator is available. Motivated by these gaps, we study the
problem of decentralized secure aggregation (DSA) from an information-theoretic
perspective. Specifically, we consider a network of $K$ fully-connected users,
each holding a private input -- an abstraction of local training data -- who
aim to securely compute the sum of all inputs. The security constraint requires
that no user learns anything beyond the input sum, even when colluding with up
to $T$ other users. We characterize the optimal rate region, which specifies
the minimum achievable communication and secret key rates for DSA. In
particular, we show that to securely compute one symbol of the desired input
sum, each user must (i) transmit at least one symbol to others, (ii) hold at
least one symbol of secret key, and (iii) all users must collectively hold no
fewer than $K - 1$ independent key symbols. Our results establish the
fundamental performance limits of DSA, providing insights for the design of
provably secure and communication-efficient protocols in distributed learning
systems.

</details>


### [52] [Deep Learning-Based Rate-Adaptive CSI Feedback for Wideband XL-MIMO Systems in the Near-Field Domain](https://arxiv.org/abs/2508.00626)
*Zhenyu Liu,Yi Ma,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 论文提出了一种名为WideNLNet-CA的深度学习框架，用于在宽带近场XL-MIMO系统中实现高效的CSI反馈。


<details>
  <summary>Details</summary>
Motivation: 在6G网络中，XL-MIMO系统的频谱效率提升依赖于准确且高效的CSI反馈，但近场球面波传播和宽带场景中的频率相关波束分裂效应带来了挑战。

Method: WideNLNet-CA采用轻量级编码器-解码器架构，结合多阶段下采样和上采样，以及高效的残差块来捕捉多尺度信道特征。此外，引入压缩比自适应模块动态调整特征选择。

Result: 实验表明，WideNLNet-CA在各种压缩比和带宽下均优于现有方法，同时保持快速推理和低存储需求。

Conclusion: WideNLNet-CA为宽带近场XL-MIMO系统中的CSI反馈提供了一种高效且灵活的解决方案。

Abstract: Accurate and efficient channel state information (CSI) feedback is crucial
for unlocking the substantial spectral efficiency gains of extremely
large-scale MIMO (XL-MIMO) systems in future 6G networks. However, the
combination of near-field spherical wave propagation and frequency-dependent
beam split effects in wideband scenarios poses significant challenges for CSI
representation and compression. This paper proposes WideNLNet-CA, a
rate-adaptive deep learning framework designed to enable efficient CSI feedback
in wideband near-field XL-MIMO systems. WideNLNet-CA introduces a lightweight
encoder-decoder architecture with multi-stage downsampling and upsampling,
incorporating computationally efficient residual blocks to capture complex
multi-scale channel features with reduced overhead. A novel compression ratio
adaptive module with feature importance estimation is introduced to dynamically
modulate feature selection based on target compression ratios, enabling
flexible adaptation across a wide range of feedback rates using a single model.
Evaluation results demonstrate that WideNLNet-CA consistently outperforms
existing compressive sensing and deep learning-based works across various
compression ratios and bandwidths, while maintaining fast inference and low
model storage requirements.

</details>
