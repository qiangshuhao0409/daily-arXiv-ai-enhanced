<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.IT](#cs.IT) [Total: 12]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Software-Defined Radio Testbed for Distributed LiDAR Point Cloud Sharing with IEEE 802.11p in V2V Networks](https://arxiv.org/abs/2509.14523)
*Mario Hernandez,Elijah Bryce,Peter Stubberud,Ebrahim Saberinia,Brendan Morris*

Main category: cs.NI

TL;DR: 基于SDR的IEEE 802.11p测试床，用于V2V通信和协同感知，评估去中心化存储系统的性能


<details>
  <summary>Details</summary>
Motivation: 构建一个模块化的成本效益高的SDR测试床，突破网络模拟与实际部署之间的间隔

Method: 使用ADALM-Pluto SDR设备，通过Docker和ROS运行通信节点，共享LiDAR点云数据并融合成集体感知环境

Result: 评估了IPFS和Filecoin等去中心化存储系统的存储收敛性、延迟和可扩展性，并进行了通道质量研究

Conclusion: 该平台成功实现了分布式V2V通信和协同感知，为去中心化存储系统在车辆通信中的应用提供了实践基础

Abstract: We present a Software Defined Radio (SDR)-based IEEE 802.11p testbed for
distributed Vehicle-to-Vehicle (V2V) communication. The platform bridges the
gap between network simulation and deployment by providing a modular codebase
configured for cost-effective ADALM-Pluto SDRs. Any device capable of running a
Docker with ROS, executing Matlab and interface with a Pluto via USB can act as
a communication node. To demonstrate collaborative sensing, we share LiDAR
point clouds between nodes and fuse them into a collective perception
environment. We evaluated a theoretical model for leveraging decentralized
storage systems (IPFS and Filecoin), analyzing constraints such as node storage
convergence, latency, and scalability. In addition, we provide a channel
quality study.

</details>


### [2] [Chameleon: Integrated Sensing and Communication with Sub-Symbol Beam Switching in mmWave Networks](https://arxiv.org/abs/2509.14628)
*Zhihui Gao,Zhecun Liu,Tingjun Chen*

Main category: cs.NI

TL;DR: Chameleon框架在5G毫米波网络中通过快速切换波束成形器，在DMRS符号期间实现通信和感知的集成，同时维持多用户通信和高速成像能力。


<details>
  <summary>Details</summary>
Motivation: 当前5G网络的波束成形通常只为通信或感知单独设计，缺乏集成方案。需要一种能够在毫米波频谱中同时实现高效通信和精确感知的框架。

Method: 提出Chameleon框架，在每个DMRS符号期间快速切换波束成形器（0.24μs间隔），在维持多用户通信波束的同时引入额外的感知波束指向目标角度。在28GHz软件定义无线电测试床上实现，支持5G PDSCH传输。

Result: 实现双用户总和数据率0.80Gbps，在0.875ms内完成31x31点2D成像。通过机器学习实现0.14m距离误差和0.24°角度误差的物体定位，以及99.0%准确率的材料分类。

Conclusion: Chameleon成功证明了在5G毫米波网络中集成感知与通信的可行性，通过快速波束切换实现了高性能的通信和感知能力，为下一代蜂窝网络提供了重要技术基础。

Abstract: Next-generation cellular networks are envisioned to integrate sensing
capabilities with communication, particularly in the millimeter-wave (mmWave)
spectrum, where beamforming using large-scale antenna arrays enables
directional signal transmissions for improved spatial multiplexing. In current
5G networks, however, beamforming is typically designed either for
communication or sensing (e.g., beam training during link establishment). In
this paper, we present Chameleon, a novel framework that augments and rapidly
switches beamformers during each demodulation reference signal (DMRS) symbol to
achieve integrated sensing and communication (ISAC) in 5G mmWave networks. Each
beamformer introduces an additional sensing beam toward target angles while
maintaining the communication beams toward multiple users. We implement
Chameleon on a 28 GHz software-defined radio testbed supporting over-the-air 5G
physical downlink shared channel (PDSCH) transmissions. Extensive experiments
in open environments show that Chameleon achieves multi-user communication with
a sum data rate of up to 0.80 Gbps across two users. Simultaneously, Chameleon
employs a beamformer switching interval of only 0.24 {\mu}s, therefore
producing a 31x31-point 2D imaging within just 0.875 ms. Leveraging machine
learning, Chameleon further enables object localization with median errors of
0.14 m (distance) and 0.24{\deg} (angle), and material classification with
99.0% accuracy.

</details>


### [3] [1Q: First-Generation Wireless Systems Integrating Classical and Quantum Communication](https://arxiv.org/abs/2509.14731)
*Petar Popovski,Čedomir Stefanović,Beatriz Soret,Israel Leyva-Mayorga,Shashi Raj Pandey,René Bødker Christensen,Jakob Kaltoft Søndergaard,Kristian Skafte Jensen,Thomas Garm Pedersen,Angela Sara Cacciapuoti,Lajos Hanzo*

Main category: cs.NI

TL;DR: 1Q是首个集成经典和量子通信的无线框架，通过量子基站支持自由空间光链路的纠缠分发，扩展量子互联网到蜂窝无线网络


<details>
  <summary>Details</summary>
Motivation: 将量子互联网扩展到无线蜂窝网络，实现经典通信与量子通信的集成，支持量子密钥分发、盲量子计算和分布式量子传感等应用

Method: 提出量子基站(QBS)、量子小区、量子用户设备(QUE)等新组件，采用混合资源分配策略，扩展蜂窝连接管理协议以包含纠缠生成、分发和切换过程

Result: 建立了支持自由空间光链路纠缠分发的无线量子通信框架，识别了量子退相干时间、保真度要求等独特约束条件

Conclusion: 1Q框架成功将量子互联网扩展到无线领域，为未来集成经典和量子通信的无线网络奠定了基础

Abstract: We sketch out the concept of 1Q, the first wireless generation of integrated
classical and quantum communication. The 1Q framework features quantum base
stations (QBSs) that support entanglement distribution via free-space optical
links alongside traditional radio communications. Key new components include
quantum cells, quantum user equipment (QUEs), and hybrid resource allocation
spanning classical time-frequency and quantum entanglement domains. Several
application scenarios are discussed and illustrated through system design
requirements for quantum key distribution, blind quantum computing, and
distributed quantum sensing. A range of unique quantum constraints are
identified, including decoherence timing, fidelity requirements, and the
interplay between quantum and classical error probabilities. Protocol
adaptations extend cellular connection management to incorporate entanglement
generation, distribution, and handover procedures, expanding the Quantum
Internet to the cellular wireless.

</details>


### [4] [AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS in 6G Smart Cities](https://arxiv.org/abs/2509.14877)
*Rohin Gillgallon,Giacomo Bergami,Reham Almutairi,Graham Morgan*

Main category: cs.NI

TL;DR: 扩展SimulatorOrchestrator模拟器，通过AI算法实现动态车辆规划和优化，在保证通信公平性的同时最小化车辆电池消耗


<details>
  <summary>Details</summary>
Motivation: 现有车载物联网节点模拟器缺乏动态代理规划和优化功能，无法在确保公平通信时间的同时最小化车辆电池消耗

Method: 扩展SimulatorOrchestrator模拟器架构，集成AI算法进行交通预测和动态代理规划，引入期望区域概念

Result: 在城市数据集上的初步结果显示，车辆规划算法相比传统最短路径算法能改善电池和QoS性能，期望区域的引入使更多救护车能以更低能耗到达目的地

Conclusion: 扩展的模拟器架构结合AI算法能够有效优化车辆能耗和通信性能，期望区域概念为动态车辆规划提供了新的优化维度

Abstract: While simulators exist for vehicular IoT nodes communicating with the Cloud
through Edge nodes in a fully-simulated osmotic architecture, they often lack
support for dynamic agent planning and optimisation to minimise vehicular
battery consumption while ensuring fair communication times. Addressing these
challenges requires extending current simulator architectures with AI
algorithms for both traffic prediction and dynamic agent planning. This paper
presents an extension of SimulatorOrchestrator (SO) to meet these requirements.
Preliminary results over a realistic urban dataset show that utilising
vehicular planning algorithms can lead to improved battery and QoS performance
compared with traditional shortest path algorithms. The additional inclusion of
desirability areas enabled more ambulances to be routed to their target
destinations while utilising less energy to do so, compared to traditional and
weighted algorithms without desirability considerations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Unified Crew Planning and Replanning Optimization in Multi-Line Metro Systems Considering Workforce Heterogeneity](https://arxiv.org/abs/2509.14251)
*Qihang Chen*

Main category: cs.AI

TL;DR: 基于层次时空网络模型的多线路地铁班组规划与重新规划统一优化框架，通过列生成算法和最短路径调整，在上海和北京地铁实际数据中验证了在成本降低和任务完成方面的优势。


<details>
  <summary>Details</summary>
Motivation: 随着地铁网络的快速扩张，多线路调度和应急管理变得至关重要。当前研究主要集中在单个地铁线路，对于跨线路协调和故障时的快速重新规划关注不够。

Method: 提出了一种统一的优化框架，构建层次时空网络模型来表示统一的班组动作空间，并涉及异质化劳务资格和偏好的高效算法约束和形式化。进一步发展了基于列生成和最短路径调整的求解算法。

Result: 在上海和北京地铁实际数据上的实验表明，该方法在成本降低和任务完成方面都超过了基准启发式算法，通过跨线路运营特别是在故障时的紧急任务中取得了显著的效率提升。

Conclusion: 这项工作强调了全局优化和跨线路协调在多线路地铁系统运营中的作用，为智慧城市公共交通的高效可靠运行提供了见解。

Abstract: Metro crew planning is a key component of smart city development as it
directly impacts the operational efficiency and service reliability of public
transportation. With the rapid expansion of metro networks, effective
multi-line scheduling and emergency management have become essential for
large-scale seamless operations. However, current research focuses primarily on
individual metro lines,with insufficient attention on cross-line coordination
and rapid replanning during disruptions. Here, a unified optimization framework
is presented for multi-line metro crew planning and replanning with
heterogeneous workforce. Specifically, a hierarchical time-space network model
is proposed to represent the unified crew action space, and computationally
efficient constraints and formulations are derived for the crew's heterogeneous
qualifications and preferences. Solution algorithms based on column generation
and shortest path adjustment are further developed, utilizing the proposed
network model. Experiments with real data from Shanghai and Beijing Metro
demonstrate that the proposed methods outperform benchmark heuristics in both
cost reduction and task completion,and achieve notable efficiency gains by
incorporating cross-line operations, particularly for urgent tasks during
disruptions. This work highlights the role of global optimization and
cross-line coordination in multi-line metro system operations, providing
insights into the efficient and reliable functioning of public transportation
in smart cities.

</details>


### [6] [From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing](https://arxiv.org/abs/2509.14289)
*Lanxiao Huang,Daksh Dave,Ming Jin,Tyler Cody,Peter Beling*

Main category: cs.AI

TL;DR: 对多种LLM代理在渗透测试中的性能评估，通过五项核心功能增强显著提升模块化代理在复杂任务中的表现


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在渗透测试中的应用日益增多，但其在不同攻击阶段的有效性和可靠性尚不明确，需要进行系统评估

Method: 通过全局上下文记忆、代理间消息传递、上下文条件调用、自适应规划和实时监控这五项核心功能增强来评估多种LLM代理架构

Result: 虽然某些架构天然具备部分功能特性，但针对性增强显著提高了模块化代理在复杂、多步骤和实时渗透测试任务中的性能

Conclusion: 通过五项核心功能的有针对性增强可以显著提升LLM代理在渗透测试中的表现，特别是在复杂和实时任务中

Abstract: Large language models (LLMs) are increasingly used to automate or augment
penetration testing, but their effectiveness and reliability across attack
phases remain unclear. We present a comprehensive evaluation of multiple
LLM-based agents, from single-agent to modular designs, across realistic
penetration testing scenarios, measuring empirical performance and recurring
failure patterns. We also isolate the impact of five core functional
capabilities via targeted augmentations: Global Context Memory (GCM),
Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive
Planning (AP), and Real-Time Monitoring (RTM). These interventions support,
respectively: (i) context coherence and retention, (ii) inter-component
coordination and state management, (iii) tool use accuracy and selective
execution, (iv) multi-step strategic planning, error detection, and recovery,
and (v) real-time dynamic responsiveness. Our results show that while some
architectures natively exhibit subsets of these properties, targeted
augmentations substantially improve modular agent performance, especially in
complex, multi-step, and real-time penetration testing tasks.

</details>


### [7] [Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents](https://arxiv.org/abs/2509.14382)
*Daniel Röder,Akhil Juneja,Roland Roller,Sven Schmeier*

Main category: cs.AI

TL;DR: 提出模块化评估框架，逐步分析LLM网页代理的错误模式，补充了现有综合性评估的不足


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注整体成功率，忽视中间错误，限刻了对失败模式的深入理解和系统性改进

Method: 提出模块化评估框架，将代理流水线解构为可解释的阶段，进行详细错误分析，以SeeAct框架和Mind2Web数据集为案例研究

Result: 该方法能够揭示标准指标没有发现的可操作弱点

Conclusion: 模块化评估框架为建造更稳健和可推广的网页代理提供了途径

Abstract: Web agents powered by large language models (LLMs) can autonomously perform
complex, multistep tasks in dynamic web environments. However, current
evaluations mostly focus on the overall success while overlooking intermediate
errors. This limits insight into failure modes and hinders systematic
improvement. This work analyzes existing benchmarks and highlights the lack of
fine-grained diagnostic tools. To address this gap, we propose a modular
evaluation framework that decomposes agent pipelines into interpretable stages
for detailed error analysis. Using the SeeAct framework and the Mind2Web
dataset as a case study, we show how this approach reveals actionable
weaknesses missed by standard metrics - paving the way for more robust and
generalizable web agents.

</details>


### [8] [VCBench: Benchmarking LLMs in Venture Capital](https://arxiv.org/abs/2509.14448)
*Rick Chen,Joseph Ternasky,Afriyie Samuel Kwesi,Ben Griffin,Aaron Ontoyin Yin,Zakari Salifu,Kelvin Amoaba,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: VCBench是首个用于预测风险投资创始人成功的基准测试，包含9000个匿名创始人档案，评估显示LLM模型表现优于人类基准和顶级投资机构


<details>
  <summary>Details</summary>
Motivation: 现有基准测试如SWE-bench和ARC-AGI加速了AGI发展，但在风险投资领域缺乏标准化评估基准，该领域信号稀疏、结果不确定，即使是顶级投资者表现也一般

Method: 创建包含9000个匿名创始人档案的VCBench数据集，进行标准化处理以保留预测特征同时防止身份泄露，使用对抗测试降低90%以上的重识别风险，评估9个最先进的大语言模型

Result: 市场指数精度1.9%，Y Combinator比指数好1.7倍，顶级机构好2.9倍。DeepSeek-V3达到基线精度6倍以上，GPT-4o获得最高F0.5分数，大多数模型超越人类基准

Conclusion: VCBench作为公开演进资源，为早期风险预测领域建立了社区驱动的可重现和隐私保护的AGI评估标准

Abstract: Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets
accelerate progress toward artificial general intelligence (AGI). We introduce
VCBench, the first benchmark for predicting founder success in venture capital
(VC), a domain where signals are sparse, outcomes are uncertain, and even top
investors perform modestly. At inception, the market index achieves a precision
of 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1
firms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,
standardized to preserve predictive features while resisting identity leakage,
with adversarial tests showing more than 90% reduction in re-identification
risk. We evaluate nine state-of-the-art large language models (LLMs).
DeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the
highest F0.5, and most models surpass human benchmarks. Designed as a public
and evolving resource available at vcbench.com, VCBench establishes a
community-driven standard for reproducible and privacy-preserving evaluation of
AGI in early-stage venture forecasting.

</details>


### [9] [From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence](https://arxiv.org/abs/2509.14474)
*Meltem Subasioglu,Nevzat Subasioglu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于认知机制的真正智能(TI)定义，包含六个核心组件，并建立了五级AGI分类评价体系，为AGI研究提供了明确的发展路径。


<details>
  <summary>Details</summary>
Motivation: 当前以性能为基础的AGI定义存在缺陷：无法提供清晰的机制化研究路线图，也无法正确定义真正智能的本质特性。需要从模仿人类表现转向基础认知架构的建设。

Method: 受人脑启发，提出真正智能(TI)的六大核心组件：体验感知融合、核心指令、动态模式创建、高度联网多专家架构、协调层，以及不可测量的联结性。建立五级AGI分类评价体系。

Result: 提供了一个基于机制的全面AGI定义框架，包含明确的发展里程碑和评估标准。认为实现五级AGI的系统在功能上等同于真正智能。

Conclusion: 该研究综合了分析心理学、模式理论、元认知、现代脑科学和AI领域的见解，首次提供了一个基于机制的全面AGI定义，为研究社群提供了清晰可执行的研究路径。

Abstract: The debate around Artificial General Intelligence (AGI) remains open due to
two fundamentally different goals: replicating human-like performance versus
replicating human-like cognitive processes. We argue that current
performance-based definitions are inadequate because they provide no clear,
mechanism-focused roadmap for research, and they fail to properly define the
qualitative nature of genuine intelligence. Drawing inspiration from the human
brain, we propose a new paradigm that shifts the focus from external mimicry to
the development of foundational cognitive architectures. We define True
Intelligence (TI) as a system characterized by six core components: embodied
sensory fusion, core directives, dynamic schemata creation, a
highly-interconnected multi-expert architecture, an orchestration layer, and
lastly, the unmeasurable quality of Interconnectedness, which we hypothesize
results in consciousness and a subjective experience. We propose a practical,
five-level taxonomy of AGI based on the number of the first five measurable
components a system exhibits. This framework provides a clear path forward with
developmental milestones that directly address the challenge of building
genuinely intelligent systems. We contend that once a system achieves Level-5
AGI by implementing all five measurable components, the difference between it
and TI remains as a purely philosophical debate. For practical purposes - and
given theories indicate consciousness is an emergent byproduct of integrated,
higher-order cognition - we conclude that a fifth-level AGI is functionally and
practically equivalent to TI. This work synthesizes diverse insights from
analytical psychology, schema theory, metacognition, modern brain architectures
and latest works in AI to provide the first holistic, mechanism-based
definition of AGI that offers a clear and actionable path for the research
community.

</details>


### [10] [Beyond the high score: Prosocial ability profiles of multi-agent populations](https://arxiv.org/abs/2509.14485)
*Marko Tesic,Yue Zhao,Joel Z. Leibo,Rakshit S. Trivedi,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 本文应用贝叶斯测量布局方法分析Melting Pot竞赛中多智能体系统的能力特征，发现高亲社会能力并不总是带来更好性能，顶级参赛方案可能在不需要合作的场景中表现更好，揭示了评估框架的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估AI智能体的社交能力需要复杂环境，但传统方法难以控制抽象行为如约定遵循。Melting Pot竞赛旨在评估AI系统合作能力，但现有方法存在局限性。

Method: 采用贝叶斯测量布局方法推断多智能体系统在Melting Pot竞赛中的能力特征，分析能力特征与未来表现的关系。

Result: 能力特征不仅能预测未来表现，还揭示了智能体的亲社会能力；高亲社会能力并不总是带来更好性能；顶级参赛方案更可能在不需要合作的场景中获得高分；竞赛获胜者使用了针对特定环境的硬编码方案。

Conclusion: 测量布局方法提供了强预测准确性和可操作见解，有助于在复杂社交环境中更透明、可泛化地评估AI系统，需要改进合作需求的标注方法并考虑测试环境带来的偏差。

Abstract: The development and evaluation of social capabilities in AI agents require
complex environments where competitive and cooperative behaviours naturally
emerge. While game-theoretic properties can explain why certain teams or agent
populations outperform others, more abstract behaviours, such as convention
following, are harder to control in training and evaluation settings. The
Melting Pot contest is a social AI evaluation suite designed to assess the
cooperation capabilities of AI systems. In this paper, we apply a Bayesian
approach known as Measurement Layouts to infer the capability profiles of
multi-agent systems in the Melting Pot contest. We show that these capability
profiles not only predict future performance within the Melting Pot suite but
also reveal the underlying prosocial abilities of agents. Our analysis
indicates that while higher prosocial capabilities sometimes correlate with
better performance, this is not a universal trend-some lower-scoring agents
exhibit stronger cooperation abilities. Furthermore, we find that
top-performing contest submissions are more likely to achieve high scores in
scenarios where prosocial capabilities are not required. These findings,
together with reports that the contest winner used a hard-coded solution
tailored to specific environments, suggest that at least one top-performing
team may have optimised for conditions where cooperation was not necessary,
potentially exploiting limitations in the evaluation framework. We provide
recommendations for improving the annotation of cooperation demands and propose
future research directions to account for biases introduced by different
testing environments. Our results demonstrate that Measurement Layouts offer
both strong predictive accuracy and actionable insights, contributing to a more
transparent and generalisable approach to evaluating AI systems in complex
social settings.

</details>


### [11] [DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction](https://arxiv.org/abs/2509.14507)
*Jian Chen,Zhenyan Chen,Xuming Hu,Peilin Zhou,Yining Hua,Han Fang,Cissy Hing Yee Choy,Xinmei Ke,Jingfeng Luo,Zixuan Yuan*

Main category: cs.AI

TL;DR: DeKeyNLU数据集和DeKeySQL管道通过改进任务分解和关键词提取，显著提升NL2SQL性能


<details>
  <summary>Details</summary>
Motivation: 现有NL2SQL方法存在任务分解不准确和关键词提取错误的问题，现有数据集缺乏领域特定关键词标注且任务过于碎片化

Method: 提出DeKeyNLU数据集（1500个标注QA对）和DeKeySQL RAG管道，包含三个模块：用户问题理解、实体检索和SQL生成

Result: 在BIRD数据集上准确率从62.31%提升到69.10%，在Spider数据集上从84.2%提升到88.7%

Conclusion: DeKeyNLU数据集和DeKeySQL管道有效解决了NL2SQL中的任务分解和关键词提取问题，显著提高了SQL生成准确性

Abstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.

</details>


### [12] [Rationality Check! Benchmarking the Rationality of Large Language Models](https://arxiv.org/abs/2509.14546)
*Zhilun Zhou,Jing Yi Wang,Nicholas Sukiennik,Chen Gao,Fengli Xu,Yong Li,James Evans*

Main category: cs.AI

TL;DR: 这是首个评估大语言模型全面理性的基准，包含多领域实验和分析工具


<details>
  <summary>Details</summary>
Motivation: 随着LLM在人工智能领域表现出人类能力，需要评估它们是否和何时能像真实人类一样理性思考和行动

Method: 建立了一个涉及广泛领域的理性评估基准，包括理论理性和实践理性，提供易用工具包和实验分析

Result: 通过实验结果呈现了LLM与理想化人类理性的洞差和会合点

Conclusion: 该基准可作为LLM开发者和使用者的基础工具，为评估模型理性提供重要参考

Abstract: Large language models (LLMs), a recent advance in deep learning and machine
intelligence, have manifested astonishing capacities, now considered among the
most promising for artificial general intelligence. With human-like
capabilities, LLMs have been used to simulate humans and serve as AI assistants
across many applications. As a result, great concern has arisen about whether
and under what circumstances LLMs think and behave like real human agents.
Rationality is among the most important concepts in assessing human behavior,
both in thinking (i.e., theoretical rationality) and in taking action (i.e.,
practical rationality). In this work, we propose the first benchmark for
evaluating the omnibus rationality of LLMs, covering a wide range of domains
and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental
results, and analysis that illuminates where LLMs converge and diverge from
idealized human rationality. We believe the benchmark can serve as a
foundational tool for both developers and users of LLMs.

</details>


### [13] [(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration](https://arxiv.org/abs/2509.14547)
*Yi Lin,Lujin Zhao,Yijie Shi*

Main category: cs.AI

TL;DR: 提出了一种先验动态框架用于自动化工作流构建，通过Q-table学习和先验决策机制，结合历史经验和任务特性，显著提升效率和适应性


<details>
  <summary>Details</summary>
Motivation: 现有自动化工作流构建方法过度依赖历史经验，在效率和适应性方面存在局限，需要更灵活地响应每个任务的独特特性

Method: 基于Q-table学习优化决策空间，结合先验决策机制评估任务进度并选择下一个执行代理，采用冷启动初始化、早停和剪枝等机制提升效率

Result: 在四个基准数据集上验证了方法的有效性，相比最先进基线平均提升4.05%，同时将工作流构建和推理成本降低至现有方法的30.68%-48.31%

Conclusion: 所提出的先验动态框架能够有效结合历史经验和任务特性，实现高效且自适应的自动化工作流构建

Abstract: Recent studies have shown that carefully designed workflows coordinating
large language models(LLMs) significantly enhance task-solving capabilities
compared to using a single model. While an increasing number of works focus on
autonomous workflow construction, most existing approaches rely solely on
historical experience, leading to limitations in efficiency and adaptability.
We argue that while historical experience is valuable, workflow construction
should also flexibly respond to the unique characteristics of each task. To
this end, we propose an a priori dynamic framework for automated workflow
construction. Our framework first leverages Q-table learning to optimize the
decision space, guiding agent decisions and enabling effective use of
historical experience. At the same time, agents evaluate the current task
progress and make a priori decisions regarding the next executing agent,
allowing the system to proactively select the more suitable workflow structure
for each given task. Additionally, we incorporate mechanisms such as cold-start
initialization, early stopping, and pruning to further improve system
efficiency. Experimental evaluations on four benchmark datasets demonstrate the
feasibility and effectiveness of our approach. Compared to state-of-the-art
baselines, our method achieves an average improvement of 4.05%, while reducing
workflow construction and inference costs to only 30.68%-48.31% of those
required by existing methods.

</details>


### [14] [SynBench: A Benchmark for Differentially Private Text Generation](https://arxiv.org/abs/2509.14594)
*Yidan Sun,Viktor Schlegel,Srinivasan Nandakumar,Iqra Zahid,Yuping Wu,Yulong Wu,Hao Li,Jie Zhang,Warren Del-Pinto,Goran Nenadic,Siew Kei Lam,Anil Anthony Bharath*

Main category: cs.AI

TL;DR: 本文研究在高风险领域如医疗和金融中，通过差分隐私技术生成合成数据，解决数据共享和隐私保护的挑战。研究包括建立评估框架、对比各种DP文本生成方法的大规模实验，以及发现公开数据集可能影响隐私保证的成员推断攻击方法。


<details>
  <summary>Details</summary>
Motivation: 高风险领域中数据共享遇到法规、机构和隐私问题的阻碍，而现有匿名化方法对非结构化文本效果不佳，需要一种具有形式隐私保证的合成数据生成方案。

Method: 采用差分隐私(DP)技术，建立包含9个领域特定数据集的综合评估框架，设计标准化的效用性和保真度指标，对比各种DP文本生成方法和不同规模的大语言模型，并开发专门针对合成文本的成员推断攻击方法。

Result: 识别出在DP约束下生成高质量领域特定合成数据仍是未解决的挑战，性能随领域复杂性增加而下降，且发现使用公开数据集可能会使声称的隐私保证失效。

Conclusion: 研究强调了在隐私敏感高风险环境中展开严格隐私审计的紧迫性，指出了开放域和专业领域评估之间的持续差距，为质量敏感领域中负责任地部署生成式AI提供了重要信息。

Abstract: Data-driven decision support in high-stakes domains like healthcare and
finance faces significant barriers to data sharing due to regulatory,
institutional, and privacy concerns. While recent generative AI models, such as
large language models, have shown impressive performance in open-domain tasks,
their adoption in sensitive environments remains limited by unpredictable
behaviors and insufficient privacy-preserving datasets for benchmarking.
Existing anonymization methods are often inadequate, especially for
unstructured text, as redaction and masking can still allow re-identification.
Differential Privacy (DP) offers a principled alternative, enabling the
generation of synthetic data with formal privacy assurances. In this work, we
address these challenges through three key contributions. First, we introduce a
comprehensive evaluation framework with standardized utility and fidelity
metrics, encompassing nine curated datasets that capture domain-specific
complexities such as technical jargon, long-context dependencies, and
specialized document structures. Second, we conduct a large-scale empirical
study benchmarking state-of-the-art DP text generation methods and LLMs of
varying sizes and different fine-tuning strategies, revealing that high-quality
domain-specific synthetic data generation under DP constraints remains an
unsolved challenge, with performance degrading as domain complexity increases.
Third, we develop a membership inference attack (MIA) methodology tailored for
synthetic text, providing first empirical evidence that the use of public
datasets - potentially present in pre-training corpora - can invalidate claimed
privacy guarantees. Our findings underscore the urgent need for rigorous
privacy auditing and highlight persistent gaps between open-domain and
specialist evaluations, informing responsible deployment of generative AI in
privacy-sensitive, high-stakes settings.

</details>


### [15] [AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production](https://arxiv.org/abs/2509.14647)
*NVJK Kartik,Garvit Sapra,Rishav Hada,Nikhil Pareek*

Main category: cs.AI

TL;DR: AgentCompass是首个专门为多智能体工作流设计的后部署监控和调试评估框架，通过结构化分析流程和双记忆系统实现持续学习，在真实部署和基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在复杂多智能体工作流中的广泛应用，现有评估方法无法有效捕捉错误、涌现行为和系统性故障带来的风险，需要专门的监控调试工具。

Method: 框架模拟专家调试者的推理过程，采用多阶段分析流程：错误识别分类、主题聚类、量化评分和策略总结，并配备情景记忆和语义记忆的双记忆系统实现持续学习。

Result: 在真实部署和TRAIL基准测试中取得最先进结果，发现了人工标注遗漏的关键问题，证明了其作为生产环境中智能体系统可靠监控和改进工具的有效性。

Conclusion: AgentCompass是一个强大、以开发者为中心的框架，能够有效监控和改进生产环境中的智能体系统可靠性，填补了后部署评估的重要空白。

Abstract: With the growing adoption of Large Language Models (LLMs) in automating
complex, multi-agent workflows, organizations face mounting risks from errors,
emergent behaviors, and systemic failures that current evaluation methods fail
to capture. We present AgentCompass, the first evaluation framework designed
specifically for post-deployment monitoring and debugging of agentic workflows.
AgentCompass models the reasoning process of expert debuggers through a
structured, multi-stage analytical pipeline: error identification and
categorization, thematic clustering, quantitative scoring, and strategic
summarization. The framework is further enhanced with a dual memory
system-episodic and semantic-that enables continual learning across executions.
Through collaborations with design partners, we demonstrate the framework's
practical utility on real-world deployments, before establishing its efficacy
against the publicly available TRAIL benchmark. AgentCompass achieves
state-of-the-art results on key metrics, while uncovering critical issues
missed in human annotations, underscoring its role as a robust,
developer-centric tool for reliable monitoring and improvement of agentic
systems in production.

</details>


### [16] [Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory](https://arxiv.org/abs/2509.14662)
*Ming Li,Nan Zhang,Chenrui Fan,Hong Jiao,Yanbin Fu,Sydney Peters,Qingshu Xu,Robert Lissitz,Tianyi Zhou*

Main category: cs.AI

TL;DR: 应用Schoenfeld的认知框架分析大型推理模型的思维结构，构建第一个细粒度机器推理分析基准，发现了认知状态迁移特征。


<details>
  <summary>Details</summary>
Motivation: 虽然大型推理模型生成了广泛的链式思维推理，但缺乏理论基础来理解这些思维的结构化特征。

Method: 采用Schoenfeld的Episode Theory认知框架，对模型生成的数学问题解决方案进行注释，使用7个认知标签（如计划、实施、验证）标记千上个句子和段落。

Result: 构建了第一个公开的细粒度机器推理分析基准，包括大规模注释语料库和详细注释指南，发现了大型推理模型的认知状态迁移动态特征。

Conclusion: 该框架为解释大型推理模型的认知提供了理论基础，能够支持未来更可控制和透明的推理系统研究。

Abstract: While Large Reasoning Models (LRMs) generate extensive chain-of-thought
reasoning, we lack a principled framework for understanding how these thoughts
are structured. In this paper, we introduce a novel approach by applying
Schoenfeld's Episode Theory, a classic cognitive framework for human
mathematical problem-solving, to analyze the reasoning traces of LRMs. We
annotated thousands of sentences and paragraphs from model-generated solutions
to math problems using seven cognitive labels (e.g., Plan, Implement, Verify).
The result is the first publicly available benchmark for the fine-grained
analysis of machine reasoning, including a large annotated corpus and detailed
annotation guidebooks. Our preliminary analysis reveals distinct patterns in
LRM reasoning, such as the transition dynamics between cognitive states. This
framework provides a theoretically grounded methodology for interpreting LRM
cognition and enables future work on more controllable and transparent
reasoning systems.

</details>


### [17] [RationAnomaly: Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning](https://arxiv.org/abs/2509.14693)
*Song Xu,Yilun Liu,Minggui He,Mingchen Dai,Ziang Chen,Chunguang Zhao,Jingzhou Du,Shimin Tao,Weibin Meng,Shenglin Zhang,Yongqian Sun,Boxing Chen,Daimeng Wei*

Main category: cs.AI

TL;DR: RationAnomaly是一个结合思维链微调和强化学习的日志异常检测框架，通过专家修正的高质量数据集和多方位的奖励函数，在准确性和逻辑一致性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有日志异常检测方法存在局限性：传统深度学习模型缺乏可解释性和泛化能力，而基于大语言模型的方法存在不可靠性和事实错误的问题。

Method: 首先通过思维链引导的监督微调注入专家级推理模式，使用专家驱动过程修正的高质量数据集；然后通过具有多方位奖励函数的强化学习阶段优化准确性和逻辑一致性，有效减少幻觉。

Result: RationAnomaly在关键基准测试中实现了优越的F1分数，同时提供透明、逐步的分析输出，优于最先进的基线方法。

Conclusion: 该框架成功解决了现有方法的局限性，提供了更可靠、可解释的日志异常检测解决方案，并发布了相应的代码和数据集资源。

Abstract: Logs constitute a form of evidence signaling the operational status of
software systems. Automated log anomaly detection is crucial for ensuring the
reliability of modern software systems. However, existing approaches face
significant limitations: traditional deep learning models lack interpretability
and generalization, while methods leveraging Large Language Models are often
hindered by unreliability and factual inaccuracies. To address these issues, we
propose RationAnomaly, a novel framework that enhances log anomaly detection by
synergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our
approach first instills expert-like reasoning patterns using CoT-guided
supervised fine-tuning, grounded in a high-quality dataset corrected through a
rigorous expert-driven process. Subsequently, a reinforcement learning phase
with a multi-faceted reward function optimizes for accuracy and logical
consistency, effectively mitigating hallucinations. Experimentally,
RationAnomaly outperforms state-of-the-art baselines, achieving superior
F1-scores on key benchmarks while providing transparent, step-by-step
analytical outputs. We have released the corresponding resources, including
code and datasets.

</details>


### [18] [The NazoNazo Benchmark: A Cost-Effective and Extensible Test of Insight-Based Reasoning in LLMs](https://arxiv.org/abs/2509.14704)
*Masaharu Mizumoto,Dat Nguyen,Zhiheng Han,Jiyuan Fang,Heyuan Guan,Xingfu Li,Naoya Shiraishi,Xuyang Tian,Yo Nakawake,Le Minh Nguyen*

Main category: cs.AI

TL;DR: Nazonazo是一个基于日本儿童谜语构建的成本效益高、可扩展的基准测试，用于评估LLM的洞察式推理能力，发现除GPT-5外所有模型都无法达到人类水平，并揭示了模型验证失败的元认知弱点。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估面临基准饱和和污染问题，需要开发成本效益高、可扩展且易于更新的评估基准来测试洞察式推理能力。

Method: 使用日本儿童谜语构建基准测试（120个谜题），评估38个前沿模型和126名成年人，通过候选追踪分析思维日志来识别验证失败案例。

Result: 人类平均准确率达到52.9%，除GPT-5外所有模型都无法达到人类水平；推理模型显著优于非推理模型，模型大小与准确率无可靠关联；发现大量验证失败案例。

Conclusion: Nazonazo提供了一个成本效益高、可扩展且易于更新的基准格式，解决了当前评估危机，同时揭示了模型在元认知方面的系统性弱点，为未来控制和校准方法提供了明确目标。

Abstract: Benchmark saturation and contamination undermine confidence in LLM
evaluation. We present Nazonazo, a cost-effective and extensible benchmark
built from Japanese children's riddles to test insight-based reasoning. Items
are short (mostly one sentence), require no specialized domain knowledge, and
can be generated at scale, enabling rapid refresh of blind sets when leakage is
suspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No
model except for GPT-5 is comparable to human performance, which achieves a
52.9% mean accuracy. Model comparison on extended 201 items shows that
reasoning models significantly outperform non-reasoning peers, while model size
shows no reliable association with accuracy. Beyond aggregate accuracy, an
informal candidate-tracking analysis of thought logs reveals many cases of
verification failure: models often produce the correct solution among
intermediate candidates yet fail to select it as the final answer, which we
illustrate with representative examples observed in multiple models. Nazonazo
thus offers a cost-effective, scalable, and easily renewable benchmark format
that addresses the current evaluation crisis while also suggesting a recurrent
meta-cognitive weakness, providing clear targets for future control and
calibration methods.

</details>


### [19] [Enhancing Retrieval Augmentation via Adversarial Collaboration](https://arxiv.org/abs/2509.14750)
*Letian Zhang,Guanghao Meng,Xudong Ren,Yiming Wang,Shu-Tao Xia*

Main category: cs.AI

TL;DR: AC-RAG框架通过对抗协作机制解决RAG中的检索幻觉问题，使用检测器和解析器两个异构代理在调解器指导下进行对抗性协作，显著提升检索准确性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决检索增强生成(RAG)中的检索幻觉问题，即微调模型无法识别和处理低质量检索文档，从而影响性能的问题。

Method: 提出对抗协作RAG(AC-RAG)框架，包含两个异构代理：通用检测器识别知识差距，领域专家解析器提供精确解决方案，在调解器指导下进行对抗性协作迭代过程。

Result: 大量实验表明AC-RAG显著提高了检索准确性，在各种垂直领域中优于最先进的RAG方法。

Conclusion: AC-RAG框架通过对抗协作机制有效解决了RAG中的检索幻觉问题，为领域特定LLMs提供了更可靠的检索增强生成解决方案。

Abstract: Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.

</details>


### [20] [OpenLens AI: Fully Autonomous Research Agent for Health Infomatics](https://arxiv.org/abs/2509.14778)
*Yuxiao Cheng,Jinli Suo*

Main category: cs.AI

TL;DR: OpenLens AI是一个专门为健康信息学设计的全自动研究框架，集成了文献综述、数据分析、代码生成和论文撰写等专业代理，通过视觉语言反馈和质控机制解决现有LLM代理在医学可视化和领域特定质量要求方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 健康信息学研究具有数据模态多样、知识快速扩展和需要整合生物医学科学、数据分析和临床实践的特点，现有LLM代理系统缺乏医学可视化解释机制且忽视领域特定质量要求，无法满足健康信息学研究需求。

Method: 开发OpenLens AI框架，集成专门代理处理文献综述、数据分析、代码生成和论文准备，通过视觉语言反馈增强医学可视化能力，并建立质量控制机制确保可重复性，自动化整个研究流程生成可发表的LaTeX论文。

Result: 构建了一个完全自动化的研究框架，能够生成具有透明可追溯工作流程的出版就绪LaTeX论文，为健康信息学研究提供了领域适配的解决方案。

Conclusion: OpenLens AI通过专业代理集成和视觉语言反馈机制，成功解决了现有LLM代理在健康信息学应用中的局限性，为自动化健康信息学研究提供了有效的领域特定框架。

Abstract: Health informatics research is characterized by diverse data modalities,
rapid knowledge expansion, and the need to integrate insights across biomedical
science, data analytics, and clinical practice. These characteristics make it
particularly well-suited for agent-based approaches that can automate knowledge
exploration, manage complex workflows, and generate clinically meaningful
outputs. Recent progress in large language model (LLM)-based agents has
demonstrated promising capabilities in literature synthesis, data analysis, and
even end-to-end research execution. However, existing systems remain limited
for health informatics because they lack mechanisms to interpret medical
visualizations and often overlook domain-specific quality requirements. To
address these gaps, we introduce OpenLens AI, a fully automated framework
tailored to health informatics. OpenLens AI integrates specialized agents for
literature review, data analysis, code generation, and manuscript preparation,
enhanced by vision-language feedback for medical visualization and quality
control for reproducibility. The framework automates the entire research
pipeline, producing publication-ready LaTeX manuscripts with transparent and
traceable workflows, thereby offering a domain-adapted solution for advancing
health informatics research.

</details>


### [21] [Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition and Patient Outcomes in an Irish Hospital with Transformers](https://arxiv.org/abs/2509.14942)
*Minh-Khoi Pham,Tai Tan Mai,Martin Crane,Rob Brennan,Marie E. Ward,Una Geary,Declan Byrne,Brian O Connell,Colm Bergin,Donncha Creagh,Nick McDonald,Marija Bezbradica*

Main category: cs.AI

TL;DR: 这研究提出了一种可解释的AI框架，使用Transformer模型分析医疗电子记录，预测股胶霉素产生肠权菌对患者结局的影响，TabTransformer模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 股胶霉素产生肠权菌(CPE)是医院感染控制的重要挑战，但现有研究对其风险预测模型的探索不足，特别是缺乏现代深度学习方法的应用。

Method: 分析爱尔兰急诊医院的患者数据，包括诊断代码、病区转换、人口统计学、感染相关变量和接触网络特征。对比Transformer基础架构与传统机器学习模型，并应用可解释AI技术解释模型决策。

Result: TabTransformer模型在多个临床预测任务中表现最佳，特别是在CPE感染预测上(AUROC和敏感度)。感染相关特征、历史医院暴露、入院情况和网络中心性指标对预测重要。

Conclusion: 该研究提供了一个健壮且可解释的AI框架，能够从复杂的医疗电子记录中识别关键风险因素并预测CPE相关结局，Transformer模型的优秀表现和多样化的临床及网络特征的重要性得到了验证。

Abstract: Carbapenemase-Producing Enterobacteriace poses a critical concern for
infection prevention and control in hospitals. However, predictive modeling of
previously highlighted CPE-associated risks such as readmission, mortality, and
extended length of stay (LOS) remains underexplored, particularly with modern
deep learning approaches. This study introduces an eXplainable AI modeling
framework to investigate CPE impact on patient outcomes from Electronic Medical
Records data of an Irish hospital. We analyzed an inpatient dataset from an
Irish acute hospital, incorporating diagnostic codes, ward transitions, patient
demographics, infection-related variables and contact network features. Several
Transformer-based architectures were benchmarked alongside traditional machine
learning models. Clinical outcomes were predicted, and XAI techniques were
applied to interpret model decisions. Our framework successfully demonstrated
the utility of Transformer-based models, with TabTransformer consistently
outperforming baselines across multiple clinical prediction tasks, especially
for CPE acquisition (AUROC and sensitivity). We found infection-related
features, including historical hospital exposure, admission context, and
network centrality measures, to be highly influential in predicting patient
outcomes and CPE acquisition risk. Explainability analyses revealed that
features like "Area of Residence", "Admission Ward" and prior admissions are
key risk factors. Network variables like "Ward PageRank" also ranked highly,
reflecting the potential value of structural exposure information. This study
presents a robust and explainable AI framework for analyzing complex EMR data
to identify key risk factors and predict CPE-related outcomes. Our findings
underscore the superior performance of the Transformer models and highlight the
importance of diverse clinical and network features.

</details>


### [22] [Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems](https://arxiv.org/abs/2509.14956)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的多自主体系统安全架构，通过切入式监视代理和协调代理的双层设计，提高系统的安全性、可靠性和可观测性。


<details>
  <summary>Details</summary>
Motivation: 解决多自主体系统中的安全风险，包括提示注入、幽灵生成、隐私泄漏、协调攻击等。需要一种动态适应的防御机制来确保系统整体性。

Method: 设计了双层安全架构：1）切入式监视代理（Sentinel Agents），使用LLM语义分析、行为分析、检索增强验证等技术监控代理通信；2）协调代理（Coordinator Agent），负责政策管理、威胁响应和系统整合性维护。

Result: 在多自主体对话环境中注入162个综合攻击（提示注入、幽灵生成、数据泄漏），切入式监视代理成功检测到所有攻击尝试，验证了监测方法的可行性。

Conclusion: 该架构能够提供动态适应的防御机制，有效应对多种安全威胁，同时提高系统可观测性和遵规性，支持政策随时间演进。

Abstract: This paper proposes a novel architectural framework aimed at enhancing
security and reliability in multi-agent systems (MAS). A central component of
this framework is a network of Sentinel Agents, functioning as a distributed
security layer that integrates techniques such as semantic analysis via large
language models (LLMs), behavioral analytics, retrieval-augmented verification,
and cross-agent anomaly detection. Such agents can potentially oversee
inter-agent communications, identify potential threats, enforce privacy and
access controls, and maintain comprehensive audit records. Complementary to the
idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator
Agent supervises policy implementation, and manages agent participation. In
addition, the Coordinator also ingests alerts from Sentinel Agents. Based on
these alerts, it can adapt policies, isolate or quarantine misbehaving agents,
and contain threats to maintain the integrity of the MAS ecosystem. This
dual-layered security approach, combining the continuous monitoring of Sentinel
Agents with the governance functions of Coordinator Agents, supports dynamic
and adaptive defense mechanisms against a range of threats, including prompt
injection, collusive agent behavior, hallucinations generated by LLMs, privacy
breaches, and coordinated multi-agent attacks. In addition to the architectural
design, we present a simulation study where 162 synthetic attacks of different
families (prompt injection, hallucination, and data exfiltration) were injected
into a multi-agent conversational environment. The Sentinel Agents successfully
detected the attack attempts, confirming the practical feasibility of the
proposed monitoring approach. The framework also offers enhanced system
observability, supports regulatory compliance, and enables policy evolution
over time.

</details>


### [23] [Set Contribution Functions for Quantitative Bipolar Argumentation and their Principles](https://arxiv.org/abs/2509.14963)
*Filip Naudot,Andreas Brännström,Vicenç Torra,Timotheus Kampik*

Main category: cs.AI

TL;DR: 本文提出了量化双极论证图中一组论证对目标论证最终强度贡献的函数，是现有单论证贡献函数的泛化，并进行了基于原则的分析。


<details>
  <summary>Details</summary>
Motivation: 现有的论证贡献分析主要关注单个论证的贡献，缺乏对论证集合整体贡献的量化方法，需要开发能够捕捉论证间交互作用的集合贡献函数。

Method: 提出了集合贡献函数作为单论证贡献函数的泛化，建立了相应的原则框架进行分析，并引入了针对集合特性的新原则来研究论证间的交互属性。

Result: 开发了通用的集合贡献函数框架，建立了相应的分析原则，并通过推荐系统应用场景展示了不同函数原则的实际表现。

Conclusion: 集合贡献函数为分析论证集合的整体影响提供了有效工具，新的集合特定原则能够更好地捕捉论证间的交互效应，在推荐系统等应用中具有实用价值。

Abstract: We present functions that quantify the contribution of a set of arguments in
quantitative bipolar argumentation graphs to (the final strength of) an
argument of interest, a so-called topic. Our set contribution functions are
generalizations of existing functions that quantify the contribution of a
single contributing argument to a topic. Accordingly, we generalize existing
contribution function principles for set contribution functions and provide a
corresponding principle-based analysis. We introduce new principles specific to
set-based functions that focus on properties pertaining to the interaction of
arguments within a set. Finally, we sketch how the principles play out across
different set contribution functions given a recommendation system application
scenario.

</details>


### [24] [A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making](https://arxiv.org/abs/2509.14998)
*Xiao Wu,Ting-Zhu Huang,Liang-Jian Deng,Yanyuan Qiao,Imran Razzak,Yutong Xie*

Main category: cs.AI

TL;DR: KAMAC是一个知识驱动的自适应多智能体协作框架，通过动态组建专家团队来解决复杂医疗诊断问题，在癌症预后等复杂场景中显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协作框架采用静态预分配角色，限制了适应性和动态知识整合能力，无法有效处理复杂临床场景中不断变化的诊断需求

Method: KAMAC从初始专家开始，通过知识驱动讨论识别知识缺口，动态招募额外专家填补空缺，支持灵活可扩展的协作，最终通过审查更新后的智能体评论做出决策

Result: 在两个真实医疗基准测试中，KAMAC显著优于单智能体和先进多智能体方法，特别是在需要动态跨专业知识的复杂临床场景（如癌症预后）中表现突出

Conclusion: KAMAC框架通过动态团队组建和知识驱动协作，有效解决了复杂医疗决策中的知识整合问题，为多智能体系统在医疗领域的应用提供了新思路

Abstract: Medical decision-making often involves integrating knowledge from multiple
clinical specialties, typically achieved through multidisciplinary teams.
Inspired by this collaborative process, recent work has leveraged large
language models (LLMs) in multi-agent collaboration frameworks to emulate
expert teamwork. While these approaches improve reasoning through agent
interaction, they are limited by static, pre-assigned roles, which hinder
adaptability and dynamic knowledge integration. To address these limitations,
we propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration
framework that enables LLM agents to dynamically form and expand expert teams
based on the evolving diagnostic context. KAMAC begins with one or more expert
agents and then conducts a knowledge-driven discussion to identify and fill
knowledge gaps by recruiting additional specialists as needed. This supports
flexible, scalable collaboration in complex clinical scenarios, with decisions
finalized through reviewing updated agent comments. Experiments on two
real-world medical benchmarks demonstrate that KAMAC significantly outperforms
both single-agent and advanced multi-agent methods, particularly in complex
clinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty
expertise. Our code is publicly available at:
https://github.com/XiaoXiao-Woo/KAMAC.

</details>


### [25] [Calibrated Generative AI as Meta-Reviewer: A Systemic Functional Linguistics Discourse Analysis of Reviews of Peer Reviews](https://arxiv.org/abs/2509.15035)
*Gabriela C. Zapata,Bill Cope,Mary Kalantzis,Duane Searsmith*

Main category: cs.AI

TL;DR: 研究探讨了使用生成式AI为研究生在线课程的同伴评审提供机器生成的元评审，以支持形成性评估。基于系统功能语言学和评价理论分析发现，AI反馈能够近似有效人类反馈的关键修辞和关系特征。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI如何通过机器生成的元评审来支持在线教育中的形成性评估，特别是在研究生课程的同伴评审环节中提供辅助反馈。

Method: 采用系统功能语言学和评价理论框架，分析了120个AI生成的元评审，从概念、人际和文本三个维度考察AI反馈的意义构建方式。

Result: AI反馈能够平衡表扬与建设性批评，与评分标准保持一致，采用结构化呈现方式并突出学生主体性，能够提供明确的指导性同时保持支持性立场。

Conclusion: AI元反馈具有搭建反馈素养支架和增强学习者参与同伴评审的潜力，能够模拟有效人类反馈的关键质量特征。

Abstract: This study investigates the use of generative AI to support formative
assessment through machine generated reviews of peer reviews in graduate online
courses in a public university in the United States. Drawing on Systemic
Functional Linguistics and Appraisal Theory, we analyzed 120 metareviews to
explore how generative AI feedback constructs meaning across ideational,
interpersonal, and textual dimensions. The findings suggest that generative AI
can approximate key rhetorical and relational features of effective human
feedback, offering directive clarity while also maintaining a supportive
stance. The reviews analyzed demonstrated a balance of praise and constructive
critique, alignment with rubric expectations, and structured staging that
foregrounded student agency. By modeling these qualities, AI metafeedback has
the potential to scaffold feedback literacy and enhance leaner engagement with
peer review.

</details>


### [26] [From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support](https://arxiv.org/abs/2509.15084)
*Doreen Jirak,Pieter Maes,Armeen Saroukanoff,Dirk van Rooy*

Main category: cs.AI

TL;DR: 海上自主技术中解释性AI的重要性，提出基于海上领域专业人员需求的调查方法


<details>
  <summary>Details</summary>
Motivation: 在复杂动态的海上环境中，AI系统的透明性和可解释性对于建立人机协作信任至关重要，需要从用户角度研究海上专业人员对信任、易用性和解释性的需求

Method: 提出一种基于领域特定需求的调查方法，用于收集海上专业人员对解释性AI系统的感知和需求

Result: 该研究为开发更符合海上作业特点的用户中心解释性AI系统提供了指导框架

Conclusion: 解释性AI是海上领域有效人机协作的基础，用户中心的调查方法能够促进更适合海上专业人员需求的XAI系统发展

Abstract: As autonomous technologies increasingly shape maritime operations,
understanding why an AI system makes a decision becomes as crucial as what it
decides. In complex and dynamic maritime environments, trust in AI depends not
only on performance but also on transparency and interpretability. This paper
highlights the importance of Explainable AI (XAI) as a foundation for effective
human-machine teaming in the maritime domain, where informed oversight and
shared understanding are essential. To support the user-centered integration of
XAI, we propose a domain-specific survey designed to capture maritime
professionals' perceptions of trust, usability, and explainability. Our aim is
to foster awareness and guide the development of user-centric XAI systems
tailored to the needs of seafarers and maritime teams.

</details>


### [27] [Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment](https://arxiv.org/abs/2509.15172)
*Ankur Samanta,Akshayaa Magesh,Youliang Yu,Runzhe Wu,Ayush Jain,Daniel Jiang,Boris Vidolov,Paul Sajda,Yonathan Efroni,Kaveh Hassani*

Main category: cs.AI

TL;DR: MACA是一种强化学习框架，通过多智能体辩论的多数/少数结果来训练语言模型选择与内部共识一致的推理路径，显著提升模型的自一致性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型是不一致的推理者，经常对相同提示生成矛盾的回答。现有推理时方法无法解决核心问题：模型难以可靠选择导致一致结果的推理路径。

Method: 提出多智能体共识对齐(MACA)框架，使用强化学习后训练模型，通过多智能体辩论的多数/少数结果来偏好与内部共识一致的推理轨迹。

Result: 在自一致性(+27.6% GSM8K)、单智能体推理(+23.7% MATH)、采样推理(+22.4% Pass@20 MATH)和多智能体集成决策(+42.7% MathQA)方面取得显著提升，在未见基准上也有强泛化能力。

Conclusion: MACA实现了稳健的自对齐，更可靠地释放语言模型的潜在推理能力，通过审议式交换创造比单轮多数投票更丰富的共识信号。

Abstract: Language Models (LMs) are inconsistent reasoners, often generating
contradictory responses to identical prompts. While inference-time methods can
mitigate these inconsistencies, they fail to address the core problem: LMs
struggle to reliably select reasoning pathways leading to consistent outcomes
under exploratory sampling. To address this, we formalize self-consistency as
an intrinsic property of well-aligned reasoning models and introduce
Multi-Agent Consensus Alignment (MACA), a reinforcement learning framework that
post-trains models to favor reasoning trajectories aligned with their internal
consensus using majority/minority outcomes from multi-agent debate. These
trajectories emerge from deliberative exchanges where agents ground reasoning
in peer arguments, not just aggregation of independent attempts, creating
richer consensus signals than single-round majority voting. MACA enables agents
to teach themselves to be more decisive and concise, and better leverage peer
insights in multi-agent settings without external supervision, driving
substantial improvements across self-consistency (+27.6% on GSM8K),
single-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4%
Pass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA).
These findings, coupled with strong generalization to unseen benchmarks (+16.3%
on GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more
reliably unlocks latent reasoning potential of language models.

</details>


### [28] [Generalizable Geometric Image Caption Synthesis](https://arxiv.org/abs/2509.15217)
*Yue Xin,Wenyuan Wang,Rui Pan,Ruida Wang,Howard Meng,Renjie Pi,Shizhe Diao,Tong Zhang*

Main category: cs.AI

TL;DR: 通过引入基于验证奖励的强化学习(RLVR)方法来生成高质量的几何图像-文本数据集，提升多模态大语言模型在几何问题解决和一般理性能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂几何问题上表现就差，主要因为缺乏高质量的几何图像-文本数据集，而传统模板化数据生成方法无法满足模板外问题的需求。

Method: 提出RLVR方法，通过基于数学问题解决任务的奖励信号来精炼几何图像的描述文本，从50个基础几何关系生成数据集。

Result: 在MathVista和MathVerse的非几何图像任务中，统计、算术、代数和数值任务的准确率提升2.8%-4.8%；在MMMU的艺术、设计、技术和工程任务中提升2.4%-3.9%。

Conclusion: RLVR方法能够生成高质量的几何数据集，不仅提升模型在几何问题上的表现，还能增强多模态大语言模型的一般理性能力。

Abstract: Multimodal large language models have various practical applications that
demand strong reasoning abilities. Despite recent advancements, these models
still struggle to solve complex geometric problems. A key challenge stems from
the lack of high-quality image-text pair datasets for understanding geometric
images. Furthermore, most template-based data synthesis pipelines typically
fail to generalize to questions beyond their predefined templates. In this
paper, we bridge this gap by introducing a complementary process of
Reinforcement Learning with Verifiable Rewards (RLVR) into the data generation
pipeline. By adopting RLVR to refine captions for geometric images synthesized
from 50 basic geometric relations and using reward signals derived from
mathematical problem-solving tasks, our pipeline successfully captures the key
features of geometry problem-solving. This enables better task generalization
and yields non-trivial improvements. Furthermore, even in out-of-distribution
scenarios, the generated dataset enhances the general reasoning capabilities of
multimodal large language models, yielding accuracy improvements of
$2.8\%\text{-}4.8\%$ in statistics, arithmetic, algebraic, and numerical tasks
with non-geometric input images of MathVista and MathVerse, along with
$2.4\%\text{-}3.9\%$ improvements in Art, Design, Tech, and Engineering tasks
in MMMU.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [29] [Resource Allocation for Mutualistic Symbiotic Radio with Hybrid Active-Passive Communications](https://arxiv.org/abs/2509.14567)
*Hong Guo,Yinghui Ye,Haijian Sun,Liqin Shi,Rose Qingyang Hu*

Main category: cs.IT

TL;DR: 本文提出一种新型互益性调制后散射通信系统，通过混合主动/被动传输和动态SIC排序优化，显著提高二级用户的总传输速率。


<details>
  <summary>Details</summary>
Motivation: 解决传统互益性调制后散射通信中二级用户传输速率极低的问题，通过混合主动/被动传输方式来提升性能。

Method: 提出HAPC混合主动/被动传输方案，建立固定和动态SIC排序两个优化问题，采用SCA和BCD迭代算法求解。

Result: 模拟结果显示新系统在同等约束下显著提升二级用户速率，动态SIC排序在高主用户速率要求时优于固定排序。

Conclusion: 该方案有效解决了互益性调制后散射通信中二级用户速率低的问题，为实际应用提供了可行解决方案。

Abstract: Mutualistic SR is a communication paradigm that offers high spectrum
efficiency and low power consumption, where the SU transmits information by
modulating and backscattering the PT's signal, enabling shared use of spectrum
and power with PT. In return, the PT's performance can be enhanced by SU's
backscattered signal, forming a mutualistic relationship. However, the low
modulation rate causes extremely inferior transmission rates for SUs. To
improve the SU transmission rate, this paper proposes a new mutualistic SR with
HAPC to explore the tradeoff between BC and AC in terms of power consumption
and transmission rate, enabling each SU to transmit signal via passive BC and
AC alternatively. We propose two problems to maximize the total rate of all SUs
under the fixed and dynamic SIC ordering, respectively. The fixed SIC
ordering-based problem is to jointly optimize the SUs' reflection coefficients,
the transmit power of each SU during AC, and the time allocation for each SU
during BC and AC, subject to the energy causality constraint and the PT's
transmission rate gain constraint. In addition to pondering the constraints
involved in the fixed SIC ordering-based problem, the dynamic SIC
ordering-based problem, which is a mixed integer programming one, further
considers the SIC ordering constraint. The above two problems are solved by our
proposed SCA-based and BCD-based iterative algorithms, respectively. Simulation
results demonstrate that: 1) the proposed mutualistic SR system outperforms
traditional designs in terms of the rates achieved by SUs under the same
constraints; 2) the total rate of all SUs under the dynamic SIC ordering is
larger than that of the fixed one when the PT's minimum rate gain is high, and
becomes nearly identical when the PT's minimum rate gain is low.

</details>


### [30] [Version Age of Information with Contact Mobility in Gossip Networks](https://arxiv.org/abs/2509.15184)
*Irtiza Hasan,Ahmed Arafa*

Main category: cs.IT

TL;DR: 研究分析了接触移动性对gossip网络中信息新鲜度的影响，使用SHS框架分析不同拓扑结构，发现移动性在断开和全连接网络中都能改善信息新鲜度，并通过优化问题平衡移动成本和版本年龄。


<details>
  <summary>Details</summary>
Motivation: 研究移动节点通过接触移动性获取信息对gossip网络信息传播的影响，旨在提高网络中信息的新鲜度。

Method: 使用随机混合系统(SHS)框架分析不同网络拓扑和移动性缩放，通过数学分析平均版本年龄缩放并进行仿真验证，最后通过优化问题最小化版本年龄和移动成本的加权和。

Result: 接触移动性能显著改善网络信息新鲜度，在断开和全连接网络中都能降低平均版本年龄，优化后的移动成本配置能进一步提升性能。

Conclusion: 接触移动性是提高gossip网络信息新鲜度的有效机制，通过适当的移动成本优化可以显著改善网络性能。

Abstract: A gossip network is considered in which a source node updates its status
while other nodes in the network aim at keeping track of it as it varies over
time. Information gets disseminated by the source sending status updates to the
nodes, and the nodes gossiping with each other. In addition, the nodes in the
network are mobile, and can move to other nodes to get information, which we
term contact mobility. The goal for the nodes is to remain as fresh as
possible, i.e., to have the same information as the source's. To evaluate the
freshness of information, we use the Version Age-of-Information (VAoI) metric,
defined as the difference between the version of information available at a
given node and that at the source. We analyze the effect of contact mobility on
information dissemination in the gossip network using a Stochastic Hybrid
System (SHS) framework for different topologies and mobility scalings with
increasing number of nodes. It is shown that with the presence of contact
mobility the freshness of the network improves in both ends of the network
connectivity spectrum: disconnected and fully connected gossip networks. We
mathematically analyze the average version age scalings and validate our
theoretical results via simulations. Finally, we incorporate the cost of
mobility for the network by formulating and solving an optimization problem
that minimizes a weighted sum of version age and mobility cost. Our results
show that contact mobility, with optimized mobility cost, improves the average
version age in the network.

</details>


### [31] [Joint Scheduling and Multiflow Maximization in Wireless Networks](https://arxiv.org/abs/2509.14582)
*Yanxiao Liu,Shenghao Yang,Cheuk Ting Li*

Main category: cs.IT

TL;DR: 本文研究了6G网络中的最大多流问题，提出了一种高效算法，能够在不需要整个调度速率区域的情况下联合计算调度速率和求解最大多流，输出准确的最优解。


<details>
  <summary>Details</summary>
Motivation: 在6G移动网络发展中，需要集成大量多维平台设备，因此需要理论上理解大规模网络的极限性能。传统方法在调度部分存在NP难问题，导致在大型网络中计算费用过高。

Method: 提出了一种高效算法，能够联合计算调度速率区域并同时求解最大多流问题。算法通过有限迭代次数确保输出最优解，且不需要先计算整个调度速率区域。

Result: 理论证明了算法总是在有限迭代次数内输出最优解。模拟结果显示，该方法在各种情况下都显著优于传统方法。

Conclusion: 该框架适用于多源多江网络中的多播多播问题，并且通过图形框架可以扩展到传播延迟较大的场景（如水下网络），利用延迟来改善调度速率区域。

Abstract: Towards the development of 6G mobile networks, it is promising to integrate a
large number of devices from multi-dimensional platforms, and it is crucial to
have a solid understanding of the theoretical limits of large-scale networks.
We revisit a fundamental problem at the heart of network communication theory:
the maximum multiflow (MMF) problem in multi-hop networks, with network coding
performed at intermediate nodes. To derive the exact-optimal solution to the
MMF problem (as opposed to approximations), conventional methods usually
involve two steps: first calculate the scheduling rate region, and then find
the maximum multiflow that can be supported by the achievable link rates.
However, the NP-hardness of the scheduling part makes solving the MMF problem
in large networks computationally prohibitive. In this paper, while still
focusing on the exact-optimal solution, we provide efficient algorithms that
can jointly calculate the scheduling rate region and solve the MMF problem,
thereby outputting optimal values without requiring the entire scheduling rate
region. We theoretically prove that our algorithms always output optimal
solutions in a finite number of iterations, and we use various simulation
results to demonstrate our advantages over conventional approaches. Our
framework is applicable to the most general scenario in multi-source multi-sink
networks: the multiple multicast problem with network coding. Moreover, by
employing a graphical framework, we show that our algorithm can be extended to
scenarios where propagation delays are large (e.g., underwater networks), in
which recent studies have shown that the scheduling rate region can be
significantly improved by utilizing such delays.

</details>


### [32] [Inference of unknown syndrome values in the implementation of the Berlekamp-Massey-Sakata algorithm](https://arxiv.org/abs/2509.14835)
*J. J. Bernal,J. J. Simón*

Main category: cs.IT

TL;DR: 研究代数几何码中实现Berlekamp-Massey-Sakata算法所需的缺失校验子值问题，并将结果应用于解决阿贝尔码的校验子校正


<details>
  <summary>Details</summary>
Motivation: 代数几何码在实现Berlekamp-Massey-Sakata算法时需要完整的校验子值，但实际应用中可能存在缺失的校验子值，这影响了Feng-Rao多数投票算法的有效实施

Method: 研究如何找到实现Berlekamp-Massey-Sakata算法所需的缺失校验子值，重点关注Feng-Rao多数投票方法在代数几何码中的应用

Result: 提出了解决缺失校验子值问题的方法，并将研究成果成功应用于阿贝尔码的校验子校正问题

Conclusion: 该研究为代数几何码中校验子缺失问题提供了有效解决方案，特别是在阿贝尔码的校验子校正方面具有重要应用价值

Abstract: We study the problem of finding those missing syndrome values that are needed
to implment the Berlekamp-Massey-Sakata algorithm as the Feng-Rao Majority
Voting for algebraic geometric codes. We apply our results to solve syndrome
correction in abelian codes.

</details>


### [33] [Beam Squint Assisted Joint Angle-Distance Localization for Near-Field Communications](https://arxiv.org/abs/2509.14850)
*Aibiao Zhang,Weizheng Zhang,Chiya Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于TTD和PS的波束倾斜辅助联合角度-距离定位方案，通过可控的JAD轨迹实现单次扫描获取目标角度和距离，采用粗到精的两阶段估计器实现高效定位。


<details>
  <summary>Details</summary>
Motivation: 解决6G系统中由相位偏移器波束成形在宽带近场场景中引起的显著近场波束倾斜问题，实现厘米级甚至毫米级精度的实时定位需求。

Method: 使用TTD单元和PS合成可控的联合角度-距离轨迹，建立子载波与空间位置的唯一映射；设计粗到精两阶段估计器：基于子载波功率峰值的粗估计阶段和基于空间平滑与近场MUSIC的精细化阶段。

Result: 仿真结果表明该方法在单用户和多用户场景下均能实现高精度和鲁棒性，显著优于传统的两步方法。

Conclusion: 该方法为6G传感和定位部署提供了有前景的解决方案，理论上证明了MUSIC空间谱峰的正确性和唯一性，并推导了联合角度-距离估计的CRLB下界。

Abstract: With the advent of extremely large-scale MIMO (XL-MIMO), mmWave/THz bands and
ultra-wideband transmission, future 6G systems demand real-time positioning
with centimeter or even millimeter level accuracy. This paper addresses the
pronounced near-field beam squint problem caused by phase shifter based
beamforming in wideband near-field scenarios and proposes a beam squint
assisted joint angle-distance localization scheme. The key idea is to employ
true-time-delay (TTD) units together with phase shifters (PS) to synthesize a
controllable joint angle-distance (JAD) trajectory that establishes a unique
mapping between subcarriers and spatial locations, enabling single scan
acquisition of target angle and range. To implement this paradigm efficiently,
we design a coarse to fine two stage estimator: a low complexity coarse stage
based on subcarrier power peaks for user separation and candidate region
selection, followed by a local high resolution refinement stage that applies
spatial smoothing and near-field multiple signal classification (MUSIC) over
multiple subcarriers and fuses the resulting spectra by geometric averaging to
suppress spurious peaks. We theoretically prove the correctness and uniqueness
of the MUSIC spatial spectrum peak under the proposed near-field steering
model, and derive the Cram\'er-Rao lower bound (CRLB) for joint angle-distance
estimation. Simulation results in single and multi-user scenarios validate that
the proposed method achieves very high accuracy and robustness, significantly
outperforming conventional two-step approaches, and is promising for practical
6G sensing and localization deployments.

</details>


### [34] [On Finite-Blocklength Noisy Classical-Quantum Channel Coding With Amplitude Damping Errors](https://arxiv.org/abs/2509.14852)
*Tamás Havas,Hsuan-Yin Lin,Eirik Rosnes,Ching-Yi Lai*

Main category: cs.IT

TL;DR: 在有限码长下，朴素的无编码方法无法在量子振幅阻尼信道(ADC)上获得量子性能优势，需要结合经典纠错码和量子输入态的复杂编码策略才能实现量子性能增益


<details>
  <summary>Details</summary>
Motivation: 研究在有限码长条件下通过量子振幅阻尼信道传输经典信息的实际编码方案，探索如何在有限块长度下实现可靠的经典-量子信道编码

Method: 分析量子振幅阻尼信道(ADC)上的编码策略，比较朴素无编码方法与结合经典纠错码和量子输入态的复杂编码方案

Result: 研究发现对于任何有限块长度，朴素的无编码方法都无法在ADC上提供任何优势，只有采用复杂的编码策略才能实现量子性能增益

Conclusion: 在有限码长的经典-量子信道编码中，必须采用结合经典纠错码和量子输入态的复杂编码策略，而不能依赖简单的无编码方法

Abstract: We investigate practical finite-blocklength classical-quantum channel coding
over the quantum amplitude damping channel (ADC), aiming to transmit classical
information reliably through quantum outputs. Our findings indicate that for
any finite blocklength, a naive (uncoded) approach fails to offer any advantage
over the ADC. Instead, sophisticated encoding strategies that leverage both
classical error-correcting codes and quantum input states are crucial for
realizing quantum performance gains at finite blocklengths.

</details>


### [35] [Four classes of LCD codes from (*)-(L,P)-twisted generalized Reed-Solomon codes](https://arxiv.org/abs/2509.14878)
*Zhonghao Liang,Qunying Liao*

Main category: cs.IT

TL;DR: 本文通过定义(*)-(L,P)-TGRS码统一了先前LCD MDS码的构造方法，给出了其奇偶校验矩阵，并构造了四类LCD码


<details>
  <summary>Details</summary>
Motivation: 统一Yue等人和Wu等人关于LCD MDS码的构造方法，提供更一般化的理论框架

Method: 定义(*)-(L,P)-扭曲广义Reed-Solomon码，推导其奇偶校验矩阵，基于此构造四类线性互补对偶码

Result: 成功统一了先前的研究成果，建立了更一般的构造框架，并给出了具体的LCD码构造实例

Conclusion: 提出的(*)-(L,P)-TGRS码框架有效统一并扩展了现有的LCD MDS码构造方法，为编码理论提供了新的工具

Abstract: It's well-known that maximum distance separable codes (in short, MDS) and
linear complementary dual (in short, LCD) codes are very important in coding
theory and practice. In 2023, Yue et al. [25] constructed three classes of LCD
MDS codes via (*)-TGRS codes. Recently, Wu et al. [27] generalized the results
given by Yue et al. and constructed several classes of LCD MDS codes. In this
paper, we unify their constructions by defining the (*)-(L,P)-twisted
generalized Reed-Solomon (in short, (*)-(L,P)-TGRS) code, give the parity-check
matrix of (*)-(L,P)-TGRS codes, and then construct four classes of LCD codes.
Finally, some corresponding examples are given.

</details>


### [36] [Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space](https://arxiv.org/abs/2509.14905)
*Wenyan Ma,Lipeng Zhu,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于可移动天线(MA)的新型无线感知系统，通过天线连续移动收集感知信号，在角度估计性能上显著优于传统固定位置天线(FPA)感知。


<details>
  <summary>Details</summary>
Motivation: 传统固定天线感知系统在角度估计精度上有限，本文动机是通过天线移动来提高感知性能，并理论分析角度估计的基础性能限制。

Method: 推导了一维(1D)和二维(2D)天线移动下到达角(AoA)估计的Cramer-Rao界(CRB)，对1D情况求解了全局最优轨迹，对2D情况设计了交替优化算法来实现水平和垂直轴两个AoA估计的最小最大CRB。

Result: 数值结果显示，提出的1D/2D MA基感知方案在CRB和实际AoA估计MSE上都显著优于传统FPA基感知以及其他基准MA轨迹。设计的MA轨迹在角度域具有低相关性，有效提高了角度分辨率。

Conclusion: 可移动天线感知系统通过优化天线轨迹，能够在角度估计上实现更高的精度和分辨率，为无线感知技术提供了新的解决方案。

Abstract: In this paper, we present a new wireless sensing system utilizing a movable
antenna (MA) that continuously moves and receives sensing signals to enhance
sensing performance over the conventional fixed-position antenna (FPA) sensing.
We show that the angle estimation performance is fundamentally determined by
the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square
error (MSE) for angle-of-arrival (AoA) estimation as a function of the
trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna
movement. For the 1D case, a globally optimal trajectory that minimizes the CRB
is derived in closed form. Notably, the resulting CRB decreases cubically with
sensing time in the time-constrained regime, whereas it decreases linearly with
sensing time and quadratically with the movement line segment's length in the
space-constrained regime. For the 2D case, we aim to achieve the minimum of
maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the
horizontal and vertical axes. To this end, we design an efficient alternating
optimization algorithm that iteratively updates the MA's horizontal or vertical
coordinates with the other being fixed, yielding a locally optimal trajectory.
Numerical results show that the proposed 1D/2D MA-based sensing schemes
significantly reduce both the CRB and actual AoA estimation MSE compared to
conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as
well as various benchmark MA trajectories. Moreover, it is revealed that the
steering vectors of our designed 1D/2D MA trajectories have low correlation in
the angular domain, thereby effectively increasing the angular resolution for
achieving higher AoA estimation accuracy.

</details>


### [37] [Indoor Fluid Antenna Systems Enabled by Layout-Specific Modeling and Group Relative Policy Optimization](https://arxiv.org/abs/2509.15006)
*Tong Zhang,Qianren Li,Shuai Wang,Wanli Ni,Jiliang Zhang,Rui Wang,Kai-Kit Wong,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 流动天线系统在室内环境中通过动态优化天线位置、收发格架和功率分配来改善通信性能，提出了专门的通道模型和GRPO算法，在计算效率和性能方面都超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 室内环境中信号传播受到建筑障碍和复杂多径反射的严重影响，流动天线系统可以通过动态调整天线位置来优化通道条件和减少多径衰落。

Method: 提出了一种布局特定的通道模型和新的组相对策略优化(GRPO)算法，用于联合优化天线位置、收发格架和功率分配。

Result: 与Sionna模型相比，计算时间减少83.3%，RMSE提高3dB。GRPO算法在总速率上超过PPO等基准方法，仅需PPO计算资源的49.2%。简化为双射线模型时能得到闭形解。

Conclusion: 流动天线系统通过动态天线位置优化可以有效改善室内通信性能，提出的通道模型和GRPO算法在计算效率和性能方面都显示出显著优势。

Abstract: The fluid antenna system (FAS) revolutionizes wireless communications by
employing position-flexible antennas that dynamically optimize channel
conditions and mitigate multipath fading. This innovation is particularly
valuable in indoor environments, where signal propagation is severely degraded
due to structural obstructions and complex multipath reflections. In this
paper, we study the channel modeling and joint optimization of antenna
positioning, beamforming, and power allocation for indoor FAS. In particular,
we propose, for the first time, a layout-specific channel model and a novel
group relative policy optimization (GRPO) algorithm for indoor FAS. Compared to
the state-of-the-art Sionna model, our approach achieves an $83.3\%$ reduction
in computation time with an approximately $3$ dB increase in root-mean-square
error (RMSE). When simplified to a two-ray model, our channel model enables a
closed-form solution for the optimal antenna position, achieving near-optimal
performance. {For the joint optimization problem, the proposed GRPO algorithm
outperforms proximal policy optimization (PPO) and other baselines in sum-rate,
while requiring only 49.2\% computational resources of PPO, due to its
group-based advantage estimation.} Simulation results reveal that increasing
either the group size or trajectory length in GRPO does not yield significant
improvements in sum-rate, suggesting that these parameters can be selected
conservatively without sacrificing performance.

</details>


### [38] [Improved Constructions and Lower Bounds for Maximally Recoverable Grid Codes](https://arxiv.org/abs/2509.15013)
*Joshua Brakensiek,Manik Dhar,Sivakanth Gopi*

Main category: cs.IT

TL;DR: 本文研究最大可恢复网格码，针对m×n网格拓扑结构，在m和h为常数、n增长的情况下，提出了多项式场大小的显式构造，并给出了新的场大小下界。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注m=n的情况，此时显式构造需要指数级场大小。受实际应用驱动，本文研究m和h为常数、n增长的场景，旨在找到更实用的多项式场大小构造。

Method: 研究m×n网格拓扑的编码，每行每列有一个奇偶校验，外加h≥1个全局奇偶校验。在m和h为常数的设定下，提出了多个新的显式构造方法。

Result: 提供了多个场大小为n的多项式的显式构造，这些构造在实用场景中更加可行。同时给出了新的场大小下界结果。

Conclusion: 在m和h为常数、n增长的实用场景中，成功实现了多项式场大小的最大可恢复网格码构造，填补了先前研究的空白，并建立了相应的理论下界。

Abstract: In this paper, we continue the study of Maximally Recoverable (MR) Grid Codes
initiated by Gopalan et al. [SODA 2017]. More precisely, we study codes over an
$m \times n$ grid topology with one parity check per row and column of the grid
along with $h \ge 1$ global parity checks. Previous works have largely focused
on the setting in which $m = n$, where explicit constructions require field
size which is exponential in $n$. Motivated by practical applications, we
consider the regime in which $m,h$ are constants and $n$ is growing. In this
setting, we provide a number of new explicit constructions whose field size is
polynomial in $n$. We further complement these results with new field size
lower bounds.

</details>


### [39] [Integrated Sensing and Communication for Vehicular Networks: A Rate-Distortion Fundamental Limits of State Estimator](https://arxiv.org/abs/2509.15025)
*Lugaoze Feng,Guocheng Lv,Xunan Li,Ye Jin*

Main category: cs.IT

TL;DR: 这篇论文通过状态依赖无记录频道模型研究集成感知与通信系统，建立了感知性能的速率-失真函数，并提出了解决算法和统一的容量-速率-失真交换区域框架。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往忽略集成感知与通信系统中感知性能的量化分析，需要建立一个统一的信息论框架来同时优化通信和感知性能。

Method: 使用状态依赖无记录频道模型，建立感知性能的速率-失真函数，提出修改的Blahut-Arimoto类算法来求解，并定义容量-速率-失真交换区域。

Result: 提供了算法的收敛性证明，通过数值评估展示了编码在某些频道中对估计速率的改善效果。

Conclusion: 该研究首次在单一优化框架下统一了通信和感知的信息论结果，为集成感知与通信系统提供了理论基础。

Abstract: The state-dependent memoryless channel (SDMC) is employed to model the
integrated sensing and communication (ISAC) system for connected vehicular
networks, where the transmitter conveys messages to the receiver while
simultaneously estimating the state parameter of interest via the received echo
signals. However, the performance of sensing has often been neglected in
existing works. To address this gap, we establish the rate-distortion function
for sensing performance in the SDMC model, which is defined based on standard
information-theoretic principles to ensure clear operational meaning. In
addition, we propose a modified Blahut-Arimoto type algorithm for solving the
rate-distortion function and provide convergence proofs for the algorithm. We
further define the capacity-rate-distortion tradeoff region, which, for the
first time, unifies information-theoretic results for communication and sensing
within a single optimization framework. Finally, we numerically evaluate the
capacity-rate-distortion region and demonstrate the benefit of coding in terms
of estimation rate for certain channels.

</details>


### [40] [Distributed Batch Matrix Multiplication: Trade-Offs in Download Rate, Randomness, and Privacy](https://arxiv.org/abs/2509.15047)
*Amirhosein Morteza,Remi A. Chou*

Main category: cs.IT

TL;DR: 该论文研究分布式批量矩阵乘法中通信速率与隐私保护的权衡，特别是当矩阵B公开而矩阵A需要保密时，分析最快k个服务器响应下的隐私约束和本地随机性需求。


<details>
  <summary>Details</summary>
Motivation: 研究分布式计算中矩阵乘法的隐私保护问题，特别是在服务器可能合谋的情况下，如何平衡通信效率和隐私泄露风险。

Method: 建立数学模型分析分布式批量矩阵乘法，设定隐私约束参数α，确保任意ℓ个合谋服务器最多只能获取矩阵A的α比例信息，并研究编码器所需本地随机性与隐私的关系。

Result: 确定了矩阵为方阵时的最优权衡关系，发现了信息泄露与通信速率之间的线性关系。

Conclusion: 该研究为分布式矩阵乘法提供了隐私保护的理论框架，揭示了隐私泄露与通信效率之间的定量关系，对设计安全的分布式计算系统具有指导意义。

Abstract: We study the trade-off between communication rate and privacy for distributed
batch matrix multiplication of two independent sequences of matrices
$\mathbf{A}$ and $\mathbf{B}$ with uniformly distributed entries. In our
setting, $\mathbf{B}$ is publicly accessible by all the servers while
$\mathbf{A}$ must remain private. A user is interested in evaluating the
product $\mathbf{AB}$ with the responses from the $k$ fastest servers. For a
given parameter $\alpha \in [0, 1]$, our privacy constraint must ensure that
any set of $\ell$ colluding servers cannot learn more than a fraction $\alpha$
of $\mathbf{A}$. Additionally, we study the trade-off between the amount of
local randomness needed at the encoder and privacy. Finally, we establish the
optimal trade-offs when the matrices are square and identify a linear
relationship between information leakage and communication rate.

</details>
