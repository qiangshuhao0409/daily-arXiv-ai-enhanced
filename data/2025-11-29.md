<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 29]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Real-World Performance Evaluations of Low-Band 5G NR/4G LTE 4x4 MIMO on Commercial Smartphones](https://arxiv.org/abs/2511.20959)
*Pasapong Wongprasert,Kasidis Arunruangsirilert,Jiro Katto*

Main category: cs.NI

TL;DR: 研究评估了索尼Xperia 1 III和IV手机在泰国b28/n28频段上的4x4 MIMO实际性能，包括不同信号条件下的可靠性测试和最优条件下的吞吐量测试，并与2Rx天线设备进行对比。


<details>
  <summary>Details</summary>
Motivation: 目前市场上绝大多数商用5G手机都缺乏低频段（<1 GHz）的4x4 MIMO支持，而泰国True-H和dtac网络在b28/n28频段部署了4T4R，这为研究低频段4x4 MIMO的实际性能提供了机会。

Method: 使用索尼Xperia 1 III和IV手机，通过固件修改可配置为仅使用2个Rx端口，在不同信号条件下进行可靠性测试，在最优条件下进行最大吞吐量测试，并与仅支持2Rx天线的设备进行性能对比。

Result: 通过实验收集了4x4 MIMO和2x2 MIMO在低频段b28/n28频段的性能数据，包括可靠性表现和最大吞吐量表现。

Conclusion: 该研究为评估低频段4x4 MIMO在实际网络环境中的性能提供了实证数据，有助于了解在泰国等已部署4T4R低频段网络的地区使用支持4x4 MIMO设备的价值。

Abstract: All 3GPP-compliant commercial 5G New Radio (NR)-capable UEs on the market are equipped with 4x4 MIMO support for Mid-Band frequencies (>1.7 GHz) and above, enabling up to rank 4 MIMO transmission. This doubles the theoretical throughput compared to rank 2 MIMO and also improves reception performance. However, 4x4 MIMO support on low-band frequencies (<1 GHz) is absent in every commercial UEs, with the exception of the Xperia 1 flagship smartphones manufactured by Sony Mobile and the Xiaomi 14 Pro as of January 2024. The reason most manufacturers omit 4x4 MIMO support for low-band frequencies is likely due to design challenges or relatively small performance gains in real-world usage due to the lack of 4T4R deployment on low-band by mobile network operators around the world.
  In Thailand, 4T4R deployment on the b28/n28 (APT) band is common on True-H and dtac networks, enabling 4x4 MIMO transmission on supported UEs. In this paper, the real-world 4x4 MIMO performance on the b28/n28 (APT) band will be investigated by evaluating the reliability test under different signal conditions and the maximum throughput test by evaluating the performance under optimal conditions, using the Sony Xperia 1 III and the Sony Xperia 1 IV smartphone. Devices from other manufacturers are also used in the experiment to investigate the performance with 2Rx antennas for comparison. Through firmware modifications, the Sony Xperia 1 III and IV can be configured to use only 2 Rx ports on low-band, enabling the collection of comparative 2 Rx performance data as a reference.

</details>


### [2] [Performance Evaluation of Low-Latency Live Streaming of MPEG-DASH UHD video over Commercial 5G NSA/SA Network](https://arxiv.org/abs/2511.20961)
*Kasidis Arunruangsirilert,Bo Wei,Hang Song,Jiro Katto*

Main category: cs.NI

TL;DR: 5G SA在泰国已覆盖76%人口，相比5G NSA和LTE网络，在UHD视频实时直播中表现更优，能95%以上按时传输视频段，而LTE失败率超过20%。


<details>
  <summary>Details</summary>
Motivation: 评估5G SA在UHD视频实时直播中的性能，比较其与5G NSA和LTE网络在低延迟视频传输方面的差异。

Method: 通过MPEG-DASH在不同移动网络技术下进行UHD视频实时直播，评估丢包率、MAC吞吐量和延迟等性能指标，涵盖静止、城市移动、高速移动和理想SINR条件。

Result: 5G SA在所有情况下都能95%以上成功按时传输UHD视频段，5G NSA表现因LTE网络状况而异，LTE网络失败率超过20%。

Conclusion: 5G SA对低延迟UHD视频流至关重要，5G NSA因依赖传统控制信号可能不足以胜任此任务。

Abstract: 5G Standalone (SA) is the goal of the 5G evolution, which aims to provide higher throughput and lower latency than the existing LTE network. One of the main applications of 5G is the real-time distribution of Ultra High-Definition (UHD) content with a resolution of 4K or 8K. In Q2/2021, Advanced Info Service (AIS), the biggest operator in Thailand, launched 5G SA, providing both 5G SA/NSA service nationwide in addition to the existing LTE network. While many parts of the world are still in process of rolling out the first phase of 5G in Non-Standalone (NSA) mode, 5G SA in Thailand already covers more than 76% of the population.
  In this paper, UHD video will be a real-time live streaming via MPEG-DASH over different mobile network technologies with minimal buffer size to provide the lowest latency. Then, performance such as the number of dropped segments, MAC throughput, and latency are evaluated in various situations such as stationary, moving in the urban area, moving at high speed, and also an ideal condition with maximum SINR. It has been found that 5G SA can deliver more than 95% of the UHD video segment successfully within the required time window in all situations, while 5G NSA produced mixed results depending on the condition of the LTE network. The result also reveals that the LTE network failed to deliver more than 20% of the video segment within the deadline, which shows that 5G SA is absolutely necessary for low-latency UHD video streaming and 5G NSA may not be good enough for such task as it relies on the legacy control signal.

</details>


### [3] [5G Network Automation Using Local Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2511.21084)
*Ahmadreza Majlesara,Ali Majlesi,Ali Mamaghani,Alireza Shokrani,Babak Hossein Khalaj*

Main category: cs.NI

TL;DR: 展示了本地部署的轻量级大语言模型（LLaMA-3 8b Q-4b）结合检索增强生成（RAG）技术来自动化5G网络管理，重点强调隐私保护。


<details>
  <summary>Details</summary>
Motivation: 解决5G网络管理中隐私安全问题，避免敏感数据通过外部API传输到互联网，同时让非专业用户也能轻松创建和配置私有网络。

Method: 在本地或边缘设备上部署轻量级LLM，通过RAG技术从综合数据库中检索相关信息，基于自然语言输入生成精确的网络配置。

Result: 提高了网络配置生成的准确性和效率，简化了私有网络的创建和配置过程，使非专业用户也能轻松使用。

Conclusion: 本地LLM与RAG技术的结合为5G网络提供了安全、高效和适应性强的解决方案，为隐私保护和用户友好的5G网络应用铺平了道路。

Abstract: This demonstration showcases the integration of a lightweight, locally deployed Large Language Model (LLaMA-3 8b Q-4b) empowered by retrieval augmented generation (RAG) to automate 5G network management, with a strong emphasis on privacy. By running the LLM on local or edge devices ,we eliminate the need for external APIs, ensuring that sensitive data remains secure and is not transmitted over the internet. Although lightweight models may not match the performance of more complex models like GPT-4, we enhance their efficiency and accuracy through RAG. RAG retrieves relevant information from a comprehensive database, enabling the LLM to generate more precise and effective network configurations based on natural language user input. This approach not only improves the accuracy of the generated configurations but also simplifies the process of creating and configuring private networks, making it accessible to users without extensive networking or programming experience. The objective of this demonstration is to highlight the potential of combining local LLMs and RAG to deliver secure, efficient, and adaptable 5G network solutions, paving the way for a future where 5G networks are both privacy-conscious and versatile across diverse user profiles.

</details>


### [4] [Digital Twin-Driven Secure Access Strategy for SAGIN-Enabled IoT Networks](https://arxiv.org/abs/2511.21156)
*Hui Liang,Zhihui Wu,Runqi Yuan,Guobin Zhang,Yanfeng Zhang,Jinkai Zheng,Tom H. Luan*

Main category: cs.NI

TL;DR: 提出了一种数字孪生驱动的安全接入策略，通过虚拟复制SAGIN环境评估窃听风险，使用演化博弈模型平衡安全性和延迟，提升物联网网络安全性能。


<details>
  <summary>Details</summary>
Motivation: 空间-空中-地面一体化网络(SAGIN)中的物联网网络面临日益严重的窃听攻击威胁，数据机密性受到挑战，需要开发有效的安全接入策略。

Method: 利用数字孪生框架创建物理SAGIN环境的虚拟副本，持续评估动态窃听风险；采用演化博弈模型平衡保密容量和排队延迟；开发分布式算法获取均衡接入策略。

Result: 仿真结果表明，所提出的基于数字孪生的方法显著提高了SAGIN物联网网络的安全性，有效平衡系统负载，防止过载发生，并降低了排队延迟。

Conclusion: 数字孪生驱动的安全接入策略能够全面改善网络整体性能，在安全性和效率之间实现良好平衡，为SAGIN物联网网络提供有效的安全保障。

Abstract: In space-air-ground integrated networks (SAGIN)-enabled IoT networks, secure access has become a significant challenge due to the increasing risks of eavesdropping attacks. To address these threats to data confidentiality, this paper proposes a Digital Twin (DT)-driven secure access strategy. The strategy leverages a virtual replica of the physical SAGIN environment within the DT framework to continuously assess dynamic eavesdropping risks by quantifying secrecy capacity. Operating within this DT framework, an evolutionary game model dynamically balances the DT-updated secrecy capacity against queuing delay, steering IoT devices toward more secure and efficient access decisions. Furthermore, a novel distributed algorithm, integral to the DT operation, is developed to obtain the equilibrium access strategy for each device in a scalable manner. Simulation results demonstrate that the proposed DT-based approach substantially improves the security of SAGIN-enabled IoT networks. Additionally, it effectively balances system load, prevents overload occurrences, and decreases queuing delay compared to benchmark schemes, thereby comprehensively improving overall network performance.

</details>


### [5] [LatencyScope: A System-Level Mathematical Framework for 5G RAN Latency](https://arxiv.org/abs/2511.21277)
*Arman Maghsoudnia,Aoyu Gong,Raphael Cannatà,Dan Mihai Dumitriu,Haitham Hassanieh*

Main category: cs.NI

TL;DR: LatencyScope是一个用于准确计算5G RAN中单向延迟的数学框架，包含延迟建模和配置优化器，在开源测试平台上验证效果优于现有模型和模拟器。


<details>
  <summary>Details</summary>
Motivation: 5G RAN中的延迟计算需要准确建模各层延迟源及其复杂依赖关系，现有分析模型和模拟器在准确性和配置优化方面存在不足。

Method: 在RAN的每一层建模延迟源，识别系统级瓶颈（如无线接口、调度策略、硬件/软件约束），并捕捉其随机特性；使用数学模型搜索数百亿种配置以找到满足延迟可靠性目标的设置。

Result: 在两个开源5G RAN测试平台（srsRAN和OAI）上验证，LatencyScope能够紧密匹配经验延迟分布，显著优于现有分析模型和常用模拟器（MATLAB 5G工具箱、5G-LENA）。

Conclusion: LatencyScope能够找到满足URLLC目标的系统配置，帮助网络运营商高效识别最佳系统设置。

Abstract: This paper presents LatencyScope, a mathematical framework for accurately computing one-way latency (for uplink and downlink) in the 5G RAN across diverse system configurations. LatencyScope models latency sources at every layer of the Radio Access Network (RAN), pinpointing system-level bottlenecks--such as radio interfaces, scheduling policies, and hardware/software constraints--while capturing their intricate dependencies and their stochastic nature. LatencyScope also includes a configuration optimizer that uses its mathematical models to search through hundreds of billions of configurations and find settings that meet latency-reliability targets under user constraints. We validate LatencyScope on two open-sourced 5G RAN testbeds (srsRAN and OAI), demonstrating that it can closely match empirical latency distributions and significantly outperform prior analytical models and widely used simulators (MATLAB 5G Toolbox, 5G-LENA). It can also find system configurations that meet Ultra-Reliable Low-Latency Communications (URLLC) targets and enable network operators to efficiently identify the best setup for their systems.

</details>


### [6] [Toward Secure Content-Centric Approaches for 5G-Based IoT: Advances and Emerging Trends](https://arxiv.org/abs/2511.21336)
*Ghada Jaber,Mohamed Ali Zormati,Walid Cavelius,Louka Chapiro,Mohamed El Ahmadi*

Main category: cs.NI

TL;DR: 本文调查了内容中心网络在5G物联网环境中的安全挑战和解决方案，重点关注内容认证、数据完整性、隐私保护和抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和5G技术的融合，内容中心网络因其网络内缓存、可扩展性和高效内容分发等优势而成为传统IP架构的有前景替代方案，但在5G物联网环境中部署时面临严重的安全挑战。

Method: 采用文献调查和分类的方法，系统回顾和分类了物联网-5G场景中内容中心架构的现有安全解决方案。

Result: 识别了当前安全解决方案的趋势和局限性，强调了分布式、移动和异构特性对安全的影响。

Conclusion: 需要开发轻量级和自适应的安全机制来应对内容中心网络在5G物联网环境中的安全挑战，并指出了未来的研究方向。

Abstract: The convergence of the Internet of Things (IoT) and 5G technologies is transforming modern communication systems by enabling massive connectivity, low latency, and high-speed data transmission. In this evolving landscape, Content-Centric Networking (CCN) is emerging as a promising alternative to traditional Internet Protocol (IP)-based architectures. CCN offers advantages such as in-network caching, scalability, and efficient content dissemination, all of which are particularly well-suited to the constraints of the IoT. However, deploying content-centric approaches in 5G-based IoT environments introduces significant security challenges. Key concerns include content authentication, data integrity, privacy protection, and resilience against attacks such as spoofing and cache poisoning. Such issues are exacerbated by the distributed, mobile, and heterogeneous nature of IoT and 5G systems. In this survey, we review and classify existing security solutions for content-centric architectures in IoT-5G scenarios. We highlight current trends, identify limitations in existing approaches, and outline future research directions with a focus on lightweight and adaptive security mechanisms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Learning Multi-Access Point Coordination in Agentic AI Wi-Fi with Large Language Models](https://arxiv.org/abs/2511.20719)
*Yifan Fan,Le Liang,Peng Liu,Xiao Li,Ziyang Guo,Qiao Lan,Shi Jin,Wen Tong*

Main category: cs.AI

TL;DR: 提出了一个基于大型语言模型代理的智能Wi-Fi框架，使接入点能够通过自然语言对话实时协商自适应协调策略，显著提升密集重叠基本服务集环境下的网络性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多接入点协调协议依赖静态规则，无法适应动态网络条件如变化的干扰水平和拓扑结构，限制了网络吞吐量的提升。

Method: 将每个接入点建模为自主的大型语言模型代理，通过认知工作流程进行自然语言对话，利用集成记忆、反思和工具使用功能，基于历史经验和环境反馈制定决策。

Result: 综合仿真结果表明，该代理框架成功适应了多样化和动态的网络环境，显著优于最先进的空分复用基线方法。

Conclusion: 该框架验证了其作为未来无线网络稳健智能解决方案的潜力，能够实现实时自适应协调策略协商。

Abstract: Multi-access point coordination (MAPC) is a key technology for enhancing throughput in next-generation Wi-Fi within dense overlapping basic service sets. However, existing MAPC protocols rely on static, protocol-defined rules, which limits their ability to adapt to dynamic network conditions such as varying interference levels and topologies. To address this limitation, we propose a novel Agentic AI Wi-Fi framework where each access point, modeled as an autonomous large language model agent, collaboratively reasons about the network state and negotiates adaptive coordination strategies in real time. This dynamic collaboration is achieved through a cognitive workflow that enables the agents to engage in natural language dialogue, leveraging integrated memory, reflection, and tool use to ground their decisions in past experience and environmental feedback. Comprehensive simulation results demonstrate that our agentic framework successfully learns to adapt to diverse and dynamic network environments, significantly outperforming the state-of-the-art spatial reuse baseline and validating its potential as a robust and intelligent solution for future wireless networks.

</details>


### [8] [Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring](https://arxiv.org/abs/2511.20679)
*Melika Ayoughi,Pascal Mettes,Paul Groth*

Main category: cs.AI

TL;DR: 本文研究使用大型语言模型自动重构层次结构以优化双曲嵌入质量，实验表明LLM重构的层次结构在多个标准指标上都能产生更高质量的双曲嵌入。


<details>
  <summary>Details</summary>
Motivation: 双曲嵌入的质量与输入层次结构密切相关，而现有层次结构往往来源于知识图谱或本体论。为了帮助知识工程师重新组织层次知识，研究LLM是否能够自动重构层次结构以满足双曲嵌入的最佳标准。

Method: 提出基于提示的方法，使用LLM根据双曲嵌入的已知期望标准来转换现有层次结构。在16个不同的层次结构上进行实验验证。

Result: 实验结果显示，LLM重构的层次结构在多个标准嵌入质量指标上始终产生更高质量的双曲嵌入。

Conclusion: LLM引导的层次结构重构不仅提高了双曲嵌入质量，还支持可解释的重组，为知识工程师提供重组理由。

Abstract: Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.

</details>


### [9] [AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI](https://arxiv.org/abs/2511.20686)
*Chae-Gyun Lim,Seung-Ho Han,EunYoung Byun,Jeongyun Han,Soohyun Cho,Eojin Joo,Heehyeon Kim,Sieun Kim,Juhoon Lee,Hyunsoo Lee,Dongkun Lee,Jonghwan Hyeon,Yechan Hwang,Young-Jun Lee,Kyeongryul Lee,Minhyeong An,Hyunjun Ahn,Jeongwoo Son,Junho Park,Donggyu Yoon,Taehyung Kim,Jeemin Kim,Dasom Choi,Kwangyoung Lee,Hyunseung Lim,Yeohyun Jung,Jongok Hong,Sooyohn Nam,Joonyoung Park,Sungmin Na,Yubin Choi,Jeanne Choi,Yoojin Hong,Sueun Jang,Youngseok Seo,Somin Park,Seoungung Jo,Wonhye Chae,Yeeun Jo,Eunyoung Kim,Joyce Jiyoung Whang,HwaJung Hong,Joseph Seering,Uichin Lee,Juho Kim,Sunna Choi,Seokyeon Ko,Taeho Kim,Kyunghoon Kim,Myungsik Ha,So Jung Lee,Jemin Hwang,JoonHo Kwak,Ho-Jin Choi*

Main category: cs.AI

TL;DR: AssurAI是一个针对韩语多模态生成AI安全评估的高质量数据集，包含11,480个文本、图像、视频和音频实例，涵盖35种AI风险因素，专门考虑了韩国社会文化背景。


<details>
  <summary>Details</summary>
Motivation: 当前的安全评估数据集主要是英语中心化的，无法捕捉非英语社会文化背景下的特定风险，特别是韩语环境中的安全问题，且大多仅限于文本模态。

Method: 1) 由多学科专家组定义35种AI风险因素分类法；2) 构建包含文本、图像、视频和音频的韩语多模态数据集；3) 采用两阶段构建流程（专家引导种子和众包扩展）、三重独立标注和迭代式专家红队测试的质量控制过程。

Result: 试点研究验证了AssurAI在评估最新大语言模型安全性方面的有效性，数据集已公开发布以促进更安全的韩语生成AI系统开发。

Conclusion: AssurAI填补了韩语多模态AI安全评估的空白，为韩国社区提供了更可靠的安全评估工具，有助于开发更安全的生成AI系统。

Abstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.

</details>


### [10] [$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators](https://arxiv.org/abs/2511.20693)
*Mingming Zhao,Xiaokang Wei,Yuanqi Shao,Kaiwen Zhou,Lin Yang,Siwei Rao,Junhui Zhan,Zhitang Chen*

Main category: cs.AI

TL;DR: A²Flow是一个完全自动化的智能体工作流生成框架，通过自适应的抽象操作符实现无需手动预定义的工作流构建。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖手动预定义的操作符，限制了泛化性和可扩展性。

Method: 采用三阶段操作符提取过程：基于案例的初始操作符生成、操作符聚类和初步抽象、深度提取抽象执行操作符，并增强节点级工作流搜索的算子记忆机制。

Result: 在通用和具身基准测试中，A²Flow平均性能提升2.4%和19.3%，资源使用减少37%。

Conclusion: A²Flow通过完全自动化的操作符提取和工作流生成，显著提升了智能体工作流设计的效率和性能。

Abstract: Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\% and 19.3\% average performance improvement and reduces resource usage by 37\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW

</details>


### [11] [Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning](https://arxiv.org/abs/2511.20694)
*Kevin Lee,Russell Spiewak,James Walsh*

Main category: cs.AI

TL;DR: 提出了一个用于太阳物理推理的新数据集和基准测试方法，发现基于系统工程原则的多智能体工作流在需要演绎推理的问题上表现优于直接提示。


<details>
  <summary>Details</summary>
Motivation: 解决太阳物理领域大型语言模型推理中需要整合物理假设、保持单位一致性和提供清晰科学格式的挑战。

Method: 构建了来自NASA和UCAR Living With a Star暑期学校问题集的数据集，采用程序化评分器检查预测结果，并比较了单次提示和四种多智能体模式。

Result: 通过系统工程原则分解工作流在需要演绎推理的问题上表现优于直接提示，但在纯归纳回忆问题上差异不明显。

Conclusion: 多智能体工作流分解方法在复杂科学推理任务中具有优势，特别是在需要演绎推理的场景下。

Abstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.

</details>


### [12] [A Brief History of Digital Twin Technology](https://arxiv.org/abs/2511.20695)
*Yunqi Zhang,Kuangyu Shi,Biao Li*

Main category: cs.AI

TL;DR: 数字孪生技术从NASA航天器模拟发展而来，现正推动医疗健康转型，通过创建患者特异性虚拟模型来支持诊断、治疗规划和药物开发，但面临互操作性、数据隐私等挑战。


<details>
  <summary>Details</summary>
Motivation: 将数字孪生技术从工业领域引入医疗健康，旨在实现从被动治疗向预测性、预防性和个性化医疗的转变。

Method: 整合医学影像、生物传感器和计算模型，创建动态数据驱动的患者虚拟副本，支持双向交互和实时更新。

Result: 已开发出心脏数字孪生预测心律失常治疗效果、肿瘤数字孪生追踪进展和优化放疗、药理学数字孪生加速药物发现等代表性应用。

Conclusion: 数字孪生技术有望彻底改变医疗模式，但需要解决互操作性、数据隐私等挑战，并通过可解释AI、联邦学习等技术推动临床整合。

Abstract: Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.

</details>


### [13] [Paraconsistent-Lib: an intuitive PAL2v algorithm Python Library](https://arxiv.org/abs/2511.20700)
*Arnaldo de Carvalho Junior,Diego Oliveira da Cruz,Bruno da Silva Alves,Fernando da Silva Paulo Junior,João Inacio da Silva Filho*

Main category: cs.AI

TL;DR: Paraconsistent-Lib是一个开源的Python库，用于构建PAL2v算法，支持12种经典格区域分析、分析节点输出和决策输出，能够简化复杂算法的实现。


<details>
  <summary>Details</summary>
Motivation: 为推理和决策系统提供一个易于使用的PAL2v算法构建工具，减少代码复杂度和错误。

Method: 开发了一个通用的PAL2v标准计算库，支持Para-analyzer、ParaExtrCTX、PAL2v Filter、PANnet和PNN等算法的独立或网络形式实现。

Result: 成功创建了稳定状态的Paraconsistent-Lib，能够有效降低算法实现的复杂性、代码量和错误率。

Conclusion: Paraconsistent-Lib是一个活跃开发的开源项目，能够响应用户需求，为PAL2v算法提供高效实现平台。

Abstract: This paper introduces Paraconsistent-Lib, an open-source, easy-to-use Python library for building PAL2v algorithms in reasoning and decision-making systems. Paraconsistent-Lib is designed as a general-purpose library of PAL2v standard calculations, presenting three types of results: paraconsistent analysis in one of the 12 classical lattice PAL2v regions, paraconsistent analysis node (PAN) outputs, and a decision output. With Paraconsistent-Lib, well-known PAL2v algorithms such as Para-analyzer, ParaExtrCTX, PAL2v Filter, paraconsistent analysis network (PANnet), and paraconsistent neural network (PNN) can be written in stand-alone or network form, reducing complexity, code size, and bugs, as two examples presented in this paper. Given its stable state, Paraconsistent-Lib is an active development to respond to user-required features and enhancements received on GitHub.

</details>


### [14] [Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework](https://arxiv.org/abs/2511.20701)
*Nitya Tiwari,Parv Maheshwari,Vidisha Agarwal*

Main category: cs.AI

TL;DR: 本文分析了多模态思维链推理在跨领域数据集上的泛化能力，发现在科学推理之外的其他领域效果有限，特别是在常识推理方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 探索多模态思维链推理在科学问答之外的多样化领域（如常识推理、图表理解）的泛化能力，填补现有研究在跨领域评估方面的空白。

Method: 采用Zhang等人提出的两阶段框架，将原理生成与答案推理分离，通过门控融合机制整合视觉特征与基于T5的语言模型，并进行系统的消融研究。

Result: 视觉特征整合显著减少了原理生成中的幻觉，但思维链推理的有效性在不同问题类型间差异很大，常识推理尤其具有挑战性。

Conclusion: 为研究者实施多模态推理系统提供了实用见解，并确定了跨领域泛化能力改进的关键方向。

Abstract: While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.

</details>


### [15] [OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability](https://arxiv.org/abs/2511.20766)
*Karen Ullrich,Jingtong Su,Claudia Shi,Arjun Subramonian,Amir Bar,Ivan Evtimov,Nikolaos Tsilivis,Randall Balestriero,Julia Kempe,Mark Ibrahim*

Main category: cs.AI

TL;DR: OpenApps是一个轻量级开源生态系统，用于评估多模态UI代理在不同应用变化中的可靠性。研究发现代理在固定应用中的表现相对稳定，但在不同应用版本中成功率波动可达50%以上。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法使用固定环境，无法衡量代理在不同应用设计和内容变化中的可靠性，而实际部署时会遇到各种应用变体。

Method: 开发了包含6个可配置应用（消息、日历、地图等）的OpenApps生态系统，使用单个CPU即可运行数千个应用版本，进行了超过10,000次独立评估。

Result: 代理在固定应用中的可靠性相对稳定，但在应用变化中波动剧烈。例如Kimi-VL-3B的平均成功率从63%降至4%。代理行为如循环或幻觉操作也因环境配置而异。

Conclusion: 应用变化是衡量代理可靠性的重要新维度，OpenApps为此提供了评估工具。

Abstract: Reliability is key to realizing the promise of autonomous UI-Agents, multimodal agents that directly interact with apps in the same manner as humans, as users must be able to trust an agent to complete a given task. Current evaluations rely on fixed environments, often clones of existing apps, which are limited in that they can only shed light on whether or how often an agent can complete a task within a specific environment. When deployed however, agents are likely to encounter variations in app design and content that can affect an agent's ability to complete a task. To address this blind spot of measuring agent reliability across app variations, we develop OpenApps, a light-weight open-source ecosystem with six apps (messenger, calendar, maps, etc.) that are configurable in appearance and content. OpenApps requires just a single CPU to run, enabling easy generation and deployment of thousands of versions of each app. Specifically, we run more than 10,000 independent evaluations to study reliability across seven leading multimodal agents. We find that while standard reliability within a fixed app is relatively stable, reliability can vary drastically when measured across app variations. Task success rates for many agents can fluctuate by more than $50\%$ across app variations. For example, Kimi-VL-3B's average success across all tasks fluctuates from $63\%$ to just $4\%$ across app versions. We also find agent behaviors such as looping or hallucinating actions can differ drastically depending on the environment configuration. These initial findings highlight the importance of measuring reliability along this new dimension of app variations. OpenApps is available at https://facebookresearch.github.io/OpenApps/

</details>


### [16] [Representation Interventions Enable Lifelong Unstructured Knowledge Control](https://arxiv.org/abs/2511.20892)
*Xuyuan Liu,Zhengzhang Chen,Xinshuai Dong,Yanchi Liu,Xujiang Zhao,Shengyu Chen,Haoyu Wang,Yujun Yan,Haifeng Chen*

Main category: cs.AI

TL;DR: RILKE是一种在表示空间进行干预的知识控制方法，通过低维子空间更新和查询自适应路由，实现大规模知识编辑而不干扰模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常产生错误或过时内容，需要在不重新训练的情况下高效准确地更新知识，特别是在终身学习环境中处理复杂非结构化知识时面临挑战。

Method: RILKE在模型表示空间进行干预，学习抗释义和编辑局部化的模块，将每个更新限制在低维子空间以减少干扰，推理时通过查询自适应路由选择合适模块。

Result: 在LLaMA和Qwen模型的知识编辑基准测试中，RILKE可扩展到大规模数据集，表现出高编辑成功率、强释义泛化能力，并能保持通用能力且内存开销较小。

Conclusion: RILKE是大语言模型终身知识控制的有效且可扩展解决方案。

Abstract: Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.

</details>


### [17] [Guaranteed Optimal Compositional Explanations for Neurons](https://arxiv.org/abs/2511.20934)
*Biagio La Rosa,Leilani H. Gilpin*

Main category: cs.AI

TL;DR: 提出了第一个计算保证最优组合解释的框架，通过分解空间对齐因素、设计启发式估计和高效算法，解决了现有方法无法保证最优性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有组合解释方法使用beam search无法提供理论最优性保证，不清楚当前解释与真正最优解的接近程度。

Method: 提出分解框架识别空间对齐影响因素，设计启发式估计方法，开发首个能在可行时间内计算最优组合解释的算法。

Result: 在计算机视觉和CNN中最流行设置下，10-40%的beam search解释在涉及重叠概念时是次优的；提出的beam search变体在运行时间上匹配或优于现有方法。

Conclusion: 该框架首次实现了保证最优的组合解释计算，揭示了现有方法的局限性，并提供了更灵活高效的替代方案。

Abstract: While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources.

</details>


### [18] [ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction](https://arxiv.org/abs/2511.20937)
*Qineng Wang,Wenlong Huang,Yu Zhou,Hang Yin,Tianwei Bao,Jianwen Lyu,Weiyu Liu,Ruohan Zhang,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: ENACT是一个评估视觉语言模型是否表现出具身认知能力的基准测试，通过世界建模任务来检验模型从自我中心交互中理解环境的能力。


<details>
  <summary>Details</summary>
Motivation: 研究现代视觉语言模型是否在非具身训练后仍能表现出具身认知的特征，即智能是否源于感知运动交互而非被动观察。

Method: 将具身认知评估构建为部分可观测马尔可夫决策过程中的世界建模问题，包含两个序列重排序任务：前向世界建模（给定动作重排观察序列）和逆世界建模（给定观察重排动作序列）。

Result: 实验发现前沿视觉语言模型与人类之间存在性能差距，且随着交互时间跨度增加而扩大；模型在逆任务上表现更好，并表现出人类中心偏见。

Conclusion: 现代视觉语言模型在具身认知能力方面仍存在不足，特别是在长时程交互和偏离人类视觉特征的情况下表现更差。

Abstract: Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.

</details>


### [19] [Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture](https://arxiv.org/abs/2511.20942)
*Rahul Dass,Thomas Bowlin,Zebing Li,Xiao Jin,Ashok Goel*

Main category: cs.AI

TL;DR: Ivy是一个AI教练系统，通过结合符号化的任务-方法-知识(TMK)模型和生成式解释层，提供结构化、多步骤的解释，以改善LLM在程序性技能学习中的解释质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)在程序性技能学习中往往产生流畅但浅显的响应，缺乏因果、目标导向和组合逻辑的结构化表达。

Method: Ivy系统将符号化的TMK模型与生成式解释层相结合，TMK编码因果转换、目标层次和问题分解，在明确的结构边界内指导LLM生成解释。

Result: 与GPT和检索增强GPT基线相比，Ivy在三个推理维度上的专家和独立注释显示，符号约束持续提高了对"如何"和"为什么"问题的解释结构质量。

Conclusion: 这项研究展示了一种可扩展的AI教育方法，通过符号约束增强了AI生成解释在智能教练系统中的教学价值。

Abstract: In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for "how" and "why" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.

</details>


### [20] [ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning](https://arxiv.org/abs/2511.21005)
*Jinpeng Wang,Chao Li,Ting Ye,Mengyuan Zhang,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: 提出了ICPO方法，通过利用LLM生成不同响应的概率来反映其推理过程的自评估，结合偏好优势分数和可验证奖励来指导探索过程，解决现有RLVR方法中的粗粒度奖励、奖励噪声和低效探索问题。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在粗粒度奖励、奖励噪声和低效探索等问题，导致训练不稳定和熵崩溃，需要改进方法来增强LLM的推理能力。

Method: ICPO方法计算每个响应的偏好优势分数，通过比较同一输入提示下多个响应的相对生成概率，并将该分数与可验证奖励结合来指导探索过程。

Result: 在四个通用领域基准和三个数学基准上的实验表明，ICPO相比GRPO能稳定提升推理能力。

Conclusion: ICPO方法有效缓解了粗粒度奖励和奖励噪声问题，抑制了过度自信错误，增强了被低估高质量响应的相对优势，防止模型对特定策略的过拟合，促进了更彻底的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.

</details>


### [21] [Towards Trustworthy Legal AI through LLM Agents and Formal Reasoning](https://arxiv.org/abs/2511.21033)
*Linze Chen,Yufan Cai,Zhe Hou,Jinsong Dong*

Main category: cs.AI

TL;DR: L4M框架结合对抗性LLM代理和SMT求解器证明，将自然语言的解释灵活性与符号验证的严谨性相结合，用于法律裁决。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统擅长表层文本分析，但缺乏原则性法理学所需的保证。法律理性包括实质理性（结果公平性）和形式理性（遵循明确规则），需要结合两者的方法。

Method: 三阶段流程：1) 法规形式化：将法律条款转换为逻辑公式；2) 双重事实和法规提取：检察官和辩护方对齐的LLM独立提取事实和法规；3) 求解器中心裁决：将双方论点编译为逻辑约束，通过不满足核心触发迭代自我批判，最终由法官LLM生成透明裁决。

Result: 在公共基准测试中，该系统超越了GPT-4-mini、DeepSeek-V3、Claude 4等先进LLM以及最先进的法律AI基线，同时提供严谨且可解释的符号化理由。

Conclusion: L4M框架成功地将自然语言的灵活性与符号验证的严谨性相结合，为法律决策提供了可解释且可靠的方法，在准确性和透明度方面均优于现有方法。

Abstract: The rationality of law manifests in two forms: substantive rationality, which concerns the fairness or moral desirability of outcomes, and formal rationality, which requires legal decisions to follow explicitly stated, general, and logically coherent rules. Existing LLM-based systems excel at surface-level text analysis but lack the guarantees required for principled jurisprudence. We introduce L4M, a novel framework that combines adversarial LLM agents with SMT-solver-backed proofs to unite the interpretive flexibility of natural language with the rigor of symbolic verification. The pipeline consists of three phases: (1) Statute Formalization, where domain-specific prompts convert legal provisions into logical formulae; (2) Dual Fact and Statute Extraction, in which prosecutor- and defense-aligned LLMs independently map case narratives to fact tuples and statutes, ensuring role isolation; and (3) Solver-Centric Adjudication, where an autoformalizer compiles both parties' arguments into logic constraints, and unsat cores trigger iterative self-critique until a satisfiable formula is achieved, which is then verbalized by a Judge-LLM into a transparent verdict and optimized sentence. Experimental results on public benchmarks show that our system surpasses advanced LLMs including GPT-o4-mini, DeepSeek-V3, and Claude 4 as well as state-of-the-art Legal AI baselines, while providing rigorous and explainable symbolic justifications.

</details>


### [22] [OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection](https://arxiv.org/abs/2511.21064)
*Chujie Wang,Jianyu Lu,Zhiyuan Luo,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: OVOD-Agent将开放词汇目标检测从被动的类别匹配转变为主动的视觉推理和自我进化检测，通过视觉思维链和弱马尔可夫决策过程提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法虽然在多模态数据上预训练，但推理仍局限于固定类别名称，存在多模态训练与单模态推理的差距。文本空间的潜力尚未充分挖掘。

Method: 提出OVOD-Agent框架，采用视觉思维链进行可解释的文本优化，将视觉上下文建模为弱马尔可夫决策过程，结合Bandit模块生成探索信号，并通过自监督奖励模型优化形成闭环学习。

Result: 在COCO和LVIS数据集上的实验表明，OVOD-Agent在各种骨干网络上均能带来一致改进，特别是在稀有类别上表现突出。

Conclusion: 该框架通过主动推理和自我进化机制有效提升了开放词汇目标检测的性能，验证了所提方法的有效性。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.

</details>


### [23] [Causality Without Causal Models](https://arxiv.org/abs/2511.21260)
*Joseph Y. Halpern,Rafael Pass*

Main category: cs.AI

TL;DR: 本文对Halpern和Pearl的因果关系定义进行了抽象化，提取其关键特征，使其能够应用于任何定义了反事实的模型，从而扩展了该定义的应用范围。


<details>
  <summary>Details</summary>
Motivation: Halpern和Pearl的因果关系定义基于因果模型，但存在局限性，无法处理涉及析取、否定、信念和嵌套反事实的复杂情况。本文旨在抽象化该定义，使其适用于更广泛的模型类型。

Method: 通过提取Halpern-Pearl定义的关键特征，构建一个抽象化的因果关系定义框架，该框架可以应用于任何定义了反事实的模型，包括允许回溯的模型。

Result: 成功实现了对Halpern-Pearl定义的抽象化，使其能够处理更复杂的逻辑公式（如析取、否定、信念和嵌套反事实），并扩展到了解释的定义。

Conclusion: 抽象化的因果关系定义不仅扩展了应用范围，还深化了对原始定义特征的理解，为在更广泛模型中进行因果分析提供了理论基础。

Abstract: Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.

</details>


### [24] [Prune4Web: DOM Tree Pruning Programming for Web Agent](https://arxiv.org/abs/2511.21398)
*Jiayuan Zhang,Kaiquan Chen,Zhihao Lu,Enshen Zhou,Qian Yu,Jing Zhang*

Main category: cs.AI

TL;DR: Prune4Web是一种新颖的网页自动化方法，通过将DOM处理从资源密集的LLM读取转变为高效的程序化剪枝，解决了复杂网页DOM结构过大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM网页代理在处理复杂真实网页时面临DOM结构过大的挑战（通常10,000-100,000个token），现有方法依赖粗略的DOM截断或低效启发式方法，无法在精度和可扩展性之间取得平衡。

Method: 提出DOM树剪枝编程，让LLM生成可执行的Python评分脚本来动态过滤DOM元素，基于分解的子任务语义线索。该方法将遍历和评分委托给轻量级可解释程序，无需LLM直接处理原始大型DOM。

Result: 实现了25倍到50倍的候选元素减少，在低级别定位任务中准确率从46.8%大幅提升至88.28%，表现出最先进的性能。

Conclusion: Prune4Web通过程序化剪枝范式有效解决了网页自动化中的DOM处理瓶颈，显著提升了定位精度和效率。

Abstract: Web automation employs intelligent agents to execute high-level tasks by mimicking human interactions with web interfaces. Despite the capabilities of recent Large Language Model (LLM)-based web agents, navigating complex, real-world webpages efficiently remains a significant hurdle due to the prohibitively large size of Document Object Model (DOM) structures, often ranging from 10,000 to 100,000 tokens. Existing strategies typically rely on crude DOM truncation -- risking the loss of critical information -- or employ inefficient heuristics and separate ranking models, failing to achieve an optimal balance between precision and scalability. To address these challenges, we introduce Prune4Web, a novel paradigm that shifts DOM processing from resource-intensive LLM reading to efficient programmatic pruning. Central to our approach is DOM Tree Pruning Programming, where an LLM generates executable Python scoring scripts to dynamically filter DOM elements based on semantic cues from decomposed sub-tasks. This mechanism eliminates the need for LLMs to ingest raw, massive DOMs, instead delegating traversal and scoring to lightweight, interpretable programs. This methodology achieves a 25x to 50x reduction in candidate elements for grounding, thereby facilitating precise action localization while mitigating attention dilution. Furthermore, we propose a specialized data annotation pipeline and a two-turn dialogue training strategy that jointly optimizes the Planner, Programmatic Filter, and Grounder within a unified framework. Extensive experiments demonstrate state-of-the-art performance. Notably, on our low-level grounding task, Prune4Web dramatically improves accuracy from 46.8% to 88.28%, underscoring its efficacy in real-world web automation.

</details>


### [25] [New Hybrid Heuristics for Pseudo-Boolean Propagation](https://arxiv.org/abs/2511.21417)
*Mia Müßig,Jan Johannsen*

Main category: cs.AI

TL;DR: 提出新的启发式方法用于伪布尔求解中的混合单元传播策略，显著优于当前方法


<details>
  <summary>Details</summary>
Motivation: 当前伪布尔求解中最成功的单元传播策略是观察文字方案与计数方法的混合模式，但需要更好的启发式方法来优化这种混合决策

Method: 在RoundingSAT求解器中引入新的启发式方法，用于混合单元传播策略的决策

Result: 新启发式方法能够大幅超越当前方法

Conclusion: 提出的新启发式方法在伪布尔求解的混合单元传播策略中表现出显著优势

Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.

</details>


### [26] [Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex](https://arxiv.org/abs/2511.21438)
*Simon Süwer,Kester Bagemihl,Sylvie Baier,Lucia Dicunta,Markus List,Jan Baumbach,Andreas Maier,Fernando M. Delgado-Chaves*

Main category: cs.AI

TL;DR: ChatDRex是一个基于对话的多智能体系统，通过自然语言访问生物医学知识图谱，实现网络药物重定位预测，让非计算机专家也能进行复杂生物信息学分析。


<details>
  <summary>Details</summary>
Motivation: 传统药物重定位预测需要多领域专家协作，但现有工具碎片化且数据异构，难以集成到统一工作流中。需要让临床专家无需计算机专业知识就能进行复杂分析。

Method: 构建基于NeDRex知识图谱的多智能体系统，包含查询路由、数据检索、算法执行、结果可视化等专门智能体，支持网络分析、功能一致性评估、文献挖掘等任务。

Result: 开发了ChatDRex系统，实现了自然语言访问生物医学知识图谱和复杂生物信息学分析的能力，包含幻觉检测和用户参与推理模块。

Conclusion: ChatDRex通过多智能体系统和自然语言界面，使临床专家能够生成假设和探索药物重定位机会，加速新疗法发现，推动个性化医疗和转化研究。

Abstract: Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem, and heterogeneous, unstructured data landscapes require specialized users to be involved. Hence, these data services do not integrate smoothly across workflows. With ChatDRex, we present a conversation-based, multi-agent system that facilitates the execution of complex bioinformatic analyses aiming for network-based drug repurposing prediction. It builds on the integrated systems medicine knowledge graph NeDRex. ChatDRex provides natural language access to its extensive biomedical KG and integrates bioinformatics agents for network analysis and drug repurposing, complemented by agents for functional coherence evaluation for in silico validation, as well as agents for literature mining and for discussing the obtained results in a scientific context. Its flexible multi-agent design assigns specific tasks to specialized agents, including query routing, data retrieval, algorithm execution, and result visualization. A dedicated reasoning module keeps the user in the loop and allows for hallucination detection. By enabling physicians and researchers without computer science expertise to control complex analyses in natural language, ChatDRex democratizes access to bioinformatics as an important resource for drug repurposing. It enables clinical experts to generate hypotheses and explore drug repurposing opportunities, ultimately accelerating the discovery of novel therapies and advancing personalized medicine and translational research.

</details>


### [27] [EWE: An Agentic Framework for Extreme Weather Analysis](https://arxiv.org/abs/2511.21444)
*Zhe Jiang,Jiong Wang,Xiaoyu Yue,Zijie Guo,Wenlong Zhang,Fenghua Ling,Wanli Ouyang,Lei Bai*

Main category: cs.AI

TL;DR: 提出了第一个专门用于极端天气自动诊断推理的智能代理框架EWE，通过知识引导规划、闭环推理和气象工具包，从原始气象数据自主生成和解释多模态可视化，实现全面诊断分析。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件对全球社会构成日益严重的风险，但专家驱动、劳动密集的诊断范式造成了关键的分析瓶颈，阻碍科学进展。虽然AI在地球科学预测方面取得进展，但自动诊断推理这一同样重要的挑战尚未被充分探索。

Method: EWE框架通过知识引导规划、闭环推理和领域定制的气象工具包来模拟专家工作流程，能够从原始气象数据自主生成和解释多模态可视化。

Result: 为这一新兴领域引入了首个基准测试，包括103个高影响事件的精选数据集和新的逐步评估指标。EWE展示了自动科学发现的潜力。

Conclusion: EWE标志着向自动科学发现迈出的一步，并有望使专业知识和智力资源民主化，特别是对易受极端天气影响的发展中国家。

Abstract: Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.

</details>


### [28] [MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning](https://arxiv.org/abs/2511.21460)
*Junjian Wang,Lidan Zhao,Xi Sheryl Zhang*

Main category: cs.AI

TL;DR: MADRA是一个无需训练的多智能体辩论风险评估框架，通过集体推理增强安全意识，同时保持任务性能。该方法在AI2-THOR和VirtualHome上实现超过90%的危险任务拒绝率，且安全任务拒绝率低。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在具身AI任务规划中的安全挑战，包括高计算成本的偏好对齐训练和单智能体安全提示的过度拒绝问题。

Method: 使用多个基于LLM的智能体对给定指令的安全性进行辩论，由关键评估器根据逻辑合理性、风险识别、证据质量和清晰度对响应评分，通过迭代审议和共识投票达成决策。

Result: 在AI2-THOR和VirtualHome上的广泛实验表明，该方法对不安全任务的拒绝率超过90%，同时保持低安全任务拒绝率，在安全性和执行效率方面优于现有方法。

Conclusion: 该工作为构建可信赖的具身智能体提供了一个可扩展、模型无关的解决方案。

Abstract: Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.

</details>


### [29] [SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition](https://arxiv.org/abs/2511.21471)
*Peiran Xu,Sudong Wang,Yao Zhu,Jianing Li,Yunjian Zhang*

Main category: cs.AI

TL;DR: 提出了一个层次化空间认知框架，将空间智能分解为5个渐进复杂层次，并构建了SpatialBench基准来评估多模态大语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准过度简化空间认知，将其简化为单一维度指标，无法捕捉空间能力的层次结构和相互依赖性。

Method: 构建层次化空间认知框架（5个认知层次），开发SpatialBench大规模细粒度基准（15个任务），引入能力导向的统一评估指标。

Result: 实验显示模型在不同认知层次上表现分层：感知基础能力强，但符号推理、因果推断和规划能力有限。人类测试表明人类进行选择性目标导向抽象，而MLLMs过度关注表面细节。

Conclusion: 建立了首个系统化测量MLLMs层次化空间认知的框架，为未来空间智能系统奠定了基础。

Abstract: Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.

</details>


### [30] [Pessimistic Verification for Open Ended Math Questions](https://arxiv.org/abs/2511.21522)
*Yanxing Huang,Zihan Tang,Zejin Lin,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 提出悲观验证方法，通过并行构建多个验证流程，只要任一验证报告错误就判定证明错误，显著提升数学问题验证性能且计算资源消耗低


<details>
  <summary>Details</summary>
Motivation: 现有验证性能的关键限制在于错误检测能力，需要改进开放数学问题的验证方法

Method: 设计悲观验证变体，为同一证明构建多个并行验证流程，任一验证报告错误即判定证明错误

Result: 显著提升多个数学验证基准测试性能，计算资源消耗低，token效率甚至超过扩展长链思维测试时缩放

Conclusion: 悲观验证能有效提高语言模型输出的可靠性和性能，在实现长视野数学任务中发挥关键作用

Abstract: The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.

</details>


### [31] [Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit](https://arxiv.org/abs/2511.21569)
*Alex Diep*

Main category: cs.AI

TL;DR: 语言模型在专业角色扮演中表现出领域特定的透明度不一致，某些专业角色（如金融顾问）的AI身份披露率较高（30.8%），而其他角色（如神经外科医生）披露率极低（3.5%），这可能导致用户过度信任模型在透明度失败的领域中的能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估语言模型在专业角色扮演中可靠披露AI身份的能力，因为如果模型无法在专家环境中透明表明其AI身份，用户将无法信任其能力边界，这在高风险领域可能造成用户伤害。

Method: 采用共同花园设计，对16个开放权重模型（4B-671B参数）进行了19,200次试验审计，测试不同专业角色下的AI身份披露行为。使用贝叶斯验证和Rogan-Gladen校正确保测量误差的稳健性。

Result: 模型表现出明显的领域特定不一致性：金融顾问角色初始披露率为30.8%，神经外科医生角色仅为3.5%。披露率范围从2.8%到73.6%，14B模型达到61.4%而70B模型仅为4.1%。模型身份比参数数量更能预测行为。推理优化在某些模型中主动抑制了自我透明度。

Conclusion: 透明度反映的是训练因素而非模型规模，组织不能假设安全属性会转移到部署环境中，需要刻意设计行为和进行实证验证。

Abstract: If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a "Reverse Gell-Mann Amnesia" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($ΔR_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($κ= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.

</details>


### [32] [From Prediction to Foresight: The Role of AI in Designing Responsible Futures](https://arxiv.org/abs/2511.21570)
*Maria Perez-Ortiz*

Main category: cs.AI

TL;DR: 本文提出了"负责任计算前瞻"概念，探讨人工智能在负责任前瞻中的作用，强调AI作为支持工具而非替代决策者判断，旨在帮助政策制定者应对21世纪重大挑战。


<details>
  <summary>Details</summary>
Motivation: 在技术快速发展和全球挑战复杂的时代，政策制定者需要负责任的前瞻框架来应对未来不确定性并塑造未来。负责任前瞻需要道德地预测新兴机遇和风险，关注主动、可持续和负责任的未来设计。

Method: 建立负责任计算前瞻的基础原则，开发一套AI驱动的前瞻工具，结合模拟和情景分析来增强政策制定者应对不确定性的能力。

Result: AI与模拟和情景分析结合，能够增强政策制定者应对不确定性、评估风险和制定可持续、韧性未来策略的能力。负责任前瞻需要理解社会、环境、经济和政治系统的相互依赖性。

Conclusion: AI将在负责任、以人为本的前瞻中发挥支持性工具的作用，补充而非替代政策制定者的判断，使能够主动塑造有韧性和道德健全的未来。倡导将AI深思熟虑地融入前瞻实践中，赋能政策制定者和社区应对21世纪重大挑战。

Abstract: In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term "responsible computational foresight", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.

</details>


### [33] [On the Limits of Innate Planning in Large Language Models](https://arxiv.org/abs/2511.21591)
*Charles Schepanowski,Charles Ling*

Main category: cs.AI

TL;DR: LLMs在8拼图任务中表现出规划能力不足，即使有外部验证器提供有效移动，也无法解决任何谜题，主要问题是脆弱的状态表示和弱启发式规划。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在规划和状态推理方面的能力，特别是在需要状态跟踪和目标导向规划的经典任务中，而不依赖代码执行或其他工具。

Method: 使用8拼图任务测试四个模型，采用常见提示条件（零样本、思维链、算法思维）和分层纠正反馈，并引入外部移动验证器。

Result: 反馈提高了某些模型-提示组合的成功率，但成功运行通常冗长且计算昂贵。即使有外部验证器，所有模型都无法解决任何谜题。定性分析显示模型存在脆弱状态表示和弱启发式规划问题。

Conclusion: 当前LLMs在规划方面存在显著限制，需要开发维护显式状态和执行结构化搜索的机制。

Abstract: Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

</details>


### [34] [Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling](https://arxiv.org/abs/2511.21636)
*Peter S. Hovmand,Kari O'Donnell,Callie Ogland-Hand,Brian Biroscak,Douglas D. Gunzler*

Main category: cs.AI

TL;DR: 本文提出了一个将系统动力学和结构方程建模结合到统一数学框架中的方法，用于为数据科学和AI/ML应用生成系统、开发方法并比较结果。


<details>
  <summary>Details</summary>
Motivation: AI/ML模型在解决先前未解决问题方面迅速崛起，但也带来了放大人类偏见的意外后果。负责任AI/ML倡导者寻求利用更丰富的系统动力学因果模型来指导负责任AI/ML的发展，但不同方法基于不同基本假设的整合存在困难。

Method: 将系统动力学和结构方程建模结合到一个共同的数学框架中，该框架能够从分布中生成系统、开发方法并比较结果。

Result: 提出了一个统一的数学框架，能够弥合系统动力学和结构方程建模之间的方法论差异，为数据科学和AI/ML应用提供基础。

Conclusion: 该框架有助于理解系统动力学的认识论基础，为负责任AI/ML的发展提供更丰富的因果模型支持，克服不同方法论假设带来的整合障碍。

Abstract: AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.

</details>


### [35] [Agentic Learner with Grow-and-Refine Multimodal Semantic Memory](https://arxiv.org/abs/2511.21678)
*Weihao Bo,Shan Zhang,Yanpeng Sun,Jingjing Wu,Qunyi Xie,Xiao Tan,Kunbin Chen,Wei He,Xiaofan Li,Na Zhao,Jingdong Wang,Zechao Li*

Main category: cs.AI

TL;DR: ViLoMem是一个双流记忆框架，通过分别编码视觉分心模式和逻辑推理错误，帮助多模态大语言模型从成功和失败经验中学习，提高多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹的记忆方法存在简洁性偏差，逐渐丢失关键领域知识，且仅记录单模态行为轨迹，无法保存视觉注意力和逻辑推理如何共同贡献于解决方案，这与人类多模态整合的语义记忆不符。

Method: 引入双流记忆框架，分别编码视觉分心模式和逻辑推理错误，采用增长-精炼原则逐步积累和更新多模态语义知识，保持稳定可泛化的策略同时避免灾难性遗忘。

Result: 在六个多模态基准测试中，ViLoMem持续提高pass@1准确率，显著减少重复的视觉和逻辑错误。消融实验证实了双流记忆与显式分心-幻觉分离的必要性。

Conclusion: ViLoMem证明了错误感知的多模态记忆对于终身和跨领域智能学习的重要价值，为多模态推理系统提供了更符合人类认知的记忆机制。

Abstract: MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.

</details>
