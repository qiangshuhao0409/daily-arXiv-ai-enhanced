{"id": "2508.06540", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.06540", "abs": "https://arxiv.org/abs/2508.06540", "authors": ["Zhiyan Li", "Ying Cui", "Danny H. K. Tsang"], "title": "AMP-based Joint Activity Detection and Channel Estimation for Massive Grant-Free Access in OFDM-based Wideband Systems", "comment": "to appear in IEEE Trans.Wireless Commun., 2025", "summary": "To realize orthogonal frequency division multiplexing (OFDM)-based grant-free\naccess for wideband systems under frequency-selective fading, existing device\nactivity detection and channel estimation methods need substantial accuracy\nimprovement or computation time reduction. In this paper, we aim to resolve\nthis issue. First, we present an exact time-domain signal model for OFDM-based\ngrant-free access under frequency-selective fading. Then, we present a maximum\na posteriori (MAP)-based device activity detection problem and two minimum mean\nsquare error (MMSE)-based channel estimation problems. The MAP-based device\nactivity detection problem and one of the MMSE-based channel estimation\nproblems are formulated for the first time. Next, we build a new factor graph\nthat captures the exact statistics of time-domain channels and device\nactivities. Based on it, we propose two approximate message passing (AMP)-based\nalgorithms, AMP-A-EC and AMP-A-AC, to approximately solve the MAP-based device\nactivity detection problem and two MMSE-based channel estimation problems. Both\nproposed algorithms alleviate the AMP's inherent convergence problem when the\npilot length is smaller or comparable to the number of active devices. Then, we\nanalyze AMP-A-EC's error probability of activity detection and mean square\nerror (MSE) of channel estimation via state evolution and show that AMP-A-AC\nhas the lower computational complexity (in dominant term). Finally, numerical\nresults show the two proposed AMP-based algorithms' superior performance and\nrespective preferable regions, revealing their significant values for\nOFDM-based grant-free access.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\uff08AMP\uff09\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3OFDM\u65e0\u6388\u6743\u63a5\u5165\u4e2d\u7684\u8bbe\u5907\u6d3b\u52a8\u68c0\u6d4b\u548c\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709OFDM\u65e0\u6388\u6743\u63a5\u5165\u65b9\u6cd5\u5728\u9891\u7387\u9009\u62e9\u6027\u8870\u843d\u4e0b\u7684\u8bbe\u5907\u6d3b\u52a8\u68c0\u6d4b\u548c\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u6216\u8ba1\u7b97\u65f6\u95f4\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u7cbe\u786e\u65f6\u57df\u4fe1\u53f7\u6a21\u578b\uff0c\u6784\u5efa\u65b0\u56e0\u5b50\u56fe\uff0c\u8bbe\u8ba1\u4e24\u79cdAMP\u7b97\u6cd5\uff08AMP-A-EC\u548cAMP-A-AC\uff09\u89e3\u51b3MAP\u548cMMSE\u95ee\u9898\u3002", "result": "\u4e24\u79cd\u7b97\u6cd5\u6709\u6548\u7f13\u89e3AMP\u6536\u655b\u95ee\u9898\uff0cAMP-A-AC\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u5728OFDM\u65e0\u6388\u6743\u63a5\u5165\u4e2d\u5177\u6709\u663e\u8457\u5e94\u7528\u4ef7\u503c\uff0c\u5206\u522b\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u3002"}}
{"id": "2508.06557", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.06557", "abs": "https://arxiv.org/abs/2508.06557", "authors": ["Zihao Hu", "Jia Yan", "Ying-Jun Angela Zhang"], "title": "Communication-Learning Co-Design for Differentially Private Over-the-Air Federated Distillation", "comment": "9 pages, 2 figures, submitted to IEEE Wireless Communication Letters", "summary": "The ever-growing learning model size nowadays challenges the communication\nefficiency and privacy preservation of the traditional federated learning (FL).\nIn this paper, we propose a novel differentially private (DP) over-the-air\nfederated distillation (FD) framework, where wireless devices (WDs)\nperiodically share noise-perturbed model outputs with the parameter server by\nharnessing the superposition property of multi-access channels. Accordingly,\nover-the-air FD enables the shared responsibility of the DP preservation on the\nlow-dimensional disclosed signals among WDs. We study the\ncommunication-learning co-design problem in differentially private over-the-air\nFD, aiming to maximize the learning convergence rate while meeting the transmit\npower and DP requirements of WDs. The main challenge is rooted in the\nintractable learning and privacy analysis in over-the-air FD, together with the\nstrong coupling among the decision variables spanning two timescales. To tackle\nthis problem, we first derive the analytical learning convergence rate and\nprivacy losses of WDs, based on which the optimal transceiver design per FD\nround and long-term training rounds decision are obtained in the closed forms.\nNumerical results demonstrate that the proposed differentially private\nover-the-air FD approach achieves a better learning-privacy trade-off with\nlargely-reduced communication overhead than the conventional FL benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u65e0\u7ebf\u8054\u90a6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u63a5\u5165\u4fe1\u9053\u7684\u53e0\u52a0\u7279\u6027\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u4e0e\u9690\u79c1\u4fdd\u62a4\uff0c\u4f18\u5316\u4e86\u5b66\u4e60\u6536\u655b\u901f\u7387\u4e0e\u901a\u4fe1\u5f00\u9500\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u4e2d\u6a21\u578b\u89c4\u6a21\u589e\u5927\u5e26\u6765\u7684\u901a\u4fe1\u6548\u7387\u4e0e\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u3002", "method": "\u5229\u7528\u5dee\u5206\u9690\u79c1\u548c\u65e0\u7ebf\u4fe1\u9053\u7684\u53e0\u52a0\u7279\u6027\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8054\u5408\u901a\u4fe1\u4e0e\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\uff0c\u5305\u62ec\u6536\u53d1\u5668\u8bbe\u8ba1\u548c\u957f\u671f\u8bad\u7ec3\u51b3\u7b56\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u8bc1\u5dee\u5206\u9690\u79c1\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u4f18\u4e8e\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u57fa\u51c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06695", "categories": ["cs.IT", "math.IT", "math.RA", "94B15, 11T71, 17A99, 81P70"], "pdf": "https://arxiv.org/pdf/2508.06695", "abs": "https://arxiv.org/abs/2508.06695", "authors": ["Monica Nevins", "Susanne Pumpluen"], "title": "When isometry and equivalence for skew constacyclic codes coincide", "comment": null, "summary": "We show that the notions of $(n,\\sigma)$-isometry and\n$(n,\\sigma)$-equivalence introduced by Ou-azzou et al coincide for most skew\n$(\\sigma,a)$-constacyclic codes of length $n$. To prove this, we show that all\nHamming-weight-preserving homomorphisms between their ambient algebras must\nhave degree one when those algebras are nonassociative. We work in the general\nsetting of commutative base rings $S$. As a consequence, we propose new\ndefinitions of equivalence and isometry of skew constacyclic codes that exactly\ncapture all Hamming-preserving isomorphisms, and lead to tighter\nclassifications. In the process we determine homomorphisms between\nnonassociative Petit algebras, prioritizing the algebras\n$S[t;\\sigma]/S[t;\\sigma](t^n-a)$, which give rise to skew constacyclic codes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06940", "categories": ["cs.IT", "math.IT", "68P30 (Primary) 68Q30, 94B70 (Secondary)"], "pdf": "https://arxiv.org/pdf/2508.06940", "abs": "https://arxiv.org/abs/2508.06940", "authors": ["Olakunle S. Abawonse", "Jan Hazla", "Ryan O'Donnell"], "title": "Generalized Samorodnitsky noisy function inequalities, with applications to error-correcting codes", "comment": "46 pages", "summary": "An inequality by Samorodnitsky states that if $f : \\mathbb{F}_2^n \\to\n\\mathbb{R}$ is a nonnegative boolean function, and $S \\subseteq [n]$ is chosen\nby randomly including each coordinate with probability a certain $\\lambda =\n\\lambda(q,\\rho) < 1$, then \\begin{equation}\n  \\log \\|T_\\rho f\\|_q \\leq \\mathbb{E}_{S} \\log \\|\\mathbb{E}(f|S)\\|_q\\;.\n\\end{equation} Samorodnitsky's inequality has several applications to the\ntheory of error-correcting codes. Perhaps most notably, it can be used to show\nthat \\emph{any} binary linear code (with minimum distance $\\omega(\\log n)$)\nthat has vanishing decoding error probability on the BEC$(\\lambda)$ (binary\nerasure channel) also has vanishing decoding error on \\emph{all} memoryless\nsymmetric channels with capacity above some $C = C(\\lambda)$.\n  Samorodnitsky determined the optimal $\\lambda = \\lambda(q,\\rho)$ for his\ninequality in the case that $q \\geq 2$ is an integer. In this work, we\ngeneralize the inequality to $f : \\Omega^n \\to \\mathbb{R}$ under any product\nprobability distribution $\\mu^{\\otimes n}$ on $\\Omega^n$; moreover, we\ndetermine the optimal value of $\\lambda = \\lambda(q,\\mu,\\rho)$ for any real $q\n\\in [2,\\infty]$, $\\rho \\in [0,1]$, and distribution~$\\mu$. As one consequence,\nwe obtain the aforementioned coding theory result for linear codes over\n\\emph{any} finite alphabet.", "AI": {"tldr": "\u8bba\u6587\u6269\u5c55\u4e86Samorodnitsky\u4e0d\u7b49\u5f0f\uff0c\u5c06\u5176\u63a8\u5e7f\u5230\u4efb\u610f\u4e58\u79ef\u6982\u7387\u5206\u5e03\u4e0b\u7684\u51fd\u6570\uff0c\u5e76\u786e\u5b9a\u4e86\u6700\u4f18\u53c2\u6570\u03bb\u7684\u8303\u56f4\u3002", "motivation": "Samorodnitsky\u4e0d\u7b49\u5f0f\u5728\u7ea0\u9519\u7801\u7406\u8bba\u4e2d\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u539f\u4e0d\u7b49\u5f0f\u4ec5\u9002\u7528\u4e8e\u5e03\u5c14\u51fd\u6570\u548c\u6574\u6570q\u3002\u672c\u6587\u65e8\u5728\u5c06\u5176\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u60c5\u51b5\u3002", "method": "\u5c06\u4e0d\u7b49\u5f0f\u63a8\u5e7f\u5230\u4efb\u610f\u4e58\u79ef\u6982\u7387\u5206\u5e03\u03bc\u2297n\u4e0b\u7684\u51fd\u6570f:\u03a9n\u2192R\uff0c\u5e76\u786e\u5b9a\u6700\u4f18\u53c2\u6570\u03bb(q,\u03bc,\u03c1)\u7684\u8303\u56f4\u3002", "result": "\u6210\u529f\u63a8\u5e7f\u4e86\u4e0d\u7b49\u5f0f\uff0c\u5e76\u786e\u5b9a\u4e86\u6700\u4f18\u03bb\u7684\u8303\u56f4\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u5b9e\u6570q\u2208[2,\u221e]\u548c\u03c1\u2208[0,1]\u3002", "conclusion": "\u63a8\u5e7f\u540e\u7684\u4e0d\u7b49\u5f0f\u6269\u5c55\u4e86\u5176\u5728\u7ea0\u9519\u7801\u7406\u8bba\u4e2d\u7684\u5e94\u7528\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u6709\u9650\u5b57\u6bcd\u8868\u7684\u7ebf\u6027\u7801\u3002"}}
{"id": "2508.06615", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.06615", "abs": "https://arxiv.org/abs/2508.06615", "authors": ["Ryan Erik Landvater", "Navin Kathawa", "Mustafa Yousif MD", "Ulysses Balis MD"], "title": "Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers", "comment": "10 pages, 4 figures, 1 table", "summary": "The Iris File Extension (IFE) is a low overhead performance-oriented whole\nslide image (WSI) file format designed to improve the image rendering\nexperience for pathologists and simplify image management for system\nadministrators. However, static hypertext transfer protocol (HTTP) file servers\ncannot natively stream subregions of high-resolution image files, such as the\nIFE. The majority of contemporary WSI viewer systems are designed as\nbrowser-based web applications and leverage OpenSeaDragon as the tile-based\nrendering framework. These systems convert WSI files to Deep Zoom Images (DZI)\nfor compatibility with simple static HTTP file servers. In order to address\nthis limitation, we have developed the Iris RESTful Server, a low-overhead HTTP\nserver with a RESTful API that is natively compatible with the DICOMweb WADO-RS\nAPI. Written in C++ with Boost Beast HTTP and Asio networking libraries atop\nthe public IFE libraries, the server offers both security and high performance.\nTesting shows that a single instance can handle over 5000 tile requests per\nsecond with a median latency of 21 ms on a private network. We also developed\nand merged a new OpenSeaDragon TileSource, compatible with the Iris RESTful\nAPI, into the next OpenSeaDragon release, enabling simple and immediate drop-in\nreplacement of DZI images within WSI viewer stacks. Designed as a secure\ncross-origin resource sharing microservice, this architecture includes detailed\ndeployment instructions for new or existing WSI workflows, and the public\nexamples.restful.irisdigitialpathology.org subdomain is provided as a\ndevelopment tool to accelerate WSI web viewer development.", "AI": {"tldr": "\u5f00\u53d1\u4e86Iris RESTful Server\uff0c\u652f\u6301\u9ad8\u6027\u80fd\u7684WSI\u6587\u4ef6\u6d41\u5f0f\u4f20\u8f93\uff0c\u517c\u5bb9DICOMweb WADO-RS API\uff0c\u5e76\u4e0eOpenSeaDragon\u96c6\u6210\u3002", "motivation": "\u89e3\u51b3\u9759\u6001HTTP\u6587\u4ef6\u670d\u52a1\u5668\u65e0\u6cd5\u6d41\u5f0f\u4f20\u8f93\u9ad8\u5206\u8fa8\u7387WSI\u6587\u4ef6\u7684\u95ee\u9898\uff0c\u63d0\u5347\u75c5\u7406\u5b66\u5bb6\u7684\u56fe\u50cf\u6e32\u67d3\u4f53\u9a8c\u3002", "method": "\u4f7f\u7528C++\u548cBoost Beast HTTP\u53caAsio\u5e93\u5f00\u53d1RESTful\u670d\u52a1\u5668\uff0c\u517c\u5bb9DICOMweb WADO-RS API\uff0c\u5e76\u96c6\u6210OpenSeaDragon TileSource\u3002", "result": "\u5355\u5b9e\u4f8b\u6bcf\u79d2\u53ef\u5904\u74065000\u4e2a\u74e6\u7247\u8bf7\u6c42\uff0c\u5ef6\u8fdf\u4e2d\u4f4d\u6570\u4e3a21\u6beb\u79d2\u3002", "conclusion": "Iris RESTful Server\u4e3aWSI\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u3001\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u7b80\u5316\u4e86\u96c6\u6210\u3002"}}
{"id": "2508.06559", "categories": ["cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06559", "abs": "https://arxiv.org/abs/2508.06559", "authors": ["Sina Baghal"], "title": "Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization", "comment": null, "summary": "Pasur is a fishing card game played over six rounds and is played similarly\nto games such as Cassino and Scopa, and Bastra. This paper introduces a\nCUDA-accelerated computational framework for simulating Pasur, emphasizing\nefficient memory management. We use our framework to compute near-Nash\nequilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm\nfor solving large imperfect-information games.\n  Solving Pasur presents unique challenges due to its intricate rules and the\nlarge size of its game tree. We handle rule complexity using PyTorch CUDA\ntensors and to address the memory-intensive nature of the game, we decompose\nthe game tree into two key components: (1) actual game states, and (2)\ninherited scores from previous rounds. We construct the Full Game Tree by\npairing card states with accumulated scores in the Unfolding Process. This\ndesign reduces memory overhead by storing only essential strategy values and\nnode connections. To further manage computational complexity, we apply a\nround-by-round backward training strategy, starting from the final round and\nrecursively propagating average utilities to earlier stages. Our approach\nconstructs the complete game tree, which on average consists of over $10^9$\nnodes. We provide detailed implementation snippets.\n  After computing a near-Nash equilibrium strategy, we train a tree-based model\nto predict these strategies for use during gameplay. We then estimate the fair\nvalue of each deck through large-scale self-play between equilibrium strategies\nby simulating, for instance, 10,000 games per matchup, executed in parallel\nusing GPU acceleration.\n  Similar frameworks can be extended to other reinforcement learning algorithms\nwhere the action tree naturally decomposes into multiple rounds such as\nturn-based strategy games or sequential trading decisions in financial markets.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8eCUDA\u52a0\u901f\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62dfPasur\u9493\u9c7c\u5361\u724c\u6e38\u620f\uff0c\u5e76\u901a\u8fc7CFR\u7b97\u6cd5\u8ba1\u7b97\u8fd1\u7eb3\u4ec0\u5747\u8861\u3002\u6846\u67b6\u901a\u8fc7\u9ad8\u6548\u5185\u5b58\u7ba1\u7406\u548c\u6e38\u620f\u6811\u5206\u89e3\u89e3\u51b3\u590d\u6742\u89c4\u5219\u548c\u5927\u89c4\u6a21\u6e38\u620f\u6811\u7684\u6311\u6218\u3002", "motivation": "Pasur\u6e38\u620f\u7684\u590d\u6742\u89c4\u5219\u548c\u5927\u89c4\u6a21\u6e38\u620f\u6811\u4e3a\u8ba1\u7b97\u8fd1\u7eb3\u4ec0\u5747\u8861\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528PyTorch CUDA\u5f20\u91cf\u5904\u7406\u89c4\u5219\u590d\u6742\u6027\uff0c\u5c06\u6e38\u620f\u6811\u5206\u89e3\u4e3a\u5b9e\u9645\u6e38\u620f\u72b6\u6001\u548c\u7ee7\u627f\u5206\u6570\uff0c\u91c7\u7528\u9010\u8f6e\u53cd\u5411\u8bad\u7ec3\u7b56\u7565\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b\u8d85\u8fc710^9\u4e2a\u8282\u70b9\u7684\u5b8c\u6574\u6e38\u620f\u6811\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u5bf9\u5f08\u4f30\u8ba1\u6bcf\u526f\u724c\u7684\u516c\u5e73\u4ef7\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u591a\u8f6e\u6b21\u5f3a\u5316\u5b66\u4e60\u573a\u666f\uff0c\u5982\u56de\u5408\u5236\u7b56\u7565\u6e38\u620f\u6216\u91d1\u878d\u5e02\u573a\u4e2d\u7684\u987a\u5e8f\u4ea4\u6613\u51b3\u7b56\u3002"}}
{"id": "2508.06956", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.06956", "abs": "https://arxiv.org/abs/2508.06956", "authors": ["Keqiang Guo", "Yuheng Zhong", "Xin Tong", "Jiangbin Lyu", "Rui Zhang"], "title": "Neural Beam Field for Spatial Beam RSRP Prediction", "comment": "Keywords: Neural Beam Field, Multipath Conditional Power Profile,\n  Channel Knowledge Map, Beam-level RSRP, Transformer", "summary": "Accurately predicting beam-level reference signal received power (RSRP) is\nessential for beam management in dense multi-user wireless networks, yet\nchallenging due to high measurement overhead and fast channel variations. This\npaper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for\nefficient and interpretable spatial beam RSRP prediction. Central to our\napproach is the introduction of the Multi-path Conditional Power Profile\n(MCPP), which bridges site-specific multipath propagation with antenna/beam\nconfigurations via closed-form analytical modeling. We adopt a decoupled\n``blackbox-whitebox\" design: a Transformer-based deep neural network (DNN)\nlearns the MCPP from sparse user measurements and positions, while a\nphysics-inspired module analytically infers beam RSRP statistics. To improve\nconvergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC)\nstrategy that leverages ray-tracing priors and on-site calibration using RSRP\ndata. Extensive simulations results demonstrate that NBF significantly\noutperforms conventional table-based channel knowledge maps (CKMs) and pure\nblackbox DNNs in prediction accuracy, training efficiency, and generalization,\nwhile maintaining a compact model size. The proposed framework offers a\nscalable and physically grounded solution for intelligent beam management in\nnext-generation dense wireless networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u795e\u7ecf\u7269\u7406\u6846\u67b6NBF\uff0c\u7528\u4e8e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u7a7a\u95f4\u6ce2\u675fRSRP\u9884\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5bc6\u96c6\u591a\u7528\u6237\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u51c6\u786e\u9884\u6d4b\u6ce2\u675f\u7ea7RSRP\u5bf9\u6ce2\u675f\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9ad8\u6d4b\u91cf\u5f00\u9500\u548c\u5feb\u901f\u4fe1\u9053\u53d8\u5316\u4f7f\u5176\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u7ed3\u5408\u4e86Transformer DNN\u548c\u7269\u7406\u6a21\u5757\uff0c\u5f15\u5165MCPP\u6865\u63a5\u591a\u5f84\u4f20\u64ad\u4e0e\u6ce2\u675f\u914d\u7f6e\uff0c\u91c7\u7528\u9884\u8bad\u7ec3\u6821\u51c6\u7b56\u7565\u3002", "result": "NBF\u5728\u9884\u6d4b\u7cbe\u5ea6\u3001\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u7d27\u51d1\u6a21\u578b\u3002", "conclusion": "NBF\u4e3a\u4e0b\u4e00\u4ee3\u5bc6\u96c6\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7269\u7406\u57fa\u7840\u624e\u5b9e\u7684\u667a\u80fd\u6ce2\u675f\u7ba1\u7406\u65b9\u6848\u3002"}}
{"id": "2508.06616", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06616", "abs": "https://arxiv.org/abs/2508.06616", "authors": ["Md Arafat Habib", "Medhat Elsayed", "Yigit Ozcan", "Pedro Enrique Iturria-Rivera", "Majid Bavand", "Melike Erol-Kantarci"], "title": "Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach", "comment": null, "summary": "With the emergence of 6G, mobile networks are becoming increasingly\nheterogeneous and dynamic, necessitating advanced automation for efficient\nmanagement. Intent-Driven Networks (IDNs) address this by translating\nhigh-level intents into optimization policies. Large Language Models (LLMs) can\nenhance this process by understanding complex human instructions to enable\nadaptive, intelligent automation. Given the rapid advancements in Generative AI\n(GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated\nRadio Access Network (RAN) environments is both timely and critical. This\narticle provides such a survey, along with a case study on a hierarchical\nlearning-enabled IDN architecture that integrates GenAI across three key\nstages: intent processing, intent validation, and intent execution. Unlike most\nexisting approaches that apply GenAI in the form of LLMs for intent processing\nonly, we propose a hierarchical framework that introduces GenAI across all\nthree stages of IDN. To demonstrate the effectiveness of the proposed IDN\nmanagement architecture, we present a case study based on the latest GenAI\narchitecture named Mamba. The case study shows how the proposed GenAI-driven\narchitecture enhances network performance through intelligent automation,\nsurpassing the performance of the conventional IDN architectures.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\uff08IDN\uff09\u67b6\u6784\u57286G\u5f02\u6784\u52a8\u6001\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u6846\u67b6\uff0c\u5c06\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u6574\u5408\u5230IDN\u7684\u4e09\u4e2a\u5173\u952e\u9636\u6bb5\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u968f\u77406G\u7684\u51fa\u73b0\uff0c\u79fb\u52a8\u7f51\u7edc\u53d8\u5f97\u65e5\u76ca\u5f02\u6784\u548c\u52a8\u6001\uff0c\u9700\u8981\u9ad8\u7ea7\u81ea\u52a8\u5316\u7ba1\u7406\u3002\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\uff08IDN\uff09\u901a\u8fc7\u5c06\u9ad8\u5c42\u610f\u56fe\u8f6c\u5316\u4e3a\u4f18\u5316\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u4ee5\u589e\u5f3a\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5b66\u4e60\u9a71\u52a8\u7684IDN\u67b6\u6784\uff0c\u5c06GenAI\u6574\u5408\u5230\u610f\u56fe\u5904\u7406\u3001\u610f\u56fe\u9a8c\u8bc1\u548c\u610f\u56fe\u6267\u884c\u4e09\u4e2a\u9636\u6bb5\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u6700\u65b0GenAI\u67b6\u6784Mamba\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684GenAI\u9a71\u52a8\u67b6\u6784\u901a\u8fc7\u667a\u80fd\u81ea\u52a8\u5316\u63d0\u5347\u4e86\u7f51\u7edc\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edfIDN\u67b6\u6784\u3002", "conclusion": "\u672c\u6587\u4e3a6G\u7f51\u7edc\u4e2dLLM-based IDN\u67b6\u6784\u7684\u5168\u9762\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u5e76\u5c55\u793a\u4e86GenAI\u5728IDN\u5168\u9636\u6bb5\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.06569", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2508.06569", "abs": "https://arxiv.org/abs/2508.06569", "authors": ["Lance Yao", "Suman Samantray", "Ayana Ghosh", "Kevin Roccapriore", "Libor Kovarik", "Sarah Allec", "Maxim Ziatdinov"], "title": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop", "comment": null, "summary": "The history of science is punctuated by serendipitous discoveries, where\nunexpected observations, rather than targeted hypotheses, opened new fields of\ninquiry. While modern autonomous laboratories excel at accelerating hypothesis\ntesting, their optimization for efficiency risks overlooking these crucial,\nunplanned findings. To address this gap, we introduce SciLink, an open-source,\nmulti-agent artificial intelligence framework designed to operationalize\nserendipity in materials research by creating a direct, automated link between\nexperimental observation, novelty assessment, and theoretical simulations. The\nframework employs a hybrid AI strategy where specialized machine learning\nmodels perform quantitative analysis of experimental data, while large language\nmodels handle higher-level reasoning. These agents autonomously convert raw\ndata from materials characterization techniques into falsifiable scientific\nclaims, which are then quantitatively scored for novelty against the published\nliterature. We demonstrate the framework's versatility across diverse research\nscenarios, showcasing its application to atomic-resolution and hyperspectral\ndata, its capacity to integrate real-time human expert guidance, and its\nability to close the research loop by proposing targeted follow-up experiments.\nBy systematically analyzing all observations and contextualizing them, SciLink\nprovides a practical framework for AI-driven materials research that not only\nenhances efficiency but also actively cultivates an environment ripe for\nserendipitous discoveries, thereby bridging the gap between automated\nexperimentation and open-ended scientific exploration.", "AI": {"tldr": "SciLink\u662f\u4e00\u4e2a\u5f00\u6e90\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u94fe\u63a5\u5b9e\u9a8c\u89c2\u5bdf\u3001\u65b0\u9896\u6027\u8bc4\u4f30\u548c\u7406\u8bba\u6a21\u62df\uff0c\u5728\u6750\u6599\u7814\u7a76\u4e2d\u5b9e\u73b0\u610f\u5916\u53d1\u73b0\u3002", "motivation": "\u73b0\u4ee3\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u867d\u80fd\u52a0\u901f\u5047\u8bbe\u9a8c\u8bc1\uff0c\u4f46\u6548\u7387\u4f18\u5316\u53ef\u80fd\u5ffd\u7565\u610f\u5916\u53d1\u73b0\uff0cSciLink\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6df7\u5408AI\u7b56\u7565\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5b9a\u91cf\u5206\u6790\u5b9e\u9a8c\u6570\u636e\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ad8\u7ea7\u63a8\u7406\uff0c\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u79d1\u5b66\u4e3b\u5f20\uff0c\u5e76\u6839\u636e\u6587\u732e\u8bc4\u4f30\u65b0\u9896\u6027\u3002", "result": "SciLink\u5728\u591a\u79cd\u7814\u7a76\u573a\u666f\u4e2d\u5c55\u73b0\u591a\u529f\u80fd\u6027\uff0c\u5305\u62ec\u539f\u5b50\u5206\u8fa8\u7387\u548c\u8d85\u5149\u8c31\u6570\u636e\u5904\u7406\uff0c\u6574\u5408\u5b9e\u65f6\u4e13\u5bb6\u6307\u5bfc\uff0c\u5e76\u63d0\u51fa\u9488\u5bf9\u6027\u540e\u7eed\u5b9e\u9a8c\u3002", "conclusion": "SciLink\u4e0d\u4ec5\u63d0\u5347\u6548\u7387\uff0c\u8fd8\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u6240\u6709\u89c2\u5bdf\u7ed3\u679c\uff0c\u4e3aAI\u9a71\u52a8\u7684\u6750\u6599\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4fc3\u8fdb\u610f\u5916\u53d1\u73b0\u7684\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2508.07009", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07009", "abs": "https://arxiv.org/abs/2508.07009", "authors": ["Xintong Chen", "Zhenyu Jiang", "Jiangbin Lyu", "Liqun Fu"], "title": "Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems", "comment": "Propose Neural Channel Knowledge Map for multi-user scheduling", "summary": "Intelligent Reflecting Surfaces (IRSs) have potential for significant\nperformance gains in next-generation wireless networks but face key challenges,\nnotably severe double-pathloss and complex multi-user scheduling due to\nhardware constraints. Active IRSs partially address pathloss but still require\nefficient scheduling in cell-level multi-IRS multi-user systems, whereby the\noverhead/delay of channel state acquisition and the scheduling complexity both\nrise dramatically as the user density and channel dimensions increase.\nMotivated by these challenges, this paper proposes a novel scheduling framework\nbased on neural Channel Knowledge Map (CKM), designing Transformer-based deep\nneural networks (DNNs) to predict ergodic spectral efficiency (SE) from\nhistorical channel/throughput measurements tagged with user positions.\nSpecifically, two cascaded networks, LPS-Net and SE-Net, are designed to\npredict link power statistics (LPS) and ergodic SE accurately. We further\npropose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling\nalgorithm. Numerical evaluations verify that the proposed neural CKM\nsignificantly enhances prediction accuracy and computational efficiency, while\nthe SM-IB algorithm effectively achieves near-optimal max-min throughput with\ngreatly reduced complexity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u901a\u9053\u77e5\u8bc6\u56fe\uff08CKM\uff09\u7684\u65b0\u578b\u8c03\u5ea6\u6846\u67b6\uff0c\u7ed3\u5408Transformer\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u4f4e\u590d\u6742\u5ea6\u8c03\u5ea6\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u5728\u591a\u7528\u6237\u7cfb\u7edf\u4e2d\u7684\u8def\u5f84\u635f\u8017\u548c\u8c03\u5ea6\u590d\u6742\u6027\u95ee\u9898\u3002", "motivation": "\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u4e25\u91cd\u7684\u53cc\u8def\u5f84\u635f\u8017\u548c\u590d\u6742\u7684\u591a\u7528\u6237\u8c03\u5ea6\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u4e3b\u52a8IRS\u4ec5\u90e8\u5206\u89e3\u51b3\u8def\u5f84\u635f\u8017\uff0c\u4ecd\u9700\u9ad8\u6548\u8c03\u5ea6\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8eTransformer\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08LPS-Net\u548cSE-Net\uff09\u9884\u6d4b\u94fe\u8def\u529f\u7387\u7edf\u8ba1\u548c\u904d\u5386\u9891\u8c31\u6548\u7387\uff0c\u5e76\u63d0\u51fa\u4f4e\u590d\u6742\u5ea6\u8c03\u5ea6\u7b97\u6cd5SM-IB\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u8868\u660e\uff0c\u795e\u7ecfCKM\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\uff0cSM-IB\u7b97\u6cd5\u4ee5\u8f83\u4f4e\u590d\u6742\u5ea6\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6700\u5927-\u6700\u5c0f\u541e\u5410\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591aIRS\u591a\u7528\u6237\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u590d\u6742\u5ea6\u5e73\u8861\u3002"}}
{"id": "2508.06975", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.06975", "abs": "https://arxiv.org/abs/2508.06975", "authors": ["Zhengying Lou", "Baha Eddine Youcef Belmekki", "Mohamed-Slim Alouini"], "title": "THz/RF Multi-Hop Routing Throughput: Performance, Optimization, and Application", "comment": null, "summary": "Terahertz (THz) communication offers a promising solution for high-throughput\nwireless systems. However, the severe path loss of THz signals raises concerns\nabout its effectiveness compared to radio frequency (RF) communication. In this\narticle, we establish the first stochastic geometry (SG)-based analytical\nframework for routing in THz systems. We develop a stepwise optimization\napproach to maximize throughput, including power allocation, relay selection,\nand number of hops design. Analytical expressions for throughput and coverage\nprobability are derived under the SG framework, enabling low complexity and\nscalable performance evaluation. Numerical results show that the proposed\nstepwise-optimal routing strategies not only outperform existing SG-based\nmethods but also approach the ideal upper bound. Moreover, we compare the\nthroughput and coverage performance of THz and RF routing and demonstrate the\napplications of the proposed analytical framework and routing strategies in\nsystem parameter design and unmanned aerial vehicle networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u51e0\u4f55\u7684THz\u901a\u4fe1\u8def\u7531\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6b65\u4f18\u5316\u65b9\u6cd5\u63d0\u5347\u541e\u5410\u91cf\uff0c\u6027\u80fd\u63a5\u8fd1\u7406\u8bba\u4e0a\u9650\u3002", "motivation": "THz\u901a\u4fe1\u7684\u9ad8\u8def\u5f84\u635f\u8017\u95ee\u9898\u9700\u8981\u9ad8\u6548\u8def\u7531\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u5176\u5728\u9ad8\u541e\u5410\u91cf\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u968f\u673a\u51e0\u4f55\u5206\u6790\u6846\u67b6\uff0c\u5206\u6b65\u4f18\u5316\u529f\u7387\u5206\u914d\u3001\u4e2d\u7ee7\u9009\u62e9\u548c\u8df3\u6570\u8bbe\u8ba1\u3002", "result": "\u63d0\u51fa\u7684\u8def\u7531\u7b56\u7565\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6027\u80fd\u63a5\u8fd1\u7406\u8bba\u4e0a\u9650\uff0c\u5e76\u9a8c\u8bc1\u4e86THz\u4e0eRF\u8def\u7531\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aTHz\u7cfb\u7edf\u53c2\u6570\u8bbe\u8ba1\u548c\u65e0\u4eba\u673a\u7f51\u7edc\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.06571", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06571", "abs": "https://arxiv.org/abs/2508.06571", "authors": ["Anqing Jiang", "Yu Gao", "Yiru Wang", "Zhigang Sun", "Shuo Wang", "Yuwen Heng", "Hao Sun", "Shichen Tang", "Lijuan Zhu", "Jinhao Chai", "Jijun Wang", "Zichong Gu", "Hao Jiang", "Li Sun"], "title": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model", "comment": "9 pagres, 2 figures", "summary": "Vision-Language-Action (VLA) models have demonstrated potential in autonomous\ndriving. However, two critical challenges hinder their development: (1)\nExisting VLA architectures are typically based on imitation learning in\nopen-loop setup which tends to capture the recorded behaviors in the dataset,\nleading to suboptimal and constrained performance, (2) Close-loop training\nrelies heavily on high-fidelity sensor simulation, where domain gaps and\ncomputational inefficiencies pose significant barriers. In this paper, we\nintroduce IRL-VLA, a novel close-loop Reinforcement Learning via\n\\textbf{I}nverse \\textbf{R}einforcement \\textbf{L}earning reward world model\nwith a self-built VLA approach. Our framework proceeds in a three-stage\nparadigm: In the first stage, we propose a VLA architecture and pretrain the\nVLA policy via imitation learning. In the second stage, we construct a\nlightweight reward world model via inverse reinforcement learning to enable\nefficient close-loop reward computation. To further enhance planning\nperformance, finally, we design specialized reward world model guidence\nreinforcement learning via PPO(Proximal Policy Optimization) to effectively\nbalance the safety incidents, comfortable driving, and traffic efficiency. Our\napproach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving\nbenchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that\nour framework will accelerate VLA research in close-loop autonomous driving.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faIRL-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u65b9\u6cd5\u89e3\u51b3VLA\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u95ed\u73af\u8bad\u7ec3\u95ee\u9898\uff0c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u9006\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u5728\u5f00\u73af\u6a21\u4eff\u5b66\u4e60\u4e2d\u8868\u73b0\u53d7\u9650\uff0c\u95ed\u73af\u8bad\u7ec3\u4f9d\u8d56\u9ad8\u4fdd\u771f\u6a21\u62df\uff0c\u5b58\u5728\u9886\u57df\u5dee\u8ddd\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u6a21\u4eff\u5b66\u4e60\u9884\u8bad\u7ec3VLA\u7b56\u7565\uff1b2) \u9006\u5f3a\u5316\u5b66\u4e60\u6784\u5efa\u8f7b\u91cf\u7ea7\u5956\u52b1\u4e16\u754c\u6a21\u578b\uff1b3) PPO\u4f18\u5316\u5956\u52b1\u6a21\u578b\u4ee5\u5e73\u8861\u5b89\u5168\u3001\u8212\u9002\u548c\u6548\u7387\u3002", "result": "\u5728NAVSIM v2\u7aef\u5230\u7aef\u9a7e\u9a76\u57fa\u51c6\u4e2d\u8fbe\u5230SOTA\uff0cCVPR2025\u81ea\u52a8\u9a7e\u9a76\u6311\u6218\u8d5b\u7b2c\u4e8c\u540d\u3002", "conclusion": "IRL-VLA\u6846\u67b6\u6709\u671b\u52a0\u901f\u95ed\u73af\u81ea\u52a8\u9a7e\u9a76\u4e2dVLA\u6a21\u578b\u7684\u7814\u7a76\u3002"}}
{"id": "2508.07030", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07030", "abs": "https://arxiv.org/abs/2508.07030", "authors": ["Roxana Smarandache", "David G. M. Mitchell", "Anthony G\u00f3mez-Fonseca"], "title": "Generalized Quasi-Cyclic LDPC Codes: Design and Efficient Encoding", "comment": null, "summary": "Generalized low-density parity-check (GLDPC) codes, where single parity-check\nconstraints on the code bits are replaced with generalized constraints (an\narbitrary linear code), are a promising class of codes for low-latency\ncommunication. The block error rate performance of the GLDPC codes, combined\nwith a complementary outer code, has been shown to outperform a variety of\nstate-of-the-art code and decoder designs with suitable lengths and rates for\nthe 5G ultra-reliable low-latency communication (URLLC) regime. A major\ndrawback of these codes is that it is not known how to construct appropriate\npolynomial matrices to encode them efficiently. In this paper, we analyze\npractical constructions of quasi-cyclic GLDPC (QC-GLDPC) codes and show how to\nconstruct polynomial generator matrices in various forms using minors of the\npolynomial matrix. The approach can be applied to fully generalized matrices or\npartially generalized (with mixed constraint node types) to find better\nperformance/rate trade-offs. The resulting encoding matrices are presented in\nuseful forms that facilitate efficient implementation. The rich substructure\ndisplayed also provides us with new methods of determining low weight\ncodewords, providing lower and upper bounds on the minimum distance and often\ngiving those of weight equal to the minimum distance. Based on the minors of\nthe polynomial parity-check matrix, we also give a formula for the rank of any\nparity-check matrix representing a QC-LDPC or QC-GLDPC code, and hence, the\ndimension of the code. Finally, we show that by applying double graph-liftings,\nthe code parameters can be improved without affecting the ability to obtain a\npolynomial generator matrix.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u51c6\u5faa\u73af\u5e7f\u4e49\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\uff08QC-GLDPC\uff09\u7801\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u9879\u5f0f\u77e9\u9635\u5b50\u5f0f\u7684\u9ad8\u6548\u7f16\u7801\u77e9\u9635\u751f\u6210\u6280\u672f\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6027\u80fd\u4e0e\u901f\u7387\u6743\u8861\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "GLDPC\u7801\u5728\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u6548\u7f16\u7801\u7684\u591a\u9879\u5f0f\u77e9\u9635\u6784\u9020\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u9879\u5f0f\u77e9\u9635\u7684\u5b50\u5f0f\uff0c\u6784\u9020\u4e86\u591a\u79cd\u5f62\u5f0f\u7684\u751f\u6210\u77e9\u9635\uff0c\u5e76\u5e94\u7528\u53cc\u56fe\u63d0\u5347\u6280\u672f\u4f18\u5316\u7801\u53c2\u6570\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u5b9e\u73b0\u7f16\u7801\u77e9\u9635\uff0c\u5e76\u63d0\u4f9b\u4e86\u7801\u7684\u6700\u5c0f\u8ddd\u79bb\u548c\u7ef4\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aQC-GLDPC\u7801\u7684\u6784\u9020\u548c\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u751f\u6210\u77e9\u9635\u7684\u591a\u9879\u5f0f\u7279\u6027\u3002"}}
{"id": "2508.07001", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07001", "abs": "https://arxiv.org/abs/2508.07001", "authors": ["Myeung Suk Oh", "Zhiyao Zhang", "FNU Hairi", "Alvaro Velasquez", "Jia Liu"], "title": "Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization", "comment": "This paper has been accepted in ACM International Symposium on\n  Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and\n  Mobile Computing (MobiHoc) 2025", "summary": "With wireless devices increasingly forming a unified smart network for\nseamless, user-friendly operations, random access (RA) medium access control\n(MAC) design is considered a key solution for handling unpredictable data\ntraffic from multiple terminals. However, it remains challenging to design an\neffective RA-based MAC protocol to minimize collisions and ensure transmission\nfairness across the devices. While existing multi-agent reinforcement learning\n(MARL) approaches with centralized training and decentralized execution (CTDE)\nhave been proposed to optimize RA performance, their reliance on centralized\ntraining and the significant overhead required for information collection can\nmake real-world applications unrealistic. In this work, we adopt a fully\ndecentralized MARL architecture, where policy learning does not rely on\ncentralized tasks but leverages consensus-based information exchanges across\ndevices. We design our MARL algorithm over an actor-critic (AC) network and\npropose exchanging only local rewards to minimize communication overhead.\nFurthermore, we provide a theoretical proof of global convergence for our\napproach. Numerical experiments show that our proposed MARL algorithm can\nsignificantly improve RA network performance compared to other baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u5c40\u90e8\u5956\u52b1\u4ea4\u6362\u4f18\u5316\u968f\u673a\u63a5\u5165\uff08RA\uff09MAC\u534f\u8bae\u6027\u80fd\uff0c\u51cf\u5c11\u78b0\u649e\u5e76\u786e\u4fdd\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u96c6\u4e2d\u8bad\u7ec3\u548c\u5206\u6563\u6267\u884c\uff08CTDE\uff09\u7684MARL\u65b9\u6cd5\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u56e0\u96c6\u4e2d\u8bad\u7ec3\u4f9d\u8d56\u548c\u4fe1\u606f\u6536\u96c6\u5f00\u9500\u5927\u800c\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684MARL\u67b6\u6784\uff0c\u57fa\u4e8e\u5171\u8bc6\u7684\u4fe1\u606f\u4ea4\u6362\uff0c\u8bbe\u8ba1\u57fa\u4e8eactor-critic\u7f51\u7edc\u7684\u7b97\u6cd5\uff0c\u4ec5\u4ea4\u6362\u5c40\u90e8\u5956\u52b1\u4ee5\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86RA\u7f51\u7edc\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u53bb\u4e2d\u5fc3\u5316MARL\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u3002"}}
{"id": "2508.06585", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06585", "abs": "https://arxiv.org/abs/2508.06585", "authors": ["Jayant Sravan Tamarapalli", "Rynaa Grover", "Nilay Pande", "Sahiti Yerramilli"], "title": "CountQA: How Well Do MLLMs Count in the Wild?", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in\nunderstanding visual scenes, yet they exhibit a critical lack in a fundamental\ncognitive skill: object counting. This blind spot severely limits their\nreliability in real-world applications. To date, this capability has been\nlargely unevaluated in complex scenarios, as existing benchmarks either feature\nsparse object densities or are confined to specific visual domains, failing to\ntest models under realistic conditions. Addressing this gap, we introduce\nCountQA, a challenging new benchmark designed to probe this deficiency.\nComprising over 1,500 question-answer pairs, CountQA features real-world images\nwith high object density, clutter, and occlusion. We investigate this weakness\nby evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the\ntop-performing model achieves a mere 42.9% accuracy, with performance declining\nas object counts rise. By providing a dedicated benchmark to diagnose and\nrectify this core weakness, CountQA paves the way for a new generation of MLLMs\nthat are not only descriptively fluent but also numerically grounded and\nspatially aware. We will open-source the dataset and code upon paper acceptance\nto foster further research.", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u89c6\u89c9\u573a\u666f\u7406\u89e3\u4e0a\u8868\u73b0\u6d41\u7545\uff0c\u4f46\u5728\u5bf9\u8c61\u8ba1\u6570\u80fd\u529b\u4e0a\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\u3002CountQA\u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u63d0\u5347MLLMs\u7684\u8ba1\u6570\u80fd\u529b\u3002", "motivation": "\u73b0\u6709MLLMs\u5728\u5bf9\u8c61\u8ba1\u6570\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6d4b\u8bd5\u590d\u6742\u573a\u666f\u4e0b\u7684\u8ba1\u6570\u80fd\u529b\u3002", "method": "\u5f15\u5165CountQA\u57fa\u51c6\uff0c\u5305\u542b1,500\u591a\u4e2a\u95ee\u7b54\u5bf9\uff0c\u8986\u76d6\u9ad8\u5bc6\u5ea6\u3001\u6742\u4e71\u548c\u906e\u6321\u7684\u771f\u5b9e\u56fe\u50cf\u3002\u8bc4\u4f30\u4e8615\u79cd\u4e3b\u6d41MLLMs\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u51c6\u786e\u7387\u4ec5\u4e3a42.9%\uff0c\u4e14\u968f\u7740\u5bf9\u8c61\u6570\u91cf\u589e\u52a0\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "CountQA\u4e3a\u8bca\u65ad\u548c\u89e3\u51b3MLLMs\u7684\u8ba1\u6570\u5f31\u70b9\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u63a8\u52a8\u66f4\u5168\u9762\u80fd\u529b\u7684MLLMs\u53d1\u5c55\u3002"}}
{"id": "2508.07098", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07098", "abs": "https://arxiv.org/abs/2508.07098", "authors": ["Ayane Lebeta Goshu", "Placido Mursia", "Vincenzo Sciancalepore", "Marco Di Renzo", "Xavier Costa-P\u00e9rez"], "title": "Realistic Evaluation of Impedance-Based RIS Modeling: Practical Insights and Applications", "comment": "Published in 2025 19th European Conference on Antennas and\n  Propagation (EuCAP): Five pages, six figures", "summary": "Reconfigurable Intelligent Surfaces (RISs) have emerged as a promising\ntechnology for next-generation wireless communications, offering\nenergy-efficient control of electromagnetic (EM) waves. While conventional RIS\nmodels based on phase shifts and amplitude adjustments have been widely\nstudied, they overlook complex EM phenomena such as mutual coupling, which are\ncrucial for advanced wave manipulations. Recent efforts in EM-consistent\nmodelling have provided more accurate representations of RIS behavior,\nhighlighting challenges like structural scattering-an unwanted signal\nreflection that can lead to interference. In this paper, we analyze the impact\nof structural scattering in RIS architectures and compare traditional and\nEM-consistent models through full-wave simulations, thus providing practical\ninsights on the realistic performance of current RIS designs. Our findings\nreveal the limitations of current modelling approaches in mitigating this\nissue, underscoring the need for new optimization strategies.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u4e2d\u7684\u7ed3\u6784\u6563\u5c04\u95ee\u9898\uff0c\u6bd4\u8f83\u4e86\u4f20\u7edf\u6a21\u578b\u4e0e\u7535\u78c1\u4e00\u81f4\u6027\u6a21\u578b\u7684\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfRIS\u6a21\u578b\u5ffd\u7565\u4e86\u590d\u6742\u7684\u7535\u78c1\u73b0\u8c61\uff08\u5982\u4e92\u8026\u5408\u548c\u7ed3\u6784\u6563\u5c04\uff09\uff0c\u800c\u7535\u78c1\u4e00\u81f4\u6027\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u63cf\u8ff0RIS\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5176\u5bf9\u6027\u80fd\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5168\u6ce2\u4eff\u771f\u5206\u6790\u7ed3\u6784\u6563\u5c04\u5728RIS\u67b6\u6784\u4e2d\u7684\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u4f20\u7edf\u6a21\u578b\u4e0e\u7535\u78c1\u4e00\u81f4\u6027\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u7f13\u89e3\u7ed3\u6784\u6563\u5c04\u95ee\u9898\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u65b0\u7684\u4f18\u5316\u7b56\u7565\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u4e86\u7535\u78c1\u4e00\u81f4\u6027\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u672a\u6765RIS\u8bbe\u8ba1\u9700\u8003\u8651\u66f4\u590d\u6742\u7684\u7535\u78c1\u73b0\u8c61\u3002"}}
{"id": "2508.07194", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07194", "abs": "https://arxiv.org/abs/2508.07194", "authors": ["Jack Wampler", "Hammas Bin Tanveer", "Rishab Nithyanand", "Eric Wustrow"], "title": "ProtoScan: Measuring censorship in IPv6", "comment": "10 pages, 2 figures, 2 tables", "summary": "Internet censorship continues to impact billions of people worldwide, and\nmeasurement of it remains an important focus of research. However, most\nInternet censorship measurements have focused solely on the IPv4 Internet\ninfrastructure. Yet, more clients and servers are available over IPv6:\nAccording to Google, over a third of their users now have native IPv6 access.\nGiven the slow-but-steady rate of IPv6 adoption, it is important to understand\nits impact on censorship. In this paper, we measure and analyze how censorship\ndiffers over IPv6 compared to the well-studied IPv4 censorship systems in use\ntoday. We perform a comprehensive global study of censorship across an array of\ncommonly censored protocols, including HTTP, DNS, and TLS, on both IPv4 and\nIPv6, and compare the results. We find that there are several differences in\nhow countries censor IPv6 traffic, both in terms of IPv6 resources, and in\nwhere and what blocklists or technologies are deployed on IPv6 networks. Many\nof these differences are not all-or-nothing: we find that most censors have\nsome capacity to block in IPv6, but are less comprehensive or less reliable\ncompared to their IPv4 censorship systems. Our results suggest that IPv6 offers\nnew areas for censorship circumvention researchers to explore, providing\npotentially new ways to evade censors. As more users gain access to IPv6\naddresses and networks, there will be a need for tools that take advantage of\nIPv6 techniques and infrastructure to bypass censorship.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86IPv6\u4e0eIPv4\u5728\u4e92\u8054\u7f51\u5ba1\u67e5\u4e2d\u7684\u5dee\u5f02\uff0c\u53d1\u73b0IPv6\u5ba1\u67e5\u80fd\u529b\u8f83\u5f31\u4e14\u4e0d\u5168\u9762\uff0c\u4e3a\u89c4\u907f\u5ba1\u67e5\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "motivation": "\u968f\u7740IPv6\u7684\u666e\u53ca\uff0c\u4e86\u89e3\u5176\u5728\u5ba1\u67e5\u4e2d\u7684\u5f71\u54cd\u53d8\u5f97\u91cd\u8981\uff0c\u56e0\u4e3a\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8IPv4\u3002", "method": "\u901a\u8fc7\u5168\u7403\u6027\u7814\u7a76\uff0c\u6bd4\u8f83IPv4\u548cIPv6\u5728HTTP\u3001DNS\u548cTLS\u7b49\u534f\u8bae\u4e0a\u7684\u5ba1\u67e5\u5dee\u5f02\u3002", "result": "\u53d1\u73b0IPv6\u7684\u5ba1\u67e5\u80fd\u529b\u8f83\u5f31\u4e14\u4e0d\u5168\u9762\uff0c\u90e8\u5206\u56fd\u5bb6\u5728IPv6\u4e0a\u7684\u5ba1\u67e5\u6280\u672f\u548c\u8d44\u6e90\u90e8\u7f72\u4e0eIPv4\u4e0d\u540c\u3002", "conclusion": "IPv6\u4e3a\u89c4\u907f\u5ba1\u67e5\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u672a\u6765\u9700\u8981\u5f00\u53d1\u5229\u7528IPv6\u6280\u672f\u548c\u57fa\u7840\u8bbe\u65bd\u7684\u5de5\u5177\u3002"}}
{"id": "2508.06668", "categories": ["cs.AI", "cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06668", "abs": "https://arxiv.org/abs/2508.06668", "authors": ["Jessie Galasso"], "title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis", "comment": null, "summary": "Formal Concept Analysis (FCA) is a mathematical framework for knowledge\nrepresentation and discovery. It performs a hierarchical clustering over a set\nof objects described by attributes, resulting in conceptual structures in which\nobjects are organized depending on the attributes they share. These conceptual\nstructures naturally highlight commonalities and variabilities among similar\nobjects by categorizing them into groups which are then arranged by similarity,\nmaking it particularly appropriate for variability extraction and analysis.\nDespite the potential of FCA, determining which of its properties can be\nleveraged for variability-related tasks (and how) is not always\nstraightforward, partly due to the mathematical orientation of its foundational\nliterature. This paper attempts to bridge part of this gap by gathering a\nselection of properties of the framework which are essential to variability\nanalysis, and how they can be used to interpret diverse variability information\nwithin the resulting conceptual structures.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u5728\u53d8\u5f02\u6027\u5206\u6790\u4e2d\u7684\u5173\u952e\u5c5e\u6027\u53ca\u5176\u5e94\u7528\u65b9\u6cd5\u3002", "motivation": "FCA\u867d\u7136\u9002\u5408\u53d8\u5f02\u6027\u5206\u6790\uff0c\u4f46\u5176\u6570\u5b66\u57fa\u7840\u4f7f\u5f97\u5982\u4f55\u5229\u7528\u5176\u5c5e\u6027\u8fdb\u884c\u53d8\u5f02\u6027\u4efb\u52a1\u5e76\u4e0d\u76f4\u89c2\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7b5b\u9009FCA\u6846\u67b6\u4e2d\u5bf9\u53d8\u5f02\u6027\u5206\u6790\u81f3\u5173\u91cd\u8981\u7684\u5c5e\u6027\uff0c\u5e76\u89e3\u91ca\u5982\u4f55\u5728\u6982\u5ff5\u7ed3\u6784\u4e2d\u89e3\u8bfb\u53d8\u5f02\u6027\u4fe1\u606f\u3002", "result": "\u660e\u786e\u4e86FCA\u4e2d\u53ef\u7528\u4e8e\u53d8\u5f02\u6027\u5206\u6790\u7684\u5173\u952e\u5c5e\u6027\u53ca\u5176\u5e94\u7528\u65b9\u5f0f\u3002", "conclusion": "\u672c\u6587\u4e3aFCA\u5728\u53d8\u5f02\u6027\u5206\u6790\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5e2e\u52a9\u66f4\u597d\u5730\u5229\u7528\u5176\u6570\u5b66\u6846\u67b6\u3002"}}
{"id": "2508.07461", "categories": ["cs.IT", "math.IT", "math.RA", "16D70, 94B60, 12E20, 08A40"], "pdf": "https://arxiv.org/pdf/2508.07461", "abs": "https://arxiv.org/abs/2508.07461", "authors": ["Maryam Bajalan", "Javier de la Cruz", "Alexandre Fotue Tabue", "Edgar Mart\u00ednez-Moro"], "title": "Duality on group algebras over finite chain rings: applications to additive group codes", "comment": null, "summary": "Given a finite group $G$ and an extension of finite chain rings $S|R$, one\ncan consider the group rings $\\mathscr{S} = S[G]$ and $\\mathscr{R} = R[G]$. The\ngroup ring $\\mathscr{S}$ can be viewed as an $R$-bimodule, and any of its\n$R$-submodules naturally inherits an $R$-bimodule structure; in the framework\nof coding theory, these are called \\emph{additive group codes}, more precisely\na (left) additive group code of is a linear code which is the image of a (left)\nideal of a group algebra via an isomorphism which maps $G$ to the standard\nbasis of $S^n$, where $n=|G|$. In the first part of the paper, the ring\nextension $S|R$ is studied, and several $R$-module isomorphisms are established\nfor decomposing group rings, thereby providing a characterization of the\nstructure of additive group codes. In the second part, we construct a\nsymmetric, nondegenerate trace-Euclidean inner product on $\\mathscr{S}$. Two\nadditive group codes $\\mathcal{C}$ and $\\mathcal{D}$ form an \\emph{additive\ncomplementary pair} (ACP) if $\\mathcal{C} + \\mathcal{D} = \\mathscr{S}$ and\n$\\mathcal{C} \\cap \\mathcal{D} = \\{0\\}$. For two-sided ACPs, we prove that the\northogonal complement of one code under the trace-Euclidean duality is\nprecisely the image of the other under an involutive anti-automorphism of\n$\\mathscr{S}$, linking coding-theoretical ACPs with module orthogonal\ndirect-sum decompositions, representation theory, and the structure of group\nalgebras over finite chain rings.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6709\u9650\u94fe\u73af\u6269\u5c55\u4e0b\u7684\u7fa4\u73af\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u52a0\u6cd5\u7fa4\u7801\u7684\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u6a21\u540c\u6784\u5206\u89e3\u7fa4\u73af\uff0c\u6784\u9020\u4e86\u5bf9\u79f0\u975e\u9000\u5316\u8ff9\u6b27\u51e0\u91cc\u5f97\u5185\u79ef\uff0c\u8bc1\u660e\u4e86\u4e92\u8865\u5bf9\u7684\u6b63\u4ea4\u6027\u8d28\u3002", "motivation": "\u7814\u7a76\u6709\u9650\u94fe\u73af\u6269\u5c55\u4e0b\u7684\u7fa4\u73af\u7ed3\u6784\u53ca\u5176\u5728\u7f16\u7801\u7406\u8bba\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u52a0\u6cd5\u7fa4\u7801\u7684\u6027\u8d28\u548c\u4e92\u8865\u5bf9\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u6a21\u540c\u6784\u5206\u89e3\u7fa4\u73af\uff0c\u6784\u9020\u5bf9\u79f0\u975e\u9000\u5316\u8ff9\u6b27\u51e0\u91cc\u5f97\u5185\u79ef\uff0c\u5e76\u5206\u6790\u52a0\u6cd5\u4e92\u8865\u5bf9\u7684\u6b63\u4ea4\u6027\u8d28\u3002", "result": "\u8bc1\u660e\u4e86\u52a0\u6cd5\u4e92\u8865\u5bf9\u7684\u6b63\u4ea4\u6027\u8d28\uff0c\u63ed\u793a\u4e86\u5176\u4e0e\u6a21\u6b63\u4ea4\u76f4\u548c\u5206\u89e3\u3001\u8868\u793a\u7406\u8bba\u53ca\u7fa4\u4ee3\u6570\u7ed3\u6784\u7684\u8054\u7cfb\u3002", "conclusion": "\u8bba\u6587\u4e3a\u6709\u9650\u94fe\u73af\u6269\u5c55\u4e0b\u7684\u7fa4\u73af\u548c\u52a0\u6cd5\u7fa4\u7801\u63d0\u4f9b\u4e86\u65b0\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u591a\u79cd\u6570\u5b66\u7406\u8bba\u7684\u8054\u7cfb\u3002"}}
{"id": "2508.07197", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07197", "abs": "https://arxiv.org/abs/2508.07197", "authors": ["Ian Martiny", "Hammas Bin Tanveer", "Jack Wampler", "Rishab Nithyanand", "Eric Wustrow"], "title": "Mind the IP Gap: Measuring the impact of IPv6 on DNS censorship", "comment": "19 pages, 6 tables", "summary": "Internet censorship impacts large segments of the Internet, but so far, prior\nwork has focused almost exclusively on performing measurements using IPv4. As\nthe Internet grows, and more users connect, IPv6 is increasingly supported and\navailable to users and servers alike. But despite this steady growth, it\nremains unclear if the information control systems that implement censorship\n(firewalls, deep packet inspection, DNS injection, etc) are as effective with\nIPv6 traffic as they are with IPv4. In this paper, we perform the first global\nmeasurement of DNS censorship on the IPv6 Internet. Leveraging a recent\ntechnique that allows us to discover IPv6-capable open resolvers (along with\ntheir corresponding IPv4 address), we send over 20 million A and AAAA DNS\nrequests to DNS resolvers worldwide, and measure the rate at which they block,\nat the resolver, network, and country level as well examine the characteristics\nof blocked domains. We observe that while nearly all censors support blocking\nIPv6, their policies are inconsistent with and frequently less effective than\ntheir IPv4 censorship infrastructure. Our results suggest that supporting IPv6\ncensorship is not all-or-nothing: many censors support it, but poorly. As a\nresult, these censors may have to expend additional resources to bring IPv6\ncensorship up to parity with IPv4. In the meantime, this affords censorship\ncircumvention researchers a new opportunity to exploit these differences to\nevade detection and blocking.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9IPv6\u4e92\u8054\u7f51\u4e0a\u7684DNS\u5ba1\u67e5\u8fdb\u884c\u4e86\u5168\u7403\u6d4b\u91cf\uff0c\u53d1\u73b0IPv6\u5ba1\u67e5\u653f\u7b56\u4e0d\u4e00\u81f4\u4e14\u6548\u679c\u4e0d\u5982IPv4\u3002", "motivation": "\u968f\u7740IPv6\u7684\u666e\u53ca\uff0c\u7814\u7a76\u5176\u5ba1\u67e5\u6548\u679c\u662f\u5426\u4e0eIPv4\u4e00\u81f4\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5229\u7528IPv6\u5f00\u653e\u89e3\u6790\u5668\u53d1\u73b0\u6280\u672f\uff0c\u53d1\u90012000\u4e07\u6b21DNS\u8bf7\u6c42\uff0c\u6d4b\u91cf\u89e3\u6790\u5668\u3001\u7f51\u7edc\u548c\u56fd\u5bb6\u5c42\u9762\u7684\u5ba1\u67e5\u7387\u3002", "result": "\u51e0\u4e4e\u6240\u6709\u5ba1\u67e5\u8005\u90fd\u652f\u6301IPv6\u5ba1\u67e5\uff0c\u4f46\u653f\u7b56\u4e0d\u4e00\u81f4\u4e14\u6548\u679c\u8f83\u5dee\u3002", "conclusion": "IPv6\u5ba1\u67e5\u652f\u6301\u4e0d\u5b8c\u5584\uff0c\u4e3a\u89c4\u907f\u5ba1\u67e5\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002"}}
{"id": "2508.06674", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06674", "abs": "https://arxiv.org/abs/2508.06674", "authors": ["Weijie Shi", "Yue Cui", "Hao Chen", "Jiaming Li", "Mengze Li", "Jia Zhu", "Jiajie Xu", "Xiaofang Zhou"], "title": "Zero-Shot Cellular Trajectory Map Matching", "comment": null, "summary": "Cellular Trajectory Map-Matching (CTMM) aims to align cellular location\nsequences to road networks, which is a necessary preprocessing in\nlocation-based services on web platforms like Google Maps, including navigation\nand route optimization. Current approaches mainly rely on ID-based features and\nregion-specific data to learn correlations between cell towers and roads,\nlimiting their adaptability to unexplored areas. To enable high-accuracy CTMM\nwithout additional training in target regions, Zero-shot CTMM requires to\nextract not only region-adaptive features, but also sequential and location\nuncertainty to alleviate positioning errors in cellular data. In this paper, we\npropose a pixel-based trajectory calibration assistant for zero-shot CTMM,\nwhich takes advantage of transferable geospatial knowledge to calibrate\npixelated trajectory, and then guide the path-finding process at the road\nnetwork level. To enhance knowledge sharing across similar regions, a Gaussian\nmixture model is incorporated into VAE, enabling the identification of\nscenario-adaptive experts through soft clustering. To mitigate high positioning\nerrors, a spatial-temporal awareness module is designed to capture sequential\nfeatures and location uncertainty, thereby facilitating the inference of\napproximate user positions. Finally, a constrained path-finding algorithm is\nemployed to reconstruct the road ID sequence, ensuring topological validity\nwithin the road network. This process is guided by the calibrated trajectory\nwhile optimizing for the shortest feasible path, thus minimizing unnecessary\ndetours. Extensive experiments demonstrate that our model outperforms existing\nmethods in zero-shot CTMM by 16.8\\%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u50cf\u7d20\u7684\u8f68\u8ff9\u6821\u51c6\u8f85\u52a9\u65b9\u6cd5\uff0c\u7528\u4e8e\u96f6\u6837\u672cCTMM\uff0c\u901a\u8fc7\u8fc1\u79fb\u5730\u7406\u7a7a\u95f4\u77e5\u8bc6\u6821\u51c6\u8f68\u8ff9\uff0c\u5e76\u7ed3\u5408\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u548c\u65f6\u7a7a\u611f\u77e5\u6a21\u5757\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709CTMM\u65b9\u6cd5\u4f9d\u8d56\u533a\u57df\u7279\u5b9a\u6570\u636e\uff0c\u9002\u5e94\u6027\u5dee\uff0c\u65e0\u6cd5\u5904\u7406\u672a\u63a2\u7d22\u533a\u57df\u3002\u96f6\u6837\u672cCTMM\u9700\u8981\u63d0\u53d6\u533a\u57df\u81ea\u9002\u5e94\u7279\u5f81\u548c\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u50cf\u7d20\u5316\u8f68\u8ff9\u6821\u51c6\u8f85\u52a9\uff0c\u7ed3\u5408\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u548cVAE\u8bc6\u522b\u573a\u666f\u81ea\u9002\u5e94\u4e13\u5bb6\uff0c\u8bbe\u8ba1\u65f6\u7a7a\u611f\u77e5\u6a21\u5757\u6355\u6349\u5e8f\u5217\u7279\u5f81\u548c\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\uff0c\u6700\u540e\u901a\u8fc7\u7ea6\u675f\u8def\u5f84\u67e5\u627e\u7b97\u6cd5\u91cd\u5efa\u9053\u8defID\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u96f6\u6837\u672cCTMM\u4e2d\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd516.8%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8fc1\u79fb\u77e5\u8bc6\u548c\u4f18\u5316\u8def\u5f84\u67e5\u627e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672cCTMM\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2508.07487", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07487", "abs": "https://arxiv.org/abs/2508.07487", "authors": ["Vukan Ninkovic", "Dejan Vukobratovic"], "title": "Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths", "comment": "Accepted for publication at IEEE Communication Letters", "summary": "Unequal error protection (UEP) coding that enables differentiated reliability\nlevels within a transmitted message is essential for modern communication\nsystems. Autoencoder (AE)-based code designs have shown promise in the context\nof learned equal error protection (EEP) coding schemes. However, their\napplication to UEP remains largely unexplored, particularly at intermediate\nblocklengths, due to the increasing complexity of AE-based models. Inspired by\nthe proven effectiveness of superposition coding and successive interference\ncancellation (SIC) decoding in conventional UEP schemes, we propose a\nstructured AE-based architecture that extends AE-based UEP codes to\nsubstantially larger blocklengths while maintaining efficient training. By\nstructuring encoding and decoding into smaller AE subblocks, our method\nprovides a flexible framework for fine-tuning UEP reliability levels while\nadapting to diverse system parameters. Numerical results show that the proposed\napproach improves over established achievability bounds of randomized\nsuperposition coding-based UEP schemes with SIC decoding, making the proposed\nstructured AE-based UEP codes a scalable and efficient solution for\nnext-generation networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\uff08AE\uff09\u7684\u7ed3\u6784\u5316UEP\u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5757\u8bbe\u8ba1\u6269\u5c55\u5230\u5927\u5757\u957f\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edf\u968f\u673a\u53e0\u52a0\u7f16\u7801\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u901a\u4fe1\u7cfb\u7edf\u9700\u8981\u5dee\u5f02\u5316\u53ef\u9760\u6027\u4f20\u8f93\uff0c\u4f46\u73b0\u6709AE\u65b9\u6cd5\u5728UEP\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u5728\u4e2d\u7b49\u5757\u957f\u5ea6\u4e0b\u3002", "method": "\u91c7\u7528\u53e0\u52a0\u7f16\u7801\u548c\u8fde\u7eed\u5e72\u6270\u6d88\u9664\uff08SIC\uff09\u89e3\u7801\u7684\u7ed3\u6784\u5316AE\u67b6\u6784\uff0c\u5c06\u7f16\u7801\u548c\u89e3\u7801\u5206\u89e3\u4e3a\u66f4\u5c0f\u7684AE\u5b50\u5757\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u968f\u673a\u53e0\u52a0\u7f16\u7801\u65b9\u6848\u7684\u6027\u80fd\u754c\u9650\u3002", "conclusion": "\u7ed3\u6784\u5316AE-UEP\u7f16\u7801\u4e3a\u4e0b\u4e00\u4ee3\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07394", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07394", "abs": "https://arxiv.org/abs/2508.07394", "authors": ["Luca Lusvarghi", "Javier Gozalvez", "Baldomero Coll-Perales", "Mohammad Irfan Khan", "Miguel Sepulcre", "Seyhan Ucar", "Onur Altintas"], "title": "The Search for Relevance: A Context-Aware Paradigm Shift in Semantic and Task-Oriented V2X Communications", "comment": null, "summary": "The design of communication systems has traditionally focused on the reliable\nand timely delivery of data. However, the scalability challenges faced by the\nevolution to a 6G-driven society demand new communication paradigms that\ncarefully curate the content being transmitted. This paper envisions a joint\nsemantic and task-oriented communication paradigm where Connected and\nAutonomous Vehicles (CAVs) transmit only the information necessary to convey\nthe desired meaning that is relevant to the intended receivers based on the\ncommunication context. The V2X domain offers a unique environment for the\ndevelopment of the envisioned semantic and task-oriented communications\nparadigm, as CAVs are native semantic devices, and the V2X domain is rich in\ncontextual information. This contextual information can be leveraged to\nestimate the relevance that information may have for the intended receivers. We\nillustrate and quantitatively evaluate the potential benefits of semantic and\ntask-oriented V2X communications. Numerical results show that by focusing on\nthe transmission of the most relevant information for the intended receivers,\nsemantic and task-oriented V2X communications can achieve a two-fold\nimprovement in communication efficiency, which will significantly benefit the\nscalability of V2X networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u54116G\u65f6\u4ee3\u7684\u8bed\u4e49\u548c\u4efb\u52a1\u5bfc\u5411\u7684\u901a\u4fe1\u8303\u5f0f\uff0c\u4e13\u6ce8\u4e8e\u4f20\u8f93\u4e0e\u63a5\u6536\u8005\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u4ee5\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u6ce8\u91cd\u6570\u636e\u7684\u53ef\u9760\u548c\u53ca\u65f6\u4f20\u8f93\uff0c\u4f466G\u65f6\u4ee3\u5bf9\u53ef\u6269\u5c55\u6027\u7684\u9700\u6c42\u8981\u6c42\u65b0\u7684\u901a\u4fe1\u8303\u5f0f\uff0c\u80fd\u591f\u6839\u636e\u4e0a\u4e0b\u6587\u7cbe\u5fc3\u7b5b\u9009\u4f20\u8f93\u5185\u5bb9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8bed\u4e49\u548c\u4efb\u52a1\u5bfc\u5411\u7684\u901a\u4fe1\u8303\u5f0f\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8f66\u8054\u7f51\uff08V2X\uff09\u73af\u5883\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u8bc4\u4f30\u4fe1\u606f\u5bf9\u63a5\u6536\u8005\u7684\u76f8\u5173\u6027\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u4f20\u8f93\u6700\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u8bed\u4e49\u548c\u4efb\u52a1\u5bfc\u5411\u7684V2X\u901a\u4fe1\u53ef\u5c06\u901a\u4fe1\u6548\u7387\u63d0\u9ad8\u4e24\u500d\u3002", "conclusion": "\u8bed\u4e49\u548c\u4efb\u52a1\u5bfc\u5411\u7684\u901a\u4fe1\u8303\u5f0f\u663e\u8457\u63d0\u5347\u4e86V2X\u7f51\u7edc\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a6G\u65f6\u4ee3\u7684\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.06706", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.06706", "abs": "https://arxiv.org/abs/2508.06706", "authors": ["Jaikrishna Manojkumar Patil", "Nathaniel Lee", "Al Mehdi Saadat Chowdhury", "YooJung Choi", "Paulo Shakarian"], "title": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets", "comment": null, "summary": "Rule-based methods for knowledge graph completion provide explainable results\nbut often require a significantly large number of rules to achieve competitive\nperformance. This can hinder explainability due to overwhelmingly large rule\nsets. We discover rule contexts (meaningful subsets of rules that work\ntogether) from training data and use learned probability distribution (i.e.\nprobabilistic circuits) over these rule contexts to more rapidly achieve\nperformance of the full rule set. Our approach achieves a 70-96% reduction in\nnumber of rules used while outperforming baseline by up to 31$\\times$ when\nusing equivalent minimal number of rules and preserves 91% of peak baseline\nperformance even when comparing our minimal rule sets against baseline's full\nrule sets. We show that our framework is grounded in well-known semantics of\nprobabilistic logic, does not require independence assumptions, and that our\ntractable inference procedure provides both approximate lower bounds and exact\nprobability of a given query. The efficacy of our method is validated by\nempirical studies on 8 standard benchmark datasets where we show competitive\nperformance by using only a fraction of the rules required by AnyBURL's\nstandard inference method, the current state-of-the-art for rule-based\nknowledge graph completion. This work may have further implications for general\nprobabilistic reasoning over learned sets of rules.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u4e0a\u4e0b\u6587\u548c\u6982\u7387\u7535\u8def\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u89c4\u5219\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u89c4\u5219\u624d\u80fd\u8fbe\u5230\u9ad8\u6027\u80fd\uff0c\u4f46\u89c4\u5219\u8fc7\u591a\u4f1a\u964d\u4f4e\u53ef\u89e3\u91ca\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u89c4\u5219\u4e0a\u4e0b\u6587\u548c\u6982\u7387\u5206\u5e03\u4f18\u5316\u89c4\u5219\u4f7f\u7528\u3002", "method": "\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u53d1\u73b0\u89c4\u5219\u4e0a\u4e0b\u6587\uff0c\u5e76\u5229\u7528\u6982\u7387\u7535\u8def\u5b66\u4e60\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u7684\u5206\u5e03\uff0c\u4ee5\u51cf\u5c11\u89c4\u5219\u6570\u91cf\u5e76\u63d0\u5347\u6027\u80fd\u3002", "result": "\u65b9\u6cd5\u51cf\u5c11\u4e8670-96%\u7684\u89c4\u5219\u6570\u91cf\uff0c\u6027\u80fd\u6700\u9ad8\u63d0\u534731\u500d\uff0c\u4e14\u4fdd\u7559\u57fa\u7ebf91%\u7684\u5cf0\u503c\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u57288\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07567", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07567", "abs": "https://arxiv.org/abs/2508.07567", "authors": ["Tian Jiao", "Yanlin Geng", "Zhiqiang Wei", "Zai Yang"], "title": "Extended AB Algorithms for Bistatic Integrated Sensing and Communications Systems", "comment": "5 pages, 2 figures", "summary": "Integrated sensing and communication (ISAC) is pivotal for next-generation\nwireless networks, rendering the computation of rate-distortion trade-off in\nISAC systems critically important. In this paper, we propose the extended\nArimoto-Blahut (AB) algorithms to calculate the rate-distortion trade-off in\nbistatic ISAC systems, which overcome the limitation of existing AB algorithms\nin handling non-convex constraints. Specifically, we introduce auxiliary\nvariables to transform non-convex distortion constraints into linear\nconstraints, prove that the reformulated linearly-constrained optimization\nproblem maintains the same optimal solution as the original problem, and\ndevelop extended AB algorithms for both squared error and logarithmic loss\ndistortion metrics based on the framework of AB algorithm. Numerical results\nvalidate the effectiveness of the proposed algorithm.", "AI": {"tldr": "\u63d0\u51fa\u6269\u5c55\u7684Arimoto-Blahut\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u53cc\u57fa\u5730ISAC\u7cfb\u7edf\u4e2d\u7684\u7387\u5931\u771f\u6743\u8861\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u5904\u7406\u975e\u51f8\u7ea6\u675f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u5bf9\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u81f3\u5173\u91cd\u8981\uff0c\u8ba1\u7b97\u5176\u7387\u5931\u771f\u6743\u8861\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5f15\u5165\u8f85\u52a9\u53d8\u91cf\u5c06\u975e\u51f8\u5931\u771f\u7ea6\u675f\u8f6c\u5316\u4e3a\u7ebf\u6027\u7ea6\u675f\uff0c\u8bc1\u660e\u5176\u4e0e\u539f\u95ee\u9898\u5177\u6709\u76f8\u540c\u6700\u4f18\u89e3\uff0c\u5e76\u57fa\u4e8eAB\u7b97\u6cd5\u6846\u67b6\u5f00\u53d1\u4e86\u6269\u5c55\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6269\u5c55AB\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u975e\u51f8\u7ea6\u675f\u95ee\u9898\uff0c\u4e3aISAC\u7cfb\u7edf\u7684\u7387\u5931\u771f\u6743\u8861\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2508.07506", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07506", "abs": "https://arxiv.org/abs/2508.07506", "authors": ["Hammas Bin Tanveer", "Wai Sun Chan", "Ricky K. P. Mok", "Sebastian Kappes", "Philipp Richter", "Oliver Gasser", "John Ronan", "Arthur Berger", "kc Claffy"], "title": "Unveiling IPv6 Scanning Dynamics: A Longitudinal Study Using Large Scale Proactive and Passive IPv6 Telescopes", "comment": "24 pages, 16 figures, 8 tables, Accepted at ACM CoNEXT 2025 for\n  publication in the Proceedings of the ACM on Networking", "summary": "We introduce new tools and vantage points to develop and integrate proactive\ntechniques to attract IPv6 scan traffic, thus enabling its analysis. By\ndeploying the largest-ever IPv6 proactive telescope in a production ISP\nnetwork, we collected over 600M packets of unsolicited traffic from 1.9k\nAutonomous Systems in 10 months. We characterized the sources of unsolicited\ntraffic, evaluated the effectiveness of five major features across the network\nstack, and inferred scanners' sources of target addresses and their strategies.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u65b0\u5de5\u5177\u548c\u89c6\u89d2\uff0c\u7528\u4e8e\u5438\u5f15\u548c\u5206\u6790IPv6\u626b\u63cf\u6d41\u91cf\uff0c\u901a\u8fc7\u90e8\u7f72\u5927\u89c4\u6a21\u4e3b\u52a8\u671b\u8fdc\u955c\u6536\u96c6\u4e866\u4ebf\u4e2a\u672a\u8bf7\u6c42\u6570\u636e\u5305\uff0c\u5e76\u5206\u6790\u4e86\u626b\u63cf\u6e90\u548c\u76ee\u6807\u5730\u5740\u7b56\u7565\u3002", "motivation": "\u5f00\u53d1\u4e3b\u52a8\u6280\u672f\u4ee5\u5438\u5f15\u548c\u5206\u6790IPv6\u626b\u63cf\u6d41\u91cf\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u90e8\u7f72\u5927\u89c4\u6a21IPv6\u4e3b\u52a8\u671b\u8fdc\u955c\u5728\u751f\u4ea7ISP\u7f51\u7edc\u4e2d\uff0c\u6536\u96c6\u548c\u5206\u6790\u672a\u8bf7\u6c42\u6d41\u91cf\u3002", "result": "\u6536\u96c6\u4e866\u4ebf\u4e2a\u6570\u636e\u5305\uff0c\u5206\u6790\u4e861.9k\u4e2a\u81ea\u6cbb\u7cfb\u7edf\u7684\u626b\u63cf\u884c\u4e3a\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cd\u7f51\u7edc\u6808\u7279\u5f81\u7684\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9IPv6\u626b\u63cf\u884c\u4e3a\u7684\u6df1\u5165\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u626b\u63cf\u6e90\u548c\u76ee\u6807\u5730\u5740\u7b56\u7565\u3002"}}
{"id": "2508.06716", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.06716", "abs": "https://arxiv.org/abs/2508.06716", "authors": ["Blair Johnson", "Clayton Kerce", "Faramarz Fekri"], "title": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning", "comment": null, "summary": "Differentiable inductive logic programming (ILP) techniques have proven\neffective at finding approximate rule-based solutions to link prediction and\nnode classification problems on knowledge graphs; however, the common\nassumption of chain-like rule structure can hamper the performance and\ninterpretability of existing approaches. We introduce GLIDR, a differentiable\nrule learning method that models the inference of logic rules with more\nexpressive syntax than previous methods. GLIDR uses a differentiable message\npassing inference algorithm that generalizes previous chain-like rule learning\nmethods to allow rules with features like branches and cycles. GLIDR has a\nsimple and expressive rule search space which is parameterized by a limit on\nthe maximum number of free variables that may be included in a rule. Explicit\nlogic rules can be extracted from the weights of a GLIDR model for use with\nsymbolic solvers. We demonstrate that GLIDR can significantly outperform\nexisting rule learning methods on knowledge graph completion tasks and even\ncompete with embedding methods despite the inherent disadvantage of being a\nstructure-only prediction method. We show that rules extracted from GLIDR\nretain significant predictive performance, and that GLIDR is highly robust to\ntraining data noise. Finally, we demonstrate that GLIDR can be chained with\ndeep neural networks and optimized end-to-end for rule learning on arbitrary\ndata modalities.", "AI": {"tldr": "GLIDR\u662f\u4e00\u79cd\u53ef\u5fae\u5206\u7684\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u65b9\u6cd5\uff0c\u901a\u8fc7\u66f4\u7075\u6d3b\u7684\u89c4\u5219\u7ed3\u6784\u548c\u6d88\u606f\u4f20\u9012\u63a8\u7406\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u94fe\u5f0f\u89c4\u5219\u7ed3\u6784\u7684\u5c40\u9650\u6027\u5f71\u54cd\u4e86\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "GLIDR\u91c7\u7528\u53ef\u5fae\u5206\u6d88\u606f\u4f20\u9012\u63a8\u7406\u7b97\u6cd5\uff0c\u652f\u6301\u5206\u652f\u548c\u5faa\u73af\u7b49\u590d\u6742\u89c4\u5219\u7ed3\u6784\uff0c\u5e76\u5141\u8bb8\u4ece\u6743\u91cd\u4e2d\u63d0\u53d6\u663e\u5f0f\u903b\u8f91\u89c4\u5219\u3002", "result": "GLIDR\u5728\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\uff0c\u751a\u81f3\u53ef\u4e0e\u5d4c\u5165\u65b9\u6cd5\u7ade\u4e89\uff0c\u4e14\u5bf9\u8bad\u7ec3\u6570\u636e\u566a\u58f0\u5177\u6709\u9ad8\u9c81\u68d2\u6027\u3002", "conclusion": "GLIDR\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u4e14\u9c81\u68d2\u7684\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u6a21\u6001\u6570\u636e\uff0c\u5e76\u80fd\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\u3002"}}
{"id": "2508.07799", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07799", "abs": "https://arxiv.org/abs/2508.07799", "authors": ["Yike Wang", "Zhike Wu", "Jiang Chen", "Chunjie Wang", "Xuhui Zhang", "Yanyan Shen"], "title": "QoS-Aware Integrated Sensing, Communication, and Control with Movable Antenna", "comment": "6 pages, 3 figures, this manuscript has been submitted to IEEE", "summary": "Integrated sensing, communication, and control (ISCC) has emerged as a key\nenabler for low-altitude wireless networks with enhanced adaptability through\nresource allocation co-design and intelligent environment awareness. However,\ndynamic interference and channel attenuation constrain the potential of the\nISCC system. To address this challenge, we propose a novel movable\nantenna-empowered ISCC system. An achievable data rate maximization problem is\nformulated while guaranteeing the sensing and control quality-of-service (QoS)\nby optimizing the positions of the antennas and the beamforming strategy for\ncommunication, sensing, and control co-design. An efficient alternating\noptimization (AO)-based algorithm is proposed to solve the highly coupled\nnon-convex problem. Numerical results demonstrate that the proposed AO-based\nalgorithm achieves substantial gains in the achievable data rate and the\ncontrol QoS compared with benchmark schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u79fb\u52a8\u5929\u7ebf\u7684ISCC\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u5e72\u6270\u548c\u4fe1\u9053\u8870\u51cf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u901f\u7387\u548c\u63a7\u5236QoS\u3002", "motivation": "\u52a8\u6001\u5e72\u6270\u548c\u4fe1\u9053\u8870\u51cf\u9650\u5236\u4e86ISCC\u7cfb\u7edf\u7684\u6f5c\u529b\uff0c\u9700\u901a\u8fc7\u8d44\u6e90\u5206\u914d\u548c\u667a\u80fd\u73af\u5883\u611f\u77e5\u63d0\u5347\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u53ef\u79fb\u52a8\u5929\u7ebf\u8d4b\u80fd\u7684ISCC\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u89e3\u51b3\u5929\u7ebf\u4f4d\u7f6e\u548c\u6ce2\u675f\u6210\u5f62\u7b56\u7565\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u6570\u636e\u901f\u7387\u548c\u63a7\u5236QoS\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u65b9\u6848\u3002", "conclusion": "\u53ef\u79fb\u52a8\u5929\u7ebf\u548c\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u4e3aISCC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.07578", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07578", "abs": "https://arxiv.org/abs/2508.07578", "authors": ["Yu Gou", "Tong Zhang", "Jun Liu", "Tingting Yang", "Shanshan Song", "Jun-Hong Cui"], "title": "Achieving Fair-Effective Communications and Robustness in Underwater Acoustic Sensor Networks: A Semi-Cooperative Approach", "comment": null, "summary": "This paper investigates the fair-effective communication and robustness in\nimperfect and energy-constrained underwater acoustic sensor networks\n(IC-UASNs). Specifically, we investigate the impact of unexpected node\nmalfunctions on the network performance under the time-varying acoustic\nchannels. Each node is expected to satisfy Quality of Service (QoS)\nrequirements. However, achieving individual QoS requirements may interfere with\nother concurrent communications. Underwater nodes rely excessively on the\nrationality of other underwater nodes when guided by fully cooperative\napproaches, making it difficult to seek a trade-off between individual QoS and\nglobal fair-effective communications under imperfect conditions. Therefore,\nthis paper presents a SEmi-COoperative Power Allocation approach (SECOPA) that\nachieves fair-effective communication and robustness in IC-UASNs. The approach\nis distributed multi-agent reinforcement learning (MARL)-based, and the\nobjectives are twofold. On the one hand, each intelligent node individually\ndecides the transmission power to simultaneously optimize individual and global\nperformance. On the other hand, advanced training algorithms are developed to\nprovide imperfect environments for training robust models that can adapt to the\ntime-varying acoustic channels and handle unexpected node failures in the\nnetwork. Numerical results are presented to validate our proposed approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u5408\u4f5c\u529f\u7387\u5206\u914d\u65b9\u6cd5\uff08SECOPA\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u6c34\u4e0b\u58f0\u5b66\u4f20\u611f\u5668\u7f51\u7edc\uff08IC-UASNs\uff09\u4e2d\u7684\u516c\u5e73\u6709\u6548\u901a\u4fe1\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5728\u80fd\u91cf\u53d7\u9650\u548c\u4fe1\u9053\u65f6\u53d8\u7684\u6c34\u4e0b\u7f51\u7edc\u4e2d\uff0c\u8282\u70b9\u6545\u969c\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u6ee1\u8db3\u4e2a\u4f53QoS\u9700\u6c42\u7684\u540c\u65f6\u5b9e\u73b0\u5168\u5c40\u516c\u5e73\u901a\u4fe1\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u65b9\u6cd5\uff0c\u667a\u80fd\u8282\u70b9\u81ea\u4e3b\u51b3\u5b9a\u4f20\u8f93\u529f\u7387\uff0c\u5e76\u5f00\u53d1\u9ad8\u7ea7\u8bad\u7ec3\u7b97\u6cd5\u4ee5\u9002\u5e94\u4e0d\u5b8c\u7f8e\u73af\u5883\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cSECOPA\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u4e2a\u4f53\u4e0e\u5168\u5c40\u6027\u80fd\uff0c\u5e76\u9002\u5e94\u65f6\u53d8\u4fe1\u9053\u548c\u8282\u70b9\u6545\u969c\u3002", "conclusion": "SECOPA\u65b9\u6cd5\u4e3aIC-UASNs\u4e2d\u7684\u516c\u5e73\u6709\u6548\u901a\u4fe1\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06736", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06736", "abs": "https://arxiv.org/abs/2508.06736", "authors": ["Alican Yilmaz", "Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "title": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search", "comment": null, "summary": "Solving Mixed-Integer Programming (MIP) problems often requires substantial\ncomputational resources due to their combinatorial nature. Parallelization has\nemerged as a critical strategy to accelerate solution times and enhance\nscalability to tackle large, complex instances. This paper investigates the\nparallelization capabilities of Balans, a recently proposed multi-armed\nbandits-based adaptive large neighborhood search for MIPs. While Balans's\nmodular architecture inherently supports parallel exploration of diverse\nparameter configurations, this potential has not been thoroughly examined. To\naddress this gap, we introduce ParBalans, an extension that leverages both\nsolver-level and algorithmic-level parallelism to improve performance on\nchallenging MIP instances. Our experimental results demonstrate that ParBalans\nexhibits competitive performance compared to the state-of-the-art commercial\nsolver Gurobi, particularly on hard optimization benchmarks.", "AI": {"tldr": "ParBalans\u901a\u8fc7\u5e76\u884c\u5316\u6269\u5c55Balans\uff0c\u63d0\u5347\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\u7684\u6c42\u89e3\u6027\u80fd\u3002", "motivation": "\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u5e76\u884c\u5316\u662f\u52a0\u901f\u6c42\u89e3\u7684\u5173\u952e\u7b56\u7565\u3002", "method": "\u63d0\u51faParBalans\uff0c\u7ed3\u5408\u6c42\u89e3\u5668\u548c\u7b97\u6cd5\u7ea7\u5e76\u884c\u5316\uff0c\u6269\u5c55Balans\u7684\u5e76\u884c\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eParBalans\u5728\u590d\u6742\u95ee\u9898\u4e0a\u6027\u80fd\u4f18\u4e8e\u5546\u4e1a\u6c42\u89e3\u5668Gurobi\u3002", "conclusion": "ParBalans\u4e3a\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e76\u884c\u6c42\u89e3\u65b9\u6848\u3002"}}
{"id": "2508.07865", "categories": ["cs.IT", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.07865", "abs": "https://arxiv.org/abs/2508.07865", "authors": ["Rishabh S. Pomaje", "Jayanth S.", "Rajshekhar V. Bhat", "Nikolaos Pappas"], "title": "Age of Information Minimization in Goal-Oriented Communication with Processing and Cost of Actuation Error Constraints", "comment": null, "summary": "We study a goal-oriented communication system in which a source monitors an\nenvironment that evolves as a discrete-time, two-state Markov chain. At each\ntime slot, a controller decides whether to sample the environment and if so\nwhether to transmit a raw or processed sample, to the controller. Processing\nimproves transmission reliability over an unreliable wireless channel, but\nincurs an additional cost. The objective is to minimize the long-term average\nage of information (AoI), subject to constraints on the costs incurred at the\nsource and the cost of actuation error (CAE), a semantic metric that assigns\ndifferent penalties to different actuation errors. Although reducing AoI can\npotentially help reduce CAE, optimizing AoI alone is insufficient, as it\noverlooks the evolution of the underlying process. For instance, faster source\ndynamics lead to higher CAE for the same average AoI, and different AoI\ntrajectories can result in markedly different CAE under identical average AoI.\nTo address this, we propose a stationary randomized policy that achieves an\naverage AoI within a bounded multiplicative factor of the optimal among all\nfeasible policies. Extensive numerical experiments are conducted to\ncharacterize system behavior under a range of parameters. These results offer\ninsights into the feasibility of the optimization problem, the structure of\nnear-optimal actions, and the fundamental trade-offs between AoI, CAE, and the\ncosts involved.", "AI": {"tldr": "\u7814\u7a76\u4e86\u76ee\u6807\u5bfc\u5411\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u91c7\u6837\u548c\u4f20\u8f93\u7b56\u7565\uff0c\u6700\u5c0f\u5316\u4fe1\u606f\u5e74\u9f84\uff08AoI\uff09\uff0c\u540c\u65f6\u8003\u8651\u4f20\u8f93\u6210\u672c\u548c\u8bed\u4e49\u8bef\u5dee\u6210\u672c\uff08CAE\uff09\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316AoI\u7684\u65b9\u6cd5\u5ffd\u7565\u4e86\u5e95\u5c42\u8fc7\u7a0b\u7684\u52a8\u6001\u53d8\u5316\u548c\u8bed\u4e49\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u9700\u63d0\u51fa\u66f4\u5168\u9762\u7684\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u968f\u673a\u7b56\u7565\uff0c\u786e\u4fddAoI\u5728\u6700\u4f18\u7b56\u7565\u7684\u6709\u9650\u500d\u6570\u5185\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u63ed\u793a\u4e86\u7cfb\u7edf\u884c\u4e3a\u3001\u4f18\u5316\u95ee\u9898\u7684\u53ef\u884c\u6027\u53caAoI\u3001CAE\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u4f18\u5316AoI\u9700\u7ed3\u5408\u8bed\u4e49\u8bef\u5dee\u548c\u52a8\u6001\u8fc7\u7a0b\uff0c\u9759\u6001\u968f\u673a\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07604", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07604", "abs": "https://arxiv.org/abs/2508.07604", "authors": ["Maryam Abbasalizadeh", "Sashank Narain"], "title": "Joint Scheduling and Resource Allocation in mmWave IAB Networks Using Deep RL", "comment": "Accepted at MILCOM 2025 (IEEE Military Communications Conference)", "summary": "Integrated Access and Backhaul (IAB) is critical for dense 5G and beyond\ndeployments, especially in mmWave bands where fiber backhaul is infeasible. We\npropose a novel Deep Reinforcement Learning (DRL) framework for joint link\nscheduling and resource slicing in dynamic, interference-prone IAB networks.\nOur method integrates a greedy Double Deep Q-Network (DDQN) scheduler to\nactivate access and backhaul links based on traffic and topology, with a\nmulti-agent DDQN allocator for bandwidth and antenna assignment across network\nslices. This decentralized approach respects strict antenna constraints and\nsupports concurrent scheduling across heterogeneous links. Evaluations across\n96 dynamic topologies show 99.84 percent scheduling accuracy and 20.90 percent\nthroughput improvement over baselines. The framework's efficient operation and\nadaptability make it suitable for dynamic and resource-constrained deployments,\nwhere fast link scheduling and autonomous backhaul coordination are vital.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u5e72\u6270\u4e25\u91cd\u7684IAB\u7f51\u7edc\u4e2d\u8054\u5408\u94fe\u8def\u8c03\u5ea6\u548c\u8d44\u6e90\u5207\u7247\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8c03\u5ea6\u51c6\u786e\u6027\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u5728\u5bc6\u96c65G\u53ca\u66f4\u9ad8\u9891\u6bb5\u90e8\u7f72\u4e2d\uff0cIAB\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5149\u7ea4\u56de\u4f20\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u9ad8\u6548\u8c03\u5ea6\u548c\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u8d2a\u5a6a\u53cc\u6df1\u5ea6Q\u7f51\u7edc\uff08DDQN\uff09\u8c03\u5ea6\u5668\u548c\u591a\u667a\u80fd\u4f53DDQN\u5206\u914d\u5668\uff0c\u5b9e\u73b0\u94fe\u8def\u6fc0\u6d3b\u53ca\u5e26\u5bbd\u4e0e\u5929\u7ebf\u5206\u914d\u7684\u8054\u5408\u4f18\u5316\u3002", "result": "\u572896\u79cd\u52a8\u6001\u62d3\u6251\u4e2d\uff0c\u8c03\u5ea6\u51c6\u786e\u7387\u8fbe99.84%\uff0c\u541e\u5410\u91cf\u63d0\u534720.90%\u3002", "conclusion": "\u8be5\u6846\u67b6\u9ad8\u6548\u9002\u5e94\u52a8\u6001\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u94fe\u8def\u8c03\u5ea6\u548c\u81ea\u4e3b\u56de\u4f20\u534f\u8c03\u3002"}}
{"id": "2508.06746", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06746", "abs": "https://arxiv.org/abs/2508.06746", "authors": ["Xin Tang", "Qian Chen", "Fengshun Li", "Youchun Gong", "Yinqiu Liu", "Wen Tian", "Shaowen Qin", "Xiaohuan Li"], "title": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism", "comment": null, "summary": "With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in\nsensitive applications, such as urban monitoring, emergency response, and\nsecure sensing, ensuring reliable connectivity and covert communication has\nbecome increasingly vital. However, dynamic mobility and exposure risks pose\nsignificant challenges. To tackle these challenges, this paper proposes a\nself-organizing UAV network framework combining Graph Diffusion-based Policy\nOptimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The\nGDPO method uses generative AI to dynamically generate sparse but\nwell-connected topologies, enabling flexible adaptation to changing node\ndistributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game\n(SG)-based incentive mechanism guides self-interested UAVs to choose relay\nbehaviors and neighbor links that support cooperation and enhance covert\ncommunication. Extensive experiments are conducted to validate the\neffectiveness of the proposed framework in terms of model convergence, topology\ngeneration quality, and enhancement of covert communication performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u6269\u6563\u7b56\u7565\u4f18\u5316\uff08GDPO\uff09\u548cStackelberg\u535a\u5f08\uff08SG\uff09\u6fc0\u52b1\u673a\u5236\u7684\u65e0\u4eba\u673a\u7f51\u7edc\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u52a8\u6001\u79fb\u52a8\u6027\u548c\u9690\u853d\u901a\u4fe1\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u7f51\u7edc\u5728\u654f\u611f\u5e94\u7528\u4e2d\u7684\u9700\u6c42\u589e\u957f\uff0c\u786e\u4fdd\u53ef\u9760\u8fde\u63a5\u548c\u9690\u853d\u901a\u4fe1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u52a8\u6001\u79fb\u52a8\u6027\u548c\u66b4\u9732\u98ce\u9669\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u91c7\u7528GDPO\u65b9\u6cd5\u751f\u6210\u7a00\u758f\u4f46\u8fde\u63a5\u826f\u597d\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408SG\u6fc0\u52b1\u673a\u5236\u5f15\u5bfc\u65e0\u4eba\u673a\u9009\u62e9\u652f\u6301\u5408\u4f5c\u548c\u9690\u853d\u901a\u4fe1\u7684\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u6a21\u578b\u6536\u655b\u6027\u3001\u62d3\u6251\u751f\u6210\u8d28\u91cf\u548c\u9690\u853d\u901a\u4fe1\u6027\u80fd\u63d0\u5347\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u65e0\u4eba\u673a\u7f51\u7edc\u7684\u52a8\u6001\u6027\u548c\u9690\u853d\u901a\u4fe1\u9700\u6c42\u3002"}}
{"id": "2508.07958", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.07958", "abs": "https://arxiv.org/abs/2508.07958", "authors": ["Dongxu Li", "Kai Yuan", "Jianhao Huang", "Chuan Huang", "Xiaoqi Qin", "Shuguang Cui", "Ping Zhang"], "title": "Adaptive Source-Channel Coding for Semantic Communications", "comment": null, "summary": "Semantic communications (SemComs) have emerged as a promising paradigm for\njoint data and task-oriented transmissions, combining the demands for both the\nbit-accurate delivery and end-to-end (E2E) distortion minimization. However,\ncurrent joint source-channel coding (JSCC) in SemComs is not compatible with\nthe existing communication systems and cannot adapt to the variations of the\nsources or the channels, while separate source-channel coding (SSCC) is\nsuboptimal in the finite blocklength regime. To address these issues, we\npropose an adaptive source-channel coding (ASCC) scheme for SemComs over\nparallel Gaussian channels, where the deep neural network (DNN)-based semantic\nsource coding and conventional digital channel coding are separately deployed\nand adaptively designed. To enable efficient adaptation between the source and\nchannel coding, we first approximate the E2E data and semantic distortions as\nfunctions of source coding rate and bit error ratio (BER) via logistic\nregression, where BER is further modeled as functions of signal-to-noise ratio\n(SNR) and channel coding rate. Then, we formulate the weighted sum E2E\ndistortion minimization problem for joint source-channel coding rate and power\nallocation over parallel channels, which is solved by the successive convex\napproximation. Finally, simulation results demonstrate that the proposed ASCC\nscheme outperforms typical deep JSCC and SSCC schemes for both the single- and\nparallel-channel scenarios while maintaining full compatibility with practical\ndigital systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u6e90\u4fe1\u9053\u7f16\u7801\uff08ASCC\uff09\u65b9\u6848\uff0c\u7528\u4e8e\u8bed\u4e49\u901a\u4fe1\uff08SemComs\uff09\uff0c\u901a\u8fc7\u5206\u79bb\u90e8\u7f72\u548c\u81ea\u9002\u5e94\u8bbe\u8ba1\u8bed\u4e49\u6e90\u7f16\u7801\u548c\u6570\u5b57\u4fe1\u9053\u7f16\u7801\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\uff08JSCC\uff09\u548c\u5206\u79bb\u6e90\u4fe1\u9053\u7f16\u7801\uff08SSCC\uff09\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u8bed\u4e49\u901a\u4fe1\u4e2d\u7684JSCC\u4e0e\u73b0\u6709\u901a\u4fe1\u7cfb\u7edf\u4e0d\u517c\u5bb9\u4e14\u65e0\u6cd5\u9002\u5e94\u6e90\u6216\u4fe1\u9053\u7684\u53d8\u5316\uff0c\u800cSSCC\u5728\u6709\u9650\u5757\u957f\u5ea6\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faASCC\u65b9\u6848\uff0c\u901a\u8fc7\u903b\u8f91\u56de\u5f52\u5efa\u6a21\u7aef\u5230\u7aef\u5931\u771f\u4e0e\u6e90\u7f16\u7801\u7387\u548c\u8bef\u7801\u7387\u7684\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u9010\u6b21\u51f8\u8fd1\u4f3c\u4f18\u5316\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u7387\u548c\u529f\u7387\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cASCC\u65b9\u6848\u5728\u5355\u4fe1\u9053\u548c\u5e76\u884c\u4fe1\u9053\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u5178\u578b\u7684\u6df1\u5ea6JSCC\u548cSSCC\u65b9\u6848\uff0c\u4e14\u4e0e\u73b0\u6709\u6570\u5b57\u7cfb\u7edf\u5b8c\u5168\u517c\u5bb9\u3002", "conclusion": "ASCC\u65b9\u6848\u4e3a\u8bed\u4e49\u901a\u4fe1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u517c\u5bb9\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07679", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07679", "abs": "https://arxiv.org/abs/2508.07679", "authors": ["Tong Zhang", "Yu Gou", "Jun Liu", "Shanshan Song", "Tingting Yang", "Jun-Hong Cui"], "title": "Joint link scheduling and power allocation in imperfect and energy-constrained underwater wireless sensor networks", "comment": "Accepted by IEEE Transactions on Mobile Computing", "summary": "Underwater wireless sensor networks (UWSNs) stand as promising technologies\nfacilitating diverse underwater applications. However, the major design issues\nof the considered system are the severely limited energy supply and unexpected\nnode malfunctions. This paper aims to provide fair, efficient, and reliable\n(FER) communication to the imperfect and energy-constrained UWSNs (IC-UWSNs).\nTherefore, we formulate a FER-communication optimization problem (FERCOP) and\npropose ICRL-JSA to solve the formulated problem. ICRL-JSA is a deep\nmulti-agent reinforcement learning (MARL)-based optimizer for IC-UWSNs through\njoint link scheduling and power allocation, which automatically learns\nscheduling algorithms without human intervention. However, conventional RL\nmethods are unable to address the challenges posed by underwater environments\nand IC-UWSNs. To construct ICRL-JSA, we integrate deep Q-network into IC-UWSNs\nand propose an advanced training mechanism to deal with complex acoustic\nchannels, limited energy supplies, and unexpected node malfunctions. Simulation\nresults demonstrate the superiority of the proposed ICRL-JSA scheme with an\nadvanced training mechanism compared to various benchmark algorithms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7684\u4f18\u5316\u5668ICRL-JSA\uff0c\u7528\u4e8e\u89e3\u51b3\u6c34\u4e0b\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\uff08UWSNs\uff09\u4e2d\u7684\u516c\u5e73\u3001\u9ad8\u6548\u548c\u53ef\u9760\u901a\u4fe1\u95ee\u9898\u3002", "motivation": "\u6c34\u4e0b\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\uff08UWSNs\uff09\u56e0\u80fd\u91cf\u4f9b\u5e94\u6709\u9650\u548c\u8282\u70b9\u6545\u969c\u95ee\u9898\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6Q\u7f51\u7edc\u548c\u5148\u8fdb\u7684\u8bad\u7ec3\u673a\u5236\uff0cICRL-JSA\u5b9e\u73b0\u4e86\u8054\u5408\u94fe\u8def\u8c03\u5ea6\u548c\u529f\u7387\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cICRL-JSA\u5728\u590d\u6742\u6c34\u4e0b\u73af\u5883\u4e2d\u4f18\u4e8e\u591a\u79cd\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "ICRL-JSA\u4e3a\u80fd\u91cf\u53d7\u9650\u548c\u8282\u70b9\u6545\u969c\u7684UWSNs\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u901a\u4fe1\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06753", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.06753", "abs": "https://arxiv.org/abs/2508.06753", "authors": ["Evangelos Georganas", "Dhiraj Kalamkar", "Alexander Heinecke"], "title": "Pushing the Envelope of LLM Inference on AI-PC", "comment": null, "summary": "The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the\nperplexity and end-task performance of their full-precision counterparts using\nthe same model size, is ushering in a new era of LLM inference for\nresource-constrained environments such as edge devices and AI PCs. While these\nquantization advances promise models that are more cost-effective in terms of\nlatency, memory, throughput, and energy consumption, the computational\nefficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)\nused to deploy them remains underexplored. In this work, we take a bottom-up\napproach: we first design and implement 1-bit and 2-bit microkernels optimized\nfor modern CPUs, achieving peak computational efficiency across a variety of\nCPU platforms. We integrate these microkernels into a state-of-the-art LLM\ninference framework, namely PyTorch-TPP, and present end-to-end inference\nresults with 2-bit models that outperform the current SOTA runtime bitnet.cpp\nby up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model\ninference. Our optimized runtime advances the state of LLM inference on AI PCs\nand edge devices, paving the way for efficient deployment of ultra-low-bit LLM\nmodels.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf91/1.58/2\u4f4d\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u7684\u4f18\u5316\u5fae\u5185\u6838\u8bbe\u8ba1\uff0c\u96c6\u6210\u5230PyTorch-TPP\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709SOTA\u8fd0\u884c\u65f6bitnet.cpp\u5feb2.2\u500d\u3001\u6bd416\u4f4d\u6a21\u578b\u5feb7\u500d\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff08\u5982\u8fb9\u7f18\u8bbe\u5907\u548cAI PC\uff09\u4e2d\u7684\u9ad8\u6548\u90e8\u7f72\uff0c\u586b\u8865\u73b0\u6709\u63a8\u7406\u8fd0\u884c\u65f6\u8ba1\u7b97\u6548\u7387\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u9488\u5bf9\u73b0\u4ee3CPU\u4f18\u5316\u76841\u4f4d\u548c2\u4f4d\u5fae\u5185\u6838\uff0c\u96c6\u6210\u5230PyTorch-TPP\u6846\u67b6\u4e2d\uff0c\u8fdb\u884c\u7aef\u5230\u7aef\u63a8\u7406\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "\u4f18\u5316\u7684\u8fd0\u884c\u65f6\u57282\u4f4d\u6a21\u578b\u4e0a\u6bd4bitnet.cpp\u5feb2.2\u500d\uff0c\u6bd416\u4f4d\u6a21\u578b\u5feb7\u500d\u3002", "conclusion": "\u4f18\u5316\u540e\u7684\u8fd0\u884c\u65f6\u63a8\u52a8\u4e86AI PC\u548c\u8fb9\u7f18\u8bbe\u5907\u4e0aLLM\u63a8\u7406\u7684\u53d1\u5c55\uff0c\u4e3a\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2508.08099", "categories": ["cs.IT", "math.IT", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2508.08099", "abs": "https://arxiv.org/abs/2508.08099", "authors": ["Lei Liu", "Yuhao Chi", "Shunqi Huang"], "title": "Random Modulation: Achieving Asymptotic Replica Optimality over Arbitrary Norm-Bounded and Spectrally Convergent Channel Matrices", "comment": null, "summary": "This paper introduces a random modulation technique that is decoupled from\nthe channel matrix, allowing it to be applied to arbitrary norm-bounded and\nspectrally convergent channel matrices. The proposed random modulation\nconstructs an equivalent dense and random channel matrix, ensuring that the\nsignals undergo sufficient statistical channel fading. It also guarantees the\nasymptotic replica maximum a posteriori (MAP) bit-error rate (BER) optimality\nof approximate message passing (AMP)-type detectors for linear systems with\narbitrary norm-bounded and spectrally convergent channel matrices when their\nstate evolution has a unique fixed point. Then, a low-complexity cross-domain\nmemory approximate message passing (CD-MAMP) detector is proposed for random\nmodulation, leveraging the sparsity of the time-domain channel and the\nrandomness of the random transform-domain channel. Furthermore, the optimal\npower allocation schemes are derived to minimize the replica MAP BER and\nmaximize the replica constrained capacity of random-modulated linear systems,\nassuming the availability of channel state information (CSI) at the\ntransceiver. Numerical results show that the proposed random modulation can\nachieve BER and block-error rate (BLER) performance gains of up to 2 - 3 dB\ncompared to existing OFDM/OTFS/AFDM with 5G-NR LDPC codes, under both average\nand optimized power allocation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u4fe1\u9053\u77e9\u9635\u89e3\u8026\u7684\u968f\u673a\u8c03\u5236\u6280\u672f\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u8303\u6570\u6709\u754c\u548c\u8c31\u6536\u655b\u7684\u4fe1\u9053\u77e9\u9635\uff0c\u5e76\u901a\u8fc7\u7b49\u6548\u5bc6\u96c6\u968f\u673a\u4fe1\u9053\u77e9\u9635\u786e\u4fdd\u4fe1\u53f7\u7ecf\u5386\u8db3\u591f\u7684\u7edf\u8ba1\u4fe1\u9053\u8870\u843d\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8c03\u5236\u6280\u672f\u5728\u9ad8\u590d\u6742\u5ea6\u4fe1\u9053\u77e9\u9635\u4e0b\u7684\u6027\u80fd\u9650\u5236\u95ee\u9898\uff0c\u63d0\u5347\u68c0\u6d4b\u5668\u7684BER\u548cBLER\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u968f\u673a\u8c03\u5236\u6280\u672f\uff0c\u6784\u5efa\u7b49\u6548\u5bc6\u96c6\u968f\u673a\u4fe1\u9053\u77e9\u9635\uff0c\u5e76\u8bbe\u8ba1\u4f4e\u590d\u6742\u5ea6CD-MAMP\u68c0\u6d4b\u5668\uff0c\u7ed3\u5408\u65f6\u57df\u4fe1\u9053\u7a00\u758f\u6027\u548c\u53d8\u6362\u57df\u968f\u673a\u6027\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u968f\u673a\u8c03\u5236\u5728BER\u548cBLER\u4e0a\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u53472-3 dB\u3002", "conclusion": "\u968f\u673a\u8c03\u5236\u6280\u672f\u5728\u9ad8\u590d\u6742\u5ea6\u4fe1\u9053\u77e9\u9635\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.07778", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07778", "abs": "https://arxiv.org/abs/2508.07778", "authors": ["Farhad Rezazadeh", "Raymond Zhao", "Jiongyu Dai", "Amir Ashtari Gargari", "Hatim Chergui", "Lingjia Liu"], "title": "An Experimental Reservoir-Augmented Foundation Model: 6G O-RAN Case Study", "comment": "5 pages, 2 figures", "summary": "Next-generation open radio access networks (O-RAN) continuously stream tens\nof key performance indicators (KPIs) together with raw in-phase/quadrature (IQ)\nsamples, yielding ultra-high-dimensional, non-stationary time series that\noverwhelm conventional transformer architectures. We introduce a\nreservoir-augmented masked autoencoding transformer (RA-MAT). This time series\nfoundation model employs echo state network (ESN) computing with masked\nautoencoding to satisfy the stringent latency, energy efficiency, and\nscalability requirements of 6G O-RAN testing. A fixed, randomly initialized ESN\nrapidly projects each temporal patch into a rich dynamical embedding without\nbackpropagation through time, converting the quadratic self-attention\nbottleneck into a lightweight linear operation. These embeddings drive a\npatch-wise masked autoencoder that reconstructs 30% randomly masked patches,\ncompelling the encoder to capture both local dynamics and long-range structure\nfrom unlabeled data. After self-supervised pre-training, RA-MAT is fine-tuned\nwith a shallow task head while keeping the reservoir and most transformer\nlayers frozen, enabling low-footprint adaptation to diverse downstream tasks\nsuch as O-RAN KPI forecasting. In a comprehensive O-RAN KPI case study, RA-MAT\nachieved sub-0.06 mean squared error (MSE) on several continuous and discrete\nKPIs. This work positions RA-MAT as a practical pathway toward real-time,\nfoundation-level analytics in future 6G networks.", "AI": {"tldr": "RA-MAT\u662f\u4e00\u79cd\u57fa\u4e8e\u50a8\u5c42\u8ba1\u7b97\u548c\u63a9\u7801\u81ea\u7f16\u7801\u7684Transformer\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u74066G O-RAN\u4e2d\u7684\u9ad8\u7ef4\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u6548\u7387\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfTransformer\u67b6\u6784\u5728\u5904\u7406\u8d85\u9ad8\u9891\u7ef4\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u7684\u6027\u80fd\u74f6\u9888\uff0c\u6ee1\u8db36G O-RAN\u5bf9\u5b9e\u65f6\u6027\u548c\u80fd\u6548\u7684\u4e25\u683c\u8981\u6c42\u3002", "method": "\u7ed3\u5408\u50a8\u5c42\u8ba1\u7b97\uff08ESN\uff09\u548c\u63a9\u7801\u81ea\u7f16\u7801\u6280\u672f\uff0c\u901a\u8fc7\u5feb\u901f\u6295\u5f71\u548c\u8f7b\u91cf\u7ea7\u7ebf\u6027\u64cd\u4f5c\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u5229\u7528\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u5728O-RAN KPI\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cRA-MAT\u5b9e\u73b0\u4e86\u4f4e\u4e8e0.06\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u3002", "conclusion": "RA-MAT\u4e3a6G\u7f51\u7edc\u4e2d\u7684\u5b9e\u65f6\u57fa\u7840\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06754", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.06754", "abs": "https://arxiv.org/abs/2508.06754", "authors": ["Vanessa Figueiredo"], "title": "A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks", "comment": null, "summary": "We introduce a modular prompting framework that supports safer and more\nadaptive use of large language models (LLMs) across dynamic, user-centered\ntasks. Grounded in human learning theory, particularly the Zone of Proximal\nDevelopment (ZPD), our method combines a natural language boundary prompt with\na control schema encoded with fuzzy scaffolding logic and adaptation rules.\nThis architecture enables LLMs to modulate behavior in response to user state\nwithout requiring fine-tuning or external orchestration. In a simulated\nintelligent tutoring setting, the framework improves scaffolding quality,\nadaptivity, and instructional alignment across multiple models, outperforming\nstandard prompting baselines. Evaluation is conducted using rubric-based LLM\ngraders at scale. While initially developed for education, the framework has\nshown promise in other interaction-heavy domains, such as procedural content\ngeneration for games. Designed for safe deployment, it provides a reusable\nmethodology for structuring interpretable, goal-aligned LLM behavior in\nuncertain or evolving contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u63d0\u793a\u6846\u67b6\uff0c\u652f\u6301\u66f4\u5b89\u5168\u3001\u66f4\u81ea\u9002\u5e94\u5730\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u3001\u7528\u6237\u4e2d\u5fc3\u7684\u4efb\u52a1\u3002", "motivation": "\u57fa\u4e8e\u4eba\u7c7b\u5b66\u4e60\u7406\u8bba\uff08\u5982\u6700\u8fd1\u53d1\u5c55\u533aZPD\uff09\uff0c\u65e8\u5728\u63d0\u5347LLM\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u8fb9\u754c\u63d0\u793a\u548c\u63a7\u5236\u6a21\u5f0f\uff0c\u91c7\u7528\u6a21\u7cca\u652f\u67b6\u903b\u8f91\u548c\u9002\u5e94\u89c4\u5219\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5916\u90e8\u534f\u8c03\u3002", "result": "\u5728\u6a21\u62df\u667a\u80fd\u8f85\u5bfc\u573a\u666f\u4e2d\uff0c\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u652f\u67b6\u8d28\u91cf\u3001\u9002\u5e94\u6027\u548c\u6559\u5b66\u4e00\u81f4\u6027\uff0c\u4f18\u4e8e\u6807\u51c6\u63d0\u793a\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u6559\u80b2\u9886\u57df\uff0c\u8fd8\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u4ea4\u4e92\u5bc6\u96c6\u578b\u9886\u57df\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6216\u52a8\u6001\u73af\u5883\u4e2d\u7684LLM\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u65b9\u6cd5\u3002"}}
{"id": "2508.08225", "categories": ["cs.NI", "cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.08225", "abs": "https://arxiv.org/abs/2508.08225", "authors": ["Mansoor Shafi", "Erik G. Larsson", "Xingqin Lin", "Dorin Panaitopol", "Stefan Parkvall", "Flavien Ronteix-Jacquet", "Antti Toskala"], "title": "Industrial Viewpoints on RAN Technologies for 6G", "comment": "submitted to the Proceedings of the IEEE", "summary": "6G standardization is to start imminently, with commercial deployments\nexpected before 2030. Its technical components and performance requirements are\nthe focus of this article. Our emphasis is on the 6G radio access, especially\nMIMO, AI, waveforms, coding, signal constellations and integration with\nnon-terrestrial networks. Whilst standardization has not yet formally started,\nthe scope of the 6G study items has been defined. Our predictions in this paper\nare speculative as there are no results of the study yet, but our views are\nguided by implementation and deployment aspects. We expect that the views here\nwill guide researchers and industry practitioners.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e866G\u6807\u51c6\u5316\u7684\u6280\u672f\u7ec4\u4ef6\u548c\u6027\u80fd\u8981\u6c42\uff0c\u91cd\u70b9\u5173\u6ce8\u65e0\u7ebf\u63a5\u5165\u6280\u672f\uff0c\u5982MIMO\u3001AI\u3001\u6ce2\u5f62\u7b49\uff0c\u5e76\u9884\u6d4b\u5176\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u4e3a\u5373\u5c06\u5f00\u59cb\u76846G\u6807\u51c6\u5316\u63d0\u4f9b\u6280\u672f\u6307\u5bfc\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u5206\u67906G\u65e0\u7ebf\u63a5\u5165\u6280\u672f\uff08\u5982MIMO\u3001AI\u3001\u6ce2\u5f62\u7b49\uff09\u53ca\u5176\u4e0e\u975e\u5730\u9762\u7f51\u7edc\u7684\u96c6\u6210\uff0c\u63d0\u51fa\u9884\u6d4b\u6027\u89c2\u70b9\u3002", "result": "\u867d\u7136\u5c1a\u65e0\u5177\u4f53\u7814\u7a76\u7ed3\u679c\uff0c\u4f46\u57fa\u4e8e\u5b9e\u65bd\u548c\u90e8\u7f72\u65b9\u9762\u7684\u7ecf\u9a8c\uff0c\u63d0\u51fa\u4e86\u5bf96G\u6280\u672f\u53d1\u5c55\u7684\u9884\u6d4b\u3002", "conclusion": "\u672c\u6587\u7684\u89c2\u70b9\u6709\u671b\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u884c\u4e1a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6307\u5bfc\uff0c\u63a8\u52a86G\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.07882", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07882", "abs": "https://arxiv.org/abs/2508.07882", "authors": ["Conor Muldoon"], "title": "Scalable and Energy-Efficient Predictive Data Collection in Wireless Sensor Networks with Constructive Interference", "comment": null, "summary": "A new class of Wireless Sensor Network has emerged whereby multiple nodes\ntransmit data simultaneously, exploiting constructive interference to enable\ndata collection frameworks with low energy usage and latency. This paper\npresents STAIR (Spatio-Temporal Activation for Intelligent Relaying), a\nscalable, resilient framework for Wireless Sensor Networks that leverages\nconstructive interference and operates effectively under stringent resource\nconstraints. Using constructive interference requires all nodes to transmit the\nsame packet at the same time, thus, only one source node can send data per time\nslot. STAIR uses coarse-grained topology information to flood a selected subset\nof the network, relaying sensor readings from individual nodes during their\nallocated time slots. A submodular optimisation algorithm with proven quality\nbounds determines near-optimal sensor activation locations and times, aiming to\nminimise the sum of mean squared prediction errors from a multiple multivariate\nlinear regression model, which is used to estimate values at unselected\nlocations and times. This framework has been extensively validated on a\nreal-world testbed deployment.", "AI": {"tldr": "STAIR\u662f\u4e00\u79cd\u5229\u7528\u65f6\u7a7a\u6fc0\u6d3b\u548c\u5efa\u8bbe\u6027\u5e72\u6270\u7684\u4f4e\u80fd\u8017\u3001\u4f4e\u5ef6\u8fdf\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u4e2d\u591a\u8282\u70b9\u540c\u65f6\u4f20\u8f93\u6570\u636e\u65f6\u7684\u8d44\u6e90\u9650\u5236\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7c97\u7c92\u5ea6\u62d3\u6251\u4fe1\u606f\u9009\u62e9\u5b50\u7f51\uff0c\u5e76\u901a\u8fc7\u6b21\u6a21\u4f18\u5316\u7b97\u6cd5\u786e\u5b9a\u4f20\u611f\u5668\u6fc0\u6d3b\u4f4d\u7f6e\u548c\u65f6\u95f4\u3002", "result": "\u5728\u771f\u5b9e\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "STAIR\u6846\u67b6\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.06823", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06823", "abs": "https://arxiv.org/abs/2508.06823", "authors": ["Xuan Zhao", "Jun Tao"], "title": "Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation", "comment": "Accepted by IEEE VIS 2025", "summary": "Exploring volumetric data is crucial for interpreting scientific datasets.\nHowever, selecting optimal viewpoints for effective navigation can be\nchallenging, particularly for users without extensive domain expertise or\nfamiliarity with 3D navigation. In this paper, we propose a novel framework\nthat leverages natural language interaction to enhance volumetric data\nexploration. Our approach encodes volumetric blocks to capture and\ndifferentiate underlying structures. It further incorporates a CLIP Score\nmechanism, which provides semantic information to the blocks to guide\nnavigation. The navigation is empowered by a reinforcement learning framework\nthat leverage these semantic cues to efficiently search for and identify\ndesired viewpoints that align with the user's intent. The selected viewpoints\nare evaluated using CLIP Score to ensure that they best reflect the user\nqueries. By automating viewpoint selection, our method improves the efficiency\nof volumetric data navigation and enhances the interpretability of complex\nscientific phenomena.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548cCLIP Score\u673a\u5236\u4f18\u5316\u4f53\u6570\u636e\u63a2\u7d22\u7684\u89c6\u70b9\u9009\u62e9\u3002", "motivation": "\u4f53\u6570\u636e\u63a2\u7d22\u5bf9\u79d1\u5b66\u6570\u636e\u96c6\u89e3\u91ca\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u62163D\u5bfc\u822a\u7ecf\u9a8c\u7684\u7528\u6237\u96be\u4ee5\u9009\u62e9\u6700\u4f73\u89c6\u70b9\u3002", "method": "\u6846\u67b6\u5c06\u4f53\u6570\u636e\u5757\u7f16\u7801\u4ee5\u533a\u5206\u7ed3\u6784\uff0c\u7ed3\u5408CLIP Score\u63d0\u4f9b\u8bed\u4e49\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u641c\u7d22\u7b26\u5408\u7528\u6237\u610f\u56fe\u7684\u89c6\u70b9\u3002", "result": "\u65b9\u6cd5\u81ea\u52a8\u5316\u89c6\u70b9\u9009\u62e9\uff0c\u63d0\u5347\u4f53\u6570\u636e\u5bfc\u822a\u6548\u7387\u548c\u590d\u6742\u79d1\u5b66\u73b0\u8c61\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u8bed\u4e49\u5f15\u5bfc\uff0c\u6846\u67b6\u663e\u8457\u4f18\u5316\u4e86\u4f53\u6570\u636e\u63a2\u7d22\u7684\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.07978", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07978", "abs": "https://arxiv.org/abs/2508.07978", "authors": ["Hamidreza Mazandarani", "Mohammad Farhoudi", "Masoud Shokrnezhad", "Tarik Taleb"], "title": "Adaptive Multiple Access and Service Placement for Generative Diffusion Models", "comment": "This manuscript has been accepted for presentation at IEEE GLOBECOM\n  2025. You can use this material personally. Reprinting or republishing this\n  material for the purpose of advertising or promotion, etc., must adhere to\n  IEEE policy. The DOI will be supplied as soon as it becomes available", "summary": "Generative Diffusion Models (GDMs) have emerged as key components of\nGenerative Artificial Intelligence (GenAI), offering unparalleled\nexpressiveness and controllability for complex data generation tasks. However,\ntheir deployment in real-time and mobile environments remains challenging due\nto the iterative and resource-intensive nature of the inference process.\nAddressing these challenges, this paper introduces a unified optimization\nframework that jointly tackles service placement and multiple access control\nfor GDMs in mobile edge networks. We propose LEARN-GDM, a Deep Reinforcement\nLearning-based algorithm that dynamically partitions denoising blocks across\nheterogeneous edge nodes, while accounting for latent transmission costs and\nenabling adaptive reduction of inference steps. Our approach integrates a\ngreedy multiple access scheme with a Double and Dueling Deep Q-Learning\n(D3QL)-based service placement, allowing for scalable, adaptable, and\nresource-efficient operation under stringent quality of service requirements.\nSimulations demonstrate the superior performance of the proposed framework in\nterms of scalability and latency resilience compared to conventional monolithic\nand fixed chain-length placement strategies. This work advances the state of\nthe art in edge-enabled GenAI by offering an adaptable solution for GDM\nservices orchestration, paving the way for future extensions toward semantic\nnetworking and co-inference across distributed environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLEARN-GDM\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u751f\u6210\u6269\u6563\u6a21\u578b\u5728\u79fb\u52a8\u8fb9\u7f18\u7f51\u7edc\u4e2d\u7684\u5b9e\u65f6\u90e8\u7f72\u95ee\u9898\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u5206\u914d\u53bb\u566a\u5757\u5e76\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u3002", "motivation": "\u751f\u6210\u6269\u6563\u6a21\u578b\u5728\u590d\u6742\u6570\u636e\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8fed\u4ee3\u548c\u8d44\u6e90\u5bc6\u96c6\u7684\u63a8\u7406\u8fc7\u7a0b\u9650\u5236\u4e86\u5728\u5b9e\u65f6\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u63d0\u51faLEARN-GDM\u7b97\u6cd5\uff0c\u7ed3\u5408\u8d2a\u5a6a\u591a\u5740\u63a5\u5165\u65b9\u6848\u548c\u57fa\u4e8eD3QL\u7684\u670d\u52a1\u653e\u7f6e\u7b56\u7565\uff0c\u52a8\u6001\u5206\u914d\u53bb\u566a\u5757\u5e76\u51cf\u5c11\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u4eff\u771f\u663e\u793a\u8be5\u6846\u67b6\u5728\u53ef\u6269\u5c55\u6027\u548c\u5ef6\u8fdf\u5f39\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8fb9\u7f18\u751f\u6210AI\u63d0\u4f9b\u4e86\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u7f51\u7edc\u548c\u534f\u540c\u63a8\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2508.06832", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06832", "abs": "https://arxiv.org/abs/2508.06832", "authors": ["Haifeng Li", "Wang Guo", "Haiyang Wu", "Mengwei Wu", "Jipeng Zhang", "Qing Zhu", "Yu Liu", "Xin Huang", "Chao Tao"], "title": "Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges", "comment": null, "summary": "The mainstream paradigm of remote sensing image interpretation has long been\ndominated by vision-centered models, which rely on visual features for semantic\nunderstanding. However, these models face inherent limitations in handling\nmulti-modal reasoning, semantic abstraction, and interactive decision-making.\nWhile recent advances have introduced Large Language Models (LLMs) into remote\nsensing workflows, existing studies primarily focus on downstream applications,\nlacking a unified theoretical framework that explains the cognitive role of\nlanguage. This review advocates a paradigm shift from vision-centered to\nlanguage-centered remote sensing interpretation. Drawing inspiration from the\nGlobal Workspace Theory (GWT) of human cognition, We propose a\nlanguage-centered framework for remote sensing interpretation that treats LLMs\nas the cognitive central hub integrating perceptual, task, knowledge and action\nspaces to enable unified understanding, reasoning, and decision-making. We\nfirst explore the potential of LLMs as the central cognitive component in\nremote sensing interpretation, and then summarize core technical challenges,\nincluding unified multimodal representation, knowledge association, and\nreasoning and decision-making. Furthermore, we construct a global\nworkspace-driven interpretation mechanism and review how language-centered\nsolutions address each challenge. Finally, we outline future research\ndirections from four perspectives: adaptive alignment of multimodal data, task\nunderstanding under dynamic knowledge constraints, trustworthy reasoning, and\nautonomous interaction. This work aims to provide a conceptual foundation for\nthe next generation of remote sensing interpretation systems and establish a\nroadmap toward cognition-driven intelligent geospatial analysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\u89c6\u89c9\u4e2d\u5fc3\u8f6c\u5411\u8bed\u8a00\u4e2d\u5fc3\u7684\u9065\u611f\u56fe\u50cf\u89e3\u91ca\u8303\u5f0f\uff0c\u501f\u9274\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\uff0c\u4ee5\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u6838\u5fc3\uff0c\u6574\u5408\u611f\u77e5\u3001\u4efb\u52a1\u3001\u77e5\u8bc6\u548c\u884c\u52a8\u7a7a\u95f4\uff0c\u5b9e\u73b0\u7edf\u4e00\u7406\u89e3\u3001\u63a8\u7406\u548c\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u4e2d\u5fc3\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u3001\u8bed\u4e49\u62bd\u8c61\u548c\u4ea4\u4e92\u51b3\u7b56\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u8bed\u8a00\u5728\u8ba4\u77e5\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u8bed\u8a00\u4e2d\u5fc3\u6846\u67b6\uff0c\u5c06LLMs\u4f5c\u4e3a\u8ba4\u77e5\u4e2d\u67a2\uff0c\u6574\u5408\u591a\u6a21\u6001\u8868\u793a\u3001\u77e5\u8bc6\u5173\u8054\u3001\u63a8\u7406\u4e0e\u51b3\u7b56\uff0c\u5e76\u6784\u5efa\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u9a71\u52a8\u7684\u89e3\u91ca\u673a\u5236\u3002", "result": "\u603b\u7ed3\u4e86\u8bed\u8a00\u4e2d\u5fc3\u89e3\u51b3\u65b9\u6848\u5982\u4f55\u5e94\u5bf9\u6838\u5fc3\u6311\u6218\uff0c\u5982\u7edf\u4e00\u591a\u6a21\u6001\u8868\u793a\u548c\u77e5\u8bc6\u5173\u8054\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u9065\u611f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\uff0c\u5efa\u7acb\u8ba4\u77e5\u9a71\u52a8\u7684\u667a\u80fd\u5730\u7406\u7a7a\u95f4\u5206\u6790\u8def\u7ebf\u56fe\u3002"}}
{"id": "2508.06836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06836", "abs": "https://arxiv.org/abs/2508.06836", "authors": ["Xutong Zhao", "Yaqi Xie"], "title": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning", "comment": "Accepted at AISTATS 2025", "summary": "Cooperative multi-agent reinforcement learning (MARL) aims to coordinate\nmultiple agents to achieve a common goal. A key challenge in MARL is credit\nassignment, which involves assessing each agent's contribution to the shared\nreward. Given the diversity of tasks, agents may perform different types of\ncoordination, with rewards attributed to diverse and often overlapping agent\nsubsets. In this work, we formalize the credit assignment level as the number\nof agents cooperating to obtain a reward, and address scenarios with multiple\ncoexisting levels. We introduce a multi-level advantage formulation that\nperforms explicit counterfactual reasoning to infer credits across distinct\nlevels. Our method, Multi-level Advantage Credit Assignment (MACA), captures\nagent contributions at multiple levels by integrating advantage functions that\nreason about individual, joint, and correlated actions. Utilizing an\nattention-based framework, MACA identifies correlated agent relationships and\nconstructs multi-level advantages to guide policy learning. Comprehensive\nexperiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior\nperformance, underscoring its efficacy in complex credit assignment scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ea7\u4f18\u52bf\u4fe1\u7528\u5206\u914d\u65b9\u6cd5\uff08MACA\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u7ea7\u4f18\u52bf\u51fd\u6570\u548c\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u4e0d\u540c\u5c42\u6b21\u7684\u667a\u80fd\u4f53\u8d21\u732e\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\u590d\u6742\uff0c\u5c24\u5176\u662f\u5f53\u4efb\u52a1\u6d89\u53ca\u4e0d\u540c\u5c42\u6b21\u7684\u534f\u4f5c\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u8bc4\u4f30\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u8d21\u732e\u3002", "method": "\u63d0\u51faMACA\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7ea7\u4f18\u52bf\u51fd\u6570\uff08\u4e2a\u4f53\u3001\u8054\u5408\u548c\u76f8\u5173\u52a8\u4f5c\uff09\u548c\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u660e\u786e\u63a8\u7406\u4e0d\u540c\u5c42\u6b21\u7684\u4fe1\u7528\u5206\u914d\u3002", "result": "\u5728Starcraft v1&v2\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMACA\u5728\u590d\u6742\u4fe1\u7528\u5206\u914d\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "MACA\u901a\u8fc7\u591a\u7ea7\u4f18\u52bf\u63a8\u7406\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4efb\u52a1\u3002"}}
{"id": "2508.07586", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07586", "abs": "https://arxiv.org/abs/2508.07586", "authors": ["Wenjing Zhang", "Ye Hu", "Tao Luo", "Zhilong Zhang", "Mingzhe Chen"], "title": "Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method", "comment": null, "summary": "In this paper, a novel covert semantic communication framework is\ninvestigated. Within this framework, a server extracts and transmits the\nsemantic information, i.e., the meaning of image data, to a user over several\ntime slots. An attacker seeks to detect and eavesdrop the semantic transmission\nto acquire details of the original image. To avoid data meaning being\neavesdropped by an attacker, a friendly jammer is deployed to transmit jamming\nsignals to interfere the attacker so as to hide the transmitted semantic\ninformation. Meanwhile, the server will strategically select time slots for\nsemantic information transmission. Due to limited energy, the jammer will not\ncommunicate with the server and hence the server does not know the transmit\npower of the jammer. Therefore, the server must jointly optimize the semantic\ninformation transmitted at each time slot and the corresponding transmit power\nto maximize the privacy and the semantic information transmission quality of\nthe user. To solve this problem, we propose a prioritised sampling assisted\ntwin delayed deep deterministic policy gradient algorithm to jointly determine\nthe transmitted semantic information and the transmit power per time slot\nwithout the communications between the server and the jammer. Compared to\nstandard reinforcement learning methods, the propose method uses an additional\nQ network to estimate Q values such that the agent can select the action with a\nlower Q value from the two Q networks thus avoiding local optimal action\nselection and estimation bias of Q values. Simulation results show that the\nproposed algorithm can improve the privacy and the semantic information\ntransmission quality by up to 77.8% and 14.3% compared to the traditional\nreinforcement learning methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9690\u853d\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u53cb\u597d\u5e72\u6270\u5668\u548c\u65f6\u95f4\u69fd\u4f18\u5316\u7b56\u7565\u4fdd\u62a4\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\uff0c\u907f\u514d\u88ab\u653b\u51fb\u8005\u7a83\u53d6\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u8bed\u4e49\u901a\u4fe1\u4e2d\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u9632\u6b62\u653b\u51fb\u8005\u7a83\u53d6\u8bed\u4e49\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u4f18\u5148\u91c7\u6837\u8f85\u52a9\u7684\u53cc\u5ef6\u8fdf\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u8bed\u4e49\u4fe1\u606f\u548c\u4f20\u8f93\u529f\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u63d0\u534777.8%\uff0c\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\u8d28\u91cf\u63d0\u534714.3%\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8bed\u4e49\u901a\u4fe1\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u4f20\u8f93\u8d28\u91cf\uff0c\u65e0\u9700\u670d\u52a1\u5668\u4e0e\u5e72\u6270\u5668\u4e4b\u95f4\u7684\u901a\u4fe1\u3002"}}
{"id": "2508.06851", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.06851", "abs": "https://arxiv.org/abs/2508.06851", "authors": ["Pengfei Zhou", "Xiaopeng Peng", "Fanrui Zhang", "Zhaopan Xu", "Jiaxin Ai", "Yansheng Qiu", "Chuanhao Li", "Zhen Li", "Ming Li", "Yukang Feng", "Jianwen Sun", "Haoquan Zhang", "Zizhen Li", "Xiaofeng Mao", "Zekai Li", "Wangbo Zhao", "Kai Wang", "Xiaojun Chang", "Wenqi Shao", "Yang You", "Kaipeng Zhang"], "title": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams", "comment": "35 pages, 33 figures", "summary": "Multimodal large language models (MLLMs), which integrate language and visual\ncues for problem-solving, are crucial for advancing artificial general\nintelligence (AGI). However, current benchmarks for measuring the intelligence\nof MLLMs suffer from limited scale, narrow coverage, and unstructured\nknowledge, offering only static and undifferentiated evaluations. To bridge\nthis gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark\nbuilt from real-world K-12 exams spanning six disciplines with 141K instances\nand 6,225 knowledge points organized in a six-layer taxonomy. Covering five\nquestion formats with difficulty and year annotations, it enables comprehensive\nevaluation to capture the extent to which MLLMs perform over four dimensions:\n1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,\nand 4) knowledge-driven reasoning. We propose a novel dynamic evaluation\nframework that introduces unfamiliar visual, textual, and question form shifts\nto challenge model generalization while improving benchmark objectivity and\nlongevity by mitigating data contamination. We further evaluate knowledge-point\nreference-augmented generation (KP-RAG) to examine the role of knowledge in\nproblem-solving. Key findings reveal limitations in current MLLMs in multiple\naspects and provide guidance for enhancing model robustness, interpretability,\nand AI-assisted education.", "AI": {"tldr": "MDK12-Bench\u662f\u4e00\u4e2a\u591a\u5b66\u79d1\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u5305\u62ec\u96be\u5ea6\u3001\u65f6\u95f4\u53d8\u5316\u3001\u4e0a\u4e0b\u6587\u53d8\u5316\u548c\u77e5\u8bc6\u9a71\u52a8\u63a8\u7406\u3002", "motivation": "\u5f53\u524dMLLMs\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u89c4\u6a21\u5c0f\u3001\u8986\u76d6\u7a84\u3001\u77e5\u8bc6\u65e0\u7ed3\u6784\u5316\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86MDK12-Bench\u57fa\u51c6\uff0c\u5305\u542b141K\u5b9e\u4f8b\u548c6,225\u4e2a\u77e5\u8bc6\u70b9\uff0c\u91c7\u7528\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u548c\u77e5\u8bc6\u53c2\u8003\u589e\u5f3a\u751f\u6210\uff08KP-RAG\uff09\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u5f53\u524dMLLMs\u5728\u591a\u4e2a\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "MDK12-Bench\u4e3aMLLMs\u7684\u5168\u9762\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u5e76\u63ed\u793a\u4e86\u6539\u8fdb\u65b9\u5411\uff0c\u5c24\u5176\u5728AI\u8f85\u52a9\u6559\u80b2\u9886\u57df\u3002"}}
{"id": "2508.06859", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06859", "abs": "https://arxiv.org/abs/2508.06859", "authors": ["Shuo Tang", "Jian Xu", "Jiadong Zhang", "Yi Chen", "Qizhao Jin", "Lingdong Shen", "Chenglin Liu", "Shiming Xiang"], "title": "MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction", "comment": null, "summary": "Timely and accurate severe weather warnings are critical for disaster\nmitigation. However, current forecasting systems remain heavily reliant on\nmanual expert interpretation, introducing subjectivity and significant\noperational burdens. With the rapid development of AI technologies, the\nend-to-end \"AI weather station\" is gradually emerging as a new trend in\npredicting severe weather events. Three core challenges impede the development\nof end-to-end AI severe weather system: (1) scarcity of severe weather event\nsamples; (2) imperfect alignment between high-dimensional meteorological data\nand textual warnings; (3) existing multimodal language models are unable to\nhandle high-dimensional meteorological data and struggle to fully capture the\ncomplex dependencies across temporal sequences, vertical pressure levels, and\nspatial dimensions. To address these challenges, we introduce MP-Bench, the\nfirst large-scale temporal multimodal dataset for severe weather events\nprediction, comprising 421,363 pairs of raw multi-year meteorological data and\ncorresponding text caption, covering a wide range of severe weather scenarios\nacross China. On top of this dataset, we develop a meteorology multimodal large\nmodel (MMLM) that directly ingests 4D meteorological inputs. In addition, it is\ndesigned to accommodate the unique characteristics of 4D meteorological data\nflow, incorporating three plug-and-play adaptive fusion modules that enable\ndynamic feature extraction and integration across temporal sequences, vertical\npressure layers, and spatial dimensions. Extensive experiments on MP-Bench\ndemonstrate that MMLM performs exceptionally well across multiple tasks,\nhighlighting its effectiveness in severe weather understanding and marking a\nkey step toward realizing automated, AI-driven weather forecasting systems. Our\nsource code and dataset will be made publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u7aef\u5230\u7aef\u5929\u6c14\u9884\u8b66\u7cfb\u7edf\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6MP-Bench\u548c\u5f00\u53d1\u6c14\u8c61\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MMLM\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6837\u672c\u7a00\u7f3a\u3001\u6570\u636e\u5bf9\u9f50\u548c\u591a\u6a21\u6001\u5904\u7406\u4e0a\u7684\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u5929\u6c14\u9884\u8b66\u7cfb\u7edf\u4f9d\u8d56\u4eba\u5de5\u4e13\u5bb6\u89e3\u8bfb\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u64cd\u4f5c\u8d1f\u62c5\u3002AI\u6280\u672f\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u5929\u6c14\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\uff0c\u4f46\u9762\u4e34\u6837\u672c\u7a00\u7f3a\u3001\u6570\u636e\u5bf9\u9f50\u548c\u591a\u6a21\u6001\u5904\u7406\u7b49\u6838\u5fc3\u6311\u6218\u3002", "method": "\u6784\u5efa\u4e86MP-Bench\u6570\u636e\u96c6\uff08421,363\u5bf9\u6c14\u8c61\u6570\u636e\u4e0e\u6587\u672c\u63cf\u8ff0\uff09\uff0c\u5e76\u5f00\u53d1\u4e86MMLM\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\u5904\u74064D\u6c14\u8c61\u6570\u636e\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u3002", "result": "MMLM\u5728MP-Bench\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5929\u6c14\u7406\u89e3\u548c\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "MMLM\u4e3a\u81ea\u52a8\u5316AI\u5929\u6c14\u9884\u8b66\u7cfb\u7edf\u8fc8\u51fa\u4e86\u5173\u952e\u4e00\u6b65\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u516c\u5f00\u3002"}}
{"id": "2508.06894", "categories": ["cs.AI", "cs.LG", "68T05"], "pdf": "https://arxiv.org/pdf/2508.06894", "abs": "https://arxiv.org/abs/2508.06894", "authors": ["Giovanni Varricchione", "Toryn Q. Klassen", "Natasha Alechina", "Mehdi Dastani", "Brian Logan", "Sheila A. McIlraith"], "title": "Pushdown Reward Machines for Reinforcement Learning", "comment": null, "summary": "Reward machines (RMs) are automata structures that encode (non-Markovian)\nreward functions for reinforcement learning (RL). RMs can reward any behaviour\nrepresentable in regular languages and, when paired with RL algorithms that\nexploit RM structure, have been shown to significantly improve sample\nefficiency in many domains. In this work, we present pushdown reward machines\n(pdRMs), an extension of reward machines based on deterministic pushdown\nautomata. pdRMs can recognize and reward temporally extended behaviours\nrepresentable in deterministic context-free languages, making them more\nexpressive than reward machines. We introduce two variants of pdRM-based\npolicies, one which has access to the entire stack of the pdRM, and one which\ncan only access the top $k$ symbols (for a given constant $k$) of the stack. We\npropose a procedure to check when the two kinds of policies (for a given\nenvironment, pdRM, and constant $k$) achieve the same optimal expected reward.\nWe then provide theoretical results establishing the expressive power of pdRMs,\nand space complexity results about the proposed learning problems. Finally, we\nprovide experimental results showing how agents can be trained to perform tasks\nrepresentable in deterministic context-free languages using pdRMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u63a8\u4e0b\u5956\u52b1\u673a\uff08pdRMs\uff09\uff0c\u6269\u5c55\u4e86\u5956\u52b1\u673a\uff08RMs\uff09\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u652f\u6301\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u7684\u884c\u4e3a\u5956\u52b1\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5956\u52b1\u673a\uff08RMs\uff09\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u80fd\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u4f46\u5176\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u4ec5\u652f\u6301\u6b63\u5219\u8bed\u8a00\u3002\u4e3a\u4e86\u652f\u6301\u66f4\u590d\u6742\u7684\u884c\u4e3a\uff08\u5982\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\uff09\uff0c\u9700\u8981\u6269\u5c55RMs\u3002", "method": "\u63d0\u51fa\u4e86\u63a8\u4e0b\u5956\u52b1\u673a\uff08pdRMs\uff09\uff0c\u57fa\u4e8e\u786e\u5b9a\u6027\u4e0b\u63a8\u81ea\u52a8\u673a\uff0c\u652f\u6301\u66f4\u590d\u6742\u7684\u884c\u4e3a\u5956\u52b1\u3002\u8bbe\u8ba1\u4e86\u4e24\u79cd\u7b56\u7565\uff1a\u4e00\u79cd\u53ef\u8bbf\u95ee\u6574\u4e2a\u5806\u6808\uff0c\u53e6\u4e00\u79cd\u4ec5\u8bbf\u95ee\u5806\u6808\u9876\u90e8k\u4e2a\u7b26\u53f7\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86pdRMs\u7684\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\uff0c\u5e76\u63d0\u4f9b\u4e86\u7a7a\u95f4\u590d\u6742\u5ea6\u5206\u6790\u3002\u5b9e\u9a8c\u8868\u660e\uff0cpdRMs\u80fd\u6709\u6548\u8bad\u7ec3\u4ee3\u7406\u5b8c\u6210\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u4efb\u52a1\u3002", "conclusion": "pdRMs\u6269\u5c55\u4e86RMs\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u652f\u6301\u66f4\u590d\u6742\u7684\u884c\u4e3a\u5956\u52b1\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.06899", "categories": ["cs.AI", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.06899", "abs": "https://arxiv.org/abs/2508.06899", "authors": ["Yanchen Deng", "Xinrun Wang", "Bo An"], "title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization", "comment": null, "summary": "Local search is an important class of incomplete algorithms for solving\nDistributed Constraint Optimization Problems (DCOPs) but it often converges to\npoor local optima. While GDBA provides a comprehensive rule set to escape\npremature convergence, its empirical benefits remain marginal on general-valued\nproblems. In this work, we systematically examine GDBA and identify three\nfactors that potentially lead to its inferior performance, i.e.,\nover-aggressive constraint violation conditions, unbounded penalty\naccumulation, and uncoordinated penalty updates. To address these issues, we\npropose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs\nthat incorporates an adaptive violation condition to selectively penalize\nconstraints with high cost, a penalty evaporation mechanism to control the\nmagnitude of penalization, and a synchronization scheme for coordinated penalty\nupdates. We theoretically show that the penalty values are bounded, and agents\nplay a potential game in our DGLS. Our extensive empirical results on various\nstandard benchmarks demonstrate the great superiority of DGLS over\nstate-of-the-art baselines. Particularly, compared to Damped Max-sum with high\ndamping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance\non general-valued problems, and outperforms it by significant margins\n(\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDGLS\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdbGDBA\u7684\u4e09\u4e2a\u95ee\u9898\u70b9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u7684\u6c42\u89e3\u6027\u80fd\u3002", "motivation": "GDBA\u5728\u89e3\u51b3\u5206\u5e03\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u65f6\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u4e14\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "\u63d0\u51faDGLS\u6846\u67b6\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u7ea6\u675f\u8fdd\u53cd\u6761\u4ef6\u3001\u60e9\u7f5a\u84b8\u53d1\u673a\u5236\u548c\u540c\u6b65\u60e9\u7f5a\u66f4\u65b0\u65b9\u6848\u3002", "result": "DGLS\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u7ed3\u6784\u5316\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DGLS\u901a\u8fc7\u6539\u8fdbGDBA\u7684\u7f3a\u9677\uff0c\u6210\u4e3a\u89e3\u51b3\u5206\u5e03\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.06931", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06931", "abs": "https://arxiv.org/abs/2508.06931", "authors": ["Wangyue Lu", "Lun Du", "Sirui Li", "Ke Weng", "Haozhe Sun", "Hengyu Liu", "Minghe Yu", "Tiancheng Zhang", "Ge Yu"], "title": "Automated Formalization via Conceptual Retrieval-Augmented LLMs", "comment": null, "summary": "Interactive theorem provers (ITPs) require manual formalization, which is\nlabor-intensive and demands expert knowledge. While automated formalization\noffers a potential solution, it faces two major challenges: model hallucination\n(e.g., undefined predicates, symbol misuse, and version incompatibility) and\nthe semantic gap caused by ambiguous or missing premises in natural language\ndescriptions. To address these issues, we propose CRAMF, a Concept-driven\nRetrieval-Augmented Mathematical Formalization framework. CRAMF enhances\nLLM-based autoformalization by retrieving formal definitions of core\nmathematical concepts, providing contextual grounding during code generation.\nHowever, applying retrieval-augmented generation (RAG) in this setting is\nnon-trivial due to the lack of structured knowledge bases, the polymorphic\nnature of mathematical concepts, and the high precision required in formal\nretrieval. We introduce a framework for automatically constructing a\nconcept-definition knowledge base from Mathlib4, the standard mathematical\nlibrary for the Lean 4 theorem prover, indexing over 26,000 formal definitions\nand 1,000+ core mathematical concepts. To address conceptual polymorphism, we\npropose contextual query augmentation with domain- and application-level\nsignals. In addition, we design a dual-channel hybrid retrieval strategy with\nreranking to ensure accurate and relevant definition retrieval. Experiments on\nminiF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that\nCRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding\nconsistent improvements in translation accuracy, achieving up to 62.1% and an\naverage of 29.9% relative improvement.", "AI": {"tldr": "CRAMF\u662f\u4e00\u4e2a\u57fa\u4e8e\u6982\u5ff5\u9a71\u52a8\u7684\u68c0\u7d22\u589e\u5f3a\u6570\u5b66\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u6838\u5fc3\u6570\u5b66\u6982\u5ff5\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u63d0\u5347\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u6a21\u578b\u5e7b\u89c9\u548c\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\u3002", "motivation": "\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u5668\uff08ITP\uff09\u9700\u8981\u624b\u52a8\u5f62\u5f0f\u5316\uff0c\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u3002\u81ea\u52a8\u5f62\u5f0f\u5316\u9762\u4e34\u6a21\u578b\u5e7b\u89c9\u548c\u8bed\u4e49\u9e3f\u6c9f\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faCRAMF\u6846\u67b6\uff0c\u4eceMathlib4\u6784\u5efa\u6982\u5ff5\u5b9a\u4e49\u77e5\u8bc6\u5e93\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u67e5\u8be2\u589e\u5f3a\u548c\u53cc\u901a\u9053\u6df7\u5408\u68c0\u7d22\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRAMF\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u51c6\u786e\u6027\uff0c\u6700\u9ad8\u76f8\u5bf9\u63d0\u5347\u8fbe62.1%\uff0c\u5e73\u5747\u63d0\u534729.9%\u3002", "conclusion": "CRAMF\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u5f62\u5f0f\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06939", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06939", "abs": "https://arxiv.org/abs/2508.06939", "authors": ["Hiba Najjar", "Deepak Pathak", "Marlon Nuske", "Andreas Dengel"], "title": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction", "comment": null, "summary": "Multimodal learning enables various machine learning tasks to benefit from\ndiverse data sources, effectively mimicking the interplay of different factors\nin real-world applications, particularly in agriculture. While the\nheterogeneous nature of involved data modalities may necessitate the design of\ncomplex architectures, the model interpretability is often overlooked. In this\nstudy, we leverage the intrinsic explainability of Transformer-based models to\nexplain multimodal learning networks, focusing on the task of crop yield\nprediction at the subfield level. The large datasets used cover various crops,\nregions, and years, and include four different input modalities: multispectral\nsatellite and weather time series, terrain elevation maps and soil properties.\nBased on the self-attention mechanism, we estimate feature attributions using\ntwo methods, namely the Attention Rollout (AR) and Generic Attention (GA), and\nevaluate their performance against Shapley-based model-agnostic estimations,\nShapley Value Sampling (SVS). Additionally, we propose the Weighted Modality\nActivation (WMA) method to assess modality attributions and compare it with SVS\nattributions. Our findings indicate that Transformer-based models outperform\nother architectures, specifically convolutional and recurrent networks,\nachieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field\nlevels, respectively. AR is shown to provide more robust and reliable temporal\nattributions, as confirmed through qualitative and quantitative evaluation,\ncompared to GA and SVS values. Information about crop phenology stages was\nleveraged to interpret the explanation results in the light of established\nagronomic knowledge. Furthermore, modality attributions revealed varying\npatterns across the two methods compared.[...]", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u57fa\u4e8eTransformer\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u89e3\u91ca\u6a21\u578b\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u8bc4\u4f30\u7279\u5f81\u548c\u6a21\u6001\u8d21\u732e\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u5728\u519c\u4e1a\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5e38\u88ab\u5ffd\u89c6\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528Transformer\u7684\u56fa\u6709\u53ef\u89e3\u91ca\u6027\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u56db\u79cd\u8f93\u5165\u6a21\u6001\u6570\u636e\uff0c\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u63d0\u51faAttention Rollout\u548cGeneric Attention\u65b9\u6cd5\uff0c\u5e76\u4e0eShapley Value Sampling\u5bf9\u6bd4\u3002", "result": "Transformer\u6a21\u578b\u4f18\u4e8e\u5377\u79ef\u548c\u5faa\u73af\u7f51\u7edc\uff0cR2\u5206\u6570\u66f4\u9ad8\uff1bAttention Rollout\u5728\u65f6\u95f4\u5c5e\u6027\u89e3\u91ca\u4e0a\u66f4\u53ef\u9760\u3002", "conclusion": "\u7814\u7a76\u9a8c\u8bc1\u4e86Transformer\u6a21\u578b\u5728\u519c\u4e1a\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u3002"}}
{"id": "2508.06950", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06950", "abs": "https://arxiv.org/abs/2508.06950", "authors": ["Sarah Schr\u00f6der", "Thekla Morgenroth", "Ulrike Kuhl", "Valerie Vaquet", "Benjamin Paa\u00dfen"], "title": "Large Language Models Do Not Simulate Human Psychology", "comment": null, "summary": "Large Language Models (LLMs),such as ChatGPT, are increasingly used in\nresearch, ranging from simple writing assistance to complex data annotation\ntasks. Recently, some research has suggested that LLMs may even be able to\nsimulate human psychology and can, hence, replace human participants in\npsychological studies. We caution against this approach. We provide conceptual\narguments against the hypothesis that LLMs simulate human psychology. We then\npresent empiric evidence illustrating our arguments by demonstrating that\nslight changes to wording that correspond to large changes in meaning lead to\nnotable discrepancies between LLMs' and human responses, even for the recent\nCENTAUR model that was specifically fine-tuned on psychological responses.\nAdditionally, different LLMs show very different responses to novel items,\nfurther illustrating their lack of reliability. We conclude that LLMs do not\nsimulate human psychology and recommend that psychological researchers should\ntreat LLMs as useful but fundamentally unreliable tools that need to be\nvalidated against human responses for every new application.", "AI": {"tldr": "\u8bba\u6587\u8b66\u544a\u4e0d\u8981\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u66ff\u4ee3\u4eba\u7c7b\u53c2\u4e0e\u8005\u8fdb\u884c\u5fc3\u7406\u5b66\u7814\u7a76\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc1\u636e\u8868\u660eLLM\u65e0\u6cd5\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u3002", "motivation": "\u63a2\u8ba8LLM\uff08\u5982ChatGPT\uff09\u662f\u5426\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u5b66\u5e76\u66ff\u4ee3\u4eba\u7c7b\u53c2\u4e0e\u8005\uff0c\u4ee5\u907f\u514d\u6f5c\u5728\u7684\u7814\u7a76\u8bef\u5bfc\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u8bba\u8bc1\u548c\u5b9e\u8bc1\u5206\u6790\uff08\u5982\u8c03\u6574\u63aa\u8f9e\u5bfc\u81f4LLM\u4e0e\u4eba\u7c7b\u53cd\u5e94\u5dee\u5f02\uff09\u6765\u9a8c\u8bc1LLM\u7684\u4e0d\u53ef\u9760\u6027\u3002", "result": "LLM\uff08\u5305\u62ec\u4e13\u4e3a\u5fc3\u7406\u5b66\u8c03\u4f18\u7684CENTAUR\u6a21\u578b\uff09\u5728\u7ec6\u5fae\u63aa\u8f9e\u53d8\u5316\u6216\u65b0\u9879\u76ee\u4e0a\u8868\u73b0\u4e0d\u4e00\u81f4\uff0c\u65e0\u6cd5\u53ef\u9760\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u3002", "conclusion": "LLM\u4e0d\u80fd\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\uff0c\u5fc3\u7406\u5b66\u7814\u7a76\u5e94\u5c06\u5176\u89c6\u4e3a\u9700\u4e0e\u4eba\u7c7b\u53cd\u5e94\u9a8c\u8bc1\u7684\u5de5\u5177\u3002"}}
{"id": "2508.06960", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06960", "abs": "https://arxiv.org/abs/2508.06960", "authors": ["Keyu Li", "Mohan Jiang", "Dayuan Fu", "Yunze Wu", "Xiangkun Hu", "Dequan Wang", "Pengfei Liu"], "title": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery", "comment": null, "summary": "The rapid advancement of large language models has fundamentally shifted the\nbottleneck in AI development from computational power to data availability-with\ncountless valuable datasets remaining hidden across specialized repositories,\nresearch appendices, and domain platforms. As reasoning capabilities and deep\nresearch methodologies continue to evolve, a critical question emerges: can AI\nagents transcend conventional search to systematically discover any dataset\nthat meets specific user requirements, enabling truly autonomous demand-driven\ndata curation? We introduce DatasetResearch, the first comprehensive benchmark\nevaluating AI agents' ability to discover and synthesize datasets from 208\nreal-world demands across knowledge-intensive and reasoning-intensive tasks.\nOur tri-dimensional evaluation framework reveals a stark reality: even advanced\ndeep research systems achieve only 22% score on our challenging\nDatasetResearch-pro subset, exposing the vast gap between current capabilities\nand perfect dataset discovery. Our analysis uncovers a fundamental\ndichotomy-search agents excel at knowledge tasks through retrieval breadth,\nwhile synthesis agents dominate reasoning challenges via structured\ngeneration-yet both catastrophically fail on \"corner cases\" outside existing\ndistributions. These findings establish the first rigorous baseline for dataset\ndiscovery agents and illuminate the path toward AI systems capable of finding\nany dataset in the digital universe. Our benchmark and comprehensive analysis\nprovide the foundation for the next generation of self-improving AI systems and\nare publicly available at https://github.com/GAIR-NLP/DatasetResearch.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DatasetResearch\u57fa\u51c6\uff0c\u8bc4\u4f30AI\u4ee3\u7406\u5728\u53d1\u73b0\u548c\u5408\u6210\u6570\u636e\u96c6\u65b9\u9762\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u4e0e\u5b8c\u7f8e\u6570\u636e\u96c6\u53d1\u73b0\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6570\u636e\u53ef\u7528\u6027\u6210\u4e3aAI\u5f00\u53d1\u7684\u74f6\u9888\uff0c\u8bb8\u591a\u6709\u4ef7\u503c\u7684\u6570\u636e\u96c6\u5206\u6563\u5728\u5404\u5904\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22AI\u4ee3\u7406\u662f\u5426\u80fd\u8d85\u8d8a\u4f20\u7edf\u641c\u7d22\uff0c\u81ea\u4e3b\u53d1\u73b0\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u7684\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165\u4e86DatasetResearch\u57fa\u51c6\uff0c\u5305\u542b208\u4e2a\u771f\u5b9e\u9700\u6c42\uff0c\u901a\u8fc7\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\u6d4b\u8bd5AI\u4ee3\u7406\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u548c\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u5728\u6311\u6218\u6027\u5b50\u96c6DatasetResearch-pro\u4e0a\u4ec5\u5f9722\u5206\uff0c\u66b4\u9732\u4e86\u5f53\u524d\u80fd\u529b\u7684\u4e0d\u8db3\u3002\u641c\u7d22\u4ee3\u7406\u5728\u77e5\u8bc6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u5408\u6210\u4ee3\u7406\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5360\u4f18\uff0c\u4f46\u4e24\u8005\u5728\u201c\u6781\u7aef\u6848\u4f8b\u201d\u4e2d\u5747\u5931\u8d25\u3002", "conclusion": "\u8bba\u6587\u4e3a\u6570\u636e\u96c6\u53d1\u73b0\u4ee3\u7406\u5efa\u7acb\u4e86\u9996\u4e2a\u4e25\u683c\u57fa\u51c6\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u516c\u5f00\u4e86\u57fa\u51c6\u548c\u5206\u6790\u3002"}}
{"id": "2508.06963", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06963", "abs": "https://arxiv.org/abs/2508.06963", "authors": ["Changqing Li", "Tianlin Li", "Xiaohan Zhang", "Aishan Liu", "Li Pan"], "title": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair", "comment": null, "summary": "Large Language Models (LLMs) face persistent and evolving trustworthiness\nissues, motivating developers to seek automated and flexible repair methods\nthat enable convenient deployment across diverse scenarios. Existing repair\nmethods like supervised fine-tuning (SFT) and reinforcement learning with human\nfeedback (RLHF) are costly and slow, while prompt engineering lacks robustness\nand scalability. Representation engineering, which steers model behavior by\ninjecting targeted concept vectors during inference, offers a lightweight,\ntraining-free alternative. However, current approaches depend on manually\ncrafted samples and fixed steering strategies, limiting automation and\nadaptability. To overcome these challenges, we propose MASteer, the first\nend-to-end framework for trustworthiness repair in LLMs based on representation\nengineering. MASteer integrates two core components: AutoTester, a multi-agent\nsystem that generates diverse, high-quality steer samples tailored to developer\nneeds; and AutoRepairer, which constructs adaptive steering strategies with\nanchor vectors for automated, context-aware strategy selection during\ninference. Experiments on standard and customized trustworthiness tasks show\nMASteer consistently outperforms baselines, improving metrics by 15.36% on\nLLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model\ncapabilities. MASteer demonstrates strong robustness, generalization, and\npractical value for scalable, efficient trustworthiness repair.", "AI": {"tldr": "MASteer\u662f\u4e00\u4e2a\u57fa\u4e8e\u8868\u793a\u5de5\u7a0b\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u4fee\u590d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53ef\u4fe1\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u6837\u672c\u548c\u81ea\u9002\u5e94\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4fee\u590d\u65b9\u6cd5\uff08\u5982SFT\u548cRLHF\uff09\u6210\u672c\u9ad8\u4e14\u901f\u5ea6\u6162\uff0c\u63d0\u793a\u5de5\u7a0b\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u8868\u793a\u5de5\u7a0b\u867d\u8f7b\u91cf\u4f46\u4f9d\u8d56\u4eba\u5de5\u6837\u672c\u548c\u56fa\u5b9a\u7b56\u7565\u3002", "method": "MASteer\u7ed3\u5408AutoTester\uff08\u591a\u667a\u80fd\u4f53\u751f\u6210\u6837\u672c\uff09\u548cAutoRepairer\uff08\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\uff09\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u4fee\u590d\u3002", "result": "\u5728LLaMA-3.1-8B-Chat\u548cQwen-3-8B-Chat\u4e0a\u5206\u522b\u63d0\u534715.36%\u548c4.21%\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u901a\u7528\u80fd\u529b\u3002", "conclusion": "MASteer\u5c55\u793a\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u53ef\u4fe1\u6027\u4fee\u590d\u80fd\u529b\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.06972", "categories": ["cs.AI", "cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06972", "abs": "https://arxiv.org/abs/2508.06972", "authors": ["Dan Ivanov", "Tristan Freiberg", "Haruna Isah"], "title": "DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning", "comment": "12 pages, 8 figures, and 10 tables", "summary": "DSperse is a modular framework for distributed machine learning inference\nwith strategic cryptographic verification. Operating within the emerging\nparadigm of distributed zero-knowledge machine learning, DSperse avoids the\nhigh cost and rigidity of full-model circuitization by enabling targeted\nverification of strategically chosen subcomputations. These verifiable\nsegments, or \"slices\", may cover part or all of the inference pipeline, with\nglobal consistency enforced through audit, replication, or economic incentives.\nThis architecture supports a pragmatic form of trust minimization, localizing\nzero-knowledge proofs to the components where they provide the greatest value.\nWe evaluate DSperse using multiple proving systems and report empirical results\non memory usage, runtime, and circuit behavior under sliced and unsliced\nconfigurations. By allowing proof boundaries to align flexibly with the model's\nlogical structure, DSperse supports scalable, targeted verification strategies\nsuited to diverse deployment needs.", "AI": {"tldr": "DSperse\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u63a8\u7406\uff0c\u901a\u8fc7\u6218\u7565\u6027\u7684\u52a0\u5bc6\u9a8c\u8bc1\u5b9e\u73b0\u9ad8\u6548\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u96f6\u77e5\u8bc6\u673a\u5668\u5b66\u4e60\u7684\u80cc\u666f\u4e0b\uff0c\u907f\u514d\u5168\u6a21\u578b\u7535\u8def\u5316\u7684\u9ad8\u6210\u672c\u548c\u50f5\u5316\uff0c\u63d0\u4f9b\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u9a8c\u8bc1\u9009\u5b9a\u7684\u5b50\u8ba1\u7b97\uff08\u201c\u5207\u7247\u201d\uff09\uff0c\u652f\u6301\u90e8\u5206\u6216\u5168\u90e8\u63a8\u7406\u7ba1\u9053\u7684\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u5ba1\u8ba1\u3001\u590d\u5236\u6216\u7ecf\u6d4e\u6fc0\u52b1\u786e\u4fdd\u5168\u5c40\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u79cd\u8bc1\u660e\u7cfb\u7edf\u4e0b\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5185\u5b58\u4f7f\u7528\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u7535\u8def\u884c\u4e3a\u5728\u5207\u7247\u4e0e\u975e\u5207\u7247\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "DSperse\u901a\u8fc7\u7075\u6d3b\u7684\u9a8c\u8bc1\u8fb9\u754c\u652f\u6301\u53ef\u6269\u5c55\u7684\u3001\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\uff0c\u9002\u5e94\u591a\u6837\u5316\u7684\u90e8\u7f72\u9700\u6c42\u3002"}}
{"id": "2508.06980", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06980", "abs": "https://arxiv.org/abs/2508.06980", "authors": ["Aswin Paul", "Moein Khajehnejad", "Forough Habibollahi", "Brett J. Kagan", "Adeel Razi"], "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model", "comment": "18 pages, 8 figures", "summary": "With recent and rapid advancements in artificial intelligence (AI),\nunderstanding the foundation of purposeful behaviour in autonomous agents is\ncrucial for developing safe and efficient systems. While artificial neural\nnetworks have dominated the path to AI, recent studies are exploring the\npotential of biologically based systems, such as networks of living biological\nneuronal networks. Along with promises of high power and data efficiency, these\nsystems may also inform more explainable and biologically plausible models. In\nthis work, we propose a framework rooted in active inference, a general theory\nof behaviour, to model decision-making in embodied agents. Using\nexperiment-informed generative models, we simulate decision-making processes in\na simulated game-play environment, mirroring experimental setups that use\nbiological neurons. Our results demonstrate learning in these agents, providing\ninsights into the role of memory-based learning and predictive planning in\nintelligent decision-making. This work contributes to the growing field of\nexplainable AI by offering a biologically grounded and scalable approach to\nunderstanding purposeful behaviour in agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u751f\u7269\u795e\u7ecf\u5143\u7f51\u7edc\u4e2d\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4e3a\u53ef\u89e3\u91caAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u751f\u7269\u5b66\u57fa\u7840\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7406\u89e3\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u76ee\u7684\u6027\u884c\u4e3a\u57fa\u7840\u5bf9\u5f00\u53d1\u5b89\u5168\u9ad8\u6548\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u751f\u7269\u795e\u7ecf\u5143\u7f51\u7edc\u53ef\u80fd\u63d0\u4f9b\u66f4\u9ad8\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5b9e\u9a8c\u7684\u751f\u6210\u6a21\u578b\uff0c\u5728\u6a21\u62df\u6e38\u620f\u73af\u5883\u4e2d\u6a21\u62df\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ed3\u5408\u4e3b\u52a8\u63a8\u7406\u7406\u8bba\u3002", "result": "\u7ed3\u679c\u8868\u660e\u4ee3\u7406\u80fd\u591f\u5b66\u4e60\uff0c\u63ed\u793a\u4e86\u8bb0\u5fc6\u5b66\u4e60\u548c\u9884\u6d4b\u89c4\u5212\u5728\u667a\u80fd\u51b3\u7b56\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u53ef\u89e3\u91caAI\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u751f\u7269\u5b66\u57fa\u7840\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u667a\u80fd\u4f53\u7684\u76ee\u7684\u6027\u884c\u4e3a\u3002"}}
{"id": "2508.07015", "categories": ["cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.07015", "abs": "https://arxiv.org/abs/2508.07015", "authors": ["Hannes Ihalainen", "Dieter Vandesande", "Andr\u00e9 Schidler", "Jeremias Berg", "Bart Bogaerts", "Matti J\u00e4rvisalo"], "title": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach", "comment": null, "summary": "The implicit hitting set (IHS) approach offers a general framework for\nsolving computationally hard combinatorial optimization problems declaratively.\nIHS iterates between a decision oracle used for extracting sources of\ninconsistency and an optimizer for computing so-called hitting sets (HSs) over\nthe accumulated sources of inconsistency. While the decision oracle is\nlanguage-specific, the optimizers is usually instantiated through integer\nprogramming.\n  We explore alternative algorithmic techniques for hitting set optimization\nbased on different ways of employing pseudo-Boolean (PB) reasoning as well as\nstochastic local search. We extensively evaluate the practical feasibility of\nthe alternatives in particular in the context of pseudo-Boolean (0-1 IP)\noptimization as one of the most recent instantiations of IHS. Highlighting a\ntrade-off between efficiency and reliability, while a commercial IP solver\nturns out to remain the most effective way to instantiate HS computations, it\ncan cause correctness issues due to numerical instability; in fact, we show\nthat exact HS computations instantiated via PB reasoning can be made\ncompetitive with a numerically exact IP solver. Furthermore, the use of PB\nreasoning as a basis for HS computations allows for obtaining certificates for\nthe correctness of IHS computations, generally applicable to any IHS\ninstantiation in which reasoning in the declarative language at hand can be\ncaptured in the PB-based proof format we employ.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9690\u5f0f\u547d\u4e2d\u96c6\uff08IHS\uff09\u6846\u67b6\u4e2d\u66ff\u4ee3\u4f18\u5316\u6280\u672f\u7684\u53ef\u884c\u6027\uff0c\u6bd4\u8f83\u4e86\u4f2a\u5e03\u5c14\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\uff0c\u53d1\u73b0\u5546\u4e1a\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668\u6548\u7387\u9ad8\u4f46\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u4f2a\u5e03\u5c14\u63a8\u7406\u7684\u7cbe\u786e\u8ba1\u7b97\u5728\u53ef\u9760\u6027\u4e0a\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u9690\u5f0f\u547d\u4e2d\u96c6\uff08IHS\uff09\u6846\u67b6\u4e2d\u66ff\u4ee3\u4f18\u5316\u6280\u672f\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u6574\u6570\u89c4\u5212\uff09\u5728\u6548\u7387\u548c\u53ef\u9760\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4f2a\u5e03\u5c14\uff08PB\uff09\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\u4f5c\u4e3a\u66ff\u4ee3\u4f18\u5316\u6280\u672f\uff0c\u5e76\u4e0e\u5546\u4e1a\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5546\u4e1a\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668\u6548\u7387\u6700\u9ad8\u4f46\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\uff1b\u57fa\u4e8e\u4f2a\u5e03\u5c14\u63a8\u7406\u7684\u7cbe\u786e\u8ba1\u7b97\u5728\u53ef\u9760\u6027\u4e0a\u66f4\u4f18\uff0c\u5e76\u80fd\u63d0\u4f9b\u6b63\u786e\u6027\u8bc1\u660e\u3002", "conclusion": "\u4f2a\u5e03\u5c14\u63a8\u7406\u5728\u9690\u5f0f\u547d\u4e2d\u96c6\u8ba1\u7b97\u4e2d\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u5728\u9700\u8981\u53ef\u9760\u6027\u548c\u6b63\u786e\u6027\u8bc1\u660e\u7684\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.07022", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.07022", "abs": "https://arxiv.org/abs/2508.07022", "authors": ["Shengtao Wen", "Haodong Chen", "Yadong Wang", "Zhongying Pan", "Xiang Chen", "Yu Tian", "Bo Qian", "Dong Liang", "Sheng-Jun Huang"], "title": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA", "comment": "Under Review", "summary": "Knowledge editing (KE) provides a scalable approach for updating factual\nknowledge in large language models without full retraining. While previous\nstudies have demonstrated effectiveness in general domains and medical QA\ntasks, little attention has been paid to KE in multimodal medical scenarios.\nUnlike text-only settings, medical KE demands integrating updated knowledge\nwith visual reasoning to support safe and interpretable clinical decisions. To\naddress this gap, we propose MultiMedEdit, the first benchmark tailored to\nevaluating KE in clinical multimodal tasks. Our framework spans both\nunderstanding and reasoning task types, defines a three-dimensional metric\nsuite (reliability, generality, and locality), and supports cross-paradigm\ncomparisons across general and domain-specific models. We conduct extensive\nexperiments under single-editing and lifelong-editing settings. Results suggest\nthat current methods struggle with generalization and long-tail reasoning,\nparticularly in complex clinical workflows. We further present an efficiency\nanalysis (e.g., edit latency, memory footprint), revealing practical trade-offs\nin real-world deployment across KE paradigms. Overall, MultiMedEdit not only\nreveals the limitations of current approaches but also provides a solid\nfoundation for developing clinically robust knowledge editing techniques in the\nfuture.", "AI": {"tldr": "MultiMedEdit\u662f\u9996\u4e2a\u9488\u5bf9\u4e34\u5e8a\u591a\u6a21\u6001\u4efb\u52a1\u7684\u77e5\u8bc6\u7f16\u8f91\uff08KE\uff09\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u5728\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u5f00\u53d1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u901a\u7528\u9886\u57df\u548c\u533b\u5b66QA\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u591a\u6a21\u6001\u533b\u5b66\u573a\u666f\u7684\u9700\u6c42\uff0c\u800c\u533b\u5b66KE\u9700\u8981\u7ed3\u5408\u89c6\u89c9\u63a8\u7406\u4ee5\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u63d0\u51faMultiMedEdit\u57fa\u51c6\uff0c\u6db5\u76d6\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52a1\u7c7b\u578b\uff0c\u5b9a\u4e49\u4e09\u7ef4\u5ea6\u91cf\u6807\u51c6\uff08\u53ef\u9760\u6027\u3001\u901a\u7528\u6027\u548c\u5c40\u90e8\u6027\uff09\uff0c\u652f\u6301\u8de8\u8303\u5f0f\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u65b9\u6cd5\u5728\u6cdb\u5316\u548c\u957f\u5c3e\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u5728\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\u3002\u6548\u7387\u5206\u6790\u63ed\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6743\u8861\u3002", "conclusion": "MultiMedEdit\u4e0d\u4ec5\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u8fd8\u4e3a\u672a\u6765\u5f00\u53d1\u4e34\u5e8a\u7a33\u5065\u7684KE\u6280\u672f\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.07043", "categories": ["cs.AI", "cs.MA", "q-bio.GN", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.07043", "abs": "https://arxiv.org/abs/2508.07043", "authors": ["Orion Li", "Vinayak Agarwal", "Summer Zhou", "Ashwin Gopinath", "Timothy Kassis"], "title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis", "comment": null, "summary": "The complexity of modern bioinformatics analysis has created a critical gap\nbetween data generation and developing scientific insights. While large\nlanguage models (LLMs) have shown promise in scientific reasoning, they remain\nfundamentally limited when dealing with real-world analytical workflows that\ndemand iterative computation, tool integration and rigorous validation. We\nintroduce K-Dense Analyst, a hierarchical multi-agent system that achieves\nautonomous bioinformatics analysis through a dual-loop architecture. K-Dense\nAnalyst, part of the broader K-Dense platform, couples planning with validated\nexecution using specialized agents to decompose complex objectives into\nexecutable, verifiable tasks within secure computational environments. On\nBixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense\nAnalyst achieves 29.2% accuracy, surpassing the best-performing language model\n(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what\nis widely considered the most powerful LLM available. Remarkably, K-Dense\nAnalyst achieves this performance using Gemini 2.5 Pro, which attains only\n18.3% accuracy when used directly, demonstrating that our architectural\ninnovations unlock capabilities far beyond the underlying model's baseline\nperformance. Our insights demonstrate that autonomous scientific reasoning\nrequires more than enhanced language models, it demands purpose-built systems\nthat can bridge the gap between high-level scientific objectives and low-level\ncomputational execution. These results represent a significant advance toward\nfully autonomous computational biologists capable of accelerating discovery\nacross the life sciences.", "AI": {"tldr": "K-Dense Analyst\u662f\u4e00\u4e2a\u5206\u5c42\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u5faa\u73af\u67b6\u6784\u5b9e\u73b0\u81ea\u4e3b\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\uff0c\u6027\u80fd\u4f18\u4e8eGPT-5\u3002", "motivation": "\u73b0\u4ee3\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\u7684\u590d\u6742\u6027\u5bfc\u81f4\u6570\u636e\u751f\u6210\u4e0e\u79d1\u5b66\u6d1e\u5bdf\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\uff0c\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u5206\u6790\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7ed3\u5408\u89c4\u5212\u4e0e\u9a8c\u8bc1\u6267\u884c\uff0c\u5c06\u590d\u6742\u76ee\u6807\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u4efb\u52a1\u3002", "result": "\u5728BixBench\u4e0a\u8fbe\u523029.2%\u51c6\u786e\u7387\uff0c\u6bd4GPT-5\u9ad86.3\u4e2a\u767e\u5206\u70b9\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u81ea\u4e3b\u79d1\u5b66\u63a8\u7406\u9700\u8981\u4e13\u95e8\u6784\u5efa\u7684\u7cfb\u7edf\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u589e\u5f3a\u7684\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2508.07063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07063", "abs": "https://arxiv.org/abs/2508.07063", "authors": ["Naseem Machlovi", "Maryam Saleki", "Innocent Ababio", "Ruhul Amin"], "title": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach", "comment": null, "summary": "As AI systems become more integrated into daily life, the need for safer and\nmore reliable moderation has never been greater. Large Language Models (LLMs)\nhave demonstrated remarkable capabilities, surpassing earlier models in\ncomplexity and performance. Their evaluation across diverse tasks has\nconsistently showcased their potential, enabling the development of adaptive\nand personalized agents. However, despite these advancements, LLMs remain prone\nto errors, particularly in areas requiring nuanced moral reasoning. They\nstruggle with detecting implicit hate, offensive language, and gender biases\ndue to the subjective and context-dependent nature of these issues. Moreover,\ntheir reliance on training data can inadvertently reinforce societal biases,\nleading to inconsistencies and ethical concerns in their outputs. To explore\nthe limitations of LLMs in this role, we developed an experimental framework\nbased on state-of-the-art (SOTA) models to assess human emotions and offensive\nbehaviors. The framework introduces a unified benchmark dataset encompassing 49\ndistinct categories spanning the wide spectrum of human emotions, offensive and\nhateful text, and gender and racial biases. Furthermore, we introduced SafePhi,\na QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and\noutperforming benchmark moderators by achieving a Macro F1 score of 0.89, where\nOpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This\nresearch also highlights the critical domains where LLM moderators consistently\nunderperformed, pressing the need to incorporate more heterogeneous and\nrepresentative data with human-in-the-loop, for better model robustness and\nexplainability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u9a8c\u6846\u67b6\u548c\u4f18\u5316\u6a21\u578bSafePhi\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u751f\u6d3b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5b89\u5168\u53ef\u9760\u7684\u5185\u5bb9\u5ba1\u6838\u9700\u6c42\u589e\u52a0\uff0c\u4f46LLMs\u5728\u9053\u5fb7\u63a8\u7406\u548c\u504f\u89c1\u5904\u7406\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eSOTA\u6a21\u578b\u7684\u5b9e\u9a8c\u6846\u67b6\uff0c\u5f15\u5165\u7edf\u4e00\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u5316\u6a21\u578bSafePhi\u3002", "result": "SafePhi\u5728Macro F1\u5f97\u5206\u4e0a\u8fbe\u52300.89\uff0c\u4f18\u4e8eOpenAI Moderator\u548cLlama Guard\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86LLMs\u5728\u5173\u952e\u9886\u57df\u7684\u4e0d\u8db3\uff0c\u9700\u7ed3\u5408\u66f4\u591a\u5f02\u6784\u6570\u636e\u548c\u4eba\u7c7b\u53c2\u4e0e\u4ee5\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.07107", "categories": ["cs.AI", "cs.CY", "K.3.1; I.2.6; H.4"], "pdf": "https://arxiv.org/pdf/2508.07107", "abs": "https://arxiv.org/abs/2508.07107", "authors": ["Timothy Oluwapelumi Adeyemi", "Nadiah Fahad AlOtaibi"], "title": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention", "comment": "10 pages, 1 figure, 3 tables", "summary": "Accurate prediction of student performance is essential for timely academic\nintervention. However, most machine learning models in education are static and\ncannot adapt when new data, such as post-intervention outcomes, become\navailable. To address this limitation, we propose a Feedback-Driven Decision\nSupport System (DSS) with a closed-loop architecture that enables continuous\nmodel refinement. The system integrates a LightGBM-based regressor with\nincremental retraining, allowing educators to input updated student results,\nwhich automatically trigger model updates. This adaptive mechanism improves\nprediction accuracy by learning from real-world academic progress. The platform\nfeatures a Flask-based web interface for real-time interaction and incorporates\nSHAP for explainability, ensuring transparency. Experimental results show a\n10.7\\% reduction in RMSE after retraining, with consistent upward adjustments\nin predicted scores for intervened students. By transforming static predictors\ninto self-improving systems, our approach advances educational analytics toward\nhuman-centered, data-driven, and responsive AI. The framework is designed for\nintegration into LMS and institutional dashboards.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cd\u9988\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff08DSS\uff09\uff0c\u901a\u8fc7\u95ed\u73af\u67b6\u6784\u548c\u589e\u91cf\u5f0f\u8bad\u7ec3\u63d0\u5347\u5b66\u751f\u6210\u7ee9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u591a\u4e3a\u9759\u6001\uff0c\u65e0\u6cd5\u9002\u5e94\u65b0\u6570\u636e\uff08\u5982\u5e72\u9884\u540e\u7ed3\u679c\uff09\uff0c\u9700\u52a8\u6001\u8c03\u6574\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u7ed3\u5408LightGBM\u56de\u5f52\u5668\u548c\u589e\u91cf\u5f0f\u8bad\u7ec3\uff0c\u652f\u6301\u5b9e\u65f6\u66f4\u65b0\u6a21\u578b\uff1b\u63d0\u4f9bFlask\u754c\u9762\u548cSHAP\u89e3\u91ca\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u663e\u793aRMSE\u964d\u4f4e10.7%\uff0c\u5e72\u9884\u5b66\u751f\u9884\u6d4b\u5206\u6570\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c06\u9759\u6001\u9884\u6d4b\u5668\u8f6c\u5316\u4e3a\u81ea\u4f18\u5316\u7cfb\u7edf\uff0c\u63a8\u52a8\u6559\u80b2\u5206\u6790\u5411\u4ee5\u4eba\u4e3a\u672c\u3001\u6570\u636e\u9a71\u52a8\u548c\u54cd\u5e94\u5f0fAI\u53d1\u5c55\u3002"}}
{"id": "2508.07186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.07186", "abs": "https://arxiv.org/abs/2508.07186", "authors": ["Amit Dhanda"], "title": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables", "comment": null, "summary": "We propose a novel framework for summarizing structured enterprise data\nacross multiple dimensions using large language model (LLM)-based agents.\nTraditional table-to-text models often lack the capacity to reason across\nhierarchical structures and context-aware deltas, which are essential in\nbusiness reporting tasks. Our method introduces a multi-agent pipeline that\nextracts, analyzes, and summarizes multi-dimensional data using agents for\nslicing, variance detection, context construction, and LLM-based generation.\nOur results show that the proposed framework outperforms traditional\napproaches, achieving 83\\% faithfulness to underlying data, superior coverage\nof significant changes, and high relevance scores (4.4/5) for decision-critical\ninsights. The improvements are especially pronounced in categories involving\nsubtle trade-offs, such as increased revenue due to price changes amid\ndeclining unit volumes, which competing methods either overlook or address with\nlimited specificity. We evaluate the framework on Kaggle datasets and\ndemonstrate significant improvements in faithfulness, relevance, and insight\nquality over baseline table summarization approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7ef4\u5ea6\u7ed3\u6784\u5316\u4f01\u4e1a\u6570\u636e\u6458\u8981\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8868\u683c\u5230\u6587\u672c\u6a21\u578b\u5728\u8de8\u5c42\u6b21\u7ed3\u6784\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5dee\u5f02\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5546\u4e1a\u62a5\u544a\u9700\u6c42\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u7ba1\u9053\uff0c\u5305\u62ec\u6570\u636e\u5207\u7247\u3001\u5dee\u5f02\u68c0\u6d4b\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u548c\u57fa\u4e8eLLM\u7684\u751f\u6210\u3002", "result": "\u6846\u67b6\u5728\u6570\u636e\u5fe0\u5b9e\u5ea6\uff0883%\uff09\u3001\u663e\u8457\u53d8\u5316\u8986\u76d6\u7387\u548c\u51b3\u7b56\u5173\u952e\u89c1\u89e3\u76f8\u5173\u6027\uff084.4/5\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u590d\u6742\u5546\u4e1a\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6458\u8981\u7684\u5fe0\u5b9e\u6027\u3001\u76f8\u5173\u6027\u548c\u89c1\u89e3\u8d28\u91cf\u3002"}}
{"id": "2508.07292", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.07292", "abs": "https://arxiv.org/abs/2508.07292", "authors": ["Yi Tang", "Kaini Wang", "Yang Chen", "Guangquan Zhou"], "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning", "comment": null, "summary": "Developing general artificial intelligence (AI) systems to support endoscopic\nimage diagnosis is an emerging research priority. Existing methods based on\nlarge-scale pretraining often lack unified coordination across tasks and\nstruggle to handle the multi-step processes required in complex clinical\nworkflows. While AI agents have shown promise in flexible instruction parsing\nand tool integration across domains, their potential in endoscopy remains\nunderexplored. To address this gap, we propose EndoAgent, the first\nmemory-guided agent for vision-to-decision endoscopic analysis that integrates\niterative reasoning with adaptive tool selection and collaboration. Built on a\ndual-memory design, it enables sophisticated decision-making by ensuring\nlogical coherence through short-term action tracking and progressively\nenhancing reasoning acuity through long-term experiential learning. To support\ndiverse clinical tasks, EndoAgent integrates a suite of expert-designed tools\nwithin a unified reasoning loop. We further introduce EndoAgentBench, a\nbenchmark of 5,709 visual question-answer pairs that assess visual\nunderstanding and language generation capabilities in realistic scenarios.\nExtensive experiments show that EndoAgent consistently outperforms both general\nand medical multimodal models, exhibiting its strong flexibility and reasoning\ncapabilities.", "AI": {"tldr": "EndoAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u53cc\u8bb0\u5fc6\u8bbe\u8ba1\u7684AI\u4ee3\u7406\uff0c\u7528\u4e8e\u5185\u7aa5\u955c\u56fe\u50cf\u8bca\u65ad\uff0c\u901a\u8fc7\u77ed\u671f\u884c\u52a8\u8ffd\u8e2a\u548c\u957f\u671f\u7ecf\u9a8c\u5b66\u4e60\u63d0\u5347\u51b3\u7b56\u80fd\u529b\uff0c\u4f18\u4e8e\u73b0\u6709\u901a\u7528\u548c\u533b\u5b66\u591a\u6a21\u6001\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\u7f3a\u4e4f\u4efb\u52a1\u95f4\u7684\u7edf\u4e00\u534f\u8c03\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\u7684\u591a\u6b65\u9aa4\u8fc7\u7a0b\uff0c\u800cAI\u4ee3\u7406\u5728\u5185\u7aa5\u955c\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faEndoAgent\uff0c\u7ed3\u5408\u8fed\u4ee3\u63a8\u7406\u4e0e\u81ea\u9002\u5e94\u5de5\u5177\u9009\u62e9\u548c\u534f\u4f5c\uff0c\u91c7\u7528\u53cc\u8bb0\u5fc6\u8bbe\u8ba1\uff08\u77ed\u671f\u884c\u52a8\u8ffd\u8e2a\u548c\u957f\u671f\u7ecf\u9a8c\u5b66\u4e60\uff09\uff0c\u5e76\u96c6\u6210\u4e13\u5bb6\u8bbe\u8ba1\u7684\u5de5\u5177\u3002", "result": "\u5728EndoAgentBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEndoAgent\u57285,709\u4e2a\u89c6\u89c9\u95ee\u7b54\u5bf9\u4e0a\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u548c\u533b\u5b66\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u7075\u6d3b\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "EndoAgent\u4e3a\u5185\u7aa5\u955c\u56fe\u50cf\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6548\u7684AI\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u590d\u6742\u4e34\u5e8a\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.07334", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07334", "abs": "https://arxiv.org/abs/2508.07334", "authors": ["Quan Shi", "Wang Xi", "Zenghui Ding", "Jianqing Gao", "Xianjun Yang"], "title": "Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape", "comment": "8 pages, 6 figures", "summary": "The illusion phenomenon of large language models (LLMs) is the core obstacle\nto their reliable deployment. This article formalizes the large language model\nas a probabilistic Turing machine by constructing a \"computational necessity\nhierarchy\", and for the first time proves the illusions are inevitable on\ndiagonalization, incomputability, and information theory boundaries supported\nby the new \"learner pump lemma\". However, we propose two \"escape routes\": one\nis to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving\ntheir absolute escape through \"computational jumps\", providing the first formal\ntheory for the effectiveness of RAGs; The second is to formalize continuous\nlearning as an \"internalized oracle\" mechanism and implement this path through\na novel neural game theory framework.Finally, this article proposes a", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u63d0\u51fa\u8ba1\u7b97\u5fc5\u8981\u6027\u5c42\u6b21\u7ed3\u6784\uff0c\u8bc1\u660e\u5e7b\u89c9\u4e0d\u53ef\u907f\u514d\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAGs\uff09\u548c\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3LLMs\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u3002", "method": "\u6784\u5efa\u8ba1\u7b97\u5fc5\u8981\u6027\u5c42\u6b21\u7ed3\u6784\uff0c\u8bc1\u660e\u5e7b\u89c9\u7684\u4e0d\u53ef\u907f\u514d\u6027\uff0c\u5e76\u63d0\u51faRAGs\u548c\u6301\u7eed\u5b66\u4e60\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8bc1\u660e\u4e86\u5e7b\u89c9\u7684\u4e0d\u53ef\u907f\u514d\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7RAGs\u548c\u6301\u7eed\u5b66\u4e60\uff0c\u53ef\u4ee5\u90e8\u5206\u89e3\u51b3LLMs\u7684\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2508.07353", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07353", "abs": "https://arxiv.org/abs/2508.07353", "authors": ["Rubing Chen", "Jiaxin Wu", "Jian Wang", "Xulu Zhang", "Wenqi Fan", "Chenghua Lin", "Xiao-Yong Wei", "Qing Li"], "title": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach", "comment": null, "summary": "Numerous benchmarks have been built to evaluate the domain-specific abilities\nof large language models (LLMs), highlighting the need for effective and\nefficient benchmark construction. Existing domain-specific benchmarks primarily\nfocus on the scaling law, relying on massive corpora for supervised fine-tuning\nor generating extensive question sets for broad coverage. However, the impact\nof corpus and question-answer (QA) set design on the precision and recall of\ndomain-specific LLMs remains unexplored. In this paper, we address this gap and\ndemonstrate that the scaling law is not always the optimal principle for\nbenchmark construction in specific domains. Instead, we propose Comp-Comp, an\niterative benchmarking framework based on a comprehensiveness-compactness\nprinciple. Here, comprehensiveness ensures semantic recall of the domain, while\ncompactness enhances precision, guiding both corpus and QA set construction. To\nvalidate our framework, we conducted a case study in a well-renowned\nuniversity, resulting in the creation of XUBench, a large-scale and\ncomprehensive closed-domain benchmark. Although we use the academic domain as\nthe case in this work, our Comp-Comp framework is designed to be extensible\nbeyond academia, providing valuable insights for benchmark construction across\nvarious domains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5168\u9762\u6027-\u7d27\u51d1\u6027\u539f\u5219\u7684\u8fed\u4ee3\u57fa\u51c6\u6846\u67b6Comp-Comp\uff0c\u7528\u4e8e\u4f18\u5316\u9886\u57df\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u51c6\u6784\u5efa\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u4e3b\u8981\u4f9d\u8d56\u6269\u5c55\u6cd5\u5219\uff0c\u4f46\u8bed\u6599\u5e93\u548c\u95ee\u7b54\u96c6\u8bbe\u8ba1\u5bf9\u6a21\u578b\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u7684\u5f71\u54cd\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u63d0\u51faComp-Comp\u6846\u67b6\uff0c\u7ed3\u5408\u5168\u9762\u6027\u548c\u7d27\u51d1\u6027\u539f\u5219\u6307\u5bfc\u8bed\u6599\u5e93\u548c\u95ee\u7b54\u96c6\u6784\u5efa\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u3002", "result": "\u521b\u5efa\u4e86XUBench\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u4e14\u5168\u9762\u7684\u5c01\u95ed\u9886\u57df\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86Comp-Comp\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "Comp-Comp\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u5b66\u672f\u9886\u57df\uff0c\u8fd8\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\uff0c\u4e3a\u57fa\u51c6\u6784\u5efa\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07382", "abs": "https://arxiv.org/abs/2508.07382", "authors": ["He Kong", "Die Hu", "Jingguo Ge", "Liangxiong Li", "Hui Li", "Tong Li"], "title": "Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning", "comment": null, "summary": "Automating penetration testing is crucial for enhancing cybersecurity, yet\ncurrent Large Language Models (LLMs) face significant limitations in this\ndomain, including poor error handling, inefficient reasoning, and an inability\nto perform complex end-to-end tasks autonomously. To address these challenges,\nwe introduce Pentest-R1, a novel framework designed to optimize LLM reasoning\ncapabilities for this task through a two-stage reinforcement learning pipeline.\nWe first construct a dataset of over 500 real-world, multi-step walkthroughs,\nwhich Pentest-R1 leverages for offline reinforcement learning (RL) to instill\nfoundational attack logic. Subsequently, the LLM is fine-tuned via online RL in\nan interactive Capture The Flag (CTF) environment, where it learns directly\nfrom environmental feedback to develop robust error self-correction and\nadaptive strategies. Our extensive experiments on the Cybench and AutoPenBench\nbenchmarks demonstrate the framework's effectiveness. On AutoPenBench,\nPentest-R1 achieves a 24.2\\% success rate, surpassing most state-of-the-art\nmodels and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a\n15.0\\% success rate in unguided tasks, establishing a new state-of-the-art for\nopen-source LLMs and matching the performance of top proprietary models.\nAblation studies confirm that the synergy of both training stages is critical\nto its success.", "AI": {"tldr": "Pentest-R1\u662f\u4e00\u4e2a\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316LLM\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u63a8\u7406\u80fd\u529b\u7684\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u5b58\u5728\u9519\u8bef\u5904\u7406\u5dee\u3001\u63a8\u7406\u6548\u7387\u4f4e\u548c\u65e0\u6cd5\u81ea\u4e3b\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\uff1a\u79bb\u7ebfRL\u5b66\u4e60\u57fa\u7840\u653b\u51fb\u903b\u8f91\uff0c\u5728\u7ebfRL\u5728CTF\u73af\u5883\u4e2d\u901a\u8fc7\u73af\u5883\u53cd\u9988\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728AutoPenBench\u4e0a\u8fbe\u523024.2%\u6210\u529f\u7387\uff0cCybench\u4e0a15.0%\u6210\u529f\u7387\uff0c\u6027\u80fd\u63a5\u8fd1\u9876\u7ea7\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "\u4e24\u9636\u6bb5\u8bad\u7ec3\u534f\u540c\u4f5c\u7528\u5bf9Pentest-R1\u7684\u6210\u529f\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u5f00\u6e90LLM\u8bbe\u5b9a\u4e86\u65b0\u6807\u6746\u3002"}}
{"id": "2508.07388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07388", "abs": "https://arxiv.org/abs/2508.07388", "authors": ["Zhaoyu Chen", "Hongnan Lin", "Yongwei Nie", "Fei Ma", "Xuemiao Xu", "Fei Yu", "Chengjiang Long"], "title": "Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding", "comment": null, "summary": "Temporal Video Grounding (TVG) seeks to localize video segments matching a\ngiven textual query. Current methods, while optimizing for high temporal\nIntersection-over-Union (IoU), often overfit to this metric, compromising\nsemantic action understanding in the video and query, a critical factor for\nrobust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),\na novel framework that enhances both localization accuracy and action\nunderstanding without additional data. Our approach leverages three inversion\ntasks derived from existing TVG annotations: (1) Verb Completion, predicting\nmasked action verbs in queries from video segments; (2) Action Recognition,\nidentifying query-described actions; and (3) Video Description, generating\ndescriptions of video segments that explicitly embed query-relevant actions.\nThese tasks, integrated with TVG via a reinforcement learning framework with\nwell-designed reward functions, ensure balanced optimization of localization\nand semantics. Experiments show our method outperforms state-of-the-art\napproaches, achieving a 7.1\\% improvement in R1@0.7 on Charades-STA for a 3B\nmodel compared to Time-R1. By inverting TVG to derive query-related actions\nfrom segments, our approach strengthens semantic understanding, significantly\nraising the ceiling of localization accuracy.", "AI": {"tldr": "Invert4TVG\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u53cd\u8f6c\u4efb\u52a1\u589e\u5f3a\u89c6\u9891\u7247\u6bb5\u5b9a\u4f4d\u548c\u52a8\u4f5c\u7406\u89e3\uff0c\u663e\u8457\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u65f6\u95f4IoU\u6307\u6807\uff0c\u727a\u7272\u4e86\u8bed\u4e49\u52a8\u4f5c\u7406\u89e3\uff0c\u5f71\u54cdTVG\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u53cd\u8f6c\u4efb\u52a1\uff08\u52a8\u8bcd\u8865\u5168\u3001\u52a8\u4f5c\u8bc6\u522b\u3001\u89c6\u9891\u63cf\u8ff0\uff09\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u5b9a\u4f4d\u548c\u8bed\u4e49\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0cCharades-STA\u4e0aR1@0.7\u63d0\u53477.1%\u3002", "conclusion": "\u901a\u8fc7\u53cd\u8f6c\u4efb\u52a1\u589e\u5f3a\u8bed\u4e49\u7406\u89e3\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u4e0a\u9650\u3002"}}
{"id": "2508.07405", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.5.4"], "pdf": "https://arxiv.org/pdf/2508.07405", "abs": "https://arxiv.org/abs/2508.07405", "authors": ["Jesse Ponnock"], "title": "Generative AI for Strategic Plan Development", "comment": "11 pages, 9 figures", "summary": "Given recent breakthroughs in Generative Artificial Intelligence (GAI) and\nLarge Language Models (LLMs), more and more professional services are being\naugmented through Artificial Intelligence (AI), which once seemed impossible to\nautomate. This paper presents a modular model for leveraging GAI in developing\nstrategic plans for large scale government organizations and evaluates leading\nmachine learning techniques in their application towards one of the identified\nmodules. Specifically, the performance of BERTopic and Non-negative Matrix\nFactorization (NMF) are evaluated in their ability to use topic modeling to\ngenerate themes representative of Vision Elements within a strategic plan. To\naccomplish this, BERTopic and NMF models are trained using a large volume of\nreports from the Government Accountability Office (GAO). The generated topics\nfrom each model are then scored for similarity against the Vision Elements of a\npublished strategic plan and the results are compared. Our results show that\nthese techniques are capable of generating themes similar to 100% of the\nelements being evaluated against. Further, we conclude that BERTopic performs\nbest in this application with more than half of its correlated topics achieving\na \"medium\" or \"strong\" correlation. A capability of GAI-enabled strategic plan\ndevelopment impacts a multi-billion dollar industry and assists the federal\ngovernment in overcoming regulatory requirements which are crucial to the\npublic good. Further work will focus on the operationalization of the concept\nproven in this study as well as viability of the remaining modules in the\nproposed model for GAI-generated strategic plans.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GAI\uff09\u4e3a\u5927\u578b\u653f\u5e9c\u7ec4\u7ec7\u5f00\u53d1\u6218\u7565\u8ba1\u5212\u7684\u6a21\u5757\u5316\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u4e86BERTopic\u548c\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff08NMF\uff09\u5728\u4e3b\u9898\u5efa\u6a21\u4e2d\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u4e9b\u6280\u672f\u80fd\u751f\u6210\u4e0e\u6218\u7565\u8ba1\u5212\u613f\u666f\u5143\u7d20\u76f8\u4f3c\u7684\u4e3b\u9898\uff0c\u5176\u4e2dBERTopic\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528GAI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u5316\u4e13\u4e1a\u670d\u52a1\uff0c\u7279\u522b\u662f\u5728\u653f\u5e9c\u6218\u7565\u8ba1\u5212\u5f00\u53d1\u4e2d\uff0c\u4ee5\u5e94\u5bf9\u4f20\u7edf\u4e0a\u96be\u4ee5\u81ea\u52a8\u5316\u7684\u4efb\u52a1\u3002", "method": "\u4f7f\u7528BERTopic\u548cNMF\u6a21\u578b\u5bf9\u653f\u5e9c\u95ee\u8d23\u529e\u516c\u5ba4\uff08GAO\uff09\u7684\u5927\u91cf\u62a5\u544a\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u751f\u6210\u7684\u4e3b\u9898\u4e0e\u5df2\u53d1\u5e03\u7684\u6218\u7565\u8ba1\u5212\u613f\u666f\u5143\u7d20\u8fdb\u884c\u76f8\u4f3c\u6027\u8bc4\u5206\u6bd4\u8f83\u3002", "result": "BERTopic\u548cNMF\u80fd\u751f\u6210\u4e0e100%\u7684\u613f\u666f\u5143\u7d20\u76f8\u4f3c\u7684\u4e3b\u9898\uff0c\u5176\u4e2dBERTopic\u8868\u73b0\u66f4\u4f18\uff0c\u8d85\u8fc7\u4e00\u534a\u7684\u4e3b\u9898\u8fbe\u5230\u201c\u4e2d\u7b49\u201d\u6216\u201c\u5f3a\u201d\u76f8\u5173\u6027\u3002", "conclusion": "GAI\u5728\u6218\u7565\u8ba1\u5212\u5f00\u53d1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u4e8e\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u548c\u5269\u4f59\u6a21\u5757\u7684\u53ef\u884c\u6027\u9a8c\u8bc1\u3002"}}
{"id": "2508.07407", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.07407", "abs": "https://arxiv.org/abs/2508.07407", "authors": ["Jinyuan Fang", "Yanwen Peng", "Xi Zhang", "Yingxu Wang", "Xinhao Yi", "Guibin Zhang", "Yi Xu", "Bin Wu", "Siwei Liu", "Zihao Li", "Zhaochun Ren", "Nikos Aletras", "Xi Wang", "Han Zhou", "Zaiqiao Meng"], "title": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems", "comment": null, "summary": "Recent advances in large language models have sparked growing interest in AI\nagents capable of solving complex, real-world tasks. However, most existing\nagent systems rely on manually crafted configurations that remain static after\ndeployment, limiting their ability to adapt to dynamic and evolving\nenvironments. To this end, recent research has explored agent evolution\ntechniques that aim to automatically enhance agent systems based on interaction\ndata and environmental feedback. This emerging direction lays the foundation\nfor self-evolving AI agents, which bridge the static capabilities of foundation\nmodels with the continuous adaptability required by lifelong agentic systems.\nIn this survey, we provide a comprehensive review of existing techniques for\nself-evolving agentic systems. Specifically, we first introduce a unified\nconceptual framework that abstracts the feedback loop underlying the design of\nself-evolving agentic systems. The framework highlights four key components:\nSystem Inputs, Agent System, Environment, and Optimisers, serving as a\nfoundation for understanding and comparing different strategies. Based on this\nframework, we systematically review a wide range of self-evolving techniques\nthat target different components of the agent system. We also investigate\ndomain-specific evolution strategies developed for specialised fields such as\nbiomedicine, programming, and finance, where optimisation objectives are\ntightly coupled with domain constraints. In addition, we provide a dedicated\ndiscussion on the evaluation, safety, and ethical considerations for\nself-evolving agentic systems, which are critical to ensuring their\neffectiveness and reliability. This survey aims to provide researchers and\npractitioners with a systematic understanding of self-evolving AI agents,\nlaying the foundation for the development of more adaptive, autonomous, and\nlifelong agentic systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u81ea\u8fdb\u5316AI\u4ee3\u7406\u7cfb\u7edf\u7684\u73b0\u6709\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u9886\u57df\u7279\u5b9a\u7b56\u7565\u53ca\u4f26\u7406\u8003\u91cf\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u7cfb\u7edf\u591a\u4e3a\u9759\u6001\u914d\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u73af\u5883\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u81ea\u8fdb\u5316\u6280\u672f\u4ee5\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u7cfb\u7edf\u8f93\u5165\u3001\u4ee3\u7406\u7cfb\u7edf\u3001\u73af\u5883\u548c\u4f18\u5316\u5668\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u7cfb\u7edf\u56de\u987e\u9488\u5bf9\u4e0d\u540c\u7ec4\u4ef6\u7684\u81ea\u8fdb\u5316\u6280\u672f\u3002", "result": "\u7efc\u8ff0\u4e86\u591a\u79cd\u81ea\u8fdb\u5316\u6280\u672f\u53ca\u9886\u57df\u7279\u5b9a\u7b56\u7565\uff0c\u5e76\u8ba8\u8bba\u4e86\u8bc4\u4f30\u3001\u5b89\u5168\u548c\u4f26\u7406\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f00\u53d1\u66f4\u5177\u9002\u5e94\u6027\u548c\u81ea\u4e3b\u6027\u7684\u7ec8\u8eab\u4ee3\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.07466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07466", "abs": "https://arxiv.org/abs/2508.07466", "authors": ["Dom Huh", "Prasant Mohapatra"], "title": "Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs", "comment": null, "summary": "Language is a ubiquitous tool that is foundational to reasoning and\ncollaboration, ranging from everyday interactions to sophisticated\nproblem-solving tasks. The establishment of a common language can serve as a\npowerful asset in ensuring clear communication and understanding amongst\nagents, facilitating desired coordination and strategies. In this work, we\nextend the capabilities of large language models (LLMs) by integrating them\nwith advancements in multi-agent decision-making algorithms. We propose a\nsystematic framework for the design of multi-agentic large language models\n(LLMs), focusing on key integration practices. These include advanced prompt\nengineering techniques, the development of effective memory architectures,\nmulti-modal information processing, and alignment strategies through\nfine-tuning algorithms. We evaluate these design choices through extensive\nablation studies on classic game settings with significant underlying social\ndilemmas and game-theoretic considerations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u7b97\u6cd5\uff0c\u63d0\u5347LLM\u5728\u534f\u4f5c\u4e0e\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u8bed\u8a00\u662f\u63a8\u7406\u4e0e\u534f\u4f5c\u7684\u57fa\u7840\uff0c\u5efa\u7acb\u5171\u540c\u8bed\u8a00\u6709\u52a9\u4e8e\u6e05\u6670\u6c9f\u901a\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55LLM\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5e94\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u6846\u67b6\uff0c\u5305\u62ec\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u3001\u6709\u6548\u8bb0\u5fc6\u67b6\u6784\u3001\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u548c\u5fae\u8c03\u7b97\u6cd5\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u7ecf\u5178\u6e38\u620f\u573a\u666f\u7684\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u667a\u80fd\u4f53LLM\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u5176\u5728\u590d\u6742\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2508.07468", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07468", "abs": "https://arxiv.org/abs/2508.07468", "authors": ["Stefan Szeider"], "title": "CP-Agent: Agentic Constraint Programming", "comment": null, "summary": "Translating natural language problem descriptions into formal constraint\nmodels remains a fundamental challenge in constraint programming, requiring\ndeep expertise in both the problem domain and modeling frameworks. Previous\napproaches to automating this translation have employed fixed workflows with\npredetermined modeling steps, failing on a significant number of benchmark\nproblems. We present a new approach using a pure agentic strategy without any\nfixed pipeline. We developed a general-purpose Python coding agent based on the\nReAct (Reason and Act) principle, utilizing a persistent IPython kernel for\nstateful code execution and iterative development. Rather than embedding\nconstraint programming logic into the agent architecture, domain-specific\nexpertise is injected solely through a carefully crafted project prompt. The\nagent combines this prompt-encoded knowledge with access to file operations and\ncode execution tools, enabling it to test hypotheses, debug failures, and\nverify solutions dynamically. Implemented in just a few hundred lines of code,\nthis architecture successfully solves all 101 problems of the CP-Bench\nconstraint programming benchmark set. The results suggest that constraint\nmodeling tasks require the combination of general coding tools and domain\nexpertise encoded in prompts, rather than specialized agent architectures or\npredefined workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7eaf\u4ee3\u7406\u7b56\u7565\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7Python\u7f16\u7801\u4ee3\u7406\u548cReAct\u539f\u5219\uff0c\u6210\u529f\u89e3\u51b3\u4e86CP-Bench\u57fa\u51c6\u96c6\u4e2d\u7684\u6240\u6709101\u4e2a\u95ee\u9898\u3002", "motivation": "\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u7ea6\u675f\u6a21\u578b\u662f\u4e00\u4e2a\u57fa\u7840\u6027\u6311\u6218\uff0c\u4f20\u7edf\u56fa\u5b9a\u6d41\u7a0b\u65b9\u6cd5\u5728\u591a\u6570\u57fa\u51c6\u95ee\u9898\u4e0a\u5931\u8d25\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eReAct\u539f\u5219\u7684Python\u7f16\u7801\u4ee3\u7406\uff0c\u901a\u8fc7\u6301\u4e45IPython\u5185\u6838\u5b9e\u73b0\u72b6\u6001\u5316\u4ee3\u7801\u6267\u884c\u548c\u8fed\u4ee3\u5f00\u53d1\uff0c\u4f9d\u8d56\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9879\u76ee\u63d0\u793a\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86CP-Bench\u57fa\u51c6\u96c6\u4e2d\u7684\u6240\u6709101\u4e2a\u95ee\u9898\u3002", "conclusion": "\u7ea6\u675f\u5efa\u6a21\u4efb\u52a1\u9700\u8981\u901a\u7528\u7f16\u7801\u5de5\u5177\u548c\u63d0\u793a\u7f16\u7801\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u800c\u975e\u4e13\u7528\u4ee3\u7406\u67b6\u6784\u6216\u9884\u5b9a\u4e49\u6d41\u7a0b\u3002"}}
{"id": "2508.07485", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07485", "abs": "https://arxiv.org/abs/2508.07485", "authors": ["Alexander Duffy", "Samuel J Paech", "Ishana Shastri", "Elizabeth Karpinski", "Baptiste Alloui-Cros", "Tyler Marques", "Matthew Lyle Olson"], "title": "Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy", "comment": null, "summary": "We present the first evaluation harness that enables any out-of-the-box,\nlocal, Large Language Models (LLMs) to play full-press Diplomacy without\nfine-tuning or specialized training. Previous work required frontier LLMs, or\nfine-tuning, due to the high complexity and information density of Diplomacy's\ngame state. Combined with the high variance of matches, these factors made\nDiplomacy prohibitive for study. In this work, we used data-driven iteration to\noptimize a textual game state representation such that a 24B model can reliably\ncomplete matches without any fine tuning. We develop tooling to facilitate\nhypothesis testing and statistical analysis, and we present case studies on\npersuasion, aggressive playstyles, and performance across a range of models. We\nconduct a variety of experiments across many popular LLMs, finding the larger\nmodels perform the best, but the smaller models still play adequately. We also\nintroduce Critical State Analysis: an experimental protocol for rapidly\niterating and analyzing key moments in a game at depth. Our harness\ndemocratizes the evaluation of strategic reasoning in LLMs by eliminating the\nneed for fine-tuning, and it provides insights into how these capabilities\nemerge naturally from widely used LLMs. Our code is available in the supplement\nand will be open sourced.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9700\u5fae\u8c03\u6216\u4e13\u95e8\u8bad\u7ec3\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u4f7f\u672c\u5730\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u591f\u73a9\u5b8c\u6574\u7248\u300a\u5916\u4ea4\u300b\u6e38\u620f\u3002", "motivation": "\u7531\u4e8e\u300a\u5916\u4ea4\u300b\u6e38\u620f\u72b6\u6001\u7684\u9ad8\u590d\u6742\u6027\u548c\u4fe1\u606f\u5bc6\u5ea6\uff0c\u5148\u524d\u7814\u7a76\u9700\u8981\u524d\u6cbfLLM\u6216\u5fae\u8c03\uff0c\u9650\u5236\u4e86\u7814\u7a76\u7684\u666e\u53ca\u3002", "method": "\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u8fed\u4ee3\u4f18\u5316\u6587\u672c\u6e38\u620f\u72b6\u6001\u8868\u793a\uff0c\u5f00\u53d1\u5de5\u5177\u652f\u6301\u5047\u8bbe\u6d4b\u8bd5\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u5e76\u5f15\u5165\u5173\u952e\u72b6\u6001\u5206\u6790\u534f\u8bae\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8f83\u5927\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u8f83\u5c0f\u6a21\u578b\u4e5f\u80fd\u80dc\u4efb\uff1b\u5de5\u5177\u4e3aLLM\u7684\u6218\u7565\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u81ea\u7136\u6d8c\u73b0\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u5de5\u5177\u6d88\u9664\u4e86\u5fae\u8c03\u9700\u6c42\uff0c\u666e\u53ca\u4e86LLM\u6218\u7565\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2508.07575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07575", "abs": "https://arxiv.org/abs/2508.07575", "authors": ["Shiqing Fan", "Xichen Ding", "Liang Zhang", "Linjian Mo"], "title": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark", "comment": "Benchmarks and Source Code Released", "summary": "LLMs' capabilities are enhanced by using function calls to integrate various\ndata sources or API results into the context window. Typical tools include\nsearch, web crawlers, maps, financial data, file systems, and browser usage,\netc. Integrating these data sources or functions requires a standardized\nmethod. The Model Context Protocol (MCP) provides a standardized way to supply\ncontext to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use\nabilities suffer from several issues. First, there's a lack of comprehensive\ndatasets or benchmarks to evaluate various MCP tools. Second, the diverse\nformats of response from MCP tool call execution further increase the\ndifficulty of evaluation. Additionally, unlike existing tool-use benchmarks\nwith high success rates in functions like programming and math functions, the\nsuccess rate of real-world MCP tool is not guaranteed and varies across\ndifferent MCP servers. Furthermore, the LLMs' context window also limits the\nnumber of available tools that can be called in a single run, because the\ntextual descriptions of tool and the parameters have long token length for an\nLLM to process all at once. To help address the challenges of evaluating LLMs'\nperformance on calling MCP tools, we propose MCPToolBench++, a large-scale,\nmulti-domain AI Agent tool use benchmark. As of July 2025, this benchmark is\nbuild upon marketplace of over 4k MCP servers from more than 40 categories,\ncollected from the MCP marketplaces and GitHub communities. The datasets\nconsist of both single-step and multi-step tool calls across different\ncategories. We evaluated SOTA LLMs with agentic abilities on this benchmark and\nreported the results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMCPToolBench++\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLMs\u8c03\u7528MCP\u5de5\u5177\u6027\u80fd\u7684\u5927\u89c4\u6a21\u591a\u9886\u57df\u57fa\u51c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5168\u9762\u7684\u6570\u636e\u96c6\u6216\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u548cAI\u4ee3\u7406\u5728MCP\u5de5\u5177\u4f7f\u7528\u4e0a\u7684\u80fd\u529b\uff0c\u4e14MCP\u5de5\u5177\u7684\u591a\u6837\u6027\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u589e\u52a0\u4e86\u8bc4\u4f30\u96be\u5ea6\u3002", "method": "\u6784\u5efaMCPToolBench++\u57fa\u51c6\uff0c\u57fa\u4e8e4k\u591a\u4e2aMCP\u670d\u52a1\u5668\u548c40\u591a\u4e2a\u7c7b\u522b\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u5355\u6b65\u548c\u591a\u6b65\u5de5\u5177\u8c03\u7528\u3002", "result": "\u8bc4\u4f30\u4e86\u5177\u6709\u4ee3\u7406\u80fd\u529b\u7684SOTA LLMs\uff0c\u5e76\u62a5\u544a\u4e86\u7ed3\u679c\u3002", "conclusion": "MCPToolBench++\u4e3a\u8bc4\u4f30LLMs\u5728MCP\u5de5\u5177\u8c03\u7528\u4e0a\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07602", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07602", "abs": "https://arxiv.org/abs/2508.07602", "authors": ["Wenpeng Xing", "Zhipeng Chen", "Changting Lin", "Meng Han"], "title": "HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol", "comment": null, "summary": "Invoking external tools enables Large Language Models (LLMs) to perform\ncomplex, real-world tasks, yet selecting the correct tool from large,\nhierarchically-structured libraries remains a significant challenge. The\nlimited context windows of LLMs and noise from irrelevant options often lead to\nlow selection accuracy and high computational costs. To address this, we\npropose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic\npruning method for scalable tool invocation. HGMF first maps the user query and\nall tool descriptions into a unified semantic space. The framework then\noperates in two stages: it clusters servers using a Gaussian Mixture Model\n(GMM) and filters them based on the query's likelihood. Subsequently, it\napplies the same GMM-based clustering and filtering to the tools associated\nwith the selected servers. This hierarchical process produces a compact,\nhigh-relevance candidate set, simplifying the final selection task for the LLM.\nExperiments on a public dataset show that HGMF significantly improves tool\nselection accuracy while reducing inference latency, confirming the framework's\nscalability and effectiveness for large-scale tool libraries.", "AI": {"tldr": "HGMF\u662f\u4e00\u79cd\u6982\u7387\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u63d0\u5347LLM\u5728\u5927\u89c4\u6a21\u5de5\u5177\u5e93\u4e2d\u9009\u62e9\u5de5\u5177\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u5927\u578b\u5206\u5c42\u5de5\u5177\u5e93\u4e2d\u9009\u62e9\u5de5\u5177\u65f6\u56e0\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u65e0\u5173\u9009\u9879\u566a\u58f0\u5bfc\u81f4\u7684\u4f4e\u51c6\u786e\u6027\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002", "method": "HGMF\u5c06\u7528\u6237\u67e5\u8be2\u548c\u5de5\u5177\u63cf\u8ff0\u6620\u5c04\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff0c\u5206\u4e24\u9636\u6bb5\u8fdb\u884c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\u548c\u57fa\u4e8e\u67e5\u8be2\u53ef\u80fd\u6027\u7684\u7b5b\u9009\uff0c\u751f\u6210\u9ad8\u76f8\u5173\u6027\u5019\u9009\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHGMF\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u5177\u9009\u62e9\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "HGMF\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u6548\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5de5\u5177\u5e93\u3002"}}
{"id": "2508.07616", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07616", "abs": "https://arxiv.org/abs/2508.07616", "authors": ["Aswin RRV", "Jacob Dineen", "Divij Handa", "Md Nayem Uddin", "Mihir Parmar", "Chitta Baral", "Ben Zhou"], "title": "ThinkTuning: Instilling Cognitive Reflections without Distillation", "comment": "15 pages", "summary": "Recent advances in test-time scaling have led to the emergence of thinking\nLLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL\ndrives this self-improvement paradigm, a recent study (Gandhi et al., 2025)\nshows that RL alone does not truly instill these new reasoning abilities - it\nmerely draws out behaviors already present in the base models. This raises a\nquestion: How can we train the models that don't exhibit such thinking behavior\nto develop it in the first place? To this end, we propose ThinkTuning, a\nGRPO-based interactive training approach where we augment the rollouts of a\nstudent model with the guidance from a teacher model. A simple idea from\nclassroom practice inspires our method: a teacher poses a problem, lets the\nstudent try an answer, then gives corrective feedback -- enough to point the\nmind in the right direction and then show the solution. Each piece of feedback\nreshapes the student's thoughts, leading them to arrive at the correct\nsolution. Similarly, we find that this type of implicit supervision through\nfeedback from a teacher model of the same size improves the reasoning\ncapabilities of the student model. In particular, on average, our method shows\na 3.85% improvement over zero-shot baselines across benchmarks, and on\nMATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements\nover the vanilla-GRPO baseline. Source code is available at\nhttps://github.com/3rdAT/ThinkTuning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faThinkTuning\u65b9\u6cd5\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u5bf9\u5b66\u751f\u6a21\u578b\u7684\u53cd\u9988\u6307\u5bfc\uff0c\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u4efb\u52a1\u57fa\u51c6\u4e0a\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\u4ec5\u80fd\u6316\u6398\u57fa\u7840\u6a21\u578b\u5df2\u6709\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u800c\u65e0\u6cd5\u771f\u6b63\u57f9\u517b\u65b0\u7684\u63a8\u7406\u80fd\u529b\u3002\u5982\u4f55\u8ba9\u4e0d\u5177\u5907\u6b64\u7c7b\u884c\u4e3a\u7684\u6a21\u578b\u53d1\u5c55\u51fa\u63a8\u7406\u80fd\u529b\u6210\u4e3a\u7814\u7a76\u52a8\u673a\u3002", "method": "\u91c7\u7528GRPO\u57fa\u7840\u7684\u4ea4\u4e92\u5f0f\u8bad\u7ec3\u65b9\u6cd5ThinkTuning\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u5bf9\u5b66\u751f\u6a21\u578b\u7684\u7b54\u6848\u63d0\u4f9b\u53cd\u9988\uff0c\u9010\u6b65\u5f15\u5bfc\u5176\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cThinkTuning\u5e73\u5747\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u53473.85%\uff0c\u5728MATH-500\u3001AIME\u548cGPQA-Diamond\u4e0a\u5206\u522b\u63d0\u53472.08%\u30012.23%\u548c3.99%\u3002", "conclusion": "ThinkTuning\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u7684\u53cd\u9988\u6307\u5bfc\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u57f9\u517b\u65b0\u578b\u63a8\u7406\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.07628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07628", "abs": "https://arxiv.org/abs/2508.07628", "authors": ["Daniel Essien", "Suresh Neethirajan"], "title": "Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization", "comment": "66 pages, 7 figures, 11 tables", "summary": "The future of poultry production depends on a paradigm shift replacing\nsubjective, labor-intensive welfare checks with data-driven, intelligent\nmonitoring ecosystems. Traditional welfare assessments-limited by human\nobservation and single-sensor data-cannot fully capture the complex,\nmultidimensional nature of laying hen welfare in modern farms. Multimodal\nArtificial Intelligence (AI) offers a breakthrough, integrating visual,\nacoustic, environmental, and physiological data streams to reveal deeper\ninsights into avian welfare dynamics. This investigation highlights multimodal\nAs transformative potential, showing that intermediate (feature-level) fusion\nstrategies achieve the best balance between robustness and performance under\nreal-world poultry conditions, and offer greater scalability than early or late\nfusion approaches. Key adoption barriers include sensor fragility in harsh farm\nenvironments, high deployment costs, inconsistent behavioral definitions, and\nlimited cross-farm generalizability. To address these, we introduce two novel\nevaluation tools - the Domain Transfer Score (DTS) to measure model\nadaptability across diverse farm settings, and the Data Reliability Index (DRI)\nto assess sensor data quality under operational constraints. We also propose a\nmodular, context-aware deployment framework designed for laying hen\nenvironments, enabling scalable and practical integration of multimodal\nsensing. This work lays the foundation for a transition from reactive, unimodal\nmonitoring to proactive, precision-driven welfare systems that unite\nproductivity with ethical, science based animal care.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5229\u7528\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u66ff\u4ee3\u4f20\u7edf\u4e3b\u89c2\u3001\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u5bb6\u79bd\u798f\u5229\u76d1\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u3001\u58f0\u5b66\u3001\u73af\u5883\u548c\u751f\u7406\u6570\u636e\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u7684\u86cb\u9e21\u798f\u5229\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u5bb6\u79bd\u798f\u5229\u8bc4\u4f30\u65b9\u6cd5\u53d7\u9650\u4e8e\u4eba\u5de5\u89c2\u5bdf\u548c\u5355\u4e00\u4f20\u611f\u5668\u6570\u636e\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u73b0\u4ee3\u519c\u573a\u4e2d\u86cb\u9e21\u798f\u5229\u7684\u591a\u7ef4\u590d\u6742\u6027\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001AI\uff0c\u63d0\u51fa\u4e2d\u95f4\uff08\u7279\u5f81\u7ea7\uff09\u878d\u5408\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u4e24\u4e2a\u65b0\u8bc4\u4f30\u5de5\u5177\uff08DTS\u548cDRI\uff09\u4ee5\u53ca\u6a21\u5757\u5316\u90e8\u7f72\u6846\u67b6\u3002", "result": "\u4e2d\u95f4\u878d\u5408\u7b56\u7565\u5728\u9c81\u68d2\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u6700\u4f73\u5e73\u8861\uff0c\u4e14\u6bd4\u65e9\u671f\u6216\u665a\u671f\u878d\u5408\u66f4\u5177\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4ece\u88ab\u52a8\u3001\u5355\u6a21\u6001\u76d1\u6d4b\u8f6c\u5411\u4e3b\u52a8\u3001\u7cbe\u51c6\u9a71\u52a8\u7684\u798f\u5229\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c06\u751f\u4ea7\u529b\u4e0e\u79d1\u5b66\u4f26\u7406\u76f8\u7ed3\u5408\u3002"}}
{"id": "2508.07642", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07642", "abs": "https://arxiv.org/abs/2508.07642", "authors": ["Tianyi Ma", "Yue Zhang", "Zehao Wang", "Parisa Kordjamshidi"], "title": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents", "comment": "18 pages, 5 Figures,", "summary": "Vision-and-Language Navigation (VLN) poses significant challenges in enabling\nagents to interpret natural language instructions and navigate complex 3D\nenvironments. While recent progress has been driven by large-scale pre-training\nand data augmentation, current methods still struggle to generalize to unseen\nscenarios, particularly when complex spatial and temporal reasoning is\nrequired. In this work, we propose SkillNav, a modular framework that\nintroduces structured, skill-based reasoning into Transformer-based VLN agents.\nOur method decomposes navigation into a set of interpretable atomic skills\n(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each\nhandled by a specialized agent. We then introduce a novel zero-shot\nVision-Language Model (VLM)-based router, which dynamically selects the most\nsuitable agent at each time step by aligning sub-goals with visual observations\nand historical actions. SkillNav achieves a new state-of-the-art performance on\nthe R2R benchmark and demonstrates strong generalization to the GSA-R2R\nbenchmark that includes novel instruction styles and unseen environments.", "AI": {"tldr": "SkillNav\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5bfc\u822a\u4efb\u52a1\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u539f\u5b50\u6280\u80fd\uff0c\u5e76\u5229\u7528VLM\u8def\u7531\u52a8\u6001\u9009\u62e9\u6700\u4f73\u6280\u80fd\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86VLN\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524dVLN\u65b9\u6cd5\u5728\u590d\u6742\u7a7a\u95f4\u548c\u65f6\u95f4\u63a8\u7406\u7684\u672a\u89c1\u573a\u666f\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u3002", "method": "SkillNav\u5c06\u5bfc\u822a\u4efb\u52a1\u5206\u89e3\u4e3a\u539f\u5b50\u6280\u80fd\uff08\u5982\u5782\u76f4\u79fb\u52a8\u3001\u533a\u57df\u8bc6\u522b\u7b49\uff09\uff0c\u6bcf\u4e2a\u6280\u80fd\u7531\u4e13\u95e8\u4ee3\u7406\u5904\u7406\uff0c\u5e76\u4f7f\u7528VLM\u8def\u7531\u52a8\u6001\u9009\u62e9\u4ee3\u7406\u3002", "result": "\u5728R2R\u548cGSA-R2R\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0SOTA\uff0c\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SkillNav\u901a\u8fc7\u6a21\u5757\u5316\u548c\u6280\u80fd\u5206\u89e3\u663e\u8457\u63d0\u5347\u4e86VLN\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.07649", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07649", "abs": "https://arxiv.org/abs/2508.07649", "authors": ["Jie Li", "Haoye Dong", "Zhengyang Wu", "Zetao Zheng", "Mingrong Lin"], "title": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation", "comment": null, "summary": "Next Point-of-Interest (POI) recommendation is a research hotspot in business\nintelligence, where users' spatial-temporal transitions and social\nrelationships play key roles. However, most existing works model spatial and\ntemporal transitions separately, leading to misaligned representations of the\nsame spatial-temporal key nodes. This misalignment introduces redundant\ninformation during fusion, increasing model uncertainty and reducing\ninterpretability. To address this issue, we propose DiMuST, a socially enhanced\nPOI recommendation model based on disentangled representation learning over\nmultiplex spatial-temporal transition graphs. The model employs a novel\nDisentangled variational multiplex graph Auto-Encoder (DAE), which first\ndisentangles shared and private distributions using a multiplex\nspatial-temporal graph strategy. It then fuses the shared features via a\nProduct of Experts (PoE) mechanism and denoises the private features through\ncontrastive constraints. The model effectively captures the spatial-temporal\ntransition representations of POIs while preserving the intrinsic correlation\nof their spatial-temporal relationships. Experiments on two challenging\ndatasets demonstrate that our DiMuST significantly outperforms existing methods\nacross multiple metrics.", "AI": {"tldr": "DiMuST\u662f\u4e00\u79cd\u57fa\u4e8e\u89e3\u8026\u8868\u793a\u5b66\u4e60\u7684POI\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u65f6\u7a7a\u8f6c\u6362\u56fe\u548c\u793e\u4f1a\u5173\u7cfb\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u65f6\u7a7a\u8f6c\u6362\u5206\u5f00\u5efa\u6a21\uff0c\u5bfc\u81f4\u5173\u952e\u8282\u70b9\u8868\u793a\u4e0d\u4e00\u81f4\uff0c\u5f15\u5165\u5197\u4f59\u4fe1\u606f\uff0c\u964d\u4f4e\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faDiMuST\u6a21\u578b\uff0c\u4f7f\u7528\u89e3\u8026\u53d8\u5206\u591a\u56fe\u81ea\u7f16\u7801\u5668\uff08DAE\uff09\u5206\u79bb\u5171\u4eab\u548c\u79c1\u6709\u5206\u5e03\uff0c\u901a\u8fc7PoE\u673a\u5236\u878d\u5408\u5171\u4eab\u7279\u5f81\uff0c\u5bf9\u6bd4\u7ea6\u675f\u53bb\u566a\u79c1\u6709\u7279\u5f81\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cDiMuST\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DiMuST\u6709\u6548\u6355\u6349POI\u7684\u65f6\u7a7a\u8f6c\u6362\u8868\u793a\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u65f6\u7a7a\u5173\u7cfb\u7684\u56fa\u6709\u76f8\u5173\u6027\u3002"}}
{"id": "2508.07667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07667", "abs": "https://arxiv.org/abs/2508.07667", "authors": ["Wenkai Li", "Liwen Sun", "Zhenxiang Guan", "Xuhui Zhou", "Maarten Sap"], "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning", "comment": null, "summary": "Addressing contextual privacy concerns remains challenging in interactive\nsettings where large language models (LLMs) process information from multiple\nsources (e.g., summarizing meetings with private and public information). We\nintroduce a multi-agent framework that decomposes privacy reasoning into\nspecialized subtasks (extraction, classification), reducing the information\nload on any single agent while enabling iterative validation and more reliable\nadherence to contextual privacy norms. To understand how privacy errors emerge\nand propagate, we conduct a systematic ablation over information-flow\ntopologies, revealing when and why upstream detection mistakes cascade into\ndownstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with\nseveral open-source and closed-sourced LLMs demonstrate that our best\nmulti-agent configuration substantially reduces private information leakage\n(\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while\npreserving the fidelity of public content, outperforming single-agent\nbaselines. These results highlight the promise of principled information-flow\ndesign in multi-agent systems for contextual privacy with LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u9690\u79c1\u63a8\u7406\u4efb\u52a1\u6765\u51cf\u5c11\u9690\u79c1\u4fe1\u606f\u6cc4\u9732\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6cc4\u9732\u7387\u3002", "motivation": "\u89e3\u51b3\u4ea4\u4e92\u5f0f\u73af\u5883\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5904\u7406\u591a\u6e90\u4fe1\u606f\u65f6\u7684\u9690\u79c1\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6df7\u5408\u516c\u5f00\u548c\u79c1\u4eba\u4fe1\u606f\u7684\u573a\u666f\u4e2d\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u9690\u79c1\u63a8\u7406\u5206\u89e3\u4e3a\u63d0\u53d6\u548c\u5206\u7c7b\u7b49\u5b50\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u4fe1\u606f\u6d41\u62d3\u6251\u5206\u6790\u9690\u79c1\u9519\u8bef\u7684\u4f20\u64ad\u3002", "result": "\u5728ConfAIde\u548cPrivacyLens\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6700\u4f73\u591a\u667a\u80fd\u4f53\u914d\u7f6e\u663e\u8457\u51cf\u5c11\u4e86\u9690\u79c1\u4fe1\u606f\u6cc4\u9732\uff08GPT-4o\u4e0b\u5206\u522b\u964d\u4f4e18%\u548c19%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u516c\u5171\u5185\u5bb9\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u6d41\u8bbe\u8ba1\u53ef\u4ee5\u6709\u6548\u63d0\u5347LLMs\u5728\u4e0a\u4e0b\u6587\u9690\u79c1\u4fdd\u62a4\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2508.07671", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "stat.AP", "68T07, 68T42, 68T50, 91F20, 62P25", "I.2.11; I.2.1; H.1.2; J.4; K.4.2"], "pdf": "https://arxiv.org/pdf/2508.07671", "abs": "https://arxiv.org/abs/2508.07671", "authors": ["Mohamed Rayan Barhdadi", "Mehmet Tuncel", "Erchin Serpedin", "Hasan Kurban"], "title": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration", "comment": "19 pages, 3 figures (plus 6 figures in supplementary), 2 tables, 1\n  algorithm. Submitted to NeurIPS 2025 Creative AI Track: Humanity", "summary": "Current AI approaches to refugee integration optimize narrow objectives such\nas employment and fail to capture the cultural, emotional, and ethical\ndimensions critical for long-term success. We introduce EMPATHIA (Enriched\nMultimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),\na multi-agent framework addressing the central Creative AI question: how do we\npreserve human dignity when machines participate in life-altering decisions?\nGrounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes\nintegration into three modules: SEED (Socio-cultural Entry and Embedding\nDecision) for initial placement, RISE (Rapid Integration and Self-sufficiency\nEngine) for early independence, and THRIVE (Transcultural Harmony and\nResilience through Integrated Values and Engagement) for sustained outcomes.\nSEED employs a selector-validator architecture with three specialized agents -\nemotional, cultural, and ethical - that deliberate transparently to produce\ninterpretable recommendations. Experiments on the UN Kakuma dataset (15,026\nindividuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and\nimplementation on 6,359 working-age refugees (15+) with 150+ socioeconomic\nvariables achieved 87.4% validation convergence and explainable assessments\nacross five host countries. EMPATHIA's weighted integration of cultural,\nemotional, and ethical factors balances competing value systems while\nsupporting practitioner-AI collaboration. By augmenting rather than replacing\nhuman expertise, EMPATHIA provides a generalizable framework for AI-driven\nallocation tasks where multiple values must be reconciled.", "AI": {"tldr": "EMPATHIA\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u96be\u6c11\u6574\u5408\u4e2d\u7684\u6587\u5316\u3001\u60c5\u611f\u548c\u4f26\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u4e2a\u6a21\u5757\uff08SEED\u3001RISE\u3001THRIVE\uff09\u5b9e\u73b0\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u3002", "motivation": "\u5f53\u524dAI\u65b9\u6cd5\u5728\u96be\u6c11\u6574\u5408\u4e2d\u8fc7\u4e8e\u5173\u6ce8\u5c31\u4e1a\u7b49\u72ed\u7a84\u76ee\u6807\uff0c\u5ffd\u89c6\u4e86\u6587\u5316\u3001\u60c5\u611f\u548c\u4f26\u7406\u7b49\u957f\u671f\u6210\u529f\u7684\u5173\u952e\u7ef4\u5ea6\u3002", "method": "\u57fa\u4e8eKegan\u7684\u5efa\u6784\u53d1\u5c55\u7406\u8bba\uff0cEMPATHIA\u5206\u4e3aSEED\uff08\u521d\u59cb\u5b89\u7f6e\uff09\u3001RISE\uff08\u65e9\u671f\u72ec\u7acb\uff09\u548cTHRIVE\uff08\u6301\u7eed\u6210\u679c\uff09\u4e09\u4e2a\u6a21\u5757\uff0c\u91c7\u7528\u9009\u62e9\u5668-\u9a8c\u8bc1\u5668\u67b6\u6784\u548c\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff08\u60c5\u611f\u3001\u6587\u5316\u3001\u4f26\u7406\uff09\u3002", "result": "\u5728UN Kakuma\u6570\u636e\u96c6\uff0815,026\u4eba\uff09\u548c6,359\u540d\u9002\u9f84\u96be\u6c11\u4e2d\uff0c\u9a8c\u8bc1\u6536\u655b\u7387\u8fbe87.4%\uff0c\u5e76\u5728\u4e94\u4e2a\u4e1c\u9053\u56fd\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u3002", "conclusion": "EMPATHIA\u901a\u8fc7\u5e73\u8861\u6587\u5316\u3001\u60c5\u611f\u548c\u4f26\u7406\u56e0\u7d20\uff0c\u652f\u6301\u4eba\u673a\u534f\u4f5c\uff0c\u4e3a\u591a\u4ef7\u503c\u534f\u8c03\u7684AI\u9a71\u52a8\u5206\u914d\u4efb\u52a1\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2508.07673", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07673", "abs": "https://arxiv.org/abs/2508.07673", "authors": ["Gianluca Bontempi"], "title": "Ethics2vec: aligning automatic agents and human preferences", "comment": null, "summary": "Though intelligent agents are supposed to improve human experience (or make\nit more efficient), it is hard from a human perspective to grasp the ethical\nvalues which are explicitly or implicitly embedded in an agent behaviour. This\nis the well-known problem of alignment, which refers to the challenge of\ndesigning AI systems that align with human values, goals and preferences. This\nproblem is particularly challenging since most human ethical considerations\nrefer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable)\nvalues and criteria. Consider, for instance, a medical agent prescribing a\ntreatment to a cancerous patient. How could it take into account (and/or weigh)\nincommensurable aspects like the value of a human life and the cost of the\ntreatment? Now, the alignment between human and artificial values is possible\nonly if we define a common space where a metric can be defined and used. This\npaper proposes to extend to ethics the conventional Anything2vec approach,\nwhich has been successful in plenty of similar and hard-to-quantify domains\n(ranging from natural language processing to recommendation systems and graph\nanalysis). This paper proposes a way to map an automatic agent decision-making\n(or control law) strategy to a multivariate vector representation, which can be\nused to compare and assess the alignment with human values. The Ethics2Vec\nmethod is first introduced in the case of an automatic agent performing binary\ndecision-making. Then, a vectorisation of an automatic control law (like in the\ncase of a self-driving car) is discussed to show how the approach can be\nextended to automatic control settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEthics2Vec\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4f26\u7406\u4ef7\u503c\u91cf\u5316\u4e3a\u5411\u91cf\u7a7a\u95f4\uff0c\u89e3\u51b3AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u96be\u4ee5\u660e\u786e\u6216\u9690\u542b\u5730\u5d4c\u5165\u4eba\u7c7b\u4f26\u7406\u4ef7\u503c\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e0d\u53ef\u6bd4\u8f83\u7684\u4ef7\u503c\u89c2\u65f6\uff08\u5982\u751f\u547d\u4ef7\u503c\u4e0e\u6cbb\u7597\u6210\u672c\uff09\u3002", "method": "\u6269\u5c55Anything2vec\u65b9\u6cd5\uff0c\u5c06\u4f26\u7406\u4ef7\u503c\u6620\u5c04\u4e3a\u591a\u5143\u5411\u91cf\u8868\u793a\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002\u9996\u5148\u5728\u4e8c\u5143\u51b3\u7b56\u573a\u666f\u4e2d\u5e94\u7528\uff0c\u968f\u540e\u6269\u5c55\u5230\u81ea\u52a8\u63a7\u5236\u9886\u57df\u3002", "result": "\u63d0\u51faEthics2Vec\u65b9\u6cd5\uff0c\u80fd\u591f\u91cf\u5316\u4f26\u7406\u4ef7\u503c\u5e76\u7528\u4e8e\u8bc4\u4f30AI\u51b3\u7b56\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u3002", "conclusion": "Ethics2Vec\u4e3a\u89e3\u51b3AI\u4f26\u7406\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4ece\u7b80\u5355\u51b3\u7b56\u5230\u590d\u6742\u63a7\u5236\u7684\u591a\u79cd\u573a\u666f\u3002"}}
{"id": "2508.07743", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07743", "abs": "https://arxiv.org/abs/2508.07743", "authors": ["Markus Fritzsche", "Elliot Gestrin", "Jendrik Seipp"], "title": "Symmetry-Aware Transformer Training for Automated Planning", "comment": null, "summary": "While transformers excel in many settings, their application in the field of\nautomated planning is limited. Prior work like PlanGPT, a state-of-the-art\ndecoder-only transformer, struggles with extrapolation from easy to hard\nplanning problems. This in turn stems from problem symmetries: planning tasks\ncan be represented with arbitrary variable names that carry no meaning beyond\nbeing identifiers. This causes a combinatorial explosion of equivalent\nrepresentations that pure transformers cannot efficiently learn from. We\npropose a novel contrastive learning objective to make transformers\nsymmetry-aware and thereby compensate for their lack of inductive bias.\nCombining this with architectural improvements, we show that transformers can\nbe efficiently trained for either plan-generation or heuristic-prediction. Our\nresults across multiple planning domains demonstrate that our symmetry-aware\ntraining effectively and efficiently addresses the limitations of PlanGPT.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u4f7fTransformer\u80fd\u591f\u611f\u77e5\u5bf9\u79f0\u6027\uff0c\u4ece\u800c\u89e3\u51b3PlanGPT\u5728\u89c4\u5212\u95ee\u9898\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "Transformer\u5728\u81ea\u52a8\u89c4\u5212\u9886\u57df\u5e94\u7528\u53d7\u9650\uff0c\u5c24\u5176\u662fPlanGPT\u5728\u5904\u7406\u4ece\u7b80\u5355\u5230\u590d\u6742\u89c4\u5212\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u7531\u4e8e\u95ee\u9898\u5bf9\u79f0\u6027\u5bfc\u81f4\u7684\u7ec4\u5408\u7206\u70b8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u7ed3\u5408\u67b6\u6784\u6539\u8fdb\uff0c\u4f7fTransformer\u80fd\u591f\u9ad8\u6548\u8bad\u7ec3\u7528\u4e8e\u89c4\u5212\u751f\u6210\u6216\u542f\u53d1\u5f0f\u9884\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u79f0\u611f\u77e5\u8bad\u7ec3\u6709\u6548\u4e14\u9ad8\u6548\u5730\u89e3\u51b3\u4e86PlanGPT\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u79f0\u611f\u77e5\u8bad\u7ec3\uff0cTransformer\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.07790", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.07790", "abs": "https://arxiv.org/abs/2508.07790", "authors": ["Alessandro Abate", "Thom Badings", "Giuseppe De Giacomo", "Francesco Fabiano"], "title": "Best-Effort Policies for Robust Markov Decision Processes", "comment": null, "summary": "We study the common generalization of Markov decision processes (MDPs) with\nsets of transition probabilities, known as robust MDPs (RMDPs). A standard goal\nin RMDPs is to compute a policy that maximizes the expected return under an\nadversarial choice of the transition probabilities. If the uncertainty in the\nprobabilities is independent between the states, known as s-rectangularity,\nsuch optimal robust policies can be computed efficiently using robust value\niteration. However, there might still be multiple optimal robust policies,\nwhich, while equivalent with respect to the worst-case, reflect different\nexpected returns under non-adversarial choices of the transition probabilities.\nHence, we propose a refined policy selection criterion for RMDPs, drawing\ninspiration from the notions of dominance and best-effort in game theory.\nInstead of seeking a policy that only maximizes the worst-case expected return,\nwe additionally require the policy to achieve a maximal expected return under\ndifferent (i.e., not fully adversarial) transition probabilities. We call such\na policy an optimal robust best-effort (ORBE) policy. We prove that ORBE\npolicies always exist, characterize their structure, and present an algorithm\nto compute them with a small overhead compared to standard robust value\niteration. ORBE policies offer a principled tie-breaker among optimal robust\npolicies. Numerical experiments show the feasibility of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08RMDPs\uff09\u4e2d\u591a\u4e2a\u6700\u4f18\u9c81\u68d2\u7b56\u7565\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u9009\u62e9\u6807\u51c6\u2014\u2014\u6700\u4f18\u9c81\u68d2\u6700\u4f73\u52aa\u529b\uff08ORBE\uff09\u7b56\u7565\uff0c\u4ee5\u5728\u975e\u5b8c\u5168\u5bf9\u6297\u6027\u6982\u7387\u4e0b\u6700\u5927\u5316\u671f\u671b\u56de\u62a5\u3002", "motivation": "\u5728RMDPs\u4e2d\uff0c\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u9c81\u68d2\u503c\u8fed\u4ee3\u9ad8\u6548\u8ba1\u7b97\u6700\u4f18\u9c81\u68d2\u7b56\u7565\uff0c\u4f46\u8fd9\u4e9b\u7b56\u7565\u5728\u975e\u5bf9\u6297\u6027\u6982\u7387\u4e0b\u7684\u8868\u73b0\u53ef\u80fd\u4e0d\u540c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u7684\u7b56\u7565\u9009\u62e9\u6807\u51c6\u3002", "method": "\u8bba\u6587\u63d0\u51faORBE\u7b56\u7565\uff0c\u7ed3\u5408\u4e86\u9c81\u68d2\u6027\u548c\u6700\u4f73\u52aa\u529b\u7684\u6982\u5ff5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b97\u6cd5\u6765\u8ba1\u7b97\u8fd9\u4e9b\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u4e86ORBE\u7b56\u7565\u7684\u5b58\u5728\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "conclusion": "ORBE\u7b56\u7565\u4e3aRMDPs\u4e2d\u7684\u7b56\u7565\u9009\u62e9\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.07834", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.07834", "abs": "https://arxiv.org/abs/2508.07834", "authors": ["Mubaris Nadeem", "Johannes Zenkert", "Lisa Bender", "Christian Weber", "Madjid Fathi"], "title": "KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations", "comment": "LWDA'23, KIRETT project, University of Siegen, Germany", "summary": "Over the years, the need for rescue operations throughout the world has\nincreased rapidly. Demographic changes and the resulting risk of injury or\nhealth disorders form the basis for emergency calls. In such scenarios, first\nresponders are in a rush to reach the patient in need, provide first aid, and\nsave lives. In these situations, they must be able to provide personalized and\noptimized healthcare in the shortest possible time and estimate the patients\ncondition with the help of freshly recorded vital data in an emergency\nsituation. However, in such a timedependent situation, first responders and\nmedical experts cannot fully grasp their knowledge and need assistance and\nrecommendation for further medical treatments. To achieve this, on the spot\ncalculated, evaluated, and processed knowledge must be made available to\nimprove treatments by first responders. The Knowledge Graph presented in this\narticle as a central knowledge representation provides first responders with an\ninnovative knowledge management that enables intelligent treatment\nrecommendations with an artificial intelligence-based pre-recognition of the\nsituation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u4eba\u5de5\u667a\u80fd\u7684\u521b\u65b0\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u8f85\u52a9\u6025\u6551\u4eba\u5458\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e2a\u6027\u5316\u6cbb\u7597\u5efa\u8bae\u3002", "motivation": "\u5168\u7403\u6551\u63f4\u9700\u6c42\u589e\u52a0\uff0c\u6025\u6551\u4eba\u5458\u9700\u5728\u77ed\u65f6\u95f4\u5185\u63d0\u4f9b\u4f18\u5316\u533b\u7597\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u65f6\u77e5\u8bc6\u652f\u6301\u3002", "method": "\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u6838\u5fc3\u77e5\u8bc6\u8868\u793a\uff0c\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u9884\u8bc6\u522b\u60c5\u5883\uff0c\u751f\u6210\u667a\u80fd\u6cbb\u7597\u5efa\u8bae\u3002", "result": "\u7cfb\u7edf\u80fd\u4e3a\u6025\u6551\u4eba\u5458\u63d0\u4f9b\u5b9e\u65f6\u3001\u667a\u80fd\u7684\u6cbb\u7597\u63a8\u8350\uff0c\u63d0\u5347\u6025\u6551\u6548\u7387\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u4e0eAI\u7ed3\u5408\u7684\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\u53ef\u6709\u6548\u652f\u6301\u6025\u6551\u51b3\u7b56\uff0c\u6539\u5584\u60a3\u8005\u6551\u6cbb\u6548\u679c\u3002"}}
{"id": "2508.07932", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07932", "abs": "https://arxiv.org/abs/2508.07932", "authors": ["Yi Zhai", "Zhiqiang Wei", "Ruohan Li", "Keyu Pan", "Shuo Liu", "Lu Zhang", "Jianmin Ji", "Wuyang Zhang", "Yu Zhang", "Yanyong Zhang"], "title": "\\(X\\)-evolve: Solution space evolution powered by large language models", "comment": null, "summary": "While combining large language models (LLMs) with evolutionary algorithms\n(EAs) shows promise for solving complex optimization problems, current\napproaches typically evolve individual solutions, often incurring high LLM call\ncosts. We introduce \\(X\\)-evolve, a paradigm-shifting method that instead\nevolves solution spaces \\(X\\) (sets of individual solutions) - subsets of the\noverall search space \\(S\\). In \\(X\\)-evolve, LLMs generate tunable programs\nwherein certain code snippets, designated as parameters, define a tunable\nsolution space. A score-based search algorithm then efficiently explores this\nparametrically defined space, guided by feedback from objective function\nscores. This strategy enables broader and more efficient exploration, which can\npotentially accelerate convergence at a much lower search cost, requiring up to\ntwo orders of magnitude fewer LLM calls than prior leading methods. We\ndemonstrate \\(X\\)-evolve's efficacy across three distinct hard optimization\nproblems. For the cap set problem, we discover a larger partial admissible set,\nestablishing a new tighter asymptotic lower bound for the cap set constant (\\(C\n\\ge 2.2203\\)). In information theory, we uncover a larger independent set for\nthe 15-vertex cycle graph (\\(\\mathcal{C}_{15}^{\\boxtimes 5}\\), size 19,946),\nthereby raising the known lower bound on its Shannon capacity. Furthermore, for\nthe NP-hard online bin packing problem, we generate heuristics that\nconsistently outperform standard strategies across established benchmarks. By\nevolving solution spaces, our method considerably improves search\neffectiveness, making it possible to tackle high-dimensional problems that were\npreviously computationally prohibitive.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aX-evolve\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6f14\u5316\u89e3\u7a7a\u95f4\u800c\u975e\u5355\u4e2a\u89e3\uff0c\u663e\u8457\u51cf\u5c11\u4e86LLM\u8c03\u7528\u6210\u672c\uff0c\u5e76\u5728\u591a\u4e2a\u4f18\u5316\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u6210\u679c\u3002", "motivation": "\u5f53\u524d\u7ed3\u5408LLM\u548c\u8fdb\u5316\u7b97\u6cd5\u7684\u65b9\u6cd5\u901a\u5e38\u6f14\u5316\u5355\u4e2a\u89e3\uff0c\u5bfc\u81f4LLM\u8c03\u7528\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "X-evolve\u901a\u8fc7LLM\u751f\u6210\u53ef\u8c03\u7a0b\u5e8f\uff0c\u5b9a\u4e49\u53ef\u8c03\u89e3\u7a7a\u95f4\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u5206\u6570\u7684\u641c\u7d22\u7b97\u6cd5\u9ad8\u6548\u63a2\u7d22\u8be5\u7a7a\u95f4\u3002", "result": "\u5728\u4e09\u4e2a\u4f18\u5316\u95ee\u9898\u4e0a\u53d6\u5f97\u663e\u8457\u6210\u679c\uff1a\u53d1\u73b0\u66f4\u5927\u7684cap set\u90e8\u5206\u53ef\u5bb9\u8bb8\u96c6\u3001\u63d0\u9ad8Shannon\u5bb9\u91cf\u4e0b\u9650\u3001\u751f\u6210\u4f18\u4e8e\u6807\u51c6\u7b56\u7565\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "conclusion": "X-evolve\u901a\u8fc7\u6f14\u5316\u89e3\u7a7a\u95f4\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6548\u7387\uff0c\u4e3a\u89e3\u51b3\u9ad8\u7ef4\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07941", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07941", "abs": "https://arxiv.org/abs/2508.07941", "authors": ["Olivier Poulet", "Fr\u00e9d\u00e9ric Guinand", "Fran\u00e7ois Gu\u00e9rin"], "title": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots", "comment": null, "summary": "This article proposes a collision risk anticipation method based on\nshort-term prediction of the agents position. A Long Short-Term Memory (LSTM)\nmodel, trained on past trajectories, is used to estimate the next position of\neach robot. This prediction allows us to define an anticipated collision risk\nby dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.\nThe approach is tested in a constrained environment, where two robots move\nwithout communication or identifiers. Despite a limited sampling frequency (1\nHz), the results show a significant decrease of the collisions number and a\nstability improvement. The proposed method, which is computationally\ninexpensive, appears particularly attractive for implementation on embedded\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eLSTM\u77ed\u671f\u9884\u6d4b\u7684\u78b0\u649e\u98ce\u9669\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574DQN\u7684\u5956\u52b1\u51cf\u5c11\u78b0\u649e\u3002", "motivation": "\u5728\u65e0\u901a\u4fe1\u6216\u6807\u8bc6\u7684\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u51cf\u5c11\u673a\u5668\u4eba\u78b0\u649e\u5e76\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528LSTM\u9884\u6d4b\u673a\u5668\u4eba\u4f4d\u7f6e\uff0c\u52a8\u6001\u8c03\u6574DQN\u7684\u5956\u52b1\u3002", "result": "\u57281Hz\u91c7\u6837\u9891\u7387\u4e0b\uff0c\u78b0\u649e\u6b21\u6570\u663e\u8457\u51cf\u5c11\uff0c\u7a33\u5b9a\u6027\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5b9e\u73b0\u3002"}}
{"id": "2508.07950", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.07950", "abs": "https://arxiv.org/abs/2508.07950", "authors": ["Chen Shen", "Wanqing Zhang", "Kehan Li", "Erwen Huang", "Haitao Bi", "Aiying Fan", "Yiwen Shen", "Hongmei Dong", "Ji Zhang", "Yuming Shao", "Zengjia Liu", "Xinshe Liu", "Tao Li", "Chunxia Yan", "Shuanliang Fan", "Di Wu", "Jianhua Ma", "Bin Cong", "Zhenyuan Wang", "Chunfeng Lian"], "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "comment": "18pages, 6 figures", "summary": "Forensic cause-of-death determination faces systemic challenges, including\nworkforce shortages and diagnostic variability, particularly in high-volume\nsystems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic\nAgenT), a multi-agent AI framework that automates and standardizes death\ninvestigations through a domain-adapted large language model. FEAT's\napplication-oriented architecture integrates: (i) a central Planner for task\ndecomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a\nMemory & Reflection module for iterative refinement, and (iv) a Global Solver\nfor conclusion synthesis. The system employs tool-augmented reasoning,\nhierarchical retrieval-augmented generation, forensic-tuned LLMs, and\nhuman-in-the-loop feedback to ensure legal and medical validity. In evaluations\nacross diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI\nsystems in both long-form autopsy analyses and concise cause-of-death\nconclusions. It demonstrated robust generalization across six geographic\nregions and achieved high expert concordance in blinded validations. Senior\npathologists validated FEAT's outputs as comparable to those of human experts,\nwith improved detection of subtle evidentiary nuances. To our knowledge, FEAT\nis the first LLM-based AI agent system dedicated to forensic medicine, offering\nscalable, consistent death certification while maintaining expert-level rigor.\nBy integrating AI efficiency with human oversight, this work could advance\nequitable access to reliable medicolegal services while addressing critical\ncapacity constraints in forensic systems.", "AI": {"tldr": "FEAT\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\u7684\u81ea\u52a8\u5316\u6cd5\u533b\u6b7b\u56e0\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u9886\u57df\u9002\u5e94\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u6548\u7387\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u6cd5\u533b\u6b7b\u56e0\u9274\u5b9a\u4e2d\u7684\u52b3\u52a8\u529b\u77ed\u7f3a\u548c\u8bca\u65ad\u5dee\u5f02\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u8d1f\u8377\u7cfb\u7edf\u5982\u4e2d\u56fd\u7684\u6cd5\u533b\u4f53\u7cfb\u4e2d\u3002", "method": "FEAT\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u62ec\u4efb\u52a1\u5206\u89e3\u7684\u4e2d\u592e\u89c4\u5212\u5668\u3001\u8bc1\u636e\u5206\u6790\u7684\u4e13\u4e1a\u672c\u5730\u6c42\u89e3\u5668\u3001\u8fed\u4ee3\u4f18\u5316\u7684\u8bb0\u5fc6\u4e0e\u53cd\u601d\u6a21\u5757\uff0c\u4ee5\u53ca\u7ed3\u8bba\u5408\u6210\u7684\u5168\u5c40\u6c42\u89e3\u5668\u3002", "result": "FEAT\u5728\u591a\u6837\u5316\u7684\u4e2d\u56fd\u6848\u4f8b\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709AI\u7cfb\u7edf\uff0c\u5177\u6709\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4e13\u5bb6\u4e00\u81f4\u6027\u3002", "conclusion": "FEAT\u662f\u9996\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cd5\u533bAI\u7cfb\u7edf\uff0c\u7ed3\u5408AI\u6548\u7387\u4e0e\u4eba\u7c7b\u76d1\u7763\uff0c\u6709\u671b\u63d0\u5347\u6cd5\u533b\u670d\u52a1\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.08001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08001", "abs": "https://arxiv.org/abs/2508.08001", "authors": ["Rui Yao", "Qi Chai", "Jinhai Yao", "Siyuan Li", "Junhao Chen", "Qi Zhang", "Hao Wang"], "title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths", "comment": "Rui Yao, Qi Chai, and Jinhai Yao contributed equally to this work.\n  Corresponding authors: Qi Zhang (zhang.qi@sjtu.edu.cn) and Hao Wang\n  (haowang@hkust-gz.edu.cn)", "summary": "\"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal\nReserve, encodes implicit policy signals and strategic stances. The Federal\nOpen Market Committee strategically employs Fedspeak as a communication tool to\nshape market expectations and influence both domestic and global economic\nconditions. As such, automatically parsing and interpreting Fedspeak presents a\nhigh-impact challenge, with significant implications for financial forecasting,\nalgorithmic trading, and data-driven policy analysis. In this paper, we propose\nan LLM-based, uncertainty-aware framework for deciphering Fedspeak and\nclassifying its underlying monetary policy stance. Technically, to enrich the\nsemantic and contextual representation of Fedspeak texts, we incorporate\ndomain-specific reasoning grounded in the monetary policy transmission\nmechanism. We further introduce a dynamic uncertainty decoding module to assess\nthe confidence of model predictions, thereby enhancing both classification\naccuracy and model reliability. Experimental results demonstrate that our\nframework achieves state-of-the-art performance on the policy stance analysis\ntask. Moreover, statistical analysis reveals a significant positive correlation\nbetween perceptual uncertainty and model error rates, validating the\neffectiveness of perceptual uncertainty as a diagnostic signal.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u6790\u7f8e\u8054\u50a8\u7684Fedspeak\u5e76\u5206\u7c7b\u5176\u9690\u542b\u7684\u8d27\u5e01\u653f\u7b56\u7acb\u573a\uff0c\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u63a8\u7406\u548c\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u89e3\u7801\u6a21\u5757\uff0c\u53d6\u5f97\u4e86\u6700\u4f18\u6027\u80fd\u3002", "motivation": "Fedspeak\u4f5c\u4e3a\u7f8e\u8054\u50a8\u7684\u7b56\u7565\u6027\u8bed\u8a00\u5de5\u5177\uff0c\u5bf9\u5e02\u573a\u9884\u671f\u548c\u7ecf\u6d4e\u6761\u4ef6\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u81ea\u52a8\u89e3\u6790Fedspeak\u5bf9\u91d1\u878d\u9884\u6d4b\u548c\u653f\u7b56\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528LLM\u6846\u67b6\uff0c\u7ed3\u5408\u8d27\u5e01\u653f\u7b56\u4f20\u5bfc\u673a\u5236\u7684\u9886\u57df\u7279\u5b9a\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u89e3\u7801\u6a21\u5757\u4ee5\u8bc4\u4f30\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u5728\u653f\u7b56\u7acb\u573a\u5206\u6790\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0e\u6a21\u578b\u9519\u8bef\u7387\u663e\u8457\u6b63\u76f8\u5173\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6a21\u578b\u53ef\u9760\u6027\uff0c\u8fd8\u9a8c\u8bc1\u4e86\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u8bca\u65ad\u4fe1\u53f7\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.08007", "categories": ["cs.AI", "Computing methodologies~Description logics, Computing\n  methodologies~Ontology engineering"], "pdf": "https://arxiv.org/pdf/2508.08007", "abs": "https://arxiv.org/abs/2508.08007", "authors": ["Maurice Funk", "Marvin Grosser", "Carsten Lutz"], "title": "Fitting Description Logic Ontologies to ABox and Query Examples", "comment": "Submitted to the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR2025), 23 pages", "summary": "We study a fitting problem inspired by ontology-mediated querying: given a\ncollection\n  of positive and negative examples of\n  the form $(\\mathcal{A},q)$ with\n  $\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek\n  an ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash\nq$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for\nall negative examples.\n  We consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as\nontology languages and\n  a range of query languages that\n  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof\n(UCQs).\n  For all of the resulting fitting problems,\n  we provide\n  effective characterizations and determine the computational complexity\n  of deciding whether a fitting ontology exists. This problem turns out to be\n${\\small CO}NP$ for AQs and full CQs\n  and $2E{\\small XP}T{\\small IME}$-complete for CQs and UCQs.\n  These results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u7684\u62df\u5408\u95ee\u9898\uff0c\u786e\u5b9a\u662f\u5426\u5b58\u5728\u6ee1\u8db3\u6b63\u8d1f\u793a\u4f8b\u7684\u672c\u4f53\uff0c\u5e76\u5206\u6790\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u4e2d\u5982\u4f55\u6839\u636e\u6b63\u8d1f\u793a\u4f8b\u62df\u5408\u51fa\u5408\u9002\u672c\u4f53\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u63cf\u8ff0\u903b\u8f91ALC\u548cALCI\u4f5c\u4e3a\u672c\u4f53\u8bed\u8a00\uff0c\u6db5\u76d6\u591a\u79cd\u67e5\u8be2\u8bed\u8a00\uff08AQs\u3001CQs\u3001UCQs\uff09\uff0c\u63d0\u4f9b\u6709\u6548\u7279\u5f81\u5316\u5e76\u5206\u6790\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5bf9\u4e8eAQs\u548c\u5b8c\u6574CQs\uff0c\u95ee\u9898\u4e3aCONP\uff1b\u5bf9\u4e8eCQs\u548cUCQs\uff0c\u95ee\u9898\u4e3a2EXPTIME\u5b8c\u5168\u3002\u7ed3\u679c\u9002\u7528\u4e8eALC\u548cALCI\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4e0d\u540c\u67e5\u8be2\u8bed\u8a00\u4e0b\u7684\u672c\u4f53\u62df\u5408\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u660e\u786e\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.08053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08053", "abs": "https://arxiv.org/abs/2508.08053", "authors": ["Runchuan Zhu", "Bowen Jiang", "Lingrui Mei", "Fangkai Yang", "Lu Wang", "Haoxiang Gao", "Fengshuo Bai", "Pu Zhao", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning", "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin agentic workflows, which are structured sequences of LLM invocations\nintended to solve complex tasks. However, existing approaches often rely on\nstatic templates or manually designed workflows, which limit adaptability to\ndiverse tasks and hinder scalability. We propose AdaptFlow, a natural\nlanguage-based meta-learning framework inspired by model-agnostic meta-learning\n(MAML). AdaptFlow learns a generalizable workflow initialization that enables\nrapid subtask-level adaptation. It employs a bi-level optimization scheme: the\ninner loop refines the workflow for a specific subtask using LLM-generated\nfeedback, while the outer loop updates the shared initialization to perform\nwell across tasks. This setup allows AdaptFlow to generalize effectively to\nunseen tasks by adapting the initialized workflow through language-guided\nmodifications. Evaluated across question answering, code generation, and\nmathematical reasoning benchmarks, AdaptFlow consistently outperforms both\nmanually crafted and automatically searched baselines, achieving\nstate-of-the-art results with strong generalization across tasks and models.\nThe source code and data are available at\nhttps://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.", "AI": {"tldr": "AdaptFlow\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u901a\u7528\u5de5\u4f5c\u6d41\u521d\u59cb\u5316\u5b9e\u73b0\u5feb\u901f\u5b50\u4efb\u52a1\u9002\u5e94\uff0c\u4f18\u4e8e\u73b0\u6709\u624b\u52a8\u548c\u81ea\u52a8\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6a21\u677f\u6216\u624b\u52a8\u8bbe\u8ba1\u5de5\u4f5c\u6d41\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6848\uff1a\u5185\u5faa\u73af\u901a\u8fc7LLM\u53cd\u9988\u4f18\u5316\u5b50\u4efb\u52a1\u5de5\u4f5c\u6d41\uff0c\u5916\u5faa\u73af\u66f4\u65b0\u5171\u4eab\u521d\u59cb\u5316\u4ee5\u8de8\u4efb\u52a1\u8868\u73b0\u826f\u597d\u3002", "result": "\u5728\u95ee\u7b54\u3001\u4ee3\u7801\u751f\u6210\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "AdaptFlow\u901a\u8fc7\u8bed\u8a00\u5f15\u5bfc\u4fee\u6539\u5b9e\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u4efb\u52a1\u548c\u6a21\u578b\u3002"}}
{"id": "2508.08075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08075", "abs": "https://arxiv.org/abs/2508.08075", "authors": ["Meishen He", "Wenjun Ma", "Jiao Wang", "Huijun Yue", "Xiaoma Fan"], "title": "FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence", "comment": null, "summary": "The Dempster-Shafer theory of evidence has been widely applied in the field\nof information fusion under uncertainty. Most existing research focuses on\ncombining evidence within the same frame of discernment. However, in real-world\nscenarios, trained algorithms or data often originate from different regions or\norganizations, where data silos are prevalent. As a result, using different\ndata sources or models to generate basic probability assignments may lead to\nheterogeneous frames, for which traditional fusion methods often yield\nunsatisfactory results. To address this challenge, this study proposes an\nopen-world information fusion method, termed Full Negation Belief\nTransformation (FNBT), based on the Dempster-Shafer theory. More specially, a\ncriterion is introduced to determine whether a given fusion task belongs to the\nopen-world setting. Then, by extending the frames, the method can accommodate\nelements from heterogeneous frames. Finally, a full negation mechanism is\nemployed to transform the mass functions, so that existing combination rules\ncan be applied to the transformed mass functions for such information fusion.\nTheoretically, the proposed method satisfies three desirable properties, which\nare formally proven: mass function invariance, heritability, and essential\nconflict elimination. Empirically, FNBT demonstrates superior performance in\npattern classification tasks on real-world datasets and successfully resolves\nZadeh's counterexample, thereby validating its practical effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDempster-Shafer\u7406\u8bba\u7684\u5f00\u653e\u4e16\u754c\u4fe1\u606f\u878d\u5408\u65b9\u6cd5FNBT\uff0c\u89e3\u51b3\u4e86\u5f02\u6784\u6846\u67b6\u4e0b\u7684\u8bc1\u636e\u878d\u5408\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u6570\u636e\u6216\u6a21\u578b\u5e38\u6765\u81ea\u4e0d\u540c\u533a\u57df\u6216\u7ec4\u7ec7\uff0c\u5bfc\u81f4\u5f02\u6784\u6846\u67b6\uff0c\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u5f00\u653e\u4e16\u754c\u5224\u5b9a\u51c6\u5219\uff0c\u6269\u5c55\u6846\u67b6\u4ee5\u5bb9\u7eb3\u5f02\u6784\u5143\u7d20\uff0c\u5e76\u901a\u8fc7\u5168\u5426\u5b9a\u673a\u5236\u8f6c\u6362\u8d28\u91cf\u51fd\u6570\u3002", "result": "FNBT\u5728\u7406\u8bba\u6ee1\u8db3\u4e09\u4e2a\u6027\u8d28\uff0c\u5e76\u5728\u5b9e\u9645\u6570\u636e\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89e3\u51b3\u4e86Zadeh\u53cd\u4f8b\u3002", "conclusion": "FNBT\u4e3a\u5f02\u6784\u6846\u67b6\u4e0b\u7684\u4fe1\u606f\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08115", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08115", "abs": "https://arxiv.org/abs/2508.08115", "authors": ["Pranav Pushkar Mishra", "Mohammad Arvan", "Mohan Zalake"], "title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork", "comment": "10 pages, 1 figure, 6 tables(2 in main, 4 in appendix)", "summary": "We present TeamMedAgents, a novel multi-agent approach that systematically\nintegrates evidence-based teamwork components from human-human collaboration\ninto medical decision-making with large language models (LLMs). Our approach\nvalidates an organizational psychology teamwork model from human collaboration\nto computational multi-agent medical systems by operationalizing six core\nteamwork components derived from Salas et al.'s \"Big Five\" model: team\nleadership, mutual performance monitoring, team orientation, shared mental\nmodels, closed-loop communication, and mutual trust. We implement and evaluate\nthese components as modular, configurable mechanisms within an adaptive\ncollaboration architecture while assessing the effect of the number of agents\ninvolved based on the task's requirements and domain. Systematic evaluation of\ncomputational implementations of teamwork behaviors across eight medical\nbenchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,\nPath-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8\nevaluated datasets. Controlled ablation studies conducted on 50 questions per\nconfiguration across 3 independent runs provide mechanistic insights into\nindividual component contributions, revealing optimal teamwork configurations\nthat vary by reasoning task complexity and domain-specific requirements. Our\nablation analyses reveal dataset-specific optimal teamwork configurations,\nindicating that different medical reasoning modalities benefit from distinct\ncollaborative patterns. TeamMedAgents represents an advancement in\ncollaborative AI by providing a systematic translation of established teamwork\ntheories from human collaboration into agentic collaboration, establishing a\nfoundation for evidence-based multi-agent system design in critical\ndecision-making domains.", "AI": {"tldr": "TeamMedAgents\u5c06\u4eba\u7c7b\u56e2\u961f\u5408\u4f5c\u7684\u5fc3\u7406\u5b66\u6a21\u578b\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u533b\u7597\u51b3\u7b56\u7cfb\u7edf\uff0c\u901a\u8fc7\u516d\u5927\u6838\u5fc3\u56e2\u961f\u5408\u4f5c\u7ec4\u4ef6\u63d0\u5347LLMs\u7684\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c06\u4eba\u7c7b\u56e2\u961f\u5408\u4f5c\u7684\u7406\u8bba\u6a21\u578b\uff08\u5982Salas\u7684\u201cBig Five\u201d\uff09\u8f6c\u5316\u4e3a\u8ba1\u7b97\u6a21\u578b\uff0c\u4ee5\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u7684\u534f\u4f5c\u6548\u679c\u3002", "method": "\u901a\u8fc7\u6a21\u5757\u5316\u3001\u53ef\u914d\u7f6e\u7684\u673a\u5236\u5b9e\u73b0\u516d\u5927\u56e2\u961f\u5408\u4f5c\u7ec4\u4ef6\uff08\u5982\u56e2\u961f\u9886\u5bfc\u529b\u3001\u5171\u4eab\u5fc3\u667a\u6a21\u578b\u7b49\uff09\uff0c\u5e76\u5728\u4e0d\u540c\u533b\u7597\u4efb\u52a1\u548c\u9886\u57df\u4e2d\u8bc4\u4f30\u667a\u80fd\u4f53\u6570\u91cf\u548c\u914d\u7f6e\u7684\u5f71\u54cd\u3002", "result": "\u57288\u4e2a\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c7\u4e2a\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u4e14\u4e0d\u540c\u4efb\u52a1\u9700\u8981\u4e0d\u540c\u7684\u6700\u4f18\u56e2\u961f\u914d\u7f6e\u3002", "conclusion": "TeamMedAgents\u4e3a\u5173\u952e\u51b3\u7b56\u9886\u57df\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u534f\u4f5cAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.08127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08127", "abs": "https://arxiv.org/abs/2508.08127", "authors": ["Rui Miao", "Yixin Liu", "Yili Wang", "Xu Shen", "Yue Tan", "Yiwei Dai", "Shirui Pan", "Xin Wang"], "title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks", "comment": null, "summary": "The security of LLM-based multi-agent systems (MAS) is critically threatened\nby propagation vulnerability, where malicious agents can distort collective\ndecision-making through inter-agent message interactions. While existing\nsupervised defense methods demonstrate promising performance, they may be\nimpractical in real-world scenarios due to their heavy reliance on labeled\nmalicious agents to train a supervised malicious detection model. To enable\npractical and generalizable MAS defenses, in this paper, we propose BlindGuard,\nan unsupervised defense method that learns without requiring any\nattack-specific labels or prior knowledge of malicious behaviors. To this end,\nwe establish a hierarchical agent encoder to capture individual, neighborhood,\nand global interaction patterns of each agent, providing a comprehensive\nunderstanding for malicious agent detection. Meanwhile, we design a\ncorruption-guided detector that consists of directional noise injection and\ncontrastive learning, allowing effective detection model training solely on\nnormal agent behaviors. Extensive experiments show that BlindGuard effectively\ndetects diverse attack types (i.e., prompt injection, memory poisoning, and\ntool attack) across MAS with various communication patterns while maintaining\nsuperior generalizability compared to supervised baselines. The code is\navailable at: https://github.com/MR9812/BlindGuard.", "AI": {"tldr": "BlindGuard\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4bLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6076\u610f\u4ee3\u7406\uff0c\u65e0\u9700\u653b\u51fb\u6807\u7b7e\u6216\u5148\u9a8c\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\uff0c\u4e0d\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f\uff0c\u9700\u5f00\u53d1\u66f4\u901a\u7528\u7684\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5206\u5c42\u4ee3\u7406\u7f16\u7801\u5668\u6355\u6349\u4e2a\u4f53\u3001\u90bb\u57df\u548c\u5168\u5c40\u4ea4\u4e92\u6a21\u5f0f\uff0c\u7ed3\u5408\u566a\u58f0\u6ce8\u5165\u548c\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eBlindGuard\u80fd\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u653b\u51fb\u7c7b\u578b\uff0c\u4e14\u4f18\u4e8e\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "BlindGuard\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u901a\u7528\u7684\u65e0\u76d1\u7763\u9632\u5fa1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.08147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08147", "abs": "https://arxiv.org/abs/2508.08147", "authors": ["Yunkai Hu", "Tianqiao Zhao", "Meng Yue"], "title": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework", "comment": null, "summary": "This paper introduces a novel Large Language Models (LLMs)-assisted agent\nthat automatically converts natural-language descriptions of power system\noptimization scenarios into compact, solver-ready formulations and generates\ncorresponding solutions. In contrast to approaches that rely solely on LLM to\nproduce solutions directly, the proposed method focuses on discovering a\nmathematically compatible formulation that can be efficiently solved by\noff-the-shelf optimization solvers. Directly using LLMs to produce solutions\noften leads to infeasible or suboptimal results, as these models lack the\nnumerical precision and constraint-handling capabilities of established\noptimization solvers. The pipeline integrates a domain-aware prompt and schema\nwith an LLM, enforces feasibility through systematic validation and iterative\nrepair, and returns both solver-ready models and user-facing results. Using the\nunit commitment problem as a representative case study, the agent produces\noptimal or near-optimal schedules along with the associated objective costs.\nResults demonstrate that coupling the solver with task-specific validation\nsignificantly enhances solution reliability. This work shows that combining AI\nwith established optimization frameworks bridges high-level problem\ndescriptions and executable mathematical models, enabling more efficient\ndecision-making in energy systems", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7406\uff0c\u5c06\u7535\u529b\u7cfb\u7edf\u4f18\u5316\u573a\u666f\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u8f6c\u6362\u4e3a\u53ef\u6c42\u89e3\u7684\u6570\u5b66\u516c\u5f0f\uff0c\u5e76\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u7cfb\u7edf\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4fee\u590d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u76f4\u63a5\u4f7f\u7528LLM\u751f\u6210\u89e3\u51b3\u65b9\u6848\u5f80\u5f80\u5bfc\u81f4\u4e0d\u53ef\u884c\u6216\u6b21\u4f18\u7ed3\u679c\uff0c\u56e0\u4e3aLLM\u7f3a\u4e4f\u6570\u503c\u7cbe\u5ea6\u548c\u7ea6\u675f\u5904\u7406\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u5408LLM\u4e0e\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9886\u57df\u611f\u77e5\u63d0\u793a\u548c\u6a21\u5f0f\u7684LLM\u7ba1\u9053\uff0c\u901a\u8fc7\u7cfb\u7edf\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4fee\u590d\u786e\u4fdd\u53ef\u884c\u6027\uff0c\u751f\u6210\u53ef\u6c42\u89e3\u7684\u6570\u5b66\u516c\u5f0f\u548c\u7528\u6237\u53cb\u597d\u7684\u7ed3\u679c\u3002", "result": "\u4ee5\u673a\u7ec4\u7ec4\u5408\u95ee\u9898\u4e3a\u4f8b\uff0c\u4ee3\u7406\u751f\u6210\u4e86\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u8c03\u5ea6\u65b9\u6848\u53ca\u76ee\u6807\u6210\u672c\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408AI\u4e0e\u4f20\u7edf\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u5c06\u9ad8\u5c42\u95ee\u9898\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6570\u5b66\u6a21\u578b\uff0c\u63d0\u5347\u80fd\u6e90\u7cfb\u7edf\u51b3\u7b56\u6548\u7387\u3002"}}
