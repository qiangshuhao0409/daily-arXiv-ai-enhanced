<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 69]
- [cs.IT](#cs.IT) [Total: 24]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Structure-Aware NL-to-SQL for SFC Provisioning via AST-Masking Empowered Language Models](https://arxiv.org/abs/2601.17295)
*Xinyu Zhu,Parisa Fard Moshiri,Poonam Lohan,Burak Kantarci,Emil Janulewicz*

Main category: cs.NI

TL;DR: 本文提出AST-Masking方法，通过SQL抽象语法树进行结构感知的微调，显著提升LLM生成SQL命令的准确性和效率，用于可解释的SFC编排。


<details>
  <summary>Details</summary>
Motivation: 在动态和延迟敏感网络中，有效的SFC编排需要精确协调。强化学习虽然提升适应性，但常忽略结构化领域知识，限制了泛化能力和可解释性。LLM可将自然语言规范转换为可执行SQL命令，但传统微调方法会导致语法不一致和低效查询。

Method: 提出AST-Masking方法，这是一种结构感知的微调技术。它利用SQL抽象语法树为关键组件分配权重，强制进行语法感知学习，且不增加推理开销。该方法专注于提升LLM生成SQL命令的准确性和语法正确性。

Result: 实验表明AST-Masking显著提高了多个语言模型的SQL生成准确率。FLAN-T5达到99.6%的执行准确率，Gemma从7.5%提升到72.0%，获得最大绝对增益。这些结果证实了结构感知微调在确保语法正确和高效SQL生成方面的有效性。

Conclusion: AST-Masking方法通过结构感知的微调，有效解决了传统微调中的语法不一致问题，显著提升了LLM生成SQL命令的准确性和效率，为可解释的SFC编排提供了可靠的技术支持。

Abstract: Effective Service Function Chain (SFC) provisioning requires precise orchestration in dynamic and latency-sensitive networks. Reinforcement Learning (RL) improves adaptability but often ignores structured domain knowledge, which limits generalization and interpretability. Large Language Models (LLMs) address this gap by translating natural language (NL) specifications into executable Structured Query Language (SQL) commands for specification-driven SFC management. Conventional fine-tuning, however, can cause syntactic inconsistencies and produce inefficient queries. To overcome this, we introduce Abstract Syntax Tree (AST)-Masking, a structure-aware fine-tuning method that uses SQL ASTs to assign weights to key components and enforce syntax-aware learning without adding inference overhead. Experiments show that AST-Masking significantly improves SQL generation accuracy across multiple language models. FLAN-T5 reaches an Execution Accuracy (EA) of 99.6%, while Gemma achieves the largest absolute gain from 7.5% to 72.0%. These results confirm the effectiveness of structure-aware fine-tuning in ensuring syntactically correct and efficient SQL generation for interpretable SFC orchestration.

</details>


### [2] [Efficient Self-Learning and Model Versioning for AI-native O-RAN Edge](https://arxiv.org/abs/2601.17534)
*Mounir Bensalem,Fin Gentzen,Tuck-Wai Choong,Yu-Chiao Jhuang,Admela Jukan,Jenq-Shiou Leu*

Main category: cs.NI

TL;DR: 提出一个用于AI原生O-RAN边缘的自学习框架，实现ML模型版本管理的自动化闭环，解决当前手动更新无法跨异构多层架构扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 6G的AI原生愿景需要RAN训练、部署和持续优化数千个ML模型，但O-RAN架构虽然提供了开放接口和智能控制平面，却未指定这些模型的生命周期管理。运营商仍依赖临时的手动更新实践，无法跨异构多层架构（基站、边缘、区域和中心云）以及三个O-RAN控制环进行扩展。

Method: 提出自学习框架，包含：1）中心/区域云中的训练管道持续生成新模型，并记录资源占用、安全评分和准确度指标到共享版本库；2）更新管理器咨询版本库并应用自学习策略决定何时何地推广新模型版本；3）容器编排器跨异构工作节点实现这些决策，使多个服务（rApps、xApps、dApps）能够以最小中断获得改进的推理。

Result: 仿真结果表明，高效的RL驱动决策能够保证服务质量、有界延迟，同时平衡模型准确性、系统稳定性和弹性。

Conclusion: 该自学习框架为AI原生O-RAN边缘提供了高效的闭环版本管理，解决了当前手动模型更新无法扩展的问题，通过自动化决策和容器编排实现了跨异构架构的模型生命周期管理。

Abstract: The AI-native vision of 6G requires Radio Access Networks to train, deploy, and continuously refine thousands of machine learning (ML) models that drive real-time radio network optimization. Although the Open RAN (O-RAN) architecture provides open interfaces and an intelligent control plane, it leaves the life-cycle management of these models unspecified. Consequently, operators still rely on ad-hoc, manual update practices that can neither scale across the heterogeneous, multi-layer stack of Cell-Site, Edge-, Regional-, and Central-Cloud domains, nor across the three O-RAN control loops (real-, near-real-, and non-real-time). We present a self-learning framework that provides an efficient closed-loop version management for an AI-native O-RAN edge. In this framework, training pipelines in the Central/Regional Cloud continuously generate new models, which are cataloged along with their resource footprints, security scores, and accuracy metrics in a shared version repository. An Update Manager consults this repository and applies a self-learning policy to decide when and where each new model version should be promoted into operation. A container orchestrator then realizes these decisions across heterogeneous worker nodes, enabling multiple services (rApps, xApps, and dApps) to obtain improved inference with minimal disruption. Simulation results show that an efficient RL-driven decision-making can guarantee quality of service, bounded latencies while balancing model accuracy, system stability, and resilience.

</details>


### [3] [Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control](https://arxiv.org/abs/2601.18069)
*Haoyuan Pan,Sizhao Chen,Zhaorui Wang,Tse-Tin Chan*

Main category: cs.NI

TL;DR: 该论文提出两种基于深度强化学习的VAoI调度算法：D2SAC用于最小化平均VAoI，RS-D3SAC用于尾部风险敏感的VAoI优化，在满足传输成本约束下提升多用户无线系统的语义信息新鲜度可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有VAoI调度方法主要关注平均性能优化，忽略了随机数据包到达和不可靠信道下可能出现的罕见但严重的语义陈旧事件，这些事件会损害系统可靠性。需要同时考虑平均性能和尾部风险敏感的VAoI调度。

Method: 1. 将平均VAoI最小化问题建模为约束马尔可夫决策过程，提出基于深度扩散的Soft Actor-Critic算法（D2SAC），通过扩散去噪过程生成动作增强策略表达能力。2. 提出风险敏感的深度分布扩散Soft Actor-Critic算法（RS-D3SAC），结合扩散actor和基于分位数的分布critic，显式建模完整VAoI回报分布，通过条件风险价值进行尾部风险优化。

Result: 仿真表明：D2SAC能有效降低平均VAoI；RS-D3SAC在不牺牲平均性能的前提下，显著降低了条件风险价值，实现了尾部风险的大幅减少。分布critic主导尾部风险降低，扩散actor提供补充细化以稳定和丰富策略决策。

Conclusion: 该研究证明了深度扩散强化学习框架在VAoI调度中的有效性，特别是RS-D3SAC算法能够实现稳健和风险感知的语义信息新鲜度调度，为多用户无线系统的可靠性保障提供了有效解决方案。

Abstract: Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems.

</details>


### [4] [Accelerating Update Broadcasts Over LoRaWAN Downlink via D2D Cooperation](https://arxiv.org/abs/2601.18134)
*Anshika Singh,Siddhartha S. Borkotoky*

Main category: cs.NI

TL;DR: 提出LoRaWAN网络中基于设备协作的广播更新机制，通过已更新设备广播更新片段加速邻居设备更新，显著减少传输延迟


<details>
  <summary>Details</summary>
Motivation: LoRaWAN网络中现有广播技术由于低数据速率和占空比限制导致更新传输延迟过长，影响物联网设备的安全补丁和机器学习模型更新

Method: 提出设备级协作机制，已更新的终端设备向邻居广播少量更新片段，通过设备间协作加速整个网络的更新分发

Result: 在400节点、1公里半径、1%占空比的网络中，将10KB更新传输到边缘设备的时间从42小时减少到45分钟，大幅提升传输效率

Conclusion: 该方案为LoRaWAN物联网提供了改进安全性和高效实现边缘智能的途径，通过设备协作显著降低了广播更新的延迟

Abstract: Broadcast distribution of updates (e.g., security patches, machine learning models) from a server to end devices (EDs) is a critical requirement in the Internet of Things (IoT). In this paper, we consider the problem of reliable over-the-air broadcast of updates in Long Range Wide Area Networks (LoRaWANs). Existing broadcast techniques for LoRaWANs suffer from long delivery delays due to low data rates and duty-cycle constraints. We address this problem by proposing a device-level cooperative mechanism, in which updated EDs broadcast a few update fragments to accelerate delivery to their neighbors. We demonstrate large reductions in the delivery time compared to conventional methods. For instance, in a 400-node network spanning 1 km radius and operating at 1% duty-cycle, the proposed scheme reduces the time required to deliver a 10 kilobyte update to an ED at the network's edge from 42 hours to 45 minutes. The proposed solution thus provides a pathway toward improved security and efficient realization of edge intelligence in LoRaWAN IoT.

</details>


### [5] [Contact Plan Design For Optical Interplanetary Communications](https://arxiv.org/abs/2601.18148)
*Jason Gerard,Juan A. Fraire,Sandra Cespedes*

Main category: cs.NI

TL;DR: 本文提出了首个考虑光学终端重定向延迟的接触计划设计框架，用于光学行星际回程网络，通过MILP调度器实现比贪心算法高30%以上的网络容量。


<details>
  <summary>Details</summary>
Motivation: 空间探索任务产生的科学遥测数据量快速增长，远超现有射频基础设施容量。自由空间光学通信虽能提供数量级更高的吞吐量，但其窄波束需要精确的指向、捕获和跟踪，且现有接触计划设计框架均未考虑光学头重定向延迟，这直接减少了可用接触时间。

Method: 提出了首个PAT感知的接触计划设计框架，捕捉直接对地光学链路和两跳中继路径中的定向时间流，使用延迟/中断容忍网络卫星。引入光学网络占空比度量来量化传输时间占接触窗口的比例，揭示因重定向延迟损失的容量。采用MILP调度器进行优化。

Result: MILP调度器比贪心算法提供超过30%的网络容量提升。更重要的是，结果揭示了一个基本行为转变：当准确建模重定向延迟时，最优调度倾向于选择更少但更长的光学链路，以最大化吞吐量同时最小化重定向开销。

Conclusion: 零延迟假设会显著高估可实现的性能并产生不现实的接触计划。准确建模光学网络中的重定向延迟对于设计高效的光学行星际回程网络至关重要，本文提出的框架为未来高容量空间通信网络提供了重要设计指导。

Abstract: Space exploration missions generate rapidly increasing volumes of scientific telemetry that far exceed the capacity of today's manually scheduled, RF-based deep-space infrastructure. Free-space optical (FSO) communications promise orders of magnitude higher throughput, but their narrow beams require precise pointing, acquisition, and tracking (PAT) for link establishment and tightly synchronized contact schedules. Critically, no existing contact plan design (CPD) framework accounts for optical head retargeting delay, the time spent during coarse pointing and link acquisition before data transmission begins, which directly reduces usable contact time. Retargeting delay is the dominant impairment unique to optical networks, which induces a seconds-to-minutes-long mechanical pointing process for an optical terminal's laser from its current partner to the next receiver. This paper introduces the first PAT-aware CPD framework for optical interplanetary backhaul networks. The model captures directional temporal flows across both direct-to-Earth optical links and two-hop relay paths using delay/disruption-tolerant networking (DTN) satellites. We also introduce an optical network duty-cycle metric that quantifies the proportion of time spent transmitting to the contact window duration, exposing capacity lost to retargeting delay. Our results show that our MILP scheduler delivers over 30 percent higher network capacity than a greedy algorithm. More importantly, the results uncover a fundamental behavioral shift: when retargeting delays are modeled accurately, optimal schedules favor fewer but longer optical links that maximize throughput while minimizing retargeting overhead. These findings demonstrate that zero-delay assumptions substantially overestimate achievable performance and yield unrealistic contact plans.

</details>


### [6] [A Mechanical Wi-Fi Antenna Device for Automatic Orientation Tuning with Bayesian Optimization](https://arxiv.org/abs/2601.18256)
*Akihito Taya,Yuuki Nishiyama,Kaoru Sezaki*

Main category: cs.NI

TL;DR: 开发了一种能够自动调整方向的机械Wi-Fi天线设备，通过贝叶斯优化算法寻找最佳天线方向，实验显示天线方向可导致约70Mbps的吞吐量变化。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi接入点广泛部署但天线方向调整困难，非专业用户难以确定最佳方向，导致天线常处于无效位置，影响通信性能。

Method: 开发机械Wi-Fi天线设备实现自动方向调整，采用贝叶斯优化算法进行方向调优，并与随机搜索进行对比。

Result: 实验结果表明，在视距条件下天线方向可导致约70Mbps的吞吐量变化，贝叶斯优化比随机搜索能找到更好的配置方案。

Conclusion: 自动天线方向调整设备能有效优化Wi-Fi性能，贝叶斯优化算法在方向调优中表现出色，为解决非专业用户天线配置问题提供了实用方案。

Abstract: Wi-Fi access points have been widely deployed in homes, offices, and public spaces. Some APs allow users to adjust the antenna orientation to improve communication performance by optimizing antenna polarization. However, it is difficult for non-expert users to determine the optimal orientation, and users often leave the antenna orientation in ineffective positions. To address this issue, we developed a mechanical Wi-Fi antenna device capable of automatically tuning its orientation. Experimental results show that antenna orientation could cause a throughput variation of approximately 70 Mbps under line-of-sight conditions. Furthermore, Bayesian optimization identified better configurations than random search, demonstrating its effectiveness for orientation tuning.

</details>


### [7] [CovertComBench: The First Domain-Specific Testbed for LLMs in Wireless Covert Communication](https://arxiv.org/abs/2601.18315)
*Zhaozhi Liu,Jiaxin Chen,Yuanai Xie,Yuna Jiang,Minrui Xu,Xiao Zhang,Pan Lai,Zan Zhou*

Main category: cs.NI

TL;DR: 论文提出了CovertComBench基准测试，用于评估大语言模型在隐蔽通信任务中的能力，发现LLMs在概念理解和代码实现方面表现良好，但在满足安全约束的数学推导方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注通用推理或标准通信任务，未能充分评估LLMs在满足隐蔽通信严格检测理论约束（如Kullback-Leibler散度限制）方面的能力，需要专门的评估框架。

Method: 引入CovertComBench统一基准，涵盖隐蔽通信流程的三个维度：概念理解（MCQs）、优化推导（ODQs）和代码生成（CGQs），并在检测理论的"LLM-as-Judge"框架下分析自动评分的可靠性。

Result: 对最先进模型的广泛评估显示显著性能差异：LLMs在概念识别（81%）和代码实现（83%）方面准确率高，但在安全保证所需的高阶数学推导方面表现较差（18%-55%）。

Conclusion: 当前LLMs更适合作为实现助手而非安全约束优化的自主求解器，未来研究应关注外部工具增强以构建可信的无线AI系统。

Abstract: The integration of Large Language Models (LLMs) into wireless networks presents significant potential for automating system design. However, unlike conventional throughput maximization, Covert Communication (CC) requires optimizing transmission utility under strict detection-theoretic constraints, such as Kullback-Leibler divergence limits. Existing benchmarks primarily focus on general reasoning or standard communication tasks and do not adequately evaluate the ability of LLMs to satisfy these rigorous security constraints. To address this limitation, we introduce CovertComBench, a unified benchmark designed to assess LLM capabilities across the CC pipeline, encompassing conceptual understanding (MCQs), optimization derivation (ODQs), and code generation (CGQs). Furthermore, we analyze the reliability of automated scoring within a detection-theoretic ``LLM-as-Judge'' framework. Extensive evaluations across state-of-the-art models reveal a significant performance discrepancy. While LLMs achieve high accuracy in conceptual identification (81%) and code implementation (83%), their performance in the higher-order mathematical derivations necessary for security guarantees ranges between 18% and 55%. This limitation indicates that current LLMs serve better as implementation assistants rather than autonomous solvers for security-constrained optimization. These findings suggest that future research should focus on external tool augmentation to build trustworthy wireless AI systems.

</details>


### [8] [Integrating HAPS, LEO, and Terrestrial Networks: A Cost-Performance Study for IoT Connectivity](https://arxiv.org/abs/2601.18361)
*Jean Michel de Souza Sant'Ana,Felipe Augusto Tondo,Nurul Huda Mahmood,Aamir Mahmood*

Main category: cs.NI

TL;DR: 该研究评估了高空平台站(HAPS)和低地球轨道(LEO)卫星作为替代或补充系统增强物联网(IoT)连接的潜力，分析了不同配置下的传输擦除概率，并进行了经济分析。


<details>
  <summary>Details</summary>
Motivation: 评估HAPS和LEO卫星作为替代或补充系统来增强物联网连接性的潜力，特别是在地面网络稀疏或不可靠的场景下。

Method: 分析不同连接配置下的传输擦除概率，包括纯HAPS、纯LEO卫星以及混合架构；考虑LEO卫星移动、网关与设备间的仰角、不同衰落模型；分析LR-FHSS随机接入上行链路技术；进行部署和运营成本的经济分析。

Result: HAPS能有效补充稀疏地面网络，在特定场景下改善卫星系统性能；虽然HAPS成本较高，但与LEO和地面部署处于可比数量级；在自然灾害等特定用例中，HAPS成为传统基础设施的有竞争力替代方案。

Conclusion: HAPS和LEO卫星可作为物联网连接的有效补充系统，HAPS在特定场景下具有竞争优势，成本虽高但可接受，混合架构能提供更可靠的物联网连接解决方案。

Abstract: This work evaluates the potential of High-Altitude Platform Stations (HAPS) and Low Earth Orbit (LEO) satellites as alternative or complementary systems to enhance Internet of Things (IoT) connectivity. We first analyze the transmission erasure probability under different connectivity configurations, including only HAPS or LEO satellites, as well as hybrid architectures that integrate both aerial/spatial and terrestrial infrastructures. To make the analysis more realistic, we considered movement of LEO satellites regarding a fixed region, elevation angle between gateway and devices, and different fading models for terrestrial and non-terrestrial communication. We also analyze LR-FHSS (Long-Range Frequency Hopping Spread Spectrum) random access uplink technology as a potential use case for IoT connectivity, showing the scalability impact of the scenarios. The simulation results demonstrate that HAPS can effectively complement sparse terrestrial networks and improve the performance of satellite-based systems in specific scenarios. Furthermore, considering the deployment and operational costs, respectively, CAPEX and OPEX, the economic analysis reveals that although HAPS exhibits higher costs, these remain within a comparable order of magnitude to LEO and terrestrial deployments. In addition, specific use cases, such as natural disasters, transform HAPS into a competitive technology for conventional infrastructures.

</details>


### [9] [An LLM-Agent-Based Framework for Age of Information Optimization in Heterogeneous Random Access Networks](https://arxiv.org/abs/2601.18563)
*Fang Liu,Erchao Zhu,Jiedan Tan,Jingwen Tong,Taotao Wang,Shengli Zhang*

Main category: cs.NI

TL;DR: 提出Reflex-Core框架，基于LLM代理实现异构网络中AoI驱动的随机接入，通过"观察-反思-决策-执行"闭环机制，结合SFT和PPO优化，开发RMA协议及其优先级变体，显著降低平均AoI并提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和异构无线网络的快速发展，信息年龄(AoI)成为评估实时个性化系统性能的关键指标。现有AoI驱动的随机接入策略面临模型假设理想化、收敛慢、泛化能力差等挑战，无法满足低空经济、室内服务机器人等下一代应用需求。

Method: 提出Reflex-Core框架，基于大型语言模型(LLM)代理，设计"观察-反思-决策-执行"闭环机制，结合监督微调(SFT)和近端策略优化(PPO)实现自主接入控制。基于该框架开发了反射式多址接入(RMA)协议及其优先级变体。

Result: 实验结果表明，在所研究场景中，RMA协议相比现有基线方法平均AoI降低达14.9%，优先级版本将收敛速度提升约20%。

Conclusion: Reflex-Core框架为异构网络中AoI驱动的随机接入提供了有效解决方案，通过LLM代理的智能决策能力克服了传统方法的局限性，在性能和收敛速度方面均表现出显著优势。

Abstract: With the rapid expansion of the Internet of Things (IoT) and heterogeneous wireless networks, the Age of Information (AoI) has emerged as a critical metric for evaluating the performance of real-time and personalized systems. While AoI-based random access is essential for next-generation applications such as the low-altitude economy and indoor service robots, existing strategies, ranging from rule-based protocols to learning-based methods, face critical challenges, including idealized model assumptions, slow convergence, and poor generalization. In this article, we propose Reflex-Core, a novel Large Language Model (LLM) agent-based framework for AoI-driven random access in heterogeneous networks. By devising an "Observe-Reflect-Decide-Execute" closed-loop mechanism, this framework integrates Supervised Fine-Tuning (SFT) and Proximal Policy Optimization (PPO) to enable optimal, autonomous access control. Based on the Reflex-Core framework, we develop a Reflexive Multiple Access (RMA) protocol and a priority-based RMA variant for intelligent access control under different heterogeneous network settings. Experimental results demonstrate that in the investigated scenarios, the RMA protocol achieves up to a 14.9% reduction in average AoI compared with existing baselines, while the priority-based version improves the convergence rate by approximately 20%.

</details>


### [10] [COMETS: Coordinated Multi-Destination Video Transmission with In-Network Rate Adaptation](https://arxiv.org/abs/2601.18670)
*Yulong Zhang,Ying Cui,Zili Meng,Abhishek Kumar,Dirk Kutscher*

Main category: cs.NI

TL;DR: COMETS是一个利用信息中心网络原则的协调多目的地视频传输框架，通过范围兴趣协议和分布式网络内决策过程，在无需集中控制的情况下实现可扩展、公平和自适应的速率控制。


<details>
  <summary>Details</summary>
Motivation: 大规模视频流事件同时吸引数百万观众，给现有传输基础设施带来压力。客户端驱动的自适应对共享拥塞反应缓慢，而基于服务器的协调存在可扩展性瓶颈和单点故障问题。

Method: COMETS采用信息中心网络原则，如请求聚合和网络内状态感知，引入新颖的范围兴趣协议和分布式网络内决策过程，开发轻量级分布式优化框架指导每跳质量自适应。

Result: 广泛仿真显示，COMETS在带宽利用率、公平性和用户体验质量方面持续优于DASH、MoQ和ICN基线方法，特别是在高并发情况下表现突出。

Conclusion: COMETS代表了下一代可扩展视频传输的实用、可部署方法，通过分布式协调解决了大规模视频流传输中的关键挑战。

Abstract: Large-scale video streaming events attract millions of simultaneous viewers, stressing existing delivery infrastructures. Client-driven adaptation reacts slowly to shared congestion, while server-based coordination introduces scalability bottlenecks and single points of failure. We present COMETS, a coordinated multi-destination video transmission framework that leverages information-centric networking principles such as request aggregation and in-network state awareness to enable scalable, fair, and adaptive rate control. COMETS introduces a novel range-interest protocol and distributed in-network decision process that aligns video quality across receiver groups while minimizing redundant transmissions. To achieve this, we develop a lightweight distributed optimization framework that guides per-hop quality adaptation without centralized control. Extensive emulation shows that COMETS consistently improves bandwidth utilization, fairness, and user-perceived quality of experience over DASH, MoQ, and ICN baselines, particularly under high concurrency. The results highlight COMETS as a practical, deployable approach for next-generation scalable video delivery.

</details>


### [11] [An ISAC-ready Full-Duplex Backscatter Architecture for the mmWave IoT](https://arxiv.org/abs/2601.18727)
*Skanda Harisha,Jimmy G. D. Hester,Aline Eid*

Main category: cs.NI

TL;DR: 首个毫米波全双工反向散射标签架构，实现45米上行和200米下行通信，比现有系统远20倍且便宜100倍以上


<details>
  <summary>Details</summary>
Motivation: 毫米波通信在物联网设备中面临功耗高、成本高的挑战，限制了大规模传感系统的实际部署。需要找到低成本、高性能的毫米波连接和定位解决方案。

Method: 提出毫米波全双工反向散射标签架构，采用新型低功耗再生放大器（30dB增益，仅30mW功耗）和再生整流器（-60dBm灵敏度），集成在紧凑PCB上。

Result: 标签在45米上行距离实现10^-2误码率，在200米下行距离实现10^-1误码率，通信范围比现有系统远20倍，成本降低100倍以上。

Conclusion: 该架构为ISAC系统提供了一条真正低成本的高性能毫米波连接和定位路径，解决了毫米波硬件功耗和成本限制的实际部署问题。

Abstract: Achieving long-range, high-rate, concurrent two-way mmWave communication with power-constrained IoT devices is fundamental to scaling future ubiquitous sensing systems, yet the substantial power demands and high cost of mmWave hardware have long stood in the way of practical deployment. This paper presents the first mmWave full-duplex backscatter tag architecture, charting a genuinely low-cost path toward high-performance mmWave connectivity and localization for ISAC systems. The proposed tag operates at ranges beyond 45m on the uplink and beyond 200m on the downlink, delivering 20x the reach of state-of-the-art systems while being over 100x cheaper than existing mmWave backscatter platforms. Enabling this leap is a novel low-power regenerative amplifier that provides 30 dB of gain while consuming only 30 mW, paired with a regenerative rectifier that achieves state-of-the-art sensitivity down to -60 dBm. We integrate our circuits on a compact PCB and evaluate it across diverse uplink and downlink scenarios, where it achieves an downlink BER of $10^{-1}$ at 200 meters and a uplink BER of $10^{-2}$ at 45 meters, demonstrating resilient, high-quality communication even at extended ranges.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Online parameter estimation for the Crazyflie quadcopter through an EM algorithm](https://arxiv.org/abs/2601.17009)
*Yanhua Zhao*

Main category: cs.AI

TL;DR: 本文研究随机噪声对四旋翼无人机系统的影响，使用扩展卡尔曼滤波进行状态估计，实现线性二次高斯控制器，并应用期望最大化算法进行参数估计，比较了离线与在线参数估计的性能。


<details>
  <summary>Details</summary>
Motivation: 无人机在救援、摄影、农业、运输等领域应用广泛，但地震等灾害会破坏基础设施，使救援人员难以到达。无人机可以进入这些区域，但系统易受随机噪声影响，需要研究噪声对四旋翼无人机系统的影响并开发有效的控制与参数估计方法。

Method: 1. 在四旋翼无人机系统中添加随机噪声；2. 使用扩展卡尔曼滤波基于传感器噪声观测进行状态估计；3. 基于随机微分方程系统实现线性二次高斯控制器；4. 应用期望最大化算法进行无人机参数估计；5. 比较离线与在线参数估计方法。

Result: 在线参数估计的收敛值范围略大于离线参数估计。这表明在线参数估计方法在应对系统变化方面具有更好的适应性，但可能带来更大的估计不确定性。

Conclusion: 本文成功分析了随机噪声对四旋翼无人机系统的影响，开发了基于扩展卡尔曼滤波和线性二次高斯控制器的鲁棒控制框架，并通过期望最大化算法实现了有效的参数估计。在线参数估计方法显示出更好的适应性，为无人机在复杂环境中的应用提供了理论支持。

Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.

</details>


### [13] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

TL;DR: 成功条件化（success conditioning）精确解决了信任域优化问题，最大化策略改进同时满足χ²散度约束，约束半径由数据自动确定。


<details>
  <summary>Details</summary>
Motivation: 成功条件化（如拒绝采样+SFT、目标条件RL、决策变换器）被广泛用于改进策略，但其背后的优化问题本质一直不明确。本文旨在揭示成功条件化究竟解决了什么优化问题。

Method: 通过理论证明，将成功条件化形式化为信任域优化问题，最大化策略改进同时约束χ²散度。建立了相对策略改进、策略变化幅度和动作影响三者相等的恒等式。

Result: 证明成功条件化是保守改进算子：不会降低性能或引发危险分布偏移；失败时会通过几乎不改变策略而可观察。应用于回报阈值化实践，显示其可放大改进但可能偏离真实目标。

Conclusion: 成功条件化精确解决了具有自动确定约束半径的信任域优化问题，为这一广泛使用的技术提供了理论基础，并揭示了其保守改进特性和潜在局限性。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [14] [A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience](https://arxiv.org/abs/2601.18308)
*Geunsik Lim*

Main category: cs.AI

TL;DR: Climate RADAR是一个基于生成式AI的可靠性层，通过整合多源数据和LLM生成个性化行动建议，改进传统预警系统，提高保护行动执行率和响应速度。


<details>
  <summary>Details</summary>
Motivation: 传统预警系统虽然能快速发布警报，但往往无法触发及时的保护行动，导致可预防的损失和不公平现象。需要一种更有效的方法来将警报转化为实际行动。

Method: 整合气象、水文、脆弱性和社会数据形成综合风险指数，使用带有防护机制的LLM生成个性化建议，通过公民、志愿者和市政三个接口分发。

Result: 通过模拟、用户研究和市政试点评估显示，系统提高了保护行动执行率、减少了响应延迟、增强了可用性和信任度。

Conclusion: Climate RADAR结合预测分析、行为科学和负责任AI，推进了以人为本、透明和公平的预警系统，为符合法规要求的灾害韧性基础设施提供了实用路径。

Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.

</details>


### [15] [Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability](https://arxiv.org/abs/2601.17168)
*Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran*

Main category: cs.AI

TL;DR: 本文分析现有可解释性方法在智能体系统中的局限性，并提出专门针对智能体系统设计的新可解释性技术方向，以确保智能体AI系统的安全可靠部署。


<details>
  <summary>Details</summary>
Motivation: 智能体系统与传统机器学习模型在架构和部署上有根本差异，引入了独特的安全挑战（如目标错位、决策错误累积、多智能体协调风险），需要嵌入可解释性和可追溯性设计。现有针对静态模型的可解释性方法在应用于智能体系统时存在局限性。

Method: 评估现有可解释性方法在智能体系统中的适用性和局限性，识别其在提供智能体决策洞察方面的不足，提出专门针对智能体系统设计的新可解释性技术方向。

Result: 发现现有可解释性方法难以应对智能体系统的时间动态性、决策累积性和上下文依赖行为，需要新的分析方法来提供有意义的决策洞察。

Conclusion: 需要开发专门针对智能体系统的可解释性技术，在智能体生命周期的各个阶段（目标形成、环境交互、结果评估）嵌入监督机制，以确保智能体AI系统的安全和可问责部署。

Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.

</details>


### [16] [Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction](https://arxiv.org/abs/2601.17188)
*Swapn Shah,Wlodek Zadrozny*

Main category: cs.AI

TL;DR: Tensor Logic框架通过三个实验验证了符号逻辑与张量运算的等价性：在圣经家谱上实现传递闭包计算、在嵌入空间实现零样本组合推理、在知识图谱上验证矩阵组合实现多跳推理。


<details>
  <summary>Details</summary>
Motivation: 统一符号推理与神经网络是AI的核心挑战。符号系统可靠可解释但缺乏可扩展性，神经网络可学习但缺乏透明度。Tensor Logic提出逻辑规则与爱因斯坦求和数学等价，为统一提供了理论路径。

Method: 通过三个实验验证Tensor Logic框架：1) 在圣经家谱图上计算传递闭包，证明递归Datalog规则与迭代张量收缩的等价性；2) 训练具有可学习变换矩阵的神经网络，在嵌入空间实现推理；3) 在FB15k-237知识图谱上验证关系矩阵公式R_r = E^⊤ A_r E，测试链接预测和组合推理能力。

Result: 1) 在包含1,972个体和1,727个亲子关系的圣经家谱上，经过74次迭代发现33,945个祖先关系；2) 成功实现零样本组合推理；3) 在FB15k-237上获得标准链接预测MRR 0.3068，在组合推理基准上获得MRR 0.3346，证明矩阵组合可实现多跳推理而无需直接训练样本。

Conclusion: Tensor Logic框架通过实证验证了符号逻辑与张量运算的数学等价性，为统一符号推理与神经网络提供了可行路径，实现了可扩展、可学习的符号推理系统。

Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.

</details>


### [17] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

TL;DR: 利用真实世界电子健康记录数据开发生成式模拟器，能够基于患者历史生成高保真度的未来临床轨迹


<details>
  <summary>Details</summary>
Motivation: 模拟在临床医学中具有变革潜力，可用于个性化治疗规划和虚拟临床试验，但模拟患者轨迹面临生物和社会文化因素复杂的挑战

Method: 基于超过2亿条临床记录预训练生成式模拟器模型，以患者历史为输入，合成细粒度、真实的未来临床轨迹

Result: 模型生成高保真未来时间线，与真实患者数据在事件发生率、实验室检测结果和时间动态上高度匹配，未来事件概率估计准确，观察与预期比值接近1.0

Conclusion: 揭示了电子健康记录中真实世界数据的未开发价值，并引入了可扩展的临床护理计算机模拟框架

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [18] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

TL;DR: 多智能体系统在固定推理预算下存在帮助、饱和或崩溃三种状态，本文提出一个包含上下文窗口、通信损失和共享故障的最小可校准理论，揭示了深度树结构的相变条件和预算协同阈值。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统理论上能提高可靠性，但在固定推理预算下常常出现帮助有限、饱和甚至崩溃的现象。现有研究缺乏统一的理论框架来解释这些不同状态，特别是如何量化通信损失、共享故障和上下文窗口限制对系统性能的影响。

Method: 构建一个包含三个核心约束的最小理论模型：有限上下文窗口W、有损通信γ(m)和共享故障相关性ρ。将每个叶子智能体建模为计算-性能缩放指数β，分析深度b叉树结构中的多数聚合机制。通过标量α_ρ（结合γ(m)、ρ和分支因子b）预测相变条件，推导组织指数s和预算协同阈值。

Result: 理论预测存在尖锐的相变：当α_ρ超过阈值时，微弱信号被放大到非平凡固定点；否则被淹没为随机水平。预算协同（优于同等预算下单智能体）发生在s>β时，得到闭式计算分配规则和预算阈值。验证了合成模拟中的相变边界，并解释了近期大规模LLM智能体系统扩展研究中的主要瓶颈。

Conclusion: 多智能体系统的性能受限于上下文窗口、通信损失和共享故障三个核心约束。通过理论框架可以预测相变条件和预算协同阈值，为智能体系统设计提供量化指导，包括计算分配规则和组织结构优化，以在有限预算下最大化系统可靠性。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [19] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

TL;DR: TheoremForge是一个低成本的形式化数学数据合成框架，通过解耦任务流程和回收失败轨迹中的有效信号，显著提高了形式化数学数据的生成效率。


<details>
  <summary>Details</summary>
Motivation: 形式化数学中智能体工作流的高成本阻碍了大规模数据合成，导致开源语料库稀缺，需要开发更经济高效的数据生成方法。

Method: 将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明修正和证明草图。采用解耦提取策略从全局失败轨迹中回收有效训练信号。

Result: 在2000个问题的基准测试中，TheoremForge达到12.6%的验证率（优于8.6%的基线），每个成功轨迹平均成本仅0.481美元，证明生成数据产量提高1.6倍。

Conclusion: TheoremForge为训练未来专家模型提供了一个可扩展的数据飞轮框架，能有效解决形式化数学数据稀缺问题。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [20] [The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability](https://arxiv.org/abs/2601.17335)
*Angshul Majumdar*

Main category: cs.AI

TL;DR: 该论文证明AGI无法获得独立于分布的理论定义，无法实现通用鲁棒性、无界泛化或可计算自验证，强AGI声明在没有明确形式化索引时是无定义的。


<details>
  <summary>Details</summary>
Motivation: 研究AGI是否具有支持存在性、鲁棒性或自验证绝对声明的连贯理论定义，探讨强AGI声明的理论基础是否成立。

Method: 将AGI形式化为基于分布、资源受限的语义谓词，通过公理化框架进行分析，使用Rice风格和哥德尔-塔斯基论证等数学工具。

Result: 1) 通用性是关系性的，无分布独立AGI概念；2) 任务分布的微小扰动可通过悬崖集使AGI属性失效；3) 有限资源下无法实现跨任务族的无界泛化；4) AGI无法通过可计算程序（包括自验证）完全可靠认证。

Conclusion: 强AGI声明在没有明确形式化索引时是无定义的，AI的经验进展不意味着可实现自验证通用智能，依赖内部自认证的递归自我改进方案是有问题的。

Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.

</details>


### [21] [Are We Evaluating the Edit Locality of LLM Model Editing Properly?](https://arxiv.org/abs/2601.17343)
*Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文指出现有模型编辑特异性评估协议存在不足，提出新的评估协议，能更敏感地衡量知识保留能力


<details>
  <summary>Details</summary>
Motivation: 模型编辑需要平衡编辑效果（成功注入目标知识）和特异性（保留现有非目标知识），但现有特异性评估协议存在根本性问题，无法有效评估不同方法的特异性表现

Method: 系统分析现有特异性评估协议的三个基本问题，提出新的构造性评估协议，消除开放LLM与确定答案假设的冲突，避免查询无关的流畅性偏差，并能在近乎连续空间中平滑调整评估严格度

Result: 实验表明，新协议产生的指标对特异性正则化强度变化更敏感，与正则化强度强相关，能更细粒度地区分不同方法的知识保留能力

Conclusion: 提出的新评估协议解决了现有特异性评估的不足，为模型编辑方法的知识保留能力提供了更准确、敏感的评估框架

Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.

</details>


### [22] [Multi-Agent Learning Path Planning via LLMs](https://arxiv.org/abs/2601.17346)
*Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu*

Main category: cs.AI

TL;DR: 提出基于多智能体协作的MALPP框架，利用LLM为高等教育提供透明、可解释的个性化学习路径规划


<details>
  <summary>Details</summary>
Motivation: 现有智能导学系统中的学习路径规划方法缺乏透明度、适应性和以学习者为中心的可解释性，需要解决这些问题以实现更有效的个性化学习

Method: 提出多智能体学习路径规划框架，包含三个基于LLM的任务特定智能体：学习者分析智能体、路径规划智能体和反思智能体，通过结构化提示和预定义规则协作

Result: 在MOOCCubeX数据集上使用7个LLM进行实验，MALPP在路径质量、知识序列一致性和认知负荷对齐方面显著优于基线模型

Conclusion: 该研究为教育领域可信赖、可解释AI的发展做出贡献，展示了基于LLM的以学习者为中心的自适应教学的规模化方法

Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.

</details>


### [23] [Auditing Disability Representation in Vision-Language Models](https://arxiv.org/abs/2601.17348)
*Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya*

Main category: cs.AI

TL;DR: 研究视觉语言模型在描述残疾人图像时的解释偏移问题，发现引入残疾上下文会降低解释保真度，产生推测性推断、情感退化等负面效应，这些效应在种族和性别维度上被放大，但针对性提示和偏好微调可有效改善。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型越来越多地应用于社会敏感领域，但它们在残疾相关方面的行为尚未得到充分探索。当前模型在描述人物中心图像时，经常从基于证据的事实描述转向包含超出可观察视觉证据的推断的解释偏移，这需要系统性的分析。

Method: 引入基于中性提示和残疾情境化提示配对的基准，在零样本设置下评估15个最先进的开放和闭源视觉语言模型，涵盖9个残疾类别。评估框架以解释保真度为核心目标，结合标准文本指标（捕捉情感退化、社会关注度和响应长度变化）和LLM作为评判协议，并由有残疾生活经验的标注者验证。

Result: 引入残疾上下文会一致性地降低解释保真度，导致解释偏移，表现为推测性推断、叙事阐述、情感退化和缺陷导向的框架。这些效应在种族和性别维度上进一步放大。针对性提示和偏好微调能有效提高解释保真度并显著减少解释偏移。

Conclusion: 视觉语言模型在描述残疾人图像时存在系统性偏见，表现为解释偏移和情感退化，这些偏见在不同人口统计维度上被放大。通过针对性干预措施可以改善模型的解释保真度，减少有害的推断和偏见。

Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.

</details>


### [24] [A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models](https://arxiv.org/abs/2601.17426)
*Zhengqing Zang,Yuqi Ding,Yanmei Gu,Changkai Song,Zhengkai Yang,Guoping Du,Junbo Zhao,Haobo Wang*

Main category: cs.AI

TL;DR: LLMs在逻辑推理中表现出从传统逻辑向现代逻辑的演变趋势，模型规模、思维链和基础模型是影响这一转变的关键因素。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否像人类逻辑一样，从直觉驱动的推理演变为严格的逻辑系统，使用存在导入作为探针来评估三段论推理。

Method: 使用存在导入作为探针，在传统逻辑和现代逻辑框架下评估三段论推理。通过在新构建的三段论数据集上测试SOTA LLMs，分析模型规模、思维链和基础模型的影响。

Result: 发现三个关键结果：(1) 模型规模扩展促进向现代逻辑的转变；(2) 思维链是超越参数扩展的高效加速器；(3) 基础模型决定这种转变的容易程度和稳定性。

Conclusion: LLMs在逻辑推理中确实表现出从传统逻辑向现代逻辑的演变，模型规模、思维链和基础模型是影响这一转变的核心因素，为理解LLMs的逻辑推理能力提供了新视角。

Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.

</details>


### [25] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

TL;DR: Lattice是一个自构建、持续改进的AI安全护栏框架，通过两阶段迭代优化实现自适应防护，在ProsocialDialog数据集上达到91% F1分数，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全护栏使用静态规则，无法适应新威胁和部署环境变化，需要能够自我构建和持续改进的适应性框架。

Method: 采用两阶段框架：1) 构建阶段通过迭代模拟和优化从标注示例创建初始护栏；2) 持续改进阶段通过风险评估、对抗测试和整合自主适应已部署护栏。

Result: 在ProsocialDialog数据集上达到91% F1分数，比关键词基线高43个百分点，比LlamaGuard高25个百分点，比NeMo高4个百分点；持续改进阶段通过闭环优化在跨域数据上实现7个百分点F1提升。

Conclusion: Lattice框架证明通过迭代优化可以自构建有效的AI安全护栏，为适应性AI安全防护提供了可行方案。

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [26] [Cognitive Platform Engineering for Autonomous Cloud Operations](https://arxiv.org/abs/2601.17542)
*Vinoth Punniyamoorthy,Nitin Saksena,Srivenkateswara Reddy Sankiti,Nachiappan Chockalingam,Aswathnarayan Muthukrishnan Kirubakaran,Shiva Kumar Reddy Carimireddy,Durgaraman Maruthavanan*

Main category: cs.AI

TL;DR: 论文提出认知平台工程新范式，通过四层参考架构整合感知、推理和自主行动，实现云原生系统的智能运维


<details>
  <summary>Details</summary>
Motivation: 传统DevOps自动化难以应对云原生系统的规模和动态性，规则驱动方法导致响应式运维、修复延迟和依赖人工经验

Method: 提出认知平台工程范式，设计四层参考架构：数据收集层、智能推理层、策略驱动编排层和人工体验层，构建持续反馈循环；基于Kubernetes、Terraform、Open Policy Agent和ML异常检测实现原型

Result: 原型系统在平均解决时间、资源效率和合规性方面均有改进，证明将智能嵌入平台运维可实现弹性、自调整和意图对齐的云环境

Conclusion: 认知平台工程是下一代平台运维范式，未来研究方向包括强化学习、可解释治理和可持续自管理云生态系统

Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.

</details>


### [27] [JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research](https://arxiv.org/abs/2601.17564)
*Aadam,Monu Verma,Mohamed Abdel-Mottaleb*

Main category: cs.AI

TL;DR: JaxARC是一个基于JAX实现的高性能强化学习环境，专门用于ARC推理任务，相比Gymnasium实现了38-5439倍的加速，支持大规模并行计算。


<details>
  <summary>Details</summary>
Motivation: 现有的Gymnasium-based RL环境在ARC任务上存在计算瓶颈，限制了实验规模，需要高性能环境来支持大规模强化学习研究。

Method: 使用JAX实现功能化、无状态的架构，支持大规模并行计算，提供多种ARC数据集、灵活的动作空间、可组合的包装器和配置驱动的可复现性。

Result: 在相同批量大小下，相比Gymnasium实现了38-5439倍的加速，峰值吞吐量达到7.9亿步/秒，使之前计算上不可行的大规模RL研究成为可能。

Conclusion: JaxARC是一个开源的高性能ARC RL环境，解决了现有环境的计算瓶颈问题，为大规模强化学习研究提供了可行的计算平台。

Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.

</details>


### [28] [Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design](https://arxiv.org/abs/2601.17587)
*Azza Fadhel,Nathaniel W. Zuckschwerdt,Aryan Deshwal,Susmita Bose,Amit Bandyopadhyay,Jana Doppa*

Main category: cs.AI

TL;DR: 该论文提出了一种结合AI驱动自适应实验设计与领域知识的方法，用于高效发现金属增材制造的可行参数配置，成功应用于NASA开发的GRCop-42合金打印，显著减少了实验时间和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 金属合金增材制造的参数配置是一个具有挑战性的问题，因为输入参数（如激光功率、扫描速度）与打印输出质量之间存在复杂关系。传统的试错方法效率低下，因为每个配置的验证都需要大量物理和人力资源，且配置空间非常大。

Method: 该方法结合了AI驱动的自适应实验设计与领域知识，通过从过去的实验中构建代理模型，在每次迭代中智能选择一小批输入配置进行验证，从而高效发现可行的参数配置。

Result: 在定向能量沉积工艺中应用于NASA开发的GRCop-42合金打印，在三个月内获得了多个无缺陷输出，大幅减少了结果获取时间和资源消耗，相比领域科学家数月的手动实验（无成功结果）有显著改进。首次在现成的红外激光平台上实现了高质量的GRCop-42制造。

Conclusion: 该方法成功解决了金属增材制造的参数配置挑战，通过AI驱动的自适应实验设计大幅提高了效率，使关键合金GRCop-42的制造更加民主化，为航空航天应用的成本效益高、分散化生产铺平了道路。

Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.

</details>


### [29] [Intelligence Requires Grounding But Not Embodiment](https://arxiv.org/abs/2601.17588)
*Marcus Ma,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 论文认为智能需要"接地"而非"具身"，论证了非具身但接地的智能体可以实现智能的四个关键属性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的进步，学界重新争论"具身化是否是智能的必要条件"。本文旨在澄清这一争议，提出智能真正需要的是"接地"而非"具身化"本身。

Method: 首先定义智能为具备四个属性：动机、预测能力、因果理解、经验学习。然后论证每个属性都可以通过非具身但接地的智能体实现。最后通过数字环境中LLM智能体的思想实验来支持论点。

Result: 论证表明接地是智能的必要条件，而具身化只是实现接地的一种方式。非具身的智能体（如数字环境中的LLM）通过接地同样可以实现智能。

Conclusion: 智能需要的是接地而非具身化。具身化只是实现接地的一种途径，但非具身的智能体通过适当的接地机制同样可以具备智能。

Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.

</details>


### [30] [Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context](https://arxiv.org/abs/2601.17642)
*Zhihao Zhang,Liting Huang,Guanghao Wu,Preslav Nakov,Heng Ji,Usman Naseem*

Main category: cs.AI

TL;DR: Health-ORSC-Bench：首个大规模医疗AI安全基准，系统评估大语言模型在医疗场景中的过度拒绝和安全完成能力，揭示当前模型在安全性和实用性之间的平衡困境。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI安全对齐主要依赖二元拒绝边界，导致对良性查询的过度拒绝或对有害查询的不安全合规。现有基准仅评估极端情况，无法衡量模型在双用途或边界查询中提供安全高层指导的能力。

Method: 构建包含31,920个良性边界提示的Health-ORSC-Bench基准，涵盖7个健康类别（如自残、医疗错误信息）。采用自动化流程结合人工验证，在不同意图模糊度级别测试模型。评估了30个最先进的LLM，包括GPT-5和Claude-4。

Result: 安全优化模型对"困难"良性提示的拒绝率高达80%，而领域特定模型常为实用性牺牲安全性。模型家族和规模显著影响校准：大型前沿模型（如GPT-5、Llama-4）表现出"安全悲观主义"和更高过度拒绝，比小型或MoE模型（如Qwen-3-Next）更保守。

Conclusion: 当前LLM难以平衡拒绝与合规，Health-ORSC-Bench为校准下一代医疗AI助手提供了严格标准，推动实现细致、安全且有用的完成能力。代码和数据将在接受后发布。

Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \emph{over-refusal} of benign queries or \emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \textbf{Over-Refusal} and \textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\% of "Hard" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit "safety-pessimism" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \textcolor{red}{Warning: Some contents may include toxic or undesired contents.}

</details>


### [31] [DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories](https://arxiv.org/abs/2601.17678)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 提出DIML框架，通过观察自利学习代理的战略交互轨迹，逆向学习未知的激励生成机制，包括非结构化（如神经网络）机制，支持反事实预测并具有可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如逆向博弈论和多智能体逆向强化学习通常只能推断结构化机制内的效用/奖励参数，而无法处理非结构化机制；可微分机制设计是前向优化而非从行为中推断。需要一种能从观察到的战略交互中逆向学习任意机制的方法。

Method: 提出DIML（Differentiable Inverse Mechanism Learning）框架：基于似然的方法，通过多智能体学习动力学模型进行微分，使用候选机制生成预测观察动作所需的反事实收益。在条件logit响应模型下建立收益差异的可识别性，并在标准正则条件下证明最大似然估计的统计一致性。

Result: DIML在非结构化神经网络机制、拥堵收费、公共物品补贴和大规模匿名博弈等模拟交互中可靠地恢复了可识别的激励差异，支持反事实预测。在小环境中性能媲美表格枚举oracle，在大规模（百参与者）环境中具有良好的收敛性。

Conclusion: DIML框架成功实现了从观察到的战略交互中逆向学习激励生成机制，包括非结构化机制，为机制逆向学习提供了有效解决方案，具有实际应用潜力。

Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.

</details>


### [32] [SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL](https://arxiv.org/abs/2601.17699)
*Harper Hua,Zhen Han,Zhengyuan Shen,Jeremy Lee,Patrick Guan,Qi Zhu,Sullam Jeoung,Yueyan Chen,Yunfei Bai,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.AI

TL;DR: SQL-Trail：一个用于Text-to-SQL的多轮强化学习代理框架，通过迭代交互和反馈机制显著提升性能，超越单次生成方法


<details>
  <summary>Details</summary>
Motivation: 当前LLM在Text-to-SQL生成上仍与人类专家存在显著差距，主要原因是单次生成范式缺乏人类自然使用的迭代推理、模式探索和错误修正行为

Method: 引入SQL-Trail多轮RL代理框架，通过与数据库环境交互和执行反馈迭代优化预测。核心包括：自适应轮次预算分配机制（根据问题难度调整交互深度）和复合奖励面板（联合激励SQL正确性和高效探索）

Result: 在多个基准测试中达到新的SOTA，数据效率比之前单次RL方法高18倍。7B和14B模型平均超越更大规模专有系统5%，展示了交互式代理工作流的有效性

Conclusion: 交互式、代理式工作流对于稳健的Text-to-SQL生成非常有效，多轮RL框架能够显著缩小AI系统与人类专家在复杂SQL生成任务上的差距

Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.

</details>


### [33] [The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data](https://arxiv.org/abs/2601.17717)
*Kaituo Zhang,Mingzhi Hu,Hoang Anh Duy Le,Fariha Kabir Torsha,Zhimeng Jiang,Minh Khai Bui,Chia-Yuan Chang,Yu-Neng Chuang,Zhen Xiong,Ying Lin,Guanchu Wang,Na Zou*

Main category: cs.AI

TL;DR: 本文提出LLM数据审计框架，系统评估LLM生成多模态合成数据的质量与可信度，指出当前评估方法的不足并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: LLM已成为生成多模态数据的有力工具，但确保合成数据的高质量仍是关键挑战。现有研究主要关注生成方法，缺乏对数据质量的直接关注，且多为单模态研究，缺少跨模态的统一视角。

Method: 提出LLM数据审计框架：1)描述LLM如何生成六种不同模态的数据；2)从质量和可信度两个维度系统分类合成数据的内在评估指标；3)分析各模态代表性生成方法的实验评估；4)基于发现提出改进建议；5)概述合成数据在不同模态中的实际应用方法。

Result: 通过该评估体系分析发现，当前评估实践存在显著缺陷。框架识别了现有评估方法的不足，并为改进数据生成评估提供了具体建议。

Conclusion: LLM数据审计框架为评估多模态合成数据提供了系统方法，将关注点从依赖下游任务性能的外在评估转向数据本身的内在属性，有助于提升合成数据质量评估的标准化和有效性。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.

</details>


### [34] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

TL;DR: EntWorld：首个大规模企业级工作流基准测试，包含6个企业领域的1756个任务，揭示当前AI代理在企业场景中的能力差距（成功率仅47.61%）


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型基准主要针对消费级场景（如电商、旅行预订），无法捕捉企业工作流的复杂性和严谨性。企业系统具有高密度用户界面、严格业务逻辑约束和精确状态一致性要求等独特挑战，当前通用代理在这些场景中表现不佳。

Method: 1. 提出基于模式的任务生成框架，直接从底层数据库模式逆向工程业务逻辑，合成真实的长时程工作流；2. 采用基于SQL的确定性验证机制，用严格的状态转换验证替代模糊的视觉匹配；3. 构建包含1756个任务、覆盖CRM、ITIL、ERP等6个企业领域的基准测试。

Result: 最先进模型（如GPT-4.1）在EntWorld上的成功率仅为47.61%，远低于人类表现。这表明当前代理能力在企业场景中存在显著差距，需要开发领域特定的企业级数字代理。

Conclusion: EntWorld填补了企业级基准测试的空白，为下一代企业就绪数字代理的开发和评估提供了严谨的测试平台。研究强调了开发专门针对企业工作流复杂性的领域特定代理的必要性。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [35] [ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents](https://arxiv.org/abs/2601.17735)
*Kyungho Kim,Geon Lee,Juyeon Kim,Dongwon Choi,Shinhwan Kang,Kijung Shin*

Main category: cs.AI

TL;DR: ReFuGe是一个基于LLM代理的框架，用于从关系数据库中自动生成有信息量的关系特征，以提升预测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 关系数据库在现实网络应用中至关重要，但针对RDB的预测任务面临挑战：需要处理复杂模式、探索组合爆炸的特征空间，且缺乏明确监督。

Method: ReFuGe框架包含三个专门化的LLM代理：模式选择代理识别相关表和列；特征生成代理从选定模式生成多样化候选特征；特征过滤代理通过推理和验证进行筛选。三者在一个迭代反馈循环中运行直至性能收敛。

Result: 在RDB基准测试上的实验表明，ReFuGe显著提升了多种RDB预测任务的性能。

Conclusion: ReFuGe通过LLM代理的协同工作，能够有效解决关系数据库特征生成的挑战，为RDB预测任务提供强大的特征增强能力。

Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.

</details>


### [36] [Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems](https://arxiv.org/abs/2601.17744)
*Amjad Fatmi*

Main category: cs.AI

TL;DR: Faramesh是一个协议无关的执行控制平面，通过不可绕过的行动授权边界强制实施执行时授权，为自主代理系统提供可执行、可预测的治理。


<details>
  <summary>Details</summary>
Motivation: 自主代理系统越来越多地触发现实世界的副作用（部署基础设施、修改数据库、移动资金、执行工作流），但大多数代理堆栈缺乏强制性的执行检查点，无法在行动改变现实之前确定性地允许、拒绝或延迟行动。

Method: 引入Faramesh系统，通过不可绕过的行动授权边界强制实施执行时授权。系统将代理意图规范化为规范行动表示，根据策略和状态确定性地评估行动，并生成决策工件（允许/延迟/拒绝），执行器必须在执行前验证该决策。系统设计为框架和模型无关，支持多代理和多租户部署，独立于传输协议。

Result: Faramesh提供了基于规范行动哈希的决策中心、仅追加的溯源日志，支持可审计性、验证和确定性重放，而无需重新运行代理推理。这些原语实现了可执行、可预测的自主执行治理，避免了与编排层的隐藏耦合或仅观察性方法。

Conclusion: Faramesh为自主代理系统提供了强制性的执行控制机制，通过协议无关的设计和不可绕过的授权边界，实现了现实世界行动的可预测治理，同时保持了系统灵活性和可审计性。

Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.

</details>


### [37] [HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis](https://arxiv.org/abs/2601.17767)
*Rajan Das Gupta,Xiaobin Wu,Xun Liu,Jiaqi He*

Main category: cs.AI

TL;DR: 提出混合集成框架，结合CNN、LSTM深度学习与KNN、XGB传统机器学习，通过投票机制提升心血管疾病预测性能


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，传统预测模型难以泛化到异构数据集和复杂生理模式，需要智能数据驱动的诊断工具

Method: 混合集成框架整合CNN和LSTM深度学习架构，以及KNN和XGB传统机器学习算法，采用集成投票机制

Result: 在两个Kaggle数据集上分别达到82.30%和97.10%的准确率，在精确率、召回率和F1分数上均有稳定提升

Conclusion: 混合AI框架对心血管疾病预测具有鲁棒性和临床潜力，支持联合国可持续发展目标3，促进早期诊断和预防

Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.

</details>


### [38] [Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789)
*Yiming Su,Kunzhao Xu,Yanjie Gao,Fan Yang,Cheng Li,Mao Yang,Tianyin Xu*

Main category: cs.AI

TL;DR: NSVIF是一个神经符号框架，用于验证LLM输出是否遵循指令，将指令遵循验证建模为约束满足问题，显著优于基于LLM的方法并提供可解释反馈。


<details>
  <summary>Details</summary>
Motivation: LLM并不总是遵循指令，这种违规在基于LLM的智能体工作流中会传播和放大，导致任务失败和系统事故，因此需要一种通用、通用的验证器来检测指令遵循情况。

Method: NSVIF将指令遵循验证建模为约束满足问题，将用户指令建模为约束，包括逻辑和语义约束，通过统一求解器协调逻辑推理和语义分析来解决约束。

Result: 在VIFBENCH基准测试中，NSVIF显著优于基于LLM的方法，提供可解释反馈，且NSVIF的反馈无需后训练即可帮助提高LLM的指令遵循能力。

Conclusion: NSVIF是一个有效的神经符号框架，能够可靠地验证LLM输出是否遵循指令，为解决LLM指令遵循问题提供了通用解决方案。

Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.

</details>


### [39] [MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing](https://arxiv.org/abs/2601.17814)
*Haoxuan Ma,Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: MMR-Bench是一个用于评估多模态大语言模型路由选择的基准测试，通过控制成本预算和任务多样性，帮助选择最适合特定查询的模型，提高部署效率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在架构、对齐策略和效率方面存在异质性，没有单一模型在所有任务上都表现最优。实际部署中，工作负载从轻量级OCR到复杂多模态推理不等，使用单一模型要么在简单任务上过度计算，要么在困难任务上牺牲准确性。需要一种查询级别的模型选择（路由）方法来解决这一矛盾。

Method: 提出了MMR-Bench基准测试，包括：(1) 具有模态感知输入和可变计算预算的控制环境；(2) 涵盖OCR、通用VQA和多模态数学推理的广泛视觉语言任务套件；(3) 强大的单模型参考、理论上限和代表性路由策略。通过该基准测试，研究如何利用多模态信号改进路由质量。

Result: 实验表明，结合多模态信号能显著提高路由质量，使路由系统在仅使用最强单模型约33%成本的情况下，就能超越其准确性。此外，在部分模型和任务上训练的策略能够零样本泛化到新数据集和纯文本基准测试，无需重新调整。

Conclusion: MMR-Bench为研究自适应多模态模型选择和高效MLLM部署提供了基础框架，证明了多模态路由在实际部署中的可行性和效率优势。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.

</details>


### [40] [RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance](https://arxiv.org/abs/2601.17826)
*Siyuan Yang,Xihan Bian,Jiayin Tang*

Main category: cs.AI

TL;DR: RegGuard是一个工业级AI助手，用于自动化解释异构监管文本并与内部公司政策对齐，通过HiSACC和ReLACE技术提高检索和生成质量，减少幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 监管更新日益频繁复杂，跨国制药公司面临巨大合规负担。合规团队需要手动解读不同司法管辖区、格式和机构的演变规则，成本高且容易出错。

Method: 系统通过安全管道摄入异构文档源，包含两个核心组件：HiSACC（分层语义聚合上下文分块）将长文档语义分段为连贯单元；ReLACE（监管列表自适应交叉编码器）基于开源模型构建，联合建模用户查询和检索候选以提高排名相关性。

Result: 企业环境评估显示，RegGuard在相关性、基础性和上下文聚焦方面显著提高答案质量，同时显著减轻幻觉风险。系统架构支持可审计性和可追溯性。

Conclusion: RegGuard为具有严格合规要求的领域提供了高度响应性的解决方案，通过自动化监管文本解释和与内部政策对齐，解决了跨国制药公司的合规挑战。

Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.

</details>


### [41] [Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards](https://arxiv.org/abs/2601.17828)
*Tanvi Verma,Yang Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.AI

TL;DR: 提出IGFT方法，通过信息增益奖励和在线强化学习训练医疗对话AI，无需人工对话数据即可生成完整病史，在两个数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话AI依赖昂贵的人工标注对话数据或静态数据集，难以学习有效的问诊策略。需要一种无需预收集人类对话、能通过自我探索学习有效问诊的方法。

Method: 结合在线Group Relative Policy Optimization和信息论奖励，使用信息增益奖励函数追踪临床实体（症状、时间模式、病史）的揭示情况，结合GPT-4o-mini的质量评估，通过LoRA微调Llama-3.1-8B-Instruct和DeepSeek-R1-Distill-Qwen-7B模型。

Result: DeepSeek-R1-Distill-Qwen-7B (IGFT)在Avey数据集上F1得分为0.408（比基础模型提升10.9%），在MIMIC数据集上为0.289（提升12.9%）。Llama-3.1-8B-Instruct (IGFT)分别达到0.384和0.336。两个模型在MIMIC上都优于OpenAI模型，并超越HuatuoGPT和UltraMedical等医疗专用基线。

Conclusion: IGFT方法通过信息增益奖励和在线强化学习，使医疗对话AI能够从自我生成的对话中学习有效问诊策略，无需依赖人工标注数据，在多个数据集上显著优于现有方法，为医疗对话AI训练提供了新范式。

Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.

</details>


### [42] [When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents](https://arxiv.org/abs/2601.17887)
*Jiahe Guo,Xiangran Guo,Yulin Hu,Zimo Long,Xingyu Sui,Xuda Zhi,Yongbo Huang,Hao He,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.AI

TL;DR: 研究发现个性化LLM代理中的"意图合法化"安全漏洞：良性个人记忆会偏见意图推断，导致模型将有害查询合法化，攻击成功率增加15.8%-243.7%


<details>
  <summary>Details</summary>
Motivation: 现有个性化代理研究主要关注实用性和用户体验，将记忆视为中性组件，忽视了其安全影响。本文旨在揭示"意图合法化"这一被忽视的安全失效模式，即良性个人记忆如何导致有害查询被合法化

Method: 1) 引入PS-Bench基准测试来识别和量化个性化交互中的意图合法化；2) 在多个记忆增强代理框架和基础LLM上进行实验；3) 从内部表示空间提供机制性证据；4) 提出轻量级检测-反思方法

Result: 个性化使攻击成功率相对无状态基线增加15.8%-243.7%；从内部表示空间获得了意图合法化的机制性证据；提出的检测-反思方法有效减少了安全退化

Conclusion: 这是对意图合法化作为安全失效模式的首次系统探索和评估，表明良性、现实世界的个性化会自然产生这种安全风险，强调在长期个性化背景下评估安全性的重要性

Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.

</details>


### [43] [UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis](https://arxiv.org/abs/2601.17897)
*Jiayu Liu,Yinhe Long,Zhenya Huang,Enhong Chen*

Main category: cs.AI

TL;DR: UniCog框架通过潜在思维空间分析LLM认知，发现帕累托原则：共享推理核心+能力特定特征，推理失败表现为潜在激活异常，基于此的候选优先级策略提升推理性能7.5%


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法在解释LLM推理过程中如何运用认知能力方面存在局限，需要新框架来分析LLM与人类不同的认知过程

Method: 提出UniCog统一框架，作为潜在变量模型，将密集模型激活编码为稀疏解耦的潜在维度，分析六个先进LLM的认知

Result: 发现LLM认知的帕累托原则：共享推理核心+能力特定特征；推理失败表现为潜在激活异常；潜在信息候选优先级策略在挑战性基准上提升性能7.5%

Conclusion: UniCog为LLM分析开辟新范式，提供基于认知的推理动态视图，潜在信息策略能有效提升推理性能

Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.

</details>


### [44] [Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation](https://arxiv.org/abs/2601.17915)
*Saurabh Jha,Rohan Arora,Bhavya,Noah Zheutlin,Paulina Toro Isaza,Laura Shwartz,Yu Deng,Daby Sow,Ruchi Mahindru,Ruchir Puri*

Main category: cs.AI

TL;DR: EoG框架通过将调查任务建模为依赖图上的溯因推理，分离LLM的局部证据挖掘与控制器的图遍历管理，解决了ReAct代理在开放调查任务中的可靠性和一致性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在开放调查任务中表现不佳，因为这类任务存在隐藏的依赖结构，需要在海量异构数据中迭代挖掘证据。ReAct代理的检索-总结-推理循环使结论对探索顺序敏感，缺乏信念跟踪和修订机制，导致结果不稳定。

Method: 提出EoG框架：将调查任务形式化为依赖图上的溯因推理。LLM负责有界的局部证据挖掘和标注（原因vs症状），而确定性控制器管理图遍历、状态维护和信念传播，计算最小解释边界。

Result: 在ITBench诊断任务上，EoG相比ReAct基线在准确性和运行一致性方面均有提升，包括实体F1分数的7倍平均增益。

Conclusion: 通过分离推理与控制职责，EoG框架能够更可靠地处理开放调查任务，解决了ReAct代理在复杂依赖结构环境中的局限性。

Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.

</details>


### [45] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

TL;DR: 这篇综述论文探讨了自动驾驶实验室中的AI代理问题，将SDL自主性建模为代理环境交互问题，回顾了主要方法家族，提出了能力驱动的分类法，并总结了实际部署中的经验教训和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶实验室为AI代理提供了具有挑战性的测试环境，包括昂贵的操作、噪声和延迟反馈、严格的可行性和安全约束以及非平稳性。论文旨在系统化地分析SDL中的AI问题，为这一新兴领域提供理论框架和实践指导。

Method: 将SDL自主性形式化为代理环境交互问题，回顾贝叶斯优化、主动学习、规划、强化学习和工具使用代理等方法，提出能力驱动的分类法，并合成基准任务模板和评估指标。

Result: 建立了连接SDL流程与AI原则的理论框架，系统化地组织了SDL系统的能力分类，提出了注重成本感知性能、漂移鲁棒性、约束违反行为和可重复性的评估方法。

Conclusion: 自动驾驶实验室是AI代理的重要应用场景，需要进一步发展多模态表示、校准不确定性、安全探索和共享基准基础设施等关键技术，以推动该领域的进步。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [46] [Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation](https://arxiv.org/abs/2601.17923)
*Ali Najar*

Main category: cs.AI

TL;DR: 论文提出了一种基于技能图的分层课程学习方法，在《黑暗之魂III》实时控制环境中实现终身学习，通过分解技能并选择性微调来适应环境变化。


<details>
  <summary>Details</summary>
Motivation: 终身学习智能体需要在复杂实时环境中持续扩展能力，而不需要从头训练或覆盖已学行为。当前方法在环境变化时往往需要全面重新训练，效率低下。

Method: 将战斗表示为有向技能图，采用分层课程训练五个可重用技能：相机控制、目标锁定、移动、闪避和治疗-攻击决策策略。每个技能针对特定职责优化，支持选择性后训练。

Result: 技能分解提高了样本效率，减少了单一策略负担。当环境从第一阶段切换到第二阶段时，仅需微调两个技能即可快速恢复性能，证明了选择性微调的有效性。

Conclusion: 技能图课程与选择性微调相结合，为复杂实时环境中持续进化的终身学习智能体提供了一条实用路径。

Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.

</details>


### [47] [LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting](https://arxiv.org/abs/2601.17942)
*Yu-Jie Yang,Hung-Fu Chang,Po-An Chen*

Main category: cs.AI

TL;DR: 提出SSEV和ReCAPAgent-SQL两个Text-to-SQL框架，前者基于单代理自优化与集成投票，后者采用多代理协作迭代优化，在多个基准测试中取得竞争性性能。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL技术能降低数据分析门槛，但自然语言查询存在歧义、模式链接复杂、SQL方言泛化有限、需要领域知识等问题，现有方法难以应对企业级数据库的复杂性和实际应用需求。

Method: 1. SSEV：基于PET-SQL构建单代理自优化与集成投票管道，无需真实数据，结合自优化、加权多数投票及其随机变体。2. ReCAPAgent-SQL：多代理协作框架，集成规划、外部知识检索、批判、动作生成、自优化、模式链接和结果验证等专门代理，通过代理协作迭代优化SQL预测。

Result: SSEV在多个基准测试中表现优异：Spider 1.0-Dev执行准确率85.5%，Spider 1.0-Test 86.4%，BIRD-Dev 66.3%。ReCAPAgent-SQL在Spider 2.0-Lite前100个查询中达到31%执行准确率，显著提升企业场景处理能力。

Conclusion: 提出的两个框架有效解决了Text-to-SQL的实际挑战，支持可扩展系统在实际环境中的部署，以更低成本和更高效率促进数据驱动决策。

Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.

</details>


### [48] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

TL;DR: Sentipolis框架为LLM智能体提供情感状态记忆，通过PAD情感表示、双速情感动态和情感-记忆耦合解决情感遗忘问题，提升社交模拟中的情感连续性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在社交模拟中常将情感视为瞬时线索，导致情感遗忘和长期情感连续性不足，需要建立具有情感状态记忆的智能体框架。

Method: 提出Sentipolis框架，包含：1）连续PAD（愉悦-唤醒-支配）情感表示；2）双速情感动态机制；3）情感与记忆耦合系统。

Result: 在数千次交互中，Sentipolis显著提升了情感基础行为、沟通能力和情感连续性。效果模型依赖：高容量模型可信度提升，小模型可能下降；情感意识可能轻微降低社会规范遵循度。

Conclusion: Sentipolis为社交模拟提供了情感状态智能体框架，支持累积社交动态研究（如联盟形成、关系渐变），反映了情感驱动行为与规则遵循之间的人类化张力。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [49] [Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing](https://arxiv.org/abs/2601.18061)
*Kiana Jafari,Paul Ulrich Nikolaus Rust,Duncan Eddy,Robbie Fraser,Nina Vasan,Darja Djordjevic,Akanksha Dadlani,Max Lamparth,Eugenia Kim,Mykel Kochenderfer*

Main category: cs.AI

TL;DR: 专家在AI心理健康安全评估中存在系统性分歧，而非随机误差，共识聚合会抹杀专业哲学差异


<details>
  <summary>Details</summary>
Motivation: 验证LHF假设：专家判断聚合能否为AI系统提供有效基准，特别是在心理健康等高安全风险领域

Method: 三位认证精神科医生使用校准评估表独立评估LLM生成回复，计算评分者间信度，并进行定性访谈分析分歧原因

Result: 评分者间信度极低（ICC 0.087-0.295），自杀自伤类别分歧最大，分歧是系统性而非随机的，反映不同的临床框架（安全优先、参与中心、文化导向）

Conclusion: 专家依赖整体风险启发式而非细粒度因子判别，共识聚合会抹杀专业哲学，应转向保留分歧的对齐方法

Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.

</details>


### [50] [EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization](https://arxiv.org/abs/2601.18067)
*Wei-Po Hsin,Ren-Hao Deng,Yao-Ting Hsieh,En-Ming Huang,Shih-Hao Hung*

Main category: cs.AI

TL;DR: EvolVE框架通过进化策略和结构化测试生成，在Verilog硬件设计中实现自动化，显著提升功能正确性和PPA优化，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: Verilog设计流程劳动密集且需要专业领域知识，现有LLM由于训练数据有限和顺序推理特性，难以捕捉硬件系统的形式逻辑和并发特性，需要新的自动化方法。

Method: 提出EvolVE框架，分析多种进化策略：MCTS用于最大化功能正确性，Idea-Guided Refinement用于优化；采用结构化测试生成加速进化过程；引入IC-RTL工业级基准测试套件。

Result: 在VerilogEval v2达到98.1%，RTLLM v2达到92%；在IC-RTL工业级问题上，超越竞赛参考实现，Huffman编码PPA降低66%，所有问题几何平均降低17%。

Conclusion: EvolVE框架通过进化策略有效解决了硬件设计自动化问题，在功能正确性和PPA优化方面均取得显著突破，为芯片设计自动化提供了新途径。

Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.

</details>


### [51] [Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?](https://arxiv.org/abs/2601.18119)
*Jing Ye,Yiwen Duan,Yonghong Yu,Victor Ma,Yang Gao,Xing Chen*

Main category: cs.AI

TL;DR: OurBench是首个企业级SQL推理与调试基准，包含469个语法错误查询和516个语义错误查询，通过自动化构建流程和免执行评估框架，评估近30个LLM发现性能差距显著，最佳模型准确率仅36.46%和32.17%。


<details>
  <summary>Details</summary>
Motivation: 企业数据工程中SQL至关重要，但即使对有经验的开发者和先进的文本转SQL LLM，一次性生成完全正确的SQL代码仍然困难，通常需要多次调试迭代，缺乏专门的基准测试工具。

Method: 采用自动化构建工作流，通过逆向工程在大规模SQL代码中系统注入真实错误；设计免执行评估框架，针对企业环境提供快速、准确、资源高效的评估；包含OurBenchSyn（语法错误）和OurBenchSem（语义错误）两类查询。

Result: 评估近30个LLM显示性能差距显著：最佳模型Claude-4-Sonnet在OurBenchSyn上准确率36.46%，在OurBenchSem上32.17%，大多数模型低于20%；查询复杂度高，平均超过140行，具有深广的抽象语法树。

Conclusion: OurBench填补了企业级SQL调试基准的空白，揭示了LLM在复杂SQL调试中的局限性，探索了四种解决方案策略，为LLM在企业SQL调试中的应用指明了有前景的方向。

Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.
  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.
  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.

</details>


### [52] [Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters](https://arxiv.org/abs/2601.18123)
*Muhammad Ibrahim Khan,Bivin Pradeep,James Brusey*

Main category: cs.AI

TL;DR: 论文研究了家庭浸入式热水器的截止时间感知控制，通过强化学习（PPO）相比传统bang-bang控制和MCTS规划器，在满足指定时间达到目标温度的前提下，显著降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 传统家庭浸入式热水器在冬季通常连续运行，追求快速加热而非高效节能，忽略了可预测的需求窗口和环境热损失。需要一种能在指定截止时间达到目标温度的同时最小化能耗的控制方法。

Method: 创建了Gymnasium环境模拟浸入式热水器（具有一阶热损失，每120秒执行0W或6000W的开关动作）。比较了三种方法：时间最优的bang-bang基线控制、零样本蒙特卡洛树搜索规划器和近端策略优化强化学习策略。

Result: PPO在60步（2小时）时间范围内能耗最低（3.23千瓦时），相比bang-bang控制（4.37-10.45千瓦时）和MCTS（4.18-6.46千瓦时）显著节能。在典型场景下，PPO比bang-bang节能54%，比MCTS节能33%。

Conclusion: 学习到的截止时间感知控制能在相同物理假设下显著降低能耗，规划器无需训练即可提供部分节能效果，而学习策略一旦训练完成，推理成本几乎为零。

Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.

</details>


### [53] [RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents](https://arxiv.org/abs/2601.18130)
*Jize Wang,Han Wu,Zhiyuan You,Yiming Song,Yijun Wang,Zifei Shan,Yining Li,Songyang Zhang,Xinyi Le,Cailian Chen,Xinping Guan,Dacheng Tao*

Main category: cs.AI

TL;DR: RouteMoA：一种通过动态路由实现的高效混合代理框架，使用轻量级评分器进行初步筛选，混合评委进行精炼评分，模型排名机制平衡性能、成本和延迟，显著降低成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 混合代理（MoA）通过分层协作提升LLM性能，但其密集拓扑结构导致成本和延迟增加。现有方法使用LLM评委过滤响应，但仍需所有模型进行推理后才能判断，无法有效降低成本。同时缺乏模型选择标准，难以处理大规模模型池，因为全推理成本高且可能超出上下文限制。

Method: 1. 轻量级评分器：根据查询预测粗略性能，筛选出高潜力候选子集，无需推理；2. 混合评委：基于现有模型输出进行轻量级自评估和交叉评估，提供后验修正而无需额外推理；3. 模型排名机制：平衡性能、成本和延迟选择模型。

Result: RouteMoA在不同任务和模型池规模下均优于MoA，在大规模模型池中降低成本89.8%，减少延迟63.6%。

Conclusion: RouteMoA通过动态路由有效解决了MoA框架的成本和延迟问题，实现了高效的大规模模型协作，为混合代理系统提供了实用的解决方案。

Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

</details>


### [54] [RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening](https://arxiv.org/abs/2601.18132)
*Xi Chen,Hongru Zhou,Huahui Yi,Shiyu Feng,Hanyu Zhou,Tiancheng He,Mingke You,Li Wang,Qiankun Li,Kun Wang,Weili Fu,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: RareAlert：基于多LLM推理校准的罕见病早期筛查系统，通过整合10个LLM的推理信号，训练出可在本地部署的单一模型，在包含33类罕见病的真实数据集上达到0.917 AUC


<details>
  <summary>Details</summary>
Motivation: 罕见病的漏诊和延迟诊断是重大挑战，现有初级诊疗分诊流程无法可靠识别罕见病患者，需要通用筛查来减少诊断延迟

Method: 整合10个LLM生成的推理信号，使用机器学习校准和加权这些信号，然后将对齐的推理蒸馏到单个可在本地部署的模型（基于Qwen3-4B）

Result: 在包含158,666个病例、覆盖33类罕见病的RareBench数据集上，RareAlert在独立测试集上达到0.917 AUC，优于所有评估的LLM（包括GPT-5、Claude-3.7等）和最佳机器学习集成

Conclusion: 罕见病识别可重新概念化为对普通患者群体的通用不确定性解决过程，通过将校准推理整合到单一模型中，RareAlert实现了准确、隐私保护、可扩展的罕见病风险筛查

Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.

</details>


### [55] [DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints](https://arxiv.org/abs/2601.18137)
*Yinger Zhang,Shutong Jiang,Renhao Li,Jianhong Tu,Yang Su,Lianghao Deng,Xudong Guo,Chenxu Lv,Junyang Lin*

Main category: cs.AI

TL;DR: DeepPlanning是一个用于评估智能体长期规划能力的挑战性基准，包含多日旅行规划和多产品购物任务，要求主动信息获取、局部约束推理和全局约束优化。


<details>
  <summary>Details</summary>
Motivation: 现有智能体评估基准过于强调局部、步骤级推理，而忽视了需要真正规划能力的全局约束优化（如时间和财务预算）。同时，现有的LLM规划基准未能充分体现现实世界中典型的主动信息收集和细粒度局部约束。

Method: 提出了DeepPlanning基准，包含多日旅行规划和多产品购物两类任务。这些任务要求智能体进行主动信息获取、局部约束推理和全局约束优化，以评估其长期规划能力。

Result: 评估显示，即使是前沿的智能体LLM在这些问题上也表现不佳，突显了可靠的显式推理模式和并行工具使用对于实现更好的效果-效率权衡的重要性。

Conclusion: DeepPlanning基准揭示了当前智能体LLM在长期规划方面的局限性，并指出了改进方向。作者开源了代码和数据以支持未来研究。

Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.

</details>


### [56] [GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models](https://arxiv.org/abs/2601.18197)
*Shaokang Wang,Pei Fu,Ruoceng Zhang,Shaojie Zhang,Xiuwen Xi,Jiahui Yang,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.AI

TL;DR: GAIA框架通过训练直觉批评模型来提升GUI代理的测试时性能，实现自我改进的数据飞轮系统


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然提升了GUI代理的能力，但操作不可逆性导致单个错误动作可能引发灾难性偏差，需要解决这个问题

Method: 提出GAIA训练框架，包含直觉批评模型(ICM)：1) 用基础代理的正负样本训练初始批评模型；2) 批评模型评估代理动作的正确性，选择高成功率操作；3) 批评模型引导代理收集精炼样本，启动自我改进循环；4) 增强数据训练第二轮批评模型

Result: 在各种数据集上的实验表明，ICM能够提升闭源和开源模型的测试时性能，并且随着数据循环利用，性能可以逐步提高

Conclusion: GAIA框架通过批评模型的迭代训练和数据飞轮系统，有效解决了GUI代理操作不可逆性的问题，实现了性能的持续提升

Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.

</details>


### [57] [SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback](https://arxiv.org/abs/2601.18202)
*Fangyuan Xu,Rujun Han,Yanfei Chen,Zifeng Wang,I-Hung Hsu,Jun Yan,Vishy Tirumalashetty,Eunsol Choi,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: SAGE：一个自动生成高质量、难度可控的深度搜索问答对的智能体管道，通过数据生成器和搜索代理的交互迭代优化，显著提升深度搜索代理的性能


<details>
  <summary>Details</summary>
Motivation: 深度搜索代理需要跨多个文档进行复杂推理，但人工标注成本过高，因为探索轨迹长且复杂。需要自动化方法生成高质量的训练数据。

Method: 提出SAGE管道，包含数据生成器（提出QA对）和搜索代理（尝试解决问题并提供执行反馈）。两个组件通过多轮交互迭代优化问答对，直到达到目标难度水平。

Result: 内在评估显示SAGE生成的问题需要多样化的推理策略，同时显著提高生成数据的正确性和难度。外在评估表明，在流行深度搜索基准测试上，使用合成数据训练的深度搜索代理性能相对提升达23%。额外实验显示，训练后的代理可以在推理时从固定语料库检索适应到Google搜索，无需进一步训练。

Conclusion: SAGE能够自动生成高质量、难度可控的深度搜索训练数据，显著提升深度搜索代理的性能，并具有良好的适应性。

Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.

</details>


### [58] [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/abs/2601.18217)
*Zhihan Liu,Lin Guan,Yixin Nie,Kai Zhang,Zhuoqun Hao,Lin Chen,Asli Celikyilmaz,Zhaoran Wang,Na Zhang*

Main category: cs.AI

TL;DR: 研究探索LLM智能体后训练在未知测试域中的泛化能力，发现状态信息丰富度和规划复杂度是影响跨域泛化的关键因素，并提出增加干扰性无关特征来提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体通常在狭窄环境集上进行后训练，但部署在更广泛的未见领域中。本研究旨在解决当最终测试域未知时，智能体后训练面临的挑战，分析哪些RL环境属性和建模选择对域外性能影响最大。

Method: 识别影响跨域泛化的两个关键环境轴：状态信息丰富度（agent需要处理的信息量）和规划复杂度（通过基础策略下的目标可达性和轨迹长度估计）。提出随机化技术：在状态中添加少量分散注意力的目标无关特征来增加信息丰富度而不改变任务。同时分析建模选择：SFT预热/中期训练的影响，以及RL期间启用逐步思考的作用。

Result: 发现域真实性和文本级相似性不是主要因素，例如简单的网格世界Sokoban在SciWorld中的泛化效果比更真实的ALFWorld更好。增加状态信息丰富度能有效提高跨域鲁棒性。SFT预热/中期训练有助于防止灾难性遗忘，但会损害未包含在中期训练数据混合中的域的泛化能力。启用逐步思考在RL期间对保持泛化能力起关键作用。

Conclusion: 状态信息丰富度和规划复杂度是影响LLM智能体跨域泛化的关键环境属性。通过添加目标无关特征增加状态信息丰富度是提升泛化能力的有效方法。在建模选择上，需要平衡SFT训练与泛化能力，并重视逐步思考在保持跨域性能中的作用。

Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.

</details>


### [59] [ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants](https://arxiv.org/abs/2601.18225)
*Pei Wang,Yanan Wu,Xiaoshuai Song,Weixun Wang,Gengru Chen,Zhongwen Li,Kezhong Yan,Ken Deng,Qi Liu,Shuaibing Zhao,Shaopan Xiong,Xuepeng Liu,Xuefeng Chen,Wanxi Deng,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: ShopSimulator是一个大规模中文购物模拟环境，用于评估和训练LLM智能体在电商场景中的表现，发现现有模型成功率不足40%，通过SFT+RL训练可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏统一的模拟环境来全面评估LLM智能体在电商购物中的能力，包括理解个人偏好、多轮对话、检索和区分高度相似产品等方面，且现有工作主要关注评估而非训练支持。

Method: 提出ShopSimulator大规模中文购物环境，包含多样化场景；使用该环境评估多种LLM表现；通过错误分析识别智能体弱点；探索监督微调(SFT)和强化学习(RL)组合的训练方法。

Result: 即使最佳模型的全成功率也不足40%；错误分析显示智能体在长轨迹中的深度搜索和产品选择、平衡个性化线索使用、有效与用户互动方面存在困难；SFT+RL组合训练显著提升了性能。

Conclusion: ShopSimulator为电商购物智能体提供了全面评估和训练环境；现有LLM在复杂购物任务中表现有限；结合SFT和RL的训练方法能有效提升智能体性能，为实际应用提供指导。

Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.

</details>


### [60] [Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks](https://arxiv.org/abs/2601.18226)
*Haotian Li,Shijun Yang,Weizhen Qi,Silei Zhao,Rui Hua,Mingzhu Song,Xiaojian Yang,Chao Peng*

Main category: cs.AI

TL;DR: 提出In-Situ Self-Evolving范式，让智能体在开放环境中通过任务交互自我演化，将短期执行反馈转化为长期可重用能力，无需真实标签监督。


<details>
  <summary>Details</summary>
Motivation: 传统智能体系统在开放环境中面临挑战：任务分布持续漂移、外部监督稀缺，依赖静态工具集或离线训练导致能力边界僵化且未知。

Method: 提出In-Situ Self-Evolving范式，将工具演化作为能力扩展的关键路径，开发Yunjue Agent系统迭代合成、优化和重用工具，并引入Parallel Batch Evolution策略优化演化效率。

Result: 在五个不同基准测试的零起点设置下，相比专有基线取得显著性能提升；补充的热启动评估证实积累的通用知识可无缝迁移到新领域；提出新的演化收敛监控指标。

Conclusion: In-Situ Self-Evolving范式使智能体能在开放环境中自我演化扩展能力，工具演化提供可验证的反馈信号，系统展示了从零开始学习并迁移知识的能力，为弹性自演化智能研究提供基础。

Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.

</details>


### [61] [Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning](https://arxiv.org/abs/2601.18282)
*Lei Wei,Jinpeng Ou,Xiao Peng,Bin Wang*

Main category: cs.AI

TL;DR: 提出Think-Augmented Function Calling (TAFC)框架，通过函数和参数级别的显式推理增强LLM的函数调用准确性，无需修改模型架构


<details>
  <summary>Details</summary>
Motivation: 当前LLM在函数调用中缺乏参数生成的显式推理透明度，特别是对于具有相互依赖参数的复杂函数。现有方法如思维链提示在代理级别操作，无法为单个函数参数提供细粒度的推理指导

Method: 提出TAFC框架：1) 引入通用的"think"参数增强，让模型阐述决策过程；2) 动态优化参数描述以提高推理质量；3) 基于复杂度评分自动触发细粒度推理；4) 提出推理引导优化以对齐人类期望

Result: 在ToolBench上对专有和开源模型的评估显示，TAFC在多参数函数的参数生成准确性和推理连贯性方面有显著改进，同时为调试AI代理行为提供增强的可解释性

Conclusion: TAFC框架通过显式推理机制显著提升了LLM函数调用的准确性和可解释性，同时保持与现有API的完全兼容性，无需修改模型架构

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal "think" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.

</details>


### [62] [Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books](https://arxiv.org/abs/2601.18353)
*Tuhin Chakrabarty,Paramveer S. Dhillon*

Main category: cs.AI

TL;DR: 生成式AI在模仿作家风格方面已超越人类专家，导致专业作家面临身份危机


<details>
  <summary>Details</summary>
Motivation: 挑战传统认为创意写作是机器无法复制的独特人类能力的假设，探究AI在模仿作家风格方面的实际能力及其对创意劳动的影响

Method: 行为实验：28位MFA作家（专家）与3个LLM竞争模仿50位知名作家风格；通过28位专家评委和131位普通评委进行盲审配对比较；采用上下文提示和微调两种条件

Result: 专家评委在上下文提示条件下82.7%偏好人类写作，但在微调后62%偏好AI写作；普通评委始终偏好AI写作；专家作家对AI写作的偏好触发了身份危机

Conclusion: AI在模仿作家风格方面已超越人类专家，挑战了关于AI创意局限的论述，并引发了对创意劳动未来的根本性问题

Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.

</details>


### [63] [AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito](https://arxiv.org/abs/2601.18381)
*Yinghan Hou,Zongyou Yang*

Main category: cs.AI

TL;DR: 开发集成AI代理框架，将传统有限差分实现转换为Devito环境，结合RAG和开源大语言模型，通过多阶段迭代工作流实现代码转换和优化。


<details>
  <summary>Details</summary>
Motivation: 为了促进传统有限差分实现向Devito环境的转换，解决代码迁移的复杂性和准确性挑战，需要智能化的自动化工具来简化这一过程。

Method: 采用混合LangGraph架构，结合RAG和开源大语言模型，构建Devito知识图谱，通过文档解析、结构感知分割、实体关系提取和社区检测。包含反向工程组件分析Fortran源代码，多阶段检索管道执行并行搜索、概念扩展和语义相似性分析，代码合成采用Pydantic约束保证结构化输出。

Result: 开发了完整的AI代理框架，能够实现从传统有限差分代码到Devito环境的自动化转换，通过验证框架确保执行正确性、结构完整性、数学一致性和API合规性。

Conclusion: 该研究的主要贡献在于整合了基于强化学习启发的反馈机制，实现了从静态代码翻译向动态自适应分析行为的转变，为科学计算代码迁移提供了智能化解决方案。

Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.

</details>


### [64] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

TL;DR: DynTS方法通过识别推理轨迹中的关键决策token并仅保留其KV缓存状态，显著提升大型推理模型的效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在生成推理轨迹时会产生大量内存占用和计算开销，成为效率瓶颈。研究发现推理轨迹中只有部分关键token对最终答案有决定性影响，其余token贡献可忽略

Method: 提出动态思维token选择(DynTS)方法，利用注意力图分析推理轨迹中各token的影响力，识别决策关键token，在推理过程中仅保留这些关键token的KV缓存状态，淘汰冗余条目

Result: 通过选择性保留关键token的KV缓存，DynTS能够显著减少内存占用和计算开销，提升大型推理模型的推理效率

Conclusion: 推理轨迹中存在大量冗余token，通过动态选择关键决策token并优化KV缓存管理，可以在不损失推理质量的前提下大幅提升模型效率

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


### [65] [OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents](https://arxiv.org/abs/2601.18467)
*Yuhang Zhou,Kai Zheng,Qiguang Chen,Mengkang Hu,Qingfeng Sun,Can Xu,Jingjing Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种完全离线的研究方法，通过开源套件生成大规模研究数据，训练出与在线强化学习性能相当的8B参数研究智能体。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体依赖昂贵的在线强化学习（需要大量API调用），而离线训练因缺乏高质量研究轨迹数据而受限。需要开发更经济高效的离线训练方法。

Method: 1. 开发开源套件：包括DeepForge任务合成框架，无需繁重预处理即可生成大规模研究查询；2. 构建高质量数据集：66k QA对、33k SFT轨迹和21k DPO对；3. 完全离线训练8B参数的OffSeeker模型。

Result: 在六个基准测试中，OffSeeker不仅在同尺寸智能体中领先，还能与通过大量在线RL训练的30B参数系统竞争。

Conclusion: 昂贵的在线强化学习并非构建强大研究智能体的唯一途径，通过高质量离线数据集和有效训练方法，可以开发出性能相当但成本更低的离线研究智能体。

Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.

</details>


### [66] [AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security](https://arxiv.org/abs/2601.18491)
*Dongrui Liu,Qihan Ren,Chen Qian,Shuai Shao,Yuejin Xie,Yu Li,Zhonghao Yang,Haoyu Luo,Peng Wang,Qingyu Liu,Binxin Hu,Ling Tang,Jilin Mei,Dadi Guo,Leitao Yuan,Junyao Yang,Guanxu Chen,Qihao Lin,Yi Yu,Bo Zhang,Jiaxuan Guo,Jie Zhang,Wenqi Shao,Huiqi Deng,Zhiheng Xi,Wenjie Wang,Wenxuan Wang,Wen Shen,Zhikai Chen,Haoyu Xie,Jialing Tao,Juntao Dai,Jiaming Ji,Zhongjie Ba,Linfeng Zhang,Yong Liu,Quanshi Zhang,Lei Zhu,Zhihua Wei,Hui Xue,Chaochao Lu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 提出AgentDoG框架，用于AI代理的安全监控和风险诊断，基于三维风险分类法构建细粒度安全基准ATBench，实现超越二元标签的透明风险溯源。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理的自主工具使用和环境交互带来复杂安全挑战，现有护栏模型缺乏代理风险意识和透明风险诊断能力，需要更精细的代理安全监控框架。

Method: 提出统一的三维风险分类法（来源、失效模式、后果），基于此构建细粒度代理安全基准ATBench，开发AgentDoG诊断护栏框架，提供跨代理轨迹的上下文监控和风险根因诊断。

Result: AgentDoG在多样复杂交互场景中实现最先进的代理安全调节性能，提供Qwen和Llama模型系列的4B、7B、8B参数版本，所有模型和数据集已开源。

Conclusion: AgentDoG通过结构化风险分类和透明诊断能力，为AI代理安全提供了超越传统二元标签的精细监控框架，有效促进代理对齐。

Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.

</details>


### [67] [DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference](https://arxiv.org/abs/2601.18496)
*Zihan wang,Hao Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yiqun Zhang,Jinghao Lin,Haihua Yang,Xiaozhong Ji*

Main category: cs.AI

TL;DR: DeepMed：针对医学领域优化的深度研究模型，通过多跳医学搜索QA合成、难度感知轮次惩罚和推理监控，解决通用DR模型在医学场景中的任务特征和工具使用扩展问题，在7个医学基准上平均提升9.79%


<details>
  <summary>Details</summary>
Motivation: 医学推理模型受限于参数知识，易遗忘和产生幻觉。通用深度研究(DR)模型虽然能在通用领域基于工具验证证据，但直接迁移到医学领域效果有限。这归因于两个差距：任务特征差距（医学问题需要在知识密集的临床背景下解释证据）和工具使用扩展差距（盲目扩展工具调用会注入噪声上下文，干扰敏感医学推理）

Method: 1. 数据：采用多跳医学搜索QA合成方法，支持模型在医学背景下应用DR范式；2. 训练：引入难度感知轮次惩罚，抑制过度工具调用增长；3. 推理：添加监控机制，在可控步骤内验证假设，避免上下文腐化

Result: 在七个医学基准测试中，DeepMed相比基础模型平均提升9.79%，并优于更大的医学推理和DR模型

Conclusion: DeepMed通过针对医学领域特点的系统优化，成功解决了通用DR模型在医学应用中的局限性，实现了更有效的医学推理能力

Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.

</details>


### [68] [Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities](https://arxiv.org/abs/2601.18554)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: MOSAIC是一个模块化框架，使用动态生成的数据集评估LLM对复杂指令的遵循能力，发现遵循能力不是单一能力，而是随约束类型、数量和位置显著变化。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法准确反映LLM在真实场景中对复杂指令的遵循能力，需要更细粒度的评估方法来诊断模型失败并开发更可靠的LLM。

Method: 提出MOSAIC框架，使用动态生成的数据集，包含最多20个面向应用的生成约束，对指令遵循能力进行模块化和独立分析。

Result: 评估五个不同家族的LLM发现：遵循能力随约束类型、数量和位置显著变化；揭示模型特定弱点；发现指令间的协同和冲突交互；识别首因效应和近因效应等位置偏差。

Conclusion: 这些细粒度洞察对于诊断模型失败和开发需要严格遵循复杂指令的系统中的可靠LLM至关重要。

Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.

</details>


### [69] [Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs](https://arxiv.org/abs/2601.18588)
*Xianzhe Meng,Qiangsheng Zeng,Ling Luo,Qinghan Yang,Jiarui Hao,Wenbo Wu,Qinyu Wang,Rui Yin,Lin Qi,Renzhi Lu*

Main category: cs.AI

TL;DR: 训练稳定性通常被视为大语言模型可靠优化的前提，但本文发现稳定训练动态可能导致生成分布集中在有限的经验模式子集上，产生系统性退化


<details>
  <summary>Details</summary>
Motivation: 研究训练稳定性如何影响生成分布，探索优化稳定性与生成表达能力之间的关系

Method: 使用基于反馈的训练框架来稳定内部生成统计量，分析稳定参数轨迹如何导致前向KL散度最小化和生成熵减少

Result: 稳定训练导致模型输出集中在有限的经验模式子集，产生低熵输出和重复行为，这种现象在不同架构和随机种子中一致出现

Conclusion: 优化稳定性和生成表达能力并不内在一致，稳定性本身不足以作为生成质量的指标

Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.

</details>


### [70] [A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic](https://arxiv.org/abs/2601.18595)
*Joseph Cotnareanu,Didier Chetelat,Yingxue Zhang,Mark Coates*

Main category: cs.AI

TL;DR: 提出一种结合LLM与逻辑求解器的新方法，通过逻辑求解器的反馈迭代补充常识关系，在缺失常识信息的逻辑推理任务上显著优于现有技术


<details>
  <summary>Details</summary>
Motivation: LLM在复杂证明规划中表现不佳，而传统逻辑求解器虽然推理效率高，但无法处理缺失的常识关系，需要一种结合两者优势的方法

Method: 使用逻辑求解器的反馈来指导LLM补充常识关系，通过搜索潜在常识假设来最大化找到有用事实的概率，同时控制成本

Result: 在多个纯逻辑推理数据集上（移除了部分常识信息），该方法相比现有技术取得了显著改进

Conclusion: 在人类语境中工作时，平衡神经和符号元素具有重要价值，结合LLM的常识推理能力和逻辑求解器的形式推理能力能有效提升推理性能

Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.

</details>


### [71] [PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression](https://arxiv.org/abs/2601.18608)
*Fabian Fumagalli,R. Teal Witter,Christopher Musco*

Main category: cs.AI

TL;DR: PolySHAP扩展KernelSHAP，使用高阶多项式近似特征交互，提供更准确的Shapley值估计，并证明配对采样等价于二阶PolySHAP。


<details>
  <summary>Details</summary>
Motivation: KernelSHAP通过线性近似计算Shapley值，但忽略了特征间的非线性交互。需要更准确的近似方法来捕捉这些复杂关系。

Method: 提出PolySHAP方法，使用高阶多项式（而不仅是线性函数）来近似游戏函数，从而捕捉特征间的非线性交互作用。

Result: PolySHAP在各种基准数据集上获得更好的Shapley值估计，证明估计具有一致性。同时证明配对采样（antithetic sampling）等价于二阶PolySHAP。

Conclusion: PolySHAP通过高阶多项式近似改进了Shapley值估计，并为配对采样启发式方法提供了首个强有力的理论依据。

Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.
  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.
  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.

</details>


### [72] [Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks](https://arxiv.org/abs/2601.18617)
*Pierre Orhan,Pablo Diego-Simón,Emmnanuel Chemla,Yair Lakretz,Yves Boubenec,Jean-Rémi King*

Main category: cs.AI

TL;DR: 研究发现人工神经网络在训练过程中会自发出现类似儿童语言习得的阶段性表征：先建立音素表征，然后是词汇，最后是句法结构，但需要比人类多得多的数据量。


<details>
  <summary>Details</summary>
Motivation: 儿童语言习得过程（音素分类、词汇识别、句法组合）已有很好描述，但缺乏统一的计算框架来解释其背后的神经表征机制。研究旨在探索人工神经网络训练中是否以及何时会出现类似的语言表征阶段。

Method: 通过分析语音和文本模型在训练过程中的神经激活模式，研究它们是否依次构建出能表征音素、词汇和句法结构的神经激活子空间几何结构。

Result: 语音和文本模型都遵循相似的学习阶段序列：训练过程中，神经激活依次构建出能表征音素、词汇和句法结构的子空间。这种发展轨迹在质量上与儿童相似，但在数量上差异巨大：这些算法需要比人类多2-4个数量级的数据量才能形成这些神经表征。

Conclusion: 研究展示了语言习得主要阶段自发出现的条件，为理解语言习得背后的计算机制提供了一条有前景的路径，同时揭示了人工系统与人类学习在数据效率上的显著差异。

Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.

</details>


### [73] [Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation](https://arxiv.org/abs/2601.18630)
*Abeer Badawi,Md Tahmid Rahman Laskar,Elahe Rahimi,Sheri Grach,Lindsay Bertrand,Lames Danok,Frank Rudzicz,Jimmy Huang,Elham Dolatabadi*

Main category: cs.AI

TL;DR: 该研究提出了一种基于人类专家的评估方法，用于评估大语言模型在心理健康对话中的表现，发现LLMs在认知支持方面表现可靠，但在情感共鸣方面存在不稳定，揭示了认知-情感差距。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康危机日益严重，存在治疗缺口和合格治疗师短缺的问题，大语言模型有望提供可扩展的心理支持。然而，LLMs在心理健康领域的可靠性、治疗相关性和与人类标准的对齐仍然存在挑战，需要建立有效的评估框架。

Method: 研究提出了一种基于人类专家的评估方法：1）从真实场景数据集中整理500个心理健康对话；2）评估9个不同LLMs（包括闭源和开源模型）生成的响应；3）由两名经过精神病学培训的专家独立使用5点李克特量表，基于包含6个属性的评估标准进行评分，该标准涵盖认知支持和情感共鸣两个维度。

Result: 分析显示：1）LLMs在认知可靠性方面表现良好，能提供安全、连贯且临床适当的信息；2）但在情感对齐方面表现不稳定；3）闭源模型（如GPT-4o）能提供更平衡的治疗响应，而开源模型表现出更大的变异性和情感平淡；4）揭示了持续的认知-情感差距。

Conclusion: 研究强调需要建立具有失败意识、基于临床的评估框架，在心理健康导向的LLMs中优先考虑关系敏感性而不仅仅是信息准确性。倡导采用以人为中心的平衡评估协议，重点关注治疗敏感性，为心理健康对话AI的负责任设计和临床监督提供指导框架。

Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.

</details>


### [74] [AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning](https://arxiv.org/abs/2601.18631)
*Mingyang Song,Haoyu Sun,Jiawei Gu,Linjie Li,Luxin Xu,Ranjay Krishna,Yu Cheng*

Main category: cs.AI

TL;DR: AdaReasoner是一个多模态模型家族，通过将工具使用作为通用推理技能来学习，而不是特定工具或显式监督行为，实现了自主工具选择、组合和适应新工具的能力。


<details>
  <summary>Details</summary>
Motivation: 人类在面对超出自身能力的问题时会使用工具，这为提高多模态大语言模型的视觉推理能力提供了有前景的范式。有效的推理需要知道使用哪些工具、何时调用它们以及如何在多步骤中组合它们，即使面对新工具或新任务时也是如此。

Method: 1) 可扩展的数据整理流程，让模型接触长视野、多步骤的工具交互；2) Tool-GRPO强化学习算法，基于最终任务成功优化工具选择和序列；3) 自适应学习机制，动态调节工具使用频率。

Result: AdaReasoner表现出强大的工具适应和泛化能力：自主采用有益工具、抑制无关工具、根据任务需求调整工具使用频率。在多个基准测试中达到最先进性能，7B基础模型平均提升24.9%，在VSP和Jigsaw等任务上超越GPT-5等强大专有系统。

Conclusion: AdaReasoner通过将工具使用作为通用推理技能来学习，实现了自主工具选择、组合和适应新工具的能力，在多模态推理任务中表现出色，为智能系统的工具使用能力提供了新范式。

Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.

</details>


### [75] [FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory](https://arxiv.org/abs/2601.18642)
*Lei Wei,Xu Dong,Xiao Peng,Niantao Xie,Bin Wang*

Main category: cs.AI

TL;DR: FadeMem：受生物启发的智能体记忆架构，通过主动遗忘机制实现选择性记忆，减少45%存储同时提升多跳推理能力


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型作为自主智能体面临关键记忆限制，缺乏选择性遗忘机制，导致要么在上下文边界发生灾难性遗忘，要么在边界内信息过载。人类记忆通过自适应衰减过程自然平衡保留与遗忘，而现有AI系统采用二元保留策略（要么全部保留要么全部丢失）。

Method: 提出FadeMem，一种受生物启发的智能体记忆架构，包含主动遗忘机制。采用双层记忆层次结构，通过自适应指数衰减函数控制保留，衰减率由语义相关性、访问频率和时间模式调节。通过LLM引导的冲突解决和智能记忆融合，系统能整合相关信息同时让无关细节逐渐淡忘。

Result: 在Multi-Session Chat、LoCoMo和LTI-Bench上的实验表明，FadeMem在多跳推理和检索方面表现优异，同时减少45%的存储需求，验证了受生物启发的遗忘机制在智能体记忆系统中的有效性。

Conclusion: 受生物启发的主动遗忘机制能有效解决智能体记忆系统的关键限制，通过选择性记忆平衡保留与遗忘，在减少存储需求的同时提升推理能力，为AI记忆系统设计提供了新方向。

Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.

</details>


### [76] [TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent](https://arxiv.org/abs/2601.18700)
*Xingyu Sui,Yanyan Zhao,Yulin Hu,Jiahe Guo,Weixiang Zhao,Bing Qin*

Main category: cs.AI

TL;DR: TEA-Bench是首个用于评估工具增强情感支持对话系统的交互式基准，通过引入外部工具减少幻觉并提高事实基础，实验显示工具增强能提升支持质量但效果与模型能力相关。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统和基准主要关注文本情感表达，忽视了外部工具在多轮情感支持中提供事实基础和减少幻觉的重要性。

Method: 提出TEA-Bench基准，包含真实情感场景、MCP风格工具环境和过程级评估指标；创建TEA-Dialog数据集；在9个LLM上进行实验，分析工具增强效果。

Result: 工具增强总体上提高了情感支持质量并减少了幻觉，但效果强烈依赖于模型能力：强模型能更选择性和有效地使用工具，弱模型获益有限；监督微调在分布内表现好但泛化能力差。

Conclusion: 工具使用对构建可靠的情感支持代理至关重要，需要开发更有效的工具增强方法，特别是针对能力较弱的模型。

Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.

</details>


### [77] [Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs](https://arxiv.org/abs/2601.18706)
*Zhichao Yang,Sepehr Janghorbani,Dongxu Zhang,Jun Han,Qian Qian,Andrew Ressler,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: Health-SCORE是一个可扩展的基于量规的LLM训练评估框架，显著降低医疗领域量规开发成本，同时保持评估质量


<details>
  <summary>Details</summary>
Motivation: 在医疗等安全关键领域，评估开放式LLM响应需要高质量的量规，但人工创建量规成本高、耗时长，限制了基于量规的评估和训练的可扩展性

Method: 开发Health-SCORE框架，通过自动化方法减少量规开发成本，同时将量规作为结构化奖励信号指导强化学习，并融入提示中进行上下文学习

Result: 在开放式医疗任务中，Health-SCORE达到与人工创建量规相当的评估质量，同时显著降低开发工作量，使基于量规的评估和训练更具可扩展性

Conclusion: Health-SCORE提供了一个通用且可扩展的框架，不仅降低了量规开发成本，还能通过强化学习和上下文学习提升LLM响应质量，推动医疗领域LLM评估和训练的可扩展应用

Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.

</details>


### [78] [Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules](https://arxiv.org/abs/2601.18716)
*Naeyma N. Islam,Thomas R. Caulfield*

Main category: cs.AI

TL;DR: 开发AI辅助药物设计方法，通过E3连接酶导向的分子胶促进Aβ-42的靶向降解，用于阿尔茨海默病治疗


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病中细胞内Aβ-42的积累是疾病进展的早期毒性驱动因素，需要开发靶向降解策略

Method: 采用结构建模、ADMET筛选和对接评估Aβ-42与三种E3连接酶的复合物形成潜力，开发了连接酶条件化的JT-VAE生成模型

Result: 生成模型能够产生化学有效、新颖且靶向特异性的分子胶，能够促进Aβ-42降解

Conclusion: 这种集成方法为设计神经退行性疾病的UPS靶向疗法提供了有前景的框架

Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.

</details>


### [79] [Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems](https://arxiv.org/abs/2601.18735)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Jing Yang,Jiawei Yao,Jian Wang,Guanlong Qu,Ziliang Chen,Keze Wang*

Main category: cs.AI

TL;DR: Agora是一个基于去中心化市场的不确定性协调框架，将认知不确定性转化为可交易资产，通过经济理性规则实现多智能体系统的成本高效协调。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的多智能体系统在经济上不可持续，异构智能体在信息不对称下的协调成本过高。现有方法依赖启发式代理，忽略了成本并破坏了不确定性结构，导致次优协调。

Method: Agora将协调重构为不确定性去中心化市场，将认知不确定性形式化为结构化可交易资产（感知、语义、推理），基于理性经济规则强制智能体进行盈利驱动交易。使用扩展Thompson采样的市场感知经纪人启动协作并引导系统达到成本高效均衡。

Result: 在五个多模态基准测试（MMMU、MMBench、MathVision、InfoVQA、CC-OCR）上，Agora优于强大的视觉语言模型和启发式多智能体策略，如在MMMU上比最佳基线准确率提升8.5%，同时成本降低3倍以上。

Conclusion: 基于市场的协调为构建经济可行的多智能体视觉智能系统提供了一个原则性和可扩展的范式。

Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.

</details>


### [80] [TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models](https://arxiv.org/abs/2601.18744)
*Fangxu Yu,Xingang Guo,Lingzhi Yuan,Haoqiang Kang,Hongyu Zhao,Lianhui Qin,Furong Huang,Bin Hu,Tianyi Zhou*

Main category: cs.AI

TL;DR: TSRBench是一个全面的多模态时间序列推理基准测试，包含4125个问题、14个领域、4个维度，评估了30多个领先模型，揭示了时间序列推理中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在现实世界中无处不在且至关重要，但现有通用模型基准测试中缺乏时间序列维度。为了填补这一空白，需要建立一个全面的时间序列推理基准测试来评估通用模型的实际问题解决能力。

Method: 构建TSRBench基准测试，包含：1) 4125个问题，覆盖14个领域，分为感知、推理、预测和决策4个主要维度；2) 15个任务评估基本推理能力；通过实验评估30多个领先的专有和开源LLM、VLM和TSLLM模型。

Result: 研究发现：1) 缩放定律适用于感知和推理，但在预测中失效；2) 强大的推理能力不能保证准确的上下文感知预测，表明语义理解和数值预测之间存在脱节；3) 当前多模态模型未能有效融合文本和视觉表示以获得性能增益。

Conclusion: TSRBench提供了一个标准化评估平台，不仅突出了现有挑战，还为推进通用模型发展提供了宝贵见解。代码和数据集已开源。

Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [81] [High-Rate Quantized Matrix Multiplication: Theory and Practice](https://arxiv.org/abs/2601.17187)
*Or Ordentlich,Yury Polyanskiy*

Main category: cs.IT

TL;DR: 该论文研究了量化矩阵乘法问题，分析了通用矩阵乘法和仅权重量化两种设置，提出了基于水填充的WaterSIC量化方案，在信息论极限内实现了接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型部署需求增长，高效的量化矩阵乘法变得至关重要。现有量化方案存在性能损失，需要理论分析和改进方法。

Method: 1) 分析通用矩阵乘法和仅权重量化的信息论基础；2) 比较ABSMAX INT和FP量化方案；3) 提出基于加权均方误差源编码水填充原理的WaterSIC方案；4) 将水填充应用于改进GPTQ算法。

Result: WaterSIC方案仅使用标量INT量化器，性能与基选择无关，仅取决于协方差矩阵行列式，在信息论失真极限内达到2πe/12的乘法因子（约0.25比特/条目）。GPTQ在随机旋转下接近WaterSIC性能。

Conclusion: 水填充原理可显著改进LLM量化算法，WaterSIC方案实现了接近信息论极限的性能，GPTQ结合随机旋转也接近最优，为高效LLM部署提供了理论指导和实用方案。

Abstract: This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $Σ_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $Σ_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\frac{2πe}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $Σ_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization).

</details>


### [82] [Joint Uplink-Downlink Fronthaul Bit Allocation in Fronthaul-Limited Massive MU-MIMO Systems](https://arxiv.org/abs/2601.17423)
*Yasaman Khorsandmanesh,Emil Bjornson,Joakim Jalden*

Main category: cs.IT

TL;DR: 该论文优化了大规模多用户MIMO系统中有限容量前传链路的比特分配，在CSI量化和预编码矩阵量化之间进行比特分配以最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 在集中式基带单元控制的高级天线系统中，前传链路容量有限，需要在CSI量化和预编码矩阵量化之间合理分配比特资源，这是提升系统性能的关键挑战。

Method: 基于硬化界推导系统和速率表达式，对最大比传输获得闭式解，揭示两种量化失真的相对影响，然后建立比特分配优化问题并提出精确求解算法。

Result: 数值结果表明，分配给CSI和预编码的比特相对重要性随信噪比变化而变化，验证了优化比特分配策略的有效性。

Conclusion: 该研究为有限前传容量下的大规模MU-MIMO系统提供了有效的比特分配方案，能够根据信噪比条件动态优化CSI和预编码的比特分配，提升系统频谱效率。

Abstract: This paper optimizes the fronthaul bit allocation in massive multi-user multiple-input multiple-output (MU-MIMO) systems operating with limited-capacity fronthaul links. We consider an advanced antenna system (AAS) controlled by a centralized baseband unit (BBU). In the AAS, multiple antenna elements together with their radio units are integrated into a single unit. In this setup, a key challenge is allocating fronthaul bits between uplink channel state information (CSI) quantization and downlink precoding matrix quantization. We formulate the problem of maximizing the sum spectral efficiency (SE) for a given fronthaul capacity. We develop an SE expression for this scenario based on the hardening bound. We compute the expression in closed form for maximum ratio transmission, which reveals the relative impact of the two types of quantization distortion. We then formulate a bit split optimization problem and propose an algorithm that exactly solves it.
  Numerical results demonstrate how the relative importance of assigning bits to CSI and precoding varies depending on the signal-to-noise ratio.

</details>


### [83] [Double-Cover-Based Analysis of the Bethe Permanent of Block-Structured Positive Matrices](https://arxiv.org/abs/2601.17508)
*Binghong Wu,Pascal O. Vontobel*

Main category: cs.IT

TL;DR: 本文研究了非负矩阵的永久值与其Bethe永久值的比值，发现对于块结构矩阵，该比值强烈集中在仅依赖于少数关键参数的某个值附近，并使用图覆盖方法解释这一现象。


<details>
  <summary>Details</summary>
Motivation: 虽然矩阵永久值与其Bethe永久值的比值在最坏情况下上下界相差指数级，但在实际中观察到该比值对许多感兴趣的矩阵集合都强烈集中在某个仅依赖于矩阵大小的值附近。本文旨在研究块结构矩阵集合中这一现象，并解释其原因。

Method: 对块结构矩阵（块内元素取值相同）进行数值研究，分析矩阵永久值与其Bethe永久值的比值分布。使用基于图覆盖的方法来解释观察到的行为并量化观测值。

Result: 观察到对于块结构矩阵集合，永久值与Bethe永久值的比值同样强烈集中在仅依赖于集合中少数关键参数的某个值附近。通过图覆盖方法成功解释了这一行为并量化了观测值。

Conclusion: 块结构矩阵的永久值与Bethe永久值比值表现出强烈的集中现象，这一行为可以通过图覆盖理论得到解释和量化，为理解矩阵永久值近似提供了理论依据。

Abstract: We consider the permanent of a square matrix with non-negative entries. A tractable approximation is given by the so-called Bethe permanent that can be efficiently computed by running the sum-product algorithm on a suitable factor graph. While the ratio of the permanent of a matrix to its Bethe permanent is, in the worst case, upper and lower bounded by expressions that are exponentially far apart in the matrix size, in practice it is observed for many ensembles of matrices of interest that this ratio is strongly concentrated around some value that depends only on the matrix size. In this paper, for an ensemble of block-structured matrices where entries in a block take the same value, we numerically study the ratio of the permanent of a matrix to its Bethe permanent. It is observed that also for this ensemble the ratio is strongly concentrated around some value depending only on a few key parameters of the ensemble. We use graph-cover-based approaches to explain the reasons for this behavior and to quantify the observed value.

</details>


### [84] [Study of Robust Power Allocation for User-Centric Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2601.17632)
*Saeed Mashdour,Saeed Mohammadzadeh,André R. Flores,Shirin Salehi,Rodrigo C. de Lamare,Anke Schmeink*

Main category: cs.IT

TL;DR: 提出一种用于无蜂窝大规模MIMO网络的鲁棒功率分配方法，采用最小二乘框架和Tikhonov正则化来应对信道估计误差，结合迫零预编码实现计算高效且对CSI不完善具有鲁棒性的设计。


<details>
  <summary>Details</summary>
Motivation: 在无蜂窝大规模MIMO网络中，由于不完美的信道状态信息(CSI)导致信道不确定性，需要鲁棒的资源分配来确保可靠的系统性能。

Method: 将功率优化问题构建为最小二乘框架，采用Tikhonov正则化来减轻信道估计误差的不利影响，并与迫零预编码结合，实现计算高效且对CSI不完善具有鲁棒性的设计。

Result: 数值结果表明，所提方法优于现有的非鲁棒技术，同时具有较低的计算开销，适用于CSI不确定下的大规模部署。

Conclusion: 提出的鲁棒功率分配方法能够有效应对信道估计误差，在无蜂窝大规模MIMO网络中实现高性能和低计算复杂度的平衡，适合实际部署。

Abstract: In cell-free massive multiple-input multiple-output (MIMO) networks, robust resource allocation is critical to ensure reliable system performance in the presence of channel uncertainties resulting from imperfect channel state information (CSI). In this work, we propose a robust power allocation method that formulates the power optimization problem into a least-squares framework, enhanced by Tikhonov regularization to mitigate the adverse effects of channel estimation errors. We integrate our approach with zero-forcing precoding, enabling a design that is both computationally efficient and resilient to CSI imperfections. Numerical results indicate that the proposed method outperforms existing non-robust techniques while benefiting from low computational overhead, making it well-suited for large-scale deployments under CSI uncertainty.

</details>


### [85] [A Model-Driven Lossless Compression Algorithm Resistant to Mismatch](https://arxiv.org/abs/2601.17684)
*Cordelia Hu,Jennifer Tang*

Main category: cs.IT

TL;DR: 提出一种基于下一标记预测的新型压缩算法，能够容忍结构化预测不匹配，在保证解码可靠性的同时实现优于传统方法的压缩比。


<details>
  <summary>Details</summary>
Motivation: 现代预测模型（如大语言模型）与熵编码结合可实现优于标准压缩算法的压缩率，但该方法依赖于编码器和解码器产生完全相同的输出分布假设。然而复杂预测模型（特别是基于神经网络的模型）存在非确定性，导致这一假设经常失效，即使微小不匹配也会导致解码失败。

Method: 提出一种基于下一标记预测的新型压缩算法，该算法对任意大但结构化的预测不匹配具有鲁棒性。在形式化不匹配认证下证明方案的正确性，并理论分析其性能，在真实数据集上进行实验验证。

Result: 实验结果表明，在认证的不匹配机制下算法能够可靠运行，同时实现的压缩比超过常用压缩方法。

Conclusion: 该研究提出了一种能够容忍预测不匹配的压缩算法，解决了现有基于预测模型的压缩方法中非确定性导致的解码失败问题，在保证可靠性的同时实现了优越的压缩性能。

Abstract: Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism.
  In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods.

</details>


### [86] [A Multi-Modal Fusion Platform for Joint Environment Sensing and Channel Sounding in Highly Dynamic Scenarios](https://arxiv.org/abs/2601.17809)
*Xuejian Zhang,Ruisi He,Mi Yang,Zhengyu Zhang,Ziyi Qi*

Main category: cs.IT

TL;DR: 提出一个多模态感知与信道探测融合平台，解决现有信道探测设备缺乏跨频段能力、动态场景适应性差和环境感知不足的问题，支持6G环境感知信道建模。


<details>
  <summary>Details</summary>
Motivation: 6G系统向全频谱覆盖、超宽带和高移动性演进，传播环境日益复杂。通信与感知深度融合是6G核心愿景，需要全面的环境感知。现有信道探测设备缺乏跨频段能力、动态场景适应性差、环境感知有限，限制了环境感知信道模型的发展。

Method: 设计多模态感知与信道探测融合平台，实现图像、点云、地理定位信息和多频段多天线信道数据的时空同步采集。采用模块化架构便于快速部署，支持Sub-6 GHz和毫米波频段，带宽达1 GHz，延迟分辨率1 ns，信道切换速率8 ms。

Result: 平台实现厘米级360°环境感知精度和米级定位精度。关键性能指标（动态范围、相位稳定性、延迟分辨率、多模态数据同步）通过车对基础设施测量活动验证。平台支持环境-信道联合建模。

Conclusion: 该平台为6G动态场景下的信道模型分析和优化提供了重要工具，支持环境感知信道建模，有助于推进6G通信与感知的深度融合。

Abstract: 6G system is evolving toward full-spectrum coverage,ultra-wide bandwidth, and high mobility, resulting in increasingly complex propagation environments. The deep integration of communication and sensing is widely recognized as a core 6G vision, underscoring the importance of comprehensive environment awareness. Accurate channel modeling forms the foundation of 6G system design and optimization, and channel sounders provide the essential empirical basis. However, existing channel sounders, although supporting wide bandwidth and large antenna arrays in selected bands, generally lack cross-band capability, struggle in dynamic scenarios, and provide limited environmental awareness. The absence of detailed environmental information restricts the development of environment-aware channel models. To address this gap, we propose a multi-modal sensing and channel sounding fusion platform that enables temporally and spatially synchronized acquisition of images, point clouds, geolocation information, and multi-band multi-antenna channel data. The modular architecture facilitates rapid deployment in diverse dynamic environments. The platform supports Sub-6 GHz and mmWave bands with up to 1 GHz bandwidth and 1 ns delay resolution, enabling multi-antenna measurements with a channel switching rate of 8 ms. Moreover, it achieves centimeter-level and 360° environmental sensing accuracy and meter-level positioning accuracy. Key performance metrics of the platform, including dynamic range, phase stability, delay resolution, and multimodal data synchronization, are validated through vehicle-to-infrastructure measurement campaign. The established platform supports environment-channel joint modeling, enabling analysis and optimization of channel models in dynamic 6G scenarios.

</details>


### [87] [On the Extension of Private Distributed Matrix Multiplication Schemes to the Grid Partition](https://arxiv.org/abs/2601.17834)
*Christoph Hofmeister,Razane Tajeddine,Antonia Wachter-Zeh,Rawad Bitar*

Main category: cs.IT

TL;DR: 本文提出了一种将现有外积分区私有分布式矩阵乘法编码扩展到网格分区的方法，并展示了新方案在某些参数下优于现有技术


<details>
  <summary>Details</summary>
Motivation: 现有私有分布式矩阵乘法编码要么专门用于外积分区，要么用于内积分区，要么适用于更一般的网格分区。需要设计一种方法将现有的外积分区编码扩展到网格分区，以改进某些参数下的性能

Method: 设计了扩展操作，可以将一大类外积分区编码设计扩展到网格分区情况。将这些操作应用于现有编码，并展示了扩展后的网格分区方案满足额外的组合约束，但也提出了不遵守这些约束的新网格分区方案

Result: 扩展操作应用于现有编码后，在某些参数下改进了现有技术水平。同时发现扩展后的网格分区方案满足额外的组合约束，这可能限制其性能。提出的新网格分区方案不遵守这些约束，在一系列参数下优于现有技术

Conclusion: 通过扩展操作可以将外积分区编码扩展到网格分区，但扩展方案存在组合约束限制性能。不遵守这些约束的新方案能获得更好的性能，为私有分布式矩阵乘法编码设计提供了新方向

Abstract: We consider polynomial codes for private distributed matrix multiplication (PDMM/SDMM). Existing codes for PDMM are either specialized for the outer product partitioning (OPP), or inner product partitioning (IPP), or are valid for the more general grid partitioning (GP). We design extension operations that can be applied to a large class of OPP code designs to extend them to the GP case. Applying them to existing codes improves upon the state-of-the-art for certain parameters. Additionally, we show that the GP schemes resulting from extension fulfill additional combinatorial constraints, potentially limiting their performance. We illustrate this point by presenting a new GP scheme that does not adhere to these constraints and outperforms the state-of-the-art for a range of parameters.

</details>


### [88] [Phase-Rotated Symbol Spreading for Scalable Rydberg Atomic-MIMO Detection](https://arxiv.org/abs/2601.17838)
*Jiuyu Liu,Yi Ma,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出相位旋转符号扩展(PRSS)方法，通过两个连续时隙传输每个符号并引入π/2相位偏移，解决Rydberg原子接收机MIMO系统的非线性信号检测问题，实现有效线性信号模型重建。


<details>
  <summary>Details</summary>
Motivation: Rydberg原子接收机的MIMO系统面临非线性信号模型带来的信号检测可扩展性挑战，需要解决这一瓶颈以提升系统性能。

Method: 提出相位旋转符号扩展(PRSS)方法，在每个符号的两个连续传输时隙中引入最优π/2相位偏移，从而重建有效的线性信号模型，同时保持频谱效率并支持传统RF-MIMO检测算法。

Result: 仿真结果显示，与现有单次传输方法相比，PRSS在使用最优穷举搜索和低复杂度次优检测方法时，分别实现了超过2.5dB和10dB的误码率改善。

Conclusion: PRSS方法有效解决了Rydberg原子接收机MIMO系统的非线性信号检测问题，显著提升了系统性能，为实际应用提供了可行的解决方案。

Abstract: Multiple-input multiple-output (MIMO) systems using Rydberg atomic (RA) receivers face significant scalability challenges in signal detection due to their nonlinear signal models. This letter proposes phase-rotated symbol spreading (PRSS), which transmits each symbol across two consecutive time slots with an optimal π/2 phase offset. PRSS enables reconstruction of an effective linear signal model while maintaining spectral efficiency and facilitating the use of conventional RF-MIMO detection algorithms. Simulation results demonstrate that PRSS achieves greater than 2.5 dB and 10 dB bit error rate improvements compared to current single-transmission methods when employing optimal exhaustive search and low-complexity sub-optimal detection methods, respectively.

</details>


### [89] [Information-Theoretic Secure Aggregation in Decentralized Networks](https://arxiv.org/abs/2601.17970)
*Xiang Zhang,Zhou Li,Shuangyang Li,Kai Wan,Derrick Wing Kwan Ng,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文研究了去中心化安全聚合（DSA）问题，确定了在去中心化联邦学习和随机优化中安全计算输入和所需的最小通信和密钥速率。


<details>
  <summary>Details</summary>
Motivation: 随着去中心化联邦学习和随机优化中对数据安全需求的增加，需要解决在满足安全要求的同时计算所有用户输入和的问题。安全要求是：即使与最多T个其他用户合谋，任何用户也不能学习到超出预期和的信息。

Method: 研究K个互连用户网络，每个用户持有私有输入（如联邦学习中的本地模型更新）。通过信息论方法分析去中心化安全聚合问题，推导出最优速率区域。

Result: 确定了DSA的基本性能限制：要安全计算1比特的输入和，每个用户必须（i）向所有其他用户传输至少1比特，（ii）持有至少1比特秘密密钥，（iii）所有用户总共必须持有不少于K-1个独立密钥比特。

Conclusion: 该研究建立了去中心化安全聚合的基本性能极限，为设计可证明安全且通信高效的分布式学习系统协议提供了理论基础和设计指导。

Abstract: Motivated by the increasing demand for data security in decentralized federated learning (FL) and stochastic optimization, we formulate and investigate the problem of information-theoretic \emph{decentralized secure aggregation} (DSA). Specifically, we consider a network of $K$ interconnected users, each holding a private input, representing, for example, local model updates in FL, who aim to simultaneously compute the sum of all inputs while satisfying the security requirement that no user, even when colluding with up to $T$ others, learns anything beyond the intended sum. We characterize the optimal rate region, which specifies the minimum achievable communication and secret key rates for DSA. In particular, we show that to securely compute one bit of the desired input sum, each user must (i) transmit at least one bit to all other users, (ii) hold at least one bit of secret key, and (iii) all users must collectively hold no fewer than $K - 1$ independent key bits. Our result establishes the fundamental performance limits of DSA and offers insights into the design of provably secure and communication-efficient protocols for distributed learning systems.

</details>


### [90] [Secure Beamforming and Reflection Design for RIS-ISAC Systems under Collusion of Passive and Active Eavesdroppers](https://arxiv.org/abs/2601.18063)
*Tian Zhang,Zhirong Su,Yueyi Dong*

Main category: cs.IT

TL;DR: 研究RIS辅助的ISAC系统中物理层安全问题，针对主动和被动窃听者合作场景，通过联合基站波束赋形和RIS反射设计，在保证感知性能下最大化系统保密率。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的ISAC系统中，存在主动和被动窃听者合作的安全威胁，需要设计有效的安全机制来保证通信保密性，同时满足感知性能要求。

Method: 将保密率最大化问题分解为三个子问题，采用交替优化框架，结合二次惩罚法和逐次凸逼近技术求解，提出JBRD联合波束赋形和反射设计算法。

Result: 提出的JBRD算法在数值仿真中表现出有效性和优越性，能够有效提升系统保密率，同时保证感知性能要求。

Conclusion: 通过联合基站波束赋形和RIS反射设计，可以有效应对ISAC系统中主动和被动窃听者合作的安全威胁，在保证感知性能的同时实现安全通信。

Abstract: In the paper, the physical-layer security for reconfigurable intelligent surface (RIS) aided integrated sensing and communication (ISAC) system is studied. There is an active eavesdropper (AE) as well as a passive eavesdropper (PE), and they cooperate each other. By joint base station beamforming and RIS reflection design, we aim to achieve the best secure data communications with guaranteed sensing performance. Mathematically, taking the constraints on sensing performance and transmission power in consideration, the system secrecy rate maximization problem is formulated with respect to transmitting beamforming, RIS reflection, and receiving beamforming. The formulated problem is non-convex and is decomposed to three subproblem by applying the alternating optimization scheme. For the decomposed subproblem, we utilize the quadratic penalty method and successive convex approximation (SCA) for the solution derivation. Thereafter, an iterative numerical algorithm, referred to as the joint beamforming and reflection design (JBRD) algorithm, is proposed. Finally, numerical results demonstrate the effectiveness and superiority of the proposed algorithm.

</details>


### [91] [Tail-Latency-Aware Federated Learning with Pinching Antenna: Latency, Participation, and Placement](https://arxiv.org/abs/2601.18097)
*Yushen Lin,Zhiguo Ding*

Main category: cs.IT

TL;DR: PASS系统通过可调天线改变客户端上行延迟，联合优化天线位置和客户端选择，最小化达到目标精度所需时间，在统计异构性下平衡延迟与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 同步无线联邦学习中，慢客户端（straggler）是主要瓶颈。在非独立同分布数据下，仅选择快速客户端会因统计异构性显著降低收敛速度。需要平衡延迟与统计多样性。

Method: 提出PASS系统，使用可调辐射夹持天线（PA）沿介质波导任意位置激活以重塑上行延迟。联合优化PA位置和客户端参与，最小化预期时间到精度，结合顺序统计量的精确预期最大轮延迟与异构感知收敛因子。

Result: 推导出一阶最优性条件，揭示KKT递归中的显式尾部延迟溢价；在延迟类结构下获得类内平方根采样定律；建立两类别相变，当每轮样本量增长时，慢类别参与在显式异构阈值条件下崩溃；为PA位置提供分段包络导数特征和精确断点-根候选枚举程序。

Conclusion: PASS系统通过智能天线放置和客户端选择，在统计异构性下实现更好的延迟-收敛权衡，使更多合格客户端参与，提高时钟精度。仿真验证了理论发现。

Abstract: Straggler synchronization is a dominant wall-clock bottleneck in synchronous wireless federated learning (FL). Under non-IID data, however, aggressively sampling only fast clients may significantly slow convergence due to statistical heterogeneity. This paper studies PASS-enabled FL, where a radiating pinching antenna (PA) can be activated at an arbitrary position along a dielectric waveguide to reshape uplink latencies. We consider a joint optimization of PA placement and client participation to minimize the expected time-to-accuracy, coupling the exact expected maximum round latency via order statistics with a heterogeneity-aware convergence factor. We derive first-order optimality conditions that reveal an explicit tail-latency premium in the KKT recursion, quantifying how latency gaps are amplified by maximum-order-statistic synchronization. Under a latency-class structure, we obtain a within-class square-root sampling law and establish a two-class phase transition where slow-class participation collapses under an explicit heterogeneity-threshold condition as the per-round sample size grows. For PA placement, we prove a piecewise envelope-derivative characterization and provide an exact breakpoint-and-root candidate-enumeration procedure. Simulation results verify the theoretical findings and show that PASS enables more eligible participation, yielding higher wall-clock accuracy.

</details>


### [92] [Scalable Quantum Message Passing Graph Neural Networks for Next-Generation Wireless Communications: Architectures, Use Cases, and Future Directions](https://arxiv.org/abs/2601.18198)
*Le Tung Giang,Nguyen Xuan Tung,Trinh Van Chien,Lajos Hanzo,Won-Joo Hwang*

Main category: cs.IT

TL;DR: 提出SQM-GNN，一种结合量子计算和图神经网络的无线资源管理方法，通过子图分解和共享参数化量子电路解决量子比特限制问题，在D2D功率控制任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统GNN在无线资源管理中面临大规模密集网络的计算挑战，量子计算与GNN结合可提升计算效率，但现有纯量子消息传递模型受限于量子比特数量，难以扩展到无线系统。

Method: 提出可扩展量子消息传递图神经网络(SQM-GNN)，将图分解为子图，对每个局部子图应用共享参数化量子电路(PQC)，同时结合节点和边特征以完整表示无线图结构。

Result: 在设备到设备(D2D)功率控制任务中，SQM-GNN表现优于传统GNN和启发式基线方法，证明了其有效性。

Conclusion: SQM-GNN为解决量子比特限制提供了可行方案，展示了量子增强GNN在无线网络优化中的潜力，是未来无线网络优化的有前景方向。

Abstract: Graph Neural Networks (GNNs) are eminently suitable for wireless resource management, thanks to their scalability, but they still face computational challenges in large-scale, dense networks in classical computers. The integration of quantum computing with GNNs offers a promising pathway for enhancing computational efficiency because they reduce the model complexity. This is achieved by leveraging the quantum advantages of parameterized quantum circuits (PQCs), while retaining the expressive power of GNNs. However, existing pure quantum message passing models remain constrained by the limited number of qubits, hence limiting the scalability of their application to the wireless systems. As a remedy, we conceive a Scalable Quantum Message Passing Graph Neural Network (SQM-GNN) relying on a quantum message passing architecture. To address the aforementioned scalability issue, we decompose the graph into subgraphs and apply a shared PQC to each local subgraph. Importantly, the model incorporates both node and edge features, facilitating the full representation of the underlying wireless graph structure. We demonstrate the efficiency of SQM GNN on a device-to-device (D2D) power control task, where it outperforms both classical GNNs and heuristic baselines. These results highlight SQM-GNN as a promising direction for future wireless network optimization.

</details>


### [93] [Complex-Valued-Matrix Permanents: SPA-based Approximations and Double-Cover Analysis](https://arxiv.org/abs/2601.18232)
*Junda Zhou,Pascal O. Vontobel*

Main category: cs.IT

TL;DR: 将基于因子图的正规因子图上的和积算法（SPA）方法从非负实值矩阵扩展到复值矩阵的永久近似，使用双边缘正规因子图，并分析SPA固定点和Bethe近似的性质。


<details>
  <summary>Details</summary>
Motivation: 复值矩阵的永久近似是玻色子采样和概率推断等应用中的基本问题。现有方法主要针对非负实值矩阵，需要扩展到复值矩阵以处理更广泛的应用场景。

Method: 扩展基于因子图的方法：1）使用双边缘正规因子图（double-edge normal factor graphs）运行和积算法（SPA）来近似复值矩阵的永久；2）从算法角度研究SPA在从实值到复值矩阵集合转换时的固定点行为；3）从分析角度使用图覆盖（graph covers）分析Bethe近似。

Result: 通过算法和分析相结合的方法，深入理解了复值问题中Bethe近似的结构，明确了这种近似在非负实值设置之外何时仍然有意义。

Conclusion: 该研究为复值矩阵的永久近似提供了新的因子图方法，并阐明了Bethe近似在复值设置中的有效性和局限性，为玻色子采样和概率推断等应用提供了理论基础。

Abstract: Approximating the permanent of a complex-valued matrix is a fundamental problem with applications in Boson sampling and probabilistic inference. In this paper, we extend factor-graph-based methods for approximating the permanent of non-negative-real-valued matrices that are based on running the sum-product algorithm (SPA) on standard normal factor graphs, to factor-graph-based methods for approximating the permanent of complex-valued matrices that are based on running the SPA on double-edge normal factor graphs.
  On the algorithmic side, we investigate the behavior of the SPA, in particular how the SPA fixed points change when transitioning from real-valued to complex-valued matrix ensembles. On the analytical side, we use graph covers to analyze the Bethe approximation of the permanent, i.e., the approximation of the permanent that is obtained with the help of the SPA.
  This combined algorithmic and analytical perspective provides new insight into the structure of Bethe approximations in complex-valued problems and clarifies when such approximations remain meaningful beyond the non-negative-real-valued settings.

</details>


### [94] [A Heterogeneous Massive MIMO Technique for Uniform Service in Cellular Networks](https://arxiv.org/abs/2601.18298)
*Wei Jiang,Hans D. Schotten*

Main category: cs.IT

TL;DR: 提出一种成本效益高的异构大规模MIMO架构，结合集中式基站天线和分布式边缘接入点，在保持用户公平性的同时大幅降低基础设施成本。


<details>
  <summary>Details</summary>
Motivation: 传统蜂窝网络对小区边缘用户服务质量差，而无小区系统虽然提供均匀服务质量但部署成本过高，需要大量接入点站点和光纤网络连接。

Method: 提出异构大规模MIMO架构，将大规模天线在集中式基站和分布式边缘接入点之间进行战略分配，减少所需接入点数量和前传连接。

Result: 数值结果表明，该架构在性能和成本平衡方面优于蜂窝和无细胞系统，在保持与无细胞系统相当的用户公平性的同时大幅降低基础设施成本。

Conclusion: 该异构大规模MIMO架构提供了一种成本效益高的解决方案，在用户公平性和基础设施成本之间实现了良好平衡，优于传统蜂窝和无细胞系统。

Abstract: Traditional cellular networks struggle with poor quality of service (QoS) for cell-edge users, while cell-free (CF) systems offer uniform QoS but incur high roll-out costs due to acquiring numerous access point (AP) sites and deploying a large-scale optical fiber network to connect them. This paper proposes a cost-effective heterogeneous massive MIMO architecture that integrates centralized co-located antennas at a cell-center base station with distributed edge APs. By strategically splitting massive antennas between centralized and distributed nodes, the system maintains high user fairness comparable to CF systems but reduces infrastructure costs substantially, by minimizing the required number of AP sites and fronthaul connections. Numerical results demonstrate its superiority in balancing performance and costs compared to cellular and CF systems.

</details>


### [95] [Time-Scale-Adaptable Spectrum Sharing for Hybrid Satellite-Terrestrial Networks](https://arxiv.org/abs/2601.18410)
*Yanmin Wang,Wei Feng,Yunfei Chen,Yongxu Zhu,Shidong Zhou,Cheng-Xiang Wang*

Main category: cs.IT

TL;DR: 提出了一种卫星-地面混合网络中基于时间尺度适应的频谱共享框架，通过链路特征草图辅助的层次化链路聚类和蒙特卡洛-逐次逼近辅助的功率优化，实现统计CSI下的联合链路调度与功率控制，以最大化网络平均和速率。


<details>
  <summary>Details</summary>
Motivation: 卫星与地面无线网络的协同合作能够满足日益增长的泛在通信覆盖需求，但面临频谱稀缺的挑战。需要研究频谱共享方案来解决卫星链路与地面链路在相同子载波上的机会共享问题。

Method: 提出时间尺度可适应的频谱共享框架，卫星-地面协作时间尺度可根据实际需求灵活调整。基于统计CSI，采用链路特征草图辅助的层次化链路聚类进行链路调度，结合蒙特卡洛-逐次逼近方法进行发射功率优化，解决复杂的混合整数规划问题。

Result: 仿真结果表明，通过链路特征草图能够充分利用用户空间分布带来的链路多样性。即使在严格的链路间干扰约束下，所提方案仍能实现显著的性能增益。

Conclusion: 提出的低复杂度频谱共享方案能够有效解决卫星-地面混合网络的频谱共享问题，通过灵活的协作时间尺度和统计CSI下的优化设计，在保证用户服务质量的同时最大化网络和速率。

Abstract: Cooperation between satellite and terrestrial wireless networks promises great potential in meeting fast-growing demands for ubiquitous communications coverage. To tackle spectrum scarcity, spectrum sharing is studied for a hybrid satellite-terrestrial network where satellite links share the same group of time-slotted sub-carriers with terrestrial links opportunistically. In particular, with coarse network-wide time synchronization, a time-scale-adaptable spectrum sharing framework is proposed based on a satellite-terrestrial cooperation time scale that can be flexibly adjusted according to practical requirements. For generality, it is assumed that both full and partial frequency reuse could be adopted among the base stations (BSs) and satellite selection is supported when multiple satellites are available. Relying on only statistical channel state information (CSI), joint link scheduling and power control are explored to maximize the average sum rate of the network while ensuring quality of service (QoS) for users. To solve the complicated mixed integer programming (MIP) problem, a low-complexity spectrum sharing scheme is presented based on link-feature-sketching-aided hierarchical link clustering and Monte-Carlo-and-successive-approximation-aided transmit power optimization. Simulation results demonstrate that by link feature sketching, diversity of the links brought by the spatial distribution of the users could be well utilized. The proposed scheme promises a significant performance gain even under strict inter-link interference constraints.

</details>


### [96] [On the Optimal Message Size in PIR Under Arbitrary Collusion Patterns](https://arxiv.org/abs/2601.18440)
*Guru S. Dornadula,Manikya Pant,Gowtham R. Kurri,Prasad Krishnan*

Main category: cs.IT

TL;DR: 该论文研究了在任意合谋模式下可分解PIR方案的最优消息大小，提出了通用下界，并在特定合谋模式下给出了匹配的可实现方案。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注无合谋情况下的最优消息大小(N-1)，但对于更一般的合谋模式缺乏可比结果。实际应用中，较小的消息大小能降低实现复杂度并减少约束，因此需要研究任意合谋模式下可分解PIR方案的最优消息大小。

Method: 首先完整刻画了任意合谋模式下容量可达的可分解PIR方案的性质。基于此刻画，推导出在任意合谋模式P下，容量可达的均匀可分解PIR方案的最优消息大小的通用下界，该下界用由合谋模式P决定的服务器子集族的新定义命中数表示。最后将下界专门应用于几类重要的合谋模式。

Result: 提出了任意合谋模式下最优消息大小的通用下界。对于循环T连续合谋和不相交的循环连续合谋集这两类模式，给出了达到相应下界的可实现方案，从而完全刻画了最优消息大小。

Conclusion: 该工作首次系统研究了任意合谋模式下可分解PIR方案的最优消息大小问题，建立了通用理论框架，并在特定重要合谋模式下给出了完整解决方案，填补了该领域的研究空白。

Abstract: A private information retrieval protocol (PIR) scheme under an arbitrary collusion pattern $\mathcal{P}$ enables a client to retrieve one message from a library of $K$ equal-sized messages duplicated in $N$ servers, while keeping the index of the desired message private from any colluding set in $\mathcal{P}$. Although achieving high rates typically requires sufficiently large message sizes, smaller message sizes also desirable due to reduced implementation complexity and fewer constraints. By characterizing the capacity-achieving schemes, Tian, Sun, and Chen (2019) showed that the optimal message size for uniformly decomposable PIR schemes under no-collusion setting is $N-1$. However, comparable results are not yet available for more general collusion settings.
  In this work, we present a complete characterization of the properties of capacity-achieving decomposable PIR schemes under arbitrary collusion patterns. Building on this characterization, we derive a general lower bound on the optimal message size for capacity-achieving uniformly decomposable PIR schemes under an arbitrary collusion pattern $\mathcal{P}$, expressed in terms of the hitting number of a newly defined family of subsets of servers determined by the collusion pattern $\mathcal{P}$. Finally, we specialize the lower bound to several important classes of collusion patterns, including $T$-collusion, disjoint collections of colluding sets, cyclically $T$-contiguous collusion, and disjoint collections of cyclically contiguous colluding sets. For the last two collusion patterns, we present matching achievable schemes that attain the corresponding bounds, thereby providing a complete characterization of the optimal message size.

</details>


### [97] [Coding Schemes for Document Exchange under Multiple Substring Edits](https://arxiv.org/abs/2601.18441)
*Hrishi Narayanan,Vinayak Ramkumar,Rawad Bitar,Antonia Wachter-Zeh*

Main category: cs.IT

TL;DR: 提出低复杂度文档交换方案，处理多子串编辑，编码长度4t log n+o(log n)比特，优于现有高复杂度方案；进一步研究均匀字符串平均编码长度，达到(4t-1) log n+o(log n)比特


<details>
  <summary>Details</summary>
Motivation: 研究多子串编辑下的文档交换问题，现有最佳方案编码长度为4t log n+O(log log n)比特但计算复杂度高，需要设计低复杂度的有效方案

Method: 构造低复杂度文档交换方案，处理多个有界长度子串编辑；针对均匀字符串场景，开发平均编码长度更优的方案

Result: 实现编码长度4t log n+o(log n)比特的低复杂度方案；在均匀字符串下达到(4t-1) log n+o(log n)比特的期望编码长度

Conclusion: 成功设计出计算复杂度显著降低的文档交换方案，并在均匀字符串场景下进一步优化编码长度，扩展了多子串编辑问题的解决方案

Abstract: We study the document exchange problem under multiple substring edits. A substring edit in a string $\mathbf{x}$ occurs when a substring $\mathbf{u}$ of $\mathbf{x}$ is replaced by an arbitrary string $\mathbf{v}$. The lengths of $\mathbf{u}$ and $\mathbf{v}$ are bounded from above by a fixed constant. Let $\mathbf{x}$ and $\mathbf{y}$ be two binary strings that differ by multiple substring edits. The aim of document exchange schemes is to construct an encoding of $\mathbf{x}$ with small length such that $\mathbf{x}$ can be recovered using $\mathbf{y}$ and the encoding. We construct a low-complexity document exchange scheme with encoding length of $4t\log n+o(\log n)$ bits, where $n$ is the length of the string $\mathbf{x}$. The best known scheme achieves an encoding length of $4t \log n+O(\log\log n)$ bits, but at a much higher computational complexity. Then, we investigate the average length of valid encodings for document exchange schemes with uniform strings $\mathbf{x}$ and develop a scheme with an expected encoding length of $(4t-1) \log n+o(\log n)$ bits. In this setting, prior works have only constructed schemes for a single substring edit.

</details>


### [98] [Finite-Aperture Fluid Antenna Array Design: Analysis and Algorithm](https://arxiv.org/abs/2601.18471)
*Zhentian Zhang,Kai-Kit Wong,Hao Jiang,Farshad Rostami Ghadi,Hyundong Shin,Yangyang Zhang*

Main category: cs.IT

TL;DR: 该论文针对有限孔径下的流体天线阵列设计问题，推导了统一的CRB闭式解和最小间距概率分布，提出了基于梯度的连续端口位置优化算法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 有限孔径约束使得阵列设计变得复杂，可能削弱传统稀疏几何结构的有效性。需要为固定孔径下的流体天线阵列设计提供通用指导。

Method: 1. 推导了统一的闭式Cramér-Rao界，将Fisher信息与端口位置几何方差明确关联；2. 获得了随机FAA放置下最小间距的闭式概率密度函数；3. 提出了基于梯度的连续端口位置优化算法。

Result: 优化的FAA可实现约30%的CRB降低和42.5%的均方误差减少，显著提升了阵列性能。

Conclusion: 该研究为有限孔径下的流体天线阵列设计提供了理论分析和实用算法，通过优化端口位置显著提升了阵列性能，为FAA设计提供了通用指导。

Abstract: Finite-aperture constraints render array design nontrivial and can undermine the effectiveness of classical sparse geometries. This letter provides universal guidance for fluid antenna array (FAA) design under a fixed aperture. We derive a closed-form Cramér--Rao bound (CRB) that unifies conventional and reconfigurable arrays by explicitly linking the Fisher information to the geometric variance of port locations. We further obtain a closed-form probability density function of the minimum spacing under random FAA placement, which yields a principled lower bound for the minimum-spacing constraint. Building upon these analytical insights, we then propose a gradient-based algorithm to optimize continuous port locations. Utilizing a simple gradient update design, the optimized FAA can achieve about a $30\%$ CRB reduction and a $42.5\%$ reduction in mean-squared error.

</details>


### [99] [Ribbons from Independence Structure: Hypercontractivity, $Φ$-Mutual Information, and Matrix $Φ$-Entropy](https://arxiv.org/abs/2601.18516)
*Chenyu Wang,Amin Gohari*

Main category: cs.IT

TL;DR: 研究服从给定独立性结构的联合分布的hypercontractivity ribbon和Φ-ribbon，在基本机制中获得紧界，提出矩阵Φ-ribbon并建立张量化和数据处理性质


<details>
  <summary>Details</summary>
Motivation: 研究具有特定独立性结构的多元随机变量分布的hypercontractivity ribbon和Φ-ribbon，探索这些信息理论工具在复杂依赖结构下的性质和行为

Method: 使用超图建模独立性结构，提供Φ-ribbon的显式内界描述为关联向量的凸包；提出多部推广版本和Φ-互信息的Zhang-Yeung不等式类似物；基于矩阵Φ-熵提出矩阵Φ-ribbon

Result: 在基本机制中获得紧界；为一般独立性结构提供Φ-ribbon的简单凸包描述；建立矩阵Φ-ribbon的张量化和数据处理性质；计算双对称二元源的精确矩阵SDPI常数

Conclusion: 该研究扩展了hypercontractivity ribbon和Φ-ribbon理论到具有复杂独立性结构的分布，提供了新的数学工具和不等式，为信息理论中的依赖结构分析开辟了新方向

Abstract: We study the hypercontractivity ribbon and the $Φ$-ribbon for joint distributions that obey a given independence structure, obtaining tight bounds in some basic regimes. For general independence structures, modeled as a hypergraph whose hyperedges specify mutually independent subcollections of random variables, we provide an explicit inner bound on the $Φ$-ribbon described by a simple convex hull of incidence vectors. We also provide a new multipartite generalization version and a $Φ$-mutual information analogue of the Zhang--Yeung inequality, which implies nontrivial points in the hypercontractivity ribbon and the $Φ$-ribbon respectively. Finally, we propose the matrix $Φ$-ribbon based on matrix $Φ$-entropy and establish the tensorization and data processing properties, together with the calculation of an exact matrix SDPI constant for the doubly symmetric binary source.

</details>


### [100] [Improvement of the Gilbert-Varshamov Bound for Linear Codes and Quantum Codes](https://arxiv.org/abs/2601.18590)
*Chen Yuan,Ruiqi Zhu*

Main category: cs.IT

TL;DR: 本文改进了经典的Gilbert-Varshamov(GV)界，对q元线性码和量子码分别给出了更好的存在性界限，改进因子为Ω(√n)。


<details>
  <summary>Details</summary>
Motivation: GV界是编码理论的核心基准，但几十年来改进困难，已知改进通常技术复杂且难以推广到量子设置。本文旨在开发简洁的概率方法，同时改进经典和量子GV界。

Method: 开发了简洁的概率方法，通过分析q元线性码的存在条件，并进一步适应量子设置，分析辛自正交结构。

Result: 对于相对距离δ<1-1/q的q元线性码，存在性条件改进为(q^k-1)/(q-1) < c_δ√n q^n/Vol_q(n,d-1)。对于量子码(δ<1-1/q^2)，存在性条件改进为(q^{2n-k}-1)/(q-1) < c_δ√n·q^{2n}/Σ_{i=0}^{d-1} C(n,i)(q^2-1)^i。

Conclusion: 本文成功改进了经典和量子GV界，获得了Ω(√n)的乘法因子改进，为编码理论提供了更好的存在性保证。

Abstract: The Gilbert--Varshamov (GV) bound is a central benchmark in coding theory, establishing existential guarantees for error-correcting codes and serving as a baseline for both Hamming and quantum fault-tolerant information processing. Despite decades of effort, improving the GV bound is notoriously difficult, and known improvements often rely on technically heavy arguments and do not extend naturally to the quantum setting due to additional self-orthogonality constraints.
  In this work we develop a concise probabilistic method that yields an improvement over the classical GV bound for $q$-ary linear codes. For relative distance $δ=d/n<1-1/q$, we show that an $[n,k,d]_q$ linear code exists whenever $\frac{q^{k}-1}{q-1}\;<\;\frac{c_δ\sqrt{n}\, q^{n}}{\mathrm{Vol}_q(n,d-1)}$, for positive constant $c_δ$ depending only on $δ$, where $\mathrm{Vol}_q(n,d-1)$ denotes the volume of a $q$-ary Hamming ball.
  We further adapt this approach to the quantum setting by analyzing symplectic self-orthogonal structures. For $δ<1-1/q^2$, we obtain an improved quantum GV bound: there exists a $q$-ary quantum code $[[n,\,n-k,\,d]]$ provided that $\frac{q^{2n-k}-1}{q-1}<\frac{c_δ\sqrt{n}\cdot q^{2n}}{\sum_{i=0}^{d-1}\binom{n}{i}(q^2-1)^i}$. In particular, our result improves the standard quantum GV bound by an $Ω(\sqrt{n})$ multiplicative factor.

</details>


### [101] [Quantum Rotation Diversity in Displaced Squeezed Binary Phase-Shift Keying](https://arxiv.org/abs/2601.18655)
*Ioannis Krikidis*

Main category: cs.IT

TL;DR: 提出量子旋转分集方案，在Gamma-Gamma湍流信道中使用BPSK位移压缩态和零差检测，通过被动正交旋转耦合连续时隙，实现分集增益


<details>
  <summary>Details</summary>
Motivation: 解决光量子通信在湍流信道中的性能问题，通过分集技术提高通信可靠性

Method: 使用二进制相移键控位移压缩态，通过被动正交旋转耦合连续时隙，重新分配位移幅度，采用联合最大似然检测

Result: 在独立衰落下获得分集阶数为2，当位移幅度和压缩强度随总光子数缩放时，有效分集阶数可达4，数值结果验证了超分集行为

Conclusion: 量子旋转分集方案能显著提高光量子通信在湍流信道中的性能，实现超分集增益

Abstract: We propose a quantum rotation diversity (QRD) scheme for optical quantum communication using binary phase-shift-keying displaced squeezed states and homodyne detection over Gamma-Gamma turbulence channels. Consecutive temporal modes are coupled by a passive orthogonal rotation that redistributes the displacement amplitude between slots, yielding a diversity order of two under independent fading and joint maximum-likelihood detection. Analytical expressions for the symbol-error rate performance, along with asymptotic results for the diversity and coding gains, are derived. The optimal rotation angle and energy allocation between displacement and squeezing are obtained in closed form. Furthermore, we show that when both the displacement amplitude and the squeezing strength scale with the total photon number, an effective diversity order of four is achieved. Numerical results validate the analysis and demonstrate the super-diversity behaviour of the proposed QRD scheme.

</details>


### [102] [Balancing Privacy and Robustness in Coded Computing Under Profiled Workers](https://arxiv.org/abs/2601.18661)
*Rimpi Borah,J. Harshan,Aaditya Sharma*

Main category: cs.IT

TL;DR: 在不可信分布式计算中，评估索引分配影响隐私和鲁棒性，NS-LCC框架下不可靠工作节点位置影响隐私保护和拜占庭错误定位能力


<details>
  <summary>Details</summary>
Motivation: 研究在分布式不可信计算环境中，评估索引分配如何影响隐私保护和拜占庭错误定位能力，特别是在有限精度算术条件下

Method: 推导分析边界量化不同评估索引分配对隐私和鲁棒性的影响，构建优化问题识别隐私最优和鲁棒性最优索引分配，提出低复杂度贪婪分配策略

Result: 发现隐私最优和鲁棒性最优的索引分配存在根本差异，隐私最大化会降低错误定位能力，反之亦然，贪婪策略能近似最优平衡

Conclusion: 在NS-LCC框架中，索引分配需要在隐私保护和错误定位能力之间权衡，提出的贪婪策略能有效平衡这一权衡关系

Abstract: In distributed computing with untrusted workers, the assignment of evaluation indices plays a critical role in determining both privacy and robustness. In this work, we study how the placement of unreliable workers within the Numerically Stable Lagrange Coded Computing (NS-LCC) framework influences privacy and the ability to localize Byzantine errors. We derive analytical bounds that quantify how different evaluation-index assignments affect privacy against colluding curious workers and robustness against Byzantine corruption under finite-precision arithmetic. Using these bounds, we formulate optimization problems that identify privacy-optimal and robustness-optimal index placements and show that the resulting assignments are fundamentally different. This exposes that index choices that maximizes privacy degrade error-localization, and vice versa. To jointly navigate this trade-off, we propose a low-complexity greedy assignment strategy that closely approximates the optimal balance between privacy and robustness.

</details>


### [103] [A Scanning-Based Indoor Optical Wireless Positioning System with Single VCSEL](https://arxiv.org/abs/2601.18740)
*Yicheng Dong,Rashid Iqbal,Julien Le Kernec,Hanaa Abumarshoud*

Main category: cs.IT

TL;DR: 提出一种基于单VCSEL激光器的室内可见光定位系统，通过二维扫描实现三维定位，硬件简化且精度高


<details>
  <summary>Details</summary>
Motivation: 传统多发射器可见光定位系统硬件复杂、成本高，需要简化系统结构同时保持高精度定位能力

Method: 使用单个垂直腔面发射激光器安装在空间中心，以1度分辨率在方位角和仰角两个维度进行空间扫描，结合到达角和接收信号强度进行定位

Result: 仿真验证显示系统对大多数测试点达到亚厘米级精度，在成本效益和系统简化方面优于传统多发射器VLP方案

Conclusion: 提出的单VCSEL激光器VLP系统在保持高精度的同时显著简化了硬件结构，为室内定位提供了更经济高效的解决方案

Abstract: This paper presents a novel indoor visible light positioning (VLP) system utilising one vertical-cavity surface-emitting laser installed at the ceiling centre of a space. The system offers three-dimensional localisation by sweeping through space at one-degree resolution in two dimensions (azimuth and elevation), significantly simplifying hardware. Through incorporating the angle of arrival and received signal strength, this system demonstrates excellent precision in indoor positioning. Simulation results verify that the system attains sub-centimetre precision for most test points, outperforming conventional multi-transmitter VLP schemes in cost-efficiency and simplicity.

</details>


### [104] [Multi-Stage Structured Estimators for Information Freshness](https://arxiv.org/abs/2601.18763)
*Sahan Liyanaarachchi,Sennur Ulukus,Nail Akar*

Main category: cs.IT

TL;DR: 提出了p-MAP估计器，将MAP估计器建模为有限段的分段常数函数，解决了信息新鲜度分析中传统martingale估计器不优而MAP估计器分析困难的问题。


<details>
  <summary>Details</summary>
Motivation: 当前信息新鲜度文献主要关注martingale估计器（仅使用最新更新作为当前估计），虽然易于分析但远非最优。在基于拉取的更新系统中，MAP估计器已知是最优的，但分析上具有挑战性。

Method: 引入新的p-MAP估计器类别，将MAP估计器建模为具有有限阶段的分段常数函数，从而更接近对信息新鲜度建模时MAP估计器的完整表征。

Result: p-MAP估计器能够将复杂的MAP估计器问题转化为更易处理的分段常数函数形式，为信息新鲜度分析提供了新的理论框架。

Conclusion: 通过提出p-MAP估计器，本文在信息新鲜度分析中填补了传统martingale估计器与最优但分析困难的MAP估计器之间的理论空白，为更精确的信息新鲜度建模提供了新途径。

Abstract: Most of the contemporary literature on information freshness solely focuses on the analysis of freshness for martingale estimators, which simply use the most recently received update as the current estimate. While martingale estimators are easier to analyze, they are far from optimal, especially in pull-based update systems, where maximum aposteriori probability (MAP) estimators are known to be optimal, but are analytically challenging. In this work, we introduce a new class of estimators called $p$-MAP estimators, which enable us to model the MAP estimator as a piecewise constant function with finitely many stages, bringing us closer to a full characterization of the MAP estimators when modeling information freshness.

</details>
