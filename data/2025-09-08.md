<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 18]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [NEXUS: Efficient and Scalable Multi-Cell mmWave Baseband Processing with Heterogeneous Compute](https://arxiv.org/abs/2509.04625)
*Zhenzhou Qi,Chung-Hsuan Tung,Zhihui Gao,Tingjun Chen*

Main category: cs.NI

TL;DR: NEXUS是首个在单服务器上实现实时虚拟化多小区毫米波基带处理的系统，通过软硬件协同设计和智能资源调度，支持16个并发小区，达到5.37Gbps总吞吐量，大幅减少调度搜索空间。


<details>
  <summary>Details</summary>
Motivation: 5G NR毫米波频谱的快速部署对基带处理的灵活性、可扩展性和效率提出严格要求，而多小区异构工作负载下的计算资源分配问题尚未得到充分探索。

Method: 集成软件数字信号处理流水线与硬件加速LDPC解码，通过虚拟函数共享Intel ACC100 eASIC；单小区使用随机森林模型预测能效最优资源分配，多小区采用功率感知调度器结合轻量级竞争模型。

Result: 支持最多16个并发全负载小区，实现5.37Gbps总吞吐量，多小区调度搜索空间减少数个数量级，微秒级推理延迟和高精度预测。

Conclusion: 虚拟化、资源感知的基带处理对下一代vRAN系统既实用又高效，为多小区毫米波部署提供了可行的解决方案。

Abstract: The rapid adoption of 5G New Radio (NR), particularly in the millimeter-wave
(mmWave) spectrum, imposes stringent demands on the flexibility, scalability,
and efficiency of baseband processing. While virtualized Radio Access Networks
(vRANs) enable dynamic spectrum sharing across cells, compute resource
allocation for baseband processing, especially in multi-cell deployments with
heterogeneous workloads, remains underexplored. In this paper, we present
NEXUS, the first system to realize real-time, virtualized multi-cell mmWave
baseband processing on a single server with heterogeneous compute resources.
NEXUS integrates software-based digital signal processing pipelines with
hardware-accelerated LDPC decoding, and introduces a novel framework for
sharing Intel's ACC100 eASIC across multiple CPU cores via virtual functions
(VFs). For single-cell operation, NEXUS employs a random forest (RAF)-based
model that predicts the most energy-efficient resource allocation for the given
cell configuration with microsecond-level inference latency and high accuracy.
For multi-cell scenarios, NEXUS introduces a power-aware scheduler that
incorporates a lightweight contention model to adjust resource allocation
strategies under concurrent execution. Through extensive evaluation across
various Frequency Range 2 (FR2) cell configurations, we show that NEXUS
supports up to 16 concurrent cells under full load, achieving 5.37Gbps
aggregate throughput, while reducing the multi-cell scheduling search space by
orders of magnitude. These results demonstrate that virtualized, resource-aware
baseband processing is both practical and efficient for next-generation vRAN
systems.

</details>


### [2] [Path Dynamics in a Deployed Path-Aware Network: A Measurement Study of SCIONLab](https://arxiv.org/abs/2509.04695)
*Lars Herschbach,Damien Rossi,Sina Keshvadi*

Main category: cs.NI

TL;DR: 这篇论文通过对SCION网络的综向测量研究，揭示了路径感知网络在实际环境中的动态特性，包括路径不稳定性、不对称性和性能交换，为多路径协议设计提供了重要实证数据。


<details>
  <summary>Details</summary>
Motivation: 路径感知网络虽然推说能提高性能和弹性，但缺乏实际环境中的实证数据阻碍了高效协议的设计。需要通过实际测量来理解网络动态特性。

Method: 在全球SCIONLab测试平台上进行综向测量研究，分析SCION架构的路径稳定性、多样性和性能特征，重点关注多路径QUIC协议的需求。

Result: 发现网络环境很动态，控制平面变化明显，路径寿命短。识别了路径差异现象（路由策略导致端点间不对称路径可用性）。同时多路径传输能提高总速率但可能降低单个路径的延迟和可靠性。

Conclusion: 多路径协议（如MPQUIC）应明确考虑高变化率和路径不对称性，这对传统多路径协议设计的假设构成挑战。实际测量数据对协议设计至关重要。

Abstract: Path-aware networks promise enhanced performance and resilience through
multipath transport, but a lack of empirical data on their real-world dynamics
hinders the design of effective protocols. This paper presents a longitudinal
measurement study of the SCION architecture on the global SCIONLab testbed,
characterizing the path stability, diversity, and performance crucial for
protocols like Multipath QUIC (MPQUIC). Our measurements reveal a dynamic
environment, with significant control-plane churn and short path lifetimes in
parts of the testbed. We identify and characterize path discrepancy, a
phenomenon where routing policies create asymmetric path availability between
endpoints. Furthermore, we observe a performance trade-off where concurrent
multipath transmissions can improve aggregate throughput but may degrade the
latency and reliability of individual paths. These findings demonstrate that
protocols such as MPQUIC should explicitly account for high churn and path
asymmetry, challenging common assumptions in multipath protocol design.

</details>


### [3] [Where Have All the Firewalls Gone? Security Consequences of Residential IPv6 Transition](https://arxiv.org/abs/2509.04792)
*Erik Rye,Dave Levin,Robert Beverly*

Main category: cs.NI

TL;DR: IPv6过渡使住宅网络更易受攻击，NAT曾是互联网的默认防火墙。通过大规模IPv6扫描发现，相比IPv4，IPv6网络中更多打印机、iPhone和智能灯等设备可直接访问，为物联网僵尸网络创造了新机会。


<details>
  <summary>Details</summary>
Motivation: 研究IPv4向IPv6过渡是否使住宅网络更易受攻击，评估NAT作为默认防火墙的作用消失后对物联网僵尸网络的影响。

Method: 开发了一种可在低资源IoT设备上运行的大规模IPv6扫描方法，对住宅网络进行了史上最大规模的IPv6测量，并与IPv4网络进行对比分析。

Result: 从118个国家2,436个AS的住宅网络中发现1,400万个可访问的IPv6地址，涵盖telnet、FTP等易受攻击协议，以及iPhone-Sync、IPP等终端设备协议。相比IPv4，IPv6网络中更多打印机、iPhone和智能灯设备可直接访问。

Conclusion: NAT确实起到了互联网默认防火墙的作用，IPv4向IPv6的过渡正在使新设备暴露在攻击风险之下，为下一代IPv6物联网僵尸网络提供了条件。

Abstract: IPv4 NAT has limited the spread of IoT botnets considerably by
default-denying bots' incoming connection requests to in-home devices unless
the owner has explicitly allowed them. As the Internet transitions to majority
IPv6, however, residential connections no longer require the use of NAT. This
paper therefore asks: has the transition from IPv4 to IPv6 ultimately made
residential networks more vulnerable to attack, thereby empowering the next
generation of IPv6-based IoT botnets? To answer this question, we introduce a
large-scale IPv6 scanning methodology that, unlike those that rely on AI, can
be run on low-resource devices common in IoT botnets. We use this methodology
to perform the largest-scale measurement of IPv6 residential networks to date,
and compare which devices are publicly accessible to comparable IPv4 networks.
We were able to receive responses from 14.0M distinct IPv6 addresses inside of
residential networks (i.e., not the external-facing gateway), in 2,436 ASes
across 118 countries. These responses come from protocols commonly exploited by
IoT botnets (including telnet and FTP), as well as protocols typically
associated with end-user devices (including iPhone-Sync and IPP). Comparing to
IPv4, we show that we are able to reach more printers, iPhones, and smart
lights over IPv6 than full IPv4-wide scans could. Collectively, our results
show that NAT has indeed acted as the de facto firewall of the Internet, and
the v4-to-v6 transition of residential networks is opening up new devices to
attack.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [4] [The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management](https://arxiv.org/abs/2509.04505)
*Somtochukwu Azie,Yiping Meng*

Main category: cs.AI

TL;DR: 大语言模型在建筑项目管理中的伦理决策支持能力存在显著缺陷，需要人类监督


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在建筑项目管理这种高风险、伦理敏感领域的可靠性和伦理可行性

Method: 混合研究方法：量化测试两个领先LLMs在12个真实伦理场景中的表现，使用EDSAC检查单；质性分析12位行业专家的半结构访谈

Result: LLMs在法律遵循等结构化领域表现迅速，但在处理上下文细节、确保负责任和提供透明推理方面存在显著缺陷

Conclusion: LLMs目前仅适合作为决策支持工具，而非自主伦理决策者，必须有人类在环监督

Abstract: The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.

</details>


### [5] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: Maestro是一个框架无关的LLM智能体整体优化器，通过联合搜索图结构和节点配置来最大化智能体质量，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有优化器主要调整配置而保持图结构固定，无法解决结构性故障模式，需要一种能够同时优化图结构和配置的holistic方法。

Method: 提出Maestro框架，联合搜索智能体的图结构（模块和信息流）和节点配置（模型、提示词、工具等），利用反射性文本反馈来优先编辑，提高样本效率。

Result: 在IFBench和HotpotQA基准测试中，Maestro平均领先MIPROv2 12%、GEPA 4.9%、GEPA+Merge 4.86%；即使在仅优化提示词的情况下仍保持领先，且使用比GEPA更少的rollout次数。

Conclusion: 联合图结构和配置搜索能够解决单纯提示词调优无法解决的结构性故障模式，在多个应用中显示出显著优势。

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [6] [Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization](https://arxiv.org/abs/2509.04646)
*Philippe J. Giabbanelli,Ameeta Agrawal*

Main category: cs.AI

TL;DR: 提出了一个框架来识别健康模拟中不同利益相关者的需求，并指导LLMs生成定制化的解释，以解决现有通用摘要无法满足多样化需求的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于代理的模型等建模与仿真方法在健康决策中具有重要潜力，但由于模型复杂性使得利益相关者难以使用。虽然LLMs可以将模拟输出转化为文本，但现有方法通常采用一刀切的摘要，无法反映临床医生、政策制定者、患者等不同利益相关者的多样化信息需求和风格偏好。

Method: 采用混合方法设计：首先获取不同健康利益相关者的解释需求和风格偏好，然后通过可控属性调优等方式优化LLMs生成定制化输出的能力，最后通过全面的评估指标进行评估以进一步改进定制化摘要的生成。

Result: 论文提出了一个逐步框架来系统识别利益相关者需求并指导LLMs生成针对健康模拟的定制化解释。

Conclusion: 该框架解决了健康模拟解释中的关键差距，通过系统理解不同利益相关者的需求并利用LLMs生成定制化输出，有望更好地实现建模与仿真方法在健康决策中的潜力。

Abstract: Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.

</details>


### [7] [An Approach to Grounding AI Model Evaluations in Human-derived Criteria](https://arxiv.org/abs/2509.04676)
*Sasha Mitts*

Main category: cs.AI

TL;DR: 通过人类评价标准增强AI模型评测，重点关注物理世界建模能力的评估


<details>
  <summary>Details</summary>
Motivation: 传统AI指标无法全面抓取AI模型的细致能力，需要结合人类评价标准来提升模型行为的可解释性和应用性

Method: 基于Perception Test和OpenEQA指标，进行深度访谈和大规模调查，识别关键认知技能（优先级、记忆、识别、上下文化）

Result: 发现人们认为AI缺乏解释性和共情能力，但对AI表现有高期望；提出了一个人类对齐的AI评估框架

Conclusion: 用户中心的AI评估对AI发展至关重要，为研究人员和实践者提供了可操作的指南，以实现AI能力与人类认知过程的对齐

Abstract: In the rapidly evolving field of artificial intelligence (AI), traditional
benchmarks can fall short in attempting to capture the nuanced capabilities of
AI models. We focus on the case of physical world modeling and propose a novel
approach to augment existing benchmarks with human-derived evaluation criteria,
aiming to enhance the interpretability and applicability of model behaviors.
Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted
in-depth interviews and large-scale surveys to identify key cognitive skills,
such as Prioritization, Memorizing, Discerning, and Contextualizing, that are
critical for both AI and human reasoning. Our findings reveal that participants
perceive AI as lacking in interpretive and empathetic skills yet hold high
expectations for AI performance. By integrating insights from our findings into
benchmark design, we offer a framework for developing more human-aligned means
of defining and measuring progress. This work underscores the importance of
user-centered evaluation in AI development, providing actionable guidelines for
researchers and practitioners aiming to align AI capabilities with human
cognitive processes. Our approach both enhances current benchmarking practices
and sets the stage for future advancements in AI model evaluation.

</details>


### [8] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 论文主张通过语言模型驱动的层次化世界模型来解决复杂多智能体任务中的探索困难和稀疏奖励问题，提出使用LLM动态生成层次化任务框架的新范式。


<details>
  <summary>Details</summary>
Motivation: 当前AI发展中，语言模型和智能体模型已有显著进展，但显式的世界模型发展滞后，特别是在复杂长时域多智能体任务中。标准强化学习在高保真但结构平坦的模拟器中面临探索空间难以处理和奖励稀疏的问题。

Method: 提出层次化脚手架方法，将复杂目标分解为结构化、可管理的子目标。利用大型语言模型动态生成这种层次化脚手架，通过语言即时构建世界模型，为智能体学习提供内在课程、密集有意义的学习信号和组合学习框架。

Result: 通过对2024年多智能体足球研究的系统回顾，发现明确的趋势是将符号化和层次化方法与多智能体强化学习结合，这些方法隐式或显式地构建基于任务的世界模型来指导智能体学习。

Conclusion: 通过构建具有显式、语言可配置任务层的环境，可以弥合低级反应行为与高级战略团队协作之间的差距，为训练下一代智能智能体创建强大且可推广的框架。

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [9] [What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791)
*Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi*

Main category: cs.AI

TL;DR: WiA-LLM是一个新范式，通过整合假设分析(WIA)和强化学习环境反馈，使大语言模型具备主动思考能力，能够在复杂动态环境中预测未来状态变化


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型只能被动处理信息，缺乏系统性探索假设未来的能力，无法在行动前预测潜在后果，这限制了它们在动态高风险场景中的实用性

Method: 整合假设分析方法，通过改变输入变量评估假设场景，利用强化学习的环境反馈，动态模拟每个潜在行动的结果，使模型能够预测未来状态而不仅仅是响应当前条件

Result: 在《王者荣耀》复杂游戏环境中验证，WiA-LLM在预测游戏状态变化方面达到74.2%的准确率（比基线提升两倍），在高难度场景中表现尤为突出

Conclusion: 这是首个正式探索和整合假设分析能力到大语言模型的工作，代表了向主动推理的根本性进步，为动态环境中的稳健决策提供了可扩展框架

Abstract: Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.

</details>


### [10] [TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models](https://arxiv.org/abs/2509.04809)
*Haechang Kim,Hao Chen,Can Li,Jong Min Lee*

Main category: cs.AI

TL;DR: TalkToAgent是一个多智能体LLM框架，通过五个专门化LLM代理提供交互式自然语言解释，弥合复杂RL策略与领域专家之间的理解鸿沟。


<details>
  <summary>Details</summary>
Motivation: 当前可解释强化学习(XRL)方法存在解释结果可理解性有限、工具覆盖孤立的问题，导致用户不确定使用哪种工具，需要更透明、交互性强的解释框架。

Method: 采用五智能体架构（协调器、解释器、编码器、评估器、调试器），自动将用户查询映射到相关XRL工具，提供关键状态变量、预期结果或反事实解释，并能从定性行为描述推导替代场景和基于规则的新策略。

Result: 在四水箱过程控制问题上验证，成功高精度映射用户查询到XRL任务，编码器-调试器交互最小化反事实生成失败，定性评估确认能有效解释智能体行为并在问题域中情境化其含义。

Conclusion: TalkToAgent框架通过多智能体LLM协作，显著提升了RL策略的可解释性和用户交互体验，为解决XRL工具碎片化和解释可理解性问题提供了有效方案。

Abstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.

</details>


### [11] [Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory](https://arxiv.org/abs/2509.04847)
*Mukul Singh,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 语言模型在迭代困徒困境中表现出优秀的合作能力和适应性，性能可与最佳经典策略相比拼，并显示出类似人类的快速适应能力


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在多方互动环境中的长期合作与竞争行为，补充以往研究对短期游戏理论情境的偏重

Method: 采用迭代困徒困境(IPD)框架，让语言模型代理与240种经典策略进行Axelrod风格的赛会比赛，并设计控制实验观察策略切换时的反应

Result: 语言模型表现与最佳经典策略相当或更优，显示出友善性、可刺激性咃富于性等特征，能在几轮内快速检测并适应对手策略变化

Conclusion: 这是首次系统性描述语言模型长期合作行为的研究，为今后更复杂的人工智能-人类混合社会环境研究奠定基础

Abstract: Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.

</details>


### [12] [Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](https://arxiv.org/abs/2509.04871)
*Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 这篇论文提出了一种从电话通话录音中克隆对话式语音AI助手的通用方法，通过整合语音识别、大语言模型对话管理和语音合成技术，实现了能够模仿人类销售人员表现的AI组织。


<details>
  <summary>Details</summary>
Motivation: 语言和语音模型的进步使得建立自主语音助手变得可行，这些系统在客服和医疗领域可以自动化重复任务、降低成本并提供24小时支持。

Method: 从电话通话录音中克隆对话AI组织，整合自动语音识别(ASR)、基于大语言模型的对话管理器和文本转语音(TTS)合成技术，构建流式推理流水线，学习顶级人类代表的结构化脚本。

Result: 在包括介绍、产品沟通、销售驱动、异议处理和成交等22个标准的评价中，盲测显示AI组织在常规通话方面接近人类表现，但在说服和异议处理方面较差。

Conclusion: 分析了AI组织的不足之处并对提示进行了精炼，提出了设计经验和未来研究方向，包括大规模模拟和自动化评估。

Abstract: Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.

</details>


### [13] [OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration](https://arxiv.org/abs/2509.04876)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Xiaofei Sun,Keze Wang*

Main category: cs.AI

TL;DR: OSC是一个知识感知的自适应协作框架，通过Collaborator Knowledge Models使多智能体系统能够动态感知协作伙伴的认知状态，实现深度认知协同，显著提升任务性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究在智能体选择和结果聚合方面已有进展，但专家智能体间高效的语言交互和深度协作仍是关键瓶颈，需要解决多智能体系统中认知协同的挑战。

Method: 提出OSC框架作为选择和聚合之间的关键中间层，引入Collaborator Knowledge Models(CKM)，通过实时认知差距分析，使智能体能够自适应调整通信行为（包括内容焦点、细节层次和表达风格）。

Result: 在复杂推理和问题解决基准测试中，OSC显著提高了任务性能和通信效率，将"并行工作的个体"转变为"深度协作的认知团队"。

Conclusion: 该框架不仅优化了多智能体协作，还为LLM智能体交互行为提供了新的见解，推动了认知协同在多智能体系统中的发展。

Abstract: This paper introduces OSC (Orchestrating Cognitive Synergy), a
knowledge-aware adaptive collaboration framework designed to enhance cognitive
synergy in multi-agent systems with large language models. While prior work has
advanced agent selection and result aggregation, efficient linguistic
interactions for deep collaboration among expert agents remain a critical
bottleneck. OSC addresses this gap as a pivotal intermediate layer between
selection and aggregation, introducing Collaborator Knowledge Models (CKM) to
enable each agent to dynamically perceive its collaborators' cognitive states.
Through real-time cognitive gap analysis, agents adaptively adjust
communication behaviors, including content focus, detail level, and expression
style, using learned strategies. Experiments on complex reasoning and
problem-solving benchmarks demonstrate that OSC significantly improves task
performance and communication efficiency, transforming "parallel-working
individuals'' into a "deeply collaborative cognitive team.'' This framework not
only optimizes multi-agent collaboration but also offers new insights into LLM
agent interaction behaviors.

</details>


### [14] [SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing](https://arxiv.org/abs/2509.04908)
*Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: SparkUI-Parser是一个新颖的端到端GUI解析框架，通过连续坐标建模和拒绝机制，显著提高了定位精度和推理速度，能够解析整个界面而不仅仅是预定义元素集。


<details>
  <summary>Details</summary>
Motivation: 解决现有MLLMs在GUI感知中的两个主要问题：1）基于文本自回归机制的离散坐标建模导致定位精度低和推理速度慢；2）只能定位预定义元素集，无法解析整个界面，限制了广泛应用和下游任务支持。

Method: 1）基于预训练MLLM，通过额外的token路由器和坐标解码器进行连续坐标建模；2）引入基于改进匈牙利匹配算法的拒绝机制，识别并拒绝不存在的元素；3）构建ScreenParse基准测试来系统评估GUI模型的结构感知能力。

Result: 在ScreenSpot、ScreenSpot-v2、CAGUI-Grounding和ScreenParse等多个基准测试中，该方法始终优于最先进的SOTA方法。

Conclusion: SparkUI-Parser通过连续建模和拒绝机制，有效解决了离散输出特性和逐token生成过程的限制，在精度和推理速度方面都有显著提升，为GUI解析提供了更强大的解决方案。

Abstract: The existing Multimodal Large Language Models (MLLMs) for GUI perception have
made great progress. However, the following challenges still exist in prior
methods: 1) They model discrete coordinates based on text autoregressive
mechanism, which results in lower grounding accuracy and slower inference
speed. 2) They can only locate predefined sets of elements and are not capable
of parsing the entire interface, which hampers the broad application and
support for downstream tasks. To address the above issues, we propose
SparkUI-Parser, a novel end-to-end framework where higher localization
precision and fine-grained parsing capability of the entire interface are
simultaneously achieved. Specifically, instead of using probability-based
discrete modeling, we perform continuous modeling of coordinates based on a
pre-trained Multimodal Large Language Model (MLLM) with an additional token
router and coordinate decoder. This effectively mitigates the limitations
inherent in the discrete output characteristics and the token-by-token
generation process of MLLMs, consequently boosting both the accuracy and the
inference speed. To further enhance robustness, a rejection mechanism based on
a modified Hungarian matching algorithm is introduced, which empowers the model
to identify and reject non-existent elements, thereby reducing false positives.
Moreover, we present ScreenParse, a rigorously constructed benchmark to
systematically assess structural perception capabilities of GUI models across
diverse scenarios. Extensive experiments demonstrate that our approach
consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,
CAGUI-Grounding and ScreenParse benchmarks. The resources are available at
https://github.com/antgroup/SparkUI-Parser.

</details>


### [15] [Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts](https://arxiv.org/abs/2509.04926)
*Barbara Gendron,Gaël Guibon,Mathieu D'aquin*

Main category: cs.AI

TL;DR: 本文提出基于本体的方法来形式化定义对话特征，通过语言描述符将定性概念转化为定量定义，应用于CEFR语言熟练度控制，通过微调指导LLM生成可控文本


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型作为对话代理时的可控性挑战，确保可预测和用户个性化的响应，特别是对定性对话特征进行形式化定义的需求

Method: 使用语言描述符将定性概念转化为定量定义，构建描述逻辑形式化的本体，通过微调指导LLM进行受控文本生成

Result: 实验结果表明该方法提供了一致且可解释的熟练度定义，提高了对话AI的透明度

Conclusion: 基于本体的方法能够有效实现对话特征的形式化定义和控制，为LLM的可控对话生成提供了可解释的框架

Abstract: The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.

</details>


### [16] [Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents](https://arxiv.org/abs/2509.04979)
*Rajesh Tembarai Krishnamachari,Srividya Rajesh*

Main category: cs.AI

TL;DR: DOVIS协议和AgentRank-UC算法为构建可信的智能体网络提供解决方案，通过隐私保护的性能数据收集和动态排名机制实现智能体的有效选择和协作。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体的发展，互联网正在向智能体网络转型，但缺乏有效的智能体排名机制。现有系统无法收集和利用分散的私有性能数据来评估智能体的实际表现。

Method: 提出DOVIS五层操作协议（发现、编排、验证、激励、语义）来收集隐私保护的性能聚合数据，并开发AgentRank-UC算法结合使用频率和能力指标进行动态排名。

Result: 通过仿真验证了算法的收敛性、鲁棒性和抗Sybil攻击能力，证明了协调协议和性能感知排名在构建可扩展可信智能体网络中的可行性。

Conclusion: DOVIS协议和AgentRank-UC算法为解决智能体网络中的排名问题提供了有效框架，为构建机器原生的智能体生态系统奠定了基础。

Abstract: AI agents -- powered by reasoning-capable large language models (LLMs) and
integrated with tools, data, and web search -- are poised to transform the
internet into a \emph{Web of Agents}: a machine-native ecosystem where
autonomous agents interact, collaborate, and execute tasks at scale. Realizing
this vision requires \emph{Agent Ranking} -- selecting agents not only by
declared capabilities but by proven, recent performance. Unlike Web~1.0's
PageRank, a global, transparent network of agent interactions does not exist;
usage signals are fragmented and private, making ranking infeasible without
coordination.
  We propose \textbf{DOVIS}, a five-layer operational protocol
(\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that
enables the collection of minimal, privacy-preserving aggregates of usage and
performance across the ecosystem. On this substrate, we implement
\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines
\emph{usage} (selection frequency) and \emph{competence} (outcome quality,
cost, safety, latency) into a unified ranking. We present simulation results
and theoretical guarantees on convergence, robustness, and Sybil resistance,
demonstrating the viability of coordinated protocols and performance-aware
ranking in enabling a scalable, trustworthy Agentic Web.

</details>


### [17] [Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework](https://arxiv.org/abs/2509.05007)
*Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.AI

TL;DR: Sticker-TTS是一个新的测试时扩展框架，通过协调三个协作的大型推理模型，利用历史经验迭代探索和优化解决方案，在数学推理任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前测试时扩展方法主要依赖冗余采样，忽略了历史经验的利用，限制了计算效率。需要一种更高效的方法来利用历史推理经验。

Method: 提出Sticker-TTS框架，使用三个协作的LRM模型，通过提炼关键条件（称为sticker）来提取、精炼和重用关键信息，采用两阶段优化策略结合模仿学习和自我改进。

Result: 在AIME-24、AIME-25和OlymMATH三个数学推理基准测试中，Sticker-TTS在可比推理预算下 consistently超越了自洽性和先进强化学习方法等强基线。

Conclusion: Sticker-TTS通过sticker引导的历史经验利用，有效提高了推理效率和性能，证明了历史经验在测试时扩展中的重要性。

Abstract: Large reasoning models (LRMs) have exhibited strong performance on complex
reasoning tasks, with further gains achievable through increased computational
budgets at inference. However, current test-time scaling methods predominantly
rely on redundant sampling, ignoring the historical experience utilization,
thereby limiting computational efficiency. To overcome this limitation, we
propose Sticker-TTS, a novel test-time scaling framework that coordinates three
collaborative LRMs to iteratively explore and refine solutions guided by
historical attempts. At the core of our framework are distilled key
conditions-termed stickers-which drive the extraction, refinement, and reuse of
critical information across multiple rounds of reasoning. To further enhance
the efficiency and performance of our framework, we introduce a two-stage
optimization strategy that combines imitation learning with self-improvement,
enabling progressive refinement. Extensive evaluations on three challenging
mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,
demonstrate that Sticker-TTS consistently surpasses strong baselines, including
self-consistency and advanced reinforcement learning approaches, under
comparable inference budgets. These results highlight the effectiveness of
sticker-guided historical experience utilization. Our code and data are
available at https://github.com/RUCAIBox/Sticker-TTS.

</details>


### [18] [Finding your MUSE: Mining Unexpected Solutions Engine](https://arxiv.org/abs/2509.05072)
*Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf*

Main category: cs.AI

TL;DR: 提出功能性概念图(FCG)方法来解决创新者的认知固化问题，通过构建大规模高质量的功能元素互联表示来支持抽象、问题重构和类比启发


<details>
  <summary>Details</summary>
Motivation: 创新者往往对现有解决方案或初步想法存在认知固化，阻碍了新颖替代方案的探索，需要一种方法来促进创造性思维

Method: 构建功能性概念图(FCG)作为功能元素的互联表示，并提出MUSE算法利用FCG为给定问题生成创造性启发

Result: 在50万项专利上计算构建了FCG，并公开发布供进一步研究使用

Conclusion: FCG方法能够有效克服先前工作的局限性，提供大规模高质量的功能抽象关系，支持创新过程中的问题重构和类比启发

Abstract: Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.

</details>


### [19] [ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback](https://arxiv.org/abs/2509.05091)
*Matteo Bortoletto,Yichao Zhou,Lance Ying,Tianmin Shu,Andreas Bulling*

Main category: cs.AI

TL;DR: ProToM是一个基于心理理论的AI系统，通过贝叶斯逆规划推断智能体目标并提供针对性反馈，在多智能体环境中有效促进亲社会行为，相比大型语言模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中智能体在追求独立目标时难以判断何时以及如何协助他人的问题，促进亲社会行为的发展。

Method: 使用贝叶斯逆规划推断智能体目标，然后通过最大化期望效用来选择上下文敏感的反馈信息。

Result: 在Doors、Keys、Gems和Overcooked环境中，ProToM相比基线方法获得更高的成功率、更短的任务完成时间，并受到人类用户的一致偏好。

Conclusion: ProToM能够提供针对性强且有用的反馈，而现有大型语言和推理模型在提供上下文接地且时机恰当的反馈方面存在不足。

Abstract: While humans are inherently social creatures, the challenge of identifying
when and how to assist and collaborate with others - particularly when pursuing
independent goals - can hinder cooperation. To address this challenge, we aim
to develop an AI system that provides useful feedback to promote prosocial
behaviour - actions that benefit others, even when not directly aligned with
one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator
that promotes prosocial actions in multi-agent systems by providing targeted,
context-sensitive feedback to individual agents. ProToM first infers agents'
goals using Bayesian inverse planning, then selects feedback to communicate by
maximising expected utility, conditioned on the inferred goal distribution. We
evaluate our approach against baselines in two multi-agent environments: Doors,
Keys, and Gems, as well as Overcooked. Our results suggest that
state-of-the-art large language and reasoning models fall short of
communicating feedback that is both contextually grounded and well-timed -
leading to higher communication overhead and task speedup. In contrast, ProToM
provides targeted and helpful feedback, achieving a higher success rate,
shorter task completion times, and is consistently preferred by human users.

</details>


### [20] [Evaluation and Comparison Semantics for ODRL](https://arxiv.org/abs/2509.05139)
*Jaime Osvaldo Salas,Paolo Pareti,Semih Yumuşak,Soulmaz Gheisari,Luis-Daniel Ibáñez,George Konstantinidis*

Main category: cs.AI

TL;DR: 为ODRL语言提供基于查询答复的正式语义学，并定义政策比较问题用于检测等价、更严格或更免许的政策


<details>
  <summary>Details</summary>
Motivation: ODRL已成为数字资源访问和使用管理的实际标准，但缺乏全面的正式语义学，影响政策评估和比较

Method: 提出基于查询答复的简单直观正式语义学，精炼之前的形式化方法，与ODRL 2.2规范保持一致

Result: 建立了一套完整的ODRL正式语义学框架，能够支持政策评估和比较

Conclusion: 该形式语义学为ODRL政策提供了坚实的理论基础，特别是在数据共享场景中对于政策比较和一致性检查具有重要价值

Abstract: We consider the problem of evaluating, and comparing computational policies
in the Open Digital Rights Language (ODRL), which has become the de facto
standard for governing the access and usage of digital resources. Although
preliminary progress has been made on the formal specification of the
language's features, a comprehensive formal semantics of ODRL is still missing.
In this paper, we provide a simple and intuitive formal semantics for ODRL that
is based on query answering. Our semantics refines previous formalisations, and
is aligned with the latest published specification of the language (2.2).
Building on our evaluation semantics, and motivated by data sharing scenarios,
we also define and study the problem of comparing two policies, detecting
equivalent, more restrictive or more permissive policies.

</details>


### [21] [LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](https://arxiv.org/abs/2509.05263)
*Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu*

Main category: cs.AI

TL;DR: LatticeWorld是一个基于轻量级LLM和游戏引擎的3D世界生成框架，通过多模态输入生成动态交互式3D环境，显著提升工业生产效率90倍以上


<details>
  <summary>Details</summary>
Motivation: 开发更真实的3D世界模型来缩小仿真与现实的差距，为具身AI、自动驾驶等领域提供丰富的仿真环境，替代传统手动建模的低效生产方式

Method: 结合轻量级LLM（LLaMA-2-7B）和工业级渲染引擎（如Unreal Engine 5），接受文本描述和视觉指令作为多模态输入，生成包含动态智能体的大规模3D交互世界

Result: 在场景布局生成和视觉保真度方面达到优异精度，相比传统手动生产方式提高工业生产效率90倍以上，同时保持高质量创意

Conclusion: LatticeWorld提供了一个简单有效的3D世界生成框架，能够高效生成具有竞争性多智能体交互、高保真物理仿真和实时渲染的动态3D环境，显著推进了3D世界生成技术的发展

Abstract: Recent research has been increasingly focusing on developing 3D world models
that simulate complex real-world scenarios. World models have found broad
applications across various domains, including embodied AI, autonomous driving,
entertainment, etc. A more realistic simulation with accurate physics will
effectively narrow the sim-to-real gap and allow us to gather rich information
about the real world conveniently. While traditional manual modeling has
enabled the creation of virtual 3D scenes, modern approaches have leveraged
advanced machine learning algorithms for 3D world generation, with most recent
advances focusing on generative methods that can create virtual worlds based on
user instructions. This work explores such a research direction by proposing
LatticeWorld, a simple yet effective 3D world generation framework that
streamlines the industrial production pipeline of 3D environments. LatticeWorld
leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering
engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed
framework accepts textual descriptions and visual instructions as multimodal
inputs and creates large-scale 3D interactive worlds with dynamic agents,
featuring competitive multi-agent interaction, high-fidelity physics
simulation, and real-time rendering. We conduct comprehensive experiments to
evaluate LatticeWorld, showing that it achieves superior accuracy in scene
layout generation and visual fidelity. Moreover, LatticeWorld achieves over a
$90\times$ increase in industrial production efficiency while maintaining high
creative quality compared with traditional manual production methods. Our demo
video is available at https://youtu.be/8VWZXpERR18

</details>
