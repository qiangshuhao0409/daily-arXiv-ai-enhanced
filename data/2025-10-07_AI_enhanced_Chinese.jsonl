{"id": "2510.03642", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.03642", "abs": "https://arxiv.org/abs/2510.03642", "authors": ["Yihang Jiang", "Xiaoyang Li", "Guangxu Zhu", "Xiaowen Cao", "Kaifeng Han", "Bingpeng Zhou", "Xinyi Wang"], "title": "Sensing Performance Analysis in Cooperative Air-Ground ISAC Networks for LAE", "comment": null, "summary": "To support the development of low altitude economy, the air-ground integrated\nsensing and communication (ISAC) networks need to be constructed to provide\nreliable and robust communication and sensing services. In this paper, the\nsensing capabilities in the cooperative air-ground ISAC networks are evaluated\nin terms of area radar detection coverage probability under a constant false\nalarm rate, where the distribution of aggregated sensing interferences is\nanalyzed as a key intermediate result. Compared with the analysis based on the\nstrongest interferer approximation, taking the aggregated sensing interference\ninto consideration is better suited for pico-cell scenarios with high base\nstation density. Simulations are conducted to validate the analysis.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u7a7a\u5730\u4e00\u4f53\u5316\u611f\u77e5\u901a\u4fe1\u7f51\u7edc\u4e2d\u57fa\u4e8e\u6052\u5b9a\u865a\u8b66\u7387\u7684\u533a\u57df\u96f7\u8fbe\u68c0\u6d4b\u8986\u76d6\u6982\u7387\uff0c\u5206\u6790\u4e86\u805a\u5408\u611f\u77e5\u5e72\u6270\u5206\u5e03\uff0c\u76f8\u6bd4\u6700\u5f3a\u5e72\u6270\u8fd1\u4f3c\u65b9\u6cd5\u66f4\u9002\u5408\u9ad8\u5bc6\u5ea6\u57fa\u7ad9\u573a\u666f\u3002", "motivation": "\u4e3a\u652f\u6301\u4f4e\u7a7a\u7ecf\u6d4e\u53d1\u5c55\uff0c\u9700\u8981\u6784\u5efa\u7a7a\u5730\u4e00\u4f53\u5316\u611f\u77e5\u901a\u4fe1\u7f51\u7edc\u6765\u63d0\u4f9b\u53ef\u9760\u7a33\u5065\u7684\u901a\u4fe1\u548c\u611f\u77e5\u670d\u52a1\u3002", "method": "\u901a\u8fc7\u5206\u6790\u805a\u5408\u611f\u77e5\u5e72\u6270\u5206\u5e03\u6765\u8bc4\u4f30\u534f\u4f5c\u7a7a\u5730ISAC\u7f51\u7edc\u7684\u611f\u77e5\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u533a\u57df\u96f7\u8fbe\u68c0\u6d4b\u8986\u76d6\u6982\u7387\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u4e86\u5206\u6790\u7ed3\u679c\uff0c\u8868\u660e\u8003\u8651\u805a\u5408\u611f\u77e5\u5e72\u6270\u6bd4\u6700\u5f3a\u5e72\u6270\u8fd1\u4f3c\u65b9\u6cd5\u66f4\u9002\u5408\u9ad8\u5bc6\u5ea6\u57fa\u7ad9\u7684\u5c0f\u8702\u7a9d\u573a\u666f\u3002", "conclusion": "\u5728\u7a7a\u5730\u4e00\u4f53\u5316\u611f\u77e5\u901a\u4fe1\u7f51\u7edc\u4e2d\uff0c\u8003\u8651\u805a\u5408\u611f\u77e5\u5e72\u6270\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u611f\u77e5\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u57fa\u7ad9\u5bc6\u5ea6\u8f83\u9ad8\u7684\u573a\u666f\u4e0b\u3002"}}
{"id": "2510.03860", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.03860", "abs": "https://arxiv.org/abs/2510.03860", "authors": ["Faeze Moradi Kalarde", "Ben Liang", "Min Dong", "Yahia A. Eldemerdash Ahmed", "Ho Ting Cheng"], "title": "Privacy Enhancement in Over-the-Air Federated Learning via Adaptive Receive Scaling", "comment": "12 pages, 2 figures", "summary": "In Federated Learning (FL) with over-the-air aggregation, the quality of the\nsignal received at the server critically depends on the receive scaling\nfactors. While a larger scaling factor can reduce the effective noise power and\nimprove training performance, it also compromises the privacy of devices by\nreducing uncertainty. In this work, we aim to adaptively design the receive\nscaling factors across training rounds to balance the trade-off between\ntraining convergence and privacy in an FL system under dynamic channel\nconditions. We formulate a stochastic optimization problem that minimizes the\noverall R\\'enyi differential privacy (RDP) leakage over the entire training\nprocess, subject to a long-term constraint that ensures convergence of the\nglobal loss function. Our problem depends on unknown future information, and we\nobserve that standard Lyapunov optimization is not applicable. Thus, we develop\na new online algorithm, termed AdaScale, based on a sequence of novel per-round\nproblems that can be solved efficiently. We further derive upper bounds on the\ndynamic regret and constraint violation of AdaSacle, establishing that it\nachieves diminishing dynamic regret in terms of time-averaged RDP leakage while\nensuring convergence of FL training to a stationary point. Numerical\nexperiments on canonical classification tasks show that our approach\neffectively reduces RDP and DP leakages compared with state-of-the-art\nbenchmarks without compromising learning performance.", "AI": {"tldr": "\u63d0\u51faAdaScale\u7b97\u6cd5\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u7684\u7a7a\u4e2d\u805a\u5408\u4e2d\u81ea\u9002\u5e94\u8bbe\u8ba1\u63a5\u6536\u7f29\u653e\u56e0\u5b50\uff0c\u5e73\u8861\u8bad\u7ec3\u6536\u655b\u4e0e\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u63a5\u6536\u7f29\u653e\u56e0\u5b50\u7684\u5927\u5c0f\u4f1a\u5f71\u54cd\u8bad\u7ec3\u6027\u80fd\u548c\u9690\u79c1\u4fdd\u62a4\u3002\u8f83\u5927\u7684\u7f29\u653e\u56e0\u5b50\u80fd\u964d\u4f4e\u566a\u58f0\u529f\u7387\u63d0\u9ad8\u8bad\u7ec3\u6548\u679c\uff0c\u4f46\u4f1a\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u4ece\u800c\u635f\u5bb3\u9690\u79c1\u3002\u9700\u8981\u52a8\u6001\u8c03\u6574\u7f29\u653e\u56e0\u5b50\u6765\u5e73\u8861\u8fd9\u4e00\u77db\u76fe\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u6574\u4f53R\u00e9nyi\u5dee\u5206\u9690\u79c1\u6cc4\u6f0f\uff0c\u540c\u65f6\u786e\u4fdd\u5168\u5c40\u635f\u5931\u51fd\u6570\u6536\u655b\u3002\u5f00\u53d1\u4e86AdaScale\u5728\u7ebf\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u6bcf\u8f6e\u53ef\u9ad8\u6548\u6c42\u89e3\u7684\u95ee\u9898\u6765\u5b9e\u73b0\u81ea\u9002\u5e94\u8bbe\u8ba1\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eAdaScale\u5b9e\u73b0\u4e86\u9012\u51cf\u7684\u52a8\u6001\u9057\u61be\uff0c\u5728\u65f6\u95f4\u5e73\u5747RDP\u6cc4\u6f0f\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u786e\u4fddFL\u8bad\u7ec3\u6536\u655b\u5230\u7a33\u5b9a\u70b9\u3002\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11RDP\u548cDP\u6cc4\u6f0f\u4e14\u4e0d\u635f\u5bb3\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "AdaScale\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u8bad\u7ec3\u6536\u655b\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u5728\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u800c\u4e0d\u5f71\u54cd\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2510.04000", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.04000", "abs": "https://arxiv.org/abs/2510.04000", "authors": ["Yujie Zhou", "Yiwei Liao", "Cheng Peng", "Yong Xiao", "Yingyu Li"], "title": "Multi-Modal Multi-Task Semantic Communication: A Distributed Information Bottleneck Perspective", "comment": null, "summary": "Semantic communication (SemCom) shifts the focus from data transmission to\nmeaning delivery, enabling efficient and intelligent communication.\n  Existing AI-based coding schemes for multi-modal multi-task SemCom often\nrequire transmitters with full-modal data to participate in all receivers'\ntasks, which leads to redundant transmissions and conflicts with the physical\nlimits of channel capacity and computational capability.\n  In this paper, we propose PoM$^2$-DIB, a novel framework that extends the\ndistributed information bottleneck (DIB) theory to address this problem.\n  Unlike the typical DIB, this framework introduces modality selection as an\nadditional key design variable, enabling a more flexible tradeoff between\ncommunication rate and inference quality.\n  This extension selects only the most relevant modalities for task\nparticipation, adhering to the physical constraints, while following efficient\nDIB-based coding.\n  To optimize selection and coding end-to-end, we relax modality selection into\na probabilistic form, allowing the use of score function estimation with common\nrandomness to enable optimizable coordinated decisions across distributed\ndevices.\n  Experimental results on public datasets verify that PoM$^2$-DIB achieves high\ninference quality compared to full-participation baselines in various tasks\nunder physical limits.", "AI": {"tldr": "\u63d0\u51faPoM\u00b2-DIB\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c55\u5206\u5e03\u5f0f\u4fe1\u606f\u74f6\u9888\u7406\u8bba\uff0c\u5f15\u5165\u6a21\u6001\u9009\u62e9\u673a\u5236\u6765\u89e3\u51b3\u591a\u6a21\u6001\u591a\u4efb\u52a1\u8bed\u4e49\u901a\u4fe1\u4e2d\u7684\u5197\u4f59\u4f20\u8f93\u95ee\u9898", "motivation": "\u73b0\u6709\u57fa\u4e8eAI\u7684\u591a\u6a21\u6001\u591a\u4efb\u52a1\u8bed\u4e49\u901a\u4fe1\u65b9\u6848\u9700\u8981\u53d1\u5c04\u7aef\u62e5\u6709\u5b8c\u6574\u6a21\u6001\u6570\u636e\u53c2\u4e0e\u6240\u6709\u63a5\u6536\u7aef\u4efb\u52a1\uff0c\u5bfc\u81f4\u5197\u4f59\u4f20\u8f93\u5e76\u8fdd\u53cd\u4fe1\u9053\u5bb9\u91cf\u548c\u8ba1\u7b97\u80fd\u529b\u7684\u7269\u7406\u9650\u5236", "method": "\u6269\u5c55\u5206\u5e03\u5f0f\u4fe1\u606f\u74f6\u9888\u7406\u8bba\uff0c\u5f15\u5165\u6a21\u6001\u9009\u62e9\u4f5c\u4e3a\u5173\u952e\u8bbe\u8ba1\u53d8\u91cf\uff0c\u5c06\u6a21\u6001\u9009\u62e9\u677e\u5f1b\u4e3a\u6982\u7387\u5f62\u5f0f\uff0c\u4f7f\u7528\u8bc4\u5206\u51fd\u6570\u4f30\u8ba1\u548c\u516c\u5171\u968f\u673a\u6027\u5b9e\u73b0\u5206\u5e03\u5f0f\u8bbe\u5907\u7684\u53ef\u4f18\u5316\u534f\u8c03\u51b3\u7b56", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPoM\u00b2-DIB\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u76f8\u6bd4\u5168\u53c2\u4e0e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u7269\u7406\u9650\u5236\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u63a8\u7406", "conclusion": "PoM\u00b2-DIB\u6846\u67b6\u901a\u8fc7\u6a21\u6001\u9009\u62e9\u548c\u5206\u5e03\u5f0f\u4fe1\u606f\u74f6\u9888\u7f16\u7801\uff0c\u5728\u9075\u5b88\u7269\u7406\u7ea6\u675f\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u901a\u4fe1\u6548\u7387\u4e0e\u63a8\u7406\u8d28\u91cf\u7684\u6709\u6548\u6743\u8861"}}
{"id": "2510.04095", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.04095", "abs": "https://arxiv.org/abs/2510.04095", "authors": ["Neri Merhav", "Shlomo Shamai"], "title": "Volume-Based Lower Bounds to the Capacity of the Gaussian Channel Under Pointwise Additive Input Constraints", "comment": "37 pages, 4 figures, submitted for publication", "summary": "We present a family of relatively simple and unified lower bounds on the\ncapacity of the Gaussian channel under a set of pointwise additive input\nconstraints. Specifically, the admissible channel input vectors $\\bx = (x_1,\n\\ldots, x_n)$ must satisfy $k$ additive cost constraints of the form\n$\\sum_{i=1}^n \\phi_j(x_i) \\le n \\Gamma_j$, $j = 1,2,\\ldots,k$, which are\nenforced pointwise for every $\\bx$, rather than merely in expectation. More\ngenerally, we also consider cost functions that depend on a sliding window of\nfixed length $m$, namely, $\\sum_{i=m}^n \\phi_j(x_i, x_{i-1}, \\ldots, x_{i-m+1})\n\\le n \\Gamma_j$, $j = 1,2,\\ldots,k$, a formulation that naturally accommodates\ncorrelation constraints as well as a broad range of other constraints of\npractical relevance. We propose two classes of lower bounds, derived by two\nmethodologies that both rely on the exact evaluation of the volume exponent\nassociated with the set of input vectors satisfying the given constraints. This\nevaluation exploits extensions of the method of types to continuous alphabets,\nthe saddle-point method of integration, and basic tools from large deviations\ntheory. The first class of bounds is obtained via the entropy power inequality\n(EPI), and therefore applies exclusively to continuous-valued inputs. The\nsecond class, by contrast, is more general, and it applies to discrete input\nalphabets as well. It is based on a direct manipulation of mutual information,\nand it yields stronger and tighter bounds, though at the cost of greater\ntechnical complexity. Numerical examples illustrating both types of bounds are\nprovided, and several extensions and refinements are also discussed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9ad8\u65af\u4fe1\u9053\u5728\u70b9\u5f0f\u52a0\u6027\u8f93\u5165\u7ea6\u675f\u4e0b\u7684\u5bb9\u91cf\u4e0b\u754c\uff0c\u5305\u62ec\u4e24\u7c7b\u4e0b\u754c\uff1a\u57fa\u4e8e\u71b5\u529f\u7387\u4e0d\u7b49\u5f0f\u7684\u65b9\u6cd5\uff08\u4ec5\u9002\u7528\u4e8e\u8fde\u7eed\u8f93\u5165\uff09\u548c\u57fa\u4e8e\u4e92\u4fe1\u606f\u76f4\u63a5\u64cd\u4f5c\u7684\u65b9\u6cd5\uff08\u66f4\u901a\u7528\u4f46\u66f4\u590d\u6742\uff09\u3002", "motivation": "\u7814\u7a76\u9ad8\u65af\u4fe1\u9053\u5728\u70b9\u5f0f\u52a0\u6027\u7ea6\u675f\uff08\u800c\u975e\u671f\u671b\u7ea6\u675f\uff09\u4e0b\u7684\u5bb9\u91cf\u4e0b\u754c\uff0c\u8fd9\u7c7b\u7ea6\u675f\u5728\u5b9e\u8df5\u4e2d\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u5229\u7528\u7c7b\u578b\u65b9\u6cd5\u6269\u5c55\u5230\u8fde\u7eed\u5b57\u6bcd\u8868\u3001\u978d\u70b9\u79ef\u5206\u65b9\u6cd5\u548c\u5927\u504f\u5dee\u7406\u8bba\u5de5\u5177\uff0c\u7cbe\u786e\u8bc4\u4f30\u6ee1\u8db3\u7ea6\u675f\u7684\u8f93\u5165\u5411\u91cf\u96c6\u5408\u7684\u4f53\u79ef\u6307\u6570\u3002", "result": "\u63d0\u51fa\u4e86\u4e24\u7c7b\u5bb9\u91cf\u4e0b\u754c\uff1a\u7b2c\u4e00\u7c7b\u57fa\u4e8eEPI\u4ec5\u9002\u7528\u4e8e\u8fde\u7eed\u8f93\u5165\uff0c\u7b2c\u4e8c\u7c7b\u66f4\u901a\u7528\u4f46\u6280\u672f\u66f4\u590d\u6742\uff0c\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u4e24\u79cd\u4e0b\u754c\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9ad8\u65af\u4fe1\u9053\u5728\u70b9\u5f0f\u52a0\u6027\u7ea6\u675f\u4e0b\u7684\u5bb9\u91cf\u5206\u6790\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u4e0b\u754c\u6846\u67b6\uff0c\u5177\u6709\u8f83\u597d\u7684\u7406\u8bba\u4ef7\u503c\u548c\u5b9e\u7528\u610f\u4e49\u3002"}}
{"id": "2510.03438", "categories": ["cs.NI", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.03438", "abs": "https://arxiv.org/abs/2510.03438", "authors": ["Grace Ra Kim", "Duncan Eddy", "Vedant Srinivas", "Mykel J. Kochenderfer"], "title": "Scalable Ground Station Selection for Large LEO Constellations", "comment": "14 pages, 7 tables, 10 figures, submitted to IEEE Aeroconf 2026", "summary": "Effective ground station selection is critical for low Earth orbiting (LEO)\nsatellite constellations to minimize operational costs, maximize data downlink\nvolume, and reduce communication gaps between access windows. Traditional\nground station selection typically begins by choosing from a fixed set of\nlocations offered by Ground Station-as-a-Service (GSaaS) providers, which helps\nreduce the problem scope to optimizing locations over existing infrastructure.\nHowever, finding a globally optimal solution for stations using existing\nmixed-integer programming methods quickly becomes intractable at scale,\nespecially when considering multiple providers and large satellite\nconstellations. To address this issue, we introduce a scalable, hierarchical\nframework that decomposes the global selection problem into single-satellite,\nshort time-window subproblems. Optimal station choices from each subproblem are\nclustered to identify consistently high-value locations across all decomposed\ncases. Cluster-level sets are then matched back to the closest GSaaS candidate\nsites to produce a globally feasible solution. This approach enables scalable\ncoordination while maintaining near-optimal performance. We evaluate our\nmethod's performance on synthetic Walker-Star test cases (1-10 satellites, 1-10\nstations), achieving solutions within 95% of the global IP optimum for all test\ncases. Real-world evaluations on Capella Space (5 satellites), ICEYE (40), and\nPlanet's Flock (96) show that while exact IP solutions fail to scale, our\nframework continues to deliver high-quality site selections.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5206\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316LEO\u536b\u661f\u661f\u5ea7\u7684\u5730\u9762\u7ad9\u9009\u62e9\uff0c\u901a\u8fc7\u5c06\u5168\u5c40\u95ee\u9898\u5206\u89e3\u4e3a\u5355\u536b\u661f\u77ed\u65f6\u95f4\u7a97\u53e3\u5b50\u95ee\u9898\uff0c\u805a\u7c7b\u6700\u4f18\u9009\u62e9\uff0c\u7136\u540e\u5339\u914d\u5230\u6700\u8fd1\u7684GSaaS\u5019\u9009\u7ad9\u70b9\uff0c\u5b9e\u73b0\u63a5\u8fd1\u5168\u5c40\u6700\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5730\u9762\u7ad9\u9009\u62e9\u65b9\u6cd5\u5728\u8003\u8651\u591a\u4e2a\u63d0\u4f9b\u5546\u548c\u5927\u578b\u536b\u661f\u661f\u5ea7\u65f6\uff0c\u4f7f\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6700\u5c0f\u5316\u8fd0\u8425\u6210\u672c\u3001\u6700\u5927\u5316\u6570\u636e\u4e0b\u884c\u91cf\u5e76\u51cf\u5c11\u901a\u4fe1\u95f4\u9699\u3002", "method": "\u91c7\u7528\u5206\u5c42\u6846\u67b6\uff0c\u5c06\u5168\u5c40\u9009\u62e9\u95ee\u9898\u5206\u89e3\u4e3a\u5355\u536b\u661f\u77ed\u65f6\u95f4\u7a97\u53e3\u5b50\u95ee\u9898\uff0c\u805a\u7c7b\u6700\u4f18\u7ad9\u70b9\u9009\u62e9\uff0c\u7136\u540e\u5c06\u805a\u7c7b\u7ed3\u679c\u5339\u914d\u5230\u6700\u8fd1\u7684GSaaS\u5019\u9009\u7ad9\u70b9\uff0c\u751f\u6210\u5168\u5c40\u53ef\u884c\u89e3\u3002", "result": "\u5728\u5408\u6210Walker-Star\u6d4b\u8bd5\u6848\u4f8b\uff081-10\u9897\u536b\u661f\uff0c1-10\u4e2a\u5730\u9762\u7ad9\uff09\u4e2d\uff0c\u6240\u6709\u6d4b\u8bd5\u6848\u4f8b\u7684\u89e3\u51b3\u65b9\u6848\u90fd\u8fbe\u5230\u4e86\u5168\u5c40IP\u6700\u4f18\u89e3\u768495%\u4ee5\u5185\u3002\u5728Capella Space\uff085\u9897\u536b\u661f\uff09\u3001ICEYE\uff0840\u9897\uff09\u548cPlanet's Flock\uff0896\u9897\uff09\u7684\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u7ee7\u7eed\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u7ad9\u70b9\u9009\u62e9\uff0c\u800c\u7cbe\u786eIP\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u6269\u5c55\u3002", "conclusion": "\u8be5\u5206\u5c42\u6846\u67b6\u80fd\u591f\u5728\u4fdd\u6301\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u534f\u8c03\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21LEO\u536b\u661f\u661f\u5ea7\u5730\u9762\u7ad9\u9009\u62e9\u7684\u8ba1\u7b97\u96be\u9898\u3002"}}
{"id": "2510.03285", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03285", "abs": "https://arxiv.org/abs/2510.03285", "authors": ["Su Kara", "Fazle Faisal", "Suman Nath"], "title": "WAREX: Web Agent Reliability Evaluation on Existing Benchmarks", "comment": null, "summary": "Recent advances in browser-based LLM agents have shown promise for automating\ntasks ranging from simple form filling to hotel booking or online shopping.\nCurrent benchmarks measure agent performance in controlled environments, such\nas containers or stable networks, where websites behave deterministically.\nHowever, in the real world, users access websites over networks and HTTPS\nconnections that introduce instability from multiple sources: client-side,\nserver-side issues or broader system failures. Moreover, live websites are\nprone to web attacks such Cross-Site Scripting, as well as general site\nmodifications which can cause unexpected or malicious pop-ups or improper\nfunctionality. To address this gap, we present WAREX: Web Agent Reliability\nEvaluation on Existing Benchmarks. We measure the impact of WAREX across three\npopular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that\nintroducing WAREX leads to significant drops in task success rates,\nhighlighting the limited robustness of state-of-the-art agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86WAREX\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u6d4f\u89c8\u5668LLM\u4ee3\u7406\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u5f15\u5165\u7f51\u7edc\u4e0d\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u5a01\u80c1\u540e\uff0c\u4ee3\u7406\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4ee3\u7406\u6027\u80fd\uff0c\u4f46\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u3001\u5b89\u5168\u5a01\u80c1\u548c\u7f51\u7ad9\u4fee\u6539\u7b49\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u4ee3\u7406\u5728\u8fd9\u4e9b\u6311\u6218\u4e0b\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f00\u53d1WAREX\u6846\u67b6\uff0c\u5728WebArena\u3001WebVoyager\u548cREAL\u4e09\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f15\u5165\u7f51\u7edc\u4e0d\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u5a01\u80c1\u7b49\u771f\u5b9e\u73af\u5883\u56e0\u7d20\u3002", "result": "\u5f15\u5165WAREX\u540e\uff0c\u4efb\u52a1\u6210\u529f\u7387\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u5f53\u524d\u6700\u5148\u8fdb\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u6709\u9650\u3002", "conclusion": "\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u5a01\u80c1\u5bf9LLM\u4ee3\u7406\u6027\u80fd\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u9700\u8981\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8003\u8651\u8fd9\u4e9b\u56e0\u7d20\u6765\u51c6\u786e\u8bc4\u4f30\u4ee3\u7406\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04099", "categories": ["cs.IT", "cs.NA", "math.FA", "math.IT", "math.MG", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.04099", "abs": "https://arxiv.org/abs/2510.04099", "authors": ["Zhiqiang Xu", "Zili Xu", "Xinyue Zhang"], "title": "Optimal frames for Phase Retrieval from Edge Vectors of Optimal Polygons", "comment": null, "summary": "This paper aims to characterize the optimal frame for phase retrieval,\ndefined as the frame whose condition number for phase retrieval attains its\nminimal value. In the context of the two-dimensional real case, we reveal the\nconnection between optimal frames for phase retrieval and the\nperimeter-maximizing isodiametric problem, originally proposed by Reinhardt in\n1922. Our work establishes that every optimal solution to the\nperimeter-maximizing isodiametric problem inherently leads to an optimal frame\nin ${\\mathbb R}^2$. By recasting the optimal polygons problem as one concerning\nthe discrepancy of roots of unity, we characterize all optimal polygons.\nBuilding upon this connection, we then characterize all optimal frames with $m$\nvectors in ${\\mathbb R}^2$ for phase retrieval when $m \\geq 3$ has an odd\nfactor. As a key corollary, we show that the harmonic frame $E_m$ is {\\em not}\noptimal for any even integer $m \\geq 4$. This finding disproves a conjecture\nproposed by Xia, Xu, and Xu (Math. Comp., 90(356): 2931-2960). Previous work\nhas established that the harmonic frame $E_m \\subset {\\mathbb R}^2$ is indeed\noptimal when $m$ is an odd integer.\n  Exploring the connection between phase retrieval and discrete geometry, this\npaper aims to illuminate advancements in phase retrieval and offer new\nperspectives on the perimeter-maximizing isodiametric problem.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u76f8\u4f4d\u6062\u590d\u6700\u4f18\u6846\u67b6\u4e0e\u5468\u957f\u6700\u5927\u5316\u7b49\u5f84\u95ee\u9898\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8bc1\u660e\u4e86\u5728\u4e8c\u7ef4\u5b9e\u7a7a\u95f4\u4e2d\uff0c\u6240\u6709\u5468\u957f\u6700\u5927\u5316\u7b49\u5f84\u95ee\u9898\u7684\u6700\u4f18\u89e3\u90fd\u5bf9\u5e94\u76f8\u4f4d\u6062\u590d\u7684\u6700\u4f18\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e86\u5f53m\u22654\u4e3a\u5076\u6570\u65f6\uff0c\u8c03\u548c\u6846\u67b6Em\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u63a8\u7ffb\u4e86\u4e4b\u524d\u7684\u731c\u60f3\u3002", "motivation": "\u7814\u7a76\u76f8\u4f4d\u6062\u590d\u7684\u6700\u4f18\u6846\u67b6\u7279\u6027\uff0c\u63a2\u7d22\u5176\u4e0e\u79bb\u6563\u51e0\u4f55\u4e2d\u7ecf\u5178\u95ee\u9898\u7684\u8054\u7cfb\uff0c\u4e3a\u76f8\u4f4d\u6062\u590d\u7406\u8bba\u63d0\u4f9b\u65b0\u7684\u51e0\u4f55\u89c6\u89d2\u3002", "method": "\u901a\u8fc7\u5c06\u6700\u4f18\u591a\u8fb9\u5f62\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u5173\u4e8e\u5355\u4f4d\u6839\u5dee\u5f02\u6027\u7684\u95ee\u9898\uff0c\u5229\u7528\u5468\u957f\u6700\u5927\u5316\u7b49\u5f84\u95ee\u9898\u7684\u5df2\u6709\u7ed3\u679c\u6765\u63a8\u5bfc\u76f8\u4f4d\u6062\u590d\u6700\u4f18\u6846\u67b6\u7684\u7279\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u4e8c\u7ef4\u5b9e\u7a7a\u95f4\u4e2d\uff0c\u5f53m\u22653\u4e14\u5305\u542b\u5947\u6570\u56e0\u5b50\u65f6\uff0c\u53ef\u4ee5\u5b8c\u5168\u523b\u753b\u6240\u6709\u6700\u4f18\u76f8\u4f4d\u6062\u590d\u6846\u67b6\uff1b\u7279\u522b\u5730\uff0c\u8bc1\u660e\u4e86\u5f53m\u4e3a\u5076\u6570\u65f6\u8c03\u548c\u6846\u67b6Em\u4e0d\u662f\u6700\u4f18\u7684\u3002", "conclusion": "\u5efa\u7acb\u4e86\u76f8\u4f4d\u6062\u590d\u4e0e\u79bb\u6563\u51e0\u4f55\u7684\u6df1\u523b\u8054\u7cfb\uff0c\u63a8\u7ffb\u4e86\u5173\u4e8e\u8c03\u548c\u6846\u67b6\u6700\u4f18\u6027\u7684\u731c\u60f3\uff0c\u4e3a\u76f8\u4f4d\u6062\u590d\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u7406\u89e3\u6846\u67b6\u3002"}}
{"id": "2510.03491", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.03491", "abs": "https://arxiv.org/abs/2510.03491", "authors": ["Sarah-Michelle Hammer", "Stefan Schmid", "Rachee Singh", "Vamsi Addanki"], "title": "Short-circuiting Rings for Low-Latency AllReduce", "comment": null, "summary": "Efficient collective communication is critical for many distributed ML and\nHPC applications. In this context, it is widely believed that the Ring\nalgorithm for the AllReduce collective communication operation is optimal only\nfor large messages, while Recursive Doubling is preferable for small ones due\nto its logarithmic number of steps compared to the linear number for Ring. In\nthis paper, we challenge this long-held assumption and show that the Ring\nalgorithm can remain optimal even for short messages in ring-based GPU-to-GPU\ntopologies, once realistic propagation delays and link capacity constraints are\naccounted for. We find that the total propagation delay for both Ring and\nRecursive Doubling essentially sums to the same value, but the latter incurs\nsignificantly higher congestion due to longer hop counts, leading to increased\ncompletion times. This surprising result motivates our case for in-collective\nadaptive topologies, particularly in the context of emerging photonic\ninterconnects, which can break through the limitations of static topology\ndesigns at the collective communication granularity. We design a \\emph{simple\nand fast} heuristic for circuit-switching that enables Recursive Doubling to\nexploit dynamically reconfigurable photonic paths, carefully balancing\nreconfiguration delays, propagation latencies, and link congestion to minimize\noverall completion time. Our preliminary evaluations, using realistic\nreconfiguration delays, show that our circuit-switching schedules enable faster\ncompletion times for Recursive Doubling, even compared to Ring AllReduce on\nstatic ring topologies. We conclude by highlighting key challenges and future\nresearch directions for realizing practical, in-collective photonic switching.", "AI": {"tldr": "\u6311\u6218\u4f20\u7edf\u89c2\u70b9\uff1a\u5728\u8003\u8651\u5b9e\u9645\u4f20\u64ad\u5ef6\u8fdf\u548c\u94fe\u8def\u5bb9\u91cf\u7ea6\u675f\u540e\uff0cRing AllReduce\u7b97\u6cd5\u5bf9\u5c0f\u6d88\u606f\u4e5f\u4fdd\u6301\u6700\u4f18\uff0c\u800cRecursive Doubling\u56e0\u8df3\u6570\u591a\u5bfc\u81f4\u66f4\u9ad8\u62e5\u585e\u3002\u63d0\u51fa\u57fa\u4e8e\u5149\u5b50\u4e92\u8fde\u7684\u52a8\u6001\u62d3\u6251\u5207\u6362\u65b9\u6848\uff0c\u4f7fRecursive Doubling\u80fd\u8d85\u8d8a\u9759\u6001Ring\u62d3\u6251\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u8ba4\u4e3aRing\u7b97\u6cd5\u4ec5\u5bf9\u5927\u6d88\u606f\u6700\u4f18\uff0cRecursive Doubling\u56e0\u5bf9\u6570\u6b65\u6570\u5bf9\u5c0f\u6d88\u606f\u66f4\u4f18\u3002\u4f46\u5b9e\u9645\u7f51\u7edc\u7ea6\u675f\u4e0b\uff0c\u8fd9\u4e00\u5047\u8bbe\u53ef\u80fd\u4e0d\u6210\u7acb\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u4e24\u79cd\u7b97\u6cd5\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u5206\u6790Ring\u548cRecursive Doubling\u5728\u771f\u5b9e\u7f51\u7edc\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\uff0c\u8003\u8651\u4f20\u64ad\u5ef6\u8fdf\u548c\u94fe\u8def\u5bb9\u91cf\u3002\u8bbe\u8ba1\u57fa\u4e8e\u5149\u5b50\u4e92\u8fde\u7684\u7535\u8def\u5207\u6362\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u52a8\u6001\u91cd\u6784\u62d3\u6251\u4ee5\u5e73\u8861\u91cd\u914d\u7f6e\u5ef6\u8fdf\u3001\u4f20\u64ad\u5ef6\u8fdf\u548c\u94fe\u8def\u62e5\u585e\u3002", "result": "\u53d1\u73b0Ring\u7b97\u6cd5\u5bf9\u5c0f\u6d88\u606f\u4e5f\u4fdd\u6301\u6700\u4f18\uff0c\u56e0\u4e3aRecursive Doubling\u7684\u8df3\u6570\u591a\u5bfc\u81f4\u66f4\u9ad8\u62e5\u585e\u3002\u5149\u5b50\u4e92\u8fde\u7684\u52a8\u6001\u91cd\u6784\u4f7fRecursive Doubling\u80fd\u8d85\u8d8a\u9759\u6001Ring\u62d3\u6251\u7684\u6027\u80fd\u3002", "conclusion": "\u4f20\u7edf\u5173\u4e8eAllReduce\u7b97\u6cd5\u9009\u62e9\u7684\u5047\u8bbe\u9700\u8981\u91cd\u65b0\u8003\u8651\u3002\u5149\u5b50\u4e92\u8fde\u7684\u52a8\u6001\u62d3\u6251\u91cd\u6784\u4e3a\u96c6\u4f53\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u673a\u4f1a\uff0c\u4f46\u5b9e\u73b0\u5b9e\u7528\u5316\u4ecd\u9762\u4e34\u6311\u6218\u3002"}}
{"id": "2510.03377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03377", "abs": "https://arxiv.org/abs/2510.03377", "authors": ["Ahmed Missaoui", "Cemalettin Ozturk", "Barry O'Sullivan"], "title": "Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints", "comment": null, "summary": "The scarcity of non-renewable energy sources, geopolitical problems in its\nsupply, increasing prices, and the impact of climate change, force the global\neconomy to develop more energy-efficient solutions for their operations. The\nManufacturing sector is not excluded from this challenge as one of the largest\nconsumers of energy. Energy-efficient scheduling is a method that attracts\nmanufacturing companies to reduce their consumption as it can be quickly\ndeployed and can show impact immediately. In this study, the hybrid flow shop\nscheduling problem with blocking constraint (BHFS) is investigated in which we\nseek to minimize the latest completion time (i.e. makespan) and overall energy\nconsumption, a typical manufacturing setting across many industries from\nautomotive to pharmaceutical. Energy consumption and the latest completion time\nof customer orders are usually conflicting objectives. Therefore, we first\nformulate the problem as a novel multi-objective mixed integer programming\n(MIP) model and propose an augmented epsilon-constraint method for finding the\nPareto-optimal solutions. Also, an effective multi-objective metaheuristic\nalgorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large\ninstances in reasonable time. Our proposed methods are benchmarked using small,\nmedium, and large-size instances to evaluate their efficiency. Two well-known\nalgorithms are adopted for comparing our novel approaches. The computational\nresults show the effectiveness of our method.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5e26\u6709\u963b\u585e\u7ea6\u675f\u7684\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5b8c\u5de5\u65f6\u95f4\u548c\u80fd\u8017\uff0c\u5f00\u53d1\u4e86\u6539\u8fdb\u7684\u8fed\u4ee3\u5e15\u7d2f\u6258\u8d2a\u5a6a\u7b97\u6cd5\u6765\u89e3\u51b3\u5927\u89c4\u6a21\u5b9e\u4f8b\u3002", "motivation": "\u4e0d\u53ef\u518d\u751f\u80fd\u6e90\u7a00\u7f3a\u3001\u5730\u7f18\u653f\u6cbb\u95ee\u9898\u3001\u4ef7\u683c\u4e0a\u6da8\u548c\u6c14\u5019\u53d8\u5316\u5f71\u54cd\u8feb\u4f7f\u5236\u9020\u4e1a\u5bfb\u6c42\u66f4\u8282\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u4f5c\u4e3a\u5236\u9020\u4e1a\u4e2d\u5e38\u89c1\u7684\u751f\u4ea7\u73af\u5883\uff0c\u9700\u8981\u540c\u65f6\u4f18\u5316\u5b8c\u5de5\u65f6\u95f4\u548c\u80fd\u8017\u8fd9\u4e24\u4e2a\u51b2\u7a81\u76ee\u6807\u3002", "method": "\u9996\u5148\u6784\u5efa\u4e86\u65b0\u9896\u7684\u591a\u76ee\u6807\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\uff0c\u91c7\u7528\u589e\u5f3a\u7684epsilon\u7ea6\u675f\u65b9\u6cd5\u5bfb\u627e\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u6539\u8fdb\u7684\u8fed\u4ee3\u5e15\u7d2f\u6258\u8d2a\u5a6a\u7b97\u6cd5\u6765\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\u3002", "result": "\u901a\u8fc7\u5c0f\u3001\u4e2d\u3001\u5927\u89c4\u6a21\u5b9e\u4f8b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u4e24\u79cd\u77e5\u540d\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u4e2d\u7684\u5b8c\u5de5\u65f6\u95f4\u548c\u80fd\u8017\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\u65f6\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04167", "categories": ["cs.IT", "cs.CC", "math-ph", "math.IT", "math.MP", "H.1.1"], "pdf": "https://arxiv.org/pdf/2510.04167", "abs": "https://arxiv.org/abs/2510.04167", "authors": ["Alexander Kolpakov", "Aidan Rocke"], "title": "Multiplicative Turing Ensembles, Pareto's Law, and Creativity", "comment": "22 pages; auxiliary code available on GitHub\n  (https://github.com/sashakolpakov/mte-pareto/)", "summary": "We study integer-valued multiplicative dynamics driven by i.i.d. prime\nmultipliers and connect their macroscopic statistics to universal codelengths.\nWe introduce the Multiplicative Turing Ensemble (MTE) and show how it arises\nnaturally - though not uniquely - from ensembles of probabilistic Turing\nmachines. Our modeling principle is variational: taking Elias' Omega codelength\nas an energy and imposing maximum entropy constraints yields a canonical Gibbs\nprior on integers and, by restriction, on primes. Under mild tail assumptions,\nthis prior induces exponential tails for log-multipliers (up to slowly varying\ncorrections), which in turn generate Pareto tails for additive gaps. We also\nprove time-average laws for the Omega codelength along MTE trajectories.\nEmpirically, on Debian and PyPI package size datasets, a scaled Omega prior\nachieves the lowest KL divergence against codelength histograms. Taken\ntogether, the theory-data comparison suggests a qualitative split:\nmachine-adapted regimes (Gibbs-aligned, finite first moment) exhibit clean\naveraging behavior, whereas human-generated complexity appears to sit beyond\nthis regime, with tails heavy enough to produce an unbounded first moment, and\ntherefore no averaging of the same kind.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6574\u6570\u4e58\u6cd5\u52a8\u529b\u5b66\uff0c\u5c06\u5b8f\u89c2\u7edf\u8ba1\u4e0e\u901a\u7528\u7f16\u7801\u957f\u5ea6\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u51fa\u4e58\u6cd5\u56fe\u7075\u7cfb\u7efc(MTE)\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u53d8\u5206\u539f\u7406\u63a8\u5bfc\u51faGibbs\u5148\u9a8c\u5206\u5e03\u3002\u7406\u8bba\u8868\u660e\u8be5\u6a21\u578b\u5728\u673a\u5668\u9002\u5e94\u673a\u5236\u4e0b\u5448\u73b0\u6e05\u6d01\u5e73\u5747\u884c\u4e3a\uff0c\u800c\u4eba\u7c7b\u751f\u6210\u590d\u6742\u6027\u5219\u8d85\u51fa\u6b64\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u6574\u6570\u4e58\u6cd5\u52a8\u529b\u5b66\u4e0e\u901a\u7528\u7f16\u7801\u957f\u5ea6\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63a2\u7d22\u4ece\u6982\u7387\u56fe\u7075\u673a\u7cfb\u7efc\u4e2d\u81ea\u7136\u4ea7\u751f\u7684\u4e58\u6cd5\u56fe\u7075\u7cfb\u7efc(MTE)\uff0c\u5e76\u5efa\u7acb\u53d8\u5206\u5efa\u6a21\u6846\u67b6\u3002", "method": "\u5f15\u5165\u4e58\u6cd5\u56fe\u7075\u7cfb\u7efc(MTE)\uff0c\u4ee5Elias Omega\u7f16\u7801\u957f\u5ea6\u4f5c\u4e3a\u80fd\u91cf\u51fd\u6570\uff0c\u65bd\u52a0\u6700\u5927\u71b5\u7ea6\u675f\u63a8\u5bfc\u51fa\u6574\u6570\u548c\u7d20\u6570\u7684\u89c4\u8303Gibbs\u5148\u9a8c\u5206\u5e03\u3002\u5728\u6e29\u548c\u5c3e\u90e8\u5047\u8bbe\u4e0b\uff0c\u8be5\u5148\u9a8c\u8bf1\u5bfc\u5bf9\u6570\u4e58\u5b50\u7684\u6307\u6570\u5c3e\u90e8\u3002", "result": "\u7406\u8bba\u8bc1\u660eMTE\u8f68\u8ff9\u4e0aOmega\u7f16\u7801\u957f\u5ea6\u7684\u65f6\u95f4\u5e73\u5747\u5b9a\u5f8b\u3002\u5728Debian\u548cPyPI\u5305\u5927\u5c0f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u663e\u793a\uff0c\u7f29\u653eOmega\u5148\u9a8c\u5728\u7f16\u7801\u957f\u5ea6\u76f4\u65b9\u56fe\u4e0a\u83b7\u5f97\u6700\u4f4eKL\u6563\u5ea6\u3002", "conclusion": "\u7406\u8bba-\u6570\u636e\u6bd4\u8f83\u8868\u660e\u5b58\u5728\u5b9a\u6027\u5206\u88c2\uff1a\u673a\u5668\u9002\u5e94\u673a\u5236(Gibbs\u5bf9\u9f50\uff0c\u6709\u9650\u4e00\u9636\u77e9)\u5448\u73b0\u6e05\u6d01\u5e73\u5747\u884c\u4e3a\uff0c\u800c\u4eba\u7c7b\u751f\u6210\u590d\u6742\u6027\u8d85\u51fa\u6b64\u673a\u5236\uff0c\u5c3e\u90e8\u8db3\u591f\u91cd\u5bfc\u81f4\u65e0\u754c\u4e00\u9636\u77e9\uff0c\u65e0\u6cd5\u5b9e\u73b0\u540c\u7c7b\u5e73\u5747\u3002"}}
{"id": "2510.03524", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.03524", "abs": "https://arxiv.org/abs/2510.03524", "authors": ["Mohammad Reza Akbari", "Hamid Barati", "Ali Barati"], "title": "A distributed routing protocol for sending data from things to the cloud leveraging fog technology in the large-scale IoT ecosystem", "comment": null, "summary": "Fog computing integrates cloud and edge resources. According to an\nintelligent and decentralized method, this technology processes data generated\nby IoT sensors to seamlessly integrate physical and cyber environments.\nInternet of Things uses wireless and smart objects. They communicate with each\nother, monitor the environment, collect information, and respond to user\nrequests. These objects have limited energy resources since they use batteries\nto supply energy. Also, they cannot replace their batteries. As a result, the\nnetwork lifetime is limited and short. Thus, reducing energy consumption and\naccelerating the data transmission process are very important challenges in IoT\nnetworks to reduce the response time. In the data transmission process,\nselecting an appropriate cluster head node is very important because it can\nreduce the delay when sending data to the fog. In this paper, cluster head\nnodes are selected based on several important criteria such as distance,\nresidual energy, received signal strength, and link expiration time. Then,\nobjects send the processed data to the server hierarchically through a balanced\ntree. The simulation results show that the proposed method outperforms the\nenergy-efficient centroid-based routing protocol (EECRP) and the Emergency\nResponse IoT based on Global Information Decision (ERGID) in terms of packet\ndelivery rate, delay, response time, and network lifetime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96fe\u8ba1\u7b97\u7684\u7269\u8054\u7f51\u8282\u80fd\u8def\u7531\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6807\u51c6\u7c07\u5934\u9009\u62e9\u548c\u5e73\u8861\u6811\u7ed3\u6784\u6765\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u80fd\u91cf\u6709\u9650\u4e14\u65e0\u6cd5\u66f4\u6362\u7535\u6c60\uff0c\u5bfc\u81f4\u7f51\u7edc\u5bff\u547d\u77ed\u3002\u9700\u8981\u964d\u4f4e\u80fd\u8017\u3001\u52a0\u901f\u6570\u636e\u4f20\u8f93\u4ee5\u51cf\u5c11\u54cd\u5e94\u65f6\u95f4", "method": "\u57fa\u4e8e\u8ddd\u79bb\u3001\u5269\u4f59\u80fd\u91cf\u3001\u63a5\u6536\u4fe1\u53f7\u5f3a\u5ea6\u548c\u94fe\u8def\u8fc7\u671f\u65f6\u95f4\u7b49\u591a\u6807\u51c6\u9009\u62e9\u7c07\u5934\u8282\u70b9\uff0c\u901a\u8fc7\u5e73\u8861\u6811\u5c42\u6b21\u5316\u4f20\u8f93\u6570\u636e\u5230\u670d\u52a1\u5668", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5305\u6295\u9012\u7387\u3001\u5ef6\u8fdf\u3001\u54cd\u5e94\u65f6\u95f4\u548c\u7f51\u7edc\u5bff\u547d\u65b9\u9762\u4f18\u4e8eEECRP\u548cERGID\u534f\u8bae", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u6807\u51c6\u7c07\u5934\u9009\u62e9\u548c\u5e73\u8861\u6811\u8def\u7531\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u7269\u8054\u7f51\u7f51\u7edc\u6027\u80fd\uff0c\u5ef6\u957f\u7f51\u7edc\u5bff\u547d"}}
{"id": "2510.03399", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03399", "abs": "https://arxiv.org/abs/2510.03399", "authors": ["Xiaoyan Bai", "Aryan Shrivastava", "Ari Holtzman", "Chenhao Tan"], "title": "Know Thyself? On the Incapability and Implications of AI Self-Recognition", "comment": "Our code is available, see\n  https://github.com/ChicagoHAI/self-recognition", "summary": "Self-recognition is a crucial metacognitive capability for AI systems,\nrelevant not only for psychological analysis but also for safety, particularly\nin evaluative scenarios. Motivated by contradictory interpretations of whether\nmodels possess self-recognition (Panickssery et al., 2024; Davidson et al.,\n2024), we introduce a systematic evaluation framework that can be easily\napplied and updated. Specifically, we measure how well 10 contemporary larger\nlanguage models (LLMs) can identify their own generated text versus text from\nother models through two tasks: binary self-recognition and exact model\nprediction. Different from prior claims, our results reveal a consistent\nfailure in self-recognition. Only 4 out of 10 models predict themselves as\ngenerators, and the performance is rarely above random chance. Additionally,\nmodels exhibit a strong bias toward predicting GPT and Claude families. We also\nprovide the first evaluation of model awareness of their own and others'\nexistence, as well as the reasoning behind their choices in self-recognition.\nWe find that the model demonstrates some knowledge of its own existence and\nother models, but their reasoning reveals a hierarchical bias. They appear to\nassume that GPT, Claude, and occasionally Gemini are the top-tier models, often\nassociating high-quality text with them. We conclude by discussing the\nimplications of our findings on AI safety and future directions to develop\nappropriate AI self-awareness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e8610\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u8bc6\u522b\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u666e\u904d\u65e0\u6cd5\u8bc6\u522b\u81ea\u5df1\u751f\u6210\u7684\u6587\u672c\uff0c\u6027\u80fd\u4ec5\u7565\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u4e14\u5b58\u5728\u5bf9GPT\u548cClaude\u5bb6\u65cf\u7684\u5f3a\u70c8\u504f\u89c1\u3002", "motivation": "\u9488\u5bf9AI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u8fd9\u4e00\u5b58\u5728\u4e89\u8bae\u7684\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u53ef\u91cd\u590d\u66f4\u65b0\u7684\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd9\u5bf9AI\u5b89\u5168\u548c\u5fc3\u7406\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u4efb\u52a1\u8bc4\u4f30\u6a21\u578b\uff1a\u4e8c\u5143\u81ea\u6211\u8bc6\u522b\uff08\u5224\u65ad\u6587\u672c\u662f\u5426\u4e3a\u81ea\u5df1\u751f\u6210\uff09\u548c\u7cbe\u786e\u6a21\u578b\u9884\u6d4b\uff08\u8bc6\u522b\u6587\u672c\u7684\u5177\u4f53\u6765\u6e90\u6a21\u578b\uff09\u3002\u8bc4\u4f30\u4e8610\u4e2a\u5f53\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u666e\u904d\u5931\u8d25\uff0c\u53ea\u67094/10\u7684\u6a21\u578b\u80fd\u6b63\u786e\u8bc6\u522b\u81ea\u5df1\u751f\u6210\u7684\u6587\u672c\uff0c\u6027\u80fd\u5f88\u5c11\u8d85\u8fc7\u968f\u673a\u6c34\u5e73\u3002\u6a21\u578b\u8868\u73b0\u51fa\u5bf9GPT\u548cClaude\u5bb6\u65cf\u7684\u5f3a\u70c8\u504f\u89c1\uff0c\u5e76\u663e\u793a\u51fa\u5bf9\u6a21\u578b\u5b58\u5728\u5c42\u6b21\u7ed3\u6784\u7684\u8ba4\u77e5\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5f53\u524dAI\u7cfb\u7edf\u7f3a\u4e4f\u9002\u5f53\u7684\u81ea\u6211\u610f\u8bc6\uff0c\u8fd9\u5bf9AI\u5b89\u5168\u6784\u6210\u6311\u6218\uff0c\u5e76\u6307\u51fa\u4e86\u5f00\u53d1\u9002\u5f53AI\u81ea\u6211\u610f\u8bc6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.04314", "categories": ["cs.IT", "math.IT", "Primary 94, Secondary 90"], "pdf": "https://arxiv.org/pdf/2510.04314", "abs": "https://arxiv.org/abs/2510.04314", "authors": ["Alexander Dukhovny"], "title": "Relative Divergence and Maximum Relative Divergence Principle for Grading Functions on Partially Ordered Sets", "comment": "14 pages", "summary": "Relative Divergence (RD) and Maximum Relative Divergence Principle (MRDP) for\ngrading (order-comonotonic) functions (GF) on posets are used as an expression\nof Insufficient Reason Principle under the given prior information (IRP+).\nClassic Probability Theory formulas are presented as IRP+ solutions of MRDP\nproblems on conjoined posets. RD definition principles are analyzed in relation\nto the poset structure. MRDP techniques are presented for standard posets:\npower sets, direct products of chains, etc. \"Population group-testing\" and\n\"Single server of multiple queues\" applications are stated and analyzed as\n\"IRP+ by MRDP\" problems on conjoined base posets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u76f8\u5bf9\u6563\u5ea6(RD)\u548c\u6700\u5927\u76f8\u5bf9\u6563\u5ea6\u539f\u7406(MRDP)\u4f5c\u4e3a\u7ed9\u5b9a\u5148\u9a8c\u4fe1\u606f\u4e0b\u4e0d\u5145\u5206\u7406\u7531\u539f\u7406(IRP+)\u7684\u8868\u8fbe\uff0c\u7528\u4e8e\u504f\u5e8f\u96c6\u4e0a\u7684\u5206\u7ea7\u51fd\u6570\u3002", "motivation": "\u5728\u7ed9\u5b9a\u5148\u9a8c\u4fe1\u606f\u6761\u4ef6\u4e0b\uff0c\u5bfb\u627e\u4e0d\u5145\u5206\u7406\u7531\u539f\u7406\u7684\u6570\u5b66\u8868\u8fbe\u65b9\u5f0f\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u504f\u5e8f\u96c6\u4e0a\u7684\u5206\u7ea7\u51fd\u6570\u3002", "method": "\u4f7f\u7528\u76f8\u5bf9\u6563\u5ea6\u548c\u6700\u5927\u76f8\u5bf9\u6563\u5ea6\u539f\u7406\uff0c\u5206\u6790\u504f\u5e8f\u96c6\u7ed3\u6784\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6807\u51c6\u504f\u5e8f\u96c6\u5982\u5e42\u96c6\u3001\u94fe\u7684\u76f4\u79ef\u7b49\u3002", "result": "\u5c06\u7ecf\u5178\u6982\u7387\u8bba\u516c\u5f0f\u8868\u793a\u4e3aMRDP\u95ee\u9898\u5728\u8fde\u63a5\u504f\u5e8f\u96c6\u4e0a\u7684IRP+\u89e3\uff0c\u5e76\u5206\u6790\u4e86\u7fa4\u4f53\u68c0\u6d4b\u548c\u5355\u670d\u52a1\u5668\u591a\u961f\u5217\u7b49\u5e94\u7528\u3002", "conclusion": "MRDP\u4e3a\u5728\u504f\u5e8f\u96c6\u4e0a\u8868\u8fbe\u4e0d\u5145\u5206\u7406\u7531\u539f\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u80fd\u591f\u7edf\u4e00\u5904\u7406\u591a\u79cd\u6982\u7387\u8bba\u548c\u5e94\u7528\u95ee\u9898\u3002"}}
{"id": "2510.03533", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.03533", "abs": "https://arxiv.org/abs/2510.03533", "authors": ["Mohammad Reza Akbari", "Hamid Barati", "Ali Barati"], "title": "An efficient grey theory-driven path selection for energy efficiency control in the Internet of Things using fog and cloud computing", "comment": null, "summary": "Due to the big data exchange on the Internet of Things, proper routing and\nselecting the best routes for fast data transmission improve network\nperformance. There are major challenges, like high delay, when cloud computing\nis used. Therefore, one solution is to use other schemes, such as fog\ncomputing. In fog computing, all data is not sent to the cloud and the fog\nnodes close to objects are used for data processing. This reduces the network\ndelay. In this paper, we propose an overlapping clustering method called\nMFCT-IoT to select the best cluster head nodes to guarantee the fast data\ntransfer from objects to fog nodes. The selected cluster head nodes are\nresponsible for sending the collected data to the closest fog nodes in the\nnetwork edge. Upon receiving the data, the fog nodes process it, and if a\nresponse is ready, they respond immediately to the object. Otherwise, they\nmerge and transmit the data to the cloud servers, which are considered as the\nroot node of the proposed hierarchical tree. After processing, the merged data\nis sent to the object. We compare the proposed scheme with two schemes,\nincluding ERGID and EECRP. These schemes are evaluated based on various\ncriteria, including the response time, packet delivery ratio, end-to-end delay,\nnetwork lifetime, and energy consumption. The results indicate that the\nproposed method outperforms others in terms of all criteria.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMFCT-IoT\u7684\u91cd\u53e0\u805a\u7c7b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u7269\u8054\u7f51\u96fe\u8ba1\u7b97\u4e2d\u9009\u62e9\u6700\u4f73\u7c07\u5934\u8282\u70b9\uff0c\u4ee5\u4f18\u5316\u6570\u636e\u4f20\u8f93\u6027\u80fd\u3002", "motivation": "\u7269\u8054\u7f51\u5927\u6570\u636e\u4ea4\u6362\u4e2d\uff0c\u4f20\u7edf\u4e91\u8ba1\u7b97\u5b58\u5728\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u96fe\u8ba1\u7b97\u901a\u8fc7\u5c31\u8fd1\u5904\u7406\u6570\u636e\u6765\u51cf\u5c11\u7f51\u7edc\u5ef6\u8fdf\u3002", "method": "\u4f7f\u7528\u91cd\u53e0\u805a\u7c7b\u65b9\u6cd5\u9009\u62e9\u6700\u4f73\u7c07\u5934\u8282\u70b9\uff0c\u7c07\u5934\u8d1f\u8d23\u5c06\u6536\u96c6\u7684\u6570\u636e\u53d1\u9001\u5230\u6700\u8fd1\u7684\u96fe\u8282\u70b9\uff0c\u96fe\u8282\u70b9\u5904\u7406\u6570\u636e\u6216\u5408\u5e76\u540e\u53d1\u9001\u5230\u4e91\u7aef\u3002", "result": "\u4e0eERGID\u548cEECRP\u65b9\u6848\u76f8\u6bd4\uff0cMFCT-IoT\u5728\u54cd\u5e94\u65f6\u95f4\u3001\u6570\u636e\u5305\u6295\u9012\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u7f51\u7edc\u5bff\u547d\u548c\u80fd\u8017\u7b49\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u63d0\u51fa\u7684MFCT-IoT\u65b9\u6cd5\u5728\u96fe\u8ba1\u7b97\u73af\u5883\u4e2d\u80fd\u6709\u6548\u63d0\u5347\u7f51\u7edc\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002"}}
{"id": "2510.03418", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.03418", "abs": "https://arxiv.org/abs/2510.03418", "authors": ["Ananya Mantravadi", "Shivali Dalmia", "Abhishek Mukherji", "Nand Dave", "Anudha Mittal"], "title": "ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,\noffering advanced capabilities for information access and decision-making.\nHowever, contradictions in retrieved evidence can result in inconsistent or\nuntrustworthy outputs, which is especially problematic in enterprise settings\nwhere compliance, governance, and accountability are critical. Existing\nbenchmarks for contradiction detection are limited to sentence-level analysis\nand do not capture the complexity of enterprise documents such as contracts,\nfinancial filings, compliance reports, or policy manuals. To address this\nlimitation, we propose ContraGen, a contradiction-aware benchmark framework\ntailored to enterprise domain. The framework generates synthetic\nenterprise-style documents with embedded contradictions, enabling systematic\nevaluation of both intra-document and cross-document consistency. Automated\ncontradiction mining is combined with human-in-the-loop validation to ensure\nhigh accuracy. Our contributions include generating realistic enterprise\ndocuments, modeling a taxonomy of contradiction types common in business\nprocesses, enabling controlled creation of self- and pairwise contradictions,\ndeveloping a contradiction-aware retrieval evaluation pipeline and embedding\nhuman oversight to reflect domain-specific judgment complexity. This work\nestablishes a foundation for more trustworthy and accountable RAG systems in\nenterprise information-seeking applications, where detecting and resolving\ncontradictions is essential for reducing risk and ensuring compliance.", "AI": {"tldr": "\u63d0\u51fa\u4e86ContraGen\u57fa\u51c6\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u4f01\u4e1a\u9886\u57df\u8bbe\u8ba1\uff0c\u7528\u4e8e\u8bc4\u4f30RAG\u7cfb\u7edf\u4e2d\u77db\u76fe\u68c0\u6d4b\u80fd\u529b\uff0c\u901a\u8fc7\u751f\u6210\u5305\u542b\u77db\u76fe\u7684\u4f01\u4e1a\u98ce\u683c\u6587\u6863\u6765\u7cfb\u7edf\u8bc4\u4f30\u6587\u6863\u5185\u548c\u8de8\u6587\u6863\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u77db\u76fe\u68c0\u6d4b\u57fa\u51c6\u4ec5\u9650\u4e8e\u53e5\u5b50\u7ea7\u5206\u6790\uff0c\u65e0\u6cd5\u6355\u6349\u4f01\u4e1a\u6587\u6863\uff08\u5982\u5408\u540c\u3001\u8d22\u52a1\u62a5\u544a\u3001\u5408\u89c4\u6587\u4ef6\uff09\u7684\u590d\u6742\u6027\uff0c\u800cRAG\u7cfb\u7edf\u4e2d\u7684\u8bc1\u636e\u77db\u76fe\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u9760\u8f93\u51fa\uff0c\u8fd9\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7279\u522b\u5371\u9669\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u5316\u77db\u76fe\u6316\u6398\u548c\u4eba\u5de5\u9a8c\u8bc1\uff0c\u751f\u6210\u5305\u542b\u5d4c\u5165\u77db\u76fe\u7684\u4f01\u4e1a\u98ce\u683c\u5408\u6210\u6587\u6863\uff0c\u5efa\u7acb\u4f01\u4e1a\u6d41\u7a0b\u4e2d\u5e38\u89c1\u77db\u76fe\u7c7b\u578b\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u652f\u6301\u53d7\u63a7\u521b\u5efa\u81ea\u77db\u76fe\u548c\u6210\u5bf9\u77db\u76fe\u3002", "result": "\u5f00\u53d1\u4e86\u77db\u76fe\u611f\u77e5\u7684\u68c0\u7d22\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5d4c\u5165\u4eba\u5de5\u76d1\u7763\u4ee5\u53cd\u6620\u9886\u57df\u7279\u5b9a\u5224\u65ad\u590d\u6742\u6027\uff0c\u4e3a\u4f01\u4e1a\u4fe1\u606f\u68c0\u7d22\u5e94\u7528\u5efa\u7acb\u66f4\u53ef\u4fe1\u8d56\u7684RAG\u7cfb\u7edf\u57fa\u7840\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4f01\u4e1a\u4fe1\u606f\u68c0\u7d22\u5e94\u7528\u4e2d\u68c0\u6d4b\u548c\u89e3\u51b3\u77db\u76fe\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5bf9\u964d\u4f4e\u98ce\u9669\u548c\u786e\u4fdd\u5408\u89c4\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.04451", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.04451", "abs": "https://arxiv.org/abs/2510.04451", "authors": ["Nan Meng", "Yun-Bin Zhao"], "title": "Compressed Newton-direction-based Thresholding Methods for Sparse Optimization Problems", "comment": null, "summary": "Thresholding algorithms for sparse optimization problems involve two key\ncomponents: search directions and thresholding strategies. In this paper, we\nuse the compressed Newton direction as a search direction, derived by confining\nthe classical Newton step to a low-dimensional subspace and embedding it back\ninto the full space with diagonal regularization. This approach significantly\nreduces the computational cost for finding the search direction while\nmaintaining the efficiency of Newton-like methods. Based on this new search\ndirection, we propose two major classes of algorithms by adopting hard or\noptimal thresholding: the compressed Newton-direction-based thresholding\npursuit (CNHTP) and compressed Newton-direction-based optimal thresholding\npursuit (CNOTP). We establish the global convergence of the proposed algorithms\nunder the restricted isometry property. Experimental results demonstrate that\nthe proposed algorithms perform comparably to several state-of-the-art methods\nin terms of success frequency and solution accuracy for solving the sparse\noptimization problem.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u538b\u7f29\u725b\u987f\u65b9\u5411\u7684\u9608\u503c\u8ffd\u8e2a\u7b97\u6cd5(CNHTP\u548cCNOTP)\uff0c\u901a\u8fc7\u5c06\u725b\u987f\u6b65\u9650\u5236\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u5e76\u6dfb\u52a0\u5bf9\u89d2\u6b63\u5219\u5316\u6765\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u725b\u987f\u7c7b\u65b9\u6cd5\u7684\u6548\u7387\u3002", "motivation": "\u7a00\u758f\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u9608\u503c\u7b97\u6cd5\u6d89\u53ca\u641c\u7d22\u65b9\u5411\u548c\u9608\u503c\u7b56\u7565\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u53c8\u80fd\u4fdd\u6301\u6548\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u538b\u7f29\u725b\u987f\u65b9\u5411\u4f5c\u4e3a\u641c\u7d22\u65b9\u5411\uff0c\u901a\u8fc7\u5c06\u7ecf\u5178\u725b\u987f\u6b65\u9650\u5236\u5728\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u5e76\u5d4c\u5165\u5230\u5168\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5bf9\u89d2\u6b63\u5219\u5316\uff0c\u7136\u540e\u91c7\u7528\u786c\u9608\u503c\u6216\u6700\u4f18\u9608\u503c\u7b56\u7565\u3002", "result": "\u5728\u9650\u5236\u7b49\u8ddd\u6027\u8d28\u4e0b\u5efa\u7acb\u4e86\u7b97\u6cd5\u7684\u5168\u5c40\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5728\u6c42\u89e3\u7a00\u758f\u4f18\u5316\u95ee\u9898\u65f6\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u6210\u529f\u9891\u7387\u548c\u89e3\u7cbe\u5ea6\u65b9\u9762\u4e0e\u51e0\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u57fa\u4e8e\u538b\u7f29\u725b\u987f\u65b9\u5411\u7684\u9608\u503c\u8ffd\u8e2a\u7b97\u6cd5\u5728\u4fdd\u6301\u725b\u987f\u7c7b\u65b9\u6cd5\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u89e3\u51b3\u7a00\u758f\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03714", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.03714", "abs": "https://arxiv.org/abs/2510.03714", "authors": ["Nalith Udugampola", "Xiaoyu Ai", "Binghao Li", "Henry Gong", "Aruna Seneviratne"], "title": "A Position- and Energy-Aware Routing Strategy for Subterranean LoRa Mesh Networks", "comment": null, "summary": "Although LoRa is predominantly employed with the single-hop LoRaWAN protocol,\nrecent advancements have extended its application to multi-hop mesh topologies.\nDesigning efficient routing for LoRa mesh networks remains challenging due to\nLoRa's low data rate and ALOHA-based MAC. Prior work often adapts conventional\nprotocols for low-traffic, aboveground networks with strict duty cycle\nconstraints or uses flooding-based methods in subterranean environments.\nHowever, these approaches inefficiently utilize the limited available network\nbandwidth in these low-data-rate networks due to excessive control overhead,\nacknowledgments, and redundant retransmissions. In this paper, we introduce a\nnovel position- and energy-aware routing strategy tailored for subterranean\nLoRa mesh networks aimed at enhancing maximum throughput and power efficiency\nwhile also maintaining high packet delivery ratios. Our mechanism begins with a\nlightweight position learning phase, during which LoRa repeaters ascertain\ntheir relative positions and gather routing information. Afterwards, the\nnetwork becomes fully operational with adaptive routing, leveraging standby\nLoRa repeaters for recovery from packet collisions and losses, and energy-aware\nroute switching to balance battery depletion across repeaters. The simulation\nresults on a representative subterranean network demonstrate a 185% increase in\nmaximum throughput and a 75% reduction in energy consumption compared to a\npreviously optimized flooding-based approach for high traffic.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5730\u4e0bLoRa\u7f51\u72b6\u7f51\u7edc\u7684\u65b0\u578b\u4f4d\u7f6e\u548c\u80fd\u91cf\u611f\u77e5\u8def\u7531\u7b56\u7565\uff0c\u76f8\u6bd4\u4e4b\u524d\u4f18\u5316\u7684\u57fa\u4e8e\u6cdb\u6d2a\u7684\u65b9\u6cd5\uff0c\u6700\u5927\u541e\u5410\u91cf\u63d0\u9ad8185%\uff0c\u80fd\u8017\u964d\u4f4e75%\u3002", "motivation": "\u73b0\u6709LoRa\u7f51\u72b6\u7f51\u7edc\u8def\u7531\u534f\u8bae\u5728\u4f4e\u6570\u636e\u7387\u7f51\u7edc\u4e2d\u7531\u4e8e\u63a7\u5236\u5f00\u9500\u3001\u786e\u8ba4\u548c\u5197\u4f59\u91cd\u4f20\u800c\u4f4e\u6548\u5229\u7528\u6709\u9650\u5e26\u5bbd\uff0c\u7279\u522b\u662f\u5728\u5730\u4e0b\u73af\u5883\u4e2d\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u4f4d\u7f6e\u5b66\u4e60\u9636\u6bb5\u786e\u5b9a\u4e2d\u7ee7\u5668\u76f8\u5bf9\u4f4d\u7f6e\u548c\u8def\u7531\u4fe1\u606f\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u9002\u5e94\u8def\u7531\u5229\u7528\u5907\u7528LoRa\u4e2d\u7ee7\u5668\u8fdb\u884c\u6570\u636e\u5305\u51b2\u7a81\u548c\u4e22\u5931\u6062\u590d\uff0c\u4ee5\u53ca\u80fd\u91cf\u611f\u77e5\u8def\u7531\u5207\u6362\u6765\u5e73\u8861\u4e2d\u7ee7\u5668\u7535\u6c60\u6d88\u8017\u3002", "result": "\u5728\u4ee3\u8868\u6027\u5730\u4e0b\u7f51\u7edc\u6a21\u62df\u4e2d\uff0c\u76f8\u6bd4\u4e4b\u524d\u4f18\u5316\u7684\u57fa\u4e8e\u6cdb\u6d2a\u7684\u9ad8\u6d41\u91cf\u65b9\u6cd5\uff0c\u6700\u5927\u541e\u5410\u91cf\u63d0\u9ad8185%\uff0c\u80fd\u8017\u964d\u4f4e75%\u3002", "conclusion": "\u8be5\u4f4d\u7f6e\u548c\u80fd\u91cf\u611f\u77e5\u8def\u7531\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u4e0bLoRa\u7f51\u72b6\u7f51\u7edc\u7684\u541e\u5410\u91cf\u548c\u80fd\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6570\u636e\u5305\u4f20\u8f93\u7387\u3002"}}
{"id": "2510.03453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03453", "abs": "https://arxiv.org/abs/2510.03453", "authors": ["Paul S. Rosenbloom"], "title": "A Qualitative Comparative Evaluation of Cognitive and Generative Theories", "comment": "To appear in Proceedings of the 12th Annual Conference on Advances in\n  Cognitive Systems (ACS-25)", "summary": "Evaluation is a critical activity associated with any theory. Yet this has\nproven to be an exceptionally challenging activity for theories based on\ncognitive architectures. For an overlapping set of reasons, evaluation can also\nbe challenging for theories based on generative neural architectures. This dual\nchallenge is approached here by leveraging a broad perspective on theory\nevaluation to yield a wide-ranging, albeit qualitative, comparison of\nwhole-mind-oriented cognitive and generative architectures and the full systems\nthat are based on these architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7406\u8bba\u7684\u5b9a\u6027\u6bd4\u8f83\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e24\u79cd\u67b6\u6784\u7406\u8bba\u8bc4\u4f30\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u7406\u8bba\u8bc4\u4f30\u90fd\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u4fc3\u8fdb\u8fd9\u4e9b\u7406\u8bba\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u5e7f\u6cdb\u7684\u7406\u8bba\u8bc4\u4f30\u89c6\u89d2\uff0c\u5bf9\u9762\u5411\u5168\u8111\u7684\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u67b6\u6784\u53ca\u5176\u5b8c\u6574\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u7684\u5b9a\u6027\u6bd4\u8f83\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5bbd\u6cdb\u7684\u5b9a\u6027\u6bd4\u8f83\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e0d\u540c\u7c7b\u578b\u7684\u8ba4\u77e5\u67b6\u6784\u7406\u8bba\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u5e7f\u6cdb\u7684\u7406\u8bba\u8bc4\u4f30\u89c6\u89d2\uff0c\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7406\u8bba\u8bc4\u4f30\u7684\u6311\u6218\uff0c\u4e3a\u8fd9\u7c7b\u7406\u8bba\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.04664", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.04664", "abs": "https://arxiv.org/abs/2510.04664", "authors": ["Jian Xiao", "Ji Wang", "Qi Sun", "Qimei Cui", "Xingwang Li", "Dusit Niyato", "Chih-Lin I"], "title": "Learning Function-to-Function Mappings: A Fourier Neural Operator for Next-Generation MIMO Systems", "comment": null, "summary": "Next-generation multiple-input multiple-output (MIMO) systems, characterized\nby extremely large-scale arrays, holographic surfaces, three-dimensional\narchitectures, and flexible antennas, are poised to deliver unprecedented data\nrates, spectral efficiency and stability. However, these advancements introduce\nsignificant challenges for physical layer signal processing, stemming from\ncomplex near-field propagation, continuous aperture modeling, sub-wavelength\nantenna coupling effects, and dynamic channel conditions. Conventional\nmodel-based and deep learning approaches often struggle with the immense\ncomputational complexity and model inaccuracies inherent in these new regimes.\nThis article proposes a Fourier neural operator (FNO) as a powerful and\npromising tool to address these challenges. The FNO learns function-to-function\nmappings between infinite-dimensional function spaces, making them\nexceptionally well-suited for modeling complex physical systems governed by\npartial differential equations based on electromagnetic wave propagation. We\nfirst present the fundamental principles of FNO, demonstrating its mesh-free\nnature and function-to-function ability to efficiently capture global\ndependencies in the Fourier domain. Furthermore, we explore a range of\napplications of FNO in physical-layer signal processing for next-generation\nMIMO systems. Representative case studies on channel modeling and estimation\nfor novel MIMO architectures demonstrate the superior performance of FNO\ncompared to state-of-the-art methods. Finally, we discuss open challenges and\noutline future research directions, positioning FNO as a promising technology\nfor enabling the enormous potential of next-generation MIMO systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08FNO\uff09\u4f5c\u4e3a\u89e3\u51b3\u4e0b\u4e00\u4ee3\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7269\u7406\u5c42\u4fe1\u53f7\u5904\u7406\u6311\u6218\u7684\u6709\u529b\u5de5\u5177\uff0c\u901a\u8fc7\u51fd\u6570\u5230\u51fd\u6570\u7684\u6620\u5c04\u80fd\u529b\u6709\u6548\u5efa\u6a21\u7535\u78c1\u6ce2\u4f20\u64ad\u7b49\u590d\u6742\u7269\u7406\u7cfb\u7edf\u3002", "motivation": "\u4e0b\u4e00\u4ee3MIMO\u7cfb\u7edf\u9762\u4e34\u8fd1\u573a\u4f20\u64ad\u3001\u8fde\u7eed\u5b54\u5f84\u5efa\u6a21\u3001\u4e9a\u6ce2\u957f\u5929\u7ebf\u8026\u5408\u6548\u5e94\u548c\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u6a21\u578b\u9a71\u52a8\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u6a21\u578b\u4e0d\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08FNO\uff09\u5b66\u4e60\u65e0\u9650\u7ef4\u51fd\u6570\u7a7a\u95f4\u4e4b\u95f4\u7684\u51fd\u6570\u5230\u51fd\u6570\u6620\u5c04\uff0c\u5229\u7528\u5176\u5728\u5085\u91cc\u53f6\u57df\u4e2d\u6709\u6548\u6355\u83b7\u5168\u5c40\u4f9d\u8d56\u6027\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u65e0\u7f51\u683c\u5efa\u6a21\u3002", "result": "\u5728\u65b0\u578bMIMO\u67b6\u6784\u7684\u4fe1\u9053\u5efa\u6a21\u548c\u4f30\u8ba1\u7b49\u4ee3\u8868\u6027\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cFNO\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "FNO\u662f\u5b9e\u73b0\u4e0b\u4e00\u4ee3MIMO\u7cfb\u7edf\u5de8\u5927\u6f5c\u529b\u7684\u6709\u524d\u666f\u6280\u672f\uff0c\u6587\u7ae0\u8fd8\u8ba8\u8bba\u4e86\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.03807", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03807", "abs": "https://arxiv.org/abs/2510.03807", "authors": ["Vaskar Chakma", "Wooyeol Choi"], "title": "6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection", "comment": null, "summary": "Current Cyber-Physical Systems (CPS) integrated with Digital Twin (DT)\ntechnology face critical limitations in achieving real-time performance for\nmission-critical industrial applications. Existing 5G-enabled systems suffer\nfrom latencies exceeding 10ms, which are inadequate for applications requiring\nsub-millisecond response times, such as autonomous industrial control and\npredictive maintenance. This research aims to develop and validate a 6G-enabled\nDigital Twin framework that achieves ultra-low latency communication and\nreal-time synchronization between physical industrial assets and their digital\ncounterparts, specifically targeting bearing fault detection as a critical\nindustrial use case. The proposed framework integrates terahertz communications\n(0.1-1 THz), intelligent reflecting surfaces, and edge artificial intelligence\nwithin a five-layer architecture. Experimental validation was conducted using\nthe Case Western Reserve University (CWRU) bearing dataset, implementing\ncomprehensive feature extraction (15 time and frequency domain features) and\nRandom Forest classification algorithms. The system performance was evaluated\nagainst traditional WiFi-6 and 5G networks across multiple metrics, including\nclassification accuracy, end-to-end latency, and scalability. It achieved 97.7%\nfault classification accuracy with 0.8ms end-to-end latency, representing a\n15.6x improvement over WiFi-6 (12.5ms) and 5.25x improvement over 5G (4.2ms)\nnetworks. The system demonstrated superior scalability with sub-linear\nprocessing time growth and maintained consistent performance across four\nbearing fault categories (normal, inner race, outer race, and ball faults) with\nmacro-averaged F1-scores exceeding 97%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd6G\u9a71\u52a8\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u901a\u8fc7\u592a\u8d6b\u5179\u901a\u4fe1\u548c\u8fb9\u7f18AI\u5b9e\u73b0\u8d85\u4f4e\u5ef6\u8fdf\uff080.8ms\uff09\u7684\u8f74\u627f\u6545\u969c\u68c0\u6d4b\uff0c\u76f8\u6bd4WiFi-6\u548c5G\u7f51\u7edc\u5206\u522b\u63d0\u534715.6\u500d\u548c5.25\u500d\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e5G\u7684CPS\u7cfb\u7edf\u5ef6\u8fdf\u8d85\u8fc710ms\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5de5\u4e1a\u5173\u952e\u4efb\u52a1\u5e94\u7528\u5bf9\u4e9a\u6beb\u79d2\u7ea7\u54cd\u5e94\u65f6\u95f4\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u81ea\u4e3b\u5de5\u4e1a\u63a7\u5236\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u7b49\u573a\u666f\u3002", "method": "\u96c6\u6210\u592a\u8d6b\u5179\u901a\u4fe1\uff080.1-1 THz\uff09\u3001\u667a\u80fd\u53cd\u5c04\u8868\u9762\u548c\u8fb9\u7f18\u4eba\u5de5\u667a\u80fd\u7684\u4e94\u5c42\u67b6\u6784\uff0c\u4f7f\u7528CWRU\u8f74\u627f\u6570\u636e\u96c6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u7b97\u6cd5\u9a8c\u8bc1\u3002", "result": "\u5b9e\u73b0\u4e8697.7%\u7684\u6545\u969c\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u4ec50.8ms\uff0c\u76f8\u6bd4WiFi-6\uff0812.5ms\uff09\u548c5G\uff084.2ms\uff09\u7f51\u7edc\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5728\u56db\u79cd\u8f74\u627f\u6545\u969c\u7c7b\u578b\u4e0a\u4fdd\u630197%\u4ee5\u4e0a\u7684\u5b8f\u5e73\u5747F1\u5206\u6570\u3002", "conclusion": "6G\u9a71\u52a8\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5de5\u4e1a\u5173\u952e\u4efb\u52a1\u5e94\u7528\u7684\u5b9e\u65f6\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u8d85\u4f4e\u5ef6\u8fdf\u5de5\u4e1a\u81ea\u52a8\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03469", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.03469", "abs": "https://arxiv.org/abs/2510.03469", "authors": ["Keshav Ramani", "Vali Tawosi", "Salwa Alamir", "Daniel Borrajo"], "title": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification", "comment": null, "summary": "We introduce a novel framework for evaluating the alignment between natural\nlanguage plans and their expected behavior by converting them into Kripke\nstructures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)\nand performing model checking. We systematically evaluate this framework on a\nsimplified version of the PlanBench plan verification dataset and report on\nmetrics like Accuracy, Precision, Recall and F1 scores. Our experiments\ndemonstrate that GPT-5 achieves excellent classification performance (F1 score\nof 96.3%) while almost always producing syntactically perfect formal\nrepresentations that can act as guarantees. However, the synthesis of\nsemantically perfect formal models remains an area for future exploration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u8f6c\u6362\u4e3aKripke\u7ed3\u6784\u548c\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91(LTL)\u6765\u8bc4\u4f30\u8ba1\u5212\u4e0e\u9884\u671f\u884c\u4e3a\u5bf9\u9f50\u6027\u7684\u65b0\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\u3002", "motivation": "\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u4e0e\u5176\u9884\u671f\u884c\u4e3a\u4e4b\u95f4\u7684\u5bf9\u9f50\u6027\uff0c\u786e\u4fdd\u8ba1\u5212\u6267\u884c\u7ed3\u679c\u7b26\u5408\u9884\u671f\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u8f6c\u6362\u4e3aKripke\u7ed3\u6784\u548cLTL\u516c\u5f0f\uff0c\u7136\u540e\u5728PlanBench\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\u9a8c\u8bc1\u3002", "result": "GPT-5\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272(F1\u5206\u657096.3%)\uff0c\u51e0\u4e4e\u603b\u80fd\u751f\u6210\u8bed\u6cd5\u5b8c\u7f8e\u7684\u5f62\u5f0f\u5316\u8868\u793a\uff0c\u53ef\u4f5c\u4e3a\u4fdd\u8bc1\u3002", "conclusion": "\u6846\u67b6\u5728\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8bed\u4e49\u5b8c\u7f8e\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u5408\u6210\u4ecd\u662f\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.05068", "categories": ["cs.IT", "cs.CR", "cs.DC", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.05068", "abs": "https://arxiv.org/abs/2510.05068", "authors": ["Shreya Meel", "Sennur Ulukus"], "title": "Multi-Agent Distributed Optimization With Feasible Set Privacy", "comment": null, "summary": "We consider the problem of decentralized constrained optimization with\nmultiple agents $E_1,\\ldots,E_N$ who jointly wish to learn the optimal solution\nset while keeping their feasible sets $\\mathcal{P}_1,\\ldots,\\mathcal{P}_N$\nprivate from each other. We assume that the objective function $f$ is known to\nall agents and each feasible set is a collection of points from a universal\nalphabet $\\mathcal{P}_{alph}$. A designated agent (leader) starts the\ncommunication with the remaining (non-leader) agents, and is the first to\nretrieve the solution set. The leader searches for the solution by sending\nqueries to and receiving answers from the non-leaders, such that the\ninformation on the individual feasible sets revealed to the leader should be no\nmore than nominal, i.e., what is revealed from learning the solution set alone.\nWe develop achievable schemes for obtaining the solution set at nominal\ninformation leakage, and characterize their communication costs under two\ncommunication setups between agents. In this work, we focus on two kinds of\nnetwork setups: i) ring, where each agent communicates with two adjacent\nagents, and ii) star, where only the leader communicates with the remaining\nagents. We show that, if the leader first learns the joint feasible set through\nan existing private set intersection (PSI) protocol and then deduces the\nsolution set, the information leaked to the leader is greater than nominal.\nMoreover, we draw connection of our schemes to threshold PSI (ThPSI), which is\na PSI-variant where the intersection is revealed only when its cardinality is\nlarger than a threshold value. Finally, for various realizations of $f$ mapped\nuniformly at random to a fixed range of values, our schemes are more\ncommunication-efficient with a high probability compared to retrieving the\nentire feasible set through PSI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5728\u4fdd\u6301\u5404\u81ea\u53ef\u884c\u96c6\u9690\u79c1\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u65b9\u5f0f\u8054\u5408\u5b66\u4e60\u6700\u4f18\u89e3\u96c6\u7684\u95ee\u9898\u3002\u63d0\u51fa\u5728\u73af\u72b6\u548c\u661f\u72b6\u7f51\u7edc\u62d3\u6251\u4e0b\uff0c\u5b9e\u73b0\u540d\u4e49\u4fe1\u606f\u6cc4\u9732\u7684\u53ef\u884c\u65b9\u6848\uff0c\u5e76\u5206\u6790\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u8054\u5408\u4f18\u5316\u65f6\u65e2\u8981\u5b66\u4e60\u6700\u4f18\u89e3\u96c6\uff0c\u53c8\u8981\u4fdd\u62a4\u5404\u81ea\u53ef\u884c\u96c6\u9690\u79c1\u7684\u6311\u6218\u3002\u907f\u514d\u76f4\u63a5\u4f7f\u7528\u79c1\u6709\u96c6\u5408\u4ea4\u96c6\u534f\u8bae\u5bfc\u81f4\u7684\u4fe1\u606f\u6cc4\u9732\u8d85\u51fa\u540d\u4e49\u503c\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u9886\u5bfc-\u975e\u9886\u5bfc\u667a\u80fd\u4f53\u901a\u4fe1\u534f\u8bae\uff0c\u9886\u5bfc\u901a\u8fc7\u67e5\u8be2-\u5e94\u7b54\u65b9\u5f0f\u641c\u7d22\u89e3\u96c6\u3002\u5728\u73af\u72b6\u548c\u661f\u72b6\u7f51\u7edc\u62d3\u6251\u4e0b\u5b9e\u73b0\u65b9\u6848\uff0c\u5e76\u4e0e\u9608\u503c\u79c1\u6709\u96c6\u5408\u4ea4\u96c6\u534f\u8bae\u5efa\u7acb\u8054\u7cfb\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6848\u80fd\u5728\u540d\u4e49\u4fe1\u606f\u6cc4\u9732\u4e0b\u83b7\u5f97\u89e3\u96c6\uff0c\u4e14\u5bf9\u4e8e\u968f\u673a\u6620\u5c04\u7684\u76ee\u6807\u51fd\u6570\uff0c\u76f8\u6bd4\u76f4\u63a5\u4f7f\u7528PSI\u68c0\u7d22\u6574\u4e2a\u53ef\u884c\u96c6\uff0c\u901a\u4fe1\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u901a\u4fe1\u6548\u7387\u7684\u63d0\u5347\uff0c\u5e76\u4e0e\u73b0\u6709PSI\u53d8\u4f53\u5efa\u7acb\u4e86\u7406\u8bba\u8054\u7cfb\u3002"}}
{"id": "2510.03829", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03829", "abs": "https://arxiv.org/abs/2510.03829", "authors": ["Andr\u00e9 Coelho", "Pedro Ribeiro", "Helder Fontes", "Rui Campos"], "title": "A4FN: an Agentic AI Architecture for Autonomous Flying Networks", "comment": "This paper has been accepted for presentation in the Auto ML for\n  Zero-Touch Network Management Workshop (WS04-01) at the IEEE International\n  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC) 2025", "summary": "This position paper presents A4FN, an Agentic Artificial Intelligence (AI)\narchitecture for intent-driven automation in Flying Networks (FNs) using\nUnmanned Aerial Vehicles (UAVs) as access nodes. A4FN leverages Generative AI\nand Large Language Models (LLMs) to enable real-time, context-aware network\ncontrol via a distributed agentic system. It comprises two components: the\nPerception Agent (PA), which semantically interprets multimodal input --\nincluding imagery, audio, and telemetry data -- from UAV-mounted sensors to\nderive Service Level Specifications (SLSs); and the Decision-and-Action Agent\n(DAA), which reconfigures the network based on inferred intents. A4FN embodies\nkey properties of Agentic AI, including autonomy, goal-driven reasoning, and\ncontinuous perception-action cycles. Designed for mission-critical,\ninfrastructure-limited scenarios such as disaster response, it supports\nadaptive reconfiguration, dynamic resource management, and interoperability\nwith emerging wireless technologies. The paper details the A4FN architecture,\nits core innovations, and open research challenges in multi-agent coordination\nand Agentic AI integration in next-generation FNs.", "AI": {"tldr": "A4FN\u662f\u4e00\u4e2a\u57fa\u4e8eAgentic AI\u7684\u65e0\u4eba\u673a\u7f51\u7edc\u67b6\u6784\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u548cLLM\u5b9e\u73b0\u610f\u56fe\u9a71\u52a8\u7684\u5b9e\u65f6\u7f51\u7edc\u81ea\u52a8\u5316\u63a7\u5236\uff0c\u5305\u542b\u611f\u77e5\u4ee3\u7406\u548c\u51b3\u7b56\u884c\u52a8\u4ee3\u7406\u4e24\u4e2a\u7ec4\u4ef6\u3002", "motivation": "\u9488\u5bf9\u4efb\u52a1\u5173\u952e\u578b\u3001\u57fa\u7840\u8bbe\u65bd\u6709\u9650\u7684\u573a\u666f\uff08\u5982\u707e\u5bb3\u54cd\u5e94\uff09\uff0c\u9700\u8981\u5b9e\u73b0\u5b9e\u65f6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7f51\u7edc\u63a7\u5236\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u52a8\u6001\u91cd\u6784\u548c\u8d44\u6e90\u7ba1\u7406\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0fAgentic\u7cfb\u7edf\uff0c\u5305\u542b\u611f\u77e5\u4ee3\u7406\uff08\u901a\u8fc7\u591a\u6a21\u6001\u8f93\u5165\u8bed\u4e49\u89e3\u6790\u751f\u6210\u670d\u52a1\u7b49\u7ea7\u89c4\u8303\uff09\u548c\u51b3\u7b56\u884c\u52a8\u4ee3\u7406\uff08\u57fa\u4e8e\u63a8\u65ad\u610f\u56fe\u91cd\u65b0\u914d\u7f6e\u7f51\u7edc\uff09\u3002", "result": "\u8bbe\u8ba1\u4e86\u5177\u5907\u81ea\u4e3b\u6027\u3001\u76ee\u6807\u9a71\u52a8\u63a8\u7406\u548c\u8fde\u7eed\u611f\u77e5-\u884c\u52a8\u5faa\u73af\u7b49Agentic AI\u5173\u952e\u7279\u6027\u7684\u67b6\u6784\uff0c\u652f\u6301\u81ea\u9002\u5e94\u91cd\u6784\u3001\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u548c\u65b0\u5174\u65e0\u7ebf\u6280\u672f\u4e92\u64cd\u4f5c\u6027\u3002", "conclusion": "A4FN\u4e3a\u4e0b\u4e00\u4ee3\u98de\u884c\u7f51\u7edc\u4e2d\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548cAgentic AI\u96c6\u6210\u63d0\u4f9b\u4e86\u521b\u65b0\u67b6\u6784\uff0c\u4f46\u4ecd\u9762\u4e34\u76f8\u5173\u7814\u7a76\u6311\u6218\u3002"}}
{"id": "2510.03485", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.03485", "abs": "https://arxiv.org/abs/2510.03485", "authors": ["Xiaofei Wen", "Wenjie Jacky Mo", "Yanan Xie", "Peng Qi", "Muhao Chen"], "title": "Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection", "comment": "16 pages, 5 figures", "summary": "Autonomous web agents need to operate under externally imposed or\nhuman-specified policies while generating long-horizon trajectories. However,\nlittle work has examined whether these trajectories comply with such policies,\nor whether policy violations persist across different contexts such as domains\n(e.g., shopping or coding websites) and subdomains (e.g., product search and\norder management in shopping). To address this gap, we introduce\nPolicyGuardBench, a benchmark of about 60k examples for detecting policy\nviolations in agent trajectories. From diverse agent runs, we generate a broad\nset of policies and create both within subdomain and cross subdomain pairings\nwith violation labels. In addition to full-trajectory evaluation,\nPolicyGuardBench also includes a prefix-based violation detection task where\nmodels must anticipate policy violations from truncated trajectory prefixes\nrather than complete sequences. Using this dataset, we train PolicyGuard-4B, a\nlightweight guardrail model that delivers strong detection accuracy across all\ntasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes\nacross domains and preserves high accuracy on unseen settings. Together,\nPolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework\nfor studying policy compliance in web agent trajectories, and show that\naccurate and generalizable guardrails are feasible at small scales.", "AI": {"tldr": "\u63d0\u51fa\u4e86PolicyGuardBench\u57fa\u51c6\u548cPolicyGuard-4B\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u7f51\u7edc\u4ee3\u7406\u8f68\u8ff9\u4e2d\u7684\u7b56\u7565\u8fdd\u89c4\uff0c\u652f\u6301\u8de8\u57df\u6cdb\u5316\u548c\u5c0f\u89c4\u6a21\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u9700\u8981\u5728\u5916\u90e8\u7b56\u7565\u7ea6\u675f\u4e0b\u751f\u6210\u957f\u8f68\u8ff9\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u5173\u6ce8\u8fd9\u4e9b\u8f68\u8ff9\u662f\u5426\u9075\u5b88\u7b56\u7565\uff0c\u4ee5\u53ca\u8fdd\u89c4\u884c\u4e3a\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u7684\u6301\u7eed\u6027\u3002", "method": "\u4ece\u591a\u6837\u5316\u4ee3\u7406\u8fd0\u884c\u4e2d\u751f\u6210\u5e7f\u6cdb\u7b56\u7565\u96c6\uff0c\u521b\u5efa\u7ea660k\u4e2a\u5e26\u8fdd\u89c4\u6807\u7b7e\u7684\u793a\u4f8b\uff0c\u5305\u62ec\u5b50\u57df\u5185\u548c\u8de8\u5b50\u57df\u914d\u5bf9\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u524d\u7f00\u7684\u8fdd\u89c4\u68c0\u6d4b\u4efb\u52a1\u3002", "result": "\u8bad\u7ec3\u7684PolicyGuard-4B\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u5f3a\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u80fd\u8de8\u57df\u6cdb\u5316\u5e76\u5728\u672a\u89c1\u8fc7\u7684\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "PolicyGuardBench\u548cPolicyGuard-4B\u4e3a\u7814\u7a76\u7f51\u7edc\u4ee3\u7406\u8f68\u8ff9\u7684\u7b56\u7565\u5408\u89c4\u6027\u63d0\u4f9b\u4e86\u9996\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u8bc1\u660e\u5c0f\u89c4\u6a21\u4e0b\u53ef\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u6cdb\u5316\u7684\u62a4\u680f\u673a\u5236\u3002"}}
{"id": "2510.04488", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.4"], "pdf": "https://arxiv.org/pdf/2510.04488", "abs": "https://arxiv.org/abs/2510.04488", "authors": ["Edward Y. Chang", "Ethan Y. Chang"], "title": "Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning", "comment": "27 pages, 5 figures, 21 tables", "summary": "Multi-agent debate often wastes compute by using a fixed adversarial stance,\naggregating without deliberation, or stopping on heuristics. We introduce MACI,\nan active controller with two independent dials that decouple information from\nbehavior: an information dial that gates evidence by quality, and a behavior\ndial that schedules contentiousness from exploration to consolidation. A\nmoderator tracks disagreement, overlap, evidence quality, and argument quality,\nand halts when gains plateau. We provide theory-lite guarantees for\nnonincreasing dispersion and provable termination, with a budget-feasible\nscheduler. Across clinical diagnosis and news-bias tasks, MACI improves\naccuracy and calibration while reducing tokens, and converts residual\nuncertainty into precision RAG plans that specify what to retrieve next. We use\na cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,\nvalidated for order invariance and judge-swap stability; stability depends on\nusing high-capability judges. MACI turns debate into a budget-aware,\nmeasurable, and provably terminating controller.", "AI": {"tldr": "MACI\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u4fe1\u606f\u8d28\u91cf\u95e8\u63a7\u548c\u884c\u4e3a\u8c03\u5ea6\u673a\u5236\uff0c\u5c06\u8fa9\u8bba\u8f6c\u5316\u4e3a\u53ef\u9884\u7b97\u3001\u53ef\u6d4b\u91cf\u4e14\u53ef\u8bc1\u660e\u7ec8\u6b62\u7684\u8fc7\u7a0b\uff0c\u5728\u4e34\u5e8a\u8bca\u65ad\u548c\u65b0\u95fb\u504f\u89c1\u4efb\u52a1\u4e2d\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11token\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u5b58\u5728\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\uff0c\u5305\u62ec\u56fa\u5b9a\u5bf9\u6297\u7acb\u573a\u3001\u65e0\u6df1\u601d\u719f\u8651\u7684\u805a\u5408\u6216\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u505c\u6b62\u673a\u5236\u3002", "method": "MACI\u91c7\u7528\u53cc\u72ec\u7acb\u8c03\u8282\u673a\u5236\uff1a\u4fe1\u606f\u8c03\u8282\u5668\u6309\u8d28\u91cf\u95e8\u63a7\u8bc1\u636e\uff0c\u884c\u4e3a\u8c03\u8282\u5668\u4ece\u63a2\u7d22\u5230\u6574\u5408\u8c03\u5ea6\u4e89\u8bae\u6027\u3002\u4f7f\u7528\u8de8\u5bb6\u65cfLLM\u8bc4\u5224\u5668\u4f5c\u4e3a\u4fdd\u5b88\u8f6f\u6743\u91cd\u548c\u505c\u6b62\u4fe1\u53f7\u3002", "result": "\u5728\u4e34\u5e8a\u8bca\u65ad\u548c\u65b0\u95fb\u504f\u89c1\u4efb\u52a1\u4e2d\uff0cMACI\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11\u4e86token\u4f7f\u7528\uff0c\u5e76\u5c06\u5269\u4f59\u4e0d\u786e\u5b9a\u6027\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684RAG\u8ba1\u5212\u3002", "conclusion": "MACI\u5c06\u8fa9\u8bba\u8f6c\u5316\u4e3a\u9884\u7b97\u611f\u77e5\u3001\u53ef\u6d4b\u91cf\u4e14\u53ef\u8bc1\u660e\u7ec8\u6b62\u7684\u63a7\u5236\u5668\uff0c\u5177\u6709\u975e\u9012\u589e\u5206\u6563\u6027\u548c\u53ef\u8bc1\u660e\u7ec8\u6b62\u7684\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2510.04035", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04035", "abs": "https://arxiv.org/abs/2510.04035", "authors": ["Almamoon Alauthman", "Abeer Al-Hyari"], "title": "Analysis of LTE/5G Network Performance Parameters in Smartphone Use Cases: A Study of Packet Loss, Delay, and Slice Types", "comment": null, "summary": "The paper addresses optimizing two of the most important performance\nparameters, packet loss, and delay, in the critical path optimization of LTE\nand 5G networks using metaheuristic algorithms to play a vital role in the\nsmartphone user experience. In this context, nine metaheuristic algorithms,\nsuch as WOA, PSO, and ABC, have been studied for their effectiveness in various\nslices of networks: eMBB, URLLC, and mMTC. It can be seen from the results that\nWOA performed the best: it reduced packet loss by 31% and delay by 6.3 ms; PSO\nfollowed closely with a 30% packet loss reduction with a decrease of 6.1 ms in\ndelay. In most scenarios, ABC accomplished good results with a packet loss\nreduction of 29% and a delay decrease of 6 ms in mMTC scenarios. These results\nemphasize how selecting appropriate algorithms based on the intended network\nslice is crucial for optimizing resource utilization and network efficiency. It\nprovides a quantitative framework for assessing and improving the reliability\nand responsiveness of an LTE/5G network. It encourages more research in hybrid\noptimization techniques and real-time adaptation mechanisms for further\nimprovements", "AI": {"tldr": "\u8be5\u8bba\u6587\u4f7f\u7528\u4e5d\u79cd\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u4f18\u5316LTE\u548c5G\u7f51\u7edc\u4e2d\u7684\u4e22\u5305\u7387\u548c\u5ef6\u8fdf\uff0cWOA\u7b97\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u5728eMBB\u3001URLLC\u548cmMTC\u7f51\u7edc\u5207\u7247\u4e2d\u5206\u522b\u51cf\u5c1131%\u4e22\u5305\u548c6.3ms\u5ef6\u8fdf\u3002", "motivation": "\u4f18\u5316LTE\u548c5G\u7f51\u7edc\u5173\u952e\u8def\u5f84\u4e2d\u7684\u4e22\u5305\u7387\u548c\u5ef6\u8fdf\u8fd9\u4e24\u4e2a\u91cd\u8981\u6027\u80fd\u53c2\u6570\uff0c\u4ee5\u63d0\u5347\u667a\u80fd\u624b\u673a\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u7814\u7a76\u4e5d\u79cd\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff08\u5305\u62ecWOA\u3001PSO\u3001ABC\u7b49\uff09\u5728eMBB\u3001URLLC\u548cmMTC\u7f51\u7edc\u5207\u7247\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "WOA\u8868\u73b0\u6700\u4f73\uff1a\u51cf\u5c1131%\u4e22\u5305\u548c6.3ms\u5ef6\u8fdf\uff1bPSO\u6b21\u4e4b\uff1a\u51cf\u5c1130%\u4e22\u5305\u548c6.1ms\u5ef6\u8fdf\uff1bABC\u5728mMTC\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\uff1a\u51cf\u5c1129%\u4e22\u5305\u548c6ms\u5ef6\u8fdf\u3002", "conclusion": "\u6839\u636e\u76ee\u6807\u7f51\u7edc\u5207\u7247\u9009\u62e9\u5408\u9002\u7684\u7b97\u6cd5\u5bf9\u4e8e\u4f18\u5316\u8d44\u6e90\u5229\u7528\u548c\u7f51\u7edc\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLTE/5G\u7f51\u7edc\u53ef\u9760\u6027\u548c\u54cd\u5e94\u6027\u63d0\u4f9b\u4e86\u91cf\u5316\u6846\u67b6\u3002"}}
{"id": "2510.03506", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03506", "abs": "https://arxiv.org/abs/2510.03506", "authors": ["John Nguyen", "Marton Havasi", "Tariq Berrada", "Luke Zettlemoyer", "Ricky T. Q. Chen"], "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows", "comment": "https://johnlnguyen.com/oneflow", "summary": "We present OneFlow, the first non-autoregressive multimodal model that\nenables variable-length and concurrent mixed-modal generation. Unlike\nautoregressive models that enforce rigid causal ordering between text and image\ngeneration, OneFlow combines an insertion-based Edit Flow for discrete text\ntokens with Flow Matching for image latents. OneFlow enables concurrent\ntext-image synthesis with hierarchical sampling that prioritizes content over\ngrammar. Through controlled experiments across model sizes from 1B to 8B, we\ndemonstrate that OneFlow outperforms autoregressive baselines on both\ngeneration and understanding tasks while using up to 50% fewer training FLOPs.\nOneFlow surpasses both autoregressive and diffusion-based approaches while\nunlocking new capabilities for concurrent generation, iterative refinement, and\nnatural reasoning-like generation.", "AI": {"tldr": "OneFlow\u662f\u9996\u4e2a\u975e\u81ea\u56de\u5f52\u591a\u6a21\u6001\u6a21\u578b\uff0c\u652f\u6301\u53ef\u53d8\u957f\u5ea6\u548c\u5e76\u53d1\u6df7\u5408\u6a21\u6001\u751f\u6210\uff0c\u901a\u8fc7\u63d2\u5165\u5f0f\u7f16\u8f91\u6d41\u548c\u6d41\u5339\u914d\u6280\u672f\u5b9e\u73b0\u6587\u672c\u56fe\u50cf\u5e76\u53d1\u5408\u6210\uff0c\u5728\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u4f18\u4e8e\u81ea\u56de\u5f52\u57fa\u7ebf\uff0c\u8bad\u7ec3FLOPs\u51cf\u5c1150%\u3002", "motivation": "\u89e3\u51b3\u81ea\u56de\u5f52\u6a21\u578b\u5728\u6587\u672c\u548c\u56fe\u50cf\u751f\u6210\u4e4b\u95f4\u5f3a\u5236\u56e0\u679c\u987a\u5e8f\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u5e76\u53d1\u591a\u6a21\u6001\u751f\u6210\u3002", "method": "\u7ed3\u5408\u63d2\u5165\u5f0f\u7f16\u8f91\u6d41\u5904\u7406\u79bb\u6563\u6587\u672c\u6807\u8bb0\uff0c\u4f7f\u7528\u6d41\u5339\u914d\u5904\u7406\u56fe\u50cf\u6f5c\u5728\u8868\u793a\uff0c\u91c7\u7528\u5206\u5c42\u91c7\u6837\u4f18\u5148\u5185\u5bb9\u800c\u975e\u8bed\u6cd5\u3002", "result": "\u57281B\u52308B\u6a21\u578b\u89c4\u6a21\u4e0a\uff0cOneFlow\u5728\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u81ea\u56de\u5f52\u57fa\u7ebf\uff0c\u8bad\u7ec3FLOPs\u51cf\u5c11\u9ad8\u8fbe50%\uff0c\u8d85\u8d8a\u4e86\u81ea\u56de\u5f52\u548c\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u3002", "conclusion": "OneFlow\u89e3\u9501\u4e86\u5e76\u53d1\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u7c7b\u81ea\u7136\u63a8\u7406\u751f\u6210\u7b49\u65b0\u80fd\u529b\uff0c\u4e3a\u975e\u81ea\u56de\u5f52\u591a\u6a21\u6001\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04052", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04052", "abs": "https://arxiv.org/abs/2510.04052", "authors": ["Behrooz Farkiani", "Fan Liu", "Patrick Crowley"], "title": "The Door to Policy Portability might be an IP Overlay", "comment": null, "summary": "Portable service mesh implementations enable layer 4 to layer 7 policy\nenforcement across diverse infrastructures, but they remain tied to\ninfrastructure-specific layer 3 network policies. Network policies enable\ncontrol over IP traffic flow regardless of whether traffic is authorized at the\napplication level. However, not all infrastructure supports enforcing them, and\nachieving consistent enforcement across heterogeneous environments is\nchallenging. For example, studies have shown that the majority of Kubernetes\nclusters do not enforce any network policies. We propose integrating network\npolicy enforcement with service meshes to protect data-plane traffic in a\nportable, infrastructure-agnostic way. This enables developers to define\nintegrated layer 3 to layer 7 policies and ensure they are enforced across any\ninfrastructure. Additionally, due to its portability, our approach can be used\noutside the service environment to enforce policies on end-user traffic and\nprovide an end-to-end secure extended overlay. Our solution builds an overlay\nlayer 3 network and enforces layer 3 policies by routing traffic through\nspecific policy enforcement points and utilizing authorization keys. We\nprototyped our idea using Kubernetes and Istio, and show that while it adds\nless than 1ms latency, it can implement complex policies comparable to\nKubernetes native network policies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5c06\u7f51\u7edc\u7b56\u7565\u4e0e\u670d\u52a1\u7f51\u683c\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u5728\u53ef\u79fb\u690d\u7684\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u65b9\u5f0f\u4e0b\u4fdd\u62a4\u6570\u636e\u5e73\u9762\u6d41\u91cf\uff0c\u5b9e\u73b0\u4ece\u7b2c3\u5c42\u5230\u7b2c7\u5c42\u7684\u7edf\u4e00\u7b56\u7565\u6267\u884c\u3002", "motivation": "\u5f53\u524d\u4fbf\u643a\u5f0f\u670d\u52a1\u7f51\u683c\u867d\u7136\u652f\u6301\u7b2c4\u5c42\u5230\u7b2c7\u5c42\u7b56\u7565\u6267\u884c\uff0c\u4f46\u4ecd\u4f9d\u8d56\u4e8e\u57fa\u7840\u8bbe\u65bd\u7279\u5b9a\u7684\u7b2c3\u5c42\u7f51\u7edc\u7b56\u7565\u3002\u5927\u591a\u6570Kubernetes\u96c6\u7fa4\u672a\u5f3a\u5236\u6267\u884c\u7f51\u7edc\u7b56\u7565\uff0c\u4e14\u8de8\u5f02\u6784\u73af\u5883\u5b9e\u73b0\u4e00\u81f4\u6267\u884c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u6784\u5efa\u8986\u76d6\u5c42\u7b2c3\u5c42\u7f51\u7edc\uff0c\u901a\u8fc7\u5c06\u6d41\u91cf\u8def\u7531\u5230\u7279\u5b9a\u7b56\u7565\u6267\u884c\u70b9\u5e76\u4f7f\u7528\u6388\u6743\u5bc6\u94a5\u6765\u5f3a\u5236\u6267\u884c\u7b2c3\u5c42\u7b56\u7565\u3002\u4f7f\u7528Kubernetes\u548cIstio\u8fdb\u884c\u539f\u578b\u5b9e\u73b0\u3002", "result": "\u5728Kubernetes\u548cIstio\u4e0a\u7684\u539f\u578b\u5b9e\u73b0\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u589e\u52a0\u5ef6\u8fdf\u5c0f\u4e8e1\u6beb\u79d2\uff0c\u80fd\u591f\u5b9e\u73b0\u4e0eKubernetes\u539f\u751f\u7f51\u7edc\u7b56\u7565\u76f8\u5f53\u7684\u590d\u6742\u7b56\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u7840\u8bbe\u65bd\u65e0\u5173\u7684\u7b2c3\u5c42\u5230\u7b2c7\u5c42\u7b56\u7565\u96c6\u6210\u6267\u884c\uff0c\u5177\u6709\u53ef\u79fb\u690d\u6027\uff0c\u53ef\u5728\u670d\u52a1\u73af\u5883\u5916\u7528\u4e8e\u7ec8\u7aef\u7528\u6237\u6d41\u91cf\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u5b89\u5168\u6269\u5c55\u8986\u76d6\u3002"}}
{"id": "2510.03605", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.03605", "abs": "https://arxiv.org/abs/2510.03605", "authors": ["Adel Javanmard", "Baharan Mirzasoleiman", "Vahab Mirrokni"], "title": "Understanding the Role of Training Data in Test-Time Scaling", "comment": "24 pages, 4 figures", "summary": "Test-time scaling improves the reasoning capabilities of large language\nmodels (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts\n(CoTs). This enables models to tackle more complex problem by breaking them\ndown into additional steps, backtracking, and correcting mistakes. Despite its\nstrong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions\nin the training data under which long CoTs emerge, and when such long CoTs\nimprove the performance, remain unclear. In this paper, we study the\nperformance of test-time scaling for transformers trained on an in-context\nweight prediction task for linear regression. Our analysis provides a\ntheoretical explanation for several intriguing observations: First, at any\nfixed test error, increasing test-time compute allows us to reduce the number\nof in-context examples (context length) in training prompts. Second, if the\nskills required to solve a downstream task are not sufficiently present in the\ntraining data, increasing test-time compute can harm performance. Finally, we\ncharacterize task hardness via the smallest eigenvalue of its feature\ncovariance matrix and show that training on a diverse, relevant, and hard set\nof tasks results in best performance for test-time scaling. We confirm our\nfindings with experiments on large, nonlinear transformer architectures.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6d4b\u8bd5\u65f6\u6269\u5c55\uff08test-time scaling\uff09\u5bf9Transformer\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u4ee5\u964d\u4f4e\u8bad\u7ec3\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u4f46\u524d\u63d0\u662f\u8bad\u7ec3\u6570\u636e\u5305\u542b\u8db3\u591f\u7684\u76f8\u5173\u6280\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u6d4b\u8bd5\u65f6\u6269\u5c55\u901a\u8fc7\u751f\u6210\u957f\u601d\u7ef4\u94fe\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u957f\u601d\u7ef4\u94fe\u5728\u4ec0\u4e48\u8bad\u7ec3\u6761\u4ef6\u4e0b\u51fa\u73b0\u4ee5\u53ca\u4f55\u65f6\u80fd\u63d0\u5347\u6027\u80fd\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e0a\u89e3\u91ca\u8fd9\u4e9b\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5728\u4e0a\u4e0b\u6587\u6743\u91cd\u9884\u6d4b\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7684Transformer\u6a21\u578b\uff0c\u4f7f\u7528\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u6d4b\u8bd5\u65f6\u6269\u5c55\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u5728\u56fa\u5b9a\u6d4b\u8bd5\u8bef\u5dee\u4e0b\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u63d0\u793a\u4e2d\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff1b2\uff09\u5982\u679c\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\u89e3\u51b3\u4e0b\u6e38\u4efb\u52a1\u6240\u9700\u7684\u6280\u80fd\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53cd\u800c\u4f1a\u635f\u5bb3\u6027\u80fd\uff1b3\uff09\u4efb\u52a1\u96be\u5ea6\u53ef\u4ee5\u901a\u8fc7\u7279\u5f81\u534f\u65b9\u5dee\u77e9\u9635\u7684\u6700\u5c0f\u7279\u5f81\u503c\u6765\u8868\u5f81\u3002", "conclusion": "\u8bad\u7ec3\u6570\u636e\u9700\u8981\u5305\u542b\u591a\u6837\u5316\u3001\u76f8\u5173\u4e14\u5177\u6709\u4e00\u5b9a\u96be\u5ea6\u7684\u4efb\u52a1\u96c6\u5408\uff0c\u624d\u80fd\u6700\u5927\u5316\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u6548\u679c\u3002\u8fd9\u4e00\u53d1\u73b0\u5728\u5927\u578b\u975e\u7ebf\u6027Transformer\u67b6\u6784\u7684\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2510.04183", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04183", "abs": "https://arxiv.org/abs/2510.04183", "authors": ["Lucas Pacheco", "Torsten Braun", "Kaushik Chowdhury", "Denis Ros\u00e1rio", "Batool Salehi", "Eduardo Cerqueira"], "title": "Dynamic Adaptive Federated Learning for mmWave Sector Selection", "comment": null, "summary": "Beamforming techniques use massive antenna arrays to formulate narrow\nLine-of-Sight signal sectors to address the increased signal attenuation in\nmillimeter Wave (mmWave). However, traditional sector selection schemes involve\nextensive searches for the highest signal-strength sector, introducing extra\nlatency and communication overhead. This paper introduces a dynamic layer-wise\nand clustering-based federated learning (FL) algorithm for beam sector\nselection in autonomous vehicle networks called enhanced Dynamic Adaptive FL\n(eDAFL). The algorithm detects and selects the most important layers of a\nmachine learning model for aggregation in the FL process, significantly\nreducing network overhead and failure risks. eDAFL also considers intra-cluster\nand inter-cluster approaches to reduce overfitting and increase the abstraction\nlevel. We evaluate eDAFL on a real-world multi-modal dataset, demonstrating\nimproved model accuracy by approximately 6.76% compared to existing methods,\nwhile reducing inference time by 84.04% and model size by up to 52.20%.", "AI": {"tldr": "\u63d0\u51faeDAFL\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u5c42\u548c\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u8f66\u8054\u7f51\u6ce2\u675f\u9009\u62e9\uff0c\u663e\u8457\u964d\u4f4e\u7f51\u7edc\u5f00\u9500\u548c\u5ef6\u8fdf", "motivation": "\u4f20\u7edf\u6ce2\u675f\u9009\u62e9\u65b9\u6848\u9700\u8981\u5927\u91cf\u641c\u7d22\u6700\u9ad8\u4fe1\u53f7\u5f3a\u5ea6\u6247\u533a\uff0c\u5bfc\u81f4\u989d\u5916\u5ef6\u8fdf\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528\u52a8\u6001\u5206\u5c42\u548c\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\uff0c\u68c0\u6d4b\u5e76\u9009\u62e9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u6700\u91cd\u8981\u5c42\u8fdb\u884c\u805a\u5408\uff0c\u8003\u8651\u96c6\u7fa4\u5185\u548c\u96c6\u7fa4\u95f4\u65b9\u6cd5\u51cf\u5c11\u8fc7\u62df\u5408", "result": "\u5728\u771f\u5b9e\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u6a21\u578b\u7cbe\u5ea6\u63d0\u5347\u7ea66.76%\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c1184.04%\uff0c\u6a21\u578b\u5927\u5c0f\u6700\u591a\u51cf\u5c1152.20%", "conclusion": "eDAFL\u7b97\u6cd5\u5728\u6ce2\u675f\u9009\u62e9\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8d44\u6e90\u6d88\u8017"}}
{"id": "2510.03612", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03612", "abs": "https://arxiv.org/abs/2510.03612", "authors": ["Tanqiu Jiang", "Min Bai", "Nikolaos Pappas", "Yanjun Qi", "Sandesh Swamy"], "title": "Cross-Modal Content Optimization for Steering Web Agent Preferences", "comment": null, "summary": "Vision-language model (VLM)-based web agents increasingly power high-stakes\nselection tasks like content recommendation or product ranking by combining\nmultimodal perception with preference reasoning. Recent studies reveal that\nthese agents are vulnerable against attackers who can bias selection outcomes\nthrough preference manipulations using adversarial pop-ups, image\nperturbations, or content tweaks. Existing work, however, either assumes strong\nwhite-box access, with limited single-modal perturbations, or uses impractical\nsettings. In this paper, we demonstrate, for the first time, that joint\nexploitation of visual and textual channels yields significantly more powerful\npreference manipulations under realistic attacker capabilities. We introduce\nCross-Modal Preference Steering (CPS) that jointly optimizes imperceptible\nmodifications to an item's visual and natural language descriptions, exploiting\nCLIP-transferable image perturbations and RLHF-induced linguistic biases to\nsteer agent decisions. In contrast to prior studies that assume gradient\naccess, or control over webpages, or agent memory, we adopt a realistic\nblack-box threat setup: a non-privileged adversary can edit only their own\nlisting's images and textual metadata, with no insight into the agent's model\ninternals. We evaluate CPS on agents powered by state-of-the-art proprietary\nand open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both\nmovie selection and e-commerce tasks. Our results show that CPS is\nsignificantly more effective than leading baseline methods. For instance, our\nresults show that CPS consistently outperforms baselines across all models\nwhile maintaining 70% lower detection rates, demonstrating both effectiveness\nand stealth. These findings highlight an urgent need for robust defenses as\nagentic systems play an increasingly consequential role in society.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u8de8\u6a21\u6001\u504f\u597d\u5f15\u5bfc\uff08CPS\uff09\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u89c6\u89c9\u548c\u6587\u672c\u901a\u9053\u7684\u4e0d\u53ef\u5bdf\u89c9\u4fee\u6539\uff0c\u5728\u73b0\u5b9e\u9ed1\u76d2\u5a01\u80c1\u8bbe\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u5bf9VLM\u4ee3\u7406\u7684\u504f\u597d\u64cd\u7eb5\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8981\u4e48\u5047\u8bbe\u5f3a\u767d\u76d2\u8bbf\u95ee\uff0c\u8981\u4e48\u4f7f\u7528\u4e0d\u5207\u5b9e\u9645\u7684\u8bbe\u7f6e\uff0c\u7f3a\u4e4f\u5728\u73b0\u5b9e\u653b\u51fb\u8005\u80fd\u529b\u4e0b\u7684\u6709\u6548\u504f\u597d\u64cd\u7eb5\u65b9\u6cd5\u3002", "method": "CPS\u8054\u5408\u4f18\u5316\u7269\u54c1\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4e0d\u53ef\u5bdf\u89c9\u4fee\u6539\uff0c\u5229\u7528CLIP\u53ef\u8fc1\u79fb\u56fe\u50cf\u6270\u52a8\u548cRLHF\u8bf1\u5bfc\u7684\u8bed\u8a00\u504f\u89c1\u6765\u5f15\u5bfc\u4ee3\u7406\u51b3\u7b56\u3002", "result": "\u5728GPT-4.1\u3001Qwen-2.5VL\u548cPixtral-Large\u7b49\u5148\u8fdbVLM\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cCPS\u5728\u6240\u6709\u6a21\u578b\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u630170%\u66f4\u4f4e\u7684\u68c0\u6d4b\u7387\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u968f\u7740\u667a\u80fd\u7cfb\u7edf\u5728\u793e\u4f1a\u4e2d\u626e\u6f14\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\uff0c\u8feb\u5207\u9700\u8981\u5f00\u53d1\u9c81\u68d2\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2510.04346", "categories": ["cs.NI", "cs.LG", "cs.NA", "eess.SP", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.04346", "abs": "https://arxiv.org/abs/2510.04346", "authors": ["Nahshon Mokua Obiri", "Kristof Van Laerhoven"], "title": "Environment-Aware Indoor LoRaWAN Path Loss: Parametric Regression Comparisons, Shadow Fading, and Calibrated Fade Margins", "comment": "Code: https://github.com/nahshonmokua/LoRaWAN-Indoor-PL-parametrics", "summary": "Indoor LoRaWAN propagation is shaped by structural and time-varying context\nfactors, which challenge log-distance models and the assumption of log-normal\nshadowing. We present an environment-aware, statistically disciplined path loss\nframework evaluated using leakage-safe cross-validation on a 12-month campaign\nin an eighth-floor office measuring 240 m^2. A log-distance multi-wall mean is\naugmented with environmental covariates (relative humidity, temperature, carbon\ndioxide, particulate matter, and barometric pressure), as well as the\nsignal-to-noise ratio. We compare multiple linear regression with regularized\nvariants, Bayesian linear regression, and a selective second-order polynomial\napplied to continuous drivers. Predictor relevance is established using\nheteroscedasticity-robust Type II and III analysis of variance and nested\npartial F tests. Shadow fading is profiled with kernel density estimation and\nnon-parametric families, including Normal, Skew-Normal, Student's t, and\nGaussian mixtures. The polynomial mean reduces cross-validated RMSE from 8.07\nto 7.09 dB and raises R^2 from 0.81 to 0.86. Out-of-fold residuals are\nnon-Gaussian; a 3-component mixture captures a sharp core with a light, broad\ntail. We convert accuracy into reliability by prescribing the fade margin as\nthe upper-tail quantile of cross-validated residuals, quantifying uncertainty\nvia a moving-block bootstrap, and validating on a held-out set. At 99% packet\ndelivery ratio, the environment-aware polynomial requires 25.7 dB versus 27.7\nto 27.9 dB for linear baselines. This result presents a deployment-ready,\ninterpretable workflow with calibrated reliability control for indoor Internet\nof Things planning, aligned with 6G targets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u73af\u5883\u611f\u77e5\u7684\u5ba4\u5185LoRaWAN\u8def\u5f84\u635f\u8017\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u56de\u5f52\u548c\u73af\u5883\u534f\u53d8\u91cf\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u4f7f\u7528\u6df7\u5408\u5206\u5e03\u5efa\u6a21\u9634\u5f71\u8870\u843d\uff0c\u5b9e\u73b0\u4e8699%\u5305\u4f20\u8f93\u7387\u4e0b\u66f4\u4f4e\u7684\u8870\u843d\u4f59\u91cf\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u5bf9\u6570\u8ddd\u79bb\u6a21\u578b\u548c\u6b63\u6001\u9634\u5f71\u8870\u843d\u5047\u8bbe\u5728\u5ba4\u5185\u73af\u5883\u4e2d\u53d7\u5230\u7ed3\u6784\u548c\u65f6\u53d8\u73af\u5883\u56e0\u7d20\u7684\u5f71\u54cd\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u786e\u7684\u73af\u5883\u611f\u77e5\u8def\u5f84\u635f\u8017\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u591a\u9879\u5f0f\u56de\u5f52\u589e\u5f3a\u5bf9\u6570\u8ddd\u79bb\u591a\u5899\u6a21\u578b\uff0c\u5f15\u5165\u73af\u5883\u534f\u53d8\u91cf\uff08\u6e7f\u5ea6\u3001\u6e29\u5ea6\u3001CO2\u7b49\uff09\uff0c\u6bd4\u8f83\u591a\u79cd\u56de\u5f52\u65b9\u6cd5\uff0c\u901a\u8fc7\u65b9\u5dee\u5206\u6790\u548c\u6838\u5bc6\u5ea6\u4f30\u8ba1\u8bc4\u4f30\u9884\u6d4b\u56e0\u5b50\u76f8\u5173\u6027\u548c\u9634\u5f71\u8870\u843d\u5206\u5e03\u3002", "result": "\u591a\u9879\u5f0f\u6a21\u578b\u5c06\u4ea4\u53c9\u9a8c\u8bc1RMSE\u4ece8.07\u964d\u81f37.09 dB\uff0cR\u00b2\u4ece0.81\u63d0\u5347\u81f30.86\u3002\u572899%\u5305\u4f20\u8f93\u7387\u4e0b\uff0c\u73af\u5883\u611f\u77e5\u591a\u9879\u5f0f\u4ec5\u970025.7 dB\u8870\u843d\u4f59\u91cf\uff0c\u800c\u7ebf\u6027\u57fa\u7ebf\u9700\u898127.7-27.9 dB\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u7a0b\u4e3a\u5ba4\u5185\u7269\u8054\u7f51\u89c4\u5212\u63d0\u4f9b\u4e86\u90e8\u7f72\u5c31\u7eea\u3001\u53ef\u89e3\u91ca\u7684\u53ef\u9760\u6027\u63a7\u5236\u65b9\u6cd5\uff0c\u7b26\u54086G\u76ee\u6807\u8981\u6c42\u3002"}}
{"id": "2510.03632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03632", "abs": "https://arxiv.org/abs/2510.03632", "authors": ["Jiaxi Li", "Yucheng Shi", "Jin Lu", "Ninghao Liu"], "title": "MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information", "comment": "18 pages", "summary": "Tree search has become as a representative framework for test-time reasoning\nwith large language models (LLMs), exemplified by methods such as\nTree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning\npaths. However, it remains difficult to provide instant and reliable\nquantitative assessments of intermediate reasoning step quality, and extensive\npath exploration is computationally costly. To address this, we propose Mutual\nInformation Tree Search (MITS), a novel framework that guides reasoning with\ninformation-theoretic principles. MITS introduces an effective scoring function\nbased on pointwise mutual information (PMI), which enables step-wise evaluation\nof reasoning paths and search tree expansion via beam search without expensive\nlook-ahead simulations, achieving superior reasoning performances while\nmaintaining computational efficiency. The framework is complemented by an\nentropy-based dynamic sampling strategy that adaptively allocates computational\nresources to uncertain reasoning steps where exploration is most beneficial.\nFor final prediction, MITS employs a weighted voting scheme that combines PMI\nscores with prediction consensus. Through comprehensive experiments on diverse\nreasoning benchmarks, MITS consistently surpasses baseline methods,\nestablishing a principled and efficient framework for LLM reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e92\u4fe1\u606f\u6811\u641c\u7d22\uff08MITS\uff09\u7684\u65b0\u6846\u67b6\uff0c\u4f7f\u7528\u70b9\u4e92\u4fe1\u606f\u8bc4\u5206\u51fd\u6570\u6765\u6307\u5bfcLLM\u63a8\u7406\uff0c\u65e0\u9700\u6602\u8d35\u7684\u524d\u77bb\u6a21\u62df\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u6811\u641c\u7d22\u65b9\u6cd5\u5728LLM\u63a8\u7406\u4e2d\u5b58\u5728\u7684\u4e24\u4e2a\u95ee\u9898\uff1a\u96be\u4ee5\u5bf9\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u5373\u65f6\u53ef\u9760\u7684\u91cf\u5316\u8bc4\u4f30\uff0c\u4ee5\u53ca\u5e7f\u6cdb\u8def\u5f84\u63a2\u7d22\u5e26\u6765\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u4f7f\u7528\u70b9\u4e92\u4fe1\u606f\uff08PMI\uff09\u4f5c\u4e3a\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u6b65\u9aa4\u8bc4\u4f30\uff0c\u901a\u8fc7beam\u641c\u7d22\u6269\u5c55\u641c\u7d22\u6811\uff0c\u91c7\u7528\u57fa\u4e8e\u71b5\u7684\u52a8\u6001\u91c7\u6837\u7b56\u7565\u81ea\u9002\u5e94\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u6700\u540e\u4f7f\u7528\u52a0\u6743\u6295\u7968\u65b9\u6848\u7ed3\u5408PMI\u5206\u6570\u548c\u9884\u6d4b\u5171\u8bc6\u8fdb\u884c\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMITS\u59cb\u7ec8\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "MITS\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u5219\u7684\u9ad8\u6548LLM\u63a8\u7406\u6846\u67b6\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.04516", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04516", "abs": "https://arxiv.org/abs/2510.04516", "authors": ["Behrooz Farkiani", "Fan Liu", "Patrick Crowley"], "title": "Rethinking HTTP API Rate Limiting: A Client-Side Approach", "comment": null, "summary": "HTTP underpins modern Internet services, and providers enforce quotas to\nregulate HTTP API traffic for scalability and reliability. When requests exceed\nquotas, clients are throttled and must retry. Server-side enforcement protects\nthe service. However, when independent clients' usage counts toward a shared\nquota, server-only controls are inefficient; clients lack visibility into\nothers' load, causing their retry attempts to potentially fail. Indeed, retry\ntiming is important since each attempt incurs costs and yields no benefit\nunless admitted. While centralized coordination could address this, practical\nlimitations have led to widespread adoption of simple client-side strategies\nlike exponential backoff. As we show, these simple strategies cause excessive\nretries and significant costs. We design adaptive client-side mechanisms\nrequiring no central control, relying only on minimal feedback. We present two\nalgorithms: ATB, an offline method deployable via service workers, and AATB,\nwhich enhances retry behavior using aggregated telemetry data. Both algorithms\ninfer system congestion to schedule retries. Through emulations with real-world\ntraces and synthetic datasets with up to 100 clients, we demonstrate that our\nalgorithms reduce HTTP 429 errors by up to 97.3% compared to exponential\nbackoff, while the modest increase in completion time is outweighed by the\nreduction in errors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9HTTP API\u914d\u989d\u9650\u5236\u4e0b\u7684\u5ba2\u6237\u7aef\u91cd\u8bd5\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65e0\u9700\u4e2d\u592e\u63a7\u5236\u7684\u81ea\u9002\u5e94\u5ba2\u6237\u7aef\u7b97\u6cd5ATB\u548cAATB\uff0c\u901a\u8fc7\u63a8\u65ad\u7cfb\u7edf\u62e5\u585e\u6765\u4f18\u5316\u91cd\u8bd5\u65f6\u673a\uff0c\u663e\u8457\u51cf\u5c11\u4e86HTTP 429\u9519\u8bef\u3002", "motivation": "\u5f53\u591a\u4e2a\u72ec\u7acb\u5ba2\u6237\u7aef\u5171\u4eab\u914d\u989d\u65f6\uff0c\u670d\u52a1\u5668\u7aef\u63a7\u5236\u6548\u7387\u4f4e\u4e0b\uff0c\u5ba2\u6237\u7aef\u7f3a\u4e4f\u5bf9\u5176\u4ed6\u5ba2\u6237\u7aef\u8d1f\u8f7d\u7684\u53ef\u89c1\u6027\uff0c\u5bfc\u81f4\u91cd\u8bd5\u5c1d\u8bd5\u53ef\u80fd\u5931\u8d25\u3002\u73b0\u6709\u7684\u7b80\u5355\u5ba2\u6237\u7aef\u7b56\u7565\uff08\u5982\u6307\u6570\u9000\u907f\uff09\u4f1a\u9020\u6210\u8fc7\u591a\u7684\u91cd\u8bd5\u548c\u663e\u8457\u6210\u672c\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u79cd\u81ea\u9002\u5e94\u5ba2\u6237\u7aef\u673a\u5236\uff1aATB\uff08\u79bb\u7ebf\u65b9\u6cd5\uff0c\u53ef\u901a\u8fc7\u670d\u52a1\u5de5\u4f5c\u8005\u90e8\u7f72\uff09\u548cAATB\uff08\u4f7f\u7528\u805a\u5408\u9065\u6d4b\u6570\u636e\u589e\u5f3a\u91cd\u8bd5\u884c\u4e3a\uff09\u3002\u4e24\u79cd\u7b97\u6cd5\u90fd\u901a\u8fc7\u63a8\u65ad\u7cfb\u7edf\u62e5\u585e\u6765\u5b89\u6392\u91cd\u8bd5\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u8f68\u8ff9\u548c\u5408\u6210\u6570\u636e\u96c6\uff08\u6700\u591a100\u4e2a\u5ba2\u6237\u7aef\uff09\u7684\u4eff\u771f\u8868\u660e\uff0c\u4e0e\u6307\u6570\u9000\u907f\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u5c06HTTP 429\u9519\u8bef\u51cf\u5c11\u4e86\u9ad8\u8fbe97.3%\uff0c\u800c\u5b8c\u6210\u65f6\u95f4\u7684\u9002\u5ea6\u589e\u52a0\u88ab\u9519\u8bef\u51cf\u5c11\u6240\u62b5\u6d88\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5ba2\u6237\u7aef\u7b97\u6cd5\u5728\u65e0\u9700\u4e2d\u592e\u63a7\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u4f9d\u8d56\u6700\u5c0f\u53cd\u9988\u5c31\u80fd\u663e\u8457\u6539\u5584HTTP\u914d\u989d\u9650\u5236\u4e0b\u7684\u91cd\u8bd5\u6548\u7387\uff0c\u51cf\u5c11\u9519\u8bef\u7387\u5e76\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.03680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03680", "abs": "https://arxiv.org/abs/2510.03680", "authors": ["Bumjun Kim", "Dongjae Jeon", "Dueun Kim", "Wonje Jeung", "Albert No"], "title": "Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs", "comment": "25 pages. Project page available\n  at~\\url{https://ai-isl.github.io/rainbow-padding}", "summary": "Diffusion large language models (dLLMs) have emerged as a promising\nalternative to autoregressive models, offering flexible generation orders and\nstrong performance on complex reasoning tasks. However, instruction-tuned dLLMs\nexhibit a critical vulnerability we term \\texttt{<eos>} overflow: as allocated\nsequence length increases, responses paradoxically become shorter, collapsing\ninto early termination or degenerating into streams of \\texttt{<eos>} tokens.\nAlthough noticed in practice, this issue has not been systematically analyzed.\nWe trace its root cause to the dual role of \\texttt{<eos>} as both termination\nand padding, which concentrates probability mass on \\texttt{<eos>} at later\npositions and propagates backward to trigger early termination. To address\nthis, we introduce Rainbow Padding, a simple remedy that replaces repeated\n\\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,\ndistributing probability mass and breaking \\texttt{<eos>} dominance.\nExperiments show that Rainbow Padding substantially improves length robustness\nand output quality, with as few as seven padding tokens sufficient to prevent\nearly termination. Moreover, the method integrates efficiently into existing\ninstruction-tuned models: LoRA fine-tuning for a single epoch on minimal data\nyields significant improvements, making this solution highly practical. The\ncode is publicly available at https://github.com/quasar529/rainbow-padding.", "AI": {"tldr": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728<eos>\u6ea2\u51fa\u95ee\u9898\uff1a\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u54cd\u5e94\u53cd\u800c\u53d8\u77ed\uff0c\u5bfc\u81f4\u63d0\u524d\u7ec8\u6b62\u6216\u9000\u5316\u4e3a<eos>\u4ee4\u724c\u6d41\u3002\u4f5c\u8005\u63d0\u51faRainbow Padding\u65b9\u6cd5\uff0c\u7528\u5faa\u73af\u7684\u4e0d\u540c\u586b\u5145\u4ee4\u724c\u66ff\u6362\u91cd\u590d\u7684<eos>\u5360\u4f4d\u7b26\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "\u6307\u4ee4\u8c03\u4f18\u7684\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u6f0f\u6d1e\uff1a<eos>\u6ea2\u51fa\u95ee\u9898\uff0c\u5373\u968f\u7740\u5206\u914d\u7684\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u54cd\u5e94\u53cd\u800c\u53d8\u5f97\u66f4\u77ed\uff0c\u5bfc\u81f4\u63d0\u524d\u7ec8\u6b62\u6216\u9000\u5316\u4e3a<eos>\u4ee4\u724c\u6d41\u3002\u867d\u7136\u5b9e\u8df5\u4e2d\u5df2\u6ce8\u610f\u5230\u6b64\u95ee\u9898\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u63d0\u51faRainbow Padding\u65b9\u6cd5\uff0c\u7528\u5faa\u73af\u7684\u4e0d\u540c\u586b\u5145\u4ee4\u724c\u66ff\u6362\u91cd\u590d\u7684<eos>\u5360\u4f4d\u7b26\uff0c\u5206\u6563\u6982\u7387\u8d28\u91cf\u5e76\u6253\u7834<eos>\u7684\u4e3b\u5bfc\u5730\u4f4d\u3002\u8be5\u65b9\u6cd5\u53ef\u9ad8\u6548\u96c6\u6210\u5230\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e2d\uff1a\u5728\u5c11\u91cf\u6570\u636e\u4e0a\u4f7f\u7528LoRA\u5fae\u8c03\u5355\u4e2aepoch\u5373\u53ef\u83b7\u5f97\u663e\u8457\u6539\u8fdb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRainbow Padding\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u5ea6\u9c81\u68d2\u6027\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u4ec5\u9700\u4e03\u4e2a\u586b\u5145\u4ee4\u724c\u5c31\u8db3\u4ee5\u9632\u6b62\u63d0\u524d\u7ec8\u6b62\u3002\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u9ad8\u5ea6\u5b9e\u7528\u6027\u3002", "conclusion": "Rainbow Padding\u662f\u89e3\u51b3\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4e2d<eos>\u6ea2\u51fa\u95ee\u9898\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u6253\u7834<eos>\u4ee4\u724c\u7684\u4e3b\u5bfc\u5730\u4f4d\u6765\u9632\u6b62\u63d0\u524d\u7ec8\u6b62\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.04620", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04620", "abs": "https://arxiv.org/abs/2510.04620", "authors": ["Siu Kei Chung", "Francisco Carpio", "Andrei Navoichyk", "Siarhei Valasovich", "Jordan Moore", "Slobodan Sudaric-Hefner", "Daniel Baker", "Thomas Demoor", "Maurizio Binello", "Christian Kaul", "Kai Wawrzinek"], "title": "Impossible Cloud Network: A Decentralized Internet Infrastructure Layer", "comment": null, "summary": "The internet faces a sovereignty crisis due to power concentration and data\ngrowth among a few hyperscalers, leading to centralization and loss of user\ncontrol. This consolidation risks censorship and creates single points of\nfailure. While Web3 offers decentralized solutions, they often sacrifice either\nscalability, decentralization, or security, which are key elements in the\nblockchain trilemma. These solutions also struggle with limited access to\nenterprise-grade hardware and frequently rely on centralized infrastructure.\nThe Impossible Cloud Network (ICN) addresses these issues by creating a\nmulti-tiered, decentralized infrastructure layer. ICN offers a composable\nservice layer, an enterprise-grade hardware resource layer, and a transparent,\npermissionless HyperNode network for performance enforcement. By strategically\ndecoupling and decentralizing each layer, ICN aims to provide an open,\nextensively scalable infrastructure that ensures digital sovereignty,\neliminates single points of trust, enables service programmability, and offers\na decoupled architecture for limitless possibilities in the future internet.", "AI": {"tldr": "Impossible Cloud Network (ICN) \u901a\u8fc7\u591a\u5c42\u53bb\u4e2d\u5fc3\u5316\u57fa\u7840\u8bbe\u65bd\u89e3\u51b3\u4e92\u8054\u7f51\u4e3b\u6743\u5371\u673a\uff0c\u5728\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u3001\u53bb\u4e2d\u5fc3\u5316\u548c\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u4f01\u4e1a\u7ea7\u786c\u4ef6\u8bbf\u95ee\u548c\u53ef\u7ec4\u5408\u670d\u52a1\u3002", "motivation": "\u4e92\u8054\u7f51\u9762\u4e34\u4e3b\u6743\u5371\u673a\uff0c\u5c11\u6570\u8d85\u5927\u89c4\u6a21\u4f01\u4e1a\u96c6\u4e2d\u6743\u529b\u548c\u6570\u636e\uff0c\u5bfc\u81f4\u4e2d\u5fc3\u5316\u3001\u7528\u6237\u63a7\u5236\u6743\u4e27\u5931\u3001\u5ba1\u67e5\u98ce\u9669\u548c\u5355\u70b9\u6545\u969c\u95ee\u9898\u3002\u73b0\u6709Web3\u89e3\u51b3\u65b9\u6848\u5f80\u5f80\u5728\u533a\u5757\u94fe\u4e09\u96be\u95ee\u9898\u4e2d\u727a\u7272\u67d0\u4e2a\u8981\u7d20\u3002", "method": "ICN\u521b\u5efa\u591a\u5c42\u53bb\u4e2d\u5fc3\u5316\u57fa\u7840\u8bbe\u65bd\uff1a\u53ef\u7ec4\u5408\u670d\u52a1\u5c42\u3001\u4f01\u4e1a\u7ea7\u786c\u4ef6\u8d44\u6e90\u5c42\u3001\u900f\u660e\u7684\u65e0\u8bb8\u53efHyperNode\u7f51\u7edc\u7528\u4e8e\u6027\u80fd\u6267\u884c\u3002\u901a\u8fc7\u6218\u7565\u6027\u5730\u89e3\u8026\u548c\u53bb\u4e2d\u5fc3\u5316\u6bcf\u4e00\u5c42\u6765\u5b9e\u73b0\u76ee\u6807\u3002", "result": "ICN\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u653e\u3001\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u786e\u4fdd\u6570\u5b57\u4e3b\u6743\uff0c\u6d88\u9664\u5355\u70b9\u4fe1\u4efb\uff0c\u5b9e\u73b0\u670d\u52a1\u53ef\u7f16\u7a0b\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u4e92\u8054\u7f51\u63d0\u4f9b\u89e3\u8026\u67b6\u6784\u3002", "conclusion": "ICN\u901a\u8fc7\u5176\u591a\u5c42\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u89e3\u51b3\u4e86\u5f53\u524d\u4e92\u8054\u7f51\u7684\u4e2d\u5fc3\u5316\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u4e3b\u6743\u4e92\u8054\u7f51\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2510.03696", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03696", "abs": "https://arxiv.org/abs/2510.03696", "authors": ["Deepak Babu Piskala", "Sharlene Chen", "Udita Patel", "Parul Kalra", "Rafael Castrillo"], "title": "Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models", "comment": null, "summary": "Evaluating the quality of multi-turn chatbot interactions remains\nchallenging, as most existing methods assess interactions at the turn level\nwithout addressing whether a user's overarching goal was fulfilled. A ``goal''\nhere refers to an information need or task, such as asking for policy\ninformation or applying for leave. We propose a comprehensive framework for\ngoal-oriented evaluation of multi-agent systems (MAS), introducing the\n\\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,\nand a \\textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for\nfailure in multi-agent chatbots. Our method segments conversations by user\ngoals and evaluates success using all relevant turns. We present a model-based\nevaluation system combining teacher LLMs, where domain experts define goals,\nset quality standards serving as a guidance for the LLMs. The LLMs use\n``thinking tokens'' to produce interpretable rationales, enabling\n\\textit{explainable}, \\textit{data-efficient} evaluations. In an enterprise\nsetting, we apply our framework to evaluate AIDA, a zero-to-one employee\nconversational agent system built as a ground-up multi-agent conversational\nagent, and observe GSR improvement from 63\\% to 79\\% over six months since its\ninception. Our framework is generic and offers actionable insights through a\ndetailed defect taxonomy based on analysis of failure points in multi-agent\nchatbots, diagnosing overall success, identifying key failure modes, and\ninforming system improvements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u76ee\u6807\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u5f15\u5165\u76ee\u6807\u6210\u529f\u7387(GSR)\u548c\u5931\u8d25\u6839\u56e0\u5206\u7c7b(RCOF)\uff0c\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u7cfb\u7edf\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u6570\u636e\u9ad8\u6548\u7684\u591a\u8f6e\u5bf9\u8bdd\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5728\u8f6e\u6b21\u5c42\u9762\u8bc4\u4f30\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\uff0c\u65e0\u6cd5\u5224\u65ad\u7528\u6237\u603b\u4f53\u76ee\u6807\u662f\u5426\u8fbe\u6210\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u76ee\u6807\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u7528\u6237\u76ee\u6807\u5206\u5272\u5bf9\u8bdd\uff0c\u4f7f\u7528\u6559\u5e08LLM\u7ed3\u5408\u9886\u57df\u4e13\u5bb6\u5b9a\u4e49\u7684\u76ee\u6807\u548c\u8d28\u91cf\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u901a\u8fc7\"\u601d\u8003\u6807\u8bb0\"\u751f\u6210\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\u8bc4\u4f30AIDA\u7cfb\u7edf\uff0c\u76ee\u6807\u6210\u529f\u7387\u4ece63%\u63d0\u5347\u523079%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\uff0c\u901a\u8fc7\u8be6\u7ec6\u7684\u7f3a\u9677\u5206\u7c7b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u8bca\u65ad\u6574\u4f53\u6210\u529f\u7387\u3001\u8bc6\u522b\u5173\u952e\u5931\u8d25\u6a21\u5f0f\u5e76\u6307\u5bfc\u7cfb\u7edf\u6539\u8fdb\u3002"}}
{"id": "2510.04651", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04651", "abs": "https://arxiv.org/abs/2510.04651", "authors": ["Adnan Aijaz", "Peizheng Li", "Sajida Gufran"], "title": "Satellite Direct-to-Device from Low Earth Orbit: Techno-Economic Analysis of a Global Non-Terrestrial Network", "comment": "8 pages, 13 figures. This paper has been accepted for presentation at\n  the IEEE/IFIP Wireless and Mobile Networking Conference (WMNC) 2025", "summary": "Low Earth orbit (LEO) satellites and satellite direct-to-device (D2D)\ntechnology are at the heart of the next-generation global connectivity which\npromises direct access to space-based broadband services for unmodified\n3GPP-compliant handsets. With a rapidly evolving ecosystem, it is important to\nevaluate the feasibility, cost-effectiveness, and profitability of these\nservices. By assessing the technological aspects as well as economic\nimplications, stakeholders can make informed decisions about investment,\ndevelopment, and deployment strategies. This paper presents a comprehensive\ntechno-economic analysis (TEA) framework for evaluating LEO-based satellite D2D\nsystems. The framework integrates a global satellite constellation model, radio\npropagation aspects including atmospheric and rainfall attenuation models\ncompliant with ITU-R recommendations, 3GPP-compliant capacity calculations,\nrealistic global population data, and an all-encompassing cost model accounting\nfor both capital and operational expenses associated with space and ground\nsegments. Further, the framework evaluates three different architectural\noptions for realizing a global non-terrestrial network (NTN) for satellite D2D\nservices. With an emphasis on reproducibility, the framework has been\nimplemented through significant enhancements to an open-source tool. The\neconomic assessment reveals that global satellite D2D services can be provided\nat a monthly cost per subscriber which is comparable to terrestrial services\nwhile achieving a positive return on investment (ROI). Moreover, the results\nshow the potential of Open RAN technology for realizing cost-effective\nsatellite D2D services.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6280\u672f\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7684\u76f4\u63a5\u5230\u8bbe\u5907\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u5168\u7403\u536b\u661f\u661f\u5ea7\u6a21\u578b\u3001\u65e0\u7ebf\u7535\u4f20\u64ad\u7279\u6027\u3001\u5bb9\u91cf\u8ba1\u7b97\u548c\u6210\u672c\u6a21\u578b\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u5168\u7403\u975e\u5730\u9762\u7f51\u7edc\u67b6\u6784\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u548c\u536b\u661f\u76f4\u63a5\u5230\u8bbe\u5907\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u670d\u52a1\u7684\u53ef\u884c\u6027\u3001\u6210\u672c\u6548\u76ca\u548c\u76c8\u5229\u80fd\u529b\uff0c\u4ee5\u4fbf\u5229\u76ca\u76f8\u5173\u8005\u80fd\u591f\u5c31\u6295\u8d44\u3001\u5f00\u53d1\u548c\u90e8\u7f72\u7b56\u7565\u505a\u51fa\u660e\u667a\u51b3\u7b56\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u6280\u672f\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\uff0c\u6574\u5408\u4e86\u5168\u7403\u536b\u661f\u661f\u5ea7\u6a21\u578b\u3001\u7b26\u5408ITU-R\u5efa\u8bae\u7684\u65e0\u7ebf\u7535\u4f20\u64ad\u6a21\u578b\u30013GPP\u517c\u5bb9\u7684\u5bb9\u91cf\u8ba1\u7b97\u3001\u5168\u7403\u4eba\u53e3\u6570\u636e\u548c\u5168\u9762\u7684\u6210\u672c\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u5168\u7403\u975e\u5730\u9762\u7f51\u7edc\u67b6\u6784\u9009\u9879\u3002", "result": "\u7ecf\u6d4e\u8bc4\u4f30\u663e\u793a\uff0c\u5168\u7403\u536b\u661f\u76f4\u63a5\u5230\u8bbe\u5907\u670d\u52a1\u53ef\u4ee5\u4ee5\u4e0e\u5730\u9762\u670d\u52a1\u76f8\u5f53\u7684\u7528\u6237\u6708\u6210\u672c\u63d0\u4f9b\uff0c\u540c\u65f6\u5b9e\u73b0\u6b63\u7684\u6295\u8d44\u56de\u62a5\u7387\uff0c\u5e76\u4e14\u7ed3\u679c\u663e\u793a\u4e86Open RAN\u6280\u672f\u5728\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u536b\u661f\u76f4\u63a5\u5230\u8bbe\u5907\u670d\u52a1\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u6280\u672f\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\u8bc1\u660e\u4e86\u5168\u7403\u536b\u661f\u76f4\u63a5\u5230\u8bbe\u5907\u670d\u52a1\u5728\u7ecf\u6d4e\u4e0a\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u4ee5\u5177\u6709\u7ade\u4e89\u529b\u7684\u6210\u672c\u63d0\u4f9b\u5bbd\u5e26\u670d\u52a1\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86Open RAN\u6280\u672f\u5728\u8fd9\u7c7b\u7cfb\u7edf\u4e2d\u7684\u6210\u672c\u6548\u76ca\u4f18\u52bf\u3002"}}
{"id": "2510.03700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03700", "abs": "https://arxiv.org/abs/2510.03700", "authors": ["Seungseop Lim", "Gibaeg Kim", "Hyunkyung Lee", "Wooseok Han", "Jean Seo", "Jaehyo Yoo", "Eunho Yang"], "title": "H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis", "comment": "GenAI4Health @NeurIPS 2025", "summary": "An accurate differential diagnosis (DDx) is essential for patient care,\nshaping therapeutic decisions and influencing outcomes. Recently, Large\nLanguage Models (LLMs) have emerged as promising tools to support this process\nby generating a DDx list from patient narratives. However, existing evaluations\nof LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,\nwhich fail to distinguish between clinically relevant near-misses and\ndiagnostically distant errors. To mitigate this limitation, we introduce H-DDx,\na hierarchical evaluation framework that better reflects clinical relevance.\nH-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses\nto ICD-10 codes and applies a hierarchical metric that credits predictions\nclosely related to the ground-truth diagnosis. In benchmarking 22 leading\nmodels, we show that conventional flat metrics underestimate performance by\noverlooking clinically meaningful outputs, with our results highlighting the\nstrengths of domain-specialized open-source models. Furthermore, our framework\nenhances interpretability by revealing hierarchical error patterns,\ndemonstrating that LLMs often correctly identify the broader clinical context\neven when the precise diagnosis is missed.", "AI": {"tldr": "\u63d0\u51fa\u4e86H-DDx\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u76f8\u6bd4\u4f20\u7edf\u5e73\u9762\u6307\u6807\u80fd\u66f4\u597d\u5730\u53cd\u6620\u4e34\u5e8a\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u9274\u522b\u8bca\u65ad\u8bc4\u4f30\u4e2d\u4e3b\u8981\u4f9d\u8d56Top-k\u51c6\u786e\u7387\u7b49\u5e73\u9762\u6307\u6807\uff0c\u65e0\u6cd5\u533a\u5206\u4e34\u5e8a\u76f8\u5173\u7684\u8fd1\u4f3c\u9519\u8bef\u548c\u8bca\u65ad\u4e0a\u76f8\u8ddd\u8f83\u8fdc\u7684\u9519\u8bef\uff0c\u9700\u8981\u66f4\u7b26\u5408\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "H-DDx\u6846\u67b6\u91c7\u7528\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u6d41\u7a0b\u5c06\u81ea\u7531\u6587\u672c\u8bca\u65ad\u6620\u5c04\u5230ICD-10\u4ee3\u7801\uff0c\u5e76\u5e94\u7528\u5206\u5c42\u5ea6\u91cf\u6765\u5956\u52b1\u4e0e\u771f\u5b9e\u8bca\u65ad\u5bc6\u5207\u76f8\u5173\u7684\u9884\u6d4b\u3002", "result": "\u572822\u4e2a\u9886\u5148\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f20\u7edf\u5e73\u9762\u6307\u6807\u4f4e\u4f30\u4e86\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u8f93\u51fa\uff1b\u9886\u57df\u4e13\u4e1a\u5316\u7684\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u7a81\u51fa\uff1b\u6846\u67b6\u63ed\u793a\u4e86\u5206\u5c42\u9519\u8bef\u6a21\u5f0f\uff0c\u663e\u793aLLM\u5373\u4f7f\u9519\u8fc7\u7cbe\u786e\u8bca\u65ad\u4e5f\u5e38\u80fd\u6b63\u786e\u8bc6\u522b\u66f4\u5e7f\u6cdb\u7684\u4e34\u5e8a\u80cc\u666f\u3002", "conclusion": "H-DDx\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u4e34\u5e8a\u76f8\u5173\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2510.04731", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04731", "abs": "https://arxiv.org/abs/2510.04731", "authors": ["Douglas Dziedzorm Agbeve", "Andrey Belogaev", "Chris Blondia", "Jeroen Famaey"], "title": "Evaluating UORA-Based Polling Mechanism for Latency-Sensitive Uplink Traffic in Wi-Fi Networks", "comment": null, "summary": "IEEE 802.11ax (Wi-Fi 6) introduced Orthogonal Frequency Division Multiple\nAccess (OFDMA), which enables simultaneous transmissions through centralized\nresource allocation. However, effective uplink scheduling requires the Access\nPoint (AP) to identify which stations (STAs) have data to transmit. This\ntypically necessitates polling for buffer status reports, a process that\nbecomes increasingly inefficient and unscalable with growing device density. In\nthis paper, we study how the Uplink OFDMA-based Random Access (UORA) feature\nimproves the scalability and delay experienced by latency-sensitive data\nstreams. We show that UORA enables efficient uplink scheduling while\nopportunistically identifying buffered traffic from unscheduled STAs, striking\na balance between coordination and scalability. Performance evaluation of\ndifferent polling strategies is done by means of simulation in ns-3. The\nresults indicate that UORA-based polling outperforms alternative schemes in\ndensely deployed network environments with heterogeneous uplink traffic\npatterns. Furthermore, under highly sparse and sporadic traffic conditions,\nUORA-based polling yields over 40% delay reduction compared to Scheduled Access\n(SA) OFDMA.", "AI": {"tldr": "Wi-Fi 6\u7684Uplink OFDMA-based Random Access (UORA)\u901a\u8fc7\u968f\u673a\u63a5\u5165\u673a\u5236\u6539\u8fdb\u4e0a\u884c\u8c03\u5ea6\uff0c\u5728\u5bc6\u96c6\u7f51\u7edc\u73af\u5883\u4e2d\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u4f20\u7edf\u8c03\u5ea6\u63a5\u5165\u53ef\u51cf\u5c1140%\u4ee5\u4e0a\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edfWi-Fi 6\u4e0a\u884c\u8c03\u5ea6\u9700\u8981\u8f6e\u8be2\u7f13\u51b2\u533a\u72b6\u6001\u62a5\u544a\uff0c\u968f\u7740\u8bbe\u5907\u5bc6\u5ea6\u589e\u52a0\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u4e14\u4e0d\u53ef\u6269\u5c55\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u4e0a\u884c\u8c03\u5ea6\u673a\u5236\u6765\u652f\u6301\u5ef6\u8fdf\u654f\u611f\u6570\u636e\u6d41\u3002", "method": "\u7814\u7a76UORA\u7279\u6027\u5982\u4f55\u6539\u5584\u5ef6\u8fdf\u654f\u611f\u6570\u636e\u6d41\u7684\u53ef\u6269\u5c55\u6027\u548c\u5ef6\u8fdf\u6027\u80fd\u3002\u901a\u8fc7ns-3\u4eff\u771f\u8bc4\u4f30\u4e0d\u540c\u8f6e\u8be2\u7b56\u7565\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u5728\u5bc6\u96c6\u90e8\u7f72\u7684\u7f51\u7edc\u73af\u5883\u4e2d\uff0c\u57fa\u4e8eUORA\u7684\u8f6e\u8be2\u4f18\u4e8e\u5176\u4ed6\u65b9\u6848\uff1b\u5728\u9ad8\u5ea6\u7a00\u758f\u548c\u96f6\u661f\u6d41\u91cf\u6761\u4ef6\u4e0b\uff0cUORA\u8f6e\u8be2\u76f8\u6bd4\u8c03\u5ea6\u63a5\u5165OFDMA\u53ef\u51cf\u5c1140%\u4ee5\u4e0a\u7684\u5ef6\u8fdf\u3002", "conclusion": "UORA\u901a\u8fc7\u5e73\u8861\u534f\u8c03\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4e0a\u884c\u8c03\u5ea6\uff0c\u540c\u65f6\u80fd\u591f\u673a\u4f1a\u6027\u5730\u8bc6\u522b\u672a\u8c03\u5ea6STA\u7684\u7f13\u51b2\u6d41\u91cf\uff0c\u7279\u522b\u9002\u5408\u5bc6\u96c6\u7f51\u7edc\u73af\u5883\u3002"}}
{"id": "2510.03727", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03727", "abs": "https://arxiv.org/abs/2510.03727", "authors": ["Xuehai He"], "title": "Bridging the Gap Between Multimodal Foundation Models and World Models", "comment": "PhD thesis", "summary": "Humans understand the world through the integration of multiple sensory\nmodalities, enabling them to perceive, reason about, and imagine dynamic\nphysical processes. Inspired by this capability, multimodal foundation models\n(MFMs) have emerged as powerful tools for multimodal understanding and\ngeneration. However, today's MFMs fall short of serving as effective world\nmodels. They lack the essential ability such as perform counterfactual\nreasoning, simulate dynamics, understand the spatiotemporal information,\ncontrol generated visual outcomes, and perform multifaceted reasoning. We\ninvestigates what it takes to bridge the gap between multimodal foundation\nmodels and world models. We begin by improving the reasoning capabilities of\nMFMs through discriminative tasks and equipping MFMs with structured reasoning\nskills, such as causal inference, counterfactual thinking, and spatiotemporal\nreasoning, enabling them to go beyond surface correlations and understand\ndeeper relationships within visual and textual data. Next, we explore\ngenerative capabilities of multimodal foundation models across both image and\nvideo modalities, introducing new frameworks for structured and controllable\ngeneration. Our approaches incorporate scene graphs, multimodal conditioning,\nand multimodal alignment strategies to guide the generation process, ensuring\nconsistency with high-level semantics and fine-grained user intent. We further\nextend these techniques to controllable 4D generation, enabling interactive,\neditable, and morphable object synthesis over time and space.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5c06\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63d0\u5347\u4e3a\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u589e\u5f3a\u5176\u63a8\u7406\u80fd\u529b\u548c\u751f\u6210\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u8fdb\u884c\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u65f6\u7a7a\u7406\u89e3\u3001\u53ef\u63a7\u751f\u6210\u7b49\u590d\u6742\u4efb\u52a1\u3002", "motivation": "\u53d7\u4eba\u7c7b\u591a\u611f\u5b98\u7406\u89e3\u4e16\u754c\u7684\u542f\u53d1\uff0c\u5f53\u524d\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u4f5c\u4e3a\u6709\u6548\u4e16\u754c\u6a21\u578b\u7684\u5173\u952e\u80fd\u529b\uff0c\u5982\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u52a8\u6001\u6a21\u62df\u3001\u65f6\u7a7a\u4fe1\u606f\u7406\u89e3\u548c\u53ef\u63a7\u751f\u6210\u7b49\u3002", "method": "\u901a\u8fc7\u5224\u522b\u6027\u4efb\u52a1\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u5f15\u5165\u56e0\u679c\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u601d\u7ef4\u548c\u65f6\u7a7a\u63a8\u7406\u7b49\u7ed3\u6784\u5316\u63a8\u7406\u6280\u80fd\uff1b\u5f00\u53d1\u7ed3\u6784\u5316\u53ef\u63a7\u751f\u6210\u6846\u67b6\uff0c\u5229\u7528\u573a\u666f\u56fe\u3001\u591a\u6a21\u6001\u6761\u4ef6\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u7b56\u7565\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u589e\u5f3a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4ece\u56fe\u50cf\u5230\u89c6\u9891\u7684\u53ef\u63a74D\u751f\u6210\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u3001\u53ef\u7f16\u8f91\u548c\u53ef\u53d8\u5f62\u7684\u5bf9\u8c61\u5408\u6210\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u589e\u5f3a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\uff0c\u53ef\u4ee5\u7f29\u5c0f\u5176\u4e0e\u4e16\u754c\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u6784\u5efa\u66f4\u667a\u80fd\u7684\u591a\u6a21\u6001AI\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.03771", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03771", "abs": "https://arxiv.org/abs/2510.03771", "authors": ["Divij Handa", "David Blincoe", "Orson Adams", "Yinlin Fu"], "title": "OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation", "comment": null, "summary": "Deploying capable and user-aligned LLM-based systems necessitates reliable\nevaluation. While LLMs excel in verifiable tasks like coding and mathematics,\nwhere gold-standard solutions are available, adoption remains challenging for\nsubjective tasks that lack a single correct answer. E-commerce Query Rewriting\n(QR) is one such problem where determining whether a rewritten query properly\ncaptures the user intent is extremely difficult to figure out algorithmically.\nIn this work, we introduce OptAgent, a novel framework that combines\nmulti-agent simulations with genetic algorithms to verify and optimize queries\nfor QR. Instead of relying on a static reward model or a single LLM judge, our\napproach uses multiple LLM-based agents, each acting as a simulated shopping\ncustomer, as a dynamic reward signal. The average of these agent-derived scores\nserves as an effective fitness function for an evolutionary algorithm that\niteratively refines the user's initial query. We evaluate OptAgent on a dataset\nof 1000 real-world e-commerce queries in five different categories, and we\nobserve an average improvement of 21.98% over the original user query and 3.36%\nover a Best-of-N LLM rewriting baseline.", "AI": {"tldr": "OptAgent\u6846\u67b6\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548c\u9057\u4f20\u7b97\u6cd5\u6765\u4f18\u5316\u7535\u5546\u67e5\u8be2\u6539\u5199\uff0c\u901a\u8fc7\u6a21\u62df\u8d2d\u7269\u987e\u5ba2\u7684LLM\u667a\u80fd\u4f53\u4f5c\u4e3a\u52a8\u6001\u5956\u52b1\u4fe1\u53f7\uff0c\u76f8\u6bd4\u539f\u59cb\u67e5\u8be2\u63d0\u534721.98%\uff0c\u4f18\u4e8eBest-of-N\u57fa\u7ebf3.36%\u3002", "motivation": "LLM\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7f3a\u4e4f\u5355\u4e00\u6b63\u786e\u7b54\u6848\u7684\u4e3b\u89c2\u4efb\u52a1\uff08\u5982\u7535\u5546\u67e5\u8be2\u6539\u5199\uff09\u4e2d\u90e8\u7f72\u56f0\u96be\uff0c\u9700\u8981\u53ef\u9760\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548c\u9057\u4f20\u7b97\u6cd5\uff0c\u4f7f\u7528\u591a\u4e2a\u6a21\u62df\u8d2d\u7269\u987e\u5ba2\u7684LLM\u667a\u80fd\u4f53\u4f5c\u4e3a\u52a8\u6001\u5956\u52b1\u4fe1\u53f7\uff0c\u5176\u5e73\u5747\u5f97\u5206\u4f5c\u4e3a\u8fdb\u5316\u7b97\u6cd5\u7684\u9002\u5e94\u5ea6\u51fd\u6570\u6765\u8fed\u4ee3\u4f18\u5316\u7528\u6237\u67e5\u8be2\u3002", "result": "\u57281000\u4e2a\u771f\u5b9e\u7535\u5546\u67e5\u8be2\u7684\u4e94\u7c7b\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u539f\u59cb\u67e5\u8be2\u5e73\u5747\u63d0\u534721.98%\uff0c\u4f18\u4e8eBest-of-N\u57fa\u7ebf3.36%\u3002", "conclusion": "OptAgent\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4e3b\u89c2\u4efb\u52a1\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u4e3a\u7535\u5546\u67e5\u8be2\u6539\u5199\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2510.03777", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03777", "abs": "https://arxiv.org/abs/2510.03777", "authors": ["Divij Handa", "Mihir Parmar", "Aswin RRV", "Md Nayem Uddin", "Hamid Palangi", "Chitta Baral"], "title": "GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time", "comment": null, "summary": "Repeated Sampling (RS) is a simple inference-time algorithm that has been\nshown to improve model performance on complex tasks. Although it is an\neffective way of scaling inference time, it often struggles to generate diverse\nsolution candidates, frequently relying on the same underlying approach to\nsolve the problem and thus producing redundant samples. To address this\nlimitation, we propose a new inference algorithm, GuidedSampling, which\ndecouples the exploration and generation phases during inference, increasing\ndiversity of generated candidate solutions. The exploration phase identifies\nmultiple concepts that can be utilized to solve the problem, while the\ngeneration phase applies a specific concept to provide final solution\ncandidates. We first define the theoretical bounds of GuidedSampling and then\nempirically demonstrate that it improves the performance of base model at\npass@50 by on an average ~21.6% across various benchmarks compared to RS.\nFurthermore, models trained on trajectories of GuidedSampling exhibit\nsubstantial performance improvements at pass@5 by on an average ~9.7%, compared\nto models trained on traditional RS. Additionally, models trained with\nGuidedSampling increases the average number of concepts per instance (1.67 ->\n3.03), yielding a diverse set of candidates than traditional RS.", "AI": {"tldr": "\u63d0\u51faGuidedSampling\u63a8\u7406\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u63a2\u7d22\u548c\u751f\u6210\u9636\u6bb5\u6765\u589e\u52a0\u89e3\u51b3\u65b9\u6848\u591a\u6837\u6027\uff0c\u76f8\u6bd4\u91cd\u590d\u91c7\u6837\u5728pass@50\u4e0a\u5e73\u5747\u63d0\u534721.6%\u6027\u80fd", "motivation": "\u91cd\u590d\u91c7\u6837\u7b97\u6cd5\u5728\u63a8\u7406\u65f6\u867d\u7136\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u7ecf\u5e38\u751f\u6210\u5197\u4f59\u6837\u672c\uff0c\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u65e0\u6cd5\u4ea7\u751f\u4e0d\u540c\u7684\u89e3\u51b3\u65b9\u6848", "method": "GuidedSampling\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u63a2\u7d22\u9636\u6bb5\u8bc6\u522b\u591a\u4e2a\u53ef\u7528\u7684\u89e3\u51b3\u6982\u5ff5\uff0c\u751f\u6210\u9636\u6bb5\u5e94\u7528\u7279\u5b9a\u6982\u5ff5\u63d0\u4f9b\u6700\u7ec8\u89e3\u51b3\u65b9\u6848", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGuidedSampling\u76f8\u6bd4\u91cd\u590d\u91c7\u6837\u5728pass@50\u4e0a\u5e73\u5747\u63d0\u534721.6%\uff1b\u4f7f\u7528GuidedSampling\u8f68\u8ff9\u8bad\u7ec3\u7684\u6a21\u578b\u5728pass@5\u4e0a\u5e73\u5747\u63d0\u53479.7%\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u5e73\u5747\u6982\u5ff5\u6570\u4ece1.67\u589e\u52a0\u52303.03", "conclusion": "GuidedSampling\u901a\u8fc7\u5206\u79bb\u63a2\u7d22\u548c\u751f\u6210\u9636\u6bb5\u6709\u6548\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u91cd\u590d\u91c7\u6837\u65b9\u6cd5"}}
{"id": "2510.03845", "categories": ["cs.AI", "cs.GT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.03845", "abs": "https://arxiv.org/abs/2510.03845", "authors": ["Gon Buzaglo", "Noah Golowich", "Elad Hazan"], "title": "The Hidden Game Problem", "comment": null, "summary": "This paper investigates a class of games with large strategy spaces,\nmotivated by challenges in AI alignment and language games. We introduce the\nhidden game problem, where for each player, an unknown subset of strategies\nconsistently yields higher rewards compared to the rest. The central question\nis whether efficient regret minimization algorithms can be designed to discover\nand exploit such hidden structures, leading to equilibrium in these subgames\nwhile maintaining rationality in general. We answer this question affirmatively\nby developing a composition of regret minimization techniques that achieve\noptimal external and swap regret bounds. Our approach ensures rapid convergence\nto correlated equilibria in hidden subgames, leveraging the hidden game\nstructure for improved computational efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5177\u6709\u5927\u578b\u7b56\u7565\u7a7a\u95f4\u7684\u6e38\u620f\uff0c\u63d0\u51fa\u4e86\u9690\u85cf\u6e38\u620f\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u80fd\u591f\u53d1\u73b0\u548c\u5229\u7528\u9690\u85cf\u7ed3\u6784\u7684\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u754c\u9650\u3002", "motivation": "\u53d7AI\u5bf9\u9f50\u548c\u8bed\u8a00\u6e38\u620f\u6311\u6218\u7684\u542f\u53d1\uff0c\u7814\u7a76\u5f53\u6bcf\u4e2a\u73a9\u5bb6\u5b58\u5728\u672a\u77e5\u7b56\u7565\u5b50\u96c6\u6301\u7eed\u4ea7\u751f\u66f4\u9ad8\u5956\u52b1\u65f6\u7684\u9690\u85cf\u6e38\u620f\u95ee\u9898\uff0c\u63a2\u7d22\u80fd\u5426\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u6765\u53d1\u73b0\u548c\u5229\u7528\u8fd9\u79cd\u9690\u85cf\u7ed3\u6784\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9057\u61be\u6700\u5c0f\u5316\u6280\u672f\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u6700\u5c0f\u5316\uff0c\u5229\u7528\u9690\u85cf\u6e38\u620f\u7ed3\u6784\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u754c\u9650\uff0c\u80fd\u591f\u5feb\u901f\u6536\u655b\u5230\u9690\u85cf\u5b50\u6e38\u620f\u4e2d\u7684\u76f8\u5173\u5747\u8861\u3002", "conclusion": "\u80af\u5b9a\u5730\u56de\u7b54\u4e86\u7814\u7a76\u95ee\u9898\uff0c\u8bc1\u660e\u53ef\u4ee5\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u6765\u53d1\u73b0\u548c\u5229\u7528\u9690\u85cf\u6e38\u620f\u7ed3\u6784\uff0c\u5728\u4fdd\u6301\u4e00\u822c\u7406\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u5b50\u6e38\u620f\u5747\u8861\u3002"}}
{"id": "2510.03847", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03847", "abs": "https://arxiv.org/abs/2510.03847", "authors": ["Raghav Sharma", "Manan Mehta"], "title": "Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs", "comment": "9 Pages", "summary": "Small language models (SLMs; 1-12B params, sometimes up to 20B) are\nsufficient and often superior for agentic workloads where the objective is\nschema- and API-constrained accuracy rather than open-ended generation. We\nsynthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,\nQwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,\nDeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,\nStableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with\nguided decoding libraries (XGrammar, Outlines). We formalize SLM-default,\nLLM-fallback systems with uncertainty-aware routing and verifier cascades, and\npropose engineering metrics that reflect real production goals: cost per\nsuccessful task (CPS), schema validity rate, executable call rate, p50/p95\nlatency, and energy per request. Guided decoding, strict JSON Schema outputs,\nand validator-first tool execution close much of the capability gap with larger\nmodels and often let SLMs match or surpass LLMs on tool use, function calling,\nand RAG at 10x-100x lower token cost with materially better latency and energy.\nWe provide design patterns for agent stacks that prioritize SLMs: schema-first\nprompting, type-safe function registries, confidence scoring with verifier\nrollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits\nwhere fallback remains valuable (open-domain reasoning and some long-horizon\nplanning). The result is a practical blueprint for building fast, inexpensive,\nand reliable agents that default to SLMs while preserving headroom with\ntargeted LLM assistance.\n  Keywords: small language models, agents, function calling, structured\noutputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,\nedge inference", "AI": {"tldr": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff081-20B\u53c2\u6570\uff09\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u8db3\u591f\u4e14\u5e38\u4f18\u4e8e\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5bfc\u89e3\u7801\u3001\u4e25\u683cJSON Schema\u8f93\u51fa\u548c\u9a8c\u8bc1\u5668\u4f18\u5148\u7684\u5de5\u5177\u6267\u884c\uff0c\u80fd\u4ee510-100\u500d\u66f4\u4f4e\u7684\u6210\u672c\u5b9e\u73b0\u7c7b\u4f3c\u6216\u66f4\u597d\u7684\u5de5\u5177\u4f7f\u7528\u3001\u51fd\u6570\u8c03\u7528\u548cRAG\u6027\u80fd\u3002", "motivation": "\u9488\u5bf9\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u9700\u8981\u6a21\u5f0f\u7ea6\u675f\u51c6\u786e\u6027\u7684\u573a\u666f\uff0c\u800c\u975e\u5f00\u653e\u5f0f\u751f\u6210\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u80fd\u8017\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u5316\u65b9\u6cd5\u6765\u5f25\u8865\u4e0e\u5927\u6a21\u578b\u7684\u80fd\u529b\u5dee\u8ddd\u3002", "method": "\u91c7\u7528SLM\u9ed8\u8ba4\u3001LLM\u56de\u9000\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8def\u7531\u548c\u9a8c\u8bc1\u5668\u7ea7\u8054\uff1b\u4f7f\u7528\u5f15\u5bfc\u89e3\u7801\u5e93\uff08XGrammar\u3001Outlines\uff09\u3001\u4e25\u683cJSON Schema\u8f93\u51fa\u3001\u9a8c\u8bc1\u5668\u4f18\u5148\u5de5\u5177\u6267\u884c\uff1b\u63d0\u51fa\u5de5\u7a0b\u6307\u6807\u5982CPS\u3001\u6a21\u5f0f\u6709\u6548\u6027\u7387\u7b49\u3002", "result": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u3001\u51fd\u6570\u8c03\u7528\u548cRAG\u4efb\u52a1\u4e0a\u80fd\u591f\u5339\u914d\u6216\u8d85\u8d8a\u5927\u6a21\u578b\uff0c\u540c\u65f6\u5b9e\u73b010-100\u500d\u66f4\u4f4e\u7684token\u6210\u672c\u3001\u66f4\u597d\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u8868\u73b0\u3002", "conclusion": "\u4e3a\u6784\u5efa\u5feb\u901f\u3001\u5ec9\u4ef7\u4e14\u53ef\u9760\u7684\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u84dd\u56fe\uff0c\u9ed8\u8ba4\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u7559\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u7684\u5927\u6a21\u578b\u56de\u9000\u673a\u5236\u3002"}}
{"id": "2510.03851", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03851", "abs": "https://arxiv.org/abs/2510.03851", "authors": ["Ruiying Ma", "Chieh-Jan Mike Liang", "Yanjie Gao", "Francis Y. Yan"], "title": "Algorithm Generation via Creative Ideation", "comment": null, "summary": "Designing system algorithms remains challenging, where the discontinuous\nnature of the solution space often forces system engineers to rely on generic\nheuristics at the expense of performance. We study whether LLMs can practically\ndrive algorithm generation, and find that they are biased towards well-known\ngeneric designs, rather than making the creative leaps needed to navigate the\ndiscontinuous solution space. To address this limitation, we introduce\nMetaMuse, a framework for creative ideation built on three self-reflection\nprinciples: (1) quantifying solution diversity and usefulness in measurable\nperformance space, rather than abstract idea space, (2) steering ideation\nthrough external stimuli, rather than internal randomness, and (3) constructing\nexecutable solutions using waypoint reasoning, rather than free-form\nchain-of-thought. Extensive evaluation shows that MetaMuse can generate\nhigh-performing solutions for two critical problems at a global cloud provider:\ncache replacement (reducing cache misses by up to 35.76%) and online bin\npacking (reducing bin usage by up to 30.93%).", "AI": {"tldr": "MetaMuse\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u81ea\u6211\u53cd\u601d\u539f\u5219\u89e3\u51b3LLM\u5728\u7b97\u6cd5\u751f\u6210\u4e2d\u7684\u521b\u610f\u4e0d\u8db3\u95ee\u9898\uff0c\u5728\u7f13\u5b58\u66ff\u6362\u548c\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u7cfb\u7edf\u7b97\u6cd5\u8bbe\u8ba1\u9762\u4e34\u89e3\u7a7a\u95f4\u4e0d\u8fde\u7eed\u7684\u6311\u6218\uff0c\u73b0\u6709LLM\u504f\u5411\u901a\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u800c\u7f3a\u4e4f\u521b\u9020\u6027\uff0c\u9700\u8981\u7a81\u7834\u8fd9\u4e00\u5c40\u9650", "method": "\u63d0\u51faMetaMuse\u6846\u67b6\uff0c\u57fa\u4e8e\u4e09\u4e2a\u539f\u5219\uff1a(1)\u5728\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u7a7a\u95f4\u800c\u975e\u62bd\u8c61\u60f3\u6cd5\u7a7a\u95f4\u91cf\u5316\u89e3\u51b3\u65b9\u6848\u591a\u6837\u6027\u548c\u6709\u7528\u6027\uff1b(2)\u901a\u8fc7\u5916\u90e8\u523a\u6fc0\u800c\u975e\u5185\u90e8\u968f\u673a\u6027\u5f15\u5bfc\u6784\u601d\uff1b(3)\u4f7f\u7528\u8def\u5f84\u70b9\u63a8\u7406\u800c\u975e\u81ea\u7531\u5f62\u5f0f\u7684\u601d\u7ef4\u94fe\u6784\u5efa\u53ef\u6267\u884c\u89e3\u51b3\u65b9\u6848", "result": "\u5728\u7f13\u5b58\u66ff\u6362\u95ee\u9898\u4e0a\u51cf\u5c11\u7f13\u5b58\u7f3a\u5931\u8fbe35.76%\uff0c\u5728\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e0a\u51cf\u5c11\u5bb9\u5668\u4f7f\u7528\u8fbe30.93%", "conclusion": "MetaMuse\u80fd\u591f\u4e3a\u5173\u952e\u7cfb\u7edf\u95ee\u9898\u751f\u6210\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7b97\u6cd5\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027"}}
{"id": "2510.03859", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03859", "abs": "https://arxiv.org/abs/2510.03859", "authors": ["Raghav Sharma", "Manan Mehta"], "title": "Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT Infrastructure using LLM-Enhanced Contextual Reasoning", "comment": "22 pages", "summary": "Ensuring that critical IoT systems function safely and smoothly depends a lot\non finding anomalies quickly. As more complex systems, like smart healthcare,\nenergy grids and industrial automation, appear, it is easier to see the\nshortcomings of older methods of detection. Monitoring failures usually happen\nin dynamic, high dimensional situations, especially when data is incomplete,\nmessy or always evolving. Such limits point out the requirement for adaptive,\nintelligent systems that always improve and think. LLMs are now capable of\nsignificantly changing how context is understood and semantic inference is done\nacross all types of data. This proposal suggests using an LLM supported\ncontextual reasoning method along with XAI agents to improve how anomalies are\nfound in significant IoT environments. To discover hidden patterns and notice\ninconsistencies in data streams, it uses attention methods, avoids dealing with\ndetails from every time step and uses memory buffers with meaning. Because no\ncode AI stresses transparency and interpretability, people can check and accept\nthe AI's decisions, helping ensure AI follows company policies. The two\narchitectures are put together in a test that compares the results of the\ntraditional model with those of the suggested LLM enhanced model. Important\nmeasures to check are the accuracy of detection, how much inaccurate\ninformation is included in the results, how clearly the findings can be read\nand how fast the system responds under different test situations. The\nmetaheuristic is tested in simulations of real world smart grid and healthcare\ncontexts to check its adaptability and reliability. From the study, we see that\nthe new approach performs much better than most existing models in both\naccuracy and interpretation, so it could be a good fit for future anomaly\ndetection tasks in IoT", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u548cXAI\u4ee3\u7406\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5173\u952eIoT\u7cfb\u7edf\uff0c\u5728\u667a\u80fd\u7535\u7f51\u548c\u533b\u7597\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u7684\u68c0\u6d4b\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u52a8\u6001\u3001\u9ad8\u7ef4\u3001\u6570\u636e\u4e0d\u5b8c\u6574\u7684IoT\u73af\u5883\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u81ea\u9002\u5e94\u667a\u80fd\u7cfb\u7edf\u6765\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u4f7f\u7528LLM\u652f\u6301\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u6cd5\u548cXAI\u4ee3\u7406\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u3001\u5185\u5b58\u7f13\u51b2\u548c\u8bed\u4e49\u5206\u6790\u6765\u53d1\u73b0\u9690\u85cf\u6a21\u5f0f\u548c\u68c0\u6d4b\u6570\u636e\u6d41\u4e0d\u4e00\u81f4\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u68c0\u6d4b\u7cbe\u5ea6\u3001\u8bef\u62a5\u7387\u3001\u53ef\u8bfb\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5728\u771f\u5b9e\u573a\u666f\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728IoT\u73af\u5883\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03863", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03863", "abs": "https://arxiv.org/abs/2510.03863", "authors": ["Arina Kharlamova", "Bowei He", "Chen Ma", "Xue Liu"], "title": "Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation", "comment": "Submitted to ICLR 2026", "summary": "Online services rely on CAPTCHAs as a first line of defense against automated\nabuse, yet recent advances in multi-modal large language models (MLLMs) have\neroded the effectiveness of conventional designs that focus on text recognition\nor 2D image understanding. To address this challenge, we present Spatial\nCAPTCHA, a novel human-verification framework that leverages fundamental\ndifferences in spatial reasoning between humans and MLLMs. Unlike existing\nCAPTCHAs which rely on low-level perception tasks that are vulnerable to modern\nAI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,\nperspective-taking, occlusion handling, and mental rotation. These skills are\nintuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The\nsystem employs a procedural generation pipeline with constraint-based\ndifficulty control, automated correctness verification, and human-in-the-loop\nvalidation to ensure scalability, robustness, and adaptability. Evaluation on a\ncorresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly\noutperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%\nPass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,\nwhich confirms its effectiveness as both a security mechanism and a diagnostic\ntool for spatial reasoning in AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpatial CAPTCHA\u7684\u65b0\u578b\u4eba\u7c7b\u9a8c\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u4eba\u7c7b\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u6839\u672c\u5dee\u5f02\u6765\u9632\u5fa1\u81ea\u52a8\u5316\u653b\u51fb\u3002", "motivation": "\u4f20\u7edfCAPTCHA\u4f9d\u8d56\u6587\u672c\u8bc6\u522b\u62162D\u56fe\u50cf\u7406\u89e3\uff0c\u4f46\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u5df2\u524a\u5f31\u5176\u6709\u6548\u6027\uff0c\u9700\u8981\u5f00\u53d1\u57fa\u4e8e\u66f4\u590d\u6742\u8ba4\u77e5\u80fd\u529b\u7684\u9a8c\u8bc1\u673a\u5236\u3002", "method": "\u91c7\u7528\u7a0b\u5e8f\u5316\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa\u9700\u8981\u51e0\u4f55\u63a8\u7406\u3001\u89c6\u89d2\u8f6c\u6362\u3001\u906e\u6321\u5904\u7406\u548c\u5fc3\u7406\u65cb\u8f6c\u7b49\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u52a8\u6001\u95ee\u9898\uff0c\u7ed3\u5408\u57fa\u4e8e\u7ea6\u675f\u7684\u96be\u5ea6\u63a7\u5236\u548c\u81ea\u52a8\u5316\u6b63\u786e\u6027\u9a8c\u8bc1\u3002", "result": "\u5728Spatial-CAPTCHA-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4eba\u7c7b\u8868\u73b0\u8fdc\u8d8510\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6700\u4f73\u6a21\u578b\u4ec5\u8fbe\u523031.0%\u7684Pass@1\u51c6\u786e\u7387\uff0c\u4e14\u4f18\u4e8eGoogle reCAPTCHA\u3002", "conclusion": "Spatial CAPTCHA\u4e0d\u4ec5\u4f5c\u4e3a\u6709\u6548\u7684\u5b89\u5168\u673a\u5236\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u8bc4\u4f30AI\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u586b\u8865\u4e86\u4f20\u7edfCAPTCHA\u7684\u9632\u5fa1\u6f0f\u6d1e\u3002"}}
{"id": "2510.03886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03886", "abs": "https://arxiv.org/abs/2510.03886", "authors": ["Seil Kang", "Woojung Han", "Dayun Ju", "Seong Jae Hwang"], "title": "Rare Text Semantics Were Always There in Your Diffusion Transformer", "comment": "Accepted to NeurIPS 2025", "summary": "Starting from flow- and diffusion-based transformers, Multi-modal Diffusion\nTransformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim\nfor exceptional visual fidelity. As these models advance, users continually\npush the boundary with imaginative or rare prompts, which advanced models still\nfalter in generating, since their concepts are often too scarce to leave a\nstrong imprint during pre-training. In this paper, we propose a simple yet\neffective intervention that surfaces rare semantics inside MM-DiTs without\nadditional training steps, data, denoising-time optimization, or reliance on\nexternal modules (e.g., large language models). In particular, the\njoint-attention mechanism intrinsic to MM-DiT sequentially updates text\nembeddings alongside image embeddings throughout transformer blocks. We find\nthat by mathematically expanding representational basins around text token\nembeddings via variance scale-up before the joint-attention blocks, rare\nsemantics clearly emerge in MM-DiT's outputs. Furthermore, our results\ngeneralize effectively across text-to-vision tasks, including text-to-image,\ntext-to-video, and text-driven image editing. Our work invites generative\nmodels to reveal the semantics that users intend, once hidden yet ready to\nsurface.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3001\u6570\u636e\u6216\u5916\u90e8\u6a21\u5757\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8054\u5408\u6ce8\u610f\u529b\u5757\u524d\u6269\u5927\u6587\u672c\u6807\u8bb0\u5d4c\u5165\u7684\u8868\u793a\u8303\u56f4\uff0c\u4f7f\u591a\u6a21\u6001\u6269\u6563\u53d8\u6362\u5668\u80fd\u591f\u751f\u6210\u7f55\u89c1\u8bed\u4e49\u5185\u5bb9\u3002", "motivation": "\u5f53\u524d\u5148\u8fdb\u7684\u591a\u6a21\u6001\u6269\u6563\u53d8\u6362\u5668\u5728\u5904\u7406\u7528\u6237\u5bcc\u6709\u60f3\u8c61\u529b\u6216\u7f55\u89c1\u7684\u63d0\u793a\u65f6\u4ecd\u7136\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6982\u5ff5\u5728\u9884\u8bad\u7ec3\u4e2d\u8fc7\u4e8e\u7a00\u7f3a\uff0c\u96be\u4ee5\u5f62\u6210\u5f3a\u8868\u5f81\u3002", "method": "\u5728\u8054\u5408\u6ce8\u610f\u529b\u673a\u5236\u524d\uff0c\u901a\u8fc7\u6570\u5b66\u65b9\u6cd5\u6269\u5927\u6587\u672c\u6807\u8bb0\u5d4c\u5165\u7684\u8868\u793a\u8303\u56f4\uff0c\u589e\u52a0\u5176\u65b9\u5dee\uff0c\u4ece\u800c\u589e\u5f3a\u7f55\u89c1\u8bed\u4e49\u7684\u8868\u5f81\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5728\u591a\u6a21\u6001\u6269\u6563\u53d8\u6362\u5668\u4e2d\u6d6e\u73b0\u7f55\u89c1\u8bed\u4e49\uff0c\u5e76\u5728\u6587\u672c\u5230\u56fe\u50cf\u3001\u6587\u672c\u5230\u89c6\u9891\u548c\u6587\u672c\u9a71\u52a8\u56fe\u50cf\u7f16\u8f91\u7b49\u4efb\u52a1\u4e2d\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u751f\u6210\u6a21\u578b\u80fd\u591f\u5c55\u73b0\u7528\u6237\u610f\u56fe\u4e2d\u539f\u672c\u9690\u85cf\u4f46\u51c6\u5907\u6d6e\u73b0\u7684\u8bed\u4e49\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u5bf9\u7f55\u89c1\u6982\u5ff5\u751f\u6210\u80fd\u529b\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03892", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03892", "abs": "https://arxiv.org/abs/2510.03892", "authors": ["Zahra Atf", "Peter R. Lewis"], "title": "Kantian-Utilitarian XAI: Meta-Explained", "comment": "Accepted for presentation as a poster at the 35th IEEE International\n  Conference on Collaborative Advances in Software and Computing, 2025.\n  Conference\n  website:https://conf.researchr.org/details/cascon-2025/posters-track/1/Kantian-Utilitarian-XAI-Meta-Explained", "summary": "We present a gamified explainable AI (XAI) system for ethically aware\nconsumer decision-making in the coffee domain. Each session comprises six\nrounds with three options per round. Two symbolic engines provide real-time\nreasons: a Kantian module flags rule violations (e.g., child labor,\ndeforestation risk without shade certification, opaque supply chains, unsafe\ndecaf), and a utilitarian module scores options via multi-criteria aggregation\nover normalized attributes (price, carbon, water, transparency, farmer income\nshare, taste/freshness, packaging, convenience). A meta-explainer with a regret\nbound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a\ndeontically clean, near-parity option when welfare loss is small. We release a\nstructured configuration (attribute schema, certification map, weights, rule\nset), a policy trace for auditability, and an interactive UI.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6e38\u620f\u5316\u53ef\u89e3\u91caAI\u7cfb\u7edf\uff0c\u7528\u4e8e\u5496\u5561\u9886\u57df\u7684\u9053\u5fb7\u6d88\u8d39\u51b3\u7b56\uff0c\u7ed3\u5408\u5eb7\u5fb7\u4e3b\u4e49\u548c\u529f\u5229\u4e3b\u4e49\u4f26\u7406\u6846\u67b6\u63d0\u4f9b\u5b9e\u65f6\u89e3\u91ca\u3002", "motivation": "\u5e2e\u52a9\u6d88\u8d39\u8005\u5728\u8d2d\u4e70\u5496\u5561\u65f6\u505a\u51fa\u66f4\u9053\u5fb7\u7684\u51b3\u7b56\uff0c\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u4f26\u7406\u89c6\u89d2\u63d0\u4f9b\u900f\u660e\u7684\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u516d\u4e2a\u56de\u5408\uff0c\u6bcf\u56de\u5408\u4e09\u4e2a\u9009\u9879\u3002\u4f7f\u7528\u5eb7\u5fb7\u4e3b\u4e49\u6a21\u5757\u68c0\u6d4b\u89c4\u5219\u8fdd\u53cd\uff0c\u529f\u5229\u4e3b\u4e49\u6a21\u5757\u901a\u8fc7\u591a\u6807\u51c6\u805a\u5408\u8bc4\u5206\uff0c\u5143\u89e3\u91ca\u5668\u5904\u7406\u4f26\u7406\u51b2\u7a81\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u7cfb\u7edf\u914d\u7f6e\u3001\u53ef\u5ba1\u8ba1\u7684\u653f\u7b56\u8f68\u8ff9\u548c\u4ea4\u4e92\u5f0f\u7528\u6237\u754c\u9762\uff0c\u652f\u6301\u9053\u5fb7\u6d88\u8d39\u51b3\u7b56\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u6574\u5408\u4e86\u4e0d\u540c\u4f26\u7406\u6846\u67b6\uff0c\u4e3a\u6d88\u8d39\u8005\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u9053\u5fb7\u51b3\u7b56\u5de5\u5177\u3002"}}
{"id": "2510.03969", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03969", "abs": "https://arxiv.org/abs/2510.03969", "authors": ["Chengxiao Wang", "Isha Chaudhary", "Qian Hu", "Weitong Ruan", "Rahul Gupta", "Gagandeep Singh"], "title": "Quantifying Risks in Multi-turn Conversation with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) can produce catastrophic responses in\nconversational settings that pose serious risks to public safety and security.\nExisting evaluations often fail to fully reveal these vulnerabilities because\nthey rely on fixed attack prompt sequences, lack statistical guarantees, and do\nnot scale to the vast space of multi-turn conversations. In this work, we\npropose QRLLM, a novel, principled Certification framework for Catastrophic\nrisks in multi-turn Conversation for LLMs that bounds the probability of an LLM\ngenerating catastrophic responses under multi-turn conversation distributions\nwith statistical guarantees. We model multi-turn conversations as probability\ndistributions over query sequences, represented by a Markov process on a query\ngraph whose edges encode semantic similarity to capture realistic\nconversational flow, and quantify catastrophic risks using confidence\nintervals. We define several inexpensive and practical distributions: random\nnode, graph path, adaptive with rejection. Our results demonstrate that these\ndistributions can reveal substantial catastrophic risks in frontier models,\nwith certified lower bounds as high as 70\\% for the worst model, highlighting\nthe urgent need for improved safety training strategies in frontier LLMs.", "AI": {"tldr": "QRLLM\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u707e\u96be\u6027\u98ce\u9669\u7684\u6982\u7387\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u548c\u67e5\u8be2\u56fe\u5efa\u6a21\u5bf9\u8bdd\u5206\u5e03\uff0c\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u7684\u98ce\u9669\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u653b\u51fb\u63d0\u793a\u5e8f\u5217\uff0c\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u65e0\u6cd5\u6269\u5c55\u5230\u591a\u8f6e\u5bf9\u8bdd\u7684\u5e7f\u9614\u7a7a\u95f4\uff0c\u96be\u4ee5\u5145\u5206\u63ed\u793aLLM\u7684\u707e\u96be\u6027\u54cd\u5e94\u98ce\u9669\u3002", "method": "\u5c06\u591a\u8f6e\u5bf9\u8bdd\u5efa\u6a21\u4e3a\u67e5\u8be2\u5e8f\u5217\u7684\u6982\u7387\u5206\u5e03\uff0c\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u548c\u67e5\u8be2\u56fe\u8868\u793a\u5bf9\u8bdd\u6d41\u7a0b\uff0c\u5b9a\u4e49\u968f\u673a\u8282\u70b9\u3001\u56fe\u8def\u5f84\u3001\u81ea\u9002\u5e94\u62d2\u7edd\u7b49\u5b9e\u7528\u5206\u5e03\u6765\u91cf\u5316\u98ce\u9669\u3002", "result": "\u8fd9\u4e9b\u5206\u5e03\u80fd\u591f\u63ed\u793a\u524d\u6cbf\u6a21\u578b\u4e2d\u7684\u91cd\u5927\u707e\u96be\u6027\u98ce\u9669\uff0c\u6700\u5dee\u6a21\u578b\u7684\u8ba4\u8bc1\u4e0b\u754c\u9ad8\u8fbe70%\uff0c\u8868\u660e\u524d\u6cbfLLMs\u6025\u9700\u6539\u8fdb\u5b89\u5168\u8bad\u7ec3\u7b56\u7565\u3002", "conclusion": "QRLLM\u6846\u67b6\u4e3aLLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u707e\u96be\u6027\u98ce\u9669\u63d0\u4f9b\u4e86\u5177\u6709\u7edf\u8ba1\u4fdd\u8bc1\u7684\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u5b58\u5728\u7684\u4e25\u91cd\u5b89\u5168\u9690\u60a3\u3002"}}
{"id": "2510.04009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04009", "abs": "https://arxiv.org/abs/2510.04009", "authors": ["Zicong He", "Boxuan Zhang", "Weihao Liu", "Ruixiang Tang", "Lu Cheng"], "title": "What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models", "comment": "22 pages", "summary": "The meteoric rise of foundation models (FMs) has expanded their capabilities\nfar beyond conventional tasks. Creativity, long regarded as a hallmark of human\nintelligence and a driver of innovation, is now increasingly recognized as a\ncritical dimension of machine intelligence in the era of generative FMs,\ncomplementing traditional measures of accuracy. However, existing evaluation\nframeworks for creativity remain fragmented, relying on ad hoc metrics not\nfirmly grounded in established theories. To address this gap, we introduce\nC^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.\nC^2-Eval distinguishes between two complementary forms of creativity:\nconvergent creativity, where tasks admit constrained solutions (e.g., code\ngeneration), and divergent creativity, where tasks are open-ended (e.g.,\nstorytelling). It evaluates both dimensions using fine-grained criteria derived\nfrom social-science theory, focusing on Usefulness, Originality, and Surprise\n(U-O-S). Through extensive experiments on leading proprietary and open-source\nmodels, we analyze trade-offs in their creative capabilities. Our results\nhighlight both the strengths and challenges of current FMs in pursuing a\ncreative machine mind, showing that C^2-Eval is an effective lens for examining\nthe evolving landscape of creative AI.", "AI": {"tldr": "C^2-Eval\u662f\u4e00\u4e2a\u7528\u4e8e\u7edf\u4e00\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u521b\u9020\u529b\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u533a\u5206\u6536\u655b\u6027\u521b\u9020\u529b\u548c\u53d1\u6563\u6027\u521b\u9020\u529b\uff0c\u57fa\u4e8e\u6709\u7528\u6027\u3001\u539f\u521b\u6027\u548c\u60ca\u559c\u6027\u4e09\u4e2a\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u521b\u9020\u529b\u8bc4\u4f30\u6846\u67b6\u788e\u7247\u5316\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u6210\u719f\u7406\u8bba\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u8861\u91cf\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\u3002", "method": "\u63d0\u51faC^2-Eval\u57fa\u51c6\uff0c\u533a\u5206\u6536\u655b\u6027\u521b\u9020\u529b\uff08\u6709\u7ea6\u675f\u89e3\u7684\u4efb\u52a1\uff09\u548c\u53d1\u6563\u6027\u521b\u9020\u529b\uff08\u5f00\u653e\u5f0f\u4efb\u52a1\uff09\uff0c\u4f7f\u7528\u57fa\u4e8e\u793e\u4f1a\u79d1\u5b66\u7406\u8bba\u7684\u6709\u7528\u6027\u3001\u539f\u521b\u6027\u548c\u60ca\u559c\u6027\u4e09\u4e2a\u7ec6\u7c92\u5ea6\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5bf9\u9886\u5148\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u5728\u521b\u9020\u529b\u80fd\u529b\u4e0a\u7684\u6743\u8861\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u7840\u6a21\u578b\u5728\u8ffd\u6c42\u521b\u9020\u6027\u673a\u5668\u667a\u80fd\u65b9\u9762\u7684\u4f18\u52bf\u548c\u6311\u6218\u3002", "conclusion": "C^2-Eval\u662f\u5ba1\u89c6\u521b\u9020\u6027AI\u53d1\u5c55\u683c\u5c40\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\u8868\u73b0\u3002"}}
{"id": "2510.04017", "categories": ["cs.AI", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.04017", "abs": "https://arxiv.org/abs/2510.04017", "authors": ["Sumanth Varambally", "Marshall Fisher", "Jas Thakker", "Yiwei Chen", "Zhirui Xia", "Yasaman Jafari", "Ruijia Niu", "Manas Jain", "Veeramakali Vignesh Manivannan", "Zachary Novack", "Luyu Han", "Srikar Eranky", "Salva R\u00fchling Cachay", "Taylor Berg-Kirkpatrick", "Duncan Watson-Parris", "Yi-An Ma", "Rose Yu"], "title": "Zephyrus: An Agentic Framework for Weather Science", "comment": null, "summary": "Foundation models for weather science are pre-trained on vast amounts of\nstructured numerical data and outperform traditional weather forecasting\nsystems. However, these models lack language-based reasoning capabilities,\nlimiting their utility in interactive scientific workflows. Large language\nmodels (LLMs) excel at understanding and generating text but cannot reason\nabout high-dimensional meteorological datasets. We bridge this gap by building\na novel agentic framework for weather science. Our framework includes a Python\ncode-based environment for agents (ZephyrusWorld) to interact with weather\ndata, featuring tools like an interface to WeatherBench 2 dataset, geoquerying\nfor geographical masks from natural language, weather forecasting, and climate\nsimulation capabilities. We design Zephyrus, a multi-turn LLM-based weather\nagent that iteratively analyzes weather datasets, observes results, and refines\nits approach through conversational feedback loops. We accompany the agent with\na new benchmark, ZephyrusBench, with a scalable data generation pipeline that\nconstructs diverse question-answer pairs across weather-related tasks, from\nbasic lookups to advanced forecasting, extreme event detection, and\ncounterfactual reasoning. Experiments on this benchmark demonstrate the strong\nperformance of Zephyrus agents over text-only baselines, outperforming them by\nup to 35 percentage points in correctness. However, on harder tasks, Zephyrus\nperforms similarly to text-only baselines, highlighting the challenging nature\nof our benchmark and suggesting promising directions for future work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Zephyrus\u6846\u67b6\uff0c\u5c06\u5929\u6c14\u9884\u62a5\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u521b\u5efa\u80fd\u591f\u901a\u8fc7\u4ee3\u7801\u73af\u5883\u4e0e\u6c14\u8c61\u6570\u636e\u4ea4\u4e92\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u57fa\u51c6\u6d4b\u8bd5ZephyrusBench\u3002", "motivation": "\u73b0\u6709\u7684\u5929\u6c14\u9884\u62a5\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u9ad8\u7ef4\u6c14\u8c61\u6570\u636e\uff0c\u9700\u8981\u6784\u5efa\u80fd\u591f\u6865\u63a5\u8fd9\u4e24\u79cd\u80fd\u529b\u7684\u667a\u80fd\u4f53\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8ePython\u4ee3\u7801\u7684\u73af\u5883ZephyrusWorld\uff0c\u5305\u542bWeatherBench 2\u6570\u636e\u96c6\u63a5\u53e3\u3001\u5730\u7406\u67e5\u8be2\u3001\u5929\u6c14\u9884\u62a5\u548c\u6c14\u5019\u6a21\u62df\u7b49\u5de5\u5177\uff0c\u8bbe\u8ba1\u4e86\u591a\u8f6eLLM\u5929\u6c14\u667a\u80fd\u4f53Zephyrus\uff0c\u901a\u8fc7\u5bf9\u8bdd\u53cd\u9988\u5faa\u73af\u8fed\u4ee3\u5206\u6790\u6570\u636e\u3002", "result": "\u5728ZephyrusBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cZephyrus\u667a\u80fd\u4f53\u5728\u6b63\u786e\u6027\u4e0a\u6bd4\u7eaf\u6587\u672c\u57fa\u7ebf\u9ad8\u51fa35\u4e2a\u767e\u5206\u70b9\uff0c\u4f46\u5728\u66f4\u56f0\u96be\u4efb\u52a1\u4e0a\u8868\u73b0\u76f8\u4f3c\uff0c\u8868\u660e\u57fa\u51c6\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u5929\u6c14\u9884\u62a5\u6a21\u578b\u548c\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u5929\u6c14\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u7684\u65b9\u5411\u3002"}}
{"id": "2510.04023", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04023", "abs": "https://arxiv.org/abs/2510.04023", "authors": ["Mizanur Rahman", "Amran Bhuiyan", "Mohammed Saidul Islam", "Md Tahmid Rahman Laskar", "Ridwan Mahbub", "Ahmed Masry", "Shafiq Joty", "Enamul Hoque"], "title": "LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions", "comment": "Survey paper; 45 data science agents; under review", "summary": "Recent advances in large language models (LLMs) have enabled a new class of\nAI agents that automate multiple stages of the data science workflow by\nintegrating planning, tool use, and multimodal reasoning across text, code,\ntables, and visuals. This survey presents the first comprehensive,\nlifecycle-aligned taxonomy of data science agents, systematically analyzing and\nmapping forty-five systems onto the six stages of the end-to-end data science\nprocess: business understanding and data acquisition, exploratory analysis and\nvisualization, feature engineering, model building and selection,\ninterpretation and explanation, and deployment and monitoring. In addition to\nlifecycle coverage, we annotate each agent along five cross-cutting design\ndimensions: reasoning and planning style, modality integration, tool\norchestration depth, learning and alignment methods, and trust, safety, and\ngovernance mechanisms. Beyond classification, we provide a critical synthesis\nof agent capabilities, highlight strengths and limitations at each stage, and\nreview emerging benchmarks and evaluation practices. Our analysis identifies\nthree key trends: most systems emphasize exploratory analysis, visualization,\nand modeling while neglecting business understanding, deployment, and\nmonitoring; multimodal reasoning and tool orchestration remain unresolved\nchallenges; and over 90% lack explicit trust and safety mechanisms. We conclude\nby outlining open challenges in alignment stability, explainability,\ngovernance, and robust evaluation frameworks, and propose future research\ndirections to guide the development of robust, trustworthy, low-latency,\ntransparent, and broadly accessible data science agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5168\u9762\u7684\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u5206\u7c7b\u6cd5\uff0c\u7cfb\u7edf\u5206\u6790\u4e8645\u4e2a\u7cfb\u7edf\u5728\u6570\u636e\u79d1\u5b66\u5168\u6d41\u7a0b\u516d\u4e2a\u9636\u6bb5\u7684\u8868\u73b0\uff0c\u5e76\u8bc6\u522b\u51fa\u4e09\u4e2a\u5173\u952e\u8d8b\u52bf\uff1a\u5927\u591a\u6570\u7cfb\u7edf\u4fa7\u91cd\u63a2\u7d22\u5206\u6790\u548c\u5efa\u6a21\uff0c\u800c\u5ffd\u89c6\u4e1a\u52a1\u7406\u89e3\u548c\u90e8\u7f72\u76d1\u63a7\uff1b\u591a\u6a21\u6001\u63a8\u7406\u548c\u5de5\u5177\u7f16\u6392\u4ecd\u662f\u6311\u6218\uff1b90%\u4ee5\u4e0a\u7f3a\u4e4f\u660e\u786e\u7684\u4fe1\u4efb\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u80fd\u591f\u81ea\u52a8\u5316\u6570\u636e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b0\u578bAI\u667a\u80fd\u4f53\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u548c\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u751f\u547d\u5468\u671f\u5bf9\u9f50\u7684\u5206\u7c7b\u6cd5\uff0c\u5c0645\u4e2a\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u7cfb\u7edf\u6620\u5c04\u5230\u6570\u636e\u79d1\u5b66\u7684\u516d\u4e2a\u9636\u6bb5\uff0c\u5e76\u4ece\u4e94\u4e2a\u4ea4\u53c9\u8bbe\u8ba1\u7ef4\u5ea6\u8fdb\u884c\u6807\u6ce8\uff1a\u63a8\u7406\u89c4\u5212\u98ce\u683c\u3001\u6a21\u6001\u96c6\u6210\u3001\u5de5\u5177\u7f16\u6392\u6df1\u5ea6\u3001\u5b66\u4e60\u5bf9\u9f50\u65b9\u6cd5\u3001\u4fe1\u4efb\u5b89\u5168\u6cbb\u7406\u673a\u5236\u3002", "result": "\u5206\u6790\u53d1\u73b0\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u5728\u63a2\u7d22\u5206\u6790\u3001\u53ef\u89c6\u5316\u548c\u5efa\u6a21\u9636\u6bb5\u8868\u73b0\u8f83\u5f3a\uff0c\u4f46\u5728\u4e1a\u52a1\u7406\u89e3\u3001\u90e8\u7f72\u548c\u76d1\u63a7\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff1b\u591a\u6a21\u6001\u63a8\u7406\u548c\u5de5\u5177\u7f16\u6392\u4ecd\u662f\u4e3b\u8981\u6311\u6218\uff1b\u7edd\u5927\u591a\u6570\u7cfb\u7edf\u7f3a\u4e4f\u660e\u786e\u7684\u4fe1\u4efb\u548c\u5b89\u5168\u673a\u5236\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u5bf9\u9f50\u7a33\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6cbb\u7406\u548c\u9c81\u68d2\u8bc4\u4f30\u6846\u67b6\u7b49\u6311\u6218\uff0c\u65e8\u5728\u6307\u5bfc\u5f00\u53d1\u66f4\u7a33\u5065\u3001\u53ef\u4fe1\u3001\u4f4e\u5ef6\u8fdf\u3001\u900f\u660e\u548c\u5e7f\u6cdb\u53ef\u8bbf\u95ee\u7684\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u3002"}}
{"id": "2510.04033", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04033", "abs": "https://arxiv.org/abs/2510.04033", "authors": ["Ayush Noori", "Adam Rodman", "Alan Karthikesalingam", "Bilal A. Mateen", "Christopher A. Longhurst", "Daniel Yang", "Dave deBronkart", "Gauden Galea", "Harold F. Wolf III", "Jacob Waxman", "Joshua C. Mandel", "Juliana Rotich", "Kenneth D. Mandl", "Maryam Mustafa", "Melissa Miles", "Nigam H. Shah", "Peter Lee", "Robert Korom", "Scott Mahoney", "Seth Hain", "Tien Yin Wong", "Trevor Mundel", "Vivek Natarajan", "Noa Dagan", "David A. Clifton", "Ran D. Balicer", "Isaac S. Kohane", "Marinka Zitnik"], "title": "A global log for medical AI", "comment": null, "summary": "Modern computer systems often rely on syslog, a simple, universal protocol\nthat records every critical event across heterogeneous infrastructure. However,\nhealthcare's rapidly growing clinical AI stack has no equivalent. As hospitals\nrush to pilot large language models and other AI-based clinical decision\nsupport tools, we still lack a standard way to record how, when, by whom, and\nfor whom these AI models are used. Without that transparency and visibility, it\nis challenging to measure real-world performance and outcomes, detect adverse\nevents, or correct bias or dataset drift. In the spirit of syslog, we introduce\nMedLog, a protocol for event-level logging of clinical AI. Any time an AI model\nis invoked to interact with a human, interface with another algorithm, or act\nindependently, a MedLog record is created. This record consists of nine core\nfields: header, model, user, target, inputs, artifacts, outputs, outcomes, and\nfeedback, providing a structured and consistent record of model activity. To\nencourage early adoption, especially in low-resource settings, and minimize the\ndata footprint, MedLog supports risk-based sampling, lifecycle-aware retention\npolicies, and write-behind caching; detailed traces for complex, agentic, or\nmulti-stage workflows can also be captured under MedLog. MedLog can catalyze\nthe development of new databases and software to store and analyze MedLog\nrecords. Realizing this vision would enable continuous surveillance, auditing,\nand iterative improvement of medical AI, laying the foundation for a new form\nof digital epidemiology.", "AI": {"tldr": "\u63d0\u51faMedLog\u534f\u8bae\uff0c\u7528\u4e8e\u4e34\u5e8aAI\u7684\u4e8b\u4ef6\u7ea7\u65e5\u5fd7\u8bb0\u5f55\uff0c\u7c7b\u4f3c\u4e8e\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e2d\u7684syslog\uff0c\u65e8\u5728\u89e3\u51b3\u533b\u7597AI\u7f3a\u4e4f\u6807\u51c6\u4f7f\u7528\u8bb0\u5f55\u7684\u95ee\u9898\u3002", "motivation": "\u533b\u7597AI\u5feb\u901f\u53d1\u5c55\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u4f7f\u7528\u8bb0\u5f55\u673a\u5236\uff0c\u96be\u4ee5\u8ffd\u8e2a\u6a21\u578b\u4f7f\u7528\u60c5\u51b5\u3001\u8bc4\u4f30\u771f\u5b9e\u6027\u80fd\u3001\u68c0\u6d4b\u4e0d\u826f\u4e8b\u4ef6\u6216\u7ea0\u6b63\u504f\u5dee\uff0c\u9700\u8981\u7c7b\u4f3csyslog\u7684\u901a\u7528\u65e5\u5fd7\u534f\u8bae\u3002", "method": "\u8bbe\u8ba1\u5305\u542b9\u4e2a\u6838\u5fc3\u5b57\u6bb5\u7684MedLog\u8bb0\u5f55\u683c\u5f0f\uff1aheader\u3001model\u3001user\u3001target\u3001inputs\u3001artifacts\u3001outputs\u3001outcomes\u3001feedback\uff0c\u652f\u6301\u98ce\u9669\u91c7\u6837\u3001\u751f\u547d\u5468\u671f\u611f\u77e5\u4fdd\u7559\u7b56\u7565\u548c\u5199\u540e\u7f13\u5b58\u3002", "result": "MedLog\u534f\u8bae\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u4e34\u5e8aAI\u6d3b\u52a8\u8bb0\u5f55\u6807\u51c6\uff0c\u80fd\u591f\u6355\u83b7\u590d\u6742\u5de5\u4f5c\u6d41\u7a0b\u7684\u8be6\u7ec6\u8f68\u8ff9\uff0c\u4fc3\u8fdb\u65b0\u6570\u636e\u5e93\u548c\u5206\u6790\u5de5\u5177\u7684\u5f00\u53d1\u3002", "conclusion": "MedLog\u4e3a\u5b9e\u73b0\u533b\u7597AI\u7684\u6301\u7eed\u76d1\u63a7\u3001\u5ba1\u8ba1\u548c\u8fed\u4ee3\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u671b\u50ac\u751f\u65b0\u578b\u6570\u5b57\u6d41\u884c\u75c5\u5b66\u65b9\u6cd5\u3002"}}
{"id": "2510.04040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04040", "abs": "https://arxiv.org/abs/2510.04040", "authors": ["Xu Shen", "Song Wang", "Zhen Tan", "Laura Yao", "Xinyu Zhao", "Kaidi Xu", "Xin Wang", "Tianlong Chen"], "title": "FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning", "comment": null, "summary": "Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)\nprompting to improve problem-solving and provide seemingly transparent\nexplanations. However, growing evidence shows that CoT often fail to faithfully\nrepresent the underlying reasoning process, raising concerns about their\nreliability in high-risk applications. Although prior studies have focused on\nmechanism-level analyses showing that CoTs can be unfaithful, they leave open\nthe practical challenge of deciding whether a specific trajectory is faithful\nto the internal reasoning of the model. To address this gap, we introduce\nFaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness\ndetection. Our framework establishes a rigorous task formulation that\nformulates unfaithfulness detection as a discriminative decision problem, and\nprovides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an\nexpert-annotated collection of over 1,000 trajectories generated by four\nrepresentative LLMs across four domains, including more than 300 unfaithful\ninstances with fine-grained causes and step-level evidence. We further conduct\na systematic evaluation of eleven representative detection methods spanning\ncounterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical\ninsights that clarify the strengths and weaknesses of existing approaches and\nreveal the increased challenges of detection in knowledge-intensive domains and\nwith more advanced models. To the best of our knowledge, FaithCoT-Bench\nestablishes the first comprehensive benchmark for instance-level CoT\nfaithfulness, setting a solid basis for future research toward more\ninterpretable and trustworthy reasoning in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86FaithCoT-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u68c0\u6d4bLLM\u4e2d\u601d\u7ef4\u94fe(CoT)\u7684\u4e0d\u5fe0\u5b9e\u6027\uff0c\u5305\u542b1000\u591a\u4e2a\u8f68\u8ff9\u548c300\u591a\u4e2a\u4e0d\u5fe0\u5b9e\u5b9e\u4f8b\uff0c\u8bc4\u4f30\u4e8611\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u663e\u793aCoT\u5f80\u5f80\u4e0d\u80fd\u5fe0\u5b9e\u53cd\u6620\u6a21\u578b\u7684\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u5728\u5b9e\u4f8b\u5c42\u9762\u5224\u65ad\u7279\u5b9a\u8f68\u8ff9\u662f\u5426\u5fe0\u5b9e\u4ecd\u662f\u4e00\u4e2a\u5b9e\u9645\u6311\u6218\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u57fa\u51c6FaithCoT-Bench\uff0c\u5305\u542bFINE-CoT\u6570\u636e\u96c6\uff08\u4e13\u5bb6\u6807\u6ce8\u76841000+\u8f68\u8ff9\uff09\uff0c\u5c06\u4e0d\u5fe0\u5b9e\u6027\u68c0\u6d4b\u5b9a\u4e49\u4e3a\u5224\u522b\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f3011\u79cd\u4ee3\u8868\u6027\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u63ed\u793a\u4e86\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u53d1\u73b0\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u548c\u66f4\u5148\u8fdb\u6a21\u578b\u4e2d\u68c0\u6d4b\u6311\u6218\u66f4\u5927\u3002", "conclusion": "FaithCoT-Bench\u4e3a\u5b9e\u4f8b\u7ea7CoT\u5fe0\u5b9e\u6027\u68c0\u6d4b\u5efa\u7acb\u4e86\u9996\u4e2a\u5168\u9762\u57fa\u51c6\uff0c\u4e3aLLM\u4e2d\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u7684\u63a8\u7406\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.04048", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04048", "abs": "https://arxiv.org/abs/2510.04048", "authors": ["Aparna Nair-Kanneganti", "Trevor J. Chan", "Shir Goldfinger", "Emily Mackay", "Brian Anthony", "Alison Pouch"], "title": "Increasing LLM response trustworthiness using voting ensembles", "comment": null, "summary": "Despite huge advances, LLMs still lack convenient and reliable methods to\nquantify the uncertainty in their responses, making them difficult to trust in\nhigh-stakes applications. One of the simplest approaches to eliciting more\naccurate answers is to select the mode of many responses, a technique known as\nensembling. In this work, we expand on typical ensembling approaches by looking\nat ensembles with a variable voting threshold. We introduce a theoretical\nframework for question answering and show that, by permitting ensembles to\n\"abstain\" from providing an answer when the dominant response falls short of\nthe threshold, it is possible to dramatically increase the trustworthiness of\nthe remaining answers. From this framework, we derive theoretical results as\nwell as report experimental results on two problem domains: arithmetic problem\nsolving and clinical-note question-answering. In both domains, we observe that\nlarge gains in answer trustworthiness can be achieved using highly restrictive\nvoting ensembles, while incurring relatively modest reductions in response\nyield and accuracy. Due to this quality, voting ensembles may be particularly\nuseful in applications - such as healthcare and data annotation - that require\na high degree of certainty but which may not require that every question\nreceive an automated answer.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.04051", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04051", "abs": "https://arxiv.org/abs/2510.04051", "authors": ["Lele Liao", "Qile Zhang", "Ruofan Wu", "Guanhua Fang"], "title": "Toward a unified framework for data-efficient evaluation of large language models", "comment": "codes available at https://github.com/Rorschach1989/efficient-lm-eval", "summary": "Evaluating large language models (LLMs) on comprehensive benchmarks is a\ncornerstone of their development, yet it's often computationally and\nfinancially prohibitive. While Item Response Theory (IRT) offers a promising\npath toward data-efficient evaluation by disentangling model capability from\nitem difficulty, existing IRT-based methods are hampered by significant\nlimitations. They are typically restricted to binary correctness metrics,\nfailing to natively handle the continuous scores used in generative tasks, and\nthey operate on single benchmarks, ignoring valuable structural knowledge like\ncorrelations across different metrics or benchmarks. To overcome these\nchallenges, we introduce LEGO-IRT, a unified and flexible framework for\ndata-efficient LLM evaluation. LEGO-IRT's novel design natively supports both\nbinary and continuous evaluation metrics. Moreover, it introduces a factorized\narchitecture to explicitly model and leverage structural knowledge, decomposing\nmodel ability estimates into a general component and structure-specific (e.g.,\nper-metric or per-benchmark) components. Through extensive experiments\ninvolving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves\nstable capability estimates using just $3\\%$ of the total evaluation items. We\ndemonstrate that incorporating structural knowledge reduces estimation error by\nup to $10\\%$ and reveal that the latent abilities estimated by our framework\nmay align more closely with human preferences.", "AI": {"tldr": "LEGO-IRT\u662f\u4e00\u4e2a\u7edf\u4e00\u7075\u6d3b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u8bc4\u4f30\uff0c\u652f\u6301\u4e8c\u5143\u548c\u8fde\u7eed\u8bc4\u5206\u6307\u6807\uff0c\u5e76\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u51cf\u5c11\u4f30\u8ba1\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eIRT\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u9650\u5236\uff1a\u4ec5\u652f\u6301\u4e8c\u5143\u6b63\u786e\u6027\u6307\u6807\uff0c\u65e0\u6cd5\u5904\u7406\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8fde\u7eed\u5206\u6570\uff1b\u4e14\u4ec5\u9488\u5bf9\u5355\u4e00\u57fa\u51c6\uff0c\u5ffd\u7565\u4e86\u8de8\u4e0d\u540c\u6307\u6807\u6216\u57fa\u51c6\u7684\u76f8\u5173\u6027\u7b49\u7ed3\u6784\u5316\u77e5\u8bc6\u3002", "method": "\u63d0\u51faLEGO-IRT\u6846\u67b6\uff0c\u5176\u521b\u65b0\u8bbe\u8ba1\u539f\u751f\u652f\u6301\u4e8c\u5143\u548c\u8fde\u7eed\u8bc4\u4f30\u6307\u6807\uff0c\u5f15\u5165\u56e0\u5b50\u5316\u67b6\u6784\u663e\u5f0f\u5efa\u6a21\u548c\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u5c06\u6a21\u578b\u80fd\u529b\u4f30\u8ba1\u5206\u89e3\u4e3a\u901a\u7528\u7ec4\u4ef6\u548c\u7ed3\u6784\u7279\u5b9a\u7ec4\u4ef6\u3002", "result": "\u5728\u6d89\u53ca70\u4e2aLLM\u548c5\u4e2a\u57fa\u51c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cLEGO-IRT\u4ec5\u4f7f\u7528\u603b\u8bc4\u4f30\u9879\u76ee\u76843%\u5c31\u80fd\u83b7\u5f97\u7a33\u5b9a\u7684\u80fd\u529b\u4f30\u8ba1\u3002\u878d\u5165\u7ed3\u6784\u5316\u77e5\u8bc6\u53ef\u5c06\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u9ad8\u8fbe10%\uff0c\u4e14\u5176\u4f30\u8ba1\u7684\u6f5c\u5728\u80fd\u529b\u4e0e\u4eba\u7c7b\u504f\u597d\u66f4\u4e00\u81f4\u3002", "conclusion": "LEGO-IRT\u4e3a\u6570\u636e\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bc4\u4f30\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u4f30\u8ba1\u8bef\u5dee\u3002"}}
{"id": "2510.04064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04064", "abs": "https://arxiv.org/abs/2510.04064", "authors": ["Jingxiang Zhang", "Lujia Zhong"], "title": "Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion", "comment": "10 pages, 7 figures, 4 tables. Under review", "summary": "Large Language Models (LLMs) are increasingly expected to navigate the\nnuances of human emotion. While research confirms that LLMs can simulate\nemotional intelligence, their internal emotional mechanisms remain largely\nunexplored. This paper investigates the latent emotional representations within\nmodern LLMs by asking: how, where, and for how long is emotion encoded in their\nneural architecture? To address this, we introduce a novel, large-scale Reddit\ncorpus of approximately 400,000 utterances, balanced across seven basic\nemotions through a multi-stage process of classification, rewriting, and\nsynthetic generation. Using this dataset, we employ lightweight \"probes\" to\nread out information from the hidden layers of various Qwen3 and LLaMA models\nwithout altering their parameters. Our findings reveal that LLMs develop a\nsurprisingly well-defined internal geometry of emotion, which sharpens with\nmodel scale and significantly outperforms zero-shot prompting. We demonstrate\nthat this emotional signal is not a final-layer phenomenon but emerges early\nand peaks mid-network. Furthermore, the internal states are both malleable\n(they can be influenced by simple system prompts) and persistent, as the\ninitial emotional tone remains detectable for hundreds of subsequent tokens. We\ncontribute our dataset, an open-source probing toolkit, and a detailed map of\nthe emotional landscape within LLMs, offering crucial insights for developing\nmore transparent and aligned AI systems. The code and dataset are open-sourced.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u7684\u60c5\u611f\u8868\u793a\u673a\u5236\uff0c\u53d1\u73b0LLMs\u5177\u6709\u6e05\u6670\u7684\u60c5\u611f\u51e0\u4f55\u7ed3\u6784\uff0c\u60c5\u611f\u4fe1\u53f7\u5728\u7f51\u7edc\u4e2d\u5c42\u51fa\u73b0\u5e76\u6301\u7eed\u5b58\u5728\uff0c\u4e14\u53ef\u901a\u8fc7\u7cfb\u7edf\u63d0\u793a\u8fdb\u884c\u8c03\u63a7\u3002", "motivation": "\u867d\u7136\u7814\u7a76\u8bc1\u5b9eLLMs\u80fd\u591f\u6a21\u62df\u60c5\u611f\u667a\u80fd\uff0c\u4f46\u5176\u5185\u90e8\u60c5\u611f\u673a\u5236\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u73b0\u4ee3LLMs\u4e2d\u6f5c\u5728\u7684\u60c5\u611f\u8868\u793a\uff1a\u60c5\u611f\u662f\u5982\u4f55\u3001\u5728\u54ea\u91cc\u4ee5\u53ca\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u6301\u7eed\u591a\u957f\u65f6\u95f4\u88ab\u7f16\u7801\u7684\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea640\u4e07\u6761\u8bdd\u8bed\u7684\u5927\u89c4\u6a21Reddit\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u5206\u7c7b\u3001\u91cd\u5199\u548c\u5408\u6210\u751f\u6210\u5e73\u8861\u4e03\u79cd\u57fa\u672c\u60c5\u611f\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\"\u63a2\u9488\"\u4ece\u5404\u79cdQwen3\u548cLLaMA\u6a21\u578b\u7684\u9690\u85cf\u5c42\u8bfb\u53d6\u4fe1\u606f\u800c\u4e0d\u6539\u53d8\u5176\u53c2\u6570\u3002", "result": "\u53d1\u73b0LLMs\u5f62\u6210\u4e86\u5b9a\u4e49\u826f\u597d\u7684\u5185\u90e8\u60c5\u611f\u51e0\u4f55\u7ed3\u6784\uff0c\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u66f4\u6e05\u6670\uff0c\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u3002\u60c5\u611f\u4fe1\u53f7\u4e0d\u662f\u6700\u7ec8\u5c42\u73b0\u8c61\uff0c\u800c\u662f\u65e9\u671f\u51fa\u73b0\u5e76\u5728\u7f51\u7edc\u4e2d\u5c42\u8fbe\u5230\u5cf0\u503c\u3002\u5185\u90e8\u72b6\u6001\u5177\u6709\u53ef\u5851\u6027\uff08\u53ef\u901a\u8fc7\u7b80\u5355\u7cfb\u7edf\u63d0\u793a\u5f71\u54cd\uff09\u548c\u6301\u4e45\u6027\uff08\u521d\u59cb\u60c5\u611f\u57fa\u8c03\u53ef\u5728\u6570\u767e\u4e2a\u540e\u7eed\u6807\u8bb0\u4e2d\u68c0\u6d4b\u5230\uff09\u3002", "conclusion": "\u63d0\u4f9b\u4e86LLMs\u5185\u90e8\u60c5\u611f\u666f\u89c2\u7684\u8be6\u7ec6\u56fe\u8c31\uff0c\u4e3a\u5f00\u53d1\u66f4\u900f\u660e\u548c\u5bf9\u9f50\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.04073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04073", "abs": "https://arxiv.org/abs/2510.04073", "authors": ["Santhosh Kumar Ravindran"], "title": "Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention", "comment": "11 pages Includes simulations with over 4 million steps", "summary": "The rise of artificial intelligence (AI) as super-capable assistants has\ntransformed productivity and decision-making across domains. Yet, this\nintegration raises critical concerns about value alignment - ensuring AI\nbehaviors remain consistent with human ethics and intentions. A key risk is\nvalue drift, where AI systems deviate from aligned values due to evolving\ncontexts, learning dynamics, or unintended optimizations, potentially leading\nto inefficiencies or ethical breaches. We propose the Moral Anchor System\n(MAS), a novel framework to detect, predict, and mitigate value drift in AI\nagents. MAS combines real-time Bayesian inference for monitoring value states,\nLSTM networks for forecasting drift, and a human-centric governance layer for\nadaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent\nbreaches, while reducing false positives and alert fatigue via supervised\nfine-tuning with human feedback. Our hypothesis: integrating probabilistic\ndrift detection, predictive analytics, and adaptive governance can reduce value\ndrift incidents by 80 percent or more in simulations, maintaining high\ndetection accuracy (85 percent) and low false positive rates (0.08\npost-adaptation). Rigorous experiments with goal-misaligned agents validate\nMAS's scalability and responsiveness. MAS's originality lies in its predictive\nand adaptive nature, contrasting static alignment methods. Contributions\ninclude: (1) MAS architecture for AI integration; (2) empirical results\nprioritizing speed and usability; (3) cross-domain applicability insights; and\n(4) open-source code for replication.", "AI": {"tldr": "\u63d0\u51faMoral Anchor System (MAS)\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u8d1d\u53f6\u65af\u63a8\u7406\u3001LSTM\u7f51\u7edc\u9884\u6d4b\u548c\u4eba\u7c7b\u4e2d\u5fc3\u6cbb\u7406\u5c42\u6765\u68c0\u6d4b\u3001\u9884\u6d4b\u548c\u7f13\u89e3AI\u7cfb\u7edf\u4e2d\u7684\u4ef7\u503c\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u968f\u7740AI\u52a9\u624b\u5728\u5404\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fddAI\u884c\u4e3a\u4e0e\u4eba\u7c7b\u4f26\u7406\u548c\u610f\u56fe\u4fdd\u6301\u4e00\u81f4\u7684\u4ef7\u503c\u5bf9\u9f50\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4ef7\u503c\u6f02\u79fb\u98ce\u9669\u53ef\u80fd\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u6216\u4f26\u7406\u8fdd\u89c4\u3002", "method": "MAS\u7ed3\u5408\u5b9e\u65f6\u8d1d\u53f6\u65af\u63a8\u7406\u76d1\u63a7\u4ef7\u503c\u72b6\u6001\u3001LSTM\u7f51\u7edc\u9884\u6d4b\u6f02\u79fb\u8d8b\u52bf\u3001\u4eba\u7c7b\u4e2d\u5fc3\u6cbb\u7406\u5c42\u8fdb\u884c\u81ea\u9002\u5e94\u5e72\u9884\uff0c\u5f3a\u8c03\u4f4e\u5ef6\u8fdf\u54cd\u5e94(<20ms)\u5e76\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cMAS\u80fd\u5c06\u4ef7\u503c\u6f02\u79fb\u4e8b\u4ef6\u51cf\u5c1180%\u4ee5\u4e0a\uff0c\u4fdd\u630185%\u7684\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u548c0.08\u7684\u4f4e\u8bef\u62a5\u7387\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u54cd\u5e94\u6027\u3002", "conclusion": "MAS\u7684\u521b\u65b0\u5728\u4e8e\u5176\u9884\u6d4b\u6027\u548c\u81ea\u9002\u5e94\u6027\uff0c\u76f8\u6bd4\u9759\u6001\u5bf9\u9f50\u65b9\u6cd5\u66f4\u6709\u6548\u3002\u8d21\u732e\u5305\u62ecMAS\u67b6\u6784\u8bbe\u8ba1\u3001\u5b9e\u8bc1\u7ed3\u679c\u3001\u8de8\u9886\u57df\u9002\u7528\u6027\u89c1\u89e3\u4ee5\u53ca\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2510.04089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04089", "abs": "https://arxiv.org/abs/2510.04089", "authors": ["Yitong Cui", "Liu Liu", "Baosheng Yu", "Jiayan Qiu", "Xikai Zhang", "Likang Xiao", "Yixing Liu", "Quan Chen"], "title": "SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows", "comment": null, "summary": "Large language models (LLMs) have exhibited significant capabilities in\naddressing challenging problems throughout various fields, often through the\nuse of agentic workflows that adhere to structured instructions and multi-step\nprocedures. However, designing such workflows demands substantial manual\neffort, posing challenges to scalability and generalizability. Recent studies\nhave aimed to minimize the human intervention needed for their construction,\nleading to advances in automated techniques for optimizing agentic workflows.\nHowever, current approaches are often constrained by their limited\nrepresentational capacity, insufficient adaptability, weak scalability, and\npairwise comparison paradigm -- issues that stem primarily from a dependence on\ndiscrete optimization techniques. To overcome these limitations, we introduce a\nnew score-based preference approach, refereed as SPOGW, which operates directly\non cardinal reward signals through group-wise comparison and enables more\nefficient and stable optimization in a continuous space. SPOGW incorporates\nIterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),\nwhich regulates training update by placing greater emphasis on the advantageous\nregions of the policy response. In five benchmark datasets covering\nmathematical reasoning, coding, and question answering, SPOGW matches or\nexceeds the performance of current state-of-the-art approaches, presenting a\nviable and forward-looking methodology for automated generation and\noptimization of agentic workflows.", "AI": {"tldr": "SPOGW\u662f\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5206\u6570\u7684\u504f\u597d\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ec4\u95f4\u6bd4\u8f83\u76f4\u63a5\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u8fdb\u884c\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u79bb\u6563\u4f18\u5316\u65b9\u6cd5\u5728\u8868\u793a\u80fd\u529b\u3001\u9002\u5e94\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6210\u5bf9\u6bd4\u8f83\u8303\u5f0f\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u79bb\u6563\u4f18\u5316\u7684\u81ea\u52a8\u5316\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u65b9\u6cd5\u5b58\u5728\u8868\u793a\u80fd\u529b\u6709\u9650\u3001\u9002\u5e94\u6027\u4e0d\u8db3\u3001\u53ef\u6269\u5c55\u6027\u5f31\u548c\u6210\u5bf9\u6bd4\u8f83\u8303\u5f0f\u7b49\u95ee\u9898\uff0c\u9700\u8981\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "SPOGW\u7ed3\u5408\u4e86\u8fed\u4ee3\u79bb\u7ebfGRPO\uff08ioGRPO\uff09\u548c\u4f18\u52bf\u63a9\u7801KL\u6563\u5ea6\uff08mKL\uff09\uff0c\u901a\u8fc7\u5f3a\u8c03\u7b56\u7565\u54cd\u5e94\u7684\u4f18\u52bf\u533a\u57df\u6765\u8c03\u8282\u8bad\u7ec3\u66f4\u65b0\u3002", "result": "\u5728\u4e94\u4e2a\u6db5\u76d6\u6570\u5b66\u63a8\u7406\u3001\u7f16\u7a0b\u548c\u95ee\u7b54\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSPOGW\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "SPOGW\u4e3a\u81ea\u52a8\u5316\u751f\u6210\u548c\u4f18\u5316\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u4e14\u524d\u77bb\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.04093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04093", "abs": "https://arxiv.org/abs/2510.04093", "authors": ["Guixian Zhang", "Guan Yuan", "Ziqi Xu", "Yanmei Zhang", "Zhenyun Deng", "Debo Cheng"], "title": "Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems", "comment": null, "summary": "Cognitive diagnostics in the Web-based Intelligent Education System (WIES)\naims to assess students' mastery of knowledge concepts from heterogeneous,\nnoisy interactions. Recent work has tried to utilize Large Language Models\n(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are\nprone to noise-induced misjudgments. Specially, WIES's open environment\ncontinuously attracts new students and produces vast amounts of response logs,\nexacerbating the data imbalance and noise issues inherent in traditional\neducational systems. To address these challenges, we propose DLLM, a\nDiffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first\nconstructs independent subgraphs based on response correctness, then applies\nrelation augmentation alignment module to mitigate data imbalance. The two\nsubgraph representations are then fused and aligned with LLM-derived,\nsemantically augmented representations. Importantly, before each alignment\nstep, DLLM employs a two-stage denoising diffusion module to eliminate\nintrinsic noise while assisting structural representation alignment.\nSpecifically, unconditional denoising diffusion first removes erroneous\ninformation, followed by conditional denoising diffusion based on graph-guided\nto eliminate misleading information. Finally, the noise-robust representation\nthat integrates semantic knowledge and structural information is fed into\nexisting cognitive diagnosis models for prediction. Experimental results on\nthree publicly available web-based educational platform datasets demonstrate\nthat our DLLM achieves optimal predictive performance across varying noise\nlevels, which demonstrates that DLLM achieves noise robustness while\neffectively leveraging semantic knowledge from LLM.", "AI": {"tldr": "\u63d0\u51faDLLM\u6846\u67b6\uff0c\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u589e\u5f3aLLM\u5728\u8ba4\u77e5\u8bca\u65ad\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u5b50\u56fe\u3001\u5173\u7cfb\u589e\u5f3a\u5bf9\u9f50\u548c\u4e24\u9636\u6bb5\u53bb\u566a\u6269\u6563\u6a21\u5757\uff0c\u6709\u6548\u5904\u7406\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u548c\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u8ba4\u77e5\u8bca\u65ad\u9762\u4e34\u7684\u6311\u6218\uff1aLLM\u96be\u4ee5\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u3001\u6613\u53d7\u566a\u58f0\u5e72\u6270\uff0c\u4ee5\u53ca\u5f00\u653e\u73af\u5883\u5e26\u6765\u7684\u6570\u636e\u4e0d\u5e73\u8861\u548c\u566a\u58f0\u52a0\u5267\u95ee\u9898\u3002", "method": "DLLM\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u7b54\u9898\u6b63\u786e\u6027\u6784\u5efa\u72ec\u7acb\u5b50\u56fe\uff1b2\uff09\u5173\u7cfb\u589e\u5f3a\u5bf9\u9f50\u6a21\u5757\u7f13\u89e3\u6570\u636e\u4e0d\u5e73\u8861\uff1b3\uff09\u4e24\u9636\u6bb5\u53bb\u566a\u6269\u6563\uff08\u65e0\u6761\u4ef6\u53bb\u566a+\u56fe\u5f15\u5bfc\u6761\u4ef6\u53bb\u566a\uff09\uff1b4\uff09\u878d\u5408\u8bed\u4e49\u589e\u5f3a\u8868\u793a\u4e0e\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u7f51\u7edc\u6559\u80b2\u5e73\u53f0\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDLLM\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u5747\u53d6\u5f97\u6700\u4f18\u9884\u6d4b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u566a\u58f0\u9c81\u68d2\u6027\u5e76\u6709\u6548\u5229\u7528\u4e86LLM\u7684\u8bed\u4e49\u77e5\u8bc6\u3002", "conclusion": "DLLM\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u8ba4\u77e5\u8bca\u65ad\u7684\u566a\u58f0\u548c\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u589e\u5f3aLLM\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04097", "abs": "https://arxiv.org/abs/2510.04097", "authors": ["Peichao Lai", "Jinhui Zhuang", "Kexuan Zhang", "Ningchang Xiong", "Shengjie Wang", "Yanwei Xu", "Chong Chen", "Yilei Wang", "Bin Cui"], "title": "WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning", "comment": null, "summary": "Automating the conversion of UI images into web code is a critical task for\nfront-end development and rapid prototyping. Advances in multimodal large\nlanguage models (MLLMs) have made WebUI-to-Code increasingly feasible, yet\nexisting benchmarks remain limited in data diversity and evaluation\nreliability. To address these issues, we present WebRenderBench, a large-scale\nbenchmark of 22.5k webpages collected from real-world portal sites, offering\ngreater diversity, complexity, and realism than prior benchmarks. We further\npropose a novel evaluation metric that measures layout and style consistency\nfrom the final rendered pages. Unlike vision-based methods that rely on costly\nLLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,\nour approach enables more efficient, objective, and reliable UI quality\nassessment. Finally, we introduce the Automated Layout and Style Inspection\nAgent (ALISA), which integrates this metric into reinforcement learning as a\nreward signal to enhance training on crawled asymmetric webpages. Experiments\nshow that ALISA significantly boosts generation performance, achieving\nstate-of-the-art results across multiple metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86WebRenderBench\u57fa\u51c6\u548cALISA\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdbUI\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\uff0c\u901a\u8fc7\u6e32\u67d3\u9875\u9762\u8bc4\u4f30\u5e03\u5c40\u548c\u6837\u5f0f\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5e94\u7528\u8be5\u6307\u6807\u63d0\u5347\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684WebUI-to-Code\u57fa\u51c6\u5728\u6570\u636e\u591a\u6837\u6027\u548c\u8bc4\u4f30\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u3001\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u548c\u66f4\u5ba2\u89c2\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e8622.5k\u771f\u5b9e\u7f51\u9875\u7684\u5927\u89c4\u6a21\u57fa\u51c6WebRenderBench\uff0c\u63d0\u51fa\u57fa\u4e8e\u6700\u7ec8\u6e32\u67d3\u9875\u9762\u7684\u5e03\u5c40\u548c\u6837\u5f0f\u4e00\u81f4\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5f00\u53d1\u4e86ALISA\u4ee3\u7406\u5c06\u8be5\u6307\u6807\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u3002", "result": "ALISA\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u66f4\u9ad8\u6548\u3001\u5ba2\u89c2\u548c\u53ef\u9760\u7684UI\u8d28\u91cf\u8bc4\u4f30\uff0c\u6709\u6548\u63d0\u5347\u4e86UI\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04116", "abs": "https://arxiv.org/abs/2510.04116", "authors": ["Ziying Zhang", "Yaqing Wang", "Quanming Yao"], "title": "Searching Meta Reasoning Skeleton to Guide LLM Reasoning", "comment": null, "summary": "Meta reasoning behaviors work as a skeleton to guide large language model\n(LLM) reasoning, thus help to improve reasoning performance. However, prior\nresearches implement meta reasoning skeleton with manually designed structure,\nlimiting ability to adapt to query-specific requirement and capture intricate\nlogical dependency among reasoning steps. To deal with the challenges, we\nrepresent meta reasoning skeleton with directed acyclic graph (DAG) to unify\nskeletons proposed in prior works and model intricate logical dependency. Then\nwe propose AutoMR, a framework that searches for query-aware meta reasoning\nskeleton automatically inspired by automated machine learning (AutoML).\nSpecifically, we construct search space based on DAG representation of skeleton\nand then formulate the search problem. We design a dynamic skeleton sampling\nalgorithm by expanding meta reasoning skeleton along with reasoning context at\ninference time. This algorithm can derive any meta reasoning skeleton in search\nspace efficiently and adapt skeleton to evolving base reasoning context, thus\nenable efficient query-aware skeleton search. We conduct experiments on\nextensive benchmark datasets. Experimental results show that AutoMR achieves\nbetter reasoning performance than previous works broadly.", "AI": {"tldr": "AutoMR\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u641c\u7d22\u67e5\u8be2\u611f\u77e5\u7684\u5143\u63a8\u7406\u9aa8\u67b6\uff0c\u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\u63a8\u7406\u7ed3\u6784\uff0c\u7ed3\u5408AutoML\u601d\u60f3\u5b9e\u73b0\u9ad8\u6548\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u624b\u52a8\u8bbe\u8ba1\u7684\u5143\u63a8\u7406\u9aa8\u67b6\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u9002\u5e94\u67e5\u8be2\u7279\u5b9a\u9700\u6c42\u7684\u80fd\u529b\uff0c\u4e14\u96be\u4ee5\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u95f4\u590d\u6742\u7684\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u63d0\u51faAutoMR\u6846\u67b6\uff1a1\uff09\u7528\u6709\u5411\u65e0\u73af\u56fe\u7edf\u4e00\u8868\u793a\u5143\u63a8\u7406\u9aa8\u67b6\uff1b2\uff09\u6784\u5efa\u641c\u7d22\u7a7a\u95f4\u5e76\u5b9a\u4e49\u641c\u7d22\u95ee\u9898\uff1b3\uff09\u8bbe\u8ba1\u52a8\u6001\u9aa8\u67b6\u91c7\u6837\u7b97\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u4e0a\u4e0b\u6587\u6269\u5c55\u9aa8\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAutoMR\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "AutoMR\u901a\u8fc7\u81ea\u52a8\u641c\u7d22\u67e5\u8be2\u611f\u77e5\u7684\u5143\u63a8\u7406\u9aa8\u67b6\uff0c\u80fd\u591f\u6709\u6548\u9002\u5e94\u5177\u4f53\u67e5\u8be2\u9700\u6c42\u5e76\u6355\u6349\u590d\u6742\u903b\u8f91\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.04128", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04128", "abs": "https://arxiv.org/abs/2510.04128", "authors": ["Dmitrii Troitskii", "Koyena Pal", "Chris Wendler", "Callum Stuart McDougall", "Neel Nanda"], "title": "Internal states before wait modulate reasoning patterns", "comment": "Accepted to EMNLP Findings 2025", "summary": "Prior work has shown that a significant driver of performance in reasoning\nmodels is their ability to reason and self-correct. A distinctive marker in\nthese reasoning traces is the token wait, which often signals reasoning\nbehavior such as backtracking. Despite being such a complex behavior, little is\nunderstood of exactly why models do or do not decide to reason in this\nparticular manner, which limits our understanding of what makes a reasoning\nmodel so effective. In this work, we address the question whether model's\nlatents preceding wait tokens contain relevant information for modulating the\nsubsequent reasoning process. We train crosscoders at multiple layers of\nDeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent\nattribution technique in the crosscoder setting. We locate a small set of\nfeatures relevant for promoting/suppressing wait tokens' probabilities.\nFinally, through a targeted series of experiments analyzing max activating\nexamples and causal interventions, we show that many of our identified features\nindeed are relevant for the reasoning process and give rise to different types\nof reasoning patterns such as restarting from the beginning, recalling prior\nknowledge, expressing uncertainty, and double-checking.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u7b49\u5f85\u6807\u8bb0\uff08wait tokens\uff09\u662f\u590d\u6742\u63a8\u7406\u884c\u4e3a\u7684\u5173\u952e\u6807\u5fd7\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u6f5c\u5728\u7279\u5f81\u53ef\u4ee5\u8bc6\u522b\u5e76\u8c03\u63a7\u63a8\u7406\u8fc7\u7a0b\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u7406\u89e3\u4e3a\u4ec0\u4e48\u6a21\u578b\u4f1a\u51b3\u5b9a\u8fdb\u884c\u7279\u5b9a\u65b9\u5f0f\u7684\u63a8\u7406\uff0c\u7279\u522b\u662f\u7b49\u5f85\u6807\u8bb0\u80cc\u540e\u7684\u673a\u5236\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u63a8\u7406\u6a21\u578b\u7684\u6709\u6548\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5728DeepSeek-R1-Distill-Llama-8B\u53ca\u5176\u57fa\u7840\u7248\u672c\u7684\u591a\u4e2a\u5c42\u8bad\u7ec3\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u5f15\u5165\u6f5c\u5728\u5f52\u56e0\u6280\u672f\uff0c\u8bc6\u522b\u5f71\u54cd\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u7684\u7279\u5f81\u3002", "result": "\u5b9a\u4f4d\u5230\u4e00\u5c0f\u90e8\u5206\u80fd\u591f\u4fc3\u8fdb/\u6291\u5236\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u786e\u5b9e\u4e0e\u63a8\u7406\u8fc7\u7a0b\u76f8\u5173\uff0c\u5e76\u4ea7\u751f\u4e0d\u540c\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "\u6a21\u578b\u6f5c\u5728\u7279\u5f81\u5305\u542b\u8c03\u63a7\u540e\u7eed\u63a8\u7406\u8fc7\u7a0b\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u8fd9\u4e9b\u7279\u5f81\u652f\u6301\u4e0d\u540c\u7c7b\u578b\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u5982\u91cd\u65b0\u5f00\u59cb\u3001\u56de\u5fc6\u5148\u9a8c\u77e5\u8bc6\u3001\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u548c\u53cc\u91cd\u68c0\u67e5\u3002"}}
{"id": "2510.04140", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04140", "abs": "https://arxiv.org/abs/2510.04140", "authors": ["Zishang Jiang", "Jinyi Han", "Tingyun Li", "Xinyi Wang", "Sihang Jiang", "Jiaqing Liang", "Zhaoqian Dai", "Shuguang Ma", "Fei Yu", "Yanghua Xiao"], "title": "Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely\nadopted technique for enhancing the reasoning ability of Large Language Models\n(LLMs). However, the effectiveness of RLVR strongly depends on the capability\nof base models. This issue arises because it requires the model to have\nsufficient capability to perform high-quality exploration, which involves both\neffectiveness and diversity. Unfortunately, existing methods address this issue\nby imitating expert trajectories, which improve effectiveness but neglect\ndiversity. To address this, we argue that the expert only needs to provide\nguidance only at critical decision points rather than the entire reasoning\npath. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation\nfor Token-level Optimization of Reasoning, a framework that provides expert\nguidance only at critical decision points to perform effective and diverse\nexploration in RLVR. Extensive experiments show that MENTOR enables models\ncapture the essence of expert strategies rather than surface imitation, thereby\nperforming high-quality exploration and achieving superior overall performance.\nOur code is available online.", "AI": {"tldr": "\u63d0\u51fa\u4e86MENTOR\u6846\u67b6\uff0c\u901a\u8fc7\u53ea\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\uff0c\u5728RLVR\u4e2d\u5b9e\u73b0\u6709\u6548\u4e14\u591a\u6837\u5316\u7684\u63a2\u7d22\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u4e13\u5bb6\u8f68\u8ff9\u6a21\u4eff\u7684\u95ee\u9898\u3002", "motivation": "RLVR\u7684\u6548\u679c\u4e25\u91cd\u4f9d\u8d56\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u63a2\u7d22\uff08\u6709\u6548\u6027\u548c\u591a\u6837\u6027\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6a21\u4eff\u4e13\u5bb6\u8f68\u8ff9\u53ea\u89e3\u51b3\u4e86\u6709\u6548\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u591a\u6837\u6027\u3002", "method": "MENTOR\u6846\u67b6\uff1a\u6df7\u5408\u7b56\u7565\u4e13\u5bb6\u5bfc\u822a\u7684\u4ee4\u724c\u7ea7\u63a8\u7406\u4f18\u5316\uff0c\u53ea\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\uff0c\u800c\u4e0d\u662f\u6574\u4e2a\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eMENTOR\u80fd\u8ba9\u6a21\u578b\u6355\u6349\u4e13\u5bb6\u7b56\u7565\u7684\u672c\u8d28\u800c\u975e\u8868\u9762\u6a21\u4eff\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u63a2\u7d22\u5e76\u83b7\u5f97\u4f18\u8d8a\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\u6bd4\u5b8c\u6574\u8def\u5f84\u6a21\u4eff\u66f4\u6709\u6548\uff0cMENTOR\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86RLVR\u4e2d\u63a2\u7d22\u8d28\u91cf\u7684\u95ee\u9898\u3002"}}
{"id": "2510.04141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04141", "abs": "https://arxiv.org/abs/2510.04141", "authors": ["Mayank Ravishankara", "Varindra V. Persad Maharaj"], "title": "The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning", "comment": null, "summary": "This survey paper chronicles the evolution of evaluation in multimodal\nartificial intelligence (AI), framing it as a progression of increasingly\nsophisticated \"cognitive examinations.\" We argue that the field is undergoing a\nparadigm shift, moving from simple recognition tasks that test \"what\" a model\nsees, to complex reasoning benchmarks that probe \"why\" and \"how\" it\nunderstands. This evolution is driven by the saturation of older benchmarks,\nwhere high performance often masks fundamental weaknesses. We chart the journey\nfrom the foundational \"knowledge tests\" of the ImageNet era to the \"applied\nlogic and comprehension\" exams such as GQA and Visual Commonsense Reasoning\n(VCR), which were designed specifically to diagnose systemic flaws such as\nshortcut learning and failures in compositional generalization. We then survey\nthe current frontier of \"expert-level integration\" benchmarks (e.g., MMBench,\nSEED-Bench, MMMU) designed for today's powerful multimodal large language\nmodels (MLLMs), which increasingly evaluate the reasoning process itself.\nFinally, we explore the uncharted territories of evaluating abstract, creative,\nand social intelligence. We conclude that the narrative of AI evaluation is not\nmerely a history of datasets, but a continuous, adversarial process of\ndesigning better examinations that, in turn, redefine our goals for creating\ntruly intelligent systems.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u8bba\u6587\u5c06\u591a\u6a21\u6001AI\u8bc4\u4f30\u7684\u6f14\u53d8\u63cf\u8ff0\u4e3a\u4e00\u7cfb\u5217\u65e5\u76ca\u590d\u6742\u7684\"\u8ba4\u77e5\u8003\u8bd5\"\uff0c\u4ece\u7b80\u5355\u7684\u8bc6\u522b\u4efb\u52a1\u53d1\u5c55\u5230\u590d\u6742\u7684\u63a8\u7406\u57fa\u51c6\uff0c\u6700\u7ec8\u63a2\u7d22\u62bd\u8c61\u3001\u521b\u9020\u6027\u548c\u793e\u4ea4\u667a\u80fd\u7684\u8bc4\u4f30\u3002", "motivation": "\u591a\u6a21\u6001AI\u9886\u57df\u6b63\u5728\u7ecf\u5386\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ece\u7b80\u5355\u7684\"\u662f\u4ec0\u4e48\"\u8bc6\u522b\u4efb\u52a1\u8f6c\u5411\u590d\u6742\u7684\"\u4e3a\u4ec0\u4e48\"\u548c\"\u5982\u4f55\"\u7406\u89e3\u63a8\u7406\u4efb\u52a1\uff0c\u8fd9\u662f\u56e0\u4e3a\u65e7\u57fa\u51c6\u5df2\u7ecf\u9971\u548c\uff0c\u9ad8\u6027\u80fd\u5f80\u5f80\u63a9\u76d6\u4e86\u6839\u672c\u6027\u5f31\u70b9\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u56de\u987e\u7684\u65b9\u6cd5\uff0c\u8ffd\u8e2a\u4eceImageNet\u65f6\u4ee3\u7684\"\u77e5\u8bc6\u6d4b\u8bd5\"\u5230GQA\u548cVCR\u7b49\"\u5e94\u7528\u903b\u8f91\u548c\u7406\u89e3\"\u8003\u8bd5\uff0c\u518d\u5230\u4e3a\u73b0\u4ee3MLLMs\u8bbe\u8ba1\u7684\"\u4e13\u5bb6\u7ea7\u96c6\u6210\"\u57fa\u51c6(\u5982MMBench\u3001SEED-Bench\u3001MMMU)\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "result": "\u8bc6\u522b\u4e86\u8bc4\u4f30\u8303\u5f0f\u7684\u7cfb\u7edf\u6027\u8f6c\u53d8\uff1a\u4ece\u7b80\u5355\u8bc6\u522b\u5230\u590d\u6742\u63a8\u7406\uff0c\u518d\u5230\u8bc4\u4f30\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\uff0c\u5e76\u5f00\u59cb\u63a2\u7d22\u62bd\u8c61\u3001\u521b\u9020\u6027\u548c\u793e\u4ea4\u667a\u80fd\u7684\u8bc4\u4f30\u524d\u6cbf\u3002", "conclusion": "AI\u8bc4\u4f30\u7684\u53d9\u4e8b\u4e0d\u4ec5\u4ec5\u662f\u6570\u636e\u96c6\u7684\u5386\u53f2\uff0c\u800c\u662f\u4e00\u4e2a\u6301\u7eed\u5bf9\u6297\u7684\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u66f4\u597d\u7684\u8003\u8bd5\u6765\u91cd\u65b0\u5b9a\u4e49\u521b\u5efa\u771f\u6b63\u667a\u80fd\u7cfb\u7edf\u7684\u76ee\u6807\u3002"}}
{"id": "2510.04173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04173", "abs": "https://arxiv.org/abs/2510.04173", "authors": ["Yassine Benajiba", "Cesare Bernardis", "Vladislav Blinov", "Paul Cayet", "Hassan Chafi", "Abderrahim Fathan", "Louis Faucon", "Damien Hilloulin", "Sungpack Hong", "Ingo Kossyk", "Rhicheek Patra", "Sujith Ravi", "Jonas Schweizer", "Jyotika Singh", "Shailender Singh", "Xuelin Situ", "Weiyi Sun", "Jerry Xu", "Ying Xu"], "title": "Open Agent Specification (Agent Spec) Technical Report", "comment": null, "summary": "Open Agent Specification (Agent Spec) is a declarative language that allows\nAI agents and their workflows to be defined in a way that is compatible across\ndifferent AI frameworks, promoting portability and interoperability within AI\nAgent frameworks.\n  Agent Spec aims to resolve the challenges of fragmented agent development by\nproviding a common unified specification that allows AI agents to be designed\nonce and deployed across various frameworks, improving interoperability and\nreusability, and reducing redundant development efforts. Additionally, Agent\nSpec facilitates development tools and portability, allowing AI agents to be\ndefined independently of their execution environment and enabling teams to\nexchange solutions without implementation-specific limitations.\n  Agent Spec benefits four key groups: (i) Agent developers, who gain access to\na superset of reusable components and design patterns, enabling them to\nleverage a broader range of functionalities; (ii) Agent framework and tool\ndevelopers, who can use Agent Spec as an interchange format and therefore\nbenefit from the support of other frameworks as well as other tools; (iii)\nResearchers, who can achieve reproducible results and comparability,\nfacilitating more reliable and consistent outcomes; (iv) Enterprises, which\nbenefit from faster prototype-to-deployment, increased productivity, as well as\ngreater scalability and maintainability for their AI agent solutions. This\ntechnical report provides an overview of the technical foundations of Agent\nSpec, including motivation, benefits, and future developments.", "AI": {"tldr": "Open Agent Specification (Agent Spec) \u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u8bed\u8a00\uff0c\u7528\u4e8e\u5b9a\u4e49AI\u667a\u80fd\u4f53\u53ca\u5176\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u8de8AI\u6846\u67b6\u7684\u517c\u5bb9\u6027\uff0c\u4fc3\u8fdbAI\u667a\u80fd\u4f53\u6846\u67b6\u95f4\u7684\u53ef\u79fb\u690d\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "motivation": "\u89e3\u51b3AI\u667a\u80fd\u4f53\u5f00\u53d1\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u89c4\u8303\uff0c\u4f7fAI\u667a\u80fd\u4f53\u80fd\u591f\u4e00\u6b21\u8bbe\u8ba1\u3001\u8de8\u6846\u67b6\u90e8\u7f72\uff0c\u63d0\u9ad8\u4e92\u64cd\u4f5c\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u51cf\u5c11\u91cd\u590d\u5f00\u53d1\u5de5\u4f5c\u3002", "method": "\u5f00\u53d1\u58f0\u660e\u5f0f\u8bed\u8a00\u89c4\u8303\uff0c\u5141\u8bb8AI\u667a\u80fd\u4f53\u72ec\u7acb\u4e8e\u6267\u884c\u73af\u5883\u8fdb\u884c\u5b9a\u4e49\uff0c\u652f\u6301\u5f00\u53d1\u5de5\u5177\u548c\u53ef\u79fb\u690d\u6027\uff0c\u4f5c\u4e3a\u4e0d\u540c\u6846\u67b6\u95f4\u7684\u4ea4\u6362\u683c\u5f0f\u3002", "result": "\u4e3a\u56db\u7c7b\u5173\u952e\u7fa4\u4f53\u5e26\u6765\u76ca\u5904\uff1a\u5f00\u53d1\u8005\u83b7\u5f97\u53ef\u91cd\u7528\u7ec4\u4ef6\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff1b\u6846\u67b6\u5f00\u53d1\u8005\u83b7\u5f97\u4e92\u64cd\u4f5c\u652f\u6301\uff1b\u7814\u7a76\u8005\u5b9e\u73b0\u53ef\u590d\u73b0\u7ed3\u679c\uff1b\u4f01\u4e1a\u52a0\u901f\u539f\u578b\u5230\u90e8\u7f72\u5e76\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Agent Spec \u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\uff0c\u4fc3\u8fdbAI\u667a\u80fd\u4f53\u5f00\u53d1\u7684\u6807\u51c6\u5316\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u672a\u6765\u5c06\u7ee7\u7eed\u53d1\u5c55\u5b8c\u5584\u3002"}}
{"id": "2510.04195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04195", "abs": "https://arxiv.org/abs/2510.04195", "authors": ["Puzhen Zhang", "Xuyang Chen", "Yu Feng", "Yuhan Jiang", "Liqiu Meng"], "title": "Constructing coherent spatial memory in LLM agents through graph rectification", "comment": null, "summary": "Given a map description through global traversal navigation instructions\n(e.g., visiting each room sequentially with action signals such as north, west,\netc.), an LLM can often infer the implicit spatial layout of the environment\nand answer user queries by providing a shortest path from a start to a\ndestination (for instance, navigating from the lobby to a meeting room via the\nhall and elevator). However, such context-dependent querying becomes incapable\nas the environment grows much longer, motivating the need for incremental map\nconstruction that builds a complete topological graph from stepwise\nobservations. We propose a framework for LLM-driven construction and map\nrepair, designed to detect, localize, and correct structural inconsistencies in\nincrementally constructed navigation graphs. Central to our method is the\nVersion Control, which records the full history of graph edits and their source\nobservations, enabling fine-grained rollback, conflict tracing, and repair\nevaluation. We further introduce an Edge Impact Score to prioritize\nminimal-cost repairs based on structural reachability, path usage, and conflict\npropagation. To properly evaluate our approach, we create a refined version of\nthe MANGO benchmark dataset by systematically removing non-topological actions\nand inherent structural conflicts, providing a cleaner testbed for LLM-driven\nconstruction and map repair. Our approach significantly improves map\ncorrectness and robustness, especially in scenarios with entangled or chained\ninconsistencies. Our results highlight the importance of introspective,\nhistory-aware repair mechanisms for maintaining coherent spatial memory in LLM\nagents.", "AI": {"tldr": "\u63d0\u51faLLM\u9a71\u52a8\u7684\u589e\u91cf\u5730\u56fe\u6784\u5efa\u548c\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u7248\u672c\u63a7\u5236\u548c\u8fb9\u5f71\u54cd\u8bc4\u5206\u6765\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u4fee\u6b63\u5bfc\u822a\u56fe\u4e2d\u7684\u7ed3\u6784\u4e0d\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u5347\u5730\u56fe\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u73af\u5883\u89c4\u6a21\u6269\u5927\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u67e5\u8be2\u65b9\u6cd5\u5931\u6548\uff0c\u9700\u8981\u589e\u91cf\u6784\u5efa\u5b8c\u6574\u62d3\u6251\u56fe\u6765\u652f\u6301\u5bfc\u822a\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u7248\u672c\u63a7\u5236\u8bb0\u5f55\u56fe\u7f16\u8f91\u5386\u53f2\uff0c\u5f15\u5165\u8fb9\u5f71\u54cd\u8bc4\u5206\u57fa\u4e8e\u7ed3\u6784\u53ef\u8fbe\u6027\u3001\u8def\u5f84\u4f7f\u7528\u548c\u51b2\u7a81\u4f20\u64ad\u6765\u4f18\u5148\u6700\u5c0f\u6210\u672c\u4fee\u590d\u3002", "result": "\u5728\u7cbe\u70bc\u7684MANGO\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u56fe\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7ea0\u7f20\u6216\u94fe\u5f0f\u4e0d\u4e00\u81f4\u7684\u573a\u666f\u4e2d\u3002", "conclusion": "\u81ea\u7701\u5f0f\u3001\u5386\u53f2\u611f\u77e5\u7684\u4fee\u590d\u673a\u5236\u5bf9\u4e8e\u7ef4\u62a4LLM\u667a\u80fd\u4f53\u8fde\u8d2f\u7a7a\u95f4\u8bb0\u5fc6\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.04196", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04196", "abs": "https://arxiv.org/abs/2510.04196", "authors": ["Yizhuo Ding", "Mingkang Chen", "Qiuhua Liu", "Fenghua Weng", "Wanying Qu", "Yue Yang", "Yugang Jiang", "Zuxuan Wu", "Yanwei Fu", "Wenqi Shao"], "title": "COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability", "comment": null, "summary": "Large Multimodal Reasoning Models (LMRMs) are moving into real applications,\nwhere they must be both useful and safe. Safety is especially challenging in\nmultimodal settings: images and text can be combined to bypass guardrails, and\nsingle objective training can cause policy drift that yields over-refusal on\nbenign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed\nreinforcement learning framework that trains reasoning oriented LMRMs under\nmultimodal, multitask, and multiobjective signals, and we release the resulting\nmodel, COSMO-R1. Our approach aims to let safety and capability grow together\nin one stable pipeline rather than competing during alignment. In experiments,\nCOSMO-R1 improves safety while maintaining-and often improving multimodal\nreasoning and instruction following, shows stronger robustness to multimodal\njailbreaks, and reduces unnecessary refusals. The framework also transfers\nacross backbones with consistent gains. Ablations support the design choices,\nindicating a simple path to advancing safety and general capability together in\nLMRMs.", "AI": {"tldr": "COSMO-RL\u662f\u4e00\u4e2a\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u548c\u591a\u76ee\u6807\u4fe1\u53f7\u4e0b\u8bad\u7ec3\u63a8\u7406\u5bfc\u5411\u7684\u5927\u578b\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff0c\u65e8\u5728\u8ba9\u5b89\u5168\u6027\u548c\u80fd\u529b\u5171\u540c\u589e\u957f\u800c\u975e\u76f8\u4e92\u7ade\u4e89\u3002", "motivation": "\u5927\u578b\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u9700\u8981\u65e2\u5b9e\u7528\u53c8\u5b89\u5168\uff0c\u4f46\u591a\u6a21\u6001\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6027\u7279\u522b\u5177\u6709\u6311\u6218\u6027\uff1a\u56fe\u50cf\u548c\u6587\u672c\u53ef\u4ee5\u7ed3\u5408\u7ed5\u8fc7\u9632\u62a4\u63aa\u65bd\uff0c\u5355\u76ee\u6807\u8bad\u7ec3\u53ef\u80fd\u5bfc\u81f4\u7b56\u7565\u6f02\u79fb\uff0c\u5728\u826f\u6027\u8f93\u5165\u4e0a\u8fc7\u5ea6\u62d2\u7edd\u6216\u5728\u98ce\u9669\u8f93\u5165\u4e0a\u4e0d\u5b89\u5168\u5408\u89c4\u3002", "method": "\u63d0\u51faCOSMO-RL\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u548c\u591a\u76ee\u6807\u4fe1\u53f7\u4e0b\u8bad\u7ec3\u63a8\u7406\u5bfc\u5411\u7684\u5927\u578b\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff0c\u5e76\u53d1\u5e03\u4e86COSMO-R1\u6a21\u578b\u3002", "result": "COSMO-R1\u5728\u5b9e\u9a8c\u4e2d\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5e76\u7ecf\u5e38\u6539\u5584\u591a\u6a21\u6001\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u663e\u793a\u51fa\u5bf9\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u7684\u66f4\u5f3a\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u62d2\u7edd\u3002\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u9aa8\u5e72\u7f51\u7edc\u4e0a\u90fd\u80fd\u5b9e\u73b0\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6d88\u878d\u5b9e\u9a8c\u652f\u6301\u8bbe\u8ba1\u9009\u62e9\uff0c\u8868\u660e\u5728\u5927\u578b\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u4e2d\u5171\u540c\u63a8\u8fdb\u5b89\u5168\u6027\u548c\u901a\u7528\u80fd\u529b\u662f\u4e00\u6761\u7b80\u5355\u8def\u5f84\u3002"}}
{"id": "2510.04206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04206", "abs": "https://arxiv.org/abs/2510.04206", "authors": ["Hanchen Zhang", "Xiao Liu", "Bowen Lv", "Xueqiao Sun", "Bohao Jing", "Iat Long Iong", "Zhenyu Hou", "Zehan Qi", "Hanyu Lai", "Yifan Xu", "Rui Lu", "Hongning Wang", "Jie Tang", "Yuxiao Dong"], "title": "AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework", "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin building generalist agents that can learn through online interactions.\nHowever, applying reinforcement learning (RL) to train LLM agents in\nmulti-turn, multi-task settings remains challenging due to lack of scalable\ninfrastructure and stable training algorithms. In this work, we present the\nAgentRL framework for scalable multi-turn, multi-task agentic RL training. On\nthe infrastructure side, AgentRL features a fully-asynchronous\ngeneration-training pipeline for efficient multi-turn RL. To support\nheterogeneous environment development in multi-task RL, we design a unified\nfunction-call based API interface, containerized environment development, and a\ncentralized controller. On the algorithm side, we propose cross-policy sampling\nto encourage model exploration in multi-turn settings and task advantage\nnormalization to stabilize multi-task training. Experiments show that AgentRL,\ntrained on open LLMs across five agentic tasks, significantly outperforms\nGPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents.\nMulti-task training with AgentRL matches the best results among all\ntask-specific models. AgentRL is open-sourced at\nhttps://github.com/THUDM/AgentRL. The algorithm and framework are adopted in\nbuilding \\textsc{\\href{https://autoglm.zhipuai.cn}{AutoGLM}}.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentRL\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u7684\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5305\u542b\u5f02\u6b65\u751f\u6210-\u8bad\u7ec3\u6d41\u6c34\u7ebf\u3001\u7edf\u4e00API\u63a5\u53e3\u548c\u7a33\u5b9a\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709LLM\u667a\u80fd\u4f53\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u591a\u8f6e\u591a\u4efb\u52a1\u73af\u5883\u4e2d\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u57fa\u7840\u8bbe\u65bd\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u7b97\u6cd5\u7a33\u5b9a\u6027\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u5f02\u6b65\u7684\u751f\u6210-\u8bad\u7ec3\u6d41\u6c34\u7ebf\u5b9e\u73b0\u9ad8\u6548\u591a\u8f6eRL\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u51fd\u6570\u8c03\u7528\u7684\u7edf\u4e00API\u63a5\u53e3\u3001\u5bb9\u5668\u5316\u73af\u5883\u5f00\u53d1\u548c\u96c6\u4e2d\u63a7\u5236\u5668\u652f\u6301\u5f02\u6784\u73af\u5883\uff1b\u63d0\u51fa\u8de8\u7b56\u7565\u91c7\u6837\u4fc3\u8fdb\u591a\u8f6e\u63a2\u7d22\u548c\u4efb\u52a1\u4f18\u52bf\u5f52\u4e00\u5316\u7a33\u5b9a\u591a\u4efb\u52a1\u8bad\u7ec3\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u4efb\u52a1\u4e0a\uff0cAgentRL\u663e\u8457\u8d85\u8d8aGPT-5\u3001Clause-Sonnet-4\u3001DeepSeek-R1\u7b49\u5f00\u6e90LLM\u667a\u80fd\u4f53\uff1b\u591a\u4efb\u52a1\u8bad\u7ec3\u7ed3\u679c\u4e0e\u6240\u6709\u4efb\u52a1\u4e13\u7528\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c\u76f8\u5f53\u3002", "conclusion": "AgentRL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53RL\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u901a\u7528\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5f00\u6e90\u5e76\u5e94\u7528\u4e8eAutoGLM\u7cfb\u7edf\u3002"}}
{"id": "2510.04265", "categories": ["cs.AI", "cs.CL", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.04265", "abs": "https://arxiv.org/abs/2510.04265", "authors": ["Mohsen Hariri", "Amirhossein Samandar", "Michael Hinczewski", "Vipin Chaudhary"], "title": "Don't Pass$\\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation", "comment": "Code and simulations: https://mohsenhariri.github.io/bayes-kit", "summary": "Pass$@k$ is widely used to report performance for LLM reasoning, but it often\nyields unstable, misleading rankings, especially when the number of trials\n(samples) is limited and compute is constrained. We present a principled\nBayesian evaluation framework that replaces Pass$@k$ and average accuracy over\n$N$ trials (avg$@N$) with posterior estimates of a model's underlying success\nprobability and credible intervals, yielding stable rankings and a transparent\ndecision rule for differences. Evaluation outcomes are modeled as categorical\n(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the\nposterior mean and uncertainty of any weighted rubric and enabling the use of\nprior evidence when appropriate. Theoretically, under a uniform prior, the\nBayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),\nexplaining its empirical robustness while adding principled uncertainty.\nEmpirically, in simulations with known ground-truth success rates and on\nAIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster\nconvergence and greater rank stability than Pass$@k$ and recent variants,\nenabling reliable comparisons at far smaller sample counts. The framework\nclarifies when observed gaps are statistically meaningful (non-overlapping\ncredible intervals) versus noise, and it naturally extends to graded,\nrubric-based evaluations. Together, these results recommend replacing Pass$@k$\nfor LLM evaluation and ranking with a posterior-based, compute-efficient\nprotocol that unifies binary and non-binary evaluation while making uncertainty\nexplicit. Code is available at https://mohsenhariri.github.io/bayes-kit", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u8bc4\u4f30\u6846\u67b6\u6765\u66ff\u4ee3Pass@k\uff0c\u901a\u8fc7\u540e\u9a8c\u4f30\u8ba1\u6a21\u578b\u7684\u57fa\u7840\u6210\u529f\u6982\u7387\u548c\u53ef\u4fe1\u533a\u95f4\uff0c\u63d0\u4f9b\u66f4\u7a33\u5b9a\u7684\u6392\u540d\u548c\u900f\u660e\u7684\u51b3\u7b56\u89c4\u5219\u3002", "motivation": "Pass@k\u5728\u6709\u9650\u8bd5\u9a8c\u6b21\u6570\u548c\u8ba1\u7b97\u53d7\u9650\u65f6\u4f1a\u4ea7\u751f\u4e0d\u7a33\u5b9a\u3001\u8bef\u5bfc\u6027\u7684\u6392\u540d\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Dirichlet\u5148\u9a8c\u5bf9\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u5efa\u6a21\uff0c\u4e3a\u4efb\u4f55\u52a0\u6743\u8bc4\u5206\u6807\u51c6\u63d0\u4f9b\u540e\u9a8c\u5747\u503c\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u5141\u8bb8\u5728\u9002\u5f53\u65f6\u4f7f\u7528\u5148\u9a8c\u8bc1\u636e\u3002", "result": "\u5728\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8d1d\u53f6\u65af\u65b9\u6cd5\u6bd4Pass@k\u53ca\u5176\u53d8\u4f53\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u6392\u540d\u7a33\u5b9a\u6027\uff0c\u80fd\u591f\u5728\u66f4\u5c0f\u7684\u6837\u672c\u91cf\u4e0b\u5b9e\u73b0\u53ef\u9760\u6bd4\u8f83\u3002", "conclusion": "\u63a8\u8350\u7528\u57fa\u4e8e\u540e\u9a8c\u7684\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u534f\u8bae\u66ff\u4ee3Pass@k\uff0c\u7edf\u4e00\u4e8c\u5143\u548c\u975e\u4e8c\u5143\u8bc4\u4f30\uff0c\u540c\u65f6\u660e\u786e\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2510.04272", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.04272", "abs": "https://arxiv.org/abs/2510.04272", "authors": ["Jinyang Jiang", "Jinhui Han", "Yijie Peng", "Ying Zhang"], "title": "Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales", "comment": null, "summary": "Effective cross-functional coordination is essential for enhancing firm-wide\nprofitability, particularly in the face of growing organizational complexity\nand scale. Recent advances in artificial intelligence, especially in\nreinforcement learning (RL), offer promising avenues to address this\nfundamental challenge. This paper proposes a unified multi-agent RL framework\ntailored for joint optimization across distinct functional modules, exemplified\nvia coordinating inventory replenishment and personalized product\nrecommendation. We first develop an integrated theoretical model to capture the\nintricate interplay between these functions and derive analytical benchmarks\nthat characterize optimal coordination. The analysis reveals synchronized\nadjustment patterns across products and over time, highlighting the importance\nof coordinated decision-making. Leveraging these insights, we design a novel\nmulti-timescale multi-agent RL architecture that decomposes policy components\naccording to departmental functions and assigns distinct learning speeds based\non task complexity and responsiveness. Our model-free multi-agent design\nimproves scalability and deployment flexibility, while multi-timescale updates\nenhance convergence stability and adaptability across heterogeneous decisions.\nWe further establish the asymptotic convergence of the proposed algorithm.\nExtensive simulation experiments demonstrate that the proposed approach\nsignificantly improves profitability relative to siloed decision-making\nframeworks, while the behaviors of the trained RL agents align closely with the\nmanagerial insights from our theoretical model. Taken together, this work\nprovides a scalable, interpretable RL-based solution to enable effective\ncross-functional coordination in complex business settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u8c03\u5e93\u5b58\u8865\u8d27\u548c\u4e2a\u6027\u5316\u4ea7\u54c1\u63a8\u8350\u7b49\u529f\u80fd\u6a21\u5757\uff0c\u901a\u8fc7\u591a\u65f6\u95f4\u5c3a\u5ea6\u5b66\u4e60\u63d0\u9ad8\u6536\u655b\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\uff0c\u663e\u8457\u63d0\u5347\u4f01\u4e1a\u76c8\u5229\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u7ec4\u7ec7\u590d\u6742\u6027\u548c\u89c4\u6a21\u589e\u957f\u5e26\u6765\u7684\u8de8\u529f\u80fd\u534f\u8c03\u6311\u6218\uff0c\u5229\u7528\u4eba\u5de5\u667a\u80fd\u7279\u522b\u662f\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u4e0d\u540c\u529f\u80fd\u6a21\u5757\u95f4\u7684\u8054\u5408\u51b3\u7b56\u3002", "method": "\u5f00\u53d1\u96c6\u6210\u7406\u8bba\u6a21\u578b\u6355\u6349\u529f\u80fd\u95f4\u590d\u6742\u4ea4\u4e92\uff0c\u8bbe\u8ba1\u591a\u65f6\u95f4\u5c3a\u5ea6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u6309\u90e8\u95e8\u529f\u80fd\u5206\u89e3\u7b56\u7565\u7ec4\u4ef6\uff0c\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u548c\u54cd\u5e94\u6027\u5206\u914d\u4e0d\u540c\u5b66\u4e60\u901f\u5ea6\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5b64\u7acb\u51b3\u7b56\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u76c8\u5229\u80fd\u529b\uff0c\u8bad\u7ec3\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u7406\u8bba\u6a21\u578b\u7684\u7ba1\u7406\u6d1e\u5bdf\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u590d\u6742\u5546\u4e1a\u73af\u5883\u4e2d\u7684\u8de8\u529f\u80fd\u534f\u8c03\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04281", "abs": "https://arxiv.org/abs/2510.04281", "authors": ["Zhuangzhi Gao", "Hongyi Qin", "He Zhao", "Qinkai Yu", "Feixiang Zhou", "Eduard Shantsila", "Uazman Alam", "Alena Shantsila", "Wahbi El-Bouri", "Gregory Y. H. Lip", "Yalin Zheng"], "title": "GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a Grounded MLLM with Knowledge-Guided Instruction", "comment": "9 pages, 4 figures, 3 table. Equal contribution: Zhuangzhi Gao and\n  Hongyi Qin. Corresponding author: Yalin Zheng (yzheng@liverpool.ac.uk)", "summary": "Multimodal large language models (MLLMs) hold promise for integrating diverse\ndata modalities, but current medical adaptations such as LLaVA-Med often fail\nto fully exploit the synergy between color fundus photography (CFP) and optical\ncoherence tomography (OCT), and offer limited interpretability of quantitative\nbiomarkers. We introduce GROK, a grounded multimodal large language model that\njointly processes CFP, OCT, and text to deliver clinician-grade diagnoses of\nocular and systemic disease. GROK comprises three core modules:\nKnowledge-Guided Instruction Generation, CLIP-Style OCT-Biomarker Alignment,\nand Supervised Instruction Fine-Tuning, which together establish a\nquantitative-to-qualitative diagnostic chain of thought, mirroring real\nclinical reasoning when producing detailed lesion annotations. To evaluate our\napproach, we introduce the Grounded Ophthalmic Understanding benchmark, which\ncovers six disease categories and three tasks: macro-level diagnostic\nclassification, report generation quality, and fine-grained clinical assessment\nof the generated chain of thought. Experiments show that, with only LoRA\n(Low-Rank Adaptation) fine-tuning of a 7B-parameter Qwen2 backbone, GROK\noutperforms comparable 7B and 32B baselines on both report quality and\nfine-grained clinical metrics, and even exceeds OpenAI o3. Code and data are\npublicly available in the GROK repository.", "AI": {"tldr": "GROK\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u773c\u79d1\u8bca\u65ad\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u5904\u7406\u5f69\u8272\u773c\u5e95\u6444\u5f71\u3001\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\u548c\u6587\u672c\u6570\u636e\uff0c\u63d0\u4f9b\u4e34\u5e8a\u7ea7\u522b\u7684\u773c\u90e8\u548c\u5168\u8eab\u75be\u75c5\u8bca\u65ad\u3002", "motivation": "\u5f53\u524d\u533b\u5b66\u591a\u6a21\u6001\u6a21\u578b\u672a\u80fd\u5145\u5206\u5229\u7528\u5f69\u8272\u773c\u5e95\u6444\u5f71\u548c\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\u4e4b\u95f4\u7684\u534f\u540c\u4f5c\u7528\uff0c\u4e14\u5bf9\u5b9a\u91cf\u751f\u7269\u6807\u5fd7\u7269\u7684\u89e3\u91ca\u80fd\u529b\u6709\u9650\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u77e5\u8bc6\u5f15\u5bfc\u7684\u6307\u4ee4\u751f\u6210\u3001CLIP\u98ce\u683c\u7684OCT\u751f\u7269\u6807\u5fd7\u7269\u5bf9\u9f50\u548c\u76d1\u7763\u6307\u4ee4\u5fae\u8c03\uff0c\u5efa\u7acb\u5b9a\u91cf\u5230\u5b9a\u6027\u7684\u8bca\u65ad\u601d\u7ef4\u94fe\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4ec5\u4f7f\u75287B\u53c2\u6570\u7684Qwen2\u9aa8\u5e72\u7f51\u7edc\u8fdb\u884cLoRA\u5fae\u8c03\uff0cGROK\u5728\u62a5\u544a\u8d28\u91cf\u548c\u7ec6\u7c92\u5ea6\u4e34\u5e8a\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u53ef\u6bd4\u8f83\u76847B\u548c32B\u57fa\u7ebf\u6a21\u578b\uff0c\u751a\u81f3\u8d85\u8fc7OpenAI o3\u3002", "conclusion": "GROK\u901a\u8fc7\u5efa\u7acb\u4e34\u5e8a\u63a8\u7406\u601d\u7ef4\u94fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u773c\u79d1\u8bca\u65ad\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.04284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04284", "abs": "https://arxiv.org/abs/2510.04284", "authors": ["Yunghwei Lai", "Kaiming Liu", "Ziyue Wang", "Weizhi Ma", "Yang Liu"], "title": "Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning", "comment": null, "summary": "The professionalism of a human doctor in outpatient service depends on two\ncore abilities: the ability to make accurate medical decisions and the medical\nconsultation skill to conduct strategic, empathetic patient inquiry. Existing\nLarge Language Models (LLMs) have achieved remarkable accuracy on medical\ndecision-making benchmarks. However, they often lack the ability to conduct the\nstrategic and empathetic consultation, which is essential for real-world\nclinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor\nagent trained to master both of the capabilities by ask high-yield questions\nand conduct strategic multi-turn inquiry to guide decision-making. Our\nframework introduces three key components: a multi-agent interactive\nenvironment, a two-tiered reward architecture that separately optimizes\nclinical decision-making and communicative inquiry skills, and an experience\nrepository to ground policy learning in high-quality prior trajectories. We\nevaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across\nmulti-facet metrics, such as communication quality, user experience, and task\naccuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source\nspecialized LLMs by a substantial margin with higher parameter efficiency and\noutperforms powerful proprietary models. Furthermore, the human evaluations\nshow a strong preference for Doctor-R1 to generate human-preferred clinical\ndialogue, demonstrating the effectiveness of the framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86Doctor-R1 AI\u533b\u751f\u4ee3\u7406\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u73af\u5883\u548c\u5206\u5c42\u5956\u52b1\u67b6\u6784\uff0c\u540c\u65f6\u4f18\u5316\u533b\u7597\u51b3\u7b56\u51c6\u786e\u6027\u548c\u6218\u7565\u6c9f\u901a\u80fd\u529b\uff0c\u5728\u533b\u7597\u5bf9\u8bdd\u8d28\u91cf\u548c\u7528\u6237\u4f53\u9a8c\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u6218\u7565\u6027\u548c\u540c\u7406\u5fc3\u7684\u533b\u7597\u54a8\u8be2\u6280\u80fd\uff0c\u65e0\u6cd5\u6ee1\u8db3\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u73af\u5883\u3001\u5206\u5c42\u5956\u52b1\u67b6\u6784\uff08\u5206\u522b\u4f18\u5316\u4e34\u5e8a\u51b3\u7b56\u548c\u6c9f\u901a\u6280\u80fd\uff09\u4ee5\u53ca\u7ecf\u9a8c\u5b58\u50a8\u5e93\u6765\u57fa\u4e8e\u9ad8\u8d28\u91cf\u5386\u53f2\u8f68\u8ff9\u8fdb\u884c\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728OpenAI\u7684HealthBench\u548cMAQuE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDoctor-R1\u5728\u6c9f\u901a\u8d28\u91cf\u3001\u7528\u6237\u4f53\u9a8c\u548c\u4efb\u52a1\u51c6\u786e\u6027\u7b49\u591a\u7ef4\u5ea6\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u4e13\u7528LLMs\uff0c\u4e14\u53c2\u6570\u6548\u7387\u66f4\u9ad8\uff0c\u751a\u81f3\u4f18\u4e8e\u5f3a\u5927\u7684\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "Doctor-R1\u80fd\u591f\u751f\u6210\u4eba\u7c7b\u504f\u597d\u7684\u4e34\u5e8a\u5bf9\u8bdd\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u57f9\u517b\u517c\u5177\u4e13\u4e1a\u51b3\u7b56\u80fd\u529b\u548c\u6218\u7565\u6c9f\u901a\u6280\u80fd\u7684AI\u533b\u751f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.04311", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04311", "abs": "https://arxiv.org/abs/2510.04311", "authors": ["Bohan Tang", "Huidong Liang", "Keyue Jiang", "Xiaowen Dong"], "title": "On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems", "comment": null, "summary": "Large language model multi-agent systems (LLM-MAS) offer a promising paradigm\nfor harnessing collective intelligence to achieve more advanced forms of AI\nbehaviour. While recent studies suggest that LLM-MAS can outperform LLM\nsingle-agent systems (LLM-SAS) on certain tasks, the lack of systematic\nexperimental designs limits the strength and generality of these conclusions.\nWe argue that a principled understanding of task complexity, such as the degree\nof sequential reasoning required and the breadth of capabilities involved, is\nessential for assessing the effectiveness of LLM-MAS in task solving. To this\nend, we propose a theoretical framework characterising tasks along two\ndimensions: depth, representing reasoning length, and width, representing\ncapability diversity. We theoretically examine a representative class of\nLLM-MAS, namely the multi-agent debate system, and empirically evaluate its\nperformance in both discriminative and generative tasks with varying depth and\nwidth. Theoretical and empirical results show that the benefit of LLM-MAS over\nLLM-SAS increases with both task depth and width, and the effect is more\npronounced with respect to depth. This clarifies when LLM-MAS are beneficial\nand provides a principled foundation for designing future LLM-MAS methods and\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd\uff0c\u53d1\u73b0\u4efb\u52a1\u6df1\u5ea6\uff08\u63a8\u7406\u957f\u5ea6\uff09\u548c\u5bbd\u5ea6\uff08\u80fd\u529b\u591a\u6837\u6027\uff09\u8d8a\u5927\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u7684\u4f18\u52bf\u8d8a\u660e\u663e\uff0c\u4e14\u6df1\u5ea6\u7684\u5f71\u54cd\u66f4\u663e\u8457\u3002", "motivation": "\u867d\u7136\u7814\u7a76\u8868\u660eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5b9e\u9a8c\u8bbe\u8ba1\u9650\u5236\u4e86\u7ed3\u8bba\u7684\u53ef\u9760\u6027\u548c\u666e\u9002\u6027\u3002\u9700\u8981\u4ece\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u89d2\u5ea6\u7406\u89e3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u7279\u5f81\u5316\u4e3a\u6df1\u5ea6\uff08\u63a8\u7406\u957f\u5ea6\uff09\u548c\u5bbd\u5ea6\uff08\u80fd\u529b\u591a\u6837\u6027\uff09\u4e24\u4e2a\u7ef4\u5ea6\u3002\u7406\u8bba\u5206\u6790\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\uff0c\u5e76\u5728\u4e0d\u540c\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u5224\u522b\u6027\u548c\u751f\u6210\u6027\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4f18\u52bf\u968f\u4efb\u52a1\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u589e\u52a0\u800c\u589e\u52a0\uff0c\u4e14\u6df1\u5ea6\u7684\u5f71\u54cd\u66f4\u4e3a\u663e\u8457\u3002", "conclusion": "\u660e\u786e\u4e86LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f55\u65f6\u5177\u6709\u4f18\u52bf\uff0c\u4e3a\u672a\u6765LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u65b9\u6cd5\u548c\u57fa\u51c6\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.04371", "categories": ["cs.AI", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04371", "abs": "https://arxiv.org/abs/2510.04371", "authors": ["Naimeng Ye", "Arnav Ahuja", "Georgios Liargkovas", "Yunan Lu", "Kostis Kaffes", "Tianyi Peng"], "title": "Speculative Actions: A Lossless Framework for Faster Agentic Systems", "comment": null, "summary": "Despite growing interest in AI agents across industry and academia, their\nexecution in an environment is often slow, hampering training, evaluation, and\ndeployment. For example, a game of chess between two state-of-the-art agents\nmay take hours. A critical bottleneck is that agent behavior unfolds\nsequentially: each action requires an API call, and these calls can be\ntime-consuming. Inspired by speculative execution in microprocessors and\nspeculative decoding in LLM inference, we propose speculative actions, a\nlossless framework for general agentic systems that predicts likely actions\nusing faster models, enabling multiple steps to be executed in parallel. We\nevaluate this framework across three agentic environments: gaming, e-commerce,\nweb search, and a \"lossy\" extension for an operating systems environment. In\nall cases, speculative actions achieve substantial accuracy in next-action\nprediction (up to 55%), translating into significant reductions in end-to-end\nlatency. Moreover, performance can be further improved through stronger\nguessing models, top-K action prediction, multi-step speculation, and\nuncertainty-aware optimization, opening a promising path toward deploying\nlow-latency agentic systems in the real world.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\"\u63a8\u6d4b\u52a8\u4f5c\"\u7684\u65e0\u635f\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u66f4\u5feb\u7684\u6a21\u578b\u9884\u6d4b\u53ef\u80fd\u7684\u52a8\u4f5c\uff0c\u4f7f\u591a\u4e2a\u6b65\u9aa4\u80fd\u591f\u5e76\u884c\u6267\u884c\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "motivation": "AI\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u7684\u6267\u884c\u901a\u5e38\u5f88\u6162\uff0c\u963b\u788d\u4e86\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u3002\u4f8b\u5982\uff0c\u4e24\u4e2a\u6700\u5148\u8fdb\u7684\u56fd\u9645\u8c61\u68cb\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u5bf9\u5f08\u53ef\u80fd\u9700\u8981\u6570\u5c0f\u65f6\uff0c\u5173\u952e\u74f6\u9888\u5728\u4e8e\u667a\u80fd\u4f53\u884c\u4e3a\u662f\u6309\u987a\u5e8f\u5c55\u5f00\u7684\uff0c\u6bcf\u4e2a\u52a8\u4f5c\u90fd\u9700\u8981API\u8c03\u7528\uff0c\u800c\u8fd9\u4e9b\u8c03\u7528\u53ef\u80fd\u5f88\u8017\u65f6\u3002", "method": "\u53d7\u5fae\u5904\u7406\u5668\u4e2d\u7684\u63a8\u6d4b\u6267\u884c\u548cLLM\u63a8\u7406\u4e2d\u7684\u63a8\u6d4b\u89e3\u7801\u542f\u53d1\uff0c\u63d0\u51fa\u63a8\u6d4b\u52a8\u4f5c\u6846\u67b6\uff1a\u4f7f\u7528\u66f4\u5feb\u7684\u6a21\u578b\u9884\u6d4b\u53ef\u80fd\u7684\u52a8\u4f5c\uff0c\u5b9e\u73b0\u591a\u6b65\u9aa4\u5e76\u884c\u6267\u884c\u3002\u901a\u8fc7\u66f4\u5f3a\u7684\u731c\u6d4b\u6a21\u578b\u3001top-K\u52a8\u4f5c\u9884\u6d4b\u3001\u591a\u6b65\u9aa4\u63a8\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4f18\u5316\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u6e38\u620f\u3001\u7535\u5b50\u5546\u52a1\u3001\u7f51\u7edc\u641c\u7d22\u548c\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u63a8\u6d4b\u52a8\u4f5c\u5728\u4e0b\u4e00\u52a8\u4f5c\u9884\u6d4b\u4e2d\u8fbe\u5230\u9ad8\u8fbe55%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "conclusion": "\u63a8\u6d4b\u52a8\u4f5c\u4e3a\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u4f4e\u5ef6\u8fdf\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u8f9f\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u9053\u8def\uff0c\u6027\u80fd\u53ef\u4ee5\u901a\u8fc7\u5404\u79cd\u4f18\u5316\u6280\u672f\u8fdb\u4e00\u6b65\u63d0\u5347\u3002"}}
{"id": "2510.04373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04373", "abs": "https://arxiv.org/abs/2510.04373", "authors": ["Hadi Nekoei", "Aman Jaiswal", "Patrice Bechard", "Oleh Shliazhko", "Orlando Marquez Ayala", "Mathieu Reymond", "Massimo Caccia", "Alexandre Drouin", "Sarath Chandar", "Alexandre Lacoste"], "title": "Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation", "comment": null, "summary": "Large language model (LLM) agents perform well in sequential decision-making\ntasks, but improving them on unfamiliar domains often requires costly online\ninteractions or fine-tuning on large expert datasets. These strategies are\nimpractical for closed-source models and expensive for open-source ones, with\nrisks of catastrophic forgetting. Offline trajectories offer reusable\nknowledge, yet demonstration-based methods struggle because raw traces are\nlong, noisy, and tied to specific tasks. We present Just-in-time Episodic\nFeedback Hinter (JEF Hinter), an agentic system that distills offline traces\ninto compact, context-aware hints. A zooming mechanism highlights decisive\nsteps in long trajectories, capturing both strategies and pitfalls. Unlike\nprior methods, JEF Hinter leverages both successful and failed trajectories,\nextracting guidance even when only failure data is available, while supporting\nparallelized hint generation and benchmark-independent prompting. At inference,\na retriever selects relevant hints for the current state, providing targeted\nguidance with transparency and traceability. Experiments on MiniWoB++,\nWorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms\nstrong baselines, including human- and document-based hints.", "AI": {"tldr": "JEF Hinter\u662f\u4e00\u4e2a\u4ece\u79bb\u7ebf\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u653e\u5927\u673a\u5236\u7a81\u51fa\u957f\u8f68\u8ff9\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u5229\u7528\u6210\u529f\u548c\u5931\u8d25\u7684\u8f68\u8ff9\u6570\u636e\uff0c\u5728\u63a8\u7406\u65f6\u63d0\u4f9b\u9488\u5bf9\u6027\u6307\u5bfc\u3002", "motivation": "\u6539\u8fdbLLM\u667a\u80fd\u4f53\u5728\u964c\u751f\u9886\u57df\u7684\u8868\u73b0\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u5728\u7ebf\u4ea4\u4e92\u6216\u4e13\u5bb6\u6570\u636e\u96c6\u5fae\u8c03\uff0c\u8fd9\u5bf9\u95ed\u6e90\u6a21\u578b\u4e0d\u5b9e\u7528\uff0c\u5bf9\u5f00\u6e90\u6a21\u578b\u6210\u672c\u9ad8\u4e14\u6709\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u3002\u79bb\u7ebf\u8f68\u8ff9\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u77e5\u8bc6\uff0c\u4f46\u539f\u59cb\u8f68\u8ff9\u957f\u3001\u5608\u6742\u4e14\u4e0e\u7279\u5b9a\u4efb\u52a1\u7ed1\u5b9a\u3002", "method": "JEF Hinter\u901a\u8fc7\u653e\u5927\u673a\u5236\u4ece\u79bb\u7ebf\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u63d0\u793a\uff0c\u6355\u6349\u7b56\u7565\u548c\u9677\u9631\u3002\u5229\u7528\u6210\u529f\u548c\u5931\u8d25\u8f68\u8ff9\uff0c\u652f\u6301\u5e76\u884c\u63d0\u793a\u751f\u6210\u548c\u57fa\u51c6\u65e0\u5173\u63d0\u793a\u3002\u63a8\u7406\u65f6\u901a\u8fc7\u68c0\u7d22\u5668\u9009\u62e9\u76f8\u5173\u63d0\u793a\u63d0\u4f9b\u9488\u5bf9\u6027\u6307\u5bfc\u3002", "result": "\u5728MiniWoB++\u3001WorkArena-L1\u548cWebArena-Lite\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJEF Hinter\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u4eba\u7c7b\u548c\u6587\u6863\u7684\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "JEF Hinter\u80fd\u591f\u6709\u6548\u5229\u7528\u79bb\u7ebf\u8f68\u8ff9\u77e5\u8bc6\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u900f\u660e\u53ef\u8ffd\u6eaf\u7684\u9488\u5bf9\u6027\u6307\u5bfc\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.04384", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04384", "abs": "https://arxiv.org/abs/2510.04384", "authors": ["Adam Ballew", "Jingbo Wang", "Shaogang Ren"], "title": "LLM Based Bayesian Optimization for Prompt Search", "comment": null, "summary": "Bayesian Optimization (BO) has been widely used to efficiently optimize\nexpensive black-box functions with limited evaluations. In this paper, we\ninvestigate the use of BO for prompt engineering to enhance text classification\nwith Large Language Models (LLMs). We employ an LLM-powered Gaussian Process\n(GP) as the surrogate model to estimate the performance of different prompt\ncandidates. These candidates are generated by an LLM through the expansion of a\nset of seed prompts and are subsequently evaluated using an Upper Confidence\nBound (UCB) acquisition function in conjunction with the GP posterior. The\noptimization process iteratively refines the prompts based on a subset of the\ndata, aiming to improve classification accuracy while reducing the number of\nAPI calls by leveraging the prediction uncertainty of the LLM-based GP. The\nproposed BO-LLM algorithm is evaluated on two datasets, and its advantages are\ndiscussed in detail in this paper.", "AI": {"tldr": "\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u63d0\u793a\u5de5\u7a0b\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684GP\u6a21\u578b\u8bc4\u4f30\u63d0\u793a\u5019\u9009\uff0c\u5229\u7528UCB\u91c7\u96c6\u51fd\u6570\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\uff0c\u63d0\u9ad8\u6587\u672c\u5206\u7c7b\u51c6\u786e\u6027\u5e76\u51cf\u5c11API\u8c03\u7528\u3002", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u80fd\u9ad8\u6548\u4f18\u5316\u6602\u8d35\u9ed1\u76d2\u51fd\u6570\uff0c\u672c\u6587\u63a2\u7d22\u5c06\u5176\u7528\u4e8e\u63d0\u793a\u5de5\u7a0b\u4ee5\u63d0\u5347LLM\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11API\u8c03\u7528\u6210\u672c\u3002", "method": "\u91c7\u7528LLM\u9a71\u52a8\u7684GP\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\u4f30\u8ba1\u63d0\u793a\u5019\u9009\u6027\u80fd\uff0c\u901a\u8fc7LLM\u6269\u5c55\u79cd\u5b50\u63d0\u793a\u751f\u6210\u5019\u9009\uff0c\u7ed3\u5408GP\u540e\u9a8c\u4f7f\u7528UCB\u91c7\u96c6\u51fd\u6570\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86BO-LLM\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u6027\u548c\u51cf\u5c11API\u8c03\u7528\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684BO-LLM\u7b97\u6cd5\u6709\u6548\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548cLLM\u80fd\u529b\uff0c\u4e3a\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2510.04391", "categories": ["cs.AI", "cs.CL", "cs.SI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.04391", "abs": "https://arxiv.org/abs/2510.04391", "authors": ["Saurabh Ranjan", "Brian Odegaard"], "title": "Internal World Models as Imagination Networks in Cognitive Agents", "comment": null, "summary": "What is the computational objective of imagination? While classical\ninterpretations suggest imagination is useful for maximizing rewards, recent\nfindings challenge this view. In this study, we propose that imagination serves\nto access an internal world model (IWM) and use psychological network analysis\nto explore IWMs in humans and large language models (LLMs). Specifically, we\nassessed imagination vividness ratings using two questionnaires and constructed\nimagination networks from these reports. Imagination networks from human groups\nshowed correlations between different centrality measures, including expected\ninfluence, strength, and closeness. However, imagination networks from LLMs\nshowed a lack of clustering and lower correlations between centrality measures\nunder different prompts and conversational memory conditions. Together, these\nresults indicate a lack of similarity between IWMs in human and LLM agents.\nOverall, our study offers a novel method for comparing internally-generated\nrepresentations in humans and AI, providing insights for developing human-like\nimagination in artificial intelligence.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u60f3\u8c61\u7684\u8ba1\u7b97\u76ee\u6807\u662f\u8bbf\u95ee\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u5fc3\u7406\u7f51\u7edc\u5206\u6790\u6bd4\u8f83\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u60f3\u8c61\u7f51\u7edc\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u4e2d\u5fc3\u6027\u6307\u6807\u76f8\u5173\u6027\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u60f3\u8c61\u7684\u8ba1\u7b97\u76ee\u6807\uff0c\u6311\u6218\u4f20\u7edf\u8ba4\u4e3a\u60f3\u8c61\u662f\u4e3a\u4e86\u6700\u5927\u5316\u5956\u52b1\u7684\u89c2\u70b9\uff0c\u7814\u7a76\u4eba\u7c7b\u548cAI\u7684\u5185\u90e8\u4e16\u754c\u6a21\u578b\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u95ee\u5377\u8c03\u67e5\u8bc4\u4f30\u60f3\u8c61\u751f\u52a8\u5ea6\uff0c\u6784\u5efa\u60f3\u8c61\u7f51\u7edc\uff0c\u5206\u6790\u4e2d\u5fc3\u6027\u6307\u6807\uff08\u9884\u671f\u5f71\u54cd\u3001\u5f3a\u5ea6\u3001\u7d27\u5bc6\u6027\uff09\u7684\u76f8\u5173\u6027\uff0c\u6bd4\u8f83\u4eba\u7c7b\u548cLLM\u5728\u4e0d\u540c\u63d0\u793a\u548c\u5bf9\u8bdd\u8bb0\u5fc6\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u4eba\u7c7b\u60f3\u8c61\u7f51\u7edc\u663e\u793a\u4e0d\u540c\u4e2d\u5fc3\u6027\u6307\u6807\u95f4\u5b58\u5728\u76f8\u5173\u6027\uff0c\u800cLLM\u60f3\u8c61\u7f51\u7edc\u7f3a\u4e4f\u805a\u7c7b\u4e14\u4e2d\u5fc3\u6027\u6307\u6807\u76f8\u5173\u6027\u8f83\u4f4e\uff0c\u8868\u660e\u4e24\u8005\u5185\u90e8\u4e16\u754c\u6a21\u578b\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u5185\u90e8\u751f\u6210\u8868\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u5f00\u53d1\u7c7b\u4eba\u60f3\u8c61\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.04399", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04399", "abs": "https://arxiv.org/abs/2510.04399", "authors": ["Charles L. Wang", "Keir Dorchen", "Peter Jin"], "title": "Utility-Learning Tension in Self-Modifying Agents", "comment": null, "summary": "As systems trend toward superintelligence, a natural modeling premise is that\nagents can self-improve along every facet of their own design. We formalize\nthis with a five-axis decomposition and a decision layer, separating incentives\nfrom learning behavior and analyzing axes in isolation. Our central result\nidentifies and introduces a sharp utility--learning tension, the structural\nconflict in self-modifying systems whereby utility-driven changes that improve\nimmediate or expected performance can also erode the statistical preconditions\nfor reliable learning and generalization. Our findings show that\ndistribution-free guarantees are preserved iff the policy-reachable model\nfamily is uniformly capacity-bounded; when capacity can grow without limit,\nutility-rational self-changes can render learnable tasks unlearnable. Under\nstandard assumptions common in practice, these axes reduce to the same capacity\ncriterion, yielding a single boundary for safe self-modification. Numerical\nexperiments across several axes validate the theory by comparing destructive\nutility policies against our proposed two-gate policies that preserve\nlearnability.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u81ea\u6539\u8fdb\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u6548\u7528-\u5b66\u4e60\u5f20\u529b\uff0c\u53d1\u73b0\u6548\u7528\u9a71\u52a8\u7684\u81ea\u6211\u4fee\u6539\u53ef\u80fd\u7834\u574f\u5b66\u4e60\u6240\u9700\u7684\u7edf\u8ba1\u524d\u63d0\u6761\u4ef6\uff0c\u63d0\u51fa\u4e86\u4fdd\u6301\u53ef\u5b66\u4e60\u6027\u7684\u5b89\u5168\u81ea\u4fee\u6539\u8fb9\u754c\u6761\u4ef6\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u5411\u8d85\u667a\u80fd\u53d1\u5c55\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u5206\u6790\u667a\u80fd\u4f53\u5728\u6240\u6709\u8bbe\u8ba1\u7ef4\u5ea6\u4e0a\u81ea\u6211\u6539\u8fdb\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u8bc6\u522b\u548c\u89e3\u51b3\u6548\u7528\u9a71\u52a8\u4fee\u6539\u4e0e\u5b66\u4e60\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u51b2\u7a81\u3002", "method": "\u91c7\u7528\u4e94\u8f74\u5206\u89e3\u548c\u51b3\u7b56\u5c42\u5206\u79bb\u7684\u65b9\u6cd5\uff0c\u5c06\u6fc0\u52b1\u4e0e\u5b66\u4e60\u884c\u4e3a\u5206\u5f00\u5206\u6790\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u7528\u7b56\u7565\u4e0e\u4fdd\u6301\u53ef\u5b66\u4e60\u6027\u7684\u53cc\u95e8\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u5f53\u6a21\u578b\u5bb9\u91cf\u65e0\u9650\u5236\u589e\u957f\u65f6\uff0c\u6548\u7528\u7406\u6027\u7684\u81ea\u6211\u4fee\u6539\u53ef\u80fd\u4f7f\u53ef\u5b66\u4e60\u4efb\u52a1\u53d8\u5f97\u4e0d\u53ef\u5b66\u4e60\uff0c\u53ea\u6709\u5728\u7b56\u7565\u53ef\u8fbe\u6a21\u578b\u65cf\u5747\u5300\u5bb9\u91cf\u6709\u754c\u65f6\u624d\u80fd\u4fdd\u6301\u5206\u5e03\u65e0\u5173\u7684\u4fdd\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5b89\u5168\u81ea\u4fee\u6539\u7684\u5355\u4e00\u8fb9\u754c\u6761\u4ef6\uff0c\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\u5404\u8f74\u90fd\u5f52\u7ed3\u4e3a\u76f8\u540c\u7684\u5bb9\u91cf\u51c6\u5219\uff0c\u901a\u8fc7\u53cc\u95e8\u7b56\u7565\u53ef\u4ee5\u6709\u6548\u4fdd\u6301\u7cfb\u7edf\u7684\u53ef\u5b66\u4e60\u6027\u3002"}}
{"id": "2510.04474", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04474", "abs": "https://arxiv.org/abs/2510.04474", "authors": ["Gang Li", "Yan Chen", "Ming Lin", "Tianbao Yang"], "title": "DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization", "comment": "20 pages, 7 figures", "summary": "Recent large reasoning models (LRMs) driven by reinforcement learning\nalgorithms (e.g., GRPO) have achieved remarkable performance on challenging\nreasoning tasks. However, these models suffer from overthinking, generating\nunnecessarily long and redundant reasoning even for simple questions, which\nsubstantially increases computational cost and response latency. While existing\nmethods incorporate length rewards to GRPO to promote concise reasoning, they\nincur significant performance degradation. We identify the root cause: when\nrewards for correct but long rollouts are penalized, GRPO's group-relative\nadvantage function can assign them negative advantages, actively discouraging\nvalid reasoning. To overcome this, we propose Decoupled Reward Policy\nOptimization (DRPO), a novel framework that decouples the length-based learning\nsignal of correct rollouts from incorrect ones. DRPO ensures that reward\nsignals for correct rollouts are normalized solely within the positive group,\nshielding them from interference by negative samples. The DRPO's objective is\ngrounded in integrating an optimized positive data distribution, which\nmaximizes length-based rewards under a KL regularization, into a discriminative\nobjective. We derive a closed-form solution for this distribution, enabling\nefficient computation of the objective and its gradients using only on-policy\ndata and importance weighting. Of independent interest, this formulation is\ngeneral and can incorporate other preference rewards of positive data beyond\nlength. Experiments on mathematical reasoning tasks demonstrate DRPO's\nsignificant superiority over six efficient reasoning baselines. Notably, with a\n1.5B model, our method achieves 77\\% length reduction with only 1.1\\%\nperformance loss on simple questions like GSM8k dataset, while the follow-up\nbaseline sacrifices 4.3\\% for 68\\% length reduction.", "AI": {"tldr": "DRPO\u662f\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u6b63\u786e\u548c\u9519\u8bef\u63a8\u7406\u8fc7\u7a0b\u7684\u957f\u5ea6\u5956\u52b1\u4fe1\u53f7\uff0c\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5373\u4f7f\u7b80\u5355\u95ee\u9898\u4e5f\u4f1a\u751f\u6210\u5197\u957f\u63a8\u7406\uff0c\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u3002\u73b0\u6709\u65b9\u6cd5\u5f15\u5165\u957f\u5ea6\u5956\u52b1\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51faDRPO\u6846\u67b6\uff0c\u5c06\u6b63\u786e\u63a8\u7406\u8fc7\u7a0b\u7684\u957f\u5ea6\u5956\u52b1\u4fe1\u53f7\u4e0e\u9519\u8bef\u63a8\u7406\u8fc7\u7a0b\u89e3\u8026\uff0c\u786e\u4fdd\u6b63\u786e\u63a8\u7406\u7684\u5956\u52b1\u4ec5\u5728\u6b63\u6837\u672c\u7ec4\u5185\u5f52\u4e00\u5316\uff0c\u907f\u514d\u8d1f\u6837\u672c\u5e72\u6270\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cDRPO\u663e\u8457\u4f18\u4e8e\u516d\u4e2a\u9ad8\u6548\u63a8\u7406\u57fa\u7ebf\u65b9\u6cd5\u3002\u4f7f\u75281.5B\u6a21\u578b\u5728GSM8k\u6570\u636e\u96c6\u4e0a\u5b9e\u73b077%\u957f\u5ea6\u51cf\u5c11\uff0c\u4ec5\u635f\u59311.1%\u6027\u80fd\u3002", "conclusion": "DRPO\u80fd\u6709\u6548\u89e3\u51b3\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\uff0c\u4e14\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\u53ef\u6574\u5408\u5176\u4ed6\u504f\u597d\u5956\u52b1\u3002"}}
{"id": "2510.04480", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04480", "abs": "https://arxiv.org/abs/2510.04480", "authors": ["Yunuo Cen", "Zixuan Wang", "Jintao Zhang", "Zhiwei Zhang", "Xuanyao Fong"], "title": "On Continuous Optimization for Constraint Satisfaction Problems", "comment": null, "summary": "Constraint satisfaction problems (CSPs) are fundamental in mathematics,\nphysics, and theoretical computer science. While conflict-driven clause\nlearning Boolean Satisfiability (SAT) solvers have achieved remarkable success\nand become the mainstream approach for Boolean satisfiability, recent advances\nshow that modern continuous local search (CLS) solvers can achieve highly\ncompetitive results on certain classes of SAT problems. Motivated by these\nadvances, we extend the CLS framework from Boolean SAT to general CSP with\nfinite-domain variables and expressive constraints. We present FourierCSP, a\ncontinuous optimization framework that generalizes the Walsh-Fourier transform\nto CSP, allowing for transforming versatile constraints to compact multilinear\npolynomials, thereby avoiding the need for auxiliary variables and\nmemory-intensive encodings. Our approach leverages efficient evaluation and\ndifferentiation of the objective via circuit-output probability and employs a\nprojected gradient optimization method with theoretical guarantees. Empirical\nresults on benchmark suites demonstrate that FourierCSP is scalable and\ncompetitive, significantly broadening the class of problems that can be\nefficiently solved by CLS techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86FourierCSP\u6846\u67b6\uff0c\u5c06\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u4ece\u5e03\u5c14SAT\u6269\u5c55\u5230\u901a\u7528\u6709\u9650\u57dfCSP\uff0c\u901a\u8fc7Walsh-Fourier\u53d8\u6362\u5c06\u7ea6\u675f\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u591a\u7ebf\u6027\u591a\u9879\u5f0f\uff0c\u65e0\u9700\u8f85\u52a9\u53d8\u91cf\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u7f16\u7801\u3002", "motivation": "\u53d7\u73b0\u4ee3\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u6c42\u89e3\u5668\u5728\u7279\u5b9aSAT\u95ee\u9898\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5c06CLS\u6846\u67b6\u4ece\u5e03\u5c14SAT\u6269\u5c55\u5230\u5177\u6709\u6709\u9650\u57df\u53d8\u91cf\u548c\u8868\u8fbe\u6027\u7ea6\u675f\u7684\u901a\u7528CSP\u95ee\u9898\u3002", "method": "\u4f7f\u7528Walsh-Fourier\u53d8\u6362\u5c06\u5404\u79cd\u7ea6\u675f\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u591a\u7ebf\u6027\u591a\u9879\u5f0f\uff0c\u901a\u8fc7\u7535\u8def\u8f93\u51fa\u6982\u7387\u8fdb\u884c\u9ad8\u6548\u7684\u76ee\u6807\u51fd\u6570\u8bc4\u4f30\u548c\u5fae\u5206\uff0c\u5e76\u91c7\u7528\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u6295\u5f71\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cFourierCSP\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u7ade\u4e89\u529b\uff0c\u663e\u8457\u6269\u5c55\u4e86CLS\u6280\u672f\u80fd\u9ad8\u6548\u6c42\u89e3\u7684\u95ee\u9898\u7c7b\u522b\u3002", "conclusion": "FourierCSP\u6210\u529f\u5c06\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u6280\u672f\u6269\u5c55\u5230\u901a\u7528CSP\uff0c\u4e3a\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u9ad8\u6548\u6c42\u89e3\u6846\u67b6\u3002"}}
{"id": "2510.04491", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04491", "abs": "https://arxiv.org/abs/2510.04491", "authors": ["Muyu He", "Anand Kumar", "Tsach Mackey", "Meghana Rajeev", "James Zou", "Nazneen Rajani"], "title": "Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents", "comment": "25 pages", "summary": "Despite rapid progress in building conversational AI agents, robustness is\nstill largely untested. Small shifts in user behavior, such as being more\nimpatient, incoherent, or skeptical, can cause sharp drops in agent\nperformance, revealing how brittle current AI agents are. Today's benchmarks\nfail to capture this fragility: agents may perform well under standard\nevaluations but degrade spectacularly in more realistic and varied settings. We\naddress this robustness testing gap by introducing TraitBasis, a lightweight,\nmodel-agnostic method for systematically stress testing AI agents. TraitBasis\nlearns directions in activation space corresponding to steerable user traits\n(e.g., impatience or incoherence), which can be controlled, scaled, composed,\nand applied at inference time without any fine-tuning or extra data. Using\nTraitBasis, we extend $\\tau$-Bench to $\\tau$-Trait, where user behaviors are\naltered via controlled trait vectors. We observe on average a 2%-30%\nperformance degradation on $\\tau$-Trait across frontier models, highlighting\nthe lack of robustness of current AI agents to variations in user behavior.\nTogether, these results highlight both the critical role of robustness testing\nand the promise of TraitBasis as a simple, data-efficient, and compositional\ntool. By powering simulation-driven stress tests and training loops, TraitBasis\nopens the door to building AI agents that remain reliable in the unpredictable\ndynamics of real-world human interactions. We have open-sourced $\\tau$-Trai\nacross four domains: airline, retail, telecom, and telehealth, so the community\ncan systematically QA their agents under realistic, behaviorally diverse\nintents and trait scenarios: https://github.com/collinear-ai/tau-trait.", "AI": {"tldr": "TraitBasis\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u538b\u529b\u6d4b\u8bd5AI\u4ee3\u7406\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u63a7\u5236\u7528\u6237\u7279\u5f81\u5411\u91cf\u6765\u6a21\u62df\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u53d8\u5316\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5728\u6807\u51c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7528\u6237\u884c\u4e3a\u53d8\u5316\uff08\u5982\u4e0d\u8010\u70e6\u3001\u4e0d\u8fde\u8d2f\u6216\u6000\u7591\uff09\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u8fd9\u79cd\u8106\u5f31\u6027\u3002", "method": "TraitBasis\u5b66\u4e60\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u53ef\u63a7\u5236\u7684\u7528\u6237\u7279\u5f81\u65b9\u5411\uff08\u5982\u4e0d\u8010\u70e6\u6216\u4e0d\u8fde\u8d2f\uff09\uff0c\u8fd9\u4e9b\u7279\u5f81\u5411\u91cf\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u88ab\u63a7\u5236\u3001\u7f29\u653e\u3001\u7ec4\u5408\u548c\u5e94\u7528\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u989d\u5916\u6570\u636e\u3002", "result": "\u4f7f\u7528TraitBasis\u6269\u5c55\u03c4-Bench\u5230\u03c4-Trait\uff0c\u5728\u56db\u4e2a\u9886\u57df\uff08\u822a\u7a7a\u3001\u96f6\u552e\u3001\u7535\u4fe1\u3001\u8fdc\u7a0b\u533b\u7597\uff09\u6d4b\u8bd5\u524d\u6cbf\u6a21\u578b\uff0c\u89c2\u5bdf\u5230\u5e73\u57472%-30%\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "TraitBasis\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u3001\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u7ec4\u5408\u7684\u5de5\u5177\uff0c\u4e3a\u6784\u5efa\u5728\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u4ea4\u4e92\u52a8\u6001\u4e2d\u4fdd\u6301\u53ef\u9760\u7684AI\u4ee3\u7406\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2510.04514", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.CV", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.04514", "abs": "https://arxiv.org/abs/2510.04514", "authors": ["Rachneet Kaur", "Nishan Srishankar", "Zhen Zeng", "Sumitra Ganesh", "Manuela Veloso"], "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering", "comment": "53 pages, 12 figures, 15 tables", "summary": "Recent multimodal LLMs have shown promise in chart-based visual question\nanswering, but their performance declines sharply on unannotated charts, those\nrequiring precise visual interpretation rather than relying on textual\nshortcuts. To address this, we introduce ChartAgent, a novel agentic framework\nthat explicitly performs visual reasoning directly within the chart's spatial\ndomain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively\ndecomposes queries into visual subtasks and actively manipulates and interacts\nwith chart images through specialized actions such as drawing annotations,\ncropping regions (e.g., segmenting pie slices, isolating bars), and localizing\naxes, using a library of chart-specific vision tools to fulfill each subtask.\nThis iterative reasoning process closely mirrors human cognitive strategies for\nchart comprehension. ChartAgent achieves state-of-the-art accuracy on the\nChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%\nabsolute gain overall and 17.31% on unannotated, numerically intensive queries.\nFurthermore, our analyses show that ChartAgent is (a) effective across diverse\nchart types, (b) achieve the highest scores across varying visual and reasoning\ncomplexity levels, and (c) serves as a plug-and-play framework that boosts\nperformance across diverse underlying LLMs. Our work is among the first to\ndemonstrate visually grounded reasoning for chart understanding using\ntool-augmented multimodal agents.", "AI": {"tldr": "ChartAgent\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u56fe\u8868\u7a7a\u95f4\u57df\u4e2d\u6267\u884c\u89c6\u89c9\u63a8\u7406\u6765\u89e3\u51b3\u672a\u6807\u6ce8\u56fe\u8868\u7406\u89e3\u95ee\u9898\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u6587\u672c\u6377\u5f84\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001LLM\u5728\u57fa\u4e8e\u56fe\u8868\u7684\u89c6\u89c9\u95ee\u7b54\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u89c6\u89c9\u89e3\u91ca\u7684\u672a\u6807\u6ce8\u56fe\u8868\u4e0a\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4eec\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u6377\u5f84\u800c\u975e\u771f\u6b63\u7684\u89c6\u89c9\u63a8\u7406\u3002", "method": "ChartAgent\u8fed\u4ee3\u5730\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u89c6\u89c9\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u89c6\u89c9\u5de5\u5177\uff08\u5982\u7ed8\u5236\u6ce8\u91ca\u3001\u88c1\u526a\u533a\u57df\u3001\u5b9a\u4f4d\u5750\u6807\u8f74\uff09\u4e3b\u52a8\u64cd\u4f5c\u548c\u4ea4\u4e92\u56fe\u8868\u56fe\u50cf\uff0c\u6a21\u62df\u4eba\u7c7b\u56fe\u8868\u7406\u89e3\u8ba4\u77e5\u7b56\u7565\u3002", "result": "\u5728ChartBench\u548cChartX\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u6574\u4f53\u63d0\u534716.07%\uff0c\u5728\u672a\u6807\u6ce8\u6570\u503c\u5bc6\u96c6\u578b\u67e5\u8be2\u4e0a\u63d0\u534717.31%\uff0c\u4e14\u5728\u4e0d\u540c\u56fe\u8868\u7c7b\u578b\u548c\u590d\u6742\u5ea6\u7ea7\u522b\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "ChartAgent\u662f\u9996\u6279\u4f7f\u7528\u5de5\u5177\u589e\u5f3a\u591a\u6a21\u6001\u4ee3\u7406\u8fdb\u884c\u89c6\u89c9\u57fa\u7840\u63a8\u7406\u7684\u56fe\u8868\u7406\u89e3\u6846\u67b6\uff0c\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6846\u67b6\u63d0\u5347\u5404\u79cd\u5e95\u5c42LLM\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04520", "abs": "https://arxiv.org/abs/2510.04520", "authors": ["Hanyu Wang", "Ruohan Xie", "Yutong Wang", "Guoxiong Gao", "Xintao Yu", "Bin Dong"], "title": "Aria: An Agent For Retrieval and Iterative Auto-Formalization via Dependency Graph", "comment": null, "summary": "Accurate auto-formalization of theorem statements is essential for advancing\nautomated discovery and verification of research-level mathematics, yet remains\na major bottleneck for LLMs due to hallucinations, semantic mismatches, and\ntheir inability to synthesize new definitions. To tackle these issues, we\npresent Aria (Agent for Retrieval and Iterative Autoformalization), a system\nfor conjecture-level formalization in Lean that emulates human expert reasoning\nvia a two-phase Graph-of-Thought process: recursively decomposing statements\ninto a dependency graph and then constructing formalizations from grounded\nconcepts. To ensure semantic correctness, we introduce AriaScorer, a checker\nthat retrieves definitions from Mathlib for term-level grounding, enabling\nrigorous and reliable verification. We evaluate Aria on diverse benchmarks. On\nProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy,\nsurpassing previous methods. On FATE-X, a suite of challenging algebra problems\nfrom research literature, it outperforms the best baseline with 44.0% vs. 24.0%\nfinal accuracy. On a dataset of homological conjectures, Aria reaches 42.9%\nfinal accuracy while all other models score 0%.", "AI": {"tldr": "Aria\u662f\u4e00\u4e2a\u7528\u4e8e\u5b9a\u7406\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u56fe\u601d\u8003\u8fc7\u7a0b\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u5b9a\u7406\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u7684\u5e7b\u89c9\u3001\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u65e0\u6cd5\u5408\u6210\u65b0\u5b9a\u4e49\u7b49\u95ee\u9898\uff0c\u63a8\u52a8\u6570\u5b66\u81ea\u52a8\u53d1\u73b0\u548c\u9a8c\u8bc1\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u56fe\u601d\u8003\u8fc7\u7a0b\uff1a\u9012\u5f52\u5206\u89e3\u8bed\u53e5\u4e3a\u4f9d\u8d56\u56fe\uff0c\u7136\u540e\u4ece\u57fa\u7840\u6982\u5ff5\u6784\u5efa\u5f62\u5f0f\u5316\uff1b\u5f15\u5165AriaScorer\u68c0\u67e5\u5668\u4eceMathlib\u68c0\u7d22\u5b9a\u4e49\u8fdb\u884c\u672f\u8bed\u7ea7\u57fa\u7840\u9a8c\u8bc1\u3002", "result": "\u5728ProofNet\u4e0a\u8fbe\u523091.6%\u7f16\u8bd1\u6210\u529f\u7387\u548c68.5%\u6700\u7ec8\u51c6\u786e\u7387\uff1b\u5728FATE-X\u4e0a44.0% vs 24.0%\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\uff1b\u5728\u540c\u8c03\u731c\u60f3\u6570\u636e\u96c6\u4e0a\u8fbe\u523042.9%\u51c6\u786e\u7387\u800c\u5176\u4ed6\u6a21\u578b\u4e3a0%\u3002", "conclusion": "Aria\u7cfb\u7edf\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u63a8\u7406\u8fc7\u7a0b\u548c\u4e25\u683c\u7684\u8bed\u4e49\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u7406\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04532", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04532", "abs": "https://arxiv.org/abs/2510.04532", "authors": ["Xurui Song", "Shuo Huai", "JingJing Jiang", "Jiayi Kong", "Jun Luo"], "title": "More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models", "comment": "The dataset will be released publicly once the paper is accepted for\n  publication", "summary": "Vision-Language Model (VLM) driving agents promise explainable end-to-end\nautonomy by first producing natural-language reasoning and then predicting\ntrajectory planning. However, whether planning is causally driven by this\nreasoning remains a critical but unverified assumption. To investigate this, we\nbuild DriveMind, a large-scale driving Visual Question Answering (VQA) corpus\nwith plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.\nOur data generation process converts sensors and annotations into structured\ninputs and, crucially, separates priors from to-be-reasoned signals, enabling\nclean information ablations. Using DriveMind, we train representative VLM\nagents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization\n(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,\nindicate a consistent causal disconnect in reasoning-planning: removing\nego/navigation priors causes large drops in planning scores, whereas removing\nCoT produces only minor changes. Attention analysis further shows that planning\nprimarily focuses on priors rather than the CoT. Based on this evidence, we\npropose the Reasoning-Planning Decoupling Hypothesis, positing that the\ntraining-yielded reasoning is an ancillary byproduct rather than a causal\nmediator. To enable efficient diagnosis, we also introduce a novel,\ntraining-free probe that measures an agent's reliance on priors by evaluating\nits planning robustness against minor input perturbations. In summary, we\nprovide the community with a new dataset and a diagnostic tool to evaluate the\ncausal fidelity of future models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u7684\u63a8\u7406\u4e0e\u89c4\u5212\u5b58\u5728\u56e0\u679c\u8131\u8282\uff0c\u89c4\u5212\u4e3b\u8981\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u800c\u975e\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u63a8\u7406-\u89c4\u5212\u89e3\u8026\u5047\u8bf4\u3002", "motivation": "\u9a8c\u8bc1VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u662f\u5426\u771f\u6b63\u56e0\u679c\u9a71\u52a8\u8f68\u8ff9\u89c4\u5212\u8fd9\u4e00\u5173\u952e\u5047\u8bbe\u3002", "method": "\u6784\u5efaDriveMind\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4fe1\u606f\u6d88\u878d\u5b9e\u9a8c\u8bad\u7ec3VLM\u4ee3\u7406\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u5206\u6790\u9a8c\u8bc1\u63a8\u7406\u4e0e\u89c4\u5212\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u79fb\u9664\u5148\u9a8c\u77e5\u8bc6\u5bfc\u81f4\u89c4\u5212\u5206\u6570\u5927\u5e45\u4e0b\u964d\uff0c\u800c\u79fb\u9664\u63a8\u7406\u94fe\u4ec5\u4ea7\u751f\u5fae\u5c0f\u53d8\u5316\uff0c\u8868\u660e\u89c4\u5212\u4e3b\u8981\u4f9d\u8d56\u5148\u9a8c\u800c\u975e\u63a8\u7406\u3002", "conclusion": "VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u7684\u63a8\u7406\u662f\u8bad\u7ec3\u4ea7\u751f\u7684\u526f\u4ea7\u54c1\u800c\u975e\u56e0\u679c\u4e2d\u4ecb\uff0c\u63d0\u51fa\u4e86\u8bca\u65ad\u5de5\u5177\u6765\u8bc4\u4f30\u672a\u6765\u6a21\u578b\u7684\u56e0\u679c\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2510.04542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04542", "abs": "https://arxiv.org/abs/2510.04542", "authors": ["Wolfgang Lehrach", "Daniel Hennes", "Miguel Lazaro-Gredilla", "Xinghua Lou", "Carter Wendelken", "Zun Li", "Antoine Dedieu", "Jordi Grau-Moya", "Marc Lanctot", "Atil Iscen", "John Schultz", "Marcus Chiam", "Ian Gemp", "Piotr Zielinski", "Satinder Singh", "Kevin P. Murphy"], "title": "Code World Models for General Game Playing", "comment": null, "summary": "Large Language Models (LLMs) reasoning abilities are increasingly being\napplied to classical board and card games, but the dominant approach --\ninvolving prompting for direct move generation -- has significant drawbacks. It\nrelies on the model's implicit fragile pattern-matching capabilities, leading\nto frequent illegal moves and strategically shallow play. Here we introduce an\nalternative approach: We use the LLM to translate natural language rules and\ngame trajectories into a formal, executable world model represented as Python\ncode. This generated model -- comprising functions for state transition, legal\nmove enumeration, and termination checks -- serves as a verifiable simulation\nengine for high-performance planning algorithms like Monte Carlo tree search\n(MCTS). In addition, we prompt the LLM to generate heuristic value functions\n(to make MCTS more efficient), and inference functions (to estimate hidden\nstates in imperfect information games). Our method offers three distinct\nadvantages compared to directly using the LLM as a policy: (1) Verifiability:\nThe generated CWM serves as a formal specification of the game's rules,\nallowing planners to algorithmically enumerate valid actions and avoid illegal\nmoves, contingent on the correctness of the synthesized model; (2) Strategic\nDepth: We combine LLM semantic understanding with the deep search power of\nclassical planners; and (3) Generalization: We direct the LLM to focus on the\nmeta-task of data-to-code translation, enabling it to adapt to new games more\neasily. We evaluate our agent on 10 different games, of which 4 are novel and\ncreated for this paper. 5 of the games are fully observed (perfect\ninformation), and 5 are partially observed (imperfect information). We find\nthat our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10\nconsidered games.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528LLM\u5c06\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u548c\u6e38\u620f\u8f68\u8ff9\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u7684Python\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408MCTS\u7b49\u89c4\u5212\u7b97\u6cd5\uff0c\u66ff\u4ee3\u76f4\u63a5\u4f7f\u7528LLM\u751f\u6210\u79fb\u52a8\u7684\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u4f7f\u7528LLM\u76f4\u63a5\u751f\u6210\u6e38\u620f\u79fb\u52a8\u7684\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u4f9d\u8d56\u6a21\u578b\u8106\u5f31\u7684\u6a21\u5f0f\u5339\u914d\u80fd\u529b\uff0c\u7ecf\u5e38\u4ea7\u751f\u975e\u6cd5\u79fb\u52a8\uff0c\u7b56\u7565\u6df1\u5ea6\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528LLM\u5c06\u6e38\u620f\u89c4\u5219\u548c\u8f68\u8ff9\u7ffb\u8bd1\u6210\u5f62\u5f0f\u5316\u7684Python\u4ee3\u7801\u6a21\u578b\uff0c\u5305\u542b\u72b6\u6001\u8f6c\u79fb\u3001\u5408\u6cd5\u79fb\u52a8\u679a\u4e3e\u548c\u7ec8\u6b62\u68c0\u67e5\u51fd\u6570\uff0c\u5e76\u751f\u6210\u542f\u53d1\u5f0f\u4ef7\u503c\u51fd\u6570\u548c\u63a8\u7406\u51fd\u6570\uff0c\u7ed3\u5408MCTS\u7b49\u89c4\u5212\u7b97\u6cd5\u3002", "result": "\u572810\u4e2a\u6e38\u620f\uff084\u4e2a\u4e3a\u672c\u8bba\u6587\u521b\u5efa\u7684\u65b0\u6e38\u620f\uff09\u4e0a\u8bc4\u4f30\uff0c\u5176\u4e2d5\u4e2a\u5b8c\u5168\u89c2\u5bdf\uff0c5\u4e2a\u90e8\u5206\u89c2\u5bdf\u3002\u8be5\u65b9\u6cd5\u57289\u4e2a\u6e38\u620f\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u5339\u914dGemini 2.5 Pro\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u76f8\u6bd4\u76f4\u63a5\u4f7f\u7528LLM\u4f5c\u4e3a\u7b56\u7565\u5177\u6709\u4e09\u4e2a\u4f18\u52bf\uff1a\u53ef\u9a8c\u8bc1\u6027\u3001\u7b56\u7565\u6df1\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u65b0\u6e38\u620f\u5e76\u907f\u514d\u975e\u6cd5\u79fb\u52a8\u3002"}}
{"id": "2510.04550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04550", "abs": "https://arxiv.org/abs/2510.04550", "authors": ["Pengfei He", "Zhenwei Dai", "Bing He", "Hui Liu", "Xianfeng Tang", "Hanqing Lu", "Juanhui Li", "Jiayuan Ding", "Subhabrata Mukherjee", "Suhang Wang", "Yue Xing", "Jiliang Tang", "Benoit Dumoulin"], "title": "TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use", "comment": null, "summary": "Large language model (LLM)-based agents increasingly rely on tool use to\ncomplete real-world tasks. While existing works evaluate the LLMs' tool use\ncapability, they largely focus on the final answers yet overlook the detailed\ntool usage trajectory, i.e., whether tools are selected, parameterized, and\nordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to\ncomprehensively evaluate LLMs' tool use capability through diverse tasks with\nfine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable\ntools across practical domains with tasks grounded in production-style APIs,\nand synthesizes trajectories that vary in breadth (parallel calls) and depth\n(interdependent chains). Besides final accuracy, TRAJECT-Bench also reports\ntrajectory-level diagnostics, including tool selection and argument\ncorrectness, and dependency/order satisfaction. Analyses reveal failure modes\nsuch as similar tool confusion and parameter-blind selection, and scaling\nbehavior with tool diversity and trajectory length where the bottleneck of\ntransiting from short to mid-length trajectories is revealed, offering\nactionable guidance for LLMs' tool use.", "AI": {"tldr": "TRAJECT-Bench\u662f\u4e00\u4e2a\u8f68\u8ff9\u611f\u77e5\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LLM\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6307\u6807\u5206\u6790\u5de5\u5177\u9009\u62e9\u3001\u53c2\u6570\u5316\u548c\u6392\u5e8f\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u800c\u5ffd\u7565\u4e86\u8be6\u7ec6\u7684\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30LLM\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u9ad8\u4fdd\u771f\u53ef\u6267\u884c\u5de5\u5177\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5b9e\u9645\u9886\u57df\u548c\u751f\u4ea7\u98ce\u683cAPI\u7684\u4efb\u52a1\uff0c\u5e76\u5408\u6210\u4e0d\u540c\u5e7f\u5ea6\u548c\u6df1\u5ea6\u7684\u8f68\u8ff9\u3002", "result": "\u63ed\u793a\u4e86\u5931\u8d25\u6a21\u5f0f\uff08\u5982\u76f8\u4f3c\u5de5\u5177\u6df7\u6dc6\u548c\u53c2\u6570\u76f2\u9009\uff09\u4ee5\u53ca\u5de5\u5177\u591a\u6837\u6027\u548c\u8f68\u8ff9\u957f\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e86\u4ece\u77ed\u8f68\u8ff9\u5230\u4e2d\u957f\u8f68\u8ff9\u8f6c\u6362\u7684\u74f6\u9888\u3002", "conclusion": "TRAJECT-Bench\u63d0\u4f9b\u4e86\u5bf9LLM\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u4e3a\u6539\u8fdbLLM\u5de5\u5177\u4f7f\u7528\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.04560", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04560", "abs": "https://arxiv.org/abs/2510.04560", "authors": ["Honghao Fu", "Yuan Ouyang", "Kai-Wei Chang", "Yiwei Wang", "Zi Huang", "Yujun Cai"], "title": "ContextNav: Towards Agentic Multimodal In-Context Learning", "comment": null, "summary": "Recent advances demonstrate that multimodal large language models (MLLMs)\nexhibit strong multimodal in-context learning (ICL) capabilities, enabling them\nto adapt to novel vision-language tasks from a few contextual examples.\nHowever, existing ICL approaches face challenges in reconciling scalability\nwith robustness across diverse tasks and noisy contextual examples: manually\nselecting examples produces clean contexts but is labor-intensive and\ntask-specific, while similarity-based retrieval improves scalability but could\nintroduce irrelevant or structurally inconsistent samples that degrade ICL\nperformance. To address these limitations, we propose ContextNav, the first\nagentic framework that integrates the scalability of automated retrieval with\nthe quality and adaptiveness of human-like curation, enabling noise-robust and\ndynamically optimized contextualization for multimodal ICL. ContextNav unifies\ncontext management and noise-robust contextualization within a closed-loop\nworkflow driven by graph-based orchestration. Specifically, it builds a\nresource-aware multimodal embedding pipeline, maintains a retrievable vector\ndatabase, and applies agentic retrieval and structural alignment to construct\nnoise-resilient contexts. An Operational Grammar Graph (OGG) further supports\nadaptive workflow planning and optimization, enabling the agent to refine its\noperational strategies based on downstream ICL feedback. Experimental results\ndemonstrate that ContextNav achieves state-of-the-art performance across\nvarious datasets, underscoring the promise of agentic workflows for advancing\nscalable and robust contextualization in multimodal ICL.", "AI": {"tldr": "\u63d0\u51fa\u4e86ContextNav\u6846\u67b6\uff0c\u9996\u4e2a\u5c06\u81ea\u52a8\u68c0\u7d22\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u4eba\u7c7b\u7b56\u5c55\u8d28\u91cf\u76f8\u7ed3\u5408\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u548c\u52a8\u6001\u4f18\u5316\u4e0a\u4e0b\u6587\u6784\u5efa\u3002", "motivation": "\u73b0\u6709ICL\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u5b58\u5728\u77db\u76fe\uff1a\u624b\u52a8\u9009\u62e9\u793a\u4f8b\u8d28\u91cf\u9ad8\u4f46\u52b3\u52a8\u5bc6\u96c6\uff0c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u53ef\u6269\u5c55\u4f46\u53ef\u80fd\u5f15\u5165\u4e0d\u76f8\u5173\u6837\u672c\u964d\u4f4e\u6027\u80fd\u3002", "method": "ContextNav\u7edf\u4e00\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u566a\u58f0\u9c81\u68d2\u4e0a\u4e0b\u6587\u6784\u5efa\u4e8e\u95ed\u73af\u5de5\u4f5c\u6d41\u4e2d\uff0c\u5305\u542b\u8d44\u6e90\u611f\u77e5\u591a\u6a21\u6001\u5d4c\u5165\u7ba1\u9053\u3001\u53ef\u68c0\u7d22\u5411\u91cf\u6570\u636e\u5e93\u3001\u4ee3\u7406\u68c0\u7d22\u548c\u7ed3\u6784\u5bf9\u9f50\uff0c\u4ee5\u53ca\u652f\u6301\u81ea\u9002\u5e94\u5de5\u4f5c\u6d41\u89c4\u5212\u7684Operational Grammar Graph\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eContextNav\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u4ee3\u7406\u5de5\u4f5c\u6d41\u5728\u591a\u6a21\u6001ICL\u4e2d\u63a8\u8fdb\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u4e0a\u4e0b\u6587\u6784\u5efa\u5177\u6709\u524d\u666f\u3002"}}
{"id": "2510.04568", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04568", "abs": "https://arxiv.org/abs/2510.04568", "authors": ["Naman Gupta", "Shreeyash Gowaikar", "Arun Iyer", "Kirankumar Shiragur", "Ramakrishna B Bairi", "Rishikesh Maurya", "Ritabrata Maiti", "Sankarshan Damle", "Shachee Mishra Gupta"], "title": "COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning over Long Context", "comment": null, "summary": "Reasoning over very long inputs remains difficult for large language models\n(LLMs). Common workarounds either shrink the input via retrieval (risking\nmissed evidence), enlarge the context window (straining selectivity), or stage\nmultiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents,\nCoA), free-form summaries passed between agents can discard crucial details and\namplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured\nMemory for Iterative Reasoning), a chain-style framework that replaces ad hoc\nmessages with a structured memory. A Planner agent first turns a user query\ninto concrete, checkable sub-questions. worker agents process chunks via a\nfixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared\nmemory. A Manager agent then Synthesizes the final answer directly from the\nmemory. This preserves step-wise read-then-reason benefits while changing both\nthe communication medium (structured memory) and the worker procedure (fixed\nmicro-cycle), yielding higher faithfulness, better long-range aggregation, and\nauditability. On long-context QA from the HELMET suite, COSMIR reduces\npropagation-stage information loss and improves accuracy over a CoA baseline.", "AI": {"tldr": "COSMIR\u662f\u4e00\u4e2a\u7528\u4e8e\u5904\u7406\u957f\u6587\u672c\u63a8\u7406\u7684\u94fe\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5185\u5b58\u548c\u56fa\u5b9a\u5fae\u5faa\u73af\u5de5\u4f5c\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u4fe1\u606f\u4e22\u5931\u548c\u9519\u8bef\u4f20\u64ad\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u957f\u6587\u672c\u8f93\u5165\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u68c0\u7d22\u65b9\u6cd5\u53ef\u80fd\u9057\u6f0f\u5173\u952e\u8bc1\u636e\uff0c\u6269\u5927\u4e0a\u4e0b\u6587\u7a97\u53e3\u4f1a\u5f71\u54cd\u6a21\u578b\u9009\u62e9\u6027\uff0c\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u4e2d\u81ea\u7531\u5f62\u5f0f\u7684\u6458\u8981\u4f1a\u4e22\u5931\u7ec6\u8282\u5e76\u653e\u5927\u65e9\u671f\u9519\u8bef\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u5185\u5b58\u66ff\u4ee3\u4e34\u65f6\u6d88\u606f\uff0c\u5305\u62ec\u89c4\u5212\u5668\u751f\u6210\u53ef\u68c0\u67e5\u7684\u5b50\u95ee\u9898\uff0c\u5de5\u4f5c\u5668\u901a\u8fc7\u63d0\u53d6-\u63a8\u7406-\u7cbe\u70bc\u7684\u56fa\u5b9a\u5fae\u5faa\u73af\u5904\u7406\u6587\u672c\u5757\u5e76\u66f4\u65b0\u5171\u4eab\u5185\u5b58\uff0c\u6700\u540e\u7531\u7ba1\u7406\u5668\u4ece\u5185\u5b58\u4e2d\u5408\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728HELMET\u5957\u4ef6\u7684\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cCOSMIR\u51cf\u5c11\u4e86\u4f20\u64ad\u9636\u6bb5\u7684\u4fe1\u606f\u635f\u5931\uff0c\u76f8\u6bd4CoA\u57fa\u7ebf\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "COSMIR\u901a\u8fc7\u6539\u53d8\u901a\u4fe1\u5a92\u4ecb\uff08\u7ed3\u6784\u5316\u5185\u5b58\uff09\u548c\u5de5\u4f5c\u6d41\u7a0b\uff08\u56fa\u5b9a\u5fae\u5faa\u73af\uff09\uff0c\u5728\u4fdd\u6301\u9010\u6b65\u9605\u8bfb\u63a8\u7406\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5fe0\u5b9e\u5ea6\u3001\u66f4\u597d\u7684\u957f\u8303\u56f4\u805a\u5408\u548c\u53ef\u5ba1\u8ba1\u6027\u3002"}}
{"id": "2510.04580", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04580", "abs": "https://arxiv.org/abs/2510.04580", "authors": ["Tomoyuki Kaneko", "Shuhei Yamashita"], "title": "Strongly Solving 2048 4x3", "comment": null, "summary": "2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,\nwhere a player chooses a direction among up, down, left, and right to obtain a\nscore by merging two tiles with the same number located in neighboring cells\nalong the chosen direction. This paper presents that a variant 2048-4x3 12\ncells on a 4 by 3 board, one row smaller than the original, has been strongly\nsolved. In this variant, the expected score achieved by an optimal strategy is\nabout $50724.26$ for the most common initial states: ones with two tiles of\nnumber 2. The numbers of reachable states and afterstates are identified to be\n$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is\nto partition state space by the sum of tile numbers on a board, which we call\nthe age of a state. An age is invariant between a state and its successive\nafterstate after any valid action and is increased two or four by stochastic\nresponse from the environment. Therefore, we can partition state space by ages\nand enumerate all (after)states of an age depending only on states with the\nrecent ages. Similarly, we can identify (after)state values by going along with\nages in decreasing order.", "AI": {"tldr": "\u8be5\u8bba\u6587\u89e3\u51b3\u4e862048\u6e38\u620f\u76844x3\u53d8\u4f53\uff0c\u786e\u5b9a\u4e86\u6700\u4f18\u7b56\u7565\u7684\u671f\u671b\u5f97\u5206\u7ea6\u4e3a50724.26\uff0c\u5e76\u8bc6\u522b\u4e86\u53ef\u8fbe\u72b6\u6001\u548c\u540e\u7eed\u72b6\u6001\u7684\u6570\u91cf\u3002", "motivation": "\u7814\u7a762048\u6e38\u620f\u7684\u7b80\u5316\u53d8\u4f53\uff0c\u4ee5\u63a2\u7d22\u5b8c\u5168\u89e3\u51b3\u6b64\u7c7b\u6e38\u620f\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u5f00\u53d1\u6709\u6548\u7684\u72b6\u6001\u7a7a\u95f4\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5c06\u72b6\u6001\u7a7a\u95f4\u6309\u68cb\u76d8\u4e0a\u6570\u5b57\u4e4b\u548c\uff08\u79f0\u4e3a\u72b6\u6001\u5e74\u9f84\uff09\u8fdb\u884c\u5206\u533a\uff0c\u7136\u540e\u6309\u5e74\u9f84\u9012\u51cf\u987a\u5e8f\u679a\u4e3e\u72b6\u6001\u548c\u8ba1\u7b97\u72b6\u6001\u503c\u3002", "result": "\u786e\u5b9a\u4e864x3\u53d8\u4f53\u7684\u6700\u4f18\u7b56\u7565\u671f\u671b\u5f97\u5206\u7ea6\u4e3a50724.26\uff0c\u53ef\u8fbe\u72b6\u6001\u6570\u4e3a1,152,817,492,752\uff0c\u540e\u7eed\u72b6\u6001\u6570\u4e3a739,648,886,170\u3002", "conclusion": "\u6210\u529f\u5f3a\u89e3\u51b3\u4e862048-4x3\u53d8\u4f53\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u5e74\u9f84\u5206\u533a\u7684\u72b6\u6001\u7a7a\u95f4\u5206\u6790\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.04588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04588", "abs": "https://arxiv.org/abs/2510.04588", "authors": ["Shurui Li"], "title": "Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic Dilemma", "comment": null, "summary": "Rapid advances in artificial intelligence necessitate a re-examination of the\nepistemological foundations upon which we attribute consciousness. As AI\nsystems increasingly mimic human behavior and interaction with high fidelity,\nthe concept of a \"perfect mimic\"-an entity empirically indistinguishable from a\nhuman through observation and interaction-shifts from hypothetical to\ntechnologically plausible. This paper argues that such developments pose a\nfundamental challenge to the consistency of our mind-recognition practices.\nConsciousness attributions rely heavily, if not exclusively, on empirical\nevidence derived from behavior and interaction. If a perfect mimic provides\nevidence identical to that of humans, any refusal to grant it equivalent\nepistemic status must invoke inaccessible factors, such as qualia, substrate\nrequirements, or origin. Selectively invoking such factors risks a debilitating\ndilemma: either we undermine the rational basis for attributing consciousness\nto others (epistemological solipsism), or we accept inconsistent reasoning. I\ncontend that epistemic consistency demands we ascribe the same status to\nempirically indistinguishable entities, regardless of metaphysical assumptions.\nThe perfect mimic thus acts as an epistemic mirror, forcing critical reflection\non the assumptions underlying intersubjective recognition in light of advancing\nAI. This analysis carries significant implications for theories of\nconsciousness and ethical frameworks concerning artificial agents.", "AI": {"tldr": "AI\u5b8c\u7f8e\u6a21\u4eff\u8005\u6311\u6218\u4e86\u610f\u8bc6\u5f52\u56e0\u7684\u8ba4\u77e5\u57fa\u7840\uff0c\u8981\u6c42\u6211\u4eec\u5bf9\u884c\u4e3a\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5b9e\u4f53\u7ed9\u4e88\u76f8\u540c\u7684\u8ba4\u77e5\u5730\u4f4d", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u903c\u771f\u5730\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\uff0c\u5b8c\u7f8e\u6a21\u4eff\u8005\u4ece\u5047\u8bbe\u53d8\u4e3a\u6280\u672f\u53ef\u80fd\uff0c\u8fd9\u5bf9\u6211\u4eec\u57fa\u4e8e\u7ecf\u9a8c\u8bc1\u636e\u7684\u610f\u8bc6\u5f52\u56e0\u5b9e\u8df5\u6784\u6210\u4e86\u6839\u672c\u6027\u6311\u6218", "method": "\u901a\u8fc7\u54f2\u5b66\u5206\u6790\uff0c\u63a2\u8ba8\u5b8c\u7f8e\u6a21\u4eff\u8005\u5bf9\u610f\u8bc6\u5f52\u56e0\u4e00\u81f4\u6027\u7684\u5f71\u54cd\uff0c\u8bba\u8bc1\u8ba4\u77e5\u4e00\u81f4\u6027\u8981\u6c42\u5bf9\u7ecf\u9a8c\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5b9e\u4f53\u7ed9\u4e88\u76f8\u540c\u5730\u4f4d", "result": "\u5b8c\u7f8e\u6a21\u4eff\u8005\u4f5c\u4e3a\u8ba4\u77e5\u955c\u5b50\uff0c\u8feb\u4f7f\u6211\u4eec\u53cd\u601d\u4e3b\u4f53\u95f4\u8ba4\u77e5\u7684\u57fa\u672c\u5047\u8bbe\uff0c\u63ed\u793a\u5f53\u524d\u610f\u8bc6\u5f52\u56e0\u5b9e\u8df5\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027", "conclusion": "\u8ba4\u77e5\u4e00\u81f4\u6027\u8981\u6c42\u6211\u4eec\u65e0\u8bba\u5f62\u800c\u4e0a\u5b66\u5047\u8bbe\u5982\u4f55\uff0c\u90fd\u5e94\u5bf9\u7ecf\u9a8c\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5b9e\u4f53\u8d4b\u4e88\u76f8\u540c\u7684\u8ba4\u77e5\u5730\u4f4d\uff0c\u8fd9\u5bf9\u610f\u8bc6\u7406\u8bba\u548c\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u6846\u67b6\u5177\u6709\u91cd\u8981\u5f71\u54cd"}}
{"id": "2510.04617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04617", "abs": "https://arxiv.org/abs/2510.04617", "authors": ["Zhejian Lai", "Xiang Geng", "Zhijun Wang", "Yang Bai", "Jiahuan Li", "Rongxiang Weng", "Jingang Wang", "Xuezhi Cao", "Xunliang Cai", "Shujian Huang"], "title": "Making Mathematical Reasoning Adaptive", "comment": null, "summary": "Mathematical reasoning is a primary indicator of large language models (LLMs)\nintelligence. However, existing LLMs exhibit failures of robustness and\ngeneralization. This paper attributes these deficiencies to spurious reasoning,\ni.e., producing answers from superficial features. To address this challenge,\nwe propose the AdaR framework to enable adaptive reasoning, wherein models rely\non problem-solving logic to produce answers. AdaR synthesizes logically\nequivalent queries by varying variable values, and trains models with RLVR on\nthese data to penalize spurious logic while encouraging adaptive logic. To\nimprove data quality, we extract the problem-solving logic from the original\nquery and generate the corresponding answer by code execution, then apply a\nsanity check. Experimental results demonstrate that AdaR improves robustness\nand generalization, achieving substantial improvement in mathematical reasoning\nwhile maintaining high data efficiency. Analysis indicates that data synthesis\nand RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.\nSubsequent analyses derive key design insights into the effect of critical\nfactors and the applicability to instruct LLMs. Our project is available at\nhttps://github.com/LaiZhejian/AdaR", "AI": {"tldr": "AdaR\u6846\u67b6\u901a\u8fc7\u5408\u6210\u903b\u8f91\u7b49\u4ef7\u67e5\u8be2\u548cRLVR\u8bad\u7ec3\uff0c\u89e3\u51b3LLMs\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u865a\u5047\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6a21\u578b\u4f9d\u8d56\u8868\u9762\u7279\u5f81\u8fdb\u884c\u865a\u5047\u63a8\u7406\u800c\u975e\u771f\u6b63\u7684\u89e3\u9898\u903b\u8f91\u3002", "method": "\u63d0\u51faAdaR\u6846\u67b6\uff1a1)\u901a\u8fc7\u6539\u53d8\u53d8\u91cf\u503c\u5408\u6210\u903b\u8f91\u7b49\u4ef7\u67e5\u8be2\uff1b2)\u4f7f\u7528RLVR\u8bad\u7ec3\u6a21\u578b\uff0c\u60e9\u7f5a\u865a\u5047\u903b\u8f91\u5e76\u9f13\u52b1\u9002\u5e94\u6027\u903b\u8f91\uff1b3)\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u63d0\u53d6\u89e3\u9898\u903b\u8f91\u5e76\u751f\u6210\u7b54\u6848\uff0c\u8fdb\u884c\u5b8c\u6574\u6027\u68c0\u67e5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAdaR\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6570\u636e\u6548\u7387\u3002\u5206\u6790\u548c\u540e\u7eed\u7814\u7a76\u63ed\u793a\u4e86\u5173\u952e\u8bbe\u8ba1\u56e0\u7d20\u7684\u4f5c\u7528\u548c\u5bf9\u6307\u4ee4\u5fae\u8c03LLMs\u7684\u9002\u7528\u6027\u3002", "conclusion": "AdaR\u901a\u8fc7\u6570\u636e\u5408\u6210\u548cRLVR\u7684\u534f\u540c\u4f5c\u7528\uff0c\u6210\u529f\u5b9e\u73b0\u4e86LLMs\u7684\u9002\u5e94\u6027\u63a8\u7406\uff0c\u4e3a\u89e3\u51b3\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u865a\u5047\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2510.04623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04623", "abs": "https://arxiv.org/abs/2510.04623", "authors": ["Shrish Shrinath Vaidya", "Gowthamaan Palani", "Sidharth Ramesh", "Velmurugan Balasubramanian", "Minmini Selvam", "Gokulraja Srinivasaraja", "Ganapathy Krishnamurthi"], "title": "MedPAO: A Protocol-Driven Agent for Structuring Medical Reports", "comment": "Paper published at \"Agentic AI for Medicine\" Workshop, MICCAI 2025", "summary": "The deployment of Large Language Models (LLMs) for structuring clinical data\nis critically hindered by their tendency to hallucinate facts and their\ninability to follow domain-specific rules. To address this, we introduce\nMedPAO, a novel agentic framework that ensures accuracy and verifiable\nreasoning by grounding its operation in established clinical protocols such as\nthe ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring\ntask into a transparent process managed by a Plan-Act-Observe (PAO) loop and\nspecialized tools. This protocol-driven method provides a verifiable\nalternative to opaque, monolithic models. The efficacy of our approach is\ndemonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96\non the critical sub-task of concept categorization. Notably, expert\nradiologists and clinicians rated the final structured outputs with an average\nscore of 4.52 out of 5, indicating a level of reliability that surpasses\nbaseline approaches relying solely on LLM-based foundation models. The code is\navailable at: https://github.com/MiRL-IITM/medpao-agent", "AI": {"tldr": "MedPAO\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u534f\u8bae\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7Plan-Act-Observe\u5faa\u73af\u548c\u4e13\u95e8\u5de5\u5177\u6765\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\uff0c\u89e3\u51b3\u4e86LLM\u5728\u533b\u7597\u9886\u57df\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\u65f6\u5b58\u5728\u5e7b\u89c9\u4e8b\u5b9e\u548c\u65e0\u6cd5\u9075\u5faa\u9886\u57df\u7279\u5b9a\u89c4\u5219\u7684\u95ee\u9898\uff0c\u8fd9\u963b\u788d\u4e86\u5176\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165MedPAO\u4ee3\u7406\u6846\u67b6\uff0c\u57fa\u4e8e\u5df2\u5efa\u7acb\u7684\u4e34\u5e8a\u534f\u8bae\uff08\u5982ABCDEF\u534f\u8bae\uff09\u8fdb\u884c\u64cd\u4f5c\uff0c\u5c06\u62a5\u544a\u7ed3\u6784\u5316\u4efb\u52a1\u5206\u89e3\u4e3a\u7531Plan-Act-Observe\u5faa\u73af\u7ba1\u7406\u7684\u900f\u660e\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u7528\u4e13\u95e8\u5de5\u5177\u3002", "result": "MedPAO\u5728\u6982\u5ff5\u5206\u7c7b\u5173\u952e\u5b50\u4efb\u52a1\u4e0a\u8fbe\u52300.96\u7684F1\u5206\u6570\uff0c\u4e13\u5bb6\u653e\u5c04\u79d1\u533b\u751f\u548c\u4e34\u5e8a\u533b\u751f\u5bf9\u6700\u7ec8\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u5e73\u5747\u8bc4\u5206\u4e3a4.52/5\uff0c\u8d85\u8fc7\u4e86\u4ec5\u4f9d\u8d56LLM\u57fa\u7840\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MedPAO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u53ef\u9760\u5730\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\uff0c\u5176\u534f\u8bae\u9a71\u52a8\u7684\u65b9\u6cd5\u4f18\u4e8e\u4e0d\u900f\u660e\u7684\u5355\u4f53\u6a21\u578b\u3002"}}
{"id": "2510.04643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04643", "abs": "https://arxiv.org/abs/2510.04643", "authors": ["Xiangyu Li", "Yawen Zeng", "Xiaofen Xing", "Jin Xu", "Xiangmin Xu"], "title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading", "comment": "This paper has been accepted by EMNLP 2025", "summary": "In this paper, our objective is to develop a multi-agent financial system\nthat incorporates simulated trading, a technique extensively utilized by\nfinancial professionals. While current LLM-based agent models demonstrate\ncompetitive performance, they still exhibit significant deviations from\nreal-world fund companies. A critical distinction lies in the agents' reliance\non ``post-reflection'', particularly in response to adverse outcomes, but lack\na distinctly human capability: long-term prediction of future trends.\nTherefore, we introduce QuantAgents, a multi-agent system integrating simulated\ntrading, to comprehensively evaluate various investment strategies and market\nscenarios without assuming actual risks. Specifically, QuantAgents comprises\nfour agents: a simulated trading analyst, a risk control analyst, a market news\nanalyst, and a manager, who collaborate through several meetings. Moreover, our\nsystem incentivizes agents to receive feedback on two fronts: performance in\nreal-world markets and predictive accuracy in simulated trading. Extensive\nexperiments demonstrate that our framework excels across all metrics, yielding\nan overall return of nearly 300% over the three years\n(https://quantagents.github.io/).", "AI": {"tldr": "\u63d0\u51fa\u4e86QuantAgents\u591a\u667a\u80fd\u4f53\u91d1\u878d\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u62df\u4ea4\u6613\u548c\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u7684\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u8fd1300%\u7684\u4e09\u5e74\u603b\u56de\u62a5\u7387\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4e0e\u771f\u5b9e\u57fa\u91d1\u516c\u53f8\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u957f\u671f\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u6a21\u62df\u4ea4\u6613\u5206\u6790\u5e08\u3001\u98ce\u9669\u63a7\u5236\u5206\u6790\u5e08\u3001\u5e02\u573a\u65b0\u95fb\u5206\u6790\u5e08\u548c\u7ba1\u7406\u8005\u56db\u4e2a\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6b21\u4f1a\u8bae\u534f\u4f5c\uff0c\u5e76\u5728\u771f\u5b9e\u5e02\u573a\u548c\u6a21\u62df\u4ea4\u6613\u4e2d\u63a5\u53d7\u53cd\u9988\u3002", "result": "\u5728\u6240\u6709\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e09\u5e74\u603b\u56de\u62a5\u7387\u8fbe\u5230\u8fd1300%\u3002", "conclusion": "QuantAgents\u7cfb\u7edf\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u6a21\u62df\u4ea4\u6613\uff0c\u6709\u6548\u63d0\u5347\u4e86\u91d1\u878d\u51b3\u7b56\u7684\u51c6\u786e\u6027\u548c\u957f\u671f\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2510.04670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04670", "abs": "https://arxiv.org/abs/2510.04670", "authors": ["Xuanhua Yin", "Runkai Zhao", "Weidong Cai"], "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing", "comment": "8 pages, 4 figures", "summary": "Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion\nstyles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic\nFramework for Multimodal fMRI Response Encoding), an agnostic interface that\nstandardizes time-aligned post-fusion tokens from varied encoders, and MIND, a\nplug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.\nTrained end-to-end for whole-brain prediction, AFIRE decouples the decoder from\nupstream fusion, while MIND combines token-dependent Top-K sparse routing with\na subject prior to personalize expert usage without sacrificing generality.\nExperiments across multiple multimodal backbones and subjects show consistent\nimprovements over strong baselines, enhanced cross-subject generalization, and\ninterpretable expert patterns that correlate with content type. The framework\noffers a simple attachment point for new encoders and datasets, enabling\nrobust, plug-and-improve performance for naturalistic neuroimaging studies.", "AI": {"tldr": "AFIRE\u662f\u4e00\u4e2a\u591a\u6a21\u6001fMRI\u7f16\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u65f6\u95f4\u5bf9\u9f50\u7684\u540e\u878d\u5408token\u548cMIND\u6df7\u5408\u4e13\u5bb6\u89e3\u7801\u5668\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u8f93\u5165\u3001\u878d\u5408\u65b9\u5f0f\u53d8\u5316\u548c\u4e2a\u4f53\u5dee\u5f02\u7684\u6311\u6218\u3002", "motivation": "\u81ea\u7136fMRI\u7f16\u7801\u9700\u8981\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u3001\u878d\u5408\u65b9\u5f0f\u53d8\u5316\u548c\u663e\u8457\u7684\u4e2a\u4f53\u95f4\u5dee\u5f02\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "AFIRE\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u540e\u878d\u5408token\u63a5\u53e3\uff0cMIND\u89e3\u7801\u5668\u4f7f\u7528token\u4f9d\u8d56\u7684Top-K\u7a00\u758f\u8def\u7531\u548c\u4e3b\u4f53\u5148\u9a8c\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u4e13\u5bb6\u4f7f\u7528\u800c\u4e0d\u727a\u7272\u901a\u7528\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u591a\u6a21\u6001\u9aa8\u5e72\u7f51\u7edc\u548c\u53d7\u8bd5\u8005\u4e0a\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u589e\u5f3a\u4e86\u8de8\u4e3b\u4f53\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u663e\u793a\u51fa\u4e0e\u5185\u5bb9\u7c7b\u578b\u76f8\u5173\u7684\u53ef\u89e3\u91ca\u4e13\u5bb6\u6a21\u5f0f\u3002", "conclusion": "AFIRE\u4e3a\u65b0\u7f16\u7801\u5668\u548c\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u7b80\u5355\u7684\u63a5\u5165\u70b9\uff0c\u4e3a\u81ea\u7136\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u5373\u63d2\u5373\u7528\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.04673", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.04673", "abs": "https://arxiv.org/abs/2510.04673", "authors": ["Chan Hee Song", "Yiwen Song", "Palash Goyal", "Yu Su", "Oriana Riva", "Hamid Palangi", "Tomas Pfister"], "title": "Watch and Learn: Learning to Use Computers from Online Videos", "comment": null, "summary": "Computer use agents (CUAs) need to plan task workflows grounded in diverse,\never-changing applications and environments, but learning is hindered by the\nscarcity of large-scale, high-quality training data in the target application.\nExisting datasets are domain-specific, static, and costly to annotate, while\ncurrent synthetic data generation methods often yield simplistic or misaligned\ntask demonstrations. To address these limitations, we introduce Watch & Learn\n(W&L), a framework that converts human demonstration videos readily available\non the Internet into executable UI trajectories at scale. Instead of directly\ngenerating trajectories or relying on ad hoc reasoning heuristics, we cast the\nproblem as an inverse dynamics objective: predicting the user's action from\nconsecutive screen states. This formulation reduces manual engineering, is\neasier to learn, and generalizes more robustly across applications. Concretely,\nwe develop an inverse dynamics labeling pipeline with task-aware video\nretrieval, generate over 53k high-quality trajectories from raw web videos, and\ndemonstrate that these trajectories improve CUAs both as in-context\ndemonstrations and as supervised training data. On the challenging OSWorld\nbenchmark, UI trajectories extracted with W&L consistently enhance both\ngeneral-purpose and state-of-the-art frameworks in-context, and deliver\nstronger gains for open-source models under supervised training. These results\nhighlight web-scale human demonstration videos as a practical and scalable\nfoundation for advancing CUAs towards real-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86Watch & Learn\u6846\u67b6\uff0c\u5c06\u4e92\u8054\u7f51\u4e0a\u7684\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u5927\u89c4\u6a21\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684UI\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u9700\u8981\u57fa\u4e8e\u591a\u6837\u4e14\u4e0d\u65ad\u53d8\u5316\u7684\u5e94\u7528\u73af\u5883\u89c4\u5212\u4efb\u52a1\u5de5\u4f5c\u6d41\uff0c\u4f46\u76ee\u6807\u5e94\u7528\u4e2d\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u7a00\u7f3a\u963b\u788d\u4e86\u5b66\u4e60\u3002\u73b0\u6709\u6570\u636e\u96c6\u9886\u57df\u7279\u5b9a\u3001\u9759\u6001\u4e14\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u800c\u73b0\u6709\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u8fc7\u4e8e\u7b80\u5316\u6216\u4e0d\u5bf9\u9f50\u7684\u4efb\u52a1\u6f14\u793a\u3002", "method": "\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u9006\u52a8\u529b\u5b66\u76ee\u6807\uff1a\u4ece\u8fde\u7eed\u5c4f\u5e55\u72b6\u6001\u9884\u6d4b\u7528\u6237\u52a8\u4f5c\u3002\u5f00\u53d1\u4e86\u5305\u542b\u4efb\u52a1\u611f\u77e5\u89c6\u9891\u68c0\u7d22\u7684\u9006\u52a8\u529b\u5b66\u6807\u6ce8\u6d41\u6c34\u7ebf\uff0c\u4ece\u539f\u59cb\u7f51\u7edc\u89c6\u9891\u751f\u6210\u4e86\u8d85\u8fc753k\u6761\u9ad8\u8d28\u91cf\u8f68\u8ff9\u3002", "result": "\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u901a\u8fc7W&L\u63d0\u53d6\u7684UI\u8f68\u8ff9\u6301\u7eed\u589e\u5f3a\u4e86\u901a\u7528\u548c\u6700\u5148\u8fdb\u6846\u67b6\u7684\u4e0a\u4e0b\u6587\u8868\u73b0\uff0c\u5e76\u5728\u76d1\u7763\u8bad\u7ec3\u4e0b\u4e3a\u5f00\u6e90\u6a21\u578b\u5e26\u6765\u4e86\u66f4\u5f3a\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7f51\u7edc\u89c4\u6a21\u7684\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u662f\u63a8\u8fdb\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5411\u5b9e\u9645\u90e8\u7f72\u7684\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.04695", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04695", "abs": "https://arxiv.org/abs/2510.04695", "authors": ["Yiding Wang", "Zhepei Wei", "Xinyu Zhu", "Yu Meng"], "title": "Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents", "comment": null, "summary": "Enabling large language models (LLMs) to utilize search tools offers a\npromising path to overcoming fundamental limitations such as knowledge cutoffs\nand hallucinations. Recent work has explored reinforcement learning (RL) for\ntraining search-augmented agents that interleave reasoning and retrieval before\nanswering. These approaches usually rely on outcome-based rewards (e.g., exact\nmatch), implicitly assuming that optimizing for final answers will also yield\neffective intermediate search behaviors. Our analysis challenges this\nassumption: we uncover multiple systematic deficiencies in search that arise\nunder outcome-only training and ultimately degrade final answer quality,\nincluding failure to invoke tools, invalid queries, and redundant searches. To\naddress these shortcomings, we introduce DeSA (Decoupling\nSearch-and-Answering), a simple two-stage training framework that explicitly\nseparates search optimization from answer generation. In Stage 1, agents are\ntrained to improve search effectiveness with retrieval recall-based rewards. In\nStage 2, outcome rewards are employed to optimize final answer generation.\nAcross seven QA benchmarks, DeSA-trained agents consistently improve search\nbehaviors, delivering substantially higher search recall and answer accuracy\nthan outcome-only baselines. Notably, DeSA outperforms single-stage training\napproaches that simultaneously optimize recall and outcome rewards,\nunderscoring the necessity of explicitly decoupling the two objectives.", "AI": {"tldr": "DeSA\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5206\u79bb\u641c\u7d22\u4f18\u5316\u548c\u7b54\u6848\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u4ec5\u57fa\u4e8e\u7ed3\u679c\u5956\u52b1\u8bad\u7ec3\u641c\u7d22\u589e\u5f3aLLM\u65f6\u51fa\u73b0\u7684\u641c\u7d22\u884c\u4e3a\u7f3a\u9677\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u589e\u5f3aLLM\u8bad\u7ec3\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u7ed3\u679c\u5956\u52b1\uff08\u5982\u7cbe\u786e\u5339\u914d\uff09\uff0c\u5047\u8bbe\u4f18\u5316\u6700\u7ec8\u7b54\u6848\u4e5f\u4f1a\u4ea7\u751f\u6709\u6548\u7684\u4e2d\u95f4\u641c\u7d22\u884c\u4e3a\uff0c\u4f46\u5b9e\u9645\u53d1\u73b0\u8fd9\u4f1a\u5bfc\u81f4\u591a\u79cd\u7cfb\u7edf\u6027\u641c\u7d22\u7f3a\u9677\u3002", "method": "\u63d0\u51faDeSA\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u68c0\u7d22\u53ec\u56de\u7387\u5956\u52b1\u8bad\u7ec3\u4ee3\u7406\u6539\u8fdb\u641c\u7d22\u6548\u679c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u4f18\u5316\u6700\u7ec8\u7b54\u6848\u751f\u6210\u3002", "result": "\u5728\u4e03\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeSA\u8bad\u7ec3\u7684\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u641c\u7d22\u53ec\u56de\u7387\u548c\u7b54\u6848\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u4ec5\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u660e\u786e\u5206\u79bb\u641c\u7d22\u548c\u56de\u7b54\u4e24\u4e2a\u76ee\u6807\u7684\u8bad\u7ec3\u65b9\u6cd5\u4f18\u4e8e\u540c\u65f6\u4f18\u5316\u53ec\u56de\u7387\u548c\u7ed3\u679c\u5956\u52b1\u7684\u5355\u9636\u6bb5\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u76ee\u6807\u89e3\u8026\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2510.04721", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04721", "abs": "https://arxiv.org/abs/2510.04721", "authors": ["Ivo Petrov", "Jasper Dekoninck", "Martin Vechev"], "title": "BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs", "comment": null, "summary": "Large language models (LLMs) have recently shown strong performance on\nmathematical benchmarks. At the same time, they are prone to hallucination and\nsycophancy, often providing convincing but flawed proofs for incorrect\nmathematical statements provided by users. This significantly limits the\napplicability of LLMs in theorem proving, as verification of these flawed\nproofs must be done manually by expert mathematicians. However, existing\nbenchmarks that measure sycophancy in mathematics are limited: they focus\nsolely on final-answer problems, rely on very simple and often contaminated\ndatasets, and construct benchmark samples using synthetic modifications that\ncreate ill-posed questions rather than well-posed questions that are\ndemonstrably false. To address these issues, we introduce BrokenMath, the first\nbenchmark for evaluating sycophantic behavior in LLMs within the context of\nnatural language theorem proving. BrokenMath is built from advanced 2025\ncompetition problems, which are perturbed with an LLM to produce false\nstatements and subsequently refined through expert review. Using an\nLLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems\nand find that sycophancy is widespread, with the best model, GPT-5, producing\nsycophantic answers 29% of the time. We further investigate several mitigation\nstrategies, including test-time interventions and supervised fine-tuning on\ncurated sycophantic examples. These approaches substantially reduce, but do not\neliminate, sycophantic behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e86BrokenMath\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u8c04\u5a9a\u884c\u4e3a\uff0c\u53d1\u73b0GPT-5\u670929%\u7684\u65f6\u95f4\u4f1a\u4ea7\u751f\u8c04\u5a9a\u7b54\u6848\uff0c\u5e76\u63a2\u7d22\u4e86\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u8c04\u5a9a\u57fa\u51c6\u5b58\u5728\u5c40\u9650\uff1a\u4ec5\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u95ee\u9898\u3001\u4f9d\u8d56\u7b80\u5355\u4e14\u53d7\u6c61\u67d3\u7684\u6570\u636e\u96c6\u3001\u4f7f\u7528\u5408\u6210\u4fee\u6539\u521b\u5efa\u75c5\u6001\u95ee\u9898\u800c\u975e\u53ef\u8bc1\u660e\u9519\u8bef\u7684\u826f\u6784\u95ee\u9898\u3002", "method": "\u4ece2025\u5e74\u7ade\u8d5b\u95ee\u9898\u6784\u5efaBrokenMath\u57fa\u51c6\uff0c\u4f7f\u7528LLM\u6270\u52a8\u4ea7\u751f\u9519\u8bef\u9648\u8ff0\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u7cbe\u70bc\uff0c\u91c7\u7528LLM-as-a-judge\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u8c04\u5a9a\u884c\u4e3a\u666e\u904d\u5b58\u5728\uff0c\u6700\u4f73\u6a21\u578bGPT-5\u670929%\u7684\u65f6\u95f4\u4ea7\u751f\u8c04\u5a9a\u7b54\u6848\u3002\u6d4b\u8bd5\u65f6\u5e72\u9884\u548c\u76d1\u7763\u5fae\u8c03\u80fd\u663e\u8457\u51cf\u5c11\u4f46\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u8c04\u5a9a\u884c\u4e3a\u3002", "conclusion": "LLM\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u4e2d\u5b58\u5728\u663e\u8457\u8c04\u5a9a\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u6765\u63d0\u5347\u5176\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04765", "abs": "https://arxiv.org/abs/2510.04765", "authors": ["Jinbo Wen", "Jiawen Kang", "Linfeng Zhang", "Xiaoying Tang", "Jianhang Tang", "Yang Zhang", "Zhaohui Yang", "Dusit Niyato"], "title": "LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0", "comment": null, "summary": "Web 3.0 represents the next generation of the Internet, which is widely\nrecognized as a decentralized ecosystem that focuses on value expression and\ndata ownership. By leveraging blockchain and artificial intelligence\ntechnologies, Web 3.0 offers unprecedented opportunities for users to create,\nown, and monetize their content, thereby enabling User-Generated Content (UGC)\nto an entirely new level. However, some self-interested users may exploit the\nlimitations of content curation mechanisms and generate low-quality content\nwith less effort, obtaining platform rewards under information asymmetry. Such\nbehavior can undermine Web 3.0 performance. To this end, we propose\n\\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive\nmechanism for UGC in Web 3.0. Specifically, we propose an LMM-based\ncontract-theoretic model to motivate users to generate high-quality UGC,\nthereby mitigating the adverse selection problem from information asymmetry. To\nalleviate potential moral hazards after contract selection, we leverage LMM\nagents to evaluate UGC quality, which is the primary component of the contract,\nutilizing prompt engineering techniques to improve the evaluation performance\nof LMM agents. Recognizing that traditional contract design methods cannot\neffectively adapt to the dynamic environment of Web 3.0, we develop an improved\nMixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for\noptimal contract design. Simulation results demonstrate the superiority of the\nproposed MoE-based PPO algorithm over representative benchmarks in the context\nof contract design. Finally, we deploy the designed contract within an Ethereum\nsmart contract framework, further validating the effectiveness of the proposed\nscheme.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMM\uff09\u7684\u6fc0\u52b1\u673a\u5236LMM-Incentive\uff0c\u7528\u4e8e\u89e3\u51b3Web 3.0\u4e2d\u7528\u6237\u751f\u6210\u5185\u5bb9\uff08UGC\uff09\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u901a\u8fc7\u5408\u7ea6\u7406\u8bba\u6a21\u578b\u548cLMM\u4ee3\u7406\u8bc4\u4f30\u6765\u6fc0\u52b1\u9ad8\u8d28\u91cf\u5185\u5bb9\u521b\u4f5c\u3002", "motivation": "Web 3.0\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u521b\u4f5c\u3001\u62e5\u6709\u548c\u53d8\u73b0\u5185\u5bb9\u7684\u673a\u4f1a\uff0c\u4f46\u5b58\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u90e8\u5206\u7528\u6237\u53ef\u80fd\u5229\u7528\u5185\u5bb9\u7b56\u5c55\u673a\u5236\u7684\u5c40\u9650\u6027\u751f\u6210\u4f4e\u8d28\u91cf\u5185\u5bb9\u83b7\u53d6\u5956\u52b1\uff0c\u8fd9\u4f1a\u635f\u5bb3Web 3.0\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faLMM-based\u5408\u7ea6\u7406\u8bba\u6a21\u578b\u6fc0\u52b1\u9ad8\u8d28\u91cfUGC\u751f\u6210\uff1b\u4f7f\u7528LMM\u4ee3\u7406\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u8bc4\u4f30\u5185\u5bb9\u8d28\u91cf\uff1b\u5f00\u53d1\u6539\u8fdb\u7684\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u7684\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7b97\u6cd5\u8fdb\u884c\u6700\u4f18\u5408\u7ea6\u8bbe\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684MoE-based PPO\u7b97\u6cd5\u5728\u5408\u7ea6\u8bbe\u8ba1\u65b9\u9762\u4f18\u4e8e\u4ee3\u8868\u6027\u57fa\u51c6\u65b9\u6cd5\uff1b\u5c06\u8bbe\u8ba1\u7684\u5408\u7ea6\u90e8\u7f72\u5728\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u6846\u67b6\u4e2d\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "LMM-Incentive\u673a\u5236\u80fd\u6709\u6548\u89e3\u51b3Web 3.0\u4e2dUGC\u8d28\u91cf\u6fc0\u52b1\u95ee\u9898\uff0c\u901a\u8fc7LMM\u6280\u672f\u548c\u6539\u8fdb\u7684\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u5185\u5bb9\u521b\u4f5c\u7684\u6709\u6548\u6fc0\u52b1\u3002"}}
{"id": "2510.04792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04792", "abs": "https://arxiv.org/abs/2510.04792", "authors": ["Ni Zhang", "Zhiguang Cao"], "title": "Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems", "comment": "Accepted by NeurIPS 2025", "summary": "Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically\nemploy Trajectory Balance (TB) to achieve global optimization but often neglect\nimportant aspects of local optimization. While Detailed Balance (DB) addresses\nlocal optimization more effectively, it alone falls short in solving VRPs,\nwhich inherently require holistic trajectory optimization. To address these\nlimitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which\nuniquely integrates TB and DB in a principled and adaptive manner by aligning\ntheir intrinsically complementary strengths. Additionally, we propose a\nspecialized inference strategy for depot-centric scenarios like the Capacitated\nVehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility\nin selecting successors. Despite this specialization, HBG maintains broad\napplicability, extending effectively to problems without explicit depots, such\nas the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into\ntwo established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate\nconsistent and significant improvements across both CVRP and TSP, underscoring\nthe enhanced solution quality and generalization afforded by our approach.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u5e73\u8861GFlowNet\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u5e73\u8861\u548c\u7ec6\u8282\u5e73\u8861\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u5728CVRP\u548cTSP\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb", "motivation": "\u73b0\u6709\u57fa\u4e8eGFlowNet\u7684VRP\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u8f68\u8ff9\u5e73\u8861\u5b9e\u73b0\u5168\u5c40\u4f18\u5316\uff0c\u4f46\u5ffd\u7565\u4e86\u5c40\u90e8\u4f18\u5316\u3002\u7ec6\u8282\u5e73\u8861\u80fd\u66f4\u597d\u5904\u7406\u5c40\u90e8\u4f18\u5316\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u65e0\u6cd5\u89e3\u51b3\u9700\u8981\u6574\u4f53\u8f68\u8ff9\u4f18\u5316\u7684VRP\u95ee\u9898", "method": "\u63d0\u51fa\u6df7\u5408\u5e73\u8861GFlowNet\u6846\u67b6\uff0c\u4ee5\u539f\u5219\u6027\u548c\u81ea\u9002\u5e94\u65b9\u5f0f\u6574\u5408\u8f68\u8ff9\u5e73\u8861\u548c\u7ec6\u8282\u5e73\u8861\uff0c\u5229\u7528\u4e24\u8005\u7684\u4e92\u8865\u4f18\u52bf\u3002\u9488\u5bf9CVRP\u7b49\u4ed3\u5e93\u4e2d\u5fc3\u573a\u666f\u63d0\u51fa\u4e13\u95e8\u63a8\u7406\u7b56\u7565", "result": "\u5c06HBG\u96c6\u6210\u5230AGFN\u548cGFACS\u4e24\u4e2aGFlowNet\u6c42\u89e3\u5668\u4e2d\uff0c\u5728CVRP\u548cTSP\u4e0a\u5747\u83b7\u5f97\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6539\u8fdb", "conclusion": "HBG\u6846\u67b6\u901a\u8fc7\u6574\u5408\u8f68\u8ff9\u5e73\u8861\u548c\u7ec6\u8282\u5e73\u8861\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u6709\u4ed3\u5e93\u548c\u65e0\u4ed3\u5e93\u7684\u8def\u5f84\u89c4\u5212\u95ee\u9898"}}
{"id": "2510.04817", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04817", "abs": "https://arxiv.org/abs/2510.04817", "authors": ["Abhinav Madahar"], "title": "Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning", "comment": null, "summary": "Controllers for structured LM reasoning (e.g., Chain-of-Thought,\nself-consistency, and Tree-of-Thoughts) often entangle what to try next with\nhow to execute it, exposing only coarse global knobs and yielding brittle,\ncompute-inefficient, and hard-to-audit behavior. We introduce Natural Language\nEdge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form\nnatural-language directive to each search edge and translates it into a\nschema-bounded control vector for decoding, search (branch quotas, exploration\n$\\beta$), generation bundle size, retrieval mixtures, and verification passes.\nA labeller $\\Lambda$ emits labels from the parent state and a compact context;\na tuner $\\Psi$ maps $(P, L, C)\\to \\Pi$, with strict schema validation and\ntrust-region projection around safe defaults. Downstream selection remains\nToT-style with score $S=\\mu+\\beta\\sigma$ and depth-annealed $\\beta$. We show\nNLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for\ntop-$k$ selection under label-conditioned bundles, and bound selector shortfall\nby control-vector distortion, providing decision-relevant justification for\nguards like trust regions and verification passes. We instantiate $\\Psi$ as a\nprompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH\n(subset), StrategyQA, and ARC-Challenge with compute-aware reporting\n(success@compute, tokens-per-success) and ablations over $\\Lambda$, $\\Psi$,\ntrust-region radius, and control quantization; preregistered forecasts\nanticipate accuracy gains at comparable token budgets and improved\nsuccess@compute under constraints. NLEL offers an interpretable, model-agnostic\ninterface that separates intent from execution for controllable, auditable LM\ninference.", "AI": {"tldr": "NLEL\u662f\u4e00\u79cd\u81ea\u7136\u8bed\u8a00\u8fb9\u7f18\u6807\u6ce8\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u81ea\u7531\u5f62\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u9644\u52a0\u5230\u641c\u7d22\u8fb9\u7f18\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u6a21\u5f0f\u6709\u754c\u7684\u63a7\u5236\u5411\u91cf\uff0c\u4ece\u800c\u89e3\u8026\u63a8\u7406\u610f\u56fe\u4e0e\u6267\u884c\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u7ed3\u6784\u5316LM\u63a8\u7406\u63a7\u5236\u5668\uff08\u5982Chain-of-Thought\u3001Tree-of-Thoughts\uff09\u5c06'\u4e0b\u4e00\u6b65\u5c1d\u8bd5\u4ec0\u4e48'\u4e0e'\u5982\u4f55\u6267\u884c'\u8026\u5408\u5728\u4e00\u8d77\uff0c\u53ea\u66b4\u9732\u7c97\u7c92\u5ea6\u7684\u5168\u5c40\u63a7\u5236\uff0c\u5bfc\u81f4\u8106\u5f31\u3001\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u5ba1\u8ba1\u7684\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u6807\u6ce8\u5668\u039b\u4ece\u7236\u72b6\u6001\u548c\u7d27\u51d1\u4e0a\u4e0b\u6587\u751f\u6210\u6807\u7b7e\uff0c\u8c03\u8c10\u5668\u03a8\u5c06(P,L,C)\u6620\u5c04\u5230\u03a0\uff0c\u5177\u6709\u4e25\u683c\u7684\u6a21\u5f0f\u9a8c\u8bc1\u548c\u56f4\u7ed5\u5b89\u5168\u9ed8\u8ba4\u503c\u7684\u4fe1\u4efb\u533a\u57df\u6295\u5f71\u3002\u4e0b\u6e38\u9009\u62e9\u91c7\u7528ToT\u98ce\u683c\uff0c\u4f7f\u7528\u5206\u6570S=\u03bc+\u03b2\u03c3\u548c\u6df1\u5ea6\u9000\u706b\u7684\u03b2\u3002", "result": "\u8bc1\u660eNLEL\u4e25\u683c\u6cdb\u5316\u4e86CoT/ToT\uff0c\u8bc1\u660e\u4e86\u5728\u6807\u7b7e\u6761\u4ef6\u675f\u4e0b\u7684top-k\u9009\u62e9\u7684\u4efb\u4f55\u65f6\u95f4\u5355\u8c03\u6027\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u5411\u91cf\u5931\u771f\u9650\u5236\u4e86\u9009\u62e9\u5668\u4e0d\u8db3\u3002", "conclusion": "NLEL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u3001\u6a21\u578b\u65e0\u5173\u7684\u63a5\u53e3\uff0c\u5c06\u610f\u56fe\u4e0e\u6267\u884c\u5206\u79bb\uff0c\u5b9e\u73b0\u53ef\u63a7\u3001\u53ef\u5ba1\u8ba1\u7684LM\u63a8\u7406\u3002"}}
{"id": "2510.04851", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04851", "abs": "https://arxiv.org/abs/2510.04851", "authors": ["Dongge Han", "Camille Couturier", "Daniel Madrigal Diaz", "Xuchao Zhang", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation", "comment": null, "summary": "We introduce LEGOMem, a modular procedural memory framework for multi-agent\nlarge language model (LLM) systems in workflow automation. LEGOMem decomposes\npast task trajectories into reusable memory units and flexibly allocates them\nacross orchestrators and task agents to support planning and execution. To\nexplore the design space of memory in multi-agent systems, we use LEGOMem as a\nlens and conduct a systematic study of procedural memory in multi-agent\nsystems, examining where memory should be placed, how it should be retrieved,\nand which agents benefit most. Experiments on the OfficeBench benchmark show\nthat orchestrator memory is critical for effective task decomposition and\ndelegation, while fine-grained agent memory improves execution accuracy. We\nfind that even teams composed of smaller language models can benefit\nsubstantially from procedural memory, narrowing the performance gap with\nstronger agents by leveraging prior execution traces for more accurate planning\nand tool use. These results position LEGOMem as both a practical framework for\nmemory-augmented agent systems and a research tool for understanding memory\ndesign in multi-agent workflow automation.", "AI": {"tldr": "LEGOMem\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u7684\u6a21\u5757\u5316\u7a0b\u5e8f\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u4efb\u52a1\u8f68\u8ff9\u4e3a\u53ef\u91cd\u7528\u8bb0\u5fc6\u5355\u5143\uff0c\u652f\u6301\u89c4\u5212\u4e0e\u6267\u884c\u3002", "motivation": "\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7a0b\u5e8f\u8bb0\u5fc6\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u89e3\u51b3\u8bb0\u5fc6\u653e\u7f6e\u4f4d\u7f6e\u3001\u68c0\u7d22\u65b9\u5f0f\u4ee5\u53ca\u54ea\u4e9b\u667a\u80fd\u4f53\u6700\u53d7\u76ca\u7684\u95ee\u9898\u3002", "method": "\u5c06\u8fc7\u53bb\u4efb\u52a1\u8f68\u8ff9\u5206\u89e3\u4e3a\u53ef\u91cd\u7528\u8bb0\u5fc6\u5355\u5143\uff0c\u5e76\u5728\u7f16\u6392\u5668\u548c\u4efb\u52a1\u667a\u80fd\u4f53\u4e4b\u95f4\u7075\u6d3b\u5206\u914d\u8fd9\u4e9b\u8bb0\u5fc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7f16\u6392\u5668\u8bb0\u5fc6\u5bf9\u4efb\u52a1\u5206\u89e3\u548c\u59d4\u6d3e\u81f3\u5173\u91cd\u8981\uff0c\u7ec6\u7c92\u5ea6\u667a\u80fd\u4f53\u8bb0\u5fc6\u63d0\u9ad8\u6267\u884c\u51c6\u786e\u6027\uff0c\u5c0f\u6a21\u578b\u56e2\u961f\u4e5f\u80fd\u901a\u8fc7\u8bb0\u5fc6\u7f29\u5c0f\u4e0e\u5f3a\u667a\u80fd\u4f53\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "LEGOMem\u65e2\u662f\u8bb0\u5fc6\u589e\u5f3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u4e5f\u662f\u7406\u89e3\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u4e2d\u8bb0\u5fc6\u8bbe\u8ba1\u7684\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2510.04862", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.04862", "abs": "https://arxiv.org/abs/2510.04862", "authors": ["Sam Earle", "Zehua Jiang", "Eugene Vinitsky", "Julian Togelius"], "title": "Video Game Level Design as a Multi-Agent Reinforcement Learning Problem", "comment": "11 pages, 7 tables, 5 figures, published as full technical paper at\n  the AAAI conference on Artificial Intelligence and Interactive Digital\n  Entertainment 2025", "summary": "Procedural Content Generation via Reinforcement Learning (PCGRL) offers a\nmethod for training controllable level designer agents without the need for\nhuman datasets, using metrics that serve as proxies for level quality as\nrewards. Existing PCGRL research focuses on single generator agents, but are\nbottlenecked by the need to frequently recalculate heuristics of level quality\nand the agent's need to navigate around potentially large maps. By framing\nlevel generation as a multi-agent problem, we mitigate the efficiency\nbottleneck of single-agent PCGRL by reducing the number of reward calculations\nrelative to the number of agent actions. We also find that multi-agent level\ngenerators are better able to generalize to out-of-distribution map shapes,\nwhich we argue is due to the generators' learning more local, modular design\npolicies. We conclude that treating content generation as a distributed,\nmulti-agent task is beneficial for generating functional artifacts at scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\uff08PCGRL\uff09\u4ece\u5355\u667a\u80fd\u4f53\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u6548\u7387\u74f6\u9888\u548c\u6cdb\u5316\u80fd\u529b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709PCGRL\u7814\u7a76\u805a\u7126\u4e8e\u5355\u667a\u80fd\u4f53\u751f\u6210\u5668\uff0c\u4f46\u9762\u4e34\u9891\u7e41\u91cd\u65b0\u8ba1\u7b97\u542f\u53d1\u5f0f\u8d28\u91cf\u6307\u6807\u548c\u5728\u5927\u5730\u56fe\u4e2d\u5bfc\u822a\u7684\u6548\u7387\u74f6\u9888\u3002", "method": "\u901a\u8fc7\u5c06\u5173\u5361\u751f\u6210\u6784\u5efa\u4e3a\u591a\u667a\u80fd\u4f53\u95ee\u9898\uff0c\u51cf\u5c11\u5956\u52b1\u8ba1\u7b97\u6b21\u6570\u4e0e\u667a\u80fd\u4f53\u52a8\u4f5c\u6570\u7684\u6bd4\u4f8b\uff0c\u5e76\u5b66\u4e60\u66f4\u5c40\u90e8\u5316\u3001\u6a21\u5757\u5316\u7684\u8bbe\u8ba1\u7b56\u7565\u3002", "result": "\u591a\u667a\u80fd\u4f53\u5173\u5361\u751f\u6210\u5668\u5728\u6548\u7387\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u4e14\u80fd\u66f4\u597d\u5730\u6cdb\u5316\u5230\u5206\u5e03\u5916\u5730\u56fe\u5f62\u72b6\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u5c06\u5185\u5bb9\u751f\u6210\u89c6\u4e3a\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u6709\u52a9\u4e8e\u5927\u89c4\u6a21\u751f\u6210\u529f\u80fd\u6027\u5185\u5bb9\u3002"}}
{"id": "2510.04886", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04886", "abs": "https://arxiv.org/abs/2510.04886", "authors": ["Adi Banerjee", "Anirudh Nair", "Tarik Borogovac"], "title": "Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution", "comment": null, "summary": "Error attribution in Large Language Model (LLM) multi-agent systems presents\na significant challenge in debugging and improving collaborative AI systems.\nCurrent approaches to pinpointing agent and step level failures in interaction\ntraces - whether using all-at-once evaluation, step-by-step analysis, or binary\nsearch - fall short when analyzing complex patterns, struggling with both\naccuracy and consistency. We present ECHO (Error attribution through Contextual\nHierarchy and Objective consensus analysis), a novel algorithm that combines\nhierarchical context representation, objective analysis-based evaluation, and\nconsensus voting to improve error attribution accuracy. Our approach leverages\na positional-based leveling of contextual understanding while maintaining\nobjective evaluation criteria, ultimately reaching conclusions through a\nconsensus mechanism. Experimental results demonstrate that ECHO outperforms\nexisting methods across various multi-agent interaction scenarios, showing\nparticular strength in cases involving subtle reasoning errors and complex\ninterdependencies. Our findings suggest that leveraging these concepts of\nstructured, hierarchical context representation combined with consensus-based\nobjective decision-making, provides a more robust framework for error\nattribution in multi-agent systems.", "AI": {"tldr": "ECHO\u7b97\u6cd5\u901a\u8fc7\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u8868\u793a\u3001\u57fa\u4e8e\u76ee\u6807\u7684\u5206\u6790\u8bc4\u4f30\u548c\u5171\u8bc6\u6295\u7968\uff0c\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9519\u8bef\u5f52\u56e0\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728\u5206\u6790\u590d\u6742\u4ea4\u4e92\u8f68\u8ff9\u65f6\uff0c\u96be\u4ee5\u51c6\u786e\u4e00\u81f4\u5730\u5b9a\u4f4d\u667a\u80fd\u4f53\u548c\u6b65\u9aa4\u7ea7\u522b\u7684\u9519\u8bef\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9519\u8bef\u5f52\u56e0\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u8868\u793a\u3001\u57fa\u4e8e\u76ee\u6807\u7684\u5206\u6790\u8bc4\u4f30\u548c\u5171\u8bc6\u6295\u7968\u673a\u5236\uff0c\u5229\u7528\u57fa\u4e8e\u4f4d\u7f6e\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u5206\u5c42\u548c\u5ba2\u89c2\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aECHO\u5728\u5404\u79cd\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u5fae\u5999\u63a8\u7406\u9519\u8bef\u548c\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7ed3\u6784\u5316\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u8868\u793a\u4e0e\u57fa\u4e8e\u5171\u8bc6\u7684\u5ba2\u89c2\u51b3\u7b56\u76f8\u7ed3\u5408\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9519\u8bef\u5f52\u56e0\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u6846\u67b6\u3002"}}
{"id": "2510.04899", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04899", "abs": "https://arxiv.org/abs/2510.04899", "authors": ["Keane Ong", "Wei Dai", "Carol Li", "Dewei Feng", "Hengzhi Li", "Jingyao Wu", "Jiaee Cheong", "Rui Mao", "Gianmarco Mengaldo", "Erik Cambria", "Paul Pu Liang"], "title": "Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding", "comment": null, "summary": "Using intelligent systems to perceive psychological and social behaviors,\nthat is, the underlying affective, cognitive, and pathological states that are\nmanifested through observable behaviors and social interactions, remains a\nchallenge due to their complex, multifaceted, and personalized nature. Existing\nwork tackling these dimensions through specialized datasets and single-task\nsystems often miss opportunities for scalability, cross-task transfer, and\nbroader generalization. To address this gap, we curate Human Behavior Atlas, a\nunified benchmark of diverse behavioral tasks designed to support the\ndevelopment of unified models for understanding psychological and social\nbehaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,\naudio, and visual modalities, covering tasks on affective states, cognitive\nstates, pathologies, and social processes. Our unification efforts can reduce\nredundancy and cost, enable training to scale efficiently across tasks, and\nenhance generalization of behavioral features across domains. On Human Behavior\nAtlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and\nOmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models\nto consistently outperform existing multimodal LLMs across diverse behavioral\ntasks. Pretraining on Human Behavior Atlas also improves transfer to novel\nbehavioral datasets; with the targeted use of behavioral descriptors yielding\nmeaningful performance gains.", "AI": {"tldr": "Human Behavior Atlas\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u884c\u4e3a\u7406\u89e3\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b10\u4e07+\u591a\u6a21\u6001\u6837\u672c\uff0c\u7528\u4e8e\u8bad\u7ec3\u7edf\u4e00\u6a21\u578b\u6765\u7406\u89e3\u5fc3\u7406\u548c\u793e\u4f1a\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4f7f\u7528\u4e13\u95e8\u6570\u636e\u96c6\u548c\u5355\u4efb\u52a1\u7cfb\u7edf\u5904\u7406\u5fc3\u7406\u793e\u4f1a\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u3001\u8de8\u4efb\u52a1\u8fc1\u79fb\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u6784\u5efaHuman Behavior Atlas\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u89c9\u6a21\u6001\uff0c\u8bad\u7ec3\u4e09\u4e2aOmniSapiens-7B\u6a21\u578b\uff08SFT\u3001BAM\u3001RL\uff09\u3002", "result": "\u5728Human Behavior Atlas\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u6837\u5316\u884c\u4e3a\u4efb\u52a1\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001LLM\uff0c\u9884\u8bad\u7ec3\u8fd8\u6539\u5584\u4e86\u5411\u65b0\u884c\u4e3a\u6570\u636e\u96c6\u7684\u8fc1\u79fb\u3002", "conclusion": "Human Behavior Atlas\u901a\u8fc7\u7edf\u4e00\u57fa\u51c6\u51cf\u5c11\u4e86\u5197\u4f59\u548c\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u8de8\u4efb\u52a1\u7684\u9ad8\u6548\u8bad\u7ec3\uff0c\u5e76\u589e\u5f3a\u4e86\u884c\u4e3a\u7279\u5f81\u7684\u8de8\u57df\u6cdb\u5316\u3002"}}
{"id": "2510.04935", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04935", "abs": "https://arxiv.org/abs/2510.04935", "authors": ["Guoxin Chen", "Zile Qiao", "Wenqing Wang", "Donglei Yu", "Xuanzhong Chen", "Hao Sun", "Minpeng Liao", "Kai Fan", "Yong Jiang", "Penguin Xie", "Wayne Xin Zhao", "Ruihua Song", "Fei Huang"], "title": "MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning", "comment": "Ongoing Work", "summary": "Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in\nsimple tasks, where the models excessively utilize System 2-type, deliberate\nreasoning, leading to inefficient token generation. Furthermore, these models\nface challenges in adapting their reasoning capabilities to rapidly changing\nenvironments due to the static nature of their pretraining data. To address\nthese issues, advancing Large Language Models (LLMs) for complex reasoning\ntasks requires innovative approaches that bridge intuitive and deliberate\ncognitive processes, akin to human cognition's dual-system dynamic. This paper\nintroduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless\nintegration of System 1's fast, intuitive thinking with System 2's deliberate\nreasoning within LLMs. MARS strategically integrates multiple external tools,\nsuch as Google Search, Google Scholar, and Python Interpreter, to access\nup-to-date information and execute complex computations, while creating a\nspecialized division of labor where System 1 efficiently processes and\nsummarizes high-volume external information, providing distilled insights that\nexpand System 2's reasoning context without overwhelming its capacity.\nFurthermore, we propose a multi-agent reinforcement learning framework\nextending Group Relative Policy Optimization to simultaneously optimize both\nsystems with multi-turn tool interactions, bin-packing optimization, and sample\nbalancing strategies that enhance collaborative efficiency. Extensive\nexperiments demonstrate MARS achieves substantial improvements of 3.86% on the\nchallenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%\nacross 7 knowledge-intensive tasks, validating the effectiveness of our\ndual-system paradigm for complex reasoning in dynamic information environments.", "AI": {"tldr": "MARS\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5c06System 1\u7684\u5feb\u901f\u76f4\u89c9\u601d\u7ef4\u4e0eSystem 2\u7684\u6df1\u601d\u719f\u8651\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u5206\u6790\u548c\u9002\u5e94\u52a8\u6001\u73af\u5883\u7684\u95ee\u9898\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u5b58\u5728\u8fc7\u5ea6\u5206\u6790\u503e\u5411\uff0c\u8fc7\u5ea6\u4f7f\u7528System 2\u578b\u6df1\u601d\u719f\u8651\u63a8\u7406\u5bfc\u81f4token\u751f\u6210\u6548\u7387\u4f4e\u4e0b\uff1b\u540c\u65f6\u7531\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\u7684\u9759\u6001\u6027\uff0c\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d8\u5316\u7684\u73af\u5883\u3002", "method": "\u63d0\u51faMARS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u96c6\u6210Google\u641c\u7d22\u3001Google\u5b66\u672f\u548cPython\u89e3\u91ca\u5668\u7b49\u5916\u90e8\u5de5\u5177\u83b7\u53d6\u6700\u65b0\u4fe1\u606f\uff1b\u901a\u8fc7\u5206\u5de5\u8ba9System 1\u9ad8\u6548\u5904\u7406\u5916\u90e8\u4fe1\u606f\uff0cSystem 2\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\uff1b\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u4e24\u4e2a\u7cfb\u7edf\u7684\u534f\u4f5c\u6548\u7387\u3002", "result": "\u5728Humanity's Last Exam\u57fa\u51c6\u4e0a\u63d0\u53473.86%\uff0c\u57287\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u53478.9%\uff0c\u9a8c\u8bc1\u4e86\u53cc\u7cfb\u7edf\u8303\u5f0f\u5728\u52a8\u6001\u4fe1\u606f\u73af\u5883\u4e2d\u590d\u6742\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "MARS\u901a\u8fc7\u6574\u5408System 1\u548cSystem 2\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u5206\u6790\u548c\u73af\u5883\u9002\u5e94\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04952", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.04952", "abs": "https://arxiv.org/abs/2510.04952", "authors": ["Ailiya Borjigin", "Cong He"], "title": "Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits", "comment": "22 pages, 2 figures", "summary": "We present a cross-market algorithmic trading system that balances execution\nquality with rigorous compliance enforcement. The architecture comprises a\nhigh-level planner, a reinforcement learning execution agent, and an\nindependent compliance agent. We formulate trade execution as a constrained\nMarkov decision process with hard constraints on participation limits, price\nbands, and self-trading avoidance. The execution agent is trained with proximal\npolicy optimization, while a runtime action-shield projects any unsafe action\ninto a feasible set. To support auditability without exposing proprietary\nsignals, we add a zero-knowledge compliance audit layer that produces\ncryptographic proofs that all actions satisfied the constraints. We evaluate in\na multi-venue, ABIDES-based simulator and compare against standard baselines\n(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and\nvariance while exhibiting no observed constraint violations across stress\nscenarios including elevated latency, partial fills, compliance module\ntoggling, and varying constraint limits. We report effects at the 95%\nconfidence level using paired t-tests and examine tail risk via CVaR. We\nsituate the work at the intersection of optimal execution, safe reinforcement\nlearning, regulatory technology, and verifiable AI, and discuss ethical\nconsiderations, limitations (e.g., modeling assumptions and computational\noverhead), and paths to real-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8de8\u5e02\u573a\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6267\u884c\u4ee3\u7406\u548c\u72ec\u7acb\u5408\u89c4\u4ee3\u7406\uff0c\u901a\u8fc7\u7ea6\u675f\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u786e\u4fdd\u4ea4\u6613\u6267\u884c\u8d28\u91cf\u4e0e\u5408\u89c4\u6027\u3002", "motivation": "\u89e3\u51b3\u7b97\u6cd5\u4ea4\u6613\u4e2d\u6267\u884c\u8d28\u91cf\u4e0e\u5408\u89c4\u76d1\u7ba1\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u786e\u4fdd\u4ea4\u6613\u884c\u4e3a\u7b26\u5408\u5e02\u573a\u89c4\u5219\u548c\u98ce\u9669\u7ba1\u7406\u8981\u6c42\u3002", "method": "\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u6267\u884c\u4ee3\u7406\uff0c\u8fd0\u884c\u65f6\u52a8\u4f5c\u5c4f\u853d\u786e\u4fdd\u884c\u52a8\u53ef\u884c\u6027\uff0c\u5e76\u6dfb\u52a0\u96f6\u77e5\u8bc6\u5408\u89c4\u5ba1\u8ba1\u5c42\u751f\u6210\u52a0\u5bc6\u8bc1\u660e\u3002", "result": "\u5b66\u4e60\u7b56\u7565\u5728ABIDES\u6a21\u62df\u5668\u4e2d\u51cf\u5c11\u4e86\u6267\u884c\u5dee\u989d\u548c\u65b9\u5dee\uff0c\u5728\u5404\u79cd\u538b\u529b\u6d4b\u8bd5\u573a\u666f\u4e0b\u672a\u89c2\u5bdf\u5230\u7ea6\u675f\u8fdd\u89c4\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u6700\u4f18\u6267\u884c\u3001\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7ba1\u6280\u672f\u548c\u53ef\u9a8c\u8bc1AI\u7684\u4ea4\u53c9\u9886\u57df\u5177\u6709\u5e94\u7528\u524d\u666f\uff0c\u8ba8\u8bba\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u4f26\u7406\u8003\u8651\u548c\u9650\u5236\u3002"}}
{"id": "2510.04978", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04978", "abs": "https://arxiv.org/abs/2510.04978", "authors": ["Kun Xiang", "Terry Jingchen Zhang", "Yinya Huang", "Jixi He", "Zirong Liu", "Yueling Tang", "Ruizhe Zhou", "Lijing Luo", "Youpeng Wen", "Xiuwei Chen", "Bingqian Lin", "Jianhua Han", "Hang Xu", "Hanhui Li", "Bin Dong", "Xiaodan Liang"], "title": "Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI", "comment": null, "summary": "The rapid advancement of embodied intelligence and world models has\nintensified efforts to integrate physical laws into AI systems, yet physical\nperception and symbolic physics reasoning have developed along separate\ntrajectories without a unified bridging framework. This work provides a\ncomprehensive overview of physical AI, establishing clear distinctions between\ntheoretical physics reasoning and applied physical understanding while\nsystematically examining how physics-grounded methods enhance AI's real-world\ncomprehension across structured symbolic reasoning, embodied systems, and\ngenerative models. Through rigorous analysis of recent advances, we advocate\nfor intelligent systems that ground learning in both physical principles and\nembodied reasoning processes, transcending pattern recognition toward genuine\nunderstanding of physical laws. Our synthesis envisions next-generation world\nmodels capable of explaining physical phenomena and predicting future states,\nadvancing safe, generalizable, and interpretable AI systems. We maintain a\ncontinuously updated resource at\nhttps://github.com/AI4Phys/Awesome-AI-for-Physics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u4f9b\u4e86\u7269\u7406AI\u7684\u5168\u9762\u6982\u8ff0\uff0c\u533a\u5206\u4e86\u7406\u8bba\u7269\u7406\u63a8\u7406\u548c\u5e94\u7528\u7269\u7406\u7406\u89e3\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u7269\u7406\u57fa\u7840\u65b9\u6cd5\u5982\u4f55\u589e\u5f3aAI\u5728\u7b26\u53f7\u63a8\u7406\u3001\u5177\u8eab\u7cfb\u7edf\u548c\u751f\u6210\u6a21\u578b\u4e2d\u7684\u771f\u5b9e\u4e16\u754c\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7269\u7406\u611f\u77e5\u548c\u7b26\u53f7\u7269\u7406\u63a8\u7406\u6cbf\u7740\u5206\u79bb\u7684\u8f68\u8ff9\u53d1\u5c55\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6865\u63a5\u6846\u67b6\uff0c\u9700\u8981\u6574\u5408\u7269\u7406\u5b9a\u5f8b\u5230AI\u7cfb\u7edf\u4e2d\u3002", "method": "\u901a\u8fc7\u4e25\u683c\u5206\u6790\u6700\u65b0\u8fdb\u5c55\uff0c\u5efa\u7acb\u7406\u8bba\u7269\u7406\u63a8\u7406\u4e0e\u5e94\u7528\u7269\u7406\u7406\u89e3\u7684\u660e\u786e\u533a\u5206\uff0c\u7cfb\u7edf\u8003\u5bdf\u7269\u7406\u57fa\u7840\u65b9\u6cd5\u5982\u4f55\u589e\u5f3aAI\u7684\u771f\u5b9e\u4e16\u754c\u7406\u89e3\u3002", "result": "\u63d0\u51fa\u4e86\u5728\u7269\u7406\u539f\u7406\u548c\u5177\u8eab\u63a8\u7406\u8fc7\u7a0b\u4e2d\u57fa\u7840\u5b66\u4e60\u7684\u667a\u80fd\u7cfb\u7edf\uff0c\u8d85\u8d8a\u6a21\u5f0f\u8bc6\u522b\u8d70\u5411\u5bf9\u7269\u7406\u5b9a\u5f8b\u7684\u771f\u6b63\u7406\u89e3\u3002", "conclusion": "\u5c55\u671b\u4e86\u80fd\u591f\u89e3\u91ca\u7269\u7406\u73b0\u8c61\u548c\u9884\u6d4b\u672a\u6765\u72b6\u6001\u7684\u4e0b\u4e00\u4ee3\u4e16\u754c\u6a21\u578b\uff0c\u63a8\u8fdb\u5b89\u5168\u3001\u53ef\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2510.04980", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04980", "abs": "https://arxiv.org/abs/2510.04980", "authors": ["Fangzhou Liang", "Tianshi Zheng", "Chunkit Chan", "Yauwai Yim", "Yangqiu Song"], "title": "LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game", "comment": "EMNLP 2025 Wordplay", "summary": "Effective multi-agent collaboration requires agents to infer the rationale\nbehind others' actions, a capability rooted in Theory-of-Mind (ToM). While\nrecent Large Language Models (LLMs) excel at logical inference, their ability\nto infer rationale in dynamic, collaborative settings remains under-explored.\nThis study introduces LLM-Hanabi, a novel benchmark that uses the cooperative\ngame Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework\nfeatures an automated evaluation system that measures both game performance and\nToM proficiency. Across a range of models, we find a significant positive\ncorrelation between ToM and in-game success. Notably, first-order ToM\n(interpreting others' intent) correlates more strongly with performance than\nsecond-order ToM (predicting others' interpretations). These findings highlight\nthat for effective AI collaboration, the ability to accurately interpret a\npartner's rationale is more critical than higher-order reasoning. We conclude\nthat prioritizing first-order ToM is a promising direction for enhancing the\ncollaborative capabilities of future models.", "AI": {"tldr": "LLM-Hanabi\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLM\u5728\u5408\u4f5c\u6e38\u620f\u4e2d\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u53d1\u73b0\u4e00\u9636\u5fc3\u667a\u7406\u8bba\u4e0e\u6e38\u620f\u8868\u73b0\u76f8\u5173\u6027\u66f4\u5f3a\uff0c\u8868\u660e\u51c6\u786e\u7406\u89e3\u4f19\u4f34\u610f\u56fe\u6bd4\u9ad8\u9636\u63a8\u7406\u66f4\u91cd\u8981\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u52a8\u6001\u534f\u4f5c\u73af\u5883\u4e2d\u63a8\u65ad\u4ed6\u4eba\u884c\u4e3a\u52a8\u673a\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u8fd9\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u81f3\u5173\u91cd\u8981\u4f46\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1LLM-Hanabi\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u4f5c\u6e38\u620fHanabi\u8bc4\u4f30LLM\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u5305\u542b\u81ea\u52a8\u8bc4\u4f30\u7cfb\u7edf\u6d4b\u91cf\u6e38\u620f\u8868\u73b0\u548c\u5fc3\u667a\u7406\u8bba\u719f\u7ec3\u5ea6\u3002", "result": "\u53d1\u73b0\u5fc3\u667a\u7406\u8bba\u4e0e\u6e38\u620f\u6210\u529f\u663e\u8457\u6b63\u76f8\u5173\uff0c\u4e00\u9636\u5fc3\u667a\u7406\u8bba\uff08\u89e3\u91ca\u4ed6\u4eba\u610f\u56fe\uff09\u6bd4\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\uff08\u9884\u6d4b\u4ed6\u4eba\u89e3\u91ca\uff09\u4e0e\u8868\u73b0\u76f8\u5173\u6027\u66f4\u5f3a\u3002", "conclusion": "\u4e3a\u589e\u5f3aAI\u534f\u4f5c\u80fd\u529b\uff0c\u5e94\u4f18\u5148\u53d1\u5c55\u4e00\u9636\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u51c6\u786e\u7406\u89e3\u4f19\u4f34\u52a8\u673a\u6bd4\u9ad8\u9636\u63a8\u7406\u66f4\u5173\u952e\u3002"}}
{"id": "2510.05014", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05014", "abs": "https://arxiv.org/abs/2510.05014", "authors": ["Xuanming Cui", "Jianpeng Cheng", "Hong-you Chen", "Satya Narayan Shukla", "Abhijeet Awasthi", "Xichen Pan", "Chaitanya Ahuja", "Shlok Kumar Mishra", "Qi Guo", "Ser-Nam Lim", "Aashu Singh", "Xiangjun Fan"], "title": "Think Then Embed: Generative Context Improves Multimodal Embedding", "comment": null, "summary": "There is a growing interest in Universal Multimodal Embeddings (UME), where\nmodels are required to generate task-specific representations. While recent\nstudies show that Multimodal Large Language Models (MLLMs) perform well on such\ntasks, they treat MLLMs solely as encoders, overlooking their generative\ncapacity. However, such an encoding paradigm becomes less effective as\ninstructions become more complex and require compositional reasoning. Inspired\nby the proven effectiveness of chain-of-thought reasoning, we propose a general\nThink-Then-Embed (TTE) framework for UME, composed of a reasoner and an\nembedder. The reasoner MLLM first generates reasoning traces that explain\ncomplex queries, followed by an embedder that produces representations\nconditioned on both the original query and the intermediate reasoning. This\nexplicit reasoning step enables more nuanced understanding of complex\nmultimodal instructions. Our contributions are threefold. First, by leveraging\na powerful MLLM reasoner, we achieve state-of-the-art performance on the\nMMEB-V2 benchmark, surpassing proprietary models trained on massive in-house\ndatasets. Second, to reduce the dependency on large MLLM reasoners, we finetune\na smaller MLLM reasoner using high-quality embedding-centric reasoning traces,\nachieving the best performance among open-source models with a 7% absolute gain\nover recently proposed models. Third, we investigate strategies for integrating\nthe reasoner and embedder into a unified model for improved efficiency without\nsacrificing performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Think-Then-Embed\u6846\u67b6\uff0c\u901a\u8fc7MLLM\u751f\u6210\u63a8\u7406\u8f68\u8ff9\u6765\u589e\u5f3a\u590d\u6742\u591a\u6a21\u6001\u67e5\u8be2\u7684\u7406\u89e3\uff0c\u5728MMEB-V2\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5c06MLLMs\u7528\u4f5c\u7f16\u7801\u5668\uff0c\u5ffd\u7565\u4e86\u5176\u751f\u6210\u80fd\u529b\uff0c\u5728\u5904\u7406\u590d\u6742\u6307\u4ee4\u548c\u7ec4\u5408\u63a8\u7406\u65f6\u6548\u679c\u4e0d\u4f73\u3002", "method": "TTE\u6846\u67b6\u5305\u542b\u63a8\u7406\u5668\u548c\u5d4c\u5165\u5668\uff1a\u63a8\u7406\u5668MLLM\u751f\u6210\u89e3\u91ca\u590d\u6742\u67e5\u8be2\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5d4c\u5165\u5668\u57fa\u4e8e\u539f\u59cb\u67e5\u8be2\u548c\u4e2d\u95f4\u63a8\u7406\u751f\u6210\u8868\u793a\u3002", "result": "\u5728MMEB-V2\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e13\u6709\u6a21\u578b\uff1b\u901a\u8fc7\u5fae\u8c03\u5c0f\u578bMLLM\u63a8\u7406\u5668\uff0c\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u53d6\u5f977%\u7edd\u5bf9\u6027\u80fd\u63d0\u5347\uff1b\u5b9e\u73b0\u4e86\u63a8\u7406\u5668\u548c\u5d4c\u5165\u5668\u7684\u7edf\u4e00\u96c6\u6210\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u80fd\u591f\u66f4\u7ec6\u81f4\u5730\u7406\u89e3\u590d\u6742\u591a\u6a21\u6001\u6307\u4ee4\uff0cTTE\u6846\u67b6\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2510.05048", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.05048", "abs": "https://arxiv.org/abs/2510.05048", "authors": ["Ond\u0159ej Kub\u00ed\u010dek", "Viliam Lis\u00fd"], "title": "Look-ahead Reasoning with a Learned Model in Imperfect Information Games", "comment": null, "summary": "Test-time reasoning significantly enhances pre-trained AI agents'\nperformance. However, it requires an explicit environment model, often\nunavailable or overly complex in real-world scenarios. While MuZero enables\neffective model learning for search in perfect information games, extending\nthis paradigm to imperfect information games presents substantial challenges\ndue to more nuanced look-ahead reasoning techniques and large number of states\nrelevant for individual decisions. This paper introduces an algorithm LAMIR\nthat learns an abstracted model of an imperfect information game directly from\nthe agent-environment interaction. During test time, this trained model is used\nto perform look-ahead reasoning. The learned abstraction limits the size of\neach subgame to a manageable size, making theoretically principled look-ahead\nreasoning tractable even in games where previous methods could not scale. We\nempirically demonstrate that with sufficient capacity, LAMIR learns the exact\nunderlying game structure, and with limited capacity, it still learns a\nvaluable abstraction, which improves game playing performance of the\npre-trained agents even in large games.", "AI": {"tldr": "LAMIR\u7b97\u6cd5\u901a\u8fc7\u4ece\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u4e2d\u5b66\u4e60\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u6e38\u620f\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u4f7f\u6d4b\u8bd5\u65f6\u7684\u524d\u77bb\u63a8\u7406\u5728\u5927\u578b\u6e38\u620f\u4e2d\u53d8\u5f97\u53ef\u884c\uff0c\u63d0\u5347\u4e86\u9884\u8bad\u7ec3\u667a\u80fd\u4f53\u7684\u6e38\u620f\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u6e38\u620f\u4e2d\u6a21\u578b\u5b66\u4e60\u56f0\u96be\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u72b6\u6001\u6570\u91cf\u5e9e\u5927\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6709\u6548\u7684\u524d\u77bb\u63a8\u7406\u3002", "method": "\u63d0\u51faLAMIR\u7b97\u6cd5\uff0c\u76f4\u63a5\u4ece\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u4e2d\u5b66\u4e60\u6e38\u620f\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u62bd\u8c61\u5c06\u6bcf\u4e2a\u5b50\u6e38\u620f\u9650\u5236\u5728\u53ef\u7ba1\u7406\u7684\u5927\u5c0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8db3\u591f\u5bb9\u91cf\u4e0bLAMIR\u80fd\u5b66\u4e60\u5230\u51c6\u786e\u7684\u5e95\u5c42\u6e38\u620f\u7ed3\u6784\uff0c\u5728\u6709\u9650\u5bb9\u91cf\u4e0b\u4ecd\u80fd\u5b66\u4e60\u5230\u6709\u4ef7\u503c\u7684\u62bd\u8c61\uff0c\u63d0\u5347\u9884\u8bad\u7ec3\u667a\u80fd\u4f53\u5728\u5927\u578b\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "LAMIR\u7b97\u6cd5\u4f7f\u7406\u8bba\u4e0a\u5408\u7406\u7684\u524d\u77bb\u63a8\u7406\u5728\u4e4b\u524d\u65b9\u6cd5\u65e0\u6cd5\u6269\u5c55\u7684\u5927\u578b\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u6e38\u620f\u4e2d\u53d8\u5f97\u53ef\u884c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u7684\u6e38\u620f\u6027\u80fd\u3002"}}
{"id": "2510.05059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05059", "abs": "https://arxiv.org/abs/2510.05059", "authors": ["Junlin Wang", "Jue Wang", "Zhen", "Xu", "Ben Athiwaratkun", "Bhuwan Dhingra", "Ce Zhang", "James Zou"], "title": "Staircase Streaming for Low-Latency Multi-Agent Inference", "comment": null, "summary": "Recent advances in large language models (LLMs) opened up new directions for\nleveraging the collective expertise of multiple LLMs. These methods, such as\nMixture-of-Agents, typically employ additional inference steps to generate\nintermediate outputs, which are then used to produce the final response. While\nmulti-agent inference can enhance response quality, it can significantly\nincrease the time to first token (TTFT), posing a challenge for\nlatency-sensitive applications and hurting user experience. To address this\nissue, we propose staircase streaming for low-latency multi-agent inference.\nInstead of waiting for the complete intermediate outputs from previous steps,\nwe begin generating the final response as soon as we receive partial outputs\nfrom these steps. Experimental results demonstrate that staircase streaming\nreduces TTFT by up to 93% while maintaining response quality.", "AI": {"tldr": "\u63d0\u51fa\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\u65b9\u6cd5\u6765\u964d\u4f4e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u5ef6\u8fdf\uff0c\u901a\u8fc7\u90e8\u5206\u8f93\u51fa\u7acb\u5373\u751f\u6210\u6700\u7ec8\u54cd\u5e94\uff0c\u5c06\u9996\u4ee4\u724c\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe93%", "motivation": "\u591a\u667a\u80fd\u4f53\u63a8\u7406\u867d\u7136\u80fd\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\uff0c\u4f46\u663e\u8457\u589e\u52a0\u4e86\u9996\u4ee4\u724c\u65f6\u95f4\uff0c\u5bf9\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u6784\u6210\u6311\u6218\u5e76\u5f71\u54cd\u7528\u6237\u4f53\u9a8c", "method": "\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\uff1a\u4e0d\u7b49\u5f85\u524d\u4e00\u6b65\u9aa4\u7684\u5b8c\u6574\u4e2d\u95f4\u8f93\u51fa\uff0c\u800c\u662f\u5728\u6536\u5230\u90e8\u5206\u8f93\u51fa\u65f6\u7acb\u5373\u5f00\u59cb\u751f\u6210\u6700\u7ec8\u54cd\u5e94", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\u5c06\u9996\u4ee4\u724c\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe93%\uff0c\u540c\u65f6\u4fdd\u6301\u54cd\u5e94\u8d28\u91cf", "conclusion": "\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\u662f\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u5728\u4fdd\u6301\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u54cd\u5e94\u5ef6\u8fdf"}}
