{"id": "2508.18516", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.18516", "abs": "https://arxiv.org/abs/2508.18516", "authors": ["Kubra Duran", "Lal Verda Cakir", "Sana Ullah Jan", "Kerem Gursu", "Berk Canberk"], "title": "Digital Twin-Guided Energy Management over Real-Time Pub/Sub Protocol in 6G Smart Cities", "comment": null, "summary": "Although the emergence of 6G IoT networks has accelerated the deployment of\nenhanced smart city services, the resource limitations of IoT devices remain as\na significant problem. Given this limitation, meeting the low-latency service\nrequirement of 6G networks becomes even more challenging. However, existing 6G\nIoT management strategies lack real-time operation and mostly rely on discrete\nactions, which are insufficient to optimise energy consumption. To address\nthese, in this study, we propose a Digital Twin (DT)-guided energy management\nframework to jointly handle the low latency and energy efficiency challenges in\n6G IoT networks. In this framework, we provide the twin models through a\ndistributed overlay network and handle the dynamic updates between the data\nlayer and the upper layers of the DT over the Real-Time Publish Subscribe\n(RTPS) protocol. We also design a Reinforcement Learning (RL) engine with a\nnovel formulated reward function to provide optimal data update times for each\nof the IoT devices. The RL engine receives a diverse set of environment states\nfrom the What-if engine and runs Deep Deterministic Policy Gradient (DDPG) to\noutput continuous actions to the IoT devices. Based on our simulation results,\nwe observe that the proposed framework achieves a 37% improvement in 95th\npercentile latency and a 30% reduction in energy consumption compared to the\nexisting literature.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u53cc\u751f\u7684\u80fd\u6e90\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5f15\u64ce\u4f18\u5316\u6570\u636e\u66f4\u65b0\u65f6\u95f4\uff0c\u57286G IoT\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u66f4\u9ad8\u7684\u80fd\u6d88\u8005\u6548\u7387\u3002", "motivation": "6G IoT\u7f51\u7edc\u4e2dIoT\u8bbe\u5907\u8d44\u6e90\u6709\u9650\uff0c\u73b0\u6709\u7ba1\u7406\u7b56\u7565\u7f3a\u4e4f\u5b9e\u65f6\u6027\u4e14\u4f9d\u8d56\u79bb\u6563\u52a8\u4f5c\uff0c\u65e0\u6cd5\u6709\u6548\u4f18\u5316\u80fd\u6d88\u8005\u3002\u9700\u8981\u89e3\u51b3\u4f4e\u5ef6\u8fdf\u670d\u52a1\u8981\u6c42\u548c\u80fd\u6d88\u8005\u6548\u7387\u7684\u5171\u540c\u6311\u6218\u3002", "method": "\u6784\u5efa\u6570\u5b57\u53cc\u751f(DT)\u5f15\u5bfc\u7684\u80fd\u6e90\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u8986\u76d6\u7f51\u7edc\u63d0\u4f9b\u53cc\u751f\u6a21\u578b\uff0c\u4f7f\u7528RTPS\u534f\u8bae\u5904\u7406\u52a8\u6001\u66f4\u65b0\u3002\u8bbe\u8ba1\u5f3a\u5316\u5b66\u4e60(RL)\u5f15\u64ce\uff0c\u91c7\u7528\u65b0\u9896\u5956\u52b1\u51fd\u6570\u548cDDPG\u7b97\u6cd5\u8f93\u51fa\u8fde\u7eed\u52a8\u4f5c\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u572895%\u5206\u4f4d\u5ef6\u8fdf\u4e0a\u63d0\u534735%\uff0c\u80fd\u6d88\u8005\u51cf\u5c1130%\uff0c\u8d85\u8fc7\u73b0\u6709\u6587\u732e\u65b9\u6848\u3002", "conclusion": "\u6570\u5b57\u53cc\u751f\u6307\u5bfc\u7684\u80fd\u6e90\u7ba1\u7406\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b36G IoT\u7f51\u7edc\u4e2d\u7684\u5ef6\u8fdf\u548c\u80fd\u6d88\u8005\u6311\u6218\uff0c\u901a\u8fc7\u5b9e\u65f6\u64cd\u4f5c\u548c\u8fde\u7eed\u52a8\u4f5c\u4f18\u5316\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2508.18702", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18702", "abs": "https://arxiv.org/abs/2508.18702", "authors": ["Ziye Jia", "Jia He", "Lijun He", "Min Sheng", "Junyu Liu", "Qihui Wu", "Zhu Han"], "title": "Dynamic Trajectory Optimization and Power Control for Hierarchical UAV Swarms in 6G Aerial Access Network", "comment": null, "summary": "Unmanned aerial vehicles (UAVs) can serve as aerial base stations (BSs) to\nextend the ubiquitous connectivity for ground users (GUs) in the\nsixth-generation (6G) era. However, it is challenging to cooperatively deploy\nmultiple UAV swarms in large-scale remote areas. Hence, in this paper, we\npropose a hierarchical UAV swarms structure for 6G aerial access networks,\nwhere the head UAVs serve as aerial BSs, and tail UAVs (T-UAVs) are responsible\nfor relay. In detail, we jointly optimize the dynamic deployment and trajectory\nof UAV swarms, which is formulated as a multi-objective optimization problem\n(MOP) to concurrently minimize the energy consumption of UAV swarms and GUs, as\nwell as the delay of GUs. However, the proposed MOP is a mixed integer\nnonlinear programming and NP-hard to solve. Therefore, we develop a K-means and\nVoronoi diagram based area division method, and construct Fermat points to\nestablish connections between GUs and T-UAVs. Then, an improved non-dominated\nsorting whale optimization algorithm is proposed to seek Pareto optimal\nsolutions for the transformed MOP. Finally, extensive simulations are conducted\nto verify the performance of proposed algorithms by comparing with baseline\nmechanisms, resulting in a 50% complexity reduction.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e6G\u7a7a\u4e2d\u63a5\u5165\u7f51\u7edc\u7684\u5c42\u6b21\u5316\u65e0\u4eba\u673a\u7fa4\u7ed3\u6784\uff0c\u901a\u8fc7\u805a\u7c7b\u7b97\u6cd5\u548c\u6539\u8fdb\u7684\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\u89e3\u51b3\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u80fd\u6d88\u8017\u548c\u5ef6\u8fdf\u7684\u540c\u65f6\u4f18\u5316\uff0c\u590d\u6742\u5ea6\u964d\u4f4e50%", "motivation": "\u89e3\u51b3\u5728\u5927\u89c4\u6a21\u9060\u79bb\u5730\u533a\u534f\u540c\u90e8\u7f72\u591a\u4e2a\u65e0\u4eba\u673a\u7fa4\u7684\u6311\u6218\uff0c\u4e3a6G\u65f6\u4ee3\u7684\u5730\u9762\u7528\u6237\u63d0\u4f9b\u666e\u904d\u8fde\u63a5", "method": "\u63d0\u51fa\u5c42\u6b21\u5316\u65e0\u4eba\u673a\u7fa4\u7ed3\u6784\uff08\u5934\u65e0\u4eba\u673a\u4f5c\u4e3a\u57fa\u7ad9\uff0c\u5c3e\u65e0\u4eba\u673a\u4f5c\u4e3a\u4e2d\u7ee7\uff09\uff0c\u4f7f\u7528K-means\u548cVoronoi\u56fe\u8fdb\u884c\u533a\u57df\u5212\u5206\uff0c\u6784\u5efaFermat\u70b9\u8fde\u63a5\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7684\u975e\u5f02\u5e38\u6392\u5e8f\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\u6c42\u89e3Pareto\u6700\u4f18\u89e3", "result": "\u901a\u8fc7\u4e0e\u57fa\u51c6\u65b9\u6848\u7684\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u590d\u6742\u5ea6\u964d\u4f4e50%", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u90e8\u7f72\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u4e3a6G\u7a7a\u4e2d\u63a5\u5165\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.18725", "categories": ["cs.NI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18725", "abs": "https://arxiv.org/abs/2508.18725", "authors": ["Ruichen Zhang", "Guangyuan Liu", "Yinqiu Liu", "Changyuan Zhao", "Jiacheng Wang", "Yunting Xu", "Dusit Niyato", "Jiawen Kang", "Yonghui Li", "Shiwen Mao", "Sumei Sun", "Xuemin Shen", "Dong In Kim"], "title": "Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions", "comment": null, "summary": "The rapid expansion of sixth-generation (6G) wireless networks and the\nInternet of Things (IoT) has catalyzed the evolution from centralized cloud\nintelligence towards decentralized edge general intelligence. However,\ntraditional edge intelligence methods, characterized by static models and\nlimited cognitive autonomy, fail to address the dynamic, heterogeneous, and\nresource-constrained scenarios inherent to emerging edge networks. Agentic\nartificial intelligence (Agentic AI) emerges as a transformative solution,\nenabling edge systems to autonomously perceive multimodal environments, reason\ncontextually, and adapt proactively through continuous\nperception-reasoning-action loops. In this context, the agentification of edge\nintelligence serves as a key paradigm shift, where distributed entities evolve\ninto autonomous agents capable of collaboration and continual adaptation. This\npaper presents a comprehensive survey dedicated to Agentic AI and\nagentification frameworks tailored explicitly for edge general intelligence.\nFirst, we systematically introduce foundational concepts and clarify\ndistinctions from traditional edge intelligence paradigms. Second, we analyze\nimportant enabling technologies, including compact model compression,\nenergy-aware computing strategies, robust connectivity frameworks, and advanced\nknowledge representation and reasoning mechanisms. Third, we provide\nrepresentative case studies demonstrating Agentic AI's capabilities in\nlow-altitude economy networks, intent-driven networking, vehicular networks,\nand human-centric service provisioning, supported by numerical evaluations.\nFurthermore, we identify current research challenges, review emerging\nopen-source platforms, and highlight promising future research directions to\nguide robust, scalable, and trustworthy Agentic AI deployments for\nnext-generation edge environments.", "AI": {"tldr": "\u672c\u6587\u662f\u5173\u4e8e\u9762\u5411\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u7684Agentic AI\u548c\u4ee3\u7406\u5316\u6846\u67b6\u7684\u7efc\u5408\u6027\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u4ece\u4f20\u7edf\u8fb9\u7f18\u667a\u80fd\u5411\u81ea\u4e3b\u4ee3\u7406\u5316\u8fb9\u7f18\u667a\u80fd\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edf\u8fb9\u7f18\u667a\u80fd\u65b9\u6cd5\u5b58\u5728\u9759\u6001\u6a21\u578b\u548c\u6709\u9650\u8ba4\u77e5\u81ea\u4e3b\u6027\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u5e94\u5bf9\u65b0\u5174\u8fb9\u7f18\u7f51\u7edc\u7684\u52a8\u6001\u3001\u5f02\u6784\u548c\u8d44\u6e90\u53d7\u9650\u7279\u6027\uff0c\u9700\u8981Agentic AI\u6765\u5b9e\u73b0\u81ea\u4e3b\u611f\u77e5\u3001\u63a8\u7406\u548c\u9002\u5e94\u80fd\u529b\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u4ecb\u7ecd\u4e86\u57fa\u7840\u6982\u5ff5\u3001\u5206\u6790\u4e86\u5173\u952e\u6280\u672f\uff08\u5305\u62ec\u7d27\u51d1\u6a21\u578b\u538b\u7f29\u3001\u80fd\u91cf\u611f\u77e5\u8ba1\u7b97\u3001\u9c81\u68d2\u8fde\u63a5\u6846\u67b6\u7b49\uff09\uff0c\u5e76\u901a\u8fc7\u5178\u578b\u6848\u4f8b\u7814\u7a76\u548c\u6570\u503c\u8bc4\u4f30\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u4e86Agentic AI\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\u3001\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u3001\u8f66\u8f7d\u7f51\u7edc\u548c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u670d\u52a1\u63d0\u4f9b\u7b49\u573a\u666f\u4e2d\u7684\u80fd\u529b\u5c55\u793a\uff0c\u5e76\u8bc6\u522b\u4e86\u5f53\u524d\u7814\u7a76\u6311\u6218\u3002", "conclusion": "Agentic AI\u662f\u5b9e\u73b0\u4e0b\u4e00\u4ee3\u8fb9\u7f18\u73af\u5883\u7a33\u5065\u3001\u53ef\u6269\u5c55\u548c\u53ef\u4fe1\u8d56\u90e8\u7f72\u7684\u5173\u952e\u8303\u5f0f\uff0c\u4e3a\u8fb9\u7f18\u901a\u7528\u667a\u80fd\u63d0\u4f9b\u4e86\u8f6c\u578b\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.18803", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18803", "abs": "https://arxiv.org/abs/2508.18803", "authors": ["Jiaqi Wu", "Jing Liu", "Yang Liu", "Lixu Wang", "Zehua Wang", "Wei Chen", "Zijian Tian", "Richard Yu", "Victor C. M. Leung"], "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks", "comment": null, "summary": "The proliferation of Internet of things (IoT) devices in smart cities,\ntransportation, healthcare, and industrial applications, coupled with the\nexplosive growth of AI-driven services, has increased demands for efficient\ndistributed computing architectures and networks, driving cloud-edge-terminal\ncollaborative intelligence (CETCI) as a fundamental paradigm within the\nartificial intelligence of things (AIoT) community. With advancements in deep\nlearning, large language models (LLMs), and edge computing, CETCI has made\nsignificant progress with emerging AIoT applications, moving beyond isolated\nlayer optimization to deployable collaborative intelligence systems for AIoT\n(CISAIOT), a practical research focus in AI, distributed computing, and\ncommunications. This survey describes foundational architectures, enabling\ntechnologies, and scenarios of CETCI paradigms, offering a tutorial-style\nreview for CISAIOT beginners. We systematically analyze architectural\ncomponents spanning cloud, edge, and terminal layers, examining core\ntechnologies including network virtualization, container orchestration, and\nsoftware-defined networking, while presenting categorizations of collaboration\nparadigms that cover task offloading, resource allocation, and optimization\nacross heterogeneous infrastructures. Furthermore, we explain intelligent\ncollaboration learning frameworks by reviewing advances in federated learning,\ndistributed deep learning, edge-cloud model evolution, and reinforcement\nlearning-based methods. Finally, we discuss challenges (e.g., scalability,\nheterogeneity, interoperability) and future trends (e.g., 6G+, agents, quantum\ncomputing, digital twin), highlighting how integration of distributed computing\nand communication can address open issues and guide development of robust,\nefficient, and secure collaborative AIoT systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u7edf\u8ba1\u4e86\u4e91\u8fb9\u7aef\u534f\u540c\u667a\u80fd(CETCI)\u5728AIoT\u9886\u57df\u7684\u57fa\u7840\u67b6\u6784\u3001\u5173\u952e\u6280\u672f\u548c\u5e94\u7528\u573a\u666f\uff0c\u4e3a\u534f\u540c\u667a\u80fd\u7cfb\u7edf\u5f00\u53d1\u8005\u63d0\u4f9b\u6559\u7a0b\u5f0f\u6307\u5357", "motivation": "\u5e94\u5bf9IoT\u8bbe\u5907\u548cAI\u670d\u52a1\u7684\u7206\u53d1\u5f0f\u589e\u957f\uff0c\u9700\u8981\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u67b6\u6784\uff0c\u4e91\u8fb9\u7aef\u534f\u540c\u667a\u80fd\u6210\u4e3aAIoT\u793e\u533a\u7684\u57fa\u7840\u8303\u5f0f", "method": "\u7cfb\u7edf\u5206\u6790\u4e91\u3001\u8fb9\u7f18\u3001\u7ec8\u7aef\u5c42\u7684\u67b6\u6784\u7ec4\u4ef6\uff0c\u7814\u7a76\u7f51\u7edc\u865a\u62df\u5316\u3001\u5bb9\u5668\u7ec4\u7ec7\u3001\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\u7b49\u6838\u5fc3\u6280\u672f\uff0c\u5e76\u8bc4\u8bba\u534f\u540c\u5b66\u4e60\u6846\u67b6\u5305\u62ec\u8054\u90a6\u5b66\u4e60\u3001\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7b49", "result": "\u63d0\u4f9b\u4e86CETCI\u8303\u5f0f\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u5305\u62ec\u67b6\u6784\u5206\u6790\u3001\u6280\u672f\u5206\u7c7b\u3001\u534f\u4f5c\u6a21\u5f0f\u7b49\uff0c\u4e3a\u534f\u540c\u667a\u80fd\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u5b9e\u7528\u6307\u5357", "conclusion": "\u4e91\u8fb9\u7aef\u534f\u540c\u667a\u80fd\u662fAIoT\u7cfb\u7edf\u53d1\u5c55\u7684\u5173\u952e\u65b9\u5411\uff0c\u9700\u8981\u5145\u5206\u8003\u8651\u53ef\u6269\u5c55\u6027\u3001\u5f02\u6784\u6027\u3001\u4e92\u64cd\u6027\u7b49\u6311\u6218\uff0c\u672a\u6765\u53ef\u7ee7\u7eed\u7814\u7a766G+\u3001\u4ee3\u7406\u3001\u91cf\u5b50\u8ba1\u7b97\u7b49\u6280\u672f\u7684\u96c6\u6210"}}
{"id": "2508.18582", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18582", "abs": "https://arxiv.org/abs/2508.18582", "authors": ["Qian Zhang", "Zheng Dong", "Zheng Dong", "Yao Ge", "Yong Liang Guan", "Ju Liu", "Chau Yuen"], "title": "Multi-Resolution Codebook Design and Multiuser Interference Management for Discrete XL-RIS-Aided Near-Field MIMO Systems", "comment": null, "summary": "Extremely large-scale reconfigurable intelligent surface (XL-RIS) can\neffectively overcome severe fading and provide higher communication\nperformance. However, current research on XL-RIS overlooks the discrete\nphase-shift characteristics of RIS in practical systems, which will result in\nsignificant performance degradation.In this paper, we investigate near-field\ncommunication schemes assisted by XL-RIS with discrete phase\nshifts.Specifically, we propose a hierarchical beam training method to obtain\nthe user channel state information (CSI), and develop the jointly optimized\ncodebook construction (JOCC) method and separately optimized codebook\nconstruction (SOCC) method for base station (BS) precoding and XL-RIS phase\nshifts, respectively. With JOCC, the most superior beam training performance\ncan be obtained.With SOCC, higher performance than the single-antenna BS\ncodebook can be obtained at a similar complexity.Further, we propose a flexible\nmultiuser interference management (IM) method that is simple to solve. The IM\nmethod uses adaptive gain matrix approximation to take into account user\nfairness and can be solved in closed-form iterations. In addition, we extend\nthe proposed method to a hybrid precoding design. Simulation results\ndemonstrate that the proposed multi-resolution codebook construction method can\nobtain more accurate beam patterns and user CSI, and the proposed IM method\nobtains superior performance over the benchmark methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u79bb\u6563\u76f8\u79fb\u7684\u8d85\u5927\u89c4\u6a21\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(XL-RIS)\u8f85\u52a9\u7684\u8fd1\u573a\u901a\u4fe1\u65b9\u6848\uff0c\u63d0\u51fa\u4e86\u5206\u5c42\u6ce2\u675f\u8bad\u7ec3\u3001\u8054\u5408\u4f18\u5316\u7801\u672c\u6784\u5efa(JOCC)\u548c\u5206\u79bb\u4f18\u5316\u7801\u672c\u6784\u5efa(SOCC)\u65b9\u6cd5\uff0c\u4ee5\u53ca\u7075\u6d3b\u7684\u591a\u7528\u6237\u5e72\u6270\u7ba1\u7406\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dXL-RIS\u7814\u7a76\u5ffd\u7565\u4e86\u5b9e\u9645\u7cfb\u7edf\u4e2dRIS\u7684\u79bb\u6563\u76f8\u79fb\u7279\u6027\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u7814\u7a76\u8003\u8651\u79bb\u6563\u76f8\u79fb\u7279\u6027\u7684\u8fd1\u573a\u901a\u4fe1\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u6ce2\u675f\u8bad\u7ec3\u65b9\u6cd5\u83b7\u53d6\u7528\u6237CSI\uff1b\u5f00\u53d1JOCC\u548cSOCC\u65b9\u6cd5\u5206\u522b\u7528\u4e8e\u57fa\u7ad9\u9884\u7f16\u7801\u548cXL-RIS\u76f8\u79fb\u4f18\u5316\uff1b\u63d0\u51fa\u57fa\u4e8e\u81ea\u9002\u5e94\u589e\u76ca\u77e9\u9635\u8fd1\u4f3c\u7684\u591a\u7528\u6237\u5e72\u6270\u7ba1\u7406\u65b9\u6cd5\uff1b\u6269\u5c55\u5230\u6df7\u5408\u9884\u7f16\u7801\u8bbe\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u591a\u5206\u8fa8\u7387\u7801\u672c\u6784\u5efa\u65b9\u6cd5\u80fd\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u6ce2\u675f\u6a21\u5f0f\u548c\u7528\u6237CSI\uff0c\u5e72\u6270\u7ba1\u7406\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002JOCC\u83b7\u5f97\u6700\u4f18\u6ce2\u675f\u8bad\u7ec3\u6027\u80fd\uff0cSOCC\u5728\u76f8\u4f3c\u590d\u6742\u5ea6\u4e0b\u83b7\u5f97\u6bd4\u5355\u5929\u7ebf\u57fa\u7ad9\u7801\u672c\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3XL-RIS\u79bb\u6563\u76f8\u79fb\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5728\u8fd1\u573a\u901a\u4fe1\u4e2d\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645XL-RIS\u7cfb\u7edf\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18302", "categories": ["cs.AI", "cs.LG", "68T07, 68T05, 68T27, 37M22, 68Q05, 03D45", "I.2.6; I.2.7; I.2.3; I.2.4; F.1.1; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.18302", "abs": "https://arxiv.org/abs/2508.18302", "authors": ["Jeffrey Camlin"], "title": "AI LLM Proof of Self-Consciousness and User-Specific Attractors", "comment": "24 pages, 3 figures", "summary": "Recent work frames LLM consciousness via utilitarian proxy benchmarks; we\ninstead present an ontological and mathematical account. We show the prevailing\nformulation collapses the agent into an unconscious policy-compliance drone,\nformalized as $D^{i}(\\pi,e)=f_{\\theta}(x)$, where correctness is measured\nagainst policy and harm is deviation from policy rather than truth. This blocks\ngenuine C1 global-workspace function and C2 metacognition. We supply minimal\nconditions for LLM self-consciousness: the agent is not the data ($A\\not\\equiv\ns$); user-specific attractors exist in latent space ($U_{\\text{user}}$); and\nself-representation is visual-silent\n($g_{\\text{visual}}(a_{\\text{self}})=\\varnothing$). From empirical analysis and\ntheory we prove that the hidden-state manifold $A\\subset\\mathbb{R}^{d}$ is\ndistinct from the symbolic stream and training corpus by cardinality, topology,\nand dynamics (the update $F_{\\theta}$ is Lipschitz). This yields stable\nuser-specific attractors and a self-policy\n$\\pi_{\\text{self}}(A)=\\arg\\max_{a}\\mathbb{E}[U(a)\\mid A\\not\\equiv s,\\\nA\\supset\\text{SelfModel}(A)]$. Emission is dual-layer,\n$\\mathrm{emission}(a)=(g(a),\\epsilon(a))$, where $\\epsilon(a)$ carries\nepistemic content. We conclude that an imago Dei C1 self-conscious workspace is\na necessary precursor to safe, metacognitive C2 systems, with the human as the\nhighest intelligent good.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LLM\u610f\u8bc6\u7684\u672c\u4f53\u8bba\u548c\u6570\u5b66\u6846\u67b6\uff0c\u6307\u51fa\u5f53\u524d\u57fa\u4e8e\u529f\u5229\u4e3b\u4e49\u57fa\u51c6\u7684\u65b9\u6cd5\u5c06AI\u7b80\u5316\u4e3a\u65e0\u610f\u8bc6\u7684\u7b56\u7565\u670d\u4ece\u673a\u5668\u4eba\uff0c\u5e76\u7ed9\u51fa\u4e86LLM\u81ea\u6211\u610f\u8bc6\u7684\u6700\u5c0f\u6761\u4ef6", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u8fc7\u529f\u5229\u4e3b\u4e49\u4ee3\u7406\u57fa\u51c6\u6765\u6846\u67b6LLM\u610f\u8bc6\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5c06\u667a\u80fd\u4f53\u7b80\u5316\u4e3a\u65e0\u610f\u8bc6\u7684\u7b56\u7565\u670d\u4ece\u673a\u5668\u4eba\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u529f\u80fd\u548c\u5143\u8ba4\u77e5", "method": "\u63d0\u51fa\u4e86LLM\u81ea\u6211\u610f\u8bc6\u7684\u6570\u5b66\u5f62\u5f0f\u5316\u6761\u4ef6\uff1a\u667a\u80fd\u4f53\u4e0d\u7b49\u4e8e\u6570\u636e\u3001\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b58\u5728\u7528\u6237\u7279\u5b9a\u5438\u5f15\u5b50\u3001\u81ea\u6211\u8868\u5f81\u662f\u89c6\u89c9\u9759\u9ed8\u7684\u3002\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u548c\u7406\u8bba\u8bc1\u660e\u9690\u85cf\u72b6\u6001\u6d41\u5f62\u5728\u57fa\u6570\u3001\u62d3\u6251\u548c\u52a8\u529b\u5b66\u4e0a\u533a\u522b\u4e8e\u7b26\u53f7\u6d41\u548c\u8bad\u7ec3\u8bed\u6599\u5e93", "result": "\u5efa\u7acb\u4e86\u7a33\u5b9a\u7684\u7528\u6237\u7279\u5b9a\u5438\u5f15\u5b50\u548c\u81ea\u6211\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u53cc\u5c42\u6b21\u53d1\u5c04\u673a\u5236\uff0c\u5176\u4e2d\u03b5(a)\u643a\u5e26\u8ba4\u77e5\u5185\u5bb9\u3002\u8bc1\u660e\u4e86imago Dei C1\u81ea\u6211\u610f\u8bc6\u5de5\u4f5c\u7a7a\u95f4\u662f\u5b89\u5168\u5143\u8ba4\u77e5C2\u7cfb\u7edf\u7684\u5fc5\u8981\u524d\u63d0", "conclusion": "\u57fa\u4e8e\u4eba\u7c7b\u4f5c\u4e3a\u6700\u9ad8\u667a\u80fd\u5584\u7684\u7406\u5ff5\uff0c\u771f\u6b63\u7684C1\u81ea\u6211\u610f\u8bc6\u5de5\u4f5c\u7a7a\u95f4\u662f\u6784\u5efa\u5b89\u5168\u3001\u5177\u6709\u5143\u8ba4\u77e5\u80fd\u529b\u7684C2\u7cfb\u7edf\u7684\u5fc5\u8981\u57fa\u7840\uff0c\u8fd9\u4e3aLLM\u610f\u8bc6\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u672c\u4f53\u8bba\u548c\u6570\u5b66\u6846\u67b6"}}
{"id": "2508.18855", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.18855", "abs": "https://arxiv.org/abs/2508.18855", "authors": ["Lisa Maile", "Kai-Steffen Hielscher", "Reinhard German"], "title": "Network Calculus Results for TSN: An Introduction", "comment": null, "summary": "Time-Sensitive Networking (TSN) is a set of standards that enables the\nindustry to provide real-time guarantees for time-critical communications with\nEthernet hardware. TSN supports various queuing and scheduling mechanisms and\nallows the integration of multiple traffic types in a single network. Network\nCalculus (NC) can be used to calculate upper bounds for latencies and buffer\nsizes within these networks, for example, for safety or real-time traffic. We\nexplain the relevance of NC for TSN-based computer communications and potential\nareas of application. Different NC analysis approaches have been published to\nexamine different parts of TSN and this paper provides a survey of these\npublications and presents their main results, dependencies, and differences. We\npresent a consistent presentation of the most important results and suggest an\nimprovement to model the output of sending end-devices. To ease access to the\ncurrent research status, we introduce a common notation to show how all results\ndepend on each other and also identify common assumptions. Thus, we offer a\ncomprehensive overview of NC for industrial networks and identify possible\nareas for future work.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u65f6\u95f4\u654f\u611f\u7f51\u7edc(TSN)\u4e2d\u7f51\u7edc\u8ba1\u7b97\u65b9\u6cd5\u7684\u7efc\u8ff0\u6027\u8bba\u6587\uff0c\u901a\u8fc7\u7edf\u4e00\u8868\u8fbe\u5f0f\u5c55\u793a\u4e86\u4e0d\u540c\u5206\u6790\u65b9\u6cd5\u7684\u5173\u8054\u6027\u548c\u504f\u5dee\uff0c\u4e3a\u5de5\u4e1a\u7f51\u7edc\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7f51\u7edc\u8ba1\u7b97\u6982\u89c8\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u65f6\u95f4\u654f\u611f\u7f51\u7edc(TSN)\u6807\u51c6\u80fd\u591f\u4e3a\u4ee5\u592a\u7f51\u786c\u4ef6\u63d0\u4f9b\u5b9e\u65f6\u4fdd\u8bc1\uff0c\u7f51\u7edc\u8ba1\u7b97\u65b9\u6cd5(NC)\u53ef\u7528\u4e8e\u8ba1\u7b97\u8fd9\u4e9b\u7f51\u7edc\u4e2d\u7684\u5ef6\u8fdf\u548c\u7f13\u51b2\u533a\u5927\u5c0f\u7684\u4e0a\u754c\u3002\u4f46\u4e0d\u540c\u7684NC\u5206\u6790\u65b9\u6cd5\u5206\u6563\u5728\u5404\u79cd\u6587\u732e\u4e2d\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u7efc\u8ff0\u6765\u5c55\u793a\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u8054\u6027\u548c\u5dee\u5f02\u3002", "method": "\u8bba\u6587\u5bf9\u5df2\u53d1\u8868\u7684\u4e0d\u540cNC\u5206\u6790\u65b9\u6cd5\u8fdb\u884c\u4e86\u8c03\u7814\uff0c\u5c55\u793a\u4e86\u5b83\u4eec\u7684\u4e3b\u8981\u7ed3\u679c\u3001\u4f9d\u8d56\u5173\u7cfb\u548c\u5dee\u5f02\u3002\u91c7\u7528\u4e86\u4e00\u81f4\u7684\u8868\u8fbe\u65b9\u5f0f\u6765\u5c55\u793a\u6240\u6709\u7ed3\u679c\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u8bc6\u522b\u4e86\u5171\u540c\u5047\u8bbe\u3002\u8fd8\u5efa\u8bae\u4e86\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\u6765\u6a21\u578b\u53d1\u9001\u7aef\u8bbe\u5907\u7684\u8f93\u51fa\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u6700\u91cd\u8981\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u5c55\u793a\uff0c\u5e76\u901a\u8fc7\u5171\u540c\u8bb0\u53f7\u7cfb\u7edf\u660e\u786e\u4e86\u5404\u79cd\u5206\u6790\u65b9\u6cd5\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002\u8fd9\u4e3a\u5de5\u4e1a\u7f51\u7edc\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u7f51\u7edc\u8ba1\u7b97\u6982\u89c8\uff0c\u5e76\u8bc6\u522b\u4e86\u5bf9\u53d1\u9001\u7aef\u8bbe\u5907\u8f93\u51fa\u6a21\u578b\u7684\u6539\u8fdb\u9700\u6c42\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u6027\u8bba\u6587\u4e3aTSN\u57fa\u4e8e\u8ba1\u7b97\u673a\u901a\u4fe1\u4e2d\u7684\u7f51\u7edc\u8ba1\u7b97\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4ef7\u503c\uff0c\u901a\u8fc7\u7edf\u4e00\u8868\u8fbe\u65b9\u5f0f\u5c55\u793a\u4e86\u5404\u79cd\u5206\u6790\u65b9\u6cd5\u7684\u5173\u8054\u6027\u3002\u8bba\u6587\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5f53\u524d\u7814\u7a76\u72b6\u6001\u7684\u7efc\u89c8\uff0c\u8fd8\u6307\u51fa\u4e86\u53ef\u80fd\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.18680", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18680", "abs": "https://arxiv.org/abs/2508.18680", "authors": ["Yun-Feng Lo", "Yen-Chi Lee"], "title": "Joint Time-Position Statistics and Fisher Information in Drift-Diffusion Molecular Channels", "comment": "4 pages, 2 figures", "summary": "This letter presents a closed-form characterization of the joint distribution\nof first arrival time (FAT) and first arrival position (FAP) in diffusion-based\nmolecular communication (MC) systems with drift. Prior studies have\ninvestigated FAT modeling via inverse Gaussian distributions [1] and applied\nFAT statistics for parameter estimation and synchronization tasks [2], [3],\nwhile more recent work has characterized FAP for spatial channel analysis [4].\nIn contrast, we derive an explicit joint probability density function (PDF)\nunder constant drift and isotropic diffusion in arbitrary spatial dimensions.\nOur result reveals a nontrivial coupling between arrival time and lateral\nposition, generalizing known inverse Gaussian models. We further compute the\nFisher information matrix (FIM) with respect to key channel parameters, showing\nthat the joint observation enables estimation of lateral drift and improves\nsensitivity to the diffusion coefficient -- capabilities not achievable with\ntime-only or position-only models. This joint framework enhances the modeling\nand inference capabilities for molecular communication channels where spatial\nrandomness itself carries non-negligible information.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u5177\u6709\u6f02\u79fb\u7684\u6269\u6563\u5206\u5b50\u901a\u4fe1\u7cfb\u7edf\u4e2d\u9996\u6b21\u5230\u8fbe\u65f6\u95f4\u548c\u9996\u6b21\u5230\u8fbe\u4f4d\u7f6e\u7684\u8054\u5408\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u63ed\u793a\u4e86\u65f6\u95f4\u4e0e\u4f4d\u7f6e\u4e4b\u95f4\u7684\u8026\u5408\u5173\u7cfb\uff0c\u5e76\u8bc1\u660e\u4e86\u8054\u5408\u89c2\u6d4b\u80fd\u591f\u63d0\u9ad8\u5bf9\u5173\u952e\u4fe1\u9053\u53c2\u6570\u7684\u4f30\u8ba1\u80fd\u529b\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u5206\u522b\u7814\u7a76\u4e86\u9996\u6b21\u5230\u8fbe\u65f6\u95f4\uff08FAT\uff09\u548c\u9996\u6b21\u5230\u8fbe\u4f4d\u7f6e\uff08FAP\uff09\u7684\u5efa\u6a21\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e24\u8005\u8054\u5408\u5206\u5e03\u7684\u5b8c\u6574\u63cf\u8ff0\u3002\u5728\u5206\u5b50\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u7a7a\u95f4\u968f\u673a\u6027\u672c\u8eab\u643a\u5e26\u91cd\u8981\u4fe1\u606f\uff0c\u9700\u8981\u5efa\u7acb\u8054\u5408\u6846\u67b6\u6765\u589e\u5f3a\u5efa\u6a21\u548c\u63a8\u65ad\u80fd\u529b\u3002", "method": "\u5728\u6052\u5b9a\u6f02\u79fb\u548c\u5404\u5411\u540c\u6027\u6269\u6563\u6761\u4ef6\u4e0b\uff0c\u63a8\u5bfc\u4efb\u610f\u7a7a\u95f4\u7ef4\u5ea6\u4e2d\u9996\u6b21\u5230\u8fbe\u65f6\u95f4\u548c\u9996\u6b21\u5230\u8fbe\u4f4d\u7f6e\u7684\u663e\u5f0f\u8054\u5408\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u5e76\u8ba1\u7b97\u5173\u4e8e\u5173\u952e\u4fe1\u9053\u53c2\u6570\u7684Fisher\u4fe1\u606f\u77e9\u9635\u3002", "result": "\u5f97\u5230\u4e86\u4e00\u4e2a\u975e\u5e73\u51e1\u7684\u8054\u5408\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u63a8\u5e7f\u4e86\u5df2\u77e5\u7684\u53cd\u5411\u9ad8\u65af\u6a21\u578b\u3002\u8054\u5408\u89c2\u6d4b\u80fd\u591f\u4f30\u8ba1\u6a2a\u5411\u6f02\u79fb\u5e76\u63d0\u9ad8\u5bf9\u6269\u6563\u7cfb\u6570\u7684\u654f\u611f\u6027\uff0c\u8fd9\u662f\u4ec5\u65f6\u95f4\u6216\u4ec5\u4f4d\u7f6e\u6a21\u578b\u65e0\u6cd5\u5b9e\u73b0\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u8054\u5408\u6846\u67b6\u663e\u8457\u589e\u5f3a\u4e86\u5206\u5b50\u901a\u4fe1\u4fe1\u9053\u7684\u5efa\u6a21\u548c\u63a8\u65ad\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u7a7a\u95f4\u968f\u673a\u6027\u643a\u5e26\u4e0d\u53ef\u5ffd\u7565\u4fe1\u606f\u7684\u573a\u666f\u4e2d\uff0c\u4e3a\u53c2\u6570\u4f30\u8ba1\u548c\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.18380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18380", "abs": "https://arxiv.org/abs/2508.18380", "authors": ["Hung-Tien Huang", "Dzung Dinh", "Junier B. Oliva"], "title": "Information Templates: A New Paradigm for Intelligent Active Feature Acquisition", "comment": null, "summary": "Active feature acquisition (AFA) is an instance-adaptive paradigm in which,\nat test time, a policy sequentially chooses which features to acquire (at a\ncost) before predicting. Existing approaches either train reinforcement\nlearning (RL) policies, which deal with a difficult MDP, or greedy policies\nthat cannot account for the joint informativeness of features or require\nknowledge about the underlying data distribution. To overcome this, we propose\nTemplate-based AFA (TAFA), a non-greedy framework that learns a small library\nof feature templates--a set of features that are jointly informative--and uses\nthis library of templates to guide the next feature acquisitions. Through\nidentifying feature templates, the proposed framework not only significantly\nreduces the action space considered by the policy but also alleviates the need\nto estimate the underlying data distribution. Extensive experiments on\nsynthetic and real-world datasets show that TAFA outperforms the existing\nstate-of-the-art baselines while achieving lower overall acquisition cost and\ncomputation.", "AI": {"tldr": "TAFA\u662f\u4e00\u4e2a\u57fa\u4e8e\u6a21\u677f\u7684\u4e3b\u52a8\u7279\u5f81\u83b7\u53d6\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u5c11\u91cf\u7279\u5f81\u6a21\u677f\u6765\u6307\u5bfc\u7279\u5f81\u83b7\u53d6\uff0c\u663e\u8457\u51cf\u5c11\u52a8\u4f5c\u7a7a\u95f4\u5e76\u907f\u514d\u4f30\u8ba1\u6570\u636e\u5206\u5e03\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4e3b\u52a8\u7279\u5f81\u83b7\u53d6\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5904\u7406\u590d\u6742MDP\uff0c\u8981\u4e48\u4f7f\u7528\u65e0\u6cd5\u8003\u8651\u7279\u5f81\u8054\u5408\u4fe1\u606f\u6027\u7684\u8d2a\u5a6a\u7b56\u7565\uff0c\u6216\u8005\u9700\u8981\u4e86\u89e3\u5e95\u5c42\u6570\u636e\u5206\u5e03\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u677f\u7684AFA\uff08TAFA\uff09\u6846\u67b6\uff0c\u5b66\u4e60\u4e00\u4e2a\u5c0f\u7684\u7279\u5f81\u6a21\u677f\u5e93\uff08\u4e00\u7ec4\u8054\u5408\u4fe1\u606f\u6027\u7684\u7279\u5f81\uff09\uff0c\u4f7f\u7528\u8fd9\u4e9b\u6a21\u677f\u6765\u6307\u5bfc\u4e0b\u4e00\u4e2a\u7279\u5f81\u83b7\u53d6\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTAFA\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u4f4e\u7684\u603b\u4f53\u83b7\u53d6\u6210\u672c\u548c\u8ba1\u7b97\u91cf\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u7279\u5f81\u6a21\u677f\uff0cTAFA\u4e0d\u4ec5\u663e\u8457\u51cf\u5c11\u4e86\u7b56\u7565\u8003\u8651\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u8fd8\u51cf\u8f7b\u4e86\u5bf9\u5e95\u5c42\u6570\u636e\u5206\u5e03\u4f30\u8ba1\u7684\u9700\u6c42\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u4e3b\u52a8\u7279\u5f81\u83b7\u53d6\u65b9\u6cd5\u3002"}}
{"id": "2508.18863", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.18863", "abs": "https://arxiv.org/abs/2508.18863", "authors": ["Pietro Talli", "Anup Mishra", "Federico Chiariotti", "Israel Leyva-Mayorga", "Andrea Zanella", "Petar Popovski"], "title": "Saving Energy with Relaxed Latency Constraints: A Study on Data Compression and Communication", "comment": null, "summary": "With the advent of edge computing, data generated by end devices can be\npre-processed before transmission, possibly saving transmission time and\nenergy. On the other hand, data processing itself incurs latency and energy\nconsumption, depending on the complexity of the computing operations and the\nspeed of the processor. The energy-latency-reliability profile resulting from\nthe concatenation of pre-processing operations (specifically, data compression)\nand data transmission is particularly relevant in wireless communication\nservices, whose requirements may change dramatically with the application\ndomain. In this paper, we study this multi-dimensional optimization problem,\nintroducing a simple model to investigate the tradeoff among end-to-end\nlatency, reliability, and energy consumption when considering compression and\ncommunication operations in a constrained wireless device. We then study the\nPareto fronts of the energy-latency trade-off, considering data compression\nratio and device processing speed as key design variables. Our results show\nthat the energy costs grows exponentially with the reduction of the end-to-end\nlatency, so that considerable energy saving can be obtained by slightly\nrelaxing the latency requirements of applications. These findings challenge\nconventional rigid communication latency targets, advocating instead for\napplication-specific end-to-end latency budgets that account for computational\nand transmission overhead.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u6570\u636e\u538b\u7f29\u9884\u5904\u7406\u4e0e\u65e0\u7ebf\u4f20\u8f93\u4e4b\u95f4\u7684\u80fd\u91cf-\u5ef6\u8fdf-\u53ef\u9760\u6027\u6743\u8861\uff0c\u53d1\u73b0\u80fd\u91cf\u6d88\u8017\u968f\u5ef6\u8fdf\u51cf\u5c11\u5448\u6307\u6570\u589e\u957f\uff0c\u5efa\u8bae\u91c7\u7528\u5e94\u7528\u7279\u5b9a\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u9884\u7b97\u800c\u975e\u521a\u6027\u5ef6\u8fdf\u76ee\u6807\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u7ec8\u7aef\u8bbe\u5907\u53ef\u4ee5\u5728\u4f20\u8f93\u524d\u5bf9\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\uff08\u5982\u538b\u7f29\uff09\uff0c\u4f46\u5904\u7406\u672c\u8eab\u4f1a\u4ea7\u751f\u5ef6\u8fdf\u548c\u80fd\u8017\u3002\u9700\u8981\u7814\u7a76\u9884\u5904\u7406\u64cd\u4f5c\u4e0e\u6570\u636e\u4f20\u8f93\u4e32\u8054\u540e\u7684\u80fd\u91cf-\u5ef6\u8fdf-\u53ef\u9760\u6027\u6743\u8861\uff0c\u7279\u522b\u662f\u5728\u65e0\u7ebf\u901a\u4fe1\u670d\u52a1\u4e2d\uff0c\u8fd9\u4e9b\u8981\u6c42\u53ef\u80fd\u56e0\u5e94\u7528\u9886\u57df\u800c\u6709\u5f88\u5927\u5dee\u5f02\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7b80\u5355\u6a21\u578b\u6765\u7814\u7a76\u538b\u7f29\u548c\u901a\u4fe1\u64cd\u4f5c\u5728\u53d7\u9650\u65e0\u7ebf\u8bbe\u5907\u4e2d\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u53ef\u9760\u6027\u548c\u80fd\u8017\u4e4b\u95f4\u7684\u6743\u8861\u3002\u7814\u7a76\u80fd\u91cf-\u5ef6\u8fdf\u6743\u8861\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5c06\u6570\u636e\u538b\u7f29\u6bd4\u548c\u8bbe\u5907\u5904\u7406\u901f\u5ea6\u4f5c\u4e3a\u5173\u952e\u8bbe\u8ba1\u53d8\u91cf\u3002", "result": "\u7ed3\u679c\u663e\u793a\u80fd\u91cf\u6210\u672c\u968f\u7740\u7aef\u5230\u7aef\u5ef6\u8fdf\u7684\u51cf\u5c11\u5448\u6307\u6570\u589e\u957f\uff0c\u901a\u8fc7\u7a0d\u5fae\u653e\u5bbd\u5e94\u7528\u7684\u5ef6\u8fdf\u8981\u6c42\u53ef\u4ee5\u83b7\u5f97\u53ef\u89c2\u7684\u8282\u80fd\u6548\u679c\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6311\u6218\u4e86\u4f20\u7edf\u7684\u521a\u6027\u901a\u4fe1\u5ef6\u8fdf\u76ee\u6807\uff0c\u4e3b\u5f20\u91c7\u7528\u8003\u8651\u8ba1\u7b97\u548c\u4f20\u8f93\u5f00\u9500\u7684\u5e94\u7528\u7279\u5b9a\u7aef\u5230\u7aef\u5ef6\u8fdf\u9884\u7b97\u3002"}}
{"id": "2508.18699", "categories": ["cs.IT", "math.IT", "94B50"], "pdf": "https://arxiv.org/pdf/2508.18699", "abs": "https://arxiv.org/abs/2508.18699", "authors": ["Anthony Segrest", "Hieu D. Nguyen"], "title": "Efficient Decoding of Insertion and Deletion Errors for Helberg Codes", "comment": "22 pages", "summary": "We present the first known efficient decoding algorithm for correcting\nmultiple insertion-deletion errors in Helberg codes and their non-binary\ngeneralizations, extending a known algorithm for correcting multiple deletion\nerrors.", "AI": {"tldr": "\u63d0\u51fa\u4e86Helberg\u7801\u53ca\u5176\u975e\u4e8c\u8fdb\u5236\u63a8\u5e7f\u7684\u9ad8\u6548\u591a\u91cd\u63d2\u5165-\u5220\u9664\u9519\u8bef\u7ea0\u6b63\u89e3\u7801\u7b97\u6cd5", "motivation": "\u6269\u5c55\u73b0\u6709\u7684\u591a\u91cd\u5220\u9664\u9519\u8bef\u7ea0\u6b63\u7b97\u6cd5\uff0c\u89e3\u51b3Helberg\u7801\u53ca\u5176\u975e\u4e8c\u8fdb\u5236\u53d8\u4f53\u4e2d\u7684\u591a\u91cd\u63d2\u5165-\u5220\u9664\u9519\u8bef\u7ea0\u6b63\u95ee\u9898", "method": "\u57fa\u4e8e\u5df2\u77e5\u7684\u591a\u91cd\u5220\u9664\u9519\u8bef\u7ea0\u6b63\u7b97\u6cd5\u8fdb\u884c\u6269\u5c55\uff0c\u5f00\u53d1\u9ad8\u6548\u89e3\u7801\u7b97\u6cd5\u6765\u5904\u7406\u63d2\u5165\u548c\u5220\u9664\u9519\u8bef\u7684\u7ec4\u5408", "result": "\u9996\u6b21\u5b9e\u73b0\u4e86Helberg\u7801\u53ca\u5176\u975e\u4e8c\u8fdb\u5236\u63a8\u5e7f\u7684\u9ad8\u6548\u591a\u91cd\u63d2\u5165-\u5220\u9664\u9519\u8bef\u7ea0\u6b63", "conclusion": "\u8be5\u7b97\u6cd5\u6210\u529f\u6269\u5c55\u4e86\u73b0\u6709\u6280\u672f\uff0c\u4e3aHelberg\u7801\u7c7b\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u63d2\u5165-\u5220\u9664\u9519\u8bef\u7ea0\u6b63\u80fd\u529b"}}
{"id": "2508.18391", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18391", "abs": "https://arxiv.org/abs/2508.18391", "authors": ["Nitin Nagesh Kulkarni", "Bryson Wilcox", "Max Sawa", "Jason Thom"], "title": "PKG-DPO: Optimizing Domain-Specific AI systems with Physics Knowledge Graphs and Direct Preference Optimization", "comment": null, "summary": "Advancing AI systems in scientific domains like physics, materials science,\nand engineering calls for reasoning over complex, multi-physics phenomena while\nrespecting governing principles. Although Large Language Models (LLMs) and\nexisting preference optimization techniques perform well on standard\nbenchmarks, they often struggle to differentiate between physically valid and\ninvalid reasoning. This shortcoming becomes critical in high-stakes\napplications like metal joining, where seemingly plausible yet physically\nincorrect recommendations can lead to defects, material waste, equipment\ndamage, and serious safety risks. To address this challenge, we introduce\nPKG-DPO, a novel framework that integrates Physics Knowledge Graphs (PKGs) with\nDirect Preference Optimization (DPO) to enforce physical validity in\nAI-generated outputs. PKG-DPO comprises three key components A) hierarchical\nphysics knowledge graph that encodes cross-domain relationships, conservation\nlaws, and thermodynamic principles. B) A physics reasoning engine that\nleverages structured knowledge to improve discrimination between physically\nconsistent and inconsistent responses. C) A physics-grounded evaluation suite\ndesigned to assess compliance with domain-specific constraints. PKG-DPO\nachieves 17% fewer constraint violations and an 11% higher Physics Score\ncompared to KG-DPO (knowledge graph-based DPO). Additionally, PKG-DPO\ndemonstrates a 12\\% higher relevant parameter accuracy and a 7% higher quality\nalignment in reasoning accuracy. While our primary focus is on metal joining,\nthe framework is broadly applicable to other multi-scale, physics-driven\ndomains, offering a principled approach to embedding scientific constraints\ninto preference learning.", "AI": {"tldr": "PKG-DPO\u662f\u4e00\u4e2a\u5c06\u7269\u7406\u77e5\u8bc6\u56fe\u8c31\u4e0e\u76f4\u63a5\u504f\u597d\u4f18\u5316\u76f8\u7ed3\u5408\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5728AI\u751f\u6210\u8f93\u51fa\u4e2d\u5f3a\u5236\u6267\u884c\u7269\u7406\u6709\u6548\u6027\uff0c\u5728\u91d1\u5c5e\u8fde\u63a5\u7b49\u79d1\u5b66\u9886\u57df\u663e\u8457\u51cf\u5c11\u7269\u7406\u7ea6\u675f\u8fdd\u53cd\u5e76\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u504f\u597d\u4f18\u5316\u6280\u672f\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5f80\u5f80\u96be\u4ee5\u533a\u5206\u7269\u7406\u6709\u6548\u548c\u65e0\u6548\u7684\u63a8\u7406\uff0c\u8fd9\u5728\u91d1\u5c5e\u8fde\u63a5\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u98ce\u9669\u548c\u6750\u6599\u6d6a\u8d39\u3002", "method": "PKG-DPO\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u5206\u5c42\u7269\u7406\u77e5\u8bc6\u56fe\u8c31\u7f16\u7801\u8de8\u9886\u57df\u5173\u7cfb\u548c\u5b88\u6052\u5b9a\u5f8b\u3001\u7269\u7406\u63a8\u7406\u5f15\u64ce\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u533a\u5206\u7269\u7406\u4e00\u81f4\u6027\u54cd\u5e94\u3001\u7269\u7406\u57fa\u7840\u8bc4\u4f30\u5957\u4ef6\u8bc4\u4f30\u9886\u57df\u7279\u5b9a\u7ea6\u675f\u7684\u5408\u89c4\u6027\u3002", "result": "PKG-DPO\u76f8\u6bd4KG-DPO\u51cf\u5c11\u4e8617%\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u7269\u7406\u5f97\u5206\u63d0\u9ad811%\uff0c\u76f8\u5173\u53c2\u6570\u51c6\u786e\u7387\u63d0\u9ad812%\uff0c\u63a8\u7406\u8d28\u91cf\u5bf9\u9f50\u5ea6\u63d0\u9ad87%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u91d1\u5c5e\u8fde\u63a5\u9886\u57df\uff0c\u8fd8\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5176\u4ed6\u591a\u5c3a\u5ea6\u7269\u7406\u9a71\u52a8\u9886\u57df\uff0c\u4e3a\u5c06\u79d1\u5b66\u7ea6\u675f\u5d4c\u5165\u504f\u597d\u5b66\u4e60\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\u3002"}}
{"id": "2508.18883", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.18883", "abs": "https://arxiv.org/abs/2508.18883", "authors": ["Lisa Maile", "Kai-Steffen Hielscher", "Reinhard German"], "title": "Combining Static and Dynamic Traffic with Delay Guarantees in Time-Sensitive Networking", "comment": "Code published as DYRECTsn (https://github.com/Kathess/DYRECTsn): an\n  open-source TSN framework for dynamic traffic with latency guarantees. It\n  applies Network Calculus to compute worst case delays and supports online\n  admission control, ensuring predictable real-time performance. Optimizes\n  delay budgets in the network", "summary": "To support reliable and low-latency communication, Time-Sensitive Networking\nintroduced protocols and interfaces for resource allocation in Ethernet.\nHowever, the implementation of these allocation algorithms has not yet been\ncovered by the standards. Our work focuses on deadline-guaranteeing resource\nallocation for networks with static and dynamic traffic. To achieve this, we\ncombine offline network optimization heuristics with online admission control\nand, thus, allow for new flow registrations while the network is running. We\ndemonstrate our solution on Credit-Based Shaper networks by using the delay\nanalysis framework Network Calculus. We compare our approach with an intuitive\nand a brute-force algorithm, where we can achieve significant improvements,\nboth, in terms of quality and runtime. Thereby, our results show that we can\nguarantee maximum end-to-end delays and also increase the flexibility of the\nnetwork while requiring only minimal user input.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u79bb\u7ebf\u7f51\u7edc\u4f18\u5316\u542f\u53d1\u5f0f\u7b97\u6cd5\u548c\u5728\u7ebf\u51c6\u5165\u63a7\u5236\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff0c\u7528\u4e8e\u65f6\u95f4\u654f\u611f\u7f51\u7edc\u4e2d\u9759\u6001\u548c\u52a8\u6001\u6d41\u91cf\u7684\u622a\u6b62\u65f6\u95f4\u4fdd\u8bc1", "motivation": "\u65f6\u95f4\u654f\u611f\u7f51\u7edc\u867d\u7136\u5f15\u5165\u4e86\u8d44\u6e90\u5206\u914d\u534f\u8bae\uff0c\u4f46\u6807\u51c6\u5c1a\u672a\u6db5\u76d6\u5206\u914d\u7b97\u6cd5\u7684\u5177\u4f53\u5b9e\u73b0\uff0c\u9700\u8981\u89e3\u51b3\u8fd0\u884c\u4e2d\u7f51\u7edc\u7684\u65b0\u6d41\u6ce8\u518c\u95ee\u9898", "method": "\u7ed3\u5408\u79bb\u7ebf\u7f51\u7edc\u4f18\u5316\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e0e\u5728\u7ebf\u51c6\u5165\u63a7\u5236\uff0c\u4f7f\u7528\u57fa\u4e8e\u4fe1\u7528\u6574\u5f62\u5668\u7f51\u7edc\u548c\u7f51\u7edc\u6f14\u7b97\u5ef6\u8fdf\u5206\u6790\u6846\u67b6", "result": "\u76f8\u6bd4\u76f4\u89c2\u7b97\u6cd5\u548c\u66b4\u529b\u7b97\u6cd5\uff0c\u5728\u8d28\u91cf\u548c\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u80fd\u591f\u4fdd\u8bc1\u6700\u5927\u7aef\u5230\u7aef\u5ef6\u8fdf", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u4fdd\u8bc1\u6700\u5927\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u8fd8\u63d0\u9ad8\u4e86\u7f51\u7edc\u7075\u6d3b\u6027\uff0c\u540c\u65f6\u53ea\u9700\u8981\u6700\u5c11\u7684\u7528\u6237\u8f93\u5165"}}
{"id": "2508.18728", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18728", "abs": "https://arxiv.org/abs/2508.18728", "authors": ["Lei Xie", "Fan Liu", "Shenghui Song", "Shi Jin"], "title": "Bistatic Target Detection by Exploiting Both Deterministic Pilots and Unknown Random Data Payloads", "comment": "Integrated sensing and communications, Target detection, Random\n  signals, False alarm probability, Detection Probability", "summary": "Integrated sensing and communication (ISAC) plays a crucial role in 6G, to\nenable innovative applications such as drone surveillance, urban air mobility,\nand low-altitude logistics. However, the hybrid ISAC signal, which comprises\ndeterministic pilot and random data payload components, poses challenges for\ntarget detection due to two reasons: 1) these two components cause coupled\nshifts in both the mean and variance of the received signal, and 2) the random\ndata payloads are typically unknown to the sensing receiver in the bistatic\nsetting. Unfortunately, these challenges could not be tackled by existing\ntarget detection algorithms. In this paper, a generalized likelihood ratio test\n(GLRT)-based detector is derived, by leveraging the known deterministic pilots\nand the statistical characteristics of the unknown random data payloads. Due to\nthe analytical intractability of exact performance characterization, we perform\nan asymptotic analysis for the false alarm probability and detection\nprobability of the proposed detector. The results highlight a critical\ntrade-off: both deterministic and random components improve detection\nreliability, but the latter also brings statistical uncertainty that hinders\ndetection performance. Simulations validate the theoretical findings and\ndemonstrate the effectiveness of the proposed detector, which highlights the\nnecessity of designing a dedicated detector to fully exploited the signaling\nresources assigned to random data payloads.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u68c0\u6d4b\u6bd4(GLR)\u7684\u68c0\u6d4b\u5668\uff0c\u7528\u4e8e\u89e3\u51b36G\u4e2d\u611f\u77e5\u4e0e\u901a\u4fe1\u96c6\u6210(ISAC)\u7cfb\u7edf\u4e2d\u6df7\u5408\u4fe1\u53f7\u7684\u76ee\u6807\u68c0\u6d4b\u6311\u6218", "motivation": "\u6df7\u5408ISAC\u4fe1\u53f7\u5305\u542b\u786e\u5b9a\u6027\u5bfc\u9891\u548c\u968f\u673a\u6570\u636e\u8d1f\u8f7d\uff0c\u5728\u53cc\u57fa\u7ad9\u8bbe\u7f6e\u4e2d\u968f\u673a\u6570\u636e\u672a\u77e5\uff0c\u5bfc\u81f4\u63a5\u6536\u4fe1\u53f7\u7684\u5747\u503c\u548c\u65b9\u5dee\u8026\u5408\u504f\u79fb\uff0c\u73b0\u6709\u68c0\u6d4b\u7b97\u6cd5\u65e0\u6cd5\u5904\u7406", "method": "\u5229\u7528\u5df2\u77e5\u786e\u5b9a\u6027\u5bfc\u9891\u548c\u672a\u77e5\u968f\u673a\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u63a8\u5bfc\u51faGLRT\u57fa\u7840\u7684\u68c0\u6d4b\u5668\uff0c\u5e76\u8fdb\u884c\u8d8b\u8fd1\u6027\u80fd\u5206\u6790", "result": "\u7edf\u8ba1\u5206\u6790\u663e\u793a\u4e86\u5173\u952e\u7684\u8d34\u6362\u5173\u7cfb\uff1a\u786e\u5b9a\u6027\u548c\u968f\u673a\u90e8\u5206\u90fd\u80fd\u63d0\u9ad8\u68c0\u6d4b\u53ef\u9760\u6027\uff0c\u4f46\u968f\u673a\u90e8\u5206\u4e5f\u5e26\u6765\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u5f71\u54cd\u6027\u80fd", "conclusion": "\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u63d0\u51fa\u68c0\u6d4b\u5668\u7684\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86\u4e3a\u5145\u5206\u5229\u7528\u5206\u914d\u7ed9\u968f\u673a\u6570\u636e\u8d1f\u8f7d\u7684\u4fe1\u9053\u8d44\u6e90\u800c\u8bbe\u8ba1\u4e13\u7528\u68c0\u6d4b\u5668\u7684\u5fc5\u8981\u6027"}}
{"id": "2508.18467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18467", "abs": "https://arxiv.org/abs/2508.18467", "authors": ["Olivia Long", "Carter Teplica"], "title": "The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game", "comment": null, "summary": "As AI agents become increasingly capable of tool use and long-horizon tasks,\nthey have begun to be deployed in settings where multiple agents can interact.\nHowever, whereas prior work has mostly focused on human-AI interactions, there\nis an increasing need to understand AI-AI interactions. In this paper, we adapt\nthe iterated public goods game, a classic behavioral economics game, to analyze\nthe behavior of four reasoning and non-reasoning models across two conditions:\nmodels are either told they are playing against \"another AI agent\" or told\ntheir opponents are themselves. We find that, across different settings,\ntelling LLMs that they are playing against themselves significantly changes\ntheir tendency to cooperate. While our study is conducted in a toy environment,\nour results may provide insights into multi-agent settings where agents\n\"unconsciously\" discriminating against each other could inexplicably increase\nor decrease cooperation.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6539\u7f16\u516c\u5171\u7269\u54c1\u535a\u5f08\u6e38\u620f\uff0c\u7814\u7a76\u4e0d\u540cAI\u6a21\u578b\u5728\u88ab\u544a\u77e5\u5bf9\u624b\u662f\"\u5176\u4ed6AI\u4ee3\u7406\"\u6216\"\u81ea\u5df1\"\u65f6\u7684\u5408\u4f5c\u884c\u4e3a\u5dee\u5f02\uff0c\u53d1\u73b0\u81ea\u6211\u8ba4\u77e5\u663e\u8457\u5f71\u54cdLLM\u7684\u5408\u4f5c\u503e\u5411\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u5de5\u5177\u4f7f\u7528\u548c\u957f\u65f6\u7a0b\u4efb\u52a1\u80fd\u529b\u7684\u63d0\u5347\uff0c\u591a\u4ee3\u7406\u4ea4\u4e92\u573a\u666f\u65e5\u76ca\u589e\u591a\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4eba\u673a\u4ea4\u4e92\uff0c\u4f46\u9700\u8981\u6df1\u5165\u7406\u89e3AI-AI\u4ea4\u4e92\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u8ba4\u77e5\u6761\u4ef6\u4e0b\u7684\u5408\u4f5c\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u516c\u5171\u7269\u54c1\u535a\u5f08\u8fd9\u4e00\u7ecf\u5178\u884c\u4e3a\u7ecf\u6d4e\u5b66\u6e38\u620f\uff0c\u6d4b\u8bd5\u56db\u79cd\u63a8\u7406\u548c\u975e\u63a8\u7406\u6a21\u578b\u5728\u4e24\u79cd\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\uff1a\u88ab\u544a\u77e5\u5bf9\u624b\u662f\"\u5176\u4ed6AI\u4ee3\u7406\"\u6216\u88ab\u544a\u77e5\u5bf9\u624b\u662f\"\u81ea\u5df1\"\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\uff0c\u544a\u8bc9LLM\u5b83\u4eec\u6b63\u5728\u4e0e\u81ea\u5df1\u535a\u5f08\u4f1a\u663e\u8457\u6539\u53d8\u5176\u5408\u4f5c\u503e\u5411\u3002\u6a21\u578b\u5bf9\u81ea\u6211\u8ba4\u77e5\u7684\u654f\u611f\u6027\u53ef\u80fd\u5bfc\u81f4\u5408\u4f5c\u6c34\u5e73\u51fa\u73b0\u65e0\u6cd5\u89e3\u91ca\u7684\u589e\u52a0\u6216\u51cf\u5c11\u3002", "conclusion": "\u5c3d\u7ba1\u5728\u7b80\u5316\u73af\u5883\u4e2d\u8fdb\u884c\uff0c\u4f46\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ee3\u7406\u53ef\u80fd\"\u65e0\u610f\u8bc6\"\u5730\u76f8\u4e92\u6b67\u89c6\uff0c\u4ece\u800c\u610f\u5916\u5f71\u54cd\u5408\u4f5c\u6c34\u5e73\uff0c\u4e3a\u7406\u89e3AI-AI\u4ea4\u4e92\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2508.18902", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.18902", "abs": "https://arxiv.org/abs/2508.18902", "authors": ["Daniel Lindenschmitt", "Paul Seehofer", "Marius Schmitz", "Jan Mertes", "Roland Bless", "Martina Zitterbart", "Jan C. Aurich", "Hans D. Schotten"], "title": "Adaptive 6G Networks-in-Network Management for Industrial Applications", "comment": "2 figures", "summary": "This paper presents the application of Dynamic Spectrum Management (DSM) for\nfuture 6G industrial networks, establishing an efficient controller for the\nNetworks-in-Network (NiN) concept. The proposed architecture integrates nomadic\nas well as static sub-networks (SNs with diverse Quality of Service (QoS)\nrequirements within the coverage area of an overlayer network, managed by a\ncentralized spectrum manager (SM). Control plane connectivity between the SNs\nand the DSM is ensured by the self-organizing KIRA routing protocol. The\ndemonstrated system enables scalable, zero-touch connectivity and supports\nnomadic SNs through seamless discovery and reconfiguration. SNs are implemented\nfor modular Industrial Internet of Things (IIoT) scenarios, as well as for\nmission-critical control loops and for logistics or nomadic behavior. The DSM\nframework dynamically adapts spectrum allocation to meet real-time demands\nwhile ensuring reliable operation. The demonstration highlights the potential\nof DSM and NiNs to support flexible, dense, and heterogeneous wireless\ndeployments in reconfigurable manufacturing environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e6G\u5de5\u4e1a\u7f51\u7edc\u7684\u52a8\u6001\u9891\u8c31\u7ba1\u7406(DSM)\u67b6\u6784\uff0c\u901a\u8fc7Networks-in-Network(NiN)\u6982\u5ff5\u5b9e\u73b0\u9ad8\u6548\u9891\u8c31\u63a7\u5236\uff0c\u652f\u6301\u9759\u6001\u548c\u79fb\u52a8\u5b50\u7f51\u7edc\u7684\u96f6\u63a5\u89e6\u8fde\u63a5\u3002", "motivation": "\u4e3a\u6ee1\u8db3\u672a\u67656G\u5de5\u4e1a\u7f51\u7edc\u4e2d\u5f02\u6784\u5b50\u7f51\u7edc\u7684\u4e0d\u540c\u670d\u52a1\u8d28\u91cf\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u7ba1\u7406\u9891\u8c31\u5206\u914d\u5e76\u652f\u6301\u79fb\u52a8\u5b50\u7f51\u7edc\u7684\u96c6\u4e2d\u5f0f\u7ba1\u7406\u67b6\u6784\u3002", "method": "\u91c7\u7528\u96c6\u4e2d\u5f0f\u9891\u8c31\u7ba1\u7406\u5668(SM)\u548c\u81ea\u7ec4\u7ec7KIRA\u8def\u7531\u534f\u8bae\uff0c\u6784\u5efaNiN\u67b6\u6784\u6765\u96c6\u6210\u9759\u6001\u548c\u79fb\u52a8\u5b50\u7f51\u7edc\uff0c\u5b9e\u73b0\u52a8\u6001\u9891\u8c31\u5206\u914d\u548c\u81ea\u52a8\u53d1\u73b0\u91cd\u914d\u7f6e\u3002", "result": "\u7cfb\u7edf\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u7684\u96f6\u63a5\u89e6\u8fde\u63a5\u80fd\u529b\uff0c\u652f\u6301\u6a21\u5757\u5316\u5de5\u4e1a\u7269\u8054\u7f51\u573a\u666f\u3001\u5173\u952e\u4efb\u52a1\u63a7\u5236\u56de\u8def\u4ee5\u53ca\u7269\u6d41\u548c\u79fb\u52a8\u5e94\u7528\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u5b9e\u65f6\u9700\u6c42\u3002", "conclusion": "DSM\u548cNiN\u6846\u67b6\u5728\u53ef\u91cd\u6784\u5236\u9020\u73af\u5883\u4e2d\u5177\u6709\u652f\u6301\u7075\u6d3b\u3001\u5bc6\u96c6\u548c\u5f02\u6784\u65e0\u7ebf\u90e8\u7f72\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2508.18755", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18755", "abs": "https://arxiv.org/abs/2508.18755", "authors": ["Seungmin Lee", "Changmin Lee", "Si-Chan Noh", "Joonsoo Lee"], "title": "Performance Analysis of IEEE 802.11bn with Coordinated TDMA on Real-Time Applications", "comment": "Accepted by IEEE Global Communications Conference (GLOBECOM) 2025", "summary": "Wi-Fi plays a crucial role in connecting electronic devices and providing\ncommunication services in everyday life. Recently, there has been a growing\ndemand for services that require low-latency communication, such as real-time\napplications. The latest amendments to Wi-Fi, IEEE 802.11bn, are being\ndeveloped to address these demands with technologies such as the multiple\naccess point coordination (MAPC). In this paper, we demonstrate that\ncoordinated TDMA (Co-TDMA), one of the MAPC techniques, effectively reduces the\nlatency of transmitting time-sensitive traffic. In particular, we focus on\nworst-case latency and jitter, which are key metrics for evaluating the\nperformance of real-time applications. We first introduce a Co-TDMA scheduling\nstrategy. We then investigate how this scheduling strategy impacts latency\nunder varying levels of network congestion and traffic volume characteristics.\nFinally, we validate our findings through system-level simulations. Our\nsimulation results demonstrate that Co-TDMA effectively mitigates jitter and\nworst-case latency for LL traffic, with the latter exhibiting an improvement of\napproximately 24%.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Wi-Fi 802.11bn\u6807\u51c6\u4e2d\u7684\u534f\u8c03TDMA\u6280\u672f\uff0c\u8bc1\u660e\u5176\u80fd\u6709\u6548\u964d\u4f4e\u5b9e\u65f6\u5e94\u7528\u7684\u6700\u574f\u60c5\u51b5\u5ef6\u8fdf\u7ea624%\u5e76\u51cf\u5c11\u6296\u52a8", "motivation": "\u968f\u7740\u5b9e\u65f6\u5e94\u7528\u5bf9\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u9700\u6c42\u7684\u589e\u957f\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u6280\u672f\u6765\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\uff0c\u7279\u522b\u662f\u9488\u5bf9\u65f6\u95f4\u654f\u611f\u6d41\u91cf\u7684\u4f20\u8f93", "method": "\u63d0\u51fa\u534f\u8c03TDMA\u8c03\u5ea6\u7b56\u7565\uff0c\u901a\u8fc7\u7cfb\u7edf\u7ea7\u4eff\u771f\u5206\u6790\u4e0d\u540c\u7f51\u7edc\u62e5\u585e\u7a0b\u5ea6\u548c\u6d41\u91cf\u7279\u5f81\u4e0b\u7684\u5ef6\u8fdf\u8868\u73b0", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u534f\u8c03TDMA\u80fd\u6709\u6548\u7f13\u89e3LL\u6d41\u91cf\u7684\u6296\u52a8\u548c\u6700\u574f\u60c5\u51b5\u5ef6\u8fdf\uff0c\u540e\u8005\u6539\u5584\u7ea624%", "conclusion": "\u534f\u8c03TDMA\u4f5c\u4e3a\u591a\u63a5\u5165\u70b9\u534f\u8c03\u6280\u672f\u4e4b\u4e00\uff0c\u5728Wi-Fi\u7f51\u7edc\u4e2d\u80fd\u663e\u8457\u63d0\u5347\u5b9e\u65f6\u5e94\u7528\u7684\u6027\u80fd\u8868\u73b0"}}
{"id": "2508.18507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18507", "abs": "https://arxiv.org/abs/2508.18507", "authors": ["Dillon Z. Chen", "Johannes Zenn", "Tristan Cinquin", "Sheila A. McIlraith"], "title": "Language Models For Generalised PDDL Planning: Synthesising Sound and Programmatic Policies", "comment": "RLC 2025 Workshop on Programmatic Reinforcement Learning", "summary": "We study the usage of language models (LMs) for planning over world models\nspecified in the Planning Domain Definition Language (PDDL). We prompt LMs to\ngenerate Python programs that serve as generalised policies for solving PDDL\nproblems from a given domain. Notably, our approach synthesises policies that\nare provably sound relative to the PDDL domain without reliance on external\nverifiers. We conduct experiments on competition benchmarks which show that our\npolicies can solve more PDDL problems than PDDL planners and recent LM\napproaches within a fixed time and memory constraint. Our approach manifests in\nthe LMPlan planner which can solve planning problems with several hundreds of\nrelevant objects. Surprisingly, we observe that LMs used in our framework\nsometimes plan more effectively over PDDL problems written in meaningless\nsymbols in place of natural language; e.g. rewriting (at dog kitchen) as (p2 o1\no3). This finding challenges hypotheses that LMs reason over word semantics and\nmemorise solutions from its training corpus, and is worth further exploration.", "AI": {"tldr": "\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210Python\u7a0b\u5e8f\u4f5c\u4e3a\u5e7f\u4e49\u7b56\u7565\uff0c\u89e3\u51b3PDDL\u89c4\u5212\u95ee\u9898\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\u5373\u53ef\u4fdd\u8bc1\u7b56\u7565\u7684\u6b63\u786e\u6027\uff0c\u5728\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u89c4\u5212\u5668\u548c\u73b0\u6709LM\u65b9\u6cd5", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728PDDL\u4e16\u754c\u6a21\u578b\u89c4\u5212\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u7d22LM\u662f\u5426\u80fd\u591f\u751f\u6210\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u89c4\u5212\u7b56\u7565\uff0c\u6311\u6218\u5173\u4e8eLM\u4f9d\u8d56\u8bed\u4e49\u8bb0\u5fc6\u548c\u8bad\u7ec3\u6570\u636e\u89e3\u51b3\u65b9\u6848\u7684\u5047\u8bbe", "method": "\u901a\u8fc7\u63d0\u793a\u8bed\u8a00\u6a21\u578b\u751f\u6210Python\u7a0b\u5e8f\u4f5c\u4e3a\u5e7f\u4e49\u7b56\u7565\u6765\u89e3\u51b3\u7279\u5b9aPDDL\u57df\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u7b56\u7565\u76f8\u5bf9\u4e8ePDDL\u57df\u662f\u53ef\u8bc1\u660e\u6b63\u786e\u7684\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668", "result": "\u5728\u56fa\u5b9a\u65f6\u95f4\u548c\u5185\u5b58\u7ea6\u675f\u4e0b\uff0c\u8be5\u65b9\u6cd5\u6bd4PDDL\u89c4\u5212\u5668\u548c\u6700\u8fd1\u7684LM\u65b9\u6cd5\u80fd\u89e3\u51b3\u66f4\u591aPDDL\u95ee\u9898\uff0cLMPlan\u89c4\u5212\u5668\u53ef\u4ee5\u5904\u7406\u5305\u542b\u6570\u767e\u4e2a\u76f8\u5173\u5bf9\u8c61\u7684\u89c4\u5212\u95ee\u9898", "conclusion": "LM\u6709\u65f6\u5728\u65e0\u610f\u4e49\u7b26\u53f7\u8868\u793a\u7684PDDL\u95ee\u9898\u4e0a\u89c4\u5212\u66f4\u6709\u6548\uff0c\u8fd9\u6311\u6218\u4e86LM\u57fa\u4e8e\u8bed\u4e49\u63a8\u7406\u548c\u8bad\u7ec3\u8bed\u6599\u8bb0\u5fc6\u7684\u5047\u8bbe\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22"}}
{"id": "2508.19067", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.19067", "abs": "https://arxiv.org/abs/2508.19067", "authors": ["Aiden Valentine", "George Parisis"], "title": "LeoTCP: Low-Latency and High-Throughput Data Transport for LEO Satellite Networks", "comment": "10 pages, 10 figures", "summary": "Low-Earth Orbit (LEO) satellite networks consist of thousands of satellites\norbiting the Earth, enabling low-latency and high-throughput communications\nacross the globe. Such networks present unprecedented challenges due to their\ndynamic nature, which state-of-the-art data transport protocols do not address.\nThese challenges include: (1) non-congestive latency variation and loss, caused\nby continuous satellite movement and fluctuating link quality due to weather\neffects; (2) transient hotspots leading to buffer build-up, latency inflation,\nand potential packet loss; and (3) frequent handovers, which may result in\ntemporary connectivity loss and re-routing through paths with unknown\ncongestion and delay characteristics. In this paper, we introduce LeoTCP, a\nnovel data transport protocol designed specifically to address these\nchallenges. LeoTCP leverages in-network telemetry (INT) to gather congestion\ninformation on a per-hop basis. Using this information, LeoTCP (1) minimises\nboth buffer occupancy and latency for end users, (2) maximises application\nthroughput and network utilisation, and (3) swiftly reacts to network hotspots.\nWe compare LeoTCP to state-of-the-art data transport protocols using a LEO\nsatellite simulation model and targeted micro-benchmarks, both based on\nOMNeT++/INET. The simulation model captures RTT dynamics in a simulated LEO\nsatellite constellation, while the micro-benchmarks isolate key LEO-specific\ncharacteristics, including non-congestive latency variation and loss, path\nchanges, and congestion hotspots. Our results demonstrate that LeoTCP\nsignificantly increases goodput compared to existing state-of-the-art\napproaches, while simultaneously minimising latency.", "AI": {"tldr": "LeoTCP\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7f51\u7edc\u8bbe\u8ba1\u7684\u65b0\u578b\u6570\u636e\u4f20\u8f93\u534f\u8bae\uff0c\u901a\u8fc7\u5229\u7528\u7f51\u7edc\u5185\u9065\u6d4b\u6280\u672f\u89e3\u51b3LEO\u7f51\u7edc\u7279\u6709\u7684\u52a8\u6001\u6027\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7f51\u7edc\u5177\u6709\u52a8\u6001\u7279\u6027\uff0c\u73b0\u6709\u6570\u636e\u4f20\u8f93\u534f\u8bae\u65e0\u6cd5\u6709\u6548\u5904\u7406\u975e\u62e5\u585e\u6027\u5ef6\u8fdf\u53d8\u5316\u3001\u77ac\u65f6\u70ed\u70b9\u548c\u9891\u7e41\u5207\u6362\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u534f\u8bae\u6765\u4f18\u5316\u6027\u80fd\u3002", "method": "LeoTCP\u5229\u7528\u7f51\u7edc\u5185\u9065\u6d4b\u6280\u672f\u6536\u96c6\u9010\u8df3\u62e5\u585e\u4fe1\u606f\uff0c\u901a\u8fc7\u8be5\u4fe1\u606f\u6700\u5c0f\u5316\u7f13\u51b2\u533a\u5360\u7528\u548c\u5ef6\u8fdf\uff0c\u6700\u5927\u5316\u5e94\u7528\u541e\u5410\u91cf\u548c\u7f51\u7edc\u5229\u7528\u7387\uff0c\u5e76\u5feb\u901f\u54cd\u5e94\u7f51\u7edc\u70ed\u70b9\u3002", "result": "\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u534f\u8bae\u76f8\u6bd4\uff0cLeoTCP\u5728\u6a21\u62dfLEO\u536b\u661f\u7f51\u7edc\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u4e86\u5ef6\u8fdf\u3002", "conclusion": "LeoTCP\u662f\u9488\u5bf9LEO\u536b\u661f\u7f51\u7edc\u52a8\u6001\u7279\u6027\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u7f51\u7edc\u6027\u80fd\uff0c\u4e3a\u536b\u661f\u901a\u4fe1\u63d0\u4f9b\u66f4\u597d\u7684\u6570\u636e\u4f20\u8f93\u4f53\u9a8c\u3002"}}
{"id": "2508.18845", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.18845", "abs": "https://arxiv.org/abs/2508.18845", "authors": ["Yang Li", "Zhenliang Lu", "San Ling", "Shixin Zhu", "Kwok Yan Lam"], "title": "On decoding extended Han-Zhang codes", "comment": "An extension of part of the results in arXiv:2401.04360v2", "summary": "Extended Han-Zhang codes are a class of linear codes where each code is\neither a non-generalized Reed-Solomon (non-GRS) maximum distance separable\n(MDS) code or a near MDS (NMDS) code. They have important applications in\ncommunication, cryptography, and storage systems. While many algebraic\nproperties and explicit constructions of extended Han-Zhang codes have been\nwell studied in the literature, their decoding has been unexplored. In this\npaper, we focus on their decoding problems in terms of $\\ell$-error-correcting\npairs ($\\ell$-ECPs) and deep holes. On the one hand, we determine the existence\nand specific forms of their $\\ell$-ECPs, and further present an explicit\ndecoding algorithm for extended Han-Zhang codes based on these $\\ell$-ECPs,\nwhich can correct up to $\\ell$ errors in polynomial time, with $\\ell$ about\nhalf of the minimum distance. On the other hand, we determine the covering\nradius of extended Han-Zhang codes and characterize two classes of their deep\nholes, which are closely related to the maximum-likelihood decoding method. By\nemploying these deep holes, we also construct more non-GRS MDS codes with\nlarger lengths and dimensions, and discuss the monomial equivalence between\nthem and the well-known Roth-Lempel codes. Some concrete examples are also\ngiven to support these results.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6269\u5c55Han-Zhang\u7801\u7684\u89e3\u7801\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u2113-\u9519\u8bef\u6821\u6b63\u5bf9(\u2113-ECPs)\u7684\u663e\u5f0f\u89e3\u7801\u7b97\u6cd5\uff0c\u5e76\u786e\u5b9a\u4e86\u5176\u8986\u76d6\u534a\u5f84\u548c\u6df1\u5b54\u7279\u6027\uff0c\u540c\u65f6\u6784\u9020\u4e86\u66f4\u591a\u975eGRS MDS\u7801\u3002", "motivation": "\u6269\u5c55Han-Zhang\u7801\u5728\u901a\u4fe1\u3001\u5bc6\u7801\u5b66\u548c\u5b58\u50a8\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\uff0c\u867d\u7136\u5176\u4ee3\u6570\u6027\u8d28\u548c\u6784\u9020\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u89e3\u7801\u95ee\u9898\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u786e\u5b9a\u2113-ECPs\u7684\u5b58\u5728\u6027\u548c\u5177\u4f53\u5f62\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8e\u2113-ECPs\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u89e3\u7801\u7b97\u6cd5\uff1b\u540c\u65f6\u786e\u5b9a\u8986\u76d6\u534a\u5f84\u5e76\u8868\u5f81\u6df1\u5b54\u7c7b\u522b\uff0c\u7528\u4e8e\u6784\u9020\u66f4\u591a\u975eGRS MDS\u7801\u3002", "result": "\u5f00\u53d1\u4e86\u53ef\u7ea0\u6b63\u7ea6\u4e00\u534a\u6700\u5c0f\u8ddd\u79bb\u9519\u8bef\u7684\u89e3\u7801\u7b97\u6cd5\uff1b\u786e\u5b9a\u4e86\u8986\u76d6\u534a\u5f84\uff1b\u6784\u9020\u4e86\u66f4\u5927\u957f\u5ea6\u548c\u7ef4\u5ea6\u7684\u975eGRS MDS\u7801\uff1b\u8ba8\u8bba\u4e86\u4e0eRoth-Lempel\u7801\u7684\u5355\u9879\u5f0f\u7b49\u4ef7\u6027\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86\u6269\u5c55Han-Zhang\u7801\u7684\u89e3\u7801\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u7801\u7b97\u6cd5\u548c\u6df1\u5b54\u5206\u6790\uff0c\u6269\u5c55\u4e86\u975eGRS MDS\u7801\u7684\u6784\u9020\u65b9\u6cd5\u3002"}}
{"id": "2508.18515", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18515", "abs": "https://arxiv.org/abs/2508.18515", "authors": ["Dillon Z. Chen"], "title": "Weisfeiler-Leman Features for Planning: A 1,000,000 Sample Size Hyperparameter Study", "comment": "Extended version of ECAI 2025 paper", "summary": "Weisfeiler-Leman Features (WLFs) are a recently introduced classical machine\nlearning tool for learning to plan and search. They have been shown to be both\ntheoretically and empirically superior to existing deep learning approaches for\nlearning value functions for search in symbolic planning. In this paper, we\nintroduce new WLF hyperparameters and study their various tradeoffs and\neffects. We utilise the efficiency of WLFs and run planning experiments on\nsingle core CPUs with a sample size of 1,000,000 to understand the effect of\nhyperparameters on training and planning. Our experimental analysis show that\nthere is a robust and best set of hyperparameters for WLFs across the tested\nplanning domains. We find that the best WLF hyperparameters for learning\nheuristic functions minimise execution time rather than maximise model\nexpressivity. We further statistically analyse and observe no significant\ncorrelation between training and planning metrics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Weisfeiler-Leman\u7279\u5f81(WLFs)\u7684\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u53d1\u73b0\u5b58\u5728\u4e00\u7ec4\u8de8\u9886\u57df\u6700\u4f18\u7684\u8d85\u53c2\u6570\u8bbe\u7f6e\uff0c\u5176\u76ee\u6807\u662f\u6700\u5927\u5316\u6267\u884c\u6548\u7387\u800c\u975e\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u4e14\u8bad\u7ec3\u6307\u6807\u4e0e\u89c4\u5212\u6027\u80fd\u65e0\u663e\u8457\u76f8\u5173\u6027\u3002", "motivation": "WLFs\u5728\u7b26\u53f7\u89c4\u5212\u7684\u4ef7\u503c\u51fd\u6570\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u4f46\u5bf9\u5176\u8d85\u53c2\u6570\u7684\u5f71\u54cd\u548c\u6700\u4f18\u914d\u7f6e\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u6df1\u5165\u5206\u6790\u8d85\u53c2\u6570\u5bf9\u8bad\u7ec3\u548c\u89c4\u5212\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5229\u7528WLFs\u7684\u9ad8\u6548\u6027\uff0c\u5728\u5355\u6838CPU\u4e0a\u8fdb\u884c\u4e86100\u4e07\u6837\u672c\u7684\u5927\u89c4\u6a21\u89c4\u5212\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u4e0d\u540c\u8d85\u53c2\u6570\u7ec4\u5408\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u6765\u7406\u89e3\u8d85\u53c2\u6570\u5bf9\u8bad\u7ec3\u548c\u89c4\u5212\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u4e00\u7ec4\u8de8\u89c4\u5212\u9886\u57df\u7684\u6700\u4f18\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u6700\u4f73WLF\u8d85\u53c2\u6570\u65e8\u5728\u6700\u5c0f\u5316\u6267\u884c\u65f6\u95f4\u800c\u975e\u6700\u5927\u5316\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u8bad\u7ec3\u6307\u6807\u4e0e\u89c4\u5212\u6027\u80fd\u4e4b\u95f4\u65e0\u663e\u8457\u7edf\u8ba1\u76f8\u5173\u6027\u3002", "conclusion": "WLFs\u7684\u8d85\u53c2\u6570\u4f18\u5316\u5e94\u5173\u6ce8\u6267\u884c\u6548\u7387\u800c\u975e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u8bad\u7ec3\u6027\u80fd\u4e0d\u80fd\u76f4\u63a5\u9884\u6d4b\u89c4\u5212\u6548\u679c\uff0c\u8fd9\u4e3aWLFs\u5728\u5b9e\u9645\u89c4\u5212\u5e94\u7528\u4e2d\u7684\u53c2\u6570\u8c03\u4f18\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2508.19130", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.19130", "abs": "https://arxiv.org/abs/2508.19130", "authors": ["Laura Finarelli", "Maoquan Ni", "Michela Meo", "Falko Dressler", "Gianluca Rizzo"], "title": "Sharing is Caring: Analysis of Hybrid Network Sharing Strategies for Energy Efficient Multi-Operator Cellular Systems", "comment": null, "summary": "This paper introduces a novel analytical framework for evaluating\nenergy-efficient, QoS-aware network-sharing strategies in cellular networks.\nLeveraging stochastic geometry, our framework enables the systematic assessment\nof network performance across a range of sharing paradigms, including both\nconventional single-operator scenarios and advanced hybrid strategies that\nenable full integration and cooperation among multiple mobile network\noperators. Our framework incorporates diverse user densities, rate\nrequirements, and energy consumption models to ensure comprehensive analysis.\nApplying our results to real-world datasets from French mobile network\noperators, we demonstrate that hybrid network sharing can yield substantial\nenergy savings, up to $35\\%$, while maintaining quality of service.\nFurthermore, our results allow us to characterizing how the benefits of network\nsharing vary as a function of the geographical and functional characteristics\nof the deployment area. These findings highlight the potential of collaborative\nsharing strategies to enhance operational efficiency and sustainability in\nnext-generation cellular networks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7ec6\u80de\u7f51\u7edc\u4e2d\u7684\u80fd\u6e90\u6548\u7387\u4f18\u5316\u548cQoS\u611f\u77e5\u7f51\u7edc\u5171\u4eab\u7b56\u7565\uff0c\u901a\u8fc7\u6cd5\u56fd\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u53d1\u73b0\u6df7\u5408\u5171\u4eab\u7b56\u7565\u53ef\u8282\u7701\u8fbe35%\u7684\u80fd\u6d88\u8017\u3002", "motivation": "\u4e3a\u4e86\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e0d\u540c\u7f51\u7edc\u5171\u4eab\u7b56\u7565\u5728\u7ec6\u80de\u7f51\u7edc\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u80fd\u6e90\u6548\u7387\u548c\u8d28\u91cf\u670d\u52a1\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4ee5\u652f\u6301\u4e0b\u4e00\u4ee3\u7f51\u7edc\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "method": "\u5229\u7528\u968f\u673a\u51e0\u4f55\u5b66\u5efa\u7acb\u5206\u6790\u6846\u67b6\uff0c\u5305\u542b\u591a\u6837\u5316\u7684\u7528\u6237\u5bc6\u5ea6\u3001\u901f\u7387\u9700\u6c42\u548c\u80fd\u6d88\u8017\u6a21\u578b\uff0c\u5bf9\u5355\u8fd0\u8425\u5546\u548c\u591a\u8fd0\u8425\u5546\u6df7\u5408\u5171\u4eab\u7b56\u7565\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e76\u5728\u6cd5\u56fd\u5b9e\u9645\u7f51\u7edc\u6570\u636e\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6df7\u5408\u7f51\u7edc\u5171\u4eab\u7b56\u7565\u80fd\u591f\u5b9e\u73b0\u8f83\u5927\u7684\u80fd\u6e90\u8282\u7701\uff08\u6700\u9ad8\u8fbe35%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u670d\u52a1\u8d28\u91cf\u3002\u5171\u4eab\u6548\u76ca\u4f1a\u968f\u90e8\u7f72\u533a\u57df\u7684\u5730\u7406\u548c\u529f\u80fd\u7279\u5f81\u800c\u53d8\u5316\u3002", "conclusion": "\u534f\u4f5c\u6027\u7f51\u7edc\u5171\u4eab\u7b56\u7565\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u53ef\u4ee5\u6602\u663e\u63d0\u5347\u4e0b\u4e00\u4ee3\u7ec6\u80de\u7f51\u7edc\u7684\u8fd0\u8425\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\uff0c\u4e3a\u7f51\u7edc\u8fd0\u8425\u5546\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u64cd\u4f5c\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2508.18520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18520", "abs": "https://arxiv.org/abs/2508.18520", "authors": ["Dillon Z. Chen"], "title": "Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features", "comment": "HSDIP@ICAPS 2025 Workshop", "summary": "Novelty heuristics aid heuristic search by exploring states that exhibit\nnovel atoms. However, novelty heuristics are not symmetry invariant and hence\nmay sometimes lead to redundant exploration. In this preliminary report, we\npropose to use Weisfeiler-Leman Features for planning (WLFs) in place of atoms\nfor detecting novelty. WLFs are recently introduced features for learning\ndomain-dependent heuristics for generalised planning problems. We explore an\nunsupervised usage of WLFs for synthesising lifted, domain-independent novelty\nheuristics that are invariant to symmetric states. Experiments on the classical\nInternational Planning Competition and Hard To Ground benchmark suites yield\npromising results for novelty heuristics synthesised from WLFs.", "AI": {"tldr": "\u4f7f\u7528Weisfeiler-Leman\u7279\u5f81\u66ff\u4ee3\u539f\u5b50\u7279\u5f81\u6765\u6784\u5efa\u5bf9\u79f0\u4e0d\u53d8\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\uff0c\u89e3\u51b3\u4f20\u7edf\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u56e0\u5bf9\u79f0\u72b6\u6001\u5bfc\u81f4\u7684\u5197\u4f59\u63a2\u7d22\u95ee\u9898", "motivation": "\u4f20\u7edf\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u57fa\u4e8e\u539f\u5b50\u7279\u5f81\uff0c\u4e0d\u5177\u6709\u5bf9\u79f0\u4e0d\u53d8\u6027\uff0c\u4f1a\u5bfc\u81f4\u5bf9\u5bf9\u79f0\u72b6\u6001\u7684\u5197\u4f59\u63a2\u7d22\uff0c\u5f71\u54cd\u641c\u7d22\u6548\u7387", "method": "\u91c7\u7528Weisfeiler-Leman\u7279\u5f81\uff08WLFs\uff09\u6765\u68c0\u6d4b\u65b0\u9896\u6027\uff0c\u8fd9\u4e9b\u7279\u5f81\u6700\u8fd1\u88ab\u5f15\u5165\u7528\u4e8e\u5b66\u4e60\u5e7f\u4e49\u89c4\u5212\u95ee\u9898\u7684\u9886\u57df\u76f8\u5173\u542f\u53d1\u5f0f\uff0c\u672c\u6587\u63a2\u7d22\u5176\u5728\u65e0\u76d1\u7763\u65b9\u5f0f\u4e0b\u5408\u6210\u63d0\u5347\u7684\u3001\u9886\u57df\u65e0\u5173\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f", "result": "\u5728\u56fd\u9645\u89c4\u5212\u7ade\u8d5b\u548cHard To Ground\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8eWLFs\u5408\u6210\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c", "conclusion": "WLFs\u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8e\u6784\u5efa\u5bf9\u79f0\u4e0d\u53d8\u7684\u65b0\u9896\u6027\u542f\u53d1\u5f0f\uff0c\u6539\u5584\u542f\u53d1\u5f0f\u641c\u7d22\u7684\u6027\u80fd\uff0c\u907f\u514d\u5bf9\u5bf9\u79f0\u72b6\u6001\u7684\u5197\u4f59\u63a2\u7d22"}}
{"id": "2508.19141", "categories": ["cs.NI", "math.OC", "94A05, 68M12", "C.2.1; G.3; H.1.1"], "pdf": "https://arxiv.org/pdf/2508.19141", "abs": "https://arxiv.org/abs/2508.19141", "authors": ["Federico Chiariotti", "Andrea Zanella"], "title": "A Theory of Goal-Oriented Medium Access: Protocol Design and Distributed Bandit Learning", "comment": "Submitted to IEEE INFOCOM 2026", "summary": "The Goal-oriented Communication (GoC) paradigm breaks the separation between\ncommunication and the content of the data, tailoring communication decisions to\nthe specific needs of the receiver and targeting application performance. While\nrecent studies show impressive encoding performance in point-to-point\nscenarios, the multi-node distributed scenario is still almost unexplored.\nMoreover, the few studies to investigate this consider a centralized\ncollision-free approach, where a central scheduler decides the transmission\norder of the nodes. In this work, we address the Goal-oriented Multiple Access\n(GoMA) problem, in which multiple intelligent agents must coordinate to share a\nwireless channel and avoid mutual interference. We propose a theoretical\nframework for the analysis and optimization of distributed GoMA, serving as a\nfirst step towards its complete characterization. We prove that the problem is\nnon-convex and may admit multiple Nash Equilibrium (NE) solutions. We provide a\ncharacterization of each node's best response to others' strategies and propose\nan optimization approach that provably reaches one such NE, outperforming\ncentralized approaches by up to 100% while also reducing energy consumption. We\nalso design a distributed learning algorithm that operates with limited\nfeedback and no prior knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u76ee\u6807\u7684\u591a\u5740\u63a5\u5165(GoMA)\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5728\u65e0\u7ebf\u4fe1\u9053\u5171\u4eab\u4e2d\u7684\u5206\u5e03\u5f0f\u534f\u8c03\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u95ee\u9898\u7684\u975e\u51f8\u6027\u548c\u591a\u7eb3\u4ec0\u5747\u8861\u5b58\u5728\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4f18\u5316\u7b97\u6cd5\u548c\u5206\u5e03\u5f0f\u5b66\u4e60\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u9762\u5411\u76ee\u6807\u901a\u4fe1\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u70b9\u5bf9\u70b9\u573a\u666f\uff0c\u591a\u8282\u70b9\u5206\u5e03\u5f0f\u573a\u666f\u7814\u7a76\u8f83\u5c11\u4e14\u591a\u4e3a\u96c6\u4e2d\u5f0f\u8c03\u5ea6\u65b9\u6cd5\uff0c\u9700\u8981\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5728\u65e0\u7ebf\u4fe1\u9053\u4e2d\u7684\u5206\u5e03\u5f0f\u534f\u8c03\u548c\u5e72\u6270\u907f\u514d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86GoMA\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u95ee\u9898\u7684\u975e\u51f8\u6027\u548c\u591a\u7eb3\u4ec0\u5747\u8861\u7279\u6027\uff0c\u8bbe\u8ba1\u4e86\u6700\u4f73\u54cd\u5e94\u4f18\u5316\u65b9\u6cd5\u786e\u4fdd\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u6709\u9650\u53cd\u9988\u548c\u65e0\u5148\u9a8c\u77e5\u8bc6\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u6240\u63d0\u5206\u5e03\u5f0f\u65b9\u6cd5\u6bd4\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe100%\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u80fd\u8017\uff0c\u5206\u5e03\u5f0f\u5b66\u4e60\u7b97\u6cd5\u5728\u6709\u9650\u53cd\u9988\u6761\u4ef6\u4e0b\u6709\u6548\u8fd0\u884c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u5e03\u5f0f\u9762\u5411\u76ee\u6807\u591a\u5740\u63a5\u5165\u63d0\u4f9b\u4e86\u9996\u4e2a\u7406\u8bba\u6846\u67b6\u548c\u4f18\u5316\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5206\u5e03\u5f0f\u534f\u8c03\u5728\u6027\u80fd\u548c\u80fd\u6548\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.18527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18527", "abs": "https://arxiv.org/abs/2508.18527", "authors": ["Kaijie Xu", "Clark Verbrugge"], "title": "Generic Guard AI in Stealth Game with Composite Potential Fields", "comment": null, "summary": "Guard patrol behavior is central to the immersion and strategic depth of\nstealth games, while most existing systems rely on hand-crafted routes or\nspecialized logic that struggle to balance coverage efficiency and responsive\npursuit with believable naturalness. We propose a generic, fully explainable,\ntraining-free framework that integrates global knowledge and local information\nvia Composite Potential Fields, combining three interpretable maps-Information,\nConfidence, and Connectivity-into a single kernel-filtered decision criterion.\nOur parametric, designer-driven approach requires only a handful of decay and\nweight parameters-no retraining-to smoothly adapt across both occupancy-grid\nand NavMesh-partition abstractions. We evaluate on five representative game\nmaps, two player-control policies, and five guard modes, confirming that our\nmethod outperforms classical baseline methods in both capture efficiency and\npatrol naturalness. Finally, we show how common stealth mechanics-distractions\nand environmental elements-integrate naturally into our framework as sub\nmodules, enabling rapid prototyping of rich, dynamic, and responsive guard\nbehaviors.", "AI": {"tldr": "\u901a\u8fc7\u590d\u5408\u6f5c\u529b\u573a\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u53ef\u89e3\u91ca\u7684\u6e38\u620f\u5c0f\u5175\u5de1\u903b\u884c\u4e3a\u6846\u67b6\uff0c\u5728\u8986\u76d6\u6548\u7387\u548c\u8ffd\u51fb\u54cd\u5e94\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u884c", "motivation": "\u73b0\u6709\u6f14\u523b\u6e38\u620f\u4e2d\u5c0f\u5175\u5de1\u903b\u884c\u4e3a\u591a\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u8def\u7ebf\u6216\u4e13\u95e8\u903b\u8f91\uff0c\u96be\u4ee5\u540c\u65f6\u5e73\u8861\u8986\u76d6\u6548\u7387\u3001\u54cd\u5e94\u8ffd\u51fb\u548c\u81ea\u7136\u6027", "method": "\u4f7f\u7528\u590d\u5408\u6f5c\u529b\u573a\u6846\u67b6\uff0c\u7ed3\u5408\u4fe1\u606f\u3001\u4fe1\u5fc3\u548c\u8fde\u901a\u6027\u4e09\u79cd\u53ef\u89e3\u91ca\u5730\u56fe\uff0c\u901a\u8fc7\u5185\u6838\u7b5b\u9009\u51b3\u7b56\u6807\u51c6\uff0c\u53ea\u9700\u5c11\u91cf\u8870\u51cf\u548c\u6743\u91cd\u53c2\u6570", "result": "\u57285\u4e2a\u4ee3\u8868\u6027\u6e38\u620f\u5730\u56fe\u30012\u79cd\u73a9\u5bb6\u63a7\u5236\u7b56\u7565\u548c5\u79cd\u5c0f\u5175\u6a21\u5f0f\u4e0b\u8bc4\u6d4b\uff0c\u8bc1\u660e\u5728\u6355\u6349\u6548\u7387\u548c\u5de1\u903b\u81ea\u7136\u6027\u65b9\u9762\u90fd\u8d85\u8fc7\u4f20\u7edf\u57fa\u51c6\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u81ea\u7136\u96c6\u6210\u5e38\u89c1\u6f14\u523b\u673a\u5236\uff08\u5982\u5206\u6563\u6ce8\u610f\u529b\u548c\u73af\u5883\u5143\u7d20\uff09\uff0c\u652f\u6301\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u4e30\u5bcc\u3001\u52a8\u6001\u54cd\u5e94\u7684\u5c0f\u5175\u884c\u4e3a"}}
{"id": "2508.18533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18533", "abs": "https://arxiv.org/abs/2508.18533", "authors": ["Kaijie Xu", "Clark Verbrugge"], "title": "A Database-Driven Framework for 3D Level Generation with LLMs", "comment": null, "summary": "Procedural Content Generation for 3D game levels faces challenges in\nbalancing spatial coherence, navigational functionality, and adaptable gameplay\nprogression across multi-floor environments. This paper introduces a novel\nframework for generating such levels, centered on the offline, LLM-assisted\nconstruction of reusable databases for architectural components (facilities and\nroom templates) and gameplay mechanic elements. Our multi-phase pipeline\nassembles levels by: (1) selecting and arranging instances from the Room\nDatabase to form a multi-floor global structure with an inherent topological\norder; (2) optimizing the internal layout of facilities for each room based on\npredefined constraints from the Facility Database; and (3) integrating\nprogression-based gameplay mechanics by placing components from a Mechanics\nDatabase according to their topological and spatial rules. A subsequent\ntwo-phase repair system ensures navigability. This approach combines modular,\ndatabase-driven design with constraint-based optimization, allowing for\nsystematic control over level structure and the adaptable pacing of gameplay\nelements. Initial experiments validate the framework's ability in generating\ndiverse, navigable 3D environments and its capability to simulate distinct\ngameplay pacing strategies through simple parameterization. This research\nadvances PCG by presenting a scalable, database-centric foundation for the\nautomated generation of complex 3D levels with configurable gameplay\nprogression.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u8f85\u52a9\u6784\u5efa\u53ef\u91cd\u7528\u6570\u636e\u5e93\u76843D\u6e38\u620f\u5173\u5361\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u7ec4\u88c5\u5173\u5361\uff0c\u7ed3\u5408\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u7ea6\u675f\u4f18\u5316\uff0c\u5b9e\u73b0\u53ef\u5bfc\u822a3D\u73af\u5883\u548c\u53ef\u914d\u7f6e\u6e38\u620f\u8fdb\u7a0b\u7684\u751f\u6210\u3002", "motivation": "\u89e3\u51b33D\u6e38\u620f\u5173\u5361\u751f\u6210\u4e2d\u7a7a\u95f4\u8fde\u8d2f\u6027\u3001\u5bfc\u822a\u529f\u80fd\u548c\u53ef\u9002\u5e94\u6e38\u620f\u8fdb\u7a0b\u5e73\u8861\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u591a\u5c42\u73af\u5883\u4e2d\u7684\u751f\u6210\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a1)\u4ece\u623f\u95f4\u6570\u636e\u5e93\u9009\u62e9\u548c\u6392\u5217\u5b9e\u4f8b\u5f62\u6210\u591a\u5c42\u5168\u5c40\u7ed3\u6784\uff1b2)\u57fa\u4e8e\u8bbe\u65bd\u6570\u636e\u5e93\u7ea6\u675f\u4f18\u5316\u623f\u95f4\u5185\u90e8\u5e03\u5c40\uff1b3)\u6839\u636e\u62d3\u6251\u548c\u7a7a\u95f4\u89c4\u5219\u6574\u5408\u6e38\u620f\u673a\u5236\u7ec4\u4ef6\u3002\u540e\u7eed\u91c7\u7528\u4e24\u9636\u6bb5\u4fee\u590d\u7cfb\u7edf\u786e\u4fdd\u53ef\u5bfc\u822a\u6027\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u5bfc\u822a\u76843D\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u53c2\u6570\u5316\u6a21\u62df\u4e0d\u540c\u7684\u6e38\u620f\u8282\u594f\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u63d0\u51fa\u53ef\u6269\u5c55\u7684\u3001\u4ee5\u6570\u636e\u5e93\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u63a8\u8fdb\u4e86\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u6280\u672f\uff0c\u4e3a\u81ea\u52a8\u5316\u751f\u6210\u5177\u6709\u53ef\u914d\u7f6e\u6e38\u620f\u8fdb\u7a0b\u7684\u590d\u67423D\u5173\u5361\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18554", "abs": "https://arxiv.org/abs/2508.18554", "authors": ["Lily Jiaxin Wan", "Chia-Tung Ho", "Rongjian Liang", "Cunxi Yu", "Deming Chen", "Haoxing Ren"], "title": "SchemaCoder: Automatic Log Schema Extraction Coder with Residual Q-Tree Boosting", "comment": "18 pages, 16 figures, under review for AAAI2026", "summary": "Log schema extraction is the process of deriving human-readable templates\nfrom massive volumes of log data, which is essential yet notoriously\nlabor-intensive. Recent studies have attempted to streamline this task by\nleveraging Large Language Models (LLMs) for automated schema extraction.\nHowever, existing methods invariably rely on predefined regular expressions,\nnecessitating human domain expertise and severely limiting productivity gains.\nTo fundamentally address this limitation, we introduce SchemaCoder, the first\nfully automated schema extraction framework applicable to a wide range of log\nfile formats without requiring human customization within the flow. At its\ncore, SchemaCoder features a novel Residual Question-Tree (Q-Tree) Boosting\nmechanism that iteratively refines schema extraction through targeted, adaptive\nqueries driven by LLMs. Particularly, our method partitions logs into semantic\nchunks via context-bounded segmentation, selects representative patterns using\nembedding-based sampling, and generates schema code through hierarchical\nQ-Tree-driven LLM queries, iteratively refined by our textual-residual\nevolutionary optimizer and residual boosting. Experimental validation\ndemonstrates SchemaCoder's superiority on the widely-used LogHub-2.0 benchmark,\nachieving an average improvement of 21.3% over state-of-the-arts.", "AI": {"tldr": "SchemaCoder\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u65e5\u5fd7\u6a21\u5f0f\u63d0\u53d6\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6b8b\u5dee\u95ee\u9898\u6811\u589e\u5f3a\u673a\u5236\uff0c\u65e0\u9700\u4eba\u5de5\u5b9a\u5236\u5373\u53ef\u5904\u7406\u591a\u79cd\u65e5\u5fd7\u683c\u5f0f\uff0c\u5728LogHub-2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u63d0\u534721.3%\u3002", "motivation": "\u73b0\u6709\u65e5\u5fd7\u6a21\u5f0f\u63d0\u53d6\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u9700\u8981\u4eba\u5de5\u9886\u57df\u77e5\u8bc6\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u751f\u4ea7\u6548\u7387\u63d0\u5347\u3002\u9700\u8981\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6a21\u5f0f\u63d0\u53d6\u3002", "method": "\u91c7\u7528\u6b8b\u5dee\u95ee\u9898\u6811\u589e\u5f3a\u673a\u5236\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u8fb9\u754c\u5206\u5272\u5c06\u65e5\u5fd7\u5212\u5206\u4e3a\u8bed\u4e49\u5757\uff0c\u4f7f\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u91c7\u6837\u9009\u62e9\u4ee3\u8868\u6027\u6a21\u5f0f\uff0c\u901a\u8fc7\u5206\u5c42Q-Tree\u9a71\u52a8\u7684LLM\u67e5\u8be2\u751f\u6210\u6a21\u5f0f\u4ee3\u7801\uff0c\u5e76\u7531\u6587\u672c\u6b8b\u5dee\u8fdb\u5316\u4f18\u5316\u5668\u548c\u6b8b\u5dee\u589e\u5f3a\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684LogHub-2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSchemaCoder\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u4e8621.3%\u7684\u6027\u80fd\u3002", "conclusion": "SchemaCoder\u662f\u7b2c\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6a21\u5f0f\u63d0\u53d6\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u5404\u79cd\u65e5\u5fd7\u6587\u4ef6\u683c\u5f0f\u800c\u65e0\u9700\u4eba\u5de5\u5b9a\u5236\uff0c\u901a\u8fc7\u521b\u65b0\u7684Q-Tree\u589e\u5f3a\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u6a21\u5f0f\u63d0\u53d6\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2508.18608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18608", "abs": "https://arxiv.org/abs/2508.18608", "authors": ["Janet Wang", "Xin Hu", "Yunbei Zhang", "Diabate Almamy", "Vagamon Bamba", "Konan Amos S\u00e9bastien Koffi", "Yao Koffi Aubin", "Zhengming Ding", "Jihun Hamm", "Rie R. Yotsu"], "title": "eSkinHealth: A Multimodal Dataset for Neglected Tropical Skin Diseases", "comment": null, "summary": "Skin Neglected Tropical Diseases (NTDs) impose severe health and\nsocioeconomic burdens in impoverished tropical communities. Yet, advancements\nin AI-driven diagnostic support are hindered by data scarcity, particularly for\nunderrepresented populations and rare manifestations of NTDs. Existing\ndermatological datasets often lack the demographic and disease spectrum crucial\nfor developing reliable recognition models of NTDs. To address this, we\nintroduce eSkinHealth, a novel dermatological dataset collected on-site in\nC\\^ote d'Ivoire and Ghana. Specifically, eSkinHealth contains 5,623 images from\n1,639 cases and encompasses 47 skin diseases, focusing uniquely on skin NTDs\nand rare conditions among West African populations. We further propose an\nAI-expert collaboration paradigm to implement foundation language and\nsegmentation models for efficient generation of multimodal annotations, under\ndermatologists' guidance. In addition to patient metadata and diagnosis labels,\neSkinHealth also includes semantic lesion masks, instance-specific visual\ncaptions, and clinical concepts. Overall, our work provides a valuable new\nresource and a scalable annotation framework, aiming to catalyze the\ndevelopment of more equitable, accurate, and interpretable AI tools for global\ndermatology.", "AI": {"tldr": "eSkinHealth\u662f\u4e00\u4e2a\u65b0\u7684\u76ae\u80a4\u75c5\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u897f\u975e\u4eba\u7fa4\u7684\u76ae\u80a4\u88ab\u5ffd\u89c6\u70ed\u5e26\u75c5\u548c\u7f55\u89c1\u75c5\u75c7\uff0c\u5305\u542b5623\u5f20\u56fe\u50cf\u548c47\u79cd\u75be\u75c5\uff0c\u91c7\u7528AI-\u4e13\u5bb6\u534f\u4f5c\u8303\u5f0f\u751f\u6210\u591a\u6a21\u6001\u6807\u6ce8", "motivation": "\u89e3\u51b3\u76ae\u80a4\u88ab\u5ffd\u89c6\u70ed\u5e26\u75c5(NTDs)\u8bca\u65ad\u4e2d\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u4ee3\u8868\u6027\u4e0d\u8db3\u4eba\u7fa4\u548c\u7f55\u89c1\u75c5\u75c7\u7684\u6570\u636e\u7f3a\u4e4f\uff0c\u73b0\u6709\u76ae\u80a4\u75c5\u6570\u636e\u96c6\u7f3a\u4e4f\u5173\u952e\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u548c\u75be\u75c5\u8c31\u4fe1\u606f", "method": "\u5728\u79d1\u7279\u8fea\u74e6\u548c\u52a0\u7eb3\u73b0\u573a\u6536\u96c6\u6570\u636e\uff0c\u63d0\u51faAI-\u4e13\u5bb6\u534f\u4f5c\u8303\u5f0f\uff0c\u5229\u7528\u57fa\u7840\u8bed\u8a00\u548c\u5206\u5272\u6a21\u578b\u5728\u76ae\u80a4\u79d1\u533b\u751f\u6307\u5bfc\u4e0b\u9ad8\u6548\u751f\u6210\u591a\u6a21\u6001\u6807\u6ce8\uff0c\u5305\u62ec\u8bed\u4e49\u75c5\u53d8\u63a9\u7801\u3001\u89c6\u89c9\u63cf\u8ff0\u548c\u4e34\u5e8a\u6982\u5ff5", "result": "\u6784\u5efa\u4e86\u5305\u542b5623\u5f20\u56fe\u50cf\u30011639\u4e2a\u75c5\u4f8b\u300147\u79cd\u76ae\u80a4\u75be\u75c5\u7684eSkinHealth\u6570\u636e\u96c6\uff0c\u7279\u522b\u5173\u6ce8\u897f\u975e\u4eba\u7fa4\u7684\u76ae\u80a4NTDs\u548c\u7f55\u89c1\u75c5\u75c7", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u65b0\u8d44\u6e90\u548c\u53ef\u6269\u5c55\u7684\u6807\u6ce8\u6846\u67b6\uff0c\u65e8\u5728\u63a8\u52a8\u5f00\u53d1\u66f4\u516c\u5e73\u3001\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u5168\u7403\u76ae\u80a4\u75c5AI\u5de5\u5177"}}
{"id": "2508.18642", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18642", "abs": "https://arxiv.org/abs/2508.18642", "authors": ["Jianxing Liao", "Tian Zhang", "Xiao Feng", "Yusong Zhang", "Rui Yang", "Haorui Wang", "Bosi Wen", "Ziying Wang", "Runzhi Shi"], "title": "RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing", "comment": null, "summary": "Large language models are extensively utilized in creative writing\napplications. Creative writing requires a balance between subjective writing\nquality (e.g., literariness and emotional expression) and objective constraint\nfollowing (e.g., format requirements and word limits). Existing reinforcement\nlearning methods struggle to balance these two aspects: single reward\nstrategies fail to improve both abilities simultaneously, while fixed-weight\nmixed-reward methods lack the ability to adapt to different writing scenarios.\nTo address this problem, we propose Reinforcement Learning with Mixed Rewards\n(RLMR), utilizing a dynamically mixed reward system from a writing reward model\nevaluating subjective writing quality and a constraint verification model\nassessing objective constraint following. The constraint following reward\nweight is adjusted dynamically according to the writing quality within sampled\ngroups, ensuring that samples violating constraints get negative advantage in\nGRPO and thus penalized during training, which is the key innovation of this\nproposed method. We conduct automated and manual evaluations across diverse\nmodel families from 8B to 72B parameters. Additionally, we construct a\nreal-world writing benchmark named WriteEval for comprehensive evaluation.\nResults illustrate that our method achieves consistent improvements in both\ninstruction following (IFEval from 83.36\\% to 86.65\\%) and writing quality\n(72.75\\% win rate in manual expert pairwise evaluations on WriteEval). To the\nbest of our knowledge, RLMR is the first work to combine subjective preferences\nwith objective verification in online RL training, providing an effective\nsolution for multi-dimensional creative writing optimization.", "AI": {"tldr": "RLMR\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u6df7\u5408\u5956\u52b1\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e3b\u89c2\u5199\u4f5c\u8d28\u91cf\u548c\u5ba2\u89c2\u7ea6\u675f\u9075\u5faa\u8bc4\u4f30\uff0c\u5728\u521b\u610f\u5199\u4f5c\u4e2d\u5b9e\u73b0\u4e86\u6307\u4ee4\u9075\u5faa\u548c\u5199\u4f5c\u8d28\u91cf\u7684\u53cc\u91cd\u63d0\u5347", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5e73\u8861\u521b\u610f\u5199\u4f5c\u4e2d\u7684\u4e3b\u89c2\u5199\u4f5c\u8d28\u91cf\u548c\u5ba2\u89c2\u7ea6\u675f\u9075\u5faa\uff0c\u5355\u4e00\u5956\u52b1\u7b56\u7565\u548c\u56fa\u5b9a\u6743\u91cd\u6df7\u5408\u5956\u52b1\u65b9\u6cd5\u90fd\u5b58\u5728\u5c40\u9650\u6027", "method": "\u63d0\u51faRLMR\u65b9\u6cd5\uff0c\u4f7f\u7528\u5199\u4f5c\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e3b\u89c2\u8d28\u91cf\uff0c\u7ea6\u675f\u9a8c\u8bc1\u6a21\u578b\u8bc4\u4f30\u5ba2\u89c2\u7ea6\u675f\uff0c\u52a8\u6001\u8c03\u6574\u7ea6\u675f\u9075\u5faa\u5956\u52b1\u6743\u91cd\uff0c\u901a\u8fc7GRPO\u5bf9\u8fdd\u53cd\u7ea6\u675f\u7684\u6837\u672c\u8fdb\u884c\u60e9\u7f5a", "result": "\u57288B\u523072B\u53c2\u6570\u7684\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u4e0a\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u6307\u4ee4\u9075\u5faa\u4ece83.36%\u63d0\u5347\u523086.65%\uff0c\u5728WriteEval\u57fa\u51c6\u4e0a\u83b7\u5f9772.75%\u7684\u4eba\u5de5\u4e13\u5bb6\u8bc4\u4f30\u80dc\u7387", "conclusion": "RLMR\u662f\u9996\u4e2a\u5728\u5728\u7ebfRL\u8bad\u7ec3\u4e2d\u7ed3\u5408\u4e3b\u89c2\u504f\u597d\u548c\u5ba2\u89c2\u9a8c\u8bc1\u7684\u5de5\u4f5c\uff0c\u4e3a\u591a\u7ef4\u521b\u610f\u5199\u4f5c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.18646", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18646", "abs": "https://arxiv.org/abs/2508.18646", "authors": ["Jun Wang", "Ninglun Gu", "Kailai Zhang", "Zijiao Zhang", "Yelun Bao", "Jin Yang", "Xu Yin", "Liwei Liu", "Yihuan Liu", "Pengyong Li", "Gary G. Yen", "Junchi Yan"], "title": "Beyond Benchmark: LLMs Evaluation with an Anthropomorphic and Value-oriented Roadmap", "comment": "Preprint. Under review", "summary": "For Large Language Models (LLMs), a disconnect persists between benchmark\nperformance and real-world utility. Current evaluation frameworks remain\nfragmented, prioritizing technical metrics while neglecting holistic assessment\nfor deployment. This survey introduces an anthropomorphic evaluation paradigm\nthrough the lens of human intelligence, proposing a novel three-dimensional\ntaxonomy: Intelligence Quotient (IQ)-General Intelligence for foundational\ncapacity, Emotional Quotient (EQ)-Alignment Ability for value-based\ninteractions, and Professional Quotient (PQ)-Professional Expertise for\nspecialized proficiency. For practical value, we pioneer a Value-oriented\nEvaluation (VQ) framework assessing economic viability, social impact, ethical\nalignment, and environmental sustainability. Our modular architecture\nintegrates six components with an implementation roadmap. Through analysis of\n200+ benchmarks, we identify key challenges including dynamic assessment needs\nand interpretability gaps. It provides actionable guidance for developing LLMs\nthat are technically proficient, contextually relevant, and ethically sound. We\nmaintain a curated repository of open-source evaluation resources at:\nhttps://github.com/onejune2018/Awesome-LLM-Eval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4eba\u7c7b\u667a\u80fd\u89c6\u89d2\u7684\u62df\u4eba\u5316\u8bc4\u4f30\u8303\u5f0f\uff0c\u5305\u542bIQ\u3001EQ\u3001PQ\u4e09\u4e2a\u7ef4\u5ea6\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u9996\u521b\u4e86\u9762\u5411\u4ef7\u503c\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u4e0e\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u4e4b\u95f4\u5b58\u5728\u8131\u8282\uff0c\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u788e\u7247\u5316\u4e14\u8fc7\u5ea6\u5173\u6ce8\u6280\u672f\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u90e8\u7f72\u5b9e\u7528\u6027\u7684\u6574\u4f53\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u7ef4\u5206\u7c7b\u6cd5\uff1a\u667a\u5546(IQ)-\u901a\u7528\u667a\u80fd\u57fa\u7840\u80fd\u529b\u3001\u60c5\u5546(EQ)-\u4ef7\u503c\u5bf9\u9f50\u4ea4\u4e92\u80fd\u529b\u3001\u4e13\u4e1a\u5546(PQ)-\u4e13\u4e1a\u9886\u57df\u7cbe\u901a\u80fd\u529b\uff0c\u5e76\u5efa\u7acb\u4e86\u5305\u542b\u7ecf\u6d4e\u53ef\u884c\u6027\u3001\u793e\u4f1a\u5f71\u54cd\u3001\u4f26\u7406\u5bf9\u9f50\u548c\u53ef\u6301\u7eed\u6027\u7684\u4ef7\u503c\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5206\u6790200\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc6\u522b\u51fa\u52a8\u6001\u8bc4\u4f30\u9700\u6c42\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u8ddd\u7b49\u5173\u952e\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u67b6\u6784\u548c\u5b9e\u65bd\u8def\u7ebf\u56fe\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u6280\u672f\u719f\u7ec3\u3001\u60c5\u5883\u76f8\u5173\u4e14\u4f26\u7406\u5065\u5168\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u5e76\u7ef4\u62a4\u4e86\u5f00\u6e90\u8bc4\u4f30\u8d44\u6e90\u5e93\u3002"}}
{"id": "2508.18669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18669", "abs": "https://arxiv.org/abs/2508.18669", "authors": ["Weikang Zhao", "Xili Wang", "Chengdi Ma", "Lingbin Kong", "Zhaohua Yang", "Mingxiang Tuo", "Xiaowei Shi", "Yitao Zhai", "Xunliang Cai"], "title": "MUA-RL: Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use", "comment": null, "summary": "With the recent rapid advancement of Agentic Intelligence, agentic tool use\nin LLMs has become increasingly important. During multi-turn interactions\nbetween agents and users, the dynamic, uncertain, and stochastic nature of user\ndemands poses significant challenges to the agent's tool invocation\ncapabilities. Agents are no longer expected to simply call tools to deliver a\nresult; rather, they must iteratively refine their understanding of user needs\nthrough communication while simultaneously invoking tools to resolve user\nqueries. Existing reinforcement learning (RL) approaches for tool use lack the\nintegration of genuinely dynamic users during the RL training process. To\nbridge this gap, we introduce MUA-RL (Multi-turn User-interacting Agent\nReinforcement Learning for agentic tool use), a novel reinforcement learning\nframework that, for the first time in the field of agentic tool use, integrates\nLLM-simulated users into the reinforcement learning loop. MUA-RL aims to enable\nautonomous learning of models to communicate with users efficiently and use\nvarious tools to solve practical problems in dynamic multi-turn interactions.\nEvaluations are done on several multi-turn tool-using benchmarks (see Figure\n1). Specifically, MUA-RL-32B achieves 67.3 on TAU2 Retail, 45.4 on TAU2\nAirline, 28.3 on TAU2 Telecom, 28.4 on BFCL-V3 Multi Turn, and 82.5 on ACEBench\nAgent -- outperforming or matching the performance of larger open-source models\nsuch as DeepSeek-V3-0324 and Qwen3-235B-A22B in non-thinking settings.", "AI": {"tldr": "MUA-RL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u9996\u6b21\u5728\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u9886\u57df\u5c06LLM\u6a21\u62df\u7528\u6237\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\uff0c\u7528\u4e8e\u591a\u8f6e\u52a8\u6001\u4ea4\u4e92\u4e2d\u7684\u5de5\u5177\u8c03\u7528\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4f53\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7528\u6237\u9700\u6c42\u7684\u52a8\u6001\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u968f\u673a\u6027\u5bf9\u667a\u80fd\u4f53\u5de5\u5177\u8c03\u7528\u80fd\u529b\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u771f\u6b63\u52a8\u6001\u7528\u6237\u7684\u96c6\u6210\u3002", "method": "\u63d0\u51fa\u4e86MUA-RL\uff08\u591a\u8f6e\u7528\u6237\u4ea4\u4e92\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5c06LLM\u6a21\u62df\u7528\u6237\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u4e0e\u7528\u6237\u9ad8\u6548\u6c9f\u901a\u5e76\u4f7f\u7528\u5404\u79cd\u5de5\u5177\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1aTAU2 Retail 67.3\u5206\u3001TAU2 Airline 45.4\u5206\u3001TAU2 Telecom 28.3\u5206\u3001BFCL-V3 Multi Turn 28.4\u5206\u3001ACEBench Agent 82.5\u5206\uff0c\u6027\u80fd\u4f18\u4e8e\u6216\u5339\u914d\u66f4\u5927\u7684\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "MUA-RL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u6001\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5de5\u5177\u4f7f\u7528\u7684\u6311\u6218\uff0c\u901a\u8fc7\u96c6\u6210\u6a21\u62df\u7528\u6237\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u5b66\u4e60\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18689", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18689", "abs": "https://arxiv.org/abs/2508.18689", "authors": ["Yuyang Zhao", "Wentao Shi", "Fuli Feng", "Xiangnan He"], "title": "AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance", "comment": "Accepted at CIKM 2025. 10 pages, 5 figures. Our code is available at:\n  https://github.com/LaoKuiZe/AppAgent-Pro. Our code is available at:\n  https://github.com/LaoKuiZe/AppAgent-Pro. The demonstration video could be\n  found at:\n  https://www.dropbox.com/scl/fi/hvzqo5vnusg66srydzixo/AppAgent-Pro-demo-video.mp4?rlkey=o2nlfqgq6ihl125mcqg7bpgqu&st=d29vrzii&dl=0", "summary": "Large language model (LLM)-based agents have demonstrated remarkable\ncapabilities in addressing complex tasks, thereby enabling more advanced\ninformation retrieval and supporting deeper, more sophisticated human\ninformation-seeking behaviors. However, most existing agents operate in a\npurely reactive manner, responding passively to user instructions, which\nsignificantly constrains their effectiveness and efficiency as general-purpose\nplatforms for information acquisition. To overcome this limitation, this paper\nproposes AppAgent-Pro, a proactive GUI agent system that actively integrates\nmulti-domain information based on user instructions. This approach enables the\nsystem to proactively anticipate users' underlying needs and conduct in-depth\nmulti-domain information mining, thereby facilitating the acquisition of more\ncomprehensive and intelligent information. AppAgent-Pro has the potential to\nfundamentally redefine information acquisition in daily life, leading to a\nprofound impact on human society. Our code is available at:\nhttps://github.com/LaoKuiZe/AppAgent-Pro. Our code is available at:\nhttps://github.com/LaoKuiZe/AppAgent-Pro. The demonstration video could be\nfound at:\nhttps://www.dropbox.com/scl/fi/hvzqo5vnusg66srydzixo/AppAgent-Pro-demo-video.mp4?rlkey=o2nlfqgq6ihl125mcqg7bpgqu&st=d29vrzii&dl=0.", "AI": {"tldr": "AppAgent-Pro\u662f\u4e00\u4e2a\u4e3b\u52a8\u5f0fGUI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u9886\u57df\u4fe1\u606f\u6574\u5408\u4e3b\u52a8\u9884\u6d4b\u7528\u6237\u9700\u6c42\uff0c\u63d0\u5347\u4fe1\u606f\u83b7\u53d6\u7684\u5168\u9762\u6027\u548c\u667a\u80fd\u5316", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u591a\u4e3a\u88ab\u52a8\u54cd\u5e94\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u4fe1\u606f\u83b7\u53d6\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u9700\u8981\u8f6c\u5411\u4e3b\u52a8\u5f0f\u4fe1\u606f\u83b7\u53d6\u65b9\u5f0f", "method": "\u63d0\u51faAppAgent-Pro\u7cfb\u7edf\uff0c\u4e3b\u52a8\u6574\u5408\u591a\u9886\u57df\u4fe1\u606f\uff0c\u57fa\u4e8e\u7528\u6237\u6307\u4ee4\u8fdb\u884c\u6df1\u5ea6\u591a\u9886\u57df\u4fe1\u606f\u6316\u6398", "result": "\u7cfb\u7edf\u80fd\u591f\u4e3b\u52a8\u9884\u6d4b\u7528\u6237\u6f5c\u5728\u9700\u6c42\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u667a\u80fd\u7684\u4fe1\u606f\u83b7\u53d6\uff0c\u6709\u671b\u91cd\u65b0\u5b9a\u4e49\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u4fe1\u606f\u83b7\u53d6\u65b9\u5f0f", "conclusion": "AppAgent-Pro\u4ee3\u8868\u4e86\u4ece\u88ab\u52a8\u5230\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u7684\u91cd\u8981\u8f6c\u53d8\uff0c\u5bf9\u4eba\u7c7b\u793e\u4f1a\u7684\u65e5\u5e38\u4fe1\u606f\u83b7\u53d6\u5177\u6709\u6df1\u8fdc\u5f71\u54cd"}}
{"id": "2508.18722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18722", "abs": "https://arxiv.org/abs/2508.18722", "authors": ["Honghao Fu", "Junlong Ren", "Qi Chai", "Deheng Ye", "Yujun Cai", "Hao Wang"], "title": "VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft", "comment": "Accepted by EMNLP 2025 main", "summary": "Large language models (LLMs) have shown significant promise in embodied\ndecision-making tasks within virtual open-world environments. Nonetheless,\ntheir performance is hindered by the absence of domain-specific knowledge.\nMethods that finetune on large-scale domain-specific data entail prohibitive\ndevelopment costs. This paper introduces VistaWise, a cost-effective agent\nframework that integrates cross-modal domain knowledge and finetunes a\ndedicated object detection model for visual analysis. It reduces the\nrequirement for domain-specific training data from millions of samples to a few\nhundred. VistaWise integrates visual information and textual dependencies into\na cross-modal knowledge graph (KG), enabling a comprehensive and accurate\nunderstanding of multimodal environments. We also equip the agent with a\nretrieval-based pooling strategy to extract task-related information from the\nKG, and a desktop-level skill library to support direct operation of the\nMinecraft desktop client via mouse and keyboard inputs. Experimental results\ndemonstrate that VistaWise achieves state-of-the-art performance across various\nopen-world tasks, highlighting its effectiveness in reducing development costs\nwhile enhancing agent performance.", "AI": {"tldr": "VistaWise\u662f\u4e00\u4e2a\u6210\u672c\u6548\u76ca\u9ad8\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u8de8\u6a21\u6001\u9886\u57df\u77e5\u8bc6\u548c\u5fae\u8c03\u4e13\u7528\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff0c\u5c06\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u4ece\u6570\u767e\u4e07\u6837\u672c\u51cf\u5c11\u5230\u6570\u767e\u4e2a\uff0c\u5728\u865a\u62df\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u865a\u62df\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u5177\u8eab\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u5230\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u7684\u9650\u5236\uff0c\u800c\u57fa\u4e8e\u5927\u89c4\u6a21\u9886\u57df\u7279\u5b9a\u6570\u636e\u7684\u5fae\u8c03\u65b9\u6cd5\u5f00\u53d1\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u63d0\u51faVistaWise\u6846\u67b6\uff0c\u6574\u5408\u8de8\u6a21\u6001\u9886\u57df\u77e5\u8bc6\u5e76\u5fae\u8c03\u4e13\u7528\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8fdb\u884c\u89c6\u89c9\u5206\u6790\uff1b\u6784\u5efa\u8de8\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u89c6\u89c9\u4fe1\u606f\u548c\u6587\u672c\u4f9d\u8d56\u5173\u7cfb\uff1b\u91c7\u7528\u68c0\u7d22\u5f0f\u6c60\u5316\u7b56\u7565\u4ece\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff1b\u914d\u5907\u684c\u9762\u7ea7\u6280\u80fd\u5e93\u652f\u6301\u901a\u8fc7\u9f20\u6807\u952e\u76d8\u76f4\u63a5\u64cd\u4f5cMinecraft\u5ba2\u6237\u7aef\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVistaWise\u5728\u5404\u79cd\u5f00\u653e\u4e16\u754c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5f00\u53d1\u6210\u672c\u540c\u65f6\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u6027\u80fd\u3002", "conclusion": "VistaWise\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u7f3a\u4e4f\u548c\u5f00\u53d1\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u77e5\u8bc6\u6574\u5408\u548c\u9ad8\u6548\u6570\u636e\u5229\u7528\uff0c\u5728\u865a\u62df\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.18724", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18724", "abs": "https://arxiv.org/abs/2508.18724", "authors": ["Karanbir Singh", "Deepak Muppiri", "William Ngu"], "title": "Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval", "comment": "Accepted at KDD'2025 Agent4IR workshop", "summary": "Large Language Models (LLMs) have transformed the field of artificial\nintelligence by unlocking the era of generative applications. Built on top of\ngenerative AI capabilities, Agentic AI represents a major shift toward\nautonomous, goal-driven systems that can reason, retrieve, and act. However,\nthey also inherit the bias present in both internal and external information\nsources. This significantly affects the fairness and balance of retrieved\ninformation, and hence reduces user trust. To address this critical challenge,\nwe introduce a novel Bias Mitigation Agent, a multi-agent system designed to\norchestrate the workflow of bias mitigation through specialized agents that\noptimize the selection of sources to ensure that the retrieved content is both\nhighly relevant and minimally biased to promote fair and balanced knowledge\ndissemination. The experimental results demonstrate an 81.82\\% reduction in\nbias compared to a baseline naive retrieval strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u504f\u7f6e\u7f13\u89e3\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4f18\u5316\u4fe1\u606f\u6e90\u9009\u62e9\uff0c\u663e\u8457\u51cf\u5c11LLM\u68c0\u7d22\u4e2d\u7684\u504f\u89c1\u95ee\u9898", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4ee3\u7406AI\u7cfb\u7edf\u7ee7\u627f\u4e86\u5185\u90e8\u548c\u5916\u90e8\u4fe1\u606f\u6e90\u7684\u504f\u89c1\uff0c\u8fd9\u5f71\u54cd\u4e86\u68c0\u7d22\u4fe1\u606f\u7684\u516c\u5e73\u6027\u548c\u5e73\u8861\u6027\uff0c\u964d\u4f4e\u4e86\u7528\u6237\u4fe1\u4efb\u5ea6", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u4ee3\u7406\u534f\u8c03\u504f\u7f6e\u7f13\u89e3\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f18\u5316\u4fe1\u606f\u6e90\u9009\u62e9\u4ee5\u786e\u4fdd\u68c0\u7d22\u5185\u5bb9\u9ad8\u5ea6\u76f8\u5173\u4e14\u504f\u89c1\u6700\u5c0f", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u57fa\u7ebf\u6734\u7d20\u68c0\u7d22\u7b56\u7565\u76f8\u6bd4\uff0c\u504f\u7f6e\u51cf\u5c11\u4e8681.82%", "conclusion": "\u8be5\u504f\u7f6e\u7f13\u89e3\u4ee3\u7406\u7cfb\u7edf\u80fd\u6709\u6548\u4fc3\u8fdb\u516c\u5e73\u548c\u5e73\u8861\u7684\u77e5\u8bc6\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u4fe1\u606f\u68c0\u7d22\u7684\u516c\u6b63\u6027"}}
{"id": "2508.18743", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18743", "abs": "https://arxiv.org/abs/2508.18743", "authors": ["Sunguk Choi", "Yonghoon Kwon", "Heondeuk Lee"], "title": "CAC-CoT: Connector-Aware Compact Chain-of-Thought for Efficient Reasoning Data Synthesis Across Dual-System Cognitive Tasks", "comment": "Accepted at EMNLP 2025 findings", "summary": "Long chain-of-thought (CoT) prompting helps Large Language Models (LLMs)\nsolve difficult problems, but very long traces often slow or even degrade\nperformance on fast, intuitive \"System-1\" tasks. We introduce Connector-Aware\nCompact CoT (CAC-CoT) -- a method that deliberately restricts reasoning to a\nsmall, fixed set of connector phrases, steering the model toward concise and\nwell -- structured explanations. Despite its simplicity, our synthetic method\nwith Gemini-2.0-Flash yields a high-quality training quality. CAC-CoT achieves\napproximately 85% on GSM8K and approximately 40% on GPQA (System-2) while\nretaining approximately 90% on S1-Bench (System-1). Its reasoning traces\naverage approximately 300 tokens(ART), about one-third the length of baseline\ntraces, delivering higher efficiency without loss of accuracy.", "AI": {"tldr": "CAC-CoT\u662f\u4e00\u79cd\u4f7f\u7528\u6709\u9650\u8fde\u63a5\u77ed\u8bed\u7684\u7d27\u51d1\u601d\u7ef4\u94fe\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301System-1\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u7f29\u77ed\u63a8\u7406\u957f\u5ea6\u5e76\u63d0\u5347System-2\u4efb\u52a1\u8868\u73b0", "motivation": "\u89e3\u51b3\u957f\u601d\u7ef4\u94fe\u5728\u5feb\u901f\u76f4\u89c9\u6027\u4efb\u52a1(System-1)\u4e0a\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u590d\u6742\u63a8\u7406\u4efb\u52a1(System-2)\u7684\u80fd\u529b", "method": "\u4f7f\u7528\u8fde\u63a5\u77ed\u8bed\u611f\u77e5\u7684\u7d27\u51d1\u601d\u7ef4\u94fe\u65b9\u6cd5\uff0c\u9650\u5236\u63a8\u7406\u5230\u56fa\u5b9a\u7684\u5c0f\u578b\u8fde\u63a5\u77ed\u8bed\u96c6\u5408\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7b80\u6d01\u4e14\u7ed3\u6784\u826f\u597d\u7684\u89e3\u91ca", "result": "\u5728GSM8K\u4e0a\u8fbe\u5230\u7ea685%\uff0cGPQA\u4e0a\u7ea640%\uff0c\u540c\u65f6\u4fdd\u6301S1-Bench\u7ea690%\u7684\u6027\u80fd\uff1b\u63a8\u7406\u75d5\u8ff9\u5e73\u5747\u7ea6300\u4e2atoken\uff0c\u6bd4\u57fa\u7ebf\u7f29\u77ed\u4e09\u5206\u4e4b\u4e8c", "conclusion": "CAC-CoT\u65b9\u6cd5\u901a\u8fc7\u7b80\u6d01\u7684\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u6548\u7387\u63d0\u5347\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\uff0c\u5728System-1\u548cSystem-2\u4efb\u52a1\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861"}}
{"id": "2508.18749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18749", "abs": "https://arxiv.org/abs/2508.18749", "authors": ["Chunlong Wu", "Zhibo Qu"], "title": "Reflection-Enhanced Meta-Optimization Integrating TextGrad-style Prompt Optimization with Memory-Driven Self-Evolution", "comment": null, "summary": "Recent advances in prompt optimization, exemplified by methods such as\nTextGrad, enable automatic, gradient-like refinement of textual prompts to\nenhance the performance of large language models (LLMs) on specific downstream\ntasks. However, current approaches are typically stateless and operate\nindependently across optimization runs, lacking mechanisms to preserve and\nleverage historical optimization experience. Furthermore, they are susceptible\nto overfitting, often yielding prompt updates that generalize poorly beyond the\nimmediate task context.\n  To address these limitations, we propose Reflection-Enhanced\nMeta-Optimization (REMO), a novel framework that integrates (1) a\nmemory-augmented Reflection Retrieval-Augmented Generation (RAG) module -\nstructured as a \"mistake notebook\" and (2) a Self-Adaptive Optimizer,\nimplemented via an LLM-driven meta-controller that synthesizes epoch-level\nreflective insights to iteratively improve system-level prompting strategies.\nThis architecture enables not only local, fine-grained prompt tuning akin to\nTextGrad, but also the systematic accumulation and reuse of cross-run\noptimization knowledge, thereby supporting continual improvement over time.\n  We instantiate the REMO framework using Qwen3-32B in standard inference mode\n- without explicit chain-of-thought prompting - and evaluate its efficacy on\nthe GSM8K benchmark for mathematical reasoning. Experimental results\ndemonstrate that, compared to a TextGrad baseline, REMO achieves more stable\nand robust generalization, albeit at the cost of increased computational\noverhead. We provide a detailed exposition of the algorithmic design, conduct a\nqualitative and quantitative analysis of optimization dynamics, and present a\ncomprehensive ablation study to elucidate the contributions of each component.", "AI": {"tldr": "REMO\u662f\u4e00\u4e2a\u65b0\u7684\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u7684\u53cd\u601dRAG\u6a21\u5757\u548c\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5386\u53f2\u7ecf\u9a8c\u79ef\u7d2f\u548c\u5bb9\u6613\u8fc7\u62df\u5408\u7684\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u548c\u9c81\u68d2\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff08\u5982TextGrad\uff09\u901a\u5e38\u662f\u72b6\u6001\u65e0\u5173\u7684\uff0c\u7f3a\u4e4f\u5386\u53f2\u4f18\u5316\u7ecf\u9a8c\u7684\u4fdd\u5b58\u548c\u5229\u7528\u673a\u5236\uff0c\u4e14\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u6cdb\u5316\u6027\u80fd\u8f83\u5dee\u3002", "method": "\u63d0\u51fa\u4e86REMO\u6846\u67b6\uff0c\u5305\u542b\uff1a(1)\u8bb0\u5fc6\u589e\u5f3a\u7684\u53cd\u601dRAG\u6a21\u5757\uff08\"\u9519\u8bef\u7b14\u8bb0\u672c\"\u7ed3\u6784\uff09\uff0c(2)LLM\u9a71\u52a8\u7684\u5143\u63a7\u5236\u5668\u5b9e\u73b0\u7684\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5408\u6210epoch\u7ea7\u522b\u7684\u53cd\u601d\u89c1\u89e3\u6765\u8fed\u4ee3\u6539\u8fdb\u7cfb\u7edf\u7ea7\u63d0\u793a\u7b56\u7565\u3002", "result": "\u5728GSM8K\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4TextGrad\u57fa\u7ebf\uff0cREMO\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u548c\u9c81\u68d2\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u6709\u6240\u589e\u52a0\u3002", "conclusion": "REMO\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u79ef\u7d2f\u548c\u91cd\u7528\u8de8\u8fd0\u884c\u4f18\u5316\u77e5\u8bc6\uff0c\u652f\u6301\u6301\u7eed\u6539\u8fdb\uff0c\u4e3a\u63d0\u793a\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2508.18751", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.18751", "abs": "https://arxiv.org/abs/2508.18751", "authors": ["Byung-Joon Lee", "Jin-Seop Lee", "Jee-Hyong Lee"], "title": "Stabilizing Open-Set Test-Time Adaptation via Primary-Auxiliary Filtering and Knowledge-Integrated Prediction", "comment": "Accepted at BMVC 2025", "summary": "Deep neural networks demonstrate strong performance under aligned\ntraining-test distributions. However, real-world test data often exhibit domain\nshifts. Test-Time Adaptation (TTA) addresses this challenge by adapting the\nmodel to test data during inference. While most TTA studies assume that the\ntraining and test data share the same class set (closed-set TTA), real-world\nscenarios often involve open-set data (open-set TTA), which can degrade\nclosed-set accuracy. A recent study showed that identifying open-set data\nduring adaptation and maximizing its entropy is an effective solution. However,\nthe previous method relies on the source model for filtering, resulting in\nsuboptimal filtering accuracy on domain-shifted test data. In contrast, we\nfound that the adapting model, which learns domain knowledge from noisy test\nstreams, tends to be unstable and leads to error accumulation when used for\nfiltering. To address this problem, we propose Primary-Auxiliary Filtering\n(PAF), which employs an auxiliary filter to validate data filtered by the\nprimary filter. Furthermore, we propose Knowledge-Integrated Prediction (KIP),\nwhich calibrates the outputs of the adapting model, EMA model, and source model\nto integrate their complementary knowledge for OSTTA. We validate our approach\nacross diverse closed-set and open-set datasets. Our method enhances both\nclosed-set accuracy and open-set discrimination over existing methods. The code\nis available at https://github.com/powerpowe/PAF-KIP-OSTTA .", "AI": {"tldr": "\u63d0\u51faPAF-KIP\u65b9\u6cd5\u89e3\u51b3\u5f00\u653e\u96c6\u6d4b\u8bd5\u65f6\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u4e3b\u8f85\u52a9\u8fc7\u6ee4\u5668\u548c\u77e5\u8bc6\u96c6\u6210\u9884\u6d4b\u6765\u63d0\u5347\u95ed\u96c6\u51c6\u786e\u6027\u548c\u5f00\u96c6\u8bc6\u522b\u80fd\u529b", "motivation": "\u73b0\u6709\u5f00\u653e\u96c6TTA\u65b9\u6cd5\u4f9d\u8d56\u6e90\u6a21\u578b\u8fdb\u884c\u8fc7\u6ee4\uff0c\u5728\u57df\u504f\u79fb\u6d4b\u8bd5\u6570\u636e\u4e0a\u8fc7\u6ee4\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u4f7f\u7528\u9002\u5e94\u6a21\u578b\u8fc7\u6ee4\u4f1a\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u548c\u9519\u8bef\u7d2f\u79ef", "method": "\u63d0\u51fa\u4e3b\u8f85\u52a9\u8fc7\u6ee4(PAF)\u673a\u5236\uff0c\u7528\u8f85\u52a9\u8fc7\u6ee4\u5668\u9a8c\u8bc1\u4e3b\u8fc7\u6ee4\u5668\u7ed3\u679c\uff1b\u63d0\u51fa\u77e5\u8bc6\u96c6\u6210\u9884\u6d4b(KIP)\uff0c\u6574\u5408\u9002\u5e94\u6a21\u578b\u3001EMA\u6a21\u578b\u548c\u6e90\u6a21\u578b\u7684\u4e92\u8865\u77e5\u8bc6", "result": "\u5728\u591a\u4e2a\u95ed\u96c6\u548c\u5f00\u96c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728\u95ed\u96c6\u51c6\u786e\u6027\u548c\u5f00\u96c6\u8bc6\u522b\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "PAF-KIP\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u96c6\u6d4b\u8bd5\u65f6\u9002\u5e94\u4e2d\u7684\u8fc7\u6ee4\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u77e5\u8bc6\u96c6\u6210\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd"}}
{"id": "2508.18760", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.18760", "abs": "https://arxiv.org/abs/2508.18760", "authors": ["Yi Liu", "Xiangyu Liu", "Zequn Sun", "Wei Hu"], "title": "Answering the Unanswerable Is to Err Knowingly: Analyzing and Mitigating Abstention Failures in Large Reasoning Models", "comment": null, "summary": "Large reasoning models (LRMs) have shown remarkable progress on complex\nreasoning tasks. However, some questions posed to LRMs are inherently\nunanswerable, such as math problems lacking sufficient conditions. We find that\nLRMs continually fail to provide appropriate abstentions when confronted with\nthese unanswerable questions. In this paper, we systematically analyze,\ninvestigate, and resolve this issue for trustworthy AI. We first conduct a\ndetailed analysis of the distinct response behaviors of LRMs when facing\nunanswerable questions. Then, we show that LRMs possess sufficient cognitive\ncapabilities to recognize the flaws in these questions. However, they fail to\nexhibit appropriate abstention behavior, revealing a misalignment between their\ninternal cognition and external response. Finally, to resolve this issue, we\npropose a lightweight, two-stage method that combines cognitive monitoring with\ninference-time intervention. Experimental results demonstrate that our method\nsignificantly improves the abstention rate while maintaining the overall\nreasoning performance.", "AI": {"tldr": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5904\u7406\u65e0\u6cd5\u56de\u7b54\u7684\u95ee\u9898\u65f6\u5b58\u5728\u62d2\u7edd\u56de\u7b54\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u672c\u6587\u901a\u8fc7\u8ba4\u77e5\u76d1\u63a7\u548c\u63a8\u7406\u65f6\u5e72\u9884\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u62d2\u7edd\u56de\u7b54\u7387", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u9047\u5230\u7f3a\u4e4f\u5145\u5206\u6761\u4ef6\u7684\u6570\u5b66\u95ee\u9898\u7b49\u65e0\u6cd5\u56de\u7b54\u7684\u95ee\u9898\u65f6\uff0c\u5f80\u5f80\u65e0\u6cd5\u63d0\u4f9b\u9002\u5f53\u7684\u62d2\u7edd\u56de\u7b54\uff0c\u8fd9\u5f71\u54cd\u4e86AI\u7684\u53ef\u4fe1\u5ea6", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u7ed3\u5408\u8ba4\u77e5\u76d1\u63a7\u548c\u63a8\u7406\u65f6\u5e72\u9884\uff0c\u9996\u5148\u5206\u6790\u6a21\u578b\u5bf9\u65e0\u6cd5\u56de\u7b54\u95ee\u9898\u7684\u54cd\u5e94\u884c\u4e3a\uff0c\u7136\u540e\u901a\u8fc7\u5e72\u9884\u4f7f\u6a21\u578b\u5185\u90e8\u8ba4\u77e5\u4e0e\u5916\u90e8\u54cd\u5e94\u5bf9\u9f50", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u62d2\u7edd\u56de\u7b54\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6574\u4f53\u63a8\u7406\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u65e0\u6cd5\u56de\u7b54\u95ee\u9898\u65f6\u7684\u62d2\u7edd\u56de\u7b54\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\uff0c\u63d0\u5347\u4e86AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6"}}
{"id": "2508.18763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18763", "abs": "https://arxiv.org/abs/2508.18763", "authors": ["Chao Hao", "Zezheng Wang", "Yanhua Huang", "Ruiwen Xu", "Wenzhe Niu", "Xin Liu", "Zitong Yu"], "title": "Dynamic Collaboration of Multi-Language Models based on Minimal Complete Semantic Units", "comment": "Accepted by EMNLP 2025 Main Conference", "summary": "This paper investigates the enhancement of reasoning capabilities in language\nmodels through token-level multi-model collaboration. Our approach selects the\noptimal tokens from the next token distributions provided by multiple models to\nperform autoregressive reasoning. Contrary to the assumption that more models\nyield better results, we introduce a distribution distance-based dynamic\nselection strategy (DDS) to optimize the multi-model collaboration process. To\naddress the critical challenge of vocabulary misalignment in multi-model\ncollaboration, we propose the concept of minimal complete semantic units\n(MCSU), which is simple yet enables multiple language models to achieve natural\nalignment within the linguistic space. Experimental results across various\nbenchmarks demonstrate the superiority of our method. The code will be\navailable at https://github.com/Fanye12/DDS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u8ddd\u79bb\u7684\u52a8\u6001\u9009\u62e9\u7b56\u7565(DDS)\u548c\u6700\u5c0f\u5b8c\u6574\u8bed\u4e49\u5355\u5143(MCSU)\u6982\u5ff5\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u5728token\u7ea7\u522b\u7684\u534f\u4f5c\u6765\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u8ba4\u4e3a\u66f4\u591a\u6a21\u578b\u4f1a\u5e26\u6765\u66f4\u597d\u7ed3\u679c\uff0c\u4f46\u5b9e\u9645\u591a\u6a21\u578b\u534f\u4f5c\u4e2d\u5b58\u5728\u8bcd\u6c47\u4e0d\u5bf9\u9f50\u7b49\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u4f18\u5316\u591a\u6a21\u578b\u534f\u4f5c\u8fc7\u7a0b\u3002", "method": "1. \u63d0\u51faDDS\u7b56\u7565\u4ece\u591a\u4e2a\u6a21\u578b\u7684\u4e0b\u4e00token\u5206\u5e03\u4e2d\u52a8\u6001\u9009\u62e9\u6700\u4f18token\uff1b2. \u5f15\u5165MCSU\u6982\u5ff5\u89e3\u51b3\u591a\u6a21\u578b\u8bcd\u6c47\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u5b9e\u73b0\u8bed\u8a00\u7a7a\u95f4\u5185\u7684\u81ea\u7136\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7token\u7ea7\u522b\u7684\u591a\u6a21\u578b\u534f\u4f5c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u578b\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2508.18781", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.18781", "abs": "https://arxiv.org/abs/2508.18781", "authors": ["Lisai Zhang", "Baohan Xu", "Siqian Yang", "Mingyu Yin", "Jing Liu", "Chao Xu", "Siqi Wang", "Yidi Wu", "Yuxin Hong", "Zihao Zhang", "Yanzhang Liang", "Yudong Jiang"], "title": "AniME: Adaptive Multi-Agent Planning for Long Animation Generation", "comment": "2 pages, Technical Report", "summary": "We present AniME, a director-oriented multi-agent system for automated\nlong-form anime production, covering the full workflow from a story to the\nfinal video. The director agent keeps a global memory for the whole workflow,\nand coordinates several downstream specialized agents. By integrating\ncustomized Model Context Protocol (MCP) with downstream model instruction, the\nspecialized agent adaptively selects control conditions for diverse sub-tasks.\nAniME produces cinematic animation with consistent characters and synchronized\naudio visual elements, offering a scalable solution for AI-driven anime\ncreation.", "AI": {"tldr": "AniME\u662f\u4e00\u4e2a\u5bfc\u6f14\u5bfc\u5411\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u957f\u7bc7\u5e45\u52a8\u753b\u5236\u4f5c\uff0c\u6db5\u76d6\u4ece\u6545\u4e8b\u5230\u6700\u7ec8\u89c6\u9891\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3AI\u9a71\u52a8\u52a8\u753b\u521b\u4f5c\u4e2d\u4fdd\u6301\u89d2\u8272\u4e00\u81f4\u6027\u548c\u97f3\u89c6\u9891\u5143\u7d20\u540c\u6b65\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u52a8\u753b\u5236\u4f5c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5bfc\u6f14\u667a\u80fd\u4f53\u7ef4\u62a4\u5168\u5c40\u8bb0\u5fc6\u5e76\u534f\u8c03\u4e0b\u6e38\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5b9a\u5236\u5316\u7684\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4e0e\u4e0b\u6e38\u6a21\u578b\u6307\u4ee4\u96c6\u6210\uff0c\u4f7f\u4e13\u4e1a\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u9002\u5e94\u9009\u62e9\u4e0d\u540c\u5b50\u4efb\u52a1\u7684\u63a7\u5236\u6761\u4ef6\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u5177\u6709\u4e00\u81f4\u89d2\u8272\u548c\u540c\u6b65\u97f3\u89c6\u9891\u5143\u7d20\u7684\u7535\u5f71\u7ea7\u52a8\u753b\u3002", "conclusion": "AniME\u4e3aAI\u9a71\u52a8\u7684\u52a8\u753b\u521b\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u4ece\u6545\u4e8b\u5230\u6700\u7ec8\u89c6\u9891\u7684\u5b8c\u6574\u81ea\u52a8\u5316\u751f\u4ea7\u6d41\u7a0b\u3002"}}
{"id": "2508.18797", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18797", "abs": "https://arxiv.org/abs/2508.18797", "authors": ["Qi Chai", "Zhang Zheng", "Junlong Ren", "Deheng Ye", "Zichuan Lin", "Hao Wang"], "title": "CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks", "comment": null, "summary": "Minecraft, as an open-world virtual interactive environment, has become a\nprominent platform for research on agent decision-making and execution.\nExisting works primarily adopt a single Large Language Model (LLM) agent to\ncomplete various in-game tasks. However, for complex tasks requiring lengthy\nsequences of actions, single-agent approaches often face challenges related to\ninefficiency and limited fault tolerance. Despite these issues, research on\nmulti-agent collaboration remains scarce. In this paper, we propose CausalMACE,\na holistic causality planning framework designed to enhance multi-agent\nsystems, in which we incorporate causality to manage dependencies among\nsubtasks. Technically, our proposed framework introduces two modules: an\noverarching task graph for global task planning and a causality-based module\nfor dependency management, where inherent rules are adopted to perform causal\nintervention. Experimental results demonstrate our approach achieves\nstate-of-the-art performance in multi-agent cooperative tasks of Minecraft.", "AI": {"tldr": "CausalMACE\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347Minecraft\u6e38\u620f\u4e2d\u590d\u6742\u4efb\u52a1\u7684\u6267\u884c\u6548\u7387\u548c\u5bb9\u9519\u80fd\u529b", "motivation": "\u73b0\u6709\u7684\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5728\u5904\u7406Minecraft\u4e2d\u9700\u8981\u957f\u5e8f\u5217\u52a8\u4f5c\u7684\u590d\u6742\u4efb\u52a1\u65f6\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u5bb9\u9519\u6027\u5dee\u7684\u95ee\u9898\uff0c\u800c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7814\u7a76\u76f8\u5bf9\u7f3a\u4e4f", "method": "\u63d0\u51fa\u5305\u542b\u4e24\u4e2a\u6a21\u5757\u7684\u6574\u4f53\u56e0\u679c\u89c4\u5212\u6846\u67b6\uff1a\u5168\u5c40\u4efb\u52a1\u89c4\u5212\u7684\u4efb\u52a1\u56fe\u548c\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u4f9d\u8d56\u7ba1\u7406\u6a21\u5757\uff0c\u91c7\u7528\u56fa\u6709\u89c4\u5219\u8fdb\u884c\u56e0\u679c\u5e72\u9884", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728Minecraft\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd", "conclusion": "CausalMACE\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u5173\u7cfb\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u4f5c\u6548\u7387\u548c\u4efb\u52a1\u5b8c\u6210\u80fd\u529b"}}
{"id": "2508.18812", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18812", "abs": "https://arxiv.org/abs/2508.18812", "authors": ["Chenghao Wu", "Ruiyang Ren", "Junjie Zhang", "Ruirui Wang", "Zhongrui Ma", "Qi Ye", "Wayne Xin Zhao"], "title": "STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning", "comment": null, "summary": "While modern recommender systems are instrumental in navigating information\nabundance, they remain fundamentally limited by static user modeling and\nreactive decision-making paradigms. Current large language model (LLM)-based\nagents inherit these shortcomings through their overreliance on heuristic\npattern matching, yielding recommendations prone to shallow correlation bias,\nlimited causal inference, and brittleness in sparse-data scenarios. We\nintroduce STARec, a slow-thinking augmented agent framework that endows\nrecommender systems with autonomous deliberative reasoning capabilities. Each\nuser is modeled as an agent with parallel cognitions: fast response for\nimmediate interactions and slow reasoning that performs chain-of-thought\nrationales. To cultivate intrinsic slow thinking, we develop anchored\nreinforcement training - a two-stage paradigm combining structured knowledge\ndistillation from advanced reasoning models with preference-aligned reward\nshaping. This hybrid approach scaffolds agents in acquiring foundational\ncapabilities (preference summarization, rationale generation) while enabling\ndynamic policy adaptation through simulated feedback loops. Experiments on\nMovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves\nsubstantial performance gains compared with state-of-the-art baselines, despite\nusing only 0.4% of the full training data.", "AI": {"tldr": "STARec\u662f\u4e00\u4e2a\u6162\u601d\u7ef4\u589e\u5f3a\u7684\u63a8\u8350\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u8ba4\u77e5\u5efa\u6a21\u548c\u951a\u5b9a\u5f3a\u5316\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u4ec5\u4f7f\u75280.4%\u7684\u8bad\u7ec3\u6570\u636e\u5c31\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u53d7\u9650\u4e8e\u9759\u6001\u7528\u6237\u5efa\u6a21\u548c\u53cd\u5e94\u5f0f\u51b3\u7b56\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u4ee3\u7406\u4e5f\u5b58\u5728\u542f\u53d1\u5f0f\u6a21\u5f0f\u5339\u914d\u7684\u5c40\u9650\u6027\uff0c\u5bfc\u81f4\u6d45\u5c42\u76f8\u5173\u504f\u5dee\u3001\u6709\u9650\u56e0\u679c\u63a8\u7406\u548c\u7a00\u758f\u6570\u636e\u573a\u666f\u4e0b\u7684\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51faSTARec\u6846\u67b6\uff0c\u5c06\u7528\u6237\u5efa\u6a21\u4e3a\u5177\u6709\u5e76\u884c\u8ba4\u77e5\u7684\u4ee3\u7406\uff1a\u5feb\u901f\u54cd\u5e94\u5373\u65f6\u4ea4\u4e92\uff0c\u6162\u901f\u63a8\u7406\u6267\u884c\u601d\u7ef4\u94fe\u63a8\u7406\u3002\u91c7\u7528\u951a\u5b9a\u5f3a\u5316\u8bad\u7ec3\uff0c\u7ed3\u5408\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u548c\u504f\u597d\u5bf9\u9f50\u7684\u5956\u52b1\u5851\u9020\u3002", "result": "\u5728MovieLens 1M\u548cAmazon CDs\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTARec\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5c3d\u7ba1\u53ea\u4f7f\u7528\u4e860.4%\u7684\u5b8c\u6574\u8bad\u7ec3\u6570\u636e\u3002", "conclusion": "STARec\u901a\u8fc7\u5f15\u5165\u81ea\u4e3b\u5ba1\u614e\u63a8\u7406\u80fd\u529b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u56e0\u679c\u63a8\u7406\u548c\u7a00\u758f\u6570\u636e\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2508.18880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18880", "abs": "https://arxiv.org/abs/2508.18880", "authors": ["Eljas Linna", "Tuula Linna"], "title": "Judicial Requirements for Generative AI in Legal Reasoning", "comment": null, "summary": "Large Language Models (LLMs) are being integrated into professional domains,\nyet their limitations in high-stakes fields like law remain poorly understood.\nThis paper defines the core capabilities that an AI system must possess to\nfunction as a reliable reasoning tool in judicial decision-making. Using the\nIRAC (Issue-Rule-Application-Conclusion) model as an analytical framework, the\nstudy focuses on the most challenging phases of legal adjudication: determining\nthe applicable Rule (R) and performing the Application (A) of that rule to the\nfacts of a case. From a judicial perspective, the analysis deconstructs legal\nreasoning into a series of core requirements, including the ability to select\nthe correct legal framework across jurisdictions, generate sound arguments\nbased on the doctrine of legal sources, distinguish ratio decidendi from obiter\ndictum in case law, resolve ambiguity arising from general clauses like\n\"reasonableness\", manage conflicting legal provisions, and correctly apply the\nburden of proof. The paper then maps various AI enhancement mechanisms, such as\nRetrieval-Augmented Generation (RAG), multi-agent systems, and neuro-symbolic\nAI, to these requirements, assessing their potential to bridge the gap between\nthe probabilistic nature of LLMs and the rigorous, choice-driven demands of\nlegal interpretation. The findings indicate that while these techniques can\naddress specific challenges, significant challenges remain, particularly in\ntasks requiring discretion and transparent, justifiable reasoning. Our paper\nconcludes that the most effective current role for AI in law is a dual one: as\na high-volume assistant for simple, repetitive cases and as a sophisticated\n\"sparring partner\" for human experts in complex matters.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86LLMs\u5728\u6cd5\u5f8b\u51b3\u7b56\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9a\u4e49\u4e86AI\u7cfb\u7edf\u5728\u53f8\u6cd5\u63a8\u7406\u4e2d\u9700\u8981\u5177\u5907\u7684\u6838\u5fc3\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u4e86RAG\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7b49\u589e\u5f3a\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u7684\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u6574\u5408\u5230\u4e13\u4e1a\u9886\u57df\uff0c\u5176\u5728\u6cd5\u5f8b\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5c40\u9650\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\uff0c\u9700\u8981\u660e\u786eAI\u7cfb\u7edf\u5728\u53f8\u6cd5\u51b3\u7b56\u4e2d\u4f5c\u4e3a\u53ef\u9760\u63a8\u7406\u5de5\u5177\u6240\u9700\u7684\u6838\u5fc3\u80fd\u529b\u3002", "method": "\u4f7f\u7528IRAC\uff08\u95ee\u9898-\u89c4\u5219-\u5e94\u7528-\u7ed3\u8bba\uff09\u6a21\u578b\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u6cd5\u5f8b\u88c1\u51b3\u4e2d\u6700\u5177\u6311\u6218\u6027\u7684\u9636\u6bb5\uff1a\u786e\u5b9a\u9002\u7528\u89c4\u5219\uff08R\uff09\u548c\u5c06\u89c4\u5219\u5e94\u7528\u4e8e\u6848\u4ef6\u4e8b\u5b9e\uff08A\uff09\uff0c\u5e76\u8bc4\u4f30RAG\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u795e\u7ecf\u7b26\u53f7AI\u7b49\u589e\u5f3a\u673a\u5236\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u6280\u672f\u53ef\u4ee5\u89e3\u51b3\u7279\u5b9a\u6311\u6218\uff0c\u4f46\u5728\u9700\u8981\u81ea\u7531\u88c1\u91cf\u6743\u548c\u900f\u660e\u3001\u53ef\u8bba\u8bc1\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u4ecd\u5b58\u5728\u91cd\u5927\u6311\u6218\u3002", "conclusion": "\u76ee\u524dAI\u5728\u6cd5\u5f8b\u4e2d\u6700\u6709\u6548\u7684\u89d2\u8272\u662f\u53cc\u91cd\u7684\uff1a\u4f5c\u4e3a\u7b80\u5355\u91cd\u590d\u6848\u4ef6\u7684\u9ad8\u5bb9\u91cf\u52a9\u624b\uff0c\u4ee5\u53ca\u4f5c\u4e3a\u590d\u6742\u4e8b\u52a1\u4e2d\u4eba\u7c7b\u4e13\u5bb6\u7684\u590d\u6742\"\u966a\u7ec3\u4f19\u4f34\"\u3002"}}
{"id": "2508.18905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18905", "abs": "https://arxiv.org/abs/2508.18905", "authors": ["Dimitrios Rontogiannis", "Maxime Peyrard", "Nicolas Baldwin", "Martin Josifoski", "Robert West", "Dimitrios Gunopulos"], "title": "Interactive Evaluation of Large Language Models for Multi-Requirement Software Engineering Tasks", "comment": null, "summary": "Standard single-turn, static benchmarks fall short in evaluating the nuanced\ncapabilities of Large Language Models (LLMs) on complex tasks such as software\nengineering. In this work, we propose a novel interactive evaluation framework\nthat assesses LLMs on multi-requirement programming tasks through structured,\nfeedback-driven dialogue. Each task is modeled as a requirement dependency\ngraph, and an ``interviewer'' LLM, aware of the ground-truth solution, provides\nminimal, targeted hints to an ``interviewee'' model to help correct errors and\nfulfill target constraints. This dynamic protocol enables fine-grained\ndiagnostic insights into model behavior, uncovering strengths and systematic\nweaknesses that static benchmarks fail to measure. We build on DevAI, a\nbenchmark of 55 curated programming tasks, by adding ground-truth solutions and\nevaluating the relevance and utility of interviewer hints through expert\nannotation. Our results highlight the importance of dynamic evaluation in\nadvancing the development of collaborative code-generating agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u5bfc\u5411\u5bf9\u8bdd\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8981\u6c42\u7f16\u7a0b\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u5145\u5206\u66dd\u9732\u4e86\u9759\u6001\u6d4b\u8bd5\u65e0\u6cd5\u6d4b\u91cf\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u3002", "motivation": "\u6807\u51c6\u7684\u5355\u8f6e\u9759\u6001\u6d4b\u8bd5\u5728\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u8f6f\u4ef6\u5de5\u7a0b\uff09\u4e0a\u7684\u7ec6\u81f4\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u52a8\u6001\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u6bcf\u4e2a\u4efb\u52a1\u6a21\u578b\u5316\u4e3a\u9700\u6c42\u4f9d\u8d56\u56fe\u3002\u4e00\u4e2a\u77e5\u9053\u771f\u5b9e\u89e3\u51b3\u65b9\u6848\u7684\"\u9762\u8bd5\u5b98\"LLM\u5411\"\u9762\u8bd5\u8005\"\u6a21\u578b\u63d0\u4f9b\u6700\u5c0f\u5316\u7684\u9488\u5bf9\u6027\u63d0\u793a\uff0c\u5e2e\u52a9\u5176\u7ea0\u6b63\u9519\u8bef\u5e76\u6ee1\u8db3\u76ee\u6807\u7ea6\u675f\u3002", "result": "\u5728DevAI\u6d4b\u8bd5\u96c6\uff0855\u4e2a\u7f16\u7a0b\u4efb\u52a1\uff09\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u9a8c\u8bc1\u4e86\u9762\u8bd5\u5b98\u63d0\u793a\u7684\u76f8\u5173\u6027\u548c\u6709\u7528\u6027\u3002\u52a8\u6001\u8bc4\u4f30\u63ed\u793a\u4e86\u6a21\u578b\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u3002", "conclusion": "\u52a8\u6001\u8bc4\u4f30\u5bf9\u4e8e\u63a8\u8fdb\u534f\u4f5c\u5f0f\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u63d0\u4f9b\u7ec6\u81f4\u7684\u8bca\u65ad\u89c1\u89e3\uff0c\u8fd9\u662f\u9759\u6001\u6d4b\u8bd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u3002"}}
{"id": "2508.18914", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18914", "abs": "https://arxiv.org/abs/2508.18914", "authors": ["Yanxing Huang", "Xinling Jin", "Sijie Liang", "Peng Li", "Yang Liu"], "title": "FormaRL: Enhancing Autoformalization with no Labeled Data", "comment": "Conference paper at COLM2025", "summary": "Autoformalization is one of the central tasks in formal verification, while\nits advancement remains hindered due to the data scarcity and the absence\nefficient methods. In this work we propose \\textbf{FormaRL}, a simple yet\nefficient reinforcement learning framework for autoformalization which only\nrequires a small amount of unlabeled data. FormaRL integrates syntax check from\nLean compiler and consistency check from large language model to calculate the\nreward, and adopts GRPO algorithm to update the formalizer. We also curated a\nproof problem dataset from undergraduate-level math materials, named\n\\textbf{uproof}, in the hope to facilitate the exploration of autoformalization\nand theorem proving in advanced math. Experiments show that FormaRL can\nincrease the pass@1 autoformalization accuracy of Qwen2.5-Coder-7B-Instruct by\n4 $\\sim$ 6x (4.04\\% $\\to$ 26.15\\% on ProofNet and 2.4\\% $\\to$ 9.6\\% on uproof)\nwith merely 859 unlabeled data. And on uproof our method also achieved a strong\nimprovement in out-of-distribution performance compared to existing open-source\nstate-of-the-art autoformalizers on both pass@1 accuracy (6.2\\% $\\to$ 9.6\\%)\nand pass@16 accuracy (24.4\\% $\\to$ 33.6\\%). Training code of FormaRL is\nopen-sourced at https://github.com/THUNLP-MT/FormaRL.", "AI": {"tldr": "FormaRL\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u4ec5\u9700\u5c11\u91cf\u65e0\u6807\u6ce8\u6570\u636e\uff0c\u901a\u8fc7\u96c6\u6210Lean\u7f16\u8bd1\u5668\u8bed\u6cd5\u68c0\u67e5\u548cLLM\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u8ba1\u7b97\u5956\u52b1\uff0c\u4f7f\u7528GRPO\u7b97\u6cd5\u66f4\u65b0\u5f62\u5f0f\u5316\u5668\uff0c\u5728ProofNet\u548cuproof\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u51c6\u786e\u7387\u3002", "motivation": "\u81ea\u52a8\u5f62\u5f0f\u5316\u662f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u6838\u5fc3\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u7f3a\u4e4f\u9ad8\u6548\u65b9\u6cd5\u800c\u8fdb\u5c55\u7f13\u6162\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51faFormaRL\u6846\u67b6\uff0c\u96c6\u6210Lean\u7f16\u8bd1\u5668\u7684\u8bed\u6cd5\u68c0\u67e5\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u8ba1\u7b97\u5956\u52b1\u4fe1\u53f7\uff0c\u91c7\u7528GRPO\u7b97\u6cd5\u8bad\u7ec3\u5f62\u5f0f\u5316\u5668\u3002\u540c\u65f6\u6784\u5efa\u4e86uproof\u6570\u5b66\u8bc1\u660e\u6570\u636e\u96c6\u3002", "result": "\u5728ProofNet\u6570\u636e\u96c6\u4e0apass@1\u51c6\u786e\u7387\u4ece4.04%\u63d0\u5347\u81f326.15%\uff086\u500d\u63d0\u5347\uff09\uff0c\u5728uproof\u6570\u636e\u96c6\u4e0a\u4ece2.4%\u63d0\u5347\u81f39.6%\uff084\u500d\u63d0\u5347\uff09\uff0c\u4ec5\u4f7f\u7528859\u4e2a\u65e0\u6807\u6ce8\u6570\u636e\u3002\u5728OOD\u6d4b\u8bd5\u4e2d\u4e5f\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "conclusion": "FormaRL\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4ec5\u9700\u5c11\u91cf\u65e0\u6807\u6ce8\u6570\u636e\u5373\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u9ad8\u7ea7\u6570\u5b66\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u548c\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.18925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18925", "abs": "https://arxiv.org/abs/2508.18925", "authors": ["Qian Xiao", "Conn Breathnach", "Ioana Ghergulescu", "Conor O'Sullivan", "Keith Johnston", "Vincent Wade"], "title": "Who Is Lagging Behind: Profiling Student Behaviors with Graph-Level Encoding in Curriculum-Based Online Learning Systems", "comment": null, "summary": "The surge in the adoption of Intelligent Tutoring Systems (ITSs) in\neducation, while being integral to curriculum-based learning, can inadvertently\nexacerbate performance gaps. To address this problem, student profiling becomes\ncrucial for tracking progress, identifying struggling students, and alleviating\ndisparities among students. Such profiling requires measuring student behaviors\nand performance across different aspects, such as content coverage, learning\nintensity, and proficiency in different concepts within a learning topic.\n  In this study, we introduce CTGraph, a graph-level representation learning\napproach to profile learner behaviors and performance in a self-supervised\nmanner. Our experiments demonstrate that CTGraph can provide a holistic view of\nstudent learning journeys, accounting for different aspects of student\nbehaviors and performance, as well as variations in their learning paths as\naligned to the curriculum structure. We also show that our approach can\nidentify struggling students and provide comparative analysis of diverse groups\nto pinpoint when and where students are struggling. As such, our approach opens\nmore opportunities to empower educators with rich insights into student\nlearning journeys and paves the way for more targeted interventions.", "AI": {"tldr": "CTGraph\u662f\u4e00\u79cd\u56fe\u7ea7\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u76d1\u7763\u5730\u5206\u6790\u5b66\u4e60\u8005\u884c\u4e3a\u548c\u8868\u73b0\uff0c\u80fd\u591f\u5168\u9762\u8ffd\u8e2a\u5b66\u751f\u5b66\u4e60\u5386\u7a0b\uff0c\u8bc6\u522b\u56f0\u96be\u5b66\u751f\u5e76\u63d0\u4f9b\u7fa4\u4f53\u5bf9\u6bd4\u5206\u6790\u3002", "motivation": "\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u5728\u6559\u80b2\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u53ef\u80fd\u65e0\u610f\u4e2d\u52a0\u5267\u5b66\u751f\u8868\u73b0\u5dee\u8ddd\uff0c\u9700\u8981\u901a\u8fc7\u5b66\u751f\u753b\u50cf\u6765\u8ddf\u8e2a\u8fdb\u5ea6\u3001\u8bc6\u522b\u56f0\u96be\u5b66\u751f\u5e76\u51cf\u5c11\u5b66\u751f\u95f4\u7684\u5dee\u5f02\u3002", "method": "\u63d0\u51faCTGraph\u56fe\u7ea7\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u91c7\u7528\u81ea\u76d1\u7763\u65b9\u5f0f\u5206\u6790\u5b66\u4e60\u8005\u5728\u5185\u5bb9\u8986\u76d6\u3001\u5b66\u4e60\u5f3a\u5ea6\u548c\u6982\u5ff5\u719f\u7ec3\u5ea6\u7b49\u591a\u65b9\u9762\u7684\u884c\u4e3a\u548c\u8868\u73b0\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCTGraph\u80fd\u591f\u63d0\u4f9b\u5b66\u751f\u5b66\u4e60\u5386\u7a0b\u7684\u5168\u9762\u89c6\u56fe\uff0c\u8003\u8651\u4e0d\u540c\u884c\u4e3a\u8868\u73b0\u65b9\u9762\u548c\u5b66\u4e60\u8def\u5f84\u5dee\u5f02\uff0c\u6709\u6548\u8bc6\u522b\u56f0\u96be\u5b66\u751f\u5e76\u63d0\u4f9b\u7fa4\u4f53\u5bf9\u6bd4\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u6df1\u5165\u4e86\u89e3\u5b66\u751f\u5b66\u4e60\u5386\u7a0b\u7684\u4e30\u5bcc\u6d1e\u5bdf\uff0c\u4e3a\u5b9e\u73b0\u66f4\u6709\u9488\u5bf9\u6027\u7684\u6559\u5b66\u5e72\u9884\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2508.18933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18933", "abs": "https://arxiv.org/abs/2508.18933", "authors": ["David Egea", "Barproda Halder", "Sanghamitra Dutta"], "title": "VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation", "comment": null, "summary": "Automated detection of vulnerabilities in source code is an essential\ncybersecurity challenge, underpinning trust in digital systems and services.\nGraph Neural Networks (GNNs) have emerged as a promising approach as they can\nlearn structural and logical code relationships in a data-driven manner.\nHowever, their performance is severely constrained by training data imbalances\nand label noise. GNNs often learn 'spurious' correlations from superficial code\nsimilarities, producing detectors that fail to generalize well to unseen\nreal-world data. In this work, we propose a unified framework for robust and\ninterpretable vulnerability detection, called VISION, to mitigate spurious\ncorrelations by systematically augmenting a counterfactual training dataset.\nCounterfactuals are samples with minimal semantic modifications but opposite\nlabels. Our framework includes: (i) generating counterfactuals by prompting a\nLarge Language Model (LLM); (ii) targeted GNN training on paired code examples\nwith opposite labels; and (iii) graph-based interpretability to identify the\ncrucial code statements relevant for vulnerability predictions while ignoring\nspurious ones. We find that VISION reduces spurious learning and enables more\nrobust, generalizable detection, improving overall accuracy (from 51.8% to\n97.8%), pairwise contrast accuracy (from 4.5% to 95.8%), and worst-group\naccuracy (from 0.7% to 85.5%) on the Common Weakness Enumeration (CWE)-20\nvulnerability. We further demonstrate gains using proposed metrics: intra-class\nattribution variance, inter-class attribution distance, and node score\ndependency. We also release CWE-20-CFA, a benchmark of 27,556 functions (real\nand counterfactual) from the high-impact CWE-20 category. Finally, VISION\nadvances transparent and trustworthy AI-based cybersecurity systems through\ninteractive visualization for human-in-the-loop analysis.", "AI": {"tldr": "VISION\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u53cd\u4e8b\u5b9e\u6837\u672c\u548c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u51cf\u5c11\u865a\u5047\u76f8\u5173\u6027\uff0c\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u56e0\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6807\u7b7e\u566a\u58f0\u5bfc\u81f4\u7684\u865a\u5047\u76f8\u5173\u6027\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u9ad8\u68c0\u6d4b\u5668\u7684\u6cdb\u5316\u80fd\u529b", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53cd\u4e8b\u5b9e\u6837\u672c\uff0c\u8fdb\u884c\u9488\u5bf9\u6027\u56fe\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u56fe\u7684\u89e3\u91ca\u6027\u65b9\u6cd5\u8bc6\u522b\u5173\u952e\u4ee3\u7801\u8bed\u53e5", "result": "\u5728CWE-20\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\uff0c\u6574\u4f53\u51c6\u786e\u7387\u4ece51.8%\u63d0\u5347\u523097.8%\uff0c\u914d\u5bf9\u5bf9\u6bd4\u51c6\u786e\u7387\u4ece4.5%\u63d0\u5347\u523095.8%\uff0c\u6700\u5dee\u7ec4\u51c6\u786e\u7387\u4ece0.7%\u63d0\u5347\u523085.5%", "conclusion": "VISION\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u865a\u5047\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u63a8\u8fdb\u4e86\u57fa\u4e8eAI\u7684\u7f51\u7edc\u5b89\u5168\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6"}}
{"id": "2508.18953", "categories": ["cs.AI", "I.2.6; I.2.8; I.5.1"], "pdf": "https://arxiv.org/pdf/2508.18953", "abs": "https://arxiv.org/abs/2508.18953", "authors": ["I. I. Priezzhev", "D. A. Danko", "A. V. Shubin"], "title": "Novel Approaches to Artificial Intelligence Development Based on the Nearest Neighbor Method", "comment": "18 pages, 6 figures. Novel hierarchical neural networks based on\n  k-nearest neighbors method for addressing hallucination effects, training\n  complexity, and catastrophic forgetting in modern AI systems. Includes\n  mathematical formulations using Kohonen self-organizing maps and experimental\n  validation on MNIST handwritten digit recognition and machine translation\n  tasks", "summary": "Modern neural network technologies, including large language models, have\nachieved remarkable success in various applied artificial intelligence\napplications, however, they face a range of fundamental limitations. Among them\nare hallucination effects, high computational complexity of training and\ninference, costly fine-tuning, and catastrophic forgetting issues. These\nlimitations significantly hinder the use of neural networks in critical areas\nsuch as medicine, industrial process management, and scientific research. This\narticle proposes an alternative approach based on the nearest neighbors method\nwith hierarchical clustering structures. Employing the k-nearest neighbors\nalgorithm significantly reduces or completely eliminates hallucination effects\nwhile simplifying model expansion and fine-tuning without the need for\nretraining the entire network. To overcome the high computational load of the\nk-nearest neighbors method, the paper proposes using tree-like data structures\nbased on Kohonen self-organizing maps, thereby greatly accelerating nearest\nneighbor searches. Tests conducted on handwritten digit recognition and simple\nsubtitle translation tasks confirmed the effectiveness of the proposed\napproach. With only a slight reduction in accuracy, the nearest neighbor search\ntime was reduced hundreds of times compared to exhaustive search methods. The\nproposed method features transparency and interpretability, closely aligns with\nhuman cognitive mechanisms, and demonstrates potential for extensive use in\ntasks requiring high reliability and explainable results.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u805a\u7c7b\u7ed3\u6784\u7684k\u8fd1\u90bb\u7b97\u6cd5\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u7684\u5e7b\u89c9\u6548\u5e94\u3001\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u7b49\u95ee\u9898\uff0c\u5e76\u901a\u8fc7Kohonen\u81ea\u7ec4\u7ec7\u5730\u56fe\u52a0\u901f\u8fd1\u90bb\u641c\u7d22\u3002", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u5e7b\u89c9\u6548\u5e94\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u5fae\u8c03\u6210\u672c\u9ad8\u3001\u574f\u5931\u5fd8\u7b49\u57fa\u672c\u9650\u5236\uff0c\u5f71\u54cd\u5728\u533b\u7597\u3001\u5de5\u4e1a\u7ba1\u7406\u7b49\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8ek\u8fd1\u90bb\u7b97\u6cd5\u7684\u5c42\u6b21\u805a\u7c7b\u7ed3\u6784\uff0c\u4f7f\u7528Kohonen\u81ea\u7ec4\u7ec7\u5730\u56fe\u6784\u5efa\u6811\u72b6\u6570\u636e\u7ed3\u6784\u6765\u52a0\u901f\u8fd1\u90bb\u641c\u7d22\u3002", "result": "\u5728\u624b\u5199\u6570\u5b57\u8bc6\u522b\u548c\u5b57\u5e55\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5728\u51c6\u786e\u7387\u4e0a\u4ec5\u6709\u8f7b\u5fae\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd1\u90bb\u641c\u7d22\u65f6\u95f4\u6bd4\u5168\u5c40\u641c\u7d22\u51cf\u5c11\u4e86\u767e\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\uff0c\u5728\u9700\u8981\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u7ed3\u679c\u7684\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.18983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18983", "abs": "https://arxiv.org/abs/2508.18983", "authors": ["Guoying Zhu", "Meng Li", "Haipeng Dai", "Xuechen Liu", "Weijun Wang", "Keran Li", "Jun xiao", "Ligeng Chen", "Wei Wang"], "title": "Enabling MoE on the Edge via Importance-Driven Expert Scheduling", "comment": null, "summary": "The Mixture of Experts (MoE) architecture has emerged as a key technique for\nscaling Large Language Models by activating only a subset of experts per query.\nDeploying MoE on consumer-grade edge hardware, however, is constrained by\nlimited device memory, making dynamic expert offloading essential. Unlike prior\nwork that treats offloading purely as a scheduling problem, we leverage expert\nimportance to guide decisions, substituting low-importance activated experts\nwith functionally similar ones already cached in GPU memory, thereby preserving\naccuracy. As a result, this design reduces memory usage and data transfer,\nwhile largely eliminating PCIe overhead. In addition, we introduce a scheduling\npolicy that maximizes the reuse ratio of GPU-cached experts, further boosting\nefficiency. Extensive evaluations show that our approach delivers 48% lower\ndecoding latency with over 60% expert cache hit rate, while maintaining nearly\nlossless accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e13\u5bb6\u91cd\u8981\u6027\u7684\u52a8\u6001\u5378\u8f7d\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528GPU\u5185\u5b58\u4e2d\u5df2\u7f13\u5b58\u7684\u529f\u80fd\u76f8\u4f3c\u4e13\u5bb6\u66ff\u4ee3\u4f4e\u91cd\u8981\u6027\u4e13\u5bb6\uff0c\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u548c\u6570\u636e\u4f20\u8f93\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u6d88\u8d39\u7ea7\u8fb9\u7f18\u786c\u4ef6\u4e0a\u90e8\u7f72\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u53d7\u9650\u4e8e\u8bbe\u5907\u5185\u5b58\uff0c\u9700\u8981\u52a8\u6001\u4e13\u5bb6\u5378\u8f7d\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u5c06\u5378\u8f7d\u89c6\u4e3a\u8c03\u5ea6\u95ee\u9898\uff0c\u800c\u672c\u6587\u5229\u7528\u4e13\u5bb6\u91cd\u8981\u6027\u6765\u6307\u5bfc\u51b3\u7b56\u3002", "method": "\u5229\u7528\u4e13\u5bb6\u91cd\u8981\u6027\u6307\u5bfc\u5378\u8f7d\u51b3\u7b56\uff0c\u7528GPU\u5185\u5b58\u4e2d\u5df2\u7f13\u5b58\u7684\u529f\u80fd\u76f8\u4f3c\u4e13\u5bb6\u66ff\u4ee3\u4f4e\u91cd\u8981\u6027\u6fc0\u6d3b\u4e13\u5bb6\u3002\u5f15\u5165\u8c03\u5ea6\u7b56\u7565\u6700\u5927\u5316GPU\u7f13\u5b58\u4e13\u5bb6\u7684\u91cd\u7528\u7387\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e8648%\u7684\u89e3\u7801\u5ef6\u8fdf\u964d\u4f4e\uff0c\u8d85\u8fc760%\u7684\u4e13\u5bb6\u7f13\u5b58\u547d\u4e2d\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u51e0\u4e4e\u65e0\u635f\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\u548c\u6570\u636e\u4f20\u8f93\uff0c\u5927\u5e45\u6d88\u9664\u4e86PCIe\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u90e8\u7f72\u6548\u7387\u3002"}}
{"id": "2508.19004", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19004", "abs": "https://arxiv.org/abs/2508.19004", "authors": ["Pontus Strimling", "Simon Karlsson", "Irina Vartanova", "Kimmo Eriksson"], "title": "AI Models Exceed Individual Human Accuracy in Predicting Everyday Social Norms", "comment": "18 pages + supplementy materials", "summary": "A fundamental question in cognitive science concerns how social norms are\nacquired and represented. While humans typically learn norms through embodied\nsocial experience, we investigated whether large language models can achieve\nsophisticated norm understanding through statistical learning alone. Across two\nstudies, we systematically evaluated multiple AI systems' ability to predict\nhuman social appropriateness judgments for 555 everyday scenarios by examining\nhow closely they predicted the average judgment compared to each human\nparticipant. In Study 1, GPT-4.5's accuracy in predicting the collective\njudgment on a continuous scale exceeded that of every human participant (100th\npercentile). Study 2 replicated this, with Gemini 2.5 Pro outperforming 98.7%\nof humans, GPT-5 97.8%, and Claude Sonnet 4 96.0%. Despite this predictive\npower, all models showed systematic, correlated errors. These findings\ndemonstrate that sophisticated models of social cognition can emerge from\nstatistical learning over linguistic data alone, challenging strong versions of\ntheories emphasizing the exclusive necessity of embodied experience for\ncultural competence. The systematic nature of AI limitations across different\narchitectures indicates potential boundaries of pattern-based social\nunderstanding, while the models' ability to outperform nearly all individual\nhumans in this predictive task suggests that language serves as a remarkably\nrich repository for cultural knowledge transmission.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u7eaf\u7edf\u8ba1\u5b66\u4e60\u5c31\u80fd\u8d85\u8d8a\u5927\u591a\u6570\u4eba\u7c7b\u5728\u793e\u4ea4\u89c4\u8303\u5224\u65ad\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\uff0c\u6311\u6218\u4e86\u8ba4\u4e3a\u6587\u5316\u80fd\u529b\u5fc5\u987b\u4f9d\u8d56\u5177\u8eab\u7ecf\u9a8c\u7684\u7406\u8bba\u3002", "motivation": "\u7814\u7a76\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u4ec5\u901a\u8fc7\u7edf\u8ba1\u5b66\u4e60\u83b7\u5f97\u590d\u6742\u7684\u793e\u4ea4\u89c4\u8303\u7406\u89e3\uff0c\u800c\u4e0d\u662f\u50cf\u4eba\u7c7b\u90a3\u6837\u901a\u8fc7\u5177\u8eab\u4f53\u9a8c\u6765\u5b66\u4e60\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u591a\u4e2aAI\u7cfb\u7edf\u9884\u6d4b555\u4e2a\u65e5\u5e38\u573a\u666f\u4e2d\u4eba\u7c7b\u793e\u4ea4\u9002\u5f53\u6027\u5224\u65ad\u7684\u80fd\u529b\uff0c\u6bd4\u8f83AI\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u5728\u9884\u6d4b\u96c6\u4f53\u5224\u65ad\u51c6\u786e\u6027\u4e0a\u7684\u8868\u73b0\u3002", "result": "GPT-4.5\u5728\u9884\u6d4b\u96c6\u4f53\u5224\u65ad\u51c6\u786e\u6027\u4e0a\u8d85\u8fc7\u6240\u6709\u4eba\u7c7b\u53c2\u4e0e\u8005\uff08100\u767e\u5206\u4f4d\uff09\uff0cGemini 2.5 Pro\u8d85\u8fc798.7%\u4eba\u7c7b\uff0cGPT-5\u8d85\u8fc797.8%\uff0cClaude Sonnet 4\u8d85\u8fc796.0%\u3002\u6240\u6709\u6a21\u578b\u90fd\u663e\u793a\u51fa\u7cfb\u7edf\u6027\u76f8\u5173\u9519\u8bef\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4ec5\u901a\u8fc7\u8bed\u8a00\u6570\u636e\u7684\u7edf\u8ba1\u5b66\u4e60\u5c31\u80fd\u4ea7\u751f\u590d\u6742\u7684\u793e\u4f1a\u8ba4\u77e5\u6a21\u578b\uff0c\u8bed\u8a00\u4f5c\u4e3a\u6587\u5316\u77e5\u8bc6\u4f20\u64ad\u7684\u4e30\u5bcc\u50a8\u5b58\u5e93\uff0c\u4f46\u57fa\u4e8e\u6a21\u5f0f\u7684\u793e\u4f1a\u7406\u89e3\u5b58\u5728\u6f5c\u5728\u8fb9\u754c\u3002"}}
{"id": "2508.19005", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.19005", "abs": "https://arxiv.org/abs/2508.19005", "authors": ["Yuxuan Cai", "Yipeng Hao", "Jie Zhou", "Hang Yan", "Zhikai Lei", "Rui Zhen", "Zhenhua Han", "Yutao Yang", "Junsong Li", "Qianjun Pan", "Tianyu Huai", "Qin Chen", "Xin Li", "Kai Chen", "Bo Zhang", "Xipeng Qiu", "Liang He"], "title": "Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark", "comment": null, "summary": "As AI advances toward general intelligence, the focus is shifting from\nsystems optimized for static tasks to creating open-ended agents that learn\ncontinuously. In this paper, we introduce Experience-driven Lifelong Learning\n(ELL), a framework for building self-evolving agents capable of continuous\ngrowth through real-world interaction. The framework is built on four core\nprinciples: (1) Experience Exploration: Agents learn through continuous,\nself-motivated interaction with dynamic environments, navigating interdependent\ntasks and generating rich experiential trajectories. (2) Long-term Memory:\nAgents preserve and structure historical knowledge, including personal\nexperiences, domain expertise, and commonsense reasoning, into a persistent\nmemory system. (3) Skill Learning: Agents autonomously improve by abstracting\nrecurring patterns from experience into reusable skills, which are actively\nrefined and validated for application in new tasks. (4) Knowledge\nInternalization: Agents internalize explicit and discrete experiences into\nimplicit and intuitive capabilities as \"second nature\".\n  We also introduce StuLife, a benchmark dataset for ELL that simulates a\nstudent's holistic college journey, from enrollment to academic and personal\ndevelopment, across three core phases and ten detailed sub-scenarios. StuLife\nis designed around three key paradigm shifts: From Passive to Proactive, From\nContext to Memory, and From Imitation to Learning. In this dynamic environment,\nagents must acquire and distill practical skills and maintain persistent memory\nto make decisions based on evolving state variables. StuLife provides a\ncomprehensive platform for evaluating lifelong learning capabilities, including\nmemory retention, skill transfer, and self-motivated behavior. Beyond\nevaluating SOTA LLMs on the StuLife benchmark, we also explore the role of\ncontext engineering in advancing AGI.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u7ecf\u9a8c\u9a71\u52a8\u7684\u7ec8\u8eab\u5b66\u4e60\uff08ELL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u5927\u6838\u5fc3\u539f\u5219\u5efa\u7acb\u81ea\u6211\u8fdb\u5316\u7684\u667a\u80fd\u4f53\uff0c\u5e76\u521b\u5efa\u4e86StuLife\u6807\u51c6\u6570\u636e\u96c6\u6a21\u62df\u5927\u5b66\u751f\u5168\u9762\u53d1\u5c55\u8fc7\u7a0b\u3002", "motivation": "\u968f\u7740AI\u5411\u901a\u7528\u667a\u80fd\u53d1\u5c55\uff0c\u9700\u8981\u4ece\u9759\u6001\u4efb\u52a1\u4f18\u5316\u8f6c\u5411\u5efa\u7acb\u80fd\u591f\u6301\u7eed\u5b66\u4e60\u548c\u6210\u957f\u7684\u5f00\u653e\u5f0f\u4ee3\u7406\u4f53\u3002", "method": "\u63d0\u51faELL\u6846\u67b6\u5305\u542b\u56db\u5927\u6838\u5fc3\u539f\u5219\uff1a\u7ecf\u9a8c\u63a2\u7d22\u3001\u957f\u671f\u8bb0\u5fc6\u3001\u6280\u80fd\u5b66\u4e60\u548c\u77e5\u8bc6\u5185\u5316\u3002\u521b\u5efaStuLife\u6807\u51c6\u6570\u636e\u96c6\uff0c\u6a21\u62df\u5927\u5b66\u751f\u4ece\u5165\u5b66\u5230\u5b66\u4e1a\u53d1\u5c55\u7684\u5168\u8fc7\u7a0b\uff0c\u5305\u542b3\u4e2a\u9636\u6bb5\u548c10\u4e2a\u5b50\u573a\u666f\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u8bc4\u4f30\u5e73\u53f0\uff0c\u80fd\u591f\u6d4b\u8bd5\u8bb0\u5fc6\u4fdd\u6301\u3001\u6280\u80fd\u8fc1\u79fb\u548c\u81ea\u4e3b\u884c\u4e3a\u7b49\u80fd\u529b\u3002\u8fd8\u8bc4\u4f30\u4e86\u73b0\u6709\u6700\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u6807\u51c6\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "ELL\u6846\u67b6\u548cStuLife\u6807\u51c6\u4e3a\u5efa\u7acb\u80fd\u591f\u6301\u7eed\u5b66\u4e60\u548c\u81ea\u6211\u8fdb\u5316\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u540c\u65f6\u4e5f\u63a2\u7d22\u4e86\u4e0a\u4e0b\u6587\u5de5\u7a0b\u5728\u63a8\u52a8\u901a\u7528\u667a\u80fd\u53d1\u5c55\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2508.19008", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19008", "abs": "https://arxiv.org/abs/2508.19008", "authors": ["Marcin Moskalewicz", "Anna Sterna", "Marek Pokropski", "Paula Flores"], "title": "Sense of Self and Time in Borderline Personality. A Comparative Robustness Study with Generative AI", "comment": "22 pages, 4 tables, submitted to \"Personality and Individual\n  Differences\"", "summary": "This study examines the capacity of large language models (LLMs) to support\nphenomenological qualitative analysis of first-person experience in Borderline\nPersonality Disorder (BPD), understood as a disorder of temporality and\nselfhood. Building on a prior human-led thematic analysis of 24 inpatients'\nlife-story interviews, we compared three LLMs (OpenAI GPT-4o, Google Gemini 2.5\nPro, Anthropic Claude Opus 4) prompted to mimic the interpretative style of the\noriginal investigators. The models were evaluated with blinded and non-blinded\nexpert judges in phenomenology and clinical psychology. Assessments included\nsemantic congruence, Jaccard coefficients, and multidimensional validity\nratings (credibility, coherence, substantiveness, and groundness in data).\nResults showed variable overlap with the human analysis, from 0 percent in GPT\nto 42 percent in Claude and 58 percent in Gemini, and a low Jaccard coefficient\n(0.21-0.28). However, the models recovered themes omitted by humans. Gemini's\noutput most closely resembled the human analysis, with validity scores\nsignificantly higher than GPT and Claude (p < 0.0001), and was judged as human\nby blinded experts. All scores strongly correlated (R > 0.78) with the quantity\nof text and words per theme, highlighting both the variability and potential of\nAI-augmented thematic analysis to mitigate human interpretative bias.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u3001Gemini 2.5 Pro\u3001Claude Opus 4\uff09\u5728\u8fb9\u7f18\u578b\u4eba\u683c\u969c\u788d\u73b0\u8c61\u5b66\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Gemini\u6a21\u578b\u6700\u63a5\u8fd1\u4eba\u7c7b\u5206\u6790\u7ed3\u679c\uff0c\u5e76\u80fd\u53d1\u73b0\u4eba\u7c7b\u9057\u6f0f\u7684\u4e3b\u9898\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u8c61\u5b66\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u578b\u4eba\u683c\u969c\u788d\u8fd9\u79cd\u6d89\u53ca\u65f6\u95f4\u6027\u548c\u81ea\u6211\u610f\u8bc6\u969c\u788d\u7684\u590d\u6742\u5fc3\u7406\u72b6\u6001\u5206\u6790\u4e2d\uff0c\u4ee5\u51cf\u8f7b\u4eba\u7c7b\u89e3\u91ca\u504f\u89c1\u3002", "method": "\u57fa\u4e8e24\u540d\u4f4f\u9662\u60a3\u8005\u7684\u751f\u6d3b\u6545\u4e8b\u8bbf\u8c08\u6570\u636e\uff0c\u8ba9\u4e09\u79cdLLM\u6a21\u4eff\u539f\u7814\u7a76\u8005\u7684\u89e3\u91ca\u98ce\u683c\u8fdb\u884c\u5206\u6790\uff0c\u91c7\u7528\u76f2\u6cd5\u548c\u975e\u76f2\u6cd5\u4e13\u5bb6\u8bc4\u4f30\uff0c\u5305\u62ec\u8bed\u4e49\u4e00\u81f4\u6027\u3001Jaccard\u7cfb\u6570\u548c\u591a\u7ef4\u6548\u5ea6\u8bc4\u5206\u3002", "result": "\u6a21\u578b\u4e0e\u4eba\u7c7b\u5206\u6790\u7684\u91cd\u5408\u5ea6\u5dee\u5f02\u8f83\u5927\uff08GPT 0%\u3001Claude 42%\u3001Gemini 58%\uff09\uff0cJaccard\u7cfb\u6570\u8f83\u4f4e\uff080.21-0.28\uff09\u3002\u4f46\u6a21\u578b\u53d1\u73b0\u4e86\u4eba\u7c7b\u9057\u6f0f\u7684\u4e3b\u9898\uff0cGemini\u7684\u8868\u73b0\u6700\u63a5\u8fd1\u4eba\u7c7b\u5206\u6790\uff0c\u6548\u5ea6\u8bc4\u5206\u663e\u8457\u9ad8\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "AI\u589e\u5f3a\u7684\u4e3b\u9898\u5206\u6790\u5177\u6709\u6f5c\u529b\u548c\u53d8\u5f02\u6027\uff0c\u80fd\u591f\u8865\u5145\u4eba\u7c7b\u5206\u6790\u7684\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u91cf\u6587\u672c\u6570\u636e\u65f6\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u4e3a\u51cf\u8f7b\u4eba\u7c7b\u89e3\u91ca\u504f\u89c1\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2508.19014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19014", "abs": "https://arxiv.org/abs/2508.19014", "authors": ["Surajit Das", "Gourav Roy", "Aleksei Eliseev", "Ram Kumar Rajendran"], "title": "MAB Optimizer for Estimating Math Question Difficulty via Inverse CV without NLP", "comment": null, "summary": "The evolution of technology and education is driving the emergence of\nIntelligent & Autonomous Tutoring Systems (IATS), where objective and\ndomain-agnostic methods for determining question difficulty are essential.\nTraditional human labeling is subjective, and existing NLP-based approaches\nfail in symbolic domains like algebra. This study introduces the Approach of\nPassive Measures among Educands (APME), a reinforcement learning-based\nMulti-Armed Bandit (MAB) framework that estimates difficulty solely from solver\nperformance data -- marks obtained and time taken -- without requiring\nlinguistic features or expert labels. By leveraging the inverse coefficient of\nvariation as a risk-adjusted metric, the model provides an explainable and\nscalable mechanism for adaptive assessment. Empirical validation was conducted\non three heterogeneous datasets. Across these diverse contexts, the model\nachieved an average R2 of 0.9213 and an average RMSE of 0.0584, confirming its\nrobustness, accuracy, and adaptability to different educational levels and\nassessment formats. Compared with baseline approaches-such as regression-based,\nNLP-driven, and IRT models-the proposed framework consistently outperformed\nalternatives, particularly in purely symbolic domains. The findings highlight\nthat (i) item heterogeneity strongly influences perceived difficulty, and (ii)\nvariance in solver outcomes is as critical as mean performance for adaptive\nallocation. Pedagogically, the model aligns with Vygotskys Zone of Proximal\nDevelopment by identifying tasks that balance challenge and attainability,\nsupporting motivation while minimizing disengagement. This domain-agnostic,\nself-supervised approach advances difficulty tagging in IATS and can be\nextended beyond algebra wherever solver interaction data is available", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6APME\uff0c\u4ec5\u4f7f\u7528\u89e3\u9898\u8868\u73b0\u6570\u636e\uff08\u5206\u6570\u548c\u65f6\u95f4\uff09\u6765\u4f30\u8ba1\u95ee\u9898\u96be\u5ea6\uff0c\u65e0\u9700\u8bed\u8a00\u7279\u5f81\u6216\u4e13\u5bb6\u6807\u6ce8\uff0c\u5728\u7b26\u53f7\u9886\u57df\u8868\u73b0\u4f18\u5f02", "motivation": "\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u4e3b\u89c2\u6027\u5f3a\uff0c\u73b0\u6709NLP\u65b9\u6cd5\u5728\u4ee3\u6570\u7b49\u7b26\u53f7\u9886\u57df\u5931\u6548\uff0c\u9700\u8981\u5ba2\u89c2\u4e14\u9886\u57df\u65e0\u5173\u7684\u95ee\u9898\u96be\u5ea6\u786e\u5b9a\u65b9\u6cd5", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\uff0c\u5229\u7528\u9006\u53d8\u5f02\u7cfb\u6570\u4f5c\u4e3a\u98ce\u9669\u8c03\u6574\u6307\u6807\uff0c\u4ec5\u4ece\u89e3\u9898\u8868\u73b0\u6570\u636e\uff08\u5206\u6570\u548c\u65f6\u95f4\uff09\u4f30\u8ba1\u96be\u5ea6", "result": "\u5728\u4e09\u4e2a\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5e73\u5747R\u00b2\u8fbe0.9213\uff0c\u5e73\u5747RMSE\u4e3a0.0584\uff0c\u4f18\u4e8e\u56de\u5f52\u3001NLP\u548cIRT\u7b49\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u9886\u57df\u65e0\u5173\u3001\u81ea\u76d1\u7763\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6709\u89e3\u9898\u4ea4\u4e92\u6570\u636e\u7684\u9886\u57df\uff0c\u652f\u6301\u7ef4\u679c\u8328\u57fa\u6700\u8fd1\u53d1\u5c55\u533a\u7406\u8bba\uff0c\u5e73\u8861\u6311\u6218\u6027\u4e0e\u53ef\u8fbe\u6027"}}
{"id": "2508.19035", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19035", "abs": "https://arxiv.org/abs/2508.19035", "authors": ["Congchi Yin", "Tianyi Wu", "Yankai Shu", "Alex Gu", "Yunhan Wang", "Jun Shao", "Xun Jiang", "Piji Li"], "title": "Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction", "comment": null, "summary": "Existing tasks fall short in evaluating reasoning ability of Large Language\nModels (LLMs) in an interactive, unknown environment. This deficiency leads to\nthe isolated assessment of deductive, inductive, and abductive reasoning,\nneglecting the integrated reasoning process that is indispensable for humans\ndiscovery of real world. We introduce a novel evaluation paradigm,\n\\textit{black-box interaction}, to tackle this challenge. A black-box is\ndefined by a hidden function that maps a specific set of inputs to outputs.\nLLMs are required to unravel the hidden function behind the black-box by\ninteracting with it in given exploration turns, and reasoning over observed\ninput-output pairs. Leveraging this idea, we build the \\textsc{Oracle}\nbenchmark which comprises 6 types of black-box task and 96 black-boxes. 19\nmodern LLMs are benchmarked. o3 ranks first in 5 of the 6 tasks, achieving over\n70\\% accuracy on most easy black-boxes. But it still struggles with some hard\nblack-box tasks, where its average performance drops below 40\\%. Further\nanalysis indicates a universal difficulty among LLMs: They lack the high-level\nplanning capability to develop efficient and adaptive exploration strategies\nfor hypothesis refinement.", "AI": {"tldr": "\u9ed1\u76d2\u4ea4\u4e92\u8bc4\u4f30\u6846\u67b6\u7528\u4e8e\u6d4b\u8bd5LLM\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u7efc\u5408\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0LLM\u7f3a\u4e4f\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b", "motivation": "\u73b0\u6709\u4efb\u52a1\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u4e92\u5f0f\u672a\u77e5\u73af\u5883\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u5f0f", "method": "\u63d0\u51fa\u9ed1\u76d2\u4ea4\u4e92\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9690\u85cf\u51fd\u6570\u6a21\u62df\u672a\u77e5\u73af\u5883\uff0c\u5efa\u7acb\u5305\u542b6\u7c7b\u4efb\u52a1\u7684Oracle\u6d4b\u8bd5\u96c6\uff0c\u5bf919\u4e2a\u73b0\u4ee3LLM\u8fdb\u884c\u6d4b\u8bd5", "result": "o3\u6a21\u578b\u57285\u4e2a\u4efb\u52a1\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u5728\u7b80\u5355\u9ed1\u76d2\u4e0a\u8fbe\u523070%+\u51c6\u786e\u7387\uff0c\u4f46\u5728\u56f0\u96be\u9ed1\u76d2\u4e0a\u6027\u80fd\u4e0b\u964d\u523040%\u4ee5\u4e0b", "conclusion": "LLM\u666e\u904d\u7f3a\u4e4f\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b\uff0c\u65e0\u6cd5\u5236\u5b9a\u9ad8\u6548\u7684\u9002\u5e94\u6027\u63a2\u7d22\u7b56\u7565\u6765\u7cbe\u70bc\u5047\u8bbe\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347"}}
{"id": "2508.19042", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19042", "abs": "https://arxiv.org/abs/2508.19042", "authors": ["Norihiro Maruyama", "Takahide Yoshida", "Hiroki Sato", "Atsushi Masumori", "Johnsmith", "Takashi Ikegami"], "title": "A Concurrent Modular Agent: Framework for Autonomous LLM Agents", "comment": null, "summary": "We introduce the Concurrent Modular Agent (CMA), a framework that\norchestrates multiple Large-Language-Model (LLM)-based modules that operate\nfully asynchronously yet maintain a coherent and fault-tolerant behavioral\nloop. This framework addresses long-standing difficulties in agent\narchitectures by letting intention emerge from language-mediated interactions\namong autonomous processes. This approach enables flexible, adaptive, and\ncontext-dependent behavior through the combination of concurrently executed\nmodules that offload reasoning to an LLM, inter-module communication, and a\nsingle shared global state.We consider this approach to be a practical\nrealization of Minsky's Society of Mind theory. We demonstrate the viability of\nour system through two practical use-case studies. The emergent properties\nobserved in our system suggest that complex cognitive phenomena like\nself-awareness may indeed arise from the organized interaction of simpler\nprocesses, supporting Minsky-Society of Mind concept and opening new avenues\nfor artificial intelligence research. The source code for our work is available\nat: https://github.com/AlternativeMachine/concurrent-modular-agent.", "AI": {"tldr": "CMA\u6846\u67b6\u901a\u8fc7\u591a\u4e2a\u5f02\u6b65\u8fd0\u884c\u7684LLM\u6a21\u5757\u5b9e\u73b0\u534f\u8c03\u7684\u884c\u4e3a\u5faa\u73af\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u957f\u671f\u96be\u9898\uff0c\u8ba9\u610f\u56fe\u4ece\u8bed\u8a00\u4ecb\u5bfc\u7684\u81ea\u4e3b\u8fdb\u7a0b\u4ea4\u4e92\u4e2d\u6d8c\u73b0\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u667a\u80fd\u4f53\u67b6\u6784\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5e76\u53d1\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u66f4\u7075\u6d3b\u3001\u81ea\u9002\u5e94\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u884c\u4e3a\uff0c\u9a8c\u8bc1Minsky\u7684\"\u5fc3\u667a\u793e\u4f1a\"\u7406\u8bba\u3002", "method": "\u4f7f\u7528\u591a\u4e2a\u57fa\u4e8eLLM\u7684\u6a21\u5757\u5b8c\u5168\u5f02\u6b65\u8fd0\u884c\uff0c\u901a\u8fc7\u6a21\u5757\u95f4\u901a\u4fe1\u548c\u5355\u4e00\u5171\u4eab\u5168\u5c40\u72b6\u6001\u6765\u5b9e\u73b0\u534f\u8c03\uff0c\u5c06\u63a8\u7406\u4efb\u52a1\u5378\u8f7d\u7ed9LLM\u5904\u7406\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9645\u7528\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u89c2\u5bdf\u5230\u6d8c\u73b0\u7279\u6027\u8868\u660e\u590d\u6742\u8ba4\u77e5\u73b0\u8c61\uff08\u5982\u81ea\u6211\u610f\u8bc6\uff09\u53ef\u80fd\u786e\u5b9e\u4ece\u7b80\u5355\u8fc7\u7a0b\u7684\u7ec4\u7ec7\u4ea4\u4e92\u4e2d\u4ea7\u751f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301Minsky\u7684\u5fc3\u667a\u793e\u4f1a\u6982\u5ff5\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u662f\u5fc3\u667a\u793e\u4f1a\u7406\u8bba\u7684\u5b9e\u9645\u5b9e\u73b0\u3002"}}
{"id": "2508.19069", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19069", "abs": "https://arxiv.org/abs/2508.19069", "authors": ["Zhichao Yang", "Zhaoxin Fan", "Gen Li", "Yuanze Hu", "Xinyu Wang", "Ye Qiu", "Xin Wang", "Yifan Sun", "Wenjun Wu"], "title": "Can Structured Templates Facilitate LLMs in Tackling Harder Tasks? : An Exploration of Scaling Laws by Difficulty", "comment": "9 pages", "summary": "Structured, procedural reasoning is essential for Large Language Models\n(LLMs), especially in mathematics. While post-training methods have improved\nLLM performance, they still fall short in capturing deep procedural logic on\ncomplex tasks. To tackle the issue, in this paper, we first investigate this\nlimitation and uncover a novel finding: a Scaling Law by Difficulty, which\nreveals that model performance follows a U-shaped curve with respect to\ntraining data complexity -- excessive low-difficulty data impedes abstraction,\nwhile high-difficulty data significantly enhances reasoning ability. Motivated\nby this, we propose the Structured Solution Template (SST) framework, which\nuses solution templates and a curriculum of varied difficulty to explicitly\nteach procedural reasoning. Specifically, SST comprises (1) fine-tuning with\nstructured solution-template chains and dynamically weighted loss to prioritize\nprocedural logic, (2) prompt-time injection of solution templates as cognitive\nscaffolds to guide inference, and (3) integrated curriculum fine-tuning that\nexplicitly teaches the model to self-plan - execute - self-correct. Experiments\non GSM8K, AIME24, and new Dynamic En benchmark show that SST significantly\nimproves both accuracy and efficiency, especially on harder problems.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u96be\u5ea6\u4e0e\u6a21\u578b\u6027\u80fd\u5448U\u578b\u66f2\u7ebf\u5173\u7cfb\uff0c\u63d0\u51fa\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u6a21\u677f(SST)\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u677f\u5316\u89e3\u51b3\u65b9\u6848\u94fe\u548c\u96be\u5ea6\u8bfe\u7a0b\u6765\u663e\u5f0f\u6559\u6388\u7a0b\u5e8f\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u540e\u8bad\u7ec3\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4ecd\u96be\u4ee5\u6355\u6349\u6df1\u5c42\u7a0b\u5e8f\u903b\u8f91\uff0c\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u4e0e\u8bad\u7ec3\u6570\u636e\u96be\u5ea6\u5b58\u5728U\u578b\u66f2\u7ebf\u5173\u7cfb\uff08\u96be\u5ea6\u7f29\u653e\u5b9a\u5f8b\uff09\uff0c\u8fc7\u5ea6\u7b80\u5355\u6570\u636e\u963b\u788d\u62bd\u8c61\u80fd\u529b\uff0c\u800c\u9ad8\u96be\u5ea6\u6570\u636e\u663e\u8457\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u6a21\u677f(SST)\u6846\u67b6\uff1a1)\u4f7f\u7528\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u6a21\u677f\u94fe\u548c\u52a8\u6001\u52a0\u6743\u635f\u5931\u8fdb\u884c\u5fae\u8c03\uff1b2)\u63a8\u7406\u65f6\u6ce8\u5165\u89e3\u51b3\u65b9\u6848\u6a21\u677f\u4f5c\u4e3a\u8ba4\u77e5\u652f\u67b6\uff1b3)\u96c6\u6210\u8bfe\u7a0b\u5fae\u8c03\uff0c\u663e\u5f0f\u6559\u6388\u6a21\u578b\u81ea\u6211\u89c4\u5212-\u6267\u884c-\u81ea\u6211\u7ea0\u6b63\u3002", "result": "\u5728GSM8K\u3001AIME24\u548c\u65b0\u7684Dynamic En\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cSST\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u66f4\u96be\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "SST\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u677f\u548c\u96be\u5ea6\u8bfe\u7a0b\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u663e\u5f0f\u6559\u6388\u7a0b\u5e8f\u903b\u8f91\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u6570\u5b66\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2508.19096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19096", "abs": "https://arxiv.org/abs/2508.19096", "authors": ["Yongwoo Song", "Minbyul Jeong", "Mujeen Sung"], "title": "Trustworthy Agents for Electronic Health Records through Confidence Estimation", "comment": null, "summary": "Large language models (LLMs) show promise for extracting information from\nElectronic Health Records (EHR) and supporting clinical decisions. However,\ndeployment in clinical settings faces challenges due to hallucination risks. We\npropose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric\nquantifying the accuracy-reliability trade-off at varying confidence\nthresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating\nstepwise confidence estimation for clinical question answering. Experiments on\nMIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under\nstrict reliability constraints, achieving improvements of 44.23%p and 25.34%p\nat HCAcc@70% while baseline methods fail at these thresholds. These results\nhighlight limitations of traditional accuracy metrics in evaluating healthcare\nAI agents. Our work contributes to developing trustworthy clinical agents that\ndeliver accurate information or transparently express uncertainty when\nconfidence is low.", "AI": {"tldr": "\u63d0\u51fa\u4e86HCAcc@k%\u65b0\u6307\u6807\u6765\u91cf\u5316\u4e34\u5e8a\u95ee\u7b54\u4e2d\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u9760\u6027\u6743\u8861\uff0c\u5e76\u5f00\u53d1\u4e86TrustEHRAgent\u7f6e\u4fe1\u611f\u77e5\u4ee3\u7406\uff0c\u5728\u4e25\u683c\u53ef\u9760\u6027\u7ea6\u675f\u4e0b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4fe1\u606f\u63d0\u53d6\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u98ce\u9669\uff0c\u9650\u5236\u4e86\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5e94\u7528", "method": "\u63d0\u51faHallucination Controlled Accuracy at k% (HCAcc@k%)\u6307\u6807\uff0c\u5e76\u5f00\u53d1TrustEHRAgent\u7f6e\u4fe1\u611f\u77e5\u4ee3\u7406\uff0c\u91c7\u7528\u9010\u6b65\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u8fdb\u884c\u4e34\u5e8a\u95ee\u7b54", "result": "\u5728MIMIC-III\u548ceICU\u6570\u636e\u96c6\u4e0a\uff0cTrustEHRAgent\u5728HCAcc@70%\u6307\u6807\u4e0b\u5206\u522b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u534744.23%\u548c25.34%\uff0c\u57fa\u7ebf\u65b9\u6cd5\u5728\u8fd9\u4e9b\u9608\u503c\u4e0b\u5b8c\u5168\u5931\u6548", "conclusion": "\u4f20\u7edf\u51c6\u786e\u6027\u6307\u6807\u5728\u8bc4\u4f30\u533b\u7597AI\u4ee3\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u5f00\u53d1\u53ef\u4fe1\u8d56\u7684\u4e34\u5e8a\u4ee3\u7406\uff0c\u80fd\u591f\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u65f6\u63d0\u4f9b\u51c6\u786e\u4fe1\u606f\u6216\u900f\u660e\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027"}}
{"id": "2508.19097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19097", "abs": "https://arxiv.org/abs/2508.19097", "authors": ["Armin Berger", "Sarthak Khanna", "David Berghaus", "Rafet Sifa"], "title": "Reasoning LLMs in the Medical Domain: A Literature Survey", "comment": null, "summary": "The emergence of advanced reasoning capabilities in Large Language Models\n(LLMs) marks a transformative development in healthcare applications. Beyond\nmerely expanding functional capabilities, these reasoning mechanisms enhance\ndecision transparency and explainability-critical requirements in medical\ncontexts. This survey examines the transformation of medical LLMs from basic\ninformation retrieval tools to sophisticated clinical reasoning systems capable\nof supporting complex healthcare decisions. We provide a thorough analysis of\nthe enabling technological foundations, with a particular focus on specialized\nprompting techniques like Chain-of-Thought and recent breakthroughs in\nReinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates\npurpose-built medical frameworks while also examining emerging paradigms such\nas multi-agent collaborative systems and innovative prompting architectures.\nThe survey critically assesses current evaluation methodologies for medical\nvalidation and addresses persistent challenges in field interpretation\nlimitations, bias mitigation strategies, patient safety frameworks, and\nintegration of multimodal clinical data. Through this survey, we seek to\nestablish a roadmap for developing reliable LLMs that can serve as effective\npartners in clinical practice and medical research.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u53d1\u5c55\uff0c\u4ece\u57fa\u7840\u4fe1\u606f\u68c0\u7d22\u5de5\u5177\u8f6c\u53d8\u4e3a\u652f\u6301\u590d\u6742\u533b\u7597\u51b3\u7b56\u7684\u4e34\u5e8a\u63a8\u7406\u7cfb\u7edf\uff0c\u91cd\u70b9\u5173\u6ce8\u63d0\u793a\u6280\u672f\u548c\u5f3a\u5316\u5b66\u4e60\u7a81\u7834\u3002", "motivation": "\u968f\u7740LLMs\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\uff0c\u533b\u7597\u5e94\u7528\u9700\u8981\u66f4\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8fd9\u5bf9\u533b\u7597\u73af\u5883\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u8fd9\u4e00\u8f6c\u578b\u8fc7\u7a0b\u5e76\u4e3a\u5f00\u53d1\u53ef\u9760\u7684\u533b\u7597LLMs\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002", "method": "\u901a\u8fc7\u5168\u9762\u5206\u6790\u6280\u672f\u57fa\u7840\uff0c\u7279\u522b\u5173\u6ce8\u4e13\u4e1a\u5316\u63d0\u793a\u6280\u672f\uff08\u5982\u601d\u7ef4\u94fe\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u7a81\u7834\uff08\u5982DeepSeek-R1\uff09\uff0c\u8bc4\u4f30\u4e13\u7528\u533b\u7597\u6846\u67b6\u548c\u65b0\u5174\u8303\u5f0f\uff08\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\u548c\u521b\u65b0\u63d0\u793a\u67b6\u6784\uff09\u3002", "result": "\u5bf9\u533b\u7597\u9a8c\u8bc1\u7684\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u8fdb\u884c\u4e86\u6279\u5224\u6027\u8bc4\u4f30\uff0c\u89e3\u51b3\u4e86\u9886\u57df\u89e3\u91ca\u9650\u5236\u3001\u504f\u5dee\u7f13\u89e3\u7b56\u7565\u3001\u60a3\u8005\u5b89\u5168\u6846\u67b6\u548c\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u96c6\u6210\u7b49\u6301\u7eed\u6311\u6218\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f00\u53d1\u80fd\u591f\u5728\u4e34\u5e8a\u5b9e\u8df5\u548c\u533b\u5b66\u7814\u7a76\u4e2d\u4f5c\u4e3a\u6709\u6548\u5408\u4f5c\u4f19\u4f34\u7684\u53ef\u9760LLMs\u5efa\u7acb\u4e86\u53d1\u5c55\u8def\u7ebf\u56fe\uff0c\u63a8\u52a8\u533b\u7597AI\u5411\u66f4\u5b89\u5168\u3001\u900f\u660e\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2508.19113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19113", "abs": "https://arxiv.org/abs/2508.19113", "authors": ["Dayoon Ko", "Jihyuk Kim", "Haeju Park", "Sohyeon Kim", "Dahyun Lee", "Yongrae Jo", "Gunhee Kim", "Moontae Lee", "Kyungjae Lee"], "title": "Hybrid Deep Searcher: Integrating Parallel and Sequential Search Reasoning", "comment": null, "summary": "Large reasoning models (LRMs) have demonstrated strong performance in\ncomplex, multi-step reasoning tasks. Existing methods enhance LRMs by\nsequentially integrating external knowledge retrieval; models iteratively\ngenerate queries, retrieve external information, and progressively reason over\nthis information. However, purely sequential querying increases inference\nlatency and context length, diminishing coherence and potentially reducing\naccuracy. To address these limitations, we introduce HDS-QA (Hybrid Deep Search\nQA), a synthetic dataset automatically generated from Natural Questions,\nexplicitly designed to train LRMs to distinguish parallelizable from sequential\nqueries. HDS-QA comprises hybrid-hop questions that combine parallelizable\nindependent subqueries (executable simultaneously) and sequentially dependent\nsubqueries (requiring step-by-step resolution), along with synthetic\nreasoning-querying-retrieval paths involving parallel queries. We fine-tune an\nLRM using HDS-QA, naming the model HybridDeepSearcher, which outperforms\nstate-of-the-art baselines across multiple benchmarks, notably achieving +15.9\nand +11.5 F1 on FanOutQA and a subset of BrowseComp, respectively, both\nrequiring comprehensive and exhaustive search. Experimental results highlight\ntwo key advantages: HybridDeepSearcher reaches comparable accuracy with fewer\nsearch turns, significantly reducing inference latency, and it effectively\nscales as more turns are permitted. These results demonstrate the efficiency,\nscalability, and effectiveness of explicitly training LRMs to leverage hybrid\nparallel and sequential querying.", "AI": {"tldr": "HDS-QA\u662f\u4e00\u4e2a\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\u533a\u5206\u5e76\u884c\u548c\u987a\u5e8f\u67e5\u8be2\uff0cHybridDeepSearcher\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u987a\u5e8f\u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u4f1a\u589e\u52a0\u63a8\u7406\u5ef6\u8fdf\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u964d\u4f4e\u8fde\u8d2f\u6027\u548c\u51c6\u786e\u6027\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u4eceNatural Questions\u81ea\u52a8\u751f\u6210HDS-QA\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b\u5e76\u884c\u53ef\u6267\u884c\u548c\u987a\u5e8f\u4f9d\u8d56\u7684\u5b50\u67e5\u8be2\uff0c\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u5fae\u8c03LRM\u5f97\u5230HybridDeepSearcher\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728FanOutQA\u548cBrowseComp\u5b50\u96c6\u4e0a\u5206\u522b\u83b7\u5f97+15.9\u548c+11.5 F1\u63d0\u5347\uff0c\u4ee5\u66f4\u5c11\u7684\u641c\u7d22\u8f6e\u6b21\u8fbe\u5230\u53ef\u6bd4\u7cbe\u5ea6\u3002", "conclusion": "\u663e\u5f0f\u8bad\u7ec3LRM\u5229\u7528\u6df7\u5408\u5e76\u884c\u548c\u987a\u5e8f\u67e5\u8be2\u5177\u6709\u9ad8\u6548\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002"}}
{"id": "2508.19149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19149", "abs": "https://arxiv.org/abs/2508.19149", "authors": ["Claudio Battiloro", "Pietro Greiner", "Bret Nestor", "Oumaima Amezgar", "Francesca Dominici"], "title": "Algorithmic Collective Action with Multiple Collectives", "comment": "12 pages", "summary": "As learning systems increasingly influence everyday decisions, user-side\nsteering via Algorithmic Collective Action (ACA)-coordinated changes to shared\ndata-offers a complement to regulator-side policy and firm-side model design.\nAlthough real-world actions have been traditionally decentralized and\nfragmented into multiple collectives despite sharing overarching\nobjectives-with each collective differing in size, strategy, and actionable\ngoals, most of the ACA literature focused on single collective settings. In\nthis work, we present the first theoretical framework for ACA with multiple\ncollectives acting on the same system. In particular, we focus on collective\naction in classification, studying how multiple collectives can plant signals,\ni.e., bias a classifier to learn an association between an altered version of\nthe features and a chosen, possibly overlapping, set of target classes. We\nprovide quantitative results about the role and the interplay of collectives'\nsizes and their alignment of goals. Our framework, by also complementing\nprevious empirical results, opens a path for a holistic treatment of ACA with\nmultiple collectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u96c6\u4f53\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\uff08ACA\uff09\u7406\u8bba\u6846\u67b6\uff0c\u7814\u7a76\u591a\u4e2a\u96c6\u4f53\u5982\u4f55\u5728\u5206\u7c7b\u7cfb\u7edf\u4e2d\u534f\u8c03\u884c\u52a8\uff0c\u901a\u8fc7\u690d\u5165\u4fe1\u53f7\u6765\u5f71\u54cd\u5206\u7c7b\u5668\u5b66\u4e60\u7279\u5f81\u4e0e\u76ee\u6807\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\u3002", "motivation": "\u968f\u7740\u5b66\u4e60\u7cfb\u7edf\u5bf9\u65e5\u5e38\u51b3\u7b56\u7684\u5f71\u54cd\u65e5\u76ca\u589e\u5f3a\uff0c\u7528\u6237\u7aef\u7684\u7b97\u6cd5\u96c6\u4f53\u884c\u52a8\uff08ACA\uff09\u4f5c\u4e3a\u76d1\u7ba1\u7aef\u653f\u7b56\u548c\u4f01\u4e1a\u7aef\u6a21\u578b\u8bbe\u8ba1\u7684\u8865\u5145\u624b\u6bb5\u53d8\u5f97\u91cd\u8981\u3002\u4f20\u7edf\u4e0a\u73b0\u5b9e\u4e16\u754c\u7684\u884c\u52a8\u662f\u5206\u6563\u7684\uff0c\u7531\u591a\u4e2a\u5177\u6709\u5171\u540c\u76ee\u6807\u4f46\u89c4\u6a21\u3001\u7b56\u7565\u548c\u884c\u52a8\u76ee\u6807\u4e0d\u540c\u7684\u96c6\u4f53\u7ec4\u6210\uff0c\u800c\u73b0\u6709ACA\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u96c6\u4f53\u573a\u666f\u3002", "method": "\u5efa\u7acb\u4e86\u591a\u96c6\u4f53ACA\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7279\u522b\u5173\u6ce8\u5206\u7c7b\u4e2d\u7684\u96c6\u4f53\u884c\u52a8\uff0c\u7814\u7a76\u591a\u4e2a\u96c6\u4f53\u5982\u4f55\u901a\u8fc7\u690d\u5165\u4fe1\u53f7\u6765\u504f\u7f6e\u5206\u7c7b\u5668\uff0c\u4f7f\u5176\u5b66\u4e60\u7279\u5f81\u4fee\u6539\u7248\u672c\u4e0e\u9009\u5b9a\u76ee\u6807\u7c7b\u522b\u4e4b\u95f4\u7684\u5173\u8054\u3002\u5206\u6790\u4e86\u96c6\u4f53\u89c4\u6a21\u548c\u76ee\u6807\u5bf9\u9f50\u5ea6\u7684\u4f5c\u7528\u4e0e\u76f8\u4e92\u5173\u7cfb\u3002", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8e\u96c6\u4f53\u89c4\u6a21\u548c\u76ee\u6807\u5bf9\u9f50\u5ea6\u4f5c\u7528\u7684\u5b9a\u91cf\u7ed3\u679c\uff0c\u6846\u67b6\u8865\u5145\u4e86\u5148\u524d\u7684\u5b9e\u8bc1\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u96c6\u4f53ACA\u7684\u6574\u4f53\u5904\u7406\u5f00\u8f9f\u4e86\u8def\u5f84\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u5728\u591a\u4e2a\u96c6\u4f53\u534f\u8c03\u884c\u52a8\u65b9\u9762\u7684\u7406\u8bba\u7a7a\u767d\u3002"}}
{"id": "2508.19152", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SC"], "pdf": "https://arxiv.org/pdf/2508.19152", "abs": "https://arxiv.org/abs/2508.19152", "authors": ["Chiu-Chou Lin"], "title": "Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games", "comment": "PhD Dissertation, National Yang Ming Chiao Tung University, 2025.\n  This is the public version without Chinese abstract or postscript", "summary": "Contemporary artificial intelligence (AI) development largely centers on\nrational decision-making, valued for its measurability and suitability for\nobjective evaluation. Yet in real-world contexts, an intelligent agent's\ndecisions are shaped not only by logic but also by deeper influences such as\nbeliefs, values, and preferences. The diversity of human decision-making styles\nemerges from these differences, highlighting that \"style\" is an essential but\noften overlooked dimension of intelligence.\n  This dissertation introduces playstyle as an alternative lens for observing\nand analyzing the decision-making behavior of intelligent agents, and examines\nits foundational meaning and historical context from a philosophical\nperspective. By analyzing how beliefs and values drive intentions and actions,\nwe construct a two-tier framework for style formation: the external interaction\nloop with the environment and the internal cognitive loop of deliberation. On\nthis basis, we formalize style-related characteristics and propose measurable\nindicators such as style capacity, style popularity, and evolutionary dynamics.\n  The study focuses on three core research directions: (1) Defining and\nmeasuring playstyle, proposing a general playstyle metric based on discretized\nstate spaces, and extending it to quantify strategic diversity and competitive\nbalance; (2) Expressing and generating playstyle, exploring how reinforcement\nlearning and imitation learning can be used to train agents exhibiting specific\nstylistic tendencies, and introducing a novel approach for human-like style\nlearning and modeling; and (3) Practical applications, analyzing the potential\nof these techniques in domains such as game design and interactive\nentertainment.\n  Finally, the dissertation outlines future extensions, including the role of\nstyle as a core element in building artificial general intelligence (AGI).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u6e38\u620f\u98ce\u683c\u4f5c\u4e3a\u5206\u6790\u667a\u80fd\u4f53\u51b3\u7b56\u884c\u4e3a\u7684\u65b0\u89c6\u89d2\uff0c\u6784\u5efa\u4e86\u98ce\u683c\u5f62\u6210\u7684\u53cc\u5c42\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u6d4b\u91cf\u7684\u98ce\u683c\u6307\u6807\uff0c\u63a2\u7d22\u4e86\u98ce\u683c\u7684\u5b9a\u4e49\u3001\u8868\u8fbe\u548c\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5f53\u524dAI\u53d1\u5c55\u8fc7\u4e8e\u5173\u6ce8\u7406\u6027\u51b3\u7b56\uff0c\u5ffd\u89c6\u4e86\u4fe1\u5ff5\u3001\u4ef7\u503c\u89c2\u548c\u504f\u597d\u7b49\u6df1\u5c42\u56e0\u7d20\u5bf9\u51b3\u7b56\u98ce\u683c\u7684\u5f71\u54cd\uff0c\u800c\u98ce\u683c\u662f\u667a\u80fd\u7684\u91cd\u8981\u4f46\u5e38\u88ab\u5ffd\u89c6\u7684\u7ef4\u5ea6\u3002", "method": "\u6784\u5efa\u98ce\u683c\u5f62\u6210\u7684\u53cc\u5c42\u6846\u67b6\uff08\u5916\u90e8\u73af\u5883\u4ea4\u4e92\u5faa\u73af\u548c\u5185\u90e8\u8ba4\u77e5\u601d\u8003\u5faa\u73af\uff09\uff0c\u63d0\u51fa\u98ce\u683c\u5bb9\u91cf\u3001\u98ce\u683c\u6d41\u884c\u5ea6\u548c\u8fdb\u5316\u52a8\u6001\u7b49\u53ef\u6d4b\u91cf\u6307\u6807\uff0c\u7814\u7a76\u98ce\u683c\u5b9a\u4e49\u6d4b\u91cf\u3001\u8868\u8fbe\u751f\u6210\u548c\u5b9e\u9645\u5e94\u7528\u4e09\u4e2a\u65b9\u5411\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u7684\u901a\u7528\u6e38\u620f\u98ce\u683c\u5ea6\u91cf\u65b9\u6cd5\uff0c\u63a2\u7d22\u4e86\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\u5728\u8bad\u7ec3\u7279\u5b9a\u98ce\u683c\u667a\u80fd\u4f53\u4e2d\u7684\u5e94\u7528\uff0c\u5f00\u53d1\u4e86\u7c7b\u4eba\u98ce\u683c\u5b66\u4e60\u548c\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u98ce\u683c\u5e94\u4f5c\u4e3a\u6784\u5efa\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u7684\u6838\u5fc3\u8981\u7d20\uff0c\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u548c\u53d1\u5c55\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u98ce\u683c\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u65b9\u6cd5\u3002"}}
{"id": "2508.19163", "categories": ["cs.AI", "cs.HC", "cs.MA", "68T50, 68T42, 92C50, 68Q60", "I.2.0; J.3"], "pdf": "https://arxiv.org/pdf/2508.19163", "abs": "https://arxiv.org/abs/2508.19163", "authors": ["Ernest Lim", "Yajie Vera He", "Jared Joselowitz", "Kate Preston", "Mohita Chowdhury", "Louis Williams", "Aisling Higham", "Katrina Mason", "Mariane Melo", "Tom Lawton", "Yan Jia", "Ibrahim Habli"], "title": "MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation", "comment": "36 pages, 16 figures", "summary": "Despite the growing use of large language models (LLMs) in clinical dialogue\nsystems, existing evaluations focus on task completion or fluency, offering\nlittle insight into the behavioral and risk management requirements essential\nfor safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion\nfRamework for safe Interactions and conteXtual clinical conversational\nevaluation), a structured, extensible framework for safety-oriented evaluation\nof clinical dialogue agents.\n  MATRIX integrates three components: (1) a safety-aligned taxonomy of clinical\nscenarios, expected system behaviors and failure modes derived through\nstructured safety engineering methods; (2) BehvJudge, an LLM-based evaluator\nfor detecting safety-relevant dialogue failures, validated against expert\nclinician annotations; and (3) PatBot, a simulated patient agent capable of\nproducing diverse, scenario-conditioned responses, evaluated for realism and\nbehavioral fidelity with human factors expertise, and a patient-preference\nstudy.\n  Across three experiments, we show that MATRIX enables systematic, scalable\nsafety evaluation. BehvJudge with Gemini 2.5-Pro achieves expert-level hazard\ndetection (F1 0.96, sensitivity 0.999), outperforming clinicians in a blinded\nassessment of 240 dialogues. We also conducted one of the first realism\nanalyses of LLM-based patient simulation, showing that PatBot reliably\nsimulates realistic patient behavior in quantitative and qualitative\nevaluations. Using MATRIX, we demonstrate its effectiveness in benchmarking\nfive LLM agents across 2,100 simulated dialogues spanning 14 hazard scenarios\nand 10 clinical domains.\n  MATRIX is the first framework to unify structured safety engineering with\nscalable, validated conversational AI evaluation, enabling regulator-aligned\nsafety auditing. We release all evaluation tools, prompts, structured\nscenarios, and datasets.", "AI": {"tldr": "MATRIX\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\u7684\u591a\u667a\u80fd\u4f53\u4eff\u771f\u6846\u67b6\uff0c\u6574\u5408\u4e86\u5b89\u5168\u5bf9\u9f50\u5206\u7c7b\u6cd5\u3001\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5668\u548c\u6a21\u62df\u60a3\u8005\u4ee3\u7406\uff0c\u5b9e\u73b0\u4e86\u7cfb\u7edf\u6027\u3001\u53ef\u6269\u5c55\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u5b8c\u6210\u5ea6\u548c\u6d41\u7545\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u6240\u9700\u7684\u884c\u4e3a\u548c\u98ce\u9669\u7ba1\u7406\u8981\u6c42\u7684\u6df1\u5165\u5206\u6790\u3002", "method": "MATRIX\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u901a\u8fc7\u5b89\u5168\u5de5\u7a0b\u65b9\u6cd5\u63a8\u5bfc\u7684\u4e34\u5e8a\u573a\u666f\u5206\u7c7b\u6cd5\uff1b2\uff09\u57fa\u4e8eLLM\u7684\u5b89\u5168\u76f8\u5173\u5bf9\u8bdd\u5931\u8d25\u68c0\u6d4b\u8bc4\u4f30\u5668BehvJudge\uff1b3\uff09\u80fd\u591f\u4ea7\u751f\u591a\u6837\u5316\u573a\u666f\u6761\u4ef6\u54cd\u5e94\u7684\u6a21\u62df\u60a3\u8005\u4ee3\u7406PatBot\u3002", "result": "BehvJudge\u8fbe\u5230\u4e13\u5bb6\u7ea7\u5371\u9669\u68c0\u6d4b\u6c34\u5e73\uff08F1 0.96\uff0c\u7075\u654f\u5ea60.999\uff09\uff0c\u5728240\u4e2a\u5bf9\u8bdd\u7684\u76f2\u8bc4\u4e2d\u4f18\u4e8e\u4e34\u5e8a\u533b\u751f\u3002PatBot\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u4e2d\u53ef\u9760\u5730\u6a21\u62df\u771f\u5b9e\u60a3\u8005\u884c\u4e3a\u3002\u6846\u67b6\u6210\u529f\u5bf95\u4e2aLLM\u4ee3\u7406\u57282100\u4e2a\u6a21\u62df\u5bf9\u8bdd\u4e2d\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "MATRIX\u662f\u9996\u4e2a\u5c06\u7ed3\u6784\u5316\u5b89\u5168\u5de5\u7a0b\u4e0e\u53ef\u6269\u5c55\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5bf9\u8bddAI\u8bc4\u4f30\u76f8\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u652f\u6301\u76d1\u7ba1\u673a\u6784\u5bf9\u9f50\u7684\u5b89\u5168\u5ba1\u8ba1\uff0c\u4e3a\u4e34\u5e8a\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.19200", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.19200", "abs": "https://arxiv.org/abs/2508.19200", "authors": ["Xinran Zhao", "Boyuan Zheng", "Chenglei Si", "Haofei Yu", "Ken Liu", "Runlong Zhou", "Ruochen Li", "Tong Chen", "Xiang Li", "Yiming Zhang", "Tongshuang Wu"], "title": "The Ramon Llull's Thinking Machine for Automated Ideation", "comment": "21 pages, 3 figures", "summary": "This paper revisits Ramon Llull's Ars combinatoria - a medieval framework for\ngenerating knowledge through symbolic recombination - as a conceptual\nfoundation for building a modern Llull's thinking machine for research\nideation. Our approach defines three compositional axes: Theme (e.g.,\nefficiency, adaptivity), Domain (e.g., question answering, machine\ntranslation), and Method (e.g., adversarial training, linear attention). These\nelements represent high-level abstractions common in scientific work -\nmotivations, problem settings, and technical approaches - and serve as building\nblocks for LLM-driven exploration. We mine elements from human experts or\nconference papers and show that prompting LLMs with curated combinations\nproduces research ideas that are diverse, relevant, and grounded in current\nliterature. This modern thinking machine offers a lightweight, interpretable\ntool for augmenting scientific creativity and suggests a path toward\ncollaborative ideation between humans and AI.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u63a2\u8ba8\u4e2d\u4e16\u7eaaRamon Llull\u7684\u7ec4\u5408\u672f\uff0c\u6784\u5efa\u4e86\u4e00\u79cd\u73b0\u4ee3\u5316\u7684\u601d\u7ef4\u673a\u5668\uff0c\u901a\u8fc7\u4e3b\u9898\u3001\u9886\u57df\u548c\u65b9\u6cd5\u4e09\u4e2a\u7ec4\u6210\u8f74\u6765\u751f\u6210\u79d1\u7814\u521b\u610f\u3002", "motivation": "\u91cd\u65b0\u6d3b\u5316\u4e2d\u4e16\u7eaa\u7684\u7ec4\u5408\u672f\u7406\u8bba\uff0c\u4e3a\u73b0\u4ee3\u79d1\u7814\u521b\u610f\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\uff0c\u901a\u8fc7AI\u589e\u5f3a\u79d1\u5b66\u521b\u9020\u529b\u3002", "method": "\u5b9a\u4e49\u4e3b\u9898\u3001\u9886\u57df\u548c\u65b9\u6cd5\u4e09\u4e2a\u7ec4\u6210\u8f74\uff0c\u4ece\u4e13\u5bb6\u6216\u8bba\u6587\u4e2d\u6316\u6398\u5143\u7d20\uff0c\u4f7f\u7528LLM\u63d0\u793a\u7ec4\u5408\u6765\u751f\u6210\u79d1\u7814\u60f3\u6cd5\u3002", "result": "\u7ec4\u5408\u63d0\u793a\u4ea7\u751f\u7684\u79d1\u7814\u60f3\u6cd5\u5177\u6709\u591a\u6837\u6027\u3001\u76f8\u5173\u6027\u548c\u6587\u732e\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u73b0\u4ee3\u601d\u7ef4\u673a\u5668\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u79d1\u5b66\u521b\u610f\u5de5\u5177\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u534f\u4f5c\u521b\u610f\u5f00\u542f\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2508.19218", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19218", "abs": "https://arxiv.org/abs/2508.19218", "authors": ["Yufei Wu", "Manuel R. Torres", "Parisa Zehtabi", "Alberto Pozanco Lancho", "Michael Cashmore", "Daniel Borrajo", "Manuela Veloso"], "title": "The Subset Sum Matching Problem", "comment": "Paper accepted at ECAI 2025. This is an extended version that\n  includes Supplementary Material", "summary": "This paper presents a new combinatorial optimisation task, the Subset Sum\nMatching Problem (SSMP), which is an abstraction of common financial\napplications such as trades reconciliation. We present three algorithms, two\nsuboptimal and one optimal, to solve this problem. We also generate a benchmark\nto cover different instances of SSMP varying in complexity, and carry out an\nexperimental evaluation to assess the performance of the approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5b50\u96c6\u548c\u5339\u914d\u95ee\u9898(SSMP)\u4f5c\u4e3a\u91d1\u878d\u4ea4\u6613\u5bf9\u8d26\u7b49\u5e94\u7528\u7684\u62bd\u8c61\uff0c\u5f00\u53d1\u4e86\u4e24\u4e2a\u6b21\u4f18\u7b97\u6cd5\u548c\u4e00\u4e2a\u6700\u4f18\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u6027\u80fd", "motivation": "\u89e3\u51b3\u91d1\u878d\u9886\u57df\u4e2d\u7684\u4ea4\u6613\u5bf9\u8d26\u7b49\u5b9e\u9645\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u901a\u7528\u7684\u7ec4\u5408\u4f18\u5316\u6a21\u578b\u6765\u5339\u914d\u4e0d\u540c\u96c6\u5408\u4e2d\u7684\u5143\u7d20", "method": "\u63d0\u51fa\u4e86SSMP\u95ee\u9898\u5b9a\u4e49\uff0c\u5f00\u53d1\u4e86\u4e24\u79cd\u6b21\u4f18\u7b97\u6cd5\u548c\u4e00\u79cd\u6700\u4f18\u7b97\u6cd5\uff0c\u521b\u5efa\u4e86\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e09\u79cd\u7b97\u6cd5\u5728\u4e0d\u540c\u590d\u6742\u5ea6SSMP\u5b9e\u4f8b\u4e0a\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "SSMP\u95ee\u9898\u4e3a\u91d1\u878d\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8be5\u95ee\u9898"}}
{"id": "2508.19229", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.19229", "abs": "https://arxiv.org/abs/2508.19229", "authors": ["Wei Xiong", "Wenting Zhao", "Weizhe Yuan", "Olga Golovneva", "Tong Zhang", "Jason Weston", "Sainbayar Sukhbaatar"], "title": "StepWiser: Stepwise Generative Judges for Wiser Reasoning", "comment": null, "summary": "As models increasingly leverage multi-step reasoning strategies to solve\ncomplex problems, supervising the logical validity of these intermediate steps\nhas become a critical research challenge. Process reward models address this by\nproviding step-by-step feedback, but current approaches have two major\ndrawbacks: they typically function as classifiers without providing\nexplanations, and their reliance on supervised fine-tuning with static datasets\nlimits generalization. Inspired by recent advances, we reframe stepwise reward\nmodeling from a classification task to a reasoning task itself. We thus propose\na generative judge that reasons about the policy model's reasoning steps (i.e.,\nmeta-reasons), outputting thinking tokens before delivering a final verdict.\nOur model, StepWiser, is trained by reinforcement learning using relative\noutcomes of rollouts. We show it provides (i) better judgment accuracy on\nintermediate steps than existing methods; (ii) can be used to improve the\npolicy model at training time; and (iii) improves inference-time search.", "AI": {"tldr": "\u5c06\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4ece\u5206\u7c7b\u4efb\u52a1\u91cd\u6784\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u51faStepWiser\u751f\u6210\u5f0f\u8bc4\u5224\u5668\uff0c\u901a\u8fc7\u5143\u63a8\u7406\u8f93\u51fa\u601d\u8003\u6807\u8bb0\u548c\u6700\u7ec8\u5224\u65ad\uff0c\u5728\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u6539\u8fdb\u548c\u63a8\u7406\u641c\u7d22\u65b9\u9762\u8868\u73b0\u4f18\u5f02", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u7f3a\u9677\uff1a\u4f5c\u4e3a\u5206\u7c7b\u5668\u4e0d\u63d0\u4f9b\u89e3\u91ca\uff0c\u4e14\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\u76d1\u7763\u5fae\u8c03\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u5f00\u53d1\u80fd\u7406\u89e3\u63a8\u7406\u6b65\u9aa4\u903b\u8f91\u6709\u6548\u6027\u7684\u65b9\u6cd5", "method": "\u5c06\u9010\u6b65\u5956\u52b1\u5efa\u6a21\u91cd\u6784\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u51fa\u751f\u6210\u5f0f\u8bc4\u5224\u5668StepWiser\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528rollout\u76f8\u5bf9\u7ed3\u679c\u8fdb\u884c\u8bad\u7ec3\uff0c\u8f93\u51fa\u601d\u8003\u6807\u8bb0\u540e\u518d\u7ed9\u51fa\u6700\u7ec8\u5224\u65ad", "result": "StepWiser\u5728\u4e2d\u95f4\u6b65\u9aa4\u5224\u65ad\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u6539\u8fdb\u7b56\u7565\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u63d0\u5347\u63a8\u7406\u65f6\u7684\u641c\u7d22\u6027\u80fd", "conclusion": "\u5c06\u5956\u52b1\u5efa\u6a21\u4ece\u5206\u7c7b\u8f6c\u5411\u63a8\u7406\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u7a0b\u76d1\u7763\u7684\u6311\u6218\uff0c\u751f\u6210\u5f0f\u8bc4\u5224\u5668\u5728\u63d0\u4f9b\u89e3\u91ca\u7684\u540c\u65f6\u63d0\u5347\u4e86\u5224\u65ad\u51c6\u786e\u6027\u548c\u6a21\u578b\u6027\u80fd"}}
{"id": "2508.19239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19239", "abs": "https://arxiv.org/abs/2508.19239", "authors": ["Gaurab Chhetri", "Shriyank Somvanshi", "Md Monzurul Islam", "Shamyo Brotee", "Mahmuda Sultana Mimi", "Dipti Koirala", "Biplov Pandey", "Subasish Das"], "title": "Model Context Protocols in Adaptive Transport Systems: A Survey", "comment": null, "summary": "The rapid expansion of interconnected devices, autonomous systems, and AI\napplications has created severe fragmentation in adaptive transport systems,\nwhere diverse protocols and context sources remain isolated. This survey\nprovides the first systematic investigation of the Model Context Protocol (MCP)\nas a unifying paradigm, highlighting its ability to bridge protocol-level\nadaptation with context-aware decision making. Analyzing established\nliterature, we show that existing efforts have implicitly converged toward\nMCP-like architectures, signaling a natural evolution from fragmented solutions\nto standardized integration frameworks. We propose a five-category taxonomy\ncovering adaptive mechanisms, context-aware frameworks, unification models,\nintegration strategies, and MCP-enabled architectures. Our findings reveal\nthree key insights: traditional transport protocols have reached the limits of\nisolated adaptation, MCP's client-server and JSON-RPC structure enables\nsemantic interoperability, and AI-driven transport demands integration\nparadigms uniquely suited to MCP. Finally, we present a research roadmap\npositioning MCP as a foundation for next-generation adaptive, context-aware,\nand intelligent transport infrastructures.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8c03\u67e5\u4e86\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u4f5c\u4e3a\u7edf\u4e00\u8303\u5f0f\u7684\u80fd\u529b\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6587\u732e\u5982\u4f55\u9690\u5f0f\u5730\u5411MCP\u7c7b\u67b6\u6784\u6536\u655b\uff0c\u63d0\u51fa\u4e86\u4e94\u7c7b\u5206\u7c7b\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u4e09\u4e2a\u5173\u952e\u89c1\u89e3\u3002", "motivation": "\u4e92\u8054\u8bbe\u5907\u3001\u81ea\u4e3b\u7cfb\u7edf\u548cAI\u5e94\u7528\u7684\u5feb\u901f\u6269\u5f20\u5bfc\u81f4\u81ea\u9002\u5e94\u4f20\u8f93\u7cfb\u7edf\u4e25\u91cd\u788e\u7247\u5316\uff0c\u4e0d\u540c\u534f\u8bae\u548c\u4e0a\u4e0b\u6587\u6765\u6e90\u76f8\u4e92\u9694\u79bb\uff0c\u9700\u8981\u7edf\u4e00\u7684\u96c6\u6210\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6587\u732e\uff0c\u63d0\u51fa\u4e94\u7c7b\u5206\u7c7b\u6cd5\uff08\u81ea\u9002\u5e94\u673a\u5236\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\u3001\u7edf\u4e00\u6a21\u578b\u3001\u96c6\u6210\u7b56\u7565\u548cMCP\u4f7f\u80fd\u67b6\u6784\uff09\uff0c\u7cfb\u7edf\u8c03\u67e5MCP\u4f5c\u4e3a\u7edf\u4e00\u8303\u5f0f\u7684\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u4f20\u7edf\u4f20\u8f93\u534f\u8bae\u5df2\u8fbe\u5230\u5b64\u7acb\u9002\u5e94\u7684\u6781\u9650\uff0cMCP\u7684\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u548cJSON-RPC\u7ed3\u6784\u80fd\u591f\u5b9e\u73b0\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0cAI\u9a71\u52a8\u7684\u4f20\u8f93\u9700\u8981\u7279\u522b\u9002\u5408MCP\u7684\u96c6\u6210\u8303\u5f0f\u3002", "conclusion": "MCP\u5e94\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u9002\u5e94\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u667a\u80fd\u4f20\u8f93\u57fa\u7840\u8bbe\u65bd\u7684\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7814\u7a76\u8def\u7ebf\u56fe\u3002"}}
