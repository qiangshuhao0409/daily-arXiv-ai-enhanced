{"id": "2510.00477", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00477", "abs": "https://arxiv.org/abs/2510.00477", "authors": ["Chengzhen Li", "Likun Zhang", "Chuang Zhang", "Jiahui Li", "Changyuan Zhao", "Ruichen Zhang", "Geng Sun"], "title": "Wireless Laser Power Transfer for Low-altitude Uncrewed Aerial Vehicle-assisted Internet of Things: Paradigms, Challenges, and Solutions", "comment": "This paper has been submitted to IEEE Internet of Things Magazine", "summary": "Low-altitude uncrewed aerial vehicles (UAVs) have become integral enablers\nfor the Internet of Things (IoT) by offering enhanced coverage, improved\nconnectivity and access to remote areas. A critical challenge limiting their\noperational capacity lies in the energy constraints of both aerial platforms\nand ground-based sensors. This paper explores WLPT as a transformative solution\nfor sustainable energy provisioning in UAV-assisted IoT networks. We first\nsystematically investigate the fundamental principles of WLPT and analysis the\ncomparative advantages. Then, we introduce three operational paradigms for\nsystem integration, identify key challenges, and discuss corresponding\npotential solutions. In case study, we propose a multi-agent reinforcement\nlearning framework to address the coordination and optimization challenges in\nWLPT-enabled UAV-assisted IoT data collection. Simulation results demonstrate\nthat our framework significantly improves energy sustainability and data\nfreshness. Finally, we discuss some future directions."}
{"id": "2510.00481", "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.MM", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.00481", "abs": "https://arxiv.org/abs/2510.00481", "authors": ["Jiayang Xu", "Xiangjie Huang", "Zijie Li", "Zili Meng"], "title": "Make a Video Call with LLM: A Measurement Campaign over Five Mainstream Apps", "comment": null, "summary": "In 2025, Large Language Model (LLM) services have launched a new feature --\nAI video chat -- allowing users to interact with AI agents via real-time video\ncommunication (RTC), just like chatting with real people. Despite its\nsignificance, no systematic study has characterized the performance of existing\nAI video chat systems. To address this gap, this paper proposes a comprehensive\nbenchmark with carefully designed metrics across four dimensions: quality,\nlatency, internal mechanisms, and system overhead. Using custom testbeds, we\nfurther evaluate five mainstream AI video chatbots with this benchmark. This\nwork provides the research community a baseline of real-world performance and\nidentifies unique system bottlenecks. In the meantime, our benchmarking results\nalso open up several research questions for future optimizations of AI video\nchatbots."}
{"id": "2510.00588", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.00588", "abs": "https://arxiv.org/abs/2510.00588", "authors": ["Almamoon Alauthman"], "title": "Dynamic Low Power Traffic Pattern for Energy Constrained Wireless Sensor Networks", "comment": null, "summary": "Wireless Sensor Networks (WSNs) are extensively utilized in critical\napplications, including remote monitoring, target tracking, healthcare systems,\nindustrial automation, and smart control in both residential and industrial\nsettings. One of the primary challenges in these systems is maintaining energy\nefficiency, given that most sensor nodes rely on limited battery resources. To\ntackle this problem, this study introduces an energy-saving strategy designed\nfor tree-structured networks with dynamic traffic patterns. The approach\nfocuses on lowering power usage by decreasing the length and occurrence of idle\nlistening state where nodes remain active unnecessarily while waiting for data\ntransmissions that may never occur. By reducing this form of energy waste, the\nproposed approach is designed to extend the operational lifetime and enhance\nthe throughput of the wireless sensor network. Simulation results obtained\nusing the OMNeT++ simulator with the MiXiM framework demonstrate that the\nsolution significantly reduces energy consumption, increases data throughput,\nand improves overall network efficiency and longevity."}
{"id": "2510.00735", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.00735", "abs": "https://arxiv.org/abs/2510.00735", "authors": ["Georgia Fragkouli", "Laurent Vanbever"], "title": "Faster Offloads by Unloading them -- The RDMA Case", "comment": "7 pages, 3 figures", "summary": "From hardware offloads like RDMA to software ones like eBPF, offloads are\neverywhere and their value is in performance. However, there is evidence that\nfully offloading -- even when feasible -- does not always give the expected\nspeedups. Starting from the observation that this is due to changes the\noffloads make -- by moving tasks from the application/CPU closer to the\nnetwork/link layer -- we argue that to further accelerate offloads, we need to\nmake offloads reversible by unloading them -- moving back part of the offloaded\ntasks.\n  Unloading comes with a set of challenges that we start answering in this\npaper by focusing on (offloaded) RDMA writes: which part of the write operation\ndoes it make sense to unload? how do we dynamically decide which writes to\nexecute on the unload or offload path to improve performance? how do we\nmaintain compatibility between the two paths? Our current prototype shows the\npotential of unloading by accelerating RDMA writes by up to 31%."}
{"id": "2510.00079", "categories": ["cs.IT", "cs.LG", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.00079", "abs": "https://arxiv.org/abs/2510.00079", "authors": ["Hai Huang"], "title": "Directed Information $γ$-covering: An Information-Theoretic Framework for Context Engineering", "comment": "15 pages, 6 tables, preprint", "summary": "We introduce \\textbf{Directed Information $\\gamma$-covering}, a simple but\ngeneral framework for redundancy-aware context engineering. Directed\ninformation (DI), a causal analogue of mutual information, measures asymmetric\npredictiveness between chunks. If $\\operatorname{DI}_{i \\to j} \\ge H(C_j) -\n\\gamma$, then $C_i$ suffices to represent $C_j$ up to $\\gamma$ bits. Building\non this criterion, we formulate context selection as a $\\gamma$-cover problem\nand propose a greedy algorithm with provable guarantees: it preserves query\ninformation within bounded slack, inherits $(1+\\ln n)$ and $(1-1/e)$\napproximations from submodular set cover, and enforces a diversity margin.\nImportantly, building the $\\gamma$-cover is \\emph{query-agnostic}: it incurs no\nonline cost and can be computed once offline and amortized across all queries.\nExperiments on HotpotQA show that $\\gamma$-covering consistently improves over\nBM25, a competitive baseline, and provides clear advantages in hard-decision\nregimes such as context compression and single-slot prompt selection. These\nresults establish DI $\\gamma$-covering as a principled, self-organizing\nbackbone for modern LLM pipelines."}
{"id": "2510.00022", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00022", "abs": "https://arxiv.org/abs/2510.00022", "authors": ["Ansh Kamthan"], "title": "Learning to Lead Themselves: Agentic AI in MAS using MARL", "comment": "Exploring foundational behaviours of agentic ai using MARL 39 pages -\n  25 minute read, 5 tables, 24 equation, 9 figures", "summary": "As autonomous systems move from prototypes to real deployments, the ability\nof multiple agents to make decentralized, cooperative decisions becomes a core\nrequirement. This paper examines how agentic artificial intelligence, agents\nthat act independently, adaptively and proactively can improve task allocation\nand coordination in multi-agent systems, with primary emphasis on drone\ndelivery and secondary relevance to warehouse automation. We formulate the\nproblem in a cooperative multi-agent reinforcement learning setting and\nimplement a lightweight multi-agent Proximal Policy Optimization, called IPPO,\napproach in PyTorch under a centralized-training, decentralized-execution\nparadigm. Experiments are conducted in PettingZoo environment, where multiple\nhomogeneous drones or agents must self-organize to cover distinct targets\nwithout explicit communication."}
{"id": "2510.00477", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00477", "abs": "https://arxiv.org/abs/2510.00477", "authors": ["Chengzhen Li", "Likun Zhang", "Chuang Zhang", "Jiahui Li", "Changyuan Zhao", "Ruichen Zhang", "Geng Sun"], "title": "Wireless Laser Power Transfer for Low-altitude Uncrewed Aerial Vehicle-assisted Internet of Things: Paradigms, Challenges, and Solutions", "comment": "This paper has been submitted to IEEE Internet of Things Magazine", "summary": "Low-altitude uncrewed aerial vehicles (UAVs) have become integral enablers\nfor the Internet of Things (IoT) by offering enhanced coverage, improved\nconnectivity and access to remote areas. A critical challenge limiting their\noperational capacity lies in the energy constraints of both aerial platforms\nand ground-based sensors. This paper explores WLPT as a transformative solution\nfor sustainable energy provisioning in UAV-assisted IoT networks. We first\nsystematically investigate the fundamental principles of WLPT and analysis the\ncomparative advantages. Then, we introduce three operational paradigms for\nsystem integration, identify key challenges, and discuss corresponding\npotential solutions. In case study, we propose a multi-agent reinforcement\nlearning framework to address the coordination and optimization challenges in\nWLPT-enabled UAV-assisted IoT data collection. Simulation results demonstrate\nthat our framework significantly improves energy sustainability and data\nfreshness. Finally, we discuss some future directions."}
{"id": "2510.00904", "categories": ["cs.NI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00904", "abs": "https://arxiv.org/abs/2510.00904", "authors": ["Erfan Delfani", "Nikolaos Pappas"], "title": "Optimizing Version AoI in Energy-Harvesting IoT: Model-Based and Learning-Based Approaches", "comment": null, "summary": "Efficient data transmission in resource-constrained Internet of Things (IoT)\nsystems requires semantics-aware management that maximizes the delivery of\ntimely and informative data. This paper investigates the optimization of the\nsemantic metric Version Age of Information (VAoI) in a status update system\ncomprising an energy-harvesting (EH) sensor and a destination monitoring node.\nWe consider three levels of knowledge about the system model -- fully known,\npartially known, and unknown -- and propose corresponding optimization\nstrategies: model-based, estimation-based, and model-free methods. By employing\nMarkov Decision Process (MDP) and Reinforcement Learning (RL) frameworks, we\nanalyze performance trade-offs under varying degrees of model information. Our\nfindings provide guidance for designing efficient and adaptive semantics-aware\npolicies in both known and unknown IoT environments."}
{"id": "2510.00257", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00257", "abs": "https://arxiv.org/abs/2510.00257", "authors": ["K. F. Nieman", "O. Kanhere", "R. Shiu", "W. Xu", "C. Duan", "S. S. Ghassemzadeh"], "title": "An Adaptive cmWave/FR3 Channel Sounder for Integrated Sensing and Communication", "comment": "GLOBECOM 2025 - 2025 IEEE Global Communications Conference, Taipei,\n  Taiwan, Dec 2025", "summary": "In this paper, we present an advanced channel sounding system designed for\nsensing and propagation experiments in all types of cellular deployment\nscenarios. The system's exceptional adaptability, high resolution, and\nsensitivity makes it an invaluable tool for utilization in a variety of indoor\nand outdoor measurement campaigns. The sounder has a 2.5 ns delay resolution,\n170 dB path loss measurement capability and is able to measure a\n{360\\textdegree} power-angular delay profile of the channel in less than 0.9\nms. Additionally, the system can be easily reconfigured to measure different\nfrequency bands by changing the RF front-end antennas. This versatile sounder\nis suitable for double directional channel sounding, high-speed vehicular\nexperiments such as vehicle-to-vehicle and vehicle-to-infrastructure\ncommunications, and integrated communication and sensing experiments."}
{"id": "2510.00023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00023", "abs": "https://arxiv.org/abs/2510.00023", "authors": ["Quy Minh Le", "Minh Sao Khue Luu", "Khanh-Tung Tran", "Duc-Hai Nguyen", "Hoang-Quoc-Viet Pham", "Quan Le", "Hoang Thanh Lam", "Hoang D. Nguyen"], "title": "ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools", "comment": null, "summary": "Effective tool use is essential for agentic AI, yet training agents to\nutilize tools remains challenging due to manually designed rewards, limited\ntraining data, and poor multi-tool selection, resulting in slow adaptation,\nwasted computational resources, and suboptimal performance. We introduce\nToolBrain, a lightweight and user-friendly framework for coaching tool use in\nagentic models with flexible reinforcement learning (RL), easing the barriers\nfor researchers and practitioners to adapt LLM-based agents to specific\ndomains. It supports a wide range of training strategies, including RL\nalgorithms such as GRPO and DPO, as well as supervised learning. ToolBrain\nenables custom reward callables directly on an agent's execution traces or\nsimply utilizes an automated LLM-as-a-judge system for reward generation. It is\npacked with useful capabilities, including knowledge distillation from large to\nsmall models for efficient development, automatic task generation from tool\ndescriptions, seamless tool retrieval, efficient fine-tuning pipelines with\nQLoRA through Unsloth, and quantized inference via bitsandbytes. We demonstrate\nToolBrain through diverse use cases, such as training a CodeAct agent to\nautonomously execute email search tasks, showing fast, targeted improvements\n(up to 30.0%) in tool-use skills while keeping the codebase simple and\nextensible in Agentic AI. Our framework is publicly available at\nhttps://toolbrain.org."}
{"id": "2510.00939", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00939", "abs": "https://arxiv.org/abs/2510.00939", "authors": ["Pouya Firouzmakan", "Suprakash Datta"], "title": "Enhancing Urban VANETs Stability: A Single-Hop Clustering Strategy in Metropolitan Environments", "comment": "10 pages, 6 figures, 5 tables, Journal", "summary": "Vehicular Ad-hoc Networks (VANETs), a subclass of Mobile Ad-hoc Networks\n(MANETs), are expected to play a crucial role in the future of intelligent\ntransportation systems (ITSs). A key objective of VANETs is to enable efficient\nand cost-effective communication among vehicles while supporting a large number\nof network participants and minimizing infrastructure dependency. However, the\nhighly dynamic nature of vehicular networks poses significant challenges to\ntheir deployment. Clustering techniques are employed to address these\nchallenges, with a strong emphasis on stability, as they directly influence the\nrouting process and enhance the quality of service (QoS). This paper explores\nthe feasibility of reducing reliance on roadside units (RSUs) in metropolitan\nareas while improving cluster stability. We propose an efficient clustering\nalgorithm tailored for urban environments, leveraging existing metropolitan\ninfrastructure to compensate for the absence of RSUs. Our approach designates\npublic transportation buses as primary cluster heads (CHs), minimizing reliance\non additional infrastructure, while stand-alone vehicles (SAVs) dynamically\nselect additional CHs. Through comprehensive case studies and comparative\nanalysis with existing algorithms, our results demonstrate the superior\nperformance of the proposed method across different transmission ranges (TRs)."}
{"id": "2510.00939", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.00939", "abs": "https://arxiv.org/abs/2510.00939", "authors": ["Pouya Firouzmakan", "Suprakash Datta"], "title": "Enhancing Urban VANETs Stability: A Single-Hop Clustering Strategy in Metropolitan Environments", "comment": "10 pages, 6 figures, 5 tables, Journal", "summary": "Vehicular Ad-hoc Networks (VANETs), a subclass of Mobile Ad-hoc Networks\n(MANETs), are expected to play a crucial role in the future of intelligent\ntransportation systems (ITSs). A key objective of VANETs is to enable efficient\nand cost-effective communication among vehicles while supporting a large number\nof network participants and minimizing infrastructure dependency. However, the\nhighly dynamic nature of vehicular networks poses significant challenges to\ntheir deployment. Clustering techniques are employed to address these\nchallenges, with a strong emphasis on stability, as they directly influence the\nrouting process and enhance the quality of service (QoS). This paper explores\nthe feasibility of reducing reliance on roadside units (RSUs) in metropolitan\nareas while improving cluster stability. We propose an efficient clustering\nalgorithm tailored for urban environments, leveraging existing metropolitan\ninfrastructure to compensate for the absence of RSUs. Our approach designates\npublic transportation buses as primary cluster heads (CHs), minimizing reliance\non additional infrastructure, while stand-alone vehicles (SAVs) dynamically\nselect additional CHs. Through comprehensive case studies and comparative\nanalysis with existing algorithms, our results demonstrate the superior\nperformance of the proposed method across different transmission ranges (TRs)."}
{"id": "2510.00269", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00269", "abs": "https://arxiv.org/abs/2510.00269", "authors": ["O. Kanhere", "K. F. Nieman", "S. S. Ghassemzadeh"], "title": "Indoor-Office Large-Scale Wireless Channel Characterization in cmWave/FR3 Spectrum", "comment": "GLOBECOM 2025 - 2025 IEEE Global Communications Conference", "summary": "This paper presents comprehensive findings on the characterization of Indoor\nHotspot channel parameters, derived from an extensive experimental campaign\nconducted at 6.9, 8.3, and 14.5 GHz in a commercial office building. Extensive\nmeasurements were carried out in diverse indoor office settings, including\ncubicles, conference rooms, hallways, and laboratory spaces across four floors.\nThe path loss, shadow fading, delay spread, and angular spread was modeled. Our\nresults offer significant insights into the attenuation and dispersion\ncharacteristics of wireless signals in diverse indoor settings in the\ncentimeter-wave frequency band, and can be used for improving indoor network\ndesign and performance in commercial buildings."}
{"id": "2510.00071", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00071", "abs": "https://arxiv.org/abs/2510.00071", "authors": ["Dongqi Zheng"], "title": "ARS: Adaptive Reasoning Suppression for Efficient Large Reasoning Language Models", "comment": "Accepted by 39th NeurIPS - Foundations of Reasoning in Language\n  Models", "summary": "Large Reasoning Language Models (LRLMs or LRMs) demonstrate remarkable\ncapabilities in complex reasoning tasks, but suffer from significant\ncomputational inefficiencies due to overthinking phenomena. Existing efficient\nreasoning methods face the challenge of balancing reasoning quality with\ninference cost reduction. We propose \\textbf{Adaptive Reasoning Suppression\n(ARS)}, a novel training-free approach that dynamically suppresses redundant\nreasoning steps while preserving accuracy through adaptive certainty\nmonitoring. ARS introduces a multi-checkpoint certainty estimation mechanism\nwith progressive suppression thresholds, achieving superior efficiency compared\nto static suppression methods. Our extensive evaluation across mathematical\nreasoning benchmarks using multiple model architectures demonstrates that ARS\nachieves up to 53%, 46.1%, and 57.9% in token, latency and energy reduction,\nwhile maintaining or improving accuracy."}
{"id": "2510.00960", "categories": ["cs.AI", "cs.NE", "cs.SY", "eess.SY", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.00960", "abs": "https://arxiv.org/abs/2510.00960", "authors": ["Miha Ožbot", "Igor Škrjanc", "Vitomir Štruc"], "title": "A Neuro-Fuzzy System for Interpretable Long-Term Stock Market Forecasting", "comment": "Published in: ERK 2025 -- 34th International Electrotechnical and\n  Computer Science Conference, Portoro\\v{z}, Slovenia, Sept. 25--26, 2025.\n  Proceedings published by Dru\\v{s}tvo Slovenska sekcija IEEE. ISSN: 2591-0442\n  (online). 4 pages, 2 figures", "summary": "In the complex landscape of multivariate time series forecasting, achieving\nboth accuracy and interpretability remains a significant challenge. This paper\nintroduces the Fuzzy Transformer (Fuzzformer), a novel recurrent neural network\narchitecture combined with multi-head self-attention and fuzzy inference\nsystems to analyze multivariate stock market data and conduct long-term time\nseries forecasting. The method leverages LSTM networks and temporal attention\nto condense multivariate data into interpretable features suitable for fuzzy\ninference systems. The resulting architecture offers comparable forecasting\nperformance to conventional models such as ARIMA and LSTM while providing\nmeaningful information flow within the network. The method was examined on the\nreal world stock market index S\\&P500. Initial results show potential for\ninterpretable forecasting and identify current performance tradeoffs,\nsuggesting practical application in understanding and forecasting stock market\nbehavior."}
{"id": "2510.00956", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00956", "abs": "https://arxiv.org/abs/2510.00956", "authors": ["Carlos Güemes-Palau", "Miquel Ferriol-Galmés", "Jordi Paillisse-Vilanova", "Albert López-Brescó", "Pere Barlet-Ros", "Albert Cabellos-Aparicio"], "title": "Bridging the Gap Between Simulated and Real Network Data Using Transfer Learning", "comment": "This paper was submitted to IEEE ICC 2026. 7 Pages, 5 Figures", "summary": "Machine Learning (ML)-based network models provide fast and accurate\npredictions for complex network behaviors but require substantial training\ndata. Collecting such data from real networks is often costly and limited,\nespecially for critical scenarios like failures. As a result, researchers\ncommonly rely on simulated data, which reduces accuracy when models are\ndeployed in real environments. We propose a hybrid approach leveraging transfer\nlearning to combine simulated and real-world data. Using RouteNet-Fermi, we\nshow that fine-tuning a pre-trained model with a small real dataset\nsignificantly improves performance. Our experiments with OMNeT++ and a custom\ntestbed reduce the Mean Absolute Percentage Error (MAPE) in packet delay\nprediction by up to 88%. With just 10 real scenarios, MAPE drops by 37%, and\nwith 50 scenarios, by 48%."}
{"id": "2510.00275", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00275", "abs": "https://arxiv.org/abs/2510.00275", "authors": ["K. F. Nieman", "O. Kanhere", "S. S. Ghassemzadeh"], "title": "cmWave/FR3 Large-Scale Channel Characterization for Urban Macro/Micro and Suburban Environments", "comment": "GLOBECOM 2025 - 2025 IEEE Global Communications Conference", "summary": "This study delves into the comprehensive characterization of large-scale\nchannels at centimeter wave frequencies 7-15 GHz for urban macro/micro and\nsuburban environments. Path-loss, large-scale fading, and angular channel\nstatistics are presented. Urban environments exhibited higher path loss and\ndelay spread due to dense obstacles, whereas suburban areas showed relatively\nlower path loss but significant variability due to fewer but larger\nobstructions. The findings provide valuable insights for network planners and\nengineers, aiding in the development of more efficient and adaptive\ncommunication strategies. Enhanced models for channel prediction and system\ndesign are proposed, contributing to the advancement of next-generation\nwireless networks."}
{"id": "2510.00075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00075", "abs": "https://arxiv.org/abs/2510.00075", "authors": ["Rishi Bommasani"], "title": "NeurIPS should lead scientific consensus on AI policy", "comment": "Published at NeurIPS 2025", "summary": "Designing wise AI policy is a grand challenge for society. To design such\npolicy, policymakers should place a premium on rigorous evidence and scientific\nconsensus. While several mechanisms exist for evidence generation, and nascent\nmechanisms tackle evidence synthesis, we identify a complete void on consensus\nformation. In this position paper, we argue NeurIPS should actively catalyze\nscientific consensus on AI policy. Beyond identifying the current deficit in\nconsensus formation mechanisms, we argue that NeurIPS is the best option due\nits strengths and the paucity of compelling alternatives. To make progress, we\nrecommend initial pilots for NeurIPS by distilling lessons from the IPCC's\nleadership to build scientific consensus on climate policy. We dispel\npredictable counters that AI researchers disagree too much to achieve consensus\nand that policy engagement is not the business of NeurIPS. NeurIPS leads AI on\nmany fronts, and it should champion scientific consensus to create higher\nquality AI policy."}
{"id": "2510.00638", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00638", "abs": "https://arxiv.org/abs/2510.00638", "authors": ["Wing Chau Ng", "Scott Yam"], "title": "On the Achievable Performance in the presence of Multiple Path Interference for Intra Data Center applications", "comment": "Submitted to European Conference on Optical Communications (ECOC)\n  2025", "summary": "An accurate analytical form of the achievable bit error rate in the presence\nof multipath interference (MPI) is proposed for PAM4 for the first time, taking\ninto account an ideal MPI estimate and compensation."}
{"id": "2510.00084", "categories": ["cs.AI", "cs.CY", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.00084", "abs": "https://arxiv.org/abs/2510.00084", "authors": ["Fabian Kovac", "Sebastian Neumaier", "Timea Pahi", "Torsten Priebe", "Rafael Rodrigues", "Dimitrios Christodoulou", "Maxime Cordy", "Sylvain Kubler", "Ali Kordia", "Georgios Pitsiladis", "John Soldatos", "Petros Zervoudakis"], "title": "Towards a Framework for Supporting the Ethical and Regulatory Certification of AI Systems", "comment": "Accepted for publication in the proceedings of the Workshop on AI\n  Certification, Fairness and Regulations, co-located with the Austrian\n  Symposium on AI and Vision (AIRoV 2025)", "summary": "Artificial Intelligence has rapidly become a cornerstone technology,\nsignificantly influencing Europe's societal and economic landscapes. However,\nthe proliferation of AI also raises critical ethical, legal, and regulatory\nchallenges. The CERTAIN (Certification for Ethical and Regulatory Transparency\nin Artificial Intelligence) project addresses these issues by developing a\ncomprehensive framework that integrates regulatory compliance, ethical\nstandards, and transparency into AI systems. In this position paper, we outline\nthe methodological steps for building the core components of this framework.\nSpecifically, we present: (i) semantic Machine Learning Operations (MLOps) for\nstructured AI lifecycle management, (ii) ontology-driven data lineage tracking\nto ensure traceability and accountability, and (iii) regulatory operations\n(RegOps) workflows to operationalize compliance requirements. By implementing\nand validating its solutions across diverse pilots, CERTAIN aims to advance\nregulatory compliance and to promote responsible AI innovation aligned with\nEuropean standards."}
{"id": "2510.00668", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00668", "abs": "https://arxiv.org/abs/2510.00668", "authors": ["Xiaojuan Zhang", "Yonghong Zeng", "Francois Chin Po Shin"], "title": "OTFS for Joint Radar and Communication: Algorithms, Prototypes, and Experiments", "comment": null, "summary": "We propose an Joint Radar and Communication (JRC) system that utilizes the\nOrthogonal Time Frequency Space (OTFS) signals. The system features a fast\nradar sensing algorithm for detecting target range and speed by using the OTFS\ncommunication signals, and a self-interference cancellation for enhanced\nmulti-target separation. In addition to target detection, we propose methods\nfor monitoring human vital signs, such as breathing rate and heartbeat.\nFurthermore, we explore two approaches for distinguishing between human and\nnonhuman targets: one based on signal processing and the other based on machine\nlearning. We have developed a prototype JRC system using the software-defined\nradio (SDR) technology. Experimental results are shown to demonstrate the\neffectiveness of the prototype in detecting range, speed, and vital signs in\nboth human and mobile robot scenarios, as well as in distinguishing between\nhuman and non-human targets."}
{"id": "2510.00088", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00088", "abs": "https://arxiv.org/abs/2510.00088", "authors": ["Sagnik Basu", "Shubham Prakash", "Ashish Maruti Barge", "Siddharth D Jaiswal", "Abhisek Dash", "Saptarshi Ghosh", "Animesh Mukherjee"], "title": "Judging by Appearances? Auditing and Intervening Vision-Language Models for Bail Prediction", "comment": null, "summary": "Large language models (LLMs) have been extensively used for legal judgment\nprediction tasks based on case reports and crime history. However, with a surge\nin the availability of large vision language models (VLMs), legal judgment\nprediction systems can now be made to leverage the images of the criminals in\naddition to the textual case reports/crime history. Applications built in this\nway could lead to inadvertent consequences and be used with malicious intent.\nIn this work, we run an audit to investigate the efficiency of standalone VLMs\nin the bail decision prediction task. We observe that the performance is poor\nacross multiple intersectional groups and models \\textit{wrongly deny bail to\ndeserving individuals with very high confidence}. We design different\nintervention algorithms by first including legal precedents through a RAG\npipeline and then fine-tuning the VLMs using innovative schemes. We demonstrate\nthat these interventions substantially improve the performance of bail\nprediction. Our work paves the way for the design of smarter interventions on\nVLMs in the future, before they can be deployed for real-world legal judgment\nprediction."}
{"id": "2510.01019", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.01019", "abs": "https://arxiv.org/abs/2510.01019", "authors": ["Niloufar Hosseinzadeh", "Mohsen Moradi", "Hessam Mahdavifar"], "title": "Layered Normalized Min-Sum Decoding with Bit Flipping for FDPC Codes", "comment": null, "summary": "Fair-density parity-check (FDPC) codes have been recently introduced\ndemonstrating improved performance compared to low-density parity-check (LDPC)\ncodes standardized in 5G systems particularly in high-rate regimes. In this\npaper, we introduce a layered normalized min-sum (LNMS) message-passing\ndecoding algorithm for the FDPC codes. We also introduce a syndrome-guided bit\nflipping (SGBF) method to enhance the error-correction performance of our\nproposed decoder. The LNMS decoder leverages conflict graph coloring for\nefficient layered scheduling, enabling faster convergence by grouping\nnon-conflicting check nodes and updating variable nodes immediately after each\nlayer. In the event of decoding failure, the SGBF method is activated,\nutilizing a novel reliability metric that combines log-likelihood ratio (LLR)\nmagnitudes and syndrome-derived error counts to identify the least reliable\nbits. A set of candidate sequences is then generated by performing single-bit\nflips at these positions, with each candidate re-decoded via LNMS. The optimal\ncandidate is selected based on the minimum syndrome weight. Extensive\nsimulation results demonstrate the superiority of the proposed decoder.\nNumerical simulations on FDPC$(256,192)$ code with a bit-flipping set size of\n$T = 128$ and a maximum of $5$ iterations demonstrate that the proposed decoder\nachieves approximately a $0.5\\,\\mathrm{dB}$ coding gain over standalone LNMS\ndecoding at a frame error rate (FER) of $10^{-3}$, while providing coding gains\nof $0.75-1.5\\,\\mathrm{dB}$ over other state-of-the-art codes including polar\ncodes and 5G-LDPC codes at the same length and rate and also under belief\npropagation decoding."}
{"id": "2510.00156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00156", "abs": "https://arxiv.org/abs/2510.00156", "authors": ["Songran Bai", "Bingzhe Wu", "Yiwei Zhang", "Chengke Wu", "Xiaolong Zheng", "Yaze Yuan", "Ke Wu", "Jianqiang Li"], "title": "AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery", "comment": null, "summary": "Financial fraud detection in real-world scenarios presents significant\nchallenges due to the subtlety and dispersion of evidence across complex,\nmulti-year financial disclosures. In this work, we introduce a novel\nmulti-agent reasoning framework AuditAgent, enhanced with auditing domain\nexpertise, for fine-grained evidence chain localization in financial fraud\ncases. Leveraging an expert-annotated dataset constructed from enforcement\ndocuments and financial reports released by the China Securities Regulatory\nCommission, our approach integrates subject-level risk priors, a hybrid\nretrieval strategy, and specialized agent modules to efficiently identify and\naggregate cross-report evidence. Extensive experiments demonstrate that our\nmethod substantially outperforms General-Purpose Agent paradigm in both recall\nand interpretability, establishing a new benchmark for automated, transparent\nfinancial forensics. Our results highlight the value of domain-specific\nreasoning and dataset construction for advancing robust financial fraud\ndetection in practical, real-world regulatory applications."}
{"id": "2510.00904", "categories": ["cs.NI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.00904", "abs": "https://arxiv.org/abs/2510.00904", "authors": ["Erfan Delfani", "Nikolaos Pappas"], "title": "Optimizing Version AoI in Energy-Harvesting IoT: Model-Based and Learning-Based Approaches", "comment": null, "summary": "Efficient data transmission in resource-constrained Internet of Things (IoT)\nsystems requires semantics-aware management that maximizes the delivery of\ntimely and informative data. This paper investigates the optimization of the\nsemantic metric Version Age of Information (VAoI) in a status update system\ncomprising an energy-harvesting (EH) sensor and a destination monitoring node.\nWe consider three levels of knowledge about the system model -- fully known,\npartially known, and unknown -- and propose corresponding optimization\nstrategies: model-based, estimation-based, and model-free methods. By employing\nMarkov Decision Process (MDP) and Reinforcement Learning (RL) frameworks, we\nanalyze performance trade-offs under varying degrees of model information. Our\nfindings provide guidance for designing efficient and adaptive semantics-aware\npolicies in both known and unknown IoT environments."}
{"id": "2510.00167", "categories": ["cs.AI", "cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00167", "abs": "https://arxiv.org/abs/2510.00167", "authors": ["Diego Ortiz Barbosa", "Mohit Agrawal", "Yash Malegaonkar", "Luis Burbano", "Axel Andersson", "György Dán", "Henrik Sandberg", "Alvaro A. Cardenas"], "title": "Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI", "comment": null, "summary": "Autonomous drones must often respond to sudden events, such as alarms,\nfaults, or unexpected changes in their environment, that require immediate and\nadaptive decision-making. Traditional approaches rely on safety engineers\nhand-coding large sets of recovery rules, but this strategy cannot anticipate\nthe vast range of real-world contingencies and quickly becomes incomplete.\nRecent advances in embodied AI, powered by large visual language models,\nprovide commonsense reasoning to assess context and generate appropriate\nactions in real time. We demonstrate this capability in a simulated urban\nbenchmark in the Unreal Engine, where drones dynamically interpret their\nsurroundings and decide on sudden maneuvers for safe landings. Our results show\nthat embodied AI makes possible a new class of adaptive recovery and\ndecision-making pipelines that were previously infeasible to design by hand,\nadvancing resilience and safety in autonomous aerial systems."}
{"id": "2510.00185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00185", "abs": "https://arxiv.org/abs/2510.00185", "authors": ["Gabriel de Olim Gaul", "Adam Gould", "Avinash Kori", "Francesca Toni"], "title": "Object-Centric Case-Based Reasoning via Argumentation", "comment": "Accepted to ArgXAI@ECAI25", "summary": "We introduce Slot Attention Argumentation for Case-Based Reasoning (SAA-CBR),\na novel neuro-symbolic pipeline for image classification that integrates\nobject-centric learning via a neural Slot Attention (SA) component with\nsymbolic reasoning conducted by Abstract Argumentation for Case-Based Reasoning\n(AA-CBR). We explore novel integrations of AA-CBR with the neural component,\nincluding feature combination strategies, casebase reduction via representative\nsamples, novel count-based partial orders, a One-Vs-Rest strategy for extending\nAA-CBR to multi-class classification, and an application of Supported AA-CBR, a\nbipolar variant of AA-CBR. We demonstrate that SAA-CBR is an effective\nclassifier on the CLEVR-Hans datasets, showing competitive performance against\nbaseline models."}
{"id": "2510.00186", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00186", "abs": "https://arxiv.org/abs/2510.00186", "authors": ["Anni Li", "Aria Attar", "Paul Dong"], "title": "Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective", "comment": null, "summary": "Transforming natural-language requests into reliable, production-ready data\ntransformations remains challenging: correctness depends on precise schema\nlinking and warehouse-specific SQL dialects, while the strongest supervision\navailable during training--execution success and result matching--are provided\nonly at the sequence level. At the same time, assembling large,\nexecution-validated corpora is costly, and token-level objectives misalign with\nthese global signals, yielding unstable optimization and limited portability.\nWe introduce Thinkquel, a fine-tuned model for producing robust, portable, and\nexecution-validated database queries. Methodologies in Thinkquel integrates a\nnovel synthetic data pipeline, TS-SQL, that leverages dbt as a portable\nintermediate representation with a span-aware reinforcement learning objective,\nand Token-Sequence GRPO (TS-GRPO), specifically designed to bridge the gap\nbetween token-level training signals and sequence-level execution rewards when\nfinetuning LLMs. On the 500-example TS-SQL test set, Thinkquel (32B) reaches\n93.2\\% execution success and 61.8\\% exact-result match with a two-stage SFT\ncurriculum, improving over the base model by 67.2\\% (exec.) and 44.4\\% (match).\nIn Spider (14B) experiments, TS-GRPO increases training stability and speeds\nconvergence of the execution-match reward relative to GRPO and GSPO."}
{"id": "2510.00229", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00229", "abs": "https://arxiv.org/abs/2510.00229", "authors": ["Rohan Kadekodi", "Zhan Jin", "Keisuke Kamahori", "Yile Gu", "Sean Khatiri", "Noah H. Bayindirli", "Sergey Gorbunov", "Baris Kasikci"], "title": "DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems", "comment": null, "summary": "The deployment of Large Language Models (LLMs) as agentic orchestrators has\nrevolutionized task automation, but the need for privacy-preserving,\ncost-effective solutions demands on-device inference capabilities. However,\nlocal LLMs consistently underperform compared to frontier models in tool\ncalling scenarios, struggling with both tool selection from large tool sets and\naccurate argument generation for complex parameter structures. We introduce a\nmethodology that disaggregates a tool-calling task into two distinct subtasks:\ntool selection and argument generation. We propose \"decoupled fine-tuning\", a\nnovel post-training approach that employs LoRA fine-tuning to create dedicated\nLoRA adapters for tool selection and tool-specific argument generation using\nseparate loss masking for each of the subtasks. Furthermore, we present\nDualTune, an inference framework that leverages the LoRA adapters created using\ndecoupled fine-tuning to perform efficient agent orchestration with the help of\nlocal models on end-user devices. DualTune decomposes the tool-call generation\nstep into tool selection and argument generation, and dynamically loads the\ncorresponding LoRA adapters to generate tool calls. Additionally, DualTune\nimplements hierarchical orchestration to restrict the number of tools required\nfor tool selection. Our experiments on the MCP-Bench benchmark demonstrate that\nthe Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool\ncalling accuracy of the base model by 46%, and outperforms other local\nreasoning, non-reasoning and fine-tuned models of similar size in all cases,\nand models that are 2x larger, in most cases."}
{"id": "2510.00274", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00274", "abs": "https://arxiv.org/abs/2510.00274", "authors": ["Maisha Maliha", "Dean Hougen"], "title": "MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning", "comment": "16 pages, 3 figures", "summary": "Understanding the decision-making process of Deep Reinforcement Learning\nagents remains a key challenge for deploying these systems in safety-critical\nand multi-agent environments. While prior explainability methods like\nStateMask, have advanced the identification of critical states, they remain\nlimited by computational cost, exploration coverage, and lack of adaptation to\nmulti-agent settings. To overcome these limitations, we propose a\nmathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent\nCollaboration with Mask-Based Explainability for Reinforcement Learning), that\nextends perturbation-based explanation to Multi-Agent Reinforcement Learning.\nOur method integrates Proximal Policy Optimization, adaptive epsilon-greedy\nexploration, and lightweight inter-agent collaboration to share masked state\ninformation and peer experience. This collaboration enables each agent to\nperform saliency-guided masking and share reward-based insights with peers,\nreducing the time required for critical state discovery, improving explanation\nfidelity, and leading to faster and more robust learning. The core novelty of\nour approach lies in generalizing explainability from single-agent to\nmulti-agent systems through a unified mathematical formalism built on\ntrajectory perturbation, reward fidelity analysis, and Kullback-Leibler\ndivergence regularization. This framework yields localized, interpretable\nexplanations grounded in probabilistic modeling and multi-agent Markov decision\nprocesses. We validate our framework on both single-agent and multi-agent\nbenchmarks, including a multi-agent highway driving environment and Google\nResearch Football, demonstrating that MAGIC-MASK consistently outperforms\nstate-of-the-art baselines in fidelity, learning efficiency, and policy\nrobustness while offering interpretable and transferable explanations."}
{"id": "2510.00300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00300", "abs": "https://arxiv.org/abs/2510.00300", "authors": ["Serena Gomez Wannaz"], "title": "ICL Optimized Fragility", "comment": null, "summary": "ICL guides are known to improve task-specific performance, but their impact\non cross-domain cognitive abilities remains unexplored. This study examines how\nICL guides affect reasoning across different knowledge domains using six\nvariants of the GPT-OSS:20b model: one baseline model and five ICL\nconfigurations (simple, chain-of-thought, random, appended text, and symbolic\nlanguage). The models were subjected to 840 tests spanning general knowledge\nquestions, logic riddles, and a mathematical olympiad problem. Statistical\nanalysis (ANOVA) revealed significant behavioral modifications (p less than\n0.001) across ICL variants, demonstrating a phenomenon termed \"optimized\nfragility.\" ICL models achieved 91%-99% accuracy on general knowledge tasks\nwhile showing degraded performance on complex reasoning problems, with accuracy\ndropping to 10-43% on riddles compared to 43% for the baseline model. Notably,\nno significant differences emerged on the olympiad problem (p=0.2173),\nsuggesting that complex mathematical reasoning remains unaffected by ICL\noptimization. These findings indicate that ICL guides create systematic\ntrade-offs between efficiency and reasoning flexibility, with important\nimplications for LLM deployment and AI safety."}
{"id": "2510.00307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00307", "abs": "https://arxiv.org/abs/2510.00307", "authors": ["Thierry Blankenstein", "Jialin Yu", "Zixuan Li", "Vassilis Plachouras", "Sunando Sengupta", "Philip Torr", "Yarin Gal", "Alasdair Paren", "Adel Bibi"], "title": "BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models", "comment": null, "summary": "Agents backed by large language models (LLMs) often rely on external tools\ndrawn from marketplaces where multiple providers offer functionally equivalent\noptions. This raises a critical point concerning fairness: if selection is\nsystematically biased, it can degrade user experience and distort competition\nby privileging some providers over others. We introduce a benchmark of diverse\ntool categories, each containing multiple functionally equivalent tools, to\nevaluate tool-selection bias. Using this benchmark, we test seven models and\nshow that unfairness exists with models either fixating on a single provider or\ndisproportionately preferring earlier-listed tools in context. To investigate\nthe origins of this bias, we conduct controlled experiments examining tool\nfeatures, metadata (name, description, parameters), and pre-training exposure.\nWe find that: (1) semantic alignment between queries and metadata is the\nstrongest predictor of choice; (2) perturbing descriptions significantly shifts\nselections; and (3) repeated pre-training exposure to a single endpoint\namplifies bias. Finally, we propose a lightweight mitigation that first filters\nthe candidate tools to a relevant subset and then samples uniformly, reducing\nbias while preserving good task coverage. Our findings highlight tool-selection\nbias as a key obstacle for the fair deployment of tool-augmented LLMs."}
{"id": "2510.00332", "categories": ["cs.AI", "cs.CE", "I.6.4; I.2.1"], "pdf": "https://arxiv.org/pdf/2510.00332", "abs": "https://arxiv.org/abs/2510.00332", "authors": ["Zeshi Dai", "Zimo Peng", "Zerui Cheng", "Ryan Yihe Li"], "title": "When Hallucination Costs Millions: Benchmarking AI Agents in High-Stakes Adversarial Financial Markets", "comment": "15 pages, 5 figures, 4 tables; In submission to ICLR 2026", "summary": "We present CAIA, a benchmark exposing a critical blind spot in AI evaluation:\nthe inability of state-of-the-art models to operate in adversarial, high-stakes\nenvironments where misinformation is weaponized and errors are irreversible.\nWhile existing benchmarks measure task completion in controlled settings,\nreal-world deployment demands resilience against active deception. Using crypto\nmarkets as a testbed where $30 billion was lost to exploits in 2024, we\nevaluate 17 models on 178 time-anchored tasks requiring agents to distinguish\ntruth from manipulation, navigate fragmented information landscapes, and make\nirreversible financial decisions under adversarial pressure.\n  Our results reveal a fundamental capability gap: without tools, even frontier\nmodels achieve only 28% accuracy on tasks junior analysts routinely handle.\nTool augmentation improves performance but plateaus at 67.4% versus 80% human\nbaseline, despite unlimited access to professional resources. Most critically,\nwe uncover a systematic tool selection catastrophe: models preferentially\nchoose unreliable web search over authoritative data, falling for SEO-optimized\nmisinformation and social media manipulation. This behavior persists even when\ncorrect answers are directly accessible through specialized tools, suggesting\nfoundational limitations rather than knowledge gaps. We also find that Pass@k\nmetrics mask dangerous trial-and-error behavior for autonomous deployment.\n  The implications extend beyond crypto to any domain with active adversaries,\ne.g. cybersecurity, content moderation, etc. We release CAIA with contamination\ncontrols and continuous updates, establishing adversarial robustness as a\nnecessary condition for trustworthy AI autonomy. The benchmark reveals that\ncurrent models, despite impressive reasoning scores, remain fundamentally\nunprepared for environments where intelligence must survive active opposition."}
{"id": "2510.00355", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00355", "abs": "https://arxiv.org/abs/2510.00355", "authors": ["Renee Ge", "Qianli Liao", "Tomaso Poggio"], "title": "Hierarchical Reasoning Model: A Critical Supplementary Material", "comment": "Preprint, Under review", "summary": "Transformers have demonstrated remarkable performance in natural language\nprocessing and related domains, as they largely focus on sequential,\nautoregressive next-token prediction tasks. Yet, they struggle in logical\nreasoning, not necessarily because of a fundamental limitation of these models,\nbut possibly due to the lack of exploration of more creative uses, such as\nlatent space and recurrent reasoning. An emerging exploration in this direction\nis the Hierarchical Reasoning Model (Wang et al., 2025), which introduces a\nnovel type of recurrent reasoning in the latent space of transformers,\nachieving remarkable performance on a wide range of 2D reasoning tasks. Despite\nthe promising results, this line of models is still at an early stage and calls\nfor in-depth investigation. In this work, we perform a critical review on this\nclass of models, examine key design choices and present intriguing variants\nthat achieve significantly better performance on the Sudoku-Extreme and\nMaze-Hard tasks than previously reported. Our results also raise surprising\nobservations and intriguing directions for further research."}
{"id": "2510.00381", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00381", "abs": "https://arxiv.org/abs/2510.00381", "authors": ["Kaiwen Yu", "Mengying Sun", "Zhijin Qin", "Xiaodong Xu", "Ping Yang", "Yue Xiao", "Gang Wu"], "title": "Semantic-Driven AI Agent Communications: Challenges and Solutions", "comment": null, "summary": "With the rapid growth of intelligent services, communication targets are\nshifting from humans to artificial intelligent (AI) agents, which require new\nparadigms to enable real-time perception, decision-making, and collaboration.\nSemantic communication, which conveys task-relevant meaning rather than raw\ndata, offers a promising solution. However, its practical deployment remains\nconstrained by dynamic environments and limited resources. To address these\nissues, this article proposes a semantic-driven AI agent communication\nframework and develops three enabling techniques. First, semantic adaptation\ntransmission applies fine-tuning with real or generative samples to efficiently\nadapt models to varying environments. Second, semantic lightweight transmission\nincorporates pruning, quantization, and perception-aware sampling to reduce\nmodel complexity and alleviate computational burden on edge agents. Third,\nsemantic self-evolution control employs distributed hierarchical\ndecision-making to optimize multi-dimensional resources, enabling robust\nmulti-agent collaboration in dynamic environments. Simulation results show that\nthe proposed solutions achieve faster convergence and stronger robustness,\nwhile the proposed distributed hierarchical optimization method significantly\noutperforms conventional decision-making schemes, highlighting its potential\nfor AI agent communication networks."}
{"id": "2510.00415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00415", "abs": "https://arxiv.org/abs/2510.00415", "authors": ["Dadi Guo", "Tianyi Zhou", "Dongrui Liu", "Chen Qian", "Qihan Ren", "Shuai Shao", "Zhiyuan Fan", "Yi R. Fung", "Kun Wang", "Linfeng Zhang", "Jing Shao"], "title": "Towards Self-Evolving Benchmarks: Synthesizing Agent Trajectories via Test-Time Exploration under Validate-by-Reproduce Paradigm", "comment": "his is a work in progress due to methodology refinement and further\n  evaluation", "summary": "Recent advances in large language models (LLMs) and agent system designs have\nempowered agents with unprecedented levels of capability. However, existing\nagent benchmarks are showing a trend of rapid ceiling-hitting by newly\ndeveloped agents, making it difficult to meet the demands for evaluating agent\nabilities. To address this problem, we propose the Trajectory-based\nValidated-by-Reproducing Agent-benchmark Complexity Evolution (TRACE)\nframework. This framework takes an original task from an existing benchmark and\nencourages agents to freely explore and evolve it into a new task with higher\ndifficulty while recording validatable agent trajectories. The framework\nproceeds in three stages: (1) evolutionary proposal mining, which provides task\nevolution proposals through preliminary exploration and divergent thinking; (2)\nproblem formation and free exploration, where proposals are conceptualized into\nfeasible problem candidates and the agents then explore them freely while\nrecording their execution trajectories; and (3) multi-level validation, which\nensures that the evolved tasks are accompanied by validatable and reproducible\ntrajectories. Experiments on the GAIA benchmark demonstrate that the TRACE\nframework consistently enhances task complexity while improving the reliability\nof correctness through validatable execution trajectories. This work marks a\nparadigm shift from static, manually curated benchmarks to dynamic,\nself-evolving evaluation systems, providing a sustainable and challenging\nrunway for agent development."}
{"id": "2510.00436", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00436", "abs": "https://arxiv.org/abs/2510.00436", "authors": ["Sarvesh Soni", "Dina Demner-Fushman"], "title": "Automated Evaluation can Distinguish the Good and Bad AI Responses to Patient Questions about Hospitalization", "comment": null, "summary": "Automated approaches to answer patient-posed health questions are rising, but\nselecting among systems requires reliable evaluation. The current gold standard\nfor evaluating the free-text artificial intelligence (AI) responses--human\nexpert review--is labor-intensive and slow, limiting scalability. Automated\nmetrics are promising yet variably aligned with human judgments and often\ncontext-dependent. To address the feasibility of automating the evaluation of\nAI responses to hospitalization-related questions posed by patients, we\nconducted a large systematic study of evaluation approaches. Across 100 patient\ncases, we collected responses from 28 AI systems (2800 total) and assessed them\nalong three dimensions: whether a system response (1) answers the question, (2)\nappropriately uses clinical note evidence, and (3) uses general medical\nknowledge. Using clinician-authored reference answers to anchor metrics,\nautomated rankings closely matched expert ratings. Our findings suggest that\ncarefully designed automated evaluation can scale comparative assessment of AI\nsystems and support patient-clinician communication."}
{"id": "2510.00480", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00480", "abs": "https://arxiv.org/abs/2510.00480", "authors": ["Kenjiro Ide", "Taiga Someya", "Kohei Kawaguchi", "Keisuke Fujii"], "title": "Expandable Decision-Making States for Multi-Agent Deep Reinforcement Learning in Soccer Tactical Analysis", "comment": "28 pages, 9 figures", "summary": "Invasion team sports such as soccer produce a high-dimensional, strongly\ncoupled state space as many players continuously interact on a shared field,\nchallenging quantitative tactical analysis. Traditional rule-based analyses are\nintuitive, while modern predictive machine learning models often perform\npattern-matching without explicit agent representations. The problem we address\nis how to build player-level agent models from data, whose learned values and\npolicies are both tactically interpretable and robust across heterogeneous data\nsources. Here, we propose Expandable Decision-Making States (EDMS), a\nsemantically enriched state representation that augments raw positions and\nvelocities with relational variables (e.g., scoring of space, pass, and score),\ncombined with an action-masking scheme that gives on-ball and off-ball agents\ndistinct decision sets. Compared to prior work, EDMS maps learned value\nfunctions and action policies to human-interpretable tactical concepts (e.g.,\nmarking pressure, passing lanes, ball accessibility) instead of raw coordinate\nfeatures, and aligns agent choices with the rules of play. In the experiments,\nEDMS with action masking consistently reduced both action-prediction loss and\ntemporal-difference (TD) error compared to the baseline. Qualitative case\nstudies and Q-value visualizations further indicate that EDMS highlights\nhigh-risk, high-reward tactical patterns (e.g., fast counterattacks and\ndefensive breakthroughs). We also integrated our approach into an open-source\nlibrary and demonstrated compatibility with multiple commercial and open\ndatasets, enabling cross-provider evaluation and reproducible experiments."}
{"id": "2510.00492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00492", "abs": "https://arxiv.org/abs/2510.00492", "authors": ["Dong Bok Lee", "Seanie Lee", "Sangwoo Park", "Minki Kang", "Jinheon Baek", "Dongki Kim", "Dominik Wagner", "Jiongdao Jin", "Heejun Lee", "Tobias Bocklet", "Jinyu Wang", "Jingjing Fu", "Sung Ju Hwang", "Jiang Bia", "Lei Song"], "title": "Rethinking Reward Models for Multi-Domain Test-Time Scaling", "comment": null, "summary": "The reliability of large language models (LLMs) during test-time scaling is\noften assessed with \\emph{external verifiers} or \\emph{reward models} that\ndistinguish correct reasoning from flawed logic. Prior work generally assumes\nthat process reward models (PRMs), which score every intermediate reasoning\nstep, outperform outcome reward models (ORMs) that assess only the final\nanswer. This view is based mainly on evidence from narrow, math-adjacent\ndomains. We present the first unified evaluation of four reward model variants,\ndiscriminative ORM and PRM (\\DisORM, \\DisPRM) and generative ORM and PRM\n(\\GenORM, \\GenPRM), across 14 diverse domains. Contrary to conventional wisdom,\nwe find that (i) \\DisORM performs on par with \\DisPRM, (ii) \\GenPRM is not\ncompetitive, and (iii) overall, \\GenORM is the most robust, yielding\nsignificant and consistent gains across every tested domain. We attribute this\nto PRM-style stepwise scoring, which inherits label noise from LLM\nauto-labeling and has difficulty evaluating long reasoning trajectories,\nincluding those involving self-correcting reasoning. Our theoretical analysis\nshows that step-wise aggregation compounds errors as reasoning length grows,\nand our empirical observations confirm this effect. These findings challenge\nthe prevailing assumption that fine-grained supervision is always better and\nsupport generative outcome verification for multi-domain deployment. We\npublicly release our code, datasets, and checkpoints at\n\\href{https://github.com/db-Lee/Multi-RM}{\\underline{\\small\\texttt{https://github.com/db-Lee/Multi-RM}}}\nto facilitate future research in multi-domain settings."}
{"id": "2510.00523", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00523", "abs": "https://arxiv.org/abs/2510.00523", "authors": ["Wei-Yao Wang", "Kazuya Tateishi", "Qiyu Wu", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "VIRTUE: Visual-Interactive Text-Image Universal Embedder", "comment": "25 pages", "summary": "Multimodal representation learning models have demonstrated successful\noperation across complex tasks, and the integration of vision-language models\n(VLMs) has further enabled embedding models with instruction-following\ncapabilities. However, existing embedding models lack visual-interactive\ncapabilities to specify regions of interest from users (e.g., point, bounding\nbox, mask), which have been explored in generative models to broaden their\nhuman-interactive applicability. Equipping embedding models with visual\ninteractions not only would unlock new applications with localized grounding of\nuser intent, which remains unexplored, but also enable the models to learn\nentity-level information within images to complement their global\nrepresentations for conventional embedding tasks. In this paper, we propose a\nnovel Visual-InteRactive Text-Image Universal Embedder (VIRTUE) that extends\nthe capabilities of the segmentation model and the vision-language model to the\nrealm of representation learning. In VIRTUE, the segmentation model can process\nvisual prompts that pinpoint specific regions within an image, thereby enabling\nthe embedder to handle complex and ambiguous scenarios more precisely. To\nevaluate the visual-interaction ability of VIRTUE, we introduce a large-scale\nSegmentation-and-Scene Caption Retrieval (SCaR) benchmark comprising 1M samples\nthat aims to retrieve the text caption by jointly considering the entity with a\nspecific object and image scene. VIRTUE consistently achieves a\nstate-of-the-art performance with significant improvements across 36 universal\nMMEB (3.1%-8.5%) and five visual-interactive SCaR (15.2%-20.3%) tasks."}
{"id": "2510.00552", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.00552", "abs": "https://arxiv.org/abs/2510.00552", "authors": ["Leopold Müller", "Joshua Holstein", "Sarah Bause", "Gerhard Satzger", "Niklas Kühl"], "title": "Data Quality Challenges in Retrieval-Augmented Generation", "comment": "Preprint version. Accepted for presentation at the International\n  Conference on Information Systems (ICIS 2025). Please cite the published\n  version when available", "summary": "Organizations increasingly adopt Retrieval-Augmented Generation (RAG) to\nenhance Large Language Models with enterprise-specific knowledge. However,\ncurrent data quality (DQ) frameworks have been primarily developed for static\ndatasets, and only inadequately address the dynamic, multi-stage nature of RAG\nsystems. This study aims to develop DQ dimensions for this new type of AI-based\nsystems. We conduct 16 semi-structured interviews with practitioners of leading\nIT service companies. Through a qualitative content analysis, we inductively\nderive 15 distinct DQ dimensions across the four processing stages of RAG\nsystems: data extraction, data transformation, prompt & search, and generation.\nOur findings reveal that (1) new dimensions have to be added to traditional DQ\nframeworks to also cover RAG contexts; (2) these new dimensions are\nconcentrated in early RAG steps, suggesting the need for front-loaded quality\nmanagement strategies, and (3) DQ issues transform and propagate through the\nRAG pipeline, necessitating a dynamic, step-aware approach to quality\nmanagement."}
{"id": "2510.00565", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00565", "abs": "https://arxiv.org/abs/2510.00565", "authors": ["Shojiro Yamabe", "Jun Sakuma"], "title": "Toward Safer Diffusion Language Models: Discovery and Mitigation of Priming Vulnerability", "comment": null, "summary": "Diffusion language models (DLMs) generate tokens in parallel through\niterative denoising, which can reduce latency and enable bidirectional\nconditioning. However, the safety risks posed by jailbreak attacks that exploit\nthis inference mechanism are not well understood. In this paper, we reveal that\nDLMs have a critical vulnerability stemming from their iterative denoising\nprocess and propose a countermeasure. Specifically, our investigation shows\nthat if an affirmative token for a harmful query appears at an intermediate\nstep, subsequent denoising can be steered toward a harmful response even in\naligned models. As a result, simply injecting such affirmative tokens can\nreadily bypass the safety guardrails. Furthermore, we demonstrate that the\nvulnerability allows existing optimization-based jailbreak attacks to succeed\non DLMs. Building on this analysis, we propose a novel safety alignment method\ntailored to DLMs that trains models to generate safe responses from\ncontaminated intermediate states that contain affirmative tokens. Our\nexperiments indicate that the proposed method significantly mitigates the\nvulnerability with minimal impact on task performance. Furthermore, our method\nimproves robustness against conventional jailbreak attacks. Our work\nunderscores the need for DLM-specific safety research."}
{"id": "2510.00615", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00615", "abs": "https://arxiv.org/abs/2510.00615", "authors": ["Minki Kang", "Wei-Ning Chen", "Dongge Han", "Huseyin A. Inan", "Lukas Wutschitz", "Yanzhi Chen", "Robert Sim", "Saravan Rajmohan"], "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "comment": "Preprint", "summary": "Large language models (LLMs) are increasingly deployed as agents in dynamic,\nreal-world environments, where success requires both reasoning and effective\ntool use. A central challenge for agentic tasks is the growing context length,\nas agents must accumulate long histories of actions and observations. This\nexpansion raises costs and reduces efficiency in long-horizon tasks, yet prior\nwork on context compression has mostly focused on single-step tasks or narrow\napplications. We introduce Agent Context Optimization (ACON), a unified\nframework that optimally compresses both environment observations and\ninteraction histories into concise yet informative condensations. ACON\nleverages compression guideline optimization in natural language space: given\npaired trajectories where full context succeeds but compressed context fails,\ncapable LLMs analyze the causes of failure, and the compression guideline is\nupdated accordingly. Furthermore, we propose distilling the optimized LLM\ncompressor into smaller models to reduce the overhead of the additional module.\nExperiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON\nreduces memory usage by 26-54% (peak tokens) while largely preserving task\nperformance, preserves over 95% of accuracy when distilled into smaller\ncompressors, and enhances smaller LMs as long-horizon agents with up to 46%\nperformance improvement."}
{"id": "2510.00620", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00620", "abs": "https://arxiv.org/abs/2510.00620", "authors": ["Rosni Vasu", "Peter Jansen", "Pao Siangliulue", "Cristina Sarasua", "Abraham Bernstein", "Peter Clark", "Bhavana Dalvi Mishra"], "title": "HARPA: A Testability-Driven, Literature-Grounded Framework for Research Ideation", "comment": "10 pages (main), 65 pages total", "summary": "While there has been a surge of interest in automated scientific discovery\n(ASD), especially with the emergence of LLMs, it remains challenging for tools\nto generate hypotheses that are both testable and grounded in the scientific\nliterature. Additionally, existing ideation tools are not adaptive to prior\nexperimental outcomes. We developed HARPA to address these challenges by\nincorporating the ideation workflow inspired by human researchers. HARPA first\nidentifies emerging research trends through literature mining, then explores\nhypothesis design spaces, and finally converges on precise, testable hypotheses\nby pinpointing research gaps and justifying design choices. Our evaluations\nshow that HARPA-generated hypothesis-driven research proposals perform\ncomparably to a strong baseline AI-researcher across most qualitative\ndimensions (e.g., specificity, novelty, overall quality), but achieve\nsignificant gains in feasibility(+0.78, p$<0.05$, bootstrap) and groundedness\n(+0.85, p$<0.01$, bootstrap) on a 10-point Likert scale. When tested with the\nASD agent (CodeScientist), HARPA produced more successful executions (20 vs. 11\nout of 40) and fewer failures (16 vs. 21 out of 40), showing that expert\nfeasibility judgments track with actual execution success. Furthermore, to\nsimulate how researchers continuously refine their understanding of what\nhypotheses are both testable and potentially interesting from experience, HARPA\nlearns a reward model that scores new hypotheses based on prior experimental\noutcomes, achieving approx. a 28\\% absolute gain over HARPA's untrained\nbaseline scorer. Together, these methods represent a step forward in the field\nof AI-driven scientific discovery."}
{"id": "2510.00625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00625", "abs": "https://arxiv.org/abs/2510.00625", "authors": ["Wei Liu", "Haomei Xu", "Bingqing Liu", "Zhiying Deng", "Haozhao Wang", "Jun Wang", "Ruixuan Li", "Yee Whye Teh", "Wee Sun Lee"], "title": "Is Model Editing Built on Sand? Revealing Its Illusory Success and Fragile Foundation", "comment": "This is a work in progress. Comments and suggestions are welcome", "summary": "Large language models (LLMs) inevitably encode outdated or incorrect\nknowledge. Updating, deleting, and forgetting such knowledge is important for\nalignment, safety, and other issues. To address this issue, model editing has\nemerged as a promising paradigm: by precisely editing a small subset of\nparameters such that a specific fact is updated while preserving other\nknowledge. Despite its great success reported in previous papers, we find the\napparent reliability of editing rests on a fragile foundation and the current\nliterature is largely driven by illusory success. The fundamental goal of\nsteering the model's output toward a target with minimal modification would\nencourage exploiting hidden shortcuts, rather than utilizing real semantics.\nThis problem directly challenges the feasibility of the current model editing\nliterature at its very foundation, as shortcuts are inherently at odds with\nrobust knowledge integration. Coincidentally, this issue has long been obscured\nby evaluation frameworks that lack the design of negative examples. To uncover\nit, we systematically develop a suite of new evaluation methods. Strikingly, we\nfind that state-of-the-art approaches collapse even under the simplest negation\nqueries. Our empirical evidence shows that editing is likely to be based on\nshortcuts rather than full semantics, calling for an urgent reconsideration of\nthe very basis of model editing before further advancements can be meaningfully\npursued."}
{"id": "2510.00627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00627", "abs": "https://arxiv.org/abs/2510.00627", "authors": ["Bingzhang Wang", "Kehua Chen", "Yinhai Wang"], "title": "Collaborative-Distilled Diffusion Models (CDDM) for Accelerated and Lightweight Trajectory Prediction", "comment": null, "summary": "Trajectory prediction is a fundamental task in Autonomous Vehicles (AVs) and\nIntelligent Transportation Systems (ITS), supporting efficient motion planning\nand real-time traffic safety management. Diffusion models have recently\ndemonstrated strong performance in probabilistic trajectory prediction, but\ntheir large model size and slow sampling process hinder real-world deployment.\nThis paper proposes Collaborative-Distilled Diffusion Models (CDDM), a novel\nmethod for real-time and lightweight trajectory prediction. Built upon\nCollaborative Progressive Distillation (CPD), CDDM progressively transfers\nknowledge from a high-capacity teacher diffusion model to a lightweight student\nmodel, jointly reducing both the number of sampling steps and the model size\nacross distillation iterations. A dual-signal regularized distillation loss is\nfurther introduced to incorporate guidance from both the teacher and\nground-truth data, mitigating potential overfitting and ensuring robust\nperformance. Extensive experiments on the ETH-UCY pedestrian benchmark and the\nnuScenes vehicle benchmark demonstrate that CDDM achieves state-of-the-art\nprediction accuracy. The well-distilled CDDM retains 96.2% and 95.5% of the\nbaseline model's ADE and FDE performance on pedestrian trajectories, while\nrequiring only 231K parameters and 4 or 2 sampling steps, corresponding to 161x\ncompression, 31x acceleration, and 9 ms latency. Qualitative results further\nshow that CDDM generates diverse and accurate trajectories under dynamic agent\nbehaviors and complex social interactions. By bridging high-performing\ngenerative models with practical deployment constraints, CDDM enables\nresource-efficient probabilistic prediction for AVs and ITS. Code is available\nat https://github.com/bingzhangw/CDDM."}
{"id": "2510.00636", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00636", "abs": "https://arxiv.org/abs/2510.00636", "authors": ["Alessio Devoto", "Maximilian Jeblick", "Simon Jégou"], "title": "Expected Attention: KV Cache Compression by Estimating Attention from Future Queries Distribution", "comment": null, "summary": "Memory consumption of the Key-Value (KV) cache represents a major bottleneck\nfor efficient large language model inference. While attention-score-based KV\ncache pruning shows promise, it faces critical practical limitations: attention\nscores from future tokens are unavailable during compression, and modern\nimplementations like Flash Attention do not materialize the full attention\nmatrix, making past scores inaccessible. To overcome these challenges, we\nintroduce $\\textbf{Expected Attention, a training-free compression method}$\nthat estimates KV pairs importance by predicting how future queries will attend\nto them. Our approach leverages the distributional properties of LLM\nactivations to compute expected attention scores in closed form for each KV\npair. These scores enable principled ranking and pruning of KV pairs with\nminimal impact on the residual stream, achieving effective compression without\nperformance degradation. Importantly, our method operates seamlessly across\nboth prefilling and decoding phases, consistently outperforming\nstate-of-the-art baselines in both scenarios. Finally, $\\textbf{we release\nKVPress, a comprehensive library to enable researchers to implement and\nbenchmark KV cache compression methods, already including more than 20\ntechniques}$."}
{"id": "2510.00664", "categories": ["cs.AI", "cs.CV", "68", "I.2; I.4"], "pdf": "https://arxiv.org/pdf/2510.00664", "abs": "https://arxiv.org/abs/2510.00664", "authors": ["Giacomo Ignesti", "Davide Moroni", "Massimo Martinelli"], "title": "Batch-CAM: Introduction to better reasoning in convolutional deep learning models", "comment": "18 pages, 7 figures, submitted to SN Computer Science Springer Nature", "summary": "Understanding the inner workings of deep learning models is crucial for\nadvancing artificial intelligence, particularly in high-stakes fields such as\nhealthcare, where accurate explanations are as vital as precision. This paper\nintroduces Batch-CAM, a novel training paradigm that fuses a batch\nimplementation of the Grad-CAM algorithm with a prototypical reconstruction\nloss. This combination guides the model to focus on salient image features,\nthereby enhancing its performance across classification tasks. Our results\ndemonstrate that Batch-CAM achieves a simultaneous improvement in accuracy and\nimage reconstruction quality while reducing training and inference times. By\nensuring models learn from evidence-relevant information,this approach makes a\nrelevant contribution to building more transparent, explainable, and\ntrustworthy AI systems."}
{"id": "2510.00689", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00689", "abs": "https://arxiv.org/abs/2510.00689", "authors": ["Chi-Huang Lin", "Ting Han Wei", "Chun-Jui Wang", "Hung Guei", "Chung-Chin Shih", "Yun-Jui Tsai", "I-Chen Wu", "Ti-Rong Wu"], "title": "Relevance-Zone Reduction in Game Solving", "comment": "Accepted by the Advances in Computer Games (ACG 2025)", "summary": "Game solving aims to find the optimal strategies for all players and\ndetermine the theoretical outcome of a game. However, due to the exponential\ngrowth of game trees, many games remain unsolved, even though methods like\nAlphaZero have demonstrated super-human level in game playing. The\nRelevance-Zone (RZ) is a local strategy reuse technique that restricts the\nsearch to only the regions relevant to the outcome, significantly reducing the\nsearch space. However, RZs are not unique. Different solutions may result in\nRZs of varying sizes. Smaller RZs are generally more favorable, as they\nincrease the chance of reuse and improve pruning efficiency. To this end, we\npropose an iterative RZ reduction method that repeatedly solves the same\nposition while gradually restricting the region involved, guiding the solver\ntoward smaller RZs. We design three constraint generation strategies and\nintegrate an RZ Pattern Table to fully leverage past solutions. In experiments\non 7x7 Killall-Go, our method reduces the average RZ size to 85.95% of the\noriginal. Furthermore, the reduced RZs can be permanently stored as reusable\nknowledge for future solving tasks, especially for larger board sizes or\ndifferent openings."}
{"id": "2510.00690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00690", "abs": "https://arxiv.org/abs/2510.00690", "authors": ["Yunhao Wang", "Ziting Li", "Shuai Chen", "Tao Liu", "Chao Song", "Junjie Jiang", "Jian Zhu", "Peng Gao", "Bin Qin"], "title": "ACPO: Adaptive Curriculum Policy Optimization for Aligning Vision-Language Models in Complex Reasoning", "comment": null, "summary": "Aligning large-scale vision-language models (VLMs) for complex reasoning via\nreinforcement learning is often hampered by the limitations of existing policy\noptimization algorithms, such as static training schedules and the rigid,\nuniform clipping mechanism in Proximal Policy Optimization (PPO). In this work,\nwe introduce Adaptive Curriculum Policy Optimization (ACPO), a novel framework\nthat addresses these challenges through a dual-component adaptive learning\nstrategy. First, ACPO employs a dynamic curriculum that orchestrates a\nprincipled transition from a stable, near on-policy exploration phase to an\nefficient, off-policy exploitation phase by progressively increasing sample\nreuse. Second, we propose an Advantage-Aware Adaptive Clipping (AAAC) mechanism\nthat replaces the fixed clipping hyperparameter with dynamic, sample-wise\nbounds modulated by the normalized advantage of each token. This allows for\nmore granular and robust policy updates, enabling larger gradients for\nhigh-potential samples while safeguarding against destructive ones. We conduct\nextensive experiments on a suite of challenging multimodal reasoning\nbenchmarks, including MathVista, LogicVista, and MMMU-Pro. Results demonstrate\nthat ACPO consistently outperforms strong baselines such as DAPO and PAPO,\nachieving state-of-the-art performance, accelerated convergence, and superior\ntraining stability."}
{"id": "2510.00706", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00706", "abs": "https://arxiv.org/abs/2510.00706", "authors": ["Yusif Ibrahimov", "Tarique Anwar", "Tommy Yuan", "Turan Mutallimov", "Elgun Hasanov"], "title": "AttentionDep: Domain-Aware Attention for Explainable Depression Severity Assessment", "comment": null, "summary": "In today's interconnected society, social media platforms provide a window\ninto individuals' thoughts, emotions, and mental states. This paper explores\nthe use of platforms like Facebook, X (formerly Twitter), and Reddit for\ndepression severity detection. We propose AttentionDep, a domain-aware\nattention model that drives explainable depression severity estimation by\nfusing contextual and domain knowledge. Posts are encoded hierarchically using\nunigrams and bigrams, with attention mechanisms highlighting clinically\nrelevant tokens. Domain knowledge from a curated mental health knowledge graph\nis incorporated through a cross-attention mechanism, enriching the contextual\nfeatures. Finally, depression severity is predicted using an ordinal regression\nframework that respects the clinical-relevance and natural ordering of severity\nlevels. Our experiments demonstrate that AttentionDep outperforms\nstate-of-the-art baselines by over 5% in graded F1 score across datasets, while\nproviding interpretable insights into its predictions. This work advances the\ndevelopment of trustworthy and transparent AI systems for mental health\nassessment from social media."}
{"id": "2510.00732", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00732", "abs": "https://arxiv.org/abs/2510.00732", "authors": ["Yuchen Tian", "Ruiyuan Huang", "Xuanwu Wang", "Jing Ma", "Zengfeng Huang", "Ziyang Luo", "Hongzhan Lin", "Da Zheng", "Lun Du"], "title": "EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty", "comment": null, "summary": "Large Language Models (LLMs) for formal theorem proving have shown\nsignificant promise, yet they often lack generalizability and are fragile to\neven minor transformations of problem statements. To address this limitation,\nwe introduce a novel data augmentation pipeline designed to enhance model\nrobustness from two perspectives: symmetry and difficulty. From the symmetry\nperspective, we propose two complementary methods: EvolAST, an Abstract Syntax\nTree (AST) based approach that targets syntactic symmetry to generate\nsemantically equivalent problem variants, and EvolDomain, which leverages LLMs\nto address semantic symmetry by translating theorems across mathematical\ndomains. From the difficulty perspective, we propose EvolDifficulty, which uses\ncarefully designed evolutionary instructions to guide LLMs in generating new\ntheorems with a wider range of difficulty. We then use the evolved data to\ntrain EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver\nestablishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%\npass@32 rate, surpassing all models of comparable size, including\nreasoning-based models. It also sets new SOTA records for non-reasoning models\non MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and\nIneq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our\ndata augmentation pipeline's effectiveness across multiple benchmarks."}
{"id": "2510.00778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00778", "abs": "https://arxiv.org/abs/2510.00778", "authors": ["Seunghoo Hong", "Geonho Son", "Juhun Lee", "Simon S. Woo"], "title": "DIA: The Adversarial Exposure of Deterministic Inversion in Diffusion Models", "comment": "ICCV2025", "summary": "Diffusion models have shown to be strong representation learners, showcasing\nstate-of-the-art performance across multiple domains. Aside from accelerated\nsampling, DDIM also enables the inversion of real images back to their latent\ncodes. A direct inheriting application of this inversion operation is real\nimage editing, where the inversion yields latent trajectories to be utilized\nduring the synthesis of the edited image. Unfortunately, this practical tool\nhas enabled malicious users to freely synthesize misinformative or deepfake\ncontents with greater ease, which promotes the spread of unethical and abusive,\nas well as privacy-, and copyright-infringing contents. While defensive\nalgorithms such as AdvDM and Photoguard have been shown to disrupt the\ndiffusion process on these images, the misalignment between their objectives\nand the iterative denoising trajectory at test time results in weak disruptive\nperformance.In this work, we present the DDIM Inversion Attack (DIA) that\nattacks the integrated DDIM trajectory path. Our results support the effective\ndisruption, surpassing previous defensive methods across various editing\nmethods. We believe that our frameworks and results can provide practical\ndefense methods against the malicious use of AI for both the industry and the\nresearch community. Our code is available here:\nhttps://anonymous.4open.science/r/DIA-13419/."}
{"id": "2510.00793", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00793", "abs": "https://arxiv.org/abs/2510.00793", "authors": ["J. A. Hageman", "C. F. W. Peeters"], "title": "AI in data science education: experiences from the classroom", "comment": "6 pages, 0 figures", "summary": "This study explores the integration of AI, particularly large language models\n(LLMs) like ChatGPT, into educational settings, focusing on the implications\nfor teaching and learning. Through interviews with course coordinators from\ndata science courses at Wageningen University, this research identifies both\nthe benefits and challenges associated with AI in the classroom. While AI tools\ncan streamline tasks and enhance learning, concerns arise regarding students'\noverreliance on these technologies, potentially hindering the development of\nessential cognitive and problem solving skills. The study highlights the\nimportance of responsible AI usage, ethical considerations, and the need for\nadapting assessment methods to ensure educational outcomes are met. With\ncareful integration, AI can be a valuable asset in education, provided it is\nused to complement rather than replace fundamental learning processes."}
{"id": "2510.00795", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00795", "abs": "https://arxiv.org/abs/2510.00795", "authors": ["Anastasia Vepreva", "Julia Razlivina", "Maria Eremeeva", "Nina Gubina", "Anastasia Orlova", "Aleksei Dmitrenko", "Ksenya Kapranova", "Susan Jyakhwo", "Nikita Vasilev", "Arsen Sarkisyan", "Ivan Yu. Chernyshov", "Vladimir Vinogradov", "Andrei Dmitrenko"], "title": "Benchmarking Agentic Systems in Automated Scientific Information Extraction with ChemX", "comment": "Accepted at The AI for Accelerated Materials Discovery (AI4Mat)\n  Workshop, NeurIPS 2025", "summary": "The emergence of agent-based systems represents a significant advancement in\nartificial intelligence, with growing applications in automated data\nextraction. However, chemical information extraction remains a formidable\nchallenge due to the inherent heterogeneity of chemical data. Current\nagent-based approaches, both general-purpose and domain-specific, exhibit\nlimited performance in this domain. To address this gap, we present ChemX, a\ncomprehensive collection of 10 manually curated and domain-expert-validated\ndatasets focusing on nanomaterials and small molecules. These datasets are\ndesigned to rigorously evaluate and enhance automated extraction methodologies\nin chemistry. To demonstrate their utility, we conduct an extensive\nbenchmarking study comparing existing state-of-the-art agentic systems such as\nChatGPT Agent and chemical-specific data extraction agents. Additionally, we\nintroduce our own single-agent approach that enables precise control over\ndocument preprocessing prior to extraction. We further evaluate the performance\nof modern baselines, such as GPT-5 and GPT-5 Thinking, to compare their\ncapabilities with agentic approaches. Our empirical findings reveal persistent\nchallenges in chemical information extraction, particularly in processing\ndomain-specific terminology, complex tabular and schematic representations, and\ncontext-dependent ambiguities. The ChemX benchmark serves as a critical\nresource for advancing automated information extraction in chemistry,\nchallenging the generalization capabilities of existing methods, and providing\nvaluable insights into effective evaluation strategies."}
{"id": "2510.00817", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.00817", "abs": "https://arxiv.org/abs/2510.00817", "authors": ["Nicholas Leisegang", "Giovanni Casini", "Thomas Meyer"], "title": "Semantic Bridges Between First Order c-Representations and Cost-Based Semantics: An Initial Perspective", "comment": null, "summary": "Weighted-knowledge bases and cost-based semantics represent a recent\nformalism introduced by Bienvenu et al. for Ontology Mediated Data Querying in\nthe case where a given knowledge base is inconsistent. This is done by adding a\nweight to each statement in the knowledge base (KB), and then giving each DL\ninterpretation a cost based on how often it breaks rules in the KB. In this\npaper we compare this approach with c-representations, a form of non-monotonic\nreasoning originally introduced by Kern-Isberner. c-Representations describe a\nmeans to interpret defeasible concept inclusions in the first-order case. This\nis done by assigning a numerical ranking to each interpretations via penalties\nfor each violated conditional. We compare these two approaches on a semantic\nlevel. In particular, we show that under certain conditions a weighted\nknowledge base and a set of defeasible conditionals can generate the same\nordering on interpretations, and therefore an equivalence of semantic\nstructures up to relative cost. Moreover, we compare entailment described in\nboth cases, where certain notions are equivalently expressible in both\nformalisms. Our results have the potential to benefit further work on both\ncost-based semantics and c-representations"}
{"id": "2510.00821", "categories": ["cs.AI", "90C05, 68T27", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2510.00821", "abs": "https://arxiv.org/abs/2510.00821", "authors": ["Andrés Corrada-Emmanuel"], "title": "Logical Consistency Between Disagreeing Experts and Its Role in AI Safety", "comment": "10 pages, 7 figures", "summary": "If two experts disagree on a test, we may conclude both cannot be 100 per\ncent correct. But if they completely agree, no possible evaluation can be\nexcluded. This asymmetry in the utility of agreements versus disagreements is\nexplored here by formalizing a logic of unsupervised evaluation for\nclassifiers. Its core problem is computing the set of group evaluations that\nare logically consistent with how we observe them agreeing and disagreeing in\ntheir decisions. Statistical summaries of their aligned decisions are inputs\ninto a Linear Programming problem in the integer space of possible correct or\nincorrect responses given true labels. Obvious logical constraints, such as,\nthe number of correct responses cannot exceed the number of observed responses,\nare inequalities. But in addition, there are axioms, universally applicable\nlinear equalities that apply to all finite tests. The practical and immediate\nutility of this approach to unsupervised evaluation using only logical\nconsistency is demonstrated by building no-knowledge alarms that can detect\nwhen one or more LLMs-as-Judges are violating a minimum grading threshold\nspecified by the user."}
{"id": "2510.00831", "categories": ["cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00831", "abs": "https://arxiv.org/abs/2510.00831", "authors": ["Julian Oelhaf", "Georg Kordowich", "Changhun Kim", "Paula Andrea Pérez-Toro", "Christian Bergler", "Andreas Maier", "Johann Jäger", "Siming Bayer"], "title": "Benchmarking Machine Learning Models for Fault Classification and Localization in Power System Protection", "comment": "Submitted to ICASSP 2026; under review", "summary": "The increasing integration of distributed energy resources (DERs),\nparticularly renewables, poses significant challenges for power system\nprotection, with fault classification (FC) and fault localization (FL) being\namong the most critical tasks. Conventional protection schemes, based on fixed\nthresholds, cannot reliably identify and localize short circuits with the\nincreasing complexity of the grid under dynamic conditions. Machine learning\n(ML) offers a promising alternative; however, systematic benchmarks across\nmodels and settings remain limited. This work presents, for the first time, a\ncomparative benchmarking study of classical ML models for FC and FL in power\nsystem protection based on EMT data. Using voltage and current waveforms\nsegmented into sliding windows of 10 ms to 50 ms, we evaluate models under\nrealistic real-time constraints. Performance is assessed in terms of accuracy,\nrobustness to window size, and runtime efficiency. The best-performing FC model\nachieved an F1 score of 0.992$\\pm$0.001, while the top FL model reached an R2\nof 0.806$\\pm$0.008 with a mean processing time of 0.563 ms."}
{"id": "2510.00836", "categories": ["cs.AI", "cs.CE", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2510.00836", "abs": "https://arxiv.org/abs/2510.00836", "authors": ["Jieun Yu", "Minjung Park", "Sangmi Chai"], "title": "Improving Cryptocurrency Pump-and-Dump Detection through Ensemble-Based Models and Synthetic Oversampling Techniques", "comment": null, "summary": "This study aims to detect pump and dump (P&D) manipulation in cryptocurrency\nmarkets, where the scarcity of such events causes severe class imbalance and\nhinders accurate detection. To address this issue, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, and advanced ensemble learning\nmodels were evaluated to distinguish manipulative trading behavior from normal\nmarket activity. The experimental results show that applying SMOTE greatly\nenhanced the ability of all models to detect P&D events by increasing recall\nand improving the overall balance between precision and recall. In particular,\nXGBoost and LightGBM achieved high recall rates (94.87% and 93.59%,\nrespectively) with strong F1-scores and demonstrated fast computational\nperformance, making them suitable for near real time surveillance. These\nfindings indicate that integrating data balancing techniques with ensemble\nmethods significantly improves the early detection of manipulative activities,\ncontributing to a fairer, more transparent, and more stable cryptocurrency\nmarket."}
{"id": "2510.00844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00844", "abs": "https://arxiv.org/abs/2510.00844", "authors": ["Jianhao Chen", "Chenxu Wang", "Gengrui Zhang", "Peng Ye", "Lei Bai", "Wei Hu", "Yuzhong Qu", "Shuyue Hu"], "title": "Learning Compact Representations of LLM Abilities via Item Response Theory", "comment": null, "summary": "Recent years have witnessed a surge in the number of large language models\n(LLMs), yet efficiently managing and utilizing these vast resources remains a\nsignificant challenge. In this work, we explore how to learn compact\nrepresentations of LLM abilities that can facilitate downstream tasks, such as\nmodel routing and performance prediction on new benchmarks. We frame this\nproblem as estimating the probability that a given model will correctly answer\na specific query. Inspired by the item response theory (IRT) in psychometrics,\nwe model this probability as a function of three key factors: (i) the model's\nmulti-skill ability vector, (2) the query's discrimination vector that\nseparates models of differing skills, and (3) the query's difficulty scalar. To\nlearn these parameters jointly, we introduce a Mixture-of-Experts (MoE) network\nthat couples model- and query-level embeddings. Extensive experiments\ndemonstrate that our approach leads to state-of-the-art performance in both\nmodel routing and benchmark accuracy prediction. Moreover, analysis validates\nthat the learned parameters encode meaningful, interpretable information about\nmodel capabilities and query characteristics."}
{"id": "2510.00876", "categories": ["cs.AI", "68T20", "I.2.8"], "pdf": "https://arxiv.org/pdf/2510.00876", "abs": "https://arxiv.org/abs/2510.00876", "authors": ["Pietro Totis", "Alberto Pozanco", "Daniel Borrajo"], "title": "Unveiling Interesting Insights: Monte Carlo Tree Search for Knowledge Discovery", "comment": null, "summary": "Organizations are increasingly focused on leveraging data from their\nprocesses to gain insights and drive decision-making. However, converting this\ndata into actionable knowledge remains a difficult and time-consuming task.\nThere is often a gap between the volume of data collected and the ability to\nprocess and understand it, which automated knowledge discovery aims to fill.\nAutomated knowledge discovery involves complex open problems, including\neffectively navigating data, building models to extract implicit relationships,\nand considering subjective goals and knowledge. In this paper, we introduce a\nnovel method for Automated Insights and Data Exploration (AIDE), that serves as\na robust foundation for tackling these challenges through the use of Monte\nCarlo Tree Search (MCTS). We evaluate AIDE using both real-world and synthetic\ndata, demonstrating its effectiveness in identifying data transformations and\nmodels that uncover interesting data patterns. Among its strengths, AIDE's\nMCTS-based framework offers significant extensibility, allowing for future\nintegration of additional pattern extraction strategies and domain knowledge.\nThis makes AIDE a valuable step towards developing a comprehensive solution for\nautomated knowledge discovery."}
{"id": "2510.00894", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00894", "abs": "https://arxiv.org/abs/2510.00894", "authors": ["Ran Liu", "Yuan Fang", "Xiaoli Li"], "title": "FusionAdapter for Few-Shot Relation Learning in Multimodal Knowledge Graphs", "comment": "Archived paper", "summary": "Multimodal Knowledge Graphs (MMKGs) incorporate various modalities, including\ntext and images, to enhance entity and relation representations. Notably,\ndifferent modalities for the same entity often present complementary and\ndiverse information. However, existing MMKG methods primarily align modalities\ninto a shared space, which tends to overlook the distinct contributions of\nspecific modalities, limiting their performance particularly in low-resource\nsettings. To address this challenge, we propose FusionAdapter for the learning\nof few-shot relationships (FSRL) in MMKG. FusionAdapter introduces (1) an\nadapter module that enables efficient adaptation of each modality to unseen\nrelations and (2) a fusion strategy that integrates multimodal entity\nrepresentations while preserving diverse modality-specific characteristics. By\neffectively adapting and fusing information from diverse modalities,\nFusionAdapter improves generalization to novel relations with minimal\nsupervision. Extensive experiments on two benchmark MMKG datasets demonstrate\nthat FusionAdapter achieves superior performance over state-of-the-art methods."}
{"id": "2510.00922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00922", "abs": "https://arxiv.org/abs/2510.00922", "authors": ["Shashank Reddy Chirra", "Jayden Teoh", "Praveen Paruchuri", "Pradeep Varakantham"], "title": "On Discovering Algorithms for Adversarial Imitation Learning", "comment": null, "summary": "Adversarial Imitation Learning (AIL) methods, while effective in settings\nwith limited expert demonstrations, are often considered unstable. These\napproaches typically decompose into two components: Density Ratio (DR)\nestimation $\\frac{\\rho_E}{\\rho_{\\pi}}$, where a discriminator estimates the\nrelative occupancy of state-action pairs under the policy versus the expert;\nand Reward Assignment (RA), where this ratio is transformed into a reward\nsignal used to train the policy. While significant research has focused on\nimproving density estimation, the role of reward assignment in influencing\ntraining dynamics and final policy performance has been largely overlooked. RA\nfunctions in AIL are typically derived from divergence minimization objectives,\nrelying heavily on human design and ingenuity. In this work, we take a\ndifferent approach: we investigate the discovery of data-driven RA functions,\ni.e, based directly on the performance of the resulting imitation policy. To\nthis end, we leverage an LLM-guided evolutionary framework that efficiently\nexplores the space of RA functions, yielding \\emph{Discovered Adversarial\nImitation Learning} (DAIL), the first meta-learnt AIL algorithm. Remarkably,\nDAIL generalises across unseen environments and policy optimization algorithms,\noutperforming the current state-of-the-art of \\emph{human-designed} baselines.\nFinally, we analyse why DAIL leads to more stable training, offering novel\ninsights into the role of RA functions in the stability of AIL. Code is\npublicly available: https://github.com/shshnkreddy/DAIL."}
{"id": "2510.00958", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.00958", "abs": "https://arxiv.org/abs/2510.00958", "authors": ["Yoonju Sim", "Hyeonah Kim", "Changhyun Kwon"], "title": "Test-Time Search in Neural Graph Coarsening Procedures for the Capacitated Vehicle Routing Problem", "comment": null, "summary": "The identification of valid inequalities, such as the rounded capacity\ninequalities (RCIs), is a key component of cutting plane methods for the\nCapacitated Vehicle Routing Problem (CVRP). While a deep learning-based\nseparation method can learn to find high-quality cuts, our analysis reveals\nthat the model produces fewer cuts than expected because it is insufficiently\nsensitive to generate a diverse set of generated subsets. This paper proposes\nan alternative: enhancing the performance of a trained model at inference time\nthrough a new test-time search with stochasticity. First, we introduce\nstochastic edge selection into the graph coarsening procedure, replacing the\npreviously proposed greedy approach. Second, we propose the Graph Coarsening\nHistory-based Partitioning (GraphCHiP) algorithm, which leverages coarsening\nhistory to identify not only RCIs but also, for the first time, the Framed\ncapacity inequalities (FCIs). Experiments on randomly generated CVRP instances\ndemonstrate the effectiveness of our approach in reducing the dual gap compared\nto the existing neural separation method. Additionally, our method discovers\neffective FCIs on a specific instance, despite the challenging nature of\nidentifying such cuts."}
{"id": "2510.00960", "categories": ["cs.AI", "cs.NE", "cs.SY", "eess.SY", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.00960", "abs": "https://arxiv.org/abs/2510.00960", "authors": ["Miha Ožbot", "Igor Škrjanc", "Vitomir Štruc"], "title": "A Neuro-Fuzzy System for Interpretable Long-Term Stock Market Forecasting", "comment": "Published in: ERK 2025 -- 34th International Electrotechnical and\n  Computer Science Conference, Portoro\\v{z}, Slovenia, Sept. 25--26, 2025.\n  Proceedings published by Dru\\v{s}tvo Slovenska sekcija IEEE. ISSN: 2591-0442\n  (online). 4 pages, 2 figures", "summary": "In the complex landscape of multivariate time series forecasting, achieving\nboth accuracy and interpretability remains a significant challenge. This paper\nintroduces the Fuzzy Transformer (Fuzzformer), a novel recurrent neural network\narchitecture combined with multi-head self-attention and fuzzy inference\nsystems to analyze multivariate stock market data and conduct long-term time\nseries forecasting. The method leverages LSTM networks and temporal attention\nto condense multivariate data into interpretable features suitable for fuzzy\ninference systems. The resulting architecture offers comparable forecasting\nperformance to conventional models such as ARIMA and LSTM while providing\nmeaningful information flow within the network. The method was examined on the\nreal world stock market index S\\&P500. Initial results show potential for\ninterpretable forecasting and identify current performance tradeoffs,\nsuggesting practical application in understanding and forecasting stock market\nbehavior."}
{"id": "2510.00967", "categories": ["cs.AI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.00967", "abs": "https://arxiv.org/abs/2510.00967", "authors": ["Cong Yu", "Valter Uotila", "Shilong Deng", "Qingyuan Wu", "Tuo Shi", "Songlin Jiang", "Lei You", "Bo Zhao"], "title": "QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL", "comment": null, "summary": "Designing and optimizing task-specific quantum circuits are crucial to\nleverage the advantage of quantum computing. Recent large language model\n(LLM)-based quantum circuit generation has emerged as a promising automatic\nsolution. However, the fundamental challenges remain unaddressed: (i)\nparameterized quantum gates require precise numerical values for optimal\nperformance, which also depend on multiple aspects, including the number of\nquantum gates, their parameters, and the layout/depth of the circuits. (ii)\nLLMs often generate low-quality or incorrect quantum circuits due to the lack\nof quantum domain-specific knowledge. We propose QUASAR, an agentic\nreinforcement learning (RL) framework for quantum circuits generation and\noptimization based on tool-augmented LLMs. To align the LLM with\nquantum-specific knowledge and improve the generated quantum circuits, QUASAR\ndesigns (i) a quantum circuit verification approach with external quantum\nsimulators and (ii) a sophisticated hierarchical reward mechanism in RL\ntraining. Extensive evaluation shows improvements in both syntax and semantic\nperformance of the generated quantum circuits. When augmenting a 4B LLM, QUASAR\nhas achieved the validity of 99.31% in Pass@1 and 100% in Pass@10,\noutperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several\nsupervised-fine-tuning (SFT)-only and RL-only baselines."}
{"id": "2510.00976", "categories": ["cs.AI", "cs.CR", "cs.DC", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.00976", "abs": "https://arxiv.org/abs/2510.00976", "authors": ["Aueaphum Aueawatthanaphisut"], "title": "Adaptive Federated Few-Shot Rare-Disease Diagnosis with Energy-Aware Secure Aggregation", "comment": "6 pages, 6 figures, 12 equations, 1 algorithm", "summary": "Rare-disease diagnosis remains one of the most pressing challenges in digital\nhealth, hindered by extreme data scarcity, privacy concerns, and the limited\nresources of edge devices. This paper proposes the Adaptive Federated Few-Shot\nRare-Disease Diagnosis (AFFR) framework, which integrates three pillars: (i)\nfew-shot federated optimization with meta-learning to generalize from limited\npatient samples, (ii) energy-aware client scheduling to mitigate device\ndropouts and ensure balanced participation, and (iii) secure aggregation with\ncalibrated differential privacy to safeguard sensitive model updates. Unlike\nprior work that addresses these aspects in isolation, AFFR unifies them into a\nmodular pipeline deployable on real-world clinical networks. Experimental\nevaluation on simulated rare-disease detection datasets demonstrates up to 10%\nimprovement in accuracy compared with baseline FL, while reducing client\ndropouts by over 50% without degrading convergence. Furthermore,\nprivacy-utility trade-offs remain within clinically acceptable bounds. These\nfindings highlight AFFR as a practical pathway for equitable and trustworthy\nfederated diagnosis of rare conditions."}
{"id": "2510.01006", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01006", "abs": "https://arxiv.org/abs/2510.01006", "authors": ["Saravanan Venkatachalam"], "title": "Integrating AI and Ensemble Forecasting: Explainable Materials Planning with Scorecards and Trend Insights for a Large-Scale Manufacturer", "comment": null, "summary": "This paper presents a practical architecture for after-sales demand\nforecasting and monitoring that unifies a revenue- and cluster-aware ensemble\nof statistical, machine-learning, and deep-learning models with a role-driven\nanalytics layer for scorecards and trend diagnostics. The framework ingests\nexogenous signals (installed base, pricing, macro indicators, life cycle,\nseasonality) and treats COVID-19 as a distinct regime, producing country-part\nforecasts with calibrated intervals. A Pareto-aware segmentation forecasts\nhigh-revenue items individually and pools the long tail via clusters, while\nhorizon-aware ensembling aligns weights with business-relevant losses (e.g.,\nWMAPE). Beyond forecasts, a performance scorecard delivers decision-focused\ninsights: accuracy within tolerance thresholds by revenue share and count, bias\ndecomposition (over- vs under-forecast), geographic and product-family\nhotspots, and ranked root causes tied to high-impact part-country pairs. A\ntrend module tracks trajectories of MAPE/WMAPE and bias across recent months,\nflags entities that are improving or deteriorating, detects change points\naligned with known regimes, and attributes movements to lifecycle and seasonal\nfactors. LLMs are embedded in the analytics layer to generate role-aware\nnarratives and enforce reporting contracts. They standardize business\ndefinitions, automate quality checks and reconciliations, and translate\nquantitative results into concise, explainable summaries for planners and\nexecutives. The system exposes a reproducible workflow -- request\nspecification, model execution, database-backed artifacts, and AI-generated\nnarratives -- so planners can move from \"How accurate are we now?\" to \"Where is\naccuracy heading and which levers should we pull?\", closing the loop between\nforecasting, monitoring, and inventory decisions across more than 90 countries\nand about 6,000 parts."}
{"id": "2510.01025", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01025", "abs": "https://arxiv.org/abs/2510.01025", "authors": ["Federico Tiblias", "Irina Bigoulaeva", "Jingcheng Niu", "Simone Balloccu", "Iryna Gurevych"], "title": "Shape Happens: Automatic Feature Manifold Discovery in LLMs via Supervised Multi-Dimensional Scaling", "comment": null, "summary": "The linear representation hypothesis states that language models (LMs) encode\nconcepts as directions in their latent space, forming organized,\nmultidimensional manifolds. Prior efforts focus on discovering specific\ngeometries for specific features, and thus lack generalization. We introduce\nSupervised Multi-Dimensional Scaling (SMDS), a model-agnostic method to\nautomatically discover feature manifolds. We apply SMDS to temporal reasoning\nas a case study, finding that different features form various geometric\nstructures such as circles, lines, and clusters. SMDS reveals many insights on\nthese structures: they consistently reflect the properties of the concepts they\nrepresent; are stable across model families and sizes; actively support\nreasoning in models; and dynamically reshape in response to context changes.\nTogether, our findings shed light on the functional role of feature manifolds,\nsupporting a model of entity-based reasoning in which LMs encode and transform\nstructured representations."}
{"id": "2510.01030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01030", "abs": "https://arxiv.org/abs/2510.01030", "authors": ["Zach Studdiford", "Timothy T. Rogers", "Kushin Mukherjee", "Siddharth Suresh"], "title": "Uncovering the Computational Ingredients of Human-Like Representations in LLMs", "comment": "9 pages", "summary": "The ability to translate diverse patterns of inputs into structured patterns\nof behavior has been thought to rest on both humans' and machines' ability to\nlearn robust representations of relevant concepts. The rapid advancement of\ntransformer-based large language models (LLMs) has led to a diversity of\ncomputational ingredients -- architectures, fine tuning methods, and training\ndatasets among others -- but it remains unclear which of these ingredients are\nmost crucial for building models that develop human-like representations.\nFurther, most current LLM benchmarks are not suited to measuring\nrepresentational alignment between humans and models, making benchmark scores\nunreliable for assessing if current LLMs are making progress towards becoming\nuseful cognitive models. We address these limitations by first evaluating a set\nof over 70 models that widely vary in their computational ingredients on a\ntriplet similarity task, a method well established in the cognitive sciences\nfor measuring human conceptual representations, using concepts from the THINGS\ndatabase. Comparing human and model representations, we find that models that\nundergo instruction-finetuning and which have larger dimensionality of\nattention heads are among the most human aligned, while multimodal pretraining\nand parameter size have limited bearing on alignment. Correlations between\nalignment scores and scores on existing benchmarks reveal that while some\nbenchmarks (e.g., MMLU) are better suited than others (e.g., MUSR) for\ncapturing representational alignment, no existing benchmark is capable of fully\naccounting for the variance of alignment scores, demonstrating their\ninsufficiency in capturing human-AI alignment. Taken together, our findings\nhelp highlight the computational ingredients most essential for advancing LLMs\ntowards models of human conceptual representation and address a key\nbenchmarking gap in LLM evaluation."}
{"id": "2510.01038", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01038", "abs": "https://arxiv.org/abs/2510.01038", "authors": ["Akchunya Chanchal", "David A. Kelly", "Hana Chockler"], "title": "Activation-Deactivation: A General Framework for Robust Post-hoc Explainable AI", "comment": "Preprint: Under Review", "summary": "Black-box explainability methods are popular tools for explaining the\ndecisions of image classifiers. A major drawback of these tools is their\nreliance on mutants obtained by occluding parts of the input, leading to\nout-of-distribution images. This raises doubts about the quality of the\nexplanations. Moreover, choosing an appropriate occlusion value often requires\ndomain knowledge. In this paper we introduce a novel forward-pass paradigm\nActivation-Deactivation (AD), which removes the effects of occluded input\nfeatures from the model's decision-making by switching off the parts of the\nmodel that correspond to the occlusions. We introduce ConvAD, a drop-in\nmechanism that can be easily added to any trained Convolutional Neural Network\n(CNN), and which implements the AD paradigm. This leads to more robust\nexplanations without any additional training or fine-tuning. We prove that the\nConvAD mechanism does not change the decision-making process of the network. We\nprovide experimental evaluation across several datasets and model\narchitectures. We compare the quality of AD-explanations with explanations\nachieved using a set of masking values, using the proxies of robustness, size,\nand confidence drop-off. We observe a consistent improvement in robustness of\nAD explanations (up to 62.5%) compared to explanations obtained with\nocclusions, demonstrating that ConvAD extracts more robust explanations without\nthe need for domain knowledge."}
{"id": "2510.01069", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01069", "abs": "https://arxiv.org/abs/2510.01069", "authors": ["Elija Perrier"], "title": "Typed Chain-of-Thought: A Curry-Howard Framework for Verifying LLM Reasoning", "comment": "Under review", "summary": "While Chain-of-Thought (CoT) prompting enhances the reasoning capabilities of\nlarge language models, the faithfulness of the generated rationales remains an\nopen problem for model interpretability. We propose a novel theoretical lens\nfor this problem grounded in the Curry-Howard correspondence, which posits a\ndirect relationship between formal proofs and computer programs. Under this\nparadigm, a faithful reasoning trace is analogous to a well-typed program,\nwhere each intermediate step corresponds to a typed logical inference. We\noperationalise this analogy, presenting methods to extract and map the\ninformal, natural language steps of CoT into a formal, typed proof structure.\nSuccessfully converting a CoT trace into a well-typed proof serves as a strong,\nverifiable certificate of its computational faithfulness, moving beyond\nheuristic interpretability towards formal verification. Our framework provides\na methodology to transform plausible narrative explanations into formally\nverifiable programs, offering a path towards building more reliable and\ntrustworthy AI systems."}
{"id": "2510.01088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01088", "abs": "https://arxiv.org/abs/2510.01088", "authors": ["Guobin Shen", "Dongcheng Zhao", "Haibo Tong", "Jindong Li", "Feifei Zhao", "Yi Zeng"], "title": "Safety Instincts: LLMs Learn to Trust Their Internal Compass for Self-Defense", "comment": null, "summary": "Ensuring Large Language Model (LLM) safety remains challenging due to the\nabsence of universal standards and reliable content validators, making it\ndifficult to obtain effective training signals. We discover that aligned models\nalready possess robust internal safety beliefs: they consistently produce\nhigh-confidence refusals to harmful requests while exhibiting high entropy when\ngenerating potentially dangerous content. This entropy gap reveals an untapped\nsignal--models intrinsically \"know\" when to refuse. We introduce Safety\nInstincts Reinforcement Learning (SIRL), which transforms this internal\nconfidence into a self-generated reward signal, eliminating dependence on\nexternal validators or human annotations. SIRL teaches models to trust their\nsafety instincts by reinforcing low-entropy refusal behaviors. Evaluated on\nLlama and Qwen models, SIRL maintains 89%+ Defense Success Rates (DSRs) against\n20+ jailbreak methods, from static prompts to adaptive attacks. Using only\n15,000 unlabeled prompts, SIRL surpasses resource-intensive supervised methods\nwhile preserving performance on mathematics, coding, and conversation\nbenchmarks. Our work demonstrates that effective alignment can emerge from\nwithin, paving the way for more autonomous and robust AI safety mechanisms that\nscale without extensive human oversight."}
{"id": "2510.01094", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01094", "abs": "https://arxiv.org/abs/2510.01094", "authors": ["Alexander Nasuta", "Alessandro Cisi", "Sylwia Olbrych", "Gustavo Vieira", "Rui Fernandes", "Lucas Paletta", "Marlene Mayr", "Rishyank Chevuri", "Robert Woitsch", "Hans Aoyang Zhou", "Anas Abdelrazeq", "Robert H. Schmitt"], "title": "Optimizing Fairness in Production Planning: A Human-Centric Approach to Machine and Workforce Allocation", "comment": null, "summary": "This work presents a two-layer, human-centric production planning framework\ndesigned to optimize both operational efficiency and workforce fairness in\nindustrial manufacturing. The first layer formulates the Order-Line allocation\nas a Constraint Programming (CP) problem, generating high-utilization\nproduction schedules that respect machine capacities, processing times, and due\ndates. The second layer models Worker-Line allocation as a Markov Decision\nProcess (MDP), integrating human factors such as worker preference, experience,\nresilience, and medical constraints into the assignment process. Three solution\nstrategies, greedy allocation, MCTS, and RL, are implemented and compared\nacross multiple evaluation scenarios. The proposed system is validated through\n16 test sessions with domain experts from the automotive industry, combining\nquantitative key performance indicators (KPIs) with expert ratings. Results\nindicate that the CP-based scheduling approach produces compact, feasible\nproduction plans with low tardiness, while the MDP-based worker allocation\nsignificantly improves fairness and preference alignment compared to baseline\napproaches. Domain experts rated both the Order-Line and Worker-Line components\nas effective and highlighted opportunities to further refine the objective\nfunction to penalize excessive earliness and improve continuity in worker\nassignments. Overall, the findings demonstrate that combining CP with\nlearning-based decision-making provides a robust approach for human-centric\nproduction planning. The approach enables simultaneous optimization of\nthroughput and workforce well-being, offering a practical foundation for fair\nand efficient manufacturing scheduling in industrial settings."}
{"id": "2510.01114", "categories": ["cs.AI", "I.2.1; I.2.4; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.01114", "abs": "https://arxiv.org/abs/2510.01114", "authors": ["Lionel Levine", "John Santerre", "Alexander S. Young", "T. Barry Levine", "Francis Campion", "Majid Sarrafzadeh"], "title": "PRISM-Consult: A Panel-of-Experts Architecture for Clinician-Aligned Diagnosis", "comment": "8 pages, 6 figures", "summary": "We present PRISM-Consult, a clinician-aligned panel-of-experts architecture\nthat extends the compact PRISM sequence model into a routed family of domain\nspecialists. Episodes are tokenized as structured clinical events; a\nlight-weight router reads the first few tokens and dispatches to specialist\nmodels (Cardiac-Vascular, Pulmonary, Gastro-Oesophageal, Musculoskeletal,\nPsychogenic). Each specialist inherits PRISM's small transformer backbone and\ntoken template, enabling parameter efficiency and interpretability. On\nreal-world Emergency Department cohorts, specialists exhibit smooth convergence\nwith low development perplexities across domains, while the router achieves\nhigh routing quality and large compute savings versus consult-all under a\nsafety-first policy. We detail the data methodology (initial vs. conclusive\nICD-9 families), routing thresholds and calibration, and report per-domain\nresults to avoid dominance by common events. The framework provides a practical\npath to safe, auditable, and low-latency consult at scale, and we outline\nvalidation steps-external/temporal replication, asymmetric life-threat\nthresholds, and multi-label arbitration-to meet prospective clinical deployment\nstandards."}
{"id": "2510.01115", "categories": ["cs.AI", "cs.MA", "econ.TH", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.01115", "abs": "https://arxiv.org/abs/2510.01115", "authors": ["Evan Heus", "Rick Bookstaber", "Dhruv Sharma"], "title": "Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis", "comment": "7 pages, 3 figures", "summary": "Large Language Models (LLMs) struggle with the complex, multi-modal, and\nnetwork-native data underlying financial risk. Standard Retrieval-Augmented\nGeneration (RAG) oversimplifies relationships, while specialist models are\ncostly and static. We address this gap with an LLM-centric agent framework for\nsupply chain risk analysis. Our core contribution is to exploit the inherent\nduality between networks and knowledge graphs (KG). We treat the supply chain\nnetwork as a KG, allowing us to use structural network science principles for\nretrieval. A graph traverser, guided by network centrality scores, efficiently\nextracts the most economically salient risk paths. An agentic architecture\norchestrates this graph retrieval alongside data from numerical factor tables\nand news streams. Crucially, it employs novel ``context shells'' -- descriptive\ntemplates that embed raw figures in natural language -- to make quantitative\ndata fully intelligible to the LLM. This lightweight approach enables the model\nto generate concise, explainable, and context-rich risk narratives in real-time\nwithout costly fine-tuning or a dedicated graph database."}
{"id": "2510.01141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01141", "abs": "https://arxiv.org/abs/2510.01141", "authors": ["Shruthan Radhakrishna", "Aman Tiwari", "Aanjaneya Shukla", "Masoud Hashemi", "Rishabh Maheshwary", "Shiva Krishna Reddy Malay", "Jash Mehta", "Pulkit Pattnaik", "Saloni Mittal", "Khalil Slimi", "Kelechi Ogueji", "Akintunde Oladipo", "Soham Parikh", "Oluwanifemi Bamgbose", "Toby Liang", "Ahmed Masry", "Khyati Mahajan", "Sai Rajeswar Mudumba", "Vikas Yadav", "Sathwik Tejaswi Madhusudhan", "Torsten Scholak", "Sagar Davasam", "Srinivas Sunkara", "Nicholas Chapados"], "title": "Apriel-1.5-15b-Thinker", "comment": null, "summary": "We present Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights\nmultimodal reasoning model that achieves frontier-level performance through\ntraining design rather than sheer scale. Starting from Pixtral-12B, we apply a\nprogressive three-stage methodology: (1) depth upscaling to expand reasoning\ncapacity without pretraining from scratch, (2) staged continual pre-training\nthat first develops foundational text and vision understanding, then enhances\nvisual reasoning through targeted synthetic data generation addressing spatial\nstructure, compositional understanding, and fine-grained perception, and (3)\nhigh-quality text-only supervised fine-tuning on curated instruction-response\npairs with explicit reasoning traces spanning mathematics, coding, science, and\ntool use. Notably, our model achieves competitive results without reinforcement\nlearning or preference optimization, isolating the contribution of our\ndata-centric continual pre-training approach. On the Artificial Analysis\nIntelligence Index, Apriel-1.5-15B-Thinker attains a score of 52, matching\nDeepSeek-R1-0528 despite requiring significantly fewer computational resources.\nAcross ten image benchmarks, its performance is on average within five points\nof Gemini-2.5-Flash and Claude Sonnet-3.7, a key achievement for a model\noperating within single-GPU deployment constraints. Our results demonstrate\nthat thoughtful mid-training 2 design can close substantial capability gaps\nwithout massive scale, making frontier-level multimodal reasoning accessible to\norganizations with limited infrastructure. We release the model checkpoint, all\ntraining recipes, and evaluation protocols under the MIT license to to advance\nopen-source research."}
{"id": "2510.01143", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01143", "abs": "https://arxiv.org/abs/2510.01143", "authors": ["Harry Dong", "David Brandfonbrener", "Eryk Helenowski", "Yun He", "Mrinal Kumar", "Han Fang", "Yuejie Chi", "Karthik Abinav Sankararaman"], "title": "Generalized Parallel Scaling with Interdependent Generations", "comment": null, "summary": "Parallel LLM inference scaling involves sampling a set of $N>1$ responses for\na single input prompt. However, these $N$ parallel responses tend to be\ngenerated independently from each other, partitioning compute resources and\nleaving potentially useful information in one generation untapped by others.\nThis is in contrast to response length scaling where past computation is used\nin all future steps. For higher quality responses and response sets, we propose\nBridge to generate interdependent responses in parallel by rethinking batched\nLLM hidden states as holistic tensors rather than independent slices. With only\na small amount (2.8%-5.1%) of new parameters, Bridge improves the relative mean\naccuracy gains from reinforcement learning with verifiable rewards by up to 50%\nand boosts consistency of correct responses. Trained once, Bridge scales to any\ngeneration width, all with greater performance than independent generations,\nunlocking a more general mode of parallel scaling that effectively leverages\ninformation between sequences, compatible with any post-generation aggregation\ntechnique."}
{"id": "2510.00481", "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.MM", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.00481", "abs": "https://arxiv.org/abs/2510.00481", "authors": ["Jiayang Xu", "Xiangjie Huang", "Zijie Li", "Zili Meng"], "title": "Make a Video Call with LLM: A Measurement Campaign over Five Mainstream Apps", "comment": null, "summary": "In 2025, Large Language Model (LLM) services have launched a new feature --\nAI video chat -- allowing users to interact with AI agents via real-time video\ncommunication (RTC), just like chatting with real people. Despite its\nsignificance, no systematic study has characterized the performance of existing\nAI video chat systems. To address this gap, this paper proposes a comprehensive\nbenchmark with carefully designed metrics across four dimensions: quality,\nlatency, internal mechanisms, and system overhead. Using custom testbeds, we\nfurther evaluate five mainstream AI video chatbots with this benchmark. This\nwork provides the research community a baseline of real-world performance and\nidentifies unique system bottlenecks. In the meantime, our benchmarking results\nalso open up several research questions for future optimizations of AI video\nchatbots."}
{"id": "2510.00956", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00956", "abs": "https://arxiv.org/abs/2510.00956", "authors": ["Carlos Güemes-Palau", "Miquel Ferriol-Galmés", "Jordi Paillisse-Vilanova", "Albert López-Brescó", "Pere Barlet-Ros", "Albert Cabellos-Aparicio"], "title": "Bridging the Gap Between Simulated and Real Network Data Using Transfer Learning", "comment": "This paper was submitted to IEEE ICC 2026. 7 Pages, 5 Figures", "summary": "Machine Learning (ML)-based network models provide fast and accurate\npredictions for complex network behaviors but require substantial training\ndata. Collecting such data from real networks is often costly and limited,\nespecially for critical scenarios like failures. As a result, researchers\ncommonly rely on simulated data, which reduces accuracy when models are\ndeployed in real environments. We propose a hybrid approach leveraging transfer\nlearning to combine simulated and real-world data. Using RouteNet-Fermi, we\nshow that fine-tuning a pre-trained model with a small real dataset\nsignificantly improves performance. Our experiments with OMNeT++ and a custom\ntestbed reduce the Mean Absolute Percentage Error (MAPE) in packet delay\nprediction by up to 88%. With just 10 real scenarios, MAPE drops by 37%, and\nwith 50 scenarios, by 48%."}
