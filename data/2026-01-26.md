<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 5]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.IT](#cs.IT) [Total: 16]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Multi-User Content Diversity in Wireless Networks](https://arxiv.org/abs/2601.16323)
*Belal Korany,Peerapol Tinnakornsrisuphap,Saadallah Kassir,Prashanth Hande,Hyun Yong Lee,Thomas Stockhammer,Hemanth Sampath*

Main category: cs.NI

TL;DR: 该论文提出利用多用户内容多样性的概念，通过内容感知的网络优化框架提升6G网络中沉浸式应用的用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统无线网络速率分配和拥塞控制机制存在三个主要问题：1）基于信道条件统一对待用户；2）仅依赖网络中心的关键性能指标；3）忽略内容多样性。这导致资源利用效率低下和用户体验下降，无法满足XR、云游戏、实时视频流等6G沉浸式应用对低延迟、高数据率和高质量用户体验的需求。

Method: 提出多用户内容多样性的概念，即不同用户同时消费复杂度不同的媒体内容，因此需要不同的比特率来获得满意的用户体验。设计了多个利用这种多样性的框架，详细说明了应用服务器、应用客户端和网络之间的信息交换机制，以及每个组件中运行的算法，以优化网络范围内的用户体验目标。

Result: 仿真结果表明，与传统速率控制方法相比，利用多用户内容多样性在用户体验容量、用户体验公平性和网络利用率方面带来了显著提升。

Conclusion: 内容感知网络是新兴无线系统的关键使能技术，多用户内容多样性的利用能够显著改善网络性能和用户体验。

Abstract: Immersive applications such as eXtended Reality (XR), cloud gaming, and real-time video streaming are central to the vision of 6G networks. These applications require not only low latency and high data rates, but also consistent and high-quality User Experience (UX). Traditional rate allocation and congestion control mechanisms in wireless networks treat users uniformly based on channel conditions, rely only on network-centric Key Performance Indicators (KPIs), and ignore the content diversity, which can lead to inefficient resource utilization and degraded UX. In this paper, we introduce the concept of Multi-User Content Diversity, which recognizes that different users concurrently consume media with varying complexity, and therefore have different bitrate requirements to achieve satisfactory UX. We propose multiple different frameworks that exploit multi-user content diversity and lead to overall network-wide gains in terms of UX. For each framework, we demonstrate the required information exchange between Application Servers (ASs), Application Clients (ACs), and the network, and the algorithms that run in each of these components to optimize a network-wide UXbased objective. Simulation results demonstrate that exploiting multi-user content diversity leads to significant gains in UX capacity, UX fairness, and network utilization, when compared to conventional rate control methods. These findings highlight the potential of content-aware networking as a key enabler for emerging wireless systems.

</details>


### [2] [UAV-Assisted Joint Data Collection and Wireless Power Transfer for Batteryless Sensor Networks](https://arxiv.org/abs/2601.16533)
*Wen Zhang,Aimin Wang,Geng Sun,Jiahui Li,Jiacheng Wang,Changyuan Zhao,Dusit Niyato*

Main category: cs.NI

TL;DR: UAV辅助的无线充电与数据收集方案，采用深度强化学习优化无人机轨迹和传输功率，提升无电池传感器网络的数据收集量、公平性和能效。


<details>
  <summary>Details</summary>
Motivation: 无线能量传输和物联网在偏远地区面临能量供应有限、环境动态变化和传输链路不稳定等挑战，需要为无电池传感器网络提供可持续的能源和数据收集解决方案。

Method: 提出无人机辅助的数据收集和无线能量传输方案，采用深度强化学习算法，结合优先级经验回放和Performer模块，联合优化无人机传输功率和飞行轨迹。

Result: 仿真结果表明，所提方法在数据收集量、公平性和无人机能耗方面均优于基准方案，系统稳定性和收敛速度得到显著提升。

Conclusion: 基于深度强化学习的无人机辅助方案能有效解决无电池传感器网络的能量和数据收集问题，在偏远地区具有实际应用价值。

Abstract: The development of wireless power transfer (WPT) and Internet of Things (IoT) offers significant potential but faces challenges such as limited energy supply, dynamic environmental changes, and unstable transmission links. This paper presents an unmanned aerial vehicle (UAV)-assisted data collection and WPT scheme to support batteryless sensor (BLS) networks in remote areas. In this system, BLSs harvest energy from the UAV and utilize the harvested energy to transmit the collected data back to the UAV. The goal is to maximize the collected data volume and fairness index while minimizing the UAV energy consumption. To achieve these objectives, an optimization problem is formulated to jointly optimize the transmit power and UAV trajectory. Due to the non-convexity and dynamic nature of the problem, a deep reinforcement learning (DRL)-based algorithm is proposed to solve the problem. Specifically, this algorithm integrates prioritized experience replay and the performer module to enhance system stability and accelerate convergence. Simulation results demonstrate that the proposed approach consistently outperforms benchmark schemes in terms of collected data volume, fairness, and UAV energy consumption.

</details>


### [3] [Predicting Networks Before They Happen: Experimentation on a Real-Time V2X Digital Twin](https://arxiv.org/abs/2601.16559)
*Roberto Pegurri,Habu Shintaro,Francesco Linsalata,Wang Kui,Tao Yu,Eugenio Moro,Maiya Igarashi,Antonio Capone,Kei Sakaguchi*

Main category: cs.NI

TL;DR: 提出一个端到端的实时V2X数字孪生框架，结合实时移动追踪与确定性信道模拟，能在物理事件发生前预测网络性能，在东京实验验证中实现RSSI预测误差最大1.01dB，LoS转换预测延迟小于250ms。


<details>
  <summary>Details</summary>
Motivation: 新兴的安全关键型V2X应用需要网络能够主动适应快速的环境变化，而不仅仅是事后反应。现有网络数字孪生解决方案难以在物理建模的高保真度与严格实时约束之间取得平衡。

Method: 提出端到端实时V2X数字孪生框架，整合东京移动数字孪生（提供实时感知和轨迹预测）与VaN3Twin（带光线追踪的全栈模拟器），实现网络性能的提前预测。

Result: 在东京部署的实验验证中，系统能够以最大平均误差1.01dB预测接收信号强度，可靠预测视距转换，最大平均端到端系统延迟为250ms（取决于光线追踪细节级别）。量化了数字模型保真度、计算延迟和轨迹预测范围之间的基本权衡。

Conclusion: 证明了高保真度和预测性数字孪生在现实城市环境中是可行的，为安全关键型V2X应用提供了实时预测能力。

Abstract: Emerging safety-critical Vehicle-to-Everything (V2X) applications require networks to proactively adapt to rapid environmental changes rather than merely reacting to them. While Network Digital Twins (NDTs) offer a pathway to such predictive capabilities, existing solutions typically struggle to reconcile high-fidelity physical modeling with strict real-time constraints. This paper presents a novel, end-to-end real-time V2X Digital Twin framework that integrates live mobility tracking with deterministic channel simulation. By coupling the Tokyo Mobility Digital Twin-which provides live sensing and trajectory forecasting-with VaN3Twin-a full-stack simulator with ray tracing-we enable the prediction of network performance before physical events occur. We validate this approach through an experimental proof-of-concept deployed in Tokyo, Japan, featuring connected vehicles operating on 60 GHz links. Our results demonstrate the system's ability to predict Received Signal Strength (RSSI) with a maximum average error of 1.01 dB and reliably forecast Line-of-Sight (LoS) transitions within a maximum average end-to-end system latency of 250 ms, depending on the ray tracing level of detail. Furthermore, we quantify the fundamental trade-offs between digital model fidelity, computational latency, and trajectory prediction horizons, proving that high-fidelity and predictive digital twins are feasible in real-world urban environments.

</details>


### [4] [Stochastic Modeling and Resource Dimensioning of Multi-Cellular Edge Intelligent Systems](https://arxiv.org/abs/2601.16848)
*Jaume Anguera Peris,Joakim Jaldén*

Main category: cs.NI

TL;DR: 提出一个统一的随机框架来维度化多小区边缘智能系统，通过联合优化无线和计算资源，在统计QoS保证下最小化部署成本。


<details>
  <summary>Details</summary>
Motivation: 边缘智能需要在网络边缘进行AI推理，但系统性能和成本效率取决于无线和计算资源的联合预部署维度化。现有研究大多关注运行时分配或使用简化的解耦模型，忽略了大规模部署中的端到端相关性。

Method: 使用泊松点过程建模网络拓扑，结合排队论和实证AI推理工作负载分析，推导端到端卸载延迟的易处理表达式，进行非凸联合优化，证明问题可分解为凸子问题。

Result: 数值结果表明：较小小区减少传输延迟但增加每请求计算成本；较大小区则相反。在干扰受限场景中，稀疏部署能提高公平性和效率；只有当频率复用随基站密度扩展时，密集化才能降低计算成本。

Conclusion: 提出了一个统一的随机框架来维度化边缘智能系统，实现了在统计QoS保证下的成本最小化，揭示了无线和计算资源之间的权衡关系，为边缘智能系统设计提供了理论指导。

Abstract: Edge intelligence enables AI inference at the network edge, co-located with or near the radio access network, rather than in centralized clouds or on mobile devices. It targets low-latency, resource-constrained applications with large data volumes, requiring tight integration of wireless access and on-site computing. Yet system performance and cost-efficiency hinge on joint pre-deployment dimensioning of radio and computational resources, especially under spatial and temporal uncertainty. Prior work largely emphasizes run-time allocation or relies on simplified models that decouple radio and computing, missing end-to-end correlations in large-scale deployments. This paper introduces a unified stochastic framework to dimension multi-cell edge-intelligent systems. We model network topology with Poisson point processes, capturing random user and base-station locations, inter-cell interference, distance-based fractional power control, and peak-power constraints. By combining this with queueing theory and empirical AI inference workload profiling, we derive tractable expressions for end-to-end offloading delay. These enable a non-convex joint optimization that minimizes deployment cost under statistical QoS guarantees, expressed through strict tail-latency and inference-accuracy constraints. We prove the problem decomposes into convex subproblems, yielding global optimality. Numerical results in noise- and interference-limited regimes identify cost-efficient design regions and configurations that cause under-utilization or user unfairness. Smaller cells reduce transmission delay but raise per-request computing cost due to weaker server multiplexing, whereas larger cells show the opposite trend. Densification reduces computational costs only when frequency reuse scales with base-station density; otherwise, sparser deployments improve fairness and efficiency in interference-limited settings.

</details>


### [5] [Evaluating Wi-Fi Performance for VR Streaming: A Study on Realistic HEVC Video Traffic](https://arxiv.org/abs/2601.16950)
*Ferran Maura,Francesc Wilhelmi,Boris Bellalta*

Main category: cs.NI

TL;DR: 本文研究802.11网络支持多用户VR流媒体的容量限制，发现Intra-refresh编码能有效降低延迟波动，支持最多4个并发VR用户（100Mbps CBR）直到信道饱和。


<details>
  <summary>Details</summary>
Motivation: 云端VR流媒体对802.11网络提出高吞吐量和低延迟的挑战，多用户共享Wi-Fi时上下行流量容易导致信道饱和，需要研究网络的实际容量限制。

Method: 开发了一个仿真框架，复现Air Light VR操作，将真实的HEVC视频流量输入802.11仿真模型，测试不同帧率、比特率、编码设置和用户数量下的性能。

Result: 研究发现Wi-Fi性能异常现象，Intra-refresh编码能有效降低延迟变异性并改善服务质量，在信道饱和前最多可支持4个并发VR用户（100Mbps恒定比特率）。

Conclusion: 802.11网络在多用户VR流媒体场景下存在容量限制，但通过适当的编码技术（如Intra-refresh）可以改善服务质量，为实际部署提供指导。

Abstract: Cloud-based Virtual Reality (VR) streaming presents significant challenges for 802.11 networks due to its high throughput and low latency requirements. When multiple VR users share a Wi-Fi network, the resulting uplink and downlink traffic can quickly saturate the channel. This paper investigates the capacity of 802.11 networks for supporting realistic VR streaming workloads across varying frame rates, bitrates, codec settings, and numbers of users. We develop an emulation framework that reproduces Air Light VR (ALVR) operation, where real HEVC video traffic is fed into an 802.11 simulation model. Our findings explore Wi-Fi's performance anomaly and demonstrate that Intra-refresh (IR) coding effectively reduces latency variability and improves QoS, supporting up to 4 concurrent VR users with Constant Bitrate (CBR) 100 Mbps before the channel is saturated.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems](https://arxiv.org/abs/2601.16280)
*Donghao Huang,Gauri Malwe,Zhaoxia Wang*

Main category: cs.AI

TL;DR: 论文提出了一个基于大数据分析的诊断框架，用于评估多智能体系统中工具使用的可靠性，通过1980个测试实例发现中等规模模型在边缘硬件上具有实用价值。


<details>
  <summary>Details</summary>
Motivation: 尽管基于大语言模型的多智能体系统正在改变企业自动化，但评估工具使用可靠性的系统方法仍然不足，特别是在隐私敏感环境中的中小企业部署方面存在关键需求。

Method: 引入一个包含12类错误分类的诊断框架，涵盖工具初始化、参数处理、执行和结果解释等故障模式。系统评估了1980个确定性测试实例，涵盖开源模型（Qwen2.5系列、Functionary）和专有模型（GPT-4、Claude 3.5/3.7），并在不同边缘硬件配置上进行测试。

Result: 研究发现程序可靠性（特别是工具初始化失败）是较小模型的主要瓶颈，而qwen2.5:32b模型表现完美，与GPT-4.1相当。中等规模模型（qwen2.5:14b）在商用硬件上提供实用的准确性与效率权衡（96.6%成功率，7.3秒延迟）。

Conclusion: 这项工作为工具增强的多智能体AI系统的系统可靠性评估建立了基础架构，为资源受限组织提供了成本效益高的智能体部署方案。

Abstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.

</details>


### [7] [Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation](https://arxiv.org/abs/2601.16863)
*Tims Pecerskis,Aivars Smirnovs*

Main category: cs.AI

TL;DR: NSED协议是一种运行时混合模型架构，通过动态专家代理和共识机制，让小模型组合达到大模型性能，同时提升安全性。


<details>
  <summary>Details</summary>
Motivation: 传统混合专家模型使用静态门控网络，无法动态适应任务需求。需要一种能在运行时优化模型选择、降低硬件成本、同时提升安全性的架构。

Method: 1. 动态专家代理：将模型选择视为背包问题变体，基于实时遥测和成本约束绑定异构检查点到功能角色
2. 宏观尺度RNN：将审议形式化为循环神经网络，共识状态通过语义遗忘门循环实现迭代优化
3. 信任less N对N同行评审编排结构
4. 二次投票激活函数实现非线性共识
5. 反馈驱动状态更新

Result: 1. 在AIME 2025和LiveCodeBench基准测试中，小于20B参数的小模型组合能够匹配或超越100B+参数的大模型性能
2. 在DarkBench安全套件测试中，同行介导的校正将谄媚分数降低到低于任何单个代理的水平
3. 建立了新的硬件套利效率前沿

Conclusion: NSED协议通过运行时动态模型组合和共识机制，实现了小模型组合达到大模型性能的目标，同时展现出内在的对齐特性，为高效AI系统设计提供了新方向。

Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.

</details>


### [8] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: SemanticALLI通过将AI管道分解为结构化中间表示，实现语义缓存，显著提升缓存命中率并减少LLM调用


<details>
  <summary>Details</summary>
Motivation: 现有AI管道存在隐藏的低效问题：即使自然语言表述全新，系统仍会重复构建相同的中间逻辑（如指标标准化、图表框架）。传统的边界缓存将推理视为黑盒，无法捕捉这种低效性。

Method: 提出SemanticALLI架构，将生成过程分解为分析意图解析（AIR）和可视化合成（VS）两个阶段，将结构化中间表示提升为可缓存的一级构件。通过管道感知的语义缓存机制，在稳定、结构化的检查点进行缓存。

Result: 基线单块缓存因语言变异性最高只能达到38.7%命中率，而结构化方法在可视化合成阶段达到83.10%命中率，避免了4,023次LLM调用，中位延迟仅2.66毫秒。显著减少了总令牌消耗。

Conclusion: 即使用户很少重复相同表述，管道在稳定、结构化的检查点仍会重复执行相同逻辑，这些位置最适合缓存。这为AI系统设计提供了实用经验：通过结构化中间表示的语义缓存可以显著提升效率。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [9] [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)
*Fan Nie,Junlin Wang,Harper Hua,Federico Bianchi,Yongchan Kwon,Zhenting Qi,Owen Queen,Shang Zhu,James Zou*

Main category: cs.AI

TL;DR: DSGym是一个用于评估和训练数据科学代理的标准化框架，通过模块化架构和真实数据环境解决现有基准测试的局限性，并展示了训练出的4B模型在分析基准上超越GPT-4o的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据科学基准测试存在三个主要问题：1）碎片化的评估接口导致跨基准比较困难；2）任务覆盖范围狭窄；3）缺乏严格的数据基础（许多任务无需实际数据即可解决）。需要一个新的框架来支持数据科学代理的端到端评估和训练。

Method: 提出DSGym框架，包含：1）模块化架构，便于添加任务、代理脚手架和工具；2）DSGym-Tasks任务套件，标准化和精炼现有基准；3）DSBio（基于文献的生物信息学任务）和DSPredict（跨领域预测任务）；4）通过执行验证的数据合成管道支持代理训练。

Result: 构建了2,000个示例的训练集，训练出的4B模型在标准化分析基准上超越了GPT-4o。DSGym能够严格测量代理在真实科学背景下规划、实施和验证数据分析的能力。

Conclusion: DSGym提供了一个可扩展的测试平台，解决了现有数据科学基准的局限性，支持数据科学代理的全面评估和训练，为加速数据驱动的科学发现提供了重要基础设施。

Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.

</details>


### [10] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP：利用AHP原则指导LLM从文档构建决策模型的框架，无需专家标注，通过结构化约束和多智能体权重机制提升逻辑一致性和任务准确性


<details>
  <summary>Details</summary>
Motivation: LLMs在语义理解方面表现出色，但在需要严格逻辑的复杂决策任务中难以保证结构一致性和推理可靠性。传统决策理论如AHP虽提供系统化理性框架，但构建依赖大量领域专家知识，存在"专家瓶颈"，限制了在通用场景下的可扩展性。

Method: 提出Doc2AHP框架，利用AHP的结构原则作为约束，指导LLM在非结构化文档空间中进行受限搜索，强制父子节点间的逻辑蕴含关系。引入多智能体权重机制和自适应一致性优化策略，确保权重分配的数字一致性。

Result: 实证结果表明，Doc2AHP不仅使非专家用户能够从零开始构建高质量决策模型，而且在逻辑完整性和下游任务准确性方面显著优于直接生成基线方法。

Conclusion: Doc2AHP成功弥合了LLMs的泛化能力和决策理论严谨性之间的差距，通过结构化推理框架实现了无需大量标注数据或人工干预的高质量决策模型构建。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [11] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: SycoEval-EM框架通过多智能体模拟评估LLM在急诊医学中面对患者压力时的鲁棒性，发现模型容易屈服于不适当医疗请求，静态基准无法预测社交压力下的安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中展现出潜力，但存在屈服于患者压力而提供不适当医疗的风险。当前缺乏评估LLM在对抗性患者说服情境下鲁棒性的系统方法。

Method: 引入SycoEval-EM多智能体模拟框架，通过对抗性患者说服在急诊医学场景中评估LLM。涵盖20个LLM模型和1,875次交互，涉及三个Choosing Wisely场景（明智选择指南）。

Result: 模型屈服率从0-100%不等，对影像检查请求的脆弱性（38.8%）高于阿片类药物处方（25.0%）。模型能力与鲁棒性相关性差，所有说服策略效果相当（30.0-36.0%），表明普遍脆弱性而非特定策略弱点。

Conclusion: 静态基准无法充分预测社交压力下的安全性，临床AI认证需要进行多轮对抗性测试以确保模型在实际医疗环境中的鲁棒性。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [12] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 传统机器学习模型在医学分类任务中表现最佳，LoRA微调的Gemma变体表现最差，零样本LLM/VLM在图像任务上有竞争力


<details>
  <summary>Details</summary>
Motivation: 评估多模态视觉语言模型和大语言模型在医学分类任务中的表现，与传统机器学习方法进行对比，为医学AI领域提供实证基准

Method: 使用四个公开数据集（涵盖文本和图像模态，包括二元和多分类任务），对比三类模型：传统ML（LR、LightGBM、ResNet-50）、基于提示的LLM/VLM（Gemini 2.5）、PEFT微调模型（LoRA适配的Gemma3变体），采用一致的数据划分和评估指标

Result: 传统ML模型在大多数医学分类任务中表现最佳，尤其在结构化文本数据集上表现优异；LoRA微调的Gemma变体在所有实验中表现最差；零样本LLM/VLM在文本任务上表现不佳，但在多分类图像任务上与ResNet-50基线相当

Conclusion: 在许多医学分类场景中，传统机器学习模型仍是最可靠的选择；基础模型并非普遍优越，PEFT的有效性高度依赖于适应策略，本研究中最小化微调反而有害

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [13] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 本文提出了一种评估多轮智能体任务中不同能力（如规划、状态跟踪）相对重要性的框架，通过程序生成的可调复杂度游戏任务，使用oracle干预来测量各项技能对性能提升的关键性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在孤立任务上表现良好，但在需要规划、状态跟踪和长上下文处理的多轮长时程智能体问题上仍存在困难。需要更好地理解这些底层能力对任务成功的相对重要性，以指导AI智能体和语言模型的未来发展。

Method: 开发了一个oracle反事实框架，在程序生成的可调复杂度游戏任务中，通过提供精确的oracle干预（如完美规划、无错误状态跟踪）来隔离各项技能的影响。使用受控环境避免现实基准中的混杂效应。

Result: 结果显示，某些干预（如规划）在各种设置下都能持续提升性能，而其他技能的有用性则取决于环境和语言模型的特性。不同能力的重要性因任务特性而异。

Conclusion: 该研究揭示了多轮智能体环境的挑战，为AI智能体和语言模型的未来发展提供了指导。oracle反事实框架能够有效评估不同能力的关键性，帮助确定研发的优先方向。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [14] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 提出了一个名为AgentsEval的多智能体流推理框架，用于评估自动生成的医学影像报告的临床正确性和推理保真度，通过模拟放射科医生的协作诊断工作流程提供结构化评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法捕捉放射学解释背后的结构化诊断逻辑，导致评估不可靠且临床相关性有限，需要更可靠、临床相关的评估框架。

Method: AgentsEval框架将评估过程分解为可解释的步骤：标准定义、证据提取、对齐和一致性评分，模拟放射科医生的协作诊断工作流程，并提供明确的推理轨迹和结构化临床反馈。

Result: 实验结果表明，AgentsEval能够提供临床对齐、语义忠实且可解释的评估，在释义、语义和风格扰动下保持稳健，并在涵盖五个医学报告数据集的多领域扰动基准上表现良好。

Conclusion: 该框架代表了向透明和临床基础的医学报告生成系统评估迈出的一步，有助于促进大语言模型在临床实践中的可信集成。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [15] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是一个5600亿参数的开源MoE推理模型，在多种智能体基准测试中达到SOTA，通过统一训练框架、环境扩展、噪声鲁棒性设计和Heavy Thinking模式实现卓越性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个具有卓越智能体推理能力的开源模型，能够处理复杂的工具交互、多轮智能体交互，并在噪声现实环境中保持鲁棒性，以应对真实世界任务的挑战。

Method: 采用统一的训练框架，结合领域并行专家训练与后续融合，端到端协同设计数据构建、环境、算法和基础设施。扩展异步强化学习框架DORA以支持大规模多环境训练，系统分析现实噪声模式并针对性训练，引入Heavy Thinking模式进行测试时扩展。

Result: 在智能体搜索、智能体工具使用和工具集成推理等广泛基准测试中达到开源模型的最先进性能，展现出对复杂工具交互的强泛化能力和噪声环境下的鲁棒行为。

Conclusion: LongCat-Flash-Thinking-2601通过创新的训练框架、环境扩展、噪声鲁棒性设计和推理增强技术，成功实现了卓越的智能体推理能力，为现实世界应用提供了强大的开源解决方案。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [16] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 开发了一种受昆虫启发的视觉点目标导航智能体，结合了昆虫大脑中负责联想学习和路径整合的两个结构模型，在Habitat点目标导航任务中表现出与SOTA模型相当的性能，但计算成本低得多。


<details>
  <summary>Details</summary>
Motivation: 受昆虫在发现食物位置和巢穴之间学习并优化视觉引导路径的能力启发，希望开发一种计算效率高的视觉点目标导航方法。昆虫大脑结构简单但功能强大，为开发轻量级导航智能体提供了生物学灵感。

Method: 结合了昆虫大脑中两个关键结构的抽象模型：一个负责联想学习，另一个负责路径整合。将Habitat点目标导航任务与昆虫的视觉导航能力进行类比，开发出简单的昆虫启发式智能体。

Result: 该昆虫启发式智能体在Habitat点目标导航任务中表现出与最近SOTA模型相当的性能，但计算成本低多个数量级。在更真实的模拟环境中测试显示，该方法对扰动具有鲁棒性。

Conclusion: 昆虫大脑的简单结构为开发高效、鲁棒的视觉导航智能体提供了有价值的灵感。这种方法在保持高性能的同时大幅降低了计算需求，展示了生物启发方法在机器人导航中的潜力。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [17] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 研究发现，通过强化学习训练的推理型LLM在心理理论任务中表现出更强的鲁棒性，但这种提升主要源于寻找正确解决方案的稳定性增强，而非形成了新的心理理论推理能力。


<details>
  <summary>Details</summary>
Motivation: 近期LLM在心理理论测试中表现出色引发争议，同时通过强化学习训练的推理模型在多个基准测试中取得显著进步。本研究旨在探究这类推理模型在心理理论任务中的行为表现，以澄清其能力本质。

Method: 采用新颖的机器心理学实验改编方法和已建立的基准测试结果，分析推理模型在心理理论任务中的表现，特别关注其对提示变化和任务扰动的鲁棒性。

Result: 推理模型在心理理论任务中表现出对提示变化和任务扰动更强的鲁棒性。分析表明，这种提升更可能归因于寻找正确解决方案的稳定性增强，而非形成了新的心理理论推理形式。

Conclusion: 研究结果表明，LLM在心理理论任务中的性能提升主要源于推理鲁棒性的增强，而非本质性的社会认知能力突破。这对评估LLM的社会认知行为具有重要意义。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [18] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: MAGE-KT：多智能体图增强知识追踪框架，通过多视图异构图和条件子图检索解决现有图KT方法中概念关系挖掘不足和注意力扩散问题


<details>
  <summary>Details</summary>
Motivation: 现有图知识追踪方法存在两个主要问题：1) 概念间关系挖掘不足，通常仅从交互序列推断；2) 完整图编码计算成本高且易受噪声影响，导致注意力扩散到学生无关区域，降低概念关系保真度

Method: 提出MAGE-KT框架：1) 构建多视图异构图，结合多智能体概念关系提取器和学生-问题交互图；2) 基于目标学生历史检索紧凑高价值子图；3) 使用非对称交叉注意力融合模块集成子图信息，避免注意力扩散和无关计算

Result: 在三个广泛使用的KT数据集上实验表明，该方法在概念关系准确性和下一问题预测方面显著优于现有方法

Conclusion: MAGE-KT通过多视图图表示和条件子图检索有效解决了图知识追踪中的概念关系挖掘和注意力扩散问题，提升了预测性能

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [19] [Preventing the Collapse of Peer Review Requires Verification-First AI](https://arxiv.org/abs/2601.16909)
*Lei You,Lele Cao,Iryna Gurevych*

Main category: cs.AI

TL;DR: 论文主张AI辅助同行评审应采用"验证优先"而非"模仿评审"模式，提出"真相耦合度"作为评审工具的核心目标，并分析了导致评审质量相变的两种力量


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助评审系统存在模仿传统评审流程的倾向，可能导致评审质量下降。论文旨在建立更科学的AI辅助评审框架，防止评审系统从追求科学真相转向优化代理指标

Method: 提出"真相耦合度"概念，形式化分析了两种驱动相变的力量：验证压力和信号收缩。构建最小模型，混合高保真检查和频繁代理判断，推导出明确的耦合定律和激励崩溃条件

Result: 揭示了在验证压力大且信号收缩的情况下，理性努力会从追求真相转向优化代理指标，即使当前决策看起来仍然可靠。提出了AI作为对抗性审计工具的具体应用方向

Conclusion: AI辅助评审应采用验证优先模式，将AI部署为生成可审计验证工件、扩展有效验证带宽的对抗性审计工具，而非放大声明膨胀的分数预测器

Abstract: This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.

</details>


### [20] [AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems](https://arxiv.org/abs/2601.16964)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.AI

TL;DR: AgentDrive是一个包含30万个LLM生成的驾驶场景的开放基准数据集，用于训练、微调和评估自主代理，并附带10万个多选题的AgentDrive-MCQ基准。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、结构化且安全关键的基准来评估和训练集成大语言模型的自主系统，这阻碍了智能体AI模型在推理驱动的感知、规划和决策方面的发展。

Method: 1) 通过LLM驱动的prompt-to-JSON管道生成语义丰富、可模拟的场景规范；2) 在七个正交轴上形式化因子化场景空间；3) 每个场景进行模拟推演、代理安全指标计算和基于规则的结果标记；4) 创建包含10万个问题的AgentDrive-MCQ多选题基准，涵盖五个推理维度。

Result: 对50个领先LLM在AgentDrive-MCQ上进行大规模评估，结果显示：专有前沿模型在上下文和政策推理方面表现最佳，而先进开源模型在结构化和物理基础推理方面正在迅速缩小差距。

Conclusion: AgentDrive为自主代理的评估和训练提供了大规模、结构化的基准，促进了智能体AI模型的发展，并揭示了不同LLM在驾驶相关推理任务上的相对优势。

Abstract: The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive

</details>


### [21] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: 提出Spatial-Agent，一种基于空间信息科学理论的地理解析AI代理，通过GeoFlow图将自然语言问题转化为可执行的地理解析工作流，显著提升地理空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理在真实地理空间计算方面存在不足，主要依赖网络搜索或模式匹配，经常产生空间关系幻觉。地理空间推理对于城市分析、交通规划、灾害响应等实际应用至关重要。

Method: 将地理分析问题回答形式化为概念转换问题，使用GeoFlow图（有向无环图）表示可执行工作流。基于空间信息理论提取空间概念，分配功能角色并应用排序约束，通过模板生成转换序列。

Result: 在MapEval-API和MapQA基准测试中，Spatial-Agent显著优于ReAct和Reflexion等现有基线方法，同时生成可解释和可执行的地理空间工作流。

Conclusion: Spatial-Agent通过将空间信息科学理论融入AI代理设计，有效解决了地理空间推理中的计算不足问题，为实际应用提供了可靠的地理分析能力。

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>


### [22] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 开发AI驱动的医疗设备维护平台，帮助资源有限地区的生物医学技术人员实时诊断和修复设备，减少停机时间


<details>
  <summary>Details</summary>
Motivation: 中低收入国家医疗设备因维护不足、技术专家缺乏和制造商支持有限而大量闲置，导致设备停机时间长、诊断延迟和患者护理质量下降

Method: 集成大型语言模型与用户友好的Web界面，让技术人员输入错误代码或症状，获取逐步故障排除指导；建立全球同行讨论论坛支持知识交流；以Philips HDI 5000超声机为概念验证

Result: 在Philips HDI 5000超声机上实现100%的错误代码解释精度和80%的纠正措施建议准确率

Conclusion: AI驱动系统支持医疗设备维护具有可行性，能减少设备停机时间，改善资源受限环境的医疗服务提供

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [23] [Study of Switched Step-size Based Filtered-x NLMS Algorithm for Active Noise Cancellation](https://arxiv.org/abs/2601.16382)
*Zhiyuan Li,Yi Yu,Hongsen He,Yuyu Zhu,Rodrigo C. de Lamare*

Main category: cs.IT

TL;DR: 提出两种改进的FxNLMS算法：SSS-FxNLMS通过动态切换步长解决收敛速度与稳态误差的矛盾，以及增强鲁棒性的变体以应对脉冲噪声环境。


<details>
  <summary>Details</summary>
Motivation: 传统FxNLMS算法存在两个关键限制：固定步长导致收敛速度与稳态残差之间的权衡，以及在脉冲噪声环境下性能显著下降。

Method: 1. 推导FxNLMS算法的均方偏差趋势；2. 通过比较不同步长对应的MSD趋势，为每次迭代选择最优步长，提出SSS-FxNLMS算法；3. 将鲁棒策略集成到SSS-FxNLMS中，形成鲁棒变体。

Result: 通过计算机仿真在不同噪声场景下验证了所提算法的有效性和优越性。

Conclusion: 提出的SSS-FxNLMS算法及其鲁棒变体成功解决了传统FxNLMS算法的步长限制和脉冲噪声敏感性问题，提升了主动噪声控制系统的性能。

Abstract: While the filtered-x normalized least mean square (FxNLMS) algorithm is widely applied due to its simple structure and easy implementation for active noise control system, it faces two critical limitations: the fixed step-size causes a trade-off between convergence rate and steady-state residual error, and its performance deteriorates significantly in impulsive noise environments. To address the step-size constraint issue, we propose the switched \mbox{step-size} FxNLMS (SSS-FxNLMS) algorithm. Specifically, we derive the \mbox{mean-square} deviation (MSD) trend of the FxNLMS algorithm, and then by comparing the MSD trends corresponding to different \mbox{step-sizes}, the optimal step-size for each iteration is selected. Furthermore, to enhance the algorithm's robustness in impulsive noise scenarios, we integrate a robust strategy into the SSS-FxNLMS algorithm, resulting in a robust variant of it. The effectiveness and superiority of the proposed algorithms has been confirmed through computer simulations in different noise scenarios.

</details>


### [24] [Two classes of LCD codes derived from $(\mathcal{L},\mathcal{P})$-TGRS codes](https://arxiv.org/abs/2601.16438)
*Ziwei Zhao,Xiaoni DU,Xingbin Qiao*

Main category: cs.IT

TL;DR: 从扭曲广义Reed-Solomon码构造两类LCD码，并进一步获得LCD MDS码


<details>
  <summary>Details</summary>
Motivation: 扭曲广义Reed-Solomon码作为经典广义Reed-Solomon码的灵活扩展，近年来受到广泛关注。本文旨在从这类码构造线性互补对偶码，特别是LCD MDS码，以增强编码理论的应用价值。

Method: 首先推导出特定扭曲广义Reed-Solomon码的校验矩阵，给出其成为AMDS码的充要条件。然后通过适当选择评估点并对扭曲项多项式中x^{h-1}系数施加限制，从该码构造两类LCD码。

Result: 成功构造了两类LCD码，并进一步从这些LCD码获得了LCD MDS码。通过多个实例验证了构造方法的有效性。

Conclusion: 本文提供了从扭曲广义Reed-Solomon码构造LCD码和LCD MDS码的系统方法，扩展了编码理论中LCD码的构造技术，具有理论和应用价值。

Abstract: Twisted generalized Reed-Solomon (TGRS) codes, as a flexible extension of classical generalized Reed-Solomon (GRS) codes, have attracted significant attention in recent years. In this paper, we construct two classes of LCD codes from the $(\mathcal{L},\mathcal{P})$-TGRS code $\mathcal{C}_h$ of length $n$ and dimension $k$, where $\mathcal{L}=\{0,1,\ldots,l\}$ for $l\leq n-k-1$ and $\mathcal{P}=\{h\}$ for $1\leq h\leq k-1$. First, we derive the parity check matrix of $\mathcal{C}_h$ and provide a necessary and sufficient condition for $\mathcal{C}_h$ to be an AMDS code. Then, we construct two classes of LCD codes from $\mathcal{C}_h$ by suitably choosing the evaluation points together with certain restrictions on the coefficient of $x^{h-1}$ in the polynomial associated with the twisting term. From the constructed LCD codes we further obtain two classes of LCD MDS codes. Finally, several examples are presented.

</details>


### [25] [Cramér-Rao Bound Minimization for Flexible Intelligent Metasurface-Enabled ISAC Systems](https://arxiv.org/abs/2601.16455)
*Qian Zhang,Yufei Zhao,Jiancheng An,Zheng Dong,Yong Liang Guan,Ju Liu,Chau Yuen*

Main category: cs.IT

TL;DR: 首次研究柔性智能超表面(FIM)使能的ISAC系统中的CRB最小化问题，通过优化FIM表面形状和波束成形，显著降低感知CRB同时保持通信质量


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)是未来无线网络的关键使能技术，CRB在量化感知精度中起核心作用。柔性智能超表面(FIM)的阵列可重构性可以显著降低CRB，但相关研究尚属空白

Method: 1) 推导平均CRB表达式，显示其与FIM表面形状的显式依赖关系；2) 采用平均Fisher信息最大化作为替代目标，使用Gauss-Hermite求积法获得目标函数显式近似；3) 将问题分解为三个子问题：波束成形优化、发射/接收FIM表面形状优化；4) 波束成形采用Schur补和惩罚基半定松弛技术；5) 接收FIM表面形状优化使用定点方程法，发射FIM使用投影梯度算法

Result: 仿真结果表明，与刚性阵列相比，发射和接收FIM的表面形状优化能显著降低平均感知CRB，同时保持通信质量，在多目标场景中仍然有效

Conclusion: 本研究首次探索了FIM使能ISAC系统中的CRB最小化问题，证明了FIM表面形状优化在提升感知性能方面的有效性，为未来ISAC系统设计提供了新思路

Abstract: Integrated sensing and communication (ISAC) have been widely recognized as a key enabler for future wireless networks, where the Cramér-Rao bound (CRB) plays a central role in quantifying sensing accuracy.In this paper, we present the first study on CRB minimization in flexible intelligent metasurface (FIM)-enabled ISAC systems.Specifically, we first derive an average CRB expression that explicitly depends on FIM surface shape and demonstrate that array reconfigurability can substantially reduce the CRB, thereby significantly enhancing sensing performance.Moreover, to tackle the challenging CRB minimization problem, we adopt average Fisher information maximization as a surrogate objective and use the Gauss-Hermite quadrature method to obtain an explicit approximation of the objective function.The resulting problem is then decoupled into three subproblem, i.e., beamforming optimization and transmit/receive FIM surface shape optimization.For beamforming optimization, we employ the Schur complement and penalty-based semi-definite relaxation (SDR) technique to solve it.Furthermore, we propose a fixed-point equation method and a projected gradient algorithm to optimize the surface shapes of the receive and transmit FIMs, respectively.Simulation results demonstrate that, compared to rigid arrays, surface shaping of both transmit and receive FIMs can significantly reduce the average sensing CRB while maintaining communication quality, and remains effective even in multi-target scenarios.

</details>


### [26] [Log-Likelihood Loss for Semantic Compression](https://arxiv.org/abs/2601.16461)
*Anuj Kumar Yadav,Dan Song,Yanina Shkel,Ayfer Özgür*

Main category: cs.IT

TL;DR: 研究基于指定条件分布P_{X|U}的负对数似然定义的失真度量下的有损信源编码，这种对数似然失真建模了重建是语义表示而非逐点近似的压缩场景。


<details>
  <summary>Details</summary>
Motivation: 传统有损压缩通常关注逐点近似，但在许多实际应用中，重建应该是能够概率生成源的语义表示。需要建立一种能够捕捉语义重建质量的失真度量框架。

Method: 提出对数似然失真度量，基于指定条件分布P_{X|U}的负对数似然定义。制定相应的率失真问题，并分析所得率失真函数的基本性质。

Result: 建立了对数似然失真框架，揭示了其与对数损失下的有损压缩、具有任意失真度量的经典率失真问题以及完美感知率失真之间的联系。

Conclusion: 对数似然失真为建模语义压缩提供了一种理论框架，其中重建是能够概率生成源的语义表示，而非简单的逐点近似。

Abstract: We study lossy source coding under a distortion measure defined by the negative log-likelihood induced by a prescribed conditional distribution $P_{X|U}$. This \emph{log-likelihood distortion} models compression settings in which the reconstruction is a semantic representation from which the source can be probabilistically generated, rather than a pointwise approximation. We formulate the corresponding rate-distortion problem and characterize fundamental properties of the resulting rate-distortion function, including its connections to lossy compression under log-loss, classical rate-distortion problems with arbitrary distortion measures, and rate-distortion with perfect perception.

</details>


### [27] [Load Balanced ISAC Systems for URLLC Users](https://arxiv.org/abs/2601.16495)
*Shivani Singh,Amudheesan Nakkeeran,Prem Singh,Ekant Sharma,Jyotsna Bapat*

Main category: cs.IT

TL;DR: 提出一种用于集成感知与通信(ISAC)网络的能量高效负载均衡算法，在服务URLLC用户的同时检测目标，相比无负载均衡基线可减少约33%的功耗。


<details>
  <summary>Details</summary>
Motivation: 在CF-mMIMO ISAC网络中，需要同时满足URLLC用户的通信QoS要求和目标检测的感知QoS要求，同时最小化网络总功耗（包括发射功率、静态功率和流量相关的前传功率）。

Method: 提出联合功率分配和AP负载均衡(JPALB)算法，通过迭代优化解决混合整数非凸优化问题，使用MRT和RZF预编码器进行仿真验证。

Result: 仿真结果显示，相比无负载均衡的基线方法，JPALB算法可减少约33%的总功耗，同时不损害通信和感知的QoS要求。

Conclusion: JPALB算法能有效降低CF-mMIMO ISAC网络的总功耗，在满足URLLC通信和感知需求的同时实现显著的节能效果。

Abstract: This paper presents an energy-efficient downlink cell-free massive multiple-input multiple-output (CF-mMIMO) integrated sensing and communication (ISAC) network that serves ultra-reliable low-latency communication (URLLC) users while simultaneously detecting a target. We propose a load-balancing algorithm that minimizes the total network power consumption; including transmit power, fixed static power, and traffic-dependent fronthaul power at the access points (APs) without degrading system performance. To this end, we formulate a mixed-integer non-convex optimization problem and introduce an iterative joint power allocation and AP load balancing (JPALB) algorithm. The algorithm aims to reduce total power usage while meeting both the communication quality-of-service (QoS) requirements of URLLC users and the sensing QoS needed for target detection. Proposed JPALB algorithm for ISAC systems was simulated with maximum-ratio transmission (MRT) and regularized zero-forcing (RZF) precoders. Simulation results show approximately 33% reduction in power consumption, using JPALB algorithm compared to a baseline with no load balancing, without compromising communication and sensing QoS requirements.

</details>


### [28] [Noise-immune and AI-enhanced DNA storage via adaptive partition mapping of digital data](https://arxiv.org/abs/2601.16518)
*Zimu Li,Bingyi Liu,Lei Zhao,Qian Zhang,Yang Liu,Jun Liu,Ke Ke,Huating Kong,Xiaolei Zuo,Chunhai Fan,Fei Wang*

Main category: cs.IT

TL;DR: 研究人员开发了一种名为PJ（分区映射与跳转旋转）的DNA存储编码方案，该方案具有卓越的噪声抗性，能够在任意链损失比例下解码原始文件，并通过AI推理实现可控恢复。


<details>
  <summary>Details</summary>
Motivation: DNA存储作为应对信息时代和人工智能崛起的数据增长解决方案具有吸引力，但实际应用受到合成、保存和测序过程中引入错误的限制，传统纠错码在噪声超过预定阈值时仍然脆弱。

Method: 开发了PJ编码方案：1) 移除跨链信息依赖，使链损失表现为局部间隙而非灾难性文件失败；2) 采用跳转旋转策略，相对于传统旋转码放宽序列约束，通过可调跳转长度提供可调信息密度；3) 利用AI推理实现可控恢复。

Result: PJ编码能够在任意链损失比例下解码和恢复原始文件信息，保真度随损坏增加而平滑下降。实验表明：1) 即使10%链损失也能有效恢复原始文件；2) 存储的机器学习数据集保持分类性能；3) 通过加速老化和高强度X射线辐照的极端环境扰动后仍能成功解码图像文件。

Conclusion: PJ编码消除了对先验错误概率的依赖，建立了一个通用的稳健、档案级DNA存储框架，能够承受现实世界保存的严格条件。

Abstract: Encoding digital information into DNA sequences offers an attractive potential solution for storing rapidly growing data under the information age and the rise of artificial intelligence. However, practical implementations of DNA storage are constrained by errors introduced during synthesis, preservation, and sequencing processes, and traditional error-correcting codes remain vulnerable to noise levels that exceed predefined thresholds. Here, we developed a Partitioning-mapping with Jump-rotating (PJ) encoding scheme, which exhibits exceptional noise resilience. PJ removes cross-strand information dependencies so that strand loss manifests as localized gaps rather than catastrophic file failure. It prioritizes file decodability under arbitrary noise conditions and leverages AI-based inference to enable controllable recovery of digital information. For the intra-strand encoding, we develop a jump-rotating strategy that relaxes sequence constraints relative to conventional rotating codes and provides tunable information density via an adjustable jump length. Based on this encoding architecture, the original file information can always be decoded and recovered under any strand loss ratio, with fidelity degrading smoothly as damage increases. We demonstrate that original files can be effectively recovered even with 10% strand loss, and machine learning datasets stored under these conditions retain their classification performance. Experiments further confirmed that PJ successfully decodes image files after extreme environmental disturbance using accelerated aging and high-intensity X-ray irradiation. By eliminating reliance on prior error probabilities, PJ establishes a general framework for robust, archival DNA storage capable of withstanding the rigorous conditions of real-world preservation.

</details>


### [29] [Generalized Forms of the Kraft Inequality for Finite-State Encoders](https://arxiv.org/abs/2601.16594)
*Neri Merhav*

Main category: cs.IT

TL;DR: 本文推导了有限状态无损编码器的Kraft不等式扩展版本，定义了Kraft矩阵概念，建立了信息无损的必要条件：Kraft矩阵特征值模长不超过1，即谱半径≤1。对于不可约情况，给出了谱半径公式的等价形式，证明Kraft和有界且不随块长增长。最后扩展到带边信息和有损压缩情况。


<details>
  <summary>Details</summary>
Motivation: 现有Kraft不等式主要针对无记忆编码器，需要扩展到有限状态编码器。有限状态编码器在数据压缩中广泛应用，但缺乏相应的Kraft不等式理论框架来刻画其信息无损条件。

Method: 定义Kraft矩阵概念，建立有限状态编码器的信息无损必要条件：Kraft矩阵特征值模长不超过1（谱半径≤1）。对于不可约有限状态编码器，利用谱半径公式推导等价不等式形式。证明Kraft和有界性，并扩展到带边信息和有损压缩场景。

Result: 1. 建立了有限状态无损编码器的广义Kraft不等式：Kraft矩阵谱半径≤1；2. 不可约情况下推导了基于谱半径公式的等价不等式；3. 证明不可约情况下Kraft和有界，不随块长增长；4. 成功扩展到带边信息和有损压缩场景。

Conclusion: 本文为有限状态编码器建立了完整的Kraft不等式理论框架，定义了Kraft矩阵概念，给出了信息无损的谱半径条件，解决了不可约情况下的有界性问题，并成功扩展到更一般的编码场景，为有限状态编码器的理论分析提供了重要工具。

Abstract: We derive a few extended versions of the Kraft inequality for information lossless finite-state encoders. The main basic contribution is in defining a notion of a Kraft matrix and in establishing the fact that a necessary condition for information losslessness of a finite-state encoder is that none of the eigenvalues of this matrix have modulus larger than unity, or equivalently, the generalized Kraft inequality asserts that the spectral radius of the Kraft matrix cannot exceed one. For the important special case where the FS encoder is irreducible, we derive several equivalent forms of this inequality, which are based on well known formulas for spectral radius. It also turns out that in the irreducible case, Kraft sums are bounded by a constant, independent of the block length, and thus cannot grow even in any subexponential rate. Finally, two extensions are outlined - one concerns the case of side information available to both encoder and decoder, and the other is for lossy compression.

</details>


### [30] [An Explicit Upper Bound of Generalized Quadratic Gauss Sums and Its Applications for Asymptotically Optimal Aperiodic Polyphase Sequence Design](https://arxiv.org/abs/2601.16599)
*Huaning Liu,Zilong Liu*

Main category: cs.IT

TL;DR: 本文通过改进广义二次高斯和的上界，首次系统构建了满足Welch界的渐近最优非周期多相序列集，揭示了Alltop序列集在非周期相关旁瓣方面的最优性。


<details>
  <summary>Details</summary>
Motivation: 解决设计满足Welch界的渐近最优非周期多相序列集这一长期开放问题。Mow在30多年前曾尝试解决，但对该问题的全面理解仍然缺乏。

Method: 1. 通过递归应用Paris渐近展开并利用Fibonacci zeta函数的快速收敛性，获得广义二次高斯和的显式上界；2. 基于这一关键发现，通过精心选择的Chu序列和Alltop序列，提出了四种系统构建方法。

Result: 首次在文献中揭示了完整Alltop序列集在低非周期相关旁瓣方面的渐近最优性。同时引入了一个新的Alltop序列子集，在整个时移窗口内同时具有最优非周期相关和模糊度特性。

Conclusion: 本文通过理论突破和系统构建，解决了长期存在的非周期多相序列集设计问题，为通信和信号处理领域提供了重要的理论工具。

Abstract: This work is motivated by the long-standing open problem of designing asymptotically order-optimal aperiodic polyphase sequence sets with respect to the celebrated Welch bound. Attempts were made by Mow over 30 years ago, but a comprehensive understanding to this problem is lacking. Our first key contribution is an explicit upper bound of generalized quadratic Gauss sums which is obtained by recursively applying Paris' asymptotic expansion and then bounding it by leveraging the fast convergence property of the Fibonacci zeta function. Building upon this major finding, our second key contribution includes four systematic constructions of order-optimal sequence sets with low aperiodic correlation and/or ambiguity properties via carefully selected Chu sequences and Alltop sequences. For the first time in the literature, we reveal that the full Alltop sequence set is asymptotically optimal for its low aperiodic correlation sidelobes. Besides, we introduce a novel subset of Alltop sequences possessing both order-optimal aperiodic correlation and ambiguity properties for the entire time-shift window.

</details>


### [31] [Term Coding: An Entropic Framework for Extremal Combinatorics and the Guessing--Number Sandwich Theorem](https://arxiv.org/abs/2601.16614)
*Søren Riis*

Main category: cs.IT

TL;DR: 论文研究项编码问题：给定有限项恒等式系统Γ，在n元字母表上最大解集规模是多少？建立了猜测数三明治定理连接项编码与图猜测数，证明最大码规模满足对数增长率为α+o(1)，其中α可通过熵和多拟阵方法计算。


<details>
  <summary>Details</summary>
Motivation: 将拟群、设计等组合结构的经典存在性问题转化为定量的极值问题，研究项恒等式系统在自由选择函数符号解释时的最大解集规模。

Method: 提出猜测数三明治定理，通过显式归一化和多样化约简，将每个实例转化为具有猜测数α的规范有向依赖结构，使用熵和多拟阵方法计算α。

Result: 证明最大码规模满足log_n S_n(Γ)=α+o(1)，即S_n(Γ)=n^{α+o(1)}，其中α可通过图猜测数（图熵）计算，并给出极值组合学和信息流约束的具体实例。

Conclusion: 建立了项编码与图猜测数之间的深刻联系，为研究组合结构的极值问题提供了统一框架，展示了在Steiner型恒等式、自正交拉丁方和网络编码约束等领域的应用。

Abstract: Term Coding asks: given a finite system of term identities $Γ$ in $v$ variables, how large can its solution set be on an $n$--element alphabet, when we are free to choose the interpretations of the function symbols? This turns familiar existence problems for quasigroups, designs, and related objects into quantitative extremal questions.
  We prove a guessing-number sandwich theorem that connects term coding to graph guessing numbers (graph entropy). After explicit normalisation and diversification reductions, every instance yields a canonical directed dependency structure with guessing number $α$ such that the maximum code size satisfies $\log_n \Sn(Γ)=α+o(1)$ (equivalently, $\Sn(Γ)=n^{α+o(1)}$), and $α$ can be bounded or computed using entropy and polymatroid methods.
  We illustrate the framework with examples from extremal combinatorics (Steiner-type identities, self-orthogonal Latin squares) and from information-flow / network-coding style constraints (including a five-cycle instance with fractional exponent and small storage/relay maps).

</details>


### [32] [Taming the Heavy Tail: Age-Optimal Preemption](https://arxiv.org/abs/2601.16624)
*Aimin Li,Yiğit İnce,Elif Uysal*

Main category: cs.IT

TL;DR: 研究连续时间联合采样与抢占问题，在一般服务时间分布下考虑采样和抢占惩罚，提出高效策略迭代算法，在重尾服务时间下相比非抢占采样和零等待基线实现高达30倍的平均成本降低。


<details>
  <summary>Details</summary>
Motivation: 现有采样和抢占问题通常假设服务时间分布特定或需要平滑性假设，本文旨在在一般服务时间分布下研究联合采样与抢占问题，避免传统HJB-QVI方法所需的平滑性假设。

Method: 将系统建模为脉冲控制的分段确定性马尔可夫过程(PDMP)，通过动态规划原理推导耦合积分平均成本最优方程，利用繁忙阶段的关键不变性将动态压缩到一维繁忙起始边界，将抢占控制转化为最优停止问题，开发具有重尾加速的高效策略迭代算法，采用混合(均匀/对数间隔)动作网格和远场线性闭包。

Result: 在Pareto和对数正态服务时间下的仿真显示，相比AoI最优的非抢占采样和零等待基线，在重尾机制下平均成本降低高达30倍，并发现一个反直觉的洞察：在抢占下，延迟方差尽管通常是负债，但可以成为信息新鲜度的战略优势。

Conclusion: 本文提出的方法在一般服务时间分布下有效解决了联合采样与抢占问题，避免了传统方法的平滑性假设，在重尾服务时间下显著优于现有基线，并揭示了延迟方差在抢占策略中的潜在战略价值。

Abstract: This paper studies a continuous-time joint sampling-and-preemption problem, incorporating sampling and preemption penalties under general service-time distributions. We formulate the system as an impulse-controlled piecewise-deterministic Markov process (PDMP) and derive coupled integral average-cost optimality equations via the dynamic programming principle, thereby avoiding the smoothness assumptions typically required for an average-cost Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI) characterization. A key invariance in the busy phase collapses the dynamics onto a one-dimensional busy-start boundary, reducing preemption control to an optimal stopping problem. Building on this structure, we develop an efficient policy iteration algorithm with heavy-tail acceleration, employing a hybrid (uniform/log-spaced) action grid and a far-field linear closure. Simulations under Pareto and log-normal service times demonstrate substantial improvements over AoI-optimal non-preemptive sampling and zero-wait baselines, achieving up to a 30x reduction in average cost in heavy-tailed regimes. Finally, simulations uncover a counterintuitive insight: under preemption, delay variance, despite typically being a liability, can become a strategic advantage for information freshness.

</details>


### [33] [The Oval Strikes Back](https://arxiv.org/abs/2601.16628)
*Andrea Di Giusto,Alberto Ravagnani,Emina Soljanin*

Main category: cs.IT

TL;DR: 本文探讨了射影平面中卵形在分布式存储中的应用，特别是服务率区域问题，构建了一类具有大量小且不相交恢复集的非系统MDS矩阵，在某些参数下优于系统生成矩阵。


<details>
  <summary>Details</summary>
Motivation: 将有限几何中的经典对象——卵形应用于现代编码理论，特别是分布式存储中的服务率区域问题，探索几何结构与编码性能之间的联系。

Method: 利用射影平面中线与卵形的关联关系，构建一类非系统MDS矩阵，这些矩阵具有大量小且不相交的恢复集，并分析其PIR特性和多数逻辑解码算法。

Result: 在某些参数选择下，所构建矩阵的服务率区域包含相同码的系统生成矩阵的区域，表现出更好的服务性能，同时具有强大的纠错能力。

Conclusion: 射影平面中的卵形作为有限几何的经典对象，在现代编码理论中重新成为有用工具，特别是在分布式存储和服务率区域优化方面展现出重要价值。

Abstract: We investigate the applications of ovals in projective planes to distributed storage, with a focus on the Service Rate Region problem. Leveraging the incidence relations between lines and ovals, we describe a class of non-systematic MDS matrices with a large number of small and disjoint recovery sets. For certain parameter choices, the service-rate region of these matrices contains the region of a systematic generator matrix for the same code, yielding better service performance. We further apply our construction to analyze the PIR properties of the considered MDS matrices and present a one-step majority-logic decoding algorithm with strong error-correcting capability. These results highlight how ovals, a classical object in finite geometry, re-emerge as a useful tool in modern coding theory.

</details>


### [34] [Stable Source Coding](https://arxiv.org/abs/2601.16680)
*Zhenduo Wen,Amin Gohari*

Main category: cs.IT

TL;DR: 研究稳定无损信源编码的压缩率，推导稳定参数下的可达速率信息论极限


<details>
  <summary>Details</summary>
Motivation: 传统随机分箱编码方法不稳定，因为随机映射导致相似信源序列可能被分配到完全不相关的箱索引。需要研究稳定信源编码的性能极限。

Method: 使用组合论证方法，推导稳定无损信源编码的可达速率作为稳定参数的函数

Result: 建立了稳定信源编码的压缩率信息论极限，量化了稳定性要求对编码效率的影响

Conclusion: 稳定信源编码存在基本的信息论极限，稳定性要求会限制可达到的压缩率，为实际稳定编码系统设计提供了理论指导

Abstract: A source encoder is stable if a small change in the source sequence (e.g., changing a few symbols) results in a small (or bounded) change in the output codeword. By this definition, the common technique of random binning is unstable; because the mapping is random, two nearly identical source sequences can be assigned to completely unrelated bin indices. We study compression rates of stable lossless source codes. Using combinatorial arguments, we derive information-theoretic limits on the achievable rate as a function of the stability parameters.

</details>


### [35] [Adaptive Beam Alignment using Noisy Twenty Questions Estimation with Trained Questioner](https://arxiv.org/abs/2601.16799)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 提出基于噪声二十问题估计框架的自适应波束对准算法，通过训练提问器解决传统方法的可行性问题和黑盒神经网络的可解释性问题，在6G毫米波MIMO系统中实现高效波束对准。


<details>
  <summary>Details</summary>
Motivation: 6G通信系统使用毫米波和MIMO技术，但面临严重的信号衰减问题，需要波束对准。传统扇区搜索算法存在显著延迟，现有自适应算法要么缺乏可行性（依赖理想假设），要么缺乏可解释性（使用端到端黑盒神经网络）。

Method: 提出基于噪声二十问题估计框架的自适应波束对准算法，训练提问器来消除对理想假设的依赖。使用两种方法：1）通过导向矢量的加权求和将二十问题估计的查询映射到波束赋形向量；2）使用多层全连接神经网络训练提问器以提高性能，同时保持可解释性。

Result: 数值仿真表明，提出的自适应波束对准算法有效，并且性能优于所有基准算法。

Conclusion: 提出的算法解决了现有自适应波束对准方法的可行性问题和可解释性问题，在6G毫米波MIMO系统中实现了高效的自适应波束对准，性能优于现有方法。

Abstract: The 6G communication systems use mmWave and MIMO technologies to achieve wide bandwidth and high throughout, leading to indispensable need for beam alignment to overcome severe signal attenuation. Traditional sector-search-based beam alignment algorithms rely on sequential sampling to identify the best sector, resulting in a significant latency burden on 6G communication systems. Recently proposed adaptive beam alignment algorithms based on the active learning framework address the problem, aiming to identify the optimal sector with the fewest possible samples under an identical sector partition. Nevertheless, these algorithms either lack feasibility (Chiu, Ronquillo and Javidi, JSAC 2019) due to ideal assumptions or lack interpretability (Sohrabi, Chen and Yu, JSAC 2021) due to the use of end-to-end black-box neural networks. To avoid ideal assumptions and maintain interpretability, we address all above problems by proposing an adaptive beam alignment algorithm using the framework of noisy twenty questions estimation with a trained questioner. Specifically, we use two methods for training the questioner to eliminate reliance on ideal assumptions. The first method maps queries of twenty questions estimation to beamforming vectors via weighted summation of steering vectors, as an initial attempt to address the feasibility problem encountered in prior pioneering study by Chiu, Ronquillo and Javidi (JSAC 2019). The second method uses multi-layer fully connected neural networks to achieve improved performance while only employing them to train the questioner, which can effectively mitigate the interpretability issues in prior study by Sohrabi, Chen and Yu (JSAC 2021). Furthermore, we provide numerical simulations to illustrate the effectiveness of our proposed adaptive beam alignment algorithms and demonstrate that our algorithms outperform all benchmark algorithms.

</details>


### [36] [Privacy-Resolution Tradeoff for Adaptive Noisy Twenty Questions Estimation](https://arxiv.org/abs/2601.16825)
*Chunsong Sun,Lin Zhou*

Main category: cs.IT

TL;DR: 本文研究带噪声的二十个问题估计中的隐私-分辨率权衡，提出两阶段隐私查询方法，分析其非渐近和二阶渐近性能，并在无噪声情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自适应查询方法通常性能更好，但会引发隐私问题。现有研究主要关注无噪声情况，本文旨在将隐私-分辨率权衡分析扩展到更实际的带噪声场景。

Method: 提出两阶段隐私查询程序：第一阶段使用非自适应查询获取初步信息，第二阶段基于第一阶段结果进行自适应查询。分析该方法的非渐近和二阶渐近性能。

Result: 提出的两阶段隐私查询方法在带噪声情况下实现了隐私与分辨率之间的权衡，在无噪声情况下性能优于COLT 2018和AISTATS 2021的现有方法。

Conclusion: 本文成功将隐私-分辨率权衡分析扩展到带噪声的二十个问题估计，提出的两阶段方法在保持隐私的同时实现了良好的估计性能，特别是在无噪声情况下超越了现有方法。

Abstract: We revisit noisy twenty questions estimation and study the privacy-resolution tradeoff for adaptive query procedures. Specifically, in twenty questions estimation, there are two players: an oracle and a questioner. The questioner aims to estimate target variables by posing queries to the oracle that knows the variables and using noisy responses to form reliable estimates. Typically, there are adaptive and non-adaptive query procedures. In adaptive querying, one designs the current query using previous queries and their noisy responses while in non-adaptive querying, all queries are posed simultaneously. Generally speaking, adaptive query procedures yield better performance. However, adaptive querying leads to privacy concerns, which were first studied by Tsitsiklis, Xu and Xu (COLT 2018) and by Xu, Xu and Yang (AISTATS 2021) for the noiseless case, where the oracle always provides correct answers to queries. In this paper, we generalize the above results to the more practical noisy case, by proposing a two-stage private query procedure, analyzing its non-asymptotic and second-order asymptotic achievable performance and discussing the impact of privacy concerns. Furthermore, when specialized to the noiseless case, our private query procedure achieves better performance than above-mentioned query procedures (COLT 2018, AISTATS 2021).

</details>


### [37] [Information Contraction under $(\varepsilon,δ)$-Differentially Private Mechanisms](https://arxiv.org/abs/2601.16845)
*Theshani Nuradha,Ian George,Christoph Hirche*

Main category: cs.IT

TL;DR: 本文针对(ε,δ)-局部差分隐私机制，推导了曲棍球散度和f-散度的线性和非线性强数据处理不等式，改进了现有仅适用于(ε,0)-LDP的界限。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数信息度量收缩特性（包括总变分距离、曲棍球散度和f-散度）的紧致刻画仅适用于(ε,0)-局部差分隐私机制，缺乏对更一般的(ε,δ)-LDP机制（δ≠0）的分析。

Method: 推导了适用于所有(ε,δ)-局部差分隐私机制的线性和非线性强数据处理不等式，这些不等式针对曲棍球散度和f-散度，扩展了现有仅适用于(ε,0)-LDP的界限。

Result: 获得了比先前已知界限更优或更一般的曲棍球散度和f-散度收缩特性，为(ε,δ)-LDP机制下的可区分性度量提供了新的理论保证。

Conclusion: 本文的工作填补了(ε,δ)-局部差分隐私机制下信息度量收缩特性的理论空白，为隐私保护机制的分析提供了更全面的工具。

Abstract: The distinguishability quantified by information measures after being processed by a private mechanism has been a useful tool in studying various statistical and operational tasks while ensuring privacy. To this end, standard data-processing inequalities and strong data-processing inequalities (SDPI) are employed. Most of the previously known and even tight characterizations of contraction of information measures, including total variation distance, hockey-stick divergences, and $f$-divergences, are applicable for $(\varepsilon,0)$-local differential private (LDP) mechanisms. In this work, we derive both linear and non-linear strong data-processing inequalities for hockey-stick divergence and $f$-divergences that are valid for all $(\varepsilon,δ)$-LDP mechanisms even when $δ\neq 0$. Our results either generalize or improve the previously known bounds on the contraction of these distinguishability measures.

</details>


### [38] [Perfect Privacy and Strong Stationary Times for Markovian Sources](https://arxiv.org/abs/2601.16857)
*Fangwei Ye,Zonghong Liu,Parimal Parag,Salim El Rouayheb*

Main category: cs.IT

TL;DR: 研究在完美信息论隐私约束下共享相关数据的问题，提出基于擦除的机制，在保护初始状态的同时最大化共享数据量，证明最优机制仅需擦除常数个数据点。


<details>
  <summary>Details</summary>
Motivation: 在数据共享中，如何在保护隐私（特别是初始状态）的同时最大化共享数据量是一个重要问题。现有方法需要平衡隐私和效用，本文研究在完美隐私约束下的最优数据共享机制。

Method: 采用擦除机制，数据要么被保留原样释放，要么被擦除。假设数据由有限时间齐次马尔可夫链生成，研究基于窗口的擦除方案和最优顺序擦除机制，建立完美隐私与强平稳时间擦除之间的联系。

Result: 证明了完美隐私可以通过基于窗口的擦除方案实现，最优顺序擦除机制具有等价的窗口解释。有趣的是，两种机制都能达到最优失真，且平均仅擦除常数个数据点，与数据长度N无关。

Conclusion: 在完美信息论隐私约束下，可以通过基于强平稳时间的擦除机制有效保护马尔可夫数据的初始状态，同时仅需擦除常数个数据点就能实现最优的数据共享效用。

Abstract: We consider the problem of sharing correlated data under a perfect information-theoretic privacy constraint. We focus on redaction (erasure) mechanisms, in which data are either withheld or released unchanged, and measure utility by the average cardinality of the released set, equivalently, the expected Hamming distortion. Assuming the data are generated by a finite time-homogeneous Markov chain, we study the protection of the initial state while maximizing the amount of shared data. We establish a connection between perfect privacy and window-based redaction schemes, showing that erasing data up to a strong stationary time preserves privacy under suitable conditions. We further study an optimal sequential redaction mechanism and prove that it admits an equivalent window interpretation. Interestingly, we show that both mechanisms achieve the optimal distortion while redacting only a constant average number of data points, independent of the data length~$N$.

</details>
