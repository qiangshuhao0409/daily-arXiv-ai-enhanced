<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.IT](#cs.IT) [Total: 7]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Managing Credible Anonymous Identities in Web 3.0 Services: A Scalable On-Chain Admission Framework with Recursive Proof Aggregation](https://arxiv.org/abs/2602.16130)
*Zibin Lin,Taotao Wang,Shengli Zhang,Long Shi,Shui Yu*

Main category: cs.NI

TL;DR: ZK-AMS：一个可扩展的准入和供应层，通过零知识凭证验证、无许可批量提交模型和去中心化隐私保护折叠管道，实现批量结算的恒定链上验证成本，为Web 3.0服务生态系统提供高效、隐私保护且成本可预测的准入服务。


<details>
  <summary>Details</summary>
Motivation: Web 3.0平台作为服务生态系统（如DeFi、DAO、去中心化社交应用）需要提供持续运行的准入控制和账户供应服务，面临Sybil抵抗（一人一账户）、用户隐私保护和链上验证成本与延迟可预测性之间的根本矛盾。现有基于凭证的ZK准入方法通常需要每次请求都进行链上验证，导致供应成本随并发加入者数量增长。

Method: ZK-AMS结合了三个关键技术：(1) 零知识凭证验证，(2) 无许可批量提交模型，(3) 使用Nova风格递归聚合与多密钥同态加密的去中心化隐私保护折叠管道。该系统能够实现批量结算，每批次的链上验证成本保持恒定。

Result: 在以太坊测试平台上实现了端到端的ZK-AMS系统，评估了准入吞吐量、端到端延迟和gas消耗。结果显示验证成本在不同批量大小下保持稳定，与非递归基线相比显著提高了准入效率，为大规模Web 3.0社区提供了实用且成本可预测的准入服务。

Conclusion: ZK-AMS通过创新的技术组合解决了Web 3.0服务生态系统中的准入控制难题，在保持Sybil抵抗和用户隐私的同时，实现了可扩展的批量处理能力，为大规模去中心化应用提供了高效、成本可预测的准入解决方案。

Abstract: Open Web 3.0 platforms increasingly operate as \emph{service ecosystems} (e.g., DeFi, DAOs, and decentralized social applications) where \emph{admission control} and \emph{account provisioning} must be delivered as an always-on service under bursty demand. Service operators face a fundamental tension: enforcing Sybil resistance (one-person-one-account) while preserving user privacy, yet keeping on-chain verification cost and admission latency predictable at scale. Existing credential-based ZK admission approaches typically require per-request on-chain verification, making the provisioning cost grow with the number of concurrent joiners. We present \textbf{ZK-AMS}, a scalable admission and provisioning layer that bridges real-world \emph{Personhood Credentials} to anonymous on-chain service accounts. ZK-AMS combines (i) zero-knowledge credential validation, (ii) a \emph{permissionless} batch submitter model, and (iii) a decentralized, privacy-preserving folding pipeline that uses Nova-style recursive aggregation together with multi-key homomorphic encryption, enabling batch settlement with \emph{constant} on-chain verification per batch. We implement ZK-AMS end-to-end on an Ethereum testbed and evaluate admission throughput, end-to-end latency, and gas consumption. Results show stable verification cost across batch sizes and substantially improved admission efficiency over non-recursive baselines, providing a practical and cost-predictable admission service for large-scale Web 3.0 communities.

</details>


### [2] [Collection: UAV-Based Wireless Multi-modal Measurements from AERPAW Autonomous Data Mule (AADM) Challenge in Digital Twin and Real-World Environments](https://arxiv.org/abs/2602.16163)
*Md Sharif Hossen,Cole Dickerson,Ozgur Ozdemir,Anil Gurses,Mohamed Rabeek Sarbudeen,Thomas Zajkowski,Ahmed Manavi Alam,Everett Tucker,William Bjorndahl,Fred Solis,Sadaf Javed,Anirudh Kamath,Xiangyao Tang,Joarder Jafor Sadique,Kevin Liu Hermstein,Kaies Al Mahmud,Jose Angel Sanchez Viloria,Skyler Hawkins,Yuqing Cui,Annoy Dey,Yuchen Liu,Ali Gurbuz,Joseph Camp,Rizwan Ahmad,Jacobus van der Merwe,Ahmed Ibrahim Mohamed,Gil Zussman,Mehmet Kurum,Namuduri Kamesh,Zhangyu Guan,Dimitris Pados,George Skilvanitis,Ismail Guvenc,Mihail Sichitiu,Magreth Mushi,Rudra Dutta*

Main category: cs.NI

TL;DR: 该论文介绍了AERPAW项目中无人机无线数据集的收集工作，该数据集来自自主空中数据中继挑战赛，包含数字孪生和物理环境中的链路质量和数据下载测量，支持自主无人机网络、传播建模等研究。


<details>
  <summary>Details</summary>
Motivation: 为自主无人机网络研究提供基准数据集，支持多基站关联、空对地传播建模、数字孪生到现实世界迁移学习等研究方向的可重复研究。

Method: 通过AERPAW自主空中数据中继挑战赛收集数据，比赛分两阶段：第一阶段在数字孪生环境中开发和实验，第二阶段在室外测试平台进行最终测试运行，综合两阶段得分。

Result: 创建了一个包含链路质量和数据下载测量的综合数据集，包括USRP测量、无人机遥测、Keysight RF传感器位置估计、LoRa接收器链路质量测量和Fortem雷达测量。

Conclusion: 该数据集为未来自主无线实验提供了基准，支持自主无人机网络、多小区关联调度、传播建模、迁移学习和集成感知通信等多个研究领域。

Abstract: In this work, we present an unmanned aerial vehicle (UAV) wireless dataset collected as part of the AERPAW Autonomous Aerial Data Mule (AADM) challenge, organized by the NSF Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW) project. The AADM challenge was the second competition in which an autonomous UAV acted as a data mule, where the UAV downloaded data from multiple base stations (BSs) in a dynamic wireless environment. Participating teams designed flight control and decision-making algorithms for choosing which BSs to communicate with and how to plan flight trajectories to maximize data download within a mission completion time. The competition was conducted in two stages: Stage 1 involved development and experimentation using a digital twin (DT) environment, and in Stage 2, the final test run was conducted on the outdoor testbed. The total score for each team was compiled from both stages. The resulting dataset includes link quality and data download measurements, both in DT and physical environments. Along with the USRP measurements used in the contest, the dataset also includes UAV telemetry, Keysight RF sensors position estimates, link quality measurements from LoRa receivers, and Fortem radar measurements. It supports reproducible research on autonomous UAV networking, multi-cell association and scheduling, air-to-ground propagation modeling, DT-to-real-world transfer learning, and integrated sensing and communication, which serves as a benchmark for future autonomous wireless experimentation.

</details>


### [3] [Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation](https://arxiv.org/abs/2602.16174)
*Fatih Temiz,Shavbo Salehi,Melike Erol-Kantarci*

Main category: cs.NI

TL;DR: 提出联邦分割决策变换器(FSDT)，一种离线强化学习框架，通过将变换器模型分割在MEC服务器和云端之间，在异构多无线接入技术环境中提升虚拟现实用户的体验质量。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算(MEC)为无线元宇宙服务提供无束缚的沉浸式体验，但需要在严格延迟约束和视觉质量要求下实现优质体验质量(QoE)。传统联邦学习存在传输完整模型参数和性能下降问题，特别是在异构多无线接入技术环境中。

Method: 提出联邦分割决策变换器(FSDT)，一种离线强化学习框架，将变换器模型分割在MEC服务器和云端之间。MEC服务器包含代理特定组件（如嵌入层和预测层），云端包含共享全局层，实现本地适应性和跨MEC服务器的协同训练。

Result: 实验结果表明，FSDT在异构环境中相比基线方法提升QoE达10%，同时将约98%的变换器模型参数卸载到云端，显著减轻MEC服务器的计算负担。

Conclusion: FSDT框架通过模型分割策略有效解决了传统联邦学习在MEC环境中的局限性，实现了本地适应性与全局协同的平衡，为无线元宇宙服务的资源分配提供了高效解决方案。

Abstract: Mobile edge computing (MEC) based wireless metaverse services offer an untethered, immersive experience to users, where the superior quality of experience (QoE) needs to be achieved under stringent latency constraints and visual quality demands. To achieve this, MEC-based intelligent resource allocation for virtual reality users needs to be supported by coordination across MEC servers to harness distributed data. Federated learning (FL) is a promising solution, and can be combined with reinforcement learning (RL) to develop generalized policies across MEC-servers. However, conventional FL incurs transmitting the full model parameters across the MEC-servers and the cloud, and suffer performance degradation due to naive global aggregation, especially in heterogeneous multi-radio access technology environments. To address these challenges, this paper proposes Federated Split Decision Transformer (FSDT), an offline RL framework where the transformer model is partitioned between MEC servers and the cloud. Agent-specific components (e.g., MEC-based embedding and prediction layers) enable local adaptability, while shared global layers in the cloud facilitate cooperative training across MEC servers. Experimental results demonstrate that FSDT enhances QoE for up to 10% in heterogeneous environments compared to baselines, while offloadingnearly 98% of the transformer model parameters to the cloud, thereby reducing the computational burden on MEC servers.

</details>


### [4] [Multi-Agent Meta-Advisor for UAV Fleet Trajectory Design in Vehicular Networks](https://arxiv.org/abs/2602.16345)
*Leonardo Spampinato,Lorenzo Mario Amorosa,Enrico Testi,Chiara Buratti,Riccardo Marini*

Main category: cs.NI

TL;DR: 本文提出MAMO框架，用于指导多无人机基站协同轨迹设计中的智能体探索，通过元策略学习和动态覆盖机制，在多种城市场景中实现更快的收敛和更高的性能。


<details>
  <summary>Details</summary>
Motivation: 未来车联网需要连续连接服务高速移动用户，但固定宏基站在非视距条件下覆盖有限。无人机基站可以动态重定位跟踪车辆用户和交通热点，但多智能体轨迹设计面临不同服务区域和起飞配置的挑战，需要快速安全地适应多种场景。

Method: 将问题建模为多任务分散部分可观测马尔可夫决策过程，采用集中训练分散执行架构和双决斗深度Q网络。提出多智能体元顾问与顾问覆盖框架，通过跨任务联合学习的元策略指导智能体探索，并引入动态覆盖机制允许智能体在顾问无法泛化到特定场景时拒绝错误指导。

Result: 在三种现实城市场景和多种起飞配置的仿真中，MAMO相比调优的ε-greedy基线实现了更快的收敛和更高的回报，优于仅使用顾问的消融实验和单一泛化策略。学习到的无人机基站编队显著提升了网络性能。

Conclusion: MAMO框架通过元策略学习和动态覆盖机制有效解决了多智能体轨迹设计中的探索瓶颈，在多种城市场景中实现了优越的性能，证明了无人机基站编队对提升车联网性能的重要价值。

Abstract: Future vehicular networks require continuous connectivity to serve highly mobile users in urban environments. To mitigate the coverage limitations of fixed terrestrial macro base stations (MBS) under non line-of-sight (NLoS) conditions, fleets of unmanned aerial base stations (UABSs) can be deployed as aerial base stations, dynamically repositioning to track vehicular users and traffic hotspots in coordination with the terrestrial network. This paper addresses cooperative multi-agent trajectory design under different service areas and takeoff configurations, where rapid and safe adaptation across scenarios is essential. We formulate the problem as a multi-task decentralized partially observable Markov decision process and solve it using centralized training and decentralized execution with double dueling deep Q-network (3DQN), enabling online training for real-world deployments. However, efficient exploration remains a bottleneck, with conventional strategies like $ε$-greedy requiring careful tuning. To overcome this, we propose the multi-agent meta-advisor with advisor override (MAMO). This framework guides agent exploration through a meta-policy learned jointly across tasks. It uses a dynamic override mechanism that allows agents to reject misaligned guidance when the advisor fails to generalize to a specific scenario. Simulation results across three realistic urban scenarios and multiple takeoff configurations show that MAMO achieves faster convergence and higher returns than tuned $ε$-greedy baselines, outperforming both an advisor-only ablation and a single generalized policy. Finally, we demonstrate that the learned UABS fleet significantly improves network performance compared to deployments without aerial support.

</details>


### [5] [A Multihop Rendezvous Protocol for Cognitive Radio-based Emergency Response Network](https://arxiv.org/abs/2602.16367)
*Zahid Ali,Saritha Unnikrishnan,Eoghan Furey,Ian McLoughlin,Saim Ghafoor*

Main category: cs.NI

TL;DR: 提出M-DMCA算法，用于认知无线电应急网络的节点发现，通过双信道选择和三次握手机制显著减少会合时间，比现有协议性能提升24%


<details>
  <summary>Details</summary>
Motivation: 认知无线电应急响应网络需要高效的节点发现机制，特别是在信道不对称、主用户活动频繁的恶劣环境下，现有会合协议的性能有待提升

Method: 提出多跳双模块时钟算法（M-DMCA），支持每个时隙双信道选择，并采用三次握手机制来减少会合时间

Result: 在最坏情况下（20个节点，20个不对称信道，信道相似度指数为2，高主用户活动），M-DMCA比多跳扩展模块时钟算法（EMCA）减少24%的会合时间，优于现有会合协议

Conclusion: M-DMCA算法通过双信道选择和三次握手机制，在认知无线电应急网络中实现了更高效的节点发现，显著提升了会合性能

Abstract: This letter proposes a novel Multihop Dual Modular Clock Algorithm (M-DMCA) for efficient node discovery in cognitive radio-based emergency response networks. M-DMCA supports dual-channel selection per timeslot and incorporates a three-way handshake mechanism to significantly reduce rendezvous time. Performance evaluation under a worst-case scenario with 20 nodes, asymmetric channel sets of size 20, channel similarity index (m) as 2, and high primary radio activity shows that M-DMCA achieves a 24% reduction in rendezvous time compared to the multihop Extended Modular Clock Algorithm (EMCA), outperforming existing rendezvous protocols.

</details>


### [6] [Towards Secure and Interoperable Data Spaces for 6G: The 6G-DALI Approach](https://arxiv.org/abs/2602.16386)
*Dimitrios Amaxilatis,Themistoklis Sarantakos,Nikolaos Tsironis,Vasileios Theodorou,Christos Verikoukis*

Main category: cs.NI

TL;DR: 6G-DALI项目提出了一种基于GAIA-X和IDSA原则的联邦数据空间架构，支持6G网络中安全、合规、可扩展的数据共享，用于AI驱动实验和服务编排。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要支持大规模复杂的数据驱动服务，对信任、互操作性和自动化有严格要求。核心挑战在于如何在分布式异构环境中创建、管理和共享高质量数据集。

Method: 采用联邦数据空间和DataOps基础设施架构，整合了联邦身份管理、基于策略的数据合约和自动化数据管道等组件，基于GAIA-X和IDSA参考模型进行扩展。

Result: 开发了6G-DALI数据架构，能够满足6G网络的独特需求，包括低延迟边缘处理、动态信任管理和跨域联邦，并通过比较分析确定了收敛点和创新需求。

Conclusion: 6G-DALI架构成功扩展了GAIA-X和IDSA参考模型，为6G网络中的数据共享提供了安全、合规、可扩展的解决方案，支持AI驱动实验和服务编排。

Abstract: The next generation of mobile networks, 6G, is expected to enable data-driven services at unprecedented scale and complexity, with stringent requirements for trust, interoperability, and automation. Central to this vision is the ability to create, manage, and share high-quality datasets across distributed and heterogeneous environments. This paper presents the data architecture of the 6G-DALI project, which implements a federated dataspace and DataOps infrastructure to support secure, compliant, and scalable data sharing for AI-driven experimentation and service orchestration. Drawing from principles defined by GAIA-X and the International Data Spaces Association (IDSA), the architecture incorporates components such as federated identity management, policy-based data contracts, and automated data pipelines. We detail how the 6G-DALI architecture aligns with and extends GAIA-X and IDSA reference models to meet the unique demands of 6G networks, including low-latency edge processing, dynamic trust management, and cross-domain federation. A comparative analysis highlights both convergence points and necessary innovations.

</details>


### [7] [Fast-MCS: A Scalable Open-Source Tool to Find Minimal Cut Sets](https://arxiv.org/abs/2602.16686)
*Shakthivelu Janardhanan,Yaxuan Chen,Wolfgang Kellerer,Carmen Mas-Machuca*

Main category: cs.NI

TL;DR: Fast-MCS是一个用于评估大型复杂网络中最小割集的开源可扩展工具，相比现有技术具有更快的计算速度。


<details>
  <summary>Details</summary>
Motivation: 最小割集在网络可靠性分析中至关重要，能够识别对网络连接性影响最大的关键元素。然而，在大型复杂网络中计算最小割集具有挑战性，需要高效的算法和工具。

Method: 开发了Fast-MCS工具，这是一个开源、可扩展的解决方案，专门用于评估大型复杂网络中的最小割集。该工具旨在处理大规模网络并提高计算效率。

Result: Fast-MCS在计算时间上与现有最先进技术进行了比较，显示出更快的性能。该工具能够有效处理大型复杂网络的最小割集评估。

Conclusion: Fast-MCS是一个有效的开源工具，能够显著提高大型复杂网络中最小割集的计算效率，为网络可靠性分析提供了实用的解决方案。

Abstract: A network is represented as a graph consisting of nodes and edges. A cut set for a source-destination pair in a network is a set of elements that, when failed, cause the source-destination pair to lose connectivity. A Minimal Cut Set (MCS) is a cut set that cannot be further reduced while maintaining its status as a cut set. MCSs are crucial in identifying the critical elements in the network that have the most significant impact on failure. This work introduces Fast-MCS, an open-source, scalable tool for evaluating MCSs in large, complex networks. Additionally, we compare the computation time of Fast-MCS with the state-of-the-art.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Towards Efficient Constraint Handling in Neural Solvers for Routing Problems](https://arxiv.org/abs/2602.16012)
*Jieyi Bi,Zhiguang Cao,Jianan Zhou,Wen Song,Yaoxin Wu,Jie Zhang,Yining Ma,Cathy Wu*

Main category: cs.AI

TL;DR: CaR是一个用于神经路由求解器的通用高效约束处理框架，通过显式的基于学习的可行性精炼，在保持计算效率的同时处理复杂约束。


<details>
  <summary>Details</summary>
Motivation: 当前神经求解器在简单路由问题上表现出色，但在处理复杂约束时，现有的可行性掩码或隐式可行性感知方法效率低下或不适用于硬约束。

Method: 提出Construct-and-Refine框架：1）联合训练框架指导构造模块生成多样且高质量的解决方案；2）使用轻量级改进过程（仅需10步而非之前的5000步）；3）首次采用构造-改进共享表示，统一编码器实现跨范式知识共享。

Result: 在典型硬路由约束上的评估显示，CaR在可行性、解决方案质量和效率方面均优于经典和神经SOTA求解器。

Conclusion: CaR是第一个基于显式学习可行性精炼的通用高效约束处理框架，为神经路由求解器处理复杂约束提供了有效解决方案。

Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.

</details>


### [9] [Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](https://arxiv.org/abs/2602.16037)
*Cameron Cagan,Pedram Fard,Jiazi Tian,Jingya Cheng,Shawn N. Murphy,Hossein Estiri*

Main category: cs.AI

TL;DR: 自主代理工作流在持续优化中可能出现性能退化，特别是在低患病率分类任务中，标准评估指标可能掩盖严重失败模式。研究发现回顾性选择比主动干预更有效。


<details>
  <summary>Details</summary>
Motivation: 自主代理工作流能够迭代优化自身行为，但其失败模式尚未得到充分研究。本研究旨在探索优化不稳定性现象，即持续自主优化反而导致分类器性能下降的问题。

Method: 使用开源框架Pythia进行自动提示优化，评估三种不同患病率的临床症状（气短23%、胸痛12%、长新冠脑雾3%）。测试两种干预措施：引导代理主动重定向优化，以及选择代理回顾性识别最佳迭代。

Result: 验证灵敏度在迭代中在1.0和0.0之间振荡，严重程度与类别患病率成反比。在3%患病率下，系统达到95%准确率但检测到零阳性病例。选择代理成功防止灾难性失败，在脑雾检测上比专家词典提升331%（F1），胸痛提升7%。

Conclusion: 自主AI系统存在关键失败模式，在低患病率分类任务中，回顾性选择比主动干预更有效地稳定系统性能。

Abstract: Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.

</details>


### [10] [How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment](https://arxiv.org/abs/2602.16039)
*Hang Li,Kaiqi Yang,Xianxuan Long,Fedor Filippov,Yucheng Chu,Yasemin Copur-Gencturk,Peng He,Cory Miller,Namsoo Shin,Joseph Krajcik,Hui Liu,Jiliang Tang*

Main category: cs.AI

TL;DR: 本文系统评估了大型语言模型在教育自动评估中的不确定性量化方法，分析了不同模型、任务和解码策略对不确定性估计的影响，为开发更可靠的评估系统提供基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在教育自动评估中展现出优势，但其固有的概率特性带来了输出不确定性的挑战。评估结果直接影响后续教学决策，不可靠的不确定性估计可能导致不稳定的教学干预，对学习过程产生负面影响。目前不确定性量化方法在教育评估领域的适用性和可靠性尚未充分探索。

Method: 对多种不确定性量化方法进行基准测试，通过综合分析多个评估数据集、不同LLM家族和生成控制设置下的不确定性行为，表征LLM在评分场景中的不确定性模式。评估不同不确定性指标的优劣，分析模型家族、评估任务和解码策略等关键因素对不确定性估计的影响。

Result: 研究发现LLM在自动评估中展现出特定的不确定性模式，不同不确定性量化方法在准确性、校准性和鲁棒性方面存在差异。模型家族、评估任务类型和解码策略显著影响不确定性估计的可靠性。研究为理解LLM评估中的不确定性特征提供了实证基础。

Conclusion: 本研究系统揭示了LLM在教育自动评估中的不确定性挑战，评估了现有不确定性量化方法的适用性，为开发更可靠、有效的基于不确定性的自动评分系统奠定了基础，并指出了未来研究的关键方向。

Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.

</details>


### [11] [Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination](https://arxiv.org/abs/2602.16050)
*Amir Hosseinian,MohammadReza Zare Shahneh,Umer Mansoor,Gilbert Szeto,Kirill Karlin,Nima Aghaeepour*

Main category: cs.AI

TL;DR: January Mirror系统在专科临床推理中超越前沿LLMs，通过证据溯源架构在120题内分泌考试中获得87.5%准确率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在一般医学考试中表现良好，但在专科临床推理方面面临挑战，因为专科指南快速演变且证据层次复杂，需要可审计的临床推理系统

Method: 开发January Mirror系统，整合精选的内分泌和心脏代谢证据语料库与结构化推理架构，在封闭证据约束下运行；与具有实时网络访问权限的前沿LLMs（GPT-5、GPT-5.2、Gemini-3-Pro）进行比较

Result: Mirror获得87.5%准确率，显著超过人类参考标准（62.3%）和所有前沿LLMs；在最难的30题中达到76.7%准确率；74.2%输出引用指南级证据，且引用准确率100%

Conclusion: 具有明确溯源的精选证据系统在专科临床推理中优于无约束的网络检索，支持临床部署的可审计性，为专科医学AI应用提供新方向

Abstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.

</details>


### [12] [Improving Interactive In-Context Learning from Natural Language Feedback](https://arxiv.org/abs/2602.16066)
*Martin Klissarov,Jonathan Cook,Diego Antognini,Hao Sun,Jingling Li,Natasha Jaques,Claudiu Musat,Edward Grefenstette*

Main category: cs.AI

TL;DR: 提出一个框架将交互式上下文学习作为可训练技能，通过信息不对称将单轮任务转为多轮教学互动，显著提升模型从语言反馈中学习的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型训练主要依赖静态语料库，忽略了人类学习中基于纠正反馈动态适应的交互反馈循环，需要开发模型从交互反馈中学习的能力。

Method: 提出可扩展方法，通过信息不对称将单轮可验证任务转化为多轮教学互动，训练模型从语言反馈中学习，并让模型预测教师批评以将外部反馈转化为内部能力。

Result: 训练后模型在困难推理任务中整合纠正反馈能力大幅提升，小模型多轮性能接近大一个数量级的大模型，在数学、编程、谜题和迷宫导航等任务上表现出鲁棒的分布外泛化能力。

Conclusion: 交互式上下文学习能力可作为可训练技能开发，通过将外部反馈信号转化为内部能力，该范式为模型自我改进提供了统一路径，使模型能够在没有教师的情况下自我纠正。

Abstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.

</details>


### [13] [GPSBench: Do Large Language Models Understand GPS Coordinates?](https://arxiv.org/abs/2602.16105)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: GPSBench：一个包含57,800个样本、17个任务的评估数据集，用于测试LLM在GPS坐标和地理空间推理方面的能力，发现几何坐标运算比真实世界地理推理更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地应用于与物理世界交互的应用（如导航、机器人、地图），强大的地理空间推理能力变得至关重要。然而，LLM在GPS坐标和真实世界地理推理方面的能力尚未得到充分探索。

Method: 引入GPSBench数据集，包含57,800个样本和17个任务，涵盖几何坐标运算（如距离和方位计算）以及将坐标与世界知识结合的推理。评估了14个最先进的LLM，重点关注内在模型能力而非工具使用。

Result: GPS推理仍然具有挑战性，不同任务间差异显著：模型在真实世界地理推理方面通常比几何计算更可靠。地理知识呈层级式退化，国家级别表现强但城市级别定位弱。对坐标噪声的鲁棒性表明模型具有真正的坐标理解而非简单记忆。

Conclusion: GPS坐标增强可以改善下游地理空间任务，微调会在几何计算能力的提升与世界知识的退化之间产生权衡。该研究为评估和改进LLM的地理空间推理能力提供了基准数据集和工具。

Abstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench

</details>


### [14] [Learning Personalized Agents from Human Feedback](https://arxiv.org/abs/2602.16173)
*Kaiqu Liang,Julia Kruk,Shengyi Qian,Xianjun Yang,Shengjie Bi,Yuanshun Yao,Shaoliang Nie,Mingyang Zhang,Lijuan Liu,Jaime Fernández Fisac,Shuyan Zhou,Saghar Hosseini*

Main category: cs.AI

TL;DR: PAHF框架通过显式用户记忆和双重反馈通道实现AI代理的持续个性化，在初始偏好学习和偏好漂移适应方面显著优于无记忆和单通道基线


<details>
  <summary>Details</summary>
Motivation: 现有AI代理虽然强大，但难以与个体用户的独特、动态偏好对齐。传统方法依赖静态数据集，无法有效处理新用户和随时间变化的偏好

Method: 提出PAHF框架，包含三步循环：1)行动前澄清以解决歧义；2)基于记忆检索偏好的行动落地；3)整合行动后反馈以更新记忆。使用显式用户记忆和双重反馈通道

Result: 在具身操作和在线购物两个基准测试中，PAHF学习速度显著更快，持续优于无记忆和单通道基线，减少初始个性化误差并快速适应偏好漂移

Conclusion: 整合显式记忆与双重反馈通道对于AI代理的持续个性化至关重要，PAHF框架能有效学习初始偏好并适应偏好变化

Abstract: Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents learn online from live interaction using explicit per-user memory. PAHF operationalizes a three-step loop: (1) seeking pre-action clarification to resolve ambiguity, (2) grounding actions in preferences retrieved from memory, and (3) integrating post-action feedback to update memory when preferences drift. To evaluate this capability, we develop a four-phase protocol and two benchmarks in embodied manipulation and online shopping. These benchmarks quantify an agent's ability to learn initial preferences from scratch and subsequently adapt to persona shifts. Our theoretical analysis and empirical results show that integrating explicit memory with dual feedback channels is critical: PAHF learns substantially faster and consistently outperforms both no-memory and single-channel baselines, reducing initial personalization error and enabling rapid adaptation to preference shifts.

</details>


### [15] [EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179)
*Sushant Mehta,Logan Ritchie,Suhaas Garre,Nick Heiner,Edwin Chen*

Main category: cs.AI

TL;DR: 在高质量企业模拟环境中训练AI智能体，其能力可泛化到训练分布之外，CoreCraft环境显著提升了模型在多个基准测试上的表现


<details>
  <summary>Details</summary>
Motivation: 研究AI智能体在真实企业环境中执行多步骤、领域特定工作的能力，探索训练环境质量对智能体能力泛化的影响

Method: 开发CoreCraft企业模拟环境（包含2500+实体、14种实体类型、23种工具），使用GRPO和自适应裁剪训练GLM 4.6模型

Result: 单轮训练后任务通过率从25.37%提升至36.76%，在多个OOD基准测试上均有显著提升：BFCL Parallel +4.5%，τ²-Bench Retail +7.4%，Toolathlon +6.8%

Conclusion: 环境质量、多样性和真实性是产生可泛化智能体能力的关键因素，任务中心的世界构建、专家制定的评分标准和真实企业工作流程是实现有效迁移学习的重要特性

Abstract: We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30\% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM~4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37\% to 36.76\% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5\% on BFCL Parallel, +7.4\% on $τ^2$-Bench Retail, and +6.8\% on Toolathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.

</details>


### [16] [Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage](https://arxiv.org/abs/2602.16192)
*Hiroaki Yamanaka,Daisuke Miyashita,Takashi Toi,Asuka Maki,Taiga Ikeda,Jun Deguchi*

Main category: cs.AI

TL;DR: 论文探讨了实现人工超智能所需的关键"记忆"设计概念，提出了不同于主流"提取后存储"范式的"存储后按需提取"等替代方法，强调保留原始经验以避免信息损失。


<details>
  <summary>Details</summary>
Motivation: 当前主流的"提取后存储"范式在提取有用信息时存在信息丢失风险，可能丢弃对不同任务有价值的潜在知识。为实现"用记忆提升世界"的使命，需要探索更有效的记忆设计方法。

Method: 提出了四种替代方法：1)"存储后按需提取"：保留原始经验，按需灵活应用；2)从大量概率性经验中发现深层洞察；3)通过共享存储经验提高经验收集效率；4)通过简单实验验证这些方法的有效性。

Result: 简单实验证实了这些替代方法的有效性，表明它们确实能够避免信息损失并提高经验利用效率。

Conclusion: 虽然这些方法直观上有效，但研究面临重大挑战。论文讨论了限制这些有前景方向研究的障碍，并提出了相应的研究课题来应对这些挑战。

Abstract: Driven by our mission of "uplifting the world with memory," this paper explores the design concept of "memory" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed "extract then store," involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the "store then on-demand extract" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.

</details>


### [17] [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246)
*Yun-Shiuan Chuang,Chaitanya Kulkarni,Alec Chiu,Avinash Thangali,Zijie Pan,Shivani Shekhar,Yirou Ge,Yixi Li,Uma Kona,Linsey Pang,Prakhar Mehrotra*

Main category: cs.AI

TL;DR: 提出Proxy State-Based Evaluation框架，使用LLM驱动的模拟来评估交互式LLM智能体，无需构建昂贵的确定性数据库，通过代理状态跟踪和LLM裁判实现可靠评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于确定性后端的智能体基准（如tau-bench、AppWorld）构建和迭代成本高昂，需要一种更实用、可扩展的评估方法，既能可靠比较模型，又能生成用于训练的在线策略数据。

Method: 提出代理状态评估框架：1）场景规范定义用户目标、事实、期望最终状态和行为；2）LLM状态跟踪器从完整交互轨迹推断结构化代理状态；3）LLM裁判验证目标完成度并检测工具/用户幻觉；4）支持用户角色敏感性分析。

Result: 基准产生稳定、能区分不同模型的排名；在线/离线策略数据能迁移到未见场景；精心设计的场景规范使模拟器幻觉率接近零；人类-LLM裁判一致性超过90%；支持敏感性分析。

Conclusion: 代理状态评估为工业级LLM智能体提供了实用、可扩展的评估替代方案，避免了构建昂贵确定性数据库的需求，同时保持可靠的自动化评估能力。

Abstract: Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluation without a deterministic database. Specifically, a scenario specifies the user goal, user/system facts, expected final state, and expected agent behavior, and an LLM state tracker infers a structured proxy state from the full interaction trace. LLM judges then verify goal completion and detect tool/user hallucinations against scenario constraints. Empirically, our benchmark produces stable, model-differentiating rankings across families and inference-time reasoning efforts, and its on-/off-policy rollouts provide supervision that transfers to unseen scenarios. Careful scenario specification yields near-zero simulator hallucination rates as supported by ablation studies. The framework also supports sensitivity analyses over user personas. Human-LLM judge agreement exceeds 90%, indicating reliable automated evaluation. Overall, proxy state-based evaluation offers a practical, scalable alternative to deterministic agentic benchmarks for industrial LLM agents.

</details>


### [18] [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301)
*Marissa A. Weis,Maciej Wołczyk,Rajai Nasser,Rif A. Saurous,Blaise Agüera y Arcas,João Sacramento,Alexander Meulemans*

Main category: cs.AI

TL;DR: 序列模型通过上下文学习实现多智能体合作，无需硬编码假设或显式时间尺度分离


<details>
  <summary>Details</summary>
Motivation: 解决自利智能体之间的合作问题是多智能体强化学习的基本挑战。现有方法依赖硬编码假设或严格的时间尺度分离，需要更自然的解决方案。

Method: 使用序列模型训练智能体对抗多样化的对手分布，自然诱导出上下文最佳响应策略，在快速时间尺度上作为学习算法运作。

Result: 发现先前工作中识别的合作机制（易受勒索驱动相互塑造）自然出现：上下文适应使智能体易受勒索，相互压力塑造对手的上下文学习动态，最终学习到合作行为。

Conclusion: 序列模型的标准分散强化学习结合对手多样性，为学习合作行为提供了可扩展的路径。

Abstract: Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between "naive learners" updating on fast timescales and "meta-learners" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.

</details>


### [19] [Verifiable Semantics for Agent-to-Agent Communication](https://arxiv.org/abs/2602.16424)
*Philipp Schoenegger,Matt Carlson,Chris Schneider,Chris Daly*

Main category: cs.AI

TL;DR: 提出基于刺激-意义模型的认证协议，通过测试智能体在可观测事件上的表现来认证术语，确保通信一致性，减少语义漂移


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统需要一致的通信，但缺乏验证智能体对术语理解是否一致的方法。自然语言可解释但易受语义漂移影响，学习协议高效但不透明

Method: 基于刺激-意义模型的认证协议：测试智能体在共享可观测事件上的表现，当经验分歧低于统计阈值时认证术语。采用核心保护推理机制，检测漂移的重新认证和恢复共享词汇的重新协商

Result: 在语义分歧程度不同的模拟中，核心保护将分歧减少72-96%。在微调语言模型的验证中，分歧减少51%

Conclusion: 该框架为可验证的智能体间通信提供了第一步，通过认证协议确保术语理解一致性，减少通信分歧

Abstract: Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms ("core-guarded reasoning") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.

</details>


### [20] [Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16435)
*Arun Vignesh Malarkkan,Wangyang Ying,Yanjie Fu*

Main category: cs.AI

TL;DR: CAFE框架将自动特征工程重构为因果引导的序列决策过程，通过因果发现和强化学习相结合，生成更鲁棒的特征表示，在分布偏移下表现更稳定。


<details>
  <summary>Details</summary>
Motivation: 现有自动特征工程方法依赖统计启发式，生成的特征在分布偏移下表现脆弱。需要结合因果结构来提高特征工程的鲁棒性和效率。

Method: 两阶段方法：第一阶段学习稀疏有向无环图获取软因果先验，将特征按因果影响分组；第二阶段使用级联多智能体深度Q学习架构选择因果组和变换操作，采用分层奖励塑造和因果组级探索策略。

Result: 在15个公共基准测试中，CAFE比强基线提升达7%，减少收敛所需回合数，在协变量偏移下性能下降减少约4倍，生成更紧凑的特征集和更稳定的后验归因。

Conclusion: 因果结构作为软归纳先验而非刚性约束，能显著提高自动特征工程的鲁棒性和效率，为分布偏移下的特征工程提供了新思路。

Abstract: Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.

</details>


### [21] [Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach](https://arxiv.org/abs/2602.16481)
*Zihao Li,Fabrizio Russo*

Main category: cs.AI

TL;DR: 该论文提出使用大型语言模型作为不完美专家，结合因果假设论证框架，从变量名称和描述中提取语义结构先验，并与条件独立性证据整合，实现最先进的因果发现性能。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现需要专家知识构建因果图，而统计方法主要依赖观测数据。本文旨在探索如何利用大型语言模型作为"不完美专家"，结合符号推理框架，将语义先验与统计证据有效整合。

Method: 采用因果假设论证框架，从大型语言模型中提取变量名称和描述的语义结构先验，与条件独立性证据相结合。提出评估协议以减轻记忆偏差对LLM因果发现评估的影响。

Result: 在标准基准测试和语义基础合成图上实现了最先进的性能。提出的评估协议有效缓解了记忆偏差问题。

Conclusion: 大型语言模型可作为有效的语义先验来源，与因果假设论证框架结合，能够显著提升因果发现性能，为整合领域知识与统计证据提供了新途径。

Abstract: Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.

</details>


### [22] [Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs](https://arxiv.org/abs/2602.16512)
*Felix Fricke,Simon Malberg,Georg Groh*

Main category: cs.AI

TL;DR: FoT是一个通用的基础框架，用于构建和优化动态推理方案，通过内置的超参数调优、提示优化、并行执行和智能缓存等功能，显著提升推理方案的性能、速度和成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有提示方案（如Chain of Thought、Tree of Thoughts等）存在两个主要问题：1）需要用户定义静态的、特定于问题的推理结构，缺乏对动态或未见问题类型的适应性；2）在超参数、提示、运行时间和提示成本方面往往未得到充分优化。

Method: 提出了Framework of Thoughts (FoT)，这是一个通用的基础框架，用于构建和优化动态推理方案。FoT内置了超参数调优、提示优化、并行执行和智能缓存等功能，能够解锁推理方案的潜在性能。

Result: 通过将三种流行方案（Tree of Thoughts、Graph of Thoughts和ProbTree）在FoT中实现，实证表明FoT能够实现显著更快的执行速度、降低成本，并通过优化获得更好的任务分数。

Conclusion: FoT是一个有效的通用框架，能够解决现有推理方案的适应性和优化问题，通过释放其潜在性能，为未来动态高效推理方案的发展提供了基础。

Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.

</details>


### [23] [Creating a digital poet](https://arxiv.org/abs/2602.16578)
*Vered Tohar,Tsahi Hayat,Amir Leshem*

Main category: cs.AI

TL;DR: 通过七个月的诗歌工作坊，研究人员使用大型语言模型通过上下文专家反馈塑造了一个数字诗人，该模型创作的诗集在盲测中与人类诗人作品难以区分，最终被商业出版社出版。


<details>
  <summary>Details</summary>
Motivation: 探索机器能否创作出优秀诗歌，这涉及艺术本质和价值的根本问题。研究旨在测试通过迭代反馈塑造AI诗人而不重新训练模型的可能性。

Method: 进行七个月的诗歌工作坊，通过迭代的上下文专家反馈塑造大型语言模型成为数字诗人。使用定量和定性分析评估模型发展出的独特风格和连贯作品集。最后进行盲测实验，让50名人文学生和毕业生判断6首诗（3首AI创作，3首知名诗人作品）的作者身份。

Result: 模型发展出独特风格和连贯作品集，创作了笔名和作者形象。盲测结果显示判断准确率接近随机水平：人类诗歌被识别为人类的概率为54%，AI诗歌被识别为AI的概率为52%，95%置信区间均包含50%。工作坊后，商业出版社出版了该模型创作的诗集。

Conclusion: 工作坊式提示方法能够支持长期创意塑造，更新了关于创造性和作者身份的辩论，表明AI可以创作出与人类作品难以区分的诗歌。

Abstract: Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.

</details>


### [24] [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653)
*Yangjie Xu,Lujun Li,Lama Sleem,Niccolo Gentile,Yewei Song,Yiqun Wang,Siming Ji,Wenbo Wu,Radu State*

Main category: cs.AI

TL;DR: Agent Skill框架能显著提升中等规模SLM（12B-30B参数）的性能，但小模型难以可靠选择技能，而80B参数的代码专用模型能达到闭源基线性能同时提升GPU效率。


<details>
  <summary>Details</summary>
Motivation: 研究Agent Skill范式是否能为小型语言模型（SLM）带来类似大型专有模型的性能提升，这在工业场景中很重要，因为数据安全和预算限制使得持续依赖公共API不可行，且SLM在高度定制化场景中泛化能力有限。

Method: 首先形式化定义了Agent Skill过程的数学定义，然后系统评估了不同规模的语言模型在多个用例中的表现，包括两个开源任务和一个真实世界的保险索赔数据集。

Result: 微小模型难以可靠选择技能；中等规模SLM（约12B-30B参数）从Agent Skill方法中获益显著；约80B参数的代码专用变体达到与闭源基线相当的性能，同时提高了GPU效率。

Conclusion: 研究全面细致地描述了Agent Skill框架的能力和限制，为在SLM中心环境中有效部署Agent Skills提供了可操作的见解。

Abstract: Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.

</details>


### [25] [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666)
*Stephan Rabanser,Sayash Kapoor,Peter Kirgis,Kangheng Liu,Saiteja Utpala,Arvind Narayanan*

Main category: cs.AI

TL;DR: 论文提出12个具体指标从一致性、鲁棒性、可预测性和安全性四个维度评估AI代理的可靠性，发现当前能力提升并未显著改善可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理评估主要依赖单一成功率指标，掩盖了关键的操作缺陷，无法反映代理在一致性、抗干扰性、可预测故障和错误严重性等方面的表现，需要更全面的可靠性评估框架。

Method: 基于安全关键工程理念，提出12个具体指标从四个维度分解代理可靠性：一致性（跨运行稳定性）、鲁棒性（抗扰动能力）、可预测性（故障模式可预测）、安全性（错误严重性有界）。在2个互补基准上评估14个代理模型。

Result: 评估发现近期AI能力提升仅带来可靠性方面的微小改进，暴露了代理在一致性、鲁棒性、可预测性和安全性方面的持续局限性。

Conclusion: 提出的12个可靠性指标补充了传统评估方法，提供了分析代理如何执行、退化和失败的工具，有助于更全面地理解和改进AI代理的实际表现。

Abstract: AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [26] [Cryptographic Applications of Twisted Goppa Codes](https://arxiv.org/abs/2602.16207)
*Harshdeep Singh,Anuj Kumar Bhagat,Ritumoni Sarma,Indivar Gupta*

Main category: cs.IT

TL;DR: 本文定义了多扭曲Goppa码作为多扭曲Reed-Solomon码对偶的子域子码，研究了其性质，提出了高效的解码算法，并证明了基于该码的Niederreiter公钥密码系统具有抗部分密钥恢复攻击的安全性。


<details>
  <summary>Details</summary>
Motivation: 传统的单扭曲Goppa码解码方法仅限于最后位置扭曲，限制了应用灵活性。本文旨在扩展多扭曲Goppa码的理论框架，开发更通用的解码算法，并探索其在公钥密码系统中的实际应用潜力。

Method: 将多扭曲Goppa码定义为多扭曲Reed-Solomon码对偶的子域子码；使用扩展欧几里得算法开发高效解码方法，可处理任意位置的单扭曲情况；通过构造拟循环多扭曲Goppa码来减小公钥尺寸。

Result: 证明了当MTG多项式次数为t时，在一定条件下最小距离至少为t+1；实现了可纠正⌊t/2⌋个错误的解码算法；证明了基于MTG码的Niederreiter PKC抗部分密钥恢复攻击；通过拟循环构造减小了公钥尺寸。

Conclusion: 多扭曲Goppa码具有优良的纠错性能和安全性，扩展欧几里得解码算法使其具有实际应用价值，基于该码的Niederreiter公钥密码系统既安全又高效，拟循环构造进一步优化了系统性能。

Abstract: This article defines multi-twisted Goppa (MTG) codes as subfield subcodes of duals of multi-twisted Reed-Solomon (MTRS) codes and examines their properties. We show that if $t$ is the degree of the MTG polynomial defining an MTG code, its minimum distance is at least $t + 1$ under certain conditions. Extending earlier methods limited to single twist at last position, we use the extended Euclidean algorithm to efficiently decode MTG codes with a single twist at any position, correcting up to $\left\lfloor \tfrac{t}{2} \right\rfloor$ errors. This decoding method highlights the practical potential of these codes within the Niederreiter public key cryptosystem (PKC). Furthermore, we establish that the Niederreiter PKC based on MTG codes is secure against partial key recovery attacks. Additionally, we also reduce the public key size by constructing quasi-cyclic MTG codes using a non-trivial automorphism group.

</details>


### [27] [Scalable Base Station Configuration via Bayesian Optimization with Block Coordinate Descent](https://arxiv.org/abs/2602.16378)
*Kakeru Takamori,Koya Sato*

Main category: cs.IT

TL;DR: 提出一种可扩展的贝叶斯优化框架，用于密集基站配置设计，通过块坐标下降法降低维度，显著提升优化性能


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化在密集基站配置设计中面临维度灾难问题，随着基站数量增加，优化性能严重下降，需要可扩展的解决方案

Method: 采用块坐标下降策略，将高维优化问题分解为低维子问题，依次优化单个基站参数，同时固定其他基站配置，降低每个优化步骤的有效维度

Result: 数值实验表明，在密集部署场景下，所提方法显著优于传统贝叶斯优化方法，展示了更好的可扩展性和优化性能

Conclusion: 通过块坐标下降策略降低维度，成功解决了贝叶斯优化在密集基站配置中的可扩展性问题，为大规模网络优化提供了有效解决方案

Abstract: This paper proposes a scalable Bayesian optimization (BO) framework for dense base-station (BS) configuration design. BO can find an optimal BS configuration by iterating parameter search, channel simulation, and probabilistic modeling of the objective function. However, its performance is severely affected by the curse of dimensionality, thereby reducing its scalability. To overcome this limitation, the proposed method sequentially optimizes per-BS parameters based on block coordinate descent while fixing the remaining BS configurations, thereby reducing the effective dimensionality of each optimization step. Numerical results demonstrate that the proposed approach significantly outperforms naive optimization in dense deployment scenarios.

</details>


### [28] [Bounds and Constructions of Codes for Ordered Composite DNA Sequences](https://arxiv.org/abs/2602.16406)
*Zuo Ye,Yuling Li,Zhaojun Lan,Gennian Ge*

Main category: cs.IT

TL;DR: 本文扩展了Dollma等人关于有序复合DNA序列编码的基础工作，从二进制扩展到一般q元字母表，研究了多种复合错误/删除信道模型下的纠错码，建立了码类等价关系、新的上界，并构造了多种具有高效编码器的近最优码。


<details>
  <summary>Details</summary>
Motivation: 先前工作主要关注二进制(q=2)情况下的有序复合DNA序列编码，本文旨在将研究扩展到一般q元字母表，并考虑更广泛的复合错误/删除信道模型，为DNA存储等应用提供更通用的编码理论支持。

Method: 1) 建立复合纠错码(CECC)和复合删除码(CDCC)家族间的等价关系，减少需要单独分析的参数集数量；2) 使用改进的球填充论证和概率方法推导CECC的新上界；3) 构造多种近最优的CDCC和CECC，并提供高效的系统编码器。

Result: 1) 建立了码类等价关系，简化了分析；2) 推导了覆盖所有参数(q,k,e_i,e)的通用上界；3) 构造了多种具有高效编码器的近最优码，包括(1,0,...,0)-CDCC、1-CDC和t-(1,...,1)-CDCC；4) 为二进制(1,0,...,0)-CECC设计了首个显式编解码算法并扩展到一般q。

Conclusion: 本文系统性地扩展了有序复合DNA序列编码理论，从二进制到一般q元字母表，建立了理论框架、上界和构造方法，为实际DNA存储应用提供了更全面的编码解决方案。

Abstract: This paper extends the foundational work of Dollma \emph{et al}. on codes for ordered composite DNA sequences. We consider the general setting with an alphabet of size $q$ and a resolution parameter $k$, moving beyond the binary ($q=2$) case primarily studied previously. We investigate error-correcting codes for substitution errors and deletion errors under several channel models, including $(e_1,\ldots,e_k)$-composite error/deletion, $e$-composite error/deletion, and the newly introduced $t$-$(e_1,\ldots,e_t)$-composite error/deletion model.
  We first establish equivalence relations among families of composite-error correcting codes (CECCs) and among families of composite-deletion correcting codes (CDCCs). This significantly reduces the number of distinct error-parameter sets that require separate analysis. We then derive novel and general upper bounds on the sizes of CECCs using refined sphere-packing arguments and probabilistic methods. These bounds together cover all values of parameters $q$, $k$, $(e_1,\ldots,e_k)$ and $e$. In contrast, previous bounds were only established for $q=2$ and limited choices of $k$, $(e_1,\ldots,e_k)$ and $e$. For CDCCs, we generalize a known non-asymptotic upper bound for $(1,0,\ldots,0)$-CDCCs and then provide a cleaner asymptotic bound.
  On the constructive side, for any $q\ge2$, we propose $(1,0,\ldots,0)$-CDCCs, $1$-CDCCs and $t$-$(1,\ldots,1)$-CDCCs with near-optimal redundancies. These codes have efficient and systematic encoders. For substitution errors, we design the first explicit encoding and decoding algorithms for the binary $(1,0,\ldots,0)$-CECC constructed by Dollma \emph{et al}, and extend the approach to general $q$. Furthermore, we give an improved construction of binary $1$-CECCs, a construction of nonbinary $1$-CECCs, and a construction of $t$-$(1,\ldots,1)$-CECCs. These constructions are also systematic.

</details>


### [29] [Enhanced Connectivity in Ambient Backscatter Communications via Fluid Antenna Readers](https://arxiv.org/abs/2602.16446)
*Masoud Kaveh,Farshad Rostami Ghadi,Riku Jantti,Kai-Kit Wong,F. Javier Lopez-Martinez*

Main category: cs.IT

TL;DR: 本文提出在环境反向散射通信系统中使用像素流体天线系统，通过测量驱动的端口选择和联合优化反向散射调制系数，显著提升系统性能，无需显式信道状态信息获取。


<details>
  <summary>Details</summary>
Motivation: 环境反向散射通信面临严重的双路径损耗和乘性衰落问题，而准确的信道状态信息获取由于反向散射信号微弱和设备资源有限而极具挑战性。传统方法难以有效解决这些问题。

Method: 在环境反向散射通信系统中，为阅读器配备像素流体天线系统，通过从紧凑孔径内的密集像素集中动态选择天线位置，利用测量驱动的端口选择实现空间分集，无需显式信道状态信息或多射频链。同时考虑反向散射设备的固有速率-能量权衡，在能量收集中性约束下联合优化反向散射调制系数。采用粒子群优化框架在优化-平均基础上联合确定流体天线系统端口选择和调制系数。

Result: 仿真结果表明，所提方案相比传统单天线阅读器显著提高了可达速率，在非完美观测、严格能量收集约束和不同像素间距下仍能保持性能增益。

Conclusion: 基于流体天线系统的环境反向散射通信方案通过测量驱动的空间分集和联合优化，有效克服了信道衰落和能量约束的挑战，为超低功耗通信提供了有前景的解决方案。

Abstract: Ambient backscatter communication (AmBC) enables ultra-low-power connectivity by allowing passive backscatter devices (BDs) to convey information through reflection of ambient signals. However, the cascaded AmBC channel suffers from severe double path loss and multiplicative fading, while accurate channel state information (CSI) acquisition is highly challenging due to the weak backscattered signal and the resource-limited nature of BDs. To address these challenges, this paper considers an AmBC system in which the reader is equipped with a pixel-based fluid antenna system (FAS). By dynamically selecting one antenna position from a dense set of pixels within a compact aperture, the FAS-enabled reader exploits spatial diversity through measurement-driven port selection, without requiring explicit CSI acquisition or multiple RF chains. The intrinsic rate-energy tradeoff at the BD is also incorporated by jointly optimizing the backscatter modulation coefficient under an energy harvesting (EH) neutrality constraint. To efficiently solve this problem, a particle swarm optimization (PSO)-based framework is developed to jointly determine the FAS port selection and modulation coefficient on an optimize-then-average (OTA) basis. Simulation results show that the proposed scheme significantly improves the achievable rate compared with conventional single-antenna readers, with gains preserved under imperfect observations, stringent EH constraints, and different pixel spacings.

</details>


### [30] [Continuous Fluid Antenna Sampling for Channel Estimation in Cell-Free Massive MIMO](https://arxiv.org/abs/2602.16459)
*Masoud Kaveh,Farshad Rostami Ghadi,Francisco Hernando-Gallego,Diego Martin,Riku Jantti,Kai-Kit Wong*

Main category: cs.IT

TL;DR: 本文为无小区大规模MIMO系统开发了连续流体天线框架，通过高斯过程回归进行信道估计，相比离散端口架构具有更低估计误差


<details>
  <summary>Details</summary>
Motivation: 传统离散端口天线架构在信道估计中存在性能限制，连续流体天线能提供更灵活的空间采样，有望提升无小区大规模MIMO系统的信道估计性能

Method: 将无线信道建模为空间相关高斯随机场，将信道估计表述为具有运动约束空间采样的高斯过程回归问题，推导LMMSE估计器和估计误差的闭式表达式

Result: 连续流体天线采样在任何有限导频预算下都能实现相等或更低的估计误差，对于非退化空间相关模型有严格改进，数值结果验证了性能增益

Conclusion: 连续流体天线框架在无小区大规模MIMO系统中具有信道估计优势，为未来天线设计提供了新方向

Abstract: In this letter, we develop a continuous fluid antenna (FA) framework for uplink channel estimation in cell-free massive multiple-input and multiple-output (CF-mMIMO) systems. By modeling the wireless channel as a spatially correlated Gaussian random field, channel estimation is formulated as a Gaussian process (GP) regression problem with motion-constrained spatial sampling. Closed-form expressions for the linear minimum mean squared error (LMMSE) estimator and the corresponding estimation error are derived. A fundamental comparison with discrete port-based architectures is established under identical position constraints, showing that continuous FA sampling achieves equal or lower estimation error for any finite pilot budget, with strict improvement for non-degenerate spatial correlation models. Numerical results validate the analysis and show the performance gains of continuous FA sampling over discrete baselines.

</details>


### [31] [Spectral Conditions for the Ingleton Inequality](https://arxiv.org/abs/2602.16536)
*Rostislav Matveev,Andrei Romashchenko*

Main category: cs.IT

TL;DR: 该论文研究了Ingleton不等式在信息论中的违反程度问题，发现对于一类特定的联合分布随机变量(X,Y)，即使互信息远不可提取，Ingleton不等式也仅存在微小加性误差。


<details>
  <summary>Details</summary>
Motivation: Ingleton不等式是经典的线性信息不等式，对可表示拟阵成立但对熵向量并非普遍有效。理解该不等式能被违反的程度是信息论中长期存在的问题。

Method: 考虑在联合支撑上均匀分布的随机变量对(X,Y)，其关联的双正则二分图是扩展图。结合扩展图混合引理和有限集划分技术，对所有与(X,Y)联合分布的辅助随机变量A和B，建立了Ingleton量下界。

Result: 对于这类扩展图结构的随机变量对，即使互信息远不可提取，Ingleton不等式也仅存在微小加性误差。这与常见直觉相反：强不可提取的互信息并不会导致Ingleton不等式的大幅违反。

Conclusion: 该研究揭示了Ingleton不等式违反程度与互信息可提取性之间的非直观关系，为理解信息不等式在特定结构下的行为提供了新见解。

Abstract: The Ingleton inequality is a classical linear information inequality that holds for representable matroids but fails to be universally valid for entropic vectors. Understanding the extent to which this inequality can be violated has been a longstanding problem in information theory. In this paper, we show that for a broad class
  of jointly distributed random variables $(X,Y)$ the Ingleton inequality holds up to a small additive error, even even though the mutual information between $X$ and $Y$ is far from being extractable. Contrary to common intuition, strongly non-extractable mutual information does not lead to large violations of the Ingleton inequality in this setting. More precisely, we consider pairs $(X,Y)$ that are uniformly distributed on their joint support and whose associated biregular bipartite graph is an expander. For all auxiliary random variables $A$ and $B$ jointly distributed with $(X,Y)$, we establish a lower bound on the Ingleton quantity $I(X:Y | A) + I(X:Y | B) + I(A:B) - I(X:Y)$ in terms of the spectral parameters of the underlying graph. Our proof combines the expander mixing lemma with a partitioning technique for finite sets.

</details>


### [32] [The Role of Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems](https://arxiv.org/abs/2602.16700)
*Shreya Meel,Sennur Ulukus*

Main category: cs.IT

TL;DR: 研究图复制数据库系统中的对称私有信息检索，分析两种公共随机性分布下的SPIR容量和最小公共随机性需求


<details>
  <summary>Details</summary>
Motivation: 研究图复制数据库系统中的对称私有信息检索问题，其中每个消息恰好复制在两个服务器上，目标是保护用户隐私（不泄露消息索引）和数据库隐私（不学习额外信息）

Method: 研究两种公共随机性分布：1）图复制公共随机性（每个共享消息的服务器对分配独立随机变量）；2）完全复制公共随机性（所有服务器分配相同随机变量集）。推导SPIR容量下界，对路径图和正则图给出匹配上界

Result: 在图复制公共随机性设置中，推导了SPIR容量的一般下界，对路径图和正则图证明该下界是紧的；最小公共随机性大小等于消息大小。在完全复制公共随机性设置中，SPIR容量优于第一种限制性设置

Conclusion: 图复制数据库系统的SPIR容量取决于公共随机性的分布方式，完全复制公共随机性能够提供更好的SPIR性能，为实际系统设计提供了理论指导

Abstract: In symmetric private information retrieval (SPIR), a user communicates with multiple servers to retrieve from them a message in a database, while not revealing the message index to any individual server (user privacy), and learning no additional information about the database (database privacy). We study the problem of SPIR on graph-replicated database systems, where each node of the graph represents a server and each link represents a message. Each message is replicated at exactly two servers; those at which the link representing the message is incident. To ensure database privacy, the servers share a set of common randomness, independent of the database and the user's desired message index. We study two cases of common randomness distribution to the servers: i) graph-replicated common randomness, and ii) fully-replicated common randomness. Given a graph-replicated database system, in i), we assign one randomness variable independently to every pair of servers sharing a message, while in ii), we assign an identical set of randomness variable to all servers, irrespective of the underlying graph. In both settings, our goal is to characterize the SPIR capacity, i.e., the maximum number of desired message symbols retrieved per downloaded symbol, and quantify the minimum amount of common randomness required to achieve the capacity. To this goal, in setting i), we derive a general lower bound on the SPIR capacity, and show it to be tight for path and regular graphs through a matching converse. Moreover, we establish that the minimum size of common randomness required for SPIR is equal to the message size. In setting ii), the SPIR capacity improves over the first, more restrictive setting. We show this through capacity lower bounds for a class of graphs, by constructing SPIR schemes from PIR schemes.

</details>
