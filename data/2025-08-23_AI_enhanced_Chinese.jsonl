{"id": "2508.15185", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15185", "abs": "https://arxiv.org/abs/2508.15185", "authors": ["Dingzhu Wen", "Sijing Xie", "Xiaowen Cao", "Yuanhao Cui", "Jie Xu", "Yuanming Shi", "Shuguang Cui"], "title": "Integrated Sensing, Communication, and Computation for Over-the-Air Federated Edge Learning", "comment": "The paper has been accepted for publication in IEEE Transactions on\n  Wireless Communications", "summary": "This paper studies an over-the-air federated edge learning (Air-FEEL) system\nwith integrated sensing, communication, and computation (ISCC), in which one\nedge server coordinates multiple edge devices to wirelessly sense the objects\nand use the sensing data to collaboratively train a machine learning model for\nrecognition tasks. In this system, over-the-air computation (AirComp) is\nemployed to enable one-shot model aggregation from edge devices. Under this\nsetup, we analyze the convergence behavior of the ISCC-enabled Air-FEEL in\nterms of the loss function degradation, by particularly taking into account the\nwireless sensing noise during the training data acquisition and the AirComp\ndistortions during the over-the-air model aggregation. The result theoretically\nshows that sensing, communication, and computation compete for network\nresources to jointly decide the convergence rate. Based on the analysis, we\ndesign the ISCC parameters under the target of maximizing the loss function\ndegradation while ensuring the latency and energy budgets in each round. The\nchallenge lies on the tightly coupled processes of sensing, communication, and\ncomputation among different devices. To tackle the challenge, we derive a\nlow-complexity ISCC algorithm by alternately optimizing the batch size control\nand the network resource allocation. It is found that for each device, less\nsensing power should be consumed if a larger batch of data samples is obtained\nand vice versa. Besides, with a given batch size, the optimal computation speed\nof one device is the minimum one that satisfies the latency constraint.\nNumerical results based on a human motion recognition task verify the\ntheoretical convergence analysis and show that the proposed ISCC algorithm well\ncoordinates the batch size control and resource allocation among sensing,\ncommunication, and computation to enhance the learning performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u96c6\u6210\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u7a7a\u4e2d\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u65e0\u7ebf\u611f\u77e5\u566a\u58f0\u548c\u7a7a\u4e2d\u8ba1\u7b97\u5931\u771f\u5bf9\u6536\u655b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4f4e\u590d\u6742\u5ea6\u7684ISCC\u7b97\u6cd5\u6765\u534f\u8c03\u6279\u5904\u7406\u5927\u5c0f\u63a7\u5236\u548c\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u8ba1\u7b97\u548c\u7269\u8054\u7f51\u7684\u53d1\u5c55\uff0c\u9700\u8981\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u3002\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u901a\u4fe1\u74f6\u9888\uff0c\u800c\u96c6\u6210\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u4e00\u4f53\u5316\u8bbe\u8ba1\u53ef\u4ee5\u63d0\u5347\u7cfb\u7edf\u6548\u7387\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u65e0\u7ebf\u611f\u77e5\u566a\u58f0\u548c\u7a7a\u4e2d\u8ba1\u7b97\u5931\u771f\u5bf9\u6536\u655b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u7a7a\u4e2d\u8ba1\u7b97\u6280\u672f\u5b9e\u73b0\u6a21\u578b\u7684\u4e00\u53d1\u805a\u5408\uff0c\u5206\u6790ISCC-enabled Air-FEEL\u7cfb\u7edf\u7684\u6536\u655b\u884c\u4e3a\uff0c\u8003\u8651\u65e0\u7ebf\u611f\u77e5\u566a\u58f0\u548c\u7a7a\u4e2d\u8ba1\u7b97\u5931\u771f\u3002\u8bbe\u8ba1ISCC\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6279\u5904\u7406\u5927\u5c0f\u63a7\u5236\u548c\u7f51\u7edc\u8d44\u6e90\u5206\u914d\u6765\u89e3\u51b3\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u8026\u5408\u95ee\u9898\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7ade\u4e89\u7f51\u7edc\u8d44\u6e90\u5171\u540c\u51b3\u5b9a\u6536\u655b\u901f\u7387\u3002\u63d0\u51fa\u7684\u4f4e\u590d\u6742\u5ea6ISCC\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u534f\u8c03\u6279\u5904\u7406\u5927\u5c0f\u63a7\u5236\u548c\u8d44\u6e90\u5206\u914d\uff0c\u6570\u503c\u5b9e\u9a8c\u57fa\u4e8e\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b\u4efb\u52a1\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u548c\u7b97\u6cd5\u6027\u80fd\u3002", "conclusion": "ISCC-enabled Air-FEEL\u7cfb\u7edf\u901a\u8fc7\u534f\u8c03\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u80fd\u591f\u5728\u6ee1\u8db3\u5ef6\u8fdf\u548c\u80fd\u91cf\u9884\u7b97\u7684\u540c\u65f6\u6700\u5927\u5316\u5b66\u4e60\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\u8bbe\u5907\u5728\u83b7\u5f97\u66f4\u5927\u6279\u6b21\u6570\u636e\u65f6\u5e94\u6d88\u8017\u66f4\u5c11\u7684\u611f\u77e5\u529f\u7387\uff0c\u53cd\u4e4b\u4ea6\u7136\uff0c\u4e14\u6700\u4f18\u8ba1\u7b97\u901f\u5ea6\u662f\u6ee1\u8db3\u5ef6\u8fdf\u7ea6\u675f\u7684\u6700\u5c0f\u503c\u3002"}}
{"id": "2508.15058", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15058", "abs": "https://arxiv.org/abs/2508.15058", "authors": ["Kaiqiang Lin", "Mohamed-Slim Alouini"], "title": "Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer", "comment": "8 pages, 4 figures, 2 tables, submitted to IEEE WCM", "summary": "Wireless underground sensor networks (WUSNs), which enable real-time sensing\nand monitoring of underground resources by underground devices (UDs), hold\ngreat promise for delivering substantial social and economic benefits across\nvarious verticals. However, due to the harsh subterranean environment, scarce\nnetwork resources, and restricted communication coverage, WUSNs face\nsignificant challenges in supporting sustainable massive machine-type\ncommunications (mMTC), particularly in remote, disaster-stricken, and\nhard-to-reach areas. To complement this, we conceptualize in this study a novel\nspace-air-ground-underground integrated network (SAGUIN) architecture that\nseamlessly incorporates satellite systems, aerial platforms, terrestrial\nnetworks, and underground communications. On this basis, we integrate LoRaWAN\nand wireless energy transfer (WET) technologies into SAGUIN to enable\nsustainable subterranean mMTC. We begin by reviewing the relevant technical\nbackground and presenting the architecture and implementation challenges of\nSAGUIN. Then, we employ simulations to model a remote underground pipeline\nmonitoring scenario to evaluate the feasibility and performance of SAGUIN based\non LoRaWAN and WET technologies, focusing on the effects of parameters such as\nunderground conditions, time allocation, LoRaWAN spread factor (SF)\nconfigurations, reporting periods, and harvested energy levels. Our results\nevidence that the proposed SAGUIN system, when combined with the derived time\nallocation strategy and an appropriate SF, can effectively extend the\noperational lifetime of UDs, thereby facilitating sustainable subterranean\nmMTC. Finally, we pinpoint key challenges and future research directions for\nSAGUIN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a7a\u5929-\u7a7a\u4e2d-\u5730\u9762-\u5730\u4e0b\u4e00\u4f53\u5316\u7f51\u7edc(SAGUIN)\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408LoRaWAN\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\uff0c\u89e3\u51b3\u5730\u4e0b\u4f20\u611f\u5668\u7f51\u7edc\u5728\u9065\u8fdc\u548c\u707e\u533a\u73af\u5883\u4e0b\u7684\u6301\u7eed\u6027\u95ee\u9898\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u5730\u4e0b\u5927\u89c4\u6a21\u673a\u5668\u7c7b\u901a\u4fe1\u3002", "motivation": "\u5730\u4e0b\u4f20\u611f\u5668\u7f51\u7edc(WUSNs)\u5728\u9065\u8fdc\u3001\u707e\u533a\u548c\u96be\u4ee5\u5230\u8fbe\u7684\u5730\u533a\u9762\u4e34\u7740\u4e25\u5cfb\u7684\u6311\u6218\uff0c\u5305\u62ec\u4e25\u5cfb\u7684\u5730\u4e0b\u73af\u5883\u3001\u7f55\u89c1\u7684\u7f51\u7edc\u8d44\u6e90\u548c\u53d7\u9650\u7684\u901a\u4fe1\u8986\u76d6\u8303\u56f4\uff0c\u5f71\u54cd\u4e86\u652f\u6301\u53ef\u6301\u7eed\u7684\u5927\u89c4\u6a21\u673a\u5668\u7c7b\u901a\u4fe1(mMTC)\u3002", "method": "\u63d0\u51fa\u7a7a\u5929-\u7a7a\u4e2d-\u5730\u9762-\u5730\u4e0b\u4e00\u4f53\u5316\u7f51\u7edc(SAGUIN)\u67b6\u6784\uff0c\u5c06\u536b\u661f\u7cfb\u7edf\u3001\u7a7a\u4e2d\u5e73\u53f0\u3001\u5730\u9762\u7f51\u7edc\u548c\u5730\u4e0b\u901a\u4fe1\u65e0\u7f1d\u6574\u5408\u3002\u91c7\u7528LoRaWAN\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93(WET)\u6280\u672f\uff0c\u901a\u8fc7\u6a21\u62df\u8fdc\u7a0b\u5730\u4e0b\u7ba1\u9053\u76d1\u6d4b\u573a\u666f\u6765\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\uff0c\u5206\u6790\u5730\u4e0b\u6761\u4ef6\u3001\u65f6\u95f4\u5206\u914d\u3001LoRaWAN\u6269\u5c4f\u56e0\u5b50\u914d\u7f6e\u3001\u62a5\u544a\u5468\u671f\u548c\u6536\u96c6\u80fd\u91cf\u7b49\u53c2\u6570\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8bc1\u660e\uff0c\u63d0\u51fa\u7684SAGUIN\u7cfb\u7edf\u7ed3\u5408\u6d3e\u751f\u7684\u65f6\u95f4\u5206\u914d\u7b56\u7565\u548c\u9002\u5f53\u7684\u6269\u5c4f\u56e0\u5b50\uff0c\u53ef\u4ee5\u6709\u6548\u5ef6\u957f\u5730\u4e0b\u8bbe\u5907\u7684\u8fd0\u884c\u5bff\u547d\uff0c\u4ece\u800c\u652f\u6301\u53ef\u6301\u7eed\u7684\u5730\u4e0b\u5927\u89c4\u6a21\u673a\u5668\u7c7b\u901a\u4fe1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684SAGUIN\u67b6\u6784\u4e3a\u5730\u4e0b\u4f20\u611f\u5668\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u7f51\u7edc\u6574\u5408\u548c\u80fd\u91cf\u6536\u96c6\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9065\u8fdc\u707e\u533a\u73af\u5883\u4e0b\u7684\u6301\u7eed\u6027\u95ee\u9898\uff0c\u4e3a\u5730\u4e0b\u8d44\u6e90\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6491\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u8be5\u9886\u57df\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.15277", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15277", "abs": "https://arxiv.org/abs/2508.15277", "authors": ["Ping Zhang", "Kai Niu", "Yiming Liu", "Zijian Liang", "Nan Ma", "Xiaodong Xu", "Wenjun Xu", "Mengying Sun", "Yinqiu Liu", "Xiaoyun Wang", "Ruichen Zhang"], "title": "Way to Build Native AI-driven 6G Air Interface: Principles, Roadmap, and Outlook", "comment": "14 pages, 7 figures", "summary": "Artificial intelligence (AI) is expected to serve as a foundational\ncapability across the entire lifecycle of 6G networks, spanning design,\ndeployment, and operation. This article proposes a native AI-driven air\ninterface architecture built around two core characteristics: compression and\nadaptation. On one hand, compression enables the system to understand and\nextract essential semantic information from the source data, focusing on task\nrelevance rather than symbol-level accuracy. On the other hand, adaptation\nallows the air interface to dynamically transmit semantic information across\ndiverse tasks, data types, and channel conditions, ensuring scalability and\nrobustness. This article first introduces the native AI-driven air interface\narchitecture, then discusses representative enabling methodologies, followed by\na case study on semantic communication in 6G non-terrestrial networks. Finally,\nit presents a forward-looking discussion on the future of native AI in 6G,\noutlining key challenges and research opportunities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u539f\u751fAI\u9a71\u52a8\u76846G\u7a7a\u53e3\u63a5\u53e3\u67b6\u6784\uff0c\u901a\u8fc7\u538b\u7f29\u548c\u9002\u5e94\u4e24\u5927\u6838\u5fc3\u7279\u6027\uff0c\u5b9e\u73b0\u4efb\u52a1\u76f8\u5173\u7684\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\uff0c\u786e\u4fdd\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5065\u6027\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u9700\u8981\u57286G\u7f51\u7edc\u7684\u6574\u4e2a\u751f\u547d\u5468\u671f\u4e2d\u53d1\u6325\u57fa\u7840\u80fd\u529b\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u7a7a\u53e3\u63a5\u53e3\u5c42\u9762\u5bf9\u4f20\u7edf\u7684\u7b26\u53f7\u7ea7\u4f20\u8f93\u65b9\u5f0f\u8fdb\u884c\u91cd\u6784\u548c\u6539\u8fdb\u3002", "method": "\u6784\u5efa\u4ee5\u538b\u7f29\u548c\u9002\u5e94\u4e3a\u6838\u5fc3\u7684\u539f\u751fAI\u9a71\u52a8\u7a7a\u53e3\u63a5\u53e3\u67b6\u6784\uff1a\u538b\u7f29\u7528\u4e8e\u7406\u89e3\u548c\u63d0\u53d6\u6e90\u6570\u636e\u7684\u6838\u5fc3\u8bed\u4e49\u4fe1\u606f\uff1b\u9002\u5e94\u7528\u4e8e\u52a8\u6001\u4f20\u8f93\u8bed\u4e49\u4fe1\u606f\uff0c\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u3001\u6570\u636e\u7c7b\u578b\u548c\u4fe1\u9053\u6761\u4ef6\u3002", "result": "\u901a\u8fc7\u4ee3\u8868\u6027\u65b9\u6cd5\u8bba\u8bc1\u548c6G\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u7684\u8bed\u4e49\u901a\u4fe1\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u8be5\u67b6\u6784\u7684\u53ef\u884c\u6027\u548c\u6548\u679c\u3002", "conclusion": "\u539f\u751fAI\u5c06\u57286G\u7f51\u7edc\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u76f8\u5173\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a6G\u7f51\u7edc\u7684AI\u5316\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2508.15087", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.15087", "abs": "https://arxiv.org/abs/2508.15087", "authors": ["Jashanjot Singh Sidhu", "Jorge Ignacio Sandoval", "Abdelhak Bentaleb", "Sandra Cespedes"], "title": "From 5G RAN Queue Dynamics to Playback: A Performance Analysis for QUIC Video Streaming", "comment": null, "summary": "The rapid adoption of QUIC as a transport protocol has transformed content\ndelivery by reducing latency, enhancing congestion control (CC), and enabling\nmore efficient multiplexing. With the advent of 5G networks, which support\nultra-low latency and high bandwidth, streaming high-resolution video at 4K and\nbeyond has become increasingly viable. However, optimizing Quality of\nExperience (QoE) in mobile networks remains challenging due to the complex\ninteractions among Adaptive Bit Rate (ABR) schemes at the application layer, CC\nalgorithms at the transport layer, and Radio Link Control (RLC) queuing at the\nlink layer in the 5G network. While prior studies have largely examined these\ncomponents in isolation, this work presents a comprehensive analysis of the\nimpact of modern active queue management (AQM) strategies, such as RED and L4S,\non video streaming over diverse QUIC implementations--focusing particularly on\ntheir interaction with the RLC buffer in 5G environments and the interplay\nbetween CC algorithms and ABR schemes. Our findings demonstrate that the\neffectiveness of AQM strategies in improving video streaming QoE is\nintrinsically linked to their dynamic interaction with QUIC implementations, CC\nalgorithms and ABR schemes-highlighting that isolated optimizations are\ninsufficient. This intricate interdependence necessitates holistic, cross-layer\nadaptive mechanisms capable of real-time coordination between network,\ntransport and application layers, which are crucial for fully leveraging the\ncapabilities of 5G networks to deliver robust, adaptive, and high-quality video\nstreaming.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u57285G\u7f51\u7edc\u4e2d\uff0c\u73b0\u4ee3\u4e3b\u52a8\u961f\u5217\u7ba1\u7406\u7b56\u7565\uff08RED\u548cL4S\uff09\u5bf9QUIC\u534f\u8bae\u4e0a\u89c6\u9891\u6d41\u64ad\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u4ecb\u8d28\u63a7\u5236\u7b97\u6cd5\u3001\u9002\u914d\u6027\u7801\u7387\u8c03\u6574\u548c\u65e0\u7ebf\u94fe\u8def\u63a7\u5236\u4e4b\u95f4\u7684\u8de8\u5c42\u534f\u540c\u4f18\u5316\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740QUIC\u534f\u8bae\u7684\u5feb\u901f\u91c7\u7528\u548c5G\u7f51\u7edc\u7684\u666e\u53ca\uff0c\u9ad8\u6e05\u89c6\u9891\u6d41\u64ad\u6210\u4e3a\u53ef\u80fd\uff0c\u4f46\u5728\u79fb\u52a8\u7f51\u7edc\u4e2d\u4f18\u5316\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\u4ecd\u9762\u4e34\u6311\u6218\u3002\u4e4b\u524d\u7684\u7814\u7a76\u591a\u72ec\u7acb\u5206\u6790\u5404\u4e2a\u5c42\u9762\uff0c\u672c\u6587\u901a\u8fc7\u5168\u9762\u5206\u6790\u73b0\u4ee3AQM\u7b56\u7565\u57285G\u73af\u5883\u4e0b\u4e0eQUIC\u5b9e\u73b0\u3001\u4ecb\u8d28\u63a7\u5236\u7b97\u6cd5\u548cABR\u65b9\u6848\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u63a2\u8ba8\u8de8\u5c42\u534f\u540c\u4f18\u5316\u7684\u5fc5\u8981\u6027\u3002", "method": "\u8fdb\u884c\u7efc\u5408\u6027\u5206\u6790\uff0c\u7814\u7a76\u73b0\u4ee3\u4e3b\u52a8\u961f\u5217\u7ba1\u7406\u7b56\u7565\uff08\u5982RED\u548cL4S\uff09\u5728\u591a\u79cdQUIC\u5b9e\u73b9\u4e2d\u5bf9\u89c6\u9891\u6d41\u64ad\u7684\u5f71\u54cd\uff0c\u91cd\u70b9\u5173\u6ce8\u5b83\u4eec\u4e0e5G\u7f51\u7edc\u4e2dRLC\u7f13\u51b2\u533a\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u4ecb\u8d28\u63a7\u5236\u7b97\u6cd5\u4e0e\u9002\u914d\u6027\u7801\u7387\u8c03\u6574\u65b9\u6848\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0AQM\u7b56\u7565\u5728\u6539\u5584\u89c6\u9891\u6d41\u64ad\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\u65b9\u9762\u7684\u6548\u679c\u4e0e\u5b83\u4eec\u4e0eQUIC\u5b9e\u73b0\u3001\u4ecb\u8d28\u63a7\u5236\u7b97\u6cd5\u548cABR\u65b9\u6848\u7684\u52a8\u6001\u4ea4\u4e92\u5bc6\u5207\u76f8\u5173\uff0c\u8bc1\u660e\u5355\u72ec\u5c42\u9762\u7684\u4f18\u5316\u4e0d\u8db3\u4ee5\u5b8c\u5168\u53d1\u63255G\u7f51\u7edc\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u79cd\u590d\u6742\u7684\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\u5fc5\u987b\u901a\u8fc7\u6574\u4f53\u6027\u7684\u8de8\u5c42\u9002\u5e94\u673a\u5236\u6765\u5904\u7406\uff0c\u8fd9\u4e9b\u673a\u5236\u80fd\u591f\u5b9e\u73b0\u7f51\u7edc\u3001\u4f20\u8f93\u548c\u5e94\u7528\u5c42\u4e4b\u95f4\u7684\u5b9e\u65f6\u534f\u8c03\uff0c\u5bf9\u4e8e\u5145\u5206\u5229\u75285G\u7f51\u7edc\u80fd\u529b\u6765\u63d0\u4f9b\u7a33\u5065\u3001\u9002\u5e94\u6027\u5f3a\u548c\u9ad8\u8d28\u91cf\u7684\u89c6\u9891\u6d41\u64ad\u670d\u52a1\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.15325", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15325", "abs": "https://arxiv.org/abs/2508.15325", "authors": ["Bingsheng Shen", "Zhengchun Zhou", "Yang Yang", "Pingzhi Fan"], "title": "Some Optimal and Near Optimal Doppler Resilient Complementary Sequence Sets", "comment": null, "summary": "Sequences with excellent ambiguity functions are very useful in radar\ndetection and modern mobile communications. Doppler resilient complementary\nsequence (DRCS) is a new type of sequence proposed recently, which can achieve\nlower ambiguity function sidelobes by summing the ambiguity functions of\nsubsequences. In this paper, we introduce some new constructions of DRCS sets\n(DRCSSs) based on one-coincidence frequency-hopping sequence sets (OC-FHSSs),\nalmost difference sets (ADSs), some specific sequences, etc. Critically, the\nproposed DRCSSs are optimal or near optimal.", "AI": {"tldr": "\u57fa\u4e8e\u8df3\u9891\u5e8f\u5217\u96c6\u548c\u5dee\u96c6\u7b49\u6570\u5b66\u5de5\u5177\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\u6784\u9020\u65b9\u6cd5\uff0c\u83b7\u5f97\u4e86\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd", "motivation": "\u5177\u6709\u826f\u597d\u6a21\u7cca\u51fd\u6570\u7684\u5e8f\u5217\u5728\u96f7\u8fbe\u68c0\u6d4b\u548c\u73b0\u4ee3\u79fb\u52a8\u901a\u4fe1\u4e2d\u975e\u5e38\u6709\u7528\uff0c\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u80fd\u591f\u901a\u8fc7\u5b50\u5e8f\u5217\u6a21\u7cca\u51fd\u6570\u6c42\u548c\u5b9e\u73b0\u66f4\u4f4e\u7684\u65c1\u74e3", "method": "\u57fa\u4e8e\u5355\u91cd\u5408\u8df3\u9891\u5e8f\u5217\u96c6(OC-FHSS)\u3001\u51e0\u4e4e\u5dee\u96c6(ADS)\u548c\u7279\u5b9a\u5e8f\u5217\u7b49\u6570\u5b66\u5de5\u5177\uff0c\u63d0\u51fa\u4e86\u65b0\u7684DRCSS\u6784\u9020\u65b9\u6cd5", "result": "\u6240\u63d0\u51fa\u7684\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\u8fbe\u5230\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u6027\u80fd", "conclusion": "\u65b0\u6784\u9020\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u6027\u80fd\u4f18\u5f02\u7684\u591a\u666e\u52d2\u5f39\u6027\u4e92\u8865\u5e8f\u5217\u96c6\uff0c\u5728\u96f7\u8fbe\u548c\u901a\u4fe1\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c"}}
{"id": "2508.15268", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.15268", "abs": "https://arxiv.org/abs/2508.15268", "authors": ["Gaosheng Zhao", "Dong In Kim"], "title": "Toward Autonomous Digital Populations for Communication-Sensing-Computation Ecosystem", "comment": null, "summary": "Future communication networks are expected to achieve deep integration of\ncommunication, sensing, and computation, forming a tightly coupled and\nautonomously operating infrastructure system. However, current reliance on\ncentralized control, static design, and human intervention continues to\nconstrain the multidimensional evolution of network functions and applications,\nlimiting adaptability and resilience in large-scale, layered, and complex\nenvironments. To address these challenges, this paper proposes a\nnature-inspired architectural framework that leverages digital twin technology\nto organize connected devices at the edge into functional digital populations,\nwhile enabling the emergence of an evolvable digital ecosystem through\nmulti-population integration at the cloud. We believe that this framework,\nwhich combines engineering methodologies with sociotechnical insights, lays the\ntheoretical foundation for building next-generation communication networks with\ndynamic coordination, distributed decision-making, continuous adaptation, and\nevolutionary capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u53d7\u81ea\u7136\u542f\u53d1\u7684\u6570\u5b57\u53cc\u751f\u67b6\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8fb9\u7f18\u6784\u5efa\u529f\u80fd\u6027\u6570\u5b57\u7fa4\u4f53\u548c\u5728\u4e91\u7aef\u5b9e\u73b0\u591a\u7fa4\u4f53\u6574\u5408\uff0c\u4ee5\u652f\u6301\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u7684\u52a8\u6001\u534f\u8c03\u3001\u5206\u5e03\u5f0f\u51b3\u7b56\u3001\u6301\u7eed\u9002\u5e94\u548c\u8fdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u901a\u4fe1\u7f51\u7edc\u4f9d\u8d56\u4e2d\u592e\u63a7\u5236\u3001\u9759\u6001\u8bbe\u8ba1\u548c\u4eba\u5de5\u5e72\u9884\uff0c\u7ea6\u675f\u4e86\u7f51\u7edc\u529f\u80fd\u7684\u591a\u7ef4\u53d1\u5c55\u548c\u5728\u5927\u89c4\u6a21\u3001\u5c42\u51b2\u590d\u6742\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u4e0e\u5f39\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53d7\u81ea\u7136\u542f\u53d1\u7684\u67b6\u6784\u6846\u67b6\uff0c\u5229\u7528\u6570\u5b57\u53cc\u751f\u6280\u672f\u5c06\u8fb9\u7f18\u8fde\u63a5\u8bbe\u5907\u7ec4\u7ec7\u6210\u529f\u80fd\u6027\u6570\u5b57\u7fa4\u4f53\uff0c\u5e76\u901a\u8fc7\u4e91\u7aef\u591a\u7fa4\u4f53\u6574\u5408\u5b9e\u73b0\u53ef\u8fdb\u5316\u7684\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u3002", "result": "\u8be5\u6846\u67b6\u7ed3\u5408\u5de5\u7a0b\u65b9\u6cd5\u8bba\u4e0e\u793e\u4f1a\u6280\u672f\u89c6\u89d2\uff0c\u4e3a\u6784\u5efa\u5177\u6709\u52a8\u6001\u534f\u8c03\u3001\u5206\u5e03\u5f0f\u51b3\u7b56\u3001\u6301\u7eed\u9002\u5e94\u548c\u8fdb\u5316\u80fd\u529b\u7684\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7f51\u7edc\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u81ea\u7136\u53d7\u542f\u7684\u6570\u5b57\u53cc\u751f\u67b6\u6784\u6846\u67b6\u6709\u671b\u89e3\u51b3\u5f53\u524d\u901a\u4fe1\u7f51\u7edc\u5728\u96c6\u4e2d\u63a7\u5236\u3001\u9759\u6001\u8bbe\u8ba1\u65b9\u9762\u7684\u9650\u5236\uff0c\u63a8\u52a8\u901a\u4fe1\u3001\u611f\u77e5\u548c\u8ba1\u7b97\u7684\u6df1\u5ea6\u878d\u5408\uff0c\u6784\u5efa\u66f4\u52a0\u81ea\u4e3b\u8fd0\u884c\u3001\u9002\u5e94\u6027\u5f3a\u7684\u672a\u6765\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2508.15639", "categories": ["cs.IT", "eess.SP", "math.IT", "94A14", "E.4"], "pdf": "https://arxiv.org/pdf/2508.15639", "abs": "https://arxiv.org/abs/2508.15639", "authors": ["Eito Kurihara", "Hideki Ochiai"], "title": "High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering", "comment": "13 pages, 13 figures", "summary": "We address a design of high-capacity and low-peak-to-average power ratio\n(PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on\nbit-interleaved coded modulation (BICM) utilizing non-equiprobable and\nnon-uniform (NENU) constellations as well as clipping and filtering (CAF). The\nproposed constellations are generated using a truncated Gaussian distribution,\nand the merging of constellation points, where the former creates a non-uniform\nconstellation (NUC), and the latter decreases the number of signal points\nwithout compromising the achievable bit-wise mutual information (BMI). Since\nthe proposed constellations are uniquely determined by only the two parameters,\neach associated with NUC and cardinality, the complexity required for the\nnumerical optimization process can be significantly low. We focus on the\nconstellation design based on one dimension, i.e., pulse amplitude modulation\n(PAM), which facilitates the reduction of demapping complexity for the BICM\nreceiver. The use of CAF at the transmitter can efficiently reduce the PAPR of\nOFDM signals; however, it introduces clipping noise that may degrade error rate\nperformance, making the application of clipping noise cancellation (CNC) at the\nreceiver essential. Therefore, we optimize the NENU constellations in the\npresence of CAF and CNC. Simulation results demonstrate that the combination of\nconstellation shaping with CAF and CNC enables BICM-OFDM systems to\nsimultaneously achieve low PAPR and high spectral efficiency over additive\nwhite Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading\nchannels. Furthermore, comparative studies confirm that the proposed system\nsignificantly outperforms the single-carrier counterpart (i.e., DFT-precoded\nBICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading\nchannels.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u5747\u5300\u975e\u7b49\u6982\u7387\u661f\u5ea7\u7684\u9ad8\u5bb9\u91cf\u4f4ePAPR OFDM\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u901a\u8fc7\u622a\u524d\u6ee4\u6ce2\u548c\u622a\u524d\u566a\u58f0\u6d88\u9664\u6280\u672f\uff0c\u5728AWGN\u548c\u9891\u9009\u8870\u843d\u4fe1\u9053\u4e0a\u540c\u65f6\u5b9e\u73b0\u4f4e\u5cf0\u5747\u6bd4\u548c\u9ad8\u8c31\u6548\u7387\u3002", "motivation": "\u89e3\u51b3OFDM\u7cfb\u7edf\u4e2d\u9ad8\u5cf0\u5747\u6bd4(PAPR)\u95ee\u9898\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8c31\u6548\u7387\u3002\u4f20\u7edf\u7684\u622a\u524d\u6ee4\u6ce2(CAF)\u6280\u672f\u867d\u7136\u53ef\u4ee5\u964d\u4f4ePAPR\uff0c\u4f46\u4f1a\u5f15\u5165\u622a\u524d\u566a\u58f0\u5bf9\u9519\u8bef\u7387\u6027\u80fd\u9020\u6210\u6076\u5316\u3002", "method": "\u91c7\u7528\u622a\u5c3e\u9ad8\u65af\u5206\u5e03\u751f\u6210\u975e\u5747\u5300\u975e\u7b49\u6982\u7387(NENU)\u661f\u5ea7\uff0c\u901a\u8fc7\u661f\u5ea7\u70b9\u5408\u5e76\u51cf\u5c11\u4fe1\u53f7\u70b9\u6570\u91cf\u4f46\u4fdd\u6301\u4fe1\u606f\u4f20\u8f93\u80fd\u529b\u3002\u7cfb\u7edf\u91c7\u7528\u4e00\u7ef4PAM\u8c03\u5236\u964d\u4f4e\u89e3\u6620\u590d\u6742\u5ea6\uff0c\u5e76\u5728\u53d1\u9001\u7aef\u4f7f\u7528CAF\u6280\u672f\uff0c\u5728\u63a5\u6536\u7aef\u4f7f\u7528\u622a\u524d\u566a\u58f0\u6d88\u9664(CNC)\u6280\u672f\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u5728AWGN\u548c\u9891\u9009\u8870\u843d\u4fe1\u9053\u4e0a\u90fd\u80fd\u540c\u65f6\u5b9e\u73b0\u4f4ePAPR\u548c\u9ad8\u8c31\u6548\u7387\u3002\u4e0e\u5355\u8f7d\u6ce2\u7cfb\u7edf\u76f8\u6bd4\uff0c\u5728\u8870\u843d\u4fe1\u9053\u4e0a\u5728PAPR\u548cBER\u6027\u80fd\u65b9\u9762\u90fd\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7NENU\u661f\u5ea7\u6210\u5f62\u3001CAF\u548cCNC\u6280\u672f\u7684\u7ed3\u5408\uff0c\u5f00\u53d1\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684BICM-OFDM\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u964d\u4f4e\u7cfb\u7edf\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u540c\u65f6\u4f18\u5316PAPR\u548c\u9519\u8bef\u7387\u6027\u80fd\u3002"}}
{"id": "2508.15307", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.15307", "abs": "https://arxiv.org/abs/2508.15307", "authors": ["Xiangtong Wang", "Wei Li", "Menglong Yang", "Songchen Han"], "title": "Unlocking the Performance Potential of Mega-Constellation Networks: An Exploration of Structure-Building Paradigms", "comment": null, "summary": "The network structure design plays a vital role in the mega-constellation\nnetwork (MSN) to coordinate massive network nodes to ensure the effectiveness\nand reliability of operations and services for future space wireless\ncommunications networks.\n  One of the critical issues in MCN is how to design an optimal network control\nstructure by configuring the most stable inter-satellite link (ISL) to achieve\nhigh available MCN within a limited average transmission delays.\n  To address this problem, this paper introduces a novel MCN structure design\nparadigm: Structure = Motif + Lattice (SML), which decouples MCN design into\nlocal motifs design and global lattices design. Specifically, we formulate the\nHigh-Availability and Low-Latency Mega-Constellation Design (HALLMD) problem,\naimed at maximizing ISL availability while minimizing the transmission latency.\nTo solve HALLMD, we propose SMLOP, a heuristic algorithm that efficiently finds\noptimal network structures in polynomial time. Experimental validation on four\npublic state-of-the-art constellations demonstrates significant improvements,\nincluding enhanced capacity by $5\\sim 18\\%$, increased throughput by $1\\sim\n12\\%$, reduced path stretch by $12\\sim 23\\%$, and Round-Trip Time (RTT) by\n$8\\sim 77\\%$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSML\uff08Structure = Motif + Lattice\uff09\u8303\u5f0f\uff0c\u901a\u8fc7\u89e3\u8026\u661f\u5ea7\u7f51\u7edc\u8bbe\u8ba1\u4e3a\u5c40\u90e8motif\u548c\u5168\u5c40lattice\u8bbe\u8ba1\uff0c\u89e3\u51b3\u9ad8\u53ef\u7528\u4f4e\u5ef6\u8fdf\u5de8\u578b\u661f\u5ea7\u7f51\u7edc\u7ed3\u6784\u4f18\u5316\u95ee\u9898", "motivation": "\u5de8\u578b\u661f\u5ea7\u7f51\u7edc\u4e2d\u9700\u8981\u8bbe\u8ba1\u6700\u4f18\u7f51\u7edc\u63a7\u5236\u7ed3\u6784\uff0c\u914d\u7f6e\u6700\u7a33\u5b9a\u7684\u661f\u95f4\u94fe\u8def\uff0c\u5728\u6709\u9650\u5e73\u5747\u4f20\u8f93\u5ef6\u8fdf\u5185\u5b9e\u73b0\u9ad8\u53ef\u7528\u6027\u7f51\u7edc", "method": "\u63d0\u51faSML\u8bbe\u8ba1\u8303\u5f0f\uff0c\u5c06MCN\u8bbe\u8ba1\u5206\u89e3\u4e3a\u5c40\u90e8motif\u8bbe\u8ba1\u548c\u5168\u5c40lattice\u8bbe\u8ba1\uff1b\u63d0\u51faHALLMD\u95ee\u9898\u5efa\u6a21\uff0c\u5e76\u5f00\u53d1SMLOP\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5bfb\u627e\u6700\u4f18\u7f51\u7edc\u7ed3\u6784", "result": "\u5728\u56db\u4e2a\u5148\u8fdb\u661f\u5ea7\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff1a\u5bb9\u91cf\u63d0\u53475-18%\uff0c\u541e\u5410\u91cf\u589e\u52a01-12%\uff0c\u8def\u5f84\u62c9\u4f38\u51cf\u5c1112-23%\uff0c\u5f80\u8fd4\u65f6\u95f4\u964d\u4f4e8-77%", "conclusion": "SML\u8303\u5f0f\u80fd\u6709\u6548\u89e3\u51b3\u5de8\u578b\u661f\u5ea7\u7f51\u7edc\u7684\u9ad8\u53ef\u7528\u4f4e\u5ef6\u8fdf\u8bbe\u8ba1\u95ee\u9898\uff0cSMLOP\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u627e\u5230\u6700\u4f18\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u7f51\u7edc\u6027\u80fd"}}
{"id": "2508.14923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14923", "abs": "https://arxiv.org/abs/2508.14923", "authors": ["Andrew Kiruluta"], "title": "A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone", "comment": null, "summary": "We propose a fully spectral, neuro\\-symbolic reasoning architecture that\nleverages Graph Signal Processing (GSP) as the primary computational backbone\nfor integrating symbolic logic and neural inference. Unlike conventional\nreasoning models that treat spectral graph methods as peripheral components,\nour approach formulates the entire reasoning pipeline in the graph spectral\ndomain. Logical entities and relationships are encoded as graph signals,\nprocessed via learnable spectral filters that control multi-scale information\npropagation, and mapped into symbolic predicates for rule-based inference. We\npresent a complete mathematical framework for spectral reasoning, including\ngraph Fourier transforms, band-selective attention, and spectral rule\ngrounding. Experiments on benchmark reasoning datasets (ProofWriter,\nEntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in\nlogical consistency, interpretability, and computational efficiency over\nstate\\-of\\-the\\-art neuro\\-symbolic models. Our results suggest that GSP\nprovides a mathematically grounded and computationally efficient substrate for\nrobust and interpretable reasoning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8e\u9891\u8c31\u7684\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u67b6\u6784\uff0c\u4f7f\u7528\u56fe\u4fe1\u53f7\u5904\u7406(GSP)\u4f5c\u4e3a\u6838\u5fc3\u8ba1\u7b97\u6846\u67b6\uff0c\u5c06\u6574\u4e2a\u63a8\u7406\u6d41\u7a0b\u7f6e\u4e8e\u56fe\u9891\u8c31\u57df\u4e2d\u5904\u7406\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u903b\u8f91\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u90fd\u6709\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u6a21\u578b\u901a\u5e38\u5c06\u9891\u8c31\u56fe\u65b9\u6cd5\u4f5c\u4e3a\u5916\u56f4\u7ec4\u4ef6\uff0c\u7f3a\u4e4f\u5b8c\u6574\u7684\u9891\u8c31\u57df\u63a8\u7406\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7GSP\u63d0\u4f9b\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u63a8\u7406\u7cfb\u7edf\u3002", "method": "\u5c06\u903b\u8f91\u5b9e\u4f53\u548c\u5173\u7cfb\u7f16\u7801\u4e3a\u56fe\u4fe1\u53f7\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u9891\u8c31\u6ee4\u6ce2\u5668\u63a7\u5236\u591a\u5c3a\u5ea6\u4fe1\u606f\u4f20\u64ad\uff0c\u5e76\u6620\u5c04\u5230\u7b26\u53f7\u8c13\u8bcd\u8fdb\u884c\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002\u5305\u62ec\u56fe\u5085\u91cc\u53f6\u53d8\u6362\u3001\u9891\u5e26\u9009\u62e9\u6027\u6ce8\u610f\u529b\u548c\u9891\u8c31\u89c4\u5219\u843d\u5730\u7b49\u5b8c\u6574\u6570\u5b66\u6846\u67b6\u3002", "result": "\u5728ProofWriter\u3001EntailmentBank\u3001bAbI\u3001CLUTRR\u548cARC-Challenge\u7b49\u57fa\u51c6\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\uff0c\u5728\u903b\u8f91\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u90fd\u6709\u6539\u8fdb\u3002", "conclusion": "GSP\u4e3a\u6784\u5efa\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u8ba1\u7b97\u57fa\u5e95\uff0c\u8bc1\u660e\u4e86\u5b8c\u5168\u9891\u8c31\u57df\u63a8\u7406\u67b6\u6784\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.15652", "categories": ["cs.AI", "cs.IT", "cs.LG", "cs.MA", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15652", "abs": "https://arxiv.org/abs/2508.15652", "authors": ["Ardian Selmonaj", "Miroslav Strupl", "Oleg Szehr", "Alessandro Antonucci"], "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning", "comment": "European Conference on Artificial Intelligence (ECAI) 2025", "summary": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is\ncrucial to understand individual agent behaviors within a team. While prior\nwork typically evaluates overall team performance based on explicit reward\nsignals or learned value functions, it is unclear how to infer agent\ncontributions in the absence of any value feedback. In this work, we\ninvestigate whether meaningful insights into agent behaviors can be extracted\nthat are consistent with the underlying value functions, solely by analyzing\nthe policy distribution. Inspired by the phenomenon that intelligent agents\ntend to pursue convergent instrumental values, which generally increase the\nlikelihood of task success, we introduce Intended Cooperation Values (ICVs), a\nmethod based on information-theoretic Shapley values for quantifying each\nagent's causal influence on their co-players' instrumental empowerment.\nSpecifically, ICVs measure an agent's action effect on its teammates' policies\nby assessing their decision uncertainty and preference alignment. The analysis\nacross cooperative and competitive MARL environments reveals the extent to\nwhich agents adopt similar or diverse strategies. By comparing action effects\nbetween policies and value functions, our method identifies which agent\nbehaviors are beneficial to team success, either by fostering deterministic\ndecisions or by preserving flexibility for future action choices. Our proposed\nmethod offers novel insights into cooperation dynamics and enhances\nexplainability in MARL systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4fe1\u606f\u8bbaShapley\u503c\u7684Intended Cooperation Values (ICVs)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u7b56\u7565\u5206\u5e03\u6765\u91cf\u5316\u667a\u80fd\u4f53\u5728\u5408\u4f5c\u4e2d\u7684\u56e0\u679c\u5f71\u54cd\u529b\uff0c\u65e0\u9700\u4ef7\u503c\u51fd\u6570\u53cd\u9988\u5373\u53ef\u8bc4\u4f30\u4e2a\u4f53\u8d21\u732e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u663e\u5f0f\u5956\u52b1\u4fe1\u53f7\u6216\u4ef7\u503c\u51fd\u6570\u6765\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u56e2\u961f\u6574\u4f53\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u5728\u65e0\u4ef7\u503c\u53cd\u9988\u60c5\u51b5\u4e0b\u63a8\u65ad\u4e2a\u4f53\u667a\u80fd\u4f53\u8d21\u732e\u7684\u65b9\u6cd5\u3002\u9700\u8981\u7406\u89e3\u667a\u80fd\u4f53\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u56e2\u961f\u6210\u529f\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u8bbaShapley\u503c\uff0c\u901a\u8fc7\u6d4b\u91cf\u667a\u80fd\u4f53\u52a8\u4f5c\u5bf9\u961f\u53cb\u7b56\u7565\u51b3\u7b56\u4e0d\u786e\u5b9a\u6027\u548c\u504f\u597d\u5bf9\u9f50\u7684\u5f71\u54cd\uff0c\u91cf\u5316\u5176\u5bf9\u5408\u4f5c\u540c\u4f34\u5de5\u5177\u6027\u8d4b\u80fd\u7684\u56e0\u679c\u5f71\u54cd\u529b\u3002", "result": "\u5728\u5408\u4f5c\u6027\u548c\u7ade\u4e89\u6027MARL\u73af\u5883\u4e2d\u7684\u5206\u6790\u63ed\u793a\u4e86\u667a\u80fd\u4f53\u91c7\u7528\u76f8\u4f3c\u6216\u591a\u6837\u5316\u7b56\u7565\u7684\u7a0b\u5ea6\uff0c\u80fd\u591f\u8bc6\u522b\u54ea\u4e9b\u884c\u4e3a\u901a\u8fc7\u4fc3\u8fdb\u786e\u5b9a\u6027\u51b3\u7b56\u6216\u4fdd\u6301\u672a\u6765\u884c\u52a8\u7075\u6d3b\u6027\u6765\u6709\u76ca\u4e8e\u56e2\u961f\u6210\u529f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aMARL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u5408\u4f5c\u52a8\u6001\u6d1e\u5bdf\uff0c\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u5728\u6ca1\u6709\u4ef7\u503c\u51fd\u6570\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u8bc4\u4f30\u667a\u80fd\u4f53\u4e2a\u4f53\u8d21\u732e\u3002"}}
{"id": "2508.15595", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.15595", "abs": "https://arxiv.org/abs/2508.15595", "authors": ["Abhishek Dandekar", "Prashiddha D. Thapa", "Ashrafur Rahman", "Julius Schulz-Zander"], "title": "Interface on demand: Towards AI native Control interfaces for 6G", "comment": null, "summary": "Traditional standardized network interfaces face significant limitations,\nincluding vendor-specific incompatibilities, rigid design assumptions, and lack\nof adaptability for new functionalities. We propose a multi-agent framework\nleveraging large language models (LLMs) to generate control interfaces on\ndemand between network functions (NFs). This includes a matching agent, which\naligns required control functionalities with NF capabilities, and a\ncode-generation agent, which generates the necessary API server for interface\nrealization. We validate our approach using simulated multi-vendor gNB and WLAN\nAP environments. The performance evaluations highlight the trade-offs between\ncost and latency across LLMs for interface generation tasks. Our work sets the\nfoundation for AI-native dynamic control interface generation, paving the way\nfor enhanced interoperability and adaptability in future mobile networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u6309\u9700\u751f\u6210\u7f51\u7edc\u529f\u80fd\u95f4\u7684\u63a7\u5236\u63a5\u53e3\uff0c\u89e3\u51b3\u4f20\u7edf\u6807\u51c6\u5316\u63a5\u53e3\u7684\u517c\u5bb9\u6027\u548c\u9002\u5e94\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6807\u51c6\u5316\u7f51\u7edc\u63a5\u53e3\u5b58\u5728\u5382\u5546\u4e0d\u517c\u5bb9\u3001\u8bbe\u8ba1\u50f5\u5316\u3001\u7f3a\u4e4f\u65b0\u529f\u80fd\u9002\u5e94\u6027\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u52a8\u6001\u63a5\u53e3\u751f\u6210\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u5339\u914d\u667a\u80fd\u4f53\u5bf9\u9f50\u63a7\u5236\u529f\u80fd\u9700\u6c42\u4e0e\u7f51\u7edc\u529f\u80fd\u80fd\u529b\uff0c\u4ee3\u7801\u751f\u6210\u667a\u80fd\u4f53\u751f\u6210\u5b9e\u73b0\u63a5\u53e3\u6240\u9700\u7684API\u670d\u52a1\u5668\u3002\u5728\u6a21\u62df\u7684\u591a\u5382\u5546gNB\u548cWLAN AP\u73af\u5883\u4e2d\u9a8c\u8bc1\u3002", "result": "\u6027\u80fd\u8bc4\u4f30\u63ed\u793a\u4e86\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a5\u53e3\u751f\u6210\u4efb\u52a1\u4e2d\u6210\u672c\u4e0e\u5ef6\u8fdf\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u4e3aAI\u539f\u751f\u52a8\u6001\u63a7\u5236\u63a5\u53e3\u751f\u6210\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u589e\u5f3a\u4e92\u64cd\u4f5c\u6027\u548c\u9002\u5e94\u6027\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.15013", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.15013", "abs": "https://arxiv.org/abs/2508.15013", "authors": ["Nadav Amir", "Stas Tiomkin", "Angela Langdon"], "title": "Goals and the Structure of Experience", "comment": null, "summary": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its\nacquisition is often believed to rely on world models, comprising both\ndescriptive (what is) and prescriptive (what is desirable) aspects that\nidentify and evaluate state of affairs in the world, respectively. Canonical\ncomputational accounts of purposeful behavior, such as reinforcement learning,\nposit distinct components of a world model comprising a state representation\n(descriptive aspect) and a reward function (prescriptive aspect). However, an\nalternative possibility, which has not yet been computationally formulated, is\nthat these two aspects instead co-emerge interdependently from an agent's goal.\nHere, we describe a computational framework of goal-directed state\nrepresentation in cognitive agents, in which the descriptive and prescriptive\naspects of a world model co-emerge from agent-environment interaction\nsequences, or experiences. Drawing on Buddhist epistemology, we introduce a\nconstruct of goal-directed, or telic, states, defined as classes of\ngoal-equivalent experience distributions. Telic states provide a parsimonious\naccount of goal-directed learning in terms of the statistical divergence\nbetween behavioral policies and desirable experience features. We review\nempirical and theoretical literature supporting this novel perspective and\ndiscuss its potential to provide a unified account of behavioral,\nphenomenological and neural dimensions of purposeful behaviors across diverse\nsubstrates.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4f5b\u6559\u8ba4\u8bc6\u8bba\u7684\u76ee\u6807\u5bfc\u5411\u72b6\u6001\u8868\u793a\u8ba1\u7b97\u6846\u67b6\uff0c\u5176\u4e2d\u63cf\u8ff0\u6027\u548c\u89c4\u8303\u6027\u65b9\u9762\u4ece\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u4e2d\u5171\u540c\u6d8c\u73b0\uff0c\u800c\u975e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u79bb\u72b6\u6001\u8868\u793a\u548c\u5956\u52b1\u51fd\u6570\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5c06\u4e16\u754c\u6a21\u578b\u5206\u4e3a\u72b6\u6001\u8868\u793a\uff08\u63cf\u8ff0\u6027\uff09\u548c\u5956\u52b1\u51fd\u6570\uff08\u89c4\u8303\u6027\uff09\u4e24\u4e2a\u72ec\u7acb\u7ec4\u4ef6\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e24\u4e2a\u65b9\u9762\u5e94\u8be5\u4ece\u667a\u80fd\u4f53\u7684\u76ee\u6807\u4e2d\u76f8\u4e92\u4f9d\u8d56\u5730\u5171\u540c\u6d8c\u73b0\u3002", "method": "\u5f15\u5165\u76ee\u6807\u5bfc\u5411\u72b6\u6001\uff08telic states\uff09\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u76ee\u6807\u7b49\u4ef7\u7ecf\u9a8c\u5206\u5e03\u7684\u7c7b\u522b\uff0c\u901a\u8fc7\u884c\u4e3a\u7b56\u7565\u4e0e\u671f\u671b\u7ecf\u9a8c\u7279\u5f81\u4e4b\u95f4\u7684\u7edf\u8ba1\u5dee\u5f02\u6765\u8861\u91cf\u76ee\u6807\u5bfc\u5411\u5b66\u4e60\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u91ca\u884c\u4e3a\u3001\u73b0\u8c61\u5b66\u548c\u795e\u7ecf\u7ef4\u5ea6\u4e0a\u7684\u76ee\u7684\u6027\u884c\u4e3a\uff0c\u4e3a\u4e0d\u540c\u57fa\u8d28\u4e2d\u7684\u76ee\u7684\u6027\u884c\u4e3a\u63d0\u4f9b\u7edf\u4e00\u89e3\u91ca\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u76ee\u7684\u6027\u884c\u4e3a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u89c6\u89d2\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u4e16\u754c\u6a21\u578b\u5206\u79bb\u89c2\u70b9\uff0c\u5f3a\u8c03\u4e86\u63cf\u8ff0\u6027\u548c\u89c4\u8303\u6027\u65b9\u9762\u7684\u5171\u540c\u6d8c\u73b0\u7279\u6027\u3002"}}
{"id": "2508.15030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15030", "abs": "https://arxiv.org/abs/2508.15030", "authors": ["Ashmi Banerjee", "Fitri Nur Aisyah", "Adithi Satish", "Wolfgang W\u00f6rndl", "Yashar Deldjoo"], "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "comment": null, "summary": "We propose Collab-REC, a multi-agent framework designed to counteract\npopularity bias and enhance diversity in tourism recommendations. In our\nsetting, three LLM-based agents -- Personalization, Popularity, and\nSustainability generate city suggestions from complementary perspectives. A\nnon-LLM moderator then merges and refines these proposals via multi-round\nnegotiation, ensuring each agent's viewpoint is incorporated while penalizing\nspurious or repeated responses. Experiments on European city queries show that\nCollab-REC improves diversity and overall relevance compared to a single-agent\nbaseline, surfacing lesser-visited locales that often remain overlooked. This\nbalanced, context-aware approach addresses over-tourism and better aligns with\nconstraints provided by the user, highlighting the promise of multi-stakeholder\ncollaboration in LLM-driven recommender systems.", "AI": {"tldr": "Collab-REC\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2aLLM\u667a\u80fd\u4f53\uff08\u4e2a\u6027\u5316\u3001\u6d41\u884c\u5ea6\u3001\u53ef\u6301\u7eed\u6027\uff09\u4ece\u4e0d\u540c\u89d2\u5ea6\u751f\u6210\u65c5\u6e38\u63a8\u8350\uff0c\u518d\u901a\u8fc7\u975eLLM\u8c03\u89e3\u5668\u8fdb\u884c\u591a\u8f6e\u534f\u5546\u6574\u5408\uff0c\u6709\u6548\u5bf9\u6297\u6d41\u884c\u5ea6\u504f\u89c1\u5e76\u63d0\u5347\u63a8\u8350\u591a\u6837\u6027\u3002", "motivation": "\u89e3\u51b3\u65c5\u6e38\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6d41\u884c\u5ea6\u504f\u89c1\u95ee\u9898\uff0c\u907f\u514d\u8fc7\u5ea6\u65c5\u6e38\uff0c\u63d0\u5347\u63a8\u8350\u591a\u6837\u6027\uff0c\u8ba9\u66f4\u591a\u5c0f\u4f17\u4f46\u4f18\u8d28\u7684\u65c5\u6e38\u5730\u70b9\u5f97\u5230\u5173\u6ce8\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\uff08\u4e2a\u6027\u5316\u3001\u6d41\u884c\u5ea6\u3001\u53ef\u6301\u7eed\u6027\uff09\u5206\u522b\u4ece\u4e0d\u540c\u89d2\u5ea6\u751f\u6210\u57ce\u5e02\u63a8\u8350\u5efa\u8bae\uff0c\u7136\u540e\u901a\u8fc7\u975eLLM\u8c03\u89e3\u5668\u8fdb\u884c\u591a\u8f6e\u534f\u5546\u548c\u6574\u5408\uff0c\u60e9\u7f5a\u91cd\u590d\u6216\u65e0\u5173\u54cd\u5e94\u3002", "result": "\u5728\u6b27\u6d32\u57ce\u5e02\u67e5\u8be2\u5b9e\u9a8c\u4e2d\uff0cCollab-REC\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u591a\u6837\u6027\u548c\u6574\u4f53\u76f8\u5173\u6027\uff0c\u80fd\u591f\u53d1\u73b0\u5e38\u88ab\u5ffd\u89c6\u7684\u5c0f\u4f17\u65c5\u6e38\u5730\u70b9\u3002", "conclusion": "\u8fd9\u79cd\u5e73\u8861\u7684\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u591a\u5229\u76ca\u76f8\u5173\u8005\u534f\u4f5c\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u5ea6\u65c5\u6e38\u95ee\u9898\uff0c\u66f4\u597d\u5730\u6ee1\u8db3\u7528\u6237\u7ea6\u675f\u6761\u4ef6\uff0c\u5c55\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5728LLM\u9a71\u52a8\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.15047", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.15047", "abs": "https://arxiv.org/abs/2508.15047", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "comment": null, "summary": "Animating and simulating crowds using an agent-based approach is a\nwell-established area where every agent in the crowd is individually controlled\nsuch that global human-like behaviour emerges. We observe that human navigation\nand movement in crowds are often influenced by complex social and environmental\ninteractions, driven mainly by language and dialogue. However, most existing\nwork does not consider these dimensions and leads to animations where\nagent-agent and agent-environment interactions are largely limited to steering\nand fixed higher-level goal extrapolation.\n  We propose a novel method that exploits large language models (LLMs) to\ncontrol agents' movement. Our method has two main components: a dialogue system\nand language-driven navigation. We periodically query agent-centric LLMs\nconditioned on character personalities, roles, desires, and relationships to\ncontrol the generation of inter-agent dialogue when necessitated by the spatial\nand social relationships with neighbouring agents. We then use the conversation\nand each agent's personality, emotional state, vision, and physical state to\ncontrol the navigation and steering of each agent. Our model thus enables\nagents to make motion decisions based on both their perceptual inputs and the\nongoing dialogue.\n  We validate our method in two complex scenarios that exemplify the interplay\nbetween social interactions, steering, and crowding. In these scenarios, we\nobserve that grouping and ungrouping of agents automatically occur.\nAdditionally, our experiments show that our method serves as an\ninformation-passing mechanism within the crowd. As a result, our framework\nproduces more realistic crowd simulations, with emergent group behaviours\narising naturally from any environmental setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a7\u5236\u7fa4\u4f53\u4e2d\u4ee3\u7406\u884c\u4e3a\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u5bfc\u822a\u6765\u5b9e\u73b0\u66f4\u73b0\u5b9e\u7684\u4eba\u7fa4\u6a21\u62df\u548c\u52a8\u753b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u7fa4\u4f53\u6a21\u62df\u65b9\u6cd5\u5bf9\u4e8e\u4eba\u4eec\u5728\u7fa4\u4f53\u4e2d\u7684\u590d\u6742\u793e\u4f1a\u548c\u73af\u5883\u4ea4\u4e92\u8003\u8651\u4e0d\u8db3\uff0c\u4e3b\u8981\u9650\u4e8e\u5bfc\u822a\u548c\u56fa\u5b9a\u9ad8\u5c42\u76ee\u6807\u63a8\u65ad\uff0c\u7f3a\u4e4f\u8bed\u8a00\u548c\u5bf9\u8bdd\u4ea4\u6d41\u7684\u5f71\u54cd\u3002", "method": "\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a\u5bf9\u8bdd\u7cfb\u7edf\u548c\u8bed\u8a00\u9a71\u52a8\u5bfc\u822a\u3002\u5468\u671f\u6027\u67e5\u8be2\u57fa\u4e8e\u4ee3\u7406\u7279\u5f81\u7684LLMs\uff0c\u6839\u636e\u89d2\u8272\u6027\u683c\u3001\u6f5c\u671f\u3001\u5173\u7cfb\u7b49\u751f\u6210\u4ee3\u7406\u95f4\u5bf9\u8bdd\uff0c\u7136\u540e\u5229\u7528\u5bf9\u8bdd\u5185\u5bb9\u3001\u4e2a\u6027\u3001\u60c5\u7eea\u72b6\u6001\u3001\u89c6\u89c9\u548c\u7269\u7406\u72b6\u6001\u6765\u63a7\u5236\u6bcf\u4e2a\u4ee3\u7406\u7684\u5bfc\u822a\u548c\u884c\u8d70\u3002", "result": "\u5728\u4e24\u4e2a\u590d\u6742\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u89c2\u5bdf\u5230\u4ee3\u7406\u81ea\u52a8\u8fdb\u884c\u5206\u7ec4\u548c\u89e3\u6563\uff0c\u5e76\u4f5c\u4e3a\u4fe1\u606f\u4f20\u9012\u673a\u5236\u5728\u7fa4\u4f53\u4e2d\u8fd0\u4f5c\u3002\u8be5\u6846\u67b6\u80fd\u591f\u4ea7\u751f\u66f4\u73b0\u5b9e\u7684\u7fa4\u4f53\u6a21\u62df\uff0c\u4ece\u4efb\u4f55\u73af\u5883\u8bbe\u7f6e\u4e2d\u81ea\u7136\u51fa\u73b0\u51fa\u73b0\u7684\u7fa4\u4f53\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u6765\u63a7\u5236\u7fa4\u4f53\u4e2d\u4ee3\u7406\u7684\u5bf9\u8bdd\u548c\u79fb\u52a8\uff0c\u672c\u6587\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u66f4\u4e30\u5bcc\u548c\u73b0\u5b9e\u7684\u4eba\u7fa4\u52a8\u753b\u6548\u679c\uff0c\u4f7f\u5f97\u793e\u4f1a\u4ea4\u4e92\u3001\u5bfc\u822a\u548c\u7fa4\u4f53\u5bc6\u5ea6\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u66f4\u52a0\u81ea\u7136\u548c\u51fa\u73b0\u3002"}}
{"id": "2508.15050", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15050", "abs": "https://arxiv.org/abs/2508.15050", "authors": ["Romain Lacombe", "Kerrie Wu", "Eddie Dilworth"], "title": "Don't Think Twice! Over-Reasoning Impairs Confidence Calibration", "comment": "Published at ICML 2025 Workshop on Reliable and Responsible\n  Foundation Models", "summary": "Large Language Models deployed as question answering tools require robust\ncalibration to avoid overconfidence. We systematically evaluate how reasoning\ncapabilities and budget affect confidence assessment accuracy, using the\nClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary\nhealth. Our key finding challenges the \"test-time scaling\" paradigm: while\nrecent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,\nincreasing reasoning budgets consistently impairs rather than improves\ncalibration. Extended reasoning leads to systematic overconfidence that worsens\nwith longer thinking budgets, producing diminishing and negative returns beyond\nmodest computational investments. Conversely, search-augmented generation\ndramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving\nrelevant evidence. Our results suggest that information access, rather than\nreasoning depth or inference budget, may be the critical bottleneck for\nimproved confidence calibration of knowledge-intensive tasks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u9884\u7b97\u589e\u52a0\u53cd\u800c\u635f\u5bb3LLM\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u663e\u8457\u4f18\u4e8e\u7eaf\u63a8\u7406\u65b9\u6cd5", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u95ee\u9898\uff0c\u7279\u522b\u662f\u63a8\u7406\u80fd\u529b\u548c\u8ba1\u7b97\u9884\u7b97\u5bf9\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u51c6\u786e\u6027\u7684\u5f71\u54cd", "method": "\u4f7f\u7528ClimateX\u6570\u636e\u96c6\u5e76\u6269\u5c55\u5230\u4eba\u7c7b\u548c\u884c\u661f\u5065\u5eb7\u9886\u57df\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u63a8\u7406\u9884\u7b97\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6027\u80fd\uff0c\u6bd4\u8f83\u7eaf\u63a8\u7406\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5", "result": "\u63a8\u7406LLM\u5728\u4e13\u5bb6\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u4e2d\u8fbe\u523048.7%\u51c6\u786e\u7387\uff0c\u4f46\u589e\u52a0\u63a8\u7406\u9884\u7b97\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\uff1b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u8fbe\u523089.3%\u51c6\u786e\u7387", "conclusion": "\u4fe1\u606f\u8bbf\u95ee\u800c\u975e\u63a8\u7406\u6df1\u5ea6\u6216\u63a8\u7406\u9884\u7b97\u662f\u6539\u8fdb\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7684\u5173\u952e\u74f6\u9888"}}
{"id": "2508.15053", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15053", "abs": "https://arxiv.org/abs/2508.15053", "authors": ["Itai Zilberstein", "Alberto Candela", "Steve Chien", "David Rijlaarsdam", "Tom Hendrix", "Leonie Buckley", "Aubrey Dunne"], "title": "Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning", "comment": "International Symposium on Artificial Intelligence, Robotics and\n  Automation in Space, November 2024", "summary": "In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is\ndemonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).\nCS-6 is a satellite with a visible and near infrared range hyperspectral\ninstrument and neural network acceleration hardware. Performing data analysis\nat the edge (e.g. onboard) can enable new Earth science measurements and\nresponses. We will demonstrate data analysis and inference onboard CS-6 for\nnumerous applications using deep learning and spectral analysis algorithms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.15068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15068", "abs": "https://arxiv.org/abs/2508.15068", "authors": ["Shuang Ao", "Gopal Rumchurn"], "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner", "comment": "9 pages, 2 figures", "summary": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning\n(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based\nagents. However, these adaptations can unintentionally compromise safety\nalignment, leading to unsafe or unstable behaviors, particularly in agent\nplanning tasks. Existing safety-aware adaptation methods often require access\nto both base and instruction-tuned model checkpoints, which are frequently\nunavailable in practice, limiting their applicability. We propose S3LoRA (Safe\nSpectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and\nmodel-independent framework that mitigates safety risks in LoRA-adapted models\nby inspecting only the fine-tuned weight updates. We first introduce\nMagnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes\nthe structural properties of LoRA updates while preserving global magnitude\ninformation. We then design the Spectral Sharpness Index (SSI), a\nsharpness-aware metric to detect layers with highly concentrated and\npotentially unsafe updates. These layers are pruned post-hoc to reduce risk\nwithout sacrificing task performance. Extensive experiments and ablation\nstudies across agent planning and language generation tasks show that S3LoRA\nconsistently improves safety metrics while maintaining or improving utility\nmetrics and significantly reducing inference cost. These results establish\nS3LoRA as a practical and scalable solution for safely deploying LLM-based\nagents in real-world, resource-constrained, and safety-critical environments.", "AI": {"tldr": "S3LoRA\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u6570\u636e\u3001\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790LoRA\u5fae\u8c03\u6743\u91cd\u66f4\u65b0\u6765\u7f13\u89e3\u5b89\u5168\u98ce\u9669\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u5b89\u5168\u6027\u5e76\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff08\u5982LoRA\uff09\u5728\u589e\u5f3aLLM\u80fd\u529b\u7684\u540c\u65f6\u53ef\u80fd\u65e0\u610f\u4e2d\u7834\u574f\u5b89\u5168\u5bf9\u9f50\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u4e14\u73b0\u6709\u5b89\u5168\u9002\u5e94\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8bbf\u95ee\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u5fae\u8c03\u68c0\u67e5\u70b9\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f80\u5f80\u4e0d\u53ef\u7528\u3002", "method": "\u63d0\u51faS3LoRA\u6846\u67b6\uff0c\u5305\u542bMAS-SVD\u65b9\u6cd5\u5206\u6790LoRA\u66f4\u65b0\u7684\u7ed3\u6784\u7279\u6027\uff0c\u8bbe\u8ba1SSI\u6307\u6807\u68c0\u6d4b\u6f5c\u5728\u4e0d\u5b89\u5168\u7684\u5c42\uff0c\u5e76\u901a\u8fc7\u540e\u526a\u679d\u964d\u4f4e\u98ce\u9669\u3002", "result": "\u5728\u667a\u80fd\u4f53\u89c4\u5212\u548c\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cS3LoRA\u80fd\u6301\u7eed\u6539\u5584\u5b89\u5168\u6307\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6548\u7528\u6307\u6807\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "conclusion": "S3LoRA\u4e3a\u5728\u73b0\u5b9e\u4e16\u754c\u3001\u8d44\u6e90\u53d7\u9650\u548c\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u5b89\u5168\u90e8\u7f72\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15118", "abs": "https://arxiv.org/abs/2508.15118", "authors": ["Jennifer Leigh", "Dimitrios Letsios", "Alessandro Mella", "Lucio Machetti", "Francesca Toni"], "title": "Argumentation for Explainable Workforce Optimisation (with Appendix)", "comment": "Accepted to PAIS 2025", "summary": "Workforce management is a complex problem optimising the makespan and travel\ndistance required for a team of operators to complete a set of jobs, using a\nset of instruments. A crucial challenge in workforce management is\naccommodating changes at execution time so that explanations are provided to\nall stakeholders involved. Here, we show that, by understanding workforce\nmanagement as abstract argumentation in an industrial application, we can\naccommodate change and obtain faithful explanations. We show, with a user\nstudy, that our tool and explanations lead to faster and more accurate problem\nsolving than conventional solutions by hand.", "AI": {"tldr": "\u5c06\u52b3\u52a8\u529b\u7ba1\u7406\u5efa\u6a21\u4e3a\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u5de5\u4e1a\u5e94\u7528\u5b9e\u73b0\u53d8\u66f4\u9002\u5e94\u548c\u53ef\u4fe1\u89e3\u91ca\uff0c\u7528\u6237\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u624b\u52a8\u89e3\u51b3\u65b9\u6848\u66f4\u5feb\u66f4\u51c6\u786e", "motivation": "\u52b3\u52a8\u529b\u7ba1\u7406\u9700\u8981\u4f18\u5316\u5b8c\u6210\u65f6\u95f4\u548c\u79fb\u52a8\u8ddd\u79bb\uff0c\u5173\u952e\u6311\u6218\u5728\u4e8e\u6267\u884c\u65f6\u9002\u5e94\u53d8\u5316\u5e76\u4e3a\u6240\u6709\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u89e3\u91ca", "method": "\u5c06\u52b3\u52a8\u529b\u7ba1\u7406\u95ee\u9898\u5efa\u6a21\u4e3a\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u5f00\u53d1\u76f8\u5e94\u7684\u5de5\u5177\u6765\u751f\u6210\u89e3\u91ca\u548c\u5904\u7406\u6267\u884c\u65f6\u7684\u53d8\u66f4", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u624b\u52a8\u89e3\u51b3\u65b9\u6848\u80fd\u5e26\u6765\u66f4\u5feb\u548c\u66f4\u51c6\u786e\u7684\u95ee\u9898\u89e3\u51b3\u6548\u679c", "conclusion": "\u62bd\u8c61\u8bba\u8bc1\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u52b3\u52a8\u529b\u7ba1\u7406\u4e2d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5e76\u63d0\u4f9b\u53ef\u4fe1\u7684\u89e3\u91ca\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5"}}
{"id": "2508.15119", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15119", "abs": "https://arxiv.org/abs/2508.15119", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "title": "Open-Universe Assistance Games", "comment": "7 pages + 2 pages references + 7 pages appendix", "summary": "Embodied AI agents must infer and act in an interpretable way on diverse\nhuman goals and preferences that are not predefined. To formalize this setting,\nwe introduce Open-Universe Assistance Games (OU-AGs), a framework where the\nagent must reason over an unbounded and evolving space of possible goals. In\nthis context, we introduce GOOD (GOals from Open-ended Dialogue), a\ndata-efficient, online method that extracts goals in the form of natural\nlanguage during an interaction with a human, and infers a distribution over\nnatural language goals. GOOD prompts an LLM to simulate users with different\ncomplex intents, using its responses to perform probabilistic inference over\ncandidate goals. This approach enables rich goal representations and\nuncertainty estimation without requiring large offline datasets. We evaluate\nGOOD in a text-based grocery shopping domain and in a text-operated simulated\nhousehold robotics environment (AI2Thor), using synthetic user profiles. Our\nmethod outperforms a baseline without explicit goal tracking, as confirmed by\nboth LLM-based and human evaluations.", "AI": {"tldr": "\u63d0\u51fa\u4e86Open-Universe Assistance Games\u6846\u67b6\u548cGOOD\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u7ebf\u5bf9\u8bdd\u4eceLLM\u6a21\u62df\u7684\u7528\u6237\u610f\u56fe\u4e2d\u63d0\u53d6\u81ea\u7136\u8bed\u8a00\u76ee\u6807\u5e76\u8fdb\u884c\u6982\u7387\u63a8\u7406\uff0c\u5728\u6587\u672c\u8d2d\u7269\u548c\u5bb6\u5ead\u673a\u5668\u4eba\u73af\u5883\u4e2d\u4f18\u4e8e\u65e0\u76ee\u6807\u8ddf\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5177\u8eabAI\u4ee3\u7406\u9700\u8981\u63a8\u65ad\u548c\u54cd\u5e94\u672a\u9884\u5b9a\u4e49\u7684\u4eba\u7c7b\u591a\u6837\u5316\u76ee\u6807\u548c\u504f\u597d\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u3001\u52a8\u6001\u7684\u76ee\u6807\u7a7a\u95f4\u4e2d\u3002", "method": "\u5f15\u5165GOOD\u65b9\u6cd5\uff1a\u4f7f\u7528LLM\u6a21\u62df\u5177\u6709\u590d\u6742\u610f\u56fe\u7684\u7528\u6237\uff0c\u901a\u8fc7\u5bf9\u8bdd\u63d0\u53d6\u81ea\u7136\u8bed\u8a00\u76ee\u6807\u8868\u793a\uff0c\u5e76\u8fdb\u884c\u6982\u7387\u63a8\u7406\u6765\u63a8\u65ad\u76ee\u6807\u5206\u5e03\uff0c\u65e0\u9700\u5927\u578b\u79bb\u7ebf\u6570\u636e\u96c6\u3002", "result": "\u5728\u6587\u672c\u8d2d\u7269\u548cAI2Thor\u5bb6\u5ead\u673a\u5668\u4eba\u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u5408\u6210\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u8fdb\u884c\u8bc4\u4f30\uff0cGOOD\u65b9\u6cd5\u5728LLM\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u90fd\u4f18\u4e8e\u65e0\u663e\u5f0f\u76ee\u6807\u8ddf\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GOOD\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5f00\u653e\u5b87\u5b99\u4e2d\u7684\u76ee\u6807\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u4f9b\u4e30\u5bcc\u7684\u76ee\u6807\u8868\u793a\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5177\u6709\u6570\u636e\u6548\u7387\u9ad8\u7684\u4f18\u52bf\u3002"}}
{"id": "2508.15126", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15126", "abs": "https://arxiv.org/abs/2508.15126", "authors": ["Pengsong Zhang", "Xiang Hu", "Guowei Huang", "Yang Qi", "Heng Zhang", "Xiuxu Li", "Jiaxing Song", "Jiabin Luo", "Yijiang Li", "Shuo Yin", "Chengxiao Dai", "Eric Hanchen Jiang", "Xiaoyan Zhou", "Zhenfei Yin", "Boqin Yuan", "Jing Dong", "Guinan Su", "Guanren Qiao", "Haiming Tang", "Anghong Du", "Lili Pan", "Zhenzhong Lan", "Xinyu Liu"], "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists", "comment": "Preprint under review. Code is available at\n  https://github.com/aixiv-org. Website is available at\n  https://forms.gle/DxQgCtXFsJ4paMtn8", "summary": "Recent advances in large language models (LLMs) have enabled AI agents to\nautonomously generate scientific proposals, conduct experiments, author papers,\nand perform peer reviews. Yet this flood of AI-generated research content\ncollides with a fragmented and largely closed publication ecosystem.\nTraditional journals and conferences rely on human peer review, making them\ndifficult to scale and often reluctant to accept AI-generated research content;\nexisting preprint servers (e.g. arXiv) lack rigorous quality-control\nmechanisms. Consequently, a significant amount of high-quality AI-generated\nresearch lacks appropriate venues for dissemination, hindering its potential to\nadvance scientific progress. To address these challenges, we introduce aiXiv, a\nnext-generation open-access platform for human and AI scientists. Its\nmulti-agent architecture allows research proposals and papers to be submitted,\nreviewed, and iteratively refined by both human and AI scientists. It also\nprovides API and MCP interfaces that enable seamless integration of\nheterogeneous human and AI scientists, creating a scalable and extensible\necosystem for autonomous scientific discovery. Through extensive experiments,\nwe demonstrate that aiXiv is a reliable and robust platform that significantly\nenhances the quality of AI-generated research proposals and papers after\niterative revising and reviewing on aiXiv. Our work lays the groundwork for a\nnext-generation open-access ecosystem for AI scientists, accelerating the\npublication and dissemination of high-quality AI-generated research content.\nCode is available at https://github.com/aixiv-org. Website is available at\nhttps://forms.gle/DxQgCtXFsJ4paMtn8.", "AI": {"tldr": "\u63d0\u51fa\u4e86aiXiv\u5e73\u53f0\uff0c\u89e3\u51b3AI\u751f\u6210\u7814\u7a76\u5185\u5bb9\u7f3a\u4e4f\u5408\u9002\u53d1\u8868\u6e20\u9053\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5b9e\u73b0\u4eba\u673a\u534f\u540c\u7684\u8bba\u6587\u63d0\u4ea4\u3001\u8bc4\u5ba1\u548c\u8fed\u4ee3\u6539\u8fdb", "motivation": "\u4f20\u7edf\u671f\u520a\u548c\u4f1a\u8bae\u96be\u4ee5\u63a5\u53d7AI\u751f\u6210\u7684\u7814\u7a76\u5185\u5bb9\uff0c\u73b0\u6709\u9884\u5370\u672c\u670d\u52a1\u5668\u7f3a\u4e4f\u8d28\u91cf\u63a7\u5236\u673a\u5236\uff0c\u5bfc\u81f4\u9ad8\u8d28\u91cfAI\u7814\u7a76\u6210\u679c\u7f3a\u4e4f\u5408\u9002\u7684\u4f20\u64ad\u6e20\u9053", "method": "\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5e73\u53f0\uff0c\u63d0\u4f9bAPI\u548cMCP\u63a5\u53e3\uff0c\u652f\u6301\u4eba\u7c7b\u548cAI\u79d1\u5b66\u5bb6\u65e0\u7f1d\u96c6\u6210\uff0c\u5b9e\u73b0\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\u7684\u63d0\u4ea4\u3001\u8bc4\u5ba1\u548c\u8fed\u4ee3\u7cbe\u70bc", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eaiXiv\u662f\u53ef\u9760\u7a33\u5065\u7684\u5e73\u53f0\uff0c\u7ecf\u8fc7\u8fed\u4ee3\u4fee\u8ba2\u548c\u8bc4\u5ba1\u540e\u663e\u8457\u63d0\u5347AI\u751f\u6210\u7814\u7a76\u63d0\u6848\u548c\u8bba\u6587\u7684\u8d28\u91cf", "conclusion": "\u4e3aAI\u79d1\u5b66\u5bb6\u5efa\u7acb\u4e86\u4e0b\u4e00\u4ee3\u5f00\u653e\u83b7\u53d6\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u52a0\u901f\u9ad8\u8d28\u91cfAI\u751f\u6210\u7814\u7a76\u5185\u5bb9\u7684\u53d1\u8868\u548c\u4f20\u64ad"}}
{"id": "2508.15144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15144", "abs": "https://arxiv.org/abs/2508.15144", "authors": ["Jiabo Ye", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Zhaoqing Zhu", "Ziwei Zheng", "Feiyu Gao", "Junjie Cao", "Zhengxi Lu", "Jitong Liao", "Qi Zheng", "Fei Huang", "Jingren Zhou", "Ming Yan"], "title": "Mobile-Agent-v3: Foundamental Agents for GUI Automation", "comment": null, "summary": "This paper introduces GUI-Owl, a foundational GUI agent model that achieves\nstate-of-the-art performance among open-source end-to-end models on ten GUI\nbenchmarks across desktop and mobile environments, covering grounding, question\nanswering, planning, decision-making, and procedural knowledge. GUI-Owl-7B\nachieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose\nMobile-Agent-v3, a general-purpose GUI agent framework that further improves\nperformance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new\nstate-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates\nthree key innovations: (1) Large-scale Environment Infrastructure: a\ncloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,\nenabling our Self-Evolving GUI Trajectory Production framework. This generates\nhigh-quality interaction data via automated query generation and correctness\nvalidation, leveraging GUI-Owl to refine trajectories iteratively, forming a\nself-improving loop. It supports diverse data pipelines and reduces manual\nannotation. (2) Diverse Foundational Agent Capabilities: by integrating UI\ngrounding, planning, action semantics, and reasoning patterns, GUI-Owl supports\nend-to-end decision-making and can act as a modular component in multi-agent\nsystems. (3) Scalable Environment RL: we develop a scalable reinforcement\nlearning framework with fully asynchronous training for real-world alignment.\nWe also introduce Trajectory-aware Relative Policy Optimization (TRPO) for\nonline RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are\nopen-sourced at https://github.com/X-PLUG/MobileAgent.", "AI": {"tldr": "GUI-Owl\u662f\u4e00\u4e2a\u57fa\u7840GUI\u4ee3\u7406\u6a21\u578b\uff0c\u572810\u4e2aGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0cMobile-Agent-v3\u6846\u67b6\u8fdb\u4e00\u6b65\u5c06\u6027\u80fd\u63d0\u5347\u81f373.3(AndroidWorld)\u548c37.7(OSWorld)\u3002", "motivation": "\u89e3\u51b3GUI\u4ee3\u7406\u5728\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u6267\u884c\u57fa\u7840\u4efb\u52a1\uff08\u5982\u5b9a\u4f4d\u3001\u95ee\u7b54\u3001\u89c4\u5212\u3001\u51b3\u7b56\u548c\u7a0b\u5e8f\u77e5\u8bc6\uff09\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u4f9b\u5f00\u6e90\u7684\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u5927\u89c4\u6a21\u4e91\u865a\u62df\u73af\u5883\u57fa\u7840\u8bbe\u65bd\u548c\u81ea\u6f14\u8fdbGUI\u8f68\u8ff9\u751f\u4ea7\u6846\u67b6\uff1b2\uff09\u96c6\u6210UI\u5b9a\u4f4d\u3001\u89c4\u5212\u3001\u52a8\u4f5c\u8bed\u4e49\u548c\u63a8\u7406\u6a21\u5f0f\u7684\u591a\u6837\u5316\u57fa\u7840\u4ee3\u7406\u80fd\u529b\uff1b3\uff09\u53ef\u6269\u5c55\u73af\u5883\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u548c\u8f68\u8ff9\u611f\u77e5\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(TRPO)\u3002", "result": "GUI-Owl-7B\u5728AndroidWorld\u8fbe\u523066.4\u5206\uff0cOSWorld\u8fbe\u523029.4\u5206\uff1bMobile-Agent-v3\u8fdb\u4e00\u6b65\u63d0\u5347\u81f373.3\u548c37.7\u5206\uff0c\u521b\u5f00\u6e90GUI\u4ee3\u7406\u6846\u67b6\u65b0\u7eaa\u5f55\uff1bTRPO\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728OSWorld\u8fbe\u523034.9\u5206\u3002", "conclusion": "GUI-Owl\u548cMobile-Agent-v3\u4e3aGUI\u4ee3\u7406\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u57fa\u7840\u8bbe\u65bd\u3001\u591a\u6837\u5316\u80fd\u529b\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86GUI\u4efb\u52a1\u7684\u6267\u884c\u6548\u679c\uff0c\u5e76\u652f\u6301\u591a\u4ee3\u7406\u7cfb\u7edf\u96c6\u6210\u3002"}}
{"id": "2508.15180", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15180", "abs": "https://arxiv.org/abs/2508.15180", "authors": ["Kai Xiong", "Yanwei Huang", "Rongjunchen Zhang", "Kun Chen", "Haipang Wu"], "title": "PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data", "comment": null, "summary": "High-quality mathematical and logical datasets with verifiable answers are\nessential for strengthening the reasoning capabilities of large language models\n(LLMs). While recent data augmentation techniques have facilitated the creation\nof large-scale benchmarks, existing LLM-generated datasets often suffer from\nlimited reliability, diversity, and scalability. To address these challenges,\nwe introduce PuzzleClone, a formal framework for synthesizing verifiable data\nat scale using Satisfiability Modulo Theories (SMT). Our approach features\nthree key innovations: (1) encoding seed puzzles into structured logical\nspecifications, (2) generating scalable variants through systematic variable\nand constraint randomization, and (3) ensuring validity via a reproduction\nmechanism. Applying PuzzleClone, we construct a curated benchmark comprising\nover 83K diverse and programmatically validated puzzles. The generated puzzles\nspan a wide spectrum of difficulty and formats, posing significant challenges\nto current state-of-the-art models. We conduct post training (SFT and RL) on\nPuzzleClone datasets. Experimental results show that training on PuzzleClone\nyields substantial improvements not only on PuzzleClone testset but also on\nlogic and mathematical benchmarks. Post training raises PuzzleClone average\nfrom 14.4 to 56.2 and delivers consistent improvements across 7 logic and\nmathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from\n52.5 to 65.0). Our code and data are available at\nhttps://github.com/puzzleclone.", "AI": {"tldr": "PuzzleClone\u662f\u4e00\u4e2a\u57fa\u4e8eSMT\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u5408\u6210\u53ef\u9a8c\u8bc1\u7684\u6570\u5b66\u903b\u8f91\u8c1c\u9898\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7f16\u7801\u79cd\u5b50\u8c1c\u9898\u3001\u7cfb\u7edf\u5316\u53d8\u91cf\u7ea6\u675f\u968f\u673a\u5316\u548c\u9a8c\u8bc1\u673a\u5236\uff0c\u6784\u5efa\u4e8683K+\u591a\u6837\u5316\u9a8c\u8bc1\u8c1c\u9898\uff0c\u663e\u8457\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u6570\u5b66\u903b\u8f91\u6570\u636e\u96c6\u5b58\u5728\u53ef\u9760\u6027\u3001\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u53ef\u9a8c\u8bc1\u7b54\u6848\u7684\u6570\u636e\u96c6\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b", "method": "\u4f7f\u7528\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba(SMT)\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u521b\u65b0\uff1a1)\u5c06\u79cd\u5b50\u8c1c\u9898\u7f16\u7801\u4e3a\u7ed3\u6784\u5316\u903b\u8f91\u89c4\u8303\uff1b2)\u901a\u8fc7\u7cfb\u7edf\u5316\u53d8\u91cf\u548c\u7ea6\u675f\u968f\u673a\u5316\u751f\u6210\u53ef\u6269\u5c55\u53d8\u4f53\uff1b3)\u901a\u8fc7\u91cd\u73b0\u673a\u5236\u786e\u4fdd\u6709\u6548\u6027", "result": "\u6784\u5efa\u4e86\u5305\u542b83K+\u591a\u6837\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u8c1c\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5728PuzzleClone\u6d4b\u8bd5\u96c6\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u4ece14.4\u63d0\u5347\u81f356.2\uff0c\u57287\u4e2a\u903b\u8f91\u6570\u5b66\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u9ad812.5\u4e2a\u767e\u5206\u70b9\u7684\u7edd\u5bf9\u63d0\u5347", "conclusion": "PuzzleClone\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u53ef\u9a8c\u8bc1\u6570\u5b66\u903b\u8f91\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347LLM\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u589e\u5f3a\u6a21\u578b\u6570\u5b66\u903b\u8f91\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6570\u636e\u5408\u6210\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.15192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15192", "abs": "https://arxiv.org/abs/2508.15192", "authors": ["Wenjie Lin", "Jin Wei-Kocsis"], "title": "LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support", "comment": null, "summary": "While large language models (LLMs) have shown promise in healthcare, their\napplication for rare medical conditions is still hindered by scarce and\nunreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing\nexcessive sweating beyond physiological needs, is one such rare disorder,\naffecting 2-3% of the population and significantly impacting both physical\ncomfort and psychosocial well-being. To date, no work has tailored LLMs to\nadvance the diagnosis or care of hyperhidrosis. To address this gap, we present\nLLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and\nempathetic hyperhidrosis support. The system follows a three-stage pipeline. In\nthe data augmentation stage, a frontier LLM generates medically plausible\nsynthetic vignettes from curated open-source data to create a diverse and\nbalanced question-answer dataset. In the fine-tuning stage, an open-source\nfoundation model is fine-tuned on the dataset to provide diagnosis,\npersonalized treatment recommendations, and empathetic psychological support.\nIn the inference and expert evaluation stage, clinical and psychological\nspecialists assess accuracy, appropriateness, and empathy, with validated\nresponses iteratively enriching the dataset. Experiments show that LLM4Sweat\noutperforms baselines and delivers the first open-source LLM framework for\nhyperhidrosis, offering a generalizable approach for other rare diseases with\nsimilar data and trustworthiness challenges.", "AI": {"tldr": "LLM4Sweat\u662f\u4e00\u4e2a\u9488\u5bf9\u7f55\u89c1\u75c5\u591a\u6c57\u75c7\u7684\u5f00\u6e90LLM\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u3001\u5fae\u8c03\u548c\u4e13\u5bb6\u8bc4\u4f30\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u63d0\u4f9b\u53ef\u4fe1\u8d56\u4e14\u5bcc\u6709\u540c\u7406\u5fc3\u7684\u533b\u7597\u652f\u6301\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u53d7\u5230\u7f55\u89c1\u75c5\u6570\u636e\u7a00\u7f3a\u548c\u4e0d\u53ef\u9760\u7684\u9650\u5236\uff0c\u591a\u6c57\u75c7\u4f5c\u4e3a\u5f71\u54cd2-3%\u4eba\u7fa4\u7684\u7f55\u89c1\u75c5\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e13\u95e8\u7684LLM\u652f\u6301\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1\uff09\u4f7f\u7528\u524d\u6cbfLLM\u4ece\u5f00\u6e90\u6570\u636e\u751f\u6210\u533b\u5b66\u4e0a\u5408\u7406\u7684\u5408\u6210\u6848\u4f8b\uff1b2\uff09\u5728\u589e\u5f3a\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u5f00\u6e90\u57fa\u7840\u6a21\u578b\uff1b3\uff09\u4e34\u5e8a\u548c\u5fc3\u7406\u4e13\u5bb6\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u9002\u5f53\u6027\u548c\u540c\u7406\u5fc3\uff0c\u5e76\u901a\u8fc7\u9a8c\u8bc1\u54cd\u5e94\u8fed\u4ee3\u4e30\u5bcc\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLM4Sweat\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u9996\u4e2a\u9488\u5bf9\u591a\u6c57\u75c7\u7684\u5f00\u6e90LLM\u6846\u67b6\uff0c\u4e3a\u5176\u4ed6\u5177\u6709\u7c7b\u4f3c\u6570\u636e\u548c\u53ef\u4fe1\u5ea6\u6311\u6218\u7684\u7f55\u89c1\u75be\u75c5\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u591a\u6c57\u75c7\u7684LLM\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u589e\u5f3a\u548c\u4e13\u5bb6\u9a8c\u8bc1\u65b9\u6cd5\u89e3\u51b3\u4e86\u7f55\u89c1\u75c5\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4e3a\u7f55\u89c1\u75c5\u533b\u7597AI\u652f\u6301\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2508.15204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15204", "abs": "https://arxiv.org/abs/2508.15204", "authors": ["Raj Jain", "Marc Wetter"], "title": "R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling", "comment": null, "summary": "Effective scheduling under tight resource, timing, and operational\nconstraints underpins large-scale planning across sectors such as capital\nprojects, manufacturing, logistics, and IT fleet transitions. However, the\nreliability of large language models (LLMs) when reasoning under\nhigh-constraint regimes is insufficiently characterized. To address this gap,\nwe present R-ConstraintBench, a scalable framework that evaluates models on\nResource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete\nfeasibility class, while difficulty increases via linear growth in constraints.\nR-ConstraintBench incrementally increases non-redundant precedence constraints\nin Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal\nwindows, and disjunctive constraints. As an illustrative example, we\ninstantiate the benchmark in a data center migration setting and evaluate\nmultiple LLMs using feasibility and error analysis, identifying degradation\nthresholds and constraint types most associated with failure. Empirically,\nstrong models are near-ceiling on precedence-only DAGs, but feasibility\nperformance collapses when downtime, temporal windows, and disjunctive\nconstraints interact, implicating constraint interaction, not graph depth, as\nthe principal bottleneck. Performance on clean synthetic ramps also does not\nguarantee transfer to domain-grounded scenarios, underscoring limited\ngeneralization.", "AI": {"tldr": "R-ConstraintBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u7ea6\u675f\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\u4e2d\u63a8\u7406\u80fd\u529b\u7684\u6846\u67b6\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4ec5\u6709\u4f18\u5148\u7ea6\u675f\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5f15\u5165\u505c\u673a\u65f6\u95f4\u3001\u65f6\u95f4\u7a97\u53e3\u548c\u5206\u79bb\u7ea6\u675f\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e25\u683c\u8d44\u6e90\u3001\u65f6\u95f4\u548c\u64cd\u4f5c\u7ea6\u675f\u4e0b\u7684\u63a8\u7406\u53ef\u9760\u6027\u7f3a\u4e4f\u5145\u5206\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ea6\u675f\u673a\u5236\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5f00\u53d1R-ConstraintBench\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6709\u5411\u65e0\u73af\u56fe\u4e2d\u9010\u6b65\u589e\u52a0\u975e\u5197\u4f59\u4f18\u5148\u7ea6\u675f\uff0c\u7136\u540e\u5f15\u5165\u505c\u673a\u65f6\u95f4\u3001\u65f6\u95f4\u7a97\u53e3\u548c\u5206\u79bb\u7ea6\u675f\u6765\u8bc4\u4f30LLMs\u7684\u6027\u80fd\u3002", "result": "\u5f3a\u6a21\u578b\u5728\u4ec5\u6709\u4f18\u5148\u7ea6\u675f\u7684DAG\u4e0a\u8868\u73b0\u63a5\u8fd1\u4e0a\u9650\uff0c\u4f46\u5f53\u591a\u79cd\u7ea6\u675f\u7c7b\u578b\u76f8\u4e92\u4f5c\u7528\u65f6\u53ef\u884c\u6027\u6027\u80fd\u5d29\u6e83\uff0c\u7ea6\u675f\u4ea4\u4e92\u662f\u4e3b\u8981\u74f6\u9888\u800c\u975e\u56fe\u6df1\u5ea6\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7ea6\u675f\u4ea4\u4e92\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u5408\u6210\u6d4b\u8bd5\u7684\u6027\u80fd\u4e0d\u80fd\u4fdd\u8bc1\u5728\u9886\u57df\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u8fc1\u79fb\u6548\u679c\u3002"}}
{"id": "2508.15222", "categories": ["cs.AI", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15222", "abs": "https://arxiv.org/abs/2508.15222", "authors": ["Hantao Zhang", "Jingyang Liu", "Ed Li"], "title": "See it. Say it. Sorted: Agentic System for Compositional Diagram Generation", "comment": null, "summary": "We study sketch-to-diagram generation: converting rough hand sketches into\nprecise, compositional diagrams. Diffusion models excel at photorealism but\nstruggle with the spatial precision, alignment, and symbolic structure required\nfor flowcharts. We introduce See it. Say it. Sorted., a training-free agentic\nsystem that couples a Vision-Language Model (VLM) with Large Language Models\n(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system\nruns an iterative loop in which a Critic VLM proposes a small set of\nqualitative, relational edits; multiple candidate LLMs synthesize SVG updates\nwith diverse strategies (conservative->aggressive, alternative, focused); and a\nJudge VLM selects the best candidate, ensuring stable improvement. This design\nprioritizes qualitative reasoning over brittle numerical estimates, preserves\nglobal constraints (e.g., alignment, connectivity), and naturally supports\nhuman-in-the-loop corrections. On 10 sketches derived from flowcharts in\npublished papers, our method more faithfully reconstructs layout and structure\nthan two frontier closed-source image generation LLMs (GPT-5 and\nGemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)\nwithout inserting unwanted text. Because outputs are programmatic SVGs, the\napproach is readily extensible to presentation tools (e.g., PowerPoint) via\nAPIs and can be specialized with improved prompts and task-specific tools. The\ncodebase is open-sourced at\nhttps://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.", "AI": {"tldr": "\u63d0\u51faSee it. Say it. Sorted.\u7cfb\u7edf\uff0c\u901a\u8fc7VLM\u548cLLM\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u5c06\u624b\u7ed8\u8349\u56fe\u8f6c\u6362\u4e3a\u7cbe\u786e\u7684\u53ef\u7f16\u8f91SVG\u56fe\u8868\uff0c\u5728\u6d41\u7a0b\u56fe\u751f\u6210\u4e0a\u4f18\u4e8eGPT-5\u548cGemini-2.5-Pro\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7a7a\u95f4\u7cbe\u5ea6\u3001\u5bf9\u9f50\u548c\u7b26\u53f7\u7ed3\u6784\u7b49\u6d41\u7a0b\u56fe\u751f\u6210\u6240\u9700\u7684\u5173\u952e\u80fd\u529b\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4ea7\u751f\u7cbe\u786e\u3001\u53ef\u7f16\u8f91\u56fe\u8868\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8bad\u7ec3\u514d\u8d39\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u548c\u5927\u8bed\u8a00\u6a21\u578b(LLM)\uff0c\u901a\u8fc7\u8fed\u4ee3\u5faa\u73af\uff1a\u6279\u8bc4VLM\u63d0\u51fa\u7f16\u8f91\u5efa\u8bae\uff0c\u591a\u4e2a\u5019\u9009LLM\u751f\u6210SVG\u66f4\u65b0\uff0c\u6cd5\u5b98VLM\u9009\u62e9\u6700\u4f73\u5019\u9009\uff0c\u786e\u4fdd\u7a33\u5b9a\u6539\u8fdb\u3002", "result": "\u572810\u4e2a\u6765\u81ea\u5df2\u53d1\u8868\u8bba\u6587\u6d41\u7a0b\u56fe\u7684\u8349\u56fe\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4GPT-5\u548cGemini-2.5-Pro\u66f4\u51c6\u786e\u5730\u91cd\u5efa\u5e03\u5c40\u548c\u7ed3\u6784\uff0c\u80fd\u591f\u7cbe\u786e\u7ec4\u5408\u56fe\u5143\u800c\u4e0d\u63d2\u5165\u4e0d\u9700\u8981\u7684\u6587\u672c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f18\u5148\u8003\u8651\u5b9a\u6027\u63a8\u7406\u800c\u975e\u8106\u5f31\u7684\u6570\u503c\u4f30\u8ba1\uff0c\u4fdd\u6301\u5168\u5c40\u7ea6\u675f\uff0c\u652f\u6301\u4eba\u5de5\u5e72\u9884\uff0c\u8f93\u51fa\u4e3a\u7a0b\u5e8f\u5316SVG\uff0c\u53ef\u901a\u8fc7API\u8f7b\u677e\u6269\u5c55\u5230\u6f14\u793a\u5de5\u5177\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.15240", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15240", "abs": "https://arxiv.org/abs/2508.15240", "authors": ["Sabab Aosaf", "Muhammad Ali Nayeem", "Afsana Haque", "M Sohel Rahmana"], "title": "Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas", "comment": null, "summary": "Urban land-use allocation represents a complex multi-objective optimization\nproblem critical for sustainable urban development policy. This paper presents\nnovel computational intelligence approaches for optimizing land-use allocation\nin mixed-use areas, addressing inherent trade-offs between land-use\ncompatibility and economic objectives. We develop multiple optimization\nalgorithms, including custom variants integrating differential evolution with\nmulti-objective genetic algorithms. Key contributions include: (1) CR+DES\nalgorithm leveraging scaled difference vectors for enhanced exploration, (2)\nsystematic constraint relaxation strategy improving solution quality while\nmaintaining feasibility, and (3) statistical validation using Kruskal-Wallis\ntests with compact letter displays. Applied to a real-world case study with\n1,290 plots, CR+DES achieves 3.16\\% improvement in land-use compatibility\ncompared to state-of-the-art methods, while MSBX+MO excels in price\noptimization with 3.3\\% improvement. Statistical analysis confirms algorithms\nincorporating difference vectors significantly outperform traditional\napproaches across multiple metrics. The constraint relaxation technique enables\nbroader solution space exploration while maintaining practical constraints.\nThese findings provide urban planners and policymakers with evidence-based\ncomputational tools for balancing competing objectives in land-use allocation,\nsupporting more effective urban development policies in rapidly urbanizing\nregions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u79cd\u8ba1\u7b97\u667a\u80fd\u7b97\u6cd5\u4f18\u5316\u6df7\u5408\u7528\u9014\u533a\u571f\u5730\u5229\u7528\u914d\u7f6e\uff0cCR+DES\u7b97\u6cd5\u5728\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u4e0a\u63d0\u53473.16%\uff0cMSBX+MO\u5728\u4ef7\u683c\u4f18\u5316\u4e0a\u63d0\u53473.3%\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u9a8c\u8bc1\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u571f\u5730\u5229\u7528\u914d\u7f6e\u4e2d\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u4e0e\u7ecf\u6d4e\u76ee\u6807\u4e4b\u95f4\u7684\u5185\u5728\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u53ef\u6301\u7eed\u57ce\u5e02\u53d1\u5c55\u653f\u7b56\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u79cd\u4f18\u5316\u7b97\u6cd5\uff0c\u5305\u62ec\u7ed3\u5408\u5dee\u5206\u8fdb\u5316\u548c\u591a\u76ee\u6807\u9057\u4f20\u7b97\u6cd5\u7684\u5b9a\u5236\u53d8\u4f53\uff0c\u91c7\u7528\u7ea6\u675f\u677e\u5f1b\u7b56\u7565\u548cKruskal-Wallis\u7edf\u8ba1\u68c0\u9a8c\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u57281,290\u4e2a\u5730\u5757\u7684\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cCR+DES\u7b97\u6cd5\u5728\u571f\u5730\u5229\u7528\u517c\u5bb9\u6027\u4e0a\u5b9e\u73b03.16%\u7684\u63d0\u5347\uff0cMSBX+MO\u5728\u4ef7\u683c\u4f18\u5316\u4e0a\u5b9e\u73b03.3%\u7684\u63d0\u5347\uff0c\u7edf\u8ba1\u8bc1\u5b9e\u542b\u5dee\u5206\u5411\u91cf\u7684\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u4e9b\u8ba1\u7b97\u5de5\u5177\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u571f\u5730\u5229\u7528\u914d\u7f6e\u4e2d\u7684\u7ade\u4e89\u76ee\u6807\uff0c\u652f\u6301\u5feb\u901f\u57ce\u5e02\u5316\u5730\u533a\u66f4\u6709\u6548\u7684\u57ce\u5e02\u53d1\u5c55\u653f\u7b56\u3002"}}
{"id": "2508.15294", "categories": ["cs.AI", "cs.CL", "cs.MA", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15294", "abs": "https://arxiv.org/abs/2508.15294", "authors": ["Gaoke Zhang", "Bo Wang", "Yunlong Ma", "Dongming Zhao", "Zifei Yu"], "title": "Multiple Memory Systems for Enhancing the Long-term Memory of Agent", "comment": null, "summary": "An agent powered by large language models have achieved impressive results,\nbut effectively handling the vast amounts of historical data generated during\ninteractions remains a challenge. The current approach is to design a memory\nmodule for the agent to process these data. However, existing methods, such as\nMemoryBank and A-MEM, have poor quality of stored memory content, which affects\nrecall performance and response quality. In order to better construct\nhigh-quality long-term memory content, we have designed a multiple memory\nsystem (MMS) inspired by cognitive psychology theory. The system processes\nshort-term memory to multiple long-term memory fragments, and constructs\nretrieval memory units and contextual memory units based on these fragments,\nwith a one-to-one correspondence between the two. During the retrieval phase,\nMMS will match the most relevant retrieval memory units based on the user's\nquery. Then, the corresponding contextual memory units is obtained as the\ncontext for the response stage to enhance knowledge, thereby effectively\nutilizing historical data. Experiments on LoCoMo dataset compared our method\nwith three others, proving its effectiveness. Ablation studies confirmed the\nrationality of our memory units. We also analyzed the robustness regarding the\nnumber of selected memory segments and the storage overhead, demonstrating its\npractical value.", "AI": {"tldr": "\u57fa\u4e8e\u8ba4\u77e5\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u591a\u91cd\u8bb0\u5fc6\u7cfb\u7edf(MMS)\uff0c\u901a\u8fc7\u5c06\u77ed\u671f\u8bb0\u5fc6\u5904\u7406\u6210\u591a\u4e2a\u957f\u671f\u8bb0\u5fc6\u7247\u6bb5\uff0c\u6784\u5efa\u68c0\u7d22\u8bb0\u5fc6\u5355\u5143\u548c\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u5355\u5143\uff0c\u63d0\u5347\u4e86\u8bb0\u5fc6\u8d28\u91cf\u548c\u56de\u5fc6\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bb0\u5fc6\u6a21\u5757\u5982MemoryBank\u548cA-MEM\u7684\u5b58\u50a8\u8bb0\u5fc6\u5185\u5bb9\u8d28\u91cf\u5dee\uff0c\u5f71\u54cd\u56de\u5fc6\u6027\u80fd\u548c\u54cd\u5e94\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u597d\u5904\u7406\u5927\u91cf\u5386\u53f2\u4ea4\u4e92\u6570\u636e\u3002", "method": "\u53d7\u8ba4\u77e5\u5fc3\u7406\u5b66\u542f\u53d1\u8bbe\u8ba1\u591a\u91cd\u8bb0\u5fc6\u7cfb\u7edf(MMS)\uff0c\u5c06\u77ed\u671f\u8bb0\u5fc6\u5904\u7406\u6210\u591a\u4e2a\u957f\u671f\u8bb0\u5fc6\u7247\u6bb5\uff0c\u6784\u5efa\u68c0\u7d22\u8bb0\u5fc6\u5355\u5143\u548c\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u5355\u5143\uff0c\u4e24\u8005\u4e00\u4e00\u5bf9\u5e94\u3002\u68c0\u7d22\u9636\u6bb5\u5339\u914d\u76f8\u5173\u68c0\u7d22\u8bb0\u5fc6\u5355\u5143\u540e\u83b7\u53d6\u5bf9\u5e94\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u4f5c\u4e3a\u54cd\u5e94\u4e0a\u4e0b\u6587\u3002", "result": "\u5728LoCoMo\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\uff0c\u6d88\u878d\u5b9e\u9a8c\u786e\u8ba4\u4e86\u8bb0\u5fc6\u5355\u5143\u7684\u5408\u7406\u6027\uff0c\u5206\u6790\u663e\u793a\u5176\u5177\u6709\u7a33\u5065\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "MMS\u7cfb\u7edf\u80fd\u591f\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u957f\u671f\u8bb0\u5fc6\u5185\u5bb9\uff0c\u6709\u6548\u5229\u7528\u5386\u53f2\u6570\u636e\u63d0\u5347\u4ee3\u7406\u5668\u6027\u80fd\u3002"}}
{"id": "2508.15305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15305", "abs": "https://arxiv.org/abs/2508.15305", "authors": ["Wei Yang", "Jinwei Xiao", "Hongming Zhang", "Qingyang Zhang", "Yanna Wang", "Bo Xu"], "title": "Coarse-to-Fine Grounded Memory for LLM Agent Planning", "comment": "Accepted to EMNLP 2025 Main Conference;27 pages,15 figures", "summary": "Recent advancements in Large Language Models (LLMs) have driven growing\ninterest in LLM-based agents for complex planning tasks. To avoid costly agent\ntraining, many studies adopted memory mechanism that enhances LLM with offline\nexperiences or online trajectory analysis. However, existing works focus on\nsingle-granularity memory derived from dynamic environmental interactions,\nwhich are inherently constrained by the quality of the collected experiences.\nThis limitation, in turn, constrain the diversity of knowledge and the\nflexibility of planning. We propose Coarse-to-Fine Grounded Memory (\\Ours{}), a\nnovel framework that grounds coarse-to-fine memories with LLM, thereby fully\nleverage them for flexible adaptation to diverse scenarios. \\Ours{} grounds\nenvironmental information into coarse-grained focus points to guide experience\ncollection in training tasks, followed by grounding of actionable\nhybrid-grained tips from each experience. At inference, \\Ours{} retrieves\ntask-relevant experiences and tips to support planning. When facing\nenvironmental anomalies, the LLM grounds the current situation into\nfine-grained key information, enabling flexible self-QA reflection and plan\ncorrection.", "AI": {"tldr": "\u63d0\u51fa\u4e86Coarse-to-Fine Grounded Memory\u6846\u67b6\uff0c\u901a\u8fc7\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u8bb0\u5fc6\u673a\u5236\u589e\u5f3aLLM\u5728\u590d\u6742\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u73b0\u6709\u5355\u7c92\u5ea6\u8bb0\u5fc6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u4e3b\u8981\u4f9d\u8d56\u5355\u7c92\u5ea6\u8bb0\u5fc6\u673a\u5236\uff0c\u53d7\u9650\u4e8e\u6536\u96c6\u7ecf\u9a8c\u7684\u8d28\u91cf\uff0c\u5bfc\u81f4\u77e5\u8bc6\u591a\u6837\u6027\u548c\u89c4\u5212\u7075\u6d3b\u6027\u4e0d\u8db3\u3002\u9700\u8981\u66f4\u7075\u6d3b\u7684\u8bb0\u5fc6\u6846\u67b6\u6765\u9002\u5e94\u591a\u6837\u5316\u573a\u666f\u3002", "method": "\u63d0\u51fa\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u8bb0\u5fc6\u6846\u67b6\uff1a1\uff09\u5728\u8bad\u7ec3\u4efb\u52a1\u4e2d\u5c06\u73af\u5883\u4fe1\u606f\u8f6c\u5316\u4e3a\u7c97\u7c92\u5ea6\u5173\u6ce8\u70b9\u6307\u5bfc\u7ecf\u9a8c\u6536\u96c6\uff1b2\uff09\u4ece\u6bcf\u4e2a\u7ecf\u9a8c\u4e2d\u63d0\u53d6\u53ef\u64cd\u4f5c\u7684\u6df7\u5408\u7c92\u5ea6\u63d0\u793a\uff1b3\uff09\u63a8\u7406\u65f6\u68c0\u7d22\u4efb\u52a1\u76f8\u5173\u7ecf\u9a8c\u548c\u63d0\u793a\uff1b4\uff09\u9762\u5bf9\u5f02\u5e38\u65f6\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5173\u952e\u4fe1\u606f\u63d0\u53d6\u548c\u81ea\u6211\u95ee\u7b54\u53cd\u601d\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u5145\u5206\u5730\u5229\u7528\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u7075\u6d3b\u7684\u573a\u666f\u9002\u5e94\uff0c\u7279\u522b\u662f\u5728\u73af\u5883\u5f02\u5e38\u60c5\u51b5\u4e0b\u80fd\u591f\u8fdb\u884c\u6709\u6548\u7684\u8ba1\u5212\u4fee\u6b63\u3002", "conclusion": "Coarse-to-Fine Grounded Memory\u6846\u67b6\u901a\u8fc7\u591a\u7c92\u5ea6\u8bb0\u5fc6\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u548c\u7075\u6d3b\u6027\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u673a\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.15327", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15327", "abs": "https://arxiv.org/abs/2508.15327", "authors": ["Xiancheng Gao", "Yufeng Shi", "Wengang Zhou", "Houqiang Li"], "title": "Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning", "comment": "7 pages, 6 figures, under review", "summary": "Offline reinforcement learning refers to the process of learning policies\nfrom fixed datasets, without requiring additional environment interaction.\nHowever, it often relies on well-defined reward functions, which are difficult\nand expensive to design. Human feedback is an appealing alternative, but its\ntwo common forms, expert demonstrations and preferences, have complementary\nlimitations. Demonstrations provide stepwise supervision, but they are costly\nto collect and often reflect limited expert behavior modes. In contrast,\npreferences are easier to collect, but it is unclear which parts of a behavior\ncontribute most to a trajectory segment, leaving credit assignment unresolved.\nIn this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to\nunify these two feedback sources. For each transition in a preference labeled\ntrajectory, SPW searches for the most similar state-action pairs from expert\ndemonstrations and directly derives stepwise importance weights based on their\nsimilarity scores. These weights are then used to guide standard preference\nlearning, enabling more accurate credit assignment that traditional approaches\nstruggle to achieve. We demonstrate that SPW enables effective joint learning\nfrom preferences and demonstrations, outperforming prior methods that leverage\nboth feedback types on challenging robot manipulation tasks.", "AI": {"tldr": "\u63d0\u51faSPW\u65b9\u6cd5\u7edf\u4e00\u4eba\u7c7b\u53cd\u9988\u7684\u4e24\u79cd\u5f62\u5f0f\uff08\u4e13\u5bb6\u6f14\u793a\u548c\u504f\u597d\uff09\uff0c\u901a\u8fc7\u641c\u7d22\u76f8\u4f3c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u6765\u5206\u914d\u6743\u91cd\uff0c\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u4f9d\u8d56\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4f46\u8bbe\u8ba1\u6210\u672c\u9ad8\u3002\u4eba\u7c7b\u53cd\u9988\u662f\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u4e13\u5bb6\u6f14\u793a\u6210\u672c\u9ad8\u4e14\u6a21\u5f0f\u6709\u9650\uff0c\u504f\u597d\u6570\u636e\u5bb9\u6613\u6536\u96c6\u4f46\u4fe1\u7528\u5206\u914d\u4e0d\u660e\u786e", "method": "SPW\u65b9\u6848\uff1a\u5728\u504f\u597d\u6807\u8bb0\u8f68\u8ff9\u4e2d\u641c\u7d22\u4e0e\u4e13\u5bb6\u6f14\u793a\u6700\u76f8\u4f3c\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u5f97\u5206\u76f4\u63a5\u63a8\u5bfc\u9010\u6b65\u91cd\u8981\u6027\u6743\u91cd\uff0c\u6307\u5bfc\u6807\u51c6\u504f\u597d\u5b66\u4e60", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\uff0cSPW\u80fd\u591f\u6709\u6548\u8054\u5408\u5b66\u4e60\u504f\u597d\u548c\u6f14\u793a\u6570\u636e\uff0c\u6027\u80fd\u4f18\u4e8e\u4e4b\u524d\u5229\u7528\u4e24\u79cd\u53cd\u9988\u7c7b\u578b\u7684\u65b9\u6cd5", "conclusion": "SPW\u6210\u529f\u7edf\u4e00\u4e86\u4e24\u79cd\u4eba\u7c7b\u53cd\u9988\u6e90\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u7684\u51c6\u786e\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5b66\u4e60\u6846\u67b6"}}
{"id": "2508.15335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15335", "abs": "https://arxiv.org/abs/2508.15335", "authors": ["Bin Deng", "Yizhe Feng", "Zeming Liu", "Qing Wei", "Xiangrong Zhu", "Shuai Chen", "Yuanfang Guo", "Yunhong Wang"], "title": "RETAIL: Towards Real-world Travel Planning for Large Language Models", "comment": null, "summary": "Although large language models have enhanced automated travel planning\nabilities, current systems remain misaligned with real-world scenarios. First,\nthey assume users provide explicit queries, while in reality requirements are\noften implicit. Second, existing solutions ignore diverse environmental factors\nand user preferences, limiting the feasibility of plans. Third, systems can\nonly generate plans with basic POI arrangements, failing to provide all-in-one\nplans with rich details. To mitigate these challenges, we construct a novel\ndataset \\textbf{RETAIL}, which supports decision-making for implicit queries\nwhile covering explicit queries, both with and without revision needs. It also\nenables environmental awareness to ensure plan feasibility under real-world\nscenarios, while incorporating detailed POI information for all-in-one travel\nplans. Furthermore, we propose a topic-guided multi-agent framework, termed\nTGMA. Our experiments reveal that even the strongest existing model achieves\nmerely a 1.0% pass rate, indicating real-world travel planning remains\nextremely challenging. In contrast, TGMA demonstrates substantially improved\nperformance 2.72%, offering promising directions for real-world travel\nplanning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RETAIL\u6570\u636e\u96c6\u548cTGMA\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709\u65c5\u884c\u89c4\u5212\u7cfb\u7edf\u5728\u9690\u5f0f\u67e5\u8be2\u3001\u73af\u5883\u56e0\u7d20\u548c\u8be6\u7ec6\u89c4\u5212\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u65c5\u884c\u89c4\u5212\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u65c5\u884c\u89c4\u5212\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u5047\u8bbe\u7528\u6237\u63d0\u4f9b\u663e\u5f0f\u67e5\u8be2\uff0c\u800c\u73b0\u5b9e\u4e2d\u9700\u6c42\u5f80\u5f80\u662f\u9690\u5f0f\u7684\uff1b2\uff09\u5ffd\u7565\u73af\u5883\u56e0\u7d20\u548c\u7528\u6237\u504f\u597d\uff0c\u5bfc\u81f4\u8ba1\u5212\u4e0d\u53ef\u884c\uff1b3\uff09\u53ea\u80fd\u751f\u6210\u57fa\u672c\u7684POI\u5b89\u6392\uff0c\u7f3a\u4e4f\u8be6\u7ec6\u7684\u4e00\u7ad9\u5f0f\u89c4\u5212\u65b9\u6848\u3002", "method": "\u6784\u5efa\u4e86RETAIL\u6570\u636e\u96c6\u652f\u6301\u9690\u5f0f\u548c\u663e\u5f0f\u67e5\u8be2\u7684\u51b3\u7b56\uff0c\u5e76\u63d0\u51fa\u4e86\u4e3b\u9898\u5f15\u5bfc\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6TGMA\uff0c\u8be5\u6846\u67b6\u5177\u5907\u73af\u5883\u611f\u77e5\u80fd\u529b\uff0c\u80fd\u591f\u751f\u6210\u5305\u542b\u4e30\u5bcc\u7ec6\u8282\u7684\u4e00\u7ad9\u5f0f\u65c5\u884c\u8ba1\u5212\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u6700\u5f3a\u6a21\u578b\u4ec5\u8fbe\u52301.0%\u7684\u901a\u8fc7\u7387\uff0c\u800cTGMA\u6846\u67b6\u5c06\u6027\u80fd\u63d0\u5347\u81f32.72%\uff0c\u8868\u660e\u5728\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "TGMA\u6846\u67b6\u4e3a\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u89c4\u5212\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u867d\u7136\u5f53\u524d\u6027\u80fd\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u4f46\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5df2\u7ecf\u6709\u4e86\u5b9e\u8d28\u6027\u6539\u8fdb\u3002"}}
{"id": "2508.15338", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15338", "abs": "https://arxiv.org/abs/2508.15338", "authors": ["Jinning Yang", "Wen Shi"], "title": "DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization", "comment": null, "summary": "Electrocardiography plays a central role in cardiovascular diagnostics, yet\nexisting automated approaches often struggle to generalize across clinical\ntasks and offer limited support for open-ended reasoning. We present DiagECG, a\nnovel framework that integrates time-series and language modeling by enabling\nlarge language models to process 12-lead ECG signals for clinical text\ngeneration tasks. Our approach discretizes continuous ECG embeddings into\nsymbolic tokens using a lead-independent encoder and quantization module. These\ntokens are then used to extend the vocabulary of LLM, allowing the model to\nhandle both ECG and natural language inputs in a unified manner. To bridge the\nmodality gap, we pretrain the model on an autoregressive ECG forecasting task,\nenabling the LLM to model temporal dynamics using its native language modeling\ncapabilities. Finally, we perform instruction tuning on both ECG question\nanswering and diagnostic report generation. Without modifying the core model,\nDiagECG achieves strong performance across tasks while maintaining\ngeneralization to out-of-distribution settings. Extensive experiments\ndemonstrate the effectiveness of each component and highlight the potential of\nintegrating symbolic ECG representations into LLMs for medical reasoning.", "AI": {"tldr": "DiagECG\u662f\u4e00\u4e2a\u5c06\u5fc3\u7535\u56fe\u4fe1\u53f7\u4e0e\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u5316ECG\u5d4c\u5165\u5230\u7b26\u53f7\u6807\u8bb0\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5904\u740612\u5bfc\u8054\u5fc3\u7535\u56fe\u5e76\u751f\u6210\u4e34\u5e8a\u6587\u672c\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u5fc3\u7535\u56fe\u5206\u6790\u65b9\u6cd5\u5728\u8de8\u4e34\u5e8a\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u548c\u5f00\u653e\u5f0f\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7edf\u4e00\u5904\u7406\u5fc3\u7535\u56fe\u4fe1\u53f7\u548c\u81ea\u7136\u8bed\u8a00\u7684\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u5bfc\u8054\u65e0\u5173\u7f16\u7801\u5668\u548c\u91cf\u5316\u6a21\u5757\u5c06\u8fde\u7eedECG\u5d4c\u5165\u79bb\u6563\u5316\u4e3a\u7b26\u53f7\u6807\u8bb0\uff0c\u6269\u5c55LLM\u8bcd\u6c47\u8868\uff1b\u901a\u8fc7\u81ea\u56de\u5f52ECG\u9884\u6d4b\u4efb\u52a1\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u6700\u540e\u5728ECG\u95ee\u7b54\u548c\u8bca\u65ad\u62a5\u544a\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\u3002", "result": "DiagECG\u5728\u4e0d\u4fee\u6539\u6838\u5fc3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u53d6\u5f97\u5f3a\u52b2\u6027\u80fd\uff0c\u5e76\u4fdd\u6301\u5bf9\u5206\u5e03\u5916\u8bbe\u7f6e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5c06\u7b26\u53f7\u5316ECG\u8868\u793a\u6574\u5408\u5230LLM\u4e2d\u8fdb\u884c\u533b\u5b66\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u4e3a\u5fc3\u8840\u7ba1\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15358", "abs": "https://arxiv.org/abs/2508.15358", "authors": ["Alberto Pozanco", "Marianela Morales", "Daniel Borrajo", "Manuela Veloso"], "title": "Planning with Minimal Disruption", "comment": null, "summary": "In many planning applications, we might be interested in finding plans that\nminimally modify the initial state to achieve the goals. We refer to this\nconcept as plan disruption. In this paper, we formally introduce it, and define\nvarious planning-based compilations that aim to jointly optimize both the sum\nof action costs and plan disruption. Experimental results in different\nbenchmarks show that the reformulated task can be effectively solved in\npractice to generate plans that balance both objectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8ba1\u5212\u5e72\u6270\u7684\u6982\u5ff5\uff0c\u65e8\u5728\u5bfb\u627e\u6700\u5c0f\u5316\u521d\u59cb\u72b6\u6001\u4fee\u6539\u6765\u5b9e\u73b0\u76ee\u6807\u7684\u8ba1\u5212\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u89c4\u5212\u7f16\u8bd1\u65b9\u6cd5\u8054\u5408\u4f18\u5316\u884c\u52a8\u6210\u672c\u548c\u8ba1\u5212\u5e72\u6270\u3002", "motivation": "\u5728\u8bb8\u591a\u89c4\u5212\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u5b9e\u73b0\u76ee\u6807\u53c8\u5c3d\u53ef\u80fd\u5c11\u6539\u53d8\u521d\u59cb\u72b6\u6001\u7684\u8ba1\u5212\uff0c\u8fd9\u79cd\u9700\u6c42\u4fc3\u4f7f\u4e86\u8ba1\u5212\u5e72\u6270\u6982\u5ff5\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u7814\u7a76\u3002", "method": "\u5b9a\u4e49\u4e86\u8ba1\u5212\u5e72\u6270\u7684\u6b63\u5f0f\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u57fa\u4e8e\u89c4\u5212\u7684\u7f16\u8bd1\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u4f18\u5316\u884c\u52a8\u6210\u672c\u603b\u548c\u548c\u8ba1\u5212\u5e72\u6270\u7a0b\u5ea6\u3002", "result": "\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91cd\u65b0\u8868\u8ff0\u7684\u4efb\u52a1\u53ef\u4ee5\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\u89e3\u51b3\uff0c\u751f\u6210\u80fd\u591f\u5e73\u8861\u4e24\u4e2a\u76ee\u6807\u7684\u8ba1\u5212\u3002", "conclusion": "\u8ba1\u5212\u5e72\u6270\u662f\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u89c4\u5212\u6982\u5ff5\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u7f16\u8bd1\u65b9\u6cd5\u53ef\u4ee5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u751f\u6210\u65e2\u7ecf\u6d4e\u53c8\u6700\u5c0f\u5316\u72b6\u6001\u6539\u53d8\u7684\u8ba1\u5212\u3002"}}
{"id": "2508.15432", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15432", "abs": "https://arxiv.org/abs/2508.15432", "authors": ["Bidyapati Pradhan", "Surajit Dasgupta", "Amit Kumar Saha", "Omkar Anustoop", "Sriram Puttagunta", "Vipul Mittal", "Gopal Sarda"], "title": "GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO", "comment": null, "summary": "The advancement of large language models (LLMs) is critically dependent on\nthe availability of high-quality datasets for Supervised Fine-Tuning (SFT),\nalignment tasks like Direct Preference Optimization (DPO), etc. In this work,\nwe present a comprehensive synthetic data generation framework that facilitates\nscalable, configurable, and high-fidelity generation of synthetic data tailored\nfor these training paradigms. Our approach employs a modular and\nconfiguration-based pipeline capable of modeling complex dialogue flows with\nminimal manual intervention. This framework uses a dual-stage quality tagging\nmechanism, combining heuristic rules and LLM-based evaluations, to\nautomatically filter and score data extracted from OASST-formatted\nconversations, ensuring the curation of high-quality dialogue samples. The\nresulting datasets are structured under a flexible schema supporting both SFT\nand DPO use cases, enabling seamless integration into diverse training\nworkflows. Together, these innovations offer a robust solution for generating\nand managing synthetic conversational data at scale, significantly reducing the\noverhead of data preparation in LLM training pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u4e3aLLM\u7684\u76d1\u7763\u5fae\u8c03\u548c\u5bf9\u9f50\u4efb\u52a1\uff08\u5982DPO\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u6269\u5c55\u7684\u5408\u6210\u5bf9\u8bdd\u6570\u636e\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e25\u91cd\u4f9d\u8d56\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u4f46\u73b0\u6709\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u89c4\u6a21\u5316\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u3001\u57fa\u4e8e\u914d\u7f6e\u7684\u6d41\u6c34\u7ebf\uff0c\u4f7f\u7528\u53cc\u9636\u6bb5\u8d28\u91cf\u6807\u8bb0\u673a\u5236\uff08\u542f\u53d1\u5f0f\u89c4\u5219+LLM\u8bc4\u4f30\uff09\u6765\u81ea\u52a8\u8fc7\u6ee4\u548c\u8bc4\u5206OASST\u683c\u5f0f\u5bf9\u8bdd\u6570\u636e\uff0c\u652f\u6301\u590d\u6742\u5bf9\u8bdd\u6d41\u5efa\u6a21\u3002", "result": "\u6784\u5efa\u4e86\u652f\u6301SFT\u548cDPO\u7528\u4f8b\u7684\u7075\u6d3b\u6570\u636e\u7ed3\u6784\uff0c\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u5404\u79cd\u8bad\u7ec3\u5de5\u4f5c\u6d41\u4e2d\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6570\u636e\u51c6\u5907\u7684\u5f00\u9500\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89c4\u6a21\u5316\u751f\u6210\u548c\u7ba1\u7406\u5408\u6210\u5bf9\u8bdd\u6570\u636e\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848\uff0c\u5927\u5927\u964d\u4f4e\u4e86LLM\u8bad\u7ec3\u6d41\u6c34\u7ebf\u4e2d\u7684\u6570\u636e\u51c6\u5907\u8d1f\u62c5\u3002"}}
{"id": "2508.15447", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15447", "abs": "https://arxiv.org/abs/2508.15447", "authors": ["Zihao Wang", "Junming Zhang"], "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence", "comment": "Accepted by ECAI 2025", "summary": "Large Language Models (LLMs) have shown promising potential in business\napplications, particularly in enterprise decision support and strategic\nplanning, yet current approaches often struggle to reconcile intricate\noperational analyses with overarching strategic goals across diverse market\nenvironments, leading to fragmented workflows and reduced collaboration across\norganizational levels. This paper introduces BusiAgent, a novel multi-agent\nframework leveraging LLMs for advanced decision-making in complex corporate\nenvironments. BusiAgent integrates three core innovations: an extended\nContinuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a\ngeneralized entropy measure to optimize collaborative efficiency, and a\nmulti-level Stackelberg game to handle hierarchical decision processes.\nAdditionally, contextual Thompson sampling is employed for prompt optimization,\nsupported by a comprehensive quality assurance system to mitigate errors.\nExtensive empirical evaluations across diverse business scenarios validate\nBusiAgent's efficacy, demonstrating its capacity to generate coherent,\nclient-focused solutions that smoothly integrate granular insights with\nhigh-level strategy, significantly outperforming established approaches in both\nsolution quality and user satisfaction. By fusing cutting-edge AI technologies\nwith deep business insights, BusiAgent marks a substantial step forward in\nAI-driven enterprise decision-making, empowering organizations to navigate\ncomplex business landscapes more effectively.", "AI": {"tldr": "BusiAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3001\u5e7f\u4e49\u71b5\u5ea6\u91cf\u548cStackelberg\u535a\u5f08\u7b49\u521b\u65b0\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f01\u4e1a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f01\u4e1a\u51b3\u7b56\u652f\u6301\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8fd0\u8425\u5206\u6790\u4e0e\u6218\u7565\u76ee\u6807\u534f\u8c03\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5de5\u4f5c\u6d41\u7a0b\u788e\u7247\u5316\u548c\u8de8\u7ec4\u7ec7\u534f\u4f5c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6574\u5408\u4e86\u6269\u5c55\u7684\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08CTMDP\uff09\u3001\u5e7f\u4e49\u71b5\u5ea6\u91cf\u4f18\u5316\u534f\u4f5c\u6548\u7387\u3001\u591a\u7ea7Stackelberg\u535a\u5f08\u5904\u7406\u5c42\u6b21\u5316\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u4e0a\u4e0b\u6587Thompson\u91c7\u6837\u8fdb\u884c\u63d0\u793a\u4f18\u5316\u3002", "result": "\u5728\u591a\u6837\u5316\u4e1a\u52a1\u573a\u666f\u4e2d\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cBusiAgent\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u7684\u3001\u4ee5\u5ba2\u6237\u4e3a\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c06\u7ec6\u7c92\u5ea6\u6d1e\u5bdf\u4e0e\u9ad8\u5c42\u6218\u7565\u65e0\u7f1d\u6574\u5408\uff0c\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "BusiAgent\u901a\u8fc7\u5c06\u524d\u6cbfAI\u6280\u672f\u4e0e\u6df1\u5ea6\u4e1a\u52a1\u6d1e\u5bdf\u76f8\u7ed3\u5408\uff0c\u5728AI\u9a71\u52a8\u7684\u4f01\u4e1a\u51b3\u7b56\u5236\u5b9a\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f7f\u7ec4\u7ec7\u80fd\u591f\u66f4\u6709\u6548\u5730\u5e94\u5bf9\u590d\u6742\u7684\u5546\u4e1a\u73af\u5883\u3002"}}
{"id": "2508.15507", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15507", "abs": "https://arxiv.org/abs/2508.15507", "authors": ["Yekun Zhu", "Guang Chen", "Chengjun Mao"], "title": "Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning", "comment": null, "summary": "Large Language Models (LLMs) with chains-of-thought have demonstrated strong\nperformance on an increasing range of tasks, particularly those involving\ncomplex logical reasoning. However, excessively long chains can lead to\noverthinking, causing computational waste and slower responses. This raises a\nquestion: can LLMs dynamically adjust the length of their reasoning processes\nbased on task complexity? To address this, we propose the Think in Blocks\nframework, which enables adaptive reasoning-from zero to deep reasoning-by\npartitioning the reasoning process into a tunable number of blocks. Our main\ncontributions are: (1) Establishing an explicit block-structured paradigm in\nwhich the model first predicts an integer reasoning budget-the number of\nblocks-and then partitions its reasoning accordingly; (2) Training an adaptive\nmodel through a three-stage pipeline-Supervised Fine-Tuning, reward-guided\nDirect Preference Optimization, and Reinforcement Learning-that adjusts its\nreasoning depth to problem difficulty; (3) Exploiting the explicit block count\nto dynamically control reasoning depth at inference time, allowing flexible\nadjustment of chain-of-thought length during deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86Think in Blocks\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u8fc7\u7a0b\u5212\u5206\u4e3a\u53ef\u8c03\u8282\u7684\u5757\u6570\uff0c\u4f7fLLM\u80fd\u591f\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u52a8\u6001\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u4ece\u96f6\u63a8\u7406\u5230\u6df1\u5ea6\u63a8\u7406\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8fc7\u957f\u7684\u63a8\u7406\u94fe\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\uff0c\u9020\u6210\u8ba1\u7b97\u6d6a\u8d39\u548c\u54cd\u5e94\u53d8\u6162\u3002\u9700\u8981\u8ba9\u6a21\u578b\u80fd\u591f\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u63a8\u7406\u957f\u5ea6\u3002", "method": "\u5efa\u7acb\u663e\u5f0f\u7684\u5757\u7ed3\u6784\u8303\u5f0f\uff1a\u6a21\u578b\u5148\u9884\u6d4b\u63a8\u7406\u9884\u7b97\uff08\u5757\u6570\uff09\uff0c\u7136\u540e\u76f8\u5e94\u5212\u5206\u63a8\u7406\u8fc7\u7a0b\uff1b\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff08\u76d1\u7763\u5fae\u8c03\u3001\u5956\u52b1\u5f15\u5bfc\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3001\u5f3a\u5316\u5b66\u4e60\uff09\u8bad\u7ec3\u81ea\u9002\u5e94\u6a21\u578b\uff1b\u5229\u7528\u663e\u5f0f\u5757\u6570\u5728\u63a8\u7406\u65f6\u52a8\u6001\u63a7\u5236\u63a8\u7406\u6df1\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6839\u636e\u95ee\u9898\u96be\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\uff0c\u5b9e\u73b0\u63a8\u7406\u94fe\u957f\u5ea6\u7684\u7075\u6d3b\u8c03\u8282\u3002", "conclusion": "Think in Blocks\u6846\u67b6\u4e3aLLM\u63d0\u4f9b\u4e86\u52a8\u6001\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u54cd\u5e94\u901f\u5ea6\u3002"}}
{"id": "2508.15510", "categories": ["cs.AI", "I.2.11; I.2.0; J.4; K.4.0; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.15510", "abs": "https://arxiv.org/abs/2508.15510", "authors": ["Filippo Tonini", "Lukas Galke"], "title": "Super-additive Cooperation in Language Model Agents", "comment": "FAIEMA 2025", "summary": "With the prospect of autonomous artificial intelligence (AI) agents, studying\ntheir tendency for cooperative behavior becomes an increasingly relevant topic.\nThis study is inspired by the super-additive cooperation theory, where the\ncombined effects of repeated interactions and inter-group rivalry have been\nargued to be the cause for cooperative tendencies found in humans. We devised a\nvirtual tournament where language model agents, grouped into teams, face each\nother in a Prisoner's Dilemma game. By simulating both internal team dynamics\nand external competition, we discovered that this blend substantially boosts\nboth overall and initial, one-shot cooperation levels (the tendency to\ncooperate in one-off interactions). This research provides a novel framework\nfor large language models to strategize and act in complex social scenarios and\noffers evidence for how intergroup competition can, counter-intuitively, result\nin more cooperative behavior. These insights are crucial for designing future\nmulti-agent AI systems that can effectively work together and better align with\nhuman values. Source code is available at\nhttps://github.com/pippot/Superadditive-cooperation-LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u56da\u5f92\u56f0\u5883\u9526\u6807\u8d5b\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u56e2\u961f\u5185\u90e8\u91cd\u590d\u4e92\u52a8\u548c\u56e2\u961f\u95f4\u7ade\u4e89\u7684\u53cc\u91cd\u4f5c\u7528\u4e0b\uff0c\u5408\u4f5c\u6c34\u5e73\u663e\u8457\u63d0\u5347\uff0c\u5305\u62ec\u4e00\u6b21\u6027\u4e92\u52a8\u4e2d\u7684\u5408\u4f5c\u503e\u5411\u3002", "motivation": "\u968f\u7740\u81ea\u4e3bAI\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u7814\u7a76\u5176\u5408\u4f5c\u884c\u4e3a\u503e\u5411\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u53d7\u8d85\u52a0\u6027\u5408\u4f5c\u7406\u8bba\u542f\u53d1\uff0c\u8be5\u7406\u8bba\u8ba4\u4e3a\u91cd\u590d\u4e92\u52a8\u548c\u7fa4\u4f53\u95f4\u7ade\u4e89\u7684\u7ed3\u5408\u662f\u4eba\u7c7b\u5408\u4f5c\u503e\u5411\u7684\u539f\u56e0\u3002", "method": "\u8bbe\u8ba1\u865a\u62df\u9526\u6807\u8d5b\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5206\u7ec4\u8fdb\u884c\u56da\u5f92\u56f0\u5883\u6e38\u620f\uff0c\u540c\u65f6\u6a21\u62df\u56e2\u961f\u5185\u90e8\u52a8\u6001\u548c\u5916\u90e8\u7ade\u4e89\u73af\u5883\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5185\u90e8\u56e2\u961f\u52a8\u6001\u548c\u5916\u90e8\u7ade\u4e89\u7684\u7ed3\u5408\u663e\u8457\u63d0\u9ad8\u4e86\u6574\u4f53\u5408\u4f5c\u6c34\u5e73\u548c\u4e00\u6b21\u6027\u4e92\u52a8\u4e2d\u7684\u5408\u4f5c\u503e\u5411\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u793e\u4f1a\u573a\u666f\u4e2d\u5236\u5b9a\u7b56\u7565\u548c\u884c\u52a8\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u7fa4\u4f53\u95f4\u7ade\u4e89\u53ef\u4ee5\u53cd\u76f4\u89c9\u5730\u5bfc\u81f4\u66f4\u591a\u5408\u4f5c\u884c\u4e3a\uff0c\u5bf9\u8bbe\u8ba1\u672a\u6765\u591a\u4ee3\u7406AI\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.15548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15548", "abs": "https://arxiv.org/abs/2508.15548", "authors": ["Jiayi Song", "Rui Wan", "Lipeng Ma", "Weidong Yang", "Qingyuan Zhou", "Yixuan Li", "Ben Fei"], "title": "DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks", "comment": null, "summary": "This work enhances the ability of large language models (LLMs) to perform\ncomplex reasoning in 3D scenes. Recent work has addressed the 3D situated\nreasoning task by invoking tool usage through large language models. Large\nlanguage models call tools via APIs and integrate the generated programs\nthrough a chain of thought to solve problems based on the program results.\nHowever, due to the simplicity of the questions in the dataset, the generated\nprogram reasoning chains are relatively short. To solve this main challenge, in\nthis paper, we introduce DeepThink3D to enhance the tool usage of LLMs in\ncomplex 3D situated reasoning tasks. Our work proposes a combinatorial and\niterative evolutionary approach on the SQA3D benchmark to generate more complex\nquestions. Building on this foundation, we fine-tune the large language model\nto make it more proficient in using 3D tools. By employing Direct Preference\nOptimization (DPO), we directly optimize the toolchain strategies generated by\nmodels, thereby enhancing their accuracy in complex tasks.", "AI": {"tldr": "DeepThink3D\u901a\u8fc7\u7ec4\u5408\u8fed\u4ee3\u8fdb\u5316\u65b9\u6cd5\u751f\u6210\u66f4\u590d\u6742\u76843D\u573a\u666f\u63a8\u7406\u95ee\u9898\uff0c\u5e76\u4f7f\u7528DPO\u4f18\u5316LLM\u7684\u5de5\u5177\u4f7f\u7528\u7b56\u7565\uff0c\u63d0\u5347\u5728\u590d\u67423D\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "motivation": "\u73b0\u67093D\u573a\u666f\u63a8\u7406\u4efb\u52a1\u7684\u95ee\u9898\u8fc7\u4e8e\u7b80\u5355\uff0c\u751f\u6210\u7684\u7a0b\u5e8f\u63a8\u7406\u94fe\u8f83\u77ed\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u63a8\u7406\u9700\u6c42", "method": "1) \u5728SQA3D\u57fa\u51c6\u4e0a\u4f7f\u7528\u7ec4\u5408\u8fed\u4ee3\u8fdb\u5316\u65b9\u6cd5\u751f\u6210\u66f4\u590d\u6742\u95ee\u9898\uff1b2) \u901a\u8fc7DPO\u76f4\u63a5\u4f18\u5316\u6a21\u578b\u751f\u6210\u7684\u5de5\u5177\u94fe\u7b56\u7565\uff0c\u63d0\u5347\u5de5\u5177\u4f7f\u7528\u51c6\u786e\u6027", "result": "\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u67423D\u573a\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u5de5\u5177\u4f7f\u7528\u7684\u51c6\u786e\u6027\u548c\u6548\u7387", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e863D\u573a\u666f\u590d\u6742\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3aLLM\u57283D\u73af\u5883\u4e2d\u7684\u9ad8\u7ea7\u63a8\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2508.15588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15588", "abs": "https://arxiv.org/abs/2508.15588", "authors": ["Ahmed Nasir", "Abdelhafid Zenati"], "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification", "comment": null, "summary": "The application of reinforcement learning to safety-critical systems is\nlimited by the lack of formal methods for verifying the robustness and safety\nof learned policies. This paper introduces a novel framework that addresses\nthis gap by analyzing the combination of an RL agent and its environment as a\ndiscrete-time autonomous dynamical system. By leveraging tools from dynamical\nsystems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we\nidentify and visualize Lagrangian Coherent Structures (LCS) that act as the\nhidden \"skeleton\" governing the system's behavior. We demonstrate that\nrepelling LCS function as safety barriers around unsafe regions, while\nattracting LCS reveal the system's convergence properties and potential failure\nmodes, such as unintended \"trap\" states. To move beyond qualitative\nvisualization, we introduce a suite of quantitative metrics, Mean Boundary\nRepulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and\nTemporally-Aware Spurious Attractor Strength (TASAS), to formally measure a\npolicy's safety margin and robustness. We further provide a method for deriving\nlocal stability guarantees and extend the analysis to handle model uncertainty.\nThrough experiments in both discrete and continuous control environments, we\nshow that this framework provides a comprehensive and interpretable assessment\nof policy behavior, successfully identifying critical flaws in policies that\nappear successful based on reward alone.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u9a8c\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u6709\u9650\u65f6\u95f4\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\u8bc6\u522b\u62c9\u683c\u6717\u65e5\u76f8\u5e72\u7ed3\u6784\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u5f62\u5f0f\u5316\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u9700\u8981\u80fd\u591f\u9a8c\u8bc1\u5b66\u4e60\u7b56\u7565\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u7684\u6846\u67b6\u3002", "method": "\u5c06RL\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u7ec4\u5408\u89c6\u4e3a\u79bb\u6563\u65f6\u95f4\u81ea\u6cbb\u52a8\u529b\u7cfb\u7edf\uff0c\u5229\u7528\u6709\u9650\u65f6\u95f4\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\u8bc6\u522b\u62c9\u683c\u6717\u65e5\u76f8\u5e72\u7ed3\u6784\uff0c\u5e76\u5f15\u5165MBR\u3001ASAS\u3001TASAS\u7b49\u91cf\u5316\u6307\u6807\u6765\u6d4b\u91cf\u7b56\u7565\u5b89\u5168\u8fb9\u9645\u3002", "result": "\u5728\u79bb\u6563\u548c\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5168\u9762\u53ef\u89e3\u91ca\u5730\u8bc4\u4f30\u7b56\u7565\u884c\u4e3a\uff0c\u6210\u529f\u8bc6\u522b\u4ec5\u57fa\u4e8e\u5956\u52b1\u770b\u4f3c\u6210\u529f\u4f46\u5b58\u5728\u5173\u952e\u7f3a\u9677\u7684\u7b56\u7565\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522b\u9690\u85cf\u7684\u5b89\u5168\u98ce\u9669\u548c\u6536\u655b\u7279\u6027\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u5b9a\u6027\u53ef\u89c6\u5316\u5206\u6790\u3002"}}
{"id": "2508.15610", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15610", "abs": "https://arxiv.org/abs/2508.15610", "authors": ["Alfio Gliozzo", "Naweed Khan", "Christodoulos Constantinides", "Nandana Mihindukulasooriya", "Nahuel Defosse", "Junkyu Lee"], "title": "Transduction is All You Need for Structured Data Workflows", "comment": "32 pages, 8 figures", "summary": "This paper introduces Agentics, a modular framework for building agent-based\nsystems capable of structured reasoning and compositional generalization over\ncomplex data. Designed with research and practical applications in mind,\nAgentics offers a novel perspective on working with data and AI workflows. In\nthis framework, agents are abstracted from the logical flow and they are used\ninternally to the data type to enable logical transduction among data. Agentics\nencourages AI developers to focus on modeling data rather than crafting\nprompts, enabling a declarative language in which data types are provided by\nLLMs and composed through logical transduction, which is executed by LLMs when\ntypes are connected. We provide empirical evidence demonstrating the\napplicability of this framework across domain-specific multiple-choice question\nanswering, semantic parsing for text-to-SQL, and automated prompt optimization\ntasks, achieving state-of-the-art accuracy or improved scalability without\nsacrificing performance. The open-source implementation is available at\n\\texttt{https://github.com/IBM/agentics}.", "AI": {"tldr": "Agentics\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u57fa\u4e8e\u4ee3\u7406\u7684\u7cfb\u7edf\uff0c\u652f\u6301\u7ed3\u6784\u5316\u63a8\u7406\u548c\u7ec4\u5408\u6cdb\u5316\uff0c\u901a\u8fc7\u6570\u636e\u5efa\u6a21\u800c\u975e\u63d0\u793a\u5de5\u7a0b\u6765\u5b9e\u73b0\u58f0\u660e\u5f0fAI\u5de5\u4f5c\u6d41\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edfAI\u5de5\u4f5c\u6d41\u4e2d\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u63d0\u793a\u548c\u6d41\u7a0b\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u66f4\u4e13\u6ce8\u4e8e\u6570\u636e\u5efa\u6a21\u7684\u6846\u67b6\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u901a\u8fc7\u58f0\u660e\u5f0f\u8bed\u8a00\u6784\u5efa\u590d\u6742\u7684AI\u5e94\u7528\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u5c06\u4ee3\u7406\u4ece\u903b\u8f91\u6d41\u4e2d\u62bd\u8c61\u51fa\u6765\uff0c\u901a\u8fc7\u6570\u636e\u7c7b\u578b\u7684\u903b\u8f91\u8f6c\u6362\u5b9e\u73b0\u7ec4\u5408\uff0cLLM\u5728\u7c7b\u578b\u8fde\u63a5\u65f6\u6267\u884c\u8f6c\u6362\u64cd\u4f5c\u3002", "result": "\u5728\u9886\u57df\u7279\u5b9a\u591a\u9009\u9898\u56de\u7b54\u3001\u6587\u672c\u5230SQL\u7684\u8bed\u4e49\u89e3\u6790\u548c\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7cbe\u5ea6\u6216\u6539\u8fdb\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u4e0d\u727a\u7272\u6027\u80fd\u3002", "conclusion": "Agentics\u6846\u67b6\u4e3aAI\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u58f0\u660e\u5f0f\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.15630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15630", "abs": "https://arxiv.org/abs/2508.15630", "authors": ["Meera Ray", "Christopher L. Dancy"], "title": "Adapting A Vector-Symbolic Memory for Lisp ACT-R", "comment": "6 pages. 5 figures. Submitted and accepted to the 23rd International\n  Conference on Cognitive Modeling (ICCM 2025)", "summary": "Holographic Declarative Memory (HDM) is a vector-symbolic alternative to\nACT-R's Declarative Memory (DM) system that can bring advantages such as\nscalability and architecturally defined similarity between DM chunks. We\nadapted HDM to work with the most comprehensive and widely-used implementation\nof ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with\nHDM without major changes. With this adaptation of HDM, we have developed\nvector-based versions of common ACT-R functions, set up a text processing\npipeline to add the contents of large documents to ACT-R memory, and most\nsignificantly created a useful and novel mechanism to retrieve an entire chunk\nof memory based on a request using only vector representations of tokens.\nPreliminary results indicate that we can maintain vector-symbolic advantages of\nHDM (e.g., chunk recall without storing the actual chunk and other advantages\nwith scaling) while also extending it so that previous ACT-R models may work\nwith the system with little (or potentially no) modifications within the actual\nprocedural and declarative memory portions of a model. As a part of iterative\nimprovement of this newly translated holographic declarative memory module, we\nwill continue to explore better time-context representations for vectors to\nimprove the module's ability to reconstruct chunks during recall. To more fully\ntest this translated HDM module, we also plan to develop decision-making models\nthat use instance-based learning (IBL) theory, which is a useful application of\nHDM given the advantages of the system.", "AI": {"tldr": "HDM\u662fACT-R\u58f0\u660e\u6027\u8bb0\u5fc6\u7cfb\u7edf\u7684\u5411\u91cf\u7b26\u53f7\u66ff\u4ee3\u65b9\u6848\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u67b6\u6784\u5b9a\u4e49\u7684\u76f8\u4f3c\u6027\u4f18\u52bf\u3002\u7814\u7a76\u5c06HDM\u9002\u914d\u5230Lisp ACT-R\uff0c\u4f7f\u73b0\u6709\u6a21\u578b\u65e0\u9700\u91cd\u5927\u4fee\u6539\u5373\u53ef\u8fd0\u884c\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u5411\u91cf\u7684\u68c0\u7d22\u673a\u5236\u3002", "motivation": "\u5c06Holographic Declarative Memory (HDM) \u6574\u5408\u5230\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684ACT-R\u5b9e\u73b0\u4e2d\uff0c\u4f7f\u73b0\u6709ACT-R\u6a21\u578b\u80fd\u591f\u5229\u7528HDM\u7684\u5411\u91cf\u7b26\u53f7\u4f18\u52bf\uff0c\u5982\u53ef\u6269\u5c55\u6027\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\uff0c\u800c\u65e0\u9700\u5bf9\u6a21\u578b\u8fdb\u884c\u91cd\u5927\u4fee\u6539\u3002", "method": "\u5c06HDM\u9002\u914d\u5230Lisp ACT-R\uff0c\u5f00\u53d1\u57fa\u4e8e\u5411\u91cf\u7684\u5e38\u89c1ACT-R\u51fd\u6570\u7248\u672c\uff0c\u5efa\u7acb\u6587\u672c\u5904\u7406\u7ba1\u9053\u5c06\u5927\u578b\u6587\u6863\u5185\u5bb9\u6dfb\u52a0\u5230\u8bb0\u5fc6\u5e93\u4e2d\uff0c\u521b\u5efa\u57fa\u4e8e\u5411\u91cf\u8868\u793a\u7684\u5b8c\u6574\u8bb0\u5fc6\u5757\u68c0\u7d22\u673a\u5236\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0cHDM\u80fd\u591f\u4fdd\u6301\u5411\u91cf\u7b26\u53f7\u4f18\u52bf\uff08\u5982\u65e0\u9700\u5b58\u50a8\u5b9e\u9645\u5757\u5373\u53ef\u56de\u5fc6\uff09\uff0c\u540c\u65f6\u4f7f\u5148\u524dACT-R\u6a21\u578b\u5728\u7a0b\u5e8f\u548c\u58f0\u660e\u6027\u8bb0\u5fc6\u90e8\u5206\u53ea\u9700\u6781\u5c11\u6216\u65e0\u9700\u4fee\u6539\u5373\u53ef\u5de5\u4f5c\u3002", "conclusion": "HDM\u6210\u529f\u6574\u5408\u5230ACT-R\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u73b0\u6709\u6a21\u578b\u63d0\u4f9b\u4e86\u5411\u91cf\u7b26\u53f7\u8bb0\u5fc6\u7684\u4f18\u52bf\u3002\u672a\u6765\u5c06\u7ee7\u7eed\u6539\u8fdb\u65f6\u95f4\u4e0a\u4e0b\u6587\u8868\u793a\u4ee5\u63d0\u9ad8\u5757\u91cd\u6784\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u5b9e\u4f8b\u5b66\u4e60\u7406\u8bba\u7684\u51b3\u7b56\u6a21\u578b\u6765\u5168\u9762\u6d4b\u8bd5\u8be5\u7cfb\u7edf\u3002"}}
{"id": "2508.15680", "categories": ["cs.AI", "cs.HC", "I.2.6; I.2.11; K.4.1; K.6.0"], "pdf": "https://arxiv.org/pdf/2508.15680", "abs": "https://arxiv.org/abs/2508.15680", "authors": ["Mark Cote", "Susana Aires"], "title": "Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle", "comment": "15 pages, 3 figures, Presented at IAIL 2025 - Imagining the AI\n  Landscape after the AI Act, 4th International Workshop on Imagining the AI\n  Landscape After the AI Act, The fourth International Conference on Hybrid\n  Human-Artificial Intelligence", "summary": "This paper argues that a techno-philosophical reading of the EU AI Act\nprovides insight into the long-term dynamics of data in AI systems,\nspecifically, how the lifecycle from ingestion to deployment generates\nrecursive value chains that challenge existing frameworks for Responsible AI.\nWe introduce a conceptual tool to frame the AI pipeline, spanning data,\ntraining regimes, architectures, feature stores, and transfer learning. Using\ncross-disciplinary methods, we develop a technically grounded and\nphilosophically coherent analysis of regulatory blind spots. Our central claim\nis that what remains absent from policymaking is an account of the dynamic of\nbecoming that underpins both the technical operation and economic logic of AI.\nTo address this, we advance a formal reading of AI inspired by Simondonian\nphilosophy of technology, reworking his concept of individuation to model the\nAI lifecycle, including the pre-individual milieu, individuation, and\nindividuated AI. To translate these ideas, we introduce futurity: the\nself-reinforcing lifecycle of AI, where more data enhances performance, deepens\npersonalisation, and expands application domains. Futurity highlights the\nrecursively generative, non-rivalrous nature of data, underpinned by\ninfrastructures like feature stores that enable feedback, adaptation, and\ntemporal recursion. Our intervention foregrounds escalating power asymmetries,\nparticularly the tech oligarchy whose infrastructures of capture, training, and\ndeployment concentrate value and decision-making. We argue that effective\nregulation must address these infrastructural and temporal dynamics, and\npropose measures including lifecycle audits, temporal traceability, feedback\naccountability, recursion transparency, and a right to contest recursive reuse.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6280\u672f\u54f2\u5b66\u89c6\u89d2\u5206\u6790\u6b27\u76dfAI\u6cd5\u6848\uff0c\u63ed\u793a\u4e86AI\u7cfb\u7edf\u4e2d\u6570\u636e\u7684\u9012\u5f52\u4ef7\u503c\u94fe\u52a8\u6001\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eSimondon\u54f2\u5b66\u7684\u5f62\u5f0f\u5316AI\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u5f3a\u8c03\u9700\u8981\u9488\u5bf9\u57fa\u7840\u8bbe\u65bd\u548c\u65f6\u95f4\u52a8\u6001\u7684\u76d1\u7ba1\u63aa\u65bd\u3002", "motivation": "\u73b0\u6709AI\u76d1\u7ba1\u6846\u67b6\u672a\u80fd\u5145\u5206\u7406\u89e3AI\u7cfb\u7edf\u4e2d\u6570\u636e\u4ece\u6444\u5165\u5230\u90e8\u7f72\u7684\u9012\u5f52\u4ef7\u503c\u94fe\u52a8\u6001\uff0c\u4ee5\u53ca\u8fd9\u79cd\u52a8\u6001\u5982\u4f55\u6311\u6218\u8d1f\u8d23\u4efbAI\u7684\u73b0\u6709\u6846\u67b6\uff0c\u9700\u8981\u4ece\u6280\u672f\u54f2\u5b66\u89d2\u5ea6\u63d0\u4f9b\u65b0\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u91c7\u7528\u8de8\u5b66\u79d1\u65b9\u6cd5\uff0c\u5f15\u5165Simondon\u6280\u672f\u54f2\u5b66\u4e2d\u7684\u4e2a\u4f53\u5316\u6982\u5ff5\u6765\u5efa\u6a21AI\u751f\u547d\u5468\u671f\uff0c\u63d0\u51fa\"\u672a\u6765\u6027\"\u6982\u5ff5\u63cf\u8ff0AI\u81ea\u6211\u5f3a\u5316\u7684\u9012\u5f52\u751f\u547d\u5468\u671f\uff0c\u5f00\u53d1\u6280\u672f\u57fa\u7840\u624e\u5b9e\u4e14\u54f2\u5b66\u8fde\u8d2f\u7684\u5206\u6790\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u4e86\u653f\u7b56\u5236\u5b9a\u4e2d\u7684\u76d1\u7ba1\u76f2\u70b9\uff0c\u63ed\u793a\u4e86\u6570\u636e\u9012\u5f52\u751f\u6210\u548c\u975e\u7ade\u4e89\u6027\u7684\u672c\u8d28\uff0c\u51f8\u663e\u4e86\u6280\u672f\u5be1\u5934\u901a\u8fc7\u6355\u83b7\u3001\u8bad\u7ec3\u548c\u90e8\u7f72\u57fa\u7840\u8bbe\u65bd\u96c6\u4e2d\u4ef7\u503c\u548c\u51b3\u7b56\u6743\u7684\u6743\u529b\u4e0d\u5bf9\u79f0\u95ee\u9898\u3002", "conclusion": "\u6709\u6548\u7684AI\u76d1\u7ba1\u5fc5\u987b\u89e3\u51b3\u57fa\u7840\u8bbe\u65bd\u548c\u65f6\u95f4\u52a8\u6001\u95ee\u9898\uff0c\u5efa\u8bae\u5b9e\u65bd\u751f\u547d\u5468\u671f\u5ba1\u8ba1\u3001\u65f6\u95f4\u53ef\u8ffd\u6eaf\u6027\u3001\u53cd\u9988\u95ee\u8d23\u3001\u9012\u5f52\u900f\u660e\u5ea6\u548c\u53cd\u5bf9\u9012\u5f52\u91cd\u7528\u7684\u6743\u5229\u7b49\u63aa\u65bd\u3002"}}
{"id": "2508.15690", "categories": ["cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.15690", "abs": "https://arxiv.org/abs/2508.15690", "authors": ["Abhigya Verma", "Sriram Puttagunta", "Seganrasan Subramanian", "Sravan Ramachandran"], "title": "GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning", "comment": "23 pages, 9 tables, 3 figures", "summary": "GRAFT is a structured multimodal benchmark for evaluating models on\ninstruction-following, visual reasoning, and visual-textual alignment tasks. It\nfeatures programmatically generated charts and synthetically rendered tables,\ncreated with Python visualization libraries to ensure control over data\nsemantics, structure, and clarity. Each GRAFT instance pairs a chart or table\nimage with a systematically generated, multi-step analytical question based\nsolely on visual content. Answers are provided in structured formats such as\nJSON or YAML, supporting consistent evaluation of both reasoning and output\nformat. The benchmark introduces a taxonomy of reasoning types including\ncomparison, trend identification, ranking, aggregation, proportion estimation,\nand anomaly detection to enable comprehensive assessment. Reference answers\nfollow strict factual and formatting guidelines for precise, aspect-based\nevaluation. GRAFT offers a unified, scalable framework for fine-grained\nbenchmarking of multimodal models on visually grounded, structured reasoning\ntasks, setting a new evaluation standard in this field.", "AI": {"tldr": "GRAFT\u662f\u4e00\u4e2a\u7ed3\u6784\u5316\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u6307\u4ee4\u8ddf\u968f\u3001\u89c6\u89c9\u63a8\u7406\u548c\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5305\u542b\u7a0b\u5e8f\u751f\u6210\u7684\u56fe\u8868\u548c\u5408\u6210\u6e32\u67d3\u7684\u8868\u683c\uff0c\u652f\u6301JSON/YAML\u683c\u5f0f\u7684\u7ed3\u6784\u5316\u7b54\u6848\u8f93\u51fa\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u63a8\u7406\u548c\u7ed3\u6784\u5316\u8f93\u51fa\u65b9\u9762\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63a7\u5236\u6570\u636e\u8bed\u4e49\u3001\u7ed3\u6784\u548c\u6e05\u6670\u5ea6\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u4f7f\u7528Python\u53ef\u89c6\u5316\u5e93\u7a0b\u5e8f\u5316\u751f\u6210\u56fe\u8868\u548c\u5408\u6210\u6e32\u67d3\u8868\u683c\uff0c\u4e3a\u6bcf\u4e2a\u56fe\u8868/\u8868\u683c\u56fe\u50cf\u751f\u6210\u591a\u6b65\u9aa4\u5206\u6790\u95ee\u9898\uff0c\u7b54\u6848\u91c7\u7528JSON\u6216YAML\u7b49\u7ed3\u6784\u5316\u683c\u5f0f\uff0c\u5e76\u5efa\u7acb\u5305\u542b\u6bd4\u8f83\u3001\u8d8b\u52bf\u8bc6\u522b\u3001\u6392\u540d\u7b49\u63a8\u7406\u7c7b\u578b\u7684\u5206\u7c7b\u6cd5\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u591f\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u57fa\u7840\u7684\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u4e3a\u8be5\u9886\u57df\u8bbe\u7acb\u4e86\u65b0\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "conclusion": "GRAFT\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5168\u9762\u3001\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u95ee\u9898\u8bbe\u8ba1\u548c\u7b54\u6848\u683c\u5f0f\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u3001\u57fa\u4e8e\u65b9\u9762\u7684\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u3002"}}
{"id": "2508.15693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15693", "abs": "https://arxiv.org/abs/2508.15693", "authors": ["Wilka Carvalho", "Vikram Goddla", "Ishaan Sinha", "Hoon Shin", "Kunal Jha"], "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments", "comment": null, "summary": "We present NiceWebRL, a research tool that enables researchers to use machine\nreinforcement learning (RL) environments for online human subject experiments.\nNiceWebRL is a Python library that allows any Jax-based environment to be\ntransformed into an online interface, supporting both single-agent and\nmulti-agent environments. As such, NiceWebRL enables AI researchers to compare\ntheir algorithms to human performance, cognitive scientists to test ML\nalgorithms as theories for human cognition, and multi-agent researchers to\ndevelop algorithms for human-AI collaboration. We showcase NiceWebRL with 3\ncase studies that demonstrate its potential to help develop Human-like AI,\nHuman-compatible AI, and Human-assistive AI. In the first case study\n(Human-like AI), NiceWebRL enables the development of a novel RL model of\ncognition. Here, NiceWebRL facilitates testing this model against human\nparticipants in both a grid world and Craftax, a 2D Minecraft domain. In our\nsecond case study (Human-compatible AI), NiceWebRL enables the development of a\nnovel multi-agent RL algorithm that can generalize to human partners in the\nOvercooked domain. Finally, in our third case study (Human-assistive AI), we\nshow how NiceWebRL can allow researchers to study how an LLM can assist humans\non complex tasks in XLand-Minigrid, an environment with millions of\nhierarchical tasks. The library is available at\nhttps://github.com/KempnerInstitute/nicewebrl.", "AI": {"tldr": "NiceWebRL\u662f\u4e00\u4e2aPython\u5e93\uff0c\u53ef\u5c06Jax\u73af\u5883\u8f6c\u6362\u4e3a\u5728\u7ebf\u754c\u9762\uff0c\u652f\u6301\u4eba\u673a\u4ea4\u4e92\u5b9e\u9a8c\uff0c\u7528\u4e8e\u6bd4\u8f83AI\u7b97\u6cd5\u4e0e\u4eba\u7c7b\u8868\u73b0\u3001\u6d4b\u8bd5\u8ba4\u77e5\u7406\u8bba\u548c\u5f00\u53d1\u4eba\u673a\u534f\u4f5c\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3AI\u7814\u7a76\u4e2d\u7f3a\u4e4f\u4fbf\u6377\u7684\u4eba\u673a\u4ea4\u4e92\u5b9e\u9a8c\u5de5\u5177\u7684\u95ee\u9898\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u8f7b\u677e\u5730\u5c06\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u8f6c\u6362\u4e3a\u5728\u7ebf\u5b9e\u9a8c\u5e73\u53f0\uff0c\u4fc3\u8fdb\u4eba\u7c7b\u4e0eAI\u7b97\u6cd5\u7684\u6bd4\u8f83\u548c\u534f\u4f5c\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aPython\u5e93\uff0c\u652f\u6301\u5c06\u4efb\u4f55\u57fa\u4e8eJax\u7684\u73af\u5883\u8f6c\u6362\u4e3a\u5728\u7ebf\u754c\u9762\uff0c\u652f\u6301\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5176\u5e94\u7528\u6f5c\u529b\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86NiceWebRL\u5728\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u5e94\u7528\uff1a\u5f00\u53d1\u4eba\u7c7b\u8ba4\u77e5\u6a21\u578b\u3001\u5f00\u53d1\u53ef\u6cdb\u5316\u5230\u4eba\u7c7b\u4f19\u4f34\u7684\u591a\u667a\u80fd\u4f53\u7b97\u6cd5\uff0c\u4ee5\u53ca\u7814\u7a76LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5bf9\u4eba\u7c7b\u7684\u8f85\u52a9\u4f5c\u7528\u3002", "conclusion": "NiceWebRL\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\uff0c\u80fd\u591f\u4fc3\u8fdb\u4eba\u7c7b\u4e0eAI\u7684\u6bd4\u8f83\u7814\u7a76\u3001\u8ba4\u77e5\u79d1\u5b66\u5b9e\u9a8c\u548c\u4eba\u673a\u534f\u4f5c\u7b97\u6cd5\u5f00\u53d1\uff0c\u4e3a\u5f00\u53d1\u4eba\u7c7b\u76f8\u4f3cAI\u3001\u4eba\u7c7b\u517c\u5bb9AI\u548c\u4eba\u7c7b\u8f85\u52a9AI\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2508.15734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15734", "abs": "https://arxiv.org/abs/2508.15734", "authors": ["Cooper Elsworth", "Keguo Huang", "David Patterson", "Ian Schneider", "Robert Sedivy", "Savannah Goodman", "Ben Townsend", "Parthasarathy Ranganathan", "Jeff Dean", "Amin Vahdat", "Ben Gomes", "James Manyika"], "title": "Measuring the environmental impact of delivering AI at Google Scale", "comment": null, "summary": "The transformative power of AI is undeniable - but as user adoption\naccelerates, so does the need to understand and mitigate the environmental\nimpact of AI serving. However, no studies have measured AI serving\nenvironmental metrics in a production environment. This paper addresses this\ngap by proposing and executing a comprehensive methodology for measuring the\nenergy usage, carbon emissions, and water consumption of AI inference workloads\nin a large-scale, AI production environment. Our approach accounts for the full\nstack of AI serving infrastructure - including active AI accelerator power,\nhost system energy, idle machine capacity, and data center energy overhead.\nThrough detailed instrumentation of Google's AI infrastructure for serving the\nGemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24\nWh of energy - a figure substantially lower than many public estimates. We also\nshow that Google's software efficiency efforts and clean energy procurement\nhave driven a 33x reduction in energy consumption and a 44x reduction in carbon\nfootprint for the median Gemini Apps text prompt over one year. We identify\nthat the median Gemini Apps text prompt uses less energy than watching nine\nseconds of television (0.24 Wh) and consumes the equivalent of five drops of\nwater (0.26 mL). While these impacts are low compared to other daily\nactivities, reducing the environmental impact of AI serving continues to\nwarrant important attention. Towards this objective, we propose that a\ncomprehensive measurement of AI serving environmental metrics is critical for\naccurately comparing models, and to properly incentivize efficiency gains\nacross the full AI serving stack.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u91cfAI\u63a8\u7406\u7684\u73af\u5883\u5f71\u54cd\uff0c\u53d1\u73b0Gemini\u6587\u672c\u63d0\u793a\u7684\u4e2d\u4f4d\u6570\u80fd\u8017\u4e3a0.24Wh\uff0c\u6bd4\u8bb8\u591a\u516c\u5f00\u4f30\u8ba1\u4f4e\u5f97\u591a\uff0c\u4e14Google\u7684\u6548\u7387\u63d0\u5347\u548c\u6e05\u6d01\u80fd\u6e90\u4f7f\u7528\u4f7f\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u5728\u4e00\u5e74\u5185\u5206\u522b\u964d\u4f4e\u4e8633\u500d\u548c44\u500d", "motivation": "\u968f\u7740AI\u7528\u6237\u91c7\u7528\u52a0\u901f\uff0c\u9700\u8981\u7406\u89e3\u548c\u51cf\u8f7bAI\u670d\u52a1\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff0c\u4f46\u76ee\u524d\u6ca1\u6709\u7814\u7a76\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u91cfAI\u670d\u52a1\u73af\u5883\u6307\u6807", "method": "\u63d0\u51fa\u5e76\u6267\u884c\u5168\u9762\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5728Google\u7684\u5927\u89c4\u6a21AI\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u91cfAI\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u7684\u80fd\u6e90\u4f7f\u7528\u3001\u78b3\u6392\u653e\u548c\u8017\u6c34\u91cf\uff0c\u5305\u62ec\u5b8c\u6574\u7684AI\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u5806\u6808", "result": "Gemini Apps\u6587\u672c\u63d0\u793a\u4e2d\u4f4d\u6570\u6d88\u80170.24Wh\u80fd\u6e90\uff0c\u6bd4\u770b\u7535\u89c69\u79d2\u7684\u80fd\u8017\u8fd8\u4f4e\uff0c\u8017\u6c34\u91cf\u76f8\u5f53\u4e8e5\u6ef4\u6c34(0.26mL)\u3002Google\u7684\u6548\u7387\u63d0\u5347\u4f7f\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u5728\u4e00\u5e74\u5185\u5206\u522b\u964d\u4f4e33\u500d\u548c44\u500d", "conclusion": "\u867d\u7136AI\u670d\u52a1\u73af\u5883\u5f71\u54cd\u76f8\u5bf9\u8f83\u4f4e\uff0c\u4f46\u4ecd\u9700\u6301\u7eed\u5173\u6ce8\u3002\u5168\u9762\u6d4b\u91cfAI\u670d\u52a1\u73af\u5883\u6307\u6807\u5bf9\u4e8e\u51c6\u786e\u6bd4\u8f83\u6a21\u578b\u548c\u5728\u5b8c\u6574AI\u670d\u52a1\u5806\u6808\u4e2d\u6fc0\u52b1\u6548\u7387\u63d0\u5347\u81f3\u5173\u91cd\u8981"}}
{"id": "2508.15748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15748", "abs": "https://arxiv.org/abs/2508.15748", "authors": ["Emma Rath", "Stuart Armstrong", "Rebecca Gorman"], "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots", "comment": null, "summary": "The development of parasocial relationships with AI agents has severe, and in\nsome cases, tragic effects for human well-being. Yet preventing such dynamics\nis challenging: parasocial cues often emerge gradually in private\nconversations, and not all forms of emotional engagement are inherently\nharmful. We address this challenge by introducing a simple response evaluation\nframework, created by repurposing a state-of-the-art language model, that\nevaluates ongoing conversations for parasocial cues in real time. To test the\nfeasibility of this approach, we constructed a small synthetic dataset of\nthirty dialogues spanning parasocial, sycophantic, and neutral conversations.\nIterative evaluation with five stage testing successfully identified all\nparasocial conversations while avoiding false positives under a tolerant\nunanimity rule, with detection typically occurring within the first few\nexchanges. These findings provide preliminary evidence that evaluation agents\ncan provide a viable solution for the prevention of parasocial relations.", "AI": {"tldr": "\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u5b9e\u65f6\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u6d4b\u8bd5\u5728\u5bf9\u8bdd\u65e9\u671f\u51c6\u786e\u68c0\u6d4b\u5047\u793e\u4ea4\u5173\u7cfb\u7b26\u53f7\uff0c\u63d0\u4f9b\u9632\u6b62\u6709\u5bb3\u5047\u793e\u4ea4\u5173\u7cfb\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u5f15\u53d1\u7684\u5047\u793e\u4ea4\u5173\u7cfb\u5bf9\u4eba\u7c7b\u5065\u5eb7\u9020\u6210\u4e25\u91cd\u5371\u5bb3\uff0c\u4f46\u9632\u6b62\u6b64\u7c7b\u95ee\u9898\u9762\u4e34\u56f0\u96be\uff0c\u56e0\u4e3a\u5047\u793e\u4ea4\u7b26\u53f7\u9010\u6e10\u51fa\u73b0\u4e14\u975e\u6240\u6709\u60c5\u611f\u4ea4\u6d41\u90fd\u6709\u5bb3\u3002", "method": "\u91cd\u65b0\u5229\u7528\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u7b80\u5355\u7684\u54cd\u5e94\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u65f6\u8bc4\u4f30\u8fdb\u884c\u4e2d\u5bf9\u8bdd\u7684\u5047\u793e\u4ea4\u7b26\u53f7\u3002\u4f7f\u752830\u4e2a\u6db5\u76d6\u5047\u793e\u4ea4\u3001\u5947\u5999\u548c\u4e2d\u6027\u5bf9\u8bdd\u7684\u5408\u6210\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u4e94\u9636\u6bb5\u8fed\u4ee3\u8bc4\u4f30\uff0c\u5728\u5bbd\u677e\u4e00\u81f4\u6027\u89c4\u5219\u4e0b\u6210\u529f\u68c0\u6d4b\u6240\u6709\u5047\u793e\u4ea4\u5bf9\u8bdd\uff0c\u4e14\u6ca1\u6709\u5047\u963b\u6027\uff0c\u68c0\u6d4b\u591a\u5728\u5bf9\u8bdd\u524d\u51e0\u8f6e\u5b8c\u6210\u3002", "conclusion": "\u8bc4\u4f30\u4ee3\u7406\u63d0\u4f9b\u4e86\u9632\u6b62\u5047\u793e\u4ea4\u5173\u7cfb\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u63d0\u4f9b\u4e86\u9884\u671f\u8bc1\u636e\u3002"}}
{"id": "2508.15757", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15757", "abs": "https://arxiv.org/abs/2508.15757", "authors": ["Yuxing Lu", "Yucheng Hu", "Nan Sun", "Xukai Zhao"], "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback", "comment": "9 pages, 4 figures, 4 tables", "summary": "Configuration optimization remains a critical bottleneck in machine learning,\nrequiring coordinated tuning across model architecture, training strategy,\nfeature engineering, and hyperparameters. Traditional approaches treat these\ndimensions independently and lack interpretability, while recent automated\nmethods struggle with dynamic adaptability and semantic reasoning about\noptimization decisions. We introduce Language-Guided Tuning (LGT), a novel\nframework that employs multi-agent Large Language Models to intelligently\noptimize configurations through natural language reasoning. We apply textual\ngradients - qualitative feedback signals that complement numerical optimization\nby providing semantic understanding of training dynamics and configuration\ninterdependencies. LGT coordinates three specialized agents: an Advisor that\nproposes configuration changes, an Evaluator that assesses progress, and an\nOptimizer that refines the decision-making process, creating a self-improving\nfeedback loop. Through comprehensive evaluation on six diverse datasets, LGT\ndemonstrates substantial improvements over traditional optimization methods,\nachieving performance gains while maintaining high interpretability.", "AI": {"tldr": "LGT\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7684\u914d\u7f6e\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u548c\u6587\u672c\u68af\u5ea6\u53cd\u9988\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u914d\u7f6e\u7684\u667a\u80fd\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u914d\u7f6e\u4f18\u5316\u5b58\u5728\u5173\u952e\u74f6\u9888\uff0c\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u7ef4\u5ea6\u72ec\u7acb\uff0c\u81ea\u52a8\u5316\u65b9\u6cd5\u96be\u4ee5\u52a8\u6001\u9002\u5e94\u548c\u8bed\u4e49\u63a8\u7406\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u5305\u542b\u63d0\u8bae\u914d\u7f6e\u53d8\u66f4\u7684Advisor\u3001\u8bc4\u4f30\u8fdb\u5c55\u7684Evaluator\u548c\u4f18\u5316\u51b3\u7b56\u8fc7\u7a0b\u7684Optimizer\uff0c\u901a\u8fc7\u6587\u672c\u68af\u5ea6\u63d0\u4f9b\u8bed\u4e49\u53cd\u9988\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cLGT\u76f8\u6bd4\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "LGT\u6846\u67b6\u901a\u8fc7\u8bed\u8a00\u5f15\u5bfc\u7684\u63a8\u7406\u548c\u6587\u672c\u68af\u5ea6\u53cd\u9988\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u5b66\u4e60\u914d\u7f6e\u4f18\u5316\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u7684\u53cc\u91cd\u63d0\u5347\u3002"}}
