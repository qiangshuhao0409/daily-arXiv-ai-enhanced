{"id": "2507.19653", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.19653", "abs": "https://arxiv.org/abs/2507.19653", "authors": ["Armen Manukyan", "Hrant Khachatrian", "Edvard Ghukasyan", "Theofanis P. Raptis"], "title": "On the Limitations of Ray-Tracing for Learning-Based RF Tasks in Urban Environments", "comment": "This work has been submitted to the IEEE for possible publication.\n  This work was supported by funding under the bilateral agreement between CNR\n  (Italy) and HESC MESCS RA (Armenia) as part of the DeepRF project for the\n  2025-2026 biennium, and by the HESC MESCS RA grant No. 22rl-052 (DISTAL)", "summary": "We study the realism of Sionna v1.0.2 ray-tracing for outdoor cellular links\nin central Rome. We use a real measurement set of 1,664 user-equipments (UEs)\nand six nominal base-station (BS) sites. Using these fixed positions we\nsystematically vary the main simulation parameters, including path depth,\ndiffuse/specular/refraction flags, carrier frequency, as well as antenna's\nproperties like its altitude, radiation pattern, and orientation. Simulator\nfidelity is scored for each base station via Spearman correlation between\nmeasured and simulated powers, and by a fingerprint-based k-nearest-neighbor\nlocalization algorithm using RSSI-based fingerprints. Across all experiments,\nsolver hyper-parameters are having immaterial effect on the chosen metrics. On\nthe contrary, antenna locations and orientations prove decisive. By simple\ngreedy optimization we improve the Spearman correlation by 5% to 130% for\nvarious base stations, while kNN-based localization error using only simulated\ndata as reference points is decreased by one-third on real-world samples, while\nstaying twice higher than the error with purely real data. Precise geometry and\ncredible antenna models are therefore necessary but not sufficient; faithfully\ncapturing the residual urban noise remains an open challenge for transferable,\nhigh-fidelity outdoor RF simulation."}
{"id": "2507.19657", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19657", "abs": "https://arxiv.org/abs/2507.19657", "authors": ["Beining Wu", "Jun Huang", "Shui Yu"], "title": "\"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems", "comment": "48 pages, 14 figures, submitted to IEEE", "summary": "The development of next-generation networking systems has inherently shifted\nfrom throughput-based paradigms towards intelligent, information-aware designs\nthat emphasize the quality, relevance, and utility of transmitted information,\nrather than sheer data volume. While classical network metrics, such as latency\nand packet loss, remain significant, they are insufficient to quantify the\nnuanced information quality requirements of modern intelligent applications,\nincluding autonomous vehicles, digital twins, and metaverse environments. In\nthis survey, we present the first comprehensive study of the ``X of\nInformation'' continuum by introducing a systematic four-dimensional taxonomic\nframework that structures information metrics along temporal, quality/utility,\nreliability/robustness, and network/communication dimensions. We uncover the\nincreasing interdependencies among these dimensions, whereby temporal freshness\ntriggers quality evaluation, which in turn helps with reliability appraisal,\nultimately enabling effective network delivery. Our analysis reveals that\nartificial intelligence technologies, such as deep reinforcement learning,\nmulti-agent systems, and neural optimization models, enable adaptive,\ncontext-aware optimization of competing information quality objectives. In our\nextensive study of six critical application domains, covering autonomous\ntransportation, industrial IoT, healthcare digital twins, UAV communications,\nLLM ecosystems, and metaverse settings, we illustrate the revolutionary promise\nof multi-dimensional information metrics for meeting diverse operational needs.\nOur survey identifies prominent implementation challenges, including ..."}
{"id": "2507.19925", "categories": ["cs.NI", "90B18", "C.2.1; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.19925", "abs": "https://arxiv.org/abs/2507.19925", "authors": ["Sowmiyan Morri", "Joy Bose", "L Raghunatha Reddy", "Sai Hareesh Anamandra"], "title": "Predicting Locations of Cell Towers for Network Capacity Expansion", "comment": "9 pages, 5 figures", "summary": "Network capacity expansion is a critical challenge for telecom operators,\nrequiring strategic placement of new cell sites to ensure optimal coverage and\nperformance. Traditional approaches, such as manual drive tests and static\noptimization, often fail to consider key real-world factors including user\ndensity, terrain features, and financial constraints. In this paper, we propose\na machine learning-based framework that combines deep neural networks for\nsignal coverage prediction with spatial clustering to recommend new tower\nlocations in underserved areas. The system integrates geospatial, demographic,\nand infrastructural data, and incorporates budget-aware constraints to\nprioritize deployments. Operating within an iterative planning loop, the\nframework refines coverage estimates after each proposed installation, enabling\nadaptive and cost-effective expansion. While full-scale simulation was limited\nby data availability, the architecture is modular, robust to missing inputs,\nand generalizable across diverse deployment scenarios. This approach advances\nradio network planning by offering a scalable, data-driven alternative to\nmanual methods."}
{"id": "2507.19938", "categories": ["cs.NI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.19938", "abs": "https://arxiv.org/abs/2507.19938", "authors": ["W. A. Sasindu Wijesuriya"], "title": "Optimizing Spreading Factor Selection for Mobile LoRa Gateways Using Single-Channel Hardware", "comment": "6 pages, 5 figures", "summary": "The deployment of mobile LoRa gateways using low-cost single-channel hardware\npresents a significant challenge in maintaining reliable communication due to\nthe lack of dynamic configuration support. In traditional LoRaWAN networks,\nAdaptive Data Rate (ADR) mechanisms optimize communication parameters in real\ntime. However, such features are typically supported only by expensive\nmulti-channel gateways. This study proposes a cost-effective and\nenergy-efficient solution by statically selecting the optimal Spreading Factor\n(SF) using a two-phase algorithm. The method first applies rule-based exclusion\nto eliminate SFs that violate constraints related to distance, data rate, link\nmargin, and regulatory limits. Remaining candidates are then evaluated using a\nweighted scoring model incorporating Time-on-Air, energy consumption, data\nrate, and link robustness. The proposed algorithm was validated through\nextensive field tests and NS-3 simulations under line-of-sight conditions.\nResults demonstrate that the selected SF matched the optimal SF in over 92% of\ncases across 672 simulated scenarios, confirming the algorithm's effectiveness.\nThis approach offers a scalable alternative to dynamic protocols, enabling\nreliable mobile LoRa deployments in cost-sensitive environments such as\nagriculture and rural sensing applications."}
{"id": "2507.19695", "categories": ["cs.IT", "cs.CR", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19695", "abs": "https://arxiv.org/abs/2507.19695", "authors": ["Geraldo A. Barbosa"], "title": "Polar Coding and Linear Decoding", "comment": "31 pages, 29 figures", "summary": "Polar encoding, described by Arikan in IEEE Transactions on Information\nTheory, Vol. 55, No. 7, July 2009, was a milestone for telecommunications. A\nPolar code distributes information among high and low-capacity channels,\nshowing the possibility of achieving perfect channel capacity. The\nhigh-capacity channels allow almost noiseless transmission of data. When these\nchannels are not high noise, reliability is achieved in the signal\ntransmission. It starts to compete against codes such a Low-Density\nParity-Check (LDPC) codes. Polar code can be also considered error correcting,\nbased on the redundancy inherent in its structure. This feature makes polar\nencoding also applicable to digital quantum-resistant cryptography protocols.\nThis work explores linear decoding at a first or single trial in the case of\nsmall losses or small number of bit-flipping, and repeated transmission for\nmedium level losses. This is distinct from Arikans successive probabilistic\ndecoding by application of probabilistic rules. Linear decoding is done\ndirectly from solving the linear equations connecting the codewords x and the\nreceived signals y after transmission via noisy channels. Numerical examples\nwill be shown. Along with this work, programming in Mathematica language was\nused. Codes are available for copy-and-paste for Mathematica users to\nimmediately try the described formalism."}
{"id": "2507.20050", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.20050", "abs": "https://arxiv.org/abs/2507.20050", "authors": ["Rohail Asim", "Ankit Bhardwaj", "Lakshmi Suramanian", "Yasir Zaki"], "title": "Towards Next Generation Immersive Applications in 5G Environments", "comment": null, "summary": "The Multi-user Immersive Reality (MIR) landscape is evolving rapidly, with\napplications spanning virtual collaboration, entertainment, and training.\nHowever, wireless network limitations create a critical bottleneck, struggling\nto meet the high-bandwidth and ultra-low latency demands essential for\nnext-generation MIR experiences. This paper presents Hera, a modular framework\nfor next-generation immersive applications, comprising a high-level streaming\nand synchronization layer for AR/VR systems and a low-level delay-based\nQoE-aware rate control protocol optimized for dynamic wireless environments.\nThe Hera framework integrates application-aware streaming logic with a\nQoE-centric rate control core, enabling adaptive video quality, multi-user\nfairness, and low-latency communication across challenging 5G network\nconditions. We demonstrate that Hera outperforms existing state-of-the-art rate\ncontrol algorithms by maintaining up to 66% lower latencies with comparable\nthroughput performance, higher visual quality with 50% average bitrate\nimprovements in our analysis, and improved fairness. By bridging the gap\nbetween application-level responsiveness and network-level adaptability, Hera\nlays the foundation for more scalable, robust, and high-fidelity multi-user\nimmersive experiences."}
{"id": "2507.19489", "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19489", "abs": "https://arxiv.org/abs/2507.19489", "authors": ["Simone Bendazzoli", "Sanna Persson", "Mehdi Astaraki", "Sebastian Pettersson", "Vitali Grozman", "Rodrigo Moreno"], "title": "MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation", "comment": "26 pages, 12 figures", "summary": "The integration of Artificial Intelligence (AI) into clinical workflows\nrequires robust collaborative platforms that are able to bridge the gap between\ntechnical innovation and practical healthcare applications. This paper\nintroduces MAIA (Medical Artificial Intelligence Assistant), an open-source\nplatform designed to facilitate interdisciplinary collaboration among\nclinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a\nmodular, scalable environment with integrated tools for data management, model\ndevelopment, annotation, deployment, and clinical feedback. Key features\ninclude project isolation, CI/CD automation, integration with high-computing\ninfrastructures and in clinical workflows. MAIA supports real-world use cases\nin medical imaging AI, with deployments in both academic and clinical\nenvironments. By promoting collaborations and interoperability, MAIA aims to\naccelerate the translation of AI research into impactful clinical solutions\nwhile promoting reproducibility, transparency, and user-centered design. We\nshowcase the use of MAIA with different projects, both at KTH Royal Institute\nof Technology and Karolinska University Hospital."}
{"id": "2507.19963", "categories": ["cs.NI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.19963", "abs": "https://arxiv.org/abs/2507.19963", "authors": ["Nikolaos Bartzoudis", "José Rubio Fernández", "David López-Bueno", "Antonio Román Villarroel"], "title": "A Scalable Resource Management Layer for FPGA SoCs in 6G Radio Units", "comment": "Paper accepted to the \"XL Simposio Nacional de la Uni\\'on\n  Cient\\'ifica Internacional de Radio (URSI 2025)\", Tarragona, Spain, 3-5\n  September 2025. Proceedings are not published. Also part of the worj appears\n  in Deliverables 2.2 and 5.2 of the SNS JU project VERGE", "summary": "This work presents a perspective on addressing the underutilization of\ncomputing resources in FPGA SoC devices deployed in 5G radio and edge computing\ninfrastructure. The initial step in this approach involves developing a\nresource management layer capable of dynamically migrating and scaling\nfunctions within these devices in response to contextual events. This layer\nserves as the foundation for designing a hierarchical, data-driven\nmicro-orchestrator responsible for managing the lifecycle of functions in FPGA\nSoC devices. In this paper, the proposed resource management layer is utilized\nto reconfigure a function based on events identified by a computer vision edge\napplication."}
{"id": "2507.19816", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19816", "abs": "https://arxiv.org/abs/2507.19816", "authors": ["Jiachuan Ye", "Shitong Wu", "Lingyi Chen", "Wenyi Zhang", "Huihui Wu", "Hao Wu"], "title": "Efficient Computation of Marton's Error Exponent via Constraint Decoupling", "comment": null, "summary": "The error exponent in lossy source coding characterizes the asymptotic decay\nrate of error probability with respect to blocklength. The Marton's error\nexponent provides the theoretically optimal bound on this rate. However,\ncomputation methods of the Marton's error exponent remain underdeveloped due to\nits formulation as a non-convex optimization problem with limited efficient\nsolvers. While a recent grid search algorithm can compute its inverse function,\nit incurs prohibitive computational costs from two-dimensional brute-force\nparameter grid searches. This paper proposes a composite maximization approach\nthat effectively handles both Marton's error exponent and its inverse function.\nThrough a constraint decoupling technique, the resulting problem formulations\nadmit efficient solvers driven by an alternating maximization algorithm. By\nfixing one parameter via a one-dimensional line search, the remaining\nsubproblem becomes convex and can be efficiently solved by alternating variable\nupdates, thereby significantly reducing search complexity. Therefore, the\nglobal convergence of the algorithm can be guaranteed. Numerical experiments\nfor simple sources and the Ahlswede's counterexample, demonstrates the superior\nefficiency of our algorithm in contrast to existing methods."}
{"id": "2507.19543", "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.19543", "abs": "https://arxiv.org/abs/2507.19543", "authors": ["Maria Emilia Mazzolenis", "Ruirui Zhang"], "title": "Agent WARPP: Workflow Adherence via Runtime Parallel Personalization", "comment": "Accepted at the ICML 2025 Workshop on Multi-Agent Systems in the Era\n  of Foundation Models: Opportunities, Challenges, and Futures. Code repo:\n  https://github.com/emiliamazzo/WARPP/", "summary": "Large language models (LLMs) are increasingly applied in task-oriented\ndialogue (TOD) systems but often struggle with long, conditional workflows that\ninvolve external tool calls and depend on user-specific information. We present\nWorkflow Adherence via Runtime Parallel Personalization, or WARPP, a\ntraining-free, modular framework that combines multi-agent orchestration with\nruntime personalization to improve workflow adherence in LLM-based systems. By\ndynamically pruning conditional branches based on user attributes, the\nframework reduces reasoning overhead and narrows tool selection at runtime.\nWARPP deploys a parallelized architecture where a dedicated Personalizer agent\noperates alongside modular, domain-specific agents to dynamically tailor\nexecution paths in real time. The framework is evaluated across five\nrepresentative user intents of varying complexity within three domains:\nbanking, flights, and healthcare. Our evaluation leverages synthetic datasets\nand LLM-powered simulated users to test scenarios with conditional\ndependencies. Our results demonstrate that WARPP outperforms both the\nnon-personalized method and the ReAct baseline, achieving increasingly larger\ngains in parameter fidelity and tool accuracy as intent complexity grows, while\nalso reducing average token usage, without any additional training."}
{"id": "2507.20050", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.20050", "abs": "https://arxiv.org/abs/2507.20050", "authors": ["Rohail Asim", "Ankit Bhardwaj", "Lakshmi Suramanian", "Yasir Zaki"], "title": "Towards Next Generation Immersive Applications in 5G Environments", "comment": null, "summary": "The Multi-user Immersive Reality (MIR) landscape is evolving rapidly, with\napplications spanning virtual collaboration, entertainment, and training.\nHowever, wireless network limitations create a critical bottleneck, struggling\nto meet the high-bandwidth and ultra-low latency demands essential for\nnext-generation MIR experiences. This paper presents Hera, a modular framework\nfor next-generation immersive applications, comprising a high-level streaming\nand synchronization layer for AR/VR systems and a low-level delay-based\nQoE-aware rate control protocol optimized for dynamic wireless environments.\nThe Hera framework integrates application-aware streaming logic with a\nQoE-centric rate control core, enabling adaptive video quality, multi-user\nfairness, and low-latency communication across challenging 5G network\nconditions. We demonstrate that Hera outperforms existing state-of-the-art rate\ncontrol algorithms by maintaining up to 66% lower latencies with comparable\nthroughput performance, higher visual quality with 50% average bitrate\nimprovements in our analysis, and improved fairness. By bridging the gap\nbetween application-level responsiveness and network-level adaptability, Hera\nlays the foundation for more scalable, robust, and high-fidelity multi-user\nimmersive experiences."}
{"id": "2507.19832", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19832", "abs": "https://arxiv.org/abs/2507.19832", "authors": ["Lingyi Chen", "Shitong Wu", "Sicheng Xu", "Huihui Wu", "Wenyi Zhang"], "title": "Neural Estimation of the Information Bottleneck Based on a Mapping Approach", "comment": "5 pages, 2 figures. This paper has been presented at the 2024 IEEE\n  Information Theory Workshop (ITW 2024)", "summary": "The information bottleneck (IB) method is a technique designed to extract\nmeaningful information related to one random variable from another random\nvariable, and has found extensive applications in machine learning problems. In\nthis paper, neural network based estimation of the IB problem solution is\nstudied, through the lens of a novel formulation of the IB problem. Via\nexploiting the inherent structure of the IB functional and leveraging the\nmapping approach, the proposed formulation of the IB problem involves only a\nsingle variable to be optimized, and subsequently is readily amenable to\ndata-driven estimators based on neural networks. A theoretical analysis is\nconducted to guarantee that the neural estimator asymptotically solves the IB\nproblem, and the numerical experiments on both synthetic and MNIST datasets\ndemonstrate the effectiveness of the neural estimator."}
{"id": "2507.19593", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.19593", "abs": "https://arxiv.org/abs/2507.19593", "authors": ["Vince Trencsenyi", "Agnieszka Mensfelt", "Kostas Stathis"], "title": "Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems", "comment": null, "summary": "Classical game-theoretic models typically assume rational agents, complete\ninformation, and common knowledge of payoffs - assumptions that are often\nviolated in real-world MAS characterized by uncertainty, misaligned\nperceptions, and nested beliefs. To overcome these limitations, researchers\nhave proposed extensions that incorporate models of cognitive constraints,\nsubjective beliefs, and heterogeneous reasoning. Among these, hypergame theory\nextends the classical paradigm by explicitly modeling agents' subjective\nperceptions of the strategic scenario, known as perceptual games, in which\nagents may hold divergent beliefs about the structure, payoffs, or available\nactions. We present a systematic review of agent-compatible applications of\nhypergame theory, examining how its descriptive capabilities have been adapted\nto dynamic and interactive MAS contexts. We analyze 44 selected studies from\ncybersecurity, robotics, social simulation, communications, and general\ngame-theoretic modeling. Building on a formal introduction to hypergame theory\nand its two major extensions - hierarchical hypergames and HNF - we develop\nagent-compatibility criteria and an agent-based classification framework to\nassess integration patterns and practical applicability. Our analysis reveals\nprevailing tendencies, including the prevalence of hierarchical and graph-based\nmodels in deceptive reasoning and the simplification of extensive theoretical\nframeworks in practical applications. We identify structural gaps, including\nthe limited adoption of HNF-based models, the lack of formal hypergame\nlanguages, and unexplored opportunities for modeling human-agent and\nagent-agent misalignment. By synthesizing trends, challenges, and open research\ndirections, this review provides a new roadmap for applying hypergame theory to\nenhance the realism and effectiveness of strategic modeling in dynamic\nmulti-agent environments."}
{"id": "2507.20115", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20115", "abs": "https://arxiv.org/abs/2507.20115", "authors": ["Gongli Xi", "Ye Tian", "Yannan Hu", "Yuchao Zhang", "Yapeng Niu", "Xiangyang Gong"], "title": "Packet-Level DDoS Data Augmentation Using Dual-Stream Temporal-Field Diffusion", "comment": "11 pages, 5 figures", "summary": "In response to Distributed Denial of Service (DDoS) attacks, recent research\nefforts increasingly rely on Machine Learning (ML)-based solutions, whose\neffectiveness largely depends on the quality of labeled training datasets. To\naddress the scarcity of such datasets, data augmentation with synthetic traces\nis often employed. However, current synthetic trace generation methods struggle\nto capture the complex temporal patterns and spatial distributions exhibited in\nemerging DDoS attacks. This results in insufficient resemblance to real traces\nand unsatisfied detection accuracy when applied to ML tasks. In this paper, we\npropose Dual-Stream Temporal-Field Diffusion (DSTF-Diffusion), a multi-view,\nmulti-stream network traffic generative model based on diffusion models,\nfeaturing two main streams: The field stream utilizes spatial mapping to bridge\nnetwork data characteristics with pre-trained realms of stable diffusion\nmodels, effectively translating complex network interactions into formats that\nstable diffusion can process, while the spatial stream adopts a dynamic\ntemporal modeling approach, meticulously capturing the intrinsic temporal\npatterns of network traffic. Extensive experiments demonstrate that data\ngenerated by our model exhibits higher statistical similarity to originals\ncompared to current state-of-the-art solutions, and enhance performances on a\nwide range of downstream tasks."}
{"id": "2507.19920", "categories": ["cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.19920", "abs": "https://arxiv.org/abs/2507.19920", "authors": ["Lingyi Chen", "Deheng Yuan", "Wenyi Zhang", "Hao Wu", "Huihui Wu"], "title": "An Efficient Alternating Minimization Algorithm for Computing Quantum Rate-Distortion Function", "comment": null, "summary": "We consider the computation of the entanglement-assisted quantum\nrate-distortion function, which plays a central role in quantum information\ntheory. We propose an efficient alternating minimization algorithm based on the\nLagrangian analysis. Instead of fixing the multiplier corresponding to the\ndistortion constraint, we update the multiplier in each iteration. Hence the\nalgorithm solves the original problem itself, rather than the Lagrangian\nrelaxation of it. Moreover, all the other variables are iterated in closed form\nwithout solving multi-dimensional nonlinear equations or multivariate\noptimization problems. Numerical experiments show the accuracy of our proposed\nalgorithm and its improved efficiency over existing methods."}
{"id": "2507.19608", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.19608", "abs": "https://arxiv.org/abs/2507.19608", "authors": ["Jiawen Qi", "Chang Gao", "Zhaochun Ren", "Qinyu Chen"], "title": "DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference", "comment": null, "summary": "Deploying Large Language Models (LLMs) on edge devices remains challenging\ndue to their quadratically increasing computations with the sequence length.\nExisting studies for dynamic attention pruning are designed for hardware with\nmassively parallel computation capabilities, such as GPUs or TPUs, and aim at\nlong context lengths (e.g., 64K), making them unsuitable for edge scenarios. We\npresent DeltaLLM, a training-free framework that exploits temporal sparsity in\nattention patterns to enable efficient LLM inference across both the prefilling\nand decoding stages, on resource-constrained edge devices. DeltaLLM introduces\nan accuracy- and memory-aware delta matrix construction strategy that\nintroduces temporal sparsity, and a context-aware hybrid attention mechanism\nthat combines full attention in a local context window with delta approximation\noutside it to increase accuracy. We evaluate our framework on the\nedge-device-friendly BitNet-b1.58-2B-4T model and Llama3.2-1B-Instruct model\nacross diverse language tasks. The results show that on BitNet, our framework\nincreases the attention sparsity from 0% to 60% during the prefilling stage\nwith slight accuracy improvement on the WG task, and 0% to 57% across both the\nprefilling and decoding stages, with even higher F1 score from 29.63 to 30.97\non SQuAD-v2 task. On the Llama model, it can also achieve up to 60% sparsity\nduring the prefilling stage and around 57% across both stages with negligible\naccuracy drop. These results demonstrate that DeltaLLM offers a promising\nsolution for efficient edge deployment, requiring no fine-tuning and seamlessly\nintegrating with existing inference pipelines."}
{"id": "2507.20116", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.20116", "abs": "https://arxiv.org/abs/2507.20116", "authors": ["Yinuo Deng", "Hailiang Zhao", "Dongjing Wang", "Peng Chen", "Wenzhuo Qian", "Jianwei Yin", "Schahram Dustdar", "Shuiguang Deng"], "title": "Accelerating Containerized Service Delivery at the Network Edge", "comment": null, "summary": "Efficient container image distribution is crucial for enabling machine\nlearning inference at the network edge, where resource limitations and dynamic\nnetwork conditions create significant challenges. In this paper, we present\nPeerSync, a decentralized P2P-based system designed to optimize image\ndistribution in edge environments. PeerSync employs a popularity- and\nnetwork-aware download engine that dynamically adapts to content popularity and\nreal-time network conditions using a sliding window mechanism. PeerSync further\nintegrates automated tracker election for rapid peer discovery and dynamic\ncache management for efficient storage utilization. We implement PeerSync with\n8000+ lines of Rust code and test its performance extensively on both physical\nedge devices and Docker-based emulations. Experimental results show that\nPeerSync delivers a remarkable speed increase of 2.72$\\times$, 1.79$\\times$,\nand 1.28$\\times$ compared to the Baseline, Dragonfly, and Kraken, respectively,\nwhile significantly reducing peak cross-network traffic by 90.72\\% under\ncongested and varying network conditions."}
{"id": "2507.19941", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19941", "abs": "https://arxiv.org/abs/2507.19941", "authors": ["Alireza Tasdighi", "Mansoor Yousefi"], "title": "Adaptive Learned Belief Propagation for Decoding Error-Correcting Codes", "comment": null, "summary": "Weighted belief propagation (WBP) for the decoding of linear block codes is\nconsidered. In WBP, the Tanner graph of the code is unrolled with respect to\nthe iterations of the belief propagation decoder. Then, weights are assigned to\nthe edges of the resulting recurrent network and optimized offline using a\ntraining dataset. The main contribution of this paper is an adaptive WBP where\nthe weights of the decoder are determined for each received word. Two variants\nof this decoder are investigated. In the parallel WBP decoders, the weights\ntake values in a discrete set. A number of WBP decoders are run in parallel to\nsearch for the best sequence of weights in real time. In the two-stage decoder,\na small neural network is used to dynamically determine the weights of the WBP\ndecoder for each received word. The proposed adaptive decoders demonstrate\nsignificant improvements over the static counterparts in two applications. In\nthe first application, Bose-Chaudhuri-Hocquenghem, polar and quasi-cyclic\nlow-density parity-check (QC-LDPC) codes are used over an additive white\nGaussian noise channel. The results indicate that the adaptive WBP achieves bit\nerror rates (BERs) up to an order of magnitude less than the BERs of the static\nWBP at about the same decoding complexity, depending on the code, its rate, and\nthe signal-to-noise ratio. The second application is a concatenated code\ndesigned for a long-haul nonlinear optical fiber channel where the inner code\nis a QC-LDPC code and the outer code is a spatially coupled LDPC code. In this\ncase, the inner code is decoded using an adaptive WBP, while the outer code is\ndecoded using the sliding window decoder and static belief propagation. The\nresults show that the adaptive WBP provides a coding gain of 0.8 dB compared to\nthe neural normalized min-sum decoder, with about the same computational\ncomplexity and decoding latency."}
{"id": "2507.19672", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.19672", "abs": "https://arxiv.org/abs/2507.19672", "authors": ["Haoran Lu", "Luyang Fang", "Ruidong Zhang", "Xinliang Li", "Jiazhang Cai", "Huimin Cheng", "Lin Tang", "Ziyu Liu", "Zeliang Sun", "Tao Wang", "Yingchuan Zhang", "Arif Hassan Zidan", "Jinwen Xu", "Jincheng Yu", "Meizhi Yu", "Hanqi Jiang", "Xilin Gong", "Weidi Luo", "Bolun Sun", "Yongkai Chen", "Terry Ma", "Shushan Wu", "Yifan Zhou", "Junhao Chen", "Haotian Xiang", "Jing Zhang", "Afrar Jahin", "Wei Ruan", "Ke Deng", "Yi Pan", "Peilong Wang", "Jiahui Li", "Zhengliang Liu", "Lu Zhang", "Lin Zhao", "Wei Liu", "Dajiang Zhu", "Xin Xing", "Fei Dou", "Wei Zhang", "Chao Huang", "Rongjie Liu", "Mengrui Zhang", "Yiwen Liu", "Xiaoxiao Sun", "Qin Lu", "Zhen Xiang", "Wenxuan Zhong", "Tianming Liu", "Ping Ma"], "title": "Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges", "comment": "119 pages, 10 figures, 7 tables", "summary": "Due to the remarkable capabilities and growing impact of large language\nmodels (LLMs), they have been deeply integrated into many aspects of society.\nThus, ensuring their alignment with human values and intentions has emerged as\na critical challenge. This survey provides a comprehensive overview of\npractical alignment techniques, training protocols, and empirical findings in\nLLM alignment. We analyze the development of alignment methods across diverse\nparadigms, characterizing the fundamental trade-offs between core alignment\nobjectives. Our analysis shows that while supervised fine-tuning enables basic\ninstruction-following, preference-based methods offer more flexibility for\naligning with nuanced human intent. We discuss state-of-the-art techniques,\nincluding Direct Preference Optimization (DPO), Constitutional AI,\nbrain-inspired methods, and alignment uncertainty quantification (AUQ),\nhighlighting their approaches to balancing quality and efficiency. We review\nexisting evaluation frameworks and benchmarking datasets, emphasizing\nlimitations such as reward misspecification, distributional robustness, and\nscalable oversight. We summarize strategies adopted by leading AI labs to\nillustrate the current state of practice. We conclude by outlining open\nproblems in oversight, value pluralism, robustness, and continuous alignment.\nThis survey aims to inform both researchers and practitioners navigating the\nevolving landscape of LLM alignment."}
{"id": "2507.20234", "categories": ["cs.NI", "cs.ET", "cs.SI", "C.2.4"], "pdf": "https://arxiv.org/pdf/2507.20234", "abs": "https://arxiv.org/abs/2507.20234", "authors": ["Burak Arda Okutan", "Stefan Schmid", "Yvonne-Anne Pignolet"], "title": "Democracy for DAOs: An Empirical Study of Decentralized Governance and Dynamic (Case Study Internet Computer SNS Ecosystem)", "comment": "This paper is an extended version of the work presented at the IEEE\n  International Conference on Blockchain and Cryptocurrency (ICBC) 2025", "summary": "Decentralized autonomous organizations (DAOs) rely on governance mechanism\nwithout centralized leadership. This paper presents an empirical study of user\nbehavior in governance for a variety of DAOs, ranging from DeFi to gaming,\nusing the Internet Computer Protocol DAO framework called SNS (Service Nervous\nSystem). To analyse user engagement, we measure participation rates and\nfrequency of proposals submission and voter approval rates. We evaluate\ndecision duration times to determine DAO agility. To investigate dynamic\naspects, we also measure metric shifts in time. We evaluate over 3,000\nproposals submitted in a time frame of 20 months from 14 SNS DAOs. The selected\nDAO have been existing between 6 and 20 months and cover a wide spectrum of use\ncases, treasury sizes, and number of participants. We also compare our results\nfor SNS DAOs with DAOs from other blockchain platforms. While approval rates\nare generally high for all DAOs studied, SNS DAOs show slightly more alignment.\nWe observe that the SNS governance mechanisms and processes in ICP lead to\nhigher activity, lower costs and faster decisions. Most importantly, in\ncontrast to studies which report a decline in participation over time for other\nframeworks, SNS DAOs exhibit sustained or increasing engagement levels over\ntime."}
{"id": "2507.19986", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19986", "abs": "https://arxiv.org/abs/2507.19986", "authors": ["Yaqi Li", "Xiaohu You", "Jiamin Li", "Chen Ji", "Bin Sheng"], "title": "Performance Analysis of Spatiotemporal 2-D Polar Codes for Massive MIMO with MMSE Receivers", "comment": "12 pages, 17 figures", "summary": "With the evolution from 5G to 6G, ultra-reliable low-latency communication\n(URLLC) faces increasingly stringent performance requirements. Lower latency\nconstraints demand shorter channel coding lengths, which can severely degrade\ndecoding performance. The massive multiple-input multiple-output (MIMO) system\nis considered a crucial technology to address this challenge due to its\nabundant spatial degrees of freedom (DoF). While polar codes are theoretically\ncapacity-achieving in the limit of infinite code length, their practical\napplicability is limited by significant decoding latency. In this paper, we\nestablish a unified theoretical framework and propose a novel spatiotemporal\ntwo-dimensional (2-D) polar coding scheme for massive MIMO systems employing\nminimum mean square error (MMSE) receivers. The polar transform is jointly\napplied over both spatial and temporal dimensions to fully exploit the large\nspatial DoF. By leveraging the near-deterministic\nsignal-to-interference-plus-noise ratio (SINR) property of MMSE detection, the\nspatial domain is modeled as a set of parallel Gaussian sub-channels. Within\nthis framework, we perform a theoretical analysis of the 2-D polarization\nbehavior using the Gaussian approximation method, and the capacity-achieving\nproperty of the proposed scheme is proved under finite blocklength constraints\nand large spatial DoF. Simulation results further demonstrate that, compared to\ntraditional time-domain polar codes, the proposed 2-D scheme can significantly\nreduce latency while guaranteeing reliability, or alternatively improve\nreliability under the same latency constraint -- offering a capacity-achieving\nand latency-efficient channel coding solution for massive MIMO systems in\nfuture 6G URLLC scenarios."}
{"id": "2507.19703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19703", "abs": "https://arxiv.org/abs/2507.19703", "authors": ["Peter V. Coveney", "Sauro Succi"], "title": "The wall confronting large language models", "comment": null, "summary": "We show that the scaling laws which determine the performance of large\nlanguage models (LLMs) severely limit their ability to improve the uncertainty\nof their predictions. As a result, raising their reliability to meet the\nstandards of scientific inquiry is intractable by any reasonable measure. We\nargue that the very mechanism which fuels much of the learning power of LLMs,\nnamely the ability to generate non-Gaussian output distributions from Gaussian\ninput ones, might well be at the roots of their propensity to produce error\npileup, ensuing information catastrophes and degenerative AI behaviour. This\ntension between learning and accuracy is a likely candidate mechanism\nunderlying the observed low values of the scaling components. It is\nsubstantially compounded by the deluge of spurious correlations pointed out by\nCalude and Longo which rapidly increase in any data set merely as a function of\nits size, regardless of its nature. The fact that a degenerative AI pathway is\na very probable feature of the LLM landscape does not mean that it must\ninevitably arise in all future AI research. Its avoidance, which we also\ndiscuss in this paper, necessitates putting a much higher premium on insight\nand understanding of the structural characteristics of the problems being\ninvestigated."}
{"id": "2507.20367", "categories": ["cs.NI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20367", "abs": "https://arxiv.org/abs/2507.20367", "authors": ["Charitha Madapatha", "Piotr Lechowicz", "Carlos Natalino", "Paolo Monti", "Tommy Svensson"], "title": "Joint Fiber and Free Space Optical Infrastructure Planning for Hybrid Integrated Access and Backhaul Networks", "comment": "Accepted invited paper for IEEE PIMRC 2025, Istanbul, Turkey", "summary": "Integrated access and backhaul (IAB) is one of the promising techniques for\n5G networks and beyond (6G), in which the same node/hardware is used to provide\nboth backhaul and cellular services in a multi-hop architecture. Due to the\nsensitivity of the backhaul links with high rate/reliability demands, proper\nnetwork planning is needed to ensure the IAB network performs with the desired\nperformance levels. In this paper, we study the effect of infrastructure\nplanning and optimization on the coverage of IAB networks. We concentrate on\nthe cases where the fiber connectivity to the nodes is constrained due to cost.\nThereby, we study the performance gains and energy efficiency in the presence\nof free-space optical (FSO) communication links. Our results indicate hybrid\nfiber/FSO deployments offer substantial cost savings compared to fully fibered\nnetworks, suggesting a beneficial trade-off for strategic link deployment while\nimproving the service coverage probability. As we show, with proper network\nplanning, the service coverage, energy efficiency, and cost efficiency can be\nimproved."}
{"id": "2507.20113", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20113", "abs": "https://arxiv.org/abs/2507.20113", "authors": ["Ji Wang", "Jiayu Tian", "Lijuan Qin", "Kunrui Cao", "Hongbo Xu", "Xingwang Li", "Tony. Q. S. Quek"], "title": "Rotatable RIS Assisted Physical Layer Multicasting", "comment": null, "summary": "Reconfigurable Intelligent Surfaces (RIS) dynamically control signal\npropagation to enhance wireless communications. This paper presents a novel\nframework for rotatable RIS assisted physical-layer multicast systems, aiming\nto maximize the sum of minimum multicast rates via joint optimization of base\nstation beamforming, RIS phase shifts, and orientation. Unlike unicast or\nnon-rotatable setups, the rotatable RIS adapts orientation to align signals\nwith user groups, improving fairness and rates for weak users. An alternating\noptimization approach combines convex optimization for beamforming/phase shifts\nwith exhaustive search and particle swarm optimization (PSO) for orientation.\nMajorization-Minimization-based algorithms solve subproblems iteratively.\nSimulation results show the framework achieves 24.1% rate improvement via\nexhaustive search and 20.0% via PSO over the non-rotatable RIS baseline, with\nPSO performance close to the exhaustive search upper bound, highlighting the\nbenefits of physical-layer multicast and orientation optimization."}
{"id": "2507.19725", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19725", "abs": "https://arxiv.org/abs/2507.19725", "authors": ["Leonardo Villalobos-Arias", "Grant Forbes", "Jianxun Wang", "David L Roberts", "Arnav Jhala"], "title": "Minding Motivation: The Effect of Intrinsic Motivation on Agent Behaviors", "comment": "11 pages, 7 figures, 3 tables", "summary": "Games are challenging for Reinforcement Learning~(RL) agents due to their\nreward-sparsity, as rewards are only obtainable after long sequences of\ndeliberate actions. Intrinsic Motivation~(IM) methods -- which introduce\nexploration rewards -- are an effective solution to reward-sparsity. However,\nIM also causes an issue known as `reward hacking' where the agent optimizes for\nthe new reward at the expense of properly playing the game. The larger problem\nis that reward hacking itself is largely unknown; there is no answer to\nwhether, and to what extent, IM rewards change the behavior of RL agents. This\nstudy takes a first step by empirically evaluating the impact on behavior of\nthree IM techniques on the MiniGrid game-like environment. We compare these IM\nmodels with Generalized Reward Matching~(GRM), a method that can be used with\nany intrinsic reward function to guarantee optimality. Our results suggest that\nIM causes noticeable change by increasing the initial rewards, but also\naltering the way the agent plays; and that GRM mitigated reward hacking in some\nscenarios."}
{"id": "2507.20438", "categories": ["cs.NI", "cs.OH", "C.2.0"], "pdf": "https://arxiv.org/pdf/2507.20438", "abs": "https://arxiv.org/abs/2507.20438", "authors": ["Rostand A. K. Fezeu", "Jason Carpenter", "Rushikesh Zende", "Sree Ganesh Lalitaditya Divakarla", "Nitin Varyani", "Faaiq Bilal", "Steven Sleder", "Nanditha Naik", "Duncan Joly", "Eman Ramadan", "Ajay Kumar Gurumadaiah", "Zhi-Li Zhang"], "title": "Teleoperating Autonomous Vehicles over Commercial 5G Networks: Are We There Yet?", "comment": "17 pages", "summary": "Remote driving, or teleoperating Autonomous Vehicles (AVs), is a key\napplication that emerging 5G networks aim to support. In this paper, we conduct\na systematic feasibility study of AV teleoperation over commercial 5G networks\nfrom both cross-layer and end-to-end (E2E) perspectives. Given the critical\nimportance of timely delivery of sensor data, such as camera and LiDAR data,\nfor AV teleoperation, we focus in particular on the performance of uplink\nsensor data delivery. We analyze the impacts of Physical Layer (PHY layer) 5G\nradio network factors, including channel conditions, radio resource allocation,\nand Handovers (HOs), on E2E latency performance. We also examine the impacts of\n5G networks on the performance of upper-layer protocols and E2E application\nQuality-of-Experience (QoE) adaptation mechanisms used for real-time sensor\ndata delivery, such as Real-Time Streaming Protocol (RTSP) and Web Real Time\nCommunication (WebRTC). Our study reveals the challenges posed by today's 5G\nnetworks and the limitations of existing sensor data streaming mechanisms. The\ninsights gained will help inform the co-design of future-generation wireless\nnetworks, edge cloud systems, and applications to overcome the low-latency\nbarriers in AV teleoperation."}
{"id": "2507.20129", "categories": ["cs.IT", "cs.NA", "math.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.20129", "abs": "https://arxiv.org/abs/2507.20129", "authors": ["Shitong Wu", "Wenhao Ye", "Xinwei Li", "Lingyi Chen", "Wenyi Zhang", "Huihui Wu", "Hao Wu"], "title": "An Optimal Transport-Based Method for Computing LM Rate and Its Convergence Analysis", "comment": null, "summary": "The mismatch capacity characterizes the highest information rate of the\nchannel under a prescribed decoding metric and serves as a critical performance\nindicator in numerous practical communication scenarios. Compared to the\ncommonly used Generalized Mutual Information (GMI), the Lower bound on the\nMismatch capacity (LM rate) generally provides a tighter lower bound on the\nmismatch capacity. However, the efficient computation of the LM rate is\nsignificantly more challenging than that of the GMI, particularly as the size\nof the channel input alphabet increases. This growth in complexity renders\nstandard numerical methods (e.g., interior point methods) computationally\nintensive and, in some cases, impractical. In this work, we reformulate the\ncomputation of the LM rate as a special instance of the optimal transport (OT)\nproblem with an additional constraint. Building on this formulation, we develop\na novel numerical algorithm based on the Sinkhorn algorithm, which is well\nknown for its efficiency in solving entropy regularized optimization problems.\nWe further provide the convergence analysis of the proposed algorithm,\nrevealing that the algorithm has a sub-linear convergence rate. Numerical\nexperiments demonstrate the feasibility and efficiency of the proposed\nalgorithm for the computation of the LM rate."}
{"id": "2507.19726", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.19726", "abs": "https://arxiv.org/abs/2507.19726", "authors": ["Yuzhang Xie", "Xu Han", "Ran Xu", "Xiao Hu", "Jiaying Lu", "Carl Yang"], "title": "HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare", "comment": "Extended version of paper accepted at the 24th International Semantic\n  Web Conference (ISWC 2025), Main Tracks, Research Track, Oral", "summary": "Knowledge graphs (KGs) are important products of the semantic web, which are\nwidely used in various application domains. Healthcare is one of such domains\nwhere KGs are intensively used, due to the high requirement for knowledge\naccuracy and interconnected nature of healthcare data. However, KGs storing\ngeneral factual information often lack the ability to account for important\ncontexts of the knowledge such as the status of specific patients, which are\ncrucial in precision healthcare. Meanwhile, electronic health records (EHRs)\nprovide rich personal data, including various diagnoses and medications, which\nprovide natural contexts for general KGs. In this paper, we propose HypKG, a\nframework that integrates patient information from EHRs into KGs to generate\ncontextualized knowledge representations for accurate healthcare predictions.\nUsing advanced entity-linking techniques, we connect relevant knowledge from\ngeneral KGs with patient information from EHRs, and then utilize a hypergraph\nmodel to \"contextualize\" the knowledge with the patient information. Finally,\nwe employ hypergraph transformers guided by downstream prediction tasks to\njointly learn proper contextualized representations for both KGs and patients,\nfully leveraging existing knowledge in KGs and patient contexts in EHRs. In\nexperiments using a large biomedical KG and two real-world EHR datasets, HypKG\ndemonstrates significant improvements in healthcare prediction tasks across\nmultiple evaluation metrics. Additionally, by integrating external contexts,\nHypKG can learn to adjust the representations of entities and relations in KG,\npotentially improving the quality and real-world utility of knowledge."}
{"id": "2507.20467", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.20467", "abs": "https://arxiv.org/abs/2507.20467", "authors": ["Avi Deb Raha", "Apurba Adhikary", "Mrityunjoy Gain", "Yumin Park", "Walid Saad", "Choong Seon Hong"], "title": "DD-JSCC: Dynamic Deep Joint Source-Channel Coding for Semantic Communications", "comment": null, "summary": "Deep Joint Source-Channel Coding (Deep-JSCC) has emerged as a promising\nsemantic communication approach for wireless image transmission by jointly\noptimizing source and channel coding using deep learning techniques. However,\ntraditional Deep-JSCC architectures employ fixed encoder-decoder structures,\nlimiting their adaptability to varying device capabilities, real-time\nperformance optimization, power constraints and channel conditions. To address\nthese limitations, we propose DD-JSCC: Dynamic Deep Joint Source-Channel Coding\nfor Semantic Communications, a novel encoder-decoder architecture designed for\nsemantic communication systems. Unlike traditional Deep-JSCC models, DD-JSCC is\nflexible for dynamically adjusting its layer structures in real-time based on\ntransmitter and receiver capabilities, power constraints, compression ratios,\nand current channel conditions. This adaptability is achieved through a\nhierarchical layer activation mechanism combined with implicit regularization\nvia sequential randomized training, effectively reducing combinatorial\ncomplexity, preventing overfitting, and ensuring consistent feature\nrepresentations across varying configurations. Simulation results demonstrate\nthat DD-JSCC enhances the performance of image reconstruction in semantic\ncommunications, achieving up to 2 dB improvement in Peak Signal-to-Noise Ratio\n(PSNR) over fixed Deep-JSCC architectures, while reducing training costs by\nover 40%. The proposed unified framework eliminates the need for multiple\nspecialized models, significantly reducing training complexity and deployment\noverhead."}
{"id": "2507.20157", "categories": ["cs.IT", "math.IT", "math.PR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.20157", "abs": "https://arxiv.org/abs/2507.20157", "authors": ["Emmanouil M. Athanasakos", "Hariprasad Manjunath"], "title": "Sparse Regression Codes for Secret Key Agreement: Achieving Strong Secrecy and Near-Optimal Rates for Gaussian Sources", "comment": "15 pages, 5 figures", "summary": "Secret key agreement from correlated physical layer observations is a\ncornerstone of information-theoretic security. This paper proposes and\nrigorously analyzes a complete, constructive protocol for secret key agreement\nfrom Gaussian sources using Sparse Regression Codes (SPARCs). Our protocol\nsystematically leverages the known optimality of SPARCs for both\nrate-distortion and Wyner-Ziv (WZ) coding, facilitated by their inherent nested\nstructure. The primary contribution of this work is a comprehensive end-to-end\nanalysis demonstrating that the proposed scheme achieves near-optimal secret\nkey rates with strong secrecy guarantees, as quantified by a vanishing\nvariational distance. We explicitly characterize the gap to the optimal rate,\nrevealing a fundamental trade-off between the key rate and the required public\ncommunication overhead, which is governed by a tunable quantization parameter.\nFurthermore, we uncover a non-trivial constrained optimization for this\nparameter, showing that practical constraints on the SPARC code parameters\ninduce a peak in the achievable secret key rate. This work establishes SPARCs\nas a viable and theoretically sound framework for secure key generation,\nproviding a compelling low-complexity alternative to existing schemes and\noffering new insights into the practical design of such protocols."}
{"id": "2507.19733", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.19733", "abs": "https://arxiv.org/abs/2507.19733", "authors": ["Alec Scully", "Cameron Stockton", "Forrest Hare"], "title": "Integrating Activity Predictions in Knowledge Graphs", "comment": "7 pages. 18 figures. Semantic Technology for Intelligence, Defense,\n  and Security (STIDS 2024)", "summary": "We argue that ontology-structured knowledge graphs can play a crucial role in\ngenerating predictions about future events. By leveraging the semantic\nframework provided by Basic Formal Ontology (BFO) and Common Core Ontologies\n(CCO), we demonstrate how data such as the movements of a fishing vessel can be\norganized in and retrieved from a knowledge graph. These query results are then\nused to create Markov chain models, allowing us to predict future states based\non the vessel's history. To fully support this process, we introduce the term\n`spatiotemporal instant' to complete the necessary structural semantics.\nAdditionally, we critique the prevailing ontological model of probability,\nwhich conflates probability with likelihood and relies on the problematic\nconcept of modal measurements: measurements of future entities. We propose an\nalternative view, where probabilities are treated as being about process\nprofiles, which better captures the dynamics of real world phenomena. Finally,\nwe demonstrate how our Markov chain based probability calculations can be\nseamlessly integrated back into the knowledge graph, enabling further analysis\nand decision-making. Keywords: predictive analytics, ontology, Markov chains,\nprobability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL."}
{"id": "2507.20524", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.20524", "abs": "https://arxiv.org/abs/2507.20524", "authors": ["Zhang Liu", "Lianfen Huang", "Zhibin Gao", "Xianbin Wang", "Dusit Niyato", "Xuemin", "Shen"], "title": "A Lyapunov-Guided Diffusion-Based Reinforcement Learning Approach for UAV-Assisted Vehicular Networks with Delayed CSI Feedback", "comment": "13 pages, 11 figures, transactions paper", "summary": "Low altitude uncrewed aerial vehicles (UAVs) are expected to facilitate the\ndevelopment of aerial-ground integrated intelligent transportation systems and\nunlocking the potential of the emerging low-altitude economy. However, several\ncritical challenges persist, including the dynamic optimization of network\nresources and UAV trajectories, limited UAV endurance, and imperfect channel\nstate information (CSI). In this paper, we offer new insights into low-altitude\neconomy networking by exploring intelligent UAV-assisted vehicle-to-everything\ncommunication strategies aligned with UAV energy efficiency. Particularly, we\nformulate an optimization problem of joint channel allocation, power control,\nand flight altitude adjustment in UAV-assisted vehicular networks. Taking CSI\nfeedback delay into account, our objective is to maximize the vehicle-to-UAV\ncommunication sum rate while satisfying the UAV's long-term energy constraint.\nTo this end, we first leverage Lyapunov optimization to decompose the original\nlong-term problem into a series of per-slot deterministic subproblems. We then\npropose a diffusion-based deep deterministic policy gradient (D3PG) algorithm,\nwhich innovatively integrates diffusion models to determine optimal channel\nallocation, power control, and flight altitude adjustment decisions. Through\nextensive simulations using real-world vehicle mobility traces, we demonstrate\nthe superior performance of the proposed D3PG algorithm compared to existing\nbenchmark solutions."}
{"id": "2507.20255", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20255", "abs": "https://arxiv.org/abs/2507.20255", "authors": ["Brendon McBain", "Yi Hong", "Emanuele Viterbo"], "title": "Stochastic Channel Models for Satellite Mega-Constellations", "comment": "Accepted for publication in the IEEE Transactions on Communications\n  in July 2025", "summary": "A general satellite channel model is proposed for communications between a\nrapidly moving low Earth orbit (LEO) satellite in a mega-constellation and a\nstationary user on Earth. The channel uses a non-homogeneous binomial point\nprocess (NBPP) for modelling the satellite positions, marked with an\nascending/descending binary random variable for modelling the satellite\ndirections. Using the marked NBPP, we derive the probability distributions of\npower gain, propagation delay, and Doppler shift, resulting in a stochastic\nsignal propagation model for the mega-constellation geometry in isolation of\nother effects. This forms the basis for our proposed channel model as a\nrandomly time-varying channel. The scattering function of this channel is\nderived to characterise how the received power is spread in the delay-Doppler\ndomain. Global channel parameters such as path loss and channel spread are\nanalysed in terms of the scattering function. The channel statistics and the\nglobal channel parameters closely match realistic orbit simulations of the\nStarlink constellation."}
{"id": "2507.19749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19749", "abs": "https://arxiv.org/abs/2507.19749", "authors": ["Lin Ren", "Guohui Xiao", "Guilin Qi", "Yishuai Geng", "Haohan Xue"], "title": "Can LLMs Solve ASP Problems? Insights from a Benchmarking Study (Extended Version)", "comment": "Accepted for publication at the 22nd International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2025). The code is\n  available at https://github.com/HomuraT/ASPBench", "summary": "Answer Set Programming (ASP) is a powerful paradigm for non-monotonic\nreasoning. Recently, large language models (LLMs) have demonstrated promising\ncapabilities in logical reasoning. Despite this potential, current evaluations\nof LLM capabilities in ASP are often limited. Existing works normally employ\noverly simplified ASP programs, do not support negation, disjunction, or\nmultiple answer sets. Furthermore, there is a lack of benchmarks that introduce\ntasks specifically designed for ASP solving. To bridge this gap, we introduce\nASPBench, a comprehensive ASP benchmark, including three ASP specific tasks:\nASP entailment, answer set verification, and answer set computation. Our\nextensive evaluations on ASPBench reveal that while 14 state-of-the-art LLMs,\nincluding \\emph{deepseek-r1}, \\emph{o4-mini}, and\n\\emph{gemini-2.5-flash-thinking}, perform relatively well on the first two\nsimpler tasks, they struggle with answer set computation, which is the core of\nASP solving. These findings offer insights into the current limitations of LLMs\nin ASP solving. This highlights the need for new approaches that integrate\nsymbolic reasoning capabilities more effectively. The code and dataset are\navailable at https://github.com/HomuraT/ASPBench."}
{"id": "2507.20806", "categories": ["cs.NI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.20806", "abs": "https://arxiv.org/abs/2507.20806", "authors": ["Yunming Xiao", "Peizhi Liu", "Ruijie Yu", "Chenkai Weng", "Matteo Varvello", "Aleksandar Kuzmanovic"], "title": "Collusion Resistant DNS With Private Information Retrieval", "comment": null, "summary": "There has been a growing interest in Internet user privacy, demonstrated by\nthe popularity of privacy-preserving products such as Telegram and Brave, and\nthe widespread adoption of HTTPS. The Domain Name System (DNS) is a key\ncomponent of Internet-based communication and its privacy has been neglected\nfor years. Recently, DNS over HTTPS (DoH) has improved the situation by fixing\nthe issue of in-path middleboxes. Further progress has been made with\nproxy-based solutions such as Oblivious DoH (ODoH), which separate a user's\nidentity from their DNS queries. However, these solutions rely on non-collusion\nassumptions between DNS resolvers and proxies -- an assumption difficult to\nguarantee in practice. To address this, we explore integrating single-server\nPrivate Information Retrieval (PIR) into DNS to enable encrypted query\nprocessing without relying on trust assumptions. However, applying PIR to DNS\nis challenging due to its hierarchical nature -- particularly, interactions\nwith recursive resolvers can still leak information. Navigating performance and\nprivacy trade-offs, we propose PDNS, a DNS extension leveraging single-server\nPIR to strengthen privacy guarantees. We have implemented a prototype of PDNS\nand compared its performance against state-of-the-art solutions via\ntrace-driven experiments. The results show that PDNS achieves acceptable\nperformance (2x faster than DoH over Tor with similar privacy guarantees) and\nstrong privacy guarantees today, mainly at the cost of its scalability, which\nspecialized hardware for PIR can address in the near future."}
{"id": "2507.20281", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20281", "abs": "https://arxiv.org/abs/2507.20281", "authors": ["Emna Ben Yacoub", "Gianluigi Liva", "Enrico Paolini", "Marco Chiani"], "title": "Ensemble Average Analysis of Non-Adaptive Group Testing with Sparse Pooling Graphs", "comment": "To be presented at the 2025 International Symposium on Topics in\n  Coding (ISTC)", "summary": "A combinatorial analysis of the false alarm (FA) and misdetection (MD)\nprobabilities of non-adaptive group testing with sparse pooling graphs is\ndeveloped. The analysis targets the combinatorial orthogonal matching pursuit\nand definite defective detection algorithms in the noiseless, non-quantitative\nsetting. The approach follows an ensemble average perspective, where average\nFA/MD probabilities are computed for pooling graph ensembles with prescribed\ndegree distributions. The accuracy of the analysis is demonstrated through\nnumerical examples, showing that the proposed technique can be used to\ncharacterize the performance of non-adaptive group testing schemes based on\nsparse pooling graphs."}
{"id": "2507.19788", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19788", "abs": "https://arxiv.org/abs/2507.19788", "authors": ["Rifny Rachman", "Josh Tingey", "Richard Allmendinger", "Pradyumn Shukla", "Wei Pan"], "title": "Reinforcement Learning for Multi-Objective Multi-Echelon Supply Chain Optimisation", "comment": null, "summary": "This study develops a generalised multi-objective, multi-echelon supply chain\noptimisation model with non-stationary markets based on a Markov decision\nprocess, incorporating economic, environmental, and social considerations. The\nmodel is evaluated using a multi-objective reinforcement learning (RL) method,\nbenchmarked against an originally single-objective RL algorithm modified with\nweighted sum using predefined weights, and a multi-objective evolutionary\nalgorithm (MOEA)-based approach. We conduct experiments on varying network\ncomplexities, mimicking typical real-world challenges using a customisable\nsimulator. The model determines production and delivery quantities across\nsupply chain routes to achieve near-optimal trade-offs between competing\nobjectives, approximating Pareto front sets. The results demonstrate that the\nprimary approach provides the most balanced trade-off between optimality,\ndiversity, and density, further enhanced with a shared experience buffer that\nallows knowledge transfer among policies. In complex settings, it achieves up\nto 75\\% higher hypervolume than the MOEA-based method and generates solutions\nthat are approximately eleven times denser, signifying better robustness, than\nthose produced by the modified single-objective RL method. Moreover, it ensures\nstable production and inventory levels while minimising demand loss."}
{"id": "2507.20871", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.20871", "abs": "https://arxiv.org/abs/2507.20871", "authors": ["Wenxuan Ye", "Xueli An", "Junfan Wang", "Xueqiang Yan", "Georg Carle"], "title": "\\textit{FedABC}: Attention-Based Client Selection for Federated Learning with Long-Term View", "comment": "Accepted to ICC 2025", "summary": "Native AI support is a key objective in the evolution of 6G networks, with\nFederated Learning (FL) emerging as a promising paradigm. FL allows\ndecentralized clients to collaboratively train an AI model without directly\nsharing their data, preserving privacy. Clients train local models on private\ndata and share model updates, which a central server aggregates to refine the\nglobal model and redistribute it for the next iteration. However, client data\nheterogeneity slows convergence and reduces model accuracy, and frequent client\nparticipation imposes communication and computational burdens. To address these\nchallenges, we propose \\textit{FedABC}, an innovative client selection\nalgorithm designed to take a long-term view in managing data heterogeneity and\noptimizing client participation. Inspired by attention mechanisms,\n\\textit{FedABC} prioritizes informative clients by evaluating both model\nsimilarity and each model's unique contributions to the global model. Moreover,\nconsidering the evolving demands of the global model, we formulate an\noptimization problem to guide \\textit{FedABC} throughout the training process.\nFollowing the ``later-is-better\" principle, \\textit{FedABC} adaptively adjusts\nthe client selection threshold, encouraging greater participation in later\ntraining stages. Extensive simulations on CIFAR-10 demonstrate that\n\\textit{FedABC} significantly outperforms existing approaches in model accuracy\nand client participation efficiency, achieving comparable performance with 32\\%\nfewer clients than the classical FL algorithm \\textit{FedAvg}, and 3.5\\% higher\naccuracy with 2\\% fewer clients than the state-of-the-art. This work marks a\nstep toward deploying FL in heterogeneous, resource-constrained environments,\nthereby supporting native AI capabilities in 6G networks."}
{"id": "2507.20477", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20477", "abs": "https://arxiv.org/abs/2507.20477", "authors": ["Maojun Zhang", "Guangxu Zhu", "Xiaoming Chen", "Kaibin Huang", "Zhaoyang Zhang"], "title": "Rethinking Multi-User Communication in Semantic Domain: Enhanced OMDMA by Shuffle-Based Orthogonalization and Diffusion Denoising", "comment": "16 pages", "summary": "Inter-user interference remains a critical bottleneck in wireless\ncommunication systems, particularly in the emerging paradigm of semantic\ncommunication (SemCom). Compared to traditional systems, inter-user\ninterference in SemCom severely degrades key semantic information, often\ncausing worse performance than Gaussian noise under the same power level. To\naddress this challenge, inspired by the recently proposed concept of Orthogonal\nModel Division Multiple Access (OMDMA) that leverages semantic orthogonality\nrooted in the personalized joint source and channel (JSCC) models to\ndistinguish users, we propose a novel, scalable framework that eliminates the\nneed for user-specific JSCC models as did in original OMDMA. Our key innovation\nlies in shuffle-based orthogonalization, where randomly permuting the positions\nof JSCC feature vectors transforms inter-user interference into Gaussian-like\nnoise. By assigning each user a unique shuffling pattern, the interference is\ntreated as channel noise, enabling effective mitigation using diffusion models\n(DMs). This approach not only simplifies system design by requiring a single\nuniversal JSCC model but also enhances privacy, as shuffling patterns act as\nimplicit private keys. Additionally, we extend the framework to scenarios\ninvolving semantically correlated data. By grouping users based on semantic\nsimilarity, a cooperative beamforming strategy is introduced to exploit\nredundancy in correlated data, further improving system performance. Extensive\nsimulations demonstrate that the proposed method outperforms state-of-the-art\nmulti-user SemCom frameworks, achieving superior semantic fidelity, robustness\nto interference, and scalability-all without requiring additional training\noverhead."}
{"id": "2507.19882", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19882", "abs": "https://arxiv.org/abs/2507.19882", "authors": ["Xinshu Li", "Ruoyu Wang", "Erdun Gao", "Mingming Gong", "Lina Yao"], "title": "Causality-aligned Prompt Learning via Diffusion-based Counterfactual Generation", "comment": null, "summary": "Prompt learning has garnered attention for its efficiency over traditional\nmodel training and fine-tuning. However, existing methods, constrained by\ninadequate theoretical foundations, encounter difficulties in achieving\ncausally invariant prompts, ultimately falling short of capturing robust\nfeatures that generalize effectively across categories. To address these\nchallenges, we introduce the $\\textit{\\textbf{DiCap}}$ model, a theoretically\ngrounded $\\textbf{Di}$ffusion-based $\\textbf{C}$ounterf$\\textbf{a}$ctual\n$\\textbf{p}$rompt learning framework, which leverages a diffusion process to\niteratively sample gradients from the marginal and conditional distributions of\nthe causal model, guiding the generation of counterfactuals that satisfy the\nminimal sufficiency criterion. Grounded in rigorous theoretical derivations,\nthis approach guarantees the identifiability of counterfactual outcomes while\nimposing strict bounds on estimation errors. We further employ a contrastive\nlearning framework that leverages the generated counterfactuals, thereby\nenabling the refined extraction of prompts that are precisely aligned with the\ncausal features of the data. Extensive experimental results demonstrate that\nour method performs excellently across tasks such as image classification,\nimage-text retrieval, and visual question answering, with particularly strong\nadvantages in unseen categories."}
{"id": "2507.20971", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.20971", "abs": "https://arxiv.org/abs/2507.20971", "authors": ["Cláudio Modesto", "João Borges", "Cleverson Nahum", "Lucas Matni", "Cristiano Bonato Both", "Kleber Cardoso", "Glauco Gonçalves", "Ilan Correa", "Silvia Lins", "Andrey Silva", "Aldebaro Klautau"], "title": "Towards a Robust Transport Network With Self-adaptive Network Digital Twin", "comment": "19 pages, 10 figures, and 6 tables", "summary": "The ability of the network digital twin (NDT) to remain aware of changes in\nits physical counterpart, known as the physical twin (PTwin), is a fundamental\ncondition to enable timely synchronization, also referred to as twinning. In\nthis way, considering a transport network, a key requirement is to handle\nunexpected traffic variability and dynamically adapt to maintain optimal\nperformance in the associated virtual model, known as the virtual twin (VTwin).\nIn this context, we propose a self-adaptive implementation of a novel NDT\narchitecture designed to provide accurate delay predictions, even under\nfluctuating traffic conditions. This architecture addresses an essential\nchallenge, underexplored in the literature: improving the resilience of\ndata-driven NDT platforms against traffic variability and improving\nsynchronization between the VTwin and its physical counterpart. Therefore, the\ncontributions of this article rely on NDT lifecycle by focusing on the\noperational phase, where telemetry modules are used to monitor incoming\ntraffic, and concept drift detection techniques guide retraining decisions\naimed at updating and redeploying the VTwin when necessary. We validate our\narchitecture with a network management use case, across various emulated\nnetwork topologies, and diverse traffic patterns to demonstrate its\neffectiveness in preserving acceptable performance and predicting per-flow\ndelay under unexpected traffic variation. The results in all tested topologies,\nusing the normalized mean square error as the evaluation metric, demonstrate\nthat our proposed architecture, after a traffic concept drift, achieves a\nperformance improvement in prediction of at least 56.7% compared to a\nconfiguration without NDT synchronization."}
{"id": "2507.20504", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20504", "abs": "https://arxiv.org/abs/2507.20504", "authors": ["Amir Mehrabian", "Georges Kaddoum"], "title": "Cooperative Jamming Detection Using Low-Rank Structure of Received Signal Matrix", "comment": null, "summary": "Wireless communication can be simply subjected to malicious attacks due to\nits open nature and shared medium. Detecting jamming attacks is the first and\nnecessary step to adopt the anti-jamming strategies. This paper presents novel\ncooperative jamming detection methods that use the low-rank structure of the\nreceived signal matrix. We employed the likelihood ratio test to propose\ndetectors for various scenarios. We regarded several scenarios with different\nnumbers of friendly and jamming nodes and different levels of available\nstatistical information on noise. We also provided an analytical examination of\nthe false alarm performance of one of the proposed detectors, which can be used\nto adjust the detection threshold. We discussed the synthetic signal generation\nand the Monte Carlo (MC)-based threshold setting method, where knowledge of the\ndistribution of the jamming-free signal, as well as several parameters such as\nnoise variance and channel state information (CSI), is required to accurately\ngenerate synthetic signals for threshold estimation. Extensive simulations\nreveal that the proposed detectors outperform several existing methods,\noffering robust and accurate jamming detection in a collaborative network of\nsensing nodes."}
{"id": "2507.19960", "categories": ["cs.AI", "I.2.0; K.2; K.4.0"], "pdf": "https://arxiv.org/pdf/2507.19960", "abs": "https://arxiv.org/abs/2507.19960", "authors": ["Olivia Guest"], "title": "What Does 'Human-Centred AI' Mean?", "comment": null, "summary": "While it seems sensible that human-centred artificial intelligence (AI) means\ncentring \"human behaviour and experience,\" it cannot be any other way. AI, I\nargue, is usefully seen as a relationship between technology and humans where\nit appears that artifacts can perform, to a greater or lesser extent, human\ncognitive labour. This is evinced using examples that juxtapose technology with\ncognition, inter alia: abacus versus mental arithmetic; alarm clock versus\nknocker-upper; camera versus vision; and sweatshop versus tailor. Using novel\ndefinitions and analyses, sociotechnical relationships can be analysed into\nvarying types of: displacement (harmful), enhancement (beneficial), and/or\nreplacement (neutral) of human cognitive labour. Ultimately, all AI implicates\nhuman cognition; no matter what. Obfuscation of cognition in the AI context --\nfrom clocks to artificial neural networks -- results in distortion, in slowing\ncritical engagement, perverting cognitive science, and indeed in limiting our\nability to truly centre humans and humanity in the engineering of AI systems.\nTo even begin to de-fetishise AI, we must look the human-in-the-loop in the\neyes."}
{"id": "2507.20966", "categories": ["cs.IT", "cs.AI", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20966", "abs": "https://arxiv.org/abs/2507.20966", "authors": ["Hussein A. Ammar", "Raviraj Adve", "Shahram Shahbazpanahi", "Gary Boudreau", "Israfil Bahceci"], "title": "Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL", "comment": "Published in IEEE Transactions on Communications (IEEE TCOM)", "summary": "In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user\nmobility necessitates updating the set of serving access points to maintain the\nuser-centric clustering. Such updates are typically performed through handoff\n(HO) operations; however, frequent HOs lead to overheads associated with the\nallocation and release of resources. This paper presents a deep reinforcement\nlearning (DRL)-based solution to predict and manage these connections for\nmobile users. Our solution employs the Soft Actor-Critic algorithm, with\ncontinuous action space representation, to train a deep neural network to serve\nas the HO policy. We present a novel proposition for a reward function that\nintegrates a HO penalty in order to balance the attainable rate and the\nassociated overhead related to HOs. We develop two variants of our system; the\nfirst one uses mobility direction-assisted (DA) observations that are based on\nthe user movement pattern, while the second one uses history-assisted (HA)\nobservations that are based on the history of the large-scale fading (LSF).\nSimulation results show that our DRL-based continuous action space approach is\nmore scalable than discrete space counterpart, and that our derived HO policy\nautomatically learns to gather HOs in specific time slots to minimize the\noverhead of initiating HOs. Our solution can also operate in real time with a\nresponse time less than 0.4 ms."}
{"id": "2507.20559", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20559", "abs": "https://arxiv.org/abs/2507.20559", "authors": ["Shengwei Liu", "Hongwei Liu", "Bocong Chen"], "title": "Construction of non-generalized Reed-Solomon MDS codes based on systematic generator matrix", "comment": null, "summary": "Maximum distance separable (MDS) codes are considered optimal because the\nminimum distance cannot be improved for a given length and code size. The most\nprominent MDS codes are likely the generalized Reed-Solomon (GRS) codes. In\n1989, Roth and Lempel constructed a type of MDS code that is not a GRS code\n(referred to as non-GRS). In 2017, Beelen et al. introduced twisted\nReed-Solomon (TRS) codes and demonstrated that many MDS TRS codes are indeed\nnon-GRS. Following this, the definition of TRS codes was generalized to the\nmost comprehensive form, which we refer to as generalized twisted Reed-Solomon\n(GTRS) codes. In this paper, we prove that two families of GTRS codes are\nnon-GRS and provide a systematic generator matrix for a class of GTRS codes.\nInspired by the form of the systematic generator matrix for GTRS codes,we also\npresent a construction of non-GRS MDS codes."}
{"id": "2507.19973", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.19973", "abs": "https://arxiv.org/abs/2507.19973", "authors": ["Ebrahim Rasromani", "Stella K. Kang", "Yanqi Xu", "Beisong Liu", "Garvit Luhadia", "Wan Fung Chui", "Felicia L. Pasadyn", "Yu Chih Hung", "Julie Y. An", "Edwin Mathieu", "Zehui Gu", "Carlos Fernandez-Granda", "Ammar A. Javed", "Greg D. Sacks", "Tamas Gonda", "Chenchan Huang", "Yiqiu Shen"], "title": "Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization", "comment": null, "summary": "Background: Manual extraction of pancreatic cystic lesion (PCL) features from\nradiology reports is labor-intensive, limiting large-scale studies needed to\nadvance PCL research. Purpose: To develop and evaluate large language models\n(LLMs) that automatically extract PCL features from MRI/CT reports and assign\nrisk categories based on guidelines. Materials and Methods: We curated a\ntraining dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134\npatients that described PCLs. Labels were generated by GPT-4o using\nchain-of-thought (CoT) prompting to extract PCL and main pancreatic duct\nfeatures. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated\nCoT data. Features were mapped to risk categories per institutional guideline\nbased on the 2017 ACR White Paper. Evaluation was performed on 285 held-out\nhuman-annotated reports. Model outputs for 100 cases were independently\nreviewed by three radiologists. Feature extraction was evaluated using exact\nmatch accuracy, risk categorization with macro-averaged F1 score, and\nradiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning\nimproved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%\nto 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved\n(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no\nstatistically significant differences. Radiologist inter-reader agreement was\nhigh (Fleiss' Kappa = 0.888) and showed no statistically significant difference\nwith the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT\n(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels\non par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT\nsupervision enable accurate, interpretable, and efficient phenotyping for\nlarge-scale PCL research, achieving performance comparable to GPT-4o."}
{"id": "2507.20577", "categories": ["cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20577", "abs": "https://arxiv.org/abs/2507.20577", "authors": ["Frank Nielsen"], "title": "A note on the Artstein-Avidan-Milman's generalized Legendre transforms", "comment": "11 pages", "summary": "Artstein-Avidan and Milman [Annals of mathematics (2009), (169):661-674]\ncharacterized invertible reverse-ordering transforms on the space of\nlower-semi-continuous extended real-valued convex functions as affine\ndeformations of the ordinary Legendre transform. In this note, we prove that\nall those generalized Legendre transforms on functions correspond to the\nordinary Legendre transform on dually corresponding affine-deformed functions.\nThat is, generalized convex conjugates are convex conjugates of affine-deformed\nfunctions. We conclude this note by sketching how this result can be\ninterpreted from the lens of information geometry."}
{"id": "2507.19974", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19974", "abs": "https://arxiv.org/abs/2507.19974", "authors": ["Tongjie Li", "Jianhua Zhang", "Li Yu", "Yuxiang Zhang", "Yunlong Cai", "Fan Xu", "Guangyi Liu"], "title": "Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application", "comment": null, "summary": "Emerging applications such as holographic communication, autonomous driving,\nand the industrial Internet of Things impose stringent requirements on\nflexible, low-latency, and reliable resource allocation in 6G networks.\nConventional methods, which rely on statistical modeling, have proven effective\nin general contexts but may fail to achieve optimal performance in specific and\ndynamic environments. Furthermore, acquiring real-time channel state\ninformation (CSI) typically requires excessive pilot overhead. To address these\nchallenges, a digital twin channel (DTC)-enabled online optimization framework\nis proposed, in which DTC is employed to predict CSI based on environmental\nsensing. The predicted CSI is then utilized by lightweight game-theoretic\nalgorithms to perform online resource allocation in a timely and efficient\nmanner. Simulation results based on a digital replica of a realistic industrial\nworkshop demonstrate that the proposed method achieves throughput improvements\nof up to 11.5\\% compared with pilot-based ideal CSI schemes, validating its\neffectiveness for scalable, low-overhead, and environment-aware communication\nin future 6G networks."}
{"id": "2507.20639", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20639", "abs": "https://arxiv.org/abs/2507.20639", "authors": ["Matteo Bertuzzo", "Alberto Ravagnani", "Eitan Yaakobi"], "title": "The Coverage Depth Problem in DNA Storage Over Small Alphabets", "comment": null, "summary": "The coverage depth problem in DNA data storage is about minimizing the\nexpected number of reads until all data is recovered. When they exist, MDS\ncodes offer the best performance in this context. This paper focuses on the\nscenario where the base field is not large enough to allow the existence of MDS\ncodes. We investigate the performance for the coverage depth problem of codes\ndefined over a small finite field, providing closed formulas for the expected\nnumber of reads for various code families. We also compare the results with the\ntheoretical bounds in asymptotic regimes. The techniques we apply range from\nprobability, to duality theory and combinatorics."}
{"id": "2507.20000", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2507.20000", "abs": "https://arxiv.org/abs/2507.20000", "authors": ["Renaud Fabre", "Daniel Egret", "Patrice Bellot"], "title": "Matching Game Preferences Through Dialogical Large Language Models: A Perspective", "comment": "28 pages, 1 figure. Published in Applied Sciences", "summary": "This perspective paper explores the future potential of \"conversational\nintelligence\" by examining how Large Language Models (LLMs) could be combined\nwith GRAPHYP's network system to better understand human conversations and\npreferences. Using recent research and case studies, we propose a conceptual\nframework that could make AI rea-soning transparent and traceable, allowing\nhumans to see and understand how AI reaches its conclusions. We present the\nconceptual perspective of \"Matching Game Preferences through Dialogical Large\nLanguage Models (D-LLMs),\" a proposed system that would allow multiple users to\nshare their different preferences through structured conversations. This\napproach envisions personalizing LLMs by embedding individual user preferences\ndirectly into how the model makes decisions. The proposed D-LLM framework would\nrequire three main components: (1) reasoning processes that could analyze\ndifferent search experiences and guide performance, (2) classification systems\nthat would identify user preference patterns, and (3) dialogue approaches that\ncould help humans resolve conflicting information. This perspective framework\naims to create an interpretable AI system where users could examine,\nunderstand, and combine the different human preferences that influence AI\nresponses, detected through GRAPHYP's search experience networks. The goal of\nthis perspective is to envision AI systems that would not only provide answers\nbut also show users how those answers were reached, making artificial\nintelligence more transparent and trustworthy for human decision-making."}
{"id": "2507.20645", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20645", "abs": "https://arxiv.org/abs/2507.20645", "authors": ["Şeyma Bodur", "Stefano Lia", "Hiram H. López", "Rati Ludhani", "Alberto Ravagnani", "Lisa Seccia"], "title": "The Random Variables of the DNA Coverage Depth Problem", "comment": null, "summary": "DNA data storage systems encode digital data into DNA strands, enabling dense\nand durable storage. Efficient data retrieval depends on coverage depth, a key\nperformance metric. We study the random access coverage depth problem and focus\non minimizing the expected number of reads needed to recover information\nstrands encoded via a linear code. We compute the asymptotic performance of a\nrecently proposed code construction, establishing and refining a conjecture in\nthe field by giving two independent proofs. We also analyze a geometric code\nconstruction based on balanced quasi-arcs and optimize its parameters. Finally,\nwe investigate the full distribution of the random variables that arise in the\ncoverage depth problem, of which the traditionally studied expectation is just\nthe first moment. This allows us to distinguish between code constructions\nthat, at first glance, may appear to behave identically."}
{"id": "2507.20010", "categories": ["cs.AI", "cs.GT", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.20010", "abs": "https://arxiv.org/abs/2507.20010", "authors": ["Müge Fidan", "Esra Erdem"], "title": "Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems", "comment": null, "summary": "The Stable Roommates problems are characterized by the preferences of agents\nover other agents as roommates. A solution is a partition of the agents into\npairs that are acceptable to each other (i.e., they are in the preference lists\nof each other), and the matching is stable (i.e., there do not exist any two\nagents who prefer each other to their roommates, and thus block the matching).\nMotivated by real-world applications, and considering that stable roommates\nproblems do not always have solutions, we continue our studies to compute\n\"good-enough\" matchings. In addition to the agents' habits and habitual\npreferences, we consider their networks of preferred friends, and introduce a\nmethod to generate personalized solutions to stable roommates problems. We\nillustrate the usefulness of our method with examples and empirical\nevaluations."}
{"id": "2507.20966", "categories": ["cs.IT", "cs.AI", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20966", "abs": "https://arxiv.org/abs/2507.20966", "authors": ["Hussein A. Ammar", "Raviraj Adve", "Shahram Shahbazpanahi", "Gary Boudreau", "Israfil Bahceci"], "title": "Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL", "comment": "Published in IEEE Transactions on Communications (IEEE TCOM)", "summary": "In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user\nmobility necessitates updating the set of serving access points to maintain the\nuser-centric clustering. Such updates are typically performed through handoff\n(HO) operations; however, frequent HOs lead to overheads associated with the\nallocation and release of resources. This paper presents a deep reinforcement\nlearning (DRL)-based solution to predict and manage these connections for\nmobile users. Our solution employs the Soft Actor-Critic algorithm, with\ncontinuous action space representation, to train a deep neural network to serve\nas the HO policy. We present a novel proposition for a reward function that\nintegrates a HO penalty in order to balance the attainable rate and the\nassociated overhead related to HOs. We develop two variants of our system; the\nfirst one uses mobility direction-assisted (DA) observations that are based on\nthe user movement pattern, while the second one uses history-assisted (HA)\nobservations that are based on the history of the large-scale fading (LSF).\nSimulation results show that our DRL-based continuous action space approach is\nmore scalable than discrete space counterpart, and that our derived HO policy\nautomatically learns to gather HOs in specific time slots to minimize the\noverhead of initiating HOs. Our solution can also operate in real time with a\nresponse time less than 0.4 ms."}
{"id": "2507.20067", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.20067", "abs": "https://arxiv.org/abs/2507.20067", "authors": ["Sarat Chandra Bobbili", "Ujwal Dinesha", "Dheeraj Narasimha", "Srinivas Shakkottai"], "title": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "comment": null, "summary": "Inference-time alignment enables large language models (LLMs) to generate\noutputs aligned with end-user preferences without further training. Recent\npost-training methods achieve this by using small guidance models to modify\ntoken generation during inference. These methods typically optimize a reward\nfunction KL-regularized by the original LLM taken as the reference policy. A\ncritical limitation, however, is their dependence on a pre-trained reward\nmodel, which requires fitting to human preference feedback--a potentially\nunstable process. In contrast, we introduce PITA, a novel framework that\nintegrates preference feedback directly into the LLM's token generation,\neliminating the need for a reward model. PITA learns a small preference-based\nguidance policy to modify token probabilities at inference time without LLM\nfine-tuning, reducing computational cost and bypassing the pre-trained reward\nmodel dependency. The problem is framed as identifying an underlying preference\ndistribution, solved through stochastic search and iterative refinement of the\npreference-based guidance model. We evaluate PITA across diverse tasks,\nincluding mathematical reasoning and sentiment classification, demonstrating\nits effectiveness in aligning LLM outputs with user preferences."}
{"id": "2507.19974", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19974", "abs": "https://arxiv.org/abs/2507.19974", "authors": ["Tongjie Li", "Jianhua Zhang", "Li Yu", "Yuxiang Zhang", "Yunlong Cai", "Fan Xu", "Guangyi Liu"], "title": "Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application", "comment": null, "summary": "Emerging applications such as holographic communication, autonomous driving,\nand the industrial Internet of Things impose stringent requirements on\nflexible, low-latency, and reliable resource allocation in 6G networks.\nConventional methods, which rely on statistical modeling, have proven effective\nin general contexts but may fail to achieve optimal performance in specific and\ndynamic environments. Furthermore, acquiring real-time channel state\ninformation (CSI) typically requires excessive pilot overhead. To address these\nchallenges, a digital twin channel (DTC)-enabled online optimization framework\nis proposed, in which DTC is employed to predict CSI based on environmental\nsensing. The predicted CSI is then utilized by lightweight game-theoretic\nalgorithms to perform online resource allocation in a timely and efficient\nmanner. Simulation results based on a digital replica of a realistic industrial\nworkshop demonstrate that the proposed method achieves throughput improvements\nof up to 11.5\\% compared with pilot-based ideal CSI schemes, validating its\neffectiveness for scalable, low-overhead, and environment-aware communication\nin future 6G networks."}
{"id": "2507.20143", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20143", "abs": "https://arxiv.org/abs/2507.20143", "authors": ["Zhonghan Ge", "Yuanyang Zhu", "Chunlin Chen"], "title": "Concept Learning for Cooperative Multi-Agent Reinforcement Learning", "comment": "IEEE-China Conference on System Simulation Technology and its\n  Applications, 2025", "summary": "Despite substantial progress in applying neural networks (NN) to multi-agent\nreinforcement learning (MARL) areas, they still largely suffer from a lack of\ntransparency and interoperability. However, its implicit cooperative mechanism\nis not yet fully understood due to black-box networks. In this work, we study\nan interpretable value decomposition framework via concept bottleneck models,\nwhich promote trustworthiness by conditioning credit assignment on an\nintermediate level of human-like cooperation concepts. To address this problem,\nwe propose a novel value-based method, named Concepts learning for Multi-agent\nQ-learning (CMQ), that goes beyond the current performance-vs-interpretability\ntrade-off by learning interpretable cooperation concepts. CMQ represents each\ncooperation concept as a supervised vector, as opposed to existing models where\nthe information flowing through their end-to-end mechanism is concept-agnostic.\nIntuitively, using individual action value conditioning on global state\nembeddings to represent each concept allows for extra cooperation\nrepresentation capacity. Empirical evaluations on the StarCraft II\nmicromanagement challenge and level-based foraging (LBF) show that CMQ achieves\nsuperior performance compared with the state-of-the-art counterparts. The\nresults also demonstrate that CMQ provides more cooperation concept\nrepresentation capturing meaningful cooperation modes, and supports test-time\nconcept interventions for detecting potential biases of cooperation mode and\nidentifying spurious artifacts that impact cooperation."}
{"id": "2507.20367", "categories": ["cs.NI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20367", "abs": "https://arxiv.org/abs/2507.20367", "authors": ["Charitha Madapatha", "Piotr Lechowicz", "Carlos Natalino", "Paolo Monti", "Tommy Svensson"], "title": "Joint Fiber and Free Space Optical Infrastructure Planning for Hybrid Integrated Access and Backhaul Networks", "comment": "Accepted invited paper for IEEE PIMRC 2025, Istanbul, Turkey", "summary": "Integrated access and backhaul (IAB) is one of the promising techniques for\n5G networks and beyond (6G), in which the same node/hardware is used to provide\nboth backhaul and cellular services in a multi-hop architecture. Due to the\nsensitivity of the backhaul links with high rate/reliability demands, proper\nnetwork planning is needed to ensure the IAB network performs with the desired\nperformance levels. In this paper, we study the effect of infrastructure\nplanning and optimization on the coverage of IAB networks. We concentrate on\nthe cases where the fiber connectivity to the nodes is constrained due to cost.\nThereby, we study the performance gains and energy efficiency in the presence\nof free-space optical (FSO) communication links. Our results indicate hybrid\nfiber/FSO deployments offer substantial cost savings compared to fully fibered\nnetworks, suggesting a beneficial trade-off for strategic link deployment while\nimproving the service coverage probability. As we show, with proper network\nplanning, the service coverage, energy efficiency, and cost efficiency can be\nimproved."}
{"id": "2507.20150", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.20150", "abs": "https://arxiv.org/abs/2507.20150", "authors": ["Xingcheng Xu"], "title": "The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models", "comment": null, "summary": "Reinforcement learning (RL) plays a crucial role in shaping the behavior of\nlarge language and reasoning models (LLMs/LRMs). However, it often produces\nbrittle and unstable policies, leading to critical failures such as spurious\nreasoning, deceptive alignment, and instruction disobedience that undermine the\ntrustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified\ntheoretical explanation and are typically addressed using ad-hoc heuristics.\nThis paper presents a rigorous mathematical framework for analyzing the\nstability of the mapping from a reward function to the optimal policy. We show\nthat policy brittleness often stems from non-unique optimal actions, a common\noccurrence when multiple valid traces exist in a reasoning task. This\ntheoretical lens provides a unified explanation for a range of seemingly\ndisparate failures, reframing them as rational outcomes of optimizing rewards\nthat may be incomplete or noisy, especially in the presence of action\ndegeneracy. We extend this analysis from the fundamental single-reward setting\nto the more realistic multi-reward RL across diverse domains, showing how\nstability is governed by an \"effective reward\" aggregation mechanism. We also\nprove that entropy regularization restores policy stability at the cost of\nincreased stochasticity. Our framework provides a unified explanation for\nrecent empirical findings on deceptive reasoning, instruction-following\ntrade-offs, and RLHF-induced sophistry, and is further validated through\nperturbation experiments in multi-reward RL. This work advances\npolicy-stability analysis from empirical heuristics towards a principled\ntheory, offering essential insights for designing safer and more trustworthy AI\nsystems."}
{"id": "2507.20641", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20641", "abs": "https://arxiv.org/abs/2507.20641", "authors": ["Lijian Li"], "title": "Adaptive Fuzzy Time Series Forecasting via Partially Asymmetric Convolution and Sub-Sliding Window Fusion", "comment": null, "summary": "At present, state-of-the-art forecasting models are short of the ability to\ncapture spatio-temporal dependency and synthesize global information at the\nstage of learning. To address this issue, in this paper, through the adaptive\nfuzzified construction of temporal data, we propose a novel convolutional\narchitecture with partially asymmetric design based on the scheme of sliding\nwindow to realize accurate time series forecasting. First, the construction\nstrategy of traditional fuzzy time series is improved to further extract short\nand long term temporal interrelation, which enables every time node to\nautomatically possess corresponding global information and inner relationships\namong them in a restricted sliding window and the process does not require\nhuman involvement. Second, a bilateral Atrous algorithm is devised to reduce\ncalculation demand of the proposed model without sacrificing global\ncharacteristics of elements. And it also allows the model to avoid processing\nredundant information. Third, after the transformation of time series, a\npartially asymmetric convolutional architecture is designed to more flexibly\nmine data features by filters in different directions on feature maps, which\ngives the convolutional neural network (CNN) the ability to construct\nsub-windows within existing sliding windows to model at a more fine-grained\nlevel. And after obtaining the time series information at different levels, the\nmulti-scale features from different sub-windows will be sent to the\ncorresponding network layer for time series information fusion. Compared with\nother competitive modern models, the proposed method achieves state-of-the-art\nresults on most of popular time series datasets, which is fully verified by the\nexperimental results."}
{"id": "2507.20199", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20199", "abs": "https://arxiv.org/abs/2507.20199", "authors": ["Shijie Shang", "Ruosi Wan", "Yue Peng", "Yutong Wu", "Xiong-hui Chen", "Jie Yan", "Xiangyu Zhang"], "title": "StepFun-Prover Preview: Let's Think and Verify Step by Step", "comment": "25 pages, 4 figures", "summary": "We present StepFun-Prover Preview, a large language model designed for formal\ntheorem proving through tool-integrated reasoning. Using a reinforcement\nlearning pipeline that incorporates tool-based interactions, StepFun-Prover can\nachieve strong performance in generating Lean 4 proofs with minimal sampling.\nOur approach enables the model to emulate human-like problem-solving strategies\nby iteratively refining proofs based on real-time environment feedback. On the\nminiF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of\n$70.0\\%$. Beyond advancing benchmark performance, we introduce an end-to-end\ntraining framework for developing tool-integrated reasoning models, offering a\npromising direction for automated theorem proving and Math AI assistant."}
{"id": "2507.20226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20226", "abs": "https://arxiv.org/abs/2507.20226", "authors": ["Shuyang Guo", "Wenjin Xie", "Ping Lu", "Ting Deng", "Richong Zhang", "Jianxin Li", "Xiangping Huang", "Zhongyi Liu"], "title": "Improving Subgraph Matching by Combining Algorithms and Graph Neural Networks", "comment": null, "summary": "Homomorphism is a key mapping technique between graphs that preserves their\nstructure. Given a graph and a pattern, the subgraph homomorphism problem\ninvolves finding a mapping from the pattern to the graph, ensuring that\nadjacent vertices in the pattern are mapped to adjacent vertices in the graph.\nUnlike subgraph isomorphism, which requires a one-to-one mapping, homomorphism\nallows multiple vertices in the pattern to map to the same vertex in the graph,\nmaking it more complex. We propose HFrame, the first graph neural network-based\nframework for subgraph homomorphism, which integrates traditional algorithms\nwith machine learning techniques. We demonstrate that HFrame outperforms\nstandard graph neural networks by being able to distinguish more graph pairs\nwhere the pattern is not homomorphic to the graph. Additionally, we provide a\ngeneralization error bound for HFrame. Through experiments on both real-world\nand synthetic graphs, we show that HFrame is up to 101.91 times faster than\nexact matching algorithms and achieves an average accuracy of 0.962."}
{"id": "2507.20230", "categories": ["cs.AI", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.20230", "abs": "https://arxiv.org/abs/2507.20230", "authors": ["Yufan Chen", "Ching Ting Leung", "Bowen Yu", "Jianwei Sun", "Yong Huang", "Linyan Li", "Hao Chen", "Hanyu Gao"], "title": "A Multi-Agent System for Information Extraction from the Chemical Literature", "comment": null, "summary": "To fully expedite AI-powered chemical research, high-quality chemical\ndatabases are the cornerstone. Automatic extraction of chemical information\nfrom the literature is essential for constructing reaction databases, but it is\ncurrently limited by the multimodality and style variability of chemical\ninformation. In this work, we developed a multimodal large language model\n(MLLM)-based multi-agent system for automatic chemical information extraction.\nWe used the MLLM's strong reasoning capability to understand the structure of\ncomplex chemical graphics, decompose the extraction task into sub-tasks and\ncoordinate a set of specialized agents to solve them. Our system achieved an F1\nscore of 80.8% on a benchmark dataset of complex chemical reaction graphics\nfrom the literature, surpassing the previous state-of-the-art model (F1 score:\n35.6%) by a significant margin. Additionally, it demonstrated consistent\nimprovements in key sub-tasks, including molecular image recognition, reaction\nimage parsing, named entity recognition and text-based reaction extraction.\nThis work is a critical step toward automated chemical information extraction\ninto structured datasets, which will be a strong promoter of AI-driven chemical\nresearch."}
{"id": "2507.20280", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.20280", "abs": "https://arxiv.org/abs/2507.20280", "authors": ["Keyan Ding", "Jing Yu", "Junjie Huang", "Yuchen Yang", "Qiang Zhang", "Huajun Chen"], "title": "SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration", "comment": "21 pages, 6 figures", "summary": "Scientific research increasingly relies on specialized computational tools,\nyet effectively utilizing these tools demands substantial domain expertise.\nWhile Large Language Models (LLMs) show promise in tool automation, they\nstruggle to seamlessly integrate and orchestrate multiple tools for complex\nscientific workflows. Here, we present SciToolAgent, an LLM-powered agent that\nautomates hundreds of scientific tools across biology, chemistry, and materials\nscience. At its core, SciToolAgent leverages a scientific tool knowledge graph\nthat enables intelligent tool selection and execution through graph-based\nretrieval-augmented generation. The agent also incorporates a comprehensive\nsafety-checking module to ensure responsible and ethical tool usage. Extensive\nevaluations on a curated benchmark demonstrate that SciToolAgent significantly\noutperforms existing approaches. Case studies in protein engineering, chemical\nreactivity prediction, chemical synthesis, and metal-organic framework\nscreening further demonstrate SciToolAgent's capability to automate complex\nscientific workflows, making advanced research tools accessible to both experts\nand non-experts."}
{"id": "2507.20322", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20322", "abs": "https://arxiv.org/abs/2507.20322", "authors": ["Manish Verma", "Vivek Sharma", "Vishal Singh"], "title": "Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting", "comment": "Page 4-Figure 1 and Page 11-Figure 2 . A preprint describing a system\n  for AI-powered technology scouting", "summary": "This paper presents the development of an AI powered software platform that\nleverages advanced large language models (LLMs) to transform technology\nscouting and solution discovery in industrial R&D. Traditional approaches to\nsolving complex research and development challenges are often time consuming,\nmanually driven, and heavily dependent on domain specific expertise. These\nmethods typically involve navigating fragmented sources such as patent\nrepositories, commercial product catalogs, and competitor data, leading to\ninefficiencies and incomplete insights. The proposed platform utilizes cutting\nedge LLM capabilities including semantic understanding, contextual reasoning,\nand cross-domain knowledge extraction to interpret problem statements and\nretrieve high-quality, sustainable solutions. The system processes unstructured\npatent texts, such as claims and technical descriptions, and systematically\nextracts potential innovations aligned with the given problem context. These\nsolutions are then algorithmically organized under standardized technical\ncategories and subcategories to ensure clarity and relevance across\ninterdisciplinary domains. In addition to patent analysis, the platform\nintegrates commercial intelligence by identifying validated market solutions\nand active organizations addressing similar challenges. This combined insight\nsourced from both intellectual property and real world product data enables R&D\nteams to assess not only technical novelty but also feasibility, scalability,\nand sustainability. The result is a comprehensive, AI driven scouting engine\nthat reduces manual effort, accelerates innovation cycles, and enhances\ndecision making in complex R&D environments."}
{"id": "2507.20333", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.20333", "abs": "https://arxiv.org/abs/2507.20333", "authors": ["Rachel S. Y. Teo", "Laziz U. Abdullaev", "Tan M. Nguyen"], "title": "The Blessing and Curse of Dimensionality in Safety Alignment", "comment": "Published as a conference paper at COLM 2025", "summary": "The focus on safety alignment in large language models (LLMs) has increased\nsignificantly due to their widespread adoption across different domains. The\nscale of LLMs play a contributing role in their success, and the growth in\nparameter count follows larger hidden dimensions. In this paper, we hypothesize\nthat while the increase in dimensions has been a key advantage, it may lead to\nemergent problems as well. These problems emerge as the linear structures in\nthe activation space can be exploited, in the form of activation engineering,\nto circumvent its safety alignment. Through detailed visualizations of linear\nsubspaces associated with different concepts, such as safety, across various\nmodel scales, we show that the curse of high-dimensional representations\nuniquely impacts LLMs. Further substantiating our claim, we demonstrate that\nprojecting the representations of the model onto a lower dimensional subspace\ncan preserve sufficient information for alignment while avoiding those linear\nstructures. Empirical results confirm that such dimensional reduction\nsignificantly reduces susceptibility to jailbreaking through representation\nengineering. Building on our empirical validations, we provide theoretical\ninsights into these linear jailbreaking methods relative to a model's hidden\ndimensions. Broadly speaking, our work posits that the high dimensions of a\nmodel's internal representations can be both a blessing and a curse in safety\nalignment."}
{"id": "2507.20342", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.20342", "abs": "https://arxiv.org/abs/2507.20342", "authors": ["Zhipeng Tang", "Sha Zhang", "Jiajun Deng", "Chenjie Wang", "Guoliang You", "Yuting Huang", "Xinrui Lin", "Yanyong Zhang"], "title": "VLMPlanner: Integrating Visual Language Models with Motion Planning", "comment": "8 pages, 3 figures, this paper has been accepted by ACM MM 2025", "summary": "Integrating large language models (LLMs) into autonomous driving motion\nplanning has recently emerged as a promising direction, offering enhanced\ninterpretability, better controllability, and improved generalization in rare\nand long-tail scenarios. However, existing methods often rely on abstracted\nperception or map-based inputs, missing crucial visual context, such as\nfine-grained road cues, accident aftermath, or unexpected obstacles, which are\nessential for robust decision-making in complex driving environments. To bridge\nthis gap, we propose VLMPlanner, a hybrid framework that combines a\nlearning-based real-time planner with a vision-language model (VLM) capable of\nreasoning over raw images. The VLM processes multi-view images to capture rich,\ndetailed visual information and leverages its common-sense reasoning\ncapabilities to guide the real-time planner in generating robust and safe\ntrajectories. Furthermore, we develop the Context-Adaptive Inference Gate\n(CAI-Gate) mechanism that enables the VLM to mimic human driving behavior by\ndynamically adjusting its inference frequency based on scene complexity,\nthereby achieving an optimal balance between planning performance and\ncomputational efficiency. We evaluate our approach on the large-scale,\nchallenging nuPlan benchmark, with comprehensive experimental results\ndemonstrating superior planning performance in scenarios with intricate road\nconditions and dynamic elements. Code will be available."}
{"id": "2507.20377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20377", "abs": "https://arxiv.org/abs/2507.20377", "authors": ["Farshid Nooshi", "Suining He"], "title": "Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping", "comment": "5 pages, UrbComp 2025", "summary": "Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing\nvehicles) is crucial for rebalancing the mobility demand and supply in the\nurban environments. We propose in this work a novel multi-agent reinforcement\nlearning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)\nfor dynamic mobility resource allocation. HAG-PS aims to address two important\nresearch challenges regarding multi-agent reinforcement learning for mobility\nresource allocation: (1) how to dynamically and adaptively share the mobility\nresource allocation policy (i.e., how to distribute mobility resources) across\nagents (i.e., representing the regional coordinators of mobility resources);\nand (2) how to achieve memory-efficient parameter sharing in an urban-scale\nsetting. To address the above challenges, we have provided following novel\ndesigns within HAG-PS. To enable dynamic and adaptive parameter sharing, we\nhave designed a hierarchical approach that consists of global and local\ninformation of the mobility resource states (e.g., distribution of mobility\nresources). We have developed an adaptive agent grouping approach in order to\nsplit or merge the groups of agents based on their relative closeness of\nencoded trajectories (i.e., states, actions, and rewards). We have designed a\nlearnable identity (ID) embeddings to enable agent specialization beyond simple\nparameter copy. We have performed extensive experimental studies based on\nreal-world NYC bike sharing data (a total of more than 1.2 million trips), and\ndemonstrated the superior performance (e.g., improved bike availability) of\nHAG-PS compared with other baseline approaches."}
{"id": "2507.20395", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20395", "abs": "https://arxiv.org/abs/2507.20395", "authors": ["Hafsteinn Einarsson"], "title": "MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models", "comment": null, "summary": "As Large Language Models (LLMs) increasingly power autonomous agents in\nrobotics and embodied AI, understanding their spatial reasoning capabilities\nbecomes crucial for ensuring reliable real-world deployment. Despite advances\nin language understanding, current research lacks evaluation of how LLMs\nperform spatial navigation without visual cues, a fundamental requirement for\nagents operating with limited sensory information. This paper addresses this\ngap by introducing MazeEval, a benchmark designed to isolate and evaluate pure\nspatial reasoning in LLMs through coordinate-based maze navigation tasks. Our\nmethodology employs a function-calling interface where models navigate mazes of\nvarying complexity ($5\\times 5$ to $15\\times 15$ grids) using only coordinate\nfeedback and distance-to-wall information, excluding visual input to test\nfundamental spatial cognition. We evaluate eight state-of-the-art LLMs across\nidentical mazes in both English and Icelandic to assess cross-linguistic\ntransfer of spatial abilities. Our findings reveal striking disparities: while\nOpenAI's O3 achieves perfect navigation for mazes up to size $30\\times 30$,\nother models exhibit catastrophic failure beyond $9\\times 9$ mazes, with 100%\nof failures attributed to excessive looping behavior where models revisit a\ncell at least 10 times. We document a significant performance degradation in\nIcelandic, with models solving mazes 3-4 sizes smaller than in English,\nsuggesting spatial reasoning in LLMs emerges from linguistic patterns rather\nthan language-agnostic mechanisms. These results have important implications\nfor global deployment of LLM-powered autonomous systems, showing spatial\nintelligence remains fundamentally constrained by training data availability\nand highlighting the need for architectural innovations to achieve reliable\nnavigation across linguistic contexts."}
{"id": "2507.20444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20444", "abs": "https://arxiv.org/abs/2507.20444", "authors": ["Chengzhuo Han"], "title": "Enhancing QoS in Edge Computing through Federated Layering Techniques: A Pathway to Resilient AI Lifelong Learning Systems", "comment": null, "summary": "In the context of the rapidly evolving information technology landscape,\nmarked by the advent of 6G communication networks, we face an increased data\nvolume and complexity in network environments. This paper addresses these\nchallenges by focusing on Quality of Service (QoS) in edge computing\nframeworks. We propose a novel approach to enhance QoS through the development\nof General Artificial Intelligence Lifelong Learning Systems, with a special\nemphasis on Federated Layering Techniques (FLT). Our work introduces a\nfederated layering-based small model collaborative mechanism aimed at improving\nAI models' operational efficiency and response time in environments where\nresources are limited. This innovative method leverages the strengths of cloud\nand edge computing, incorporating a negotiation and debate mechanism among\nsmall AI models to enhance reasoning and decision-making processes. By\nintegrating model layering techniques with privacy protection measures, our\napproach ensures the secure transmission of model parameters while maintaining\nhigh efficiency in learning and reasoning capabilities. The experimental\nresults demonstrate that our strategy not only enhances learning efficiency and\nreasoning accuracy but also effectively protects the privacy of edge nodes.\nThis presents a viable solution for achieving resilient large model lifelong\nlearning systems, with a significant improvement in QoS for edge computing\nenvironments."}
{"id": "2507.20451", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20451", "abs": "https://arxiv.org/abs/2507.20451", "authors": ["Pritom Ray Nobin", "Imran Ahammad Rifat"], "title": "STARN-GAT: A Multi-Modal Spatio-Temporal Graph Attention Network for Accident Severity Prediction", "comment": "10 pages", "summary": "Accurate prediction of traffic accident severity is critical for improving\nroad safety, optimizing emergency response strategies, and informing the design\nof safer transportation infrastructure. However, existing approaches often\nstruggle to effectively model the intricate interdependencies among spatial,\ntemporal, and contextual variables that govern accident outcomes. In this\nstudy, we introduce STARN-GAT, a Multi-Modal Spatio-Temporal Graph Attention\nNetwork, which leverages adaptive graph construction and modality-aware\nattention mechanisms to capture these complex relationships. Unlike\nconventional methods, STARN-GAT integrates road network topology, temporal\ntraffic patterns, and environmental context within a unified attention-based\nframework. The model is evaluated on the Fatality Analysis Reporting System\n(FARS) dataset, achieving a Macro F1-score of 85 percent, ROC-AUC of 0.91, and\nrecall of 81 percent for severe incidents. To ensure generalizability within\nthe South Asian context, STARN-GAT is further validated on the ARI-BUET traffic\naccident dataset, where it attains a Macro F1-score of 0.84, recall of 0.78,\nand ROC-AUC of 0.89. These results demonstrate the model's effectiveness in\nidentifying high-risk cases and its potential for deployment in real-time,\nsafety-critical traffic management systems. Furthermore, the attention-based\narchitecture enhances interpretability, offering insights into contributing\nfactors and supporting trust in AI-assisted decision-making. Overall, STARN-GAT\nbridges the gap between advanced graph neural network techniques and practical\napplications in road safety analytics."}
{"id": "2507.20526", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.20526", "abs": "https://arxiv.org/abs/2507.20526", "authors": ["Andy Zou", "Maxwell Lin", "Eliot Jones", "Micha Nowak", "Mateusz Dziemian", "Nick Winter", "Alexander Grattan", "Valent Nathanael", "Ayla Croft", "Xander Davies", "Jai Patel", "Robert Kirk", "Nate Burnikell", "Yarin Gal", "Dan Hendrycks", "J. Zico Kolter", "Matt Fredrikson"], "title": "Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition", "comment": null, "summary": "Recent advances have enabled LLM-powered AI agents to autonomously execute\ncomplex tasks by combining language model reasoning with tools, memory, and web\naccess. But can these systems be trusted to follow deployment policies in\nrealistic environments, especially under attack? To investigate, we ran the\nlargest public red-teaming competition to date, targeting 22 frontier AI agents\nacross 44 realistic deployment scenarios. Participants submitted 1.8 million\nprompt-injection attacks, with over 60,000 successfully eliciting policy\nviolations such as unauthorized data access, illicit financial actions, and\nregulatory noncompliance. We use these results to build the Agent Red Teaming\n(ART) benchmark - a curated set of high-impact attacks - and evaluate it across\n19 state-of-the-art models. Nearly all agents exhibit policy violations for\nmost behaviors within 10-100 queries, with high attack transferability across\nmodels and tasks. Importantly, we find limited correlation between agent\nrobustness and model size, capability, or inference-time compute, suggesting\nthat additional defenses are needed against adversarial misuse. Our findings\nhighlight critical and persistent vulnerabilities in today's AI agents. By\nreleasing the ART benchmark and accompanying evaluation framework, we aim to\nsupport more rigorous security assessment and drive progress toward safer agent\ndeployment."}
{"id": "2507.20541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20541", "abs": "https://arxiv.org/abs/2507.20541", "authors": ["Zishang Qiu", "Xinan Chen", "Long Chen", "Ruibin Bai"], "title": "MeLA: A Metacognitive LLM-Driven Architecture for Automatic Heuristic Design", "comment": null, "summary": "This paper introduces MeLA, a Metacognitive LLM-Driven Architecture that\npresents a new paradigm for Automatic Heuristic Design (AHD). Traditional\nevolutionary methods operate directly on heuristic code; in contrast, MeLA\nevolves the instructional prompts used to guide a Large Language Model (LLM) in\ngenerating these heuristics. This process of \"prompt evolution\" is driven by a\nnovel metacognitive framework where the system analyzes performance feedback to\nsystematically refine its generative strategy. MeLA's architecture integrates a\nproblem analyzer to construct an initial strategic prompt, an error diagnosis\nsystem to repair faulty code, and a metacognitive search engine that\niteratively optimizes the prompt based on heuristic effectiveness. In\ncomprehensive experiments across both benchmark and real-world problems, MeLA\nconsistently generates more effective and robust heuristics, significantly\noutperforming state-of-the-art methods. Ultimately, this research demonstrates\nthe profound potential of using cognitive science as a blueprint for AI\narchitecture, revealing that by enabling an LLM to metacognitively regulate its\nproblem-solving process, we unlock a more robust and interpretable path to AHD."}
{"id": "2507.20566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20566", "abs": "https://arxiv.org/abs/2507.20566", "authors": ["Jiajun Liu", "Wenjun Ke", "Peng Wang", "Yao He", "Ziyu Shang", "Guozheng Li", "Zijie Xu", "Ke Ji"], "title": "Unlearning of Knowledge Graph Embedding via Preference Optimization", "comment": null, "summary": "Existing knowledge graphs (KGs) inevitably contain outdated or erroneous\nknowledge that needs to be removed from knowledge graph embedding (KGE) models.\nTo address this challenge, knowledge unlearning can be applied to eliminate\nspecific information while preserving the integrity of the remaining knowledge\nin KGs. Existing unlearning methods can generally be categorized into exact\nunlearning and approximate unlearning. However, exact unlearning requires high\ntraining costs while approximate unlearning faces two issues when applied to\nKGs due to the inherent connectivity of triples: (1) It fails to fully remove\ntargeted information, as forgetting triples can still be inferred from\nremaining ones. (2) It focuses on local data for specific removal, which\nweakens the remaining knowledge in the forgetting boundary. To address these\nissues, we propose GraphDPO, a novel approximate unlearning framework based on\ndirect preference optimization (DPO). Firstly, to effectively remove forgetting\ntriples, we reframe unlearning as a preference optimization problem, where the\nmodel is trained by DPO to prefer reconstructed alternatives over the original\nforgetting triples. This formulation penalizes reliance on forgettable\nknowledge, mitigating incomplete forgetting caused by KG connectivity.\nMoreover, we introduce an out-boundary sampling strategy to construct\npreference pairs with minimal semantic overlap, weakening the connection\nbetween forgetting and retained knowledge. Secondly, to preserve boundary\nknowledge, we introduce a boundary recall mechanism that replays and distills\nrelevant information both within and across time steps. We construct eight\nunlearning datasets across four popular KGs with varying unlearning rates.\nExperiments show that GraphDPO outperforms state-of-the-art baselines by up to\n10.1% in MRR_Avg and 14.0% in MRR_F1."}
{"id": "2507.20613", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.20613", "abs": "https://arxiv.org/abs/2507.20613", "authors": ["Te Zhang", "Yuheng Li", "Junxiang Wang", "Lujun Li"], "title": "Enhancing Large Multimodal Models with Adaptive Sparsity and KV Cache Compression", "comment": "6 pages", "summary": "Large multimodal models (LMMs) have advanced significantly by integrating\nvisual encoders with extensive language models, enabling robust reasoning\ncapabilities. However, compressing LMMs for deployment on edge devices remains\na critical challenge. In this work, we propose an adaptive search algorithm\nthat optimizes sparsity and KV cache compression to enhance LMM efficiency.\nUtilizing the Tree-structured Parzen Estimator, our method dynamically adjusts\npruning ratios and KV cache quantization bandwidth across different LMM layers,\nusing model performance as the optimization objective. This approach uniquely\ncombines pruning with key-value cache quantization and incorporates a fast\npruning technique that eliminates the need for additional fine-tuning or weight\nadjustments, achieving efficient compression without compromising accuracy.\nComprehensive evaluations on benchmark datasets, including LLaVA-1.5 7B and\n13B, demonstrate our method superiority over state-of-the-art techniques such\nas SparseGPT and Wanda across various compression levels. Notably, our\nframework automatic allocation of KV cache compression resources sets a new\nstandard in LMM optimization, delivering memory efficiency without sacrificing\nmuch performance."}
{"id": "2507.20620", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.20620", "abs": "https://arxiv.org/abs/2507.20620", "authors": ["Lijian Li"], "title": "Complementarity-driven Representation Learning for Multi-modal Knowledge Graph Completion", "comment": null, "summary": "Multi-modal Knowledge Graph Completion (MMKGC) aims to uncover hidden world\nknowledge in multimodal knowledge graphs by leveraging both multimodal and\nstructural entity information. However, the inherent imbalance in multimodal\nknowledge graphs, where modality distributions vary across entities, poses\nchallenges in utilizing additional modality data for robust entity\nrepresentation. Existing MMKGC methods typically rely on attention or\ngate-based fusion mechanisms but overlook complementarity contained in\nmulti-modal data. In this paper, we propose a novel framework named Mixture of\nComplementary Modality Experts (MoCME), which consists of a\nComplementarity-guided Modality Knowledge Fusion (CMKF) module and an\nEntropy-guided Negative Sampling (EGNS) mechanism. The CMKF module exploits\nboth intra-modal and inter-modal complementarity to fuse multi-view and\nmulti-modal embeddings, enhancing representations of entities. Additionally, we\nintroduce an Entropy-guided Negative Sampling mechanism to dynamically\nprioritize informative and uncertain negative samples to enhance training\neffectiveness and model robustness. Extensive experiments on five benchmark\ndatasets demonstrate that our MoCME achieves state-of-the-art performance,\nsurpassing existing approaches."}
{"id": "2507.20641", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20641", "abs": "https://arxiv.org/abs/2507.20641", "authors": ["Lijian Li"], "title": "Adaptive Fuzzy Time Series Forecasting via Partially Asymmetric Convolution and Sub-Sliding Window Fusion", "comment": null, "summary": "At present, state-of-the-art forecasting models are short of the ability to\ncapture spatio-temporal dependency and synthesize global information at the\nstage of learning. To address this issue, in this paper, through the adaptive\nfuzzified construction of temporal data, we propose a novel convolutional\narchitecture with partially asymmetric design based on the scheme of sliding\nwindow to realize accurate time series forecasting. First, the construction\nstrategy of traditional fuzzy time series is improved to further extract short\nand long term temporal interrelation, which enables every time node to\nautomatically possess corresponding global information and inner relationships\namong them in a restricted sliding window and the process does not require\nhuman involvement. Second, a bilateral Atrous algorithm is devised to reduce\ncalculation demand of the proposed model without sacrificing global\ncharacteristics of elements. And it also allows the model to avoid processing\nredundant information. Third, after the transformation of time series, a\npartially asymmetric convolutional architecture is designed to more flexibly\nmine data features by filters in different directions on feature maps, which\ngives the convolutional neural network (CNN) the ability to construct\nsub-windows within existing sliding windows to model at a more fine-grained\nlevel. And after obtaining the time series information at different levels, the\nmulti-scale features from different sub-windows will be sent to the\ncorresponding network layer for time series information fusion. Compared with\nother competitive modern models, the proposed method achieves state-of-the-art\nresults on most of popular time series datasets, which is fully verified by the\nexperimental results."}
{"id": "2507.20703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20703", "abs": "https://arxiv.org/abs/2507.20703", "authors": ["Aysu Bogatarkan", "Esra Erdem"], "title": "A General Framework for Dynamic MAPF using Multi-Shot ASP and Tunnels", "comment": null, "summary": "MAPF problem aims to find plans for multiple agents in an environment within\na given time, such that the agents do not collide with each other or obstacles.\nMotivated by the execution and monitoring of these plans, we study Dynamic MAPF\n(D-MAPF) problem, which allows changes such as agents entering/leaving the\nenvironment or obstacles being removed/moved. Considering the requirements of\nreal-world applications in warehouses with the presence of humans, we introduce\n1) a general definition for D-MAPF (applicable to variations of D-MAPF), 2) a\nnew framework to solve D-MAPF (utilizing multi-shot computation, and allowing\ndifferent methods to solve D-MAPF), and 3) a new ASP-based method to solve\nD-MAPF (combining advantages of replanning and repairing methods, with a novel\nconcept of tunnels to specify where agents can move). We have illustrated the\nstrengths and weaknesses of this method by experimental evaluations, from the\nperspectives of computational performance and quality of solutions."}
{"id": "2507.20711", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20711", "abs": "https://arxiv.org/abs/2507.20711", "authors": ["Filip Cano", "Thomas A. Henzinger", "Konstantin Kueffner"], "title": "Algorithmic Fairness: A Runtime Perspective", "comment": "To appear in RV 2025", "summary": "Fairness in AI is traditionally studied as a static property evaluated once,\nover a fixed dataset. However, real-world AI systems operate sequentially, with\noutcomes and environments evolving over time. This paper proposes a framework\nfor analysing fairness as a runtime property. Using a minimal yet expressive\nmodel based on sequences of coin tosses with possibly evolving biases, we study\nthe problems of monitoring and enforcing fairness expressed in either toss\noutcomes or coin biases. Since there is no one-size-fits-all solution for\neither problem, we provide a summary of monitoring and enforcement strategies,\nparametrised by environment dynamics, prediction horizon, and confidence\nthresholds. For both problems, we present general results under simple or\nminimal assumptions. We survey existing solutions for the monitoring problem\nfor Markovian and additive dynamics, and existing solutions for the enforcement\nproblem in static settings with known dynamics."}
{"id": "2507.20728", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.20728", "abs": "https://arxiv.org/abs/2507.20728", "authors": ["Andrés Holgado-Sánchez", "Holger Billhardt", "Sascha Ossowski", "Sara Degli-Esposti"], "title": "Learning the Value Systems of Societies from Preferences", "comment": "Full version of publication under the same accepted at ECAI 2025\n  conference (Submission 6755). 8 pages + 2 supplementary material", "summary": "Aligning AI systems with human values and the value-based preferences of\nvarious stakeholders (their value systems) is key in ethical AI. In value-aware\nAI systems, decision-making draws upon explicit computational representations\nof individual values (groundings) and their aggregation into value systems. As\nthese are notoriously difficult to elicit and calibrate manually, value\nlearning approaches aim to automatically derive computational models of an\nagent's values and value system from demonstrations of human behaviour.\nNonetheless, social science and humanities literature suggest that it is more\nadequate to conceive the value system of a society as a set of value systems of\ndifferent groups, rather than as the simple aggregation of individual value\nsystems. Accordingly, here we formalize the problem of learning the value\nsystems of societies and propose a method to address it based on heuristic deep\nclustering. The method learns socially shared value groundings and a set of\ndiverse value systems representing a given society by observing qualitative\nvalue-based preferences from a sample of agents. We evaluate the proposal in a\nuse case with real data about travelling decisions."}
{"id": "2507.20755", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20755", "abs": "https://arxiv.org/abs/2507.20755", "authors": ["Arpan Dasgupta", "Sarvesh Gharat", "Neha Madhiwalla", "Aparna Hegde", "Milind Tambe", "Aparna Taneja"], "title": "Beyond Listenership: AI-Predicted Interventions Drive Improvements in Maternal Health Behaviours", "comment": null, "summary": "Automated voice calls with health information are a proven method for\ndisseminating maternal and child health information among beneficiaries and are\ndeployed in several programs around the world. However, these programs often\nsuffer from beneficiary dropoffs and poor engagement. In previous work, through\nreal-world trials, we showed that an AI model, specifically a restless bandit\nmodel, could identify beneficiaries who would benefit most from live service\ncall interventions, preventing dropoffs and boosting engagement. However, one\nkey question has remained open so far: does such improved listenership via\nAI-targeted interventions translate into beneficiaries' improved knowledge and\nhealth behaviors? We present a first study that shows not only listenership\nimprovements due to AI interventions, but also simultaneously links these\nimprovements to health behavior changes. Specifically, we demonstrate that\nAI-scheduled interventions, which enhance listenership, lead to statistically\nsignificant improvements in beneficiaries' health behaviors such as taking iron\nor calcium supplements in the postnatal period, as well as understanding of\ncritical health topics during pregnancy and infancy. This underscores the\npotential of AI to drive meaningful improvements in maternal and child health."}
{"id": "2507.20758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20758", "abs": "https://arxiv.org/abs/2507.20758", "authors": ["Hao Yang", "Qinghua Zhao", "Lei Li"], "title": "How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection, and Activation", "comment": null, "summary": "Chain-of-Thought (CoT) prompting significantly enhances model reasoning, yet\nits internal mechanisms remain poorly understood. We analyze CoT's operational\nprinciples by reversely tracing information flow across decoding, projection,\nand activation phases. Our quantitative analysis suggests that CoT may serve as\na decoding space pruner, leveraging answer templates to guide output\ngeneration, with higher template adherence strongly correlating with improved\nperformance. Furthermore, we surprisingly find that CoT modulates neuron\nengagement in a task-dependent manner: reducing neuron activation in\nopen-domain tasks, yet increasing it in closed-domain scenarios. These findings\noffer a novel mechanistic interpretability framework and critical insights for\nenabling targeted CoT interventions to design more efficient and robust\nprompts. We released our code and data at\nhttps://anonymous.4open.science/r/cot-D247."}
{"id": "2507.20774", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20774", "abs": "https://arxiv.org/abs/2507.20774", "authors": ["Fatou Ndiaye Mbodji"], "title": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments", "comment": "4 pages, 4 tables", "summary": "Smart contract comment generation has gained traction as a means to improve\ncode comprehension and maintainability in blockchain systems. However,\nevaluating the quality of generated comments remains a challenge. Traditional\nmetrics such as BLEU and ROUGE fail to capture domain-specific nuances, while\nhuman evaluation is costly and unscalable. In this paper, we present\n\\texttt{evalSmarT}, a modular and extensible framework that leverages large\nlanguage models (LLMs) as evaluators. The system supports over 400 evaluator\nconfigurations by combining approximately 40 LLMs with 10 prompting strategies.\nWe demonstrate its application in benchmarking comment generation tools and\nselecting the most informative outputs. Our results show that prompt design\nsignificantly impacts alignment with human judgment, and that LLM-based\nevaluation offers a scalable and semantically rich alternative to existing\nmethods."}
{"id": "2507.20804", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20804", "abs": "https://arxiv.org/abs/2507.20804", "authors": ["Xueyao Wan", "Hang Yu"], "title": "MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances language model generation by\nretrieving relevant information from external knowledge bases. However,\nconventional RAG methods face the issue of missing multimodal information.\nMultimodal RAG methods address this by fusing images and text through mapping\nthem into a shared embedding space, but they fail to capture the structure of\nknowledge and logical chains between modalities. Moreover, they also require\nlarge-scale training for specific tasks, resulting in limited generalizing\nability. To address these limitations, we propose MMGraphRAG, which refines\nvisual content through scene graphs and constructs a multimodal knowledge graph\n(MMKG) in conjunction with text-based KG. It employs spectral clustering to\nachieve cross-modal entity linking and retrieves context along reasoning paths\nto guide the generative process. Experimental results show that MMGraphRAG\nachieves state-of-the-art performance on the DocBench and MMLongBench datasets,\ndemonstrating strong domain adaptability and clear reasoning paths."}
{"id": "2507.20951", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.20951", "abs": "https://arxiv.org/abs/2507.20951", "authors": ["Yang You", "Vincent Thomas", "Alex Schutz", "Robert Skilton", "Nick Hawes", "Olivier Buffet"], "title": "Partially Observable Monte-Carlo Graph Search", "comment": "To be published in Proceedings of ICAPS 2025", "summary": "Currently, large partially observable Markov decision processes (POMDPs) are\noften solved by sampling-based online methods which interleave planning and\nexecution phases. However, a pre-computed offline policy is more desirable in\nPOMDP applications with time or energy constraints. But previous offline\nalgorithms are not able to scale up to large POMDPs. In this article, we\npropose a new sampling-based algorithm, the partially observable Monte-Carlo\ngraph search (POMCGS) to solve large POMDPs offline. Different from many online\nPOMDP methods, which progressively develop a tree while performing\n(Monte-Carlo) simulations, POMCGS folds this search tree on the fly to\nconstruct a policy graph, so that computations can be drastically reduced, and\nusers can analyze and validate the policy prior to embedding and executing it.\nMoreover, POMCGS, together with action progressive widening and observation\nclustering methods provided in this article, is able to address certain\ncontinuous POMDPs. Through experiments, we demonstrate that POMCGS can generate\npolicies on the most challenging POMDPs, which cannot be computed by previous\noffline algorithms, and these policies' values are competitive compared with\nthe state-of-the-art online POMDP algorithms."}
{"id": "2507.20960", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20960", "abs": "https://arxiv.org/abs/2507.20960", "authors": ["Bill Cochran"], "title": "On the Limits of Hierarchically Embedded Logic in Classical Neural Networks", "comment": "9 pages", "summary": "We propose a formal model of reasoning limitations in large neural net models\nfor language, grounded in the depth of their neural architecture. By treating\nneural networks as linear operators over logic predicate space we show that\neach layer can encode at most one additional level of logical reasoning. We\nprove that a neural network of depth a particular depth cannot faithfully\nrepresent predicates in a one higher order logic, such as simple counting over\ncomplex predicates, implying a strict upper bound on logical expressiveness.\nThis structure induces a nontrivial null space during tokenization and\nembedding, excluding higher-order predicates from representability. Our\nframework offers a natural explanation for phenomena such as hallucination,\nrepetition, and limited planning, while also providing a foundation for\nunderstanding how approximations to higher-order logic may emerge. These\nresults motivate architectural extensions and interpretability strategies in\nfuture development of language models."}
{"id": "2507.20964", "categories": ["cs.AI", "cs.CC", "cs.GT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.20964", "abs": "https://arxiv.org/abs/2507.20964", "authors": ["Aran Nayebi"], "title": "Core Safety Values for Provably Corrigible Agents", "comment": "14 pages", "summary": "We introduce the first implementable framework for corrigibility, with\nprovable guarantees in multi-step, partially observed environments. Our\nframework replaces a single opaque reward with five *structurally separate*\nutility heads -- deference, switch-access preservation, truthfulness,\nlow-impact behavior via a belief-based extension of Attainable Utility\nPreservation, and bounded task reward -- combined lexicographically by strict\nweight gaps. Theorem 1 proves exact single-round corrigibility in the partially\nobservable off-switch game; Theorem 3 extends the guarantee to multi-step,\nself-spawning agents, showing that even if each head is \\emph{learned} to\nmean-squared error $\\varepsilon$ and the planner is $\\varepsilon$-sub-optimal,\nthe probability of violating \\emph{any} safety property is bounded while still\nensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF,\nwhich merge all norms into one learned scalar, our separation makes obedience\nand impact-limits dominate even when incentives conflict. For open-ended\nsettings where adversaries can modify the agent, we prove that deciding whether\nan arbitrary post-hack agent will ever violate corrigibility is undecidable by\nreduction to the halting problem, then carve out a finite-horizon ``decidable\nisland'' where safety can be certified in randomized polynomial time and\nverified with privacy-preserving, constant-round zero-knowledge proofs.\nConsequently, the remaining challenge is the ordinary ML task of data coverage\nand generalization: reward-hacking risk is pushed into evaluation quality\nrather than hidden incentive leak-through, giving clearer implementation\nguidance for today's LLM assistants and future autonomous systems."}
{"id": "2507.21017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21017", "abs": "https://arxiv.org/abs/2507.21017", "authors": ["Weichen Zhang", "Yiyou Sun", "Pohao Huang", "Jiayue Pu", "Heyue Lin", "Dawn Song"], "title": "MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them", "comment": "Code and data: https://github.com/sunblaze-ucb/mirage-bench.git", "summary": "Hallucinations pose critical risks for large language model (LLM)-based\nagents, often manifesting as hallucinative actions resulting from fabricated or\nmisinterpreted information within the cognitive context. While recent studies\nhave exposed such failures, existing evaluations remain fragmented and lack a\nprincipled testbed. In this paper, we present MIRAGE-Bench--Measuring Illusions\nin Risky AGEnt settings--the first unified benchmark for eliciting and\nevaluating hallucinations in interactive LLM-agent scenarios. We begin by\nintroducing a three-part taxonomy to address agentic hallucinations: actions\nthat are unfaithful to (i) task instructions, (ii) execution history, or (iii)\nenvironment observations. To analyze, we first elicit such failures by\nperforming a systematic audit of existing agent benchmarks, then synthesize\ntest cases using a snapshot strategy that isolates decision points in\ndeterministic and reproducible manners. To evaluate hallucination behaviors, we\nadopt a fine-grained-level LLM-as-a-Judge paradigm with tailored risk-aware\nprompts, enabling scalable, high-fidelity assessment of agent actions without\nenumerating full action spaces. MIRAGE-Bench provides actionable insights on\nfailure modes of LLM agents and lays the groundwork for principled progress in\nmitigating hallucinations in interactive environments."}
{"id": "2507.21027", "categories": ["cs.AI", "cs.SE", "D.1.6; I.2.1"], "pdf": "https://arxiv.org/pdf/2507.21027", "abs": "https://arxiv.org/abs/2507.21027", "authors": ["Lucia Balážová", "Richard Comploi-Taupe", "Susana Hahn", "Nicolas Rühling", "Gottfried Schenner"], "title": "Smart Expansion Techniques for ASP-based Interactive Configuration", "comment": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "summary": "Product configuration is a successful application of Answer Set Programming\n(ASP). However, challenges are still open for interactive systems to\neffectively guide users through the configuration process. The aim of our work\nis to provide an ASP-based solver for interactive configuration that can deal\nwith large-scale industrial configuration problems and that supports intuitive\nuser interfaces via an API. In this paper, we focus on improving the\nperformance of automatically completing a partial configuration. Our main\ncontribution enhances the classical incremental approach for multi-shot solving\nby four different smart expansion functions. The core idea is to determine and\nadd specific objects or associations to the partial configuration by exploiting\ncautious and brave consequences before checking for the existence of a complete\nconfiguration with the current objects in each iteration. This approach limits\nthe number of costly unsatisfiability checks and reduces the search space,\nthereby improving solving performance. In addition, we present a user interface\nthat uses our API and is implemented in ASP."}
{"id": "2507.21035", "categories": ["cs.AI", "cs.LG", "cs.MA", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2507.21035", "abs": "https://arxiv.org/abs/2507.21035", "authors": ["Haoyang Liu", "Yijiang Li", "Haohan Wang"], "title": "GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis", "comment": "51 pages, 5 figures", "summary": "Gene expression analysis holds the key to many biomedical discoveries, yet\nextracting insights from raw transcriptomic data remains formidable due to the\ncomplexity of multiple large, semi-structured files and the need for extensive\ndomain expertise. Current automation approaches are often limited by either\ninflexible workflows that break down in edge cases or by fully autonomous\nagents that lack the necessary precision for rigorous scientific inquiry.\nGenoMAS charts a different course by presenting a team of LLM-based scientists\nthat integrates the reliability of structured workflows with the adaptability\nof autonomous agents. GenoMAS orchestrates six specialized LLM agents through\ntyped message-passing protocols, each contributing complementary strengths to a\nshared analytic canvas. At the heart of GenoMAS lies a guided-planning\nframework: programming agents unfold high-level task guidelines into Action\nUnits and, at each juncture, elect to advance, revise, bypass, or backtrack,\nthereby maintaining logical coherence while bending gracefully to the\nidiosyncrasies of genomic data.\n  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation\nof 89.13% for data preprocessing and an F$_1$ of 60.48% for gene\nidentification, surpassing the best prior art by 10.61% and 16.85%\nrespectively. Beyond metrics, GenoMAS surfaces biologically plausible\ngene-phenotype associations corroborated by the literature, all while adjusting\nfor latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS."}
{"id": "2507.21046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.21046", "abs": "https://arxiv.org/abs/2507.21046", "authors": ["Huan-ang Gao", "Jiayi Geng", "Wenyue Hua", "Mengkang Hu", "Xinzhe Juan", "Hongzhang Liu", "Shilong Liu", "Jiahao Qiu", "Xuan Qi", "Yiran Wu", "Hongru Wang", "Han Xiao", "Yuhang Zhou", "Shaokun Zhang", "Jiayi Zhang", "Jinyu Xiang", "Yixiong Fang", "Qiwen Zhao", "Dongrui Liu", "Qihan Ren", "Cheng Qian", "Zhenghailong Wang", "Minda Hu", "Huazheng Wang", "Qingyun Wu", "Heng Ji", "Mengdi Wang"], "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence", "comment": "51 pages, 9 figures", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities but remain\nfundamentally static, unable to adapt their internal parameters to novel tasks,\nevolving knowledge domains, or dynamic interaction contexts. As LLMs are\nincreasingly deployed in open-ended, interactive environments, this static\nnature has become a critical bottleneck, necessitating agents that can\nadaptively reason, act, and evolve in real time. This paradigm shift -- from\nscaling static models to developing self-evolving agents -- has sparked growing\ninterest in architectures and methods enabling continual learning and\nadaptation from data, interactions, and experiences. This survey provides the\nfirst systematic and comprehensive review of self-evolving agents, organized\naround three foundational dimensions -- what to evolve, when to evolve, and how\nto evolve. We examine evolutionary mechanisms across agent components (e.g.,\nmodels, memory, tools, architecture), categorize adaptation methods by stages\n(e.g., intra-test-time, inter-test-time), and analyze the algorithmic and\narchitectural designs that guide evolutionary adaptation (e.g., scalar rewards,\ntextual feedback, single-agent and multi-agent systems). Additionally, we\nanalyze evaluation metrics and benchmarks tailored for self-evolving agents,\nhighlight applications in domains such as coding, education, and healthcare,\nand identify critical challenges and research directions in safety,\nscalability, and co-evolutionary dynamics. By providing a structured framework\nfor understanding and designing self-evolving agents, this survey establishes a\nroadmap for advancing adaptive agentic systems in both research and real-world\ndeployments, ultimately shedding lights to pave the way for the realization of\nArtificial Super Intelligence (ASI), where agents evolve autonomously,\nperforming at or beyond human-level intelligence across a wide array of tasks."}
{"id": "2507.19653", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.19653", "abs": "https://arxiv.org/abs/2507.19653", "authors": ["Armen Manukyan", "Hrant Khachatrian", "Edvard Ghukasyan", "Theofanis P. Raptis"], "title": "On the Limitations of Ray-Tracing for Learning-Based RF Tasks in Urban Environments", "comment": "This work has been submitted to the IEEE for possible publication.\n  This work was supported by funding under the bilateral agreement between CNR\n  (Italy) and HESC MESCS RA (Armenia) as part of the DeepRF project for the\n  2025-2026 biennium, and by the HESC MESCS RA grant No. 22rl-052 (DISTAL)", "summary": "We study the realism of Sionna v1.0.2 ray-tracing for outdoor cellular links\nin central Rome. We use a real measurement set of 1,664 user-equipments (UEs)\nand six nominal base-station (BS) sites. Using these fixed positions we\nsystematically vary the main simulation parameters, including path depth,\ndiffuse/specular/refraction flags, carrier frequency, as well as antenna's\nproperties like its altitude, radiation pattern, and orientation. Simulator\nfidelity is scored for each base station via Spearman correlation between\nmeasured and simulated powers, and by a fingerprint-based k-nearest-neighbor\nlocalization algorithm using RSSI-based fingerprints. Across all experiments,\nsolver hyper-parameters are having immaterial effect on the chosen metrics. On\nthe contrary, antenna locations and orientations prove decisive. By simple\ngreedy optimization we improve the Spearman correlation by 5% to 130% for\nvarious base stations, while kNN-based localization error using only simulated\ndata as reference points is decreased by one-third on real-world samples, while\nstaying twice higher than the error with purely real data. Precise geometry and\ncredible antenna models are therefore necessary but not sufficient; faithfully\ncapturing the residual urban noise remains an open challenge for transferable,\nhigh-fidelity outdoor RF simulation."}
{"id": "2507.19657", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19657", "abs": "https://arxiv.org/abs/2507.19657", "authors": ["Beining Wu", "Jun Huang", "Shui Yu"], "title": "\"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems", "comment": "48 pages, 14 figures, submitted to IEEE", "summary": "The development of next-generation networking systems has inherently shifted\nfrom throughput-based paradigms towards intelligent, information-aware designs\nthat emphasize the quality, relevance, and utility of transmitted information,\nrather than sheer data volume. While classical network metrics, such as latency\nand packet loss, remain significant, they are insufficient to quantify the\nnuanced information quality requirements of modern intelligent applications,\nincluding autonomous vehicles, digital twins, and metaverse environments. In\nthis survey, we present the first comprehensive study of the ``X of\nInformation'' continuum by introducing a systematic four-dimensional taxonomic\nframework that structures information metrics along temporal, quality/utility,\nreliability/robustness, and network/communication dimensions. We uncover the\nincreasing interdependencies among these dimensions, whereby temporal freshness\ntriggers quality evaluation, which in turn helps with reliability appraisal,\nultimately enabling effective network delivery. Our analysis reveals that\nartificial intelligence technologies, such as deep reinforcement learning,\nmulti-agent systems, and neural optimization models, enable adaptive,\ncontext-aware optimization of competing information quality objectives. In our\nextensive study of six critical application domains, covering autonomous\ntransportation, industrial IoT, healthcare digital twins, UAV communications,\nLLM ecosystems, and metaverse settings, we illustrate the revolutionary promise\nof multi-dimensional information metrics for meeting diverse operational needs.\nOur survey identifies prominent implementation challenges, including ..."}
{"id": "2507.20115", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.20115", "abs": "https://arxiv.org/abs/2507.20115", "authors": ["Gongli Xi", "Ye Tian", "Yannan Hu", "Yuchao Zhang", "Yapeng Niu", "Xiangyang Gong"], "title": "Packet-Level DDoS Data Augmentation Using Dual-Stream Temporal-Field Diffusion", "comment": "11 pages, 5 figures", "summary": "In response to Distributed Denial of Service (DDoS) attacks, recent research\nefforts increasingly rely on Machine Learning (ML)-based solutions, whose\neffectiveness largely depends on the quality of labeled training datasets. To\naddress the scarcity of such datasets, data augmentation with synthetic traces\nis often employed. However, current synthetic trace generation methods struggle\nto capture the complex temporal patterns and spatial distributions exhibited in\nemerging DDoS attacks. This results in insufficient resemblance to real traces\nand unsatisfied detection accuracy when applied to ML tasks. In this paper, we\npropose Dual-Stream Temporal-Field Diffusion (DSTF-Diffusion), a multi-view,\nmulti-stream network traffic generative model based on diffusion models,\nfeaturing two main streams: The field stream utilizes spatial mapping to bridge\nnetwork data characteristics with pre-trained realms of stable diffusion\nmodels, effectively translating complex network interactions into formats that\nstable diffusion can process, while the spatial stream adopts a dynamic\ntemporal modeling approach, meticulously capturing the intrinsic temporal\npatterns of network traffic. Extensive experiments demonstrate that data\ngenerated by our model exhibits higher statistical similarity to originals\ncompared to current state-of-the-art solutions, and enhance performances on a\nwide range of downstream tasks."}
{"id": "2507.20966", "categories": ["cs.IT", "cs.AI", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.20966", "abs": "https://arxiv.org/abs/2507.20966", "authors": ["Hussein A. Ammar", "Raviraj Adve", "Shahram Shahbazpanahi", "Gary Boudreau", "Israfil Bahceci"], "title": "Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL", "comment": "Published in IEEE Transactions on Communications (IEEE TCOM)", "summary": "In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user\nmobility necessitates updating the set of serving access points to maintain the\nuser-centric clustering. Such updates are typically performed through handoff\n(HO) operations; however, frequent HOs lead to overheads associated with the\nallocation and release of resources. This paper presents a deep reinforcement\nlearning (DRL)-based solution to predict and manage these connections for\nmobile users. Our solution employs the Soft Actor-Critic algorithm, with\ncontinuous action space representation, to train a deep neural network to serve\nas the HO policy. We present a novel proposition for a reward function that\nintegrates a HO penalty in order to balance the attainable rate and the\nassociated overhead related to HOs. We develop two variants of our system; the\nfirst one uses mobility direction-assisted (DA) observations that are based on\nthe user movement pattern, while the second one uses history-assisted (HA)\nobservations that are based on the history of the large-scale fading (LSF).\nSimulation results show that our DRL-based continuous action space approach is\nmore scalable than discrete space counterpart, and that our derived HO policy\nautomatically learns to gather HOs in specific time slots to minimize the\noverhead of initiating HOs. Our solution can also operate in real time with a\nresponse time less than 0.4 ms."}
