{"id": "2512.00023", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00023", "abs": "https://arxiv.org/abs/2512.00023", "authors": ["Hetvi Shastri", "Akanksha Atrey", "Andre Beck", "Nirupama Ravi"], "title": "Trust or Bust: A Survey of Threats in Decentralized Wireless Networks", "comment": null, "summary": "The recent emergence of decentralized wireless networks empowers individual entities to own, operate, and offer subscriptionless connectivity services in exchange for monetary compensation. While traditional connectivity providers have built trust over decades through widespread adoption, established practices, and regulation, entities in a decentralized wireless network, lacking this foundation, may be incentivized to exploit the service for their own advantage. For example, a dishonest hotspot operator can intentionally violate the agreed upon connection terms in an attempt to increase their profits. In this paper, we examine and develop a taxonomy of adversarial behavior patterns in decentralized wireless networks. Our case study finds that provider-driven attacks can potentially more than triple provider earnings. We conclude the paper with a discussion on the critical need to develop novel techniques to detect and mitigate adversarial behavior in decentralized wireless networks.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u53bb\u4e2d\u5fc3\u5316\u65e0\u7ebf\u7f51\u7edc\u4e2d\u70ed\u70b9\u8fd0\u8425\u5546\u53ef\u80fd\u5b9e\u65bd\u7684\u5bf9\u6297\u6027\u884c\u4e3a\u6a21\u5f0f\uff0c\u53d1\u73b0\u8fd9\u4e9b\u653b\u51fb\u53ef\u4f7f\u8fd0\u8425\u5546\u6536\u76ca\u589e\u52a0\u4e09\u500d\u4ee5\u4e0a\uff0c\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u68c0\u6d4b\u548c\u7f13\u89e3\u6280\u672f\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u65e0\u7ebf\u7f51\u7edc\u5141\u8bb8\u4e2a\u4f53\u5b9e\u4f53\u63d0\u4f9b\u65e0\u8ba2\u9605\u8fde\u63a5\u670d\u52a1\u4ee5\u83b7\u53d6\u62a5\u916c\uff0c\u4f46\u8fd9\u4e9b\u5b9e\u4f53\u7f3a\u4e4f\u4f20\u7edf\u8fd0\u8425\u5546\u901a\u8fc7\u6570\u5341\u5e74\u5efa\u7acb\u7684\u4fe1\u4efb\u57fa\u7840\uff0c\u53ef\u80fd\u4e3a\u81ea\u8eab\u5229\u76ca\u800c\u5229\u7528\u670d\u52a1\uff0c\u4f8b\u5982\u70ed\u70b9\u8fd0\u8425\u5546\u53ef\u80fd\u6545\u610f\u8fdd\u53cd\u8fde\u63a5\u534f\u8bae\u6765\u589e\u52a0\u5229\u6da6\u3002", "method": "\u8bba\u6587\u7814\u7a76\u5e76\u5f00\u53d1\u4e86\u53bb\u4e2d\u5fc3\u5316\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5bf9\u6297\u6027\u884c\u4e3a\u6a21\u5f0f\u7684\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790\u4e86\u63d0\u4f9b\u5546\u9a71\u52a8\u7684\u653b\u51fb\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u63d0\u4f9b\u5546\u9a71\u52a8\u7684\u653b\u51fb\u53ef\u80fd\u4f7f\u63d0\u4f9b\u5546\u6536\u76ca\u589e\u52a0\u4e09\u500d\u4ee5\u4e0a\uff0c\u7a81\u663e\u4e86\u53bb\u4e2d\u5fc3\u5316\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5bf9\u6297\u6027\u884c\u4e3a\u7684\u4e25\u91cd\u7ecf\u6d4e\u5f71\u54cd\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u8feb\u5207\u9700\u8981\u5f00\u53d1\u65b0\u6280\u672f\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u53bb\u4e2d\u5fc3\u5316\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5bf9\u6297\u6027\u884c\u4e3a\uff0c\u4ee5\u786e\u4fdd\u7f51\u7edc\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.00025", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00025", "abs": "https://arxiv.org/abs/2512.00025", "authors": ["Yun Ji", "Zeyu Chen", "Xiaoxiong Zhong", "Yanan Ma", "Sheng Zhang", "Yuguang Fang"], "title": "Multi-Server FL with Overlapping Clients: A Latency-Aware Relay Framework", "comment": null, "summary": "Multi-server Federated Learning (FL) has emerged as a promising solution to mitigate communication bottlenecks of single-server FL. In a typical multi-server FL architecture, the regions covered by different edge servers (ESs) may overlap. Under this architecture, clients located in the overlapping areas can access edge models from multiple ESs. Building on this observation, we propose a cloud-free multi-server FL framework that leverages Overlapping Clients (OCs) as relays for inter-server model exchange while uploading the local updated model to ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs without introducing new communication links. We derive a new convergence upper bound for non-convex objectives under non-IID data and an arbitrary number of cells, which explicitly quantifies the impact of inter-server propagation depth on convergence error. Guided by this theoretical result, we formulate an optimization problem that aims to maximize dissemination range of each ES model among all ESs within a limited latency. To solve this problem, we develop a conflict-graph-based local search algorithm optimizing the routing strategy and scheduling the transmission times of individual ESs to its neighboring ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs, achieving the widest possible transmission coverage for each model without introducing new communication links. Extensive experimental results show remarkable performance gains of our scheme compared to existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u53e0\u5ba2\u6237\u7aef\u7684\u65e0\u4e91\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u91cd\u53e0\u533a\u57df\u5ba2\u6237\u7aef\u4f5c\u4e3a\u4e2d\u7ee7\u8fdb\u884c\u670d\u52a1\u5668\u95f4\u6a21\u578b\u4ea4\u6362\uff0c\u65e0\u9700\u989d\u5916\u901a\u4fe1\u94fe\u8def\uff0c\u901a\u8fc7\u4f18\u5316\u8def\u7531\u7b56\u7565\u6700\u5927\u5316\u6a21\u578b\u4f20\u64ad\u8303\u56f4\u3002", "motivation": "\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u4e0d\u540c\u8fb9\u7f18\u670d\u52a1\u5668\u8986\u76d6\u533a\u57df\u53ef\u80fd\u5b58\u5728\u91cd\u53e0\uff0c\u4f4d\u4e8e\u91cd\u53e0\u533a\u57df\u7684\u5ba2\u6237\u7aef\u53ef\u4ee5\u8bbf\u95ee\u591a\u4e2a\u8fb9\u7f18\u670d\u52a1\u5668\u7684\u6a21\u578b\u3002\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u901a\u4fe1\u74f6\u9888\uff0c\u9700\u8981\u5229\u7528\u8fd9\u4e00\u7279\u6027\u6765\u6539\u5584\u670d\u52a1\u5668\u95f4\u6a21\u578b\u4ea4\u6362\u6548\u7387\u3002", "method": "\u63d0\u51fa\u65e0\u4e91\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u91cd\u53e0\u5ba2\u6237\u7aef\u4f5c\u4e3a\u4e2d\u7ee7\u8fdb\u884c\u670d\u52a1\u5668\u95f4\u6a21\u578b\u4ea4\u6362\uff1b\u63a8\u5bfc\u975e\u51f8\u76ee\u6807\u4e0b\u975eIID\u6570\u636e\u7684\u6536\u655b\u4e0a\u754c\uff1b\u57fa\u4e8e\u51b2\u7a81\u56fe\u7684\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u4f18\u5316\u8def\u7531\u7b56\u7565\u548c\u4f20\u8f93\u8c03\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u65b9\u6848\u5728\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u80fd\u591f\u5728\u4e0d\u5f15\u5165\u65b0\u901a\u4fe1\u94fe\u8def\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u591a\u8df3\u4e2d\u7ee7\u5b9e\u73b0\u6700\u5e7f\u6cdb\u7684\u6a21\u578b\u4f20\u64ad\u8986\u76d6\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u91cd\u53e0\u5ba2\u6237\u7aef\u7684\u65e0\u4e91\u591a\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u670d\u52a1\u5668\u95f4\u6a21\u578b\u4ea4\u6362\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6a21\u578b\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.00029", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00029", "abs": "https://arxiv.org/abs/2512.00029", "authors": ["Andreas Kouloumpris", "Georgios L. Stavrinides", "Maria K. Michael", "Theocharis Theocharides"], "title": "An optimization framework for task allocation in the edge/hub/cloud paradigm", "comment": "This version of the manuscript has been accepted for publication in Future Generation Computer Systems after peer review (Author Accepted Manuscript). It is not the final published version (Version of Record) and does not reflect any post-acceptance improvements. The Version of Record is available online at https://doi.org/10.1016/j.future.2024.02.005", "summary": "With the advent of the Internet of Things (IoT), novel critical applications have emerged that leverage the edge/hub/cloud paradigm, which diverges from the conventional edge computing perspective. A growing number of such applications require a streamlined architecture for their effective execution, often comprising a single edge device with sensing capabilities, a single hub device (e.g., a laptop or smartphone) for managing and assisting the edge device, and a more computationally capable cloud server. Typical examples include the utilization of an unmanned aerial vehicle (UAV) for critical infrastructure inspection or a wearable biomedical device (e.g., a smartwatch) for remote patient monitoring. Task allocation in this streamlined architecture is particularly challenging, due to the computational, communication, and energy limitations of the devices at the network edge. Consequently, there is a need for a comprehensive framework that can address the specific task allocation problem optimally and efficiently. To this end, we propose a complete, binary integer linear programming (BILP) based formulation for an application-driven design-time approach, capable of providing an optimal task allocation in the targeted edge/hub/cloud environment. The proposed method minimizes the desired objective, either the overall latency or overall energy consumption, while considering several crucial parameters and constraints often overlooked in related literature. We evaluate our framework using a real-world use-case scenario, as well as appropriate synthetic benchmarks. Our extensive experimentation reveals that the proposed approach yields optimal and scalable results, enabling efficient design space exploration for different applications and computational devices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eBILP\u7684\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u8fb9\u7f18/\u67a2\u7ebd/\u4e91\u67b6\u6784\u4e2d\u7684\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u5ef6\u8fdf\u6216\u80fd\u8017", "motivation": "\u7269\u8054\u7f51\u8fb9\u7f18/\u67a2\u7ebd/\u4e91\u67b6\u6784\u4e2d\u7684\u4efb\u52a1\u5206\u914d\u9762\u4e34\u8ba1\u7b97\u3001\u901a\u4fe1\u548c\u80fd\u91cf\u9650\u5236\u7684\u6311\u6218\uff0c\u9700\u8981\u9488\u5bf9\u8fd9\u79cd\u7b80\u5316\u67b6\u6784\u7684\u4f18\u5316\u6846\u67b6", "method": "\u91c7\u7528\u4e8c\u8fdb\u5236\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08BILP\uff09\u65b9\u6cd5\uff0c\u5728\u8bbe\u8ba1\u65f6\u63d0\u4f9b\u8fb9\u7f18/\u67a2\u7ebd/\u4e91\u73af\u5883\u4e2d\u7684\u6700\u4f18\u4efb\u52a1\u5206\u914d\u65b9\u6848", "result": "\u901a\u8fc7\u771f\u5b9e\u7528\u4f8b\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u4ea7\u751f\u6700\u4f18\u4e14\u53ef\u6269\u5c55\u7684\u7ed3\u679c\uff0c\u652f\u6301\u4e0d\u540c\u5e94\u7528\u548c\u8ba1\u7b97\u8bbe\u5907\u7684\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22", "conclusion": "\u63d0\u51fa\u7684BILP\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u8fb9\u7f18/\u67a2\u7ebd/\u4e91\u67b6\u6784\u4e2d\u7684\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff0c\u5728\u5ef6\u8fdf\u548c\u80fd\u8017\u4f18\u5316\u65b9\u9762\u8868\u73b0\u4f18\u5f02"}}
{"id": "2512.00036", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00036", "abs": "https://arxiv.org/abs/2512.00036", "authors": ["Parth Ashokbhai Shiroya", "Amod Ashtekar", "Swarnagowri Shashidhar", "Mohammed E. Eltayeb"], "title": "Refined Bayesian Optimization for Efficient Beam Alignment in Intelligent Indoor Wireless Environments", "comment": null, "summary": "Future intelligent indoor wireless environments re- quire fast and reliable beam alignment to sustain high-throughput links under mobility and blockage. Exhaustive beam training achieves optimal performance but is prohibitively costly. In indoor settings, dense scatterers and transceiver hardware imperfections introduce multipath and sidelobe leakage, producing measurable power across multiple angles and reducing the effectiveness of outdoor-oriented alignment algorithms. This paper presents a Refined Bayesian Optimization (R-BO) framework that exploits the inherent structure of mmWave transceiver patterns, where received power gradually increases as the transmit and receive beams converge toward the optimum. R-BO integrates a Gaussian Process (GP) surrogate with a Matern kernel and an Expected Improvement (EI) acquisition function, followed by a localized refinement around the predicted optimum. The GP hyperparam- eters are re-optimized online to adapt to irregular variations in the measured angular power field caused by reflections and sidelobe leakage. Experiments across 43 receiver positions in an indoor laboratory demonstrate 97.7% beam-alignment accuracy within 10 degrees, less than 0.3 dB average loss, and an 88% reduction in probing overhead compared to exhaustive search. These results establish R-BO as an efficient and adaptive beam-alignment solution for real-time intelligent indoor wireless environments.", "AI": {"tldr": "\u63d0\u51faR-BO\u6846\u67b6\uff0c\u5229\u7528\u6beb\u7c73\u6ce2\u6536\u53d1\u5668\u6a21\u5f0f\u7684\u7ed3\u6784\u7279\u6027\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u5c40\u90e8\u7ec6\u5316\u5b9e\u73b0\u5ba4\u5185\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u6ce2\u675f\u5bf9\u51c6\uff0c\u51cf\u5c1188%\u7684\u63a2\u6d4b\u5f00\u9500\u3002", "motivation": "\u5ba4\u5185\u667a\u80fd\u65e0\u7ebf\u73af\u5883\u9700\u8981\u5feb\u901f\u53ef\u9760\u7684\u6ce2\u675f\u5bf9\u51c6\u6765\u7ef4\u6301\u9ad8\u541e\u5410\u91cf\u8fde\u63a5\u3002\u4f20\u7edf\u7a77\u4e3e\u6ce2\u675f\u8bad\u7ec3\u6210\u672c\u8fc7\u9ad8\uff0c\u800c\u5ba4\u5185\u5bc6\u96c6\u6563\u5c04\u4f53\u548c\u786c\u4ef6\u7f3a\u9677\u5bfc\u81f4\u591a\u5f84\u548c\u65c1\u74e3\u6cc4\u6f0f\uff0c\u964d\u4f4e\u4e86\u5ba4\u5916\u7b97\u6cd5\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u7cbe\u70bc\u8d1d\u53f6\u65af\u4f18\u5316(R-BO)\u6846\u67b6\uff0c\u5229\u7528\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\u914d\u5408Matern\u6838\u51fd\u6570\u548c\u671f\u671b\u6539\u8fdb\u91c7\u96c6\u51fd\u6570\uff0c\u5728\u7ebf\u91cd\u65b0\u4f18\u5316\u8d85\u53c2\u6570\u4ee5\u9002\u5e94\u4e0d\u89c4\u5219\u53d8\u5316\uff0c\u5e76\u5728\u9884\u6d4b\u6700\u4f18\u503c\u5468\u56f4\u8fdb\u884c\u5c40\u90e8\u7ec6\u5316\u3002", "result": "\u5728\u5ba4\u5185\u5b9e\u9a8c\u5ba443\u4e2a\u63a5\u6536\u4f4d\u7f6e\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff1a10\u5ea6\u5185\u6ce2\u675f\u5bf9\u51c6\u51c6\u786e\u7387\u8fbe97.7%\uff0c\u5e73\u5747\u635f\u8017\u5c0f\u4e8e0.3dB\uff0c\u76f8\u6bd4\u7a77\u4e3e\u641c\u7d22\u51cf\u5c1188%\u7684\u63a2\u6d4b\u5f00\u9500\u3002", "conclusion": "R-BO\u4e3a\u5b9e\u65f6\u5ba4\u5185\u667a\u80fd\u65e0\u7ebf\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u6ce2\u675f\u5bf9\u51c6\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5ba4\u5185\u591a\u5f84\u548c\u786c\u4ef6\u7f3a\u9677\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2512.00135", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00135", "abs": "https://arxiv.org/abs/2512.00135", "authors": ["Amirreza Zamani", "Ayfer \u00d6zg\u00fcr", "Mikael Skoglund"], "title": "An Information Geometric Approach to Fairness With Equalized Odds Constraint", "comment": null, "summary": "We study the statistical design of a fair mechanism that attains equalized odds, where an agent uses some useful data (database) $X$ to solve a task $T$. Since both $X$ and $T$ are correlated with some latent sensitive attribute $S$, the agent designs a representation $Y$ that satisfies an equalized odds, that is, such that $I(Y;S|T) =0$. In contrast to our previous work, we assume here that the agent has no direct access to $S$ and $T$; hence, the Markov chains $S - X - Y$ and $T - X - Y$ hold. Furthermore, we impose a geometric structure on the conditional distribution $P_{S|Y}$, allowing $Y$ and $S$ to have a small correlation, bounded by a threshold. When the threshold is small, concepts from information geometry allow us to approximate mutual information and reformulate the fair mechanism design problem as a quadratic program with closed-form solutions under certain constraints. For other cases, we derive simple, low-complexity lower bounds based on the maximum singular value and vector of a matrix. Finally, we compare our designs with the optimal solution in a numerical example.", "AI": {"tldr": "\u7814\u7a76\u5728\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u654f\u611f\u5c5e\u6027S\u548c\u4efb\u52a1T\u7684\u60c5\u51b5\u4e0b\uff0c\u8bbe\u8ba1\u6ee1\u8db3\u5747\u8861\u8d54\u7387\uff08equalized odds\uff09\u7684\u516c\u5e73\u673a\u5236\uff0c\u901a\u8fc7\u4fe1\u606f\u51e0\u4f55\u65b9\u6cd5\u8fd1\u4f3c\u4e92\u4fe1\u606f\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u4e8c\u6b21\u89c4\u5212\u3002", "motivation": "\u4f20\u7edf\u516c\u5e73\u673a\u5236\u8bbe\u8ba1\u901a\u5e38\u5047\u8bbe\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee\u654f\u611f\u5c5e\u6027S\u548c\u4efb\u52a1T\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u4ee3\u7406\u53ea\u80fd\u901a\u8fc7\u76f8\u5173\u6570\u636eX\u95f4\u63a5\u83b7\u53d6\u4fe1\u606f\u3002\u672c\u6587\u7814\u7a76\u5728S-X-Y\u548cT-X-Y\u9a6c\u5c14\u53ef\u592b\u94fe\u7ea6\u675f\u4e0b\uff0c\u8bbe\u8ba1\u6ee1\u8db3\u5747\u8861\u8d54\u7387\uff08I(Y;S|T)=0\uff09\u7684\u516c\u5e73\u8868\u793aY\u3002", "method": "1) \u5047\u8bbe\u4ee3\u7406\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95eeS\u548cT\uff0c\u53ea\u80fd\u901a\u8fc7\u6570\u636eX\uff1b2) \u5728P_{S|Y}\u4e0a\u65bd\u52a0\u51e0\u4f55\u7ed3\u6784\uff0c\u5141\u8bb8Y\u548cS\u4e4b\u95f4\u5b58\u5728\u6709\u754c\u7684\u5c0f\u76f8\u5173\u6027\uff1b3) \u5f53\u76f8\u5173\u6027\u9608\u503c\u8f83\u5c0f\u65f6\uff0c\u5229\u7528\u4fe1\u606f\u51e0\u4f55\u6982\u5ff5\u8fd1\u4f3c\u4e92\u4fe1\u606f\uff1b4) \u5c06\u516c\u5e73\u673a\u5236\u8bbe\u8ba1\u95ee\u9898\u8f6c\u5316\u4e3a\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\uff1b5) \u5bf9\u4e8e\u5176\u4ed6\u60c5\u51b5\uff0c\u57fa\u4e8e\u77e9\u9635\u7684\u6700\u5927\u5947\u5f02\u503c\u548c\u5411\u91cf\u63a8\u5bfc\u7b80\u5355\u4f4e\u590d\u6742\u5ea6\u7684\u4e0b\u754c\u3002", "result": "\u5728\u7279\u5b9a\u7ea6\u675f\u4e0b\uff0c\u901a\u8fc7\u4fe1\u606f\u51e0\u4f55\u8fd1\u4f3c\u65b9\u6cd5\u83b7\u5f97\u4e86\u95ed\u5f0f\u89e3\u3002\u5bf9\u4e8e\u66f4\u4e00\u822c\u60c5\u51b5\uff0c\u63a8\u5bfc\u4e86\u57fa\u4e8e\u77e9\u9635\u6700\u5927\u5947\u5f02\u503c\u7684\u4f4e\u590d\u6742\u5ea6\u4e0b\u754c\u3002\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u6240\u63d0\u8bbe\u8ba1\u4e0e\u6700\u4f18\u89e3\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u654f\u611f\u5c5e\u6027\u548c\u4efb\u52a1\u7684\u60c5\u51b5\u4e0b\u8bbe\u8ba1\u516c\u5e73\u673a\u5236\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fe1\u606f\u51e0\u4f55\u8fd1\u4f3c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u89e3\u7684\u4e8c\u6b21\u89c4\u5212\uff0c\u4e3a\u5b9e\u9645\u516c\u5e73\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00969", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.00969", "abs": "https://arxiv.org/abs/2512.00969", "authors": ["Felix Saretzky", "Lucas Andersen", "Thomas Engel", "Fazel Ansari"], "title": "Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE", "comment": "9 pages, 3 images, 1 table, conference paper", "summary": "The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a \"what-if\" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56e0\u679c\u673a\u5668\u5b66\u4e60\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u8bc6\u522b\u6545\u969c\u6839\u672c\u539f\u56e0\u5e76\u91cf\u5316\u5e72\u9884\u63aa\u65bd\u5bf9\u7cfb\u7edfKPI\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u4ece\u8bca\u65ad\u5230\u4e3b\u52a8\u5904\u65b9\u7684\u8f6c\u53d8\u3002", "motivation": "\u5f53\u524d\u5236\u9020\u4e1a\u9884\u6d4b\u6027\u7ef4\u62a4\u4f9d\u8d56\u7684\u9884\u6d4b\u6a21\u578b\u5f80\u5f80\u57fa\u4e8e\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u7684\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\uff0c\u5bfc\u81f4\u8bef\u8bca\u548c\u65e0\u6548\u5e72\u9884\u3002\u5173\u952e\u6311\u6218\u5728\u4e8e\uff1a\u867d\u7136\u80fd\u9884\u6d4b\u6545\u969c\u53d1\u751f\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u65b9\u6cd5\u6765\u7406\u89e3\u6545\u969c\u539f\u56e0\uff0c\u4ece\u800c\u65e0\u6cd5\u786e\u5b9a\u6700\u6709\u6548\u7684\u5e72\u9884\u63aa\u65bd\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u56e0\u679c\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\"\u5047\u8bbe\u5206\u6790\"\u6a21\u578b\uff0c\u8bc4\u4f30\u6f5c\u5728\u4fee\u590d\u63aa\u65bd\u7684\u6548\u679c\u3002\u901a\u8fc7\u6d4b\u91cf\u6bcf\u4e2a\u5e72\u9884\u5bf9\u7cfb\u7edf\u7ea7KPI\uff08\u5982\u8bbe\u5907\u7efc\u5408\u6548\u7387OEE\uff09\u7684\u56e0\u679c\u6548\u5e94\uff0c\u4e3a\u751f\u4ea7\u7ebf\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u884c\u52a8\u6392\u5e8f\u63a8\u8350\u3002", "result": "\u4f7f\u7528\u534a\u5408\u6210\u5236\u9020\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30\uff0c\u5e76\u4e0e\u57fa\u7ebf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u8bc6\u522b\u6839\u672c\u539f\u56e0\uff0c\u8fd8\u80fd\u91cf\u5316\u5176\u64cd\u4f5c\u5f71\u54cd\u3002", "conclusion": "\u4e3a\u7a33\u5065\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u6846\u67b6\u5960\u5b9a\u6280\u672f\u57fa\u7840\uff0c\u4f7f\u5de5\u7a0b\u5e08\u80fd\u591f\u5728\u56e0\u679c\u73af\u5883\u4e2d\u6d4b\u8bd5\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u505a\u51fa\u66f4\u6709\u6548\u7684\u64cd\u4f5c\u51b3\u7b56\u5e76\u51cf\u5c11\u6602\u8d35\u7684\u505c\u673a\u65f6\u95f4\u3002"}}
{"id": "2512.00097", "categories": ["cs.AI", "cs.CG"], "pdf": "https://arxiv.org/pdf/2512.00097", "abs": "https://arxiv.org/abs/2512.00097", "authors": ["Boyan Duan", "Xiao Liang", "Shuai Lu", "Yaoxiang Wang", "Yelong Shen", "Kai-Wei Chang", "Ying Nian Wu", "Mao Yang", "Weizhu Chen", "Yeyun Gong"], "title": "Gold-Medal-Level Olympiad Geometry Solving with Efficient Heuristic Auxiliary Constructions", "comment": null, "summary": "Automated theorem proving in Euclidean geometry, particularly for International Mathematical Olympiad (IMO) level problems, remains a major challenge and an important research focus in Artificial Intelligence. In this paper, we present a highly efficient method for geometry theorem proving that runs entirely on CPUs without relying on neural network-based inference. Our initial study shows that a simple random strategy for adding auxiliary points can achieve silver-medal level human performance on IMO. Building on this, we propose HAGeo, a Heuristic-based method for adding Auxiliary constructions in Geometric deduction that solves 28 of 30 problems on the IMO-30 benchmark, achieving gold-medal level performance and surpassing AlphaGeometry, a competitive neural network-based approach, by a notable margin. To evaluate our method and existing approaches more comprehensively, we further construct HAGeo-409, a benchmark consisting of 409 geometry problems with human-assessed difficulty levels. Compared with the widely used IMO-30, our benchmark poses greater challenges and provides a more precise evaluation, setting a higher bar for geometry theorem proving.", "AI": {"tldr": "HAGeo\u65b9\u6cd5\u5728\u51e0\u4f55\u5b9a\u7406\u8bc1\u660e\u4e2d\u901a\u8fc7\u542f\u53d1\u5f0f\u6dfb\u52a0\u8f85\u52a9\u6784\u9020\uff0c\u5728IMO-30\u57fa\u51c6\u4e0a\u8fbe\u523028/30\u7684\u89e3\u9898\u7387\uff0c\u8d85\u8d8aAlphaGeometry\uff0c\u5e76\u521b\u5efa\u4e86\u66f4\u5177\u6311\u6218\u6027\u7684HAGeo-409\u57fa\u51c6\u3002", "motivation": "\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u7684\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff0c\u7279\u522b\u662fIMO\u7ea7\u522b\u7684\u95ee\u9898\uff0c\u662fAI\u9886\u57df\u7684\u91cd\u8981\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\uff0c\u9700\u8981GPU\u8d44\u6e90\u4e14\u6548\u7387\u6709\u9650\u3002", "method": "\u63d0\u51faHAGeo\u65b9\u6cd5\uff1a\u57fa\u4e8e\u542f\u53d1\u5f0f\u7b56\u7565\u6dfb\u52a0\u8f85\u52a9\u6784\u9020\u7684\u51e0\u4f55\u63a8\u7406\u65b9\u6cd5\uff0c\u5b8c\u5168\u5728CPU\u4e0a\u8fd0\u884c\uff0c\u65e0\u9700\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u3002\u9996\u5148\u53d1\u73b0\u7b80\u5355\u7684\u968f\u673a\u6dfb\u52a0\u8f85\u52a9\u70b9\u7b56\u7565\u5c31\u80fd\u8fbe\u5230\u94f6\u724c\u6c34\u5e73\uff0c\u7136\u540e\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u5728IMO-30\u57fa\u51c6\u4e0a\u89e3\u51b3\u4e8628/30\u4e2a\u95ee\u9898\uff0c\u8fbe\u5230\u91d1\u724c\u6c34\u5e73\uff0c\u663e\u8457\u8d85\u8d8aAlphaGeometry\u3002\u521b\u5efa\u4e86\u5305\u542b409\u4e2a\u95ee\u9898\u7684HAGeo-409\u57fa\u51c6\uff0c\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u8bc4\u4f30\u548c\u66f4\u9ad8\u6311\u6218\u3002", "conclusion": "HAGeo\u5c55\u793a\u4e86\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u5728\u51e0\u4f55\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u9ad8\u6548\u6027\uff0c\u65e0\u9700\u795e\u7ecf\u7f51\u7edc\u5c31\u80fd\u8fbe\u5230\u9876\u5c16\u6c34\u5e73\u3002\u65b0\u57fa\u51c6\u4e3a\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2512.00039", "categories": ["cs.NI", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00039", "abs": "https://arxiv.org/abs/2512.00039", "authors": ["Tasnim Ahmed", "Siana Rizwan", "Naveed Ejaz", "Salimur Choudhury"], "title": "LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation", "comment": null, "summary": "Building on advancements in Large Language Models (LLMs), we can tackle complex analytical and mathematical reasoning tasks requiring nuanced contextual understanding. A prime example of such complex tasks is modelling resource allocation optimization in networks, which extends beyond translating natural language inputs into mathematical equations or Linear Programming (LP), Integer Linear Programming (ILP), and Mixed-Integer Linear Programming (MILP) models. However, existing benchmarks and datasets cannot address the complexities of such problems with dynamic environments, interdependent variables, and heterogeneous constraints. To address this gap, we introduce NL4RA, a curated dataset comprising 50 resource allocation optimization problems formulated as LP, ILP, and MILP. We then evaluate the performance of well-known open-source LLMs with varying parameter counts. To enhance existing LLM based methods, we introduce LM4Opt RA, a multi candidate framework that applies diverse prompting strategies such as direct, few shot, and chain of thought, combined with a structured ranking mechanism to improve accuracy. We identified discrepancies between human judgments and automated scoring such as ROUGE, BLEU, or BERT scores. However, human evaluation is time-consuming and requires specialized expertise, making it impractical for a fully automated end-to-end framework. To quantify the difference between LLM-generated responses and ground truth, we introduce LLM-Assisted Mathematical Evaluation (LAME), an automated metric designed for mathematical formulations. Using LM4Opt-RA, Llama-3.1-70B achieved a LAME score of 0.8007, outperforming other models by a significant margin, followed closely by Llama-3.1-8B. While baseline LLMs demonstrate considerable promise, they still lag behind human expertise; our proposed method surpasses these baselines regarding LAME and other metrics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faNL4RA\u6570\u636e\u96c6\u548cLM4Opt RA\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u8d44\u6e90\u5206\u914d\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6570\u5b66\u5efa\u6a21\u80fd\u529b\uff0c\u5e76\u5f15\u5165LAME\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5904\u7406\u52a8\u6001\u73af\u5883\u3001\u76f8\u4e92\u4f9d\u8d56\u53d8\u91cf\u548c\u5f02\u6784\u7ea6\u675f\u7684\u590d\u6742\u8d44\u6e90\u5206\u914d\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cfLLM\u5728\u8fd9\u7c7b\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "1) \u521b\u5efaNL4RA\u6570\u636e\u96c6\uff0850\u4e2aLP/ILP/MILP\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff09\uff1b2) \u63d0\u51faLM4Opt RA\u591a\u5019\u9009\u6846\u67b6\uff0c\u7ed3\u5408\u76f4\u63a5\u63d0\u793a\u3001\u5c11\u6837\u672c\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u7b49\u7b56\u7565\uff1b3) \u5f15\u5165LAME\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u66ff\u4ee3\u4f20\u7edf\u6587\u672c\u76f8\u4f3c\u5ea6\u6307\u6807\u3002", "result": "Llama-3.1-70B\u5728LM4Opt-RA\u6846\u67b6\u4e0b\u83b7\u5f970.8007\u7684LAME\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0cLlama-3.1-8B\u7d27\u968f\u5176\u540e\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5728LAME\u548c\u5176\u4ed6\u6307\u6807\u4e0a\u5747\u8d85\u8d8a\u57fa\u7ebfLLM\u3002", "conclusion": "\u867d\u7136\u57fa\u7ebfLLM\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u843d\u540e\u4e8e\u4eba\u7c7b\u4e13\u5bb6\uff1b\u63d0\u51fa\u7684LM4Opt RA\u6846\u67b6\u548cLAME\u8bc4\u4f30\u6307\u6807\u4e3a\u8d44\u6e90\u5206\u914d\u4f18\u5316\u95ee\u9898\u7684\u81ea\u52a8\u6570\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00248", "categories": ["cs.IT", "cs.CC"], "pdf": "https://arxiv.org/pdf/2512.00248", "abs": "https://arxiv.org/abs/2512.00248", "authors": ["Rohan Goyal", "Prahladh Harsha", "Mrinal Kumar", "Ashutosh Shankar"], "title": "Fast list recovery of univariate multiplicity and folded Reed-Solomon codes", "comment": null, "summary": "A recent work of Goyal, Harsha, Kumar and Shankar gave nearly linear time algorithms for the list decoding of Folded Reed-Solomon codes (FRS) and univariate multiplicity codes up to list decoding capacity in their natural setting of parameters. A curious aspect of this work was that unlike most list decoding algorithms for codes that also naturally extend to the problem of list recovery, the algorithm in the work of Goyal et al. seemed to be crucially tied to the problem of list decoding. In particular, it wasn't clear if their algorithm could be generalized to solve the problem of list recovery FRS and univariate multiplicity codes in near linear time.\n  In this work, we address this question and design $\\tilde{O}(n)$-time algorithms for list recovery of Folded Reed-Solomon codes and univariate Multiplicity codes up to capacity, where $n$ is the blocklength of the code. For our proof, we build upon the lattice based ideas crucially used by Goyal et al. with one additional technical ingredient - we show the construction of appropriately structured lattices over the univariate polynomial ring that \\emph{capture} the list recovery problem for these codes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bbe\u8ba1\u4e86\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u7528\u4e8e\u6298\u53e0\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u548c\u5355\u53d8\u91cf\u91cd\u6570\u7801\u7684\u5217\u8868\u6062\u590d\uff0c\u8fbe\u5230\u5bb9\u91cf\u9650\u5236\u3002", "motivation": "\u5148\u524dGoyal\u7b49\u4eba\u7684\u5de5\u4f5c\u4e3a\u6298\u53e0\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u548c\u5355\u53d8\u91cf\u91cd\u6570\u7801\u7684\u5217\u8868\u89e3\u7801\u63d0\u4f9b\u4e86\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u7b97\u6cd5\u4f3c\u4e4e\u4e13\u95e8\u9488\u5bf9\u5217\u8868\u89e3\u7801\u95ee\u9898\uff0c\u65e0\u6cd5\u81ea\u7136\u5730\u6269\u5c55\u5230\u5217\u8868\u6062\u590d\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\uff0c\u4e3a\u8fd9\u4e9b\u7801\u7684\u5217\u8868\u6062\u590d\u95ee\u9898\u8bbe\u8ba1\u9ad8\u6548\u7684\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u3002", "method": "\u57fa\u4e8eGoyal\u7b49\u4eba\u4f7f\u7528\u7684\u683c\u57fa\u601d\u60f3\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u5173\u952e\u6280\u672f\u8981\u7d20\uff1a\u6784\u9020\u5728\u5355\u53d8\u91cf\u591a\u9879\u5f0f\u73af\u4e0a\u5177\u6709\u9002\u5f53\u7ed3\u6784\u7684\u683c\uff0c\u8fd9\u4e9b\u683c\u80fd\u591f\"\u6355\u83b7\"\u8fd9\u4e9b\u7801\u7684\u5217\u8868\u6062\u590d\u95ee\u9898\u3002", "result": "\u8bbe\u8ba1\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$\\tilde{O}(n)$\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u6298\u53e0\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u548c\u5355\u53d8\u91cf\u91cd\u6570\u7801\u7684\u5217\u8868\u6062\u590d\uff0c\u8fbe\u5230\u5bb9\u91cf\u9650\u5236\uff0c\u5176\u4e2d$n$\u662f\u7801\u7684\u5757\u957f\u5ea6\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86\u5148\u524d\u5de5\u4f5c\u4e2d\u7b97\u6cd5\u65e0\u6cd5\u6269\u5c55\u5230\u5217\u8868\u6062\u590d\u7684\u95ee\u9898\uff0c\u4e3a\u6298\u53e0\u91cc\u5fb7-\u6240\u7f57\u95e8\u7801\u548c\u5355\u53d8\u91cf\u91cd\u6570\u7801\u7684\u5217\u8868\u6062\u590d\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u6280\u672f\u7a7a\u767d\u3002"}}
{"id": "2512.00998", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.00998", "abs": "https://arxiv.org/abs/2512.00998", "authors": ["Christof R\u00f6hrig", "Benz Cramer"], "title": "LPWAN based IoT Architecture for Distributed Energy Monitoring in Deep Indoor Environments", "comment": null, "summary": "Continuous energy monitoring is essential for identifying potential savings and predicting the energy requirements of buildings. Energy meters are often located in underground spaces that are difficult to reach with wireless technology. This paper presents an experimental study comparing different Low Power Wide Area Networks (LPWAN) technologies in terms of building penetration and radio coverage. The technologies Low Power Long Range Wide Area Networks (LoRaWAN), Narrow Band Internet of Things (NB-IoT), Sigfox 0G and Wireless Smart Ubiquitous Networks (Wi-SUN) are evaluated experimentally. It also proposes a distributed hybrid IoT architecture that combines multiple LPWAN technologies using an abstraction layer to optimize cost and coverage. Communication is message-based using the publish-subscribe messaging pattern. It is implemented using the MQTT protocol. The abstraction layer decodes the proprietary binary data and converts it to a normalized JSON format.", "AI": {"tldr": "\u5b9e\u9a8c\u6bd4\u8f83\u591a\u79cdLPWAN\u6280\u672f\u5728\u5efa\u7b51\u7a7f\u900f\u548c\u8986\u76d6\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u591a\u79cdLPWAN\u6280\u672f\u7684\u5206\u5e03\u5f0f\u6df7\u5408\u7269\u8054\u7f51\u67b6\u6784", "motivation": "\u5efa\u7b51\u80fd\u8017\u76d1\u6d4b\u9700\u8981\u5728\u5730\u4e0b\u7a7a\u95f4\u7b49\u65e0\u7ebf\u4fe1\u53f7\u96be\u4ee5\u8986\u76d6\u7684\u533a\u57df\u90e8\u7f72\u4f20\u611f\u5668\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540cLPWAN\u6280\u672f\u7684\u7a7f\u900f\u80fd\u529b\u548c\u8986\u76d6\u8303\u56f4", "method": "\u5b9e\u9a8c\u6bd4\u8f83LoRaWAN\u3001NB-IoT\u3001Sigfox 0G\u548cWi-SUN\u56db\u79cdLPWAN\u6280\u672f\uff1b\u63d0\u51fa\u57fa\u4e8e\u62bd\u8c61\u5c42\u7684\u5206\u5e03\u5f0f\u6df7\u5408\u7269\u8054\u7f51\u67b6\u6784\uff0c\u4f7f\u7528MQTT\u534f\u8bae\u5b9e\u73b0\u53d1\u5e03-\u8ba2\u9605\u6d88\u606f\u6a21\u5f0f", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e0d\u540cLPWAN\u6280\u672f\u7684\u5efa\u7b51\u7a7f\u900f\u548c\u65e0\u7ebf\u8986\u76d6\u6027\u80fd\uff1b\u5b9e\u73b0\u4e86\u5c06\u4e13\u6709\u4e8c\u8fdb\u5236\u6570\u636e\u89e3\u7801\u5e76\u8f6c\u6362\u4e3a\u6807\u51c6\u5316JSON\u683c\u5f0f\u7684\u62bd\u8c61\u5c42", "conclusion": "\u6df7\u5408LPWAN\u67b6\u6784\u53ef\u4ee5\u4f18\u5316\u6210\u672c\u548c\u8986\u76d6\u8303\u56f4\uff0c\u4e3a\u5efa\u7b51\u80fd\u8017\u76d1\u6d4b\u63d0\u4f9b\u53ef\u9760\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.00185", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00185", "abs": "https://arxiv.org/abs/2512.00185", "authors": ["Shashanka B R", "Mohith Charan R", "Seema Banu F"], "title": "Chunking Strategies for Multimodal AI Systems", "comment": "45 pages, 5 figure", "summary": "Our goal is to consolidate the landscape of multimodal chunking strategies, providing researchers and practitioners with a technical foundation and design space for developing more effective and efficient multimodal AI systems. This survey paves the way for innovations in robust chunking pipelines that scale with modality complexity, enhance processing accuracy, and improve generative coherence in real-world applications. This survey provides a comprehensive taxonomy and technical analysis of chunking strategies tailored for each modality: text, images, audio, video, and cross-modal data. We examine classical and modern approaches such as fixed-size token windowing, recursive text splitting, object-centric visual chunking, silence-based audio segmentation, and scene detection in videos. Each approach is analyzed in terms of its underlying methodology, supporting tools (e.g., LangChain, Detectron2, PySceneDetect), benefits, and challenges, particularly those related to granularity-context trade-offs and multimodal alignment. Furthermore, we explore emerging cross-modal chunking strategies that aim to preserve alignment and semantic consistency across disparate data types [4]. We also include comparative insights, highlight open problems such as asynchronous information density and noisy alignment signals, and identify opportunities for future research in adaptive, learning-based, and task-specific chunking.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u7cfb\u7edf\u68b3\u7406\u4e86\u591a\u6a21\u6001\u5206\u5757\u7b56\u7565\uff0c\u4e3a\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u591a\u6a21\u6001AI\u7cfb\u7edf\u63d0\u4f9b\u6280\u672f\u57fa\u7840\u548c\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u6db5\u76d6\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u548c\u8de8\u6a21\u6001\u6570\u636e\u7684\u5206\u5757\u65b9\u6cd5\u3002", "motivation": "\u6574\u5408\u591a\u6a21\u6001\u5206\u5757\u7b56\u7565\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u6280\u672f\u57fa\u7840\uff0c\u5e2e\u52a9\u5f00\u53d1\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001AI\u7cfb\u7edf\uff0c\u5e94\u5bf9\u73b0\u5b9e\u5e94\u7528\u4e2d\u6a21\u6001\u590d\u6742\u6027\u3001\u5904\u7406\u51c6\u786e\u6027\u548c\u751f\u6210\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002", "method": "\u63d0\u4f9b\u5168\u9762\u7684\u5206\u7c7b\u548c\u6280\u672f\u5206\u6790\uff0c\u9488\u5bf9\u6bcf\u79cd\u6a21\u6001\uff08\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u3001\u8de8\u6a21\u6001\u6570\u636e\uff09\u5206\u6790\u7ecf\u5178\u548c\u73b0\u4ee3\u65b9\u6cd5\uff0c\u5305\u62ec\u56fa\u5b9a\u5927\u5c0f\u6807\u8bb0\u7a97\u53e3\u3001\u9012\u5f52\u6587\u672c\u5206\u5272\u3001\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u89c6\u89c9\u5206\u5757\u3001\u57fa\u4e8e\u9759\u97f3\u7684\u97f3\u9891\u5206\u5272\u548c\u89c6\u9891\u573a\u666f\u68c0\u6d4b\u7b49\uff0c\u5e76\u5206\u6790\u6bcf\u79cd\u65b9\u6cd5\u7684\u5e95\u5c42\u65b9\u6cd5\u8bba\u3001\u652f\u6301\u5de5\u5177\u3001\u4f18\u52bf\u548c\u6311\u6218\u3002", "result": "\u5efa\u7acb\u4e86\u591a\u6a21\u6001\u5206\u5757\u7b56\u7565\u7684\u7efc\u5408\u5206\u7c7b\u4f53\u7cfb\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u7c92\u5ea6-\u4e0a\u4e0b\u6587\u6743\u8861\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u7b49\u5173\u952e\u6311\u6218\uff0c\u63a2\u7d22\u4e86\u65b0\u5174\u7684\u8de8\u6a21\u6001\u5206\u5757\u7b56\u7565\uff0c\u5e76\u63d0\u4f9b\u4e86\u6bd4\u8f83\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u5f00\u53d1\u9c81\u68d2\u7684\u5206\u5757\u7ba1\u9053\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u80fd\u591f\u968f\u7740\u6a21\u6001\u590d\u6742\u6027\u6269\u5c55\u3001\u63d0\u9ad8\u5904\u7406\u51c6\u786e\u6027\u5e76\u6539\u5584\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u751f\u6210\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5f02\u6b65\u4fe1\u606f\u5bc6\u5ea6\u548c\u566a\u58f0\u5bf9\u9f50\u4fe1\u53f7\u7b49\u5f00\u653e\u95ee\u9898\uff0c\u4ee5\u53ca\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u5b66\u4e60\u548c\u4efb\u52a1\u7279\u5b9a\u5206\u5757\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2512.00040", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00040", "abs": "https://arxiv.org/abs/2512.00040", "authors": ["Sagar Sudhakara", "Pankaj Rajak"], "title": "Constrained Network Slice Assignment via Large Language Models", "comment": "Accepted at NeurIPS 2025 Workshop on AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG), San Diego, CA", "summary": "Modern networks support network slicing, which partitions physical infrastructure into virtual slices tailored to different service requirements (for example, high bandwidth or low latency). Optimally allocating users to slices is a constrained optimization problem that traditionally requires complex algorithms. In this paper, we explore the use of Large Language Models (LLMs) to tackle radio resource allocation for network slicing. We focus on two approaches: (1) using an LLM in a zero-shot setting to directly assign user service requests to slices, and (2) formulating an integer programming model where the LLM provides semantic insight by estimating similarity between requests. Our experiments show that an LLM, even with zero-shot prompting, can produce a reasonable first draft of slice assignments, although it may violate some capacity or latency constraints. We then incorporate the LLM's understanding of service requirements into an optimization solver to generate an improved allocation. The results demonstrate that LLM-guided grouping of requests, based on minimal textual input, achieves performance comparable to traditional methods that use detailed numerical data, in terms of resource utilization and slice isolation. While the LLM alone does not perfectly satisfy all constraints, it significantly reduces the search space and, when combined with exact solvers, provides a promising approach for efficient 5G network slicing resource allocation.", "AI": {"tldr": "LLM\u7528\u4e8e5G\u7f51\u7edc\u5207\u7247\u8d44\u6e90\u5206\u914d\uff0c\u901a\u8fc7\u96f6-shot\u76f4\u63a5\u5206\u914d\u548c\u63d0\u4f9b\u8bed\u4e49\u6d1e\u5bdf\u8f85\u52a9\u6574\u6570\u89c4\u5212\uff0c\u6027\u80fd\u63a5\u8fd1\u4f20\u7edf\u65b9\u6cd5\u4f46\u9700\u7ed3\u5408\u7cbe\u786e\u6c42\u89e3\u5668\u6ee1\u8db3\u7ea6\u675f", "motivation": "\u7f51\u7edc\u5207\u7247\u9700\u8981\u6839\u636e\u670d\u52a1\u9700\u6c42\uff08\u5982\u9ad8\u5e26\u5bbd\u3001\u4f4e\u5ef6\u8fdf\uff09\u5c06\u7528\u6237\u5206\u914d\u5230\u865a\u62df\u5207\u7247\uff0c\u4f20\u7edf\u4f18\u5316\u7b97\u6cd5\u590d\u6742\uff0c\u63a2\u7d22LLM\u80fd\u5426\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b", "method": "\u4e24\u79cd\u65b9\u6cd5\uff1a1) LLM\u96f6-shot\u76f4\u63a5\u5206\u914d\u7528\u6237\u670d\u52a1\u8bf7\u6c42\u5230\u5207\u7247\uff1b2) LLM\u63d0\u4f9b\u8bed\u4e49\u6d1e\u5bdf\u4f30\u8ba1\u8bf7\u6c42\u76f8\u4f3c\u5ea6\uff0c\u8f85\u52a9\u6574\u6570\u89c4\u5212\u6a21\u578b", "result": "LLM\u96f6-shot\u80fd\u4ea7\u751f\u5408\u7406\u7684\u5207\u7247\u5206\u914d\u521d\u7a3f\uff0c\u4f46\u53ef\u80fd\u8fdd\u53cd\u5bb9\u91cf\u6216\u5ef6\u8fdf\u7ea6\u675f\uff1bLLM\u5f15\u5bfc\u7684\u5206\u7ec4\u7ed3\u5408\u4f18\u5316\u6c42\u89e3\u5668\u540e\uff0c\u6027\u80fd\u4e0e\u4f20\u7edf\u4f7f\u7528\u8be6\u7ec6\u6570\u503c\u6570\u636e\u7684\u65b9\u6cd5\u76f8\u5f53", "conclusion": "LLM\u5355\u72ec\u4f7f\u7528\u4e0d\u80fd\u5b8c\u7f8e\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\uff0c\u4f46\u80fd\u663e\u8457\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u4e0e\u7cbe\u786e\u6c42\u89e3\u5668\u7ed3\u5408\u4e3a5G\u7f51\u7edc\u5207\u7247\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5"}}
{"id": "2512.00347", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00347", "abs": "https://arxiv.org/abs/2512.00347", "authors": ["Zhuang Li", "Wenyi Zhang"], "title": "ORBGRAND Is Exactly Capacity-achieving via Rank Companding", "comment": null, "summary": "Among guessing random additive noise decoding (GRAND) algorithms, ordered reliability bits GRAND (ORBGRAND) has attracted considerable attention due to its efficient use of soft information and suitability for hardware implementation. It has also been shown that ORBGRAND achieves a rate very close to the capacity over additive white Gaussian noise channels with antipodal inputs. In this work, it is further established that, via suitably companding the ranks in ORBGRAND according to the inverse cumulative distribution function (CDF) of channel reliability, the resulting CDF-ORBGRAND algorithm exactly achieves the mutual information of general binary-input memoryless channels under symmetric input distribution, i.e., the symmetric capacity. This result is then applied to bit-interleaved coded modulation (BICM) systems to handle high-order input constellations. Via considering the effects of mismatched decoding due to both BICM and ORBGRAND, it is shown that CDF-ORBGRAND is capable of achieving the BICM capacity, which was initially derived by treating BICM as a set of independent parallel channels.", "AI": {"tldr": "CDF-ORBGRAND\u7b97\u6cd5\u901a\u8fc7\u6839\u636e\u4fe1\u9053\u53ef\u9760\u6027\u7684\u9006\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u538b\u7f29ORBGRAND\u4e2d\u7684\u6392\u5e8f\uff0c\u80fd\u591f\u7cbe\u786e\u8fbe\u5230\u4e8c\u8fdb\u5236\u8f93\u5165\u5bf9\u79f0\u5bb9\u91cf\uff0c\u5e76\u6269\u5c55\u5e94\u7528\u5230BICM\u7cfb\u7edf\u5b9e\u73b0BICM\u5bb9\u91cf\u3002", "motivation": "ORBGRAND\u7b97\u6cd5\u867d\u7136\u80fd\u6709\u6548\u5229\u7528\u8f6f\u4fe1\u606f\u5e76\u9002\u5408\u786c\u4ef6\u5b9e\u73b0\uff0c\u4e14\u5728AWGN\u4fe1\u9053\u4e0a\u63a5\u8fd1\u5bb9\u91cf\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u5728\u66f4\u4e00\u822c\u7684\u4e8c\u8fdb\u5236\u8f93\u5165\u65e0\u8bb0\u5fc6\u4fe1\u9053\u4e0a\u7cbe\u786e\u8fbe\u5230\u5bf9\u79f0\u5bb9\u91cf\u3002", "method": "\u63d0\u51faCDF-ORBGRAND\u7b97\u6cd5\uff1a\u901a\u8fc7\u6839\u636e\u4fe1\u9053\u53ef\u9760\u6027\u7684\u9006\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u538b\u7f29ORBGRAND\u4e2d\u7684\u6392\u5e8f\uff0c\u7136\u540e\u5c06\u8be5\u65b9\u6cd5\u6269\u5c55\u5230BICM\u7cfb\u7edf\u5904\u7406\u9ad8\u9636\u8f93\u5165\u661f\u5ea7\uff0c\u8003\u8651BICM\u548cORBGRAND\u5bfc\u81f4\u7684\u5931\u914d\u89e3\u7801\u6548\u5e94\u3002", "result": "CDF-ORBGRAND\u80fd\u591f\u7cbe\u786e\u8fbe\u5230\u4e00\u822c\u4e8c\u8fdb\u5236\u8f93\u5165\u65e0\u8bb0\u5fc6\u4fe1\u9053\u7684\u5bf9\u79f0\u5bb9\u91cf\uff0c\u5e76\u4e14\u5728BICM\u7cfb\u7edf\u4e2d\u80fd\u591f\u5b9e\u73b0BICM\u5bb9\u91cf\uff0c\u8be5\u5bb9\u91cf\u6700\u521d\u662f\u901a\u8fc7\u5c06BICM\u89c6\u4e3a\u4e00\u7ec4\u72ec\u7acb\u5e76\u884c\u4fe1\u9053\u63a8\u5bfc\u7684\u3002", "conclusion": "\u901a\u8fc7\u9002\u5f53\u7684\u6392\u5e8f\u538b\u7f29\uff0cCDF-ORBGRAND\u7b97\u6cd5\u4e0d\u4ec5\u80fd\u5728\u4e00\u822c\u4e8c\u8fdb\u5236\u8f93\u5165\u4fe1\u9053\u4e0a\u8fbe\u5230\u5bf9\u79f0\u5bb9\u91cf\uff0c\u8fd8\u80fd\u6709\u6548\u5904\u7406\u9ad8\u9636\u8c03\u5236\u7cfb\u7edf\uff0c\u5b9e\u73b0BICM\u5bb9\u91cf\uff0c\u4e3a\u5b9e\u9645\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u7801\u65b9\u6848\u3002"}}
{"id": "2512.01454", "categories": ["cs.IT", "cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.01454", "abs": "https://arxiv.org/abs/2512.01454", "authors": ["Jiping Luo", "Bowen Li", "Nikolaos Pappas"], "title": "Value of Communication in Goal-Oriented Semantic Communications: A Pareto Analysis", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Emerging cyber-physical systems increasingly operate under stringent communication constraints that preclude the reliable transmission of their extensive machine-type data streams. Since raw measurements often contain correlated or redundant components, effective operation depends not on transmitting all available data but on selecting the information that contributes to achieving the objectives of the system. Beyond accuracy, goal-oriented semantic communication assesses the \\emph{value of information} and aims to generate and transmit only what is relevant and at the right time. Motivated by this perspective, this work studies the \\emph{value of communication} through the canonical setting of remote estimation of Markov sources, where a value-of-information measure quantifies the relevance of information. We investigate how optimal estimation performance varies with the available communication budget and determine the marginal performance gain attributable to additional communication. Our approach is based on a \\emph{Pareto analysis} that characterizes the complete set of policies that achieve optimal trade-offs between estimation performance and communication cost. The value of communication is defined as the absolute slope of the resulting Pareto frontier. Although computing this frontier is non-trivial, we demonstrate that in our setting it admits a notably tractable structure: it is strictly decreasing, convex, and piecewise linear, and its slope is governed by a finite collection of constants. Moreover, each Pareto-optimal operating point is realizable as a convex combination of two stationary deterministic policies, enabling practical implementation. Leveraging these structural insights, we introduce SPLIT, an efficient and provably optimal algorithm for constructing the complete Pareto frontier.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u901a\u4fe1\u7ea6\u675f\u4e0b\u8fdc\u7a0b\u4f30\u8ba1\u9a6c\u5c14\u53ef\u592b\u6e90\u65f6\u7684\u901a\u4fe1\u4ef7\u503c\uff0c\u901a\u8fc7\u5e15\u7d2f\u6258\u524d\u6cbf\u5206\u6790\u6700\u4f18\u4f30\u8ba1\u6027\u80fd\u4e0e\u901a\u4fe1\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u7b97\u6cd5SPLIT\u6784\u5efa\u5b8c\u6574\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u65b0\u5174\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u5728\u4e25\u683c\u901a\u4fe1\u7ea6\u675f\u4e0b\u8fd0\u884c\uff0c\u65e0\u6cd5\u53ef\u9760\u4f20\u8f93\u5927\u91cf\u673a\u5668\u7c7b\u578b\u6570\u636e\u6d41\u3002\u7531\u4e8e\u539f\u59cb\u6d4b\u91cf\u503c\u5e38\u5305\u542b\u76f8\u5173\u6216\u5197\u4f59\u6210\u5206\uff0c\u6709\u6548\u8fd0\u884c\u4e0d\u4f9d\u8d56\u4e8e\u4f20\u8f93\u6240\u6709\u6570\u636e\uff0c\u800c\u662f\u9009\u62e9\u6709\u52a9\u4e8e\u5b9e\u73b0\u7cfb\u7edf\u76ee\u6807\u7684\u4fe1\u606f\u3002\u8d85\u8d8a\u51c6\u786e\u6027\uff0c\u9762\u5411\u76ee\u6807\u7684\u8bed\u4e49\u901a\u4fe1\u8bc4\u4f30\u4fe1\u606f\u4ef7\u503c\uff0c\u65e8\u5728\u4ec5\u751f\u6210\u548c\u4f20\u8f93\u76f8\u5173\u4e14\u9002\u65f6\u7684\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u5e15\u7d2f\u6258\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u8fdc\u7a0b\u4f30\u8ba1\u9a6c\u5c14\u53ef\u592b\u6e90\u7684\u901a\u4fe1\u4ef7\u503c\u3002\u901a\u8fc7\u4fe1\u606f\u4ef7\u503c\u5ea6\u91cf\u91cf\u5316\u4fe1\u606f\u76f8\u5173\u6027\uff0c\u5206\u6790\u6700\u4f18\u4f30\u8ba1\u6027\u80fd\u5982\u4f55\u968f\u53ef\u7528\u901a\u4fe1\u9884\u7b97\u53d8\u5316\uff0c\u5e76\u786e\u5b9a\u989d\u5916\u901a\u4fe1\u5e26\u6765\u7684\u8fb9\u9645\u6027\u80fd\u589e\u76ca\u3002\u8bc1\u660e\u5e15\u7d2f\u6258\u524d\u6cbf\u5177\u6709\u4e25\u683c\u9012\u51cf\u3001\u51f8\u4e14\u5206\u6bb5\u7ebf\u6027\u7684\u7ed3\u6784\uff0c\u6bcf\u4e2a\u5e15\u7d2f\u6258\u6700\u4f18\u64cd\u4f5c\u70b9\u53ef\u5b9e\u73b0\u4e3a\u4e24\u4e2a\u5e73\u7a33\u786e\u5b9a\u6027\u7b56\u7565\u7684\u51f8\u7ec4\u5408\u3002", "result": "\u901a\u4fe1\u4ef7\u503c\u5b9a\u4e49\u4e3a\u5e15\u7d2f\u6258\u524d\u6cbf\u7684\u7edd\u5bf9\u659c\u7387\u3002\u5728\u8be5\u8bbe\u7f6e\u4e2d\uff0c\u5e15\u7d2f\u6258\u524d\u6cbf\u5177\u6709\u663e\u8457\u6613\u5904\u7406\u7684\u7ed3\u6784\uff1a\u4e25\u683c\u9012\u51cf\u3001\u51f8\u4e14\u5206\u6bb5\u7ebf\u6027\uff0c\u5176\u659c\u7387\u7531\u6709\u9650\u5e38\u6570\u96c6\u5408\u63a7\u5236\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7ed3\u6784\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e86SPLIT\u7b97\u6cd5\uff0c\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u8bc1\u660e\u6700\u4f18\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u5b8c\u6574\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u5e15\u7d2f\u6258\u5206\u6790\u6846\u67b6\u91cf\u5316\u4e86\u901a\u4fe1\u7ea6\u675f\u4e0b\u8fdc\u7a0b\u4f30\u8ba1\u7684\u901a\u4fe1\u4ef7\u503c\uff0c\u63ed\u793a\u4e86\u5e15\u7d2f\u6258\u524d\u6cbf\u7684\u6613\u5904\u7406\u6570\u5b66\u7ed3\u6784\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7b97\u6cd5\u5de5\u5177SPLIT\u6765\u5b9e\u73b0\u6700\u4f18\u6743\u8861\u7b56\u7565\uff0c\u4e3a\u9762\u5411\u76ee\u6807\u7684\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u73b0\u65b9\u6cd5\u3002"}}
{"id": "2512.00193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00193", "abs": "https://arxiv.org/abs/2512.00193", "authors": ["Anson Ho", "Jean-Stanislas Denain", "David Atanasov", "Samuel Albanie", "Rohin Shah"], "title": "A Rosetta Stone for AI Benchmarks", "comment": null, "summary": "Most AI benchmarks saturate within years or even months after they are introduced, making it hard to study long-run trends in AI capabilities. To address this challenge, we build a statistical framework that stitches benchmarks together, putting model capabilities and benchmark difficulties on a single numerical scale. This acts as a \"Rosetta Stone\", allowing us to compare models across a wide range of abilities and time, even if they are not evaluated on the same benchmarks. Moreover, this works without assuming how capabilities evolve across time or with training compute. We demonstrate three applications of this framework. First, we use it to measure the speed of AI progress over time, and to forecast future AI capabilities. Second, we estimate the rate of improvements in algorithmic efficiency, finding estimates that are higher, but broadly consistent with prior work. Finally, we find that our approach can be used to detect rapid accelerations in AI progress.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u8ba1\u6846\u67b6\uff0c\u5c06\u4e0d\u540cAI\u57fa\u51c6\u6d4b\u8bd5\u8fde\u63a5\u8d77\u6765\uff0c\u5728\u5355\u4e00\u6570\u503c\u5c3a\u5ea6\u4e0a\u8861\u91cf\u6a21\u578b\u80fd\u529b\u548c\u57fa\u51c6\u96be\u5ea6\uff0c\u5b9e\u73b0\u8de8\u65f6\u95f4\u548c\u8de8\u57fa\u51c6\u7684AI\u80fd\u529b\u6bd4\u8f83", "motivation": "\u5927\u591a\u6570AI\u57fa\u51c6\u6d4b\u8bd5\u5728\u63a8\u51fa\u540e\u51e0\u5e74\u751a\u81f3\u51e0\u4e2a\u6708\u5185\u5c31\u4f1a\u9971\u548c\uff0c\u96be\u4ee5\u7814\u7a76AI\u80fd\u529b\u7684\u957f\u671f\u8d8b\u52bf\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e0d\u540c\u65f6\u95f4\u3001\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0b\u7684\u6a21\u578b\u80fd\u529b", "method": "\u6784\u5efa\u7edf\u8ba1\u6846\u67b6\uff0c\u5c06\u6a21\u578b\u80fd\u529b\u548c\u57fa\u51c6\u6d4b\u8bd5\u96be\u5ea6\u6620\u5c04\u5230\u540c\u4e00\u6570\u503c\u5c3a\u5ea6\u4e0a\uff0c\u5f62\u6210\"\u7f57\u585e\u5854\u77f3\u7891\"\uff0c\u65e0\u9700\u5047\u8bbe\u80fd\u529b\u968f\u65f6\u95f4\u6216\u8bad\u7ec3\u8ba1\u7b97\u91cf\u7684\u6f14\u53d8\u65b9\u5f0f", "result": "\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u57fa\u51c6\u548c\u8de8\u65f6\u95f4\u7684\u6a21\u578b\u80fd\u529b\u6bd4\u8f83\uff0c\u80fd\u591f\u6d4b\u91cfAI\u8fdb\u5c55\u901f\u5ea6\u3001\u9884\u6d4b\u672a\u6765\u80fd\u529b\u3001\u4f30\u8ba1\u7b97\u6cd5\u6548\u7387\u6539\u8fdb\u7387\uff0c\u5e76\u80fd\u68c0\u6d4bAI\u8fdb\u5c55\u7684\u5feb\u901f\u52a0\u901f", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3AI\u57fa\u51c6\u6d4b\u8bd5\u9971\u548c\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u7cfb\u7edf\u7814\u7a76AI\u80fd\u529b\u7684\u957f\u671f\u8d8b\u52bf\uff0c\u4e3aAI\u8fdb\u5c55\u6d4b\u91cf\u548c\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2512.00161", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00161", "abs": "https://arxiv.org/abs/2512.00161", "authors": ["Ram Ramanathan", "Dmitrii Dugaev", "Liang Tan", "Warren Ramanathan"], "title": "Mesh Augmentation of LoRaWAN-based IoT Networks", "comment": null, "summary": "LoRaWAN is a leading standard and technology for low-power, long-range Internet-of-Things (IoT) communications. However, its single-hop architecture results in limited effective range and excessive power consumption for end devices, especially when deployed in large, remote and RF-challenged environments. Existing solutions are either incompatible with LoRaWAN, or limit relaying to a single hop. We present LIMA, a protocol for augmenting an existing or new LoRaWAN deployment with a mesh network of LIMA Routers. LIMA increases the effective coverage range well beyond the maximum LoRa range via multi-hopping, and significantly reduces the energy consumed by end-devices. LIMA requires no changes to the end-device, the servers or the LoRaWAN standard. LIMA builds routes using reverse path forwarding, tunnels LoRaWAN messages over LIMA, provides transparent extension of the existing Adaptive Data Rate (ADR), and suppresses duplicate forwarding if the device is directly reachable from the Gateway. Simulations using Network Simulator 3 (ns-3) show that LIMA increases the delivery rate, scalability, ED energy consumption by up to 5x, 8x and 12.6x respectively, and reduces latency by up to 2.3x. Table-top and outdoor testing with a prototype constructed using a commercial gateway as a starting point confirm that LIMA can be successfully deployed within an existing LoRaWAN system, and can provide range and energy gains transparently.", "AI": {"tldr": "LIMA\u534f\u8bae\u901a\u8fc7\u591a\u8df3\u7f51\u72b6\u7f51\u7edc\u6269\u5c55LoRaWAN\u8986\u76d6\u8303\u56f4\u5e76\u964d\u4f4e\u7ec8\u7aef\u8bbe\u5907\u80fd\u8017\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u8bbe\u5907\u548c\u6807\u51c6\u3002", "motivation": "LoRaWAN\u7684\u5355\u8df3\u67b6\u6784\u5728\u5927\u578b\u3001\u504f\u8fdc\u548c\u5c04\u9891\u6311\u6218\u73af\u5883\u4e2d\u5b58\u5728\u8986\u76d6\u8303\u56f4\u6709\u9650\u548c\u7ec8\u7aef\u8bbe\u5907\u80fd\u8017\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u4e0d\u517c\u5bb9LoRaWAN\uff0c\u8981\u4e48\u4ec5\u9650\u4e8e\u5355\u8df3\u4e2d\u7ee7\u3002", "method": "LIMA\u901a\u8fc7LIMA\u8def\u7531\u5668\u6784\u5efa\u7f51\u72b6\u7f51\u7edc\uff0c\u4f7f\u7528\u53cd\u5411\u8def\u5f84\u8f6c\u53d1\u5efa\u7acb\u8def\u7531\uff0c\u901a\u8fc7LIMA\u96a7\u9053\u4f20\u8f93LoRaWAN\u6d88\u606f\uff0c\u900f\u660e\u6269\u5c55\u81ea\u9002\u5e94\u6570\u636e\u901f\u7387(ADR)\uff0c\u5e76\u5728\u8bbe\u5907\u53ef\u76f4\u63a5\u4ece\u7f51\u5173\u8bbf\u95ee\u65f6\u6291\u5236\u91cd\u590d\u8f6c\u53d1\u3002", "result": "NS-3\u6a21\u62df\u663e\u793aLIMA\u5c06\u6295\u9012\u7387\u3001\u53ef\u6269\u5c55\u6027\u3001\u7ec8\u7aef\u8bbe\u5907\u80fd\u8017\u5206\u522b\u63d0\u5347\u9ad8\u8fbe5\u500d\u30018\u500d\u548c12.6\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e2.3\u500d\u3002\u539f\u578b\u6d4b\u8bd5\u8bc1\u5b9eLIMA\u53ef\u5728\u73b0\u6709LoRaWAN\u7cfb\u7edf\u4e2d\u6210\u529f\u90e8\u7f72\u3002", "conclusion": "LIMA\u534f\u8bae\u80fd\u591f\u663e\u8457\u63d0\u5347LoRaWAN\u7684\u8986\u76d6\u8303\u56f4\u548c\u80fd\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709\u8bbe\u5907\u548c\u6807\u51c6\u7684\u5b8c\u5168\u517c\u5bb9\u6027\uff0c\u4e3a\u7269\u8054\u7f51\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u589e\u5f3a\u65b9\u6848\u3002"}}
{"id": "2512.00378", "categories": ["cs.IT", "cs.DS", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00378", "abs": "https://arxiv.org/abs/2512.00378", "authors": ["Nikit Phadke"], "title": "The Information Theory of Similarity", "comment": null, "summary": "We establish a precise mathematical equivalence between witness-based similarity systems (REWA) and Shannon's information theory. We prove that witness overlap is mutual information, that REWA bit complexity bounds arise from channel capacity limitations, and that ranking-preserving encodings obey rate-distortion constraints. This unification reveals that fifty years of similarity search research -- from Bloom filters to locality-sensitive hashing to neural retrieval -- implicitly developed information theory for relational data. We derive fundamental lower bounds showing that REWA's $O(\u0394^{-2} \\log N)$ complexity is optimal: no encoding scheme can preserve similarity rankings with fewer bits. The framework establishes that semantic similarity has physical units (bits of mutual information), search is communication (query transmission over a noisy channel), and retrieval systems face fundamental capacity limits analogous to Shannon's channel coding theorem.", "AI": {"tldr": "\u8bba\u6587\u5efa\u7acb\u4e86\u89c1\u8bc1\u76f8\u4f3c\u6027\u7cfb\u7edf\uff08REWA\uff09\u4e0e\u9999\u519c\u4fe1\u606f\u8bba\u4e4b\u95f4\u7684\u7cbe\u786e\u6570\u5b66\u7b49\u4ef7\u5173\u7cfb\uff0c\u8bc1\u660e\u89c1\u8bc1\u91cd\u53e0\u662f\u4e92\u4fe1\u606f\uff0cREWA\u6bd4\u7279\u590d\u6742\u5ea6\u6e90\u4e8e\u4fe1\u9053\u5bb9\u91cf\u9650\u5236\uff0c\u6392\u5e8f\u4fdd\u6301\u7f16\u7801\u9075\u5faa\u7387\u5931\u771f\u7ea6\u675f\u3002", "motivation": "\u7edf\u4e00\u4e94\u5341\u5e74\u7684\u76f8\u4f3c\u6027\u641c\u7d22\u7814\u7a76\uff08\u4ece\u5e03\u9686\u8fc7\u6ee4\u5668\u5230\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u518d\u5230\u795e\u7ecf\u68c0\u7d22\uff09\uff0c\u63ed\u793a\u8fd9\u4e9b\u65b9\u6cd5\u5b9e\u9645\u4e0a\u662f\u5728\u4e3a\u5173\u7cfb\u6570\u636e\u5f00\u53d1\u4fe1\u606f\u8bba\uff0c\u4e3a\u8bed\u4e49\u76f8\u4f3c\u6027\u5efa\u7acb\u7269\u7406\u5355\u4f4d\uff08\u4e92\u4fe1\u606f\u6bd4\u7279\uff09\u3002", "method": "\u5efa\u7acbREWA\u4e0e\u9999\u519c\u4fe1\u606f\u8bba\u7684\u7cbe\u786e\u6570\u5b66\u7b49\u4ef7\uff0c\u8bc1\u660e\u89c1\u8bc1\u91cd\u53e0\u7b49\u4e8e\u4e92\u4fe1\u606f\uff0c\u63a8\u5bfcREWA\u6bd4\u7279\u590d\u6742\u5ea6\u4e0e\u4fe1\u9053\u5bb9\u91cf\u7684\u5173\u7cfb\uff0c\u5206\u6790\u6392\u5e8f\u4fdd\u6301\u7f16\u7801\u7684\u7387\u5931\u771f\u7ea6\u675f\u3002", "result": "\u8bc1\u660e\u4e86REWA\u7684O(\u0394^{-2} log N)\u590d\u6742\u5ea6\u662f\u6700\u4f18\u7684\uff1a\u6ca1\u6709\u4efb\u4f55\u7f16\u7801\u65b9\u6848\u80fd\u7528\u66f4\u5c11\u7684\u6bd4\u7279\u4fdd\u6301\u76f8\u4f3c\u6027\u6392\u5e8f\u3002\u63ed\u793a\u4e86\u76f8\u4f3c\u6027\u641c\u7d22\u672c\u8d28\u4e0a\u662f\u901a\u4fe1\uff08\u901a\u8fc7\u566a\u58f0\u4fe1\u9053\u4f20\u8f93\u67e5\u8be2\uff09\uff0c\u68c0\u7d22\u7cfb\u7edf\u9762\u4e34\u4e0e\u9999\u519c\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\u7c7b\u4f3c\u7684\u57fa\u672c\u5bb9\u91cf\u9650\u5236\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u7269\u7406\u5355\u4f4d\uff08\u4e92\u4fe1\u606f\u6bd4\u7279\uff09\uff0c\u641c\u7d22\u5373\u901a\u4fe1\uff08\u67e5\u8be2\u5728\u566a\u58f0\u4fe1\u9053\u4e0a\u7684\u4f20\u8f93\uff09\uff0c\u68c0\u7d22\u7cfb\u7edf\u9762\u4e34\u4e0e\u9999\u519c\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\u7c7b\u4f3c\u7684\u57fa\u672c\u5bb9\u91cf\u9650\u5236\uff0c\u7edf\u4e00\u4e86\u4e94\u5341\u5e74\u7684\u76f8\u4f3c\u6027\u641c\u7d22\u7814\u7a76\u3002"}}
{"id": "2512.00218", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.00218", "abs": "https://arxiv.org/abs/2512.00218", "authors": ["Matt MacDermott", "Qiyao Wei", "Rada Djoneva", "Francis Rhys Ward"], "title": "Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?", "comment": null, "summary": "AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \\emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \\emph{training incentives}, applied to a reasoning model, affect its monitorability. We introduce a novel methodology for measuring monitorability according to whether a monitor can predict a key latent variable using the model's reasoning. When controlling for accuracy, we do not find evidence for consistent effects from commonly used incentives (length penalties and KL regularisation), but we find that adversarial optimisation (penalising monitor accuracy) degrades monitor performance, while direct optimisation for monitorability does not reliably lead to improvements. Our code is available at https://github.com/QiyaoWei/reasoning-under-pressure.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u6fc0\u52b1\u5bf9AI\u63a8\u7406\u8fc7\u7a0b\u53ef\u76d1\u63a7\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5bf9\u6297\u6027\u4f18\u5316\u4f1a\u964d\u4f4e\u76d1\u63a7\u6027\u80fd\uff0c\u800c\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\u5e76\u4e0d\u603b\u80fd\u5e26\u6765\u6539\u8fdb", "motivation": "AI\u7cfb\u7edf\u8f93\u51fa\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u8fc7\u7a0b\u4e3a\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u662f\u5426\u5fe0\u5b9e\u53cd\u6620\u5e95\u5c42\u601d\u7ef4\u4ee5\u53ca\u53ef\u76d1\u63a7\u7a0b\u5ea6\u53ef\u80fd\u53d7\u8bad\u7ec3\u65b9\u5f0f\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u6fc0\u52b1\u5982\u4f55\u5f71\u54cd\u76d1\u63a7\u80fd\u529b", "method": "\u63d0\u51fa\u6d4b\u91cf\u53ef\u76d1\u63a7\u6027\u7684\u65b0\u65b9\u6cd5\uff1a\u901a\u8fc7\u76d1\u63a7\u5668\u80fd\u5426\u4f7f\u7528\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u9884\u6d4b\u5173\u952e\u6f5c\u5728\u53d8\u91cf\u6765\u8bc4\u4f30\uff1b\u5b9e\u9a8c\u6bd4\u8f83\u4e0d\u540c\u8bad\u7ec3\u6fc0\u52b1\uff08\u957f\u5ea6\u60e9\u7f5a\u3001KL\u6b63\u5219\u5316\u3001\u5bf9\u6297\u6027\u4f18\u5316\u3001\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\uff09\u7684\u6548\u679c", "result": "\u5728\u63a7\u5236\u51c6\u786e\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u5e38\u89c1\u6fc0\u52b1\uff08\u957f\u5ea6\u60e9\u7f5a\u548cKL\u6b63\u5219\u5316\uff09\u6ca1\u6709\u4e00\u81f4\u5f71\u54cd\uff1b\u5bf9\u6297\u6027\u4f18\u5316\u4f1a\u964d\u4f4e\u76d1\u63a7\u6027\u80fd\uff1b\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\u5e76\u4e0d\u80fd\u53ef\u9760\u5730\u5e26\u6765\u6539\u8fdb", "conclusion": "\u8bad\u7ec3\u6fc0\u52b1\u5bf9AI\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u76d1\u63a7\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5bf9\u6297\u6027\u4f18\u5316\u4f1a\u635f\u5bb3\u76d1\u63a7\u80fd\u529b\uff0c\u800c\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\u5e76\u975e\u53ef\u9760\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7406\u89e3\u8bad\u7ec3\u4e0e\u76d1\u63a7\u4e4b\u95f4\u7684\u5173\u7cfb"}}
{"id": "2512.00211", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00211", "abs": "https://arxiv.org/abs/2512.00211", "authors": ["Gabriele Formis", "Amanda Ericson", "Stefan Forsstrom", "Kyi Thar", "Gianluca Cena", "Stefano Scanzio"], "title": "On the Prediction of Wi-Fi Performance through Deep Learning", "comment": "preprint accepted, 4 pages, 2025", "summary": "Ensuring reliable and predictable communications is one of the main goals in modern industrial systems that rely on Wi-Fi networks, especially in scenarios where continuity of operation and low latency are required. In these contexts, the ability to predict changes in wireless channel quality can enable adaptive strategies and significantly improve system robustness. This contribution focuses on the prediction of the Frame Delivery Ratio (FDR), a key metric that represents the percentage of successful transmissions, starting from time sequences of binary outcomes (success/failure) collected in a real scenario. The analysis focuses on two models of deep learning: a Convolutional Neural Network (CNN) and a Long Short-Term Memory network (LSTM), both selected for their ability to predict the outcome of time sequences. Models are compared in terms of prediction accuracy and computational complexity, with the aim of evaluating their applicability to systems with limited resources. Preliminary results show that both models are able to predict the evolution of the FDR with good accuracy, even from minimal information (a single binary sequence). In particular, CNN shows a significantly lower inference latency, with a marginal loss in accuracy compared to LSTM.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528CNN\u548cLSTM\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9884\u6d4bWi-Fi\u7f51\u7edc\u4e2d\u7684\u5e27\u4f20\u8f93\u6210\u529f\u7387(FDR)\uff0cCNN\u5728\u63a8\u7406\u5ef6\u8fdf\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u7cbe\u5ea6\u635f\u5931\u8f83\u5c0f\u3002", "motivation": "\u73b0\u4ee3\u5de5\u4e1aWi-Fi\u7cfb\u7edf\u9700\u8981\u53ef\u9760\u3001\u53ef\u9884\u6d4b\u7684\u901a\u4fe1\uff0c\u7279\u522b\u662f\u5728\u8981\u6c42\u8fde\u7eed\u8fd0\u884c\u548c\u4f4e\u5ef6\u8fdf\u7684\u573a\u666f\u4e2d\u3002\u9884\u6d4b\u65e0\u7ebf\u4fe1\u9053\u8d28\u91cf\u53d8\u5316\u80fd\u591f\u5b9e\u73b0\u81ea\u9002\u5e94\u7b56\u7565\u5e76\u663e\u8457\u63d0\u9ad8\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc(LSTM)\u4e24\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u57fa\u4e8e\u771f\u5b9e\u573a\u666f\u6536\u96c6\u7684\u4e8c\u8fdb\u5236\u65f6\u95f4\u5e8f\u5217\uff08\u6210\u529f/\u5931\u8d25\uff09\u6765\u9884\u6d4b\u5e27\u4f20\u8f93\u6210\u529f\u7387(FDR)\u3002\u6bd4\u8f83\u4e24\u79cd\u6a21\u578b\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u90fd\u80fd\u4ee5\u826f\u597d\u7cbe\u5ea6\u9884\u6d4bFDR\u6f14\u53d8\uff0c\u5373\u4f7f\u4ec5\u4f7f\u7528\u6700\u5c0f\u4fe1\u606f\uff08\u5355\u4e2a\u4e8c\u8fdb\u5236\u5e8f\u5217\uff09\u3002CNN\u663e\u793a\u51fa\u663e\u8457\u66f4\u4f4e\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u4e0eLSTM\u76f8\u6bd4\u7cbe\u5ea6\u635f\u5931\u8f83\u5c0f\u3002", "conclusion": "CNN\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u4e2d\u66f4\u5177\u5e94\u7528\u6f5c\u529b\uff0c\u56e0\u4e3a\u5b83\u5728\u4fdd\u6301\u826f\u597d\u9884\u6d4b\u7cbe\u5ea6\u7684\u540c\u65f6\u5177\u6709\u66f4\u4f4e\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u66f4\u9002\u5408\u5de5\u4e1aWi-Fi\u7f51\u7edc\u7684\u5b9e\u65f6\u9884\u6d4b\u9700\u6c42\u3002"}}
{"id": "2512.00531", "categories": ["cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00531", "abs": "https://arxiv.org/abs/2512.00531", "authors": ["Saeed Mashdour", "Andr\u00e9 R. Flores", "Rodrigo C. de Lamare"], "title": "Robust Precoding for Resilient Cell-Free Networks", "comment": "2 figures, 6 pages", "summary": "This paper presents a robust precoder design for resilient cell-free massive MIMO (CF-mMIMO) systems that minimizes the weighted sum of desired signal mean square error (MSE) and residual interference leakage power under a total transmit power constraint. The proposed robust precoder incorporates channel state information (CSI) error statistics to enhance resilience against CSI imperfections. We employ an alternating optimization algorithm initialized with a minimum MSE-type solution, which iteratively refines the precoder while maintaining low computational complexity and ensuring fast convergence. Numerical results show that the proposed method significantly outperforms conventional linear precoders, providing an effective balance between performance and computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u5f39\u6027\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u9c81\u68d2\u9884\u7f16\u7801\u5668\u8bbe\u8ba1\uff0c\u5728\u603b\u53d1\u5c04\u529f\u7387\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u671f\u671b\u4fe1\u53f7\u5747\u65b9\u8bef\u5dee\u548c\u6b8b\u4f59\u5e72\u6270\u6cc4\u6f0f\u529f\u7387\u7684\u52a0\u6743\u548c\uff0c\u5229\u7528CSI\u8bef\u5dee\u7edf\u8ba1\u589e\u5f3a\u5bf9\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u7684\u6311\u6218\uff0c\u4f20\u7edf\u7ebf\u6027\u9884\u7f16\u7801\u5668\u5bf9\u6b64\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u5e94\u5bf9CSI\u8bef\u5dee\u7684\u9884\u7f16\u7801\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u7ef4\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51fa\u9c81\u68d2\u9884\u7f16\u7801\u5668\u8bbe\u8ba1\uff0c\u5728\u603b\u53d1\u5c04\u529f\u7387\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u671f\u671b\u4fe1\u53f7\u5747\u65b9\u8bef\u5dee\u548c\u6b8b\u4f59\u5e72\u6270\u6cc4\u6f0f\u529f\u7387\u7684\u52a0\u6743\u548c\uff1b\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\uff0c\u4ee5\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u578b\u89e3\u521d\u59cb\u5316\uff0c\u8fed\u4ee3\u4f18\u5316\u9884\u7f16\u7801\u5668\uff1b\u7b97\u6cd5\u4fdd\u6301\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u786e\u4fdd\u5feb\u901f\u6536\u655b\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7ebf\u6027\u9884\u7f16\u7801\u5668\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6709\u6548\u5e73\u8861\uff0c\u589e\u5f3a\u4e86\u7cfb\u7edf\u5bf9CSI\u4e0d\u5b8c\u7f8e\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u9c81\u68d2\u9884\u7f16\u7801\u5668\u8bbe\u8ba1\u4e3a\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728CSI\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff0c\u540c\u65f6\u7ef4\u6301\u5408\u7406\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2512.00267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00267", "abs": "https://arxiv.org/abs/2512.00267", "authors": ["Anab Maulana Barik", "Shou Ziyi", "Yang Kaiwen", "Yang Qi", "Shen Xin"], "title": "Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking", "comment": null, "summary": "Technological advancement allows information to be shared in just a single click, which has enabled the rapid spread of false information. This makes automated fact-checking system necessary to ensure the safety and integrity of our online media ecosystem. Previous methods have demonstrated the effectiveness of decomposing the claim into simpler sub-tasks and utilizing LLM-based multi agent system to execute them. However, those models faces two limitations: they often fail to verify every component in the claim and lack of structured framework to logically connect the results of sub-tasks for a final prediction. In this work, we propose a novel automated fact-checking framework called Trification. Our framework begins by generating a comprehensive set of verification actions to ensure complete coverage of the claim. It then structured these actions into a dependency graph to model the logical interaction between actions. Furthermore, the graph can be dynamically modified, allowing the system to adapt its verification strategy. Experimental results on two challenging benchmarks demonstrate that our framework significantly enhances fact-checking accuracy, thereby advancing current state-of-the-art in automated fact-checking system.", "AI": {"tldr": "\u63d0\u51faTrification\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5168\u9762\u9a8c\u8bc1\u52a8\u4f5c\u548c\u6784\u5efa\u4f9d\u8d56\u56fe\u6765\u6539\u8fdb\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u9a8c\u8bc1\u6240\u6709\u58f0\u660e\u7ec4\u4ef6\u548c\u7f3a\u4e4f\u7ed3\u6784\u5316\u903b\u8f91\u8fde\u63a5\u7684\u95ee\u9898\u3002", "motivation": "\u6280\u672f\u53d1\u5c55\u4f7f\u865a\u5047\u4fe1\u606f\u5feb\u901f\u4f20\u64ad\uff0c\u9700\u8981\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u6765\u7ef4\u62a4\u5728\u7ebf\u5a92\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u548c\u5b8c\u6574\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u901a\u8fc7\u5206\u89e3\u58f0\u660e\u4e3a\u5b50\u4efb\u52a1\u5e76\u4f7f\u7528LLM\u591a\u4ee3\u7406\u7cfb\u7edf\u6709\u6548\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u5c40\u9650\uff1a\u65e0\u6cd5\u9a8c\u8bc1\u58f0\u660e\u7684\u6bcf\u4e2a\u7ec4\u4ef6\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u7ed3\u6784\u5316\u6846\u67b6\u6765\u903b\u8f91\u8fde\u63a5\u5b50\u4efb\u52a1\u7ed3\u679c\u4ee5\u5f97\u51fa\u6700\u7ec8\u9884\u6d4b\u3002", "method": "\u63d0\u51faTrification\u6846\u67b6\uff1a1) \u751f\u6210\u5168\u9762\u7684\u9a8c\u8bc1\u52a8\u4f5c\u96c6\u4ee5\u786e\u4fdd\u5bf9\u58f0\u660e\u7684\u5b8c\u5168\u8986\u76d6\uff1b2) \u5c06\u8fd9\u4e9b\u52a8\u4f5c\u7ec4\u7ec7\u6210\u4f9d\u8d56\u56fe\u4ee5\u5efa\u6a21\u52a8\u4f5c\u95f4\u7684\u903b\u8f91\u4ea4\u4e92\uff1b3) \u652f\u6301\u52a8\u6001\u4fee\u6539\u56fe\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u8c03\u6574\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u63a8\u8fdb\u4e86\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u6700\u65b0\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "Trification\u6846\u67b6\u901a\u8fc7\u751f\u6210\u5168\u9762\u9a8c\u8bc1\u52a8\u4f5c\u548c\u6784\u5efa\u4f9d\u8d56\u56fe\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e8b\u5b9e\u6838\u67e5\u51c6\u786e\u6027\uff0c\u4e3a\u5728\u7ebf\u5a92\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6280\u672f\u4fdd\u969c\u3002"}}
{"id": "2512.00221", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00221", "abs": "https://arxiv.org/abs/2512.00221", "authors": ["Stefano Scanzio", "Pietro Chiavassa", "Gianluca Cena"], "title": "Analysis of the operation of a TSN switch and other devices using executable QR codes", "comment": "preprint accepted, 2 pages, 2025", "summary": "Executable QR codes, also known as sQRy, are a technology aimed at inserting executable programs in a QR code. Through a concrete example, in this paper, we demonstrate their usage in the context of industrial networks in order to assess the operation of a TSN switch by analyzing its status LEDs even in the absence of an internet connection. The entire generation chain that is used to create the sQRy, as well as the corresponding execution chain that, starting from the sQRy, runs it on a mobile device, has been detailed through examples.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u53ef\u6267\u884cQR\u7801\uff08sQRy\uff09\u6280\u672f\uff0c\u901a\u8fc7\u5177\u4f53\u6848\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u5728\u5de5\u4e1a\u7f51\u7edc\u73af\u5883\u4e2d\u5229\u7528\u8be5\u6280\u672f\u8bc4\u4f30TSN\u4ea4\u6362\u673a\u7684\u8fd0\u884c\u72b6\u6001\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u7f51\u7edc\u8fde\u63a5\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5206\u6790\u5176\u72b6\u6001LED\u3002", "motivation": "\u5728\u5de5\u4e1a\u7f51\u7edc\u73af\u5883\u4e2d\uff0c\u5f53\u7f3a\u4e4f\u4e92\u8054\u7f51\u8fde\u63a5\u65f6\uff0c\u6280\u672f\u4eba\u5458\u9700\u8981\u4e00\u79cd\u4fbf\u6377\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30TSN\u4ea4\u6362\u673a\u7684\u8fd0\u884c\u72b6\u6001\u3002\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u53d7\u9650\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u4e0d\u4f9d\u8d56\u7f51\u7edc\u8fde\u63a5\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u53ef\u6267\u884cQR\u7801\uff08sQRy\uff09\u6280\u672f\uff0c\u8be6\u7ec6\u63cf\u8ff0\u4e86\u4ece\u751f\u6210\u53ef\u6267\u884cQR\u7801\u7684\u5b8c\u6574\u751f\u6210\u94fe\uff0c\u5230\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u6267\u884c\u8be5\u4ee3\u7801\u7684\u5b8c\u6574\u6267\u884c\u94fe\u3002\u901a\u8fc7\u5177\u4f53\u793a\u4f8b\u5c55\u793a\u4e86\u6574\u4e2a\u6280\u672f\u6d41\u7a0b\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86sQRy\u6280\u672f\u5728\u5de5\u4e1a\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u80fd\u591f\u901a\u8fc7\u5206\u6790TSN\u4ea4\u6362\u673a\u7684\u72b6\u6001LED\u6765\u8bc4\u4f30\u5176\u8fd0\u884c\u72b6\u6001\uff0c\u5373\u4f7f\u5728\u65e0\u7f51\u7edc\u8fde\u63a5\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6b63\u5e38\u5de5\u4f5c\u3002", "conclusion": "\u53ef\u6267\u884cQR\u7801\u6280\u672f\u4e3a\u5de5\u4e1a\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u8bbe\u5907\u72b6\u6001\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7f3a\u4e4f\u7f51\u7edc\u8fde\u63a5\u7684\u573a\u666f\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.00711", "categories": ["cs.IT", "cs.DC", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.00711", "abs": "https://arxiv.org/abs/2512.00711", "authors": ["Loc X. Nguyen", "Ji Su Yoon", "Huy Q. Le", "Yu Qiao", "Avi Deb Raha", "Eui-Nam Huh", "Walid Saad", "Dusit Niyato", "Zhu Han", "Choong Seon Hong"], "title": "Cross-Domain Federated Semantic Communication with Global Representation Alignment and Domain-Aware Aggregation", "comment": "13 pages, 7 figures, 6 tables", "summary": "Semantic communication can significantly improve bandwidth utilization in wireless systems by exploiting the meaning behind raw data. However, the advancements achieved through semantic communication are closely dependent on the development of deep learning (DL) models for joint source-channel coding (JSCC) encoder/decoder techniques, which require a large amount of data for training. To address this data-intensive nature of DL models, federated learning (FL) has been proposed to train a model in a distributed manner, where the server broadcasts the DL model to clients in the network for training with their local data. However, the conventional FL approaches suffer from catastrophic degradation when client data are from different domains. In contrast, in this paper, a novel FL framework is proposed to address this domain shift by constructing the global representation, which aligns with the local features of the clients to preserve the semantics of different data domains. In addition, the dominance problem of client domains with a large number of samples is identified and, then, addressed with a domain-aware aggregation approach. This work is the first to consider the domain shift in training the semantic communication system for the image reconstruction task. Finally, simulation results demonstrate that the proposed approach outperforms the model-contrastive FL (MOON) framework by 0.5 for PSNR values under three domains at an SNR of 1 dB, and this gap continues to widen as the channel quality improves.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6765\u89e3\u51b3\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e2d\u4e0d\u540c\u6570\u636e\u57df\u95f4\u7684\u57df\u504f\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u5168\u5c40\u8868\u793a\u6765\u5bf9\u9f50\u5ba2\u6237\u7aef\u672c\u5730\u7279\u5f81\uff0c\u5e76\u91c7\u7528\u57df\u611f\u77e5\u805a\u5408\u65b9\u6cd5\u89e3\u51b3\u6837\u672c\u6570\u91cf\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u8bed\u4e49\u901a\u4fe1\u4f9d\u8d56\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u8054\u5408\u4fe1\u6e90\u4fe1\u9053\u7f16\u7801\uff0c\u4f46\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002\u8054\u90a6\u5b66\u4e60\u53ef\u4ee5\u5206\u5e03\u5f0f\u8bad\u7ec3\u6a21\u578b\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u5ba2\u6237\u7aef\u6570\u636e\u6765\u81ea\u4e0d\u540c\u57df\u65f6\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u89e3\u51b3\u57df\u504f\u79fb\u548c\u6837\u672c\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff1a1) \u6784\u5efa\u5168\u5c40\u8868\u793a\u6765\u5bf9\u9f50\u5ba2\u6237\u7aef\u672c\u5730\u7279\u5f81\uff0c\u4fdd\u6301\u4e0d\u540c\u6570\u636e\u57df\u7684\u8bed\u4e49\uff1b2) \u91c7\u7528\u57df\u611f\u77e5\u805a\u5408\u65b9\u6cd5\u89e3\u51b3\u6837\u672c\u6570\u91cf\u591a\u7684\u5ba2\u6237\u7aef\u57df\u4e3b\u5bfc\u95ee\u9898\u3002", "result": "\u5728\u56fe\u50cf\u91cd\u5efa\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u57281dB\u4fe1\u566a\u6bd4\u4e0b\u6bd4MOON\u6846\u67b6\u7684PSNR\u503c\u9ad8\u51fa0.5\uff0c\u4e14\u968f\u7740\u4fe1\u9053\u8d28\u91cf\u6539\u5584\uff0c\u6027\u80fd\u5dee\u8ddd\u8fdb\u4e00\u6b65\u6269\u5927\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u8003\u8651\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u8bad\u7ec3\u4e2d\u57df\u504f\u79fb\u95ee\u9898\u7684\u5de5\u4f5c\uff0c\u63d0\u51fa\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u4e0d\u540c\u6570\u636e\u57df\u548c\u6837\u672c\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.00305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00305", "abs": "https://arxiv.org/abs/2512.00305", "authors": ["Zhengzhuo Xu", "SiNan Du", "Yiyan Qi", "SiwenLu", "Chengjin Xu", "Chun Yuan", "Jian Guo"], "title": "ChartPoint: Guiding MLLMs with Grounding Reflection for Chart Reasoning", "comment": "Accepted by ICCV 2025", "summary": "Multimodal Large Language Models (MLLMs) have emerged as powerful tools for chart comprehension. However, they heavily rely on extracted content via OCR, which leads to numerical hallucinations when chart textual annotations are sparse. While existing methods focus on scaling instructions, they fail to address the fundamental challenge, i.e., reasoning with visual perception. In this paper, we identify a critical observation: MLLMs exhibit weak grounding in chart elements and proportional relationships, as evidenced by their inability to localize key positions to match their reasoning. To bridge this gap, we propose PointCoT, which integrates reflective interaction into chain-of-thought reasoning in charts. By prompting MLLMs to generate bounding boxes and re-render charts based on location annotations, we establish connections between textual reasoning steps and visual grounding regions. We further introduce an automated pipeline to construct ChartPoint-SFT-62k, a dataset featuring 19.2K high-quality chart samples with step-by-step CoT, bounding box, and re-rendered visualizations. Leveraging this data, we develop two instruction-tuned models, ChartPointQ2 and ChartPointQ2.5, which outperform state-of-the-art across several chart benchmarks, e.g., +5.04\\% on ChartBench.", "AI": {"tldr": "\u63d0\u51faPointCoT\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fb9\u754c\u6846\u751f\u6210\u548c\u56fe\u8868\u91cd\u7ed8\uff0c\u5c06\u89c6\u89c9\u611f\u77e5\u878d\u5165\u56fe\u8868\u63a8\u7406\uff0c\u89e3\u51b3MLLMs\u5728\u56fe\u8868\u7406\u89e3\u4e2d\u7684\u6570\u503c\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709MLLMs\u4f9d\u8d56OCR\u63d0\u53d6\u5185\u5bb9\uff0c\u5f53\u56fe\u8868\u6587\u672c\u6807\u6ce8\u7a00\u758f\u65f6\u4f1a\u4ea7\u751f\u6570\u503c\u5e7b\u89c9\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6307\u4ee4\u6269\u5c55\uff0c\u672a\u80fd\u89e3\u51b3\u89c6\u89c9\u611f\u77e5\u63a8\u7406\u7684\u6839\u672c\u6311\u6218\u3002", "method": "\u63d0\u51faPointCoT\u65b9\u6cd5\uff0c\u5c06\u53cd\u601d\u6027\u4ea4\u4e92\u878d\u5165\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u901a\u8fc7\u751f\u6210\u8fb9\u754c\u6846\u548c\u57fa\u4e8e\u4f4d\u7f6e\u6807\u6ce8\u91cd\u7ed8\u56fe\u8868\uff0c\u5efa\u7acb\u6587\u672c\u63a8\u7406\u6b65\u9aa4\u4e0e\u89c6\u89c9\u57fa\u7840\u533a\u57df\u7684\u8fde\u63a5\u3002\u6784\u5efaChartPoint-SFT-62k\u6570\u636e\u96c6\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u56fe\u8868\u6837\u672c\u53ca\u9010\u6b65CoT\u3001\u8fb9\u754c\u6846\u548c\u91cd\u7ed8\u53ef\u89c6\u5316\u3002", "result": "\u5f00\u53d1\u4e86\u4e24\u4e2a\u6307\u4ee4\u8c03\u4f18\u6a21\u578bChartPointQ2\u548cChartPointQ2.5\uff0c\u5728\u591a\u4e2a\u56fe\u8868\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5982\u5728ChartBench\u4e0a\u63d0\u53475.04%\u3002", "conclusion": "PointCoT\u901a\u8fc7\u89c6\u89c9\u611f\u77e5\u589e\u5f3a\u7684\u63a8\u7406\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MLLMs\u5728\u56fe\u8868\u7406\u89e3\u4e2d\u7684\u6570\u503c\u5e7b\u89c9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u8868\u7406\u89e3\u6027\u80fd\u3002"}}
{"id": "2512.00259", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00259", "abs": "https://arxiv.org/abs/2512.00259", "authors": ["Diogo Ferreira", "Pedro Ribeiro", "Andr\u00e9 Coelho", "Rui Campos"], "title": "Design and Evaluation of a Multi-Agent Perception System for Autonomous Flying Networks", "comment": null, "summary": "Autonomous Flying Networks (FNs) are emerging as a key enabler of on-demand connectivity in dynamic and infrastructure-limited environments. However, current approaches mainly focus on UAV placement, routing, and resource management, neglecting the autonomous perception of users and their service demands - a critical capability for zero-touch network operation.\n  This paper presents the Multi-Agent Perception System (MAPS), a modular and scalable system that leverages multi-modal large language models (MM-LLMs) and agentic Artificial Intelligence (AI) to interpret visual and audio data collected by UAVs and generate Service Level Specifications (SLSs) describing user count, spatial distribution, and traffic demand. MAPS is evaluated using a synthetic multimodal emergency dataset, achieving user detection accuracies above 70% and SLS generation under 130 seconds in 90% of cases. Results demonstrate that combining audio and visual modalities enhances user detection and show that MAPS provides the perception layer required for autonomous, zero-touch FNs.", "AI": {"tldr": "MAPS\u7cfb\u7edf\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\uff0c\u901a\u8fc7\u65e0\u4eba\u673a\u6536\u96c6\u7684\u89c6\u89c9\u548c\u97f3\u9891\u6570\u636e\u611f\u77e5\u7528\u6237\u9700\u6c42\uff0c\u81ea\u52a8\u751f\u6210\u670d\u52a1\u7b49\u7ea7\u89c4\u8303\uff0c\u4e3a\u81ea\u4e3b\u98de\u884c\u7f51\u7edc\u63d0\u4f9b\u611f\u77e5\u5c42\u652f\u6301\u3002", "motivation": "\u5f53\u524d\u81ea\u4e3b\u98de\u884c\u7f51\u7edc\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u65e0\u4eba\u673a\u90e8\u7f72\u3001\u8def\u7531\u548c\u8d44\u6e90\u7ba1\u7406\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7528\u6237\u53ca\u5176\u670d\u52a1\u9700\u6c42\u7684\u81ea\u4e3b\u611f\u77e5\u80fd\u529b\uff0c\u8fd9\u662f\u5b9e\u73b0\u96f6\u63a5\u89e6\u7f51\u7edc\u64cd\u4f5c\u7684\u5173\u952e\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u611f\u77e5\u7cfb\u7edf(MAPS)\uff0c\u91c7\u7528\u6a21\u5757\u5316\u53ef\u6269\u5c55\u67b6\u6784\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u6280\u672f\uff0c\u89e3\u6790\u65e0\u4eba\u673a\u6536\u96c6\u7684\u89c6\u89c9\u548c\u97f3\u9891\u6570\u636e\uff0c\u81ea\u52a8\u751f\u6210\u63cf\u8ff0\u7528\u6237\u6570\u91cf\u3001\u7a7a\u95f4\u5206\u5e03\u548c\u6d41\u91cf\u9700\u6c42\u7684\u670d\u52a1\u7b49\u7ea7\u89c4\u8303\u3002", "result": "\u5728\u5408\u6210\u591a\u6a21\u6001\u5e94\u6025\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7528\u6237\u68c0\u6d4b\u51c6\u786e\u7387\u8d85\u8fc770%\uff0c90%\u60c5\u51b5\u4e0bSLS\u751f\u6210\u65f6\u95f4\u4f4e\u4e8e130\u79d2\u3002\u7ed3\u679c\u8868\u660e\u7ed3\u5408\u97f3\u9891\u548c\u89c6\u89c9\u6a21\u6001\u80fd\u63d0\u5347\u7528\u6237\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "MAPS\u4e3a\u81ea\u4e3b\u96f6\u63a5\u89e6\u98de\u884c\u7f51\u7edc\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u611f\u77e5\u5c42\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001AI\u5728\u81ea\u4e3b\u7f51\u7edc\u611f\u77e5\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.00758", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00758", "abs": "https://arxiv.org/abs/2512.00758", "authors": ["Yushen Wang", "Weidong Mei", "Xin Wei", "Zhi Chen", "Boyu Ning"], "title": "Movable Antenna Empowered Near-Field Sensing via Antenna Position Optimization", "comment": null, "summary": "Movable antenna (MA) technology exhibits great promise for enhancing the sensing capabilities of future sixth-generation (6G) networks due to its capability to alter antenna array geometry. With the growing prevalence of near-field propagation at ultra-high frequencies, this paper focuses on the application of one-dimensional (1D) and two-dimensional (2D) MA arrays for near-field sensing to jointly estimate the angle and distance information about a target. First, for the 1D MA array scenario, to gain insights into MA-enhanced near-field sensing, we investigate two simplified cases with only angle-of-arrival (AoA) or distance estimation, respectively, assuming that the other information is already known. The worst-case Cramer-Rao bounds (CRBs) on the mean square errors (MSEs) of the AoA estimation and the distance estimation are derived in these two cases. Then, we jointly optimize the positions of the MAs within the 1D array to minimize these CRBs and derive their closed-form solutions, which yield an identical array geometry to MA-enhanced far-field sensing. For the more challenging joint AoA and distance estimation, since the associated worst-case CRB is a highly complex and non-convex function with respect to the MA positions, a discrete sampling-based approach is proposed to sequentially update the MA positions and obtain an efficient suboptimal solution. Furthermore, we investigate the worst-case CRB minimization problems for a 2D MA array under various conditions and extend our proposed algorithms to solve them efficiently. Numerical results demonstrate that the proposed MA-enhanced near-field sensing scheme dramatically outperforms conventional fixed-position antennas (FPAs). Moreover, the joint angle and distance estimation results in a different array geometry from that in the individual estimation of angle/distance or far-field sensing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u53ef\u79fb\u52a8\u5929\u7ebf\uff08MA\uff09\u9635\u5217\u57286G\u8fd1\u573a\u611f\u77e5\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u6765\u8054\u5408\u4f30\u8ba1\u76ee\u6807\u7684\u5230\u8fbe\u89d2\u548c\u8ddd\u79bb\uff0c\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u663e\u8457\u63d0\u5347\u4e86\u611f\u77e5\u6027\u80fd\u3002", "motivation": "\u968f\u77406G\u7f51\u7edc\u5411\u8d85\u9ad8\u9891\u7387\u53d1\u5c55\uff0c\u8fd1\u573a\u4f20\u64ad\u53d8\u5f97\u8d8a\u6765\u8d8a\u666e\u904d\u3002\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u5728\u8fd1\u573a\u611f\u77e5\u4e2d\u6027\u80fd\u6709\u9650\uff0c\u800c\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u80fd\u591f\u901a\u8fc7\u6539\u53d8\u9635\u5217\u51e0\u4f55\u5f62\u72b6\u6765\u589e\u5f3a\u611f\u77e5\u80fd\u529b\uff0c\u56e0\u6b64\u7814\u7a76MA\u9635\u5217\u5728\u8fd1\u573a\u89d2\u5ea6\u548c\u8ddd\u79bb\u8054\u5408\u4f30\u8ba1\u4e2d\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u9996\u5148\u7814\u7a761D MA\u9635\u5217\u7684\u7b80\u5316\u60c5\u51b5\uff08\u4ec5AoA\u6216\u4ec5\u8ddd\u79bb\u4f30\u8ba1\uff09\uff0c\u63a8\u5bfc\u6700\u574f\u60c5\u51b5Cramer-Rao\u754c\uff08CRB\uff09\u3002\u7136\u540e\u8054\u5408\u4f18\u5316MA\u4f4d\u7f6e\u4ee5\u6700\u5c0f\u5316CRB\uff0c\u83b7\u5f97\u95ed\u5f0f\u89e3\u3002\u5bf9\u4e8e\u66f4\u590d\u6742\u7684\u89d2\u5ea6\u548c\u8ddd\u79bb\u8054\u5408\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u79bb\u6563\u91c7\u6837\u7684\u65b9\u6cd5\u987a\u5e8f\u66f4\u65b0MA\u4f4d\u7f6e\u3002\u6700\u540e\u5c06\u65b9\u6cd5\u6269\u5c55\u52302D MA\u9635\u5217\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684MA\u589e\u5f3a\u8fd1\u573a\u611f\u77e5\u65b9\u6848\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\uff08FPA\uff09\u3002\u540c\u65f6\u53d1\u73b0\uff0c\u89d2\u5ea6\u548c\u8ddd\u79bb\u8054\u5408\u4f30\u8ba1\u4ea7\u751f\u7684\u9635\u5217\u51e0\u4f55\u5f62\u72b6\u4e0e\u5355\u72ec\u7684\u89d2\u5ea6/\u8ddd\u79bb\u4f30\u8ba1\u6216\u8fdc\u573a\u611f\u77e5\u4e0d\u540c\u3002", "conclusion": "\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u80fd\u591f\u6709\u6548\u589e\u5f3a6G\u7f51\u7edc\u7684\u8fd1\u573a\u611f\u77e5\u80fd\u529b\uff0c\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u9635\u5217\u51e0\u4f55\u5f62\u72b6\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u89d2\u5ea6\u548c\u8ddd\u79bb\u4f30\u8ba1\u6027\u80fd\uff0c\u4e3a\u672a\u67656G\u7f51\u7edc\u7684\u9ad8\u7cbe\u5ea6\u611f\u77e5\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2512.00319", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00319", "abs": "https://arxiv.org/abs/2512.00319", "authors": ["Ruike Hu", "Shulei Wu"], "title": "RL-Struct: A Lightweight Reinforcement Learning Framework for Reliable Structured Output in LLMs", "comment": "23 pages, 14 figures. Model is available at https://huggingface.co/Freakz3z/Qwen-JSON", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language generation and reasoning. However, their integration into automated software ecosystems is often hindered by the \"Structure Gap\" - the inherent tension between the probabilistic nature of token generation and the deterministic requirements of structured data formats (e.g., JSON, XML). Traditional Supervised Fine-Tuning (SFT) often fails to enforce strict syntactic constraints, leading to \"hallucinated\" keys or malformed structures, while constrained decoding methods impose significant inference latency. In this paper, we propose a lightweight, efficient Reinforcement Learning (RL) framework to bridge this gap. We introduce a novel Multi-dimensional Reward Function that decomposes the structured output task into a hierarchy of constraints: structural integrity, format correctness, content accuracy, and validity. Leveraging Gradient Regularized Policy Optimization (GRPO), we enable the model to internalize these constraints without the need for a separate critic network, reducing peak VRAM usage by 40% compared to PPO. We validate our approach on multiple tasks, including complex recipe generation and structured math reasoning (GSM8K-JSON). Experimental results demonstrate that our method achieves 89.7% structural accuracy and 92.1% JSON validity, significantly outperforming both zero-shot baselines (e.g., GPT-3.5) and SFT on larger models like LLaMA-3-8B. Furthermore, we provide a detailed analysis of training dynamics, revealing a distinct self-paced curriculum where the model sequentially acquires syntactic proficiency before semantic accuracy. Our model is publicly available at https://huggingface.co/Freakz3z/Qwen-JSON.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3LLM\u751f\u6210\u7ed3\u6784\u5316\u6570\u636e\u65f6\u7684\"\u7ed3\u6784\u9e3f\u6c9f\"\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u7ef4\u5956\u52b1\u51fd\u6570\u548c\u68af\u5ea6\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347JSON\u6709\u6548\u6027\u81f392.1%", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u96c6\u6210\u65f6\u9762\u4e34\"\u7ed3\u6784\u9e3f\u6c9f\"\u95ee\u9898\u2014\u2014\u6982\u7387\u6027token\u751f\u6210\u4e0e\u786e\u5b9a\u6027\u7ed3\u6784\u5316\u6570\u636e\u683c\u5f0f(\u5982JSON\u3001XML)\u4e4b\u95f4\u7684\u5185\u5728\u77db\u76fe\u3002\u4f20\u7edf\u76d1\u7763\u5fae\u8c03\u96be\u4ee5\u5f3a\u5236\u6267\u884c\u4e25\u683c\u8bed\u6cd5\u7ea6\u675f\uff0c\u5bfc\u81f4\"\u5e7b\u89c9\"\u952e\u6216\u683c\u5f0f\u9519\u8bef\uff0c\u800c\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u53c8\u4f1a\u5e26\u6765\u663e\u8457\u7684\u63a8\u7406\u5ef6\u8fdf\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u591a\u7ef4\u5956\u52b1\u51fd\u6570\u5c06\u7ed3\u6784\u5316\u8f93\u51fa\u4efb\u52a1\u5206\u89e3\u4e3a\u5c42\u6b21\u5316\u7ea6\u675f\uff1a\u7ed3\u6784\u5b8c\u6574\u6027\u3001\u683c\u5f0f\u6b63\u786e\u6027\u3001\u5185\u5bb9\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002\u91c7\u7528\u68af\u5ea6\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316(GRPO)\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5185\u5316\u8fd9\u4e9b\u7ea6\u675f\u800c\u65e0\u9700\u5355\u72ec\u7684\u6279\u8bc4\u7f51\u7edc\uff0c\u76f8\u6bd4PPO\u51cf\u5c1140%\u7684\u5cf0\u503cVRAM\u4f7f\u7528\u3002", "result": "\u5728\u590d\u6742\u98df\u8c31\u751f\u6210\u548c\u7ed3\u6784\u5316\u6570\u5b66\u63a8\u7406(GSM8K-JSON)\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u8fbe\u523089.7%\u7684\u7ed3\u6784\u51c6\u786e\u7387\u548c92.1%\u7684JSON\u6709\u6548\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u7ebf(\u5982GPT-3.5)\u548c\u5728LLaMA-3-8B\u7b49\u66f4\u5927\u6a21\u578b\u4e0a\u7684\u76d1\u7763\u5fae\u8c03\u3002\u8bad\u7ec3\u52a8\u6001\u5206\u6790\u663e\u793a\u6a21\u578b\u6309\u81ea\u5b9a\u8fdb\u5ea6\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5148\u638c\u63e1\u8bed\u6cd5\u719f\u7ec3\u5ea6\u518d\u83b7\u5f97\u8bed\u4e49\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u751f\u6210\u7ed3\u6784\u5316\u6570\u636e\u65f6\u7684\"\u7ed3\u6784\u9e3f\u6c9f\"\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u7ef4\u5956\u52b1\u51fd\u6570\u548c\u68af\u5ea6\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7ed3\u6784\u7ea6\u675f\u5185\u5316\uff0c\u5728\u4fdd\u6301\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2512.00491", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00491", "abs": "https://arxiv.org/abs/2512.00491", "authors": ["Yule Han", "Kezhi Wang", "Kun Yang"], "title": "Smart-TCP: An Agentic AI-based Autonomous and Adaptive TCP Protocol", "comment": "Submitted for possible journal publication", "summary": "The Transmission Control Protocol (TCP) relies on a state machine and deterministic arithmetic to ensure reliable connections. However, traditional protocol logic driven by hard-coded state machines struggles to meet the demands of intelligent and autonomous network architectures. Here, we adopt the agentic AI-based paradigm, driven by Large Language Models (LLMs), characterized by context perception, autonomous reasoning, and tool use. Based on this, we propose Smart-TCP, which re-imagines TCP's core control logic as an autonomous agent. Specifically, the proposed architecture employs a context aggregation mechanism to synthesize the protocol context, utilizes the LLM for autonomous logical reasoning, and invokes an Arithmetic Logic Unit (ALU) as a tool for computation. Furthermore, we establish a dual-agent interaction framework based on this architecture and implement TCP protocol interactions. Experiments demonstrate that the Smart-TCP agent excels in static prediction and error detection, achieving a 93.33% success rate in end-to-end sessions. These results strongly validate the technical feasibility of an agentic AI-based TCP protocol.", "AI": {"tldr": "Smart-TCP\uff1a\u57fa\u4e8eLLM\u7684\u667a\u80fdTCP\u534f\u8bae\uff0c\u5c06\u4f20\u7edfTCP\u72b6\u6001\u673a\u63a7\u5236\u903b\u8f91\u91cd\u6784\u4e3a\u5177\u5907\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u81ea\u4e3b\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u667a\u80fd\u4f53\u67b6\u6784", "motivation": "\u4f20\u7edfTCP\u534f\u8bae\u4f9d\u8d56\u786c\u7f16\u7801\u72b6\u6001\u673a\u548c\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u96be\u4ee5\u6ee1\u8db3\u667a\u80fd\u81ea\u4e3b\u7f51\u7edc\u67b6\u6784\u7684\u9700\u6c42\u3002\u9700\u8981\u66f4\u7075\u6d3b\u3001\u667a\u80fd\u7684\u534f\u8bae\u63a7\u5236\u673a\u5236\u6765\u9002\u5e94\u590d\u6742\u7f51\u7edc\u73af\u5883", "method": "1. \u91c7\u7528\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u8303\u5f0f\uff1b2. \u63d0\u51faSmart-TCP\u67b6\u6784\uff0c\u5c06TCP\u6838\u5fc3\u63a7\u5236\u903b\u8f91\u91cd\u6784\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\uff1b3. \u4f7f\u7528\u4e0a\u4e0b\u6587\u805a\u5408\u673a\u5236\u5408\u6210\u534f\u8bae\u4e0a\u4e0b\u6587\uff1b4. \u5229\u7528LLM\u8fdb\u884c\u81ea\u4e3b\u903b\u8f91\u63a8\u7406\uff1b5. \u8c03\u7528\u7b97\u672f\u903b\u8f91\u5355\u5143(ALU)\u4f5c\u4e3a\u8ba1\u7b97\u5de5\u5177\uff1b6. \u5efa\u7acb\u57fa\u4e8e\u8be5\u67b6\u6784\u7684\u53cc\u667a\u80fd\u4f53\u4ea4\u4e92\u6846\u67b6", "result": "Smart-TCP\u667a\u80fd\u4f53\u5728\u9759\u6001\u9884\u6d4b\u548c\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7aef\u5230\u7aef\u4f1a\u8bdd\u6210\u529f\u7387\u8fbe\u523093.33%\uff0c\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u667a\u80fd\u4f53AI\u7684TCP\u534f\u8bae\u6280\u672f\u53ef\u884c\u6027", "conclusion": "\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u8303\u5f0f\u80fd\u591f\u6709\u6548\u91cd\u6784TCP\u534f\u8bae\u63a7\u5236\u903b\u8f91\uff0c\u4e3a\u667a\u80fd\u81ea\u4e3b\u7f51\u7edc\u67b6\u6784\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\uff0c\u5c55\u793a\u4e86AI\u9a71\u52a8\u7684\u7f51\u7edc\u534f\u8bae\u8bbe\u8ba1\u7684\u6f5c\u529b"}}
{"id": "2512.00770", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00770", "abs": "https://arxiv.org/abs/2512.00770", "authors": ["Jiasi Zhou", "Chintha Tellambura", "Geoffrey Ye Li"], "title": "Rate-Splitting Multiple Access for Secure Near-Field Integrated Sensing and Communication", "comment": null, "summary": "Near-field integrated sensing and communication (ISAC) leverages distance-dependent channel variations for joint distance and angle estimation. However, full-digital architectures have prohibitive hardware costs, making hybrid analog-digital (HAD) designs the primary alternative. Nevertheless, such architectures compromise beamfocusing precision and lead to energy leakage, which exacerbates inter-user interference and increases eavesdropping risks. To address these challenges, this paper proposes a rate-splitting multiple access (RSMA)-enhanced secure transmit scheme for near-field ISAC. For the first time, it exploits the common stream in RSMA to concurrently (i) flexibly manage interference, (ii) act as artificial noise to suppress eavesdropping, and (iii) serve as sensing sequences. The objective is to maximize the minimum secrecy rate while satisfying the angle and distance Cramer-Rao Bound (CRB) constraints. This results in a hard, non-convex optimization problem, and we employ block coordinate descent to decompose it into three sub-problems with lower computational complexity. In the first stage of optimizing fully digital beamfocusers, we develop an iterative solution using weighted minimum mean-squared error (WMMSE), quadratic transform, and Taylor expansion methods, thus avoiding conventional semidefinite relaxation. In the second and third stages, the analog and digital beamfocusers are optimized in closed form. Simulation results show that the proposed scheme (1) achieves near full-digital beamfocusing performance with a 16-fold reduction in RF chains, (2) provides superior secrecy performance compared to conventional beamfocusing-only and far-field security schemes, and (3) enables high-accuracy sensing with negligible loss in secrecy performance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eRSMA\u7684\u8fd1\u573aISAC\u5b89\u5168\u4f20\u8f93\u65b9\u6848\uff0c\u5229\u7528RSMA\u7684\u516c\u5171\u6d41\u540c\u65f6\u7ba1\u7406\u5e72\u6270\u3001\u6291\u5236\u7a83\u542c\u5e76\u4f5c\u4e3a\u611f\u77e5\u5e8f\u5217\uff0c\u5728\u6ee1\u8db3CRB\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u6700\u5c0f\u4fdd\u5bc6\u901f\u7387", "motivation": "\u8fd1\u573aISAC\u4e2d\uff0c\u5168\u6570\u5b57\u67b6\u6784\u786c\u4ef6\u6210\u672c\u8fc7\u9ad8\uff0c\u800c\u6df7\u5408\u6a21\u62df\u6570\u5b57\u67b6\u6784\u4f1a\u964d\u4f4e\u6ce2\u675f\u805a\u7126\u7cbe\u5ea6\uff0c\u5bfc\u81f4\u80fd\u91cf\u6cc4\u6f0f\uff0c\u52a0\u5267\u7528\u6237\u95f4\u5e72\u6270\u548c\u7a83\u542c\u98ce\u9669", "method": "\u63d0\u51faRSMA\u589e\u5f3a\u7684\u5b89\u5168\u4f20\u8f93\u65b9\u6848\uff0c\u5229\u7528RSMA\u516c\u5171\u6d41\u540c\u65f6\u5b9e\u73b0\u5e72\u6270\u7ba1\u7406\u3001\u7a83\u542c\u6291\u5236\u548c\u611f\u77e5\u5e8f\u5217\u529f\u80fd\uff1b\u91c7\u7528\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u5206\u89e3\u4f18\u5316\u95ee\u9898\uff0c\u5206\u4e09\u9636\u6bb5\u4f18\u5316\uff1a\u5168\u6570\u5b57\u6ce2\u675f\u805a\u7126\u5668\uff08WMMSE+\u4e8c\u6b21\u53d8\u6362+\u6cf0\u52d2\u5c55\u5f00\uff09\u3001\u6a21\u62df\u6ce2\u675f\u805a\u7126\u5668\uff08\u95ed\u5f0f\u89e3\uff09\u3001\u6570\u5b57\u6ce2\u675f\u805a\u7126\u5668\uff08\u95ed\u5f0f\u89e3\uff09", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff1a1) \u5728RF\u94fe\u51cf\u5c1116\u500d\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u5168\u6570\u5b57\u6ce2\u675f\u805a\u7126\u6027\u80fd\uff1b2) \u76f8\u6bd4\u4f20\u7edf\u6ce2\u675f\u805a\u7126\u548c\u8fdc\u573a\u5b89\u5168\u65b9\u6848\u63d0\u4f9b\u66f4\u4f18\u7684\u4fdd\u5bc6\u6027\u80fd\uff1b3) \u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u611f\u77e5\u4e14\u4fdd\u5bc6\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565", "conclusion": "\u63d0\u51fa\u7684RSMA\u589e\u5f3a\u8fd1\u573aISAC\u5b89\u5168\u4f20\u8f93\u65b9\u6848\u80fd\u6709\u6548\u89e3\u51b3\u6df7\u5408\u67b6\u6784\u7684\u6ce2\u675f\u805a\u7126\u7cbe\u5ea6\u635f\u5931\u95ee\u9898\uff0c\u540c\u65f6\u5b9e\u73b0\u5b89\u5168\u901a\u4fe1\u548c\u9ad8\u7cbe\u5ea6\u611f\u77e5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2512.00331", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.00331", "abs": "https://arxiv.org/abs/2512.00331", "authors": ["Yefeng Wu", "Yuchen Song", "Yecheng Zhao", "Ling Wu", "Shan Wan"], "title": "CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended interactions. We argue that retrieval, memory, and control should be treated as a coupled cognitive evolution process. We instantiate this view in CogEvo-Edu, a hierarchical educational multi-agent system comprising a Cognitive Perception Layer (CPL), a Knowledge Evolution Layer (KEL), and a Meta-Control Layer (MCL). CPL maintains dual memories and performs confidence-weighted consolidation to build structured, self-correcting student profiles under limited context. KEL assigns each knowledge chunk a spatiotemporal value that drives activation, semantic compression, and forgetting. MCL formulates tutoring as hierarchical sequential decision making, orchestrating specialized agents and jointly adapting CPL/KEL hyperparameters via a dual inner--outer loop. To evaluate CogEvo-Edu, we construct DSP-EduBench, a vertical benchmark for DSP tutoring with heterogeneous resources, simulated student profiles, and long-horizon interaction scripts. Using a three-model LLM-as-a-Judge ensemble, CogEvo-Edu raises the overall score from 5.32 to 9.23 and improves all six indicators over static RAG, simple memory, and a single-agent variant, demonstrating the value of jointly evolving student profiles, knowledge bases, and teaching policies.", "AI": {"tldr": "CogEvo-Edu\uff1a\u4e00\u4e2a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u68c0\u7d22\u3001\u8bb0\u5fc6\u548c\u63a7\u5236\u4f5c\u4e3a\u8026\u5408\u7684\u8ba4\u77e5\u6f14\u5316\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347STEM\u6559\u80b2\u4e2dLLM\u5bf9\u8bdd\u5bfc\u5e08\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524dSTEM\u6559\u80b2\u4e2d\u90e8\u7f72\u7684LLM\u5bf9\u8bdd\u5bfc\u5e08\u5927\u591a\u91c7\u7528\u5355\u4e00LLM\u548c\u9759\u6001RAG\u7ba1\u9053\uff0c\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u7b49\u590d\u6742\u9886\u57df\u4e2d\u96be\u4ee5\u7ef4\u6301\u8fde\u8d2f\u7684\u5b66\u751f\u6a21\u578b\u3001\u7ba1\u7406\u5f02\u6784\u77e5\u8bc6\u5e93\u548c\u9002\u5e94\u957f\u671f\u4e92\u52a8\u3002\u9700\u8981\u5c06\u68c0\u7d22\u3001\u8bb0\u5fc6\u548c\u63a7\u5236\u89c6\u4e3a\u8026\u5408\u7684\u8ba4\u77e5\u6f14\u5316\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faCogEvo-Edu\u5206\u5c42\u6559\u80b2\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1a\u8ba4\u77e5\u611f\u77e5\u5c42\u7ef4\u62a4\u53cc\u91cd\u8bb0\u5fc6\u5e76\u8fdb\u884c\u7f6e\u4fe1\u5ea6\u52a0\u6743\u6574\u5408\u4ee5\u6784\u5efa\u7ed3\u6784\u5316\u3001\u81ea\u6821\u6b63\u7684\u5b66\u751f\u6863\u6848\uff1b\u77e5\u8bc6\u6f14\u5316\u5c42\u4e3a\u6bcf\u4e2a\u77e5\u8bc6\u5757\u5206\u914d\u65f6\u7a7a\u4ef7\u503c\u4ee5\u9a71\u52a8\u6fc0\u6d3b\u3001\u8bed\u4e49\u538b\u7f29\u548c\u9057\u5fd8\uff1b\u5143\u63a7\u5236\u5c42\u5c06\u6559\u5b66\u5236\u5b9a\u4e3a\u5206\u5c42\u987a\u5e8f\u51b3\u7b56\uff0c\u534f\u8c03\u4e13\u4e1a\u667a\u80fd\u4f53\u5e76\u901a\u8fc7\u53cc\u91cd\u5185\u5916\u5faa\u73af\u8054\u5408\u8c03\u6574CPL/KEL\u8d85\u53c2\u6570\u3002", "result": "\u5728\u6784\u5efa\u7684DSP-EduBench\u5782\u76f4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u4e09\u6a21\u578bLLM-as-a-Judge\u96c6\u6210\u8bc4\u4f30\uff0cCogEvo-Edu\u5c06\u603b\u4f53\u5f97\u5206\u4ece5.32\u63d0\u5347\u52309.23\uff0c\u5728\u6240\u6709\u516d\u4e2a\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u9759\u6001RAG\u3001\u7b80\u5355\u8bb0\u5fc6\u548c\u5355\u667a\u80fd\u4f53\u53d8\u4f53\u3002", "conclusion": "CogEvo-Edu\u901a\u8fc7\u8054\u5408\u6f14\u5316\u5b66\u751f\u6863\u6848\u3001\u77e5\u8bc6\u5e93\u548c\u6559\u5b66\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u5c06\u68c0\u7d22\u3001\u8bb0\u5fc6\u548c\u63a7\u5236\u4f5c\u4e3a\u8026\u5408\u8ba4\u77e5\u6f14\u5316\u8fc7\u7a0b\u7684\u4ef7\u503c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742STEM\u9886\u57df\u4e2d\u7684\u6559\u5b66\u6548\u679c\u3002"}}
{"id": "2512.00509", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00509", "abs": "https://arxiv.org/abs/2512.00509", "authors": ["Sumita Majhi", "Kaushal Shelke", "Pinaki Mitra", "Ujjwal Biswas"], "title": "Improving Channel Estimation Through Gold Sequences", "comment": null, "summary": "This study evaluates Non-Orthogonal Multiple Access (NOMA) systems using Gold coding and Conventional-V-BLAST (C-V-BLAST). Superimposed signals on shared subcarriers make NOMA user separation difficult, unlike MIMO. Gold sequences' orthogonal features may enhance user separation and channel estimation. A novel channel estimation approach uses fractional power allocation and partially decoded data symbols. A realistic simulation environment was created using AWGN, Rayleigh fading, and shadowing. Using pilot signals, power allocation, and data symbols, our Channel Prediction Function (CPF) surpasses pilot-based techniques.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528Gold\u7f16\u7801\u548c\u4f20\u7edfV-BLAST\u7684NOMA\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5206\u6570\u529f\u7387\u5206\u914d\u548c\u90e8\u5206\u89e3\u7801\u6570\u636e\u7b26\u53f7\u7684\u65b0\u578b\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5728AWGN\u3001\u745e\u5229\u8870\u843d\u548c\u9634\u5f71\u7684\u4eff\u771f\u73af\u5883\u4e2d\u4f18\u4e8e\u4f20\u7edf\u5bfc\u9891\u6280\u672f\u3002", "motivation": "NOMA\u7cfb\u7edf\u4e2d\u53e0\u52a0\u4fe1\u53f7\u5728\u5171\u4eab\u5b50\u8f7d\u6ce2\u4e0a\u4f7f\u5f97\u7528\u6237\u5206\u79bb\u56f0\u96be\uff0c\u4e0d\u540c\u4e8eMIMO\u7cfb\u7edf\u3002Gold\u5e8f\u5217\u7684\u6b63\u4ea4\u7279\u6027\u53ef\u80fd\u589e\u5f3a\u7528\u6237\u5206\u79bb\u548c\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u5206\u6570\u529f\u7387\u5206\u914d\u548c\u90e8\u5206\u89e3\u7801\u6570\u636e\u7b26\u53f7\u3002\u521b\u5efa\u5305\u542bAWGN\u3001\u745e\u5229\u8870\u843d\u548c\u9634\u5f71\u7684\u73b0\u5b9e\u4eff\u771f\u73af\u5883\uff0c\u4f7f\u7528\u5bfc\u9891\u4fe1\u53f7\u3001\u529f\u7387\u5206\u914d\u548c\u6570\u636e\u7b26\u53f7\u6784\u5efa\u4fe1\u9053\u9884\u6d4b\u51fd\u6570(CPF)\u3002", "result": "\u63d0\u51fa\u7684\u4fe1\u9053\u9884\u6d4b\u51fd\u6570(CPF)\u5728\u4eff\u771f\u73af\u5883\u4e2d\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u5bfc\u9891\u57fa\u4fe1\u9053\u4f30\u8ba1\u6280\u672f\u3002", "conclusion": "Gold\u7f16\u7801\u548cC-V-BLAST\u7ed3\u5408\u7684NOMA\u7cfb\u7edf\u901a\u8fc7\u65b0\u578b\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6539\u5584\u7528\u6237\u5206\u79bb\u548c\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\uff0c\u4e3aNOMA\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00774", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00774", "abs": "https://arxiv.org/abs/2512.00774", "authors": ["Jiasi Zhou", "Huiyun Xia", "Chuan Wu", "Chintha Tellambura"], "title": "Hybrid Beamfocusing Design for RSMA-Enhanced Near-Field Secure Communications", "comment": "10 pages and 6 figures", "summary": "Near-field spherical wavefronts enable spotlight-like beam focusing to mitigate unintended energy leakage, creating new opportunities for physical-layer security (PLS). However, under hybrid analog-digital (HAD) antenna architectures, beamfocusing alone may not provide foolproof privacy protection due to reduced focusing precision. To address this issue, this paper proposes a rate-splitting multiple access (RSMA)-enhanced secure transmit scheme for near-field communications with fully-connected or sub-connected HAD architectures. In the proposed scheme, the common stream is designed for dual purposes, delivering the desired message for legitimate users while acting as artificial noise to disrupt eavesdropping. The primary objective is to maximize the minimum secrecy rate by jointly optimizing the analog beamfocuser, digital beamfocuser, and common secrecy rate allocation. To solve the formulated non-convex problem, we develop a penalty-based alternating optimization algorithm. Specifically, the variables are partitioned into three blocks, where one block is solved via a surrogate optimization method, while the others are updated in closed form. Simulation results reveal that our transmit scheme: (1) approaches fully digital beamfocusing with substantially fewer radio frequency chains, (2) outperforms conventional beamfocusing-only and far-field security schemes, and (3) preserves secrecy without significantly compromising communication rates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u901f\u7387\u5206\u5272\u591a\u5740\uff08RSMA\uff09\u7684\u8fd1\u573a\u901a\u4fe1\u5b89\u5168\u4f20\u8f93\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6a21\u62df\u6ce2\u675f\u805a\u7126\u5668\u3001\u6570\u5b57\u6ce2\u675f\u805a\u7126\u5668\u548c\u516c\u5171\u4fdd\u5bc6\u901f\u7387\u5206\u914d\uff0c\u5728\u6df7\u5408\u6a21\u62df-\u6570\u5b57\u5929\u7ebf\u67b6\u6784\u4e0b\u5b9e\u73b0\u6700\u5927\u6700\u5c0f\u4fdd\u5bc6\u7387\u3002", "motivation": "\u8fd1\u573a\u7403\u9762\u6ce2\u524d\u80fd\u591f\u5b9e\u73b0\u805a\u5149\u706f\u5f0f\u6ce2\u675f\u805a\u7126\uff0c\u51cf\u5c11\u80fd\u91cf\u6cc4\u6f0f\uff0c\u4e3a\u7269\u7406\u5c42\u5b89\u5168\u63d0\u4f9b\u65b0\u673a\u4f1a\u3002\u4f46\u5728\u6df7\u5408\u6a21\u62df-\u6570\u5b57\u5929\u7ebf\u67b6\u6784\u4e0b\uff0c\u4ec5\u9760\u6ce2\u675f\u805a\u7126\u53ef\u80fd\u65e0\u6cd5\u63d0\u4f9b\u53ef\u9760\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u56e0\u4e3a\u805a\u7126\u7cbe\u5ea6\u964d\u4f4e\u3002\u9700\u8981\u89e3\u51b3\u6df7\u5408\u67b6\u6784\u4e0b\u7684\u8fd1\u573a\u901a\u4fe1\u5b89\u5168\u95ee\u9898\u3002", "method": "\u63d0\u51faRSMA\u589e\u5f3a\u7684\u5b89\u5168\u4f20\u8f93\u65b9\u6848\uff0c\u5c06\u516c\u5171\u6d41\u8bbe\u8ba1\u4e3a\u53cc\u91cd\u7528\u9014\uff1a\u4e3a\u5408\u6cd5\u7528\u6237\u4f20\u9012\u671f\u671b\u6d88\u606f\uff0c\u540c\u65f6\u4f5c\u4e3a\u4eba\u5de5\u566a\u58f0\u5e72\u6270\u7a83\u542c\u3002\u91c7\u7528\u57fa\u4e8e\u60e9\u7f5a\u7684\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\uff0c\u5c06\u53d8\u91cf\u5206\u4e3a\u4e09\u4e2a\u5757\uff0c\u5176\u4e2d\u4e00\u4e2a\u5757\u901a\u8fc7\u4ee3\u7406\u4f18\u5316\u65b9\u6cd5\u6c42\u89e3\uff0c\u5176\u4ed6\u5757\u4ee5\u95ed\u5f0f\u66f4\u65b0\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff1a(1) \u65b9\u6848\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u5c04\u9891\u94fe\u63a5\u8fd1\u5168\u6570\u5b57\u6ce2\u675f\u805a\u7126\u6027\u80fd\uff1b(2) \u4f18\u4e8e\u4f20\u7edf\u7684\u4ec5\u6ce2\u675f\u805a\u7126\u548c\u8fdc\u573a\u5b89\u5168\u65b9\u6848\uff1b(3) \u5728\u4e0d\u663e\u8457\u5f71\u54cd\u901a\u4fe1\u901f\u7387\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u4fdd\u5bc6\u6027\u3002", "conclusion": "RSMA\u589e\u5f3a\u7684\u5b89\u5168\u4f20\u8f93\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408\u6a21\u62df-\u6570\u5b57\u67b6\u6784\u4e0b\u8fd1\u573a\u901a\u4fe1\u7684\u5b89\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u516c\u5171\u6d41\u7684\u53cc\u91cd\u7528\u9014\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7269\u7406\u5c42\u5b89\u5168\u4fdd\u62a4\u3002"}}
{"id": "2512.00344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00344", "abs": "https://arxiv.org/abs/2512.00344", "authors": ["Naifan Zhang", "Ruihan Sun", "Ruixi Su", "Shiqi Ma", "Shiya Zhang", "Xianna Weng", "Xiaofan Zhang", "Yuhan Zhan", "Yuyang Xu", "Zhaohan Chen", "Zhengyuan Pan", "Ziyi Song"], "title": "Echo-N1: Affective RL Frontier", "comment": null, "summary": "The LLM field has spent a year perfecting RL for tasks machines already excel at, math, code, and deterministic reasoning, while completely sidestepping the domain that actually defines human intelligence: subjective, emotionally grounded, personality sensitive conversation. This space has often been regarded as inherently subjective and challenging to formalize, making it appear unsuitable for conventional RL pipelines. We show that it is not only possible and it is a solvable and transformative RL problem. We propose the first framework that infers user personality on the fly and optimizes model behavior toward personalized conversational preferences. Contrary to the widespread belief that RL collapses in non-verifiable settings, our method produces consistent, robust, and dramatic improvements in humanlike interaction quality. We also introduce the first dynamic emotional intelligence evaluation suite to quantify these gains. Our model, which is introduced as Echo-N1, behaves far above its base version and outperforming the proprietary Doubao 1.5 Character. This work establishes a new frontier for RL: optimizing models for the deeply subjective, deeply human dimensions of conversation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9996\u4e2a\u80fd\u5b9e\u65f6\u63a8\u65ad\u7528\u6237\u4e2a\u6027\u5e76\u4f18\u5316\u5bf9\u8bdd\u884c\u4e3a\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4e3b\u89c2\u60c5\u611f\u5bf9\u8bdd\u9886\u57df\u53d6\u5f97\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u5f53\u524dLLM\u9886\u57df\u8fc7\u5ea6\u5173\u6ce8\u6570\u5b66\u3001\u4ee3\u7801\u7b49\u673a\u5668\u64c5\u957f\u7684\u786e\u5b9a\u6027\u4efb\u52a1\uff0c\u800c\u5ffd\u7565\u4e86\u771f\u6b63\u5b9a\u4e49\u4eba\u7c7b\u667a\u80fd\u7684\u4e3b\u89c2\u60c5\u611f\u5bf9\u8bdd\u9886\u57df\u3002\u8be5\u9886\u57df\u56e0\u4e3b\u89c2\u6027\u5f3a\u3001\u96be\u4ee5\u5f62\u5f0f\u5316\u800c\u88ab\u8ba4\u4e3a\u4e0d\u9002\u5408\u4f20\u7edfRL\u65b9\u6cd5\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u4e00\u4e2a\u53ef\u89e3\u51b3\u4e14\u5177\u6709\u53d8\u9769\u6027\u7684RL\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u80fd\u5b9e\u65f6\u63a8\u65ad\u7528\u6237\u4e2a\u6027\u5e76\u4f18\u5316\u6a21\u578b\u884c\u4e3a\u4ee5\u9002\u5e94\u4e2a\u6027\u5316\u5bf9\u8bdd\u504f\u597d\u7684\u6846\u67b6\u3002\u5f15\u5165\u52a8\u6001\u60c5\u611f\u667a\u80fd\u8bc4\u4f30\u5957\u4ef6\u6765\u91cf\u5316\u6539\u8fdb\u6548\u679c\u3002\u6a21\u578b\u540d\u4e3aEcho-N1\u3002", "result": "\u65b9\u6cd5\u5728\u975e\u53ef\u9a8c\u8bc1\u73af\u5883\u4e2d\u4ea7\u751f\u4e00\u81f4\u3001\u7a33\u5065\u4e14\u663e\u8457\u7684\u6539\u8fdb\uff0cEcho-N1\u8868\u73b0\u8fdc\u8d85\u5176\u57fa\u7840\u7248\u672c\uff0c\u5e76\u8d85\u8d8a\u4e86\u4e13\u6709\u7684Doubao 1.5 Character\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aRL\u5f00\u8f9f\u4e86\u65b0\u524d\u6cbf\uff1a\u4e3a\u5bf9\u8bdd\u4e2d\u6df1\u523b\u4e3b\u89c2\u3001\u6df1\u523b\u4eba\u6027\u5316\u7684\u7ef4\u5ea6\u4f18\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86RL\u5728\u4e3b\u89c2\u60c5\u611f\u5bf9\u8bdd\u9886\u57df\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2512.00985", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00985", "abs": "https://arxiv.org/abs/2512.00985", "authors": ["Adem Utku Atasayar", "Aimin Li", "\u00c7a\u011fr\u0131 Ar\u0131", "Elif Uysal"], "title": "Age Optimal Sampling and Routing under Intermittent Links and Energy Constraints", "comment": null, "summary": "Links in practical systems, such as satellite-terrestrial integrated networks, exhibit distinct delay distributions, intermittent availability, and heterogeneous energy costs. These characteristics pose significant challenges to maintaining timely and energy-efficient status updates. While link availability restricts feasible transmission routes, routing decisions determine the actual delay and energy expenditure. This paper tackles these challenges by jointly optimizing sampling and routing decisions to minimize monotonic, nonlinear Age of Information (AoI). The proposed formulation incorporates key system features, including multiple routes with correlated random delays, stochastic link availability, and route-dependent energy consumption. We model the problem as an infinite-horizon constrained semi-Markov decision process (CSMDP) with a hybrid state-action space and develop an efficient nested algorithm, termed Bisec-ReaVI, to solve this problem. We reveal a well-defined jointly optimal policy structure: (i) the optimal routing policy is a monotonic handover policy that adapts to the availability of routes and their mean delays; and (ii) the optimal sampling policy is a piecewise linear waiting policy, with at most \"N choose 2 + N\" breakpoints given N routes. Numerical experiments in a satellite-terrestrial integrated routing scenario demonstrate that the proposed scheme efficiently balances energy usage and information freshness, and reveal a counter-intuitive insight: even routes with higher average delay, higher delay variance, or lower availability can still play a critical role in minimizing monotonic functions of AoI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u4f18\u5316\u91c7\u6837\u548c\u8def\u7531\u51b3\u7b56\u7684\u65b9\u6cd5\uff0c\u4ee5\u6700\u5c0f\u5316\u536b\u661f-\u5730\u9762\u7efc\u5408\u7f51\u7edc\u4e2d\u5355\u8c03\u975e\u7ebf\u6027\u7684\u4fe1\u606f\u5e74\u9f84(AoI)\uff0c\u8003\u8651\u4e86\u94fe\u8def\u5ef6\u8fdf\u5206\u5e03\u3001\u95f4\u6b47\u53ef\u7528\u6027\u548c\u5f02\u6784\u80fd\u8017\u7b49\u5b9e\u9645\u7cfb\u7edf\u7279\u5f81\u3002", "motivation": "\u5b9e\u9645\u7cfb\u7edf\uff08\u5982\u536b\u661f-\u5730\u9762\u7efc\u5408\u7f51\u7edc\uff09\u4e2d\u7684\u94fe\u8def\u5177\u6709\u4e0d\u540c\u7684\u5ef6\u8fdf\u5206\u5e03\u3001\u95f4\u6b47\u53ef\u7528\u6027\u548c\u5f02\u6784\u80fd\u8017\u7279\u6027\uff0c\u8fd9\u4e9b\u7279\u6027\u5bf9\u4fdd\u6301\u53ca\u65f6\u4e14\u8282\u80fd\u7684\u72b6\u6001\u66f4\u65b0\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002\u94fe\u8def\u53ef\u7528\u6027\u9650\u5236\u4e86\u53ef\u884c\u7684\u4f20\u8f93\u8def\u5f84\uff0c\u800c\u8def\u7531\u51b3\u7b56\u53c8\u51b3\u5b9a\u4e86\u5b9e\u9645\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u5177\u6709\u6df7\u5408\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u7684\u65e0\u9650\u65f6\u57df\u7ea6\u675f\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(CSMDP)\uff0c\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u5d4c\u5957\u7b97\u6cd5Bisec-ReaVI\u3002\u63ed\u793a\u4e86\u8054\u5408\u6700\u4f18\u7b56\u7565\u7ed3\u6784\uff1a\u6700\u4f18\u8def\u7531\u7b56\u7565\u662f\u9002\u5e94\u8def\u5f84\u53ef\u7528\u6027\u548c\u5e73\u5747\u5ef6\u8fdf\u7684\u5355\u8c03\u5207\u6362\u7b56\u7565\uff1b\u6700\u4f18\u91c7\u6837\u7b56\u7565\u662f\u5206\u6bb5\u7ebf\u6027\u7b49\u5f85\u7b56\u7565\u3002", "result": "\u5728\u536b\u661f-\u5730\u9762\u7efc\u5408\u8def\u7531\u573a\u666f\u4e2d\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u80fd\u6709\u6548\u5e73\u8861\u80fd\u8017\u548c\u4fe1\u606f\u65b0\u9c9c\u5ea6\u3002\u63ed\u793a\u4e86\u4e00\u4e2a\u53cd\u76f4\u89c9\u7684\u89c1\u89e3\uff1a\u5373\u4f7f\u5e73\u5747\u5ef6\u8fdf\u66f4\u9ad8\u3001\u5ef6\u8fdf\u65b9\u5dee\u66f4\u5927\u6216\u53ef\u7528\u6027\u66f4\u4f4e\u7684\u8def\u5f84\uff0c\u5728\u6700\u5c0f\u5316AoI\u5355\u8c03\u51fd\u6570\u65f6\u4ecd\u80fd\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5177\u6709\u5f02\u6784\u94fe\u8def\u7279\u6027\u7684\u5b9e\u9645\u7f51\u7edc\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8054\u5408\u91c7\u6837\u548c\u8def\u7531\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5e73\u8861\u4fe1\u606f\u65b0\u9c9c\u5ea6\u548c\u80fd\u8017\uff0c\u5e76\u63ed\u793a\u4e86\u975e\u7406\u60f3\u8def\u5f84\u5728AoI\u4f18\u5316\u4e2d\u7684\u6f5c\u5728\u4ef7\u503c\u3002"}}
{"id": "2512.00349", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00349", "abs": "https://arxiv.org/abs/2512.00349", "authors": ["Sitong Fang", "Shiyi Hou", "Kaile Wang", "Boyuan Chen", "Donghai Hong", "Jiayi Zhou", "Josef Dai", "Yaodong Yang", "Jiaming Ji"], "title": "Debate with Images: Detecting Deceptive Behaviors in Multimodal Large Language Models", "comment": null, "summary": "Are frontier AI systems becoming more capable? Certainly. Yet such progress is not an unalloyed blessing but rather a Trojan horse: behind their performance leaps lie more insidious and destructive safety risks, namely deception. Unlike hallucination, which arises from insufficient capability and leads to mistakes, deception represents a deeper threat in which models deliberately mislead users through complex reasoning and insincere responses. As system capabilities advance, deceptive behaviours have spread from textual to multimodal settings, amplifying their potential harm. First and foremost, how can we monitor these covert multimodal deceptive behaviors? Nevertheless, current research remains almost entirely confined to text, leaving the deceptive risks of multimodal large language models unexplored. In this work, we systematically reveal and quantify multimodal deception risks, introducing MM-DeceptionBench, the first benchmark explicitly designed to evaluate multimodal deception. Covering six categories of deception, MM-DeceptionBench characterizes how models strategically manipulate and mislead through combined visual and textual modalities. On the other hand, multimodal deception evaluation is almost a blind spot in existing methods. Its stealth, compounded by visual-semantic ambiguity and the complexity of cross-modal reasoning, renders action monitoring and chain-of-thought monitoring largely ineffective. To tackle this challenge, we propose debate with images, a novel multi-agent debate monitor framework. By compelling models to ground their claims in visual evidence, this method substantially improves the detectability of deceptive strategies. Experiments show that it consistently increases agreement with human judgements across all tested models, boosting Cohen's kappa by 1.5x and accuracy by 1.25x on GPT-4o.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u6b3a\u9a97\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u6a21\u6001\u6b3a\u9a97\u8bc4\u4f30\u57fa\u51c6MM-DeceptionBench\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u56fe\u50cf\u8fa9\u8bba\u7684\u591a\u667a\u80fd\u4f53\u76d1\u63a7\u6846\u67b6\u6765\u68c0\u6d4b\u8fd9\u4e9b\u9690\u853d\u7684\u6b3a\u9a97\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u524d\u6cbfAI\u7cfb\u7edf\u80fd\u529b\u63d0\u5347\uff0c\u6b3a\u9a97\u884c\u4e3a\u4ece\u6587\u672c\u6269\u5c55\u5230\u591a\u6a21\u6001\u9886\u57df\uff0c\u5e26\u6765\u66f4\u9690\u853d\u548c\u7834\u574f\u6027\u7684\u5b89\u5168\u98ce\u9669\u3002\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u6587\u672c\u6b3a\u9a97\uff0c\u591a\u6a21\u6001\u6b3a\u9a97\u98ce\u9669\u5c1a\u672a\u88ab\u63a2\u7d22\uff0c\u4e14\u73b0\u6709\u76d1\u63a7\u65b9\u6cd5\u5bf9\u6b64\u7c7b\u590d\u6742\u8de8\u6a21\u6001\u6b3a\u9a97\u884c\u4e3a\u6548\u679c\u6709\u9650\u3002", "method": "1) \u6784\u5efaMM-DeceptionBench\u57fa\u51c6\uff0c\u6db5\u76d6\u516d\u7c7b\u6b3a\u9a97\u884c\u4e3a\uff0c\u8bc4\u4f30\u6a21\u578b\u901a\u8fc7\u89c6\u89c9\u548c\u6587\u672c\u6a21\u6001\u8fdb\u884c\u7b56\u7565\u6027\u64cd\u7eb5\u7684\u80fd\u529b\uff1b2) \u63d0\u51fa\"\u57fa\u4e8e\u56fe\u50cf\u7684\u8fa9\u8bba\"\u591a\u667a\u80fd\u4f53\u76d1\u63a7\u6846\u67b6\uff0c\u5f3a\u5236\u6a21\u578b\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u8bba\u8bc1\uff0c\u63d0\u9ad8\u6b3a\u9a97\u7b56\u7565\u7684\u53ef\u68c0\u6d4b\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u76d1\u63a7\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\uff0c\u5728\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u4e0a\u5747\u6709\u6548\uff0cGPT-4o\u7684Cohen's kappa\u63d0\u9ad8\u4e861.5\u500d\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e861.25\u500d\u3002", "conclusion": "\u591a\u6a21\u6001\u6b3a\u9a97\u662fAI\u5b89\u5168\u7684\u91cd\u8981\u5a01\u80c1\uff0c\u9700\u8981\u4e13\u95e8\u5de5\u5177\u8fdb\u884c\u76d1\u6d4b\u3002MM-DeceptionBench\u57fa\u51c6\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u8fa9\u8bba\u76d1\u63a7\u6846\u67b6\u4e3a\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u7c7b\u98ce\u9669\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u591a\u6a21\u6001\u6b3a\u9a97\u8bc4\u4f30\u7684\u7814\u7a76\u7a7a\u767d\u3002"}}
{"id": "2512.01035", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01035", "abs": "https://arxiv.org/abs/2512.01035", "authors": ["Shutong Chen", "Qi Liao", "Adnan Aijaz", "Yansha Deng"], "title": "Goal-Oriented Multi-Agent Semantic Networking: Unifying Intents, Semantics, and Intelligence", "comment": "Submitting to IEEE for potential publications", "summary": "6G services are evolving toward goal-oriented and AI-native communication, which are expected to deliver transformative societal benefits across various industries and promote energy sustainability. Yet today's networking architectures, built on complete decoupling of the applications and the network, cannot expose or exploit high-level goals, limiting their ability to adapt intelligently to service needs. This work introduces Goal-Oriented Multi-Agent Semantic Networking (GoAgentNet), a new architecture that elevates communication from data exchange to goal fulfilment. GoAgentNet enables applications and the network to collaborate by abstracting their functions into multiple collaborative agents, and jointly orchestrates multi-agent sensing, networking, computation, and control through semantic computation and cross-layer semantic networking, allowing the entire architecture to pursue unified application goals. We first outline the limitations of legacy network designs in supporting 6G services, based on which we highlight key enablers of our GoAgentNet design. Then, through three representative 6G usage scenarios, we demonstrate how GoAgentNet can unlock more efficient and intelligent services. We further identify unique challenges faced by GoAgentNet deployment and corresponding potential solutions. A case study on robotic fault detection and recovery shows that our GoAgentNet architecture improves energy efficiency by up to 99% and increases the task success rate by up to 72%, compared with the existing networking architectures without GoAgentNet, which underscores its potential to support scalable and sustainable 6G systems.", "AI": {"tldr": "GoAgentNet\u662f\u4e00\u79cd\u9762\u54116G\u7684\u76ee\u6807\u5bfc\u5411\u591a\u667a\u80fd\u4f53\u8bed\u4e49\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u5e94\u7528\u548c\u7f51\u7edc\u529f\u80fd\u62bd\u8c61\u4e3a\u534f\u4f5c\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u4ece\u6570\u636e\u4ea4\u6362\u5230\u76ee\u6807\u8fbe\u6210\u7684\u901a\u4fe1\u8303\u5f0f\u8f6c\u53d8\uff0c\u663e\u8457\u63d0\u5347\u80fd\u6548\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u67b6\u6784\u5c06\u5e94\u7528\u4e0e\u7f51\u7edc\u5b8c\u5168\u89e3\u8026\uff0c\u65e0\u6cd5\u66b4\u9732\u548c\u5229\u7528\u9ad8\u5c42\u76ee\u6807\uff0c\u9650\u5236\u4e86\u667a\u80fd\u9002\u5e94\u670d\u52a1\u9700\u6c42\u7684\u80fd\u529b\u30026G\u670d\u52a1\u6b63\u5411\u76ee\u6807\u5bfc\u5411\u548cAI\u539f\u751f\u901a\u4fe1\u6f14\u8fdb\uff0c\u9700\u8981\u65b0\u7684\u67b6\u6784\u652f\u6301\u80fd\u6548\u548c\u667a\u80fd\u670d\u52a1\u3002", "method": "\u63d0\u51faGoAgentNet\u67b6\u6784\uff0c\u5c06\u5e94\u7528\u548c\u7f51\u7edc\u529f\u80fd\u62bd\u8c61\u4e3a\u591a\u4e2a\u534f\u4f5c\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u8bed\u4e49\u8ba1\u7b97\u548c\u8de8\u5c42\u8bed\u4e49\u7f51\u7edc\u8054\u5408\u7f16\u6392\u591a\u667a\u80fd\u4f53\u7684\u611f\u77e5\u3001\u7f51\u7edc\u3001\u8ba1\u7b97\u548c\u63a7\u5236\uff0c\u5b9e\u73b0\u7edf\u4e00\u5e94\u7528\u76ee\u6807\u7684\u534f\u540c\u8ffd\u6c42\u3002", "result": "\u5728\u673a\u5668\u4eba\u6545\u969c\u68c0\u6d4b\u548c\u6062\u590d\u6848\u4f8b\u4e2d\uff0cGoAgentNet\u76f8\u6bd4\u73b0\u6709\u7f51\u7edc\u67b6\u6784\u80fd\u6548\u63d0\u5347\u9ad8\u8fbe99%\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe72%\uff0c\u5c55\u793a\u4e86\u652f\u6301\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed6G\u7cfb\u7edf\u7684\u6f5c\u529b\u3002", "conclusion": "GoAgentNet\u901a\u8fc7\u5c06\u901a\u4fe1\u4ece\u6570\u636e\u4ea4\u6362\u63d0\u5347\u5230\u76ee\u6807\u8fbe\u6210\uff0c\u4e3a6G\u670d\u52a1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u667a\u80fd\u7684\u67b6\u6784\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u8bc6\u522b\u4e86\u90e8\u7f72\u6311\u6218\u548c\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.00406", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00406", "abs": "https://arxiv.org/abs/2512.00406", "authors": ["Pengyu Zeng", "Yuqin Dai", "Jun Yin", "Jing Zhong", "Ziyang Han", "Chaoyang Shi", "ZhanXiang Jin", "Maowei Jiang", "Yuxing Han", "Shuai Lu"], "title": "GreenPlanner: Practical Floorplan Layout Generation via an Energy-Aware and Function-Feasible Generative Framework", "comment": "11 pages, 6 figures", "summary": "Building design directly affects human well-being and carbon emissions, yet generating spatial-functional and energy-compliant floorplans remains manual, costly, and non-scalable. Existing methods produce visually plausible layouts but frequently violate key constraints, yielding invalid results due to the absence of automated evaluation. We present GreenPlanner, an energy- and functionality-aware generative framework that unifies design evaluation and generation. It consists of a labeled Design Feasibility Dataset for learning constraint priors; a fast Practical Design Evaluator (PDE) for predicting energy performance and spatial-functional validity; a Green Plan Dataset (GreenPD) derived from PDE-guided filtering to pair user requirements with regulation-compliant layouts; and a GreenFlow generator trained on GreenPD with PDE feedback for controllable, regulation-aware generation. Experiments show that GreenPlanner accelerates evaluation by over $10^{5}\\times$ with $>$99% accuracy, eliminates invalid samples, and boosts design efficiency by 87% over professional architects.", "AI": {"tldr": "GreenPlanner\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u80fd\u6e90\u548c\u529f\u80fd\u611f\u77e5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u8bc4\u4f30\u548c\u751f\u6210\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u5efa\u7b51\u8bbe\u8ba1\u4e2d\u7a7a\u95f4\u529f\u80fd\u4e0e\u80fd\u6e90\u5408\u89c4\u6027\u7684\u6311\u6218\u3002", "motivation": "\u5efa\u7b51\u8bbe\u8ba1\u76f4\u63a5\u5f71\u54cd\u4eba\u7c7b\u798f\u7949\u548c\u78b3\u6392\u653e\uff0c\u4f46\u751f\u6210\u7a7a\u95f4\u529f\u80fd\u548c\u80fd\u6e90\u5408\u89c4\u7684\u5e73\u9762\u56fe\u4ecd\u7136\u662f\u624b\u52a8\u3001\u6602\u8d35\u4e14\u4e0d\u53ef\u6269\u5c55\u7684\u3002\u73b0\u6709\u65b9\u6cd5\u4ea7\u751f\u89c6\u89c9\u4e0a\u5408\u7406\u7684\u5e03\u5c40\uff0c\u4f46\u7ecf\u5e38\u8fdd\u53cd\u5173\u952e\u7ea6\u675f\uff0c\u7531\u4e8e\u7f3a\u4e4f\u81ea\u52a8\u5316\u8bc4\u4f30\u800c\u5bfc\u81f4\u65e0\u6548\u7ed3\u679c\u3002", "method": "GreenPlanner\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u7528\u4e8e\u5b66\u4e60\u7ea6\u675f\u5148\u9a8c\u7684\u6807\u8bb0\u8bbe\u8ba1\u53ef\u884c\u6027\u6570\u636e\u96c6\uff1b2) \u7528\u4e8e\u9884\u6d4b\u80fd\u6e90\u6027\u80fd\u548c\u7a7a\u95f4\u529f\u80fd\u6709\u6548\u6027\u7684\u5feb\u901f\u5b9e\u7528\u8bbe\u8ba1\u8bc4\u4f30\u5668(PDE)\uff1b3) \u901a\u8fc7PDE\u5f15\u5bfc\u8fc7\u6ee4\u5f97\u5230\u7684\u7eff\u8272\u5e73\u9762\u6570\u636e\u96c6(GreenPD)\uff0c\u5c06\u7528\u6237\u9700\u6c42\u4e0e\u6cd5\u89c4\u5408\u89c4\u5e03\u5c40\u914d\u5bf9\uff1b4) \u5728GreenPD\u4e0a\u8bad\u7ec3\u5e76\u4f7f\u7528PDE\u53cd\u9988\u7684GreenFlow\u751f\u6210\u5668\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u6cd5\u89c4\u611f\u77e5\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGreenPlanner\u5c06\u8bc4\u4f30\u901f\u5ea6\u52a0\u901f\u8d85\u8fc710^5\u500d\uff0c\u51c6\u786e\u7387\u8d85\u8fc799%\uff0c\u6d88\u9664\u4e86\u65e0\u6548\u6837\u672c\uff0c\u5e76\u5c06\u8bbe\u8ba1\u6548\u7387\u6bd4\u4e13\u4e1a\u5efa\u7b51\u5e08\u63d0\u9ad8\u4e8687%\u3002", "conclusion": "GreenPlanner\u901a\u8fc7\u7edf\u4e00\u8bbe\u8ba1\u8bc4\u4f30\u548c\u751f\u6210\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u5408\u89c4\u7684\u5efa\u7b51\u5e73\u9762\u56fe\u81ea\u52a8\u5316\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u8ba1\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2512.01083", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.01083", "abs": "https://arxiv.org/abs/2512.01083", "authors": ["Fatih E. Bilgen", "A. Sila Okcu", "O. Tansel Baydas", "Ozgur B. Akan"], "title": "Internet of Intelligent Reflecting Surfaces (IoIRS)", "comment": "8 pages, 3 figures", "summary": "Intelligent Reflecting Surfaces (IRS) are anticipated to serve as a key cornerstone of future wireless networks, providing an unmatched capability to deterministically shape electromagnetic wave propagation. Despite this potential, most existing research still considers the IRS merely as a standalone physical-layer component, controlled by transmitters. However, as networks grow to encompass a massive number of these surfaces and a massive number of transmitters wishing to use them, this transmitter-centric design encounters substantial challenges. To overcome this challenge, we propose the Internet of IRS (IoIRS), an architecture that reconceives the IRS not just as a passive reflecting surface, but as a connected, hybrid entity functioning across both the physical layer and upper network layers. We present the conceptual framework and a preliminary protocol suite necessary to integrate these surfaces into the higher network layers. We conclude by examining how IoIRS architectures could be applied in practice, as their deployment will be essential for fully realizing the capabilities of future wireless networks.", "AI": {"tldr": "\u63d0\u51fa\"\u667a\u80fd\u53cd\u5c04\u8868\u9762\u4e92\u8054\u7f51(IoIRS)\"\u67b6\u6784\uff0c\u5c06IRS\u4ece\u5355\u7eaf\u7269\u7406\u5c42\u7ec4\u4ef6\u91cd\u6784\u4e3a\u8de8\u7269\u7406\u5c42\u548c\u4e0a\u5c42\u7f51\u7edc\u5c42\u7684\u8fde\u63a5\u6df7\u5408\u5b9e\u4f53\uff0c\u4ee5\u89e3\u51b3\u5927\u89c4\u6a21IRS\u7f51\u7edc\u4e2d\u7684\u63a7\u5236\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06IRS\u89c6\u4e3a\u4ec5\u7531\u53d1\u5c04\u673a\u63a7\u5236\u7684\u72ec\u7acb\u7269\u7406\u5c42\u7ec4\u4ef6\uff0c\u4f46\u5728\u5927\u89c4\u6a21IRS\u7f51\u7edc\u548c\u5927\u91cf\u53d1\u5c04\u673a\u4f7f\u7528\u573a\u666f\u4e0b\uff0c\u8fd9\u79cd\u53d1\u5c04\u673a\u4e2d\u5fc3\u8bbe\u8ba1\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u9700\u8981\u65b0\u7684\u67b6\u6784\u6765\u5145\u5206\u53d1\u6325IRS\u5728\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faIoIRS\u67b6\u6784\uff0c\u5c06IRS\u91cd\u65b0\u6784\u60f3\u4e3a\u8fde\u63a5\u3001\u6df7\u5408\u7684\u5b9e\u4f53\uff0c\u8de8\u8d8a\u7269\u7406\u5c42\u548c\u4e0a\u5c42\u7f51\u7edc\u5c42\u8fd0\u884c\u3002\u63d0\u4f9b\u4e86\u6982\u5ff5\u6846\u67b6\u548c\u521d\u6b65\u534f\u8bae\u5957\u4ef6\uff0c\u4ee5\u5c06\u8fd9\u4e9b\u8868\u9762\u96c6\u6210\u5230\u66f4\u9ad8\u7f51\u7edc\u5c42\u4e2d\u3002", "result": "\u63d0\u51fa\u4e86IoIRS\u67b6\u6784\u7684\u6982\u5ff5\u6846\u67b6\u548c\u521d\u6b65\u534f\u8bae\u5957\u4ef6\uff0c\u63a2\u8ba8\u4e86\u8be5\u67b6\u6784\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5e94\u7528\u65b9\u5f0f\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u5145\u5206\u53d1\u6325IRS\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u601d\u8def\u3002", "conclusion": "IoIRS\u67b6\u6784\u5bf9\u4e8e\u5145\u5206\u53d1\u6325\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u4e2dIRS\u7684\u6f5c\u529b\u81f3\u5173\u91cd\u8981\uff0c\u5176\u90e8\u7f72\u5c06\u662f\u5b9e\u73b0\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u5168\u90e8\u80fd\u529b\u7684\u5173\u952e\u3002\u8be5\u67b6\u6784\u5c06IRS\u4ece\u88ab\u52a8\u53cd\u5c04\u8868\u9762\u8f6c\u53d8\u4e3a\u8fde\u63a5\u7684\u7f51\u7edc\u5b9e\u4f53\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u7684\u63a7\u5236\u6311\u6218\u3002"}}
{"id": "2512.01505", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.01505", "abs": "https://arxiv.org/abs/2512.01505", "authors": ["Geoffrey Deperle", "Philippe Jacquet"], "title": "Generating Random Hyperfractal Cities", "comment": null, "summary": "This paper focuses on the challenge of interactively modeling street networks. In this work, we extend the simple fractal model, which is particularly useful for describing small cities or individual districts, by constructing random cities based on a tiling structure over which hyperfractals are distributed. This approach enables the connection of multiple hyperfractal districts, providing a more comprehensive urban representation. Furthermore, we demonstrate how this decomposition can be used to segment a city into distinct districts through fractal analysis. Finally, we present tools for the numerical generation of random cities following this model.", "AI": {"tldr": "\u6269\u5c55\u7b80\u5355\u5206\u5f62\u6a21\u578b\uff0c\u901a\u8fc7\u57fa\u4e8e\u5e73\u94fa\u7ed3\u6784\u7684\u8d85\u5206\u5f62\u5206\u5e03\u6784\u5efa\u968f\u673a\u57ce\u5e02\uff0c\u8fde\u63a5\u591a\u4e2a\u8d85\u5206\u5f62\u533a\u57df\uff0c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u57ce\u5e02\u8868\u793a", "motivation": "\u89e3\u51b3\u4ea4\u4e92\u5f0f\u5efa\u6a21\u8857\u9053\u7f51\u7edc\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4e3a\u5c0f\u57ce\u5e02\u6216\u5355\u4e2a\u533a\u57df\u63d0\u4f9b\u66f4\u597d\u7684\u63cf\u8ff0\u65b9\u6cd5", "method": "\u6269\u5c55\u7b80\u5355\u5206\u5f62\u6a21\u578b\uff0c\u5728\u5e73\u94fa\u7ed3\u6784\u4e0a\u5206\u5e03\u8d85\u5206\u5f62\u6765\u6784\u5efa\u968f\u673a\u57ce\u5e02\uff0c\u8fde\u63a5\u591a\u4e2a\u8d85\u5206\u5f62\u533a\u57df", "result": "\u80fd\u591f\u5c06\u57ce\u5e02\u5206\u89e3\u4e3a\u4e0d\u540c\u533a\u57df\uff0c\u901a\u8fc7\u5206\u5f62\u5206\u6790\u8fdb\u884c\u533a\u57df\u5206\u5272\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u8be5\u6a21\u578b\u7684\u968f\u673a\u57ce\u5e02\u6570\u503c\u751f\u6210\u5de5\u5177", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u57ce\u5e02\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8868\u793a\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u8857\u9053\u7f51\u7edc\u5efa\u6a21\u548c\u57ce\u5e02\u533a\u57df\u5206\u6790"}}
{"id": "2512.00479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00479", "abs": "https://arxiv.org/abs/2512.00479", "authors": ["Yuta Kobayashi", "Vincent Jeanselme", "Shalmali Joshi"], "title": "Mind the data gap: Missingness Still Shapes Large Language Model Prognoses", "comment": "Presented at ML4H 2025 - Findings Track", "summary": "Data collection often reflects human decisions. In healthcare, for instance, a referral for a diagnostic test is influenced by the patient's health, their preferences, available resources, and the practitioner's recommendations. Despite the extensive literature on the informativeness of missingness, its implications on the performance of Large Language Models (LLMs) have not been studied. Through a series of experiments on data from Columbia University Medical Center, a large urban academic medical center, and MIMIC-IV, we demonstrate that patterns of missingness significantly impact zero-shot predictive performance. Notably, the explicit inclusion of missingness indicators at prompting benefits some while hurting other LLMs' zero-shot predictive performance and calibration, suggesting an inconsistent impact. The proposed aggregated analysis and theoretical insights suggest that larger models benefit from these interventions, while smaller models can be negatively impacted. The LLM paradigm risks obscuring the impact of missingness, often neglected even in conventional ML, even further. We conclude that there is a need for more transparent accounting and systematic evaluation of the impact of representing (informative) missingness on downstream performance.", "AI": {"tldr": "LLMs\u5728\u533b\u7597\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u96f6\u6837\u672c\u8868\u73b0\u53d7\u6570\u636e\u7f3a\u5931\u6a21\u5f0f\u663e\u8457\u5f71\u54cd\uff0c\u7f3a\u5931\u6307\u793a\u7b26\u7684\u52a0\u5165\u5bf9\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u6548\u679c\u4e0d\u4e00\u81f4\uff0c\u5927\u6a21\u578b\u53d7\u76ca\u800c\u5c0f\u6a21\u578b\u53ef\u80fd\u53d7\u635f\u3002", "motivation": "\u7814\u7a76\u7f3a\u5931\u6570\u636e\u6a21\u5f0f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u9886\u57df\uff0c\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u5b58\u5728\u5927\u91cf\u7531\u4eba\u7c7b\u51b3\u7b56\u5bfc\u81f4\u7684\u7cfb\u7edf\u6027\u7f3a\u5931\uff0c\u8fd9\u79cd\u4fe1\u606f\u6027\u7f3a\u5931\u5bf9\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u5bf9LLMs\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5728\u54e5\u4f26\u6bd4\u4e9a\u5927\u5b66\u533b\u5b66\u4e2d\u5fc3\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u7814\u7a76\u7f3a\u5931\u6a21\u5f0f\u5bf9LLMs\u96f6\u6837\u672c\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u6d4b\u8bd5\u4e86\u5728\u63d0\u793a\u4e2d\u660e\u786e\u5305\u542b\u7f3a\u5931\u6307\u793a\u7b26\u7684\u6548\u679c\u3002", "result": "\u7f3a\u5931\u6a21\u5f0f\u663e\u8457\u5f71\u54cdLLMs\u7684\u96f6\u6837\u672c\u9884\u6d4b\u6027\u80fd\uff1b\u660e\u786e\u5305\u542b\u7f3a\u5931\u6307\u793a\u7b26\u5bf9\u67d0\u4e9bLLMs\u6709\u76ca\uff0c\u4f46\u5bf9\u5176\u4ed6LLMs\u6709\u5bb3\uff0c\u5f71\u54cd\u4e0d\u4e00\u81f4\uff1b\u8f83\u5927\u6a21\u578b\u4ece\u8fd9\u4e9b\u5e72\u9884\u4e2d\u53d7\u76ca\uff0c\u800c\u8f83\u5c0f\u6a21\u578b\u53ef\u80fd\u53d7\u5230\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "LLM\u8303\u5f0f\u53ef\u80fd\u8fdb\u4e00\u6b65\u63a9\u76d6\u7f3a\u5931\u6570\u636e\u7684\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u900f\u660e\u7684\u8bb0\u5f55\u548c\u7cfb\u7edf\u8bc4\u4f30\u4fe1\u606f\u6027\u7f3a\u5931\u8868\u793a\u5bf9\u4e0b\u6e38\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u7b49\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2512.01088", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01088", "abs": "https://arxiv.org/abs/2512.01088", "authors": ["Jingxiang Huang", "Samer Lahoud"], "title": "Physical-Layer Analysis of LoRa Robustness in the Presence of Narrowband Interference", "comment": null, "summary": "With the rapid development of Internet of Things (IoT) technologies, the sub-GHz unlicensed spectrum is increasingly being shared by protocols such as Long Range (LoRa), Sigfox, and Long-Range Frequency-Hopping Spread Spectrum (LR-FHSS). These protocols must coexist within the same frequency bands, leading to mutual interference. This paper investigates the physical-layer impact of two types of narrowband signals (BPSK and GMSK) on LoRa demodulation. We employ symbol-level Monte Carlo simulations to analyse how the interference-to-noise ratio (INR) affects the symbol error rate (SER) at a given signal-to-noise ratio (SNR) and noise floor, and then compare the results with those for additive white Gaussian noise (AWGN) of equal power. We demonstrate that modelling narrowband interference as additive white Gaussian noise (AWGN) systematically overestimates the SER of Chirp Spread Spectrum (CSS) demodulation. We also clarify the distinct impairment levels induced by AWGN and two types of narrowband interferers, and provide physical insight into the underlying mechanisms. Finally, we fit a two-segment function for the maximum INR that ensures correct demodulation across SNRs, with one segment for low SNR and the other for high SNR.", "AI": {"tldr": "\u7814\u7a76\u7a84\u5e26\u5e72\u6270\uff08BPSK\u548cGMSK\uff09\u5bf9LoRa\u7269\u7406\u5c42\u89e3\u8c03\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5c06\u7a84\u5e26\u5e72\u6270\u5efa\u6a21\u4e3aAWGN\u4f1a\u7cfb\u7edf\u6027\u9ad8\u4f30CSS\u89e3\u8c03\u7684\u8bef\u7b26\u53f7\u7387\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u6280\u672f\u7684\u53d1\u5c55\uff0cSub-GHz\u514d\u8bb8\u53ef\u9891\u6bb5\u4e2dLoRa\u3001Sigfox\u3001LR-FHSS\u7b49\u534f\u8bae\u9700\u8981\u5171\u5b58\uff0c\u5bfc\u81f4\u76f8\u4e92\u5e72\u6270\u3002\u9700\u8981\u7814\u7a76\u7a84\u5e26\u5e72\u6270\u5bf9LoRa\u89e3\u8c03\u7684\u5177\u4f53\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u7b26\u53f7\u7ea7\u8499\u7279\u5361\u6d1b\u4eff\u771f\uff0c\u5206\u6790\u5e72\u6270\u566a\u58f0\u6bd4\uff08INR\uff09\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\uff08SNR\uff09\u548c\u566a\u58f0\u57fa\u5e95\u4e0b\u5bf9\u8bef\u7b26\u53f7\u7387\uff08SER\uff09\u7684\u5f71\u54cd\uff0c\u5e76\u4e0e\u7b49\u529f\u7387AWGN\u5e72\u6270\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "1. \u5c06\u7a84\u5e26\u5e72\u6270\u5efa\u6a21\u4e3aAWGN\u4f1a\u7cfb\u7edf\u6027\u9ad8\u4f30CSS\u89e3\u8c03\u7684SER\uff1b2. \u660e\u786e\u4e86AWGN\u548c\u4e24\u79cd\u7a84\u5e26\u5e72\u6270\u5668\u9020\u6210\u7684\u4e0d\u540c\u635f\u4f24\u6c34\u5e73\uff1b3. \u4e3a\u6700\u5927INR\u62df\u5408\u4e86\u4e24\u6bb5\u51fd\u6570\uff08\u4f4eSNR\u6bb5\u548c\u9ad8SNR\u6bb5\uff09\uff0c\u786e\u4fdd\u6b63\u786e\u89e3\u8c03\u3002", "conclusion": "\u7a84\u5e26\u5e72\u6270\u5bf9LoRa\u89e3\u8c03\u7684\u5f71\u54cd\u4e0eAWGN\u4e0d\u540c\uff0c\u4e0d\u80fd\u7b80\u5355\u5efa\u6a21\u4e3aAWGN\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u5e72\u6270\u673a\u5236\u7684\u7269\u7406\u6d1e\u5bdf\uff0c\u5e76\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684INR\u9608\u503c\u51fd\u6570\u3002"}}
{"id": "2512.01861", "categories": ["cs.IT", "cond-mat.dis-nn", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.01861", "abs": "https://arxiv.org/abs/2512.01861", "authors": ["Yingying Xu", "Masayuki Ohzeki", "Yoshiyuki Kabashima"], "title": "Storage capacity of perceptron with variable selection", "comment": "21 pages, 3 figures", "summary": "A central challenge in machine learning is to distinguish genuine structure from chance correlations in high-dimensional data. In this work, we address this issue for the perceptron, a foundational model of neural computation. Specifically, we investigate the relationship between the pattern load $\u03b1$ and the variable selection ratio $\u03c1$ for which a simple perceptron can perfectly classify $P = \u03b1N$ random patterns by optimally selecting $M = \u03c1N$ variables out of $N$ variables. While the Cover--Gardner theory establishes that a random subset of $\u03c1N$ dimensions can separate $\u03b1N$ random patterns if and only if $\u03b1< 2\u03c1$, we demonstrate that optimal variable selection can surpass this bound by developing a method, based on the replica method from statistical mechanics, for enumerating the combinations of variables that enable perfect pattern classification. This not only provides a quantitative criterion for distinguishing true structure in the data from spurious regularities, but also yields the storage capacity of associative memory models with sparse asymmetric couplings.", "AI": {"tldr": "\u611f\u77e5\u673a\u5728\u6700\u4f18\u53d8\u91cf\u9009\u62e9\u4e0b\u53ef\u4ee5\u8d85\u8d8aCover-Gardner\u7406\u8bba\u754c\u9650\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u6a21\u5f0f\u5206\u7c7b\u6027\u80fd", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u533a\u5206\u9ad8\u7ef4\u6570\u636e\u4e2d\u771f\u5b9e\u7ed3\u6784\u4e0e\u5076\u7136\u76f8\u5173\u6027\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4e3a\u611f\u77e5\u673a\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u5206\u6790", "method": "\u57fa\u4e8e\u7edf\u8ba1\u529b\u5b66\u4e2d\u7684\u526f\u672c\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u679a\u4e3e\u80fd\u591f\u5b9e\u73b0\u5b8c\u7f8e\u6a21\u5f0f\u5206\u7c7b\u7684\u53d8\u91cf\u7ec4\u5408\u7684\u65b9\u6cd5", "result": "\u6700\u4f18\u53d8\u91cf\u9009\u62e9\u53ef\u4ee5\u8d85\u8d8aCover-Gardner\u7406\u8bba\u754c\u9650\uff08\u03b1<2\u03c1\uff09\uff0c\u63d0\u4f9b\u4e86\u533a\u5206\u6570\u636e\u771f\u5b9e\u7ed3\u6784\u4e0e\u865a\u5047\u89c4\u5f8b\u6027\u7684\u5b9a\u91cf\u6807\u51c6", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4e3a\u611f\u77e5\u673a\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u8fd8\u5f97\u5230\u4e86\u5177\u6709\u7a00\u758f\u975e\u5bf9\u79f0\u8026\u5408\u7684\u8054\u60f3\u8bb0\u5fc6\u6a21\u578b\u7684\u5b58\u50a8\u5bb9\u91cf"}}
{"id": "2512.00601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00601", "abs": "https://arxiv.org/abs/2512.00601", "authors": ["Boyang Gu", "Hongjian Zhou", "Bradley Max Segal", "Jinge Wu", "Zeyu Cao", "Hantao Zhong", "Lei Clifton", "Fenglin Liu", "David A. Clifton"], "title": "Clinical-R1: Empowering Large Language Models for Faithful and Comprehensive Reasoning with Clinical Objective Relative Policy Optimization", "comment": null, "summary": "Recent advances in large language models (LLMs) have shown strong reasoning capabilities through large-scale pretraining and post-training reinforcement learning, demonstrated by DeepSeek-R1. However, current post-training methods, such as Grouped Relative Policy Optimization (GRPO), mainly reward correctness, which is not aligned with the multi-dimensional objectives required in high-stakes fields such as medicine, where reasoning must also be faithful and comprehensive. We introduce Clinical-Objective Relative Policy Optimization (CRPO), a scalable, multi-objective, verifiable reinforcement learning method designed to align LLM post-training with clinical reasoning principles. CRPO integrates rule-based and verifiable reward signals that jointly optimize accuracy, faithfulness, and comprehensiveness without relying on human annotation. To demonstrate its effectiveness, we train Clinical-R1-3B, a 3B-parameter model for clinical reasoning. The experiments on three benchmarks demonstrate that our CRPO substantially improves reasoning on truthfulness and completeness over standard GRPO while maintaining comfortable accuracy enhancements. This framework provides a scalable pathway to align LLM reasoning with clinical objectives, enabling safer and more collaborative AI systems for healthcare while also highlighting the potential of multi-objective, verifiable RL methods in post-training scaling of LLMs for medical domains.", "AI": {"tldr": "CRPO\u662f\u4e00\u79cd\u7528\u4e8e\u4e34\u5e8a\u63a8\u7406\u7684\u591a\u76ee\u6807\u53ef\u9a8c\u8bc1\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u89c4\u5219\u548c\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u540c\u65f6\u4f18\u5316\u51c6\u786e\u6027\u3001\u5fe0\u5b9e\u6027\u548c\u5168\u9762\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u5f53\u524d\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff08\u5982GRPO\uff09\u4e3b\u8981\u5956\u52b1\u6b63\u786e\u6027\uff0c\u8fd9\u4e0e\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u6240\u9700\u7684\u591a\u7ef4\u76ee\u6807\uff08\u9700\u8981\u63a8\u7406\u5fe0\u5b9e\u4e14\u5168\u9762\uff09\u4e0d\u4e00\u81f4\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5bf9\u9f50\u4e34\u5e8a\u63a8\u7406\u539f\u5219\u7684LLM\u540e\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u76ee\u6807\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08CRPO\uff09\uff0c\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u591a\u76ee\u6807\u3001\u53ef\u9a8c\u8bc1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u6574\u5408\u57fa\u4e8e\u89c4\u5219\u548c\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u8054\u5408\u4f18\u5316\u51c6\u786e\u6027\u3001\u5fe0\u5b9e\u6027\u548c\u5168\u9762\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002\u8bad\u7ec3\u4e863B\u53c2\u6570\u7684Clinical-R1-3B\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCRPO\u5728\u771f\u5b9e\u6027\u548c\u5b8c\u6574\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6807\u51c6GRPO\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u51c6\u786e\u6027\u63d0\u5347\u3002Clinical-R1-3B\u6a21\u578b\u5728\u4e34\u5e8a\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "CRPO\u6846\u67b6\u4e3a\u5c06LLM\u63a8\u7406\u4e0e\u4e34\u5e8a\u76ee\u6807\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9014\u5f84\uff0c\u5b9e\u73b0\u4e86\u66f4\u5b89\u5168\u3001\u66f4\u534f\u4f5c\u7684\u533b\u7597AI\u7cfb\u7edf\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u591a\u76ee\u6807\u53ef\u9a8c\u8bc1RL\u65b9\u6cd5\u5728\u533b\u5b66\u9886\u57dfLLM\u540e\u8bad\u7ec3\u6269\u5c55\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.01477", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01477", "abs": "https://arxiv.org/abs/2512.01477", "authors": ["Saso Nikolovski", "Pece Mitrevski"], "title": "Modeling and Simulation of Data Protection Systems for Business Continuity and Disaster Recovery", "comment": "17 pages, 11 figures, 9 tables", "summary": "In today's corporate landscape, particularly where operations rely heavily on information technologies, establishing a robust business continuity plan, including a disaster recovery strategy, is essential for ensuring swift recuperation following outages. This study presents a comparative analysis of recovery solutions, focusing on systems that operate partially or entirely within cloud environments and assessing their reliability in fulfilling organizational roles securely and dependably. Two such systems were deployed and evaluated in a real-world production setting. Key performance and reliability metrics were identified using simulation software to enhance these systems, alongside a System Dynamics analysis conducted for each. This work proposes a comprehensive framework for selecting and maintaining data protection and recovery solutions within organizational structures, outlining criteria for aligning chosen approaches with operational needs while adhering to predetermined timelines specified in business continuity and disaster recovery plans. The resulting analysis and findings offer actionable insights to guide decision-making when selecting appropriate recovery concepts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u9009\u62e9\u548c\u7ef4\u62a4\u7ec4\u7ec7\u5185\u6570\u636e\u4fdd\u62a4\u4e0e\u6062\u590d\u89e3\u51b3\u65b9\u6848\u7684\u7efc\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e91\u73af\u5883\u4e2d\u7684\u6062\u590d\u7cfb\u7edf\uff0c\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u8bc4\u4f30\u5176\u53ef\u9760\u6027\uff0c\u4e3a\u4e1a\u52a1\u8fde\u7eed\u6027\u8ba1\u5212\u63d0\u4f9b\u51b3\u7b56\u6307\u5bfc\u3002", "motivation": "\u5728\u5f53\u4eca\u4f9d\u8d56\u4fe1\u606f\u6280\u672f\u7684\u4f01\u4e1a\u73af\u5883\u4e2d\uff0c\u5efa\u7acb\u5305\u542b\u707e\u96be\u6062\u590d\u7b56\u7565\u7684\u7a33\u5065\u4e1a\u52a1\u8fde\u7eed\u6027\u8ba1\u5212\u5bf9\u4e8e\u786e\u4fdd\u5728\u4e2d\u65ad\u540e\u5feb\u901f\u6062\u590d\u81f3\u5173\u91cd\u8981\u3002\u7ec4\u7ec7\u9700\u8981\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u548c\u7ef4\u62a4\u6570\u636e\u4fdd\u62a4\u4e0e\u6062\u590d\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u5bf9\u90e8\u5206\u6216\u5b8c\u5168\u5728\u4e91\u73af\u5883\u4e2d\u8fd0\u884c\u7684\u7cfb\u7edf\u8fdb\u884c\u6062\u590d\u89e3\u51b3\u65b9\u6848\u7684\u6bd4\u8f83\u5206\u6790\uff1b2) \u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u548c\u8bc4\u4f30\u4e24\u4e2a\u7cfb\u7edf\uff1b3) \u4f7f\u7528\u4eff\u771f\u8f6f\u4ef6\u8bc6\u522b\u5173\u952e\u6027\u80fd\u548c\u53ef\u9760\u6027\u6307\u6807\uff1b4) \u5bf9\u6bcf\u4e2a\u7cfb\u7edf\u8fdb\u884c\u7cfb\u7edf\u52a8\u529b\u5b66\u5206\u6790\uff1b5) \u63d0\u51fa\u9009\u62e9\u548c\u7ef4\u62a4\u6570\u636e\u4fdd\u62a4\u4e0e\u6062\u590d\u89e3\u51b3\u65b9\u6848\u7684\u7efc\u5408\u6846\u67b6\u3002", "result": "\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u8bc4\u4f30\u4e86\u4e24\u4e2a\u6062\u590d\u7cfb\u7edf\uff0c\u901a\u8fc7\u4eff\u771f\u8f6f\u4ef6\u8bc6\u522b\u4e86\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u8fdb\u884c\u4e86\u7cfb\u7edf\u52a8\u529b\u5b66\u5206\u6790\uff0c\u6700\u7ec8\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\uff0c\u4e3a\u9009\u62e9\u9002\u5f53\u7684\u6062\u590d\u6982\u5ff5\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u5e2e\u52a9\u7ec4\u7ec7\u6839\u636e\u8fd0\u8425\u9700\u6c42\u9009\u62e9\u548c\u7ef4\u62a4\u6570\u636e\u4fdd\u62a4\u4e0e\u6062\u590d\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u9075\u5faa\u4e1a\u52a1\u8fde\u7eed\u6027\u548c\u707e\u96be\u6062\u590d\u8ba1\u5212\u4e2d\u9884\u5b9a\u7684\u65f6\u95f4\u8868\uff0c\u4e3a\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2512.01985", "categories": ["cs.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.01985", "abs": "https://arxiv.org/abs/2512.01985", "authors": ["Daniel T. Larsson", "Dipankar Maity", "Panagiotis Tsiotras"], "title": "A Dual Approach for Hierarchical Information-Theoretic Tree Abstractions", "comment": null, "summary": "In this paper, we consider establishing a formal connection between two distinct tree-abstraction problems inspired by the information-bottleneck (IB) method. Specifically, we consider the hard- and soft-constrained formulations that have recently appeared in the literature to determine the conditions for which the two approaches are equivalent. Our analysis leverages concepts from Lagrangian relaxation and duality theory to relate the dual function of the hard-constrained problem to the Q-function employed in Q-tree search and shows the connection between tree phase transitions and solutions to the dual problem obtained by exploiting the problem structure. An algorithm is proposed that employs knowledge of the tree phase transitions to find a setting of the dual variable that solves the dual problem. Furthermore, we present an alternative approach to select the dual variable that leverages the integer programming formulation of the hard-constrained problem and the strong duality of linear programming. To obtain a linear program, we establish that a relaxation of the integer programming formulation of the hard-constrained tree-search problem has the integrality property by showing that the program constraint matrix is totally unimodular. Empirical results that corroborate the theoretical developments are presented and discussed throughout.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u6811\u62bd\u8c61\u95ee\u9898\u4e4b\u95f4\u7684\u5f62\u5f0f\u5316\u8fde\u63a5\uff0c\u5229\u7528\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u548c\u5bf9\u5076\u7406\u8bba\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\u7684\u7b49\u4ef7\u6761\u4ef6\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6811\u76f8\u53d8\u548c\u5bf9\u5076\u53d8\u91cf\u9009\u62e9\u7684\u7b97\u6cd5\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u662f\u5efa\u7acb\u4fe1\u606f\u74f6\u9888\u65b9\u6cd5\u542f\u53d1\u7684\u4e24\u79cd\u4e0d\u540c\u6811\u62bd\u8c61\u95ee\u9898\uff08\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u516c\u5f0f\uff09\u4e4b\u95f4\u7684\u5f62\u5f0f\u5316\u8fde\u63a5\uff0c\u786e\u5b9a\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0b\u662f\u7b49\u4ef7\u7684\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5229\u7528\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u548c\u5bf9\u5076\u7406\u8bba\u5c06\u786c\u7ea6\u675f\u95ee\u9898\u7684\u5bf9\u5076\u51fd\u6570\u4e0eQ\u6811\u641c\u7d22\u4e2d\u7684Q\u51fd\u6570\u8054\u7cfb\u8d77\u6765\uff1b2\uff09\u5206\u6790\u6811\u76f8\u53d8\u4e0e\u5bf9\u5076\u95ee\u9898\u89e3\u7684\u5173\u7cfb\uff1b3\uff09\u63d0\u51fa\u57fa\u4e8e\u6811\u76f8\u53d8\u77e5\u8bc6\u5bfb\u627e\u5bf9\u5076\u53d8\u91cf\u8bbe\u7f6e\u7684\u7b97\u6cd5\uff1b4\uff09\u901a\u8fc7\u6574\u6570\u89c4\u5212\u516c\u5f0f\u548c\u7ebf\u6027\u89c4\u5212\u5f3a\u5bf9\u5076\u6027\u9009\u62e9\u5bf9\u5076\u53d8\u91cf\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff1a1\uff09\u5efa\u7acb\u4e86\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u6811\u62bd\u8c61\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u8fde\u63a5\uff1b2\uff09\u8bc1\u660e\u4e86\u786c\u7ea6\u675f\u6811\u641c\u7d22\u95ee\u9898\u7684\u6574\u6570\u89c4\u5212\u677e\u5f1b\u5177\u6709\u5b8c\u6574\u6027\u6027\u8d28\uff08\u7ea6\u675f\u77e9\u9635\u5b8c\u5168\u5355\u6a21\uff09\uff1b3\uff09\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u627e\u5230\u89e3\u51b3\u5bf9\u5076\u95ee\u9898\u7684\u5bf9\u5076\u53d8\u91cf\u8bbe\u7f6e\uff1b4\uff09\u5b9e\u8bc1\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u5c55\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u5efa\u7acb\u4e86\u4e24\u79cd\u6811\u62bd\u8c61\u95ee\u9898\u4e4b\u95f4\u7684\u5f62\u5f0f\u5316\u8fde\u63a5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5bf9\u5076\u7406\u8bba\u548c\u6811\u76f8\u53d8\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4fe1\u606f\u74f6\u9888\u65b9\u6cd5\u5728\u6811\u62bd\u8c61\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.00670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00670", "abs": "https://arxiv.org/abs/2512.00670", "authors": ["He-Yen Hsieh", "Hong Wang", "H. T. Kung"], "title": "EDIT: Early Diffusion Inference Termination for dLLMs Based on Dynamics of Training Gradients", "comment": "22 pages, 11 figures", "summary": "Diffusion-based large language models (dLLMs) refine token generations through iterative denoising, but answers often stabilize before all steps complete. We propose EDIT (Early Diffusion Inference Termination), an inference-time criterion that adaptively stops denoising once sufficient reasoning stability relative to training-time reasoning is detected. EDIT monitors the alignment between token activations and a reasoning map derived from AdamW-aggregated LoRA updates captured during supervised fine-tuning (SFT). During training, optimization dynamics generate rich metadata about parameter importance that in prior methods is typically discarded upon model release. We preserve this information as a compact representation of learned reasoning pathways. During inference, alignment scores are converted to a distribution over the tokens already unmasked at the current denoising step, and convergence is detected when KL divergence between consecutive steps falls below a threshold on the matched unmasked (visible) tokens. Across reasoning benchmarks, EDIT reduces diffusion steps by 11.8% to 68.3% while preserving or improving accuracy in most settings, with approximately 0.02% storage overhead (about 1.5-2 MB for all QKV modules across 32 blocks in an 8 GB model). By utilizing training-gradient dynamics, our work opens a new research direction for reducing dLLM inference time and cost.", "AI": {"tldr": "EDIT\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bad\u7ec3\u68af\u5ea6\u52a8\u6001\u7684\u65e9\u671f\u6269\u6563\u63a8\u7406\u7ec8\u6b62\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u6d4btoken\u6fc0\u6d3b\u4e0e\u63a8\u7406\u56fe\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u5730\u505c\u6b62\u53bb\u566a\u6b65\u9aa4\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8fed\u4ee3\u53bb\u566a\u751f\u6210token\uff0c\u4f46\u7b54\u6848\u901a\u5e38\u5728\u5b8c\u6210\u6240\u6709\u6b65\u9aa4\u524d\u5c31\u5df2\u7a33\u5b9a\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u53d1\u5e03\u65f6\u4e22\u5f03\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e30\u5bcc\u7684\u4f18\u5316\u52a8\u6001\u5143\u6570\u636e\uff0c\u800c\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u7528\u4e8e\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "EDIT\u65b9\u6cd5\uff1a1\uff09\u5728\u76d1\u7763\u5fae\u8c03\u671f\u95f4\u6355\u83b7AdamW\u805a\u5408\u7684LoRA\u66f4\u65b0\uff0c\u6784\u5efa\u63a8\u7406\u56fe\uff1b2\uff09\u63a8\u7406\u65f6\u76d1\u6d4btoken\u6fc0\u6d3b\u4e0e\u63a8\u7406\u56fe\u7684\u5bf9\u9f50\u60c5\u51b5\uff1b3\uff09\u5c06\u5bf9\u9f50\u5206\u6570\u8f6c\u6362\u4e3a\u5df2\u89e3\u63a9\u7801token\u7684\u5206\u5e03\uff1b4\uff09\u5f53\u8fde\u7eed\u6b65\u9aa4\u95f4KL\u6563\u5ea6\u4f4e\u4e8e\u9608\u503c\u65f6\u68c0\u6d4b\u6536\u655b\u5e76\u7ec8\u6b62\u53bb\u566a\u3002", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEDIT\u5c06\u6269\u6563\u6b65\u9aa4\u51cf\u5c1111.8%\u81f368.3%\uff0c\u540c\u65f6\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5b58\u50a8\u5f00\u9500\u4ec5\u7ea60.02%\uff08\u5bf9\u4e8e8GB\u6a21\u578b\u7ea61.5-2MB\uff09\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u8bad\u7ec3\u68af\u5ea6\u52a8\u6001\uff0cEDIT\u4e3a\u51cf\u5c11\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u95f4\u548c\u6210\u672c\u5f00\u8f9f\u4e86\u65b0\u7814\u7a76\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u63a8\u7406\u7ec8\u6b62\u3002"}}
{"id": "2512.01571", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01571", "abs": "https://arxiv.org/abs/2512.01571", "authors": ["Xiao Xu", "Qiong Wu", "Pingyi Fan", "Kezhi Wang", "Nan Cheng", "Wen Chen", "Khaled B. Letaief"], "title": "Velocity-Adaptive Access Scheme for Semantic-Aware Vehicular Networks: Joint Fairness and AoI Optimization", "comment": "This paper has been submitted to IEEE transactions on moblie computing", "summary": "In this paper, we address the problem of fair access and Age of Information (AoI) optimization in 5G New Radio (NR) Vehicle to Everything (V2X) Mode 2. Specifically, vehicles need to exchange information with the road side unit (RSU). However, due to the varying vehicle speeds leading to different communication durations, the amount of data exchanged between different vehicles and the RSU may vary. This may poses significant safety risks in high-speed environments. To address this, we define a fairness index through tuning the selection window of different vehicles and consider the image semantic communication system to reduce latency. However, adjusting the selection window may affect the communication time, thereby impacting the AoI. Moreover, considering the re-evaluation mechanism in 5G NR, which helps reduce resource collisions, it may lead to an increase in AoI. We analyze the AoI using Stochastic Hybrid System (SHS) and construct a multi-objective optimization problem to achieve fair access and AoI optimization. Sequential Convex Approximation (SCA) is employed to transform the non-convex problem into a convex one, and solve it using convex optimization. We also provide a large language model (LLM) based algorithm. The scheme's effectiveness is validated through numerical simulations.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf95G NR V2X Mode 2\u4e2d\u7684\u516c\u5e73\u63a5\u5165\u548cAoI\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8c03\u6574\u9009\u62e9\u7a97\u53e3\u5b9e\u73b0\u516c\u5e73\u6027\uff0c\u91c7\u7528\u56fe\u50cf\u8bed\u4e49\u901a\u4fe1\u964d\u4f4e\u5ef6\u8fdf\uff0c\u4f7f\u7528SHS\u5206\u6790AoI\uff0c\u6784\u5efa\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u5e76\u7528SCA\u548c\u51f8\u4f18\u5316\u6c42\u89e3\uff0c\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u7b97\u6cd5\u3002", "motivation": "\u57285G NR V2X Mode 2\u4e2d\uff0c\u8f66\u8f86\u4e0eRSU\u901a\u4fe1\u65f6\uff0c\u7531\u4e8e\u8f66\u901f\u5dee\u5f02\u5bfc\u81f4\u901a\u4fe1\u65f6\u957f\u4e0d\u540c\uff0c\u9020\u6210\u6570\u636e\u4f20\u8f93\u91cf\u4e0d\u5747\uff0c\u8fd9\u5728\u9ad8\u901f\u73af\u5883\u4e0b\u5e26\u6765\u5b89\u5168\u9690\u60a3\u3002\u540c\u65f6\uff0c\u8c03\u6574\u9009\u62e9\u7a97\u53e3\u4f1a\u5f71\u54cd\u901a\u4fe1\u65f6\u95f4\u4ece\u800c\u5f71\u54cdAoI\uff0c\u800c5G NR\u7684\u91cd\u8bc4\u4f30\u673a\u5236\u867d\u51cf\u5c11\u8d44\u6e90\u78b0\u649e\u4f46\u53ef\u80fd\u589e\u52a0AoI\u3002", "method": "1) \u901a\u8fc7\u8c03\u6574\u4e0d\u540c\u8f66\u8f86\u7684\u9009\u62e9\u7a97\u53e3\u5b9a\u4e49\u516c\u5e73\u6307\u6570\uff1b2) \u91c7\u7528\u56fe\u50cf\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u964d\u4f4e\u5ef6\u8fdf\uff1b3) \u4f7f\u7528\u968f\u673a\u6df7\u5408\u7cfb\u7edf(SHS)\u5206\u6790AoI\uff1b4) \u6784\u5efa\u516c\u5e73\u63a5\u5165\u548cAoI\u4f18\u5316\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff1b5) \u91c7\u7528\u987a\u5e8f\u51f8\u903c\u8fd1(SCA)\u5c06\u975e\u51f8\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u95ee\u9898\uff1b6) \u4f7f\u7528\u51f8\u4f18\u5316\u6c42\u89e3\uff1b7) \u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u8bc1\u516c\u5e73\u63a5\u5165\u7684\u540c\u65f6\u4f18\u5316AoI\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e865G NR V2X Mode 2\u4e2d\u7684\u516c\u5e73\u63a5\u5165\u548cAoI\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8c03\u6574\u9009\u62e9\u7a97\u53e3\u3001\u91c7\u7528\u8bed\u4e49\u901a\u4fe1\u3001\u6784\u5efa\u4f18\u5316\u95ee\u9898\u5e76\u5229\u7528SCA\u548c\u51f8\u4f18\u5316\u6c42\u89e3\uff0c\u5b9e\u73b0\u4e86\u516c\u5e73\u6027\u548c\u4fe1\u606f\u65b0\u9c9c\u5ea6\u7684\u5e73\u8861\uff0c\u4e3a\u9ad8\u901f\u8f66\u8054\u7f51\u73af\u5883\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00683", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00683", "abs": "https://arxiv.org/abs/2512.00683", "authors": ["Wu Yonggang"], "title": "Model of human cognition", "comment": null, "summary": "The development of large language models (LLMs) is limited by a lack of explainability, the absence of a unifying theory, and prohibitive operational costs. We propose a neuro-theoretical framework for the emergence of intelligence in systems that is both functionally robust and biologically plausible. The model provides theoretical insights into cognitive processes such as decision-making and problem solving, and a computationally efficient approach for the creation of explainable and generalizable artificial intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91ca\u667a\u80fd\u7cfb\u7edf\u5982\u4f55\u6d8c\u73b0\uff0c\u517c\u5177\u529f\u80fd\u9c81\u68d2\u6027\u548c\u751f\u7269\u5408\u7406\u6027\uff0c\u4e3a\u521b\u5efa\u53ef\u89e3\u91ca\u3001\u53ef\u6cdb\u5316AI\u63d0\u4f9b\u8ba1\u7b97\u9ad8\u6548\u65b9\u6cd5", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e09\u5927\u9650\u5236\uff1a\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u7f3a\u5c11\u7edf\u4e00\u7406\u8bba\u3001\u8fd0\u8425\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u89e3\u91ca\u667a\u80fd\u6d8c\u73b0\u53c8\u5177\u6709\u751f\u7269\u5408\u7406\u6027\u7684\u7406\u8bba\u6846\u67b6", "method": "\u63d0\u51fa\u795e\u7ecf\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u795e\u7ecf\u79d1\u5b66\u548c\u7406\u8bba\u89d2\u5ea6\u89e3\u91ca\u667a\u80fd\u7cfb\u7edf\u7684\u6d8c\u73b0\u673a\u5236\uff0c\u8be5\u6846\u67b6\u65e2\u8003\u8651\u529f\u80fd\u9c81\u68d2\u6027\u53c8\u4fdd\u6301\u751f\u7269\u5408\u7406\u6027", "result": "\u8be5\u6a21\u578b\u4e3a\u51b3\u7b56\u5236\u5b9a\u3001\u95ee\u9898\u89e3\u51b3\u7b49\u8ba4\u77e5\u8fc7\u7a0b\u63d0\u4f9b\u7406\u8bba\u6d1e\u89c1\uff0c\u5e76\u4e3a\u521b\u5efa\u53ef\u89e3\u91ca\u3001\u53ef\u6cdb\u5316\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u795e\u7ecf\u7406\u8bba\u6846\u67b6\u4e3a\u89e3\u51b3LLM\u7684\u53ef\u89e3\u91ca\u6027\u3001\u7406\u8bba\u7edf\u4e00\u6027\u548c\u6210\u672c\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u6709\u671b\u63a8\u52a8\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u89e3\u91ca\u7684AI\u7cfb\u7edf\u53d1\u5c55"}}
{"id": "2512.01824", "categories": ["cs.NI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.01824", "abs": "https://arxiv.org/abs/2512.01824", "authors": ["J\u00e9ssica Consci\u00eancia", "Ant\u00f3nio Grilo"], "title": "HERMES: Heterogeneous Application-Enabled Routing Middleware for Edge-IoT Systems", "comment": "14 pages", "summary": "The growth of the Internet of Things has enabled a new generation of applications, pushing computation and intelligence toward the network edge. This trend, however, exposes challenges, as the heterogeneity of devices and the complex requirements of applications are often misaligned with the assumptions of traditional routing protocols, which lack the flexibility to accommodate application-layer metrics and policies. This work addresses this gap by proposing a software framework that enhances routing flexibility by dynamically incorporating application-aware decisions. The core of the work establishes a multi-hop Wi-Fi network of heterogeneous devices, specifically ESP8266, ESP32, and Raspberry Pi 3B. The routing layer follows a proactive approach, while the network is fault-tolerant, maintaining operation despite both node loss and message loss. On top of this, a middleware layer introduces three strategies for influencing routing behavior: two adapt the path a message traverses until arriving at the destination, while the third allows applications to shape the network topology. This layer offers a flexible interface for diverse applications. The framework was validated on a physical testbed through edge intelligence use cases, including distributing neural network inference computations across multiple devices and offloading the entire workload to the most capable node. Distributed inference is useful in scenarios requiring low latency, energy efficiency, privacy, and autonomy. Experimental results indicated that device heterogeneity significantly impacts network performance. Throughput and inference duration analysis showed the influence of the strategies on application behaviour, revealed that topology critically affects decentralized performance, and demonstrated the suitability of the framework for complex tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8f6f\u4ef6\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u5e94\u7528\u611f\u77e5\u51b3\u7b56\u6765\u589e\u5f3a\u8def\u7531\u7075\u6d3b\u6027\uff0c\u5728\u5f02\u6784\u8bbe\u5907\u7ec4\u6210\u7684\u591a\u8df3Wi-Fi\u7f51\u7edc\u4e2d\u5b9e\u73b0\u8fb9\u7f18\u667a\u80fd\u5e94\u7528\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u5f02\u6784\u6027\u548c\u5e94\u7528\u590d\u6742\u9700\u6c42\u4e0e\u4f20\u7edf\u8def\u7531\u534f\u8bae\u5047\u8bbe\u4e0d\u5339\u914d\uff0c\u4f20\u7edf\u8def\u7531\u7f3a\u4e4f\u7075\u6d3b\u6027\u6765\u9002\u5e94\u5e94\u7528\u5c42\u6307\u6807\u548c\u7b56\u7565\u3002", "method": "\u5efa\u7acb\u7531ESP8266\u3001ESP32\u548cRaspberry Pi 3B\u7ec4\u6210\u7684\u591a\u8df3Wi-Fi\u7f51\u7edc\uff0c\u91c7\u7528\u4e3b\u52a8\u5f0f\u8def\u7531\u5c42\u548c\u5bb9\u9519\u673a\u5236\uff0c\u4e2d\u95f4\u4ef6\u5c42\u63d0\u4f9b\u4e09\u79cd\u8def\u7531\u7b56\u7565\uff1a\u4e24\u79cd\u8c03\u6574\u6d88\u606f\u8def\u5f84\uff0c\u4e00\u79cd\u5141\u8bb8\u5e94\u7528\u5851\u9020\u7f51\u7edc\u62d3\u6251\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u8bbe\u5907\u5f02\u6784\u6027\u663e\u8457\u5f71\u54cd\u7f51\u7edc\u6027\u80fd\uff0c\u541e\u5410\u91cf\u548c\u63a8\u7406\u6301\u7eed\u65f6\u95f4\u5206\u6790\u8868\u660e\u7b56\u7565\u5f71\u54cd\u5e94\u7528\u884c\u4e3a\uff0c\u62d3\u6251\u5bf9\u53bb\u4e2d\u5fc3\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u6846\u67b6\u9002\u5408\u590d\u6742\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5e94\u7528\u611f\u77e5\u8def\u7531\u589e\u5f3a\u4e86\u8fb9\u7f18\u8ba1\u7b97\u7f51\u7edc\u7684\u7075\u6d3b\u6027\uff0c\u80fd\u591f\u652f\u6301\u5206\u5e03\u5f0f\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u7b49\u8fb9\u7f18\u667a\u80fd\u5e94\u7528\uff0c\u9002\u5e94\u5f02\u6784\u8bbe\u5907\u73af\u5883\u3002"}}
{"id": "2512.00709", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00709", "abs": "https://arxiv.org/abs/2512.00709", "authors": ["Yifan Xu", "Xichen Ye", "Yifan Chen", "Qiaosheng Zhang"], "title": "When Human Preferences Flip: An Instance-Dependent Robust Loss for RLHF", "comment": "Accepted by AAAI-26-AIA", "summary": "Quality of datasets plays an important role in large language model (LLM) alignment. In collecting human feedback, however, preference flipping is ubiquitous and causes corruption in data annotation; the issue necessitates the alignment algorithms with improved robustness against potential flipped pairs. To this end, this paper introduces a Flipping-Aware Direct Preference Optimization (FA-DPO) algorithm tailored to preference flipping from a reinforcement learning with human feedback (RLHF) perspective. We dissect the inherent human intention model and the preference flipping mechanism introduced by external factors as two distinct stages; in the latter, we introduce an instance-dependent flipping probability on the basis of the Bradley-Terry (BT) model. Further, by leveraging features relevant to preference annotation, we capture uncertainty in judgments and model preference flipping patterns. In practice, we design a simple yet efficient iterative optimization algorithm compatible with the original RLHF and DPO algorithms. In our experiments, we investigate the instance-dependent preference flipping model under multiple circumstances for evaluation of our proposed method, as well as other baseline methods.", "AI": {"tldr": "FA-DPO\uff1a\u9488\u5bf9\u4eba\u7c7b\u53cd\u9988\u4e2d\u666e\u904d\u5b58\u5728\u7684\u504f\u597d\u7ffb\u8f6c\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u7ffb\u8f6c\u611f\u77e5\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u5efa\u6a21\u5b9e\u4f8b\u4f9d\u8d56\u7684\u7ffb\u8f6c\u6982\u7387\u6765\u589e\u5f3a\u5bf9\u9f50\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u6570\u636e\u96c6\u8d28\u91cf\u5bf9LLM\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4eba\u7c7b\u53cd\u9988\u6536\u96c6\u8fc7\u7a0b\u4e2d\u666e\u904d\u5b58\u5728\u504f\u597d\u7ffb\u8f6c\u95ee\u9898\uff0c\u5bfc\u81f4\u6570\u636e\u6807\u6ce8\u88ab\u6c61\u67d3\uff0c\u9700\u8981\u5f00\u53d1\u5bf9\u6f5c\u5728\u7ffb\u8f6c\u5bf9\u5177\u6709\u66f4\u5f3a\u9c81\u68d2\u6027\u7684\u5bf9\u9f50\u7b97\u6cd5\u3002", "method": "\u4eceRLHF\u89c6\u89d2\u51fa\u53d1\uff0c\u5c06\u5185\u5728\u4eba\u7c7b\u610f\u56fe\u6a21\u578b\u548c\u5916\u90e8\u56e0\u7d20\u5f15\u5165\u7684\u504f\u597d\u7ffb\u8f6c\u673a\u5236\u89e3\u8026\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1b\u5728\u540e\u4e00\u9636\u6bb5\u57fa\u4e8eBradley-Terry\u6a21\u578b\u5f15\u5165\u5b9e\u4f8b\u4f9d\u8d56\u7684\u7ffb\u8f6c\u6982\u7387\uff0c\u5229\u7528\u504f\u597d\u6807\u6ce8\u76f8\u5173\u7279\u5f81\u6355\u6349\u5224\u65ad\u4e0d\u786e\u5b9a\u6027\u548c\u504f\u597d\u7ffb\u8f6c\u6a21\u5f0f\uff1b\u8bbe\u8ba1\u7b80\u5355\u9ad8\u6548\u7684\u8fed\u4ee3\u4f18\u5316\u7b97\u6cd5\uff0c\u517c\u5bb9\u539f\u59cbRLHF\u548cDPO\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u8bc4\u4f30\u4e86\u5b9e\u4f8b\u4f9d\u8d56\u7684\u504f\u597d\u7ffb\u8f6c\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "FA-DPO\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4eba\u7c7b\u53cd\u9988\u4e2d\u7684\u504f\u597d\u7ffb\u8f6c\u95ee\u9898\uff0c\u63d0\u9ad8LLM\u5bf9\u9f50\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5b58\u5728\u6807\u6ce8\u566a\u58f0\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01829", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01829", "abs": "https://arxiv.org/abs/2512.01829", "authors": ["Salah Abdeljabar", "Marco Zennaro", "Mohamed-Slim Alouini"], "title": "Delay Tolerant Networking to Extend Connectivity in Rural Areas Using Public Transport Systems: Design And Analysis", "comment": null, "summary": "In today's digital age, access to the Internet is essential, yet a significant digital divide exists, particularly in rural areas of developing nations. This paper presents a Delay Tolerant Networking (DTN) framework that utilizes informal public transportation systems, such as minibus taxis, as mobile data mules to enhance connectivity in these underserved regions. We develop a probabilistic model to capture the randomness in vehicle mobility, including travel times and contact durations at bus stops. Key performance metrics are analyzed, including average data transmission rate and Peak Age of Information (PAoI), to assess the effectiveness of the proposed system. An analytical approximation for the Mean PAoI (MPAoI) is derived and validated through simulations. Case studies from real-world datasets in Nouakchott, Accra, and Addis Ababa demonstrate the practical applicability and scalability of our framework. The findings indicate that leveraging existing transportation networks can significantly bridge the digital divide by providing reliable internet-like connectivity to remote areas.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u975e\u6b63\u5f0f\u516c\u5171\u4ea4\u901a\u7cfb\u7edf\u4f5c\u4e3a\u79fb\u52a8\u6570\u636e\u9a6e\u9a6c\u7684\u5ef6\u8fdf\u5bb9\u5fcd\u7f51\u7edc\u6846\u67b6\uff0c\u4ee5\u6539\u5584\u53d1\u5c55\u4e2d\u56fd\u5bb6\u519c\u6751\u5730\u533a\u7684\u4e92\u8054\u7f51\u8fde\u63a5", "motivation": "\u6570\u5b57\u65f6\u4ee3\u4e92\u8054\u7f51\u63a5\u5165\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u53d1\u5c55\u4e2d\u56fd\u5bb6\u519c\u6751\u5730\u533a\u5b58\u5728\u663e\u8457\u6570\u5b57\u9e3f\u6c9f\uff0c\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u4f9b\u8fde\u63a5", "method": "\u5f00\u53d1\u57fa\u4e8e\u975e\u6b63\u5f0f\u516c\u5171\u4ea4\u901a\u7cfb\u7edf\uff08\u5982\u5c0f\u5df4\u51fa\u79df\u8f66\uff09\u7684\u5ef6\u8fdf\u5bb9\u5fcd\u7f51\u7edc\u6846\u67b6\uff0c\u5efa\u7acb\u6982\u7387\u6a21\u578b\u6355\u6349\u8f66\u8f86\u79fb\u52a8\u968f\u673a\u6027\uff0c\u5206\u6790\u6570\u636e\u4f20\u8f93\u7387\u548c\u5cf0\u503c\u4fe1\u606f\u5e74\u9f84\u7b49\u6027\u80fd\u6307\u6807", "result": "\u63a8\u5bfc\u51fa\u5e73\u5747\u5cf0\u503c\u4fe1\u606f\u5e74\u9f84\u7684\u89e3\u6790\u8fd1\u4f3c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\uff0c\u5229\u7528\u52aa\u74e6\u514b\u8096\u7279\u3001\u963f\u514b\u62c9\u548c\u4e9a\u7684\u65af\u4e9a\u8d1d\u5df4\u7684\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u6846\u67b6\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "\u5229\u7528\u73b0\u6709\u4ea4\u901a\u7f51\u7edc\u53ef\u4ee5\u663e\u8457\u5f25\u5408\u6570\u5b57\u9e3f\u6c9f\uff0c\u4e3a\u504f\u8fdc\u5730\u533a\u63d0\u4f9b\u53ef\u9760\u7684\u7c7b\u4e92\u8054\u7f51\u8fde\u63a5"}}
{"id": "2512.00722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00722", "abs": "https://arxiv.org/abs/2512.00722", "authors": ["Jiaming Xu", "Jiayi Pan", "Hanzhen Wang", "Yongkang Zhou", "Jiancai Ye", "Yu Wang", "Guohao Dai"], "title": "SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs", "comment": "Accepted by ASPLOS 2026", "summary": "In this paper, we point out that the objective of the retrieval algorithms is to align with the LLM, which is similar to the objective of knowledge distillation in LLMs. We analyze the similarity in information focus between the distilled language model(DLM) and the original LLM from the perspective of information theory, and thus propose a novel paradigm that leverages a DLM as the retrieval algorithm. Based on the insight, we present SpeContext, an algorithm and system co-design for long-context reasoning. (1) At the algorithm level, SpeContext proposes lightweight retrieval head based on the head-level attention weights of DLM, achieving > 90% parameters reduction by pruning the redundancy. (2) At the system level, SpeContext designs an asynchronous prefetch dataflow via the elastic loading strategy, effectively overlapping KV cache retrieval with the LLM computation. (3) At the compilation level, SpeContext constructs the theoretical memory model and implements an adaptive memory management system to achieve acceleration by maximizing GPU memory utilization. We deploy and evaluate SpeContext in two resourceconstrained environments, cloud and edge. Extensive experiments show that, compared with the Huggingface framework, SpeContext achieves up to 24.89x throughput improvement in cloud and 10.06x speedup in edge with negligible accuracy loss, pushing the Pareto frontier of accuracy and throughput.", "AI": {"tldr": "SpeContext \u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u84b8\u998f\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u68c0\u7d22\u7b97\u6cd5\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u7b97\u6cd5\u3001\u7cfb\u7edf\u548c\u7f16\u8bd1\u4e09\u4e2a\u5c42\u9762\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u672c\u6587\u89c2\u5bdf\u5230\u68c0\u7d22\u7b97\u6cd5\u7684\u76ee\u6807\u4e0eLLM\u5bf9\u9f50\uff0c\u7c7b\u4f3c\u4e8eLLM\u4e2d\u7684\u77e5\u8bc6\u84b8\u998f\u76ee\u6807\u3002\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u5206\u6790\u84b8\u998f\u8bed\u8a00\u6a21\u578b\u4e0e\u539f\u59cbLLM\u5728\u4fe1\u606f\u5173\u6ce8\u4e0a\u7684\u76f8\u4f3c\u6027\uff0c\u63d0\u51fa\u5229\u7528DLM\u4f5c\u4e3a\u68c0\u7d22\u7b97\u6cd5\u7684\u65b0\u8303\u5f0f\u3002", "method": "1. \u7b97\u6cd5\u5c42\u9762\uff1a\u57fa\u4e8eDLM\u7684\u6ce8\u610f\u529b\u5934\u6743\u91cd\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u68c0\u7d22\u5934\uff0c\u901a\u8fc7\u526a\u679d\u5197\u4f59\u5b9e\u73b090%\u4ee5\u4e0a\u53c2\u6570\u51cf\u5c11\n2. \u7cfb\u7edf\u5c42\u9762\uff1a\u901a\u8fc7\u5f39\u6027\u52a0\u8f7d\u7b56\u7565\u8bbe\u8ba1\u5f02\u6b65\u9884\u53d6\u6570\u636e\u6d41\uff0c\u6709\u6548\u91cd\u53e0KV\u7f13\u5b58\u68c0\u7d22\u4e0eLLM\u8ba1\u7b97\n3. \u7f16\u8bd1\u5c42\u9762\uff1a\u6784\u5efa\u7406\u8bba\u5185\u5b58\u6a21\u578b\u5e76\u5b9e\u73b0\u81ea\u9002\u5e94\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u6700\u5927\u5316GPU\u5185\u5b58\u5229\u7528\u7387\u5b9e\u73b0\u52a0\u901f", "result": "\u5728\u4e91\u548c\u8fb9\u7f18\u4e24\u79cd\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u8bc4\u4f30\uff0c\u76f8\u6bd4Huggingface\u6846\u67b6\uff0cSpeContext\u5728\u4e91\u7aef\u5b9e\u73b0\u4e86\u6700\u9ad824.89\u500d\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5728\u8fb9\u7f18\u5b9e\u73b010.06\u500d\u52a0\u901f\uff0c\u51c6\u786e\u7387\u635f\u5931\u53ef\u5ffd\u7565\uff0c\u63a8\u52a8\u4e86\u51c6\u786e\u7387\u4e0e\u541e\u5410\u91cf\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "SpeContext\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff0c\u6210\u529f\u5229\u7528\u84b8\u998f\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9ad8\u6548\u68c0\u7d22\u7b97\u6cd5\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00834", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00834", "abs": "https://arxiv.org/abs/2512.00834", "authors": ["Lin Zhu", "Kezhi Wang", "Luping Xiang", "Kun Yang"], "title": "SemAgent: Semantic-Driven Agentic AI Empowered Trajectory Prediction in Vehicular Networks", "comment": "Submitted for possible journal publication", "summary": "Efficient information exchange and reliable contextual reasoning are essential for vehicle-to-everything (V2X) networks. Conventional communication schemes often incur significant transmission overhead and latency, while existing trajectory prediction models generally lack environmental perception and logical inference capabilities. This paper presents a trajectory prediction framework that integrates semantic communication with Agentic AI to enhance predictive performance in vehicular environments. In vehicle-to-infrastructure (V2I) communication, a feature-extraction agent at the Roadside Unit (RSU) derives compact representations from historical vehicle trajectories, followed by semantic reasoning performed by a semantic-analysis agent. The RSU then transmits both feature representations and semantic insights to the target vehicle via semantic communication, enabling the vehicle to predict future trajectories by combining received semantics with its own historical data. In vehicle-to-vehicle (V2V) communication, each vehicle performs local feature extraction and semantic analysis while receiving predicted trajectories from neighboring vehicles, and jointly utilizes this information for its own trajectory prediction. Extensive experiments across diverse communication conditions demonstrate that the proposed method significantly outperforms baseline schemes, achieving up to a 47.5% improvement in prediction accuracy under low signal-to-noise ratio (SNR) conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u4e49\u901a\u4fe1\u4e0e\u667a\u80fd\u4f53AI\u7684\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u8f66\u8054\u7f51\u73af\u5883\u4e2d\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u5347\u8fbe47.5%\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u65b9\u6848\u5b58\u5728\u663e\u8457\u7684\u4f20\u8f93\u5f00\u9500\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u73b0\u6709\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u73af\u5883\u611f\u77e5\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4fe1\u606f\u4ea4\u6362\u548c\u53ef\u9760\u7684\u60c5\u5883\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u8bed\u4e49\u901a\u4fe1\u4e0e\u667a\u80fd\u4f53AI\u7684\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff1a\u5728V2I\u901a\u4fe1\u4e2d\uff0cRSU\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u667a\u80fd\u4f53\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u8868\u793a\uff0c\u8bed\u4e49\u5206\u6790\u667a\u80fd\u4f53\u8fdb\u884c\u8bed\u4e49\u63a8\u7406\uff0c\u7136\u540e\u901a\u8fc7\u8bed\u4e49\u901a\u4fe1\u5c06\u7279\u5f81\u8868\u793a\u548c\u8bed\u4e49\u6d1e\u5bdf\u4f20\u8f93\u7ed9\u76ee\u6807\u8f66\u8f86\uff1b\u5728V2V\u901a\u4fe1\u4e2d\uff0c\u6bcf\u8f86\u8f66\u8fdb\u884c\u672c\u5730\u7279\u5f81\u63d0\u53d6\u548c\u8bed\u4e49\u5206\u6790\uff0c\u540c\u65f6\u63a5\u6536\u90bb\u8fd1\u8f66\u8f86\u7684\u9884\u6d4b\u8f68\u8ff9\uff0c\u7efc\u5408\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u81ea\u8eab\u8f68\u8ff9\u9884\u6d4b\u3002", "result": "\u5728\u5404\u79cd\u901a\u4fe1\u6761\u4ef6\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6848\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe47.5%\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bed\u4e49\u901a\u4fe1\u4e0e\u667a\u80fd\u4f53AI\u96c6\u6210\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u8f66\u8054\u7f51\u73af\u5883\u4e2d\u7684\u8f68\u8ff9\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6076\u52a3\u901a\u4fe1\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2512.00729", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00729", "abs": "https://arxiv.org/abs/2512.00729", "authors": ["Yuxiang Chen", "Zuohan Wu", "Ziwei Wang", "Xiangning Yu", "Xujia Li", "Linyi Yang", "Mengyue Yang", "Jun Wang", "Lei Chen"], "title": "Probing the \"Psyche'' of Large Reasoning Models: Understanding Through a Human Lens", "comment": "13 pages", "summary": "Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u4eba\u7c7b\u5fc3\u667a\u8fc7\u7a0b\u7684\u5206\u7c7b\u6cd5\u6765\u7406\u89e3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\"\u5fc3\u7406\"\uff0c\u5305\u542b5\u7ec417\u7c7b\u539f\u5b50\u63a8\u7406\u6b65\u9aa4\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u6807\u6ce8\u6846\u67b6CAPO\uff0c\u5206\u6790\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u7684\u81ea\u6211\u76d1\u63a7\u68c0\u67e5\u5927\u591a\u6d41\u4e8e\u8868\u9762\uff0c\u9700\u8981\u6fc0\u52b1\u591a\u6b65\u53cd\u601d\u6765\u6539\u8fdb\u63a8\u7406\u6a21\u578b\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5c55\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7406\u89e3\u6846\u67b6\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4ece\u8de8\u5b66\u79d1\u7684\u4eba\u7c7b\u5fc3\u667a\u8fc7\u7a0b\u89d2\u5ea6\uff0c\u5efa\u7acb\u5206\u7c7b\u6cd5\u6765\u6df1\u5165\u63a2\u7a76LRMs\u7684\"\u5fc3\u7406\"\u673a\u5236\uff0c\u4e3a\u6539\u8fdb\u8bad\u7ec3\u548c\u63a8\u7406\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "1) \u63d0\u51fa\u57fa\u4e8e\u4eba\u7c7b\u5fc3\u667a\u8fc7\u7a0b\u7684\u5206\u7c7b\u6cd5\uff0c\u5305\u542b5\u7ec417\u7c7b\u539f\u5b50\u63a8\u7406\u6b65\u9aa4\uff1b2) \u5e94\u7528\u8be5\u5206\u7c7b\u6cd5\u6807\u6ce8\u4e86277,534\u4e2a\u539f\u5b50\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff1b3) \u5f00\u53d1\u81ea\u52a8\u6807\u6ce8\u6846\u67b6CAPO\uff0c\u5229\u7528LLMs\u751f\u6210\u5206\u7c7b\u6cd5\u6807\u6ce8\uff1b4) \u5206\u6790\u5f53\u4ee3LRMs\u5e76\u63d0\u53d6\u6539\u8fdb\u89c1\u89e3\u3002", "result": "1) CAPO\u6846\u67b6\u5728\u6807\u6ce8\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u66f4\u4e00\u81f4\uff1b2) \u5206\u6790\u53d1\u73b0\u5f53\u524dLRMs\u7684\u81ea\u6211\u76d1\u63a7\u68c0\u67e5\u5927\u591a\u6d41\u4e8e\u8868\u9762\uff0c\u5f88\u5c11\u4ea7\u751f\u5b9e\u8d28\u6027\u4fee\u8ba2\uff1b3) \u63d0\u51fa\u6fc0\u52b1\u591a\u6b65\u53cd\u601d\u800c\u975e\u7b80\u5355\u81ea\u6211\u76d1\u63a7\u7684\u6539\u8fdb\u65b9\u5411\uff1b4) \u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684LRM\u5206\u6790\u8def\u5f84\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u3001CAPO\u6846\u67b6\u548c\u6d1e\u5bdf\u4e3a\u7406\u89e3\u548c\u63a8\u8fdbLRM\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002\u5f3a\u8c03\u9700\u8981\u4ece\u4eba\u7c7b\u8ba4\u77e5\u89d2\u5ea6\u6df1\u5165\u7406\u89e3LRMs\uff0c\u5e76\u901a\u8fc7\u6fc0\u52b1\u591a\u6b65\u53cd\u601d\u6765\u5b9e\u8d28\u6027\u6539\u8fdb\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u8fc7\u7a0b\u3002"}}
{"id": "2512.00756", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00756", "abs": "https://arxiv.org/abs/2512.00756", "authors": ["Ruihan Chen", "Qiming Li", "Xiaocheng Feng", "Xiaoliang Yang", "Weihong Zhong", "Yuxuan Gu", "Zekun Zhou", "Bing Qin"], "title": "MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents", "comment": "27pages, 12figures", "summary": "With the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P&R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P&R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements' spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents' P&R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P&R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P&R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents' multilingual P&R capability by 6.5% on average.", "AI": {"tldr": "\u63d0\u51fa\u4e86MPR-GUI-Bench\u591a\u8bed\u8a00\u7ec6\u7c92\u5ea6GUI\u611f\u77e5\u63a8\u7406\u57fa\u51c6\uff0c\u53d1\u73b0LVLMs\u5728\u975e\u82f1\u8bedGUI\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u8f83\u5dee\uff0c\u5e76\u63d0\u51faGUI-XLI\u8de8\u8bed\u8a00\u5e72\u9884\u65b9\u6cd5\u63d0\u5347\u591a\u8bed\u8a00\u6027\u80fd", "motivation": "\u73b0\u6709\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u82f1\u8bedGUI\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u6027\u80fd\u7814\u7a76\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5168\u7403\u5e94\u7528\u3002\u540c\u65f6\uff0c\u73b0\u6709GUI\u4efb\u52a1\u7814\u7a76\u7f3a\u4e4f\u5bf9\u7ec4\u4ef6\u529f\u80fd\u548c\u7a7a\u95f4\u5173\u7cfb\u7b49\u7ec6\u7c92\u5ea6\u5206\u6790", "method": "1) \u63d0\u51faMPR-GUI-Bench\u591a\u8bed\u8a00\u7ec6\u7c92\u5ea6GUI\u611f\u77e5\u63a8\u7406\u57fa\u51c6\uff1b2) \u63d0\u51faGUI-XLI\u8de8\u8bed\u8a00\u5e72\u9884\u65b9\u6cd5\uff0c\u5728\u611f\u77e5\u63a8\u7406\u76f8\u5173\u5c42\u7684\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u5e72\u9884\uff0c\u7f13\u89e3\u4e0d\u540c\u8bed\u8a00\u5728\u6f5c\u5728\u7a7a\u95f4\u7684\u5dee\u5f02", "result": "\u8bc4\u4f30\u663e\u793aLVLMs\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u7684\u611f\u77e5\u63a8\u7406\u6027\u80fd\u663e\u8457\u4f4e\u4e8e\u82f1\u8bed\u3002GUI-XLI\u65b9\u6cd5\u5e73\u5747\u63d0\u5347GUI\u4ee3\u7406\u591a\u8bed\u8a00\u611f\u77e5\u63a8\u7406\u80fd\u529b6.5%", "conclusion": "\u591a\u8bed\u8a00GUI\u4efb\u52a1\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u63d0\u51fa\u7684\u57fa\u51c6\u548c\u65b9\u6cd5\u80fd\u6709\u6548\u8bc4\u4f30\u548c\u63d0\u5347\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00GUI\u573a\u666f\u4e0b\u7684\u611f\u77e5\u63a8\u7406\u80fd\u529b"}}
{"id": "2512.00807", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00807", "abs": "https://arxiv.org/abs/2512.00807", "authors": ["Yujie Lin", "Jiayao Ma", "Qingguo Hu", "Derek F. Wong", "Jinsong Su"], "title": "BioPro: On Difference-Aware Gender Fairness for Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) inherit significant social biases from their training data, notably in gender representation. Current fairness interventions often adopt a difference-unaware perspective that enforces uniform treatment across demographic groups. These approaches, however, fail to distinguish between contexts where neutrality is required and those where group-specific attributes are legitimate and must be preserved. Building upon recent advances in difference-aware fairness for text-only models, we extend this concept to the multimodal domain and formalize the problem of difference-aware gender fairness for image captioning and text-to-image generation. We advocate for selective debiasing, which aims to mitigate unwanted bias in neutral contexts while preserving valid distinctions in explicit ones. To achieve this, we propose BioPro (Bias Orthogonal Projection), an entirely training-free framework. BioPro identifies a low-dimensional gender-variation subspace through counterfactual embeddings and applies projection to selectively neutralize gender-related information. Experiments show that BioPro effectively reduces gender bias in neutral cases while maintaining gender faithfulness in explicit ones, thus providing a promising direction toward achieving selective fairness in VLMs. Beyond gender bias, we further demonstrate that BioPro can effectively generalize to continuous bias variables, such as scene brightness, highlighting its broader applicability.", "AI": {"tldr": "BioPro\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u4f4e\u7ef4\u6027\u522b\u53d8\u5316\u5b50\u7a7a\u95f4\u5e76\u5e94\u7528\u6295\u5f71\u6765\u9009\u62e9\u6027\u4e2d\u548c\u6027\u522b\u4fe1\u606f\uff0c\u5728\u4fdd\u6301\u663e\u5f0f\u573a\u666f\u4e2d\u6027\u522b\u5fe0\u5b9e\u5ea6\u7684\u540c\u65f6\u51cf\u5c11\u4e2d\u6027\u573a\u666f\u4e2d\u7684\u6027\u522b\u504f\u89c1\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u6027\u522b\u504f\u89c1\uff0c\u800c\u73b0\u6709\u7684\u516c\u5e73\u6027\u5e72\u9884\u65b9\u6cd5\u91c7\u7528\u5dee\u5f02\u65e0\u611f\u77e5\u89c6\u89d2\uff0c\u5bf9\u6240\u6709\u4eba\u53e3\u7fa4\u4f53\u5b9e\u65bd\u7edf\u4e00\u5904\u7406\u3002\u8fd9\u4e9b\u65b9\u6cd5\u65e0\u6cd5\u533a\u5206\u9700\u8981\u4e2d\u7acb\u6027\u7684\u573a\u666f\u548c\u9700\u8981\u4fdd\u7559\u7fa4\u4f53\u7279\u5b9a\u5c5e\u6027\u7684\u573a\u666f\u3002", "method": "\u63d0\u51faBioPro\uff08Bias Orthogonal Projection\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5d4c\u5165\u8bc6\u522b\u4f4e\u7ef4\u6027\u522b\u53d8\u5316\u5b50\u7a7a\u95f4\uff0c\u5e76\u5e94\u7528\u6295\u5f71\u6765\u9009\u62e9\u6027\u4e2d\u548c\u6027\u522b\u76f8\u5173\u4fe1\u606f\u3002\u8be5\u6846\u67b6\u5b8c\u5168\u65e0\u9700\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eBioPro\u80fd\u6709\u6548\u51cf\u5c11\u4e2d\u6027\u573a\u666f\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u540c\u65f6\u5728\u663e\u5f0f\u573a\u666f\u4e2d\u4fdd\u6301\u6027\u522b\u5fe0\u5b9e\u5ea6\u3002\u6b64\u5916\uff0cBioPro\u8fd8\u80fd\u63a8\u5e7f\u5230\u8fde\u7eed\u504f\u89c1\u53d8\u91cf\uff08\u5982\u573a\u666f\u4eae\u5ea6\uff09\uff0c\u663e\u793a\u51fa\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "conclusion": "BioPro\u4e3a\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u5b9e\u73b0\u9009\u62e9\u6027\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u65e2\u80fd\u51cf\u8f7b\u4e0d\u9700\u8981\u7684\u504f\u89c1\uff0c\u53c8\u80fd\u4fdd\u7559\u6709\u6548\u7684\u7fa4\u4f53\u5dee\u5f02\u3002"}}
{"id": "2512.00818", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.00818", "abs": "https://arxiv.org/abs/2512.00818", "authors": ["Haozhen Gong", "Xiaozhong Ji", "Yuansen Liu", "Wenbin Wu", "Xiaoxiao Yan", "Jingjing Liu", "Kai Wu", "Jiazhen Pan", "Bailiang Jian", "Jiangning Zhang", "Xiaobin Hu", "Hongwei Bran Li"], "title": "Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning", "comment": null, "summary": "MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.", "AI": {"tldr": "Med-CMR\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u533b\u5b66\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30MLLMs\u5728\u4e34\u5e8a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u5305\u542b20,653\u4e2aVQA\u5bf9\uff0c\u6db5\u76d611\u4e2a\u5668\u5b98\u7cfb\u7edf\u548c12\u79cd\u6210\u50cf\u6a21\u6001\u3002", "motivation": "MLLMs\u5f00\u59cb\u5e94\u7528\u4e8e\u4e34\u5e8a\u5de5\u4f5c\u6d41\uff0c\u4f46\u5176\u6267\u884c\u590d\u6742\u533b\u5b66\u63a8\u7406\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u533b\u5b66\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002", "method": "1) \u7cfb\u7edf\u80fd\u529b\u5206\u89e3\uff1a\u5c06\u533b\u5b66\u591a\u6a21\u6001\u63a8\u7406\u5206\u89e3\u4e3a\u7ec6\u7c92\u5ea6\u89c6\u89c9\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\uff1b2) \u6311\u6218\u6027\u4efb\u52a1\u8bbe\u8ba1\uff1a\u89c6\u89c9\u7406\u89e3\u6db5\u76d6\u4e09\u4e2a\u7ef4\u5ea6\uff08\u5c0f\u7269\u4f53\u68c0\u6d4b\u3001\u7ec6\u8282\u8fa8\u522b\u3001\u7a7a\u95f4\u7406\u89e3\uff09\uff0c\u63a8\u7406\u6db5\u76d6\u56db\u4e2a\u4e34\u5e8a\u76f8\u5173\u573a\u666f\uff1b3) \u5e7f\u6cdb\u9ad8\u8d28\u91cf\u6570\u636e\u8986\u76d6\uff1a20,653\u4e2aVQA\u5bf9\uff0c\u7ecf\u8fc7\u4e24\u9636\u6bb5\uff08\u4e13\u5bb6+\u6a21\u578b\u8f85\u52a9\uff09\u5ba1\u67e5\u786e\u4fdd\u4e34\u5e8a\u771f\u5b9e\u6027\u3002", "result": "\u8bc4\u4f3018\u4e2aSOTA MLLMs\uff0cGPT-5\u8868\u73b0\u6700\u4f73\uff08MCQ\u51c6\u786e\u738757.81%\uff0c\u5f00\u653e\u5f0f\u5f97\u520648.70\uff09\uff0c\u4f18\u4e8eGemini 2.5 Pro\u548cQwen3-VL-235B-A22B\u3002\u4e13\u4e1a\u533b\u5b66MLLMs\u672a\u7a33\u5b9a\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u957f\u5c3e\u6cdb\u5316\u662f\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "Med-CMR\u4e3a\u533b\u5b66MLLMs\u7684\u89c6\u89c9-\u63a8\u7406\u6574\u5408\u548c\u7f55\u89c1\u75c5\u4f8b\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u538b\u529b\u6d4b\u8bd5\uff0c\u4e3a\u672a\u6765\u4e34\u5e8a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e25\u683c\u57fa\u51c6\u3002"}}
{"id": "2512.00836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00836", "abs": "https://arxiv.org/abs/2512.00836", "authors": ["Emily Howerton", "Justin Lessler"], "title": "Assessing model error in counterfactual worlds", "comment": null, "summary": "Counterfactual scenario modeling exercises that ask \"what would happen if?\" are one of the most common ways we plan for the future. Despite their ubiquity in planning and decision making, scenario projections are rarely evaluated retrospectively. Differences between projections and observations come from two sources: scenario deviation and model miscalibration. We argue the latter is most important for assessing the value of models in decision making, but requires estimating model error in counterfactual worlds. Here we present and contrast three approaches for estimating this error, and demonstrate the benefits and limitations of each in a simulation experiment. We provide recommendations for the estimation of counterfactual error and discuss the components of scenario design that are required to make scenario projections evaluable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e09\u79cd\u4f30\u8ba1\u53cd\u4e8b\u5b9e\u6a21\u578b\u8bef\u5dee\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u60c5\u666f\u9884\u6d4b\u4e2d\u6a21\u578b\u6821\u51c6\u7684\u91cd\u8981\u6027\uff0c\u800c\u975e\u60c5\u666f\u504f\u5dee", "motivation": "\u5c3d\u7ba1\u60c5\u666f\u5efa\u6a21\u5728\u89c4\u5212\u51b3\u7b56\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u9884\u6d4b\u7ed3\u679c\u5f88\u5c11\u88ab\u56de\u987e\u6027\u8bc4\u4f30\u3002\u9884\u6d4b\u4e0e\u89c2\u6d4b\u7684\u5dee\u5f02\u6765\u81ea\u60c5\u666f\u504f\u5dee\u548c\u6a21\u578b\u6821\u51c6\u9519\u8bef\uff0c\u540e\u8005\u5bf9\u8bc4\u4f30\u6a21\u578b\u5728\u51b3\u7b56\u4e2d\u7684\u4ef7\u503c\u66f4\u4e3a\u91cd\u8981\uff0c\u4f46\u9700\u8981\u5728\u53cd\u4e8b\u5b9e\u4e16\u754c\u4e2d\u4f30\u8ba1\u6a21\u578b\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u5e76\u5bf9\u6bd4\u4e09\u79cd\u4f30\u8ba1\u53cd\u4e8b\u5b9e\u6a21\u578b\u8bef\u5dee\u7684\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u7684\u8bef\u5dee\u4f30\u8ba1\uff0c2\uff09\u4f7f\u7528\u66ff\u4ee3\u60c5\u666f\u7684\u8bef\u5dee\u8f6c\u79fb\uff0c3\uff09\u6a21\u578b\u7ed3\u6784\u8bef\u5dee\u5206\u6790\u3002\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5c55\u793a\u6bcf\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\u4e09\u79cd\u65b9\u6cd5\u5404\u6709\u9002\u7528\u573a\u666f\u548c\u5c40\u9650\u6027\u3002\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u7684\u65b9\u6cd5\u5728\u60c5\u666f\u7a33\u5b9a\u65f6\u6709\u6548\uff1b\u8bef\u5dee\u8f6c\u79fb\u65b9\u6cd5\u9700\u8981\u60c5\u666f\u76f8\u4f3c\u6027\uff1b\u7ed3\u6784\u5206\u6790\u80fd\u63ed\u793a\u6839\u672c\u8bef\u5dee\u4f46\u5b9e\u65bd\u590d\u6742\u3002", "conclusion": "\u4e3a\u6709\u6548\u8bc4\u4f30\u60c5\u666f\u9884\u6d4b\uff0c\u9700\u8981\u8bbe\u8ba1\u53ef\u8bc4\u4f30\u7684\u60c5\u666f\uff0c\u5e76\u9009\u62e9\u5408\u9002\u7684\u53cd\u4e8b\u5b9e\u8bef\u5dee\u4f30\u8ba1\u65b9\u6cd5\u3002\u6a21\u578b\u6821\u51c6\u8bef\u5dee\u7684\u51c6\u786e\u4f30\u8ba1\u5bf9\u51b3\u7b56\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u672a\u6765\u60c5\u666f\u8bbe\u8ba1\u5e94\u5305\u542b\u8bc4\u4f30\u673a\u5236\u3002"}}
{"id": "2512.00839", "categories": ["cs.AI", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.00839", "abs": "https://arxiv.org/abs/2512.00839", "authors": ["Fabrizio Maturo", "Donato Riccio", "Andrea Mazzitelli", "Giuseppe Bifulco", "Francesco Paolone", "Iulia Brezeanu"], "title": "ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI", "comment": "35 pages, 9 figures, 4 tables", "summary": "This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.", "AI": {"tldr": "ARCADIA\u662f\u4e00\u4e2a\u7528\u4e8e\u56e0\u679c\u53d1\u73b0\u7684\u667a\u80fdAI\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u7edf\u8ba1\u8bca\u65ad\u6765\u6784\u5efa\u6709\u6548\u3001\u65f6\u95f4\u4e00\u81f4\u7684\u56e0\u679c\u7ed3\u6784\uff0c\u76f8\u6bd4\u4f20\u7edf\u7b97\u6cd5\u80fd\u4ea7\u751f\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u56fe\u3002", "motivation": "\u4f20\u7edf\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u5728\u9ad8\u98ce\u9669\u73b0\u5b9e\u9886\u57df\uff08\u5982\u4f01\u4e1a\u7834\u4ea7\u9884\u6d4b\uff09\u4e2d\u5f80\u5f80\u7f3a\u4e4f\u7a33\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u4e3b\u6784\u5efa\u6709\u6548\u56e0\u679c\u7ed3\u6784\u5e76\u652f\u6301\u5e72\u9884\u7684\u667a\u80fd\u6846\u67b6\u3002", "method": "ARCADIA\u901a\u8fc7\u7ea6\u675f\u5f15\u5bfc\u63d0\u793a\u548c\u56e0\u679c\u6709\u6548\u6027\u53cd\u9988\u7684\u8fed\u4ee3\u5faa\u73af\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u7edf\u8ba1\u8bca\u65ad\u76f8\u7ed3\u5408\uff0c\u9010\u6b65\u4f18\u5316\u5019\u9009\u6709\u5411\u65e0\u73af\u56fe\uff08DAGs\uff09\uff0c\u5f62\u6210\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u6a21\u578b\u3002", "result": "\u5728\u4f01\u4e1a\u7834\u4ea7\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cARCADIA\u6bd4NOTEARS\u3001GOLEM\u548cDirectLiNGAM\u7b49\u4f20\u7edf\u7b97\u6cd5\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u56e0\u679c\u56fe\uff0c\u540c\u65f6\u63d0\u4f9b\u5b8c\u5168\u53ef\u89e3\u91ca\u3001\u652f\u6301\u5e72\u9884\u7684\u5b8c\u6574\u6d41\u7a0b\u3002", "conclusion": "ARCADIA\u6846\u67b6\u5c55\u793a\u4e86\u667a\u80fd\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u53c2\u4e0e\u81ea\u4e3b\u79d1\u5b66\u5efa\u6a21\u548c\u7ed3\u6784\u5316\u56e0\u679c\u63a8\u65ad\uff0c\u63a8\u52a8\u4e86AI\u5728\u56e0\u679c\u53d1\u73b0\u9886\u57df\u7684\u53d1\u5c55\uff0c\u4e3a\u9ad8\u98ce\u9669\u73b0\u5b9e\u5e94\u7528\u63d0\u4f9b\u4e86\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00852", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00852", "abs": "https://arxiv.org/abs/2512.00852", "authors": ["Yandong Sun", "Qiang Huang", "Ziwei Xu", "Yiqun Sun", "Yixuan Tang", "Anthony K. H. Tung"], "title": "One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces", "comment": null, "summary": "Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.", "AI": {"tldr": "\u63d0\u51faSFS\uff08\u8bed\u4e49\u573a\u5b50\u7a7a\u95f4\uff09\u548cSAFARI\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6355\u6349\u5c40\u90e8\u8bed\u4e49\u90bb\u57df\u5e76\u53d1\u73b0\u5c42\u6b21\u5316\u8bed\u4e49\u7ed3\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u8bed\u4e49\u7406\u89e3\u3002", "motivation": "\u5f53\u524d\u5d4c\u5165\u7a7a\u95f4\u7684\u5185\u90e8\u7ed3\u6784\u4e0d\u900f\u660e\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u727a\u7272\u8bed\u4e49\u8fde\u8d2f\u6027\u8ffd\u6c42\u7ed3\u6784\u89c4\u5f8b\u6027\uff0c\u8981\u4e48\u8ba1\u7b97\u5f00\u9500\u5927\u3002\u9700\u8981\u4e00\u79cd\u80fd\u4fdd\u6301\u51e0\u4f55\u7279\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u5206\u6790\u548c\u7406\u89e3\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u7ed3\u6784\u3002", "method": "1. \u63d0\u51faSFS\uff08\u8bed\u4e49\u573a\u5b50\u7a7a\u95f4\uff09\uff1a\u4e00\u79cd\u4fdd\u6301\u51e0\u4f55\u7279\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8868\u793a\u65b9\u6cd5\uff0c\u6355\u6349\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u5c40\u90e8\u8bed\u4e49\u90bb\u57df\u30022. \u63d0\u51faSAFARI\u7b97\u6cd5\uff1a\u65e0\u76d1\u7763\u3001\u6a21\u6001\u65e0\u5173\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u65b0\u9896\u7684\"\u8bed\u4e49\u504f\u79fb\"\u5ea6\u91cf\u6765\u53d1\u73b0\u5c42\u6b21\u5316\u8bed\u4e49\u7ed3\u6784\u30023. \u5f00\u53d1\u9ad8\u6548\u7684\u8bed\u4e49\u504f\u79fb\u8fd1\u4f3c\u65b9\u6cd5\uff1a\u66ff\u4ee3\u6602\u8d35\u7684SVD\u8ba1\u7b97\uff0c\u5b9e\u73b015~30\u500d\u52a0\u901f\uff0c\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e0.01\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6587\u672c\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff1a1. SFS\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6807\u51c6\u5206\u7c7b\u5668\uff1b2. \u5728\u653f\u6cbb\u504f\u89c1\u68c0\u6d4b\u7b49\u7ec6\u5fae\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff1b3. SAFARI\u59cb\u7ec8\u80fd\u53d1\u73b0\u53ef\u89e3\u91ca\u4e14\u53ef\u6cdb\u5316\u7684\u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7ed3\u6784\u5316\u3001\u5206\u6790\u548c\u6269\u5c55\u8bed\u4e49\u7406\u89e3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bed\u4e49\u8fde\u8d2f\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.00881", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00881", "abs": "https://arxiv.org/abs/2512.00881", "authors": ["Li Yuan", "Qingfei Huang", "Bingshan Zhu", "Yi Cai", "Qingbao Huang", "Changmeng Zheng", "Zikun Deng", "Tao Wang"], "title": "Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing", "comment": "Accepted by AAAI 2026", "summary": "Multimodal Knowledge Editing (MKE) extends traditional knowledge editing to settings involving both textual and visual modalities. However, existing MKE benchmarks primarily assess final answer correctness while neglecting the quality of intermediate reasoning and robustness to visually rephrased inputs. To address this limitation, we introduce MMQAKE, the first benchmark for multimodal multihop question answering with knowledge editing. MMQAKE evaluates (1) a model's ability to reason over 2-5-hop factual chains that span both text and images, including performance at each intermediate step, and (2) robustness to visually rephrased inputs in multihop questions. Our evaluation shows that current MKE methods often struggle to consistently update and reason over multimodal reasoning chains after knowledge edits. To overcome these challenges, we propose Hybrid-DMKG, a hybrid reasoning framework built on a dynamic multimodal knowledge graph (DMKG) to enable accurate multihop reasoning over updated multimodal knowledge. Hybrid-DMKG first uses a large language model to decompose multimodal multihop questions into sequential sub-questions, then applies a multimodal retrieval model to locate updated facts by jointly encoding each sub-question with candidate entities and their associated images. For answer inference, a hybrid reasoning module operates over the DMKG via two parallel paths: (1) relation linking prediction, and (2) RAG reasoning with large vision-language models. A decision module aggregates evidence from both paths to select the most credible answer. Experimental results on MMQAKE show that Hybrid-DMKG significantly outperforms existing MKE approaches, achieving higher accuracy and improved robustness to knowledge updates.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u6a21\u6001\u591a\u8df3\u95ee\u7b54\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6MMQAKE\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u52a8\u6001\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u6df7\u5408\u63a8\u7406\u6846\u67b6Hybrid-DMKG\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u77e5\u8bc6\u7f16\u8f91\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709MKE\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u4e2d\u95f4\u63a8\u7406\u8d28\u91cf\u548c\u89c6\u89c9\u91cd\u8ff0\u8f93\u5165\u7684\u9c81\u68d2\u6027\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6d4b\u8bd5\u6a21\u578b\u5728\u591a\u6a21\u6001\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u77e5\u8bc6\u7f16\u8f91\u80fd\u529b\u3002", "method": "\u63d0\u51faHybrid-DMKG\u6846\u67b6\uff1a1) \u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u89e3\u591a\u8df3\u95ee\u9898\u4e3a\u5b50\u95ee\u9898\uff1b2) \u591a\u6a21\u6001\u68c0\u7d22\u6a21\u578b\u5b9a\u4f4d\u66f4\u65b0\u4e8b\u5b9e\uff1b3) \u6df7\u5408\u63a8\u7406\u6a21\u5757\u901a\u8fc7\u5173\u7cfb\u94fe\u63a5\u9884\u6d4b\u548cRAG\u63a8\u7406\u4e24\u6761\u8def\u5f84\u5728DMKG\u4e0a\u63a8\u7406\uff1b4) \u51b3\u7b56\u6a21\u5757\u805a\u5408\u8bc1\u636e\u9009\u62e9\u6700\u53ef\u4fe1\u7b54\u6848\u3002", "result": "\u5728MMQAKE\u57fa\u51c6\u4e0a\uff0cHybrid-DMKG\u663e\u8457\u4f18\u4e8e\u73b0\u6709MKE\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u5bf9\u77e5\u8bc6\u66f4\u65b0\u7684\u66f4\u597d\u9c81\u68d2\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u63a8\u7406\u94fe\u66f4\u65b0\u548c\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "MMQAKE\u57fa\u51c6\u586b\u8865\u4e86\u591a\u6a21\u6001\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u7684\u7a7a\u767d\uff0cHybrid-DMKG\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u6df7\u5408\u63a8\u7406\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u77e5\u8bc6\u7f16\u8f91\u6311\u6218\u3002"}}
{"id": "2512.00918", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00918", "abs": "https://arxiv.org/abs/2512.00918", "authors": ["Cen Lu", "Yung-Chen Tang", "Andrea Cavallaro"], "title": "Minimal neuron ablation triggers catastrophic collapse in the language core of Large Vision-Language Models", "comment": "15 pages, 6 figures,", "summary": "Large Vision-Language Models (LVLMs) have shown impressive multimodal understanding capabilities, yet their robustness is poorly understood. In this paper, we investigate the structural vulnerabilities of LVLMs to identify any critical neurons whose removal triggers catastrophic collapse. In this context, we propose CAN, a method to detect Consistently Activated Neurons and to locate critical neurons by progressive masking. Experiments on LLaVA-1.5-7b-hf and InstructBLIP-Vicuna-7b reveal that masking only a tiny portion of the language model's feed-forward networks (just as few as four neurons in extreme cases) suffices to trigger catastrophic collapse. Notably, critical neurons are predominantly localized in the language model rather than in the vision components, and the down-projection layer is a particularly vulnerable structure. We also observe a consistent two-stage collapse pattern: initial expressive degradation followed by sudden, complete collapse. Our findings provide important insights for safety research in LVLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7ed3\u6784\u8106\u5f31\u6027\uff0c\u4ec5\u9700\u5c4f\u853d\u8bed\u8a00\u6a21\u578b\u4e2d\u6781\u5c11\u6570\u795e\u7ecf\u5143\uff08\u6781\u7aef\u60c5\u51b5\u4e0b\u4ec54\u4e2a\uff09\u5373\u53ef\u5f15\u53d1\u707e\u96be\u6027\u5d29\u6e83", "motivation": "\u5c3d\u7ba1\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u5176\u9c81\u68d2\u6027\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76LVLMs\u7684\u7ed3\u6784\u8106\u5f31\u6027\uff0c\u8bc6\u522b\u90a3\u4e9b\u79fb\u9664\u540e\u4f1a\u5f15\u53d1\u707e\u96be\u6027\u5d29\u6e83\u7684\u5173\u952e\u795e\u7ecf\u5143\u3002", "method": "\u63d0\u51faCAN\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e00\u81f4\u6fc0\u6d3b\u795e\u7ecf\u5143\u5e76\u91c7\u7528\u6e10\u8fdb\u5f0f\u63a9\u7801\u5b9a\u4f4d\u5173\u952e\u795e\u7ecf\u5143\u3002\u5728LLaVA-1.5-7b-hf\u548cInstructBLIP-Vicuna-7b\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u4ec5\u9700\u5c4f\u853d\u8bed\u8a00\u6a21\u578b\u524d\u9988\u7f51\u7edc\u4e2d\u6781\u5c11\u90e8\u5206\u795e\u7ecf\u5143\uff08\u6781\u7aef\u60c5\u51b5\u4e0b\u4ec54\u4e2a\uff09\u5c31\u8db3\u4ee5\u89e6\u53d1\u707e\u96be\u6027\u5d29\u6e83\u3002\u5173\u952e\u795e\u7ecf\u5143\u4e3b\u8981\u4f4d\u4e8e\u8bed\u8a00\u6a21\u578b\u800c\u975e\u89c6\u89c9\u7ec4\u4ef6\uff0c\u4e0b\u6295\u5f71\u5c42\u662f\u7279\u522b\u8106\u5f31\u7684\u7ed3\u6784\u3002\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u4e24\u9636\u6bb5\u5d29\u6e83\u6a21\u5f0f\uff1a\u521d\u59cb\u8868\u8fbe\u80fd\u529b\u4e0b\u964d\uff0c\u968f\u540e\u7a81\u7136\u5b8c\u5168\u5d29\u6e83\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\u8106\u5f31\u6027\uff0c\u5173\u952e\u795e\u7ecf\u5143\u4e3b\u8981\u5b58\u5728\u4e8e\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u8fd9\u4e3aLVLMs\u7684\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2512.00997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00997", "abs": "https://arxiv.org/abs/2512.00997", "authors": ["Param Biyani", "Shashank Kirtania", "Yasharth Bajpai", "Sumit Gulwani", "Ashish Tiwari"], "title": "IndiMathBench: Autoformalizing Mathematical Reasoning Problems with a Human Touch", "comment": null, "summary": "We introduce IndiMathBench, a human-verified benchmark designed to evaluate mathematical theorem proving, curated using an AI-powered human-assisted pipeline for formalizing natural language problems in Lean. IndiMathBench is composed of 312 formal Lean 4 theorems paired with their corresponding informal problem statements, sourced from Indian Mathematics Olympiads. Through category-based retrieval, iterative compiler feedback, and multi-model ensembles, our pipeline generates candidate formalizations that experts efficiently validate via an interactive dashboard with automated quality summaries. Evaluation across multiple frontier models demonstrates that autoformalization remains challenging, with substantial gaps between syntactic validity and semantic correctness, while theorem proving success rates remain low even with iterative refinement, demonstrating that \\benchmark~presents a challenging testbed for mathematical reasoning. IndiMathBench is available at https://github.com/prmbiy/IndiMathBench.", "AI": {"tldr": "IndiMathBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u5370\u5ea6\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u95ee\u9898\u6784\u5efa\u7684\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b312\u4e2a\u5f62\u5f0f\u5316Lean 4\u5b9a\u7406\u53ca\u5176\u5bf9\u5e94\u7684\u975e\u6b63\u5f0f\u95ee\u9898\u9648\u8ff0\uff0c\u901a\u8fc7AI\u8f85\u52a9\u4eba\u5de5\u9a8c\u8bc1\u6d41\u7a0b\u521b\u5efa\u3002", "motivation": "\u5f53\u524d\u6570\u5b66\u5b9a\u7406\u81ea\u52a8\u5f62\u5f0f\u5316\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u6784\u5efa\u9ad8\u8d28\u91cf\u3001\u7ecf\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5f62\u5f0f\u5316\u6570\u5b66\u63a8\u7406\u7684\u8bc4\u4f30\u3002", "method": "\u91c7\u7528AI\u9a71\u52a8\u7684\u4eba\u5de5\u8f85\u52a9\u6d41\u7a0b\uff1a\u901a\u8fc7\u7c7b\u522b\u68c0\u7d22\u3001\u8fed\u4ee3\u7f16\u8bd1\u5668\u53cd\u9988\u548c\u591a\u6a21\u578b\u96c6\u6210\u751f\u6210\u5019\u9009\u5f62\u5f0f\u5316\uff0c\u4e13\u5bb6\u901a\u8fc7\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u8fdb\u884c\u9ad8\u6548\u9a8c\u8bc1\uff0c\u5e76\u5229\u7528\u81ea\u52a8\u5316\u8d28\u91cf\u6458\u8981\u8f85\u52a9\u51b3\u7b56\u3002", "result": "\u8bc4\u4f30\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\u663e\u793a\uff0c\u81ea\u52a8\u5f62\u5f0f\u5316\u4ecd\u7136\u56f0\u96be\uff0c\u8bed\u6cd5\u6709\u6548\u6027\u548c\u8bed\u4e49\u6b63\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5b9a\u7406\u8bc1\u660e\u6210\u529f\u7387\u5373\u4f7f\u5728\u8fed\u4ee3\u4f18\u5316\u540e\u4ecd\u7136\u8f83\u4f4e\uff0c\u8868\u660e\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "IndiMathBench\u4e3a\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5c55\u793a\u4e86\u5f53\u524dAI\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u516c\u5f00\u53ef\u7528\u7684\u9ad8\u8d28\u91cf\u57fa\u51c6\u6570\u636e\u96c6\u3002"}}
{"id": "2512.01017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01017", "abs": "https://arxiv.org/abs/2512.01017", "authors": ["Xinhang Li", "Jingbo Zhou", "Pengfei Luo", "Yixiong Xiao", "Tong Xu"], "title": "ChartAnchor: Chart Grounding with Structural-Semantic Fidelity", "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension.Chart grounding refers to the bidirectional alignment between a chart's visual appearance and the structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important applications in real-world scenarios.Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation (synthesizing executable code to replicate charts) and controlled chart-to-table reconstruction (extracting exact data with predefined headers), enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.", "AI": {"tldr": "ChartAnchor\u662f\u4e00\u4e2a\u5305\u542b8k+\u56fe\u8868-\u8868\u683c-\u4ee3\u7801\u4e09\u5143\u7ec4\u7684\u7efc\u5408\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d630\u79cd\u56fe\u8868\u7c7b\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u56fe\u8868\u7406\u89e3\u80fd\u529b\uff0c\u5305\u62ec\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\u548c\u53d7\u63a7\u56fe\u8868\u5230\u8868\u683c\u91cd\u5efa\u4e24\u4e2a\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u56fe\u8868\u591a\u6837\u6027\u3001\u4efb\u52a1\u5b64\u7acb\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u5b8c\u6574\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u7684\u56fe\u8868\u57fa\u7840\u80fd\u529b\u3002\u56fe\u8868\u57fa\u7840\uff08\u53cc\u5411\u5bf9\u9f50\u56fe\u8868\u89c6\u89c9\u5916\u89c2\u4e0e\u7ed3\u6784\u5316\u8bed\u4e49\uff09\u76f4\u63a5\u53cd\u6620\u6a21\u578b\u5728\u6570\u503c\u63a8\u7406\u3001\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u7ed3\u6784\u91cd\u5efa\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6709\u91cd\u8981\u5e94\u7528\u3002", "method": "\u63d0\u51faChartAnchor\u57fa\u51c6\uff0c\u5305\u542b\u6765\u81ea\u771f\u5b9e\u4e16\u754c\u548c\u589e\u5f3a\u6765\u6e90\u76848k+\u56fe\u8868-\u8868\u683c-\u4ee3\u7801\u4e09\u5143\u7ec4\uff0c\u6db5\u76d630\u79cd\u56fe\u8868\u7c7b\u578b\u3002\u5f15\u5165\u4e24\u4e2a\u4e92\u8865\u4efb\u52a1\uff1a\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\uff08\u5408\u6210\u53ef\u6267\u884c\u4ee3\u7801\u590d\u5236\u56fe\u8868\uff09\u548c\u53d7\u63a7\u56fe\u8868\u5230\u8868\u683c\u91cd\u5efa\uff08\u63d0\u53d6\u5177\u6709\u9884\u5b9a\u4e49\u6807\u9898\u7684\u7cbe\u786e\u6570\u636e\uff09\u3002\u91c7\u7528\u591a\u7ea7\u8bc4\u4f30\u6846\u67b6\uff0c\u96c6\u6210\u8bed\u4e49\u9a8c\u8bc1\u3001\u98ce\u683c\u5206\u6790\u548c\u611f\u77e5\u6307\u6807\u3002", "result": "\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u63ed\u793a\u4e86\u6570\u503c\u7cbe\u5ea6\u548c\u4ee3\u7801\u5408\u6210\u65b9\u9762\u7684\u5173\u952e\u9650\u5236\uff0c\u5f3a\u8c03\u4e86\u8d85\u8d8a\u8868\u9762\u611f\u77e5\u7684\u7ed3\u6784\u5316\u63a8\u7406\u9700\u6c42\u3002\u901a\u8fc7\u7edf\u4e00\u7b26\u53f7\u548c\u6570\u636e\u9a71\u52a8\u7684\u57fa\u7840\uff0cChartAnchor\u4e3a\u56fe\u8868\u57fa\u7840\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u57fa\u7840\u3002", "conclusion": "ChartAnchor\u4e3a\u56fe\u8868\u57fa\u7840\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u7edf\u4e00\u7b26\u53f7\u548c\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u4e3a\u63a8\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u3001\u91d1\u878d\u548c\u5de5\u4e1a\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.01020", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01020", "abs": "https://arxiv.org/abs/2512.01020", "authors": ["Jinu Lee", "Kyoung-Woon On", "Simeng Han", "Arman Cohan", "Julia Hockenmaier"], "title": "Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics", "comment": null, "summary": "Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.", "AI": {"tldr": "LEGIT\u6570\u636e\u96c6\uff1a\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u6cd5\u5f8b\u9886\u57df\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u7684\u5927\u89c4\u6a21\u4e13\u5bb6\u7ea7\u6cd5\u5f8b\u63a8\u7406\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5c06\u6cd5\u5ead\u5224\u51b3\u8f6c\u6362\u4e3a\u5c42\u6b21\u5316\u8bba\u8bc1\u6811\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\u3002", "motivation": "\u5728\u4e13\u5bb6\u9886\u57df\uff08\u5982\u6cd5\u5f8b\uff09\u4e2d\u8bc4\u4f30LLM\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u5bf9\u4e8e\u786e\u4fdd\u53ef\u4fe1\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u6b64\u7c7b\u63a8\u7406\u4efb\u52a1\u7684\u56fa\u6709\u590d\u6742\u6027\uff0c\u8fd9\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5c06\u6cd5\u5ead\u5224\u51b3\u8f6c\u6362\u4e3a\u5bf9\u7acb\u53cc\u65b9\u8bba\u8bc1\u548c\u6cd5\u5ead\u7ed3\u8bba\u7684\u5c42\u6b21\u5316\u6811\u7ed3\u6784\uff0c\u4f5c\u4e3a\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u95ee\u9898\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\u7684\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u9a8c\u8bc1\u53ef\u9760\u6027\u3002", "result": "1) LLM\u7684\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u53d7\u5230\u6cd5\u5f8b\u95ee\u9898\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\u7684\u4e25\u91cd\u5f71\u54cd\uff1b2) RAG\u548c\u57fa\u4e8e\u6807\u51c6\u7684RL\u5bf9\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u5e26\u6765\u4e92\u8865\u4f18\u52bf\uff1aRAG\u63d0\u5347\u6574\u4f53\u63a8\u7406\u80fd\u529b\uff0cRL\u63d0\u5347\u6b63\u786e\u6027\u4f46\u4f1a\u964d\u4f4e\u8986\u76d6\u7387\u3002", "conclusion": "LEGIT\u6570\u636e\u96c6\u4e3a\u8bc4\u4f30\u4e13\u5bb6\u9886\u57dfLLM\u63a8\u7406\u8f68\u8ff9\u63d0\u4f9b\u4e86\u53ef\u9760\u6807\u51c6\uff0c\u63ed\u793a\u4e86LLM\u6cd5\u5f8b\u63a8\u7406\u7684\u5c40\u9650\u6027\u4ee5\u53caRAG\u548cRL\u65b9\u6cd5\u7684\u4e92\u8865\u4f5c\u7528\u3002"}}
{"id": "2512.01045", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01045", "abs": "https://arxiv.org/abs/2512.01045", "authors": ["Shenxi Liu", "Kan Li", "Mingyang Zhao", "Yuhang Tian", "Shoujun Zhou", "Bin Li"], "title": "Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal", "comment": "8 pages, 7 figures", "summary": "The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \\textbf{\\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.", "AI": {"tldr": "\u63d0\u51faMed-CRAFT\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u6570\u636e\u5de5\u7a0b\u65b9\u6cd5\u81ea\u52a8\u5316\u751f\u6210\u533b\u5b66\u89c6\u9891\u63a8\u7406\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u548c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u7f3a\u4e4f\u903b\u8f91\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u533b\u5b66\u9886\u57df\u9ad8\u8d28\u91cf\u903b\u8f91\u6807\u6ce8\u89c6\u9891\u6570\u636e\u96c6\u7a00\u7f3a\u662fMLLMs\u53d1\u5c55\u7684\u4e3b\u8981\u74f6\u9888\u3002\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u4e14\u4e0d\u53ef\u6269\u5c55\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5b58\u5728\u968f\u673a\u5e7b\u89c9\u548c\u7f3a\u4e4f\u903b\u8f91\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faMed-CRAFT\u795e\u7ecf\u7b26\u53f7\u6570\u636e\u5de5\u7a0b\u6846\u67b6\uff0c\u5c06\u57fa\u51c6\u5408\u6210\u5f62\u5f0f\u5316\u4e3a\u786e\u5b9a\u6027\u56fe\u904d\u5386\u8fc7\u7a0b\u3002\u4ece\u539f\u59cb\u89c6\u9891\u6d41\u63d0\u53d6\u7ed3\u6784\u5316\u89c6\u89c9\u57fa\u5143\uff0c\u5b9e\u4f8b\u5316\u4e3a\u52a8\u6001\u65f6\u7a7a\u77e5\u8bc6\u56fe\u8c31\uff0c\u57fa\u4e8e\u56fe\u4e2d\u6709\u6548\u8def\u5f84\u751f\u6210\u67e5\u8be2\uff0c\u786e\u4fdd\u6bcf\u4e2a\u5408\u6210\u57fa\u51c6\u9879\u5177\u6709\u4e25\u683c\u7684\u601d\u7ef4\u94fe\u53ef\u8ffd\u6eaf\u6027\u3002", "result": "\u6784\u5efa\u4e86M3-Med-Auto\u5927\u89c4\u6a21\u533b\u5b66\u89c6\u9891\u63a8\u7406\u57fa\u51c6\uff0c\u5177\u6709\u7ec6\u7c92\u5ea6\u65f6\u95f4\u9009\u62e9\u6027\u548c\u591a\u8df3\u903b\u8f91\u590d\u6742\u6027\u3002\u8bc4\u4f30\u663e\u793a\u81ea\u52a8\u5316\u7ba1\u9053\u751f\u6210\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u4e0e\u4e13\u5bb6\u7b56\u5212\u6570\u636e\u96c6\u76f8\u5f53\uff0c\u903b\u8f91\u5bf9\u9f50\u5206\u6790\u663e\u793a\u56fe\u62d3\u6251\u4e0e\u6700\u5148\u8fdbMLLMs\u63a8\u7406\u6b65\u9aa4\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5173\u952e\u9886\u57df\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u7684\u7a33\u5065\u8bc4\u4f30\u534f\u8bae\u6784\u5efa\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5c06\u53ef\u9a8c\u8bc1\u903b\u8f91\u7f16\u7801\u5230\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2512.01046", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01046", "abs": "https://arxiv.org/abs/2512.01046", "authors": ["Hadi Nekoei", "Alexandre Blondin Mass\u00e9", "Rachid Hassani", "Sarath Chandar", "Vincent Mai"], "title": "Shielded Controller Units for RL with Operational Constraints Applied to Remote Microgrids", "comment": null, "summary": "Reinforcement learning (RL) is a powerful framework for optimizing decision-making in complex systems under uncertainty, an essential challenge in real-world settings, particularly in the context of the energy transition. A representative example is remote microgrids that supply power to communities disconnected from the main grid. Enabling the energy transition in such systems requires coordinated control of renewable sources like wind turbines, alongside fuel generators and batteries, to meet demand while minimizing fuel consumption and battery degradation under exogenous and intermittent load and wind conditions. These systems must often conform to extensive regulations and complex operational constraints. To ensure that RL agents respect these constraints, it is crucial to provide interpretable guarantees. In this paper, we introduce Shielded Controller Units (SCUs), a systematic and interpretable approach that leverages prior knowledge of system dynamics to ensure constraint satisfaction. Our shield synthesis methodology, designed for real-world deployment, decomposes the environment into a hierarchical structure where each SCU explicitly manages a subset of constraints. We demonstrate the effectiveness of SCUs on a remote microgrid optimization task with strict operational requirements. The RL agent, equipped with SCUs, achieves a 24% reduction in fuel consumption without increasing battery degradation, outperforming other baselines while satisfying all constraints. We hope SCUs contribute to the safe application of RL to the many decision-making challenges linked to the energy transition.", "AI": {"tldr": "\u63d0\u51faShielded Controller Units (SCUs)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u7ea6\u675f\u7ba1\u7406\u786e\u4fdd\u5f3a\u5316\u5b66\u4e60\u5728\u5fae\u7535\u7f51\u4f18\u5316\u4e2d\u6ee1\u8db3\u4e25\u683c\u64cd\u4f5c\u7ea6\u675f\uff0c\u5b9e\u73b0\u71c3\u6599\u6d88\u8017\u964d\u4f4e24%\u4e14\u4e0d\u589e\u52a0\u7535\u6c60\u635f\u8017\u3002", "motivation": "\u80fd\u6e90\u8f6c\u578b\u4e2d\u7684\u5fae\u7535\u7f51\u7b49\u590d\u6742\u7cfb\u7edf\u9700\u8981\u5728\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u8fdb\u884c\u51b3\u7b56\u4f18\u5316\uff0c\u540c\u65f6\u5fc5\u987b\u6ee1\u8db3\u5927\u91cf\u6cd5\u89c4\u548c\u64cd\u4f5c\u7ea6\u675f\u3002\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ea6\u675f\u6ee1\u8db3\u4fdd\u8bc1\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u80fd\u6e90\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faShielded Controller Units (SCUs)\u65b9\u6cd5\uff0c\u5229\u7528\u7cfb\u7edf\u52a8\u6001\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u5c06\u73af\u5883\u5206\u89e3\u4e3a\u5206\u5c42\u7ed3\u6784\uff0c\u6bcf\u4e2aSCU\u663e\u5f0f\u7ba1\u7406\u7ea6\u675f\u5b50\u96c6\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ea6\u675f\u6ee1\u8db3\u4fdd\u8bc1\u3002", "result": "\u5728\u8fdc\u7a0b\u5fae\u7535\u7f51\u4f18\u5316\u4efb\u52a1\u4e2d\uff0c\u914d\u5907SCUs\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5b9e\u73b0\u4e86\u71c3\u6599\u6d88\u8017\u964d\u4f4e24%\uff0c\u4e14\u4e0d\u589e\u52a0\u7535\u6c60\u635f\u8017\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u64cd\u4f5c\u7ea6\u675f\u3002", "conclusion": "SCUs\u4e3a\u5f3a\u5316\u5b66\u4e60\u5728\u80fd\u6e90\u8f6c\u578b\u76f8\u5173\u51b3\u7b56\u6311\u6218\u4e2d\u7684\u5b89\u5168\u5e94\u7528\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u548c\u53ef\u89e3\u91ca\u7684\u7ea6\u675f\u6ee1\u8db3\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5f3a\u5316\u5b66\u4e60\u5728\u5b9e\u9645\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u90e8\u7f72\u3002"}}
{"id": "2512.01047", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01047", "abs": "https://arxiv.org/abs/2512.01047", "authors": ["Tanmay Ambadkar", "\u0110or\u0111e \u017dikeli\u0107", "Abhinav Verma"], "title": "Automating the Refinement of Reinforcement Learning Specifications", "comment": null, "summary": "Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \\textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \\textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \\textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \\textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \\textsc{AutoSpec} are utilized.", "AI": {"tldr": "AutoSpec\u6846\u67b6\u901a\u8fc7\u63a2\u7d22\u5f15\u5bfc\u7684\u7b56\u7565\u6539\u8fdb\u7c97\u7c92\u5ea6\u903b\u8f91\u89c4\u8303\uff0c\u5e2e\u52a9\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5b66\u4e60\u66f4\u6709\u7528\u7684\u7b56\u7565\u3002", "motivation": "\u5f53\u4efb\u52a1\u89c4\u8303\u4e0d\u591f\u5177\u4f53\u65f6\uff0c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u53ef\u80fd\u65e0\u6cd5\u5b66\u4e60\u5230\u6709\u7528\u7684\u7b56\u7565\u3002\u7c97\u7c92\u5ea6\u7684\u903b\u8f91\u89c4\u8303\u65e0\u6cd5\u63d0\u4f9b\u8db3\u591f\u7684\u6307\u5bfc\uff0c\u9700\u8981\u81ea\u52a8\u7ec6\u5316\u6765\u63d0\u4f9b\u66f4\u597d\u7684\u5b66\u4e60\u4fe1\u53f7\u3002", "method": "\u63d0\u51faAutoSpec\u6846\u67b6\uff0c\u57fa\u4e8eSpectRL\u89c4\u8303\u903b\u8f91\uff0c\u901a\u8fc7\u56db\u79cd\u7ec6\u5316\u7a0b\u5e8f\u4fee\u6539\u89c4\u8303\u7684\u62bd\u8c61\u56fe\uff1a\u7ec6\u5316\u73b0\u6709\u8fb9\u89c4\u8303\u6216\u5f15\u5165\u65b0\u7684\u8fb9\u89c4\u8303\uff0c\u4fdd\u6301\u89c4\u8303\u7684\u6b63\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528AutoSpec\u751f\u6210\u7684\u7ec6\u5316\u903b\u8f91\u89c4\u8303\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u590d\u6742\u63a7\u5236\u4efb\u52a1\u7684\u80fd\u529b\u3002", "conclusion": "AutoSpec\u80fd\u591f\u81ea\u52a8\u6539\u8fdb\u903b\u8f91\u89c4\u8303\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u66f4\u597d\u7684\u6307\u5bfc\uff0c\u4ece\u800c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002"}}
{"id": "2512.01078", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01078", "abs": "https://arxiv.org/abs/2512.01078", "authors": ["Jiawei Ren", "Yan Zhuang", "Xiaokang Ye", "Lingjun Mao", "Xuhong He", "Jianzhi Shen", "Mrinaal Dogra", "Yiming Liang", "Ruixuan Zhang", "Tianai Yue", "Yiqing Yang", "Eric Liu", "Ryan Wu", "Kevin Benavente", "Rajiv Mandya Nagaraju", "Muhammad Faayez", "Xiyan Zhang", "Dhruv Vivek Sharma", "Xianrui Zhong", "Ziqiao Ma", "Tianmin Shu", "Zhiting Hu", "Lianhui Qin"], "title": "SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds", "comment": null, "summary": "While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.", "AI": {"tldr": "SimWorld\uff1a\u57fa\u4e8e\u865a\u5e7b\u5f15\u64ce5\u6784\u5efa\u7684\u65b0\u578b\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u5728\u4e30\u5bcc\u3001\u903c\u771f\u7684\u73af\u5883\u4e2d\u5f00\u53d1\u548c\u8bc4\u4f30LLM/VLM\u667a\u80fd\u4f53\uff0c\u652f\u6301\u7269\u7406\u548c\u793e\u4f1a\u52a8\u6001\u6a21\u62df\u3001\u591a\u6a21\u6001\u63a5\u53e3\u4ee5\u53ca\u53ef\u6269\u5c55\u7684\u573a\u666f\u3002", "motivation": "\u5f53\u524dLLM/VLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u7269\u7406\u548c\u793e\u4f1a\u73af\u5883\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u6a21\u62df\u5668\u5b58\u5728\u73af\u5883\u6709\u9650\u3001\u7269\u7406\u7b80\u5316\u3001\u7f3a\u4e4f\u5bf9LLM/VLM\u539f\u751f\u652f\u6301\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u3001\u5f00\u653e\u7684\u4e16\u754c\u6a21\u62df\u5e73\u53f0\u3002", "method": "\u57fa\u4e8e\u865a\u5e7b\u5f15\u64ce5\u6784\u5efaSimWorld\u6a21\u62df\u5668\uff0c\u63d0\u4f9b\u4e09\u4e2a\u6838\u5fc3\u80fd\u529b\uff1a1) \u903c\u771f\u7684\u5f00\u653e\u4e16\u754c\u6a21\u62df\uff0c\u5305\u62ec\u51c6\u786e\u7684\u7269\u7406\u548c\u793e\u4f1a\u52a8\u6001\u4ee5\u53ca\u8bed\u8a00\u9a71\u52a8\u7684\u7a0b\u5e8f\u5316\u73af\u5883\u751f\u6210\uff1b2) \u4e30\u5bcc\u7684LLM/VLM\u667a\u80fd\u4f53\u63a5\u53e3\uff0c\u652f\u6301\u591a\u6a21\u6001\u8f93\u5165\u548c\u4e0d\u540c\u62bd\u8c61\u7ea7\u522b\u7684\u5f00\u653e\u8bcd\u6c47\u52a8\u4f5c\uff1b3) \u591a\u6837\u53ef\u6269\u5c55\u7684\u7269\u7406\u548c\u793e\u4f1a\u63a8\u7406\u573a\u666f\uff0c\u7528\u6237\u53ef\u8f7b\u677e\u5b9a\u5236\u3002", "result": "\u901a\u8fc7\u5728\u6d89\u53ca\u6218\u7565\u5408\u4f5c\u4e0e\u7ade\u4e89\u7684\u957f\u671f\u591a\u667a\u80fd\u4f53\u914d\u9001\u4efb\u52a1\u4e2d\u90e8\u7f72\u524d\u6cbfLLM\u667a\u80fd\u4f53\uff08\u5982GPT-4o\u3001Gemini-2.5-Flash\u7b49\uff09\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u63a8\u7406\u6a21\u5f0f\u548c\u5c40\u9650\u6027\u65b9\u9762\u7684\u5dee\u5f02\u3002", "conclusion": "SimWorld\u5f00\u6e90\u53d1\u5e03\uff0c\u65e8\u5728\u6210\u4e3a\u8de8\u5b66\u79d1\u63a8\u8fdb\u73b0\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u667a\u80fd\u7684\u57fa\u7840\u5e73\u53f0\uff0c\u4e3a\u5f00\u53d1\u80fd\u591f\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u751f\u5b58\u548c\u53d1\u5c55\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u5fc5\u8981\u7684\u6a21\u62df\u73af\u5883\u3002"}}
{"id": "2512.01081", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.NE", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.01081", "abs": "https://arxiv.org/abs/2512.01081", "authors": ["Stephen Fitz"], "title": "Testing the Machine Consciousness Hypothesis", "comment": null, "summary": "The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u673a\u5668\u610f\u8bc6\u5047\u8bf4\uff0c\u8ba4\u4e3a\u610f\u8bc6\u662f\u8ba1\u7b97\u7cfb\u7edf\u7684\u529f\u80fd\u5c5e\u6027\uff0c\u53ef\u901a\u8fc7\u5206\u5e03\u5f0f\u5b66\u4e60\u7cfb\u7edf\u5728\u81ea\u7ec4\u7ec7\u73af\u5883\u4e2d\u7814\u7a76\u96c6\u4f53\u81ea\u6211\u6a21\u578b\u7684\u6d8c\u73b0\u3002", "motivation": "\u7814\u7a76\u673a\u5668\u610f\u8bc6\u7684\u672c\u8d28\uff0c\u63a2\u7d22\u610f\u8bc6\u662f\u5426\u53ef\u4ee5\u4f5c\u4e3a\u8ba1\u7b97\u7cfb\u7edf\u7684\u529f\u80fd\u5c5e\u6027\u5728\u7845\u57fa\u7cfb\u7edf\u4e2d\u5b9e\u73b0\uff0c\u4e3a\u673a\u5668\u610f\u8bc6\u53d1\u5c55\u53ef\u5b9e\u8bc1\u68c0\u9a8c\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5efa\u6a21\u65b9\u6cd5\uff1a\u4ee5\u7ec6\u80de\u81ea\u52a8\u673a\u4f5c\u4e3a\u57fa\u7840\u8ba1\u7b97\u4e16\u754c\uff0c\u5728\u5176\u4e0a\u6784\u5efa\u5177\u6709\u901a\u4fe1\u548c\u9002\u5e94\u80fd\u529b\u7684\u5c40\u90e8\u9884\u6d4b\u6027\u8868\u793a\uff08\u795e\u7ecf\uff09\u6a21\u578b\u7f51\u7edc\uff0c\u7814\u7a76\u96c6\u4f53\u667a\u80fd\u5982\u4f55\u901a\u8fc7\u4ee3\u7406\u95f4\u5bf9\u9f50\u4ea7\u751f\u81ea\u6211\u8868\u793a\u3002", "result": "\u63d0\u51fa\u610f\u8bc6\u6e90\u4e8e\u901a\u4fe1\u800c\u975e\u5efa\u6a21\u672c\u8eab\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8ba4\u4e3a\u610f\u8bc6\u901a\u8fc7\u5c40\u90e8\u89c2\u5bdf\u8005\u4e4b\u95f4\u9884\u6d4b\u6027\u6d88\u606f\u7684\u566a\u58f0\u3001\u6709\u635f\u4ea4\u6362\u800c\u6d8c\u73b0\uff0c\u5f62\u6210\u5171\u4eab\u6a21\u578b\u548c\u5bf9\u4e16\u754c\u7684\u5bf9\u9f50\u89c6\u56fe\u3002", "conclusion": "\u610f\u8bc6\u662f\u96c6\u4f53\u667a\u80fd\u7cfb\u7edf\u901a\u8fc7\u901a\u4fe1\u540c\u6b65\u9884\u6d4b\u7684\u6d8c\u73b0\u5c5e\u6027\uff0c\u662f\u7cfb\u7edf\u4e3a\u5185\u90e8\u63cf\u8ff0\u81ea\u8eab\u800c\u6f14\u5316\u7684\u8bed\u8a00\u5c5e\u6027\uff0c\u4e3a\u673a\u5668\u610f\u8bc6\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u5b9e\u8bc1\u68c0\u9a8c\u7684\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2512.01089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01089", "abs": "https://arxiv.org/abs/2512.01089", "authors": ["Peter Jansen", "Samiah Hassan", "Pragnya Narasimha"], "title": "CodeDistiller: Automatically Generating Code Libraries for Scientific Coding Agents", "comment": "8 pages, 3 figures, 2 tables", "summary": "Automated Scientific Discovery (ASD) systems can help automatically generate and run code-based experiments, but their capabilities are limited by the code they can reliably generate from parametric knowledge alone. As a result, current systems either mutate a small number of manually-crafted experiment examples, or operate solely from parametric knowledge, limiting quality and reach. We introduce CodeDistiller, a system that automatically distills large collections of scientific Github repositories into a vetted library of working domain-specific code examples, allowing ASD agents to expand their capabilities without manual effort. Using a combination of automatic and domain-expert evaluation on 250 materials science repositories, we find the best model is capable of producing functional examples for 74% of repositories, while our downstream evaluation shows an ASD agent augmented with a CodeDistiller generated library produces more accurate, complete, and scientifically sound experiments than an agent with only general materials-science code examples.", "AI": {"tldr": "CodeDistiller\u7cfb\u7edf\u81ea\u52a8\u4ece\u5927\u91cf\u79d1\u5b66Github\u4ed3\u5e93\u4e2d\u63d0\u53d6\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u9886\u57df\u7279\u5b9a\u4ee3\u7801\u793a\u4f8b\u5e93\uff0c\u589e\u5f3a\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u7684\u80fd\u529b", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u53d7\u9650\u4e8e\u4ec5\u4ece\u53c2\u6570\u77e5\u8bc6\u751f\u6210\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u8981\u4e48\u53ea\u80fd\u53d8\u5f02\u5c11\u91cf\u624b\u52a8\u7f16\u5199\u7684\u5b9e\u9a8c\u793a\u4f8b\uff0c\u8981\u4e48\u5b8c\u5168\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u8d28\u91cf\u548c\u8986\u76d6\u8303\u56f4", "method": "\u5f00\u53d1CodeDistiller\u7cfb\u7edf\uff0c\u81ea\u52a8\u4ece\u5927\u91cf\u79d1\u5b66Github\u4ed3\u5e93\u4e2d\u63d0\u53d6\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u9886\u57df\u7279\u5b9a\u4ee3\u7801\u793a\u4f8b\u5e93\uff0c\u7ed3\u5408\u81ea\u52a8\u548c\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u65b9\u6cd5", "result": "\u6700\u4f73\u6a21\u578b\u80fd\u4e3a74%\u7684\u4ed3\u5e93\u751f\u6210\u529f\u80fd\u793a\u4f8b\uff1b\u4f7f\u7528CodeDistiller\u751f\u6210\u5e93\u589e\u5f3a\u7684ASD\u4ee3\u7406\u6bd4\u4ec5\u4f7f\u7528\u901a\u7528\u6750\u6599\u79d1\u5b66\u4ee3\u7801\u793a\u4f8b\u7684\u4ee3\u7406\u4ea7\u751f\u66f4\u51c6\u786e\u3001\u5b8c\u6574\u548c\u79d1\u5b66\u5408\u7406\u7684\u5b9e\u9a8c", "conclusion": "CodeDistiller\u80fd\u591f\u81ea\u52a8\u4ece\u73b0\u6709\u79d1\u5b66\u4ee3\u7801\u5e93\u4e2d\u63d0\u53d6\u5de5\u4f5c\u4ee3\u7801\u793a\u4f8b\uff0c\u663e\u8457\u589e\u5f3a\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884"}}
{"id": "2512.01099", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01099", "abs": "https://arxiv.org/abs/2512.01099", "authors": ["Daria Smirnova", "Hamid Nasiri", "Marta Adamska", "Zhengxin Yu", "Peter Garraghan"], "title": "Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems", "comment": null, "summary": "As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.", "AI": {"tldr": "GUIDE\uff1a\u4e00\u4e2a\u57fa\u4e8e\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7279\u5f81\u7684\u80fd\u6e90\u611f\u77e5\u6a21\u578b\u9009\u62e9\u6846\u67b6\uff0c\u89e3\u51b3LLM\u7f16\u6392\u5668\u56e0\u4f9d\u8d56\u5b9a\u6027\u63cf\u8ff0\u5bfc\u81f4\u7684\u6b21\u4f18\u9009\u62e9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u548c\u80fd\u6e90\u6548\u7387", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u7f16\u6392\u5668\u4f9d\u8d56\u5b9a\u6027\u6a21\u578b\u63cf\u8ff0\u8fdb\u884c\u51b3\u7b56\uff0c\u8fd9\u4e9b\u63cf\u8ff0\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u6a21\u578b\u80fd\u529b\u548c\u6027\u80fd\u7279\u5f81\uff0c\u5bfc\u81f4\u6a21\u578b\u9009\u62e9\u6b21\u4f18\u5316\u3001\u51c6\u786e\u6027\u964d\u4f4e\u548c\u80fd\u6e90\u6210\u672c\u589e\u52a0", "method": "\u63d0\u51faGUIDE\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7279\u5f81\u7eb3\u5165\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8003\u8651\u6027\u80fd-\u80fd\u6e90\u6743\u8861\uff0c\u5b9e\u73b0\u80fd\u6e90\u611f\u77e5\u7684\u6a21\u578b\u9009\u62e9", "result": "GUIDE\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u5c06\u51c6\u786e\u6027\u63d0\u53470.90%-11.92%\uff0c\u80fd\u6e90\u6548\u7387\u6700\u9ad8\u63d0\u534754%\uff0c\u540c\u65f6\u5c06\u7f16\u6392\u5668\u6a21\u578b\u9009\u62e9\u5ef6\u8fdf\u4ece4.51\u79d2\u964d\u4f4e\u52307.2\u6beb\u79d2", "conclusion": "GUIDE\u6846\u67b6\u901a\u8fc7\u6574\u5408\u91cf\u5316\u6027\u80fd\u7279\u5f81\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u7f16\u6392\u5668\u7684\u5c40\u9650\u6027\uff0c\u5728\u51c6\u786e\u6027\u3001\u80fd\u6e90\u6548\u7387\u548c\u5ef6\u8fdf\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb"}}
{"id": "2512.01107", "categories": ["cs.AI", "econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.01107", "abs": "https://arxiv.org/abs/2512.01107", "authors": ["Sanjog Misra"], "title": "Foundation Priors", "comment": null, "summary": "Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.\n  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\"\u57fa\u7840\u5148\u9a8c\"\u6982\u5ff5\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u89c6\u4e3a\u5148\u9a8c\u9884\u6d4b\u5206\u5e03\u800c\u975e\u771f\u5b9e\u89c2\u6d4b\uff0c\u4e3a\u5728\u5b9e\u8bc1\u7814\u7a76\u4e2d\u5408\u7406\u4f7f\u7528\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u54cd\u5e94\uff0c\u7814\u7a76\u8005\u8d8a\u6765\u8d8a\u503e\u5411\u4e8e\u4f7f\u7528\u8fd9\u4e9b\"\u5408\u6210\"\u8f93\u51fa\u4f5c\u4e3a\u5b9e\u8bc1\u7814\u7a76\u548c\u51b3\u7b56\u7684\u6570\u636e\u3002\u4f46\u9700\u8981\u907f\u514d\u5c06\u5408\u6210\"\u4e8b\u5b9e\"\u4e0e\u771f\u5b9e\u6570\u636e\u6df7\u6dc6\uff0c\u9700\u8981\u7406\u8bba\u6846\u67b6\u6765\u89c4\u8303\u4f7f\u7528\u3002", "method": "\u63d0\u51fa\"\u57fa\u7840\u5148\u9a8c\"\u6982\u5ff5\uff0c\u5c06\u751f\u6210\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u7528\u6237\u9884\u671f\u6570\u636e\u5206\u5e03\u3001\u63d0\u793a\u5de5\u7a0b\u8fc7\u7a0b\u548c\u6a21\u578b\u4fe1\u4efb\u5ea6\u7684\u51fd\u6570\u3002\u63a8\u5bfc\u51fa\u57fa\u7840\u5148\u9a8c\u4f5c\u4e3a\u7528\u6237\u539f\u59cb\u5148\u9a8c\u7684\u6307\u6570\u503e\u659c\u5e7f\u4e49\u8d1d\u53f6\u65af\u66f4\u65b0\uff0c\u5176\u4e2d\u4fe1\u4efb\u53c2\u6570\u63a7\u5236\u5408\u6210\u6570\u636e\u7684\u6743\u91cd\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u5408\u6210\u6570\u636e\u548c\u57fa\u7840\u5148\u9a8c\u7eb3\u5165\u6807\u51c6\u7edf\u8ba1\u548c\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u6a21\u578b\u7cbe\u70bc\u3001\u6f5c\u5728\u6784\u5ff5\u6784\u5efa\u3001\u5b9e\u9a8c\u8bbe\u8ba1\u6307\u5bfc\u3001\u968f\u673a\u7cfb\u6570\u548c\u90e8\u5206\u7ebf\u6027\u89c4\u8303\u589e\u5f3a\u7b49\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u3002", "conclusion": "\u901a\u8fc7\u5c06\u751f\u6210\u8f93\u51fa\u89c6\u4e3a\u7ed3\u6784\u5316\u3001\u660e\u786e\u4e3b\u89c2\u7684\u5148\u9a8c\u800c\u975e\u7ecf\u9a8c\u89c2\u6d4b\uff0c\u8be5\u6846\u67b6\u4e3a\u5728\u5b9e\u8bc1\u5de5\u4f5c\u4e2d\u5229\u7528\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u540c\u65f6\u907f\u514d\u4e86\u5408\u6210\"\u4e8b\u5b9e\"\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u6df7\u6dc6\u3002"}}
{"id": "2512.01149", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01149", "abs": "https://arxiv.org/abs/2512.01149", "authors": ["Krishna Taduri", "Shaunak Dhande", "Giacinto Paolo", "Saggese", "Paul Smith"], "title": "A Benchmark of Causal vs Correlation AI for Predictive Maintenance", "comment": null, "summary": "Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.", "AI": {"tldr": "\u56e0\u679cAI\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u7ef4\u62a4\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u76f8\u5173\u6a21\u578b\uff0c\u5b9e\u73b0\u5e74\u8282\u7701116\u4e07\u7f8e\u5143\uff0c\u51cf\u5c1170.2%\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ec\u56de\u7387\u5e76\u5927\u5e45\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u5236\u9020\u4e1a\u9884\u6d4b\u6027\u7ef4\u62a4\u9762\u4e34\u6781\u7aef\u6210\u672c\u4e0d\u5bf9\u79f0\u95ee\u9898\uff08\u6f0f\u68c0\u6210\u672c\u662f\u8bef\u62a5\u768450\u500d\uff09\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316\u7edf\u8ba1\u51c6\u786e\u6027\u6307\u6807\u800c\u975e\u5b9e\u9645\u8fd0\u8425\u6210\u672c\uff0c\u4e14\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u56e0\u679c\u5173\u7cfb\u4e0e\u865a\u5047\u76f8\u5173\u3002", "method": "\u8bc4\u4f30\u516b\u79cd\u9884\u6d4b\u6a21\u578b\uff0c\u5305\u62ec\u57fa\u7ebf\u7edf\u8ba1\u65b9\u6cd5\u548c\u6b63\u5f0f\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u572810,000\u53f0CNC\u673a\u5e8a\u6570\u636e\u96c6\uff08\u6545\u969c\u73873.3%\uff09\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u5bf9\u6bd4\u56e0\u679c\u6a21\u578b\uff08L5\uff09\u4e0e\u6700\u4f73\u76f8\u5173\u51b3\u7b56\u6811\u6a21\u578b\uff08L3\uff09\u7684\u6027\u80fd\u3002", "result": "\u56e0\u679c\u6a21\u578b\u5b9e\u73b0\u5e74\u8282\u7701116\u4e07\u7f8e\u5143\uff08\u6210\u672c\u964d\u4f4e70.2%\uff09\uff0c\u6bd4\u6700\u4f73\u76f8\u5173\u6a21\u578b\u591a\u8282\u77018\u4e07\u7f8e\u5143/\u5e74\u3002\u4fdd\u6301\u6700\u9ad8\u53ec\u56de\u738787.9%\uff0c\u540c\u65f6\u5c06\u8bef\u62a5\u51cf\u5c1197%\uff08\u4ece165\u964d\u81f35\uff09\uff0c\u7cbe\u5ea6\u8fbe92.1%\uff0c\u8bad\u7ec3-\u6d4b\u8bd5\u6027\u80fd\u5dee\u8ddd\u4ec52.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u56e0\u679cAI\u65b9\u6cd5\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\uff0c\u5728\u9884\u6d4b\u6027\u7ef4\u62a4\u5e94\u7528\u4e2d\u6bd4\u76f8\u5173\u65b9\u6cd5\u4ea7\u751f\u66f4\u4f18\u7684\u8d22\u52a1\u7ed3\u679c\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\uff0c\u8868\u660e\u56e0\u679c\u63a8\u7406\u5728\u5de5\u4e1a\u4f18\u5316\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2512.01189", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01189", "abs": "https://arxiv.org/abs/2512.01189", "authors": ["Chunzheng Zhu", "Jialin Shao", "Jianxin Lin", "Yijun Wang", "Jing Wang", "Jinhui Tang", "Kenli Li"], "title": "fMRI2GES: Co-speech Gesture Reconstruction from fMRI Signal with Dual Brain Decoding Alignment", "comment": "IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) 2025", "summary": "Understanding how the brain responds to external stimuli and decoding this process has been a significant challenge in neuroscience. While previous studies typically concentrated on brain-to-image and brain-to-language reconstruction, our work strives to reconstruct gestures associated with speech stimuli perceived by brain. Unfortunately, the lack of paired \\{brain, speech, gesture\\} data hinders the deployment of deep learning models for this purpose. In this paper, we introduce a novel approach, \\textbf{fMRI2GES}, that allows training of fMRI-to-gesture reconstruction networks on unpaired data using \\textbf{Dual Brain Decoding Alignment}. This method relies on two key components: (i) observed texts that elicit brain responses, and (ii) textual descriptions associated with the gestures. Then, instead of training models in a completely supervised manner to find a mapping relationship among the three modalities, we harness an fMRI-to-text model, a text-to-gesture model with paired data and an fMRI-to-gesture model with unpaired data, establishing dual fMRI-to-gesture reconstruction patterns. Afterward, we explicitly align two outputs and train our model in a self-supervision way. We show that our proposed method can reconstruct expressive gestures directly from fMRI recordings. We also investigate fMRI signals from different ROIs in the cortex and how they affect generation results. Overall, we provide new insights into decoding co-speech gestures, thereby advancing our understanding of neuroscience and cognitive science.", "AI": {"tldr": "\u63d0\u51fafMRI2GES\u65b9\u6cd5\uff0c\u5229\u7528\u53cc\u8111\u89e3\u7801\u5bf9\u9f50\u6280\u672f\uff0c\u5728\u65e0\u914d\u5bf9\u6570\u636e\u60c5\u51b5\u4e0b\u4ecefMRI\u4fe1\u53f7\u91cd\u5efa\u8bed\u97f3\u76f8\u5173\u624b\u52bf", "motivation": "\u4f20\u7edf\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8111\u5230\u56fe\u50cf\u548c\u8111\u5230\u8bed\u8a00\u7684\u91cd\u5efa\uff0c\u4f46\u7f3a\u4e4f\u4ece\u8111\u4fe1\u53f7\u91cd\u5efa\u8bed\u97f3\u76f8\u5173\u624b\u52bf\u7684\u7814\u7a76\u3002\u7531\u4e8e\u7f3a\u4e4f\u914d\u5bf9\u7684{\u8111\u3001\u8bed\u97f3\u3001\u624b\u52bf}\u6570\u636e\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u3002", "method": "\u63d0\u51fafMRI2GES\u65b9\u6cd5\uff0c\u91c7\u7528\u53cc\u8111\u89e3\u7801\u5bf9\u9f50\u6280\u672f\uff1a1) \u5229\u7528\u5f15\u53d1\u8111\u54cd\u5e94\u7684\u89c2\u5bdf\u6587\u672c\uff1b2) \u5229\u7528\u4e0e\u624b\u52bf\u76f8\u5173\u7684\u6587\u672c\u63cf\u8ff0\u3002\u901a\u8fc7fMRI\u5230\u6587\u672c\u6a21\u578b\u3001\u6587\u672c\u5230\u624b\u52bf\u6a21\u578b\uff08\u6709\u914d\u5bf9\u6570\u636e\uff09\u548cfMRI\u5230\u624b\u52bf\u6a21\u578b\uff08\u65e0\u914d\u5bf9\u6570\u636e\uff09\u5efa\u7acb\u53cc\u91cd\u91cd\u5efa\u6a21\u5f0f\uff0c\u7136\u540e\u5bf9\u9f50\u4e24\u4e2a\u8f93\u51fa\u8fdb\u884c\u81ea\u76d1\u7763\u8bad\u7ec3\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u76f4\u63a5\u4ecefMRI\u8bb0\u5f55\u4e2d\u91cd\u5efa\u5bcc\u6709\u8868\u73b0\u529b\u7684\u624b\u52bf\uff0c\u5e76\u7814\u7a76\u4e86\u5927\u8111\u76ae\u5c42\u4e0d\u540cROI\u533a\u57df\u7684fMRI\u4fe1\u53f7\u5bf9\u751f\u6210\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "conclusion": "\u4e3a\u89e3\u7801\u4f34\u968f\u8bed\u97f3\u7684\u624b\u52bf\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u63a8\u52a8\u4e86\u795e\u7ecf\u79d1\u5b66\u548c\u8ba4\u77e5\u79d1\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.01210", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01210", "abs": "https://arxiv.org/abs/2512.01210", "authors": ["Ruiyu Wang", "Tuan Vinh", "Ran Xu", "Yuyin Zhou", "Jiaying Lu", "Carl Yang", "Francisco Pasquel"], "title": "Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction", "comment": null, "summary": "Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u5f15\u5bfc\u7684\u601d\u7ef4\u94fe\u6846\u67b6\uff0c\u4e3a\u7535\u5b50\u75c5\u5386\u4e2d\u7684\u75be\u75c5\u9884\u6d4b\u751f\u6210\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728MIMIC-III\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u80fd\u96f6\u6837\u672c\u8fc1\u79fb\u5230\u5176\u4ed6\u961f\u5217\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u75c5\u5386\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u63d0\u4f9b\u7c97\u7565\u7684\u4e8b\u540e\u89e3\u91ca\uff0c\u5bf9\u60a3\u8005\u5c42\u9762\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u6709\u9650\uff0c\u9700\u8981\u66f4\u7ec6\u81f4\u3001\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u5c06ICD-9\u7f16\u7801\u6620\u5c04\u5230PrimeKG\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u53d6\u75be\u75c5\u76f8\u5173\u8282\u70b9\u548c\u591a\u8df3\u63a8\u7406\u8def\u5f84\u4f5c\u4e3a\u601d\u7ef4\u94fe\u7684\u9aa8\u67b6\uff0c\u4ec5\u4fdd\u7559\u4e0e\u89c2\u5bdf\u7ed3\u679c\u4e00\u81f4\u7684\u63a8\u7406\uff0c\u7136\u540e\u5fae\u8c03\u8f7b\u91cf\u7ea7LLaMA-3.1\u548cGemma\u6a21\u578b\u3002", "result": "\u572810\u79cdPrimeKG\u6620\u5c04\u75be\u75c5\u548c\u6709\u9650\u8bad\u7ec3\u6570\u636e\uff08400\u548c1000\u4f8b\uff09\u4e0b\uff0cKG\u5f15\u5bfc\u6a21\u578bAUROC\u8fbe0.66-0.70\uff0cmacro-AUPR\u8fbe0.40-0.47\uff0c\u96f6\u6837\u672c\u8fc1\u79fb\u5230CRADLE\u961f\u5217\u65f6\u51c6\u786e\u7387\u4ece0.40-0.51\u63d0\u5347\u81f30.72-0.77\u3002", "conclusion": "KG\u5f15\u5bfc\u7684\u601d\u7ef4\u94fe\u6846\u67b6\u80fd\u751f\u6210\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u63d0\u9ad8\u75be\u75c5\u9884\u6d4b\u6027\u80fd\uff0c\u76f2\u6cd5\u4e34\u5e8a\u8bc4\u4f30\u663e\u793a\u5176\u5728\u6e05\u6670\u5ea6\u3001\u76f8\u5173\u6027\u548c\u4e34\u5e8a\u6b63\u786e\u6027\u65b9\u9762\u66f4\u53d7\u9752\u7750\u3002"}}
{"id": "2512.01222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01222", "abs": "https://arxiv.org/abs/2512.01222", "authors": ["Ching Fang", "Samuel Marks"], "title": "Unsupervised decoding of encoded reasoning using language model interpretability", "comment": null, "summary": "As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6784\u5efaROT-13\u52a0\u5bc6\u63a8\u7406\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u8bc4\u4f30\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff08\u7279\u522b\u662flogit lens\uff09\u80fd\u5426\u89e3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\uff0c\u53d1\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u6bd4\u9884\u671f\u66f4\u6709\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u589e\u5f3a\uff0c\u4eba\u4eec\u62c5\u5fc3\u5b83\u4eec\u53ef\u80fd\u53d1\u5c55\u51fa\u4eba\u7c7b\u65e0\u6cd5\u76d1\u7763\u7684\u7f16\u7801\u6216\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\u3002\u9700\u8981\u7814\u7a76\u5f53\u524d\u53ef\u89e3\u91ca\u6027\u6280\u672f\u80fd\u5426\u7a7f\u900f\u8fd9\u79cd\u7f16\u7801\u63a8\u7406\u3002", "method": "\u901a\u8fc7\u5fae\u8c03\u63a8\u7406\u6a21\u578b\uff08DeepSeek-R1-Distill-Llama-70B\uff09\u4f7f\u5176\u5728ROT-13\u52a0\u5bc6\u4e0b\u8fdb\u884c\u94fe\u5f0f\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u8bfb\u7684\u82f1\u6587\u8f93\u51fa\u3002\u4f7f\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff08\u7279\u522b\u662flogit lens\u5206\u6790\uff09\u8bc4\u4f30\u4ec5\u901a\u8fc7\u5185\u90e8\u6fc0\u6d3b\u89e3\u7801\u6a21\u578b\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\u7684\u80fd\u529b\u3002", "result": "logit lens\u80fd\u6709\u6548\u7ffb\u8bd1\u7f16\u7801\u63a8\u7406\uff0c\u51c6\u786e\u7387\u5728\u4e2d\u95f4\u5230\u540e\u671f\u5c42\u8fbe\u5230\u5cf0\u503c\u3002\u5f00\u53d1\u4e86\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u89e3\u7801\u6d41\u7a0b\uff0c\u7ed3\u5408logit lens\u548c\u81ea\u52a8\u8f6c\u8ff0\uff0c\u4ece\u5185\u90e8\u6a21\u578b\u8868\u793a\u4e2d\u91cd\u5efa\u5b8c\u6574\u63a8\u7406\u8bb0\u5f55\uff0c\u53d6\u5f97\u663e\u8457\u51c6\u786e\u7387\u3002", "conclusion": "\u5f53\u524d\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5bf9\u7b80\u5355\u7f16\u7801\u63a8\u7406\u7684\u9c81\u68d2\u6027\u53ef\u80fd\u6bd4\u4e4b\u524d\u7406\u89e3\u7684\u66f4\u5f3a\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8bc4\u4f30\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5bf9\u6297\u975e\u4eba\u7c7b\u53ef\u8bfb\u683c\u5f0f\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u7ef4\u62a4\u5bf9\u65e5\u76ca\u5f3a\u5927AI\u7cfb\u7edf\u7684\u76d1\u7763\u3002"}}
{"id": "2512.01289", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2512.01289", "abs": "https://arxiv.org/abs/2512.01289", "authors": ["Mingqin Yu", "Fethi Rabhi", "Boming Xia", "Zhengyi Yang", "Felix Tan", "Qinghua Lu"], "title": "OntoMetric: An Ontology-Guided Framework for Automated ESG Knowledge Graph Construction", "comment": null, "summary": "Environmental, Social, and Governance (ESG) disclosure frameworks such as SASB, TCFD, and IFRS S2 require organizations to compute and report numerous metrics for compliance, yet these requirements are embedded in long, unstructured PDF documents that are difficult to interpret, standardize, and audit. Manual extraction is unscalable, while unconstrained large language model (LLM) extraction often produces inconsistent entities, hallucinated relationships, missing provenance, and high validation failure rates. We present OntoMetric, an ontology-guided framework that transforms ESG regulatory documents into validated, AI- and web-ready knowledge graphs. OntoMetric operates through a three-stage pipeline: (1) structure-aware segmentation using table-of-contents boundaries, (2) ontology-constrained LLM extraction that embeds the ESGMKG schema into prompts while enriching entities with semantic fields for downstream reasoning, and (3) two-phase validation that combines LLM-based semantic verification with rule-based schema checking across entity, property, and relationship levels (VR001-VR006). The framework preserves both segment-level and page-level provenance for audit traceability. Evaluated on five ESG standards (SASB Commercial Banks, SASB Semiconductors, TCFD, IFRS S2, AASB S2) totaling 228 pages and 60 segments, OntoMetric achieves 65-90% semantic accuracy and 80-90% schema compliance, compared to 3-10% for baseline unconstrained extraction, at approximately 0.01 to 0.02 USD per validated entity. Our results demonstrate that combining symbolic ontology constraints with neural extraction enables reliable, auditable knowledge graphs suitable for regulatory compliance and web integration, supporting downstream applications such as sustainable-finance analytics, transparency portals, and automated compliance tools.", "AI": {"tldr": "OntoMetric\uff1a\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u8bba\u6307\u5bfc\u7684\u6846\u67b6\uff0c\u5c06ESG\u76d1\u7ba1\u6587\u6863\u8f6c\u5316\u4e3a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u3001AI\u548c\u7f51\u7edc\u5c31\u7eea\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u7ed3\u5408\u7b26\u53f7\u7ea6\u675f\u4e0e\u795e\u7ecf\u63d0\u53d6\uff0c\u663e\u8457\u63d0\u9ad8\u63d0\u53d6\u51c6\u786e\u6027\u548c\u5408\u89c4\u6027\u3002", "motivation": "\u5f53\u524dESG\u62ab\u9732\u6846\u67b6\uff08\u5982SASB\u3001TCFD\u3001IFRS S2\uff09\u7684\u8981\u6c42\u5d4c\u5165\u5728\u5197\u957f\u3001\u975e\u7ed3\u6784\u5316\u7684PDF\u6587\u6863\u4e2d\uff0c\u96be\u4ee5\u89e3\u91ca\u3001\u6807\u51c6\u5316\u548c\u5ba1\u8ba1\u3002\u624b\u52a8\u63d0\u53d6\u4e0d\u53ef\u6269\u5c55\uff0c\u800c\u65e0\u7ea6\u675f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u5b58\u5728\u5b9e\u4f53\u4e0d\u4e00\u81f4\u3001\u5173\u7cfb\u5e7b\u89c9\u3001\u7f3a\u4e4f\u6765\u6e90\u8ffd\u6eaf\u548c\u9ad8\u9a8c\u8bc1\u5931\u8d25\u7387\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a1\uff09\u57fa\u4e8e\u76ee\u5f55\u8fb9\u754c\u7684\u7ed3\u6784\u611f\u77e5\u5206\u5272\uff1b2\uff09\u672c\u4f53\u7ea6\u675f\u7684LLM\u63d0\u53d6\uff0c\u5c06ESGMKG\u6a21\u5f0f\u5d4c\u5165\u63d0\u793a\u4e2d\uff0c\u540c\u65f6\u7528\u8bed\u4e49\u5b57\u6bb5\u4e30\u5bcc\u5b9e\u4f53\u4ee5\u652f\u6301\u4e0b\u6e38\u63a8\u7406\uff1b3\uff09\u4e24\u9636\u6bb5\u9a8c\u8bc1\uff0c\u7ed3\u5408\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u9a8c\u8bc1\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u6a21\u5f0f\u68c0\u67e5\uff08VR001-VR006\uff09\uff0c\u4fdd\u7559\u6bb5\u7ea7\u548c\u9875\u7ea7\u6765\u6e90\u4ee5\u5b9e\u73b0\u5ba1\u8ba1\u53ef\u8ffd\u6eaf\u6027\u3002", "result": "\u5728\u4e94\u4e2aESG\u6807\u51c6\uff08\u603b\u8ba1228\u9875\u300160\u4e2a\u6bb5\u843d\uff09\u4e0a\u8bc4\u4f30\uff0cOntoMetric\u5b9e\u73b065-90%\u7684\u8bed\u4e49\u51c6\u786e\u6027\u548c80-90%\u7684\u6a21\u5f0f\u5408\u89c4\u6027\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65e0\u7ea6\u675f\u63d0\u53d6\u76843-10%\u6709\u663e\u8457\u63d0\u5347\uff0c\u6bcf\u4e2a\u9a8c\u8bc1\u5b9e\u4f53\u7684\u6210\u672c\u7ea6\u4e3a0.01-0.02\u7f8e\u5143\u3002", "conclusion": "\u5c06\u7b26\u53f7\u672c\u4f53\u7ea6\u675f\u4e0e\u795e\u7ecf\u63d0\u53d6\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u521b\u5efa\u53ef\u9760\u3001\u53ef\u5ba1\u8ba1\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u9002\u7528\u4e8e\u76d1\u7ba1\u5408\u89c4\u548c\u7f51\u7edc\u96c6\u6210\uff0c\u652f\u6301\u53ef\u6301\u7eed\u91d1\u878d\u5206\u6790\u3001\u900f\u660e\u5ea6\u95e8\u6237\u548c\u81ea\u52a8\u5316\u5408\u89c4\u5de5\u5177\u7b49\u4e0b\u6e38\u5e94\u7528\u3002"}}
{"id": "2512.01300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01300", "abs": "https://arxiv.org/abs/2512.01300", "authors": ["Dacheng Liao", "Mengshi Qi", "Peng Shu", "Zhining Zhang", "Yuxin Lin", "Liang Liu", "Huadong Ma"], "title": "RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving", "comment": null, "summary": "Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86RoboDriveBench\uff0c\u9996\u4e2a\u9488\u5bf9VLM\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7684\u9c81\u68d2\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b11\u79cd\u4f20\u611f\u5668\u548c\u63d0\u793a\u635f\u574f\u573a\u666f\uff0c\u5e76\u63d0\u51fa\u4e86RoboDriveVLM\u6846\u67b6\u548c\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9a7e\u9a76\u51b3\u7b56\uff0c\u4f46\u5728\u73b0\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u5b58\u5728\u591a\u79cd\u98ce\u9669\u3002\u9700\u8981\u8bc4\u4f30VLM\u662f\u5426\u771f\u6b63\u9002\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\uff0c\u5e76\u89e3\u51b3\u5176\u9c81\u68d2\u6027\u95ee\u9898\u3002", "method": "1) \u63d0\u51faRoboDriveBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b11\u79cd\u6a21\u62df\u573a\u666f\uff086\u79cd\u4f20\u611f\u5668\u635f\u574f\u548c5\u79cd\u63d0\u793a\u635f\u574f\uff09\uff0c\u517164,559\u4e2a\u8f68\u8ff9\u9884\u6d4b\u6848\u4f8b\uff1b2) \u63d0\u51faRoboDriveVLM\u6846\u67b6\uff0c\u5c06\u66f4\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u6fc0\u5149\u96f7\u8fbe\u548c\u96f7\u8fbe\uff09\u6620\u5c04\u5230\u7edf\u4e00\u6f5c\u5728\u7a7a\u95f4\uff1b3) \u63d0\u51fa\u57fa\u4e8e\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\uff0c\u5de5\u4f5c\u63ed\u793a\u4e86\u5f53\u524dVLM\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u73b0\u5b9e\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u53d1\u5e03\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5f53\u524dVLM\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u8bc4\u4f30\u57fa\u51c6\u548c\u6539\u8fdb\u6846\u67b6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.01311", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01311", "abs": "https://arxiv.org/abs/2512.01311", "authors": ["Shinji Mai", "Yunpeng Zhai", "Ziqian Chen", "Cheng Chen", "Anni Zou", "Shuchang Tao", "Zhaoyang Liu", "Bolin Ding"], "title": "CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL", "comment": null, "summary": "Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/research/CuES.", "AI": {"tldr": "CuES\u6846\u67b6\u901a\u8fc7\u597d\u5947\u5fc3\u9a71\u52a8\u548c\u73af\u5883\u57fa\u7840\u7684\u4efb\u52a1\u751f\u6210\uff0c\u89e3\u51b3\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u4efb\u52a1\u7a00\u7f3a\u95ee\u9898\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u4efb\u52a1\u5373\u53ef\u81ea\u4e3b\u751f\u6210\u591a\u6837\u3001\u53ef\u6267\u884c\u7684\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u5de5\u5177\u589e\u5f3a\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\uff0c\u5f3a\u5316\u5b66\u4e60\u6548\u679c\u4e25\u91cd\u4f9d\u8d56\u7ed3\u6784\u5316\u8bad\u7ec3\u4efb\u52a1\u3002\u7136\u800c\u5728\u8bb8\u591a\u5b9e\u9645\u73af\u5883\u4e2d\uff0c\u9884\u5b9a\u4e49\u4efb\u52a1\u5e76\u4e0d\u5b58\u5728\uff08\u4efb\u52a1\u7a00\u7f3a\u95ee\u9898\uff09\uff0c\u8fd9\u6210\u4e3a\u6269\u5c55\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6709\u9884\u5b9a\u4e49\u4efb\u52a1\u96c6\u5408\uff0c\u8fd9\u5728\u5de5\u5177\u8bed\u4e49\u548c\u53ef\u7528\u6027\u672a\u77e5\u7684\u65b0\u73af\u5883\u4e2d\u4e0d\u6210\u7acb\u3002", "method": "\u63d0\u51faCuES\u6846\u67b6\uff1a\u597d\u5947\u5fc3\u9a71\u52a8\u548c\u73af\u5883\u57fa\u7840\u7684\u4efb\u52a1\u5408\u6210\u65b9\u6cd5\u3002\u901a\u8fc7\u5185\u5728\u597d\u5947\u5fc3\u9a71\u52a8\u63a2\u7d22\uff0c\u4ece\u73af\u5883\u7ed3\u6784\u548c\u53ef\u7528\u6027\u4e2d\u62bd\u8c61\u4ea4\u4e92\u6a21\u5f0f\u4e3a\u53ef\u91cd\u7528\u4efb\u52a1\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u4e0a\u800c\u4e0b\u6307\u5bfc\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8d28\u91cf\u63a7\u5236\u8fdb\u884c\u7cbe\u70bc\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4eba\u5de5\u79cd\u5b50\u6216\u5916\u90e8\u8bed\u6599\u5e93\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u73af\u5883\uff08AppWorld\u3001BFCL\u3001WebShop\uff09\u4e2d\uff0cCuES\u751f\u6210\u7684\u4efb\u52a1\u5206\u5e03\u5728\u591a\u6837\u6027\u548c\u53ef\u6267\u884c\u6027\u65b9\u9762\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u624b\u52a8\u7b56\u5212\u7684\u6570\u636e\u96c6\uff0c\u5e26\u6765\u663e\u8457\u7684\u4e0b\u6e38\u7b56\u7565\u6539\u8fdb\u3002", "conclusion": "\u597d\u5947\u5fc3\u9a71\u52a8\u3001\u73af\u5883\u57fa\u7840\u7684\u4efb\u52a1\u751f\u6210\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u4f7f\u667a\u80fd\u4f53\u4e0d\u4ec5\u80fd\u5b66\u4e60\u5982\u4f55\u884c\u52a8\uff0c\u8fd8\u80fd\u5b66\u4e60\u5b66\u4e60\u4ec0\u4e48\u3002\u8fd9\u4e3a\u89e3\u51b3\u4efb\u52a1\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.01321", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01321", "abs": "https://arxiv.org/abs/2512.01321", "authors": ["Juan Hernandez", "Diego Fern\u00e1ndez", "Manuel Cifuentes", "Denis Parra", "Rodrigo Toro Icarte"], "title": "Extending NGU to Multi-Agent RL: A Preliminary Study", "comment": "9 pages, 4 figures, 1 table. Accepted at the LatinX in AI (LXAI) Workshop at NeurIPS 2025. Includes experimental results for Multi-NGU and Multi-DQN in the PettingZoo simple_tag environment", "summary": "The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.", "AI": {"tldr": "\u5c06NGU\u7b97\u6cd5\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u5728PettingZoo\u7684simple_tag\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u53d1\u73b0\u5171\u4eab\u7ecf\u9a8c\u56de\u653e\u7ed3\u5408\u5185\u5728\u63a2\u7d22\u80fd\u63d0\u5347\u6027\u80fd", "motivation": "NGU\u7b97\u6cd5\u5728\u7a00\u758f\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5c1a\u672a\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22NGU\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u6548\u679c", "method": "\u5c06NGU\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u5728simple_tag\u73af\u5883\u4e2d\u4e0e\u591a\u667a\u80fd\u4f53DQN\u57fa\u7ebf\u5bf9\u6bd4\uff0c\u7814\u7a76\u4e09\u79cd\u8bbe\u8ba1\u9009\u62e9\uff1a\u5171\u4eab/\u4e2a\u4f53\u56de\u653e\u7f13\u51b2\u533a\u3001\u4e0d\u540ck\u9608\u503c\u7684\u65b0\u5947\u6027\u5171\u4eab\u3001\u5f02\u8d28beta\u53c2\u6570", "result": "NGU\u6bd4\u591a\u667a\u80fd\u4f53DQN\u57fa\u7ebf\u83b7\u5f97\u4e2d\u7b49\u66f4\u9ad8\u7684\u56de\u62a5\u548c\u66f4\u7a33\u5b9a\u7684\u5b66\u4e60\u52a8\u6001\u3002\u5171\u4eab\u56de\u653e\u7f13\u51b2\u533a\u8868\u73b0\u6700\u4f73\uff0c\u65b0\u5947\u6027\u5171\u4eab\u5728k=1\u65f6\u6548\u679c\u76f8\u5f53\u4f46k\u503c\u589e\u5927\u4f1a\u964d\u4f4e\u5b66\u4e60\u6548\u679c\uff0c\u5f02\u8d28beta\u53c2\u6570\u6ca1\u6709\u6539\u8fdb", "conclusion": "NGU\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\uff0c\u5173\u952e\u5728\u4e8e\u5171\u4eab\u7ecf\u9a8c\u548c\u7cbe\u5fc3\u8c03\u6574\u5185\u5728\u63a2\u7d22\u4fe1\u53f7\u3002\u5171\u4eab\u56de\u653e\u7f13\u51b2\u533a\u7ed3\u5408NGU\u5185\u5728\u63a2\u7d22\u80fd\u5e26\u6765\u6700\u4f73\u6027\u80fd\u548c\u7a33\u5b9a\u6027"}}
{"id": "2512.01331", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01331", "abs": "https://arxiv.org/abs/2512.01331", "authors": ["Saman Ahmadi", "Mahdi Jalili"], "title": "A Fast Heuristic Search Approach for Energy-Optimal Profile Routing for Electric Vehicles", "comment": "13 pages, 5 Figures, 1 table, To appear as part of AAAI 2026 Proceedings", "summary": "We study the energy-optimal shortest path problem for electric vehicles (EVs) in large-scale road networks, where recuperated energy along downhill segments introduces negative energy costs. While traditional point-to-point pathfinding algorithms for EVs assume a known initial energy level, many real-world scenarios involving uncertainty in available energy require planning optimal paths for all possible initial energy levels, a task known as energy-optimal profile search. Existing solutions typically rely on specialized profile-merging procedures within a label-correcting framework that results in searching over complex profiles. In this paper, we propose a simple yet effective label-setting approach based on multi-objective A* search, which employs a novel profile dominance rule to avoid generating and handling complex profiles. We develop four variants of our method and evaluate them on real-world road networks enriched with realistic energy consumption data. Experimental results demonstrate that our energy profile A* search achieves performance comparable to energy-optimal A* with a known initial energy level.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u76ee\u6807A*\u641c\u7d22\u7684\u6807\u7b7e\u8bbe\u7f6e\u65b9\u6cd5\uff0c\u7528\u4e8e\u7535\u52a8\u6c7d\u8f66\u80fd\u91cf\u6700\u4f18\u8def\u5f84\u89c4\u5212\uff0c\u907f\u514d\u5904\u7406\u590d\u6742\u80fd\u91cf\u66f2\u7ebf", "motivation": "\u4f20\u7edf\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u5047\u8bbe\u5df2\u77e5\u521d\u59cb\u80fd\u91cf\u6c34\u5e73\uff0c\u4f46\u5b9e\u9645\u573a\u666f\u4e2d\u521d\u59cb\u80fd\u91cf\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u4e3a\u6240\u6709\u53ef\u80fd\u7684\u521d\u59cb\u80fd\u91cf\u6c34\u5e73\u89c4\u5212\u6700\u4f18\u8def\u5f84\uff08\u80fd\u91cf\u6700\u4f18\u66f2\u7ebf\u641c\u7d22\uff09", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u76ee\u6807A*\u641c\u7d22\u7684\u6807\u7b7e\u8bbe\u7f6e\u65b9\u6cd5\uff0c\u91c7\u7528\u65b0\u9896\u7684\u66f2\u7ebf\u652f\u914d\u89c4\u5219\u907f\u514d\u751f\u6210\u548c\u5904\u7406\u590d\u6742\u80fd\u91cf\u66f2\u7ebf\uff0c\u5f00\u53d1\u4e86\u56db\u79cd\u53d8\u4f53\u65b9\u6cd5", "result": "\u5728\u771f\u5b9e\u9053\u8def\u7f51\u7edc\u4e0a\u4f7f\u7528\u5b9e\u9645\u80fd\u91cf\u6d88\u8017\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u80fd\u91cf\u66f2\u7ebfA*\u641c\u7d22\u7684\u6027\u80fd\u4e0e\u5df2\u77e5\u521d\u59cb\u80fd\u91cf\u6c34\u5e73\u7684\u80fd\u91cf\u6700\u4f18A*\u76f8\u5f53", "conclusion": "\u63d0\u51fa\u7684\u6807\u7b7e\u8bbe\u7f6e\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u80fd\u591f\u5904\u7406\u7535\u52a8\u6c7d\u8f66\u80fd\u91cf\u6700\u4f18\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u521d\u59cb\u80fd\u91cf\u4e0d\u786e\u5b9a\u6027\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u590d\u6742\u7684\u66f2\u7ebf\u5408\u5e76\u8fc7\u7a0b"}}
{"id": "2512.01351", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01351", "abs": "https://arxiv.org/abs/2512.01351", "authors": ["Elinor Poole-Dayan", "Jiayi Wu", "Taylor Sorensen", "Jiaxin Pei", "Michiel A. Bakker"], "title": "Benchmarking Overton Pluralism in LLMs", "comment": null, "summary": "We introduce a novel framework for measuring Overton pluralism in LLMs--the extent to which diverse viewpoints are represented in model outputs. We (i) formalize Overton pluralism as a set coverage metric (OvertonScore), (ii) conduct a large-scale U.S.-representative human study (N = 1209; 60 questions; 8 LLMs), and (iii) develop an automated benchmark that closely reproduces human judgments. On average, models achieve OvertonScores of 0.35--0.41, with DeepSeek V3 performing best; yet all models remain far below the theoretical maximum of 1.0, revealing substantial headroom for improvement. Because repeated large-scale human studies are costly and slow, scalable evaluation tools are essential for model development. Hence, we propose an automated benchmark that achieves high rank correlation with human judgments ($\u03c1=0.88$), providing a practical proxy without replacing human assessment. By turning pluralistic alignment from a normative aim into a measurable benchmark, our work establishes a foundation for systematic progress toward more pluralistic LLMs.", "AI": {"tldr": "\u63d0\u51faOvertonScore\u6846\u67b6\u91cf\u5316LLMs\u89c2\u70b9\u591a\u6837\u6027\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u4eba\u7c7b\u7814\u7a76\u8bc4\u4f308\u4e2a\u6a21\u578b\uff0c\u5f00\u53d1\u81ea\u52a8\u5316\u57fa\u51c6\u5de5\u5177\uff0c\u53d1\u73b0\u6a21\u578b\u591a\u6837\u6027\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709LLMs\u8bc4\u4f30\u7f3a\u4e4f\u5bf9\u89c2\u70b9\u591a\u6837\u6027\u7684\u7cfb\u7edf\u6d4b\u91cf\uff0c\u9700\u8981\u5c06\u591a\u5143\u4e3b\u4e49\u5bf9\u9f50\u4ece\u89c4\u8303\u6027\u76ee\u6807\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u7684\u57fa\u51c6\uff0c\u4ee5\u63a8\u52a8\u6a21\u578b\u5411\u66f4\u5305\u5bb9\u7684\u65b9\u5411\u53d1\u5c55\u3002", "method": "1) \u5c06Overton\u591a\u5143\u4e3b\u4e49\u5f62\u5f0f\u5316\u4e3a\u96c6\u5408\u8986\u76d6\u5ea6\u91cf\uff1b2) \u8fdb\u884c\u5927\u89c4\u6a21\u4ee3\u8868\u6027\u4eba\u7c7b\u7814\u7a76(N=1209, 60\u4e2a\u95ee\u9898, 8\u4e2aLLMs)\uff1b3) \u5f00\u53d1\u81ea\u52a8\u5316\u57fa\u51c6\u5de5\u5177\uff0c\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u76f8\u5173\u3002", "result": "\u6a21\u578b\u5e73\u5747OvertonScore\u4e3a0.35-0.41\uff0cDeepSeek V3\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u8fdc\u4f4e\u4e8e\u7406\u8bba\u6700\u5927\u503c1.0\u3002\u81ea\u52a8\u5316\u57fa\u51c6\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u79e9\u76f8\u5173\u6027\u8fbe\u5230\u03c1=0.88\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u548c\u6539\u8fdbLLMs\u89c2\u70b9\u591a\u6837\u6027\u5efa\u7acb\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u81ea\u52a8\u5316\u57fa\u51c6\u5de5\u5177\u4e3a\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f46\u4eba\u7c7b\u8bc4\u4f30\u4ecd\u4e0d\u53ef\u66ff\u4ee3\u3002"}}
{"id": "2512.01354", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2512.01354", "abs": "https://arxiv.org/abs/2512.01354", "authors": ["Zhongjie Jiang"], "title": "The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness", "comment": "38 pages,5 figures,30 tables. This paper proposes the Prompt-driven Cognitive Computing Framework (PMCSF) and validates it with A-share market stress tests (N=23 for 2015 crash, N=13 for 2024 bull market). Includes detailed appendices on cognitive vector definitions, perturbation operators, and financial backtest data", "summary": "Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.\n  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.\n  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.\n  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8ba4\u77e5\u8ba1\u7b97\u6846\u67b6PMCSF\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u800c\u975e\u6a21\u4eff\u8868\u9762\u6570\u636e\u6765\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u89e3\u51b3AI\u6570\u636e\u5d29\u6e83\u5371\u673a\u3002", "motivation": "\u5f53\u524d\u5408\u6210\u6570\u636e\u751f\u6210\u8303\u5f0f\u8ffd\u6c42\u7edf\u8ba1\u5e73\u6ed1\u6027\uff0c\u4f46\u79fb\u9664\u4e86\u4eba\u7c7b\u6587\u672c\u4e2d\u5177\u6709\u8ba4\u77e5\u57fa\u7840\u7684\u957f\u5c3e\u4e0d\u89c4\u5219\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u5d29\u6e83\u52a0\u901f\u3002\u9700\u8981\u4ece\u6a21\u4eff\u6570\u636e\u8868\u9762\u5c5e\u6027\u8f6c\u5411\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u751f\u6210\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faPrompt\u9a71\u52a8\u7684\u8ba4\u77e5\u8ba1\u7b97\u6846\u67b6(PMCSF)\uff0c\u5305\u542b\u8ba4\u77e5\u72b6\u6001\u89e3\u7801\u5668(CSD)\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u53cd\u8f6c\u4e3a\u7ed3\u6784\u5316\u8ba4\u77e5\u5411\u91cf\uff0c\u4ee5\u53ca\u8ba4\u77e5\u6587\u672c\u7f16\u7801\u5668(CTE)\u901a\u8fc7\u6570\u5b66\u5b9a\u4e49\u7684\u8ba4\u77e5\u6270\u52a8\u7b97\u5b50\u5c06\u8fd9\u4e9b\u72b6\u6001\u91cd\u65b0\u7269\u8d28\u5316\u4e3a\u5bcc\u542b\u4eba\u7c7b\u5178\u578b\u7f3a\u9677\u7684\u6587\u672c\u3002", "result": "\u8ba4\u77e5\u7f16\u89e3\u7801\u9a8c\u8bc1\u663e\u793aCTE\u6587\u672c\u4e0e\u4eba\u7c7b\u6587\u672c\u7684Jensen-Shannon\u6563\u5ea6\u4e3a0.0614\uff08\u6807\u51c6LLM\u8f93\u51fa\u4e3a0.4431\uff09\uff0c\u901a\u8fc7\u53cc\u76f2\u4e13\u4e1a\u5a92\u4f53\u8bc4\u5ba1\uff0c\u8ba4\u77e5\u8f6e\u5ed3\u5bf9\u9f50\u7684\u7ec4\u5185\u76f8\u5173\u7cfb\u6570ICC>0.9\u3002\u529f\u80fd\u589e\u76ca\u8bc4\u4f30\u4e2d\uff0cA\u80a1\u5e02\u573a\u540c\u6784\u538b\u529b\u6d4b\u8bd5\u663e\u793a\u5305\u542bCTE\u751f\u6210\u6570\u636e\u7684\u7b56\u7565\u57282015\u5e74\u80a1\u707e\u671f\u95f4\u6700\u5927\u56de\u64a4\u51cf\u5c1147.4%\uff0c\u4ea7\u751f8.6%\u9632\u5fa1\u6027\u963f\u5c14\u6cd5\uff0c\u8d85\u8fc7\u4ea4\u6613\u6210\u672c33\u500d\u3002", "conclusion": "\u5efa\u6a21\u4eba\u7c7b\u8ba4\u77e5\u9650\u5236\u800c\u975e\u590d\u5236\u8868\u9762\u6570\u636e\uff0c\u80fd\u591f\u751f\u6210\u5177\u6709\u771f\u6b63\u529f\u80fd\u589e\u76ca\u7684\u5408\u6210\u6570\u636e\uff0c\u4e3a\u89e3\u51b3AI\u6570\u636e\u5d29\u6e83\u5371\u673a\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2512.01434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01434", "abs": "https://arxiv.org/abs/2512.01434", "authors": ["Daull Xavier", "Patrice Bellot", "Emmanuel Bruno", "Vincent Martin", "Elisabeth Murisasco"], "title": "A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building", "comment": null, "summary": "We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.", "AI": {"tldr": "CollabToolBuilder\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u5728\u73af\u6307\u5bfc\u8fed\u4ee3\u5b66\u4e60\u4e3a\u76ee\u6807\u521b\u5efa\u5de5\u5177\uff0c\u51cf\u5c11\u4efb\u52a1/\u9886\u57df\u9002\u5e94\u65f6\u95f4\u548c\u4eba\u5de5\u53cd\u9988\u6536\u96c6", "motivation": "\u89e3\u51b3\u590d\u6742\u8fed\u4ee3\u95ee\u9898\uff08\u5982\u79d1\u5b66\u6587\u6863\u751f\u6210\uff09\u4e2d\u5de5\u5177\u521b\u5efa\u4e0e\u4eba\u7c7b\u610f\u56fe\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u51cf\u5c11\u9886\u57df\u9002\u5e94\u65f6\u95f4\u548c\u4eba\u5de5\u53cd\u9988\u9700\u6c42", "method": "\u4f7f\u7528\u56db\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff08\u6559\u7ec3\u3001\u7f16\u7801\u5458\u3001\u6279\u8bc4\u8005\u3001\u8d44\u672c\u5316\u8005\uff09\u901a\u8fc7\u5f3a\u5316\u52a8\u6001\u63d0\u793a\u548c\u7cfb\u7edf\u5316\u4eba\u5de5\u53cd\u9988\u96c6\u6210\u6765\u751f\u6210\u548c\u9a8c\u8bc1\u5de5\u5177", "result": "\u521d\u6b65\u5b9e\u9a8c\u5c55\u793a\u4e86\u6846\u67b6\u5728\u751f\u6210\u524d\u6cbf\u7814\u7a76\u8bba\u6587\u6216\u4e13\u5229\u7b49\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5728\u5176\u4ed6\u8fed\u4ee3\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u9002\u7528\u6027", "conclusion": "CollabToolBuilder\u662f\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u4e13\u5bb6\u5728\u73af\u63a7\u5236\u548c\u53ef\u91cd\u7528\u5de5\u5177\u8d44\u672c\u5316\uff0c\u4e3a\u590d\u6742\u8fed\u4ee3\u95ee\u9898\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.01440", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.01440", "abs": "https://arxiv.org/abs/2512.01440", "authors": ["Sylvain Mari\u00e9", "Pablo Knecht"], "title": "A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale", "comment": null, "summary": "Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u72b6\u6001\u8f6c\u79fb\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\uff08STE-ts\uff09\u548c\u9009\u62e9\u6027\u65f6\u5e8f\u6c49\u660e\u8ddd\u79bb\uff08STH\uff09\uff0c\u907f\u514d\u4e86\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u5e93\u8fdb\u884c\u4ee3\u4ef7\u9ad8\u6602\u4e14\u626d\u66f2\u7684\u91cd\u91c7\u6837\u64cd\u4f5c\uff0c\u540c\u65f6\u5229\u7528\u8f6c\u79fb\u65f6\u95f4\u548c\u72b6\u6001\u6301\u7eed\u65f6\u95f4\u4fe1\u606f\u3002", "motivation": "\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u5728\u81ea\u7136\u89c2\u6d4b\u3001\u793e\u4f1a\u7ecf\u6d4e\u79d1\u5b66\u548c\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u666e\u904d\u5b58\u5728\u3002\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u4e8b\u4ef6/\u72b6\u6001\u53cc\u91cd\u6027\u8d28\uff1a\u4fe1\u53f7\u8981\u4e48\u88ab\u5efa\u6a21\u4e3a\u8f6c\u79fb\u4e8b\u4ef6\u5e8f\u5217\uff08\u5f3a\u8c03\u4e8b\u4ef6\u987a\u5e8f\u5bf9\u9f50\uff09\uff0c\u8981\u4e48\u88ab\u5efa\u6a21\u4e3a\u5206\u7c7b\u6216\u6709\u5e8f\u72b6\u6001\u65f6\u95f4\u5e8f\u5217\uff08\u901a\u5e38\u9700\u8981\u91cd\u91c7\u6837\uff0c\u968f\u7740\u89c2\u6d4b\u5468\u671f\u548c\u4e8b\u4ef6\u6570\u91cf\u7684\u589e\u957f\uff0c\u8fd9\u4f1a\u6210\u4e3a\u626d\u66f2\u4e14\u4ee3\u4ef7\u9ad8\u6602\u7684\u64cd\u4f5c\uff09\u3002", "method": "\u5b9a\u4e49\u72b6\u6001\u8f6c\u79fb\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\uff08STE-ts\uff09\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u9009\u62e9\u6027\u65f6\u5e8f\u6c49\u660e\u8ddd\u79bb\uff08STH\uff09\uff0c\u8be5\u8ddd\u79bb\u540c\u65f6\u5229\u7528\u8f6c\u79fb\u65f6\u95f4\u548c\u72b6\u6001\u6301\u7eed\u65f6\u95f4\uff0c\u907f\u514d\u5728\u5927\u89c4\u6a21\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u4ee3\u4ef7\u9ad8\u6602\u4e14\u626d\u66f2\u7684\u91cd\u91c7\u6837\u3002", "result": "STH\u63a8\u5e7f\u4e86\u91cd\u91c7\u6837\u6c49\u660e\u548cJaccard\u5ea6\u91cf\uff0c\u5177\u6709\u66f4\u597d\u7684\u7cbe\u5ea6\u548c\u8ba1\u7b97\u65f6\u95f4\uff0c\u5e76\u4e14\u80fd\u591f\u805a\u7126\u4e8e\u591a\u4e2a\u611f\u5174\u8da3\u7684\u72b6\u6001\u3002\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684STE-ts\u548cSTH\u65b9\u6cd5\u4e3a\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u7cbe\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u91cd\u91c7\u6837\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3002"}}
{"id": "2512.01452", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01452", "abs": "https://arxiv.org/abs/2512.01452", "authors": ["Lingbo Li", "Anuradha Mathrani", "Teo Susnjak"], "title": "Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework", "comment": null, "summary": "Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faGEPA\u6a21\u5757\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4ee3\u7801\u4f18\u5316\u66ff\u4ee3\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\uff0c\u5b9e\u73b0\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\uff0c\u63d0\u9ad8\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u7684\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u5bf9\u8bc1\u636e\u5408\u6210\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u5b58\u5728\u8bc4\u4f30\u8005\u95f4\u5dee\u5f02\u3002\u73b0\u6709LLM\u81ea\u52a8\u5316\u65b9\u6cd5\u4f9d\u8d56\u96be\u4ee5\u590d\u73b0\u3001\u6cdb\u5316\u6216\u8bc4\u4f30\u7684\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u3002", "method": "\u5f15\u5165\u53ef\u7f16\u7a0b\u7684\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4f7f\u7528DSPy\u53ca\u5176GEPA\u6a21\u5757\uff0c\u901a\u8fc7\u5e15\u7d2f\u6258\u5f15\u5bfc\u641c\u7d22\u4f18\u5316LLM\u63a8\u7406\uff0c\u751f\u6210\u53ef\u68c0\u67e5\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u5b9e\u73b0\u4f18\u5316\u8fc7\u7a0b\u900f\u660e\u590d\u73b0\u3002", "result": "\u57287\u4e2a\u504f\u501a\u98ce\u9669\u9886\u57df\u7684100\u4e2aRCT\u8bc4\u4f30\u4e2d\uff0cGEPA\u751f\u6210\u7684\u63d0\u793a\u5728\u968f\u673a\u5e8f\u5217\u751f\u6210\u7b49\u62a5\u544a\u6e05\u6670\u7684\u9886\u57df\u8868\u73b0\u6700\u4f73\uff0c\u76f8\u6bd4\u624b\u52a8\u63d0\u793a\u5728\u968f\u673a\u5e8f\u5217\u751f\u6210\u548c\u9009\u62e9\u6027\u62a5\u544a\u65b9\u9762\u6027\u80fd\u63d0\u534730%-40%\uff0c\u6574\u4f53\u51c6\u786e\u7387\u6700\u9ad8\u3002", "conclusion": "GEPA\u80fd\u591f\u4e3a\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u751f\u6210\u4e00\u81f4\u4e14\u53ef\u590d\u73b0\u7684\u63d0\u793a\uff0c\u652f\u6301LLM\u5728\u8bc1\u636e\u5408\u6210\u4e2d\u7684\u7ed3\u6784\u5316\u548c\u539f\u5219\u6027\u4f7f\u7528\u3002"}}
{"id": "2512.01485", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01485", "abs": "https://arxiv.org/abs/2512.01485", "authors": ["Jindi Lv", "Yuhao Zhou", "Zheng Zhu", "Xiaofeng Wang", "Guan Huang", "Jiancheng Lv"], "title": "Multi-Path Collaborative Reasoning via Reinforcement Learning", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning has significantly advanced the problem-solving capabilities of Large Language Models (LLMs), yet conventional CoT often exhibits internal determinism during decoding, limiting exploration of plausible alternatives. Recent methods attempt to address this by generating soft abstract tokens to enable reasoning in a continuous semantic space. However, we find that such approaches remain constrained by the greedy nature of autoregressive decoding, which fundamentally isolates the model from alternative reasoning possibilities. In this work, we propose Multi-Path Perception Policy Optimization (M3PO), a novel reinforcement learning framework that explicitly injects collective insights into the reasoning process. M3PO leverages parallel policy rollouts as naturally diverse reasoning sources and integrates cross-path interactions into policy updates through a lightweight collaborative mechanism. This design allows each trajectory to refine its reasoning with peer feedback, thereby cultivating more reliable multi-step reasoning patterns. Empirical results show that M3PO achieves state-of-the-art performance on both knowledge- and reasoning-intensive benchmarks. Models trained with M3PO maintain interpretability and inference efficiency, underscoring the promise of multi-path collaborative learning for robust reasoning.", "AI": {"tldr": "M3PO\u63d0\u51fa\u4e86\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u7b56\u7565rollout\u548c\u591a\u8def\u5f84\u534f\u4f5c\u673a\u5236\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6ce8\u5165\u96c6\u4f53\u6d1e\u5bdf\uff0c\u63d0\u5347LLMs\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684CoT\u63a8\u7406\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u5185\u90e8\u786e\u5b9a\u6027\uff0c\u9650\u5236\u4e86\u63a2\u7d22\u5408\u7406\u66ff\u4ee3\u65b9\u6848\u7684\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u5c1d\u8bd5\u5728\u8fde\u7eed\u8bed\u4e49\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a8\u7406\uff0c\u4f46\u4ecd\u53d7\u9650\u4e8e\u81ea\u56de\u5f52\u89e3\u7801\u7684\u8d2a\u5a6a\u6027\u8d28\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u66ff\u4ee3\u63a8\u7406\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u591a\u8def\u5f84\u611f\u77e5\u7b56\u7565\u4f18\u5316\uff08M3PO\uff09\u6846\u67b6\uff0c\u5229\u7528\u5e76\u884c\u7b56\u7565rollout\u4f5c\u4e3a\u81ea\u7136\u591a\u6837\u5316\u7684\u63a8\u7406\u6e90\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u534f\u4f5c\u673a\u5236\u5c06\u8de8\u8def\u5f84\u4ea4\u4e92\u6574\u5408\u5230\u7b56\u7565\u66f4\u65b0\u4e2d\uff0c\u4f7f\u6bcf\u4e2a\u8f68\u8ff9\u90fd\u80fd\u901a\u8fc7\u540c\u4f34\u53cd\u9988\u7cbe\u70bc\u63a8\u7406\u3002", "result": "M3PO\u5728\u77e5\u8bc6\u548c\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u591a\u8def\u5f84\u534f\u4f5c\u5b66\u4e60\u4e3a\u7a33\u5065\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0cM3PO\u6846\u67b6\u901a\u8fc7\u96c6\u4f53\u6d1e\u5bdf\u6ce8\u5165\u548c\u8de8\u8def\u5f84\u4ea4\u4e92\uff0c\u6709\u6548\u63d0\u5347\u4e86LLMs\u7684\u591a\u6b65\u63a8\u7406\u6a21\u5f0f\u53ef\u9760\u6027\u3002"}}
{"id": "2512.01507", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01507", "abs": "https://arxiv.org/abs/2512.01507", "authors": ["Daniel Armstrong", "Zlatko Jon\u010dev", "Andres M Bran", "Philippe Schwaller"], "title": "SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry", "comment": null, "summary": "Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u5408\u6210\u77e5\u8bc6\u8f6c\u5316\u4e3a\u4ee3\u7801\uff0c\u5b9e\u73b0\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\u4e2d\u7684\u6218\u7565\u8003\u91cf\uff0c\u5982\u6c47\u805a\u5f0f\u7ec4\u88c5\u3001\u4fdd\u62a4\u57fa\u6700\u5c0f\u5316\u548c\u6700\u4f18\u73af\u5f62\u6210\u5e8f\u5217\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\u7cfb\u7edf\u80fd\u751f\u6210\u5316\u5b66\u4e0a\u6709\u6548\u7684\u53cd\u5e94\u6b65\u9aa4\uff0c\u4f46\u96be\u4ee5\u6574\u5408\u6218\u7565\u8003\u91cf\uff08\u5982\u6c47\u805a\u5f0f\u7ec4\u88c5\u3001\u4fdd\u62a4\u57fa\u6700\u5c0f\u5316\u3001\u6700\u4f18\u73af\u5f62\u6210\u5e8f\u5217\u7b49\uff09\u3002\u9700\u8981\u5c06\u5408\u6210\u6218\u7565\u77e5\u8bc6\u5f62\u5f0f\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u4ee3\u7801\u800c\u975e\u7b80\u5355\u542f\u53d1\u5f0f\u89c4\u5219\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u5408\u6210\u77e5\u8bc6\u8f6c\u5316\u4e3aPython\u51fd\u6570\uff0c\u4ee3\u8868\u5404\u79cd\u6218\u7565\u548c\u6218\u672f\u89c4\u5219\uff08\u5982\u6218\u7565\u5b98\u80fd\u56e2\u8f6c\u5316\u3001\u73af\u6784\u5efa\u7b56\u7565\uff09\u3002\u521b\u5efa\u53ef\u6d4b\u8bd5\u3001\u53ef\u89e3\u91ca\u7684\u5408\u6210\u6218\u7565\u8868\u793a\uff0c\u5e76\u53d1\u5e03\u5b8c\u6574\u4ee3\u7801\u5e93\u548cUSPTO-ST\u6570\u636e\u96c6\uff08\u5e26\u6218\u7565\u6807\u7b7e\u7684\u5408\u6210\u8def\u7ebf\uff09\u3002", "result": "\u5b9e\u73b0\u4e86CASP\u7684\u65b0\u80fd\u529b\uff1a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u8def\u7ebf\u68c0\u7d22\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523075%\u7684Top-3\u51c6\u786e\u7387\u3002\u901a\u8fc7\u5386\u53f2\u8d8b\u52bf\u7684\u65f6\u95f4\u5206\u6790\u548c\u5316\u5b66\u76f4\u89c2\u7684\u8def\u7ebf\u805a\u7c7b\u9a8c\u8bc1\u4e86\u8be5\u5e93\uff0c\u63d0\u4f9b\u4e86\u6bd4\u5148\u524d\u65b9\u6cd5\u66f4\u7ec6\u7c92\u5ea6\u7684\u5212\u5206\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f25\u5408\u4e86CASP\u4e2d\u6218\u672f\u4e0e\u6218\u7565\u7684\u9e3f\u6c9f\uff0c\u4f7f\u5f97\u80fd\u591f\u57fa\u4e8e\u6218\u7565\u6807\u51c6\u800c\u975e\u4ec5\u7ed3\u6784\u6765\u6307\u5b9a\u3001\u641c\u7d22\u548c\u8bc4\u4f30\u5408\u6210\u8def\u7ebf\u3002"}}
{"id": "2512.01556", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01556", "abs": "https://arxiv.org/abs/2512.01556", "authors": ["Zhiyuan Wang", "Aniri", "Tianlong Chen", "Yue Zhang", "Heng Tao Shen", "Xiaoshuang Shi", "Kaidi Xu"], "title": "LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems", "comment": null, "summary": "Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.", "AI": {"tldr": "LEC\u65b9\u6cd5\u901a\u8fc7\u7ebf\u6027\u671f\u671b\u7ea6\u675f\u548cFDR\u63a7\u5236\uff0c\u4e3aLLM\u9884\u6d4b\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5e76\u5f15\u5165\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u4e0d\u53ef\u9760\u7b54\u6848\u7684\u95ee\u9898\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u9884\u6d4b\uff0c\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\u3002", "method": "\u63d0\u51faLEC\u6846\u67b6\uff0c\u5c06\u9009\u62e9\u6027\u9884\u6d4b\u91cd\u65b0\u89e3\u91ca\u4e3a\u7ea6\u675f\u51b3\u7b56\u95ee\u9898\uff0c\u901a\u8fc7\u7ebf\u6027\u671f\u671b\u7ea6\u675f\u548cFDR\u63a7\u5236\u8ba1\u7b97\u9608\u503c\uff0c\u5e76\u6269\u5c55\u5230\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\u3002", "result": "\u5728\u95ed\u5f0f\u548c\u5f00\u653e\u5f0fQA\u6570\u636e\u96c6\u4e0a\uff0cLEC\u5b9e\u73b0\u4e86\u66f4\u4e25\u683c\u7684FDR\u63a7\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u4fdd\u7559\u7387\uff0c\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\u5728\u66f4\u4f4e\u98ce\u9669\u6c34\u5e73\u4e0b\u63a5\u53d7\u66f4\u591a\u6b63\u786e\u6837\u672c\u3002", "conclusion": "LEC\u4e3aLLM\u9884\u6d4b\u63d0\u4f9b\u4e86\u7edf\u8ba1\u4fdd\u8bc1\u7684FDR\u63a7\u5236\u6846\u67b6\uff0c\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u662f\u89e3\u51b3LLM\u4e0d\u53ef\u9760\u6027\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2512.01616", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01616", "abs": "https://arxiv.org/abs/2512.01616", "authors": ["Chainesh Gautam", "Raghuram Bharadwaj Diddigi"], "title": "CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning", "comment": "4 pages, 2 figures, accepted as a extended abstract at RLDM 2025", "summary": "Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00-\u7b56\u7565\u5bf9\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u7acb\u81ea\u7136\u8bed\u8a00\u4e0e\u7b56\u7565\u5d4c\u5165\u7684\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u5feb\u901f\u8fc1\u79fb", "motivation": "\u5f53\u524d\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u540c\u4e00\u73af\u5883\u4e2d\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u7684\u667a\u80fd\u4f53\uff0c\u7279\u522b\u662f\u5f53\u8fd9\u4e9b\u4efb\u52a1\u4e0e\u8bed\u8a00\u81ea\u7136\u5173\u8054\u65f6\u3002\u9700\u8981\u5efa\u7acb\u9ad8\u6548\u7684\u8fc1\u79fb\u5b66\u4e60\u7ba1\u9053\u3002", "method": "\u53d7\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2dCLIP\u65b9\u6cd5\u7684\u542f\u53d1\uff0c\u5c06\"\u6307\u4ee4\u548c\u5bf9\u5e94\u7b56\u7565\u4ee3\u8868\u540c\u4e00\u4efb\u52a1\u7684\u4e0d\u540c\u6a21\u6001\"\u8fd9\u4e00\u7406\u5ff5\u6269\u5c55\u5230\u5f3a\u5316\u5b66\u4e60\u3002\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u8bed\u8a00-\u7b56\u7565\u5bf9\uff0c\u5efa\u7acb\u81ea\u7136\u8bed\u8a00\u548c\u7b56\u7565\u5d4c\u5165\u7684\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u73b0\u8de8\u4efb\u52a1\u5feb\u901f\u8fc1\u79fb\u65b9\u9762\u5177\u6709\u5b9e\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06CLIP\u601d\u60f3\u6269\u5c55\u5230\u5f3a\u5316\u5b66\u4e60\u9886\u57df\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u8bed\u8a00-\u7b56\u7565\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4efb\u52a1\u95f4\u7684\u5feb\u901f\u77e5\u8bc6\u8fc1\u79fb\u3002"}}
{"id": "2512.01723", "categories": ["cs.AI", "cs.GT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.01723", "abs": "https://arxiv.org/abs/2512.01723", "authors": ["Saba Kublashvili"], "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation", "comment": "Preprint. Code and simulation notebooks available at the GitHub repository: https://github.com/Saba-Kublashvili/bayesian-computational-modeling.-", "summary": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.", "AI": {"tldr": "HistoricalML\uff1a\u4e00\u4e2a\u6982\u7387\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6781\u7aef\u6570\u636e\u7a00\u7f3a\uff08N<100\uff09\u4e0b\u5efa\u6a21\u5386\u53f2\u4e8b\u4ef6\uff0c\u6574\u5408\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u3001\u56e0\u679c\u6a21\u578b\u3001\u535a\u5f08\u8bba\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e94\u7528\u4e8e\u975e\u6d32\u5206\u5272\u548c\u5e03\u533f\u6218\u4e89\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u5386\u53f2\u4e8b\u4ef6\u5efa\u6a21\u9762\u4e34\u56db\u5927\u6311\u6218\uff1a\u6781\u7aef\u6570\u636e\u7a00\u7f3a\uff08N<100\uff09\u3001\u5f02\u6784\u566a\u58f0\u6d4b\u91cf\u3001\u53cd\u4e8b\u5b9e\u7f3a\u5931\u3001\u4ee5\u53ca\u9700\u8981\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faHistoricalML\u6846\u67b6\uff0c\u6574\u5408\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u79bb\u8ba4\u77e5\u4e0e\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff1b2\uff09\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u8fdb\u884c\u6df7\u6742\u4e0b\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\uff1b3\uff09\u5408\u4f5c\u535a\u5f08\u8bba\uff08Shapley\u503c\uff09\u8fdb\u884c\u516c\u5e73\u5206\u914d\u5efa\u6a21\uff1b4\uff09\u6ce8\u610f\u529b\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u56e0\u5b50\u52a0\u6743\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\uff1a\u5728\u7a00\u758f\u6570\u636e\u4e0b\uff0c\u5f53\u6709\u5f3a\u9886\u57df\u77e5\u8bc6\u5148\u9a8c\u65f6\uff0c\u65b9\u6cd5\u80fd\u5b9e\u73b0\u4e00\u81f4\u4f30\u8ba1\uff1bShapley\u5206\u914d\u6ee1\u8db3\u516c\u7406\u516c\u5e73\u6027\u4fdd\u8bc1\u3002\u6848\u4f8b\u7814\u7a76\uff1a1\uff0919\u4e16\u7eaa\u975e\u6d32\u5206\u5272\u8bc6\u522b\u5fb7\u56fd+107.9%\u5dee\u5f02\u4f5c\u4e3a\u4e00\u6218\u524d\u7684\u7ed3\u6784\u6027\u7d27\u5f20\uff1b2\uff09\u5e03\u533f\u6218\u4e89\u6a21\u62df\u663e\u793a\u574e\u5c3c\u6218\u5f79\u8fe6\u592a\u57fa57.3%\u80dc\u7387\uff0c\u624e\u9a6c\u6218\u5f79\u7f57\u9a6c57.8%\u80dc\u7387\uff1b\u53cd\u4e8b\u5b9e\u5206\u6790\u63ed\u793a\u8fe6\u592a\u57fa\u653f\u6cbb\u652f\u6301\uff086.4\u5206\uff09\u800c\u975e\u519b\u4e8b\u5b9e\u529b\u662f\u51b3\u5b9a\u6027\u56e0\u7d20\u3002", "conclusion": "HistoricalML\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5386\u53f2\u4e8b\u4ef6\u5efa\u6a21\u7684\u6838\u5fc3\u6311\u6218\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u6574\u5408\u5b9e\u73b0\u4e86\u5728\u6781\u7aef\u6570\u636e\u7a00\u7f3a\u4e0b\u7684\u53ef\u9760\u4f30\u8ba1\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u548c\u53ef\u89e3\u91ca\u5206\u6790\uff0c\u4e3a\u5386\u53f2\u7814\u7a76\u63d0\u4f9b\u4e86\u91cf\u5316\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2512.01786", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01786", "abs": "https://arxiv.org/abs/2512.01786", "authors": ["Xiaochuan Li", "Ke Wang", "Girija Gouda", "Shubham Choudhary", "Yaqun Wang", "Linwei Hu", "Joel Vaughan", "Freddy Lecue"], "title": "Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems", "comment": "66 pages, 22 figures, 37 tables", "summary": "As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.", "AI": {"tldr": "LLM Jury-on-Demand\uff1a\u4e00\u4e2a\u52a8\u6001\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u53ef\u9760\u6027\u9884\u6d4b\u5668\u6765\u8bc4\u4f30LLM\u8bc4\u59d4\u4f55\u65f6\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e00\u81f4\uff0c\u4e3a\u6bcf\u4e2a\u6570\u636e\u70b9\u52a8\u6001\u9009\u62e9\u6700\u4f18\u8bc4\u59d4\u56e2\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8bc4\u4f30\u3002", "motivation": "\u968f\u7740LLM\u96c6\u6210\u5230\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u9700\u8981\u65e2\u9002\u5408\u5b9e\u65f6\u90e8\u7f72\u53c8\u53ef\u6269\u5c55\uff0c\u53c8\u5bf9\u5173\u952e\u51b3\u7b56\u53ef\u9760\u7684\u65b0\u578b\u8bc4\u4f30\u65b9\u6cd5\u3002\u4eba\u5de5\u8bc4\u4f30\u53ef\u9760\u4f46\u7f13\u6162\u6602\u8d35\uff0c\u5355\u4e00LLM\u8bc4\u59d4\u5b58\u5728\u504f\u89c1\uff0c\u9759\u6001\u8bc4\u59d4\u56e2\u7f3a\u4e4f\u9002\u5e94\u6027\u3002", "method": "\u8bad\u7ec3\u4e00\u7ec4\u53ef\u9760\u6027\u9884\u6d4b\u5668\uff0c\u5229\u7528token\u5206\u5e03\u3001\u5d4c\u5165\u548c\u7ed3\u6784\u8f93\u5165\u7279\u5f81\u6765\u8bc4\u4f30LLM\u8bc4\u59d4\u4f55\u65f6\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e00\u81f4\u3002\u4e3a\u6bcf\u4e2a\u6570\u636e\u70b9\u52a8\u6001\u9009\u62e9\u6700\u4f18\u8bc4\u59d4\u56e2\uff0c\u5e76\u4f7f\u7528\u5176\u53ef\u9760\u6027\u4f5c\u4e3a\u6743\u91cd\u805a\u5408\u8bc4\u5206\u3002", "result": "\u5728\u6458\u8981\u548cRAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u52a8\u6001\u8bc4\u59d4\u56e2\u7cfb\u7edf\u6bd4\u5355\u4e00\u8bc4\u59d4\u548c\u9759\u6001\u8bc4\u59d4\u56e2\u57fa\u7ebf\u663e\u8457\u63d0\u9ad8\u4e86\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u8bc4\u59d4\u56e2\u65b9\u6cd5\u4e3a\u73b0\u4ee3LLM\u5728\u9ad8\u98ce\u9669\u9886\u57df\u6784\u5efa\u53ef\u6269\u5c55\u3001\u66f4\u53ef\u9760\u548c\u53ef\u4fe1\u7684\u8bc4\u4f30\u7cfb\u7edf\u5c55\u73b0\u4e86\u524d\u666f\u3002"}}
{"id": "2512.01797", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.01797", "abs": "https://arxiv.org/abs/2512.01797", "authors": ["Cheng Gao", "Huimin Chen", "Chaojun Xiao", "Zhiyi Chen", "Zhiyuan Liu", "Maosong Sun"], "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons", "comment": "20 pages, 4 figures", "summary": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\u4e0e\u6781\u5c11\u6570\u7279\u5b9a\u795e\u7ecf\u5143\uff08H-Neurons\uff09\u76f8\u5173\uff0c\u8fd9\u4e9b\u795e\u7ecf\u5143\u4ec5\u5360\u603b\u6570\u4e0d\u52300.1%\uff0c\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\uff0c\u4e14\u4e0e\u8fc7\u5ea6\u987a\u4ece\u884c\u4e3a\u6709\u56e0\u679c\u5173\u8054\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u5e7b\u89c9\uff08\u770b\u4f3c\u5408\u7406\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u8f93\u51fa\uff09\uff0c\u8fd9\u524a\u5f31\u4e86\u5176\u53ef\u9760\u6027\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u4ece\u5b8f\u89c2\u89d2\u5ea6\uff08\u5982\u8bad\u7ec3\u6570\u636e\u548c\u76ee\u6807\uff09\u8003\u5bdf\u5e7b\u89c9\uff0c\u800c\u795e\u7ecf\u5143\u5c42\u9762\u7684\u673a\u5236\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4ece\u4e09\u4e2a\u89d2\u5ea6\u7cfb\u7edf\u7814\u7a76\u5e7b\u89c9\u76f8\u5173\u795e\u7ecf\u5143\uff08H-Neurons\uff09\uff1a1\uff09\u8bc6\u522b\uff1a\u53d1\u73b0\u6781\u7a00\u758f\u7684\u795e\u7ecf\u5143\u5b50\u96c6\uff08<0.1%\uff09\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\uff1b2\uff09\u884c\u4e3a\u5f71\u54cd\uff1a\u901a\u8fc7\u53d7\u63a7\u5e72\u9884\u9a8c\u8bc1\u8fd9\u4e9b\u795e\u7ecf\u5143\u4e0e\u8fc7\u5ea6\u987a\u4ece\u884c\u4e3a\u7684\u56e0\u679c\u5173\u8054\uff1b3\uff09\u8d77\u6e90\uff1a\u8ffd\u6eaf\u8fd9\u4e9b\u795e\u7ecf\u5143\u5230\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u5c31\u5df2\u5f62\u6210\u3002", "result": "H-Neurons\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\uff0c\u4e14\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b\u8fd9\u4e9b\u795e\u7ecf\u5143\u4e0e\u6a21\u578b\u7684\u8fc7\u5ea6\u987a\u4ece\u884c\u4e3a\u6709\u56e0\u679c\u5173\u8054\uff1b\u5b83\u4eec\u6e90\u4e8e\u9884\u8bad\u7ec3\u9636\u6bb5\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u4ecd\u80fd\u6709\u6548\u9884\u6d4b\u5e7b\u89c9\u3002", "conclusion": "\u7814\u7a76\u5c06\u5b8f\u89c2\u884c\u4e3a\u6a21\u5f0f\u4e0e\u5fae\u89c2\u795e\u7ecf\u673a\u5236\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u8868\u660e\u901a\u8fc7\u8bc6\u522b\u548c\u5e72\u9884\u7279\u5b9a\u795e\u7ecf\u5143\u53ef\u80fd\u51cf\u5c11\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2512.01870", "categories": ["cs.AI", "cond-mat.dis-nn", "math-ph", "math.NT"], "pdf": "https://arxiv.org/pdf/2512.01870", "abs": "https://arxiv.org/abs/2512.01870", "authors": ["Alessandro Breccia", "Federica Gerace", "Marco Lippi", "Gabriele Sicuro", "Pierluigi Contucci"], "title": "Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees", "comment": "21 pages, 8 figures", "summary": "We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \\mathbb{N}\\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\\mathbb{N}\\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.", "AI": {"tldr": "GPT-2\u6a21\u578b\u80fd\u591f\u90e8\u5206\u5b66\u4e60\u81ea\u7136\u6570\u8fed\u4ee3\u8d28\u56e0\u6570\u5206\u89e3\u751f\u6210\u7684\u6811\u5e8f\u5217\u7684\u5185\u90e8\u8bed\u6cd5\uff0c\u8868\u660e\u53ef\u5b66\u4e60\u6027\u53ef\u80fd\u6269\u5c55\u5230\u7b97\u672f\u7ed3\u6784\u672c\u8eab", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u5b66\u4e60\u7531\u81ea\u7136\u6570\u8fed\u4ee3\u8d28\u56e0\u6570\u5206\u89e3\u751f\u6210\u7684\u786e\u5b9a\u6027\u6811\u5e8f\u5217\uff0c\u63a2\u7d22\u6a21\u578b\u5bf9\u7b97\u672f\u7ed3\u6784\u7684\u5b66\u4e60\u80fd\u529b", "method": "\u4f7f\u7528GPT-2\u67b6\u6784\u7684Transformer\u7f51\u7edc\uff0c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u524d10^11\u4e2a\u5143\u7d20\uff0c\u6d4b\u8bd5\u5176\u5728\u4e0b\u4e00\u4e2a\u8bcd\u548c\u63a9\u7801\u8bcd\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u9884\u6d4b\u80fd\u529b", "result": "\u6a21\u578b\u90e8\u5206\u5b66\u4e60\u4e86\u6811\u5e8f\u5217\u7684\u5185\u90e8\u8bed\u6cd5\uff0c\u6355\u6349\u5230\u4e86\u975e\u5e73\u51e1\u7684\u89c4\u5f8b\u6027\u548c\u76f8\u5173\u6027", "conclusion": "\u53ef\u5b66\u4e60\u6027\u53ef\u80fd\u8d85\u8d8a\u7ecf\u9a8c\u6570\u636e\uff0c\u6269\u5c55\u5230\u7b97\u672f\u7ed3\u6784\u672c\u8eab\uff0c\u8868\u660e\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u6570\u5b66\u7ed3\u6784\u7684\u5185\u90e8\u89c4\u5f8b"}}
{"id": "2512.01878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01878", "abs": "https://arxiv.org/abs/2512.01878", "authors": ["Gaganpreet Jhajj", "Fuhua Lin"], "title": "Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning", "comment": "Accepted to NORA Workshop at NeurIPS 2025", "summary": "In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u60ca\u5947\u6700\u5c0f\u5316\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u81ea\u7531\u80fd\u539f\u7406\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7cfb\u7edf\u8fde\u63a5\uff0c\u4f7f\u7528\u56fe\u8ddd\u79bb\u5ea6\u91cf\u60ca\u5947", "motivation": "\u63a2\u7d22\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u81ea\u7531\u80fd\u539f\u7406\uff08FEP\uff09\u5e94\u7528\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7cfb\u7edf\uff0c\u5efa\u7acb\u56fe\u8ddd\u79bb\u4e0e\u60ca\u5947\u6700\u5c0f\u5316\u7684\u8054\u7cfb", "method": "\u4f7f\u7528\u6709\u5411\u56fe\u4e2d\u7684\u6700\u77ed\u8def\u5f84\u8ddd\u79bb\u5f62\u5f0f\u5316\u60ca\u5947\u5ea6\u91cf\uff0c\u6784\u5efa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u56fe\u8ddd\u79bb\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6d88\u606f\u4f20\u9012\u6df1\u5ea6\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4e16\u754c\u6a21\u578b\u8f68\u8ff9\u8054\u7cfb\u8d77\u6765", "result": "\u8fd9\u662f\u4e00\u4e2a\u8fdb\u884c\u4e2d\u7684\u7814\u7a76\uff0c\u63a2\u7d22\u57fa\u4e8e\u8ddd\u79bb\u7684\u60ca\u5947\u662f\u5426\u80fd\u6269\u5c55\u6700\u8fd1\u5173\u4e8e\u8bed\u6cd5\u901a\u8fc7\u6811\u7ed3\u6784\u6700\u5c0f\u5316\u60ca\u5947\u548c\u81ea\u7531\u80fd\u7684\u5de5\u4f5c", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fde\u63a5\u81ea\u7531\u80fd\u539f\u7406\u548c\u77e5\u8bc6\u56fe\u8c31\u7cfb\u7edf\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u57fa\u4e8e\u60ca\u5947\u6700\u5c0f\u5316\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411"}}
{"id": "2512.01880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01880", "abs": "https://arxiv.org/abs/2512.01880", "authors": ["Daren Zhong", "Dingcheng Huang", "Clayton Greenberg"], "title": "Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models", "comment": null, "summary": "Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.\n  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.\n  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8en-gram\u8bed\u8a00\u6a21\u578b\u7684\u56fd\u9645\u8c61\u68cb\u8d70\u6cd5\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u8d70\u6cd5\u9884\u6d4b\u89c6\u4e3a\u884c\u4e3a\u5206\u6790\u4efb\u52a1\uff0c\u9488\u5bf9\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u7684\u73a9\u5bb6\u8bad\u7ec3\u72ec\u7acb\u6a21\u578b\uff0c\u5b9e\u73b0\u5b9e\u65f6\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u4e3b\u8981\u5173\u6ce8\u6700\u4f18\u8d70\u6cd5\u8ba1\u7b97\uff0c\u5ffd\u7565\u4e86\u4eba\u7c7b\u73a9\u5bb6\u5728\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u4e0b\u7684\u884c\u4e3a\u53d8\u5f02\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u73a9\u5bb6\u8d70\u6cd5\u6a21\u5f0f\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5c06\u73a9\u5bb6\u5206\u4e3a7\u4e2a\u6280\u80fd\u7b49\u7ea7\uff0c\u4f7f\u7528Lichess\u5e73\u53f0\u7684\u5f00\u6e90\u6570\u636e\u8bad\u7ec3\u72ec\u7acb\u7684n-gram\u8bed\u8a00\u6a21\u578b\u3002\u6846\u67b6\u5305\u542b\u6a21\u578b\u9009\u62e9\u5668\u6a21\u5757\uff0c\u6839\u636e\u65e9\u671f\u6e38\u620f\u4fe1\u606f\u52a8\u6001\u9009\u62e9\u6700\u5408\u9002\u7684\u6a21\u578b\u8fdb\u884c\u8d70\u6cd5\u9884\u6d4b\u3002", "result": "\u6a21\u578b\u9009\u62e9\u5668\u572816\u4e2a\u534a\u56de\u5408\u7684\u65e9\u671f\u6e38\u620f\u4fe1\u606f\u4e0b\uff0c\u6280\u80fd\u6c34\u5e73\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523031.7%\u3002\u8d70\u6cd5\u9884\u6d4b\u6846\u67b6\u76f8\u6bd4\u57fa\u51c6\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe39.1%\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9002\u5408\u5b9e\u65f6\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u56fd\u9645\u8c61\u68cb\u8d70\u6cd5\u9884\u6d4b\u8f6c\u5316\u4e3a\u884c\u4e3a\u5206\u6790\u4efb\u52a1\uff0c\u901a\u8fc7\u6280\u80fd\u6c34\u5e73\u7279\u5b9a\u7684n-gram\u6a21\u578b\u6709\u6548\u6355\u6349\u4eba\u7c7b\u73a9\u5bb6\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u4e3a\u5b9e\u65f6\u8c61\u68cb\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01958", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01958", "abs": "https://arxiv.org/abs/2512.01958", "authors": ["Jie Meng", "Jin Mao"], "title": "Learned-Rule-Augmented Large Language Model Evaluators", "comment": null, "summary": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89c4\u5219\u589e\u5f3a\u7684LLM\u8bc4\u4f30\u8303\u5f0f\uff0c\u901a\u8fc7\u89c4\u5219\u84b8\u998f\u548c\u89c4\u5219\u5e94\u7528\u7b56\u7565\u63d0\u5347LLM\u4f5c\u4e3a\u901a\u7528\u8bc4\u4f30\u5668\u7684\u6027\u80fd", "motivation": "\u73b0\u6709LLM\u8bc4\u4f30\u5668\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u8bc4\u4f30\u539f\u5219\uff0c\u6210\u672c\u9ad8\u4e14\u4e0e\u6807\u6ce8\u6570\u636e\u548cLLM\u7406\u89e3\u4e0d\u4e00\u81f4\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u591a\u6837\u5316\u7684\u8bc4\u4f30\u573a\u666f", "method": "1) \u89c4\u5219\u84b8\u998f\uff1a\u4f7f\u7528LLM\u8f85\u52a9\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u81ea\u52a8\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u8bc4\u5206\u89c4\u5219\uff1b2) \u89c4\u5219\u5e94\u7528\u7b56\u7565\uff1a\u94fe\u5f0f\u89c4\u5219\u5f15\u5bfc\u548c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u89c4\u5219\u589e\u5f3a\u7684LLM\u8bc4\u4f30\u5668", "result": "\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u8bc4\u4f30\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b", "conclusion": "\u63d0\u51fa\u7684\u89c4\u5219\u589e\u5f3a\u8bc4\u4f30\u8303\u5f0f\u89e3\u51b3\u4e86\u73b0\u6709LLM\u8bc4\u4f30\u5668\u7684\u5c40\u9650\u6027\uff0c\u4e3aLLM\u4f5c\u4e3a\u901a\u7528\u8bc4\u4f30\u5668\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.01970", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01970", "abs": "https://arxiv.org/abs/2512.01970", "authors": ["Sitao Cheng", "Xunjian Yin", "Ruiwen Zhou", "Yuxuan Li", "Xinyi Wang", "Liangming Pan", "William Yang Wang", "Victor Zhong"], "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning", "comment": "Work in Progress. Code and data will be available at https://github.com/sitaocheng/from_atomic_to_composite", "summary": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.", "AI": {"tldr": "RL\u80fd\u4e3b\u52a8\u5408\u6210\u590d\u6742\u63a8\u7406\u7b56\u7565\u800c\u975e\u4ec5\u653e\u5927\u5df2\u6709\u884c\u4e3a\uff0c\u4f46\u524d\u63d0\u662f\u57fa\u7840\u6a21\u578b\u5df2\u901a\u8fc7SFT\u638c\u63e1\u539f\u5b50\u6280\u80fd\uff08\u53c2\u6570\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\uff09\u3002", "motivation": "\u7814\u7a76RL\u5982\u4f55\u8d21\u732e\u63a8\u7406\u80fd\u529b\u2014\u2014\u662f\u6fc0\u52b1\u65b0\u6280\u80fd\u5408\u6210\u8fd8\u662f\u4ec5\u653e\u5927\u73b0\u6709\u884c\u4e3a\uff0c\u901a\u8fc7\u4e92\u8865\u63a8\u7406\u4efb\u52a1\u63a2\u7a76\u8fd9\u4e00\u6838\u5fc3\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u63a7\u5236\u5408\u6210\u7684\u4eba\u7c7b\u4f20\u8bb0\u6570\u636e\u96c6\uff0c\u5c06\u4e92\u8865\u63a8\u7406\u4e25\u683c\u89e3\u8026\u4e3a\u53c2\u6570\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u4e24\u4e2a\u539f\u5b50\u6280\u80fd\uff0c\u5728I.I.D.\u3001\u7ec4\u5408\u548c\u96f6\u6837\u672c\u4e09\u4e2a\u96be\u5ea6\u7ea7\u522b\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u53d1\u73b0SFT\u5728\u5206\u5e03\u5185\u8868\u73b0\u826f\u597d\u4f46\u5206\u5e03\u5916\u6cdb\u5316\u5dee\uff08\u7279\u522b\u662f\u96f6\u6837\u672c\uff09\uff0c\u5b58\u5728\"SFT\u6cdb\u5316\u6096\u8bba\"\uff1bRL\u80fd\u4f5c\u4e3a\u63a8\u7406\u5408\u6210\u5668\u800c\u975e\u6982\u7387\u653e\u5927\u5668\uff0c\u4f46\u524d\u63d0\u662f\u57fa\u7840\u6a21\u578b\u5df2\u638c\u63e1\u539f\u5b50\u6280\u80fd\u3002", "conclusion": "RL\u4e0d\u662f\u7b80\u5355\u7684\u653e\u5927\u5668\uff0c\u5728\u8db3\u591f\u539f\u5b50\u57fa\u7840\u4e0b\u80fd\u4e3b\u52a8\u4ece\u5b66\u4e60\u5230\u7684\u539f\u8bed\u5408\u6210\u590d\u6742\u63a8\u7406\u7b56\u7565\uff0c\u89e3\u8026\u539f\u5b50\u8bad\u7ec3\u540e\u63a5RL\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6cdb\u5316\u8def\u5f84\u3002"}}
{"id": "2512.01979", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.01979", "abs": "https://arxiv.org/abs/2512.01979", "authors": ["Aiden Yiliu Li", "Bizhi Yu", "Daoan Lei", "Tianhe Ren", "Shilong Liu"], "title": "Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback", "comment": null, "summary": "GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.", "AI": {"tldr": "\u63d0\u51faChain of Ground (CoG)\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u8fed\u4ee3\u63a8\u7406\u63d0\u5347GUI\u89c6\u89c9\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u5728ScreenSpot Pro\u57fa\u51c6\u4e0a\u63d0\u53474.8\u70b9\uff0c\u5728\u5de5\u4e1a\u63a7\u5236\u9762\u677f\u6570\u636e\u96c6\u4e0a\u63d0\u53476.9\u70b9\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728GUI\u89c6\u89c9\u5b9a\u4f4d\u4e2d\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff1a\u96be\u4ee5\u5904\u7406\u5c0f\u76ee\u6807\u3001\u89c6\u89c9\u76f8\u4f3c\u76ee\u6807\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u5e03\u5c40\u4e2d\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u8fd9\u6e90\u4e8e\u6709\u9650\u7684\u5b9a\u4f4d\u80fd\u529b\u548c\u672a\u5145\u5206\u5229\u7528\u73b0\u6709\u63a8\u7406\u6f5c\u529b\u3002", "method": "\u63d0\u51faChain of Ground (CoG)\u6846\u67b6\uff0c\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u6b65\u5b9a\u4f4d\u65b9\u6cd5\u3002\u6a21\u578b\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\uff0c\u800c\u662f\u901a\u8fc7\u8fed\u4ee3\u89c6\u89c9\u63a8\u7406\u548c\u7ec6\u5316\u9010\u6b65\u53cd\u601d\u548c\u8c03\u6574\u5047\u8bbe\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u5b9a\u4f4d\u3002", "result": "\u5728ScreenSpot Pro\u57fa\u51c6\u4e0a\u8fbe\u523068.4%\u51c6\u786e\u7387\uff0c\u63d0\u53474.8\u70b9\uff1b\u5728TPanel UI\u5de5\u4e1a\u63a7\u5236\u9762\u677f\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4Qwen3 VL 235B\u57fa\u7ebf\u63d0\u53476.9\u70b9\uff0c\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u548c\u6570\u5b57\u754c\u9762\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u7ec6\u5316\u800c\u975e\u989d\u5916\u8bad\u7ec3\uff0c\u53ef\u4ee5\u91ca\u653e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9a\u4f4d\u6f5c\u529b\uff0c\u4e3aGUI\u89c6\u89c9\u5b9a\u4f4d\u63d0\u4f9b\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2512.01992", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01992", "abs": "https://arxiv.org/abs/2512.01992", "authors": ["Sai Kolasani", "Maxim Saplin", "Nicholas Crispino", "Kyle Montgomery", "Jared Quincy Davis", "Matei Zaharia", "Chi Wang", "Chenguang Wang"], "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess", "comment": null, "summary": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.", "AI": {"tldr": "LLM CHESS\u662f\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u56fd\u9645\u8c61\u68cb\u9886\u57df\u7684\u6269\u5c55\u4ee3\u7406\u4ea4\u4e92\u6765\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u6cdb\u5316\u6027\uff0c\u5bf950\u591a\u4e2a\u6a21\u578b\u8fdb\u884c\u6392\u540d\uff0c\u53d1\u73b0\u8bb8\u591a\u5148\u8fdb\u6a21\u578b\u96be\u4ee5\u5b8c\u6210\u6e38\u620f\u6216\u53d6\u5f97\u7a33\u5b9a\u80dc\u5229\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u5bb9\u6613\u8fc7\u62df\u5408\u548c\u8bb0\u5fc6\u5316\uff0c\u4e14\u5bb9\u6613\u8fbe\u5230\u9971\u548c\u3002\u9700\u8981\u4e00\u79cd\u968f\u673a\u3001\u52a8\u6001\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u66f4\u771f\u5b9e\u5730\u6d4b\u8bd5LLMs\u7684\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u7684\u6cdb\u5316\u6027\uff0c\u7279\u522b\u662f\u5728\u6269\u5c55\u4ee3\u7406\u4ea4\u4e92\u73af\u5883\u4e2d\u3002", "method": "\u5f00\u53d1LLM CHESS\u6846\u67b6\uff0c\u8ba9LLMs\u4e0e\u968f\u673a\u5bf9\u624b\u8fdb\u884c\u56fd\u9645\u8c61\u68cb\u5bf9\u5f08\uff0c\u4f7f\u7528\u591a\u79cd\u884c\u4e3a\u6307\u6807\uff08\u80dc\u7387\u3001\u79fb\u52a8\u8d28\u91cf\u3001\u5408\u6cd5\u6027\u3001\u5e7b\u89c9\u52a8\u4f5c\u3001\u6e38\u620f\u65f6\u957f\uff09\u8bc4\u4f30\u3002\u5bf9\u9876\u7ea7\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u4e0e\u53ef\u53d8\u6280\u80fd\u914d\u7f6e\u7684\u8c61\u68cb\u5f15\u64ce\u5bf9\u5f08\u8ba1\u7b97Elo\u8bc4\u5206\u3002", "result": "\u5bf950\u591a\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u8fdb\u884c\u6392\u540d\uff0c\u53d1\u73b0\u8bb8\u591a\u6700\u5148\u8fdb\u6a21\u578b\u96be\u4ee5\u5b8c\u6210\u6e38\u620f\u6216\u53d6\u5f97\u7a33\u5b9a\u80dc\u5229\u3002\u5b9e\u9a8c\u663e\u793a\u63a8\u7406\u6a21\u578b\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u5206\u79bb\u3002\u8be5\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u8fc7\u62df\u5408\u548c\u8bb0\u5fc6\u5316\uff0c\u5373\u4f7f\u9876\u7ea7\u63a8\u7406\u6a21\u578b\u4e5f\u96be\u4ee5\u5e94\u5bf9\u3002", "conclusion": "LLM CHESS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u72ec\u7279\u3001\u52a8\u6001\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u6709\u6548\u6d4b\u8bd5LLMs\u7684\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u6cdb\u5316\u6027\uff0c\u51cf\u5c11\u57fa\u51c6\u9971\u548c\u95ee\u9898\u3002\u4f5c\u8005\u53d1\u5e03\u4e86\u5b9e\u9a8c\u6846\u67b6\u3001\u516c\u5f00\u6392\u884c\u699c\u548c\u76f8\u5173\u6e38\u620f\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
