{"id": "2507.08119", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.08119", "abs": "https://arxiv.org/abs/2507.08119", "authors": ["Eric Ding", "Chuhan Ouyang", "Rachee Singh"], "title": "Photonic Rails in ML Datacenters", "comment": null, "summary": "Rail-optimized network fabrics have become the de facto datacenter scale-out\nfabric for large-scale ML training. However, the use of high-radix electrical\nswitches to provide all-to-all connectivity in rails imposes massive power,\ncost, and complexity overheads. We propose a rethinking of the rail abstraction\nby retaining its communication semantics, but realizing it using optical\ncircuit switches. The key challenge is that optical switches support only\none-to-one connectivity at a time, limiting the fan-out of traffic in ML\nworkloads using hybrid parallelisms. We introduce parallelism-driven rail\nreconfiguration as a solution that leverages the sequential ordering between\ntraffic from different parallelisms. We design a control plane, Opus, to enable\ntime-multiplexed emulation of electrical rail switches using optical switches.\nMore broadly, our work discusses a new research agenda: datacenter fabrics that\nco-evolve with the model parallelism dimensions within each job, as opposed to\nthe prevailing mindset of reconfiguring networks before a job begins.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u7535\u8def\u4ea4\u6362\u673a\u7684\u94c1\u8def\u4f18\u5316\u7f51\u7edc\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u9ad8\u57fa\u6570\u7535\u6c14\u4ea4\u6362\u673a\u5728\u5927\u578bML\u8bad\u7ec3\u4e2d\u7684\u9ad8\u529f\u8017\u3001\u9ad8\u6210\u672c\u548c\u9ad8\u590d\u6742\u6027\u95ee\u9898\u3002\u901a\u8fc7\u5e76\u884c\u9a71\u52a8\u7684\u94c1\u8def\u91cd\u914d\u7f6e\u548c\u63a7\u5236\u5e73\u9762Opus\uff0c\u5b9e\u73b0\u4e86\u5149\u4ea4\u6362\u673a\u7684\u65f6\u95f4\u590d\u7528\u4eff\u771f\u3002", "motivation": "\u4f20\u7edf\u94c1\u8def\u4f18\u5316\u7f51\u7edc\u67b6\u6784\u4f7f\u7528\u9ad8\u57fa\u6570\u7535\u6c14\u4ea4\u6362\u673a\u5b9e\u73b0\u5168\u8fde\u63a5\uff0c\u4f46\u5e26\u6765\u4e86\u5de8\u5927\u7684\u529f\u8017\u3001\u6210\u672c\u548c\u590d\u6742\u6027\u5f00\u9500\u3002\u5149\u4ea4\u6362\u673a\u867d\u7136\u80fd\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5176\u4e00\u5bf9\u4e00\u8fde\u63a5\u7279\u6027\u9650\u5236\u4e86ML\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6247\u51fa\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5e76\u884c\u9a71\u52a8\u7684\u94c1\u8def\u91cd\u914d\u7f6e\u65b9\u6cd5\uff0c\u5229\u7528\u4e0d\u540c\u5e76\u884c\u6027\u6d41\u91cf\u4e4b\u95f4\u7684\u987a\u5e8f\u6027\uff0c\u8bbe\u8ba1\u63a7\u5236\u5e73\u9762Opus\uff0c\u5b9e\u73b0\u5149\u4ea4\u6362\u673a\u7684\u65f6\u95f4\u590d\u7528\u4eff\u771f\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5149\u4ea4\u6362\u673a\u5bf9\u7535\u6c14\u94c1\u8def\u4ea4\u6362\u673a\u7684\u65f6\u95f4\u590d\u7528\u4eff\u771f\uff0c\u4e3a\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u67b6\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u67b6\u6784\u7814\u7a76\u65b9\u5411\uff0c\u5373\u7f51\u7edc\u67b6\u6784\u4e0e\u6a21\u578b\u5e76\u884c\u7ef4\u5ea6\u5171\u540c\u6f14\u8fdb\uff0c\u800c\u975e\u5728\u4efb\u52a1\u5f00\u59cb\u524d\u9759\u6001\u914d\u7f6e\u7f51\u7edc\u3002"}}
{"id": "2507.08134", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.08134", "abs": "https://arxiv.org/abs/2507.08134", "authors": ["Minhu Wang", "Yixin Shen", "Bo Wang", "Haixuan Tong", "Yutong Xie", "Yixuan Gao", "Yan Liu", "Li Chen", "Mingwei Xu", "Jianping Wu"], "title": "Rattan: An Extensible and Scalable Modular Internet Path Emulator", "comment": null, "summary": "The rapid growth of Internet paths in heterogeneity, scale, and dynamics has\nmade existing emulators increasingly insufficient in flexibility, scalability,\nand usability. To address these limitations, we present Rattan, an extensible\nand scalable software network path emulator for modern Internet conditions.\nRattan's core innovation lies in its cell-based architecture: by splitting\nemulation functions into modular \"cells\" with well-documented asynchronous\ninterfaces, users are allowed to easily compose different cells by\nhierarchically linking them and easily construct new cells by using standard\ncell interfaces. This design enables: (1) scalability, supporting hundreds of\nconcurrent gigabit-level paths on a single machine and cluster-level\nexperiments composed of multiple machines; (2) extensibility, simulating new\nnetwork conditions by constructing new cells. Rattan empowers developers and\nresearchers to efficiently and confidently evaluate, validate, and diagnose\ndiverse network transport innovations for online services.", "AI": {"tldr": "Rattan\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u548c\u53ef\u6269\u5c55\u7684\u8f6f\u4ef6\u7f51\u7edc\u8def\u5f84\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u201c\u5355\u5143\u201d\u67b6\u6784\u89e3\u51b3\u73b0\u6709\u6a21\u62df\u5668\u5728\u7075\u6d3b\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u4e92\u8054\u7f51\u8def\u5f84\u7684\u5f02\u8d28\u6027\u3001\u89c4\u6a21\u548c\u52a8\u6001\u6027\u5feb\u901f\u589e\u957f\uff0c\u73b0\u6709\u6a21\u62df\u5668\u5728\u7075\u6d3b\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7528\u6027\u4e0a\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5355\u5143\u7684\u67b6\u6784\uff0c\u5c06\u6a21\u62df\u529f\u80fd\u62c6\u5206\u4e3a\u6a21\u5757\u5316\u5355\u5143\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u5c42\u6b21\u5316\u94fe\u63a5\u7ec4\u5408\u5355\u5143\u6216\u6784\u5efa\u65b0\u5355\u5143\u3002", "result": "\u652f\u6301\u5355\u673a\u4e0a\u767e\u4e2a\u5343\u5146\u7ea7\u8def\u5f84\u548c\u96c6\u7fa4\u7ea7\u5b9e\u9a8c\uff0c\u5e76\u80fd\u901a\u8fc7\u65b0\u5355\u5143\u6a21\u62df\u65b0\u7f51\u7edc\u6761\u4ef6\u3002", "conclusion": "Rattan\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u9760\u7684\u7f51\u7edc\u4f20\u8f93\u521b\u65b0\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2507.08164", "categories": ["cs.NI", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.08164", "abs": "https://arxiv.org/abs/2507.08164", "authors": ["Yun Tang", "Mengbang Zou", "Zeinab Nezami", "Syed Ali Raza Zaidi", "Weisi Guo"], "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence", "comment": "7 pages, 5 figures, submitted for possible publication", "summary": "The emergence of large language models (LLMs) and agentic systems is enabling\nautonomous 6G networks with advanced intelligence, including\nself-configuration, self-optimization, and self-healing. However, the current\nimplementation of individual intelligence tasks necessitates isolated knowledge\nretrieval pipelines, resulting in redundant data flows and inconsistent\ninterpretations. Inspired by the service model unification effort in Open-RAN\n(to support interoperability and vendor diversity), we propose KP-A: a unified\nNetwork Knowledge Plane specifically designed for Agentic network intelligence.\nBy decoupling network knowledge acquisition and management from intelligence\nlogic, KP-A streamlines development and reduces maintenance complexity for\nintelligence engineers. By offering an intuitive and consistent knowledge\ninterface, KP-A also enhances interoperability for the network intelligence\nagents. We demonstrate KP-A in two representative intelligence tasks: live\nnetwork knowledge Q&A and edge AI service orchestration. All implementation\nartifacts have been open-sourced to support reproducibility and future\nstandardization efforts.", "AI": {"tldr": "KP-A\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u7f51\u7edc\u77e5\u8bc6\u5e73\u9762\uff0c\u65e8\u5728\u4e3a6G\u7f51\u7edc\u4e2d\u7684\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e00\u81f4\u7684\u77e5\u8bc6\u63a5\u53e3\uff0c\u51cf\u5c11\u5197\u4f59\u6570\u636e\u6d41\u548c\u4e0d\u4e00\u81f4\u89e3\u91ca\uff0c\u5e76\u7b80\u5316\u5f00\u53d1\u548c\u7ef4\u62a4\u3002", "motivation": "\u5f53\u524d6G\u7f51\u7edc\u4e2d\u667a\u80fd\u4efb\u52a1\u7684\u5b9e\u73b0\u9700\u8981\u72ec\u7acb\u7684\u77e5\u8bc6\u68c0\u7d22\u7ba1\u9053\uff0c\u5bfc\u81f4\u6570\u636e\u5197\u4f59\u548c\u89e3\u91ca\u4e0d\u4e00\u81f4\uff0cKP-A\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "KP-A\u901a\u8fc7\u89e3\u8026\u7f51\u7edc\u77e5\u8bc6\u83b7\u53d6\u4e0e\u7ba1\u7406\u4e0e\u667a\u80fd\u903b\u8f91\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u77e5\u8bc6\u63a5\u53e3\uff0c\u652f\u6301\u667a\u80fd\u4ee3\u7406\u7684\u4e92\u64cd\u4f5c\u6027\u3002", "result": "KP-A\u5728\u5b9e\u65f6\u7f51\u7edc\u77e5\u8bc6\u95ee\u7b54\u548c\u8fb9\u7f18AI\u670d\u52a1\u7f16\u6392\u4e24\u4e2a\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u5f00\u6e90\u4e86\u5b9e\u73b0\u3002", "conclusion": "KP-A\u4e3a6G\u7f51\u7edc\u7684\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7edf\u4e00\u7684\u77e5\u8bc6\u7ba1\u7406\u65b9\u6848\uff0c\u652f\u6301\u672a\u6765\u7684\u6807\u51c6\u5316\u5de5\u4f5c\u3002"}}
{"id": "2507.08403", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.08403", "abs": "https://arxiv.org/abs/2507.08403", "authors": ["Nan Li", "Qi Sun", "Lehan Wang", "Xiaofei Xu", "Jinri Huang", "Chunhui Liu", "Jing Gao", "Yuhong Huang", "Chih-Lin I"], "title": "Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization", "comment": null, "summary": "Artificial Intelligence/Machine Learning (AI/ML) has become the most certain\nand prominent feature of 6G mobile networks. Unlike 5G, where AI/ML was not\nnatively integrated but rather an add-on feature over existing architecture, 6G\nshall incorporate AI from the onset to address its complexity and support\nubiquitous AI applications. Based on our extensive mobile network operation and\nstandardization experience from 2G to 5G, this paper explores the design and\nstandardization principles of AI-Native radio access networks (RAN) for 6G,\nwith a particular focus on its critical Day 1 architecture, functionalities and\ncapabilities. We investigate the framework of AI-Native RAN and present its\nthree essential capabilities to shed some light on the standardization\ndirection; namely, AI-driven RAN processing/optimization/automation, reliable\nAI lifecycle management (LCM), and AI-as-a-Service (AIaaS) provisioning. The\nstandardization of AI-Native RAN, in particular the Day 1 features, including\nan AI-Native 6G RAN architecture, were proposed. For validation, a large-scale\nfield trial with over 5000 5G-A base stations have been built and delivered\nsignificant improvements in average air interface latency, root cause\nidentification, and network energy consumption with the proposed architecture\nand the supporting AI functions. This paper aims to provide a Day 1 framework\nfor 6G AI-Native RAN standardization design, balancing technical innovation\nwith practical deployment.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e866G\u79fb\u52a8\u7f51\u7edc\u4e2dAI\u539f\u751f\u65e0\u7ebf\u63a5\u5165\u7f51\uff08RAN\uff09\u7684\u8bbe\u8ba1\u4e0e\u6807\u51c6\u5316\u539f\u5219\uff0c\u63d0\u51fa\u4e86\u5173\u952eDay 1\u67b6\u6784\u3001\u529f\u80fd\u4e0e\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u8bd5\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u63d0\u5347\u3002", "motivation": "5G\u4e2dAI/ML\u4ec5\u4e3a\u9644\u52a0\u529f\u80fd\uff0c\u800c6G\u9700\u4ece\u8bbe\u8ba1\u4e4b\u521d\u5c31\u539f\u751f\u96c6\u6210AI\u4ee5\u5e94\u5bf9\u590d\u6742\u6027\u5e76\u652f\u6301\u5e7f\u6cdbAI\u5e94\u7528\u3002", "method": "\u63d0\u51faAI\u539f\u751fRAN\u6846\u67b6\uff0c\u5305\u62ecAI\u9a71\u52a8\u7684RAN\u5904\u7406/\u4f18\u5316/\u81ea\u52a8\u5316\u3001\u53ef\u9760\u7684AI\u751f\u547d\u5468\u671f\u7ba1\u7406\uff08LCM\uff09\u53caAI\u5373\u670d\u52a1\uff08AIaaS\uff09\u4e09\u5927\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1Day 1\u6807\u51c6\u5316\u67b6\u6784\u3002", "result": "\u901a\u8fc75000\u591a\u4e2a5G-A\u57fa\u7ad9\u7684\u5927\u89c4\u6a21\u8bd5\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u67b6\u6784\u5728\u964d\u4f4e\u5ef6\u8fdf\u3001\u6839\u56e0\u8bc6\u522b\u548c\u80fd\u8017\u65b9\u9762\u7684\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u4e3a6G AI\u539f\u751fRAN\u6807\u51c6\u5316\u63d0\u4f9b\u4e86Day 1\u6846\u67b6\uff0c\u5e73\u8861\u6280\u672f\u521b\u65b0\u4e0e\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2507.08315", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08315", "abs": "https://arxiv.org/abs/2507.08315", "authors": ["Yaqin Li", "Kangquan Li", "Qiancheng Zhang"], "title": "New constructions of $2$-to-$1$ mappings over $\\gf_{2^n}$ and their applications to binary linear codes", "comment": null, "summary": "The $2$-to-$1$ mapping over finite fields has a wide range of applications,\nincluding combinatorial mathematics and coding theory. Thus, constructions of\n$2$-to-$1$ mappings have attracted considerable attention recently. Based on\nsummarizing the existing construction results of all $2$-to-$1$ mappings over\nfinite fields with even characteristic, this article first applies the\ngeneralized switching method to the study of $2$-to-$1$ mappings, that is, to\nconstruct $2$-to-$1$ mappings over the finite field $\\mathbb{F}_{q^l}$ with\n$F(x)=G(x)+{\\rm Tr}_{q^l/q}(R(x))$, where $G$ is a monomial and $R$ is a\nmonomial or binomial. Using the properties of Dickson polynomial theory and the\ncomplete characterization of low-degree equations, we construct a total of $16$\nnew classes of $2$-to-$1$ mappings, which are not QM-equivalent to any existing\n$2$-to-$1$ polynomials. Among these, $9$ classes are of the form $cx + {\\rm\nTr}_{q^l/q}(x^d)$, and $7$ classes have the form $cx + {\\rm Tr}_{q^l/q}(x^{d_1}\n+ x^{d_2})$. These new infinite classes explain most of numerical results by\nMAGMA under the conditions that $q=2^k$, $k>1$, $kl<14$ and $c \\in\n\\gf_{q^l}^*$. Finally, we construct some binary linear codes using the newly\nproposed $2$-to-$1$ mappings of the form $cx + {\\rm Tr}_{q^l/q}(x^d)$. The\nweight distributions of these codes are also determined. Interestingly, our\ncodes are self-orthogonal, minimal, and have few weights.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u6709\u9650\u57df\u4e0a2-to-1\u6620\u5c04\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u5e7f\u4e49\u5207\u6362\u65b9\u6cd5\u63d0\u51fa\u4e8616\u7c7b\u65b0\u76842-to-1\u6620\u5c04\uff0c\u5176\u4e2d9\u7c7b\u4e3a\u5355\u9879\u5f0f\u5f62\u5f0f\uff0c7\u7c7b\u4e3a\u4e8c\u9879\u5f0f\u5f62\u5f0f\u3002\u8fd9\u4e9b\u65b0\u6620\u5c04\u5728\u7f16\u7801\u7406\u8bba\u4e2d\u5e94\u7528\uff0c\u6784\u9020\u4e86\u81ea\u6b63\u4ea4\u3001\u6781\u5c0f\u4e14\u5c11\u6743\u7684\u4e8c\u8fdb\u5236\u7ebf\u6027\u7801\u3002", "motivation": "2-to-1\u6620\u5c04\u5728\u7ec4\u5408\u6570\u5b66\u548c\u7f16\u7801\u7406\u8bba\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u6784\u9020\u65b9\u6cd5\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u65b0\u7684\u6784\u9020\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u5e7f\u4e49\u5207\u6362\u65b9\u6cd5\uff0c\u7ed3\u5408Dickson\u591a\u9879\u5f0f\u7406\u8bba\u548c\u4f4e\u6b21\u65b9\u7a0b\u6027\u8d28\uff0c\u6784\u9020\u4e8616\u7c7b\u65b0\u76842-to-1\u6620\u5c04\u3002", "result": "\u63d0\u51fa\u4e8616\u7c7b\u65b0\u76842-to-1\u6620\u5c04\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u6620\u5c04\u6784\u9020\u4e86\u81ea\u6b63\u4ea4\u3001\u6781\u5c0f\u4e14\u5c11\u6743\u7684\u4e8c\u8fdb\u5236\u7ebf\u6027\u7801\u3002", "conclusion": "\u65b0\u6784\u9020\u76842-to-1\u6620\u5c04\u4e30\u5bcc\u4e86\u73b0\u6709\u7406\u8bba\uff0c\u5e76\u5728\u7f16\u7801\u7406\u8bba\u4e2d\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.08001", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.08001", "abs": "https://arxiv.org/abs/2507.08001", "authors": ["Shengyi Xie"], "title": "Human Creativity and AI", "comment": null, "summary": "With the advancement of science and technology, the philosophy of creativity\nhas undergone significant reinterpretation. This paper investigates\ncontemporary research in the fields of psychology, cognitive neuroscience, and\nthe philosophy of creativity, particularly in the context of the development of\nartificial intelligence (AI) techniques. It aims to address the central\nquestion: Can AI exhibit creativity? The paper reviews the historical\nperspectives on the philosophy of creativity and explores the influence of\npsychological advancements on the study of creativity. Furthermore, it analyzes\nvarious definitions of creativity and examines the responses of naturalism and\ncognitive neuroscience to the concept of creativity.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u662f\u5426\u80fd\u8868\u73b0\u521b\u9020\u529b\uff0c\u7ed3\u5408\u5fc3\u7406\u5b66\u3001\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u548c\u54f2\u5b66\u89c6\u89d2\uff0c\u5206\u6790\u521b\u9020\u529b\u7684\u5b9a\u4e49\u53ca\u5176\u5728AI\u6280\u672f\u53d1\u5c55\u4e2d\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u79d1\u6280\u8fdb\u6b65\uff0c\u521b\u9020\u529b\u54f2\u5b66\u88ab\u91cd\u65b0\u8be0\u91ca\uff0c\u7814\u7a76\u65e8\u5728\u56de\u7b54AI\u662f\u5426\u5177\u5907\u521b\u9020\u529b\u8fd9\u4e00\u6838\u5fc3\u95ee\u9898\u3002", "method": "\u56de\u987e\u521b\u9020\u529b\u54f2\u5b66\u7684\u5386\u53f2\u89c2\u70b9\uff0c\u7ed3\u5408\u5fc3\u7406\u5b66\u548c\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u8fdb\u5c55\uff0c\u5206\u6790\u521b\u9020\u529b\u7684\u591a\u79cd\u5b9a\u4e49\u3002", "result": "\u63a2\u8ba8\u4e86\u81ea\u7136\u4e3b\u4e49\u548c\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u5bf9\u521b\u9020\u529b\u7684\u56de\u5e94\uff0c\u63ed\u793a\u4e86AI\u6280\u672f\u5bf9\u521b\u9020\u529b\u7814\u7a76\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "conclusion": "AI\u5728\u521b\u9020\u529b\u65b9\u9762\u7684\u8868\u73b0\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u4f46\u5176\u53d1\u5c55\u5df2\u4e3a\u521b\u9020\u529b\u54f2\u5b66\u548c\u79d1\u5b66\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.08429", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.08429", "abs": "https://arxiv.org/abs/2507.08429", "authors": ["Geng Sun", "Likun Zhang", "Jiahui Li", "Jing Wu", "Jiacheng Wang", "Zemin Sun", "Changyuan Zhao", "Victor C. M. Leung"], "title": "Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method", "comment": "21 pages, 8 figures", "summary": "The integration of unmanned aerial vehicles (UAVs) with Internet of Things\n(IoT) networks offers promising solutions for efficient data collection.\nHowever, the limited energy capacity of UAVs remains a significant challenge.\nIn this case, laser beam directors (LBDs) have emerged as an effective\ntechnology for wireless charging of UAVs during operation, thereby enabling\nsustained data collection without frequent returns to charging stations (CSs).\nIn this work, we investigate the age of information (AoI) optimization in\nLBD-powered UAV-assisted IoT networks, where multiple UAVs collect data from\ndistributed IoTs while being recharged by laser beams. We formulate a joint\noptimization problem that aims to minimize the peak AoI while determining\noptimal UAV trajectories and laser charging strategies. This problem is\nparticularly challenging due to its non-convex nature, complex temporal\ndependencies, and the need to balance data collection efficiency with energy\nconsumption constraints. To address these challenges, we propose a novel\nmulti-agent proximal policy optimization with temporal memory and multi-agent\ncoordination (MAPPO-TM) framework. Specifically, MAPPO-TM incorporates temporal\nmemory mechanisms to capture the dynamic nature of UAV operations and\nfacilitates effective coordination among multiple UAVs through decentralized\nlearning while considering global system objectives. Simulation results\ndemonstrate that the proposed MAPPO-TM algorithm outperforms conventional\napproaches in terms of peak AoI minimization and energy efficiency. Ideally,\nthe proposed algorithm achieves up to 15.1% reduction in peak AoI compared to\nconventional multi-agent deep reinforcement learning (MADRL) methods.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6fc0\u5149\u675f\u5145\u7535\u65e0\u4eba\u673a\uff08UAV\uff09\u8f85\u52a9\u7269\u8054\u7f51\uff08IoT\uff09\u7f51\u7edc\u4e2d\u7684\u4fe1\u606f\u65f6\u6548\u6027\uff08AoI\uff09\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff08MAPPO-TM\uff09\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5cf0\u503cAoI\u5e76\u63d0\u9ad8\u4e86\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u65e0\u4eba\u673a\u4e0e\u7269\u8054\u7f51\u7f51\u7edc\u7684\u7ed3\u5408\u4e3a\u9ad8\u6548\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\uff0c\u4f46\u65e0\u4eba\u673a\u7684\u6709\u9650\u80fd\u6e90\u5bb9\u91cf\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u3002\u6fc0\u5149\u675f\u5145\u7535\u6280\u672f\uff08LBD\uff09\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5982\u4f55\u4f18\u5316\u4fe1\u606f\u65f6\u6548\u6027\uff08AoI\uff09\u4ecd\u662f\u4e00\u4e2a\u590d\u6742\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff08MAPPO-TM\uff09\uff0c\u7ed3\u5408\u65f6\u95f4\u8bb0\u5fc6\u673a\u5236\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\uff0c\u4f18\u5316\u65e0\u4eba\u673a\u8f68\u8ff9\u548c\u6fc0\u5149\u5145\u7535\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cMAPPO-TM\u5728\u5cf0\u503cAoI\u6700\u5c0f\u5316\u548c\u80fd\u6e90\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5cf0\u503cAoI\u964d\u4f4e\u4e8615.1%\u3002", "conclusion": "MAPPO-TM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u8f85\u52a9\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u7684AoI\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.08352", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08352", "abs": "https://arxiv.org/abs/2507.08352", "authors": ["Gia-Huy Nguyen", "Anh-Nhat Nguyen", "Minh-Sang Nguyen", "Khai Nguyen", "Tung-Son Ngo", "Ngoc-Anh Bui", "Phuong-Chi Le", "Manh-Duc Hoang"], "title": "Secrecy Offloading Analysis of UAV-assisted NOMA-MEC Incorporating WPT in IoT Networks", "comment": "6 pages, 7 figures, 2024 28th International Computer Science and\n  Engineering Conference (ICSEC)", "summary": "This article studies the efficiency of secrecy data offloading for an\nunmanned aerial vehicle (UAV)-assisted nonorthogonal multiple access\n(NOMA)-integrated mobile-edge computing (MEC) incorporating wireless power\ntransfer (WPT) within an Internet of Things (IoT) network. Specifically, this\nstudy assumes an UAV to function in dual roles: as a mobile computation\nplatform and as an aerial power-supply station, offering substantial advantages\nfor resource-constrained edge devices (EDs) in mitigating interference from an\npassive eavesdropper. To assess the system's secrecy offloading efficacy, the\nsecrecy successful computation probability (SSCP) closed-formed formulation\nunder Nakagami-m fading channel is derived. The theoretical results are\nconducted with a variety of parameters, thereby validating the precision of our\nanalysis.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u8f85\u52a9\u7684\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165\uff08NOMA\uff09\u4e0e\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u7ed3\u5408\u7684\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\uff08WPT\uff09\u5bf9\u6570\u636e\u5378\u8f7d\u6548\u7387\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\uff08EDs\uff09\u5728\u88ab\u52a8\u7a83\u542c\u8005\u5e72\u6270\u4e0b\u7684\u6570\u636e\u5378\u8f7d\u95ee\u9898\uff0c\u5229\u7528\u65e0\u4eba\u673a\u7684\u53cc\u91cd\u89d2\u8272\uff08\u8ba1\u7b97\u5e73\u53f0\u548c\u80fd\u91cf\u4f9b\u5e94\u7ad9\uff09\u63d0\u5347\u6548\u7387\u3002", "method": "\u63a8\u5bfc\u4e86Nakagami-m\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u4fdd\u5bc6\u6210\u529f\u8ba1\u7b97\u6982\u7387\uff08SSCP\uff09\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u53c2\u6570\u9a8c\u8bc1\u5206\u6790\u7cbe\u5ea6\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65e0\u4eba\u673a\u53cc\u91cd\u89d2\u8272\u5728\u63d0\u5347\u6570\u636e\u5378\u8f7d\u6548\u7387\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u65e0\u4eba\u673a\u5728NOMA-MEC-WPT\u7cfb\u7edf\u4e2d\u80fd\u663e\u8457\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u7684\u8ba1\u7b97\u6548\u7387\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2507.08046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08046", "abs": "https://arxiv.org/abs/2507.08046", "authors": ["Sishi Xiong", "Dakai Wang", "Yu Zhao", "Jie Zhang", "Changzai Pan", "Haowei He", "Xiangyu Li", "Wenhan Chang", "Zhongjiang He", "Shuangyong Song", "Yongxiang Li"], "title": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models", "comment": null, "summary": "The paper presents our system developed for table question answering (TQA).\nTQA tasks face challenges due to the characteristics of real-world tabular\ndata, such as large size, incomplete column semantics, and entity ambiguity. To\naddress these issues, we propose a large language model (LLM)-powered and\nprogramming-based table reasoning framework, named TableReasoner. It models a\ntable using the schema that combines structural and semantic representations,\nenabling holistic understanding and efficient processing of large tables. We\ndesign a multi-step schema linking plan to derive a focused table schema that\nretains only query-relevant information, eliminating ambiguity and alleviating\nhallucinations. This focused table schema provides precise and sufficient table\ndetails for query refinement and programming. Furthermore, we integrate the\nreasoning workflow into an iterative thinking architecture, allowing\nincremental cycles of thinking, reasoning and reflection. Our system achieves\nfirst place in both subtasks of SemEval-2025 Task 8.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTableReasoner\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7a0b\u65b9\u6cd5\uff0c\u89e3\u51b3\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u5982\u8868\u683c\u89c4\u6a21\u5927\u3001\u8bed\u4e49\u4e0d\u5b8c\u6574\u548c\u5b9e\u4f53\u6b67\u4e49\u3002", "motivation": "\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u9762\u4e34\u771f\u5b9e\u4e16\u754c\u8868\u683c\u6570\u636e\u7684\u6311\u6218\uff0c\u5982\u89c4\u6a21\u5927\u3001\u8bed\u4e49\u4e0d\u5b8c\u6574\u548c\u5b9e\u4f53\u6b67\u4e49\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faTableReasoner\u6846\u67b6\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u548c\u8bed\u4e49\u8868\u793a\u7684\u8868\u6a21\u5f0f\uff0c\u8bbe\u8ba1\u591a\u6b65\u6a21\u5f0f\u94fe\u63a5\u8ba1\u5212\uff0c\u751f\u6210\u805a\u7126\u8868\u6a21\u5f0f\uff0c\u5e76\u96c6\u6210\u8fed\u4ee3\u601d\u8003\u67b6\u6784\u3002", "result": "\u7cfb\u7edf\u5728SemEval-2025 Task 8\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u5747\u83b7\u5f97\u7b2c\u4e00\u540d\u3002", "conclusion": "TableReasoner\u901a\u8fc7\u7ed3\u5408LLM\u548c\u7f16\u7a0b\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8868\u683c\u95ee\u7b54\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.08715", "categories": ["cs.AI", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.08715", "abs": "https://arxiv.org/abs/2507.08715", "authors": ["Paul Saves", "Jasper Bussemaker", "R\u00e9mi Lafage", "Thierry Lefebvre", "Nathalie Bartoli", "Youssef Diouane", "Joseph Morlier"], "title": "System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility", "comment": null, "summary": "For developing innovative systems architectures, modeling and optimization\ntechniques have been central to frame the architecting process and define the\noptimization and modeling problems. In this context, for system-of-systems the\nuse of efficient dedicated approaches (often physics-based simulations) is\nhighly recommended to reduce the computational complexity of the targeted\napplications. However, exploring novel architectures using such dedicated\napproaches might pose challenges for optimization algorithms, including\nincreased evaluation costs and potential failures. To address these challenges,\nsurrogate-based optimization algorithms, such as Bayesian optimization\nutilizing Gaussian process models have emerged.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u7cfb\u7edf\u67b6\u6784\u5f00\u53d1\u4e2d\uff0c\u4f7f\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u7b97\u6cd5\uff08\u5982\u8d1d\u53f6\u65af\u4f18\u5316\uff09\u6765\u89e3\u51b3\u4f20\u7edf\u7269\u7406\u6a21\u62df\u65b9\u6cd5\u5e26\u6765\u7684\u8ba1\u7b97\u590d\u6742\u6027\u548c\u4f18\u5316\u6311\u6218\u3002", "motivation": "\u9488\u5bf9\u7cfb\u7edf\u67b6\u6784\u5f00\u53d1\u4e2d\u4f20\u7edf\u7269\u7406\u6a21\u62df\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u6f5c\u5728\u5931\u8d25\u95ee\u9898\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u6280\u672f\u6765\u63a2\u7d22\u65b0\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u8d1d\u53f6\u65af\u4f18\u5316\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\uff0c\u4ee5\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u7b97\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u4f18\u5316\u6548\u7387\u3002", "conclusion": "\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u7b97\u6cd5\u4e3a\u7cfb\u7edf\u67b6\u6784\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08507", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.08507", "abs": "https://arxiv.org/abs/2507.08507", "authors": ["Geng Sun", "Chenbang Liu", "Jiahui Li", "Guannan Qu", "Shuang Liang", "Jiacheng Wang", "Changyuan Zhao", "Dusit Niyato"], "title": "Recovery of UAV Swarm-enabled Collaborative Beamforming in Low-altitude Wireless Networks under Wind Field Disturbances", "comment": null, "summary": "Unmanned aerial vehicle (UAV) swarms utilizing collaborative beamforming (CB)\nin low-altitude wireless networks (LAWN) demonstrate significant potential for\nenhanced communication range, energy efficiency, and signal directivity through\nthe formation of virtual antenna arrays (VAA). However, environmental\ndisturbances, particularly wind fields, significantly degrade CB performance by\nintroducing positional errors that disrupt beam patterns, thereby compromising\ntransmission reliability. This paper investigates the critical challenge of\nmaintaining CB performance in UAV-based VAAs operating in LAWN under wind field\ndisturbances. We propose a comprehensive framework that models the impact of\nthree distinct wind conditions (constant, shear, and turbulent) on UAV array\nperformance, and formulate a long-term real-time optimization problem to\nmaximize directivity while minimizing maximum sidelobe levels through adaptive\nexcitation current weight adjustments. To address the inherent complexity of\nthis problem, we propose a novel proximal policy optimization algorithm with\nlong short-term memory (LSTM) structure and adaptive learning rate (PPO-LA),\nwhich effectively captures temporal patterns in wind field disturbances and\nenables real-time adaptation without requiring extensive prior training for\nspecific wind conditions. Our simulation results demonstrate that the proposed\nPPO-LA algorithm successfully recovers degraded CB performance across various\nwind scenarios, and thus significantly outperforming benchmark algorithms.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u7fa4\u5728\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5229\u7528\u534f\u4f5c\u6ce2\u675f\u5f62\u6210\u65f6\uff0c\u98ce\u573a\u5e72\u6270\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePPO-LA\u7b97\u6cd5\u7684\u5b9e\u65f6\u4f18\u5316\u6846\u67b6\u3002", "motivation": "\u98ce\u573a\u5e72\u6270\u4f1a\u663e\u8457\u964d\u4f4e\u65e0\u4eba\u673a\u865a\u62df\u5929\u7ebf\u9635\u5217\u7684\u6ce2\u675f\u5f62\u6210\u6027\u80fd\uff0c\u5f71\u54cd\u901a\u4fe1\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5b9e\u65f6\u9002\u5e94\u98ce\u573a\u53d8\u5316\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LSTM\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u7684PPO-LA\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u4f18\u5316\u6ce2\u675f\u5f62\u6210\u7684\u6fc0\u52b1\u7535\u6d41\u6743\u91cd\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u540c\u98ce\u573a\u6761\u4ef6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cPPO-LA\u7b97\u6cd5\u80fd\u6709\u6548\u6062\u590d\u6ce2\u675f\u5f62\u6210\u6027\u80fd\uff0c\u5e76\u5728\u591a\u79cd\u98ce\u573a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "PPO-LA\u7b97\u6cd5\u4e3a\u89e3\u51b3\u98ce\u573a\u5e72\u6270\u4e0b\u7684\u534f\u4f5c\u6ce2\u675f\u5f62\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08598", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08598", "abs": "https://arxiv.org/abs/2507.08598", "authors": ["Hossam Hassan", "Ali Gaber", "Mohammed Karmoose", "Noha Korany"], "title": "Discovering the Unequal Importance of Coded Bits in the Decoding of Polar Codes", "comment": null, "summary": "Polar codes are widely used in modern communication systems due to their\ncapacity-achieving properties. This paper investigates the importance of coded\nbits in the decoding process of polar codes and aims to determine which bits\ncontribute most to successful decoding. We investigate the problem via a\nbrute-force search approach and surrogate optimization techniques to identify\nthe most critical coded bits. We also demonstrate how mapping these important\nbits to the most reliable channels improves system performance with minimal\nadditional cost. We show the performance of our proposed bit mapping in OFDM\nbased systems, and demonstrate up to x7 gain in BER performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6781\u5316\u7801\u4e2d\u7f16\u7801\u6bd4\u7279\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u901a\u8fc7\u66b4\u529b\u641c\u7d22\u548c\u4ee3\u7406\u4f18\u5316\u6280\u672f\u786e\u5b9a\u5173\u952e\u6bd4\u7279\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8fd9\u4e9b\u6bd4\u7279\u6620\u5c04\u5230\u53ef\u9760\u4fe1\u9053\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u6781\u5316\u7801\u56e0\u5176\u5bb9\u91cf\u903c\u8fd1\u7279\u6027\u5728\u73b0\u4ee3\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u89e3\u7801\u8fc7\u7a0b\u4e2d\u54ea\u4e9b\u6bd4\u7279\u5bf9\u6210\u529f\u89e3\u7801\u8d21\u732e\u6700\u5927\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u91c7\u7528\u66b4\u529b\u641c\u7d22\u548c\u4ee3\u7406\u4f18\u5316\u6280\u672f\u8bc6\u522b\u5173\u952e\u7f16\u7801\u6bd4\u7279\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u6700\u53ef\u9760\u7684\u4fe1\u9053\u3002", "result": "\u5728OFDM\u7cfb\u7edf\u4e2d\uff0c\u63d0\u51fa\u7684\u6bd4\u7279\u6620\u5c04\u65b9\u6cd5\u53ef\u5c06BER\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe7\u500d\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u6bd4\u7279\u6620\u5c04\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6781\u5316\u7801\u89e3\u7801\u6027\u80fd\uff0c\u4e14\u989d\u5916\u6210\u672c\u6781\u4f4e\u3002"}}
{"id": "2507.08207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08207", "abs": "https://arxiv.org/abs/2507.08207", "authors": ["Zhengye Han", "Quanyan Zhu"], "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in critical\napplications, the challenge of jailbreaking, where adversaries manipulate the\nmodels to bypass safety mechanisms, has become a significant concern. This\npaper presents a dynamic Stackelberg game framework to model the interactions\nbetween attackers and defenders in the context of LLM jailbreaking. The\nframework treats the prompt-response dynamics as a sequential extensive-form\ngame, where the defender, as the leader, commits to a strategy while\nanticipating the attacker's optimal responses. We propose a novel agentic AI\nsolution, the \"Purple Agent,\" which integrates adversarial exploration and\ndefensive strategies using Rapidly-exploring Random Trees (RRT). The Purple\nAgent actively simulates potential attack trajectories and intervenes\nproactively to prevent harmful outputs. This approach offers a principled\nmethod for analyzing adversarial dynamics and provides a foundation for\nmitigating the risk of jailbreaking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21LLM\u8d8a\u72f1\u4e2d\u7684\u653b\u9632\u4ea4\u4e92\uff0c\u5e76\u5f15\u5165\u201cPurple Agent\u201d\u7ed3\u5408RRT\u6280\u672f\u4e3b\u52a8\u9632\u5fa1\u3002", "motivation": "\u968f\u7740LLM\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u8d8a\u72f1\u653b\u51fb\u6210\u4e3a\u91cd\u8981\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u6709\u6548\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u5c06\u63d0\u793a-\u54cd\u5e94\u52a8\u6001\u5efa\u6a21\u4e3a\u987a\u5e8f\u6269\u5c55\u535a\u5f08\uff0c\u63d0\u51fa\u7ed3\u5408RRT\u7684Purple Agent\u8fdb\u884c\u4e3b\u52a8\u9632\u5fa1\u3002", "result": "\u6846\u67b6\u4e3a\u5206\u6790\u5bf9\u6297\u52a8\u6001\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u5e76\u80fd\u4e3b\u52a8\u9884\u9632\u6709\u5bb3\u8f93\u51fa\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7f13\u89e3LLM\u8d8a\u72f1\u98ce\u9669\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.08549", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.08549", "abs": "https://arxiv.org/abs/2507.08549", "authors": ["Yaojia Wang", "Qi Zhang", "Kun Qiu", "Yue Gao"], "title": "Stabilizing and Optimizing Inter-Shell Routing in LEO Networks with Integrated Routing Cost", "comment": "6 pages, 8 figures, 2025 IEEE/CIC International Conference on\n  Communications in China (ICCC Workshops)", "summary": "The low Earth orbit (LEO) mega-constellation network (LMCN), which uses\nthousands of satellites across multi-shell architectures to deliver different\nservices, is facing challenges in inter-shell routing stability due to dynamic\nnetwork topologies and frequent inter-satellite link (ISL) switching. Existing\nstrategies, such as the Minimum Hop Path set, prioritize minimizing hop counts\nto reduce latency, but ignore ISL switching costs, which leads to high\ninstability. To overcome this, the Adaptive Path Routing Scheme introduces path\nsimilarity thresholds to reduce the ISL switching frequency between shells.\nHowever, the greedy approach of Adaptive Path Routing Scheme is often trapped\nin local optima, sacrificing inter-shell path distance efficiency. To address\nthese limitations, we propose the Dynamic Programming-based Integrated Routing\nCost (DP-IRC) algorithm, which is designed explicitly for inter-shell routing\noptimization. By formulating multi-shell paths as a multistage decision\nproblem, DP-IRC balances hop counts and ISL stability through an Integrated\nRouting Cost (IRC) metric, combining inter-/intra-shell hops and switching\ncosts. Experiments over 60 time slots with real-world Starlink and OneWeb\nconfigurations show that DP-IRC reduces inter-shell ISL switching rates by\n39.1% and 22.0% compared to the Minimum Hop Path set strategy and Adaptive Path\nRouting Scheme, respectively, while still maintaining near-optimal end-to-end\ndistances.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7684\u96c6\u6210\u8def\u7531\u6210\u672c\u7b97\u6cd5\uff08DP-IRC\uff09\uff0c\u7528\u4e8e\u4f18\u5316\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u591a\u58f3\u7f51\u7edc\u4e2d\u7684\u8de8\u58f3\u8def\u7531\u7a33\u5b9a\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u94fe\u8def\u5207\u6362\u9891\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u8de8\u58f3\u8def\u7531\u7b56\u7565\uff08\u5982\u6700\u5c0f\u8df3\u6570\u8def\u5f84\u96c6\u548c\u81ea\u9002\u5e94\u8def\u5f84\u8def\u7531\u65b9\u6848\uff09\u5728\u52a8\u6001\u7f51\u7edc\u62d3\u6251\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u8981\u4e48\u5ffd\u7565\u94fe\u8def\u5207\u6362\u6210\u672c\uff0c\u8981\u4e48\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002", "method": "\u901a\u8fc7\u5c06\u591a\u58f3\u8def\u5f84\u5efa\u6a21\u4e3a\u591a\u9636\u6bb5\u51b3\u7b56\u95ee\u9898\uff0cDP-IRC\u4f7f\u7528\u96c6\u6210\u8def\u7531\u6210\u672c\uff08IRC\uff09\u6307\u6807\u5e73\u8861\u8df3\u6570\u548c\u94fe\u8def\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDP-IRC\u6bd4\u6700\u5c0f\u8df3\u6570\u8def\u5f84\u96c6\u548c\u81ea\u9002\u5e94\u8def\u5f84\u8def\u7531\u65b9\u6848\u5206\u522b\u51cf\u5c1139.1%\u548c22.0%\u7684\u94fe\u8def\u5207\u6362\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u6700\u4f18\u7684\u7aef\u5230\u7aef\u8ddd\u79bb\u3002", "conclusion": "DP-IRC\u5728\u8de8\u58f3\u8def\u7531\u4e2d\u5b9e\u73b0\u4e86\u94fe\u8def\u7a33\u5b9a\u6027\u548c\u8def\u5f84\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3aLEO\u591a\u58f3\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08599", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08599", "abs": "https://arxiv.org/abs/2507.08599", "authors": ["Haricharan Balasundaram", "Krishna Jagannathan"], "title": "Learning to Transmit Over Unknown Erasure Channels with Empirical Erasure Rate Feedback", "comment": null, "summary": "We address the problem of reliable data transmission within a finite time\nhorizon $T$ over a binary erasure channel with unknown erasure probability. We\nconsider a feedback model wherein the transmitter can query the receiver\ninfrequently and obtain the empirical erasure rate experienced by the latter.\nWe aim to minimize a regret quantity, i.e. how much worse a strategy performs\ncompared to an oracle who knows the probability of erasure, while operating at\nthe same block error rate. A learning vs. exploitation dilemma manifests in\nthis scenario -- specifically, we need to balance between (i) learning the\nerasure probability with reasonable accuracy and (ii) utilizing the channel to\ntransmit as many information bits as possible. We propose two strategies: (i) a\ntwo-phase approach using rate estimation followed by transmission that achieves\nan $O({T}^{\\frac 23})$ regret using only one query, and (ii) a windowing\nstrategy using geometrically-increasing window sizes that achieves an\n$O({\\sqrt{T}})$ regret using $O(\\log(T))$ queries.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u6709\u9650\u65f6\u95f4T\u5185\u901a\u8fc7\u672a\u77e5\u64e6\u9664\u6982\u7387\u7684\u4e8c\u8fdb\u5236\u64e6\u9664\u4fe1\u9053\u8fdb\u884c\u53ef\u9760\u6570\u636e\u4f20\u8f93\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7b56\u7565\u4ee5\u6700\u5c0f\u5316\u9057\u61be\u503c\u3002", "motivation": "\u89e3\u51b3\u5728\u672a\u77e5\u64e6\u9664\u6982\u7387\u7684\u4fe1\u9053\u4e2d\uff0c\u5982\u4f55\u5e73\u8861\u5b66\u4e60\u548c\u4f20\u8f93\u4ee5\u5b9e\u73b0\u53ef\u9760\u6570\u636e\u4f20\u8f93\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7b56\u7565\uff1a(1) \u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5148\u4f30\u8ba1\u64e6\u9664\u6982\u7387\u518d\u4f20\u8f93\uff1b(2) \u51e0\u4f55\u9012\u589e\u7a97\u53e3\u7b56\u7565\u3002", "result": "\u7b2c\u4e00\u79cd\u7b56\u7565\u4f7f\u7528\u4e00\u6b21\u67e5\u8be2\u8fbe\u5230O(T^(2/3))\u9057\u61be\uff0c\u7b2c\u4e8c\u79cd\u7b56\u7565\u4f7f\u7528O(log(T))\u67e5\u8be2\u8fbe\u5230O(\u221aT)\u9057\u61be\u3002", "conclusion": "\u4e24\u79cd\u7b56\u7565\u5728\u4e0d\u540c\u67e5\u8be2\u590d\u6742\u5ea6\u4e0b\u5747\u80fd\u6709\u6548\u51cf\u5c11\u9057\u61be\u503c\uff0c\u4e3a\u672a\u77e5\u4fe1\u9053\u4e0b\u7684\u6570\u636e\u4f20\u8f93\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08208", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2507.08208", "abs": "https://arxiv.org/abs/2507.08208", "authors": ["Quanyan Zhu"], "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions", "comment": null, "summary": "We introduce the LLM-Nash framework, a game-theoretic model where agents\nselect reasoning prompts to guide decision-making via Large Language Models\n(LLMs). Unlike classical games that assume utility-maximizing agents with full\nrationality, this framework captures bounded rationality by modeling the\nreasoning process explicitly. Equilibrium is defined over the prompt space,\nwith actions emerging as the behavioral output of LLM inference. This approach\nenables the study of cognitive constraints, mindset expressiveness, and\nepistemic learning. Through illustrative examples, we show how reasoning\nequilibria can diverge from classical Nash outcomes, offering a new foundation\nfor strategic interaction in LLM-enabled systems.", "AI": {"tldr": "LLM-Nash\u6846\u67b6\u901a\u8fc7\u6e38\u620f\u7406\u8bba\u6a21\u578b\u7814\u7a76LLM\u9a71\u52a8\u7684\u51b3\u7b56\uff0c\u5f15\u5165\u63d0\u793a\u9009\u62e9\u4ee5\u6355\u6349\u6709\u9650\u7406\u6027\uff0c\u5b9a\u4e49\u63d0\u793a\u7a7a\u95f4\u5747\u8861\uff0c\u5c55\u793a\u4e0e\u4f20\u7edf\u7eb3\u4ec0\u5747\u8861\u7684\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76LLM\u5728\u6218\u7565\u4ea4\u4e92\u4e2d\u7684\u6709\u9650\u7406\u6027\u884c\u4e3a\uff0c\u5f25\u8865\u4f20\u7edf\u6e38\u620f\u7406\u8bba\u4e2d\u5b8c\u5168\u7406\u6027\u5047\u8bbe\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u6e38\u620f\u7406\u8bba\u6a21\u578b\uff0c\u4ee3\u7406\u901a\u8fc7\u9009\u62e9\u63d0\u793a\u6307\u5bfcLLM\u51b3\u7b56\uff0c\u5b9a\u4e49\u63d0\u793a\u7a7a\u95f4\u5747\u8861\u3002", "result": "\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u63a8\u7406\u5747\u8861\u4e0e\u4f20\u7edf\u7eb3\u4ec0\u5747\u8861\u7684\u5dee\u5f02\uff0c\u4e3aLLM\u7cfb\u7edf\u6218\u7565\u4ea4\u4e92\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "conclusion": "LLM-Nash\u6846\u67b6\u4e3a\u7814\u7a76\u6709\u9650\u7406\u6027\u3001\u8ba4\u77e5\u7ea6\u675f\u548c\u6218\u7565\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2507.08677", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.08677", "abs": "https://arxiv.org/abs/2507.08677", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphal"], "title": "Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect", "comment": null, "summary": "There are currently many communication options in the Internet of Things,\neven in particular areas such as constrained and battery-powered devices, such\nas Low Power Wide Area Networks. Understanding the differences and\ncharacteristics of each option is a challenge, even for professionals and\nresearchers in the field. To meet this need, this work analyses the qualitative\ncharacteristics of Low Power Wide Area Network protocols and the challenges and\nopportunities of using constrained devices for sparse networks based on\nlong-life batteries. For this study, a bibliographic survey of the literature\nwas carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and\nSigfox), and a detailing of the first one. As a result, there is a discussion\nabout the chosen network protocol and its use in IoT solutions with sparse\nsensors.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4f4e\u529f\u8017\u5e7f\u57df\u7f51\uff08LPWAN\uff09\u534f\u8bae\u7684\u5b9a\u6027\u7279\u5f81\uff0c\u63a2\u8ba8\u4e86\u5728\u7a00\u758f\u7f51\u7edc\u4e2d\u57fa\u4e8e\u957f\u5bff\u547d\u7535\u6c60\u7684\u53d7\u9650\u8bbe\u5907\u7684\u6311\u6218\u4e0e\u673a\u9047\u3002", "motivation": "\u7269\u8054\u7f51\u4e2d\u901a\u4fe1\u9009\u9879\u4f17\u591a\uff0c\u7406\u89e3\u6bcf\u79cd\u9009\u9879\u7684\u5dee\u5f02\u548c\u7279\u6027\u5bf9\u4e13\u4e1a\u4eba\u58eb\u548c\u7814\u7a76\u4eba\u5458\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u901a\u8fc7\u6587\u732e\u8c03\u67e5\u5206\u6790\u4e86\u4e09\u79cd\u534f\u8bae\uff08LoRaWAN\u3001NB-IoT\u548cSigfox\uff09\uff0c\u5e76\u8be6\u7ec6\u8ba8\u8bba\u4e86LoRaWAN\u3002", "result": "\u8ba8\u8bba\u4e86\u6240\u9009\u7f51\u7edc\u534f\u8bae\u53ca\u5176\u5728\u7a00\u758f\u4f20\u611f\u5668\u7269\u8054\u7f51\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3LPWAN\u534f\u8bae\u53ca\u5176\u5728\u53d7\u9650\u8bbe\u5907\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2507.08611", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08611", "abs": "https://arxiv.org/abs/2507.08611", "authors": ["Sina Beyraghi", "Giovanni Interdonato", "Giovanni Geraci", "Stefano Buzzi", "Angel Lozano"], "title": "Evaluating the Performance of Reconfigurable Intelligent Base Stations through Ray Tracing", "comment": null, "summary": "Massive multiple-input multiple-output (mMIMO) is a key capacity-boosting\ntechnology in 5G wireless systems. To reduce the number of radio frequency (RF)\nchains needed in such systems, a novel approach has recently been introduced\ninvolving an antenna array supported by a reconfigurable intelligent surface.\nThis arrangement, known as a reconfigurable intelligent base station (RIBS),\noffers performance comparable to that of a traditional mMIMO array, but with\nsignificantly fewer RF chains. Given the growing importance of precise,\nlocation-specific performance prediction, this paper evaluates the performance\nof an RIBS system by means of the SIONNA ray-tracing module. That performance\nis contrasted against results derived from a statistical 3GPP-compliant channel\nmodel, optimizing power and RIS configuration to maximize the sum spectral\nefficiency. Ray tracing predicts better performance than the statistical model\nin the evaluated scenario, suggesting the potential of site-specific modeling.\nHowever, empirical validation is needed to confirm this advantage.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u91cd\u6784\u667a\u80fd\u57fa\u7ad9\uff08RIBS\uff09\u7684\u65b0\u578bmMIMO\u7cfb\u7edf\uff0c\u901a\u8fc7\u51cf\u5c11\u5c04\u9891\u94fe\u6570\u91cf\u5b9e\u73b0\u4e0e\u4f20\u7edfmMIMO\u9635\u5217\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u4f7f\u7528SIONNA\u5c04\u7ebf\u8ffd\u8e2a\u6a21\u5757\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "motivation": "5G\u65e0\u7ebf\u7cfb\u7edf\u4e2d\uff0cmMIMO\u662f\u63d0\u5347\u5bb9\u91cf\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u4f20\u7edf\u7cfb\u7edf\u9700\u8981\u5927\u91cf\u5c04\u9891\u94fe\u3002RIBS\u901a\u8fc7\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u51cf\u5c11\u5c04\u9891\u94fe\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u5176\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u4f7f\u7528SIONNA\u5c04\u7ebf\u8ffd\u8e2a\u6a21\u5757\u548c\u7edf\u8ba13GPP\u4fe1\u9053\u6a21\u578b\u5bf9\u6bd4RIBS\u6027\u80fd\uff0c\u4f18\u5316\u529f\u7387\u548cRIS\u914d\u7f6e\u4ee5\u6700\u5927\u5316\u9891\u8c31\u6548\u7387\u3002", "result": "\u5c04\u7ebf\u8ffd\u8e2a\u9884\u6d4b\u7684\u6027\u80fd\u4f18\u4e8e\u7edf\u8ba1\u6a21\u578b\uff0c\u8868\u660e\u7ad9\u70b9\u7279\u5b9a\u5efa\u6a21\u7684\u6f5c\u529b\u3002", "conclusion": "RIBS\u5728\u51cf\u5c11\u5c04\u9891\u94fe\u7684\u540c\u65f6\u6027\u80fd\u63a5\u8fd1\u4f20\u7edfmMIMO\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u5b9e\u8bc1\u9a8c\u8bc1\u5c04\u7ebf\u8ffd\u8e2a\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.08210", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08210", "abs": "https://arxiv.org/abs/2507.08210", "authors": ["Fryderyk Mantiuk", "Hanqi Zhou", "Charley M. Wu"], "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration", "comment": null, "summary": "What drives an agent to explore the world while also maintaining control over\nthe environment? From a child at play to scientists in the lab, intelligent\nagents must balance curiosity (the drive to seek knowledge) with competence\n(the drive to master and control the environment). Bridging cognitive theories\nof intrinsic motivation with reinforcement learning, we ask how evolving\ninternal representations mediate the trade-off between curiosity (novelty or\ninformation gain) and competence (empowerment). We compare two model-based\nagents using handcrafted state abstractions (Tabular) or learning an internal\nworld model (Dreamer). The Tabular agent shows curiosity and competence guide\nexploration in distinct patterns, while prioritizing both improves exploration.\nThe Dreamer agent reveals a two-way interaction between exploration and\nrepresentation learning, mirroring the developmental co-evolution of curiosity\nand competence. Our findings formalize adaptive exploration as a balance\nbetween pursuing the unknown and the controllable, offering insights for\ncognitive theories and efficient reinforcement learning.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u667a\u80fd\u4f53\u5982\u4f55\u5728\u63a2\u7d22\u4e16\u754c\uff08\u597d\u5947\u5fc3\uff09\u4e0e\u63a7\u5236\u73af\u5883\uff08\u80fd\u529b\uff09\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e24\u79cd\u6a21\u578b\uff08Tabular\u548cDreamer\uff09\uff0c\u63ed\u793a\u4e86\u63a2\u7d22\u4e0e\u8868\u5f81\u5b66\u4e60\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u667a\u80fd\u4f53\u5982\u4f55\u5e73\u8861\u597d\u5947\u5fc3\uff08\u8ffd\u6c42\u77e5\u8bc6\uff09\u4e0e\u80fd\u529b\uff08\u63a7\u5236\u73af\u5883\uff09\uff0c\u4ee5\u7406\u89e3\u63a2\u7d22\u884c\u4e3a\u7684\u9a71\u52a8\u673a\u5236\u3002", "method": "\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\uff1aTabular\uff08\u624b\u5de5\u8bbe\u8ba1\u72b6\u6001\u62bd\u8c61\uff09\u548cDreamer\uff08\u5b66\u4e60\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff09\u3002", "result": "Tabular\u667a\u80fd\u4f53\u663e\u793a\u597d\u5947\u5fc3\u548c\u80fd\u529b\u5f15\u5bfc\u63a2\u7d22\u7684\u4e0d\u540c\u6a21\u5f0f\uff0c\u800cDreamer\u667a\u80fd\u4f53\u63ed\u793a\u4e86\u63a2\u7d22\u4e0e\u8868\u5f81\u5b66\u4e60\u7684\u53cc\u5411\u4e92\u52a8\u3002", "conclusion": "\u7814\u7a76\u5f62\u5f0f\u5316\u4e86\u9002\u5e94\u6027\u63a2\u7d22\u4e3a\u8ffd\u6c42\u672a\u77e5\u4e0e\u53ef\u63a7\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u4e3a\u8ba4\u77e5\u7406\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.08717", "categories": ["cs.NI", "00"], "pdf": "https://arxiv.org/pdf/2507.08717", "abs": "https://arxiv.org/abs/2507.08717", "authors": ["Akshay Jain", "Sylvaine Kerboeuf", "Sokratis Barmpounakis", "Crist\u00f3bal Vinagre Z.", "Stefan Wendt", "Dinh Thai Bui", "Pol Alemany", "Riccardo Nicolicchia", "Jos\u00e9 Mar\u00eda Jorquera Valero", "Dani Korpi", "Mohammad Hossein Moghaddam", "Mikko A. Uusitalo", "Patrik Rugeland", "Abdelkader Outtagarts", "Karthik Upadhya", "Panagiotis Demestichas", "Raul Mu\u00f1oz", "Manuel Gil P\u00e9rez", "Daniel Adanza", "Ricard Vilalta"], "title": "Knowledge Graph-Based approach for Sustainable 6G End-to-End System Design", "comment": "The paper is submitted to IEEE Open Journal of the Communications\n  Society (IEEE OJCOMS)", "summary": "Previous generations of cellular communication, such as 5G, have been\ndesigned with the objective of improving key performance indicators (KPIs) such\nas throughput, latency, etc. However, to meet the evolving KPI demands as well\nas the ambitious sustainability targets for the ICT industry, 6G will need to\nbe designed differently. Concretely, 6G will need to consider both the\nperformance and sustainability targets for the various use cases it will serve.\nMoreover, like previous generations, 6G will have various candidate\ntechnological enablers, making the design space of the system even more\ncomplex. Furthermore, given the subjective nature of the sustainability\nindicators, in particular social sustainability, there is a significant gap in\nliterature on how technical enablers and 6G System design can be linked to\nthem. Hence, in this article a novel method for 6G end-to-end (E2E) system\ndesign based on Knowledge graphs (KG) has been introduced. It considers as its\ninput: the use case KPIs, use case sustainability requirements expressed as Key\nValues (KV) and KV Indicators (KVIs), the ability of the technological enablers\nto satisfy these KPIs and KVIs, the 6G system design principles defined in\nHexa-X-II project, the maturity of a technological enabler and the dependencies\nbetween the various enablers. As part of the KG method, a novel approach for\ndetermining the key values a technological enabler addresses, has also been\nintroduced. The effectiveness of the KG method was demonstrated by its\napplication in designing the 6G E2E system for the cooperating mobile robot use\ncase defined in the Hexa-X-II project, where 82 enablers were selected. Lastly,\nresults from proof-of-concept demonstrations for a subset of the selected\nenablers have also been provided, which reinforce the efficacy of the KG method\nfor designing a sustainable 6G system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u76846G\u7aef\u5230\u7aef\u7cfb\u7edf\u8bbe\u8ba1\u65b0\u65b9\u6cd5\uff0c\u7efc\u5408\u8003\u8651\u6027\u80fd\u6307\u6807\uff08KPI\uff09\u3001\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff08KV/KVI\uff09\u53ca\u6280\u672f\u4f7f\u80fd\u56e0\u7d20\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u7528\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "5G\u7b49\u524d\u4ee3\u901a\u4fe1\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u6027\u80fd\u6307\u6807\uff0c\u800c6G\u9700\u540c\u65f6\u6ee1\u8db3\u6027\u80fd\u548c\u53ef\u6301\u7eed\u6027\u76ee\u6807\uff0c\u5c24\u5176\u662f\u793e\u4f1a\u53ef\u6301\u7eed\u6027\u3002\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u6280\u672f\u4f7f\u80fd\u4e0e\u53ef\u6301\u7eed\u6027\u6307\u6807\u95f4\u7684\u660e\u786e\u8054\u7cfb\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u65b9\u6cd5\uff0c\u6574\u5408\u7528\u4f8bKPI\u3001\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff08KV/KVI\uff09\u3001\u6280\u672f\u4f7f\u80fd\u80fd\u529b\u30016G\u8bbe\u8ba1\u539f\u5219\u3001\u6280\u672f\u6210\u719f\u5ea6\u53ca\u4f7f\u80fd\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u65b0\u65b9\u6cd5\u786e\u5b9a\u6280\u672f\u4f7f\u80fd\u7684\u5173\u952e\u4ef7\u503c\u3002", "result": "\u5728Hexa-X-II\u9879\u76ee\u7684\u534f\u4f5c\u79fb\u52a8\u673a\u5668\u4eba\u7528\u4f8b\u4e2d\uff0c\u6210\u529f\u5e94\u7528KG\u65b9\u6cd5\u7b5b\u9009\u51fa82\u4e2a\u4f7f\u80fd\uff0c\u5e76\u901a\u8fc7\u6982\u5ff5\u9a8c\u8bc1\u6f14\u793a\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "KG\u65b9\u6cd5\u4e3a\u8bbe\u8ba1\u53ef\u6301\u7eed\u76846G\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u6269\u5c55\u5e94\u7528\u3002"}}
{"id": "2507.08696", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08696", "abs": "https://arxiv.org/abs/2507.08696", "authors": ["Li Wan", "Huarui Yin", "Wenyi Zhang"], "title": "Fine-tuning ORBGRAND with Very Few Channel Soft Values", "comment": null, "summary": "Guessing random additive noise decoding (GRAND) is a universal decoding\nparadigm that decodes by repeatedly testing error patterns until identifying a\ncodeword, where the ordering of tests is generated by the received channel\nvalues. On one hand, while testing error patterns in a descending order of\nposterior probabilities leads to maximum likelihood decoding, its\nimplementation complexity is prohibitive. On the other hand, testing error\npatterns with a prescribed set of error patterns permuted by the ranking among\nmagnitudes of log-likelihood ratios (i.e., ordered reliability bits, ORB)\nenables efficient implementation, but results in performance loss for\nfinite-length codes. Aiming at harnessing the strengths of these two\napproaches, this work proposes a fine-tuning method to improve ORBGRAND,\nadjusting the ordering of tests with the aid of very few exact channel soft\nvalues. This method is based on a metric for assessing the ``well-orderedness''\nof error patterns. The metric is studied via the lens of the asymptotic theory\nof integer partitioning, which provides highly accurate estimation in numerical\nexperiments. The metric then leads to an effective identification of\nfine-tuning to conduct, at the cost of a negligible increment of complexity.\nNumerical experiments demonstrate that the proposed fine-tuning method achieves\na substantial performance enhancement compared with ORBGRAND.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdbORBGRAND\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c11\u91cf\u7cbe\u786e\u4fe1\u9053\u8f6f\u503c\u8c03\u6574\u6d4b\u8bd5\u987a\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u7ed3\u5408\u6700\u5927\u4f3c\u7136\u89e3\u7801\u7684\u9ad8\u6027\u80fd\u548cORBGRAND\u7684\u9ad8\u6548\u5b9e\u73b0\uff0c\u89e3\u51b3\u6709\u9650\u957f\u7801\u6027\u80fd\u635f\u5931\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6574\u6570\u5212\u5206\u7406\u8bba\u8bbe\u8ba1\u5ea6\u91cf\u6807\u51c6\uff0c\u8bc4\u4f30\u9519\u8bef\u6a21\u5f0f\u7684\u987a\u5e8f\u6027\uff0c\u5e76\u901a\u8fc7\u5c11\u91cf\u8f6f\u503c\u8c03\u6574\u6d4b\u8bd5\u987a\u5e8f\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86ORBGRAND\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5fae\u8c03\u65b9\u6cd5\u5728\u590d\u6742\u5ea6\u51e0\u4e4e\u4e0d\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u89e3\u7801\u6027\u80fd\u3002"}}
{"id": "2507.08216", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08216", "abs": "https://arxiv.org/abs/2507.08216", "authors": ["Rodrigo Castellano Ontiveros", "Francesco Giannini", "Marco Gori", "Giuseppe Marra", "Michelangelo Diligenti"], "title": "Grounding Methods for Neural-Symbolic AI", "comment": null, "summary": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to\nprocess the input entities, while relying on a reasoner based on First-Order\nLogic to represent and process more complex relationships among the entities. A\nfundamental role for these methods is played by the process of logic grounding,\nwhich determines the relevant substitutions for the logic rules using a\n(sub)set of entities. Some NeSy methods use an exhaustive derivation of all\npossible substitutions, preserving the full expressive power of the logic\nknowledge. This leads to a combinatorial explosion in the number of ground\nformulas to consider and, therefore, strongly limits their scalability. Other\nmethods rely on heuristic-based selective derivations, which are generally more\ncomputationally efficient, but lack a justification and provide no guarantees\nof preserving the information provided to and returned by the reasoner. Taking\ninspiration from multi-hop symbolic reasoning, this paper proposes a\nparametrized family of grounding methods generalizing classic Backward\nChaining. Different selections within this family allow us to obtain commonly\nemployed grounding methods as special cases, and to control the trade-off\nbetween expressiveness and scalability of the reasoner. The experimental\nresults show that the selection of the grounding criterion is often as\nimportant as the NeSy method itself.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u5316\u7684\u903b\u8f91\u63a5\u5730\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e7f\u4e49\u53cd\u5411\u94fe\u63a7\u5236\u8868\u8fbe\u529b\u4e0e\u53ef\u6269\u5c55\u6027\u7684\u6743\u8861\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7ec4\u5408\u7206\u70b8\u6216\u542f\u53d1\u5f0f\u9009\u62e9\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u903b\u8f91\u63a5\u5730\u65f6\u9762\u4e34\u7ec4\u5408\u7206\u70b8\u6216\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u4e14\u53ef\u63a7\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53c2\u6570\u5316\u5bb6\u65cf\u65b9\u6cd5\uff0c\u5e7f\u4e49\u53cd\u5411\u94fe\uff0c\u6db5\u76d6\u5e38\u89c1\u63a5\u5730\u65b9\u6cd5\uff0c\u5e76\u5141\u8bb8\u63a7\u5236\u8868\u8fbe\u529b\u4e0e\u53ef\u6269\u5c55\u6027\u7684\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u63a5\u5730\u51c6\u5219\u7684\u9009\u62e9\u5bf9\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u53c2\u6570\u5316\u63a5\u5730\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u7075\u6d3b\u6027\u4e0e\u53ef\u63a7\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2507.08755", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08755", "abs": "https://arxiv.org/abs/2507.08755", "authors": ["Wei Liu", "Jinquan Luo", "Puyin Wang", "Dengxin Zhai"], "title": "Column Twisted Reed-Solomon Codes as MDS Codes", "comment": null, "summary": "In this paper, we study column twisted Reed-Solomon(TRS) codes. We establish\nsome conditions for column TRS codes to be MDS codes and show that the\ndimension of their Schur square codes is $2k$. Consequently, these TRS codes\nare not equivalent to Reed-Solomon(RS) codes. Moreover, this construction\nmethod provides more flexible parameters compared to previous twisted\ngeneralized Reed-Solomon(TGRS) code constructions. For large odd prime power\n$q$, different from the systematically constructed TGRS codes whose length was\npreviously limited to $\\frac{q+1}{2}$, our construction achieves code lengths\nup to $\\frac{q+3}{2}$. Finally, we present the dual codes of column TRS codes.\nThis paper provides a new approach to construct MDS codes by adding column\nvectors to generator matrix of RS codes.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5217\u626d\u66f2Reed-Solomon\uff08TRS\uff09\u7801\uff0c\u63d0\u51fa\u4e86\u5176\u6210\u4e3aMDS\u7801\u7684\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u5176Schur\u5e73\u65b9\u7801\u7684\u7ef4\u6570\u4e3a2k\uff0c\u8868\u660eTRS\u7801\u4e0eRS\u7801\u4e0d\u7b49\u4ef7\u3002\u6784\u9020\u65b9\u6cd5\u6bd4\u4e4b\u524d\u7684TGRS\u7801\u66f4\u7075\u6d3b\uff0c\u7801\u957f\u53ef\u8fbe(q+3)/2\u3002", "motivation": "\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u6784\u9020MDS\u7801\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5411RS\u7801\u7684\u751f\u6210\u77e9\u9635\u6dfb\u52a0\u5217\u5411\u91cf\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u7801\u53c2\u6570\u3002", "method": "\u7814\u7a76\u4e86\u5217TRS\u7801\u7684\u6027\u8d28\uff0c\u5efa\u7acb\u4e86\u5176\u6210\u4e3aMDS\u7801\u7684\u6761\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u5176Schur\u5e73\u65b9\u7801\u7684\u7ef4\u6570\u3002", "result": "\u8bc1\u660e\u4e86TRS\u7801\u4e0eRS\u7801\u4e0d\u7b49\u4ef7\uff0c\u4e14\u6784\u9020\u7684\u7801\u957f\u53ef\u8fbe(q+3)/2\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684TGRS\u7801\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6784\u9020MDS\u7801\u7684\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u7801\u7684\u53c2\u6570\u8303\u56f4\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.08217", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08217", "abs": "https://arxiv.org/abs/2507.08217", "authors": ["Atit Pokharel", "Ratun Rahman", "Thomas Morris", "Dinh C. Nguyen"], "title": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach", "comment": "This paper was presented at BEAM with CVPR 2025", "summary": "Quantum federated learning (QFL) has been recently introduced to enable a\ndistributed privacy-preserving quantum machine learning (QML) model training\nacross quantum processors (clients). Despite recent research efforts, existing\nQFL frameworks predominantly focus on unimodal systems, limiting their\napplicability to real-world tasks that often naturally involve multiple\nmodalities. To fill this significant gap, we present for the first time a novel\nmultimodal approach specifically tailored for the QFL setting with the\nintermediate fusion using quantum entanglement. Furthermore, to address a major\nbottleneck in multimodal QFL, where the absence of certain modalities during\ntraining can degrade model performance, we introduce a Missing Modality\nAgnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring\nstable training without corrupted states. Simulation results demonstrate that\nthe proposed multimodal QFL method with MMA yields an improvement in accuracy\nof 6.84% in independent and identically distributed (IID) and 7.25% in non-IID\ndata distributions compared to the state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50\u7ea0\u7f20\u5b9e\u73b0\u4e2d\u95f4\u878d\u5408\uff0c\u5e76\u5f15\u5165\u7f3a\u5931\u6a21\u6001\u65e0\u5173\u673a\u5236\uff08MMA\uff09\u4ee5\u63d0\u5347\u6a21\u578b\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u663e\u793a\u5728IID\u548c\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\uff0c\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u4e866.84%\u548c7.25%\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\uff08QFL\uff09\u6846\u67b6\u591a\u4e3a\u5355\u6a21\u6001\uff0c\u96be\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u591a\u6a21\u6001\u9700\u6c42\uff0c\u4e14\u6a21\u6001\u7f3a\u5931\u4f1a\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001QFL\u6846\u67b6\uff0c\u5229\u7528\u91cf\u5b50\u7ea0\u7f20\u5b9e\u73b0\u4e2d\u95f4\u878d\u5408\uff0c\u5e76\u63d0\u51faMMA\u673a\u5236\u9694\u79bb\u672a\u8bad\u7ec3\u7684\u91cf\u5b50\u7535\u8def\u3002", "result": "\u5728IID\u548c\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\uff0c\u51c6\u786e\u7387\u5206\u522b\u63d0\u5347\u4e866.84%\u548c7.25%\u3002", "conclusion": "\u591a\u6a21\u6001QFL\u7ed3\u5408MMA\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u6a21\u6001\u7f3a\u5931\u95ee\u9898\u3002"}}
{"id": "2507.08249", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08249", "abs": "https://arxiv.org/abs/2507.08249", "authors": ["Bill Marino", "Ari Juels"], "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm", "comment": null, "summary": "There is growing interest in giving AI agents access to cryptocurrencies as\nwell as to the smart contracts that transact them. But doing so, this position\npaper argues, could lead to formidable new vectors of AI harm. To support this\nargument, we first examine the unique properties of cryptocurrencies and smart\ncontracts that could lead to these new vectors of harm. Next, we describe each\nof these new vectors of harm in detail. Finally, we conclude with a call for\nmore technical research aimed at preventing and mitigating these harms and,\nthereby making it safer to endow AI agents with cryptocurrencies and smart\ncontracts.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8d4b\u4e88AI\u4ee3\u7406\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u8bbf\u95ee\u6743\u9650\u53ef\u80fd\u5e26\u6765\u7684\u65b0\u5371\u5bb3\uff0c\u5e76\u547c\u5401\u66f4\u591a\u6280\u672f\u7814\u7a76\u4ee5\u9884\u9632\u548c\u51cf\u8f7b\u8fd9\u4e9b\u5371\u5bb3\u3002", "motivation": "\u968f\u7740\u5bf9AI\u4ee3\u7406\u4f7f\u7528\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u7684\u5174\u8da3\u589e\u52a0\uff0c\u7814\u7a76\u5176\u6f5c\u5728\u5371\u5bb3\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5206\u6790\u4e86\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u7684\u72ec\u7279\u5c5e\u6027\uff0c\u8be6\u7ec6\u63cf\u8ff0\u4e86\u53ef\u80fd\u7684\u65b0\u5371\u5bb3\u5411\u91cf\u3002", "result": "\u8bc6\u522b\u4e86\u65b0\u7684AI\u5371\u5bb3\u5411\u91cf\uff0c\u5f3a\u8c03\u4e86\u6f5c\u5728\u98ce\u9669\u3002", "conclusion": "\u547c\u5401\u66f4\u591a\u6280\u672f\u7814\u7a76\u4ee5\u786e\u4fddAI\u4ee3\u7406\u5b89\u5168\u4f7f\u7528\u52a0\u5bc6\u8d27\u5e01\u548c\u667a\u80fd\u5408\u7ea6\u3002"}}
{"id": "2507.08264", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08264", "abs": "https://arxiv.org/abs/2507.08264", "authors": ["Abhinav Sood", "Kazjon Grace", "Stephen Wan", "Cecile Paris"], "title": "Abductive Computational Systems: Creative Abduction and Future Directions", "comment": "Published in the 16th International Conference on Computational\n  Creativity, ICCC25. Accepted Paper in\n  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025abductive.pdf", "summary": "Abductive reasoning, reasoning for inferring explanations for observations,\nis often mentioned in scientific, design-related and artistic contexts, but its\nunderstanding varies across these domains. This paper reviews how abductive\nreasoning is discussed in epistemology, science and design, and then analyses\nhow various computational systems use abductive reasoning. Our analysis shows\nthat neither theoretical accounts nor computational implementations of\nabductive reasoning adequately address generating creative hypotheses.\nTheoretical frameworks do not provide a straightforward model for generating\ncreative abductive hypotheses, computational systems largely implement\nsyllogistic forms of abductive reasoning. We break down abductive computational\nsystems into components and conclude by identifying specific directions for\nfuture research that could advance the state of creative abductive reasoning in\ncomputational systems.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u6eaf\u56e0\u63a8\u7406\u5728\u8ba4\u8bc6\u8bba\u3001\u79d1\u5b66\u548c\u8bbe\u8ba1\u4e2d\u7684\u8ba8\u8bba\uff0c\u5206\u6790\u4e86\u8ba1\u7b97\u7cfb\u7edf\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u7406\u8bba\u548c\u8ba1\u7b97\u5b9e\u73b0\u5747\u672a\u5145\u5206\u652f\u6301\u521b\u9020\u6027\u5047\u8bbe\u751f\u6210\u3002", "motivation": "\u63a2\u8ba8\u6eaf\u56e0\u63a8\u7406\u5728\u4e0d\u540c\u9886\u57df\u7684\u7406\u89e3\u5dee\u5f02\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u5b9e\u73b0\u60c5\u51b5\u3002", "method": "\u7efc\u8ff0\u7406\u8bba\u6587\u732e\u5e76\u5206\u6790\u8ba1\u7b97\u7cfb\u7edf\u7684\u6eaf\u56e0\u63a8\u7406\u5b9e\u73b0\u3002", "result": "\u7406\u8bba\u548c\u8ba1\u7b97\u7cfb\u7edf\u5747\u672a\u80fd\u6709\u6548\u652f\u6301\u521b\u9020\u6027\u6eaf\u56e0\u5047\u8bbe\u7684\u751f\u6210\u3002", "conclusion": "\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u4ee5\u6539\u8fdb\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u7684\u521b\u9020\u6027\u6eaf\u56e0\u63a8\u7406\u3002"}}
{"id": "2507.08270", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.08270", "abs": "https://arxiv.org/abs/2507.08270", "authors": ["Zeyang Sha", "Hanling Tian", "Zhuoer Xu", "Shiwen Cui", "Changhua Meng", "Weiqiang Wang"], "title": "Agent Safety Alignment via Reinforcement Learning", "comment": null, "summary": "The emergence of autonomous Large Language Model (LLM) agents capable of tool\nusage has introduced new safety risks that go beyond traditional conversational\nmisuse. These agents, empowered to execute external functions, are vulnerable\nto both user-initiated threats (e.g., adversarial prompts) and tool-initiated\nthreats (e.g., malicious outputs from compromised tools). In this paper, we\npropose the first unified safety-alignment framework for tool-using agents,\nenabling models to handle both channels of threat via structured reasoning and\nsandboxed reinforcement learning. We introduce a tri-modal taxonomy, including\nbenign, malicious, and sensitive for both user prompts and tool responses, and\ndefine a policy-driven decision model. Our framework employs a custom-designed\nsandbox environment that simulates real-world tool execution and allows\nfine-grained reward shaping. Through extensive evaluations on public and\nself-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we\ndemonstrate that our safety-aligned agents significantly improve resistance to\nsecurity threats while preserving strong utility on benign tasks. Our results\nshow that safety and effectiveness can be jointly optimized, laying the\ngroundwork for trustworthy deployment of autonomous LLM agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5b89\u5168\u5bf9\u9f50\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u4f7f\u7528\u5de5\u5177\u7684LLM\u4ee3\u7406\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5305\u62ec\u7528\u6237\u548c\u5de5\u5177\u7aef\u7684\u5a01\u80c1\u3002", "motivation": "\u81ea\u4e3bLLM\u4ee3\u7406\u7684\u5de5\u5177\u4f7f\u7528\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4f20\u7edf\u5bf9\u8bdd\u6ee5\u7528\u4e4b\u5916\uff0c\u8fd8\u5b58\u5728\u7528\u6237\u548c\u5de5\u5177\u7aef\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u6a21\u6001\u5206\u7c7b\u6cd5\uff08\u826f\u6027\u3001\u6076\u610f\u3001\u654f\u611f\uff09\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u548c\u6c99\u76d2\u5f3a\u5316\u5b66\u4e60\uff0c\u8bbe\u8ba1\u4e86\u7b56\u7565\u9a71\u52a8\u7684\u51b3\u7b56\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b89\u5168\u5bf9\u9f50\u7684\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u5b89\u5168\u5a01\u80c1\u7684\u62b5\u6297\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u6027\u4efb\u52a1\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u5b89\u5168\u4e0e\u6709\u6548\u6027\u53ef\u4ee5\u5171\u540c\u4f18\u5316\uff0c\u4e3a\u81ea\u4e3bLLM\u4ee3\u7406\u7684\u53ef\u4fe1\u90e8\u7f72\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.08306", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08306", "abs": "https://arxiv.org/abs/2507.08306", "authors": ["Inclusion AI", ":", "Fudong Wang", "Jiajia Liu", "Jingdong Chen", "Jun Zhou", "Kaixiang Ji", "Lixiang Ru", "Qingpei Guo", "Ruobing Zheng", "Tianqi Li", "Yi Yuan", "Yifan Mao", "Yuting Xiao", "Ziping Ma"], "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "comment": "31pages, 14 figures", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs), particularly\nthrough Reinforcement Learning with Verifiable Rewards (RLVR), have\nsignificantly enhanced their reasoning abilities. However, a critical gap\npersists: these models struggle with dynamic spatial interactions, a capability\nessential for real-world applications. To bridge this gap, we introduce\nM2-Reasoning-7B, a model designed to excel in both general and spatial\nreasoning. Our approach integrates two key innovations: (1) a novel data\npipeline that generates 294.2K high-quality data samples (168K for cold-start\nfine-tuning and 126.2K for RLVR), which feature logically coherent reasoning\ntrajectories and have undergone comprehensive assessment; and (2) a dynamic\nmulti-task training strategy with step-wise optimization to mitigate conflicts\nbetween data, and task-specific rewards for delivering tailored incentive\nsignals. This combination of curated data and advanced training allows\nM2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks,\nshowcasing superior performance in both general and spatial reasoning domains.", "AI": {"tldr": "M2-Reasoning-7B\u6a21\u578b\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u548c\u52a8\u6001\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u7a7a\u95f4\u4ea4\u4e92\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0SOTA\u3002", "motivation": "\u73b0\u6709MLLMs\u5728\u52a8\u6001\u7a7a\u95f4\u4ea4\u4e92\u80fd\u529b\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faM2-Reasoning-7B\uff0c\u7ed3\u5408\u9ad8\u8d28\u91cf\u6570\u636e\u751f\u6210\uff08294.2K\u6837\u672c\uff09\u548c\u52a8\u6001\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff08\u4efb\u52a1\u7279\u5b9a\u5956\u52b1\uff09\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0SOTA\uff0c\u5c24\u5176\u5728\u901a\u7528\u548c\u7a7a\u95f4\u63a8\u7406\u9886\u57df\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "M2-Reasoning-7B\u901a\u8fc7\u6570\u636e\u4e0e\u8bad\u7ec3\u7b56\u7565\u7684\u521b\u65b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u52a8\u6001\u7a7a\u95f4\u4ea4\u4e92\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2507.08392", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.08392", "abs": "https://arxiv.org/abs/2507.08392", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "title": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems", "comment": null, "summary": "Incorporating ethics into the requirement elicitation process is essential\nfor creating ethically aligned systems. Although eliciting manual ethics\nrequirements is effective, it requires diverse input from multiple\nstakeholders, which can be challenging due to time and resource constraints.\nMoreover, it is often given a low priority in the requirements elicitation\nprocess. This study proposes a framework for generating ethics requirements\ndrafts by introducing an ethics advocate agent in a multi-agent LLM setting.\nThis agent critiques and provides input on ethical issues based on the system\ndescription. The proposed framework is evaluated through two case studies from\ndifferent contexts, demonstrating that it captures the majority of ethics\nrequirements identified by researchers during 30-minute interviews and\nintroduces several additional relevant requirements. However, it also\nhighlights reliability issues in generating ethics requirements, emphasizing\nthe need for human feedback in this sensitive domain. We believe this work can\nfacilitate the broader adoption of ethics in the requirements engineering\nprocess, ultimately leading to more ethically aligned products.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u591a\u667a\u80fd\u4f53LLM\u73af\u5883\u4e2d\u5f15\u5165\u4f26\u7406\u5021\u5bfc\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u4f26\u7406\u9700\u6c42\u8349\u7a3f\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u540c\u65f6\u6307\u51fa\u9700\u8981\u4eba\u5de5\u53cd\u9988\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u7531\u4e8e\u65f6\u95f4\u548c\u8d44\u6e90\u9650\u5236\uff0c\u624b\u52a8\u83b7\u53d6\u4f26\u7406\u9700\u6c42\u5177\u6709\u6311\u6218\u6027\u4e14\u4f18\u5148\u7ea7\u8f83\u4f4e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u4fc3\u8fdb\u4f26\u7406\u9700\u6c42\u7684\u751f\u6210\u3002", "method": "\u5728\u591a\u667a\u80fd\u4f53LLM\u73af\u5883\u4e2d\u5f15\u5165\u4f26\u7406\u5021\u5bfc\u4ee3\u7406\uff0c\u6839\u636e\u7cfb\u7edf\u63cf\u8ff0\u63d0\u4f9b\u4f26\u7406\u95ee\u9898\u7684\u6279\u8bc4\u548c\u8f93\u5165\uff0c\u751f\u6210\u4f26\u7406\u9700\u6c42\u8349\u7a3f\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6355\u6349\u5927\u90e8\u5206\u7814\u7a76\u4eba\u5458\u572830\u5206\u949f\u8bbf\u8c08\u4e2d\u8bc6\u522b\u7684\u4f26\u7406\u9700\u6c42\uff0c\u5e76\u5f15\u5165\u989d\u5916\u76f8\u5173\u9700\u6c42\uff0c\u4f46\u4e5f\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u66f4\u5e7f\u6cdb\u5730\u91c7\u7528\u4f26\u7406\u8003\u91cf\uff0c\u4f46\u9700\u7ed3\u5408\u4eba\u5de5\u53cd\u9988\u4ee5\u786e\u4fdd\u53ef\u9760\u6027\u3002"}}
{"id": "2507.08454", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 03B05", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2507.08454", "abs": "https://arxiv.org/abs/2507.08454", "authors": ["Tobias Geibinger", "Reijo Jaakkola", "Antti Kuusisto", "Xinghan Liu", "Miikka Vilander"], "title": "Why this and not that? A Logic-based Framework for Contrastive Explanations", "comment": "20 pages, accepted to JELIA 2025", "summary": "We define several canonical problems related to contrastive explanations,\neach answering a question of the form ''Why P but not Q?''. The problems\ncompute causes for both P and Q, explicitly comparing their differences. We\ninvestigate the basic properties of our definitions in the setting of\npropositional logic. We show, inter alia, that our framework captures a\ncardinality-minimal version of existing contrastive explanations in the\nliterature. Furthermore, we provide an extensive analysis of the computational\ncomplexities of the problems. We also implement the problems for CNF-formulas\nusing answer set programming and present several examples demonstrating how\nthey work in practice.", "AI": {"tldr": "\u8bba\u6587\u5b9a\u4e49\u4e86\u4e0e\u5bf9\u6bd4\u89e3\u91ca\u76f8\u5173\u7684\u51e0\u4e2a\u5178\u578b\u95ee\u9898\uff0c\u7814\u7a76\u5176\u57fa\u672c\u6027\u8d28\u3001\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u5c55\u793a\u5176\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u5bf9\u6bd4\u89e3\u91ca\u95ee\u9898\uff08\u5982\u201c\u4e3a\u4ec0\u4e48\u662fP\u800c\u4e0d\u662fQ\uff1f\u201d\uff09\uff0c\u660e\u786e\u6bd4\u8f83P\u548cQ\u7684\u5dee\u5f02\u3002", "method": "\u5728\u547d\u9898\u903b\u8f91\u4e2d\u5b9a\u4e49\u95ee\u9898\uff0c\u5206\u6790\u5176\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5e76\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\u5b9e\u73b0CNF\u516c\u5f0f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6846\u67b6\u6355\u6349\u4e86\u6587\u732e\u4e2d\u5bf9\u6bd4\u89e3\u91ca\u7684\u57fa\u6570\u6700\u5c0f\u7248\u672c\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u7684\u8be6\u7ec6\u5206\u6790\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u6bd4\u89e3\u91ca\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2507.08501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08501", "abs": "https://arxiv.org/abs/2507.08501", "authors": ["Keying Yang", "Hao Wang", "Kai Yang"], "title": "From Language to Logic: A Bi-Level Framework for Structured Reasoning", "comment": null, "summary": "Structured reasoning over natural language inputs remains a core challenge in\nartificial intelligence, as it requires bridging the gap between unstructured\nlinguistic expressions and formal logical representations. In this paper, we\npropose a novel \\textbf{bi-level framework} that maps language to logic through\na two-stage process: high-level task abstraction and low-level logic\ngeneration. At the upper level, a large language model (LLM) parses natural\nlanguage queries into intermediate structured representations specifying the\nproblem type, objectives, decision variables, and symbolic constraints. At the\nlower level, the LLM uses these representations to generate symbolic workflows\nor executable reasoning programs for accurate and interpretable decision\nmaking. The framework supports modular reasoning, enforces explicit\nconstraints, and generalizes across domains such as mathematical problem\nsolving, question answering, and logical inference. We further optimize the\nframework with an end-to-end {bi-level} optimization approach that jointly\nrefines both the high-level abstraction and low-level logic generation stages.\nExperiments on multiple realistic reasoning benchmarks demonstrate that our\napproach significantly outperforms existing baselines in accuracy, with\naccuracy gains reaching as high as 40\\%. Moreover, the bi-level design enhances\ntransparency and error traceability, offering a promising step toward\ntrustworthy and systematic reasoning with LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u62bd\u8c61\u548c\u903b\u8f91\u751f\u6210\u4e24\u9636\u6bb5\u5c06\u81ea\u7136\u8bed\u8a00\u6620\u5c04\u5230\u903b\u8f91\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u5230\u5f62\u5f0f\u903b\u8f91\u8868\u793a\u7684\u8f6c\u6362\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u6846\u67b6\uff1a\u9ad8\u5c42\u4efb\u52a1\u62bd\u8c61\u548c\u4f4e\u5c42\u903b\u8f91\u751f\u6210\uff0c\u7ed3\u5408\u7aef\u5230\u7aef\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe40%\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\u548c\u9519\u8bef\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u7684\u53ef\u4fe1\u548c\u7cfb\u7edf\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2507.08529", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.08529", "abs": "https://arxiv.org/abs/2507.08529", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qin", "Guoyu Ye", "Ruixiang Tang"], "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "comment": "10 pages,3 figures", "summary": "Despite advances from medical large language models in healthcare,\nrare-disease diagnosis remains hampered by insufficient\nknowledge-representation depth, limited concept understanding, and constrained\nclinical reasoning. We propose a framework that couples multi-granularity\nsparse activation of medical concepts with a hierarchical knowledge graph. Four\ncomplementary matching algorithms, diversity control, and a five-level fallback\nstrategy enable precise concept activation, while a three-layer knowledge graph\n(taxonomy, clinical features, instances) provides structured, up-to-date\ncontext. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,\nROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89\napproaching the 0.90 clinical threshold. Expert evaluation confirms\nimprovements in information quality, reasoning, and professional expression,\nsuggesting our approach shortens the \"diagnostic odyssey\" for rare-disease\npatients.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u548c\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u7f55\u89c1\u75c5\u8bca\u65ad\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63d0\u5347\uff0c\u63a5\u8fd1\u4e34\u5e8a\u9608\u503c\u3002", "motivation": "\u7f55\u89c1\u75c5\u8bca\u65ad\u56e0\u77e5\u8bc6\u8868\u793a\u4e0d\u8db3\u3001\u6982\u5ff5\u7406\u89e3\u6709\u9650\u548c\u4e34\u5e8a\u63a8\u7406\u53d7\u9650\u800c\u53d7\u963b\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u591a\u7c92\u5ea6\u7a00\u758f\u6fc0\u6d3b\u3001\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31\uff08\u5206\u7c7b\u3001\u4e34\u5e8a\u7279\u5f81\u3001\u5b9e\u4f8b\uff09\u3001\u56db\u79cd\u5339\u914d\u7b97\u6cd5\u3001\u591a\u6837\u6027\u63a7\u5236\u548c\u4e94\u7ea7\u56de\u9000\u7b56\u7565\u3002", "result": "\u5728BioASQ\u7f55\u89c1\u75c5QA\u96c6\u4e0a\uff0cBLEU\u63d0\u53470.09\uff0cROUGE\u63d0\u53470.05\uff0c\u51c6\u786e\u7387\u63d0\u53470.12\uff0c\u5cf0\u503c\u51c6\u786e\u73870.89\u63a5\u8fd1\u4e34\u5e8a\u9608\u503c0.90\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4fe1\u606f\u8d28\u91cf\u3001\u63a8\u7406\u80fd\u529b\u548c\u4e13\u4e1a\u8868\u8fbe\uff0c\u6709\u671b\u7f29\u77ed\u7f55\u89c1\u75c5\u60a3\u8005\u7684\u8bca\u65ad\u65f6\u95f4\u3002"}}
{"id": "2507.08575", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.08575", "abs": "https://arxiv.org/abs/2507.08575", "authors": ["Kalana Wijegunarathna", "Kristin Stock", "Christopher B. Jones"], "title": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing", "comment": null, "summary": "Millions of biological sample records collected in the last few centuries\narchived in natural history collections are un-georeferenced. Georeferencing\ncomplex locality descriptions associated with these collection samples is a\nhighly labour-intensive task collection agencies struggle with. None of the\nexisting automated methods exploit maps that are an essential tool for\ngeoreferencing complex relations. We present preliminary experiments and\nresults of a novel method that exploits multi-modal capabilities of recent\nLarge Multi-Modal Models (LMM). This method enables the model to visually\ncontextualize spatial relations it reads in the locality description. We use a\ngrid-based approach to adapt these auto-regressive models for this task in a\nzero-shot setting. Our experiments conducted on a small manually annotated\ndataset show impressive results for our approach ($\\sim$1 km Average distance\nerror) compared to uni-modal georeferencing with Large Language Models and\nexisting georeferencing tools. The paper also discusses the findings of the\nexperiments in light of an LMM's ability to comprehend fine-grained maps.\nMotivated by these results, a practical framework is proposed to integrate this\nmethod into a georeferencing workflow.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08LMM\uff09\u81ea\u52a8\u5730\u7406\u53c2\u8003\u751f\u7269\u6837\u672c\u8bb0\u5f55\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c6\u89c9\u4e0a\u4e0b\u6587\u7406\u89e3\u7a7a\u95f4\u5173\u7cfb\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u4f18\u4e8e\u5355\u6a21\u6001\u65b9\u6cd5\u548c\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u5386\u53f2\u6536\u85cf\u4e2d\u5927\u91cf\u672a\u5730\u7406\u53c2\u8003\u7684\u751f\u7269\u6837\u672c\u8bb0\u5f55\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u52b3\u52a8\u5bc6\u96c6\u4e14\u6548\u7387\u4f4e\u3002", "method": "\u91c7\u7528\u7f51\u683c\u5316\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08LMM\uff09\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5730\u7406\u53c2\u8003\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5e73\u5747\u8ddd\u79bb\u8bef\u5dee\u7ea6\u4e3a1\u516c\u91cc\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u548c\u73b0\u6709\u5de5\u5177\u3002", "conclusion": "\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u7406\u89e3\u7cbe\u7ec6\u5730\u56fe\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u5c06\u5176\u6574\u5408\u5230\u5730\u7406\u53c2\u8003\u5de5\u4f5c\u6d41\u7a0b\u7684\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2507.08603", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.08603", "abs": "https://arxiv.org/abs/2507.08603", "authors": ["Yonghua Hei", "Yibo Yan", "Shuliang Liu", "Huiyu Zhou", "Linfeng Zhang", "Xuming Hu"], "title": "Unlocking Speech Instruction Data Potential with Query Rewriting", "comment": "ACL 2025 Findings", "summary": "End-to-end Large Speech Language Models~(\\textbf{LSLMs}) demonstrate strong\npotential in response latency and speech comprehension capabilities, showcasing\ngeneral intelligence across speech understanding tasks. However, the ability to\nfollow speech instructions has not been fully realized due to the lack of\ndatasets and heavily biased training tasks. Leveraging the rich ASR datasets,\nprevious approaches have used Large Language Models~(\\textbf{LLMs}) to continue\nthe linguistic information of speech to construct speech instruction datasets.\nYet, due to the gap between LLM-generated results and real human responses, the\ncontinuation methods further amplify these shortcomings. Given the high costs\nof collecting and annotating speech instruction datasets by humans, using\nspeech synthesis to construct large-scale speech instruction datasets has\nbecome a balanced and robust alternative. Although modern\nText-To-Speech~(\\textbf{TTS}) models have achieved near-human-level synthesis\nquality, it is challenging to appropriately convert out-of-distribution text\ninstruction to speech due to the limitations of the training data distribution\nin TTS models. To address this issue, we propose a query rewriting framework\nwith multi-LLM knowledge fusion, employing multiple agents to annotate and\nvalidate the synthesized speech, making it possible to construct high-quality\nspeech instruction datasets without relying on human annotation. Experiments\nshow that this method can transform text instructions into distributions more\nsuitable for TTS models for speech synthesis through zero-shot rewriting,\nincreasing data usability from 72\\% to 93\\%. It also demonstrates unique\nadvantages in rewriting tasks that require complex knowledge and\ncontext-related abilities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591aLLM\u77e5\u8bc6\u878d\u5408\u7684\u67e5\u8be2\u91cd\u5199\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86TTS\u6a21\u578b\u5728\u5206\u5e03\u5916\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\u7684\u7f3a\u4e4f\u548c\u8bad\u7ec3\u4efb\u52a1\u7684\u504f\u5dee\u9650\u5236\u4e86\u5927\u578b\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08LSLMs\uff09\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u800c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5408\u6210\u8bed\u97f3\u6210\u4e3a\u66ff\u4ee3\u65b9\u6848\u3002\u4f46TTS\u6a21\u578b\u5728\u5206\u5e03\u5916\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e2d\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u591aLLM\u77e5\u8bc6\u878d\u5408\u7684\u67e5\u8be2\u91cd\u5199\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6807\u6ce8\u548c\u9a8c\u8bc1\u5408\u6210\u8bed\u97f3\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u6784\u5efa\u9ad8\u8d28\u91cf\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u96f6\u6837\u672c\u91cd\u5199\u5c06\u6570\u636e\u53ef\u7528\u6027\u4ece72%\u63d0\u5347\u81f393%\uff0c\u5e76\u5728\u590d\u6742\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u9ad8\u8d28\u91cf\u8bed\u97f3\u6307\u4ee4\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86TTS\u6a21\u578b\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2507.08619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08619", "abs": "https://arxiv.org/abs/2507.08619", "authors": ["Soheyl Massoudi", "Mark Fuge"], "title": "Agentic Large Language Models for Conceptual Systems Engineering and Design", "comment": "32 pages, 3 figures", "summary": "Early-stage engineering design involves complex, iterative reasoning, yet\nexisting large language model (LLM) workflows struggle to maintain task\ncontinuity and generate executable models. We evaluate whether a structured\nmulti-agent system (MAS) can more effectively manage requirements extraction,\nfunctional decomposition, and simulator code generation than a simpler\ntwo-agent system (2AS). The target application is a solar-powered water\nfiltration system as described in a cahier des charges. We introduce the\nDesign-State Graph (DSG), a JSON-serializable representation that bundles\nrequirements, physical embodiments, and Python-based physics models into graph\nnodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS\ncollapses the process to a Generator-Reflector loop. Both systems run a total\nof 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1\n70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON\nvalidity, requirement coverage, embodiment presence, code compatibility,\nworkflow completion, runtime, and graph size. Across all runs, both MAS and 2AS\nmaintained perfect JSON integrity and embodiment tagging. Requirement coverage\nremained minimal (less than 20\\%). Code compatibility peaked at 100\\% under\nspecific 2AS settings but averaged below 50\\% for MAS. Only the\nreasoning-distilled model reliably flagged workflow completion. Powered by\nDeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes)\nwhereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced\ndesign detail. Reasoning-distilled LLM improved completion rates, yet low\nrequirements and fidelity gaps in coding persisted.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u65e9\u671f\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u4e86\u5176\u4e0e\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\uff082AS\uff09\u5728\u9700\u6c42\u63d0\u53d6\u3001\u529f\u80fd\u5206\u89e3\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u6548\u679c\u3002\u7ed3\u679c\u663e\u793aMAS\u5728\u751f\u6210\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bbe\u8ba1\u72b6\u6001\u56fe\uff08DSG\uff09\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u9700\u6c42\u8986\u76d6\u7387\u548c\u4ee3\u7801\u517c\u5bb9\u6027\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u65e9\u671f\u5de5\u7a0b\u8bbe\u8ba1\u6d89\u53ca\u590d\u6742\u7684\u8fed\u4ee3\u63a8\u7406\uff0c\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5de5\u4f5c\u6d41\u96be\u4ee5\u4fdd\u6301\u4efb\u52a1\u8fde\u7eed\u6027\u548c\u751f\u6210\u53ef\u6267\u884c\u6a21\u578b\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u7ed3\u6784\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u662f\u5426\u80fd\u66f4\u6709\u6548\u5730\u7ba1\u7406\u8bbe\u8ba1\u6d41\u7a0b\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u72b6\u6001\u56fe\uff08DSG\uff09\u8868\u793a\u9700\u6c42\u3001\u7269\u7406\u5b9e\u73b0\u548cPython\u7269\u7406\u6a21\u578b\uff0c\u6bd4\u8f83\u4e5d\u89d2\u8272MAS\u4e0e\u53cc\u89d2\u82722AS\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u4f7f\u7528\u4e24\u79cdLLM\uff08Llama 3.3 70B\u548cDeepSeek R1 70B\uff09\uff0c\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\u8fd0\u884c60\u6b21\u5b9e\u9a8c\u3002", "result": "MAS\u5728\u751f\u6210\u7ec6\u7c92\u5ea6DSG\u65b9\u9762\u4f18\u4e8e2AS\uff0c\u4f46\u9700\u6c42\u8986\u76d6\u7387\u4f4e\uff08<20%\uff09\u3002\u4ee3\u7801\u517c\u5bb9\u6027\u5728\u7279\u5b9a2AS\u8bbe\u7f6e\u4e0b\u8fbe\u5230100%\uff0c\u4f46MAS\u5e73\u5747\u4f4e\u4e8e50%\u3002DeepSeek R1 70B\u80fd\u53ef\u9760\u6807\u8bb0\u5de5\u4f5c\u6d41\u5b8c\u6210\u3002", "conclusion": "\u7ed3\u6784\u5316\u591a\u667a\u80fd\u4f53\u7f16\u6392\u63d0\u5347\u4e86\u8bbe\u8ba1\u7ec6\u8282\uff0c\u63a8\u7406\u84b8\u998f\u7684LLM\u63d0\u9ad8\u4e86\u5b8c\u6210\u7387\uff0c\u4f46\u9700\u6c42\u8986\u76d6\u548c\u4ee3\u7801\u4fdd\u771f\u5ea6\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2507.08649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08649", "abs": "https://arxiv.org/abs/2507.08649", "authors": ["Xingguang Ji", "Yahui Liu", "Qi Wang", "Jingyuan Zhang", "Yang Yue", "Rui Shi", "Chenxi Sun", "Fuzheng Zhang", "Guorui Zhou", "Kun Gai"], "title": "Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning", "comment": "23 pages, 13 figures", "summary": "We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that\ncan produce formal theorem proofs in Lean 4, with verifier-integrated Long\nChain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we\ncontinual to choose to posttrain existing strong prover models for further\nperformance improvement. In our V2 version, we mainly upgrade the Reinforcement\nLearning (RL) with feedback provided by the Lean 4 verifier. Crucially,\nverifier feedback, such as indicating success or detailing specific errors,\nallows the LLM to become ``self-aware'' of the correctness of its own reasoning\nprocess and learn to reflexively correct errors. Leanabell-Prover-V2 directly\noptimizes LLM reasoning trajectories with multi-turn verifier interactions,\ntogether with feedback token masking for stable RL training and a simple reward\nstrategy. Experiments show that Leanabell-Prover-V2 improves performance by\n3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with\nDeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data\nand models are available at:\nhttps://github.com/Leanabell-LM/Leanabell-Prover-V2.", "AI": {"tldr": "Leanabell-Prover-V2\u662f\u4e00\u4e2a7B\u53c2\u6570\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u5728Lean 4\u4e2d\u751f\u6210\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5668\u96c6\u6210\u7684\u957f\u94fe\u601d\u7ef4\uff08CoT\uff09\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u5728Leanabell-Prover-V1\u7684\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u901a\u8fc7\u9a8c\u8bc1\u5668\u53cd\u9988\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7ed3\u5408Lean 4\u9a8c\u8bc1\u5668\u53cd\u9988\uff0c\u5305\u62ec\u9519\u8bef\u6307\u793a\u548c\u6210\u529f\u786e\u8ba4\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u6211\u4fee\u6b63\u63a8\u7406\u9519\u8bef\u3002\u540c\u65f6\u4f7f\u7528\u53cd\u9988\u4ee4\u724c\u63a9\u7801\u548c\u7b80\u5355\u5956\u52b1\u7b56\u7565\u3002", "result": "\u5728MiniF2F\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e863.2%\uff08Kimina-Prover-Preview-Distill-7B\uff09\u548c2.0%\uff08DeepSeek-Prover-V2-7B\uff09\u3002", "conclusion": "Leanabell-Prover-V2\u901a\u8fc7\u9a8c\u8bc1\u5668\u53cd\u9988\u548c\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u7684\u6027\u80fd\u3002"}}
{"id": "2507.08664", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.08664", "abs": "https://arxiv.org/abs/2507.08664", "authors": ["Haoran Sun", "Shaoning Zeng"], "title": "Introspection of Thought Helps AI Agents", "comment": null, "summary": "AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to\nperform interpretation and inference in text and image tasks without\npost-training, where LLMs and MLLMs play the most critical role and determine\nthe initial ability and limitations of AI Agents. Usually, AI Agents utilize\nsophisticated prompt engineering and external reasoning framework to obtain a\npromising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought\nand Image-of-Thought. However, they are still constrained by the inherent\nlimitations of LLM in understanding natural language, and the iterative\nreasoning process will generate a large amount of inference cost. To this end,\nwe propose a novel AI Agent Reasoning Framework with Introspection of Thought\n(INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute\nprogrammatic dialogue reasoning processes following the code in prompt.\nTherefore, self-denial and reflection occur within LLM instead of outside LLM,\nwhich can reduce token cost effectively. Through our experiments on six\nbenchmarks for three different tasks, the effectiveness of INoT is verified,\nwith an average improvement of 7.95\\% in performance, exceeding the baselines.\nFurthermore, the token cost of INoT is lower on average than the best\nperforming method at baseline by 58.3\\%. In addition, we demonstrate the\nversatility of INoT in image interpretation and inference through verification\nexperiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aINoT\u7684\u65b0\u578bAI\u4ee3\u7406\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1LLM\u53ef\u8bfb\u7684\u63d0\u793a\u4ee3\u7801\uff0c\u51cf\u5c11\u63a8\u7406\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u4f9d\u8d56LLMs\u548cMLLMs\uff0c\u4f46\u5176\u63a8\u7406\u8fc7\u7a0b\u6210\u672c\u9ad8\u4e14\u53d7\u9650\u4e8e\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1LLM-Read\u4ee3\u7801\u63d0\u793a\uff0c\u4f7fLLM\u5728\u5185\u90e8\u6267\u884c\u7a0b\u5e8f\u5316\u5bf9\u8bdd\u63a8\u7406\uff0c\u51cf\u5c11\u5916\u90e8\u8fed\u4ee3\u6210\u672c\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u5e73\u5747\u63d0\u53477.95%\uff0c\u63a8\u7406\u6210\u672c\u964d\u4f4e58.3%\u3002", "conclusion": "INoT\u6846\u67b6\u5728\u6027\u80fd\u548c\u6210\u672c\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u56fe\u50cf\u4efb\u52a1\u4e2d\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2507.08705", "categories": ["cs.AI", "I.2.5; I.2.1; I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2507.08705", "abs": "https://arxiv.org/abs/2507.08705", "authors": ["Philip Osborne", "Danilo S. Carvalho", "Andr\u00e9 Freitas"], "title": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings", "comment": "6 pages, 1 figure, 3 tables, 11 Appendix pages, submitted to EMNLP\n  2025 Call for System Demonstrations", "summary": "We present elsciRL, an open-source Python library to facilitate the\napplication of language solutions on reinforcement learning problems. We\ndemonstrate the potential of our software by extending the Language Adapter\nwith Self-Completing Instruction framework defined in (Osborne, 2024) with the\nuse of LLMs. Our approach can be re-applied to new applications with minimal\nsetup requirements. We provide a novel GUI that allows a user to provide text\ninput for an LLM to generate instructions which it can then self-complete.\nEmpirical results indicate that these instructions \\textit{can} improve a\nreinforcement learning agent's performance. Therefore, we present this work to\naccelerate the evaluation of language solutions on reward based environments to\nenable new opportunities for scientific discovery.", "AI": {"tldr": "elsciRL\u662f\u4e00\u4e2a\u5f00\u6e90Python\u5e93\uff0c\u7528\u4e8e\u5728\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e2d\u5e94\u7528\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u7ed3\u5408LLMs\u6269\u5c55\u4e86\u73b0\u6709\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u6613\u4e8e\u4f7f\u7528\u7684GUI\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u6307\u4ee4\u53ef\u4ee5\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6027\u80fd\u3002", "motivation": "\u52a0\u901f\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u5728\u5956\u52b1\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\uff0c\u4e3a\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u65b0\u673a\u4f1a\u3002", "method": "\u6269\u5c55\u4e86Language Adapter with Self-Completing Instruction\u6846\u67b6\uff0c\u7ed3\u5408LLMs\u751f\u6210\u6307\u4ee4\uff0c\u5e76\u63d0\u4f9bGUI\u652f\u6301\u7528\u6237\u8f93\u5165\u6587\u672c\u3002", "result": "\u751f\u6210\u7684\u6307\u4ee4\u80fd\u591f\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6027\u80fd\u3002", "conclusion": "elsciRL\u4e3a\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4fbf\u6377\u5de5\u5177\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
