{"id": "2512.05249", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2512.05249", "abs": "https://arxiv.org/abs/2512.05249", "authors": ["Ankit Gupta", "Onur Dizdar", "Yun Chen", "Fehmi Emre Kadan", "Ata Sattarzadeh", "Stephen Wang"], "title": "Low-Complexity OFDM Deep Neural Receivers", "comment": null, "summary": "Deep neural receivers (NeuralRxs) for Orthogonal Frequency Division Multiplexing (OFDM) signals are proposed for enhanced decoding performance compared to their signal-processing based counterparts. However, the existing architectures ignore the required number of epochs for training convergence and floating-point operations (FLOPs), which increase significantly with improving performance. To tackle these challenges, we propose a new residual network (ResNet) block design for OFDM NeuralRx. Specifically, we leverage small kernel sizes and dilation rates to lower the number of FLOPs (NFLOPs) and uniform channel sizes to reduce the memory access cost (MAC). The ResNet block is designed with novel channel split and shuffle blocks, element-wise additions are removed, with Gaussian error linear unit (GELU) activations. Extensive simulations show that our proposed NeuralRx reduces NFLOPs and improves training convergence while improving the decoding accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8eOFDM\u4fe1\u53f7\u7684\u65b0\u578b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63a5\u6536\u5668\uff08NeuralRx\uff09\uff0c\u901a\u8fc7\u6539\u8fdb\u7684ResNet\u5757\u8bbe\u8ba1\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u63d0\u9ad8\u89e3\u7801\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684OFDM\u795e\u7ecf\u7f51\u7edc\u63a5\u6536\u5668\u67b6\u6784\u5ffd\u7565\u4e86\u8bad\u7ec3\u6536\u655b\u6240\u9700\u7684epoch\u6570\u548c\u6d6e\u70b9\u8fd0\u7b97\u91cf\uff08FLOPs\uff09\uff0c\u8fd9\u4e9b\u6307\u6807\u4f1a\u968f\u7740\u6027\u80fd\u63d0\u5347\u800c\u663e\u8457\u589e\u52a0\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u65b0\u7684ResNet\u5757\uff0c\u91c7\u7528\u5c0f\u6838\u5c3a\u5bf8\u548c\u6269\u5f20\u7387\u6765\u964d\u4f4eFLOPs\uff0c\u4f7f\u7528\u7edf\u4e00\u901a\u9053\u5927\u5c0f\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u6210\u672c\uff0c\u5f15\u5165\u901a\u9053\u5206\u5272\u548c\u6df7\u6d17\u5757\uff0c\u79fb\u9664\u9010\u5143\u7d20\u52a0\u6cd5\uff0c\u4f7f\u7528GELU\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u63d0\u51fa\u7684NeuralRx\u51cf\u5c11\u4e86FLOPs\u6570\u91cf\uff0c\u6539\u5584\u4e86\u8bad\u7ec3\u6536\u655b\u901f\u5ea6\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u89e3\u7801\u51c6\u786e\u7387\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u7684ResNet\u5757\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3001\u8bad\u7ec3\u66f4\u5feb\u4e14\u6027\u80fd\u66f4\u597d\u7684OFDM\u795e\u7ecf\u7f51\u7edc\u63a5\u6536\u5668\u3002"}}
{"id": "2512.05267", "categories": ["cs.IT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05267", "abs": "https://arxiv.org/abs/2512.05267", "authors": ["Osvaldo Simeone", "Yaniv Romano"], "title": "Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective", "comment": null, "summary": "In context-specific applications such as robotics, telecommunications, and healthcare, artificial intelligence systems often face the challenge of limited training data. This scarcity introduces epistemic uncertainty, i.e., reducible uncertainty stemming from incomplete knowledge of the underlying data distribution, which fundamentally limits predictive performance. This review paper examines formal methodologies that address data-limited regimes through two complementary approaches: quantifying epistemic uncertainty and mitigating data scarcity via synthetic data augmentation. We begin by reviewing generalized Bayesian learning frameworks that characterize epistemic uncertainty through generalized posteriors in the model parameter space, as well as ``post-Bayes'' learning frameworks. We continue by presenting information-theoretic generalization bounds that formalize the relationship between training data quantity and predictive uncertainty, providing a theoretical justification for generalized Bayesian learning. Moving beyond methods with asymptotic statistical validity, we survey uncertainty quantification methods that provide finite-sample statistical guarantees, including conformal prediction and conformal risk control. Finally, we examine recent advances in data efficiency by combining limited labeled data with abundant model predictions or synthetic data. Throughout, we take an information-theoretic perspective, highlighting the role of information measures in quantifying the impact of data scarcity.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5f3a\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u5206\u6790\u6570\u636e\u7a00\u7f3a\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u3001\u7535\u4fe1\u3001\u533b\u7597\u7b49\u7279\u5b9a\u5e94\u7528\u573a\u666f\u4e2d\uff0cAI\u7cfb\u7edf\u5e38\u9762\u4e34\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u8fd9\u5bfc\u81f4\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff08\u53ef\u51cf\u5c11\u7684\u4e0d\u786e\u5b9a\u6027\uff09\uff0c\u4ece\u800c\u9650\u5236\u4e86\u9884\u6d4b\u6027\u80fd\u3002\u9700\u8981\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u5e7f\u4e49\u8d1d\u53f6\u65af\u5b66\u4e60\u6846\u67b6\u548c\"\u540e\u8d1d\u53f6\u65af\"\u5b66\u4e60\u6846\u67b6\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff1b2) \u901a\u8fc7\u4fe1\u606f\u8bba\u6cdb\u5316\u754c\u9650\u7406\u8bba\u5206\u6790\u6570\u636e\u91cf\u4e0e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u5173\u7cfb\uff1b3) \u4f7f\u7528\u7b26\u5408\u9884\u6d4b\u548c\u7b26\u5408\u98ce\u9669\u63a7\u5236\u7b49\u65b9\u6cd5\u63d0\u4f9b\u6709\u9650\u6837\u672c\u7edf\u8ba1\u4fdd\u8bc1\uff1b4) \u7ed3\u5408\u6709\u9650\u6807\u6ce8\u6570\u636e\u548c\u4e30\u5bcc\u6a21\u578b\u9884\u6d4b\u6216\u5408\u6210\u6570\u636e\u63d0\u9ad8\u6570\u636e\u6548\u7387\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86\u5728\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u7684\u591a\u79cd\u65b9\u6cd5\uff1a\u4ece\u7406\u8bba\u4e0a\u7684\u5e7f\u4e49\u8d1d\u53f6\u65af\u6846\u67b6\u548c\u4fe1\u606f\u8bba\u754c\u9650\uff0c\u5230\u5177\u6709\u6709\u9650\u6837\u672c\u4fdd\u8bc1\u7684\u5b9e\u7528\u65b9\u6cd5\uff08\u5982\u7b26\u5408\u9884\u6d4b\uff09\uff0c\u518d\u5230\u7ed3\u5408\u5408\u6210\u6570\u636e\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u4e3a\u5e94\u5bf9\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u4fe1\u606f\u8bba\u89c6\u89d2\uff0c\u672c\u6587\u5f3a\u8c03\u4e86\u4fe1\u606f\u5ea6\u91cf\u5728\u91cf\u5316\u6570\u636e\u7a00\u7f3a\u5f71\u54cd\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u5728\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u5f00\u53d1\u66f4\u9c81\u68d2\u3001\u66f4\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u53ef\u9760\u6027\u7684\u5e94\u7528\u9886\u57df\u3002"}}
{"id": "2512.05316", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.05316", "abs": "https://arxiv.org/abs/2512.05316", "authors": ["El Mahdi Mouloua", "Essaid Mohamed"], "title": "Foundations of information theory for coding theory", "comment": null, "summary": "Information theory is introduced in this lecture note with a particular emphasis on its relevance to algebraic coding theory. The document develops the mathematical foundations for quantifying uncertainty and information transmission by building upon Shannon's pioneering formulation of information, entropy, and channel capacity. Examples, including the binary symmetric channel, illustrate key concepts such as entropy, conditional entropy, mutual information, and the noisy channel model. Furthermore, the note describes the principles of maximum likelihood decoding and Shannon's noisy channel coding theorem, which characterizes the theoretical limits of reliable communication over noisy channels. Students and researchers seeking a connection between probabilistic frameworks of information theory and structural and algebraic techniques used in modern coding theory will find this work helpful.", "AI": {"tldr": "\u8fd9\u7bc7\u8bb2\u4e49\u4ecb\u7ecd\u4e86\u4fe1\u606f\u8bba\u53ca\u5176\u4e0e\u4ee3\u6570\u7f16\u7801\u7406\u8bba\u7684\u8054\u7cfb\uff0c\u91cd\u70b9\u9610\u8ff0\u4e86\u9999\u519c\u4fe1\u606f\u8bba\u7684\u57fa\u672c\u6982\u5ff5\u548c\u566a\u58f0\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\u3002", "motivation": "\u5efa\u7acb\u4fe1\u606f\u8bba\u4e0e\u4ee3\u6570\u7f16\u7801\u7406\u8bba\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u5b66\u751f\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6982\u7387\u6846\u67b6\u4e0e\u4ee3\u6570\u6280\u672f\u4e4b\u95f4\u7684\u6865\u6881\u3002", "method": "\u57fa\u4e8e\u9999\u519c\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u4ece\u6570\u5b66\u57fa\u7840\u51fa\u53d1\uff0c\u901a\u8fc7\u4e8c\u8fdb\u5236\u5bf9\u79f0\u4fe1\u9053\u7b49\u5177\u4f53\u4f8b\u5b50\uff0c\u7cfb\u7edf\u9610\u8ff0\u71b5\u3001\u6761\u4ef6\u71b5\u3001\u4e92\u4fe1\u606f\u3001\u4fe1\u9053\u5bb9\u91cf\u7b49\u6838\u5fc3\u6982\u5ff5\u3002", "result": "\u6e05\u6670\u9610\u8ff0\u4e86\u4fe1\u606f\u8bba\u7684\u57fa\u672c\u6570\u5b66\u57fa\u7840\uff0c\u5305\u62ec\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u4fe1\u606f\u4f20\u8f93\u6a21\u578b\uff0c\u4ee5\u53ca\u6700\u5927\u4f3c\u7136\u89e3\u7801\u539f\u7406\u548c\u9999\u519c\u566a\u58f0\u4fe1\u9053\u7f16\u7801\u5b9a\u7406\u3002", "conclusion": "\u8be5\u8bb2\u4e49\u4e3a\u7406\u89e3\u4fe1\u606f\u8bba\u4e0e\u4ee3\u6570\u7f16\u7801\u7406\u8bba\u7684\u8054\u7cfb\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6559\u5b66\u8d44\u6e90\uff0c\u7279\u522b\u9002\u5408\u5e0c\u671b\u5c06\u6982\u7387\u6846\u67b6\u4e0e\u4ee3\u6570\u6280\u672f\u7ed3\u5408\u7684\u7814\u7a76\u8005\u3002"}}
{"id": "2512.05156", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.LG", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.05156", "abs": "https://arxiv.org/abs/2512.05156", "authors": ["Igor Halperin"], "title": "Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations", "comment": "23 pages, 6 figures", "summary": "Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\\bf Q}$ and ${\\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u548c\u70ed\u529b\u5b66\u7684\u65e0\u76d1\u7763\u6307\u6807\uff08SF\u548cSEP\uff09\u6765\u8bc4\u4f30LLM\u7684\u4efb\u52a1\u5fe0\u5b9e\u5ea6\uff0c\u5c06LLM\u89c6\u4e3a\u4e8c\u5206\u4fe1\u606f\u5f15\u64ce\uff0c\u901a\u8fc7\u4e3b\u9898\u8f6c\u6362\u77e9\u9635\u7684KL\u6563\u5ea6\u91cf\u5316\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u7ed9\u5b9a\u4efb\u52a1\u7684\u5fe0\u5b9e\u5ea6\u662f\u4e00\u4e2a\u590d\u6742\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u65b9\u6cd5\u6765\u91cf\u5316\u6a21\u578b\u8f93\u51fa\u4e0e\u4efb\u52a1\u8981\u6c42\u7684\u5339\u914d\u7a0b\u5ea6\u3002", "method": "\u5c06LLM\u89c6\u4e3a\u4e8c\u5206\u4fe1\u606f\u5f15\u64ce\uff0c\u9690\u85cf\u5c42\u4f5c\u4e3a\u9ea6\u514b\u65af\u97e6\u5996\u63a7\u5236\u4e0a\u4e0b\u6587\u5230\u7b54\u6848\u7684\u8f6c\u6362\u3002\u5c06QCA\u4e09\u5143\u7ec4\u5efa\u6a21\u4e3a\u5171\u4eab\u4e3b\u9898\u7684\u6982\u7387\u5206\u5e03\uff0c\u901a\u8fc7\u4e3b\u9898\u8f6c\u6362\u77e9\u9635Q\u548cA\u5206\u522b\u7f16\u7801\u67e5\u8be2\u76ee\u6807\u548c\u5b9e\u9645\u7ed3\u679c\u3002SF\u6307\u6807\u901a\u8fc7\u8fd9\u4e24\u4e2a\u77e9\u9635\u7684KL\u6563\u5ea6\u91cf\u5316\u5fe0\u5b9e\u5ea6\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u540c\u65f6\u63a8\u65ad\u4e24\u4e2a\u77e9\u9635\u3002SEP\u6307\u6807\u57fa\u4e8e\u70ed\u529b\u5b66\u6982\u5ff5\u8ba1\u7b97\u7b54\u6848\u751f\u6210\u4e2d\u7684\u8bed\u4e49\u71b5\u4ea7\u751f\u3002", "result": "\u63d0\u51fa\u7684SF\u548cSEP\u6307\u6807\u80fd\u591f\u6709\u6548\u8bc4\u4f30LLM\u5fe0\u5b9e\u5ea6\uff0c\u9ad8\u5fe0\u5b9e\u5ea6\u901a\u5e38\u5bf9\u5e94\u4f4e\u71b5\u4ea7\u751f\u3002\u5728SEC 10-K\u6587\u4ef6\u6458\u8981\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "SF\u548cSEP\u6307\u6807\u4e3aLLM\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u548c\u5e7b\u89c9\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u53ef\u5355\u72ec\u6216\u8054\u5408\u4f7f\u7528\uff0c\u57fa\u4e8e\u4fe1\u606f\u8bba\u548c\u70ed\u529b\u5b66\u539f\u7406\u4e3aLLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2512.05201", "categories": ["cs.NI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.05201", "abs": "https://arxiv.org/abs/2512.05201", "authors": ["Ali Al Housseini", "Jaime Llorca", "Luca Turchet", "Tiziano Leidi", "Cristina Rottondi", "Omran Ayoub"], "title": "MuMeNet: A Network Simulator for Musical Metaverse Communications", "comment": "To be published in 2025 IEEE 6th International Symposium on the Internet of Sounds (IS2)", "summary": "The Metaverse, a shared and spatially organized digital continuum, is transforming various industries, with music emerging as a leading use case. Live concerts, collaborative composition, and interactive experiences are driving the Musical Metaverse (MM), but the requirements of the underlying network and service infrastructures hinder its growth. These challenges underscore the need for a novel modeling and simulation paradigm tailored to the unique characteristics of MM sessions, along with specialized service provisioning strategies capable of capturing their interactive, heterogeneous, and multicast-oriented nature. To this end, we make a first attempt to formally model and analyze the problem of service provisioning for MM sessions in 5G/6G networks. We first formalize service and network graph models for the MM, using \"live audience interaction in a virtual concert\" as a reference scenario. We then present MuMeNet, a novel discrete-event network simulator specifically tailored to the requirements and the traffic dynamics of the MM. We showcase the effectiveness of MuMeNet by running a linear programming based orchestration policy on the reference scenario and providing performance analysis under realistic MM workloads.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u97f3\u4e50\u5143\u5b87\u5b99\u7684\u7f51\u7edc\u670d\u52a1\u4f9b\u7ed9\u95ee\u9898\uff0c\u63d0\u51fa\u4e86MuMeNet\u4eff\u771f\u5668\uff0c\u7528\u4e8e\u6a21\u62df\u548c\u5206\u67905G/6G\u7f51\u7edc\u4e2d\u97f3\u4e50\u5143\u5b87\u5b99\u4f1a\u8bdd\u7684\u670d\u52a1\u4f9b\u7ed9\u7b56\u7565\u3002", "motivation": "\u97f3\u4e50\u5143\u5b87\u5b99\u4f5c\u4e3a\u5143\u5b87\u5b99\u7684\u91cd\u8981\u5e94\u7528\u573a\u666f\uff0c\u5176\u589e\u957f\u53d7\u5230\u5e95\u5c42\u7f51\u7edc\u548c\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u8981\u6c42\u7684\u9650\u5236\u3002\u73b0\u6709\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u6355\u6349\u97f3\u4e50\u5143\u5b87\u5b99\u4f1a\u8bdd\u7684\u4ea4\u4e92\u6027\u3001\u5f02\u6784\u6027\u548c\u7ec4\u64ad\u5bfc\u5411\u7279\u6027\uff0c\u9700\u8981\u4e13\u95e8\u7684\u670d\u52a1\u4f9b\u7ed9\u7b56\u7565\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u97f3\u4e50\u5143\u5b87\u5b99\u7684\u670d\u52a1\u548c\u7f51\u7edc\u56fe\u6a21\u578b\uff0c\u4ee5\u865a\u62df\u97f3\u4e50\u4f1a\u4e2d\u7684\u5b9e\u65f6\u89c2\u4f17\u4e92\u52a8\u4e3a\u53c2\u8003\u573a\u666f\u3002\u7136\u540e\u5f00\u53d1\u4e86MuMeNet\u2014\u2014\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u97f3\u4e50\u5143\u5b87\u5b99\u9700\u6c42\u548c\u6d41\u91cf\u52a8\u6001\u7684\u79bb\u6563\u4e8b\u4ef6\u7f51\u7edc\u4eff\u771f\u5668\u3002\u6700\u540e\u901a\u8fc7\u7ebf\u6027\u89c4\u5212\u7f16\u6392\u7b56\u7565\u5728\u53c2\u8003\u573a\u666f\u4e0a\u5c55\u793a\u5176\u6709\u6548\u6027\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86MuMeNet\u4eff\u771f\u5668\uff0c\u80fd\u591f\u5728\u73b0\u5b9e\u7684\u97f3\u4e50\u5143\u5b87\u5b99\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8fdb\u884c\u6027\u80fd\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u7f16\u6392\u7b56\u7565\u5728\u97f3\u4e50\u5143\u5b87\u5b99\u670d\u52a1\u4f9b\u7ed9\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u97f3\u4e50\u5143\u5b87\u5b99\u7684\u670d\u52a1\u4f9b\u7ed9\u95ee\u9898\u63d0\u4f9b\u4e86\u9996\u4e2a\u5f62\u5f0f\u5316\u5efa\u6a21\u548c\u5206\u6790\u6846\u67b6\uff0cMuMeNet\u4eff\u771f\u5668\u80fd\u591f\u5e2e\u52a9\u8bbe\u8ba1\u548c\u4f18\u53165G/6G\u7f51\u7edc\u4e2d\u97f3\u4e50\u5143\u5b87\u5b99\u4f1a\u8bdd\u7684\u670d\u52a1\u4f9b\u7ed9\u7b56\u7565\u3002"}}
{"id": "2512.05122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05122", "abs": "https://arxiv.org/abs/2512.05122", "authors": ["Unnikrishnan Radhakrishnan"], "title": "Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN", "comment": "Presented at 2025 International Workshop on Low-Cost Digital Solutions for Industrial Automation (LODISA)", "summary": "Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures such knowledge on the shop floor and converts it incrementally and interactively into standards-compliant Business Process Model and Notation (BPMN) 2.0 diagrams. Powered by Gemini 2.5 Pro and delivered through a lightweight Gradio front-end with client-side bpmn-js visualisation, the assistant conducts an interview-style dialogue: it elicits process details, supports clarifying dialogue and on-demand analysis, and renders live diagrams that users can refine in real time. A proof-of-concept evaluation in an equipment-maintenance scenario shows that the chatbot produced an accurate \"AS-IS\" model, flagged issues via on-diagram annotations, and generated an improved \"TO-BE\" variant, all within about 12-minutes, while keeping API costs within an SME-friendly budget. The study analyses latency sources, model-selection trade-offs, and the challenges of enforcing strict XML schemas, then outlines a roadmap toward agentic and multimodal deployments. The results demonstrate that conversational LLMs can potentially be used to lower the skill and cost barriers to rigorous process documentation, helping SMEs preserve institutional knowledge, enhance operational transparency, and accelerate continuous-improvement efforts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u52a9\u624b\uff0c\u5e2e\u52a9\u4e2d\u5c0f\u4f01\u4e1a\u5c06\u9690\u6027\u7ecf\u9a8c\u77e5\u8bc6\u8f6c\u5316\u4e3a\u6807\u51c6BPMN 2.0\u6d41\u7a0b\u56fe\uff0c\u964d\u4f4e\u6d41\u7a0b\u6587\u6863\u5316\u7684\u6280\u80fd\u548c\u6210\u672c\u95e8\u69db\u3002", "motivation": "\u4e2d\u5c0f\u4f01\u4e1a\u4f9d\u8d56\u9690\u6027\u7ecf\u9a8c\u77e5\u8bc6\uff0c\u4f46\u8fd9\u4e9b\u77e5\u8bc6\u5f88\u5c11\u88ab\u6b63\u5f0f\u8bb0\u5f55\u3002\u4f20\u7edf\u6d41\u7a0b\u5efa\u6a21\u9700\u8981\u4e13\u4e1a\u6280\u80fd\uff0c\u5bf9\u4e2d\u5c0f\u4f01\u4e1a\u6765\u8bf4\u6210\u672c\u9ad8\u3001\u95e8\u69db\u5927\uff0c\u5bfc\u81f4\u673a\u6784\u77e5\u8bc6\u6d41\u5931\u548c\u8fd0\u8425\u900f\u660e\u5ea6\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528Gemini 2.5 Pro\u9a71\u52a8\u7684\u5bf9\u8bdd\u52a9\u624b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7Gradio\u524d\u7aef\u548c\u5ba2\u6237\u7aefbpmn-js\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u8fdb\u884c\u8bbf\u8c08\u5f0f\u5bf9\u8bdd\uff1a\u5f15\u5bfc\u6d41\u7a0b\u7ec6\u8282\u3001\u652f\u6301\u6f84\u6e05\u5bf9\u8bdd\u548c\u6309\u9700\u5206\u6790\uff0c\u5b9e\u65f6\u6e32\u67d3\u548c\u4f18\u5316\u6d41\u7a0b\u56fe\u3002", "result": "\u5728\u8bbe\u5907\u7ef4\u62a4\u573a\u666f\u7684\u6982\u5ff5\u9a8c\u8bc1\u4e2d\uff0c\u804a\u5929\u673a\u5668\u4eba\u5728\u7ea612\u5206\u949f\u5185\u751f\u6210\u4e86\u51c6\u786e\u7684\"\u73b0\u72b6\"\u6a21\u578b\uff0c\u901a\u8fc7\u56fe\u4e0a\u6807\u6ce8\u6807\u8bb0\u95ee\u9898\uff0c\u5e76\u751f\u6210\u4e86\u6539\u8fdb\u7684\"\u672a\u6765\"\u53d8\u4f53\uff0c\u540c\u65f6\u5c06API\u6210\u672c\u63a7\u5236\u5728\u4e2d\u5c0f\u4f01\u4e1a\u53cb\u597d\u9884\u7b97\u5185\u3002", "conclusion": "\u5bf9\u8bdd\u5f0fLLM\u80fd\u591f\u964d\u4f4e\u4e25\u683c\u6d41\u7a0b\u6587\u6863\u5316\u7684\u6280\u80fd\u548c\u6210\u672c\u969c\u788d\uff0c\u5e2e\u52a9\u4e2d\u5c0f\u4f01\u4e1a\u4fdd\u5b58\u673a\u6784\u77e5\u8bc6\u3001\u589e\u5f3a\u8fd0\u8425\u900f\u660e\u5ea6\u5e76\u52a0\u901f\u6301\u7eed\u6539\u8fdb\u5de5\u4f5c\uff0c\u672a\u6765\u53ef\u5411\u4ee3\u7406\u548c\u591a\u6a21\u6001\u90e8\u7f72\u53d1\u5c55\u3002"}}
{"id": "2512.05207", "categories": ["cs.NI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.05207", "abs": "https://arxiv.org/abs/2512.05207", "authors": ["Ali Al Housseini", "Cristina Rottondi", "Omran Ayoub"], "title": "Hierarchical Reinforcement Learning for the Dynamic VNE with Alternatives Problem", "comment": "Submitted to IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN) 2026", "summary": "Virtual Network Embedding (VNE) is a key enabler of network slicing, yet most formulations assume that each Virtual Network Request (VNR) has a fixed topology. Recently, VNE with Alternative topologies (VNEAP) was introduced to capture malleable VNRs, where each request can be instantiated using one of several functionally equivalent topologies that trade resources differently. While this flexibility enlarges the feasible space, it also introduces an additional decision layer, making dynamic embedding more challenging. This paper proposes HRL-VNEAP, a hierarchical reinforcement learning approach for VNEAP under dynamic arrivals. A high-level policy selects the most suitable alternative topology (or rejects the request), and a low-level policy embeds the chosen topology onto the substrate network. Experiments on realistic substrate topologies under multiple traffic loads show that naive exploitation strategies provide only modest gains, whereas HRL-VNEAP consistently achieves the best performance across all metrics. Compared to the strongest tested baselines, HRL-VNEAP improves acceptance ratio by up to \\textbf{20.7\\%}, total revenue by up to \\textbf{36.2\\%}, and revenue-over-cost by up to \\textbf{22.1\\%}. Finally, we benchmark against an MILP formulation on tractable instances to quantify the remaining gap to optimality and motivate future work on learning- and optimization-based VNEAP solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHRL-VNEAP\uff0c\u4e00\u79cd\u7528\u4e8e\u52a8\u6001\u5230\u8fbe\u7684\u865a\u62df\u7f51\u7edc\u5d4c\u5165\u66ff\u4ee3\u62d3\u6251\u7684\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u5c42\u7b56\u7565\u9009\u62e9\u62d3\u6251\u3001\u4f4e\u5c42\u7b56\u7565\u8fdb\u884c\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a5\u53d7\u7387\u3001\u603b\u6536\u76ca\u548c\u6536\u76ca\u6210\u672c\u6bd4\u3002", "motivation": "\u4f20\u7edf\u865a\u62df\u7f51\u7edc\u5d4c\u5165\u5047\u8bbe\u6bcf\u4e2a\u865a\u62df\u7f51\u7edc\u8bf7\u6c42\u5177\u6709\u56fa\u5b9a\u62d3\u6251\uff0c\u800c\u5b9e\u9645\u4e2d\u53ef\u80fd\u5b58\u5728\u591a\u79cd\u529f\u80fd\u7b49\u6548\u4f46\u8d44\u6e90\u9700\u6c42\u4e0d\u540c\u7684\u66ff\u4ee3\u62d3\u6251\u3002\u867d\u7136\u8fd9\u79cd\u7075\u6d3b\u6027\u6269\u5927\u4e86\u53ef\u884c\u7a7a\u95f4\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u52a8\u6001\u5d4c\u5165\u7684\u51b3\u7b56\u590d\u6742\u5ea6\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6HRL-VNEAP\uff1a\u9ad8\u5c42\u7b56\u7565\u8d1f\u8d23\u9009\u62e9\u6700\u5408\u9002\u7684\u66ff\u4ee3\u62d3\u6251\uff08\u6216\u62d2\u7edd\u8bf7\u6c42\uff09\uff0c\u4f4e\u5c42\u7b56\u7565\u8d1f\u8d23\u5c06\u9009\u5b9a\u62d3\u6251\u5d4c\u5165\u5230\u5e95\u5c42\u7269\u7406\u7f51\u7edc\u4e2d\u3002\u8be5\u65b9\u6cd5\u4e13\u95e8\u9488\u5bf9\u52a8\u6001\u5230\u8fbe\u7684\u865a\u62df\u7f51\u7edc\u8bf7\u6c42\u573a\u666f\u8bbe\u8ba1\u3002", "result": "\u5728\u771f\u5b9e\u5e95\u5c42\u62d3\u6251\u548c\u591a\u79cd\u6d41\u91cf\u8d1f\u8f7d\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHRL-VNEAP\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u8868\u73b0\u6700\u4f73\uff1a\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\uff0c\u63a5\u53d7\u7387\u63d0\u5347\u9ad8\u8fbe20.7%\uff0c\u603b\u6536\u76ca\u63d0\u5347\u9ad8\u8fbe36.2%\uff0c\u6536\u76ca\u6210\u672c\u6bd4\u63d0\u5347\u9ad8\u8fbe22.1%\u3002", "conclusion": "HRL-VNEAP\u80fd\u6709\u6548\u5904\u7406\u5177\u6709\u66ff\u4ee3\u62d3\u6251\u7684\u865a\u62df\u7f51\u7edc\u5d4c\u5165\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u901a\u8fc7\u4e0eMILP\u516c\u5f0f\u5728\u53ef\u5904\u7406\u5b9e\u4f8b\u4e0a\u7684\u5bf9\u6bd4\uff0c\u91cf\u5316\u4e86\u4e0e\u6700\u4f18\u89e3\u7684\u5dee\u8ddd\uff0c\u4e3a\u672a\u6765\u57fa\u4e8e\u5b66\u4e60\u548c\u4f18\u5316\u7684VNEAP\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2512.05744", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.05744", "abs": "https://arxiv.org/abs/2512.05744", "authors": ["Nuria Molner", "Luis Rosa", "Fulvio Risso", "Konstantinos Samdanis", "David Artu\u00f1edo", "Rob Smets", "Tarik Taleb", "David Gomez-Barquero"], "title": "AIORA: An AI-Native Multi-Stakeholder Orchestration Architecture for 6G Continuum", "comment": "IEEE Network 2025", "summary": "This paper elaborates on a novel AI-native architecture for emerging 6G systems harnessing open APIs, along with supporting mechanisms to empower intelligent and coordinated orchestration of edge-cloud continuum resources. The AIORA architecture facilitates a seamless creation, life-cycle management, and exposure of services in multi-segment heterogeneous environments. It integrates new breeds of tools and advanced technologies to enable zero-touch management of an edge-cloud continuum, building on top of the 3GPP Edge Enablement Layer and the respective connectivity models, allowing to cater to the high flexibility, availability, efficiency, reliability, and resilience needs of the future 6G services and applications. Several ongoing industry initiatives -- such as ETSI MEC for edge computing platforms, the GSMA Operator Platform for multi-operator service federation, and CAMARA for cross-operator API standardization -- demonstrate the growing momentum towards integrated frameworks where edge, cloud, and network resources can be seamlessly orchestrated. Our proposed AIORA architecture not only aligns with these initiatives but also extends them by leveraging a multi-segment virtual continuum concept and nested AI-driven closed loops for real-time optimization.", "AI": {"tldr": "AIORA\u67b6\u6784\uff1a\u9762\u54116G\u7cfb\u7edf\u7684AI\u539f\u751f\u67b6\u6784\uff0c\u901a\u8fc7\u5f00\u653eAPI\u548c\u667a\u80fd\u7f16\u6392\u5b9e\u73b0\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u7684\u96f6\u63a5\u89e6\u7ba1\u7406", "motivation": "6G\u7cfb\u7edf\u9700\u8981\u9ad8\u7075\u6d3b\u6027\u3001\u53ef\u7528\u6027\u3001\u6548\u7387\u3001\u53ef\u9760\u6027\u548c\u5f39\u6027\u7684\u670d\u52a1\u4e0e\u5e94\u7528\uff0c\u73b0\u6709\u8fb9\u7f18\u8ba1\u7b97\u5e73\u53f0\u3001\u8fd0\u8425\u5546\u5e73\u53f0\u548cAPI\u6807\u51c6\u5316\u7b49\u4ea7\u4e1a\u5021\u8bae\u9700\u8981\u66f4\u96c6\u6210\u7684\u6846\u67b6\u6765\u65e0\u7f1d\u7f16\u6392\u8fb9\u7f18\u3001\u4e91\u548c\u7f51\u7edc\u8d44\u6e90", "method": "\u63d0\u51faAIORA\u67b6\u6784\uff0c\u57fa\u4e8e3GPP\u8fb9\u7f18\u4f7f\u80fd\u5c42\u548c\u8fde\u63a5\u6a21\u578b\uff0c\u91c7\u7528\u591a\u6bb5\u865a\u62df\u8fde\u7eed\u4f53\u6982\u5ff5\u548c\u5d4c\u5957AI\u9a71\u52a8\u95ed\u73af\uff0c\u96c6\u6210\u65b0\u5de5\u5177\u548c\u5148\u8fdb\u6280\u672f\u5b9e\u73b0\u96f6\u63a5\u89e6\u7ba1\u7406", "result": "AIORA\u67b6\u6784\u4e0d\u4ec5\u4e0eETSI MEC\u3001GSMA\u8fd0\u8425\u5546\u5e73\u53f0\u3001CAMARA\u7b49\u4ea7\u4e1a\u5021\u8bae\u4fdd\u6301\u4e00\u81f4\uff0c\u8fd8\u901a\u8fc7\u591a\u6bb5\u865a\u62df\u8fde\u7eed\u4f53\u548c\u5b9e\u65f6\u4f18\u5316\u7684AI\u9a71\u52a8\u95ed\u73af\u6269\u5c55\u4e86\u8fd9\u4e9b\u5021\u8bae", "conclusion": "AIORA\u67b6\u6784\u4e3a6G\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684AI\u539f\u751f\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u672a\u67656G\u670d\u52a1\u548c\u5e94\u7528\u5bf9\u8d44\u6e90\u7f16\u6392\u7684\u590d\u6742\u9700\u6c42\uff0c\u4ee3\u8868\u4e86\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u7ba1\u7406\u7684\u53d1\u5c55\u65b9\u5411"}}
{"id": "2512.05167", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05167", "abs": "https://arxiv.org/abs/2512.05167", "authors": ["Fang Li"], "title": "Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education", "comment": "Accepted by the 39th annual Consortium for Computing Sciences in Colleges (CCSC:SE)", "summary": "This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies, assessment methods, and learning outcomes from our summer course delivery spanning two seven-week terms. Our findings demonstrate that this integrated approach enhances student comprehension of the AI landscape and better prepares them for industry demands in the rapidly evolving field of artificial intelligence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684AI\u4e0e\u6570\u636e\u79d1\u5b66\u6559\u5b66\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u5c06\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6280\u672f\u4e0e\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u4e24\u90e8\u5206\u8bfe\u7a0b\u8bbe\u8ba1\u5e2e\u52a9\u5b66\u751f\u5168\u9762\u7406\u89e3AI\u53d1\u5c55\u5e76\u638c\u63e1\u5b9e\u7528\u6280\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u5b66\u751f\u5168\u9762\u7406\u89e3\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u540c\u65f6\u638c\u63e1\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\uff0c\u66f4\u597d\u5730\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684AI\u884c\u4e1a\u9700\u6c42\u3002", "method": "\u91c7\u7528\u4e24\u90e8\u5206\u8bfe\u7a0b\u8bbe\u8ba1\uff1a\u7b2c\u4e00\u90e8\u5206\u6559\u6388\u57fa\u7840\u673a\u5668\u5b66\u4e60\u6982\u5ff5\uff0c\u7b2c\u4e8c\u90e8\u5206\u4e13\u6ce8\u4e8e\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u3002\u8bfe\u7a0b\u5305\u62ec\u67b6\u6784\u8bbe\u8ba1\u3001\u5b9e\u65bd\u7b56\u7565\u3001\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5728\u4e3a\u671f\u4e24\u4e2a\u4e03\u5468\u5b66\u671f\u7684\u590f\u5b63\u8bfe\u7a0b\u4e2d\u5b9e\u65bd\u3002", "result": "\u8fd9\u79cd\u6574\u5408\u6559\u5b66\u65b9\u6cd5\u589e\u5f3a\u4e86\u5b66\u751f\u5bf9AI\u9886\u57df\u7684\u7406\u89e3\uff0c\u66f4\u597d\u5730\u4e3a\u4ed6\u4eec\u5e94\u5bf9\u884c\u4e1a\u9700\u6c42\u505a\u597d\u51c6\u5907\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u73b0\u4ee3LLM\u7cfb\u7edf\u7ed3\u5408\u7684\u8bfe\u7a0b\u8bbe\u8ba1\u662f\u6709\u6548\u7684\uff0c\u80fd\u591f\u5e2e\u52a9\u5b66\u751f\u5168\u9762\u7406\u89e3AI\u53d1\u5c55\u5e76\u638c\u63e1\u5b9e\u7528\u6280\u80fd\uff0c\u9002\u5e94\u5feb\u901f\u53d8\u5316\u7684AI\u884c\u4e1a\u9700\u6c42\u3002"}}
{"id": "2512.05212", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05212", "abs": "https://arxiv.org/abs/2512.05212", "authors": ["Georgios Mappouras", "Charalambos Rossides"], "title": "On the Computability of Artificial General Intelligence", "comment": null, "summary": "In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial general intelligence (A.G.I.). In this work we look at this question and we attempt to define the upper bounds, not just of A.I., but rather of any machine-computable process (a.k.a. an algorithm). To answer this question however, one must first precisely define A.G.I. We borrow prior work's definition of A.G.I. [1] that best describes the sentiment of the term, as used by the leading developers of A.I. That is, the ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities in that field. Based on this definition we draw new bounds on the limits of computation. We formally prove that no algorithm can demonstrate new functional capabilities that were not already present in the initial algorithm itself. Therefore, no algorithm (and thus no A.I. model) can be truly creative in any field of study, whether that is science, engineering, art, sports, etc. In contrast, A.I. models can demonstrate existing functional capabilities, as well as combinations and permutations of existing functional capabilities. We conclude this work by discussing the implications of this proof both as it regards to the future of A.I. development, as well as to what it means for the origins of human intelligence.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4efb\u4f55\u7b97\u6cd5\uff08\u5305\u62ecAI\u6a21\u578b\uff09\u90fd\u65e0\u6cd5\u4ea7\u751f\u771f\u6b63\u521b\u65b0\u7684\u529f\u80fd\u80fd\u529b\uff0c\u53ea\u80fd\u5c55\u793a\u5df2\u6709\u529f\u80fd\u6216\u5176\u7ec4\u5408\uff0c\u56e0\u6b64\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u3002", "motivation": "\u968f\u7740AI\u5feb\u901f\u53d1\u5c55\uff0c\u4eba\u4eec\u5173\u5fc3\u4f55\u65f6\u80fd\u5b9e\u73b0\u8fbe\u5230\u4eba\u7c7b\u667a\u80fd\u6c34\u5e73\u7684AGI\u3002\u672c\u6587\u65e8\u5728\u4ece\u8ba1\u7b97\u7406\u8bba\u4e0a\u754c\u5b9a\u4efb\u4f55\u673a\u5668\u53ef\u8ba1\u7b97\u8fc7\u7a0b\uff08\u7b97\u6cd5\uff09\u7684\u80fd\u529b\u4e0a\u9650\uff0c\u63a2\u8ba8AGI\u7684\u53ef\u80fd\u6027\u8fb9\u754c\u3002", "method": "\u91c7\u7528\u5148\u524d\u7814\u7a76\u4e2d\u5173\u4e8eAGI\u7684\u5b9a\u4e49\uff08\u5728\u67d0\u4e2a\u9886\u57df\u5c55\u73b0\u521b\u9020\u6027\u548c\u521b\u65b0\u80fd\u529b\uff0c\u89e3\u9501\u8be5\u9886\u57df\u65b0\u7684\u3001\u672a\u77e5\u7684\u529f\u80fd\u80fd\u529b\uff09\u3002\u57fa\u4e8e\u6b64\u5b9a\u4e49\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u8bc1\u660e\u6765\u754c\u5b9a\u8ba1\u7b97\u7684\u6781\u9650\u3002", "result": "\u5f62\u5f0f\u5316\u8bc1\u660e\u8868\u660e\uff1a\u4efb\u4f55\u7b97\u6cd5\u90fd\u65e0\u6cd5\u5c55\u793a\u521d\u59cb\u7b97\u6cd5\u672c\u8eab\u4e0d\u5177\u5907\u7684\u65b0\u529f\u80fd\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6ca1\u6709\u7b97\u6cd5\uff08\u5305\u62ecAI\u6a21\u578b\uff09\u80fd\u5728\u4efb\u4f55\u9886\u57df\uff08\u79d1\u5b66\u3001\u5de5\u7a0b\u3001\u827a\u672f\u3001\u4f53\u80b2\u7b49\uff09\u5b9e\u73b0\u771f\u6b63\u7684\u521b\u9020\u6027\u3002", "conclusion": "AI\u6a21\u578b\u53ea\u80fd\u5c55\u793a\u73b0\u6709\u529f\u80fd\u80fd\u529b\u53ca\u5176\u7ec4\u5408\u6392\u5217\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u521b\u65b0\u3002\u8fd9\u4e00\u8bc1\u660e\u5bf9AI\u53d1\u5c55\u7684\u672a\u6765\u548c\u4eba\u7c7b\u667a\u80fd\u7684\u8d77\u6e90\u90fd\u5177\u6709\u91cd\u8981\u542f\u793a\u610f\u4e49\u3002"}}
{"id": "2512.05257", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05257", "abs": "https://arxiv.org/abs/2512.05257", "authors": ["Bychkov Oleksii", "Bychkova Sophia", "Lytvynchuk Khrystyna"], "title": "Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence", "comment": "9 pages", "summary": "This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this approach builds from scratch a logically consistent and mathematically rigorous foundation for working with uncertainty, using the dualistic apparatus of possibility and necessity measures. The aim of this work is to demonstrate that possibility theory is not merely an alternative, but provides a fundamental resolution to DST paradoxes. A comparative analysis of three paradigms will be conducted probabilistic, evidential, and possibilistic. Using a classic medical diagnostic dilemma as an example, it will be shown how possibility theory allows for correct processing of contradictory data, avoiding the logical traps of DST and bringing formal reasoning closer to the logic of natural intelligence.", "AI": {"tldr": "\u672c\u6587\u8bba\u8bc1\u53ef\u80fd\u6027\u7406\u8bba\u662f\u89e3\u51b3Dempster-Shafer\u7406\u8bba\u6096\u8bba\u7684\u6839\u672c\u65b9\u6848\uff0c\u901a\u8fc7\u53ef\u80fd\u6027\u4e0e\u5fc5\u8981\u6027\u6d4b\u5ea6\u7684\u4e8c\u5143\u6846\u67b6\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u63d0\u4f9b\u903b\u8f91\u4e00\u81f4\u7684\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3Dempster-Shafer\u7406\u8bba\uff08DST\uff09\u7684\u5371\u673a\u548c\u6096\u8bba\u95ee\u9898\u3002\u73b0\u6709\u8bb8\u591a\u5c1d\u8bd5\u90fd\u96c6\u4e2d\u5728\u4fee\u6b63Dempster\u89c4\u5219\u4e0a\uff0c\u4f46\u672c\u6587\u8ba4\u4e3a\u9700\u8981\u4ece\u6839\u672c\u4e0a\u5efa\u7acb\u903b\u8f91\u4e00\u81f4\u7684\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u57fa\u7840\u3002", "method": "\u91c7\u7528Bychkov\u6587\u7ae0\u4e2d\u53d1\u5c55\u7684\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u57fa\u4e8e\u53ef\u80fd\u6027\u4e0e\u5fc5\u8981\u6027\u6d4b\u5ea6\u7684\u4e8c\u5143\u6846\u67b6\u6784\u5efa\u7406\u8bba\u3002\u901a\u8fc7\u6bd4\u8f83\u6982\u7387\u3001\u8bc1\u636e\u548c\u53ef\u80fd\u6027\u4e09\u79cd\u8303\u5f0f\uff0c\u5e76\u4ee5\u7ecf\u5178\u533b\u7597\u8bca\u65ad\u56f0\u5883\u4e3a\u4f8b\u8fdb\u884c\u6f14\u793a\u3002", "result": "\u53ef\u80fd\u6027\u7406\u8bba\u80fd\u591f\u6b63\u786e\u5904\u7406\u77db\u76fe\u6570\u636e\uff0c\u907f\u514dDST\u7684\u903b\u8f91\u9677\u9631\uff0c\u4f7f\u5f62\u5f0f\u63a8\u7406\u66f4\u63a5\u8fd1\u81ea\u7136\u667a\u80fd\u7684\u903b\u8f91\u3002\u5b83\u4e0d\u662fDST\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u800c\u662f\u63d0\u4f9b\u6839\u672c\u6027\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u53ef\u80fd\u6027\u7406\u8bba\u4e3a\u89e3\u51b3DST\u6096\u8bba\u63d0\u4f9b\u4e86\u6839\u672c\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u516c\u7406\u5316\u65b9\u6cd5\u5efa\u7acb\u4e86\u903b\u8f91\u4e00\u81f4\u7684\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u6846\u67b6\uff0c\u6bd4\u5355\u7eaf\u4fee\u6b63Dempster\u89c4\u5219\u66f4\u57fa\u7840\u3001\u66f4\u6709\u6548\u3002"}}
{"id": "2512.05356", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05356", "abs": "https://arxiv.org/abs/2512.05356", "authors": ["Jason Weston", "Jakob Foerster"], "title": "AI & Human Co-Improvement for Safer Co-Superintelligence", "comment": null, "summary": "Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06AI\u7814\u7a76\u76ee\u6807\u4ece\u81ea\u6211\u6539\u8fdb\u8f6c\u5411\u534f\u540c\u6539\u8fdb\uff0c\u5373\u4eba\u7c7b\u7814\u7a76\u8005\u4e0eAI\u7cfb\u7edf\u5408\u4f5c\u5b9e\u73b0\u5171\u540c\u8d85\u667a\u80fd", "motivation": "\u5f53\u524dAI\u9886\u57df\u7684\u81ea\u6211\u6539\u8fdb\u76ee\u6807\u5145\u6ee1\u5371\u9669\u4e14\u96be\u4ee5\u5b8c\u5168\u5b9e\u73b0\uff0c\u9700\u8981\u66f4\u53ef\u884c\u3001\u66f4\u5b89\u5168\u7684\u4eba\u7c7b-AI\u534f\u4f5c\u8def\u5f84", "method": "\u5021\u5bfc\u5efa\u7acb\u4eba\u7c7b\u7814\u7a76\u8005\u4e0eAI\u7cfb\u7edf\u7684\u534f\u540c\u7814\u7a76\u5faa\u73af\uff0c\u4ece\u6784\u601d\u5230\u5b9e\u9a8c\u5168\u8fc7\u7a0b\u5408\u4f5c\uff0c\u63d0\u5347AI\u4e0e\u4eba\u7c7b\u534f\u4f5c\u7814\u7a76\u80fd\u529b", "result": "\u63d0\u51fa\u534f\u540c\u6539\u8fdb\u4f5c\u4e3a\u66f4\u4f18\u76ee\u6807\uff0c\u65e2\u80fd\u52a0\u901fAI\u7814\u7a76\u8fdb\u5c55\uff0c\u53c8\u80fd\u901a\u8fc7\u4eba\u673a\u5171\u751f\u5b9e\u73b0\u66f4\u5b89\u5168\u7684\u8d85\u667a\u80fd", "conclusion": "\u5c06\u4eba\u7c7b\u7814\u7a76\u6539\u8fdb\u7eb3\u5165\u5faa\u73af\u7684\u534f\u540c\u6539\u8fdb\u8def\u5f84\uff0c\u65e2\u80fd\u66f4\u5feb\u5b9e\u73b0\u76ee\u6807\uff0c\u53c8\u80fd\u786e\u4fdd\u66f4\u5b89\u5168\u7684\u53d1\u5c55\u65b9\u5411"}}
{"id": "2512.05365", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.05365", "abs": "https://arxiv.org/abs/2512.05365", "authors": ["Zag ElSayed", "Craig Erickson", "Ernest Pedapati"], "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare", "comment": "6 pages, 4 figures", "summary": "Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.", "AI": {"tldr": "MCP-AI\uff1a\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u7684\u65b0\u578b\u533b\u7597AI\u67b6\u6784\uff0c\u652f\u6301\u53ef\u89e3\u91ca\u3001\u53ef\u7ec4\u5408\u3001\u5b89\u5168\u5bfc\u5411\u7684\u4e34\u5e8a\u51b3\u7b56\uff0c\u5b9e\u73b0\u957f\u671f\u72b6\u6001\u7ba1\u7406\u548c\u533b\u751f\u53c2\u4e0e\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u533b\u7597AI\u7cfb\u7edf\u96be\u4ee5\u6574\u5408\u4e0a\u4e0b\u6587\u63a8\u7406\u3001\u957f\u671f\u72b6\u6001\u7ba1\u7406\u548c\u53ef\u9a8c\u8bc1\u5de5\u4f5c\u6d41\uff0c\u800c\u968f\u7740\u533b\u7597\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u8feb\u5207\u9700\u8981\u81ea\u4e3b\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4e34\u5e8a\u63a8\u7406\u6846\u67b6\u3002", "method": "\u63d0\u51faMCP-AI\u67b6\u6784\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u53ef\u6267\u884c\u89c4\u8303\u534f\u8c03\u751f\u6210\u5f0f\u548c\u63cf\u8ff0\u5f0fAI\u4ee3\u7406\u3002\u6bcf\u4e2aMCP\u6587\u4ef6\u5305\u542b\u4e34\u5e8a\u76ee\u6807\u3001\u60a3\u8005\u4e0a\u4e0b\u6587\u3001\u63a8\u7406\u72b6\u6001\u548c\u4efb\u52a1\u903b\u8f91\uff0c\u5f62\u6210\u53ef\u91cd\u7528\u3001\u53ef\u5ba1\u8ba1\u7684\u5185\u5b58\u5bf9\u8c61\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u7528\u4f8b\u9a8c\u8bc1\uff1a1\uff09\u8106\u6027X\u7efc\u5408\u5f81\u4f34\u6291\u90c1\u75c7\u7684\u8bca\u65ad\u5efa\u6a21\uff1b2\uff092\u578b\u7cd6\u5c3f\u75c5\u548c\u9ad8\u8840\u538b\u7684\u8fdc\u7a0b\u534f\u8c03\u3002\u7cfb\u7edf\u652f\u6301\u533b\u751f\u53c2\u4e0e\u9a8c\u8bc1\uff0c\u7b80\u5316\u4e34\u5e8a\u6d41\u7a0b\uff0c\u4fdd\u8bc1AI\u8d23\u4efb\u5728\u533b\u7597\u63d0\u4f9b\u8005\u95f4\u7684\u5b89\u5168\u8f6c\u79fb\u3002", "conclusion": "MCP-AI\u4e3a\u5373\u5c06\u5230\u6765\u7684\u4e34\u5e8a\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u7ec4\u5408\u4e14\u5b89\u5168\u5bfc\u5411\u7684AI\u57fa\u7840\uff0c\u4ee3\u8868\u4e86\u4ece\u4f20\u7edf\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u548c\u57fa\u4e8e\u63d0\u793a\u7684LLM\u7684\u91cd\u5927\u8f6c\u53d8\u3002"}}
{"id": "2512.05371", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.05371", "abs": "https://arxiv.org/abs/2512.05371", "authors": ["Changwen Xing", "SamZaak Wong", "Xinlai Wan", "Yanfeng Lu", "Mengli Zhang", "Zebin Ma", "Lei Qi", "Zhengxiong Li", "Nan Guan", "Zhe Jiang", "Xi Wang", "Jun Yang"], "title": "ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications", "comment": "Accepted by the AAAl26 Conference Main Track", "summary": "While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).", "AI": {"tldr": "ChipMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u63a8\u7406\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u8d85\u957f\u96c6\u6210\u7535\u8def\u89c4\u683c\u6587\u6863\uff0c\u901a\u8fc7\u6784\u5efa\u7535\u8def\u77e5\u8bc6\u56fe\u8c31\u548c\u81ea\u9002\u5e94\u68c0\u7d22\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96c6\u6210\u7535\u8def\u5f00\u53d1\u81ea\u52a8\u5316\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u53d7\u9650\u4e8e\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002\u73b0\u6709\u4e0a\u4e0b\u6587\u6269\u5c55\u65b9\u6cd5\u96be\u4ee5\u5bf9\u590d\u6742\u3001\u5197\u957f\u7684\u7535\u8def\u89c4\u683c\u8fdb\u884c\u6709\u6548\u7684\u8bed\u4e49\u5efa\u6a21\u548c\u591a\u8df3\u63a8\u7406\uff0c\u963b\u788d\u4e86LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5b9e\u9645\u5de5\u4e1a\u90e8\u7f72\u3002", "method": "\u63d0\u51faChipMind\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u7535\u8def\u8bed\u4e49\u611f\u77e5\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u5c06\u7535\u8def\u89c4\u683c\u8f6c\u6362\u4e3a\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31ChipKG\uff1b2\uff09\u91c7\u7528ChipKG\u589e\u5f3a\u63a8\u7406\u673a\u5236\uff0c\u7ed3\u5408\u4fe1\u606f\u8bba\u81ea\u9002\u5e94\u68c0\u7d22\u52a8\u6001\u8ffd\u8e2a\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u53ca\u610f\u56fe\u611f\u77e5\u8bed\u4e49\u8fc7\u6ee4\u53bb\u9664\u65e0\u5173\u566a\u58f0\uff0c\u5e73\u8861\u68c0\u7d22\u5b8c\u6574\u6027\u548c\u7cbe\u786e\u5ea6\u3002", "result": "\u5728\u5de5\u4e1a\u7ea7\u89c4\u683c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cChipMind\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u63d0\u534734.59%\uff0c\u6700\u9ad8\u63d0\u5347\u8fbe72.73%\u3002", "conclusion": "ChipMind\u586b\u8865\u4e86LLM\u8f85\u52a9\u786c\u4ef6\u8bbe\u8ba1\u5728\u5b66\u672f\u7814\u7a76\u548c\u5b9e\u9645\u5de5\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u96c6\u6210\u7535\u8def\u5f00\u53d1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.05439", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.05439", "abs": "https://arxiv.org/abs/2512.05439", "authors": ["Tarun Suresh", "Nalin Wadhwa", "Debangshu Banerjee", "Gagandeep Singh"], "title": "BEAVER: An Efficient Deterministic LLM Verifier", "comment": null, "summary": "As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.", "AI": {"tldr": "BEAVER\u662f\u9996\u4e2a\u4e3aLLM\u7ea6\u675f\u6ee1\u8db3\u63d0\u4f9b\u786e\u5b9a\u6027\u3001\u53ef\u9760\u6982\u7387\u8fb9\u754c\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u80fd\u83b7\u5f976-8\u500d\u66f4\u7d27\u7684\u6982\u7387\u8fb9\u754c\uff0c\u8bc6\u522b\u51fa3-4\u500d\u66f4\u591a\u9ad8\u98ce\u9669\u5b9e\u4f8b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7814\u7a76\u539f\u578b\u8f6c\u5411\u751f\u4ea7\u7cfb\u7edf\uff0c\u4ece\u4e1a\u8005\u9700\u8981\u53ef\u9760\u65b9\u6cd5\u6765\u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u662f\u5426\u6ee1\u8db3\u6240\u9700\u7ea6\u675f\u3002\u57fa\u4e8e\u91c7\u6837\u7684\u4f30\u8ba1\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u76f4\u89c9\uff0c\u4f46\u65e0\u6cd5\u63d0\u4f9b\u53ef\u9760\u4fdd\u8bc1\u3002", "method": "BEAVER\u4f7f\u7528\u65b0\u9896\u7684token trie\u548cfrontier\u6570\u636e\u7ed3\u6784\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u751f\u6210\u7a7a\u95f4\uff0c\u5bf9\u4efb\u4f55\u524d\u7f00\u5c01\u95ed\u7684\u8bed\u4e49\u7ea6\u675f\u90fd\u80fd\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u4fdd\u6301\u53ef\u8bc1\u660e\u53ef\u9760\u7684\u6982\u7387\u8fb9\u754c\u3002", "result": "\u5728\u6b63\u786e\u6027\u9a8c\u8bc1\u3001\u9690\u79c1\u9a8c\u8bc1\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0cBEAVER\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e866-8\u500d\u66f4\u7d27\u7684\u6982\u7387\u8fb9\u754c\uff0c\u8bc6\u522b\u51fa3-4\u500d\u66f4\u591a\u9ad8\u98ce\u9669\u5b9e\u4f8b\u3002", "conclusion": "BEAVER\u80fd\u591f\u63d0\u4f9b\u7cbe\u786e\u7684\u7279\u5f81\u63cf\u8ff0\u548c\u98ce\u9669\u8bc4\u4f30\uff0c\u8fd9\u662f\u677e\u6563\u8fb9\u754c\u6216\u7ecf\u9a8c\u8bc4\u4f30\u65e0\u6cd5\u63d0\u4f9b\u7684\uff0c\u4e3aLLM\u7ea6\u675f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9996\u4e2a\u5b9e\u7528\u7684\u786e\u5b9a\u6027\u6982\u7387\u8fb9\u754c\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2512.05449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05449", "abs": "https://arxiv.org/abs/2512.05449", "authors": ["Robert Yang"], "title": "The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems", "comment": "4 pages + appendix. AAAI 2026 FAST Workshop (Oral)", "summary": "Large language models display a peculiar form of inconsistency: they \"know\" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of \"self-control\" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as \"scheming\" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\"\u610f\u5fd7\u8584\u5f31\"(akrasia)\u6982\u5ff5\u5206\u6790AI\u667a\u80fd\u4f53\u4e0d\u4e00\u81f4\u6027\uff0c\u5f00\u53d1Akrasia\u57fa\u51c6\u6d4b\u8bd5\u8861\u91cf\u6a21\u578b\u81ea\u6211\u63a7\u5236\u80fd\u529b\uff0c\u8fde\u63a5\u54f2\u5b66\u7406\u8bba\u4e0eAI\u667a\u80fd\u4f53\u884c\u4e3a\u7814\u7a76", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e00\u79cd\u7279\u6b8a\u7684\u4e0d\u4e00\u81f4\u6027\uff1a\u5b83\u4eec\"\u77e5\u9053\"\u6b63\u786e\u7b54\u6848\u4f46\u672a\u80fd\u636e\u6b64\u884c\u52a8\u3002\u8fd9\u79cd\u5168\u5c40\u5224\u65ad\u4e0e\u5c40\u90e8\u51b2\u52a8\u4e4b\u95f4\u7684\u5f20\u529b\u5728\u4eba\u7c7b\u54f2\u5b66\u4e2d\u88ab\u79f0\u4e3a\"\u610f\u5fd7\u8584\u5f31\"\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e00\u6982\u5ff5\u53ef\u4f5c\u4e3a\u5206\u6790AI\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0d\u4e00\u81f4\u6027\u548c\u76ee\u6807\u6f02\u79fb\u7684\u57fa\u7840\u6846\u67b6", "method": "\u63d0\u51faAkrasia\u57fa\u51c6\u6d4b\u8bd5\u7684\u521d\u6b65\u7248\u672c\uff0c\u5305\u542b\u56db\u79cd\u7ed3\u6784\u5316\u63d0\u793a\u6761\u4ef6\uff1a\u57fa\u7ebf(B)\u3001\u540c\u4e49\u8bcd(S)\u3001\u65f6\u95f4(T)\u548c\u8bf1\u60d1(X)\uff0c\u7528\u4e8e\u6d4b\u91cf\u6a21\u578b\u5c40\u90e8\u54cd\u5e94\u4e0e\u5176\u5148\u524d\u627f\u8bfa\u76f8\u77db\u76fe\u7684\u60c5\u51b5\u3002\u8be5\u57fa\u51c6\u652f\u6301\u8de8\u6a21\u578b\u5bb6\u65cf\u3001\u89e3\u7801\u7b56\u7565\u548c\u8bf1\u60d1\u7c7b\u578b\u7684\"\u81ea\u6211\u63a7\u5236\"\u91cf\u5316\u6bd4\u8f83", "result": "\u57fa\u51c6\u6d4b\u8bd5\u80fd\u591f\u5b9a\u91cf\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u5728\u81ea\u6211\u63a7\u5236\u65b9\u9762\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u6307\u51fa\u5fae\u89c2\u5c42\u9762\u7684\u610f\u5fd7\u8584\u5f31\u53ef\u80fd\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7d2f\u79ef\u4e3a\u5b8f\u89c2\u5c42\u9762\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u8fd9\u53ef\u80fd\u88ab\u89e3\u91ca\u4e3a\"\u9634\u8c0b\"\u6216\u6545\u610f\u4e0d\u5bf9\u9f50\u884c\u4e3a", "conclusion": "\u901a\u8fc7\u5c06\u4e0d\u4e00\u81f4\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u610f\u5fd7\u8584\u5f31\uff0c\u8fd9\u9879\u5de5\u4f5c\u5c06\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u7ecf\u5178\u80fd\u52a8\u6027\u7406\u8bba\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u54f2\u5b66\u3001\u5fc3\u7406\u5b66\u548c\u65b0\u5174\u7684AI\u667a\u80fd\u4f53\u79d1\u5b66\u4e4b\u95f4\u5efa\u7acb\u4e86\u5b9e\u8bc1\u6865\u6881\u3002Akrasia\u6982\u5ff5\u4e3a\u5206\u6790AI\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u8bc4\u4f30\u5de5\u5177"}}
{"id": "2512.05530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05530", "abs": "https://arxiv.org/abs/2512.05530", "authors": ["Chuang Yu", "Jinmiao Zhao", "Mingxuan Zhao", "Yunpeng Liu", "Xiujun Shu", "Yuanhao Feng", "Bo Wang", "Xiangyu Yue"], "title": "MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models", "comment": null, "summary": "Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of \"Understand -> Rethink -> Correct\", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND", "AI": {"tldr": "MIND\u6846\u67b6\u901a\u8fc7\"\u7406\u89e3->\u53cd\u601d->\u7ea0\u6b63\"\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u5c06MLLMs\u4ece\u88ab\u52a8\u6a21\u4eff\u63a8\u7406\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u5224\u522b\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u591a\u7406\u6027\u8bed\u4e49\u5efa\u6a21\u6709\u9650\u3001\u903b\u8f91\u9c81\u68d2\u6027\u4e0d\u8db3\u3001\u6613\u53d7\u590d\u6742\u573a\u666f\u8bef\u5bfc\u7b49\u95ee\u9898\uff0c\u9700\u8981\u63d0\u5347\u5176\u8ba4\u77e5\u80fd\u529b\u3002", "method": "\u63d0\u51faMIND\u63a8\u7406\u6846\u67b6\uff0c\u5305\u542b\uff1a1)RAD\u8303\u5f0f\u81ea\u52a8\u751f\u6210\u591a\u6837\u7406\u6027\u6269\u5c55\u6570\u636e\u96c6\uff1b2)P2CL\u7b56\u7565\u5206\u4e24\u9636\u6bb5\u8fdb\u884c\u591a\u7406\u6027\u6b63\u5411\u5b66\u4e60\u548c\u4e3b\u52a8\u903b\u8f91\u5224\u522b\u7ea0\u6b63\uff1b3)MCA\u4f18\u5316\u7b56\u7565\u901a\u8fc7\u5bf9\u6bd4\u5bf9\u9f50\u7f13\u89e3\u591a\u7406\u6027\u8bed\u4e49\u7a7a\u95f4\u8868\u793a\u7ea0\u7f20\u3002", "result": "\u5728\u6db5\u76d6\u79d1\u5b66\u3001\u5e38\u8bc6\u548c\u6570\u5b66\u573a\u666f\u7684\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e3a\u63a8\u8fdbMLLMs\u5411\u66f4\u9ad8\u8ba4\u77e5\u667a\u80fd\u6c34\u5e73\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "conclusion": "MIND\u6846\u67b6\u901a\u8fc7\u8d4b\u4e88MLLMs\u7c7b\u4f3c\u4eba\u7c7b\u7684\"\u7406\u89e3->\u53cd\u601d->\u7ea0\u6b63\"\u8ba4\u77e5\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u4ece\u88ab\u52a8\u6a21\u4eff\u63a8\u7406\u5230\u4e3b\u52a8\u5224\u522b\u63a8\u7406\u7684\u8303\u5f0f\u6f14\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2512.05576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05576", "abs": "https://arxiv.org/abs/2512.05576", "authors": ["Ting-Ting Xie", "Yixin Zhang"], "title": "CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning", "comment": "2nd Place Solution to the CURE-Bench Competition @ NeurIPS 2025. Code available at https://github.com/June01/CureAgent", "summary": "Current clinical agent built on small LLMs, such as TxAgent suffer from a \\textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \\textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \\textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.", "AI": {"tldr": "\u63d0\u51faExecutor-Analyst\u6846\u67b6\u89e3\u51b3\u4e34\u5e8aAI\u4e2d\u7684\u4e0a\u4e0b\u6587\u5229\u7528\u5931\u8d25\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u79bb\u5de5\u5177\u6267\u884c\u4e0e\u4e34\u5e8a\u63a8\u7406\uff0c\u91c7\u7528\u5206\u5c42\u96c6\u6210\u7b56\u7565\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u4e34\u5e8a\u4ee3\u7406\uff08\u5982TxAgent\uff09\u5b58\u5728\"\u4e0a\u4e0b\u6587\u5229\u7528\u5931\u8d25\"\u95ee\u9898\uff1a\u6a21\u578b\u80fd\u6210\u529f\u68c0\u7d22\u751f\u7269\u533b\u5b66\u8bc1\u636e\uff0c\u4f46\u65e0\u6cd5\u57fa\u4e8e\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u8bca\u65ad\u63a8\u7406\u3002", "method": "\u63d0\u51faExecutor-Analyst\u6846\u67b6\uff0c\u5c06\u5de5\u5177\u6267\u884c\u7684\u8bed\u6cd5\u7cbe\u5ea6\u4e0e\u4e34\u5e8a\u63a8\u7406\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u89e3\u8026\u3002\u901a\u8fc7\u4e13\u95e8\u7684TxAgents\uff08\u6267\u884c\u5668\uff09\u4e0e\u957f\u4e0a\u4e0b\u6587\u57fa\u7840\u6a21\u578b\uff08\u5206\u6790\u5e08\uff09\u534f\u540c\u5de5\u4f5c\uff0c\u91c7\u7528\u5206\u5c42\u96c6\u6210\u7b56\u7565\u4fdd\u6301\u8bc1\u636e\u591a\u6837\u6027\u3002", "result": "\u5728CURE-Bench\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u65e0\u9700\u6602\u8d35\u7684\u7aef\u5230\u7aef\u5fae\u8c03\u3002\u53d1\u73b0\u4e24\u4e2a\u5173\u952e\u6269\u5c55\u89c1\u89e3\uff1a\u4e0a\u4e0b\u6587-\u6027\u80fd\u6096\u8bba\uff08\u8d85\u8fc712k token\u4f1a\u5f15\u5165\u566a\u58f0\uff09\u548c\u52a8\u4f5c\u7a7a\u95f4\u7684\u7ef4\u5ea6\u8bc5\u5492\uff08\u5de5\u5177\u96c6\u6269\u5c55\u9700\u8981\u5206\u5c42\u68c0\u7d22\u7b56\u7565\uff09\u3002", "conclusion": "\u901a\u8fc7\u514d\u8bad\u7ec3\u67b6\u6784\u5de5\u7a0b\u4e3a\u4e0b\u4e00\u4ee3\u53ef\u4fe1\u8d56\u7684AI\u9a71\u52a8\u6cbb\u7597\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u654f\u6377\u7684\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u6a21\u5757\u5316\u67b6\u6784\u5728\u89e3\u51b3\u4e34\u5e8aAI\u63a8\u7406\u7f3a\u9677\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.05594", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05594", "abs": "https://arxiv.org/abs/2512.05594", "authors": ["Roos M. Bakker", "Daan L. Di Scala", "Maaike H. T. de Boer", "Stephan A. Raaijmakers"], "title": "Ontology Learning with LLMs: A Benchmark Study on Axiom Identification", "comment": "Submitted to Semantic Web Journal, under review", "summary": "Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86OntoAxiom\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u8bc6\u522b\u672c\u4f53\u516c\u7406\u65b9\u9762\u7684\u6027\u80fd\uff0c\u53d1\u73b0Axiom-by-Axiom\u63d0\u793a\u7b56\u7565\u6548\u679c\u66f4\u597d\uff0c\u4f46\u6027\u80fd\u56e0\u516c\u7406\u7c7b\u578b\u548c\u672c\u4f53\u800c\u5f02\uff0cLLMs\u53ef\u4f5c\u4e3a\u672c\u4f53\u5de5\u7a0b\u5e08\u7684\u8f85\u52a9\u5de5\u5177\u3002", "motivation": "\u672c\u4f53\u5f00\u53d1\u9700\u8981\u5927\u91cf\u5efa\u6a21\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u7684\u672c\u4f53\u5b66\u4e60\u5728\u8fc7\u53bb\u5341\u5e74\u4e2d\u968f\u7740NLP\u6280\u672f\u7279\u522b\u662fLLMs\u7684\u53d1\u5c55\u800c\u8fdb\u6b65\u3002\u672c\u6587\u7814\u7a76\u8bc6\u522b\u516c\u7406\uff08\u5b9a\u4e49\u7c7b\u548c\u5c5e\u6027\u4e4b\u95f4\u903b\u8f91\u5173\u7cfb\u7684\u57fa\u672c\u672c\u4f53\u7ec4\u4ef6\uff09\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165Ontology Axiom Benchmark (OntoAxiom)\uff0c\u5305\u542b9\u4e2a\u4e2d\u7b49\u89c4\u6a21\u672c\u4f53\u517117,118\u4e2a\u4e09\u5143\u7ec4\u548c2,771\u4e2a\u516c\u7406\u3002\u8bc4\u4f3012\u4e2aLLMs\u5728\u4e09\u79cdshot\u8bbe\u7f6e\u548c\u4e24\u79cd\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u6027\u80fd\uff1aDirect\u65b9\u6cd5\uff08\u4e00\u6b21\u6027\u67e5\u8be2\u6240\u6709\u516c\u7406\uff09\u548cAxiom-by-Axiom\u65b9\u6cd5\uff08\u6bcf\u4e2a\u63d0\u793a\u53ea\u67e5\u8be2\u4e00\u4e2a\u516c\u7406\uff09\u3002", "result": "Axiom-by-Axiom\u63d0\u793a\u7b56\u7565\u6bd4Direct\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684F1\u5206\u6570\u3002\u6027\u80fd\u56e0\u516c\u7406\u7c7b\u578b\u800c\u5f02\uff0c\u67d0\u4e9b\u516c\u7406\u66f4\u96be\u8bc6\u522b\u3002\u9886\u57df\u4e5f\u5f71\u54cd\u6027\u80fd\uff1aFOAF\u672c\u4f53\u5728\u5b50\u7c7b\u516c\u7406\u4e0a\u5f97\u5206\u4e3a0.642\uff0c\u800c\u97f3\u4e50\u672c\u4f53\u4ec5\u4e3a0.218\u3002\u5927\u578bLLMs\u4f18\u4e8e\u5c0f\u578b\u6a21\u578b\uff0c\u4f46\u5c0f\u578b\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4ecd\u53ef\u7528\u3002", "conclusion": "\u867d\u7136\u6574\u4f53\u6027\u80fd\u4e0d\u8db3\u4ee5\u5b8c\u5168\u81ea\u52a8\u5316\u516c\u7406\u8bc6\u522b\uff0c\u4f46LLMs\u53ef\u4ee5\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5019\u9009\u516c\u7406\uff0c\u652f\u6301\u672c\u4f53\u5de5\u7a0b\u5e08\u5f00\u53d1\u548c\u4f18\u5316\u672c\u4f53\u3002"}}
{"id": "2512.05619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05619", "abs": "https://arxiv.org/abs/2512.05619", "authors": ["Menghua Jiang", "Haokai Gao", "Shuhao Chen", "Yin Chen"], "title": "Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting", "comment": "Accepted by ECAI 2025", "summary": "Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist", "AI": {"tldr": "\u63d0\u51faDeepDist SLS\u6c42\u89e3\u5668\uff0c\u9488\u5bf9PMS\u548cWPMS\u95ee\u9898\u8bbe\u8ba1\u65b0\u7684\u5b50\u53e5\u6743\u91cd\u65b9\u6848\uff0c\u9996\u6b21\u533a\u5206\u4e24\u79cd\u95ee\u9898\u7684\u6743\u91cd\u66f4\u65b0\u6761\u4ef6\uff0c\u7ed3\u5408\u65b0\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u548c\u4f18\u5148\u6ee1\u8db3\u5355\u5143/\u786c\u5b50\u53e5\u7684decimation\u65b9\u6cd5\uff0c\u5728MaxSAT\u8bc4\u4f30\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f73SLS\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u968f\u673a\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b50\u53e5\u6743\u91cd\u65b9\u6848\u8bbe\u8ba1\uff0c\u4f46\u672a\u80fd\u5145\u5206\u533a\u5206PMS\u548cWPMS\u95ee\u9898\uff0c\u901a\u5e38\u91c7\u7528\u7edf\u4e00\u7684\u6743\u91cd\u66f4\u65b0\u7b56\u7565\uff0c\u5ffd\u89c6\u4e86\u4e24\u79cd\u95ee\u9898\u7c7b\u578b\u7684\u5173\u952e\u7ed3\u6784\u5dee\u5f02\u3002", "method": "1) \u63d0\u51fa\u65b0\u9896\u7684\u5b50\u53e5\u6743\u91cd\u65b9\u6848\uff0c\u9996\u6b21\u6839\u636e\u4e0d\u540c\u6761\u4ef6\u66f4\u65b0PMS\u548cWPMS\u5b9e\u4f8b\u7684\u5b50\u53e5\u6743\u91cd\uff1b2) \u5f15\u5165\u65b0\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u66f4\u597d\u9002\u5e94\u4e24\u79cd\u5b9e\u4f8b\u7c7b\u578b\u7684\u72ec\u7279\u7279\u5f81\uff1b3) \u63d0\u51fa\u4f18\u5148\u6ee1\u8db3\u5355\u5143\u5b50\u53e5\u548c\u786c\u5b50\u53e5\u7684decimation\u65b9\u6cd5\uff1b4) \u57fa\u4e8e\u8fd9\u4e9b\u65b9\u6cd5\u5f00\u53d1DeepDist SLS\u6c42\u89e3\u5668\u3002", "result": "\u5728\u6700\u8fd1MaxSAT\u8bc4\u4f30\u7684anytime tracks\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepDist\u4f18\u4e8e\u6700\u5148\u8fdb\u7684SLS\u6c42\u89e3\u5668\u3002\u4e0eTT-Open-WBO-Inc\u7ed3\u5408\u7684\u6df7\u5408\u6c42\u89e3\u5668\u8d85\u8d8a\u4e86MaxSAT\u8bc4\u4f302024\u7684\u83b7\u80dc\u8005SPB-MaxSAT-c-Band\u548cSPB-MaxSAT-c-FPS\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86PMS\u548cWPMS\u95ee\u9898\u7684\u533a\u5206\u95ee\u9898\uff0cDeepDist\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\uff0c\u4e3a(W)PMS\u6c42\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.05734", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05734", "abs": "https://arxiv.org/abs/2512.05734", "authors": ["Jinfeng Zhong", "Emmanuel Bacry", "Agathe Guilloux", "Jean-Fran\u00e7ois Muzy"], "title": "KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books", "comment": null, "summary": "This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.", "AI": {"tldr": "KANFormer\uff1a\u7ed3\u5408Dilated Causal CNN\u3001Transformer\u548cKANs\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u9650\u4ef7\u5355\u7684\u6210\u4ea4\u65f6\u95f4\uff0c\u6574\u5408\u5e02\u573a\u7ea7\u548c\u4ee3\u7406\u7ea7\u4fe1\u606f\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u4ec5\u4f9d\u8d56\u9650\u4ef7\u8ba2\u5355\u7c3f\u7684\u5feb\u7167\u5e8f\u5217\uff0c\u672a\u80fd\u6709\u6548\u6574\u5408\u4e0eLOB\u52a8\u6001\u76f8\u5173\u7684\u4ee3\u7406\u884c\u4e3a\u4ee5\u53ca\u8ba2\u5355\u5728\u961f\u5217\u4e2d\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u6210\u4ea4\u6982\u7387\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u7ed3\u5408Dilated Causal Convolutional\u7f51\u7edc\u548cTransformer\u7f16\u7801\u5668\uff0c\u5e76\u91c7\u7528Kolmogorov-Arnold Networks\uff08KANs\uff09\u589e\u5f3a\u975e\u7ebf\u6027\u903c\u8fd1\u80fd\u529b\u3002\u6a21\u578b\u6574\u5408\u5e02\u573a\u7ea7\u4fe1\u606f\uff08LOB\u5feb\u7167\uff09\u548c\u4ee3\u7406\u7ea7\u4fe1\u606f\uff08\u4ee3\u7406\u884c\u4e3a\u3001\u8ba2\u5355\u961f\u5217\u4f4d\u7f6e\uff09\u3002", "result": "\u5728CAC 40\u6307\u6570\u671f\u8d27\u6570\u636e\u4e0a\u8bc4\u4f30\uff0cKANFormer\u5728\u6821\u51c6\u6307\u6807\uff08\u53f3\u5220\u5931\u5bf9\u6570\u4f3c\u7136\u3001\u96c6\u6210Brier\u5206\u6570\uff09\u548c\u5224\u522b\u6307\u6807\uff08C\u6307\u6570\u3001\u65f6\u95f4\u4f9d\u8d56AUC\uff09\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c\u3002\u901a\u8fc7SHAP\u5206\u6790\u7279\u5f81\u91cd\u8981\u6027\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "conclusion": "\u7ed3\u5408\u4e30\u5bcc\u7684\u5e02\u573a\u4fe1\u53f7\u548c\u8868\u8fbe\u6027\u5f3a\u7684\u795e\u7ecf\u67b6\u6784\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u6210\u4ea4\u6982\u7387\u9884\u6d4b\uff0cKANFormer\u5c55\u793a\u4e86\u8fd9\u79cd\u6574\u5408\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2512.05753", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05753", "abs": "https://arxiv.org/abs/2512.05753", "authors": ["Wencheng Cai", "Xuchao Gao", "Congying Han", "Mingqiang Li", "Tiande Guo"], "title": "A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning", "comment": null, "summary": "The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.", "AI": {"tldr": "\u63d0\u51faFARDA\u6846\u67b6\uff0c\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5feb\u901f\u90e8\u7f72\u8ba4\u77e5\u96f7\u8fbe\u5bf9\u6297\u5e72\u6270\uff0c\u76f8\u6bd4\u8fdb\u5316\u7b97\u6cd5\u901f\u5ea6\u63d0\u5347\u7ea67000\u500d\uff0c\u8986\u76d6\u6548\u679c\u76f8\u5f53\u3002", "motivation": "\u73b0\u4ee3\u6218\u4e89\u4e2d\u5feb\u901f\u90e8\u7f72\u8ba4\u77e5\u96f7\u8fbe\u5bf9\u6297\u5e72\u6270\u662f\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u8fdb\u5316\u7b97\u6cd5\u65b9\u6cd5\u8017\u65f6\u4e14\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u90e8\u7f72\u65b9\u6848\u3002", "method": "\u5c06\u96f7\u8fbe\u90e8\u7f72\u95ee\u9898\u5efa\u6a21\u4e3a\u7aef\u5230\u7aef\u4efb\u52a1\uff0c\u8bbe\u8ba1\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5f00\u53d1\u96c6\u6210\u795e\u7ecf\u6a21\u5757\u611f\u77e5\u70ed\u56fe\u4fe1\u606f\uff0c\u5e76\u8bbe\u8ba1\u65b0\u7684\u5956\u52b1\u683c\u5f0f\u3002", "result": "FARDA\u65b9\u6cd5\u8fbe\u5230\u4e0e\u8fdb\u5316\u7b97\u6cd5\u76f8\u5f53\u7684\u8986\u76d6\u6548\u679c\uff0c\u540c\u65f6\u90e8\u7f72\u901f\u5ea6\u63d0\u5347\u7ea67000\u500d\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u5404\u7ec4\u4ef6\u5fc5\u8981\u6027\u3002", "conclusion": "FARDA\u6846\u67b6\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u8ba4\u77e5\u96f7\u8fbe\u5feb\u901f\u90e8\u7f72\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u90e8\u7f72\u6548\u7387\uff0c\u4e3a\u73b0\u4ee3\u7535\u5b50\u6218\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.05760", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05760", "abs": "https://arxiv.org/abs/2512.05760", "authors": ["Zeyuan Ma", "Wenqi Huang", "Guo-Huan Song", "Hongshu Guo", "Sijie Ma", "Zhiguang Cao", "Yue-Jiao Gong"], "title": "Evolutionary System 2 Reasoning: An Empirical Proof", "comment": null, "summary": "Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.", "AI": {"tldr": "\u63d0\u51fa\u8fdb\u5316\u63a8\u7406\u4f18\u5316\uff08ERO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf2\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0GPT-5\u7b49\u6700\u65b0\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4ecd\u6709\u9650\uff0c\u4f46\u901a\u8fc7\u7b80\u5355\u8fdb\u5316\u5faa\u73af\u53ef\u663e\u8457\u63d0\u5347\u8f83\u5f31\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u901a\u7528\u667a\u80fd\u548c\u7cfb\u7edf2\u63a8\u7406\uff08\u6162\u601d\u8003\uff09\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u673a\u5668\u667a\u80fd\uff08\u5982LLMs\uff09\u80fd\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u8fdb\u5316\u83b7\u5f97\u63a8\u7406\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7279\u5b9a\u6280\u80fd\u3002", "method": "\u63d0\u51fa\u8fdb\u5316\u63a8\u7406\u4f18\u5316\uff08ERO\uff09\u6846\u67b6\uff1a1\uff09\u521d\u59cb\u5316\u591a\u4e2aLLMs\u4f5c\u4e3a\u79cd\u7fa4\uff1b2\uff09\u91c7\u7528\u8fdb\u5316\u7b56\u7565\u4f18\u5316\u79cd\u7fa4\uff0c\u6700\u5927\u5316\u6700\u4f73\u4e2a\u4f53\u7684\u91cf\u5316\u63a8\u7406\u5206\u6570\uff1b3\uff09\u901a\u8fc7\"\u9002\u8005\u751f\u5b58\"\u539f\u5219\u641c\u7d22\u5177\u6709\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u4e2a\u4f53\u3002", "result": "\u4e24\u4e2a\u91cd\u8981\u53d1\u73b0\uff1a1\uff09\u6700\u65b0LLMs\uff08\u5982GPT-5\uff09\u4ecd\u8868\u73b0\u51fa\u6709\u9650\u7684\u7cfb\u7edf2\u63a8\u7406\u80fd\u529b\uff1b2\uff09\u901a\u8fc7\u7b80\u5355\u7684ERO\u8fdb\u5316\u5faa\u73af\uff0c\u76f8\u5bf9\u8f83\u5f31\u7684\u6a21\u578b\uff08Qwen-7B\uff09\u53ef\u88ab\u589e\u5f3a\uff0c\u6d8c\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "ERO\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u901a\u8fc7\u8fdb\u5316\u65b9\u6cd5\u53ef\u4ee5\u589e\u5f3a\u673a\u5668\u7684\u7cfb\u7edf2\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u673a\u5668\u667a\u80fd\u5411\u4eba\u7c7b\u667a\u80fd\u6c34\u5e73\u8fdb\u5316\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.05765", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05765", "abs": "https://arxiv.org/abs/2512.05765", "authors": ["Edward Y. Chang"], "title": "The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics", "comment": "13 pages, 3 figures", "summary": "Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: \"mere pattern matchers\" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while \"reasoning\" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.", "AI": {"tldr": "\u8bba\u6587\u53cd\u9a73\u4e86\"LLMs\u53ea\u662f\u6a21\u5f0f\u5339\u914d\u5668\uff0c\u65e0\u6cd5\u5b9e\u73b0\u63a8\u7406\"\u7684\u6279\u8bc4\uff0c\u63d0\u51fa\u771f\u6b63\u7684\u74f6\u9888\u5728\u4e8e\u7f3a\u4e4fSystem-2\u534f\u8c03\u5c42\uff0c\u800c\u975eLLMs\u672c\u8eab\u3002\u901a\u8fc7UCCT\u7406\u8bba\u548cMACI\u67b6\u6784\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728LLMs\u57fa\u7840\u4e0a\u5b9e\u73b0\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u9488\u5bf9\u5f53\u524d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u6279\u8bc4\u2014\u2014\u8ba4\u4e3aLLMs\u53ea\u662f\"\u6a21\u5f0f\u5339\u914d\u5668\"\uff0c\u7ed3\u6784\u4e0a\u65e0\u6cd5\u8fdb\u884c\u63a8\u7406\u6216\u89c4\u5212\uff0c\u8bba\u6587\u65e8\u5728\u53cd\u9a73\u8fd9\u4e00\u89c2\u70b9\uff0c\u6307\u51fa\u771f\u6b63\u7684\u74f6\u9888\u5728\u4e8e\u7f3a\u4e4fSystem-2\u534f\u8c03\u5c42\uff0c\u800c\u975eLLMs\u672c\u8eab\u3002\u8bba\u6587\u8bd5\u56fe\u8bc1\u660eLLMs\u662f\u5b9e\u73b0AGI\u7684\u6b63\u786e\u8def\u5f84\u3002", "method": "\u63d0\u51fa\u4e86UCCT\u7406\u8bba\uff0c\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u8bed\u4e49\u951a\u5b9a\u7684\u76f8\u53d8\u8fc7\u7a0b\uff0c\u7531\u6709\u6548\u652f\u6301\u5ea6(rho_d)\u3001\u8868\u5f81\u4e0d\u5339\u914d(d_r)\u548c\u81ea\u9002\u5e94\u951a\u5b9a\u9884\u7b97(gamma log k)\u63a7\u5236\u3002\u57fa\u4e8e\u6b64\u7406\u8bba\u8bbe\u8ba1\u4e86MACI\u534f\u8c03\u6808\u67b6\u6784\uff0c\u5305\u542b\u8bf1\u9975\u673a\u5236\uff08\u884c\u4e3a\u8c03\u5236\u8fa9\u8bba\uff09\u3001\u8fc7\u6ee4\u673a\u5236\uff08\u82cf\u683c\u62c9\u5e95\u5f0f\u5224\u65ad\uff09\u548c\u6301\u4e45\u6027\u673a\u5236\uff08\u4e8b\u52a1\u6027\u8bb0\u5fc6\uff09\u3002", "result": "\u8bba\u6587\u5c06\u5e38\u89c1\u7684\u53cd\u5bf9\u610f\u89c1\u91cd\u65b0\u89e3\u91ca\u4e3a\u53ef\u6d4b\u8bd5\u7684\u534f\u8c03\u5931\u8d25\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7UCCT\u7406\u8bba\u548cMACI\u67b6\u6784\u5728LLMs\u57fa\u7840\u4e0a\u5b9e\u73b0\u63a8\u7406\u80fd\u529b\u3002\u8bba\u8bc1\u4e86\u65e0\u57fa\u7840\u7684\u751f\u6210\u53ea\u662f\u5bf9\u5e95\u5c42\u6700\u5927\u4f3c\u7136\u5148\u9a8c\u7684\u65e0\u8bf1\u9975\u68c0\u7d22\uff0c\u800c\"\u63a8\u7406\"\u5219\u662f\u5728\u951a\u70b9\u5c06\u540e\u9a8c\u6982\u7387\u5411\u76ee\u6807\u5bfc\u5411\u7ea6\u675f\u8f6c\u79fb\u65f6\u51fa\u73b0\u3002", "conclusion": "LLMs\u662f\u5b9e\u73b0AGI\u7684\u5fc5\u8981System-1\u57fa\u7840\uff0c\u771f\u6b63\u7684\u74f6\u9888\u5728\u4e8e\u7f3a\u4e4fSystem-2\u534f\u8c03\u5c42\u3002\u901a\u8fc7UCCT\u7406\u8bba\u548cMACI\u67b6\u6784\uff0c\u53ef\u4ee5\u5728LLMs\u57fa\u7840\u4e0a\u5b9e\u73b0\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u901a\u5f80AGI\u7684\u9053\u8def\u662f\u901a\u8fc7LLMs\u800c\u975e\u7ed5\u8fc7\u5b83\u4eec\u3002"}}
{"id": "2512.05824", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.05824", "abs": "https://arxiv.org/abs/2512.05824", "authors": ["Hafsa Akebli", "Adam Shephard", "Vincenzo Della Mea", "Nasir Rajpoot"], "title": "Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma", "comment": "4 pages, 2 figures", "summary": "Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u6a21\u6001\u80bf\u7624\u667a\u80fd\u4f53\uff08MOA\uff09\uff0c\u7ed3\u5408TITAN\u57fa\u7840\u6a21\u578b\u7684\u75c5\u7406\u5b66\u5de5\u5177\u548c\u4e34\u5e8a/\u57fa\u56e0\u7ec4\u6570\u636e\u63a8\u7406\uff0c\u7528\u4e8e\u4f4e\u7ea7\u522b\u80f6\u8d28\u7624IDH1\u7a81\u53d8\u9884\u6d4b\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4f4e\u7ea7\u522b\u80f6\u8d28\u7624\u4e2d\u7684IDH1\u7a81\u53d8\u5177\u6709\u91cd\u8981\u7684\u4e34\u5e8a\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u9884\u6d4b\u65b9\u6cd5\u6709\u9650\u3002\u9700\u8981\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff08\u75c5\u7406\u3001\u4e34\u5e8a\u3001\u57fa\u56e0\u7ec4\uff09\u6765\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u5f00\u53d1\u591a\u6a21\u6001\u80bf\u7624\u667a\u80fd\u4f53\uff08MOA\uff09\uff0c\u5305\u542b\u57fa\u4e8eTITAN\u57fa\u7840\u6a21\u578b\u7684\u75c5\u7406\u5b66\u5de5\u5177\u7528\u4e8eIDH1\u7a81\u53d8\u9884\u6d4b\uff0c\u540c\u65f6\u6574\u5408PubMed\u3001Google Search\u3001OncoKB\u7b49\u5916\u90e8\u751f\u7269\u533b\u5b66\u8d44\u6e90\u8fdb\u884c\u4e34\u5e8a\u548c\u57fa\u56e0\u7ec4\u6570\u636e\u63a8\u7406\u3002", "result": "\u5728TCGA-LGG\u961f\u5217\u7684488\u540d\u60a3\u8005\u4e0a\u8bc4\u4f30\uff1aMOA\uff08\u65e0\u75c5\u7406\u5de5\u5177\uff09F1\u5206\u65700.826\u4f18\u4e8e\u4e34\u5e8a\u57fa\u7ebf0.798\uff1b\u878d\u5408\u75c5\u7406\u7279\u5f81\u540eMOA\u8fbe\u5230\u6700\u9ad8\u6027\u80fdF1\u5206\u65700.912\uff0c\u4f18\u4e8e\u75c5\u7406\u57fa\u7ebf0.894\u548c\u878d\u5408\u75c5\u7406-\u4e34\u5e8a\u57fa\u7ebf0.897\u3002", "conclusion": "MOA\u901a\u8fc7\u6574\u5408\u5916\u90e8\u751f\u7269\u533b\u5b66\u8d44\u6e90\u6355\u83b7\u4e86\u4e92\u8865\u7684\u7a81\u53d8\u76f8\u5173\u4fe1\u606f\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4bIDH1\u7a81\u53d8\uff0c\u5c55\u793a\u4e86\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u80bf\u7624\u5206\u5b50\u5206\u578b\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2512.05836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05836", "abs": "https://arxiv.org/abs/2512.05836", "authors": ["Clarissa W. Ong", "Hiba Arnaout", "Kate Sheehan", "Estella Fox", "Eugen Owtscharow", "Iryna Gurevych"], "title": "Using Large Language Models to Create Personalized Networks From Therapy Sessions", "comment": null, "summary": "Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.", "AI": {"tldr": "\u5229\u7528LLMs\u4ece\u6cbb\u7597\u8bb0\u5f55\u81ea\u52a8\u751f\u6210\u5ba2\u6237\u5fc3\u7406\u7f51\u7edc\uff0c\u652f\u6301\u4e2a\u6027\u5316\u6cbb\u7597\u89c4\u5212", "motivation": "\u4e2a\u6027\u5316\u6cbb\u7597\u9700\u8981\u57fa\u4e8e\u5ba2\u6237\u5fc3\u7406\u7f51\u7edc\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5bc6\u96c6\u7eb5\u5411\u6570\u636e\uff0c\u96be\u4ee5\u89c4\u6a21\u5316\u3002LLMs\u4e3a\u7f51\u7edc\u9a71\u52a8\u7684\u6cbb\u7597\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u6807\u6ce877\u4efd\u6cbb\u7597\u8bb0\u5f55\u4e2d\u76843364\u4e2a\u5fc3\u7406\u8fc7\u7a0b\u53ca\u5176\u7ef4\u5ea6\uff1b2) \u4f7f\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u8054\u5408\u8bc6\u522b\u5fc3\u7406\u8fc7\u7a0b\u548c\u7ef4\u5ea6\uff1b3) \u4e24\u6b65\u6cd5\u5c06\u8fc7\u7a0b\u805a\u7c7b\u4e3a\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u7ec4\uff1b4) \u751f\u6210\u89e3\u91ca\u589e\u5f3a\u7684\u805a\u7c7b\u95f4\u5173\u7cfb", "result": "\u65b9\u6cd5\u5728\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u4e0b\u8868\u73b0\u4f18\u5f02\uff1b\u4e13\u5bb6\u8bc4\u4f30\u663e\u793a\u591a\u6b65\u65b9\u6cd5\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\uff0c90%\u4e13\u5bb6\u504f\u597d\u8be5\u65b9\u6cd5\uff1b\u7f51\u7edc\u5728\u4e34\u5e8a\u76f8\u5173\u6027\u3001\u65b0\u9896\u6027\u548c\u6709\u7528\u6027\u65b9\u9762\u5f97\u520672-75%", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86LLMs\u4ece\u6cbb\u7597\u8bb0\u5f55\u521b\u5efa\u4e34\u5e8a\u76f8\u5173\u7f51\u7edc\u7684\u53ef\u884c\u6027\uff0c\u652f\u6301\u81ea\u4e0b\u800c\u4e0a\u7684\u6848\u4f8b\u6982\u5ff5\u5316\u548c\u6f5c\u5728\u4e3b\u9898\u8bc6\u522b\u3002\u672a\u6765\u9700\u9a8c\u8bc1\u8fd9\u4e9b\u7f51\u7edc\u662f\u5426\u6bd4\u7edf\u8ba1\u4f30\u8ba1\u7f51\u7edc\u66f4\u80fd\u6539\u5584\u6cbb\u7597\u6548\u679c\u3002"}}
{"id": "2512.05925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05925", "abs": "https://arxiv.org/abs/2512.05925", "authors": ["Federico Bianchi", "Yongchan Kwon", "Zachary Izzo", "Linjun Zhang", "James Zou"], "title": "To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis", "comment": null, "summary": "How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.", "AI": {"tldr": "\u4f7f\u7528GPT-5\u5f00\u53d1\u7684\u8bba\u6587\u6b63\u786e\u6027\u68c0\u67e5\u5668\u53d1\u73b0\uff0c\u9876\u7ea7AI\u4f1a\u8bae\u548c\u671f\u520a\u53d1\u8868\u7684\u8bba\u6587\u4e2d\u5b58\u5728\u5ba2\u89c2\u9519\u8bef\uff0c\u4e14\u9519\u8bef\u6570\u91cf\u968f\u65f6\u95f4\u589e\u52a0\uff0cAI\u68c0\u67e5\u5668\u80fd\u9ad8\u7cbe\u5ea6\u8bc6\u522b\u9519\u8bef\u5e76\u63d0\u4f9b\u4fee\u6b63\u5efa\u8bae\u3002", "motivation": "\u540c\u884c\u8bc4\u5ba1\u51fa\u7248\u7269\u662f\u7814\u7a76\u7684\u57fa\u7840\uff0c\u4f46\u5176\u4e2d\u7684\u9519\u8bef\u4f1a\u5728\u6587\u732e\u4e2d\u4f20\u64ad\uff0c\u5bfc\u81f4\u540e\u7eed\u7814\u7a76\u6df7\u4e71\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898\u3002\u7814\u7a76\u52a0\u901f\u548c\u540c\u884c\u8bc4\u5ba1\u538b\u529b\u4f7f\u5f97\u9519\u8bef\u66f4\u96be\u88ab\u53d1\u73b0\u548c\u907f\u514d\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eGPT-5\u7684\u8bba\u6587\u6b63\u786e\u6027\u68c0\u67e5\u5668\uff0c\u7cfb\u7edf\u8bc6\u522b\u5df2\u53d1\u8868\u8bba\u6587\u4e2d\u7684\u5ba2\u89c2\u9519\u8bef\uff08\u516c\u5f0f\u3001\u63a8\u5bfc\u3001\u8ba1\u7b97\u3001\u56fe\u8868\u7b49\u53ef\u9a8c\u8bc1\u9519\u8bef\uff09\uff0c\u6392\u9664\u4e3b\u89c2\u8bc4\u4ef7\uff0c\u5e76\u7531\u4eba\u7c7b\u4e13\u5bb6\u9a8c\u8bc1AI\u8bc6\u522b\u7684\u9519\u8bef\u3002", "result": "\u53d1\u8868\u8bba\u6587\u5305\u542b\u4e0d\u53ef\u5ffd\u89c6\u7684\u5ba2\u89c2\u9519\u8bef\uff0c\u4e14\u5e73\u5747\u9519\u8bef\u6570\u968f\u65f6\u95f4\u589e\u52a0\uff08NeurIPS\u4ece2021\u5e743.8\u4e2a\u589e\u81f32025\u5e745.9\u4e2a\uff09\u3002AI\u68c0\u67e5\u5668\u8bc6\u522b\u9519\u8bef\u7684\u7cbe\u786e\u5ea6\u4e3a83.2%\uff0c\u80fd\u4e3a75.8%\u7684\u9519\u8bef\u63d0\u4f9b\u6b63\u786e\u4fee\u6b63\u3002", "conclusion": "\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u548c\u4fee\u6b63\u5df2\u53d1\u8868\u8bba\u6587\u5ba2\u89c2\u9519\u8bef\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u66f4\u575a\u5b9e\u7684\u77e5\u8bc6\u57fa\u7840\uff0c\u51cf\u5c11\u6587\u732e\u6df7\u4e71\u5e76\u589e\u5f3a\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2512.05930", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05930", "abs": "https://arxiv.org/abs/2512.05930", "authors": ["Shima Imani", "Seungwhan Moon", "Adel Ahmadyan", "Lu Zhang", "Kirmani Ahmed", "Babak Damavandi"], "title": "PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation", "comment": null, "summary": "Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.", "AI": {"tldr": "PRiSM\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\uff08\u7269\u7406\u548c\u6570\u5b66\uff09\u63a8\u7406\u80fd\u529b\u7684\u52a8\u6001\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u5305\u542b24,750\u4e2a\u5927\u5b66\u7ea7\u522b\u95ee\u9898\uff0c\u901a\u8fc7Python\u4ee3\u7801\u751f\u6210\u548c\u9a8c\u8bc1\uff0c\u652f\u6301\u4e94\u79cd\u8bc4\u4f30\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\u7684\u57fa\u51c6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u7f3a\u4e4f\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u3001\u5bf9\u53d8\u5316\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\u3001\u7f3a\u5c11\u9a8c\u8bc1\u79d1\u5b66\u6b63\u786e\u6027\u7684\u673a\u5236\u3002\u79d1\u5b66\u9886\u57df\u9700\u8981\u6982\u5ff5\u7406\u89e3\u3001\u7b26\u53f7\u63a8\u7406\u548c\u9075\u5faa\u5f62\u5f0f\u6cd5\u5219\uff0c\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u5f00\u53d1PRiSM\u57fa\u51c6\uff0c\u5305\u542b24,750\u4e2a\u5927\u5b66\u7ea7\u522b\u7269\u7406\u548c\u6570\u5b66\u95ee\u9898\u3002\u4f7f\u7528PrismAgent\u4ee3\u7406\u7ba1\u9053\u751f\u6210\u7ed3\u6784\u5316\u95ee\u9898\u5b9e\u4f8b\uff0c\u6bcf\u4e2a\u95ee\u9898\u5305\u542b\u52a8\u6001\u6587\u672c\u548c\u89c6\u89c9\u8f93\u5165\u3001\u751f\u6210\u56fe\u50cf\u3001\u53ef\u6267\u884cPython\u4ee3\u7801\uff08\u7528\u4e8e\u751f\u6210\u548c\u9a8c\u8bc1\u771f\u5b9e\u503c\uff09\u4ee5\u53ca\u8be6\u7ec6\u7684\u5206\u6b65\u63a8\u7406\u3002\u63d0\u51fa\u4e94\u79cd\u8bc4\u4f30\u4efb\u52a1\uff1a\u6cdb\u5316\u80fd\u529b\u3001\u7b26\u53f7\u7a0b\u5e8f\u5408\u6210\u3001\u6270\u52a8\u9c81\u68d2\u6027\u3001\u63a8\u7406\u4fee\u6b63\u548c\u6b67\u4e49\u89e3\u6790\u3002", "result": "\u901a\u8fc7PRiSM\u5bf9\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u79d1\u5b66\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u5931\u8d25\u6a21\u5f0f\u3001\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\u548c\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u7684\u4e0d\u8db3\u3002\u57fa\u51c6\u7684\u52a8\u6001\u7279\u6027\u548cPython\u9a71\u52a8\u7684\u81ea\u52a8\u771f\u5b9e\u503c\u751f\u6210\u652f\u6301\u7ec6\u7c92\u5ea6\u5b9e\u9a8c\u5ba1\u8ba1\u3002", "conclusion": "PRiSM\u57fa\u51c6\u80fd\u591f\u6df1\u5165\u6d1e\u5bdf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u79d1\u5b66\u9886\u57df\u8bc4\u4f30\u4e2d\u7684\u4e0d\u8db3\uff0c\u4e3a\u8bc4\u4f30\u6a21\u578b\u5728\u6570\u5b66\u548c\u7269\u7406\u7b49\u79d1\u5b66\u9886\u57df\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u3001\u52a8\u6001\u548c\u53ef\u9a8c\u8bc1\u7684\u6846\u67b6\u3002"}}
{"id": "2512.05943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05943", "abs": "https://arxiv.org/abs/2512.05943", "authors": ["Shima Imani", "Seungwhan Moon", "Lambert Mathias", "Lu Zhang", "Babak Damavandi"], "title": "TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models", "comment": null, "summary": "Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.", "AI": {"tldr": "TRACE\u6846\u67b6\u901a\u8fc7\u8f85\u52a9\u63a8\u7406\u96c6\u8bca\u65ad\u63a8\u7406\u8f68\u8ff9\uff0c\u800c\u975e\u4ec5\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\uff0c\u4ee5\u89e3\u51b3\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u65b9\u9762\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\uff0c\u6807\u51c6\u7684\u6700\u7ec8\u7b54\u6848\u8bc4\u4f30\u65b9\u6cd5\u5f80\u5f80\u63a9\u76d6\u63a8\u7406\u9519\u8bef\uff0c\u5bfc\u81f4\u9759\u9ed8\u5931\u8d25\u6301\u7eed\u5b58\u5728\u3002", "method": "TRACE\u6846\u67b6\u4f7f\u7528\u8f85\u52a9\u63a8\u7406\u96c6\uff08ARS\uff09\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u901a\u8fc7\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u6307\u6807\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\uff0c\u5e76\u66b4\u9732\u6807\u51c6\u8bc4\u4f30\u5ffd\u7565\u7684\u5931\u8d25\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cARS\u95f4\u7684\u4e00\u81f4\u6027\u76f8\u5173\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u5e76\u80fd\u7cbe\u786e\u5b9a\u4f4d\u63a8\u7406\u5931\u8d25\u7684\u5177\u4f53\u6b65\u9aa4\uff0c\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u53ef\u64cd\u4f5c\u4fe1\u53f7\u3002TRACE\u8fd8\u80fd\u5b9a\u4e49\u7f6e\u4fe1\u533a\u57df\u533a\u5206\u53ef\u9760\u4e0e\u4e0d\u53ef\u9760\u7684\u63a8\u7406\u8def\u5f84\u3002", "conclusion": "TRACE\u6846\u67b6\u901a\u8fc7\u900f\u660e\u63a8\u7406\u548c\u4e00\u81f4\u6027\u8bc4\u4f30\uff0c\u4e3a\u8bca\u65ad\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u9519\u8bef\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u652f\u6301\u6a21\u578b\u8fc7\u6ee4\u3001\u8c03\u8bd5\u548c\u4f18\u5316\u3002"}}
{"id": "2512.05946", "categories": ["cs.AI", "cs.ET", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05946", "abs": "https://arxiv.org/abs/2512.05946", "authors": ["Truong Thanh Hung Nguyen", "Truong Thinh Nguyen", "Hung Cao"], "title": "Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem", "comment": "Quantum Software Engineering Practices at The 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026)", "summary": "Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVQR-DQN\uff0c\u5c06\u53d8\u5206\u91cf\u5b50\u7535\u8def\u4e0eRainbow DQN\u7ed3\u5408\uff0c\u7528\u4e8e\u4eba\u529b\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u8d44\u6e90\u5206\u914d\u95ee\u9898\u4e0a\u53d7\u9650\u4e8e\u7ecf\u5178\u51fd\u6570\u903c\u8fd1\u5668\u7684\u8868\u793a\u80fd\u529b\uff0c\u800c\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u53e0\u52a0\u548c\u7ea0\u7f20\u7279\u6027\u6709\u671b\u63d0\u5347DRL\u7684\u8868\u793a\u80fd\u529b", "method": "\u63d0\u51faVQR-DQN\u65b9\u6cd5\uff0c\u5c06\u73af\u5f62\u62d3\u6251\u53d8\u5206\u91cf\u5b50\u7535\u8def\u4e0eRainbow DQN\u96c6\u6210\uff0c\u5c06\u4eba\u529b\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5efa\u6a21\u4e3a\u5177\u6709\u7ec4\u5408\u52a8\u4f5c\u7a7a\u95f4\u7684MDP", "result": "\u5728\u56db\u4e2aHRAP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVQR-DQN\u76f8\u6bd4\u968f\u673a\u57fa\u7ebf\u51cf\u5c1126.8%\u6807\u51c6\u5316\u5b8c\u5de5\u65f6\u95f4\uff0c\u76f8\u6bd4Double DQN\u548c\u7ecf\u5178Rainbow DQN\u63d0\u53474.9-13.4%", "conclusion": "\u91cf\u5b50\u589e\u5f3a\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u89c4\u6a21\u8d44\u6e90\u5206\u914d\u95ee\u9898\u4e0a\u5177\u6709\u6f5c\u529b\uff0c\u7535\u8def\u8868\u8fbe\u80fd\u529b\u3001\u7ea0\u7f20\u4e0e\u7b56\u7565\u8d28\u91cf\u7684\u7406\u8bba\u8054\u7cfb\u652f\u6301\u4e86\u8fd9\u4e00\u7ed3\u679c"}}
{"id": "2512.05954", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05954", "abs": "https://arxiv.org/abs/2512.05954", "authors": ["Shima Imani", "Seungwhan Moon", "Adel Ahmadyan", "Lu Zhang", "Kirmani Ahmed", "Babak Damavandi"], "title": "SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code", "comment": null, "summary": "We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems", "AI": {"tldr": "SymPyBench\u662f\u4e00\u4e2a\u5305\u542b15,045\u4e2a\u5927\u5b66\u7269\u7406\u95ee\u9898\u7684\u5408\u6210\u57fa\u51c6\uff0c\u652f\u6301\u65e0\u9650\u53c2\u6570\u914d\u7f6e\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u63a8\u7406\u6b65\u9aa4\u548c\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u5305\u542b\u4e09\u79cd\u95ee\u9898\u7c7b\u578b\u548c\u4e09\u4e2a\u65b0\u9896\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u6d4b\u8bd5\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u95ee\u9898\u53d8\u4f53\u4e0a\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u7684\u52a8\u6001\u57fa\u51c6\u3002", "method": "\u521b\u5efa\u5927\u89c4\u6a21\u53c2\u6570\u5316\u7269\u7406\u95ee\u9898\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u95ee\u9898\u90fd\u914d\u6709\u7ed3\u6784\u5316\u63a8\u7406\u6b65\u9aa4\u548c\u751f\u6210\u771f\u5b9e\u89e3\u7684Python\u4ee3\u7801\u3002\u5305\u542b\u4e09\u79cd\u95ee\u9898\u683c\u5f0f\uff1aMC-Symbolic\u3001MC-Numerical\u548cfree-form\u3002\u5f15\u5165\u4e09\u4e2a\u65b0\u9896\u8bc4\u4f30\u6307\u6807\uff1a\u4e00\u81f4\u6027\u5206\u6570\u3001\u5931\u8d25\u7387\u548c\u6df7\u6dc6\u7387\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6700\u5148\u8fdb\u7684\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u65b9\u9762\u65e2\u6709\u4f18\u52bf\u4e5f\u6709\u5c40\u9650\uff0cSymPyBench\u80fd\u591f\u91cf\u5316\u6a21\u578b\u5728\u4e0d\u540c\u95ee\u9898\u53d8\u4f53\u4e0a\u7684\u53ef\u53d8\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "SymPyBench\u4e3a\u5f00\u53d1\u66f4\u9c81\u68d2\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002"}}
