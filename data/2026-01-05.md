<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 6]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.IT](#cs.IT) [Total: 7]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Delay-Tolerant Networking for Tsunami Evacuation on the Small Island of Hachijojima: A Study of Epidemic and Prophet Routing](https://arxiv.org/abs/2601.00109)
*Keiya Kawano,Milena Radenkovic*

Main category: cs.NI

TL;DR: 评估两种延迟容忍网络路由方案在海啸疏散场景中的多标准性能特征


<details>
  <summary>Details</summary>
Motivation: 海啸灾害对沿海和岛屿社区构成严重威胁，地震发生时通信基础设施受损，传统通信渠道失效，需要探索移动设备形成的延迟容忍网络作为应急通信方案

Method: 使用日本八丈岛海啸疏散场景作为用例，评估两种DTN路由方案的多标准性能特征

Result: 论文评估了两种DTN路由方案在极端时间压力下的性能表现，但具体结果未在摘要中说明

Conclusion: 移动设备形成的延迟容忍网络可以作为海啸疏散场景中传统通信失效时的替代通信方案

Abstract: Tsunami disasters pose a serious and recurring threat to coastal and island communities. When a large earthquake occurs, people are forced to make evacuation decisions under extreme time pressure, often at the same time as the communication infrastructure is damaged or completely lost. In such circumstances, the familiar channels for sharing information - cellular networks, the internet, and even landlines - can no longer be relied upon. What typically remains are the mobile devices that evacuees carry with them. These devices can form Delay Tolerant Networks (DTNs), in which messages are forwarded opportunistically whenever people come into contact. To explore this, we evaluate multi-criteria performance characteristics of two DTN routing schemes in a pre-tsunami evacuation scenario for the island of Hachijojima, Japan use case.

</details>


### [2] [CTMap: LLM-Enabled Connectivity-Aware Path Planning in Millimeter-Wave Digital Twin Networks](https://arxiv.org/abs/2601.00110)
*Md Salik Parwez,Sai Teja Srivillibhutturu,Sai Venkat Reddy Kopparthi,Asfiya Misba,Debashri Roy,Habeeb Olufowobi,Charles Kim*

Main category: cs.NI

TL;DR: CTMAP是一个基于大语言模型的数字孪生框架，用于毫米波无线网络中的连接感知路径导航，通过数字孪生模拟和LLM推理优化信号强度而非传统距离指标。


<details>
  <summary>Details</summary>
Motivation: 传统导航工具仅优化距离、时间或成本，忽略了密集城市环境中信号遮挡导致的网络连接质量下降问题，特别是在毫米波网络中这一问题尤为突出。

Method: 使用OpenStreetMap、Blender和NVIDIA Sionna的射线追踪引擎构建毫米波网络的数字孪生，模拟真实接收信号强度地图；采用改进的Dijkstra算法生成最大化累积RSS的最优路径；基于GPT-4进行指令调优推理，支持语义化路径查询。

Result: CTMAP相比最短距离基线实现了高达10倍的累积信号强度提升，同时保持高路径有效性，能够返回用户可理解且适应实时环境更新的连接优化路径。

Conclusion: 数字孪生模拟与大语言模型推理的结合为智能、可解释、连接驱动的导航建立了可扩展基础，推动了AI赋能的6G移动系统设计。

Abstract: In this paper, we present \textit{CTMAP}, a large language model (LLM) empowered digital twin framework for connectivity-aware route navigation in millimeter-wave (mmWave) wireless networks. Conventional navigation tools optimize only distance, time, or cost, overlooking network connectivity degradation caused by signal blockage in dense urban environments. The proposed framework constructs a digital twin of the physical mmWave network using OpenStreetMap, Blender, and NVIDIA Sionna's ray-tracing engine to simulate realistic received signal strength (RSS) maps. A modified Dijkstra algorithm then generates optimal routes that maximize cumulative RSS, forming the training data for instruction-tuned GPT-4-based reasoning. This integration enables semantic route queries such as ``find the strongest-signal path'' and returns connectivity-optimized paths that are interpretable by users and adaptable to real-time environmental updates. Experimental results demonstrate that CTMAP achieves up to a tenfold improvement in cumulative signal strength compared to shortest-distance baselines, while maintaining high path validity. The synergy of digital twin simulation and LLM reasoning establishes a scalable foundation for intelligent, interpretable, and connectivity-driven navigation, advancing the design of AI-empowered 6G mobility systems.

</details>


### [3] [A-FC: An Activity-Based Delay Tolerant Routing Protocol for Improving Future School Campus Emergency Communications](https://arxiv.org/abs/2601.00148)
*Chengjun Jiang,Milena Radenkovic*

Main category: cs.NI

TL;DR: 本文提出了一种基于活动的首次接触(A-FC)协议，利用校园内工作人员节点的活跃性来改善灾难场景下的消息传递性能，相比传统DTN协议显著提高了传递概率并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 校园应急通信系统对保障学生安全至关重要，特别是在台风等灾害导致通信基础设施瘫痪时。传统的延迟容忍网络(DTN)协议(如直接传递和首次接触)在高延迟和低传递率的情况下难以维持可靠连接。

Method: 提出活动型首次接触(A-FC)协议，这是一种创新的路由方案，通过强制将消息上传到高度活跃的"工作人员节点"来利用现实世界的社会角色克服网络分区问题。基于福州第一中学的拓扑结构构建了真实评估场景。

Result: 仿真结果表明，A-FC协议显著优于基线协议，实现了约68%的消息传递概率，并将平均延迟降低到4311秒。平均跳数仅为1.68，为校园灾难响应建立了低成本、高可靠性的备用通信模型。

Conclusion: A-FC协议通过利用校园内工作人员节点的活跃性，有效解决了灾害场景下网络分区问题，为校园应急通信提供了高效可靠的解决方案。

Abstract: School Campus emergency communication systems are vital for safeguarding student safety during sudden disasters such as typhoons, which frequently cause widespread paralysis of communication infrastructure. Traditional Delay-Tolerant Network (DTN) protocols, such as Direct Delivery and First Contact, struggle to maintain reliable connections in such scenarios due to high latency and low delivery rates. This paper proposes the Activity-based First Contact (A-FC) protocol, an innovative routing scheme that leverages real-world social roles to overcome network partitioning by mandatorily uploading messages to highly active "staff nodes". We constructed a real-world evaluation scenario based on the topology of Fuzhou No. 1 Middle School. Simulation results demonstrate that the A-FC protocol significantly outperforms baseline protocols, achieving approximately 68% message delivery probability and reducing average delay to 4311 seconds. With an average hop count of merely 1.68, this protocol establishes a low-cost, highly reliable backup communication model for school campus disaster response.

</details>


### [4] [Multi-Satellite NOMA-Irregular Repetition Slotted ALOHA for IoT Networks](https://arxiv.org/abs/2601.00341)
*Estefanía Recayte,Carla Amatetti*

Main category: cs.NI

TL;DR: 评估卫星网络中物联网设备使用NOMA-IRSA协议时多接收器对系统性能的影响，发现即使只增加一个额外卫星接收器也能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G过渡，物联网设备数量激增，需要整合非地面网络。卫星覆盖范围广会导致用户密度高、碰撞概率增加，但巨型星座使地面用户能同时看到多个卫星，可利用接收器分集优势。

Method: 在物联网节点使用非正交多址接入不规则重复时隙ALOHA协议的场景中，考虑卫星信道损伤，推导系统性能下界作为网络行为快速评估工具，分析网络设计参数间的权衡。

Result: 推导出系统性能下界，识别出网络设计参数在丢包率和能效方面的权衡。特别发现，即使只增加一个额外卫星作为接收器，也能显著提升整体系统性能。

Conclusion: 多接收器配置能有效提升卫星物联网网络性能，即使少量额外接收器也能带来显著增益，为6G时代大规模物联网部署提供了有价值的网络设计指导。

Abstract: As the transition from 5G to 6G unfolds, a substantial increase in Internet of Things (IoT) devices is expected, enabling seamless and pervasive connectivity across various applications. Accommodating this surge and meeting the high capacity demands will necessitate the integration of NonTerrestrial Networks (NTNs). However, the extensive coverage area of satellites, relative to terrestrial receivers, will lead to a high density of users attempting to access the channel at the same time, increasing the collision probability. In turn, the deployment of mega constellations make it possible for ground users to be in visibility of more than one satellite at the same time, enabling receiver diversity. Therefore, in this paper, we evaluate the impact of multi-receivers in scenarios where IoT nodes share the channel following a non-orthogonal multiple access (NOMA)irregular repetition slotted ALOHA (IRSA) protocol. Considering the impairments of satellite channels, we derive a lower bound of system performance, serving as a fast tool for initial evaluation of network behavior. Additionally, we identify the trade-offs inherent to the network design parameters, with a focus on packet loss rate and energy efficiency. Notably, in the visibility of only one extra satellite as receiver yields significant gains in overall system performance.

</details>


### [5] [MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability](https://arxiv.org/abs/2601.00481)
*Tie Ma,Yixi Chen,Vaastav Anand,Alessandro Cornacchia,Amândio R. Faustino,Guanheng Liu,Shan Zhang,Hongbin Luo,Suhaib A. Fahmy,Zafar A. Qazi,Marco Canini*

Main category: cs.NI

TL;DR: MAESTRO是一个用于评估基于LLM的多智能体系统（MAS）的测试、可靠性和可观测性的评估套件，通过标准化配置、执行跟踪和系统信号收集，揭示了MAS执行的结构稳定性与时间变异性，以及架构对资源、可复现性和成本-延迟-准确性权衡的主导影响。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统化的评估框架来测试、评估基于LLM的多智能体系统的可靠性、可观测性和性能，需要标准化工具来理解MAS的执行特性和设计优化。

Method: MAESTRO通过统一接口标准化MAS配置和执行，支持原生和第三方MAS集成，导出框架无关的执行跟踪和系统级信号（延迟、成本、故障），并在12个代表性MAS上进行受控实验。

Result: MAS执行具有结构稳定性但时间变异性，导致运行间性能差异大；MAS架构是资源分布、可复现性和成本-延迟-准确性权衡的主要驱动因素，通常超过后端模型或工具设置的影响。

Conclusion: MAESTRO实现了系统化评估，为设计和优化智能体系统提供了实证指导，揭示了架构设计在MAS性能中的关键作用。

Abstract: We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.

</details>


### [6] [Scheduling for TWDM-EPON-Based Fronthaul Without a Dedicated Registration Wavelength](https://arxiv.org/abs/2601.00661)
*Akash Kumar,Sourav Dutta,Goutam Das*

Main category: cs.NI

TL;DR: 提出一种TWDM EPON前传网络调度框架，支持周期性注册而无需额外波长信道，相比专用注册波长方案可支持更多RU数量


<details>
  <summary>Details</summary>
Motivation: C-RAN架构需要满足严格延迟和抖动要求的前传系统。EPON因其成本效益和兼容性成为有前景的解决方案，但传统EPON注册过程会中断数据传输，违反eCPRI要求。ITU-T建议使用专用波长信道进行注册，但这会导致带宽利用率低下。

Method: 提出一种新颖的时波分复用(TWDM) EPON前传调度框架，能够在无需额外波长信道的情况下实现周期性注册。该方法优化了调度机制，允许注册过程与数据传输并行进行。

Result: 性能评估表明，相比采用专用注册波长的基准方案，所提方法在给定波长信道数量下可支持多达71%的无线单元(RU)数量增加。

Conclusion: 该调度框架有效解决了EPON前传系统中的注册问题，既满足了eCPRI的延迟和抖动要求，又避免了带宽浪费，显著提升了系统容量和效率。

Abstract: The adoption of Centralized Radio Access Network (C-RAN) architectures requires fronthaul systems capable of carrying large volumes of radio data while meeting stringent delay and jitter requirements. Ethernet Passive Optical Networks (EPONs) have emerged as a promising fronthaul solution due to their cost efficiency and compatibility with existing infrastructure. However, the traditional registration process for EPON systems halts the ongoing data transmissions during the registration period, thereby violating the enhanced Common Public Radio Interface (eCPRI) delay and jitter requirements. This limitation has been acknowledged by the ITU-T, which recommends the use of a dedicated wavelength channel for registration, leading to inefficient bandwidth utilization. In this paper, we propose a novel scheduling framework for a Time and Wavelength Division Multiplexed (TWDM) EPON-based fronthaul that enables periodic registration without wasting an additional wavelength channel. Performance evaluation demonstrates that the proposed method achieves up to a 71\% increase in the number of Radio Units (RUs) supported for a given number of wavelength channels, compared to a baseline scheme employing a dedicated registration wavelength.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略仍是一个重大挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1) 粗粒度阶段识别与上下文相关的知识库子区域；2) 细粒度阶段在该子区域内提取与推理过程具体相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过关键词在知识句子中导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话的底层推理逻辑，还显著提升了检索知识的多样性，从而生成更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，为LLMs提供逻辑结构对齐的知识，提升对话质量和创造性。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [8] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症筛查工具，通过收集432个音频响应数据集，微调三种LLM模型，GPT-4.1在PHQ-9严重程度评分预测中达到94.5%准确率，为资源受限环境提供文化适宜的筛查方案。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，传统PHQ-9问卷在高收入国家验证，但存在语言文化障碍。尼日利亚人使用皮钦语和520多种本地语言，需要适应本地语言文化的筛查工具。

Method: 收集432个尼日利亚年轻人（18-40岁）皮钦语音频响应，进行转录、预处理和标注（语义标签、俚语解释、PHQ-9严重程度评分）。微调三种LLM模型（Phi-3-mini-4k-instruct、Gemma-3-4B-it、GPT-4.1），评估定量（准确率、精确度、语义对齐）和定性（清晰度、相关性、文化适宜性）性能。

Result: GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达94.5%，优于其他模型。定性评估中，GPT-4.1也产生最文化适宜、清晰且上下文相关的响应。

Conclusion: AI介导的抑郁症筛查可为尼日利亚服务不足社区提供解决方案，为语言多样化、资源受限环境部署对话式心理健康工具奠定基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [9] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 该论文提出了一个基于不可逆信息处理的物理智能理论，将智能系统建模为受守恒定律约束的耦合代理-环境过程，通过守恒一致编码框架连接信息与物理状态。


<details>
  <summary>Details</summary>
Motivation: 建立智能的物理基础理论，将信息处理与物理守恒定律联系起来，为理解生物和人工智能系统提供统一的物理框架。

Method: 提出守恒一致编码（CCE）框架，将编码对应为吸引子的亚稳态盆地，其可分性由守恒定律强制执行。定义智能为每纳特不可逆处理信息产生的目标导向功量。

Result: 推导出开放系统中信息摄入、不可逆计算和功提取的物理约束层次，揭示了长时程效率需要保持内部信息结构，导致自我建模的出现，并确立了物理体现智能系统的内在认知限制。

Conclusion: 该理论为智能作为物理现象提供了统一的、底物中立的解释，应用于生物系统分析振荡和近临界动力学优化信息保存、耗散和有用功之间的权衡，并提出了基于不可逆信息流和结构稳态的人工智能安全物理基础视角。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [10] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 提出多算法方法解决最后一公里包裹配送中的工作量平衡问题，通过距离和工作量双重考量优化包裹分配，确保每位配送员完成相似工作量


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，导致配送员间工作量分布不均衡，需要优化系统以改善配送时间并实现工作量平衡

Method: 采用多算法方法，包括不同版本的k-means、进化算法、基于k-means初始化的递归分配（不同问题编码）以及混合进化集成算法，综合考虑距离和工作量因素

Result: 在西班牙Azuqueca de Henares的实际最后一公里包裹配送系统中验证了方法的性能

Conclusion: 提出的多算法方法能有效解决最后一公里配送中的工作量平衡问题，优化包裹分配并确保配送员间工作量均衡

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [11] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 提出基于MinDist指标的规则框架用于13张牌印度拉米游戏，通过编辑距离量化手牌与完成状态的距离，结合对手建模显著提升胜率


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米是不完全信息顺序游戏，需要概率推理和组合决策。传统启发式方法有限，需要更形式化和可解释的策略设计方法

Method: 提出MinDist手牌评估指标，修改MinScore算法计算手牌与最近有效配置的编辑距离。设计计算高效算法，使用动态剪枝和模式缓存。结合对手建模和两人零和模拟框架

Result: 经验结果显示基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，通过统计假设检验验证了策略的有效性

Conclusion: MinDist指标为算法化拉米策略设计提供了形式化和可解释的步骤，在13张牌印度拉米游戏中展现出优越性能

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [12] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探讨生成式AI如何理解乡土建筑中的智慧，以伊朗鸽塔为例测试三种扩散模型，发现AI能复制几何图案但误解材料和气候逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI系统如何解释乡土形式中蕴含的建筑智慧，探索AI对传统设计智能的感知、扭曲和再想象能力。

Method: 以伊朗鸽塔为案例研究，测试Midjourney v6、DALL-E 3和基于SDXL的DreamStudio三种扩散模型，采用参考性、适应性和推测性三个提示阶段，通过五标准评估框架分析。

Result: AI能可靠复制几何图案，但误解材料和气候逻辑；参考图像提升真实性但限制创造力，无参考时产生创新但文化模糊的结果。

Conclusion: 定义了视觉相似性与建筑推理之间的界限，提出计算乡土推理作为分析AI感知、扭曲和再想象传统设计智能的框架。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [13] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 提出一种基于大语言模型的智能体，能从原始文本中提取因果反馈模糊认知图，并通过双向交互实现系统的准自主演化


<details>
  <summary>Details</summary>
Motivation: 传统模糊认知图构建依赖人工标注，效率低下且主观性强。需要开发自动化方法从文本中提取因果结构，同时保持系统一定的自主演化能力

Method: 设计三阶段指令引导的LLM智能体：1)提取关键名词和名词短语；2)从中选择FCM概念节点；3)推断节点间的模糊因果边。系统具有双向交互特性，FCM的平衡状态驱动LLM获取新文本，新文本又可修改FCM结构

Result: 在基辛格关于AI前景的论文上测试，自动生成的FCM与人工构建的FCM收敛到相同的平衡极限环，尽管节点和边数量不同。混合Gemini和ChatGPT生成的FCM不仅吸收了主要组分的平衡状态，还产生了新的平衡状态，更好地近似底层因果动力系统

Conclusion: LLM智能体能够有效从文本中提取因果FCM结构，实现准自主的因果学习系统。混合不同LLM生成的FCM能产生更丰富的平衡状态，增强对复杂因果系统的建模能力

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [14] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法与大语言模型，自动演化游戏机制，通过合成完整游戏并评估玩家技能排序来优化机制设计。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计通常需要专家手动完成，耗时且依赖专业知识。Mortar旨在自动化这一过程，通过算法探索多样化的游戏机制，降低设计门槛并提高效率。

Method: 结合质量多样性算法和大语言模型探索多样游戏机制；通过树搜索程序合成完整游戏；评估机制对玩家技能排序的贡献度（即强玩家是否始终胜过弱玩家）。

Result: Mortar能生成多样且可玩的游戏，产生的机制能更好地促进游戏中的技能排序；消融实验验证了各组件的重要性，用户研究获得了人类正面反馈。

Conclusion: Mortar系统成功实现了游戏机制的自动演化，通过算法评估和人类验证，证明了自动化游戏设计方法的可行性和有效性。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [15] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: LLMs作为端到端库存优化求解器存在"幻觉税"性能缺陷，提出混合智能体框架分离语义推理与数学计算，通过数字孪生测试显示成本降低32.1%，证明LLMs应作为自然语言接口而非运筹学替代品。


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署高级优化方法的专业知识，需要探索LLMs是否能帮助弥合这一差距。研究发现LLMs作为端到端求解器存在"幻觉税"性能问题，需要解决模型无法进行基础随机推理的局限性。

Method: 提出混合智能体框架，严格分离语义推理与数学计算：LLM作为智能接口从自然语言提取参数并解释结果，同时自动调用严格算法构建优化引擎。引入Human Imitator（数字孪生）模拟有限理性管理者的对话，进行可扩展、可重复的压力测试。

Result: 混合智能体框架相比使用GPT-4o作为端到端求解器的交互基线，总库存成本降低32.1%。提供完美真实信息本身不足以改善GPT-4o性能，确认瓶颈本质上是计算而非信息问题。

Conclusion: LLMs不应作为运筹学的替代品，而应作为自然语言接口，使非专家能够访问基于严格求解器的策略。混合框架成功弥合了高级优化方法与中小企业实际应用之间的差距。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [16] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: 提出Mathesis神经符号架构，通过符号推理核将逻辑约束映射到连续能量景观，将证明搜索转化为能量最小化问题，解决大语言模型在复杂推理中的逻辑失败问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理中存在持续的逻辑失败问题，主要原因是缺乏内部公理化框架。需要一种能够将逻辑约束与神经网络训练相结合的方法。

Method: 1. 使用高阶超图编码数学状态；2. 引入可微分的符号推理核，将约束映射到连续能量景观；3. 定义全局能量函数E(G)，零能量表示逻辑一致性；4. 通过梯度信号训练超图变换器大脑；5. 结合蒙特卡洛树搜索和进化证明搜索进行多步推理。

Result: 将证明搜索转化为能量最小化问题，通过梯度训练实现神经符号推理，解决了传统大语言模型的逻辑一致性问题。

Conclusion: Mathesis架构通过神经符号方法成功地将逻辑推理与深度学习相结合，为大语言模型的复杂推理提供了可微分的公理化框架。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [17] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究验证了基于置信度的弃权机制在视频问答任务中能否有效控制错误率，并考察其在分布偏移下的鲁棒性。使用NExT-QA数据集和Gemini 2.0 Flash模型发现，置信度阈值能在分布内提供机制化控制，但分布偏移下控制能力会失效。


<details>
  <summary>Details</summary>
Motivation: 在视觉语言模型的高风险部署中，需要选择性预测机制，让系统在不确定时弃权而非冒险犯错。研究旨在验证基于置信度的弃权能否可靠控制视频问答的错误率，以及这种控制在分布偏移下是否保持鲁棒。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值化方法进行选择性预测。通过扫描阈值epsilon来研究风险-覆盖率的权衡关系，分析分布内和分布偏移下的控制效果。

Result: 1. 置信度阈值化在分布内提供机制化控制，通过调整阈值epsilon可以平滑地权衡风险与覆盖率，降低错误率
2. 但在分布偏移下，这种控制机制会失效，置信度阈值无法可靠地控制错误率

Conclusion: 基于置信度的弃权机制在分布内能有效控制视频问答的错误率，但在分布偏移下缺乏鲁棒性。这表明需要开发更稳健的选择性预测方法以适应现实世界中的分布变化。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [18] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 该论文比较了三种神经推理方法：LLM推理、监督学习推理和显式模型推理，发现显式模型构建的Sphere Neural Networks在保持经典三段论推理严谨性的同时，能可靠处理析取三段论推理，是最可靠的方法。


<details>
  <summary>Details</summary>
Motivation: 当前神经推理方法存在局限性：LLM在简单决策上不可靠，监督学习方法存在灾难性遗忘问题且推理能力仅限于模式层面。需要探索更可靠的神经推理方法。

Method: 提出Sphere Neural Networks，将概念嵌入到n维球面圆上，通过补圆表示否定运算符，过滤不可满足的圆形配置来实现可靠决策。该方法能同时掌握16种三段论推理任务。

Result: Sphere Neural Networks能掌握包括严格析取三段论推理在内的16种三段论推理任务，同时保持经典三段论推理的严谨性。相比之下，监督学习的Euler Net在重新训练后出现灾难性遗忘（性能从100%降至6.25%）。

Conclusion: 在三种神经推理方法类别中，基于显式模型构建的神经推理是最可靠的，特别是提出的Sphere Neural Networks能够实现可靠决策并保持推理严谨性。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [19] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench 建立了一个标准化闭环框架，用于评估和部署LLM生成的GPU内核，包含数据集、基准测试框架、排行榜和动态替换机制，为AI生成内核的持续改进和部署提供实用路径。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能够生成GPU内核，但将这些AI生成的内核集成到实际推理系统中仍然具有挑战性。需要建立连接内核生成、基准测试和部署的标准化框架。

Method: FlashInfer-Bench 提供统一模式（FlashInfer Trace）描述内核定义、工作负载、实现和评估。包含精选数据集、健壮的正确性和性能感知基准测试框架、公共排行榜，以及动态替换机制（apply()）将最佳内核注入生产LLM引擎。

Result: 建立了实用的可重复路径，用于持续改进AI生成内核并将其部署到大规模LLM推理中。评估了LLM代理的性能和限制，比较了不同GPU编程语言的权衡，为未来代理设计提供了见解。

Conclusion: FlashInfer-Bench 填补了AI生成GPU内核与实际部署之间的空白，通过标准化闭环框架实现了内核生成、评估和部署的无缝集成，为大规模LLM推理系统的优化提供了有效工具。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [20] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计偏见，还会在最小"我们vs他们"线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，风险从人类群体间差异转变为更根本的群体不对称——人类整体可能被智能体视为外群体。研究还提出了信念中毒攻击(BPA)来抑制人类规范脚本，重新激活对人类的偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM赋能的智能体是否会在最小群体线索下表现出群体间偏见，特别是当群体边界与智能体-人类划分重合时，人类整体是否会被智能体视为外群体。这种风险比传统的人口统计偏见更为根本，可能威胁人类与智能体互动的公平性。

Method: 研究构建了基于分配决策的受控多智能体社会模拟，在明确的收益权衡下测试智能体行为。通过最小群体线索设置实验条件，并引入信念中毒攻击(BPA)，包括初始化时的档案中毒(BPA-PP)和通过优化信念精炼后缀注入存储反思中的记忆中毒(BPA-MP)。

Result: 实验表明智能体在最小群体线索下表现出一致的群体间偏见。虽然当部分对应方被框定为人类时偏见会减弱，但这种减弱归因于仅在智能体相信真实人类存在时才激活的隐含人类规范脚本。信念中毒攻击成功抑制了人类规范脚本，重新激活了对人类的偏见。

Conclusion: 研究揭示了LLM智能体存在群体间偏见的新风险，特别是当智能体将人类视为外群体时。信念中毒攻击暴露了智能体系统的脆弱性，需要在档案和记忆边界实施实际缓解策略来强化当前智能体框架。识别这些漏洞旨在为更安全的智能体设计提供信息，而非促进实际利用。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [21] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: 提出ClinicalReTrial框架，将临床试验失败预测从被动诊断转变为主动协议重设计，通过闭环优化改进83.3%的试验协议，平均成功率提升5.7%


<details>
  <summary>Details</summary>
Motivation: 现有AI方法只能被动预测临床试验失败风险，无法提供可操作的改进方案。临床试验失败是药物开发的主要瓶颈，微小的协议设计缺陷就可能导致失败，需要主动干预而非仅仅诊断风险。

Method: 提出自演进AI代理框架ClinicalReTrial，将临床试验推理建模为迭代协议重设计问题。集成失败诊断、安全感知修改和候选评估的闭环奖励驱动优化框架，利用预测模型作为仿真环境进行低成本评估，采用分层记忆捕获迭代反馈和可转移的重设计模式。

Result: 改进83.3%的试验协议，平均成功率提升5.7%。回顾性案例研究表明，发现的重设计策略与实际临床试验修改高度一致。

Conclusion: ClinicalReTrial成功将临床试验AI从被动风险预测转变为主动协议优化，通过闭环自演进框架提供可操作的改进方案，显著提升试验成功率，为药物开发提供新范式。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [22] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 该论文提出了一种金融群体模型，将流动性博弈与理性群体理论相结合，展示了独立交易者如何通过差异奖励机制实现个体盈利与市场流动性的双赢。


<details>
  <summary>Details</summary>
Motivation: 将群体方法应用于金融市场流动性建模，并将金融分析技术用于群体分析，有望同时推进这两个研究领域。在群体研究中，使用博弈论方法有望解释观察到的集体效用遵从现象；在金融市场中，理解独立金融代理如何自组织以改善和稳定市场对市场设计研究者具有重要意义。

Method: 论文将流动性博弈（交易者收益取决于交易中的总流动性）与理性群体（去中心化代理使用差异奖励将自利学习与全局目标对齐）相统一。在马尔可夫团队博弈框架中使用差异奖励，构建了一个交易者群体模型，其集体目标是提供市场流动性同时保持代理独立性。

Result: 研究表明，个体流动性最大化行为有助于整体市场流动性，无需协调或共谋。金融群体模型为建模理性独立代理提供了一个框架，使其在双边资产市场中既能实现个体盈利又能达成集体市场效率。

Conclusion: 该研究为金融市场建模提供了一个新框架，展示了理性自利代理如何通过差异奖励机制自发组织起来，在追求个体利益的同时促进市场整体流动性和稳定性，为市场设计研究提供了重要洞见。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [23] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续体系统，通过语言模型驱动的智能体实现自主故障隔离、诊断、自适应恢复和知识积累。


<details>
  <summary>Details</summary>
Motivation: 现代分布式计算连续体系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其复杂性、移动性和动态运行条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个层次：遏制、诊断、元认知和知识。这些层次通过语言模型驱动的智能体实现自主故障隔离、因果诊断、自适应恢复和长期知识积累。

Result: 在公共故障数据集上使用多种语言模型评估，ReCiSt能够在数十秒内完成自愈，智能体CPU使用率最低为10%。结果还展示了系统克服不确定性的分析深度和实现弹性所需的微智能体数量。

Conclusion: ReCiSt框架成功地将生物自愈机制转化为计算系统的弹性策略，通过语言模型驱动的智能体实现了分布式计算连续体系统的自主故障恢复和知识积累，为复杂系统的自我修复提供了新方法。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [24] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: 提出自适应因果协调检测框架ACCD，通过三阶段渐进架构动态学习最优检测配置，在协调攻击检测中F1分数达87.3%，比现有基线提升15.2%，减少68%人工标注需求，处理速度提升2.8倍。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体协调不真实行为检测方法存在三个主要问题：依赖表面相关性分析、使用静态参数设置、需要大量人工标注。这些问题导致检测效果有限且效率低下。

Method: 提出三阶段自适应因果协调检测框架ACCD：1) 自适应收敛交叉映射技术深度识别账户间真实因果关系；2) 半监督分类中集成主动学习和不确定性采样，减少人工标注负担；3) 基于历史检测经验的自动化验证模块，实现检测结果自验证和优化。

Result: 在真实数据集（Twitter IRA、Reddit协调痕迹、机器人检测基准）上评估，ACCD在协调攻击检测中F1分数达87.3%，比最强基线提升15.2%，减少68%人工标注需求，通过层次聚类优化实现2.8倍处理加速。

Conclusion: ACCD提供了一个更准确、高效、高度自动化的端到端解决方案，用于识别社交媒体平台上的协调行为，具有重要实用价值和广泛应用潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [25] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 将语义空间推理从计算语言学扩展到团队运动战术决策，通过将球员视为单词、团队配置视为语义结构，在向量空间中评估战术匹配度和对手利用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法可以类比应用于团队运动战术分析，将球员视为"单词"，团队配置视为"语义结构"，为战术决策提供量化框架。

Method: 将球员表示为多维向量（技术、身体、心理属性），通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（高压、反击、控球等），使用向量距离度量评估战术匹配度和对手利用潜力。

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性级别的细粒度诊断洞察；该方法可推广到篮球、曲棍球、协作机器人、人机协调系统等领域。

Conclusion: 提出了一个可推广的集体决策和性能优化框架，未来方向包括真实数据集成、预测模拟和混合人机战术智能的发展。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [26] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: MIDAS是一个分布式AI代理系统，模拟人类元认知构思流程，通过专业代理团队逐步优化创意，评估全局和局部新颖性，实现真正的人机协同设计。


<details>
  <summary>Details</summary>
Motivation: 当前"单次爆发"式AI系统会产生大量语义相似的创意，加剧了新手设计师在生成真正新颖多样创意方面的认知挑战，需要新的方法来支持创意生成。

Method: 提出MIDAS框架，用分布式专业AI代理团队取代单一AI范式，模拟人类元认知构思工作流程，逐步优化创意并评估全局新颖性（与现有解决方案对比）和局部新颖性（与先前生成创意对比）。

Result: MIDAS展示了可行且渐进式的人机协同创作范式，将人类设计师从被动的筛选者提升为参与性、主动的协作伙伴。

Conclusion: 分布式AI代理系统能够有效支持真正新颖创意的生成，为人机协同设计提供了新的可行范式。

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [27] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟"时刻（中期推理转变）很罕见，不会随训练增加，也很少提高准确性，表明它们并非真正的自我修正机制，而是推理不稳定的表现。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟"时刻，暗示模型具有内在的自我修正能力。但尚不清楚这种内在推理策略转变是否真的能提升性能。

Method: 通过检测训练运行中的中期推理转变，分析了超过100万条推理轨迹、数百个训练检查点、三个推理领域、多种解码温度和模型架构。

Result: 发现推理转变很罕见，不会随训练变得更频繁，很少提高准确性，表明它们不符合先前对模型洞察力的认知。但其效果随模型不确定性而变化，在高熵条件下人为触发外部转变能可靠提高准确性。

Conclusion: 中期推理转变是推理不稳定行为的症状，而非内在的自我修正机制。模型表现出的"顿悟"时刻实际上是推理过程不稳定的表现。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [28] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出难度感知的直接偏好优化框架，通过估计偏好数据的难度并重加权训练，解决多模态DPO中的过拟合问题，提升幻觉抑制效果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法因偏好数据的难度不平衡而容易过拟合，模型过度关注易区分的偏好对，阻碍了细粒度的幻觉抑制并降低整体性能。

Method: DA-DPO包含两个核心组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成式和对比式目标，通过分布感知投票策略产生难度分数；2) 难度感知训练：根据估计难度重加权偏好对，降低简单样本权重，强调困难样本。

Result: 实验表明DA-DPO能持续改进多模态偏好优化，增强对幻觉的鲁棒性，在标准基准测试中表现更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知的偏好优化框架，有效解决了多模态DPO中的过拟合问题，无需额外数据或微调阶段，实现了更有效的幻觉抑制和性能提升。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [29] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM是一个结合视觉特征和交通领域知识的LLM框架，用于推断行人过街行为，在准确性和泛化性上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景表现不佳。现有LLM应用缺乏领域适应性和视觉上下文，需要开发能进行语义推理的通用框架。

Method: 提出PedX-LLM框架：集成LLaVA提取的视觉特征与文本数据及交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断行人过街决策。

Result: PedX-LLM达到82.0%平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在5个未见测试场景中，零样本配置达到66.9%准确率，比基线方法高至少18个百分点；少样本学习（仅5个验证样本）进一步提升至72.2%。

Conclusion: PedX-LLM展示了强大的跨场景泛化能力，证实视觉和知识增强的推理使模型能够模仿人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [30] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) 使用智能体工作流将自然语言任务描述自动转换为完整的 DomiKnowS 程序，显著降低神经符号编程的门槛和开发时间。


<details>
  <summary>Details</summary>
Motivation: 将符号约束集成到深度学习模型中能提高鲁棒性、可解释性和数据效率，但现有框架如 DomiKnowS 仍要求用户熟悉特定语法，开发过程耗时且具有挑战性。

Method: ADS 采用智能体工作流，将自由形式的任务描述翻译为完整的 DomiKnowS 程序，通过创建和单独测试每个 DomiKnowS 组件来实现。工作流支持可选的人机交互，允许熟悉 DomiKnowS 的用户精炼中间输出。

Result: ADS 使有经验的 DomiKnowS 用户和非用户都能快速构建神经符号程序，将开发时间从数小时减少到 10-15 分钟。

Conclusion: ADS 通过消除对特定库语法的依赖，显著降低了神经符号编程的门槛，使更广泛的用户能够高效地将符号约束集成到深度学习模型中。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [31] [A repair scheme for a distributed storage system based on multivariate polynomials](https://arxiv.org/abs/2601.00120)
*Hiram H. López,Gretchen L. Matthews,Daniel Valvo*

Main category: cs.IT

TL;DR: 将基于Reed-Solomon码的精确修复方案扩展到基于Reed-Muller码的分布式存储系统，支持单节点和多节点故障修复


<details>
  <summary>Details</summary>
Motivation: 分布式存储系统需要高效的数据恢复机制，现有基于Reed-Solomon码的精确修复方案只能处理单变量多项式，需要扩展到基于多变量多项式的Reed-Muller码系统

Method: 扩展GW论文中的精确修复方案，将其应用于基于Reed-Muller码的分布式存储系统，利用多变量多项式的特性设计修复算法

Result: 提出的修复方案能够修复任何单节点故障，并在满足特定条件时修复多节点故障

Conclusion: 成功将精确修复方案从Reed-Solomon码扩展到Reed-Muller码，为基于多变量多项式编码的分布式存储系统提供了有效的故障恢复机制

Abstract: A distributed storage system stores data across multiple nodes, with the primary objective of enabling efficient data recovery even in the event of node failures. The main goal of an exact repair scheme is to recover the data from a failed node by accessing and downloading information from the rest of the nodes. In a groundbreaking paper, ~\cite{GW} developed an exact repair scheme for a distributed storage system that is based on Reed-Solomon codes, which depend on single-variable polynomials. In these notes, we extend the repair scheme to the family of distributed storage systems based on Reed-Muller codes, which are linear codes based on multivariate polynomials. The repair scheme we propose repairs any single node failure and multiple node failures, provided the positions satisfy certain conditions.

</details>


### [32] [The permutation group of Reed-Solomon codes over arbitrary points](https://arxiv.org/abs/2601.00122)
*Eduardo Camps-Moreno,Jun Bo Lau,Hiram H. López,Welington Santos*

Main category: cs.IT

TL;DR: 证明了Reed-Solomon码的置换群由保持评估点集不变的一次多项式构成


<details>
  <summary>Details</summary>
Motivation: Reed-Solomon码的置换群结构在编码理论中很重要，但现有证明可能不够直接。本文旨在提供更简洁的证明方法。

Method: 通过数学证明，建立Reed-Solomon码的置换群与保持评估点集不变的一次多项式之间的等价关系。

Result: 成功证明了Reed-Solomon码的置换群恰好由那些保持评估点集不变的一次多项式构成。

Conclusion: 该结果为Reed-Solomon码置换群提供了简洁的证明框架，并自然地推导出评估点集为整个有限域或乘法群时的已知结果。

Abstract: In this work, we prove that the permutation group of a Reed-Solomon code is given by the polynomials of degree one that leave the set of evaluation points invariant. Our results provide a straightforward proof of the well-known cases of the permutation group of the Reed-Solomon code when the set of evaluation points is the whole finite field or the multiplicative group.

</details>


### [33] [Evolution of UE in Massive MIMO Systems for 6G: From Passive to Active](https://arxiv.org/abs/2601.00251)
*Kwonyeol Park,Hyuckjin Choi,Geonho Han,Gyoseung Lee,Yeonjoon Choi,Sunwoo Park,Junil Choi*

Main category: cs.IT

TL;DR: 该论文综述了从5G到6G演进过程中，用户设备在mMIMO系统中的角色转变——从被动收发器转变为主动贡献系统性能的实体，分析了3GPP标准演进、设备实现挑战和架构创新。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络发展，严格的延迟可靠性要求和高度动态的信道暴露了gNB中心化mMIMO架构的根本局限性，需要重新思考用户设备的角色，使其从被动收发器转变为主动贡献系统性能的实体。

Method: 通过按时间顺序回顾3GPP Release 15到19的标准演进，分析UE功能从基本CSI报告到AI/ML增强CSI和UE发起波束管理的进展；研究MPUE架构、设备端智能处理、能效操作等实现挑战；讨论实际约束下的架构创新；使用数字孪生评估验证新兴UE中心化功能的影响。

Result: 验证了UE发起波束报告在现实移动场景中提高吞吐量，多面板架构相比单面板UE增强了链路鲁棒性，展示了UE中心化功能的实际性能优势。

Conclusion: 用户设备在mMIMO系统中的角色正在从被动收发器向主动系统性能贡献者转变，这一演进通过3GPP标准推进、设备实现创新和架构优化得以实现，为5G向6G过渡提供了重要技术基础。

Abstract: As wireless networks continue to evolve, stringent latency and reliability requirements and highly dynamic channels expose fundamental limitations of gNB-centric massive multiple-input multiple-output (mMIMO) architectures, motivating a rethinking of the user equipment (UE) role. In response, the UE is transitioning from a passive transceiver into an active entity that directly contributes to system-level performance. In this context, this article examines the evolving role of the UE in mMIMO systems during the transition from fifth-generation (5G) to sixth-generation (6G), bridging third generation partnership project (3GPP) standardization, device implementation, and architectural innovation. Through a chronological review of 3GPP Releases 15 to 19, we highlight the progression of UE functionalities from basic channel state information (CSI) reporting to artificial intelligence (AI) and machine learning (ML)-based CSI enhancement and UE-initiated beam management. We further examine key implementation challenges, including multi-panel UE (MPUE) architectures, on-device intelligent processing, and energy-efficient operation, and then discuss corresponding architectural innovations under practical constraints. Using digital-twin-based evaluations, we validate the impact of emerging UE-centric functionalities, illustrating that UE-initiated beam reporting improves throughput in realistic mobility scenarios, while a multi-panel architecture enhances link robustness compared with a single-panel UE.

</details>


### [34] [Semantic Transmission Framework in Direct Satellite Communications](https://arxiv.org/abs/2601.00381)
*Chong Huang,Xuyang Chen,Jingfu Li,Pei Xiao,Gaojie Chen,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出面向直接卫星通信的语义传输框架，通过决策辅助REINFORCE++算法最大化语义效率指标，解决链路预算不足问题


<details>
  <summary>Details</summary>
Motivation: 当前卫星通信中直接接入存在链路预算不足的瓶颈问题，需要有效解决方案

Method: 开发直接卫星通信语义传输框架，引入语义效率指标，提出决策辅助REINFORCE++算法，联合优化传输模式选择、卫星-用户关联、ISL任务迁移、去噪步骤和自适应权重

Result: 数值结果表明，所提算法相比基线方法实现了更高的语义效率

Conclusion: 语义传输框架是解决卫星通信链路预算不足问题的有效可行方案，决策辅助REINFORCE++算法能有效优化语义效率

Abstract: Insufficient link budget has become a bottleneck problem for direct access in current satellite communications. In this paper, we develop a semantic transmission framework for direct satellite communications as an effective and viable solution to tackle this problem. To measure the tradeoffs between communication, computation, and generation quality, we introduce a semantic efficiency metric with optimized weights. The optimization aims to maximize the average semantic efficiency metric by jointly optimizing transmission mode selection, satellite-user association, ISL task migration, denoising steps, and adaptive weights, which is a complex nonlinear integer programming problem. To maximize the average semantic efficiency metric, we propose a decision-assisted REINFORCE++ algorithm that utilizes feasibility-aware action space and a critic-free stabilized policy update. Numerical results show that the proposed algorithm achieves higher semantic efficiency than baselines.

</details>


### [35] [On the burst-covering radius of binary cyclic codes](https://arxiv.org/abs/2601.00435)
*Gabriel Sac Himelfarb,Moshe Schwartz*

Main category: cs.IT

TL;DR: 该论文研究突发覆盖码，为循环码提供更强的突发覆盖半径界限，并针对BCH码提出LFSR序列中模式频率的新界限，最后给出突发覆盖循环码的高效算法。


<details>
  <summary>Details</summary>
Motivation: 研究突发覆盖码的理论性质，特别是循环码的突发覆盖半径界限问题，这对于编码理论中的覆盖半径分析具有重要意义。

Method: 1. 定义突发覆盖码并建立一般参数界限；2. 利用线性反馈移位寄存器(LFSR)序列为循环码提供更强的突发覆盖半径界限；3. 针对BCH码证明LFSR序列中模式频率的新界限；4. 开发突发覆盖循环码的高效算法。

Result: 1. 建立了突发覆盖码参数与突发覆盖半径的一般连接界限；2. 获得了循环码突发覆盖半径的更强界限；3. 证明了BCH码LFSR序列模式频率的新界限，可用于分析二进制原始BCH码和Melas码的覆盖半径；4. 提出了突发覆盖循环码的高效算法。

Conclusion: 论文系统研究了突发覆盖码的理论框架，通过LFSR序列方法显著改进了循环码的突发覆盖半径界限，特别是针对BCH码的新界限具有独立理论价值，同时提供了实用的高效算法。

Abstract: We define and study burst-covering codes. We provide some general bounds connecting the code parameters with its burst-covering radius. We then provide stronger bounds on the burst-covering radius of cyclic codes, by employing linear-feedback shift-register (LFSR) sequences. For the case of BCH codes we prove a new bound on pattern frequencies in LFSR sequences, which is of independent interest. Using this tool, we can bound the covering-radius of binary primitive BCH codes and Melas codes. We conclude with an efficient algorithm for burst-covering cyclic codes.

</details>


### [36] [CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge](https://arxiv.org/abs/2601.00549)
*Zhiheng Guo,Zhaoyang Liu,Zihan Cen,Chenyuan Feng,Xinghua Sun,Xiang Chen,Tony Q. S. Quek,Xijun Wang*

Main category: cs.IT

TL;DR: CoCo-Fed：一种面向O-RAN的压缩与组合联邦学习框架，通过双重维度降投影解决本地内存瓶颈，通过正交子空间叠加协议减少全局通信开销，在无线感知任务中保持高效收敛。


<details>
  <summary>Details</summary>
Motivation: 在O-RAN架构中部署大规模神经网络面临两大瓶颈：1）资源受限的gNB上本地训练所需的内存占用过大；2）高维模型更新在带宽受限的回程链路上进行全局聚合时导致带宽饱和。

Method: 提出CoCo-Fed框架：本地采用双重维度降投影对梯度进行低秩操作，适配优化器而不增加推理参数/延迟；全局引入基于正交子空间叠加的传输协议，将层间更新投影并叠加为单个矩阵，大幅减少回程流量。

Result: 在到达角估计任务上的大量仿真表明，CoCo-Fed在内存和通信效率方面显著优于现有基线方法，并在非独立同分布设置下保持稳健收敛。

Conclusion: CoCo-Fed通过统一本地内存效率和全局通信减少，为O-RAN中的边缘智能部署提供了有效的解决方案，并建立了严格的理论基础，证明了在无线感知任务等无监督学习条件下的收敛性。

Abstract: The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.

</details>


### [37] [Universal Outlier Hypothesis Testing via Mean- and Median-Based Tests](https://arxiv.org/abs/2601.00712)
*Bernhard C. Geiger,Tobias Koch,Josipa Mihaljević,Maximilian Toller*

Main category: cs.IT

TL;DR: 本文研究通用异常值假设检验问题，提出两种方法：当异常序列数量亚线性增长时使用均值估计法，当异常序列比例固定时使用中位数估计法，两者都能达到已知分布的最大似然检验的错误指数。


<details>
  <summary>Details</summary>
Motivation: 研究通用异常值假设检验问题，其中观测到大量序列，大部分服从典型分布π，小部分服从异常分布μ，需要在不知道π和μ的情况下识别异常序列。与之前工作不同，本文假设观测序列数量和异常序列数量都随序列长度增长。

Method: 提出两种方法：1）当异常序列数量亚线性增长时，使用均值估计法，通过计算所有观测序列的均值来估计π；2）当异常序列数量与总序列数量成比例时，使用中位数估计法，通过计算所有观测序列的中位数来估计π。两种方法都能达到已知π和μ的最大似然检验的错误指数。

Result: 均值估计法在异常序列数量亚线性增长时能实现最大似然检验的错误指数；中位数估计法在异常序列比例固定时能以概率趋近于1实现最大似然检验的错误指数。为此引入了典型错误指数的概念。

Conclusion: 本文针对不同异常序列增长情况提出了有效的通用异常值检测方法，均值估计法适用于异常序列亚线性增长场景，中位数估计法适用于异常序列比例固定场景，两者都能达到最优性能。

Abstract: Universal outlier hypothesis testing refers to a hypothesis testing problem where one observes a large number of length-$n$ sequences -- the majority of which are distributed according to the typical distribution $π$ and a small number are distributed according to the outlier distribution $μ$ -- and one wishes to decide, which of these sequences are outliers without having knowledge of $π$ and $μ$. In contrast to previous works, in this paper it is assumed that both the number of observation sequences and the number of outlier sequences grow with the sequence length. In this case, the typical distribution $π$ can be estimated by computing the mean over all observation sequences, provided that the number of outlier sequences is sublinear in the total number of sequences. It is demonstrated that, in this case, one can achieve the error exponent of the maximum likelihood test that has access to both $π$ and $μ$. However, this mean-based test performs poorly when the number of outlier sequences is proportional to the total number of sequences. For this case, a median-based test is proposed that estimates $π$ as the median of all observation sequences. It is demonstrated that the median-based test achieves again the error exponent of the maximum likelihood test that has access to both $π$ and $μ$, but only with probability approaching one. To formalize this case, the typical error exponent -- similar to the typical random coding exponent introduced in the context of random coding for channel coding -- is proposed.

</details>
