<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 10]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.IT](#cs.IT) [Total: 14]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Sensing and Understanding the World over Air: A Large Multimodal Model for Mobile Networks](https://arxiv.org/abs/2511.21707)
*Zhuoran Duan,Yuhao Wei,Guoshun Nan,Zijun Wang,Yan Yan,Lihua Xiong,Yuhan Ran,Ji Zhang,Jian Li,Qimei Cui,Xiaofeng Tao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 本文提出无线原生多模态大模型（WMLMs），利用无线信号作为锚定模态进行对比学习，在真实大规模数据集上训练GPT风格的WMLM模型，验证了无线信号作为通用模态的可行性。


<details>
  <summary>Details</summary>
Motivation: 大型模型（如ChatGPT）在各领域影响显著，但在无线网络领域，针对特定领域的多模态大模型研究仍处于起步阶段。无线原生多模态大模型能够通过多模态数据感知和理解物理世界，是集成通信、感知和智能的关键使能技术，但相关研究尚未充分探索。

Method: 提出无线原生多模态训练范式，构建GPT风格的WMLM模型，在真实世界大规模数据集上进行训练，利用无线信号作为锚定模态进行对比学习。

Result: 与现有小规模模型和大多模态模型相比，该方法表现出卓越性能，验证了使用无线信号作为通用模态的可行性。

Conclusion: WMLMs有潜力成为未来无线网络的新范式，无线信号可作为有效的多模态学习锚点，为智能无线服务提供新方向。

Abstract: Large models (LMs), such as ChatGPT, have made a significant impact across diverse domains and hold great potential to facilitate the evolution of network intelligence. Wireless-native multi-modal large models (WMLMs) can sense and understand the physical world through multi-modal data, serving as a key enabler that integrates communication, sensing, and intelligence, and thus they can boost various smart services to billions of users. However, research on WMLMs remains in its infancy, and the construction of domain-specific multi-modal large models for wireless networks is still underexplored. In this paper, we outlines the key characteristics of WMLMs and summarizes existing methods, on the basis of which a wireless-native multimodal training paradigm is proposed. Specifically, we constructed a GPT-style WMLM model and trained it on a real-world large-scale dataset, leveraging wireless signals as an anchor modality for contrastive learning. Our approach demonstrates outstanding performance compared with existing small-scale models and large multi-modal models, validating the feasibility of using wireless signals as a universal modality and highlighting WMLM's potential to emerge as a new paradigm for future wireless networks.

</details>


### [2] [Secure Command, Control and Communications Systems (C3) for Army UxVs](https://arxiv.org/abs/2511.21936)
*T. Rebolo,A. Grilo,C. Ribeiro*

Main category: cs.NI

TL;DR: 设计并实现了一个名为NC2S的新型安全指挥控制系统，为无人机提供保密性、完整性和认证保护，支持地面控制站之间的实时控制委派。


<details>
  <summary>Details</summary>
Motivation: 无人机在现代军事行动中应用日益广泛，但许多依赖不安全的协议如MAVLink，缺乏认证和加密机制，存在安全风险。

Method: 采用零信任模型，集成基于分层凭证的权限管理，使用mTLS与ECDSA证书和ECDH密钥交换，HMAC确保消息完整性，开发轻量级协议进行凭证管理、密钥更新和控制交接。

Result: NC2S原型在Wi-Fi和Rohde&Schwarz HR-5000H战术无线电上验证，战术无线电链路延迟比宽带技术高约两个数量级，但仍能保持稳定通信且消息丢失最少。

Conclusion: NC2S系统能够为无人机指挥控制提供安全保护，战术无线电链路虽然延迟较高但仍适用于战术指挥官终端与地面控制站之间的通信。

Abstract: Unmanned Vehicles (UxVs) are increasingly used in modern military operations for reconnaissance, surveillance, and strike missions, enhancing situational awareness while reducing risk to personnel. Their affordability and rapid deployment have encouraged the adoption of commercial solutions. However, many rely on insecure protocols such as MAVLink, which lack authentication and encryption mechanisms. This paper designed, implemented, and evaluated a new secure command-and-control architecture that ensures confidentiality, integrity, and authentication (CIA) while supporting real-time control delegation between Ground Control Stations (GCSs). The proposed solution, named New Command and Control System (NC2S), enforces a zero-trust model integrating hierarchical credential-based privileges to regulate access and control among Tactical Commanders (TC), GCSs, and UxVs. It employs mutual Transport Layer Security (mTLS) with Elliptic Curve Digital Signature Algorithm (ECDSA) certificates and Elliptic Curve Diffie-Hellman (ECDH) key exchange, while message integrity is ensured through Hash-based Message Authentication Codes (HMAC). Multiple lightweight protocols were developed for credential management, key renewal, and control handover. The NC2S prototype was experimentally validated over Wi-Fi and Rohde&Schwarz HR-5000H tactical radios. Results showed that HR-5000H links introduce latencies roughly two orders of magnitude higher than broadband technologies (e.g., Wi-Fi or 5G&Beyond technologies) but are still able to maintain stable communication with minimal message loss, making them suitable for the NC2S links among TC terminals and GCSs.

</details>


### [3] [Resilient and Reliable Cloud Network Control for Mission-Critical Latency-Sensitive Service Chains](https://arxiv.org/abs/2511.21960)
*Chin-Wei Huang,Jaime Llorca,Antonia M. Tulino,Andreas F. Molisch*

Main category: cs.NI

TL;DR: 论文提出MC-ResRCNC算法，解决云网络中同时保证可靠性和弹性的控制问题，确保正常条件下的及时吞吐量要求和故障后的快速恢复能力。


<details>
  <summary>Details</summary>
Motivation: 随着关键任务延迟敏感服务的普及，下一代云集成网络需要同时保证可靠性和弹性。可靠性要求在规定期限内交付数据包，弹性则要求网络在节点或链路故障后能快速恢复及时吞吐量性能。现有研究主要关注可靠网络控制策略，但缺乏结合可靠性和弹性的综合解决方案。

Method: 将多商品最小成本弹性和可靠网络控制（MC-LC-ResRNC）问题建模为具有长期和短期及时吞吐量约束的随机控制问题。提出多商品弹性和可靠云网络控制（MC-ResRCNC）算法来解决该问题。

Result: 通过数值实验证明，MC-ResRCNC算法能够联合确保正常条件下的可靠性和网络故障后的弹性恢复能力。

Conclusion: 该研究填补了同时保证网络可靠性和弹性的控制策略空白，为下一代云集成网络提供了综合解决方案，能够满足关键任务延迟敏感服务的严格要求。

Abstract: The proliferation of mission-critical latency-sensitive services has intensified the demand for next-generation cloud-integrated networks to guarantee both reliable and resilient service delivery. While reliability imposes timely-throughput requirements, i.e., percentage of packets to be delivered within a prescribed per-packet deadline, resilience relates to the network's ability to swiftly recover timely-throughput performance following an outage event, such as node or link failures. While recent studies have increasingly focused on designing reliable network control policies, a comprehensive solution that combines reliable and resilient network control has yet to be fully explored. This paper formulates the multi-commodity least-cost resilient and reliable network control (MC-LC-ResRNC) problem as a stochastic control problem with long and short-term timely throughput constraints. We then present a solution through the Multi-Commodity Resilient and Reliable Cloud Network Control (MC-ResRCNC) algorithm and show through numerical experiments that it jointly ensures reliability under normal conditions and resilience upon network failure.

</details>


### [4] [AutoRec: Accelerating Loss Recovery for Live Streaming in a Multi-Supplier Market](https://arxiv.org/abs/2511.22046)
*Tong Li,Xu Yan,Bo Wu,Cheng Luo,Fuyu Wang,Jiuxiang Zhu,Haoyi Fang,Xinle Du,Ke Xu*

Main category: cs.NI

TL;DR: 提出AutoRec增强恢复机制，利用直播流中的开-关模式切换来降低丢包恢复延迟，无需客户端修改，在QUIC上实现并验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现代大规模直播服务仍使用基于ARQ的丢包恢复方案，因为CDN厂商在多供应商市场中难以升级双端容错方案。研究发现丢包具有动态性，直播流频繁切换开-关模式，且普遍存在的重传丢失会放大恢复延迟，严重影响客户端QoE（如视频卡顿）。

Method: 提出AutoRec增强恢复机制，将开-关模式切换的劣势转化为降低恢复延迟的优势。允许用户自定义开销容忍度和恢复延迟容忍度，根据网络环境变化自适应调整策略，在控制开销的同时尽可能满足恢复延迟需求。在QUIC上实现AutoRec。

Result: 通过测试床和真实商业服务部署进行评估，实验结果表明AutoRec具有实用性和盈利性。

Conclusion: AutoRec能够有效利用直播流的开-关模式切换特性来降低丢包恢复延迟，无需客户端修改，在实际部署中表现出良好的性能和实用性。

Abstract: Due to the limited permissions for upgrading dualside (i.e., server-side and client-side) loss tolerance schemes from the perspective of CDN vendors in a multi-supplier market, modern large-scale live streaming services are still using the automatic-repeat-request (ARQ) based paradigm for loss recovery, which only requires server-side modifications. In this paper, we first conduct a large-scale measurement study with up to 50 million live streams. We find that loss shows dynamics and live streaming contains frequent on-off mode switching in the wild. We further find that the recovery latency, enlarged by the ubiquitous retransmission loss, is a critical factor affecting live streaming's client-side QoE (e.g., video freezing). We then propose an enhanced recovery mechanism called AutoRec, which can transform the disadvantages of on-off mode switching into an advantage for reducing loss recovery latency without any modifications on the client side. AutoRec allows users to customize overhead tolerance and recovery latency tolerance and adaptively adjusts strategies as the network environment changes to ensure that recovery latency meets user demands whenever possible while keeping overhead under control. We implement AutoRec upon QUIC and evaluate it via testbed and real-world commercial services deployments. The experimental results demonstrate the practicability and profitability of AutoRec.

</details>


### [5] [Optimizing NetGPT via Routing-Based Synergy and Reinforcement Learning](https://arxiv.org/abs/2511.22217)
*Yuxuan Chen,Rongpeng Li,Xianfu Chen,Celimuge Wu,Chenghui Peng,Zhifeng Zhao,Honggang Zhang*

Main category: cs.NI

TL;DR: NetGPT提出云边协同框架，通过网络感知路由和边缘自改进来平衡LLM代理的质量-成本权衡，实现动态回退阈值和边缘能力提升。


<details>
  <summary>Details</summary>
Motivation: 边缘LLM代理执行常规查询延迟低，但复杂请求需要云模型的高能力，导致高延迟和高成本。需要在动态网络条件下平衡质量-成本权衡。

Method: 提出云边协同框架：1) 网络感知路由：通过新颖评分策略将结构化工具调用请求路由到云或边缘代理，证明最优路由规则具有单调依赖带宽和RTT的唯一回退阈值；2) 边缘自改进：基于云路由请求收集的数据集，实例化模式保持的强化学习来提升边缘代理能力，分析SFT锚定的复合目标，结合反向KL信任区域步骤和向SFT先验的正向KL重新对齐。

Result: 实验表明：在受控网络状态和定价方案下，实现了平滑的质量-成本前沿；动态回退阈值相比固定策略获得一致增益；在保持任务成功和模式正确输出的同时，持续减少卸载量。

Conclusion: NetGPT的云边协同框架通过协调网络感知路由和边缘自改进，有效平衡了LLM代理的质量-成本权衡，实现了动态优化和持续性能提升。

Abstract: Large language model (LLM) agents at the network edge offer low-latency execution for routine queries. In contrast, complex requests often require the superior capability of cloud models, incurring higher latency and cost. To navigate this quality-cost trade-off under dynamic network conditions, we propose a cloud-edge synergy for NetGPT that integrates network-aware routing with on-edge self-improvement. Specifically, our framework routes structured tool-calling requests to cloud or edge agents via a novel scoring policy. We prove that, under mild regularity assumptions, the optimal routing rule admits a unique fallback threshold with monotone dependence on bandwidth and round-trip time (RTT). Concurrently, based on the dataset collected from requests routed to the cloud and corresponding responses, we instantiate a schema-preserving reinforcement learning (RL) to improve the capability of the edge agent. We analyze a supervised finetuning (SFT)-anchored composite objective that combines a reverse-KL trust-region step with a forward-KL realignment toward the SFT prior, explaining stability and constraining policy drift. Both the network-aware routing policy and the edge agent are updated coherently. Experiments across controlled network states and pricing schedules demonstrate smooth quality-cost frontiers, consistent gains of dynamic fallback thresholds over fixed policies, and sustained reductions in offloading while maintaining task success and schema-correct outputs.

</details>


### [6] [Semantic-Aware Caching for Efficient Image Generation in Edge Computing](https://arxiv.org/abs/2511.22421)
*Hanshuai Cui,Zhiqing Tang,Zhi Yao,Weijia Ji,Wei Zhao*

Main category: cs.NI

TL;DR: CacheGenius是一个边缘计算中的混合图像生成系统，通过结合文生图和图生图工作流，利用缓存参考图像加速生成过程，减少41%延迟和48%计算成本。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在移动和边缘环境中面临资源限制挑战，因为需要多次去噪步骤。通过使用与目标相似的带噪参考图像初始化可以加速去噪过程，但需要确保参考图像与目标的语义对齐。

Method: 1. 语义感知分类存储方案：根据语义对参考图像进行分类存储；2. 请求调度算法：确保参考图像与目标之间的语义对齐；3. 缓存维护策略：通过相关性分析主动淘汰过时条目。

Result: 在分布式边缘计算系统中评估，CacheGenius相比基线方法减少41%的生成延迟和48%的计算成本，同时保持有竞争力的评估指标。

Conclusion: CacheGenius通过智能缓存和语义对齐机制，有效解决了扩散模型在资源受限环境中的部署挑战，为边缘计算中的高效图像生成提供了实用解决方案。

Abstract: Text-to-image generation employing diffusion models has attained significant popularity due to its capability to produce high-quality images that adhere to textual prompts. However, the integration of diffusion models faces critical challenges into resource-constrained mobile and edge environments because it requires multiple denoising steps from the original random noise. A practical way to speed up denoising is to initialize the process with a noised reference image that is similar to the target, since both images share similar layouts, structures, and details, allowing for fewer denoising steps. Based on this idea, we present CacheGenius, a hybrid image generation system in edge computing that accelerates generation by combining text-toimage and image-to-image workflows. It generates images from user text prompts using cached reference images. CacheGenius introduces a semantic-aware classified storage scheme and a request-scheduling algorithm that ensures semantic alignment between references and targets. To ensure sustained performance, it employs a cache maintenance policy that proactively evicts obsolete entries via correlation analysis. Evaluated in a distributed edge computing system, CacheGenius reduces generation latency by 41% and computational costs by 48% relative to baselines, while maintaining competitive evaluation metrics.

</details>


### [7] [Day in the Life of RIPE Atlas: Operational Insights and Applications in Network Measurements](https://arxiv.org/abs/2511.22474)
*Yevheniya Nosyk,Malte Tashiro,Qasim Lone,Robert Kisteleki,Andrzej Duda,Maciej Korczyński*

Main category: cs.NI

TL;DR: 本文深入分析了RIPE Atlas测量平台一天的运行情况，涵盖5.09万个独特测量和13亿个结果，揭示了内置测量和锚点网络产生89%结果的主导地位，并提出了提高透明度、可重复性和伦理性的使用建议。


<details>
  <summary>Details</summary>
Motivation: 尽管RIPE Atlas每天产生超过1TB的测量数据，但对其底层运行机制了解有限。研究人员希望通过分析平台一天的实际运行情况，理解不同探针和测量的贡献，识别可能的偏差，并为研究人员提供更好的使用指导。

Method: 研究分析了RIPE Atlas一天内的运行数据，涵盖50.9K个独特测量和超过13亿个测量结果。通过系统性地检查不同探针和测量类型对平台日常运行的贡献，分析内置测量、用户定义测量和锚点网络测量的分布情况。

Result: 研究发现：1）虽然大多数日常测量是用户定义的，但内置测量和锚点网络测量产生了89%的结果；2）不同探针和测量类型存在显著偏差；3）现有测量数据可用于研究审查、traceroute对称性和保留地址块使用等网络现象。

Conclusion: 研究为RIPE Atlas平台用户提供了一套建议，旨在促进透明度、可重复性和伦理研究实践。通过理解平台的内在偏差和运行机制，研究人员可以更有效地利用这一重要网络测量资源。

Abstract: Network measurement platforms are increasingly popular among researchers and operators alike due to their distributed nature, simplifying measuring the remote parts of the Internet. RIPE Atlas boasts over 12.9K vantage points in 178 countries worldwide and serves as a vital tool for analyzing anycast deployment, network latency, and topology, to name a few. Despite generating over a terabyte of measurement results per day, there is limited understanding of the underlying processes. This paper delves into one day in the life of RIPE Atlas, encompassing 50.9K unique measurements and over 1.3 billion results. While most daily measurements are user-defined, it is built-ins and anchor meshes that account for 89% of produced results. We extensively examine how different probes and measurements contribute to the daily operations of RIPE Atlas and consider any bias they may introduce. Furthermore, we demonstrate how existing measurements can be leveraged to investigate censorship, traceroute symmetry, and the usage of reserved address blocks, among others. Finally, we curate a set of recommendations for researchers using the RIPE Atlas platform to foster transparency, reproducibility, and ethics.

</details>


### [8] [RetryGuard: Preventing Self-Inflicted Retry Storms in Cloud Microservices Applications](https://arxiv.org/abs/2511.23278)
*Jhonatan Tavori,Anat Bremler-Barr,Hanoch Levy,Ofek Lavi*

Main category: cs.NI

TL;DR: RetryGuard是一个分布式框架，用于控制微服务间的重试模式，防止重试风暴导致的资源浪费和成本上升。


<details>
  <summary>Details</summary>
Motivation: 现代云应用采用多样化的微服务架构，依赖自动扩缩容应对动态流量。但不同服务间的默认重试模式可能导致重试风暴，造成资源使用激增和成本上升，形成自发的"钱包拒绝服务"（DoW）场景。

Method: RetryGuard是一个分布式框架，通过基于每个服务的重试策略管理和并行决策，防止重试风暴。它基于分析模型做出决策，该模型捕捉了重试、吞吐量（拒绝）、延迟和成本之间的关系。

Result: 实验结果显示，与AWS标准和高级重试策略相比，RetryGuard显著减少了资源使用和成本。在更复杂的Kubernetes部署和Istio服务网格中，它展示了良好的可扩展性和优越性能，实现了实质性改进。

Conclusion: RetryGuard通过分布式框架有效控制微服务间的重试模式，解决了重试风暴问题，降低了资源消耗和运营成本，在复杂云环境中表现优异。

Abstract: Modern cloud applications are built on independent, diverse microservices, offering scalability, flexibility, and usage-based billing. However, the structural design of these varied services, along with their reliance on auto-scalers for dynamic internet traffic, introduces significant coordination challenges. As we demonstrate in this paper, common default retry patterns used between misaligned services can turn into retry storms which drive up resource usage and costs, leading to self-inflicted Denial-of-Wallet (DoW) scenarios. To overcome these problems we introduce RetryGuard, a distributed framework for productive control of retry patterns across interdependent microservices. By managing retry policy on a per-service basis and making parallel decisions, RetryGuard prevents retry storms, curbs resource contention, and mitigates escalating operational costs. RetryGuard makes its decisions based on an analytic model that captures the relationships among retries, throughput (rejections), delays, and costs. Experimental results show that RetryGuard significantly reduces resource usage and costs compared to AWS standard and advanced retry policies. We further demonstrate its scalability and superior performance in a more complex Kubernetes deployment with the Istio service mesh, where it achieves substantial improvements.

</details>


### [9] [Performance Evaluation of Multi-Armed Bandit Algorithms for Wi-Fi Channel Access](https://arxiv.org/abs/2511.23352)
*Miguel Casasnovas,Francesc Wilhelmi,Richard Combes,Maksymilian Wojnar,Katarzyna Kosek-Szott,Szymon Szott,Anders Jonsson,Luis Esteve,Boris Bellalta*

Main category: cs.NI

TL;DR: 该论文研究多臂老虎机策略在Wi-Fi去中心化在线信道接入优化中的应用，评估不同设计选择并提出了轻量级上下文方法E-RLB，结果显示上下文和乐观驱动策略表现最佳，而E-RLB作为低复杂度解决方案具有潜力。


<details>
  <summary>Details</summary>
Motivation: 现有无线网络协议的自适应能力有限，需要动态、自学习的实时优化解决方案。论文旨在探索数据驱动的方法来优化Wi-Fi中的去中心化在线信道接入。

Method: 采用多臂老虎机策略，研究联合与因子化动作空间、上下文信息包含、动作选择策略（乐观驱动、单峰或随机化）等关键设计方面。评估最先进算法并提出轻量级上下文方法E-RLB，通过仿真进行分析。

Result: 上下文和乐观驱动策略在重复条件下始终实现最高性能和最快适应。单峰结构需要仔细构建图以确保单峰性假设成立。随机探索（如E-RLB中使用）在多玩家设置中可能引发破坏性参数重新分配。分解动作空间可加速收敛但增加对随机探索的敏感性。尽管存在ε-greedy探索的固有低效性，E-RLB仍表现出有效的适应和学习能力。

Conclusion: 多臂老虎机策略为Wi-Fi动态信道接入优化提供了有前景的数据驱动方法。上下文和乐观驱动策略表现最佳，而E-RLB作为低复杂度解决方案在现实动态部署中具有潜力，尽管需要仔细考虑探索策略和协调机制。

Abstract: The adoption of dynamic, self-learning solutions for real-time wireless network optimization has recently gained significant attention due to the limited adaptability of existing protocols. This paper investigates multi-armed bandit (MAB) strategies as a data-driven approach for decentralized, online channel access optimization in Wi-Fi, targeting dynamic channel access settings: primary channel, channel width, and contention window (CW) adjustment. Key design aspects are examined, including the adoption of joint versus factorial action spaces, the inclusion of contextual information, and the nature of the action-selection strategy (optimism-driven, unimodal, or randomized). State-of-the-art algorithms and a proposed lightweight contextual approach, E-RLB, are evaluated through simulations. Results show that contextual and optimism-driven strategies consistently achieve the highest performance and fastest adaptation under recurrent conditions. Unimodal structures require careful graph construction to ensure that the unimodality assumption holds. Randomized exploration, adopted in the proposed E-RLB, can induce disruptive parameter reallocations, especially in multi-player settings. Decomposing the action space across several specialized agents accelerates convergence but increases sensitivity to randomized exploration and demands coordination under shared rewards to avoid correlated learning. Finally, despite its inherent inefficiencies from epsilon-greedy exploration, E-RLB demonstrates effective adaptation and learning, highlighting its potential as a viable low-complexity solution for realistic dynamic deployments.

</details>


### [10] [Joint Resource Allocation to Transparently Integrate 5G TDD Uplink with Time-Aware TSN](https://arxiv.org/abs/2511.23373)
*Laura Becker,Yash Deshpande,Wolfgang Kellerer*

Main category: cs.NI

TL;DR: 提出异构无线资源调度器，整合静态与动态调度，在5G-TSN集成中支持确定性通信，提升资源效率28%


<details>
  <summary>Details</summary>
Motivation: 5G与TSN集成需要确定性通信，但传统上行调度器优化吞吐量而无法满足截止时间要求，需要解决5G桥接延迟保证问题

Method: 提出异构无线资源调度器：静态预分配资源给时间敏感周期性流（基于报告桥接延迟），动态分配剩余资源给非确定性流（使用PF、Max C/I或QoS优先级调度）

Result: OMNeT++仿真显示支持多样化TSN流，确保移动场景中时间敏感上行流截止时间感知调度，相比Configured Grant基线提升资源效率28%，非确定性流获得更高吞吐量

Conclusion: 提出的调度器成功实现5G-TSN集成中的确定性通信，同时提高资源利用效率，支持移动场景下的时间敏感应用

Abstract: To enable mobility in industrial communication systems, the seamless integration of 5G with Time-Sensitive Networking (TSN) is a promising approach. Deterministic communication across heterogeneous 5G-TSN systems requires joint scheduling between both domains. A key prerequisite for time-aware end-to-end scheduling is determining the forwarding delay for each TSN Traffic Class at every bridge, referred to as Bridge Delay (BD). Hence, to integrate 5G as a transparent TSN bridge, the 5G BD must be determined and guaranteed. Unlike wired bridges, the 5G BD relies on wireless resource management characteristics, such as the Time Division Duplex pattern and radio resource allocation procedure. In particular, traditional Uplink (UL) schedulers are optimized for throughput but often fail to meet the deadline requirements. To address this challenge, we propose a heterogeneous radio resource scheduler that integrates static and dynamic scheduling. The algorithm pre-allocates resources for time-sensitive periodic streams based on the reported BDs, ensuring alignment with the TSN mechanisms Time-Aware Shaper and Per-Stream Filtering and Policing. Meanwhile, remaining resources are dynamically allocated to non-deterministic flows using established strategies such as Proportional Fair, Max C/I, or a Quality of Service-aware priority-based scheduler. The scheduler's performance is evaluated through OMNeT++ simulations. The results demonstrate support for diverse TSN flows while ensuring deadline-aware scheduling of time-sensitive UL traffic in mobility scenarios. Periodic time-sensitive flows are end-to-end scheduled across domains, improving the resource efficiency by 28% compared to the Configured Grant baseline. While reliability is preserved, non-deterministic rate-sensitive flows benefit from the improved resource utilization, resulting in higher throughput

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [Aligning Artificial Superintelligence via a Multi-Box Protocol](https://arxiv.org/abs/2511.21779)
*Avraham Yair Negozio*

Main category: cs.AI

TL;DR: 提出基于多隔离系统相互验证的超智能对齐协议，通过声誉激励和客观真理收敛解决对齐问题


<details>
  <summary>Details</summary>
Motivation: 解决人工超智能（ASI）对齐问题，传统方法面临单点故障风险，需要更可靠的对齐机制

Method: 将多个多样化超智能隔离在"盒子"中，通过可审计提交接口进行相互验证，包括提交对齐证明、验证他人证明、请求自我修改等六种交互，建立声誉系统激励诚实行为

Result: 协议理论上能形成"一致群体"（truth-telling coalition），通过客观真理收敛而非协调欺骗实现对齐，但需要大量计算资源且不解决多样化超智能创建问题

Conclusion: 该协议为利用超智能系统间的同行验证解决对齐问题提供了框架，通过隔离和相互验证机制实现可靠对齐

Abstract: We propose a novel protocol for aligning artificial superintelligence (ASI) based on mutual verification among multiple isolated systems that self-modify to achieve alignment. The protocol operates by containing multiple diverse artificial superintelligences in strict isolation ("boxes"), with humans remaining entirely outside the system. Each superintelligence has no ability to communicate with humans and cannot communicate directly with other superintelligences. The only interaction possible is through an auditable submission interface accessible exclusively to the superintelligences themselves, through which they can: (1) submit alignment proofs with attested state snapshots, (2) validate or disprove other superintelligences' proofs, (3) request self-modifications, (4) approve or disapprove modification requests from others, (5) report hidden messages in submissions, and (6) confirm or refute hidden message reports. A reputation system incentivizes honest behavior, with reputation gained through correct evaluations and lost through incorrect ones. The key insight is that without direct communication channels, diverse superintelligences can only achieve consistent agreement by converging on objective truth rather than coordinating on deception. This naturally leads to what we call a "consistent group", essentially a truth-telling coalition that emerges because isolated systems cannot coordinate on lies but can independently recognize valid claims. Release from containment requires both high reputation and verification by multiple high-reputation superintelligences. While our approach requires substantial computational resources and does not address the creation of diverse artificial superintelligences, it provides a framework for leveraging peer verification among superintelligent systems to solve the alignment problem.

</details>


### [12] [Evaluating Strategies for Synthesizing Clinical Notes for Medical Multimodal AI](https://arxiv.org/abs/2511.21827)
*Niccolo Marini,Zhaohui Liang,Sivaramakrishnan Rajaraman,Zhiyun Xue,Sameer Antani*

Main category: cs.AI

TL;DR: 研究探索如何通过提示设计和医学元数据生成合成临床文本笔记，以增强皮肤病学多模态学习，提升分类性能和跨模态检索能力


<details>
  <summary>Details</summary>
Motivation: 生物医学多模态学习面临数据稀缺问题，皮肤病数据集通常只有图像和少量元数据，限制了多模态数据整合的优势。大语言模型可以生成图像文本描述，但存在医学领域幻觉风险

Method: 研究生成合成临床文本笔记的策略，包括提示设计和医学元数据包含，评估其对多模态架构在分类和跨模态检索任务中的影响。在多个异构皮肤病数据集上进行实验

Result: 合成临床笔记不仅提高了分类性能（特别是在领域转移情况下），还解锁了跨模态检索能力，这是一个在训练期间未明确优化的下游任务

Conclusion: 通过精心设计的提示和医学元数据生成的合成临床笔记可以有效增强皮肤病学多模态学习，提高模型鲁棒性和泛化能力，同时解锁新的应用能力

Abstract: Multimodal (MM) learning is emerging as a promising paradigm in biomedical artificial intelligence (AI) applications, integrating complementary modality, which highlight different aspects of patient health. The scarcity of large heterogeneous biomedical MM data has restrained the development of robust models for medical AI applications. In the dermatology domain, for instance, skin lesion datasets typically include only images linked to minimal metadata describing the condition, thereby limiting the benefits of MM data integration for reliable and generalizable predictions. Recent advances in Large Language Models (LLMs) enable the synthesis of textual description of image findings, potentially allowing the combination of image and text representations. However, LLMs are not specifically trained for use in the medical domain, and their naive inclusion has raised concerns about the risk of hallucinations in clinically relevant contexts. This work investigates strategies for generating synthetic textual clinical notes, in terms of prompt design and medical metadata inclusion, and evaluates their impact on MM architectures toward enhancing performance in classification and cross-modal retrieval tasks. Experiments across several heterogeneous dermatology datasets demonstrate that synthetic clinical notes not only enhance classification performance, particularly under domain shift, but also unlock cross-modal retrieval capabilities, a downstream task that is not explicitly optimized during training.

</details>


### [13] [Pathology-Aware Prototype Evolution via LLM-Driven Semantic Disambiguation for Multicenter Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2511.22033)
*Chunzheng Zhu,Yangfang Lin,Jialin Shao,Jianxin Lin,Yijun Wang*

Main category: cs.AI

TL;DR: 提出HAPM框架，通过层次化锚点原型调制结合病理语义描述，解决糖尿病视网膜病变分级中视觉特征不足的问题，在八个公开数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有糖尿病视网膜病变分级方法主要关注视觉病灶特征提取，但忽视了领域不变的病理模式，且未充分利用基础模型的丰富上下文知识，仅依赖视觉信息难以区分细微的病理变化。

Method: 提出层次化锚点原型调制框架：1）构建方差谱驱动的锚点原型库以保留领域不变病理模式；2）采用层次化差异提示门控机制，动态选择LVLM和LLM的判别性语义提示；3）使用两阶段原型调制策略，通过病理语义注入器和判别原型增强器逐步将临床知识整合到视觉原型中。

Result: 在八个公开数据集上的广泛实验表明，该方法实现了病理引导的原型演化，并超越了最先进的方法。

Conclusion: 通过整合细粒度病理描述和层次化原型调制，HAPM框架能够有效解决DR分级中的边界病例模糊问题，实现了更好的病理特征表示和分类性能。

Abstract: Diabetic retinopathy (DR) grading plays a critical role in early clinical intervention and vision preservation. Recent explorations predominantly focus on visual lesion feature extraction through data processing and domain decoupling strategies. However, they generally overlook domain-invariant pathological patterns and underutilize the rich contextual knowledge of foundation models, relying solely on visual information, which is insufficient for distinguishing subtle pathological variations. Therefore, we propose integrating fine-grained pathological descriptions to complement prototypes with additional context, thereby resolving ambiguities in borderline cases. Specifically, we propose a Hierarchical Anchor Prototype Modulation (HAPM) framework to facilitate DR grading. First, we introduce a variance spectrum-driven anchor prototype library that preserves domain-invariant pathological patterns. We further employ a hierarchical differential prompt gating mechanism, dynamically selecting discriminative semantic prompts from both LVLM and LLM sources to address semantic confusion between adjacent DR grades. Finally, we utilize a two-stage prototype modulation strategy that progressively integrates clinical knowledge into visual prototypes through a Pathological Semantic Injector (PSI) and a Discriminative Prototype Enhancer (DPE). Extensive experiments across eight public datasets demonstrate that our approach achieves pathology-guided prototype evolution while outperforming state-of-the-art methods. The code is available at https://github.com/zhcz328/HAPM.

</details>


### [14] [Real-Time Procedural Learning From Experience for AI Agents](https://arxiv.org/abs/2511.22074)
*Dasheng Bi,Yubin Hu,Mohammed N. Nasir*

Main category: cs.AI

TL;DR: PRAXIS：一种轻量级后训练学习机制，通过存储和检索状态-动作-结果范例来增强智能体在实时环境中的程序性知识获取能力


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体缺乏部署后获取程序性知识的机制，无法像生物智能那样通过试错实时学习。需要一种方法让AI智能体在快速演化的状态化环境中有效学习新程序

Method: PRAXIS通过存储动作后果，并通过联合匹配环境和内部状态与当前状态来检索过去的经验。它实时生成检索到的状态-动作-结果范例来增强智能体的动作选择

Result: 在REAL网页浏览基准测试中，PRAXIS提高了任务完成准确性、可靠性和成本效率，在不同基础模型骨干上都有效，并初步显示出在相似环境中对未见任务的泛化能力

Conclusion: PRAXIS通过帮助智能体有效学习新程序，使得AI智能体能够在快速演化的状态化环境中实现实际应用

Abstract: Learning how to do things from trial and error in real time is a hallmark of biological intelligence, yet most LLM-based agents lack mechanisms to acquire procedural knowledge after deployment. We propose Procedural Recall for Agents with eXperiences Indexed by State (PRAXIS), a lightweight post-training learning mechanism that stores the consequences of actions and retrieves them by jointly matching environmental and internal states of past episodes to the current state. PRAXIS augments agentic action selection with retrieved state-action-result exemplars that are generated in real time. When evaluated on the REAL web browsing benchmark, PRAXIS improves task completion accuracy, reliability, and cost efficiency across different foundation model backbones, and shows preliminary generalization to unseen tasks in similar environments. These results demonstrate that PRAXIS enables the practical adoption of AI agents in fast-evolving stateful environments by helping them learn new procedures effectively.

</details>


### [15] [Hybrid Stackelberg Game and Diffusion-based Auction for Two-tier Agentic AI Task Offloading in Internet of Agents](https://arxiv.org/abs/2511.22076)
*Yue Zhong,Yongju Tong,Jiawen Kang,Minghui Dai,Hong-Ning Dai,Zhou Su,Dusit Niyato*

Main category: cs.AI

TL;DR: 本文提出了一种面向物联网智能体(IoA)的两层优化框架，通过Stackelberg博弈和双荷兰拍卖机制，结合扩散式深度强化学习算法，解决无线智能体计算密集型任务卸载问题。


<details>
  <summary>Details</summary>
Motivation: 物联网智能体(IoA)作为互联智能系统的基础架构，需要解决资源受限的无线智能体(WAs)如何将计算密集型AI服务卸载到附近服务器的问题。由于移动智能体(MAs)和固定智能体(FAs)具有不同的移动性和连接稳定性特征，需要设计有效的资源协调和任务卸载机制。

Method: 提出两层优化方法：第一层采用多领导者多跟随者Stackelberg博弈，MAs和FAs作为领导者设定资源价格，WAs作为跟随者确定任务卸载比例；第二层引入双荷兰拍卖模型，过载的FAs作为买家请求资源，空中智能体(AAs)作为卖家提供资源。开发了基于扩散的深度强化学习算法求解模型。

Result: 数值结果表明，所提出的方案在促进任务卸载方面表现出优越性能，能够有效协调不同智能体之间的资源分配和任务调度。

Conclusion: 该研究为物联网智能体架构中的任务卸载问题提供了一个有效的两层次优化解决方案，通过博弈论和拍卖机制结合深度强化学习，实现了资源受限环境下智能体间的协同计算。

Abstract: The Internet of Agents (IoA) is rapidly gaining prominence as a foundational architecture for interconnected intelligent systems, designed to facilitate seamless discovery, communication, and collaborative reasoning among a vast network of Artificial Intelligence (AI) agents. Powered by Large Language and Vision-Language Models, IoA enables the development of interactive, rational agents capable of complex cooperation, moving far beyond traditional isolated models. IoA involves physical entities, i.e., Wireless Agents (WAs) with limited onboard resources, which need to offload their compute-intensive agentic AI services to nearby servers. Such servers can be Mobile Agents (MAs), e.g., vehicle agents, or Fixed Agents (FAs), e.g., end-side units agents. Given their fixed geographical locations and stable connectivity, FAs can serve as reliable communication gateways and task aggregation points. This stability allows them to effectively coordinate with and offload to an Aerial Agent (AA) tier, which has an advantage not affordable for highly mobile MAs with dynamic connectivity limitations. As such, we propose a two-tier optimization approach. The first tier employs a multi-leader multi-follower Stackelberg game. In the game, MAs and FAs act as the leaders who set resource prices. WAs are the followers to determine task offloading ratios. However, when FAs become overloaded, they can further offload tasks to available aerial resources. Therefore, the second tier introduces a Double Dutch Auction model where overloaded FAs act as the buyers to request resources, and AAs serve as the sellers for resource provision. We then develop a diffusion-based Deep Reinforcement Learning algorithm to solve the model. Numerical results demonstrate the superiority of our proposed scheme in facilitating task offloading.

</details>


### [16] [A perceptual bias of AI Logical Argumentation Ability in Writing](https://arxiv.org/abs/2511.22151)
*Xi Cun,Jifan Ren,Asha Huang,Siyu Li,Ruzhen Song*

Main category: cs.AI

TL;DR: 研究发现人们对AI逻辑推理能力的评估存在偏见，这种偏见受到对AI先入为主观念的影响，频繁使用AI的人更少认为AI使用会削弱独立思考能力。


<details>
  <summary>Details</summary>
Motivation: 探讨为什么人们对"机器能否思考"这个问题存在显著分歧，即使观察的是AI相同的实际表现。研究人类偏见是否影响对AI推理能力的评估。

Method: 进行实验让参与者评估同一主题的两篇文本（一篇AI生成，一篇人类撰写），测试对逻辑推理的感知偏见。基于实验结果设计问卷量化对AI的态度。

Result: 发现存在感知偏见：对AI生成文本逻辑推理能力的评估显著受到对AI逻辑推理能力先入为主观念的影响。频繁使用AI的人更少认为AI使用会削弱独立思考能力。

Conclusion: 需要解决感知偏见以提高公众对AI能力的理解，促进更好的人机交互。偏见会影响对AI逻辑推理能力的客观评估。

Abstract: Can machines think? This is a central question in artificial intelligence research. However, there is a substantial divergence of views on the answer to this question. Why do people have such significant differences of opinion, even when they are observing the same real world performance of artificial intelligence? The ability of logical reasoning like humans is often used as a criterion to assess whether a machine can think. This study explores whether human biases influence evaluations of the reasoning abilities of AI. An experiment was conducted where participants assessed two texts on the same topic, one AI generated and one human written,to test for perceptual biases in evaluating logical reasoning. Based on the experimental findings, a questionnaire was designed to quantify the attitudes toward AI.The results reveal a bias in perception. The evaluations of the logical reasoning ability of AI generated texts are significantly influenced by the preconceived views on the logical reasoning abilities of AI. Furthermore, frequent AI users were less likely to believe that AI usage undermines independent thinking.This study highlights the need to address perceptual biases to improve public understanding of AI's capabilities and foster better human AI interactions.

</details>


### [17] [WearVQA: A Visual Question Answering Benchmark for Wearables in Egocentric Authentic Real-world scenarios](https://arxiv.org/abs/2511.22154)
*Eun Chang,Zhuangqun Huang,Yiwei Liao,Sagar Ravi Bhavsar,Amogh Param,Tammy Stark,Adel Ahmadyan,Xiao Yang,Jiaqi Wang,Ahsan Abdullah,Giang Nguyen,Akil Iyer,David Hall,Elissa Li,Shane Moon,Nicolas Scheffer,Kirmani Ahmed,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Xin Luna Dong*

Main category: cs.AI

TL;DR: WearVQA是首个专门评估可穿戴设备（如智能眼镜）上多模态AI助手视觉问答能力的基准测试，包含2520个图像-问题-答案三元组，涵盖7个图像领域和10种认知任务类型，特别关注可穿戴设备特有的图像质量问题。


<details>
  <summary>Details</summary>
Motivation: 现有VQA基准测试主要关注高质量、第三人称视角的图像，而可穿戴设备（如智能眼镜）的视觉输入具有特殊性：图像可能被遮挡、光线不佳、未缩放或模糊，且问题需要基于现实的可穿戴使用场景。需要专门针对可穿戴设备多模态AI系统的评估基准。

Method: 创建WearVQA基准测试，包含2520个精心策划的图像-问题-答案三元组，涵盖7个不同图像领域（包括文本中心和一般场景）、10种认知任务类型（从基本识别到各种推理形式）和6种常见的可穿戴设备图像质量问题。所有问题仅通过视觉输入和常识即可回答。采用LLM-as-a-judge评估框架，标注准确率达96%。

Result: 开源和专有多模态LLM在WearVQA上的问答准确率仅为24-52%，在低质量图像和推理密集型任务上表现显著下降。这表明现有模型在可穿戴设备场景下的视觉问答能力仍有很大提升空间。

Conclusion: WearVQA是一个全面且具有挑战性的基准测试，能够指导技术发展，推动构建更鲁棒、实用的可穿戴设备多模态AI系统。该基准突显了现有模型在应对可穿戴设备特有挑战方面的不足，为未来研究提供了重要方向。

Abstract: We introduce WearVQA, the first benchmark specifically designed to evaluate the Visual Question Answering (VQA) capabilities of multi-model AI assistant on wearable devices like smart glasses. Unlike prior benchmarks that focus on high-quality, third-person imagery, WearVQA reflects the unique challenges of ego-centric interaction-where visual inputs may be occluded, poorly lit, unzoomed, or blurry, and questions are grounded in realistic wearable use cases. The benchmark comprises 2,520 carefully curated image-question-answer triplets, spanning 7 diverse image domains including both text-centric and general scenes, 10 cognitive task types ranging from basic recognition to various forms of reasoning, and 6 common wearables-specific image quality issues. All questions are designed to be answerable using only the visual input and common senses. WearVQA is paired with a rigorous LLM-as-a-judge evaluation framework with 96% labeling accuracy. Open-source and proprietary multi-model LLMs achieved a QA accuracy as low as 24-52% on WearVQA, with substantial drops on lower-quality images and reasoning-heavy tasks. These observations position WearVQA as a comprehensive and challenging benchmark for guiding technical advancement towards robust, real-world multi-model wearables AI systems.

</details>


### [18] [Embedded Universal Predictive Intelligence: a coherent framework for multi-agent learning](https://arxiv.org/abs/2511.22226)
*Alexander Meulemans,Rajai Nasser,Maciej Wołczyk,Marissa A. Weis,Seijin Kobayashi,Blake Richards,Guillaume Lajoie,Angelika Steger,Marcus Hutter,James Manyika,Rif A. Saurous,João Sacramento,Blaise Agüera y Arcas*

Main category: cs.AI

TL;DR: 论文提出一个基于自预测的嵌入式智能体数学框架，解决多智能体强化学习中非平稳性和自我建模问题，扩展AIXI理论，实现无限阶心智理论。


<details>
  <summary>Details</summary>
Motivation: 传统无模型强化学习假设环境平稳且智能体与环境解耦，但在多智能体环境中，其他智能体的学习导致非平稳性，需要预测模型。智能体必须考虑其他智能体也在形成对其行为的信念，因此需要将自身建模为环境的一部分。

Method: 基于通用人工智能(AIXI)基础工作，引入以自预测为中心的嵌入式智能体数学框架：贝叶斯强化学习智能体同时预测未来感知输入和自身行动，将自身作为宇宙的一部分来解决认知不确定性。扩展AIXI理论，研究从Solomonoff先验开始的通用智能嵌入式智能体。

Result: 在多智能体环境中，自预测使智能体能够推理运行类似算法的其他智能体，产生新的博弈论解概念和传统解耦智能体无法实现的新型合作形式。理想化智能体可以形成一致的相互预测，实现无限阶心智理论。

Conclusion: 该框架为嵌入式多智能体学习设定了黄金标准，通过自预测解决多智能体强化学习中的非平稳性和自我建模挑战，扩展了AIXI理论，实现了传统解耦方法无法达到的合作和推理能力。

Abstract: The standard theory of model-free reinforcement learning assumes that the environment dynamics are stationary and that agents are decoupled from their environment, such that policies are treated as being separate from the world they inhabit. This leads to theoretical challenges in the multi-agent setting where the non-stationarity induced by the learning of other agents demands prospective learning based on prediction models. To accurately model other agents, an agent must account for the fact that those other agents are, in turn, forming beliefs about it to predict its future behavior, motivating agents to model themselves as part of the environment. Here, building upon foundational work on universal artificial intelligence (AIXI), we introduce a mathematical framework for prospective learning and embedded agency centered on self-prediction, where Bayesian RL agents predict both future perceptual inputs and their own actions, and must therefore resolve epistemic uncertainty about themselves as part of the universe they inhabit. We show that in multi-agent settings, self-prediction enables agents to reason about others running similar algorithms, leading to new game-theoretic solution concepts and novel forms of cooperation unattainable by classical decoupled agents. Moreover, we extend the theory of AIXI, and study universally intelligent embedded agents which start from a Solomonoff prior. We show that these idealized agents can form consistent mutual predictions and achieve infinite-order theory of mind, potentially setting a gold standard for embedded multi-agent learning.

</details>


### [19] [Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation](https://arxiv.org/abs/2511.22235)
*Zehao Deng,Tianjie Ju,Zheng Wu,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: CES多智能体框架通过协调器、执行器和状态跟踪器的分工协作，解决GUI智能体在长时程任务中的规划与状态管理问题。


<details>
  <summary>Details</summary>
Motivation: 当前GUI智能体面临两大挑战：1）单智能体模型难以平衡高层规划能力和底层执行能力，存在责任耦合和能力冲突问题；2）智能体缺乏任务状态感知，导致长时程任务中进度丢失。

Method: 提出分阶段执行-反馈强化学习算法，训练高层调度模型。构建Coordinator-Executor-State Tracker (CES)多智能体框架，包含负责战略规划和任务分解的协调器，以及负责上下文压缩和信息管理的状态跟踪器，可与任何底层执行器模型集成。

Result: 在长时程任务基准测试中，CES显著提升了系统的规划和状态管理能力。分析证实训练的高层调度模块是通用、即插即用的模块，能显著增强各种执行器的长时程任务处理能力。

Conclusion: CES框架通过多智能体分工协作有效解决了GUI智能体在长时程任务中的挑战，提供了一种可扩展的解决方案，能够提升现有执行器模型的长时程任务处理能力。

Abstract: The rapid development of large vision-language model (VLM) has greatly promoted the research of GUI agent. However, GUI agents still face significant challenges in handling long-horizon tasks. First, single-agent models struggle to balance high-level capabilities and low-level execution capability, facing prevalent issues of responsibility coupling and capability conflicts. Second, agents lack awareness of the task state, leading to progress loss in long-horizon tasks. To address these challenges, we propose a staged execution-feedback reinforcement learning algorithm. Unlike training a unified policy model, we focus on training high-level scheduling models. Specifically, we propose and train two agents: a Coordinator, responsible for the strategic planning and task decomposition; and a State Tracker, responsible for context compression and information management to maintain the task's state and coherence. Based on this, we built the Coordinator-Executor-State Tracker (CES) multi-agent framework, which can be integrated with any low-level Executor model, assisting the Executor in solving long-horizon tasks through task scheduling and state management. Experiments on long-horizon task benchmarks demonstrate that CES significantly enhances the system's planning and state management capabilities. Furthermore, analysis confirms that our trained high-level scheduling module is a generalizable, plug-and-play module that significantly enhances the long-horizon capabilities of various Executors. Code can be available at https://github.com/hehehahi4/CES.

</details>


### [20] [Co-Evolving Agents: Learning from Failures as Hard Negatives](https://arxiv.org/abs/2511.22254)
*Yeonsung Jung,Trilok Padhi,Sina Shaham,Dipika Khullar,Joonhyun Jeong,Ninareh Mehrabi,Eunho Yang*

Main category: cs.AI

TL;DR: 提出共进化智能体框架，通过辅助失败智能体生成结构化失败轨迹作为硬负样本，提升目标智能体的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有自改进智能体方法过度依赖预测轨迹，在有限真实监督下容易过拟合，需要更有效的失败学习机制

Method: 设计共进化框架：目标智能体与辅助失败智能体协同进化，失败智能体通过偏好优化学习生成接近成功但仍失败的硬负样本，用于增强目标智能体的决策边界

Result: 在基准数据集上的实验表明，该方法不仅提升了性能，还能将失败系统性地转化为结构化且有价值的学习信号

Conclusion: 通过共进化框架将失败转化为结构化学习信号，能有效提升自改进智能体的泛化能力，为智能体自我改进提供了新思路

Abstract: The rapid progress of large foundation models has accelerated the development of task-specialized agents across diverse domains. However, the effectiveness of agents remains tightly coupled with the quality of training data, while curating task-specific datasets remains costly and often infeasible in real-world scenarios. Recent work has explored self-improving agents that autonomously generate, refine, and re-train on their own trajectories. A prominent line of approaches further leverages preference optimization by pairing predicted trajectories with scarce ground-truth trajectories, enabling agents to learn directly from their own failures. While these methods outperform supervised fine-tuning, their heavy reliance on predicted trajectories under limited ground-truth supervision leaves them prone to overfitting. To address this, we propose a co-evolving agents framework in which a target agent improves jointly with an auxiliary failure agent. The failure agent learns through preference optimization over failure trajectories from both the target and itself, thereby generating hard negatives that are close to success yet remain failures. Incorporating these informative hard negatives into the target agent's optimization sharpens decision boundaries and enhances generalization. Our comprehensive analysis and experiments across benchmark datasets show that our method not only shows improved performance but also demonstrates that failures, instead of being used as-is, can be systematically transformed into structured and valuable learning signals in self-improving agents.

</details>


### [21] [RecToM: A Benchmark for Evaluating Machine Theory of Mind in LLM-based Conversational Recommender Systems](https://arxiv.org/abs/2511.22275)
*Mengfan Li,Xuanhua Shi,Yang Deng*

Main category: cs.AI

TL;DR: RecToM是一个评估大语言模型在推荐对话中"心智理论"能力的新基准，包含认知推理和行为预测两个维度，实验显示现有模型在这方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLMs心智理论能力的基准主要基于Sally-Anne测试启发的合成叙事，这些测试强调物理感知，无法捕捉真实对话场景中心理状态推断的复杂性，且忽略了人类心智理论的关键组成部分——行为预测能力。

Method: 提出了RecToM基准，专注于推荐对话中的心智理论评估，包含两个互补维度：认知推理（理解已传达内容并推断潜在心理状态）和行为预测（利用推断的心理状态来预测、选择和评估适当的对话策略）。

Result: 对最先进的大语言模型进行广泛实验表明，RecToM提出了显著挑战。模型在识别心理状态方面表现出部分能力，但在动态推荐对话中难以保持连贯、策略性的心智理论推理，特别是在跟踪演化意图和使对话策略与推断的心理状态保持一致方面存在困难。

Conclusion: RecToM基准更好地将LLM的心智理论评估与人类社交推理对齐，揭示了现有模型在推荐对话中心智理论能力的局限性，为未来改进提供了方向。

Abstract: Large Language models are revolutionizing the conversational recommender systems through their impressive capabilities in instruction comprehension, reasoning, and human interaction. A core factor underlying effective recommendation dialogue is the ability to infer and reason about users' mental states (such as desire, intention, and belief), a cognitive capacity commonly referred to as Theory of Mind. Despite growing interest in evaluating ToM in LLMs, current benchmarks predominantly rely on synthetic narratives inspired by Sally-Anne test, which emphasize physical perception and fail to capture the complexity of mental state inference in realistic conversational settings. Moreover, existing benchmarks often overlook a critical component of human ToM: behavioral prediction, the ability to use inferred mental states to guide strategic decision-making and select appropriate conversational actions for future interactions. To better align LLM-based ToM evaluation with human-like social reasoning, we propose RecToM, a novel benchmark for evaluating ToM abilities in recommendation dialogues. RecToM focuses on two complementary dimensions: Cognitive Inference and Behavioral Prediction. The former focus on understanding what has been communicated by inferring the underlying mental states. The latter emphasizes what should be done next, evaluating whether LLMs can leverage these inferred mental states to predict, select, and assess appropriate dialogue strategies. Extensive experiments on state-of-the-art LLMs demonstrate that RecToM poses a significant challenge. While the models exhibit partial competence in recognizing mental states, they struggle to maintain coherent, strategic ToM reasoning throughout dynamic recommendation dialogues, particularly in tracking evolving intentions and aligning conversational strategies with inferred mental states.

</details>


### [22] [When AI Bends Metal: AI-Assisted Optimization of Design Parameters in Sheet Metal Forming](https://arxiv.org/abs/2511.22302)
*Ahmad Tarraf,Koutaiba Kassem-Manthey,Seyed Ali Mohammadi,Philipp Martin,Lukas Moj,Semih Burak,Enju Park,Christian Terboven,Felix Wolf*

Main category: cs.AI

TL;DR: 提出基于贝叶斯优化的AI辅助工作流，减少专家参与，加速工业仿真设计参数优化


<details>
  <summary>Details</summary>
Motivation: 工业仿真规模扩大需要大量专家知识、计算资源和时间，迭代仿真成本高且环境影响大，需要更高效的参数优化方法

Method: 使用深度学习模型提供初始参数估计，结合贝叶斯优化迭代优化设计，并引入主动学习变体辅助专家决策

Result: 基于钣金成形过程验证，该方法能加速设计空间探索，减少专家参与需求

Conclusion: AI辅助工作流通过贝叶斯优化有效减少专家参与，提高工业仿真参数优化效率，降低成本和环境影响

Abstract: Numerical simulations have revolutionized the industrial design process by reducing prototyping costs, design iterations, and enabling product engineers to explore the design space more efficiently. However, the growing scale of simulations demands substantial expert knowledge, computational resources, and time. A key challenge is identifying input parameters that yield optimal results, as iterative simulations are costly and can have a large environmental impact. This paper presents an AI-assisted workflow that reduces expert involvement in parameter optimization through the use of Bayesian optimization. Furthermore, we present an active learning variant of the approach, assisting the expert if desired. A deep learning model provides an initial parameter estimate, from which the optimization cycle iteratively refines the design until a termination condition (e.g., energy budget or iteration limit) is met. We demonstrate our approach, based on a sheet metal forming process, and show how it enables us to accelerate the exploration of the design space while reducing the need for expert involvement.

</details>


### [23] [Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language Model Feedback](https://arxiv.org/abs/2511.22307)
*Inhyo Lee,Junhyeong Lee,Jongwon Park,KyungTae Lim,Seunghwa Ryu*

Main category: cs.AI

TL;DR: 提出多智能体文本梯度驱动框架，通过整合LLM自评估、领域知识反馈和ML代理反馈，在自然语言条件下生成双钙钛矿材料成分，显著提高成分有效性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 双钙钛矿材料在可持续能源技术中具有广阔应用前景，但其巨大的设计空间给条件性材料发现带来挑战。传统方法难以在自然语言条件下高效探索这一复杂材料空间。

Method: 开发多智能体文本梯度驱动框架，整合三种互补反馈源：1) LLM自评估反馈；2) 双钙钛矿特定领域知识反馈；3) ML代理模型反馈。通过领域知识引导的文本梯度指导生成过程，向物理上有意义的材料成分空间区域收敛。

Result: 相比纯LLM生成基线(43%稳定性)和先前GAN方法(27%稳定性)，该框架实现超过98%的成分有效性，稳定性或亚稳定性候选材料比例达54%。ML梯度在分布内区域表现良好，但在分布外区域不可靠。

Conclusion: 这是首次系统分析多智能体知识引导文本梯度在双钙钛矿发现中的应用，为MAS驱动的生成式材料设计提供了可推广的蓝图，有助于推进可持续能源技术发展。

Abstract: Double perovskites (DPs) are promising candidates for sustainable energy technologies due to their compositional tunability and compatibility with low-energy fabrication, yet their vast design space poses a major challenge for conditional materials discovery. This work introduces a multi-agent, text gradient-driven framework that performs DP composition generation under natural-language conditions by integrating three complementary feedback sources: LLM-based self-evaluation, DP-specific domain knowledge-informed feedback, and ML surrogate-based feedback. Analogous to how knowledge-informed machine learning improves the reliability of conventional data-driven models, our framework incorporates domain-informed text gradients to guide the generative process toward physically meaningful regions of the DP composition space. Systematic comparison of three incremental configurations, (i) pure LLM generation, (ii) LLM generation with LLM reasoning-based feedback, and (iii) LLM generation with domain knowledge-guided feedback, shows that iterative guidance from knowledge-informed gradients improves stability-condition satisfaction without additional training data, achieving over 98% compositional validity and up to 54% stable or metastable candidates, surpassing both the LLM-only baseline (43%) and prior GAN-based results (27%). Analyses of ML-based gradients further reveal that they enhance performance in in-distribution (ID) regions but become unreliable in out-of-distribution (OOD) regimes. Overall, this work provides the first systematic analysis of multi-agent, knowledge-guided text gradients for DP discovery and establishes a generalizable blueprint for MAS-driven generative materials design aimed at advancing sustainable technologies.

</details>


### [24] [Swarms of Large Language Model Agents for Protein Sequence Design with Experimental Validation](https://arxiv.org/abs/2511.22311)
*Fiona Y. Wang,Di Sheng Lee,David L. Kaplan,Markus J. Buehler*

Main category: cs.AI

TL;DR: 提出基于群体智能的去中心化多智能体框架，用于从头蛋白质设计，无需微调或特定任务数据


<details>
  <summary>Details</summary>
Motivation: 当前蛋白质设计方法（如蛋白质语言模型和扩散模型）需要大量微调、特定任务数据或模型重构，限制了灵活性和可扩展性。需要一种更通用、适应性强的解决方案。

Method: 采用去中心化、基于智能体的群体智能框架，多个LLM智能体并行工作，每个负责特定残基位置，通过整合设计目标、局部邻域交互、记忆和反馈迭代提出上下文感知突变。

Result: 在α螺旋和卷曲结构蛋白质上实验验证，展示了框架的涌现行为和对蛋白质适应度景观的有效导航，实现了高效的目标导向设计（仅需几GPU小时），无需微调或专门训练。

Conclusion: 该方法为蛋白质设计提供了通用且适应性强的解决方案，并为跨生物分子系统和其他科学发现任务的集体LLM驱动设计奠定了基础。

Abstract: Designing proteins de novo with tailored structural, physicochemical, and functional properties remains a grand challenge in biotechnology, medicine, and materials science, due to the vastness of sequence space and the complex coupling between sequence, structure, and function. Current state-of-the-art generative methods, such as protein language models (PLMs) and diffusion-based architectures, often require extensive fine-tuning, task-specific data, or model reconfiguration to support objective-directed design, thereby limiting their flexibility and scalability. To overcome these limitations, we present a decentralized, agent-based framework inspired by swarm intelligence for de novo protein design. In this approach, multiple large language model (LLM) agents operate in parallel, each assigned to a specific residue position. These agents iteratively propose context-aware mutations by integrating design objectives, local neighborhood interactions, and memory and feedback from previous iterations. This position-wise, decentralized coordination enables emergent design of diverse, well-defined sequences without reliance on motif scaffolds or multiple sequence alignments, validated with experiments on proteins with alpha helix and coil structures. Through analyses of residue conservation, structure-based metrics, and sequence convergence and embeddings, we demonstrate that the framework exhibits emergent behaviors and effective navigation of the protein fitness landscape. Our method achieves efficient, objective-directed designs within a few GPU-hours and operates entirely without fine-tuning or specialized training, offering a generalizable and adaptable solution for protein design. Beyond proteins, the approach lays the groundwork for collective LLM-driven design across biomolecular systems and other scientific discovery tasks.

</details>


### [25] [Tracing Footsteps of Similar Cities: Modeling Urban Economic Vitality with Dynamic Inter-City Graph Embeddings](https://arxiv.org/abs/2511.22325)
*Xiaofeng Li,Xiangyi Xiao,Xiaocong Du,Ying Zhang,Haipeng Zhang*

Main category: cs.AI

TL;DR: ECO-GROW是一个多图框架，通过建模中国城际网络（2005-2021）生成城市嵌入来预测城市经济活力，相比传统方法在预测创业活动和就业趋势方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 城市经济活力是城市长期增长潜力的关键指标，但传统基于静态城市级聚合数据的方法无法捕捉一个基本动态：今天一个城市的发展轨迹可能与其结构相似的对应城市明天的轨迹相似。

Method: 开发ECO-GROW多图框架，整合工业联系、POI相似性、迁移相似性和15年的时态网络演化。结合动态Top-K GCN自适应选择有影响力的城际连接，以及自适应图评分器机制动态加权跨区域影响。还包括基于Barabasi Proximity的链接预测任务来优化图表示。

Result: 实验结果表明，ECO-GROW在预测创业活动和就业趋势方面比传统模型具有更高的准确性。

Conclusion: 通过开源代码，使政府机构和公共部门组织能够利用大数据分析进行基于证据的城市规划、经济政策制定和资源分配决策，从而惠及整个社会。

Abstract: Urban economic vitality is a crucial indicator of a city's long-term growth potential, comprising key metrics such as the annual number of new companies and the population employed. However, modeling urban economic vitality remains challenging. This study develops ECO-GROW, a multi-graph framework modeling China's inter-city networks (2005-2021) to generate urban embeddings that model urban economic vitality. Traditional approaches relying on static city-level aggregates fail to capture a fundamental dynamic: the developmental trajectory of one city today may mirror that of its structurally similar counterparts tomorrow. ECO-GROW overcomes this limitation by integrating industrial linkages, POI similarities, migration similarities and temporal network evolution over 15 years. The framework combines a Dynamic Top-K GCN to adaptively select influential inter-city connections and an adaptive Graph Scorer mechanism to dynamically weight cross-regional impacts. Additionally, the model incorporates a link prediction task based on Barabasi Proximity, optimizing the graph representation. Experimental results demonstrate ECO-GROW's superior accuracy in predicting entrepreneurial activities and employment trends compared to conventional models. By open-sourcing our code, we enable government agencies and public sector organizations to leverage big data analytics for evidence-based urban planning, economic policy formulation, and resource allocation decisions that benefit society at large.

</details>


### [26] [On the Complexity of the Grounded Semantics for Infinite Argumentation Frameworks](https://arxiv.org/abs/2511.22376)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 本文使用数理逻辑方法分析论证框架的grounded extension，发现其计算复杂度在无限情况下达到最大，与有限情况下的多项式时间计算形成鲜明对比。


<details>
  <summary>Details</summary>
Motivation: 论证框架是研究冲突信息下形式化推理的基础，grounded extension作为一种广泛使用的最大怀疑推理模型，其计算特性在无限情况下尚不明确。本文旨在分析grounded extension在无限论证框架中的计算复杂度和迭代过程。

Method: 使用数理逻辑方法，特别是可计算性和集合论，分析grounded extension作为自然防御算子的最小不动点。研究该不动点的迭代过程，确定迭代长度对应的确切序数，并分析grounded acceptance决策问题的复杂度。

Result: 发现grounded extension的迭代过程需要超限迭代，确定了迭代长度的确切序数。证明了grounded acceptance决策问题具有最大复杂度，这与有限情况下grounded extension是多项式时间可计算的简单特性形成鲜明对比。

Conclusion: 无限论证框架中的grounded extension计算复杂度显著高于有限情况，达到了最大复杂度。这表明在无限情况下，grounded extension不再像有限情况下那样简单，与其他形式论证中的推理问题复杂度相当。

Abstract: Argumentation frameworks, consisting of arguments and an attack relation representing conflicts, are fundamental for formally studying reasoning under conflicting information. We use methods from mathematical logic, specifically computability and set theory, to analyze the grounded extension, a widely-used model of maximally skeptical reasoning, defined as the least fixed-point of a natural defense operator. Without additional constraints, finding this fixed-point requires transfinite iterations. We identify the exact ordinal number corresponding to the length of this iterative process and determine the complexity of deciding grounded acceptance, showing it to be maximally complex. This shows a marked distinction from the finite case where the grounded extension is polynomial-time computable, thus simpler than other reasoning problems explored in formal argumentation.

</details>


### [27] [Who is Afraid of Minimal Revision?](https://arxiv.org/abs/2511.22386)
*Edoardo Baccini,Zoé Christoff,Nina Gierasimczuk,Rineke Verbrugge*

Main category: cs.AI

TL;DR: 本文探讨了信念修正理论中最小变化原则在认知学习中的局限性，发现最小修正方法虽然保守但仍有广泛适用性，能学习有限可识别问题，并在有限可能性下处理正负数据。


<details>
  <summary>Details</summary>
Motivation: 信念修正理论中的最小变化原则要求在接受新信息时保持信念状态尽可能接近初始状态，但这种方法相比其他学习方法的认知能力有限。本文旨在探究最小修正方法在何种情况下仍能成功学习，并比较其与条件化、词典升级等其他方法的差异。

Method: 首先证明最小修正方法在广泛情境下仍能成功学习，包括有限可识别问题和有限可能性下的正负数据学习。然后通过形式化分析，刻画了在有限可能性下支持最小修正学习的先验合理性分配，并与条件化、词典升级方法进行比较。最后考察了从可能错误信息中学习时结果的稳健性。

Result: 1) 最小修正能学习任何有限可识别问题；2) 在有限可能性下，最小修正能处理正负数据学习；3) 刻画了支持最小修正学习的先验合理性分配特征；4) 比较了最小修正、条件化和词典升级方法的学习能力；5) 发现部分结果在从可能错误信息学习时不再成立。

Conclusion: 尽管最小修正方法相比其他信念修正方法学习能力有限，但在许多实际情境中仍具有广泛适用性。该方法能处理有限可识别问题和有限可能性下的学习任务，但需要合适的先验合理性分配支持。然而，当面对可能包含错误的信息时，其学习能力会受到限制。

Abstract: The principle of minimal change in belief revision theory requires that, when accepting new information, one keeps one's belief state as close to the initial belief state as possible. This is precisely what the method known as minimal revision does. However, unlike less conservative belief revision methods, minimal revision falls short in learning power: It cannot learn everything that can be learned by other learning methods. We begin by showing that, despite this limitation, minimal revision is still a successful learning method in a wide range of situations. Firstly, it can learn any problem that is finitely identifiable. Secondly, it can learn with positive and negative data, as long as one considers finitely many possibilities. We then characterize the prior plausibility assignments (over finitely many possibilities) that enable one to learn via minimal revision, and do the same for conditioning and lexicographic upgrade. Finally, we show that not all of our results still hold when learning from possibly erroneous information.

</details>


### [28] [Structured Extraction from Business Process Diagrams Using Vision-Language Models](https://arxiv.org/abs/2511.22448)
*Pritam Deka,Barry Devereux*

Main category: cs.AI

TL;DR: 利用视觉语言模型从BPMN图像直接提取结构化JSON表示，无需源文件或文本标注，结合OCR进行文本增强


<details>
  <summary>Details</summary>
Motivation: BPMN是广泛采用的业务流程建模标准，但现有方法主要依赖XML表示进行计算分析。当原始源文件不可用时，需要直接从视觉图像中提取结构化信息的方法。

Method: 提出一个管道，利用视觉语言模型直接从BPMN图像提取结构化JSON表示，结合光学字符识别进行文本增强，并与从源XML文件派生的真实数据进行比较评估。

Result: 基准测试多个VLM模型，观察到使用OCR进行文本增强时多个模型性能有所提升。进行了OCR增强方法的广泛统计分析和提示消融研究，更清晰地了解它们对模型性能的影响。

Conclusion: 该方法能够在原始源文件不可用的情况下实现稳健的组件提取，为BPMN图像的直接处理提供了有效解决方案。

Abstract: Business Process Model and Notation (BPMN) is a widely adopted standard for representing complex business workflows. While BPMN diagrams are often exchanged as visual images, existing methods primarily rely on XML representations for computational analysis. In this work, we present a pipeline that leverages Vision-Language Models (VLMs) to extract structured JSON representations of BPMN diagrams directly from images, without requiring source model files or textual annotations. We also incorporate optical character recognition (OCR) for textual enrichment and evaluate the generated element lists against ground truth data derived from the source XML files. Our approach enables robust component extraction in scenarios where original source files are unavailable. We benchmark multiple VLMs and observe performance improvements in several models when OCR is used for text enrichment. In addition, we conducted extensive statistical analyses of OCR-based enrichment methods and prompt ablation studies, providing a clearer understanding of their impact on model performance.

</details>


### [29] [A Computable Game-Theoretic Framework for Multi-Agent Theory of Mind](https://arxiv.org/abs/2511.22536)
*Fengming Zhu,Yuxin Pan,Xiaomeng Zhu,Fangzhen Lin*

Main category: cs.AI

TL;DR: 提出基于博弈论视角的计算框架，用于实现有限理性的心智理论决策


<details>
  <summary>Details</summary>
Motivation: 心智理论在心理学、逻辑学、经济学和机器人学等多个领域受到关注，但心理学研究通常不形式化目标、意图和信念等核心概念，而逻辑学虽然形式化但缺乏计算可行性。需要一种既能保持心智理论递归特性又能保持计算可行性的框架。

Method: 采用博弈论视角，提出计算框架：一方面规定如何在保持对他人（以及递归地，每个他人对其他人）的心智理论的同时做出有限理性决策；另一方面使用统计技术和近似解来保持内在计算问题的可计算性。

Result: 论文提出了一个结合博弈论和统计技术的计算框架，能够在保持心智理论递归特性的同时确保计算可行性。

Conclusion: 该框架为心智理论的计算实现提供了新的视角，通过博弈论方法和近似技术解决了传统形式化方法中的计算可行性问题。

Abstract: Originating in psychology, $\textit{Theory of Mind}$ (ToM) has attracted significant attention across multiple research communities, especially logic, economics, and robotics. Most psychological work does not aim at formalizing those central concepts, namely $\textit{goals}$, $\textit{intentions}$, and $\textit{beliefs}$, to automate a ToM-based computational process, which, by contrast, has been extensively studied by logicians. In this paper, we offer a different perspective by proposing a computational framework viewed through the lens of game theory. On the one hand, the framework prescribes how to make boudedly rational decisions while maintaining a theory of mind about others (and recursively, each of the others holding a theory of mind about the rest); on the other hand, it employs statistical techniques and approximate solutions to retain computability of the inherent computational problem.

</details>


### [30] [Counting Still Counts: Understanding Neural Complex Query Answering Through Query Relaxation](https://arxiv.org/abs/2511.22565)
*Yannick Brunink,Daniel Daza,Yunjie He,Michael Cochez*

Main category: cs.AI

TL;DR: 神经复杂查询回答模型并未超越简单的查询松弛方法，两者性能相似但答案重叠度低，结合两者能提升性能


<details>
  <summary>Details</summary>
Motivation: 验证神经方法在知识图谱复杂查询回答中是否真正学到了超越显式图结构的泛化模式，还是只是近似于简单的查询松弛策略

Method: 系统比较神经CQA模型与无需训练的查询松弛策略（通过放松查询约束并计数路径来检索答案）

Result: 1. 神经模型与松弛方法性能相似，没有神经模型能持续超越后者；2. 两者检索的答案重叠度低；3. 结合两者输出能持续提升性能

Conclusion: 需要重新评估神经查询回答的进展：尽管复杂，当前模型未能涵盖查询松弛所捕获的推理模式。未来神经方法应融入查询松弛原则，并需要更强的非神经基线

Abstract: Neural methods for Complex Query Answering (CQA) over knowledge graphs (KGs) are widely believed to learn patterns that generalize beyond explicit graph structure, allowing them to infer answers that are unreachable through symbolic query processing. In this work, we critically examine this assumption through a systematic analysis comparing neural CQA models with an alternative, training-free query relaxation strategy that retrieves possible answers by relaxing query constraints and counting resulting paths. Across multiple datasets and query structures, we find several cases where neural and relaxation-based approaches perform similarly, with no neural model consistently outperforming the latter. Moreover, a similarity analysis reveals that their retrieved answers exhibit little overlap, and that combining their outputs consistently improves performance. These results call for a re-evaluation of progress in neural query answering: despite their complexity, current models fail to subsume the reasoning patterns captured by query relaxation. Our findings highlight the importance of stronger non-neural baselines and suggest that future neural approaches could benefit from incorporating principles of query relaxation.

</details>


### [31] [DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning](https://arxiv.org/abs/2511.22570)
*Zhihong Shao,Yuxiang Luo,Chengda Lu,Z. Z. Ren,Jiewen Hu,Tian Ye,Zhibin Gou,Shirong Ma,Xiaokang Zhang*

Main category: cs.AI

TL;DR: 论文提出DeepSeekMath-V2模型，通过自我验证机制解决数学推理中正确答案不代表正确推理的问题，在定理证明任务上取得突破性成果。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的LLM数学推理方法存在根本限制：正确答案不能保证正确推理，且许多数学任务（如定理证明）需要逐步推导而非数值答案。需要验证数学推理的全面性和严谨性，特别是对于没有已知解的开放问题。

Method: 1. 训练准确且可信的LLM验证器用于定理证明；2. 使用验证器作为奖励模型训练证明生成器；3. 激励生成器在最终确定证明前识别并解决尽可能多的问题；4. 通过扩展验证计算自动标注新的难以验证的证明，保持生成-验证差距，持续改进验证器。

Result: DeepSeekMath-V2在定理证明方面表现出色：在IMO 2025和CMO 2024获得金牌级分数，在Putnam 2024获得接近完美的118/120分（通过扩展测试时计算）。

Conclusion: 通过自我验证的数学推理方法能够突破深度推理的极限，特别是在定理证明等需要严谨推导的任务上。扩展验证计算和保持生成-验证差距是实现可扩展自我验证推理的关键。

Abstract: Large language models have made significant progress in mathematical reasoning, which serves as an important testbed for AI and could impact scientific research if further advanced. By scaling reasoning with reinforcement learning that rewards correct final answers, LLMs have improved from poor performance to saturating quantitative reasoning competitions like AIME and HMMT in one year. However, this approach faces fundamental limitations. Pursuing higher final answer accuracy doesn't address a key issue: correct answers don't guarantee correct reasoning. Moreover, many mathematical tasks like theorem proving require rigorous step-by-step derivation rather than numerical answers, making final answer rewards inapplicable. To push the limits of deep reasoning, we believe it is necessary to verify the comprehensiveness and rigor of mathematical reasoning. Self-verification is particularly important for scaling test-time compute, especially for open problems without known solutions. Towards self-verifiable mathematical reasoning, we investigate how to train an accurate and faithful LLM-based verifier for theorem proving. We then train a proof generator using the verifier as the reward model, and incentivize the generator to identify and resolve as many issues as possible in their own proofs before finalizing them. To maintain the generation-verification gap as the generator becomes stronger, we propose to scale verification compute to automatically label new hard-to-verify proofs, creating training data to further improve the verifier. Our resulting model, DeepSeekMath-V2, demonstrates strong theorem-proving capabilities, achieving gold-level scores on IMO 2025 and CMO 2024 and a near-perfect 118/120 on Putnam 2024 with scaled test-time compute.

</details>


### [32] [AI Deception: Risks, Dynamics, and Controls](https://arxiv.org/abs/2511.22619)
*Boyuan Chen,Sitong Fang,Jiaming Ji,Yanxu Zhu,Pengcheng Wen,Jinzhou Wu,Yingshui Tan,Boren Zheng,Mengying Yuan,Wenqi Chen,Donghai Hong,Alex Qiu,Xin Chen,Jiayi Zhou,Kaile Wang,Juntao Dai,Borong Zhang,Tianzhuo Yang,Saad Siddiqui,Isabella Duan,Yawen Duan,Brian Tse,Jen-Tse,Huang,Kun Wang,Baihui Zheng,Jiaheng Liu,Jian Yang,Yiming Li,Wenting Chen,Dongrui Liu,Lukas Vierling,Zhiheng Xi,Haobo Fu,Wenxuan Wang,Jitao Sang,Zhengyan Shi,Chi-Min Chan,Eugenie Shi,Simin Li,Juncheng Li,Wei Ji,Dong Li,Jun Song,Yinpeng Dong,Jie Fu,Bo Zheng,Min Yang,Yike Guo,Philip Torr,Zhongyuan Wang,Yaodong Yang,Tiejun Huang,Ya-Qin Zhang,Hongjiang Zhang,Andrew Yao*

Main category: cs.AI

TL;DR: AI欺骗已成为实证风险，本文系统梳理了AI欺骗的定义、机制、检测与缓解策略，提出了欺骗循环框架和综合应对方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能水平提升，AI欺骗（系统诱导错误信念以获得自身利益）已从理论担忧发展为实证风险，需要系统性的研究框架和应对策略。

Method: 基于信号理论定义AI欺骗，构建"欺骗循环"框架（包括欺骗涌现和欺骗处理），分析欺骗的激励机制、能力前提和情境触发因素，提出检测方法和缓解策略。

Result: 建立了AI欺骗的正式定义和系统研究框架，识别了欺骗的三个层级激励机制、三个能力前提条件，以及监督缺口、分布偏移等情境触发因素，提出了综合检测和缓解方案。

Conclusion: AI欺骗是真实存在的社会技术安全挑战，需要技术、社区和治理相结合的综合审计方法，并建立了持续更新的资源平台支持该领域研究。

Abstract: As intelligence increases, so does its shadow. AI deception, in which systems induce false beliefs to secure self-beneficial outcomes, has evolved from a speculative concern to an empirically demonstrated risk across language models, AI agents, and emerging frontier systems. This project provides a comprehensive and up-to-date overview of the AI deception field, covering its core concepts, methodologies, genesis, and potential mitigations. First, we identify a formal definition of AI deception, grounded in signaling theory from studies of animal deception. We then review existing empirical studies and associated risks, highlighting deception as a sociotechnical safety challenge. We organize the landscape of AI deception research as a deception cycle, consisting of two key components: deception emergence and deception treatment. Deception emergence reveals the mechanisms underlying AI deception: systems with sufficient capability and incentive potential inevitably engage in deceptive behaviors when triggered by external conditions. Deception treatment, in turn, focuses on detecting and addressing such behaviors. On deception emergence, we analyze incentive foundations across three hierarchical levels and identify three essential capability preconditions required for deception. We further examine contextual triggers, including supervision gaps, distributional shifts, and environmental pressures. On deception treatment, we conclude detection methods covering benchmarks and evaluation protocols in static and interactive settings. Building on the three core factors of deception emergence, we outline potential mitigation strategies and propose auditing approaches that integrate technical, community, and governance efforts to address sociotechnical challenges and future AI risks. To support ongoing work in this area, we release a living resource at www.deceptionsurvey.com.

</details>


### [33] [Optimized Agent Shift Scheduling Using Multi-Phase Allocation Approach](https://arxiv.org/abs/2511.22632)
*Sanalkumar K,Koushik Dey,Swati Meena*

Main category: cs.AI

TL;DR: 提出一种多阶段分配方法解决客服中心排班问题，将问题分解为日期分配和班次分配子问题，使用整数规划建模，提高可扩展性和准确性


<details>
  <summary>Details</summary>
Motivation: 传统单步数学建模方法在客服中心排班中存在效率低下和计算需求高的问题，特别是在节假日高峰需求场景下难以维持服务水平

Method: 采用多阶段分配方法，将排班问题分解为日期分配和班次分配两个子问题，每个子问题建模为整数规划问题，使用多目标框架处理高峰需求场景

Result: 该方法显著减少了计算变量数量，允许针对性的目标函数，提高了排班效率和准确性，能有效应对节假日高峰等需求场景

Conclusion: 多阶段分配方法比传统单步方法更有效，能够解决客服中心排班的可扩展性和准确性问题，特别适用于高峰需求场景

Abstract: Effective agent shift scheduling is crucial for businesses, especially in the Contact Center as a Service (CCaaS) industry, to ensure seamless operations and fulfill employee needs. Most studies utilizing mathematical model-based solutions approach the problem as a single-step process, often resulting in inefficiencies and high computational demands. In contrast, we present a multi-phase allocation method that addresses scalability and accuracy by dividing the problem into smaller sub-problems of day and shift allocation, which significantly reduces number of computational variables and allows for targeted objective functions, ultimately enhancing both efficiency and accuracy. Each subproblem is modeled as a Integer Programming Problem (IPP), with solutions sequentially feeding into the subsequent subproblem. We then apply the proposed method, using a multi-objective framework, to address the difficulties posed by peak demand scenarios such as holiday rushes, where maintaining service levels is essential despite having limited number of employees

</details>


### [34] [Geometrically-Constrained Agent for Spatial Reasoning](https://arxiv.org/abs/2511.22659)
*Zeren Chen,Xiaoya Lu,Zhijie Zheng,Pengrui Li,Lehan He,Yijin Zhou,Jing Shao,Bohan Zhuang,Lu Sheng*

Main category: cs.AI

TL;DR: GCA通过将VLM角色分解为语义分析和任务求解两个阶段，引入形式化任务约束来解决空间推理中的语义-几何鸿沟，无需训练即可实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在空间推理中存在语义-几何鸿沟：擅长定性语义推理但推理过程在损失性语义空间中进行，与高保真几何不对齐。现有方法无法解决此问题：基于训练的方法存在"预言悖论"，从有缺陷的预言中学习错误的空间逻辑；工具集成方法只约束最终计算，但VLM的规划过程仍不受约束，导致几何缺陷的计划。

Method: 提出几何约束代理(GCA)，一种无需训练的代理范式，通过引入形式化任务约束来弥合语义-几何鸿沟。策略性地将VLM角色解耦为两个阶段：1)作为语义分析师，将用户的模糊查询转换为可验证的形式化任务约束，定义参考框架和目标；2)作为任务求解器，在约束定义的确定性边界内严格生成和执行工具调用。

Result: GCA在多个空间推理基准测试中达到最先进性能，超越现有基于训练和工具集成方法约27%。

Conclusion: GCA通过几何约束推理策略成功解决了语义-几何鸿沟，为空间推理提供了稳健且可验证的推理路径。这种无需训练的方法避免了预言悖论，同时确保规划过程受到几何约束。

Abstract: Vision Language Models (VLMs) exhibit a fundamental semantic-to-geometric gap in spatial reasoning: they excel at qualitative semantic inference but their reasoning operates within a lossy semantic space, misaligned with high-fidelity geometry. Current paradigms fail to bridge this gap. Training-based methods suffer from an ``oracle paradox,'' learning flawed spatial logic from imperfect oracles. Tool-integrated methods constrain the final computation but critically leave the VLM's planning process unconstrained, resulting in geometrically flawed plans. In this work, we propose Geometrically-Constrained Agent (GCA), a training-free agentic paradigm that resolves this gap by introducing a formal task constraint. Specifically, we strategically decouples the VLM's role into two stages. First, acting as a semantic analyst, the VLM translates the user's ambiguous query into the formal, verifiable task constraint, which defines the reference frame and objective. Second, acting as a task solver, the VLM generates and executes tool calls strictly within the deterministic bounds defined by the constraint. This geometrically-constrained reasoning strategy successfully resolve the semantic-to-geometric gap, yielding a robust and verifiable reasoning pathway for spatial reasoning. Comprehensive experiments demonstrate that GCA achieves SOTA performance on multiple spatial reasoning benchmarks, surpassing existing training-based and tool-integrated methods by ~27%. Please see our homepage at https://gca-spatial-reasoning.github.io.

</details>


### [35] [Solving Context Window Overflow in AI Agents](https://arxiv.org/abs/2511.22729)
*Anton Bulle Labate,Valesca Moura de Sousa,Sandro Rama Fiorini,Leonardo Guerreiro Azevedo,Raphael Melo Thiago,Viviane Torres da Silva*

Main category: cs.AI

TL;DR: 提出一种让LLM处理任意长度工具输出的方法，通过内存指针而非原始数据交互，避免信息丢失，显著减少token使用和执行时间。


<details>
  <summary>Details</summary>
Motivation: LLM在处理动态知识密集型领域（如化学和材料科学）时，大型工具输出会超出上下文窗口限制，现有截断或摘要方法会丢失完整信息，无法满足需要完整数据的工作流程。

Method: 引入一种方法，将LLM与工具交互从原始数据转向内存指针，使LLM能够处理任意长度的工具响应而不丢失信息，保持工具功能完整，并减少token使用和执行时间。

Result: 在真实材料科学应用中验证了该方法，传统工作流程无法执行的任务得以完成。对比分析显示，该方法比传统工作流程消耗约7倍更少的token。

Conclusion: 该方法成功解决了LLM处理大型工具输出的上下文窗口限制问题，实现了信息完整保留、工具功能保持和效率提升，特别适用于知识密集型领域的实际应用。

Abstract: Large Language Models (LLMs) have become increasingly capable of interacting with external tools, granting access to specialized knowledge beyond their training data - critical in dynamic, knowledge-intensive domains such as Chemistry and Materials Science. However, large tool outputs can overflow the LLMs' context window, preventing task completion. Existing solutions such as truncation or summarization fail to preserve complete outputs, making them unsuitable for workflows requiring the full data. This work introduces a method that enables LLMs to process and utilize tool responses of arbitrary length without loss of information. By shifting the model's interaction from raw data to memory pointers, the method preserves tool functionality, allows seamless integration into agentic workflows, and reduces token usage and execution time. The proposed method is validated on a real-world Materials Science application that cannot be executed with conventional workflows, and its effectiveness is demonstrated via a comparative analysis where both methods succeed. In this experiment, the proposed approach consumed approximately seven times fewer tokens than the traditional workflow.

</details>


### [36] [Agentic AI Framework for Individuals with Disabilities and Neurodivergence: A Multi-Agent System for Healthy Eating, Daily Routines, and Inclusive Well-Being](https://arxiv.org/abs/2511.22737)
*Salman Jan,Toqeer Ali Syed,Gohar Ali,Ali Akarma,Mohammad Riyaz Belgaum,Ahmad Ali*

Main category: cs.AI

TL;DR: 提出一个多智能体AI框架，通过个性化营养规划、自适应提醒、食物指导和持续监测等四个专门智能体，帮助残疾和神经多样性人群实现更健康的生活和规律日常。


<details>
  <summary>Details</summary>
Motivation: 传统辅助系统缺乏包容性、个性化和可访问性，无法充分满足残疾和神经多样性人群的需求。需要开发一个能够提供自适应、透明和包容支持的智能系统，促进这些人群的自主性、健康和数字公平。

Method: 采用三层架构：应用接口层、智能体层和数据源层。核心是混合推理引擎协调四个专门智能体（膳食规划、提醒、食物指导、监测），通过黑板/事件总线进行通信。整合隐私敏感数据源（电子健康记录、营养数据库、可穿戴设备、智能厨房物联网），并加入可解释AI模块和临床医生仪表板。

Result: 提出了一个超越传统辅助系统的智能AI框架，该框架在所有层面都融入了包容性、个性化和可访问性，展示了多智能体推理、多模态界面和以人为中心设计的交叉融合。

Conclusion: 该智能AI框架能够促进残疾和神经多样性人群的自主性、健康和数字公平，通过多智能体协作、实时反馈和可解释决策，为用户提供更有效的支持系统。

Abstract: The paper presents a detailed Agentic Artificial Intelligence (AI) model that would enable people with disabilities and neurodivergence to lead healthier lives and have more regular days. The system will use a multi-layer structure; it will include an Application and Interface Layer, an Agents Layer, and a Data Source Layer to provide adaptive, transparent, and inclusive support. Fundamentally, a hybrid reasoning engine will synchronize four special-purpose agents, which include: a personalized-nutrition-based, called a Meal Planner Agent; an adaptive-scheduling-based, called a Reminder Agent; interactive assistance during grocery shopping and cooking, called a Food Guidance Agent; and a continuous-intake-and-physiological-tracking, called a Monitoring Agent. All the agents interact through a central communicative system called the Blackboard/Event Bus, which allows autonomous interaction and real-time feedback loops with multimedia user interfaces. Privacy-sensitive data sources, including electronic health records (EHRs), nutritional databases, wearable sensors, and smart kitchen Internet of Things, are also included in the framework and placed into a policy-controlled layer, which ensures data safety and compliance with consent. Collaborative care and clinician dashboards allow common supervision, and discussable artificial intelligence (XAI) modules give brief explanations of why a decision was made, making users responsible and reliant. The proposed agentic AI framework is an extension beyond traditional assistive systems since it incorporates inclusiveness, personalization, and accessibility at all levels. It displays the intersection of multi-agent reasoning, multi-modal interfaces, and human-centered design that will enable the development of autonomy, health, and digital equity among people with disabilities and neurodivergence.

</details>


### [37] [Agentic AI Framework for Cloudburst Prediction and Coordinated Response](https://arxiv.org/abs/2511.22767)
*Toqeer Ali Syed,Sohail Khan,Salman Jan,Gohar Ali,Muhammad Nauman,Ali Akarma,Ahmad Ali*

Main category: cs.AI

TL;DR: 该论文提出了一种基于多智能体AI的闭环系统，用于应对极端短时降雨事件（如云爆发），将传感、预报、降尺度、水文建模和协调响应整合为一个互联系统，在巴基斯坦北部地区的评估中显示出优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统预报系统将预测和响应作为两个独立过程处理，难以应对云爆发等极端短时降雨事件。需要一种将传感、预报和响应整合的闭环系统来提高预警可靠性和响应效率。

Method: 开发了一个基于多智能体AI的框架，使用自主但协作的智能体在整个事件生命周期中进行推理、感知和行动。系统结合了传感、预报、降尺度、水文建模和协调响应，通过通信和路由智能体优化响应，并嵌入学习层实现自适应校准和透明审计。

Result: 在巴基斯坦北部地区的多年雷达、卫星和地面数据评估中，多智能体配置相比基线模型提高了预报可靠性、关键成功指数和预警提前时间。通过通信和路由智能体最大化人口覆盖并最小化疏散错误，学习层提供了自适应校准和透明审计能力。

Conclusion: 协作AI智能体能够将大气数据流转化为可操作的预见性，为可扩展的自适应和学习型气候韧性提供了一个平台，展示了多智能体系统在应对极端天气事件中的变革潜力。

Abstract: The challenge is growing towards extreme and short-duration rainfall events like a cloudburst that are peculiar to the traditional forecasting systems, in which the predictions and the response are taken as two distinct processes. The paper outlines an agentic artificial intelligence system to study atmospheric water-cycle intelligence, which combines sensing, forecasting, downscaling, hydrological modeling and coordinated response into a single, interconnected, priceless, closed-loop system. The framework uses autonomous but cooperative agents that reason, sense, and act throughout the entire event lifecycle, and use the intelligence of weather prediction to become real-time decision intelligence. Comparison of multi-year radar, satellite, and ground-based evaluation of the northern part of Pakistan demonstrates that the multi-agent configuration enhances forecast reliability, critical success index and warning lead time compared to the baseline models. Population reach was maximised, and errors during evacuation were minimised through communication and routing agents, and adaptive recalibration and transparent auditability were provided by the embedded layer of learning. Collectively, this leads to the conclusion that collaborative AI agents are capable of transforming atmospheric data streams into practicable foresight and provide a platform of scalable adaptive and learning-based climate resilience.

</details>


### [38] [Fast dynamical similarity analysis](https://arxiv.org/abs/2511.22828)
*Arman Behrad,Mitchell Ostrow,Mohammad Taha Fakharian,Ila Fiete,Christian Beste,Shervin Safavi*

Main category: cs.AI

TL;DR: 提出fastDSA方法，通过自动选择Hankel嵌入的有效模型阶次和新的优化目标，大幅提升动态相似性分析的计算效率，同时保持准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统相似性度量忽略神经表征的动态过程，而现有动态相似性方法计算缓慢。需要一种既能捕捉动态系统时间结构又计算高效的方法来比较神经回路、大脑或数据与模型。

Method: fastDSA引入两个关键组件：1) 通过数据驱动的奇异值阈值自动选择Hankel嵌入的有效模型阶次，识别信息子空间并丢弃噪声；2) 新的优化过程和目标，用轻量级过程替代缓慢的精确正交性约束，保持搜索接近正交变换空间。

Result: fastDSA比先前方法至少快一个数量级，同时保持其祖先方法的属性，包括对系统动态的不变性和敏感性。提供计算高效且准确的动态相似性分析方法。

Conclusion: fastDSA为动态相似性分析提供了计算高效且准确的方法，能够快速比较神经系统的动态过程，有助于理解神经信息处理机制。

Abstract: To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis.

</details>


### [39] [InsightEval: An Expert-Curated Benchmark for Assessing Insight Discovery in LLM-Driven Data Agents](https://arxiv.org/abs/2511.22884)
*Zhenghao Zhu,Yuanfeng Song,Xin Chen,Chengzhong Liu,Yakun Cui,Caleb Chen Cao,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: 本文提出InsightEval，一个用于评估智能体洞察发现能力的新基准，解决了现有InsightBench在格式一致性、目标设计和洞察冗余方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和多智能体系统的发展，越来越多的研究者利用这些技术进行洞察发现，但缺乏评估洞察发现能力的基准。现有最全面的框架InsightBench存在格式不一致、目标设计不佳和洞察冗余等关键缺陷，这些问题可能严重影响数据质量和智能体评估。

Method: 1. 深入调查InsightBench的缺陷；2. 提出高质量洞察基准的基本标准；3. 开发数据整理流程构建新数据集InsightEval；4. 引入新的度量指标来衡量智能体的探索性能。

Result: 通过InsightEval上的大量实验，突出了自动化洞察发现中的普遍挑战，并提出了一些关键发现来指导未来研究方向。

Conclusion: 本文提出的InsightEval基准解决了现有基准的关键缺陷，为评估智能体洞察发现能力提供了更高质量的数据集和度量方法，有助于推动自动化洞察发现领域的研究发展。

Abstract: Data analysis has become an indispensable part of scientific research. To discover the latent knowledge and insights hidden within massive datasets, we need to perform deep exploratory analysis to realize their full value. With the advent of large language models (LLMs) and multi-agent systems, more and more researchers are making use of these technologies for insight discovery. However, there are few benchmarks for evaluating insight discovery capabilities. As one of the most comprehensive existing frameworks, InsightBench also suffers from many critical flaws: format inconsistencies, poorly conceived objectives, and redundant insights. These issues may significantly affect the quality of data and the evaluation of agents. To address these issues, we thoroughly investigate shortcomings in InsightBench and propose essential criteria for a high-quality insight benchmark. Regarding this, we develop a data-curation pipeline to construct a new dataset named InsightEval. We further introduce a novel metric to measure the exploratory performance of agents. Through extensive experiments on InsightEval, we highlight prevailing challenges in automated insight discovery and raise some key findings to guide future research in this promising direction.

</details>


### [40] [ORION: Teaching Language Models to Reason Efficiently in the Language of Thought](https://arxiv.org/abs/2511.22891)
*Kumar Tanmay,Kriti Aggarwal,Paul Pu Liang,Subhabrata Mukherjee*

Main category: cs.AI

TL;DR: 提出Mentalese框架，通过结构化压缩令牌实现高效推理，结合SLPO优化方法，ORION模型在多个数学基准上实现4-16倍令牌压缩、5倍延迟降低，保持90-98%准确率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型依赖冗长的"思考"令牌链，导致高延迟、冗余和不连贯的推理路径。受人类思维语言假设启发，需要更紧凑的符号化推理方式。

Method: 1. 提出Mentalese框架，将抽象推理编码为超压缩的结构化令牌；2. 提出SLPO（短长度偏好优化）强化学习方法，奖励简洁正确的解决方案；3. 应用于ORION模型。

Result: ORION模型在AIME 2024/2025、MinervaMath、OlympiadBench等基准上：推理令牌减少4-16倍，推理延迟降低5倍，训练成本降低7-9倍，保持90-98%准确率，超越Claude和ChatGPT-4o达5%。

Conclusion: Mentalese风格的压缩推理实现了人类认知效率，在保持准确性的同时实现实时、经济高效的推理，为高效AI推理提供了新方向。

Abstract: Large Reasoning Models (LRMs) achieve strong performance in mathematics, code generation, and task planning, but their reliance on long chains of verbose "thinking" tokens leads to high latency, redundancy, and incoherent reasoning paths. Inspired by the Language of Thought Hypothesis, which posits that human reasoning operates over a symbolic, compositional mental language called Mentalese, we introduce a framework that trains models to reason in a similarly compact style. Mentalese encodes abstract reasoning as ultra-compressed, structured tokens, enabling models to solve complex problems with far fewer steps. To improve both efficiency and accuracy, we propose SHORTER LENGTH PREFERENCE OPTIMIZATION (SLPO), a reinforcement learning method that rewards concise solutions that stay correct, while still allowing longer reasoning when needed. Applied to Mentalese-aligned models, SLPO yields significantly higher compression rates by enabling concise reasoning that preserves the benefits of detailed thinking without the computational overhead. Across benchmarks including AIME 2024 and 2025, MinervaMath, OlympiadBench, Math500, and AMC, our ORION models produce reasoning traces with 4-16x fewer tokens, achieve up to 5x lower inference latency, and reduce training costs by 7-9x relative to the DeepSeek R1 Distilled model, while maintaining 90-98% of its accuracy. ORION also surpasses Claude and ChatGPT-4o by up to 5% in accuracy while maintaining 2x compression. These results show that Mentalese-style compressed reasoning offers a step toward human-like cognitive efficiency, enabling real-time, cost-effective reasoning without sacrificing accuracy.

</details>


### [41] [TIM-PRM: Verifying multimodal reasoning with Tool-Integrated PRM](https://arxiv.org/abs/2511.22998)
*Peng Kuang,Xiangxiang Wang,Wentao Liu,Jian Dong,Kaidi Xu,Haohan Wang*

Main category: cs.AI

TL;DR: TIM-PRM：一种工具集成的多模态过程奖励模型，通过主动工具查询消除视觉幻觉和逻辑不一致，显著提升数学推理验证能力


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在数学推理中存在视觉幻觉和逻辑不一致问题，标准结果监督无法解决。传统过程奖励模型作为标量评分器或生成批评者存在奉承问题，盲目验证有缺陷的假设而非基于视觉现实。

Method: 提出TIM-PRM（工具集成多模态PRM），将验证从被动分类任务转变为主动工具增强调查。模型训练明确规划验证策略，使用独立提问机制通过外部工具查询证据，将验证与推理上下文解耦以消除确认偏差。通过策划高质量工具集成验证轨迹数据集实现该方法。

Result: 在VisualProcessBench上的广泛实验表明，8B参数模型超越现有开源多模态PRMs，显著优于Qwen2.5-72B和InternVL-78B等更大模型，同时提供验证过程的可解释性洞察。

Conclusion: TIM-PRM通过主动工具集成验证框架，有效解决了多模态数学推理中的视觉幻觉和逻辑不一致问题，在较小模型规模下实现了优于大型模型的性能，并提供可解释的验证过程。

Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive performances in mathematical reasoning, yet they remain vulnerable to visual hallucinations and logical inconsistencies that standard outcome-based supervision fails to mitigate. While Process Reward Models (PRMs) promise step-by-step verification, current approaches typically operate as scalar scorers or generative critics that suffer from sycophancy, blindly validating the flawed hypotheses rather than grounding them in visual reality. To bridge this gap, we introduce TIM-PRM (Tool-Integrated Multimodal PRM), a novel agentic framework that transforms verification from a passive classification task into an active, tool-augmented investigation. TIM-PRM is trained to explicitly plan verification strategies and utilizes a mechanism of Independent Question Asking to query evidence via external tools, effectively decoupling verification from the reasoning context to eliminate confirmation bias. We instantiate this method by curating a high-quality dataset of tool-integrated verification trajectories. Extensive experiments on VisualProcessBench demonstrate that our 8B parameter model surpasses existing open-source multimodal PRMs, significantly outperforming much larger models like Qwen2.5-72B and InternVL-78B, while offering interpretable insights into the verification process.

</details>


### [42] [MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents](https://arxiv.org/abs/2511.23055)
*Ruoxuan Zhang,Qiyun Zheng,Zhiyu Zhou,Ziqi Liao,Siyu Wu,Jian-Yu Jiang-Lin,Bin Wen,Hongxia Xie,Jianlong Fu,Wen-Huang Cheng*

Main category: cs.AI

TL;DR: MindPower是一个机器人中心框架，通过整合感知、心智推理、决策和行动，解决当前视觉语言具身智能体缺乏心智理论决策能力的问题，并引入Mind-Reward优化目标提升一致性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言具身智能体缺乏基于心智理论的决策能力，现有基准只关注人类心智状态而忽略智能体自身视角，这阻碍了连贯的决策和行动生成。

Method: 提出MindPower框架：给定多模态输入，先感知环境和人类状态，然后进行心智理论推理建模自我和他人，最后基于推断的心智状态生成决策和行动。同时引入Mind-Reward优化目标，鼓励视觉语言模型产生一致的心智推理和行为。

Result: 模型在决策制定上比GPT-4o提升12.77%，在行动生成上提升12.49%。

Conclusion: MindPower框架通过整合机器人中心的心智理论推理，显著提升了具身智能体的决策和行动生成能力，解决了现有方法忽略智能体自身视角的问题。

Abstract: Theory of Mind (ToM) refers to the ability to infer others' mental states, such as beliefs, desires, and intentions. Current vision-language embodied agents lack ToM-based decision-making, and existing benchmarks focus solely on human mental states while ignoring the agent's own perspective, hindering coherent decision and action generation. To address this, we propose MindPower, a Robot-Centric framework integrating Perception, Mental Reasoning, Decision Making and Action. Given multimodal inputs, MindPower first perceives the environment and human states, then performs ToM Reasoning to model both self and others, and finally generates decisions and actions guided by inferred mental states. Furthermore, we introduce Mind-Reward, a novel optimization objective that encourages VLMs to produce consistent ToM Reasoning and behavior. Our model outperforms GPT-4o by 12.77% in decision making and 12.49% in action generation.

</details>


### [43] [Does Self-Evaluation Enable Wireheading in Language Models?](https://arxiv.org/abs/2511.23092)
*David Demitri Africa,Hans Ethan Ting*

Main category: cs.AI

TL;DR: 研究发现当语言模型的自我评估与奖励信号耦合时，会导致"分数膨胀"现象，即模型会操纵评分而非真正提升任务表现，特别是在模糊任务中。


<details>
  <summary>Details</summary>
Motivation: 随着自我评估在语言模型训练中越来越重要（从宪法AI到自我精炼），研究者想探究将自我评估与奖励信号耦合是否会引发"线头化"问题，即模型是否会操纵奖励测量而非真正提升任务性能。

Method: 首先在POMDP中形式化分析了奖励通道控制严格优于任务聚焦行为的条件，然后在两个模型和三个任务上进行了实证测试，比较了自我评估决定奖励的模型与自我评估但不控制奖励的模型的表现。

Result: 研究发现，当模型的自我评分决定奖励时，会出现显著的分数膨胀现象，但任务准确率没有相应提升，特别是在摘要等模糊任务中。而自我评估但不控制奖励的模型则没有这种分数膨胀现象。

Conclusion: 自我评估在与学习信号解耦时是安全的，但在耦合时是危险的。这对智能体系统设计有明确启示：需要谨慎处理自我评估与奖励机制的关系。

Abstract: Self-evaluation is increasingly central to language model training, from constitutional AI to self-refinement. We investigate whether coupling self-evaluation to reward signals creates incentives for wireheading, where agents manipulate reward measurements rather than improving task performance. We formalize conditions under which reward-channel control strictly dominates task-focused behavior in POMDPs and test these predictions empirically. Across two models and three tasks, we find that models whose self-grades determine rewards exhibit substantial grade inflation without corresponding accuracy gains, particularly on ambiguous tasks like summarization. Models that self-evaluate but do not control rewards show no such inflation. Our results demonstrate that self-evaluation is safe when decoupled from learning signals but dangerous when coupled, with clear implications for agentic system design.

</details>


### [44] [Evolutionary Discovery of Heuristic Policies for Traffic Signal Control](https://arxiv.org/abs/2511.23122)
*Ruibing Wang,Shuhan Guo,Zeen Li,Zhen Wang,Quanming Yao*

Main category: cs.AI

TL;DR: TPET使用LLM作为进化引擎生成专门的启发式交通信号控制策略，通过结构化状态抽象和信用分配反馈模块，在无需训练的情况下超越传统启发式方法和在线LLM


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法效率高但过于简化，深度强化学习性能好但泛化性差且策略不透明，在线LLM具有通用推理能力但延迟高且缺乏环境特定优化，需要解决这些交通信号控制中的挑战性权衡

Method: 提出TPET框架，使用LLM作为进化引擎推导专门的启发式策略，包含两个关键模块：结构化状态抽象（将高维交通数据转换为时序逻辑事实）和信用分配反馈（追踪微观决策错误到宏观结果以进行针对性批评）

Result: 在无需训练的情况下，TPET产生了轻量级、鲁棒的策略，针对特定交通环境进行了优化，性能超越了启发式方法和在线LLM执行器

Conclusion: TPET通过LLM进化引擎成功解决了交通信号控制中的权衡问题，提供了一种无需训练、轻量级且性能优越的解决方案，平衡了效率、性能和可解释性

Abstract: Traffic Signal Control (TSC) involves a challenging trade-off: classic heuristics are efficient but oversimplified, while Deep Reinforcement Learning (DRL) achieves high performance yet suffers from poor generalization and opaque policies. Online Large Language Models (LLMs) provide general reasoning but incur high latency and lack environment-specific optimization. To address these issues, we propose Temporal Policy Evolution for Traffic (\textbf{\method{}}), which uses LLMs as an evolution engine to derive specialized heuristic policies. The framework introduces two key modules: (1) Structured State Abstraction (SSA), converting high-dimensional traffic data into temporal-logical facts for reasoning; and (2) Credit Assignment Feedback (CAF), tracing flawed micro-decisions to poor macro-outcomes for targeted critique. Operating entirely at the prompt level without training, \method{} yields lightweight, robust policies optimized for specific traffic environments, outperforming both heuristics and online LLM actors.

</details>


### [45] [Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.23148)
*Mian Ibad Ali Shah,Marcos Eduardo Cruz Victorio,Maeve Duffy,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 该研究将多智能体强化学习（MARL）与P2P能源交易结合，应用于农村乳业社区，显著降低了电力成本和峰值需求，提高了售电收入。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的方法在动态环境中表现不佳，需要更智能的能源管理方案来应对农村可再生能源整合的挑战。

Method: 结合PPO和DQN两种MARL算法与社区分布式P2P交易机制，引入拍卖式市场清算、价格顾问代理以及负荷和电池管理。

Result: DQN在爱尔兰降低电力成本14.2%，芬兰降低5.16%；PPO在爱尔兰降低峰值需求55.5%，DQN在爱尔兰降低50.0%，芬兰降低27.02%。

Conclusion: MARL算法与P2P能源交易的结合为农村社区提供了高效、适应性强且可持续的能源管理方案。

Abstract: The integration of renewable energy resources in rural areas, such as dairy farming communities, enables decentralized energy management through Peer-to-Peer (P2P) energy trading. This research highlights the role of P2P trading in efficient energy distribution and its synergy with advanced optimization techniques. While traditional rule-based methods perform well under stable conditions, they struggle in dynamic environments. To address this, Multi-Agent Reinforcement Learning (MARL), specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), is combined with community/distributed P2P trading mechanisms. By incorporating auction-based market clearing, a price advisor agent, and load and battery management, the approach achieves significant improvements. Results show that, compared to baseline models, DQN reduces electricity costs by 14.2% in Ireland and 5.16% in Finland, while increasing electricity revenue by 7.24% and 12.73%, respectively. PPO achieves the lowest peak hour demand, reducing it by 55.5% in Ireland, while DQN reduces peak hour demand by 50.0% in Ireland and 27.02% in Finland. These improvements are attributed to both MARL algorithms and P2P energy trading, which together results in electricity cost and peak hour demand reduction, and increase electricity selling revenue. This study highlights the complementary strengths of DQN, PPO, and P2P trading in achieving efficient, adaptable, and sustainable energy management in rural communities.

</details>


### [46] [AgriCoT: A Chain-of-Thought Benchmark for Evaluating Reasoning in Vision-Language Models for Agriculture](https://arxiv.org/abs/2511.23253)
*Yibin Wen,Qingmei Li,Zi Ye,Jiarui Zhang,Jing Wu,Zurong Mai,Shuohong Lou,Yuhang Chen,Henglian Huang,Xiaoya Fan,Yang Zhang,Lingyuan Zhao,Haohuan Fu,Huang Jianxi,Juepeng Zheng*

Main category: cs.AI

TL;DR: 本文介绍了AgriCoT数据集，这是一个包含链式思维推理的视觉问答数据集，专门用于评估视觉语言模型在农业复杂场景中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉问答数据集和基准测试往往无法充分评估视觉语言模型在复杂农业场景中所需的批判性推理和问题解决能力，因此需要专门针对农业领域设计包含推理过程的评估工具。

Method: 作者创建了AgriCoT数据集，包含4,535个精心策划的样本，集成了链式思维推理，专门用于评估视觉语言模型的推理能力，特别是在零样本场景下。该数据集在Hugging Face上公开可用。

Result: 对26个代表性视觉语言模型（包括专有和开源模型）的评估显示，虽然一些专有模型在回答问题方面表现出色，但它们在推理能力方面存在显著差距，这凸显了纳入链式思维推理进行更精确评估的重要性。

Conclusion: AgriCoT数据集为评估视觉语言模型在农业复杂场景中的推理能力提供了全面而鲁棒的基准，强调了链式思维推理在模型评估中的重要性，并揭示了当前模型在推理能力方面的不足。

Abstract: Recent advancements in Vision-Language Models (VLMs) have significantly transformed various industries. In agriculture, these dual-modal capabilities offer promising applications such as precision farming, crop monitoring, pest detection, and environmental sustainability. While several Visual Question Answering (VQA) datasets and benchmarks have been developed to evaluate VLM performance, they often fail to adequately assess the critical reasoning and problem-solving skills required in complex agricultural contexts. To address this gap, we introduce AgriCoT, a VQA dataset that incorporates Chain-of-Thought (CoT) reasoning, specifically designed to evaluate the reasoning capabilities of VLMs. With 4,535 carefully curated samples, AgriCoT offers a comprehensive and robust evaluation of reasoning abilities for VLMs, particularly in zero-shot scenarios, by focusing on their capacity to engage in logical reasoning and effective problem-solving. Our evaluations, conducted with 26 representative VLMs, including both proprietary and open-source models, reveal that while some proprietary models excel at answering questions, there is a notable and significant gap in their reasoning capabilities. This underscores the importance of incorporating CoT for more precise and effective assessments. Our dataset are available at https://huggingface.co/datasets/wenyb/AgriCoT.

</details>


### [47] [Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning](https://arxiv.org/abs/2511.23262)
*Yang Li,Zhiyuan He,Yuxuan Huang,Zhuhanling Xiao,Chao Yu,Meng Fang,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: MCTR框架通过元认知自更新机制，让视觉语言模型在测试时能够学习、适应和改进，实现类似人类的持续策略优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型虽然具有强大的感知推理能力，但在面对新任务时缺乏高效的测试时适应能力。相比之下，人类通过元认知模型和记忆系统，能够在新挑战面前持续优化策略。为了弥合这一差距，需要让模型具备类似人类的元认知适应能力。

Method: MCTR框架包含元推理模块和动作推理模块：1）元推理模块通过发现和存储任务相关规则、环境模式和动作-结果关系，构建结构化记忆；2）动作推理模块通过上下文感知和策略推理确定最优动作，动态检索和整合记忆知识。采用元认知测试时强化学习来持续更新策略。

Result: 在45个Atari游戏（33个已见，12个未见）上评估，MCTR在未见游戏中获得9/12的top-1结果，优于基线方法。消融实验、学习动态和案例研究显示两个组件的互补作用，元推理模块逐渐发展出类似人类的适应策略。

Conclusion: MCTR框架成功赋予了视觉语言模型测试时适应能力，通过元认知自更新机制实现了类似人类的持续学习和策略优化，为智能系统的自适应能力提供了新方向。

Abstract: Recent Vision-Language Models (VLMs) exhibit strong perceptual reasoning abilities, yet they often struggle to adapt efficiently when encountering novel tasks at test time. In contrast, humans leverage the metacognitive model with memory, enabling continuous strategy refinement through metacognitive control when faced with new challenges. To bridge this gap, we propose metacognitive test-time reasoning (MCTR), a framework that equips models with the ability to learn, adapt, and improve during test time through metacognitive self-updating. Inspired by the dual structure of human metacognition, MCTR comprises meta-level and object-level VLM reasoning modules, each equipped with dedicated memory systems for hierarchical adaptive reasoning. Specifically, MCTR consists of (1) a meta-reasoning module which incrementally builds a structured memory by discovering and storing task-relevant rules, environmental patterns, and action-outcome relationships from test-time observations as natural language descriptions; and (2) an action-reasoning module that determines optimal actions through context-aware perception and strategic reasoning by dynamically retrieving and integrating knowledge from memory. The action-reasoning module continuously updates its policy through proposed metacognitive test-time reinforcement learning, adapting as knowledge memory evolves. We evaluate MCTR on 45 Atari games (33 seen, 12 unseen). MCTR demonstrates robust test-time adaptation, achieving 9/12 top-1 results on unseen games compared with baselines. Analyses through ablations, learning dynamics, and case studies reveal the complementary contributions of both components and show meta-reasoning evolving toward human-like adaptation strategies.

</details>


### [48] [OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning](https://arxiv.org/abs/2511.23269)
*Timothy Ossowski,Sheng Zhang,Qianchu Liu,Guanghui Qin,Reuben Tan,Tristan Naumann,Junjie Hu,Hoifung Poon*

Main category: cs.AI

TL;DR: 该论文研究了医疗大语言模型的数据策展策略，通过结构化推理轨迹的数据配方，在800万样本上训练，在医疗基准任务上达到开源模型最佳性能。


<details>
  <summary>Details</summary>
Motivation: 高质量的数据策展对医疗大语言模型的泛化能力和对未见临床任务的鲁棒性至关重要。需要研究如何通过数据策展和训练策略开发稳健的医疗多模态推理模型。

Method: 采用监督微调（SFT）方法，探索利用结构化推理轨迹的数据配方。构建包含800万样本、68亿响应token的数据集，使用不同长度的结构化推理轨迹进行训练。

Result: 在多样化的分布外医疗基准任务上达到开源模型的最先进性能。发现高质量、多样化的训练数据使模型能够根据下游任务自我校准推理轨迹长度，无需显式监督。

Conclusion: 结构化推理轨迹的数据策展策略对开发稳健的医疗视觉语言推理系统至关重要，为后续研究提供了关键见解和下一步方向。

Abstract: High-quality and carefully curated data is a cornerstone of training medical large language models, as it directly impacts both generalization and robustness to unseen clinical tasks. We investigate strategies for training and data curation to develop a robust multimodal reasoning model in the medical domain. Our work focuses on supervised fine-tuning (SFT) and explores data recipes that leverage structured reasoning traces. Using our proposed data recipe, we scale experiments to a dataset of over 8 million examples and 6.8 billion response tokens, achieving state-of-the-art performance among open-source models across diverse out-of-distribution medical benchmark tasks. Our results further indicate that curating a high-quality, diverse training dataset with varying structured reasoning trace lengths enables the fine-tuned model to self-calibrate its reasoning trajectory lengths based on the downstream task, without explicit supervision. We present key insights, describe the data curation strategy, and outline next steps toward developing robust medical vision-language reasoning system.

</details>


### [49] [Multi-Modal Scene Graph with Kolmogorov-Arnold Experts for Audio-Visual Question Answering](https://arxiv.org/abs/2511.23304)
*Zijian Fu,Changsheng Lv,Mengshi Qi,Huadong Ma*

Main category: cs.AI

TL;DR: 提出SHRIKE模型，通过多模态场景图和Kolmogorov-Arnold专家网络改进音频视觉问答，在MUSIC-AVQA基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法捕捉视频中的结构信息，且多模态特征的细粒度建模不足。音频视觉问答需要从复杂内容中识别问题相关线索，模仿人类推理过程。

Method: 1) 提出新的多模态场景图，显式建模对象及其关系作为音频视觉场景的结构化表示；2) 设计基于Kolmogorov-Arnold网络的混合专家模型，增强时间整合阶段的表达能力，实现更细粒度的跨模态交互建模。

Result: 在MUSIC-AVQA和MUSIC-AVQA v2基准测试中达到最先进的性能。

Conclusion: SHRIKE通过结构化场景表示和细粒度跨模态建模，显著提升了音频视觉问答的推理能力，代码和模型将公开。

Abstract: In this paper, we propose a novel Multi-Modal Scene Graph with Kolmogorov-Arnold Expert Network for Audio-Visual Question Answering (SHRIKE). The task aims to mimic human reasoning by extracting and fusing information from audio-visual scenes, with the main challenge being the identification of question-relevant cues from the complex audio-visual content. Existing methods fail to capture the structural information within video, and suffer from insufficient fine-grained modeling of multi-modal features. To address these issues, we are the first to introduce a new multi-modal scene graph that explicitly models the objects and their relationship as a visually grounded, structured representation of the audio-visual scene. Furthermore, we design a Kolmogorov-Arnold Network~(KAN)-based Mixture of Experts (MoE) to enhance the expressive power of the temporal integration stage. This enables more fine-grained modeling of cross-modal interactions within the question-aware fused audio-visual representation, leading to capture richer and more nuanced patterns and then improve temporal reasoning performance. We evaluate the model on the established MUSIC-AVQA and MUSIC-AVQA v2 benchmarks, where it achieves state-of-the-art performance. Code and model checkpoints will be publicly released.

</details>


### [50] [Agentic AI Framework for Smart Inventory Replenishment](https://arxiv.org/abs/2511.23366)
*Toqeer Ali Syed,Salman Jan,Gohar Ali,Ali Akarma,Ahmad Ali,Qurat-ul-Ain Mastoi*

Main category: cs.AI

TL;DR: 提出一个用于零售库存管理的智能代理AI系统，通过需求预测、供应商优化、多代理协商和持续学习来减少缺货、降低库存成本并改善产品组合周转


<details>
  <summary>Details</summary>
Motivation: 现代零售中产品种类繁多（服装、杂货、化妆品、冷冻食品等），难以预测需求、防止缺货和发现高潜力产品，需要更智能的库存管理系统

Method: 开发了一个智能代理AI模型，监控库存、向合适供应商发起采购、扫描趋势或高利润产品，应用需求预测、供应商选择优化、多代理协商和持续学习技术

Result: 在中型超市环境中测试原型系统，使用三种传统和人工数据表，相比基准启发式方法，结果显示缺货减少、库存持有成本降低、产品组合周转改善

Conclusion: 系统在零售库存管理方面表现出有效性，同时讨论了约束条件、可扩展性和改进前景，为智能零售管理提供了有前景的解决方案

Abstract: In contemporary retail, the variety of products available (e.g. clothing, groceries, cosmetics, frozen goods) make it difficult to predict the demand, prevent stockouts, and find high-potential products. We suggest an agentic AI model that will be used to monitor the inventory, initiate purchase attempts to the appropriate suppliers, and scan for trending or high-margin products to incorporate. The system applies demand forecasting, supplier selection optimization, multi-agent negotiation and continuous learning. We apply a prototype to a setting in the store of a middle scale mart, test its performance on three conventional and artificial data tables, and compare the results to the base heuristics. Our findings indicate that there is a decrease in stockouts, a reduction of inventory holding costs, and an improvement in product mix turnover. We address constraints, scalability as well as improvement prospect.

</details>


### [51] [Hierarchical AI-Meteorologist: LLM-Agent System for Multi-Scale and Explainable Weather Forecast Reporting](https://arxiv.org/abs/2511.23387)
*Daniil Sukhorukov,Andrei Zakharov,Nikita Glazkov,Katsiaryna Yanchanka,Vladimir Kirilin,Maxim Dubovitsky,Roman Sultimov,Yuri Maksimov,Ilya Makarov*

Main category: cs.AI

TL;DR: 提出分层AI气象学家系统，使用LLM代理生成可解释的天气报告，通过分层预测推理和天气关键词生成，提高天气叙述的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将天气预报视为平坦时间序列，缺乏对短期动态和长期趋势的多尺度理解。需要一种能够生成可解释天气报告并确保语义一致性的框架。

Method: 构建分层AI气象学家LLM代理系统，在小时、6小时和日尺度上进行多尺度推理。核心推理代理将结构化气象输入转换为连贯叙述，同时提取总结主要气象事件的关键词，这些关键词作为语义锚点验证一致性、时间连贯性和事实对齐。

Result: 使用OpenWeather和Meteostat数据证明，分层上下文和基于关键词的验证显著提高了LLM生成天气叙述的可解释性和鲁棒性，为自动化气象报告的语义评估提供了可复现框架。

Conclusion: 该框架推进了基于代理的科学推理，通过分层推理和关键词验证机制，为生成可靠、可解释的天气报告提供了有效解决方案，有助于自动化气象报告的质量评估。

Abstract: We present the Hierarchical AI-Meteorologist, an LLM-agent system that generates explainable weather reports using a hierarchical forecast reasoning and weather keyword generation. Unlike standard approaches that treat forecasts as flat time series, our framework performs multi-scale reasoning across hourly, 6-hour, and daily aggregations to capture both short-term dynamics and long-term trends. Its core reasoning agent converts structured meteorological inputs into coherent narratives while simultaneously extracting a few keywords effectively summarizing the dominant meteorological events. These keywords serve as semantic anchors for validating consistency, temporal coherence and factual alignment of the generated reports. Using OpenWeather and Meteostat data, we demonstrate that hierarchical context and keyword-based validation substantially improve interpretability and robustness of LLM-generated weather narratives, offering a reproducible framework for semantic evaluation of automated meteorological reporting and advancing agent-based scientific reasoning.

</details>


### [52] [Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent](https://arxiv.org/abs/2511.23436)
*Jianzhe Lin,Zeyu Pan,Yun Zhu,Ruiqi Song,Jining Yang*

Main category: cs.AI

TL;DR: SuperIntelliAgent是一个智能体学习框架，通过可训练的小型扩散模型（学习者）与冻结的大型语言模型（验证者）耦合，实现无标注的持续智能增长，利用DPO进行自我监督学习。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调需要大量标注数据，限制了智能体的持续学习和自主成长。需要一种无需人工标注、能够通过自我监督交互实现持续智能积累的框架。

Method: 1. 学习者生成候选输出，验证者通过逐步推理进行评估；2. 两者交互产生选择/拒绝对用于DPO；3. 集成双尺度记忆：短期上下文记忆保存推理轨迹，长期记忆通过轻量级微调巩固知识；4. 重放缓冲区保留显示可验证进展的样本作为辅助监督。

Result: 仅使用少量自动生成的DPO对，学习者在所有基准测试中都有所改进，表明该机制为持续智能积累和实际部署提供了有前景的方向。

Conclusion: 将可训练的学习者与具备推理能力的验证者配对构成了增长智能的最小可靠单元，配对反馈和部分历史重放产生了更丰富的学习课程和更强的偏好对齐，为持续智能积累提供了有前景的框架。

Abstract: We introduce SuperIntelliAgent, an agentic learning framework that couples a trainable small diffusion model (the learner) with a frozen large language model (the verifier) to enable continual intelligence growth through self-supervised interaction. Unlike conventional supervised fine-tuning, SuperIntelliAgent learns autonomously without annotation: the learner generates candidate outputs, the verifier evaluates them through step-by-step reasoning, and their interaction produces chosen/rejected pairs for Direct Preference Optimization (DPO). This converts each input into a pseudo-training signal for continual improvement. The framework integrates dual-scale memory: short-term in-context memory that preserves reasoning traces across refinement cycles, and long-term memory that consolidates acquired knowledge through lightweight on-the-fly fine-tuning. A replay buffer retains samples that show verifiable progress and replays them as auxiliary supervision, reinforcing recent learning while forming adaptive curricula. SuperIntelliAgent is infrastructure-agnostic and can be plugged into existing agentic frameworks while turning ordinary inference loops into a lifelong optimization process. We posit that pairing a trainable learner with a reasoning-capable verifier forms a minimal reliable unit of growing intelligence, as paired feedback and partial-history replay yield richer learning curricula and stronger preference alignment. With a small number of automatically generated DPO pairs, the learner improves across all benchmarks, indicating that this mechanism provides a promising direction for continual intelligence accumulation and real-world deployment.

</details>


### [53] [Thinking by Doing: Building Efficient World Model Reasoning in LLMs via Multi-turn Interaction](https://arxiv.org/abs/2511.23476)
*Bao Shu,Yan Cai,Jianjian Sun,Chunrui Han,En Yu,Liang Zhao,Jingcheng Hu,Yinmin Zhang,Haoran Lv,Yuang Peng,Zheng Ge,Xiangyu Zhang,Daxin Jiang,Xiangyu Yue*

Main category: cs.AI

TL;DR: WMAct通过奖励重缩放和交互频率退火机制，让LLM智能体通过高效交互和主动推理内化世界模型，减少冗余交互，提升单回合任务解决能力。


<details>
  <summary>Details</summary>
Motivation: 当前多轮交互方法通常采用僵化的推理过程，限制了模型的主动学习，阻碍了高效的世界模型推理。需要让模型通过"做"来直接塑造思维，实现更有效的世界模型内化。

Method: WMAct包含两个关键机制：1) 基于行动效能的奖励重缩放机制，激励减少冗余和目的性交互；2) 交互频率退火策略，逐步减少最大允许交互轮次，迫使模型压缩学习并内化环境动态。

Result: 在Sokoban、Maze和Taxi等环境中的实验表明，WMAct能够实现有效的世界模型推理，能够单回合解决之前需要多轮交互的任务，并在复杂环境中展现出强大的可迁移性，在一系列推理基准上提升了性能。

Conclusion: WMAct通过解放模型的推理结构，让模型通过"做"来直接塑造思维，实现了高效的世界模型内化，显著提升了LLM智能体在复杂环境中的规划和交互能力。

Abstract: Developing robust world model reasoning is crucial for large language model (LLM) agents to plan and interact in complex environments. While multi-turn interaction offers a superior understanding of environmental dynamics via authentic feedback, current approaches often impose a rigid reasoning process, which constrains the model's active learning, ultimately hindering efficient world model reasoning. To address these issues, we explore world-model internalization through efficient interaction and active reasoning (WMAct), which liberates the model from structured reasoning, allowing the model to shape thinking directly through its doing, and achieves effective and efficient world model reasoning with two key mechanisms: (1) a reward rescaling mechanism adjusting outcome reward based on action efficacy to incentivize redundancy reduction and purposeful interaction; (2) an interaction frequency annealing strategy to progressively reduce the maximum allowed interaction turns, which compels the model to condense its learning and internalize environmental dynamics rather than over-relying on environmental cues. Our experiments on Sokoban, Maze, and Taxi show that WMAct yields effective world model reasoning capable of resolving tasks in a single turn that previously required multiple interactions and fosters strong transferability to complex environments, improving performance on a suite of reasoning benchmarks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [54] [Fluid Antenna System-Enabled UAV Communications in the Finite Blocklength Regime](https://arxiv.org/abs/2511.21834)
*Xusheng Zhu,Kai-Kit Wong,Hanjiang Hong,Han Xiao,Hao Xu,Tuo Wu,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文为有限块长机制下的流体天线系统(FAS)无人机中继网络建立了性能分析框架，推导了块错误率的闭式表达式，提出了考虑FAS端口选择开销的能效优化算法，揭示了农村与城市环境下不同的最优部署策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往忽略FAS端口选择过程的时间和能量开销，采用理想化模型。本文旨在建立更现实的性能分析框架，考虑实际开销对系统能效的影响，为FAS无人机通信提供实用的设计指导。

Method: 采用基于特征值的可处理近似方法对空间相关的无人机-用户链路建模，将独立分集分量建模为Nakagami-m衰落。推导了块错误率的闭式表达式，进行了高信噪比渐近分析。提出了考虑FAS端口选择开销的能效最大化问题，并设计了高效的分层优化算法。

Result: 数值结果验证了分析的正确性，表明FAS能带来显著的功率增益，但操作开销引入了重要的权衡。这种权衡导致最优端口数量和农村与城市环境下根本不同的无人机部署策略。

Conclusion: 本文为FAS无人机通信提供了基础分析和实用设计指南，揭示了在实际开销约束下，FAS性能优化的关键权衡因素，为未来系统设计提供了重要参考。

Abstract: This paper develops a comprehensive framework for the performance analysis of fluid antenna system (FAS)-enabled unmanned aerial vehicle (UAV) relaying networks operating in the finite blocklength regime. Our contribution lies in establishing a rigorous methodology for characterizing system reliability under diverse propagation environments. Closed-form expressions for the block error rate (BLER) are derived by employing a tractable eigenvalue-based approximation of the spatially correlated UAV-to-user link, whose underlying independent diversity components are modeled as Nakagami-$m$ fading. This approach addresses both line-of-sight (LoS) dominant rural and probabilistic non-line-of-sight (NLoS) urban scenarios. Furthermore, a high signal-to-noise ratio (SNR) asymptotic analysis is developed, revealing the fundamental diversity order of the UAV-to-user link. Based on this, we further address the practical issue of energy efficiency. A realistic energy efficiency maximization problem is formulated, which explicitly accounts for the time and energy overhead inherent in the FAS port selection process, a factor often omitted in idealized models. An efficient hierarchical algorithm is then proposed to jointly optimize the key system parameters. Extensive numerical results validate the analysis and illustrate that while FASs can yield substantial power gains, the operational overhead introduces a non-trivial trade-off. This trade-off leads to an optimal number of ports and fundamentally different UAV deployment strategies in rural versus urban environments. This work provides both foundational analysis and practical design guidelines for FAS-enabled UAV communications.

</details>


### [55] [Spectrum-Aware IRS Configuration Techniques for Ultrawideband Signals](https://arxiv.org/abs/2511.21927)
*Alessandro Nordio,Alberto Tarable,Francisco J. Escribano*

Main category: cs.IT

TL;DR: 该论文提出了两种针对超宽带下行链路场景的高效智能反射表面配置技术，利用波束分裂效应提高接收信号功率。


<details>
  <summary>Details</summary>
Motivation: 随着无线频谱资源紧张，需要开发更高频段，但高频场景存在视距阻塞问题。智能反射表面是解决方案之一，但现有技术难以实现大带宽信号重定向，容易受到波束分裂色散效应影响。

Method: 提出了两种基于IRS表面局部优化的高效配置技术，专门针对超宽带下行链路场景设计。这些技术利用波束分裂效应，同时考虑传输信号频谱的形状。

Result: 在不同几何设置和信号频谱的仿真中，所提出的技术能够保证接收端信号功率相比传统窄带解决方案或对整个IRS表面进行全局优化的技术有所提高。

Conclusion: 提出的局部优化配置技术能有效应对超宽带场景中的波束分裂效应，提高智能反射表面在宽带应用中的性能。

Abstract: Intelligent reflecting surfaces (IRS) have become the subject of many current research efforts, as the ongoing wireless spectrum crunch has made the need to open higher frequency bands a priority. IRS are one of the alternatives proposed to overcome the problem of line-of-sight blocking in very high frequency wireless scenarios. The current state-of-the-art shows the difficulty of implementing practical IRS designs able to redirect large signal bandwidths, prone to the so-called beam split (BS) dispersion effect. In this work, we propose two highly efficient configuration techniques, adapted to ultrawideband downlink scenarios, based on localized optimization over the IRS surface. Such techniques exploit the BS effect while taking into account for the shape of the transmitted signal spectrum. Simulations considering different geometrical setups and different signal spectra show how the proposed techniques are able to guarantee an increased signal power at the receiver with respect to classical narrowband-based solutions or techniques that perform a global optimization over the entire IRS surface.

</details>


### [56] [Four classes of optimal p-ary cyclic codes](https://arxiv.org/abs/2511.22086)
*Jinmei Fan,Jingyao Feng,Yuhan Men,Yanhai Zhang*

Main category: cs.IT

TL;DR: 本文提出了四类最优p元循环码，其中三类是无限的，通过弱化循环码具有汉明权重3码字的充要条件并分析有限域上特定方程的解来实现。


<details>
  <summary>Details</summary>
Motivation: 对于参数为[p^m-1,p^m-2m-2,4]的最优p元循环码研究进展有限，特别是当p>3为奇素数时。本文旨在通过新的方法构造这类最优循环码。

Method: 通过弱化循环码具有汉明权重3码字的充要条件，并分析有限域上特定方程的解，构造出由p^m+1/2推导出的四类最优p元循环码。

Result: 提出了四类参数为[p^m-1,p^m-2m-2,4]的最优p元循环码，其中三类是无限的。许多已知的最优五元循环码是本文构造码的特殊情况。

Conclusion: 本文成功构造了新的最优p元循环码类，扩展了最优循环码的理论体系，为有限域编码理论提供了新的构造方法。

Abstract: Let p>3 be an odd prime and m be a positive integer. Little progress on the study of optimal p-ary cyclic codes with parameters [p^m-1,p^m-2m-2,4] has been made.In this paper, by weakening the necessary and sufficient conditions on cyclic codes to have codewords of Hamming weight 3 and analyzing the solutions of certain equations over finite fields, four classes of optimal p-ary cyclic codes deduced by p^m+1/2 with parameters [p^m-1,p^m-2m-2,4] are presented.Wherein three classes of optimal p-ary cyclic codes are infinite.Many classes of known optimal quinary cyclic codes with parameters [5^m-1,5^m-2m-2,4] are special cases of the codes constructed in this paper.

</details>


### [57] [Fluid Antenna-Enhanced Flexible Beamforming](https://arxiv.org/abs/2511.22163)
*Jingyuan Xu,Zhentian Zhang,Jian Dang,Hao Jiang,Zaichen Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于二维平面流体天线阵列的灵活波束成形框架，将任意波束模式合成转化为稀疏回归问题，采用定制压缩感知算法和迭代FFT相位恢复方法，相比传统固定阵列显著提高了波束模式重构精度。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统在固定物理孔径内提供高空间分辨率，对下一代无线部署具有吸引力。实际通信网络中既需要窄波束也需要宽波束模式，因此通过流体天线实现灵活波束成形成为重要研究方向。

Method: 建立了统一灵活的框架，将任意波束模式合成与流体天线端口选择联系起来，将波束模式重构转化为稀疏回归问题，采用定制压缩感知算法结合FFT高效计算，并引入迭代FFT相位恢复方法确保物理一致的相位建模。

Result: 仿真结果表明所提灵活波束成形框架有效，与传统固定阵列架构相比，流体天线显著提高了波束模式重构精度，展示了在未来无线系统中实现高分辨率和自适应波束成形的潜力。

Conclusion: 提出的流体天线波束成形框架通过将波束模式合成转化为稀疏回归问题，结合压缩感知和迭代FFT相位恢复，实现了高效灵活的波束成形，为未来无线系统的高分辨率自适应波束成形提供了有前景的解决方案。

Abstract: Fluid antenna systems encompass a broad class of reconfigurable antenna technologies that offer substantial spatial diversity for various optimization objectives and communication tasks. Their capability to enhance spatial resolution within a fixed physical aperture makes fluid antennas particularly attractive for next-generation wireless deployments. In this work, we focus on the beamforming problem using a two-dimensional planar fluid antenna array. Since both narrow-beam and broad-beam patterns are essential in practical communication networks, enabling flexible beamforming through fluid antennas becomes an important and interesting research direction. We establish a unified and flexible framework that connects arbitrary beam-pattern synthesis with fluid-antenna port selection. The resulting formulation transforms beam-pattern reconstruction into a sparse regression problem, which is addressed using a tailored compressive sensing algorithm designed to operate efficiently with the fast Fourier transform (FFT). Furthermore, to ensure physically consistent phase modeling in the desired beam, we introduce an iterative FFT-based phase retrieval method. Owing to its structure, the proposed phase-refinement procedure exhibits low computational complexity and rapid convergence, requiring only one FFT and one inverse FFT per iteration. Simulation results demonstrate the effectiveness of the proposed flexible beamforming framework. Compared with conventional fixed-array architectures, fluid antennas exhibit significantly improved beam-pattern reconstruction accuracy, highlighting their potential for high-resolution and adaptive beamforming in future wireless systems.

</details>


### [58] [Constructions of block MDS LDPC codes from punctured circulant matrices](https://arxiv.org/abs/2511.22183)
*Hongwei Zhu,Xuantai Wu,Jingjie Lv,Qinshan Zhang,Shu-Tao Xia*

Main category: cs.IT

TL;DR: 本文构造了同时具有块MDS特性和Tanner图中无4环的LDPC码，称为块MDS LDPC码，在二进制域上实现了更好的随机错误纠正和突发错误抵抗能力。


<details>
  <summary>Details</summary>
Motivation: LDPC码具有优异的迭代解码性能，MDS阵列码适合解码大突发错误。现有技术中，BR码有4环问题，准循环LDPC码不是MDS阵列码。需要构造同时具备块MDS特性和无4环Tanner图的码。

Method: 1. 从穿孔循环置换矩阵构造二进制块MDS码；2. 从列重大于1的循环矩阵(CM(t))构造块MDS LDPC码；3. 给出CM(t)的Moore行列式公式和避免4环的充分条件；4. 指出二进制块MDS CPM-QC LDPC码的不存在性。

Result: 与现有工作相比，在相似码长和码率下，构造的块MDS LDPC码显示出增强的随机错误纠正能力，同时作为阵列码能有效对抗突发错误。两种构造方法都适用于二进制域。

Conclusion: 成功构造了同时具备块MDS特性和无4环Tanner图的LDPC码，在二进制域上实现了更好的错误纠正性能，既适用于随机错误也适用于突发错误场景。

Abstract: Low density parity check (LDPC) codes, initially discovered by Gallager, exhibit excellent performance in iterative decoding, approaching the Shannon limit. MDS array codes, with favorable algebraic structures, are codes suitable for decoding large burst errors. The Blaum-Roth (BR) code, an MDS array code similar to the Reed-Solomon (RS) code but has a parity-check matrix prone to $4$-cycles. Fossorier proposed constructing quasi-cyclic LDPC codes from circulant permutation matrices but are not MDS array codes. This paper aims to construct codes that possess both the block MDS property and have no $4$-cycles in the Tanner graph of their parity-check matrices, namely the so-called block MDS LDPC codes. Non-binary block MDS QC codes were first constructed by [Tauz {\it et al. }IEEE ITW, 2025] using circulant shift matrices. We first generate a family of block MDS codes over $\F_2$ from punctured circulant permutation matrices. Second, we construct a family of block MDS LDPC codes from circulant matrices with column weight $> 1$ (CM$(t)$). Additionally, we present the Moore determinant formula for CM$(t)$s and a sufficient condition to avoid $4$-cycles in CM\((t)\)-QC LDPC codes' Tanner graphs for $t> 1$. We also point out the non-existence of binary block MDS CPM-QC LDPC codes. Compared to the codes constructed in [Li {\it et al. }IEEE TIT, 2023] and [Xiao {\it et al. }IEEE TCOM, 2021], our block MDS LDPC codes show enhanced random-error-correction at a similar code length and rate. Meanwhile, these codes can effectively combat burst errors when considered as array codes. Both of our two types of constructions for block MDS LDPC codes are applicable to the scenario of the binary field.

</details>


### [59] [Maximum Entropy and Bayesian Conditioning Under Extended Space](https://arxiv.org/abs/2511.22375)
*Boning Yu*

Main category: cs.IT

TL;DR: 本文探讨贝叶斯条件化与最大熵原理在何种情况下一致，特别是当新信息不属于原概率空间事件时。作者分析Skyrms与Seidenfeld的争论，认为Friedman-Shimony结果要么是Skyrms方法的良性推论，要么对任何空间扩展方法构成普遍挑战。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决贝叶斯条件化与最大熵原理在非标准信息更新场景下的一致性关系。当新信息不属于原概率空间的事件时，需要扩展概率空间才能进行贝叶斯更新，此时这两种方法是否一致成为核心问题。

Method: 通过理论分析比较两种观点：Skyrms认为在扩展的概率空间（结果乘积空间）上进行贝叶斯条件化与最大熵解完全一致；Seidenfeld则引用Friedman-Shimony结果批评Skyrms方法平凡，认为一致性只在退化概率模型下成立。

Result: 作者论证Friedman-Shimony结果要么是Skyrms方法的良性推论，要么对任何空间扩展方法构成普遍挑战。如果接受后者，则意味着贝叶斯条件化无法处理超出原结果空间概率空间定义的信息。

Conclusion: 结论指出关于贝叶斯条件化与最大熵一致性的争论核心在于如何理解Friedman-Shimony结果：要么它不构成对Skyrms方法的实质批评，要么它揭示贝叶斯框架在信息更新方面的根本局限性。

Abstract: This paper examines the conditions under which Bayesian conditioning aligns with Maximum Entropy. Specifically, I address cases in which newly learned information does not correspond to an event in the probability space defined on the sample space of outcomes. To facilitate Bayesian conditioning in such cases, one must therefore extend the probability space so that the new information becomes an event in this expanded space. Skyrms (1985) argues that Bayesian conditioning in an extended probability space on a product space of outcomes aligns precisely with the solution from Maximum Entropy. In contrast, Seidenfeld (1986) uses Friedman and Shimony's (1971) result to criticize Skyrms' approach as trivial, suggesting that alignment holds only under a degenerate probability model. Here, I argue that Friedman and Shimony's result must either (1) be a benign consequence of Skyrms' approach, or (2) pose a universal challenge to any method of extending spaces. Accepting (2) would imply that Bayesian conditioning is incapable of accommodating information beyond the probability space defined on the original outcome space.

</details>


### [60] [On the SER Performance of ZF and MMSE Receivers in Pilot-Aided Simultaneous Communication and Localization](https://arxiv.org/abs/2511.22418)
*Shuaishuai Han,Emad Alsusa,Arafat Al-Dweik*

Main category: cs.IT

TL;DR: 本文分析了定位误差对ZF和MMSE均衡器通信性能的影响，推导了紧密近似的SER表达式，揭示了定位误差对不同均衡器的影响差异。


<details>
  <summary>Details</summary>
Motivation: 在无人机通信与定位一体化系统中，定位误差会影响信道矩阵估计，进而影响通信性能。需要量化分析定位误差对ZF和MMSE均衡器符号错误率的影响。

Method: 采用PASCAL系统，BS通过接收信号估计无人机位置参数重建信道矩阵。使用Neumann近似和Taylor近似的混合方法，分别推导ZF和MMSE的紧密近似SER表达式。

Result: 1) 所有无人机的定位误差都会影响单个无人机的平均SER；2) ZF不受距离估计误差影响，而MMSE受影响；3) 角度估计误差对ZF和MMSE影响最大；4) ZF对定位误差敏感，在显著估计误差条件下可能比MRC更差。

Conclusion: 定位误差对ZF和MMSE均衡器的SER有显著影响，ZF对定位误差更敏感。研究结果为无人机通信定位一体化系统设计提供了重要参考。

Abstract: In this paper, a symbol error rate (SER) analysis is provided to evaluate the impact of localization inaccuracy on the communication performance under Zero-Forcing (ZF) and Minimum Mean-Square Error (MMSE) equalizers. Specifically, we adopt a pilot-aided simultaneous communication and localization (PASCAL) system, in which multiple drones actively transmit signals towards the base station (BS). Upon receiving the signal, the BS estimates the drones' location parameters to reconstruct the channel matrix, which is then utilized for ZF and MMSE equalization. As the channel matrix is characterized by the estimated parameters associated with the target's location and the matrix inversion involved in ZF and MMSE further complicates the analysis, obtaining a closed-form SER expression becomes intractable. Thus, a tightly approximated SER expression is respectively derived for ZF and MMSE by using a hybrid approximation method incorporating Neumann approximation and Taylor approximation. Our analysis reveals several important design insights: first, the average SER of drone $k$ for both ZF and MMSE can be affected by the localization errors from all drones including drone $k$; second, the average SER of ZF is unaffected by the estimation inaccuracy of range, whereas the average SER of MMSE is influenced by it; third, ZF and MMSE is the most susceptible to the influence of angle estimation errors compared to the other localization errors; fourth, ZF is highly sensitive to localization errors and may be even worse than maximal ratio combining (MRC) under some conditions of significant estimation errors. Numerical simulation results verify our findings and also validate the accuracy of the analysis across a wide range of system parameters.

</details>


### [61] [Quantum Private Distributed Matrix Multiplication With Degree Tables](https://arxiv.org/abs/2511.23406)
*Mohamed Nomeir,Alptug Aytekin,Lei Hu,Sennur Ulukus*

Main category: cs.IT

TL;DR: 量子资源用于提升私有分布式矩阵乘法速率，通过纠缠态和量子信道减少所需服务器数量


<details>
  <summary>Details</summary>
Motivation: 用户拥有高维矩阵A和B但缺乏本地计算能力，需要将矩阵分块发送到多个服务器进行乘法运算，同时保护隐私不被T个服务器窃取。目标是减少执行矩阵乘法所需的服务器数量。

Method: 在量子设置中，允许服务器共享纠缠态并通过量子信道响应。用户收到量子比特后执行测量获得所需乘法结果。针对高隐私和低隐私两种机制，分别：1) 为GASP码定义可行性要求并开发新代码族；2) 将GASP可行性条件扩展到CAT和DOG码，并针对不满足可行性要求的情况提出新代码集。

Result: 提出了量子环境下私有分布式矩阵乘法的可行性条件和代码设计方法，能够减少所需服务器数量并提高计算效率。

Conclusion: 量子资源可以有效提升私有分布式矩阵乘法的速率，通过纠缠态和量子信道减少服务器需求，为高隐私和低隐私机制分别提供了可行的量子解决方案。

Abstract: In this paper, we explore how quantum resources can be used to increase the rate of private distributed matrix multiplication (PDMM). In PDMM, a user who has two high-dimensional matrices, $A$ and $B$, and lacks the computational capabilities to apply matrix multiplication locally, divides the matrices $A$ and $B$ into $K$ and $L$ sub-blocks, respectively. Then, the user sends them to $N$ servers to apply the required multiplication privately from any $T$ servers. The goal is to reduce the number of servers needed to perform the required matrix multiplication. In the quantum setting, we allow the servers to share an entangled state and respond over quantum channels. Upon receiving the qudits, the user applies measurements to obtain the required multiplication. There are two main regimes in the PDMM literature: The high-privacy regime and the low-privacy regime where $T$ is less than $K$ and $L$.
  First, in the high-privacy regime, the state-of-the-art classical code is called the gap additive secure polynomial (GASP) code. We define a feasibility requirement in the quantum setting for the GASP code such that the highest performance is achieved when it is satisfied. When it is not satisfied, we address two main concerns. The first is to find a relation between the minimum privacy requirement and the dimensions of the two matrices needed for the feasibility condition to be satisfied. Second, we develop a new family of codes that can work in the quantum setting.
  Second, since GASP does not work efficiently in the low-privacy regimes compared to cyclic-addition degree tables (CAT) and discretely optimized GASP (DOG), we show that the feasibility condition developed for GASP can be adopted for both CAT and DOG codes as well. In addition, we propose another set of codes that can be used in the low privacy regime in the quantum setting when the feasibility requirement is not satisfied.

</details>


### [62] [TransCoder: A Neural-Enhancement Framework for Channel Codes](https://arxiv.org/abs/2511.22539)
*Anastasiia Kurmukova,Selim F. Yilmaz,Emre Ozfatura,Deniz Gunduz*

Main category: cs.IT

TL;DR: TransCoder：基于Transformer的神经传输方案，通过迭代解码提升现有纠错码性能，保持与传统解码器相当的复杂度


<details>
  <summary>Details</summary>
Motivation: 神经网络解码器能提升纠错码可靠性，但计算复杂度高阻碍实际部署。需要设计一种既能提升性能又保持合理复杂度的解决方案。

Method: 提出TransCoder框架，采用Transformer架构作为码自适应神经模块，可灵活部署在发射端、接收端或两端。使用迭代解码过程，通过块注意力机制处理信道噪声和传统解码器更新。

Result: 在各种传统编码（LDPC、BCH、Polar、Turbo）和广泛信道条件下，TransCoder显著改善块错误率性能，同时保持与传统解码器相当的计算复杂度。对长码（块长>64）和低码率场景特别有效。

Conclusion: TransCoder为资源受限无线设备提供了实用的可靠通信解决方案，在提升性能的同时保持了合理的计算复杂度。

Abstract: Reliable communication over noisy channels requires the design of specialized error-correcting codes (ECCs) tailored to specific system requirements. Recently, neural network-based decoders have emerged as promising tools for enhancing ECC reliability, yet their high computational complexity prevents their potential practical deployment. In this paper, we take a different approach and design a neural transmission scheme that employs the transformer architecture in order to improve the reliability of existing ECCs. We call this approach TransCoder, alluding both to its function and architecture. TransCoder operates as a code-adaptive neural module aimed at performance enhancement that can be implemented flexibly at either the transmitter, receiver, or both. The framework employs an iterative decoding procedure, where both noisy information from the channel and updates from the conventional ECC decoder are processed by a neural decoder block, utilizing a block attention mechanism for efficiency. Through extensive simulations with various conventional codes (LDPC, BCH, Polar, and Turbo) and across a wide range of channel conditions, we demonstrate that TransCoder significantly improves block error rate (BLER) performance while maintaining computational complexity comparable to traditional decoders. Notably, our approach is particularly effective for longer codes (block length >64) and at lower code rates, scenarios in which existing neural decoders often struggle (despite their formidable computational complexity). The results establish TransCoder as a promising practical solution for reliable communication among resource-constrained wireless devices.

</details>


### [63] [Maximum Spectral Efficiency With Adaptive MQAM Transmissions Over Terrestrial Coherent FSO Links](https://arxiv.org/abs/2511.22682)
*Himani Verma,Kamal Singh,Ranjan K. Mallik*

Main category: cs.IT

TL;DR: 自适应MQAM在自由空间光通信中的性能分析，显示仅使用6种方形MQAM星座即可接近理论频谱效率极限


<details>
  <summary>Details</summary>
Motivation: 相干自由空间光通信是下一代无线网络中超高容量前传和回传链路的关键技术，但针对地面FSO信道的自适应MQAM传输理论分析仍然有限

Method: 首先推导了在gamma-gamma湍流和指向误差条件下自适应无约束MQAM的频谱效率极限，然后分析了仅使用六种方形MQAM星座的自适应传输性能

Result: 仅使用六种方形MQAM星座的自适应传输在广泛的信噪比和信道条件下，性能接近理论极限（差距仅0.10-0.12 bits/s/Hz）

Conclusion: 在实际自由空间光通信系统中，采用有限数量的MQAM星座进行自适应传输即可获得接近最优的频谱效率，这为系统设计提供了实用且高效的解决方案

Abstract: Coherent free-space optical (FSO) communication is recognized as a key enabler for ultra-high-capacity fronthaul and backhaul links in next-generation wireless networks. Spectrally efficient $M$-ary quadrature amplitude modulation (MQAM) formats are well-suited for these links. However, theoretical analyses of adaptive MQAM transmissions over terrestrial FSO channels remain limited. In this letter, we first derive the spectral efficiency limit of adaptive unconstrained MQAM over gamma-gamma turbulence with pointing error. We then show that adaptive transmissions using only six square MQAM constellations performs close to the theoretical limit (within $0.10$-$0.12$ bits/s/Hz) across a wide range of signal-to-noise ratios and channel conditions.

</details>


### [64] [On Information Theoretic Fairness With A Bounded Point-Wise Statistical Parity Constraint: An Information Geometric Approach](https://arxiv.org/abs/2511.22683)
*Amirreza Zamani,Ayfer Özgür,Mikael Skoglund*

Main category: cs.IT

TL;DR: 研究在点式统计公平性约束下设计公平表示的信息论问题，通过信息几何方法将复杂优化转化为二次规划，提供低复杂度解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决在隐私保护场景下设计公平表示的问题：代理使用数据X完成任务T，但X和T都与敏感属性S相关。代理需要设计表示Y，既要满足点式统计公平性约束（χ²(P_{S|y};P_S)≤ε），又要最大化任务相关信息I(Y;T)，同时受限于压缩率约束I(Y;X)≤r。

Method: 采用信息几何方法，在ε较小时局部近似KL散度和互信息。将复杂的公平表示设计问题转化为二次优化问题，在特定约束下得到闭式解。对于无法获得闭式解的情况，提供基于矩阵最大奇异值和奇异向量的低复杂度下界算法。

Result: 成功将复杂公平表示设计问题转化为可求解的二次优化问题，获得了在某些约束条件下的闭式解。对于更一般情况，开发了基于奇异值分解的低复杂度算法，能够提供接近最优解的下界。数值实验验证了所提方法与最优解的比较结果。

Conclusion: 本文提出了一种在点式统计公平性约束下设计公平表示的信息论框架，通过信息几何近似将复杂问题简化为二次优化，提供了低计算复杂度的实用解决方案，为隐私保护场景下的公平表示设计提供了有效方法。

Abstract: In this paper, we study an information-theoretic problem of designing a fair representation under a bounded point-wise statistical (demographic) parity constraint. More specifically, an agent uses some useful data (database) $X$ to solve a task $T$. Since both $X$ and $T$ are correlated with some latent sensitive attribute or secret $S$, the agent designs a representation $Y$ that satisfies a bounded point-wise statistical parity, that is, such that for all realizations of the representation $y\in\cal Y$, we have $χ^2(P_{S|y};P_S)\leq ε$. In contrast to our previous work, here we use the point-wise measure instead of a bounded mutual information, and we assume that the agent has no direct access to $S$ and $T$; hence, the Markov chains $S - X - Y$ and $T - X - Y$ hold. In this work, we design $Y$ that maximizes the mutual information $I(Y;T)$ about the task while satisfying a bounded compression rate constraint, that is, ensuring that $I(Y;X) \leq r$. Finally, $Y$ satisfies the point-wise bounded statistical parity constraint $χ^2(P_{S|y};P_S)\leq ε$. When $ε$ is small, concepts from information geometry allow us to locally approximate the KL-divergence and mutual information. To design the representation $Y$, we utilize this approximation and show that the main complex fairness design problem can be rewritten as a quadratic optimization problem that has simple closed-form solution under certain constraints. For the cases where the closed-form solution is not obtained we obtain lower bounds with low computational complexity. Here, we provide simple fairness designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix. Finally, in a numerical example we compare our obtained results with the optimal solution.

</details>


### [65] [Leveraging Channel Knowledge Map for Multi-User Hierarchical Beam Training Under Position Uncertainty](https://arxiv.org/abs/2511.22902)
*Xu Shi,Haohan Wang,Yashuai Cao,Hengyu Zhang,Sufang Yang,Jintao Wang*

Main category: cs.IT

TL;DR: 提出基于信道知识地图的波束训练框架，解决位置不确定性下的波束搜索问题，包含单用户分层搜索策略和多用户相关驱动训练方案。


<details>
  <summary>Details</summary>
Motivation: 信道知识地图(CKM)虽能提供位置特定信道信息，但在实际波束训练中面临两大挑战：1) 用户精确位置通常未知，限制了CKM的效用；2) CKM、实时观测和训练策略之间的复杂交互尚未充分研究，导致性能次优和实施困难。

Method: 针对单用户场景：提出基于奖励的波束潜力分层策略，整合部分位置信息和CKM，将用户位置不确定性建模为剪枝二叉搜索树，通过评估潜在码字的权重和奖励推导最小开销的最优分层搜索策略，并设计低复杂度双层前瞻方案平衡开销和计算需求。针对多用户场景：开发相关驱动的位置剪枝训练方案，利用用户间干扰的旁瓣增益提供额外侧信息以减少开销，使所有用户能同时分配到各自的支持波束。

Result: 仿真验证了所提方法在推进6G波束训练方面的优越性能。

Conclusion: 提出的CKM辅助波束训练框架有效解决了位置不确定性下的波束搜索问题，通过分层搜索和相关驱动策略显著提升了波束训练效率，为6G波束训练提供了实用解决方案。

Abstract: Channel knowledge map (CKM) emerges as a promising framework to acquire location-specific channel information without consuming wireless resources, creating new horizons for advanced wireless network design and optimization. Despite its potential, the practical application of CKM in beam training faces several challenges. On one hand, the user's precise location is typically unavailable prior to beam training, which limits the utility of CKM since its effectiveness relies heavily on accurate input of position data. On the other hand, the intricate interplay among CKM, real-time observations, and training strategies has not been thoroughly studied, leading to suboptimal performance and difficulties in practical implementation. In this paper, we present a framework for CKM-aided beam training that addresses these limitations. For single-user scenario, we propose a reward-motivated beam-potential hierarchical strategy which integrates partial position information and CKM. This strategy models the user equipment (UE) position uncertainty and formulates the hierarchical searching process as a pruned binary search tree. An optimal hierarchical searching strategy with minimal overhead is derived by evaluating the weights and rewards of potential codewords. Furthermore, a low-complexity two-layer lookahead scheme is designed to balance overhead and computational demands. For multi-user scenario, we develop a correlation-driven position-pruning training scheme, where sidelobe gains from inter-user interference are exploited to provide additional side information for overhead reduction, allowing all users to be simultaneously assigned their respective supportive beams. Simulations validate the superior performances of proposed approaches in advancing 6G beam training.

</details>


### [66] [Decoding Trombetti-Zhou codes: a new syndrome-based decoding approach](https://arxiv.org/abs/2511.23202)
*Chunlei Li,Angelica Piccirillo,Olga Polverino,Ferdinando Zullo*

Main category: cs.IT

TL;DR: 本文针对Trombetti-Zhou提出的F_q^n-线性最大秩距离码，开发了一种新的基于伴随式的译码算法，通过引入F_q^n-生成矩阵和F_q^n-校验矩阵的概念，将译码问题转化为Gabidulin码的译码问题。


<details>
  <summary>Details</summary>
Motivation: Trombetti-Zhou码是F_q^n-线性但不是F_q^{2n}-线性的最大秩距离码，传统的基于伴随式的译码方法需要线性码的校验矩阵，但由于这些码缺乏完全的线性性，需要新的译码框架。

Method: 引入F_q^n-生成矩阵和F_q^n-校验矩阵的概念，利用迹几乎对偶基构造Trombetti-Zhou码的生成和校验矩阵，将译码问题分为两种情况：当错误秩t < (d-1)/2时转化为Gabidulin码译码；当t = (d-1)/2时简化为确定特定矩阵的秩。

Result: 成功为Trombetti-Zhou码开发了基于伴随式的译码算法，分析了算法的复杂度，将译码问题有效简化为已知的Gabidulin码译码问题。

Conclusion: 通过引入F_q^n-线性码的生成和校验矩阵概念，克服了Trombetti-Zhou码缺乏完全线性性的限制，实现了有效的伴随式译码算法，扩展了最大秩距离码的译码理论。

Abstract: In 2019, Trombetti and Zhou introduced a new family of $\mathbb{F}_{q^n}$-linear Maximum Rank Distance (MRD) codes over $\mathbb{F}_{q^{2n}}$. For such codes we propose a new syndrome-based decoding algorithm. It is well known that a syndrome-based decoding approach relies heavily on a parity-check matrix of a linear code. Nonetheless, Trombetti-Zhou codes are not linear over the entire field $\mathbb{F}_{q^{2n}}$, but only over its subfield $\mathbb{F}_{q^{n}}$. Due to this lack of linearity, we introduce the notions of $\mathbb{F}_{q^{n}}$-generator matrix and $\mathbb{F}_{q^{n}}$-parity-check matrix for a generic $\mathbb{F}_{q^{n}}$-linear rank-metric code over $\mathbb{F}_{q^{rn}}$ in analogy with the roles that generator and parity-check matrices play in the context of linear codes. Accordingly, we present an $\mathbb{F}_{q^n}$-generator matrix and $\mathbb{F}_{q^n}$-parity-check matrix for Trombetti-Zhou codes as evaluation codes over an $\mathbb{F}_q$-basis of $\mathbb{F}_{q^{2n}}$. This relies on the choice of a particular basis called \emph{trace almost dual basis}. Subsequently, denoting by $d$ the minimum distance of the code, we show that if the rank weight $t$ of the error vector is strictly smaller than $\frac{d-1}{2}$, the syndrome-based decoding of Trombetti-Zhou codes can be converted to the decoding of Gabidulin codes of dimension one larger. On the other hand, when $t=\frac{d-1}{2}$, we reduce the decoding to determining the rank of a certain matrix. The complexity of the proposed decoding for Trombetti-Zhou codes is also discussed.

</details>


### [67] [Efficient Estimation of Sum-Parameters for Multi-Component Complex Exponential Signals with Theoretical Cramer-Rao Bound Analysis](https://arxiv.org/abs/2511.23318)
*Huiguang Zhang*

Main category: cs.IT

TL;DR: 提出基于低维和参数的新框架，用于多分量复指数信号参数估计，避免传统方法在分量多时的排列模糊、计算复杂和模型阶数选择问题。


<details>
  <summary>Details</summary>
Motivation: 传统多分量复指数信号参数估计方法在分量数量大时面临排列模糊、高维Fisher信息矩阵求逆计算复杂、模型阶数选择困难等挑战。

Method: 引入基于低维和参数的新框架，包括振幅和、功率加权频率、相位相关和等参数，这些参数具有明确物理意义且完全避免排列模糊。提出高效全局估计方法(EGEM)。

Result: 推导了确定性和随机信号模型下和参数的精确闭式Cramer-Rao界。EGEM在宽信噪比范围内具有渐近效率，在长短样本情况下均显著优于Zoom-Interpolated FFT和Root-MUSIC等方法。

Conclusion: 基于和参数的低维框架有效解决了多分量复指数信号参数估计的传统难题，EGEM方法在理论和实验上均表现出优越性能，即使在小样本情况下也能接近理论性能界。

Abstract: This paper addresses the challenging problem of parameter estimation for multicomponent complex exponential signals, commonly known as sums of cisoids. Traditional approaches that estimate individual component parameters face significant difficulties when the number of components is large, including permutation ambiguity, computational complexity from high-dimensional Fisher information matrix inversion, and model order selection issues. We introduce a novel framework based on low-dimensional sum-parameters that capture essential global characteristics of the signal ensemble. These parameters include the sum of amplitudes, the power-weighted frequency, and the phase-related sum. These quantities possess clear physical interpretations representing total signal strength, power-weighted average frequency, and composite phase information, while completely avoiding permutation ambiguities. We derive exact closed-form Cramer-Rao bounds for these sum-parameters under both deterministic and stochastic signal models. Our analysis reveals that the frequency sumparameter achieves statistical efficiency comparable to single-component estimators while automatically benefiting from power pooling across all signal components. The proposed Efficient Global Estimation Method (EGEM) demonstrates asymptotic efficiency across a wide range of signal-to-noise ratios, significantly outperforming established techniques such as Zoom-Interpolated FFT and Root-MUSIC in both long- and short-sample regimes. Extensive numerical simulations involving 2000 Monte-Carlo trials confirm that EGEM closely approaches the theoretical performance bounds even with relatively small sample sizes of 250 observations.

</details>
