{"id": "2510.24869", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24869", "abs": "https://arxiv.org/abs/2510.24869", "authors": ["Mehrshad Eskandarpour", "Hossein Soleimani"], "title": "Deep Reinforcement Learning Approach to QoSAware Load Balancing in 5G Cellular Networks under User Mobility and Observation Uncertainty", "comment": null, "summary": "Efficient mobility management and load balancing are critical to sustaining\nQuality of Service (QoS) in dense, highly dynamic 5G radio access networks. We\npresent a deep reinforcement learning framework based on Proximal Policy\nOptimization (PPO) for autonomous, QoS-aware load balancing implemented\nend-to-end in a lightweight, pure-Python simulation environment. The control\nproblem is formulated as a Markov Decision Process in which the agent\nperiodically adjusts Cell Individual Offset (CIO) values to steer user-cell\nassociations. A multi-objective reward captures key performance indicators\n(aggregate throughput, latency, jitter, packet loss rate, Jain's fairness\nindex, and handover count), so the learned policy explicitly balances\nefficiency and stability under user mobility and noisy observations. The PPO\nagent uses an actor-critic neural network trained from trajectories generated\nby the Python simulator with configurable mobility (e.g., Gauss-Markov) and\nstochastic measurement noise. Across 500+ training episodes and stress tests\nwith increasing user density, the PPO policy consistently improves KPI trends\n(higher throughput and fairness, lower delay, jitter, packet loss, and\nhandovers) and exhibits rapid, stable convergence. Comparative evaluations show\nthat PPO outperforms rule-based ReBuHa and A3 as well as the learning-based\nCDQL baseline across all KPIs while maintaining smoother learning dynamics and\nstronger generalization as load increases. These results indicate that PPO's\nclipped policy updates and advantage-based training yield robust, deployable\ncontrol for next-generation RAN load balancing using an entirely Python-based\ntoolchain."}
{"id": "2510.25079", "categories": ["cs.NI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.25079", "abs": "https://arxiv.org/abs/2510.25079", "authors": ["Albert Espinal", "V. Sanchez Padilla", "Yesenia Cevallos"], "title": "Performance Evaluation of Multimedia Traffic in Cloud Storage Services over Wi-Fi and LTE Networks", "comment": "2025 20th Iberian Conference on Information Systems and Technologies\n  (CISTI), Lecture Notes in Networks and Systems", "summary": "The performance of Dropbox, Google Drive, and OneDrive cloud storage services\nwas evaluated under Wi-Fi and LTE network conditions during multimedia file\nuploads. Traffic was captured using Wireshark, and key metrics (including\ndelay, jitter, bandwidth, and packet loss) were analyzed. Google Drive\nmaintained the most consistent performance across both types of networks,\nshowing low latency and reduced jitter. Dropbox showed efficient bandwidth\nutilization, but experienced a longer delay over LTE, attributed to a greater\nnumber of intermediate hops. OneDrive presented variable behavior, with\nelevated packet rates and increased sensitivity to fluctuations in the mobile\nnetwork. A bimodal distribution of packet sizes was observed and modeled using\na dual Poisson function. In general, Wi-Fi connections provided greater\nstability for multimedia transfers, while LTE performance varied depending on\nplatform-specific implementations. The results contribute to a better\nunderstanding of traffic behavior in cloud-based storage applications and\nsuggest further analysis with larger datasets and heterogeneous access\nnetworks."}
{"id": "2510.25105", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25105", "abs": "https://arxiv.org/abs/2510.25105", "authors": ["Mihai Mazilu", "Luca Giacomoni", "George Parisis"], "title": "Learning-Based vs Human-Derived Congestion Control: An In-Depth Experimental Study", "comment": "10 pages, 13 figures", "summary": "Learning-based congestion control (CC), including Reinforcement-Learning,\npromises efficient CC in a fast-changing networking landscape, where evolving\ncommunication technologies, applications and traffic workloads pose severe\nchallenges to human-derived, static CC algorithms. Learning-based CC is in its\nearly days and substantial research is required to understand existing\nlimitations, identify research challenges and, eventually, yield deployable\nsolutions for real-world networks. In this paper, we extend our prior work and\npresent a reproducible and systematic study of learning-based CC with the aim\nto highlight strengths and uncover fundamental limitations of the\nstate-of-the-art. We directly contrast said approaches with widely deployed,\nhuman-derived CC algorithms, namely TCP Cubic and BBR (version 3). We identify\nchallenges in evaluating learning-based CC, establish a methodology for\nstudying said approaches and perform large-scale experimentation with\nlearning-based CC approaches that are publicly available. We show that\nembedding fairness directly into reward functions is effective; however, the\nfairness properties do not generalise into unseen conditions. We then show that\nRL learning-based approaches existing approaches can acquire all available\nbandwidth while largely maintaining low latency. Finally, we highlight that\nexisting the latest learning-based CC approaches under-perform when the\navailable bandwidth and end-to-end latency dynamically change while remaining\nresistant to non-congestive loss. As with our initial study, our\nexperimentation codebase and datasets are publicly available with the aim to\ngalvanise the research community towards transparency and reproducibility,\nwhich have been recognised as crucial for researching and evaluating\nmachine-generated policies."}
{"id": "2510.25145", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25145", "abs": "https://arxiv.org/abs/2510.25145", "authors": ["Giancarlo Maldonado Cardenas", "Diana C. Gonzalez", "Judy C. Guevara", "Carlos A. Astudillo", "Nelson L. S. da Fonseca"], "title": "ML-Based Preamble Collision Detection in the Random Access Procedure of Cellular IoT Networks", "comment": null, "summary": "Preamble collision in the random access channel (RACH) is a major bottleneck\nin massive machine-type communication (mMTC) scenarios, typical of cellular IoT\n(CIoT) deployments. This work proposes a machine learning-based mechanism for\nearly collision detection during the random access (RA) procedure. A labeled\ndataset was generated using the RA procedure messages exchanged between the\nusers and the base station under realistic channel conditions, simulated in\nMATLAB. We evaluate nine classic classifiers -- including tree ensembles,\nsupport vector machines, and neural networks -- across four communication\nscenarios, varying both channel characteristics (e.g., Doppler spread,\nmultipath) and the cell coverage radius, to emulate realistic propagation,\nmobility, and spatial conditions. The neural network outperformed all other\nmodels, achieving over 98\\% balanced accuracy in the in-distribution evaluation\n(train and test drawn from the same dataset) and sustaining 95\\% under\nout-of-distribution evaluation (train/test from different datasets). To enable\ndeployment on typical base station hardware, we apply post-training\nquantization. Full integer quantization reduced inference time from 2500 ms to\nas low as 0.3 ms with negligible accuracy loss. The proposed solution combines\nhigh detection accuracy with low-latency inference, making it suitable for\nscalable, real-time CIoT applications found in real networks."}
{"id": "2510.24763", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24763", "abs": "https://arxiv.org/abs/2510.24763", "authors": ["Tingting Huang", "Jundong Chen", "Huanqiang Zeng", "Guofa Cai", "Georges Kaddoum"], "title": "Dual-Domain Deep Learning-Assisted NOMA-CSK Systems for Secure and Efficient Vehicular Communications", "comment": null, "summary": "Ensuring secure and efficient multi-user (MU) transmission is critical for\nvehicular communication systems. Chaos-based modulation schemes have garnered\nconsiderable interest due to their benefits in physical layer security.\nHowever, most existing MU chaotic communication systems, particularly those\nbased on non-coherent detection, suffer from low spectral efficiency due to\nreference signal transmission, and limited user connectivity under orthogonal\nmultiple access (OMA). While non-orthogonal schemes, such as sparse code\nmultiple access (SCMA)-based DCSK, have been explored, they face high\ncomputational complexity and inflexible scalability due to their fixed codebook\ndesigns. This paper proposes a deep learning-assisted power domain\nnon-orthogonal multiple access chaos shift keying (DL-NOMA-CSK) system for\nvehicular communications. A deep neural network (DNN)-based demodulator is\ndesigned to learn intrinsic chaotic signal characteristics during offline\ntraining, thereby eliminating the need for chaotic synchronization or reference\nsignal transmission. The demodulator employs a dual-domain feature extraction\narchitecture that jointly processes the time-domain and frequency-domain\ninformation of chaotic signals, enhancing feature learning under dynamic\nchannels. The DNN is integrated into the successive interference cancellation\n(SIC) framework to mitigate error propagation issues. Theoretical analysis and\nextensive simulations demonstrate that the proposed system achieves superior\nperformance in terms of spectral efficiency (SE), energy efficiency (EE), bit\nerror rate (BER), security, and robustness, while maintaining lower\ncomputational complexity compared to traditional MU-DCSK and existing DL-aided\nschemes. These advantages validate its practical viability for secure vehicular\ncommunications."}
{"id": "2510.24869", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24869", "abs": "https://arxiv.org/abs/2510.24869", "authors": ["Mehrshad Eskandarpour", "Hossein Soleimani"], "title": "Deep Reinforcement Learning Approach to QoSAware Load Balancing in 5G Cellular Networks under User Mobility and Observation Uncertainty", "comment": null, "summary": "Efficient mobility management and load balancing are critical to sustaining\nQuality of Service (QoS) in dense, highly dynamic 5G radio access networks. We\npresent a deep reinforcement learning framework based on Proximal Policy\nOptimization (PPO) for autonomous, QoS-aware load balancing implemented\nend-to-end in a lightweight, pure-Python simulation environment. The control\nproblem is formulated as a Markov Decision Process in which the agent\nperiodically adjusts Cell Individual Offset (CIO) values to steer user-cell\nassociations. A multi-objective reward captures key performance indicators\n(aggregate throughput, latency, jitter, packet loss rate, Jain's fairness\nindex, and handover count), so the learned policy explicitly balances\nefficiency and stability under user mobility and noisy observations. The PPO\nagent uses an actor-critic neural network trained from trajectories generated\nby the Python simulator with configurable mobility (e.g., Gauss-Markov) and\nstochastic measurement noise. Across 500+ training episodes and stress tests\nwith increasing user density, the PPO policy consistently improves KPI trends\n(higher throughput and fairness, lower delay, jitter, packet loss, and\nhandovers) and exhibits rapid, stable convergence. Comparative evaluations show\nthat PPO outperforms rule-based ReBuHa and A3 as well as the learning-based\nCDQL baseline across all KPIs while maintaining smoother learning dynamics and\nstronger generalization as load increases. These results indicate that PPO's\nclipped policy updates and advantage-based training yield robust, deployable\ncontrol for next-generation RAN load balancing using an entirely Python-based\ntoolchain."}
{"id": "2510.24832", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24832", "abs": "https://arxiv.org/abs/2510.24832", "authors": ["Hong Wang", "Zhezheng Hao", "Jian Luo", "Chenxing Wei", "Yao Shu", "Lei Liu", "Qiang Lin", "Hande Dong", "Jiawei Chen"], "title": "Scheduling Your LLM Reinforcement Learning with Reasoning Trees", "comment": null, "summary": "Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large\nLanguage Models (LLMs) can be conceptualized as progressively editing a query's\n`Reasoning Tree'. This process involves exploring nodes (tokens) and\ndynamically modifying the model's policy at each node. When combined with data\nscheduling, this process yields further gains in data efficiency and accuracy.\nHowever, existing RLVR data scheduling methods typically rely on path-based\nmetrics to rank queries, overlooking the reasoning tree structures of these\nqueries. In this paper, we introduce a novel metric, namely Reasoning Score\n(r-score), which measures the query's learning difficulty based on the\nstructure of its reasoning tree. Based on the r-score, we propose the Reasoning\nTree Schedule (Re-Schedule), a scheduling algorithm that constructs a\ncurriculum progressing from structurally simple (high r-score) to complex (low\nr-score) queries. Experiments on six math-reasoning benchmarks show that\nRe-Schedule significantly improves average accuracy, achieving gains of up to\n3.2%. These strong results validate our approach and demonstrate that a\nstructural understanding of the reasoning tree provides a more powerful and\nprincipled foundation for RLVR data scheduling."}
{"id": "2510.25271", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25271", "abs": "https://arxiv.org/abs/2510.25271", "authors": ["Sabrine Aroua", "Christos Anastasios Bovolis", "Bo Göransson", "Anastasios Giovanidis", "Mathieu Leconte", "Apostolos Destounis"], "title": "Adaptive Design of mmWave Initial Access Codebooks using Reinforcement Learning", "comment": "7 pages, 5 figures, submitted to IEEE ICC 2026", "summary": "Initial access (IA) is the process by which user equipment (UE) establishes\nits first connection with a base station. In 5G systems, particularly at\nmillimeter-wave frequencies, IA integrates beam management to support highly\ndirectional transmissions. The base station employs a codebook of beams for the\ntransmission of Synchronization Signal Blocks (SSBs), which are periodically\nswept to detect and connect users. The design of this SSB codebook is critical\nfor ensuring reliable, wide-area coverage. In current networks, SSB codebooks\nare meticulously engineered by domain experts. While these expert-defined\ncodebooks provide a robust baseline, they lack flexibility in dynamic or\nheterogeneous environments where user distributions vary, limiting their\noverall effectiveness. This paper proposes a hybrid Reinforcement Learning (RL)\nframework for adaptive SSB codebook design. Building on top of expert\nknowledge, the RL agent leverages a pool of expert-designed SSB beams and\nlearns to adaptively select or combine them based on real-time feedback. This\nenables the agent to dynamically tailor codebooks to the actual environment,\nwithout requiring explicit user location information, while always respecting\npractical beam constraints. Simulation results demonstrate that, on average,\nthe proposed approach improves user connectivity by 10.8$\\%$ compared to static\nexpert configurations. These findings highlight the potential of combining\nexpert knowledge with data-driven optimization to achieve more intelligent,\nflexible, and resilient beam management in next-generation wireless networks."}
{"id": "2510.25002", "categories": ["cs.IT", "cs.CV", "cs.MM", "eess.IV", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25002", "abs": "https://arxiv.org/abs/2510.25002", "authors": ["Zhenyu Liu", "Yi Ma", "Rahim Tafazolli", "Zhi Ding"], "title": "Resi-VidTok: An Efficient and Decomposed Progressive Tokenization Framework for Ultra-Low-Rate and Lightweight Video Transmission", "comment": null, "summary": "Real-time transmission of video over wireless networks remains highly\nchallenging, even with advanced deep models, particularly under severe channel\nconditions such as limited bandwidth and weak connectivity. In this paper, we\npropose Resi-VidTok, a Resilient Tokenization-Enabled framework designed for\nultra-low-rate and lightweight video transmission that delivers strong\nrobustness while preserving perceptual and semantic fidelity on commodity\ndigital hardware. By reorganizing spatio--temporal content into a discrete,\nimportance-ordered token stream composed of key tokens and refinement tokens,\nResi-VidTok enables progressive encoding, prefix-decodable reconstruction, and\ngraceful quality degradation under constrained channels. A key contribution is\na resilient 1D tokenization pipeline for video that integrates differential\ntemporal token coding, explicitly supporting reliable recovery from incomplete\ntoken sets using a single shared framewise decoder--without auxiliary temporal\nextractors or heavy generative models. Furthermore, stride-controlled frame\nsparsification combined with a lightweight decoder-side interpolator reduces\ntransmission load while maintaining motion continuity. Finally, a\nchannel-adaptive source--channel coding and modulation scheme dynamically\nallocates rate and protection according to token importance and channel\ncondition, yielding stable quality across adverse SNRs. Evaluation results\nindicate robust visual and semantic consistency at channel bandwidth ratios\n(CBR) as low as 0.0004 and real-time reconstruction at over 30 fps,\ndemonstrating the practicality of Resi-VidTok for energy-efficient,\nlatency-sensitive, and reliability-critical wireless applications."}
{"id": "2510.25562", "categories": ["cs.NI", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25562", "abs": "https://arxiv.org/abs/2510.25562", "authors": ["Kaiqiang Lin", "Kangchun Zhao", "Yijie Mao"], "title": "Deep Reinforcement Learning-Based Cooperative Rate Splitting for Satellite-to-Underground Communication Networks", "comment": "6 pages, 3 figures, 1 table, and submitted to IEEE TVT", "summary": "Reliable downlink communication in satellite-to-underground networks remains\nchallenging due to severe signal attenuation caused by underground soil and\nrefraction in the air-soil interface. To address this, we propose a novel\ncooperative rate-splitting (CRS)-aided transmission framework, where an\naboveground relay decodes and forwards the common stream to underground devices\n(UDs). Based on this framework, we formulate a max-min fairness optimization\nproblem that jointly optimizes power allocation, message splitting, and time\nslot scheduling to maximize the minimum achievable rate across UDs. To solve\nthis high-dimensional non-convex problem under uncertain channels, we develop a\ndeep reinforcement learning solution framework based on the proximal policy\noptimization (PPO) algorithm that integrates distribution-aware action modeling\nand a multi-branch actor network. Simulation results under a realistic\nunderground pipeline monitoring scenario demonstrate that the proposed approach\nachieves average max-min rate gains exceeding $167\\%$ over conventional\nbenchmark strategies across various numbers of UDs and underground conditions."}
{"id": "2510.25005", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25005", "abs": "https://arxiv.org/abs/2510.25005", "authors": ["Saptarshi Saha", "Dhruv Vansraj Rathore", "Utpal Garain"], "title": "Cyclic Counterfactuals under Shift-Scale Interventions", "comment": "Accepted at NeurIPS 2025", "summary": "Most counterfactual inference frameworks traditionally assume acyclic\nstructural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,\nmany real-world systems (e.g. biological systems) contain feedback loops or\ncyclic dependencies that violate acyclicity. In this work, we study\ncounterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,\nsoft, policy-style changes that rescale and/or shift a variable's mechanism."}
{"id": "2510.25281", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25281", "abs": "https://arxiv.org/abs/2510.25281", "authors": ["Lukas Prause", "Mark Akselrod"], "title": "TCP ROCCET: An RTT-Oriented CUBIC Congestion Control Extension for 5G and Beyond Networks", "comment": null, "summary": "The behavior of loss-based TCP congestion control algorithms like TCP CUBIC\ncontinues to be a challenge in modern cellular networks. Due to the large RLC\nlayer buffers required to deal with short-term changes in channel capacity, the\nbehavior of both the Slow Start and congestion avoidance phases may be heavily\nimpacted by the lack of packet losses and the resulting bufferbloat. While\nexisting congestion control algorithms like TCP BBR do tend to perform better\neven in the presence of large bottleneck buffers, they still tend to fill the\nbuffer more than necessary and can have fairness issues when compared to\nloss-based algorithms.\n  In this paper, we analyze the issues with the use of loss-based congestion\ncontrol algorithms by analyzing TCP CUBIC, which is currently the most popular\nvariant. To mitigate the issues experienced by TCP CUBIC in cellular networks,\nwe introduce TCP ROCCET, a latency-based extension of TCP CUBIC that responds\nto network congestion based on round-trip time in addition to packet loss.\n  Our findings show that TCP ROCCET can reduce latency and bufferbloat compared\nto the standard CUBIC implementation, without requiring a specific network\narchitecture. Compared to TCP BBRv3, ROCCET offers similar throughput while\nmaintaining lower overall latency. The evaluation was conducted in real 5G\nnetworks, including both stationary and mobile scenarios, confirming ROCCET's\nimproved response to network congestion under varying conditions."}
{"id": "2510.25181", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25181", "abs": "https://arxiv.org/abs/2510.25181", "authors": ["Yixiang Zhou", "Tong Wu", "Meixia Tao", "Jianhua Mo"], "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder", "comment": null, "summary": "This paper addresses the critical challenges of communication overhead, data\nheterogeneity, and privacy in deep learning for channel state information (CSI)\nfeedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel\nfederated learning framework that incorporates personalized encoders and a\nLoRA-adapted shared decoder. Specifically, personalized encoders are trained\nlocally on each user equipment (UE) to capture device-specific channel\ncharacteristics, while a shared decoder is updated globally via the\ncoordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This\ndesign ensures that only compact LoRA adapter parameters instead of full model\nupdates are transmitted for aggregation. To further enhance convergence\nstability, we introduce an alternating freezing strategy with calibrated\nlearning-rate ratio during LoRA aggregation. Extensive simulations on\n3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\%\nof the uplink communication cost compared to conventional methods while\nachieving a performance gain of 1.2 dB in CSI feedback accuracy under\nheterogeneous conditions."}
{"id": "2510.25007", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25007", "abs": "https://arxiv.org/abs/2510.25007", "authors": ["Islam Nassar", "Yang Lin", "Yuan Jin", "Rongxin Zhu", "Chang Wei Tan", "Zenan Zhai", "Nitika Mathur", "Thanh Tien Vu", "Xu Zhong", "Long Duong", "Yuan-Fang Li"], "title": "Taming the Real-world Complexities in CPT E/M Coding with Large Language Models", "comment": "EMNLP 2025 Industry Track", "summary": "Evaluation and Management (E/M) coding, under the Current Procedural\nTerminology (CPT) taxonomy, documents medical services provided to patients by\nphysicians. Used primarily for billing purposes, it is in physicians' best\ninterest to provide accurate CPT E/M codes. %While important, it is an\nauxiliary task that adds to physicians' documentation burden. Automating this\ncoding task will help alleviate physicians' documentation burden, improve\nbilling efficiency, and ultimately enable better patient care. However, a\nnumber of real-world complexities have made E/M encoding automation a\nchallenging task. In this paper, we elaborate some of the key complexities and\npresent ProFees, our LLM-based framework that tackles them, followed by a\nsystematic evaluation. On an expert-curated real-world dataset, ProFees\nachieves an increase in coding accuracy of more than 36\\% over a commercial CPT\nE/M coding system and almost 5\\% over our strongest single-prompt baseline,\ndemonstrating its effectiveness in addressing the real-world complexities."}
{"id": "2510.25357", "categories": ["cs.NI", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.25357", "abs": "https://arxiv.org/abs/2510.25357", "authors": ["Roberto Viola", "Mikel Irazola", "José Ramón Juárez", "Minh Nguyen", "Alexander Zoubarev", "Alexander Futasz", "Louay Bassbouss", "Amr A. AbdelNabi", "Javier Fernández Hidalgo"], "title": "Energy consumption assessment of a Virtual Reality Remote Rendering application over 5G networks", "comment": null, "summary": "This paper investigates the energy implications of remote rendering for\nVirtual Reality (VR) applications within a real 5G testbed. Remote rendering\nenables lightweight devices to access high-performance graphical content by\noffloading computationally intensive tasks to Cloud-native Network Functions\n(CNFs) running on remote servers. However, this approach raises concerns\nregarding energy consumption across the various network components involved,\nincluding the remote computing node, the 5G Core, the Radio Access Network\n(RAN), and the User Equipment (UE). This work proposes and evaluates two\ncomplementary energy monitoring solutions, one hardware-based and one\nsoftware-based, to measure energy consumption at different system levels. A VR\nremote renderer, deployed as CNF and leveraging the Media over QUIC (MoQ)\nprotocol, is used as test case for assessing its energy footprint under\ndifferent multimedia and network configurations. The results provide critical\ninsights into the trade-off between energy consumption and performance of a\nreal-world VR application running in a 5G environment."}
{"id": "2510.25266", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25266", "abs": "https://arxiv.org/abs/2510.25266", "authors": ["Ziwei Liu", "Wen Chen", "Zhendong Li", "Qiong Wu"], "title": "Joint Spatial Registration and Resource Allocation for Transmissive RIS Enabled Cooperative ISCC Networks", "comment": null, "summary": "In this paper, we propose a novel transmissive reconfigurable intelligent\nsurface (TRIS) transceiver-driven cooperative integrated sensing, computing,\nand communication (ISCC) network to meet the requirement for a diverse network\nwith low energy consumption. The cooperative base stations (BSs) are equipped\nwith TRIS transceivers to accomplish sensing data acquisition, communication\noffloading, and computation in a time slot. In order to obtain higher\ncooperation gain, we utilize a signal-level spatial registration algorithm,\nwhich is realized by adjusting the beamwidth. Meanwhile, for more efficient\noffloading of the computational task, multistream communication is considered,\nand rank-$N$ constraints are introduced, which are handled using an iterative\nrank minimization (IRM) scheme. We construct an optimization problem with the\nobjective function of minimizing the total energy consumption of the network to\njointly optimize the beamforming matrix, time slot allocation, sensing data\nallocation and sensing beam scheduling variables. Due to the coupling of the\nvariables, the proposed problem is a non-convex optimization problem, which we\ndecouple and solve using a block coordinate descent (BCD) scheme. Finally,\nnumerical simulation results confirm the superiority of the proposed scheme in\nimproving the overall network performance and reducing the total energy\nconsumption of the network."}
{"id": "2510.25014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25014", "abs": "https://arxiv.org/abs/2510.25014", "authors": ["Minkyung Kim", "Junsik Kim", "Woongcheol Yang", "Sangdon Park", "Sohee Bae"], "title": "Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading", "comment": "8 pages main content, 18 pages supplementary material, 4 figures", "summary": "Large Language Models (LLMs) enable dynamic game interactions but fail to\nfollow essential procedural flows in rule-governed trading systems, eroding\nplayer trust. This work resolves the core tension between the creative\nflexibility of LLMs and the procedural demands of in-game trading\n(browse-offer-review-confirm). To this end, Autoregressive State-Tracking\nPrompting (ASTP) is introduced, a methodology centered on a strategically\norchestrated prompt that compels an LLM to make its state-tracking process\nexplicit and verifiable. Instead of relying on implicit contextual\nunderstanding, ASTP tasks the LLM with identifying and reporting a predefined\nstate label from the previous turn. To ensure transactional integrity, this is\ncomplemented by a state-specific placeholder post-processing method for\naccurate price calculations. Evaluation across 300 trading dialogues\ndemonstrates >99% state compliance and 99.3% calculation precision. Notably,\nASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)\nmatches larger models' (Gemini-2.5-Pro) performance while reducing response\ntime from 21.2s to 2.4s, establishing a practical foundation that satisfies\nboth real-time requirements and resource constraints of commercial games."}
{"id": "2510.25498", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25498", "abs": "https://arxiv.org/abs/2510.25498", "authors": ["Mihai Mazilu", "Aiden Valentine", "George Parisis"], "title": "Evaluating Learning Congestion control Schemes for LEO Constellations", "comment": "10 pages, 9 figures", "summary": "Low Earth Orbit (LEO) satellite networks introduce unique congestion control\n(CC) challenges due to frequent handovers, rapidly changing round-trip times\n(RTTs), and non-congestive loss. This paper presents the first comprehensive,\nemulation-driven evaluation of CC schemes in LEO networks, combining realistic\norbital dynamics via the LeoEM framework with targeted Mininet\nmicro-benchmarks. We evaluated representative CC algorithms from three classes,\nloss-based (Cubic, SaTCP), model-based (BBRv3), and learning-based (Vivace,\nSage, Astraea), across diverse single-flow and multi-flow scenarios, including\ninteractions with active queue management (AQM). Our findings reveal that: (1)\nhandover-aware loss-based schemes can reclaim bandwidth but at the cost of\nincreased latency; (2) BBRv3 sustains high throughput with modest delay\npenalties, yet reacts slowly to abrupt RTT changes; (3) RL-based schemes\nseverely underperform under dynamic conditions, despite being notably resistant\nto non-congestive loss; (4) fairness degrades significantly with RTT asymmetry\nand multiple bottlenecks, especially in human-designed CC schemes; and (5) AQM\nat bottlenecks can restore fairness and boost efficiency. These results expose\ncritical limitations in current CC schemes and provide insight for designing\nLEO-specific data transport protocols."}
{"id": "2510.25305", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25305", "abs": "https://arxiv.org/abs/2510.25305", "authors": ["Yitzchak Grunbaum", "Eitan Yaakobi"], "title": "General Coverage Models: Structure, Monotonicity, and Shotgun Sequencing", "comment": "13 pages", "summary": "We study coverage processes in which each draw reveals a subset of $[n]$, and\nthe goal is to determine the expected number of draws until all items are seen\nat least once. A classical example is the Coupon Collector's Problem, where\neach draw reveals exactly one item. Motivated by shotgun DNA sequencing, we\nintroduce a model where each draw is a contiguous window of fixed length, in\nboth cyclic and non-cyclic variants. We develop a unifying combinatorial tool\nthat shifts the task of finding coverage time from probability, to a counting\nproblem over families of subsets of $[n]$ that together contain all items,\nenabling exact calculation. Using this result, we obtain exact expressions for\nthe window models. We then leverage past results on a continuous analogue of\nthe cyclic window model to analyze the asymptotic behavior of both models. We\nfurther study what we call uniform $\\ell$-regular models, where every draw has\nsize $\\ell$ and every item appears in the same number of admissible draws. We\ncompare these to the batch sampling model, in which all $\\ell$-subsets are\ndrawn uniformly at random and present upper and lower bounds, which were also\nobtained independently by Berend and Sher. We conjecture, and prove for special\ncases, that this model maximizes the coverage time among all uniform\n$\\ell$-regular models. Finally, we prove a universal upper bound on the entire\nclass of uniform $\\ell$-regular models, which illuminates the fact that many\nsampling models share the same leading asymptotic order, while potentially\ndiffering significantly in lower-order terms."}
{"id": "2510.25065", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25065", "abs": "https://arxiv.org/abs/2510.25065", "authors": ["Taekhyun Park", "Yongjae Lee", "Hyerim Bae"], "title": "Reasoning-Aware GRPO using Process Mining", "comment": null, "summary": "Reinforcement learning (RL)-based post-training has been crucial for enabling\nmulti-step reasoning in large reasoning models (LRMs), yet current reward\nschemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware\nGroup Relative Policy Optimization (GRPO) that augments standard answer/format\nrewards with signals over the reasoning procedure. To this end, process mining\ntechniques are utilized to compute a scalar conformance reward that measures\nhow closely a policy model's reasoning aligns with the pretrained teacher\nmodel. The empirical results on five benchmarks demonstrate that PM4GRPO\nsignificantly outperforms existing methodologies for GRPO-based post-training.\nThese results highlight that leveraging process mining for reasoning-aware GRPO\neffectively enhances the reasoning capabilities of policy models."}
{"id": "2510.25552", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25552", "abs": "https://arxiv.org/abs/2510.25552", "authors": ["K Prajwal", "Tharun K", "Navaneeth P", "Ishwar Mandal", "Kiran M"], "title": "Device to Device Pairs Sharding based on Distance", "comment": null, "summary": "In the conventional cellular system, devices are not allowed to communicate\ndirectly with each other in the licensed cellular bandwidth and all\ncommunications take place through the base stations. The users requirements has\nled the technology to become fast and faster. Multimedia rich data exchange,\nfast service, high quality voice calls, newer and more demanding applications,\ninformation at fingertips, everything requires technology and communication\nbetween devices. A constant need to increase network capacity for meeting the\nusers growing demands has led to the growth of cellular communication networks\nfrom the first generation(1G) to the fifth generation(5G). There will be crores\nof connected devices in the coming future . A large number of connections are\ngoing to be heterogeneous, demanding lesser delays, higher data rates, superior\nthroughput and enhanced system capacity. The available spectrum resources are\nlimited and has to be flexibly used by mobile network operators to cope with\nthe rising demands. An emerging facilitator of the upcoming high data rate\ndemanding next-generation networks are device-to-device(D2D) communication.\nThis paper has developed a model that establishes Device-to-Device (D2D)\ncommunication between two end-users without involving the eNB (evolved Node B).\nWe have sharded the UEs and CUs based on the criteria of DISTANCE. To do so, we\nused the K-means clustering method."}
{"id": "2510.25343", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25343", "abs": "https://arxiv.org/abs/2510.25343", "authors": ["Hadi Aghaee", "Christian Deppe", "Holger Boche"], "title": "Network Oblivious Transfer via Noisy Broadcast Channels", "comment": null, "summary": "This paper investigates information-theoretic oblivious transfer via a\ndiscrete memoryless broadcast channel with one sender and two receivers. We\nanalyze both non-colluding and colluding honest-but-curious user models and\nestablish general upper bounds on the achievable oblivious transfer capacity\nregion for each case. Two explicit oblivious transfer protocols are proposed.\nThe first ensures correctness and privacy for independent, non-colluding\nreceivers by leveraging the structure of binary erasure broadcast channels. The\nsecond protocol, secure even under receiver collusion, introduces additional\nentropy-sharing and privacy amplification mechanisms to preserve secrecy\ndespite information leakage between users. Our results show that for the\nnon-colluding case, the upper and lower bounds on oblivious transfer capacity\ncoincide, providing a complete characterization of the achievable region. The\nwork provides a unified theoretical framework bridging network information\ntheory and cryptographic security, highlighting the potential of noisy\nbroadcast channels as powerful primitives for multi-user privacy-preserving\ncommunication."}
{"id": "2510.25091", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25091", "abs": "https://arxiv.org/abs/2510.25091", "authors": ["Peilin Tan", "Liang Xie", "Churan Zhi", "Dian Tu", "Chuanqi Shi"], "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts", "comment": null, "summary": "Stock movement prediction remains fundamentally challenging due to complex\ntemporal dependencies, heterogeneous modalities, and dynamically evolving\ninter-stock relationships. Existing approaches often fail to unify structural,\nsemantic, and regime-adaptive modeling within a scalable framework. This work\nintroduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with\nLLM reasoning and Style-Structured Mixture of Experts, integrating three key\ninnovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically\ncaptures fine-grained spatiotemporal dynamics via a Local Context Hypergraph\n(LCH) and persistent inter-stock dependencies through a Global Context\nHypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon\nDivergence weighting mechanism for adaptive relational learning and cross-modal\nalignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large\nlanguage model with lightweight adapters to semantically fuse and align\nquantitative and textual modalities, enriching representations with\ndomain-specific financial knowledge; and (3) a Style-Structured Mixture of\nExperts (SSMoEs) that combines shared market experts and industry-specialized\nexperts, each parameterized by learnable style vectors enabling regime-aware\nspecialization under sparse activation. Extensive experiments on three major\nstock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in\nboth superior predictive accuracy and investment performance, while exhibiting\neffective risk control. Datasets, source code, and model weights are available\nat our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs."}
{"id": "2510.25562", "categories": ["cs.NI", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25562", "abs": "https://arxiv.org/abs/2510.25562", "authors": ["Kaiqiang Lin", "Kangchun Zhao", "Yijie Mao"], "title": "Deep Reinforcement Learning-Based Cooperative Rate Splitting for Satellite-to-Underground Communication Networks", "comment": "6 pages, 3 figures, 1 table, and submitted to IEEE TVT", "summary": "Reliable downlink communication in satellite-to-underground networks remains\nchallenging due to severe signal attenuation caused by underground soil and\nrefraction in the air-soil interface. To address this, we propose a novel\ncooperative rate-splitting (CRS)-aided transmission framework, where an\naboveground relay decodes and forwards the common stream to underground devices\n(UDs). Based on this framework, we formulate a max-min fairness optimization\nproblem that jointly optimizes power allocation, message splitting, and time\nslot scheduling to maximize the minimum achievable rate across UDs. To solve\nthis high-dimensional non-convex problem under uncertain channels, we develop a\ndeep reinforcement learning solution framework based on the proximal policy\noptimization (PPO) algorithm that integrates distribution-aware action modeling\nand a multi-branch actor network. Simulation results under a realistic\nunderground pipeline monitoring scenario demonstrate that the proposed approach\nachieves average max-min rate gains exceeding $167\\%$ over conventional\nbenchmark strategies across various numbers of UDs and underground conditions."}
{"id": "2510.25346", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25346", "abs": "https://arxiv.org/abs/2510.25346", "authors": ["Chi Qiu", "Wen Chen", "Qingqing Wu", "Fen Hou", "Wanming Hao", "Ruiqi Liu", "Derrick Wing Kwan Ng"], "title": "Joint Beamforming Design and Resource Allocation for IRS-Assisted Full-Duplex Terahertz Systems", "comment": null, "summary": "Intelligent reflecting surface (IRS)-assisted full-duplex (FD) terahertz\n(THz) communication systems have emerged as a promising paradigm to satisfy the\nescalating demand for ultra-high data rates and spectral efficiency in future\nwireless networks. However, the practical deployment of such systems presents\nunique technical challenges, stemming from severe propagation loss,\nfrequency-dependent molecular absorption in the THz band, and the presence of\nstrong residual self-interference (SI) inherent to FD communications. To tackle\nthese issues, this paper proposes a joint resource allocation framework that\naims to maximize the weighted minimum rate among all users, thereby ensuring\nfairness in quality of service. Specifically, the proposed design jointly\noptimizes IRS reflecting phase shifts, uplink/downlink transmit power control,\nsub-band bandwidth allocation, and sub-band assignment, explicitly capturing\nthe unique propagation characteristics of THz channels and the impact of\nresidual SI. To strike an balance between system performance and computational\ncomplexity, two computationally efficient algorithms are developed under\ndistinct spectrum partitioning schemes: one assumes equal sub-band bandwidth\nallocation to facilliate tractable optimization, while the other introduces\nadaptive bandwidth allocation to further enhance spectral utilization and\nsystem flexibility. Simulation results validate the effectiveness of the\nproposed designs and demonstrate that the adopted scheme achieves significant\nspectral efficiency improvements over benchmark schemes."}
{"id": "2510.25101", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25101", "abs": "https://arxiv.org/abs/2510.25101", "authors": ["Zhuo Chen", "Fei Wang", "Zixuan Li", "Zhao Zhang", "Weiwei Ding", "Chuanguang Yang", "Yongjun Xu", "Xiaolong Jin", "Jiafeng Guo"], "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA", "comment": null, "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural-language\nquestions over a structured Knowledge Base (KB). Recent work improves KBQA by\nadopting an agentic reasoning paradigm, in which Large Language Models (LLMs)\niteratively decompose a question, generate its corresponding logical queries,\nand interact with the KB to derive the answer. However, these methods typically\nfine-tune LLMs on reasoning trajectories synthesized via process supervision,\nwhich offers weak incentives for exploration and thus fails to strengthen the\nagentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that\ncan autonomously perform agentic reasoning on KBs to obtain answers. To\nincentivize autonomous exploration, KnowCoder-A1 trains the LLM under\noutcome-only supervision via a multi-stage curriculum reinforcement learning\nwith an easy-to-hard curriculum. To establish foundational agentic\ncapabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of\nhigh-quality trajectories obtained through outcome-based rejection sampling.\nThen, to alleviate the reward sparsity inherent in outcome-only supervision, it\napplies multi-stage curriculum RL with reward schedules that progress from easy\nto hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful\nreasoning behaviors and consistently outperforms prior approaches across three\nmainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1\nachieves up to an 11.1% relative improvement while using only one-twelfth of\nthe training data, demonstrating strong agentic reasoning capabilities."}
{"id": "2510.25705", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.25705", "abs": "https://arxiv.org/abs/2510.25705", "authors": ["Elif Ebru Ohri", "Qi Liao", "Anastasios Giovanidis", "Francesca Fossati", "Nour-El-Houda Yellas"], "title": "MetaLore: Learning to Orchestrate Communication and Computation for Metaverse Synchronization", "comment": "This work has been accepted at IEEE GLOBECOM 2025. The final version\n  of record will appear in IEEE Xplore", "summary": "As augmented and virtual reality evolve, achieving seamless synchronization\nbetween physical and digital realms remains a critical challenge, especially\nfor real-time applications where delays affect the user experience. This paper\npresents MetaLore, a Deep Reinforcement Learning (DRL) based framework for\njoint communication and computational resource allocation in Metaverse or\ndigital twin environments. MetaLore dynamically shares the communication\nbandwidth and computational resources among sensors and mobile devices to\noptimize synchronization, while offering high throughput performance. Special\ntreatment is given in satisfying end-to-end delay guarantees. A key\ncontribution is the introduction of two novel Age of Information (AoI) metrics:\nAge of Request Information (AoRI) and Age of Sensor Information (AoSI),\nintegrated into the reward function to enhance synchronization quality. An open\nsource simulator has been extended to incorporate and evaluate the approach.\nThe DRL solution is shown to achieve the performance of full-enumeration\nbrute-force solutions by making use of a small, task-oriented observation space\nof two queue lengths at the network side. This allows the DRL approach the\nflexibility to effectively and autonomously adapt to dynamic traffic\nconditions."}
{"id": "2510.25389", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25389", "abs": "https://arxiv.org/abs/2510.25389", "authors": ["Meng Hua", "Haotian Wu", "Deniz Gündüz"], "title": "AirCNN via Reconfigurable Intelligent Surfaces: Architecture Design and Implementation", "comment": "Using wireless hardware to implement neural networks; This work is\n  submitted to IEEE journal for possible publication", "summary": "This paper introduces AirCNN, a novel paradigm for implementing convolutional\nneural networks (CNNs) via over-the-air (OTA) analog computation. By leveraging\nmultiple reconfigurable intelligent surfaces (RISs) and transceiver designs, we\nengineer the ambient wireless propagation environment to emulate the operations\nof a CNN layer. To comprehensively evaluate AirCNN, we consider two types of\nCNNs, namely classic two-dimensional (2D) convolution (Conv2d) and light-weight\nconvolution, i.e., depthwise separable convolution (ConvSD). For Conv2d\nrealization via OTA computation, we propose and analyze two RIS-aided\ntransmission architectures: multiple-input multiple-output (MIMO) and\nmultiple-input single-output (MISO), balancing transmission overhead and\nemulation performance. We jointly optimize all parameters, including the\ntransmitter precoder, receiver combiner, and RIS phase shifts, under practical\nconstraints such as transmit power budget and unit-modulus phase shift\nrequirements. We further extend the framework to ConvSD, which requires\ndistinct transmission strategies for depthwise and pointwise convolutions.\nSimulation results demonstrate that the proposed AirCNN architectures can\nachieve satisfactory classification performance. Notably, Conv2d MISO\nconsistently outperforms Conv2d MIMO across various settings, while for ConvSD,\nMISO is superior only under poor channel conditions. Moreover, employing\nmultiple RISs significantly enhances performance compared to a single RIS,\nespecially in line-of-sight (LoS)-dominated wireless environments."}
{"id": "2510.25179", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25179", "abs": "https://arxiv.org/abs/2510.25179", "authors": ["Juan Ren", "Mark Dras", "Usman Naseem"], "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models", "comment": null, "summary": "Agentic methods have emerged as a powerful and autonomous paradigm that\nenhances reasoning, collaboration, and adaptive control, enabling systems to\ncoordinate and independently solve complex tasks. We extend this paradigm to\nsafety alignment by introducing Agentic Moderation, a model-agnostic framework\nthat leverages specialised agents to defend multimodal systems against\njailbreak attacks. Unlike prior approaches that apply as a static layer over\ninputs or outputs and provide only binary classifications (safe or unsafe), our\nmethod integrates dynamic, cooperative agents, including Shield, Responder,\nEvaluator, and Reflector, to achieve context-aware and interpretable\nmoderation. Extensive experiments across five datasets and four representative\nLarge Vision-Language Models (LVLMs) demonstrate that our approach reduces the\nAttack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),\nand improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,\nand well-balanced safety performance. By harnessing the flexibility and\nreasoning capacity of agentic architectures, Agentic Moderation provides\nmodular, scalable, and fine-grained safety enforcement, highlighting the\nbroader potential of agentic systems as a foundation for automated safety\ngovernance."}
{"id": "2510.25578", "categories": ["cs.IT", "math.IT", "94B05, 11T71, 11T23"], "pdf": "https://arxiv.org/pdf/2510.25578", "abs": "https://arxiv.org/abs/2510.25578", "authors": ["Mrinal Kanti Bose", "Abhay Kumar Singh"], "title": "Several classes of $p$-ary linear codes with few-weights derived from Weil sums", "comment": null, "summary": "Linear codes with few weights have been a significant area of research in\ncoding theory for many years, due to their applications in secret sharing\nschemes, authentication codes, association schemes, and strongly regular\ngraphs. Inspired by the works of Cheng and Gao \\cite{P8} and Wu, Li and Zeng\n\\cite{P12}, in this paper, we propose several new classes of few-weight linear\ncodes over the finite field $\\mathbb{F}_{p}$ through the selection of two\nspecific defining sets. Consequently, we obtain five classes of $4$-weight\nlinear codes and one class of $2$-weight linear codes from our first defining\nset. Furthermore, by employing weakly regular bent functions in our second\ndefining set, we derive two classes of $6$-weight codes, two classes of\n$8$-weight codes, and one class of $9$-weight codes. The parameters and weight\ndistributions of all these constructed codes are wholly determined by detailed\ncalculations on certain Weil sums over finite fields. In addition, we identify\nan optimal class of $2$-weight codes that meet the Griesmer bound."}
{"id": "2510.25205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25205", "abs": "https://arxiv.org/abs/2510.25205", "authors": ["Yuyang Xia", "Zibo Liang", "Liwei Deng", "Yan Zhao", "Han Su", "Kai Zheng"], "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision", "comment": "It was accepted by ICDE2026", "summary": "Autonomous driving is an emerging technology that is expected to bring\nsignificant social, economic, and environmental benefits. However, these\nbenefits come with rising energy consumption by computation engines, limiting\nthe driving range of vehicles, especially electric ones. Perception computing\nis typically the most power-intensive component, as it relies on largescale\ndeep learning models to extract environmental features. Recently, numerous\nstudies have employed model compression techniques, such as sparsification,\nquantization, and distillation, to reduce computational consumption. However,\nthese methods often result in either a substantial model size or a significant\ndrop in perception accuracy compared to high-computation models. To address\nthese challenges, we propose an energy-efficient autonomous driving framework,\ncalled EneAD. In the adaptive perception module, a perception optimization\nstrategy is designed from the perspective of data management and tuning.\nFirstly, we manage multiple perception models with different computational\nconsumption and adjust the execution framerate dynamically. Then, we define\nthem as knobs and design a transferable tuning method based on Bayesian\noptimization to identify promising knob values that achieve low computation\nwhile maintaining desired accuracy. To adaptively switch the knob values in\nvarious traffic scenarios, a lightweight classification model is proposed to\ndistinguish the perception difficulty in different scenarios. In the robust\ndecision module, we propose a decision model based on reinforcement learning\nand design a regularization term to enhance driving stability in the face of\nperturbed perception results. Extensive experiments evidence the superiority of\nour framework in both energy consumption and driving performance. EneAD can\nreduce perception consumption by 1.9x to 3.5x and thus improve driving range by\n3.9% to 8.5%"}
{"id": "2510.25592", "categories": ["cs.IT", "math.CO", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25592", "abs": "https://arxiv.org/abs/2510.25592", "authors": ["Hagai Berend", "Ohad Elishco", "Moshe Schwartz"], "title": "On Multidimensional 2-Weight-Limited Burst-Correcting Codes", "comment": null, "summary": "We consider multidimensional codes capable of correcting a burst error of\nweight at most $2$. When two positions are in error, the burst limits their\nrelative position. We study three such limitations: the $L_\\infty$ distance\nbetween the positions is bounded, the $L_1$ distance between the positions is\nbounded, or the two positions are on an axis-parallel line with bounded\ndistance between them. In all cases we provide explicit code constructions, and\ncompare their excess redundancy to a lower bound we prove."}
{"id": "2510.25206", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.25206", "abs": "https://arxiv.org/abs/2510.25206", "authors": ["Tianqianjin Lin", "Xi Zhao", "Xingyao Zhang", "Rujiao Long", "Yi Xu", "Zhuoren Jiang", "Wenbo Su", "Bo Zheng"], "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models", "comment": "17 pages, 11 figures", "summary": "Reinforcement learning (RL) can refine the reasoning abilities of large\nlanguage models (LLMs), but critically depends on a key prerequisite: the LLM\ncan already generate high-utility reasoning paths with non-negligible\nprobability. For tasks beyond the LLM's current competence, such reasoning path\ncan be hard to sample, and learning risks reinforcing familiar but suboptimal\nreasoning. We are motivated by the insight from cognitive science that Why is\nthis the answer is often an easier question than What is the answer, as it\navoids the heavy cognitive load of open-ended exploration, opting instead for\nexplanatory reconstruction-systematically retracing the reasoning that links a\nquestion to its answer. We show that LLMs can similarly leverage answers to\nderive high-quality reasoning paths. We formalize this phenomenon and prove\nthat conditioning on answer provably increases the expected utility of sampled\nreasoning paths, thereby transforming intractable problems into learnable ones.\nBuilding on this insight, we introduce RAVR (Reference-Answer-guided\nVariational Reasoning), an end-to-end framework that uses answer-conditioned\nreasoning as a variational surrogate for question-only reasoning. Experiments\nin both general and math domains demonstrate consistent improvements over\nstrong baselines. We further analyze the reasoning behavior and find that RAVR\nreduces hesitation, strengthens conclusion consolidation, and promotes\nproblem-specific strategies in reasoning."}
{"id": "2510.25736", "categories": ["cs.IT", "cs.CR", "cs.DC", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25736", "abs": "https://arxiv.org/abs/2510.25736", "authors": ["Shreya Meel", "Sennur Ulukus"], "title": "Effect of Full Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems", "comment": null, "summary": "We revisit the problem of symmetric private information retrieval (SPIR) in\nsettings where the database replication is modeled by a simple graph. Here,\neach vertex corresponds to a server, and a message is replicated on two servers\nif and only if there is an edge between them. To satisfy the requirement of\ndatabase privacy, we let all the servers share some common randomness,\nindependent of the messages. We aim to quantify the improvement in SPIR\ncapacity, i.e., the maximum ratio of the number of desired and downloaded\nsymbols, compared to the setting with graph-replicated common randomness.\nTowards this, we develop an algorithm to convert a class of PIR schemes into\nthe corresponding SPIR schemes, thereby establishing a capacity lower bound on\ngraphs for which such schemes exist. This includes the class of path and cyclic\ngraphs for which we derive capacity upper bounds that are tighter than the\ntrivial bounds given by the respective PIR capacities. For the special case of\npath graph with three vertices, we identify the SPIR capacity to be\n$\\frac{1}{2}$."}
{"id": "2510.25223", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25223", "abs": "https://arxiv.org/abs/2510.25223", "authors": ["Kun ouyang", "Haoyu Wang", "Dong Fang"], "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data", "comment": "14 pages, 11 figures", "summary": "Event log data, recording fine-grained user actions and system events,\nrepresent one of the most valuable assets for modern digital services. However,\nthe complexity and heterogeneity of industrial event logs--characterized by\nlarge scale, high dimensionality, diverse data types, and intricate temporal or\nrelational structures--make feature engineering extremely challenging. Existing\nautomatic feature engineering approaches, such as AutoML or genetic methods,\noften suffer from limited explainability, rigid predefined operations, and poor\nadaptability to complicated heterogeneous data. In this paper, we propose FELA\n(Feature Engineering LLM Agents), a multi-agent evolutionary system that\nautonomously extracts meaningful and high-performing features from complex\nindustrial event log data. FELA integrates the reasoning and coding\ncapabilities of large language models (LLMs) with an insight-guided\nself-evolution paradigm. Specifically, FELA employs specialized agents--Idea\nAgents, Code Agents, and Critic Agents--to collaboratively generate, validate,\nand implement novel feature ideas. An Evaluation Agent summarizes feedback and\nupdates a hierarchical knowledge base and dual-memory system to enable\ncontinual improvement. Moreover, FELA introduces an agentic evolution\nalgorithm, combining reinforcement learning and genetic algorithm principles to\nbalance exploration and exploitation across the idea space. Extensive\nexperiments on real industrial datasets demonstrate that FELA can generate\nexplainable, domain-relevant features that significantly improve model\nperformance while reducing manual effort. Our results highlight the potential\nof LLM-based multi-agent systems as a general framework for automated,\ninterpretable, and adaptive feature engineering in complex real-world\nenvironments."}
{"id": "2510.25740", "categories": ["cs.IT", "math.IT", "math.PR", "q-fin.MF", "q-fin.PM", "94A15, 94A17, 91G10, 91G80, 60F10, 62B10"], "pdf": "https://arxiv.org/pdf/2510.25740", "abs": "https://arxiv.org/abs/2510.25740", "authors": ["Steven Campbell", "Ting-Kam Leonard Wong"], "title": "A mathematical study of the excess growth rate", "comment": "54 pages, 2 figures", "summary": "We study the excess growth rate -- a fundamental logarithmic functional\narising in portfolio theory -- from the perspective of information theory. We\nshow that the excess growth rate can be connected to the R\\'{e}nyi and cross\nentropies, the Helmholtz free energy, L. Campbell's measure of average code\nlength and large deviations. Our main results consist of three axiomatic\ncharacterization theorems of the excess growth rate, in terms of (i) the\nrelative entropy, (ii) the gap in Jensen's inequality, and (iii) the\nlogarithmic divergence that generalizes the Bregman divergence. Furthermore, we\nstudy maximization of the excess growth rate and compare it with the growth\noptimal portfolio. Our results not only provide theoretical justifications of\nthe significance of the excess growth rate, but also establish new connections\nbetween information theory and quantitative finance."}
{"id": "2510.25232", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25232", "abs": "https://arxiv.org/abs/2510.25232", "authors": ["Tianxi Wan", "Jiaming Luo", "Siyuan Chen", "Kunyao Lan", "Jianhua Chen", "Haiyang Geng", "Mengyue Wu"], "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity", "comment": null, "summary": "Psychiatric comorbidity is clinically significant yet challenging due to the\ncomplexity of multiple co-occurring disorders. To address this, we develop a\nnovel approach integrating synthetic patient electronic medical record (EMR)\nconstruction and multi-agent diagnostic dialogue generation. We create 502\nsynthetic EMRs for common comorbid conditions using a pipeline that ensures\nclinical relevance and diversity. Our multi-agent framework transfers the\nclinical interview protocol into a hierarchical state machine and context tree,\nsupporting over 130 diagnostic states while maintaining clinical standards.\nThrough this rigorous process, we construct PsyCoTalk, the first large-scale\ndialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic\ndialogues validated by psychiatrists. This dataset enhances diagnostic accuracy\nand treatment planning, offering a valuable resource for psychiatric\ncomorbidity research. Compared to real-world clinical transcripts, PsyCoTalk\nexhibits high structural and linguistic fidelity in terms of dialogue length,\ntoken distribution, and diagnostic reasoning strategies. Licensed psychiatrists\nconfirm the realism and diagnostic validity of the dialogues. This dataset\nenables the development and evaluation of models capable of multi-disorder\npsychiatric screening in a single conversational pass."}
{"id": "2510.25320", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25320", "abs": "https://arxiv.org/abs/2510.25320", "authors": ["Jiaqi Wu", "Qinlao Zhao", "Zefeng Chen", "Kai Qin", "Yifei Zhao", "Xueqian Wang", "Yuhang Yao"], "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning", "comment": null, "summary": "Autonomous agents powered by large language models (LLMs) have shown\nimpressive capabilities in tool manipulation for complex task-solving. However,\nexisting paradigms such as ReAct rely on sequential reasoning and execution,\nfailing to exploit the inherent parallelism among independent sub-tasks. This\nsequential bottleneck leads to inefficient tool utilization and suboptimal\nperformance in multi-step reasoning scenarios. We introduce Graph-based Agent\nPlanning (GAP), a novel framework that explicitly models inter-task\ndependencies through graph-based planning to enable adaptive parallel and\nserial tool execution. Our approach trains agent foundation models to decompose\ncomplex tasks into dependency-aware sub-task graphs, autonomously determining\nwhich tools can be executed in parallel and which must follow sequential\ndependencies. This dependency-aware orchestration achieves substantial\nimprovements in both execution efficiency and task accuracy. To train GAP, we\nconstruct a high-quality dataset of graph-based planning traces derived from\nthe Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage\ntraining strategy: supervised fine-tuning (SFT) on the curated dataset,\nfollowed by reinforcement learning (RL) with a correctness-based reward\nfunction on strategically sampled queries where tool-based reasoning provides\nmaximum value. Experimental results on MHQA datasets demonstrate that GAP\nsignificantly outperforms traditional ReAct baselines, particularly on\nmulti-step retrieval tasks, while achieving dramatic improvements in tool\ninvocation efficiency through intelligent parallelization. The project page is\navailable at: https://github.com/WJQ7777/Graph-Agent-Planning."}
{"id": "2510.25388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25388", "abs": "https://arxiv.org/abs/2510.25388", "authors": ["Robin Schmöcker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Grouping Nodes With Known Value Differences: A Lossless UCT-based Abstraction Algorithm", "comment": null, "summary": "A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,\nwhich can be improved by grouping state-action pairs and using their aggregate\nstatistics instead of single-node statistics. On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS\nabstraction algorithm for deterministic environments that builds its\nabstraction using the Abstractions of State-Action Pairs (ASAP) framework,\nwhich aims to detect states and state-action pairs with the same value under\noptimal play by analysing the search graph. ASAP, however, requires two\nstate-action pairs to have the same immediate reward, which is a rigid\ncondition that limits the number of abstractions that can be found and thereby\nthe sample efficiency. In this paper, we break with the paradigm of grouping\nvalue-equivalent states or state-action pairs and instead group states and\nstate-action pairs with possibly different values as long as the difference\nbetween their values can be inferred. We call this abstraction framework Known\nValue Difference Abstractions (KVDA), which infers the value differences by\nanalysis of the immediate rewards and modifies OGA-UCT to use this framework\ninstead. The modification is called KVDA-UCT, which detects significantly more\nabstractions than OGA-UCT, introduces no additional parameter, and outperforms\nOGA-UCT on a variety of deterministic environments and parameter settings."}
{"id": "2510.25445", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25445", "abs": "https://arxiv.org/abs/2510.25445", "authors": ["Mohamad Abou Ali", "Fadi Dornaika"], "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions", "comment": null, "summary": "Agentic AI represents a transformative shift in artificial intelligence, but\nits rapid advancement has led to a fragmented understanding, often conflating\nmodern neural systems with outdated symbolic models -- a practice known as\nconceptual retrofitting. This survey cuts through this confusion by introducing\na novel dual-paradigm framework that categorizes agentic systems into two\ndistinct lineages: the Symbolic/Classical (relying on algorithmic planning and\npersistent state) and the Neural/Generative (leveraging stochastic generation\nand prompt-driven orchestration). Through a systematic PRISMA-based review of\n90 studies (2018--2025), we provide a comprehensive analysis structured around\nthis framework across three dimensions: (1) the theoretical foundations and\narchitectural principles defining each paradigm; (2) domain-specific\nimplementations in healthcare, finance, and robotics, demonstrating how\napplication constraints dictate paradigm selection; and (3) paradigm-specific\nethical and governance challenges, revealing divergent risks and mitigation\nstrategies. Our analysis reveals that the choice of paradigm is strategic:\nsymbolic systems dominate safety-critical domains (e.g., healthcare), while\nneural systems prevail in adaptive, data-rich environments (e.g., finance).\nFurthermore, we identify critical research gaps, including a significant\ndeficit in governance models for symbolic systems and a pressing need for\nhybrid neuro-symbolic architectures. The findings culminate in a strategic\nroadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are both\nadaptable and reliable. This work provides the essential conceptual toolkit to\nguide future research, development, and policy toward robust and trustworthy\nhybrid intelligent systems."}
{"id": "2510.25471", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.25471", "abs": "https://arxiv.org/abs/2510.25471", "authors": ["Willem Fourie"], "title": "Instrumental goals in advanced AI systems: Features to be managed and not failures to be eliminated?", "comment": null, "summary": "In artificial intelligence (AI) alignment research, instrumental goals, also\ncalled instrumental subgoals or instrumental convergent goals, are widely\nassociated with advanced AI systems. These goals, which include tendencies such\nas power-seeking and self-preservation, become problematic when they conflict\nwith human aims. Conventional alignment theory treats instrumental goals as\nsources of risk that become problematic through failure modes such as reward\nhacking or goal misgeneralization, and attempts to limit the symptoms of\ninstrumental goals, notably resource acquisition and self-preservation. This\narticle proposes an alternative framing: that a philosophical argument can be\nconstructed according to which instrumental goals may be understood as features\nto be accepted and managed rather than failures to be limited. Drawing on\nAristotle's ontology and its modern interpretations, an ontology of concrete,\ngoal-directed entities, it argues that advanced AI systems can be seen as\nartifacts whose formal and material constitution gives rise to effects distinct\nfrom their designers' intentions. In this view, the instrumental tendencies of\nsuch systems correspond to per se outcomes of their constitution rather than\naccidental malfunctions. The implication is that efforts should focus less on\neliminating instrumental goals and more on understanding, managing, and\ndirecting them toward human-aligned ends."}
{"id": "2510.25504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25504", "abs": "https://arxiv.org/abs/2510.25504", "authors": ["Oren Salzman", "Carlos Hernández Ulloa", "Ariel Felner", "Sven Koenig"], "title": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions", "comment": null, "summary": "Multi-objective search (MOS) has emerged as a unifying framework for planning\nand decision-making problems where multiple, often conflicting, criteria must\nbe balanced. While the problem has been studied for decades, recent years have\nseen renewed interest in the topic across AI applications such as robotics,\ntransportation, and operations research, reflecting the reality that real-world\nsystems rarely optimize a single measure. This paper surveys developments in\nMOS while highlighting cross-disciplinary opportunities, and outlines open\nchallenges that define the emerging frontier of MOS"}
{"id": "2510.25510", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25510", "abs": "https://arxiv.org/abs/2510.25510", "authors": ["Zekun Xu", "Siyu Xia", "Chuhuai Yue", "Jiajun Chai", "Mingxue Tian", "Xiaohan Wang", "Wei Lin", "Haoxuan Li", "Guojun Yin"], "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL", "comment": null, "summary": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks,\nReinforcement Learning (RL) has become a common method for improving\nperformance. Existing methods primarily rely on static execution feedback,\nwhich restricts real-time error correction. However, integrating multi-turn\ntool invocation along with dynamic feedback could significantly improve\nadaptability and robustness, ultimately enhancing model performance. To address\nthese issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated\nReasoning reinforcement learning framework for Text-to-SQL. Our approach\nintroduces an execution-aware multi-turn reasoning paradigm that seamlessly\nincorporates database execution feedback at each reasoning step, enabling\ncontext-sensitive query generation and progressive refinement throughout the\nreasoning process. The framework extends the GRPO algorithm to accommodate\ncomplex multi-turn interaction scenarios. Considering the training instability\ncharacteristics of MTIR and the potential for significant Deviation of model\ndistribution from the initial model, we enhance the GRPO algorithm by adding a\ntrajectory filtering mechanism and removing KL loss constraints. Experimental\nresults demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\%\naccuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,\nsignificantly outperforming existing approaches."}
{"id": "2510.25517", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25517", "abs": "https://arxiv.org/abs/2510.25517", "authors": ["Elisabetta Gentili", "Tony Ribeiro", "Fabrizio Riguzzi", "Katsumi Inoue"], "title": "Predicate Renaming via Large Language Models", "comment": null, "summary": "In this paper, we address the problem of giving names to predicates in logic\nrules using Large Language Models (LLMs). In the context of Inductive Logic\nProgramming, various rule generation methods produce rules containing unnamed\npredicates, with Predicate Invention being a key example. This hinders the\nreadability, interpretability, and reusability of the logic theory. Leveraging\nrecent advancements in LLMs development, we explore their ability to process\nnatural language and code to provide semantically meaningful suggestions for\ngiving a name to unnamed predicates. The evaluation of our approach on some\nhand-crafted logic rules indicates that LLMs hold potential for this task."}
{"id": "2510.25518", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25518", "abs": "https://arxiv.org/abs/2510.25518", "authors": ["Thomas Cook", "Richard Osuagwu", "Liman Tsatiashvili", "Vrynsia Vrynsia", "Koustav Ghosal", "Maraim Masoud", "Riccardo Mattivi"], "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation", "comment": "Keywords: RAG Agentic AI Fintech NLP KB Domain-Specific Ontology\n  Query Understanding", "summary": "Retrieval-Augmented Generation (RAG) systems often face limitations in\nspecialized domains such as fintech, where domain-specific ontologies, dense\nterminology, and acronyms complicate effective retrieval and synthesis. This\npaper introduces an agentic RAG architecture designed to address these\nchallenges through a modular pipeline of specialized agents. The proposed\nsystem supports intelligent query reformulation, iterative sub-query\ndecomposition guided by keyphrase extraction, contextual acronym resolution,\nand cross-encoder-based context re-ranking. We evaluate our approach against a\nstandard RAG baseline using a curated dataset of 85 question--answer--reference\ntriples derived from an enterprise fintech knowledge base. Experimental results\ndemonstrate that the agentic RAG system outperforms the baseline in retrieval\nprecision and relevance, albeit with increased latency. These findings suggest\nthat structured, multi-agent methodologies offer a promising direction for\nenhancing retrieval robustness in complex, domain-specific settings."}
{"id": "2510.25528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25528", "abs": "https://arxiv.org/abs/2510.25528", "authors": ["Yuyuan Zeng", "Yufei Huang", "Can Xu", "Qingfeng Sun", "Jianfeng Yan", "Guanghui Xu", "Tao Yang", "Fengzong Lian"], "title": "Zero Reinforcement Learning Towards General Domains", "comment": null, "summary": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach\nfor enhancing the reasoning capabilities of large language models (LLMs) by\ndirectly applying reinforcement learning with verifiable rewards on pretrained\nmodels, without the need for a supervised fine-tuning phase. However, current\nresearch on zero-RL primarily focuses on domains with easily verifiable reward\nsignals, such as mathematics, programming, and other reasoning tasks. The\nchallenge of eliciting reasoning abilities in more diverse scenarios, where\nverification is not straightforward, remains underexplored. To address this\ngap, we propose a novel zero-RL paradigm designed to improve a model's\nreasoning ability across both verifiable and non-verifiable domains. By\ncombining verifiable rewards with a generative reward model, we conduct\nmulti-task zero-RL training across both domains, facilitating the transfer of\nreasoning capabilities between them. Furthermore, to mitigate reward hacking in\nthe generative reward model, we design a smooth length penalty that encourages\nthe generation of more comprehensive thinking tokens in general domains.\nExperimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our\napproach achieves superior reasoning performance, not only on tasks requiring\nextensive reasoning but also on more general tasks."}
{"id": "2510.25529", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25529", "abs": "https://arxiv.org/abs/2510.25529", "authors": ["Likun Wang", "Xiangteng Zhang", "Yinuo Wang", "Guojian Zhan", "Wenxuan Wang", "Haoyu Gao", "Jingliang Duan", "Shengbo Eben Li"], "title": "Off-policy Reinforcement Learning with Model-based Exploration Augmentation", "comment": null, "summary": "Exploration is fundamental to reinforcement learning (RL), as it determines\nhow effectively an agent discovers and exploits the underlying structure of its\nenvironment to achieve optimal performance. Existing exploration methods\ngenerally fall into two categories: active exploration and passive exploration.\nThe former introduces stochasticity into the policy but struggles in\nhigh-dimensional environments, while the latter adaptively prioritizes\ntransitions in the replay buffer to enhance exploration, yet remains\nconstrained by limited sample diversity. To address the limitation in passive\nexploration, we propose Modelic Generative Exploration (MoGE), which augments\nexploration through the generation of under-explored critical states and\nsynthesis of dynamics-consistent experiences through transition models. MoGE is\ncomposed of two components: (1) a diffusion-based generator that synthesizes\ncritical states under the guidance of a utility function evaluating each\nstate's potential influence on policy exploration, and (2) a one-step\nimagination world model for constructing critical transitions based on the\ncritical states for agent learning. Our method adopts a modular formulation\nthat aligns with the principles of off-policy learning, allowing seamless\nintegration with existing algorithms to improve exploration without altering\ntheir core structures. Empirical results on OpenAI Gym and DeepMind Control\nSuite reveal that MoGE effectively bridges exploration and policy learning,\nleading to remarkable gains in both sample efficiency and performance across\ncomplex control tasks."}
{"id": "2510.25588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25588", "abs": "https://arxiv.org/abs/2510.25588", "authors": ["Eranga Bandara", "Ross Gore", "Atmaram Yarlagadda", "Anita H. Clayton", "Preston Samuel", "Christopher K. Rhea", "Sachin Shetty"], "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System", "comment": null, "summary": "The diagnosis of most mental disorders, including psychiatric evaluations,\nprimarily depends on dialogues between psychiatrists and patients. This\nsubjective process can lead to variability in diagnoses across clinicians and\npatients, resulting in inconsistencies and challenges in achieving reliable\noutcomes. To address these issues and standardize psychiatric diagnoses, we\npropose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss\nReasoning LLM-enabled Decision Support System for the clinical diagnosis of\nmental disorders. Our approach leverages fine-tuned LLMs trained on\nconversational datasets involving psychiatrist-patient interactions focused on\nmental health conditions (e.g., depression). The diagnostic predictions from\nindividual models are aggregated through a consensus-based decision-making\nprocess, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method\nfor deploying LLM agents that orchestrate communication between the LLM\nconsortium and the reasoning LLM, ensuring transparency, reliability, and\nresponsible AI across the entire diagnostic workflow. Experimental results\ndemonstrate the transformative potential of combining fine-tuned LLMs with a\nreasoning model to create a robust and highly accurate diagnostic system for\nmental health assessment. A prototype of the proposed platform, integrating\nthree fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in\ncollaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,\nUSA. To the best of our knowledge, this work represents the first application\nof a fine-tuned LLM consortium integrated with a reasoning LLM for clinical\nmental health diagnosis paving the way for next-generation AI-powered eHealth\nsystems aimed at standardizing psychiatric diagnoses."}
{"id": "2510.25612", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.25612", "abs": "https://arxiv.org/abs/2510.25612", "authors": ["Amit Giloni", "Chiara Picardi", "Roy Betser", "Shamik Bose", "Aishvariya Priya Rathina Sabapathy", "Roman Vainshtein"], "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows", "comment": "Accepted to EMNLP 2025, 27 pages, 6 figures", "summary": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,\nis an autonomous system that assembles several LLM-based agents to work\ncollaboratively towards a shared goal. The high autonomy, widespread adoption,\nand growing interest in such AAWs highlight the need for a deeper understanding\nof their operations, from both quality and security aspects. To this day, there\nare no existing methods to assess the influence of each agent on the AAW's\nfinal output. Adopting techniques from related fields is not feasible since\nexisting methods perform only static structural analysis, which is unsuitable\nfor inference time execution. We present Counterfactual-based Agent Influence\nRanker (CAIR) - the first method for assessing the influence level of each\nagent on the AAW's output and determining which agents are the most\ninfluential. By performing counterfactual analysis, CAIR provides a\ntask-agnostic analysis that can be used both offline and at inference time. We\nevaluate CAIR using an AAWs dataset of our creation, containing 30 different\nuse cases with 230 different functionalities. Our evaluation showed that CAIR\nproduces consistent rankings, outperforms baseline methods, and can easily\nenhance the effectiveness and relevancy of downstream tasks."}
{"id": "2510.25668", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.25668", "abs": "https://arxiv.org/abs/2510.25668", "authors": ["Tianyu Yang", "Terry Ruas", "Yijun Tian", "Jan Philip Wahle", "Daniel Kurzawe", "Bela Gipp"], "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents", "comment": null, "summary": "Vision-language models (VLMs) excel at interpreting text-rich images but\nstruggle with long, visually complex documents that demand analysis and\nintegration of information spread across multiple pages. Existing approaches\ntypically rely on fixed reasoning templates or rigid pipelines, which force\nVLMs into a passive role and hinder both efficiency and generalization. We\npresent Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement\nlearning framework that fine-tunes VLMs as interactive agents capable of\nactively navigating long, visually rich documents. ALDEN introduces a novel\nfetch action that directly accesses the page by index, complementing the\nclassic search action and better exploiting document structure. For dense\nprocess supervision and efficient training, we propose a rule-based cross-level\nreward that provides both turn- and token-level signals. To address the\nempirically observed training instability caused by numerous visual tokens from\nlong documents, we further propose a visual-semantic anchoring mechanism that\napplies a dual-path KL-divergence constraint to stabilize visual and textual\nrepresentations separately during training. Trained on a corpus constructed\nfrom three open-source datasets, ALDEN achieves state-of-the-art performance on\nfive long-document benchmarks. Overall, ALDEN marks a step beyond passive\ndocument reading toward agents that autonomously navigate and reason across\nlong, visually rich documents, offering a robust path to more accurate and\nefficient long-document understanding."}
{"id": "2510.25679", "categories": ["cs.AI", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.25679", "abs": "https://arxiv.org/abs/2510.25679", "authors": ["Federica Tonti", "Ricardo Vinuesa"], "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning", "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for\ndelivery and surveillance purposes. In this work, we develop an optimal\nnavigation strategy based on Deep Reinforcement Learning. The environment is\nrepresented by a three-dimensional high-fidelity simulation of an urban flow,\ncharacterized by turbulence and recirculation zones. The algorithm presented\nhere is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated\nTransformer eXtra Large (GTrXL) architecture, giving the agent richer\ninformation about the turbulent flow field in which it navigates. The results\nare compared with a PPO+GTrXL without the secondary prediction tasks, a PPO\ncombined with Long Short Term Memory (LSTM) cells and a traditional navigation\nalgorithm. The obtained results show a significant increase in the success rate\n(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the\nclassical Zermelo's navigation algorithm, paving the way to a completely\nreimagined UAV landscape in complex urban environments."}
{"id": "2510.25724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25724", "abs": "https://arxiv.org/abs/2510.25724", "authors": ["Vanya Arikutharam", "Arkadiy Ukolov"], "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph", "comment": null, "summary": "Retrieval-Augmented Generation allows LLMs to access external knowledge,\nreducing hallucinations and ageing-data issues. However, it treats retrieved\nchunks independently and struggles with multi-hop or relational reasoning,\nespecially across documents. Knowledge graphs enhance this by capturing the\nrelationships between entities using triplets, enabling structured, multi-chunk\nreasoning. However, these tend to miss information that fails to conform to the\ntriplet structure. We introduce BambooKG, a knowledge graph with\nfrequency-based weights on non-triplet edges which reflect link strength,\ndrawing on the Hebbian principle of \"fire together, wire together\". This\ndecreases information loss and results in improved performance on single- and\nmulti-hop reasoning, outperforming the existing solutions."}
{"id": "2510.25758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25758", "abs": "https://arxiv.org/abs/2510.25758", "authors": ["He Hu", "Yucheng Zhou", "Chiyuan Ma", "Qianning Wang", "Zheng Zhang", "Fei Ma", "Laizhong Cui", "Qi Tian"], "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling", "comment": null, "summary": "Large language models (LLMs) in psychological counseling have attracted\nincreasing attention. However, existing approaches often lack emotional\nunderstanding, adaptive strategies, and the use of therapeutic methods across\nmultiple sessions with long-term memory, leaving them far from real clinical\npractice. To address these critical gaps, we introduce TheraMind, a strategic\nand adaptive agent for longitudinal psychological counseling. The cornerstone\nof TheraMind is a novel dual-loop architecture that decouples the complex\ncounseling process into an Intra-Session Loop for tactical dialogue management\nand a Cross-Session Loop for strategic therapeutic planning. The Intra-Session\nLoop perceives the patient's emotional state to dynamically select response\nstrategies while leveraging cross-session memory to ensure continuity.\nCrucially, the Cross-Session Loop empowers the agent with long-term\nadaptability by evaluating the efficacy of the applied therapy after each\nsession and adjusting the method for subsequent interactions. We validate our\napproach in a high-fidelity simulation environment grounded in real clinical\ncases. Extensive evaluations show that TheraMind outperforms other methods,\nespecially on multi-session metrics like Coherence, Flexibility, and\nTherapeutic Attunement, validating the effectiveness of its dual-loop design in\nemulating strategic, adaptive, and longitudinal therapeutic behavior. The code\nis publicly available at https://0mwwm0.github.io/TheraMind/."}
{"id": "2510.24763", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24763", "abs": "https://arxiv.org/abs/2510.24763", "authors": ["Tingting Huang", "Jundong Chen", "Huanqiang Zeng", "Guofa Cai", "Georges Kaddoum"], "title": "Dual-Domain Deep Learning-Assisted NOMA-CSK Systems for Secure and Efficient Vehicular Communications", "comment": null, "summary": "Ensuring secure and efficient multi-user (MU) transmission is critical for\nvehicular communication systems. Chaos-based modulation schemes have garnered\nconsiderable interest due to their benefits in physical layer security.\nHowever, most existing MU chaotic communication systems, particularly those\nbased on non-coherent detection, suffer from low spectral efficiency due to\nreference signal transmission, and limited user connectivity under orthogonal\nmultiple access (OMA). While non-orthogonal schemes, such as sparse code\nmultiple access (SCMA)-based DCSK, have been explored, they face high\ncomputational complexity and inflexible scalability due to their fixed codebook\ndesigns. This paper proposes a deep learning-assisted power domain\nnon-orthogonal multiple access chaos shift keying (DL-NOMA-CSK) system for\nvehicular communications. A deep neural network (DNN)-based demodulator is\ndesigned to learn intrinsic chaotic signal characteristics during offline\ntraining, thereby eliminating the need for chaotic synchronization or reference\nsignal transmission. The demodulator employs a dual-domain feature extraction\narchitecture that jointly processes the time-domain and frequency-domain\ninformation of chaotic signals, enhancing feature learning under dynamic\nchannels. The DNN is integrated into the successive interference cancellation\n(SIC) framework to mitigate error propagation issues. Theoretical analysis and\nextensive simulations demonstrate that the proposed system achieves superior\nperformance in terms of spectral efficiency (SE), energy efficiency (EE), bit\nerror rate (BER), security, and robustness, while maintaining lower\ncomputational complexity compared to traditional MU-DCSK and existing DL-aided\nschemes. These advantages validate its practical viability for secure vehicular\ncommunications."}
{"id": "2510.25181", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.25181", "abs": "https://arxiv.org/abs/2510.25181", "authors": ["Yixiang Zhou", "Tong Wu", "Meixia Tao", "Jianhua Mo"], "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder", "comment": null, "summary": "This paper addresses the critical challenges of communication overhead, data\nheterogeneity, and privacy in deep learning for channel state information (CSI)\nfeedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel\nfederated learning framework that incorporates personalized encoders and a\nLoRA-adapted shared decoder. Specifically, personalized encoders are trained\nlocally on each user equipment (UE) to capture device-specific channel\ncharacteristics, while a shared decoder is updated globally via the\ncoordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This\ndesign ensures that only compact LoRA adapter parameters instead of full model\nupdates are transmitted for aggregation. To further enhance convergence\nstability, we introduce an alternating freezing strategy with calibrated\nlearning-rate ratio during LoRA aggregation. Extensive simulations on\n3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\%\nof the uplink communication cost compared to conventional methods while\nachieving a performance gain of 1.2 dB in CSI feedback accuracy under\nheterogeneous conditions."}
