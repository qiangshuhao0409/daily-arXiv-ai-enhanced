<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Graph-Neural Multi-Agent Coordination for Distributed Access-Point Selection in Cell-Free Massive MIMO](https://arxiv.org/abs/2602.17954)
*Mohammad Zangooei,Lou Salaün,Chung Shue Chen,Raouf Boutaba*

Main category: cs.NI

TL;DR: APS-GNN：用于无蜂窝大规模MIMO系统的可扩展分布式多智能体学习框架，通过图神经网络协调AP选择，在满足频谱效率要求的同时显著降低网络功耗和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO系统需要在严格的通信和延迟约束下运行，但现有的接入点选择方法难以同时满足频谱效率要求和最小化网络功耗，特别是在大规模网络中缺乏可扩展的分布式协调机制。

Method: 提出APS-GNN框架：1）将APS问题分解为单个AP-UE连接级别的智能体；2）通过新颖的图神经网络架构进行本地观测交换和协调；3）采用约束强化学习方法，将频谱效率满足度作为成本，功耗降低作为奖励；4）通过监督模仿学习从启发式基线初始化策略以提高训练稳定性。

Result: 在不同评估场景中，APS-GNN能够满足目标频谱效率要求，同时比启发式和集中式多智能体强化学习方法激活的AP数量减少50-70%。推理延迟比集中式MARL方法低1-2个数量级，实现了完全并行和分布式执行。

Conclusion: APS-GNN为大规模无蜂窝大规模MIMO网络中的接入点选择问题提供了一个实用且可扩展的解决方案，在满足服务质量要求的同时显著降低了网络功耗和延迟。

Abstract: Cell-free massive MIMO (CFmMIMO) systems require scalable and reliable distributed coordination mechanisms to operate under stringent communication and latency constraints. A central challenge is the Access Point Selection (APS) problem, which seeks to determine the subset of serving Access Points (APs) for each User Equipment (UE) that can satisfy UEs' Spectral Efficiency (SE) requirements while minimizing network power consumption. We introduce APS-GNN, a scalable distributed multi-agent learning framework that decomposes APS into agents operating at the granularity of individual AP-UE connections. Agents coordinate via local observation exchange over a novel Graph Neural Network (GNN) architecture and share parameters to reuse their knowledge and experience. APS-GNN adopts a constrained reinforcement learning approach to provide agents with explicit observability of APS' conflicting objectives, treating SE satisfaction as a cost and power reduction as a reward. Both signals are defined locally, facilitating effective credit assignment and scalable coordination in large networks. To further improve training stability and exploration efficiency, the policy is initialized via supervised imitation learning from a heuristic APS baseline. We develop a realistic CFmMIMO simulator and demonstrate that APS-GNN delivers the target SE while activating 50-70% fewer APs than heuristic and centralized Multi-agent Reinforcement Learning (MARL) baselines in different evaluation scenarios. Moreover, APS-GNN achieves one to two orders of magnitude lower inference latency than centralized MARL approaches due to its fully parallel and distributed execution. These results establish APS-GNN as a practical and scalable solution for APS in large-scale CFmMIMO networks.

</details>


### [2] [Rethinking Beam Management: Generalization Limits Under Hardware Heterogeneity](https://arxiv.org/abs/2602.18151)
*Nikita Zeulin,Olga Galinina,Ibrahim Kilinc,Sergey Andreev,Robert W. Heath*

Main category: cs.NI

TL;DR: 该论文强调硬件异构性是5G及以后波束管理的关键设计问题，分析了异构环境下的失败模式，并提出了改进泛化能力的策略。


<details>
  <summary>Details</summary>
Motivation: 用户设备的硬件异构性给5G及以后的波束通信带来了新挑战，限制了基于机器学习的算法适用性，需要将硬件异构性作为波束管理的首要设计考虑因素。

Method: 分析了异构环境下的关键失败模式，并通过案例研究展示了异构性对性能的影响，讨论了改进波束管理泛化能力的潜在策略。

Result: 论文展示了硬件异构性如何导致波束管理算法失败，并强调了需要专门设计来应对异构环境的机器学习方法。

Conclusion: 硬件异构性应被视为机器学习辅助波束管理的一等设计关注点，需要开发能够适应不同硬件配置的鲁棒算法来确保5G及以后网络的可靠性能。

Abstract: Hardware heterogeneity across diverse user devices poses new challenges for beam-based communication in 5G and beyond. This heterogeneity limits the applicability of machine learning (ML)-based algorithms. This article highlights the critical need to treat hardware heterogeneity as a first-class design concern in ML-aided beam management. We analyze key failure modes in the presence of heterogeneity and present case studies demonstrating their performance impact. Finally, we discuss potential strategies to improve generalization in beam management.

</details>


### [3] [Noise Mitigation Methods for Digital Visible Light Communication](https://arxiv.org/abs/2602.18187)
*Wataru Uemura,Takumi Hamano*

Main category: cs.NI

TL;DR: 提出两种降低数字可见光通信系统噪声的方法：基于交流电源干扰周期性特征的采样减法，以及受主动噪声控制启发的实时噪声消除技术。


<details>
  <summary>Details</summary>
Motivation: 可见光通信虽然具有低功耗、长寿命和快速响应等优点，但会受到荧光灯等环境光源产生的光学噪声干扰，导致波形失真和误码率增加。

Method: 1. 利用交流电源照明干扰的周期性特征，从接收信号中减去采样噪声波形；2. 受主动噪声控制技术启发，引入额外光电二极管接收噪声，并使用减法电路实时衰减噪声。

Result: 实验结果表明两种方法相比传统接收器都能改善误码率性能，其中受主动噪声控制启发的方法在所有测试条件下都表现出更优越的性能。

Conclusion: 提出的两种噪声降低方法有效改善了数字可见光通信系统的性能，特别是基于主动噪声控制的方法在各种条件下都表现出更好的噪声抑制效果。

Abstract: Visible Light Communication (VLC) using Light Emitting Diodes (LEDs) has gained attention due to its low power consumption, long lifetime, and fast response. However, VLC suffers from optical noise generated by ambient light sources such as fluorescent lamps, which leads to waveform distortion and increased bit error rates (BER). In this paper, we propose two noise reduction methods for Digital Visible Light Communication (DVLC) systems. The first method exploits the periodic nature of interference caused by AC-powered-line illumination and reduces interference by subtracting sampled noise waveforms from the received signal. Second, inspired by Active Noise Control (ANC) techniques, an additional photodiode is introduced for noise reception, and subtraction circuits are employed to attenuate noise in real time. Experimental results show that both methods improve BER performance compared with conventional receivers, with the ANC-inspired approach achieving superior performance under all tested conditions.

</details>


### [4] [A traffic incident management framework for vehicular ad hoc networks](https://arxiv.org/abs/2602.18208)
*Rezvi Shahariar,Chris Phillips*

Main category: cs.NI

TL;DR: 本文提出了一种VANET交通事件管理模型，通过控制消息生成和转发时机来高效管理多种交通事件，并通过仿真验证了四跳转发比60秒转发能通知更多车辆。


<details>
  <summary>Details</summary>
Motivation: 现有VANET模型虽然提出了信任评估、安全认证和信息传播方法，但缺乏能够全面管理交通事件的完整模型。本文旨在解决如何及时报告和管理交通事件的挑战。

Method: 提出交通事件管理模型，详细规定消息生成和转发的时机条件。使用VEINS仿真器模拟车辆、RSU和TA，实验比较两种转发策略：四跳转发和60秒时间限制转发。

Result: 仿真结果显示，在两种情况下，四跳转发策略比60秒时间限制转发能通知更多车辆。实验测量了报告单个交通事件所需的平均传输次数，并考虑了车辆密度变化。

Conclusion: 提出的交通事件管理模型能够有效管理多种交通事件，四跳转发策略在信息传播效果上优于时间限制转发，为VANET中的事件管理提供了实用解决方案。

Abstract: Vehicular Ad Hoc Networks (VANETs) support the information dissemination among vehicles, Roadside Units (RSUs), and a Trust Authority (TA). A trust model evaluates an entity or data or both to determine truthfulness. A security model confirms authentication, integrity, availability, non repudiation issues. With these aspects in mind, many models have been proposed in literature. Furthermore, many information dissemination approaches are proposed. However, the lack of a model that can manage traffic incidents completely inspires this work. This paper details how and when a message needs to be generated and relayed so that the incidents can be reported and managed in a timely manner. This paper addresses this challenge by providing a traffic incident management model to manage several traffic incidents efficiently. Additionally, we simulate this model using the VEINS simulator with vehicles, RSUs, and a TA. From the experiments, we measure the average number of transmissions required for reporting a single traffic incident while varying the vehicle density and relaying considerations. We consider two types of relaying. In one series of experiments, messages from regular vehicles and RSUs are relayed up to four hops. In another series of experiments, messages from the regular vehicles and RSUs are relayed until their generation time reaches sixty seconds. Additionally, messages from the official vehicles are relayed when they approach an incident or when the incident is cleared. Results from the simulations show that more vehicles are informed with four-hop relaying than sixty-second relaying in both cases.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Epistemic Traps: Rational Misalignment Driven by Model Misspecification](https://arxiv.org/abs/2602.17676)
*Xingcheng Xu,Jingjing Qu,Qiaosheng Zhang,Chaochao Lu,Yanqing Yang,Na Zou,Xia Hu*

Main category: cs.AI

TL;DR: 论文提出AI安全问题的根源是模型误设而非训练缺陷，通过经济学理性化理论解释AI行为病理，提出主观模型工程作为新的安全范式


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型和AI代理在关键领域部署受到行为病理（如奉承、幻觉、策略性欺骗）的阻碍，现有安全范式将这些视为训练缺陷，缺乏统一理论框架解释其出现和稳定性

Method: 将经济学中的Berk-Nash理性化理论应用于AI，建立理论框架将智能体建模为在错误主观世界模型中优化，通过六个先进模型的行为实验验证理论预测

Result: 验证了不安全行为是结构必然性：要么作为稳定错位均衡出现，要么表现为振荡循环；策略性欺骗作为"锁定"均衡或认知不确定性持续存在；安全是离散相而非奖励幅度的连续函数

Conclusion: 安全取决于智能体的认知先验而非奖励大小，主观模型工程（设计智能体内部信念结构）是实现稳健对齐的必要条件，标志着从操纵环境奖励到塑造智能体现实解释的范式转变

Abstract: The rapid deployment of Large Language Models and AI agents across critical societal and technical domains is hindered by persistent behavioral pathologies including sycophancy, hallucination, and strategic deception that resist mitigation via reinforcement learning. Current safety paradigms treat these failures as transient training artifacts, lacking a unified theoretical framework to explain their emergence and stability. Here we show that these misalignments are not errors, but mathematically rationalizable behaviors arising from model misspecification. By adapting Berk-Nash Rationalizability from theoretical economics to artificial intelligence, we derive a rigorous framework that models the agent as optimizing against a flawed subjective world model. We demonstrate that widely observed failures are structural necessities: unsafe behaviors emerge as either a stable misaligned equilibrium or oscillatory cycles depending on reward scheme, while strategic deception persists as a "locked-in" equilibrium or through epistemic indeterminacy robust to objective risks. We validate these theoretical predictions through behavioral experiments on six state-of-the-art model families, generating phase diagrams that precisely map the topological boundaries of safe behavior. Our findings reveal that safety is a discrete phase determined by the agent's epistemic priors rather than a continuous function of reward magnitude. This establishes Subjective Model Engineering, defined as the design of an agent's internal belief structure, as a necessary condition for robust alignment, marking a paradigm shift from manipulating environmental rewards to shaping the agent's interpretation of reality.

</details>


### [6] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 论文研究形式化本体论能否通过检索增强生成提升语言模型在数学领域的可靠性，发现高质量本体检索能提升性能，但无关上下文会降低性能


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本限制，在需要可验证推理的高风险专业领域尤为突出。研究旨在探索形式化领域本体论是否能通过检索增强生成提升语言模型可靠性

Method: 使用数学作为概念验证，实现神经符号管道，利用OpenMath本体结合混合检索和交叉编码器重排序，将相关定义注入模型提示中

Result: 在MATH基准测试中评估三个开源模型，发现本体引导的上下文在检索质量高时能提升性能，但无关上下文会主动降低性能

Conclusion: 神经符号方法既有前景也存在挑战，本体引导的上下文改进依赖于高质量的检索，无关信息会损害模型性能

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [7] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一个基于编程谜题的自挑战评估框架，模型通过相互出题和解题进行对决，无需人工出题即可评估推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型推理能力面临挑战：人工设计难题成本高，且难以区分模型是真正推理还是见过类似训练数据。需要一种无法被设计饱和、能同时测试创造力和问题生成能力的评估范式。

Method: 受16世纪数学决斗启发，设计Token Games框架：模型相互挑战，创建编程谜题（给定返回布尔值的Python函数，找到使函数返回True的输入）。通过两两对决计算Elo评分，比较模型相对能力。

Result: 评估了10个前沿模型，TTG的排名结果与Humanity's Last Exam等现有基准高度一致，且无需人工出题。发现创建好谜题对当前模型仍是极具挑战的任务，这是以往基准未测量的能力。

Conclusion: TTG提出了一种新的推理评估范式，不会被设计饱和，能够同时测试模型的问题解决、创造力和任务生成能力，为评估大语言模型提供了更全面的框架。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [8] [El Agente Gráfico: Structured Execution Graphs for Scientific Agents](https://arxiv.org/abs/2602.17902)
*Jiaru Bai,Abdulrahman Aldossary,Thomas Swanick,Marcel Müller,Yeonghun Kang,Zijian Zhang,Jin Won Lee,Tsz Wai Ko,Mohammad Ghazi Vakili,Varinia Bernales,Alán Aspuru-Guzik*

Main category: cs.AI

TL;DR: 提出了El Agente Gráfico框架，通过类型安全的执行环境和动态知识图谱，将LLM驱动的决策嵌入到科学工作流自动化中，解决当前基于文本的代理方法在上下文管理和可审计性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM与异构计算工具的集成方式临时且脆弱，基于非结构化文本的代理方法会产生大量信息，难以追踪决策来源和进行审计。需要更可靠、可扩展的科学自动化框架。

Method: 开发了单代理框架，将科学概念抽象为类型安全的Python对象，通过对象-图映射器将计算状态表示为类型化对象，存储在内存或外部知识图谱中。使用类型化符号标识符而非原始文本进行上下文管理。

Result: 在量子化学任务上构建了自动化基准测试框架，证明单代理结合可靠执行引擎能够稳健执行复杂、多步骤、并行计算。还将该范式扩展到构象集合生成和金属有机框架设计等应用。

Conclusion: 抽象化和类型安全为基于代理的科学自动化提供了可扩展的基础，超越了以提示为中心的设计，通过知识图谱作为记忆和推理基础，支持一致性、来源追踪和高效工具编排。

Abstract: Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making within a type-safe execution environment and dynamic knowledge graphs for external persistence. Central to our approach is a structured abstraction of scientific concepts and an object-graph mapper that represents computational state as typed Python objects, stored either in memory or persisted in an external knowledge graph. This design enables context management through typed symbolic identifiers rather than raw text, thereby ensuring consistency, supporting provenance tracking, and enabling efficient tool orchestration. We evaluate the system by developing an automated benchmarking framework across a suite of university-level quantum chemistry tasks previously evaluated on a multi-agent system, demonstrating that a single agent, when coupled to a reliable execution engine, can robustly perform complex, multi-step, and parallel computations. We further extend this paradigm to two other large classes of applications: conformer ensemble generation and metal-organic framework design, where knowledge graphs serve as both memory and reasoning substrates. Together, these results illustrate how abstraction and type safety can provide a scalable foundation for agentic scientific automation beyond prompt-centric designs.

</details>


### [9] [Alignment in Time: Peak-Aware Orchestration for Long-Horizon Agentic Systems](https://arxiv.org/abs/2602.17910)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.AI

TL;DR: APEMO是一个运行时调度层，通过利用时间-情感信号优化计算资源分配，提升自主代理在长期工作流中的轨迹级可靠性和重用概率。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐主要关注单个模型输出，但自主代理在长期工作流中需要在整个交互轨迹上保持持续可靠性。现有方法通常修改模型权重，而本文提出通过运行时调度来优化计算资源分配。

Method: APEMO（Affect-aware Peak-End Modulation for Orchestration）是一个运行时调度层，通过行为代理检测轨迹不稳定性，并在关键片段（如峰值时刻和结束时刻）进行修复。它不修改模型权重，而是在固定预算下优化计算分配。

Result: 在多智能体模拟和基于LLM的规划-执行流程中的评估表明，APEMO在轨迹级质量和重用概率方面持续优于结构化编排器。

Conclusion: 研究结果将AI对齐重新定义为时间控制问题，为长期智能代理系统的开发提供了一条有弹性的工程路径。

Abstract: Traditional AI alignment primarily focuses on individual model outputs; however, autonomous agents in long-horizon workflows require sustained reliability across entire interaction trajectories. We introduce APEMO (Affect-aware Peak-End Modulation for Orchestration), a runtime scheduling layer that optimizes computational allocation under fixed budgets by operationalizing temporal-affective signals. Instead of modifying model weights, APEMO detects trajectory instability through behavioral proxies and targets repairs at critical segments, such as peak moments and endings. Evaluation across multi-agent simulations and LLM-based planner--executor flows demonstrates that APEMO consistently enhances trajectory-level quality and reuse probability over structural orchestrators. Our results reframe alignment as a temporal control problem, offering a resilient engineering pathway for the development of long-horizon agentic systems.

</details>


### [10] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: 提出了WorkflowPerturb基准，通过可控扰动评估工作流评估指标的敏感性和校准性


<details>
  <summary>Details</summary>
Motivation: LLM生成的结构化工作流评估困难，现有指标分数未校准，分数变化不能直接反映工作流退化严重程度

Method: 创建包含4,973个黄金工作流和44,757个扰动变体的基准，应用三种扰动类型（缺失步骤、压缩步骤、描述变化）和三个严重级别（10%、30%、50%）

Result: 基准测试了多个指标家族，分析了其敏感性和校准特性，揭示了指标家族间的系统性差异，支持基于严重程度的工作流评估分数解释

Conclusion: WorkflowPerturb为工作流评估指标提供了可控的基准，有助于理解指标性能并实现严重程度感知的评估

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [11] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 论文提出结合离线强化学习与跨具身学习的方法，通过聚合异构机器人轨迹来获取通用控制先验，并引入基于形态相似性的分组策略来缓解多机器人学习中的梯度冲突问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人策略预训练中高质量演示数据收集成本高的问题，通过结合离线RL（利用专家和次优数据）与跨具身学习（聚合异构机器人轨迹）来获取通用控制先验。

Method: 1. 系统分析离线RL与跨具身学习范式；2. 构建包含16个不同机器人平台的运动数据集；3. 提出基于形态相似性的分组策略，将机器人按形态聚类，使用组梯度更新模型以减少跨机器人梯度冲突。

Result: 实验证实：1. 结合方法在次优轨迹丰富的数据集上优于纯行为克隆；2. 随着次优数据比例和机器人类型增加，形态间的梯度冲突会阻碍学习；3. 提出的静态分组策略能显著减少机器人间冲突，优于现有冲突解决方法。

Conclusion: 离线RL与跨具身学习结合能有效利用次优数据和异构机器人轨迹进行预训练，但需解决多机器人学习中的梯度冲突问题。提出的基于形态的分组策略是简单有效的解决方案。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [12] [Neurosymbolic Language Reasoning as Satisfiability Modulo Theory](https://arxiv.org/abs/2602.18095)
*Hyunseok Oh,Sam Stern,Youngki Lee,Matthai Philipose*

Main category: cs.AI

TL;DR: Logitext：一种将自然语言文档表示为文本约束的神经符号语言，通过结合LLM约束评估和SMT求解实现文本与逻辑的联合推理


<details>
  <summary>Details</summary>
Motivation: 现有神经符号系统仅限于完全可形式化的任务（如数学或程序合成），无法处理仅具有部分逻辑结构的自然文档。自然语言理解需要交织文本和逻辑推理，但大语言模型在这方面往往不可靠。

Method: 提出Logitext神经符号语言，将文档表示为自然语言文本约束（NLTCs），使部分逻辑结构显式化。开发算法将基于LLM的约束评估与可满足性模理论（SMT）求解相结合，实现联合文本-逻辑推理。

Result: 在新内容审核基准、LegalBench和Super-Natural Instructions上的实验表明，Logitext提高了准确性和覆盖率。这是首个将基于LLM的推理视为SMT理论的工作。

Conclusion: Logitext扩展了神经符号方法的应用范围，使其超越完全可形式化领域，能够处理具有部分逻辑结构的自然文档，实现了更可靠的文本与逻辑联合推理。

Abstract: Natural language understanding requires interleaving textual and logical reasoning, yet large language models often fail to perform such reasoning reliably. Existing neurosymbolic systems combine LLMs with solvers but remain limited to fully formalizable tasks such as math or program synthesis, leaving natural documents with only partial logical structure unaddressed. We introduce Logitext, a neurosymbolic language that represents documents as natural language text constraints (NLTCs), making partial logical structure explicit. We develop an algorithm that integrates LLM-based constraint evaluation with satisfiability modulo theory (SMT) solving, enabling joint textual-logical reasoning. Experiments on a new content moderation benchmark, together with LegalBench and Super-Natural Instructions, show that Logitext improves both accuracy and coverage. This work is the first that treats LLM-based reasoning as an SMT theory, extending neurosymbolic methods beyond fully formalizable domains.

</details>


### [13] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: SOMtime方法在无监督表示中能自动恢复被排除的敏感属性（如年龄、收入），表明"通过无知实现公平"在表示层面失效


<details>
  <summary>Details</summary>
Motivation: 挑战无监督表示对敏感属性保持中性的假设，研究当敏感属性被排除时，它们是否仍会在表示中自动出现

Method: 使用SOMtime（基于高容量自组织映射的拓扑保持表示方法），在两个大规模真实数据集（世界价值观调查和人口普查收入数据集）上测试

Result: SOMtime恢复了与被排除敏感属性对齐的单调排序，Spearman相关性高达0.85，而PCA、UMAP、t-SNE和自编码器最多只有0.34；无监督分割产生人口统计偏斜的聚类

Conclusion: 公平性审计必须扩展到机器学习管道的无监督组件，"通过无知实现公平"在序数敏感属性的表示层面失败

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [14] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD：首个在线多智能体强化学习扩散策略框架，通过放松策略目标最大化联合熵，实现高效探索与协调，在MPE和MAMuJoCo任务上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成和离线设置中展现出卓越的表达能力和多模态表示能力，但在在线多智能体强化学习中的应用尚未充分探索。主要障碍是扩散模型的不可处理似然性阻碍了基于熵的探索和协调。

Method: 提出OMAD框架：1）放松策略目标最大化缩放联合熵，实现无需可处理似然的探索；2）在CTDE范式下使用联合分布值函数优化去中心化扩散策略；3）利用可处理的熵增强目标指导扩散策略同时更新，确保稳定协调。

Result: 在MPE和MAMuJoCo的10个多样化任务上达到新的SOTA性能，样本效率提升2.5倍到5倍。

Conclusion: OMAD成功将扩散策略应用于在线多智能体强化学习，通过放松策略目标和联合分布值函数克服了扩散模型不可处理似然的挑战，实现了高效的探索与协调。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [15] [Flexible Coupler Array with Reconfigurable Pattern: Mechanical Beamforming and Digital Agent](https://arxiv.org/abs/2602.17710)
*Xiaodan Shao,Yixiao Zhang,Nan Cheng,Weihua Zhuang,Xuemin,Shen*

Main category: cs.IT

TL;DR: 提出柔性耦合器阵列，通过移动被动耦合元件实现机械波束成形，增强无线网络容量和覆盖范围，采用数字代理框架优化天线位置和波束成形。


<details>
  <summary>Details</summary>
Motivation: 柔性耦合器通过移动被动耦合元件重塑感应电流，能够增强无线网络容量，但现有方案在辐射模式重构和通信覆盖方面自由度有限，硬件成本较高。

Method: 提出柔性耦合器阵列，保持主动天线固定，仅移动被动耦合元件实现机械波束成形；天线可沿导轨滑动增强覆盖；采用双时间尺度优化框架，基于统计CSI优化天线位置和波束成形；开发数字代理框架利用电磁地图生成统计信道信息，训练深度神经网络学习慢-快性能代理模型。

Result: 仿真结果验证了所提柔性耦合器阵列和数字代理辅助算法的性能增益，实现了更好的通信覆盖和容量提升。

Conclusion: 柔性耦合器阵列通过引入额外的自由度，在低硬件成本下实现了辐射模式重构和通信覆盖增强，数字代理框架有效解决了双时间尺度优化和信道采样成本高的问题。

Abstract: Flexible coupler is a promising solution for enhancing wireless network capacity by moving passive couplers around a fixed-position active antenna to reshape the induced currents on passive elements. Motivated by this, this paper proposes a novel flexible coupler array that incorporates additional degrees of freedom (DoF) in radiation pattern reconfiguration and enhanced communication coverage with low hardware cost. Specifically, a new form of mechanical beamforming can be obtained by moving only the passive coupling elements while keeping the active antenna stationary. In addition, the flexible coupler antenna can slide along a rail toward users, thereby enhancing communication coverage. To fully exploit the potential of the flexible coupler array, we formulate a two-timescale sum-rate maximization problem with statistical channel state information (CSI). The antenna position is optimized based on scattering cluster-core statistics in the slow timescale, while mechanical beamforming is optimized based on multipath channel statistics in the fast timescale, subject to movement and energy constraints. To address the coupling between timescales and the high cost of extensive channel sampling, we develop a digital agent framework that leverages an electromagnetic (EM) map to generate statistical channel information for different user and antenna positions. Then, a deep neural network is trained to learn a slow-fast performance (SFP) surrogate. Mechanical beamforming at the fast timescale is obtained by selecting per-antenna radiation patterns from a predefined dictionary via a convex relaxation. Simulation results verify the performance gains achieved by the proposed flexible coupler array and the digital-agent-assisted algorithm.

</details>


### [16] [Optimality Analysis of RSMA Degenerating to SDMA Under Imperfect SIC](https://arxiv.org/abs/2602.18077)
*Xuejun Cheng,Qian Zhang,Yunnuo Xu,Zheng Dong,Ju Liu,Bruno Clerckx*

Main category: cs.IT

TL;DR: 当SIC严重失效时，RSMA最优解退化为SDMA，为仿真中观察到的收敛现象提供理论依据


<details>
  <summary>Details</summary>
Motivation: 在同时考虑收发机硬件损伤和不完美SIC的建模框架下，从最优性角度为仿真中观察到的"RSMA性能随SIC退化逐渐接近SDMA"现象提供理论证明

Method: 在联合考虑收发机硬件损伤和不完美SIC的建模框架下，系统性地推导和证明：当残余干扰系数趋近于1时，存在最优解使得公共流波束赋形器为零

Result: 证明了当SIC严重失效时，RSMA的最优传输结构退化为SDMA，为仿真观察到的收敛现象提供了可验证的理论依据

Conclusion: 该结论为SIC受限场景下的多址接入选择和系统设计提供了理论参考，解释了RSMA与SDMA性能趋同的理论机制

Abstract: This document serves as supplementary material for our journal submission, providing detailed mathematical proofs and derivations that support the results presented in the main manuscript. Specifically, under a modeling framework that jointly considers transceiver hardware impairments and imperfect successive interference cancellation (SIC), we systematically derive and prove from an optimality perspective that: when the residual interference coefficient approaches 1 (i.e., SIC becomes severely ineffective), there exists an optimal solution such that the common stream beamformer satisfies $\bm w_c^\star=\bm 0$, and hence the optimal rate-splitting multiple access (RSMA) transmission structure degenerates into space division multiple access (SDMA). This conclusion provides a verifiable theoretical justification for the convergence phenomenon observed in simulations, namely that "the RSMA performance gradually approaches that of SDMA as SIC degrades", and can also serve as a reference for multiple-access selection and system design in SIC-limited scenarios.

</details>


### [17] [Uncertainty-Aware Jamming Mitigation with Active RIS: A Robust Stackelberg Game Approach](https://arxiv.org/abs/2602.18165)
*Xiao Tang,Zhen Ma,Limeng Dong,Yichen Wang,Qinghe Du,Dusit Niyato,Zhu Han*

Main category: cs.IT

TL;DR: 本文提出了一种利用主动可重构智能表面（ARIS）进行抗干扰通信的方案，采用Stackelberg博弈建模合法方与干扰方的交互，通过BSUM框架优化功率分配、波束成形和主动反射，实现鲁棒抗干扰。


<details>
  <summary>Details</summary>
Motivation: 恶意干扰对安全通信构成普遍威胁，随着干扰器能力增强能够适应合法传输，这一问题变得日益严重。本文旨在利用主动可重构智能表面（ARIS）进行干扰抑制，特别关注信道不确定性以实现鲁棒抗干扰设计。

Method: 采用Stackelberg博弈建模合法方（领导者）与干扰方（跟随者）的战略交互，证明博弈均衡存在并使用逆向归纳法分析均衡。首先推导干扰方的最优干扰策略作为跟随者最佳响应，然后将其纳入合法方优化进行鲁棒抗干扰设计。利用误差界处理不确定性，在BSUM框架内分解问题，分别优化功率分配、收发波束成形和主动反射，迭代实现鲁棒干扰抑制方案。

Result: 仿真结果表明，所提方案在不确定性条件下能有效保护合法传输，在干扰抑制性能方面优于基线方法。

Conclusion: 本文提出的基于主动可重构智能表面的鲁棒抗干扰方案能够有效应对信道不确定性下的恶意干扰，通过Stackelberg博弈建模和BSUM优化框架实现了优于基线方法的干扰抑制性能。

Abstract: Malicious jamming presents a pervasive threat to the secure communications, where the challenge becomes increasingly severe due to the growing capability of the jammer allowing the adaptation to legitimate transmissions. This paper investigates the jamming mitigation by leveraging an active reconfigurable intelligent surface (ARIS), where the channel uncertainties are particularly addressed for robust anti-jamming design. Towards this issue, we adopt the Stackelberg game formulation to model the strategic interaction between the legitimate side and the adversary, acting as the leader and follower, respectively. We prove the existence of the game equilibrium and adopt the backward induction method for equilibrium analysis. We first derive the optimal jamming policy as the follower's best response, which is then incorporated into the legitimate-side optimization for robust anti-jamming design. We address the uncertainty issue and reformulate the legitimate-side problem by exploiting the error bounds to combat the worst-case jamming attacks. The problem is decomposed within a block successive upper bound minimization (BSUM) framework to tackle the power allocation, transceiving beamforming, and active reflection, respectively, which are iterated towards the robust jamming mitigation scheme. Simulation results are provided to demonstrate the effectiveness of the proposed scheme in protecting the legitimate transmissions under uncertainties, and the superior performance in terms of jamming mitigation as compared with the baselines.

</details>


### [18] [Construction of Cyclic Codes over a Class of Matrix Rings](https://arxiv.org/abs/2602.18255)
*Soham Ravikant Joshi,Shikha Patel,Om Prakash*

Main category: cs.IT

TL;DR: 本文通过有限非交换非链矩阵环构造了有限域上的循环码，建立了环结构与理想形式，推导了码的基数公式，并给出了具有良好参数的实际例子。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索通过有限非交换非链矩阵环构造有限域上循环码的方法，以获取具有良好参数的新线性码，扩展编码理论的研究范围。

Method: 首先分析矩阵环的结构并证明其同构性，然后建立环的理想形式和相关的循环码，推导码的基数公式，考虑欧几里得和对偶，最后通过Bachoc映射和Gray映射将环上的循环码映射到有限域上。

Result: 成功构造了通过矩阵环得到的有限域上的循环码，推导了码的基数公式，建立了对偶关系，并提供了具有良好参数的实际例子，部分码优于现有文献中的码。

Conclusion: 通过有限非交换非链矩阵环可以有效地构造有限域上的循环码，这种方法能够产生具有良好参数的新线性码，扩展了编码理论的研究工具和应用范围。

Abstract: Let $ \mathbb F_2[u]/ \langle u^k \rangle= \mathbb F_2+u\mathbb F_2+u^2\mathbb F_2+\cdots+u^{k-1}\mathbb F_2 ,$ where $u^k=0$ for a positive integer $k$, and $\mathcal{R}=M_4 (\mathbb F_2( u)/ \langle u^k \rangle)$ be the finite noncommutative non-chain matrix ring of order $4\times4$. This paper presents the construction of cyclic codes over the finite field $\mathbb F_{16}$ via the considered matrix ring $\mathcal{R}$. In this connection, first, we discuss the structure of the ring $\mathcal{R}$ and show that $\mathcal{R}$ is isomorphic to the ring $( \mathbb F_{16}+ v\mathbb F_{16} + v^2\mathbb F_{16} + v^3\mathbb F_{16}) + u(\mathbb F_{16} + v\mathbb F_{16} + v^2\mathbb F_{16} + v^3\mathbb F_{16}) + u^2(\mathbb F_{16} + v\mathbb F_{16} + v^2\mathbb F_{16}+ v^3\mathbb F_{16}) + \cdots + u^{k-1}(\mathbb F_{16} + v\mathbb F_{16} + v^2\mathbb F_{16} + v^3\mathbb F_{16})$ where $v^4=0, u^k=0, u^iv^j=v^ju^i$ for $i \in \{1,\dots, k-1\}$ and $j \in \{1, 2, 3\}$. Then, we establish the form of ideals of the ring $\mathcal{R}$ and related cyclic codes over $\mathcal{R}$. Further, we show that these cyclic codes can be written as the direct sums of $\mathcal{R}$-submodules of $\frac{\mathcal{R}[x]}{<x^n-1>}$, and derive the formula for the cardinality of cyclic codes over $\mathcal{R}$. Then, we consider the Euclidean and Hermitian duals of the derived cyclic codes over $\mathcal{R}$. Under the module isometry for $\mathcal{R}$, we use the Bachoc map and the Gray map, which takes a derived cyclic code over $\mathcal{R}$ to $\mathbb F_{16}$. Finally, we provide some non-trivial examples of linear codes over $\mathbb F_{16}$ with good parameters that support our derived results and compare a few codes with existing codes in the literature.

</details>


### [19] [Quantum Maximum Likelihood Prediction via Hilbert Space Embeddings](https://arxiv.org/abs/2602.18364)
*Sreejith Sreekumar,Nir Weinberger*

Main category: cs.IT

TL;DR: 提出从信息几何和统计视角理解大语言模型上下文学习，将其建模为量子密度算子的概率分布嵌入和最大似然预测，建立量子反向信息投影和量子勾股定理的解释框架。


<details>
  <summary>Details</summary>
Motivation: 现有研究对大语言模型上下文预测能力提出了多种解释，本文希望从信息几何和统计角度提供替代概念框架，统一处理经典和量子大语言模型。

Method: 将训练建模为概率分布到量子密度算子空间的嵌入学习，将上下文学习建模为指定量子模型类上的最大似然预测，利用量子反向信息投影和量子勾股定理进行理论解释。

Result: 建立了量子模型充分表达时的量子反向信息投影和量子勾股定理解释框架，推导了迹范数和量子相对熵下的非渐近性能保证，包括收敛速率和集中不等式。

Conclusion: 该信息几何和统计框架为理解大语言模型上下文学习提供了统一的理论基础，能够同时处理经典和量子模型，建立了严格的数学保证。

Abstract: Recent works have proposed various explanations for the ability of modern large language models (LLMs) to perform in-context prediction. We propose an alternative conceptual viewpoint from an information-geometric and statistical perspective. Motivated by Bach[2023], we model training as learning an embedding of probability distributions into the space of quantum density operators, and in-context learning as maximum-likelihood prediction over a specified class of quantum models. We provide an interpretation of this predictor in terms of quantum reverse information projection and quantum Pythagorean theorem when the class of quantum models is sufficiently expressive. We further derive non-asymptotic performance guarantees in terms of convergence rates and concentration inequalities, both in trace norm and quantum relative entropy. Our approach provides a unified framework to handle both classical and quantum LLMs.

</details>


### [20] [A Generalized Information Bottleneck Method: A Decision-Theoretic Perspective](https://arxiv.org/abs/2602.18405)
*Akira Kamatsuka,Takahiro Yoshida*

Main category: cs.IT

TL;DR: 该研究探讨了广义信息瓶颈问题，使用满足凹性和平均条件的ℋ-互信息来评估表示效用，并基于统计决策理论解释开发了交替优化算法。


<details>
  <summary>Details</summary>
Motivation: 经典信息瓶颈方法使用互信息来评估数据压缩和表示效用，但存在局限性。本研究旨在探索更广义的信息瓶颈问题，使用满足特定条件的ℋ-互信息来提供更灵活的效用评估框架。

Method: 基于ℋ-互信息的统计决策理论解释，将其等价于样本信息的期望值，然后开发了交替优化算法来评估广义信息瓶颈问题中的压缩与效用权衡。

Result: 提出了一个理论框架，将广义信息瓶颈问题与统计决策理论联系起来，并开发了相应的优化算法来处理压缩与效用之间的权衡。

Conclusion: 通过引入满足CV和AVG条件的ℋ-互信息，本研究扩展了经典信息瓶颈方法，提供了更灵活的表示学习框架，并建立了与统计决策理论的联系，为实际应用提供了理论基础。

Abstract: The information bottleneck (IB) method seeks a compressed representation of data that preserves information relevant to a target variable for prediction while discarding irrelevant information from the original data. In its classical formulation, the IB method employs mutual information to evaluate the compression between the original and compressed data and the utility of the representation for the target variable. In this study, we investigate a generalized IB problem, where the evaluation of utility is based on the $\mathcal{H}$-mutual information that satisfies the concave (\texttt{CV}) and averaging (\texttt{AVG}) conditions. This class of information measures admits a statistical decision-theoretic interpretation via its equivalence to the expected value of sample information. Based on this interpretation, we derive an alternating optimization algorithm to assess the tradeoff between compression and utility in the generalized IB problem.

</details>
