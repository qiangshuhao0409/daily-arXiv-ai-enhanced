{"id": "2510.02487", "categories": ["cs.NI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02487", "abs": "https://arxiv.org/abs/2510.02487", "authors": ["Ahmed Danladi Abdullahi", "Erfan Bahrami", "Tooska Dargahi", "Mohammed Al-Khalidi", "Mohammad Hammoudeh"], "title": "Interplay between Security, Privacy and Trust in 6G-enabled Intelligent Transportation Systems", "comment": "Submitted to IEEE Open Journal of Intelligent Transportation Systems\n  (32 pages, 5 figures, 7 tables)", "summary": "The advancement of 6G technology has the potential to revolutionize the\ntransportation sector and significantly improve how we travel. 6G-enabled\nIntelligent Transportation Systems (ITS) promise to offer high-speed,\nlow-latency communication and advanced data analytics capabilities, supporting\nthe development of safer, more efficient, and more sustainable transportation\nsolutions. However, various security and privacy challenges were identified in\nthe literature that must be addressed to enable the safe and secure deployment\nof 6G-ITS and ensure people's trust in using these technologies. This paper\nreviews the opportunities and challenges of 6G-ITS, particularly focusing on\ntrust, security, and privacy, with special attention to quantum technologies\nthat both enhance security through quantum key distribution and introduce new\nvulnerabilities. It discusses the potential benefits of 6G technology in the\ntransportation sector, including improved communication, device\ninteroperability support, data analytic capabilities, and increased automation\nfor different components, such as transportation management and communication\nsystems. A taxonomy of different attack models in 6G-ITS is proposed, and a\ncomparison of the security threats in 5G-ITS and 6G-ITS is provided, along with\npotential mitigating solutions. This research highlights the urgent need for a\ncomprehensive, multi-layered security framework spanning physical\ninfrastructure protection, network protocol security, data management\nsafeguards, application security measures, and trust management systems to\neffectively mitigate emerging security and privacy risks and ensure the\nintegrity and resilience of future transportation ecosystems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e866G\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u673a\u9047\u4e0e\u6311\u6218\uff0c\u7279\u522b\u5173\u6ce8\u4fe1\u4efb\u3001\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\uff0c\u5206\u6790\u4e86\u91cf\u5b50\u6280\u672f\u5e26\u6765\u7684\u53cc\u91cd\u5f71\u54cd\uff0c\u63d0\u51fa\u4e866G-ITS\u653b\u51fb\u6a21\u578b\u5206\u7c7b\uff0c\u5e76\u5f3a\u8c03\u4e86\u6784\u5efa\u591a\u5c42\u5b89\u5168\u6846\u67b6\u7684\u5fc5\u8981\u6027\u3002", "motivation": "6G\u6280\u672f\u6709\u671b\u5f7b\u5e95\u6539\u53d8\u4ea4\u901a\u884c\u4e1a\uff0c\u4f46\u5b58\u5728\u5404\u79cd\u5b89\u5168\u548c\u9690\u79c1\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u624d\u80fd\u786e\u4fdd6G-ITS\u7684\u5b89\u5168\u90e8\u7f72\u548c\u516c\u4f17\u4fe1\u4efb\u3002", "method": "\u56de\u987e6G-ITS\u7684\u673a\u4f1a\u4e0e\u6311\u6218\uff0c\u91cd\u70b9\u5173\u6ce8\u4fe1\u4efb\u3001\u5b89\u5168\u548c\u9690\u79c1\uff1b\u63d0\u51fa6G-ITS\u653b\u51fb\u6a21\u578b\u5206\u7c7b\uff1b\u6bd4\u8f835G-ITS\u548c6G-ITS\u7684\u5b89\u5168\u5a01\u80c1\uff1b\u8ba8\u8bba\u6f5c\u5728\u7f13\u89e3\u65b9\u6848\u3002", "result": "\u8bc6\u522b\u4e866G-ITS\u4e2d\u7684\u5173\u952e\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u653b\u51fb\u6a21\u578b\u5206\u7c7b\uff0c\u6bd4\u8f83\u4e865G\u548c6G\u7684\u5b89\u5168\u5a01\u80c1\u5dee\u5f02\uff0c\u5e76\u5f3a\u8c03\u4e86\u91cf\u5b50\u6280\u672f\u65e2\u589e\u5f3a\u5b89\u5168\u53c8\u5f15\u5165\u65b0\u6f0f\u6d1e\u7684\u53cc\u91cd\u4f5c\u7528\u3002", "conclusion": "\u8feb\u5207\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u591a\u5c42\u5b89\u5168\u6846\u67b6\uff0c\u6db5\u76d6\u7269\u7406\u57fa\u7840\u8bbe\u65bd\u4fdd\u62a4\u3001\u7f51\u7edc\u534f\u8bae\u5b89\u5168\u3001\u6570\u636e\u7ba1\u7406\u4fdd\u969c\u3001\u5e94\u7528\u5b89\u5168\u63aa\u65bd\u548c\u4fe1\u4efb\u7ba1\u7406\u7cfb\u7edf\uff0c\u4ee5\u6709\u6548\u7f13\u89e3\u65b0\u5174\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2510.02682", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.02682", "abs": "https://arxiv.org/abs/2510.02682", "authors": ["Haoran Wan", "Kyle Jamieson"], "title": "L4Span: Spanning Congestion Signaling over NextG Networks for Interactive Applications", "comment": null, "summary": "Design for low latency networking is essential for tomorrow's interactive\napplications, but it is essential to deploy incrementally and universally at\nthe network's last mile. While wired broadband ISPs are rolling out the leading\nqueue occupancy signaling mechanisms, the cellular Radio Access Network (RAN),\nanother important last mile to many users, lags behind these efforts. This\npaper proposes a new RAN design, L4Span, that abstracts the complexities of RAN\nqueueing in a simple interface, thus tying the queue state of the RAN to\nend-to-end low-latency signaling all the way back to the content server. At\nmillisecond-level timescales, L4Span predicts the RAN's queuing occupancy and\nperforms ECN marking for both low-latency and classic flows. L4Span is\nlightweight, requiring minimal RAN modifications, and remains 3GPP and O-RAN\ncompliant for maximum ease of deployment. We implement a prototype on the\nsrsRAN open-source software in C++. Our evaluation compares the performance of\nlow-latency as well as classic flows with or without the deployment of L4Span\nin various wireless channel conditions. Results show that L4Span reduces the\none-way delay of both low-latency and classic flows by up to 98 %, while\nsimultaneously maintaining near line-rate throughput. The code is available at\nhttps://github.com/PrincetonUniversity/L4Span.", "AI": {"tldr": "L4Span\u662f\u4e00\u79cd\u65b0\u7684\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc(RAN)\u8bbe\u8ba1\uff0c\u901a\u8fc7\u62bd\u8c61RAN\u961f\u5217\u590d\u6742\u6027\uff0c\u5c06RAN\u961f\u5217\u72b6\u6001\u4e0e\u7aef\u5230\u7aef\u4f4e\u5ef6\u8fdf\u4fe1\u4ee4\u7ed1\u5b9a\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u6709\u7ebf\u5bbd\u5e26ISP\u6b63\u5728\u90e8\u7f72\u5148\u8fdb\u7684\u961f\u5217\u5360\u7528\u4fe1\u4ee4\u673a\u5236\uff0c\u4f46\u8702\u7a9d\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc(RAN)\u4f5c\u4e3a\u91cd\u8981\u7684\u6700\u540e\u4e00\u82f1\u91cc\u7f51\u7edc\uff0c\u5728\u8fd9\u4e9b\u52aa\u529b\u4e2d\u843d\u540e\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u589e\u91cf\u90e8\u7f72\u4e14\u517c\u5bb9\u73b0\u6709\u6807\u51c6\u7684RAN\u4f4e\u5ef6\u8fdf\u89e3\u51b3\u65b9\u6848\u3002", "method": "L4Span\u5728\u6beb\u79d2\u7ea7\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u9884\u6d4bRAN\u7684\u961f\u5217\u5360\u7528\u60c5\u51b5\uff0c\u4e3a\u4f4e\u5ef6\u8fdf\u548c\u7ecf\u5178\u6d41\u91cf\u6267\u884cECN\u6807\u8bb0\u3002\u8be5\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\uff0c\u9700\u8981\u6700\u5c0f\u7684RAN\u4fee\u6539\uff0c\u5e76\u4fdd\u63013GPP\u548cO-RAN\u517c\u5bb9\u6027\u3002\u5728srsRAN\u5f00\u6e90\u8f6f\u4ef6\u4e0a\u4f7f\u7528C++\u5b9e\u73b0\u539f\u578b\u3002", "result": "\u5728\u5404\u79cd\u65e0\u7ebf\u4fe1\u9053\u6761\u4ef6\u4e0b\u8bc4\u4f30\uff0cL4Span\u5c06\u4f4e\u5ef6\u8fdf\u548c\u7ecf\u5178\u6d41\u91cf\u7684\u5355\u5411\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe98%\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u7ebf\u901f\u7684\u541e\u5410\u91cf\u3002", "conclusion": "L4Span\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u5584RAN\u4e2d\u7684\u5ef6\u8fdf\u6027\u80fd\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u63a5\u53e3\u62bd\u8c61RAN\u961f\u5217\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u4f4e\u5ef6\u8fdf\u4fe1\u4ee4\uff0c\u4e14\u6613\u4e8e\u90e8\u7f72\u3002"}}
{"id": "2510.02800", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.02800", "abs": "https://arxiv.org/abs/2510.02800", "authors": ["Rohith Reddy Vennam", "Maiyun Zhang", "Raghav Subbaraman", "Deepak Vashist", "Dinesh Bharadia"], "title": "FSMA: Scalable and Reliable LoRa for Non-Terrestrial Networks with Mobile Gateways", "comment": "14 pages, 19 figures", "summary": "The proliferation of Low Earth Orbit (LEO) satellites for universal IoT\napplications and the growing use of drones in emergency services, agriculture,\nand military operations highlight the transformative potential of\nnon-terrestrial networks (NTN). However, these networks face two key\nchallenges: (1) large coverage footprints that create frequent collisions and\n(2) moving gateways that cause dynamic links and demand synchronization-free,\nlink-aware transmissions. Existing random access schemes such as ALOHA, CSMA,\nand BSMA fail in this setting, suffering from high collision rates, hidden\nterminals, or excessive gateway energy overhead. We propose Free Signal\nMultiple Access (FSMA), a gateway-controlled protocol that introduces a\nlightweight free signal chirp (FreeChirp). FreeChirp ensures that nodes\ntransmit only when the channel is idle and when links are reliable, thereby\nreducing collisions and enabling link-aware access without the need for\nsynchronization or complex scheduling. We evaluate FSMA using 25 commercial\nLoRa devices with a drone-mounted moving gateway and demonstrate up to 2x\nhigher throughput, 2x to 5x better packet reception ratio, and 5x improved\nenergy efficiency compared to the baselines. Large-scale simulations with a\ncustom Satellite IoT Simulator further show that FSMA scales to 5000+ devices\nper satellite pass. These results establish FSMA as a practical step toward\nscalable, energy-efficient, and reliable NTN IoT networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86Free Signal Multiple Access (FSMA)\u534f\u8bae\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u81ea\u7531\u4fe1\u53f7\u5541\u557e(FreeChirp)\u5b9e\u73b0\u7f51\u5173\u63a7\u5236\u7684\u94fe\u8def\u611f\u77e5\u63a5\u5165\uff0c\u89e3\u51b3\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u78b0\u649e\u548c\u52a8\u6001\u94fe\u8def\u95ee\u9898\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u548c\u65e0\u4eba\u673a\u7f51\u7edc\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u5927\u8986\u76d6\u8303\u56f4\u5bfc\u81f4\u9891\u7e41\u78b0\u649e\uff0c\u79fb\u52a8\u7f51\u5173\u9020\u6210\u52a8\u6001\u94fe\u8def\uff0c\u9700\u8981\u514d\u540c\u6b65\u7684\u94fe\u8def\u611f\u77e5\u4f20\u8f93\u3002\u73b0\u6709\u968f\u673a\u63a5\u5165\u65b9\u6848\u5982ALOHA\u3001CSMA\u3001BSMA\u5728\u6b64\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "FSMA\u534f\u8bae\u5f15\u5165\u8f7b\u91cf\u7ea7FreeChirp\u4fe1\u53f7\uff0c\u786e\u4fdd\u8282\u70b9\u4ec5\u5728\u4fe1\u9053\u7a7a\u95f2\u4e14\u94fe\u8def\u53ef\u9760\u65f6\u4f20\u8f93\uff0c\u65e0\u9700\u540c\u6b65\u6216\u590d\u6742\u8c03\u5ea6\u5373\u53ef\u5b9e\u73b0\u94fe\u8def\u611f\u77e5\u63a5\u5165\u3002", "result": "\u4f7f\u752825\u4e2a\u5546\u7528LoRa\u8bbe\u5907\u548c\u65e0\u4eba\u673a\u79fb\u52a8\u7f51\u5173\u6d4b\u8bd5\uff0cFSMA\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6848\u541e\u5410\u91cf\u63d0\u53472\u500d\uff0c\u5305\u63a5\u6536\u7387\u63d0\u53472-5\u500d\uff0c\u80fd\u6548\u63d0\u53475\u500d\u3002\u5927\u89c4\u6a21\u4eff\u771f\u663e\u793a\u53ef\u6269\u5c55\u52305000+\u8bbe\u5907\u3002", "conclusion": "FSMA\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u9ad8\u80fd\u6548\u3001\u53ef\u9760\u975e\u5730\u9762\u7f51\u7edc\u7269\u8054\u7f51\u7684\u5b9e\u9645\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02622", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02622", "abs": "https://arxiv.org/abs/2510.02622", "authors": ["Yuhong Wang", "Yonghong Zeng", "Peng Hui Tan", "Sumei Sun", "Yugang Ma"], "title": "Drone Controller Localization Based on TDoA", "comment": null, "summary": "We study time difference of arrival (TDoA)-based algorithms for drone\ncontroller localization and analyze TDoA estimation in multipath channels.\nBuilding on TDoA estimation, we propose two algorithms to enhance localization\naccuracy in multipath environments: the Maximum Likelihood (ML) algorithm and\nthe Least Squares Bancroft with Gauss-Newton (LS-BF-GN) algorithm. We evaluate\nthese proposed algorithms in two typical outdoor channels: Wireless Local Area\nNetwork (WLAN) Channel F and the two-ray ground reflection (TRGR) channel. Our\nsimulation results demonstrate that the ML and LS-BF-GN algorithms\nsignificantly outperform the LS-BF algorithm in multipath channels. To further\nenhance localization accuracy, we propose averaging multiple tentative location\nestimations. Additionally, we evaluate the impact of time synchronization\nerrors among sensors on localization performance through simulation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eTDoA\u7684\u65e0\u4eba\u673a\u63a7\u5236\u5668\u5b9a\u4f4d\u7b97\u6cd5\uff0c\u5206\u6790\u4e86\u591a\u5f84\u4fe1\u9053\u4e2d\u7684TDoA\u4f30\u8ba1\uff0c\u63d0\u51fa\u4e86ML\u548cLS-BF-GN\u4e24\u79cd\u7b97\u6cd5\u6765\u63d0\u9ad8\u591a\u5f84\u73af\u5883\u4e0b\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u5728\u591a\u5f84\u4fe1\u9053\u73af\u5883\u4e0b\uff0c\u4f20\u7edf\u7684TDoA\u5b9a\u4f4d\u7b97\u6cd5\u6027\u80fd\u4f1a\u663e\u8457\u4e0b\u964d\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u7b97\u6cd5\u6765\u63d0\u9ad8\u65e0\u4eba\u673a\u63a7\u5236\u5668\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u6700\u5927\u4f3c\u7136(ML)\u7b97\u6cd5\u548c\u6700\u5c0f\u4e8c\u4e58\u73ed\u514b\u7f57\u592b\u7279-\u9ad8\u65af\u725b\u987f(LS-BF-GN)\u7b97\u6cd5\uff0c\u5e76\u5728WLAN\u4fe1\u9053F\u548c\u53cc\u5c04\u7ebf\u5730\u9762\u53cd\u5c04\u4fe1\u9053\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cML\u548cLS-BF-GN\u7b97\u6cd5\u5728\u591a\u5f84\u4fe1\u9053\u4e2d\u663e\u8457\u4f18\u4e8eLS-BF\u7b97\u6cd5\uff0c\u901a\u8fc7\u591a\u6b21\u5b9a\u4f4d\u4f30\u8ba1\u5e73\u5747\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u591a\u5f84\u73af\u5883\u4e0b\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u9700\u8981\u8003\u8651\u4f20\u611f\u5668\u95f4\u65f6\u95f4\u540c\u6b65\u8bef\u5dee\u5bf9\u5b9a\u4f4d\u6027\u80fd\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.02895", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.02895", "abs": "https://arxiv.org/abs/2510.02895", "authors": ["Akihisa Takahashi", "Yoshito Tobe"], "title": "DH-EAC: Design of a Dynamic, Hierarchical Entanglement Access Control Protocol", "comment": null, "summary": "We propose Dynamic, Hierarchical Entanglement Access Control (DH-EAC), a\npure-quantum protocol for fair and anonymous allocation of scarce entanglement\nacross wide-area quantum networks composed of many quantum LANs (QLANs). Prior\nDicke-state-based pure-quantum MACs resolve contention by local measurements\nwithout classical signaling, but they mainly target a single QLAN under static\nconditions; extending them to wide-area, dynamic settings while avoiding\npost-selection reconciliation remains open. DH-EAC adopts a two-layer\npure-quantum lottery: the outer layer selects winning QLANs and the inner layer\nselects winning nodes within each winning QLAN. A key design principle is that\nboth the winning set and the per-QLAN quota are fixed by measurements alone, so\nthe contention loop requires no classical round trip. The protocol thus aims to\njointly satisfy anonymity (no node IDs revealed until decisions are fixed) and\nfairness (bias suppression under heterogeneous QLAN sizes). We also provide\nanalytical models for success probability and latency under a standard i.i.d.\nloss model, and we evaluate DH-EAC against two baselines - single-layer Dicke\nwithin one QLAN and a classical GO-driven allocator - using a minimal,\nreproducible set of scenarios. Metrics include success probability, end-to-end\nlatency, throughput, and Jain's fairness index. The results indicate that\nDH-EAC offers an implementable design point in the space of entanglement access\ncontrol, balancing pure-quantum contention resolution, anonymity, and\nscalability for multi-QLAN networks.", "AI": {"tldr": "DH-EAC\u662f\u4e00\u79cd\u7eaf\u91cf\u5b50\u534f\u8bae\uff0c\u7528\u4e8e\u5728\u7531\u591a\u4e2a\u91cf\u5b50\u5c40\u57df\u7f51\u7ec4\u6210\u7684\u5e7f\u57df\u91cf\u5b50\u7f51\u7edc\u4e2d\u516c\u5e73\u533f\u540d\u5730\u5206\u914d\u7a00\u7f3a\u7ea0\u7f20\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eDicke\u6001\u7684\u7eaf\u91cf\u5b50MAC\u534f\u8bae\u4e3b\u8981\u9488\u5bf9\u5355\u4e2a\u91cf\u5b50\u5c40\u57df\u7f51\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5e7f\u57df\u52a8\u6001\u73af\u5883\uff0c\u4e14\u9700\u8981\u907f\u514d\u540e\u9009\u62e9\u534f\u8c03\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u7eaf\u91cf\u5b50\u62bd\u7b7e\u673a\u5236\uff1a\u5916\u5c42\u9009\u62e9\u83b7\u80dc\u7684\u91cf\u5b50\u5c40\u57df\u7f51\uff0c\u5185\u5c42\u9009\u62e9\u6bcf\u4e2a\u83b7\u80dc\u5c40\u57df\u7f51\u5185\u7684\u83b7\u80dc\u8282\u70b9\u3002\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u662f\u901a\u8fc7\u6d4b\u91cf\u56fa\u5b9a\u83b7\u80dc\u96c6\u5408\u548c\u6bcf\u4e2a\u5c40\u57df\u7f51\u7684\u914d\u989d\uff0c\u65e0\u9700\u7ecf\u5178\u5f80\u8fd4\u901a\u4fe1\u3002", "result": "\u5728\u6807\u51c6\u72ec\u7acb\u540c\u5206\u5e03\u635f\u8017\u6a21\u578b\u4e0b\uff0c\u534f\u8bae\u5b9e\u73b0\u4e86\u533f\u540d\u6027\u548c\u516c\u5e73\u6027\uff0c\u76f8\u6bd4\u5355\u5c42Dicke\u534f\u8bae\u548c\u7ecf\u5178GO\u9a71\u52a8\u5206\u914d\u5668\uff0c\u5728\u6210\u529f\u6982\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u516c\u5e73\u6027\u6307\u6807\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "DH-EAC\u5728\u7ea0\u7f20\u8bbf\u95ee\u63a7\u5236\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u5b9e\u65bd\u7684\u8bbe\u8ba1\u70b9\uff0c\u5e73\u8861\u4e86\u7eaf\u91cf\u5b50\u7ade\u4e89\u89e3\u51b3\u3001\u533f\u540d\u6027\u548c\u591a\u91cf\u5b50\u5c40\u57df\u7f51\u7f51\u7edc\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.02640", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02640", "abs": "https://arxiv.org/abs/2510.02640", "authors": ["Jaewon Yun", "Joohyuk Park", "Yo-Seb Jeon"], "title": "Anti-Jamming Modulation for OFDM Systems under Jamming Attacks", "comment": null, "summary": "In this paper, we propose an anti-jamming communication framework for\northogonal frequency-division multiplexing (OFDM) systems under jamming\nattacks. To this end, we first develop an anti-jamming modulation scheme that\nuses a spreading matrix to distribute each symbol across multiple subcarriers,\nenhancing robustness against jamming. For optimal demodulation at a receiver,\nwe devise a maximum likelihood detection (MLD) method and its low-complexity\nvariant tailored to our anti-jamming modulation scheme in scenarios with known\njamming variance. We analyze the bit error rate (BER) of our modulation scheme\nto optimize its modulation order according to a jamming scenario. To adapt to\ndynamic and unknown jamming environments, we present a jamming-adaptive\ncommunication framework consisting of two phases: (i) a jamming-noncoherent\nphase and (ii) a jamming-coherent phase. In the jamming-noncoherent phase, we\ndevelop an approximate MLD method that operates without prior knowledge of\njamming variance and enables the estimation of jamming parameters. In the\njamming-coherent phase, we use these estimated parameters to optimize the\nproposed modulation scheme while employing the low-complexity MLD method.\nSimulation results demonstrate the superior BER performance of the proposed\nanti-jamming framework compared to existing OFDM communication frameworks\nacross a wide range of communication and jamming scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9OFDM\u7cfb\u7edf\u7684\u6297\u5e72\u6270\u901a\u4fe1\u6846\u67b6\uff0c\u5305\u62ec\u6297\u5e72\u6270\u8c03\u5236\u65b9\u6848\u548c\u81ea\u9002\u5e94\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u5df2\u77e5\u548c\u672a\u77e5\u5e72\u6270\u73af\u5883\u4e0b\u90fd\u80fd\u5b9e\u73b0\u4f18\u8d8a\u7684\u8bef\u7801\u7387\u6027\u80fd\u3002", "motivation": "OFDM\u7cfb\u7edf\u5728\u5e72\u6270\u653b\u51fb\u4e0b\u6027\u80fd\u4f1a\u4e25\u91cd\u4e0b\u964d\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6297\u5e72\u6270\u901a\u4fe1\u65b9\u6848\u6765\u589e\u5f3a\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4f7f\u7528\u6269\u9891\u77e9\u9635\u7684\u6297\u5e72\u6270\u8c03\u5236\u65b9\u6848\uff0c\u8bbe\u8ba1\u4e86\u6700\u5927\u4f3c\u7136\u68c0\u6d4b\u65b9\u6cd5\u53ca\u5176\u4f4e\u590d\u6742\u5ea6\u53d8\u4f53\uff0c\u5e76\u63d0\u51fa\u4e86\u5305\u542b\u5e72\u6270\u975e\u76f8\u5e72\u548c\u76f8\u5e72\u4e24\u9636\u6bb5\u7684\u81ea\u9002\u5e94\u901a\u4fe1\u6846\u67b6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6297\u5e72\u6270\u6846\u67b6\u5728\u5404\u79cd\u901a\u4fe1\u548c\u5e72\u6270\u573a\u666f\u4e0b\u90fd\u4f18\u4e8e\u73b0\u6709\u7684OFDM\u901a\u4fe1\u6846\u67b6\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u8bef\u7801\u7387\u6027\u80fd\u3002", "conclusion": "\u8be5\u6297\u5e72\u6270\u901a\u4fe1\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9OFDM\u7cfb\u7edf\u4e2d\u7684\u5e72\u6270\u653b\u51fb\uff0c\u5728\u52a8\u6001\u548c\u672a\u77e5\u5e72\u6270\u73af\u5883\u4e0b\u4fdd\u6301\u53ef\u9760\u7684\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2510.02418", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02418", "abs": "https://arxiv.org/abs/2510.02418", "authors": ["Sagnik Anupam", "Davis Brown", "Shuo Li", "Eric Wong", "Hamed Hassani", "Osbert Bastani"], "title": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks", "comment": null, "summary": "LLM web agents now browse and take actions on the open web, yet current agent\nevaluations are constrained to sandboxed environments or artificial tasks. We\nintroduce BrowserArena, a live open-web agent evaluation platform that collects\nuser-submitted tasks, runs Arena-style head-to-head comparisons, and uses\nstep-level human feedback to surface failure modes. Collecting and analyzing\nstep-level annotations on the agent traces, we identify three consistent\nfailure modes: captcha resolution, pop-up banner removal, and direct navigation\nto URLs. By constructing targeted datasets to further study these tasks, we\ndiscover variations in how different language models navigate these failure\nmodes. We find, for example, that o4-mini deploys a wider variety of strategies\nto circumvent captcha resolution than other models and DeepSeek-R1 consistently\nmisleads users about captcha resolution. Our findings surface both the\ndiversity and brittleness of current web agents. More broadly, our benchmarking\nmethodology provides an approach to evaluating and understanding web agent\nfailure modes at scale.", "AI": {"tldr": "BrowserArena\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u7f51\u9875\u4ee3\u7406\u8bc4\u4f30\u5e73\u53f0\uff0c\u901a\u8fc7\u6536\u96c6\u7528\u6237\u63d0\u4ea4\u7684\u4efb\u52a1\u3001\u8fdb\u884cArena\u5f0f\u5bf9\u6bd4\u6d4b\u8bd5\u548c\u4f7f\u7528\u6b65\u9aa4\u7ea7\u4eba\u5de5\u53cd\u9988\u6765\u8bc6\u522b\u4ee3\u7406\u7684\u5931\u8d25\u6a21\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u7f51\u9875\u4ee3\u7406\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\uff1a\u9a8c\u8bc1\u7801\u8bc6\u522b\u3001\u5f39\u7a97\u6a2a\u5e45\u79fb\u9664\u548c\u76f4\u63a5URL\u5bfc\u822a\u3002", "motivation": "\u5f53\u524d\u7f51\u9875\u4ee3\u7406\u8bc4\u4f30\u5c40\u9650\u4e8e\u6c99\u76d2\u73af\u5883\u6216\u4eba\u5de5\u4efb\u52a1\uff0c\u9700\u8981\u771f\u5b9e\u7684\u5f00\u653e\u7f51\u7edc\u73af\u5883\u6765\u8bc4\u4f30\u4ee3\u7406\u6027\u80fd\u5e76\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u6784\u5efaBrowserArena\u5e73\u53f0\uff0c\u6536\u96c6\u7528\u6237\u63d0\u4ea4\u7684\u771f\u5b9e\u4efb\u52a1\uff0c\u8fdb\u884cArena\u5f0f\u5bf9\u6bd4\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6b65\u9aa4\u7ea7\u4eba\u5de5\u53cd\u9988\u5206\u6790\u4ee3\u7406\u8f68\u8ff9\uff0c\u5e76\u9488\u5bf9\u53d1\u73b0\u7684\u5931\u8d25\u6a21\u5f0f\u6784\u5efa\u4e13\u95e8\u6570\u636e\u96c6\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u4e2a\u4e00\u81f4\u7684\u5931\u8d25\u6a21\u5f0f\uff1a\u9a8c\u8bc1\u7801\u8bc6\u522b\u3001\u5f39\u7a97\u79fb\u9664\u548c\u76f4\u63a5URL\u5bfc\u822a\u3002\u53d1\u73b0\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5982o4-mini\u4f7f\u7528\u66f4\u591a\u7b56\u7565\u7ed5\u8fc7\u9a8c\u8bc1\u7801\uff0c\u800cDeepSeek-R1\u5728\u9a8c\u8bc1\u7801\u89e3\u51b3\u4e0a\u8bef\u5bfc\u7528\u6237\u3002", "conclusion": "\u5f53\u524d\u7f51\u9875\u4ee3\u7406\u8868\u73b0\u51fa\u591a\u6837\u6027\u548c\u8106\u5f31\u6027\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u8bc4\u4f30\u548c\u7406\u89e3\u7f51\u9875\u4ee3\u7406\u5931\u8d25\u6a21\u5f0f\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.02958", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.02958", "abs": "https://arxiv.org/abs/2510.02958", "authors": ["Muhammad Kabeer", "Rosdiadee Nordin", "Mehran Behjati", "Lau Sian Lun"], "title": "Sequence-Based Deep Learning for Handover Optimization in Dense Urban Cellular Network", "comment": "6 pages, 6 figures, conference", "summary": "Efficient handover management remains a critical challenge in dense urban\ncellular networks, where high cell density, user mobility, and diverse service\ndemands increase the likelihood of unnecessary handovers and ping-pong effects.\nThis paper leverages a real-world, multi-operator drive-test dataset of 30,925\nlabelled records collected within a 2 km area around Sunway City to investigate\nsequence-based deep learning approaches for handover detection and avoidance.\nWe formulate handover prediction as a sequence problem and evaluate Gated\nRecurrent Unit (GRU), Long Short-Term Memory (LSTM), and Transformer\narchitectures under Reference Signal Received Power (RSRP)-only and all-feature\nsettings. The integration of multi-dimensional features significantly enhanced\nhandover performance in dense urban cellular networks. The proposed GRU-based\nmodel achieved a remarkable 98% reduction in ping-pong handovers, alongside a\n46.25% decrease in unnecessary handovers, outperforming the baseline RSRP-only\napproach which yielded a 22.19% reduction. Furthermore, the model demonstrated\na 46% improvement in Time of Stay (ToS), indicating more stable user\nconnections. With an inference time of just 0.91 seconds, the solution proves\nhighly efficient and well-suited for real-time edge deployment scenarios.\nCompared to the conventional 3GPP A3 algorithm, these improvements demonstrate\nsignificant gains in mobility robustness and user Quality of Experience (QoE)\nimprovement. The dataset is released to foster reproducibility and further\nresearch in intelligent mobility management for 5G and beyond.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u771f\u5b9e\u4e16\u754c\u591a\u8fd0\u8425\u5546\u8def\u6d4b\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u57fa\u4e8e\u5e8f\u5217\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u5bc6\u96c6\u57ce\u5e02\u8702\u7a9d\u7f51\u7edc\u4e2d\u7684\u5207\u6362\u68c0\u6d4b\u548c\u907f\u514d\uff0cGRU\u6a21\u578b\u5728\u51cf\u5c11\u4e52\u4e53\u5207\u6362\u548c\u4e0d\u5fc5\u8981\u5207\u6362\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5bc6\u96c6\u57ce\u5e02\u8702\u7a9d\u7f51\u7edc\u4e2d\u9ad8\u5c0f\u533a\u5bc6\u5ea6\u3001\u7528\u6237\u79fb\u52a8\u6027\u548c\u591a\u6837\u5316\u670d\u52a1\u9700\u6c42\u589e\u52a0\u4e86\u4e0d\u5fc5\u8981\u5207\u6362\u548c\u4e52\u4e53\u6548\u5e94\u7684\u53ef\u80fd\u6027\uff0c\u9700\u8981\u9ad8\u6548\u7684\u5207\u6362\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u5207\u6362\u9884\u6d4b\u5236\u5b9a\u4e3a\u5e8f\u5217\u95ee\u9898\uff0c\u5728\u4ec5\u4f7f\u7528\u53c2\u8003\u4fe1\u53f7\u63a5\u6536\u529f\u7387(RSRP)\u548c\u5168\u7279\u5f81\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u95e8\u63a7\u5faa\u73af\u5355\u5143(GRU)\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc(LSTM)\u548cTransformer\u67b6\u6784\u3002", "result": "\u57fa\u4e8eGRU\u7684\u6a21\u578b\u5b9e\u73b0\u4e8698%\u7684\u4e52\u4e53\u5207\u6362\u51cf\u5c11\u548c46.25%\u7684\u4e0d\u5fc5\u8981\u5207\u6362\u51cf\u5c11\uff0c\u9a7b\u7559\u65f6\u95f4(ToS)\u6539\u558446%\uff0c\u63a8\u7406\u65f6\u95f4\u4ec50.91\u79d2\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf3GPP A3\u7b97\u6cd5\u3002", "conclusion": "\u591a\u7ef4\u7279\u5f81\u7684\u96c6\u6210\u663e\u8457\u63d0\u5347\u4e86\u5bc6\u96c6\u57ce\u5e02\u8702\u7a9d\u7f51\u7edc\u4e2d\u7684\u5207\u6362\u6027\u80fd\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u9ad8\u6548\u4e14\u9002\u5408\u5b9e\u65f6\u8fb9\u7f18\u90e8\u7f72\uff0c\u5728\u79fb\u52a8\u9c81\u68d2\u6027\u548c\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\u65b9\u9762\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2510.02649", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02649", "abs": "https://arxiv.org/abs/2510.02649", "authors": ["Abel Jansma", "Erik Hoel"], "title": "Engineering Emergence", "comment": "25 pages, 5 figures", "summary": "One of the reasons complex systems are complex is because they have\nmultiscale structure. How does this multiscale structure come about? We argue\nthat it reflects an emergent hierarchy of scales that contribute to the\nsystem's causal workings. An example is how a computer can be described at the\nlevel of its hardware circuitry but also its software. But we show that many\nsystems, even simple ones, have such an emergent hierarchy, built from a small\nsubset of all their possible scales of description. Formally, we extend the\ntheory of causal emergence (2.0) so as to analyze the causal contributions\nacross the full multiscale structure of a system rather than just over a single\npath that traverses the system's scales. Our methods reveal that systems can be\nclassified as being causally top-heavy or bottom-heavy, or their emergent\nhierarchies can be highly complex. We argue that this provides a more specific\nnotion of scale-freeness (here, when causation is spread equally across the\nscales of a system) than the standard network science terminology. More\nbroadly, we provide the mathematical tools to quantify this complexity and\nprovide diverse examples of the taxonomy of emergent hierarchies. Finally, we\ndemonstrate the ability to engineer not just degree of emergence in a system,\nbut how that emergence is distributed across the multiscale structure.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6269\u5c55\u4e86\u56e0\u679c\u6d8c\u73b0\u7406\u8bba\uff0c\u5206\u6790\u4e86\u7cfb\u7edf\u591a\u5c3a\u5ea6\u7ed3\u6784\u4e2d\u7684\u56e0\u679c\u8d21\u732e\u5206\u5e03\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u53ef\u5206\u4e3a\u56e0\u679c\u9876\u91cd\u3001\u5e95\u91cd\u6216\u590d\u6742\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u63d0\u4f9b\u4e86\u91cf\u5316\u8fd9\u79cd\u590d\u6742\u6027\u7684\u6570\u5b66\u5de5\u5177\u3002", "motivation": "\u7814\u7a76\u590d\u6742\u7cfb\u7edf\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784\u5982\u4f55\u4ea7\u751f\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u5c3a\u5ea6\u5982\u4f55\u8d21\u732e\u4e8e\u7cfb\u7edf\u7684\u56e0\u679c\u5de5\u4f5c\u673a\u5236\uff0c\u65e8\u5728\u66f4\u7cbe\u786e\u5730\u7406\u89e3\u5c3a\u5ea6\u81ea\u7531\u6027\u548c\u7cfb\u7edf\u590d\u6742\u6027\u3002", "method": "\u6269\u5c55\u56e0\u679c\u6d8c\u73b0\u7406\u8bba(2.0)\uff0c\u5206\u6790\u7cfb\u7edf\u5b8c\u6574\u591a\u5c3a\u5ea6\u7ed3\u6784\u800c\u975e\u5355\u4e00\u5c3a\u5ea6\u8def\u5f84\u7684\u56e0\u679c\u8d21\u732e\uff0c\u5f00\u53d1\u6570\u5b66\u5de5\u5177\u6765\u91cf\u5316\u591a\u5c3a\u5ea6\u7ed3\u6784\u7684\u590d\u6742\u6027\u3002", "result": "\u63ed\u793a\u4e86\u7cfb\u7edf\u53ef\u5206\u4e3a\u56e0\u679c\u9876\u91cd\u578b\u3001\u5e95\u91cd\u578b\u6216\u590d\u6742\u5c42\u6b21\u7ed3\u6784\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u7f51\u7edc\u79d1\u5b66\u66f4\u5177\u4f53\u7684\u5c3a\u5ea6\u81ea\u7531\u6027\u6982\u5ff5\uff0c\u5c55\u793a\u4e86\u5728\u7cfb\u7edf\u591a\u5c3a\u5ea6\u7ed3\u6784\u4e2d\u5de5\u7a0b\u5316\u6d8c\u73b0\u5206\u5e03\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u7cfb\u7edf\u591a\u5c3a\u5ea6\u7ed3\u6784\u7684\u56e0\u679c\u5c42\u6b21\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u6570\u5b66\u5de5\u5177\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u63cf\u8ff0\u548c\u5de5\u7a0b\u5316\u7cfb\u7edf\u7684\u6d8c\u73b0\u7279\u6027\u5206\u5e03\u3002"}}
{"id": "2510.02423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02423", "abs": "https://arxiv.org/abs/2510.02423", "authors": ["Hang Wu", "Yujun Cai", "Haonan Ge", "Hongkai Chen", "Ming-Hsuan Yang", "Yiwei Wang"], "title": "RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation", "comment": null, "summary": "Cinematography understanding refers to the ability to recognize not only the\nvisual content of a scene but also the cinematic techniques that shape\nnarrative meaning. This capability is attracting increasing attention, as it\nenhances multimodal understanding in real-world applications and underpins\ncoherent content creation in film and media. As the most comprehensive\nbenchmark for this task, ShotBench spans a wide range of cinematic concepts and\nVQA-style evaluations, with ShotVL achieving state-of-the-art results on it.\nHowever, our analysis reveals that ambiguous option design in ShotBench and\nShotVL's shortcomings in reasoning consistency and instruction adherence\nundermine evaluation reliability, limiting fair comparison and hindering future\nprogress. To overcome these issues, we systematically refine ShotBench through\nconsistent option restructuring, conduct the first critical analysis of\nShotVL's reasoning behavior, and introduce an extended evaluation protocol that\njointly assesses task accuracy and core model competencies. These efforts lead\nto RefineShot, a refined and expanded benchmark that enables more reliable\nassessment and fosters future advances in cinematography understanding.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86ShotBench\u57fa\u51c6\u6d4b\u8bd5\u5728\u7535\u5f71\u6444\u5f71\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u9009\u9879\u8bbe\u8ba1\u6a21\u7cca\u548cShotVL\u6a21\u578b\u5728\u63a8\u7406\u4e00\u81f4\u6027\u4e0e\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86RefineShot\u57fa\u51c6\u6765\u6539\u8fdb\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u7535\u5f71\u6444\u5f71\u7406\u89e3\u57fa\u51c6ShotBench\u5b58\u5728\u9009\u9879\u8bbe\u8ba1\u6a21\u7cca\u95ee\u9898\uff0c\u4e14ShotVL\u6a21\u578b\u5728\u63a8\u7406\u4e00\u81f4\u6027\u548c\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u5b58\u5728\u7f3a\u9677\uff0c\u8fd9\u5f71\u54cd\u4e86\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u963b\u788d\u4e86\u516c\u5e73\u6bd4\u8f83\u548c\u672a\u6765\u8fdb\u5c55\u3002", "method": "\u901a\u8fc7\u4e00\u81f4\u7684\u9009\u9879\u91cd\u6784\u7cfb\u7edf\u5316\u6539\u8fdbShotBench\uff0c\u5bf9ShotVL\u7684\u63a8\u7406\u884c\u4e3a\u8fdb\u884c\u9996\u6b21\u6279\u5224\u6027\u5206\u6790\uff0c\u5e76\u5f15\u5165\u8054\u5408\u8bc4\u4f30\u4efb\u52a1\u51c6\u786e\u6027\u548c\u6838\u5fc3\u6a21\u578b\u80fd\u529b\u7684\u6269\u5c55\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u5f00\u53d1\u4e86RefineShot\u57fa\u51c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ecf\u8fc7\u6539\u8fdb\u548c\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\uff0c\u4fc3\u8fdb\u7535\u5f71\u6444\u5f71\u7406\u89e3\u7684\u672a\u6765\u53d1\u5c55\u3002", "conclusion": "RefineShot\u57fa\u51c6\u89e3\u51b3\u4e86ShotBench\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7535\u5f71\u6444\u5f71\u7406\u89e3\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2510.03205", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03205", "abs": "https://arxiv.org/abs/2510.03205", "authors": ["Shenjia Ding", "David Flynn", "Paul Harvey"], "title": "Automatic Generation of Digital Twins for Network Testing", "comment": "Accepted to ANMS at ICDCS 2025", "summary": "The increased use of software in the operation and management of\ntelecommunication networks has moved the industry one step closer to realizing\nautonomous network operation. One consequence of this shift is the\nsignificantly increased need for testing and validation before such software\ncan be deployed. Complementing existing simulation or hardware-based\napproaches, digital twins present an environment to achieve this testing;\nhowever, they require significant time and human effort to configure and\nexecute. This paper explores the automatic generation of digital twins to\nprovide efficient and accurate validation tools, aligned to the ITU-T\nautonomous network architecture's experimentation subsystem. We present\nexperimental results for an initial use case, demonstrating that the approach\nis feasible in automatically creating efficient digital twins with sufficient\naccuracy to be included as part of existing validation pipelines.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u81ea\u52a8\u751f\u6210\u6570\u5b57\u5b6a\u751f\u6280\u672f\uff0c\u4e3a\u7535\u4fe1\u7f51\u7edc\u8f6f\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u9ad8\u6548\u51c6\u786e\u7684\u9a8c\u8bc1\u5de5\u5177\uff0c\u7b26\u5408ITU-T\u81ea\u4e3b\u7f51\u7edc\u67b6\u6784\u7684\u5b9e\u9a8c\u5b50\u7cfb\u7edf\u8981\u6c42\u3002", "motivation": "\u968f\u7740\u7535\u4fe1\u7f51\u7edc\u8fd0\u8425\u7ba1\u7406\u4e2d\u8f6f\u4ef6\u4f7f\u7528\u7684\u589e\u52a0\uff0c\u5bf9\u90e8\u7f72\u524d\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u7684\u9700\u6c42\u663e\u8457\u589e\u957f\u3002\u6570\u5b57\u5b6a\u751f\u867d\u7136\u80fd\u63d0\u4f9b\u6d4b\u8bd5\u73af\u5883\uff0c\u4f46\u914d\u7f6e\u548c\u6267\u884c\u9700\u8981\u5927\u91cf\u65f6\u95f4\u548c\u4eba\u529b\u6295\u5165\u3002", "method": "\u63d0\u51fa\u4e86\u81ea\u52a8\u751f\u6210\u6570\u5b57\u5b6a\u751f\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8eITU-T\u81ea\u4e3b\u7f51\u7edc\u67b6\u6784\u7684\u5b9e\u9a8c\u5b50\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u521b\u5efa\u6570\u5b57\u5b6a\u751f\u73af\u5883\u3002", "result": "\u901a\u8fc7\u521d\u6b65\u7528\u4f8b\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u521b\u5efa\u9ad8\u6548\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u5177\u6709\u8db3\u591f\u7684\u51c6\u786e\u6027\uff0c\u53ef\u4ee5\u7eb3\u5165\u73b0\u6709\u7684\u9a8c\u8bc1\u6d41\u7a0b\u4e2d\u3002", "conclusion": "\u81ea\u52a8\u751f\u6210\u6570\u5b57\u5b6a\u751f\u7684\u65b9\u6cd5\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u4e3a\u7535\u4fe1\u7f51\u7edc\u8f6f\u4ef6\u7684\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u63d0\u4f9b\u6709\u6548\u7684\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2510.02701", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02701", "abs": "https://arxiv.org/abs/2510.02701", "authors": ["Chong Zhang", "Ben Liang", "Min Dong", "Ali Afana", "Yahia Ahmed"], "title": "Robust Segmented Analog Broadcast Design to Accelerate Wireless Federated Learning", "comment": "10 pages, 10 figures", "summary": "We consider downlink broadcast design for federated learning (FL) in a\nwireless network with imperfect channel state information (CSI). Aiming to\nreduce transmission latency, we propose a segmented analog broadcast (SegAB)\nscheme, where the parameter server, hosted by a multi-antenna base station,\npartitions the global model parameter vector into segments and transmits\nmultiple parameters from these segments simultaneously over a common downlink\nchannel. We formulate the SegAB transmission and reception processes to\ncharacterize FL training convergence, capturing the effects of downlink\nbeamforming and imperfect CSI. To maximize the FL training convergence rate, we\nestablish an upper bound on the expected model optimality gap and show that it\ncan be minimized separately over the training rounds in online optimization,\nwithout requiring knowledge of the future channel states. We solve the\nper-round problem to achieve robust downlink beamforming, by minimizing the\nworst-case objective via an epigraph representation and a feasibility\nsubproblem that ensures monotone convergence. Simulation with standard\nclassification tasks under typical wireless network setting shows that the\nproposed SegAB substantially outperforms conventional full-model per-parameter\nbroadcast and other alternatives.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6bb5\u6a21\u62df\u5e7f\u64ad(SegAB)\u65b9\u6848\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u4e0b\u884c\u94fe\u8def\u4f20\u8f93\uff0c\u901a\u8fc7\u5206\u5272\u6a21\u578b\u53c2\u6570\u5e76\u540c\u65f6\u4f20\u8f93\u6765\u51cf\u5c11\u5ef6\u8fdf\uff0c\u5728\u975e\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0b\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u4ee5\u6700\u5927\u5316\u8bad\u7ec3\u6536\u655b\u901f\u7387\u3002", "motivation": "\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\uff0c\u8054\u90a6\u5b66\u4e60\u7684\u4e0b\u884c\u94fe\u8def\u4f20\u8f93\u9762\u4e34\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u548c\u4f20\u8f93\u5ef6\u8fdf\u7684\u6311\u6218\uff0c\u9700\u8981\u8bbe\u8ba1\u9ad8\u6548\u7684\u5e7f\u64ad\u65b9\u6848\u6765\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u91c7\u7528\u5206\u6bb5\u6a21\u62df\u5e7f\u64ad(SegAB)\u65b9\u6848\uff0c\u5c06\u5168\u5c40\u6a21\u578b\u53c2\u6570\u5411\u91cf\u5206\u5272\u6210\u6bb5\uff0c\u5728\u516c\u5171\u4e0b\u884c\u94fe\u8def\u4e0a\u540c\u65f6\u4f20\u8f93\u591a\u4e2a\u53c2\u6570\uff0c\u5e76\u5efa\u7acb\u4f20\u8f93\u548c\u63a5\u6536\u8fc7\u7a0b\u7684\u6570\u5b66\u6a21\u578b\uff0c\u901a\u8fc7epigraph\u8868\u793a\u548c\u53ef\u884c\u6027\u5b50\u95ee\u9898\u5b9e\u73b0\u9c81\u68d2\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u5728\u6807\u51c6\u5206\u7c7b\u4efb\u52a1\u548c\u5178\u578b\u65e0\u7ebf\u7f51\u7edc\u8bbe\u7f6e\u4e0b\u7684\u4eff\u771f\u8868\u660e\uff0cSegAB\u65b9\u6848\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u5168\u6a21\u578b\u9010\u53c2\u6570\u5e7f\u64ad\u548c\u5176\u4ed6\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "SegAB\u65b9\u6848\u80fd\u591f\u6709\u6548\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u7684\u4f20\u8f93\u5ef6\u8fdf\uff0c\u5728\u975e\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4e0b\u901a\u8fc7\u9c81\u68d2\u6ce2\u675f\u6210\u5f62\u4f18\u5316\u63d0\u5347\u8bad\u7ec3\u6536\u655b\u6027\u80fd\u3002"}}
{"id": "2510.02480", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02480", "abs": "https://arxiv.org/abs/2510.02480", "authors": ["Andrea Wynn", "Metod Jazbec", "Charith Peris", "Rinat Khaziev", "Anqi Liu", "Daniel Khashabi", "Eric Nalisnick"], "title": "Safe and Efficient In-Context Learning via Risk Control", "comment": null, "summary": "Large language models (LLMs) demonstrate a remarkable ability to learn new\ntasks from a few in-context examples. However, this flexibility introduces\nsafety concerns: LLMs can be influenced by incorrect or malicious\ndemonstrations -- for example, if an adversary tampers with or injects harmful\nexamples without a human supervisor noticing. This motivates principled designs\nin which the system itself includes built-in mechanisms to guard against such\nattacks. We propose a novel approach to limit the degree to which harmful\ndemonstrations can degrade model performance. First, we define a baseline\n``safe'' behavior for the model -- the model's performance given no in-context\ndemonstrations (zero-shot). Next, we apply distribution-free risk control\n(DFRC) to control the extent to which in-context samples can decay performance\nbelow zero-shot. We achieve this by leveraging dynamic early exit prediction,\nignoring later attention heads that attend the most to the unsafe inputs.\nFinally, we propose modifications to DFRC that allow it to both control risk\nfor harmful inputs \\textit{and} leverage performance and efficiency gains on\nhelpful inputs. We present both theoretical and empirical results showing that\nour approach can effectively control risk for harmful in-context demonstrations\nwhile simultaneously achieving substantial computational efficiency gains with\nhelpful demonstrations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u65e0\u5173\u98ce\u9669\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u63d0\u524d\u9000\u51fa\u673a\u5236\u6765\u9632\u5fa1\u6076\u610f\u4e0a\u4e0b\u6587\u793a\u4f8b\u5bf9LLM\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6709\u76ca\u793a\u4f8b\u7684\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002", "motivation": "LLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u6076\u610f\u6216\u9519\u8bef\u793a\u4f8b\u7684\u5f71\u54cd\uff0c\u9700\u8981\u5185\u7f6e\u5b89\u5168\u673a\u5236\u6765\u9632\u6b62\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5b9a\u4e49\u96f6\u6837\u672c\u57fa\u51c6\u5b89\u5168\u884c\u4e3a\uff0c\u5e94\u7528\u5206\u5e03\u65e0\u5173\u98ce\u9669\u63a7\u5236\uff0c\u91c7\u7528\u52a8\u6001\u63d0\u524d\u9000\u51fa\u9884\u6d4b\u673a\u5236\uff0c\u5ffd\u7565\u5bf9\u4e0d\u5b89\u5168\u8f93\u5165\u5173\u6ce8\u5ea6\u9ad8\u7684\u6ce8\u610f\u529b\u5934\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u6076\u610f\u4e0a\u4e0b\u6587\u793a\u4f8b\u7684\u98ce\u9669\uff0c\u540c\u65f6\u5728\u6709\u76ca\u793a\u4f8b\u4e0a\u5b9e\u73b0\u663e\u8457\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aLLM\u63d0\u4f9b\u4e86\u5185\u7f6e\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u4e0d\u727a\u7272\u6709\u76ca\u4e0a\u4e0b\u6587\u793a\u4f8b\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u548c\u6548\u7387\u4f18\u52bf\u3002"}}
{"id": "2510.02981", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02981", "abs": "https://arxiv.org/abs/2510.02981", "authors": ["Yuxin Li", "Guangyue Lu", "Yinghui Ye", "Zehui Xiong", "Liqin Shi"], "title": "Symbol Timing Synchronization and Signal Detection for Ambient Backscatter Communication", "comment": null, "summary": "Ambient backscatter communication (AmBC) enables ambient Internet of Things\n(AIoT) devices to achieve ultra-low-power, low-cost, and massive connectivity.\nMost existing AmBC studies assume ideal synchronization between the backscatter\ndevice (BD) and the backscatter receiver (BR). However, in practice, symbol\ntiming offset (STO) occurs due to both the propagation delay and the BR\nactivation latency, which leads to unreliable symbol recovery at the BR.\nMoreover, the uncontrollable nature of the ambient radio frequency source\nrenders conventional correlation-based synchronization methods infeasible in\nAmBC. To address this challenge, we investigate STO estimation and symbol\ndetection in AmBC without requiring coordination from the ambient radio\nfrequency source. Firstly, we design a specialized pilot sequence at the BD to\ninduce sampling errors in the pilot signal. Furthermore, we propose a\npilot-based STO estimator using the framework of maximum likelihood estimation\n(MLE), which can exploit the statistical variations in the received pilot\nsignal. Finally, we integrate STO compensation into an energy detector and\nevaluate the bit error rate (BER) performance. Simulation results show that the\nproposed estimator achieves accurate STO estimation and effectively mitigates\nthe BER performance degradation caused by STO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u4e2d\u7b26\u53f7\u5b9a\u65f6\u504f\u79fb\u95ee\u9898\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e13\u7528\u5bfc\u9891\u5e8f\u5217\u548c\u80fd\u91cf\u68c0\u6d4b\u5668\u5b9e\u73b0\u51c6\u786e\u7684STO\u4f30\u8ba1\u548c\u7b26\u53f7\u68c0\u6d4b\u3002", "motivation": "\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u7b26\u53f7\u5b9a\u65f6\u504f\u79fb\u95ee\u9898\uff0c\u8fd9\u6e90\u4e8e\u4f20\u64ad\u5ef6\u8fdf\u548c\u63a5\u6536\u5668\u6fc0\u6d3b\u5ef6\u8fdf\uff0c\u5bfc\u81f4\u4e0d\u53ef\u9760\u7684\u7b26\u53f7\u6062\u590d\u3002\u4f20\u7edf\u57fa\u4e8e\u76f8\u5173\u7684\u540c\u6b65\u65b9\u6cd5\u5728AmBC\u4e2d\u4e0d\u53ef\u884c\uff0c\u56e0\u4e3a\u73af\u5883\u5c04\u9891\u6e90\u4e0d\u53ef\u63a7\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e13\u7528\u5bfc\u9891\u5e8f\u5217\u4ee5\u5728\u5bfc\u9891\u4fe1\u53f7\u4e2d\u5f15\u5165\u91c7\u6837\u8bef\u5dee\uff1b\u63d0\u51fa\u4e86\u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u5bfc\u9891STO\u4f30\u8ba1\u5668\uff0c\u5229\u7528\u63a5\u6536\u5bfc\u9891\u4fe1\u53f7\u7684\u7edf\u8ba1\u53d8\u5316\uff1b\u5c06STO\u8865\u507f\u96c6\u6210\u5230\u80fd\u91cf\u68c0\u6d4b\u5668\u4e2d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u5b9e\u73b0\u4e86\u51c6\u786e\u7684STO\u4f30\u8ba1\uff0c\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u7531STO\u5f15\u8d77\u7684BER\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u9700\u8981\u73af\u5883\u5c04\u9891\u6e90\u534f\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u89e3\u51b3AmBC\u4e2d\u7684\u7b26\u53f7\u5b9a\u65f6\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u9ad8\u901a\u4fe1\u53ef\u9760\u6027\u3002"}}
{"id": "2510.02528", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02528", "abs": "https://arxiv.org/abs/2510.02528", "authors": ["Shuhao Fu", "Esther Goldberg", "Ying Nian Wu", "Hongjing Lu"], "title": "Multimodal Function Vectors for Spatial Relations", "comment": null, "summary": "Large Multimodal Models (LMMs) demonstrate impressive in-context learning\nabilities from limited multimodal demonstrations, yet the internal mechanisms\nsupporting such task learning remain opaque. Building on prior work of large\nlanguage models, we show that a small subset of attention heads in the\nvision-language model OpenFlamingo-4B is responsible for transmitting\nrepresentations of spatial relations. The activations of these attention heads,\ntermed function vectors, can be extracted and manipulated to alter an LMM's\nperformance on relational tasks. First, using both synthetic and real image\ndatasets, we apply causal mediation analysis to identify attention heads that\nstrongly influence relational predictions, and extract multimodal function\nvectors that improve zero-shot accuracy at inference time. We further\ndemonstrate that these multimodal function vectors can be fine-tuned with a\nmodest amount of training data, while keeping LMM parameters frozen, to\nsignificantly outperform in-context learning baselines. Finally, we show that\nrelation-specific function vectors can be linearly combined to solve analogy\nproblems involving novel and untrained spatial relations, highlighting the\nstrong generalization ability of this approach. Our results show that LMMs\nencode spatial relational knowledge within localized internal structures, which\ncan be systematically extracted and optimized, thereby advancing our\nunderstanding of model modularity and enhancing control over relational\nreasoning in LMMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u4e00\u5c0f\u90e8\u5206\u6ce8\u610f\u529b\u5934\u8d1f\u8d23\u4f20\u9012\u7a7a\u95f4\u5173\u7cfb\u8868\u5f81\uff0c\u8fd9\u4e9b\u6ce8\u610f\u529b\u5934\u7684\u6fc0\u6d3b\uff08\u79f0\u4e3a\u529f\u80fd\u5411\u91cf\uff09\u53ef\u4ee5\u88ab\u63d0\u53d6\u548c\u64cd\u4f5c\u6765\u6539\u53d8\u6a21\u578b\u5728\u5173\u7cfb\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5c55\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u60c5\u5883\u5b66\u4e60\u80fd\u529b\uff0c\u4f46\u5176\u652f\u6301\u4efb\u52a1\u5b66\u4e60\u7684\u5185\u5728\u673a\u5236\u4ecd\u7136\u4e0d\u900f\u660e\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u6a21\u578b\u5982\u4f55\u7f16\u7801\u548c\u5904\u7406\u7a7a\u95f4\u5173\u7cfb\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u8bc6\u522b\u5f71\u54cd\u5173\u7cfb\u9884\u6d4b\u7684\u6ce8\u610f\u529b\u5934\uff0c\u63d0\u53d6\u591a\u6a21\u6001\u529f\u80fd\u5411\u91cf\uff0c\u5e76\u5728\u4fdd\u6301\u6a21\u578b\u53c2\u6570\u51bb\u7ed3\u7684\u60c5\u51b5\u4e0b\u7528\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u5fae\u8c03\u8fd9\u4e9b\u529f\u80fd\u5411\u91cf\u3002", "result": "\u63d0\u53d6\u7684\u529f\u80fd\u5411\u91cf\u5728\u63a8\u7406\u65f6\u63d0\u9ad8\u4e86\u96f6\u6837\u672c\u51c6\u786e\u6027\uff0c\u7ecf\u8fc7\u5fae\u8c03\u540e\u663e\u8457\u4f18\u4e8e\u60c5\u5883\u5b66\u4e60\u57fa\u7ebf\uff0c\u5e76\u80fd\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u89e3\u51b3\u6d89\u53ca\u672a\u8bad\u7ec3\u7a7a\u95f4\u5173\u7cfb\u7684\u7c7b\u6bd4\u95ee\u9898\u3002", "conclusion": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u5c40\u90e8\u5185\u90e8\u7ed3\u6784\u4e2d\u7f16\u7801\u7a7a\u95f4\u5173\u7cfb\u77e5\u8bc6\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u53ef\u4ee5\u88ab\u7cfb\u7edf\u63d0\u53d6\u548c\u4f18\u5316\uff0c\u4ece\u800c\u589e\u8fdb\u5bf9\u6a21\u578b\u6a21\u5757\u5316\u7684\u7406\u89e3\u5e76\u589e\u5f3a\u5bf9\u5173\u7cfb\u63a8\u7406\u7684\u63a7\u5236\u3002"}}
{"id": "2510.02989", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02989", "abs": "https://arxiv.org/abs/2510.02989", "authors": ["Kaito Hori", "Chihiro Tsutake", "Keita Takahashi", "Toshiaki Fujii"], "title": "Transport of Event Equation: Phase Retrieval from Defocus Events", "comment": null, "summary": "To time-efficiently and stably acquire the intensity information for phase\nretrieval under a coherent illumination, we leverage an event-based vision\nsensor (EVS) that can detect changes in logarithmic intensity at the pixel\nlevel with a wide dynamic range. In our optical system, we translate the EVS\nalong the optical axis, where the EVS records the intensity changes induced by\ndefocus as events. To recover phase distributions, we formulate a partial\ndifferential equation, referred to as the transport of event equation, which\npresents a linear relationship between the defocus events and the phase\ndistribution. We demonstrate through experiments that the EVS is more\nadvantageous than the conventional image sensor for rapidly and stably\ndetecting the intensity information, defocus events, which enables accurate\nphase retrieval, particularly under low-lighting conditions.", "AI": {"tldr": "\u5229\u7528\u4e8b\u4ef6\u89c6\u89c9\u4f20\u611f\u5668(EVS)\u8fdb\u884c\u76f8\u4f4d\u6062\u590d\uff0c\u901a\u8fc7\u6cbf\u5149\u8f74\u79fb\u52a8EVS\u8bb0\u5f55\u79bb\u7126\u4e8b\u4ef6\uff0c\u5efa\u7acb\u4f20\u8f93\u4e8b\u4ef6\u65b9\u7a0b\u6765\u7ebf\u6027\u5173\u8054\u79bb\u7126\u4e8b\u4ef6\u4e0e\u76f8\u4f4d\u5206\u5e03\uff0c\u5b9e\u73b0\u5feb\u901f\u7a33\u5b9a\u7684\u76f8\u4f4d\u6062\u590d\u3002", "motivation": "\u4f20\u7edf\u76f8\u4f4d\u6062\u590d\u65b9\u6cd5\u5728\u65f6\u95f4\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u4f4e\u5149\u7167\u6761\u4ef6\u4e0b\u3002EVS\u80fd\u591f\u4ee5\u9ad8\u52a8\u6001\u8303\u56f4\u68c0\u6d4b\u50cf\u7d20\u7ea7\u5bf9\u6570\u5f3a\u5ea6\u53d8\u5316\uff0c\u4e3a\u5feb\u901f\u7a33\u5b9a\u7684\u76f8\u4f4d\u4fe1\u606f\u83b7\u53d6\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "method": "\u5c06EVS\u6cbf\u5149\u8f74\u5e73\u79fb\uff0c\u8bb0\u5f55\u7531\u79bb\u7126\u5f15\u8d77\u7684\u5f3a\u5ea6\u53d8\u5316\u4e8b\u4ef6\u3002\u5efa\u7acb\u4f20\u8f93\u4e8b\u4ef6\u65b9\u7a0b(TEE)\uff0c\u8be5\u504f\u5fae\u5206\u65b9\u7a0b\u5448\u73b0\u4e86\u79bb\u7126\u4e8b\u4ef6\u4e0e\u76f8\u4f4d\u5206\u5e03\u4e4b\u95f4\u7684\u7ebf\u6027\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEVS\u6bd4\u4f20\u7edf\u56fe\u50cf\u4f20\u611f\u5668\u5728\u5feb\u901f\u7a33\u5b9a\u68c0\u6d4b\u5f3a\u5ea6\u4fe1\u606f\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u4f4e\u5149\u7167\u6761\u4ef6\u4e0b\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u7684\u76f8\u4f4d\u6062\u590d\u3002", "conclusion": "\u57fa\u4e8eEVS\u7684\u76f8\u4f4d\u6062\u590d\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u79bb\u7126\u4e8b\u4ef6\u548c\u4f20\u8f93\u4e8b\u4ef6\u65b9\u7a0b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65f6\u95f4\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u76f8\u4f4d\u83b7\u53d6\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4e\u5149\u7167\u6761\u4ef6\u3002"}}
{"id": "2510.02557", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02557", "abs": "https://arxiv.org/abs/2510.02557", "authors": ["Charlie Masters", "Advaith Vellanki", "Jiangbo Shangguan", "Bart Kultys", "Jonathan Gilmore", "Alastair Moore", "Stefano V. Albrecht"], "title": "Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge", "comment": "Accepted as an oral paper for the conference for Distributed\n  Artificial Intelligence (DAI 2025). 8 pages, 2 figures", "summary": "While agentic AI has advanced in automating individual tasks, managing\ncomplex multi-agent workflows remains a challenging problem. This paper\npresents a research vision for autonomous agentic systems that orchestrate\ncollaboration within dynamic human-AI teams. We propose the Autonomous Manager\nAgent as a core challenge: an agent that decomposes complex goals into task\ngraphs, allocates tasks to human and AI workers, monitors progress, adapts to\nchanging conditions, and maintains transparent stakeholder communication. We\nformalize workflow management as a Partially Observable Stochastic Game and\nidentify four foundational challenges: (1) compositional reasoning for\nhierarchical decomposition, (2) multi-objective optimization under shifting\npreferences, (3) coordination and planning in ad hoc teams, and (4) governance\nand compliance by design. To advance this agenda, we release MA-Gym, an\nopen-source simulation and evaluation framework for multi-agent workflow\norchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we\nfind they struggle to jointly optimize for goal completion, constraint\nadherence, and workflow runtime - underscoring workflow management as a\ndifficult open problem. We conclude with organizational and ethical\nimplications of autonomous management systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u4e3b\u7ba1\u7406\u4ee3\u7406\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u534f\u8c03\u52a8\u6001\u4eba\u673a\u56e2\u961f\u4e2d\u7684\u590d\u6742\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u968f\u673a\u535a\u5f08\uff0c\u5e76\u8bc6\u522b\u4e86\u56db\u4e2a\u6838\u5fc3\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1\u667a\u80fd\u4f53AI\u5728\u81ea\u52a8\u5316\u5355\u4e2a\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7ba1\u7406\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u81ea\u4e3b\u7ba1\u7406\u4ee3\u7406\u4f5c\u4e3a\u6838\u5fc3\u6311\u6218\uff0c\u5f62\u5f0f\u5316\u5de5\u4f5c\u6d41\u7ba1\u7406\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u968f\u673a\u535a\u5f08\uff0c\u5e76\u5f00\u53d1\u4e86MA-Gym\u5f00\u6e90\u4eff\u771f\u6846\u67b6\u6765\u8bc4\u4f30\u57fa\u4e8eGPT-5\u7684\u7ba1\u7406\u4ee3\u7406\u3002", "result": "\u572820\u4e2a\u5de5\u4f5c\u6d41\u4e2d\u8bc4\u4f30GPT-5\u7ba1\u7406\u4ee3\u7406\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u540c\u65f6\u4f18\u5316\u76ee\u6807\u5b8c\u6210\u3001\u7ea6\u675f\u9075\u5b88\u548c\u5de5\u4f5c\u6d41\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u5de5\u4f5c\u6d41\u7ba1\u7406\u662f\u4e00\u4e2a\u56f0\u96be\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u81ea\u4e3b\u7ba1\u7406\u7cfb\u7edf\u5177\u6709\u7ec4\u7ec7\u548c\u4f26\u7406\u5f71\u54cd\u3002"}}
{"id": "2510.03057", "categories": ["cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.03057", "abs": "https://arxiv.org/abs/2510.03057", "authors": ["Anirudh Krishna", "Gilles Z\u00e9mor"], "title": "Tradeoffs on the volume of fault-tolerant circuits", "comment": "17 pages, 1 figure. Comments welcome", "summary": "Dating back to the seminal work of von Neumann [von Neumann, Automata\nStudies, 1956], it is known that error correcting codes can overcome faulty\ncircuit components to enable robust computation. Choosing an appropriate code\nis non-trivial as it must balance several requirements. Increasing the rate of\nthe code reduces the relative number of redundant bits used in the\nfault-tolerant circuit, while increasing the distance of the code ensures\nrobustness against faults. If the rate and distance were the only concerns, we\ncould use asymptotically optimal codes as is done in communication settings.\nHowever, choosing a code for computation is challenging due to an additional\nrequirement: The code needs to facilitate accessibility of encoded information\nto enable computation on encoded data. This seems to conflict with having large\nrate and distance. We prove that this is indeed the case, namely that a code\nfamily cannot simultaneously have constant rate, growing distance and\nshort-depth gadgets to perform encoded CNOT gates. As a consequence, achieving\ngood rate and distance may necessarily entail accepting very deep circuits, an\nundesirable trade-off in certain architectures and applications.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u7ea0\u9519\u7801\u65e0\u6cd5\u540c\u65f6\u5177\u5907\u6052\u5b9a\u7801\u7387\u3001\u589e\u957f\u8ddd\u79bb\u548c\u77ed\u6df1\u5ea6CNOT\u95e8\u5b9e\u73b0\uff0c\u8fd9\u8868\u660e\u5728\u8ba1\u7b97\u5e94\u7528\u4e2d\u9700\u8981\u6743\u8861\u7801\u7387\u3001\u8ddd\u79bb\u548c\u7535\u8def\u6df1\u5ea6\u3002", "motivation": "\u9009\u62e9\u9002\u5408\u8ba1\u7b97\u7684\u7ea0\u9519\u7801\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u9700\u8981\u5728\u7801\u7387\u3001\u8ddd\u79bb\u548c\u7f16\u7801\u4fe1\u606f\u53ef\u8bbf\u95ee\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u800c\u540e\u8005\u5bf9\u4e8e\u5728\u7f16\u7801\u6570\u636e\u4e0a\u6267\u884c\u8ba1\u7b97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u5206\u6790\u7ea0\u9519\u7801\u5728\u8ba1\u7b97\u5e94\u7528\u4e2d\u7684\u57fa\u672c\u9650\u5236\uff0c\u7279\u522b\u662f\u7814\u7a76\u7801\u7387\u3001\u8ddd\u79bb\u4e0e\u5b9e\u73b0CNOT\u95e8\u6240\u9700\u7684\u7535\u8def\u6df1\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4efb\u4f55\u7801\u65cf\u90fd\u4e0d\u80fd\u540c\u65f6\u5177\u6709\u6052\u5b9a\u7801\u7387\u3001\u589e\u957f\u8ddd\u79bb\u548c\u77ed\u6df1\u5ea6CNOT\u95e8\u5b9e\u73b0\uff0c\u8fd9\u610f\u5473\u7740\u826f\u597d\u7684\u7801\u7387\u548c\u8ddd\u79bb\u53ef\u80fd\u9700\u8981\u63a5\u53d7\u5f88\u6df1\u7684\u7535\u8def\u3002", "conclusion": "\u5728\u8ba1\u7b97\u5e94\u7528\u4e2d\u5b9e\u73b0\u826f\u597d\u7684\u7801\u7387\u548c\u8ddd\u79bb\u53ef\u80fd\u9700\u8981\u4ee5\u7535\u8def\u6df1\u5ea6\u4e3a\u4ee3\u4ef7\uff0c\u8fd9\u79cd\u6743\u8861\u5728\u67d0\u4e9b\u67b6\u6784\u548c\u5e94\u7528\u4e2d\u662f\u4e0d\u7406\u60f3\u7684\u3002"}}
{"id": "2510.02567", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02567", "abs": "https://arxiv.org/abs/2510.02567", "authors": ["Peter Pak", "Achuth Chandrasekhar", "Amir Barati Farimani"], "title": "Agentic Additive Manufacturing Alloy Discovery", "comment": null, "summary": "Agentic systems enable the intelligent use of research tooling, augmenting a\nresearcher's ability to investigate and propose novel solutions to existing\nproblems. Within Additive Manufacturing (AM), alloy discovery remains a complex\nchallenge, often requiring expertise in the various domains of materials\nscience, thermodynamic simulations, and experimental analysis. Large Language\nModel (LLM) enabled agents can facilitate this endeavor by utilizing their\nextensive knowledge base to dispatch tool calls via Model Context Protocol\n(MCP) to perform actions such as Thermo-Calc property diagram calculations and\nlack of fusion process map generation. In addition, the multi-agent system\ndeveloped in this work is able to effectively reason through complex user\nprompts and provide analysis on the printability of proposed alloys. These\nagents can dynamically adjust their task trajectory to the outcomes of tool\ncall results, effectively enabling autonomous decision-making in practical\nenvironments. This work aims to utilize LLM enabled agents to automate and\naccelerate the task of alloy discovery within the field of additive\nmanufacturing and showcase the benefits of adopting this multi-agent system.", "AI": {"tldr": "\u5229\u7528LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7MCP\u534f\u8bae\u8c03\u7528\u70ed\u529b\u5b66\u8ba1\u7b97\u5de5\u5177\uff0c\u81ea\u52a8\u5316\u52a0\u901f\u589e\u6750\u5236\u9020\u9886\u57df\u7684\u5408\u91d1\u53d1\u73b0\u8fc7\u7a0b\u3002", "motivation": "\u589e\u6750\u5236\u9020\u4e2d\u7684\u5408\u91d1\u53d1\u73b0\u662f\u4e00\u4e2a\u590d\u6742\u6311\u6218\uff0c\u9700\u8981\u6750\u6599\u79d1\u5b66\u3001\u70ed\u529b\u5b66\u6a21\u62df\u548c\u5b9e\u9a8c\u5206\u6790\u7b49\u591a\u4e2a\u9886\u57df\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u52a0\u901f\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u8c03\u7528Thermo-Calc\u5c5e\u6027\u56fe\u8ba1\u7b97\u548c\u7194\u5408\u7f3a\u9677\u8fc7\u7a0b\u56fe\u751f\u6210\u7b49\u5de5\u5177\uff0c\u80fd\u591f\u6839\u636e\u5de5\u5177\u8c03\u7528\u7ed3\u679c\u52a8\u6001\u8c03\u6574\u4efb\u52a1\u8f68\u8ff9\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63a8\u7406\u590d\u6742\u7528\u6237\u63d0\u793a\uff0c\u5bf9\u63d0\u51fa\u7684\u5408\u91d1\u53ef\u6253\u5370\u6027\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u51b3\u7b56\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5316\u5e76\u52a0\u901f\u589e\u6750\u5236\u9020\u9886\u57df\u7684\u5408\u91d1\u53d1\u73b0\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u91c7\u7528\u8fd9\u79cd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.03184", "categories": ["cs.IT", "math.IT", "E.4; F.2.2"], "pdf": "https://arxiv.org/pdf/2510.03184", "abs": "https://arxiv.org/abs/2510.03184", "authors": ["Elena Grigorescu", "Alice Moayyedi"], "title": "On the Hardness of the One-Sided Code Sparsifier Problem", "comment": "9 pages, LaTeX", "summary": "The notion of code sparsification was introduced by Khanna, Putterman and\nSudan (arxiv.2311.00788), as an analogue to the the more established notion of\ncut sparsification in graphs and hypergraphs. In particular, for $\\alpha\\in\n(0,1)$ an (unweighted) one-sided $\\alpha$-sparsifier for a linear code\n$\\mathcal{C} \\subseteq \\mathbb{F}_2^n$ is a subset $S\\subseteq [n]$ such that\nthe weight of each codeword projected onto the coordinates in $S$ is preserved\nup to an $\\alpha$ fraction. Recently, Gharan and Sahami (arxiv.2502.02799) show\nthe existence of one-sided 1/2-sparsifiers of size $n/2+O(\\sqrt{kn})$ for any\nlinear code, where $k$ is the dimension of $\\mathcal{C}$. In this paper, we\nconsider the computational problem of finding a one-sided 1/2-sparsifier of\nminimal size, and show that it is NP-hard, via a reduction from the classical\nnearest codeword problem. We also show hardness of approximation results.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5bfb\u627e\u6700\u5c0f\u5c3a\u5bf8\u7684\u5355\u8fb91/2\u7a00\u758f\u5316\u5668\u662fNP\u96be\u95ee\u9898\uff0c\u5e76\u7ed9\u51fa\u4e86\u8fd1\u4f3c\u96be\u5ea6\u7ed3\u679c\u3002", "motivation": "\u4ee3\u7801\u7a00\u758f\u5316\u662f\u56fe\u8bba\u4e2d\u5272\u7a00\u758f\u5316\u6982\u5ff5\u7684\u7c7b\u6bd4\uff0c\u6700\u8fd1Gharan\u548cSahami\u8bc1\u660e\u4e86\u5355\u8fb91/2\u7a00\u758f\u5316\u5668\u7684\u5b58\u5728\u6027\uff0c\u4f46\u8ba1\u7b97\u6700\u5c0f\u5c3a\u5bf8\u7a00\u758f\u5316\u5668\u7684\u590d\u6742\u6027\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u4ece\u7ecf\u5178\u7684\u6700\u8fd1\u7801\u5b57\u95ee\u9898\u5f52\u7ea6\uff0c\u8bc1\u660e\u6700\u5c0f\u5355\u8fb91/2\u7a00\u758f\u5316\u5668\u95ee\u9898\u7684NP\u96be\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5bfb\u627e\u6700\u5c0f\u5c3a\u5bf8\u7684\u5355\u8fb91/2\u7a00\u758f\u5316\u5668\u662fNP\u96be\u95ee\u9898\uff0c\u5e76\u7ed9\u51fa\u4e86\u8fd1\u4f3c\u96be\u5ea6\u7ed3\u679c\u3002", "conclusion": "\u4ee3\u7801\u7a00\u758f\u5316\u7684\u8ba1\u7b97\u95ee\u9898\u5177\u6709\u5185\u5728\u7684\u590d\u6742\u6027\uff0c\u6700\u5c0f\u7a00\u758f\u5316\u5668\u7684\u5bfb\u627e\u662f\u8ba1\u7b97\u56f0\u96be\u7684\u95ee\u9898\u3002"}}
{"id": "2510.02589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02589", "abs": "https://arxiv.org/abs/2510.02589", "authors": ["Yunqi Huang", "Nishith Chennakeshava", "Alexis Carras", "Vladislav Neverov", "Wei Liu", "Aske Plaat", "Yingjie Fan"], "title": "A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem", "comment": null, "summary": "Container stowage planning (CSPP) is a critical component of maritime\ntransportation and terminal operations, directly affecting supply chain\nefficiency. Owing to its complexity, CSPP has traditionally relied on human\nexpertise. While reinforcement learning (RL) has recently been applied to CSPP,\nsystematic benchmark comparisons across different algorithms remain limited. To\naddress this gap, we develop a Gym environment that captures the fundamental\nfeatures of CSPP and extend it to include crane scheduling in both multi-agent\nand single-agent formulations. Within this framework, we evaluate five RL\nalgorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying\ncomplexity. The results reveal distinct performance gaps with increasing\ncomplexity, underscoring the importance of algorithm choice and problem\nformulation for CSPP. Overall, this paper benchmarks multiple RL methods for\nCSPP while providing a reusable Gym environment with crane scheduling, thus\noffering a foundation for future research and practical deployment in maritime\nlogistics.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u8d77\u91cd\u673a\u8c03\u5ea6\u7684CSPP Gym\u73af\u5883\uff0c\u8bc4\u4f30\u4e865\u79cdRL\u7b97\u6cd5\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u7b97\u6cd5\u9009\u62e9\u548c\u95ee\u9898\u8868\u8ff0\u5bf9CSPP\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u96c6\u88c5\u7bb1\u914d\u8f7d\u89c4\u5212\u5728\u6d77\u4e0a\u8fd0\u8f93\u548c\u7801\u5934\u8fd0\u8425\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u4e0d\u540cRL\u7b97\u6cd5\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u6bd4\u8f83\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6355\u6349CSPP\u57fa\u672c\u7279\u5f81\u7684Gym\u73af\u5883\uff0c\u6269\u5c55\u5230\u5305\u542b\u8d77\u91cd\u673a\u8c03\u5ea6\uff08\u591a\u667a\u80fd\u4f53\u548c\u5355\u667a\u80fd\u4f53\uff09\uff0c\u8bc4\u4f30\u4e86DQN\u3001QR-DQN\u3001A2C\u3001PPO\u548cTRPO\u4e94\u79cdRL\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u968f\u7740\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u6027\u80fd\u5dee\u8ddd\u660e\u663e\uff0c\u5f3a\u8c03\u4e86\u7b97\u6cd5\u9009\u62e9\u548c\u95ee\u9898\u8868\u8ff0\u5bf9CSPP\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u6587\u4e3aCSPP\u63d0\u4f9b\u4e86\u591a\u4e2aRL\u65b9\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u7528\u7684\u5305\u542b\u8d77\u91cd\u673a\u8c03\u5ea6\u7684Gym\u73af\u5883\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u6d77\u4e8b\u7269\u6d41\u5b9e\u9645\u90e8\u7f72\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02592", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02592", "abs": "https://arxiv.org/abs/2510.02592", "authors": ["Jean Douglas Carvalho", "Hugo Kenji", "Ahmad Mohammad Saber", "Glaucia Melo", "Max Mauro Dias Santos", "Deepa Kundur"], "title": "Multimodal Large Language Model Framework for Safe and Interpretable Grid-Integrated EVs", "comment": "This paper has been presented at the 2025 IEEE PES Conference on\n  Innovative Smart Grid Technologies (ISGT 2025)", "summary": "The integration of electric vehicles (EVs) into smart grids presents unique\nopportunities to enhance both transportation systems and energy networks.\nHowever, ensuring safe and interpretable interactions between drivers,\nvehicles, and the surrounding environment remains a critical challenge. This\npaper presents a multi-modal large language model (LLM)-based framework to\nprocess multimodal sensor data - such as object detection, semantic\nsegmentation, and vehicular telemetry - and generate natural-language alerts\nfor drivers. The framework is validated using real-world data collected from\ninstrumented vehicles driving on urban roads, ensuring its applicability to\nreal-world scenarios. By combining visual perception (YOLOv8), geocoded\npositioning, and CAN bus telemetry, the framework bridges raw sensor data and\ndriver comprehension, enabling safer and more informed decision-making in urban\ndriving scenarios. Case studies using real data demonstrate the framework's\neffectiveness in generating context-aware alerts for critical situations, such\nas proximity to pedestrians, cyclists, and other vehicles. This paper\nhighlights the potential of LLMs as assistive tools in e-mobility, benefiting\nboth transportation systems and electric networks by enabling scalable fleet\ncoordination, EV load forecasting, and traffic-aware energy planning.\n  Index Terms - Electric vehicles, visual perception, large language models,\nYOLOv8, semantic segmentation, CAN bus, prompt engineering, smart grid.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u5904\u7406\u89c6\u89c9\u611f\u77e5\u3001\u5b9a\u4f4d\u548c\u8f66\u8f86\u6570\u636e\uff0c\u4e3a\u9a7e\u9a76\u5458\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8b66\u62a5\uff0c\u63d0\u5347\u7535\u52a8\u6c7d\u8f66\u5728\u667a\u80fd\u7535\u7f51\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u4e0e\u667a\u80fd\u7535\u7f51\u878d\u5408\u65f6\uff0c\u786e\u4fdd\u9a7e\u9a76\u5458\u3001\u8f66\u8f86\u4e0e\u73af\u5883\u4e4b\u95f4\u5b89\u5168\u53ef\u89e3\u91ca\u7684\u4ea4\u4e92\u4ecd\u662f\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u5c06\u539f\u59cb\u4f20\u611f\u5668\u6570\u636e\u8f6c\u5316\u4e3a\u9a7e\u9a76\u5458\u53ef\u7406\u89e3\u7684\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5bf9\u8c61\u68c0\u6d4b\u3001\u8bed\u4e49\u5206\u5272\u548c\u8f66\u8f86\u9065\u6d4b\u7b49\u591a\u6e90\u4f20\u611f\u5668\u6570\u636e\uff0c\u7ed3\u5408YOLOv8\u89c6\u89c9\u611f\u77e5\u3001\u5730\u7406\u7f16\u7801\u5b9a\u4f4d\u548cCAN\u603b\u7ebf\u6570\u636e\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8b66\u62a5\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u751f\u6210\u9488\u5bf9\u5173\u952e\u60c5\u5883\uff08\u5982\u63a5\u8fd1\u884c\u4eba\u3001\u81ea\u884c\u8f66\u548c\u5176\u4ed6\u8f66\u8f86\uff09\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u8b66\u62a5\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4f5c\u4e3a\u7535\u52a8\u51fa\u884c\u7684\u8f85\u52a9\u5de5\u5177\uff0c\u901a\u8fc7\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u8f66\u961f\u534f\u8c03\u3001\u7535\u52a8\u6c7d\u8f66\u8d1f\u8f7d\u9884\u6d4b\u548c\u4ea4\u901a\u611f\u77e5\u80fd\u6e90\u89c4\u5212\uff0c\u540c\u65f6\u60e0\u53ca\u4ea4\u901a\u7cfb\u7edf\u548c\u7535\u7f51\u3002"}}
{"id": "2510.02608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02608", "abs": "https://arxiv.org/abs/2510.02608", "authors": ["Chen Henry Wu", "Neil Kale", "Aditi Raghunathan"], "title": "Mitigating Modal Imbalance in Multimodal Reasoning", "comment": "10 pages, 10 figures, CoLM 2025", "summary": "Foundation models (FMs) deployed in real-world tasks such as computer-use\nagents must integrate diverse modalities. How good are FMs at performing joint\nreasoning, simultaneously reasoning over multiple modalities, especially when\nthe modalities interact and relate to each other to form cross-modal context?\nTo better understand this problem, we study FMs on cross-modal conflicts:\nscenarios where conflicting evidence is presented across modalities. This\nallows us to examine whether FMs prioritize one modality over another or reason\njointly to reconcile the conflict. Our experiments reveal that FMs can\nrecognize conflicts in unimodal contexts, composed of a single modality, 90% of\nthe time, but the ratio falls as low as 3% when evidence is split across\nmodalities -- similar observations hold in cross-lingual contexts, composed of\nmultiple languages. We trace this failure to cross-modal attention imbalance,\nshowing that FMs exhibit extreme asymmetry in attention scores,\ndisproportionately prioritizing certain modalities. We show that cross-modal\nattention imbalance does not go away by simply scaling up multimodal or\nmultilingual datasets blindly, since they lack training examples that\nexplicitly require cross-modal reasoning. We demonstrate that even a simple and\nscalable method of explicitly combining multiple modalities within each\ntraining instance significantly reduces attention imbalance. Reduced attention\nimbalance directly translates to improved downstream performance on several\nvision-language benchmarks. Our findings underscore the importance of\nsystematically addressing cross-modal contexts to build reliable foundation\nmodels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u7840\u6a21\u578b\u5728\u591a\u6a21\u6001\u8054\u5408\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u8de8\u6a21\u6001\u51b2\u7a81\u573a\u666f\u4e0b\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u5355\u6a21\u6001\u4e2d\u80fd\u8bc6\u522b90%\u7684\u51b2\u7a81\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u60c5\u51b5\u4e0b\u8bc6\u522b\u7387\u964d\u81f33%\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\u3002", "motivation": "\u7814\u7a76\u57fa\u7840\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u8054\u5408\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5f53\u4e0d\u540c\u6a21\u6001\u4e4b\u95f4\u5b58\u5728\u51b2\u7a81\u8bc1\u636e\u65f6\uff0c\u6a21\u578b\u662f\u5426\u80fd\u8fdb\u884c\u8de8\u6a21\u6001\u63a8\u7406\u6765\u8c03\u548c\u51b2\u7a81\u3002", "method": "\u901a\u8fc7\u8de8\u6a21\u6001\u51b2\u7a81\u5b9e\u9a8c\u6765\u6d4b\u8bd5\u6a21\u578b\u8868\u73b0\uff0c\u5206\u6790\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff1a\u5728\u8bad\u7ec3\u5b9e\u4f8b\u4e2d\u663e\u5f0f\u7ec4\u5408\u591a\u4e2a\u6a21\u6001\u3002", "result": "\u6a21\u578b\u5728\u5355\u6a21\u6001\u51b2\u7a81\u4e2d\u8bc6\u522b\u7387\u8fbe90%\uff0c\u4f46\u8de8\u6a21\u6001\u51b2\u7a81\u8bc6\u522b\u7387\u964d\u81f33%\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\uff0c\u5e76\u5728\u591a\u4e2a\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u9700\u8981\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u8de8\u6a21\u6001\u4e0a\u4e0b\u6587\u95ee\u9898\uff0c\u4ee5\u6784\u5efa\u53ef\u9760\u7684\u57fa\u7840\u6a21\u578b\u3002\u76f2\u76ee\u6269\u5c55\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0d\u8db3\u4ee5\u89e3\u51b3\u8de8\u6a21\u6001\u63a8\u7406\u95ee\u9898\uff0c\u9700\u8981\u663e\u5f0f\u7684\u8de8\u6a21\u6001\u8bad\u7ec3\u7b56\u7565\u3002"}}
{"id": "2510.02611", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02611", "abs": "https://arxiv.org/abs/2510.02611", "authors": ["Yuheng Wu", "Azalia Mirhoseini", "Thierry Tambe"], "title": "On the Role of Temperature Sampling in Test-Time Scaling", "comment": null, "summary": "Large language models (LLMs) can improve reasoning at inference time through\ntest-time scaling (TTS), where multiple reasoning traces are generated and the\nbest one is selected. Prior work shows that increasing the number of samples K\nsteadily improves accuracy. In this paper, we demonstrate that this trend does\nnot hold indefinitely: at large K, further scaling yields no gains, and certain\nhard questions remain unsolved regardless of the number of traces.\nInterestingly, we find that different sampling temperatures solve different\nsubsets of problems, implying that single-temperature scaling explores only\npart of a model's potential. We therefore propose scaling along the temperature\ndimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3\n(0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME\n2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an\nadditional 7.3 points over single-temperature TTS. Temperature scaling also\nenables base models to reach performance comparable to reinforcement learning\n(RL)-trained counterparts, without additional post-training. We further provide\na comprehensive analysis of this phenomenon and design a multi-temperature\nvoting method that reduces the overhead of temperature scaling. Overall, our\nfindings suggest that TTS is more powerful than previously thought, and that\ntemperature scaling offers a simple and effective way to unlock the latent\npotential of base models.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u6d4b\u8bd5\u65f6\u7f29\u653e(TTS)\u4e2d\u5355\u7eaf\u589e\u52a0\u6837\u672c\u6570\u91cfK\u7684\u6536\u76ca\u6709\u9650\uff0c\u63d0\u51fa\u6e29\u5ea6\u7ef4\u5ea6\u7f29\u653e\u80fd\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u57fa\u7840\u6a21\u578b\u8fbe\u5230\u63a5\u8fd1RL\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u589e\u52a0\u63a8\u7406\u8f68\u8ff9\u6837\u672c\u6570\u91cfK\u80fd\u6301\u7eed\u63d0\u5347\u51c6\u786e\u7387\uff0c\u4f46\u672c\u6587\u53d1\u73b0\u8fd9\u79cd\u8d8b\u52bf\u5e76\u975e\u65e0\u9650\u6301\u7eed\uff0c\u4e14\u5355\u4e00\u6e29\u5ea6\u91c7\u6837\u53ea\u80fd\u63a2\u7d22\u6a21\u578b\u6f5c\u529b\u7684\u90e8\u5206\u5b50\u96c6\u3002", "method": "\u63d0\u51fa\u6e29\u5ea6\u7ef4\u5ea6\u7f29\u653e\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u91c7\u6837\u6e29\u5ea6\u4e0b\u751f\u6210\u63a8\u7406\u8f68\u8ff9\uff0c\u5e76\u8bbe\u8ba1\u591a\u6e29\u5ea6\u6295\u7968\u673a\u5236\u6765\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6e29\u5ea6\u7f29\u653e\u6bd4\u5355\u4e00\u6e29\u5ea6TTS\u989d\u5916\u63d0\u53477.3\u4e2a\u767e\u5206\u70b9\uff0c\u4f7f\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63a5\u8fd1RL\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "TTS\u7684\u6f5c\u529b\u6bd4\u4e4b\u524d\u8ba4\u4e3a\u7684\u66f4\u5927\uff0c\u6e29\u5ea6\u7f29\u653e\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u91ca\u653e\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u5728\u80fd\u529b\u3002"}}
{"id": "2510.02653", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02653", "abs": "https://arxiv.org/abs/2510.02653", "authors": ["Micaela Fuel Pozo", "Andrea Guatumillo Saltos", "Yese\u00f1a Tipan Llumiquinga", "Kelly Lascano Aguirre", "Marilyn Castillo Jara", "Christian Mejia-Escobar"], "title": "Geolog-IA: Conversational System for Academic Theses", "comment": "17 pages, in Spanish language", "summary": "This study presents the development of Geolog-IA, a novel conversational\nsystem based on artificial intelligence that responds naturally to questions\nabout geology theses from the Central University of Ecuador. Our proposal uses\nthe Llama 3.1 and Gemini 2.5 language models, which are complemented by a\nRetrieval Augmented Generation (RAG) architecture and an SQLite database. This\nstrategy allows us to overcome problems such as hallucinations and outdated\nknowledge. The evaluation of Geolog-IA's performance with the BLEU metric\nreaches an average of 0.87, indicating high consistency and accuracy in the\nresponses generated. The system offers an intuitive, web-based interface that\nfacilitates interaction and information retrieval for directors, teachers,\nstudents, and administrative staff at the institution. This tool can be a key\nsupport in education, training, and research and establishes a basis for future\napplications in other disciplines.", "AI": {"tldr": "\u5f00\u53d1\u4e86Geolog-IA\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u4f7f\u7528Llama 3.1\u548cGemini 2.5\u8bed\u8a00\u6a21\u578b\u7ed3\u5408RAG\u67b6\u6784\u548cSQLite\u6570\u636e\u5e93\uff0c\u4e3a\u5384\u74dc\u591a\u5c14\u4e2d\u592e\u5927\u5b66\u5730\u8d28\u5b66\u8bba\u6587\u63d0\u4f9b\u81ea\u7136\u95ee\u7b54\u670d\u52a1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfAI\u7cfb\u7edf\u5728\u56de\u7b54\u5730\u8d28\u5b66\u8bba\u6587\u95ee\u9898\u65f6\u51fa\u73b0\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u77e5\u8bc6\u8fc7\u65f6\u95ee\u9898\uff0c\u4e3a\u5927\u5b66\u5e08\u751f\u548c\u7ba1\u7406\u4eba\u5458\u63d0\u4f9b\u51c6\u786e\u7684\u4fe1\u606f\u68c0\u7d22\u5de5\u5177\u3002", "method": "\u91c7\u7528Llama 3.1\u548cGemini 2.5\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u67b6\u6784\u548cSQLite\u6570\u636e\u5e93\uff0c\u6784\u5efa\u57fa\u4e8eWeb\u7684\u5bf9\u8bdd\u7cfb\u7edf\u3002", "result": "\u4f7f\u7528BLEU\u6307\u6807\u8bc4\u4f30\uff0c\u7cfb\u7edf\u6027\u80fd\u5e73\u5747\u8fbe\u52300.87\uff0c\u8868\u660e\u751f\u6210\u56de\u7b54\u5177\u6709\u9ad8\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u6559\u80b2\u3001\u57f9\u8bad\u548c\u7814\u7a76\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u5e76\u4e3a\u5176\u4ed6\u5b66\u79d1\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02655", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02655", "abs": "https://arxiv.org/abs/2510.02655", "authors": ["Daniel G. Schwartz"], "title": "A Concept of Possibility for Real-World Events", "comment": null, "summary": "This paper offers a new concept of {\\it possibility} as an alternative to the\nnow-a-days standard concept originally introduced by L.A. Zadeh in 1978. This\nnew version was inspired by the original but, formally, has nothing in common\nwith it other than that they both adopt the {\\L}ukasiewicz multivalent\ninterpretation of the logical connectives. Moreover, rather than seeking to\nprovide a general notion of possibility, this focuses specifically on the\npossibility of a real-world event. An event is viewed as having prerequisites\nthat enable its occurrence and constraints that may impede its occurrence, and\nthe possibility of the event is computed as a function of the probabilities\nthat the prerequisites hold and the constraints do not. This version of\npossibility might appropriately be applied to problems of planning. When there\nare multiple plans available for achieving a goal, this theory can be used to\ndetermine which plan is most possible, i.e., easiest or most feasible to\ncomplete. It is speculated that this model of reasoning correctly captures\nnormal human reasoning about plans. The theory is elaborated and an\nillustrative example for vehicle route planning is provided. There is also a\nsuggestion of potential future applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u80fd\u6027\u6982\u5ff5\u4f5c\u4e3aZadeh(1978)\u6807\u51c6\u6982\u5ff5\u7684\u66ff\u4ee3\uff0c\u4e13\u6ce8\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u7684\u53ef\u80fd\u6027\u8ba1\u7b97\uff0c\u57fa\u4e8e\u4e8b\u4ef6\u7684\u5148\u51b3\u6761\u4ef6\u548c\u7ea6\u675f\u7684\u6982\u7387\u51fd\u6570\u3002", "motivation": "\u4e3a\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u66f4\u9002\u7528\u7684\u53ef\u80fd\u6027\u7406\u8bba\uff0c\u7279\u522b\u662f\u7528\u4e8e\u8bc4\u4f30\u591a\u4e2a\u8ba1\u5212\u4e2d\u54ea\u4e2a\u6700\u5bb9\u6613\u6216\u6700\u53ef\u884c\u5b8c\u6210\u3002", "method": "\u5c06\u4e8b\u4ef6\u89c6\u4e3a\u5177\u6709\u4fc3\u4f7f\u5176\u53d1\u751f\u7684\u5148\u51b3\u6761\u4ef6\u548c\u963b\u788d\u5176\u53d1\u751f\u7684\u7ea6\u675f\uff0c\u53ef\u80fd\u6027\u8ba1\u7b97\u4e3a\u5148\u51b3\u6761\u4ef6\u6210\u7acb\u4e14\u7ea6\u675f\u4e0d\u6210\u7acb\u7684\u6982\u7387\u51fd\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u0141ukasiewicz\u591a\u503c\u903b\u8f91\u8fde\u63a5\u8bcd\u7684\u65b0\u53ef\u80fd\u6027\u7406\u8bba\uff0c\u63d0\u4f9b\u4e86\u8f66\u8f86\u8def\u7ebf\u89c4\u5212\u7684\u793a\u4f8b\u8bf4\u660e\u3002", "conclusion": "\u8be5\u53ef\u80fd\u6027\u6a21\u578b\u53ef\u80fd\u6b63\u786e\u6355\u6349\u4e86\u4eba\u7c7b\u5173\u4e8e\u8ba1\u5212\u7684\u6b63\u5e38\u63a8\u7406\uff0c\u5e76\u5177\u6709\u672a\u6765\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.02669", "categories": ["cs.AI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02669", "abs": "https://arxiv.org/abs/2510.02669", "authors": ["Bo Ma", "Hang Li", "ZeHua Hu", "XiaoFan Gui", "LuYao Liu", "Simon Liu"], "title": "AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models", "comment": null, "summary": "Multi-agent systems powered by large language models have demonstrated\nremarkable capabilities across diverse domains, yet existing automated design\napproaches seek monolithic solutions that fail to adapt resource allocation\nbased on query complexity and domain requirements. This paper introduces\nAutoMaAS, a self-evolving multi-agent architecture search framework that\nleverages neural architecture search principles to automatically discover\noptimal agent configurations through dynamic operator lifecycle management and\nautomated machine learning techniques. Our approach incorporates four key\ninnovations: (1) automatic operator generation, fusion, and elimination based\non performance-cost analysis, (2) dynamic cost-aware optimization with\nreal-time parameter adjustment, (3) online feedback integration for continuous\narchitecture refinement, and (4) enhanced interpretability through decision\ntracing mechanisms. Extensive experiments across six benchmarks demonstrate\nthat AutoMaAS achieves 1.0-7.1\\% performance improvement while reducing\ninference costs by 3-5\\% compared to state-of-the-art methods. The framework\nshows superior transferability across datasets and LLM backbones, establishing\na new paradigm for automated multi-agent system design in the era of large\nlanguage models.", "AI": {"tldr": "AutoMaAS\u662f\u4e00\u4e2a\u81ea\u8fdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u539f\u7406\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u667a\u80fd\u4f53\u914d\u7f6e\uff0c\u5728\u6027\u80fd\u63d0\u53471.0-7.1%\u7684\u540c\u65f6\u964d\u4f4e\u63a8\u7406\u6210\u672c3-5%\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u8bbe\u8ba1\u65b9\u6cd5\u5bfb\u6c42\u5355\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u6cd5\u6839\u636e\u67e5\u8be2\u590d\u6742\u5ea6\u548c\u9886\u57df\u9700\u6c42\u81ea\u9002\u5e94\u5206\u914d\u8d44\u6e90\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u539f\u5219\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u81ea\u52a8\u7b97\u5b50\u751f\u6210\u3001\u878d\u5408\u548c\u6d88\u9664\uff1b\u52a8\u6001\u6210\u672c\u611f\u77e5\u4f18\u5316\uff1b\u5728\u7ebf\u53cd\u9988\u96c6\u6210\uff1b\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u51b3\u7b56\u8ffd\u8e2a\u673a\u5236\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u53471.0-7.1%\uff0c\u63a8\u7406\u6210\u672c\u964d\u4f4e3-5%\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548cLLM\u9aa8\u5e72\u7f51\u7edc\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u8fc1\u79fb\u6027\u3002", "conclusion": "AutoMaAS\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u7684\u81ea\u52a8\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u8fc1\u79fb\u6027\u3002"}}
{"id": "2510.02677", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02677", "abs": "https://arxiv.org/abs/2510.02677", "authors": ["Zhaorun Chen", "Xun Liu", "Mintong Kang", "Jiawei Zhang", "Minzhou Pan", "Shuang Yang", "Bo Li"], "title": "ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks", "comment": "60 pages, 16 figures", "summary": "As vision-language models (VLMs) gain prominence, their multimodal interfaces\nalso introduce new safety vulnerabilities, making the safety evaluation\nchallenging and critical. Existing red-teaming efforts are either restricted to\na narrow set of adversarial patterns or depend heavily on manual engineering,\nlacking scalable exploration of emerging real-world VLM vulnerabilities. To\nbridge this gap, we propose ARMs, an adaptive red-teaming agent that\nsystematically conducts comprehensive risk assessments for VLMs. Given a target\nharmful behavior or risk definition, ARMs automatically optimizes diverse\nred-teaming strategies with reasoning-enhanced multi-step orchestration, to\neffectively elicit harmful outputs from target VLMs. We propose 11 novel\nmultimodal attack strategies, covering diverse adversarial patterns of VLMs\n(e.g., reasoning hijacking, contextual cloaking), and integrate 17 red-teaming\nalgorithms into ARMs via model context protocol (MCP). To balance the diversity\nand effectiveness of the attack, we design a layered memory with an\nepsilon-greedy attack exploration algorithm. Extensive experiments on instance-\nand policy-based benchmarks show that ARMs achieves SOTA attack success rates,\nexceeding baselines by an average of 52.1% and surpassing 90% on\nClaude-4-Sonnet. We show that the diversity of red-teaming instances generated\nby ARMs is significantly higher, revealing emerging vulnerabilities in VLMs.\nLeveraging ARMs, we construct ARMs-Bench, a large-scale multimodal safety\ndataset comprising over 30K red-teaming instances spanning 51 diverse risk\ncategories, grounded in both real-world multimodal threats and regulatory\nrisks. Safety fine-tuning with ARMs-Bench substantially improves the robustness\nof VLMs while preserving their general utility, providing actionable guidance\nto improve multimodal safety alignment against emerging threats.", "AI": {"tldr": "ARMs\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u7ea2\u961f\u4ee3\u7406\uff0c\u901a\u8fc7\u63a8\u7406\u589e\u5f3a\u7684\u591a\u6b65\u9aa4\u7f16\u6392\u81ea\u52a8\u4f18\u5316\u591a\u6837\u5316\u7ea2\u961f\u7b56\u7565\uff0c\u6709\u6548\u5f15\u53d1\u76ee\u6807VLM\u7684\u6709\u5bb3\u8f93\u51fa\u3002\u5b83\u6574\u5408\u4e8617\u79cd\u7ea2\u961f\u7b97\u6cd5\u548c11\u79cd\u65b0\u578b\u591a\u6a21\u6001\u653b\u51fb\u7b56\u7565\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc7\u57fa\u7ebf52.1%\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b30K+\u7ea2\u961f\u5b9e\u4f8b\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u5b89\u5168\u6570\u636e\u96c6ARMs-Bench\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u7684\u666e\u53ca\uff0c\u5176\u591a\u6a21\u6001\u63a5\u53e3\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\u8981\u4e48\u5c40\u9650\u4e8e\u6709\u9650\u7684\u5bf9\u6297\u6a21\u5f0f\uff0c\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u5de5\u7a0b\uff0c\u7f3a\u4e4f\u5bf9\u65b0\u5174\u771f\u5b9e\u4e16\u754cVLM\u6f0f\u6d1e\u7684\u53ef\u6269\u5c55\u63a2\u7d22\u3002", "method": "\u63d0\u51faARMs\u81ea\u9002\u5e94\u7ea2\u961f\u4ee3\u7406\uff0c\u91c7\u7528\u63a8\u7406\u589e\u5f3a\u7684\u591a\u6b65\u9aa4\u7f16\u6392\u81ea\u52a8\u4f18\u5316\u591a\u6837\u5316\u7ea2\u961f\u7b56\u7565\uff1b\u8bbe\u8ba1\u4e8611\u79cd\u65b0\u578b\u591a\u6a21\u6001\u653b\u51fb\u7b56\u7565\u548c\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\uff0c\u901a\u8fc7epsilon-greedy\u653b\u51fb\u63a2\u7d22\u7b97\u6cd5\u5e73\u8861\u653b\u51fb\u591a\u6837\u6027\u548c\u6709\u6548\u6027\uff1b\u6574\u540817\u79cd\u7ea2\u961f\u7b97\u6cd5\u901a\u8fc7\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u3002", "result": "\u5728\u5b9e\u4f8b\u548c\u7b56\u7565\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARMs\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e73\u5747\u8d85\u8fc7\u57fa\u7ebf52.1%\uff0c\u5728Claude-4-Sonnet\u4e0a\u8d85\u8fc790%\uff1b\u751f\u6210\u7684\u7ea2\u961f\u5b9e\u4f8b\u591a\u6837\u6027\u663e\u8457\u66f4\u9ad8\uff0c\u63ed\u793a\u4e86VLM\u7684\u65b0\u5174\u6f0f\u6d1e\uff1b\u6784\u5efa\u4e86ARMs-Bench\u6570\u636e\u96c6\uff0c\u5305\u542b30K+\u7ea2\u961f\u5b9e\u4f8b\uff0c\u6db5\u76d651\u4e2a\u98ce\u9669\u7c7b\u522b\u3002", "conclusion": "\u57fa\u4e8eARMs-Bench\u7684\u5b89\u5168\u5fae\u8c03\u663e\u8457\u63d0\u9ad8\u4e86VLM\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u901a\u7528\u6548\u7528\uff0c\u4e3a\u6539\u8fdb\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5bfc\u3002"}}
{"id": "2510.02679", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02679", "abs": "https://arxiv.org/abs/2510.02679", "authors": ["Yu-Zhe Shi", "Qiao Xu", "Yanjia Li", "Mingchen Liu", "Huamin Qu", "Lecheng Ruan", "Qining Wang"], "title": "Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation", "comment": "Accepted for publication in IEEE Transactions on Automation Science\n  and Engineering", "summary": "Advanced Planning and Scheduling (APS) systems have become indispensable for\nmodern manufacturing operations, enabling optimized resource allocation and\nproduction efficiency in increasingly complex and dynamic environments. While\nalgorithms for solving abstracted scheduling problems have been extensively\ninvestigated, the critical prerequisite of specifying manufacturing\nrequirements into formal constraints remains manual and labor-intensive.\nAlthough recent advances of generative models, particularly Large Language\nModels (LLMs), show promise in automating constraint specification from\nheterogeneous raw manufacturing data, their direct application faces challenges\ndue to natural language ambiguity, non-deterministic outputs, and limited\ndomain-specific knowledge. This paper presents a constraint-centric\narchitecture that regulates LLMs to perform reliable automated constraint\nspecification for production scheduling. The architecture defines a\nhierarchical structural space organized across three levels, implemented\nthrough domain-specific representation to ensure precision and reliability\nwhile maintaining flexibility. Furthermore, an automated production scenario\nadaptation algorithm is designed and deployed to efficiently customize the\narchitecture for specific manufacturing configurations. Experimental results\ndemonstrate that the proposed approach successfully balances the generative\ncapabilities of LLMs with the reliability requirements of manufacturing\nsystems, significantly outperforming pure LLM-based approaches in constraint\nspecification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u4e2d\u5fc3\u7684\u67b6\u6784\uff0c\u5229\u7528LLMs\u5b9e\u73b0\u751f\u4ea7\u8c03\u5ea6\u4e2d\u53ef\u9760\u7684\u81ea\u52a8\u5316\u7ea6\u675f\u89c4\u8303\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u81ea\u7136\u8bed\u8a00\u6a21\u7cca\u6027\u548c\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u7cfb\u7edf\u4e2dAPS\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c06\u5236\u9020\u9700\u6c42\u8f6c\u5316\u4e3a\u6b63\u5f0f\u7ea6\u675f\u7684\u8fc7\u7a0b\u4ecd\u4f9d\u8d56\u4eba\u5de5\u4e14\u8017\u65f6\u3002\u867d\u7136LLMs\u5728\u81ea\u52a8\u5316\u7ea6\u675f\u89c4\u8303\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u9762\u4e34\u81ea\u7136\u8bed\u8a00\u6a21\u7cca\u6027\u3001\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u548c\u9886\u57df\u77e5\u8bc6\u6709\u9650\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ea6\u675f\u4e2d\u5fc3\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u4e2a\u5c42\u6b21\u7ec4\u7ec7\u7684\u5c42\u6b21\u7ed3\u6784\u7a7a\u95f4\uff0c\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u8868\u793a\u786e\u4fdd\u7cbe\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u7075\u6d3b\u6027\u3002\u8fd8\u5f00\u53d1\u4e86\u81ea\u52a8\u751f\u4ea7\u573a\u666f\u9002\u914d\u7b97\u6cd5\uff0c\u4e3a\u7279\u5b9a\u5236\u9020\u914d\u7f6e\u9ad8\u6548\u5b9a\u5236\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5e73\u8861\u4e86LLMs\u7684\u751f\u6210\u80fd\u529b\u4e0e\u5236\u9020\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u8981\u6c42\uff0c\u5728\u7ea6\u675f\u89c4\u8303\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u7eafLLM\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ea6\u675f\u4e2d\u5fc3\u67b6\u6784\u80fd\u591f\u6709\u6548\u5229\u7528LLMs\u5b9e\u73b0\u53ef\u9760\u7684\u81ea\u52a8\u5316\u7ea6\u675f\u89c4\u8303\uff0c\u4e3a\u5236\u9020\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u51c6\u786e\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02816", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02816", "abs": "https://arxiv.org/abs/2510.02816", "authors": ["Yulong Zhang", "Li Wang", "Wei Du", "Peilin Li", "Yuqin Dai Zhiyuan Zhao", "Lingyong Fang", "Ziniu Liu", "Ru Zhang", "Huijia Zhu", "Gongshen Liu"], "title": "NCV: A Node-Wise Consistency Verification Approach for Low-Cost Structured Error Localization in LLM Reasoning", "comment": null, "summary": "Verifying multi-step reasoning in large language models is difficult due to\nimprecise error localization and high token costs. Existing methods either\nassess entire reasoning chains, suffering attention dilution, or rely on\nexpensive multi-sampling. We introduce Node-wise Consistency Verification\n(NCV), a training-free framework that recasts verification as lightweight\nbinary consistency checks at the node level. By decomposing the chain of\nthought into interconnected verification nodes, NCV precisely localizes errors\nand avoids unnecessary long-form generation. Experiments demonstrate that our\napproach enhances interpretability and efficiency, presenting a scalable\nsolution for reliable LLM reasoning verification. On public datasets, NCV\nachieves a 10\\% to 25\\% improvement in F1 scores over baselines while utilizing\n$6\\times$~$58\\times$ fewer tokens than traditional methods like CoT-based\nverifiers.", "AI": {"tldr": "\u63d0\u51faNode-wise Consistency Verification (NCV)\u6846\u67b6\uff0c\u901a\u8fc7\u8282\u70b9\u7ea7\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\uff0c\u63d0\u9ad8\u9519\u8bef\u5b9a\u4f4d\u7cbe\u5ea6\u5e76\u51cf\u5c11token\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u8bc4\u4f30\u6574\u4e2a\u63a8\u7406\u94fe\u5bfc\u81f4\u6ce8\u610f\u529b\u5206\u6563\uff0c\u8981\u4e48\u4f9d\u8d56\u6602\u8d35\u7684\u591a\u91cd\u91c7\u6837\uff0c\u96be\u4ee5\u7cbe\u786e\u5b9a\u4f4d\u9519\u8bef\u4e14token\u6210\u672c\u9ad8\u3002", "method": "\u5c06\u63a8\u7406\u94fe\u5206\u89e3\u4e3a\u4e92\u8fde\u7684\u9a8c\u8bc1\u8282\u70b9\uff0c\u8fdb\u884c\u8f7b\u91cf\u7ea7\u4e8c\u5143\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u907f\u514d\u751f\u6210\u957f\u6587\u672c\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cNCV\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5F1\u5206\u6570\u63d0\u534710%-25%\uff0ctoken\u4f7f\u7528\u91cf\u51cf\u5c116-58\u500d\u3002", "conclusion": "NCV\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u53ef\u9760LLM\u63a8\u7406\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.02837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02837", "abs": "https://arxiv.org/abs/2510.02837", "authors": ["Wonjoong Kim", "Sangwu Park", "Yeonjun In", "Sein Kim", "Dongha Lee", "Chanyoung Park"], "title": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents", "comment": "Preprint. Under Review", "summary": "Although recent tool-augmented benchmarks incorporate complex user requests\nand diverse tools, the evaluation methods for most of them remain limited to\nanswer matching. However, as the number of steps required to resolve a user\nrequest increases, a proper evaluation of an agent's performance must go beyond\nthe final answer to also assess the problem-solving trajectory, including\npreviously ignored aspects such as efficiency, hallucination, and adaptivity.\nThe most straightforward method for evaluating these aspects is to compare an\nagent's trajectory with the ground-truth trajectory, but this approach is\nfundamentally limited since annotating all valid ground-truth trajectories is\nprohibitively expensive. However, a simple LLM-based evaluator struggles to\nassess trajectories in detail without ground truth. To effectively evaluate the\nagents in this manner, we introduce TRACE, a framework for the\nmulti-dimensional evaluation of tool-augmented LLM agent performance. By\nincorporating an evidence bank, which accumulates knowledge gathered from\npreceding reasoning steps, TRACE enables a multi-faceted analysis and\nevaluation of an agent's reasoning trajectory effectively. To validate our\nframework, we develop a new meta-evaluation dataset by augmenting existing\nbenchmarks with diverse and flawed trajectories, each labeled with\nmulti-faceted performance scores. Our results confirm that TRACE accurately\nevaluates these complex behaviors in a scalable and cost-effective manner, even\nwith small open-source LLMs. Furthermore, we apply our method to evaluate the\ntrajectories that agents produce while solving tool-augmented tasks, presenting\npreviously unreported observations and their corresponding insights.", "AI": {"tldr": "TRACE\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u7ef4\u5ea6\u8bc4\u4f30\u5de5\u5177\u589e\u5f3aLLM\u4ee3\u7406\u6027\u80fd\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u5e93\u79ef\u7d2f\u63a8\u7406\u6b65\u9aa4\u77e5\u8bc6\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u4ee3\u7406\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5305\u62ec\u6548\u7387\u3001\u5e7b\u89c9\u548c\u9002\u5e94\u6027\u7b49\u65b9\u9762\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u7b54\u6848\u5339\u914d\uff0c\u4f46\u968f\u7740\u89e3\u51b3\u7528\u6237\u8bf7\u6c42\u6240\u9700\u6b65\u9aa4\u589e\u52a0\uff0c\u9700\u8981\u8d85\u8d8a\u6700\u7ec8\u7b54\u6848\u6765\u8bc4\u4f30\u95ee\u9898\u89e3\u51b3\u8f68\u8ff9\uff0c\u5305\u62ec\u6548\u7387\u3001\u5e7b\u89c9\u548c\u9002\u5e94\u6027\u7b49\u88ab\u5ffd\u89c6\u7684\u65b9\u9762\u3002", "method": "\u5f15\u5165TRACE\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u5e93\u79ef\u7d2f\u524d\u9762\u63a8\u7406\u6b65\u9aa4\u7684\u77e5\u8bc6\uff0c\u5b9e\u73b0\u5bf9\u4ee3\u7406\u63a8\u7406\u8f68\u8ff9\u7684\u591a\u65b9\u9762\u5206\u6790\u548c\u8bc4\u4f30\u3002\u521b\u5efa\u5143\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5728\u73b0\u6709\u57fa\u51c6\u4e0a\u6dfb\u52a0\u591a\u6837\u4e14\u6709\u7f3a\u9677\u7684\u8f68\u8ff9\uff0c\u5e76\u6807\u6ce8\u591a\u65b9\u9762\u6027\u80fd\u5206\u6570\u3002", "result": "TRACE\u80fd\u591f\u51c6\u786e\u8bc4\u4f30\u590d\u6742\u884c\u4e3a\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\uff0c\u5373\u4f7f\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90LLM\u4e5f\u80fd\u5b9e\u73b0\u3002\u5e94\u7528\u8be5\u65b9\u6cd5\u8bc4\u4f30\u4ee3\u7406\u5728\u89e3\u51b3\u5de5\u5177\u589e\u5f3a\u4efb\u52a1\u65f6\u4ea7\u751f\u7684\u8f68\u8ff9\uff0c\u63d0\u4f9b\u4e86\u4e4b\u524d\u672a\u62a5\u544a\u7684\u89c2\u5bdf\u548c\u89c1\u89e3\u3002", "conclusion": "TRACE\u6846\u67b6\u4e3a\u5de5\u5177\u589e\u5f3aLLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u8d85\u8d8a\u7b80\u5355\u7684\u7b54\u6848\u5339\u914d\uff0c\u5168\u9762\u8bc4\u4f30\u95ee\u9898\u89e3\u51b3\u8f68\u8ff9\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.02840", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02840", "abs": "https://arxiv.org/abs/2510.02840", "authors": ["Antoine Maier", "Aude Maier", "Tom David"], "title": "Take Goodhart Seriously: Principled Limit on General-Purpose AI Optimization", "comment": "9 pages, 1 figure. Under review", "summary": "A common but rarely examined assumption in machine learning is that training\nyields models that actually satisfy their specified objective function. We call\nthis the Objective Satisfaction Assumption (OSA). Although deviations from OSA\nare acknowledged, their implications are overlooked. We argue, in a\nlearning-paradigm-agnostic framework, that OSA fails in realistic conditions:\napproximation, estimation, and optimization errors guarantee systematic\ndeviations from the intended objective, regardless of the quality of its\nspecification. Beyond these technical limitations, perfectly capturing and\ntranslating the developer's intent, such as alignment with human preferences,\ninto a formal objective is practically impossible, making misspecification\ninevitable. Building on recent mathematical results, absent a mathematical\ncharacterization of these gaps, they are indistinguishable from those that\ncollapse into Goodhart's law failure modes under strong optimization pressure.\nBecause the Goodhart breaking point cannot be located ex ante, a principled\nlimit on the optimization of General-Purpose AI systems is necessary. Absent\nsuch a limit, continued optimization is liable to push systems into predictable\nand irreversible loss of control.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6311\u6218\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u8bad\u7ec3\u6a21\u578b\u80fd\u5b8c\u5168\u6ee1\u8db3\u76ee\u6807\u51fd\u6570\u7684\u5047\u8bbe\uff0c\u6307\u51fa\u7531\u4e8e\u8fd1\u4f3c\u3001\u4f30\u8ba1\u548c\u4f18\u5316\u8bef\u5dee\uff0c\u4ee5\u53ca\u76ee\u6807\u51fd\u6570\u672c\u8eab\u65e0\u6cd5\u5b8c\u7f8e\u6355\u6349\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u7cfb\u7edf\u4f1a\u504f\u79bb\u9884\u671f\u76ee\u6807\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5728\u5f3a\u4f18\u5316\u538b\u529b\u4e0b\u51fa\u73b0Goodhart\u5b9a\u5f8b\u7684\u5931\u63a7\u6a21\u5f0f\u3002", "motivation": "\u52a8\u673a\u662f\u68c0\u9a8c\u673a\u5668\u5b66\u4e60\u4e2d\u666e\u904d\u4f46\u672a\u7ecf\u68c0\u9a8c\u7684\u5047\u8bbe\u2014\u2014\u8bad\u7ec3\u4ea7\u751f\u7684\u6a21\u578b\u80fd\u5b8c\u5168\u6ee1\u8db3\u5176\u6307\u5b9a\u76ee\u6807\u51fd\u6570\uff08\u76ee\u6807\u6ee1\u8db3\u5047\u8bbeOSA\uff09\uff0c\u5e76\u63a2\u8ba8OSA\u5931\u8d25\u7684\u73b0\u5b9e\u5f71\u54cd\u548c\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u91c7\u7528\u5b66\u4e60\u8303\u5f0f\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5206\u6790\u8fd1\u4f3c\u8bef\u5dee\u3001\u4f30\u8ba1\u8bef\u5dee\u548c\u4f18\u5316\u8bef\u5dee\u5982\u4f55\u5bfc\u81f4\u7cfb\u7edf\u504f\u79bb\u9884\u671f\u76ee\u6807\uff0c\u5e76\u57fa\u4e8e\u8fd1\u671f\u6570\u5b66\u7ed3\u679c\u8bba\u8bc1\u8fd9\u4e9b\u504f\u5dee\u5728\u7f3a\u4e4f\u6570\u5b66\u8868\u5f81\u65f6\u4e0eGoodhart\u5b9a\u5f8b\u5931\u6548\u6a21\u5f0f\u65e0\u6cd5\u533a\u5206\u3002", "result": "\u7814\u7a76\u53d1\u73b0OSA\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5fc5\u7136\u5931\u8d25\uff0c\u76ee\u6807\u51fd\u6570\u65e0\u6cd5\u5b8c\u7f8e\u6355\u6349\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u5bfc\u81f4\u9519\u8bef\u89c4\u8303\u4e0d\u53ef\u907f\u514d\u3002\u5728\u5f3a\u4f18\u5316\u538b\u529b\u4e0b\uff0c\u8fd9\u4e9b\u504f\u5dee\u4f1a\u6f14\u53d8\u4e3aGoodhart\u5b9a\u5f8b\u7684\u5931\u63a7\u6a21\u5f0f\u3002", "conclusion": "\u7531\u4e8e\u65e0\u6cd5\u9884\u5148\u786e\u5b9aGoodhart\u4e34\u754c\u70b9\uff0c\u5fc5\u987b\u5bf9\u901a\u7528\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4f18\u5316\u65bd\u52a0\u539f\u5219\u6027\u9650\u5236\uff0c\u5426\u5219\u6301\u7eed\u4f18\u5316\u53ef\u80fd\u5bfc\u81f4\u53ef\u9884\u6d4b\u4e14\u4e0d\u53ef\u9006\u7684\u5931\u63a7\u3002"}}
{"id": "2510.02850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02850", "abs": "https://arxiv.org/abs/2510.02850", "authors": ["Xinle Wu", "Yao Lu"], "title": "Reward Model Routing in Alignment", "comment": null, "summary": "Reinforcement learning from human or AI feedback (RLHF / RLAIF) has become\nthe standard paradigm for aligning large language models (LLMs). However, most\npipelines rely on a single reward model (RM), limiting alignment quality and\nrisking overfitting. Recent work explores RM routing--dynamically selecting an\nRM from a candidate pool to exploit complementary strengths while maintaining\n$O(1)$ RM calls--but existing methods suffer from cold-start and insufficient\nexploration. We propose BayesianRouter, a hybrid routing framework that\ncombines offline RM strengths learning with online Bayesian selection. In the\noffline stage, a multi-task router is trained on preference data to estimate\nper-RM reliability. In the online stage, a Bayesian Thompson sampling router\nperforms per-query RM selection, initializing RM-specific weight vectors with\noffline embeddings as Gaussian priors and adaptively updating their posteriors\nwith online rewards to adapt to the evolving policy distribution. Extensive\nexperiments on instruction-following (AlpacaEval-2, Arena-Hard, MT-Bench) and\nreasoning (GSM8K, MMLU) benchmarks show that BayesianRouter consistently\noutperforms individual RMs, RM ensembling, and existing routing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86BayesianRouter\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u7ebfRM\u5f3a\u5ea6\u5b66\u4e60\u548c\u5728\u7ebf\u8d1d\u53f6\u65af\u9009\u62e9\uff0c\u52a8\u6001\u9009\u62e9\u5956\u52b1\u6a21\u578b\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u51b7\u542f\u52a8\u548c\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684RLHF/RLAIF\u6d41\u7a0b\u4f9d\u8d56\u5355\u4e00\u5956\u52b1\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5bf9\u9f50\u8d28\u91cf\u5e76\u53ef\u80fd\u5bfc\u81f4\u8fc7\u62df\u5408\u3002\u867d\u7136\u6700\u8fd1\u6709\u7814\u7a76\u63a2\u7d22\u5956\u52b1\u6a21\u578b\u8def\u7531\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u51b7\u542f\u52a8\u548c\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u8def\u7531\u6846\u67b6BayesianRouter\uff1a\u79bb\u7ebf\u9636\u6bb5\u8bad\u7ec3\u591a\u4efb\u52a1\u8def\u7531\u5668\u4f30\u8ba1\u6bcf\u4e2aRM\u7684\u53ef\u9760\u6027\uff1b\u5728\u7ebf\u9636\u6bb5\u4f7f\u7528\u8d1d\u53f6\u65afThompson\u91c7\u6837\u8def\u7531\u5668\u8fdb\u884c\u6bcf\u67e5\u8be2RM\u9009\u62e9\uff0c\u7528\u79bb\u7ebf\u5d4c\u5165\u4f5c\u4e3a\u9ad8\u65af\u5148\u9a8c\u521d\u59cb\u5316\u6743\u91cd\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u5956\u52b1\u81ea\u9002\u5e94\u66f4\u65b0\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5728\u6307\u4ee4\u8ddf\u968f\uff08AlpacaEval-2\u3001Arena-Hard\u3001MT-Bench\uff09\u548c\u63a8\u7406\uff08GSM8K\u3001MMLU\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBayesianRouter\u59cb\u7ec8\u4f18\u4e8e\u5355\u4e2aRM\u3001RM\u96c6\u6210\u548c\u73b0\u6709\u8def\u7531\u65b9\u6cd5\u3002", "conclusion": "BayesianRouter\u6846\u67b6\u901a\u8fc7\u6709\u6548\u7ed3\u5408\u79bb\u7ebf\u548c\u5728\u7ebf\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u8def\u7531\u7684\u6027\u80fd\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02880", "abs": "https://arxiv.org/abs/2510.02880", "authors": ["Tianren Ma", "Mu Zhang", "Yibing Wang", "Qixiang Ye"], "title": "Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models", "comment": "Project Page: https://github.com/martian422/MaskGRPO", "summary": "Optimizing discrete diffusion model (DDM) with rewards remains a challenge:\nthe non-autoregressive paradigm makes importance sampling intractable and\nrollout complex, puzzling reinforcement learning methods such as Group Relative\nPolicy Optimization (GRPO). In this study, we introduce MaskGRPO, the first\nviable approach to enable scalable multimodal reinforcement learning in\ndiscrete diffusion with effective importance sampling and modality-specific\nadaptations. To this end, we first clarify the theoretical foundation for DDMs,\nwhich facilitates building an importance estimator that captures valuable token\nfluctuation for gradient updates. We then delicately tailored the rollout\nmethod for visual sequences, which yields diverse completions and reliable\noptimization gradients. Upon math reasoning, coding, and visual generation\nbenchmarks, MaskGRPO brings more stable and efficient updates, leading to\nstronger reasoning performance and better generation quality. This study\nestablishes MaskGRPO as a systematic policy optimization approach and the first\npractical way for discretized visual diffusion.", "AI": {"tldr": "\u63d0\u51fa\u4e86MaskGRPO\u65b9\u6cd5\uff0c\u8fd9\u662f\u9996\u4e2a\u5728\u79bb\u6563\u6269\u6563\u6a21\u578b\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u91cd\u8981\u6027\u91c7\u6837\u548c\u6a21\u6001\u7279\u5b9a\u9002\u5e94\u95ee\u9898\u3002", "motivation": "\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u975e\u81ea\u56de\u5f52\u7279\u6027\u4f7f\u5f97\u91cd\u8981\u6027\u91c7\u6837\u96be\u4ee5\u5904\u7406\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982GRPO\u96be\u4ee5\u5e94\u7528\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u9996\u5148\u6f84\u6e05DDM\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6784\u5efa\u6355\u6349\u6709\u4ef7\u503ctoken\u6ce2\u52a8\u7684\u91cd\u8981\u6027\u4f30\u8ba1\u5668\uff1b\u7136\u540e\u4e3a\u89c6\u89c9\u5e8f\u5217\u7cbe\u5fc3\u8bbe\u8ba1rollout\u65b9\u6cd5\uff0c\u4ea7\u751f\u591a\u6837\u5316\u8865\u5168\u548c\u53ef\u9760\u4f18\u5316\u68af\u5ea6\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u7f16\u7801\u548c\u89c6\u89c9\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMaskGRPO\u5e26\u6765\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u66f4\u65b0\uff0c\u83b7\u5f97\u66f4\u5f3a\u7684\u63a8\u7406\u6027\u80fd\u548c\u66f4\u597d\u7684\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "MaskGRPO\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u662f\u79bb\u6563\u5316\u89c6\u89c9\u6269\u6563\u7684\u7b2c\u4e00\u4e2a\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02996", "abs": "https://arxiv.org/abs/2510.02996", "authors": ["Martina Mattioli", "Eike Petersen", "Aasa Feragen", "Marcello Pelillo", "Siavash A. Bigdeli"], "title": "Onto-Epistemological Analysis of AI Explanations", "comment": null, "summary": "Artificial intelligence (AI) is being applied in almost every field. At the\nsame time, the currently dominant deep learning methods are fundamentally\nblack-box systems that lack explanations for their inferences, significantly\nlimiting their trustworthiness and adoption. Explainable AI (XAI) methods aim\nto overcome this challenge by providing explanations of the models' decision\nprocess. Such methods are often proposed and developed by engineers and\nscientists with a predominantly technical background and incorporate their\nassumptions about the existence, validity, and explanatory utility of different\nconceivable explanatory mechanisms. However, the basic concept of an\nexplanation -- what it is, whether we can know it, whether it is absolute or\nrelative -- is far from trivial and has been the subject of deep philosophical\ndebate for millennia. As we point out here, the assumptions incorporated into\ndifferent XAI methods are not harmless and have important consequences for the\nvalidity and interpretation of AI explanations in different domains. We\ninvestigate ontological and epistemological assumptions in explainability\nmethods when they are applied to AI systems, meaning the assumptions we make\nabout the existence of explanations and our ability to gain knowledge about\nthose explanations. Our analysis shows how seemingly small technical changes to\nan XAI method may correspond to important differences in the underlying\nassumptions about explanations. We furthermore highlight the risks of ignoring\nthe underlying onto-epistemological paradigm when choosing an XAI method for a\ngiven application, and we discuss how to select and adapt appropriate XAI\nmethods for different domains of application.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e2d\u7684\u672c\u4f53\u8bba\u548c\u8ba4\u8bc6\u8bba\u5047\u8bbe\uff0c\u6307\u51fa\u8fd9\u4e9b\u5047\u8bbe\u5bf9AI\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u89e3\u91ca\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u4e86\u5982\u4f55\u4e3a\u4e0d\u540c\u5e94\u7528\u9886\u57df\u9009\u62e9\u548c\u9002\u914d\u9002\u5f53\u7684XAI\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u662f\u9ed1\u76d2\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u5bf9\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u89e3\u91ca\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53ef\u4fe1\u5ea6\u548c\u91c7\u7528\u3002\u867d\u7136\u53ef\u89e3\u91caAI\u65b9\u6cd5\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u57fa\u4e8e\u6280\u672f\u80cc\u666f\u5f00\u53d1\u8005\u7684\u5047\u8bbe\uff0c\u800c\u89e3\u91ca\u7684\u57fa\u672c\u6982\u5ff5\u672c\u8eab\u5728\u54f2\u5b66\u4e0a\u5b58\u5728\u6df1\u523b\u4e89\u8bae\u3002", "method": "\u7814\u7a76\u53ef\u89e3\u91caAI\u65b9\u6cd5\u5e94\u7528\u4e8eAI\u7cfb\u7edf\u65f6\u7684\u672c\u4f53\u8bba\u548c\u8ba4\u8bc6\u8bba\u5047\u8bbe\uff0c\u5373\u5173\u4e8e\u89e3\u91ca\u5b58\u5728\u6027\u4ee5\u53ca\u6211\u4eec\u83b7\u53d6\u8fd9\u4e9b\u89e3\u91ca\u77e5\u8bc6\u80fd\u529b\u7684\u5047\u8bbe\u3002\u5206\u6790XAI\u65b9\u6cd5\u4e2d\u770b\u4f3c\u5c0f\u7684\u6280\u672f\u53d8\u5316\u5982\u4f55\u5bf9\u5e94\u89e3\u91ca\u57fa\u7840\u5047\u8bbe\u7684\u91cd\u8981\u5dee\u5f02\u3002", "result": "\u5206\u6790\u663e\u793a\uff0cXAI\u65b9\u6cd5\u4e2d\u7684\u6280\u672f\u9009\u62e9\u53cd\u6620\u4e86\u4e0d\u540c\u7684\u672c\u4f53\u8bba\u548c\u8ba4\u8bc6\u8bba\u7acb\u573a\uff0c\u8fd9\u4e9b\u5047\u8bbe\u5bf9\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u89e3\u91ca\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u5ffd\u7565\u57fa\u7840\u7684\u672c\u4f53-\u8ba4\u8bc6\u8bba\u8303\u5f0f\u5728\u9009\u62e9XAI\u65b9\u6cd5\u65f6\u5b58\u5728\u98ce\u9669\u3002", "conclusion": "\u5728\u9009\u62e9XAI\u65b9\u6cd5\u65f6\u9700\u8981\u8003\u8651\u5176\u57fa\u7840\u7684\u672c\u4f53\u8bba\u548c\u8ba4\u8bc6\u8bba\u5047\u8bbe\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u5e94\u7528\u9886\u57df\u9009\u62e9\u548c\u9002\u914d\u9002\u5f53\u7684\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fdd\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2510.03078", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03078", "abs": "https://arxiv.org/abs/2510.03078", "authors": ["Anna Trapp", "Mersedeh Sadeghi", "Andreas Vogelsang"], "title": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments", "comment": "Accepted at Ex-ASE 2025, co-located with the 40th IEEE/ACM\n  International Conference on Automated Software Engineering (ASE 2025)", "summary": "Explainability is increasingly seen as an essential feature of rule-based\nsmart environments. While counterfactual explanations, which describe what\ncould have been done differently to achieve a desired outcome, are a powerful\ntool in eXplainable AI (XAI), no established methods exist for generating them\nin these rule-based domains. In this paper, we present the first formalization\nand implementation of counterfactual explanations tailored to this domain. It\nis implemented as a plugin that extends an existing explanation engine for\nsmart environments. We conducted a user study (N=17) to evaluate our generated\ncounterfactuals against traditional causal explanations. The results show that\nuser preference is highly contextual: causal explanations are favored for their\nlinguistic simplicity and in time-pressured situations, while counterfactuals\nare preferred for their actionable content, particularly when a user wants to\nresolve a problem. Our work contributes a practical framework for a new type of\nexplanation in smart environments and provides empirical evidence to guide the\nchoice of when each explanation type is most effective.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u73af\u5883\u9886\u57df\u5f62\u5f0f\u5316\u5e76\u5b9e\u73b0\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u53d1\u73b0\u7528\u6237\u504f\u597d\u9ad8\u5ea6\u60c5\u5883\u5316\uff1a\u56e0\u679c\u89e3\u91ca\u56e0\u5176\u8bed\u8a00\u7b80\u6d01\u6027\u5728\u65f6\u95f4\u7d27\u8feb\u65f6\u66f4\u53d7\u9752\u7750\uff0c\u800c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u56e0\u5176\u53ef\u64cd\u4f5c\u6027\u5185\u5bb9\u5728\u89e3\u51b3\u95ee\u9898\u65f6\u66f4\u53d7\u6b22\u8fce\u3002", "motivation": "\u867d\u7136\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5728\u53ef\u89e3\u91caAI\u4e2d\u662f\u4e00\u4e2a\u5f3a\u5927\u5de5\u5177\uff0c\u4f46\u5728\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u73af\u5883\u9886\u57df\u5c1a\u65e0\u6210\u719f\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u9700\u8981\u4e3a\u8fd9\u4e00\u9886\u57df\u5f00\u53d1\u4e13\u95e8\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u63d2\u4ef6\u6765\u6269\u5c55\u73b0\u6709\u7684\u667a\u80fd\u73af\u5883\u89e3\u91ca\u5f15\u64ce\uff0c\u5b9e\u73b0\u4e86\u9488\u5bf9\u8be5\u9886\u57df\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76(N=17)\u8bc4\u4f30\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e0e\u4f20\u7edf\u56e0\u679c\u89e3\u91ca\u7684\u6548\u679c\u3002", "result": "\u7528\u6237\u504f\u597d\u9ad8\u5ea6\u4f9d\u8d56\u60c5\u5883\uff1a\u56e0\u679c\u89e3\u91ca\u56e0\u8bed\u8a00\u7b80\u6d01\u6027\u548c\u5728\u65f6\u95f4\u7d27\u8feb\u60c5\u51b5\u4e0b\u66f4\u53d7\u9752\u7750\uff1b\u53cd\u4e8b\u5b9e\u89e3\u91ca\u56e0\u63d0\u4f9b\u53ef\u64cd\u4f5c\u5185\u5bb9\uff0c\u5728\u7528\u6237\u60f3\u8981\u89e3\u51b3\u95ee\u9898\u65f6\u66f4\u53d7\u6b22\u8fce\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u667a\u80fd\u73af\u5883\u4e2d\u7684\u65b0\u578b\u89e3\u91ca\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u5e76\u4e3a\u9009\u62e9\u6700\u6709\u6548\u89e3\u91ca\u7c7b\u578b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u5f3a\u8c03\u4e86\u89e3\u91ca\u7c7b\u578b\u9009\u62e9\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u3002"}}
{"id": "2510.03127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03127", "abs": "https://arxiv.org/abs/2510.03127", "authors": ["Binze Li"], "title": "A Study of Rule Omission in Raven's Progressive Matrices", "comment": null, "summary": "Analogical reasoning lies at the core of human cognition and remains a\nfundamental challenge for artificial intelligence. Raven's Progressive Matrices\n(RPM) serve as a widely used benchmark to assess abstract reasoning by\nrequiring the inference of underlying structural rules. While many vision-based\nand language-based models have achieved success on RPM tasks, it remains\nunclear whether their performance reflects genuine reasoning ability or\nreliance on statistical shortcuts. This study investigates the generalization\ncapacity of modern AI systems under conditions of incomplete training by\ndeliberately omitting several structural rules during training. Both\nsequence-to-sequence transformer models and vision-based architectures such as\nCoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN\n(I-RAVEN) dataset. Experiments reveal that although transformers demonstrate\nstrong performance on familiar rules, their accuracy declines sharply when\nfaced with novel or omitted rules. Moreover, the gap between token-level\naccuracy and complete answer accuracy highlights fundamental limitations in\ncurrent approaches. These findings provide new insights into the reasoning\nmechanisms underlying deep learning models and underscore the need for\narchitectures that move beyond pattern recognition toward robust abstract\nreasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6545\u610f\u5728\u8bad\u7ec3\u4e2d\u7701\u7565\u90e8\u5206\u7ed3\u6784\u89c4\u5219\uff0c\u8bc4\u4f30\u73b0\u4ee3AI\u7cfb\u7edf\u5728\u4e0d\u5b8c\u6574\u8bad\u7ec3\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0transformer\u6a21\u578b\u5728\u9762\u5bf9\u65b0\u89c4\u5219\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u5728\u62bd\u8c61\u63a8\u7406\u65b9\u9762\u7684\u6839\u672c\u5c40\u9650\u6027\u3002", "motivation": "\u7c7b\u6bd4\u63a8\u7406\u662f\u4eba\u7c7b\u8ba4\u77e5\u7684\u6838\u5fc3\uff0c\u4e5f\u662f\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u672c\u6311\u6218\u3002\u867d\u7136\u8bb8\u591a\u57fa\u4e8e\u89c6\u89c9\u548c\u8bed\u8a00\u7684\u6a21\u578b\u5728Raven\u6e10\u8fdb\u77e9\u9635\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5176\u6027\u80fd\u662f\u5426\u53cd\u6620\u4e86\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u8fd8\u662f\u4f9d\u8d56\u4e8e\u7edf\u8ba1\u6377\u5f84\u3002", "method": "\u5728Impartial-RAVEN\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5e8f\u5217\u5230\u5e8f\u5217transformer\u6a21\u578b\u548c\u57fa\u4e8e\u89c6\u89c9\u7684\u67b6\u6784\uff08\u5982CoPINet\u548c\u53cc\u5bf9\u6bd4\u7f51\u7edc\uff09\uff0c\u901a\u8fc7\u6545\u610f\u5728\u8bad\u7ec3\u4e2d\u7701\u7565\u51e0\u4e2a\u7ed3\u6784\u89c4\u5219\u6765\u6d4b\u8bd5\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u867d\u7136transformer\u5728\u719f\u6089\u89c4\u5219\u4e0a\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5f53\u9762\u5bf9\u65b0\u9896\u6216\u7701\u7565\u7684\u89c4\u5219\u65f6\uff0c\u5176\u51c6\u786e\u6027\u6025\u5267\u4e0b\u964d\u3002token\u7ea7\u51c6\u786e\u6027\u548c\u5b8c\u6574\u7b54\u6848\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u7a81\u663e\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u6839\u672c\u5c40\u9650\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u63a8\u7406\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u8d85\u8d8a\u6a21\u5f0f\u8bc6\u522b\u3001\u5b9e\u73b0\u7a33\u5065\u62bd\u8c61\u63a8\u7406\u7684\u67b6\u6784\u3002"}}
{"id": "2510.03153", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03153", "abs": "https://arxiv.org/abs/2510.03153", "authors": ["Hima Jacob Leven Suprabha", "Laxmi Nag Laxminarayan Nagesh", "Ajith Nair", "Alvin Reuben Amal Selvaster", "Ayan Khan", "Raghuram Damarla", "Sanju Hannah Samuel", "Sreenithi Saravana Perumal", "Titouan Puech", "Venkataramireddy Marella", "Vishal Sonar", "Alessandro Suglia", "Oliver Lemon"], "title": "Improving Cooperation in Collaborative Embodied AI", "comment": "In proceedings of UKCI 2025", "summary": "The integration of Large Language Models (LLMs) into multiagent systems has\nopened new possibilities for collaborative reasoning and cooperation with AI\nagents. This paper explores different prompting methods and evaluates their\neffectiveness in enhancing agent collaborative behaviour and decision-making.\nWe enhance CoELA, a framework designed for building Collaborative Embodied\nAgents that leverage LLMs for multi-agent communication, reasoning, and task\ncoordination in shared virtual spaces. Through systematic experimentation, we\nexamine different LLMs and prompt engineering strategies to identify optimised\ncombinations that maximise collaboration performance. Furthermore, we extend\nour research by integrating speech capabilities, enabling seamless\ncollaborative voice-based interactions. Our findings highlight the\neffectiveness of prompt optimisation in enhancing collaborative agent\nperformance; for example, our best combination improved the efficiency of the\nsystem running with Gemma3 by 22% compared to the original CoELA system. In\naddition, the speech integration provides a more engaging user interface for\niterative system development and demonstrations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e0d\u540c\u63d0\u793a\u65b9\u6cd5\u5728\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u4f18\u5316CoELA\u6846\u67b6\u4e2d\u7684LLM\u63d0\u793a\u5de5\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u534f\u4f5c\u6027\u80fd\uff0c\u5e76\u96c6\u6210\u4e86\u8bed\u97f3\u529f\u80fd\u4ee5\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u4f18\u5316\u667a\u80fd\u4f53\u95f4\u7684\u534f\u4f5c\u63a8\u7406\u548c\u51b3\u7b56\u80fd\u529b\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u3002", "method": "\u589e\u5f3aCoELA\u6846\u67b6\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u4e0d\u540cLLM\u548c\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u5bfb\u627e\u6700\u4f18\u7ec4\u5408\u6765\u6700\u5927\u5316\u534f\u4f5c\u6027\u80fd\uff0c\u5e76\u96c6\u6210\u8bed\u97f3\u529f\u80fd\u5b9e\u73b0\u57fa\u4e8e\u8bed\u97f3\u7684\u534f\u4f5c\u4ea4\u4e92\u3002", "result": "\u6700\u4f73\u7ec4\u5408\u76f8\u6bd4\u539f\u59cbCoELA\u7cfb\u7edf\uff0c\u5728Gemma3\u4e0a\u8fd0\u884c\u6548\u7387\u63d0\u5347\u4e8622%\u3002\u8bed\u97f3\u96c6\u6210\u63d0\u4f9b\u4e86\u66f4\u5177\u5438\u5f15\u529b\u7684\u7528\u6237\u754c\u9762\u3002", "conclusion": "\u63d0\u793a\u4f18\u5316\u80fd\u6709\u6548\u63d0\u5347\u534f\u4f5c\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u8bed\u97f3\u96c6\u6210\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u4ea4\u4e92\u4f53\u9a8c\u548c\u6f14\u793a\u6548\u679c\u3002"}}
{"id": "2510.03194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03194", "abs": "https://arxiv.org/abs/2510.03194", "authors": ["Zichen Chen", "Jiefeng Chen", "Sercan \u00d6. Arik", "Misha Sra", "Tomas Pfister", "Jinsung Yoon"], "title": "CoDA: Agentic Systems for Collaborative Data Visualization", "comment": "31 pages, 6 figures, 5 tables", "summary": "Deep research has revolutionized data analysis, yet data scientists still\ndevote substantial time to manually crafting visualizations, highlighting the\nneed for robust automation from natural language queries. However, current\nsystems struggle with complex datasets containing multiple files and iterative\nrefinement. Existing approaches, including simple single- or multi-agent\nsystems, often oversimplify the task, focusing on initial query parsing while\nfailing to robustly manage data complexity, code errors, or final visualization\nquality. In this paper, we reframe this challenge as a collaborative\nmulti-agent problem. We introduce CoDA, a multi-agent system that employs\nspecialized LLM agents for metadata analysis, task planning, code generation,\nand self-reflection. We formalize this pipeline, demonstrating how\nmetadata-focused analysis bypasses token limits and quality-driven refinement\nensures robustness. Extensive evaluations show CoDA achieves substantial gains\nin the overall score, outperforming competitive baselines by up to 41.5%. This\nwork demonstrates that the future of visualization automation lies not in\nisolated code generation but in integrated, collaborative agentic workflows.", "AI": {"tldr": "CoDA\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e13\u95e8\u7684LLM\u667a\u80fd\u4f53\u8fdb\u884c\u5143\u6570\u636e\u5206\u6790\u3001\u4efb\u52a1\u89c4\u5212\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u6211\u53cd\u601d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5230\u53ef\u89c6\u5316\u7684\u81ea\u52a8\u5316\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u7cfb\u7edf\u5728\u5904\u7406\u5305\u542b\u591a\u4e2a\u6587\u4ef6\u7684\u590d\u6742\u6570\u636e\u96c6\u548c\u8fed\u4ee3\u4f18\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u8fc7\u5ea6\u7b80\u5316\u4efb\u52a1\uff0c\u65e0\u6cd5\u6709\u6548\u7ba1\u7406\u6570\u636e\u590d\u6742\u6027\u3001\u4ee3\u7801\u9519\u8bef\u6216\u6700\u7ec8\u53ef\u89c6\u5316\u8d28\u91cf\u3002", "method": "\u5c06\u6311\u6218\u91cd\u65b0\u5b9a\u4e49\u4e3a\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u95ee\u9898\uff0c\u5f15\u5165CoDA\u7cfb\u7edf\uff0c\u4f7f\u7528\u4e13\u95e8\u7684LLM\u667a\u80fd\u4f53\u8fdb\u884c\u5143\u6570\u636e\u5206\u6790\u3001\u4efb\u52a1\u89c4\u5212\u3001\u4ee3\u7801\u751f\u6210\u548c\u81ea\u6211\u53cd\u601d\uff0c\u901a\u8fc7\u5143\u6570\u636e\u5206\u6790\u7ed5\u8fc7token\u9650\u5236\uff0c\u901a\u8fc7\u8d28\u91cf\u9a71\u52a8\u7684\u4f18\u5316\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793aCoDA\u5728\u6574\u4f53\u5f97\u5206\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u6bd4\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u9ad8\u51fa41.5%\u3002", "conclusion": "\u53ef\u89c6\u5316\u81ea\u52a8\u5316\u7684\u672a\u6765\u4e0d\u5728\u4e8e\u5b64\u7acb\u7684\u4ee3\u7801\u751f\u6210\uff0c\u800c\u5728\u4e8e\u96c6\u6210\u7684\u3001\u534f\u4f5c\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2510.03206", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03206", "abs": "https://arxiv.org/abs/2510.03206", "authors": ["Cai Zhou", "Chenxiao Yang", "Yi Hu", "Chenyu Wang", "Chubin Zhang", "Muhan Zhang", "Lester Mackey", "Tommi Jaakkola", "Stephen Bates", "Dinghuai Zhang"], "title": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner", "comment": "27 pages", "summary": "Diffusion language models, especially masked discrete diffusion models, have\nachieved great success recently. While there are some theoretical and primary\nempirical results showing the advantages of latent reasoning with looped\ntransformers or continuous chain-of-thoughts, continuous diffusion models\ntypically underperform their discrete counterparts. In this paper, we argue\nthat diffusion language models do not necessarily need to be in the discrete\nspace. In particular, we prove that continuous diffusion models have stronger\nexpressivity than discrete diffusions and looped transformers. We attribute the\ncontradiction between the theoretical expressiveness and empirical performance\nto their practical trainability: while continuous diffusion provides\nintermediate supervision that looped transformers lack, they introduce\nadditional difficulty decoding tokens into the discrete token space from the\ncontinuous representation space. We therefore propose Coevolutionary Continuous\nDiscrete Diffusion (CCDD), which defines a joint multimodal diffusion process\non the union of a continuous representation space and a discrete token space,\nleveraging a single model to simultaneously denoise in the joint space. By\ncombining two modalities, CCDD is expressive with rich semantics in the latent\nspace, as well as good trainability and sample quality with the help of\nexplicit discrete tokens. We also propose effective architectures and advanced\ntraining/sampling techniques for CCDD, which reveals strong empirical\nperformance in extensive language modeling experiments on real-world tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u8fde\u7eed\u79bb\u6563\u6269\u6563\u6a21\u578bCCDD\uff0c\u901a\u8fc7\u5728\u8fde\u7eed\u8868\u793a\u7a7a\u95f4\u548c\u79bb\u6563\u6807\u8bb0\u7a7a\u95f4\u7684\u8054\u5408\u7a7a\u95f4\u4e2d\u8fdb\u884c\u591a\u6a21\u6001\u6269\u6563\uff0c\u89e3\u51b3\u4e86\u8fde\u7eed\u6269\u6563\u6a21\u578b\u5728\u8bed\u8a00\u5efa\u6a21\u4e2d\u8868\u8fbe\u80fd\u529b\u4e0e\u8bad\u7ec3\u6027\u80fd\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "motivation": "\u8fde\u7eed\u6269\u6563\u6a21\u578b\u5728\u7406\u8bba\u4e0a\u6bd4\u79bb\u6563\u6269\u6563\u6a21\u578b\u548c\u5faa\u73af\u53d8\u6362\u5668\u5177\u6709\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u5728\u5b9e\u9645\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u8fde\u7eed\u6269\u6563\u6a21\u578b\u5728\u5c06\u8fde\u7eed\u8868\u793a\u89e3\u7801\u56de\u79bb\u6563\u6807\u8bb0\u7a7a\u95f4\u65f6\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86CCDD\u6a21\u578b\uff0c\u5728\u8fde\u7eed\u8868\u793a\u7a7a\u95f4\u548c\u79bb\u6563\u6807\u8bb0\u7a7a\u95f4\u7684\u8054\u5408\u7a7a\u95f4\u4e0a\u5b9a\u4e49\u8054\u5408\u591a\u6a21\u6001\u6269\u6563\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u540c\u65f6\u5728\u8054\u5408\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53bb\u566a\u3002\u7ed3\u5408\u4e86\u4e24\u79cd\u6a21\u6001\u7684\u4f18\u52bf\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u67b6\u6784\u548c\u5148\u8fdb\u7684\u8bad\u7ec3/\u91c7\u6837\u6280\u672f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u4e2d\uff0cCCDD\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u5177\u6709\u4e30\u5bcc\u7684\u6f5c\u5728\u7a7a\u95f4\u8bed\u4e49\u548c\u826f\u597d\u7684\u6837\u672c\u8d28\u91cf\u3002", "conclusion": "CCDD\u901a\u8fc7\u8054\u5408\u8fde\u7eed\u79bb\u6563\u6269\u6563\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8fde\u7eed\u6269\u6563\u6a21\u578b\u5728\u8bed\u8a00\u5efa\u6a21\u4e2d\u7684\u8bad\u7ec3\u6027\u80fd\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5176\u7406\u8bba\u4e0a\u7684\u8868\u8fbe\u80fd\u529b\u4f18\u52bf\u3002"}}
