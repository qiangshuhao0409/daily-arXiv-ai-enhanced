<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.IT](#cs.IT) [Total: 4]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [BISCAY: Practical Radio KPI Driven Congestion Control for Mobile Networks](https://arxiv.org/abs/2509.02806)
*Jon Larrea,Tanya Shreedhar,Mahesh K. Marina*

Main category: cs.NI

TL;DR: Biscay是一个基于无线电KPI测量的移动网络拥塞控制系统，通过OpenDiag工具实时提取设备芯片组KPI数据，精确测量蜂窝链路可用带宽，显著降低延迟90%以上，同时保持或提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 移动应用性能严重依赖传输层拥塞控制设计，蜂窝链路带宽波动剧烈，需要更精确及时的带宽测量方法来优化性能。

Method: 提出Biscay系统，包含OpenDiag内核实时无线电KPI提取工具和KPI驱动的带宽确定层，动态调整拥塞窗口以最优利用可用带宽并最小化延迟。

Result: 在4G和5G多种场景下的实验显示，相比BBR和CUBIC等先进方案，平均和尾部延迟改善显著（通常降低90%以上），吞吐量相当或更好，OpenDiag的KPI测量粒度比MobileInsight提升100%。

Conclusion: Biscay是一个实用可部署的解决方案，通过在非root的Android 5G手机上实现，证明了其在实际移动网络环境中优化性能的有效性。

Abstract: Mobile application performance relies heavily on the congestion control
design of the underlying transport, which is typically bottlenecked by cellular
link and has to cope with rapid cellular link bandwidth fluctuations. We
observe that radio KPI measurements from the mobile device chipset can be
exploited for precise and timely measurement of available bandwidth on the
cellular link. Building on this insight, we propose Biscay, a practical and
radio KPI-driven congestion control system design for mobile networks. Biscay
leverages OpenDiag, the in-kernel real-time radio KPI extraction tool we
introduce in this paper, along with our KPI-based accurate bandwidth
determination layer towards dynamically adjusting the congestion window to
optimally use the available bandwidth while keeping delay to the minimum. Our
solution is practical and deployable, as shown through our implementation of
Biscay and OpenDiag on unrooted Android 5G phones. We extensively evaluate
Biscay against different state-of-the-art congestion control designs including
BBR and CUBIC with emulations driven by real measurement traces as well as
real-world experiments spanning diverse 4G and 5G scenarios, and show that it
provides significant average and tail delay improvements (typically over 90%
reduction) while yielding better or similar throughput. These gains are enabled
by 100% improvement in the granularity of on-device radio KPI measurements with
OpenDiag compared to existing alternatives like MobileInsight.

</details>


### [2] [Multi-layer Digital Twin System for Future Mobile Metaverse](https://arxiv.org/abs/2509.03049)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出了一种多层次数字双胞系统，通过协调本地、边缘和云端DT，为6G网络提供主动适应能力和支撑元宇宙应用。


<details>
  <summary>Details</summary>
Motivation: 解决6G时代通信网络面临的复杂性和动态性挑战，利用数字双胞技术实现网络从被动响应到主动适应的转变。

Method: 提出一种协调本地DT、边缘DT和云端DT的多层次DT系统架构，采用分布式、移动性、层层递进的方式。

Result: 该系统能够实现实时数据驱动的决策制定和数字代理功能，同时为元宇宙应用提供核心数据、预训练模型和开放接口。

Conclusion: 多层次DT系统为6G网络架构提供了有效的主动适应解决方案，并为元宇宙服务的开发和体验创造了条件。

Abstract: In the upcoming 6G era, the communication networks are expected to face
unprecedented challenges in terms of complexity and dynamics. Digital Twin (DT)
technology, with its various digital capabilities, holds great potential to
facilitate the transformation of the communication network from passive
responding to proactive adaptation. Thus, in this paper, we propose a
multi-layer DT system that coordinates local DT, edge DT, and cloud DT for
future network architecture and functions. In our vision, the proposed DT
system will not only achieve real-time data-driven decision-making and digital
agent functions previously handled by centralized DT, but will do so in a more
distributed, mobile, layer-by-layer manner. Moreover, it will supply essential
data, pre-trained models, and open interfaces for future metaverse
applications, enabling creators and users to efficiently develop and experience
metaverse services.

</details>


### [3] [Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3](https://arxiv.org/abs/2509.02811)
*Alessandro Traspadini,Michele Zorzi,Marco Giordani*

Main category: cs.NI

TL;DR: 研究探索了LoRa技术通过低地球轨道卫星网关支持大规模物联网连接的可行性和性能，开发了ns3-LoRa-NTN仿真模块进行端到端卫星通信仿真。


<details>
  <summary>Details</summary>
Motivation: 在偏远地区地面基础设施有限或不可用的情况下，需要通过卫星网关为传感器和执行器提供连接，LoRa技术因其长距离、高能效和灵活性而具有巨大潜力。

Method: 开发了新的ns3-LoRa-NTN仿真模块，集成并扩展了ns3-LoRa和ns3-NTN模块，实现了LoRa网络中卫星通信的完整端到端仿真。

Result: 结果表明LoRa可以有效支持从地面到LEO卫星的直接通信，但当终端节点在长距离上使用相同的扩频因子时，需要网络优化来降低碰撞概率。

Conclusion: LoRa技术能够有效支持通过LEO卫星网关的大规模物联网连接，但需要对网络进行优化以处理长距离通信中的碰撞问题。

Abstract: The integration of Internet of Things (IoT) and Non-Terrestrial Networks
(NTNs) has emerged as a key paradigm to provide connectivity for sensors and
actuators via satellite gateways in remote areas where terrestrial
infrastructure is limited or unavailable. Among other Low-Power Wide-Area
Network (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential
given its long range, energy efficiency, and flexibility. In this paper, we
explore the feasibility and performance of LoRa to support large-scale IoT
connectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we
developed a new ns3-LoRa-NTN simulation module, which integrates and extends
the ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of
satellite communication in LoRa networks. Our results, given in terms of
average data rate and Packet Reception Ratio (PRR), confirm that LoRa can
effectively support direct communication from the ground to LEO satellites, but
network optimization is required to mitigate collision probability when end
nodes use the same Spreading Factors (SFs) over long distances.

</details>


### [4] [Machine Learning-Driven Anomaly Detection for 5G O-RAN Performance Metrics](https://arxiv.org/abs/2509.03290)
*Babak Azkaei,Kishor Chandra Joshi,George Exarchakos*

Main category: cs.NI

TL;DR: 基于O-RAN的主动异常检测框架，通过两种算法预阻通信网络通信量下降和手势失败，平均减少手势目标小区41.27%


<details>
  <summary>Details</summary>
Motivation: 靠近临界5G/6G网络运维复杂性增加，需要主动自动化故障管理。O-RAN规范提供了开放接口和AI/ML集成机会，为网络健康监控和异常检测带来新可能性

Method: 提出两种可行动异常检测算法：1）分析资源块利用率、信号质量等KPI指标，识别有通信量严重下降风险的UE，启动主动手势；2）评估邻小区无线覆盖质量，过滤信号强度或干扰水平异常的小区

Result: 平均减少手势目标小区41.27%，有效减轻手势后失败和通信量下降，运行速度远超近实时延迟要求

Conclusion: 该框架为自治愈6G网络掌了道路，通过主动异常检测和预阻性手势，提高网络可靠性和性能

Abstract: The ever-increasing reliance of critical services on network infrastructure
coupled with the increased operational complexity of beyond-5G/6G networks
necessitate the need for proactive and automated network fault management. The
provision for open interfaces among different radio access network\,(RAN)
elements and the integration of AI/ML into network architecture enabled by the
Open RAN\,(O-RAN) specifications bring new possibilities for active network
health monitoring and anomaly detection. In this paper we leverage these
advantages and develop an anomaly detection framework that proactively detect
the possible throughput drops for a UE and minimize the post-handover failures.
We propose two actionable anomaly detection algorithms tailored for real-world
deployment. The first algorithm identifies user equipment (UE) at risk of
severe throughput degradation by analyzing key performance indicators (KPIs)
such as resource block utilization and signal quality metrics, enabling
proactive handover initiation. The second algorithm evaluates neighbor cell
radio coverage quality, filtering out cells with anomalous signal strength or
interference levels. This reduces candidate targets for handover by 41.27\% on
average. Together, these methods mitigate post-handover failures and throughput
drops while operating much faster than the near-real-time latency constraints.
This paves the way for self-healing 6G networks.

</details>


### [5] [GPS Spoofing Attacks on Automated Frequency Coordination System in Wi-Fi 6E and Beyond](https://arxiv.org/abs/2509.02824)
*Yilu Dong,Tianchang Yang,Arupjyoti Bhuyan,Syed Rafiul Hussain*

Main category: cs.NI

TL;DR: 研究发现Wi-Fi 6E/7的6GHz频段AFC系统存在GPS位置欺骗漏洞，攻击者可用廉价设备伪造AP位置，从而非法获取频谱、造成干扰或禁用AP


<details>
  <summary>Details</summary>
Motivation: 6GHz频段与关键任务系统共享频谱，FCC要求使用AFC系统基于AP位置分配频率和功率，但GPS位置报告机制存在安全风险

Method: 使用廉价商用无线电设备在实验室环境中对商用AP进行GPS欺骗攻击，并评估商业AFC系统在欺骗场景下的表现

Result: 成功验证了通过GPS欺骗可以操纵AP行为，获得未授权频谱访问，造成有害干扰或完全禁用AP

Conclusion: AFC系统的安全假设存在严重漏洞，需要更强的位置完整性保护机制

Abstract: The 6 GHz spectrum, recently opened for unlicensed use under Wi-Fi 6E and
Wi-Fi 7, overlaps with frequencies used by mission-critical incumbent systems
such as public safety communications and utility infrastructure. To prevent
interference, the FCC mandates the use of Automated Frequency Coordination
(AFC) systems, which assign safe frequency and power levels based on Wi-Fi
Access Point (AP)-reported locations. In this work, we demonstrate that
GPS-based location reporting, which Wi-Fi APs use, can be spoofed using
inexpensive, off-the-shelf radio equipment. This enables attackers to
manipulate AP behavior, gain unauthorized spectrum access, cause harmful
interference, or disable APs entirely by spoofing them into foreign locations.
We validate these attacks in a controlled lab setting against a commercial AP
and evaluate a commercial AFC system under spoofed scenarios. Our findings
highlight critical gaps in the security assumptions of AFC and motivate the
need for stronger location integrity protections.

</details>


### [6] [Closing the Visibility Gap: A Monitoring Framework for Verifiable Open RAN Operations](https://arxiv.org/abs/2509.03000)
*Hexuan Yu,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.NI

TL;DR: 这篇论文提出了一种监控框架，用于解决Open RAN中的安全挑战，特别是在多运营商共享部署环境中的策神违规问题。该框架能够主动验证配置状态和控制行为，并在约200毫秒的处理延迟下实现及时的策神执行。


<details>
  <summary>Details</summary>
Motivation: Open RAN的开放性和解聚化特性带来了新的安全挑战，特别是在多运营商共享组件的部署中。现有的零信任架构假设认证组件会遵守运营策神，但这称造成了严重的安全盲点：被攻击或错误配置的组件可能会轻声违反策神、滥用资源或破坏下游过程。

Method: 研究者提出了一种监控框架，用于低信任O-RAN环境中的配置状态和控制行为主动验证。该系统基于租户定义的策神，提供可扩展的、可验证的监督机制。研究人员使用标准化的O-RAN配置实现并评估了该框架。

Result: 该监控框架的总处理延迟约为200毫秒，证明了其在多运营商部署中进行及时策神执行和遵循性审计时的高效性和实用性。

Conclusion: 该研究提出的监控框架有效解决了Open RAN中的安全盲点问题，通过主动验证配置和行为来提升O-RAN运营的透明度和信任度，为多运营商共享部署提供了可靠的安全保障。

Abstract: Open Radio Access Network (Open RAN) is reshaping mobile network architecture
by promoting openness, disaggregation, and cross-vendor interoperability.
However, this architectural flexibility introduces new security challenges,
especially in deployments where multiple mobile network operators (MNOs)
jointly operate shared components. Existing Zero Trust Architectures (ZTA) in
O-RAN, as defined by governmental and industry standards, implicitly assume
that authenticated components will comply with operational policies. However,
this assumption creates a critical blind spot: misconfigured or compromised
components can silently violate policies, misuse resources, or corrupt
downstream processes (e.g., ML-based RIC xApps).
  To address this critical gap, we propose a monitoring framework for low-trust
O-RAN environments that proactively verifies configuration state and control
behavior against tenant-defined policies. Our system provides scalable,
verifiable oversight to enhance transparency and trust in O-RAN operations. We
implement and evaluate the framework using standardized O-RAN configurations,
with total processing latency of approximately 200 ms, demonstrating its
efficiency and practicality for timely policy enforcement and compliance
auditing in multi-MNO deployments.

</details>


### [7] [Dependency Chain Analysis of ROS 2 DDS QoS Policies: From Lifecycle Tutorial to Static Verification](https://arxiv.org/abs/2509.03381)
*Sanghoon Lee,Junha Kang,Kyung-Joon Park*

Main category: cs.NI

TL;DR: ROS 2用户缺乏DDS QoS策略配置指导，导致运行时故障。本文分析了DDS通信生命周期，提供了QoS策略教程，建立了QoS依赖链和41条违规规则，并开发了QoS Guard工具进行静态验证。


<details>
  <summary>Details</summary>
Motivation: ROS 2依赖DDS的20多个QoS策略，但用户缺乏安全策略组合和验证指导，导致试错调优和意外运行时故障。

Method: 分析DDS发布者-订阅者通信生命周期（发现、数据交换、解关联），提供16个QoS策略教程，建立QoS依赖链并分类41条依赖违规规则，开发QoS Guard工具进行离线静态验证。

Result: 提供了概念性见解和具体工具，能够早期检测错误配置，提高ROS 2机器人系统的可靠性和资源效率。

Conclusion: 通过系统化的QoS策略分析和验证工具，解决了ROS 2用户在实际部署中遇到的配置问题，提升了系统可靠性。

Abstract: Robot Operating System 2 (ROS 2) relies on the Data Distribution Service
(DDS), which offers more than 20 Quality of Service (QoS) policies governing
availability, reliability, and resource usage. Yet ROS 2 users lack clear
guidance on safe policy combinations and validation processes prior to
deployment, which often leads to trial-and-error tuning and unexpected runtime
failures. To address these challenges, we analyze DDS Publisher-Subscriber
communication over a life cycle divided into Discovery, Data Exchange, and
Disassociation, and provide a user oriented tutorial explaining how 16 QoS
policies operate in each phase. Building on this analysis, we derive a QoS
dependency chain that formalizes inter-policy relationships and classifies 41
dependency violation rules, capturing constraints that commonly cause
communication failures in practice. Finally, we introduce QoS Guard, a ROS 2
package that statically validates DDS XML profiles offline, flags conflicts,
and enables safe, predeployment tuning without establishing a live ROS 2
session. Together, these contributions give ROS 2 users both conceptual insight
and a concrete tool that enables early detection of misconfigurations,
improving the reliability and resource efficiency of ROS 2 based robotic
systems.

</details>


### [8] [Hierarchical Low-Altitude Wireless Network Empowered Air Traffic Management](https://arxiv.org/abs/2509.03386)
*Ziye Jia,Jia He,Yuanhao Cui,Qiuming Zhu,Ligang Yuan,Fuhui Zhou,Qihui Wu,Dusit Niyato,Zhu Han*

Main category: cs.NI

TL;DR: 本文提出了一种分层低空无线网络（HLWN）框架，通过三维空间离散化和监测机制来管理低空航空交通，保障安全运行和优化资源利用。


<details>
  <summary>Details</summary>
Motivation: 随着低空飞行器的发展日益增多，低空网络的合理设计直接影响航空安全和资源利用效率。现有交通管理面临环境复杂性和飞行器异构性的挑战。

Method: 提出分层低空无线网络（HLWN）框架，采用三维空间离散化和集成无线监测机制，设计低空航空走廊来保障安全运行。发展多维飞行风险评估方法，包括冲突检测和概率碰撞分析，支持异构飞行器的动态避碰。

Result: 该框架能够有效管理复杂环境下的低空航空交通，通过空中走廊设计保障安全运行，并通过风险评估实现动态碰撞避免。

Conclusion: 分层低空无线网络框架为管理低空航空交通提供了有效解决方案，本文还探讨了相关开放问题和未来发展方向，为HLAN发展提供了见解。

Abstract: As the increasing development of low-altitude aircrafts, the rational design
of low-altitude networks directly impacts the aerial safety and resource
utilization. To address the challenges of environmental complexity and aircraft
diversity in the traffic management, we propose a hierarchical low-altitude
wireless network (HLWN) framework. Empowered by the threedimensional spatial
discretization and integrated wireless monitoring mechanisms in HLWN, we design
low-altitude air corridors to guarantee safe operation and optimization.
Besides, we develop the multi-dimensional flight risk assessment through
conflict detection and probabilistic collision analysis, facilitating dynamic
collision avoidance for heterogeneous aircrafts. Finally, the open issues and
future directions are investigated to provide insights into HLAN development.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis](https://arxiv.org/abs/2509.02650)
*Henrique Correia da Fonseca,António Fernandes,Zhao Song,Theodor Cimpeanu,Nataliya Balabanova,Adeela Bashir,Paolo Bova,Alessio Buscemi,Alessandro Di Stefano,Manh Hong Duong,Elias Fernandez Domingos,Ndidi Bianca Ogbo,Simon T. Powers,Daniele Proverbio,Zia Ush Shamszaman,Fernando P. Santos,The Anh Han,Marcus Krellner*

Main category: cs.AI

TL;DR: 程序员在利润与安全问题上往往选择利润，但媒体报道可通过损害企业声誉来促使AI创造者采取安全措施。通过游戏理论模型研究发现，媒体在信息质量可靠、成本合理的条件下能有效促进合作。


<details>
  <summary>Details</summary>
Motivation: 研究媒体报道是否能够作为一种软性监管机制，通过损害AI创造者的声誉来促使他们采取安全措施，以实现AI技术的普遍采用。

Method: 创建自利性创造者和用户的人工群体，通过进化游戏理论进行研究分析。

Result: 媒体确实能够促进创造者与用户之间的合作，但需要满足两个条件：媒体信息质量充分可靠，以及访问媒体或确保安全的成本不能过高。

Conclusion: 媒体通过形成公众意见和让开发者承担责任，可以成为一种强大的软性监管机制，在没有政府正式监管的情况下也能指导AI安全发展。

Abstract: When developers of artificial intelligence (AI) products need to decide
between profit and safety for the users, they likely choose profit.
Untrustworthy AI technology must come packaged with tangible negative
consequences. Here, we envisage those consequences as the loss of reputation
caused by media coverage of their misdeeds, disseminated to the public. We
explore whether media coverage has the potential to push AI creators into the
production of safe products, enabling widespread adoption of AI technology. We
created artificial populations of self-interested creators and users and
studied them through the lens of evolutionary game theory. Our results reveal
that media is indeed able to foster cooperation between creators and users, but
not always. Cooperation does not evolve if the quality of the information
provided by the media is not reliable enough, or if the costs of either
accessing media or ensuring safety are too high. By shaping public perception
and holding developers accountable, media emerges as a powerful soft regulator
-- guiding AI safety even in the absence of formal government oversight.

</details>


### [10] [The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)](https://arxiv.org/abs/2509.02661)
*Andrew Ferguson,Marisa LaFleur,Lars Ruthotto,Jesse Thaler,Yuan-Sen Ting,Pratyush Tiwary,Soledad Villar,E. Paulo Alves,Jeremy Avigad,Simon Billinge,Camille Bilodeau,Keith Brown,Emmanuel Candes,Arghya Chattopadhyay,Bingqing Cheng,Jonathan Clausen,Connor Coley,Andrew Connolly,Fred Daum,Sijia Dong,Chrisy Xiyu Du,Cora Dvorkin,Cristiano Fanelli,Eric B. Ford,Luis Manuel Frutos,Nicolás García Trillos,Cecilia Garraffo,Robert Ghrist,Rafael Gomez-Bombarelli,Gianluca Guadagni,Sreelekha Guggilam,Sergei Gukov,Juan B. Gutiérrez,Salman Habib,Johannes Hachmann,Boris Hanin,Philip Harris,Murray Holland,Elizabeth Holm,Hsin-Yuan Huang,Shih-Chieh Hsu,Nick Jackson,Olexandr Isayev,Heng Ji,Aggelos Katsaggelos,Jeremy Kepner,Yannis Kevrekidis,Michelle Kuchera,J. Nathan Kutz,Branislava Lalic,Ann Lee,Matt LeBlanc,Josiah Lim,Rebecca Lindsey,Yongmin Liu,Peter Y. Lu,Sudhir Malik,Vuk Mandic,Vidya Manian,Emeka P. Mazi,Pankaj Mehta,Peter Melchior,Brice Ménard,Jennifer Ngadiuba,Stella Offner,Elsa Olivetti,Shyue Ping Ong,Christopher Rackauckas,Philippe Rigollet,Chad Risko,Philip Romero,Grant Rotskoff,Brett Savoie,Uros Seljak,David Shih,Gary Shiu,Dima Shlyakhtenko,Eva Silverstein,Taylor Sparks,Thomas Strohmer,Christopher Stubbs,Stephen Thomas,Suriyanarayanan Vaikuntanathan,Rene Vidal,Francisco Villaescusa-Navarro,Gregory Voth,Benjamin Wandelt,Rachel Ward,Melanie Weber,Risa Wechsler,Stephen Whitelam,Olaf Wiest,Mike Williams,Zhuoran Yang,Yaroslava G. Yingling,Bin Yu,Shuwen Yue,Ann Zabludoff,Huimin Zhao,Tong Zhang*

Main category: cs.AI

TL;DR: NSF研讨会报告：探讨数学与物理科学（MPS）领域如何利用AI并为其发展做出贡献，提出双向研究、跨学科社区建设和教育培训三大战略重点


<details>
  <summary>Details</summary>
Motivation: 理解数学与物理科学（天文学、化学、材料研究、数学科学和物理学）如何最好地利用AI并为其未来发展做出贡献，抓住AI与科学紧密结合的关键时刻

Method: 通过NSF研讨会形成社区共识，提出包括双向研究、跨学科社区建设、教育培训三方面的战略活动和优先事项

Result: 形成了MPS社区对AI+MPS发展的综合视角，提出了具体的战略建议和优先事项

Conclusion: 需要资助机构、教育机构和个人研究者共同努力，通过实施提出的战略优先事项，使MPS社区在AI+MPS变革潜力中占据领导地位并充分利用其优势

Abstract: This community paper developed out of the NSF Workshop on the Future of
Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS),
which was held in March 2025 with the goal of understanding how the MPS domains
(Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics)
can best capitalize on, and contribute to, the future of AI. We present here a
summary and snapshot of the MPS community's perspective, as of Spring/Summer
2025, in a rapidly developing field. The link between AI and MPS is becoming
increasingly inextricable; now is a crucial moment to strengthen the link
between AI and Science by pursuing a strategy that proactively and thoughtfully
leverages the potential of AI for scientific discovery and optimizes
opportunities to impact the development of AI by applying concepts from
fundamental science. To achieve this, we propose activities and strategic
priorities that: (1) enable AI+MPS research in both directions; (2) build up an
interdisciplinary community of AI+MPS researchers; and (3) foster education and
workforce development in AI for MPS researchers and students. We conclude with
a summary of suggested priorities for funding agencies, educational
institutions, and individual researchers to help position the MPS community to
be a leader in, and take full advantage of, the transformative potential of
AI+MPS.

</details>


### [11] [Planning with Reasoning using Vision Language World Model](https://arxiv.org/abs/2509.02722)
*Delong Chen,Theo Moutakanni,Willy Chung,Yejin Bang,Ziwei Ji,Allen Bolourchi,Pascale Fung*

Main category: cs.AI

TL;DR: VLWM是一个基于视觉语言的世界模型，通过语言建模在自然视频上进行训练，能够进行语义和时间抽象的动作推理，在视觉规划任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前高层次世界模型在理解和推理具有语义和时间抽象的动作方面仍不成熟，需要开发能够进行有效规划的世界模型。

Method: 使用Vision Language World Model (VLWM)，通过LLM自优化提取目标，学习动作策略和动态模型，支持系统1的反应式计划解码和系统2的基于成本最小化的反思式规划。

Result: 在Visual Planning for Assistance (VPA)基准测试和PlannerArena人工评估中达到最先进性能，系统2比系统1Elo得分提升27%，在RoboVQA和WorldPrediction基准上也优于强VLM基线。

Conclusion: VLWM成功展示了语言基础世界模型在视觉规划任务中的有效性，通过结合反应式和反思式规划实现了优异的性能表现。

Abstract: Effective planning requires strong world models, but high-level world models
that can understand and reason about actions with semantic and temporal
abstraction remain largely underdeveloped. We introduce the Vision Language
World Model (VLWM), a foundation model trained for language-based world
modeling on natural videos. Given visual observations, the VLWM first infers
the overall goal achievements then predicts a trajectory composed of
interleaved actions and world state changes. Those targets are extracted by
iterative LLM Self-Refine conditioned on compressed future observations
represented by Tree of Captions. The VLWM learns both an action policy and a
dynamics model, which respectively facilitates reactive system-1 plan decoding
and reflective system-2 planning via cost minimization. The cost evaluates the
semantic distance between the hypothetical future states given by VLWM
roll-outs and the expected goal state, and is measured by a critic model that
we trained in a self-supervised manner. The VLWM achieves state-of-the-art
Visual Planning for Assistance (VPA) performance on both benchmark evaluations
and our proposed PlannerArena human evaluations, where system-2 improves the
Elo score by +27% upon system-1. The VLWM models also outperforms strong VLM
baselines on RoboVQA and WorldPrediction benchmark.

</details>


### [12] [Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics](https://arxiv.org/abs/2509.02751)
*Matthew Russo,Tim Kraska*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的AI驱动数据分析运行时，结合了语义运算符的优化执行和深度研究系统的灵活性，通过让LLM组件编写和执行优化的语义运算符程序来提高查询性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有语义运算符在大规模数据集上执行成本高、不适合交互式分析的问题，以及深度研究系结构缺乏查询计划优化导致执行效率低的挑战。

Method: 构建了一个原型系统，允许深度研究组件编写和执行优化的语义运算符程序，结合了两种方法的优点。

Result: 在两个基础查询上，该原型系统超过了手工编写的语义运算符程序和开源深度研究系统，相比标准深度研究组件获得了最高1.95倍的F1分数，成本和运行时间节省了最76.8%和72.7%。

Conclusion: 该研究为AI驱动数据分析领域提供了一种有前景的方向，通过结合语义运算符的优化执行和深度研究系统的灵活性，能够在保持高准确性的同时显著提高查询性能。

Abstract: With advances in large language models (LLMs), researchers are creating new
systems that can perform AI-driven analytics over large unstructured datasets.
Recent work has explored executing such analytics queries using semantic
operators -- a declarative set of AI-powered data transformations with natural
language specifications. However, even when optimized, these operators can be
expensive to execute on millions of records and their iterator execution
semantics make them ill-suited for interactive data analytics tasks. In another
line of work, Deep Research systems have demonstrated an ability to answer
natural language question(s) over large datasets. These systems use one or more
LLM agent(s) to plan their execution, process the dataset(s), and iteratively
refine their answer. However, these systems do not explicitly optimize their
query plans which can lead to poor plan execution. In order for AI-driven
analytics to excel, we need a runtime which combines the optimized execution of
semantic operators with the flexibility and more dynamic execution of Deep
Research systems. As a first step towards this vision, we build a prototype
which enables Deep Research agents to write and execute optimized semantic
operator programs. We evaluate our prototype and demonstrate that it can
outperform a handcrafted semantic operator program and open Deep Research
systems on two basic queries. Compared to a standard open Deep Research agent,
our prototype achieves up to 1.95x better F1-score. Furthermore, even if we
give the agent access to semantic operators as tools, our prototype still
achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its
optimized execution.

</details>


### [13] [Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving](https://arxiv.org/abs/2509.02754)
*Mingyi Wang,Jingke Wang,Tengju Ye,Junbo Chen,Kaicheng Yu*

Main category: cs.AI

TL;DR: 这篇论文系统性评估了五个关键的大语言模型模块在自主驾驶运动生成中的可移植性，包括分词器设计、位置嵌入、预训练范式、训练后策略和测试时计算，并在Waymo Sim Agents基准上获得了竞争力结果。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在自主驾驶运动生成领域有着类似的自回归序列建模特征，但对哪些LLM模块真正可移植缺乏系统性理解。

Method: 通过在Waymo Sim Agents基准上进行涉及五个关键LLM模块（分词器设计、位置嵌入、预训练范式、训练后策略、测试时计算）的系统性实验评估。

Result: 当适当适配时，这些LLM模块能够显著提升自主驾驶运动生成的性能，并在Sim Agents任务中取得了竞争力的结果。

Conclusion: 研究识别了可有效移植的技术，分析了某些方法失败的潜在原因，并讨论了自主驾驶场景下所需的特定适配方法。

Abstract: Recent breakthroughs in large language models (LLMs) have not only advanced
natural language processing but also inspired their application in domains with
structurally similar problems--most notably, autonomous driving motion
generation. Both domains involve autoregressive sequence modeling, token-based
representations, and context-aware decision making, making the transfer of LLM
components a natural and increasingly common practice. However, despite
promising early attempts, a systematic understanding of which LLM modules are
truly transferable remains lacking. In this paper, we present a comprehensive
evaluation of five key LLM modules--tokenizer design, positional embedding,
pre-training paradigms, post-training strategies, and test-time
computation--within the context of motion generation for autonomous driving.
Through extensive experiments on the Waymo Sim Agents benchmark, we demonstrate
that, when appropriately adapted, these modules can significantly improve
performance for autonomous driving motion generation. In addition, we identify
which techniques can be effectively transferred, analyze the potential reasons
for the failure of others, and discuss the specific adaptations needed for
autonomous driving scenarios. We evaluate our method on the Sim Agents task and
achieve competitive results.

</details>


### [14] [Plan Verification for LLM-Based Embodied Task Completion Agents](https://arxiv.org/abs/2509.02761)
*Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.AI

TL;DR: 提出基于LLM的迭代验证框架，通过Judge LLM批评和Planner LLM修订来净化任务计划，提高空间连贯性和动作质量


<details>
  <summary>Details</summary>
Motivation: LLM生成的任务计划和人类演示可能包含噪声动作、冗余导航和逻辑错误，影响策略质量

Method: 使用Judge LLM批评动作序列，Planner LLM应用修订，通过自然语言提示实现迭代验证

Result: 在TEACh数据集上达到90%召回率和100%精确度，96.5%序列最多3次迭代收敛，改善时空效率

Conclusion: 为具身AI中的模仿学习提供了可扩展的高质量训练数据生成方法，支持鲁棒纠错行为研究

Abstract: Large language model (LLM) based task plans and corresponding human
demonstrations for embodied AI may be noisy, with unnecessary actions,
redundant navigation, and logical errors that reduce policy quality. We propose
an iterative verification framework in which a Judge LLM critiques action
sequences and a Planner LLM applies the revisions, yielding progressively
cleaner and more spatially coherent trajectories. Unlike rule-based approaches,
our method relies on natural language prompting, enabling broad generalization
across error types including irrelevant actions, contradictions, and missing
steps. On a set of manually annotated actions from the TEACh embodied AI
dataset, our framework achieves up to 90% recall and 100% precision across four
state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout).
The refinement loop converges quickly, with 96.5% of sequences requiring at
most three iterations, while improving both temporal efficiency and spatial
action organization. Crucially, the method preserves human error-recovery
patterns rather than collapsing them, supporting future work on robust
corrective behavior. By establishing plan verification as a reliable LLM
capability for spatial planning and action refinement, we provide a scalable
path to higher-quality training data for imitation learning in embodied AI.

</details>


### [15] [Key Principles in Cross-Domain Hyper-Heuristic Performance](https://arxiv.org/abs/2509.02782)
*Václav Sobotka,Lucas Kletzander,Nysret Musliu,Hana Rudová*

Main category: cs.AI

TL;DR: 这篇论文探索了跨域选择超级质量算法中的低级质量算法集合的策略性转换，通过解决方案接受、重复执行和扰动强度等原则，使平凡的随机选择机制能够超越现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的选择超级质量算法主要关注从预定义集合中适应性选择低级质量算法，而本文重点研究如何构建和策略性转换这个集合本身。

Method: 系统分析基于三个关键原则的转换：解决方案接受、低级质量算法重复执行和扰动强度。在平凡的无偏随机选择机制上展示这些转换的原始效果。

Result: 通过适当的转换构建，平凡的方法在三个具有挑战性的实际领域中超过了所有现有的最先进超级质量算法，并找到了11个新的最佳解。在CHeSC竞赛标准测试中也具有竞争力。

Conclusion: 策略性转换方法不仅能够在跨域测试和实际领域中超越当前最先进方法，还经常能够简化算法设计。

Abstract: Cross-domain selection hyper-heuristics aim to distill decades of research on
problem-specific heuristic search algorithms into adaptable general-purpose
search strategies. In this respect, existing selection hyper-heuristics
primarily focus on an adaptive selection of low-level heuristics (LLHs) from a
predefined set. In contrast, we concentrate on the composition of this set and
its strategic transformations. We systematically analyze transformations based
on three key principles: solution acceptance, LLH repetitions, and perturbation
intensity, i.e., the proportion of a solution affected by a perturbative LLH.
We demonstrate the raw effects of our transformations on a trivial unbiased
random selection mechanism. With an appropriately constructed transformation,
this trivial method outperforms all available state-of-the-art hyper-heuristics
on three challenging real-world domains and finds 11 new best-known solutions.
The same method is competitive with the winner of the CHeSC competition,
commonly used as the standard cross-domain benchmark. Moreover, we accompany
several recent hyper-heuristics with such strategic transformations. Using this
approach, we outperform the current state-of-the-art methods on both the CHeSC
benchmark and real-world domains while often simplifying their designs.

</details>


### [16] [Learning General Policies From Examples](https://arxiv.org/abs/2509.02794)
*Blai Bonet,Hector Geffner*

Main category: cs.AI

TL;DR: 提出了一种基于采样计划泛化的符号学习方法，能够处理百万级状态和数十万特征的大规模问题，解决了现有组合方法无法扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 现有组合学习方法虽然能生成可理解且正确的策略，但无法扩展到大规模问题，只能处理小规模训练实例和特征池。

Method: 使用基于命中集算法的符号学习方法，通过泛化采样计划来学习策略，确保结构终止性和无环性，替代了传统的SAT/ASP方法。

Result: 该方法能够有效处理包含数百万状态和数十万特征的大规模问题，在多个基准测试中表现出良好的可扩展性。

Conclusion: 提出的符号学习方法突破了传统组合方法的规模限制，为大规模规划问题的策略学习提供了有效的解决方案。

Abstract: Combinatorial methods for learning general policies that solve large
collections of planning problems have been recently developed. One of their
strengths, in relation to deep learning approaches, is that the resulting
policies can be understood and shown to be correct. A weakness is that the
methods do not scale up and learn only from small training instances and
feature pools that contain a few hundreds of states and features at most. In
this work, we propose a new symbolic method for learning policies based on the
generalization of sampled plans that ensures structural termination and hence
acyclicity. The proposed learning approach is not based on SAT/ASP, as previous
symbolic methods, but on a hitting set algorithm that can effectively handle
problems with millions of states, and pools with hundreds of thousands of
features. The formal properties of the approach are analyzed, and its
scalability is tested on a number of benchmarks.

</details>


### [17] [Uncertainty-driven Adaptive Exploration](https://arxiv.org/abs/2509.03219)
*Leonidas Bakopoulos,Georgios Chalkiadakis*

Main category: cs.AI

TL;DR: 通过不确定性来决定探索与利用的切换时机的适配性探索框架，在MuJoCo环境中表现更优


<details>
  <summary>Details</summary>
Motivation: 解决适配性探索方法中的关键问题：如何在探索和利用之间适时切换，特别是在需要学习长而复杂动作序列的领域

Method: 提出一个通用的适配性控索框架，利用不确定性来原则性地处理切换问题，可结合内在动机或认知不确定性等任意不确定性测量机制

Result: 在多个MuJoCo环境中，该框架生成的适配性探索策略超过了标准探索方法的表现

Conclusion: 通过不确定性来控制探索-利用切换的方法是有效的，该框架具有通用性且可以包含以往的适配性探索方法

Abstract: Adaptive exploration methods propose ways to learn complex policies via
alternating between exploration and exploitation. An important question for
such methods is to determine the appropriate moment to switch between
exploration and exploitation and vice versa. This is critical in domains that
require the learning of long and complex sequences of actions. In this work, we
present a generic adaptive exploration framework that employs uncertainty to
address this important issue in a principled manner. Our framework includes
previous adaptive exploration approaches as special cases. Moreover, we can
incorporate in our framework any uncertainty-measuring mechanism of choice, for
instance mechanisms used in intrinsic motivation or epistemic uncertainty-based
exploration methods. We experimentally demonstrate that our framework gives
rise to adaptive exploration strategies that outperform standard ones across
several MuJoCo environments.

</details>


### [18] [Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making](https://arxiv.org/abs/2509.03286)
*Prachi Bagave,Marcus Westberg,Marijn Janssen,Aaron Yi Ding*

Main category: cs.AI

TL;DR: 这篇论文提出了一个医疗AI负责制框架，解决相关指南的模糊性，通过三层结构来处理不同的负责制机制，并强调共享依赖和协作的重要性。


<details>
  <summary>Details</summary>
Motivation: 医疗领域AI的负责制问题日益受到关注，但相关指南往往只关注"做什么"而不关注"怎么做"，导致实践知识缺口。不同行为体对负责制的理解和处理方式存在差异，需要一个统一的框架来次次辖。

Method: 通过对负责制概念的深入分析，形成了一个负责制框架，并提供了一个三层结构来处理各种负责制机制。该框架将医疗AI系统的相关规定和机制置于一个一致的负责制体系下。

Result: 论文建立了一个统一的医疗AI负责制框架，能够将相关规定和机制整合到一个一致的体系中。三层结构帮助医疗AI系统的各方参与者根据其行为对机制进行分类。

Conclusion: 医疗AI的决策过程具有共享依赖性，负责制应该通过协作来共同承担。可解释性在促进各方参与者之间的沟通和信息共享中发挥重要作用，进一步推动协作过程。

Abstract: AI is transforming the healthcare domain and is increasingly helping
practitioners to make health-related decisions. Therefore, accountability
becomes a crucial concern for critical AI-driven decisions. Although regulatory
bodies, such as the EU commission, provide guidelines, they are highlevel and
focus on the ''what'' that should be done and less on the ''how'', creating a
knowledge gap for actors. Through an extensive analysis, we found that the term
accountability is perceived and dealt with in many different ways, depending on
the actor's expertise and domain of work. With increasing concerns about AI
accountability issues and the ambiguity around this term, this paper bridges
the gap between the ''what'' and ''how'' of AI accountability, specifically for
AI systems in healthcare. We do this by analysing the concept of
accountability, formulating an accountability framework, and providing a
three-tier structure for handling various accountability mechanisms. Our
accountability framework positions the regulations of healthcare AI systems and
the mechanisms adopted by the actors under a consistent accountability regime.
Moreover, the three-tier structure guides the actors of the healthcare AI
system to categorise the mechanisms based on their conduct. Through our
framework, we advocate that decision-making in healthcare AI holds shared
dependencies, where accountability should be dealt with jointly and should
foster collaborations. We highlight the role of explainability in instigating
communication and information sharing between the actors to further facilitate
the collaborative process.

</details>


### [19] [app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding](https://arxiv.org/abs/2509.03310)
*Evgenii Kniazev,Arseny Kravchenko,Igor Rekun,James Broadhead,Nikita Shamgunov,Pranav Sah,Pratik Nichite,Ivan Yamshchikov*

Main category: cs.AI

TL;DR: app.build是一个开源框架，通过系统化验证和结构化环境改进基于LLM的应用生成，实现了73.3%的可行性率和30%的完美质量评分。


<details>
  <summary>Details</summary>
Motivation: 提高基于大语言模型的应用生成可靠性和质量，解决AI代理系统在生产环境中的可扩展性问题。

Method: 采用多层验证管道、特定技术栈编排和模型无关架构，在三个参考技术栈上实现系统化验证。

Result: 在30个生成任务评估中，综合验证实现73.3%可行性率，30%达到完美质量；开源模型在结构化环境中达到闭源模型80.8%的性能；社区已生成3000多个应用。

Conclusion: 扩展可靠的AI代理需要扩展环境而不仅仅是模型，该工作为生产导向的代理系统提供了实证见解和完整参考实现。

Abstract: We present app.build (https://github.com/appdotbuild/agent/), an open-source
framework that improves LLM-based application generation through systematic
validation and structured environments. Our approach combines multi-layered
validation pipelines, stack-specific orchestration, and model-agnostic
architecture, implemented across three reference stacks. Through evaluation on
30 generation tasks, we demonstrate that comprehensive validation achieves
73.3% viability rate with 30% reaching perfect quality scores, while
open-weights models achieve 80.8% of closed-model performance when provided
structured environments. The open-source framework has been adopted by the
community, with over 3,000 applications generated to date. This work
demonstrates that scaling reliable AI agents requires scaling environments, not
just models -- providing empirical insights and complete reference
implementations for production-oriented agent systems.

</details>


### [20] [Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](https://arxiv.org/abs/2509.03345)
*Yunxin Sun,Abulhair Saparov*

Main category: cs.AI

TL;DR: 该论文提出了InAbHyD数据集来评估大语言模型在归纳和溯因推理方面的能力，发现LLM在简单场景中能进行此类推理，但在复杂世界模型中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前大多数研究只关注演绎推理，而归纳和溯因推理在解决现实问题中同样重要但研究较少，需要系统评估LLM在这方面的能力。

Method: 创建了可编程的合成数据集InAbHyD，包含不完整的世界模型和观察数据，要求智能体产生假设来解释观察结果，并基于奥卡姆剃刀原理提出新的评估指标。

Result: 评估显示LLM在简单场景中能进行归纳和溯因推理，但在复杂世界模型中表现不佳，即使使用上下文学习和RLVR等推理增强技术也难以产生高质量假设。

Conclusion: LLM在归纳和溯因推理方面仍有局限，特别是在处理复杂世界模型时，需要进一步研究提升这方面的推理能力。

Abstract: Reasoning is a core capability in artificial intelligence systems, for which
large language models (LLMs) have recently shown remarkable progress. However,
most work focuses exclusively on deductive reasoning, which is problematic
since other types of reasoning are also essential in solving real-world
problems, and they are less explored. This work focuses on evaluating LLMs'
inductive and abductive reasoning capabilities. We introduce a programmable and
synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example
consists of an incomplete world model and a set of observations. The task for
the intelligent agent is to produce hypotheses to explain observations under
the incomplete world model to solve each reasoning example. We propose a new
metric to evaluate the quality of hypotheses based on Occam's Razor. We
evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs
can perform inductive and abductive reasoning in simple scenarios, but struggle
with complex world models and producing high-quality hypotheses, even with
popular reasoning-enhancing techniques such as in-context learning and RLVR.

</details>


### [21] [Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems](https://arxiv.org/abs/2509.03380)
*Peter J. Bentley,Soo Ling Lim,Fuyuki Ishikawa*

Main category: cs.AI

TL;DR: 本文提出一种基于环境变化触发的底层框架，通过分面概念实现专业化代理的信息隔离，达到零信息泄漏的效果。


<details>
  <summary>Details</summary>
Motivation: 解决当前代理性LLM AI代理存在的问题：仅作为自主聊天机器人，按脚本执行任务，且由不可靠的指挥者控制，导致信息泄漏达83%。

Method: 提出一种底层框架，将AI代理定位于环境中，所有行为都由环境变化触发。引入了分面概念，类似umwelt，不同代理以不同方式感知环境，实现更清晰的信息控制。

Result: 与典型架构相比（有时信息泄漏率达83%），分面代理性AI能够实现零信息泄漏。

Conclusion: 专业化代理在自己的信息小生境中高效工作的概念，可以提高方案的安全性和效率。

Abstract: Agentic LLM AI agents are often little more than autonomous chatbots: actors
following scripts, often controlled by an unreliable director. This work
introduces a bottom-up framework that situates AI agents in their environment,
with all behaviors triggered by changes in their environments. It introduces
the notion of aspects, similar to the idea of umwelt, where sets of agents
perceive their environment differently to each other, enabling clearer control
of information. We provide an illustrative implementation and show that
compared to a typical architecture, which leaks up to 83% of the time,
aspective agentic AI enables zero information leakage. We anticipate that this
concept of specialist agents working efficiently in their own information
niches can provide improvements to both security and efficiency.

</details>


### [22] [ANNIE: Be Careful of Your Robots](https://arxiv.org/abs/2509.03383)
*Yiyang Huang,Zixuan Wang,Zishen Wan,Yapeng Tian,Haobo Xu,Yinhe Han,Yiming Gan*

Main category: cs.AI

TL;DR: 本文首次系统研究了具身AI系统的对抗性安全攻击，基于ISO标准提出了安全违规分类法，开发了ANNIEBench基准测试和ANNIE-Attack攻击框架，在代表性EAI模型上攻击成功率超过50%，揭示了物理AI时代的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言-动作模型在具身AI机器人中的集成，系统面临新的安全风险：受损的VLA模型可将对抗性扰动直接转化为不安全的物理动作。传统机器学习安全方法已不足够，需要研究在物理接地、交互环境中的安全定义、测量和防御机制。

Method: 1) 基于物理约束（分离距离、速度、碰撞边界）形式化安全违规分类法（关键、危险、风险）；2) 开发ANNIEBench基准测试，包含9个安全关键场景和2400个视频-动作序列；3) 提出ANNIE-Attack任务感知对抗框架，使用攻击引导模型将长时程目标分解为帧级扰动。

Result: 在代表性EAI模型上的评估显示，所有安全类别的攻击成功率均超过50%。展示了稀疏和自适应攻击策略，并通过物理机器人实验验证了现实世界影响。

Conclusion: 研究结果揭示了具身AI系统中先前未被充分探索但影响重大的攻击面，强调了物理AI时代安全驱动防御的紧迫需求。

Abstract: The integration of vision-language-action (VLA) models into embodied AI (EAI)
robots is rapidly advancing their ability to perform complex, long-horizon
tasks in humancentric environments. However, EAI systems introduce critical
security risks: a compromised VLA model can directly translate adversarial
perturbations on sensory input into unsafe physical actions. Traditional safety
definitions and methodologies from the machine learning community are no longer
sufficient. EAI systems raise new questions, such as what constitutes safety,
how to measure it, and how to design effective attack and defense mechanisms in
physically grounded, interactive settings. In this work, we present the first
systematic study of adversarial safety attacks on embodied AI systems, grounded
in ISO standards for human-robot interactions. We (1) formalize a principled
taxonomy of safety violations (critical, dangerous, risky) based on physical
constraints such as separation distance, velocity, and collision boundaries;
(2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with
2,400 video-action sequences for evaluating embodied safety; and (3)
ANNIE-Attack, a task-aware adversarial framework with an attack leader model
that decomposes long-horizon goals into frame-level perturbations. Our
evaluation across representative EAI models shows attack success rates
exceeding 50% across all safety categories. We further demonstrate sparse and
adaptive attack strategies and validate the real-world impact through physical
robot experiments. These results expose a previously underexplored but highly
consequential attack surface in embodied AI systems, highlighting the urgent
need for security-driven defenses in the physical AI era. Code is available at
https://github.com/RLCLab/Annie.

</details>


### [23] [sam-llm: interpretable lane change trajectoryprediction via parametric finetuning](https://arxiv.org/abs/2509.03462)
*Zhuo Cao,Yunxiao Shi,Min Xu*

Main category: cs.AI

TL;DR: SAM-LLM是一种混合架构，将大语言模型的上下文推理能力与运动学车道变换模型的物理精度相结合，用于自动驾驶中的可解释车道变换轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统坐标预测方法缺乏物理可解释性和计算效率低的问题，需要一种既能保持预测精度又能提供物理参数解释的轨迹预测方法。

Method: 通过微调LLM输出轨迹模型的核心物理参数而非原始坐标，对于车道保持场景预测离散坐标，对于车道变换则生成增强正弦加速度模型(SAM)的参数，包括横向位移、操纵时长、初始横向速度和纵向速度变化。

Result: 实现了80%的输出尺寸缩减，整体意图预测准确率达到98.73%的state-of-the-art水平，在保持与传统LLM预测器相当性能的同时，显著提升了可解释性和资源效率。

Conclusion: SAM-LLM提供了一种连续、物理合理且计算高效的轨迹模型，在自动驾驶轨迹预测领域实现了性能与可解释性的良好平衡。

Abstract: This work introduces SAM-LLM, a novel hybrid architecture that bridges the
gap between the contextual reasoning of Large Language Models (LLMs) and the
physical precision of kinematic lane change models for autonomous driving. The
system is designed for interpretable lane change trajectory prediction by
finetuning an LLM to output the core physical parameters of a trajectory model
instead of raw coordinates. For lane-keeping scenarios, the model predicts
discrete coordinates, but for lane change maneuvers, it generates the
parameters for an enhanced Sinusoidal Acceleration Model (SAM), including
lateral displacement, maneuver duration, initial lateral velocity, and
longitudinal velocity change. This parametric approach yields a complete,
continuous, and physically plausible trajectory model that is inherently
interpretable and computationally efficient, achieving an 80% reduction in
output size compared to coordinate-based methods. The SAM-LLM achieves a
state-of-the-art overall intention prediction accuracy of 98.73%, demonstrating
performance equivalent to traditional LLM predictors while offering significant
advantages in explainability and resource efficiency.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [24] [On a class of twisted elliptic curve codes](https://arxiv.org/abs/2509.03034)
*Xiaofeng Liu,Jun Zhang,Fang-Wei Fu*

Main category: cs.IT

TL;DR: 本文首次研究扭曲椭圆曲线码(TECCs)，特别关注单扭曲情况。通过Weil微分给出校验矩阵，建立自对偶条件，确定最小距离，并提供MDS、AMDS、自对偶码的实例。最后计算Schur平方维度并证明与ECC/GRS码的非等价性。


<details>
  <summary>Details</summary>
Motivation: 受扭曲广义Reed-Solomon(TGRS)码研究的启发，启动对扭曲椭圆曲线码(TECCs)的研究，探索其在编码理论中的新特性和应用潜力。

Method: 使用Weil微分计算显式给出TECCs的校验矩阵，建立自对偶的充分必要条件，确定最小距离，并通过具体实例验证理论结果。

Result: 成功构建了TECCs的理论框架，给出了MDS、AMDS、自对偶和MDS自对偶码的具体实例，证明了TECCs与ECC/GRS码的非等价性。

Conclusion: 扭曲椭圆曲线码是一类具有独特性质的新编码结构，在自对偶性和最小距离方面表现出良好特性，为编码理论提供了新的研究方向。

Abstract: Motivated by the studies of twisted generalized Reed-Solomon (TGRS) codes, we
initiate the study of twisted elliptic curve codes (TECCs) in this paper. In
particular, we study a class of TECCs with one twist. The parity-check matrices
of the TECCs are explicitly given by computing the Weil differentials. Then the
sufficient and necessary conditions of self-duality are presented. The minimum
distances of the TECCs are also determined. Moreover, examples of MDS, AMDS,
self-dual and MDS self-dual TECCs are given. Finally, we calculate the
dimensions of the Schur squares of TECCs and show the non-equivalence between
TECCs and ECCs/GRS codes.

</details>


### [25] [Successive Cancellation Decoding For General Monotone Chain Polar Codes](https://arxiv.org/abs/2509.03128)
*Zichang Ren,Chunhang Zheng,Dou Li,Yuping Zhao*

Main category: cs.IT

TL;DR: 提出了单调链极化码的通用SC解码策略，支持多终端、非二进制字母表和任意单调链解码，通过概率传播计算图框架实现，时间复杂度在O(NlogN)到O(N^2)之间，并引入了常数时间解码器分叉策略。


<details>
  <summary>Details</summary>
Motivation: 单调链极化码在分布式无损编码中提供了灵活性，但现有SC解码方案面临挑战，需要通用的解码解决方案来处理多终端、非二进制字母表和任意单调链。

Method: 将SC解码任务制定为一系列在极化变换上的推理子任务，基于概率传播原理提出计算图框架，分析变量切换对解码的影响，并引入常数时间解码器分叉策略。

Result: 数值结果表明，所提方案相比经典的懒复制方案具有更优性能，时间复杂度取决于链结构，空间优化不普遍适用。

Conclusion: 提出的解码策略为单调链极化码提供了通用的SC解码解决方案，支持多种配置和高效列表解码，性能优于现有方法。

Abstract: Monotone chain polar codes generalize classical polar codes to multivariate
settings, offering a flexible approach for achieving the entire admissible rate
region in the distributed lossless coding problem. However, this flexibility
also introduces significant challenges for existing successive cancellation
(SC) based decoding schemes. Motivated by the need for a general SC decoding
solution, we present a comprehensive decoding strategy for monotone chain polar
codes that can handle arbitrary numbers of terminals, non-binary alphabets, and
decoding along arbitrary monotone chains. Specifically, we formulate the SC
decoding task as a series of inference subtasks over the polar transform and
propose a computational graph framework based on probability propagation
principles. This approach highlights the impact of variable switching during
decoding and shows that time complexity varies between $O(N\log{N})$ and
$O(N^2)$, depending on the specific chain structure. Moreover, we demonstrate
that the widely used $O(N)$ space optimization is not universally applicable to
monotone chain polar codes, which prompts us to introduce a constant-time
decoder forking strategy based on the proposed logical computation graphs. This
strategy enables time-efficient list decoding without relying on $O(N)$-space
techniques. Numerical results verify the superior performance of the proposed
scheme compared with the classical lazy-copy scheme.

</details>


### [26] [New Bounds for Linear Codes with Applications](https://arxiv.org/abs/2509.03337)
*Liren Lin,Guanghui Zhang,Bocong Chen,Hongwei Liu*

Main category: cs.IT

TL;DR: 本文提出了在已知码字重量的附加条件下，对线性码参数的新约束界限，结合残码技术和经典界限，获得了更严格的码重限制


<details>
  <summary>Details</summary>
Motivation: 经典编码理论界限仅基于n,k,d,q参数，但实际应用中常已知码字重量信息，需要开发包含重量参数w的新界限来获得更精确的码结构限制

Method: 结合残码技术和Singleton、Griesmer等经典界限，推导出显式的不等式关系，链接参数n,k,d,q和w

Result: 获得了比传统界限更严格的码重限制，特别是在接近最小距离或码长的重量范围内，扩大了已知排除重量范围，数值比较显示界限更尖锐

Conclusion: 包含码字重量信息的界限能够显著改进对线性码结构的理解，为MDS码和一般线性码提供更精确的重量分布约束

Abstract: Bounds on linear codes play a central role in coding theory, as they capture
the fundamental trade-off between error-correction capability (minimum
distance) and information rate (dimension relative to length). Classical
results characterize this trade-off solely in terms of the parameters $n$, $k$,
$d$ and $q$. In this work we derive new bounds under the additional assumption
that the code contains a nonzero codeword of weight $w$.By combining
residual-code techniques with classical results such as the Singleton and
Griesmer bounds,we obtain explicit inequalities linking $n$, $k$, $d$, $q$ and
$w$. These bounds impose sharper restrictions on admissible codeword weights,
particularly those close to the minimum distance or to the code length.
Applications include refined constraints on the weights of MDS codes, numerical
restrictions on general linear codes, and excluded weight ranges in the weight
distribution. Numerical comparisons across standard parameter sets demonstrate
that these $w$-aware bounds strictly enlarge known excluded weight ranges and
sharpen structural limitations on linear codes.

</details>


### [27] [PoolPy: Flexible Group Testing Design for Large-Scale Screening](https://arxiv.org/abs/2509.03481)
*Lorenzo Talamanca,Julian Trouillon*

Main category: cs.IT

TL;DR: PoolPy是一个统一框架，用于设计和选择最优的群体检测策略，涵盖10种不同方法，根据用户定义的时间、成本或样本稀释等约束条件进行优化。


<details>
  <summary>Details</summary>
Motivation: 在大规模筛查活动中，群体检测相比单个样本检测可大幅减少检测次数，但由于方法多样、性能差异大且缺乏易用工具，选择和实施合适的群体检测方法仍然具有挑战性。

Method: 开发了PoolPy框架，通过计算超过10,000种群体检测设计方案，并通过Web界面提供，识别关键权衡因素如最小化检测次数或组大小。

Result: 研究发现没有单一方法在所有情况下都是最优的，确定了不同用例的适用性关键权衡因素。

Conclusion: 提供了基于具体案例的方法选择明确指导，强调需要根据特定约束条件选择最适合的群体检测策略。

Abstract: In large screening campaigns, group testing can greatly reduce the number of
tests needed when compared to testing each sample individually. However,
choosing and applying an appropriate group testing method remains challenging
due to the wide variety in design and performance across methods, and the lack
of accessible tools. Here, we present PoolPy, a unified framework for designing
and selecting optimal group testing strategies across ten different methods
according to user-defined constraints, such as time, cost or sample dilution.
By computing over 10,000 group testing designs made available through a web
interface, we identified key trade-offs, such as minimizing test number or
group size, that define applicability to specific use cases. Overall, we show
that no single method is universally optimal, and provide clear indications for
method choice on a case-by-case basis.

</details>
