{"id": "2601.17295", "categories": ["cs.NI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17295", "abs": "https://arxiv.org/abs/2601.17295", "authors": ["Xinyu Zhu", "Parisa Fard Moshiri", "Poonam Lohan", "Burak Kantarci", "Emil Janulewicz"], "title": "Structure-Aware NL-to-SQL for SFC Provisioning via AST-Masking Empowered Language Models", "comment": "6 pages, 3 figures, accepted to IEEE International Conference on Communications (ICC) 2026", "summary": "Effective Service Function Chain (SFC) provisioning requires precise orchestration in dynamic and latency-sensitive networks. Reinforcement Learning (RL) improves adaptability but often ignores structured domain knowledge, which limits generalization and interpretability. Large Language Models (LLMs) address this gap by translating natural language (NL) specifications into executable Structured Query Language (SQL) commands for specification-driven SFC management. Conventional fine-tuning, however, can cause syntactic inconsistencies and produce inefficient queries. To overcome this, we introduce Abstract Syntax Tree (AST)-Masking, a structure-aware fine-tuning method that uses SQL ASTs to assign weights to key components and enforce syntax-aware learning without adding inference overhead. Experiments show that AST-Masking significantly improves SQL generation accuracy across multiple language models. FLAN-T5 reaches an Execution Accuracy (EA) of 99.6%, while Gemma achieves the largest absolute gain from 7.5% to 72.0%. These results confirm the effectiveness of structure-aware fine-tuning in ensuring syntactically correct and efficient SQL generation for interpretable SFC orchestration."}
{"id": "2601.17534", "categories": ["cs.NI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.17534", "abs": "https://arxiv.org/abs/2601.17534", "authors": ["Mounir Bensalem", "Fin Gentzen", "Tuck-Wai Choong", "Yu-Chiao Jhuang", "Admela Jukan", "Jenq-Shiou Leu"], "title": "Efficient Self-Learning and Model Versioning for AI-native O-RAN Edge", "comment": "This paper is uploaded here for research community, thus it is for non-commercial purposes", "summary": "The AI-native vision of 6G requires Radio Access Networks to train, deploy, and continuously refine thousands of machine learning (ML) models that drive real-time radio network optimization. Although the Open RAN (O-RAN) architecture provides open interfaces and an intelligent control plane, it leaves the life-cycle management of these models unspecified. Consequently, operators still rely on ad-hoc, manual update practices that can neither scale across the heterogeneous, multi-layer stack of Cell-Site, Edge-, Regional-, and Central-Cloud domains, nor across the three O-RAN control loops (real-, near-real-, and non-real-time). We present a self-learning framework that provides an efficient closed-loop version management for an AI-native O-RAN edge. In this framework, training pipelines in the Central/Regional Cloud continuously generate new models, which are cataloged along with their resource footprints, security scores, and accuracy metrics in a shared version repository. An Update Manager consults this repository and applies a self-learning policy to decide when and where each new model version should be promoted into operation. A container orchestrator then realizes these decisions across heterogeneous worker nodes, enabling multiple services (rApps, xApps, and dApps) to obtain improved inference with minimal disruption. Simulation results show that an efficient RL-driven decision-making can guarantee quality of service, bounded latencies while balancing model accuracy, system stability, and resilience."}
{"id": "2601.18069", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18069", "abs": "https://arxiv.org/abs/2601.18069", "authors": ["Haoyuan Pan", "Sizhao Chen", "Zhaorui Wang", "Tse-Tin Chan"], "title": "Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control", "comment": "16 pages, 11 figures", "summary": "Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems."}
{"id": "2601.18134", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18134", "abs": "https://arxiv.org/abs/2601.18134", "authors": ["Anshika Singh", "Siddhartha S. Borkotoky"], "title": "Accelerating Update Broadcasts Over LoRaWAN Downlink via D2D Cooperation", "comment": null, "summary": "Broadcast distribution of updates (e.g., security patches, machine learning models) from a server to end devices (EDs) is a critical requirement in the Internet of Things (IoT). In this paper, we consider the problem of reliable over-the-air broadcast of updates in Long Range Wide Area Networks (LoRaWANs). Existing broadcast techniques for LoRaWANs suffer from long delivery delays due to low data rates and duty-cycle constraints. We address this problem by proposing a device-level cooperative mechanism, in which updated EDs broadcast a few update fragments to accelerate delivery to their neighbors. We demonstrate large reductions in the delivery time compared to conventional methods. For instance, in a 400-node network spanning 1 km radius and operating at 1% duty-cycle, the proposed scheme reduces the time required to deliver a 10 kilobyte update to an ED at the network's edge from 42 hours to 45 minutes. The proposed solution thus provides a pathway toward improved security and efficient realization of edge intelligence in LoRaWAN IoT."}
{"id": "2601.17187", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17187", "abs": "https://arxiv.org/abs/2601.17187", "authors": ["Or Ordentlich", "Yury Polyanskiy"], "title": "High-Rate Quantized Matrix Multiplication: Theory and Practice", "comment": null, "summary": "This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $Σ_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $Σ_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\\frac{2πe}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $Σ_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization)."}
{"id": "2601.18148", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18148", "abs": "https://arxiv.org/abs/2601.18148", "authors": ["Jason Gerard", "Juan A. Fraire", "Sandra Cespedes"], "title": "Contact Plan Design For Optical Interplanetary Communications", "comment": null, "summary": "Space exploration missions generate rapidly increasing volumes of scientific telemetry that far exceed the capacity of today's manually scheduled, RF-based deep-space infrastructure. Free-space optical (FSO) communications promise orders of magnitude higher throughput, but their narrow beams require precise pointing, acquisition, and tracking (PAT) for link establishment and tightly synchronized contact schedules. Critically, no existing contact plan design (CPD) framework accounts for optical head retargeting delay, the time spent during coarse pointing and link acquisition before data transmission begins, which directly reduces usable contact time. Retargeting delay is the dominant impairment unique to optical networks, which induces a seconds-to-minutes-long mechanical pointing process for an optical terminal's laser from its current partner to the next receiver. This paper introduces the first PAT-aware CPD framework for optical interplanetary backhaul networks. The model captures directional temporal flows across both direct-to-Earth optical links and two-hop relay paths using delay/disruption-tolerant networking (DTN) satellites. We also introduce an optical network duty-cycle metric that quantifies the proportion of time spent transmitting to the contact window duration, exposing capacity lost to retargeting delay. Our results show that our MILP scheduler delivers over 30 percent higher network capacity than a greedy algorithm. More importantly, the results uncover a fundamental behavioral shift: when retargeting delays are modeled accurately, optimal schedules favor fewer but longer optical links that maximize throughput while minimizing retargeting overhead. These findings demonstrate that zero-delay assumptions substantially overestimate achievable performance and yield unrealistic contact plans."}
{"id": "2601.17423", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.17423", "abs": "https://arxiv.org/abs/2601.17423", "authors": ["Yasaman Khorsandmanesh", "Emil Bjornson", "Joakim Jalden"], "title": "Joint Uplink-Downlink Fronthaul Bit Allocation in Fronthaul-Limited Massive MU-MIMO Systems", "comment": "To be presented at the ICC 2026 in the wireless communication symposium", "summary": "This paper optimizes the fronthaul bit allocation in massive multi-user multiple-input multiple-output (MU-MIMO) systems operating with limited-capacity fronthaul links. We consider an advanced antenna system (AAS) controlled by a centralized baseband unit (BBU). In the AAS, multiple antenna elements together with their radio units are integrated into a single unit. In this setup, a key challenge is allocating fronthaul bits between uplink channel state information (CSI) quantization and downlink precoding matrix quantization. We formulate the problem of maximizing the sum spectral efficiency (SE) for a given fronthaul capacity. We develop an SE expression for this scenario based on the hardening bound. We compute the expression in closed form for maximum ratio transmission, which reveals the relative impact of the two types of quantization distortion. We then formulate a bit split optimization problem and propose an algorithm that exactly solves it.\n  Numerical results demonstrate how the relative importance of assigning bits to CSI and precoding varies depending on the signal-to-noise ratio."}
{"id": "2601.18256", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18256", "abs": "https://arxiv.org/abs/2601.18256", "authors": ["Akihito Taya", "Yuuki Nishiyama", "Kaoru Sezaki"], "title": "A Mechanical Wi-Fi Antenna Device for Automatic Orientation Tuning with Bayesian Optimization", "comment": "(c) 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "summary": "Wi-Fi access points have been widely deployed in homes, offices, and public spaces. Some APs allow users to adjust the antenna orientation to improve communication performance by optimizing antenna polarization. However, it is difficult for non-expert users to determine the optimal orientation, and users often leave the antenna orientation in ineffective positions. To address this issue, we developed a mechanical Wi-Fi antenna device capable of automatically tuning its orientation. Experimental results show that antenna orientation could cause a throughput variation of approximately 70 Mbps under line-of-sight conditions. Furthermore, Bayesian optimization identified better configurations than random search, demonstrating its effectiveness for orientation tuning."}
{"id": "2601.17508", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.17508", "abs": "https://arxiv.org/abs/2601.17508", "authors": ["Binghong Wu", "Pascal O. Vontobel"], "title": "Double-Cover-Based Analysis of the Bethe Permanent of Block-Structured Positive Matrices", "comment": null, "summary": "We consider the permanent of a square matrix with non-negative entries. A tractable approximation is given by the so-called Bethe permanent that can be efficiently computed by running the sum-product algorithm on a suitable factor graph. While the ratio of the permanent of a matrix to its Bethe permanent is, in the worst case, upper and lower bounded by expressions that are exponentially far apart in the matrix size, in practice it is observed for many ensembles of matrices of interest that this ratio is strongly concentrated around some value that depends only on the matrix size. In this paper, for an ensemble of block-structured matrices where entries in a block take the same value, we numerically study the ratio of the permanent of a matrix to its Bethe permanent. It is observed that also for this ensemble the ratio is strongly concentrated around some value depending only on a few key parameters of the ensemble. We use graph-cover-based approaches to explain the reasons for this behavior and to quantify the observed value."}
{"id": "2601.18315", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18315", "abs": "https://arxiv.org/abs/2601.18315", "authors": ["Zhaozhi Liu", "Jiaxin Chen", "Yuanai Xie", "Yuna Jiang", "Minrui Xu", "Xiao Zhang", "Pan Lai", "Zan Zhou"], "title": "CovertComBench: The First Domain-Specific Testbed for LLMs in Wireless Covert Communication", "comment": "6pages", "summary": "The integration of Large Language Models (LLMs) into wireless networks presents significant potential for automating system design. However, unlike conventional throughput maximization, Covert Communication (CC) requires optimizing transmission utility under strict detection-theoretic constraints, such as Kullback-Leibler divergence limits. Existing benchmarks primarily focus on general reasoning or standard communication tasks and do not adequately evaluate the ability of LLMs to satisfy these rigorous security constraints. To address this limitation, we introduce CovertComBench, a unified benchmark designed to assess LLM capabilities across the CC pipeline, encompassing conceptual understanding (MCQs), optimization derivation (ODQs), and code generation (CGQs). Furthermore, we analyze the reliability of automated scoring within a detection-theoretic ``LLM-as-Judge'' framework. Extensive evaluations across state-of-the-art models reveal a significant performance discrepancy. While LLMs achieve high accuracy in conceptual identification (81%) and code implementation (83%), their performance in the higher-order mathematical derivations necessary for security guarantees ranges between 18% and 55%. This limitation indicates that current LLMs serve better as implementation assistants rather than autonomous solvers for security-constrained optimization. These findings suggest that future research should focus on external tool augmentation to build trustworthy wireless AI systems."}
{"id": "2601.17632", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.17632", "abs": "https://arxiv.org/abs/2601.17632", "authors": ["Saeed Mashdour", "Saeed Mohammadzadeh", "André R. Flores", "Shirin Salehi", "Rodrigo C. de Lamare", "Anke Schmeink"], "title": "Study of Robust Power Allocation for User-Centric Cell-Free Massive MIMO Networks", "comment": "6 pages, 2 figures", "summary": "In cell-free massive multiple-input multiple-output (MIMO) networks, robust resource allocation is critical to ensure reliable system performance in the presence of channel uncertainties resulting from imperfect channel state information (CSI). In this work, we propose a robust power allocation method that formulates the power optimization problem into a least-squares framework, enhanced by Tikhonov regularization to mitigate the adverse effects of channel estimation errors. We integrate our approach with zero-forcing precoding, enabling a design that is both computationally efficient and resilient to CSI imperfections. Numerical results indicate that the proposed method outperforms existing non-robust techniques while benefiting from low computational overhead, making it well-suited for large-scale deployments under CSI uncertainty."}
{"id": "2601.17009", "categories": ["cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.17009", "abs": "https://arxiv.org/abs/2601.17009", "authors": ["Yanhua Zhao"], "title": "Online parameter estimation for the Crazyflie quadcopter through an EM algorithm", "comment": "20 pages, 37 figures", "summary": "Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation."}
{"id": "2601.18361", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18361", "abs": "https://arxiv.org/abs/2601.18361", "authors": ["Jean Michel de Souza Sant'Ana", "Felipe Augusto Tondo", "Nurul Huda Mahmood", "Aamir Mahmood"], "title": "Integrating HAPS, LEO, and Terrestrial Networks: A Cost-Performance Study for IoT Connectivity", "comment": "10 pages, 6 figures. Submitted to the IEEE Transactions on Aerospace and Electronic Systems", "summary": "This work evaluates the potential of High-Altitude Platform Stations (HAPS) and Low Earth Orbit (LEO) satellites as alternative or complementary systems to enhance Internet of Things (IoT) connectivity. We first analyze the transmission erasure probability under different connectivity configurations, including only HAPS or LEO satellites, as well as hybrid architectures that integrate both aerial/spatial and terrestrial infrastructures. To make the analysis more realistic, we considered movement of LEO satellites regarding a fixed region, elevation angle between gateway and devices, and different fading models for terrestrial and non-terrestrial communication. We also analyze LR-FHSS (Long-Range Frequency Hopping Spread Spectrum) random access uplink technology as a potential use case for IoT connectivity, showing the scalability impact of the scenarios. The simulation results demonstrate that HAPS can effectively complement sparse terrestrial networks and improve the performance of satellite-based systems in specific scenarios. Furthermore, considering the deployment and operational costs, respectively, CAPEX and OPEX, the economic analysis reveals that although HAPS exhibits higher costs, these remain within a comparable order of magnitude to LEO and terrestrial deployments. In addition, specific use cases, such as natural disasters, transform HAPS into a competitive technology for conventional infrastructures."}
{"id": "2601.17684", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17684", "abs": "https://arxiv.org/abs/2601.17684", "authors": ["Cordelia Hu", "Jennifer Tang"], "title": "A Model-Driven Lossless Compression Algorithm Resistant to Mismatch", "comment": "10 pages, 5 figure. Submitted to ISIT 2026. This is a follow-up to the following paper: arXiv:2601.10678", "summary": "Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism.\n  In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods."}
{"id": "2601.18175", "categories": ["cs.AI", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18175", "abs": "https://arxiv.org/abs/2601.18175", "authors": ["Daniel Russo"], "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success", "comment": null, "summary": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective."}
{"id": "2601.17009", "categories": ["cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.17009", "abs": "https://arxiv.org/abs/2601.17009", "authors": ["Yanhua Zhao"], "title": "Online parameter estimation for the Crazyflie quadcopter through an EM algorithm", "comment": "20 pages, 37 figures", "summary": "Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation."}
{"id": "2601.18563", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18563", "abs": "https://arxiv.org/abs/2601.18563", "authors": ["Fang Liu", "Erchao Zhu", "Jiedan Tan", "Jingwen Tong", "Taotao Wang", "Shengli Zhang"], "title": "An LLM-Agent-Based Framework for Age of Information Optimization in Heterogeneous Random Access Networks", "comment": null, "summary": "With the rapid expansion of the Internet of Things (IoT) and heterogeneous wireless networks, the Age of Information (AoI) has emerged as a critical metric for evaluating the performance of real-time and personalized systems. While AoI-based random access is essential for next-generation applications such as the low-altitude economy and indoor service robots, existing strategies, ranging from rule-based protocols to learning-based methods, face critical challenges, including idealized model assumptions, slow convergence, and poor generalization. In this article, we propose Reflex-Core, a novel Large Language Model (LLM) agent-based framework for AoI-driven random access in heterogeneous networks. By devising an \"Observe-Reflect-Decide-Execute\" closed-loop mechanism, this framework integrates Supervised Fine-Tuning (SFT) and Proximal Policy Optimization (PPO) to enable optimal, autonomous access control. Based on the Reflex-Core framework, we develop a Reflexive Multiple Access (RMA) protocol and a priority-based RMA variant for intelligent access control under different heterogeneous network settings. Experimental results demonstrate that in the investigated scenarios, the RMA protocol achieves up to a 14.9% reduction in average AoI compared with existing baselines, while the priority-based version improves the convergence rate by approximately 20%."}
{"id": "2601.17809", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.17809", "abs": "https://arxiv.org/abs/2601.17809", "authors": ["Xuejian Zhang", "Ruisi He", "Mi Yang", "Zhengyu Zhang", "Ziyi Qi"], "title": "A Multi-Modal Fusion Platform for Joint Environment Sensing and Channel Sounding in Highly Dynamic Scenarios", "comment": null, "summary": "6G system is evolving toward full-spectrum coverage,ultra-wide bandwidth, and high mobility, resulting in increasingly complex propagation environments. The deep integration of communication and sensing is widely recognized as a core 6G vision, underscoring the importance of comprehensive environment awareness. Accurate channel modeling forms the foundation of 6G system design and optimization, and channel sounders provide the essential empirical basis. However, existing channel sounders, although supporting wide bandwidth and large antenna arrays in selected bands, generally lack cross-band capability, struggle in dynamic scenarios, and provide limited environmental awareness. The absence of detailed environmental information restricts the development of environment-aware channel models. To address this gap, we propose a multi-modal sensing and channel sounding fusion platform that enables temporally and spatially synchronized acquisition of images, point clouds, geolocation information, and multi-band multi-antenna channel data. The modular architecture facilitates rapid deployment in diverse dynamic environments. The platform supports Sub-6 GHz and mmWave bands with up to 1 GHz bandwidth and 1 ns delay resolution, enabling multi-antenna measurements with a channel switching rate of 8 ms. Moreover, it achieves centimeter-level and 360° environmental sensing accuracy and meter-level positioning accuracy. Key performance metrics of the platform, including dynamic range, phase stability, delay resolution, and multimodal data synchronization, are validated through vehicle-to-infrastructure measurement campaign. The established platform supports environment-channel joint modeling, enabling analysis and optimization of channel models in dynamic 6G scenarios."}
{"id": "2601.18308", "categories": ["cs.AI", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18308", "abs": "https://arxiv.org/abs/2601.18308", "authors": ["Geunsik Lim"], "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience", "comment": "19 pages", "summary": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures."}
{"id": "2601.17168", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.17168", "abs": "https://arxiv.org/abs/2601.17168", "authors": ["Judy Zhu", "Dhari Gandhi", "Himanshu Joshi", "Ahmad Rezaie Mianroodi", "Sedef Akinli Kocak", "Dhanesh Ramachandran"], "title": "Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability", "comment": null, "summary": "Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems."}
{"id": "2601.18670", "categories": ["cs.NI", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.18670", "abs": "https://arxiv.org/abs/2601.18670", "authors": ["Yulong Zhang", "Ying Cui", "Zili Meng", "Abhishek Kumar", "Dirk Kutscher"], "title": "COMETS: Coordinated Multi-Destination Video Transmission with In-Network Rate Adaptation", "comment": "Accepted to appear in IEEE Transactions on Multimedia (2026)", "summary": "Large-scale video streaming events attract millions of simultaneous viewers, stressing existing delivery infrastructures. Client-driven adaptation reacts slowly to shared congestion, while server-based coordination introduces scalability bottlenecks and single points of failure. We present COMETS, a coordinated multi-destination video transmission framework that leverages information-centric networking principles such as request aggregation and in-network state awareness to enable scalable, fair, and adaptive rate control. COMETS introduces a novel range-interest protocol and distributed in-network decision process that aligns video quality across receiver groups while minimizing redundant transmissions. To achieve this, we develop a lightweight distributed optimization framework that guides per-hop quality adaptation without centralized control. Extensive emulation shows that COMETS consistently improves bandwidth utilization, fairness, and user-perceived quality of experience over DASH, MoQ, and ICN baselines, particularly under high concurrency. The results highlight COMETS as a practical, deployable approach for next-generation scalable video delivery."}
{"id": "2601.17834", "categories": ["cs.IT", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17834", "abs": "https://arxiv.org/abs/2601.17834", "authors": ["Christoph Hofmeister", "Razane Tajeddine", "Antonia Wachter-Zeh", "Rawad Bitar"], "title": "On the Extension of Private Distributed Matrix Multiplication Schemes to the Grid Partition", "comment": null, "summary": "We consider polynomial codes for private distributed matrix multiplication (PDMM/SDMM). Existing codes for PDMM are either specialized for the outer product partitioning (OPP), or inner product partitioning (IPP), or are valid for the more general grid partitioning (GP). We design extension operations that can be applied to a large class of OPP code designs to extend them to the GP case. Applying them to existing codes improves upon the state-of-the-art for certain parameters. Additionally, we show that the GP schemes resulting from extension fulfill additional combinatorial constraints, potentially limiting their performance. We illustrate this point by presenting a new GP scheme that does not adhere to these constraints and outperforms the state-of-the-art for a range of parameters."}
{"id": "2601.17188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17188", "abs": "https://arxiv.org/abs/2601.17188", "authors": ["Swapn Shah", "Wlodek Zadrozny"], "title": "Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction", "comment": null, "summary": "The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples."}
{"id": "2601.18727", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.18727", "abs": "https://arxiv.org/abs/2601.18727", "authors": ["Skanda Harisha", "Jimmy G. D. Hester", "Aline Eid"], "title": "An ISAC-ready Full-Duplex Backscatter Architecture for the mmWave IoT", "comment": null, "summary": "Achieving long-range, high-rate, concurrent two-way mmWave communication with power-constrained IoT devices is fundamental to scaling future ubiquitous sensing systems, yet the substantial power demands and high cost of mmWave hardware have long stood in the way of practical deployment. This paper presents the first mmWave full-duplex backscatter tag architecture, charting a genuinely low-cost path toward high-performance mmWave connectivity and localization for ISAC systems. The proposed tag operates at ranges beyond 45m on the uplink and beyond 200m on the downlink, delivering 20x the reach of state-of-the-art systems while being over 100x cheaper than existing mmWave backscatter platforms. Enabling this leap is a novel low-power regenerative amplifier that provides 30 dB of gain while consuming only 30 mW, paired with a regenerative rectifier that achieves state-of-the-art sensitivity down to -60 dBm. We integrate our circuits on a compact PCB and evaluate it across diverse uplink and downlink scenarios, where it achieves an downlink BER of $10^{-1}$ at 200 meters and a uplink BER of $10^{-2}$ at 45 meters, demonstrating resilient, high-quality communication even at extended ranges."}
{"id": "2601.17838", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.17838", "abs": "https://arxiv.org/abs/2601.17838", "authors": ["Jiuyu Liu", "Yi Ma", "Rahim Tafazolli"], "title": "Phase-Rotated Symbol Spreading for Scalable Rydberg Atomic-MIMO Detection", "comment": "This work has been accepted by IEEE Wireless Communications Letters", "summary": "Multiple-input multiple-output (MIMO) systems using Rydberg atomic (RA) receivers face significant scalability challenges in signal detection due to their nonlinear signal models. This letter proposes phase-rotated symbol spreading (PRSS), which transmits each symbol across two consecutive time slots with an optimal π/2 phase offset. PRSS enables reconstruction of an effective linear signal model while maintaining spectral efficiency and facilitating the use of conventional RF-MIMO detection algorithms. Simulation results demonstrate that PRSS achieves greater than 2.5 dB and 10 dB bit error rate improvements compared to current single-transmission methods when employing optimal exhaustive search and low-complexity sub-optimal detection methods, respectively."}
{"id": "2601.17310", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17310", "abs": "https://arxiv.org/abs/2601.17310", "authors": ["Yu Akagi", "Tomohisa Seki", "Hiromasa Ito", "Toru Takiguchi", "Kazuhiko Ohe", "Yoshimasa Kawazoe"], "title": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data", "comment": null, "summary": "Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care."}
{"id": "2601.17970", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.17970", "abs": "https://arxiv.org/abs/2601.17970", "authors": ["Xiang Zhang", "Zhou Li", "Shuangyang Li", "Kai Wan", "Derrick Wing Kwan Ng", "Giuseppe Caire"], "title": "Information-Theoretic Secure Aggregation in Decentralized Networks", "comment": "Accepted by IEEE International Conference on Communications (ICC) 2026. arXiv admin note: substantial text overlap with arXiv:2508.00596. substantial text overlap with arXiv:2508.00596. substantial text overlap with arXiv:2508.00596. substantial text overlap with arXiv:2508.00596", "summary": "Motivated by the increasing demand for data security in decentralized federated learning (FL) and stochastic optimization, we formulate and investigate the problem of information-theoretic \\emph{decentralized secure aggregation} (DSA). Specifically, we consider a network of $K$ interconnected users, each holding a private input, representing, for example, local model updates in FL, who aim to simultaneously compute the sum of all inputs while satisfying the security requirement that no user, even when colluding with up to $T$ others, learns anything beyond the intended sum. We characterize the optimal rate region, which specifies the minimum achievable communication and secret key rates for DSA. In particular, we show that to securely compute one bit of the desired input sum, each user must (i) transmit at least one bit to all other users, (ii) hold at least one bit of secret key, and (iii) all users must collectively hold no fewer than $K - 1$ independent key bits. Our result establishes the fundamental performance limits of DSA and offers insights into the design of provably secure and communication-efficient protocols for distributed learning systems."}
{"id": "2601.17311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17311", "abs": "https://arxiv.org/abs/2601.17311", "authors": ["Bang Liu", "Linglong Kong", "Jian Pei"], "title": "Phase Transition for Budgeted Multi-Agent Synergy", "comment": "55 pages, 12 figures", "summary": "Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling."}
{"id": "2601.18063", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18063", "abs": "https://arxiv.org/abs/2601.18063", "authors": ["Tian Zhang", "Zhirong Su", "Yueyi Dong"], "title": "Secure Beamforming and Reflection Design for RIS-ISAC Systems under Collusion of Passive and Active Eavesdroppers", "comment": "10 pages, 7 figures", "summary": "In the paper, the physical-layer security for reconfigurable intelligent surface (RIS) aided integrated sensing and communication (ISAC) system is studied. There is an active eavesdropper (AE) as well as a passive eavesdropper (PE), and they cooperate each other. By joint base station beamforming and RIS reflection design, we aim to achieve the best secure data communications with guaranteed sensing performance. Mathematically, taking the constraints on sensing performance and transmission power in consideration, the system secrecy rate maximization problem is formulated with respect to transmitting beamforming, RIS reflection, and receiving beamforming. The formulated problem is non-convex and is decomposed to three subproblem by applying the alternating optimization scheme. For the decomposed subproblem, we utilize the quadratic penalty method and successive convex approximation (SCA) for the solution derivation. Thereafter, an iterative numerical algorithm, referred to as the joint beamforming and reflection design (JBRD) algorithm, is proposed. Finally, numerical results demonstrate the effectiveness and superiority of the proposed algorithm."}
{"id": "2601.17332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17332", "abs": "https://arxiv.org/abs/2601.17332", "authors": ["Yicheng Tao", "Hongteng Xu"], "title": "TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow", "comment": null, "summary": "The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \\textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \\textit{statement formalization}, \\textit{proof generation}, \\textit{premise selection}, \\textit{proof correction} and \\textit{proof sketching}. By implementing a \\textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\\%, surpassing the 8.6\\% baseline, at an average cost of only \\textbf{\\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \\textbf{1.6$\\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \\href{https://github.com/timechess/TheoremForge}{here}."}
{"id": "2601.18097", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18097", "abs": "https://arxiv.org/abs/2601.18097", "authors": ["Yushen Lin", "Zhiguo Ding"], "title": "Tail-Latency-Aware Federated Learning with Pinching Antenna: Latency, Participation, and Placement", "comment": null, "summary": "Straggler synchronization is a dominant wall-clock bottleneck in synchronous wireless federated learning (FL). Under non-IID data, however, aggressively sampling only fast clients may significantly slow convergence due to statistical heterogeneity. This paper studies PASS-enabled FL, where a radiating pinching antenna (PA) can be activated at an arbitrary position along a dielectric waveguide to reshape uplink latencies. We consider a joint optimization of PA placement and client participation to minimize the expected time-to-accuracy, coupling the exact expected maximum round latency via order statistics with a heterogeneity-aware convergence factor. We derive first-order optimality conditions that reveal an explicit tail-latency premium in the KKT recursion, quantifying how latency gaps are amplified by maximum-order-statistic synchronization. Under a latency-class structure, we obtain a within-class square-root sampling law and establish a two-class phase transition where slow-class participation collapses under an explicit heterogeneity-threshold condition as the per-round sample size grows. For PA placement, we prove a piecewise envelope-derivative characterization and provide an exact breakpoint-and-root candidate-enumeration procedure. Simulation results verify the theoretical findings and show that PASS enables more eligible participation, yielding higher wall-clock accuracy."}
{"id": "2601.17335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17335", "abs": "https://arxiv.org/abs/2601.17335", "authors": ["Angshul Majumdar"], "title": "The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability", "comment": null, "summary": "We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence."}
{"id": "2601.18198", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18198", "abs": "https://arxiv.org/abs/2601.18198", "authors": ["Le Tung Giang", "Nguyen Xuan Tung", "Trinh Van Chien", "Lajos Hanzo", "Won-Joo Hwang"], "title": "Scalable Quantum Message Passing Graph Neural Networks for Next-Generation Wireless Communications: Architectures, Use Cases, and Future Directions", "comment": "8 pages, 3 figures, and 3 tables. Submitted for publication", "summary": "Graph Neural Networks (GNNs) are eminently suitable for wireless resource management, thanks to their scalability, but they still face computational challenges in large-scale, dense networks in classical computers. The integration of quantum computing with GNNs offers a promising pathway for enhancing computational efficiency because they reduce the model complexity. This is achieved by leveraging the quantum advantages of parameterized quantum circuits (PQCs), while retaining the expressive power of GNNs. However, existing pure quantum message passing models remain constrained by the limited number of qubits, hence limiting the scalability of their application to the wireless systems. As a remedy, we conceive a Scalable Quantum Message Passing Graph Neural Network (SQM-GNN) relying on a quantum message passing architecture. To address the aforementioned scalability issue, we decompose the graph into subgraphs and apply a shared PQC to each local subgraph. Importantly, the model incorporates both node and edge features, facilitating the full representation of the underlying wireless graph structure. We demonstrate the efficiency of SQM GNN on a device-to-device (D2D) power control task, where it outperforms both classical GNNs and heuristic baselines. These results highlight SQM-GNN as a promising direction for future wireless network optimization."}
{"id": "2601.17343", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17343", "abs": "https://arxiv.org/abs/2601.17343", "authors": ["Wei Liu", "Haomei Xu", "Hongkai Liu", "Zhiying Deng", "Ruixuan Li", "Heng Huang", "Yee Whye Teh", "Wee Sun Lee"], "title": "Are We Evaluating the Edit Locality of LLM Model Editing Properly?", "comment": null, "summary": "Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities."}
{"id": "2601.18232", "categories": ["cs.IT", "math.CO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.18232", "abs": "https://arxiv.org/abs/2601.18232", "authors": ["Junda Zhou", "Pascal O. Vontobel"], "title": "Complex-Valued-Matrix Permanents: SPA-based Approximations and Double-Cover Analysis", "comment": null, "summary": "Approximating the permanent of a complex-valued matrix is a fundamental problem with applications in Boson sampling and probabilistic inference. In this paper, we extend factor-graph-based methods for approximating the permanent of non-negative-real-valued matrices that are based on running the sum-product algorithm (SPA) on standard normal factor graphs, to factor-graph-based methods for approximating the permanent of complex-valued matrices that are based on running the SPA on double-edge normal factor graphs.\n  On the algorithmic side, we investigate the behavior of the SPA, in particular how the SPA fixed points change when transitioning from real-valued to complex-valued matrix ensembles. On the analytical side, we use graph covers to analyze the Bethe approximation of the permanent, i.e., the approximation of the permanent that is obtained with the help of the SPA.\n  This combined algorithmic and analytical perspective provides new insight into the structure of Bethe approximations in complex-valued problems and clarifies when such approximations remain meaningful beyond the non-negative-real-valued settings."}
{"id": "2601.17346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17346", "abs": "https://arxiv.org/abs/2601.17346", "authors": ["Haoxin Xu", "Changyong Qi", "Tong Liu", "Bohao Zhang", "Anna He", "Bingqian Jiang", "Longwei Zheng", "Xiaoqing Gu"], "title": "Multi-Agent Learning Path Planning via LLMs", "comment": null, "summary": "The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs."}
{"id": "2601.18298", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.18298", "abs": "https://arxiv.org/abs/2601.18298", "authors": ["Wei Jiang", "Hans D. Schotten"], "title": "A Heterogeneous Massive MIMO Technique for Uniform Service in Cellular Networks", "comment": null, "summary": "Traditional cellular networks struggle with poor quality of service (QoS) for cell-edge users, while cell-free (CF) systems offer uniform QoS but incur high roll-out costs due to acquiring numerous access point (AP) sites and deploying a large-scale optical fiber network to connect them. This paper proposes a cost-effective heterogeneous massive MIMO architecture that integrates centralized co-located antennas at a cell-center base station with distributed edge APs. By strategically splitting massive antennas between centralized and distributed nodes, the system maintains high user fairness comparable to CF systems but reduces infrastructure costs substantially, by minimizing the required number of AP sites and fronthaul connections. Numerical results demonstrate its superiority in balancing performance and costs compared to cellular and CF systems."}
{"id": "2601.17348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17348", "abs": "https://arxiv.org/abs/2601.17348", "authors": ["Srikant Panda", "Sourabh Singh Yadav", "Palkesh Malviya"], "title": "Auditing Disability Representation in Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts."}
{"id": "2601.18410", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18410", "abs": "https://arxiv.org/abs/2601.18410", "authors": ["Yanmin Wang", "Wei Feng", "Yunfei Chen", "Yongxu Zhu", "Shidong Zhou", "Cheng-Xiang Wang"], "title": "Time-Scale-Adaptable Spectrum Sharing for Hybrid Satellite-Terrestrial Networks", "comment": null, "summary": "Cooperation between satellite and terrestrial wireless networks promises great potential in meeting fast-growing demands for ubiquitous communications coverage. To tackle spectrum scarcity, spectrum sharing is studied for a hybrid satellite-terrestrial network where satellite links share the same group of time-slotted sub-carriers with terrestrial links opportunistically. In particular, with coarse network-wide time synchronization, a time-scale-adaptable spectrum sharing framework is proposed based on a satellite-terrestrial cooperation time scale that can be flexibly adjusted according to practical requirements. For generality, it is assumed that both full and partial frequency reuse could be adopted among the base stations (BSs) and satellite selection is supported when multiple satellites are available. Relying on only statistical channel state information (CSI), joint link scheduling and power control are explored to maximize the average sum rate of the network while ensuring quality of service (QoS) for users. To solve the complicated mixed integer programming (MIP) problem, a low-complexity spectrum sharing scheme is presented based on link-feature-sketching-aided hierarchical link clustering and Monte-Carlo-and-successive-approximation-aided transmit power optimization. Simulation results demonstrate that by link feature sketching, diversity of the links brought by the spatial distribution of the users could be well utilized. The proposed scheme promises a significant performance gain even under strict inter-link interference constraints."}
{"id": "2601.17426", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.17426", "abs": "https://arxiv.org/abs/2601.17426", "authors": ["Zhengqing Zang", "Yuqi Ding", "Yanmei Gu", "Changkai Song", "Zhengkai Yang", "Guoping Du", "Junbo Zhao", "Haobo Wang"], "title": "A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models", "comment": null, "summary": "Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning."}
{"id": "2601.18440", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18440", "abs": "https://arxiv.org/abs/2601.18440", "authors": ["Guru S. Dornadula", "Manikya Pant", "Gowtham R. Kurri", "Prasad Krishnan"], "title": "On the Optimal Message Size in PIR Under Arbitrary Collusion Patterns", "comment": "12 pages", "summary": "A private information retrieval protocol (PIR) scheme under an arbitrary collusion pattern $\\mathcal{P}$ enables a client to retrieve one message from a library of $K$ equal-sized messages duplicated in $N$ servers, while keeping the index of the desired message private from any colluding set in $\\mathcal{P}$. Although achieving high rates typically requires sufficiently large message sizes, smaller message sizes also desirable due to reduced implementation complexity and fewer constraints. By characterizing the capacity-achieving schemes, Tian, Sun, and Chen (2019) showed that the optimal message size for uniformly decomposable PIR schemes under no-collusion setting is $N-1$. However, comparable results are not yet available for more general collusion settings.\n  In this work, we present a complete characterization of the properties of capacity-achieving decomposable PIR schemes under arbitrary collusion patterns. Building on this characterization, we derive a general lower bound on the optimal message size for capacity-achieving uniformly decomposable PIR schemes under an arbitrary collusion pattern $\\mathcal{P}$, expressed in terms of the hitting number of a newly defined family of subsets of servers determined by the collusion pattern $\\mathcal{P}$. Finally, we specialize the lower bound to several important classes of collusion patterns, including $T$-collusion, disjoint collections of colluding sets, cyclically $T$-contiguous collusion, and disjoint collections of cyclically contiguous colluding sets. For the last two collusion patterns, we present matching achievable schemes that attain the corresponding bounds, thereby providing a complete characterization of the optimal message size."}
{"id": "2601.17481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17481", "abs": "https://arxiv.org/abs/2601.17481", "authors": ["Emily Broadhurst", "Tawab Safi", "Joseph Edell", "Vashisht Ganesh", "Karime Maamari"], "title": "Lattice: Generative Guardrails for Conversational Agents", "comment": null, "summary": "Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization."}
{"id": "2601.18441", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18441", "abs": "https://arxiv.org/abs/2601.18441", "authors": ["Hrishi Narayanan", "Vinayak Ramkumar", "Rawad Bitar", "Antonia Wachter-Zeh"], "title": "Coding Schemes for Document Exchange under Multiple Substring Edits", "comment": null, "summary": "We study the document exchange problem under multiple substring edits. A substring edit in a string $\\mathbf{x}$ occurs when a substring $\\mathbf{u}$ of $\\mathbf{x}$ is replaced by an arbitrary string $\\mathbf{v}$. The lengths of $\\mathbf{u}$ and $\\mathbf{v}$ are bounded from above by a fixed constant. Let $\\mathbf{x}$ and $\\mathbf{y}$ be two binary strings that differ by multiple substring edits. The aim of document exchange schemes is to construct an encoding of $\\mathbf{x}$ with small length such that $\\mathbf{x}$ can be recovered using $\\mathbf{y}$ and the encoding. We construct a low-complexity document exchange scheme with encoding length of $4t\\log n+o(\\log n)$ bits, where $n$ is the length of the string $\\mathbf{x}$. The best known scheme achieves an encoding length of $4t \\log n+O(\\log\\log n)$ bits, but at a much higher computational complexity. Then, we investigate the average length of valid encodings for document exchange schemes with uniform strings $\\mathbf{x}$ and develop a scheme with an expected encoding length of $(4t-1) \\log n+o(\\log n)$ bits. In this setting, prior works have only constructed schemes for a single substring edit."}
{"id": "2601.17542", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.17542", "abs": "https://arxiv.org/abs/2601.17542", "authors": ["Vinoth Punniyamoorthy", "Nitin Saksena", "Srivenkateswara Reddy Sankiti", "Nachiappan Chockalingam", "Aswathnarayan Muthukrishnan Kirubakaran", "Shiva Kumar Reddy Carimireddy", "Durgaraman Maruthavanan"], "title": "Cognitive Platform Engineering for Autonomous Cloud Operations", "comment": null, "summary": "Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems."}
{"id": "2601.18471", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18471", "abs": "https://arxiv.org/abs/2601.18471", "authors": ["Zhentian Zhang", "Kai-Kit Wong", "Hao Jiang", "Farshad Rostami Ghadi", "Hyundong Shin", "Yangyang Zhang"], "title": "Finite-Aperture Fluid Antenna Array Design: Analysis and Algorithm", "comment": null, "summary": "Finite-aperture constraints render array design nontrivial and can undermine the effectiveness of classical sparse geometries. This letter provides universal guidance for fluid antenna array (FAA) design under a fixed aperture. We derive a closed-form Cramér--Rao bound (CRB) that unifies conventional and reconfigurable arrays by explicitly linking the Fisher information to the geometric variance of port locations. We further obtain a closed-form probability density function of the minimum spacing under random FAA placement, which yields a principled lower bound for the minimum-spacing constraint. Building upon these analytical insights, we then propose a gradient-based algorithm to optimize continuous port locations. Utilizing a simple gradient update design, the optimized FAA can achieve about a $30\\%$ CRB reduction and a $42.5\\%$ reduction in mean-squared error."}
{"id": "2601.17564", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17564", "abs": "https://arxiv.org/abs/2601.17564", "authors": ["Aadam", "Monu Verma", "Mohamed Abdel-Mottaleb"], "title": "JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research", "comment": null, "summary": "The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC."}
{"id": "2601.18516", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18516", "abs": "https://arxiv.org/abs/2601.18516", "authors": ["Chenyu Wang", "Amin Gohari"], "title": "Ribbons from Independence Structure: Hypercontractivity, $Φ$-Mutual Information, and Matrix $Φ$-Entropy", "comment": "17 pages", "summary": "We study the hypercontractivity ribbon and the $Φ$-ribbon for joint distributions that obey a given independence structure, obtaining tight bounds in some basic regimes. For general independence structures, modeled as a hypergraph whose hyperedges specify mutually independent subcollections of random variables, we provide an explicit inner bound on the $Φ$-ribbon described by a simple convex hull of incidence vectors. We also provide a new multipartite generalization version and a $Φ$-mutual information analogue of the Zhang--Yeung inequality, which implies nontrivial points in the hypercontractivity ribbon and the $Φ$-ribbon respectively. Finally, we propose the matrix $Φ$-ribbon based on matrix $Φ$-entropy and establish the tensorization and data processing properties, together with the calculation of an exact matrix SDPI constant for the doubly symmetric binary source."}
{"id": "2601.17587", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17587", "abs": "https://arxiv.org/abs/2601.17587", "authors": ["Azza Fadhel", "Nathaniel W. Zuckschwerdt", "Aryan Deshwal", "Susmita Bose", "Amit Bandyopadhyay", "Jana Doppa"], "title": "Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design", "comment": "Proceedings of Innovative Applications of AI (IAAI) 2026 Conference", "summary": "Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications."}
{"id": "2601.18590", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18590", "abs": "https://arxiv.org/abs/2601.18590", "authors": ["Chen Yuan", "Ruiqi Zhu"], "title": "Improvement of the Gilbert-Varshamov Bound for Linear Codes and Quantum Codes", "comment": "31 pages", "summary": "The Gilbert--Varshamov (GV) bound is a central benchmark in coding theory, establishing existential guarantees for error-correcting codes and serving as a baseline for both Hamming and quantum fault-tolerant information processing. Despite decades of effort, improving the GV bound is notoriously difficult, and known improvements often rely on technically heavy arguments and do not extend naturally to the quantum setting due to additional self-orthogonality constraints.\n  In this work we develop a concise probabilistic method that yields an improvement over the classical GV bound for $q$-ary linear codes. For relative distance $δ=d/n<1-1/q$, we show that an $[n,k,d]_q$ linear code exists whenever $\\frac{q^{k}-1}{q-1}\\;<\\;\\frac{c_δ\\sqrt{n}\\, q^{n}}{\\mathrm{Vol}_q(n,d-1)}$, for positive constant $c_δ$ depending only on $δ$, where $\\mathrm{Vol}_q(n,d-1)$ denotes the volume of a $q$-ary Hamming ball.\n  We further adapt this approach to the quantum setting by analyzing symplectic self-orthogonal structures. For $δ<1-1/q^2$, we obtain an improved quantum GV bound: there exists a $q$-ary quantum code $[[n,\\,n-k,\\,d]]$ provided that $\\frac{q^{2n-k}-1}{q-1}<\\frac{c_δ\\sqrt{n}\\cdot q^{2n}}{\\sum_{i=0}^{d-1}\\binom{n}{i}(q^2-1)^i}$. In particular, our result improves the standard quantum GV bound by an $Ω(\\sqrt{n})$ multiplicative factor."}
{"id": "2601.17588", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17588", "abs": "https://arxiv.org/abs/2601.17588", "authors": ["Marcus Ma", "Shrikanth Narayanan"], "title": "Intelligence Requires Grounding But Not Embodiment", "comment": null, "summary": "Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments."}
{"id": "2601.18655", "categories": ["cs.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.18655", "abs": "https://arxiv.org/abs/2601.18655", "authors": ["Ioannis Krikidis"], "title": "Quantum Rotation Diversity in Displaced Squeezed Binary Phase-Shift Keying", "comment": "IEEE Transactions on Quantum Engineering, 2026", "summary": "We propose a quantum rotation diversity (QRD) scheme for optical quantum communication using binary phase-shift-keying displaced squeezed states and homodyne detection over Gamma-Gamma turbulence channels. Consecutive temporal modes are coupled by a passive orthogonal rotation that redistributes the displacement amplitude between slots, yielding a diversity order of two under independent fading and joint maximum-likelihood detection. Analytical expressions for the symbol-error rate performance, along with asymptotic results for the diversity and coding gains, are derived. The optimal rotation angle and energy allocation between displacement and squeezing are obtained in closed form. Furthermore, we show that when both the displacement amplitude and the squeezing strength scale with the total photon number, an effective diversity order of four is achieved. Numerical results validate the analysis and demonstrate the super-diversity behaviour of the proposed QRD scheme."}
{"id": "2601.17642", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17642", "abs": "https://arxiv.org/abs/2601.17642", "authors": ["Zhihao Zhang", "Liting Huang", "Guanghao Wu", "Preslav Nakov", "Heng Ji", "Usman Naseem"], "title": "Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context", "comment": "Preprint", "summary": "Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \\emph{over-refusal} of benign queries or \\emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \\textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \\textbf{Over-Refusal} and \\textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\\% of \"Hard\" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit \"safety-pessimism\" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \\textcolor{red}{Warning: Some contents may include toxic or undesired contents.}"}
{"id": "2601.18661", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18661", "abs": "https://arxiv.org/abs/2601.18661", "authors": ["Rimpi Borah", "J. Harshan", "Aaditya Sharma"], "title": "Balancing Privacy and Robustness in Coded Computing Under Profiled Workers", "comment": "6 pages", "summary": "In distributed computing with untrusted workers, the assignment of evaluation indices plays a critical role in determining both privacy and robustness. In this work, we study how the placement of unreliable workers within the Numerically Stable Lagrange Coded Computing (NS-LCC) framework influences privacy and the ability to localize Byzantine errors. We derive analytical bounds that quantify how different evaluation-index assignments affect privacy against colluding curious workers and robustness against Byzantine corruption under finite-precision arithmetic. Using these bounds, we formulate optimization problems that identify privacy-optimal and robustness-optimal index placements and show that the resulting assignments are fundamentally different. This exposes that index choices that maximizes privacy degrade error-localization, and vice versa. To jointly navigate this trade-off, we propose a low-complexity greedy assignment strategy that closely approximates the optimal balance between privacy and robustness."}
{"id": "2601.17678", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.17678", "abs": "https://arxiv.org/abs/2601.17678", "authors": ["Zhiyu An", "Wan Du"], "title": "DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories", "comment": null, "summary": "We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced."}
{"id": "2601.18740", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18740", "abs": "https://arxiv.org/abs/2601.18740", "authors": ["Yicheng Dong", "Rashid Iqbal", "Julien Le Kernec", "Hanaa Abumarshoud"], "title": "A Scanning-Based Indoor Optical Wireless Positioning System with Single VCSEL", "comment": null, "summary": "This paper presents a novel indoor visible light positioning (VLP) system utilising one vertical-cavity surface-emitting laser installed at the ceiling centre of a space. The system offers three-dimensional localisation by sweeping through space at one-degree resolution in two dimensions (azimuth and elevation), significantly simplifying hardware. Through incorporating the angle of arrival and received signal strength, this system demonstrates excellent precision in indoor positioning. Simulation results verify that the system attains sub-centimetre precision for most test points, outperforming conventional multi-transmitter VLP schemes in cost-efficiency and simplicity."}
{"id": "2601.17699", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.17699", "abs": "https://arxiv.org/abs/2601.17699", "authors": ["Harper Hua", "Zhen Han", "Zhengyuan Shen", "Jeremy Lee", "Patrick Guan", "Qi Zhu", "Sullam Jeoung", "Yueyan Chen", "Yunfei Bai", "Shuai Wang", "Vassilis Ioannidis", "Huzefa Rangwala"], "title": "SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL", "comment": null, "summary": "While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation."}
{"id": "2601.18763", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.18763", "abs": "https://arxiv.org/abs/2601.18763", "authors": ["Sahan Liyanaarachchi", "Sennur Ulukus", "Nail Akar"], "title": "Multi-Stage Structured Estimators for Information Freshness", "comment": null, "summary": "Most of the contemporary literature on information freshness solely focuses on the analysis of freshness for martingale estimators, which simply use the most recently received update as the current estimate. While martingale estimators are easier to analyze, they are far from optimal, especially in pull-based update systems, where maximum aposteriori probability (MAP) estimators are known to be optimal, but are analytically challenging. In this work, we introduce a new class of estimators called $p$-MAP estimators, which enable us to model the MAP estimator as a piecewise constant function with finitely many stages, bringing us closer to a full characterization of the MAP estimators when modeling information freshness."}
{"id": "2601.17717", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17717", "abs": "https://arxiv.org/abs/2601.17717", "authors": ["Kaituo Zhang", "Mingzhi Hu", "Hoang Anh Duy Le", "Fariha Kabir Torsha", "Zhimeng Jiang", "Minh Khai Bui", "Chia-Yuan Chang", "Yu-Neng Chuang", "Zhen Xiong", "Ying Lin", "Guanchu Wang", "Na Zou"], "title": "The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \\textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities."}
{"id": "2601.17722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17722", "abs": "https://arxiv.org/abs/2601.17722", "authors": ["Ying Mo", "Yu Bai", "Dapeng Sun", "Yuqian Shi", "Yukai Miao", "Li Chen", "Dan Li"], "title": "EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents", "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents."}
{"id": "2601.17735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17735", "abs": "https://arxiv.org/abs/2601.17735", "authors": ["Kyungho Kim", "Geon Lee", "Juyeon Kim", "Dongwon Choi", "Shinhwan Kang", "Kijung Shin"], "title": "ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents", "comment": "Accepted in ACM WWW 2026 (Short Paper)", "summary": "Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE."}
{"id": "2601.17744", "categories": ["cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.17744", "abs": "https://arxiv.org/abs/2601.17744", "authors": ["Amjad Fatmi"], "title": "Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems", "comment": "40 pages, 10 figures. Preprint. Code: https://github.com/faramesh/faramesh-core", "summary": "Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches."}
{"id": "2601.17767", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17767", "abs": "https://arxiv.org/abs/2601.17767", "authors": ["Rajan Das Gupta", "Xiaobin Wu", "Xun Liu", "Jiaqi He"], "title": "HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis", "comment": "Accepted and published in the 2025 4th International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)", "summary": "Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions."}
{"id": "2601.17789", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17789", "abs": "https://arxiv.org/abs/2601.17789", "authors": ["Yiming Su", "Kunzhao Xu", "Yanjie Gao", "Fan Yang", "Cheng Li", "Mao Yang", "Tianyin Xu"], "title": "Neuro-Symbolic Verification on Instruction Following of LLMs", "comment": null, "summary": "A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training."}
{"id": "2601.17814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17814", "abs": "https://arxiv.org/abs/2601.17814", "authors": ["Haoxuan Ma", "Guannan Lai", "Han-Jia Ye"], "title": "MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench."}
{"id": "2601.17826", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17826", "abs": "https://arxiv.org/abs/2601.17826", "authors": ["Siyuan Yang", "Xihan Bian", "Jiayin Tang"], "title": "RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance", "comment": null, "summary": "The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands."}
{"id": "2601.17828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17828", "abs": "https://arxiv.org/abs/2601.17828", "authors": ["Tanvi Verma", "Yang Zhou", "Rick Siow Mong Goh", "Yong Liu"], "title": "Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards", "comment": null, "summary": "We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations."}
{"id": "2601.17887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17887", "abs": "https://arxiv.org/abs/2601.17887", "authors": ["Jiahe Guo", "Xiangran Guo", "Yulin Hu", "Zimo Long", "Xingyu Sui", "Xuda Zhi", "Yongbo Huang", "Hao He", "Weixiang Zhao", "Yanyan Zhao", "Bing Qin"], "title": "When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents", "comment": null, "summary": "Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content."}
{"id": "2601.17897", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17897", "abs": "https://arxiv.org/abs/2601.17897", "authors": ["Jiayu Liu", "Yinhe Long", "Zhenya Huang", "Enhong Chen"], "title": "UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis", "comment": null, "summary": "A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog."}
{"id": "2601.17915", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.17915", "abs": "https://arxiv.org/abs/2601.17915", "authors": ["Saurabh Jha", "Rohan Arora", "Bhavya", "Noah Zheutlin", "Paulina Toro Isaza", "Laura Shwartz", "Yu Deng", "Daby Sow", "Ruchi Mahindru", "Ruchir Puri"], "title": "Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation", "comment": null, "summary": "LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.\n  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1."}
{"id": "2601.17920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17920", "abs": "https://arxiv.org/abs/2601.17920", "authors": ["Xuanzhou Chen", "Audrey Wang", "Stanley Yin", "Hanyang Jiang", "Dong Zhang"], "title": "Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges", "comment": null, "summary": "Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure."}
{"id": "2601.17923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17923", "abs": "https://arxiv.org/abs/2601.17923", "authors": ["Ali Najar"], "title": "Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation", "comment": "5 pages", "summary": "Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments."}
{"id": "2601.17942", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.17942", "abs": "https://arxiv.org/abs/2601.17942", "authors": ["Yu-Jie Yang", "Hung-Fu Chang", "Po-An Chen"], "title": "LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting", "comment": "29 pages, 22 figures", "summary": "Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency."}
{"id": "2601.18027", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18027", "abs": "https://arxiv.org/abs/2601.18027", "authors": ["Chiyuan Fu", "Lyuhao Chen", "Yunze Xiao", "Weihao Xuan", "Carlos Busso", "Mona Diab"], "title": "Sentipolis: Emotion-Aware Agents for Social Simulations", "comment": null, "summary": "LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change."}
{"id": "2601.18061", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18061", "abs": "https://arxiv.org/abs/2601.18061", "authors": ["Kiana Jafari", "Paul Ulrich Nikolaus Rust", "Duncan Eddy", "Robbie Fraser", "Nina Vasan", "Darja Djordjevic", "Akanksha Dadlani", "Max Lamparth", "Eugenia Kim", "Mykel Kochenderfer"], "title": "Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing", "comment": "17 pages, 7 pages of appendix, 21 tables", "summary": "Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement."}
{"id": "2601.18067", "categories": ["cs.AI", "cs.NE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.18067", "abs": "https://arxiv.org/abs/2601.18067", "authors": ["Wei-Po Hsin", "Ren-Hao Deng", "Yao-Ting Hsieh", "En-Ming Huang", "Shih-Hao Hung"], "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization", "comment": "17 pages, 6 figures, 8 tables", "summary": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL."}
{"id": "2601.18119", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18119", "abs": "https://arxiv.org/abs/2601.18119", "authors": ["Jing Ye", "Yiwen Duan", "Yonghong Yu", "Victor Ma", "Yang Gao", "Xing Chen"], "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?", "comment": null, "summary": "SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.\n  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.\n  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs."}
{"id": "2601.18123", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18123", "abs": "https://arxiv.org/abs/2601.18123", "authors": ["Muhammad Ibrahim Khan", "Bivin Pradeep", "James Brusey"], "title": "Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters", "comment": "Accepted at AAAI 2026", "summary": "Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained."}
{"id": "2601.18130", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18130", "abs": "https://arxiv.org/abs/2601.18130", "authors": ["Jize Wang", "Han Wu", "Zhiyuan You", "Yiming Song", "Yijun Wang", "Zifei Shan", "Yining Li", "Songyang Zhang", "Xinyi Le", "Cailian Chen", "Xinping Guan", "Dacheng Tao"], "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents", "comment": null, "summary": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool."}
{"id": "2601.18132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18132", "abs": "https://arxiv.org/abs/2601.18132", "authors": ["Xi Chen", "Hongru Zhou", "Huahui Yi", "Shiyu Feng", "Hanyu Zhou", "Tiancheng He", "Mingke You", "Li Wang", "Qiankun Li", "Kun Wang", "Weili Fu", "Kang Li", "Jian Li"], "title": "RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening", "comment": "28 page, 3 figures", "summary": "Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment."}
{"id": "2601.18137", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18137", "abs": "https://arxiv.org/abs/2601.18137", "authors": ["Yinger Zhang", "Shutong Jiang", "Renhao Li", "Jianhong Tu", "Yang Su", "Lianghao Deng", "Xudong Guo", "Chenxu Lv", "Junyang Lin"], "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints", "comment": null, "summary": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research."}
{"id": "2601.18175", "categories": ["cs.AI", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18175", "abs": "https://arxiv.org/abs/2601.18175", "authors": ["Daniel Russo"], "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success", "comment": null, "summary": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective."}
{"id": "2601.18197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18197", "abs": "https://arxiv.org/abs/2601.18197", "authors": ["Shaokang Wang", "Pei Fu", "Ruoceng Zhang", "Shaojie Zhang", "Xiuwen Xi", "Jiahui Yang", "Bin Qin", "Ying Huang", "Zhenbo Luo", "Jian Luan"], "title": "GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models", "comment": null, "summary": "While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released."}
{"id": "2601.18202", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18202", "abs": "https://arxiv.org/abs/2601.18202", "authors": ["Fangyuan Xu", "Rujun Han", "Yanfei Chen", "Zifeng Wang", "I-Hung Hsu", "Jun Yan", "Vishy Tirumalashetty", "Eunsol Choi", "Tomas Pfister", "Chen-Yu Lee"], "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback", "comment": null, "summary": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training."}
{"id": "2601.18217", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18217", "abs": "https://arxiv.org/abs/2601.18217", "authors": ["Zhihan Liu", "Lin Guan", "Yixin Nie", "Kai Zhang", "Zhuoqun Hao", "Lin Chen", "Asli Celikyilmaz", "Zhaoran Wang", "Na Zhang"], "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents", "comment": null, "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization."}
{"id": "2601.18225", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18225", "abs": "https://arxiv.org/abs/2601.18225", "authors": ["Pei Wang", "Yanan Wu", "Xiaoshuai Song", "Weixun Wang", "Gengru Chen", "Zhongwen Li", "Kezhong Yan", "Ken Deng", "Qi Liu", "Shuaibing Zhao", "Shaopan Xiong", "Xuepeng Liu", "Xuefeng Chen", "Wanxi Deng", "Wenbo Su", "Bo Zheng"], "title": "ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants", "comment": null, "summary": "Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator."}
{"id": "2601.18226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18226", "abs": "https://arxiv.org/abs/2601.18226", "authors": ["Haotian Li", "Shijun Yang", "Weizhen Qi", "Silei Zhao", "Rui Hua", "Mingzhu Song", "Xiaojian Yang", "Chao Peng"], "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks", "comment": null, "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence."}
{"id": "2601.18282", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18282", "abs": "https://arxiv.org/abs/2601.18282", "authors": ["Lei Wei", "Jinpeng Ou", "Xiao Peng", "Bin Wang"], "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors."}
{"id": "2601.18308", "categories": ["cs.AI", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18308", "abs": "https://arxiv.org/abs/2601.18308", "authors": ["Geunsik Lim"], "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience", "comment": "19 pages", "summary": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures."}
{"id": "2601.18353", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18353", "abs": "https://arxiv.org/abs/2601.18353", "authors": ["Tuhin Chakrabarty", "Paramveer S. Dhillon"], "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books", "comment": "Proceedings of CHI 2026 Conference (To Appear)", "summary": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor."}
{"id": "2601.18381", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.18381", "abs": "https://arxiv.org/abs/2601.18381", "authors": ["Yinghan Hou", "Zongyou Yang"], "title": "AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito", "comment": "14 pages, 7 figures", "summary": "To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior."}
{"id": "2601.18383", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18383", "abs": "https://arxiv.org/abs/2601.18383", "authors": ["Zhenyuan Guo", "Tong Chen", "Wenlong Meng", "Chen Gong", "Xin Yu", "Chengkun Wei", "Wenzhi Chen"], "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency."}
{"id": "2601.18467", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18467", "abs": "https://arxiv.org/abs/2601.18467", "authors": ["Yuhang Zhou", "Kai Zheng", "Qiguang Chen", "Mengkang Hu", "Qingfeng Sun", "Can Xu", "Jingjing Chen"], "title": "OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents", "comment": null, "summary": "Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL."}
{"id": "2601.18491", "categories": ["cs.AI", "cs.CC", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18491", "abs": "https://arxiv.org/abs/2601.18491", "authors": ["Dongrui Liu", "Qihan Ren", "Chen Qian", "Shuai Shao", "Yuejin Xie", "Yu Li", "Zhonghao Yang", "Haoyu Luo", "Peng Wang", "Qingyu Liu", "Binxin Hu", "Ling Tang", "Jilin Mei", "Dadi Guo", "Leitao Yuan", "Junyao Yang", "Guanxu Chen", "Qihao Lin", "Yi Yu", "Bo Zhang", "Jiaxuan Guo", "Jie Zhang", "Wenqi Shao", "Huiqi Deng", "Zhiheng Xi", "Wenjie Wang", "Wenxuan Wang", "Wen Shen", "Zhikai Chen", "Haoyu Xie", "Jialing Tao", "Juntao Dai", "Jiaming Ji", "Zhongjie Ba", "Linfeng Zhang", "Yong Liu", "Quanshi Zhang", "Lei Zhu", "Zhihua Wei", "Hui Xue", "Chaochao Lu", "Jing Shao", "Xia Hu"], "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security", "comment": "40 pages, 26 figures", "summary": "The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released."}
{"id": "2601.18496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18496", "abs": "https://arxiv.org/abs/2601.18496", "authors": ["Zihan wang", "Hao Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yiqun Zhang", "Jinghao Lin", "Haihua Yang", "Xiaozhong Ji"], "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference", "comment": null, "summary": "Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models."}
{"id": "2601.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18554", "abs": "https://arxiv.org/abs/2601.18554", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities", "comment": "Paper accepted to EACL 2026", "summary": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions."}
{"id": "2601.18588", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18588", "abs": "https://arxiv.org/abs/2601.18588", "authors": ["Xianzhe Meng", "Qiangsheng Zeng", "Ling Luo", "Qinghan Yang", "Jiarui Hao", "Wenbo Wu", "Qinyu Wang", "Rui Yin", "Lin Qi", "Renzhi Lu"], "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs", "comment": null, "summary": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality."}
{"id": "2601.18595", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18595", "abs": "https://arxiv.org/abs/2601.18595", "authors": ["Joseph Cotnareanu", "Didier Chetelat", "Yingxue Zhang", "Mark Coates"], "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic", "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts."}
{"id": "2601.18608", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18608", "abs": "https://arxiv.org/abs/2601.18608", "authors": ["Fabian Fumagalli", "R. Teal Witter", "Christopher Musco"], "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression", "comment": null, "summary": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.\n  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.\n  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic."}
{"id": "2601.18617", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18617", "abs": "https://arxiv.org/abs/2601.18617", "authors": ["Pierre Orhan", "Pablo Diego-Simón", "Emmnanuel Chemla", "Yair Lakretz", "Yves Boubenec", "Jean-Rémi King"], "title": "Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks", "comment": null, "summary": "During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition."}
{"id": "2601.18630", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18630", "abs": "https://arxiv.org/abs/2601.18630", "authors": ["Abeer Badawi", "Md Tahmid Rahman Laskar", "Elahe Rahimi", "Sheri Grach", "Lindsay Bertrand", "Lames Danok", "Frank Rudzicz", "Jimmy Huang", "Elham Dolatabadi"], "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation", "comment": null, "summary": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI."}
{"id": "2601.18631", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.18631", "abs": "https://arxiv.org/abs/2601.18631", "authors": ["Mingyang Song", "Haoyu Sun", "Jiawei Gu", "Linjie Li", "Luxin Xu", "Ranjay Krishna", "Yu Cheng"], "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning", "comment": "28 pages, 10 figures and 13 tables", "summary": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw."}
{"id": "2601.18642", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18642", "abs": "https://arxiv.org/abs/2601.18642", "authors": ["Lei Wei", "Xu Dong", "Xiao Peng", "Niantao Xie", "Bin Wang"], "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory", "comment": null, "summary": "Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems."}
{"id": "2601.18700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18700", "abs": "https://arxiv.org/abs/2601.18700", "authors": ["Xingyu Sui", "Yanyan Zhao", "Yulin Hu", "Jiahe Guo", "Weixiang Zhao", "Bing Qin"], "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent", "comment": null, "summary": "Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents."}
{"id": "2601.18706", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18706", "abs": "https://arxiv.org/abs/2601.18706", "authors": ["Zhichao Yang", "Sepehr Janghorbani", "Dongxu Zhang", "Jun Han", "Qian Qian", "Andrew Ressler", "Gregory D. Lyng", "Sanjit Singh Batra", "Robert E. Tillman"], "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs", "comment": null, "summary": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable."}
{"id": "2601.18716", "categories": ["cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.18716", "abs": "https://arxiv.org/abs/2601.18716", "authors": ["Naeyma N. Islam", "Thomas R. Caulfield"], "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules", "comment": "30 pages, 8 figures", "summary": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases."}
{"id": "2601.18735", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18735", "abs": "https://arxiv.org/abs/2601.18735", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Jing Yang", "Jiawei Yao", "Jian Wang", "Guanlong Qu", "Ziliang Chen", "Keze Wang"], "title": "Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems", "comment": "Accepted to ICLR 2026", "summary": "Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems."}
{"id": "2601.18744", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18744", "abs": "https://arxiv.org/abs/2601.18744", "authors": ["Fangxu Yu", "Xingang Guo", "Lingzhi Yuan", "Haoqiang Kang", "Hongyu Zhao", "Lianhui Qin", "Furong Huang", "Bin Hu", "Tianyi Zhou"], "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models", "comment": null, "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/."}
{"id": "2601.17187", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17187", "abs": "https://arxiv.org/abs/2601.17187", "authors": ["Or Ordentlich", "Yury Polyanskiy"], "title": "High-Rate Quantized Matrix Multiplication: Theory and Practice", "comment": null, "summary": "This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $Σ_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $Σ_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\\frac{2πe}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $Σ_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization)."}
{"id": "2601.17684", "categories": ["cs.IT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17684", "abs": "https://arxiv.org/abs/2601.17684", "authors": ["Cordelia Hu", "Jennifer Tang"], "title": "A Model-Driven Lossless Compression Algorithm Resistant to Mismatch", "comment": "10 pages, 5 figure. Submitted to ISIT 2026. This is a follow-up to the following paper: arXiv:2601.10678", "summary": "Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism.\n  In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods."}
{"id": "2601.18069", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18069", "abs": "https://arxiv.org/abs/2601.18069", "authors": ["Haoyuan Pan", "Sizhao Chen", "Zhaorui Wang", "Tse-Tin Chan"], "title": "Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control", "comment": "16 pages, 11 figures", "summary": "Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems."}
