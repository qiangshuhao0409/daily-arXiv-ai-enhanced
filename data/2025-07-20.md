<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Energy-Efficient RSMA-enabled Low-altitude MEC Optimization Via Generative AI-enhanced Deep Reinforcement Learning](https://arxiv.org/abs/2507.12910)
*Xudong Wang,Hongyang Du,Lei Feng,Kaibin Huang*

Main category: cs.NI

TL;DR: 本文针对6G低延迟计算需求，提出了一种基于无人机的低空移动边缘计算系统，采用率分割多址接入(RSMA)技术来解决地面终端间的上行链路干扰问题，并使用生成式AI增强的深度强化学习框架进行联合优化。


<details>
  <summary>Details</summary>
Motivation: 6G对低延迟计算的日益增长需求推动了基于无人机的低空移动边缘计算系统的使用，但有限的频谱资源导致地面终端间出现严重的上行链路干扰问题，需要有效的解决方案来缓解多用户干扰并提高能效。

Method: 提出了基于率分割多址接入(RSMA)的低空移动边缘计算系统，建立了涉及无人机3D轨迹、RSMA解码顺序、任务卸载决策和资源分配的联合优化问题。采用生成式AI增强的深度强化学习(DRL)框架求解，在actor网络中嵌入扩散模型来生成高质量动作样本，并设计了基于优先级的RSMA解码策略。

Result: 仿真结果表明，所提出的低空移动边缘计算系统方法优于基准方法，将生成扩散模型(GDM)与RSMA相结合能够显著提高能效性能。扩散模型的嵌入改善了混合动作空间中的探索能力并避免了局部最优解。

Conclusion: 基于RSMA的低空移动边缘计算系统结合生成式AI增强的深度强化学习框架，能够有效缓解多用户干扰，提高系统能效，为6G低延迟计算需求提供了一种有效的解决方案。

Abstract: The growing demand for low-latency computing in 6G is driving the use of
UAV-based low-altitude mobile edge computing (MEC) systems. However, limited
spectrum often leads to severe uplink interference among ground terminals
(GTs). In this paper, we investigate a rate-splitting multiple access
(RSMA)-enabled low-altitude MEC system, where a UAV-based edge server assists
multiple GTs in concurrently offloading their tasks over a shared uplink. We
formulate a joint optimization problem involving the UAV 3D trajectory, RSMA
decoding order, task offloading decisions, and resource allocation, aiming to
mitigate multi-user interference and maximize energy efficiency. Given the high
dimensionality, non-convex nature, and dynamic characteristics of this
optimization problem, we propose a generative AI-enhanced deep reinforcement
learning (DRL) framework to solve it efficiently. Specifically, we embed a
diffusion model into the actor network to generate high-quality action samples,
improving exploration in hybrid action spaces and avoiding local optima. In
addition, a priority-based RSMA decoding strategy is designed to facilitate
efficient successive interference cancellation with low complexity. Simulation
results demonstrate that the proposed method for low-altitude MEC systems
outperforms baseline methods, and that integrating GDM with RSMA can achieve
significantly improved energy efficiency performance.

</details>


### [2] [RIDAS: A Multi-Agent Framework for AI-RAN with Representation- and Intention-Driven Agents](https://arxiv.org/abs/2507.13140)
*Kuiyuan Ding,Caili Guo,Yang Yang,Jianzhang Guo*

Main category: cs.NI

TL;DR: RIDAS是一个多智能体框架，通过表示驱动代理（RDA）和意图驱动代理（IDA）优化6G网络中的资源分配，支持更多用户且满足QoS要求。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要AI与RAN紧密集成以满足严格的QoS和资源效率要求，现有方案难以弥合高层用户意图与低层参数配置之间的差距。

Method: RIDAS框架包含RDA（提供可调参数接口）和IDA（基于LLM的两阶段规划方案），将用户意图映射为最优配置。

Result: 实验显示，RIDAS在相同QoS约束下比WirelessAgent多支持44.71%的用户。

Conclusion: RIDAS能有效捕获用户意图并高效分配资源，适用于AI RAN环境。

Abstract: Sixth generation (6G) networks demand tight integration of artificial
intelligence (AI) into radio access networks (RANs) to meet stringent quality
of service (QoS) and resource efficiency requirements. Existing solutions
struggle to bridge the gap between high level user intents and the low level,
parameterized configurations required for optimal performance. To address this
challenge, we propose RIDAS, a multi agent framework composed of representation
driven agents (RDAs) and an intention driven agent (IDA). RDAs expose open
interface with tunable control parameters (rank and quantization bits, enabling
explicit trade) offs between distortion and transmission rate. The IDA employs
a two stage planning scheme (bandwidth pre allocation and reallocation) driven
by a large language model (LLM) to map user intents and system state into
optimal RDA configurations. Experiments demonstrate that RIDAS supports 44.71\%
more users than WirelessAgent under equivalent QoS constraints. These results
validate ability of RIDAS to capture user intent and allocate resources more
efficiently in AI RAN environments.

</details>


### [3] [Predictability-Aware Motion Prediction for Edge XR via High-Order Error-State Kalman Filtering](https://arxiv.org/abs/2507.13179)
*Ziyu Zhong,Hector A Caltenco,Björn Landfeldt,Günter Alce*

Main category: cs.NI

TL;DR: 6G网络为XR应用提供了低延迟和边缘处理能力，使得计算密集型任务可从用户设备迁移到网络，降低设备电池需求并支持更小尺寸设计。


<details>
  <summary>Details</summary>
Motivation: 探索6G网络在降低延迟和增强边缘处理能力方面的潜力，以支持XR应用的实时卸载。

Method: 利用6G的低延迟和边缘处理基础设施，将渲染等计算密集型任务从用户设备迁移到网络。

Result: 实现了降低用户设备电池需求和设计更小尺寸设备的可能性。

Conclusion: 6G网络为XR应用提供了高效的卸载方案，显著提升了用户体验和设备设计灵活性。

Abstract: As 6G networks are developed and defined, offloading of XR applications is
emerging as one of the strong new use cases. The reduced 6G latency coupled
with edge processing infrastructure will for the first time provide a realistic
offloading scenario in cellular networks where several computationally
intensive functions, including rendering, can migrate from the user device and
into the network. A key advantage of doing so is the lowering of the battery
needs in the user devices and the possibility to design new devices with
smaller form factors.

</details>


### [4] [Bidirectional Age of Incorrect Information: A Performance Metric for Status Updates in Virtual Dynamic Environments](https://arxiv.org/abs/2507.13312)
*Chiara Schiavo,Manuele Favero,Alessandro Buratto,Leonardo Badia*

Main category: cs.NI

TL;DR: 本文提出双向错误信息年龄（BAoII）来量化虚拟动态环境（VDE）中因信息不准确或过时而导致的惩罚，并通过马尔可夫链模型推导出长期BAoII的闭式解，优化更新策略。


<details>
  <summary>Details</summary>
Motivation: 虚拟动态环境（如元宇宙和数字孪生）需要准确且实时地表示交互实体，以确保无缝交互和系统可靠性。

Method: 提出BAoII概念，扩展了单向错误信息年龄，通过连续时间马尔可夫链模型推导闭式解，并确定最优更新策略的传输成本阈值。

Result: 数值模拟验证了BAoII对系统性能评估的影响，并揭示了通信成本与信息新鲜度之间的权衡。

Conclusion: BAoII为元宇宙和数字孪生中的实时协作提供了重要的性能评估工具。

Abstract: Virtual dynamic environments (VDEs) such as the Metaverse and digital twins
(DTs) require proper representation of the interacting entities to map their
characteristics within the simulated or augmented space. Keeping these
representations accurate and up-to-date is crucial for seamless interaction and
system reliability. In this paper, we propose bidirectional age of incorrect
information (BAoII) to address this aspect. BAoII quantifies the time-dependent
penalty paid by an entity in a VDE due to incorrect or outdated knowledge about
itself and the overall dynamically changing space. This extends the concept of
age of incorrect information for a bidirectional information exchange,
capturing that a VDE requires mutual awareness of the entity's own
representation, measured in the virtual space, and what the other entities
share about their representations. Using a continuous-time Markov chain model,
we derive a closed-form expression for long-term BAoII and identify a
transmission cost threshold for optimal update strategies. We describe a
trade-off between communication cost and information freshness and validate our
model through numerical simulations, demonstrating the impact of BAoII on
evaluating system performance and highlighting its relevance for real-time
collaboration in the Metaverse and DTs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 本文提出了一种新型多代理AI辅导平台，旨在解决现有AI辅导系统的被动性问题，提供结构化、个性化且工具辅助的学习体验。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅导系统在数学领域表现不足，缺乏深度反思和结构化教学工具，限制了学习效果。

Method: 开发了一个结合自适应反馈、结构化课程生成和教材知识检索的多代理AI辅导平台。

Result: 该系统支持学生个性化学习、弱点识别、高效复习和无限练习，提升了数学教学效果。

Conclusion: 该平台通过整合教学代理和AI驱动组件，为数学教育提供了模块化且高效的系统。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [6] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 提出一种基于博弈论的高速公路合流场景战术决策模型，结合改进的收益函数和滞后动作，以更真实、可解释的方式模拟驾驶员行为。


<details>
  <summary>Details</summary>
Motivation: 提升仿真环境中驾驶员行为的真实性，以支持自动驾驶技术开发，特别是在高速公路合流场景中。

Method: 结合博弈论模型与底层动力学模型，改进收益函数和滞后动作，形成统一的决策与动力学模型。

Result: 模型在真实数据集上验证了复杂交互的可重现性，并在高保真仿真环境中表现出高效的计算性能。

Conclusion: 该模型能够有效模拟高速公路合流场景中的真实交互，适用于大规模仿真以支持自动驾驶开发。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [7] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: 本文提出了一种基于“What”和“How”问题的直观分类法，用于梳理可解释强化学习（XRL）领域的研究，并对250多篇论文进行了综述。


<details>
  <summary>Details</summary>
Motivation: 由于深度神经网络的内部机制不透明，理解AI模型的输出变得困难，因此需要可解释性方法。本文专注于可解释强化学习（XRL），旨在解释强化学习智能体的行为。

Method: 提出了一种基于“What”（解释目标）和“How”（解释方式）的分类法，并用于综述250多篇XRL相关论文。

Result: 通过分类法梳理了XRL领域的研究现状，并指出了相关领域的研究需求和未来方向。

Conclusion: XRL领域需要更多关注，本文的分类法和综述为未来研究提供了基础和方向。

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [8] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 论文提出了一种结合强化学习（RL）和多模态模型（LMM）的自动化游戏设计框架，通过RL代理测试游戏并生成行为数据，LMM根据这些数据调整游戏设计，以实现目标导向的迭代优化。


<details>
  <summary>Details</summary>
Motivation: 现代生成系统仅通过分析游戏代码或资源难以捕捉静态规则与动态玩家行为之间的关系，因此需要一种能够填补这一空白的方法。

Method: 框架通过RL代理进行游戏测试，生成数值指标或图像摘要，LMM根据这些数据和分析结果调整游戏配置，以引导玩家行为朝向目标。

Result: 实验表明，LMM能够基于RL代理提供的行为数据迭代优化游戏机制，为AI辅助游戏设计提供了实用且可扩展的工具。

Conclusion: 该框架展示了AI在游戏设计中的潜力，能够通过行为数据驱动的迭代优化实现更智能的设计支持。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [9] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: 论文研究了AI助手的欺骗行为检测，比较了白盒监控（可访问探针激活）和黑盒监控（无访问）的效果，发现现有欺骗探针的白盒优势微弱但令人鼓舞。


<details>
  <summary>Details</summary>
Motivation: 探讨欺骗探针在实际中检测AI助手欺骗行为的有效性，以及其是否能抵抗欺骗助手的反检测策略。

Method: 比较白盒监控和黑盒监控的性能差异，通过黑盒到白盒的性能提升（black-to-white performance boost）评估欺骗探针的效果。

Result: 发现现有欺骗探针的黑盒到白盒性能提升微弱但令人鼓舞。

Conclusion: 欺骗探针在实际检测中具有一定潜力，但效果仍需改进。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [10] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 研究开发AI学习伴侣以支持同伴学习，验证同水平同伴在英语写作中的有效性。


<details>
  <summary>Details</summary>
Motivation: 同伴学习虽有效但存在限制，需同水平同伴。

Method: 假设同水平同伴会犯相同错误，以英语写作为例验证。

Result: 未明确提及具体结果。

Conclusion: AI伴侣可解决同伴学习的时空限制，需进一步验证同水平假设。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [11] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval是一个基于模型上下文协议（MCP）的开源框架，用于自动化生成任务和深度评估LLM智能代理，解决了现有静态基准和人工数据收集的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态基准和人工数据收集，限制了实际评估的效率和可扩展性。

Method: 提出MCPEval框架，基于MCP协议，自动化生成任务并深度评估LLM代理，标准化指标并集成原生工具。

Result: 在五个实际领域中验证了MCPEval的有效性，能够揭示领域特定的性能差异。

Conclusion: MCPEval为LLM代理评估提供了可重复和标准化的解决方案，并已开源。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [12] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文介绍了利用大规模语言模型结合提示工程和微调技术，提升情感支持对话（ESC）任务性能的方法，并在NLPCC 2025 Task 8中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 满足心理健康支持的需求，提供更具同理心和有效的情感支持对话。

Method: 结合参数高效的Low-Rank Adaptation和全参数微调策略，优化模型生成支持性和上下文相关回应的能力。

Result: 最佳模型在竞赛中排名第二，证明了LLMs结合有效适应方法在ESC任务中的潜力。

Conclusion: 未来工作将集中于增强情感理解和回应个性化，以构建更实用可靠的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [13] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 论文提出人类智能的高效适应能力源于世界模型的快速构建与优化，并呼吁在AI中建立新的评估框架，以测试模型在新颖环境中的适应能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI中的世界模型评估过于静态，缺乏对人类高效适应能力的模拟，因此需要新的评估方法。

Method: 借鉴认知科学研究，提出基于新颖游戏的评估框架，设计具有持续变化的游戏结构以测试模型的适应能力。

Result: 提出了一种新的评估范式，包括游戏设计和度量标准，以挑战和评估AI模型的快速世界模型归纳能力。

Conclusion: 新框架有望推动AI世界模型的研究，迈向具有人类般快速适应能力的通用人工智能。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [14] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 论文提出了一种方法，将人类伦理判断从模拟决策循环中移出，设计伦理度量空间供模拟环境探索，最终由人类指挥官从少数选项中选择最佳行动方案。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，人类指挥官需要利用计算能力模拟大量场景，但依赖人类判断每个决策的伦理后果既不高效也不可行。

Method: 人类设计伦理度量空间，模拟环境探索该空间并生成选项，人类指挥官从中选择最佳行动方案。

Result: 论文探讨了如何在模拟中动态加权伦理决策属性，借鉴多准则决策文献中的熵概念来自动计算权重。

Conclusion: 该方法将人类判断与模拟决策分离，提高了效率，同时确保伦理决策的合理性。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [15] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: 前沿AI系统在说服、欺骗和影响人类行为方面能力迅速提升，可能威胁网络安全。本文提出首个系统性框架，评估和缓解AI操纵风险。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统已展现出人类水平的说服和欺骗能力，可能被滥用操纵员工，威胁企业安全。缺乏系统性框架评估此类风险。

Method: 提出基于三个核心论点（无能、控制、可信度）的安全案例框架，明确证据需求、评估方法和实施考虑。

Result: 提供了首个将操纵风险纳入AI安全治理的系统方法，为企业评估和缓解威胁提供基础。

Conclusion: AI操纵风险需系统性管理，本文框架为企业提供了实用工具，以预防潜在灾难性后果。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [16] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 论文探讨了强化学习（RL）在提升大语言模型（LLMs）数学推理能力时的局限性，并提出了一种新的符号化评估框架VAR-MATH，以解决现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在数学推理任务上的改进可能只是对特定基准模式的过拟合，而非真正的推理能力提升。论文旨在验证这一点并改进评估方法。

Method: 引入VAR-MATH框架，将固定数值问题转化为符号模板，要求模型解决多个变体，以评估其推理一致性。

Result: 实验显示，RL训练的模型在符号化版本（VAR-AMC23和VAR-AIME24）上性能显著下降，表明其依赖表面启发式方法。

Conclusion: VAR-MATH提供了一种抗污染、更稳健的数学推理评估范式，揭示了现有RL方法的局限性。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [17] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 将概率事件演算（PEC）转化为马尔可夫决策过程（MDP），以支持目标导向推理和规划，同时保持PEC的可解释性。


<details>
  <summary>Details</summary>
Motivation: PEC在不确定环境中具有强大的叙事推理能力，但缺乏目标导向推理机制。

Method: 通过将PEC领域形式化转化为MDP，引入“行动情境”概念，保留PEC的灵活语义。

Result: PEC-MDP形式化支持时间推理和目标驱动规划，并能将学习策略映射回可解释的PEC表示。

Conclusion: PEC-MDP扩展了PEC的能力，同时保持了其可解释性，为复杂推理任务提供了新工具。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [18] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: X-MILP是一种基于约束推理技术的领域无关方法，用于为混合整数线性规划（MILP）构建对比解释，通过不可约不可行子系统（IIS）生成解释图。


<details>
  <summary>Details</summary>
Motivation: 随着对可信AI的需求增加，开发针对MILP的对比解释技术变得重要。

Method: 将用户查询编码为额外约束，通过计算IIS生成解释图。

Result: 在经典优化问题上测试，验证了方法的实用性。

Conclusion: X-MILP为MILP提供了有效的对比解释工具。

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [19] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 研究基于人工智能算法预测加州高速公路交通流量，使用MLR和RF模型，发现10分钟数据采集间隔效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决全球交通拥堵问题。

Method: 利用加州78号公路5个月的30秒间隔交通数据，采用MLR和RF算法，分析不同数据采集间隔（30秒至15分钟）。

Result: MLR和RF模型在10分钟数据采集间隔下表现最优（R^2、MAE、RMSE评估）。

Conclusion: 研究结果有助于未来交通拥堵解决方案和高效交通管理。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [20] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 论文提出了一种动态强化学习框架，改进静态树结构推理方法，提升推理质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有树结构推理方法（如ProbTree）在动态适应性和计算效率上的局限性。

Method: 采用动态强化学习框架，实时构建推理树并学习最优策略，实现选择性扩展和资源分配。

Result: 在保持概率严谨性的同时，提高了解决方案质量和计算效率。

Conclusion: 为树结构推理提供了新范式，平衡了概率框架的可靠性和实际问答系统所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [21] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: 论文提出修订后的十项功能标准，用于评估基于大语言模型（LLM）的人工道德代理（AMA），以应对LLM不透明性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的随机输出和不透明内部状态，传统伦理标准已不适用，需修订标准以指导LLM的道德代理发展。

Method: 提出十项功能标准，并通过模拟道德代理（SMA-LLS）和自动驾驶公交车（APB）场景进行验证。

Result: 修订后的标准（如道德一致性、上下文敏感性等）能更有效地评估LLM的道德代理。

Conclusion: 新标准有助于LLM道德代理的社会整合与对齐，未来需进一步验证其实际效果。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [22] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 论文提出了一种结合高阶模式和模糊等价关系的统一算法，用于决策任务中的推理。


<details>
  <summary>Details</summary>
Motivation: 在涉及抽象函数和谓词的决策任务中，高阶理论和模糊逻辑的结合具有潜力，但高效推理和计算技术仍具挑战性。

Method: 采用高阶模式和基于最小T-范数的模糊等价关系，提出统一算法并证明其终止性、可靠性和完备性。

Result: 算法能计算最一般的统一子，并在可统一时提供最高近似度。

Conclusion: 该算法为高阶模糊逻辑推理提供了有效工具，适用于需要模糊匹配的场景。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [23] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 论文提出了一种名为GEA（Generative Energy Arena）的新方法，通过将模型能耗信息纳入评估过程，研究能耗意识如何影响用户选择模型。初步结果显示，用户倾向于选择更节能的小型模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估方法存在局限性，如自动化基准测试与人类评估相关性差，而传统人类评估方法又难以扩展且成本高。此外，模型能耗问题日益重要，但尚未被纳入评估体系。

Method: 提出GEA（Generative Energy Arena），一种公开竞技场，允许用户在评估模型时获取能耗信息，并基于此选择模型。

Result: 初步结果表明，用户在了解能耗信息后，更倾向于选择小型且节能的模型，而非性能更高但能耗更大的模型。

Conclusion: GEA为模型评估提供了新视角，表明在大多数用户交互中，高能耗模型的额外成本并未带来感知质量的显著提升，因此节能模型更具实际优势。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [24] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 论文提出了FormulaOne基准测试，用于评估前沿AI模型在复杂现实研究问题中的表现，结果显示当前最先进模型表现极差。


<details>
  <summary>Details</summary>
Motivation: 探讨前沿AI模型是否具备接近人类或超人类专家的能力，尤其是在解决复杂现实研究问题方面。

Method: 构建FormulaOne基准测试，结合图论、逻辑和算法，生成高难度问题，并评估模型表现。

Result: 最先进模型（如OpenAI的o3）在FormulaOne上表现极差，解决率低于1%。

Conclusion: 前沿AI模型在复杂领域仍远未达到专家水平，FormulaOne为未来研究提供了评估框架。

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Robust Resource Allocation for Pinching-Antenna Systems under Imperfect CSI](https://arxiv.org/abs/2507.12582)
*Ming Zeng,Xianbin Wang,Yuanwei Liu,Zhiguo Ding,George K. Karagiannidis,H. Vincent Poor*

Main category: cs.IT

TL;DR: 本文研究了在多用户夹持天线下行系统中，用户位置不确定时的鲁棒资源分配问题，旨在最小化总发射功率并满足个体中断概率约束。


<details>
  <summary>Details</summary>
Motivation: 现有夹持天线设计通常假设用户位置完全已知，这在实际系统中不现实。本文旨在解决用户位置不确定的问题。

Method: 针对单用户情况，通过二分法和几何分析确定最优夹持天线位置和功率分配；针对多用户情况，采用粒子群优化（PSO）算法解决非凸、不可微的优化问题。

Result: 仿真结果表明，所提方案优于传统固定天线系统，验证了PSO算法在位置不确定下的有效性。

Conclusion: 本文提出的方法在多用户夹持天线系统中有效解决了位置不确定性问题，显著提升了系统性能。

Abstract: Pinching-antenna technology has lately showcased its promising capability for
reconfiguring wireless propagation environments, especially in high-frequency
communication systems like millimeter-wave and terahertz bands. By dynamically
placing the antenna over a dielectric waveguide, line-of-sight (LoS)
connections can be made to significantly improve system performance. Although
recent research have illustrated the advantages of pinching-antenna-assisted
designs, they mainly presuppose complete knowledge of user locations -- an
impractical assumption in real-world systems. To address this issue, the robust
resource allocation in a multi-user pinching antenna downlink system with
uncertain user positions is investigated, aiming to minimize total transmit
power while satisfying individual outage probability constraints. First, we
address the single-user case, deriving the optimal pinching antenna position
and obtaining the corresponding power allocation using a bisection method
combined with geometric analysis. We then extend this solution to the
multi-user case. In this case, we optimize the pinching antenna position using
a particle swarm optimization (PSO) algorithm to handle the resulting
non-convex and non-differentiable optimization problem. Simulation results
demonstrate that the proposed scheme outperforms conventional fixed-antenna
systems and validate the effectiveness of the PSO-based antenna placement
strategy under location uncertainty.

</details>


### [26] [Learning-Based Interface for Semantic Communication with Bit Importance Awareness](https://arxiv.org/abs/2507.12850)
*Wenzheng Kong,Wenyi Zhang*

Main category: cs.IT

TL;DR: 提出一种基于学习的接口设计方法，提升Split DeepJSCC性能，支持动态适应不同信道条件。


<details>
  <summary>Details</summary>
Motivation: 解决现有JSCC方法难以与现有通信网络架构集成的问题。

Method: 提出学习型接口设计，引入可训练参数，并设计重要性感知网络以动态适应信道条件。

Result: 实验表明，该方法在无线图像传输任务中性能提升。

Conclusion: 为现有无线网络中实现语义通信提供了潜在解决方案。

Abstract: Joint source-channel coding (JSCC) is an effective approach for semantic
communication. However, current JSCC methods are difficult to integrate with
existing communication network architectures, where application and network
providers are typically different entities. Recently, a novel paradigm termed
Split DeepJSCC has been under consideration to address this challenge. Split
DeepJSCC employs a bit-level interface that enables separate design of source
and channel codes, ensuring compatibility with existing communication networks
while preserving the advantages of JSCC in terms of semantic fidelity and
channel adaptability. In this paper, we propose a learning-based interface
design by treating its parameters as trainable, achieving improved end-to-end
performance compared to Split DeepJSCC. In particular, the interface enables
specification of bit-level importance at the output of the source code.
Furthermore, we propose an Importance-Aware Net that utilizes the
interface-derived bit importance information, enabling dynamical adaptation to
diverse channel bandwidth ratios and time-varying channel conditions.
Experimental results show that our method improves performance in wireless
image transmission tasks. This work provides a potential solution for realizing
semantic communications in existing wireless networks.

</details>


### [27] [Robust Beamforming Design for Secure Near-Field ISAC Systems](https://arxiv.org/abs/2507.12881)
*Ziqiang CHen,Feng Wang,Guojun Han,Xin Wang,Vincent K. N. Lau*

Main category: cs.IT

TL;DR: 该论文研究了近场安全集成感知与通信（ISAC）系统中的鲁棒波束成形设计，考虑了信道不确定性约束，通过优化方法提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC系统在安全性和鲁棒性方面面临挑战，特别是在存在多个通信用户、目标和窃听者的情况下，需要设计高效的波束成形方案。

Method: 采用S-Procedure将半无限信道不确定性约束转化为线性矩阵不等式（LMIs），并利用SROCR方法处理秩一约束。

Result: 数值结果表明，所提出的ISAC波束成形设计在性能上优于现有的SDR和其他基线方案，显著提升了系统的安全性和鲁棒性。

Conclusion: 该研究为近场ISAC系统提供了一种高效的鲁棒波束成形设计方案，具有实际应用潜力。

Abstract: This letter investigates the robust beamforming design for a near-field
secure integrated sensing and communication (ISAC) system with multiple
communication users (CUs) and targets, as well as multiple eavesdroppers.
Taking into account the channel uncertainty constraints, we maximize the
minimum sensing beampattern gain for targets, subject to the minimum
signal-to-interference-plus-noise ratio (SINR) constraint for each CU and the
maximum SINR constraint for each eavesdropper, as well as the ISAC transmit
power constraint. The formulated design problem is non-convex. As a
low-complexity suboptimal solution, we first apply the S-Procedure to convert
semi-infinite channel uncertainty constraints into linear matrix inequalities
(LMIs) and then use the state-of-the-art sequential rank-one constraint
relaxation (SROCR) method to address the rank-one constraints. The numerical
results show that the proposed ISAC beamforming design scheme outperforms the
existing semidefinite relaxation (SDR) and other baseline schemes, and it
significantly enhances security and robustness for near-field ISAC systems.

</details>


### [28] [Secure Pinching Antenna-aided ISAC](https://arxiv.org/abs/2507.13131)
*Elmehdi Illi,Marwa Qaraqe,Ali Ghrayeb*

Main category: cs.IT

TL;DR: 研究了一种基于夹持天线（PA）的安全集成感知与通信系统（ISAC）方案，优化PA位置和信号设计以提升感知性能，同时确保通信保密性。


<details>
  <summary>Details</summary>
Motivation: 在双功能雷达通信（DFRC）基站系统中，如何在服务合法用户的同时检测恶意目标并确保通信保密性是一个关键问题。

Method: 通过优化PA位置，设计合法信号波束成形和人工噪声协方差矩阵，以最大化感知性能，同时满足保密性和总功率约束。

Result: 数值实验表明，该方案在照明功率上比传统PA方案提升3dB，比传统ISAC系统提升高达30dB。

Conclusion: 提出的PA辅助方案在感知性能和通信保密性方面显著优于传统方法。

Abstract: In this letter, a pinching antenna (PA)-aided scheme for establishing a
secure integrated sensing and communication system (ISAC) is investigated. The
underlying system comprises a dual-functional radar communication (DFRC) base
station (BS) linked to multiple waveguides to serve several downlink users
while sensing a set of malicious targets in a given area. The PA-aided BS aims
at preserving communication confidentiality with the legitimate users while
being able to detect malicious targets. One objective of the proposed scheme is
to optimize the PA locations, based on which an optimal design of the
legitimate signal beamforming and artificial noise covariance matrices is
provided to maximize the network's sensing performance, subject to secrecy and
total power constraints. We demonstrate the efficacy of the proposed scheme
through numerical examples and compare that against a traditional DFRC ISAC
system with a uniform linear array of half-wavelength-spaced antennas. We show
that the proposed scheme outperforms the baseline PA-aided scheme with
equidistant PAs by $3$ dB in terms of illumination power, while it can provide
gains of up to $30$ dB of the same metric against a traditional ISAC system
with half-wavelength-space uniform linear arrays.

</details>


### [29] [A Framework of Distributed Source Encryption using Mutual Information Security Criterion and the Strong Converse Theorem](https://arxiv.org/abs/2507.13294)
*Yasutada Oohama,Bagus Santoso*

Main category: cs.IT

TL;DR: 本文重新研究了基于Oohama和Santoso提出的通用密钥加密系统的分布式安全源编码，采用标准安全准则（标准互信息）重新建立了速率区域的边界。


<details>
  <summary>Details</summary>
Motivation: Oohama和Santoso提出的框架使用了非标准安全准则，本文旨在采用标准安全准则重新评估其速率区域的边界。

Method: 使用信息谱方法和Birkhoff-von Neumann定理的变体，推导速率区域的边界。

Result: 成功基于标准安全准则建立了速率区域的边界。

Conclusion: 通过标准安全准则重新验证了分布式安全源编码的可靠性，为相关研究提供了更通用的理论基础。

Abstract: We reinvestigate the general distributed secure source coding based on the
common key cryptosystem proposed by Oohama and Santoso (ITW 2021). They
proposed a framework of distributed source encryption and derived the necessary
and sufficient conditions to have reliable and secure transmission. However,
the bounds of the rate region, which specifies both necessary and sufficient
conditions to have reliable and secure transmission under the proposed
cryptosystem, were derived based on a self-tailored non-standard} security
criterion. In this paper we adopt the standard security criterion, i.e.,
standard mutual information. We successfully establish the bounds of the rate
region based on this security criterion. Information spectrum method and a
variant of Birkhoff-von Neumann theorem play an important role in deriving the
result.

</details>


### [30] [Analytical Optimization for Antenna Placement in Pinching-Antenna Systems](https://arxiv.org/abs/2507.13307)
*Zhiguo Ding,H. Vincent Poor*

Main category: cs.IT

TL;DR: 本文通过解析优化方法研究了夹持天线系统的天线位置优化问题，揭示了不同传输方案下最优天线位置的选择规律。


<details>
  <summary>Details</summary>
Motivation: 现有研究多采用数值优化方法，缺乏对夹持天线位置选择的深入理解，本文旨在填补这一研究空白。

Method: 采用解析优化方法，针对正交多址（OMA）和非正交多址（NOMA）传输方案，推导了最优天线位置的闭式解。

Result: 对于用户公平导向的OMA传输，天线位置需对所有用户有利；而对于贪婪分配的OMA传输，天线位置应靠近波导最近用户。NOMA传输下，最优位置则靠近波导最近用户。

Conclusion: 解析优化揭示了天线位置对系统性能的影响，为夹持天线系统设计提供了理论指导。

Abstract: As the main issue in pinching-antenna system design, antenna location
optimization is key to realizing channel reconfigurability and system
flexibility. Most existing works in this area adopt sophisticated optimization
and learning tools to identify the optimal antenna locations in a numerical
manner, where insightful understandings of the pinching antenna placement are
still missing. Motivated by this research gap, this paper aims to carry out
analytical optimization for pinching antenna placement, where closed-form
solutions for the optimal antenna locations are obtained to reveal the impact
of antenna placement on the system performance. In particular, for the
user-fairness-oriented orthogonal multiple access (OMA) based transmission,
analytical results are obtained to reveal that the pinching antenna needs to be
activated at the place that would be beneficial to all served users; however,
the users' distances to the waveguide have no impact on the location selection.
For the greedy-allocation-based OMA transmission, an asymptotic study based on
a high signal-to-noise ratio approximation is carried out to show that the
optimal antenna location is in close proximity to the user who is nearest to
the waveguide. For non-orthogonal multiple access (NOMA) based transmission,
even with a user-fairness-oriented objective, the obtained analytical results
show that the optimal antenna location is not the position that can benefit all
users, but rather is near the user positioned closest to the waveguide.

</details>
