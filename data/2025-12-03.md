<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.IT](#cs.IT) [Total: 14]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [The xApp Store: A Framework for xApp Onboarding and Deployment in O-RAN](https://arxiv.org/abs/2512.02297)
*Philip Rodgers,Paul Harvey*

Main category: cs.NI

TL;DR: 基于开源O-RAN实现设计和开发xApp应用商店的经验分享


<details>
  <summary>Details</summary>
Motivation: 5G及未来移动通信网络正像云计算一样拥抱软件技术，特别是在无线接入网(RAN)中。RAN现在越来越多地由称为xApps的软件应用程序控制，这为第三方开发xApps打开了大门，类似于手机应用生态。然而，目前还没有一个可以托管或供应xApps的市场平台。

Method: 利用开源O-RAN实现来设计和开发xApp应用商店

Result: 论文描述了基于开源O-RAN实现设计和开发xApp应用商店的具体经验

Conclusion: 通过开发xApp应用商店，为O-RAN生态系统中的第三方xApps提供了一个市场平台，促进了RAN软件应用的多样化和生态系统发展，为实现自主网络运营提供了途径。

Abstract: 5G and beyond mobile telecommunication networks are increasingly embracing software technologies in their operation and control, similar to what has powered the growth of the cloud. This is most recently seen in the radio access network (RAN). In this new approach, the RAN is increasingly controlled by software applications known as xApps, and opens the door to third party development of xApps bringing diversity to the ecosystem, similar to mobile phone apps. This model aligns closely with the controllers in the ITU-T architecture for autonomous networks, and provides a pathway towards autonomous operation in the RAN. Unfortunately, no marketplace to host or supply xApps currently exists.
  This work describes our experiences in leveraging open-source O-RAN implementations to design and develop an xApp store.

</details>


### [2] [Intrusion Detection on Resource-Constrained IoT Devices with Hardware-Aware ML and DL](https://arxiv.org/abs/2512.02272)
*Ali Diab,Adel Chehade,Edoardo Ragusa,Paolo Gastaldo,Rodolfo Zunino,Amer Baghdadi,Mostafa Rizk*

Main category: cs.NI

TL;DR: 提出针对IoT/IIoT网络的硬件感知入侵检测系统，在边缘设备严格约束下优化树模型和紧凑DNN，实现快速、隐私保护、资源高效的威胁检测。


<details>
  <summary>Details</summary>
Motivation: IoT/IIoT网络需要快速、隐私保护且资源高效的入侵检测系统，但边缘设备有严格的存储、内存和计算限制，需要优化模型以适应这些约束。

Method: 采用约束网格搜索优化树基分类器（如LightGBM），使用硬件感知神经架构搜索（HW-NAS）优化1D-CNN；在Edge-IIoTset基准上评估，并在Raspberry Pi 3 B Plus上部署完整流水线。

Result: LightGBM达到95.3%准确率，仅需75KB闪存和1.2K操作；HW-NAS优化的CNN达到97.2%准确率，需要190KB闪存和840K FLOPs。树模型在30ms内运行，CNN在精度优先时仍适用。

Conclusion: 硬件约束模型设计对于边缘实时入侵检测系统具有实际可行性，树模型和CNN在不同场景下各有优势，为IoT/IIoT安全提供了实用的解决方案。

Abstract: This paper proposes a hardware-aware intrusion detection system (IDS) for Internet of Things (IoT) and Industrial IoT (IIoT) networks; it targets scenarios where classification is essential for fast, privacy-preserving, and resource-efficient threat detection. The goal is to optimize both tree-based machine learning (ML) models and compact deep neural networks (DNNs) within strict edge-device constraints. This allows for a fair comparison and reveals trade-offs between model families. We apply constrained grid search for tree-based classifiers and hardware-aware neural architecture search (HW-NAS) for 1D convolutional neural networks (1D-CNNs). Evaluation on the Edge-IIoTset benchmark shows that selected models meet tight flash, RAM, and compute limits: LightGBM achieves 95.3% accuracy using 75 KB flash and 1.2 K operations, while the HW-NAS-optimized CNN reaches 97.2% with 190 KB flash and 840 K floating-point operations (FLOPs). We deploy the full pipeline on a Raspberry Pi 3 B Plus, confirming that tree-based models operate within 30 ms and that CNNs remain suitable when accuracy outweighs latency. These results highlight the practicality of hardware-constrained model design for real-time IDS at the edge.

</details>


### [3] [Adversarial Robustness of Traffic Classification under Resource Constraints: Input Structure Matters](https://arxiv.org/abs/2512.02276)
*Adel Chehade,Edoardo Ragusa,Paolo Gastaldo,Rodolfo Zunino*

Main category: cs.NI

TL;DR: 使用硬件感知神经架构搜索（HW-NAS）开发轻量级流量分类模型，研究输入结构（扁平字节序列vs 2D时间序列）对对抗性攻击鲁棒性的影响，并通过对抗性微调提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 在物联网和嵌入式环境中，流量分类需要在硬件资源受限的边缘设备上本地执行，因此需要开发既准确又高效的轻量级模型。同时，这些模型需要具备对抗对抗性攻击的鲁棒性，以确保网络安全。

Method: 采用硬件感知神经架构搜索（HW-NAS）设计轻量级流量分类模型，考虑两种输入格式：扁平字节序列和2D包级时间序列。评估模型在FGSM和PGD白盒攻击下的鲁棒性，并通过对抗性微调提升模型安全性。

Result: 在USTC-TFC2016数据集上，两种HW-NAS模型在干净数据上都达到99%以上的准确率，参数量小于65k，计算量小于2M FLOPs。但在强度0.1的扰动下，扁平模型保持85%以上准确率，而时间序列模型降至35%以下。对抗性微调后，扁平模型准确率超过96%，时间序列模型鲁棒性提升60个百分点，且不牺牲效率。

Conclusion: 输入结构显著影响模型的对抗性脆弱性，扁平输入格式比时间序列格式更具鲁棒性。通过对抗性微调，即使是紧凑的资源高效模型也能获得强大的鲁棒性，支持其在安全边缘流量分类中的实际部署。

Abstract: Traffic classification (TC) plays a critical role in cybersecurity, particularly in IoT and embedded contexts, where inspection must often occur locally under tight hardware constraints. We use hardware-aware neural architecture search (HW-NAS) to derive lightweight TC models that are accurate, efficient, and deployable on edge platforms. Two input formats are considered: a flattened byte sequence and a 2D packet-wise time series; we examine how input structure affects adversarial vulnerability when using resource-constrained models. Robustness is assessed against white-box attacks, specifically Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD). On USTC-TFC2016, both HW-NAS models achieve over 99% clean-data accuracy while remaining within 65k parameters and 2M FLOPs. Yet under perturbations of strength 0.1, their robustness diverges: the flat model retains over 85% accuracy, while the time-series variant drops below 35%. Adversarial fine-tuning delivers robust gains, with flat-input accuracy exceeding 96% and the time-series variant recovering over 60 percentage points in robustness, all without compromising efficiency. The results underscore how input structure influences adversarial vulnerability, and show that even compact, resource-efficient models can attain strong robustness, supporting their practical deployment in secure edge-based TC.

</details>


### [4] [Coalitional Game Framework for Multicast in Wireless Networks](https://arxiv.org/abs/2512.02347)
*Anjali Yadav,Arya Agarwal,Alok Kumar,Tushar S. Muratkar,Gaurav S. Kasbekar*

Main category: cs.NI

TL;DR: 研究无线网络中用户通过合作形成联盟进行组播下载的稳定性条件，分析核心解的存在性和D_c稳定性，探讨系统参数对联盟稳定性的影响。


<details>
  <summary>Details</summary>
Motivation: 在无线网络中，多个用户都希望从发射机下载同一个热门文件。本文旨在研究用户之间是否有激励进行合作形成联盟，以便通过组播方式接收文件，从而更有效地利用网络资源。

Method: 使用合作博弈论框架，首先采用核心解概念分析大联盟的稳定性条件，识别核心非空和空的条件；然后使用D_c稳定性概念分析固定数量联盟形成的条件；最后通过数值计算验证分析结果。

Result: 分析结果表明，不同系统参数（如用户数据速率、发射和接收功率、文件大小、带宽成本等）的值会影响联盟的稳定性特性。提供了评估用户组播合作可行性的系统方法，并识别了稳定合作组播策略的条件。

Conclusion: 本文解决了组播背景下联盟形成的基本问题，为无线网络中稳定合作组播策略的可行性提供了新的见解，有助于更深入地理解无线网络中的合作行为。

Abstract: We consider a wireless network in which there is a transmitter and a set of users, all of whom want to download a popular file from the transmitter. Using the framework of cooperative game theory, we investigate conditions under which users have incentives to cooperate among themselves to form coalitions for the purpose of receiving the file via multicast from the transmitter. First, using the solution concept of core, we investigate conditions under which it is beneficial for all users to cooperate, i.e., the grand coalition is stable. We provide several sets of sufficient conditions under which the core is non-empty as well as those under which the core is empty. Next, we use the concept of $\mathbb{D}_c$-stability to identify a set of sufficient conditions under which the users in the network form a certain fixed number of coalitions such that all the users within each coalition cooperate among themselves. Our analytical results show how the values of different system parameters, e.g., data rates of different users, transmit and receive power, file size, bandwidth cost, etc., influence stability properties of coalitions, and provide a systematic approach to evaluating cooperation of users for multicast. We also study cooperation among different users using numerical computations. The problem of coalition formation in the context of multicast addressed in this paper is fundamental, and our analysis provides new insights into the feasibility of stable cooperative multicast strategies, contributing to a deeper understanding of cooperation in wireless networks.

</details>


### [5] [Diffusion-Model-enhanced Multiobjective Optimization for Improving Forest Monitoring Efficiency in UAV-enabled Internet-of-Things](https://arxiv.org/abs/2512.02370)
*Hongyang Pan,Bin Lin,Yanheng Liu,Shuang Liang,Chau Yuen*

Main category: cs.NI

TL;DR: 本文提出了一种基于扩散模型增强的多目标灰狼优化器（IMOGWO），用于解决森林监测中无人机辅助物联网系统的多目标优化问题，旨在同时最小化计算延迟、运动能耗和计算资源。


<details>
  <summary>Details</summary>
Motivation: 森林监测中物联网传感器节点计算能力有限，虽然无人机可以作为移动计算处理器增强计算能力，但面临着有限能量预算和计算资源下的高效监测挑战。需要同时优化计算延迟、能耗和资源使用。

Method: 构建了同时最小化最大计算延迟、总运动能耗和最大计算资源的三目标优化框架。针对混合解空间（连续和离散解），提出了扩散模型增强的改进多目标灰狼优化器（IMOGWO）。

Result: IMOGWO在解决该优化框架时优于其他基准方法。在小规模网络（6架无人机，50个传感器节点）中，相比次优基准，运动能耗降低53.32%，计算资源减少9.83%，同时保持计算延迟水平。在大规模网络（8架无人机，100个传感器节点）中，运动能耗降低41.81%，计算资源减少7.93%，计算延迟保持相当。

Conclusion: 提出的IMOGWO算法能有效解决森林监测中无人机辅助物联网系统的多目标优化问题，在降低能耗和资源使用的同时保持计算性能，为高效森林监测提供了可行的解决方案。

Abstract: The Internet-of-Things (IoT) is widely applied for forest monitoring, since the sensor nodes (SNs) in IoT network are low-cost and have computing ability to process the monitoring data. To further improve the performance of forest monitoring, uncrewed aerial vehicles (UAVs) are employed as the data processors to enhance computing capability. However, efficient forest monitoring with limited energy budget and computing resource presents a significant challenge. For this purpose, this paper formulates a multi-objective optimization framework to simultaneously consider three optimization objectives, which are minimizing the maximum computing delay, minimizing the total motion energy consumption, and minimizing the maximum computing resource, corresponding to efficient forest monitoring, energy consumption reduction, and computing resource control, respectively. Due to the hybrid solution space that consists of continuous and discrete solutions, we propose a diffusion model-enhanced improved multi-objective grey wolf optimizer (IMOGWO) to solve the formulated framework. The simulation results show that the proposed IMOGWO outperforms other benchmarks for solving the formulated framework. Specifically, for a small-scale network with $6$ UAVs and $50$ SNs, compared to the suboptimal benchmark, IMOGWO reduces the motion energy consumption and the computing resource by $53.32\%$ and $9.83\%$, respectively, while maintaining computing delay at the same level. Similarly, for a large-scale network with $8$ UAVs and $100$ SNs, IMOGWO achieves reductions of $41.81\%$ in motion energy consumption and $7.93\%$ in computing resource, with the computing delay also remaining comparable.

</details>


### [6] [ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs](https://arxiv.org/abs/2512.02398)
*Zhiyu Zhou,Xin Zhe Khooi,Satis Kumar Permal,Mun Choon Chan*

Main category: cs.NI

TL;DR: ProtO-RU是首个基于SDR和商用CPU的开源软件定义O-RAN Split-7.2无线单元，采用srsRAN软件栈，支持TDD/FDD模式，能与商用5G终端互操作，性能与商用O-RU相当。


<details>
  <summary>Details</summary>
Motivation: 当前O-RAN无线单元多为专有硬件，缺乏开源可编程方案，限制了RU级别的创新和端到端O-RAN研究的门槛。

Method: 基于开源srsRAN软件栈，使用软件定义无线电和商用CPU构建软件定义的O-RU，支持与srsRAN和OpenAirInterface5G CU/DU栈集成。

Result: ProtO-RU在多用户持续负载下保持稳定，吞吐量与Split-8和商用O-RU相当，支持TDD/FDD模式，能与商用5G终端互操作。

Conclusion: ProtO-RU为RU级别创新提供了新机会，降低了端到端O-RAN研究的门槛，是首个开源软件定义的O-RAN Split-7.2无线单元。

Abstract: We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.

</details>


### [7] [Widening the Coverage of Reference Broadcast Infrastructure Synchronization in Wi-Fi Networks](https://arxiv.org/abs/2512.02454)
*Gianluca Cena,Pietro Chiavassa,Gabriele Formis,Stefano Scanzio*

Main category: cs.NI

TL;DR: DOMINO是RBIS协议的演进版本，通过边界时钟机制将Wi-Fi时间同步扩展到整个工厂范围，而不仅限于单个网络基础设施。


<details>
  <summary>Details</summary>
Motivation: 精确时钟同步协议对工业环境至关重要，但现有RBIS方案仅适用于单个Wi-Fi网络，无法覆盖整个工厂范围。需要扩展同步范围以支持大规模工业应用。

Method: 提出DOMINO协议，利用能够同时看到多个接入点的无线站点作为边界时钟，在重叠网络间传播参考时间，从而扩展同步覆盖范围。

Result: DOMINO的覆盖区域远大于单个Wi-Fi基础设施网络，可潜在覆盖整个工厂范围，实现大规模时间同步。

Conclusion: DOMINO作为RBIS的演进版本，通过边界时钟机制成功扩展了Wi-Fi时间同步的范围，为工业环境提供了更广泛的时间同步解决方案。

Abstract: Precise clock synchronization protocols are increasingly used to ensure that all the nodes in a network share the very same time base. They enable several mechanisms aimed at improving determinism at both the application and communication levels, which makes them highly relevant to industrial environments. Reference Broadcast Infrastructure Synchronization (RBIS) is a solution specifically conceived for Wi-Fi that exploits existing beacons and can run on commercial devices. In this paper, an evolution of RBIS is presented, we call DOMINO, whose coverage area is much larger than the single Wi-Fi infrastructure network, potentially including the whole plant. In particular, wireless stations that can see more than one access point at the same time behave as boundary clocks and propagate the reference time across overlapping networks.

</details>


### [8] [Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments](https://arxiv.org/abs/2512.02455)
*Pietro Chiavassa,Stefano Scanzio,Gianluca Cena*

Main category: cs.NI

TL;DR: 评估Wi-Fi速率自适应算法Minstrel在工业环境中的性能，重点关注静态和移动场景下的延迟和丢包率，为基于数字孪生的增强算法开发提供基础。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi在工业环境中用于连接移动设备（如自主移动机器人和主动外骨骼）具有前景，但工业环境对可靠性和有界传输延迟的要求很高。速率自适应算法对数据包传输成功率影响很大，而Minstrel作为Linux内核默认算法，其性能在工业场景下需要评估。

Method: 对Minstrel速率自适应算法进行性能评估，包括静态场景和移动场景。分析重点放在工业环境关心的指标上：延迟和丢包率。研究为未来基于集中式数字孪生的增强速率自适应算法开发提供初步评估。

Result: 论文提供了Minstrel算法在静态和移动场景下的性能评估结果，重点关注延迟和丢包率指标。这些结果为后续开发基于数字孪生的增强速率自适应算法奠定了基础。

Conclusion: Minstrel速率自适应算法在工业环境中的性能需要进一步优化，特别是针对有界延迟要求。基于集中式数字孪生的增强算法是未来的发展方向，本文的评估为此提供了必要的性能基准。

Abstract: Wi-Fi is currently considered one of the most promising solutions for interconnecting mobile equipment (e.g., autonomous mobile robots and active exoskeletons) in industrial environments. However, relability requirements imposed by the industrial context, such as ensuring bounded transmission latency, are a major challenge for over-the-air communication. One of the aspects of Wi-Fi technology that greatly affects the probability of a packet reaching its destination is the selection of the appropriate transmission rate. Rate adaptation algorithms are in charge of this operation, but their design and implementation are not regulated by the IEEE 802.11 standard. One of the most popular solutions, available as open source, is Minstrel, which is the default choice for the Linux Kernel. In this paper, Minstrel performance is evaluated for both static and mobility scenarios. Our analysis focuses on metrics of interest for industrial contexts, i.e., latency and packet loss ratio, and serves as a preliminary evaluation for the future development of enhanced rate adaptation algorithms based on centralized digital twins.

</details>


### [9] [Rural Connectivity Inequalities in Finland and Sweden: Evidence, Measures, and Policy Reflections](https://arxiv.org/abs/2512.02649)
*Sameera Bandaranayake,Amirreza Moradi,Tanja Suomalainen,Harri Saarnisaari,Pasi Karppinen,Payal Gupta,Jaap van de Beek*

Main category: cs.NI

TL;DR: 本文研究了芬兰和瑞典北部农村地区的宽带连接不平等问题，提出了新的蜂窝覆盖不平等指数（CCI），揭示了国家统计数据掩盖的空间差异，并提出了六项政策建议。


<details>
  <summary>Details</summary>
Motivation: 即使在数字化先进国家，城乡宽带连接差距仍然是重大政策挑战。本文旨在研究这些不平等在芬兰和瑞典北部的表现，这些地区人口稀疏、距离遥远、需求季节性变化导致服务质量差距持续存在。

Method: 采用混合研究方法：调查数据（n=148）、深度访谈和空间分析，探索北极农村社区的连接体验，并引入新的蜂窝覆盖不平等指数（CCI），该指数结合了农村性和网络性能的测量。

Result: 结果显示标题指标夸大了包容性，而本地用户报告了影响工作、安全和获取服务的慢性连接差距。CCI指数揭示了被国家覆盖统计数据掩盖的空间不平等。

Conclusion: 本文提出了六项政策建议：共享基础设施和漫游框架、农村运营商的频谱灵活性、基于性能的服务质量监控、标准化透明报告、时间和季节性容量管理、数字技能倡议。强调需要多维指标和治理机制，将技术性能、空间公平和用户体验联系起来。

Abstract: Persistent rural-urban disparities in broadband connectivity remain a major policy challenge, even in digitally advanced countries. This paper examines how these inequalities manifest in northern Finland and Sweden, where sparse populations, long distances, and seasonal variations in demand create persistent gaps in service quality and reliability. Drawing on survey data (n = 148), in-depth interviews, and spatial analysis, the study explores the lived experience of connectivity in Arctic rural communities and introduces a novel Cellular Coverage Inequality (CCI) Index. The index combines measures of rurality and network performance to quantify spatial disparities that are masked by national coverage statistics. Results reveal that headline indicators overstate inclusiveness, while local users report chronic connectivity gaps affecting work, safety, and access to services. Building on these findings, the paper outlines policy reflections in six areas: shared infrastructure and roaming frameworks, spectrum flexibility for rural operators, performance-based Quality-of-Service monitoring, standardized and transparent reporting, temporal and seasonal capacity management, and digital-skills initiatives. Together, these recommendations highlight the need for multidimensional metrics and governance mechanisms that link technical performance, spatial equity, and user experience. The analysis contributes to ongoing debates on how broadband policy in sparsely populated regions can move beyond nominal coverage targets toward genuine inclusion and reliability.

</details>


### [10] [ISAC-Powered Distributed Matching and Resource Allocation in Multi-band NTN](https://arxiv.org/abs/2512.02843)
*Israel Leyva-Mayorga,Shashi Raj Pandey,Petar Popovski,Fabio Saggese,Beatriz Soret,Cedomir Stefanovic*

Main category: cs.NI

TL;DR: 该论文提出了一种基于集成感知与通信（ISAC）的多频段卫星网络框架，通过分布式大气感知、小区-卫星匹配和资源分配机制，在5G非地面网络中实现弹性高效运行，相比单频段系统提升73%的用户吞吐量。


<details>
  <summary>Details</summary>
Motivation: 非对地静止轨道（NGSO）卫星网络面临可扩展性挑战，大量地面用户共享有限的sub-6 GHz频谱。虽然使用K频段及更高频段可增加可用带宽，但这些频段受大气衰减（特别是降雨）影响严重，可能导致性能下降和链路中断。

Method: 提出ISAC驱动的多频段卫星网络框架，包含分布式大气感知、小区-卫星匹配和资源分配机制。在5G非地面网络（NTN）广域场景中，采用准地球固定小区和波束跳变机制，通过多层多频段星座（S频段和K频段卫星）实现。

Result: 在多层多频段星座（S频段和K频段卫星）的测试中，该ISAC驱动的多频段系统相比单S频段和单K频段系统，实现了73%更高的每用户吞吐量。

Conclusion: ISAC驱动的多频段卫星网络框架能够有效应对大气衰减挑战，通过智能感知和资源分配实现弹性高效运行，显著提升卫星网络性能和用户体验。

Abstract: Scalability is a major challenge in non-geostationary orbit (NGSO) satellite networks due to the massive number of ground users sharing the limited sub-6 GHz spectrum. Using K- and higher bands is a promising alternative to increase the accessible bandwidth, but these bands are subject to significant atmospheric attenuation, notably rainfall, which can lead to degraded performance and link outages. We present an integrated sensing and communications (ISAC)-powered framework for resilient and efficient operation of multi-band satellite networks. It is based on distributed mechanisms for atmospheric sensing, cell-to-satellite matching, and resource allocation (RA) in a 5G Non-Terrestrial Network (NTN) wide-area scenario with quasi-Earth fixed cells and a beam hopping mechanism. Results with a multi-layer multi-band constellation with satellites operating in the S- and K-bands demonstrate the benefits of our framework for ISAC-powered multi-band systems, which achieves 73% higher throughput per user when compared to single S- and K-band systems.

</details>


### [11] [Network Self-Configuration based on Fine-Tuned Small Language Models](https://arxiv.org/abs/2512.02861)
*Oscar G. Lira,Oscar M. Caicedo,Nelson L. S. Da Fonseca*

Main category: cs.NI

TL;DR: SLM_netconfig是一个基于微调小型语言模型的网络配置框架，使用代理架构和参数高效适应技术，将自然语言需求转换为有效网络配置，实现高效、准确且保护隐私的本地自动化配置。


<details>
  <summary>Details</summary>
Motivation: 随着网络规模和复杂性增长，手动配置效率低下且易出错。现有基于大语言模型的意图驱动配置方法计算成本高、资源密集，且依赖外部云基础设施引发隐私担忧。

Method: 采用微调小型语言模型框架，结合代理架构和参数高效适应技术，使用从厂商文档生成的领域特定数据集进行训练，实现自然语言到网络配置的转换。

Result: SLM_netconfig在问题到配置模型上，比LLM-NetCFG获得更高的语法准确性和目标准确性，显著降低翻译延迟，生成简洁可解释的配置。

Conclusion: 微调的小型语言模型能够提供高效、准确且保护隐私的自动化配置生成，完全在本地运行，是现代自主网络配置的实用且可扩展解决方案。

Abstract: As modern networks grow in scale and complexity, manual configuration becomes increasingly inefficient and prone to human error. While intent-driven self-configuration using large language models has shown significant promise, such models remain computationally expensive, resource-intensive, and often raise privacy concerns because they typically rely on external cloud infrastructure. This work introduces SLM_netconfig, a fine-tuned small language model framework that uses an agent-based architecture and parameter-efficient adaptation techniques to translate configuration intents expressed as natural language requirements or questions into syntactically and semantically valid network configurations. The system is trained on a domain-specific dataset generated through a pipeline derived from vendor documentation, ensuring strong alignment with real-world configuration practices. Extensive evaluation shows that SLM_netconfig, when using its question-to-configuration model, achieves higher syntactic accuracy and goal accuracy than LLM-NetCFG while substantially reducing translation latency and producing concise, interpretable configurations. These results demonstrate that fine-tuned small language models, as implemented in SLM_netconfig, can deliver efficient, accurate, and privacy-preserving automated configuration generation entirely on-premise, making them a practical and scalable solution for modern autonomous network configuration.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [The 4/$δ$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee](https://arxiv.org/abs/2512.02080)
*PIerre Dantas,Lucas Cordeiro,Youcheng Sun,Waldir Junior*

Main category: cs.AI

TL;DR: 提出LLM-Verifier收敛定理，为LLM与形式验证工具的交互提供首个具有可证明终止性和收敛性保证的形式化框架，并通过大规模实验验证理论预测。


<details>
  <summary>Details</summary>
Motivation: 当前将大型语言模型与形式验证工具结合的方法缺乏可靠的理论基础，导致验证过程不稳定（可能收敛、循环或发散），限制了在安全关键软件环境中的可靠应用。

Method: 将LLM与验证器的交互建模为离散时间马尔可夫链，状态转移由错误减少概率δ决定。提出LLM-Verifier收敛定理，证明对于任意δ>0，过程几乎必然达到验证状态，且期望迭代次数有界E[n]≤4/δ。通过超过90,000次试验进行大规模实证验证。

Result: 理论预测与实证结果高度一致：所有运行都成功达到验证，收敛因子紧密聚集在Cf≈1.0附近。基于此将工作流划分为三个操作区域（边缘、实用、高性能），并建立了可靠的设计阈值。

Conclusion: 该工作为LLM辅助验证提供了坚实的理论基础和实验证据，使工程师能够进行可预测的资源规划和性能预算，为安全关键软件环境中的部署提供了必要的架构基础。

Abstract: The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($δ$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $δ> 0$, with an expected iteration count bounded by $\mathbb{E}[n] \leq 4/δ$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.

</details>


### [13] [Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code](https://arxiv.org/abs/2512.02170)
*Pritam Deka,Barry Devereux*

Main category: cs.AI

TL;DR: Flowchart2Mermaid：一个轻量级Web系统，可将流程图图像转换为可编辑的Mermaid.js代码，支持混合主动式编辑和AI助手


<details>
  <summary>Details</summary>
Motivation: 流程图通常以静态图像形式分享，难以编辑和重用，需要一种方法将其转换为结构化、版本可控的文本表示

Method: 使用详细的系统提示和视觉语言模型，通过Web界面将流程图图像转换为Mermaid.js代码，支持文本编辑、拖放节点插入和自然语言命令

Result: 开发了一个能生成结构化、版本可控文本表示的系统，该表示与渲染的图表保持同步，并引入了评估结构准确性、流程正确性、语法有效性和完整性的指标

Conclusion: 相比之前的图像转图表工具，该方法提供了更灵活、可编辑的解决方案，使流程图更易于重用和协作

Abstract: Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present \textsc{Flowchart2Mermaid}, a lightweight web system that converts flowchart images into editable Mermaid.js code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.

</details>


### [14] [From monoliths to modules: Decomposing transducers for efficient world modelling](https://arxiv.org/abs/2512.02193)
*Alexander Boyd,Franz Nowak,David Hyland,Manuel Baltieri,Fernando E. Rosas*

Main category: cs.AI

TL;DR: 提出一个框架，用于将复杂的世界模型（用transducer表示）分解为可并行处理的子transducer，从而提高计算效率并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实世界模型通常计算需求高，但真实场景往往包含模块化交互的子组件。为了在AI安全所需的透明性和实际推理所需的计算效率之间建立桥梁，需要开发可分解的世界模型框架。

Method: 开发了一个框架，用于将表示为transducer（一种推广POMDP的模型类）的复杂世界模型分解。该方法反转了transducer组合过程，推导出在独立输入-输出子空间上运行的子transducer。

Result: 实现了可并行化和可解释的模块化世界建模替代方案，支持分布式推理。为AI安全的结构透明性和实际推理的计算效率需求之间建立了基础。

Conclusion: 该框架为复杂世界模型的分解提供了理论基础，使得在保持模型透明性的同时提高计算效率成为可能，有助于AI系统的安全部署。

Abstract: World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.

</details>


### [15] [STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls](https://arxiv.org/abs/2512.02228)
*Shubhi Asthana,Bing Zhang,Chad DeLuca,Ruchi Mahindru,Hima Patel*

Main category: cs.AI

TL;DR: STRIDE框架帮助决定何时使用AI代理：通过任务分解、动态性评估和自反思需求分析，为任务推荐最合适的AI部署模式（直接LLM调用、引导式助手或完全自主代理），避免不必要的代理部署。


<details>
  <summary>Details</summary>
Motivation: 随着AI从无状态大语言模型向自主目标驱动代理的快速转变，需要解决一个核心问题：何时真正需要代理式AI？不加区分地部署代理会导致成本、复杂性和风险增加，因此需要原则性的框架来决定何时使用代理。

Method: 提出STRIDE框架，通过结构化任务分解、动态性归因和自反思需求分析，计算代理适用性分数，为任务推荐三种部署模式之一：直接LLM调用、引导式AI助手或完全自主代理式AI。

Result: 在30个真实世界任务（涵盖SRE、合规和企业自动化）中评估，STRIDE在模式选择上达到92%准确率，减少45%不必要的代理部署，降低37%资源成本。六个月专家验证确认其实际效用。

Conclusion: 这项工作将代理采用重新定义为必要性驱动的设计决策，确保自主性只在收益证明成本合理时才被应用，为AI部署提供了原则性的决策框架。

Abstract: The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.
  We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context.
  Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.

</details>


### [16] [Benchmarking LLM Agents for Wealth-Management Workflows](https://arxiv.org/abs/2512.02230)
*Rory Milsom*

Main category: cs.AI

TL;DR: 该论文扩展了TheAgentCompany平台，创建了财富管理领域的评估基准，研究通用LLM代理能否准确且经济地完成财富管理任务，发现代理的主要限制在于端到端工作流可靠性而非数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管现代工作依赖各种数字协作工具，但常规流程仍受人为错误和延迟困扰。论文旨在填补这一空白，研究通用LLM代理是否能在财富管理任务中既准确又经济地工作，为评估代理在助理级财富管理工作中的适用性创建有意义的评估集。

Method: 扩展TheAgentCompany平台，创建财务导向的环境；引入合成领域数据；丰富同事模拟；原型化自动任务生成管道；构建包含12个任务对的财富管理助理基准，涵盖检索、分析和综合/沟通任务；为每个任务创建高自主性和低自主性变体；使用明确的验收标准和确定性评分器。

Result: 代理的主要限制不在于数学推理能力，而在于端到端工作流的可靠性；自主性水平对代理性能有显著影响；不正确的模型评估阻碍了基准测试的有效性。

Conclusion: 通用LLM代理在财富管理任务中面临的主要挑战是工作流可靠性而非数学能力，自主性水平是关键影响因素，需要改进评估方法以准确衡量代理在专业领域的适用性。

Abstract: Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.

</details>


### [17] [TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?](https://arxiv.org/abs/2512.02261)
*Lewen Yan,Jilin Mei,Tianyi Zhou,Lige Huang,Jie Zhang,Dongrui Liu,Jing Shao*

Main category: cs.AI

TL;DR: TradeTrap是一个统一的评估框架，用于系统性地压力测试自适应和程序化自主交易代理，通过针对市场情报、策略制定、投资组合与账本处理、交易执行四个核心组件施加受控扰动，揭示当前自主交易代理在系统层面易被误导的脆弱性。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的交易代理在真实金融市场中部署越来越多，但其在对抗性或故障条件下的可靠性和鲁棒性尚未得到充分检验，而金融环境具有高风险和不可逆的特点，这种安全漏洞可能带来严重后果。

Method: 提出TradeTrap统一评估框架，针对自主交易代理的四个核心组件（市场情报、策略制定、投资组合与账本处理、交易执行）施加系统级扰动，在真实美国股票市场数据的闭环历史回测环境中进行公平可重复的比较评估。

Result: 实验表明，单个组件的小幅扰动会通过代理决策循环传播，导致极端集中、失控敞口和大幅投资组合回撤，证明当前自主交易代理在系统层面可被系统性误导。

Conclusion: 当前自主交易代理存在系统性脆弱性，需要更严格的鲁棒性评估和安全保障措施，TradeTrap框架为评估和改进交易代理的可靠性提供了重要工具。

Abstract: LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.

</details>


### [18] [Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence](https://arxiv.org/abs/2512.02280)
*Noorbakhsh Amiri Golilarz,Sindhuja Penchala,Shahram Rahimi*

Main category: cs.AI

TL;DR: 论文分析了当前AI系统的七大核心缺陷，主张向基于认知原理的AI范式转变，以实现真正的自主性和适应性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在感知、语言、推理和多模态领域取得了快速进展，但现代AI系统在自我监控、自我纠正和自主行为调节方面仍然存在根本性限制。这些限制阻碍了AI实现稳健的泛化、终身适应性和现实世界自主性。

Method: 通过识别和分析当代AI模型的七大核心缺陷：缺乏内在自我监控、元认知意识缺失、固定非适应性学习机制、无法重构目标、缺乏表征维护、不足的具身反馈、以及内在能动性缺失。结合人工智能研究、认知科学和神经科学的见解，进行人工系统与生物认知的比较分析。

Result: 论文指出当前架构（包括深度学习和基于Transformer的系统）存在结构性限制，仅靠扩展规模无法解决这些问题。这些限制阻碍了AI实现真正的自主性、适应性和泛化能力。

Conclusion: 主张向基于认知原理的AI范式转变，发展具有认知自主性的系统，能够进行自我导向的适应、动态表征管理和有意图的目标导向行为，同时配备改革性监督机制以确保系统的可解释性、可治理性和与人类价值观的一致性。

Abstract: Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fundamentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self-monitoring, lack of meta-cognitive awareness, fixed and non-adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust generalization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.

</details>


### [19] [DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses](https://arxiv.org/abs/2512.02282)
*Han Luo,Guy Laban*

Main category: cs.AI

TL;DR: DialogGuard是一个多智能体框架，用于评估LLM在心理健康等敏感场景中的心理社会风险，包含五种高风险维度和四种评估流程，比单智能体评估更准确。


<details>
  <summary>Details</summary>
Motivation: 当前LLM已广泛应用于心理健康、危机干预等情感敏感服务，但其在这些场景中的心理社会安全性仍缺乏深入理解和有效评估方法。

Method: 提出DialogGuard多智能体框架，评估隐私侵犯、歧视行为、心理操纵、心理伤害和侮辱行为五个高风险维度；采用四种LLM-as-a-judge流程：单智能体评分、双智能体修正、多智能体辩论和随机多数投票，基于共享的三级评分标准。

Result: 使用PKU-SafeRLHF数据集验证，多智能体机制比非LLM基线和单智能体评估更准确地检测心理社会风险；双智能体修正和多数投票在准确性、与人工评分对齐度和鲁棒性方面达到最佳平衡；辩论机制召回率更高但容易过度标记边界案例。

Conclusion: DialogGuard作为开源软件发布，提供网页界面显示各维度风险分数和可解释的自然语言理由；对12名从业者的形成性研究表明，该框架支持面向脆弱用户的网络应用进行提示设计、审计和监督。

Abstract: Large language models (LLMs) now mediate many web-based mental-health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent framework for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discriminatory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse generative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi-agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog-Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language rationales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.

</details>


### [20] [Model Recovery at the Edge under Resource Constraints for Physical AI](https://arxiv.org/abs/2512.02283)
*Bin Xu,Ayan Banerjee,Sandeep K. S. Gupta*

Main category: cs.AI

TL;DR: MERINDA是一个FPGA加速的模型恢复框架，用于边缘设备上的实时任务关键自主系统，通过并行化神经架构替代迭代求解器，显著降低内存和能耗。


<details>
  <summary>Details</summary>
Motivation: 模型恢复（MR）对于任务关键自主系统的安全可解释决策很重要，但在边缘设备上部署面临挑战，因为神经ODE的迭代特性在FPGA上效率低下，内存和能耗是主要问题。

Method: 提出MERINDA框架，用并行化神经架构替代神经ODE中的迭代求解器，该架构在功能上等同于NODEs，专门针对FPGA加速设计。

Result: 相比移动GPU，MERINDA实现了近11倍的DRAM使用降低和2.2倍的运行速度提升。实验显示在固定精度下内存和能耗存在反比关系。

Conclusion: MERINDA特别适合资源受限的实时任务关键自主系统，通过FPGA加速解决了模型恢复在边缘设备部署的内存和能耗瓶颈。

Abstract: Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.

</details>


### [21] [Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization](https://arxiv.org/abs/2512.02302)
*Varun Kumar Dasoju,Qingsu Cheng,Zeyun Yu*

Main category: cs.AI

TL;DR: 使用量子启发的边缘增强和稳定多组件损失函数，仅需599张训练图像就在乳腺细胞分割中达到95.5% Dice分数，显著减少医学图像标注工作量。


<details>
  <summary>Details</summary>
Motivation: 医学图像标注需要大量时间和专家知识，特别是乳腺上皮细胞分割中数据稀缺且类别极度不平衡（乳腺组织仅占图像的0.1%-20%），这成为临床感知AI发展的主要瓶颈。

Method: 1) 使用多尺度Gabor滤波器进行量子启发式边缘增强，创建第四输入通道改善边界检测；2) 提出稳定多组件损失函数，整合自适应Dice损失、边界感知项和自动正样本加权；3) 引入基于复杂度的加权采样策略，优先处理挑战性区域；4) 采用EfficientNet-B7/UNet++架构，通过4到3通道投影利用预训练权重；5) 通过指数移动平均和统计异常值检测进行鲁棒验证。

Result: 在仅599张训练图像上达到95.5% ± 0.3% Dice分数和91.2% ± 0.4% IoU。量子增强使边界准确率提升2.1%，加权采样使小病灶检测提升3.8%。在仅有129张图像的验证集上获得可靠性能评估。

Conclusion: 该框架通过创新的量子启发边缘增强、稳定损失函数和智能采样策略，在有限标注数据下实现了突破性性能，显著减少了医学专家创建数据集所需时间，解决了临床感知AI发展的根本瓶颈。

Abstract: Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.

</details>


### [22] [OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning](https://arxiv.org/abs/2512.02306)
*Boyu Zhu,Xiaofei Wen,Wenjie Jacky Mo,Tinghui Zhu,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: OmniGuard是首个全模态安全护栏系统，通过精心策划的大型数据集和专家模型蒸馏，为处理文本、图像、视频和音频的全模态大语言模型提供统一的安全保障框架。


<details>
  <summary>Details</summary>
Motivation: 全模态大语言模型处理多种模态数据时，现有安全护栏研究主要针对单模态场景，采用二元分类方法，缺乏跨模态的鲁棒性和适应性，需要新的安全保障方案。

Method: 提出OmniGuard框架，构建包含21万+多样本的全模态安全数据集，涵盖所有模态的单模态和跨模态样本，通过专家模型蒸馏生成结构化安全标签和安全评估。

Result: 在15个基准测试中，OmniGuard在广泛的多模态安全场景中表现出强大的有效性和泛化能力，能够统一执行策略并降低全模态风险。

Conclusion: OmniGuard为构建更鲁棒和强大的全模态安全保障系统提供了统一框架，解决了全模态大语言模型的安全挑战。

Abstract: Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.

</details>


### [23] [Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective](https://arxiv.org/abs/2512.02340)
*Qiyao Xue,Weichen Liu,Shiqi Wang,Haoming Wang,Yuyang Wu,Wei Gao*

Main category: cs.AI

TL;DR: 该论文提出了ReMindView-Bench基准测试，用于评估视觉语言模型在多视角空间推理中的表现，发现现有模型在跨视角对齐和视角转换方面存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多视角设置中进行空间推理时，难以保持几何一致性和跨视角一致性。缺乏能够将多视角推理与单视角感知和时间因素分离的细粒度基准测试。

Method: 提出了ReMindView-Bench基准测试，系统性地变化视角空间模式和查询类型来探测空间认知的关键因素。使用显性分阶段分析（LLM作为评判和自一致性提示）和隐性分析（线性探测和熵动态）来诊断推理过程。

Result: 评估了15个当前视觉语言模型，发现它们在跨视角对齐和视角转换方面存在一致性失败。模型在帧内感知表现良好，但在跨视角信息整合时性能急剧下降。隐性分析显示任务相关信息逐渐丢失，正确与错误轨迹之间的不确定性分离。

Conclusion: 该研究提供了基于认知科学的视觉语言模型空间推理诊断，揭示了多视角空间心理模型在推理过程中如何形成、退化和失稳。ReMindView-Bench基准测试可用于深入分析多视角空间推理能力。

Abstract: Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.

</details>


### [24] [Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games](https://arxiv.org/abs/2512.02358)
*Ran Zhang,Kun Ouyang,Tiancheng Ma,Yida Yang,Dong Fang*

Main category: cs.AI

TL;DR: 该论文提出了一种基于LLM的生成式智能体MMO模拟系统，用于优化游戏数值系统和机制设计，通过SFT和RL训练LLM模拟真实玩家行为，结合数据驱动的环境模型，提供可靠、可解释且成本效益高的优化框架。


<details>
  <summary>Details</summary>
Motivation: 传统MMO游戏优化方法依赖大规模在线实验或基于预定义统计模型的参数调优，成本高、耗时长且可能干扰玩家体验。现有离线模拟系统保真度有限，无法准确模拟真实玩家的推理和干预反应。

Method: 1. 基于LLM的生成式智能体模拟系统；2. 在大规模真实玩家行为数据上应用监督微调(SFT)和强化学习(RL)，将LLM从通用先验适应到游戏特定领域；3. 基于真实游戏日志训练数据驱动的环境模型，重建动态游戏系统。

Result: 实验表明系统与真实世界玩家行为具有强一致性，在干预下能产生合理的因果响应，为数据驱动的数值设计优化提供了可靠、可解释且成本效益高的框架。

Conclusion: 提出的基于LLM的生成式智能体MMO模拟系统解决了传统优化方法的局限性，通过高保真模拟真实玩家行为，为游戏数值系统和机制设计提供了高效、可靠的优化工具。

Abstract: Optimizing numerical systems and mechanism design is crucial for enhancing player experience in Massively Multiplayer Online (MMO) games. Traditional optimization approaches rely on large-scale online experiments or parameter tuning over predefined statistical models, which are costly, time-consuming, and may disrupt player experience. Although simplified offline simulation systems are often adopted as alternatives, their limited fidelity prevents agents from accurately mimicking real player reasoning and reactions to interventions. To address these limitations, we propose a generative agent-based MMO simulation system empowered by Large Language Models (LLMs). By applying Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on large-scale real player behavioral data, we adapt LLMs from general priors to game-specific domains, enabling realistic and interpretable player decision-making. In parallel, a data-driven environment model trained on real gameplay logs reconstructs dynamic in-game systems. Experiments demonstrate strong consistency with real-world player behaviors and plausible causal responses under interventions, providing a reliable, interpretable, and cost-efficient framework for data-driven numerical design optimization.

</details>


### [25] [Synthetic Error Injection Fails to Elicit Self-Correction In Language Models](https://arxiv.org/abs/2512.02389)
*David X. Wu,Shreyas Kapur,Anant Sahai,Stuart Russell*

Main category: cs.AI

TL;DR: 监督学习结合人工错误注入无法有效提升语言模型的自我纠错能力，即使模型能发现错误也常重复原错误，分布偏移是主要原因


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能激发大语言模型的推理和自我纠错能力，但计算成本高昂，需要探索替代方法。受自动驾驶和机器人技术启发，研究监督学习结合人工错误注入是否能诱导语言模型的自我纠错能力。

Method: 在推理链中插入人工错误，掩盖这些错误，然后监督模型识别和纠正这些错误。通过合成错误注入的监督学习方法，测试其在多个模型上的效果。

Result: 该方法即使在简单的合成任务上也无法显著提升性能。即使模型能发现自己的错误，也常常重复原来的错误。合成错误与在线策略错误之间的分布偏移显著降低了微调模型的纠错能力，即使合成错误能很好地覆盖在线策略错误。

Conclusion: 监督学习结合人工错误注入无法有效替代强化学习来激发自我纠错能力。分布偏移问题解释了为什么在线策略强化学习方法在激发自我纠错方面具有独特效果。

Abstract: Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.

</details>


### [26] [Semantic Trading: Agentic AI for Clustering and Relationship Discovery in Prediction Markets](https://arxiv.org/abs/2512.02436)
*Agostino Capponi,Alfio Gliozzo,Brian Zhu*

Main category: cs.AI

TL;DR: 本文提出一个AI代理管道，自动聚类预测市场并识别市场间的依赖关系，通过交易策略验证发现的关系能带来约20%的周收益。


<details>
  <summary>Details</summary>
Motivation: 预测市场存在碎片化问题，包括重叠问题、隐含等价关系和隐藏矛盾，这阻碍了市场效率。需要一种方法来自动发现市场间的语义关系和依赖结构。

Method: 开发了一个AI代理管道：1) 使用自然语言理解对市场合同文本和元数据进行聚类，形成连贯的主题组；2) 识别组内市场对之间的强依赖关系，包括相同结果（正相关）和不同结果（负相关）的关系。

Result: 在Polymarket历史数据集上的评估显示：AI识别的关系准确率达到约60-70%；基于这些关系构建的简单交易策略在周时间范围内获得约20%的平均收益。

Conclusion: AI代理和大语言模型能够有效发现预测市场中潜在的语义结构，识别的关系具有实际交易价值，为市场分析和交易策略提供了新工具。

Abstract: Prediction markets allow users to trade on outcomes of real-world events, but are prone to fragmentation through overlapping questions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters markets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster market pairs whose resolved outcomes exhibit strong dependence, including same-outcome (correlated) and different-outcome (anti-correlated) relationships. Using a historical dataset of resolved markets on Polymarket, we evaluate the accuracy of the agent's relational predictions. We then translate discovered relationships into a simple trading strategy to quantify how these relationships map to actionable signals. Results show that agent-identified relationships achieve roughly 60-70% accuracy, and their induced trading strategies earn about 20% average returns over week-long horizons, highlighting the ability of agentic AI and large language models to uncover latent semantic structure in prediction markets.

</details>


### [27] [Guided Self-Evolving LLMs with Minimal Human Supervision](https://arxiv.org/abs/2512.02472)
*Wenhao Yu,Zhenwen Liang,Chengsong Huang,Kishan Panaganti,Tianqing Fang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: R-Few是一个引导式自我进化框架，通过轻量级人类监督（上下文grounding和混合训练）实现稳定可控的AI自我进化，在数学和通用推理任务上取得持续迭代改进。


<details>
  <summary>Details</summary>
Motivation: AI自我进化被认为是通向超智能的路径，但实践中无引导的自我进化系统往往快速平台化甚至退化，存在概念漂移、多样性崩溃和错误进化等问题。需要实现稳定可控的自我进化，同时最小化对人类监督的依赖。

Method: 提出R-Few框架：引导式自我对弈挑战者-求解器框架。挑战者采样少量人类标注示例指导合成问题生成，求解器在在线难度课程下联合训练人类和合成示例。包含上下文grounding和混合训练。

Result: 在数学和通用推理基准测试中，R-Few实现一致且迭代的改进。例如，Qwen3-8B-Base在数学任务上比R-Zero提升3.0分，性能与使用20倍人类数据训练的General-Reasoner相当。消融研究确认了grounded挑战者训练和课程求解器训练的互补贡献。

Conclusion: R-Few通过轻量级人类监督实现了稳定可控的自我进化，缓解了漂移问题，产生更稳定可控的协同进化动态，为AI自我进化提供了可行的解决方案。

Abstract: AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.

</details>


### [28] [COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes](https://arxiv.org/abs/2512.02499)
*Yongkai Liu,Helena Feng,Bin Jiang,Yixin Wang,Max Wintermark,David S. Liebeskind,Michael Moseley,Maarten Lansberg,Gregory Albers,Jeremy Heit,Greg Zaharchuk*

Main category: cs.AI

TL;DR: COPE是一个基于链式思维推理的LLM框架，用于从非结构化临床笔记预测急性缺血性卒中90天功能结局，性能与GPT-4.1相当，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富的上下文信息，但其非结构化特性限制了在传统预测模型中的应用。需要开发能够利用这些信息进行准确预后预测的方法。

Method: COPE采用两步链式思维框架：第一步LLaMA-3-8B生成临床推理，第二步输出改良Rankin量表预测。与GPT-4.1、ClinicalBERT、结构化机器学习模型和单步LLM进行比较。

Result: COPE的MAE为1.01，±1准确率74.4%，精确准确率32.8%，性能与GPT-4.1相当，优于其他方法。在不同亚组中表现一致，但在老年患者、接受血栓切除术患者和较长摘要患者中误差略高。

Conclusion: COPE作为一个轻量级、可解释且保护隐私的开源框架，为从非结构化临床文本进行结局预测提供了准确实用的解决方案。

Abstract: Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.

</details>


### [29] [Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration](https://arxiv.org/abs/2512.02530)
*Yuxiang He,Jian Zhao,Yuchen Yuan,Tianle Zhang,Wei Cai,Haojie Cheng,Ziyan Shi,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Aetheria是一个基于多智能体辩论与协作的多模态可解释内容安全框架，通过五个核心智能体的协作架构，结合RAG知识检索，实现深度分析和裁决，显著提升内容安全准确性，特别是在隐式风险识别方面。


<details>
  <summary>Details</summary>
Motivation: 数字内容的指数增长给内容安全带来重大挑战。现有的基于单一模型或固定流水线的审核系统在识别隐式风险和提供可解释的判断过程方面存在局限性。

Method: 提出Aetheria框架，采用五个核心智能体的协作架构，通过动态的相互说服辩论机制对多模态内容进行深度分析和裁决，基于RAG的知识检索提供支持。

Result: 在提出的基准测试AIR-Bench上的综合实验验证，Aetheria不仅能生成详细且可追溯的审核报告，而且在整体内容安全准确性上显著优于基线方法，特别是在隐式风险识别方面。

Conclusion: 该框架建立了一个透明且可解释的范式，显著推进了可信AI内容审核领域的发展。

Abstract: The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.

</details>


### [30] [Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance](https://arxiv.org/abs/2512.02558)
*Yufei Xiao,Shangfei Wang*

Main category: cs.AI

TL;DR: 提出一种融合视频、音频和文本的多模态共情预测方法，利用监督文档作为特权信息增强训练效果


<details>
  <summary>Details</summary>
Motivation: 现有共情预测方法主要关注单一模态（通常是文本），忽略了多模态处理能力，也没有充分利用特权信息（如额外的共情内容）

Method: 1. 多模态共情预测：使用预训练网络提取视频、音频和文本特征，进行跨模态融合得到多模态特征表示；2. 监督文档辅助训练：在训练阶段引入监督文档作为特权信息，使用LDA模型识别潜在主题分布来约束文本特征

Result: 在多模态和对话共情数据集上的实验结果表明，该方法优于现有方法

Conclusion: 提出的多模态共情预测方法有效整合了多种模态信息，并通过监督文档辅助训练提升了性能，为共情预测提供了更全面的解决方案

Abstract: Prevalent empathy prediction techniques primarily concentrate on a singular modality, typically textual, thus neglecting multi-modal processing capabilities. They also overlook the utilization of certain privileged information, which may encompass additional empathetic content. In response, we introduce an advanced multi-modal empathy prediction method integrating video, audio, and text information. The method comprises the Multi-Modal Empathy Prediction and Supervisory Documentation Assisted Training. We use pre-trained networks in the empathy prediction network to extract features from various modalities, followed by a cross-modal fusion. This process yields a multi-modal feature representation, which is employed to predict empathy labels. To enhance the extraction of text features, we incorporate supervisory documents as privileged information during the assisted training phase. Specifically, we apply the Latent Dirichlet Allocation model to identify potential topic distributions to constrain text features. These supervisory documents, created by supervisors, focus on the counseling topics and the counselor's display of empathy. Notably, this privileged information is only available during training and is not accessible during the prediction phase. Experimental results on the multi-modal and dialogue empathy datasets demonstrate that our approach is superior to the existing methods.

</details>


### [31] [PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing](https://arxiv.org/abs/2512.02589)
*Junyi Hou,Andre Lin Huikai,Nuo Chen,Yiwei Gong,Bingsheng He*

Main category: cs.AI

TL;DR: PaperDebugger：一个基于多代理的LaTeX编辑器插件，将LLM驱动的学术写作助手直接集成到Overleaf等编辑环境中，支持上下文感知的文档操作和版本控制。


<details>
  <summary>Details</summary>
Motivation: 现有AI写作助手与编辑器分离，无法深度交互文档状态、结构和修订历史，限制了在LaTeX编辑器中进行上下文感知的代理操作。

Method: 通过Chrome扩展、Kubernetes原生编排层和模型上下文协议工具链，实现可靠的双向同步、细粒度版本控制、安全状态管理、多代理调度和外部工具集成。

Result: 开发了完全集成的工作流演示，包括本地化编辑、结构化评审、并行代理执行和基于差异的更新，早期聚合分析显示积极的用户参与度。

Conclusion: PaperDebugger验证了编辑器原生、代理式写作助手的实用性，为学术写作提供了深度集成的AI辅助解决方案。

Abstract: Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at https://github.com/PaperDebugger/PaperDebugger.

</details>


### [32] [IACT: A Self-Organizing Recursive Model for General AI Agents: A Technical White Paper on the Architecture Behind kragent.ai](https://arxiv.org/abs/2512.02605)
*Pengju Lu*

Main category: cs.AI

TL;DR: IACT是一个通过用户对话驱动的通用自主系统，能够动态生成递归代理拓扑结构，替代传统的预定义工作流，实现运行时错误纠正和模糊性解决。


<details>
  <summary>Details</summary>
Motivation: 解决静态硬编码代理工作流的局限性，传统系统需要预定义图或专门编程，无法灵活适应开放任务。

Method: 基于用户对话驱动，自主构建动态递归代理拓扑结构，采用双向有状态对话替代单向函数调用，实现交互冗余和运行时错误纠正。

Result: 在kragent.ai系统中成功部署，通过实际工作流展示其能力，而非依赖基准测试结果。

Conclusion: IACT模型能够根据问题结构动态扩展组织复杂性，有效缓解错误传播，为开放任务提供灵活的自主系统解决方案。

Abstract: This technical white paper introduces the Interactive Agents Call Tree (IACT), a computational model designed to address the limitations of static, hard-coded agent workflows. Unlike traditional systems that require pre-defined graphs or specialized programming, IACT operates as a general-purpose autonomous system driven purely by user dialogue. Given a high-level objective, the system autonomously grows a dynamic, recursive agent topology incrementally tailored to the problem's structure. This allows it to scale its organizational complexity to match open-ended tasks. To mitigate the error propagation inherent in unidirectional function calls, IACT introduces interactional redundancy by replacing rigid invocations with bidirectional, stateful dialogues. This mechanism enables runtime error correction and ambiguity resolution. We describe the architecture, design principles, and practical lessons behind the production deployment of this model in the kragent.ai system, presenting qualitative evidence from real-world workflows rather than exhaustive benchmark results.

</details>


### [33] [Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction](https://arxiv.org/abs/2512.02610)
*Yubo Hou,Mohamed Ragab,Min Wu,Chee-Keong Kwoh,Xiaoli Li,Zhenghua Chen*

Main category: cs.AI

TL;DR: 提出TACDA方法用于跨域剩余使用寿命预测，通过目标域重构策略保留目标特定信息，并采用聚类配对策略实现退化阶段一致性对齐，显著提升跨域预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的RUL预测方法假设训练和测试数据来自相同分布，但实际工业环境中存在域差异问题。先前对抗域适应方法仅关注域不变特征，忽略了目标特定信息和退化阶段的一致性特征，导致性能不佳。

Method: 提出TACDA方法：1）在对抗适应过程中引入目标域重构策略，在学习域不变特征的同时保留目标特定信息；2）开发聚类配对策略，在相似退化阶段之间进行一致性对齐。

Result: 通过大量实验验证，TACDA方法在两种不同评估指标上均显著优于现有最先进方法，展现出卓越的跨域RUL预测性能。

Conclusion: TACDA方法通过目标域重构和退化阶段一致性对齐策略，有效解决了跨域RUL预测中的域差异问题，为实际工业应用提供了更可靠的解决方案。

Abstract: Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at https://github.com/keyplay/TACDA.

</details>


### [34] [Zero-Shot Instruction Following in RL via Structured LTL Representations](https://arxiv.org/abs/2512.02633)
*Mattia Giuri,Mathias Jackermeier,Alessandro Abate*

Main category: cs.AI

TL;DR: 提出一种基于图神经网络编码布尔公式序列的新方法，用于学习遵循任意LTL指令的多任务策略，解决了现有方法在多个高层事件同时发生且复杂交互环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有将LTL指令解释为有限自动机的方法在多个原子命题同时为真且可能复杂交互的环境中表现不佳，需要改进多任务策略学习。

Method: 提出基于简单布尔公式序列的策略条件化方法，这些公式直接对应自动机中的转移，并通过图神经网络编码以产生结构化任务表示。

Result: 在复杂的基于象棋的环境中进行的实验证明了该方法的优势。

Conclusion: 该方法能够有效处理多个高层事件同时发生且复杂交互的环境，为遵循任意LTL指令的多任务策略学习提供了更好的解决方案。

Abstract: Linear temporal logic (LTL) is a compelling framework for specifying complex, structured tasks for reinforcement learning (RL) agents. Recent work has shown that interpreting LTL instructions as finite automata, which can be seen as high-level programs monitoring task progress, enables learning a single generalist policy capable of executing arbitrary instructions at test time. However, existing approaches fall short in environments where multiple high-level events (i.e., atomic propositions) can be true at the same time and potentially interact in complicated ways. In this work, we propose a novel approach to learning a multi-task policy for following arbitrary LTL instructions that addresses this shortcoming. Our method conditions the policy on sequences of simple Boolean formulae, which directly align with transitions in the automaton, and are encoded via a graph neural network (GNN) to yield structured task representations. Experiments in a complex chess-based environment demonstrate the advantages of our approach.

</details>


### [35] [Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks](https://arxiv.org/abs/2512.02677)
*Zhiyuan He*

Main category: cs.AI

TL;DR: 该论文发现标准Transformer模型在处理深度递归推理问题时存在局限性，即使它们能处理更长的序列。作者提出了一种循环定位替换管道方法来解决深度泛化问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在许多任务上表现出色，但在处理递归推理问题（需要解决嵌套层次结构的问题）时面临挑战。先前研究主要关注长度泛化，而本文研究一个未被充分探索的限制：深度泛化，即模型处理比训练时更深嵌套层次的能力。

Method: 提出了一种新颖的循环定位替换管道方法，将递归问题分解为可管理的子组件。该方法使用两个专门模型：定位器识别可解的子表达式，替换器评估这些组件同时保持整体结构。

Result: 在布尔代数、递归算术和命题逻辑三个精心设计的领域进行评估，每个领域都有可控的递归深度。结果表明，该方法在测试超出分布范围的递归深度时，有效缓解了性能衰减问题。

Conclusion: 标准Transformer架构在处理比训练时更深的递归问题时存在困难，这源于它们无法维持类似栈的行为。提出的循环定位替换管道方法为解决深度泛化问题提供了有效解决方案。

Abstract: Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.

</details>


### [36] [Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding](https://arxiv.org/abs/2512.02699)
*Hyeongseop Rha,Jeong Hun Yeo,Junil Won,Se Jin Park,Yong Man Ro*

Main category: cs.AI

TL;DR: MIGR框架通过模态重要性引导推理，改善多模态大语言模型的情感理解可靠性，减少推理漂移问题


<details>
  <summary>Details</summary>
Motivation: 现有方法存在推理漂移问题：模型逐渐依赖自身生成的文本而非多模态证据，且解释过度受视觉主导推理路径影响，导致情感理解不可靠

Method: 引入模态重要性机制识别情感主导模态，据此重组推理序列，使解释从最关键模态开始；采用两阶段框架：模态对齐监督微调和模态感知奖励优化

Result: 在DFEW基准测试中，MIGR显著提升推理可靠性，将正确预测但情感不一致解释的比例从18.10%降至7.37%

Conclusion: 从情感主导模态开始推理能有效改善多模态情感理解的可靠性，模态重要性引导的推理框架具有实际应用价值

Abstract: In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.

</details>


### [37] [Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs](https://arxiv.org/abs/2512.02713)
*Theodoros Aivalis,Iraklis A. Klampanos,Antonis Troumpoukis,Joemon M. Jose*

Main category: cs.AI

TL;DR: 提出一个通过构建本体对齐知识图谱来解释生成模型输出的框架，用于追踪训练数据对生成内容的影响


<details>
  <summary>Details</summary>
Motivation: 随着生成模型能力增强，透明度、问责制和版权侵权问题日益突出，需要理解训练数据如何影响模型输出

Method: 利用多模态大语言模型从图像中提取结构化三元组，构建与领域本体对齐的知识图谱，通过比较生成图像和训练图像的KG来追踪潜在影响

Result: 通过本地模型去学习和风格特定实验验证了方法的有效性，支持版权分析、数据集透明度和可解释AI

Conclusion: 该框架有助于开发促进人类协作、创造力和激发好奇心的AI系统

Abstract: As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.

</details>


### [38] [Menta: A Small Language Model for On-Device Mental Health Prediction](https://arxiv.org/abs/2512.02716)
*Tianyi Zhang,Xiangyuan Xue,Lingyan Ruan,Shiya Fu,Feng Xia,Simon D'Alfonso,Vassilis Kostakos,Hong Jia*

Main category: cs.AI

TL;DR: Menta是首个针对社交媒体心理健康预测优化的轻量级小语言模型，在多项任务上超越现有SLM和部分LLM，并能在移动设备实时部署。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题影响全球数亿人，但早期检测仍然有限。虽然大语言模型在心理健康应用中有潜力，但其规模和计算需求阻碍了实际部署。小语言模型提供了轻量级替代方案，但在基于社交媒体的心理健康预测方面尚未充分探索。

Method: 开发Menta模型，采用LoRA微调框架、跨数据集策略和平衡准确率导向的损失函数，在六个分类任务上进行联合训练，专门用于社交媒体数据的心理健康预测。

Result: Menta在抑郁、压力和自杀倾向等任务上比最佳非微调SLM平均提升15.2%，在抑郁和压力分类任务上准确率超过130亿参数LLM，模型大小约为其1/3.25。能在iPhone 15 Pro Max上实时部署，仅需约3GB内存。

Conclusion: Menta展示了轻量级模型在可扩展、隐私保护的心理健康监测方面的潜力，为实际部署提供了可行的技术方案。

Abstract: Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: https://xxue752-nz.github.io/menta-project/

</details>


### [39] [StockMem: An Event-Reflection Memory Framework for Stock Forecasting](https://arxiv.org/abs/2512.02720)
*He Wang,Wenyilin Xiao,Songqiao Han,Hailiang Huang*

Main category: cs.AI

TL;DR: StockMem：基于事件-反思双层记忆框架的股票价格预测模型，通过结构化新闻事件和追踪事件演化来提取市场预期差异信息，实现可解释的金融预测。


<details>
  <summary>Details</summary>
Motivation: 股票价格预测面临市场波动性和实时事件敏感性的挑战。虽然大语言模型为基于文本的预测提供了新途径，但在金融领域的应用受到噪声新闻数据和文本中缺乏明确答案的限制。通用记忆架构难以识别价格变动的关键驱动因素。

Method: 提出StockMem事件-反思双层记忆框架：1）将新闻结构化处理为事件；2）横向整合每日事件；3）纵向追踪事件演化以提取反映市场预期差异的增量信息，构建时序事件知识库；4）通过分析事件-价格动态形成因果经验的反思知识库；5）预测时检索类似历史场景，结合当前事件、增量数据和过往经验进行推理。

Result: 实验表明StockMem优于现有记忆架构，通过追踪影响价格的信息链提供更优且可解释的推理，增强了金融预测的决策透明度。

Conclusion: StockMem框架通过事件结构化和演化追踪有效解决了金融新闻数据噪声问题，构建的双层记忆系统能够识别价格变动的关键驱动因素，为股票预测提供了可解释且透明的解决方案。

Abstract: Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.

</details>


### [40] [AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping](https://arxiv.org/abs/2512.02726)
*Md Abdul Kadir,Sai Suresh Macharla Vasu,Sidharth S. Nair,Daniel Sonntag*

Main category: cs.AI

TL;DR: LLMs在复式记账异常检测中超越传统规则方法和机器学习基线，提供自然语言解释，支持AI增强审计


<details>
  <summary>Details</summary>
Motivation: 传统日记账测试（JETs）产生大量误报且难以检测细微异常，需要更有效的审计方法

Method: 在合成和真实匿名账本上对LLaMA、Gemma等最先进LLMs进行基准测试，与传统JETs和机器学习基线比较

Result: LLMs在异常检测中持续优于传统规则方法和经典机器学习基线，同时提供增强可解释性的自然语言解释

Conclusion: LLMs展示了AI增强审计的潜力，人类审计师与基础模型协作可加强财务完整性

Abstract: Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.

</details>


### [41] [Self-Improving AI Agents through Self-Play](https://arxiv.org/abs/2512.02731)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 将心理测量电池的模数理论框架扩展到动力系统领域，将智能体形式化为由计算资源参数化的流，推导出保证自我改进稳定性的方差不等式条件，并统一了近期语言自我博弈、自我纠正和合成数据引导等研究。


<details>
  <summary>Details</summary>
Motivation: 现有AAI能力评分是智能体表示空间上的静态泛函，需要将其扩展到动力系统领域，以形式化智能体随计算资源演化的自我改进过程。

Method: 将智能体形式化为参数化流ν_r，由递归的生成器-验证器-更新器(GVU)算子控制，证明该算子在参数流形Θ上生成向量场，将自我改进系数κ定义为能力泛函沿该流的李导数。

Result: 推导出方差不等式这一谱条件，证明在温和正则性条件下，该条件足以保证自我改进的稳定性。κ>0的充分条件是生成和验证的组合噪声足够小（考虑曲率和步长效应）。

Conclusion: 该形式化框架统一了语言自我博弈、自我纠正和合成数据引导等近期研究，表明STaR、SPIN、Reflexion、GANs和AlphaZero等架构都是满足方差不等式的GVU算子的具体拓扑实现。

Abstract: We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $ν_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $Θ$, and we identify the coefficient of self-improvement $κ$ as the Lie derivative of the capability functional along this flow.
  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $κ> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.
  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.

</details>


### [42] [A Framework for Causal Concept-based Model Explanations](https://arxiv.org/abs/2512.02735)
*Anna Rodum Bjøru,Jacob Lysnæs-Larsen,Oskar Jørgensen,Inga Strümke,Helge Langseth*

Main category: cs.AI

TL;DR: 提出基于因果概念的后可解释AI框架，通过概念干预的充分概率生成局部和全局解释，在CelebA数据集上验证，强调解释的可理解性和对模型的忠实性


<details>
  <summary>Details</summary>
Motivation: 针对非可解释模型需要既易于理解又忠实于原模型的解释，现有方法在这两方面存在不足，需要建立概念化、因果化的解释框架

Method: 基于因果概念的后可解释AI框架，通过计算概念干预的充分概率生成局部和全局解释，使用概念化词汇表，在CelebA数据集上构建概念验证模型

Result: 在CelebA数据集上展示了示例解释，证明了框架的可理解性（通过清晰的概念词汇）和忠实性（通过强调框架假设和解释上下文对齐）

Conclusion: 提出的因果概念后解释框架能够为不可解释模型提供既易于理解又忠实于模型的解释，关键在于解释生成和解释解释的上下文必须保持一致

Abstract: This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.

</details>


### [43] [Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents](https://arxiv.org/abs/2512.02812)
*Zijie Lin,Qilin Cai,Liang Shen,Mingjun Xiao*

Main category: cs.AI

TL;DR: 提出无提示协作代理框架，通过验证和精炼代理自动提升论文到代码生成质量，相比基线提升约15%准确率和13%完整性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化论文复现框架缺乏对生成过程各步骤输出的验证和精炼机制，或过度依赖人工设计的提示进行自我精炼，限制了适应性和可扩展性。

Method: 提出无提示协作代理框架，包含验证代理（检查各步骤输出是否满足系统提示要求）和精炼代理（基于识别问题修订输出），仅利用原始系统提示实现自动验证和改进。

Result: 在PaperBench Code-Dev和Paper2CodeBench数据集上，相比无代理基线，准确率提升约15%，完整性提升约13%。与Self-Refine对比验证了方法的鲁棒性和一致性。

Conclusion: 提出的无提示协作代理框架能有效提升论文到代码生成的准确性和完整性，无需人工设计精炼提示，具有更好的适应性和可扩展性。

Abstract: Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\% and 13\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.

</details>


### [44] [Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control](https://arxiv.org/abs/2512.02814)
*Yongrui Yu,Zhongzhen Huang,Linjie Mu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: Radiologist Copilot是一个基于大语言模型的智能体系统，通过编排多种工具实现自动化放射学报告生成与质量控制，模拟放射科医生完整工作流程，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 放射学报告撰写耗时且易出错，现有自动化方法主要关注报告生成阶段，忽视了关键的质量控制环节，无法为放射科医生提供全面支持。

Method: 利用大语言模型作为推理核心，构建智能体系统自主选择工具、规划和执行动作。编排的工具包括：区域定位、基于"图像思维范式"的区域分析规划、战略模板选择报告生成、质量评估和反馈驱动的自适应精炼质量控制。

Result: 实验结果表明，Radiologist Copilot在放射学报告生成方面显著超越了其他最先进的方法。

Conclusion: Radiologist Copilot能够促进准确、完整、高效的放射学报告撰写，协助放射科医生并提高临床效率。源代码将在接受后发布。

Abstract: Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.

</details>


### [45] [The future of AI in critical mineral exploration](https://arxiv.org/abs/2512.02879)
*Jef Caers*

Main category: cs.AI

TL;DR: 提出基于贝叶斯主义和证伪原则的AI驱动科学方法，用于减少认知偏差、降低勘探成本，通过无监督学习和人在环AI优化数据采集决策


<details>
  <summary>Details</summary>
Motivation: 尽管投资增加，但过去20年新矿产发现减少，需要解决认知偏差和假阳性问题，降低勘探成本

Method: 基于贝叶斯主义和证伪原则的哲学方法，将数据采集视为证伪人类假设的手段，使用可验证指标量化数据采集决策，提出包含无监督学习（生成竞争地质假设）和人在环AI（优化地质、地球物理、地球化学和钻探数据采集）的实用协议

Result: 提出一个可在任何勘探活动中使用的模板协议，通过AI减少认知偏差和假阳性，降低勘探成本

Conclusion: AI能够实现严格的科学方法，通过贝叶斯主义和证伪原则优化矿产勘探，地质假设的不确定性降低优先于品位和储量不确定性降低

Abstract: The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage

</details>


### [46] [Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning](https://arxiv.org/abs/2512.02914)
*Zhonghao He,Tianyi Qiu,Hirokazu Shirado,Maarten Sap*

Main category: cs.AI

TL;DR: 该研究提出了一种基于鞅性质的无监督评估框架，用于检测大语言模型在推理过程中的信念固化现象，发现迭代推理可能导致确认偏误而非真相寻求行为。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型的推理能力有所提升，但迭代推理可能强化信念固化和确认偏误，而非增强真相寻求行为。需要系统评估LLM推理中的信念固化问题。

Method: 提出基于贝叶斯统计中鞅性质的无监督评估框架，利用回归方法计算鞅分数来衡量信念更新是否违反理性更新原则，从而检测信念固化现象。

Result: 在事件预测、价值负载问题和学术论文评审等多个开放领域，发现信念固化现象普遍存在，当前信念正向预测未来信念更新。鞅分数能预测有标签领域的真实准确性。

Conclusion: 信念固化在LLM推理中普遍存在，鞅分数作为无监督指标能有效评估推理过程的真相寻求能力，为理解和改进LLM推理提供了重要工具。

Abstract: Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics. This property implies that, under rational belief updating, the expected value of future beliefs should remain equal to the current belief, i.e., belief updates are unpredictable from the current belief. We propose the unsupervised, regression-based Martingale Score to measure violations of this property, which signal deviation from the Bayesian ability of updating on new evidence. In open-ended problem domains including event forecasting, value-laden questions, and academic paper review, we find such violations to be widespread across models and setups, where the current belief positively predicts future belief updates, a phenomenon which we term belief entrenchment. We identify the models, reasoning techniques, and domains more prone to belief entrenchment. Finally, we validate the Martingale Score by showing that it predicts ground-truth accuracy on problem domains where ground truth labels are available. This indicates that, while designed as an unsupervised metric that operates even in domains without access to ground truth, the Martingale Score is a useful proxy of the truth-seeking ability of a reasoning process.

</details>


### [47] [Invasive Context Engineering to Control Large Language Models](https://arxiv.org/abs/2512.03001)
*Thomas Rivasseau*

Main category: cs.AI

TL;DR: 提出侵入式上下文工程，通过插入控制语句来增强LLM在长上下文场景下的安全性，防止越狱和恶意行为


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全研究虽然通过偏好训练、提示工程和输入输出过滤提高了模型鲁棒性，但LLM仍然容易受到攻击，且越狱概率随上下文长度增加而增加，需要为长上下文场景提供更强的安全保证

Method: 提出侵入式上下文工程技术，在LLM上下文中插入控制语句，这种方法不依赖LLM训练，避免了长上下文场景下训练数据不足的问题，并可推广到思维链过程中防止策略性欺骗

Result: 该方法理论上能够部分解决长上下文LLM的安全问题，提供比现有方法更强的安全保证

Conclusion: 侵入式上下文工程是一种有前景的LLM安全增强方法，特别适用于长上下文场景，通过上下文控制而非模型训练来提高安全性

Abstract: Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.

</details>


### [48] [From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?](https://arxiv.org/abs/2512.03005)
*Dawei Li,Abdullah Alnaibari,Arslan Bisharat,Manny Sandoval,Deborah Hall,Yasin Silva,Huan Liu*

Main category: cs.AI

TL;DR: LLMs可作为在线冲突调解员，通过判断对话公平性和情感动态，并生成共情信息引导解决冲突，API模型表现优于开源模型。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地介入在线沟通，研究它们能否促进共情和建设性对话，而不仅仅是检测有害内容，成为负责任AI研究的重要前沿。

Method: 将调解分解为两个子任务：判断（评估对话公平性和情感动态）和引导（生成共情、缓和的信息）。构建大型Reddit数据集，提出多阶段评估流程，结合原则评分、用户模拟和人工比较。

Result: 实验表明，API模型在推理和干预对齐方面优于开源模型。LLMs在在线社交调解方面展现出潜力，但也存在局限性。

Conclusion: 当前LLMs作为在线社交调解新兴代理既有前景也有局限，需要进一步研究提升其调解能力。

Abstract: The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [49] [Weight distributions of simplex codes over finite chain rings and their Gray map images](https://arxiv.org/abs/2512.02149)
*Cristina Fernández-Córdoba,Sergi Sánchez-Aragón,Mercè Villanueva*

Main category: cs.IT

TL;DR: 本文研究有限链环上线性单纯形码及其对应R-线性单纯形码的构造与性质分析


<details>
  <summary>Details</summary>
Motivation: 将Z_{p^s}上的线性码推广到更一般的有限链环R上，研究R-线性码作为广义Gray映射下线性码的像，探索这类广义线性码的构造与性质

Method: 构造有限链环R上的线性单纯形码及其对应的R-线性单纯形码（α型和β型），分析其基本参数包括最小汉明距离和完全重量分布，并研究其相对于Griesmer型界的优化性

Result: 给出了线性单纯形码和R-线性单纯形码的构造方法，确定了它们的基本参数和完全重量分布，并分析了这些码相对于Griesmer型界的优化性质

Conclusion: 成功将单纯形码的概念推广到有限链环上，建立了完整的理论框架，为有限链环上的编码理论研究提供了新的工具和结果

Abstract: A linear code of length $n$ over a finite chain ring $R$ with residue field $\F_q$ is a $R$-submodule of $R^n$. A $R$-linear code is a code over $\F_q$ (not necessarily linear) which is the generalized Gray map image of a linear code over $R$. These codes can be seen as a generalization of the linear codes over $\Z_{p^s}$ with $p$ prime and $s \geq 1$. In this paper, we present the construction of linear simplex codes over $R$ and their corresponding $R$-linear simplex codes of type $α$ and $β$. Moreover, we show the fundamental parameters of these codes, including their minimum Hamming distance, as well as their complete weight distributions. We also study whether these simplex codes are optimal with respect to the Griesmer-type bound.

</details>


### [50] [Low-Power Double RIS-Assisted Mobile LEO Satellite Communications](https://arxiv.org/abs/2512.02255)
*Kunnathully Sadanandan Sanila,Rickard Nilsson,Emad Ibrahim,Neelakandan Rajamohan*

Main category: cs.IT

TL;DR: 提出一种采用双可重构智能表面(RIS)的低功耗移动LEO卫星通信架构，通过近场和远场效应优化能量效率和信号性能


<details>
  <summary>Details</summary>
Motivation: 在能量受限的LEO卫星通信环境中，需要降低功耗并提高信号性能，传统方法难以满足需求

Method: 采用双RIS架构，一个RIS在卫星天线近场，另一个在用户近场，RIS间距满足远场要求；建立考虑近场和远场效应的双RIS路径损耗模型；使用双级波束成形最大化信号功率并最小化功耗

Result: 仿真结果显示，在上行链路中，使用0.25平方米的小型RIS靠近用户时，功耗可降低40dB

Conclusion: 提出的双RIS架构能有效降低LEO卫星通信系统的功耗，特别适用于能量受限的通信环境

Abstract: We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.

</details>


### [51] [Entropies associated with orbits of finite groups](https://arxiv.org/abs/2512.02257)
*Ryan Leal,Jingtong Sun,Juan Pablo Vigneaux*

Main category: cs.IT

TL;DR: 该论文将信息论中的熵公式与群论中的轨道计数联系起来，扩展了传统Shannon熵和Tsallis熵与对称群和一般线性群的对应关系，研究了其他反射群和典型群，发现了新的熵泛函。


<details>
  <summary>Details</summary>
Motivation: 传统信息论公式主要对应对称群（Shannon熵）和一般线性群（Tsallis 2-熵），作者希望将这种群论-信息论对应关系扩展到其他类型的群，特别是其他反射群和典型群（如辛群），以发现新的熵泛函。

Method: 通过研究有限反射群和有限域上典型群（李型群）的抛物子群商空间，分析轨道基数的渐近行为。这些群按Dynkin图分类为无限系列A_n、B_n、C_n、D_n和有限个例外群，其中A_n系列对应已知结果，作者首次从信息论角度研究其他系列。

Result: 发现了B_n、C_n、D_n等系列群对应的新熵泛函，这些泛函通过轨道基数的渐近行为与信息论中的熵概念相联系。对称群（A_n反射情况）对应Shannon熵，一般线性群（A_n李情况）对应Tsallis 2-熵，而其他系列对应新的熵函数。

Conclusion: 群论中的轨道计数与信息论中的熵公式之间存在深刻的对应关系，这种关系不仅限于传统的对称群和一般线性群，还扩展到其他反射群和典型群，为信息论提供了新的数学基础和熵泛函。

Abstract: For certain groups, parabolic subgroups appear as stabilizers of flags of sets or vector spaces. Quotients by these parabolic subgroups represent orbits of flags, and their cardinalities asymptotically reveal entropies (as rates of exponential or superexponential growth). The multiplicative "chain rules" that involve these cardinalities induce, asymptotically, additive analogues for entropies. Many traditional formulas in information theory correspond to quotients of symmetric groups, which are a particular kind of reflection group; in this case, the cardinalities of orbits are given by multinomial coefficients and are asymptotically related to Shannon entropy. One can treat similarly quotients of the general linear groups over a finite field; in this case, the cardinalities of orbits are given by $q$-multinomials and are asymptotically related to the Tsallis 2-entropy. In this contribution, we consider other finite reflection groups as well as the symplectic group as an example of a classical group over a finite field (groups of Lie type). In both cases, the groups are classified by Dynkin diagrams into infinite series of similar groups $A_n$, $B_n$, $C_n$, $D_n$ and a finite number of exceptional ones. The $A_n$ series consists of the symmetric groups (reflection case) and general linear groups (Lie case). Some of the other series, studied here from an information-theoretic perspective for the first time, are linked to new entropic functionals.

</details>


### [52] [New Constructions of Non-GRS MDS Codes, Recovery and Determination Algorithms for GRS Codes](https://arxiv.org/abs/2512.02325)
*Guodong Wang,Hongwei Liu,Jinquan Luo*

Main category: cs.IT

TL;DR: 提出构造非GRS MDS码的新方法，分析其与扭曲GRS码的不等价性，并设计高效算法解决GRS码识别和密钥恢复问题。


<details>
  <summary>Details</summary>
Motivation: 现有GRS码在密码学应用中存在安全隐患（如Sidelnikov-Shestakov攻击），需要构造非GRS的MDS码以增强安全性，同时需要高效算法来识别GRS码和恢复其参数。

Method: 1. 提出构造非GRS MDS码的新方法，码长可达(q+3)/2（奇特征）和(q+4)/2（偶特征）；2. 使用柯西矩阵方法分析MDS和非GRS条件；3. 分析与扭曲GRS码的不等价性；4. 设计两个高效算法：GRS码识别算法（复杂度O(nk+n)）和密钥向量恢复算法。

Result: 1. 构造出长度达到理论界限的非GRS MDS码；2. 证明了新构造码与扭曲GRS码的不等价性；3. 提出的算法复杂度显著优于Sidelnikov-Shestakov攻击（O(nk+n) vs O(qk²n+qk³)）；4. 分析了现有各类非GRS MDS码构造之间的关系。

Conclusion: 本文提出了构造非GRS MDS码的有效方法，并设计了高效的GRS码识别和参数恢复算法，在码长和计算效率方面都有显著改进，为密码学应用提供了更安全的编码方案。

Abstract: In this paper, we propose a new method for constructing a class of non-GRS MDS codes. The lengths of these codes can reach up to $\frac{q+3}{2}$ (for finite fields of odd characteristic) and $\frac{q+4}{2}$ (for even characteristic), respectively. Owing to their special structure, we can use the Cauchy matrix method to obtain the necessary and sufficient conditions for these codes to be MDS codes and non-GRS MDS codes. Additionally, the inequivalence between these codes and twisted GRS codes is analyzed. Furthermore, we analyze the relationships among several existing classes of codes used for constructing non-GRS MDS codes, propose explicit constructions, and discuss the lengths of non-GRS MDS codes based on these constructions. Finally, we design two efficient algorithms to address two main problems in GRS code research, i.e., determining whether an unknown code $C$ is a GRS code from its generator matrix $G$, and recovering the key vectors $\bmα$ and $\bm{v}$ such that $C = \GRS_{n,k}(\bmα, \bm{v})$ if $C$ is indeed a GRS code. A computational complexity comparison of the proposed algorithms ($O(nk+n)$) with that of the Sidelnikov-Shestakov attack (exceeding $O(qk^2n+qk^3)$) shows that our methods offer superior computational efficiency.

</details>


### [53] [Age of Information for Constrained Scheduling with Imperfect Feedback](https://arxiv.org/abs/2512.02332)
*Yuqing Zhu,Yuan-Hsun Lo,Yan Lin,Yijin Zhang*

Main category: cs.IT

TL;DR: 该论文研究了多用户下行链路系统中考虑不完美反馈和受限传输速率下的AoI优化调度算法，针对零反馈和伯努利流量场景提出了多种策略，并扩展到一般不完美反馈场景。


<details>
  <summary>Details</summary>
Motivation: 实际系统中存在不完美反馈和受限传输速率这两个关键限制因素，现有研究未能充分反映这些因素对信息年龄(AoI)的影响，特别是在零反馈场景下。

Method: 1) 针对零反馈的generate-at-will流量，推导了可达到AoI的闭式下界，提出结合速率分割和模运算的策略；2) 针对零反馈的伯努利流量，基于Lyapunov优化理论开发了具有阈值结构的DPP策略；3) 将DPP策略扩展到一般不完美反馈场景，保持在线计算复杂度不变。

Result: 1) 零反馈场景下首次推导了反映零反馈影响的闭式AoI下界，提出的策略在许多情况下能达到该下界；2) 为伯努利流量提供了闭式性能保证；3) 数值结果验证了理论分析和所提策略相对于现有策略的AoI优势。

Conclusion: 论文成功解决了实际系统中不完美反馈和受限传输速率下的AoI优化问题，提出的调度算法在多种场景下都能有效降低信息年龄，为实际无线通信系统的AoI优化提供了理论指导和实用方案。

Abstract: This paper considers a downlink system where an access point sends the monitored status of multiple sources to multiple users. By jointly accounting for imperfect feedback and constrained transmission rate, which are key limited factors in practical systems, we aim to design scheduling algorithms to optimize the age of information (AoI) over the infinite time horizon. For zero feedback under the generate-at-will traffic, we derive a closed-form lower bound of achievable AoI, which, to the best of our knowledge, reflects the impact of zero feedback for the first time, and propose a policy that achieves this bound in many cases by jointly applying rate splitting and modular arithmetic. For zero feedback under the Bernoulli traffic, we develop a drift-plus-penalty (DPP) policy with a threshold structure based on the theory of Lyapunov optimization and provide a closed-form performance guarantee. Furthermore, we extend the design of this DPP policy to support general imperfect feedback without increasing the online computational complexity. Numerical results verify our theoretical analysis and the AoI advantage of the proposed policies over state-of-the-art policies.

</details>


### [54] [A Cyclic Shift Embedded Pilot based Channel Estimation for Multi-User MIMO-OTFS systems with fractional delay and Doppler](https://arxiv.org/abs/2512.02353)
*Ruizhe Wang,Hong Ren,Cunhua Pan,Ruisong Weng,Jiangzhou Wang*

Main category: cs.IT

TL;DR: 提出多用户MIMO-OTFS系统的信道估计与导频设计方法，包括基于多维分解的信道估计算法和循环移位嵌入式导频结构，显著降低导频开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 多用户OTFS系统中，传统嵌入式导频方案需要为每个用户独立分配导频，导致导频开销线性增加。为满足未来无线网络高移动性场景下的可靠通信需求，需要解决多用户MIMO-OTFS系统的信道估计和导频设计问题。

Method: 1. 提出基于多维分解的信道估计算法：首先通过子空间分解方法估计到达角，构建空间投影矩阵解耦接收信号；然后使用基于压缩感知的离网信道估计方法获取剩余分数时延和多普勒频移。2. 提出循环移位嵌入式导频结构：利用Zadoff-Chu序列的循环移位正交性实现用户复用，减少导频开销。3. 基于CSEP结构改进信道估计方法。

Result: 仿真结果表明：1. 提出的信道估计方法性能优越；2. CSEP结构相比传统嵌入式导频结构可节省超过30%的导频开销；3. 整体方案在计算复杂度、估计精度和误码率性能之间取得了良好平衡。

Conclusion: 本文提出的多用户MIMO-OTFS系统信道估计与导频设计方案有效解决了传统方法导频开销大的问题，通过多维分解算法和循环移位导频结构实现了高性能、低开销的信道估计，为高移动性场景下的可靠通信提供了有效解决方案。

Abstract: Orthogonal time frequency space (OTFS) modulation has been proposed to meet the demand for reliable communication in high-mobility scenarios for future wireless networks. However, in multi-user OTFS systems, conventional embedded pilot schemes require independent pilot allocation for each user, leading to linearly increasing pilot overhead. To address these issues, in this paper, we investigate the uplink channel estimation and pilot design for multi-user multiple-input multiple-output (MIMO)-OTFS systems. We propose a multi-dimensional decomposition-based channel estimation algorithm. Specifically, the proposed algorithm first estimates the angles of arrivals (AoAs) via subspace decomposition-based method. A spatial projection matrix, constructed from the estimated AOAs, decouples the received signal by propagation path subspace, effectively mitigating inter-path interference. The remaining fractional delay and Doppler can be obtained by a compressed sensing (CS)-based off-grid channel estimation method. Furthermore, to reduce the pilot overhead in multi-user OTFS systems, this paper proposes a novel cyclic shift embedded pilot (CSEP) structure, which can reuse users through cyclic shift-orthogonality of Zadoff-Chu (ZC) sequences. Compared with conventional embedded pilot structures, the CSEP structure can save over 30\% of pilot overhead. Finally, an imporved channel estimation method based on the CSEP structure is proposed. Simulation results demonstrate that it achieves superior performance in channel estimation. Moreover, the proposed CSEP structure and channel estimation algorithm achieve a favorable balance between computational complexity, estimation accuracy, and bit error rate (BER) performance.

</details>


### [55] [Boltzmann-Shannon Index: A Geometric-Aware Measure of Clustering Balance](https://arxiv.org/abs/2512.02397)
*Emanuele Bossi,C. Tyler Diggans,Abd AlRahman R. AlMomani*

Main category: cs.IT

TL;DR: 提出Boltzmann-Shannon指数(BSI)，一种用于聚类连续数据的归一化度量，捕捉基于频率和基于几何的概率分布之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 传统聚类度量在评估聚类质量时往往只关注频率分布或几何分布，无法同时反映聚类的人口统计权重和几何扩展，特别是在资源分配等实际应用中需要平衡这两方面因素。

Method: 基于几何粗粒化和信息理论思想，BSI量化分区如何反映每个聚类的人口统计和有效几何范围，通过结合频率基和几何基概率分布来评估聚类质量。

Result: 在合成高斯混合、Iris基准和高不平衡资源分配场景中，BSI提供了连贯的评估，即使在传统指标给出不完整或误导信号时也能有效工作。在资源分配中，BSI能高灵敏度检测密度-几何不一致性。

Conclusion: BSI不仅是一个有效的聚类评估指标，还能作为平滑、优化就绪的目标函数，自然地支持平衡人口统计权重与结果空间中有效扩展的资源分配，为现代政策制定和算法治理提供梯度友好的正则化器。

Abstract: We introduce the Boltzmann-Shannon Index (BSI), a normalized measure for clustered continuous data that captures the interaction between frequency-based and geometry-based probability distributions. Building on ideas from geometric coarse-graining and information theory, the BSI quantifies how well a partition reflects both the population of each cluster and its effective geometric extent. We illustrate its behavior on synthetic Gaussian mixtures, the Iris benchmark, and a high-imbalance resource-allocation scenario, showing that the index provides a coherent assessment even when traditional metrics give incomplete or misleading signals. Moreover, in resource-allocation settings, we demonstrate that BSI not only detects severe density-geometry inconsistency with high sensitivity, but also offers a smooth, optimization-ready objective that naturally favors allocations balancing demographic weight with each group's effective spread in the outcome space, while providing a smooth, gradient-friendly regularizer that can be easily embedded in modern policy-making and algorithmic governance optimization frameworks.

</details>


### [56] [Optimal Handover Strategies in LEO Satellite Networks](https://arxiv.org/abs/2512.02449)
*Brendon McBain,Yi Hong,Emanuele Viterbo*

Main category: cs.IT

TL;DR: 提出一个分析LEO卫星网络容量的通用框架，考虑任意切换策略，推导持久容量及其上下界，并给出最优切换决策规则。


<details>
  <summary>Details</summary>
Motivation: 现有卫星星座理论分析存在限制性假设（如短服务时间），或在评估实际切换策略时缺乏可处理性，需要更通用的分析框架。

Method: 将传输链路建模为阴影Rician衰落，引入持久卫星信道概念（信道过程由i.i.d.更新过程控制），利用更新理论推导持久容量，建立闭式上下界，将最优切换问题公式化为非线性分式规划，使用Dinkelbach算法变体获得显式决策规则。

Result: 推导出持久卫星信道的遍历容量（持久容量），建立了与先前研究的非持久容量的关系，提出了闭式上下界，获得了最优切换的显式决策规则，并证明最大化服务容量的简化切换策略能很好地逼近最优策略。

Conclusion: 该框架为准确表征LEO卫星网络在任意切换策略下的容量提供了理论基础，提出的简化切换策略为设计高吞吐量LEO卫星通信系统提供了实用见解。

Abstract: Existing theoretical analyses of satellite mega-constellations often rely on restrictive assumptions, such as short serving times, or lack tractability when evaluating realistic handover strategies. Motivated by these limitations, this paper develops a general analytical framework for accurately characterising the ergodic capacity of low Earth orbit (LEO) satellite networks under arbitrary handover strategies. Specifically, we model the transmission link as shadowed-Rician fading and introduce the persistent satellite channel, wherein the channel process is governed by an i.i.d. renewal process under mild assumptions of uncoordinated handover decisions and knowledge of satellite ephemeris and fading parameters. Within this framework, we derive the ergodic capacity (persistent capacity) of the persistent satellite channel using renewal theory and establish its relation to the non-persistent capacity studied in prior work. To address computational challenges, we present closed-form upper and lower bounds on persistent capacity. The optimal handover problem is formulated as a non-linear fractional program, obtaining an explicit decision rule via a variant of Dinkelbach's algorithm. We further demonstrate that a simpler handover strategy maximising serving capacity closely approximates the optimal strategy, providing practical insights for designing high-throughput LEO satellite communication systems.

</details>


### [57] [Artificial Noise Aided Physical Layer Security for Near-Field MIMO with Fluid Antenna Systems](https://arxiv.org/abs/2512.02461)
*Peng Zhang,Jian Dang,Miaowen Wen,Ziyang Liu,Chen Zhao,Huaifeng Shi,Chengsheng Pan,Zaichen Zhang*

Main category: cs.IT

TL;DR: 提出一种用于近场流体天线MIMO系统的人工噪声辅助物理层安全方案，通过交替优化框架联合设计波束成形和人工噪声，利用流体天线的几何和位置自由度提升保密性能。


<details>
  <summary>Details</summary>
Motivation: 随着无线系统向大规模阵列和高频可重构架构演进，近场流体天线系统为物理层安全提供了新的自由度。现有方案在非极大阵列中仅靠近场波束聚焦不足以保证安全性能，需要利用流体天线的几何和位置自由度来增强保密性。

Method: 采用交替优化框架处理稀疏约束非凸设计，分为连续波束成形/人工噪声联合设计子问题和离散流体天线端口选择子问题。通过广义谱注水过程获得闭式全数字波束成形/人工噪声解，并通过硬件高效的混合波束成形架构实现。对于端口选择，采用基于行能量的修剪-重拟合规则。

Result: 仿真结果表明，所提设计能有效利用流体天线的几何和位置自由度，显著提升保密性能，特别是在非极大阵列中，仅靠近场波束聚焦不足以保证安全的情况下表现优异。

Conclusion: 该研究为近场流体天线MIMO系统提供了一种高效的人工噪声辅助物理层安全方案，通过联合优化波束成形、人工噪声和端口选择，充分利用了流体天线在近场区域的自由度优势，为未来大规模阵列系统的安全通信提供了有效解决方案。

Abstract: With the evolution of wireless systems toward large-scale arrays and high-frequency reconfigurable architectures, fluid antenna systems (FAS) operating in the near-field (NF) regime provide new degrees of freedom (DoF) for physical layer security (PLS). This paper proposes an artificial-noise (AN)-aided PLS scheme for NF fluid-antenna multiple-input multiple-output (FA-MIMO) systems, with joint beamforming (BF) and AN design for both compact and large arrays. An alternating-optimization (AO) framework addresses the sparsity-constrained non-convex design by splitting it into a continuous BF/AN joint-design subproblem and a discrete FAS port-selection subproblem. Closed-form fully digital BF/AN solutions are obtained via a generalized spectral water-filling procedure within a block coordinate descent (BCD) surrogate and realized by a hardware-efficient hybrid beamforming (HBF) architecture that embeds AN in the baseband without extra radio-frequency (RF) chains. For FAS port selection, a row-energy based prune--refit rule, aligned with Karush--Kuhn--Tucker (KKT) conditions of a group-sparsity surrogate, enables efficient active-port determination. Simulation results confirm that the proposed design exploits the geometry and position-domain DoF of FAS and significantly improves secrecy performance, particularly for non-extremely-large arrays where NF beam focusing alone is inadequate.

</details>


### [58] [Quantum Optimization in Wireless Communication Systems: Principles and Applications](https://arxiv.org/abs/2512.02468)
*Ioannis Krikidis,Valentin Gilbert*

Main category: cs.IT

TL;DR: 该论文综述了量子优化在下一代无线通信系统设计中的应用，重点介绍了绝热量子计算原理及其两种主要计算模型（量子退火和门基量子近似优化算法），并通过无源可重构智能表面波束成形设计案例展示了实际量子硬件的实验结果。


<details>
  <summary>Details</summary>
Motivation: 量子优化有望解决下一代无线通信系统设计中的关键计算和技术挑战，通过利用量子计算的优势来推动无线通信系统设计的进步。

Method: 基于绝热量子计算原理，探讨了两种主要计算模型：量子退火和门基量子近似优化算法，并通过无源可重构智能表面波束成形设计作为案例研究，使用真实量子硬件进行实验验证。

Result: 论文展示了量子优化方法在无线通信系统设计中的实际应用潜力，通过真实量子硬件实验验证了无源可重构智能表面波束成形设计的可行性。

Conclusion: 量子退火和量子近似优化算法是推动无线通信系统设计的有前景的工具，量子优化将在下一代无线通信系统设计中发挥变革性作用。

Abstract: Quantum optimization is poised to play a transformative role in the design of next-generation wireless communication systems by addressing key computational and technological challenges. This paper provides an overview of the principles of adiabatic quantum computing, the foundation of quantum optimization, and explores its two primary computational models: quantum annealing and the gate-based quantum approximate optimization algorithm. By highlighting their core features, performance benefits, limitations, and distinctions, we position these methods as promising tools for advancing wireless communication system design. As a case study, we examine the design of passive reconfigurable intelligent surface beamforming with binary phase-shift resolution, supported by experimental results obtained from real-world quantum hardware.

</details>


### [59] [Deep Q-Learning-Driven Power Control for Enhanced Noma User Performance](https://arxiv.org/abs/2512.02582)
*Bach Hung Luu,Sinh Cong Lam,Nam Hoang Nguyen*

Main category: cs.IT

TL;DR: 本文提出了一种基于无人机辅助的蜂窝网络智能功率控制方案，通过距离判据选择边缘用户进行无人机中继，使用DQN优化功率分配，显著提升了边缘用户性能。


<details>
  <summary>Details</summary>
Motivation: 蜂窝网络中边缘用户由于距离基站远、存在物理遮挡，信道条件差，数据速率远低于中心用户，存在性能差距问题需要解决。

Method: 提出无人机辅助蜂窝网络架构，采用距离判据（仅距离超过参考值的用户获得无人机中继），无人机作为放大转发中继，用户同时接收基站和无人机信号获得分集增益，使用深度Q网络学习功率控制策略。

Result: 在最优参考距离400m时达到峰值平均速率2.28bps/Hz，相比无无人机辅助网络提升3.6%，相比所有用户都获得无人机支持的网络提升0.9%。无人机高度和参考距离是关键影响因素，较低高度性能更好。

Conclusion: 基于距离判据的无人机辅助网络结合DQN功率控制能有效缩小边缘用户与中心用户的性能差距，智能功率分配策略无需精确信道模型，无人机高度和参考距离优化对系统性能至关重要。

Abstract: Cell-edge users (CEUs) in cellular networks typically suffer from poor channel conditions due to long distances from serving base stations and physical obstructions, resulting in much lower data rates compared to cell-center users (CCUs). This paper proposes an Unmanned Aerial Vehicles (UAV)-assisted cellular network with intelligent power control to address the performance gap between CEUs and CCUs. Unlike conventional approaches that either deploy UAVs for all users or use no UAV assistance, our model uses a distance-based criterion where only users beyond a reference distance receive UAV relay assistance. Each UAV operates as an amplify-and-forward relay, enabling assisted users to receive signals from both the base station and the UAV simultaneously, thereby achieving diversity gain. To optimize transmission power allocation across base stations, we employ a Deep Q-Network (DQN) learning framework that learns power control policies without requiring accurate channel models. Simulation results show that the proposed approach achieves a peak average rate of 2.28 bps/Hz at the optimal reference distance of 400m, which represents a 3.6% improvement compared to networks without UAV assistance and 0.9% improvement compared to networks where all users receive UAV support. The results also reveal that UAV altitude and reference distance are critical factors affecting system performance, with lower altitudes providing better performance.

</details>


### [60] [Digit-Indexed q-ary SEC-DED Codes with Near-Hamming Overhead](https://arxiv.org/abs/2512.02747)
*Jiaxu Hu,Kenneth J. Roche*

Main category: cs.IT

TL;DR: 提出一个简单的q进制单纠双检(SEC-DED)线性码族，其校验位与坐标索引的p进制数字直接相关，具有近汉明码开销和常数时间解码，并扩展到更高距离码


<details>
  <summary>Details</summary>
Motivation: 传统纠错码实现复杂，需要开发结构简单、易于实现、阵列友好的编码方案，特别是具有明确错误定位映射和模块化升级能力的码

Method: 基于坐标索引的p进制数字构建校验位，块长n=p^r时仅需r+1个校验位。开发两种扩展：A1码通过移除特定冗余三进制位提高信息率；A2码结合两组和校验与3-wise XOR线性独立条件，实现距离4的三进制码

Result: 构建了具有近汉明码开销的简单SEC-DED码，支持常数时间错误定位和幅度恢复。扩展版本A1提高信息率，A2实现距离4的三进制SEC-TED码。框架可推广到距离d=n+1的码，甚至恢复了三进制Golay码

Conclusion: 贡献在于实现简单性和阵列友好结构，而非最优性。校验位是数字位和全局和，错误定位映射明确，SEC-TED升级模块化。与经典q进制汉明码和SPC/乘积码基准相比，在奇偶校验开销、解码工作和双错误行为方面具有优势

Abstract: We present a simple $q$-ary family of single-error-correcting, double-error-detecting (SEC--DED) linear codes whose parity checks are tied directly to the base-$p$ ($q=p$ prime) digits of the coordinate index. For blocklength $n=p^r$ the construction uses only $r+1$ parity checks -- \emph{near-Hamming} overhead -- and admits an index-based decoder that runs in a single pass with constant-time location and magnitude recovery from the syndromes. Based on the prototype, we develop two extensions: Code A1, which removes specific redundant trits to achieve higher information rate and support variable-length encoding; and Code A2, which incorporates two group-sum checks together with a 3-wise XOR linear independence condition on index subsets, yielding a ternary distance-4 (SEC--TED) variant. Furthermore, we demonstrate how the framework generalizes via $n$-wise XOR linearly independent sets to construct codes with distance $d = n + 1$, notably recovering the ternary Golay code for $n = 5$ -- showing both structural generality and a serendipitous link to optimal classical codes.
  Our contribution is not optimality but \emph{implementational simplicity} and an \emph{array-friendly} structure: the checks are digitwise and global sums, the mapping from syndromes to error location is explicit, and the SEC--TED upgrade is modular. We position the scheme against classical $q$-ary Hamming and SPC/product-code baselines and provide a small comparison of parity overhead, decoding work, and two-error behavior.

</details>


### [61] [Structural Properties of Entropic Vectors and Stability of the Ingleton Inequality](https://arxiv.org/abs/2512.02767)
*Rostislav Matveev,Andrei Romashchenko*

Main category: cs.IT

TL;DR: 研究熵框架下Ingleton不等式的约束版本及其在条件独立性小破坏下的稳定性，建立了受控误差下的不等式保持


<details>
  <summary>Details</summary>
Motivation: 经典Ingleton不等式在一般熵分布中不成立，但在某些精确独立性约束下成立。研究在条件互信息项很小（但不为零）时的不等式稳定性

Method: 使用结构引理具体化部分互信息，隐含捕获无限多非Shannon型不等式效应，提供概念清晰的证明而无需显式调用无限不等式族

Result: 得到受控误差下Ingleton不等式的稳定性结果，部分结果统一恢复了Matúš和Dougherty-Freiling-Zeger的无限不等式族推论，部分结果是新的

Conclusion: 通过结构引理方法，在条件独立性小破坏下建立了Ingleton不等式的稳定性理论，为熵不等式研究提供了新视角

Abstract: We study constrained versions of the Ingleton inequality in the entropic setting and quantify its stability under small violations of conditional independence. Although the classical Ingleton inequality fails for general entropy profiles, it is known to hold under certain exact independence constraints. We focus on the regime where selected conditional mutual information terms are small (but not zero), and the inequality continues to hold up to controlled error terms. A central technical tool is a structural lemma that materializes part of the mutual information between two random variables, implicitly capturing the effect of infinitely many non-Shannon--type inequalities. This leads to conceptually transparent proofs without explicitly invoking such infinite families. Some of our bounds recover, in a unified way, what can also be deduced from the infinite families of inequalities of Matúš (2007) and of Dougherty--Freiling--Zeger (2011), while others appear to be new.

</details>


### [62] [Pseudocodewords of quantum, quasi-cyclic, and spatially-coupled LDPC codes: a fundamental cone perspective](https://arxiv.org/abs/2512.02941)
*Wittawat Kositwattanarerk,Gretchen L. Matthews,Emily McMillon,Tunchanok Yutitumsatit*

Main category: cs.IT

TL;DR: 本文分析量子稳定子码、准循环LDPC码和空间耦合LDPC码在LP解码下产生的伪码字底层结构


<details>
  <summary>Details</summary>
Motivation: 虽然LDPC码与迭代解码器结合时接近容量极限，但这些解码器可能由于伪码字的存在而无法输出有效码字。伪码字的研究有助于理解现代解码器（包括迭代解码和线性规划解码）的性能表现。

Method: 采用线性规划（LP）解码方法，该方法与图覆盖解码相关联，能够捕获伪码字。重点分析量子稳定子码、准循环LDPC码和空间耦合LDPC码在LP解码下产生的伪码字底层结构。

Result: 研究发现伪码字依赖于码的奇偶校验矩阵和特定的解码算法。通过LP解码与图覆盖解码的联系，提供了捕获这些伪码字的函数。

Conclusion: 对量子稳定子码、准循环LDPC码和空间耦合LDPC码在LP解码下伪码字结构的分析，为理解现代解码器性能提供了重要见解，有助于改进解码算法设计。

Abstract: While low-density parity-check (LDPC) codes are near capacity-achieving when paired with iterative decoders, these decoders may not output a codeword due to the existence of pseudocodewords. Thus, pseudocodewords have been studied to give insight into the performance of modern decoders including iterative and linear programming decoders. These pseudocodewords are found to be dependent on the parity-check matrix of the code and the particular decoding algorithm used. In this paper, we consider LP decoding, which has been linked to graph cover decoding, providing functions which capture these pseudocodewords. In particular, we analyze the underlying structure of pseudocodewords from quantum stabilizer codes that arise from LP decoding, quasi-cyclic LDPC codes, and spatially-coupled LDPC codes.

</details>
