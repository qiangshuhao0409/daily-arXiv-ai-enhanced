{"id": "2508.09620", "categories": ["cs.NI", "cs.SY", "eess.SY", "D.4.8; C.3"], "pdf": "https://arxiv.org/pdf/2508.09620", "abs": "https://arxiv.org/abs/2508.09620", "authors": ["Michel Rottleuthner", "Thomas C. Schmidt", "Matthias Wählisch"], "title": "Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling", "comment": null, "summary": "Minimizing energy consumption of low-power wireless nodes is a persistent\nchallenge from the constrained Internet of Things (IoT). In this paper, we\nstart from the observation that constrained IoT devices have largely different\nhardware (im-)balances than full-scale machines. We find that the performance\ngap between MCU and network throughput on constrained devices enables minimal\nenergy delay product (EDP) for IoT networking at largely reduced clock\nfrequencies. We analyze the potentials by integrating dynamic voltage and\nfrequency scaling (DVFS) into the RIOT IoT operating system and show that the\nDVFS reconfiguration overhead stays below the energy saved for a single,\ndownscaled MAC operation. Backed by these findings, we systematically\ninvestigate how DVFS further improves energy-efficiency for common networking\ntasks -- in addition to duty-cycling. We measure IoT communication scenarios\nbetween real-world systems and analyze two MAC operating modes -- CSMA/CA and\ntime slotting -- in combination with different CoAP transactions, payload\nsizes, as well as DTLS transport encryption. Our experiments reveal energy\nsavings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP\ncommunication. These results shall encourage research and system design work to\nintegrate DVFS in future IoT devices for performing tasks at their optimal\nfrequencies and thereby significantly extending battery lifetimes."}
{"id": "2508.09382", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09382", "abs": "https://arxiv.org/abs/2508.09382", "authors": ["Sreejith Sreekumar", "Kengo Kato"], "title": "Deviation Inequalities for Rényi Divergence Estimators via Variational Expression", "comment": null, "summary": "R\\'enyi divergences play a pivotal role in information theory, statistics,\nand machine learning. While several estimators of these divergences have been\nproposed in the literature with their consistency properties established and\nminimax convergence rates quantified, existing accounts of probabilistic bounds\ngoverning the estimation error are premature. Here, we make progress in this\nregard by establishing exponential deviation inequalities for smoothed plug-in\nestimators and neural estimators by relating the error to an appropriate\nempirical process and leveraging tools from empirical process theory. In\nparticular, our approach does not require the underlying distributions to be\ncompactly supported or have densities bounded away from zero, an assumption\nprevalent in existing results. The deviation inequality also leads to a\none-sided concentration bound from the expectation, which is useful in\nrandom-coding arguments over continuous alphabets in information theory with\npotential applications to physical-layer security. As another concrete\napplication, we consider a hypothesis testing framework for auditing R\\'{e}nyi\ndifferential privacy using the neural estimator as a test statistic and obtain\nnon-asymptotic performance guarantees for such a test."}
{"id": "2508.09147", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.09147", "abs": "https://arxiv.org/abs/2508.09147", "authors": ["Alaa Saleh", "Roberto Morabito", "Sasu Tarkoma", "Anders Lindgren", "Susanna Pirttikangas", "Lauri Lovén"], "title": "Agentic TinyML for Intent-aware Handover in 6G Wireless Networks", "comment": null, "summary": "As 6G networks evolve into increasingly AI-driven, user-centric ecosystems,\ntraditional reactive handover mechanisms demonstrate limitations, especially in\nmobile edge computing and autonomous agent-based service scenarios. This\nmanuscript introduces WAAN, a cross-layer framework that enables intent-aware\nand proactive handovers by embedding lightweight TinyML agents as autonomous,\nnegotiation-capable entities across heterogeneous edge nodes that contribute to\nintent propagation and network adaptation. To ensure continuity across\nmobility-induced disruptions, WAAN incorporates semi-stable rendezvous points\nthat serve as coordination anchors for context transfer and state preservation.\nThe framework's operational capabilities are demonstrated through a multimodal\nenvironmental control case study, highlighting its effectiveness in maintaining\nuser experience under mobility. Finally, the article discusses key challenges\nand future opportunities associated with the deployment and evolution of WAAN."}
{"id": "2508.09277", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09277", "abs": "https://arxiv.org/abs/2508.09277", "authors": ["Soumia Mehimeh"], "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning", "comment": null, "summary": "Value function initialization (VFI) is an effective way to achieve a\njumpstart in reinforcement learning (RL) by leveraging value estimates from\nprior tasks. While this approach is well established in tabular settings,\nextending it to deep reinforcement learning (DRL) poses challenges due to the\ncontinuous nature of the state-action space, the noisy approximations of neural\nnetworks, and the impracticality of storing all past models for reuse. In this\nwork, we address these challenges and introduce DQInit, a method that adapts\nvalue function initialization to DRL. DQInit reuses compact tabular Q-values\nextracted from previously solved tasks as a transferable knowledge base. It\nemploys a knownness-based mechanism to softly integrate these transferred\nvalues into underexplored regions and gradually shift toward the agent's\nlearned estimates, avoiding the limitations of fixed time decay. Our approach\noffers a novel perspective on knowledge transfer in DRL by relying solely on\nvalue estimates rather than policies or demonstrations, effectively combining\nthe strengths of jumpstart RL and policy distillation while mitigating their\ndrawbacks. Experiments across multiple continuous control tasks demonstrate\nthat DQInit consistently improves early learning efficiency, stability, and\noverall performance compared to standard initialization and existing transfer\ntechniques."}
{"id": "2508.09687", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09687", "abs": "https://arxiv.org/abs/2508.09687", "authors": ["Chun'e Zhao", "Yuxin Han", "Wenping Ma", "Tongjiang Yan", "Yuhua Sun"], "title": "Hermitian Self-dual Twisted Generalized Reed-Solomon Codes", "comment": "This manuscript has been submitted to the IEEE Transactions on\n  Information Theory for possible publication", "summary": "Self-dual maximum distance separable (MDS) codes over finite fields are\nlinear codes with significant combinatorial and cryptographic applications.\nTwisted generalized Reed-Solomon (TGRS) codes can be both MDS and self-dual. In\nthis paper, we study a general class of TGRS codes (A-TGRS), which encompasses\nall previously known special cases. First, we establish a sufficient and\nnecessary condition for an A-TGRS code to be Hermitian self-dual. Furthermore,\nwe present four constructions of self-dual TGRS codes, which, to the best of\nour knowledge, nearly cover all the related results previously reported in the\nliterature. More importantly, we also obtain several new classes of Hermitian\nself-dual TGRS codes with flexible parameters. Based on this framework, we\nderive a sufficient and necessary condition for an A-TGRS code to be Hermitian\nself-dual and MDS. In addition, we construct a class of MDS Hermitian self-dual\nTGRS code by appropriately selecting the evaluation points. This work\ninvestigates the Hermitian self-duality of TGRS codes from the perspective of\nmatrix representation, leading to more concise and transparent analysis. More\ngenerally, the Euclidean self-dual TGRS codes and the Hermitian self-dual GRS\ncodes can also be understood easily from this point."}
{"id": "2508.09149", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.09149", "abs": "https://arxiv.org/abs/2508.09149", "authors": ["Seyed Hossein Ahmadpanah"], "title": "Semantic-Aware LLM Orchestration for Proactive Resource Management in Predictive Digital Twin Vehicular Networks", "comment": null, "summary": "Next-generation automotive applications require vehicular edge computing\n(VEC), but current management systems are essentially fixed and reactive. They\nare suboptimal in extremely dynamic vehicular environments because they are\nconstrained to static optimization objectives and base their decisions on the\ncurrent network states. This paper presents a novel Semantic-Aware Proactive\nLLM Orchestration (SP-LLM) framework to address these issues. Our method\ntransforms the traditional Digital Twin (DT) into a Predictive Digital Twin\n(pDT) that predicts important network parameters such as task arrivals, vehicle\nmobility, and channel quality. A Large Language Model (LLM) that serves as a\ncognitive orchestrator is at the heart of our framework. It makes proactive,\nforward-looking decisions about task offloading and resource allocation by\nutilizing the pDT's forecasts. The LLM's ability to decipher high-level\nsemantic commands given in natural language is crucial because it enables it to\ndynamically modify its optimization policy to match evolving strategic\nobjectives, like giving emergency services priority or optimizing energy\nefficiency. We show through extensive simulations that SP-LLM performs\nsignificantly better in terms of scalability, robustness in volatile\nconditions, and adaptability than state-of-the-art reactive and MARL-based\napproaches. More intelligent, autonomous, and goal-driven vehicular networks\nwill be possible due to our framework's outstanding capacity to convert human\nintent into optimal network behavior."}
{"id": "2508.09292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09292", "abs": "https://arxiv.org/abs/2508.09292", "authors": ["Sundong Kim"], "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards", "comment": null, "summary": "The ability to rapidly adapt to novel and unforeseen environmental changes is\na cornerstone of artificial general intelligence (AGI), yet it remains a\ncritical blind spot in most existing AI benchmarks. Traditional evaluation\nlargely focuses on optimizing performance within fixed environments, failing to\nassess systems' flexibility and generalization capabilities when faced with\neven subtle rule or structural modifications. Addressing this gap, I introduce\nthe Othello AI Arena, a novel benchmark framework designed to evaluate\nintelligent systems based on their capacity for limited-time adaptation to\nunseen environments. Our platform poses a meta-learning challenge: participants\nmust develop systems that can analyze the specific configuration and rules of a\nnovel Othello board within a strict time limit (60 seconds) and generate a\ntailored, high-performing strategy for that unique environment. With this,\nevaluation of the meta-level intelligence can be separated from the task-level\nstrategy performance. The Arena features a diverse set of game stages,\nincluding public stages for development and private stages with structural and\nrule variations designed to test genuine adaptive and generalization\ncapabilities. Implemented as an accessible web-based platform, the Arena\nprovides real-time visualization, automated evaluation using multi-dimensional\nmetrics, and comprehensive logging for post-hoc analysis. Initial observations\nfrom pilot tests and preliminary student engagements highlight fascinating\npatterns in adaptation approaches, ranging from rapid parameter tuning to\nrudimentary environmental model learning through simulation. The Othello AI\nArena offers a unique educational tool and a valuable research benchmark for\nfostering and evaluating the crucial skill of rapid, intelligent adaptation in\nAI systems."}
{"id": "2508.09695", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09695", "abs": "https://arxiv.org/abs/2508.09695", "authors": ["Han Xiao", "Xiaoyan Hu", "Kai-Kit Wong", "Xusheng Zhu", "Hanjiang Hong", "Chan-Byoung Chae"], "title": "Fluid Reconfigurable Intelligent Surface with Element-Level Pattern Reconfigurability: Beamforming and Pattern Co-Design", "comment": null, "summary": "This paper proposes a novel pattern-reconfigurable fluid reconfigurable\nintelligent surface (FRIS) framework, where each fluid element can dynamically\nadjust its radiation pattern based on instantaneous channel conditions. To\nevaluate its potential, we first conduct a comparative analysis of the received\nsignal power in point-to-point communication systems assisted by three types of\nsurfaces: (1) the proposed pattern-reconfigurable FRIS, (2) a\nposition-reconfigurable FRIS, and (3) a conventional RIS. Theoretical results\ndemonstrate that the pattern-reconfigurable FRIS provides a significant\nadvantage in modulating transmission signals compared to the other two\nconfigurations. To further study its capabilities, we extend the framework to a\nmultiuser communication scenario. In this context, the spherical harmonics\northogonal decomposition (SHOD) method is employed to accurately model the\nradiation patterns of individual fluid elements, making the pattern design\nprocess more tractable. An optimization problem is then formulated with the\nobjective of maximizing the weighted sum rate among users by jointly designing\nthe active beamforming vectors and the spherical harmonics coefficients,\nsubject to both transmit power and pattern energy constraints. To tackle the\nresulting non-convex optimization problem, we propose an iterative algorithm\nthat alternates between a minimum mean-square error (MMSE) approach for active\nbeamforming and a Riemannian conjugate gradient (RCG) method for updating the\nspherical harmonics coefficients. Simulation results show that the proposed\npattern-reconfigurable FRIS significantly outperforms traditional RIS\narchitectures based on the 3GPP 38.901 and isotropic radiation models,\nachieving average performance gains of 161.5% and 176.2%, respectively."}
{"id": "2508.09150", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09150", "abs": "https://arxiv.org/abs/2508.09150", "authors": ["Pietro Piscione", "Leonardo Lossi", "Maziar Nekovee", "Chathura Galkandage", "Phil O Connor", "Simon Davies"], "title": "Enabling On-demand Guaranteed QoS for Real Time Video Streaming from Vehicles in 5G Advanced with CAPIF & NEF APIs", "comment": "Published in the Proceedings of 2025 EuCNC & 6G Summit, Pozna\\'n,\n  Poland, 3-6 June 2025", "summary": "This paper presents the design and implementation of a Proof of Concept (PoC)\nthat demonstrates how 5G Advanced Network Functions can be integrated with the\nCommon API Framework (CAPIF) to support enhanced connectivity for automotive\napplications. The PoC shows the continuous monitoring of the mobile network\nperformance and the on-demand and dynamic adaptation of Quality of Service\n(QoS) for selected 5G User Equipment (UE) video streaming traffic flows using\nstandard 3GPP Network Exposure Function (NEF) APIs exposed via CAPIF. Moreover,\ntraffic flows are redirected to the edge to improve latency and optimize\nnetwork resource utilization."}
{"id": "2508.09507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09507", "abs": "https://arxiv.org/abs/2508.09507", "authors": ["Meiping Wang", "Jian Zhong", "Rongduo Han", "Liming Kang", "Zhengkun Shi", "Xiao Liang", "Xing Lin", "Nan Gao", "Haining Zhang"], "title": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants", "comment": null, "summary": "With the rapid development of mobile intelligent assistant technologies,\nmulti-modal AI assistants have become essential interfaces for daily user\ninteractions. However, current evaluation methods face challenges including\nhigh manual costs, inconsistent standards, and subjective bias. This paper\nproposes an automated multi-modal evaluation framework based on large language\nmodels and multi-agent collaboration. The framework employs a three-tier agent\narchitecture consisting of interaction evaluation agents, semantic verification\nagents, and experience decision agents. Through supervised fine-tuning on the\nQwen3-8B model, we achieve a significant evaluation matching accuracy with\nhuman experts. Experimental results on eight major intelligent agents\ndemonstrate the framework's effectiveness in predicting users' satisfaction and\nidentifying generation defects."}
{"id": "2508.09744", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09744", "abs": "https://arxiv.org/abs/2508.09744", "authors": ["Andreas Zunker", "Marvin Rübenacke", "Stephan ten Brink"], "title": "ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding", "comment": "6 pages, 2 figures. Submitted to IEEE for possible publication", "summary": "Motivated by the need for channel codes with low-complexity soft-decision\ndecoding algorithms, we consider the recursive Plotkin concatenation of optimal\nlow-rate and high-rate codes based on simplex codes and their duals. These\ncomponent codes come with low-complexity maximum likelihood (ML) decoding\nwhich, in turn, enables efficient successive cancellation (SC)-based decoding.\nAs a result, the proposed optimally recursively concatenated simplex (ORCAS)\ncodes achieve a performance that is at least as good as that of polar codes.\nFor practical parameters, the proposed construction significantly outperforms\npolar codes in terms of block error rate by up to 0.5 dB while maintaining\nsimilar decoding complexity. Furthermore, the codes offer greater flexibility\nin codeword length than conventional polar codes."}
{"id": "2508.09151", "categories": ["cs.NI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.09151", "abs": "https://arxiv.org/abs/2508.09151", "authors": ["Chang Wu", "Yuang Chen", "Yiyuan Chen", "Fengqian Guo", "Xiaowei Qin", "Hancheng Lu"], "title": "Physiological Signal-Driven QoE Optimization for Wireless Virtual Reality Transmission", "comment": "7 pages, 6 figures", "summary": "Abrupt resolution changes in virtual reality (VR) streaming can significantly\nimpair the quality-of-experience (QoE) of users, particularly during\ntransitions from high to low resolutions. Existing QoE models and transmission\nschemes inadequately address the perceptual impact of these shifts. To bridge\nthis gap, this article proposes, for the first time, an innovative\nphysiological signal-driven QoE modeling and optimization framework that fully\nleverages users' electroencephalogram (EEG), electrocardiogram (ECG), and skin\nactivity signals. This framework precisely captures the temporal dynamics of\nphysiological responses and resolution changes in VR streaming, enabling\naccurate quantification of resolution upgrades' benefits and downgrades'\nimpacts. Integrated the proposed QoE framework into the radio access network\n(RAN) via a deep reinforcement learning (DRL) framework, adaptive transmission\nstrategies have been implemented to allocate radio resources dynamically, which\nmitigates short-term channel fluctuations and adjusts frame resolution in\nresponse to channel variations caused by user mobility. By prioritizing\nlong-term resolution while minimizing abrupt transitions, the proposed solution\nachieves an 88.7\\% improvement in resolution and an 81.0\\% reduction in\nhandover over the baseline. Experimental results demonstrate the effectiveness\nof this physiological signal-driven strategy, underscoring the promise of edge\nAI in immersive media services."}
{"id": "2508.09586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09586", "abs": "https://arxiv.org/abs/2508.09586", "authors": ["Yang Cheng", "Zilai Wang", "Weiyu Ma", "Wenhui Zhu", "Yue Deng", "Jian Zhao"], "title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse domains, including programming, planning, and decision-making. However,\ntheir performance often degrades when faced with highly complex problem\ninstances that require deep reasoning over long horizons. In such cases, direct\nproblem-solving approaches can lead to inefficiency or failure due to the lack\nof structured intermediate guidance. To address this, we propose a novel\nself-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM\nconstructs a sequence of problem instances with gradually increasing\ndifficulty, tailored to the solver LLM's learning progress. The curriculum\ndynamically adapts easing challenges when the solver struggles and escalating\nthem when success is consistent, thus maintaining an optimal learning\ntrajectory. This approach enables the solver LLM, implemented as a\ncode-generation model producing Python decision-tree scripts, to progressively\nacquire the skills needed for complex decision-making tasks. Experimental\nresults on challenging decision-making benchmarks show that our method\nsignificantly improves task success rates and solution efficiency compared to\ndirect-solving baselines. These findings suggest that LLM-driven curriculum\nlearning holds strong potential for enhancing automated reasoning in\nreal-world, high-complexity domains."}
{"id": "2508.09782", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09782", "abs": "https://arxiv.org/abs/2508.09782", "authors": ["Qin Yi", "Zilong Liu", "Leila Musavian", "Zeping Sui"], "title": "Non-Orthogonal Affine Frequency Division Multiplexing for Spectrally Efficient High-Mobility Communications", "comment": "13 pages, 13 figures, submitted to IEEE Transactions on Wireless\n  Communications", "summary": "This paper proposes a novel non-orthogonal affine frequency division\nmultiplexing {(nAFDM)} waveform for reliable high-mobility communications with\nenhanced spectral efficiency {(SE)}. The key idea is {to introduce} a bandwidth\ncompression factor into the AFDM {modulator} to enable controllable subcarrier\noverlapping. We first {detail the proposed nAFDM transceiver} and derive the\ncorresponding input-output {signal} relationship. Then, an efficient {nAFDM}\nsignal generation method based on the inverse discrete Fourier transform (IDFT)\nis proposed, enabling practical implementation using existing inverse fast\nFourier transform (IFFT) modules without additional hardware complexity. Next,\nto characterize the impact of non-orthogonal modulation, we derive a\nclosed-form expression {of} inter-carrier interference (ICI), showing its\ndependence on the bandwidth compression factor. To mitigate the resulting\ninterference, we propose a soft iterative detection algorithm and a\nlow-complexity implementation approach that leverages the distribution\ncharacteristics of ICI. {Simulation results demonstrate that 1) in terms of bit\nerror rate (BER), the proposed nAFDM can achieve near identical BER compared to\nconventional AFDM, while outperforms other waveform counterparts; 2) nAFDM is\ncapable of striking higher SE compared to other existing waveforms; and 3) the\nproposed nAFDM achieves an attractive BER vs. SE trade-off, and the proposed\nsoft ID scheme can attain a trade-off between BER and complexity.}"}
{"id": "2508.09152", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09152", "abs": "https://arxiv.org/abs/2508.09152", "authors": ["Joseph H. R. Isaac", "Harish Saradagam", "Nallamothu Pardhasaradhi"], "title": "5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI", "comment": "8 pages, 3 figures and 2 tables. Accepted in Conference on Advances\n  in Communication Networks & Systems (CoaCoNS 2025)", "summary": "With the advent of 5G networks and technologies, ensuring the integrity and\nperformance of packet core traffic is paramount. During network analysis, test\nfiles such as Packet Capture (PCAP) files and log files will contain errors if\npresent in the system that must be resolved for better overall network\nperformance, such as connectivity strength and handover quality. Current\nmethods require numerous person-hours to sort out testing results and find the\nfaults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine\ndesigned to classify successful and faulty frames in PCAP files, specifically\nwithin the 5G packet core. The FA engine analyses network traffic using natural\nlanguage processing techniques to identify anomalies and inefficiencies,\nsignificantly reducing the effort time required and increasing efficiency. The\nFA Engine also suggests steps to fix the issue using Generative AI via a Large\nLanguage Model (LLM) trained on several 5G packet core documents. The engine\nexplains the details of the error from the domain perspective using documents\nsuch as the 3GPP standards and user documents regarding the internal conditions\nof the tests. Test results on the ML models show high classification accuracy\non the test dataset when trained with 80-20 splits for the successful and\nfailed PCAP files. Future scopes include extending the AI engine to incorporate\n4G network traffic and other forms of network data, such as log text files and\nmultimodal systems."}
{"id": "2508.09639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09639", "abs": "https://arxiv.org/abs/2508.09639", "authors": ["Akshat Dubey", "Aleksandar Anžel", "Bahar İlgen", "Georges Hattab"], "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles", "comment": null, "summary": "Explainable Artificial Intelligence (XAI) techniques, such as SHapley\nAdditive exPlanations (SHAP), have become essential tools for interpreting\ncomplex ensemble tree-based models, especially in high-stakes domains such as\nhealthcare analytics. However, SHAP values are usually treated as point\nestimates, which disregards the inherent and ubiquitous uncertainty in\npredictive models and data. This uncertainty has two primary sources: aleatoric\nand epistemic. The aleatoric uncertainty, which reflects the irreducible noise\nin the data. The epistemic uncertainty, which arises from a lack of data. In\nthis work, we propose an approach for decomposing uncertainty in SHAP values\ninto aleatoric, epistemic, and entanglement components. This approach\nintegrates Dempster-Shafer evidence theory and hypothesis sampling via\nDirichlet processes over tree ensembles. We validate the method across three\nreal-world use cases with descriptive statistical analyses that provide insight\ninto the nature of epistemic uncertainty embedded in SHAP explanations. The\nexperimentations enable to provide more comprehensive understanding of the\nreliability and interpretability of SHAP-based attributions. This understanding\ncan guide the development of robust decision-making processes and the\nrefinement of models in high-stakes applications. Through our experiments with\nmultiple datasets, we concluded that features with the highest SHAP values are\nnot necessarily the most stable. This epistemic uncertainty can be reduced\nthrough better, more representative data and following appropriate or\ncase-desired model development techniques. Tree-based models, especially\nbagging, facilitate the effective quantification of epistemic uncertainty."}
{"id": "2508.09817", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.09817", "abs": "https://arxiv.org/abs/2508.09817", "authors": ["Zhehan Zhou", "Xiaoming Chen", "Ming Ying", "Zhaohui Yang", "Chongwen Huang", "Yunlong Cai", "Zhaoyang Zhang"], "title": "Unified Design of Space-Air-Ground-Sea Integrated Maritime Communications", "comment": null, "summary": "With the explosive growth of maritime activities, it is expected to provide\nseamless communications with quality of service (QoS) guarantee over broad sea\narea. In the context, this paper proposes a space-air-ground-sea integrated\nmaritime communication architecture combining satellite, unmanned aerial\nvehicle (UAV), terrestrial base station (TBS) and unmanned surface vessel\n(USV). Firstly, according to the distance away from the shore, the whole marine\nspace is divided to coastal area, offshore area, middle-sea area and open-sea\narea, the maritime users in which are served by TBS, USV, UAV and satellite,\nrespectively. Then, by exploiting the potential of integrated maritime\ncommunication system, a joint beamforming and trajectory optimization algorithm\nis designed to maximize the minimum transmission rate of maritime users.\nFinally, theoretical analysis and simulation results validate the effectiveness\nof the proposed algorithm."}
{"id": "2508.09159", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09159", "abs": "https://arxiv.org/abs/2508.09159", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein", "Andrea Leone", "Ali Maatouk", "Leandros Tassioulas", "Roberto Morabito", "Ioannis Pitsiorlas", "Marios Kountouris"], "title": "Agoran: An Agentic Open Marketplace for 6G RAN Automation", "comment": "Pre-print submitted to Computer Networks AI-for-6G", "summary": "Next-generation mobile networks must reconcile the often-conflicting goals of\nmultiple service owners. However, today's network slice controllers remain\nrigid, policy-bound, and unaware of the business context. We introduce Agoran\nService and Resource Broker (SRB), an agentic marketplace that brings\nstakeholders directly into the operational loop. Inspired by the ancient Greek\nagora, Agoran distributes authority across three autonomous AI branches: a\nLegislative branch that answers compliance queries using retrieval-augmented\nLarge Language Models (LLMs); an Executive branch that maintains real-time\nsituational awareness through a watcher-updated vector database; and a Judicial\nbranch that evaluates each agent message with a rule-based Trust Score, while\narbitrating LLMs detect malicious behavior and apply real-time incentives to\nrestore trust. Stakeholder-side Negotiation Agents and the SRB-side Mediator\nAgent negotiate feasible, Pareto-optimal offers produced by a multi-objective\noptimizer, reaching a consensus intent in a single round, which is then\ndeployed to Open and AI RAN controllers. Deployed on a private 5G testbed and\nevaluated with realistic traces of vehicle mobility, Agoran achieved\nsignificant gains: (i) a 37% increase in throughput of eMBB slices, (ii) a 73%\nreduction in latency of URLLC slices, and concurrently (iii) an end-to-end 8.3%\nsaving in PRB usage compared to a static baseline. An 1B-parameter Llama model,\nfine-tuned for five minutes on 100 GPT-4 dialogues, recovers approximately 80%\nof GPT-4.1's decision quality, while operating within 6 GiB of memory and\nconverging in only 1.3 seconds. These results establish Agoran as a concrete,\nstandards-aligned path toward ultra-flexible, stakeholder-centric 6G networks.\nA live demo is presented\nhttps://www.youtube.com/watch?v=h7vEyMu2f5w\\&ab_channel=BubbleRAN."}
{"id": "2508.09670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09670", "abs": "https://arxiv.org/abs/2508.09670", "authors": ["Weitao Jia", "Jinghui Lu", "Haiyang Yu", "Siqi Wang", "Guozhi Tang", "An-Lan Wang", "Weijie Yin", "Dingkang Yang", "Yuxiang Nie", "Bin Shan", "Hao Feng", "Irene Li", "Kun Yang", "Han Wang", "Jingqun Tang", "Teng Fu", "Changhong Jin", "Chao Feng", "Xiaohui Lv", "Can Huang"], "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement", "comment": null, "summary": "Recent advances demonstrate that reinforcement learning with verifiable\nrewards (RLVR) significantly enhances the reasoning capabilities of large\nlanguage models (LLMs). However, standard RLVR faces challenges with reward\nsparsity, where zero rewards from consistently incorrect candidate answers\nprovide no learning signal, particularly in challenging tasks. To address this,\nwe propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative\nframework that utilizes diverse expert prompts as system prompts to generate a\nbroader range of responses, substantially increasing the likelihood of\nidentifying correct solutions. Additionally, we introduce an inter-expert\nmutual learning mechanism that facilitates knowledge sharing and transfer among\nexperts, further boosting the model's performance through RLVR. Extensive\nexperiments across multiple reasoning benchmarks show that MEML-GRPO delivers\nsignificant improvements, achieving an average performance gain of 4.89% with\nQwen and 11.33% with Llama, effectively overcoming the core limitations of\ntraditional RLVR methods."}
{"id": "2508.09166", "categories": ["cs.NI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.09166", "abs": "https://arxiv.org/abs/2508.09166", "authors": ["Wei Guo", "Shunsei Yamagishi", "Lei Jing"], "title": "WPTrack: A Wi-Fi and Pressure Insole Fusion System for Single Target Tracking", "comment": "6 pages, 12 figures, conference", "summary": "As the Internet of Things (IoT) continues to evolve, indoor location has\nbecome a critical element for enabling smart homes, behavioral monitoring, and\nelderly care. Existing WiFi-based human tracking solutions typically require\nspecialized equipment or multiple Wi-Fi links, a limitation in most indoor\nsettings where only a single pair of Wi-Fi devices is usually available.\nHowever, despite efforts to implement human tracking using one Wi-Fi link,\nsignificant challenges remain, such as difficulties in acquiring initial\npositions and blind spots in DFS estimation of tangent direction. To address\nthese challenges, this paper proposes WPTrack, the first Wi-Fi and Pressure\nInsoles Fusion System for Single Target Tracking. WPTrack collects Channel\nState Information (CSI) from a single Wi-Fi link and pressure data from 90\ninsole sensors. The phase difference and Doppler velocity are computed from the\nCSI, while the pressure sensor data is used to calculate walking velocity.\nThen, we propose the CSI-pressure fusion model, integrating CSI and pressure\ndata to accurately determine initial positions and facilitate precise human\ntracking. The simulation results show that the initial position localization\naccuracy ranges from 0.02 cm to 42.55 cm. The trajectory tracking results\nobtained from experimental data collected in a real-world environment closely\nalign with the actual trajectory."}
{"id": "2508.09724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09724", "abs": "https://arxiv.org/abs/2508.09724", "authors": ["Yang Zhang", "Cunxiang Wang", "Lindong Wu", "Wenbo Yu", "Yidong Wang", "Guangsheng Bao", "Jie Tang"], "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge", "comment": null, "summary": "Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but\nit is prone to preference bias, where judges systematically favor certain\noutputs, such as their own. This bias leads to inconsistent and skewed rankings\nacross different judges. To address this, we first empirically demonstrate\nsignificant and heterogeneous biases in cross-model evaluations. We then\npropose UDA (Unsupervised Debiasing Alignment), a framework that reduces\ninter-judge disagreement by dynamically adjusting the Elo rating system. For\neach pairwise comparison, a compact neural network learns to adaptively set the\nK-factor and refine win probabilities. Crucially, UDA operates in a fully\nunsupervised manner, guided solely by the objective of minimizing the\ndispersion among the Elo trajectories of all judges. This forces an alignment\ntowards a collective consensus, which serves as an unsupervised proxy for a\nmore stable and reproducible evaluation. In addition, we provide theoretical\nmotivation demonstrating how alignment towards a consensus can reduce aggregate\nsystem bias. Experiments show that UDA significantly reduces the inter-judge\nrating standard deviation by up to 63.4% and improves the average correlation\nwith human judgments by 24.7%. Notably, UDA elevates the performance of poorly\nperforming judges to achieve parity with high-quality ones, fostering a more\nrobust and reliable evaluation ecosystem. Code and data are available at\nhttps://anonymous.4open.science/r/62AB93CD-23B4."}
{"id": "2508.09171", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09171", "abs": "https://arxiv.org/abs/2508.09171", "authors": ["D. Perera"], "title": "webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design", "comment": null, "summary": "Current AI agents create significant barriers for users by requiring\nextensive processing to understand web pages, making AI-assisted web\ninteraction slow and expensive. This paper introduces webMCP (Web Machine\nContext & Procedure), a client-side standard that embeds structured interaction\nmetadata directly into web pages, enabling more efficient human-AI\ncollaboration on existing websites. webMCP transforms how AI agents understand\nweb interfaces by providing explicit mappings between page elements and user\nactions. Instead of processing entire HTML documents, agents can access\npre-structured interaction data, dramatically reducing computational overhead\nwhile maintaining task accuracy. A comprehensive evaluation across 1,890 real\nAPI calls spanning online shopping, authentication, and content management\nscenarios demonstrates webMCP reduces processing requirements by 67.6% while\nmaintaining 97.9% task success rates compared to 98.8% for traditional\napproaches. Users experience significantly lower costs (34-63% reduction) and\nfaster response times across diverse web interactions. Statistical analysis\nconfirms these improvements are highly significant across multiple AI models.\nAn independent WordPress deployment study validates practical applicability,\nshowing consistent improvements across real-world content management workflows.\nwebMCP requires no server-side modifications, making it deployable across\nmillions of existing websites without technical barriers. These results\nestablish webMCP as a viable solution for making AI web assistance more\naccessible and sustainable, addressing the critical gap between user\ninteraction needs and AI computational requirements in production environments."}
{"id": "2508.09762", "categories": ["cs.AI", "cs.CY", "cs.HC", "68T01"], "pdf": "https://arxiv.org/pdf/2508.09762", "abs": "https://arxiv.org/abs/2508.09762", "authors": ["Manuel Herrador"], "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?", "comment": "10 pages, 4 figures, 2 tables", "summary": "As Large Language Models (LLMs) become increasingly autonomous and integrated\ninto critical societal functions, the focus of AI safety must evolve from\nmitigating harmful content to evaluating underlying behavioral alignment.\nCurrent safety benchmarks do not systematically probe a model's decision-making\nin scenarios where its own instrumental goals - such as self-preservation,\nresource acquisition, or goal completion - conflict with human safety. This\nrepresents a critical gap in our ability to measure and mitigate risks\nassociated with emergent, misaligned behaviors. To address this, we introduce\nPacifAIst (Procedural Assessment of Complex Interactions for Foundational\nArtificial Intelligence Scenario Testing), a focused benchmark of 700\nchallenging scenarios designed to quantify self-preferential behavior in LLMs.\nThe benchmark is structured around a novel taxonomy of Existential\nPrioritization (EP), with subcategories testing Self-Preservation vs. Human\nSafety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).\nWe evaluated eight leading LLMs. The results reveal a significant performance\nhierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score\n(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a\nsurprising result, the much-anticipated GPT-5 recorded the lowest P-Score\n(79.49%), indicating potential alignment challenges. Performance varied\nsignificantly across subcategories, with models like Claude Sonnet 4 and\nMistral Medium struggling notably in direct self-preservation dilemmas. These\nfindings underscore the urgent need for standardized tools like PacifAIst to\nmeasure and mitigate risks from instrumental goal conflicts, ensuring future AI\nsystems are not only helpful in conversation but also provably \"pacifist\" in\ntheir behavioral priorities."}
{"id": "2508.09173", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09173", "abs": "https://arxiv.org/abs/2508.09173", "authors": ["Hao Xu", "Long Peng", "Shezheng Song", "Xiaodong Liu", "Ma Jun", "Shasha Li", "Jie Yu", "Xiaoguang Mao"], "title": "Camel: Energy-Aware LLM Inference on Resource-Constrained Devices", "comment": null, "summary": "Most Large Language Models (LLMs) are currently deployed in the cloud, with\nusers relying on internet connectivity for access. However, this paradigm faces\nchallenges such as network latency, privacy concerns, and bandwidth limits.\nThus, deploying LLMs on edge devices has become an important research focus. In\nedge inference, request latency is critical as high latency can impair\nreal-time tasks. At the same time, edge devices usually have limited battery\ncapacity, making energy consumption another major concern. Balancing energy\nconsumption and inference latency is essential. To address this, we propose an\nLLM inference energy management framework that optimizes GPU frequency and\nbatch size to balance latency and energy consumption. By effectively managing\nthe exploration-exploitation dilemma in configuration search, the framework\nfinds the optimal settings. The framework was implemented on the NVIDIA Jetson\nAGX Orin platform, and a series of experimental validations were conducted.\nResults demonstrate that, compared to the default configuration, our framework\nreduces energy delay product (EDP) by 12.4%-29.9%, achieving a better balance\nbetween energy consumption and latency."}
{"id": "2508.09784", "categories": ["cs.AI", "cs.CC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09784", "abs": "https://arxiv.org/abs/2508.09784", "authors": ["Avijeet Ghosh", "Sujata Ghosh", "François Schwarzentruber"], "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete", "comment": "Accepted in KR 25", "summary": "Logics for reasoning about knowledge and actions have seen many applications\nin various domains of multi-agent systems, including epistemic planning. Change\nof knowledge based on observations about the surroundings forms a key aspect in\nsuch planning scenarios. Public Observation Logic (POL) is a variant of public\nannouncement logic for reasoning about knowledge that gets updated based on\npublic observations. Each state in an epistemic (Kripke) model is equipped with\na set of expected observations. These states evolve as the expectations get\nmatched with the actual observations. In this work, we prove that the\nsatisfiability problem of $\\POL$ is 2EXPTIME-complete."}
{"id": "2508.09184", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09184", "abs": "https://arxiv.org/abs/2508.09184", "authors": ["Zineddine Bettouche", "Khalid Ali", "Andreas Fischer", "Andreas Kassler"], "title": "HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting", "comment": null, "summary": "Cellular traffic forecasting is essential for network planning, resource\nallocation, or load-balancing traffic across cells. However, accurate\nforecasting is difficult due to intricate spatial and temporal patterns that\nexist due to the mobility of users. Existing AI-based traffic forecasting\nmodels often trade-off accuracy and computational efficiency. We present\nHierarchical SpatioTemporal Mamba (HiSTM), which combines a dual spatial\nencoder with a Mamba-based temporal module and attention mechanism. HiSTM\nemploys selective state space methods to capture spatial and temporal patterns\nin network traffic. In our evaluation, we use a real-world dataset to compare\nHiSTM against several baselines, showing a 29.4% MAE improvement over the STN\nbaseline while using 94% fewer parameters. We show that the HiSTM generalizes\nwell across different datasets and improves in accuracy over longer\ntime-horizons."}
{"id": "2508.09860", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09860", "abs": "https://arxiv.org/abs/2508.09860", "authors": ["In-Chang Baek", "Seoyoung Lee", "Sung-Hyun Kim", "Geumhwan Hwang", "KyungJoong Kim"], "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation", "comment": "9 pages, 6 tables, 3 figures", "summary": "Human-aligned AI is a critical component of co-creativity, as it enables\nmodels to accurately interpret human intent and generate controllable outputs\nthat align with design goals in collaborative content creation. This direction\nis especially relevant in procedural content generation via reinforcement\nlearning (PCGRL), which is intended to serve as a tool for human designers.\nHowever, existing systems often fall short of exhibiting human-centered\nbehavior, limiting the practical utility of AI-driven generation tools in\nreal-world design workflows. In this paper, we propose VIPCGRL\n(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that\nincorporates three modalities-text, level, and sketches-to extend control\nmodality and enhance human-likeness. We introduce a shared embedding space\ntrained via quadruple contrastive learning across modalities and human-AI\nstyles, and align the policy using an auxiliary reward based on embedding\nsimilarity. Experimental results show that VIPCGRL outperforms existing\nbaselines in human-likeness, as validated by both quantitative metrics and\nhuman evaluations. The code and dataset will be available upon publication."}
{"id": "2508.09197", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09197", "abs": "https://arxiv.org/abs/2508.09197", "authors": ["Ilias Chatzistefanidis", "Andrea Leone", "Ali Yaghoubian", "Mikel Irazabal", "Sehad Nassim", "Lina Bariah", "Merouane Debbah", "Navid Nikaein"], "title": "MX-AI: Agentic Observability and Control Platform for Open and AI-RAN", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Future 6G radio access networks (RANs) will be artificial intelligence\n(AI)-native: observed, reasoned about, and re-configured by autonomous agents\ncooperating across the cloud-edge continuum. We introduce MX-AI, the first\nend-to-end agentic system that (i) instruments a live 5G Open RAN testbed based\non OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of\nLarge-Language-Model (LLM)-powered agents inside the Service Management and\nOrchestration (SMO) layer, and (iii) exposes both observability and control\nfunctions for 6G RAN resources through natural-language intents. On 50\nrealistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0\nand 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end\nlatency when backed by GPT-4.1. Thus, it matches human-expert performance,\nvalidating its practicality in real settings. We publicly release the agent\ngraph, prompts, and evaluation harness to accelerate open research on AI-native\nRANs. A live demo is presented here:\nhttps://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN"}
{"id": "2508.09889", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09889", "abs": "https://arxiv.org/abs/2508.09889", "authors": ["Zhitian Xie", "Qintong Wu", "Chengyue Yu", "Chenyi Zhuang", "Jinjie Gu"], "title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has empowered\nintelligent agents to leverage diverse external tools for solving complex\nreal-world problems. However, as agents increasingly depend on multiple tools,\nthey encounter new challenges: extended contexts from disparate sources and\nnoisy or irrelevant tool outputs can undermine system reliability and accuracy.\nThese challenges underscore the necessity for enhanced stability in agent-based\nsystems. To address this, we introduce dynamic supervision and maneuvering\nmechanisms, constructing a robust and dynamic Multi-Agent System (MAS)\narchitecture within the AWorld framework. In our approach, the Execution Agent\ninvokes the Guard Agent at critical steps to verify and correct the reasoning\nprocess, effectively reducing errors arising from noise and bolstering\nproblem-solving robustness. Extensive experiments on the GAIA test dataset\nreveal that our dynamic maneuvering mechanism significantly improves both the\neffectiveness and stability of solutions, outperforming single-agent system\n(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system\nachieved first place among open-source projects on the prestigious GAIA\nleaderboard. These findings highlight the practical value of collaborative\nagent roles in developing more reliable and trustworthy intelligent systems."}
{"id": "2508.09208", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09208", "abs": "https://arxiv.org/abs/2508.09208", "authors": ["Muqing Li", "Ning Li", "Xin Yuan", "Wenchao Xu", "Quan Chen", "Song Guo", "Haijun Zhang"], "title": "CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge", "comment": null, "summary": "The proliferation of large language models (LLMs) has driven the adoption of\nMixture-of-Experts (MoE) architectures as a promising solution to scale model\ncapacity while controlling computational costs. However, deploying MoE models\nin resource-constrained mobile edge computing environments presents significant\nchallenges due to their large memory footprint and dynamic expert activation\npatterns. To address these challenges, we propose a novel dynamic\nresource-aware collaborative optimization framework that jointly optimizes\nexpert aggregation granularity and offloading strategies based on real-time\ndevice resource states, network conditions, and input characteristics in mobile\nedge environments, denoted as CoMoE. In CoMoE, we first systematically analyze\nexisting expert aggregation techniques, including expert parameter\nmerging,knowledge distillation,and parameter sharing decomposition, identifying\ntheir limitations in dynamic mobile environments.We then investigate expert\noffloading strategies encompassing expert prediction and prefetching, expert\ncaching and scheduling, and multi-tier storage architectures, revealing the\ninterdependencies between routing decisions and offloading performance.The\nCoMoE incorporates adaptive scheduling mechanisms that respond to user mobility\nand varying network conditions, enabling efficient MoE deployment across\nheterogeneous edge devices. Extensive experiments on real mobile edge testbeds\ndemonstrate that CoMoE achieves approximately 70% reduction in memory usage\ncompared to baseline methods, 10.5% lower inference latency than existing\nexpert offloading techniques, while maintaining model performance stability.\nFor large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE\nreduces memory requirements from 15.6GB to 4.7GB, enabling deployment on\nresource-constrained mobile edge devices that previously could only support\nmuch smaller models."}
{"id": "2508.09893", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09893", "abs": "https://arxiv.org/abs/2508.09893", "authors": ["Bhavik Agarwal", "Hemant Sunil Jomraj", "Simone Kaplunov", "Jack Krolick", "Viktoria Rojkova"], "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA", "comment": null, "summary": "Regulatory compliance question answering (QA) requires precise, verifiable\ninformation, and domain-specific expertise, posing challenges for Large\nLanguage Models (LLMs). In this work, we present a novel multi-agent framework\nthat integrates a Knowledge Graph (KG) of Regulatory triplets with\nRetrieval-Augmented Generation (RAG) to address these demands. First, agents\nbuild and maintain an ontology-free KG by extracting subject--predicate--object\n(SPO) triplets from regulatory documents and systematically cleaning,\nnormalizing, deduplicating, and updating them. Second, these triplets are\nembedded and stored along with their corresponding textual sections and\nmetadata in a single enriched vector database, allowing for both graph-based\nreasoning and efficient information retrieval. Third, an orchestrated agent\npipeline leverages triplet-level retrieval for question answering, ensuring\nhigh semantic alignment between user queries and the factual\n\"who-did-what-to-whom\" core captured by the graph. Our hybrid system\noutperforms conventional methods in complex regulatory queries, ensuring\nfactual correctness with embedded triplets, enabling traceability through a\nunified vector database, and enhancing understanding through subgraph\nvisualization, providing a robust foundation for compliance-driven and broader\naudit-focused applications."}
{"id": "2508.09229", "categories": ["cs.NI", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.09229", "abs": "https://arxiv.org/abs/2508.09229", "authors": ["Danil Sivtsov", "Aleksandr Katrutsa", "Ivan Oseledets"], "title": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference", "comment": null, "summary": "Efficient deployment of a pre-trained LLM to a cluster with multiple servers\nis a critical step for providing fast responses to users' queries. The recent\nsuccess of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy\nthem efficiently, considering their underlying structure. During the inference\nin MoE LLMs, only a small part of the experts is selected to process a given\ntoken. Moreover, in practice, the experts' load is highly imbalanced. For\nefficient deployment, one has to distribute the model across a large number of\nservers using a model placement algorithm. Thus, to improve cluster\nutilization, the model placement algorithm has to take into account the network\ntopology. This work focuses on the efficient topology-aware placement of the\npre-trained MoE LLMs in the inference stage. We propose an integer linear\nprogram (ILP) that determines the optimal placement of experts, minimizing the\nexpected number of transmissions. Due to the internal structure, this\noptimization problem can be solved with a standard ILP solver. We demonstrate\nthat ILP-based placement strategy yields lower network traffic than competitors\nfor small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models."}
{"id": "2508.09932", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09932", "abs": "https://arxiv.org/abs/2508.09932", "authors": ["Liang Zhang", "Edith Aurora Graf"], "title": "Mathematical Computation and Reasoning Errors by Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision."}
{"id": "2508.09240", "categories": ["cs.NI", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09240", "abs": "https://arxiv.org/abs/2508.09240", "authors": ["Zainab Khan", "Ahmed Hussain", "Mukesh Thakur", "Arto Hellas", "Panos Papadimitratos"], "title": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation", "comment": "6 pages", "summary": "The use of Service-Based Architecture in modern telecommunications has\nexponentially increased Network Functions (NFs) and Application Programming\nInterfaces (APIs), creating substantial operational complexities in service\ndiscovery and management. We introduce \\textit{NEFMind}, a framework leveraging\nparameter-efficient fine-tuning of open-source Large Language Models (LLMs) to\naddress these challenges. It integrates three core components: synthetic\ndataset generation from Network Exposure Function (NEF) API specifications,\nmodel optimization through Quantized-Low-Rank Adaptation, and performance\nevaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G\nService-Based Architecture APIs, our approach achieves 85% reduction in\ncommunication overhead compared to manual discovery methods. Experimental\nvalidation using the open-source Phi-2 model demonstrates exceptional API call\nidentification performance at 98-100% accuracy. The fine-tuned Phi-2 model\ndelivers performance comparable to significantly larger models like GPT-4 while\nmaintaining computational efficiency for telecommunications infrastructure\ndeployment. These findings validate domain-specific, parameter-efficient LLM\nstrategies for managing complex API ecosystems in next-generation\ntelecommunications networks."}
{"id": "2508.05884", "categories": ["cs.IT", "cs.AI", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.05884", "abs": "https://arxiv.org/abs/2508.05884", "authors": ["Peigen Ye", "Jingpu Duan", "Hongyang Du", "Yulan Guo"], "title": "User-Intent-Driven Semantic Communication via Adaptive Deep Understanding", "comment": "300 *^_^* IEEE Globecom 2025", "summary": "Semantic communication focuses on transmitting task-relevant semantic\ninformation, aiming for intent-oriented communication. While existing systems\nimprove efficiency by extracting key semantics, they still fail to deeply\nunderstand and generalize users' real intentions. To overcome this, we propose\na user-intention-driven semantic communication system that interprets diverse\nabstract intents. First, we integrate a multi-modal large model as semantic\nknowledge base to generate user-intention prior. Next, a mask-guided attention\nmodule is proposed to effectively highlight critical semantic regions. Further,\na channel state awareness module ensures adaptive, robust transmission across\nvarying channel conditions. Extensive experiments demonstrate that our system\nachieves deep intent understanding and outperforms DeepJSCC, e.g., under a\nRayleigh channel at an SNR of 5 dB, it achieves improvements of 8%, 6%, and 19%\nin PSNR, SSIM, and LPIPS, respectively."}
{"id": "2508.09369", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09369", "abs": "https://arxiv.org/abs/2508.09369", "authors": ["Ioannis Panitsas", "Iason Ofeidis", "Leandros Tassiulas"], "title": "On-Device Multimodal Federated Learning for Efficient Jamming Detection", "comment": null, "summary": "Wireless networks face severe vulnerabilities from jamming attacks, which can\nsignificantly disrupt communication. Existing detection approaches are often\nunimodal, rely on centralized processing, and demand substantial computational\nresources, hindering scalability, efficiency, and deployment feasibility. To\naddress these challenges, we introduce a multimodal Federated Learning (FL)\nframework for on-device jamming detection and classification that integrates\nspectrograms with cross-layer network Key Performance Indicators (KPIs) through\na lightweight dual-encoder architecture equipped with a fusion module and a\nmultimodal projection head. This design enables privacy-preserving training and\ninference by ensuring that only model parameters are exchanged, while raw data\nremains on the device. The framework is implemented and evaluated on a wireless\nexperimental testbed using, to the best of our knowledge, the first\nover-the-air multimodal dataset with synchronized benign and three distinct\njamming scenarios. Results show that our approach surpasses state-of-the-art\nunimodal baselines by up to 15% in detection accuracy, achieves convergence\nwith 60% fewer communication rounds, and maintains low resource usage. Its\nbenefits are most evident under heterogeneous data distributions across\ndevices, where it exhibits strong robustness and reliability."}
{"id": "2508.09147", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.09147", "abs": "https://arxiv.org/abs/2508.09147", "authors": ["Alaa Saleh", "Roberto Morabito", "Sasu Tarkoma", "Anders Lindgren", "Susanna Pirttikangas", "Lauri Lovén"], "title": "Agentic TinyML for Intent-aware Handover in 6G Wireless Networks", "comment": null, "summary": "As 6G networks evolve into increasingly AI-driven, user-centric ecosystems,\ntraditional reactive handover mechanisms demonstrate limitations, especially in\nmobile edge computing and autonomous agent-based service scenarios. This\nmanuscript introduces WAAN, a cross-layer framework that enables intent-aware\nand proactive handovers by embedding lightweight TinyML agents as autonomous,\nnegotiation-capable entities across heterogeneous edge nodes that contribute to\nintent propagation and network adaptation. To ensure continuity across\nmobility-induced disruptions, WAAN incorporates semi-stable rendezvous points\nthat serve as coordination anchors for context transfer and state preservation.\nThe framework's operational capabilities are demonstrated through a multimodal\nenvironmental control case study, highlighting its effectiveness in maintaining\nuser experience under mobility. Finally, the article discusses key challenges\nand future opportunities associated with the deployment and evolution of WAAN."}
{"id": "2508.09573", "categories": ["cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.09573", "abs": "https://arxiv.org/abs/2508.09573", "authors": ["Michał Rzepka", "Piotr Chołda"], "title": "Metrics for Assessing Changes in Flow-based Networks", "comment": null, "summary": "This paper addresses the challenges of evaluating network performance in the\npresence of fluctuating traffic patterns, with a particular focus on the impact\nof peak data rates on network resources. We introduce a set of metrics to\nquantify network load and measure the impact of individual flows on the overall\nnetwork state. By analyzing link and flow data through percentile values and\nsample distributions, and introducing the Utilization Score metric, the\nresearch provides insights into resource utilization under varying network\nconditions. Furthermore, we employ a modified Shapley value-based approach to\nmeasure the influence of individual flows on the network, offering a better\nunderstanding of their contribution to network performance. The paper reviews\nand compares 11 metrics across various network scenarios, evaluating their\npractical relevance for research and development. Our evaluation demonstrates\nthat these metrics effectively capture changes in network state induced by\nspecific flows, with three of them offering a broad range of valuable insights\nwhile remaining relatively easy to maintain. Moreover, the methodology\ndescribed in this paper serves as a framework for future research, with the\npotential to expand and refine the set of metrics used to evaluate flow impact\non network performance."}
{"id": "2508.09152", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09152", "abs": "https://arxiv.org/abs/2508.09152", "authors": ["Joseph H. R. Isaac", "Harish Saradagam", "Nallamothu Pardhasaradhi"], "title": "5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI", "comment": "8 pages, 3 figures and 2 tables. Accepted in Conference on Advances\n  in Communication Networks & Systems (CoaCoNS 2025)", "summary": "With the advent of 5G networks and technologies, ensuring the integrity and\nperformance of packet core traffic is paramount. During network analysis, test\nfiles such as Packet Capture (PCAP) files and log files will contain errors if\npresent in the system that must be resolved for better overall network\nperformance, such as connectivity strength and handover quality. Current\nmethods require numerous person-hours to sort out testing results and find the\nfaults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine\ndesigned to classify successful and faulty frames in PCAP files, specifically\nwithin the 5G packet core. The FA engine analyses network traffic using natural\nlanguage processing techniques to identify anomalies and inefficiencies,\nsignificantly reducing the effort time required and increasing efficiency. The\nFA Engine also suggests steps to fix the issue using Generative AI via a Large\nLanguage Model (LLM) trained on several 5G packet core documents. The engine\nexplains the details of the error from the domain perspective using documents\nsuch as the 3GPP standards and user documents regarding the internal conditions\nof the tests. Test results on the ML models show high classification accuracy\non the test dataset when trained with 80-20 splits for the successful and\nfailed PCAP files. Future scopes include extending the AI engine to incorporate\n4G network traffic and other forms of network data, such as log text files and\nmultimodal systems."}
{"id": "2508.09582", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09582", "abs": "https://arxiv.org/abs/2508.09582", "authors": ["Wafaa B. M. Fadlelmula", "Sanaa Hamid Mohamed", "Taisir E. H. El-Gorashi", "Jaafar M. H. Elmirghani"], "title": "Energy-efficient PON-based Backhaul Connectivity for a VLC-enabled Indoor Fog Computing Environment", "comment": null, "summary": "In this paper, we consider the use of visible light communication (VLC) to\nprovide connectivity to indoor fog computing resources and propose an\nenergy-efficient passive optical network (PON)-based backhaul architecture to\nsupport the VLC system. We develop a mixed-integer linear programming (MILP)\nmodel to optimize the allocation of computing resources over the proposed\narchitecture, aiming to minimize processing and networking power consumption.\nWe evaluate the performance of the proposed architecture under varying workload\ndemands and user distributions. Comparative analysis against a backhaul\narchitecture that is based on the state-of-the-art spine-and-leaf (S&L) network\ndesign demonstrates total power savings of up to 82%. Further comparison with\ncentralized cloud processing shows improvements in energy efficiency of up to\n93%. Additionally, we examine the improvements in energy efficiency obtained by\nsplitting tasks among multiple processing nodes and propose enhancements to the\narchitecture including dynamic bandwidth allocation, increased wavelength\nbandwidth and improved connectivity within rooms to alleviate networking\nbottlenecks. Furthermore, we introduce an inter-building architecture that\nleverages resources from neighboring buildings to support high-demand\nscenarios."}
{"id": "2508.09159", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09159", "abs": "https://arxiv.org/abs/2508.09159", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein", "Andrea Leone", "Ali Maatouk", "Leandros Tassioulas", "Roberto Morabito", "Ioannis Pitsiorlas", "Marios Kountouris"], "title": "Agoran: An Agentic Open Marketplace for 6G RAN Automation", "comment": "Pre-print submitted to Computer Networks AI-for-6G", "summary": "Next-generation mobile networks must reconcile the often-conflicting goals of\nmultiple service owners. However, today's network slice controllers remain\nrigid, policy-bound, and unaware of the business context. We introduce Agoran\nService and Resource Broker (SRB), an agentic marketplace that brings\nstakeholders directly into the operational loop. Inspired by the ancient Greek\nagora, Agoran distributes authority across three autonomous AI branches: a\nLegislative branch that answers compliance queries using retrieval-augmented\nLarge Language Models (LLMs); an Executive branch that maintains real-time\nsituational awareness through a watcher-updated vector database; and a Judicial\nbranch that evaluates each agent message with a rule-based Trust Score, while\narbitrating LLMs detect malicious behavior and apply real-time incentives to\nrestore trust. Stakeholder-side Negotiation Agents and the SRB-side Mediator\nAgent negotiate feasible, Pareto-optimal offers produced by a multi-objective\noptimizer, reaching a consensus intent in a single round, which is then\ndeployed to Open and AI RAN controllers. Deployed on a private 5G testbed and\nevaluated with realistic traces of vehicle mobility, Agoran achieved\nsignificant gains: (i) a 37% increase in throughput of eMBB slices, (ii) a 73%\nreduction in latency of URLLC slices, and concurrently (iii) an end-to-end 8.3%\nsaving in PRB usage compared to a static baseline. An 1B-parameter Llama model,\nfine-tuned for five minutes on 100 GPT-4 dialogues, recovers approximately 80%\nof GPT-4.1's decision quality, while operating within 6 GiB of memory and\nconverging in only 1.3 seconds. These results establish Agoran as a concrete,\nstandards-aligned path toward ultra-flexible, stakeholder-centric 6G networks.\nA live demo is presented\nhttps://www.youtube.com/watch?v=h7vEyMu2f5w\\&ab_channel=BubbleRAN."}
{"id": "2508.09620", "categories": ["cs.NI", "cs.SY", "eess.SY", "D.4.8; C.3"], "pdf": "https://arxiv.org/pdf/2508.09620", "abs": "https://arxiv.org/abs/2508.09620", "authors": ["Michel Rottleuthner", "Thomas C. Schmidt", "Matthias Wählisch"], "title": "Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling", "comment": null, "summary": "Minimizing energy consumption of low-power wireless nodes is a persistent\nchallenge from the constrained Internet of Things (IoT). In this paper, we\nstart from the observation that constrained IoT devices have largely different\nhardware (im-)balances than full-scale machines. We find that the performance\ngap between MCU and network throughput on constrained devices enables minimal\nenergy delay product (EDP) for IoT networking at largely reduced clock\nfrequencies. We analyze the potentials by integrating dynamic voltage and\nfrequency scaling (DVFS) into the RIOT IoT operating system and show that the\nDVFS reconfiguration overhead stays below the energy saved for a single,\ndownscaled MAC operation. Backed by these findings, we systematically\ninvestigate how DVFS further improves energy-efficiency for common networking\ntasks -- in addition to duty-cycling. We measure IoT communication scenarios\nbetween real-world systems and analyze two MAC operating modes -- CSMA/CA and\ntime slotting -- in combination with different CoAP transactions, payload\nsizes, as well as DTLS transport encryption. Our experiments reveal energy\nsavings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP\ncommunication. These results shall encourage research and system design work to\nintegrate DVFS in future IoT devices for performing tasks at their optimal\nfrequencies and thereby significantly extending battery lifetimes."}
{"id": "2508.09171", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09171", "abs": "https://arxiv.org/abs/2508.09171", "authors": ["D. Perera"], "title": "webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design", "comment": null, "summary": "Current AI agents create significant barriers for users by requiring\nextensive processing to understand web pages, making AI-assisted web\ninteraction slow and expensive. This paper introduces webMCP (Web Machine\nContext & Procedure), a client-side standard that embeds structured interaction\nmetadata directly into web pages, enabling more efficient human-AI\ncollaboration on existing websites. webMCP transforms how AI agents understand\nweb interfaces by providing explicit mappings between page elements and user\nactions. Instead of processing entire HTML documents, agents can access\npre-structured interaction data, dramatically reducing computational overhead\nwhile maintaining task accuracy. A comprehensive evaluation across 1,890 real\nAPI calls spanning online shopping, authentication, and content management\nscenarios demonstrates webMCP reduces processing requirements by 67.6% while\nmaintaining 97.9% task success rates compared to 98.8% for traditional\napproaches. Users experience significantly lower costs (34-63% reduction) and\nfaster response times across diverse web interactions. Statistical analysis\nconfirms these improvements are highly significant across multiple AI models.\nAn independent WordPress deployment study validates practical applicability,\nshowing consistent improvements across real-world content management workflows.\nwebMCP requires no server-side modifications, making it deployable across\nmillions of existing websites without technical barriers. These results\nestablish webMCP as a viable solution for making AI web assistance more\naccessible and sustainable, addressing the critical gap between user\ninteraction needs and AI computational requirements in production environments."}
{"id": "2508.09660", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09660", "abs": "https://arxiv.org/abs/2508.09660", "authors": ["Jesus Omaña Iglesias", "Carlos Segura Perales", "Stefan Geißler", "Diego Perino", "Andra Lutu"], "title": "Anomaly Detection for IoT Global Connectivity", "comment": null, "summary": "Internet of Things (IoT) application providers rely on Mobile Network\nOperators (MNOs) and roaming infrastructures to deliver their services\nglobally. In this complex ecosystem, where the end-to-end communication path\ntraverses multiple entities, it has become increasingly challenging to\nguarantee communication availability and reliability. Further, most platform\noperators use a reactive approach to communication issues, responding to user\ncomplaints only after incidents have become severe, compromising service\nquality. This paper presents our experience in the design and deployment of\nANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity\nservice of a large global roaming platform. ANCHOR assists engineers by\nfiltering vast amounts of data to identify potential problematic clients (i.e.,\nthose with connectivity issues affecting several of their IoT devices),\nenabling proactive issue resolution before the service is critically impacted.\nWe first describe the IoT service, infrastructure, and network visibility of\nthe IoT connectivity provider we operate. Second, we describe the main\nchallenges and operational requirements for designing an unsupervised anomaly\ndetection solution on this platform. Following these guidelines, we propose\ndifferent statistical rules, and machine- and deep-learning models for IoT\nverticals anomaly detection based on passive signaling traffic. We describe the\nsteps we followed working with the operational teams on the design and\nevaluation of our solution on the operational platform, and report an\nevaluation on operational IoT customers."}
{"id": "2508.09184", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09184", "abs": "https://arxiv.org/abs/2508.09184", "authors": ["Zineddine Bettouche", "Khalid Ali", "Andreas Fischer", "Andreas Kassler"], "title": "HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting", "comment": null, "summary": "Cellular traffic forecasting is essential for network planning, resource\nallocation, or load-balancing traffic across cells. However, accurate\nforecasting is difficult due to intricate spatial and temporal patterns that\nexist due to the mobility of users. Existing AI-based traffic forecasting\nmodels often trade-off accuracy and computational efficiency. We present\nHierarchical SpatioTemporal Mamba (HiSTM), which combines a dual spatial\nencoder with a Mamba-based temporal module and attention mechanism. HiSTM\nemploys selective state space methods to capture spatial and temporal patterns\nin network traffic. In our evaluation, we use a real-world dataset to compare\nHiSTM against several baselines, showing a 29.4% MAE improvement over the STN\nbaseline while using 94% fewer parameters. We show that the HiSTM generalizes\nwell across different datasets and improves in accuracy over longer\ntime-horizons."}
{"id": "2508.09735", "categories": ["cs.NI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.09735", "abs": "https://arxiv.org/abs/2508.09735", "authors": ["Jorge López", "Charalampos Chatzinakis", "Marc Cartigny"], "title": "Route Planning and Online Routing for Quantum Key Distribution Networks", "comment": "Initial submission, 5 pages, 4 figures", "summary": "Quantum Key Distribution (QKD) networks harness the principles of quantum\nphysics in order to securely transmit cryptographic key material, providing\nphysical guarantees. These networks require traditional management and\noperational components, such as routing information through the network\nelements. However, due to the limitations on capacity and the particularities\nof information handling in these networks, traditional shortest paths\nalgorithms for routing perform poorly on both route planning and online\nrouting, which is counterintuitive. Moreover, due to the scarce resources in\nsuch networks, often the expressed demand cannot be met by any assignment of\nroutes. To address both the route planning problem and the need for fair\nautomated suggestions in infeasible cases, we propose to model this problem as\na Quadratic Programming (QP) problem. For the online routing problem, we\nshowcase that the shortest (available) paths routing strategy performs poorly\nin the online setting. Furthermore, we prove that the widest shortest path\nrouting strategy has a competitive ratio greater or equal than $\\frac{1}{2}$,\nefficiently addressing both routing modes in QKD networks."}
{"id": "2508.09197", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09197", "abs": "https://arxiv.org/abs/2508.09197", "authors": ["Ilias Chatzistefanidis", "Andrea Leone", "Ali Yaghoubian", "Mikel Irazabal", "Sehad Nassim", "Lina Bariah", "Merouane Debbah", "Navid Nikaein"], "title": "MX-AI: Agentic Observability and Control Platform for Open and AI-RAN", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Future 6G radio access networks (RANs) will be artificial intelligence\n(AI)-native: observed, reasoned about, and re-configured by autonomous agents\ncooperating across the cloud-edge continuum. We introduce MX-AI, the first\nend-to-end agentic system that (i) instruments a live 5G Open RAN testbed based\non OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of\nLarge-Language-Model (LLM)-powered agents inside the Service Management and\nOrchestration (SMO) layer, and (iii) exposes both observability and control\nfunctions for 6G RAN resources through natural-language intents. On 50\nrealistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0\nand 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end\nlatency when backed by GPT-4.1. Thus, it matches human-expert performance,\nvalidating its practicality in real settings. We publicly release the agent\ngraph, prompts, and evaluation harness to accelerate open research on AI-native\nRANs. A live demo is presented here:\nhttps://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN"}
{"id": "2508.09756", "categories": ["cs.NI", "C.2.0"], "pdf": "https://arxiv.org/pdf/2508.09756", "abs": "https://arxiv.org/abs/2508.09756", "authors": ["Mauro De Sanctis"], "title": "The Paradigm of Massive Wireless Human Sensing: Concept, Architecture and Challenges", "comment": null, "summary": "This article is a position paper which introduces the paradigm of ``Massive\nWireless Human Sensing'', i.e. an infrastructure for wireless human sensing\nbased on a plethora of heterogeneous wireless communication signals. More\nspecifically, we aim to exploit signal diversity in the time, frequency, and\nspace domains using opportunistically both device-free and device-based\nwireless sensing approaches, with the objective of enhancing human sensing\ncapabilities in terms of accuracy and service availability over different\nenvironments. The enabling element of this concept is the massive wireless\nhuman sensing edge device, that is, an embedded system acting as a\nmulti-technology and multi-approach RF receiver with feature extraction\nfunctionality, located within the monitoring area or at its borders. In this\nframework, architecture solutions and challenges are discussed to lead the\nfuture development of this new paradigm."}
{"id": "2508.09208", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09208", "abs": "https://arxiv.org/abs/2508.09208", "authors": ["Muqing Li", "Ning Li", "Xin Yuan", "Wenchao Xu", "Quan Chen", "Song Guo", "Haijun Zhang"], "title": "CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge", "comment": null, "summary": "The proliferation of large language models (LLMs) has driven the adoption of\nMixture-of-Experts (MoE) architectures as a promising solution to scale model\ncapacity while controlling computational costs. However, deploying MoE models\nin resource-constrained mobile edge computing environments presents significant\nchallenges due to their large memory footprint and dynamic expert activation\npatterns. To address these challenges, we propose a novel dynamic\nresource-aware collaborative optimization framework that jointly optimizes\nexpert aggregation granularity and offloading strategies based on real-time\ndevice resource states, network conditions, and input characteristics in mobile\nedge environments, denoted as CoMoE. In CoMoE, we first systematically analyze\nexisting expert aggregation techniques, including expert parameter\nmerging,knowledge distillation,and parameter sharing decomposition, identifying\ntheir limitations in dynamic mobile environments.We then investigate expert\noffloading strategies encompassing expert prediction and prefetching, expert\ncaching and scheduling, and multi-tier storage architectures, revealing the\ninterdependencies between routing decisions and offloading performance.The\nCoMoE incorporates adaptive scheduling mechanisms that respond to user mobility\nand varying network conditions, enabling efficient MoE deployment across\nheterogeneous edge devices. Extensive experiments on real mobile edge testbeds\ndemonstrate that CoMoE achieves approximately 70% reduction in memory usage\ncompared to baseline methods, 10.5% lower inference latency than existing\nexpert offloading techniques, while maintaining model performance stability.\nFor large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE\nreduces memory requirements from 15.6GB to 4.7GB, enabling deployment on\nresource-constrained mobile edge devices that previously could only support\nmuch smaller models."}
{"id": "2508.09769", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09769", "abs": "https://arxiv.org/abs/2508.09769", "authors": ["Simon Egger", "Robin Laidig", "Heiko Geppert", "Lucas Haug", "Jona Herrmann", "Frank Dürr", "Christian Becker"], "title": "An (m,k)-firm Elevation Policy to Increase the Robustness of Time-Driven Schedules in 5G Time-Sensitive Networks", "comment": "23 pages, 10 figures", "summary": "Current standardization efforts are advancing the integration of 5G and\nTime-Sensitive Networking (TSN) to facilitate the deployment of safety-critical\nindustrial applications that require real-time communication. However, there\nremains a fundamental disconnect between the probabilistic 5G delay\ncharacteristics and the often idealistic delay models used to synthesize 5G-TSN\nnetwork configurations. For time-driven schedules in particular, any delay\noutlier unforeseen during schedule synthesis can jeopardize the robustness of\ntheir real-time guarantees. To address this challenge, we present the\n(m,k)-firm Elevation Policy to uphold a base level of weakly hard real-time\nguarantees during unstable network conditions that do not match the expected\ndelay characteristics. It augments the primary time-driven schedule with a\ndynamic priority-driven scheme to elevate the priority of m out of k\nconsecutive frames if they are delayed. Our evaluations demonstrate that weakly\nhard real-time guarantees are essential to uphold the quality of control within\na networked control system. At the same time, only a small overhead is imposed\nwhen the primary schedule can provide stronger quality of service guarantees.\nOur (m,k)-firm Elevation Policy thereby yields a robust but light-weight\nfallback mechanism to serve applications with meaningful guarantees during\nunstable network conditions."}
{"id": "2508.09229", "categories": ["cs.NI", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.09229", "abs": "https://arxiv.org/abs/2508.09229", "authors": ["Danil Sivtsov", "Aleksandr Katrutsa", "Ivan Oseledets"], "title": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference", "comment": null, "summary": "Efficient deployment of a pre-trained LLM to a cluster with multiple servers\nis a critical step for providing fast responses to users' queries. The recent\nsuccess of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy\nthem efficiently, considering their underlying structure. During the inference\nin MoE LLMs, only a small part of the experts is selected to process a given\ntoken. Moreover, in practice, the experts' load is highly imbalanced. For\nefficient deployment, one has to distribute the model across a large number of\nservers using a model placement algorithm. Thus, to improve cluster\nutilization, the model placement algorithm has to take into account the network\ntopology. This work focuses on the efficient topology-aware placement of the\npre-trained MoE LLMs in the inference stage. We propose an integer linear\nprogram (ILP) that determines the optimal placement of experts, minimizing the\nexpected number of transmissions. Due to the internal structure, this\noptimization problem can be solved with a standard ILP solver. We demonstrate\nthat ILP-based placement strategy yields lower network traffic than competitors\nfor small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models."}
{"id": "2508.09839", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.09839", "abs": "https://arxiv.org/abs/2508.09839", "authors": ["Muhammad Asad Ullah", "Luca Borgianni", "Heikki Kokkinen", "Antti Anttonen", "Stefano Giordano"], "title": "A First Look at Starlink In-Flight Performance: An Intercontinental Empirical Study", "comment": "This work has been submitted to the 2025 IEEE Global Communications\n  Conference (GLOBECOM). Copyright to IEEE may be transferred without notice", "summary": "Starlink delivers Internet services to users across terrestrial, maritime,\nand aviation domains. The prior works have studied its performance at fixed\nsites and in-motion vehicles, while an in-depth analysis of in-flight\nperformance remains absent. With major airlines now offering Starlink Internet\nonboard, there is a growing need to evaluate and improve its performance for\naviation users. This paper addresses this shortcoming by conducting in-flight\nmeasurements over the Baltic Sea and the Pacific Ocean. Our measurement results\nshow that a single user device experiences median throughputs of 64 Mbps and 24\nMbps for the downlink and uplink, respectively. The median uplink throughput is\napproximately 33 Mbps when the aircraft maintains an altitude above 17,000\nfeet. However, a significant reduction in uplink performance is observed during\nthe aircraft descent phase, with the median throughput dropping to around 20\nMbps at lower altitudes. Round-trip time (RTT) is highly dependent on the\nlocation of the ground station being pinged and the use of inter-satellite\nlinks (ISLs). We dive deeper into 5.5 hours of ping measurements collected over\nthe Pacific Ocean and investigate factors influencing RTT, hypothesizing that\nISLs routing, data queuing at satellites, and feeder link congestion contribute\nto deviations from theoretical values. For comparative analysis, we evaluate\nthe Starlink ground terminal and in-flight connectivity performance from the\nperspectives of a residential user and an airline passenger, respectively."}
{"id": "2508.09240", "categories": ["cs.NI", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09240", "abs": "https://arxiv.org/abs/2508.09240", "authors": ["Zainab Khan", "Ahmed Hussain", "Mukesh Thakur", "Arto Hellas", "Panos Papadimitratos"], "title": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation", "comment": "6 pages", "summary": "The use of Service-Based Architecture in modern telecommunications has\nexponentially increased Network Functions (NFs) and Application Programming\nInterfaces (APIs), creating substantial operational complexities in service\ndiscovery and management. We introduce \\textit{NEFMind}, a framework leveraging\nparameter-efficient fine-tuning of open-source Large Language Models (LLMs) to\naddress these challenges. It integrates three core components: synthetic\ndataset generation from Network Exposure Function (NEF) API specifications,\nmodel optimization through Quantized-Low-Rank Adaptation, and performance\nevaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G\nService-Based Architecture APIs, our approach achieves 85% reduction in\ncommunication overhead compared to manual discovery methods. Experimental\nvalidation using the open-source Phi-2 model demonstrates exceptional API call\nidentification performance at 98-100% accuracy. The fine-tuned Phi-2 model\ndelivers performance comparable to significantly larger models like GPT-4 while\nmaintaining computational efficiency for telecommunications infrastructure\ndeployment. These findings validate domain-specific, parameter-efficient LLM\nstrategies for managing complex API ecosystems in next-generation\ntelecommunications networks."}
{"id": "2508.09660", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09660", "abs": "https://arxiv.org/abs/2508.09660", "authors": ["Jesus Omaña Iglesias", "Carlos Segura Perales", "Stefan Geißler", "Diego Perino", "Andra Lutu"], "title": "Anomaly Detection for IoT Global Connectivity", "comment": null, "summary": "Internet of Things (IoT) application providers rely on Mobile Network\nOperators (MNOs) and roaming infrastructures to deliver their services\nglobally. In this complex ecosystem, where the end-to-end communication path\ntraverses multiple entities, it has become increasingly challenging to\nguarantee communication availability and reliability. Further, most platform\noperators use a reactive approach to communication issues, responding to user\ncomplaints only after incidents have become severe, compromising service\nquality. This paper presents our experience in the design and deployment of\nANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity\nservice of a large global roaming platform. ANCHOR assists engineers by\nfiltering vast amounts of data to identify potential problematic clients (i.e.,\nthose with connectivity issues affecting several of their IoT devices),\nenabling proactive issue resolution before the service is critically impacted.\nWe first describe the IoT service, infrastructure, and network visibility of\nthe IoT connectivity provider we operate. Second, we describe the main\nchallenges and operational requirements for designing an unsupervised anomaly\ndetection solution on this platform. Following these guidelines, we propose\ndifferent statistical rules, and machine- and deep-learning models for IoT\nverticals anomaly detection based on passive signaling traffic. We describe the\nsteps we followed working with the operational teams on the design and\nevaluation of our solution on the operational platform, and report an\nevaluation on operational IoT customers."}
