<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 12]
- [cs.AI](#cs.AI) [Total: 29]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Probabilistic Fair Ordering of Events](https://arxiv.org/abs/2602.09148)
*Muhammad Haseeb,Jinkun Geng,Aurojit Panda,Radhika Mittal,Nirav Atre,Srinivas Narayana,Anirudh Sivaraman*

Main category: cs.NI

TL;DR: Tommy是一个使用统计时钟同步误差模型来概率性比较噪声时间戳的排序器，通过社会选择理论的排名方法处理不可传递比较，实现比Spanner TrueTime基线更好的公平排序。


<details>
  <summary>Details</summary>
Motivation: 许多应用需要公平排序（先发生的事件应先处理），但实践中时钟同步不完美，短时间内不同客户端生成的事件时间戳无法可靠排序。与其消除同步误差，不如接受它并建立概率公平的排序过程。

Method: Tommy使用每个时钟同步误差的统计模型来概率性比较噪声时间戳。由于概率比较器不可传递，将排序问题映射到社会选择理论的经典排名问题，使用有原则的机制处理不可传递比较，生成事件的部分顺序。

Result: Tommy实现了显著优于基于Spanner TrueTime基线方法的公平性。

Conclusion: 通过接受时钟同步误差并使用统计模型结合社会选择理论方法，可以构建概率公平的排序系统，比传统方法提供更好的公平性保证。

Abstract: A growing class of applications depends on fair ordering, where events that occur earlier should be processed before later ones. Providing such guarantees is difficult in practice because clock synchronization is inherently imperfect: events generated at different clients within a short time window may carry timestamps that cannot be reliably ordered. Rather than attempting to eliminate synchronization error, we embrace it and establish a probabilistically fair sequencing process. Tommy is a sequencer that uses a statistical model of per-clock synchronization error to compare noisy timestamps probabilistically. Although this enables ordering of two events, the probabilistic comparator is intransitive, making global ordering non-trivial. We address this challenge by mapping the sequencing problem to a classical ranking problem from social choice theory, which offers principled mechanisms for reasoning with intransitive comparisons. Using this formulation, Tommy produces a partial order of events, achieving significantly better fairness than a Spanner TrueTime-based baseline approach.

</details>


### [2] [Harvest: Adaptive Photonic Switching Schedules for Collective Communication in Scale-up Domains](https://arxiv.org/abs/2602.09188)
*Mahir Rahman,Samuel Joseph,Nihar Kodkani,Behnaz Arzani,Vamsi Addanki*

Main category: cs.NI

TL;DR: Harvest：一种为光子互连合成拓扑重配置调度的系统方法，通过动态规划平衡重配置开销与通信延迟，显著减少集体通信完成时间


<details>
  <summary>Details</summary>
Motivation: 硅光子芯片间互连具有带宽和能效优势，但其电路交换特性带来基本问题：何时以及如何重新配置互连以实现这些优势？直接光路径可减少拥塞和传播延迟，但每次重配置都有不可忽略的开销，使得每步重配置不切实际。

Method: 提出Harvest方法，将合成问题转化为动态规划，包含底层拓扑优化子问题。该方法适用于任意集体通信算法，并利用递归加倍算法的结构特性合成最优重配置调度，无需优化器。通过参数化重配置延迟，适应不同光子技术。

Result: 通过数据包级和流级评估，以及在商用GPU上的硬件仿真，显示Harvest合成的调度相比静态互连和每步重配置基线，显著减少了多种集体算法的集体完成时间。

Conclusion: Harvest为光子互连提供了一种系统化的拓扑重配置调度合成方法，通过平衡重配置开销与通信性能，在实际硬件上实现了显著的集体通信加速。

Abstract: As chip-to-chip silicon photonics gain traction for their bandwidth and energy efficiency, their circuit-switched nature raises a fundamental question for collective communication: when and how should the interconnect be reconfigured to realize these benefits? Establishing direct optical paths can reduce congestion and propagation delay, but each reconfiguration incurs non-negligible overhead, making naive per-step reconfiguration impractical.
  We present Harvest, a systematic approach for synthesizing topology reconfiguration schedules that minimize collective completion time in photonic interconnects. Given a collective communication algorithm and its fixed communication schedule, Harvest determines how the interconnect should evolve over the course of the collective, explicitly balancing reconfiguration delay against congestion and propagation delay. We reduce the synthesis problem into a dynamic program with an underlying topology optimization subproblem and show that the approach applies to arbitrary collective communication algorithms. Furthermore, we exploit the algorithmic structure of a well-known AllReduce algorithm (Recursive Doubling) to synthesize optimal reconfiguration schedules without using any optimizers. By parameterizing the formulation using reconfiguration delay, Harvest naturally adapts to various photonic technologies. Using packet-level and flow-level evaluations, as well as hardware emulation on commercial GPUs, we show that the schedules synthesized by Harvest significantly reduce collective completion time across multiple collective algorithms compared to static interconnects and reconfigure-every-step baselines.

</details>


### [3] [XLB: A High Performance Layer-7 Load Balancer for Microservices using eBPF-based In-kernel Interposition](https://arxiv.org/abs/2602.09473)
*Yuejie Wang,Chenchen Shou,Jiaxu Qian,Guyue Liu*

Main category: cs.NI

TL;DR: XLB是一种基于eBPF的内核级L7负载均衡器架构，通过在套接字层实现负载均衡逻辑，相比传统sidecar方案显著提升了性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 微服务架构对负载均衡器提出了更高性能和更强隔离性的要求，而传统的sidecar负载均衡器无法满足这些需求，导致显著的性能下降。

Method: 将L7负载均衡器重塑为内核级套接字层拦截架构，利用eBPF在内核中实现核心负载均衡逻辑，通过新颖的套接字层重定向和嵌套eBPF映射设计解决连接管理和状态维护挑战。

Result: 相比广泛使用的微服务负载均衡器（Istio和Cilium），在50个微服务实例的场景下，XLB实现了高达1.5倍的吞吐量提升和60%的端到端延迟降低。

Conclusion: XLB通过消除调度、通信和数据移动的额外开销，提供了一个更轻量、可扩展和高效的L7负载均衡器架构，能够满足现代微服务架构的性能和隔离性要求。

Abstract: L7 load balancers are a fundamental building block in microservices as they enable fine-grained traffic distribution. Compared to monolithic applications, microservices demand higher performance and stricter isolation from load balancers. This is due to the increased number of instances, longer service chains, and the necessity for co-location with services on the same host. Traditional sidecar-based load balancers are ill-equipped to meet these demands, often resulting in significant performance degradation.
  In this work, we present XLB, a novel architecture that reshapes L7 load balancers as in-kernel interposition operating on the socket layer. We leverage eBPF to implement the core load balancing logic in the kernel, and address the connection management and state maintenance challenges through novel socket layer redirection and nested eBPF maps designs. XLB eliminates the extra overhead of scheduling, communication, and data movement, resulting in a more lightweight, scalable, and efficient L7 load balancer architecture. Compared to the widely used microservices load balancers (Istio and Cilium), over 50 microservice instances, XLB achieves up to 1.5x higher throughput and 60% lower end-to-end latency.

</details>


### [4] [QoS Identifier and Slice Mapping in 5G and Non-Terrestrial Network Interconnected Systems](https://arxiv.org/abs/2602.09493)
*Yuma Abe,Mariko Sekiguchi,Amane Miura*

Main category: cs.NI

TL;DR: 提出NTN QoS标识符(NQI)和切片分组框架，优化5G流量在非地面网络中的服务质量管理和资源分配


<details>
  <summary>Details</summary>
Motivation: 现有5G QoS标识符(5QI)无法充分捕捉NTN环境中的多样化延迟、容量和可靠性需求，特别是当NTN用作回传时。此外，当大量5G流量出现在NTN系统中时，难以管理单个流量流并进行高效的资源分配和路由。

Method: 提出优化框架，引入NTN QoS标识符(NQI)，将具有相似需求的5G流量分组到NTN切片中。框架包括：5QI到NQI的映射、NTN流量到NTN切片的映射、以及切片级的流量和路由优化。

Result: 通过数值模拟比较多种映射方案，分析它们对整体网络性能的影响。该框架能够实现对大量5G流量的统一资源控制和路由管理。

Conclusion: 提出的NQI和切片分组框架有效解决了NTN环境中5G流量的QoS管理挑战，通过统一资源控制和路由优化提升了网络性能。

Abstract: The interconnection of 5G and non-terrestrial networks (NTNs) has been actively studied to expand connectivity beyond conventional terrestrial infrastructure. In the 3GPP standardization of 5G systems, the 5G Quality of Service (QoS) Identifier (5QI) is defined to characterize the QoS requirements of different traffic requirements. However, it falls short in capturing the diverse latency, capacity, and reliability profiles of NTN environments, particularly when NTNs are used as backhaul. Furthermore, it is difficult to manage individual traffic flows and perform efficient resource allocation and routing when a large number of 5G traffic flows are present in NTN systems. To address these challenges, we propose an optimization framework that enhances QoS handling by introducing an NTN QoS Identifier (NQI) and grouping 5G traffic into NTN slices based on similar requirements. This enables unified resource control and routing for a large number of 5G flows in NTN systems. In this paper, we present the detailed procedure of the proposed framework, which consists of 5QI to NQI mapping, NTN traffic to NTN slice mapping, and slice-level flow and routing optimization. We evaluate the framework by comparing multiple mapping schemes through numerical simulations and analyze their impact on overall network performance.

</details>


### [5] [ISO FastLane: Faster ISO 11783 with Dual Stack Approach as a Short Term Solution](https://arxiv.org/abs/2602.09633)
*Timo Oksanen*

Main category: cs.NI

TL;DR: ISO FastLane：一种无需网关的双栈方案，将点对点ISOBUS流量路由到以太网，同时保持广播消息在现有CAN总线上，显著提升ISOBUS性能


<details>
  <summary>Details</summary>
Motivation: 农业机械中的ISOBUS（ISO 11783）CAN总线带宽（250kbit/s）已无法满足现代播种机、喷雾器和虚拟终端的需求，但十多年来尚未出现标准化的高速替代方案

Method: 采用无网关的双栈方法：点对点ISOBUS流量通过以太网路由，广播消息保留在现有CAN总线；无需新状态机、中间件或应用层代码修改，仅需简单的第3层路由决策和轻量级对等发现机制（增强地址声明AACL）

Result: 初步测试显示：虚拟终端对象池上传速度提升8倍，任务控制器消息速率超过当前规范限制100倍以上；完全基于现有J1939和ISO 11783标准，可在数周内实现

Conclusion: ISO FastLane为ISOBUS提供了即时的性能提升，无需等待长期的高速ISOBUS解决方案，可在现有标准基础上快速部署，实现显著的带宽改进

Abstract: The agricultural industry has been searching for a high-speed successor to the 250~kbit/s CAN bus backbone of ISO~11783 (ISOBUS) for over a decade, yet no protocol-level solution has reached standardization. Meanwhile, modern planters, sprayers, and Virtual Terminals are already constrained by the bus bandwidth. This paper presents ISO FastLane, a gateway-less dual-stack approach that routes point-to-point ISOBUS traffic over Ethernet while keeping broadcast messages on the existing CAN bus. The solution requires no new state machines, no middleware, and no changes to application layer code: only a simple Layer~3 routing decision and a lightweight peer discovery mechanism called Augmented Address Claim (AACL). Legacy devices continue to operate unmodified and unaware of FastLane traffic. Preliminary tests reported on the paper demonstrate that ISO FastLane accelerates Virtual Terminal object pool uploads by factor of 8 and sustains Task Controller message rates over 100 times beyond the current specification limit. Because ISO FastLane builds entirely on existing J1939 and ISO~11783 conventions, it can be implemented by ISOBUS engineers in a matter of weeks. This is delivering tangible performance gains today, without waiting for the long-term High Speed ISOBUS solution.

</details>


### [6] [Optimally Deployed Multistatic OTFS-ISAC Design With Kalman-Based Tracking of Targets](https://arxiv.org/abs/2602.09776)
*Jyotsna Rani,Kuntal Deka,Ganesh Prasad,Zilong Liu*

Main category: cs.NI

TL;DR: 该论文研究了OTFS调制辅助的多站ISAC在车联网中的应用，利用其延迟-多普勒鲁棒性增强通信和高分辨率感知，提出了三角定位部署框架结合卡尔曼滤波，并设计了接收器次优布局策略以减少定位误差。


<details>
  <summary>Details</summary>
Motivation: 车联网中需要同时实现高可靠通信和高精度感知，传统方法在动态环境中性能受限。OTFS调制具有延迟-多普勒鲁棒性，适合车辆高速移动场景，但多站ISAC系统的部署和优化仍需研究。

Method: 提出三角定位部署框架结合卡尔曼滤波，实现目标定位和速度估计；评估多站拓扑下的ISAC性能；设计多站接收器的次优布局策略以减少定位误差。

Result: 数值结果表明，该方法显著降低了感知误差和比特误码率(BER)性能，在动态环境中表现出色。

Conclusion: OTFS调制辅助的多站ISAC系统在车联网中具有显著优势，提出的部署框架和布局策略能有效提升通信和感知性能，适用于动态车辆环境。

Abstract: This paper studies orthogonal time-frequency space (OTFS) modulation aided multistatic integrated sensing and communication (ISAC) in vehicular networks, whereby its delay-Doppler robustness is exploited for enhanced communication and high-resolution sensing. We present a triangulation-based deployment framework combined with Kalman filtering (KF) that enables accurate target localization and velocity estimation. In addition, we assess the ISAC performance in the multistatic topology to determine its effectiveness in the dynamic environment. Further, a suboptimal placement strategy for the multistatic receivers is devised to reduce the targets' localization error. Numerical results demonstrate significant reductions in the sensing error and bit error rate (BER) performances.

</details>


### [7] [6G NTN Waveforms: A Comparison of OTFS, AFDM and OCDM in LEO Satellite Channels](https://arxiv.org/abs/2602.09834)
*Baidyanath Mandal,Aniruddha Chandra,Rastislav Roka,Jarosław Wojtun,Jan Kelner,Cezary Ziołkowski*

Main category: cs.NI

TL;DR: 比较三种超越OFDM波形（OTFS、AFDM、OCDM）在6G非地面网络中的性能，发现AFDM和OTFS优于OCDM，AFDM在高信噪比下表现最佳


<details>
  <summary>Details</summary>
Motivation: 6G物理层正在超越传统的OFDM波形，需要评估适合高移动性非地面网络的新型波形性能，特别是考虑LEO卫星的多普勒效应

Method: 使用四种3GPP TDL信道模型（TDL-A/B/C/D）比较三种波形（OTFS、AFDM、OCDM）的误码率性能，采用MMSE-SD算法进行信道均衡和检测增强

Result: AFDM和OTFS在所有TDL模型中均优于OCDM；在高信噪比下，AFDM在TDL-B和TDL-C模型中表现优于OTFS

Conclusion: AFDM和OTFS是6G非地面网络的合适候选波形，AFDM在高移动性场景中表现更优，研究提供了开源仿真框架供进一步验证和开发

Abstract: Sixth generation (6G) physical layer (PHY) is evolving beyond the legacy orthogonal frequency division multiplexing (OFDM)-based waveforms. In this paper, we compare the bit error rate (BER) performance of three beyond-OFDM waveforms, namely, orthogonal time-frequency-space (OTFS) modulation, affine frequency division multiplexing (AFDM), and orthogonal chirp division multiplexing (OCDM), which are particularly suitable for the highly mobile non-terrestrial network (NTN) vertical of 6G. In order to characterize the effect of mobility and Doppler shift in low Earth orbit (LEO) satellites, we performed BER comparisons over four different NTN tapped-delay-line (TDL) models, TDL-A, TDL-B, TDL-C, and TDL-D, as specified in the 3rd generation partnership project (3GPP) technical report TR 38.811. After channel equalization, a minimum mean squared error with successive detection (MMSE-SD) algorithm was used to enhance the BER performance. It was found that AFDM and OTFS consistently outperformed OCDM across all TDL models, while AFDM performed better than OTFS in TDL-B and TDL-C, in the high signal-to-noise ratio (SNR) regime. The complete simulation framework is made available as an open-source code for quick validation and further development.

</details>


### [8] [Hybrid Responsible AI-Stochastic Approach for SLA Compliance in Multivendor 6G Networks](https://arxiv.org/abs/2602.09841)
*Emanuel Figetakis,Ahmed Refaey Hussein*

Main category: cs.NI

TL;DR: 提出混合式负责任AI-随机学习框架，解决6G多供应商网络中AI自主管理的透明度、公平性和问责制问题，通过集成RAI博弈与随机优化，实现动态对抗重加权和概率探索，并建立审计机制追踪SLA违规责任。


<details>
  <summary>Details</summary>
Motivation: AI与6G网络自动化融合带来了多供应商管理系统中的透明度、公平性和问责制挑战。闭环AI编排虽然提高了适应性和自优化能力，但造成了责任缺口，使得SLA违规无法因果归因于特定代理或供应商。

Method: 提出混合式负责任AI-随机学习框架，将公平性、鲁棒性和可审计性直接嵌入网络控制循环。框架集成RAI博弈与随机优化，实现动态对抗重加权和跨异构供应商域的概率探索。建立RAAP持续记录AI驱动决策轨迹，生成双重问责报告：用户级SLA摘要和运营商级责任分析。

Result: 在合成两类多组数据集上的实验评估表明，混合模型将最差组准确率提高了10.5%。具体而言，混合RAI实现了60.5%的WGAcc和72.7%的AvgAcc，优于传统RAI-GA（50.0%）和ERM（21.5%）。审计机制成功追踪了99%的模拟SLA违规到负责的AI实体，生成了供应商和代理级问责指数。

Conclusion: 混合方法不仅增强了公平性和鲁棒性，还为多供应商6G网络中的自主SLA保障建立了具体的问责框架，解决了AI自主管理中的责任归属问题。

Abstract: The convergence of AI and 6G network automation introduces new challenges in maintaining transparency, fairness, and accountability across multivendor management systems. Although closed-loop AI orchestration improves adaptability and self-optimization, it also creates a responsibility gap, where violations of SLAs cannot be causally attributed to specific agents or vendors. This paper presents a hybrid responsible AI-stochastic learning framework that embeds fairness, robustness, and auditability directly into the network control loop. The framework integrates RAI games with stochastic optimization, enabling dynamic adversarial reweighting and probabilistic exploration across heterogeneous vendor domains. An RAAP continuously records AI-driven decision trajectories and produces dual accountability reports: user-level SLA summaries and operator-level responsibility analytics. Experimental evaluations on synthetic two-class multigroup datasets demonstrate that the proposed hybrid model improves the accuracy of the worst group by up to 10.5\%. Specifically, hybrid RAI achieved a WGAcc of 60.5\% and an AvgAcc of 72.7\%, outperforming traditional RAI-GA (50.0\%) and ERM (21.5\%). The audit mechanism successfully traced 99\% simulated SLA violations to the AI entities responsible, producing both vendor and agent-level accountability indices. These results confirm that the proposed hybrid approach enhances fairness and robustness as well as establishes a concrete accountability framework for autonomous SLA assurance in multivendor 6G networks.

</details>


### [9] [Tracing Data Packet Paths over the Internet using Traceroute](https://arxiv.org/abs/2602.09857)
*Thomas Dreibholz,Somnath Mazumdar*

Main category: cs.NI

TL;DR: 对五年用户数据流量的追踪分析显示：IP数据包传输路径非确定性，不总是选择地理最短路径；数据包会经过多国绕行，即使改变ISP类型路由仍显著不同；传输延迟受ISP和IP协议版本影响。


<details>
  <summary>Details</summary>
Motivation: 从终端系统角度研究IP数据通信随时间的变化，不依赖底层网络提供商，了解用户数据包在实际网络中的传输特性。

Method: 基于追踪数据的分析，覆盖五年观察期、六大ISP（研究、商业和消费类）、二十个自治系统、十四个国家。

Result: 发现三个主要结果：1) 用户数据包传输路径非确定性，不总是地理最短路径；2) 数据包会经过多国绕行，即使改变ISP类型路由仍显著不同；3) 传输延迟受ISP和IP协议版本（IPv4到IPv6）影响。

Conclusion: IP数据通信在实际网络中表现出复杂的路径选择行为，受多种因素影响，这对网络性能优化和应用设计有重要启示。

Abstract: Network communication using the Internet Protocol (IP) is a pillar of modern Internet applications. IP allows data packets to travel the world through a complex set of interconnected computer networks managed by different operators. How IP-based data communication changes over time can be interesting from an end-system's perspective without relying on underlying network providers. This article presents an extensive, trace-driven analysis of user data traffic (covering five years of observations, six large Internet service providers (covering research, business and consumer category type), twenty autonomous systems, and fourteen countries.
  Our three primary findings are: i users data packet transmission paths are not deterministic and does not always select the geographically shortest path; ii) user packets take different routes that cover many countries and detour between two fixed points. Even after changing the types of Internet service provider type (e.g., from commercial to research), the routing can differ significantly between two locations. iii) Packet transmission delay can be influenced by changing the Internet service provider and IP protocol versions (i.e., from IPv4 to IPv6).

</details>


### [10] [SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study](https://arxiv.org/abs/2602.09971)
*Chuan-Chi Lai*

Main category: cs.NI

TL;DR: 提出SCOPE框架，无需训练即可在线优化3D无人机基站部署，相比深度强化学习方法显著降低计算延迟和能耗


<details>
  <summary>Details</summary>
Motivation: 无人机基站为临时热点场景提供灵活服务，但现有数据驱动方法（特别是深度强化学习）存在训练开销大、泛化能力差、计算复杂度高等问题

Method: SCOPE框架结合边界提取机制和最小包围圆算法，动态优化3D无人机位置，无需训练即可在线部署

Result: 理论证明算法收敛性，时间复杂度为O(N² log N)；实验表明SCOPE达到与DRL方法相当的用户满意度，但计算延迟显著降低（毫秒级vs小时级训练），能耗效率更优

Conclusion: SCOPE是实时按需应急部署的理想解决方案，在保持性能的同时大幅降低计算开销

Abstract: Unmanned Aerial Vehicle (UAV)-mounted Base Stations (UAV-BSs) offer a flexible solution for serving ground users in temporary hotspot scenarios. However, efficiently deploying UAV-BSs to satisfy heterogeneous user distributions remains a challenging optimization problem. While recent data-driven approaches, particularly Deep Reinforcement Learning (DRL), have shown promise in dynamic environments, they often suffer from prohibitive training overhead, poor generalization to topology changes, and high computational complexity. To address these limitations, this paper proposes Satisfaction-driven Coverage Optimization via Perimeter Extraction (SCOPE), a training-free and online 3D deployment framework. Unlike heuristic baselines that rely on fixed-altitude assumptions, SCOPE integrates a perimeter extraction mechanism with the Smallest Enclosing Circle (SEC) algorithm to dynamically optimize 3D UAV positions. Theoretically, we provide a rigorous convergence proof of the proposed algorithm and derive its polynomial time complexity of $O(N^2 \log N)$. Experimentally, we conduct a comprehensive comparative study against state-of-the-art DRL baselines (e.g., PPO). Simulation results demonstrate that SCOPE achieves comparable user satisfaction to DRL methods but significantly lower computational latency (milliseconds vs. hours of training) and superior energy efficiency, making it an ideal solution for real-time, on-demand emergency deployment.

</details>


### [11] [ORCHID: Fairness-Aware Orchestration in Mission-Critical Air-Ground Integrated Networks](https://arxiv.org/abs/2602.09994)
*Chuan-Chi Lai,Chi Jai Choy*

Main category: cs.NI

TL;DR: ORCHID：面向6G空地一体化网络的稳定性增强两阶段学习框架，通过GBS感知拓扑分区和重置微调机制解决多无人机协同中的不稳定性和能效-公平性平衡问题


<details>
  <summary>Details</summary>
Motivation: 在6G空地一体化网络中，无人机在任务关键环境（如灾后救援）中提供按需无线覆盖至关重要。传统深度强化学习方法面临多智能体环境非平稳性导致的训练不稳定，以及能效与服务公平性难以平衡的挑战。

Method: 提出ORCHID两阶段学习框架：1) GBS感知拓扑分区策略缓解探索冷启动问题；2) 在MAPPO架构中引入重置微调机制，通过同步学习率衰减和优化器状态重置稳定学习过程，抑制梯度方差防止策略退化；3) 采用最大最小公平性设计平衡服务公平性与能效。

Result: 实验证明ORCHID相比现有基线方法占据帕累托优势位置，确保鲁棒收敛和弹性连接。发现反直觉的效率-公平性协同效应：最大最小公平性设计不仅保障边缘用户服务，还比比例公平性实现更高能效。

Conclusion: ORCHID框架有效解决了多无人机协同中的稳定性和公平性-能效平衡问题，为任务关键场景下的6G空地一体化网络提供了可靠的多无人机协同解决方案。

Abstract: In the era of 6G Air-Ground Integrated Networks (AGINs), Unmanned Aerial Vehicles (UAVs) are pivotal for providing on-demand wireless coverage in mission-critical environments, such as post-disaster rescue operations. However, traditional Deep Reinforcement Learning (DRL) approaches for multi-UAV orchestration often face critical challenges: instability due to the non-stationarity of multi-agent environments and the difficulty of balancing energy efficiency with service equity. To address these issues, this paper proposes ORCHID (Orchestration of Resilient Coverage via Hybrid Intelligent Deployment), a novel stability-enhanced two-stage learning framework. First, ORCHID leverages a GBS-aware topology partitioning strategy to mitigate the exploration cold-start problem. Second, we introduce a Reset-and-Finetune (R\&F) mechanism within the MAPPO architecture that stabilizes the learning process via synchronized learning rate decay and optimizer state resetting. This mechanism effectively suppresses gradient variance to prevent policy degradation, thereby ensuring algorithmic resilience in dynamic environments. Furthermore, we uncover a counter-intuitive efficiency-fairness synergy: contrary to the conventional trade-off, our results demonstrate that the proposed Max-Min Fairness (MMF) design not only guarantees service for cell-edge users but also achieves superior energy efficiency compared to Proportional Fairness (PF), which tends to converge to suboptimal greedy equilibria. Extensive experiments confirm that ORCHID occupies a superior Pareto-dominant position compared to state-of-the-art baselines, ensuring robust convergence and resilient connectivity in mission-critical scenarios.

</details>


### [12] [Resilient Topology-Aware Coordination for Dynamic 3D UAV Networks under Node Failure](https://arxiv.org/abs/2602.10029)
*Chuan-Chi Lai*

Main category: cs.NI

TL;DR: 提出TAG-MAPPO框架，通过图神经网络增强3D空地网络在节点故障下的自愈能力，相比传统MLP方法减少50%冗余切换，故障后15步内恢复90%服务覆盖


<details>
  <summary>Details</summary>
Motivation: 3D空地网络在关键任务应用中需要保证连续服务覆盖，但突发硬件故障会导致拓扑动态变形，传统MARL方法对此缺乏弹性

Method: 提出拓扑感知图MAPPO框架，结合图特征聚合和残差自我状态融合机制，捕捉复杂的智能体间依赖关系，实现自主3D空间重构

Result: TAG-MAPPO在稳定性和效率上均优于基线，减少50%冗余切换，故障后15步内恢复90%服务覆盖，在密集城市场景中公平性指数甚至超过原始四无人机配置

Conclusion: 拓扑感知协调对于实现弹性6G空中网络至关重要，为动态环境中的自适应部署提供了坚实基础

Abstract: In 3D Aerial-Ground Integrated Networks (AGINs), ensuring continuous service coverage under unexpected hardware failures is critical for mission-critical applications. While Multi-Agent Reinforcement Learning (MARL) has shown promise in autonomous coordination, its resilience under sudden node failures remains a challenge due to dynamic topology deformation. This paper proposes a Topology-Aware Graph MAPPO (TAG-MAPPO) framework designed to enhance system survivability through autonomous 3D spatial reconfiguration. Our framework incorporates graph-based feature aggregation with a residual ego-state fusion mechanism to capture intricate inter-agent dependencies. This architecture enables the surviving swarm to rapidly adapt its topology compared to conventional Multi-Layer Perceptron (MLP) based approaches. Extensive simulations across heterogeneous environments, ranging from interference-limited Crowded Urban to sparse Rural areas, validate the proposed approach. The results demonstrate that TAG-MAPPO consistently outperforms baselines in both stability and efficiency; specifically, it reduces redundant handoffs by up to 50 percent while maintaining a lead in energy efficiency. Most notably, the framework exhibits exceptional self-healing capabilities following a catastrophic node failure. TAG-MAPPO restores over 90 percent of the pre-failure service coverage within 15 time steps, exhibiting a significantly faster V-shaped recovery trajectory than MLP baselines. Furthermore, in dense urban scenarios, the framework achieves a post-failure Jain's Fairness Index that even surpasses its original four-UAV configuration by effectively resolving service overlaps. These findings suggest that topology-aware coordination is essential for the realization of resilient 6G aerial networks and provides a robust foundation for adaptive deployments in volatile environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation](https://arxiv.org/abs/2602.09112)
*Russ Webb,Jason Ramapuram*

Main category: cs.AI

TL;DR: Cadmus系统：一个低成本的小型模型训练框架，用于研究程序合成，相比大语言模型提供更好的可控性和可解释性


<details>
  <summary>Details</summary>
Motivation: 当前程序合成研究主要依赖大语言模型，存在分布外泛化、微调效果、分词影响等问题，且计算和存储成本高昂。需要一种低成本、可控的研究平台来深入理解程序合成的内在机制。

Method: 开发Cadmus系统，包含整数虚拟机、多样化真实程序数据集，以及训练成本低于200美元的自回归Transformer模型。系统允许研究者精细控制训练分布，并能检查和插装模型。

Result: Cadmus模型在简单的整数算术程序补全任务上达到100%准确率，优于GPT-5的95%。更重要的是，系统提供了数据与任务关系的透明度，而GPT-5在解决相同任务时引入了未知的先验知识。

Conclusion: 小型模型在复杂推理任务上为程序合成研究提供了经济、可控的实验平台，有助于深入理解模型行为，避免大语言模型中训练数据与任务关系不明确的问题。

Abstract: What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\% accuracy while GPT-5 has 95\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.

</details>


### [14] [Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization](https://arxiv.org/abs/2602.09121)
*Rémi Grzeczkowicz,Eric Soriano,Ali Janati,Miyu Zhang,Gerard Comas-Quiles,Victor Carballo Araruna,Aneesh Jonelagadda*

Main category: cs.AI

TL;DR: 提出轻量级隐私保护的多模态情感识别框架，适用于边缘设备部署，使用语音、文本和面部三种模态，引入基于Dempster-Shafer理论和Dirichlet证据的模型无关融合机制，在五个基准数据集上验证了竞争性准确率和计算效率。


<details>
  <summary>Details</summary>
Motivation: 开发适用于边缘设备的轻量级隐私保护多模态情感识别框架，解决现有方法计算量大、隐私风险高、对不确定性和缺失输入处理不足的问题，为医疗保健、人机交互等应用提供实用解决方案。

Method: 使用三种模态：语音（Emotion2Vec）、面部（ResNet）、文本（DistilRoBERTa），每个模态有专用优化骨干网络。引入基于Dempster-Shafer理论和Dirichlet证据的模型与任务无关融合机制，直接在模型logits上操作，无需额外训练或联合分布估计。

Result: 在五个基准数据集（eNTERFACE05, MEAD, MELD, RAVDESS, CREMA-D）上验证，方法达到竞争性准确率，保持计算效率，对模糊或缺失输入具有鲁棒性，框架具有模块化、可扩展性和实际可行性。

Conclusion: 提出的框架强调模块化、可扩展性和实际可行性，为医疗保健、人机交互等情感感知应用铺平了道路，展示了不确定性感知多模态系统的潜力。

Abstract: In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery. However, the system is fully modular, and can be extended to support other modalities or tasks. Each modality is processed through a dedicated backbone optimized for inference efficiency: Emotion2Vec for speech, a ResNet-based model for facial expressions, and DistilRoBERTa for text. To reconcile uncertainty across modalities, we introduce a model- and task-agnostic fusion mechanism grounded in Dempster-Shafer theory and Dirichlet evidence. Operating directly on model logits, this approach captures predictive uncertainty without requiring additional training or joint distribution estimation, making it broadly applicable beyond emotion recognition. Validation on five benchmark datasets (eNTERFACE05, MEAD, MELD, RAVDESS and CREMA-D) show that our method achieves competitive accuracy while remaining computationally efficient and robust to ambiguous or missing inputs. Overall, the proposed framework emphasizes modularity, scalability, and real-world feasibility, paving the way toward uncertainty-aware multimodal systems for healthcare, human-computer interaction, and other emotion-informed applications.

</details>


### [15] [PABU: Progress-Aware Belief Update for Efficient LLM Agents](https://arxiv.org/abs/2602.09138)
*Haitao Jiang,Lin Ge,Hengrui Cai,Rui Song*

Main category: cs.AI

TL;DR: PABU框架通过显式建模任务进度和选择性保留历史信息，减少LLM智能体中的冗余动作和推理成本，在多个环境中显著提升任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体通常基于完整的动作-观察历史来决策，这会引入任务无关信息，导致冗余动作和更高的推理成本。需要一种更紧凑的状态表示方法来提高效率。

Method: 提出Progress-Aware Belief Update (PABU)信念状态框架：1）显式建模任务进度，预测相对进展；2）选择性保留过去的动作和观察；3）仅基于保留的子集进行未来决策。

Result: 在AgentGym基准的8个环境中，PABU达到81.0%的任务完成率，比基于完整历史的SOTA模型提升23.9%；平均交互步骤减少到9.5步，降低26.9%。消融研究证实进度预测和选择性保留都是必要的。

Conclusion: PABU通过显式建模任务进度和选择性信息保留，有效减少了LLM智能体中的冗余，显著提升了任务完成效率和性能，为高效的信念状态学习提供了新方法。

Abstract: Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.

</details>


### [16] [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159)
*Yichen Wu,Yujin Oh,Sangjoon Park,Kailong Fan,Dania Daye,Hana Farzaneh,Xiang Li,Raul Uppot,Quanzheng Li*

Main category: cs.AI

TL;DR: CoMMa是一个去中心化的医疗多智能体框架，通过博弈论目标协调专科医生，使用确定性嵌入投影进行贡献感知信用分配，在肿瘤学决策任务中实现更高准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗多智能体框架在处理动态、异质患者数据时，大多依赖随机叙事推理，缺乏明确的证据归因和稳定的决策路径。需要一种能够提供可解释、数学基础扎实的决策支持系统。

Method: 提出CoMMa框架：1) 去中心化LLM智能体架构，专科医生在分区证据上操作；2) 通过博弈论目标进行协调；3) 使用确定性嵌入投影近似贡献感知信用分配；4) 通过估计每个智能体的边际效用实现明确证据归因。

Result: 在多样化肿瘤学基准测试（包括真实世界多学科肿瘤委员会数据集）中，CoMMa相比数据集中化和基于角色的多智能体基线，实现了更高的准确性和更稳定的性能。

Conclusion: CoMMa通过贡献感知信用分配机制，为肿瘤学决策支持提供了可解释、数学基础扎实的决策路径，在准确性和稳定性方面优于现有方法，展现了去中心化多智能体框架在复杂医疗决策中的潜力。

Abstract: Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.

</details>


### [17] [FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases](https://arxiv.org/abs/2602.09163)
*Xingjian Zhang,Sophia Moylan,Ziyang Xiong,Qiaozhu Mei,Yichen Luo,Jiaqi W. Ma*

Main category: cs.AI

TL;DR: FlyBench是一个评估AI代理从科学文献中进行端到端本体论知识库构建的基准测试，要求AI根据基因符号搜索和阅读上万篇论文，生成结构化注释，包括基因功能、表达模式和历史同义词。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注命名实体识别或关系提取等孤立子任务，无法捕捉科学知识库构建所需的端到端工作流程，需要评估AI代理在整个知识库构建过程中的能力。

Method: 构建包含16,898篇全文论文的语料库，要求AI代理仅根据基因符号搜索和阅读文献，生成结构化注释（基因本体论术语、表达模式、历史同义词）。基准包含100个基因的7,397个专家注释，评估了四种代理架构：记忆化、固定流程、单代理和多代理。

Result: 架构选择显著影响性能，多代理设计优于简单替代方案，但扩展骨干模型带来的收益递减。所有基线仍有很大改进空间。分析发现代理主要使用检索来确认参数知识而非发现新信息。

Conclusion: FlyBench将推动检索增强科学推理能力的发展，这种能力在科学领域具有广泛应用前景。基准测试为未来开发提供了指导方向。

Abstract: Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains.

</details>


### [18] [Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities](https://arxiv.org/abs/2602.09286)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.AI

TL;DR: 论文通过分析Reddit社区r/OpenClaw和r/Moltbook，发现不同AI代理角色（部署运营vs社交互动）对"人类控制"的理解存在显著差异，提出应根据角色设计监督机制而非一刀切政策。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI监督的讨论常将"人类控制"视为单一目标，但早期采用可能产生角色特定的期望。研究旨在探索不同社会技术角色如何形成不同的监督期望。

Method: 使用比较分析方法，通过主题建模、共享比较空间、粗粒度监督主题抽象、参与度加权显著性分析和分歧测试，分析2026年1-2月两个活跃Reddit社区的数据。

Result: 两个社区在监督期望上显著可分（JSD=0.418，余弦相似度=0.372，置换检验p=0.0005）。r/OpenClaw强调执行护栏和恢复（行动风险），而r/Moltbook强调身份、合法性和公共互动中的问责（意义风险）。

Conclusion: 研究提供了可移植的视角，用于设计和评估匹配AI代理角色的监督机制，而非应用一刀切的控制政策，强调需要根据具体角色定制监督方法。

Abstract: Oversight for agentic AI is often discussed as a single goal ("human control"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium.
  Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, "human control" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies.

</details>


### [19] [Measuring Dataset Diversity from a Geometric Perspective](https://arxiv.org/abs/2602.09340)
*Yang Ba,Mohammad Sadeq Abolhasani,Michelle V Mancenido,Rong Pan*

Main category: cs.AI

TL;DR: 提出基于拓扑数据分析（TDA）和持久性景观（PLs）的几何多样性度量框架PLDiv，超越传统熵和分布变异，捕捉数据集的几何结构特征。


<details>
  <summary>Details</summary>
Motivation: 现有多样性度量主要关注特征空间离散度或度量空间幅度，主要捕捉分布变异或熵，而忽略了数据集的几何结构。需要一种能捕捉数据几何丰富性和结构特性的多样性度量方法。

Method: 基于拓扑数据分析和持久性景观框架，从数据中提取和量化几何特征。该方法提供理论基础的多样性度量，超越熵的概念，捕捉数据集的几何和结构特性。

Result: 通过跨多种模态的广泛实验，证明提出的PLDiv度量方法强大、可靠且可解释，直接将数据多样性与其底层几何结构联系起来。

Conclusion: PLDiv为数据集构建、增强和评估提供了基础工具，通过拓扑数据分析方法实现了对数据集几何结构多样性的量化度量。

Abstract: Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.

</details>


### [20] [Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge](https://arxiv.org/abs/2602.09341)
*Wei Yang,Shixuan Li,Heng Ping,Peiyu Zhang,Paul Bogdan,Jesse Thomason*

Main category: cs.AI

TL;DR: AgentAuditor：用推理树路径搜索替代多数投票的多智能体系统框架，通过ACPO训练裁决器，在5个场景中比多数投票提升5%准确率


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统大多使用多数投票聚合智能体输出，这种方法丢弃了推理轨迹的证据结构，且在"幻觉共识"（智能体共享相关偏见并收敛于相同错误推理）下表现脆弱

Method: 1. AgentAuditor：用推理树路径搜索替代投票，显式表示智能体轨迹间的共识与分歧，在关键分歧点比较推理分支，将全局裁决转化为高效的局部验证；2. ACPO：在多数投票失败案例上训练裁决器，奖励基于证据的少数选择而非流行错误

Result: 在5个流行设置中，AgentAuditor比多数投票提升高达5%的绝对准确率，比使用LLM-as-Judge提升高达3%

Conclusion: AgentAuditor提供了一种与多智能体设置无关的框架，通过显式建模推理分歧和训练抗共识偏好，显著提升了多智能体系统的推理准确性和鲁棒性

Abstract: Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.

</details>


### [21] [Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks](https://arxiv.org/abs/2602.09343)
*Michail S. Alexiou,J. Sukarno Mertoguno*

Main category: cs.AI

TL;DR: 提出结合形式推理与机器学习的方法来增强毒性检测系统对否定攻击的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 社交媒体中网络欺凌和有毒评论日益严重，现有基于统计的机器学习毒性检测系统容易受到包含否定逻辑的对抗性攻击

Method: 设计形式推理包装器，作为预处理和后处理步骤包裹现有机器学习毒性检测系统，专门处理否定攻击问题

Result: 在否定对抗数据集上的实验表明，混合方法（形式推理+机器学习）相比纯统计解决方案显著提高了准确性和有效性

Conclusion: 形式推理包装器能有效缓解否定攻击问题，提升毒性检测系统的鲁棒性，为在线内容审核提供更可靠的解决方案

Abstract: The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing machine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adversarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.

</details>


### [22] [Image Quality in the Era of Artificial Intelligence](https://arxiv.org/abs/2602.09347)
*Jana G. Delfino,Jason L. Granstedt,Frank W. Samuelson,Robert Ochs,Krishna Juluru*

Main category: cs.AI

TL;DR: 本文讨论了AI在放射学图像重建和增强中的应用，强调需要认识其局限性以实现安全有效的使用


<details>
  <summary>Details</summary>
Motivation: AI在放射学中快速部署，虽然能显著改善图像质量、加快获取速度，但也引入了新的故障模式，并加剧了图像感知质量与信息内容之间的脱节。理解AI图像重建和增强的局限性对于安全有效使用该技术至关重要。

Method: 本文是一篇通讯文章，旨在提高人们对AI在放射学图像重建和增强中局限性的认识，通过分析AI技术的潜在风险和故障模式来达成目标。

Result: 文章指出AI在图像重建和增强方面具有显著优势（图像更清晰、更平滑、更详细，获取更快，审查更迅速），但同时会引入新的故障模式，并可能使图像感知质量与实际信息内容之间的差距扩大。

Conclusion: 了解AI图像重建和增强的局限性至关重要，这有助于用户在享受技术益处的同时最小化风险，实现安全有效的临床应用。

Abstract: Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.

</details>


### [23] [P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads](https://arxiv.org/abs/2602.09443)
*Yun Luo,Futing Wang,Qianjia Cheng,Fangchen Yu,Haodi Lei,Jianhao Yan,Chenxi Li,Jiacheng Chen,Yufeng Zhao,Haiyuan Wan,Yuchen Zhang,Shenghe Zheng,Junchi Yao,Qingyang Zhang,Haonan He,Wenxuan Zeng,Li Sheng,Chengxing Xie,Yuxin Zuo,Yizhuo Li,Yulun Wu,Rui Huang,Dongzhan Zhou,Kai Chen,Yu Qiao,Lei Bai,Yu Cheng,Ning Ding,Bowen Zhou,Peng Ye,Ganqu Cui*

Main category: cs.AI

TL;DR: P1-VL是一个开源视觉语言模型家族，专门用于高级科学推理，在物理奥林匹克竞赛基准测试中达到开源模型最佳性能，全球排名第二。


<details>
  <summary>Details</summary>
Motivation: 从符号操作到科学级推理是LLMs的关键前沿，物理作为连接抽象逻辑与物理现实的测试锚点。物理要求模型保持与宇宙定律的一致性，这需要多模态感知将抽象逻辑与现实接地。在奥林匹克级别，图表通常是构成性的而非说明性的，包含文本中缺失的关键约束条件。

Method: 引入P1-VL家族开源视觉语言模型，结合课程强化学习（采用渐进难度扩展稳定后训练）和代理增强（在推理时实现迭代自验证）。

Result: 在HiPhO基准测试（13个2024-2025年考试）中，旗舰模型P1-VL-235B-A22B成为首个获得12枚金牌的开源VLM，在开源模型中达到最先进性能。代理增强系统全球排名第二，仅次于Gemini-3-Pro。在STEM基准测试中表现出显著的科学推理能力和泛化性。

Conclusion: 通过开源P1-VL，为通用物理智能提供了基础性步骤，更好地将视觉感知与抽象物理定律对齐，促进机器科学发现。

Abstract: The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery.

</details>


### [24] [SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning](https://arxiv.org/abs/2602.09463)
*Furong Jia,Ling Dai,Wenjin Deng,Fan Zhang,Chen Hu,Daxin Jiang,Yu Liu*

Main category: cs.AI

TL;DR: SpotAgent是一个用于地理定位的智能体框架，通过工具调用和强化学习解决视觉线索稀疏、长尾分布和高度模糊的问题，实现可验证的精准定位。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在地理定位任务中面临视觉线索稀疏、长尾分布和高度模糊的挑战，且受限于内部知识，经常产生自信但无根据的预测，缺乏可验证性。

Method: 提出SpotAgent框架，将地理定位形式化为智能体推理过程，结合专家级推理能力，通过工具调用（如网络搜索、地图）进行视觉解释和验证。采用3阶段后训练流程：监督微调对齐基础能力，多智能体框架合成高质量轨迹进行智能体冷启动，最后通过空间感知动态过滤策略的强化学习优化推理能力。

Result: 在标准基准测试中，SpotAgent实现了最先进的性能，有效减少幻觉，提供精确且可验证的地理定位结果。

Conclusion: SpotAgent通过智能体推理框架和工具辅助验证，解决了地理定位中的视觉线索稀疏和可验证性问题，为实际应用提供了可靠的地理定位解决方案。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an agentic reasoning process that leverages expert-level reasoning to synergize visual interpretation with tool-assisted verification. SpotAgent actively explores and verifies visual cues by leveraging external tools (e.g., web search, maps) through a ReAct diagram. We introduce a 3-stage post-training pipeline starting with a Supervised Fine-Tuning (SFT) stage for basic alignment, followed by an Agentic Cold Start phase utilizing high-quality trajectories synthesized via a Multi-Agent framework, aiming to instill tool-calling expertise. Subsequently, the model's reasoning capabilities are refined through Reinforcement Learning. We propose a Spatially-Aware Dynamic Filtering strategy to enhance the efficiency of the RL stage by prioritizing learnable samples based on spatial difficulty. Extensive experiments on standard benchmarks demonstrate that SpotAgent achieves state-of-the-art performance, effectively mitigating hallucinations while delivering precise and verifiable geo-localization.

</details>


### [25] [Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models](https://arxiv.org/abs/2602.09485)
*Yizhi Wang,Linan Yue,Min-Ling Zhang*

Main category: cs.AI

TL;DR: XMCC：一种可解释的多模态思维链压缩器，通过强化学习将压缩建模为序列决策过程，在缩短推理轨迹的同时保留关键步骤和答案正确性，并提供自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理模型广泛使用长思维链来捕捉详细视觉信息，但这些长思维链往往过于冗长且包含冗余推理步骤，影响推理效率。现有压缩方法面临两大挑战：1）可能破坏视觉-文本推理的完整性，移除关键对齐线索；2）压缩过程缺乏可解释性，难以辨别哪些信息是关键的。

Method: 提出XMCC（可解释多模态思维链压缩器），将压缩建模为序列决策过程，通过强化学习进行优化。该方法能够有效缩短推理轨迹，同时保留关键推理步骤和答案正确性，并为压缩决策生成自然语言解释。

Result: 在代表性多模态推理基准上的大量实验表明，XMCC不仅能减少推理长度，还能提供可解释的解释，验证了其有效性。

Conclusion: XMCC通过强化学习驱动的序列决策方法，成功解决了长思维链压缩中的完整性和可解释性问题，为多模态推理提供了高效且透明的压缩解决方案。

Abstract: Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.

</details>


### [26] [Computing Conditional Shapley Values Using Tabular Foundation Models](https://arxiv.org/abs/2602.09489)
*Lars Henry Berge Olsen,Dennis Christensen*

Main category: cs.AI

TL;DR: 使用TabPFN等表格基础模型高效计算Shapley值，相比现有方法在大多数情况下性能最优，且运行时间大幅减少


<details>
  <summary>Details</summary>
Motivation: Shapley值是解释性AI的核心方法，但计算成本高昂，尤其在特征相关时。传统方法需要大量条件期望的近似计算，而深度学习方法因需要为每个条件期望重新训练而效率低下。表格基础模型如TabPFN通过上下文学习克服了这一计算障碍。

Method: 使用TabPFN的多种变体计算Shapley值，通过上下文学习近似条件期望而无需重新训练。在模拟和真实数据集上与最先进方法进行比较。

Result: 在大多数情况下，TabPFN表现最佳；在少数情况下仅略逊于最佳方法，但运行时间仅为其他方法的几分之一。

Conclusion: 表格基础模型为Shapley值计算提供了高效解决方案，未来可以通过专门针对条件Shapley值估计的改进来进一步提升性能。

Abstract: Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.

</details>


### [27] [Autoregressive Direct Preference Optimization](https://arxiv.org/abs/2602.09533)
*Masanari Oi,Mahiro Ukai,Masahiro Kaneko,Naoaki Okazaki,Nakamasa Inoue*

Main category: cs.AI

TL;DR: 本文提出了一种新的自回归DPO（ADPO）方法，通过将自回归假设显式引入偏好优化框架，改进了传统的DPO方法，并区分了token长度和反馈长度两种度量。


<details>
  <summary>Details</summary>
Motivation: 传统DPO方法广泛依赖响应级别的Bradley-Terry模型，但这种方法在推导目标函数后才假设参考模型和可学习模型是自回归的，这可能限制了其潜力。作者希望重新审视DPO的理论基础，将自回归假设更早地引入偏好优化框架。

Method: 作者重新审视DPO的理论基础，提出了一种新的公式化方法，在应用Bradley-Terry模型之前显式引入自回归假设。通过重新表述和扩展DPO，推导出名为自回归DPO（ADPO）的新变体，该变体将自回归建模显式集成到偏好优化框架中。

Result: 推导出的损失函数具有优雅的形式：它将DPO目标中的求和操作移到log-sigmoid函数之外。通过理论分析发现，在设计基于DPO的算法时需要考虑两种长度度量：token长度μ和反馈长度μ'。这是首次明确区分这两种度量并分析它们对LLM偏好优化的影响。

Conclusion: ADPO通过更早地引入自回归假设，改进了传统DPO方法，为大型语言模型的偏好对齐提供了更理论严谨的框架，并首次明确区分了token长度和反馈长度两种重要度量。

Abstract: Direct preference optimization (DPO) has emerged as a promising approach for aligning large language models (LLMs) with human preferences. However, the widespread reliance on the response-level Bradley-Terry (BT) model may limit its full potential, as the reference and learnable models are assumed to be autoregressive only after deriving the objective function. Motivated by this limitation, we revisit the theoretical foundations of DPO and propose a novel formulation that explicitly introduces the autoregressive assumption prior to applying the BT model. By reformulating and extending DPO, we derive a novel variant, termed Autoregressive DPO (ADPO), that explicitly integrates autoregressive modeling into the preference optimization framework. Without violating the theoretical foundations, the derived loss takes an elegant form: it shifts the summation operation in the DPO objective outside the log-sigmoid function. Furthermore, through theoretical analysis of ADPO, we show that there exist two length measures to be considered when designing DPO-based algorithms: the token length $μ$ and the feedback length $μ$'. To the best of our knowledge, we are the first to explicitly distinguish these two measures and analyze their implications for preference optimization in LLMs.

</details>


### [28] [Detecting radar targets swarms in range profiles with a partially complex-valued neural network](https://arxiv.org/abs/2602.09597)
*Martin Bauw*

Main category: cs.AI

TL;DR: 该论文提出使用部分复值神经网络处理雷达距离剖面中的多目标检测问题，相比传统脉冲压缩方法，该神经网络能一次性处理整个接收信号生成完整的检测剖面。


<details>
  <summary>Details</summary>
Motivation: 雷达目标检测面临多个挑战：杂波干扰、波形失真，以及多个目标相对接近时可能被误认为单个目标或相互影响检测阈值。目标接近的负面影响取决于雷达参数定义的距离分辨率和自适应阈值。

Method: 提出部分复值神经网络作为自适应距离剖面处理方法。该方法采用生成式架构，一次性处理整个接收信号生成完整的检测剖面，而不是像传统脉冲压缩那样每次只处理一个脉冲长度。

Result: 通过生成模拟数据集进行实验，比较了传统脉冲压缩方法与简单部分复值神经网络的表现。神经网络能够更好地处理多目标接近和回波失真的情况。

Conclusion: 部分复值神经网络为雷达多目标检测提供了一种有效的自适应处理方法，能够克服传统脉冲压缩在处理多目标接近和回波失真时的局限性。

Abstract: Correctly detecting radar targets is usually challenged by clutter and waveform distortion. An additional difficulty stems from the relative proximity of several targets, the latter being perceived as a single target in the worst case, or influencing each other's detection thresholds. The negative impact of targets proximity notably depends on the range resolution defined by the radar parameters and the adaptive threshold adopted. This paper addresses the matter of targets detection in radar range profiles containing multiple targets with varying proximity and distorted echoes. Inspired by recent contributions in the radar and signal processing literature, this work proposes partially complex-valued neural networks as an adaptive range profile processing. Simulated datasets are generated and experiments are conducted to compare a common pulse compression approach with a simple neural network partially defined by complex-valued parameters. Whereas the pulse compression processes one pulse length at a time, the neural network put forward is a generative architecture going through the entire received signal in one go to generate a complete detection profile.

</details>


### [29] [FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints](https://arxiv.org/abs/2602.09620)
*Jorge Fandinno,Pedro Cabalar,Philipp Wanko,Torsten Schaub*

Main category: cs.AI

TL;DR: FLINGO语言扩展了约束ASP，将ASP的丰富表达特性（如默认值、未定义属性、选择规则等）融入数值约束中，解决了传统CASP表达性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统约束ASP（CASP）在表达数值约束时失去了ASP的许多重要特性，如默认值声明、属性未定义、选择规则的非确定性赋值和聚合值使用等。这限制了CASP在实际应用中的表达能力。

Method: 提出FLINGO语言和工具，将ASP的表达特性融入数值约束中。基于先前建立的语义基础，提供了从FLINGO语法到标准CASP程序（遵循CLINGCON输入格式）的翻译方法。

Result: FLINGO语言成功地将ASP的表达特性整合到数值约束中，通过多个示例展示了其表达能力。实现了从FLINGO到标准CASP的翻译机制。

Conclusion: FLINGO语言填补了ASP和CASP之间的表达鸿沟，使CASP能够保留ASP的丰富表达特性，同时具备数值约束处理能力，增强了CASP在实际应用中的实用性。

Abstract: Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.

</details>


### [30] [ClinAlign: Scaling Healthcare Alignment from Clinician Preference](https://arxiv.org/abs/2602.09653)
*Shiwei Lyu,Xidong Wang,Lei Liu,Hao Zhu,Chaohe Zhang,Jian Wang,Jinjie Gu,Benyou Wang,Yue Shen*

Main category: cs.AI

TL;DR: 提出HealthRubrics数据集和HealthPrinciples框架，通过医生验证的偏好示例和可重用临床原则，实现LLM在医疗领域的细粒度对齐，在资源有限情况下超越更大模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型具备专家级医学知识，但其开放输出与临床医生细粒度偏好的对齐仍具挑战。现有方法依赖粗粒度目标或不可靠的自动评估，缺乏专业指南基础。

Method: 提出两阶段框架：1) 构建HealthRubrics数据集（7,034个医生验证的偏好示例），临床医生精炼LLM生成的评分标准以满足医学标准；2) 提炼为HealthPrinciples（119个可重用临床原则），用于离线对齐和推理时引导自我修订。

Result: 仅激活30B参数中3B参数的模型在HealthBench-Hard上达到33.4%，超越包括Deepseek-R1和o3在内的更大模型，建立了临床对齐的资源高效基准。

Conclusion: 通过医生验证的偏好示例和可重用临床原则，实现了LLM在医疗领域的细粒度对齐，提供了一种资源高效的临床对齐方法，为医疗AI的可靠部署奠定了基础。

Abstract: Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.

</details>


### [31] [GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis](https://arxiv.org/abs/2602.09794)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Xudong Wang,Zhenzhen Huang,Pengcheng Zheng,Shuai Yuan,Sheng Zheng,Qigan Sun,Jie Zou,Lik-Hang Lee,Yang Yang*

Main category: cs.AI

TL;DR: 提出GHS-TDA方法，通过构建全局假设图和多尺度拓扑分析，解决CoT推理中早期错误传播和缺乏结构化分析的问题，提升推理准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在两个根本性局限：1）推理过程对早期决策高度敏感，一旦引入初始错误会传播放大且难以纠正；2）缺乏结构化分析技术过滤冗余推理和提取关键特征，导致推理不稳定且可解释性有限。

Method: 提出GHS-TDA方法：1）构建语义丰富的全局假设图，聚合、对齐和协调多个候选推理路径，提供全局修正路径；2）应用基于持久同调的拓扑数据分析，捕获稳定的多尺度结构，去除冗余和不一致，提取更可靠的推理骨架。

Result: GHS-TDA通过联合利用推理多样性和拓扑稳定性，实现自适应收敛，产生高置信度和可解释的推理路径，在多个推理基准测试中，在准确性和鲁棒性方面均优于强基线方法。

Conclusion: GHS-TDA有效解决了CoT推理中的错误传播和结构化分析不足的问题，通过全局协调和拓扑稳定性分析，显著提升了推理的准确性、鲁棒性和可解释性。

Abstract: Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.

</details>


### [32] [Symbolic Pattern Temporal Numeric Planning with Intermediate Conditions and Effects](https://arxiv.org/abs/2602.09798)
*Matteo Cardellini,Enrico Giunchiglia*

Main category: cs.AI

TL;DR: 将符号模式规划（SPP）扩展到具有中间条件和效果（ICE）的时间规划，提出Patty规划器，在多个领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的SPP方法仅适用于数值规划，而现实世界中的时间规划问题通常涉及持续动作（可以重叠执行）以及中间条件和效果，需要扩展SPP来处理这类更复杂的时间规划问题。

Method: 将SPP扩展到时间规划中的ICE片段：1）动作是持续的，可以时间重叠；2）条件和效果可以在动作执行期间的任何时间检查/应用；3）可以指定在计划执行特定时间必须检查/应用的条件/效果。使用模式（有限动作序列）建议动作间的因果顺序，编码为SMT公式，如果模式不准确则扩展模式直到找到有效计划。

Result: Patty规划器：1）在大多数无ICE的时间规划领域优于其他现有规划器；2）在有ICE的文献领域与最先进的搜索规划器表现相当；3）在基于真实应用的新领域中优于同一规划器。

Conclusion: SPP方法可以成功扩展到具有中间条件和效果的时间规划领域，Patty规划器在多个时间规划领域表现出优越性能，特别是在真实世界应用场景中。

Abstract: Recently, a Symbolic Pattern Planning (SPP) approach was proposed for numeric planning where a pattern (i.e., a finite sequence of actions) suggests a causal order between actions. The pattern is then encoded in a SMT formula whose models correspond to valid plans. If the suggestion by the pattern is inaccurate and no valid plan can be found, the pattern is extended until it contains the causal order of actions in a valid plan, making the approach complete. In this paper, we extend the SPP approach to the temporal planning with Intermediate Conditions and Effects (ICEs) fragment, where $(i)$ actions are durative (and thus can overlap over time) and have conditions/effects which can be checked/applied at any time during an action's execution, and $(ii)$ one can specify plan's conditions/effects that must be checked/applied at specific times during the plan execution. Experimental results show that our SPP planner Patty $(i)$ outperforms all other planners in the literature in the majority of temporal domains without ICEs, $(ii)$ obtains comparable results with the SoTA search planner for ICS in literature domains with ICEs, and $(iii)$ outperforms the same planner in a novel domain based on a real-world application.

</details>


### [33] [Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices](https://arxiv.org/abs/2602.09802)
*Manon Reusens,Sofie Goethals,Toon Calders,David Martens*

Main category: cs.AI

TL;DR: 研究LLM在旅行助手场景中的主观决策能力，通过选择困境实验和支付意愿估计，发现LLM能产生有意义的支付意愿值，但存在系统性偏差，且整体高估人类支付意愿。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在旅行助手、购物支持等应用中的部署，它们经常需要在没有客观正确答案的情况下为用户做出主观选择。研究LLM在这种主观决策环境中的表现，评估其作为决策支持工具的潜力和局限性。

Method: 在旅行助手情境中向LLM呈现选择困境，使用多项logit模型分析响应以推导隐含支付意愿估计。比较这些估计值与经济学文献中的人类基准值。研究不同条件下的模型行为：基线设置、提供用户历史选择信息、基于角色的提示。

Result: 较大的LLM能够产生有意义的支付意愿值，但在属性层面存在系统性偏差。LLM整体上高估人类支付意愿，特别是当涉及昂贵选项或商业导向角色时。当模型基于对更便宜选项的先前偏好时，估值更接近人类基准。

Conclusion: LLM在主观决策支持方面既有潜力也有局限性。实际部署时需要仔细选择模型、设计提示和用户表示。模型对先前偏好的条件化可以改善与人类基准的一致性。

Abstract: As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.

</details>


### [34] [Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning](https://arxiv.org/abs/2602.09813)
*Dexun Li,Sidney Tio,Pradeep Varakantham*

Main category: cs.AI

TL;DR: 提出分层MDP框架用于环境设计，通过教师代理利用学生策略表示生成训练环境，并加入生成模型减少师生交互需求，在资源受限场景中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有无监督环境设计方法依赖随机过程无限生成环境，这在师生交互机会有限的资源受限场景中不切实际，需要更高效的课程生成方法。

Method: 引入分层MDP框架，教师代理利用从评估环境中提取的学生策略表示来生成训练环境；加入生成模型增强教师训练数据集，减少师生交互需求。

Result: 在多个领域实验中，该方法在单次交互中需要更少的师生交互次数，同时性能优于基线方法。

Conclusion: 该方法适用于训练机会有限的场景，为资源受限环境下的无监督环境设计提供了有效解决方案。

Abstract: Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision Process (MDP) framework for environment design. Our framework features a teacher agent that leverages student policy representations derived from discovered evaluation environments, enabling it to generate training environments based on the student's capabilities. To improve efficiency, we incorporate a generative model that augments the teacher's training dataset with synthetic data, reducing the need for teacher-student interactions. In experiments across several domains, we show that our method outperforms baseline approaches while requiring fewer teacher-student interactions in a single episode. The results suggest the applicability of our approach in settings where training opportunities are limited.

</details>


### [35] [Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?](https://arxiv.org/abs/2602.09937)
*Taeyoon Kim,Woohyeok Park,Hoyeong Yun,Kyungyong Lee*

Main category: cs.AI

TL;DR: 论文对基于LLM的云系统根因分析(RCA)代理进行了过程级失败分析，识别出12种陷阱类型，发现主要问题源于共享的代理架构而非单个模型限制，提示工程无法解决主要问题，但改进代理间通信协议可减少15%的通信相关失败。


<details>
  <summary>Details</summary>
Motivation: 大规模云系统故障造成重大经济损失，需要自动化根因分析(RCA)。现有LLM代理系统检测准确率低，且当前评估框架只关注最终答案正确性，无法揭示代理推理失败的原因。

Method: 在五个LLM模型上执行完整的OpenRCA基准测试，产生1,675次代理运行，将观察到的失败分类为12种陷阱类型，涵盖代理内推理、代理间通信和代理-环境交互三个层面。

Result: 分析显示最普遍的陷阱（特别是幻觉数据解释和不完整探索）在所有模型中持续存在，表明这些失败源于共享的代理架构而非单个模型限制。控制缓解实验表明提示工程无法解决主要陷阱，而丰富代理间通信协议可将通信相关失败减少15个百分点。

Conclusion: 本文开发的陷阱分类和诊断方法为设计更可靠的云RCA自主代理奠定了基础，揭示了需要从系统架构层面而非单纯模型层面解决LLM代理的可靠性问题。

Abstract: Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-based RCA agents. We execute the full OpenRCA benchmark across five LLM models, producing 1,675 agent runs, and classify observed failures into 12 pitfall types across intra-agent reasoning, inter-agent communication, and agent-environment interaction. Our analysis reveals that the most prevalent pitfalls, notably hallucinated data interpretation and incomplete exploration, persist across all models regardless of capability tier, indicating that these failures originate from the shared agent architecture rather than from individual model limitations. Controlled mitigation experiments further show that prompt engineering alone cannot resolve the dominant pitfalls, whereas enriching the inter-agent communication protocol reduces communication-related failures by up to 15 percentage points. The pitfall taxonomy and diagnostic methodology developed in this work provide a foundation for designing more reliable autonomous agents for cloud RCA.

</details>


### [36] [Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning](https://arxiv.org/abs/2602.09945)
*Jinsong Liu,Yuhang Jiang,Ramayya Krishnan,Rema Padman,Yiye Zhang,Jiang Bian*

Main category: cs.AI

TL;DR: DRL框架通过分析推理差异来提升临床决策支持系统，使用图编辑距离比较参考推理与代理推理，构建差异知识库并通过RAG检索指令来修补逻辑漏洞。


<details>
  <summary>Details</summary>
Motivation: 临床决策支持不仅需要正确答案，还需要临床有效的推理过程。现有方法在复杂推理场景中可能存在逻辑漏洞，需要一种机制来识别和修补这些推理差异。

Method: 提出差异推理学习（DRL）框架：1）将参考推理（医生临床推理、临床指南或更强模型输出）和代理的自由形式链式思考转换为有向无环图；2）使用临床加权的图编辑距离进行差异分析；3）LLM作为裁判对齐语义等价节点并诊断差异；4）将图级差异转换为自然语言指令存储在差异推理知识库（DR-KB）中；5）推理时通过检索增强生成（RAG）检索top-k指令来增强代理提示。

Result: 在开放医学问答基准和内部临床数据的返院预测任务上，DRL超越了基线方法，提高了最终答案准确性和推理保真度。消融研究证实了参考推理注入和top-k检索策略的有效性。临床医生评审进一步验证了方法的可靠性。

Conclusion: DRL能够在复杂推理场景中支持更可靠的临床决策，并在有限token预算下提供实用的部署机制，为临床决策支持系统提供了有效的推理质量改进方法。

Abstract: Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a clinically weighted graph edit distance (GED)-based discrepancy analysis. An LLM-as-a-judge aligns semantically equivalent nodes and diagnoses discrepancies between graphs. These graph-level discrepancy diagnostics are converted into natural-language instructions and stored in a Differential Reasoning Knowledge Base (DR-KB). At inference, we retrieve top-$k$ instructions via Retrieval-Augmented Generation (RAG) to augment the agent prompt and patch likely logic gaps. Evaluation on open medical question answering (QA) benchmarks and a Return Visit Admissions (RVA) prediction task from internal clinical data demonstrates gains over baselines, improving both final-answer accuracy and reasoning fidelity. Ablation studies confirm gains from infusing reference reasoning rationales and the top-$k$ retrieval strategy. Clinicians' review of the output provides further assurance of the approach. Together, results suggest that DRL supports more reliable clinical decision-making in complex reasoning scenarios and offers a practical mechanism for deployment under limited token budgets.

</details>


### [37] [ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference](https://arxiv.org/abs/2602.10004)
*Junda Wang,Zhichao Yang,Dongxu Zhang,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: ESTAR方法通过早期停止机制减少大型推理模型中的冗余推理计算，在保持准确率的同时将推理长度减少约3.7倍


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在生成长链式思维时经常在已经得到正确答案后继续冗余推理，浪费计算资源。需要一种方法来检测和减少这种推理冗余，提高效率而不牺牲准确性。

Method: ESTAR结合三种技术：(1)基于轨迹的分类器识别何时可以安全停止推理；(2)监督微调教导LRMs提出自生成的<stop>信号；(3)具有计算感知奖励的<stop>感知强化学习，在自生成的停止点截断推演。

Result: 在四个推理数据集上的实验显示，ESTAR将推理长度从4,799减少到1,290（约3.7倍），同时保持准确率（74.9% vs. 74.2%），并展现出强大的跨领域泛化能力。

Conclusion: 早期停止是一种简单而强大的机制，可以显著提高大型推理模型的推理效率，在保持准确性的同时大幅减少计算开销。

Abstract: Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated <stop> signals, and (iii) <stop>-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs.

</details>


### [38] [Discovering High Level Patterns from Simulation Traces](https://arxiv.org/abs/2602.10009)
*Sean Memery,Kartic Subr*

Main category: cs.AI

TL;DR: 提出一种自然语言引导的方法，从详细仿真日志中发现粗粒度模式，使语言模型能更好地进行物理推理和生成奖励程序。


<details>
  <summary>Details</summary>
Motivation: 语言模型在物理推理任务上表现不佳，因为它们从观测数据学习而非基于仿真。现有方法将仿真轨迹作为上下文，但可扩展性差，因为仿真轨迹包含大量细粒度数值和语义数据。

Method: 提出自然语言引导的方法，从详细仿真日志中发现粗粒度模式（如"刚体碰撞"、"稳定支撑"等）。具体通过合成程序操作仿真日志，将其映射到一系列高级激活模式。

Result: 在两个物理基准测试中，这种带注释的仿真日志表示更适用于自然语言物理系统推理。该方法使语言模型能够从自然语言指定的目标生成有效的奖励程序，可用于规划或监督学习。

Conclusion: 通过从仿真日志中提取粗粒度模式，可以显著提高语言模型在物理推理任务中的表现，使其能够更好地理解和操作物理系统。

Abstract: Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.

</details>


### [39] [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063)
*Tianyi Jiang,Arctanx An,Hengyi Feng,Naixin Zhai,Haodong Li,Xiaomin Yu,Jiahui Liu,Hanwen Du,Shuo Zhang,Zhi Yang,Jie Huang,Yuhua Li,Yongxin Ni,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: 提出Chain of Mindset (CoM)框架，通过动态协调四种不同思维模式（空间、收敛、发散、算法）来提升LLM推理能力，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法存在"单一思维模式"陷阱，在解决同一问题的不同阶段都使用相同的固定思维模式，而人类解决问题时会整合多种思维模式。这种单一思维假设阻碍了模型达到更高智能水平。

Method: 提出Chain of Mindset (CoM)训练无关的代理框架，将推理分解为四种功能异构的思维模式：空间思维、收敛思维、发散思维和算法思维。元代理根据推理状态动态选择最优思维模式，双向上下文门过滤跨模块信息流以保持效率和效果。

Result: 在数学、代码生成、科学问答和空间推理等六个挑战性基准测试中，CoM在Qwen3-VL-32B-Instruct和Gemini-2.0-Flash上分别比最强基线提升4.96%和4.72%的总体准确率，同时平衡推理效率。

Conclusion: CoM框架通过动态协调多种思维模式，解决了现有LLM推理方法的单一思维限制，实现了更接近人类的问题解决方式，在多个领域达到最先进性能。

Abstract: Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\% and 4.72\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.

</details>


### [40] [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](https://arxiv.org/abs/2602.10085)
*Richard Bornemann,Pierluigi Vito Amadori,Antoine Cully*

Main category: cs.AI

TL;DR: CODE-SHARP框架利用基础模型自动发现和演化分层技能，通过代码形式的奖励函数实现开放式的技能学习，在Craftax环境中显著提升了智能体解决长时程任务的能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖人工设计的奖励函数，不适用于开放式技能发现，因为有意义技能的集合是未知的。虽然近期方法在自动化奖励设计方面有进展，但仍局限于预定义任务的奖励优化。

Method: 提出CODE-SHARP框架，利用基础模型开放地扩展和精炼分层技能档案，将其构建为可执行奖励函数代码的有向图。通过高层FM规划器组合发现的技能，使单个目标条件智能体能够解决复杂任务。

Result: 在Craftax环境中，仅使用发现的SHARP技能生成的奖励进行训练的目标条件智能体能够解决越来越长时程的目标。组合技能后，智能体在复杂长时程任务上的表现平均超过预训练智能体和任务特定专家策略134%。

Conclusion: CODE-SHARP通过基础模型驱动的开放式技能发现和演化，实现了无需人工干预的自主技能学习，为解决开放式技能发现这一AI重大挑战提供了有前景的途径。

Abstract: Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos $\href{https://sites.google.com/view/code-sharp/homepage}{here}$.

</details>


### [41] [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090)
*Zhaoyang Wang,Canwen Xu,Boyi Liu,Yite Wang,Siwei Han,Zhewei Yao,Huaxiu Yao,Yuxiong He*

Main category: cs.AI

TL;DR: 提出Agent World Model (AWM)合成环境生成管道，创建1000个代码驱动的日常场景环境，支持大规模强化学习训练工具使用智能体，实现强泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型智能体训练面临缺乏多样可靠环境的限制，需要可扩展的合成环境来支持多轮交互工具使用任务

Method: 提出Agent World Model (AWM)合成环境生成管道，创建代码驱动、数据库支持的环境，每个环境平均包含35个工具，提供高质量观测和可靠状态转换

Result: 在三个基准测试中，仅在合成环境中训练的工具使用智能体展现出强大的分布外泛化能力，优于在特定基准环境中训练的方法

Conclusion: AWM合成环境管道为智能体训练提供了可扩展、可靠且高效的解决方案，支持大规模强化学习并实现良好泛化性能

Abstract: Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [42] [Entropy-Based Evidence for Bitcoin's Discrete Time Mechanism](https://arxiv.org/abs/2602.09027)
*Bin Chen,Pan Feng*

Main category: cs.IT

TL;DR: 比特币通过工作量证明和区块发现实现可验证的时间顺序，而非依赖可信时钟。研究发现区块到达呈指数分布，工作量证明维持高熵搜索状态，在发现有效区块时熵会突然崩溃，这解释了比特币的非连续时间结构。但在分布式网络中，熵崩溃不是瞬时完成的，而是需要传播时间。


<details>
  <summary>Details</summary>
Motivation: 比特币的时间顺序不是基于可信时钟，而是通过概率性的区块发现和累积工作量证明来实现。本文旨在从熵的角度理解比特币的时间结构机制，并研究在分布式网络中这种熵崩溃过程的实际表现。

Method: 通过分析比特币区块到达的统计特性，证明其呈稳定的指数分布；从信息熵角度解释工作量证明过程；利用临时分叉的实证观察来研究熵崩溃在分布式网络中的传播过程。

Result: 区块到达确实表现出稳定的指数行为；工作量证明过程维持高熵搜索状态，在发现有效区块时熵会突然崩溃；在分布式网络中，熵崩溃需要有限的传播时间来完成，但在实践中仍然很快。

Conclusion: 比特币的时间结构可以从熵的角度进行机制性解释，工作量证明过程创造了离散的熵崩溃事件，形成了非连续的时间顺序。在分布式网络中，熵崩溃的完成需要传播时间，这解释了临时分叉现象，但整体上比特币的时间机制在实践中运行良好。

Abstract: Bitcoin derives a verifiable temporal order from probabilistic block discovery and cumulative proof-of-work rather than from a trusted global clock. We show that block arrivals exhibit stable exponential behavior across difficulty epochs, and that the proof-of-work process maintains a high-entropy search state that collapses discretely upon the discovery of a valid block. This entropy-based interpretation provides a mechanistic account of Bitcoin's non-continuous temporal structure. In a distributed network, however, entropy collapse is not completed instantaneously across all participants. Using empirical observations of temporary forks, we show that collapse completion unfolds over a finite propagation-bounded interval, while remaining rapid in practice.

</details>


### [43] [Non-existence of Information-Geometric Fermat Structures: Violation of Dual Lattice Consistency in Statistical Manifolds with $L^n$ Structure](https://arxiv.org/abs/2602.09028)
*Kanta Tochigi*

Main category: cs.IT

TL;DR: 将费马大定理重新表述为信息几何结构的嵌入问题，证明当n≥3时不存在满足"对偶格一致性"的信息几何结构，揭示了整数结构与能量结构在双重平坦空间中的不兼容性。


<details>
  <summary>Details</summary>
Motivation: 将费马方程重新解释为信息几何问题，探索局部二次度量（Fisher信息度量）与全局L^n结构之间的差异，研究整数结构与能量结构在双重平坦空间中的兼容性。

Method: 通过最大熵原理构建广义正态分布的统计流形，将费马方程视为n阶矩约束。使用Chentsov定理确定自然度量，通过Poisson求和公式和Hausdorff-Young不等式分析傅里叶变换对函数族的影响，证明对偶格一致性的不可能性。

Result: 证明了当n≥3时不存在满足"对偶格一致性"的信息几何费马解，揭示了傅里叶变换导致函数族从L^n到L^q的转变（其中1/n+1/q=1），使得对偶格一致性在解析上不可能实现。

Conclusion: 费马大定理的不可解性源于整数结构与能量结构在双重平坦空间中的几何不兼容性，这种不兼容性表现为局部二次度量与全局L^n结构之间的差异，并与椭圆曲线理论存在对应关系。

Abstract: This paper reformulates Fermat's Last Theorem as an embedding problem of information-geometric structures. We reinterpret the Fermat equation as an $n$-th moment constraint, constructing a statistical manifold $\mathcal{M}_n$ of generalized normal distributions via the Maximum Entropy Principle. By Chentsov's Theorem, the natural metric is the Fisher information metric ($L^2$); however, the global structure is governed by the $L^n$ moment constraint. This reveals a discrepancy between the local quadratic metric and the global $L^n$ structure. We axiomatically define an "Information-Geometric Fermat Solution," postulating that the lattice structure must maintain "dual lattice consistency" under the Legendre transform. We prove the non-existence of such structures for $n \ge 3$. Through the Poisson Summation Formula and Hausdorff-Young Inequality, we demonstrate that the Fourier transform induces an alteration of the function family ($L^n \to L^q$, where $1/n + 1/q = 1$), rendering dual lattice consistency analytically impossible. This identifies a geometric obstruction where integer and energy structures are incompatible within a dually flat space. We conclude by discussing the correspondence between this model and elliptic curves.

</details>


### [44] [Universal Asymptotics for Jensen--Shannon Divergence under Shuffling](https://arxiv.org/abs/2602.09029)
*Alex Shvets*

Main category: cs.IT

TL;DR: 该论文研究了在洗牌模型中，相邻数据集诱导的转录分布之间的Jensen-Shannon散度，推导了在温和正性假设下的两阶渐近展开式。


<details>
  <summary>Details</summary>
Motivation: 研究洗牌模型中差分隐私机制的性能，特别是Jensen-Shannon散度作为隐私泄露的度量，这对于理解洗牌模型中的隐私保护效果至关重要。

Method: 在洗牌模型框架下，假设每个用户应用固定的局部随机化器，可信洗牌器发布输出直方图。在温和正性假设下，使用渐近分析推导JSD的显式展开式。

Result: 证明了JSD的两项渐近展开，其中主导项是卡方散度除以8n。对于二元和k元随机响应作为特例，对于基于独立重复的多消息协议，主导系数变为(1+卡方)^m-1。

Conclusion: 该研究为洗牌模型中Jensen-Shannon散度的渐近行为提供了精确的数学刻画，有助于更好地理解和分析差分隐私机制在洗牌模型中的隐私保护性能。

Abstract: We study the Jensen--Shannon divergence (JSD) between transcript distributions induced by neighboring datasets in the shuffle model when each user applies a fixed local randomizer and a trusted shuffler releases the output histogram. Under a mild positivity assumption, we prove an explicit two-term asymptotic expansion where the leading term is chi-squared divergence divided by 8n. Binary randomized response and k-ary randomized response follow as corollaries. For multi-message protocols based on independent repetition, the leading coefficient becomes (1 + chi-squared)^m - 1. A fully explicit remainder control is provided in the appendix.

</details>


### [45] [Dispersion of Gaussian Sources with Memory and an Extension to Abstract Sources](https://arxiv.org/abs/2602.09176)
*Eyyup Tasci,Victoria Kostina*

Main category: cs.IT

TL;DR: 该论文研究了具有独立但非同分布分量的信息源在有限块长下的有损压缩问题，推导了最小可达速率的精确表达式，推广了现有i.i.d.源的弥散结果，并改进了高斯-马尔可夫源的已知结果。


<details>
  <summary>Details</summary>
Motivation: 研究具有独立但非同分布分量的信息源的有损压缩问题，这类源包括具有记忆的高斯源（在二次失真下可转化为该形式）。现有弥散结果主要针对i.i.d.分量源，对具有记忆的源研究有限，需要建立更一般的理论框架。

Method: 提出点质量乘积代理测度作为关键技术工具，该工具推广了经验分布概念，保持了坐标间的可加性，便于对独立非同分布项的和进行典型性分析。通过构造典型集，推导了有限块长下的速率表达式。

Result: 证明了在超过失真d的概率不超过ε的操作约束下，最小可达速率满足：R(n,d,ε)=ℝ_n(d)+√(𝕍_n(d)/n)Q^{-1}(ε)+O(log n/n)，其中ℝ_n(d)是n阶信息率失真函数，𝕍_n(d)是源弥散。该结果推广了i.i.d.源的弥散结果，并改进和扩展了标量高斯-马尔可夫源的已知结果。

Conclusion: 论文建立了具有独立但非同分布分量信息源的有限块长有损压缩理论，提出的点质量乘积代理测度是关键技术创新，能够处理更一般的源模型，为具有记忆的源提供了精确的弥散特性描述。

Abstract: We consider finite blocklength lossy compression of information sources whose components are independent but non-identically distributed. Crucially, Gaussian sources with memory and quadratic distortion can be cast in this form. We show that under the operational constraint of exceeding distortion $d$ with probability at most $ε$, the minimum achievable rate at blocklength $n$ satisfies $R(n, d, ε)=\mathbb{R}_n(d)+\sqrt{\frac{\mathbb{V}_n(d)}{n}}Q^{-1}(ε)+O \left(\frac{\log n}{n}\right)$, where $Q^{-1}(\cdot)$ is the inverse $Q$-function, while $\mathbb{R}_n(d)$ and $\mathbb{V}_n(d)$ are fundamental characteristics of the source computed using its $n$-letter joint distribution and the distortion measure, called the $n$th-order informational rate-distortion function and the source dispersion, respectively. Our result generalizes the existing dispersion result for abstract sources with i.i.d. components. It also sharpens and extends the only known dispersion result for a source with memory, namely, the scalar Gauss-Markov source. The key novel technical tool in our analysis is the point-mass product proxy measure, which enables the construction of typical sets. This proxy generalizes the empirical distribution beyond the i.i.d. setting by preserving additivity across coordinates and facilitating a typicality analysis for sums of independent, non-identical terms.

</details>


### [46] [On the Subpacketization Level of the Banawan-Ulukus Multi-Message PIR Scheme](https://arxiv.org/abs/2602.09417)
*Anoosheh Heidarzadeh*

Main category: cs.IT

TL;DR: 该论文分析了Banawan和Ulukus多消息PIR方案中子分组化级别的线性递归关系，推导出了归一化子分组化级别L的显式公式，显示其为N的多项式，首项为N^{K-D+1}/D。


<details>
  <summary>Details</summary>
Motivation: Banawan和Ulukus提出的多消息PIR方案在计算子分组化级别时产生了一个线性递归关系，需要对该递归进行解析以获得子分组化级别的显式表达式，从而更好地理解方案的参数特性。

Method: 分析计算子分组化级别时出现的线性递归关系，推导出归一化子分组化级别L关于服务器数量N、总消息数K和需求消息数D的显式表示公式。

Result: 得到了L的显式公式，证明L是N的多项式且系数非负，其首项为N^{K-D+1}/D，该公式的整数倍即为方案的实际子分组化级别。

Conclusion: 成功解析了多消息PIR方案中子分组化级别的递归关系，获得了简洁的显式公式，揭示了子分组化级别随系统参数变化的数学结构，为方案分析和优化提供了理论基础。

Abstract: This note analyzes a linear recursion that arises in the computation of the subpacketization level for the multi-message PIR scheme of Banawan and Ulukus. We derive an explicit representation for the normalized subpacketization level $L$, whose smallest integer multiple yields the subpacketization level of the scheme, in terms of the number of servers $N$, the total number of messages $K$, and the number of demand messages $D$. The resulting formula shows that $L$ is a polynomial in $N$ with nonnegative coefficients, and its leading term is $N^{K-D+1}/D$.

</details>


### [47] [Directed Information: Estimation, Optimization and Applications in Communications and Causality](https://arxiv.org/abs/2602.09711)
*Dor Tsur,Oron Sabag,Navin Kashyap,Haim Permuter,Gerhard Kramer*

Main category: cs.IT

TL;DR: 本专著系统综述了定向信息（DI）及其在信息论中的主要应用，重点介绍了反馈信道容量的计算方法，特别是针对有限状态信道的各种优化技术。


<details>
  <summary>Details</summary>
Motivation: 定向信息作为捕捉随机过程间信息流向的度量，在因果推断和信道容量分析中具有重要价值。本专著旨在系统梳理DI的理论基础、估计方法及其在反馈信道容量计算中的应用，特别是针对有限状态信道的求解技术。

Method: 首先回顾DI的定义、基本性质及其与香农互信息的关系；然后综述DI估计技术，从经典插件估计器到现代神经网络估计器；重点介绍反馈信道容量计算方法，包括值迭代算法、Q图方法和强化学习算法等。

Result: 建立了DI与信道容量之间的理论联系，特别是对于单形有限状态信道，反馈容量可转化为马尔可夫决策过程的最优平均奖励问题，并开发了多种精确计算或近似估计的方法。

Conclusion: 定向信息是分析反馈信道容量的核心工具，本专著系统总结了DI的理论框架、估计方法和在有限状态信道容量计算中的应用，为相关领域研究提供了全面的参考。

Abstract: Directed information (DI) is an information measure that attempts to capture directionality in the flow of information from one random process to another. It is closely related to other causal influence measures, such as transfer entropy, Granger causality, and Pearl's causal framework. This monograph provides an overview of DI and its main application in information theory, namely, characterizing the capacity of channels with feedback and memory. We begin by reviewing the definitions of DI, its basic properties, and its relation to Shannon's mutual information. Next, we provide a survey of DI estimation techniques, ranging from classic plug-in estimators to modern neural-network-based estimators. Considering the application of channel capacity estimation, we describe how such estimators numerically optimize DI rate over a class of joint distributions on input and output processes. A significant part of the monograph is devoted to techniques to compute the feedback capacity of finite-state channels (FSCs). The feedback capacity of a strongly connected FSC involves the maximization of the DI rate from the channel input process to the output process. This maximization is performed over the class of causal conditioned probability input distributions. When the FSC is also unifilar, i.e., the next state is given by a time-invariant function of the current state and the new input-output symbol pair, the feedback capacity is the optimal average reward of an appropriately formulated Markov decision process (MDP). This MDP formulation has been exploited to develop several methods to compute exactly, or at least estimate closely, the feedback capacity of a unifilar FSC. This monograph describes these methods, starting from the value iteration algorithm, to Q-graph methods, and reinforcement learning algorithms that can handle large input and output alphabets.

</details>


### [48] [METTLE: Efficient Streaming Erasure Code with Peeling Decodability](https://arxiv.org/abs/2602.10020)
*Qianru Yu,Tianji Yang,Jingfan Meng,Jun Xu*

Main category: cs.IT

TL;DR: METTLE是首个同时满足高编码效率、低编码复杂度和低解码延迟三大要求的擦除码，相比流式RaptorQ在编码效率上略差但解码速度快47.7-84.6倍


<details>
  <summary>Details</summary>
Motivation: 解决编码理论中长期存在的开放问题：设计同时满足高编码效率、低编码复杂度和流式编码（低解码延迟）三大要求的擦除码，这在网络和系统中有广泛应用需求

Method: 提出METTLE（Multi-Edge Type with Touch-less Leading Edge）擦除码，通过多边类型和无接触前沿设计来实现三大要求的平衡

Result: 相比为降低延迟而配置小源块大小的流式RaptorQ，METTLE在编码效率上仅略差，但解码速度快47.7到84.6倍

Conclusion: METTLE是首个同时满足三大要求的擦除码，解决了编码理论中的长期开放问题，在网络和系统应用中具有重要价值

Abstract: In this work, we solve a long-standing open problem in coding theory with broad applications in networking and systems: designing an erasure code that simultaneously satisfies three requirements: (1) high coding efficiency, (2) low coding complexity, and (3) being a streaming code (defined as one with low decoding latency). We propose METTLE (Multi-Edge Type with Touch-less Leading Edge), the first erasure code to meet all three requirements. Compared to "streaming RaptorQ" (RaptorQ configured with a small source block size to ensure a low decoding latency), METTLE is only slightly worse in coding efficiency, but 47.7 to 84.6 times faster to decode.

</details>


### [49] [On the generalization of $g$-circulant MDS matrices](https://arxiv.org/abs/2602.10028)
*Atif Ahmad Khan,Shakir Ali,Bhupendra Singh*

Main category: cs.IT

TL;DR: 本文研究了有限域上的一类新型矩阵——consta-g-循环矩阵，给出了其可逆性条件、计数公式，并完全刻画了3阶和4阶g-循环MDS矩阵，最后基于斜多项式环构造了g-循环矩阵的新变体。


<details>
  <summary>Details</summary>
Motivation: MDS矩阵在密码学和编码理论中非常重要，因为它们提供了强大的数据保护和高效的信息扩散。然而，寻找和构造MDS矩阵是一个具有挑战性的问题。本文旨在通过研究consta-g-循环矩阵这一新型矩阵结构，为MDS矩阵的构造和识别提供新的理论工具和方法。

Method: 1. 引入consta-g-循环矩阵作为g-循环矩阵的推广，基于多项式h(x)=x^m-λ+∑h_i x^i定义线性变换；2. 建立这类矩阵可逆性的充分必要条件；3. 当x^m-λ可分解为不可约因子乘积时，推导可逆consta-g-循环矩阵的精确计数公式；4. 完全刻画3阶和4阶g-循环MDS矩阵；5. 受斜多项式环启发，构造g-循环矩阵的新变体。

Result: 1. 得到了consta-g-循环矩阵可逆性的判定条件；2. 当x^m-λ=∏f_i(x)^{e_i}时，可逆consta-g-循环矩阵的数量为N·∏(q^{deg f_i}-1)，其中N由特定整数k的计数确定；3. 完全分类了3阶和4阶g-循环MDS矩阵；4. 基于斜多项式环构造了新的g-循环矩阵变体；5. 提供了相关实例验证理论结果。

Conclusion: 本文系统研究了consta-g-循环矩阵的理论性质，特别是其可逆性和MDS性质。提出的计数公式显著减少了验证矩阵是否为MDS的计算复杂度。对低阶g-循环MDS矩阵的完全刻画以及基于斜多项式环的新构造，为密码学和编码理论中MDS矩阵的设计提供了新的理论框架和实用工具。

Abstract: A matrix $M$ over the finite field $ \mathbb{F}_q $ is called \emph{maximum distance separable} (MDS) if all of its square submatrices are non-singular. These MDS matrices are very important in cryptography and coding theory because they provide strong data protection and help spread information efficiently. In this paper, we introduce a new type of matrix called a \emph{consta-$g$-circulant matrix}, which extends the idea of $g$-circulant matrices. These matrices come from a linear transformation defined by the polynomial
  $
  h(x) = x^m - λ+ \sum_{i=0}^{m-1} h_i x^i
  $
  over $ \mathbb{F}_q $. We find the upper bound of such matrices exist and give conditions to check when they are invertible. This helps us know when they are MDS matrices. If the polynomial $ x^m - λ$ factors as
  $
  x^m - λ= \prod_{i=1}^{t} f_i(x)^{e_i},
  $
  where each \( f_i(x) \) is irreducible, then the number of invertible consta-$g$-circulant matrices is
  $
  N \cdot \prod_{i=1}^{t} \left( q^{°f_i} - 1 \right),
  $
  where $r$ is the multiplicative order of $λ$, and \( N \) is the number of integers \( k \) such that
  $
  0 \leq k < \left\lfloor \frac{m - 1}{r} \right\rfloor + 1 \quad \text{and} \quad \gcd(1 + rk, m) = 1.
  $
  This formula help us to reduce the number of cases to check whether such matrices is MDS. Moreover, we give complete characterization of $g$-circulant MDS matrices of order 3 and 4. Additionally, inspired by skew polynomial rings, we construct a new variant of $g$-circulant matrix. In the last, we provide some examples related to our findings.

</details>
