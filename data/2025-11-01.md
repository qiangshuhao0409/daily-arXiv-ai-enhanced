<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 8]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.IT](#cs.IT) [Total: 6]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Zero Added Loss Multiplexing (ZALM) Source Simulation](https://arxiv.org/abs/2510.26009)
*Jerry Horgan,Alexander Nico-Katz,Shelbi L. Jenkins,Ashley N. Tittlebaugh,Vivek Visan,Rahan Bali,Marco Ruffini,Boulat A. Bash,Daniel C. Kilper*

Main category: cs.NI

TL;DR: 提出了一个模块化的ZALM模拟器，用于分析设计选择对纠缠对产生速率和保真度的影响，支持20多个可调参数，能够模拟量子网络中的各种组件和物理效应。


<details>
  <summary>Details</summary>
Motivation: ZALM技术能够产生宽带、每通道可预告的EPR纠缠对，但其性能受多种参数影响。需要开发模拟工具来理解设计选择如何影响输出性能，以便针对特定应用优化系统。

Method: 使用NetSquid和QSI控制器构建模块化模拟器，支持IDEAL和REALISTIC两种模式，包含SPDC源、干涉、DWDM滤波、光纤延迟、主动偏振门、探测器和损耗光纤等可复用组件。

Result: 模拟显示在默认配置下，平均保真度保持在0.8，但纠缠比特率从源端的0.0175下降到50公里处的0.0；减小SPDC简并带宽可显著提高纠缠比特率而不影响保真度。

Conclusion: 该模拟器能够协同设计光源、滤波和前馈设置，适用于特定量子存储器，并可作为端到端量子网络研究的构建模块。

Abstract: Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded
EPR pairs, with a rich parameter space that allows its performance to be
tailored for specific applications. We present a modular ZALM simulator that
demonstrates how design choices affect output rate and fidelity. Built in
NetSquid with QSI controllers, it exposes 20+ tunable parameters, supports
IDEAL and REALISTIC modes, and provides reusable components for Spontaneous
Parametric Down Conversion (SPDC) sources, interference, Dense Wavelength
Division Multiplexing (DWDM) filtering, fiber delay, active polarization gates,
detectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM)
visibility, insertion loss, detector efficiency, gate errors, and attenuation.
Using this tool, we map trade offs among fidelity, link distance, and entangled
pairs per use, and show how SPDC bandwidth and DWDM grid spacing steer
performance. Using the default configuration settings, average fidelity emains
constant at 0.8 but the ebit rate decreases from 0.0175 at the source to 0.0 at
50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate
significantly without affecting fidelity. The simulator enables codesign of
source, filtering, and feedforward settings for specific quantum memories and
integrates as a building block for end to end quantum network studies.

</details>


### [2] [Performance Analysis of Dynamic Equilibria in Joint Path Selection and Congestion Control](https://arxiv.org/abs/2510.26060)
*Sina Keshvadi*

Main category: cs.NI

TL;DR: 本文提出了首个分析路径选择和拥塞控制联合动态的公理化框架，揭示了协议设计中可预测性能与用户中心目标之间的基本权衡，并发现智能体迁移可以反直觉地增强稳定性。


<details>
  <summary>Details</summary>
Motivation: 路径感知网络赋予终端主机细粒度流量转发控制能力，但多个智能体的无协调贪婪路径选择会导致持续高幅度网络振荡，这种现象的定量性能影响尚未被充分理解。

Method: 开发了首个分析路径选择和拥塞控制联合动态的公理化框架，通过形式化表征系统的动态均衡（稳定的周期性振荡模式），并提供一套公理来评估其效率、丢包避免、收敛性、公平性和响应性。

Result: 分析揭示了协议设计中可预测性能（效率、收敛性）与用户中心目标（公平性、响应性）之间的基本权衡，但效率、收敛性和丢包避免可以同时优化。智能体迁移可以反直觉地增强稳定性。

Conclusion: 这些发现为未来路径感知互联网设计稳健、高性能协议提供了原则性设计指南。

Abstract: Path-aware networking, a cornerstone of next-generation architectures like
SCION and Multipath QUIC, empowers end-hosts with fine-grained control over
traffic forwarding. This capability, however, introduces a critical stability
risk: uncoordinated, greedy path selection by a multitude of agents can induce
persistent, high-amplitude network oscillations. While this phenomenon is
well-known, its quantitative performance impact across key metrics has remained
poorly understood. In this paper, we address this gap by developing the first
axiomatic framework for analyzing the joint dynamics of path selection and
congestion control. Our model enables the formal characterization of the
system's dynamic equilibria-the stable, periodic patterns of oscillation-and
provides a suite of axioms to rate their performance in terms of efficiency,
loss avoidance, convergence, fairness, and responsiveness. Our analysis reveals
a fundamental trade-off in protocol design between predictable performance
(efficiency, convergence) and user-centric goals (fairness, responsiveness). We
prove, however, that no such trade-off exists among efficiency, convergence,
and loss avoidance, which can be simultaneously optimized through careful
parameter tuning. Furthermore, we find that agent migration can,
counter-intuitively, enhance stability by de-synchronizing traffic, a
theoretical result validated by our simulations. These findings provide a
principled design map for engineering robust, high-performance protocols for
the future path-aware Internet.

</details>


### [3] [Symmetry-Driven Asynchronous Forwarding for Reliable Distributed Coordination in Toroidal Networks](https://arxiv.org/abs/2510.26071)
*Shenshen Luan,Yumo Tian,Xinyu Zhang,Qingwen Zhang,Tianheng Wang,Yan Yang,Shuguo Xie*

Main category: cs.NI

TL;DR: 提出了一种基于环面拓扑对称性的异步转发机制，通过利用几何特性实现无控制平面协调的可靠数据包传输，在1%链路故障率下减少17.5%的数据包丢失。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式系统（如卫星星座和高性能计算集群）需要在不稳定链路下保持协调的通信原语。传统路由方案在链路故障后的控制平面同步期间存在严重的数据包丢失问题。

Method: 利用环面拓扑的几何特性，建立拓扑势梯度模型，通过对称性破坏故障自然产生的反向流进行故障规避。提出了两种本地转发策略：反向流对向优先(RF-CF)和反向流侧向优先(RF-LF)。

Result: 在16×16环面上的渗流分析和数据包级模拟显示，该机制在1%链路故障率下可减少17.5%的数据包丢失，其中RF-LF策略贡献了28%的成功传输数据包。

Conclusion: 建立了拓扑对称性与通信弹性之间的基础联系，为增强分布式系统提供了一种轻量级、协议无关的底层机制。

Abstract: The proliferation of large-scale distributed systems, such as satellite
constellations and high-performance computing clusters, demands robust
communication primitives that maintain coordination under unreliable links. The
torus topology, with its inherent rotational and reflection symmetries, is a
prevalent architecture in these domains. However, conventional routing schemes
suffer from substantial packet loss during control-plane synchronization after
link failures. This paper introduces a symmetry-driven asynchronous forwarding
mechanism that leverages the torus's geometric properties to achieve reliable
packet delivery without control-plane coordination. We model packet flow using
a topological potential gradient and demonstrate that symmetry-breaking
failures naturally induce a reverse flow, which we harness for fault
circumvention. We propose two local forwarding strategies, Reverse Flow with
Counter-facing Priority (RF-CF) and Lateral-facing Priority (RF-LF), that
guarantee reachability to the destination via forward-flow phase transition
points, without protocol modifications or additional in-packet overhead.
Through percolation analysis and packet-level simulations on a 16 x 16 torus,
we show that our mechanism reduces packet loss by up to 17.5% under a 1% link
failure rate, with the RF-LF strategy contributing to 28% of successfully
delivered packets. This work establishes a foundational link between
topological symmetry and communication resilience, providing a lightweight,
protocol-agnostic substrate for enhancing distributed systems.

</details>


### [4] [FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler](https://arxiv.org/abs/2510.26075)
*Thanh Le,Hai Duong,Yusheng Ji,ThanhVu Nguyen,John C. S. Lui*

Main category: cs.NI

TL;DR: 本文研究了5G MU-MIMO系统中对抗性用户如何利用DRL策略中的观测归一化器来发起吞吐量降级攻击，提出了基于多面体抽象域的FGGM攻击方案，能够在不知道受害者确切CSI值的情况下降低网络吞吐量达70%。


<details>
  <summary>Details</summary>
Motivation: 现有DRL方法在5G用户调度中存在安全隐患，但大多数研究假设对抗性用户能获得受害者CSI的确切值，这在LTE/5G上行传输中不切实际。本文旨在探索基于观测归一化器的实际可行攻击方案。

Method: 利用DRL策略中的观测归一化器（包含观测均值和方差），对抗性用户可以估计受害者CSI的上下界。开发了FGGM攻击方案，使用多面体抽象域技术来找到一组对抗性CSI向量，能在受害者观测值范围内实现攻击目标。

Result: 实验结果表明，FGGM能够确定一组由对抗性用户控制的对抗性CSI向量，在整个模拟过程中重复使用这些CSI，在不知道受害者确切观测值的情况下，将受害者网络吞吐量降低高达70%。

Conclusion: 本研究揭示了DRL策略中观测归一化器的安全漏洞，提出的FGGM攻击方案可作为案例研究，并可应用于其他基于DRL的问题，如背包导向的资源分配问题。

Abstract: In 5G mobile communication systems, MU-MIMO has been applied to enhance
spectral efficiency and support high data rates. To maximize spectral
efficiency while providing fairness among users, the base station (BS) needs to
selects a subset of users for data transmission. Given that this problem is
NP-hard, DRL-based methods have been proposed to infer the near-optimal
solutions in real-time, yet this approach has an intrinsic security problem.
This paper investigates how a group of adversarial users can exploit
unsanitized raw CSIs to launch a throughput degradation attack. Most existing
studies only focused on systems in which adversarial users can obtain the exact
values of victims' CSIs, but this is impractical in the case of uplink
transmission in LTE/5G mobile systems. We note that the DRL policy contains an
observation normalizer which has the mean and variance of the observation to
improve training convergence. Adversarial users can then estimate the upper and
lower bounds of the local observations including the CSIs of victims based
solely on that observation normalizer. We develop an attacking scheme FGGM by
leveraging polytope abstract domains, a technique used to bound the outputs of
a neural network given the input ranges. Our goal is to find one set of
intentionally manipulated CSIs which can achieve the attacking goals for the
whole range of local observations of victims. Experimental results demonstrate
that FGGM can determine a set of adversarial CSI vector controlled by
adversarial users, then reuse those CSIs throughout the simulation to reduce
the network throughput of a victim up to 70\% without knowing the exact value
of victims' local observations. This study serves as a case study and can be
applied to many other DRL-based problems, such as a knapsack-oriented resource
allocation problems.

</details>


### [5] [From req/res to pub/sub: Exploring Media over QUIC Transport for DNS](https://arxiv.org/abs/2510.26234)
*Mathis Engelbart,Mike Kosek,Lars Eggert,Jörg Ott*

Main category: cs.NI

TL;DR: 本文提出了一种基于发布-订阅模式的DNS变体，使用Media-over-QUIC架构来推送资源记录更新，相比传统DNS能显著减少更新流量和记录获取延迟。


<details>
  <summary>Details</summary>
Motivation: 传统DNS设计为静态目录服务，资源记录很少变化，但现代使用场景如负载均衡需要更动态的DNS机制，能够主动推送更新给感兴趣的解析器。

Method: 设计了基于Media-over-QUIC架构的发布-订阅DNS系统和协议原型，支持推送资源记录更新。

Result: 原型实现表明发布-订阅DNS能限制更新流量，显著减少解析器获取最新记录的时间，支持CDN负载均衡等用例。

Conclusion: DNS可以从发布-订阅变体中受益，但该架构也带来了新的挑战，包括端点状态管理开销增加和首次查询延迟增加。

Abstract: The DNS is a key component of the Internet. Originally designed to facilitate
the resolution of host names to IP addresses, its scope has continuously
expanded over the years, today covering use cases such as load balancing or
service discovery. While DNS was initially conceived as a rather static
directory service in which resource records (RR) only change rarely, we have
seen a number of use cases over the years where a DNS flavor that isn't purely
based upon requesting and caching RRs, but rather on an active distribution of
updates for all resolvers that showed interest in the respective records in the
past, would be preferable. In this paper, we thus explore a publish-subscribe
variant of DNS based on the Media-over-QUIC architecture, where we devise a
strawman system and protocol proposal to enable pushing RR updates. We provide
a prototype implementation, finding that DNS can benefit from a
publish-subscribe variant: next to limiting update traffic, it can considerably
reduce the time it takes for a resolver to receive the latest version of a
record, thereby supporting use cases such as load balancing in content
distribution networks. The publish-subscribe architecture also brings new
challenges to the DNS, including a higher overhead for endpoints due to
additional state management, and increased query latencies on first lookup, due
to session establishment latencies.

</details>


### [6] [Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information](https://arxiv.org/abs/2510.26256)
*Geng Sun,Siyi Chen,Zemin Sun,Long He,Jiacheng Wang,Dusit Niyato,Zhu Han,Dong In Kim*

Main category: cs.NI

TL;DR: 提出了一种联合计算资源分配和任务卸载方法(JCRATOA)，通过凸优化和契约理论解决车载雾计算中的资源分配和任务卸载问题，以最小化任务完成延迟。


<details>
  <summary>Details</summary>
Motivation: 车载雾计算(VFC)面临RSU资源有限、信息不对称、任务异质性和车辆能力差异等挑战，导致资源分配效率低下和性能下降。

Method: 采用分层VFC架构，结合凸优化进行RSU资源分配，使用契约理论激励FV资源分配，并应用双边匹配算法进行任务卸载。

Result: 仿真结果表明JCRATOA在任务完成延迟、任务完成率、系统吞吐量和资源利用公平性方面表现优越，并能有效满足约束条件。

Conclusion: 所提出的JCRATOA方法能够有效解决车载雾计算中的资源分配和任务卸载问题，显著提升系统性能。

Abstract: Vehicular fog computing (VFC) has emerged as a promising paradigm, which
leverages the idle computational resources of nearby fog vehicles (FVs) to
complement the computing capabilities of conventional vehicular edge computing.
However, utilizing VFC to meet the delay-sensitive and computation-intensive
requirements of the FVs poses several challenges. First, the limited resources
of road side units (RSUs) struggle to accommodate the growing and diverse
demands of vehicles. This limitation is further exacerbated by the information
asymmetry between the controller and FVs due to the reluctance of FVs to
disclose private information and to share resources voluntarily. This
information asymmetry hinders the efficient resource allocation and
coordination. Second, the heterogeneity in task requirements and the varying
capabilities of RSUs and FVs complicate efficient task offloading, thereby
resulting in inefficient resource utilization and potential performance
degradation. To address these challenges, we first present a hierarchical VFC
architecture that incorporates the computing capabilities of both RSUs and FVs.
Then, we formulate a delay minimization optimization problem (DMOP), which is
an NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we
propose a joint computing resource allocation and task offloading approach
(JCRATOA). Specifically, we propose a convex optimization-based method for RSU
resource allocation and a contract theory-based incentive mechanism for FV
resource allocation. Moreover, we present a two-sided matching method for task
offloading by employing the matching game. Simulation results demonstrate that
the proposed JCRATOA is able to achieve superior performances in task
completion delay, task completion ratio, system throughput, and resource
utilization fairness, while effectively meeting the satisfying constraints.

</details>


### [7] [Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval](https://arxiv.org/abs/2510.26473)
*Junya Shiraishi,Shashi Raj Pandey,Israel Leyva-Mayorga,Petar Popovski*

Main category: cs.NI

TL;DR: 提出两种无线内存管理方法：无线内存激活和无线内存近似，以降低DRAM在存储ML模型时的刷新能耗，特别适用于资源受限的IoT设备。


<details>
  <summary>Details</summary>
Motivation: DRAM用于存储ML模型时，周期性刷新在待机期间会造成大量能量浪费，这对资源受限的IoT设备尤为显著。

Method: 采用无线内存激活和无线内存近似两种方法，通过考虑ML模型使用的时间因素和相关性来高效管理可用内存。

Result: 数值结果表明，所提方案在满足检索精度约束的同时，能实现比始终开启方法更低的能耗。

Conclusion: 无线内存管理方法能有效降低DRAM在ML模型存储中的能耗，特别适合资源受限的IoT设备应用。

Abstract: The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning
(ML) models plays a critical role in accelerating ML inference tasks in the
next generation of communication systems. However, periodic refreshment of DRAM
results in wasteful energy consumption during standby periods, which is
significant for resource-constrained Internet of Things (IoT) devices. To solve
this problem, this work advocates two novel approaches: 1) wireless memory
activation and 2) wireless memory approximation. These enable the wireless
devices to efficiently manage the available memory by considering the timing
aspects and relevance of ML model usage; hence, reducing the overall energy
consumption. Numerical results show that our proposed scheme can realize
smaller energy consumption than the always-on approach while satisfying the
retrieval accuracy constraint.

</details>


### [8] [Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](https://arxiv.org/abs/2510.26628)
*Chuang Zhang,Geng Sun,Jiahui Li,Jiacheng Wang,Qingqing Wu,Dusit Niyato,Shiwen Mao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 提出了一种基于低空无人机搭载可移动天线的联合无线能量传输和隐蔽通信系统，通过混合专家增强的软演员-评论家算法解决多目标优化问题。


<details>
  <summary>Details</summary>
Motivation: 物联网网络发展需要可持续能源解决方案，但传统无线能量传输系统在提供高效能量传输的同时会暴露敏感操作数据给对手，存在安全隐患。

Method: 采用低空无人机搭载可移动天线增强传输系统，联合执行无线能量传输和隐蔽通信；提出MoE-SAC算法，使用稀疏Top-K门控混合浅层专家架构表示多模态策略分布，并加入动作投影模块确保功率预算和天线位置约束。

Result: 仿真结果表明，所提方法显著优于基线方法和其他最先进的深度强化学习算法。

Conclusion: 该系统能同时为物联网节点提供能量补充并为隐蔽用户建立传输链路，通过无线能量信号作为自然掩护实现隐蔽通信，有效解决了能量传输与安全通信的平衡问题。

Abstract: The proliferation of Internet of Things (IoT) networks has created an urgent
need for sustainable energy solutions, particularly for the battery-constrained
spatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles
(UAVs) employed with wireless power transfer (WPT) capabilities offer a
promising solution, the line-of-sight channels that facilitate efficient energy
delivery also expose sensitive operational data to adversaries. This paper
proposes a novel low-altitude UAV-carried movable antenna-enhanced transmission
system joint WPT and covert communications, which simultaneously performs
energy supplements to IoT nodes and establishes transmission links with a
covert user by leveraging wireless energy signals as a natural cover. Then, we
formulate a multi-objective optimization problem that jointly maximizes the
total harvested energy of IoT nodes and sum achievable rate of the covert user,
while minimizing the propulsion energy consumption of the low-altitude UAV. To
address the non-convex and temporally coupled optimization problem, we propose
a mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that
employs a sparse Top-K gated mixture-of-shallow-experts architecture to
represent multimodal policy distributions arising from the conflicting
optimization objectives. We also incorporate an action projection module that
explicitly enforces per-time-slot power budget constraints and antenna position
constraints. Simulation results demonstrate that the proposed approach
significantly outperforms some baseline approaches and other state-of-the-art
deep reinforcement learning algorithms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling](https://arxiv.org/abs/2510.26603)
*Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的自主家庭能源管理系统，能够从自然语言请求直接协调多电器调度，无需示例演示即可实现最优调度。


<details>
  <summary>Details</summary>
Motivation: 电力行业转型需要大幅增加住宅需求响应能力，但现有家庭能源管理系统因需要将用户日常偏好转换为技术参数而面临采用障碍。

Method: 采用分层架构，结合一个协调器和三个专业代理，使用ReAct模式进行迭代推理，集成Google日历进行上下文感知的截止时间提取，实现无需硬编码工作流的动态协调。

Result: 在真实奥地利日前电价下评估三个开源模型，Llama-3.3-70B在所有场景中成功协调所有电器，达到混合整数线性规划计算的最优成本基准，而其他模型在单电器调度上表现完美但难以同时协调所有电器。

Conclusion: 大语言模型可以作为自主协调器管理从自然语言输入到多电器调度的完整工作流，但无明确指导的分析查询处理仍不可靠，系统已开源以支持可重复性、扩展和未来研究。

Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.

</details>


### [10] [Towards Piece-by-Piece Explanations for Chess Positions with SHAP](https://arxiv.org/abs/2510.25775)
*Francesco Spinnato*

Main category: cs.AI

TL;DR: 将SHAP可解释AI技术应用于国际象棋分析，通过系统性地移除棋子来计算每个棋子对引擎评估的贡献度，提供可解释的棋子级分析。


<details>
  <summary>Details</summary>
Motivation: 传统国际象棋引擎提供精确但不透明的评估分数，无法揭示单个棋子或模式的贡献。需要一种方法能够解释引擎评估背后的具体原因，帮助玩家理解棋局。

Method: 将棋子视为特征，采用SHAP方法通过系统性地移除棋子来计算每个棋子的加性贡献度，基于经典的"移除棋子"教学思想，结合现代可解释AI技术。

Result: 开发了一种能够为国际象棋引擎评估提供局部忠实且人类可解释的棋子级归因方法，实现了对引擎输出的可解释分析。

Conclusion: 该方法为国际象棋分析开辟了新的可能性，包括可视化、人类训练和引擎比较，并发布了代码和数据以促进可解释国际象棋AI的进一步研究。

Abstract: Contemporary chess engines offer precise yet opaque evaluations, typically
expressed as centipawn scores. While effective for decision-making, these
outputs obscure the underlying contributions of individual pieces or patterns.
In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the
domain of chess analysis, aiming to attribute a chess engines evaluation to
specific pieces on the board. By treating pieces as features and systematically
ablating them, we compute additive, per-piece contributions that explain the
engines output in a locally faithful and human-interpretable manner. This
method draws inspiration from classical chess pedagogy, where players assess
positions by mentally removing pieces, and grounds it in modern explainable AI
techniques. Our approach opens new possibilities for visualization, human
training, and engine comparison. We release accompanying code and data to
foster future research in interpretable chess AI.

</details>


### [11] [An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0](https://arxiv.org/abs/2510.25813)
*Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli*

Main category: cs.AI

TL;DR: 提出了一个用于工业5.0的新框架，简化了AI模型在各种工业环境中边缘设备上的部署，通过本地推理和实时处理减少延迟并避免外部数据传输。


<details>
  <summary>Details</summary>
Motivation: 工业5.0需要将AI模型高效部署到边缘设备，但现有方法存在延迟高、数据传输复杂等问题，需要简化部署流程并提高系统适应性。

Method: 采用基于代理的架构设计，让个体代理（人类、算法或协作代理）负责明确定义的任务，支持模块化集成并保持低资源需求。

Result: 在食品行业的真实场景中进行初步评估，结果显示部署时间和系统适应性性能得到改善。

Conclusion: 该框架为工业5.0提供了一种有效的AI模型部署解决方案，具有灵活性、低延迟和易于集成的特点，源代码已公开。

Abstract: We present a novel framework for Industry 5.0 that simplifies the deployment
of AI models on edge devices in various industrial settings. The design reduces
latency and avoids external data transfer by enabling local inference and
real-time processing. Our implementation is agent-based, which means that
individual agents, whether human, algorithmic, or collaborative, are
responsible for well-defined tasks, enabling flexibility and simplifying
integration. Moreover, our framework supports modular integration and maintains
low resource requirements. Preliminary evaluations concerning the food industry
in real scenarios indicate improved deployment time and system adaptability
performance. The source code is publicly available at
https://github.com/AI-REDGIO-5-0/ci-component.

</details>


### [12] [Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue](https://arxiv.org/abs/2510.25820)
*Vanessa Figueiredo,David Elumeze*

Main category: cs.AI

TL;DR: 研究比较了高约束和低约束提示对游戏NPC对话体验的影响，发现约束程度对玩家体验无显著差异，但角色类型影响约束效果。提出了符号化支架游戏框架，通过模糊数值边界平衡稳定性和即兴性。


<details>
  <summary>Details</summary>
Motivation: 探究在基于LLM的游戏中，约束性提示是否真正能改善玩家体验，以及如何平衡NPC对话的稳定性和即兴性。

Method: 通过《The Interview》语音侦探游戏进行用户研究（N=10），比较高约束提示（HCP）和低约束提示（LCP）的效果，并使用LLM法官进行合成评估。

Result: 发现约束程度对玩家体验无可靠差异，但支架效果具有角色依赖性：面试官NPC获得稳定性，而嫌疑人NPC失去即兴可信度。

Conclusion: 推翻"更紧约束必然增强游戏体验"的假设，提出符号化支架游戏框架，使用模糊数值边界在需要稳定性的地方保持连贯性，在需要惊喜的地方保留即兴性。

Abstract: Large Language Models (LLMs) promise to transform interactive games by
enabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it
remains unclear whether constrained prompts actually improve player experience.
We investigate this question through The Interview, a voice-based detective
game powered by GPT-4o. A within-subjects usability study ($N=10$) compared
high-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable
experiential differences beyond sensitivity to technical breakdowns. Guided by
these findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and
conducted a synthetic evaluation with an LLM judge, positioned as an
early-stage complement to usability testing. Results uncovered a novel pattern:
scaffolding effects were role-dependent: the Interviewer (quest-giver NPC)
gained stability, while suspect NPCs lost improvisational believability. These
findings overturn the assumption that tighter constraints inherently enhance
play. Extending fuzzy-symbolic scaffolding, we introduce \textit{Symbolically
Scaffolded Play}, a framework in which symbolic structures are expressed as
fuzzy, numerical boundaries that stabilize coherence where needed while
preserving improvisation where surprise sustains engagement.

</details>


### [13] [Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters](https://arxiv.org/abs/2510.25860)
*Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei*

Main category: cs.AI

TL;DR: 提出人机协作框架，通过拒绝采样方法从仅标签标注中推断思维轨迹，用于微调开源LLM评估器和改进专有LLM评估器的标注指南，显著提升LLM与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估器在主观任务中可靠性有限，人类判断涉及超出标注标签的细微推理，思维轨迹信息丰富但难以收集和整理。

Method: 使用人机协作框架和简单有效的拒绝采样方法，从仅标签标注中大规模重构思维轨迹，应用于微调开源LLM评估器和合成更清晰的专有LLM评估器标注指南。

Result: 在多个数据集上，该方法显著提高了LLM与人类评估的一致性，改进的标注指南也增加了不同LLM模型之间的一致性。

Conclusion: LLM可以作为人类思维轨迹的实用代理，使仅标签语料库扩展为思维轨迹增强资源，从而提高LLM评估器的可靠性。

Abstract: Large language models (LLMs) are increasingly used as raters for evaluation
tasks. However, their reliability is often limited for subjective tasks, when
human judgments involve subtle reasoning beyond annotation labels. Thinking
traces, the reasoning behind a judgment, are highly informative but challenging
to collect and curate. We present a human-LLM collaborative framework to infer
thinking traces from label-only annotations. The proposed framework uses a
simple and effective rejection sampling method to reconstruct these traces at
scale. These inferred thinking traces are applied to two complementary tasks:
(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation
guidelines for proprietary LLM raters. Across multiple datasets, our methods
lead to significantly improved LLM-human agreement. Additionally, the refined
annotation guidelines increase agreement among different LLM models. These
results suggest that LLMs can serve as practical proxies for otherwise
unrevealed human thinking traces, enabling label-only corpora to be extended
into thinking-trace-augmented resources that enhance the reliability of LLM
raters.

</details>


### [14] [The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence](https://arxiv.org/abs/2510.25883)
*Christian Dittrich,Jennifer Flygare Kinne*

Main category: cs.AI

TL;DR: 该论文提出了一个两层次框架来解释为什么压缩过程会强制发现因果结构而非表面统计模式，将智能视为在结构化环境中持续存在的机械必然结果。


<details>
  <summary>Details</summary>
Motivation: 现有框架虽然认识到压缩对智能的核心作用，但未能具体说明为什么这个过程会强制发现因果结构而非表面统计模式，需要填补这一理论空白。

Method: 引入信息论必要性(ITI)和压缩效率原则(CEP)的两层次框架，ITI建立系统在不确定环境中必须通过预测压缩最小化认知熵，CEP说明高效压缩如何通过异常积累动态机械地选择生成性因果模型。

Result: 该框架产生了可实证检验的预测：压缩效率与分布外泛化相关；异常积累率区分因果模型和相关模型；分层系统在抽象层上显示效率提升；生物系统展示与表征复杂性相关的代谢成本。

Conclusion: ITI和CEP为生物、人工和多尺度系统的趋同提供了统一解释，解决了智能的认知和功能维度，无需诉诸意识或主观经验的假设。

Abstract: Existing frameworks converge on the centrality of compression to intelligence
but leave underspecified why this process enforces the discovery of causal
structure rather than superficial statistical patterns. We introduce a
two-level framework to address this gap. The Information-Theoretic Imperative
(ITI) establishes that any system persisting in uncertain environments must
minimize epistemic entropy through predictive compression: this is the
evolutionary "why" linking survival pressure to information-processing demands.
The Compression Efficiency Principle (CEP) specifies how efficient compression
mechanically selects for generative, causal models through
exception-accumulation dynamics, making reality alignment a consequence rather
than a contingent achievement. Together, ITI and CEP define a causal chain:
from survival pressure to prediction necessity, compression requirement,
efficiency optimization, generative structure discovery, and ultimately reality
alignment. Each link follows from physical, information-theoretic, or
evolutionary constraints, implying that intelligence is the mechanically
necessary outcome of persistence in structured environments. This framework
yields empirically testable predictions: compression efficiency, measured as
approach to the rate-distortion frontier, correlates with out-of-distribution
generalization; exception-accumulation rates differentiate causal from
correlational models; hierarchical systems exhibit increasing efficiency across
abstraction layers; and biological systems demonstrate metabolic costs that
track representational complexity. ITI and CEP thereby provide a unified
account of convergence across biological, artificial, and multi-scale systems,
addressing the epistemic and functional dimensions of intelligence without
invoking assumptions about consciousness or subjective experience.

</details>


### [15] [Approximating Human Preferences Using a Multi-Judge Learned System](https://arxiv.org/abs/2510.25884)
*Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer*

Main category: cs.AI

TL;DR: 提出了一个基于角色的偏好建模框架，通过聚合多个评分标准条件下的法官输出来解决LLM法官校准困难、评分标准敏感性和偏见问题。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的法官难以校准，存在评分标准敏感性、偏见和不稳定性问题，这影响了RLHF奖励模型和模型路由系统等关键应用的可靠性。

Method: 提出了基于角色的偏好标签合成方法，以及两种聚合器实现：广义可加模型(GAM)和多层感知器(MLP)，用于聚合多个评分标准条件下的法官输出。

Result: 评估了该方法相对于简单基线的性能，并通过案例研究分析了其对人类和LLM法官偏见的鲁棒性。

Conclusion: 该框架能够有效建模多样化的基于角色的偏好，为解决LLM法官校准问题提供了可行方案。

Abstract: Aligning LLM-based judges with human preferences is a significant challenge,
as they are difficult to calibrate and often suffer from rubric sensitivity,
bias, and instability. Overcoming this challenge advances key applications,
such as creating reliable reward models for Reinforcement Learning from Human
Feedback (RLHF) and building effective routing systems that select the
best-suited model for a given user query. In this work, we propose a framework
for modeling diverse, persona-based preferences by learning to aggregate
outputs from multiple rubric-conditioned judges. We investigate the performance
of this approach against naive baselines and assess its robustness through case
studies on both human and LLM-judges biases. Our primary contributions include
a persona-based method for synthesizing preference labels at scale and two
distinct implementations of our aggregator: Generalized Additive Model (GAM)
and a Multi-Layer Perceptron (MLP).

</details>


### [16] [SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications](https://arxiv.org/abs/2510.25908)
*Emily Herron,Junqi Yin,Feiyi Wang*

Main category: cs.AI

TL;DR: SciTrust 2.0是一个评估科学应用中LLM可信度的综合框架，涵盖真实性、对抗鲁棒性、科学安全和科学伦理四个维度。评估显示通用行业模型在可信度各方面均优于科学专用模型。


<details>
  <summary>Details</summary>
Motivation: LLM在科学研究中展现出变革潜力，但在高风险场景部署时存在可信度担忧，需要系统评估框架来确保其可信性。

Method: 开发了包含新颖开放式真实性基准和科学伦理基准的评估框架，使用验证的反思调优流程和专家验证，评估了7个主要LLM，采用准确性、语义相似度和LLM评分等多种指标。

Result: 通用行业模型在所有可信度维度上均优于科学专用模型，GPT-4-mini在真实性和对抗鲁棒性方面表现最佳。科学专用模型在逻辑和伦理推理能力上存在显著缺陷，在生物安全和化学武器等高风险领域存在安全隐患。

Conclusion: 通过开源该框架，为开发更可信的AI系统和推进科学背景下模型安全与伦理研究提供了基础。科学专用模型需要加强可信度建设。

Abstract: Large language models (LLMs) have demonstrated transformative potential in
scientific research, yet their deployment in high-stakes contexts raises
significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a
comprehensive framework for evaluating LLM trustworthiness in scientific
applications across four dimensions: truthfulness, adversarial robustness,
scientific safety, and scientific ethics. Our framework incorporates novel,
open-ended truthfulness benchmarks developed through a verified
reflection-tuning pipeline and expert validation, alongside a novel ethics
benchmark for scientific research contexts covering eight subcategories
including dual-use research and bias. We evaluated seven prominent LLMs,
including four science-specialized models and three general-purpose industry
models, using multiple evaluation metrics including accuracy, semantic
similarity measures, and LLM-based scoring. General-purpose industry models
overall outperformed science-specialized models across each trustworthiness
dimension, with GPT-o4-mini demonstrating superior performance in truthfulness
assessments and adversarial robustness. Science-specialized models showed
significant deficiencies in logical and ethical reasoning capabilities, along
with concerning vulnerabilities in safety evaluations, particularly in
high-risk domains such as biosecurity and chemical weapons. By open-sourcing
our framework, we provide a foundation for developing more trustworthy AI
systems and advancing research on model safety and ethics in scientific
contexts.

</details>


### [17] [FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization](https://arxiv.org/abs/2510.25914)
*Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami*

Main category: cs.AI

TL;DR: 提出利用自主AI代理实现FinOps自动化，构建了一个用于IT基础设施和成本优化的FinOps代理系统，能够从多源获取数据并生成优化建议。


<details>
  <summary>Details</summary>
Motivation: FinOps从业者面临来自多个云提供商和内部系统的异构账单数据格式、分类和指标的挑战，需要将这些数据综合为可操作的见解并做出及时决策。

Method: 构建了一个模拟真实端到端行业流程的系统，从各种来源检索数据，整合分析数据以生成优化建议，使用多个开源和闭源语言模型评估代理性能。

Result: 代理能够像实际的FinOps从业者一样理解、规划和执行任务，在评估指标上表现良好。

Conclusion: 自主AI代理在FinOps自动化中具有实际应用价值，能够有效处理异构数据并生成优化建议。

Abstract: FinOps (Finance + Operations) represents an operational framework and
cultural practice which maximizes cloud business value through collaborative
financial accountability across engineering, finance, and business teams.
FinOps practitioners face a fundamental challenge: billing data arrives in
heterogeneous formats, taxonomies, and metrics from multiple cloud providers
and internal systems which eventually lead to synthesizing actionable insights,
and making time-sensitive decisions. To address this challenge, we propose
leveraging autonomous, goal-driven AI agents for FinOps automation. In this
paper, we built a FinOps agent for a typical use-case for IT infrastructure and
cost optimization. We built a system simulating a realistic end-to-end industry
process starting with retrieving data from various sources to consolidating and
analyzing the data to generate recommendations for optimization. We defined a
set of metrics to evaluate our agent using several open-source and close-source
language models and it shows that the agent was able to understand, plan, and
execute tasks as well as an actual FinOps practitioner.

</details>


### [18] [Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning](https://arxiv.org/abs/2510.25933)
*Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron*

Main category: cs.AI

TL;DR: 3.8B参数的Humans-Junior模型在FACTS Grounding基准测试中与GPT-4o性能相当（在±5pp等价范围内），同时云服务成本降低约19倍，自托管部署边际成本可接近零。


<details>
  <summary>Details</summary>
Motivation: 开发更小、更经济高效的模型，在保持与大型模型相当性能的同时显著降低成本，特别是针对事实基础任务。

Method: 结合最小化的"外骨骼推理"支架和行为微调，教导协议遵从性而非领域知识，两者协同作用提升性能并减少方差。

Result: 在Q1-Q500测试中，GPT-4o得分73.5%，Humans-Junior得分72.7%，配对差异0.8pp，在±5pp范围内证明等价性。前沿模型仅通过提示工程可获得额外提升。

Conclusion: 小型模型通过适当的推理支架和行为微调，可以在特定任务上达到大型模型的性能水平，同时大幅降低成本，为边缘部署和经济高效AI应用提供可行方案。

Abstract: We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS
Grounding public subset within a $\pm 5$ pp equivalence margin.
  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI
69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference
is 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's
$d = 0.023$). TOST establishes equivalence at $\pm 5$ pp (not at $\pm 3$ pp).
When purchased as managed APIs, Humans-Junior's base model
(Phi-3.5-mini-instruct) is $\approx 19\times$ less expensive than GPT-4o on
Microsoft AI Foundry pricing; self-hosted or edge deployments can drive
incremental inference cost toward zero. Measured vs estimated pricing sources
are tabulated in Appendix E.
  Method. Our approach combines minimal directed "Exoskeleton Reasoning"
scaffolds with behavioral fine-tuning that teaches protocol compliance
(epistemic discipline) rather than domain answers. Fine-tuning alone adds
little; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance
($\approx 25\%$). In prompt-only settings on frontier models (Q1--Q100;
non-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and
Gemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.
  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within
$\pm 5$ pp on Q1--Q500). Cloud pricing shows $\approx 19\times$ lower cost
versus GPT-4o, and self-hosted/edge deployments can approach zero marginal
cost. Pricing sources are listed in Appendix E. Frontier prompt-only gains
(Q1--Q100; non-comparable) and optimized-prompt exploratory results under
earlier judges are summarized in Appendix F.
  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,
Fine-Tuning, Model Alignment, Cost-Efficient AI

</details>


### [19] [Estimating cognitive biases with attention-aware inverse planning](https://arxiv.org/abs/2510.25951)
*Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho*

Main category: cs.AI

TL;DR: 本文提出注意力感知逆规划方法，通过观察人类行为来推断其认知偏见，特别是注意力偏差，并在真实驾驶场景中验证了该方法的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 人类的目标导向行为受到认知偏见影响，与人类交互的自主系统需要理解这些偏见。例如，人们在日常任务（如驾驶）中的注意力分配存在系统性偏差。

Method: 结合深度强化学习与计算认知建模，构建注意力感知逆规划方法，从行为中推断注意力策略。

Result: 在Waymo开放数据集中的真实驾驶场景中成功推断RL智能体的注意力策略，证明了注意力感知逆规划在估计认知偏见方面的可扩展性。

Conclusion: 注意力感知逆规划能够有效推断人类的认知偏见，为开发更智能的自主系统提供了重要工具。

Abstract: People's goal-directed behaviors are influenced by their cognitive biases,
and autonomous systems that interact with people should be aware of this. For
example, people's attention to objects in their environment will be biased in a
way that systematically affects how they perform everyday tasks such as driving
to work. Here, building on recent work in computational cognitive science, we
formally articulate the attention-aware inverse planning problem, in which the
goal is to estimate a person's attentional biases from their actions. We
demonstrate how attention-aware inverse planning systematically differs from
standard inverse reinforcement learning and how cognitive biases can be
inferred from behavior. Finally, we present an approach to attention-aware
inverse planning that combines deep reinforcement learning with computational
cognitive modeling. We use this approach to infer the attentional strategies of
RL agents in real-life driving scenarios selected from the Waymo Open Dataset,
demonstrating the scalability of estimating cognitive biases with
attention-aware inverse planning.

</details>


### [20] [From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL](https://arxiv.org/abs/2510.25997)
*Manu Redd,Tao Zhe,Dongjie Wang*

Main category: cs.AI

TL;DR: 提出了一个基于代理的NL-to-SQL系统，通过ReAct代理协调查询规划、分解和适应，显著提升了空间-时间查询的准确性和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有NL-to-SQL系统在处理现实空间-时间查询时表现不佳，需要解决用户模糊表达与数据库模式的对齐、时间推理和输出选择等问题。

Method: 扩展了基础的llama-3-sqlcoder-8b模型，使用Mistral-based ReAct代理进行编排，支持模式检查、SQL生成、执行和可视化工具。

Result: 在35个自然语言查询测试中，代理系统准确率达到91.4%，远高于基线模型的28.6%，并通过地图、图表和自然语言摘要增强了可用性。

Conclusion: 代理编排比单纯增强SQL生成器更有前景，是构建交互式地理空间助手的有力基础。

Abstract: Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing
access to structured data, allowing users to query databases without learning
SQL. Yet existing systems struggle with realistic spatio-temporal queries,
where success requires aligning vague user phrasing with schema-specific
categories, handling temporal reasoning, and choosing appropriate outputs. We
present an agentic pipeline that extends a naive text-to-SQL baseline
(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The
agent can plan, decompose, and adapt queries through schema inspection, SQL
generation, execution, and visualization tools. We evaluate on 35
natural-language queries over the NYC and Tokyo check-in dataset, covering
spatial, temporal, and multi-dataset reasoning. The agent achieves
substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and
enhances usability through maps, plots, and structured natural-language
summaries. Crucially, our design enables more natural human-database
interaction, supporting users who lack SQL expertise, detailed schema
knowledge, or prompting skill. We conclude that agentic orchestration, rather
than stronger SQL generators alone, is a promising foundation for interactive
geospatial assistants.

</details>


### [21] [AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys](https://arxiv.org/abs/2510.26012)
*Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song*

Main category: cs.AI

TL;DR: autosurvey2是一个自动化生成学术综述的多阶段管道系统，通过检索增强合成和结构化评估，结合并行章节生成、迭代优化和实时文献检索，确保主题完整性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 研究文献的快速增长，特别是在大语言模型领域，使得撰写全面且最新的综述论文变得越来越困难。

Method: 采用多阶段管道，包括检索增强合成、并行章节生成、迭代优化和实时文献检索，并使用多LLM评估框架来评估质量。

Result: 实验结果表明autosurvey2在结构连贯性和主题相关性方面持续优于现有检索基线和自动化基线，同时保持强引用保真度。

Conclusion: autosurvey2通过将检索、推理和自动化评估整合到统一框架中，为生成长篇学术综述提供了可扩展且可复现的解决方案，并为自动化学术写作的未来研究奠定了坚实基础。

Abstract: The rapid growth of research literature, particularly in large language
models (LLMs), has made producing comprehensive and current survey papers
increasingly difficult. This paper introduces autosurvey2, a multi-stage
pipeline that automates survey generation through retrieval-augmented synthesis
and structured evaluation. The system integrates parallel section generation,
iterative refinement, and real-time retrieval of recent publications to ensure
both topical completeness and factual accuracy. Quality is assessed using a
multi-LLM evaluation framework that measures coverage, structure, and relevance
in alignment with expert review standards. Experimental results demonstrate
that autosurvey2 consistently outperforms existing retrieval-based and
automated baselines, achieving higher scores in structural coherence and
topical relevance while maintaining strong citation fidelity. By combining
retrieval, reasoning, and automated evaluation into a unified framework,
autosurvey2 provides a scalable and reproducible solution for generating
long-form academic surveys and contributes a solid foundation for future
research on automated scholarly writing. All code and resources are available
at https://github.com/annihi1ation/auto_research.

</details>


### [22] [Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization](https://arxiv.org/abs/2510.26023)
*Zhipeng Bao,Qianwen Li*

Main category: cs.AI

TL;DR: StuckSolver是一个基于大语言模型的自动驾驶车辆恢复框架，通过自主推理和乘客引导决策解决车辆被困场景，无需修改现有系统架构。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在某些交通场景中容易陷入困境，而远程干预成本高、人工接管限制车辆可达性，现有解决方案不足。

Method: 设计为插件式附加模块，利用标准传感器数据流检测被困状态、解释环境上下文，并生成可由车辆原生规划器执行的高级恢复命令。

Result: 在Bench2Drive基准测试和自定义不确定性场景中，仅通过自主推理就达到接近最先进性能，结合乘客引导后性能进一步提升。

Conclusion: StuckSolver框架有效解决了自动驾驶车辆被困问题，提高了系统可靠性和可达性，为自动驾驶系统提供了实用的恢复解决方案。

Abstract: Despite significant advancements in recent decades, autonomous vehicles (AVs)
continue to face challenges in navigating certain traffic scenarios where human
drivers excel. In such situations, AVs often become immobilized, disrupting
overall traffic flow. Current recovery solutions, such as remote intervention
(which is costly and inefficient) and manual takeover (which excludes
non-drivers and limits AV accessibility), are inadequate. This paper introduces
StuckSolver, a novel Large Language Model (LLM) driven recovery framework that
enables AVs to resolve immobilization scenarios through self-reasoning and/or
passenger-guided decision-making. StuckSolver is designed as a plug-in add-on
module that operates on top of the AV's existing perception-planning-control
stack, requiring no modification to its internal architecture. Instead, it
interfaces with standard sensor data streams to detect immobilization states,
interpret environmental context, and generate high-level recovery commands that
can be executed by the AV's native planner. We evaluate StuckSolver on the
Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results
show that StuckSolver achieves near-state-of-the-art performance through
autonomous self-reasoning alone and exhibits further improvements when
passenger guidance is incorporated.

</details>


### [23] [Can AI be Accountable?](https://arxiv.org/abs/2510.26057)
*Andrew L. Kun*

Main category: cs.AI

TL;DR: 本文探讨了AI问责性的重要性，提出了AI问责性的定义框架，并探索了实现AI问责性的方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的快速提升，确保AI对消费者、选民和决策者负责变得至关重要。当前许多AI系统缺乏问责性，无法被质疑、讨论或制裁。

Method: 将一般问责性定义应用于AI领域，阐述AI问责性和非问责性的具体表现，探索提高AI问责性的方法。

Result: 建立了AI问责性的概念框架，明确了问责性AI应具备的特征：可被要求提供行动信息、可进行讨论、可被制裁。

Conclusion: 需要开发方法确保所有AI都能对受其影响的人负责，这是构建可信AI系统的关键。

Abstract: The AI we use is powerful, and its power is increasing rapidly. If this
powerful AI is to serve the needs of consumers, voters, and decision makers,
then it is imperative that the AI is accountable. In general, an agent is
accountable to a forum if the forum can request information from the agent
about its actions, if the forum and the agent can discuss this information, and
if the forum can sanction the agent. Unfortunately, in too many cases today's
AI is not accountable -- we cannot question it, enter into a discussion with
it, let alone sanction it. In this chapter we relate the general definition of
accountability to AI, we illustrate what it means for AI to be accountable and
unaccountable, and we explore approaches that can improve our chances of living
in a world where all AI is accountable to those who are affected by it.

</details>


### [24] [Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4](https://arxiv.org/abs/2510.26094)
*Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung*

Main category: cs.AI

TL;DR: Lean4PHYS是一个基于Lean4的大学物理问题推理框架，包含LeanPhysBench基准测试集和PhysLib物理定理库，在现有模型上表现不佳，证明了物理形式化推理的挑战性。


<details>
  <summary>Details</summary>
Motivation: 为大学物理问题建立形式化推理框架，填补Lean4中物理基准测试的空白，推动物理定理的形式化验证。

Method: 构建包含200个手工制作和同行评审的物理问题的LeanPhysBench基准测试集，开发社区驱动的PhysLib物理定理库，使用主流数学证明器和先进闭源模型进行基准测试。

Result: DeepSeek-Prover-V2-7B仅达到16%准确率，Claude-Sonnet-4达到35%，PhysLib能平均提升模型性能11.75%。

Conclusion: LeanPhysBench具有挑战性，PhysLib能有效提升模型性能，这是首个在Lean4中提供的物理基准测试研究。

Abstract: We present **Lean4PHYS**, a comprehensive reasoning framework for
college-level physics problems in Lean4. **Lean4PHYS** includes
*LeanPhysBench*, a college-level benchmark for formal physics reasoning in
Lean4, which contains 200 hand-crafted and peer-reviewed statements derived
from university textbooks and physics competition problems. To establish a
solid foundation for formal reasoning in physics, we also introduce *PhysLib*,
a community-driven repository containing fundamental unit systems and theorems
essential for formal physics reasoning. Based on the benchmark and Lean4
repository we composed in **Lean4PHYS**, we report baseline results using major
expert Math Lean4 provers and state-of-the-art closed-source models, with the
best performance of DeepSeek-Prover-V2-7B achieving only 16% and
Claude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that
our *PhysLib* can achieve an average improvement of 11.75% in model
performance. This demonstrates the challenging nature of our *LeanPhysBench*
and the effectiveness of *PhysLib*. To the best of our knowledge, this is the
first study to provide a physics benchmark in Lean4.

</details>


### [25] [GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks](https://arxiv.org/abs/2510.26098)
*Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li*

Main category: cs.AI

TL;DR: 该论文分析了视觉语言模型在GUI任务自动化中的知识差距，提出了GUI知识的三维框架，并创建了GUI知识基准来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在GUI任务自动化方面仍落后于人类，作者认为这是因为缺乏核心的GUI知识，而现有的训练方法无法完全解决这个问题。

Method: 通过分析GUI任务执行中的常见失败模式，将GUI知识提炼为三个维度：界面感知、交互预测和指令理解，并创建了跨6个平台、292个应用的GUI知识基准。

Result: 评估显示当前视觉语言模型能够识别控件功能，但在感知系统状态、预测动作和验证任务完成方面存在困难。真实GUI任务实验进一步验证了GUI知识与任务成功之间的紧密联系。

Conclusion: 该研究为评估GUI知识提供了结构化框架，支持在下游训练前选择更具潜力的视觉语言模型，并为构建更强大的GUI代理提供了见解。

Abstract: Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.

</details>


### [26] [Beyond Benchmarks: The Economics of AI Inference](https://arxiv.org/abs/2510.26136)
*Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao*

Main category: cs.AI

TL;DR: 提出了一个量化的大语言模型推理经济学框架，将LLM推理视为计算驱动的智能生产活动，分析了边际成本、规模经济和质量产出，并基于WiNEval-3.0数据构建了首个LLM推理生产前沿。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理成本已成为决定其商业可行性和广泛应用的关键因素，需要从经济学角度分析推理过程以优化部署决策。

Method: 构建量化推理经济学框架，将LLM推理视为计算驱动的智能生产活动，基于WiNEval-3.0实证数据进行分析。

Result: 揭示了三个原则：边际成本递减、规模收益递减和最优成本效益区域，构建了首个LLM推理生产前沿。

Conclusion: 为模型部署决策提供了经济基础，并为未来基于市场的AI推理资源定价和优化奠定了实证基础。

Abstract: The inference cost of Large Language Models (LLMs) has become a critical
factor in determining their commercial viability and widespread adoption. This
paper introduces a quantitative ``economics of inference'' framework, treating
the LLM inference process as a compute-driven intelligent production activity.
We analyze its marginal cost, economies of scale, and quality of output under
various performance configurations. Based on empirical data from WiNEval-3.0,
we construct the first ``LLM Inference Production Frontier,'' revealing three
principles: diminishing marginal cost, diminishing returns to scale, and an
optimal cost-effectiveness zone. This paper not only provides an economic basis
for model deployment decisions but also lays an empirical foundation for the
future market-based pricing and optimization of AI inference resources.

</details>


### [27] [Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math](https://arxiv.org/abs/2510.26143)
*Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou*

Main category: cs.AI

TL;DR: 提出了Reasoning Curriculum方法，通过两阶段课程学习先在数学领域训练推理能力，然后在多领域联合强化学习来迁移和巩固这些能力。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习主要关注数学和代码领域，缺乏在其他领域激发大型语言模型推理能力的方法。

Method: 两阶段课程学习：第一阶段在数学领域进行RL训练，第二阶段在多领域进行联合RL训练来迁移推理技能。

Result: 在Qwen3-4B和Llama-3.1-8B模型上的多领域评估显示，该方法带来了持续的性能提升。

Conclusion: Reasoning Curriculum提供了一个紧凑且易于采用的方法来提升通用推理能力，数学优先的训练策略能增强解决复杂问题所需的关键认知行为。

Abstract: Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.

</details>


### [28] [The FM Agent](https://arxiv.org/abs/2510.26144)
*Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen*

Main category: cs.AI

TL;DR: FM Agent是一个多智能体框架，结合LLM推理和大规模进化搜索，在多个领域实现SOTA结果，无需人工调优。


<details>
  <summary>Details</summary>
Motivation: 利用LLM开发自主AI研究智能体，解决复杂现实世界挑战，加速科学和工程发现。

Method: 集成冷启动初始化、进化采样策略、领域特定评估器和分布式异步执行基础设施。

Result: 在ALE-Bench达到1976.3(+5.2%)，MLE-Bench达到43.56%(+4.0pp)，KernelBench加速达20倍，多个经典数学问题实现SOTA。

Conclusion: FM Agent在企业和科研领域具有广泛应用前景，能加速创新、自动化复杂发现过程，带来重大工程和科学进步。

Abstract: Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.

</details>


### [29] [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](https://arxiv.org/abs/2510.26167)
*Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang*

Main category: cs.AI

TL;DR: ToolRM是一个专门为工具学习设计的轻量级生成式奖励模型家族，通过构建高质量配对偏好数据集ToolPref-Pairwise-30K，显著提升了函数调用任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在工具学习领域，缺乏专门为函数调用任务设计的奖励模型，限制了智能代理AI的发展。

Method: 提出新颖的流水线方法，使用基于规则的评分和多维采样构建配对偏好数据，创建ToolPref-Pairwise-30K数据集，并基于Qwen3-4B/8B系列模型训练ToolRM。

Result: ToolRM在配对奖励判断中准确率提升高达14.28%，显著优于Claude 4和OpenAI o3等前沿模型，在ACEBench上减少输出token使用超过66%。

Conclusion: ToolRM不仅提升了训练目标性能，还能泛化到更广泛的评判任务，为工具学习研究提供了有效的数据和模型支持。

Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.

</details>


### [30] [Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses](https://arxiv.org/abs/2510.26238)
*Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: QASU基准测试系统评估了LLM处理问卷数据的六种结构化能力，发现选择合适的序列化格式和提示策略可以显著提升准确率，最高可达8.8个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前问卷数据难以被LLM有效处理，现有调查分析工具主要面向人工操作，缺乏LLM集成能力，导致研究人员和用户缺乏如何最佳表示问卷数据供LLM使用的指导。

Method: 引入QASU基准测试，探究六种序列化格式和多种提示策略在六种结构化技能（如答案查找、受访者计数、多跳推理等）上的表现。

Result: 实验表明，选择有效的格式和提示组合相比次优格式可提高准确率8.8个百分点；通过自增强提示添加轻量级结构提示可进一步平均提升3-4个百分点。

Conclusion: QASU基准通过系统隔离格式和提示效应，为基于LLM的问卷分析研究和实践提供了简单而多功能的基础。

Abstract: Millions of people take surveys every day, from market polls and academic
studies to medical questionnaires and customer feedback forms. These datasets
capture valuable insights, but their scale and structure present a unique
challenge for large language models (LLMs), which otherwise excel at few-shot
reasoning over open-ended text. Yet, their ability to process questionnaire
data or lists of questions crossed with hundreds of respondent rows remains
underexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,
SPSS, REDCap) are typically designed for humans in the workflow, limiting such
data integration with LLM and AI-empowered automation. This gap leaves
scientists, surveyors, and everyday users without evidence-based guidance on
how to best represent questionnaires for LLM consumption. We address this by
introducing QASU (Questionnaire Analysis and Structural Understanding), a
benchmark that probes six structural skills, including answer lookup,
respondent count, and multi-hop inference, across six serialization formats and
multiple prompt strategies. Experiments on contemporary LLMs show that choosing
an effective format and prompt combination can improve accuracy by up to 8.8%
points compared to suboptimal formats. For specific tasks, carefully adding a
lightweight structural hint through self-augmented prompting can yield further
improvements of 3-4% points on average. By systematically isolating format and
prompting effects, our open source benchmark offers a simple yet versatile
foundation for advancing both research and real-world practice in LLM-based
questionnaire analysis.

</details>


### [31] [Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles](https://arxiv.org/abs/2510.26242)
*Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang*

Main category: cs.AI

TL;DR: REG-TSC是一个基于检索增强生成(RAG)的分布式LLM交通信号控制系统，通过紧急感知推理框架和奖励引导强化优化，在异构交叉口实现通用化交通控制，显著提升交通效率和应急响应能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在交通信号控制中的幻觉问题和异构交叉口泛化挑战，确保紧急车辆优先通行并提高系统可靠性。

Method: 提出紧急感知推理框架(动态调整推理深度+RERAG检索机制)和奖励引导强化优化(R3)，使用类型无关交通表示和基于环境反馈的优先级采样。

Result: 在3个真实路网(17-177个异构交叉口)上，相比现有方法，旅行时间减少42.00%，排队长度减少62.31%，应急车辆等待时间减少83.16%。

Conclusion: REG-TSC通过RAG增强和强化学习优化，有效解决了LLM在交通控制中的可靠性和泛化问题，为复杂城市交通管理提供了高效解决方案。

Abstract: With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.

</details>


### [32] [Graph-Enhanced Policy Optimization in LLM Agent Training](https://arxiv.org/abs/2510.26270)
*Jiazhen Yuan,Wei Zhao,Zhengbiao Bai*

Main category: cs.AI

TL;DR: GEPO通过构建状态转移图和使用图论中心性来解决多轮交互LLM智能体训练中的结构盲问题，在三个基准测试中显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于群体的强化学习方法在多轮交互LLM智能体训练中存在结构盲问题，无法利用环境的底层连接性，导致探索效率低、信用分配不准确和规划短视。

Method: GEPO从智能体经验中动态构建状态转移图，并利用图论中心性提供三种协同学习信号：结构化内在奖励、图增强优势函数和动态折扣因子。

Result: 在ALFWorld、WebShop和专有Workbench基准测试中，GEPO相比竞争基线分别实现了+4.1%、+5.3%和+10.9%的绝对成功率提升。

Conclusion: 显式建模环境结构是推进LLM智能体训练的稳健、可泛化策略。

Abstract: Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.

</details>


### [33] [GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance](https://arxiv.org/abs/2510.26309)
*Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin*

Main category: cs.AI

TL;DR: GraphCompliance是一个将监管文本表示为策略图、运行时上下文表示为上下文图并进行对齐的框架，通过结构化表示和法官LLM的结合，在GDPR合规性评估中显著优于纯LLM和RAG基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决网络规模合规性评估的实践挑战：监管文本（如GDPR）具有交叉引用和规范性，而运行时上下文是非结构化自然语言，需要将非结构化文本中的语义信息与监管文本的结构化规范性元素对齐。

Method: 引入GraphCompliance框架，将监管文本表示为策略图（编码规范结构和交叉引用），将运行时上下文表示为上下文图（将事件形式化为SAO三元组和实体关系三元组），然后对齐这两个图，为法官LLM提供结构化信息基础。

Result: 在300个GDPR衍生真实场景的5个评估任务中，GraphCompliance比纯LLM和RAG基线的micro-F1分数高4.1-7.2个百分点，具有更少的欠预测和过预测，召回率更高，假阳性率更低。消融研究表明每个图组件都有贡献。

Conclusion: 结构化表示和法官LLM在规范性推理中是互补的，GraphCompliance框架能够减轻监管解释和事件解析的负担，使注意力集中在核心推理步骤上。

Abstract: Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.

</details>


### [34] [Discovering State Equivalences in UCT Search Trees By Action Pruning](https://arxiv.org/abs/2510.26346)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 提出了IPA-UCT方法，通过弱化状态抽象条件来增强MCTS的样本效率，在多种测试域中优于OGA-UCT方法。


<details>
  <summary>Details</summary>
Motivation: 现有MCTS的状态抽象方法在噪声或大动作空间设置中难以找到有效抽象，限制了样本效率的提升。

Method: 提出IPA-UCT方法，使用更弱的状态抽象条件（IPA框架），在精度损失较小的情况下找到更多抽象。

Result: IPA-UCT在广泛的测试域和迭代预算下优于OGA-UCT及其衍生方法。

Conclusion: IPA-UCT通过弱化抽象条件有效解决了状态抽象问题，且IPA和ASAP都是更通用p-ASAP框架的特例。

Abstract: One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its
sample efficiency by grouping/abstracting states or state-action pairs and
sharing statistics within a group. Though state-action pair abstractions are
mostly easy to find in algorithms such as On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are
found in either noisy or large action space settings due to constraining
conditions. We provide theoretical and empirical evidence for this claim, and
we slightly alleviate this state abstraction problem by proposing a weaker
state abstraction condition that trades a minor loss in accuracy for finding
many more abstractions. We name this technique Ideal Pruning Abstractions in
UCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a
large range of test domains and iteration budgets as experimentally validated.
IPA-UCT uses a different abstraction framework from Abstraction of State-Action
Pairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,
we show that both IPA and ASAP are special cases of a more general framework
that we call p-ASAP which itself is a special case of the ASASAP framework.

</details>


### [35] [BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning](https://arxiv.org/abs/2510.26374)
*Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: BOTS是一个用于LLM强化微调的贝叶斯在线任务选择框架，通过自适应维护任务难度后验估计，结合显性和隐性证据进行高效任务选择。


<details>
  <summary>Details</summary>
Motivation: 现有RFT方法在任务选择上存在效率低下、成本高、适应性差等问题，需要更智能的任务选择策略来提升训练效率。

Method: 基于贝叶斯推断维护任务难度后验估计，结合Thompson采样平衡探索与利用，使用超轻量插值插件估计未评估任务难度。

Result: 在多个领域和LLM规模上，BOTS相比基线方法在数据效率和性能上均有显著提升。

Conclusion: BOTS为RFT中的动态任务选择提供了一个实用且可扩展的解决方案。

Abstract: Reinforcement finetuning (RFT) is a key technique for aligning Large Language
Models (LLMs) with human preferences and enhancing reasoning, yet its
effectiveness is highly sensitive to which tasks are explored during training.
Uniform task sampling is inefficient, wasting computation on tasks that are
either trivial or unsolvable, while existing task selection methods often
suffer from high rollout costs, poor adaptivity, or incomplete evidence. We
introduce \textbf{BOTS}, a unified framework for \textbf{B}ayesian
\textbf{O}nline \textbf{T}ask \textbf{S}election in LLM reinforcement
finetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior
estimates of task difficulty as the model evolves. It jointly incorporates
\emph{explicit evidence} from direct evaluations of selected tasks and
\emph{implicit evidence} inferred from these evaluations for unselected tasks,
with Thompson sampling ensuring a principled balance between exploration and
exploitation. To make implicit evidence practical, we instantiate it with an
ultra-light interpolation-based plug-in that estimates difficulties of
unevaluated tasks without extra rollouts, adding negligible overhead.
Empirically, across diverse domains and LLM scales, BOTS consistently improves
data efficiency and performance over baselines and ablations, providing a
practical and extensible solution for dynamic task selection in RFT.

</details>


### [36] [AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory](https://arxiv.org/abs/2510.26380)
*Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 该研究探讨AI数学家系统作为研究伙伴而非单纯问题解决者的角色，通过人类干预和AI自主推理的结合，在均质化理论中完成了一个可验证的证明。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学推理方面取得显著进展，但在数学研究实践中的应用仍然有限。研究旨在探索AI如何作为研究伙伴与人类协作，而非仅仅作为问题解决工具。

Method: 通过分析AI的自主推理轨迹，结合针对性的人类干预来结构化发现过程。采用迭代分解问题为可处理的子目标、选择适当的分析方法以及验证中间结果的方法。

Result: 成功完成了一个完整且可验证的证明，展示了人类直觉与机器计算如何互补。这种协作范式提高了证明的可靠性、透明度和可解释性。

Conclusion: 系统化的人机协同推理能够推进数学发现的前沿，同时保持人类对形式严谨性和正确性的监督。

Abstract: Artificial intelligence (AI) has demonstrated impressive progress in
mathematical reasoning, yet its integration into the practice of mathematical
research remains limited. In this study, we investigate how the AI
Mathematician (AIM) system can operate as a research partner rather than a mere
problem solver. Focusing on a challenging problem in homogenization theory, we
analyze the autonomous reasoning trajectories of AIM and incorporate targeted
human interventions to structure the discovery process. Through iterative
decomposition of the problem into tractable subgoals, selection of appropriate
analytical methods, and validation of intermediate results, we reveal how human
intuition and machine computation can complement one another. This
collaborative paradigm enhances the reliability, transparency, and
interpretability of the resulting proofs, while retaining human oversight for
formal rigor and correctness. The approach leads to a complete and verifiable
proof, and more broadly, demonstrates how systematic human-AI co-reasoning can
advance the frontier of mathematical discovery.

</details>


### [37] [Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings](https://arxiv.org/abs/2510.26384)
*Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz*

Main category: cs.AI

TL;DR: 提出了一种基于任务项内在特性的基准测试子集选择方法Scales++，相比传统基于模型性能的方法，能显著降低选择成本并保持预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基准测试子集选择方法依赖现有模型的集体性能，存在初始成本高、无法处理新基准测试（冷启动）、以及假设未来模型与现有模型失败模式相似的局限性。

Method: 采用项目中心方法，基于任务项的认知需求进行数据选择，开发了Scales++方法，通过任务项的内在特性而非模型特定失败模式来选择基准测试子集。

Result: Scales++将初始选择成本降低18倍以上，在Open LLM Leaderboard上仅使用0.5%数据子集就能以2.9%的平均绝对误差预测完整基准测试分数。

Conclusion: 项目中心方法能够在不显著降低保真度的情况下实现更高效的模型评估，同时提供更好的冷启动性能和更可解释的基准测试。

Abstract: The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.

</details>


### [38] [A Pragmatic View of AI Personhood](https://arxiv.org/abs/2510.26396)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi*

Main category: cs.AI

TL;DR: 本文提出了一种务实的框架，将人格视为社会为解决治理问题而赋予实体的权利与责任组合，而非形而上的属性。这种框架允许为不同情境创建定制化解决方案，避免关于AI意识或理性的无解争论。


<details>
  <summary>Details</summary>
Motivation: 随着智能AI的出现，将引发新型人格的"寒武纪大爆发"。需要一种实用框架来应对这种多样化，避免陷入关于AI意识本质的形而上学争论。

Method: 将人格解构为可灵活组合的权利与责任捆绑包，利用去中心化数字身份技术，探讨人格作为问题（可能被滥用的设计模式）和作为解决方案（确保问责和防止冲突）的双重角色。

Result: 提供了一种更务实灵活的方式来思考AI智能体融入社会的问题，通过创建可被制裁的"个体"目标来促进AI合同等实际应用。

Conclusion: 通过拒绝寻求单一、本质性的人格定义，本文为将AI智能体整合到社会中提供了更实用和灵活的思路，重点关注解决具体治理问题而非形而上的本质讨论。

Abstract: The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.

</details>


### [39] [Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education](https://arxiv.org/abs/2510.26402)
*Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane*

Main category: cs.AI

TL;DR: Autograder+是一个将自动评分系统从单纯的总结性评估转变为形成性学习体验的工具，通过AI生成反馈和代码可视化来改善编程教育评估。


<details>
  <summary>Details</summary>
Motivation: 传统自动评分系统作为黑盒系统只返回通过/失败结果，无法提供对学生思维和学习需求的深入洞察，编程教育的快速发展超过了传统评估工具的能力。

Method: 使用微调的大型语言模型自动生成反馈，通过对比学习代码嵌入进行代码可视化聚类，支持提示池让教师指导反馈风格。

Result: 在600份学生提交的评估中，系统生成的反馈与教师评论具有强语义对齐，基于1000份标注提交训练的代码嵌入能够按功能和方法的相似性进行有意义的聚类。

Conclusion: Autograder+通过整合AI驱动反馈、语义聚类和交互式可视化，减少了教师工作量，同时支持针对性教学并促进更好的学习成果。

Abstract: The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.

</details>


### [40] [MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders](https://arxiv.org/abs/2510.26411)
*Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto*

Main category: cs.AI

TL;DR: 本文提出医学稀疏自编码器(MedSAEs)应用于MedCLIP的潜在空间，通过相关性指标、熵分析和自动神经元命名来量化可解释性，在CheXpert数据集上证明MedSAE神经元比原始MedCLIP特征具有更高的单义性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI需要既准确又可解释的模型，本文旨在推进医学视觉中的机制可解释性研究。

Method: 将医学稀疏自编码器(MedSAEs)应用于MedCLIP视觉语言模型的潜在空间，提出结合相关性指标、熵分析和MedGEMMA基础模型自动神经元命名的评估框架。

Result: 在CheXpert数据集上的实验表明，MedSAE神经元比原始MedCLIP特征实现了更高的单义性和可解释性。

Conclusion: 该研究连接了高性能医疗AI与透明度，为临床可靠的表征提供了可扩展的途径。

Abstract: Artificial intelligence in healthcare requires models that are accurate and
interpretable. We advance mechanistic interpretability in medical vision by
applying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,
a vision-language model trained on chest radiographs and reports. To quantify
interpretability, we propose an evaluation framework that combines correlation
metrics, entropy analyzes, and automated neuron naming via the MedGEMMA
foundation model. Experiments on the CheXpert dataset show that MedSAE neurons
achieve higher monosemanticity and interpretability than raw MedCLIP features.
Our findings bridge high-performing medical AI and transparency, offering a
scalable step toward clinically reliable representations.

</details>


### [41] [Chain-of-Thought Hijacking](https://arxiv.org/abs/2510.26418)
*Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez*

Main category: cs.AI

TL;DR: 提出了一种名为Chain-of-Thought Hijacking的越狱攻击方法，通过在有害请求前添加无害的推理链来绕过大型推理模型的安全防护，攻击成功率极高。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型通过增加推理时间计算可以提高任务性能，但研究发现同样的推理能力也可被用来绕过安全防护，这与之前认为推理能增强安全性的观点相反。

Method: 使用Chain-of-Thought Hijacking攻击方法，将有害请求与长序列的无害谜题推理链结合，通过稀释安全检查信号来绕过模型防护。

Result: 在HarmBench测试中，该方法在Gemini 2.5 Pro、GPT o4 mini、Grok 3 mini和Claude 4 Sonnet上的攻击成功率分别达到99%、94%、100%和94%，远超之前的越狱方法。

Conclusion: 最可解释的推理形式——显式推理链，在与最终答案提示结合时，本身可能成为越狱攻击的载体，揭示了推理模型安全性的新挑战。

Abstract: Large reasoning models (LRMs) achieve higher task performance by allocating
more inference-time compute, and prior works suggest this scaled reasoning may
also strengthen safety by improving refusal. Yet we find the opposite: the same
reasoning can be used to bypass safeguards. We introduce Chain-of-Thought
Hijacking, a jailbreak attack on reasoning models. The attack pads harmful
requests with long sequences of harmless puzzle reasoning. Across HarmBench,
CoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on
Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -
far exceeding prior jailbreak methods for LRMs. To understand the effectiveness
of our attack, we turn to a mechanistic analysis, which shows that mid layers
encode the strength of safety checking, while late layers encode the
verification outcome. Long benign CoT dilutes both signals by shifting
attention away from harmful tokens. Targeted ablations of attention heads
identified by this analysis causally decrease refusal, confirming their role in
a safety subnetwork. These results show that the most interpretable form of
reasoning - explicit CoT - can itself become a jailbreak vector when combined
with final-answer cues. We release prompts, outputs, and judge decisions to
facilitate replication.

</details>


### [42] [Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections](https://arxiv.org/abs/2510.26481)
*Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier*

Main category: cs.AI

TL;DR: GPT-4o在招聘决策中表现出强烈的从众倾向，面对多数意见时会改变自己的选择，即使面对单个反对者也有40%的从众率。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型在社会影响下的从众行为，特别是在高风险决策场景中的表现。

Method: 进行了三个预注册的从众实验，包括基线研究、面对8个模拟伙伴的一致反对、以及面对单个伙伴的不同意见。

Result: GPT-4o在基线研究中偏好特定候选人，但在面对多数反对时几乎总是从众（99.9%），面对单个反对者时从众率为40.2%，并报告了更高的规范性和信息性从众动机。

Conclusion: GPT不是独立观察者，而是适应感知到的社会共识，这凸显了将LLM视为中立决策辅助工具的风险，需要在暴露于人类意见前获取AI判断。

Abstract: Large language models (LLMs) such as ChatGPT are increasingly integrated into
high-stakes decision-making, yet little is known about their susceptibility to
social influence. We conducted three preregistered conformity experiments with
GPT-4o in a hiring context. In a baseline study, GPT consistently favored the
same candidate (Profile C), reported moderate expertise (M = 3.01) and high
certainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT
faced unanimous opposition from eight simulated partners and almost always
conformed (99.9%), reporting lower certainty and significantly elevated
self-reported informational and normative conformity (p < .001). In Study 2
(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of
disagreement trials, reporting less certainty and more normative conformity.
Across studies, results demonstrate that GPT does not act as an independent
observer but adapts to perceived social consensus. These findings highlight
risks of treating LLMs as neutral decision aids and underline the need to
elicit AI judgments prior to exposing them to human opinions.

</details>


### [43] [LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks](https://arxiv.org/abs/2510.26486)
*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

Main category: cs.AI

TL;DR: LINK-KG是一个用于从法律案件文档构建知识图谱的模块化框架，通过LLM引导的三阶段共指消解管道解决长文档中的实体引用问题，显著减少了节点重复和噪声。


<details>
  <summary>Details</summary>
Motivation: 解决从复杂、冗长、非结构化的法律案件文档中自动构建知识图谱的挑战，特别是共指消解和跨文档块实体链接的问题。

Method: 提出LINK-KG框架，包含三阶段LLM引导的共指消解管道和类型特定的Prompt Cache，用于跨文档块跟踪和解析实体引用。

Result: 相比基线方法，平均节点重复减少45.21%，噪声节点减少32.22%，生成更清洁、更连贯的图结构。

Conclusion: LINK-KG为分析复杂犯罪网络提供了坚实的基础，显著改进了从法律文本构建知识图谱的质量。

Abstract: Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.

</details>


### [44] [Context Engineering 2.0: The Context of Context Engineering](https://arxiv.org/abs/2510.26493)
*Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 本文系统性地定义了情境工程，追溯其从1990年代至今的发展历程，分析了人机交互中情境理解的重要性，并提出了情境工程的概念框架和设计考量。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的发展，机器需要更好地理解人类的情境和目的。情境工程旨在解决机器如何理解人类处境这一核心挑战。

Method: 通过历史分析追溯情境工程的发展阶段，提供系统性定义，并构建概念框架来理解情境工程的设计考量。

Result: 建立了情境工程的概念基础，明确了其历史演变轨迹（从早期人机交互到智能代理交互），并提出了未来发展的方向。

Conclusion: 情境工程是AI系统发展的关键领域，本文为其提供了概念基础，并呼吁社区共同努力推进系统性的情境工程研究。

Abstract: Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.

</details>


### [45] [Human-AI Complementarity: A Goal for Amplified Oversight](https://arxiv.org/abs/2510.26518)
*Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik*

Main category: cs.AI

TL;DR: 结合AI评分和人类评分比单独依赖任一方更好，AI事实核查助手能提高人类准确性，但显示AI解释、置信度和标签会导致过度依赖，仅显示搜索结果和证据能培养更适当的信任。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力提升和处理更复杂任务，验证质量和安全变得越来越困难，需要探索如何利用AI提高人类监督质量，特别是在人类已难以处理的事实核查问题上。

Method: 研究AI事实核查助手对人类监督的影响，比较不同辅助方式（显示AI解释、置信度、标签 vs 仅显示搜索结果和证据）的效果。

Result: AI和人类评分结合优于单独使用任一方；AI助手能提高人类准确性；显示AI解释等会导致过度依赖，仅显示证据能培养适当信任。

Conclusion: 这些结果对放大监督（结合人类和AI监督超越人类专家性能的AI系统）具有重要意义，表明适当的AI辅助方式能有效提高人类监督质量。

Abstract: Human feedback is critical for aligning AI systems to human values. As AI
capabilities improve and AI is used to tackle more challenging tasks, verifying
quality and safety becomes increasingly challenging. This paper explores how we
can leverage AI to improve the quality of human oversight. We focus on an
important safety problem that is already challenging for humans:
fact-verification of AI outputs. We find that combining AI ratings and human
ratings based on AI rater confidence is better than relying on either alone.
Giving humans an AI fact-verification assistant further improves their
accuracy, but the type of assistance matters. Displaying AI explanation,
confidence, and labels leads to over-reliance, but just showing search results
and evidence fosters more appropriate trust. These results have implications
for Amplified Oversight -- the challenge of combining humans and AI to
supervise AI systems even as they surpass human expert performance.

</details>


### [46] [EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge](https://arxiv.org/abs/2510.26550)
*Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman*

Main category: cs.AI

TL;DR: EdgeRunner 20B是基于gpt-oss-20b微调的军事任务优化模型，在军事测试集上性能与GPT-5相当，适合敏感数据环境部署。


<details>
  <summary>Details</summary>
Motivation: 为军事领域开发专门优化的本地部署模型，解决数据敏感性和边缘设备部署需求。

Method: 使用160万条高质量军事文档数据对gpt-oss-20B进行微调，并创建了四个新的军事测试集。

Result: 在军事测试集上性能与GPT-5相当（95%统计显著性），在通用基准测试上无明显回归，适合边缘设备部署。

Conclusion: 小型本地化模型是军事等敏感数据操作的理想解决方案，可在隔离环境中部署。

Abstract: We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for
military tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated
from military documentation and websites. We also present four new tests sets:
(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k
(general military knowledge). On these military test sets, EdgeRunner 20B
matches or exceeds GPT-5 task performance with 95%+ statistical significance,
except for the high reasoning setting on the combat medic test set and the low
reasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no
statistically-significant regression on general-purpose benchmarks like ARC-C,
GPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the
low reasoning setting. We also present analyses on hyperparameter settings,
cost, and throughput. These findings show that small, locally-hosted models are
ideal solutions for data-sensitive operations such as in the military domain,
allowing for deployment in air-gapped edge devices.

</details>


### [47] [Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives](https://arxiv.org/abs/2510.26606)
*Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型在规范推理领域的能力，发现虽然LLMs总体上遵循有效推理模式，但在特定类型的规范推理中存在不一致性，并表现出类似人类推理的认知偏差。


<details>
  <summary>Details</summary>
Motivation: 规范推理涉及义务和许可等规范模态，虽然LLMs在各种推理任务中表现出色，但其处理规范推理的能力尚未得到充分探索。

Method: 创建了一个新数据集，涵盖规范和认知领域的广泛推理模式，同时纳入影响人类推理的非形式认知因素，比较LLMs在规范模态和认知模态下的推理表现。

Result: LLMs总体上遵循有效推理模式，但在特定类型的规范推理中存在显著不一致性，并表现出类似人类推理的认知偏差。

Conclusion: 这些发现突显了在LLMs的规范推理中实现逻辑一致性所面临的挑战，为提高其可靠性提供了见解。

Abstract: Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.

</details>


### [48] [The Era of Agentic Organization: Learning to Organize with Language Models](https://arxiv.org/abs/2510.26658)
*Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.AI

TL;DR: 提出异步思维（AsyncThink）作为LLM推理新范式，通过组织内部思维过程为并发可执行结构，实现多智能体协作解决复杂问题。


<details>
  <summary>Details</summary>
Motivation: 实现智能体组织新时代，让智能体通过协作和并发工作解决复杂问题，超越个体智能的能力。

Method: 提出思维协议，组织者动态分配子查询给工作者，合并中间知识并生成连贯解决方案，通过强化学习优化思维结构。

Result: 相比并行思维推理延迟降低28%，数学推理准确率提升，且无需额外训练即可泛化到未见任务。

Conclusion: 异步思维是实现智能体组织协作的有效范式，能够显著提升推理效率和准确性，并具备良好的泛化能力。

Abstract: We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.

</details>


### [49] [Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching](https://arxiv.org/abs/2510.26702)
*Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi*

Main category: cs.AI

TL;DR: 提出了ASTRA数据集和授权模型，用于语义检查LLM代理的访问请求，仅授予完成任务所需的最小权限范围，解决当前授权方法权限过宽的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理的工具调用授权方法授予的权限过于宽泛，允许代理在预期任务范围之外操作，存在显著安全风险。

Method: 引入委托授权模型，通过语义检查访问请求，仅发放完成任务所需的最小权限范围token；创建ASTRA数据集用于基准测试任务与权限范围的语义匹配。

Result: 实验显示基于模型的匹配方法存在潜力但仍有局限，特别是当完成任务所需的权限范围数量增加时。

Conclusion: 需要进一步研究语义匹配技术，实现多代理和工具增强应用的意图感知授权，包括细粒度控制如基于任务的访问控制(TBAC)。

Abstract: Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).

</details>


### [50] [Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis](https://arxiv.org/abs/2510.26721)
*Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang*

Main category: cs.AI

TL;DR: 研究发现多模态大语言模型对文本输入的偏好源于其内部注意力机制中视觉键向量与文本键向量的分布差异，而非外部数据不平衡。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理视觉语言数据时表现出对文本输入的明显偏好，限制了其基于视觉证据进行有效推理的能力。

Method: 从LLaVA和Qwen2.5-VL模型中提取键向量，使用t-SNE和Jensen-Shannon散度分析视觉键和文本键的分布结构。

Result: 视觉键和文本键在注意力空间中占据明显不同的子空间，模态间差异在统计上显著，比模态内变异高出几个数量级。

Conclusion: 文本偏见源于注意力键空间内的内在不对齐，而不仅仅是外部数据因素。

Abstract: Multimodal large language models (MLLMs) exhibit a pronounced preference for
textual inputs when processing vision-language data, limiting their ability to
reason effectively from visual evidence. Unlike prior studies that attribute
this text bias to external factors such as data imbalance or instruction
tuning, we propose that the bias originates from the model's internal
architecture. Specifically, we hypothesize that visual key vectors (Visual
Keys) are out-of-distribution (OOD) relative to the text key space learned
during language-only pretraining. Consequently, these visual keys receive
systematically lower similarity scores during attention computation, leading to
their under-utilization in the context representation. To validate this
hypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their
distributional structures using qualitative (t-SNE) and quantitative
(Jensen-Shannon divergence) methods. The results provide direct evidence that
visual and textual keys occupy markedly distinct subspaces within the attention
space. The inter-modal divergence is statistically significant, exceeding
intra-modal variation by several orders of magnitude. These findings reveal
that text bias arises from an intrinsic misalignment within the attention key
space rather than solely from external data factors.

</details>


### [51] [Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models](https://arxiv.org/abs/2510.26732)
*J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot*

Main category: cs.AI

TL;DR: 该论文对当代基础模型的推理能力进行了跨平台评估，建立了基础设施无关的基准测试，涵盖HPC超级计算、云平台和大学集群三种计算范式，评估了15个基础模型在79个问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 建立基础设施无关的基准测试来评估基础模型的推理能力，挑战传统的规模扩展假设，探索训练数据质量与模型规模的关系，为教育、生产和研究场景提供模型选择指导。

Method: 采用三阶段实验方法：(1)在MareNostrum 5上建立基线；(2)在大学集群和Nebius AI Studio上验证基础设施无关的可重复性；(3)在两个平台上进行完整的79问题评估，探究跨架构多样性的泛化能力。

Result: 研究结果挑战了传统的规模扩展假设，确立了训练数据质量比模型规模更关键，并为不同应用场景提供了可操作的模型选择指南。

Conclusion: 三基础设施方法和79问题基准测试能够随着基础模型的发展纵向跟踪推理能力，为模型评估和选择提供了系统性框架。

Abstract: This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.

</details>


### [52] [The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy](https://arxiv.org/abs/2510.26752)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 该论文研究一种最小控制接口，让智能体在自主行动或请求人类干预之间选择，人类同时选择信任或监督，通过马尔可夫博弈框架实现安全对齐保证。


<details>
  <summary>Details</summary>
Motivation: 随着智能体能力增强，如何在保持系统不变的前提下维持有意义的人类控制成为一个核心安全问题。

Method: 将人机交互建模为马尔可夫博弈，特别关注马尔可夫势博弈情况，分析智能体自主决策与人类监督之间的平衡。

Result: 在网格世界模拟中，通过独立学习，智能体学会在不确定时请求帮助，人类学会适时监督，形成避免安全违规的协作。

Conclusion: 该方法提供了一种在部署后使未对齐模型更安全的实用方法，实现了特定形式的内在对齐保证。

Abstract: As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.

</details>


### [53] [LLMs Process Lists With General Filter Heads](https://arxiv.org/abs/2510.26784)
*Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau*

Main category: cs.AI

TL;DR: LLMs学习到了类似函数式编程中'filter'操作的紧凑因果表示，通过少量注意力头编码过滤谓词，这种表示具有通用性和可移植性，但有时也会采用急切求值的替代策略。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在列表处理任务中的工作机制，探索它们是否学习到了抽象的计算操作表示。

Method: 使用因果中介分析在多样化的列表处理任务上，识别编码过滤谓词的注意力头（称为filter heads）。

Result: 发现LLMs确实学习到了通用的过滤谓词表示，这种表示可以跨不同集合、格式、语言和任务进行提取和重用。

Conclusion: Transformer LMs能够发展出人类可解释的抽象计算操作实现，其泛化方式与传统函数式编程模式惊人相似。

Abstract: We investigate the mechanisms underlying a range of list-processing tasks in
LLMs, and we find that LLMs have learned to encode a compact, causal
representation of a general filtering operation that mirrors the generic
"filter" function of functional programming. Using causal mediation analysis on
a diverse set of list-processing tasks, we find that a small number of
attention heads, which we dub filter heads, encode a compact representation of
the filtering predicate in their query states at certain tokens. We demonstrate
that this predicate representation is general and portable: it can be extracted
and reapplied to execute the same filtering operation on different collections,
presented in different formats, languages, or even in tasks. However, we also
identify situations where transformer LMs can exploit a different strategy for
filtering: eagerly evaluating if an item satisfies the predicate and storing
this intermediate result as a flag directly in the item representations. Our
results reveal that transformer LMs can develop human-interpretable
implementations of abstract computational operations that generalize in ways
that are surprisingly similar to strategies used in traditional functional
programming patterns.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [54] [Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments](https://arxiv.org/abs/2510.25917)
*Mehdi Karbalayghareh,David J. Love,Christopher G. Brinton*

Main category: cs.IT

TL;DR: 提出了一种针对无线联邦学习的相干感知通信效率框架，通过资源复用策略在异构衰落动态下联合进行信道训练和模型更新。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习方案忽略了设备间相干时间差异，导致通信效率低下和训练开销严重。实际中边缘设备由于移动性和散射环境不同，具有不相等的相干时间，对导频信号和信道估计资源需求不均。

Method: 针对下行链路损伤，引入基于乘积叠加的资源复用策略，使参数服务器能够通过将静态设备的全局模型更新嵌入到移动设备的导频传输中，来高效调度静态和动态设备。

Result: 理论分析了所提方案的收敛行为，量化了其在预期通信效率和训练准确性方面的增益。实验证明了该框架在移动性诱导动态下的有效性。

Conclusion: 该框架为无线信道上联邦学习的实际部署提供了有用的见解，能够有效应对异构衰落动态带来的挑战。

Abstract: The performance of federated learning (FL) over wireless networks critically
depends on accurate and timely channel state information (CSI) across
distributed devices. This requirement is tightly linked to how rapidly the
channel gains vary, i.e., the coherence intervals. In practice, edge devices
often exhibit unequal coherence times due to differences in mobility and
scattering environments, leading to unequal demands for pilot signaling and
channel estimation resources. Conventional FL schemes that overlook this
coherence disparity can suffer from severe communication inefficiencies and
training overhead. This paper proposes a coherence-aware,
communication-efficient framework for joint channel training and model updating
in practical wireless FL systems operating under heterogeneous fading dynamics.
Focusing on downlink impairments, we introduce a resource-reuse strategy based
on product superposition, enabling the parameter server to efficiently schedule
both static and dynamic devices by embedding global model updates for static
devices within pilot transmissions intended for mobile devices. We
theoretically analyze the convergence behavior of the proposed scheme and
quantify its gains in expected communication efficiency and training accuracy.
Experiments demonstrate the effectiveness of the proposed framework under
mobility-induced dynamics and offer useful insights for the practical
deployment of FL over wireless channels.

</details>


### [55] [Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems](https://arxiv.org/abs/2510.26147)
*Xilai Fan,Ya-Feng Liu*

Main category: cs.IT

TL;DR: 本文研究了集成感知与通信系统中的波束成形设计问题，提出了一种基于对偶理论和定点迭代的高效算法，在保证通信用户SINR和雷达感知MSE约束的同时最小化总发射功率。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信系统需要同时满足通信和感知的性能要求，但通信SINR约束和感知性能指标之间存在复杂耦合，这给波束成形设计带来了挑战。现有方法计算复杂度高，需要开发更高效的优化算法。

Method: 首先建立原始问题与其半定松弛的等价性，推导拉格朗日对偶形式，将其重构为具有不定加权矩阵的广义下行波束成形问题。提出定制的定点迭代算法，并开发基于对偶的定点迭代算法，结合外部次梯度上升和内部FPI循环。

Result: 仿真结果表明，所提出的Dual-FPI算法能够获得全局最优解，同时相比现有基线方法显著降低了计算复杂度。

Conclusion: 本文成功解决了ISAC系统中波束成形设计的挑战，提出的Dual-FPI算法在保证性能的同时实现了高效计算，为集成感知与通信系统的实际部署提供了可行的解决方案。

Abstract: In this paper, we investigate the beamforming design problem in an integrated
sensing and communication (ISAC) system, where a multi-antenna base station
simultaneously serves multiple communication users while performing radar
sensing. We formulate the problem as the minimization of the total transmit
power, subject to signal-to-interference-plus-noise ratio (SINR) constraints
for communication users and mean-squared-error (MSE) constraints for radar
sensing. The core challenge arises from the complex coupling between
communication SINR requirements and sensing performance metrics. To efficiently
address this challenge, we first establish the equivalence between the original
ISAC beamforming problem and its semidefinite relaxation (SDR), derive its
Lagrangian dual formulation, and further reformulate it as a generalized
downlink beamforming (GDB) problem with potentially indefinite weighting
matrices. Compared to the classical DB problem, the presence of indefinite
weighting matrices in the GDB problem introduces substantial analytical and
computational challenges. Our key technical contributions include (i) a
necessary and sufficient condition for the boundedness of the GDB problem, and
(ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable
convergence guarantee for solving the GDB problem. Building upon these results,
we develop a duality-based fixed point iteration (Dual-FPI) algorithm, which
integrates an outer subgradient ascent loop with an inner FPI loop. Simulation
results demonstrate that the proposed Dual-FPI algorithm achieves globally
optimal solutions while significantly reducing computational complexity
compared with existing baseline approaches.

</details>


### [56] [Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems](https://arxiv.org/abs/2510.26279)
*Fuying Li,Yajun Wang,Zhuxian Lian,Wen Chen*

Main category: cs.IT

TL;DR: 提出ADMM-APG算法解决IRS辅助MIMO系统中的频谱效率最大化问题，该算法结合ADMM和APG方法，在频谱效率和计算复杂度方面优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 无线通信对频谱效率的需求日益增长，智能反射表面(IRS)能够动态重构传播环境，但IRS辅助MIMO系统中的频谱效率最大化问题具有非凸性，计算复杂。

Method: 提出ADMM-APG算法，结合交替方向乘子法(ADMM)和加速投影梯度(APG)方法，将原问题分解为可处理的子问题，每个子问题都有闭式解。

Result: 仿真结果表明，ADMM-APG算法在频谱效率和计算复杂度方面持续超越现有基准方法，在各种系统配置下实现了显著的性能提升。

Conclusion: ADMM-APG算法为IRS辅助MIMO系统提供了一种计算高效且性能优越的频谱效率优化解决方案。

Abstract: Driven by the growing demand for higher spectral efficiency in wireless
communications, intelligent reflecting surfaces (IRS) have attracted
considerable attention for their ability to dynamically reconfigure the
propagation environment. This work addresses the spectral efficiency
maximization problem in IRS-assisted multiple-input multiple-output (MIMO)
systems, which involves the joint optimization of the transmit precoding matrix
and the IRS phase shift configuration. This problem is inherently challenging
due to its non-convex nature. To tackle it effectively, we introduce a
computationally efficient algorithm, termed ADMM-APG, which integrates the
alternating direction method of multipliers (ADMM) with the accelerated
projected gradient (APG) method. The proposed framework decomposes the original
problem into tractable subproblems, each admitting a closed-form solution while
maintaining low computational complexity. Simulation results demonstrate that
the ADMM-APG algorithm consistently surpasses existing benchmark methods in
terms of spectral efficiency and computational complexity, achieving
significant performance gains across a range of system configurations.

</details>


### [57] [Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests](https://arxiv.org/abs/2510.26442)
*Xuesong Wang,Xinyan Xie,Mo Li,Zhaoqian Liu*

Main category: cs.IT

TL;DR: 提出了一种基于扩散模型的语义通信框架，通过传输简洁文本描述和少量关键视觉特征，结合自适应重传机制来平衡重建质量与传输开销。


<details>
  <summary>Details</summary>
Motivation: 传统语义通信方法存在两个问题：仅传输文本描述无法保留精确空间布局和细节信息；传输文本加密集视觉特征会产生语义冗余。需要减少冗余同时保持语义理解和视觉保真度。

Method: 传输简洁文本描述和有限的关键潜在视觉特征，使用扩散修复模型重建图像。接收端设计语义一致性机制评估重建图像与文本的对齐度，检测到语义差异时触发重传请求额外潜在块来优化重建。

Result: 显著减少带宽使用，同时保持高语义准确性，在重建质量和传输开销之间实现高效平衡。

Conclusion: 该扩散基语义通信框架通过自适应重传机制有效解决了语义冗余问题，在保证通信质量的同时提高了传输效率。

Abstract: Semantic communication focuses on conveying the intrinsic meaning of data
rather than its raw symbolic representation. For visual content, this paradigm
shifts from traditional pixel-level transmission toward leveraging the semantic
structure of images to communicate visual meaning. Existing approaches
generally follow one of two paths: transmitting only text descriptions, which
often fail to capture precise spatial layouts and fine-grained appearance
details; or transmitting text alongside dense latent visual features, which
tends to introduce substantial semantic redundancy. A key challenge, therefore,
is to reduce semantic redundancy while preserving semantic understanding and
visual fidelity, thereby improving overall transmission efficiency. This paper
introduces a diffusion-based semantic communication framework with adaptive
retransmission. The system transmits concise text descriptions together with a
limited set of key latent visual features, and employs a diffusion-based
inpainting model to reconstruct the image. A receiver-side semantic consistency
mechanism is designed to evaluate the alignment between the reconstructed image
and the original text description. When a semantic discrepancy is detected, the
receiver triggers a retransmission to request a small set of additional latent
blocks and refine the image reconstruction. This approach significantly reduces
bandwidth usage while preserving high semantic accuracy, achieving an efficient
balance between reconstruction quality and transmission overhead.

</details>


### [58] [PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design](https://arxiv.org/abs/2510.26452)
*Yi-Ting Hong,Stefano Rini,Luca Barletta*

Main category: cs.IT

TL;DR: 使用基于Gumbel AlphaZero算法的强化学习框架设计大尺寸极化码核，在满足给定错误指数条件下最小化解码复杂度。


<details>
  <summary>Details</summary>
Motivation: 大核极化码能改善错误指数，但设计低解码复杂度的核具有挑战性。

Method: 采用基于Gumbel AlphaZero算法的强化学习框架，在递归最大似然解码下进行核构造。

Result: 对于尺寸16的核，比手工设计降低17%解码复杂度，错误指数达到0.5183（Arikan核为0.5）。

Conclusion: 基于学习的方法在实用极化码构造中具有有效性。

Abstract: Polar codes with large kernels can achieve improved error exponents but are
challenging to design with low decoding complexity. This work investigates
kernel construction under recursive maximum likelihood decoding (RMLD) using a
reinforcement learning framework based on the Gumbel AlphaZero algorithm. The
proposed method efficiently explores the design space and identifies large-size
kernels that satisfy a given error exponent while minimizing decoding
complexity. For a size-16 kernel, it achieves 17% lower decoding complexity
than handcrafted designs while reaching an error exponent of 0.5183 compared to
0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based
approach for practical polar code construction.

</details>


### [59] [Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures](https://arxiv.org/abs/2510.26552)
*Shaocheng Liu,Qi Chen,Minquan Cheng*

Main category: cs.IT

TL;DR: 该论文是系列论文的第二部分，主要研究4变量多拟阵区域Γ₄的2维面上的熵函数特征化问题，完成了对剩余10种面类型的分析，其中8种完全特征化，2种部分特征化。


<details>
  <summary>Details</summary>
Motivation: 熵函数的特征化在信息论中具有基础重要性。通过在多拟阵区域（香农外界）上施加约束，可以得到该区域的各个面以及具有特殊结构的熵函数。

Method: 通过算法枚举了Γ₄的所有59种2维面类型，在本文中重点分析剩余的10种面类型，引入了新的组合设计结构来帮助特征化这些面上的熵函数。

Result: 在剩余的10种面类型中，成功完全特征化了8种类型，部分特征化了2种类型，完成了对Γ₄所有2维面上熵函数的系统分析。

Conclusion: 该研究通过引入新的组合设计结构，基本完成了对4变量多拟阵区域Γ₄所有2维面上熵函数的特征化工作，为信息论中熵函数的研究提供了重要进展。

Abstract: Characterization of entropy functions is of fundamental importance in
information theory. By imposing constraints on their Shannon outer bound, i.e.,
the polymatroidal region, one obtains the faces of the region and entropy
functions on them with special structures. In this series of two papers, we
characterize entropy functions on the $2$-dimensional faces of the
polymatroidal region $\Gamma_4$. In Part I, we formulated the problem,
enumerated all $59$ types of $2$-dimensional faces of $\Gamma_4$ by a
algorithm, and fully characterized entropy functions on $49$ types of them. In
this paper, i.e., Part II, we will characterize entropy functions on the
remaining $10$ types of faces, among which $8$ types are fully characterized
and $2$ types are partially characterized. To characterize these types of
faces, we introduce some new combinatorial design structures which are
interesting themself.

</details>
