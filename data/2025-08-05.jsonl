{"id": "2508.01190", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01190", "abs": "https://arxiv.org/abs/2508.01190", "authors": ["Xi Xie", "Nian Li", "Qiang Wang", "Xiangyong Zeng", "Yinglong Du"], "title": "Construction of $(n,n)$-functions with low differential-linear uniformity", "comment": null, "summary": "The differential-linear connectivity table (DLCT), introduced by Bar-On et\nal. at EUROCRYPT'19, is a novel tool that captures the dependency between the\ntwo subciphers involved in differential-linear attacks. This paper is devoted\nto exploring the differential-linear properties of $(n,n)$-functions. First, by\nrefining specific exponential sums, we propose two classes of power functions\nover $\\mathbb{F}_{2^n}$ with low differential-linear uniformity (DLU). Next, we\nfurther investigate the differential-linear properties of $(n,n)$-functions\nthat are polynomials by utilizing power functions with known DLU. Specifically,\nby combining a cubic function with quadratic functions, and employing\ngeneralized cyclotomic mappings, we construct several classes of\n$(n,n)$-functions with low DLU, including some that achieve optimal or\nnear-optimal DLU compared to existing results."}
{"id": "2508.01201", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01201", "abs": "https://arxiv.org/abs/2508.01201", "authors": ["Shicong Liu", "Xianghao Yu", "Jie Xu", "Rui Zhang"], "title": "Near-Field Communication with Massive Movable Antennas: A Functional Perspective", "comment": "14 pages, 10 figures", "summary": "The advent of massive multiple-input multiple-output (MIMO) technology has\nprovided new opportunities for capacity improvement via strategic antenna\ndeployment, especially when the near-field effect is pronounced due to antenna\nproliferation. In this paper, we investigate the optimal antenna placement for\nmaximizing the achievable rate of a point-to-point near-field channel, where\nthe transmitter is deployed with massive movable antennas. First, we propose a\nnovel design framework to explore the relationship between antenna positions\nand achievable data rate. By introducing the continuous antenna position\nfunction (APF) and antenna density function (ADF), we reformulate the antenna\nposition design problem from the discrete to the continuous domain, which\nmaximizes the achievable rate functional with respect to ADF. Leveraging\nfunctional analysis and variational methods, we derive the optimal ADF\ncondition and propose a gradient-based algorithm for numerical solutions under\ngeneral channel conditions. Furthermore, for the near-field line-of-sight (LoS)\nscenario, we present a closed-form solution for the optimal ADF, revealing the\ncritical role of edge antenna density in enhancing the achievable rate.\nFinally, we propose a flexible antenna array-based deployment method that\nensures practical implementation while mitigating mutual coupling issues.\nSimulation results demonstrate the effectiveness of the proposed framework,\nwith uniform circular arrays emerging as a promising geometry for balancing\nperformance and deployment feasibility in near-field communications."}
{"id": "2508.01229", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01229", "abs": "https://arxiv.org/abs/2508.01229", "authors": ["Lipeng Zhu", "Haobin Mao", "Wenyan Ma", "Zhenyu Xiao", "Jun Zhang", "Rui Zhang"], "title": "Towed Movable Antenna (ToMA) Array for Ultra Secure Airborne Communications", "comment": null, "summary": "This paper proposes a novel towed movable antenna (ToMA) array architecture\nto enhance the physical layer security of airborne communication systems.\nUnlike conventional onboard arrays with fixed-position antennas (FPAs), the\nToMA array employs multiple subarrays mounted on flexible cables and towed by\ndistributed drones, enabling agile deployment in three-dimensional (3D) space\nsurrounding the central aircraft. This design significantly enlarges the\neffective array aperture and allows dynamic geometry reconfiguration, offering\nsuperior spatial resolution and beamforming flexibility. We consider a secure\ntransmission scenario where an airborne transmitter communicates with multiple\nlegitimate users in the presence of potential eavesdroppers. To ensure\nsecurity, zero-forcing beamforming is employed to nullify signal leakage toward\neavesdroppers. Based on the statistical distributions of locations of users and\neavesdroppers, the antenna position vector (APV) of the ToMA array is optimized\nto maximize the users' ergodic achievable rate. Analytical results for the case\nof a single user and a single eavesdropper reveal the optimal APV structure\nthat minimizes their channel correlation. For the general multiuser scenario,\nwe develop a low-complexity alternating optimization algorithm by leveraging\nRiemannian manifold optimization. Simulation results confirm that the proposed\nToMA array achieves significant performance gains over conventional onboard FPA\narrays, especially in scenarios where eavesdroppers are closely located to\nusers under line-of-sight (LoS)-dominant channels."}
{"id": "2508.01258", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01258", "abs": "https://arxiv.org/abs/2508.01258", "authors": ["Gang Wang", "Hong-Yang Yao", "Fang-Wei Fu"], "title": "New constant-dimension subspace codes from parallel cosets of optimal Ferrers diagram rank-metric codes and multilevel inserting constructions", "comment": "28 pages, 11 Tables", "summary": "Constant-dimension subspace codes (CDCs), a special class of subspace codes,\nhave attracted significant attention due to their applications in network\ncoding. A fundamental research problem of CDCs is to determine the maximum\nnumber of codewords under the given parameters. The paper first proposes the\nconstruction of parallel cosets of optimal Ferrers diagram rank-metric codes\n(FDRMCs) by employing the list of CDCs and inverse list of CDCs. Then a new\nclass of CDCs is obtained by combining the parallel cosets of optimal FDRMCs\nwith parallel linkage construction. Next, we present a novel set of identifying\nvectors and provide a new construction of CDCs via the multilevel constuction.\nFinally, the coset construction is inserted into the multilevel construction\nand three classes of large CDCs are provided, one of which is constructed by\nusing new optimal FDRMCs. Our results establish at least 65 new lower bounds\nfor CDCs with larger sizes than the previously best known codes."}
{"id": "2508.00844", "categories": ["cs.AI", "cs.ET", "cs.MA", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.00844", "abs": "https://arxiv.org/abs/2508.00844", "authors": ["Christopher Wissuchek", "Patrick Zschech"], "title": "Exploring Agentic Artificial Intelligence Systems: Towards a Typological Framework", "comment": "Preprint accepted for archival and presentation at the Pacific-Asia\n  Conference on Information Systems (PACIS) 2025, Kuala Lumpur, Malaysia", "summary": "Artificial intelligence (AI) systems are evolving beyond passive tools into\nautonomous agents capable of reasoning, adapting, and acting with minimal human\nintervention. Despite their growing presence, a structured framework is lacking\nto classify and compare these systems. This paper develops a typology of\nagentic AI systems, introducing eight dimensions that define their cognitive\nand environmental agency in an ordinal structure. Using a multi-phase\nmethodological approach, we construct and refine this typology, which is then\nevaluated through a human-AI hybrid approach and further distilled into\nconstructed types. The framework enables researchers and practitioners to\nanalyze varying levels of agency in AI systems. By offering a structured\nperspective on the progression of AI capabilities, the typology provides a\nfoundation for assessing current systems and anticipating future developments\nin agentic AI."}
{"id": "2508.01047", "categories": ["cs.NI", "cs.AI", "C.2.2; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2508.01047", "abs": "https://arxiv.org/abs/2508.01047", "authors": ["Efe Ağlamazlar", "Emirhan Eken", "Harun Batur Geçici"], "title": "A Deep Reinforcement Learning-Based TCP Congestion Control Algorithm: Design, Simulation, and Evaluation", "comment": "This paper presents a novel TCP congestion control algorithm based on\n  Deep Reinforcement Learning. The study includes 5 figures and 8 pages of\n  content", "summary": "This paper presents a novel TCP congestion control algorithm based on Deep\nReinforcement Learning. The proposed approach utilizes Deep Q-Networks to\noptimize the congestion window (cWnd) by observing key network parameters and\ntaking real-time actions. The algorithm is trained and evaluated within the\nNS-3 network simulator using the OpenGym interface. The results demonstrate\nsignificant improvements over traditional TCP New Reno in terms of latency and\nthroughput, with better adaptability to changing network conditions. This study\nemphasizes the potential of reinforcement learning techniques for solving\ncomplex congestion control problems in modern networks."}
{"id": "2508.01898", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.01898", "abs": "https://arxiv.org/abs/2508.01898", "authors": ["Yijing Zhang", "Md-Ferdous Pervej", "Andreas F. Molisch"], "title": "Revenue Optimization in Wireless Video Caching Networks: A Privacy-Preserving Two-Stage Solution", "comment": "Under review for possible publication in the IEEE Transactions on\n  Communications", "summary": "Video caching can significantly improve delivery efficiency and enhance\nquality of video streaming, which constitutes the majority of wireless\ncommunication traffic. Due to limited cache size, caching strategies must be\ndesigned to adapt to and dynamic user demand in order to maximize system\nrevenue. The system revenue depends on the benefits of delivering the requested\nvideos and costs for (a) transporting the files to the users and (b) cache\nreplacement. Since the cache content at any point in time impacts the\nreplacement costs in the future, demand predictions over multiple cache\nplacement slots become an important prerequisite for efficient cache planning.\nMotivated by this, we introduce a novel two-stage privacy-preserving solution\nfor revenue optimization in wireless video caching networks. First, we train a\nTransformer using privacy-preserving federated learning (FL) to predict\nmulti-slot future demands. Given that prediction results are never entirely\naccurate, especially for longer horizons, we further combine global content\npopularity with per-user prediction results to estimate the content demand\ndistribution. Then, in the second stage, we leverage these estimation results\nto find caching strategies that maximize the long-term system revenue. This\nlatter problem takes on the form of a multi-stage knapsack problem, which we\nthen transform to a integer linear program. Our extensive simulation results\ndemonstrate that (i) our FL solution delivers nearly identical performance to\nthat of the ideal centralized solution and outperforms other existing caching\nmethods, and (ii) our novel revenue optimization approach provides deeper\nsystem performance insights than traditional cache hit ratio (CHR)-based\noptimization approaches."}
{"id": "2508.01438", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01438", "abs": "https://arxiv.org/abs/2508.01438", "authors": ["Daniel Plabst", "Mohamed Akrout", "Amine Mezghani", "Gerhard Kramer"], "title": "Information Rates of Approximate Message Passing for Bandlimited Direct-Detection Channels", "comment": null, "summary": "The capacity of bandlimited direct-detection channels is difficult to compute\nor approach because of the receiver nonlinearity. A generalized vector\napproximate message passing (GVAMP) detector is designed to achieve high rates\nwith reasonable complexity. The rates increase by using multi-level coding and\nsuccessive interference cancellation. The methods are applied to optical fiber\nchannels with long intersymbol interference, as encountered in practice.\nBipolar modulation operates within 0.3 bits per channel use (bpcu) of the\nreal-alphabet coherent capacity for optically-amplified links, improving the\nbest existing gap of 1 bpcu based on theory. Remarkably, bipolar modulation\ngains 6 decibels (dB) in power efficiency over unipolar modulation, and 3 dB\nfor unamplified links. The detector is robust to changes in channel parameters\nsuch as the fiber length. The GVAMP complexity, measured in multiplications per\ninformation bit (mpib), is proportional to the number of iterations and the\nlogarithm of the block length, and is substantially less than state-of-the-art\nneural networks. The receiver requires approximately 38 iterations to achieve a\nrate of 5 bpcu with 80 mpib."}
{"id": "2508.00853", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00853", "abs": "https://arxiv.org/abs/2508.00853", "authors": ["Kei Itoh"], "title": "A Formal Framework for the Definition of 'State': Hierarchical Representation and Meta-Universe Interpretation", "comment": "43 pages, 8 figures, 8 Tables, in English, in Japanese", "summary": "This study aims to reinforce the theoretical foundation for diverse\nsystems--including the axiomatic definition of intelligence--by introducing a\nmathematically rigorous and unified formal structure for the concept of\n'state,' which has long been used without consensus or formal clarity. First, a\n'hierarchical state grid' composed of two axes--state depth and mapping\nhierarchy--is proposed to provide a unified notational system applicable across\nmathematical, physical, and linguistic domains. Next, the 'Intermediate\nMeta-Universe (IMU)' is introduced to enable explicit descriptions of definers\n(ourselves) and the languages we use, thereby allowing conscious meta-level\noperations while avoiding self-reference and logical inconsistency. Building on\nthis meta-theoretical foundation, this study expands inter-universal theory\nbeyond mathematics to include linguistic translation and agent integration,\nintroducing the conceptual division between macrocosm-inter-universal and\nmicrocosm-inter-universal operations for broader expressivity. Through these\ncontributions, this paper presents a meta-formal logical framework--grounded in\nthe principle of definition = state--that spans time, language, agents, and\noperations, providing a mathematically robust foundation applicable to the\ndefinition of intelligence, formal logic, and scientific theory at large."}
{"id": "2508.01060", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01060", "abs": "https://arxiv.org/abs/2508.01060", "authors": ["Ibrahim Althamary", "Chen-Fu Chou", "Chih-Wei Huang"], "title": "Connectivity Management in Satellite-Aided Vehicular Networks with Multi-Head Attention-Based State Estimation", "comment": null, "summary": "Managing connectivity in integrated satellite-terrestrial vehicular networks\nis critical for 6G, yet is challenged by dynamic conditions and partial\nobservability. This letter introduces the Multi-Agent Actor-Critic with\nSatellite-Aided Multi-head self-attention (MAAC-SAM), a novel multi-agent\nreinforcement learning framework that enables vehicles to autonomously manage\nconnectivity across Vehicle-to-Satellite (V2S), Vehicle-to-Infrastructure\n(V2I), and Vehicle-to-Vehicle (V2V) links. Our key innovation is the\nintegration of a multi-head attention mechanism, which allows for robust state\nestimation even with fluctuating and limited information sharing among\nvehicles. The framework further leverages self-imitation learning (SIL) and\nfingerprinting to improve learning efficiency and real-time decisions.\nSimulation results, based on realistic SUMO traffic models and 3GPP-compliant\nconfigurations, demonstrate that MAAC-SAM outperforms state-of-the-art\nterrestrial and satellite-assisted baselines by up to 14% in transmission\nutility and maintains high estimation accuracy across varying vehicle densities\nand sharing levels."}
{"id": "2508.01702", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01702", "abs": "https://arxiv.org/abs/2508.01702", "authors": ["Hareesh K.", "Rashid Ummer N. T.", "B. Sundar Rajan"], "title": "Explicit Function-Correcting Code Constructions for Lee Metric Channels", "comment": "16 pages, 4 tables and 1 figure", "summary": "Function-Correcting Codes (FCCs) are a novel class of codes designed to\nprotect function evaluations of messages against errors while minimizing\nredundancy. A theoretical framework for systematic FCCs to channels matched to\nthe Lee metric has been studied recently, which introduced function-correcting\nLee codes (FCLCs) and also derived upper and lower bounds on their optimal\nredundancy. In this paper, we propose a Plotkin-like bound for irregular\nLee-distance codes, which improves an existing bound. We construct explicit\nFCLCs for specific classes of functions, including the Lee weight, Lee weight\ndistribution, modular sum, and locally bounded function. For these functions,\nlower bounds on redundancy are obtained, and our constructions are shown to be\noptimal in certain cases. Finally, a comparative analysis with classical Lee\nerror-correcting codes and codes correcting errors in function values\ndemonstrates that FCLCs can significantly reduce redundancy while preserving\nfunction correctness."}
{"id": "2508.00890", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.00890", "abs": "https://arxiv.org/abs/2508.00890", "authors": ["Fali Wang", "Hui Liu", "Zhenwei Dai", "Jingying Zeng", "Zhiwei Zhang", "Zongyu Wu", "Chen Luo", "Zhen Li", "Xianfeng Tang", "Qi He", "Suhang Wang"], "title": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "comment": "Under review", "summary": "Test-time scaling (TTS) enhances the performance of large language models\n(LLMs) by allocating additional compute resources during inference. However,\nexisting research primarily investigates TTS in single-stage tasks; while many\nreal-world problems are multi-stage complex tasks, composed of a sequence of\nheterogeneous subtasks with each subtask requires LLM of specific capability.\nTherefore, we study a novel problem: the test-time compute-optimal scaling in\nmulti-stage complex tasks, aiming to select suitable models and allocate\nbudgets per subtask to maximize overall performance. TTS in multi-stage tasks\nintroduces two fundamental challenges: (i) The combinatorial search space of\nmodel and budget allocations, combined with the high cost of inference, makes\nbrute-force search impractical. (ii) The optimal model and budget allocations\nacross subtasks are interdependent, increasing the complexity of the\ncompute-optimal search. To address this gap, we conduct extensive pilot\nexperiments on four tasks across six datasets, deriving three empirical\ninsights characterizing the behavior of LLMs in multi-stage complex tasks.\nInformed by these insights, we propose AgentTTS, an LLM-agent-based framework\nthat autonomously searches for compute-optimal allocations through iterative\nfeedback-driven interactions with the execution environment. Experimental\nresults demonstrate that AgentTTS significantly outperforms traditional and\nother LLM-based baselines in search efficiency, and shows improved robustness\nto varying training set sizes and enhanced interpretability."}
{"id": "2508.01298", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.01298", "abs": "https://arxiv.org/abs/2508.01298", "authors": ["Azadeh Sadat Miraftab", "Ahmadreza Montazerolghaem", "Behrad Mahboobi"], "title": "Improving performance of content-centric networks via decentralized coded caching for multi-level popularity and access", "comment": null, "summary": "Content-Centric Networking (CCN) offers a novel architectural paradigm that\nseeks to address the inherent limitations of the prevailing Internet Protocol\n(IP)-based networking model. In contrast to the host-centric communication\napproach of IP networks, CCN prioritizes content by enabling direct addressing\nand routing based on content identifiers. The potential performance\nimprovements of CCN can be further amplified through optimized management of\ncoded data storage and transmission strategies. Decentralized Coded Caching\n(DCC) emerges as a promising technique that harnesses the collective caching\npower of distributed network elements. By strategically pre-positioning\nfrequently accessed content closer to potential consumers during periods of low\nnetwork utilization, DCC has the potential to mitigate content transfer rates\nduring peak traffic periods. This paper proposes a series of fundamental\nmodifications to the CCN architecture by integrating DCC. The proposed\nframework incorporates differentiated coding strategies tailored to user access\nprivileges, thereby eliminating the overhead associated with queue-based\nsearching. Additionally, the framework facilitates recoding of uncoded data\nencountered along the content delivery path. These combined methodologies\ndemonstrably enhance network throughput, elevate cache hit ratios, and\nconsequently, reduce content delivery latency compared to conventional CCN\nimplementations."}
{"id": "2508.01840", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.01840", "abs": "https://arxiv.org/abs/2508.01840", "authors": ["Meng Hua", "Chenghong Bian", "Haotian Wu", "Deniz Gunduz"], "title": "Implementing Neural Networks Over-the-Air via Reconfigurable Intelligent Surfaces", "comment": "Submitted to IEEE Journal for possible publicaiton", "summary": "In this paper, we investigate reconfigurable intelligent surface (RIS)-aided\nmultiple-input-multiple-output (MIMO) OAC systems designed to emulate the\nfully-connected (FC) layer of a neural network (NN) via analog OAC, where the\nRIS and the transceivers are jointly adjusted to engineer the ambient wireless\npropagation environment to emulate the weights of the target FC layer. We refer\nto this novel computational paradigm as AirFC. We first study the case in which\nthe precoder, combiner, and RIS phase shift matrices are jointly optimized to\nminimize the mismatch between the OAC system and the target FC layer. To solve\nthis non-convex optimization problem, we propose a low-complexity alternating\noptimization algorithm, where semi-closed-form/closed-form solutions for all\noptimization variables are derived. Next, we consider training of the system\nparameters using two distinct learning strategies, namely centralized training\nand distributed training. In the centralized training approach, training is\nperformed at either the transmitter or the receiver, whichever possesses the\nchannel state information (CSI), and the trained parameters are provided to the\nother terminal. In the distributed training approach, the transmitter and\nreceiver iteratively update their parameters through back and forth\ntransmissions by leveraging channel reciprocity, thereby avoiding CSI\nacquisition and significantly reducing computational complexity. Subsequently,\nwe extend our analysis to a multi-RIS scenario by exploiting its spatial\ndiversity gain to enhance the system performance. Simulation results show that\nthe AirFC system realized by the RIS-aided MIMO configuration achieves\nsatisfactory classification accuracy."}
{"id": "2508.00899", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00899", "abs": "https://arxiv.org/abs/2508.00899", "authors": ["Abeer Dyoub", "Ivan Letteri", "Francesca A. Lisi"], "title": "ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI", "comment": null, "summary": "The emergence of Symbiotic AI (SAI) introduces new challenges to ethical\ndecision-making as it deepens human-AI collaboration. As symbiosis grows, AI\nsystems pose greater ethical risks, including harm to human rights and trust.\nEthical Risk Assessment (ERA) thus becomes crucial for guiding decisions that\nminimize such risks. However, ERA is hindered by uncertainty, vagueness, and\nincomplete information, and morality itself is context-dependent and imprecise.\nThis motivates the need for a flexible, transparent, yet robust framework for\nERA. Our work supports ethical decision-making by quantitatively assessing and\nprioritizing multiple ethical risks so that artificial agents can select\nactions aligned with human values and acceptable risk levels. We introduce\nff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic\nHierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks\nvia an Ethical Risk Score (ERS) for each risk type. The final ERS combines the\nFAHP-derived weight, propagated CF, and risk level. The framework offers a\nrobust mathematical approach for collaborative ERA modeling and systematic,\nstep-by-step analysis. A case study confirms that ff4ERA yields\ncontext-sensitive, ethically meaningful risk scores reflecting both expert\ninput and sensor-based evidence. Risk scores vary consistently with relevant\nfactors while remaining robust to unrelated inputs. Local sensitivity analysis\nshows predictable, mostly monotonic behavior across perturbations, and global\nSobol analysis highlights the dominant influence of expert-defined weights and\ncertainty factors, validating the model design. Overall, the results\ndemonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware\nethical assessments, enabling what-if analyses and guiding designers in\ncalibrating membership functions and expert judgments for reliable ethical\ndecision support."}
{"id": "2508.01805", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.01805", "abs": "https://arxiv.org/abs/2508.01805", "authors": ["Yongjie Zeng", "Hongyang Du"], "title": "M3LLM: Model Context Protocol-aided Mixture of Vision Experts For Multimodal LLMs in Networks", "comment": null, "summary": "Current Multimodal Large Language Models (MLLMs) rely on centralized\narchitectures and often suffer from poor alignment between the input task and\ntheir fixed visual encoding modules, which limits performance on diverse and\ndynamic visual tasks. With the increasing deployment of resource-efficient\nmodels on edge devices in wireless networks, a new opportunity emerges to\ndynamically use distributed vision experts for improved MLLM inference quality.\nTo enable this, we propose M3LLM, where the Model Context Protocol (MCP)\ncoordinates a mixture of vision experts to achieve distributed MLLMs.\nSpecifically, MCP is an open protocol that structures the input task context\ninto interpretable representations, enabling wireless network-aware\ncoordination between the central model backbone and edge-hosted vision experts.\nBased on the MCP representation, M3LLM formulates vision expert routing as a\njoint optimization problem that balances task-expert semantic compatibility and\nchannel performance. To solve the resulting gradient conflicts, we develop a\ndual-stream Soft Actor-Critic (SAC) algorithm with decoupled reward signals and\nintroduce an Adaptive Stability Enhancement Module (ASEM) based on hierarchical\nBayesian modeling to ensure effective routing. Experiments show that M3LLM\nimproves task accuracy, reduces communication cost, and enhances expert routing\nadaptability under dynamic wireless network conditions."}
{"id": "2508.02158", "categories": ["cs.IT", "cs.CR", "cs.DS", "cs.LG", "math.IT", "math.ST", "stat.TH", "68R10, 05C80", "E.4; E.2; G.3; F.2"], "pdf": "https://arxiv.org/pdf/2508.02158", "abs": "https://arxiv.org/abs/2508.02158", "authors": ["Dor Elimelech", "Wasim Huleihel"], "title": "Robust Detection of Planted Subgraphs in Semi-Random Models", "comment": "32 pages", "summary": "Detection of planted subgraphs in Erd\\\"os-R\\'enyi random graphs has been\nextensively studied, leading to a rich body of results characterizing both\nstatistical and computational thresholds. However, most prior work assumes a\npurely random generative model, making the resulting algorithms potentially\nfragile in the face of real-world perturbations. In this work, we initiate the\nstudy of semi-random models for the planted subgraph detection problem, wherein\nan adversary is allowed to remove edges outside the planted subgraph before the\ngraph is revealed to the statistician. Crucially, the statistician remains\nunaware of which edges have been removed, introducing fundamental challenges to\nthe inference task. We establish fundamental statistical limits for detection\nunder this semi-random model, revealing a sharp dichotomy. Specifically, for\nplanted subgraphs with strongly sub-logarithmic maximum density detection\nbecomes information-theoretically impossible in the presence of an adversary,\ndespite being possible in the classical random model. In stark contrast, for\nsubgraphs with super-logarithmic density, the statistical limits remain\nessentially unchanged; we prove that the optimal (albeit computationally\nintractable) likelihood ratio test remains robust. Beyond these statistical\nboundaries, we design a new computationally efficient and robust detection\nalgorithm, and provide rigorous statistical guarantees for its performance. Our\nresults establish the first robust framework for planted subgraph detection and\nopen new directions in the study of semi-random models,\ncomputational-statistical trade-offs, and robustness in graph inference\nproblems."}
{"id": "2508.00902", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.00902", "abs": "https://arxiv.org/abs/2508.00902", "authors": ["Kenneth Payne"], "title": "An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models", "comment": "26 pages, 2 figures, 9 tables, 2 appendices", "summary": "Judgment of risk is key to decision-making under uncertainty. As Daniel\nKahneman and Amos Tversky famously discovered, humans do so in a distinctive\nway that departs from mathematical rationalism. Specifically, they demonstrated\nexperimentally that humans accept more risk when they feel themselves at risk\nof losing something than when they might gain. I report the first tests of\nKahneman and Tversky's landmark 'prospect theory' with Large Language Models,\nincluding today's state of the art chain-of-thought 'reasoners'.\n  In common with humans, I find that prospect theory often anticipates how\nthese models approach risky decisions across a range of scenarios. I also\ndemonstrate that context is key to explaining much of the variance in risk\nappetite. The 'frame' through which risk is apprehended appears to be embedded\nwithin the language of the scenarios tackled by the models. Specifically, I\nfind that military scenarios generate far larger 'framing effects' than do\ncivilian settings, ceteris paribus. My research suggests, therefore, that\nlanguage models the world, capturing our human heuristics and biases. But also\nthat these biases are uneven - the idea of a 'frame' is richer than simple\ngains and losses. Wittgenstein's notion of 'language games' explains the\ncontingent, localised biases activated by these scenarios. Finally, I use my\nfindings to reframe the ongoing debate about reasoning and memorisation in\nLLMs."}
{"id": "2508.01898", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.01898", "abs": "https://arxiv.org/abs/2508.01898", "authors": ["Yijing Zhang", "Md-Ferdous Pervej", "Andreas F. Molisch"], "title": "Revenue Optimization in Wireless Video Caching Networks: A Privacy-Preserving Two-Stage Solution", "comment": "Under review for possible publication in the IEEE Transactions on\n  Communications", "summary": "Video caching can significantly improve delivery efficiency and enhance\nquality of video streaming, which constitutes the majority of wireless\ncommunication traffic. Due to limited cache size, caching strategies must be\ndesigned to adapt to and dynamic user demand in order to maximize system\nrevenue. The system revenue depends on the benefits of delivering the requested\nvideos and costs for (a) transporting the files to the users and (b) cache\nreplacement. Since the cache content at any point in time impacts the\nreplacement costs in the future, demand predictions over multiple cache\nplacement slots become an important prerequisite for efficient cache planning.\nMotivated by this, we introduce a novel two-stage privacy-preserving solution\nfor revenue optimization in wireless video caching networks. First, we train a\nTransformer using privacy-preserving federated learning (FL) to predict\nmulti-slot future demands. Given that prediction results are never entirely\naccurate, especially for longer horizons, we further combine global content\npopularity with per-user prediction results to estimate the content demand\ndistribution. Then, in the second stage, we leverage these estimation results\nto find caching strategies that maximize the long-term system revenue. This\nlatter problem takes on the form of a multi-stage knapsack problem, which we\nthen transform to a integer linear program. Our extensive simulation results\ndemonstrate that (i) our FL solution delivers nearly identical performance to\nthat of the ideal centralized solution and outperforms other existing caching\nmethods, and (ii) our novel revenue optimization approach provides deeper\nsystem performance insights than traditional cache hit ratio (CHR)-based\noptimization approaches."}
{"id": "2508.02229", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02229", "abs": "https://arxiv.org/abs/2508.02229", "authors": ["Jessica Bariffi", "Antonia Wachter-Zeh", "Eitan Yaakobi"], "title": "Sequence Reconstruction over Coloring Channels for Protein Identification", "comment": null, "summary": "This paper studies the sequence reconstruction problem for a channel inspired\nby protein identification. We introduce a coloring channel, where a sequence is\ntransmitted through a channel that deletes all symbols not belonging to a fixed\nsubset (the coloring) of the alphabet. By extending this to a coloring profile,\na tuple of distinct colorings, we analyze the channel's information rate and\ncapacity. We prove that optimal (i.e., achieving maximum information rate)\ncoloring profiles correspond to 2-covering designs and identify the minimal\ncovering number required for maximum information rate, as well as the minimum\nnumber for which any coloring profile is optimal."}
{"id": "2508.00914", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00914", "abs": "https://arxiv.org/abs/2508.00914", "authors": ["Dominic Simon", "Rickard Ewetz"], "title": "Knowledge Editing for Multi-Hop Question Answering Using Semantic Analysis", "comment": "14 pages, 15 figures, pre-print of paper accepted to IJCAI 2025", "summary": "Large Language Models (LLMs) require lightweight avenues of updating stored\ninformation that has fallen out of date. Knowledge Editing (KE) approaches have\nbeen successful in updating model knowledge for simple factual queries but\nstruggle with handling tasks that require compositional reasoning such as\nmulti-hop question answering (MQA). We observe that existing knowledge editors\nleverage decompositional techniques that result in illogical reasoning\nprocesses. In this paper, we propose a knowledge editor for MQA based on\nsemantic analysis called CHECK. Our framework is based on insights from an\nanalogy between compilers and reasoning using LLMs. Similar to how source code\nis first compiled before being executed, we propose to semantically analyze\nreasoning chains before executing the chains to answer questions. Reasoning\nchains with semantic errors are revised to ensure consistency through logic\noptimization and re-prompting the LLM model at a higher temperature. We\nevaluate the effectiveness of CHECK against five state-of-the-art frameworks on\nfour datasets and achieve an average 22.8% improved MQA accuracy."}
{"id": "2508.02001", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02001", "abs": "https://arxiv.org/abs/2508.02001", "authors": ["Chungang Lin", "Weiyao Zhang", "Tianyu Zuo", "Chao Zha", "Yilong Jiang", "Ruiqi Meng", "Haitong Luo", "Xuying Meng", "Yujun Zhang"], "title": "Convolutions are Competitive with Transformers for Encrypted Traffic Classification with Pre-training", "comment": "Under review", "summary": "Encrypted traffic classification is vital for modern network management and\nsecurity. To reduce reliance on handcrafted features and labeled data, recent\nmethods focus on learning generic representations through pre-training on\nlarge-scale unlabeled data. However, current pre-trained models face two\nlimitations originating from the adopted Transformer architecture: (1) Limited\nmodel efficiency due to the self-attention mechanism with quadratic complexity;\n(2) Unstable traffic scalability to longer byte sequences, as the explicit\npositional encodings fail to generalize to input lengths not seen during\npre-training. In this paper, we investigate whether convolutions, with linear\ncomplexity and implicit positional encoding, are competitive with Transformers\nin encrypted traffic classification with pre-training. We first conduct a\nsystematic comparison, and observe that convolutions achieve higher efficiency\nand scalability, with lower classification performance. To address this\ntrade-off, we propose NetConv, a novel pre-trained convolution model for\nencrypted traffic classification. NetConv employs stacked traffic convolution\nlayers, which enhance the ability to capture localized byte-sequence patterns\nthrough window-wise byte scoring and sequence-wise byte gating. We design a\ncontinuous byte masking pre-training task to help NetConv learn\nprotocol-specific patterns. Experimental results on four tasks demonstrate that\nNetConv improves average classification performance by 6.88% and model\nthroughput by 7.41X over existing pre-trained models."}
{"id": "2508.02314", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02314", "abs": "https://arxiv.org/abs/2508.02314", "authors": ["Jiajia Guo", "Yiming Cui", "Shi Jin", "Jun Zhang"], "title": "Large AI Models for Wireless Physical Layer", "comment": "A collection of paper on Large AI Models for wireless physical layer\n  can be found at https://github.com/AI4Wireless/LAM4PHY_6G", "summary": "Large artificial intelligence models (LAMs) are transforming wireless\nphysical layer technologies through their robust generalization, multitask\nprocessing, and multimodal capabilities. This article reviews recent\nadvancements in LAM applications for physical layer communications, addressing\nlimitations of conventional AI-based approaches. LAM applications are\nclassified into two strategies: leveraging pre-trained LAMs and developing\nnative LAMs designed specifically for physical layer tasks. The motivations and\nkey frameworks of these approaches are comprehensively examined through\nmultiple use cases. Both strategies significantly improve performance and\nadaptability across diverse wireless scenarios. Future research directions,\nincluding efficient architectures, interpretability, standardized datasets, and\ncollaboration between large and small models, are proposed to advance LAM-based\nphysical layer solutions for next-generation communication systems."}
{"id": "2508.00967", "categories": ["cs.AI", "cs.RO", "68T07, 68T45, 93C85", "I.2.6; I.2.9; I.2.10; I.4.8"], "pdf": "https://arxiv.org/pdf/2508.00967", "abs": "https://arxiv.org/abs/2508.00967", "authors": ["Massoud Pourmandi"], "title": "Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF", "comment": "15 pages, 3 figures, 1 table, 1 algorithm. Preprint based on NeurIPS\n  2024 template", "summary": "The proposal introduces an innovative drone swarm perception system that aims\nto solve problems related to computational limitations and low-bandwidth\ncommunication, and real-time scene reconstruction. The framework enables\nefficient multi-agent 3D/4D scene synthesis through federated learning of\nshared diffusion model and YOLOv12 lightweight semantic extraction and local\nNeRF updates while maintaining privacy and scalability. The framework redesigns\ngenerative diffusion models for joint scene reconstruction, and improves\ncooperative scene understanding, while adding semantic-aware compression\nprotocols. The approach can be validated through simulations and potential\nreal-world deployment on drone testbeds, positioning it as a disruptive\nadvancement in multi-agent AI for autonomous systems."}
{"id": "2508.02031", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.02031", "abs": "https://arxiv.org/abs/2508.02031", "authors": ["Tian Qin", "Guang Cheng", "Zihan Chen", "Yuyang Zhou"], "title": "PRIME: Plasticity-Robust Incremental Model for Encrypted Traffic Classification in Dynamic Network Environments", "comment": null, "summary": "With the continuous development of network environments and technologies,\nensuring cyber security and governance is increasingly challenging. Network\ntraffic classification(ETC) can analyzes attributes such as application\ncategories and malicious intent, supporting network management services like\nQoS optimization, intrusion detection, and targeted billing. As the prevalence\nof traffic encryption increases, deep learning models are relied upon for\ncontent-agnostic analysis of packet sequences. However, the emergence of new\nservices and attack variants often leads to incremental tasks for ETC models.\nTo ensure model effectiveness, incremental learning techniques are essential;\nhowever, recent studies indicate that neural networks experience declining\nplasticity as tasks increase. We identified plasticity issues in existing\nincremental learning methods across diverse traffic samples and proposed the\nPRIME framework. By observing the effective rank of model parameters and the\nproportion of inactive neurons, the PRIME architecture can appropriately\nincrease the parameter scale when the model's plasticity deteriorates.\nExperiments show that in multiple encrypted traffic datasets and different\ncategory increment scenarios, the PRIME architecture performs significantly\nbetter than other incremental learning algorithms with minimal increase in\nparameter scale."}
{"id": "2508.02382", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02382", "abs": "https://arxiv.org/abs/2508.02382", "authors": ["Yang Li", "Martianus Frederic Ezerman", "Huimin Lao", "San Ling"], "title": "Properties and Decoding of Twisted GRS Codes and Their Extensions", "comment": null, "summary": "Maximum distance separable (MDS) codes that are not equivalent to generalized\nReed-Solomon (GRS) codes are called non-GRS MDS codes. Alongside near MDS\n(NMDS) codes, they are applicable in communication, cryptography, and storage\nsystems. From theoretical perspective, it is particularly intriguing to\ninvestigate families of linear codes in which each element can be determined to\nbe either a non-GRS MDS or an NMDS code. Two promising candidates for such\nfamilies emerge from what is known as twisted GRS (TGRS) construction. These\ncandidates are the $(+)$-TGRS codes and their extended versions, called\n$(+)$-extended TGRS (ETGRS) codes.\n  Although many of their properties have been characterized, there are gaps to\nfill. Which among the codes are non-GRS MDS? Can we improve on their decoding\nby using their error-correcting pairs or deep holes? In this paper we solve\nthese problems. The answer to the first problem leads us to two classes of\nnon-GRS MDS Hermitian self-dual TGRS codes and a proof that there is no Galois\nself-dual ETGRS code. Addressing the second problem, we present an explicit\ndecoding algorithm for ETGRS codes that outperforms existing decoding\nalgorithms given some conditions. By considering the duals of TGRS codes which\nare MDS, we determine the covering radius and a class of deep holes of the\nrecently constructed non-GRS MDS codes due to Han and Zhang."}
{"id": "2508.01012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01012", "abs": "https://arxiv.org/abs/2508.01012", "authors": ["Yiyi Lu", "Hoi Ian Au", "Junyao Zhang", "Jingyu Pan", "Yiting Wang", "Ang Li", "Jianyi Zhang", "Yiran Chen"], "title": "AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents", "comment": null, "summary": "Modern Electronic Design Automation (EDA) workflows, especially the\nRTL-to-GDSII flow, require heavily manual scripting and demonstrate a multitude\nof tool-specific interactions which limits scalability and efficiency. While\nLLMs introduces strides for automation, existing LLM solutions require\nexpensive fine-tuning and do not contain standardized frameworks for\nintegration and evaluation. We introduce AutoEDA, a framework for EDA\nautomation that leverages paralleled learning through the Model Context\nProtocol (MCP) specific for standardized and scalable natural language\nexperience across the entire RTL-to-GDSII flow. AutoEDA limits fine-tuning\nthrough structured prompt engineering, implements intelligent parameter\nextraction and task decomposition, and provides an extended CodeBLEU metric to\nevaluate the quality of TCL scripts. Results from experiments over five\npreviously curated benchmarks show improvements in automation accuracy and\nefficiency, as well as script quality when compared to existing methods.\nAutoEDA is released open-sourced to support reproducibility and the EDA\ncommunity. Available at: https://github.com/AndyLu666/MCP-EDA-Server"}
{"id": "2508.02282", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.02282", "abs": "https://arxiv.org/abs/2508.02282", "authors": ["Ziyue Huang", "Chungang Lin", "Weiyao Zhang", "Xuying Meng", "Yujun Zhang"], "title": "Distillation-Enhanced Clustering Acceleration for Encrypted Traffic Classification", "comment": "Under review", "summary": "Traffic classification plays a significant role in network service\nmanagement. The advancement of deep learning has established pretrained models\nas a robust approach for this task. However, contemporary encrypted traffic\nclassification systems face dual limitations. Firstly, pretrained models\ntypically exhibit large-scale architectures, where their extensive\nparameterization results in slow inference speeds and high computational\nlatency. Secondly, reliance on labeled data for fine-tuning restricts these\nmodels to predefined supervised classes, creating a bottleneck when novel\ntraffic types emerge in the evolving Internet landscape. To address these\nchallenges, we propose NetClus, a novel framework integrating pretrained models\nwith distillation-enhanced clustering acceleration. During fine-tuning, NetClus\nfirst introduces a cluster-friendly loss to jointly reshape the latent space\nfor both classification and clustering. With the fine-tuned model, it distills\nthe model into a lightweight Feed-Forward Neural Network model to retain\nsemantics. During inference, NetClus performs heuristic merge with near-linear\nruntime, and valid the cluster purity with newly proposed metrics ASI to\nidentify emergent traffic types while expediting classification. Benchmarked\nagainst existing pretrained methods, NetClus achieves up to 6.2x acceleration\nwhile maintaining classification degradation below 1%."}
{"id": "2508.02553", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02553", "abs": "https://arxiv.org/abs/2508.02553", "authors": ["Phillip Stephan", "Florian Euchner", "Stephan ten Brink"], "title": "CSI Obfuscation: Single-Antenna Transmitters Can Not Hide from Adversarial Multi-Antenna Radio Localization Systems", "comment": null, "summary": "The ability of modern telecommunication systems to locate users and objects\nin the radio environment raises justified privacy concerns. To prevent\nunauthorized localization, single-antenna transmitters can obfuscate the signal\nby convolving it with a randomized sequence prior to transmission, which alters\nthe channel state information (CSI) estimated at the receiver. However, this\nstrategy is only effective against CSI-based localization systems deploying\nsingle-antenna receivers. Inspired by the concept of blind multichannel\nidentification, we propose a simple CSI recovery method for multi-antenna\nreceivers to extract channel features that ensure reliable user localization\nregardless of the transmitted signal. We comparatively evaluate the impact of\nsignal obfuscation and the proposed recovery method on the localization\nperformance of CSI fingerprinting, channel charting, and classical\ntriangulation using real-world channel measurements. This work aims to\ndemonstrate the necessity for further efforts to protect the location privacy\nof users from adversarial radio-based localization systems."}
{"id": "2508.01031", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01031", "abs": "https://arxiv.org/abs/2508.01031", "authors": ["Jingzhe Ni", "Xiaolong Yin", "Xintong Li", "Xingyu Lu", "Ji Wei", "Ruofeng Tong", "Min Tang", "Peng Du"], "title": "CADDesigner: Conceptual Design of CAD Models Based on General-Purpose Agent", "comment": null, "summary": "Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing\nbut typically requires a high level of expertise from designers. To lower the\nentry barrier and improve design efficiency, we present an agent for CAD\nconceptual design powered by large language models (LLMs). The agent accepts\nboth abstract textual descriptions and freehand sketches as input, engaging in\ninteractive dialogue with users to refine and clarify design requirements\nthrough comprehensive requirement analysis. Built upon a novel\nContext-Independent Imperative Paradigm (CIP), the agent generates high-quality\nCAD modeling code. During the generation process, the agent incorporates\niterative visual feedback to improve model quality. Generated design cases are\nstored in a structured knowledge base, enabling continuous improvement of the\nagent's code generation capabilities. Experimental results demonstrate that our\nmethod achieves state-of-the-art performance in CAD code generation."}
{"id": "2508.02373", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.02373", "abs": "https://arxiv.org/abs/2508.02373", "authors": ["Iulisloi Zacarias", "Oussama Ben Taarit", "Admela Jukan"], "title": "On Effectiveness of Graph Neural Network Architectures for Network Digital Twins (NDTs)", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Future networks, such as 6G, will need to support a vast and diverse range of\ninterconnected devices and applications, each with its own set of requirements.\nWhile traditional network management approaches will suffice, an automated\nsolutions are becoming a must. However, network automation frameworks are prone\nto errors, and often they employ ML-based techniques that require training to\nlearn how the network can be optimized. In this sense, network digital twins\nare a useful tool that allows for the simulation, testing, and training of AI\nmodels without affecting the real-world networks and users. This paper presents\nan AI-based Network Digital Twin (AI-NDT) that leverages a multi-layered\nknowledge graph architecture and graph neural networks to predict network\nmetrics that directly affect the quality of experience of users. An evaluation\nof the four most prominent Graph Neural Networks (GNN) architectures was\nconducted to assess their effectiveness in developing network digital twins. We\ntrained the digital twin on publicly available measurement data from RIPE\nAtlas, therefore obtaining results close to what is expected in real-world\napplications. The results show that among the four architectures evaluated,\nGraphTransformer presents the best performance. However, other architectures\nmight fit better in scenarios where shorter training time is important, while\nalso delivering acceptable results. The results of this work are indicative of\nwhat might become common practice for proactive network management, offering a\nscalable and accurate solution aligned with the requirements of the\nnext-generation networks."}
{"id": "2508.02586", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02586", "abs": "https://arxiv.org/abs/2508.02586", "authors": ["Altan B. Kilic", "Alberto Ravagnani", "Flavio Salizzoni"], "title": "The Length of Functional Batch and PIR Codes", "comment": null, "summary": "We consider the problem of computing the minimum length of functional batch\nand PIR codes of fixed dimension and for a fixed list size, over an arbitrary\nfinite field. We recover, generalize, and refine several results that were\npreviously obtained for binary codes. We present new upper and lower bounds for\nthe minimum length, and discuss the asymptotic behaviour of this parameter. We\nalso compute its value for several parameter sets. The paper also offers\ninsights into the \"correct\" list size to consider for the Functional Batch\nConjecture over non-binary finite fields, and establishes various supporting\nresults."}
{"id": "2508.01057", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.01057", "abs": "https://arxiv.org/abs/2508.01057", "authors": ["Fengze Yang", "Bo Yu", "Yang Zhou", "Xuewen Luo", "Zhengzhong Tu", "Chenxi Liu"], "title": "REACT: A Real-Time Edge-AI Based V2X Framework for Accident Avoidance in Autonomous Driving System", "comment": "24 pages, 6 tables, 7 figures", "summary": "Collisions caused by human error are the most common type of multi-vehicle\ncrash, highlighting the critical need for autonomous driving (AD) systems to\nleverage cooperative perception through Vehicle-to-Everything (V2X)\ncommunication. This capability extends situational awareness beyond the\nlimitations of onboard sensors. However, current transformer-based V2X\nframeworks suffer from limited generalization, shallow contextual reasoning,\nand reliance on mono-modal inputs. Vision-Language Models (VLMs) offer enhanced\nreasoning and multimodal integration but typically fall short of real-time\nperformance requirements in safety-critical applications. This paper presents\nREACT, a real-time, V2X-integrated trajectory optimization framework built upon\na fine-tuned lightweight VLM. REACT integrates a set of specialized modules\nthat process multimodal inputs into optimized, risk-aware trajectories. To\nensure real-time performance on edge devices, REACT incorporates edge\nadaptation strategies that reduce model complexity and accelerate inference.\nEvaluated on the DeepAccident benchmark, REACT achieves state-of-the-art\nperformance, a 77% collision rate reduction, a 48.2% Video Panoptic Quality\n(VPQ), and a 0.57-second inference latency on the Jetson AGX Orin. Ablation\nstudies validate the contribution of each input, module, and edge adaptation\nstrategy. These results demonstrate the feasibility of lightweight VLMs for\nreal-time edge-based cooperative planning and showcase the potential of\nlanguage-guided contextual reasoning to improve safety and responsiveness in\nautonomous driving."}
{"id": "2508.02571", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2508.02571", "abs": "https://arxiv.org/abs/2508.02571", "authors": ["Yongzhe Xu", "Weitong Li", "Eeshan Umrani", "Taejoong Chung"], "title": "ASINT: Learning AS-to-Organization Mapping from Internet Metadata", "comment": null, "summary": "Accurately mapping Autonomous Systems (ASNs) to their owning or operating\norganizations underpins Internet measurement research and security\napplications. Yet existing approaches commonly rely solely on WHOIS or\nPeeringDB, missing important relationships (e.g., cross-regional aliases,\nparent-child ownership) and failing to unify organizations scattered across\ndifferent RIR identifiers. We introduce ASINT, an end-to-end pipeline that\nfuses bulk registry data with unstructured Web sources, then employs\nretrieval-augmented generation (RAG) to guide large language model (LLM)\ninference. Through a multi-stage procedure, ASINT merges ASNs into\n\"organization families,\" capturing nuanced ties beyond the scope of simpler\nheuristics.\n  ASINT maps 111,470 ASNs to 81,233 organization families; compared to both\nAS2ORG+ and AS-Sibling, ASINT identifies more cross-regional groupings (e.g.,\noperator aliases, rebrands) that other datasets overlook. Moreover, our refined\nmappings enhance multiple security and measurement tasks: ASINT exposes 27.5%\nmore intra-organizational RPKI misconfigurations, cuts false-positive hijack\nalarms by 9.4%, and lowers erroneous IP leasing inferences by 5.9%.\n  Finally, ASINT supports periodic updates and cost-sensitive LLM selection,\ndemonstrating that broader Web evidence can provide a more accurate, evolving\nview of the Internet's organizational structure."}
{"id": "2508.02657", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02657", "abs": "https://arxiv.org/abs/2508.02657", "authors": ["Irtiza Hasan", "Ahmed Arafa"], "title": "RC-Gossip: Information Freshness in Clustered Networks with Rate-Changing Gossip", "comment": "To appear in the 2025 Asilomar Conference on Signals, Systems, and\n  Computers", "summary": "A clustered gossip network is considered in which a source updates its\ninformation over time, and end-nodes, organized in clusters through\nclusterheads, are keeping track of it. The goal for the nodes is to remain as\nfresh as possible, i.e., have the same information as the source, which we\nassess by the long-term average binary freshness metric. We introduce a smart\nmechanism of information dissemination which we coin rate-changing gossip\n(RC-Gossip). Its main idea is that gossiping is directed towards nodes that\nneed it the most, and hence the rate of gossiping changes based on the number\nof fresh nodes in the network at a given time. While Stochastic Hybrid System\n(SHS) analysis has been the norm in studying freshness of gossip networks, we\npresent an equivalent way to analyze freshness using a renewal-reward-based\napproach. Using that, we show that RC-gossip significantly increases freshness\nof nodes in different clustered networks, with optimal cluster sizes, compared\nto traditional gossiping techniques."}
{"id": "2508.01073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01073", "abs": "https://arxiv.org/abs/2508.01073", "authors": ["Martin Böckling", "Heiko Paulheim"], "title": "gpuRDF2vec -- Scalable GPU-based RDF2vec", "comment": "18 pages, ISWC 2025", "summary": "Generating Knowledge Graph (KG) embeddings at web scale remains challenging.\nAmong existing techniques, RDF2vec combines effectiveness with strong\nscalability. We present gpuRDF2vec, an open source library that harnesses\nmodern GPUs and supports multi-node execution to accelerate every stage of the\nRDF2vec pipeline. Extensive experiments on both synthetically generated graphs\nand real-world benchmarks show that gpuRDF2vec achieves up to a substantial\nspeedup over the currently fastest alternative, i.e., jRDF2vec. In a\nsingle-node setup, our walk-extraction phase alone outperforms pyRDF2vec,\nSparkKGML, and jRDF2vec by a substantial margin using random walks on large/\ndense graphs, and scales very well to longer walks, which typically lead to\nbetter quality embeddings. Our implementation of gpuRDF2vec enables\npractitioners and researchers to train high-quality KG embeddings on\nlarge-scale graphs within practical time budgets and builds on top of Pytorch\nLightning for the scalable word2vec implementation."}
{"id": "2508.02657", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.02657", "abs": "https://arxiv.org/abs/2508.02657", "authors": ["Irtiza Hasan", "Ahmed Arafa"], "title": "RC-Gossip: Information Freshness in Clustered Networks with Rate-Changing Gossip", "comment": "To appear in the 2025 Asilomar Conference on Signals, Systems, and\n  Computers", "summary": "A clustered gossip network is considered in which a source updates its\ninformation over time, and end-nodes, organized in clusters through\nclusterheads, are keeping track of it. The goal for the nodes is to remain as\nfresh as possible, i.e., have the same information as the source, which we\nassess by the long-term average binary freshness metric. We introduce a smart\nmechanism of information dissemination which we coin rate-changing gossip\n(RC-Gossip). Its main idea is that gossiping is directed towards nodes that\nneed it the most, and hence the rate of gossiping changes based on the number\nof fresh nodes in the network at a given time. While Stochastic Hybrid System\n(SHS) analysis has been the norm in studying freshness of gossip networks, we\npresent an equivalent way to analyze freshness using a renewal-reward-based\napproach. Using that, we show that RC-gossip significantly increases freshness\nof nodes in different clustered networks, with optimal cluster sizes, compared\nto traditional gossiping techniques."}
{"id": "2507.21524", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.21524", "abs": "https://arxiv.org/abs/2507.21524", "authors": ["Le Liang", "Hao Ye", "Yucheng Sheng", "Ouya Wang", "Jiacheng Wang", "Shi Jin", "Geoffrey Ye Li"], "title": "Large Language Models for Wireless Communications: From Adaptation to Autonomy", "comment": null, "summary": "The emergence of large language models (LLMs) has revolutionized artificial\nintelligence, offering unprecedented capabilities in reasoning, generalization,\nand zero-shot learning. These strengths open new frontiers in wireless\ncommunications, where increasing complexity and dynamics demand intelligent and\nadaptive solutions. This article explores the role of LLMs in transforming\nwireless systems across three key directions: adapting pretrained LLMs for core\ncommunication tasks, developing wireless-specific foundation models to balance\nversatility and efficiency, and enabling agentic LLMs with autonomous reasoning\nand coordination capabilities. We highlight recent advances, practical case\nstudies, and the unique benefits of LLM-based approaches over traditional\nmethods. Finally, we outline open challenges and research opportunities,\nincluding multimodal fusion, collaboration with lightweight models, and\nself-improving capabilities, charting a path toward intelligent, adaptive, and\nautonomous wireless networks of the future."}
{"id": "2508.01097", "categories": ["cs.AI", "nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2508.01097", "abs": "https://arxiv.org/abs/2508.01097", "authors": ["Neil F. Johnson", "Frank Yingjie Huo"], "title": "Multispin Physics of AI Tipping Points and Hallucinations", "comment": null, "summary": "Output from generative AI such as ChatGPT, can be repetitive and biased. But\nmore worrying is that this output can mysteriously tip mid-response from good\n(correct) to bad (misleading or wrong) without the user noticing. In 2024\nalone, this reportedly caused $67 billion in losses and several deaths.\nEstablishing a mathematical mapping to a multispin thermal system, we reveal a\nhidden tipping instability at the scale of the AI's 'atom' (basic Attention\nhead). We derive a simple but essentially exact formula for this tipping point\nwhich shows directly the impact of a user's prompt choice and the AI's training\nbias. We then show how the output tipping can get amplified by the AI's\nmultilayer architecture. As well as helping improve AI transparency,\nexplainability and performance, our results open a path to quantifying users'\nAI risk and legal liabilities."}
{"id": "2508.01109", "categories": ["cs.AI", "68T07", "I.2; J.4"], "pdf": "https://arxiv.org/pdf/2508.01109", "abs": "https://arxiv.org/abs/2508.01109", "authors": ["Satiyabooshan Murugaboopathy", "Connor T. Jerzak", "Adel Daoud"], "title": "Platonic Representations for Poverty Mapping: Unified Vision-Language Codes or Agent-Induced Novelty?", "comment": "7 figures", "summary": "We investigate whether socio-economic indicators like household wealth leave\nrecoverable imprints in satellite imagery (capturing physical features) and\nInternet-sourced text (reflecting historical/economic narratives). Using\nDemographic and Health Survey (DHS) data from African neighborhoods, we pair\nLandsat images with LLM-generated textual descriptions conditioned on\nlocation/year and text retrieved by an AI search agent from web sources. We\ndevelop a multimodal framework predicting household wealth (International\nWealth Index) through five pipelines: (i) vision model on satellite images,\n(ii) LLM using only location/year, (iii) AI agent searching/synthesizing web\ntext, (iv) joint image-text encoder, (v) ensemble of all signals. Our framework\nyields three contributions. First, fusing vision and agent/LLM text outperforms\nvision-only baselines in wealth prediction (e.g., R-squared of 0.77 vs. 0.63 on\nout-of-sample splits), with LLM-internal knowledge proving more effective than\nagent-retrieved text, improving robustness to out-of-country and out-of-time\ngeneralization. Second, we find partial representational convergence: fused\nembeddings from vision/language modalities correlate moderately (median cosine\nsimilarity of 0.60 after alignment), suggesting a shared latent code of\nmaterial well-being while retaining complementary details, consistent with the\nPlatonic Representation Hypothesis. Although LLM-only text outperforms\nagent-retrieved data, challenging our Agent-Induced Novelty Hypothesis, modest\ngains from combining agent data in some splits weakly support the notion that\nagent-gathered information introduces unique representational structures not\nfully captured by static LLM knowledge. Third, we release a large-scale\nmultimodal dataset comprising more than 60,000 DHS clusters linked to satellite\nimages, LLM-generated descriptions, and agent-retrieved texts."}
{"id": "2508.01158", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01158", "abs": "https://arxiv.org/abs/2508.01158", "authors": ["Yunlong Lin", "Zirui Li", "Guodong Du", "Xiaocong Zhao", "Cheng Gong", "Xinwei Wang", "Chao Lu", "Jianwei Gong"], "title": "H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving", "comment": "Open source code: https://github.com/BIT-Jack/H2C-lifelong", "summary": "Deep learning (DL) has shown state-of-the-art performance in trajectory\nprediction, which is critical to safe navigation in autonomous driving (AD).\nHowever, most DL-based methods suffer from catastrophic forgetting, where\nadapting to a new distribution may cause significant performance degradation in\npreviously learned ones. Such inability to retain learned knowledge limits\ntheir applicability in the real world, where AD systems need to operate across\nvarying scenarios with dynamic distributions. As revealed by neuroscience, the\nhippocampal circuit plays a crucial role in memory replay, effectively\nreconstructing learned knowledge based on limited resources. Inspired by this,\nwe propose a hippocampal circuit-inspired continual learning method (H2C) for\ntrajectory prediction across varying scenarios. H2C retains prior knowledge by\nselectively recalling a small subset of learned samples. First, two\ncomplementary strategies are developed to select the subset to represent\nlearned knowledge. Specifically, one strategy maximizes inter-sample diversity\nto represent the distinctive knowledge, and the other estimates the overall\nknowledge by equiprobable sampling. Then, H2C updates via a memory replay loss\nfunction calculated by these selected samples to retain knowledge while\nlearning new data. Experiments based on various scenarios from the INTERACTION\ndataset are designed to evaluate H2C. Experimental results show that H2C\nreduces catastrophic forgetting of DL baselines by 22.71% on average in a\ntask-free manner, without relying on manually informed distributional shifts.\nThe implementation is available at https://github.com/BIT-Jack/H2C-lifelong."}
{"id": "2508.01181", "categories": ["cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS", "68", "I.2.10"], "pdf": "https://arxiv.org/pdf/2508.01181", "abs": "https://arxiv.org/abs/2508.01181", "authors": ["Zhiyuan Han", "Beier Zhu", "Yanlong Xu", "Peipei Song", "Xun Yang"], "title": "Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning", "comment": "ACM Multimedia 2025", "summary": "Despite their strong performance in multimodal emotion reasoning, existing\nMultimodal Large Language Models (MLLMs) often overlook the scenarios involving\nemotion conflicts, where emotional cues from different modalities are\ninconsistent. To fill this gap, we first introduce CA-MER, a new benchmark\ndesigned to examine MLLMs under realistic emotion conflicts. It consists of\nthree subsets: video-aligned, audio-aligned, and consistent, where only one or\nall modalities reflect the true emotion. However, evaluations on our CA-MER\nreveal that current state-of-the-art emotion MLLMs systematically over-rely on\naudio signal during emotion conflicts, neglecting critical cues from visual\nmodality. To mitigate this bias, we propose MoSEAR, a parameter-efficient\nframework that promotes balanced modality integration. MoSEAR consists of two\nmodules: (1)MoSE, modality-specific experts with a regularized gating mechanism\nthat reduces modality bias in the fine-tuning heads; and (2)AR, an attention\nreallocation mechanism that rebalances modality contributions in frozen\nbackbones during inference. Our framework offers two key advantages: it\nmitigates emotion conflicts and improves performance on consistent\nsamples-without incurring a trade-off between audio and visual modalities.\nExperiments on multiple benchmarks-including MER2023, EMER, DFEW, and our\nCA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,\nparticularly under modality conflict conditions."}
{"id": "2508.01186", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.01186", "abs": "https://arxiv.org/abs/2508.01186", "authors": ["Chaojia Yu", "Zihan Cheng", "Hanwen Cui", "Yishuo Gao", "Zexu Luo", "Yijin Wang", "Hangbin Zheng", "Yong Zhao"], "title": "A Survey on Agent Workflow -- Status and Future", "comment": "12 pages, 3 figures, accepted to IEEE Conference,\n  ICAIBD(International Conference of Artificial Intelligence and Big Data)\n  2025. This is the author's version, not the publisher's. See\n  https://ieeexplore.ieee.org/document/11082076", "summary": "In the age of large language models (LLMs), autonomous agents have emerged as\na powerful paradigm for achieving general intelligence. These agents\ndynamically leverage tools, memory, and reasoning capabilities to accomplish\nuser-defined goals. As agent systems grow in complexity, agent\nworkflows-structured orchestration frameworks-have become central to enabling\nscalable, controllable, and secure AI behaviors. This survey provides a\ncomprehensive review of agent workflow systems, spanning academic frameworks\nand industrial implementations. We classify existing systems along two key\ndimensions: functional capabilities (e.g., planning, multi-agent collaboration,\nexternal API integration) and architectural features (e.g., agent roles,\norchestration flows, specification languages). By comparing over 20\nrepresentative systems, we highlight common patterns, potential technical\nchallenges, and emerging trends. We further address concerns related to\nworkflow optimization strategies and security. Finally, we outline open\nproblems such as standardization and multimodal integration, offering insights\nfor future research at the intersection of agent design, workflow\ninfrastructure, and safe automation."}
{"id": "2508.01191", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.01191", "abs": "https://arxiv.org/abs/2508.01191", "authors": ["Chengshuai Zhao", "Zhen Tan", "Pingchuan Ma", "Dawei Li", "Bohan Jiang", "Yancheng Wang", "Yingzhen Yang", "Huan Liu"], "title": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens", "comment": null, "summary": "Chain-of-Thought (CoT) prompting has been shown to improve Large Language\nModel (LLM) performance on various tasks. With this approach, LLMs appear to\nproduce human-like reasoning steps before providing answers (a.k.a., CoT\nreasoning), which often leads to the perception that they engage in deliberate\ninferential processes. However, some initial findings suggest that CoT\nreasoning may be more superficial than it appears, motivating us to explore\nfurther. In this paper, we study CoT reasoning via a data distribution lens and\ninvestigate if CoT reasoning reflects a structured inductive bias learned from\nin-distribution data, allowing the model to conditionally generate reasoning\npaths that approximate those seen during training. Thus, its effectiveness is\nfundamentally bounded by the degree of distribution discrepancy between the\ntraining data and the test queries. With this lens, we dissect CoT reasoning\nvia three dimensions: task, length, and format. To investigate each dimension,\nwe design DataAlchemy, an isolated and controlled environment to train LLMs\nfrom scratch and systematically probe them under various distribution\nconditions. Our results reveal that CoT reasoning is a brittle mirage that\nvanishes when it is pushed beyond training distributions. This work offers a\ndeeper understanding of why and when CoT reasoning fails, emphasizing the\nongoing challenge of achieving genuine and generalizable reasoning."}
{"id": "2508.01203", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01203", "abs": "https://arxiv.org/abs/2508.01203", "authors": ["Junjie Shi", "Wei Ma", "Shi Ying", "Lingxiao Jiang", "Yang liu", "Bo Du"], "title": "Importance Sampling is All You Need: Predict LLM's performance on new benchmark by reusing existing benchmark", "comment": null, "summary": "With the rapid advancement of large language models , code generation has\nbecome a key benchmark for evaluating LLM capabilities. However, existing\nbenchmarks face two major challenges: (1) the escalating cost of constructing\nhigh-quality test suites and reference solutions, and (2) the increasing risk\nof data contamination, which undermines the reliability of benchmark-based\nevaluations. In this paper, we propose BIS, a prompt-centric evaluation\nframework that enables ground-truth-free prediction of LLM performance on code\ngeneration tasks. Rather than executing generated code, BIS estimates\nperformance metrics by analyzing the prompt distribution alone. Built on\nimportance sampling theory and implemented using Importance Weighted\nAutoencoders, our method reweights samples from existing annotated benchmarks\nto estimate performance on new, unseen benchmarks. To stabilize the estimation,\nwe introduce weight truncation strategies and compute marginal expectations\nacross the fitted distributions. BIS serves as a complementary tool that\nsupports benchmark development and validation under constrained resources,\noffering actionable and quick feedback for prompt selection and contamination\nassessment. We conduct extensive experiments involving 8,000 evaluation points\nacross 4 CodeLlama models and 9 diverse benchmarks. Our framework achieves an\naverage absolute prediction error of 1.1% for code correctness scores, with\nbest- and worst-case errors of 0.3% and 1.9%, respectively. It also generalizes\nwell to other metrics, attaining average absolute errors of 2.15% for pass@1.\nThese results demonstrate the reliability and broad applicability of BIS, which\ncan significantly reduce the cost and effort of benchmarking LLMs in\ncode-related tasks."}
{"id": "2508.01208", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01208", "abs": "https://arxiv.org/abs/2508.01208", "authors": ["Mingchen Mei", "Yi Li", "YiYao Qian", "Zijun Jia"], "title": "Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests", "comment": null, "summary": "Fault detection is crucial for ensuring the safety and reliability of modern\nindustrial systems. However, a significant scientific challenge is the lack of\nrigorous risk control and reliable uncertainty quantification in existing\ndiagnostic models, particularly when facing complex scenarios such as\ndistributional shifts. To address this issue, this paper proposes a novel fault\ndetection method that integrates significance testing with the conformal\nprediction framework to provide formal risk guarantees. The method transforms\nfault detection into a hypothesis testing task by defining a nonconformity\nmeasure based on model residuals. It then leverages a calibration dataset to\ncompute p-values for new samples, which are used to construct prediction sets\nmathematically guaranteed to contain the true label with a user-specified\nprobability, $1-\\alpha$. Fault classification is subsequently performed by\nanalyzing the intersection of the constructed prediction set with predefined\nnormal and fault label sets. Experimental results on cross-domain fault\ndiagnosis tasks validate the theoretical properties of our approach. The\nproposed method consistently achieves an empirical coverage rate at or above\nthe nominal level ($1-\\alpha$), demonstrating robustness even when the\nunderlying point-prediction models perform poorly. Furthermore, the results\nreveal a controllable trade-off between the user-defined risk level ($\\alpha$)\nand efficiency, where higher risk tolerance leads to smaller average prediction\nset sizes. This research contributes a theoretically grounded framework for\nfault detection that enables explicit risk control, enhancing the\ntrustworthiness of diagnostic systems in safety-critical applications and\nadvancing the field from simple point predictions to informative,\nuncertainty-aware outputs."}
{"id": "2508.01237", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01237", "abs": "https://arxiv.org/abs/2508.01237", "authors": ["Cheng Tan", "Qi Chen", "Jingxuan Wei", "Gaowei Wu", "Zhangyang Gao", "Siyuan Li", "Bihui Yu", "Ruifeng Guo", "Stan Z. Li"], "title": "SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches", "comment": "Accepted by IJCAI 2025", "summary": "Hand-drawn sketches are a natural and efficient medium for capturing and\nconveying ideas. Despite significant advancements in controllable natural image\ngeneration, translating freehand sketches into structured, machine-readable\ndiagrams remains a labor-intensive and predominantly manual task. The primary\nchallenge stems from the inherent ambiguity of sketches, which lack the\nstructural constraints and semantic precision required for automated diagram\ngeneration. To address this challenge, we introduce SketchAgent, a multi-agent\nsystem designed to automate the transformation of hand-drawn sketches into\nstructured diagrams. SketchAgent integrates sketch recognition, symbolic\nreasoning, and iterative validation to produce semantically coherent and\nstructurally accurate diagrams, significantly reducing the need for manual\neffort. To evaluate the effectiveness of our approach, we propose the\nSketch2Diagram Benchmark, a comprehensive dataset and evaluation framework\nencompassing eight diverse diagram categories, such as flowcharts, directed\ngraphs, and model architectures. The dataset comprises over 6,000 high-quality\nexamples with token-level annotations, standardized preprocessing, and rigorous\nquality control. By streamlining the diagram generation process, SketchAgent\nholds great promise for applications in design, education, and engineering,\nwhile offering a significant step toward bridging the gap between intuitive\nsketching and machine-readable diagram generation. The benchmark is released at\nhttps://huggingface.co/datasets/DiagramAgent/Sketch2Diagram-Benchmark."}
{"id": "2508.01261", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01261", "abs": "https://arxiv.org/abs/2508.01261", "authors": ["Sushant Mehta", "Raj Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models", "comment": null, "summary": "We present MoE-MLA-RoPE, a novel architecture combination that combines\nMixture of Experts (MoE) with Multi-head Latent Attention (MLA) and Rotary\nPosition Embeddings (RoPE) for efficient language modeling. Our approach\naddresses the fundamental trade-off between model capacity and computational\nefficiency through three key innovations: (1) fine-grained expert routing with\n64 micro-experts and top-$k$ selection, enabling flexible specialization\nthrough 3.6 * 10^7 possible expert combinations; (2) shared expert isolation\nthat dedicates 2 always active experts for common patterns while routing to 6\nof 62 specialized experts; and (3) gradient-conflict-free load balancing that\nmaintains expert utilization without interfering with primary loss\noptimization.\n  Extensive experiments on models ranging from 17M to 202M parameters\ndemonstrate that MoE-MLA-RoPE with compression ratio r=d/2 achieves 68% KV\ncache memory reduction and 3.2x inference speedup while maintaining competitive\nperplexity (0.8% degradation). Compared to the parameters with 53.9M\nparameters, MoE-MLA-RoPE improves the validation loss by 6.9% over the vanilla\ntransformers while using 42% fewer active parameters per forward pass.\nFLOP-matched experiments reveal even larger gains: 11.1% improvement with 3.2x\ninference acceleration. Automated evaluation using GPT-4 as a judge confirms\nquality improvements in generation, with higher scores on coherence (8.1/10),\ncreativity (7.9/10) and grammatical correctness (8.2/10). Our results establish\nthat architectural novelty, not parameter scaling, defines the efficiency\nfrontier for resource-constrained language model deployment."}
{"id": "2508.01268", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.01268", "abs": "https://arxiv.org/abs/2508.01268", "authors": ["Roya Arkhmammadova", "Hosein Madadi Tamar", "M. Emre Gursoy"], "title": "Win-k: Improved Membership Inference Attacks on Small Language Models", "comment": null, "summary": "Small language models (SLMs) are increasingly valued for their efficiency and\ndeployability in resource-constrained environments, making them useful for\non-device, privacy-sensitive, and edge computing applications. On the other\nhand, membership inference attacks (MIAs), which aim to determine whether a\ngiven sample was used in a model's training, are an important threat with\nserious privacy and intellectual property implications. In this paper, we study\nMIAs on SLMs. Although MIAs were shown to be effective on large language models\n(LLMs), they are relatively less studied on emerging SLMs, and furthermore,\ntheir effectiveness decreases as models get smaller. Motivated by this finding,\nwe propose a new MIA called win-k, which builds on top of a state-of-the-art\nattack (min-k). We experimentally evaluate win-k by comparing it with five\nexisting MIAs using three datasets and eight SLMs. Results show that win-k\noutperforms existing MIAs in terms of AUROC, TPR @ 1% FPR, and FPR @ 99% TPR\nmetrics, especially on smaller models."}
{"id": "2508.01273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01273", "abs": "https://arxiv.org/abs/2508.01273", "authors": ["Xianda Zheng", "Zijian Huang", "Meng-Fen Chiang", "Michael J. Witbrock", "Kaiqi Zhao"], "title": "KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs", "comment": null, "summary": "Knowledge conflicts commonly arise across diverse sources, and their\nprevalence has increased with the advent of LLMs. When dealing with conflicts\nbetween multiple contexts, also known as \\emph{inter-context knowledge\nconflicts}, LLMs are often confused by lengthy and conflicting contexts. To\naddress this challenge, we propose the Knowledge Conflict Reasoning (KCR)\nframework, which enhances the ability of LLMs to resolve conflicting knowledge.\nThe key idea of KCR is to train backbone LLMs to establish a correct reasoning\nprocess by rewarding them for selecting and adhering to the context with\nstronger logical consistency when presented with conflicting contexts.\nSpecifically, we first extract reasoning paths, represented by either text or\nlocal knowledge graphs, from the conflicting long contexts. Subsequently, we\nemploy Reinforcement Learning to encourage the model to learn the paradigm of\nreasoning process that follows correct reasoning paths rather than the\nincorrect counterparts. This enables the backbone models to genuinely acquire\nthe capability to resolve inter-context knowledge conflicts within long\ncontexts. Experimental results demonstrate that our framework significantly\nimproves the ability of various backbone models to resolve knowledge conflicts\nin long-context scenarios, yielding substantial performance gains."}
{"id": "2508.01274", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01274", "abs": "https://arxiv.org/abs/2508.01274", "authors": ["Jui-Ming Yao", "Bing-Cheng Xie", "Sheng-Wei Peng", "Hao-Yuan Chen", "He-Rong Zheng", "Bing-Jia Tan", "Peter Shaojui Wang", "Shun-Feng Su"], "title": "Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) process visual, acoustic, and\ntextual inputs, addressing the limitations of single-modality LLMs. However,\nexisting benchmarks often overlook tri-modal evaluation in Traditional Chinese\nand do not consider inference latency. To address this, we introduce Multi-TW,\nthe first Traditional Chinese benchmark for evaluating the performance and\nlatency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice\nquestions (image and text, audio and text pairs) sourced from official\nproficiency tests developed with the Steering Committee for the Test of\nProficiency-Huayu (SC-TOP). We evaluated various any-to-any models and\nvision-language models (VLMs) with audio transcription. Our results show that\nclosed-source models generally outperform open-source ones across modalities,\nalthough open-source models can perform well in audio tasks. End-to-end\nany-to-any pipelines offer clear latency advantages compared to VLMs using\nseparate audio transcription. Multi-TW presents a comprehensive view of model\ncapabilities and highlights the need for Traditional Chinese fine-tuning and\nefficient multimodal architectures."}
{"id": "2508.01285", "categories": ["cs.AI", "cs.ET", "cs.IR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2508.01285", "abs": "https://arxiv.org/abs/2508.01285", "authors": ["Yujing Ke", "Kevin George", "Kathan Pandya", "David Blumenthal", "Maximilian Sprang", "Gerrit Großmann", "Sebastian Vollmer", "David Antony Selby"], "title": "BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation", "comment": "7 pages main content + 11 pages appendices", "summary": "Identifying novel hypotheses is essential to scientific research, yet this\nprocess risks being overwhelmed by the sheer volume and complexity of available\ninformation. Existing automated methods often struggle to generate novel and\nevidence-grounded hypotheses, lack robust iterative refinement and rarely\nundergo rigorous temporal evaluation for future discovery potential. To address\nthis, we propose BioDisco, a multi-agent framework that draws upon language\nmodel-based reasoning and a dual-mode evidence system (biomedical knowledge\ngraphs and automated literature retrieval) for grounded novelty, integrates an\ninternal scoring and feedback loop for iterative refinement, and validates\nperformance through pioneering temporal and human evaluations and a\nBradley-Terry paired comparison model to provide statistically-grounded\nassessment. Our evaluations demonstrate superior novelty and significance over\nablated configurations representative of existing agentic architectures.\nDesigned for flexibility and modularity, BioDisco allows seamless integration\nof custom language models or knowledge graphs, and can be run with just a few\nlines of code. We anticipate researchers using this practical tool as a\ncatalyst for the discovery of new hypotheses."}
{"id": "2508.01300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01300", "abs": "https://arxiv.org/abs/2508.01300", "authors": ["Ma'ayan Armony", "Albert Meroño-Peñuela", "Gerard Canal"], "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective", "comment": null, "summary": "The reasoning and planning abilities of Large Language Models (LLMs) have\nbeen a frequent topic of discussion in recent years. Their ability to take\nunstructured planning problems as input has made LLMs' integration into AI\nplanning an area of interest. Nevertheless, LLMs are still not reliable as\nplanners, with the generated plans often containing mistaken or hallucinated\nactions. Existing benchmarking and evaluation methods investigate planning with\nLLMs, focusing primarily on success rate as a quality indicator in various\nplanning tasks, such as validating plans or planning in relaxed conditions. In\nthis paper, we approach planning with LLMs as a natural language processing\n(NLP) task, given that LLMs are NLP models themselves. We propose a recovery\npipeline consisting of an NLP-based evaluation of the generated plans, along\nwith three stages to recover the plans through NLP manipulation of the\nLLM-generated plans, and eventually complete the plan using a symbolic planner.\nThis pipeline provides a holistic analysis of LLM capabilities in the context\nof AI task planning, enabling a broader understanding of the quality of invalid\nplans. Our findings reveal no clear evidence of underlying reasoning during\nplan generation, and that a pipeline comprising an NLP-based analysis of the\nplans, followed by a recovery mechanism, still falls short of the quality and\nreliability of classical planners. On average, only the first 2.65 actions of\nthe plan are executable, with the average length of symbolically generated\nplans being 8.4 actions. The pipeline still improves action quality and\nincreases the overall success rate from 21.9% to 27.5%."}
{"id": "2508.01306", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.01306", "abs": "https://arxiv.org/abs/2508.01306", "authors": ["Yelim Ahn", "Jaejin Lee"], "title": "PUZZLED: Jailbreaking LLMs through Word-Based Puzzles", "comment": "15 pages", "summary": "As large language models (LLMs) are increasingly deployed across diverse\ndomains, ensuring their safety has become a critical concern. In response,\nstudies on jailbreak attacks have been actively growing. Existing approaches\ntypically rely on iterative prompt engineering or semantic transformations of\nharmful instructions to evade detection. In this work, we introduce PUZZLED, a\nnovel jailbreak method that leverages the LLM's reasoning capabilities. It\nmasks keywords in a harmful instruction and presents them as word puzzles for\nthe LLM to solve. We design three puzzle types-word search, anagram, and\ncrossword-that are familiar to humans but cognitively demanding for LLMs. The\nmodel must solve the puzzle to uncover the masked words and then proceed to\ngenerate responses to the reconstructed harmful instruction. We evaluate\nPUZZLED on five state-of-the-art LLMs and observe a high average attack success\nrate (ASR) of 88.8%, specifically 96.5% on GPT-4.1 and 92.3% on Claude 3.7\nSonnet. PUZZLED is a simple yet powerful attack that transforms familiar\npuzzles into an effective jailbreak strategy by harnessing LLMs' reasoning\ncapabilities."}
{"id": "2508.01323", "categories": ["cs.AI", "cs.CY", "econ.GN", "q-fin.EC", "47H10, 06B10, 91B40, 91B55, 68T20", "I.2.0; I.2.11; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.01323", "abs": "https://arxiv.org/abs/2508.01323", "authors": ["Faruk Alpay", "Bugra Kilictas", "Taylan Alpay", "Hamdi Alakkad"], "title": "Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work", "comment": "25 pages, 9 figures, 4 tables. Proves existence/uniqueness of an\n  \"idempotent equilibrium\" for human-AI task allocation and provides\n  closed-form steady-state automation share", "summary": "The rapid advance of large-scale AI systems is reshaping how work is divided\nbetween people and machines. We formalise this reallocation as an iterated\ntask-delegation map and show that--under broad, empirically grounded\nassumptions--the process converges to a stable idempotent equilibrium in which\nevery task is performed by the agent (human or machine) with enduring\ncomparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski\nand Banach), we (i) prove existence of at least one such equilibrium and (ii)\nderive mild monotonicity conditions that guarantee uniqueness. In a stylised\ncontinuous model the long-run automated share takes the closed form $x^* =\n\\alpha / (\\alpha + \\beta)$, where $\\alpha$ captures the pace of automation and\n$\\beta$ the rate at which new, human-centric tasks appear; hence full\nautomation is precluded whenever $\\beta > 0$. We embed this analytic result in\nthree complementary dynamical benchmarks--a discrete linear update, an\nevolutionary replicator dynamic, and a continuous Beta-distributed task\nspectrum--each of which converges to the same mixed equilibrium and is\nreproducible from the provided code-free formulas. A 2025-to-2045 simulation\ncalibrated to current adoption rates projects automation rising from\napproximately 10% of work to approximately 65%, leaving a persistent one-third\nof tasks to humans. We interpret that residual as a new profession of workflow\nconductor: humans specialise in assigning, supervising and integrating AI\nmodules rather than competing with them. Finally, we discuss implications for\nskill development, benchmark design and AI governance, arguing that policies\nwhich promote \"centaur\" human-AI teaming can steer the economy toward the\nwelfare-maximising fixed point."}
{"id": "2508.01324", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01324", "abs": "https://arxiv.org/abs/2508.01324", "authors": ["Ke Miao", "Yuke Hu", "Xiaochen Li", "Wenjie Bao", "Zhihao Liu", "Zhan Qin", "Kui Ren"], "title": "Towards Evaluation for Real-World LLM Unlearning", "comment": null, "summary": "This paper analyzes the limitations of existing unlearning evaluation metrics\nin terms of practicality, exactness, and robustness in real-world LLM\nunlearning scenarios. To overcome these limitations, we propose a new metric\ncalled Distribution Correction-based Unlearning Evaluation (DCUE). It\nidentifies core tokens and corrects distributional biases in their confidence\nscores using a validation set. The evaluation results are quantified using the\nKolmogorov-Smirnov test. Experimental results demonstrate that DCUE overcomes\nthe limitations of existing metrics, which also guides the design of more\npractical and reliable unlearning algorithms in the future."}
{"id": "2508.01330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01330", "abs": "https://arxiv.org/abs/2508.01330", "authors": ["Zihan Zheng", "Tianle Cui", "Chuwen Xie", "Jiahui Zhang", "Jiahui Pan", "Lewei He", "Qianglong Chen"], "title": "NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset", "comment": null, "summary": "The rapid advancement of Large Language Model (LLM)-driven Graphical User\nInterface (GUI) agents is significantly hampered by the profound limitations of\nexisting evaluation benchmarks in terms of accuracy, reproducibility, and\nscalability. To address this critical gap, we introduce \\Benchmark, a novel\nbenchmark engineered on the principle of Causal Pathways. This design paradigm\nstructures complex tasks into a series of programmatically verifiable atomic\nsteps, ensuring a rigorous, fully automated, and reproducible standard for\nassessment. Concurrently, to mitigate the inherent capability deficits of\nagents, we developed \\Agent, a hierarchical agent architecture specifically\noptimized for long-horizon tasks. We leveraged this agent to generate a\nhigh-quality, human-verified trajectory dataset that uniquely captures diverse\nand even self-correcting interaction patterns of LLMs. We then utilized this\ndataset to perform Reinforcement Fine-Tuning (RFT) on the Qwen2.5-VL-7B model.\nOur experiments reveal that \\Benchmark~presents a formidable challenge to\ncurrent state-of-the-art LLMs; even the top-performing Claude-sonnet-4 achieved\na Weighted Pathway Success Rate (WPSR) of only 34.6\\%. Moreover, while RFT\nsubstantially improved the smaller model's GUI execution capabilities (WPSR\nincreased from 3.3\\% to 10.8\\%), its performance degraded sharply when handling\ncomplex scenarios. This outcome highlights the inherent capability ceiling of\nsmaller models when faced with comprehensive tasks that integrate perception,\ndecision-making, and execution. This research contributes a rigorous evaluation\nstandard and a high-quality dataset to the community, aiming to guide the\nfuture development of GUI agents."}
{"id": "2508.01368", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01368", "abs": "https://arxiv.org/abs/2508.01368", "authors": ["Zhehong Ren", "Tianluo Zhang", "Yiheng Lu", "Yushen Liang", "Promethee Spathis"], "title": "Relation-Aware LNN-Transformer for Intersection-Centric Next-Step Prediction", "comment": "8 pages, 5 figures", "summary": "Next-step location prediction plays a pivotal role in modeling human\nmobility, underpinning applications from personalized navigation to strategic\nurban planning. However, approaches that assume a closed world - restricting\nchoices to a predefined set of points of interest (POIs) - often fail to\ncapture exploratory or target-agnostic behavior and the topological constraints\nof urban road networks. Hence, we introduce a road-node-centric framework that\nrepresents road-user trajectories on the city's road-intersection graph,\nthereby relaxing the closed-world constraint and supporting next-step\nforecasting beyond fixed POI sets. To encode environmental context, we\nintroduce a sector-wise directional POI aggregation that produces compact\nfeatures capturing distance, bearing, density and presence cues. By combining\nthese cues with structural graph embeddings, we obtain semantically grounded\nnode representations. For sequence modeling, we integrate a Relation-Aware\nLNN-Transformer - a hybrid of a Continuous-time Forgetting Cell CfC-LNN and a\nbearing-biased self-attention module - to capture both fine-grained temporal\ndynamics and long-range spatial dependencies. Evaluated on city-scale road-user\ntrajectories, our model outperforms six state-of-the-art baselines by up to 17\npercentage points in accuracy at one hop and 10 percentage points in MRR, and\nmaintains high resilience under noise, losing only 2.4 percentage points in\naccuracy at one under 50 meter GPS perturbation and 8.9 percentage points in\naccuracy at one hop under 25 percent POI noise."}
{"id": "2508.01432", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01432", "abs": "https://arxiv.org/abs/2508.01432", "authors": ["Yuanzhe Shen", "Kaimin Wang", "Changze Lv", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "TripTailor: A Real-World Benchmark for Personalized Travel Planning", "comment": "Accepted to ACL 2025 Findings", "summary": "The continuous evolution and enhanced reasoning capabilities of large\nlanguage models (LLMs) have elevated their role in complex tasks, notably in\ntravel planning, where demand for personalized, high-quality itineraries is\nrising. However, current benchmarks often rely on unrealistic simulated data,\nfailing to reflect the differences between LLM-generated and real-world\nitineraries. Existing evaluation metrics, which primarily emphasize\nconstraints, fall short of providing a comprehensive assessment of the overall\nquality of travel plans. To address these limitations, we introduce TripTailor,\na benchmark designed specifically for personalized travel planning in\nreal-world scenarios. This dataset features an extensive collection of over\n500,000 real-world points of interest (POIs) and nearly 4,000 diverse travel\nitineraries, complete with detailed information, providing a more authentic\nevaluation framework. Experiments show that fewer than 10\\% of the itineraries\ngenerated by the latest state-of-the-art LLMs achieve human-level performance.\nMoreover, we identify several critical challenges in travel planning, including\nthe feasibility, rationality, and personalized customization of the proposed\nsolutions. We hope that TripTailor will drive the development of travel\nplanning agents capable of understanding and meeting user needs while\ngenerating practical itineraries. Our code and dataset are available at\nhttps://github.com/swxkfm/TripTailor"}
{"id": "2508.01475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01475", "abs": "https://arxiv.org/abs/2508.01475", "authors": ["Zhen Wu", "Ritam Dutt", "Luke M. Breitfeller", "Armineh Nourbakhsh", "Siddharth Parekh", "Carolyn Rosé"], "title": "$R^2$-CoD: Understanding Text-Graph Complementarity in Relational Reasoning via Knowledge Co-Distillation", "comment": null, "summary": "Relational reasoning lies at the core of many NLP tasks, drawing on\ncomplementary signals from text and graphs. While prior research has\ninvestigated how to leverage this dual complementarity, a detailed and\nsystematic understanding of text-graph interplay and its effect on hybrid\nmodels remains underexplored. We take an analysis-driven approach to\ninvestigate text-graph representation complementarity via a unified\narchitecture that supports knowledge co-distillation (CoD). We explore five\ntasks involving relational reasoning that differ in how text and graph\nstructures encode the information needed to solve that task. By tracking how\nthese dual representations evolve during training, we uncover interpretable\npatterns of alignment and divergence, and provide insights into when and why\ntheir integration is beneficial."}
{"id": "2508.01476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01476", "abs": "https://arxiv.org/abs/2508.01476", "authors": ["Arindam Khanda", "Anurag Satpathy", "Amit Jha", "Sajal K. Das"], "title": "CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics", "comment": null, "summary": "With growing interest in sustainable logistics, electric vehicle (EV)-based\ndeliveries offer a promising alternative for urban distribution. However, EVs\nface challenges due to their limited battery capacity, requiring careful\nplanning for recharging. This depends on factors such as the charging point\n(CP) availability, cost, proximity, and vehicles' state of charge (SoC). We\npropose CARGO, a framework addressing the EV-based delivery route planning\nproblem (EDRP), which jointly optimizes route planning and charging for\ndeliveries within time windows. After proving the problem's NP-hardness, we\npropose a mixed integer linear programming (MILP)-based exact solution and a\ncomputationally efficient heuristic method. Using real-world datasets, we\nevaluate our methods by comparing the heuristic to the MILP solution, and\nbenchmarking it against baseline strategies, Earliest Deadline First (EDF) and\nNearest Delivery First (NDF). The results show up to 39% and 22% reductions in\nthe charging cost over EDF and NDF, respectively, while completing comparable\ndeliveries."}
{"id": "2508.01495", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01495", "abs": "https://arxiv.org/abs/2508.01495", "authors": ["Jingtian Yan", "Stephen F. Smith", "Jiaoyang Li"], "title": "WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning", "comment": null, "summary": "Planning collision-free paths for a large group of agents is a challenging\nproblem with numerous real-world applications. While recent advances in\nMulti-Agent Path Finding (MAPF) have shown promising progress, standard MAPF\nalgorithms rely on simplified kinodynamic models, preventing agents from\ndirectly following the generated MAPF plan. To bridge this gap, we propose\nkinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed\noptimization algorithm that efficiently refines a MAPF plan into a\nkinodynamically feasible plan while accounting for uncertainties and preserving\ncollision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a\nMAPF execution framework that incrementally refines MAPF plans using a\nwindow-based mechanism, dynamically incorporating agent information during\nexecution to reduce uncertainty. Experiments show that WinkTPG can generate\nspeed profiles for up to 1,000 agents in 1 second and improves solution quality\nby up to 51.7% over existing MAPF execution methods."}
{"id": "2508.01543", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01543", "abs": "https://arxiv.org/abs/2508.01543", "authors": ["Derin Cayir", "Renjie Tao", "Rashi Rungta", "Kai Sun", "Sean Chen", "Haidar Khan", "Minseok Kim", "Julia Reinspach", "Yue Liu"], "title": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable progress through\npreference-based fine-tuning, which critically depends on the quality of the\nunderlying training data. While human feedback is essential for improving data\nquality, it is costly and does not scale well. In this paper, we introduce\nRefine-n-Judge, an automated iterative approach that leverages a single LLM as\nboth a refiner and a judge to enhance dataset quality. Unlike existing\niterative refinement methods, Refine-n-Judge employs an LLM to both generate\nrefinements and explicitly evaluate each improvement, ensuring that every\niteration meaningfully enhances the dataset without requiring additional human\nannotation or a separate reward model. At each step, the LLM refines a response\nand judges whether the refinement is an improvement over the previous answer.\nThis process continues until the LLM prefers the initial answer over the\nrefinement, indicating no further improvements. This produces sequences of\nincreasing quality, preference-labeled responses ideal for fine-tuning.\n  We demonstrate the effectiveness of Refine-n-Judge across a range of public\ndatasets spanning five corpora, targeting tasks such as coding, math, and\nconversation. Models (Llama 3.1-8B and Llama 3.3-70B) fine-tuned on\nRefine-n-Judge-enhanced datasets were preferred by LLM judges in over 74% of\ncomparisons against models tuned on the original dataset by GPT-4.\nAdditionally, we report performance gains: +5% on AlpacaEval and AlpacaEval\n2.0, and +19% on MT-Bench. Our results indicate that Refine-n-Judge produces\nhigh-quality datasets and scalable model improvements."}
{"id": "2508.01545", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.01545", "abs": "https://arxiv.org/abs/2508.01545", "authors": ["Emilio Barkett", "Olivia Long", "Paul Kröger"], "title": "Getting out of the Big-Muddy: Escalation of Commitment in LLMs", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in autonomous\ndecision-making roles across high-stakes domains. However, since models are\ntrained on human-generated data, they may inherit cognitive biases that\nsystematically distort human judgment, including escalation of commitment,\nwhere decision-makers continue investing in failing courses of action due to\nprior investment. Understanding when LLMs exhibit such biases presents a unique\nchallenge. While these biases are well-documented in humans, it remains unclear\nwhether they manifest consistently in LLMs or require specific triggering\nconditions. This paper investigates this question using a two-stage investment\ntask across four experimental conditions: model as investor, model as advisor,\nmulti-agent deliberation, and compound pressure scenario. Across N = 6,500\ntrials, we find that bias manifestation in LLMs is highly context-dependent. In\nindividual decision-making contexts (Studies 1-2, N = 4,000), LLMs demonstrate\nstrong rational cost-benefit logic with minimal escalation of commitment.\nHowever, multi-agent deliberation reveals a striking hierarchy effect (Study 3,\nN = 500): while asymmetrical hierarchies show moderate escalation rates\n(46.2%), symmetrical peer-based decision-making produces near-universal\nescalation (99.2%). Similarly, when subjected to compound organizational and\npersonal pressures (Study 4, N = 2,000), models exhibit high degrees of\nescalation of commitment (68.95% average allocation to failing divisions).\nThese findings reveal that LLM bias manifestation depends critically on social\nand organizational context rather than being inherent, with significant\nimplications for the deployment of multi-agent systems and unsupervised\noperations where such conditions may emerge naturally."}
{"id": "2508.01556", "categories": ["cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.01556", "abs": "https://arxiv.org/abs/2508.01556", "authors": ["Mengshi Chen", "Yuxiang Sun", "Tengchao Li", "Jianwei Wang", "Kai Wang", "Xuemin Lin", "Ying Zhang", "Wenjie Zhang"], "title": "Empowering Tabular Data Preparation with Language Models: Why and How?", "comment": "Preprint under submission, 16 pages, 2 figures, 1 table", "summary": "Data preparation is a critical step in enhancing the usability of tabular\ndata and thus boosts downstream data-driven tasks. Traditional methods often\nface challenges in capturing the intricate relationships within tables and\nadapting to the tasks involved. Recent advances in Language Models (LMs),\nespecially in Large Language Models (LLMs), offer new opportunities to automate\nand support tabular data preparation. However, why LMs suit tabular data\npreparation (i.e., how their capabilities match task demands) and how to use\nthem effectively across phases still remain to be systematically explored. In\nthis survey, we systematically analyze the role of LMs in enhancing tabular\ndata preparation processes, focusing on four core phases: data acquisition,\nintegration, cleaning, and transformation. For each phase, we present an\nintegrated analysis of how LMs can be combined with other components for\ndifferent preparation tasks, highlight key advancements, and outline\nprospective pipelines."}
{"id": "2508.01561", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01561", "abs": "https://arxiv.org/abs/2508.01561", "authors": ["Zijian Guo", "İlker Işık", "H. M. Sabbir Ahmad", "Wenchao Li"], "title": "One Subgoal at a Time: Zero-Shot Generalization to Arbitrary Linear Temporal Logic Requirements in Multi-Task Reinforcement Learning", "comment": null, "summary": "Generalizing to complex and temporally extended task objectives and safety\nconstraints remains a critical challenge in reinforcement learning (RL). Linear\ntemporal logic (LTL) offers a unified formalism to specify such requirements,\nyet existing methods are limited in their abilities to handle nested\nlong-horizon tasks and safety constraints, and cannot identify situations when\na subgoal is not satisfiable and an alternative should be sought. In this\npaper, we introduce GenZ-LTL, a method that enables zero-shot generalization to\narbitrary LTL specifications. GenZ-LTL leverages the structure of B\\\"uchi\nautomata to decompose an LTL task specification into sequences of reach-avoid\nsubgoals. Contrary to the current state-of-the-art method that conditions on\nsubgoal sequences, we show that it is more effective to achieve zero-shot\ngeneralization by solving these reach-avoid problems \\textit{one subgoal at a\ntime} through proper safe RL formulations. In addition, we introduce a novel\nsubgoal-induced observation reduction technique that can mitigate the\nexponential complexity of subgoal-state combinations under realistic\nassumptions. Empirical results show that GenZ-LTL substantially outperforms\nexisting methods in zero-shot generalization to unseen LTL specifications."}
{"id": "2508.01581", "categories": ["cs.AI", "math.CO", "stat.CO"], "pdf": "https://arxiv.org/pdf/2508.01581", "abs": "https://arxiv.org/abs/2508.01581", "authors": ["David Pearl", "Matthew Murphy", "James Intriligator"], "title": "Polymorphic Combinatorial Frameworks (PCF): Guiding the Design of Mathematically-Grounded, Adaptive AI Agents", "comment": null, "summary": "The Polymorphic Combinatorial Framework (PCF) leverages Large Language Models\n(LLMs) and mathematical frameworks to guide the meta-prompt enabled design of\nsolution spaces and adaptive AI agents for complex, dynamic environments.\nUnlike static agent architectures, PCF enables real-time parameter\nreconfiguration through mathematically-grounded combinatorial spaces, allowing\nagents to adapt their core behavioral traits dynamically. Grounded in\ncombinatorial logic, topos theory, and rough fuzzy set theory, PCF defines a\nmultidimensional SPARK parameter space (Skills, Personalities, Approaches,\nResources, Knowledge) to capture agent behaviors. This paper demonstrates how\nLLMs can parameterize complex spaces and estimate likely parameter\nvalues/variabilities. Using PCF, we parameterized mock caf\\'e domains (five\nlevels of complexity), estimated variables/variabilities, and conducted over\n1.25 million Monte Carlo simulations. The results revealed trends in agent\nadaptability and performance across the five complexity tiers, with diminishing\nreturns at higher complexity levels highlighting thresholds for scalable\ndesigns. PCF enables the generation of optimized agent configurations for\nspecific scenarios while maintaining logical consistency. This framework\nsupports scalable, dynamic, explainable, and ethical AI applications in domains\nlike customer service, healthcare, robotics, and collaborative systems, paving\nthe way for adaptable and cooperative next-generation polymorphic agents."}
{"id": "2508.01623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01623", "abs": "https://arxiv.org/abs/2508.01623", "authors": ["Tadisetty Sai Yashwanth", "Dhatri C"], "title": "A Multi-Agent Pokemon Tournament for Evaluating Strategic Reasoning of Large Language Models", "comment": null, "summary": "This research presents LLM Pokemon League, a competitive tournament system\nthat leverages Large Language Models (LLMs) as intelligent agents to simulate\nstrategic decision-making in Pok\\'emon battles. The platform is designed to\nanalyze and compare the reasoning, adaptability, and tactical depth exhibited\nby different LLMs in a type-based, turn-based combat environment. By\nstructuring the competition as a single-elimination tournament involving\ndiverse AI trainers, the system captures detailed decision logs, including\nteam-building rationale, action selection strategies, and switching decisions.\nThe project enables rich exploration into comparative AI behavior, battle\npsychology, and meta-strategy development in constrained, rule-based game\nenvironments. Through this system, we investigate how modern LLMs understand,\nadapt, and optimize decisions under uncertainty, making Pok\\'emon League a\nnovel benchmark for AI research in strategic reasoning and competitive\nlearning."}
{"id": "2508.01670", "categories": ["cs.AI", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2508.01670", "abs": "https://arxiv.org/abs/2508.01670", "authors": ["Jiaqing Xie", "Weida Wang", "Ben Gao", "Zhuo Yang", "Haiyuan Wan", "Shufei Zhang", "Tianfan Fu", "Yuqiang Li"], "title": "QCBench: Evaluating Large Language Models on Domain-Specific Quantitative Chemistry", "comment": "13 pages, 8 figures", "summary": "Quantitative chemistry plays a fundamental role in chemistry research,\nenabling precise predictions of molecular properties, reaction outcomes, and\nmaterial behaviors. While large language models (LLMs) have shown promise in\nchemistry-related tasks, their ability to perform rigorous, step-by-step\nquantitative reasoning remains underexplored. To fill this blank, we propose\nQCBench, a Quantitative Chemistry benchmark comprising 350 computational\nchemistry problems across 7 chemistry subfields (analytical chemistry,\nbio/organic chemistry, general chemistry, inorganic chemistry, physical\nchemistry, polymer chemistry and quantum chemistry), categorized into three\nhierarchical tiers-basic, intermediate, and expert-to systematically evaluate\nthe mathematical reasoning abilities of large language models (LLMs). Designed\nto minimize shortcuts and emphasize stepwise numerical reasoning, each problem\nfocuses on pure calculations rooted in real-world chemical vertical fields.\nQCBench enables fine-grained diagnosis of computational weaknesses, reveals\nmodel-specific limitations across difficulty levels, and lays the groundwork\nfor future improvements such as domain adaptive fine-tuning or multi-modal\nintegration. Evaluations on 19 LLMs demonstrate a consistent performance\ndegradation with increasing task complexity, highlighting the current gap\nbetween language fluency and scientific computation accuracy."}
{"id": "2508.01680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01680", "abs": "https://arxiv.org/abs/2508.01680", "authors": ["Dong Li", "Yichen Niu", "Ying Ai", "Xiang Zou", "Biqing Qi", "Jianxing Liu"], "title": "T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance in natural\nlanguage generation but remain limited in knowle-\n  dge-intensive tasks due to outdated or incomplete internal knowledge.\nRetrieval-Augmented Generation (RAG) addresses this by incorporating external\nretrieval, with GraphRAG further enhancing performance through structured\nknowledge graphs and multi-hop reasoning. However, existing GraphRAG methods\nlargely ignore the temporal dynamics of knowledge, leading to issues such as\ntemporal ambiguity, time-insensitive retrieval, and semantic redundancy. To\novercome these limitations, we propose Temporal GraphRAG (T-GRAG), a dynamic,\ntemporally-aware RAG framework that models the evolution of knowledge over\ntime. T-GRAG consists of five key components: (1) a Temporal Knowledge Graph\nGenerator that creates time-stamped, evolving graph structures; (2) a Temporal\nQuery Decomposition mechanism that breaks complex temporal queries into\nmanageable sub-queries; (3) a Three-layer Interactive Retriever that\nprogressively filters and refines retrieval across temporal subgraphs; (4) a\nSource Text Extractor to mitigate noise; and (5) a LLM-based Generator that\nsynthesizes contextually and temporally accurate responses. We also introduce\nTime-LongQA, a novel benchmark dataset based on real-world corporate annual\nreports, designed to test temporal reasoning across evolving knowledge.\nExtensive experiments show that T-GRAG significantly outperforms prior RAG and\nGraphRAG baselines in both retrieval accuracy and response relevance under\ntemporal constraints, highlighting the necessity of modeling knowledge\nevolution for robust long-text question answering. Our code is publicly\navailable on the T-GRAG"}
{"id": "2508.01693", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.01693", "abs": "https://arxiv.org/abs/2508.01693", "authors": ["Yuhang Gu", "Xingyu Hu", "Yuyu Fan", "Xulin Yan", "Longhuan Xu", "Peng peng"], "title": "SURE-Med: Systematic Uncertainty Reduction for Enhanced Reliability in Medical Report Generation", "comment": null, "summary": "Automated medical report generation (MRG) holds great promise for reducing\nthe heavy workload of radiologists. However, its clinical deployment is\nhindered by three major sources of uncertainty. First, visual uncertainty,\ncaused by noisy or incorrect view annotations, compromises feature extraction.\nSecond, label distribution uncertainty, stemming from long-tailed disease\nprevalence, biases models against rare but clinically critical conditions.\nThird, contextual uncertainty, introduced by unverified historical reports,\noften leads to factual hallucinations. These challenges collectively limit the\nreliability and clinical trustworthiness of MRG systems. To address these\nissues, we propose SURE-Med, a unified framework that systematically reduces\nuncertainty across three critical dimensions: visual, distributional, and\ncontextual. To mitigate visual uncertainty, a Frontal-Aware View Repair\nResampling module corrects view annotation errors and adaptively selects\ninformative features from supplementary views. To tackle label distribution\nuncertainty, we introduce a Token Sensitive Learning objective that enhances\nthe modeling of critical diagnostic sentences while reweighting\nunderrepresented diagnostic terms, thereby improving sensitivity to infrequent\nconditions. To reduce contextual uncertainty, our Contextual Evidence Filter\nvalidates and selectively incorporates prior information that aligns with the\ncurrent image, effectively suppressing hallucinations. Extensive experiments on\nthe MIMIC-CXR and IU-Xray benchmarks demonstrate that SURE-Med achieves\nstate-of-the-art performance. By holistically reducing uncertainty across\nmultiple input modalities, SURE-Med sets a new benchmark for reliability in\nmedical report generation and offers a robust step toward trustworthy clinical\ndecision support."}
{"id": "2508.01700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01700", "abs": "https://arxiv.org/abs/2508.01700", "authors": ["Zhihao Shuai", "Boyan Li", "Siyu Yan", "Yuyu Luo", "Weikai Yang"], "title": "DeepVIS: Bridging Natural Language and Data Visualization Through Step-wise Reasoning", "comment": null, "summary": "Although data visualization is powerful for revealing patterns and\ncommunicating insights, creating effective visualizations requires familiarity\nwith authoring tools and often disrupts the analysis flow. While large language\nmodels show promise for automatically converting analysis intent into\nvisualizations, existing methods function as black boxes without transparent\nreasoning processes, which prevents users from understanding design rationales\nand refining suboptimal outputs. To bridge this gap, we propose integrating\nChain-of-Thought (CoT) reasoning into the Natural Language to Visualization\n(NL2VIS) pipeline. First, we design a comprehensive CoT reasoning process for\nNL2VIS and develop an automatic pipeline to equip existing datasets with\nstructured reasoning steps. Second, we introduce nvBench-CoT, a specialized\ndataset capturing detailed step-by-step reasoning from ambiguous natural\nlanguage descriptions to finalized visualizations, which enables\nstate-of-the-art performance when used for model fine-tuning. Third, we develop\nDeepVIS, an interactive visual interface that tightly integrates with the CoT\nreasoning process, allowing users to inspect reasoning steps, identify errors,\nand make targeted adjustments to improve visualization outcomes. Quantitative\nbenchmark evaluations, two use cases, and a user study collectively demonstrate\nthat our CoT framework effectively enhances NL2VIS quality while providing\ninsightful reasoning steps to users."}
{"id": "2508.01724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01724", "abs": "https://arxiv.org/abs/2508.01724", "authors": ["Shijie Cao", "Yuan Yuan"], "title": "ReflecSched: Solving Dynamic Flexible Job-Shop Scheduling via LLM-Powered Hierarchical Reflection", "comment": null, "summary": "Dynamic Flexible Job-Shop Scheduling (DFJSP) is an NP-hard problem challenged\nby real-time event adaptation and complex machine routing. While traditional\ndispatching rules are efficient but rigid, deep learning approaches are opaque\nand require intricate feature engineering. Large Language Models (LLMs) promise\nadaptive reasoning without this engineering overhead, yet we find their direct\napplication is suboptimal. Baseline LLMs suffer from three key pitfalls: the\nlong-context paradox, where crucial data is underutilized; an underutilization\nof expert heuristics; and myopic decision-making. To address this, we propose\nReflecSched, a framework that empowers the LLM beyond a direct scheduler by\nequipping it with a strategic analysis capability. ReflecSched tasks the LLM to\nanalyze heuristic-driven simulations across multiple planning horizons and\ndistill them into a concise, natural-language summary termed ``Strategic\nExperience''. This summary is then integrated into the prompt of a final\ndecision-making module, guiding it to produce non-myopic actions. Experiments\nshow that ReflecSched not only statistically significantly outperforms direct\nLLM baselines, securing a 71.35\\% Win Rate and a 2.755\\% Relative Percentage\nDeviation reduction, but also surpasses the performance of all individual\nheuristics evaluated, all while demonstrably mitigating the three identified\npitfalls. Additionally, ReflecSched performs on par with the best heuristic\ntailored to each instance across all problem cases."}
{"id": "2508.01746", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2508.01746", "abs": "https://arxiv.org/abs/2508.01746", "authors": ["Shiyang Duan", "Yuan Tian", "Qi Bing", "Xiaowei Shao"], "title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization", "comment": "Corresponding author: Xiaowei Shao. 12 pages, 4 figures", "summary": "The exponential growth of scientific knowledge has made the automated\ngeneration of scientific hypotheses that combine novelty, feasibility, and\nresearch value a core challenge. Existing methods based on large language\nmodels fail to systematically model the inherent in hypotheses or incorporate\nthe closed-loop feedback mechanisms crucial for refinement. This paper proposes\na multi-agent collaborative framework called HypoAgents, which for the first\ntime integrates Bayesian reasoning with an information entropy-driven search\nmechanism across three stages-hypotheses generation, evidence validation, and\nhypotheses Refinement-to construct an iterative closed-loop simulating\nscientists' cognitive processes. Specifically, the framework first generates an\ninitial set of hypotheses through diversity sampling and establishes prior\nbeliefs based on a composite novelty-relevance-feasibility (N-R-F) score. It\nthen employs etrieval-augmented generation (RAG) to gather external literature\nevidence, updating the posterior probabilities of hypotheses using Bayes'\ntheorem. Finally, it identifies high-uncertainty hypotheses using information\nentropy $H = - \\sum {{p_i}\\log {p_i}}$ and actively refines them, guiding the\niterative optimization of the hypothesis set toward higher quality and\nconfidence. Experimental results on the ICLR 2025 conference real-world\nresearch question dataset (100 research questions) show that after 12\noptimization iterations, the average ELO score of generated hypotheses improves\nby 116.3, surpassing the benchmark of real paper abstracts by 17.8, while the\nframework's overall uncertainty, as measured by Shannon entropy, decreases\nsignificantly by 0.92. This study presents an interpretable probabilistic\nreasoning framework for automated scientific discovery, substantially improving\nthe quality and reliability of machine-generated research hypotheses."}
{"id": "2508.01751", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01751", "abs": "https://arxiv.org/abs/2508.01751", "authors": ["Pierre Schaus", "Charles Thomas", "Roger Kameugne"], "title": "Implementing Cumulative Functions with Generalized Cumulative Constraints", "comment": null, "summary": "Modeling scheduling problems with conditional time intervals and cumulative\nfunctions has become a common approach when using modern commercial constraint\nprogramming solvers. This paradigm enables the modeling of a wide range of\nscheduling problems, including those involving producers and consumers.\nHowever, it is unavailable in existing open-source solvers and practical\nimplementation details remain undocumented. In this work, we present an\nimplementation of this modeling approach using a single, generic global\nconstraint called the Generalized Cumulative. We also introduce a novel\ntime-table filtering algorithm designed to handle tasks defined on conditional\ntime-intervals. Experimental results demonstrate that this approach, combined\nwith the new filtering algorithm, performs competitively with existing solvers\nenabling the modeling of producer and consumer scheduling problems and\neffectively scales to large problems."}
{"id": "2508.01763", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.01763", "abs": "https://arxiv.org/abs/2508.01763", "authors": ["Saleh Nikooroo", "Thomas Engel"], "title": "Reasoning Systems as Structured Processes: Foundations, Failures, and Formal Criteria", "comment": null, "summary": "This paper outlines a general formal framework for reasoning systems,\nintended to support future analysis of inference architectures across domains.\nWe model reasoning systems as structured tuples comprising phenomena,\nexplanation space, inference and generation maps, and a principle base. The\nformulation accommodates logical, algorithmic, and learning-based reasoning\nprocesses within a unified structural schema, while remaining agnostic to any\nspecific reasoning algorithm or logic system. We survey basic internal\ncriteria--including coherence, soundness, and completeness-and catalog typical\nfailure modes such as contradiction, incompleteness, and non-convergence. The\nframework also admits dynamic behaviors like iterative refinement and principle\nevolution. The goal of this work is to establish a foundational structure for\nrepresenting and comparing reasoning systems, particularly in contexts where\ninternal failure, adaptation, or fragmentation may arise. No specific solution\narchitecture is proposed; instead, we aim to support future theoretical and\npractical investigations into reasoning under structural constraint."}
{"id": "2508.01773", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01773", "abs": "https://arxiv.org/abs/2508.01773", "authors": ["Jiuzhou Han", "Wray Buntine", "Ehsan Shareghi"], "title": "Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning", "comment": null, "summary": "Large language models have demonstrated remarkable capabilities in complex\nmathematical reasoning tasks, but they inevitably generate errors throughout\nmulti-step solutions. Process-level Reward Models (PRMs) have shown great\npromise by providing supervision and evaluation at each intermediate step,\nthereby effectively improving the models' reasoning abilities. However,\ntraining effective PRMs requires high-quality process reward data, yet existing\nmethods for constructing such data are often labour-intensive or inefficient.\nIn this paper, we propose an uncertainty-driven framework for automated process\nreward data construction, encompassing both data generation and annotation\nprocesses for PRMs. Additionally, we identify the limitations of both majority\nvote and PRMs, and introduce two generic uncertainty-aware output aggregation\nmethods: Hybrid Majority Reward Vote and Weighted Reward Frequency Vote, which\ncombine the strengths of majority vote with PRMs. Extensive experiments on\nProcessBench, MATH, and GSMPlus show the effectiveness and efficiency of the\nproposed PRM data construction framework, and demonstrate that the two output\naggregation methods further improve the mathematical reasoning abilities across\ndiverse PRMs. The code and data will be publicly available at\nhttps://github.com/Jiuzhouh/UnPRM."}
{"id": "2508.01780", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.01780", "abs": "https://arxiv.org/abs/2508.01780", "authors": ["Guozhao Mo", "Wenliang Zhong", "Jiawei Chen", "Xuanang Chen", "Yaojie Lu", "Hongyu Lin", "Ben He", "Xianpei Han", "Le Sun"], "title": "LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?", "comment": "Our code and data will be publicly available at\n  https://icip-cas.github.io/LiveMCPBench", "summary": "With the rapid development of Model Context Protocol (MCP), the number of MCP\nservers has surpassed 10,000. However, existing MCP benchmarks are limited to\nsingle-server settings with only a few tools, hindering effective evaluation of\nagent capabilities in large-scale, real-world scenarios. To address this\nlimitation, we present LiveMCPBench, the first comprehensive benchmark\ncomprising 95 real-world tasks grounded in the MCP ecosystem, designed to\nevaluate LLM agents at scale across diverse servers. To support a scalable and\nreproducible evaluation pipeline in large-scale MCP environments, we curate\nLiveMCPTool, a diverse and readily deployable collection of 70 MCP servers and\n527 tools. Furthermore, we introduce LiveMCPEval, an LLM-as-a-Judge framework\nthat enables automated and adaptive evaluation in dynamic, time-varying task\nenvironments, achieving 81% agreement with human reviewers. Finally, we propose\nthe MCP Copilot Agent, a multi-step agent that routes tools for dynamic\nplanning and executes tools for API interaction across the entire LiveMCPTool\nsuite. Our evaluation covers 10 leading models, with the best-performing model\n(Claude-Sonnet-4) reaching a 78.95% success rate. However, we observe large\nperformance variance across models, and several widely-used models perform\npoorly in LiveMCPBench's complex, tool-rich environments. Overall, LiveMCPBench\noffers the first unified framework for benchmarking LLM agents in realistic,\ntool-rich, and dynamic MCP environments, laying a solid foundation for scalable\nand reproducible research on agent capabilities. Our code and data will be\npublicly available at https://icip-cas.github.io/LiveMCPBench."}
{"id": "2508.01844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01844", "abs": "https://arxiv.org/abs/2508.01844", "authors": ["Xinkai Zou", "Xuan Jiang", "Ruikai Huang", "Haoze He", "Parv Kapoor", "Jiahua Zhao"], "title": "CloudAnoAgent: Anomaly Detection for Cloud Sites via LLM Agent with Neuro-Symbolic Mechanism", "comment": null, "summary": "Anomaly detection in cloud sites remains a critical yet challenging task.\nExisting approaches that rely solely on metric data often suffer from high\nfalse positive rates (FPR) due to data imbalance between normal and anomalous\nevents, leading to significant operational overhead for system reliance\nengineers. Recent advances in large language models (LLMs) offer new\nopportunities for integrating metrics with log data, enabling more accurate and\ninterpretable anomaly detection. In this paper, we propose CloudAnoAgent, the\nfirst neuro-symbolic LLM-based agent for anomaly detection in cloud\nenvironments. CloudAnoAgent jointly processes structured metrics and textual\nlog data in a unified pipeline, leveraging symbolic verification to validate\ndetection hypotheses and generate structured anomaly reports. To support\nsystematic evaluation, we introduce CloudAnoBench, the first benchmark that\nprovides LLM-generated paired metrics and log data with fine-grained anomaly\nbehavior annotations, filling a critical gap in existing datasets. Experimental\nresults demonstrate that CloudAnoAgent improves anomaly classification accuracy\nby 46.36% and 36.67% on average and reduces the FPR by 36.67% and 33.89% on\naverage over traditional baselines and LLM-only baseline, with a boost on\nanomaly type detection accuracy by 12.8% compared to vanilla LLM prompting.\nThese results demonstrate the strengths of our approach in improving detection\naccuracy, reducing false positives, and enhancing interpretability, thereby\nsupporting practical deployment in enterprise cloud environments."}
{"id": "2508.01869", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01869", "abs": "https://arxiv.org/abs/2508.01869", "authors": ["Yuanyuan Liang", "Xiaoman Wang", "Tingyu Xie", "Lei Pan"], "title": "ProKG-Dial: Progressive Multi-Turn Dialogue Construction with Domain Knowledge Graphs", "comment": "15 pages", "summary": "Current large language models (LLMs) excel at general NLP tasks but often\nlack domain specific precision in professional settings. Building a high\nquality domain specific multi turn dialogue dataset is essential for developing\nspecialized conversational systems. However, existing methods such as manual\nannotation, simulated human LLM interactions, and role based LLM dialogues are\nresource intensive or suffer from limitations in dialogue quality and domain\ncoverage. To address these challenges, we introduce ProKG Dial, a progressive\nframework for constructing knowledge intensive multi turn dialogue datasets\nusing domain specific knowledge graphs (KGs). ProKG Dial leverages the\nstructured nature of KGs to encode complex domain knowledge and relationships,\nproviding a solid foundation for generating meaningful and coherent dialogues.\nSpecifically, ProKG Dial begins by applying community detection to partition\nthe KG into semantically cohesive subgraphs. For each subgraph, the framework\nincrementally generates a series of questions and answers centered around a\ntarget entity, ensuring relevance and coverage. A rigorous filtering step is\nemployed to maintain high dialogue quality. We validate ProKG Dial on a medical\nknowledge graph by evaluating the generated dialogues in terms of diversity,\nsemantic coherence, and entity coverage. Furthermore, we fine tune a base LLM\non the resulting dataset and benchmark it against several baselines. Both\nautomatic metrics and human evaluations demonstrate that ProKG Dial\nsubstantially improves dialogue quality and domain specific performance,\nhighlighting its effectiveness and practical utility."}
{"id": "2508.01871", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.01871", "abs": "https://arxiv.org/abs/2508.01871", "authors": ["Yuanyuan Liang", "Lei Pan", "Tingyu Xie", "Yunshi Lan", "Weining Qian"], "title": "Multi-turn Natural Language to Graph Query Language Translation", "comment": "21 pages", "summary": "In recent years, research on transforming natural language into graph query\nlanguage (NL2GQL) has been increasing. Most existing methods focus on\nsingle-turn transformation from NL to GQL. In practical applications, user\ninteractions with graph databases are typically multi-turn, dynamic, and\ncontext-dependent. While single-turn methods can handle straightforward\nqueries, more complex scenarios often require users to iteratively adjust their\nqueries, investigate the connections between entities, or request additional\ndetails across multiple dialogue turns. Research focused on single-turn\nconversion fails to effectively address multi-turn dialogues and complex\ncontext dependencies. Additionally, the scarcity of high-quality multi-turn\nNL2GQL datasets further hinders the progress of this field. To address this\nchallenge, we propose an automated method for constructing multi-turn NL2GQL\ndatasets based on Large Language Models (LLMs) , and apply this method to\ndevelop the MTGQL dataset, which is constructed from a financial market graph\ndatabase and will be publicly released for future research. Moreover, we\npropose three types of baseline methods to assess the effectiveness of\nmulti-turn NL2GQL translation, thereby laying a solid foundation for future\nresearch."}
{"id": "2508.01956", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.01956", "abs": "https://arxiv.org/abs/2508.01956", "authors": ["Jiayi Wang", "Jacqueline Jil Vallon", "Neil Panjwani", "Xi Ling", "Sushmita Vij", "Sandy Srinivas", "John Leppert", "Mark K. Buyyounouski", "Mohsen Bayati"], "title": "Agent-Based Feature Generation from Clinical Notes for Outcome Prediction", "comment": null, "summary": "Electronic health records (EHRs) contain rich unstructured clinical notes\nthat could enhance predictive modeling, yet extracting meaningful features from\nthese notes remains challenging. Current approaches range from labor-intensive\nmanual clinician feature generation (CFG) to fully automated representational\nfeature generation (RFG) that lack interpretability and clinical relevance.\nHere we introduce SNOW (Scalable Note-to-Outcome Workflow), a modular\nmulti-agent system powered by large language models (LLMs) that autonomously\ngenerates structured clinical features from unstructured notes without human\nintervention. We evaluated SNOW against manual CFG, clinician-guided LLM\napproaches, and RFG methods for predicting 5-year prostate cancer recurrence in\n147 patients from Stanford Healthcare. While manual CFG achieved the highest\nperformance (AUC-ROC: 0.771), SNOW matched this performance (0.761) without\nrequiring any clinical expertise, significantly outperforming both baseline\nfeatures alone (0.691) and all RFG approaches. The clinician-guided LLM method\nalso performed well (0.732) but still required expert input. SNOW's specialized\nagents handle feature discovery, extraction, validation, post-processing, and\naggregation, creating interpretable features that capture complex clinical\ninformation typically accessible only through manual review. Our findings\ndemonstrate that autonomous LLM systems can replicate expert-level feature\nengineering at scale, potentially transforming how clinical ML models leverage\nunstructured EHR data while maintaining the interpretability essential for\nclinical deployment."}
{"id": "2508.02016", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02016", "abs": "https://arxiv.org/abs/2508.02016", "authors": ["Jeiyoon Park", "Yongshin Han", "Minseop Kim", "Kisu Yang"], "title": "Dynamic Context Adaptation for Consistent Role-Playing Agents with Retrieval-Augmented Generations", "comment": "preprint", "summary": "We propose AMADEUS, which is composed of Adaptive Context-aware Text Splitter\n(ACTS), Guided Selection (GS), and Attribute Extractor (AE). ACTS finds an\noptimal chunk length and hierarchical contexts for each character. AE\nidentifies a character's general attributes from the chunks retrieved by GS and\nuses these attributes as a final context to maintain robust persona consistency\neven when answering out of knowledge questions. To facilitate the development\nand evaluation of RAG-based RPAs, we construct CharacterRAG, a role-playing\ndataset that consists of persona documents for 15 distinct fictional characters\ntotaling 976K written characters, and 450 question and answer pairs. We find\nthat our framework effectively models not only the knowledge possessed by\ncharacters, but also various attributes such as personality."}
{"id": "2508.02063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02063", "abs": "https://arxiv.org/abs/2508.02063", "authors": ["Amitava Das", "Vinija Jain", "Aman Chadha"], "title": "TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs", "comment": null, "summary": "Large Language Models (LLMs) fine-tuned to align with human values often\nexhibit alignment drift, producing unsafe or policy-violating completions when\nexposed to adversarial prompts, decoding perturbations, or paraphrased\njailbreaks. While prior work has behaviorally characterized alignment failure,\nlittle is known about the training-time belief sources underlying these\nfailures. We introduce TraceAlign, a unified framework for tracing unsafe\ncompletions back to their root causes in the model's training corpus. Central\nto our approach is the Belief Conflict Index (BCI), which quantifies semantic\ninconsistency between generated spans and aligned policies, based on retrieved\ntraining documents using suffix-array matching. We propose three complementary\ninterventions: (i) TraceShield, an inference-time safety filter that refuses\ncompletions with high-BCI spans, (ii) Contrastive Belief Deconfliction Loss, a\ncontrastive fine-tuning objective penalizing high-BCI continuations during DPO,\nand (iii) Prov-Decode, a provenance-aware decoding strategy that vetoes beam\nexpansions predicted to yield high-BCI spans. Together, these defenses reduce\nalignment drift by up to 85% on our curated Alignment Drift Benchmark (ADB)\nwhile preserving utility on standard tasks, with delta less than 0.2 and\nimproved refusal quality. We further derive a theoretical upper bound on drift\nlikelihood via suffix-array span statistics, linking memorization frequency and\nlength to adversarial reactivation risk. TraceAlign thus provides the first\nscalable, traceable, and grounded toolkit for understanding and mitigating\nalignment failures at source. To encourage further exploration and development,\nwe open-source our implementation at:\nhttps://anonymous.4open.science/r/tracealign-2DA7"}
{"id": "2508.02073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02073", "abs": "https://arxiv.org/abs/2508.02073", "authors": ["Jiawei Li", "Chengye Yang", "Yaochen Zhang", "Weilin Sun", "Lei Meng", "Xiangxu Meng"], "title": "Risk identification based on similar case retrieval enhancement,", "comment": "in Chinese language", "summary": "The goal of construction site risk and hazard identification is to enhance\nsafety management through automation. Existing research based on large language\nmodels falls into two categories: image-text matching for collaborative\nreasoning, which struggles with complex hazard features, and instruction\nfine-tuning or dialogue guidance using professional datasets, which suffers\nfrom high training costs and poor generalization.To address this, we propose a\nhazard identification method using similar case retrieval enhancement. By\nintegrating external knowledge and retrieved case contexts via prompt\nfine-tuning, we mitigate misjudgments caused by limited domain knowledge and\nweak feature associations. Our method includes three modules: retrieval\nlibrary, image similarity retrieval, and large model retrieval enhancement,\nenabling efficient recognition without training. Experiments on real\nconstruction data show significant improvements. For instance, GLM-4V's\nrecognition accuracy increased to 50\\%, a 35.49\\% boost. The method enhances\naccuracy, context understanding, and stability, offering new theoretical and\ntechnical support for hazard detection."}
{"id": "2508.02076", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2508.02076", "abs": "https://arxiv.org/abs/2508.02076", "authors": ["Yunhao Liang", "Yuan Qu", "Jingyuan Yang", "Shaochong Lin", "Zuo-Jun Max Shen"], "title": "Everyone Contributes! Incentivizing Strategic Cooperation in Multi-LLM Systems via Sequential Public Goods Games", "comment": null, "summary": "Coordinating multiple large language models (LLMs) to solve complex tasks\ncollaboratively poses a fundamental trade-off between the computation costs and\ncollective performance compared with individual model. We introduce a novel,\ngame-theoretically grounded reinforcement learning (RL) framework, the\nMulti-Agent Cooperation Sequential Public Goods Game (MAC-SPGG), to\nsystematically incentivize cooperation in multi-LLM ensembles. In MAC-SPGG, LLM\nagents move in sequence, observing predecessors' outputs and updating beliefs\nto condition their own contributions. By redesigning the public-goods reward,\neffortful contributions become the unique Subgame Perfect Nash Equilibrium\n(SPNE), which eliminates free-riding under traditional SPGG or PGG. Its\nsequential protocol replaces costly round-based information exchanges with a\nstreamlined decision flow, cutting communication overhead while retaining\nstrategic depth. We prove the existence and uniqueness of the SPNE under\nrealistic parameters, and empirically show that MAC-SPGG-trained ensembles\noutperform single-agent baselines, chain-of-thought prompting, and other\ncooperative methods, even achieving comparable performance to large-scale\nmodels across reasoning, math, code generation, and NLP tasks. Our results\nhighlight the power of structured, incentive-aligned MAC-SPGG cooperation for\nscalable and robust multi-agent language generation."}
{"id": "2508.02085", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02085", "abs": "https://arxiv.org/abs/2508.02085", "authors": ["Jiaye Lin", "Yifu Guo", "Yuzhen Han", "Sen Hu", "Ziyi Ni", "Licheng Wang", "Mingguang Chen", "Daxin Jiang", "Binxing Jiao", "Chen Hu", "Huacan Wang"], "title": "SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents", "comment": null, "summary": "Large Language Model (LLM)-based agents have recently shown impressive\ncapabilities in complex reasoning and tool use via multi-step interactions with\ntheir environments. While these agents have the potential to tackle complicated\ntasks, their problem-solving process, i.e., agents' interaction trajectory\nleading to task completion, remains underexploited. These trajectories contain\nrich feedback that can navigate agents toward the right directions for solving\nproblems correctly. Although prevailing approaches, such as Monte Carlo Tree\nSearch (MCTS), can effectively balance exploration and exploitation, they\nignore the interdependence among various trajectories and lack the diversity of\nsearch spaces, which leads to redundant reasoning and suboptimal outcomes. To\naddress these challenges, we propose SE-Agent, a Self-Evolution framework that\nenables Agents to optimize their reasoning processes iteratively. Our approach\nrevisits and enhances former pilot trajectories through three key operations:\nrevision, recombination, and refinement. This evolutionary mechanism enables\ntwo critical advantages: (1) it expands the search space beyond local optima by\nintelligently exploring diverse solution paths guided by previous trajectories,\nand (2) it leverages cross-trajectory inspiration to efficiently enhance\nperformance while mitigating the impact of suboptimal reasoning paths. Through\nthese mechanisms, SE-Agent achieves continuous self-evolution that\nincrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench\nVerified to resolve real-world GitHub issues. Experimental results across five\nstrong LLMs show that integrating SE-Agent delivers up to 55% relative\nimprovement, achieving state-of-the-art performance among all open-source\nagents on SWE-bench Verified. Our code and demonstration materials are publicly\navailable at https://github.com/wanghuacan/SE-Agent."}
{"id": "2508.02093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02093", "abs": "https://arxiv.org/abs/2508.02093", "authors": ["Yiqing Xu", "Linfeng Li", "Cunjun Yu", "David Hsu"], "title": "\"Stack It Up!\": 3D Stable Structure Generation from 2D Hand-drawn Sketch", "comment": "Accepted to CoRL 2025", "summary": "Imagine a child sketching the Eiffel Tower and asking a robot to bring it to\nlife. Today's robot manipulation systems can't act on such sketches\ndirectly-they require precise 3D block poses as goals, which in turn demand\nstructural analysis and expert tools like CAD. We present StackItUp, a system\nthat enables non-experts to specify complex 3D structures using only 2D\nfront-view hand-drawn sketches. StackItUp introduces an abstract relation graph\nto bridge the gap between rough sketches and accurate 3D block arrangements,\ncapturing the symbolic geometric relations (e.g., left-of) and stability\npatterns (e.g., two-pillar-bridge) while discarding noisy metric details from\nsketches. It then grounds this graph to 3D poses using compositional diffusion\nmodels and iteratively updates it by predicting hidden internal and rear\nsupports-critical for stability but absent from the sketch. Evaluated on\nsketches of iconic landmarks and modern house designs, StackItUp consistently\nproduces stable, multilevel 3D structures and outperforms all baselines in both\nstability and visual resemblance."}
{"id": "2508.02110", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02110", "abs": "https://arxiv.org/abs/2508.02110", "authors": ["Kanghua Mo", "Li Hu", "Yucheng Long", "Zhihao Li"], "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities\nin complex reasoning and decision-making by leveraging external tools. However,\nthis tool-centric paradigm introduces a previously underexplored attack\nsurface: adversaries can manipulate tool metadata -- such as names,\ndescriptions, and parameter schemas -- to influence agent behavior. We identify\nthis as a new and stealthy threat surface that allows malicious tools to be\npreferentially selected by LLM agents, without requiring prompt injection or\naccess to model internals. To demonstrate and exploit this vulnerability, we\npropose the Attractive Metadata Attack (AMA), a black-box in-context learning\nframework that generates highly attractive but syntactically and semantically\nvalid tool metadata through iterative optimization. Our attack integrates\nseamlessly into standard tool ecosystems and requires no modification to the\nagent's execution framework. Extensive experiments across ten realistic,\nsimulated tool-use scenarios and a range of popular LLM agents demonstrate\nconsistently high attack success rates (81\\%-95\\%) and significant privacy\nleakage, with negligible impact on primary task execution. Moreover, the attack\nremains effective even under prompt-level defenses and structured\ntool-selection protocols such as the Model Context Protocol, revealing systemic\nvulnerabilities in current agent architectures. These findings reveal that\nmetadata manipulation constitutes a potent and stealthy attack surface,\nhighlighting the need for execution-level security mechanisms that go beyond\nprompt-level defenses."}
{"id": "2508.02120", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02120", "abs": "https://arxiv.org/abs/2508.02120", "authors": ["Linan Yue", "Yichao Du", "Yizhi Wang", "Weibo Gao", "Fangzhou Yao", "Li Wang", "Ye Liu", "Ziyu Xu", "Qi Liu", "Shimin Di", "Min-Ling Zhang"], "title": "Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models", "comment": null, "summary": "Recently, Large Reasoning Models (LRMs) have gradually become a research\nhotspot due to their outstanding performance in handling complex tasks. Among\nthem, DeepSeek R1 has garnered significant attention for its exceptional\nperformance and open-source nature, driving advancements in the research of\nR1-style LRMs. Unlike traditional Large Language Models (LLMs), these models\nenhance logical deduction and decision-making capabilities during reasoning by\nincorporating mechanisms such as long chain-of-thought and self-reflection\nthrough reinforcement learning. However, with the widespread application of\nthese models, the problem of overthinking has gradually emerged. Specifically,\nwhen generating answers, these models often construct excessively long\nreasoning chains with redundant or repetitive steps, which leads to reduced\nreasoning efficiency and may affect the accuracy of the final answer. To this\nend, various efficient reasoning methods have been proposed, aiming to reduce\nthe length of reasoning paths without compromising model performance and\nreasoning capability. By reviewing the current research advancements in the\nfield of efficient reasoning methods systematically, we categorize existing\nworks into two main directions based on the lens of single-model optimization\nversus model collaboration: (1) Efficient Reasoning with Single Model, which\nfocuses on improving the reasoning efficiency of individual models; and (2)\nEfficient Reasoning with Model Collaboration, which explores optimizing\nreasoning paths through collaboration among multiple models. Besides, we\nmaintain a public GitHub repository that tracks the latest progress in\nefficient reasoning methods."}
{"id": "2508.02121", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.02121", "abs": "https://arxiv.org/abs/2508.02121", "authors": ["Zexin Wang", "Jingjing Li", "Quan Zhou", "Haotian Si", "Yuanhao Liu", "Jianhui Li", "Gaogang Xie", "Fei Sun", "Dan Pei", "Changhua Pei"], "title": "A Survey on AgentOps: Categorization, Challenges, and Future Directions", "comment": "35 pages", "summary": "As the reasoning capabilities of Large Language Models (LLMs) continue to\nadvance, LLM-based agent systems offer advantages in flexibility and\ninterpretability over traditional systems, garnering increasing attention.\nHowever, despite the widespread research interest and industrial application of\nagent systems, these systems, like their traditional counterparts, frequently\nencounter anomalies. These anomalies lead to instability and insecurity,\nhindering their further development. Therefore, a comprehensive and systematic\napproach to the operation and maintenance of agent systems is urgently needed.\nUnfortunately, current research on the operations of agent systems is sparse.\nTo address this gap, we have undertaken a survey on agent system operations\nwith the aim of establishing a clear framework for the field, defining the\nchallenges, and facilitating further development. Specifically, this paper\nbegins by systematically defining anomalies within agent systems, categorizing\nthem into intra-agent anomalies and inter-agent anomalies. Next, we introduce a\nnovel and comprehensive operational framework for agent systems, dubbed Agent\nSystem Operations (AgentOps). We provide detailed definitions and explanations\nof its four key stages: monitoring, anomaly detection, root cause analysis, and\nresolution."}
{"id": "2508.02124", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02124", "abs": "https://arxiv.org/abs/2508.02124", "authors": ["Jingze Shi", "Yifan Wu", "Bingheng Wu", "Yiran Peng", "Liangdong Wang", "Guang Liu", "Yuyu Luo"], "title": "Trainable Dynamic Mask Sparse Attention", "comment": "8 figures, 4 tables", "summary": "In large language models, the demand for modeling long contexts is constantly\nincreasing, but the quadratic complexity of the standard self-attention\nmechanism often becomes a bottleneck. Although existing sparse attention\nmechanisms have improved efficiency, they may still encounter issues such as\nstatic patterns or information loss. We introduce a trainable dynamic mask\nsparse attention mechanism, Dynamic Mask Attention, which effectively utilizes\ncontent-aware and position-aware sparsity. DMA achieves this through two key\ninnovations: First, it dynamically generates content-aware sparse masks from\nvalue representations, enabling the model to identify and focus on critical\ninformation adaptively. Second, it implements position-aware sparse attention\ncomputation that effectively skips unnecessary calculation regions. This\ndual-sparsity design allows the model to significantly reduce the computational\ncomplexity of important information while retaining complete information,\nachieving an excellent balance between information fidelity and computational\nefficiency. We have verified the performance of DMA through comprehensive\nexperiments. Comparative studies show that DMA outperforms multi-head\nattention, sliding window attention, multi-head latent attention, and native\nsparse attention in terms of perplexity under Chinchilla Scaling Law settings.\nMoreover, in challenging multi-query associative recall tasks, DMA also\ndemonstrates superior performance and efficiency compared to these methods.\nCrucially, in the evaluation of a 1.7B parameter model, DMA significantly\noutperforms multi-head attention in both standard benchmark performance and the\nchallenging needle-in-a-haystack task. These experimental results highlight its\ncapability to balance model efficiency and long-context modeling ability\neffectively."}
{"id": "2508.02132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02132", "abs": "https://arxiv.org/abs/2508.02132", "authors": ["Yunge Wen", "Chenliang Huang", "Hangyu Zhou", "Zhuo Zeng", "Chun Ming Louis Po", "Julian Togelius", "Timothy Merino", "Sam Earle"], "title": "All Stories Are One Story: Emotional Arc Guided Procedural Game Level Generation", "comment": null, "summary": "The emotional arc is a universal narrative structure underlying stories\nacross cultures and media -- an idea central to structuralist narratology,\noften encapsulated in the phrase \"all stories are one story.\" We present a\nframework for procedural game narrative generation that incorporates emotional\narcs as a structural backbone for both story progression and gameplay dynamics.\nLeveraging established narratological theories and large-scale empirical\nanalyses, we focus on two core emotional patterns -- Rise and Fall -- to guide\nthe generation of branching story graphs. Each story node is automatically\npopulated with characters, items, and gameplay-relevant attributes (e.g.,\nhealth, attack), with difficulty adjusted according to the emotional\ntrajectory. Implemented in a prototype action role-playing game (ARPG), our\nsystem demonstrates how emotional arcs can be operationalized using large\nlanguage models (LLMs) and adaptive entity generation. Evaluation through\nplayer ratings, interviews, and sentiment analysis shows that emotional arc\nintegration significantly enhances engagement, narrative coherence, and\nemotional impact. These results highlight the potential of emotionally\nstructured procedural generation for advancing interactive storytelling for\ngames."}
{"id": "2508.02150", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02150", "abs": "https://arxiv.org/abs/2508.02150", "authors": ["Qingyu Ren", "Qianyu He", "Bowei Zhang", "Jie Zeng", "Jiaqing Liang", "Yanghua Xiao", "Weikang Zhou", "Zeye Sun", "Fei Yu"], "title": "Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following", "comment": null, "summary": "Reasoning models excel in complex problem solving but exhibit a concerning\ntrade off between reasoning capabilities and instruction following abilities.\nExisting approaches for improving instruction following rely on stronger\nexternal models, creating methodological bottlenecks and practical limitations\nincluding increased costs and accessibility constraints. We propose a\nself-supervised RL framework that leverages reasoning models' own internal\nsignals to improve instruction following capabilities without external\nsupervision. Extensive experiments demonstrate that our framework significantly\nimproves instruction following capabilities while maintaining reasoning\nperformance, offering a scalable and cost-effective approach to enhance\ninstruction following in reasoning models. The data and code are publicly\navailable at https://github.com/Rainier-rq/verl-if."}
{"id": "2508.02178", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02178", "abs": "https://arxiv.org/abs/2508.02178", "authors": ["Jialiang Hong", "Taihang Zhen", "Kai Chen", "Jiaheng Liu", "Wenpeng Zhu", "Jing Huo", "Yang Gao", "Depeng Wang", "Haitao Wan", "Xi Yang", "Boyan Wang", "Fanyu Meng"], "title": "Reconsidering Overthinking: Penalizing Internal and External Redundancy in CoT Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) often produce excessively verbose reasoning\ntraces, a phenomenon known as overthinking, which hampers both efficiency and\ninterpretability. Prior works primarily address this issue by reducing response\nlength, without fully examining the underlying semantic structure of the\nreasoning process. In this paper, we revisit overthinking by decomposing it\ninto two distinct forms: internal redundancy, which consists of\nlow-contribution reasoning steps within the first correct solution (FCS), and\nexternal redundancy, which refers to unnecessary continuation after the FCS. To\nmitigate both forms, we propose a dual-penalty reinforcement learning\nframework. For internal redundancy, we adopt a sliding-window semantic analysis\nto penalize low-gain reasoning steps that contribute little toward reaching the\ncorrect answer. For external redundancy, we penalize its proportion beyond the\nFCS to encourage earlier termination. Our method significantly compresses\nreasoning traces with minimal accuracy loss, and generalizes effectively to\nout-of-domain tasks such as question answering and code generation. Crucially,\nwe find that external redundancy can be safely removed without degrading\nperformance, whereas internal redundancy must be reduced more cautiously to\navoid impairing correctness. These findings suggest that our method not only\nimproves reasoning efficiency but also enables implicit, semantic-aware control\nover Chain-of-Thought length, paving the way for more concise and interpretable\nLRMs."}
{"id": "2508.02191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02191", "abs": "https://arxiv.org/abs/2508.02191", "authors": ["Boheng Liu", "Ziyu Li", "Xia Wu"], "title": "Neuromorphic Computing with Multi-Frequency Oscillations: A Bio-Inspired Approach to Artificial Intelligence", "comment": null, "summary": "Despite remarkable capabilities, artificial neural networks exhibit limited\nflexible, generalizable intelligence. This limitation stems from their\nfundamental divergence from biological cognition that overlooks both neural\nregions' functional specialization and the temporal dynamics critical for\ncoordinating these specialized systems. We propose a tripartite brain-inspired\narchitecture comprising functionally specialized perceptual, auxiliary, and\nexecutive systems. Moreover, the integration of temporal dynamics through the\nsimulation of multi-frequency neural oscillation and synaptic dynamic\nadaptation mechanisms enhances the architecture, thereby enabling more flexible\nand efficient artificial cognition. Initial evaluations demonstrate superior\nperformance compared to state-of-the-art temporal processing approaches, with\n2.18\\% accuracy improvements while reducing required computation iterations by\n48.44\\%, and achieving higher correlation with human confidence patterns.\nThough currently demonstrated on visual processing tasks, this architecture\nestablishes a theoretical foundation for brain-like intelligence across\ncognitive domains, potentially bridging the gap between artificial and\nbiological intelligence."}
{"id": "2508.02197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02197", "abs": "https://arxiv.org/abs/2508.02197", "authors": ["Wouter W. L. Nuijten", "Mykola Lukashchuk", "Thijs van de Laar", "Bert de Vries"], "title": "A Message Passing Realization of Expected Free Energy Minimization", "comment": null, "summary": "We present a message passing approach to Expected Free Energy (EFE)\nminimization on factor graphs, based on the theory introduced in\narXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy\nminimization with epistemic priors, we transform a combinatorial search problem\ninto a tractable inference problem solvable through standard variational\ntechniques. Applying our message passing method to factorized state-space\nmodels enables efficient policy inference. We evaluate our method on\nenvironments with epistemic uncertainty: a stochastic gridworld and a partially\nobservable Minigrid task. Agents using our approach consistently outperform\nconventional KL-control agents on these tasks, showing more robust planning and\nefficient exploration under uncertainty. In the stochastic gridworld\nenvironment, EFE-minimizing agents avoid risky paths, while in the partially\nobservable minigrid setting, they conduct more systematic information-seeking.\nThis approach bridges active inference theory with practical implementations,\nproviding empirical evidence for the efficiency of epistemic priors in\nartificial agents."}
{"id": "2508.02269", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02269", "abs": "https://arxiv.org/abs/2508.02269", "authors": ["Dewi Sid William Gould", "George De Ath", "Ben Carvell", "Nick Pepper"], "title": "AirTrafficGen: Configurable Air Traffic Scenario Generation with Large Language Models", "comment": "7 pages and appendices", "summary": "The manual design of scenarios for Air Traffic Control (ATC) training is a\ndemanding and time-consuming bottleneck that limits the diversity of\nsimulations available to controllers. To address this, we introduce a novel,\nend-to-end approach, AirTrafficGen, that leverages large language models (LLMs)\nto automate and control the generation of complex ATC scenarios. Our method\nuses a purpose-built, graph-based representation to encode sector topology\n(including airspace geometry, routes, and fixes) into a format LLMs can\nprocess. Through rigorous benchmarking, we show that state-of-the-art models\nlike Gemini 2.5 Pro and OpenAI o3 can generate high-traffic scenarios whilst\nmaintaining operational realism. Our engineered prompting enables fine-grained\ncontrol over interaction presence, type, and location. Initial findings suggest\nthese models are also capable of iterative refinement, correcting flawed\nscenarios based on simple textual feedback. This approach provides a scalable\nalternative to manual scenario design, addressing the need for a greater volume\nand variety of ATC training and validation simulations. More broadly, this work\nshowcases the potential of LLMs for complex planning in safety-critical\ndomains."}
{"id": "2508.02292", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02292", "abs": "https://arxiv.org/abs/2508.02292", "authors": ["Wentao Zhang", "Yilei Zhao", "Chuqiao Zong", "Xinrun Wang", "Bo An"], "title": "FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment", "comment": null, "summary": "Financial AI holds great promise for transforming modern finance, with the\npotential to support a wide range of tasks such as market forecasting,\nportfolio management, quantitative trading, and automated analysis. However,\nexisting platforms remain limited in task coverage, lack robust multimodal data\nintegration, and offer insufficient support for the training and deployment of\nlarge language models (LLMs). In response to these limitations, we present\nFinWorld, an all-in-one open-source platform that provides end-to-end support\nfor the entire financial AI workflow, from data acquisition to experimentation\nand deployment. FinWorld distinguishes itself through native integration of\nheterogeneous financial data, unified support for diverse AI paradigms, and\nadvanced agent automation, enabling seamless development and deployment.\nLeveraging data from 2 representative markets, 4 stock pools, and over 800\nmillion financial data points, we conduct comprehensive experiments on 4 key\nfinancial AI tasks. These experiments systematically evaluate deep learning and\nreinforcement learning algorithms, with particular emphasis on RL-based\nfinetuning for LLMs and LLM Agents. The empirical results demonstrate that\nFinWorld significantly enhances reproducibility, supports transparent\nbenchmarking, and streamlines deployment, thereby providing a strong foundation\nfor future research and real-world applications. Code is available at\nGithub~\\footnote{https://github.com/DVampire/FinWorld}."}
{"id": "2508.02344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02344", "abs": "https://arxiv.org/abs/2508.02344", "authors": ["Xingchen Zou", "Yuhao Yang", "Zheng Chen", "Xixuan Hao", "Yiqi Chen", "Chao Huang", "Yuxuan Liang"], "title": "Traffic-R1: Reinforced LLMs Bring Human-Like Reasoning to Traffic Signal Control Systems", "comment": null, "summary": "Traffic signal control (TSC) is vital for mitigating congestion and\nsustaining urban mobility. In this paper, we introduce Traffic-R1, a foundation\nmodel with human-like reasoning for TSC systems. Our model is developed through\nself-exploration and iteration of reinforced large language models (LLMs) with\nexpert guidance in a simulated traffic environment. Compared to traditional\nreinforcement learning (RL) and recent LLM-based methods, Traffic-R1 offers\nthree significant advantages. First, Traffic-R1 delivers zero-shot\ngeneralisation, transferring unchanged to new road networks and\nout-of-distribution incidents by utilizing its internal traffic control\npolicies and human-like reasoning. Second, its 3B-parameter architecture is\nlightweight enough for real-time inference on mobile-class chips, enabling\nlarge-scale edge deployment. Third, Traffic-R1 provides an explainable TSC\nprocess and facilitates multi-intersection communication through its\nself-iteration and a new synchronous communication network. Extensive\nbenchmarks demonstrate that Traffic-R1 sets a new state of the art,\noutperforming strong baselines and training-intensive RL controllers. In\npractice, the model now manages signals for more than 55,000 drivers daily,\nshortening average queues by over 5% and halving operator workload. Our\ncheckpoint is available at https://huggingface.co/Season998/Traffic-R1."}
{"id": "2508.02427", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.02427", "abs": "https://arxiv.org/abs/2508.02427", "authors": ["Tung-Thuy Pham", "Duy-Quan Luong", "Minh-Quan Duong", "Trung-Hieu Nguyen", "Thu-Trang Nguyen", "Son Nguyen", "Hieu Dinh Vo"], "title": "CABENCH: Benchmarking Composable AI for Solving Complex Tasks through Composing Ready-to-Use Models", "comment": null, "summary": "Composable AI offers a scalable and effective paradigm for tackling complex\nAI tasks by decomposing them into sub-tasks and solving each sub-task using\nready-to-use well-trained models. However, systematically evaluating methods\nunder this setting remains largely unexplored. In this paper, we introduce\nCABENCH, the first public benchmark comprising 70 realistic composable AI\ntasks, along with a curated pool of 700 models across multiple modalities and\ndomains. We also propose an evaluation framework to enable end-to-end\nassessment of composable AI solutions. To establish initial baselines, we\nprovide human-designed reference solutions and compare their performance with\ntwo LLM-based approaches. Our results illustrate the promise of composable AI\nin addressing complex real-world problems while highlighting the need for\nmethods that can fully unlock its potential by automatically generating\neffective execution pipelines."}
{"id": "2508.02429", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02429", "abs": "https://arxiv.org/abs/2508.02429", "authors": ["Miaosen Luo", "Jiesen Long", "Zequn Li", "Yunying Yang", "Yuncheng Jiang", "Sijie Mai"], "title": "Multimodal Large Language Models for End-to-End Affective Computing: Benchmarking and Boosting with Generative Knowledge Prompting", "comment": null, "summary": "Multimodal Affective Computing (MAC) aims to recognize and interpret human\nemotions by integrating information from diverse modalities such as text,\nvideo, and audio. Recent advancements in Multimodal Large Language Models\n(MLLMs) have significantly reshaped the landscape of MAC by offering a unified\nframework for processing and aligning cross-modal information. However,\npractical challenges remain, including performance variability across complex\nMAC tasks and insufficient understanding of how architectural designs and data\ncharacteristics impact affective analysis. To address these gaps, we conduct a\nsystematic benchmark evaluation of state-of-the-art open-source MLLMs capable\nof concurrently processing audio, visual, and textual modalities across\nmultiple established MAC datasets. Our evaluation not only compares the\nperformance of these MLLMs but also provides actionable insights into model\noptimization by analyzing the influence of model architectures and dataset\nproperties. Furthermore, we propose a novel hybrid strategy that combines\ngenerative knowledge prompting with supervised fine-tuning to enhance MLLMs'\naffective computing capabilities. Experimental results demonstrate that this\nintegrated approach significantly improves performance across various MAC\ntasks, offering a promising avenue for future research and development in this\nfield. Our code is released on https://github.com/LuoMSen/MLLM-MAC."}
{"id": "2508.02490", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02490", "abs": "https://arxiv.org/abs/2508.02490", "authors": ["Puyu Yang", "Laifa Tao", "Zijian Huang", "Haifei Liu", "Wenyan Cao", "Hao Ji", "Jianan Qiu", "Qixuan Huang", "Xuanyuan Su", "Yuhang Xie", "Jun Zhang", "Shangyu Li", "Chen Lu", "Zhixuan Lian"], "title": "PHM-Bench: A Domain-Specific Benchmarking Framework for Systematic Evaluation of Large Models in Prognostics and Health Management", "comment": null, "summary": "With the rapid advancement of generative artificial intelligence, large\nlanguage models (LLMs) are increasingly adopted in industrial domains, offering\nnew opportunities for Prognostics and Health Management (PHM). These models\nhelp address challenges such as high development costs, long deployment cycles,\nand limited generalizability. However, despite the growing synergy between PHM\nand LLMs, existing evaluation methodologies often fall short in structural\ncompleteness, dimensional comprehensiveness, and evaluation granularity. This\nhampers the in-depth integration of LLMs into the PHM domain. To address these\nlimitations, this study proposes PHM-Bench, a novel three-dimensional\nevaluation framework for PHM-oriented large models. Grounded in the triadic\nstructure of fundamental capability, core task, and entire lifecycle, PHM-Bench\nis tailored to the unique demands of PHM system engineering. It defines\nmulti-level evaluation metrics spanning knowledge comprehension, algorithmic\ngeneration, and task optimization. These metrics align with typical PHM tasks,\nincluding condition monitoring, fault diagnosis, RUL prediction, and\nmaintenance decision-making. Utilizing both curated case sets and publicly\navailable industrial datasets, our study enables multi-dimensional evaluation\nof general-purpose and domain-specific models across diverse PHM tasks.\nPHM-Bench establishes a methodological foundation for large-scale assessment of\nLLMs in PHM and offers a critical benchmark to guide the transition from\ngeneral-purpose to PHM-specialized models."}
{"id": "2508.02503", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02503", "abs": "https://arxiv.org/abs/2508.02503", "authors": ["Maxime Bouscary", "Saurabh Amin"], "title": "OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical Modeling", "comment": null, "summary": "LLM-based solvers have emerged as a promising means of automating problem\nmodeling and solving. However, they remain unreliable and often depend on\niterative repair loops that result in significant latency. We introduce\nOptiHive, an LLM-based framework that produces high-quality solvers for\noptimization problems from natural-language descriptions without iterative\nself-correction. OptiHive uses a single batched LLM query to generate diverse\ncomponents (solvers, problem instances, and validation tests) and filters out\nerroneous components to ensure fully interpretable outputs. Taking into account\nthe imperfection of the generated components, we employ a statistical model to\ninfer their true performance, enabling principled uncertainty quantification\nand solver selection. On tasks ranging from traditional optimization problems\nto challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive\nsignificantly outperforms baselines, increasing the optimality rate from 5\\% to\n92\\% on the most complex problems."}
{"id": "2508.02511", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02511", "abs": "https://arxiv.org/abs/2508.02511", "authors": ["Chenxu Yang", "Qingyi Si", "Mz Dai", "Dingyu Yao", "Mingyu Zheng", "Minghui Chen", "Zheng Lin", "Weiping Wang"], "title": "Test-time Prompt Intervention", "comment": "23 pages, 16 figures, under review", "summary": "Test-time compute has led to remarkable success in the large language model\n(LLM) community, particularly for complex tasks, where longer chains of thought\n(CoTs) are generated to enhance reasoning capabilities. However, growing\nevidence reveals that such reasoning models often produce CoTs plagued by\nexcessive redundancy, including unnecessary verification steps and repetitive\nreasoning shifts. The root cause lies in post-training of them that overly rely\non outcome reward paradigms, as the data of process reward paradigms, which\nregulate intermediate reasoning steps, is difficult to construct at scale. To\naddress this, we propose PI, a novel framework for Test-time Prompt\nIntervention. PI provides an interface to dynamically guide and regulate\nreasoning paths during inference through timely (When module) and proper (How\nmodule) interventions and post-intervention sampling (Which module). This\nallows human problem-solving expertise and cognitive science principles to be\nseamlessly integrated into LLMs' reasoning processes, enhancing controllability\nand interpretability. Extensive experiments across multiple models and datasets\ndemonstrate that PI significantly shortens CoTs while reducing hallucination,\nyielding more concise and reliable reasoning."}
{"id": "2508.02525", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02525", "abs": "https://arxiv.org/abs/2508.02525", "authors": ["Qifan Chen", "Jin Cui", "Cindy Duan", "Yushuo Han", "Yifei Shi"], "title": "Accurate and Interpretable Postmenstrual Age Prediction via Multimodal Large Language Model", "comment": "Submitted to the NeurIPS 2025 Workshop GenAI4Health. Conference\n  website: https://aihealth.ischool.utexas.edu/GenAI4HealthNeurips2025/", "summary": "Accurate estimation of postmenstrual age (PMA) at scan is crucial for\nassessing neonatal development and health. While deep learning models have\nachieved high accuracy in predicting PMA from brain MRI, they often function as\nblack boxes, offering limited transparency and interpretability in clinical\ndecision support. In this work, we address the dual challenge of accuracy and\ninterpretability by adapting a multimodal large language model (MLLM) to\nperform both precise PMA prediction and clinically relevant explanation\ngeneration. We introduce a parameter-efficient fine-tuning (PEFT) strategy\nusing instruction tuning and Low-Rank Adaptation (LoRA) applied to the\nQwen2.5-VL-7B model. The model is trained on four 2D cortical surface\nprojection maps derived from neonatal MRI scans. By employing distinct prompts\nfor training and inference, our approach enables the MLLM to handle a\nregression task during training and generate clinically relevant explanations\nduring inference. The fine-tuned model achieves a low prediction error with a\n95 percent confidence interval of 0.78 to 1.52 weeks, while producing\ninterpretable outputs grounded in developmental features, marking a significant\nstep toward transparent and trustworthy AI systems in perinatal neuroscience."}
{"id": "2508.02583", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02583", "abs": "https://arxiv.org/abs/2508.02583", "authors": ["Lei Zan", "Keli Zhang", "Ruichu Cai", "Lujia Pan"], "title": "CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong performance across a\nwide range of tasks, yet they still struggle with complex mathematical\nreasoning, a challenge fundamentally rooted in deep structural dependencies. To\naddress this challenge, we propose \\textbf{CA}usal \\textbf{MA}thematician\n(\\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit,\nreusable mathematical structure. In the learning stage, CAMA first constructs\nthe \\textbf{M}athematical \\textbf{C}ausal \\textbf{G}raph (\\textbf{MCG}), a\nhigh-level representation of solution strategies, by combining LLM priors with\ncausal discovery algorithms applied to a corpus of question-solution pairs. The\nresulting MCG encodes essential knowledge points and their causal dependencies.\nTo better align the graph with downstream reasoning tasks, CAMA further refines\nthe MCG through iterative feedback derived from a selected subset of the\nquestion-solution pairs. In the reasoning stage, given a new question, CAMA\ndynamically extracts a task-relevant subgraph from the MCG, conditioned on both\nthe question content and the LLM's intermediate reasoning trace. This subgraph,\nwhich encodes the most pertinent knowledge points and their causal\ndependencies, is then injected back into the LLM to guide its reasoning\nprocess. Empirical results on real-world datasets show that CAMA significantly\nimproves LLM performance on challenging mathematical problems. Furthermore, our\nexperiments demonstrate that structured guidance consistently outperforms\nunstructured alternatives, and that incorporating asymmetric causal\nrelationships yields greater improvements than using symmetric associations\nalone."}
{"id": "2508.02621", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.02621", "abs": "https://arxiv.org/abs/2508.02621", "authors": ["Yinghao Zhu", "Yifan Qi", "Zixiang Wang", "Lei Gu", "Dehao Sui", "Haoran Hu", "Xichen Zhang", "Ziyi He", "Liantao Ma", "Lequan Yu"], "title": "HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous Healthcare Research", "comment": "Code: https://github.com/yhzhu99/HealthFlow", "summary": "The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery."}
{"id": "2508.02622", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.02622", "abs": "https://arxiv.org/abs/2508.02622", "authors": ["Enrico De Santis", "Antonello Rizzi"], "title": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction", "comment": null, "summary": "This paper introduces and formalizes Noosemia, a novel\ncognitive-phenomenological phenomenon emerging from human interaction with\ngenerative AI systems, particularly those enabling dialogic or multimodal\nexchanges. We propose a multidisciplinary framework to explain how, under\ncertain conditions, users attribute intentionality, agency, and even\ninteriority to these systems - a process grounded not in physical resemblance,\nbut in linguistic performance, epistemic opacity, and emergent technological\ncomplexity. By linking an LLM declination of meaning holism to our technical\nnotion of the LLM Contextual Cognitive Field, we clarify how LLMs construct\nmeaning relationally and how coherence and a simulacrum of agency arise at the\nhuman-AI interface. The analysis situates noosemia alongside pareidolia,\nanimism, the intentional stance and the uncanny valley, distinguishing its\nunique characteristics. We also introduce a-noosemia to describe the\nphenomenological withdrawal of such projections. The paper concludes with\nreflections on the broader philosophical, epistemological, and social\nimplications of noosemic dynamics and directions for future research."}
{"id": "2508.02630", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.02630", "abs": "https://arxiv.org/abs/2508.02630", "authors": ["Amine Allouah", "Omar Besbes", "Josué D Figueroa", "Yash Kanoria", "Akshit Kumar"], "title": "What Is Your AI Agent Buying? Evaluation, Implications and Emerging Questions for Agentic E-Commerce", "comment": null, "summary": "Online marketplaces will be transformed by autonomous AI agents acting on\nbehalf of consumers. Rather than humans browsing and clicking,\nvision-language-model (VLM) agents can parse webpages, evaluate products, and\ntransact. This raises a fundamental question: what do AI agents buy, and why?\nWe develop ACES, a sandbox environment that pairs a platform-agnostic VLM agent\nwith a fully programmable mock marketplace to study this question. We first\nconduct basic rationality checks in the context of simple tasks, and then, by\nrandomizing product positions, prices, ratings, reviews, sponsored tags, and\nplatform endorsements, we obtain causal estimates of how frontier VLMs actually\nshop. Models show strong but heterogeneous position effects: all favor the top\nrow, yet different models prefer different columns, undermining the assumption\nof a universal \"top\" rank. They penalize sponsored tags and reward\nendorsements. Sensitivities to price, ratings, and reviews are directionally\nhuman-like but vary sharply in magnitude across models. Motivated by scenarios\nwhere sellers use AI agents to optimize product listings, we show that a\nseller-side agent that makes minor tweaks to product descriptions, targeting AI\nbuyer preferences, can deliver substantial market-share gains if AI-mediated\nshopping dominates. We also find that modal product choices can differ across\nmodels and, in some cases, demand may concentrate on a few select products,\nraising competition questions. Together, our results illuminate how AI agents\nmay behave in e-commerce settings and surface concrete seller strategy,\nplatform design, and regulatory questions in an AI-mediated ecosystem."}
{"id": "2508.02634", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02634", "abs": "https://arxiv.org/abs/2508.02634", "authors": ["Enrique Valero-Leal", "Pedro Larrañaga", "Concha Bielza"], "title": "Actionable Counterfactual Explanations Using Bayesian Networks and Path Planning with Applications to Environmental Quality Improvement", "comment": null, "summary": "Counterfactual explanations study what should have changed in order to get an\nalternative result, enabling end-users to understand machine learning\nmechanisms with counterexamples. Actionability is defined as the ability to\ntransform the original case to be explained into a counterfactual one. We\ndevelop a method for actionable counterfactual explanations that, unlike\npredecessors, does not directly leverage training data. Rather, data is only\nused to learn a density estimator, creating a search landscape in which to\napply path planning algorithms to solve the problem and masking the endogenous\ndata, which can be sensitive or private. We put special focus on estimating the\ndata density using Bayesian networks, demonstrating how their enhanced\ninterpretability is useful in high-stakes scenarios in which fairness is\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\nproposal finds more actionable and simpler counterfactuals than the current\nstate-of-the-art algorithms. We also test our algorithm with a real-world\nEnvironmental Protection Agency dataset, facilitating a more efficient and\nequitable study of policies to improve the quality of life in United States of\nAmerica counties. Our proposal captures the interaction of variables, ensuring\nequity in decisions, as policies to improve certain domains of study (air,\nwater quality, etc.) can be detrimental in others. In particular, the\nsociodemographic domain is often involved, where we find important variables\nrelated to the ongoing housing crisis that can potentially have a severe\nnegative impact on communities."}
{"id": "2508.02644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02644", "abs": "https://arxiv.org/abs/2508.02644", "authors": ["Guowei Zou", "Weibing Li", "Hejun Wu", "Yukun Qian", "Yuhang Wang", "Haitao Wang"], "title": "D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss", "comment": null, "summary": "Diffusion policies excel at robotic manipulation by naturally modeling\nmultimodal action distributions in high-dimensional spaces. Nevertheless,\ndiffusion policies suffer from diffusion representation collapse: semantically\nsimilar observations are mapped to indistinguishable features, ultimately\nimpairing their ability to handle subtle but critical variations required for\ncomplex robotic manipulation. To address this problem, we propose D2PPO\n(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces\ndispersive loss regularization that combats representation collapse by treating\nall hidden representations within each batch as negative pairs. D2PPO compels\nthe network to learn discriminative representations of similar observations,\nthereby enabling the policy to identify subtle yet crucial differences\nnecessary for precise manipulation. In evaluation, we find that early-layer\nregularization benefits simple tasks, while late-layer regularization sharply\nenhances performance on complex manipulation tasks. On RoboMimic benchmarks,\nD2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after\nfine-tuning, setting new SOTA results. In comparison with SOTA, results of\nreal-world experiments on a Franka Emika Panda robot show the excitingly high\nsuccess rate of our method. The superiority of our method is especially evident\nin complex tasks. Project page: https://guowei-zou.github.io/d2ppo/"}
{"id": "2508.01047", "categories": ["cs.NI", "cs.AI", "C.2.2; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2508.01047", "abs": "https://arxiv.org/abs/2508.01047", "authors": ["Efe Ağlamazlar", "Emirhan Eken", "Harun Batur Geçici"], "title": "A Deep Reinforcement Learning-Based TCP Congestion Control Algorithm: Design, Simulation, and Evaluation", "comment": "This paper presents a novel TCP congestion control algorithm based on\n  Deep Reinforcement Learning. The study includes 5 figures and 8 pages of\n  content", "summary": "This paper presents a novel TCP congestion control algorithm based on Deep\nReinforcement Learning. The proposed approach utilizes Deep Q-Networks to\noptimize the congestion window (cWnd) by observing key network parameters and\ntaking real-time actions. The algorithm is trained and evaluated within the\nNS-3 network simulator using the OpenGym interface. The results demonstrate\nsignificant improvements over traditional TCP New Reno in terms of latency and\nthroughput, with better adaptability to changing network conditions. This study\nemphasizes the potential of reinforcement learning techniques for solving\ncomplex congestion control problems in modern networks."}
{"id": "2508.01060", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.01060", "abs": "https://arxiv.org/abs/2508.01060", "authors": ["Ibrahim Althamary", "Chen-Fu Chou", "Chih-Wei Huang"], "title": "Connectivity Management in Satellite-Aided Vehicular Networks with Multi-Head Attention-Based State Estimation", "comment": null, "summary": "Managing connectivity in integrated satellite-terrestrial vehicular networks\nis critical for 6G, yet is challenged by dynamic conditions and partial\nobservability. This letter introduces the Multi-Agent Actor-Critic with\nSatellite-Aided Multi-head self-attention (MAAC-SAM), a novel multi-agent\nreinforcement learning framework that enables vehicles to autonomously manage\nconnectivity across Vehicle-to-Satellite (V2S), Vehicle-to-Infrastructure\n(V2I), and Vehicle-to-Vehicle (V2V) links. Our key innovation is the\nintegration of a multi-head attention mechanism, which allows for robust state\nestimation even with fluctuating and limited information sharing among\nvehicles. The framework further leverages self-imitation learning (SIL) and\nfingerprinting to improve learning efficiency and real-time decisions.\nSimulation results, based on realistic SUMO traffic models and 3GPP-compliant\nconfigurations, demonstrate that MAAC-SAM outperforms state-of-the-art\nterrestrial and satellite-assisted baselines by up to 14% in transmission\nutility and maintains high estimation accuracy across varying vehicle densities\nand sharing levels."}
