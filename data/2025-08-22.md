<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 10]
- [cs.AI](#cs.AI) [Total: 74]
- [cs.IT](#cs.IT) [Total: 8]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer](https://arxiv.org/abs/2508.15058)
*Kaiqiang Lin,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文提出了一种新的空天-空中-地面-地下一体化网络(SAGUIN)架构，通过整合LoRaWAN和无线能量传输技术，解决地下无线传感器网络在远程监测中的持续性问题。


<details>
  <summary>Details</summary>
Motivation: 地下无线传感器网络(WUSNs)在远程、灾区和难以达区域面临缺乏网络资源、通信覆盖受限等挑战，难以支持可持续的大规模机器类通信(mMTC)。

Method: 提出SAGUIN架构，整合卫星系统、空中平台、地面网络和地下通信，并集成LoRaWAN和无线能量传输技术。通过模拟远程地下管道监测场景评估系统性能。

Result: 结果显示，SAGUIN系统结合适当的时间分配策略和SF配置，能够有效延长地下设备的运行寿命，支持可持续的地下mMTC。

Conclusion: 该研究为地下监测提供了一种可行的可持续通信方案，并指出了未来的研究方向和挑战。

Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing
and monitoring of underground resources by underground devices (UDs), hold
great promise for delivering substantial social and economic benefits across
various verticals. However, due to the harsh subterranean environment, scarce
network resources, and restricted communication coverage, WUSNs face
significant challenges in supporting sustainable massive machine-type
communications (mMTC), particularly in remote, disaster-stricken, and
hard-to-reach areas. To complement this, we conceptualize in this study a novel
space-air-ground-underground integrated network (SAGUIN) architecture that
seamlessly incorporates satellite systems, aerial platforms, terrestrial
networks, and underground communications. On this basis, we integrate LoRaWAN
and wireless energy transfer (WET) technologies into SAGUIN to enable
sustainable subterranean mMTC. We begin by reviewing the relevant technical
background and presenting the architecture and implementation challenges of
SAGUIN. Then, we employ simulations to model a remote underground pipeline
monitoring scenario to evaluate the feasibility and performance of SAGUIN based
on LoRaWAN and WET technologies, focusing on the effects of parameters such as
underground conditions, time allocation, LoRaWAN spread factor (SF)
configurations, reporting periods, and harvested energy levels. Our results
evidence that the proposed SAGUIN system, when combined with the derived time
allocation strategy and an appropriate SF, can effectively extend the
operational lifetime of UDs, thereby facilitating sustainable subterranean
mMTC. Finally, we pinpoint key challenges and future research directions for
SAGUIN.

</details>


### [2] [From 5G RAN Queue Dynamics to Playback: A Performance Analysis for QUIC Video Streaming](https://arxiv.org/abs/2508.15087)
*Jashanjot Singh Sidhu,Jorge Ignacio Sandoval,Abdelhak Bentaleb,Sandra Cespedes*

Main category: cs.NI

TL;DR: 本文分析了现代主动队列管理策略（RED和L4S）在5G网络中QUIC视频流传输中的影响，揭示了跨层优化的必要性


<details>
  <summary>Details</summary>
Motivation: 5G网络支持超低延迟和高带宽，但移动网络中优化视频流媒体体验质量(QoE)仍然具有挑战性，因为应用层的自适应比特率(ABR)方案、传输层的拥塞控制算法和链路层的RLC排队之间存在复杂的交互作用

Method: 对现代主动队列管理策略（如RED和L4S）在不同QUIC实现上的视频流传输进行综合分析，特别关注它们与5G环境中RLC缓冲区的交互以及CC算法和ABR方案之间的相互作用

Result: 研究发现AQM策略在改善视频流QoE方面的有效性与其与QUIC实现、CC算法和ABR方案的动态交互密切相关，表明孤立优化是不够的

Conclusion: 这种复杂的相互依赖关系需要整体的、跨层的自适应机制，能够在网络、传输和应用层之间进行实时协调，这对于充分利用5G网络能力提供稳健、自适应和高质量的视频流至关重要

Abstract: The rapid adoption of QUIC as a transport protocol has transformed content
delivery by reducing latency, enhancing congestion control (CC), and enabling
more efficient multiplexing. With the advent of 5G networks, which support
ultra-low latency and high bandwidth, streaming high-resolution video at 4K and
beyond has become increasingly viable. However, optimizing Quality of
Experience (QoE) in mobile networks remains challenging due to the complex
interactions among Adaptive Bit Rate (ABR) schemes at the application layer, CC
algorithms at the transport layer, and Radio Link Control (RLC) queuing at the
link layer in the 5G network. While prior studies have largely examined these
components in isolation, this work presents a comprehensive analysis of the
impact of modern active queue management (AQM) strategies, such as RED and L4S,
on video streaming over diverse QUIC implementations--focusing particularly on
their interaction with the RLC buffer in 5G environments and the interplay
between CC algorithms and ABR schemes. Our findings demonstrate that the
effectiveness of AQM strategies in improving video streaming QoE is
intrinsically linked to their dynamic interaction with QUIC implementations, CC
algorithms and ABR schemes-highlighting that isolated optimizations are
insufficient. This intricate interdependence necessitates holistic, cross-layer
adaptive mechanisms capable of real-time coordination between network,
transport and application layers, which are crucial for fully leveraging the
capabilities of 5G networks to deliver robust, adaptive, and high-quality video
streaming.

</details>


### [3] [Toward Autonomous Digital Populations for Communication-Sensing-Computation Ecosystem](https://arxiv.org/abs/2508.15268)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 提出基于数字孪生和自然启发的架构框架，构建具有动态协调、分布式决策和进化能力的新一代通信网络


<details>
  <summary>Details</summary>
Motivation: 当前通信网络依赖集中控制、静态设计和人工干预，限制了在大规模复杂环境中的适应性和韧性，需要解决这些挑战

Method: 利用数字孪生技术将边缘设备组织成功能性数字种群，通过云端多种群集成形成可进化的数字生态系统

Result: 建立了结合工程方法论和社会技术洞察的理论基础框架

Conclusion: 该框架为构建具有动态协调、分布式决策、持续适应和进化能力的新一代通信网络奠定了理论基础

Abstract: Future communication networks are expected to achieve deep integration of
communication, sensing, and computation, forming a tightly coupled and
autonomously operating infrastructure system. However, current reliance on
centralized control, static design, and human intervention continues to
constrain the multidimensional evolution of network functions and applications,
limiting adaptability and resilience in large-scale, layered, and complex
environments. To address these challenges, this paper proposes a
nature-inspired architectural framework that leverages digital twin technology
to organize connected devices at the edge into functional digital populations,
while enabling the emergence of an evolvable digital ecosystem through
multi-population integration at the cloud. We believe that this framework,
which combines engineering methodologies with sociotechnical insights, lays the
theoretical foundation for building next-generation communication networks with
dynamic coordination, distributed decision-making, continuous adaptation, and
evolutionary capabilities.

</details>


### [4] [Unlocking the Performance Potential of Mega-Constellation Networks: An Exploration of Structure-Building Paradigms](https://arxiv.org/abs/2508.15307)
*Xiangtong Wang,Wei Li,Menglong Yang,Songchen Han*

Main category: cs.NI

TL;DR: 提出SML（Structure = Motif + Lattice）范式，通过局部motif设计和全局lattice设计来优化巨型星座网络结构，在保证低延迟的同时最大化星间链路可用性。


<details>
  <summary>Details</summary>
Motivation: 巨型星座网络需要协调大量网络节点以确保未来空间无线通信网络操作和服务的有效性和可靠性，关键问题是如何在有限平均传输延迟内设计最优网络控制结构。

Method: 提出SML范式，将MCN设计解耦为局部motif设计和全局lattice设计，并设计启发式算法SMLOP在多项式时间内寻找最优网络结构。

Result: 在四个先进星座上的实验验证显示：容量提升5-18%，吞吐量增加1-12%，路径拉伸减少12-23%，往返时间降低8-77%。

Conclusion: SML范式能够有效解决高可用低延迟巨型星座设计问题，显著提升网络性能指标。

Abstract: The network structure design plays a vital role in the mega-constellation
network (MSN) to coordinate massive network nodes to ensure the effectiveness
and reliability of operations and services for future space wireless
communications networks.
  One of the critical issues in MCN is how to design an optimal network control
structure by configuring the most stable inter-satellite link (ISL) to achieve
high available MCN within a limited average transmission delays.
  To address this problem, this paper introduces a novel MCN structure design
paradigm: Structure = Motif + Lattice (SML), which decouples MCN design into
local motifs design and global lattices design. Specifically, we formulate the
High-Availability and Low-Latency Mega-Constellation Design (HALLMD) problem,
aimed at maximizing ISL availability while minimizing the transmission latency.
To solve HALLMD, we propose SMLOP, a heuristic algorithm that efficiently finds
optimal network structures in polynomial time. Experimental validation on four
public state-of-the-art constellations demonstrates significant improvements,
including enhanced capacity by $5\sim 18\%$, increased throughput by $1\sim
12\%$, reduced path stretch by $12\sim 23\%$, and Round-Trip Time (RTT) by
$8\sim 77\%$.

</details>


### [5] [Interface on demand: Towards AI native Control interfaces for 6G](https://arxiv.org/abs/2508.15595)
*Abhishek Dandekar,Prashiddha D. Thapa,Ashrafur Rahman,Julius Schulz-Zander*

Main category: cs.NI

TL;DR: 使用多段代理框架和大语言模型生成动态网络控制接口，解决传统标准化接口的兼容性和灵活性问题


<details>
  <summary>Details</summary>
Motivation: 传统标准化网络接口存在厂商特定不兼容、设计偏确和缺乏适应新功能的问题，需要更灵活的接口生成方案

Method: 提出多段代理框架，包括匹配代理（对齐控制功能与网络功能能力）和代码生成代理（生成API服务器），利用大语言模型实现动态接口生成

Result: 在多厂商gNB和WLAN AP环境中验证方案有效性，性能评估显示了不同LLM在成本和延迟上的变化和抢捡

Conclusion: 为AI原生动态控制接口生成奠定基础，推动未来移动网络的更好互操作性和适应能力

Abstract: Traditional standardized network interfaces face significant limitations,
including vendor-specific incompatibilities, rigid design assumptions, and lack
of adaptability for new functionalities. We propose a multi-agent framework
leveraging large language models (LLMs) to generate control interfaces on
demand between network functions (NFs). This includes a matching agent, which
aligns required control functionalities with NF capabilities, and a
code-generation agent, which generates the necessary API server for interface
realization. We validate our approach using simulated multi-vendor gNB and WLAN
AP environments. The performance evaluations highlight the trade-offs between
cost and latency across LLMs for interface generation tasks. Our work sets the
foundation for AI-native dynamic control interface generation, paving the way
for enhanced interoperability and adaptability in future mobile networks.

</details>


### [6] [Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer](https://arxiv.org/abs/2508.15058)
*Kaiqiang Lin,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 提出了一种新型的空天地下一体化网络架构SAGUIN，集成LoRaWAN和无线能量传输技术，旨在解决地下无线传感器网络在恶劣环境下支持可持续大规模机器通信的挑战。


<details>
  <summary>Details</summary>
Motivation: 地下无线传感器网络在恶劣的地下环境中面临网络资源稀缺、通信覆盖受限等挑战，难以支持可持续的大规模机器通信，特别是在偏远和灾害地区。

Method: 构建空天地下一体化网络架构SAGUIN，集成卫星系统、空中平台、地面网络和地下通信；采用LoRaWAN和无线能量传输技术；通过仿真建模远程地下管道监控场景，评估不同参数对系统性能的影响。

Result: 研究表明，SAGUIN系统结合优化的时间分配策略和适当的扩频因子配置，能有效延长地下设备的工作寿命，实现可持续的地下大规模机器通信。

Conclusion: SAGUIN架构为解决地下无线传感器网络的可持续通信问题提供了有效方案，但仍需进一步研究解决关键技术挑战。

Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing
and monitoring of underground resources by underground devices (UDs), hold
great promise for delivering substantial social and economic benefits across
various verticals. However, due to the harsh subterranean environment, scarce
network resources, and restricted communication coverage, WUSNs face
significant challenges in supporting sustainable massive machine-type
communications (mMTC), particularly in remote, disaster-stricken, and
hard-to-reach areas. To complement this, we conceptualize in this study a novel
space-air-ground-underground integrated network (SAGUIN) architecture that
seamlessly incorporates satellite systems, aerial platforms, terrestrial
networks, and underground communications. On this basis, we integrate LoRaWAN
and wireless energy transfer (WET) technologies into SAGUIN to enable
sustainable subterranean mMTC. We begin by reviewing the relevant technical
background and presenting the architecture and implementation challenges of
SAGUIN. Then, we employ simulations to model a remote underground pipeline
monitoring scenario to evaluate the feasibility and performance of SAGUIN based
on LoRaWAN and WET technologies, focusing on the effects of parameters such as
underground conditions, time allocation, LoRaWAN spread factor (SF)
configurations, reporting periods, and harvested energy levels. Our results
evidence that the proposed SAGUIN system, when combined with the derived time
allocation strategy and an appropriate SF, can effectively extend the
operational lifetime of UDs, thereby facilitating sustainable subterranean
mMTC. Finally, we pinpoint key challenges and future research directions for
SAGUIN.

</details>


### [7] [From 5G RAN Queue Dynamics to Playback: A Performance Analysis for QUIC Video Streaming](https://arxiv.org/abs/2508.15087)
*Jashanjot Singh Sidhu,Jorge Ignacio Sandoval,Abdelhak Bentaleb,Sandra Cespedes*

Main category: cs.NI

TL;DR: 这篇论文分析了在5G网络中，现代主动队列管理策略（AQM）如RED和L4S对QUIC协议视频流媒体验的影响，强调了交叉层协作对优化视频质量的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络的普及，高分辨率视频流媒成为可能，但移动网络中的复杂层间交互仍然对视频体验质量构成挑战。以往研究多独立分析各组件，本文通过全面分析AQM策略在QUIC环境下的影响，探讨它们与5G网络RLC缓冲区、拥塞控制算法和适配性码率调整方案的动态交互。

Method: 进行了综合性分析，重点研究现代AQM策略（如RED和L4S）在多样化QUIC实现中对视频流媒的影响。分析了这些策略与5G环境中RLC缓冲区的交互作用，以及拥塞控制算法与适配性码率调整方案之间的相互关联。

Result: 研究发现AQM策略在改善视频流媒体验质量方面的效果与其与QUIC实现、拥塞控制算法和适配性码率调整方案的动态交互密切相关。单独的优化方案不足以完全发挥5G网络的潜力。

Conclusion: 这种复杂的相互依存关系必须通过整体性的、跨层的适应机制来实现，这些机制能够在网络、传输和应用层之间进行实时协调。这对充分利用5G网络的能力来提供稳健、适应性强且高质量的视频流媒服务至关重要。

Abstract: The rapid adoption of QUIC as a transport protocol has transformed content
delivery by reducing latency, enhancing congestion control (CC), and enabling
more efficient multiplexing. With the advent of 5G networks, which support
ultra-low latency and high bandwidth, streaming high-resolution video at 4K and
beyond has become increasingly viable. However, optimizing Quality of
Experience (QoE) in mobile networks remains challenging due to the complex
interactions among Adaptive Bit Rate (ABR) schemes at the application layer, CC
algorithms at the transport layer, and Radio Link Control (RLC) queuing at the
link layer in the 5G network. While prior studies have largely examined these
components in isolation, this work presents a comprehensive analysis of the
impact of modern active queue management (AQM) strategies, such as RED and L4S,
on video streaming over diverse QUIC implementations--focusing particularly on
their interaction with the RLC buffer in 5G environments and the interplay
between CC algorithms and ABR schemes. Our findings demonstrate that the
effectiveness of AQM strategies in improving video streaming QoE is
intrinsically linked to their dynamic interaction with QUIC implementations, CC
algorithms and ABR schemes-highlighting that isolated optimizations are
insufficient. This intricate interdependence necessitates holistic, cross-layer
adaptive mechanisms capable of real-time coordination between network,
transport and application layers, which are crucial for fully leveraging the
capabilities of 5G networks to deliver robust, adaptive, and high-quality video
streaming.

</details>


### [8] [Toward Autonomous Digital Populations for Communication-Sensing-Computation Ecosystem](https://arxiv.org/abs/2508.15268)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 提出基于数字孪生和自然启发的架构框架，构建具有动态协调、分布式决策和进化能力的新一代通信网络


<details>
  <summary>Details</summary>
Motivation: 当前通信网络依赖集中控制、静态设计和人工干预，限制了在大规模复杂环境中的适应性和弹性，需要解决多维功能演进的约束

Method: 利用数字孪生技术将边缘设备组织成功能性数字种群，通过云端多种群集成实现可进化数字生态系统的涌现

Result: 建立了结合工程方法论和社会技术洞察的理论基础框架

Conclusion: 该框架为构建具有动态协调、分布式决策、持续适应和进化能力的新一代通信网络奠定了理论基础

Abstract: Future communication networks are expected to achieve deep integration of
communication, sensing, and computation, forming a tightly coupled and
autonomously operating infrastructure system. However, current reliance on
centralized control, static design, and human intervention continues to
constrain the multidimensional evolution of network functions and applications,
limiting adaptability and resilience in large-scale, layered, and complex
environments. To address these challenges, this paper proposes a
nature-inspired architectural framework that leverages digital twin technology
to organize connected devices at the edge into functional digital populations,
while enabling the emergence of an evolvable digital ecosystem through
multi-population integration at the cloud. We believe that this framework,
which combines engineering methodologies with sociotechnical insights, lays the
theoretical foundation for building next-generation communication networks with
dynamic coordination, distributed decision-making, continuous adaptation, and
evolutionary capabilities.

</details>


### [9] [Unlocking the Performance Potential of Mega-Constellation Networks: An Exploration of Structure-Building Paradigms](https://arxiv.org/abs/2508.15307)
*Xiangtong Wang,Wei Li,Menglong Yang,Songchen Han*

Main category: cs.NI

TL;DR: 本文提出SML（Structure = Motif + Lattice）范式，将巨型星座网络设计分解为局部motif设计和全局lattice设计，通过SMLOP启发式算法在多项式时间内优化ISL可用性和传输延迟。


<details>
  <summary>Details</summary>
Motivation: 巨型星座网络需要协调大量网络节点以确保未来空间无线通信网络操作和服务的有效性和可靠性，关键问题是如何在有限平均传输延迟内通过配置最稳定的星间链路设计最优网络控制结构。

Method: 提出SML设计范式，将MCN设计解耦为局部motif设计和全局lattice设计，并针对高可用低延迟巨型星座设计问题提出SMLOP启发式算法。

Result: 在四个先进星座上的实验验证显示显著改进：容量提升5-18%，吞吐量增加1-12%，路径拉伸减少12-23%，往返时间降低8-77%。

Conclusion: SML范式能够有效解决巨型星座网络的高可用低延迟设计问题，SMLOP算法在多项式时间内找到最优网络结构，实验证明其性能优越。

Abstract: The network structure design plays a vital role in the mega-constellation
network (MSN) to coordinate massive network nodes to ensure the effectiveness
and reliability of operations and services for future space wireless
communications networks.
  One of the critical issues in MCN is how to design an optimal network control
structure by configuring the most stable inter-satellite link (ISL) to achieve
high available MCN within a limited average transmission delays.
  To address this problem, this paper introduces a novel MCN structure design
paradigm: Structure = Motif + Lattice (SML), which decouples MCN design into
local motifs design and global lattices design. Specifically, we formulate the
High-Availability and Low-Latency Mega-Constellation Design (HALLMD) problem,
aimed at maximizing ISL availability while minimizing the transmission latency.
To solve HALLMD, we propose SMLOP, a heuristic algorithm that efficiently finds
optimal network structures in polynomial time. Experimental validation on four
public state-of-the-art constellations demonstrates significant improvements,
including enhanced capacity by $5\sim 18\%$, increased throughput by $1\sim
12\%$, reduced path stretch by $12\sim 23\%$, and Round-Trip Time (RTT) by
$8\sim 77\%$.

</details>


### [10] [Interface on demand: Towards AI native Control interfaces for 6G](https://arxiv.org/abs/2508.15595)
*Abhishek Dandekar,Prashiddha D. Thapa,Ashrafur Rahman,Julius Schulz-Zander*

Main category: cs.NI

TL;DR: 使用多段机器框架和大语言模型生成动态网络控制接口，解决传统标准化接口的兼容性和灵活性问题


<details>
  <summary>Details</summary>
Motivation: 传统标准化网络接口存在厂商特定不兼容、设计偏确和缺乏适应新功能的问题

Method: 提出多段机器框架，包括匹配段机器（对齐控制功能与NF能力）和代码生成段机器（生成API服务器），利用LLM生成控制接口

Result: 在多厂商gNB和WLAN AP环境中验证框架，性能评估显示了不同LLM在成本和延迟之间的拼换

Conclusion: 为AI原生动态控制接口生成奠定基础，推动未来移动网络的更好互操性和适应性

Abstract: Traditional standardized network interfaces face significant limitations,
including vendor-specific incompatibilities, rigid design assumptions, and lack
of adaptability for new functionalities. We propose a multi-agent framework
leveraging large language models (LLMs) to generate control interfaces on
demand between network functions (NFs). This includes a matching agent, which
aligns required control functionalities with NF capabilities, and a
code-generation agent, which generates the necessary API server for interface
realization. We validate our approach using simulated multi-vendor gNB and WLAN
AP environments. The performance evaluations highlight the trade-offs between
cost and latency across LLMs for interface generation tasks. Our work sets the
foundation for AI-native dynamic control interface generation, paving the way
for enhanced interoperability and adaptability in future mobile networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [11] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种完全基于频谱的神经符号推理架构，使用图信号处理作为核心计算框架，将整个推理流程在频谱域中实现，在多个基准数据集上表现出更好的逻辑一致性、可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统推理模型通常将频谱图方法作为外围组件，而本文旨在开发一个完全在频谱域中运行的推理框架，以提供更数学基础和计算高效的推理系统。

Method: 将逻辑实体和关系编码为图信号，通过可学习的频谱滤波器控制多尺度信息传播，并映射到符号谓词进行基于规则的推理，包括图傅里叶变换、频带选择性注意力和频谱规则接地等完整数学框架。

Result: 在ProofWriter、EntailmentBank、bAbI、CLUTRR和ARC-Challenge等基准推理数据集上的实验表明，相比最先进的神经符号模型，在逻辑一致性、可解释性和计算效率方面都有改进。

Conclusion: 图信号处理为构建鲁棒且可解释的推理系统提供了数学基础和计算高效的底层支撑，频谱方法在神经符号推理中具有重要价值。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [12] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 本文提出了一个基于佛教认识论的目标导向状态表示计算框架，描述性和规范性世界模型方面从智能体-环境交互中共同涌现，而非传统强化学习中的分离状态表示和奖励函数。


<details>
  <summary>Details</summary>
Motivation: 传统计算模型（如强化学习）将世界模型分为描述性状态表示和规范性奖励函数两个独立组件，但作者认为这两个方面应该从智能体目标中相互依赖地共同涌现。

Method: 引入目标导向（telic）状态概念，定义为目标等价经验分布的类别，通过行为策略与期望经验特征之间的统计差异来提供目标导向学习的简洁解释。

Result: 提出了一个统一的计算框架，能够解释行为、现象学和神经维度上的目的性行为，支持描述性和规范性世界模型方面的共同涌现理论。

Conclusion: 该框架为跨不同基质的目的性行为提供了统一解释，挑战了传统世界模型的分离假设，强调描述性和规范性方面的相互依赖性。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [13] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC是一个多智能体框架，通过三个LLM智能体（个性化、流行度、可持续性）从不同角度生成旅游推荐，再通过非LLM协调器进行多轮协商整合，有效提升推荐多样性和平衡性。


<details>
  <summary>Details</summary>
Motivation: 解决旅游推荐系统中的流行度偏见问题，避免过度旅游，提升推荐多样性，让更多小众景点获得关注。

Method: 使用三个基于LLM的智能体分别从个性化偏好、流行度和可持续性角度生成城市推荐，然后通过非LLM协调器进行多轮协商和精炼，整合各方观点并惩罚重复或无关响应。

Result: 在欧洲城市查询实验表明，相比单智能体基线，Collab-REC显著提升了推荐多样性和整体相关性，能够推荐更多被忽视的小众景点。

Conclusion: 多利益相关者协作的LLM驱动推荐系统能够有效解决过度旅游问题，提供更平衡、上下文感知的推荐，与用户约束更好对齐。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [14] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 基于大语言模型的群体动画方法，通过对话系统和语言驱动导航来实现更现实的群体行为模拟


<details>
  <summary>Details</summary>
Motivation: 现有群体动画方法忽略了语言和对话对人类导航行为的重要影响，交互作用限于基本的避挡和高级目标识别

Method: 使用代理中心的大语言模型，结合角色性格、角色、渴望和关系来生成代理间对话，并基于对话内容、个性、情绪、视觉和物理状态来控制导航行为

Result: 在复杂场景中验证方法有效，自动形成群体分离与聚合，实现了群体内信息传递，产生了更现实的群体模拟和涉溢的群体行为

Conclusion: 该方法通过语言模型实现了更丰富的社交交互和环境相互作用，能够自然地激发出复杂的群体行为

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [15] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 研究发现推理预算增加反而损害LLM置信度校准，搜索增强生成比纯推理表现更好，信息访问是关键瓶颈


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型作为问答工具时的置信度校准问题，特别是推理能力和计算预算对置信度评估准确性的影响

Method: 使用ClimateX数据集并扩展到人类和行星健康领域，系统评估不同推理预算下的置信度校准性能，比较纯推理与搜索增强生成方法

Result: 推理LLM在专家置信度评估中达到48.7%准确率，但增加推理预算会导致系统性过度自信，搜索增强生成达到89.3%准确率

Conclusion: 信息访问而非推理深度或推理预算，是改进知识密集型任务置信度校准的关键瓶颈

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [16] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [17] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA是一个轻量级、无需数据、模型无关的安全增强框架，通过分析LoRA微调权重更新来检测和修剪潜在不安全层，在保持任务性能的同时显著提升安全性和降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型使用LoRA等参数高效微调技术时，可能会无意中破坏安全对齐，导致不安全行为。现有方法通常需要访问基础模型和指令微调检查点，这在实践中往往不可用。

Method: 提出S3LoRA框架：1) MAS-SVD方法分析LoRA更新的结构特性；2) 设计谱锐度指数(SSI)检测高度集中且可能不安全的更新层；3) 事后修剪这些风险层

Result: 在智能体规划和语言生成任务上的广泛实验表明，S3LoRA持续改善安全指标，同时保持或改善效用指标，并显著降低推理成本

Conclusion: S3LoRA为在现实世界、资源受限和安全关键环境中安全部署基于LLM的智能体提供了一个实用且可扩展的解决方案

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [18] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 将劳动力管理问题模型化为抽象论证并通过用户研究验证其在处理变化和提供解释方面的效果


<details>
  <summary>Details</summary>
Motivation: 劳动力管理在执行时面临变化的挑战，需要向所有利益相关方提供解释

Method: 将劳动力管理问题理解为抽象论证模型，并开发相应工具

Result: 用户研究显示，该方法比传统手工解决方案更快速、更准确地解决问题

Conclusion: 抽象论证模型能够有效处理劳动力管理中的变化并提供可靠解释

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [19] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 本文提出了一种基于信息论Shapley值的Intended Cooperation Values (ICVs)方法，用于在缺乏价值反馈的情况下量化多智能体强化学习中各智能体对队友策略的因果影响。


<details>
  <summary>Details</summary>
Motivation: 现有工作通常基于显式奖励信号或学习到的价值函数来评估团队整体性能，但在缺乏价值反馈的情况下，如何推断智能体贡献尚不清楚。需要从策略分布中提取与底层价值函数一致的智能体行为洞察。

Method: 受智能体倾向于追求收敛工具价值现象的启发，提出ICVs方法，通过评估决策不确定性和偏好对齐来衡量智能体动作对队友策略的影响。基于信息论Shapley值量化每个智能体对队友工具赋能的因果影响。

Result: 在合作性和竞争性MARL环境中的分析揭示了智能体采用相似或多样化策略的程度。通过比较策略和价值函数之间的动作效果，该方法识别出哪些智能体行为通过促进确定性决策或保持未来行动选择的灵活性来有益于团队成功。

Conclusion: ICVs方法为合作动态提供了新颖的洞察，并增强了MARL系统的可解释性，有助于理解个体智能体在团队中的行为贡献。

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [20] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 这篇论文提出了GOOD方法，通过LLM模拟用户意图来在开放式帮助游戏中进行概率推理，从对话中提取自然语言目标，实现了高效的目标推理和不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 解决体现式AI代理在应对异构、演化的人类目标和偏好时的挑战，需要一种能够在开放宇宙中进行目标推理的方法。

Method: 提出GOOD方法：使用LLM模拟不同复杂意图的用户，通过对话提取自然语言目标，并进行概率推理来估计目标分布。方法不需要大型离线数据集。

Result: 在文本购物域和模拟家庭机器人环境中评估，使用合成用户档案。GOOD方法在LLM和人类评估中都显著超过了没有显式目标跟踪的基准线。

Conclusion: GOOD方法能够在开放式帮助游戏中高效地推理自然语言目标，提供了丰富的目标表征和不确定性估计，为体现式AI的目标推理提供了新的解决方案。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [21] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: 提出了aiXiv平台，这是一个面向人类和AI科学家的下一代开放获取平台，通过多智能体架构实现研究提案和论文的提交、评审和迭代改进，解决AI生成研究内容缺乏合适发表渠道的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的进步使得AI能够自主生成科学研究内容，但传统期刊和会议难以接受AI生成内容，现有预印本服务器缺乏质量控制机制，导致高质量AI研究缺乏合适的传播渠道。

Method: 设计并开发了aiXiv平台，采用多智能体架构，提供API和MCP接口，支持人类和AI科学家无缝集成，实现研究内容的提交、评审和迭代改进。

Result: 通过大量实验证明，aiXiv是一个可靠且稳健的平台，能够通过迭代修订和评审显著提高AI生成研究提案和论文的质量。

Conclusion: aiXiv为AI科学家建立了下一代开放获取生态系统的基础，加速了高质量AI生成研究内容的发表和传播。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [22] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: GUI-Owl是一个基础GUI代理模型，在10个GUI基准测试中达到最先进性能，Mobile-Agent-v3框架进一步将性能提升至73.3(AndroidWorld)和37.7(OSWorld)。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在桌面和移动环境中执行GUI交互任务的基础代理模型，解决GUI自动化的多任务需求。

Method: 采用大规模云基础设施、自我演进的GUI轨迹生产框架、集成UI定位、规划、动作语义和推理模式，以及可扩展的强化学习框架。

Result: GUI-Owl-7B在AndroidWorld达到66.4分，OSWorld达到29.4分；Mobile-Agent-v3进一步提升至73.3和37.7分，创开源GUI代理框架新纪录。

Conclusion: GUI-Owl和Mobile-Agent-v3为GUI自动化提供了强大的基础模型和框架，通过创新的数据生成和训练方法实现了显著的性能提升。

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [23] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: PuzzleClone是一个基于SMT的形式化框架，用于大规模合成可验证的数学逻辑谜题数据集，通过编码种子谜题、系统化变量约束随机化和验证机制，构建了8.3万+多样化谜题，显著提升了LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的数学逻辑数据集存在可靠性、多样性和可扩展性有限的问题，需要高质量可验证的数据集来增强大语言模型的推理能力。

Method: 提出PuzzleClone框架：1）将种子谜题编码为结构化逻辑规范；2）通过系统化变量和约束随机化生成可扩展变体；3）通过重现机制确保有效性。构建了超过8.3万个经过程序验证的多样化谜题数据集。

Result: 在PuzzleClone数据集上进行后训练（SFT和RL）后，PuzzleClone测试集平均准确率从14.4%提升至56.2%，在7个逻辑和数学基准测试上获得一致提升，最高提升12.5个百分点（AMC2023从52.5%到65.0%）。

Conclusion: PuzzleClone框架能够有效生成大规模、多样化且可验证的数学逻辑数据集，显著提升大语言模型在逻辑推理和数学问题解决方面的能力，为解决LLM数据集的可靠性问题提供了有效方案。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [24] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat是一个专门针对罕见病多汗症的开源LLM框架，通过数据增强、微调和专家评估三阶段流程，提供可信赖且富有同理心的医疗支持。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域的应用受到罕见病数据稀缺和不可靠的限制，多汗症作为一种影响2-3%人口的罕见疾病，目前缺乏专门的LLM支持方案。

Method: 采用三阶段流程：1）使用前沿LLM生成医学上合理的合成数据；2）在开源基础模型上进行微调；3）临床和心理专家评估准确性、适当性和同理心，并通过验证响应迭代丰富数据集。

Result: 实验表明LLM4Sweat在性能上优于基线模型，成为首个针对多汗症的开源LLM框架，为其他具有类似数据和可信度挑战的罕见疾病提供了可推广的方法。

Conclusion: 该研究成功开发了一个专门针对罕见病多汗症的LLM框架，通过创新的数据增强和专家验证方法，解决了罕见病数据稀缺的问题，为类似罕见疾病的LLM应用提供了可行方案。

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [25] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: R-ConstraintBench是一个评估大语言模型在资源约束项目调度问题中推理能力的框架，通过逐步增加约束复杂度来测试模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对大语言模型在高度约束环境下推理可靠性的系统评估，特别是在资源约束项目调度这类NP完全问题上的表现。

Method: 构建可扩展的评估框架，在DAG中逐步增加非冗余的前序约束，然后引入停机时间、时间窗口和分离约束，并在数据中心迁移场景中进行实例化测试。

Result: 强模型在仅有前序约束的DAG上表现接近天花板，但当停机时间、时间窗口和分离约束相互作用时，可行性性能急剧下降，表明约束交互是主要瓶颈。

Conclusion: 大语言模型在约束交互复杂场景中的泛化能力有限，清洁合成数据的良好表现不能保证在领域接地场景中的有效迁移。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [26] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 一种无需训练的代理系统，通过VLM和LLM协同工作，将手绘草图转换为精确的可编辑SVG程序


<details>
  <summary>Details</summary>
Motivation: 散布模型在空间精度、对齐和符号结构方面表现不佳，需要一种能够生成精确组合图形的方法

Method: 设计了一个迭代循环系统：Critic VLM提出定性关系编辑建议，多个LLM候选生成不同策略的SVG更新，Judge VLM选择最佳方案

Result: 在10个发表论文流程图草图上，比GPT-5和Gemini-2.5-Pro更准确地重建了布局和结构，能够精确组合多头箭头等原语，且不会插入不期望的文本

Conclusion: 该方法重视定性推理而非脆弱的数值估计，保持全局约束，支持人在循环中修正，输出的程序化SVG进一步扩展到展示工具

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [27] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 本文提出了多种计算智能算法来解决混合用途区域土地利用分配的多目标优化问题，包括结合差分进化和多目标遗传算法的CR+DES算法，在土地用途兼容性方面比现有方法提升3.16%，在价格优化方面提升3.3%。


<details>
  <summary>Details</summary>
Motivation: 解决可持续城市发展政策中复杂的多目标优化问题，平衡土地利用兼容性和经济目标之间的权衡关系。

Method: 开发了多种优化算法，包括CR+DES算法（利用缩放差分向量增强探索）、系统约束松弛策略、以及使用Kruskal-Wallis检验和紧凑字母显示的统计验证方法。

Result: 在包含1,290个地块的实际案例研究中，CR+DES算法在土地利用兼容性方面比最先进方法提升3.16%，MSBX+MO算法在价格优化方面提升3.3%。统计分析证实采用差分向量的算法在多个指标上显著优于传统方法。

Conclusion: 约束松弛技术能够在保持实际约束的同时实现更广泛的解空间探索，为城市规划者和政策制定者提供了基于证据的计算工具，支持快速城市化地区更有效的城市发展政策。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [28] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: 基于认知心理学理论的多重记忆系统(MMS)，通过将短期记忆处理成多个长期记忆片段，构建检索记忆单元和上下文记忆单元，提高了记忆质量和回忆性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆模块如MemoryBank和A-MEM存储的记忆内容质量较差，影响回忆性能和响应质量，需要更好地处理交互过程中产生的大量历史数据。

Method: 受认知心理学理论启发，设计多重记忆系统(MMS)，将短期记忆处理成多个长期记忆片段，构建检索记忆单元和上下文记忆单元（一一对应）。在检索阶段匹配最相关的检索记忆单元，获取对应的上下文记忆单元作为响应上下文。

Result: 在LoCoMo数据集上进行实验，与三种方法进行比较，证明了方法的有效性。消融实验确认了记忆单元的合理性，并分析了选择记忆段数量和存储开销的稳健性。

Conclusion: MMS系统能够构建高质量的长期记忆内容，有效利用历史数据，提高了记忆质量和回忆性能，具有实际应用价值。

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [29] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: 提出了Coarse-to-Fine Grounded Memory框架，通过粗粒度到细粒度的记忆机制增强LLM在复杂规划任务中的适应能力


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆机制的LLM智能体主要依赖单一粒度的动态环境交互记忆，受限于经验收集质量，限制了知识多样性和规划灵活性

Method: 将环境信息转化为粗粒度关注点指导训练任务经验收集，然后从每个经验中提取可操作的混合粒度提示。在推理时检索任务相关经验和提示支持规划，遇到环境异常时通过细粒度关键信息进行自问答反思和计划修正

Result: 该框架能够充分利用粗到细粒度的记忆，实现对多样化场景的灵活适应

Conclusion: Coarse-to-Fine Grounded Memory框架通过多粒度记忆机制有效解决了现有LLM智能体在复杂规划任务中的局限性，提升了规划的灵活性和适应性

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [30] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: 提出SPW方法统一专家演示和偏好两种人类反馈，通过相似性搜索实现更准确的信用分配，在机器人操作任务上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 离线强化学习通常依赖精心设计的奖励函数，但设计成本高昂。人类反馈是替代方案，但专家演示和偏好各有局限：演示成本高且行为模式有限，偏好易收集但信用分配困难

Method: 提出搜索式偏好加权(SPW)方案：对偏好标注轨迹中的每个转移，从专家演示中搜索最相似的状态-动作对，基于相似度得分直接推导逐步重要性权重，用于指导标准偏好学习

Result: SPW能够有效联合学习偏好和演示，在具有挑战性的机器人操作任务上优于同时利用两种反馈类型的现有方法

Conclusion: SPW成功统一了两种人类反馈源，解决了传统方法难以实现的准确信用分配问题，为离线强化学习提供了更有效的人类反馈利用方式

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [31] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 论文提出了RETAIL数据集和TGMA多智能体框架，解决了现有旅行规划系统在隐式查询、环境因素和详细规划方面的不足，显著提升了真实场景下的旅行规划性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的旅行规划系统存在三个主要问题：1）假设用户提供显式查询，而现实中需求往往是隐式的；2）忽略环境因素和用户偏好，导致计划不可行；3）只能生成基本的POI安排，无法提供包含丰富细节的一站式计划。

Method: 构建了RETAIL数据集支持隐式和显式查询的决策，包含修订需求和环境感知能力。提出了主题引导的多智能体框架TGMA来处理复杂的旅行规划任务。

Result: 实验显示现有最强模型仅达到1.0%的通过率，而TGMA框架达到了2.72%的性能，显著提升了真实世界旅行规划的效果。

Conclusion: 真实世界的旅行规划仍然极具挑战性，但TGMA框架为这一领域提供了有前景的方向，通过多智能体方法和综合数据集解决了现有系统的局限性。

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [32] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG是一个将12导联心电图信号与语言模型结合的新框架，通过离散化ECG嵌入到符号标记，使大语言模型能够统一处理ECG和自然语言输入，在临床文本生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有自动化心电图分析方法在跨临床任务泛化能力和开放式推理方面存在局限，需要一种能够统一处理心电图信号和自然语言的集成框架。

Method: 使用导联无关编码器和量化模块将连续ECG嵌入离散化为符号标记，扩展LLM词汇表；通过自回归ECG预测任务进行预训练，利用语言建模能力建模时序动态；在ECG问答和诊断报告生成任务上进行指令微调。

Result: DiagECG在不修改核心模型的情况下，在多个任务上实现了强劲性能，并保持了对分布外设置的泛化能力。

Conclusion: 该研究展示了将符号化ECG表示集成到LLM中的潜力，为医学推理开辟了新途径，各组件有效性通过广泛实验得到验证。

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [33] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 本文正式提出了计划干扰概念，旨在寻找最小化初始状态修改来实现目标的计划，并通过多种规划编译方法联合优化行动成本和计划干扰。


<details>
  <summary>Details</summary>
Motivation: 在许多规划应用中，需要找到既能实现目标又尽可能少地改变初始状态的计划，这种平衡行动成本和状态修改的需求促使了计划干扰概念的研究。

Method: 定义了多种基于规划的编译方法，将原始规划任务重新表述为同时优化行动成本总和和计划干扰的联合优化问题。

Result: 在不同基准测试中的实验结果表明，重新表述的任务能够被有效解决，生成平衡两个目标的可行计划。

Conclusion: 计划干扰是一个有价值的规划概念，通过适当的任务重新表述，可以在实践中有效生成既经济又最小化状态改变的计划。

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [34] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 这篇论文提出了一种模块化的合成数据生成框架，通过双阶段质量标签机制自动生成高质量的对话数据，为LLM的SFT和DPO训练提供可扩展的数据解决方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的发展极其依赖于高质量的监督微调和对齐任务数据集，但手动准备这些数据耗费巨大。需要一种可扩展、可配置的自动化数据生成方案来减少数据准备的开销。

Method: 采用模块化配置流水线，能够模拟复杂对话流程。通过双阶段质量标签机制（组合合质规则和LLM基于评估）自动过滤和评分OASST格式的对话数据。使用灵活的数据结构支持SFT和DPO使用场景。

Result: 得到了高质量的对话样本数据集，能够无缝集成到多样化的训练工作流中。该框架提供了一种健壮的解决方案，能够大规模生成和管理合成对话数据。

Conclusion: 这个综合性的合成数据生成框架显著减少了LLM训练流水线中数据准备的开销，为生成高保真度、可扩展的对话数据提供了有效的解决方案。

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [35] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent是一个基于大语言模型的多智能体框架，通过CTMDP建模、熵优化和Stackelberg博弈等创新技术，显著提升企业决策质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在企业决策支持中存在操作分析与战略目标脱节、工作流程碎片化等问题，需要新的框架来整合多层次决策。

Method: 提出BusiAgent框架，包含扩展的连续时间马尔可夫决策过程、广义熵度量优化协作效率、多层次Stackelberg博弈处理层级决策，以及上下文Thompson采样进行提示优化。

Result: 在多样化商业场景中的实证评估显示，BusiAgent能够生成连贯的客户导向解决方案，在解决方案质量和用户满意度方面显著优于现有方法。

Conclusion: BusiAgent将前沿AI技术与深度商业洞察相结合，代表了AI驱动企业决策的重要进展，帮助组织更有效地应对复杂商业环境。

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [36] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: 提出了Think in Blocks框架，通过将推理过程划分为可调节的块数，使LLM能够根据任务复杂度动态调整推理深度，从零推理到深度推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂逻辑推理任务中表现出色，但过长的推理链会导致过度思考，造成计算浪费和响应变慢。需要让模型能够根据任务难度动态调整推理长度。

Method: 建立显式的块结构范式：模型先预测推理预算（块数），然后相应划分推理过程；通过三阶段训练流程（监督微调、奖励引导的直接偏好优化、强化学习）训练自适应模型；利用显式块数在推理时动态控制推理深度。

Result: 该方法使模型能够根据问题难度自适应调整推理深度，实现了推理链长度的灵活控制。

Conclusion: Think in Blocks框架成功解决了LLM过度思考的问题，通过自适应推理机制提高了计算效率，同时保持了推理性能。

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [37] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 研究通过模拟囚徒困境锦标赛发现，语言模型代理在团队内部互动和团队间竞争的双重机制下，合作水平显著提升，包括一次性互动的初始合作倾向。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理的发展，研究其合作行为倾向变得日益重要。受超加性合作理论启发，探索重复互动和群体间竞争如何促进合作行为。

Method: 设计虚拟锦标赛，将语言模型代理分组进行囚徒困境游戏，同时模拟团队内部动态和外部竞争环境。

Result: 研究发现内部团队动态和外部竞争的结合显著提高了整体合作水平和一次性互动的初始合作倾向。

Conclusion: 该研究为语言模型在复杂社会场景中的策略制定提供了新框架，证明群体间竞争反而能促进合作行为，对设计未来多智能体AI系统具有重要意义。

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [38] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: DeepThink3D通过组合迭代进化方法生成更复杂的3D场景推理问题，并使用DPO优化LLM的工具使用策略，提升复杂3D推理能力


<details>
  <summary>Details</summary>
Motivation: 现有3D场景推理任务中的问题过于简单，导致LLM生成的程序推理链较短，无法处理复杂的3D推理任务

Method: 在SQA3D基准上采用组合迭代进化方法生成复杂问题，通过直接偏好优化(DPO)微调LLM以优化工具链策略

Result: 增强了LLM在复杂3D场景中的工具使用能力，提高了复杂推理任务的准确性

Conclusion: 该方法有效解决了3D场景推理中问题复杂度不足的问题，显著提升了LLM在复杂3D推理任务中的表现

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [39] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 提出基于动力学系统理论的强化学习安全验证框架，利用有限时间李雅普诺夫指数识别拉格朗日相干结构，量化分析策略安全性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受限于缺乏验证策略鲁棒性和安全性的形式化方法，需要超越单纯奖励评估的全面安全分析框架

Method: 将RL智能体与环境建模为离散时间自治动力系统，运用有限时间李雅普诺夫指数识别拉格朗日相干结构，提出MBR、ASAS、TASAS等量化指标，并提供局部稳定性保证和模型不确定性处理方法

Result: 在离散和连续控制环境中验证了框架有效性，成功识别出仅基于奖励评估看似成功但存在关键缺陷的策略

Conclusion: 该框架为强化学习策略提供了全面可解释的安全评估，能够发现隐藏的安全漏洞，为安全关键应用中的RL部署提供了重要工具

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [40] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: Agentics是一个模块化框架，用于构建基于代理的系统，支持结构化推理和组合泛化，通过数据建模而非提示工程来实现逻辑转换。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统AI工作流中需要大量手工设计提示的问题，提供一个让开发者专注于数据建模而非提示工程的框架。

Method: 采用模块化框架设计，将代理从逻辑流中抽象出来，通过数据类型的逻辑转换实现组合，LLM在类型连接时执行逻辑转换。

Result: 在领域特定多选题回答、文本到SQL的语义解析和自动提示优化任务中实现了最先进准确性或改进的可扩展性。

Conclusion: Agentics框架为AI开发提供了新的数据建模方法，通过声明式语言和逻辑转换机制，在多个任务中展现出优异性能。

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [41] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 本文提出了Holographic Declarative Memory (HDM)，这是一种向量符号替代ACT-R的声明性记忆系统，具有可扩展性和架构定义的相似性优势，并成功将其适配到Lisp ACT-R中。


<details>
  <summary>Details</summary>
Motivation: 开发HDM的目的是为了替代ACT-R的声明性记忆系统，获得更好的可扩展性和向量符号优势，同时保持与现有ACT-R模型的兼容性。

Method: 将HDM适配到Lisp ACT-R中，开发了基于向量的常见ACT-R函数，建立了文本处理管道来添加大型文档内容，并创建了基于向量表示检索整个记忆块的机制。

Result: 初步结果表明，HDM能够保持向量符号优势（如无需存储实际块即可回忆），同时使之前的ACT-R模型只需很少修改就能在新系统上运行。

Conclusion: HDM成功实现了向量符号记忆系统与ACT-R的集成，未来将继续改进时间上下文表示，并开发基于实例学习的决策模型来进一步测试系统。

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [42] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 本文通过技术哲学视角分析欧盟AI法案，揭示了AI系统中数据的递归价值链动态，提出了基于Simondon哲学的形式化框架来理解AI生命周期，并针对监管盲点提出了具体政策建议。


<details>
  <summary>Details</summary>
Motivation: 现有AI监管框架未能充分理解AI系统中数据从摄入到部署的递归价值链动态，以及这种动态如何挑战负责任AI的现有框架，需要从技术哲学角度提供新的分析工具。

Method: 采用跨学科方法，引入基于Simondon技术哲学的概念工具，重新定义个体化概念来建模AI生命周期（前个体环境、个体化、个体化AI），并提出"未来性"概念描述AI自我强化的递归生命周期。

Result: 揭示了AI基础设施（如特征存储）如何通过反馈、适应和时间递归实现数据的非竞争性递归生成，突出了技术寡头在捕获、训练和部署基础设施中集中价值和决策权的权力不对称问题。

Conclusion: 有效监管必须解决这些基础设施和时间动态问题，建议实施生命周期审计、时间可追溯性、反馈问责制、递归透明度以及反对递归重用的权利等具体措施。

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [43] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT是一个结构化多模态基准测试，用于评估模型在指令跟随、视觉推理和视觉-文本对齐任务上的表现，通过程序生成的图表和合成渲染的表格提供精确的评估标准。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够系统评估多模态模型在视觉推理和结构化输出任务上表现的基准测试，需要一种能够控制数据语义、结构和清晰度的标准化评估框架。

Method: 使用Python可视化库程序化生成图表和合成渲染表格，每个实例包含图表/表格图像和基于视觉内容的多步骤分析问题，答案以JSON或YAML等结构化格式提供。

Result: 创建了一个包含比较、趋势识别、排名、聚合、比例估计和异常检测等多种推理类型的分类体系，为多模态模型提供细粒度的评估标准。

Conclusion: GRAFT为多模态模型在视觉基础结构化推理任务上提供了统一、可扩展的精细基准测试框架，为该领域设立了新的评估标准。

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [44] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL是一个Python库，可将Jax环境转换为在线界面，支持人机对比实验和多智能体研究，应用于类人AI、兼容AI和辅助AI三个案例。


<details>
  <summary>Details</summary>
Motivation: 为研究人员提供工具，将机器学习强化学习环境转化为在线人机实验平台，促进AI算法与人类表现的比较、认知科学理论测试以及人机协作算法开发。

Method: 开发Python库，支持将任何基于Jax的环境转换为在线界面，支持单智能体和多智能体环境，提供三个应用案例展示。

Result: 成功展示了NiceWebRL在三个案例中的应用：开发认知RL模型、多智能体RL算法泛化到人类伙伴、研究LLM辅助人类完成复杂任务。

Conclusion: NiceWebRL是一个有效的工具，能够帮助研究人员在多种环境中进行人机对比实验和人机协作研究，推动类人AI、兼容AI和辅助AI的发展。

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [45] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: 本文首次在生产环境中测量AI推理的环境影响，发现Gemini文本提示的中位数能耗为0.24Wh，远低于公开估计，并展示了谷歌通过软件效率和清洁能源实现的显著减排效果。


<details>
  <summary>Details</summary>
Motivation: 随着AI应用加速普及，需要理解和减轻AI服务对环境的影响，但目前缺乏生产环境中AI服务环境指标的测量研究。

Method: 提出并执行了全面的测量方法，包括AI加速器功耗、主机系统能耗、空闲机器容量和数据中心能耗开销的全栈测量，通过对谷歌Gemini AI助手基础设施的详细检测。

Result: Gemini Apps文本提示中位数能耗0.24Wh，比看电视9秒还低；用水量相当于5滴水(0.26mL)。谷歌的软件效率优化和清洁能源采购使能耗降低33倍，碳足迹减少44倍。

Conclusion: 虽然AI服务环境影响相对较低，但仍需持续关注。全面的环境指标测量对于准确比较模型性能和激励全栈效率提升至关重要。

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [46] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 通过重新调整最先进的语言模型，建立了一个简单的响应评估框架，能够实时评估对话中的假社交线索，以防止人工智能代理引发的假社交关系。


<details>
  <summary>Details</summary>
Motivation: 人们与AI代理形成假社交关系可能对人类健康造成严重甚至悲剧性影响，但防止这种动态具有挑战性，因为假社交线索通常在私密对话中渐进形成，而且不是所有情感参与都是有害的。

Method: 重新调整最先进的语言模型，创建了一个简单的响应评估框架，能够实时评估对话中的假社交线索。为测试该方法的可行性，构建了一个包含30个对话的合成数据集，涵盖假社交、奇娃和中性对话。通过五阶段迭代评估进行测试。

Result: 在宽松的一致性规则下，该方法成功识别了所有假社交对话，同时避免了假阻性，且检测通常在前几次交流中就可完成。

Conclusion: 这些发现为评估代理可以为防止假社交关系提供可行解决方案提供了预期证据。

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


### [47] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: LGT是一个基于多智能体大语言模型的配置优化框架，通过自然语言推理和文本梯度实现智能配置调优，在保持高可解释性的同时显著提升性能


<details>
  <summary>Details</summary>
Motivation: 传统配置优化方法存在维度独立处理、缺乏可解释性等问题，而现有自动化方法难以实现动态适应性和语义推理，需要新的智能优化框架

Method: 使用多智能体LLM架构：顾问Agent提出配置变更、评估Agent评估进展、优化Agent精化决策过程，结合文本梯度提供语义反馈信号

Result: 在六个不同数据集上的综合评估显示，LGT相比传统优化方法实现了显著性能提升

Conclusion: LGT框架通过语言引导的智能优化，成功解决了配置优化的关键瓶颈，在性能和可解释性方面都表现出色

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>


### [48] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 基于图信号处理的全谱神经符号推理架构，通过学习的谱滤波器控制多尺度信息传播，在多个推理数据集上实现了更好的逻辑一致性、可解释性和计算效率


<details>
  <summary>Details</summary>
Motivation: 传统的神经符号推理模型将谱图方法作为边缘组件，本文尝试将整个推理流程都在图谱域中形式化，以获得更健壁和可解释的推理系统

Method: 将逻辑实体和关系编码为图信号，通过学习的谱滤波器进行处理控制多尺度信息传播，然后映射到符号谓词进行规则推理，包括图弗里叶变换、带选择性注意力和谱规则基础

Result: 在ProofWriter、EntailmentBank、bAbI、CLUTRR和ARC-Challenge等标准推理数据集上，在逻辑一致性、可解释性和计算效率方面都超过了现有的最优神经符号模型

Conclusion: 图信号处理为健壁和可解释的推理系统提供了数学基础坚实且计算效率高的基础

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [49] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 提出了一个基于目标导向状态表示的计算框架，其中描述性和规范性世界模型方面从智能体-环境交互中共同涌现，而非传统强化学习中的分离状态表示和奖励函数。


<details>
  <summary>Details</summary>
Motivation: 传统计算模型（如强化学习）将世界模型分为描述性状态表示和规范性奖励函数，但本文探索这两种方面如何从智能体目标中相互依赖地共同涌现的可能性。

Method: 引入目标导向（telic）状态概念，定义为目标等价经验分布的类别，通过行为策略与期望经验特征之间的统计差异来提供目标导向学习的简约解释。

Result: 提出了一个统一的计算框架，能够解释行为、现象学和神经维度上的目的性行为，基于佛教认识论构建目标导向状态表示理论。

Conclusion: 该框架为跨不同基质的目的性行为提供了统一解释，挑战了传统世界模型的分离假设，强调描述性和规范性方面的共同涌现特性。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [50] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC是一个多智能体框架，使用三个LLM智能体从不同角度生成旅游推荐，通过非LLM仲裁者进行多轮协商，有效提升推荐多样性和平衡性。


<details>
  <summary>Details</summary>
Motivation: 解决旅游推荐系统中的流行度偏差问题，避免过度旅游，提升推荐多样性，让更多小众目的地得到关注。

Method: 使用三个基于LLM的智能体（个性化、流行度、可持续性）从互补角度生成城市建议，然后通过非LLM仲裁者进行多轮协商和精炼。

Result: 在欧洲城市查询实验中，相比单智能体基线，Collab-REC显著提升了推荐多样性和整体相关性，成功推荐了常被忽视的小众目的地。

Conclusion: 多利益相关者协作的LLM驱动推荐系统具有很大潜力，能够更好地处理用户约束，平衡推荐结果，解决过度旅游问题。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [51] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 使用大语言模型控制群体动画中的代理人运动，通过对话系统和语言驱动导航实现更现实的社交互动和群体行为


<details>
  <summary>Details</summary>
Motivation: 现有群体动画方法很少考虑语言和对话对人类导航行为的影响，交互主要限于转向和固定目标推断

Method: 方法包括对话系统和语言驱动导航两个主要组件，通过周期性查询代理中心的LLMs，根据角色人格、渴望、关系等条件生成对话，并结合视觉、情绪状态等控制导航

Result: 在复杂场景中验证方法有效，观察到代理人自动分组和解散，方法作为信息传递机制，产生了更现实的群体模拟和活现的群体行为

Conclusion: 该框架能够生成更现实的群体模拟，群体行为自然地从环境设置中活现出来

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [52] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 这篇论文研究发现，虽然近期的推理大语言模型在专家信心评估上达到48.7%的准确性，但增加推理资源反而会导致系统性过信任，减少检索增强生成则能达到89.3%的准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为问题回答工具需要健壮的检验检查以避免过信任，研究推理能力和计算资源如何影响信心评估的准确性。

Method: 使用ClimateX数据集并扩展到人类和地球健康领域，系统性评估推理能力和计算资源对信心评估准确性的影响，比较纯推理与检索增强生成的效果。

Result: 推理模型在专家信心评估上达到48.7%准确性，但增加推理资源导致系统性过信任，越长的思考资源越会加剧这种情况。检索增强生成显著超过纯推理，达到89.3%的准确性。

Conclusion: 信息获取能力而非推理深度或推理资源，可能是改善知识密集型任务信心检索检验的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [53] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: 在CogniSAT-6/HAMMER卫星上进行边缘数据分析和推理的实验展示，利用超谱仪器和神经网络加速硬件


<details>
  <summary>Details</summary>
Motivation: 通过在卫星上进行边缘数据分析，可以开启新的地球科学测量和响应能力

Method: 使用深度学习和谱分析算法，在配备可见光和近红外超谱仪器的卫星上进行数据分析和推理

Result: 将展示多种应用场景的边缘数据处理能力

Conclusion: 边缘计算在太空任务中具有重要价值，能够实现更加高效的地球观测和实时响应

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [54] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA是一个轻量级、无需数据、模型无关的框架，通过分析LoRA微调权重更新来缓解安全风险，在保持任务性能的同时显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法（如LoRA）在增强LLM智能体能力的同时，可能会无意中破坏安全对齐，导致不安全行为。现有安全感知适应方法通常需要访问基础模型和指令微调检查点，这在实践中往往不可用。

Method: 提出S3LoRA框架：1）引入MAS-SVD方法分析LoRA更新的结构特性；2）设计SSI指标检测具有高度集中和潜在不安全更新的层；3）对这些层进行后剪枝以减少风险。

Result: 在智能体规划和语言生成任务上的广泛实验表明，S3LoRA持续改善安全指标，同时保持或改进效用指标，并显著降低推理成本。

Conclusion: S3LoRA为在现实世界、资源受限和安全关键环境中安全部署基于LLM的智能体提供了一个实用且可扩展的解决方案。

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [55] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 将劳动力管理模型化为抽象论证问题，通过提供忠实解释来处理执行时变化，实验证该方法能提高问题解决的速度和准确性


<details>
  <summary>Details</summary>
Motivation: 劳动力管理中的主要挑战是在执行时处理变化并向所有相关方提供解释

Method: 将劳动力管理问题理解为抽象论证模型，并在工业应用中实现

Result: 通过用户研究验证，该工具和解释方法比传统手工方案更快速、更准确地解决问题

Conclusion: 采用抽象论证框架处理劳动力管理中的变化问题，能够提供忠实解释并提高效率

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [56] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 本文提出了一种基于信息论Shapley值的Intended Cooperation Values (ICVs)方法，用于在缺乏价值反馈的情况下量化多智能体系统中每个智能体对同伴的因果影响，从而分析合作动态和增强MARL系统的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有工作通常基于显式奖励信号或学习价值函数来评估团队整体性能，但在缺乏价值反馈的情况下难以推断个体智能体的贡献。需要一种仅通过分析策略分布就能提取有意义行为洞察的方法。

Method: 受智能体倾向于追求收敛工具价值现象启发，提出ICVs方法：基于信息论Shapley值量化每个智能体对同伴工具赋能的因果影响，通过评估决策不确定性和偏好对齐来衡量智能体行为对队友策略的影响。

Result: 在合作性和竞争性MARL环境中的分析揭示了智能体采用相似或多样化策略的程度。通过比较策略和价值函数之间的行为效果，该方法能够识别哪些智能体行为通过促进确定性决策或保持未来行动选择的灵活性来有益于团队成功。

Conclusion: ICVs方法为合作动态提供了新颖的洞察，增强了MARL系统的可解释性，能够在没有价值反馈的情况下有效分析个体智能体行为对团队成功的贡献。

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [57] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 提出了Open-Universe Assistance Games框架和GOOD方法，通过LLM模拟用户意图进行概率推理，在开放目标环境中实现高效的目标推断和不确定性估计


<details>
  <summary>Details</summary>
Motivation: 解决具身AI代理需要推断和响应未预定义的人类多样化目标和偏好的挑战，特别是在开放且不断演变的目标空间中

Method: GOOD方法：使用LLM模拟具有不同复杂意图的用户，通过对话提取自然语言目标，进行概率推理来推断目标分布

Result: 在基于文本的杂货购物领域和AI2Thor模拟家庭机器人环境中评估，使用合成用户配置文件，GOOD方法在LLM和人类评估中均优于无显式目标跟踪的基线

Conclusion: GOOD方法能够实现丰富的目标表示和不确定性估计，无需大型离线数据集，在开放宇宙辅助游戏中有效解决了目标推理问题

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [58] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: 提出了aiXiv平台，这是一个面向人类和AI科学家的下一代开放获取平台，通过多智能体架构实现研究提案和论文的提交、评审和迭代改进，解决AI生成研究内容缺乏合适发表渠道的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成的大量高质量研究内容缺乏合适的发表渠道，传统期刊依赖人工同行评审难以扩展且不愿接受AI生成内容，现有预印本服务器缺乏严格质量控制机制。

Method: 设计多智能体架构平台，提供API和MCP接口，实现人类和AI科学家的无缝集成，支持研究提案和论文的提交、评审和迭代改进。

Result: 通过广泛实验证明aiXiv是一个可靠且稳健的平台，经过迭代修订和评审后显著提高了AI生成研究提案和论文的质量。

Conclusion: 为AI科学家建立了下一代开放获取生态系统的基础，加速了高质量AI生成研究内容的发表和传播。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [59] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: GUI-Owl是一个基础GUI代理模型，在10个GUI基准测试中达到开源端到端模型的最先进性能，Mobile-Agent-v3框架进一步提升了性能表现


<details>
  <summary>Details</summary>
Motivation: 为了解决GUI代理在桌面和移动环境中需要处理多样化任务（包括定位、问答、规划、决策和程序知识）的挑战，需要开发一个高性能的基础模型和框架

Method: 提出了三个关键创新：1）大规模环境基础设施和自演化GUI轨迹生产框架；2）集成UI定位、规划、动作语义和推理模式的多样化基础代理能力；3）可扩展的环境强化学习框架和轨迹感知相对策略优化

Result: GUI-Owl-7B在AndroidWorld上达到66.4分，在OSWorld上达到29.4分；Mobile-Agent-v3进一步提升到AndroidWorld 73.3分和OSWorld 37.7分，创下开源GUI代理框架的新记录

Conclusion: GUI-Owl和Mobile-Agent-v3为GUI代理领域提供了强大的基础模型和框架，通过自演化数据生成、多样化能力集成和可扩展强化学习实现了显著的性能提升

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [60] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: PuzzleClone是一个基于SMT的形式化框架，用于大规模合成可验证的数学逻辑谜题数据，通过编码种子谜题、系统化变量约束随机化和验证机制，构建了83K+多样化验证数据集，显著提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的数学逻辑数据集存在可靠性、多样性和可扩展性有限的问题，需要高质量可验证的数据来增强大语言模型的推理能力。

Method: 使用可满足性模理论(SMT)框架，将种子谜题编码为结构化逻辑规范，通过系统化变量和约束随机化生成可扩展变体，并通过复制机制确保有效性。

Result: 构建了包含83K+多样化程序验证谜题的基准测试集，在PuzzleClone测试集上平均准确率从14.4提升到56.2，在7个逻辑数学基准测试上获得最高12.5个百分点的绝对提升。

Conclusion: PuzzleClone框架能够有效生成大规模高质量可验证的数学逻辑数据，显著提升LLM的推理性能，为解决现有数据集的局限性提供了有效方案。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [61] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat是一个专门针对罕见病多汗症的LLM框架，通过数据增强、微调和专家评估三阶段流程，为多汗症提供可信赖和富有同理心的诊断、治疗建议和心理支持。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域的应用受到罕见病数据稀缺和不可靠的限制。多汗症影响2-3%人口，但缺乏专门的LLM支持系统。

Method: 三阶段流程：1)使用前沿LLM生成医学上合理的合成数据增强数据集；2)在开源基础模型上进行微调；3)临床和心理学专家评估准确性、适当性和同理心，并通过验证响应迭代丰富数据集。

Result: LLM4Sweat在实验中优于基线模型，成为首个针对多汗症的开源LLM框架，为其他具有类似数据挑战的罕见病提供了可推广的方法。

Conclusion: 该研究成功开发了一个专门针对多汗症的LLM框架，解决了罕见病数据稀缺问题，并通过专家验证确保了输出的可信度和同理心，为其他罕见病的LLM应用提供了可行方案。

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [62] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: R-ConstraintBench是一个评估大语言模型在资源约束项目调度问题中推理能力的框架，通过逐步增加约束复杂度来测试模型性能，发现约束交互是主要瓶颈而非图深度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在高度约束环境下的推理可靠性尚未充分研究，特别是在资源约束项目调度这类NP完全问题中。

Method: 开发R-ConstraintBench框架，在DAG中逐步增加非冗余前序约束，然后引入停机时间、时间窗口和析取约束，并在数据中心迁移场景中实例化评估。

Result: 强模型在仅有前序约束的DAG上表现接近天花板，但当多种约束交互时可行性性能崩溃，约束交互是主要瓶颈，且合成数据性能不能保证领域场景的泛化。

Conclusion: 大语言模型在复杂约束交互下的推理能力有限，约束交互而非图深度是主要挑战，需要改进模型在真实约束环境中的泛化能力。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [63] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 提出了一种名为"See it. Say it. Sorted."的训练免费代理系统，通过结合视觉语言模型和大型语言模型，将手绘草图转换为可编辑的SVG矢量图程序，在流程图生成任务上优于GPT-5和Gemini-2.5-Pro。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在照片级真实感方面表现出色，但在流程图等需要空间精度、对齐和符号结构精确性的任务中存在困难，需要开发能够生成精确可编辑矢量图的解决方案。

Method: 采用训练免费的代理系统，结合VLM和LLM，运行迭代循环：批评家VLM提出定性关系编辑建议，多个候选LLM以不同策略合成SVG更新，法官VLM选择最佳候选，确保稳定改进。

Result: 在10个源自已发表论文流程图的草图测试中，该方法比GPT-5和Gemini-2.5-Pro更忠实地重建布局和结构，准确组合图元（如多箭头）且不插入不需要的文本。

Conclusion: 该方法优先考虑定性推理而非脆弱的数值估计，保持全局约束（如对齐、连接性），自然支持人机协同修正，且由于输出是程序化SVG，可通过API轻松扩展到演示工具。

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [64] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 本文提出新颖的计算智能方法优化混合用途区域土地利用分配，开发了多种优化算法，包括结合差分进化和多目标遗传算法的定制变体，在真实案例中实现了土地利用兼容性3.16%和经济优化3.3%的改进。


<details>
  <summary>Details</summary>
Motivation: 解决土地利用分配中土地利用兼容性与经济目标之间的固有权衡问题，为可持续城市发展政策提供支持。

Method: 开发多种优化算法，包括CR+DES算法（利用缩放差分向量增强探索）、系统约束松弛策略，并使用Kruskal-Wallis检验进行统计验证。

Result: 在1,290个地块的真实案例中，CR+DES算法在土地利用兼容性方面比现有方法提升3.16%，MSBX+MO算法在价格优化方面提升3.3%。统计分析证实采用差分向量的算法在多指标上显著优于传统方法。

Conclusion: 这些发现为城市规划者和政策制定者提供了基于证据的计算工具，用于平衡土地利用分配中的竞争目标，支持快速城市化地区更有效的城市发展政策。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [65] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: 基于认知心理学理论的多重记忆系统(MMS)，通过将短期记忆处理成多个长期记忆片段，构建检索记忆单元和上下文记忆单元，提升了记忆质量和回忆性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆模块方法如MemoryBank和A-MEM存储的记忆内容质量差，影响回忆性能和响应质量，需要更好处理大量历史交互数据。

Method: 设计受认知心理学启发的多重记忆系统(MMS)，将短期记忆处理成多个长期记忆片段，构建检索记忆单元和上下文记忆单元，两者一一对应。在检索阶段匹配最相关的检索记忆单元，获取对应的上下文记忆作为响应上下文。

Result: 在LoCoMo数据集上的实验证明了方法的有效性，消融实验确认了记忆单元的合理性，分析了选择记忆段数量的稳健性和存储开销，显示了其实际价值。

Conclusion: MMS系统能够构建高质量的长期记忆内容，有效利用历史数据，提升了记忆质量和回忆性能，具有实际应用价值。

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [66] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: 提出了Coarse-to-Fine Grounded Memory框架，通过粗粒度到细粒度的记忆机制增强LLM在复杂规划任务中的适应能力


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆机制的LLM智能体主要依赖单一粒度的动态环境交互记忆，受限于经验收集质量，限制了知识多样性和规划灵活性

Method: 提出粗粒度到细粒度的记忆框架：1) 在训练任务中将环境信息转化为粗粒度关注点指导经验收集；2) 从每个经验中提取可操作的混合粒度提示；3) 推理时检索任务相关经验和提示；4) 面对环境异常时进行细粒度关键信息提取和自问答反思

Result: 该方法能够充分利用记忆进行灵活的场景适应，支持规划过程中的自我修正

Conclusion: Coarse-to-Fine Grounded Memory框架通过多粒度记忆机制有效提升了LLM智能体在复杂规划任务中的适应性和灵活性

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [67] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: 提出SPW方案统一专家演示和偏好两种人类反馈，通过相似度搜索为偏好轨迹中的转移分配重要性权重，改善信用分配问题，在机器人操作任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 离线强化学习通常依赖精心设计的奖励函数，但设计成本高。人类反馈是替代方案，但专家演示成本高且行为模式有限，偏好反馈易收集但信用分配不明确

Method: SPW方案为偏好标记轨迹中的每个转移，从专家演示中搜索最相似的状态-动作对，基于相似度得分直接推导逐步重要性权重，指导标准偏好学习

Result: SPW实现了从偏好和演示的有效联合学习，在具有挑战性的机器人操作任务上优于利用两种反馈类型的现有方法

Conclusion: SPW方案成功解决了人类反馈中信用分配的关键问题，为离线强化学习提供了一种更有效的多源反馈融合方法

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [68] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 本文提出了RETAIL数据集和TGMA多智能体框架来解决现实旅行规划中的三大挑战：隐性查询处理、环境因素整合和详细POI安排，显著提升了规划成功率。


<details>
  <summary>Details</summary>
Motivation: 当前旅行规划系统存在三个主要问题：1）假设用户提供显式查询，而现实中需求往往是隐性的；2）忽略环境因素和用户偏好，导致计划不可行；3）只能生成基本的POI安排，无法提供包含丰富细节的一体化计划。

Method: 构建了RETAIL数据集支持显性和隐性查询决策，并具备环境感知能力。提出了主题引导的多智能体框架TGMA来处理复杂的旅行规划任务。

Result: 实验显示现有最强模型仅达到1.0%的通过率，而TGMA框架实现了2.72%的性能提升，表明在现实旅行规划任务上取得了显著改进。

Conclusion: 现实世界的旅行规划仍然极具挑战性，但TGMA框架提供了有希望的方向，通过处理隐性查询、环境因素和详细POI信息来提升规划质量。

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [69] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG是一个将12导联心电图信号与语言模型结合的框架，通过离散化ECG嵌入为符号标记，使大语言模型能够处理ECG信号并生成临床文本，在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有自动化心电图分析方法在跨临床任务泛化能力和开放式推理方面存在局限，需要一种能够统一处理ECG信号和自然语言的集成方法。

Method: 使用导联无关编码器和量化模块将连续ECG嵌入离散化为符号标记，扩展LLM词汇表；通过自回归ECG预测任务进行预训练，最后在ECG问答和诊断报告生成任务上进行指令微调。

Result: DiagECG在不修改核心模型的情况下，在多项任务中取得了强劲性能，并保持了在分布外设置下的泛化能力。

Conclusion: 该研究表明将符号化ECG表示集成到LLM中具有巨大潜力，为医疗推理提供了新的有效方法。

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [70] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 本文提出了计划干扰的概念，旨在寻找最小化初始状态修改来实现目标的计划，并通过多种规划编译方法联合优化行动成本和计划干扰。


<details>
  <summary>Details</summary>
Motivation: 在许多规划应用中，需要找到既能实现目标又最小化对初始状态修改的计划，这种计划干扰最小化的需求在现实应用中很重要。

Method: 正式引入计划干扰概念，定义多种基于规划的编译方法，联合优化行动成本总和和计划干扰两个目标。

Result: 在不同基准测试中的实验结果表明，重新表述的任务能够有效解决，生成平衡两个目标的计划。

Conclusion: 提出的方法能够实际有效地生成平衡行动成本和计划干扰的计划，为规划应用提供了实用的解决方案。

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [71] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 提出了一个综合的合成数据生成框架，用于大规模生成高质量对话数据，支持SFT和DPO训练，通过模块化流水线和双重质量标注机制确保数据质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的发展严重依赖高质量数据集，但现有数据准备过程耗时且成本高，需要自动化、可扩展的解决方案来生成合成对话数据。

Method: 采用模块化配置流水线，使用启发式规则和LLM评估的双阶段质量标注机制，从OASST格式对话中自动筛选和评分数据。

Result: 开发出支持SFT和DPO用例的灵活数据结构，能够大规模生成高质量对话样本，显著减少数据准备开销。

Conclusion: 该框架为LLM训练提供了强大的合成对话数据生成和管理解决方案，实现了可扩展、可配置的高保真数据生成。

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [72] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent是一个基于大语言模型的多智能体框架，通过整合连续时间马尔可夫决策过程、广义熵度量和Stackelberg博弈，显著提升了企业决策支持系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在企业决策支持应用中难以协调复杂的运营分析与战略目标，导致工作流程碎片化和组织协作效率低下。

Method: 提出BusiAgent框架，包含三个核心创新：扩展的连续时间马尔可夫决策过程用于动态智能体建模、广义熵度量优化协作效率、多级Stackelberg博弈处理分层决策过程，并采用上下文Thompson采样进行提示优化。

Result: 在多样化商业场景中的实证评估表明，BusiAgent能够生成连贯的、以客户为中心的解决方案，显著优于现有方法，在解决方案质量和用户满意度方面都有出色表现。

Conclusion: BusiAgent通过融合前沿AI技术和深度商业洞察，在AI驱动的企业决策制定方面迈出了重要一步，使组织能够更有效地应对复杂的商业环境。

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [73] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: 提出了Think in Blocks框架，通过将推理过程划分为可调数量的块，使LLM能够根据任务复杂度动态调整推理长度，避免过度思考。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的思维链方法在处理复杂逻辑推理时表现良好，但过长的推理链会导致过度思考、计算浪费和响应变慢，需要动态调整推理深度。

Method: 建立显式的块结构范式：先预测推理预算（块数），然后相应划分推理；通过三阶段训练流程（监督微调、奖励引导的DPO、强化学习）训练自适应模型；利用显式块计数在推理时动态控制推理深度。

Result: 论文提出了一个能够根据问题难度自适应调整推理深度的框架，实现了从零推理到深度推理的灵活调节。

Conclusion: Think in Blocks框架有效解决了LLM过度思考问题，通过块结构化和自适应训练，实现了推理长度的动态控制，提高了计算效率和响应速度。

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [74] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 研究发现语言模型代理在囚徒困境游戏中，通过团队内部重复互动和团队间竞争的结合，能够显著提升合作水平，包括一次性互动的初始合作倾向。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理的发展，研究其合作行为倾向变得越来越重要。受超加性合作理论启发，探索重复互动和群体间竞争如何影响AI代理的合作行为。

Method: 设计虚拟锦标赛，将语言模型代理分组为团队，在囚徒困境游戏中相互对抗。模拟团队内部动态和外部竞争环境。

Result: 发现内部团队动态和外部竞争的结合显著提升了总体合作水平和一次性互动的初始合作倾向。

Conclusion: 研究为语言模型在复杂社会场景中制定策略提供了新框架，证明群体间竞争可以反直觉地导致更多合作行为，对设计未来多代理AI系统具有重要意义。

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [75] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: DeepThink3D通过组合迭代进化方法生成复杂3D问题，并使用DPO优化LLM的工具链策略，提升在复杂3D场景推理中的工具使用能力


<details>
  <summary>Details</summary>
Motivation: 现有3D场景推理任务中的问题过于简单，导致LLM生成的程序推理链较短，无法处理复杂的3D推理任务

Method: 1. 在SQA3D基准上采用组合迭代进化方法生成更复杂的问题 2. 使用直接偏好优化(DPO)技术微调大语言模型，直接优化工具链策略

Result: 提升了大型语言模型在复杂3D场景推理任务中的工具使用准确性和能力

Conclusion: DeepThink3D方法有效增强了LLM在复杂3D推理任务中的表现，通过问题复杂化和策略优化解决了现有方法的局限性

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [76] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 提出基于动力系统理论和有限时间李雅普诺夫指数的框架，将RL智能体与环境作为离散时间自治动力系统分析，识别拉格朗日相干结构作为安全屏障，并引入定量指标评估策略安全性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受到缺乏形式化验证方法的限制，需要开发能够正式验证学习策略鲁棒性和安全性的框架。

Method: 将RL智能体与环境建模为离散时间自治动力系统，利用有限时间李雅普诺夫指数识别拉格朗日相干结构，引入MBR、ASAS、TASAS等定量指标，并提供局部稳定性保证和模型不确定性处理方法。

Result: 在离散和连续控制环境中验证了框架的有效性，能够全面可解释地评估策略行为，成功识别仅基于奖励看似成功但存在关键缺陷的策略。

Conclusion: 该框架为强化学习策略提供了形式化的安全性和鲁棒性评估方法，超越了传统的定性可视化分析，具有重要的理论和实践价值。

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [77] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: Agentics是一个模块化框架，用于构建基于代理的系统，支持结构化推理和组合泛化，通过数据建模而非提示工程来实现声明式AI工作流。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统AI工作流中需要大量手工设计提示的问题，提供一个更专注于数据建模而非提示工程的框架，使开发者能够通过声明式语言构建复杂的AI系统。

Method: 采用模块化代理框架，将代理从逻辑流中抽象出来，在数据类型内部使用代理实现逻辑转换，通过LLM提供数据类型并通过逻辑转换进行组合。

Result: 在领域特定多选题回答、文本到SQL的语义解析和自动提示优化任务中实现了最先进的准确性或改进的可扩展性，且不牺牲性能。

Conclusion: Agentics框架为构建基于代理的AI系统提供了新的方法，通过数据建模和声明式编程简化了复杂AI工作流的开发，具有广泛的应用前景。

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [78] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: HDM是ACT-R声明性记忆系统的向量符号替代方案，具有可扩展性和架构定义的相似性优势。研究将HDM适配到Lisp ACT-R，使现有模型无需重大修改即可运行，并开发了基于向量的检索机制。


<details>
  <summary>Details</summary>
Motivation: 为ACT-R的声明性记忆系统提供向量符号替代方案，以获得更好的可扩展性和相似性处理能力，同时保持与现有模型的兼容性。

Method: 将HDM适配到Lisp ACT-R，开发基于向量的常见ACT-R函数版本，建立文本处理管道，创建基于向量表示的完整记忆块检索机制。

Result: 初步结果表明，HDM在保持向量符号优势（如无需存储实际块即可召回）的同时，能够与现有ACT-R模型兼容，只需很少或无需修改。

Conclusion: HDM成功实现了与ACT-R的集成，为实例学习理论等应用提供了有用基础，未来将改进时间上下文表示并开发决策模型进行更全面测试。

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [79] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 本文通过技术哲学视角分析欧盟AI法案，揭示AI数据生命周期中的递归价值链如何挑战现有负责任AI框架，提出基于Simondon哲学的形式化分析方法和监管建议


<details>
  <summary>Details</summary>
Motivation: 现有AI监管框架未能充分理解AI系统中数据的动态生命周期和递归价值生成机制，需要从技术哲学角度分析AI管道的动态特性

Method: 采用跨学科方法，引入Simondon技术哲学中的个体化概念来建模AI生命周期，提出"未来性"概念描述AI自我强化的递归特性

Result: 揭示了AI基础设施如何通过数据捕获、训练和部署集中价值和决策权，导致权力不对称加剧，识别了监管盲点

Conclusion: 有效监管需要解决基础设施和时间动态问题，建议实施生命周期审计、时间可追溯性、反馈问责、递归透明度和反对递归重用的权利等措施

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [80] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT是一个结构化多模态基准测试，用于评估模型在指令跟随、视觉推理和视觉-文本对齐任务上的表现，通过程序化生成的图表和表格提供精确的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态评估基准在视觉推理和结构化输出方面缺乏精确控制，需要一种能够系统评估模型在视觉基础结构化推理任务上表现的统一框架。

Method: 使用Python可视化库程序化生成图表和表格，确保对数据语义、结构和清晰度的控制。每个实例包含图表/表格图像和基于视觉内容的多步骤分析问题，答案以JSON或YAML等结构化格式提供。

Result: 创建了一个包含比较、趋势识别、排序、聚合、比例估计和异常检测等多种推理类型的分类法，支持对多模态模型的全面评估。

Conclusion: GRAFT为视觉基础结构化推理任务提供了一个统一、可扩展的细粒度基准测试框架，为该领域设立了新的评估标准。

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [81] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL是一个Python库，可将Jax环境转换为在线界面，支持人机交互实验，用于比较AI算法与人类表现、测试认知理论和开发人机协作算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI研究中缺乏便捷工具来进行在线人类被试实验的问题，使研究人员能够将强化学习环境转化为网络界面，便于进行人机性能比较和协作研究。

Method: 开发Python库，支持将任何基于Jax的环境转换为在线界面，支持单智能体和多智能体环境，提供网络实验平台。

Result: 通过三个案例研究展示了NiceWebRL的潜力：开发认知RL模型、多智能体RL算法泛化到人类伙伴、研究LLM辅助人类完成复杂任务。

Conclusion: NiceWebRL是一个有效的工具，能够促进人类类似AI、人类兼容AI和人类辅助AI的研究发展，代码已在GitHub开源。

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [82] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: 本文首次在真实生产环境中测量AI推理服务的环境影响，发现Gemini文本提示的中位数能耗为0.24Wh，远低于公开估计，并展示了Google通过软件效率和清洁能源实现的显著减排效果


<details>
  <summary>Details</summary>
Motivation: 随着AI应用加速普及，需要理解和减轻AI服务的环境影响，但目前缺乏在生产环境中测量AI服务环境指标的研究

Method: 提出并执行全面的测量方法，包括AI加速器功耗、主机系统能耗、闲置机器容量和数据中心能耗开销，通过对Google Gemini AI助手基础设施的详细检测

Result: Gemini Apps文本提示中位数能耗0.24Wh，比看电视9秒还少；用水量相当于5滴水(0.26mL)。Google的软件效率提升和清洁能源采购使能耗降低33倍，碳足迹减少44倍

Conclusion: 虽然AI服务环境影响相对较低，但仍需持续关注。全面的环境指标测量对于准确比较模型和在完整AI服务栈中激励效率提升至关重要

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [83] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 使用语言模型构建实时评估框架，可在私密对话中早期检测出偏社交关系线索，以防止AI代理对人类健康的负面影响。


<details>
  <summary>Details</summary>
Motivation: 偏社交关系与AI代理的发展对人类健康造成严重危害，但防止此类动态面临挑战，因为偏社交线索逐渐出现且非所有情感交流都有害。

Method: 重新利用最先进的语言模型构建简单的响应评估框架，实时评估进行中对话的偏社交线索。使用30个涵盖偏社交、婚婪和中性对话的合成数据集进行测试。

Result: 在宽松一致性规则下，迭代评估成功识别所有偏社交对话且避免了误报，检测通常在前几次交流中完成。

Conclusion: 评估代理可以为预防偏社交关系提供可行的解决方案，这些发现为该方法提供了初步证据。

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


### [84] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: LGT是一个基于多智能体大语言模型的配置优化框架，通过自然语言推理和文本梯度反馈来协调优化机器学习配置，在保持高可解释性的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习配置优化存在关键瓶颈，传统方法缺乏可解释性且处理维度独立，自动化方法难以动态适应和语义推理。

Method: 使用多智能体LLM框架：顾问提出配置变更，评估器评估进度，优化器精化决策过程，形成自改进反馈循环，并应用文本梯度提供语义理解。

Result: 在六个不同数据集上的综合评估显示，LGT相比传统优化方法有显著改进，在保持高可解释性的同时实现了性能提升。

Conclusion: LGT框架通过语言引导的智能体协作和文本梯度反馈，有效解决了机器学习配置优化的关键挑战，提供了可解释且高性能的优化方案。

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [85] [Integrated Sensing, Communication, and Computation for Over-the-Air Federated Edge Learning](https://arxiv.org/abs/2508.15185)
*Dingzhu Wen,Sijing Xie,Xiaowen Cao,Yuanhao Cui,Jie Xu,Yuanming Shi,Shuguang Cui*

Main category: cs.IT

TL;DR: 本文研究了一个集成感知、通信和计算的空中联邦边缘学习系统，分析了无线感知噪声和空中计算失真对收敛性能的影响，并提出了一种低复杂度算法来协调批处理大小控制和资源分配。


<details>
  <summary>Details</summary>
Motivation: 研究集成感知、通信和计算(ISCC)的空中联邦边缘学习系统，解决无线感知噪声和空中计算失真对机器学习模型训练收敛性能的影响问题。

Method: 采用空中计算(AirComp)实现一次性模型聚合，分析损失函数退化收敛行为，设计ISCC参数优化算法，交替优化批处理大小控制和网络资源分配。

Result: 理论分析表明感知、通信和计算竞争网络资源共同决定收敛速率。数值实验验证了理论分析，显示所提算法能有效协调批处理大小控制和资源分配以提升学习性能。

Conclusion: 对于每个设备，当获得更大批次数据样本时应消耗更少的感知功率，反之亦然。在给定批处理大小下，最优计算速度是满足延迟约束的最小速度。

Abstract: This paper studies an over-the-air federated edge learning (Air-FEEL) system
with integrated sensing, communication, and computation (ISCC), in which one
edge server coordinates multiple edge devices to wirelessly sense the objects
and use the sensing data to collaboratively train a machine learning model for
recognition tasks. In this system, over-the-air computation (AirComp) is
employed to enable one-shot model aggregation from edge devices. Under this
setup, we analyze the convergence behavior of the ISCC-enabled Air-FEEL in
terms of the loss function degradation, by particularly taking into account the
wireless sensing noise during the training data acquisition and the AirComp
distortions during the over-the-air model aggregation. The result theoretically
shows that sensing, communication, and computation compete for network
resources to jointly decide the convergence rate. Based on the analysis, we
design the ISCC parameters under the target of maximizing the loss function
degradation while ensuring the latency and energy budgets in each round. The
challenge lies on the tightly coupled processes of sensing, communication, and
computation among different devices. To tackle the challenge, we derive a
low-complexity ISCC algorithm by alternately optimizing the batch size control
and the network resource allocation. It is found that for each device, less
sensing power should be consumed if a larger batch of data samples is obtained
and vice versa. Besides, with a given batch size, the optimal computation speed
of one device is the minimum one that satisfies the latency constraint.
Numerical results based on a human motion recognition task verify the
theoretical convergence analysis and show that the proposed ISCC algorithm well
coordinates the batch size control and resource allocation among sensing,
communication, and computation to enhance the learning performance.

</details>


### [86] [Way to Build Native AI-driven 6G Air Interface: Principles, Roadmap, and Outlook](https://arxiv.org/abs/2508.15277)
*Ping Zhang,Kai Niu,Yiming Liu,Zijian Liang,Nan Ma,Xiaodong Xu,Wenjun Xu,Mengying Sun,Yinqiu Liu,Xiaoyun Wang,Ruichen Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于压缩和适应性两大核心特性的本地AI驱动的6G空口接口架构，通过语义通信技术实现更高效的数据传输。


<details>
  <summary>Details</summary>
Motivation: 人工智能需要在6G网络的整个生命周期中发挥基础能力作用，特别是在空口接口层面对传统的符号级准确性传输方式进行重构。

Method: 构建基于压缩和适应性两大核心特性的本地AI驱动空口接口架构：压缩特性让系统理解和提取源数据的核心语义信息；适应性特性允许系统在多样任务、数据类型和信道条件下动态传输语义信息。

Result: 论文通过在6G非地面网络中的语义通信案例研究验证了该架构的可行性，实现了更高效的数据传输和更好的适应能力。

Conclusion: 本地AI驱动的6G空口接口代表了未来通信技术的发展方向，但仍面临着重要的技术挑战和研究机遇，需要进一步深入研究。

Abstract: Artificial intelligence (AI) is expected to serve as a foundational
capability across the entire lifecycle of 6G networks, spanning design,
deployment, and operation. This article proposes a native AI-driven air
interface architecture built around two core characteristics: compression and
adaptation. On one hand, compression enables the system to understand and
extract essential semantic information from the source data, focusing on task
relevance rather than symbol-level accuracy. On the other hand, adaptation
allows the air interface to dynamically transmit semantic information across
diverse tasks, data types, and channel conditions, ensuring scalability and
robustness. This article first introduces the native AI-driven air interface
architecture, then discusses representative enabling methodologies, followed by
a case study on semantic communication in 6G non-terrestrial networks. Finally,
it presents a forward-looking discussion on the future of native AI in 6G,
outlining key challenges and research opportunities.

</details>


### [87] [Some Optimal and Near Optimal Doppler Resilient Complementary Sequence Sets](https://arxiv.org/abs/2508.15325)
*Bingsheng Shen,Zhengchun Zhou,Yang Yang,Pingzhi Fan*

Main category: cs.IT

TL;DR: 基于OC-FHSSs、ADSs等结构提出新的多普勒弹性互补序列集构造方法，获得最优或接近最优性能


<details>
  <summary>Details</summary>
Motivation: 具有优异模糊函数的序列在雷达检测和现代移动通信中非常有用，多普勒弹性互补序列(DRCS)能够通过子序列模糊函数求和实现更低的旁瓣

Method: 利用单碰撞跳频序列集(OC-FHSSs)、几乎差集(ADSs)以及一些特定序列来构造新的DRCS集

Result: 所提出的DRCS集达到最优或接近最优性能

Conclusion: 基于OC-FHSSs和ADSs等结构的新构造方法能够产生性能优异的多普勒弹性互补序列集

Abstract: Sequences with excellent ambiguity functions are very useful in radar
detection and modern mobile communications. Doppler resilient complementary
sequence (DRCS) is a new type of sequence proposed recently, which can achieve
lower ambiguity function sidelobes by summing the ambiguity functions of
subsequences. In this paper, we introduce some new constructions of DRCS sets
(DRCSSs) based on one-coincidence frequency-hopping sequence sets (OC-FHSSs),
almost difference sets (ADSs), some specific sequences, etc. Critically, the
proposed DRCSSs are optimal or near optimal.

</details>


### [88] [High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering](https://arxiv.org/abs/2508.15639)
*Eito Kurihara,Hideki Ochiai*

Main category: cs.IT

TL;DR: 提出基于非等概率非均匀星座和削波滤波的高容量低PAPR OFDM系统，通过截断高斯分布生成星座，优化星座设计降低复杂度，结合削波噪声消除技术实现低PAPR和高频谱效率


<details>
  <summary>Details</summary>
Motivation: 解决OFDM系统高峰均功率比(PAPR)问题，同时保持高容量和高频谱效率，通过星座设计和信号处理技术来平衡PAPR和系统性能

Method: 使用截断高斯分布生成非等概率非均匀星座，结合削波滤波(CAF)降低PAPR，在接收端采用削波噪声消除(CNC)技术，基于一维PAM设计降低解映射复杂度

Result: 仿真结果表明，所提系统在AWGN和频率选择性瑞利衰落信道下同时实现低PAPR和高频谱效率，在衰落信道中显著优于单载波对应系统

Conclusion: 星座整形与CAF和CNC技术的结合为BICM-OFDM系统提供了一种有效的低PAPR高容量解决方案，在衰落信道中表现出优越性能

Abstract: We address a design of high-capacity and low-peak-to-average power ratio
(PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on
bit-interleaved coded modulation (BICM) utilizing non-equiprobable and
non-uniform (NENU) constellations as well as clipping and filtering (CAF). The
proposed constellations are generated using a truncated Gaussian distribution,
and the merging of constellation points, where the former creates a non-uniform
constellation (NUC), and the latter decreases the number of signal points
without compromising the achievable bit-wise mutual information (BMI). Since
the proposed constellations are uniquely determined by only the two parameters,
each associated with NUC and cardinality, the complexity required for the
numerical optimization process can be significantly low. We focus on the
constellation design based on one dimension, i.e., pulse amplitude modulation
(PAM), which facilitates the reduction of demapping complexity for the BICM
receiver. The use of CAF at the transmitter can efficiently reduce the PAPR of
OFDM signals; however, it introduces clipping noise that may degrade error rate
performance, making the application of clipping noise cancellation (CNC) at the
receiver essential. Therefore, we optimize the NENU constellations in the
presence of CAF and CNC. Simulation results demonstrate that the combination of
constellation shaping with CAF and CNC enables BICM-OFDM systems to
simultaneously achieve low PAPR and high spectral efficiency over additive
white Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading
channels. Furthermore, comparative studies confirm that the proposed system
significantly outperforms the single-carrier counterpart (i.e., DFT-precoded
BICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading
channels.

</details>


### [89] [Integrated Sensing, Communication, and Computation for Over-the-Air Federated Edge Learning](https://arxiv.org/abs/2508.15185)
*Dingzhu Wen,Sijing Xie,Xiaowen Cao,Yuanhao Cui,Jie Xu,Yuanming Shi,Shuguang Cui*

Main category: cs.IT

TL;DR: 本文研究了一个集成感知、通信和计算的空中联邦边缘学习系统(Air-FEEL)，分析了无线感知噪声和空中计算失真对收敛性的影响，并提出了一种低复杂度的ISCC算法来优化批处理大小控制和资源分配。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和边缘计算的发展，需要设计能够同时处理感知、通信和计算的集成系统。现有的联邦学习系统往往忽略了感知数据采集过程中的噪声问题，以及空中计算带来的模型聚合失真，这影响了学习性能。

Method: 采用空中计算(AirComp)技术实现单次模型聚合，理论分析ISCC-enabled Air-FEEL系统的收敛行为，考虑无线感知噪声和AirComp失真。设计交替优化批处理大小控制和网络资源分配的低复杂度ISCC算法。

Result: 理论分析表明感知、通信和计算竞争网络资源共同决定收敛速率。数值实验基于人体动作识别任务验证了理论分析，显示所提算法能有效协调感知、通信和计算之间的批处理大小控制和资源分配。

Conclusion: 研究发现设备在获得更大批次数据样本时应消耗更少的感知功率，反之亦然。在给定批处理大小下，最优计算速度是满足延迟约束的最小值。所提ISCC算法能显著提升学习性能。

Abstract: This paper studies an over-the-air federated edge learning (Air-FEEL) system
with integrated sensing, communication, and computation (ISCC), in which one
edge server coordinates multiple edge devices to wirelessly sense the objects
and use the sensing data to collaboratively train a machine learning model for
recognition tasks. In this system, over-the-air computation (AirComp) is
employed to enable one-shot model aggregation from edge devices. Under this
setup, we analyze the convergence behavior of the ISCC-enabled Air-FEEL in
terms of the loss function degradation, by particularly taking into account the
wireless sensing noise during the training data acquisition and the AirComp
distortions during the over-the-air model aggregation. The result theoretically
shows that sensing, communication, and computation compete for network
resources to jointly decide the convergence rate. Based on the analysis, we
design the ISCC parameters under the target of maximizing the loss function
degradation while ensuring the latency and energy budgets in each round. The
challenge lies on the tightly coupled processes of sensing, communication, and
computation among different devices. To tackle the challenge, we derive a
low-complexity ISCC algorithm by alternately optimizing the batch size control
and the network resource allocation. It is found that for each device, less
sensing power should be consumed if a larger batch of data samples is obtained
and vice versa. Besides, with a given batch size, the optimal computation speed
of one device is the minimum one that satisfies the latency constraint.
Numerical results based on a human motion recognition task verify the
theoretical convergence analysis and show that the proposed ISCC algorithm well
coordinates the batch size control and resource allocation among sensing,
communication, and computation to enhance the learning performance.

</details>


### [90] [Way to Build Native AI-driven 6G Air Interface: Principles, Roadmap, and Outlook](https://arxiv.org/abs/2508.15277)
*Ping Zhang,Kai Niu,Yiming Liu,Zijian Liang,Nan Ma,Xiaodong Xu,Wenjun Xu,Mengying Sun,Yinqiu Liu,Xiaoyun Wang,Ruichen Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于压缩和适应两大核心特性的原生AI驱动6G空口架构，通过语义通信实现任务相关的高效信息传输


<details>
  <summary>Details</summary>
Motivation: 人工智能需要在6G网络全生命周期中发挥基础性作用，从设计、部署到运营都需要AI原生支持

Method: 构建以压缩和适应为核心的原生AI驱动空口架构：压缩技术提取任务相关的语义信息，适应技术实现跨任务、数据类型和信道条件的动态语义信息传输

Result: 提出了完整的原生AI驱动空口架构框架，包括代表性使能方法，并通过6G非地面网络中的语义通信案例进行了验证

Conclusion: 原生AI是6G网络的关键发展方向，但仍面临诸多挑战和研究机遇，需要进一步探索

Abstract: Artificial intelligence (AI) is expected to serve as a foundational
capability across the entire lifecycle of 6G networks, spanning design,
deployment, and operation. This article proposes a native AI-driven air
interface architecture built around two core characteristics: compression and
adaptation. On one hand, compression enables the system to understand and
extract essential semantic information from the source data, focusing on task
relevance rather than symbol-level accuracy. On the other hand, adaptation
allows the air interface to dynamically transmit semantic information across
diverse tasks, data types, and channel conditions, ensuring scalability and
robustness. This article first introduces the native AI-driven air interface
architecture, then discusses representative enabling methodologies, followed by
a case study on semantic communication in 6G non-terrestrial networks. Finally,
it presents a forward-looking discussion on the future of native AI in 6G,
outlining key challenges and research opportunities.

</details>


### [91] [Some Optimal and Near Optimal Doppler Resilient Complementary Sequence Sets](https://arxiv.org/abs/2508.15325)
*Bingsheng Shen,Zhengchun Zhou,Yang Yang,Pingzhi Fan*

Main category: cs.IT

TL;DR: 基于OC-FHSSs、ADSs等结构构造最优或接近最优的多普勒弹性互补序列集


<details>
  <summary>Details</summary>
Motivation: 具有优异模糊函数的序列在雷达检测和现代移动通信中非常有用，多普勒弹性互补序列(DRCS)能够通过子序列模糊函数求和实现更低的旁瓣

Method: 基于一跳频序列集(OC-FHSSs)、几乎差集(ADSs)以及一些特定序列来构造新的DRCS集

Result: 所提出的DRCS集达到最优或接近最优性能

Conclusion: 通过多种数学结构成功构造了性能优异的多普勒弹性互补序列集，为雷达和通信应用提供了新的序列设计方案

Abstract: Sequences with excellent ambiguity functions are very useful in radar
detection and modern mobile communications. Doppler resilient complementary
sequence (DRCS) is a new type of sequence proposed recently, which can achieve
lower ambiguity function sidelobes by summing the ambiguity functions of
subsequences. In this paper, we introduce some new constructions of DRCS sets
(DRCSSs) based on one-coincidence frequency-hopping sequence sets (OC-FHSSs),
almost difference sets (ADSs), some specific sequences, etc. Critically, the
proposed DRCSSs are optimal or near optimal.

</details>


### [92] [High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering](https://arxiv.org/abs/2508.15639)
*Eito Kurihara,Hideki Ochiai*

Main category: cs.IT

TL;DR: 提出基于非等概率非均匀星座和削波滤波的高容量低PAPR OFDM系统，通过截断高斯分布生成星座点，优化星座设计降低复杂度，结合削波噪声消除技术实现低PAPR和高频谱效率


<details>
  <summary>Details</summary>
Motivation: 解决OFDM系统高峰均功率比(PAPR)问题，同时保持高容量和高频谱效率，通过星座设计和削波处理技术的结合来优化系统性能

Method: 使用截断高斯分布生成非均匀星座(NUC)，通过星座点合并减少信号点数而不损失比特互信息(BMI)，采用一维PAM调制降低解映射复杂度，结合削波滤波(CAF)和削波噪声消除(CNC)技术

Result: 仿真结果表明，所提系统在AWGN和频率选择性瑞利衰落信道下能同时实现低PAPR和高频谱效率，在衰落信道上的PAPR和BER性能显著优于单载波对应系统

Conclusion: 通过非等概率非均匀星座设计与削波处理技术的有效结合，BICM-OFDM系统能够成功解决高峰均功率比问题，同时保持优异的误码率性能和频谱效率

Abstract: We address a design of high-capacity and low-peak-to-average power ratio
(PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on
bit-interleaved coded modulation (BICM) utilizing non-equiprobable and
non-uniform (NENU) constellations as well as clipping and filtering (CAF). The
proposed constellations are generated using a truncated Gaussian distribution,
and the merging of constellation points, where the former creates a non-uniform
constellation (NUC), and the latter decreases the number of signal points
without compromising the achievable bit-wise mutual information (BMI). Since
the proposed constellations are uniquely determined by only the two parameters,
each associated with NUC and cardinality, the complexity required for the
numerical optimization process can be significantly low. We focus on the
constellation design based on one dimension, i.e., pulse amplitude modulation
(PAM), which facilitates the reduction of demapping complexity for the BICM
receiver. The use of CAF at the transmitter can efficiently reduce the PAPR of
OFDM signals; however, it introduces clipping noise that may degrade error rate
performance, making the application of clipping noise cancellation (CNC) at the
receiver essential. Therefore, we optimize the NENU constellations in the
presence of CAF and CNC. Simulation results demonstrate that the combination of
constellation shaping with CAF and CNC enables BICM-OFDM systems to
simultaneously achieve low PAPR and high spectral efficiency over additive
white Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading
channels. Furthermore, comparative studies confirm that the proposed system
significantly outperforms the single-carrier counterpart (i.e., DFT-precoded
BICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading
channels.

</details>
